[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Psicometria",
    "section": "",
    "text": "Benvenuti\nBenvenuti nel sito web dell’insegnamento di Psicometria, parte del Corso di Laurea in Scienze e Tecniche Psicologiche dell’Università degli Studi di Firenze.",
    "crumbs": [
      "Benvenuti"
    ]
  },
  {
    "objectID": "index.html#descrizione",
    "href": "index.html#descrizione",
    "title": "Psicometria",
    "section": "Descrizione",
    "text": "Descrizione\nIl corso offre una formazione teorico-pratica nell’analisi dei dati psicologici, con particolare attenzione alle applicazioni in R. Vengono affrontati temi come analisi descrittiva, esplorazione dei dati, flusso di lavoro, organizzazione di progetti e modelli statistici di base, sia bayesiani che frequentisti. Grande enfasi è posta sulle buone pratiche di Open Science, promuovendo trasparenza e riproducibilità nelle analisi.\n\nAnno Accademico: 2024-2025\nCodice Insegnamento: B000286\nOrario e Luogo: Lunedì e Martedì (8:30-10:30), Giovedì (11:30-13:30), Plesso didattico La Torretta.\n\n\n\n\n\n\n\nQuesto sito web ospita la dispensa ufficiale dell’insegnamento B000286 - Psicometria, che include tutte le note e i materiali relativi alle lezioni.",
    "crumbs": [
      "Benvenuti"
    ]
  },
  {
    "objectID": "index.html#struttura-dellinsegnamento",
    "href": "index.html#struttura-dellinsegnamento",
    "title": "Psicometria",
    "section": "Struttura dell’Insegnamento",
    "text": "Struttura dell’Insegnamento\nIl corso è strutturato per fornire una solida base teorica e pratica nell’analisi dei dati psicologici, combinando approcci metodologici, applicazioni pratiche ed esercitazioni mirate.\n\nIntroduzione a R: Approccio pratico all’utilizzo di R per l’analisi dei dati, con enfasi sulla scrittura di script replicabili e sulla creazione di workflow efficienti.\n\nGestione di Progetti di Analisi: Strategie per organizzare, documentare e comunicare progetti di data analysis, seguendo le buone pratiche della Open Science e della ricerca trasparente.\n\nStatistica Descrittiva: Esplorazione dei dati attraverso misure descrittive, distribuzioni statistiche e visualizzazioni grafiche.\n\nFondamenti di Probabilità: Introduzione ai concetti di probabilità, distribuzioni e incertezza, come base essenziale per l’inferenza statistica.\n\nInferenza Frequentista e Bayesiana: Panoramica sui due principali approcci all’inferenza statistica, con esempi pratici e confronto tra i metodi.\n\nVisualizzazione e Comunicazione: Tecniche avanzate per rappresentare risultati statistici in modo chiaro, efficace e persuasivo, includendo la creazione di report e grafici professionali.\n\nIl corso integra questi argomenti in un percorso didattico coerente, che combina lezioni teoriche, esercitazioni pratiche e momenti di riflessione critica. Gli studenti saranno così preparati ad applicare l’analisi dei dati sia in contesti accademici che pratici.",
    "crumbs": [
      "Benvenuti"
    ]
  },
  {
    "objectID": "index.html#esercizi",
    "href": "index.html#esercizi",
    "title": "Psicometria",
    "section": "Esercizi",
    "text": "Esercizi\nLe esercitazioni pratiche e gli esempi applicativi sono disponibili sulla pagina Moodle dedicata all’insegnamento.",
    "crumbs": [
      "Benvenuti"
    ]
  },
  {
    "objectID": "index.html#syllabus",
    "href": "index.html#syllabus",
    "title": "Psicometria",
    "section": "Syllabus",
    "text": "Syllabus\nConsulta il syllabus completo per ulteriori dettagli.",
    "crumbs": [
      "Benvenuti"
    ]
  },
  {
    "objectID": "prefazione.html",
    "href": "prefazione.html",
    "title": "Prefazione",
    "section": "",
    "text": "Bibliografia\nCome possiamo migliorare l’analisi dei dati psicologici per renderla più affidabile e robusta? È possibile affrontare questa sfida semplicemente applicando una serie di algoritmi o procedure standard? L’analisi dei dati in psicologia può davvero essere ridotta a un insieme di “ricette” preconfezionate (McElreath, 2020)?\nQueste domande ci portano a riflettere sulla natura stessa dell’analisi dei dati psicologici. A differenza di ciò che suggerisce l’approccio frequentista del test dell’ipotesi nulla, l’analisi dei dati non è una disciplina che si esaurisce con l’applicazione meccanica di metodi predefiniti. Anzi, considerare l’analisi dei dati come un insieme di procedure automatiche contribuisce a uno dei problemi più gravi della psicologia contemporanea: la crisi della replicabilità dei risultati (Korbmacher et al., 2023).\nMa perché la replicabilità è così cruciale? Se i risultati delle ricerche psicologiche non sono replicabili, significa che la nostra comprensione dei fenomeni psicologici è superficiale e inaffidabile. Questo non è solo un problema teorico o accademico; ha implicazioni dirette sulle applicazioni pratiche della psicologia. Se le basi scientifiche sono incerte, anche le strategie di intervento psicologico rischiano di essere inefficaci o addirittura dannose (Funder et al., 2014; Ioannidis, 2019; Shrout & Rodgers, 2018; Tackett et al., 2019).\nPerché le pratiche di analisi dei dati derivanti dal frequentismo potrebbero contribuire a questa crisi? In che modo gli incentivi accademici influenzano la qualità della ricerca psicologica? E, soprattutto, quali alternative abbiamo per migliorare l’affidabilità e la validità delle nostre conclusioni?\nL’analisi bayesiana emerge come una delle proposte per superare i limiti dell’approccio frequentista (Gelman et al., 1995). Tuttavia, è sufficiente abbandonare l’inferenza frequentista per risolvere i problemi della psicologia? Come possiamo integrare metodi robusti e flessibili, come quelli bayesiani, con una comprensione più approfondita e trasparente dei fenomeni psicologici?\nIn questo corso, esploreremo queste domande, cercando di identificare le “buone pratiche” dell’analisi dei dati psicologici. Discuteremo i limiti delle metodologie attuali, esamineremo le cause sottostanti della crisi della replicabilità e valuteremo come l’adozione di metodi avanzati, come l’inferenza bayesiana e la modellazione causale, possa offrire soluzioni efficaci (Oberauer & Lewandowsky, 2019; Wagenmakers et al., 2018; Yarkoni, 2022). Il nostro obiettivo è fornire una visione critica e costruttiva, che non solo identifichi le sfide della ricerca psicologica, ma proponga anche percorsi concreti per migliorare la qualità e l’affidabilità della scienza psicologica.",
    "crumbs": [
      "Prefazione"
    ]
  },
  {
    "objectID": "prefazione.html#bibliografia",
    "href": "prefazione.html#bibliografia",
    "title": "Prefazione",
    "section": "",
    "text": "Funder, D. C., Levine, J. M., Mackie, D. M., Morf, C. C., Sansone, C., Vazire, S., & West, S. G. (2014). Improving the dependability of research in personality and social psychology: Recommendations for research and educational practice. Personality and Social Psychology Review, 18(1), 3–12.\n\n\nGelman, A., Carlin, J. B., Stern, H. S., & Rubin, D. B. (1995). Bayesian data analysis. Chapman; Hall/CRC.\n\n\nIoannidis, J. P. (2019). What have we (not) learnt from millions of scientific papers with P values? The American Statistician, 73(sup1), 20–25.\n\n\nKorbmacher, M., Azevedo, F., Pennington, C. R., Hartmann, H., Pownall, M., Schmidt, K., Elsherif, M., Breznau, N., Robertson, O., Kalandadze, T., et al. (2023). The replication crisis has led to positive structural, procedural, and community changes. Communications Psychology, 1(1), 3.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nOberauer, K., & Lewandowsky, S. (2019). Addressing the theory crisis in psychology. Psychonomic Bulletin & Review, 26, 1596–1618.\n\n\nShrout, P. E., & Rodgers, J. L. (2018). Psychology, science, and knowledge construction: Broadening perspectives from the replication crisis. Annual Review of Psychology, 69(1), 487–510.\n\n\nTackett, J. L., Brandes, C. M., King, K. M., & Markon, K. E. (2019). Psychology’s replication crisis and clinical psychological science. Annual Review of Clinical Psychology, 15(1), 579–604.\n\n\nWagenmakers, E.-J., Marsman, M., Jamil, T., Ly, A., Verhagen, J., Love, J., Selker, R., Gronau, Q. F., Šmı́ra, M., Epskamp, S., et al. (2018). Bayesian inference for psychology. Part I: Theoretical advantages and practical ramifications. Psychonomic Bulletin & Review, 25, 35–57.\n\n\nYarkoni, T. (2022). The generalizability crisis. Behavioral and Brain Sciences, 45, e1.",
    "crumbs": [
      "Prefazione"
    ]
  },
  {
    "objectID": "programmazione2024.html",
    "href": "programmazione2024.html",
    "title": "Calendario Didattico e Programma del Corso",
    "section": "",
    "text": "Calendario delle relazioni in itinere\nIl calendario didattico prevede 32 incontri, con un esame parziale a metà corso e gli ultimi tre incontri riservati a un secondo esame parziale e alle presentazioni degli studenti.\nLe relazioni di avanzamento del progetto di gruppo dovranno essere consegnate entro le scadenze stabilite. Ogni gruppo dovrà presentare un unico elaborato.\nOgni relazione rappresenta una tappa del progetto di gruppo, che culminerà nella presentazione finale durante gli ultimi incontri del corso.",
    "crumbs": [
      "Calendario",
      "Calendario Didattico e Programma del Corso"
    ]
  },
  {
    "objectID": "programmazione2024.html#calendario-delle-lezioni",
    "href": "programmazione2024.html#calendario-delle-lezioni",
    "title": "1  Incontri",
    "section": "",
    "text": "Incontro\nData\nArgomento\nOrario\n\n\n\n\n1\n3 marzo\nPresentazione del corso, struttura e obiettivi. Fondamenti\n8:30-10:30\n\n\n2\n4 marzo\nTeoria della misurazione. Introduzione a R (I)\n8:30-10:30\n\n\n3\n6 marzo\nIntroduzione a R (II)\n11:30-13:30\n\n\n4\n10 marzo\nIntroduzione a R (III)\n8:30-10:30\n\n\n5\n11 marzo\nExploratory Data Analysis\n8:30-10:30\n\n\n6\n13 marzo\nStatistica descrittiva\n11:30-13:30\n\n\n7\n17 marzo\nAssociazioni tra variabili. Causalità\n8:30-10:30\n\n\n8\n18 marzo\nElementi di teoria della probabilità\n8:30-10:30\n\n\n9\n20 marzo\nProbabilità condizionata\n11:30-13:30\n\n\n10\n24 marzo\nVariabili casuali\n8:30-10:30\n\n\n11\n25 marzo\nTeorema di Bayes\n8:30-10:30\n\n\n12\n27 marzo\nDistribuzioni campionarie\n11:30-13:30\n\n\n13\n31 marzo\nDistribuzione di probabilità congiunta. Densità di probabilità\n8:30-10:30\n\n\n14\n1 aprile\nDistribuzioni di massa di probabilità\n8:30-10:30\n\n\n15\n3 aprile\nDistribuzioni di densità di probabilità\n11:30-13:30\n\n\n16\n7 aprile\nFunzione di verosimiglianza\n8:30-10:30\n\n\n17\n8 aprile\nIntroduzione all’inferenza bayesiana\n8:30-10:30\n\n\n18\n10 aprile\nMetodi numerici per approssimare la distribuzione a posteriori\n11:30-13:30\n\n\n19\n15 aprile\nFamiglie coniugate. Sommario a posteriori\n8:30-10:30\n\n\n20\n17 aprile\nEsame parziale\n11:30-13:30\n\n\n21\n22 aprile\nAlgoritmo di Metropolis\n8:30-10:30\n\n\n22\n24 aprile\nModello di regressione frequentista\n11:30-13:30\n\n\n23\n28 aprile\nModello di regressione bayesiano\n8:30-10:30\n\n\n24\n29 aprile\nInferenza bayesiana sulla media di un campione e sulle medie di due campioni indipendenti.\n8:30-10:30\n\n\n25\n6 maggio\nAnalisi della varianza ad una e due vie\n8:30-10:30\n\n\n26\n8 maggio\nInferenza frequentista: intervalli di fiducia\n11:30-13:30\n\n\n27\n12 maggio\nInferenza frequentista: test di ipotesi\n8:30-10:30\n\n\n28\n13 maggio\nInferenza frequentista: due gruppi indipendenti\n8:30-10:30\n\n\n29\n15 maggio\nCrisi della replicazione\n11:30-13:30\n\n\n30\n19 maggio\nEsame parziale finale\n8:30-10:30\n\n\n31\n20 maggio\nPresentazioni dei progetti\n8:30-10:30\n\n\n32\n22 maggio\nPresentazioni dei progetti\n11:30-13:30",
    "crumbs": [
      "Calendario",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Incontri</span>"
    ]
  },
  {
    "objectID": "programmazione2024.html#calendario-delle-relazioni-in-itinere",
    "href": "programmazione2024.html#calendario-delle-relazioni-in-itinere",
    "title": "Calendario Didattico e Programma del Corso",
    "section": "",
    "text": "Data di Scadenza\nContenuto della Relazione\n\n\n\n\n23 marzo\nRelazione 1: Importazione dei dati, data wrangling, data tidying, dizionario dei dati, statistiche descrittive\n\n\n23 aprile\nRelazione 2: Priori coniugati e metodo basato su griglia\n\n\n10 maggio\nRelazione 3: Regressione lineare\n\n\n18 maggio\nRelazione 4: Analisi frequentista; limiti dell’approccio frequentista",
    "crumbs": [
      "Calendario",
      "Calendario Didattico e Programma del Corso"
    ]
  },
  {
    "objectID": "programmazione2024.html#esame-parziale-e-presentazioni-finali",
    "href": "programmazione2024.html#esame-parziale-e-presentazioni-finali",
    "title": "1  Incontri",
    "section": "1.2 Esame parziale e presentazioni finali",
    "text": "1.2 Esame parziale e presentazioni finali\n\n\n\n\n\n\n\n\n\nIncontro\nData\nArgomento\nOrario\n\n\n\n\n30\n19 maggio\nEsame parziale finale\n8:30-10:30\n\n\n31\n20 maggio\nPresentazioni dei progetti\n8:30-10:30\n\n\n32\n22 maggio\nPresentazioni dei progetti\n11:30-13:30",
    "crumbs": [
      "Calendario",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Incontri</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/introduction_key_notions.html",
    "href": "chapters/key_notions/introduction_key_notions.html",
    "title": "Fondamenti",
    "section": "",
    "text": "La data science è un campo che si sviluppa all’intersezione tra la statistica e l’informatica. La statistica fornisce una serie di metodologie per analizzare i dati e ottenere informazioni significative, mentre l’informatica si occupa dello sviluppo di software e strumenti per implementare tali metodologie. In questa sezione della dispensa, approfondiremo alcuni concetti fondamentali della statistica e della misurazione psicologica. Considereremo anche in termini generali quali sono gli obiettivi e i limiti dell’analisi dei dati psicologici.",
    "crumbs": [
      "Fondamenti"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_uncertainty.html",
    "href": "chapters/key_notions/01_uncertainty.html",
    "title": "2  Abbracciare l’incertezza",
    "section": "",
    "text": "2.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nL’espressione “abbracciare l’incertezza” è tra le più emblematiche nel panorama della statistica bayesiana. In questo capitolo, approfondiremo il significato di questa affermazione, seguendo la trattazione introduttiva proposta nel primo capitolo di Understanding Uncertainty di Lindley (Lindley, 2013).",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_uncertainty.html#lincertezza-nella-ricerca-psicologica",
    "href": "chapters/key_notions/01_uncertainty.html#lincertezza-nella-ricerca-psicologica",
    "title": "2  Abbracciare l’incertezza",
    "section": "2.2 L’incertezza nella ricerca psicologica",
    "text": "2.2 L’incertezza nella ricerca psicologica\nL’incertezza rappresenta un elemento cruciale non solo nella statistica, ma in tutte le discipline scientifiche, con particolare rilievo per la psicologia, che affronta fenomeni complessi e difficili da misurare. Nell’indagare processi cognitivi, emozioni e comportamenti, i ricercatori si confrontano con dati complessi, spesso ambigui e suscettibili di interpretazioni molteplici. Sebbene alcune affermazioni possano essere sostenute con elevata confidenza o confutate con certezza, la maggior parte delle ipotesi scientifiche si colloca in una zona grigia dominata dall’incertezza.\nL’obiettivo di questo insegnamento è guidare gli studenti nella comprensione e nella gestione dell’incertezza nella ricerca psicologica, adottando l’approccio bayesiano all’analisi dei dati. Questo metodo, basato sulla quantificazione e sull’aggiornamento delle credenze alla luce di nuove evidenze, fornirà agli studenti gli strumenti per affrontare l’incertezza in modo rigoroso e sistematico, sia nella carriera accademica sia nella pratica clinica.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_uncertainty.html#la-natura-soggettiva-dellincertezza",
    "href": "chapters/key_notions/01_uncertainty.html#la-natura-soggettiva-dellincertezza",
    "title": "2  Abbracciare l’incertezza",
    "section": "2.3 La natura soggettiva dell’incertezza",
    "text": "2.3 La natura soggettiva dell’incertezza\nUn elemento cruciale dell’incertezza, spesso trascurato, è la sua dimensione soggettiva. De Finetti (Finetti, 1970) ha evidenziato come l’incertezza sia, almeno in parte, una questione personale: ciò che è incerto per uno psicologo può non esserlo per un altro, in funzione delle loro esperienze, conoscenze pregresse e interpretazioni dei dati disponibili. Anche di fronte a una stessa questione, due ricercatori possono condividere un’incertezza comune, ma con gradi di intensità diversi.\nQuesta componente soggettiva è particolarmente significativa in psicologia, dove le differenze individuali e culturali influenzano la percezione e l’interpretazione dei fenomeni. L’approccio bayesiano offre un potente strumento per affrontare questa soggettività, consentendo di quantificare le differenze tra credenze individuali e di aggiornarle in modo coerente sulla base di nuove evidenze oggettive.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_uncertainty.html#lonnipresenza-dellincertezza",
    "href": "chapters/key_notions/01_uncertainty.html#lonnipresenza-dellincertezza",
    "title": "2  Abbracciare l’incertezza",
    "section": "2.4 L’onnipresenza dell’incertezza",
    "text": "2.4 L’onnipresenza dell’incertezza\nL’incertezza pervade ogni aspetto della ricerca psicologica. Ogni esperimento, misurazione o interpretazione dei dati comporta un margine di incertezza. Questa condizione è particolarmente evidente nello studio di fenomeni complessi come il comportamento umano o i processi mentali, dove innumerevoli variabili interagiscono, molte delle quali difficili da misurare o controllare con precisione.\nTuttavia, l’incertezza non deve essere vista come un ostacolo insormontabile. Al contrario, riconoscerla e quantificarla può favorire una comprensione più profonda e realistica dei fenomeni psicologici. Attraverso l’approccio bayesiano, diventa possibile integrare l’incertezza nel processo di indagine scientifica, trattandola non come un limite, ma come una risorsa (Koetke et al., 2024).",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_uncertainty.html#superare-la-soppressione-dellincertezza",
    "href": "chapters/key_notions/01_uncertainty.html#superare-la-soppressione-dellincertezza",
    "title": "2  Abbracciare l’incertezza",
    "section": "2.5 Superare la soppressione dell’incertezza",
    "text": "2.5 Superare la soppressione dell’incertezza\nNonostante la sua onnipresenza, l’incertezza è spesso ignorata o minimizzata nella comunicazione scientifica. Questo può avvenire attraverso interpretazioni eccessivamente ottimistiche dei risultati, la presentazione di conclusioni come fatti certi, o una riluttanza a riconoscere i limiti degli studi condotti. Tale atteggiamento, sebbene comprensibile, può condurre a conclusioni errate e a una visione distorta della realtà.\nL’approccio bayesiano permette di affrontare l’incertezza in modo esplicito e costruttivo. Fornendo un quadro rigoroso per quantificarla, analizzarla e comunicarla chiaramente, migliora la trasparenza della ricerca e promuove conclusioni più oneste e accurate.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_uncertainty.html#i-benefici-dellincertezza",
    "href": "chapters/key_notions/01_uncertainty.html#i-benefici-dellincertezza",
    "title": "2  Abbracciare l’incertezza",
    "section": "2.6 I benefici dell’incertezza",
    "text": "2.6 I benefici dell’incertezza\nContrariamente a quanto si possa pensare, l’incertezza offre numerosi vantaggi per la ricerca psicologica:\n\nStimola l’esplorazione scientifica: La consapevolezza dell’incertezza incoraggia i ricercatori a formulare nuove ipotesi e a migliorare i metodi di studio.\nPromuove l’onestà intellettuale: Accettare l’incertezza rende i ricercatori più cauti e aperti a prospettive alternative.\nMigliora la qualità delle analisi: Integrare l’incertezza porta a disegni sperimentali più robusti e interpretazioni più accurate.\nFacilita la collaborazione interdisciplinare: Riconoscere i limiti delle proprie conoscenze stimola la ricerca di input da altri esperti.\nRiflette la complessità dei fenomeni psicologici: L’incertezza è intrinseca ai processi mentali e riconoscerla consente di rappresentarli in modo più realistico.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_uncertainty.html#tipi-di-incertezza",
    "href": "chapters/key_notions/01_uncertainty.html#tipi-di-incertezza",
    "title": "2  Abbracciare l’incertezza",
    "section": "2.7 Tipi di incertezza",
    "text": "2.7 Tipi di incertezza\nL’incertezza nella ricerca può essere classificata in tre categorie principali, in base alla sua origine: aleatoria, epistemica e ontologica (Gansch & Adee, 2020).\n\n2.7.1 Incertezza Aleatoria\nL’incertezza aleatoria è intrinseca alla natura casuale di un processo e non può essere eliminata per un dato modello probabilistico. Essa è considerata irreducibile e viene quantificata tramite distribuzioni probabilistiche. Ad esempio, nella misurazione della risposta di un individuo a uno stimolo, la variabilità intrinseca nel comportamento umano, dovuta a fattori imprevedibili, rappresenta un caso di incertezza aleatoria. Questo tipo di incertezza è una caratteristica fondamentale di molti fenomeni psicologici e biologici.\n\n\n2.7.2 Incertezza Epistemica\nL’incertezza epistemica deriva dalla conoscenza limitata o incompleta di un fenomeno. Essa rappresenta il “noto-ignoto”, cioè ciò che sappiamo di non sapere, ed è legata alle semplificazioni insite in ogni modello scientifico. Ad esempio, un modello psicologico che non consideri le influenze culturali o ambientali potrebbe risultare incompleto, introducendo incertezza epistemica. Diversamente dall’incertezza aleatoria, l’incertezza epistemica può essere ridotta attraverso il miglioramento dei modelli, l’inclusione di variabili rilevanti o la raccolta di ulteriori dati.\n\n\n2.7.3 Incertezza Ontologica\nL’incertezza ontologica riguarda l’“ignoto-ignoto”, ovvero aspetti di un sistema che non sono ancora stati identificati. In psicologia, questo potrebbe riferirsi a variabili o processi non ancora scoperti che influenzano un comportamento. Ad esempio, studiando i disturbi mentali, potrebbero emergere nuovi fattori di rischio precedentemente sconosciuti.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_uncertainty.html#il-calcolo-dellincertezza-nellapproccio-bayesiano",
    "href": "chapters/key_notions/01_uncertainty.html#il-calcolo-dellincertezza-nellapproccio-bayesiano",
    "title": "2  Abbracciare l’incertezza",
    "section": "2.8 Il calcolo dell’incertezza nell’approccio bayesiano",
    "text": "2.8 Il calcolo dell’incertezza nell’approccio bayesiano\nL’insegnamento si propone di fornire agli studenti strumenti per affrontare e quantificare l’incertezza attraverso l’approccio bayesiano (Gelman et al., 1995). Fondato sul teorema di Bayes, questo metodo rappresenta un quadro teorico rigoroso e sistematico per aggiornare le credenze alla luce di nuove evidenze, configurandosi come una componente centrale della metodologia scientifica.\nIl processo si basa su quattro passaggi essenziali. In primo luogo, si parte dalla quantificazione delle credenze iniziali, note come prior, che rappresentano le conoscenze pregresse o le ipotesi relative a un determinato fenomeno psicologico. Successivamente, si analizza la forza delle evidenze empiriche fornite dai dati raccolti, formalizzata nella likelihood. Queste due informazioni vengono combinate per generare le credenze aggiornate, chiamate posterior, che sintetizzano la conoscenza disponibile integrando i dati empirici e le ipotesi iniziali. Infine, le credenze aggiornate possono essere utilizzate per prendere decisioni più informate, pianificare ricerche future e orientare interventi.\n\n2.8.1 Il ruolo delle credenze e delle decisioni nella ricerca psicologica\nLe credenze rivestono un ruolo fondamentale nella ricerca psicologica, influenzando tutte le fasi del processo scientifico, dalla progettazione degli esperimenti all’interpretazione dei risultati, fino alla scelta di interventi clinici. L’approccio bayesiano si distingue per la sua capacità di esplicitare e formalizzare queste credenze, consentendo di aggiornare il loro contenuto in modo coerente e trasparente man mano che emergono nuove evidenze.\nQuesto metodo permette non solo di ottimizzare le decisioni basandosi su informazioni aggiornate, ma anche di comunicare chiaramente l’incertezza associata alle conclusioni, evidenziandone i limiti e garantendo maggiore trasparenza scientifica. Affrontare l’incertezza come una componente intrinseca della ricerca non solo migliora la qualità dell’analisi, ma consente anche di promuovere un approccio più realistico e rigoroso nello studio dei fenomeni psicologici.\nIn sintesi, l’approccio bayesiano offre un modello operativo per integrare l’incertezza nel processo decisionale, trattandola non come un ostacolo, ma come un elemento essenziale per una comprensione più sfumata e accurata della realtà.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_uncertainty.html#riflessioni-conclusive",
    "href": "chapters/key_notions/01_uncertainty.html#riflessioni-conclusive",
    "title": "2  Abbracciare l’incertezza",
    "section": "2.9 Riflessioni Conclusive",
    "text": "2.9 Riflessioni Conclusive\nQuesto insegnamento fornisce gli strumenti per applicare l’analisi bayesiana nell’ambito dei dati psicologici, insegnando a considerare l’incertezza come una parte integrante e preziosa del processo scientifico. Attraverso questo approccio, gli studenti potranno acquisire una comprensione più raffinata e strutturata dei fenomeni psicologici, integrando l’incertezza come elemento fondamentale per interpretare i dati e formulare inferenze rigorose.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_uncertainty.html#bibliografia",
    "href": "chapters/key_notions/01_uncertainty.html#bibliografia",
    "title": "2  Abbracciare l’incertezza",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nFinetti, B. de. (1970). Teoria delle probabilità: sintesi introduttiva con appendice critica. Einaudi.\n\n\nGansch, R., & Adee, A. (2020). System theoretic view on uncertainties. 2020 Design, Automation & Test in Europe Conference & Exhibition (DATE), 1345–1350.\n\n\nGelman, A., Carlin, J. B., Stern, H. S., & Rubin, D. B. (1995). Bayesian data analysis. Chapman; Hall/CRC.\n\n\nKoetke, J., Schumann, K., Bowes, S. M., & Vaupotič, N. (2024). The effect of seeing scientists as intellectually humble on trust in scientists and their research. Nature Human Behaviour, 1–14.\n\n\nLindley, D. V. (2013). Understanding uncertainty. John Wiley & Sons.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_key_notions.html",
    "href": "chapters/key_notions/02_key_notions.html",
    "title": "3  Concetti chiave",
    "section": "",
    "text": "Introduzione\nNel contesto della ricerca scientifica, la formulazione di risposte a specifiche domande di indagine si realizza mediante l’applicazione di metodologie rigorose e l’esecuzione di osservazioni accurate e controllate. Le informazioni raccolte attraverso diverse tecniche di indagine – come le ricerche sul campo, le indagini campionarie e i protocolli sperimentali – vengono identificate con il termine tecnico di dati. Questo capitolo introduce i principi fondamentali dell’analisi dei dati, concentrandosi sia sulle caratteristiche dei dati stessi sia sui metodi di raccolta.\nL’analisi dei dati consente di sintetizzare grandi quantità di informazioni e di verificare le previsioni avanzate dalle teorie. Tuttavia, senza una teoria che dia significato ai dati, le osservazioni rimangono mere descrizioni prive di un contesto esplicativo. È attraverso l’integrazione tra dati e teoria che si raggiunge una comprensione profonda dei fenomeni e si favorisce l’avanzamento scientifico.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_key_notions.html#introduzione",
    "href": "chapters/key_notions/02_key_notions.html#introduzione",
    "title": "3  Concetti chiave",
    "section": "",
    "text": "Statistica\n\n\n\nIl termine “statistica” può assumere diversi significati, a seconda del contesto in cui viene utilizzato.\n\nNel primo senso, la statistica è una scienza e una disciplina che si occupa dello studio e dell’applicazione di metodi e tecniche per la raccolta, l’organizzazione, l’analisi, l’interpretazione e la presentazione di dati.\nNel secondo senso, il termine “statistica” si riferisce a una singola misura o un valore numerico che è stato calcolato a partire da un campione di dati. Questo tipo di statistica rappresenta una caratteristica specifica del campione. Esempi comuni di statistiche in questo senso includono la media campionaria, la deviazione standard campionaria o il coefficiente di correlazione campionario.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_key_notions.html#la-spiegazione-scientifica",
    "href": "chapters/key_notions/02_key_notions.html#la-spiegazione-scientifica",
    "title": "3  Concetti chiave",
    "section": "3.1 La Spiegazione Scientifica",
    "text": "3.1 La Spiegazione Scientifica\nLa scienza non si limita a descrivere o prevedere i fenomeni: il suo obiettivo principale è spiegare il perché degli eventi, offrendo una comprensione approfondita delle cause e dei meccanismi che regolano il mondo. La spiegazione scientifica rappresenta un elemento cruciale per la costruzione di teorie capaci non solo di descrivere e prevedere, ma anche di chiarire le dinamiche causali e le connessioni tra i fenomeni, contribuendo così a un controllo più consapevole e informato su di essi.\nConsideriamo, ad esempio, il rapporto tra il background familiare e il rendimento scolastico. Numerose ricerche evidenziano una forte correlazione tra il livello di istruzione dei genitori e il successo accademico dei figli. Una prospettiva puramente descrittiva potrebbe limitarsi a constatare che: “Gli studenti provenienti da famiglie con basso livello di istruzione hanno minori probabilità di conseguire un titolo universitario”. Tuttavia, la vera sfida scientifica consiste nell’andare oltre questa previsione, ponendosi domande più profonde:\n\nQuali meccanismi causali determinano questa disparità?\n\nQuali interventi possono efficacemente ridurre tali disuguaglianze?\n\nPer superare il livello di semplice previsione, la ricerca deve identificare i fattori causali alla base del fenomeno, esplorare come l’azione su questi fattori possa modificare gli esiti, e valutare le incertezze e le dinamiche temporali degli interventi.\nNel caso dell’educazione, ciò implica comprendere, ad esempio:\n\nSe e in che modo il sostegno finanziario possa realmente favorire il percorso degli studenti svantaggiati.\n\nQuali politiche educative possano produrre effetti positivi sul lungo termine.\n\nCome i meccanismi sociali e individuali influenzino il processo educativo.\n\nAcquisire una conoscenza approfondita dei meccanismi causali permette di andare oltre la semplice previsione, rendendo possibile la progettazione di interventi mirati e strategici che possano realmente incidere sui fenomeni in modo efficace e duraturo.\n\n3.1.1 Elementi Fondamentali della Spiegazione Scientifica\nLa filosofia della scienza identifica tre elementi essenziali che caratterizzano una spiegazione scientifica:\n\nExplanandum: il fenomeno da spiegare, ovvero ciò che richiede una comprensione o una giustificazione. Ad esempio, “gli studenti con livelli elevati di ansia da prestazione ottengono punteggi inferiori nei test scolastici rispetto ai loro coetanei.”\nExplanans: l’insieme di fattori o affermazioni che spiegano il fenomeno osservato. Nel caso dell’ansia da prestazione, l’explanans potrebbe includere: “l’ansia compromette la capacità di concentrazione e memoria di lavoro, influenzando negativamente la prestazione nei test.”\nLegame esplicativo: i principi o i meccanismi che descrivono come l’explanans produce l’explanandum. Nel nostro esempio, il legame esplicativo potrebbe essere: “elevati livelli di ansia attivano il sistema nervoso simpatico, aumentando lo stress fisiologico e riducendo l’efficienza dei processi cognitivi necessari per svolgere compiti complessi.”\n\nQuesti tre elementi si integrano nei modelli scientifici, che rappresentano strumenti metodologici per ottenere spiegazioni. I modelli scientifici in psicologia, in particolare, cercano di includere il fenomeno da spiegare, i fattori causali che lo influenzano, e i meccanismi sottostanti che collegano cause ed effetti.\nAd esempio, un modello psicologico sull’ansia da prestazione potrebbe incorporare variabili come il livello di ansia percepita, la capacità di regolazione emotiva, e la relazione di queste con la memoria di lavoro. Rispetto ai modelli puramente descrittivi o predittivi, tali modelli rispondono a domande causali, permettendo non solo di comprendere il fenomeno, ma anche di progettare interventi per ridurre l’impatto dell’ansia sulla prestazione.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_key_notions.html#modelli-psicologici",
    "href": "chapters/key_notions/02_key_notions.html#modelli-psicologici",
    "title": "3  Concetti chiave",
    "section": "3.2 Modelli Psicologici",
    "text": "3.2 Modelli Psicologici\nUn modello è una rappresentazione matematica e concettuale semplificata di un fenomeno reale. Si basa su un insieme di equazioni e ipotesi che definiscono le relazioni tra variabili e la struttura probabilistica del fenomeno, con l’obiettivo di coglierne gli aspetti essenziali senza includerne ogni dettaglio. Poiché spesso esistono diversi modelli applicabili a uno stesso problema, il compito della ricerca è identificare quello che meglio descrive i dati, rispettando criteri di validità, precisione e parsimonia.\nI modelli psicologici, in particolare, sono strumenti teorici per descrivere, spiegare e prevedere il comportamento umano e i processi mentali. Un modello psicologico ben costruito dovrebbe possedere alcune caratteristiche fondamentali:\n\nCoerenza descrittiva: Il modello deve rappresentare il fenomeno in modo logico e coerente, catturando gli aspetti chiave del processo psicologico e organizzando le osservazioni in una struttura comprensibile.\nCapacità predittiva: Deve essere in grado di fare previsioni accurate su futuri sviluppi del fenomeno, rendendo possibile testare la validità delle sue ipotesi attraverso i dati.\nSupporto empirico: Le ipotesi e le previsioni del modello devono essere confermate da dati raccolti mediante ricerche sistematiche e rigorose.\nFalsificabilità: Un modello scientifico deve poter essere testato e, se necessario, confutato sulla base di osservazioni e risultati sperimentali. Questo principio garantisce la possibilità di revisione e miglioramento.\nParsimonia: Il modello deve spiegare il fenomeno in modo semplice, evitando complessità inutili o ridondanti.\nGeneralizzabilità: Deve essere applicabile a una varietà di situazioni e contesti, superando i confini di specifiche condizioni sperimentali.\nUtilità pratica: Deve fornire indicazioni utili per interventi, terapie o applicazioni concrete nel mondo reale.\n\nLa modellazione in psicologia presenta sfide uniche a causa della natura soggettiva, complessa e variabile dell’esperienza umana. I ricercatori devono trovare un equilibrio tra la precisione teorica e la flessibilità necessaria per cogliere la complessità dei fenomeni psicologici, tenendo conto anche dei limiti etici della sperimentazione e delle implicazioni sociali.\nL’analisi dei dati è uno strumento centrale per valutare i modelli psicologici. Attraverso tecniche statistiche avanzate, si verifica se il modello riesce a spiegare i dati osservati e a fare previsioni attendibili su dati futuri. Questo processo consente non solo di comprendere meglio i fenomeni psicologici, ma anche di prevedere e, in alcuni casi, influenzare il comportamento e i processi mentali. Un modello valido rappresenta quindi un potente strumento per il progresso teorico e per lo sviluppo di interventi pratici.\n\n3.2.1 Rappresentare i Fenomeni per Ragionare e Comunicare\nLa spiegazione scientifica non si limita a chiarire i meccanismi causali, ma offre un linguaggio formale per analizzare e condividere conoscenze sui fenomeni. In psicologia, i modelli scientifici rappresentano strumenti fondamentali per descrivere i processi attraverso variabili, funzioni e parametri, fornendo una struttura per identificare relazioni e proprietà essenziali. Un modello efficace semplifica la complessità del fenomeno, rendendo più agevole sia la comunicazione tra studiosi sia la comprensione intuitiva.\nI modelli non solo organizzano informazioni, ma stimolano anche intuizioni, generando nuove domande di ricerca. Una rappresentazione chiara consente di formulare ipotesi innovative, collegare concetti apparentemente distanti e trasferire conoscenze tra ambiti disciplinari, ampliando così il campo della ricerca.\n\n\n3.2.2 Il Ruolo dell’Analisi dei Dati\nL’analisi dei dati è cruciale per la scienza, e in psicologia svolge due funzioni principali:\n\nSemplificare e sintetizzare informazioni complesse\nAttraverso statistiche descrittive, grafici e altre rappresentazioni, l’analisi dei dati aiuta a identificare schemi, tendenze e anomalie. Questo processo facilita la comprensione dei fenomeni psicologici e consente di esplorare le differenze tra individui o gruppi.\nValutare le predizioni teoriche\nConfrontando le aspettative di un modello con i dati raccolti, l’analisi verifica la validità delle ipotesi sottostanti. Questo confronto è essenziale per sostenere, migliorare o rivedere le teorie, contribuendo al progresso scientifico.\n\nTuttavia, l’analisi dei dati da sola non è sufficiente per comprendere a fondo un fenomeno. Correlazioni o schemi identificati nei dati, se privi di un contesto teorico, forniscono una visione limitata. Per esempio, osservare una relazione tra due variabili psicologiche non chiarisce la natura di questa connessione né spiega perché esista. È indispensabile un quadro teorico che interpreti e contestualizzi i risultati, proponendo meccanismi causali che diano significato alle osservazioni.\nUnire modelli teorici e analisi dei dati permette di andare oltre la descrizione, offrendo spiegazioni solide e utili per sviluppare interventi o approfondire la conoscenza dei fenomeni psicologici.\n\n\n3.2.3 Carattere Multidisciplinare dell’Analisi dei Dati\nL’analisi dei dati si colloca all’intersezione di tre discipline fondamentali: statistica, teoria della probabilità e informatica. Ciascuna di queste apporta strumenti, metodologie e prospettive indispensabili per comprendere i dati, estrarre conoscenze utili e sviluppare nuove ipotesi scientifiche.\n\nStatistica:\nLa statistica fornisce metodi per raccogliere, organizzare e interpretare i dati. Grazie a tecniche descrittive e inferenziali, consente di sintetizzare informazioni, identificare schemi, effettuare confronti e prendere decisioni basate sull’evidenza.\nTeoria della probabilità:\nQuesta disciplina costituisce il fondamento matematico della statistica. Permette di modellare e misurare l’incertezza, fornendo strumenti per analizzare i fenomeni aleatori e comprendere la variabilità che caratterizza molte osservazioni in psicologia.\nInformatica:\nL’informatica contribuisce all’analisi dei dati con strumenti per gestire, elaborare e visualizzare grandi quantità di informazioni. Attraverso la programmazione e l’utilizzo di algoritmi avanzati, rende possibile l’applicazione di modelli complessi e l’analisi di dataset di dimensioni considerevoli.\n\nQuesta natura multidisciplinare riflette la complessità intrinseca dell’analisi dei dati e la necessità di integrare competenze provenienti da diverse aree per affrontare con successo le sfide scientifiche moderne.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_key_notions.html#concetti-chiave-nellanalisi-dei-dati",
    "href": "chapters/key_notions/02_key_notions.html#concetti-chiave-nellanalisi-dei-dati",
    "title": "3  Concetti chiave",
    "section": "3.3 Concetti Chiave nell’Analisi dei Dati",
    "text": "3.3 Concetti Chiave nell’Analisi dei Dati\nPer condurre un’analisi dei dati efficace, è fondamentale comprendere alcuni concetti chiave che guidano il processo di indagine, dall’identificazione del fenomeno alla formulazione di inferenze.\n\n3.3.1 Popolazioni e Campioni\nL’analisi dei dati inizia con l’identificazione della popolazione di interesse, che rappresenta l’insieme completo degli individui o delle entità coinvolte nel fenomeno studiato. Ad esempio, in psicologia si potrebbe voler analizzare il benessere in una popolazione generale o in un gruppo specifico, come persone che hanno vissuto eventi traumatici.\nPoiché studiare un’intera popolazione è spesso impraticabile, si ricorre ai campioni, sottoinsiemi rappresentativi della popolazione. La qualità e la rappresentatività del campione sono cruciali: un campione non rappresentativo può portare a conclusioni errate, limitando la generalizzabilità dei risultati.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_key_notions.html#parametri-e-statistiche",
    "href": "chapters/key_notions/02_key_notions.html#parametri-e-statistiche",
    "title": "3  Concetti chiave",
    "section": "3.4 Parametri e Statistiche",
    "text": "3.4 Parametri e Statistiche\nUn parametro è una caratteristica numerica della popolazione (es. media μ, deviazione standard σ). Una statistica è una caratteristica numerica calcolata sul campione (es. media campionaria x̄, deviazione standard campionaria s). L’inferenza statistica si occupa di stimare i parametri della popolazione a partire dalle statistiche campionarie.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_key_notions.html#le-sfide-dellinferenza-statistica-in-psicologia",
    "href": "chapters/key_notions/02_key_notions.html#le-sfide-dellinferenza-statistica-in-psicologia",
    "title": "3  Concetti chiave",
    "section": "3.5 Le Sfide dell’Inferenza Statistica in Psicologia",
    "text": "3.5 Le Sfide dell’Inferenza Statistica in Psicologia\nL’inferenza statistica, in particolare in psicologia e nelle scienze sociali, si confronta con alcune sfide specifiche, che riflettono la complessità dei fenomeni studiati (Gelman et al., 2021):\n\nGeneralizzazione dai campioni alla popolazione: I campioni utilizzati nella ricerca psicologica e sociale spesso presentano limitazioni in termini di rappresentatività della popolazione target. L’uso frequente di campioni di convenienza (ad esempio, studenti universitari) può compromettere la generalizzabilità dei risultati a popolazioni più ampie e diversificate.\nGeneralizzazione dal trattamento al gruppo di controllo (validità esterna): Negli studi sperimentali, è fondamentale valutare se gli effetti osservati nel gruppo trattato siano generalizzabili ad altri contesti, popolazioni o condizioni. Questo aspetto è strettamente legato al concetto di validità esterna.\nInferenza su costrutti latenti: Molti costrutti psicologici (come l’ansia, l’intelligenza o la personalità) non sono direttamente osservabili, ma vengono inferiti attraverso misurazioni indirette (ad esempio, questionari, test, osservazioni comportamentali). L’inferenza statistica deve quindi affrontare la sfida di collegare i dati osservati ai costrutti teorici sottostanti, tenendo conto dell’errore di misurazione e delle limitazioni degli strumenti di valutazione.\n\n\n3.5.1 L’Incertezza\nLe considerazioni introduttive di questo capitolo fanno capire come un aspetto cruciale della stima e dell’inferenza sia la gestione e la quantificazione dell’incertezza. Ogni stima derivata da un campione è intrinsecamente soggetta a errore, in quanto il campione rappresenta solo una parte della popolazione. L’inferenza statistica fornisce gli strumenti per quantificare tale incertezza, ad esempio attraverso gli intervalli di confidenza (nell’approccio frequentista) o le distribuzioni a posteriori (nell’approccio bayesiano), consentendo di esprimere il grado di fiducia nelle conclusioni tratte.\nIn conclusione, la stima e l’inferenza statistica sono strumenti indispensabili per trasformare i dati empirici in conoscenza utile e rilevante. Tuttavia, è fondamentale applicare queste metodologie con rigore e consapevolezza delle loro limitazioni, prestando particolare attenzione alla rappresentatività del campione, alla validità delle misurazioni e alla corretta interpretazione dei risultati, al fine di evitare generalizzazioni inappropriate e conclusioni errate.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_key_notions.html#riflessioni-conclusive",
    "href": "chapters/key_notions/02_key_notions.html#riflessioni-conclusive",
    "title": "3  Concetti chiave",
    "section": "3.6 Riflessioni Conclusive",
    "text": "3.6 Riflessioni Conclusive\nL’analisi dei dati acquisisce valore solo quando è integrata con una solida teoria scientifica, che fornisce il contesto e il quadro interpretativo necessario per attribuire senso ai risultati. Ad esempio, osservare che un trattamento psicologico riduce i sintomi è un’osservazione empirica che, senza una teoria che chiarisca i meccanismi sottostanti, rimane priva di potere esplicativo. È la teoria che orienta il processo analitico, formulando ipotesi verificabili e offrendo interpretazioni che si inseriscono in un modello più ampio.\nIn definitiva, la relazione tra teoria e analisi dei dati è intrinsecamente circolare e dinamica: le teorie guidano la raccolta, l’analisi e l’interpretazione dei dati, mentre i dati, a loro volta, stimolano il perfezionamento e l’evoluzione delle teorie. Questo dialogo continuo è ciò che permette un progresso costante nella comprensione dei fenomeni psicologici.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_key_notions.html#bibliografia",
    "href": "chapters/key_notions/02_key_notions.html#bibliografia",
    "title": "3  Concetti chiave",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other stories. Cambridge University Press.\n\n\nHuntington-Klein, N. (2021). The effect: An introduction to research design and causality. Chapman; Hall/CRC.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nMurray, E. J., & Carr, K. C. (2024). Measuring Racial Sentiment Using Social Media Is Harder Than It Seems. Epidemiology, 35(1), 60–63.\n\n\nNobles, M. (2000). Shades of citizenship: Race and the census in modern politics. Stanford University Press.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_design.html",
    "href": "chapters/key_notions/03_design.html",
    "title": "4  Campionamento, metodologia sperimentale e studi osservazionali",
    "section": "",
    "text": "4.1 Introduzione\nQuesto capitolo approfondisce concetti precedentemente introdotti, focalizzandosi sul processo di campionamento e sull’importanza delle diverse metodologie di ricerca in psicologia. Dopo aver compreso il ruolo fondamentale dei dati nella verifica delle teorie, emerge la questione cruciale di come questi dati vengano raccolti.\nÈ essenziale sottolineare che il processo di raccolta dei dati non è un’attività neutra o priva di conseguenze metodologiche. I dati, infatti, non possiedono lo stesso “valore” scientifico a seconda di come vengono ottenuti. Alcune modalità di raccolta dati generano informazioni preziose e utili per la verifica delle teorie, mentre altre possono produrre informazioni fuorvianti, distorte o addirittura dannose per la validità della ricerca.\nIl metodo scientifico fornisce un quadro di riferimento che delinea le caratteristiche ideali di un processo di raccolta dati in grado di produrre informazioni valide e affidabili per il test delle teorie. Tuttavia, le prescrizioni del metodo scientifico, per loro natura, sono generali e astratte. Tradurre questi principi generali in procedure concrete e applicarli efficacemente in un contesto di ricerca specifico rappresenta una sfida importante.\nQuesto passaggio cruciale, che collega la teoria del metodo scientifico alla pratica della ricerca, dipende dalle risorse disponibili, dalla competenza metodologica e dalla creatività del ricercatore. La capacità di ideare e attuare strategie di raccolta dati adeguate al contesto specifico della ricerca rappresenta un aspetto fondamentale per garantire la qualità e la validità dei risultati ottenuti. In questo capitolo, approfondiremo i principi del campionamento e introdurremo i concetti chiave relativi ai disegni di ricerca.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Campionamento, metodologia sperimentale e studi osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_design.html#popolazioni-e-campioni",
    "href": "chapters/key_notions/03_design.html#popolazioni-e-campioni",
    "title": "4  Campionamento, metodologia sperimentale e studi osservazionali",
    "section": "4.2 Popolazioni e Campioni",
    "text": "4.2 Popolazioni e Campioni\nIn ambito di ricerca, è fondamentale distinguere tra popolazione e campione. Formalmente, una popolazione (di dimensione N) rappresenta l’insieme completo di unità che condividono una o più caratteristiche specifiche oggetto di studio. Un campione (di dimensione n) è un sottoinsieme della popolazione. L’obiettivo del campionamento è ottenere un campione rappresentativo, ossia un sottoinsieme che riflette accuratamente le caratteristiche della popolazione di riferimento.\n\n4.2.1 Metodi di Campionamento\nEsistono diverse strategie per selezionare un campione rappresentativo da una popolazione. Queste strategie si dividono principalmente in due categorie: campionamento probabilistico e campionamento non probabilistico.\n\n4.2.1.1 Campionamento probabilistico\nNel campionamento probabilistico, ogni unità della popolazione ha una probabilità nota e non nulla di essere inclusa nel campione. Questo approccio minimizza il rischio di distorsioni sistematiche (bias) e consente di stimare l’errore di campionamento.\n\nCampionamento Casuale Semplice (CCS): Ogni unità della popolazione ha la stessa probabilità di essere inclusa nel campione. Questo metodo richiede una lista completa di tutte le unità della popolazione (frame di campionamento). La selezione può avvenire con reinserimento (ogni unità estratta viene rimessa nella popolazione) o senza reinserimento (l’unità estratta non viene rimessa). Il CCS senza reinserimento è il più comune nella pratica. Tuttavia, nelle ricerche psicologiche è raramente utilizzabile poiché ottenere un frame completo della popolazione è spesso impraticabile.\nCampionamento Stratificato: La popolazione viene divisa in strati (H, sottogruppi omogenei) in base a una o più variabili rilevanti (es. età, genere, regione geografica). Da ogni strato h viene estratto un campione casuale semplice di dimensione nh. Questo metodo può essere:\n\nProporzionale: La dimensione del campione in ogni strato è proporzionale alla dimensione dello strato nella popolazione.\nNon proporzionale: Utilizzato per sovra-campionare gruppi minoritari, consentendo analisi dettagliate di sottogruppi altrimenti poco rappresentati. Nelle ricerche psicologiche, il campionamento stratificato è utile per garantire che variabili come il genere o l’età siano adeguatamente rappresentate, ma può essere complesso da implementare.\n\nCampionamento a Grappolo (Cluster Sampling): La popolazione viene suddivisa in grappoli (cluster), che rappresentano gruppi eterogenei (es. scuole, ospedali, quartieri). Vengono selezionati casualmente alcuni grappoli, includendo tutte le unità al loro interno. Questo metodo è economico e pratico, specialmente in contesti dove accedere all’intera popolazione è difficile. Tuttavia, la precisione può essere ridotta se i grappoli differiscono notevolmente tra loro.\nCampionamento Multistadio: Combinazione di campionamento a grappolo e CCS. Vengono selezionati casualmente alcuni grappoli e successivamente, all’interno di ciascun grappolo, si estrae un campione casuale di unità. Questo metodo bilancia costi e precisione, risultando particolarmente adatto a studi su larga scala, ad esempio a livello nazionale.\n\n\n\n4.2.1.2 Campionamento non probabilistico\nNel campionamento non probabilistico, la probabilità di inclusione di ogni unità nel campione non è nota. Questo approccio è spesso adottato per ragioni di praticità o quando non è disponibile un frame di campionamento. Tuttavia, aumenta il rischio di distorsioni e limita la generalizzabilità dei risultati alla popolazione.\n\nCampionamento Convenienza: È il metodo più diffuso nella ricerca psicologica. I partecipanti vengono selezionati in base alla loro facile accessibilità (es., studenti universitari, volontari). Questo metodo è rapido ed economico, ma introduce significativi bias di selezione, poiché il campione non è rappresentativo della popolazione generale.\n\n\n\n\n4.2.2 Il Campionamento nella Ricerca Psicologica\nA causa di vincoli pratici, economici e di accessibilità, il campionamento casuale semplice e stratificato sono raramente applicati in modo rigoroso nella ricerca psicologica. Il campionamento di convenienza è molto comune, soprattutto in contesti accademici.\n\n4.2.2.1 Limiti del Campionamento di Convenienza e Strategie di Mitigazione\n\nBias di Selezione: Il campione non riflette la diversità della popolazione, limitando la generalizzabilità dei risultati.\nStrategie di Mitigazione:\n\nSovra-campionamento: Includere deliberatamente un numero maggiore di partecipanti appartenenti a gruppi sottorappresentati per consentire analisi più accurate.\nReplicazione degli Studi: Ripetere lo studio con campioni diversi per verificare la robustezza dei risultati e aumentare la generalizzabilità.\nDescrizione Dettagliata del Campione: Fornire informazioni precise sulle caratteristiche del campione (es., età, genere, provenienza geografica, livello di istruzione) per consentire ai lettori di valutare la generalizzabilità dei risultati al loro specifico contesto.\n\n\nÈ fondamentale che i ricercatori siano consapevoli dei limiti del metodo di campionamento utilizzato e che interpretino i risultati con cautela, evidenziando le potenziali limitazioni alla generalizzabilità.\nEcco una versione riformulata evitando il linguaggio frequentista e rendendola più chiara e coerente con un approccio descrittivo e bayesiano:",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Campionamento, metodologia sperimentale e studi osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_design.html#metodologia-sperimentale",
    "href": "chapters/key_notions/03_design.html#metodologia-sperimentale",
    "title": "4  Campionamento, metodologia sperimentale e studi osservazionali",
    "section": "4.3 Metodologia Sperimentale",
    "text": "4.3 Metodologia Sperimentale\n\n4.3.1 Principi Fondamentali del Disegno Sperimentale\n\nControllo: L’obiettivo è ridurre l’influenza di variabili confondenti (Z) sulla relazione tra la variabile indipendente (X) e quella dipendente (Y). Utilizzare un gruppo di controllo consente di stabilire un riferimento per valutare l’effetto del trattamento.\nRandomizzazione: L’assegnazione casuale dei partecipanti ai gruppi sperimentali distribuisce le variabili confondenti in modo equilibrato tra i gruppi, aumentando la credibilità dell’inferenza causale tra X e Y. Questo approccio garantisce che eventuali differenze osservate siano attribuibili al trattamento e non a fattori esterni.\n\n\n\n4.3.2 Strategie di Mitigazione dei Bias\n\nCecità (Blinding): Strumento chiave per minimizzare l’influenza di aspettative e pregiudizi, sia nei partecipanti che nei ricercatori. Le principali modalità includono:\n\nCecità singola: I partecipanti non sono consapevoli del trattamento assegnato.\nCecità doppia: Sia i partecipanti che i ricercatori che interagiscono direttamente con loro non conoscono l’assegnazione dei trattamenti.\nCecità tripla: Né i partecipanti, né i ricercatori, né gli analisti dei dati sono a conoscenza dei trattamenti durante la raccolta e l’analisi dei dati.\n\nGruppo di Controllo: L’introduzione di un gruppo che riceve un trattamento inerte (controllo) consente di isolare gli effetti psicologici legati alle aspettative dei partecipanti, distinguendoli dagli effetti specifici del trattamento.\nStandardizzazione delle Procedure: Garantire che tutte le condizioni sperimentali, eccetto la variabile manipolata, siano mantenute costanti tra i gruppi. Questo riduce la variabilità non controllata, migliorando la comparabilità dei risultati.\n\n\n\n4.3.3 Nota sulla Replicazione\nLa replicazione degli esperimenti non è una caratteristica intrinseca del metodo sperimentale, ma rappresenta una pratica fondamentale nella scienza per verificare l’affidabilità e la generalizzabilità dei risultati. Si distingue in:\n\nReplicazione diretta: Ripetere lo stesso studio con le stesse condizioni.\nReplicazione concettuale: Ripetere lo studio modificando aspetti specifici per testare la robustezza del risultato.\n\n\n\n4.3.4 Tipologie di Disegni Sperimentali\n\nDisegno a Gruppi Indipendenti (Between-Subjects): I partecipanti vengono assegnati a un unico gruppo e sono esposti a una sola condizione sperimentale. Questo disegno è utile quando l’esposizione multipla potrebbe introdurre confondenti, ma richiede un campione più ampio per raggiungere lo stesso livello di precisione.\nDisegno a Misure Ripetute (Within-Subjects): Gli stessi partecipanti vengono esposti a tutte le condizioni sperimentali. Questo approccio riduce la variabilità tra soggetti, migliorando la precisione delle stime. Tuttavia, richiede attenzione nel controllare gli effetti di ordine, come affaticamento o apprendimento, spesso attraverso il bilanciamento dell’ordine di presentazione dei trattamenti.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Campionamento, metodologia sperimentale e studi osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_design.html#studi-osservazionali",
    "href": "chapters/key_notions/03_design.html#studi-osservazionali",
    "title": "4  Campionamento, metodologia sperimentale e studi osservazionali",
    "section": "4.4 Studi Osservazionali",
    "text": "4.4 Studi Osservazionali\nGli studi osservazionali possono essere classificati in:\n\nStudi Trasversali (Cross-Sectional): I dati vengono raccolti in un singolo momento. Utili per stimare la prevalenza di una condizione, ma non permettono di stabilire relazioni causali.\nStudi di Coorte (Cohort Studies): Un gruppo di individui (coorte) viene seguito nel tempo per osservare l’incidenza di un evento. Permettono di studiare la relazione tra esposizione e outcome, ma possono essere costosi e richiedere molto tempo.\nStudi Caso-Controllo (Case-Control Studies): Vengono confrontati individui con una determinata condizione (casi) con individui senza la condizione (controlli) per identificare possibili fattori di rischio. Utili per studiare malattie rare, ma soggetti a bias di selezione e di ricordo.\n\nLe principali limitazioni degli studi osservazionali sono la presenza di variabili confondenti e la difficoltà di stabilire relazioni causali.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Campionamento, metodologia sperimentale e studi osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_design.html#riflessioni-conclusive",
    "href": "chapters/key_notions/03_design.html#riflessioni-conclusive",
    "title": "4  Campionamento, metodologia sperimentale e studi osservazionali",
    "section": "4.5 Riflessioni Conclusive",
    "text": "4.5 Riflessioni Conclusive\nLa comprensione dei metodi di campionamento, dei principi della metodologia sperimentale e delle caratteristiche degli studi osservazionali è essenziale per interpretare correttamente i risultati riportati nella letteratura scientifica in psicologia.\nQuesti concetti permettono di valutare la solidità delle conclusioni tratte dagli autori, di identificare potenziali limiti metodologici e di distinguere tra evidenze solide e ipotesi meno supportate. Saper riconoscere l’importanza di aspetti come il controllo, la randomizzazione e il disegno dello studio è indispensabile per leggere la letteratura scientifica con un approccio critico e consapevole.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Campionamento, metodologia sperimentale e studi osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_design.html#bibliografia",
    "href": "chapters/key_notions/03_design.html#bibliografia",
    "title": "4  Campionamento, metodologia sperimentale e studi osservazionali",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nYouyou, W., Yang, Y., & Uzzi, B. (2023). A discipline-wide investigation of the replicability of Psychology papers over the past two decades. Proceedings of the National Academy of Sciences, 120(6), e2208863120.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Campionamento, metodologia sperimentale e studi osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/04_measurement.html",
    "href": "chapters/key_notions/04_measurement.html",
    "title": "5  La misurazione in psicologia",
    "section": "",
    "text": "5.1 Introduzione\nLa scienza si avvale di modelli per interpretare i dati, ma opera sempre con teorie incomplete e misurazioni soggette a errori. Di conseguenza, è fondamentale riconoscere le incertezze quando si cerca di estrarre informazioni dalle misurazioni utilizzando i nostri modelli. Nessuna misurazione, spiegazione o previsione è perfettamente accurata e precisa, e non possiamo mai conoscere con esattezza l’entità dei loro errori.\nQuesta incertezza viene catturata in tre equazioni fondamentali. La prima è l’Equazione di Misurazione, che riconosce l’errore osservativo: \\(y = z + \\varepsilon_y\\), dove \\(y\\) rappresenta il valore misurato, \\(z\\) il valore reale e \\(\\varepsilon_y\\) l’errore di misurazione. La seconda è l’Equazione di Modellazione, che esprime la presenza di un diverso tipo di errore: \\(z = f(x, \\theta) + \\varepsilon_\\text{model}\\), dove \\(f\\) è il modello, \\(x\\) sono le condizioni ambientali per cui eseguiamo il modello, \\(\\theta\\) sono i valori dei parametri del modello e \\(\\varepsilon_\\text{model}\\) rappresenta l’errore del modello, che sorge perché \\(f\\), \\(x\\) e \\(\\theta\\) saranno tutti in qualche misura imprecisi.\nCombinando queste due equazioni, otteniamo l’Equazione della Scienza: \\(y = f(x, \\theta) + \\varepsilon_\\text{model} + \\varepsilon_y\\). La scienza è il tentativo di spiegare le osservazioni \\(y\\) utilizzando un modello \\(f\\), cercando di minimizzare l’errore di misurazione \\(\\varepsilon_y\\) e l’errore del modello \\(\\varepsilon_\\text{model}\\), in modo che il modello possa essere utilizzato per fare previsioni sul mondo reale (\\(z\\)). L’approccio bayesiano alla scienza riconosce e quantifica le incertezze su tutti e sei gli elementi dell’Equazione della Scienza: \\(y\\), \\(f\\), \\(x\\), \\(\\theta\\), \\(\\varepsilon_\\text{model}\\) e \\(\\varepsilon_y\\).",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/04_measurement.html#la-teoria-della-misurazione",
    "href": "chapters/key_notions/04_measurement.html#la-teoria-della-misurazione",
    "title": "5  La misurazione in psicologia",
    "section": "5.2 La teoria della Misurazione",
    "text": "5.2 La teoria della Misurazione\nLa teoria della misurazione, oggetto di questo capitolo, si concentra sull’errore di misurazione e sull’equazione fondamentale \\(y = z + \\varepsilon_y\\). Questa equazione può essere esaminata da tre prospettive distinte. La prima concerne l’affidabilità della misura, rappresentata dal termine \\(\\varepsilon_y\\). La psicometria, branca dedicata alla teoria della misurazione psicologica, si occupa di quantificare l’affidabilità delle misure psicologiche attraverso metodi come la Teoria Classica dei Test e la Teoria di Risposta all’Item.\nLa seconda prospettiva riguarda la validità delle misure psicologiche, ovvero quanto adeguatamente la misura \\(y\\) rappresenti il costrutto \\(z\\). Questo aspetto, più complesso dell’affidabilità, non può essere risolto meramente con metodi statistici, ma richiede una profonda comprensione delle teorie psicologiche e della loro capacità di descrivere e prevedere i fenomeni psicologici.\nLa terza prospettiva si concentra sulle procedure di assegnazione dei valori a \\(y\\), esplorando quali metodi (questionari, interviste, esperimenti) siano più appropriati e come valutarne l’adeguatezza.\n\n5.2.1 Costrutti Psicologici\nLa teoria della misurazione sottolinea l’importanza di distinguere tra la procedura di misurazione e il costrutto che si intende misurare. Ad esempio, mentre la temperatura è un costrutto, il termometro è lo strumento di misurazione. Analogamente, l’abilità matematica è un costrutto, mentre un test di matematica è la procedura per misurarla.\nNelle scienze psicologiche e sociali, la misurazione presenta sfide uniche rispetto alle scienze fisiche, poiché i costrutti in esame sono spesso astratti e non direttamente osservabili. Ciò richiede una particolare attenzione alla validità e all’affidabilità degli strumenti di misurazione, nonché una costante riflessione sulle limitazioni e le potenziali fonti di errore.\nIl capitolo introduce concetti fondamentali relativi alla misurazione quantitativa delle caratteristiche psicologiche, con un focus sulla teoria delle scale di misura di Stevens (1946). Questa teoria fornisce un quadro concettuale per comprendere i diversi tipi di scale di misurazione e le operazioni matematiche appropriate per ciascuna. Inoltre, vengono esplorate alcune procedure di scaling psicologico, ovvero l’assegnazione di numeri all’intensità di fenomeni psicologici.\n\n\n5.2.2 Scaling Psicologico\nLo scaling psicologico si occupa della trasformazione dei dati empirici raccolti durante uno studio psicologico in misure o punteggi che rappresentino accuratamente le caratteristiche psicologiche oggetto di indagine.\nScaling di Guttman. Uno dei metodi di scaling più noti è lo «Scaling di Guttman», che viene utilizzato per rappresentare relazioni ordinate tra gli elementi di una scala. Ad esempio, in un questionario sui sintomi dell’ansia, le domande possono essere disposte in ordine di intensità crescente dei sintomi. Secondo il modello di Guttman, se un partecipante risponde “sì” a una domanda che riflette un sintomo più intenso, ci si aspetta che abbia risposto “sì” anche a tutte le domande precedenti, che rappresentano sintomi di intensità minore. Questo approccio consente di costruire una scala che riflette in modo sistematico e coerente la gravità dei sintomi.\nScaling Thurstoniano. Lo «Scaling Thurstoniano» è un metodo utilizzato per misurare preferenze o giudizi soggettivi. Ad esempio, per valutare la preferenza tra diversi tipi di cibi, i partecipanti confrontano due cibi alla volta ed esprimono una preferenza. Le risposte vengono poi utilizzate per assegnare punteggi che riflettono la preferenza media per ciascun cibo.\nQuestionari Likert. I questionari Likert richiedono ai partecipanti di esprimere il loro grado di accordo con una serie di affermazioni su una scala a più livelli, che va da «fortemente in disaccordo» a «fortemente d’accordo». I punteggi ottenuti vengono sommati per rappresentare la posizione complessiva dell’individuo rispetto all’oggetto di studio.\n\n\n5.2.3 Metodi di Valutazione delle Scale Psicologiche\nPer valutare le proprietà delle scale psicologiche, vengono utilizzati vari metodi. Ad esempio, l’affidabilità delle misure può essere analizzata utilizzando il coefficiente alpha di Cronbach o il coefficiente Omega di McDonald, entrambi utilizzati per misurare la coerenza interna delle risposte ai diversi item di un questionario. Inoltre, la validità delle scale può essere esaminata confrontando i risultati ottenuti con misure simili o attraverso analisi statistiche che verificano se la scala cattura accuratamente il costrutto psicologico che si intende misurare. La validità di costrutto è particolarmente cruciale, poiché riguarda la capacità della scala di misurare effettivamente il concetto psicologico che si intende esplorare.\n\n\n5.2.4 Prospettive Moderne\nNegli ultimi anni, il dibattito sulla misurazione psicologica si è arricchito di nuove prospettive, grazie all’avvento di tecnologie avanzate e all’integrazione di approcci interdisciplinari. Ecco alcune delle tendenze più rilevanti.\nTeoria della Risposta agli Item. La Teoria della Risposta agli Item (IRT) ha guadagnato popolarità per la sua capacità di fornire stime più precise delle abilità latenti rispetto ai modelli classici. La IRT considera la probabilità che un individuo risponda correttamente a un item in funzione della sua abilità e delle caratteristiche dell’item stesso, offrendo una visione più dettagliata delle proprietà psicometriche degli strumenti di misurazione.\nApprocci Bayesiani. Gli approcci bayesiani stanno rivoluzionando il campo della psicometria, permettendo di incorporare informazioni a priori nelle stime e di aggiornare le credenze sulla base di nuovi dati. Questi metodi sono particolarmente utili per affrontare la complessità e l’incertezza inerenti alla misurazione psicologica.\nAnalisi di Rete. L’analisi di rete è un’altra metodologia emergente che vede i costrutti psicologici non come variabili latenti indipendenti, ma come reti di sintomi interconnessi. Questo approccio può offrire nuove intuizioni sulla struttura delle psicopatologie e sulla dinamica dei sintomi.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/04_measurement.html#le-scale-di-misurazione",
    "href": "chapters/key_notions/04_measurement.html#le-scale-di-misurazione",
    "title": "5  La misurazione in psicologia",
    "section": "5.3 Le scale di misurazione",
    "text": "5.3 Le scale di misurazione\nLe scale di misurazione sono strumenti fondamentali per assegnare numeri ai dati osservati, rappresentando le proprietà psicologiche. La teoria delle scale di Stevens Stevens (1946) identifica quattro tipi di scale di misurazione: nominali, ordinali, a intervalli e di rapporti. Ognuna di queste scale consente di effettuare operazioni aritmetiche diverse, poiché ciascuna di esse è in grado di “catturare” solo alcune delle proprietà dei fenomeni psicologici che si intende misurare.\n\n\n\nScale di misurazione.\n\n\n\n5.3.1 Scala nominale\nILa scala nominale è il livello di misurazione più semplice e corrisponde ad una tassonomia o classificazione delle categorie che utilizziamo per descrivere i fenomeni psicologici. I simboli o numeri che costituiscono questa scala rappresentano i nomi delle categorie e non hanno alcun valore numerico intrinseco. Con la scala nominale possiamo solo distinguere se una caratteristica psicologica è uguale o diversa da un’altra.\nI dati raccolti con la scala nominale sono suddivisi in categorie qualitative e mutuamente esclusive, in cui ogni dato appartiene ad una sola categoria. In questa scala, esiste solo la relazione di equivalenza tra le misure delle unità di studio: gli elementi del campione appartenenti a classi diverse sono differenti, mentre tutti quelli della stessa classe sono tra loro equivalenti.\nL’unica operazione algebrica consentita dalla scala nominale è quella di contare le unità di studio che appartengono ad ogni categoria e il numero totale di categorie. Di conseguenza, la descrizione dei dati avviene tramite le frequenze assolute e le frequenze relative.\nDalla scala nominale è possibile costruire altre scale nominali equivalenti alla prima, trasformando i valori della scala di partenza in modo tale da cambiare i nomi delle categorie, ma lasciando inalterata la suddivisione delle unità di studio nelle medesime classi di equivalenza. In altre parole, cambiando i nomi delle categorie di una variabile misurata su scala nominale, si ottiene una nuova variabile esattamente equivalente alla prima.\n\n\n5.3.2 Scala ordinale\nLa scala ordinale mantiene la caratteristica della scala nominale di classificare ogni unità di misura all’interno di una singola categoria, ma introduce la relazione di ordinamento tra le categorie. In quanto basata su una relazione di ordine, una scala ordinale descrive solo il rango di ordine tra le categorie e non fornisce informazioni sulla distanza tra di esse. Non ci dice, ad esempio, se la distanza tra le categorie \\(a\\) e \\(b\\) è uguale, maggiore o minore della distanza tra le categorie \\(b\\) e \\(c\\).\nUn esempio classico di scala ordinale è quello della scala Mohs per la determinazione della durezza dei minerali. Per stabilire la durezza dei minerali si usa il criterio empirico della scalfittura. Vengono stabiliti livelli di durezza crescente da 1 a 10 con riferimento a dieci minerali: talco, gesso, calcite, fluorite, apatite, ortoclasio, quarzo, topazio, corindone e diamante. Un minerale appartenente ad uno di questi livelli se scalfisce quello di livello inferiore ed è scalfito da quello di livello superiore.\n\n\n\nLa scala di durezza dei minerali di Mohs. Un oggetto è considerato più duro di X se graffia X. Sono incluse anche misure di durezza relativa utilizzando uno sclerometro, da cui emerge la non linearità della scala di Mohs (Burchard, 2004).\n\n\n\n\n5.3.3 Scala ad intervalli\nLa scala ad intervalli di misurazione include le proprietà della scala nominale e della scala ordinale e permette di misurare le distanze tra le coppie di unità statistiche in termini di un intervallo costante, chiamato “unità di misura”, a cui viene attribuito il valore “1”. L’origine della scala, ovvero il punto zero, è scelta arbitrariamente e non indica l’assenza della proprietà che si sta misurando. Ciò significa che la scala ad intervalli consente anche valori negativi e lo zero non viene attribuito all’unità statistica in cui la proprietà risulta assente.\nLa scala ad intervalli equivalenti consente l’esecuzione di operazioni algebriche basate sulla differenza tra i numeri associati ai diversi punti della scala, operazioni algebriche non possibili con le scale di misura nominale o ordinale. Tuttavia, il limite della scala ad intervalli è che non consente di calcolare il rapporto tra coppie di misure. È possibile affermare la differenza tra \\(a\\) e \\(b\\) come la metà della differenza tra \\(c\\) e \\(d\\) o che le due differenze sono uguali, ma non è possibile affermare che \\(a\\) abbia una proprietà misurata in quantità doppia rispetto a \\(b\\). In altre parole, non è possibile stabilire rapporti diretti tra le misure ottenute. Solo le differenze tra le modalità permettono tutte le operazioni aritmetiche, come la somma, l’elevazione a potenza o la divisione, che sono alla base della statistica inferenziale.\nNelle scale ad intervalli equivalenti, l’unità di misura è arbitraria e può essere cambiata attraverso una dilatazione, ovvero la moltiplicazione di tutti i valori della scala per una costante positiva. Inoltre, la traslazione, ovvero l’aggiunta di una costante a tutti i valori della scala, è ammessa poiché non altera le differenze tra i valori della scala. La scala rimane invariata rispetto a traslazioni e dilatazioni e dunque le uniche trasformazioni ammissibili sono le trasformazioni lineari:\n\\[\ny' = a + by, \\quad b &gt; 0.\n\\]\nInfatti, l’uguaglianza dei rapporti fra gli intervalli rimane invariata a seguito di una trasformazione lineare.\nEsempio di scala ad intervalli è la temperatura misurata in gradi Celsius o Fahrenheit, ma non Kelvin. Come per la scala nominale, è possibile stabilire se due modalità sono uguali o diverse: 30\\(^\\circ\\)C \\(\\neq\\) 20\\(^\\circ\\)C. Come per la scala ordinale è possibile mettere due modalità in una relazione d’ordine: 30\\(^\\circ\\)C \\(&gt;\\) 20\\(^\\circ\\)C. In aggiunta ai casi precedenti, però, è possibile definire una unità di misura per cui è possibile dire che tra 30\\(^\\circ\\)C e 20\\(^\\circ\\)C c’è una differenza di 30\\(^\\circ\\) - 20\\(^\\circ\\) = 10\\(^\\circ\\)C. I valori di temperatura, oltre a poter essere ordinati secondo l’intensità del fenomeno, godono della proprietà che le differenze tra loro sono direttamente confrontabili e quantificabili.\nIl limite della scala ad intervalli è quello di non consentire il calcolo del rapporto tra coppie di misure. Ad esempio, una temperatura di 80\\(^\\circ\\)C non è il doppio di una di 40\\(^\\circ\\)C. Se infatti esprimiamo le stesse temperature nei termini della scala Fahrenheit, allora i due valori non saranno in rapporto di 1 a 2 tra loro. Infatti, 20\\(^\\circ\\)C = 68\\(^\\circ\\)F e 40\\(^\\circ\\)C = 104\\(^\\circ\\)F. Questo significa che la relazione “il doppio di” che avevamo individuato in precedenza si applicava ai numeri della scala centigrada, ma non alla proprietà misurata (cioè la temperatura). La decisione di che scala usare (Centigrada vs. Fahrenheit) è arbitraria. Ma questa arbitrarietà non deve influenzare le inferenze che traiamo dai dati. Queste inferenze, infatti, devono dirci qualcosa a proposito della realtà empirica e non possono in nessun modo essere condizionate dalle nostre scelte arbitrarie che ci portano a scegliere la scala Centigrada piuttosto che quella Fahrenheit.\nConsideriamo ora l’aspetto invariante di una trasformazione lineare, ovvero l’uguaglianza dei rapporti fra intervalli. Prendiamo in esame, ad esempio, tre temperature: \\(20^\\circ C = 68^\\circ F\\), \\(15^\\circ C = 59^\\circ F\\), \\(10^\\circ C = 50 ^\\circ F\\).\nÈ facile rendersi conto del fatto che i rapporti fra intervalli restano costanti indipendentemente dall’unità di misura che è stata scelta:\n\\[\n  \\frac{20^\\circ C - 10^\\circ C}{20^\\circ C - 15^\\circ C} =\n  \\frac{68^\\circ F - 50^\\circ F}{68^\\circ F-59^\\circ F} = 2.\n\\]\n\n\n5.3.4 Scala di rapporti\nNella scala a rapporti equivalenti, lo zero non è arbitrario e rappresenta l’elemento che ha intensità nulla rispetto alla proprietà misurata. Per costruire questa scala, si associa il numero 0 all’elemento con intensità nulla e si sceglie un’unità di misura \\(u\\). Ad ogni elemento si assegna un numero \\(a\\) definito come \\(a=d/u\\), dove \\(d\\) rappresenta la distanza dall’origine. In questo modo, i numeri assegnati riflettono le differenze e i rapporti tra le intensità della proprietà misurata.\nIn questa scala, è possibile effettuare operazioni aritmetiche non solo sulle differenze tra i valori della scala, ma anche sui valori stessi della scala. L’unica scelta arbitraria è l’unità di misura, ma lo zero deve sempre rappresentare l’intensità nulla della proprietà considerata.\nLe trasformazioni ammissibili in questa scala sono chiamate trasformazioni di similarità e sono del tipo \\(y' = by\\), dove \\(b&gt;0\\). In questa scala, i rapporti tra i valori rimangono invariati dopo le trasformazioni. In altre parole, se rapportiamo due valori originali e due valori trasformati, il rapporto rimane lo stesso: \\(\\frac{y_i}{y_j} = \\frac{y'_i}{y'_j}\\).",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/04_measurement.html#gerarchia-dei-livelli-delle-scale-di-misurazione",
    "href": "chapters/key_notions/04_measurement.html#gerarchia-dei-livelli-delle-scale-di-misurazione",
    "title": "5  La misurazione in psicologia",
    "section": "5.4 Gerarchia dei livelli delle scale di misurazione",
    "text": "5.4 Gerarchia dei livelli delle scale di misurazione\nSecondo Stevens (1946), esiste una gerarchia dei livelli delle scale di misurazione, denominati “livelli di scala”. Questi livelli sono organizzati in modo gerarchico, in cui la scala nominale rappresenta il livello più basso della misurazione, mentre la scala a rapporti equivalenti rappresenta il livello più alto.\n\nLa scala nominale è il livello più elementare, in cui le categorie o le etichette vengono assegnate agli oggetti o agli individui senza alcuna valutazione di grandezza o ordine.\nAl livello successivo si trova la scala ordinale, in cui le categorie sono ordinate in base a una qualche qualità o caratteristica. Qui, è possibile stabilire un ordine di preferenza o gerarchia tra le categorie, ma non è possibile quantificare la differenza tra di esse in modo preciso.\nLa scala intervallo rappresenta un livello successivo, in cui le categorie sono ordinate e la differenza tra di esse è quantificabile in modo preciso. In questa scala, è possibile effettuare operazioni matematiche come l’addizione e la sottrazione tra i valori, ma non è possibile stabilire un vero e proprio punto zero significativo.\nInfine, la scala a rapporti equivalenti rappresenta il livello più alto. In questa scala, le categorie sono ordinate, la differenza tra di esse è quantificabile in modo preciso e esiste un punto zero assoluto che rappresenta l’assenza totale della grandezza misurata. Questo livello di scala permette di effettuare tutte le operazioni matematiche, compresa la moltiplicazione e la divisione.\n\nPassando da un livello di misurazione ad uno più alto aumenta il numero di operazioni aritmetiche che possono essere compiute sui valori della scala, come indicato nella figura seguente.\n\n\n\nRelazioni tra i livelli di misurazione.\n\n\nPer ciò che riguarda le trasformazioni ammissibili, più il livello di scala è basso, più le funzioni sono generali (sono minori cioè i vincoli per passare da una rappresentazione numerica ad un’altra equivalente). Salendo la gerarchia, la natura delle funzioni di trasformazione si fa più restrittiva.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/04_measurement.html#variabili-discrete-o-continue",
    "href": "chapters/key_notions/04_measurement.html#variabili-discrete-o-continue",
    "title": "5  La misurazione in psicologia",
    "section": "5.5 Variabili discrete o continue",
    "text": "5.5 Variabili discrete o continue\nLe variabili possono essere classificate come variabili a livello di intervalli o di rapporti e possono essere sia discrete che continue.\n\nLe variabili discrete assumono valori specifici ma non possono assumere valori intermedi. Una volta che l’elenco dei valori accettabili è stato definito, non vi sono casi che si trovano tra questi valori. In genere, le variabili discrete assumono valori interi, come il numero di eventi, il numero di persone o il numero di oggetti.\nD’altra parte, le variabili continue possono assumere qualsiasi valore all’interno di un intervallo specificato. Teoricamente, ciò significa che è possibile utilizzare frazioni e decimali per ottenere qualsiasi grado di precisione.\n\n\n\n\nVariabili discrete e continue.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/04_measurement.html#comprendere-gli-errori-nella-misurazione",
    "href": "chapters/key_notions/04_measurement.html#comprendere-gli-errori-nella-misurazione",
    "title": "5  La misurazione in psicologia",
    "section": "5.6 Comprendere gli errori nella misurazione",
    "text": "5.6 Comprendere gli errori nella misurazione\nLa teoria della misurazione si basa sull’assunto che ogni misura sia composta da due componenti principali: una componente “vera”, che rappresenta l’attributo reale del fenomeno che si intende misurare, e una componente di errore. La finalità principale della teoria psicometrica è stimare e quantificare l’entità dell’errore nelle misurazioni psicologiche. Questo costituisce il nucleo della disciplina del Testing Psicologico.\nDi seguito introduciamo alcune nozioni fondamentali utili per approfondire questi concetti.\n\n5.6.1 Precisione e Accuratezza\nGli errori di misurazione possono essere casuali o sistematici. Gli errori casuali sono fluttuazioni aleatorie, mentre gli errori sistematici sono costanti e derivano da problemi nel metodo di misurazione o negli strumenti.\nLa precisione indica la coerenza tra misurazioni ripetute (stabilità), mentre l’accuratezza si riferisce alla vicinanza del valore misurato al valore reale. Entrambi i concetti sono cruciali per l’assessment psicometrico.\nUn’analogia efficace è quella del tiro al bersaglio:\n\nprecisione senza accuratezza: i colpi sono concentrati ma lontani dal centro;\naccuratezza senza precisione: i colpi sono distribuiti, ma in media vicini al centro.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/04_measurement.html#assessment-psicometrico",
    "href": "chapters/key_notions/04_measurement.html#assessment-psicometrico",
    "title": "5  La misurazione in psicologia",
    "section": "5.7 Assessment psicometrico",
    "text": "5.7 Assessment psicometrico\nL’assessment psicometrico si focalizza sulla qualità delle misurazioni psicologiche, considerando due dimensioni principali:\n\naffidabilità: misura la consistenza delle osservazioni;\nvalidità: valuta se uno strumento misura effettivamente ciò che intende misurare.\n\n\n5.7.1 Affidabilità\nL’affidabilità indica la stabilità e la coerenza di uno strumento di misura. Le principali forme di affidabilità includono:\n\nAffidabilità Test-Retest: Questa forma di affidabilità verifica la consistenza delle misurazioni nel tempo. Se un individuo viene testato in due momenti diversi, i risultati dovrebbero essere simili, assumendo che non ci siano stati cambiamenti significativi nel costrutto misurato.\nAffidabilità Inter-rater: In questo caso, l’affidabilità è determinata dalla concordanza tra le valutazioni di diversi esaminatori. Ad esempio, se più psicologi dovessero valutare un individuo utilizzando lo stesso strumento, le loro valutazioni dovrebbero essere simili.\nAffidabilità Intra-rater: Questa misura dell’affidabilità si riferisce alla consistenza delle valutazioni dello stesso esaminatore in momenti diversi.\nAffidabilità Interna: Si riferisce alla coerenza delle risposte all’interno dello stesso test. Ad esempio, se un test misura un costrutto come l’ansia, gli item che misurano l’ansia dovrebbero correlare positivamente l’uno con l’altro. Un modo comune per valutare l’affidabilità interna è utilizzare il coefficiente \\(\\omega\\) di McDonald.\n\n\n\n5.7.2 Validità nella Misurazione Psicologica\nL’affidabilità è necessaria ma non sufficiente: una misura deve anche essere valida. La validità si riferisce al grado in cui teoria ed evidenze supportano l’interpretazione e l’utilizzo dei punteggi.\nSecondo gli Standards for Educational and Psychological Testing (2014), la validità è “la considerazione più fondamentale nello sviluppo e nella valutazione dei test” e integra diversi tipi di evidenze.\n\n\n5.7.3 Tipologie di Validità\nStoricamente, la validità era suddivisa in tre categorie:\n\nValidità di Contenuto: Si riferisce alla corrispondenza tra il contenuto degli item di un test e il dominio dell’attributo psicologico che il test intende misurare. È importante che gli item siano pertinenti e rappresentativi dell’attributo misurato.\nValidità di Criterio: Valuta il grado di concordanza tra i risultati ottenuti tramite lo strumento di misurazione e i risultati ottenuti da altri strumenti che misurano lo stesso costrutto o da un criterio esterno. Include validità concorrente e predittiva.\nValidità di Costrutto: Riguarda il grado in cui un test misura effettivamente il costrutto che si intende misurare. Si suddivide in validità convergente (accordo con strumenti che misurano lo stesso costrutto) e validità divergente (capacità di discriminare tra costrutti diversi).\n\n\n\n5.7.4 Visione Moderna della Validità\nLa moderna teoria della validità non adotta più questa visione tripartita. Gli Standards del 2014 descrivono la validità come un concetto unitario, dove diverse forme di evidenza concorrono a supportare l’interpretazione dei punteggi del test per il loro utilizzo previsto. Gli Standards del 2014 identificano cinque categorie principali di prove di validità:\n\nProve Basate sul Contenuto del Test: Valutano quanto il contenuto del test rappresenti adeguatamente il dominio del costrutto da misurare.\nProve Basate sui Processi di Risposta: Analizzano se i processi cognitivi e comportamentali degli esaminandi riflettono il costrutto valutato.\nProve Basate sulla Struttura Interna: Esaminano la coerenza tra gli elementi del test e la struttura teorica del costrutto. L’analisi fattoriale è uno strumento chiave in questo contesto.\nProve Basate sulle Relazioni con Altre Variabili: Studiano la correlazione tra i punteggi del test e altre variabili teoricamente correlate, utilizzando metodi come la validità convergente e divergente.\nProve Basate sulle Conseguenze del Test: Considerano le implicazioni e gli effetti dell’uso del test, sia intenzionali che non intenzionali.\n\n\n\n5.7.5 Minacce alla Validità\nLe principali minacce includono:\n\nSotto-rappresentazione del costrutto: lo strumento non misura pienamente il costrutto.\nVarianza estranea: interferenze non pertinenti che influenzano i punteggi.\nFattori esterni: ansia, motivazione o errori nell’amministrazione del test.\n\n\n\n5.7.6 Integrazione delle Prove di Validità\nLa validità di un test deriva dall’integrazione di più evidenze. Ogni interpretazione deve essere validata considerando:\n\nla qualità tecnica dello strumento;\nl’adeguatezza delle sue applicazioni.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/04_measurement.html#riflessioni-conclusive",
    "href": "chapters/key_notions/04_measurement.html#riflessioni-conclusive",
    "title": "5  La misurazione in psicologia",
    "section": "5.8 Riflessioni Conclusive",
    "text": "5.8 Riflessioni Conclusive\nLa teoria della misurazione è fondamentale nella ricerca empirica per valutare l’attendibilità e la validità delle misurazioni. È cruciale valutare l’errore nella misurazione per garantire la precisione e l’accuratezza delle misure. L’assessment psicometrico si occupa di valutare la qualità delle misurazioni psicologiche, considerando l’affidabilità e la validità per garantire misure accurate dei costrutti teorici. Le moderne tecnologie e metodologie stanno continuamente arricchendo questo campo, offrendo strumenti sempre più raffinati per la comprensione delle caratteristiche psicologiche.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/04_measurement.html#bibliografia",
    "href": "chapters/key_notions/04_measurement.html#bibliografia",
    "title": "5  La misurazione in psicologia",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nLilienfeld, S. O., & Strother, A. N. (2020). Psychological measurement and the replication crisis: Four sacred cows. Canadian Psychology/Psychologie Canadienne, 61(4), 281–288.\n\n\nMaul, A., Irribarra, D. T., & Wilson, M. (2016). On the philosophical foundations of psychological measurement. Measurement, 79, 311–320.\n\n\nStevens, S. S. (1946). On the theory of scales of measurement. Science, 103(2684), 677–680.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/05_data_analysis.html",
    "href": "chapters/key_notions/05_data_analysis.html",
    "title": "6  La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana",
    "section": "",
    "text": "Introduzione\nNel panorama contemporaneo delle scienze sociali e della psicologia, gli ultimi due decenni hanno visto l’emergere di una profonda trasformazione metodologica ed epistemologica. Questo movimento, caratterizzato da concetti chiave quali “Credibility Revolution” (Angrist & Pischke, 2010), “Causal Revolution” (Pearl & Mackenzie, 2018) e “Replication Crisis” (Collaboration, 2015; Nosek et al., 2022), ha determinato un cambiamento paradigmatico nelle pratiche delle scienze sociali e, in particolare, della psicologia (Korbmacher et al., 2023). Questa transizione verso quella che Munger (2023) definisce “Science versione 2” è stata motivata dalle lacune metodologiche precedenti e ha catalizzato l’adozione di approcci più rigorosi e replicabili.\nLa genesi di questa Riforma è radicata nella constatazione di problematiche metodologiche pervasive, tra cui la proliferazione di falsi positivi (Simmons et al., 2011), l’abuso dei “gradi di libertà dei ricercatori” (Gelman & Loken, 2013), e l’inadeguatezza delle pratiche statistiche tradizionali (Gelman & Loken, 2014). Fenomeni come il p-hacking, l’uso di campioni sottodimensionati (Button et al., 2013), e la mancanza di trasparenza nei metodi di ricerca hanno contribuito a minare la credibilità delle scoperte psicologiche (Ioannidis, 2005; Meehl, 1967), portando alla cosiddetta “Replication Crisis” (Baker, 2016; Bishop, 2019) – si veda il Capitolo 76.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/05_data_analysis.html#lapproccio-bayesiano",
    "href": "chapters/key_notions/05_data_analysis.html#lapproccio-bayesiano",
    "title": "6  La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana",
    "section": "6.1 L’Approccio Bayesiano",
    "text": "6.1 L’Approccio Bayesiano\nIn risposta a queste sfide, l’approccio bayesiano è emerso come un paradigma statistico fondamentale nella “Credibility Revolution”. Contrariamente all’inferenza frequentista basata sul Test dell’Ipotesi Nulla, la statistica bayesiana offre un framework più flessibile e intuitivo per l’analisi dei dati e l’inferenza causale. Il principio cardine dell’approccio bayesiano, l’aggiornamento delle distribuzioni di probabilità a priori (priors) alla luce di nuove evidenze, si allinea perfettamente con l’obiettivo di una scienza cumulativa e auto-correttiva.\nL’adozione di metodi bayesiani in psicologia comporta diversi vantaggi significativi:\n\nQuantificazione dell’incertezza: L’inferenza bayesiana fornisce distribuzioni di probabilità posteriori complete per i parametri di interesse, offrendo una rappresentazione più ricca e sfumata dell’incertezza rispetto agli intervalli di confidenza frequentisti.\nIncorporazione di conoscenze pregresse: Le priors bayesiane consentono l’integrazione formale di conoscenze precedenti nel processo inferenziale, promuovendo un approccio cumulativo alla ricerca.\nRobustezza alle pratiche di ricerca discutibili: I metodi bayesiani sono meno suscettibili a pratiche come il p-hacking, poiché l’inferenza si basa sull’intera distribuzione posteriore piuttosto che su soglie arbitrarie di significatività.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/05_data_analysis.html#lapproccio-bayesiano-nella-ricerca",
    "href": "chapters/key_notions/05_data_analysis.html#lapproccio-bayesiano-nella-ricerca",
    "title": "6  La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana",
    "section": "6.2 L’approccio bayesiano nella ricerca",
    "text": "6.2 L’approccio bayesiano nella ricerca\nL’impiego delle statistiche bayesiane nella ricerca psicologica presenta notevoli vantaggi rispetto ad altri metodi statistici tradizionali, come il test di significatività dell’ipotesi nulla. Un punto di forza importante risiede nella sua indipendenza dalla teoria dei grandi campioni, rendendolo particolarmente adatto per gli studi psicologici che spesso si basano su campioni di dimensioni ridotte (Larson et al., 2023).\nLa ricerca psicologica è frequentemente caratterizzata da campioni limitati, dovuti a diversi fattori quali la bassa prevalenza di determinate condizioni, le difficoltà nel reclutamento dei partecipanti e le complessità nelle procedure di valutazione. Questi campioni di piccole dimensioni sono intrinsecamente soggetti a una maggiore eterogeneità, che si manifesta nella variabilità del fenotipo comportamentale delle condizioni psicologiche esaminate e nella discrepanza tra le stime degli effetti in diversi studi. Tale eterogeneità può condurre a stime degli effetti distorte e scarsamente riproducibili.\nL’approccio bayesiano offre una soluzione efficace a queste problematiche. In primo luogo, consente di valutare l’adeguatezza della dimensione del campione attraverso un’analisi della sensibilità dei risultati rispetto alla specificazione delle distribuzioni a priori. In secondo luogo, permette di ottenere risultati precisi anche con campioni ridotti, a condizione che le conoscenze a priori siano accurate e ben definite.\nUn ulteriore vantaggio dell’approccio bayesiano è la sua capacità di ottimizzare l’uso dei campioni di partecipanti, favorendo un’inclusione equa delle popolazioni diversificate. Questo è particolarmente rilevante per gruppi spesso sottorappresentati, come le minoranze etniche. Le statistiche bayesiane aiutano a superare questa sfida evitando di esercitare una pressione eccessiva su questi gruppi per aumentarne la partecipazione, permettendo così una ricerca più equa e rappresentativa.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/05_data_analysis.html#modellazione-formale",
    "href": "chapters/key_notions/05_data_analysis.html#modellazione-formale",
    "title": "6  La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana",
    "section": "6.3 Modellazione Formale",
    "text": "6.3 Modellazione Formale\nLa “Credibility Revolution” ha catalizzato l’integrazione della Data Science nelle pratiche di ricerca psicologica. L’adozione di pipeline di analisi dei dati riproducibili, l’uso di controllo di versione, e la condivisione di dati e codice sono diventati standard de facto nella comunità scientifica. Questi strumenti non solo migliorano la trasparenza e la replicabilità della ricerca, ma facilitano anche la collaborazione e l’accumulo di conoscenze nel campo.\nParallelamente, si è osservato un rinnovato interesse per la modellazione formale in psicologia, che consente non solo la verifica ma anche lo sviluppo di modelli dei meccanismi sottostanti ai fenomeni psicologici (Oberauer & Lewandowsky, 2019; Van Dongen et al., 2024). Questo approccio supera la mera descrizione delle associazioni tra variabili, che era tipica della pratica dominante dell’ANOVA nel contesto pre-riforma.\nLa modellazione bayesiana si presta particolarmente bene a questo approccio, offrendo un framework unificato per la specificazione di modelli formali, l’incorporazione di incertezza parametrica, e la valutazione dell’evidenza empirica. Attraverso tecniche come il confronto tra modelli bayesiano e l’analisi di sensibilità, i ricercatori possono valutare rigorosamente la plausibilità relativa di diverse teorie psicologiche.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/05_data_analysis.html#riflessioni-epistemologiche",
    "href": "chapters/key_notions/05_data_analysis.html#riflessioni-epistemologiche",
    "title": "6  La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana",
    "section": "6.4 Riflessioni Epistemologiche",
    "text": "6.4 Riflessioni Epistemologiche\nL’adozione di metodi bayesiani e della Data Science in psicologia deve essere accompagnata da una profonda riflessione epistemologica. Come sottolineato da George Box\n\ntutti i modelli sono sbagliati, ma alcuni sono utili.\n\nQuesta massima risuona particolarmente nel contesto della ricerca psicologica, dove i fenomeni di interesse sono spesso complessi e multifattoriali.\nL’approccio bayesiano, con la sua enfasi sull’aggiornamento iterativo delle credenze alla luce di nuove evidenze, si allinea naturalmente con una visione della scienza come processo di apprendimento continuo piuttosto che come ricerca di verità assolute. Questa prospettiva riconosce i limiti intrinseci dei nostri modelli e delle nostre teorie, pur valorizzandone l’utilità euristica e predittiva (si veda la discussione nella ?sec-poetic-validity).\nIn particolare, McElreath (2020) sottolinea l’importanza di riconoscere la dualità tra il “mondo del modello” e il mondo reale più ampio che cerchiamo di comprendere. Questa consapevolezza è cruciale per evitare la reificazione dei nostri modelli statistici e per mantenere una prospettiva critica sulle nostre inferenze.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/05_data_analysis.html#conclusione",
    "href": "chapters/key_notions/05_data_analysis.html#conclusione",
    "title": "6  La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana",
    "section": "6.5 Conclusione",
    "text": "6.5 Conclusione\nL’integrazione dell’approccio bayesiano e della data science nella ricerca psicologica rappresenta una risposta promettente alle sfide poste dalla “Replication Crisis”. Offrendo un framework coerente per la modellazione formale, l’inferenza statistica e l’incorporazione di conoscenze pregresse, questi approcci promettono di elevare il rigore e la credibilità della ricerca psicologica. Tuttavia, è fondamentale che l’adozione di questi metodi sia accompagnata da una adeguata consapevolezza metodologica ed epistemologica – si veda, ad esempio, il ?sec-causal-inference-regr.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/05_data_analysis.html#bibliografia",
    "href": "chapters/key_notions/05_data_analysis.html#bibliografia",
    "title": "6  La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAngrist, J. D., & Pischke, J.-S. (2010). The credibility revolution in empirical economics: How better research design is taking the con out of econometrics. Journal of economic perspectives, 24(2), 3–30.\n\n\nBaker, M. (2016). 1,500 scientists lift the lid on reproducibility. Nature, 533(7604).\n\n\nBishop, D. (2019). The psychology of experimental psychologists: Overcoming cognitive constraints to improve research.\n\n\nButton, K. S., Ioannidis, J. P., Mokrysz, C., Nosek, B. A., Flint, J., Robinson, E. S., & Munafò, M. R. (2013). Power failure: why small sample size undermines the reliability of neuroscience. Nature Reviews Neuroscience, 14(5), 365–376.\n\n\nCollaboration, O. S. (2015). Estimating the reproducibility of psychological science. Science, 349(6251), aac4716.\n\n\nGelman, A., & Loken, E. (2013). The garden of forking paths: Why multiple comparisons can be a problem, even when there is no «fishing expedition» or «p-hacking» and the research hypothesis was posited ahead of time. Department of Statistics, Columbia University, 348(1-17), 3.\n\n\nGelman, A., & Loken, E. (2014). The statistical crisis in science. American scientist, 102(6), 460–465.\n\n\nIoannidis, J. P. (2005). Why most published research findings are false. PLoS medicine, 2(8), e124.\n\n\nKorbmacher, M., Azevedo, F., Pennington, C. R., Hartmann, H., Pownall, M., Schmidt, K., Elsherif, M., Breznau, N., Robertson, O., Kalandadze, T., et al. (2023). The replication crisis has led to positive structural, procedural, and community changes. Communications Psychology, 1(1), 3.\n\n\nLabatut, B. (2021). Quando abbiamo smesso di capire il mondo. Adelphi Edizioni spa.\n\n\nLarson, C., Kaplan, D., Girolamo, T., Kover, S. T., & Eigsti, I.-M. (2023). A Bayesian statistics tutorial for clinical research: Prior distributions and meaningful results for small clinical samples. Journal of Clinical Psychology, 79(11), 2602–2624.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nMeehl, P. E. (1967). Theory-testing in psychology and physics: A methodological paradox. Philosophy of science, 34(2), 103–115.\n\n\nMunger, K. (2023). Temporal validity as meta-science. Research & Politics, 10(3), 20531680231187271.\n\n\nNosek, B. A., Hardwicke, T. E., Moshontz, H., Allard, A., Corker, K. S., Dreber, A., Fidler, F., Hilgard, J., Kline Struhl, M., Nuijten, M. B., et al. (2022). Replicability, robustness, and reproducibility in psychological science. Annual Review of Psychology, 73(1), 719–748.\n\n\nOberauer, K., & Lewandowsky, S. (2019). Addressing the theory crisis in psychology. Psychonomic Bulletin & Review, 26, 1596–1618.\n\n\nPearl, J., & Mackenzie, D. (2018). The book of why: the new science of cause and effect. Basic books.\n\n\nSimmons, J. P., Nelson, L. D., & Simonsohn, U. (2011). False-positive psychology: Undisclosed flexibility in data collection and analysis allows presenting anything as significant. Psychological science, 22(11), 1359–1366.\n\n\nVan Dongen, N., Bork, R. van, Finnemann, A., Haslbeck, J., Maas, H. L. van der, Robinaugh, D. J., Ron, J. de, Sprenger, J., & Borsboom, D. (2024). Productive explanation: A framework for evaluating explanations in psychological science. Psychological Review.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/R/introduction_r_lang.html",
    "href": "chapters/R/introduction_r_lang.html",
    "title": "R",
    "section": "",
    "text": "R è uno dei linguaggi di programmazione più utilizzati per l’analisi dei dati, apprezzato per la sua flessibilità, potenza e il supporto offerto da una vasta comunità di utenti e sviluppatori. Nato come progetto open-source agli inizi degli anni ’90, R è stato concepito specificamente per rispondere alle esigenze di analisi statistica e visualizzazione grafica, diventando rapidamente uno strumento essenziale nel panorama accademico e scientifico.\nR si distingue per la sua capacità di gestire, manipolare e analizzare grandi quantità di dati. Il linguaggio offre un ecosistema ricchissimo di funzionalità che spaziano dalla modellazione lineare e non lineare all’analisi delle serie temporali, includendo tecniche avanzate di classificazione e clustering. Tale versatilità copre praticamente ogni possibile esigenza di analisi statistica, e grazie a una libreria pressoché infinita di pacchetti disponibili, gli utenti possono estendere ulteriormente le capacità del linguaggio per soddisfare necessità specifiche e settoriali.\nUno degli aspetti più apprezzati di R è la sua capacità di creare grafici e visualizzazioni di alta qualità. Con strumenti come quelli offerti dai pacchetti ggplot2 e plotly, R permette di realizzare rappresentazioni grafiche personalizzate e immediatamente pronte per la pubblicazione, come istogrammi, scatterplot e visualizzazioni interattive. Questi strumenti grafici ricoprono un ruolo cruciale nella comunicazione scientifica, rendendo i dati complessi più comprensibili e accessibili.\nIn psicologia e nelle scienze sociali, R è particolarmente utile grazie alle sue capacità avanzate di analisi statistica e visualizzazione. Permette di affrontare analisi sofisticate, come modelli di regressione, analisi fattoriale, e metodi per dati longitudinali, rendendolo uno strumento indispensabile per chi si occupa di ricerca. La sua flessibilità lo rende inoltre ideale per adattarsi a dataset eterogenei e complessi, spesso caratteristici di queste discipline.\nImparare R non significa solo acquisire competenze tecniche, ma anche aprire le porte a nuove possibilità di analisi e ricerca. Grazie al suo continuo sviluppo e alla natura open-source, R è in costante evoluzione, garantendo strumenti sempre aggiornati per affrontare le sfide più attuali nel campo della scienza dei dati.\nIn questo percorso introduttivo, esploreremo le basi del linguaggio R, muovendoci dalla gestione basilare dei dati fino alla creazione di grafici complessi e alla realizzazione di analisi statistiche articolate.",
    "crumbs": [
      "R"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html",
    "href": "chapters/R/01_r_syntax.html",
    "title": "7  Data Science e R: un approccio moderno all’analisi dei dati",
    "section": "",
    "text": "7.1 Introduzione\nNegli ultimi anni, la data science è emersa come uno dei domini più rilevanti nel panorama tecnologico e scientifico. Questa crescita è guidata dalla necessità sempre maggiore di analizzare grandi quantità di dati per supportare processi decisionali più efficaci. In questo contesto, R si è affermato come uno degli strumenti più potenti e versatili, particolarmente apprezzato da statistici e data scientist.\nR è un linguaggio di programmazione specializzato nel calcolo statistico, che eccelle nell’analisi dei dati e nel data mining. La sua piattaforma offre capacità straordinarie per l’analisi, l’elaborazione e la visualizzazione dei dati, rendendolo uno strumento fondamentale nel panorama della data science moderna.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data Science e R: un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#trasparenza-e-riproducibilità",
    "href": "chapters/R/01_r_syntax.html#trasparenza-e-riproducibilità",
    "title": "7  Data Science e R: un approccio moderno all’analisi dei dati",
    "section": "\n7.2 Trasparenza e Riproducibilità",
    "text": "7.2 Trasparenza e Riproducibilità\nLa scelta di R come strumento per la data science assume particolare rilevanza nel contesto della “crisi della replicabilità” in psicologia, un problema che ha evidenziato come molte analisi dei dati non siano facilmente riproducibili (Obels et al., 2020). R affronta questa sfida offrendo tre vantaggi fondamentali:\n\n\nDocumentazione Trasparente attraverso lo Scripting\n\nOgni analisi viene documentata attraverso script espliciti\nIl codice può essere salvato, condiviso e rivisto\nLe analisi possono essere facilmente replicate con nuovi dati\n\n\n\nFlessibilità e Personalizzazione\n\nAmbiente adattabile a diverse esigenze analitiche\nVasta collezione di pacchetti per metodi statistici avanzati\nPossibilità di sviluppare soluzioni personalizzate\n\n\n\nReporting Integrato\n\nIntegrazione con strumenti come R Markdown e Quarto\nCreazione di documenti dinamici che combinano codice e risultati\nGenerazione automatica di report aggiornabili\n\n\n\nA differenza dei software con interfacce grafiche, l’approccio basato sul codice di R elimina le ambiguità e aumenta la verificabilità delle analisi. Questo non solo migliora la qualità della ricerca, ma contribuisce anche a costruire una comunità scientifica più trasparente e affidabile.\nL’utilizzo di R rappresenta quindi non solo una scelta tecnica, ma l’adozione di una metodologia che promuove rigore scientifico, trasparenza e riproducibilità nella ricerca moderna.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data Science e R: un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#installare-r-e-rstudio",
    "href": "chapters/R/01_r_syntax.html#installare-r-e-rstudio",
    "title": "7  Data Science e R: un approccio moderno all’analisi dei dati",
    "section": "\n7.3 Installare R e RStudio",
    "text": "7.3 Installare R e RStudio\n\nScarica e installa R\nVai al sito ufficiale di CRAN (https://cran.r-project.org/), scegli la versione per il tuo sistema operativo (Windows, Mac o Linux) e segui le istruzioni di installazione.\nScarica e installa RStudio\nDopo aver installato R, scarica RStudio dal sito ufficiale (https://posit.co/download/rstudio-desktop/). Scegli la versione gratuita “RStudio Desktop” e segui le istruzioni per il tuo sistema operativo.\n\nUna spiegazione dettagliata del processo di installazione di R e RStudio è disponibile in Okoye & Hosseini (2024).",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data Science e R: un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#panoramica-sullinterfaccia-di-rstudio",
    "href": "chapters/R/01_r_syntax.html#panoramica-sullinterfaccia-di-rstudio",
    "title": "7  Data Science e R: un approccio moderno all’analisi dei dati",
    "section": "\n7.4 Panoramica sull’interfaccia di RStudio",
    "text": "7.4 Panoramica sull’interfaccia di RStudio\nRStudio rende l’uso di R più intuitivo grazie alla sua interfaccia divisa in quattro pannelli principali:\n\n\nPannello degli script: Qui puoi scrivere e modificare i tuoi script, cioè sequenze di comandi salvabili per analisi ripetibili e organizzate.\n\nConsole: Esegue i comandi scritti direttamente o lanciati dagli script, mostrando risultati, messaggi e errori.\n\nPannello dell’ambiente: Mostra i dataset, le variabili e gli oggetti caricati nella sessione di lavoro, permettendoti di gestire facilmente i dati.\n\nPannello grafici/aiuto/file: Visualizza grafici, fornisce accesso alla documentazione di R e consente di navigare tra file e cartelle sul tuo sistema.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data Science e R: un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#creare-un-nuovo-progetto-in-rstudio",
    "href": "chapters/R/01_r_syntax.html#creare-un-nuovo-progetto-in-rstudio",
    "title": "7  Data Science e R: un approccio moderno all’analisi dei dati",
    "section": "\n7.5 Creare un Nuovo Progetto in RStudio",
    "text": "7.5 Creare un Nuovo Progetto in RStudio\nAvviare un nuovo progetto\nDal menu di RStudio, seleziona File &gt; New Project… per creare un nuovo progetto. I progetti in RStudio sono uno strumento efficace per organizzare il lavoro relativo a una specifica analisi o domanda di ricerca. All’interno di un progetto puoi raccogliere script, file di dati e output, mantenendo tutto ben strutturato.\nScegliere la posizione del progetto\nPuoi creare una nuova directory dedicata al progetto oppure associare il progetto a una directory esistente. Organizzare i progetti in cartelle dedicate aiuta a mantenere i file in ordine e a utilizzare percorsi relativi, rendendo il tuo lavoro più facile da condividere con collaboratori e più portabile tra diversi sistemi.\nQuesta organizzazione è particolarmente utile per evitare confusione e assicurarsi che tutti i file necessari siano facilmente accessibili e collegati al progetto corretto.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data Science e R: un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#concetti-di-base-nella-programmazione-in-r",
    "href": "chapters/R/01_r_syntax.html#concetti-di-base-nella-programmazione-in-r",
    "title": "7  Data Science e R: un approccio moderno all’analisi dei dati",
    "section": "\n7.6 Concetti di Base nella Programmazione in R",
    "text": "7.6 Concetti di Base nella Programmazione in R\nIniziare a usare R, soprattutto per chi si avvicina per la prima volta a questo linguaggio nel contesto della psicologia, significa comprendere i concetti fondamentali che ne costituiscono la base. Questo capitolo introduce i principi essenziali della programmazione in R, tra cui:\n\nLa comprensione della sintassi di R.\nLa familiarizzazione con i principali tipi di dati e strutture.\nL’acquisizione delle operazioni di base.\n\nQuesti concetti sono fondamentali per manipolare efficacemente i dati e condurre analisi statistiche, rappresentando il punto di partenza per sfruttare al meglio le potenzialità di R.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data Science e R: un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#oggetti-in-r",
    "href": "chapters/R/01_r_syntax.html#oggetti-in-r",
    "title": "7  Data Science e R: un approccio moderno all’analisi dei dati",
    "section": "\n7.7 Oggetti in R",
    "text": "7.7 Oggetti in R\nIn R, tutto è un oggetto: dai numeri o stringhe di testo semplici, fino a strutture più complesse come grafici, riassunti di analisi statistiche o script che eseguono compiti specifici. Creare e assegnare valori agli oggetti è fondamentale per lavorare in R.\n\n7.7.1 Creare oggetti\nPer creare un oggetto, basta assegnargli un nome e un valore usando l’operatore di assegnazione &lt;-:\n\nmy_obj &lt;- 48\n\nIn questo esempio, abbiamo creato un oggetto chiamato my_obj e gli abbiamo assegnato il valore 48. Anche l’operatore = può essere usato, ma è considerato una cattiva pratica.\nPer visualizzare il valore di un oggetto, basta scriverne il nome:\n\nmy_obj\n#&gt; [1] 48\n\nGli oggetti creati vengono memorizzati nell’ambiente di lavoro. In RStudio, puoi visualizzarli nella scheda Environment e ottenere dettagli come tipo, lunghezza e valore.\nÈ possibile assegnare a un oggetto anche una stringa di testo, racchiudendola tra virgolette:\n\nmy_obj2 &lt;- \"R è fantastico\"\nmy_obj2\n#&gt; [1] \"R è fantastico\"\n\nSe dimentichi le virgolette, R mostrerà un errore.\nPer modificare il valore di un oggetto esistente, basta riassegnarlo:\n\nmy_obj2 &lt;- 1024\n\nOra il tipo di my_obj2 è cambiato da carattere a numerico. È anche possibile usare oggetti per crearne di nuovi:\n\nmy_obj3 &lt;- my_obj + my_obj2\nmy_obj3\n#&gt; [1] 1072\n\nSe provi a sommare oggetti di tipo diverso, R restituirà un errore:\nchar_obj &lt;- \"ciao\"\nchar_obj2 &lt;- \"mondo\"\nchar_obj3 &lt;- char_obj + char_obj2\n#&gt; Error in char_obj + char_obj2 : non-numeric argument to binary operator\nQuando incontri errori come questo, chiedi a AI la spiegazione del messaggio, per esempio: “non-numeric argument to binary operator error + r”. Un errore comune è anche:\nmy_obj &lt;- 48\nmy_obj4 &lt;- my_obj + no_obj\n#&gt; Error: object 'no_obj' not found\nR segnala che no_obj non è stato definito e, di conseguenza, l’oggetto my_obj4 non è stato creato.\n\n7.7.2 Nomi degli Oggetti\nAttribuire nomi agli oggetti potrebbe sembrare un dettaglio secondario, ma è fondamentale scegliere nomi brevi e informativi. Un buon nome migliora la leggibilità del codice e ne facilita la manutenzione. È importante adottare uno stile coerente, come uno dei seguenti:\n\n\nSnake case: output_summary\n\n\nDot case: output.summary\n\n\nCamel case: outputSummary\n\n\nIn questo corso useremo lo stile più diffuso, Snake Case, che separa le parole con il carattere di sottolineatura _.\nCi sono alcune regole fondamentali da rispettare nella scelta dei nomi:\n\nNon possono iniziare con un numero (ad esempio, 2my_variable non è valido).\n\nNon possono contenere caratteri speciali come &, ^, /, ecc.\n\nEvita di usare parole riservate (ad esempio, TRUE, NA) o nomi di funzioni esistenti (ad esempio, data).\n\nEsempio di cosa non fare:\ndata &lt;- read.table(\"mydatafile\", header = TRUE) # `data` è già una funzione!\n\n7.7.3 Commenti\nI commenti sono uno strumento essenziale per rendere il codice più chiaro e comprensibile, sia per te stesso sia per altri. Nel linguaggio R, i commenti iniziano con il simbolo #, e tutto ciò che lo segue sulla stessa riga viene ignorato dall’interprete durante l’esecuzione.\n\n7.7.3.1 Perché commentare?\nI commenti servono a spiegare perché il codice è scritto in un certo modo, non solo come funziona (questo è evidente leggendo il codice). Una buona pratica consiste nel commentare le decisioni o i passaggi che non risultano immediatamente evidenti.\nAd esempio, invece di scrivere un commento ridondante come:\n\n# Assegno 42 alla variabile x\nx &lt;- 42\n\nè più utile fornire un contesto:\n\n# Valore iniziale scelto per semplificare i calcoli successivi\nx &lt;- 42\n\n\n7.7.3.2 Vantaggi\nCommentare in modo appropriato aiuta a:\n\n\nRidurre il tempo necessario per comprendere o modificare il codice, anche mesi o anni dopo averlo scritto.\n\nFacilitare la collaborazione con altri, rendendo il codice leggibile e accessibile.\n\nMigliorare la manutenibilità e il riutilizzo del codice.\n\nUn codice ben commentato non è solo più facile da leggere, ma anche più professionale e robusto nel lungo termine.\n\n7.7.4 Usare R come Calcolatore\nR può essere utilizzato come un semplice calcolatore digitando direttamente nella console numeri e operatori aritmetici per eseguire operazioni come somma, sottrazione, moltiplicazione e divisione (+, -, *, /). Questo lo rende uno strumento immediato e versatile per calcoli di base e avanzati.\n\nEsempio 7.1 La Satisfaction With Life Scale (SWLS) contiene 5 item, ciascuno valutato con una scala Likert a 7 punti, dove:\n1 = “completamente in disaccordo” e 7 = “completamente d’accordo”.\nGli item sono:\n\nPer la maggior parte, la mia vita si avvicina al mio ideale.\n\nLe mie condizioni di vita sono eccellenti.\n\nSono soddisfatto della mia vita.\n\nFino ad ora, ho ottenuto le cose importanti che voglio nella vita.\n\nSe potessi vivere la mia vita di nuovo, non cambierei quasi nulla.\n\nSupponiamo che un individuo risponda nel seguente modo:\n\nItem 1: 5\n\nItem 2: 3\n\nItem 3: 4\n\nItem 4: 2\n\nItem 5: 2\n\nIl punteggio totale sulla SWLS si calcola sommando i punteggi di ciascun item:\n\nsogg1 &lt;- 5 + 3 + 4 + 2 + 2 \nsogg1\n#&gt; [1] 16\n\n\n\nEsempio 7.2 Il Body Mass Index (BMI) si calcola dividendo il peso, in chilogrammi, per il quadrato dell’altezza, in metri.\nLa formula è:\n\\[\n\\text{BMI} = \\frac{\\text{Peso (kg)}}{\\text{Altezza (m)}^2} .\n\\]\nSupponiamo che un individuo pesi 79.000 grammi (79 kg) e sia alto 176 cm (1.76 m). Il calcolo in R sarà:\n\nbmi &lt;- (79000 / 1000) / (176 / 100)^2\nbmi\n#&gt; [1] 25.5\n\n\nNota. L’uso di parentesi è fondamentale per garantire che le operazioni vengano eseguite nell’ordine corretto. In R, come in matematica, le operazioni racchiuse tra parentesi hanno la precedenza rispetto ad altre operazioni. Ad esempio, nel calcolo del BMI, abbiamo usato le parentesi per calcolare prima la conversione dei valori nell’unità di misura appropriata.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data Science e R: un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#ordine-di-precedenza-degli-operatori",
    "href": "chapters/R/01_r_syntax.html#ordine-di-precedenza-degli-operatori",
    "title": "7  Data Science e R: un approccio moderno all’analisi dei dati",
    "section": "\n7.8 Ordine di precedenza degli operatori",
    "text": "7.8 Ordine di precedenza degli operatori\nLe operazioni algebriche vengono eseguite in una particolare sequenza in R, nota come ordine di precedenza degli operatori. Questo ordine determina quali operazioni vengono eseguite per prime quando un’espressione include più operatori. In assenza di parentesi, l’ordine di precedenza è il seguente (dal più alto al più basso):\n\n\nParentesi: Le operazioni racchiuse tra parentesi () vengono eseguite per prime. Questo permette di sovrascrivere l’ordine naturale delle operazioni.\n\nresult &lt;- (2 + 3) * 4  # Risultato: 20\n\n\n\nEsponenziazione: L’operatore ^ viene eseguito dopo le parentesi.\n\nresult &lt;- 2^3  # Risultato: 8\n\n\n\nSegni unari: Il segno meno - o più + applicato a un singolo valore.\n\nresult &lt;- -3 + 5  # Risultato: 2\n\n\n\nMoltiplicazione, divisione e modulo: Gli operatori *, /, %/% (divisione intera) e %% (resto) hanno la stessa precedenza e vengono eseguiti da sinistra a destra.\n\nresult &lt;- 10 / 2 * 3  # Risultato: 15\nresult &lt;- 10 %% 3     # Risultato: 1\n\n\n\nAddizione e sottrazione: Gli operatori + e - vengono eseguiti dopo quelli di moltiplicazione/divisione.\n\nresult &lt;- 5 + 3 - 2  # Risultato: 6\n\n\n\nOperatori di assegnazione: Gli operatori &lt;-, -&gt;, =, che assegnano valori a variabili, vengono valutati per ultimi.\n\nx &lt;- 2 + 3 * 4  # Risultato: 14\n\n\n\nNote importanti:\n\n\nAssociazione a sinistra: La maggior parte degli operatori in R viene valutata da sinistra a destra (ad esempio, +, *, /).\n\nUso delle parentesi: Quando l’ordine di precedenza non è immediatamente chiaro o si vuole assicurare un ordine specifico, è sempre buona pratica usare le parentesi.\n\nCapire l’ordine di precedenza è fondamentale per evitare errori logici e garantire che il codice funzioni come previsto.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data Science e R: un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#usare-le-funzioni-in-r",
    "href": "chapters/R/01_r_syntax.html#usare-le-funzioni-in-r",
    "title": "7  Data Science e R: un approccio moderno all’analisi dei dati",
    "section": "\n7.9 Usare le funzioni in R",
    "text": "7.9 Usare le funzioni in R\nFino ad ora abbiamo creato oggetti semplici assegnando loro direttamente un valore. Con l’aumento dell’esperienza in R, potresti voler creare oggetti più complessi. Per aiutarti, R offre numerose funzioni già disponibili nella sua installazione di base, e altre possono essere aggiunte installando pacchetti. Una funzione è un insieme di istruzioni che eseguono un compito specifico. Inoltre, è possibile creare funzioni personalizzate.\n\n7.9.1 La funzione c() per creare vettori\nLa prima funzione utile da imparare è c(), che serve a concatenare valori in un vettore. Ad esempio:\n\nmy_vec &lt;- c(2, 3, 1, 6, 4, 3, 3, 7)\n\nQuesto codice crea un oggetto chiamato my_vec che contiene una sequenza di numeri. Alcuni concetti fondamentali sulle funzioni in R:\n\n\nNome e parentesi: Le funzioni in R sono sempre seguite da parentesi tonde ().\n\nArgomenti: Gli elementi passati alla funzione (tra le parentesi) ne personalizzano il comportamento e sono separati da virgole.\n\nPer vedere il contenuto del vettore:\n\nmy_vec\n#&gt; [1] 2 3 1 6 4 3 3 7\n\n\n7.9.2 Funzioni per analizzare vettori\nPuoi utilizzare altre funzioni per calcolare statistiche sul vettore:\n\nmean(my_vec)    # Media\n#&gt; [1] 3.62\n\n\nvar(my_vec)     # Varianza\n#&gt; [1] 3.98\n\n\nsd(my_vec)      # Deviazione standard\n#&gt; [1] 2\n\n\nlength(my_vec)  # Numero di elementi\n#&gt; [1] 8\n\nPuoi anche salvare i risultati in nuovi oggetti per riutilizzarli:\n\nvec_mean &lt;- mean(my_vec)\nvec_mean\n#&gt; [1] 3.62\n\n\n7.9.3 Creare sequenze regolari\nPer creare sequenze di numeri in passi regolari, puoi usare i seguenti comandi.\nSimbolo : per sequenze semplici:\n\nmy_seq &lt;- 1:10\nmy_seq\n#&gt;  [1]  1  2  3  4  5  6  7  8  9 10\n\nFunzione seq() per maggiore controllo:\n\nmy_seq2 &lt;- seq(from = 1, to = 5, by = 0.5)\nmy_seq2\n#&gt; [1] 1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0\n\n\n7.9.4 Ripetere valori\nPuoi ripetere valori o sequenze con la funzione rep().\nRipetere un valore:\n\nmy_seq3 &lt;- rep(2, times = 10)\nmy_seq3\n#&gt;  [1] 2 2 2 2 2 2 2 2 2 2\n\nRipetere una sequenza:\n\nmy_seq5 &lt;- rep(1:5, times = 3)\n\nRipetere ogni elemento di una sequenza:\n\nmy_seq6 &lt;- rep(1:5, each = 3)\nmy_seq6\n#&gt;  [1] 1 1 1 2 2 2 3 3 3 4 4 4 5 5 5\n\n\n7.9.5 Annidare funzioni\nÈ possibile combinare funzioni per creare comandi più complessi, come nell’esempio:\n\nmy_seq7 &lt;- rep(c(3, 1, 10, 7), each = 3)\nmy_seq7\n#&gt;  [1]  3  3  3  1  1  1 10 10 10  7  7  7\n\nPer maggiore leggibilità, puoi separare i passaggi:\n\nin_vec &lt;- c(3, 1, 10, 7)\nmy_seq7 &lt;- rep(in_vec, each = 3)\nmy_seq7\n#&gt;  [1]  3  3  3  1  1  1 10 10 10  7  7  7\n\nQuesta pratica facilita la comprensione del codice e lo rende più chiaro.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data Science e R: un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#lavorare-con-i-vettori-in-r",
    "href": "chapters/R/01_r_syntax.html#lavorare-con-i-vettori-in-r",
    "title": "7  Data Science e R: un approccio moderno all’analisi dei dati",
    "section": "\n7.10 Lavorare con i vettori in R",
    "text": "7.10 Lavorare con i vettori in R\nIn R, i vettori sono uno degli elementi fondamentali per manipolare, riassumere e ordinare i dati. Qui trovi una panoramica su come estrarre, sostituire, ordinare, lavorare con dati mancanti e sfruttare la vettorizzazione dei vettori.\n\n7.10.1 Estrarre elementi da un vettore\nPuoi estrarre uno o più elementi da un vettore usando le parentesi quadre [ ].\nPer posizione: Specifica la posizione degli elementi.\n\nmy_vec &lt;- c(2, 3, 1, 6, 4, 3, 3, 7)\nmy_vec[3]  # Terzo elemento\n#&gt; [1] 1\n\n\nmy_vec[c(1, 5, 6)]  # Elementi 1°, 5° e 6°\n#&gt; [1] 2 4 3\n\n\nmy_vec[3:8]  # Da 3° a 8°\n#&gt; [1] 1 6 4 3 3 7\n\nCon condizioni logiche: Usa espressioni logiche per selezionare elementi.\n\nmy_vec[my_vec &gt; 4]  # Elementi &gt; 4\n#&gt; [1] 6 7\n\n\nmy_vec[my_vec &lt;= 4]  # Elementi ≤ 4\n#&gt; [1] 2 3 1 4 3 3\n\n\nmy_vec[my_vec != 4]  # Elementi diversi da 4\n#&gt; [1] 2 3 1 6 3 3 7\n\nOperatori logici: Combina condizioni con & (AND) e | (OR).\n\nmy_vec[my_vec &gt; 2 & my_vec &lt; 6]  # Tra 2 e 6\n#&gt; [1] 3 4 3 3\n\n\n7.10.2 Sostituire elementi in un vettore\nPuoi modificare i valori di un vettore usando [ ] e l’operatore &lt;-.\nUn singolo elemento:\n\nmy_vec[4] &lt;- 500  # Cambia il 4° elemento\nmy_vec\n#&gt; [1]   2   3   1 500   4   3   3   7\n\nPiù elementi:\n\nmy_vec[c(6, 7)] &lt;- 100  # Cambia il 6° e 7° elemento\nmy_vec\n#&gt; [1]   2   3   1 500   4 100 100   7\n\nCon condizioni logiche:\n\nmy_vec[my_vec &lt;= 4] &lt;- 1000  # Cambia valori ≤ 4\nmy_vec\n#&gt; [1] 1000 1000 1000  500 1000  100  100    7\n\n\n7.10.3 Ordinare un vettore\nDal più piccolo al più grande:\n\nvec_sort &lt;- sort(my_vec)\nvec_sort\n#&gt; [1]    7  100  100  500 1000 1000 1000 1000\n\nDal più grande al più piccolo:\n\nvec_sort2 &lt;- sort(my_vec, decreasing = TRUE)\nvec_sort2\n#&gt; [1] 1000 1000 1000 1000  500  100  100    7\n\nOrdinare un vettore in base a un altro:\n\nheight &lt;- c(180, 155, 160, 167, 181)\np.names &lt;- c(\"Joanna\", \"Charlotte\", \"Helen\", \"Karen\", \"Amy\")\nheight_ord &lt;- order(height)\nnames_ord &lt;- p.names[height_ord]\nnames_ord\n#&gt; [1] \"Charlotte\" \"Helen\"     \"Karen\"     \"Joanna\"    \"Amy\"",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data Science e R: un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#operazioni-vettoriali-e-vettorizzazione-in-r",
    "href": "chapters/R/01_r_syntax.html#operazioni-vettoriali-e-vettorizzazione-in-r",
    "title": "7  Data Science e R: un approccio moderno all’analisi dei dati",
    "section": "\n7.11 Operazioni Vettoriali e Vettorizzazione in R",
    "text": "7.11 Operazioni Vettoriali e Vettorizzazione in R\nLa vettorializzazione è una delle caratteristiche più potenti di R, che consente di applicare operazioni o funzioni direttamente a tutti gli elementi di un vettore in modo simultaneo, senza dover ricorrere a cicli espliciti. Questo approccio rende il codice più conciso, leggibile ed efficiente, sfruttando al meglio le capacità intrinseche del linguaggio.\n\n7.11.1 Operazioni Aritmetiche su Vettori\nLe operazioni algebriche in R, come addizione, sottrazione, moltiplicazione e divisione, sono vettorizzate. Questo significa che ogni operazione viene applicata “elemento per elemento” al vettore.\nConsideriamo ad esempio il seguente vettore:\n\nmy_vec &lt;- c(3, 5, 7, 1, 9, 20)\n\nSe vogliamo moltiplicare ciascun elemento di my_vec per 5, possiamo scrivere:\n\nmy_vec * 5\n#&gt; [1]  15  25  35   5  45 100\n\nAnalogamente, possiamo effettuare altre operazioni algebriche, come divisione o elevamento a potenza:\n\nmy_vec / 2\n#&gt; [1]  1.5  2.5  3.5  0.5  4.5 10.0\n\n\nmy_vec^2\n#&gt; [1]   9  25  49   1  81 400\n\nQueste operazioni vengono applicate automaticamente a ciascun elemento del vettore, senza dover iterare su di essi.\n\n7.11.2 Operazioni Elemento per Elemento tra Due Vettori\nLa vettorializzazione consente anche di eseguire operazioni tra due vettori, applicandole elemento per elemento. Supponiamo di avere un secondo vettore:\n\nmy_vec2 &lt;- c(17, 15, 13, 19, 11, 0)\n\nSe vogliamo sommare i due vettori, possiamo scrivere:\n\nmy_vec + my_vec2\n#&gt; [1] 20 20 20 20 20 20\n\nIn questo caso, il primo elemento di my_vec viene sommato al primo elemento di my_vec2, il secondo elemento al secondo, e così via.\n\nEsempio 7.3 Di seguito mostriamo come calcolare i punteggi totali per 10 individui che hanno risposto ai 5 item della Satisfaction With Life Scale (SWLS), utilizzando le formule e l’aritmetica vettorializzata di R.\nStep 1: Definiamo i punteggi per ciascun item. Ogni vettore contiene i punteggi dati dai 10 individui a uno specifico item della scala:\n\n# Punteggi dei 10 individui per ciascun item\nitem1 &lt;- c(5, 4, 6, 7, 3, 2, 5, 6, 4, 7)\nitem2 &lt;- c(3, 2, 4, 6, 2, 1, 4, 5, 3, 6)\nitem3 &lt;- c(4, 5, 6, 5, 3, 2, 5, 7, 4, 5)\nitem4 &lt;- c(2, 3, 4, 3, 2, 1, 3, 4, 2, 5)\nitem5 &lt;- c(2, 2, 3, 4, 1, 1, 3, 3, 2, 4)\n\nI valori 5, 3, 4, 2, 2 sono i punteggi del primo individuo sui 5 item; i punteggio 4, 2, 5, 3, 2 sono i punteggi del secondo individuo sui 5 item, e così via.\nStep 2: Sommiamo i punteggi per calcolare il totale. Il punteggio totale di ciascun individuo è la somma dei punteggi relativi ai 5 item. Formalmente, per l’individuo \\(i\\) (\\(i = 1, 2, \\ldots, 10\\)), il punteggio totale è calcolato come:\n\\[\n\\text{PunteggioTotale}_i = \\text{item1}_i + \\text{item2}_i + \\text{item3}_i + \\text{item4}_i + \\text{item5}_i .\n\\]\nIn R, possiamo sommare i vettori direttamente grazie all’aritmetica vettorializzata:\n\n# Calcolo dei punteggi totali per ciascun individuo\ntotal_scores &lt;- item1 + item2 + item3 + item4 + item5\ntotal_scores\n#&gt;  [1] 16 16 23 25 11  7 20 25 15 27\n\nIl risultato è un vettore con i punteggi totali per ciascun individuo.\nStep 3: Mostriamo i risultati. Per organizzare meglio i dati, creiamo una tabella che associa i punteggi totali agli individui:\n\n# Creiamo una tabella con i punteggi totali\nindividui &lt;- paste(\"Individuo\", 1:10)\nrisultati_swls &lt;- data.frame(Individuo = individui, PunteggioTotale = total_scores)\nprint(risultati_swls)\n#&gt;       Individuo PunteggioTotale\n#&gt; 1   Individuo 1              16\n#&gt; 2   Individuo 2              16\n#&gt; 3   Individuo 3              23\n#&gt; 4   Individuo 4              25\n#&gt; 5   Individuo 5              11\n#&gt; 6   Individuo 6               7\n#&gt; 7   Individuo 7              20\n#&gt; 8   Individuo 8              25\n#&gt; 9   Individuo 9              15\n#&gt; 10 Individuo 10              27\n\nSpiegazione delle operazioni:\n\nOgni vettore contiene i punteggi di 10 individui per un dato item. Ad esempio, il vettore item1 contiene i punteggi relativi al primo item, e così via.\n\nGrazie all’aritmetica vettorializzata, quando sommiamo i vettori \\(\\text{item1}\\), \\(\\text{item2}\\), \\(\\text{item3}\\), \\(\\text{item4}\\), \\(\\text{item5}\\), R somma elemento per elemento:\n\\[\n\\text{total\\_scores}_i = \\text{item1}_i + \\text{item2}_i + \\text{item3}_i + \\text{item4}_i + \\text{item5}_i\n\\]\n\nQuesta tecnica consente di calcolare rapidamente i punteggi totali per tutti gli individui senza dover scrivere un ciclo esplicito, rendendo il codice più semplice e leggibile.\n\nQuesto esempio illustra come R semplifichi operazioni complesse grazie al calcolo vettorializzato, migliorando l’efficienza e la chiarezza del codice.\n\n\n7.11.3 Attenzione al Riciclo dei Vettori\nSe i due vettori hanno lunghezze diverse, R applicherà il meccanismo di riciclo: gli elementi del vettore più corto verranno ripetuti ciclicamente per abbinarsi alla lunghezza del vettore più lungo. Questo comportamento, sebbene utile, richiede attenzione per evitare risultati inattesi.\nAd esempio:\n\nshort_vec &lt;- c(1, 2)\nmy_vec + short_vec\n#&gt; [1]  4  7  8  3 10 22\n\nIn questo caso, gli elementi di short_vec vengono riciclati per abbinarsi alla lunghezza di my_vec. Il risultato è:\n(3+1, 5+2, 7+1, 1+2, 9+1, 20+2)\n\n7.11.4 Applicazione di Funzioni su Vettori\nLa vettorializzazione non si limita alle operazioni algebriche, ma si estende anche all’uso di funzioni. Supponiamo di voler calcolare il logaritmo naturale di ciascun elemento di un vettore:\n\nlog(my_vec)\n#&gt; [1] 1.10 1.61 1.95 0.00 2.20 3.00\n\nLa funzione log() viene applicata automaticamente a ogni elemento del vettore. Analogamente, possiamo utilizzare altre funzioni predefinite di R, come:\n\nsqrt(my_vec)  # Calcola la radice quadrata di ciascun elemento\n#&gt; [1] 1.73 2.24 2.65 1.00 3.00 4.47\nexp(my_vec)   # Eleva e alla potenza specificata da ciascun elemento\n#&gt; [1] 2.01e+01 1.48e+02 1.10e+03 2.72e+00 8.10e+03 4.85e+08\n\nIn conclusione, la vettorializzazione in R rappresenta un approccio elegante ed efficiente per gestire calcoli su vettori. Che si tratti di operazioni algebriche, operazioni tra vettori o applicazione di funzioni, la possibilità di evitare cicli espliciti migliora la leggibilità e la velocità del codice. Tuttavia, è importante prestare attenzione al riciclo dei vettori per evitare errori non intenzionali.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data Science e R: un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#gestire-dati-mancanti-na",
    "href": "chapters/R/01_r_syntax.html#gestire-dati-mancanti-na",
    "title": "7  Data Science e R: un approccio moderno all’analisi dei dati",
    "section": "\n7.12 Gestire dati mancanti (NA)",
    "text": "7.12 Gestire dati mancanti (NA)\nR rappresenta i dati mancanti con NA. La gestione dei dati mancanti dipende dalla funzione utilizzata.\nCalcolo con dati mancanti:\n\ntemp &lt;- c(7.2, NA, 7.1, 6.9, 6.5, 5.8, 5.8, 5.5, NA, 5.5)\nmean(temp)  # Restituisce NA\n#&gt; [1] NA\n\n\nmean(temp, na.rm = TRUE)  # Ignora i valori mancanti\n#&gt; [1] 6.29\n\nNota: na.rm = TRUE è un argomento comune per ignorare i NA, ma non tutte le funzioni lo supportano. Consulta la documentazione della funzione per verificare come gestisce i dati mancanti.\nIn conclusione, manipolare vettori è un’abilità essenziale in R. Dalla selezione e modifica degli elementi all’ordinamento e gestione di dati mancanti, queste tecniche sono alla base dell’analisi dei dati in R.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data Science e R: un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#i-dati-in-r",
    "href": "chapters/R/01_r_syntax.html#i-dati-in-r",
    "title": "7  Data Science e R: un approccio moderno all’analisi dei dati",
    "section": "\n7.13 I dati in R",
    "text": "7.13 I dati in R\nIn R, i dati possono essere rappresentati in diversi tipi e strutture. Comprendere come gestirli è fondamentale per manipolare, analizzare e riassumere i dataset più complessi.\n\n7.13.1 Tipi di dati in R\nR supporta diversi tipi di dati:\n\n\nNumeric: Numeri decimali (es. 2.5).\n\nInteger: Numeri interi (es. 3).\n\nLogical: Valori booleani (TRUE o FALSE) e NA per dati mancanti.\n\nCharacter: Stringhe di testo (es. \"hello\").\n\nFactor: Variabili categoriche (es. livelli come \"low\", \"medium\", \"high\").\n\nPuoi verificare il tipo di un oggetto con class() e controllare se appartiene a un tipo specifico con funzioni come is.numeric(). È anche possibile convertire un tipo in un altro con funzioni come as.character().\n\n7.13.2 Strutture di dati in R\nVettori: Contengono dati dello stesso tipo (es. numeri, stringhe o logici).\n\nmy_vec &lt;- c(1, 2, 3)\nmy_vec\n#&gt; [1] 1 2 3\n\nMatrici e array: Strutture bidimensionali (matrici) o multidimensionali (array) con dati dello stesso tipo.\nCreare una matrice:\n\nmy_mat &lt;- matrix(1:12, nrow = 3, byrow = TRUE)\nmy_mat\n#&gt;      [,1] [,2] [,3] [,4]\n#&gt; [1,]    1    2    3    4\n#&gt; [2,]    5    6    7    8\n#&gt; [3,]    9   10   11   12\n\nOperazioni utili:\n\n\nTrasposizione: t(my_mat)\n\n\nDiagonale: diag(my_mat)\n\n\nMoltiplicazione matriciale: mat1 %*% mat2\n\n\nListe: Possono contenere elementi di tipi diversi, inclusi vettori, matrici o altre liste.\n\nmy_list &lt;- list(\n  numbers = c(1, 2), \n  text = \"hello\", \n  mat = matrix(1:4, nrow = 2)\n)\nmy_list$numbers  # Accedi agli elementi con il nome\n#&gt; [1] 1 2\n\nData frame: Strutture bidimensionali che possono contenere colonne di tipi diversi. Ideale per dataset strutturati.\nCreare un data frame:\n\nheight &lt;- c(180, 155, 160)\nweight &lt;- c(65, 50, 52)\nnames &lt;- c(\"Joanna\", \"Charlotte\", \"Helen\")\n\ndataf &lt;- data.frame(height = height, weight = weight, names = names)\nstr(dataf)  # Mostra la struttura del data frame\n#&gt; 'data.frame':    3 obs. of  3 variables:\n#&gt;  $ height: num  180 155 160\n#&gt;  $ weight: num  65 50 52\n#&gt;  $ names : chr  \"Joanna\" \"Charlotte\" \"Helen\"\n\nPer convertire le stringhe in fattori durante la creazione:\n\ndataf &lt;- data.frame(\n  height = height, \n  weight = weight, \n  names = names, \n  stringsAsFactors = TRUE\n)\n\ndataf\n#&gt;   height weight     names\n#&gt; 1    180     65    Joanna\n#&gt; 2    155     50 Charlotte\n#&gt; 3    160     52     Helen\n\n\n7.13.3 Operazioni utili sui data frame\n\n\nVerificare dimensioni: dim(dataf)\n\n\nVisualizzare struttura: str(dataf)\n\n\nAccedere a colonne: dataf$height",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data Science e R: un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#operazioni-di-base-in-r",
    "href": "chapters/R/01_r_syntax.html#operazioni-di-base-in-r",
    "title": "7  Data Science e R: un approccio moderno all’analisi dei dati",
    "section": "\n7.14 Operazioni di Base in R",
    "text": "7.14 Operazioni di Base in R\n\n7.14.1 Operazioni Aritmetiche\nCome abbiamo visto in precedenza, R supporta le classiche operazioni aritmetiche come somma (+), sottrazione (-), moltiplicazione (*), divisione (/) ed esponenziazione (^).\n\n7.14.2 Operazioni Logiche\nLe operazioni logiche in R includono:\n\n\n&: “and” logico\n\n\n|: “or” logico\n\n\n!: “not” logico\n\n\n&gt;: maggiore di\n\n\n&lt;: minore di\n\n\n==: uguale a\n\n\n!=: diverso da\n\nPer esempio:\n\n# Maggiore di\n3 &gt; 2\n#&gt; [1] TRUE\n# Uguale a\n3 == 2\n#&gt; [1] FALSE\n\n\nEsempio 7.4 Consideriamo l’esempio precedente, in cui abbiamo calcolato i punteggi totali dei 10 individui sulla Satisfaction With Life Scale (SWLS). Ora vogliamo determinare la proporzione di individui nel campione che ha ottenuto un punteggio totale maggiore di 15.\nI punteggi totali dei 10 individui sono memorizzati nella colonna PunteggioTotale del data frame risultati_swls:\n\nrisultati_swls$PunteggioTotale\n#&gt;  [1] 16 16 23 25 11  7 20 25 15 27\n\nPossiamo creare un vettore logico che indica, per ciascun individuo, se il suo punteggio totale supera 15. In R, l’operatore di confronto &gt; restituisce un valore TRUE se la condizione è soddisfatta e FALSE altrimenti:\n\nrisultati_swls$PunteggioTotale &gt; 15\n#&gt;  [1]  TRUE  TRUE  TRUE  TRUE FALSE FALSE  TRUE  TRUE FALSE  TRUE\n\nIn R, i valori TRUE e FALSE possono essere trattati come numeri: TRUE equivale a 1 e FALSE equivale a 0. Questo ci permette di sommare i valori logici per contare quante volte la condizione è soddisfatta. Per calcolare la proporzione, dividiamo questa somma per il numero totale di individui:\n\nsum(risultati_swls$PunteggioTotale &gt; 15) / length(risultati_swls$PunteggioTotale)\n#&gt; [1] 0.7\n\nLa proporzione è calcolata come:\n\\[\n\\text{Proporzione} = \\frac{\\sum_{i=1}^{n} I(\\text{PunteggioTotale}_i &gt; 15)}{n} ,\n\\]\ndove:\n\n\n\\(n\\) è il numero totale di individui (in questo caso, 10),\n\n\\(I(\\text{PunteggioTotale}_i &gt; 15)\\) è una funzione indicatrice che vale 1 se il punteggio dell’individuo \\(i\\) è maggiore di 15, e 0 altrimenti.\n\nNel nostro esempio, la proporzione degli individui con punteggio totale maggiore di 15 è 0.7, cioè il 70% del campione soddisfa questa condizione.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data Science e R: un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#estrazione-di-sottoinsiemi-di-oggetti-in-r",
    "href": "chapters/R/01_r_syntax.html#estrazione-di-sottoinsiemi-di-oggetti-in-r",
    "title": "7  Data Science e R: un approccio moderno all’analisi dei dati",
    "section": "\n7.15 Estrazione di Sottoinsiemi di Oggetti in R",
    "text": "7.15 Estrazione di Sottoinsiemi di Oggetti in R\nIn R esistono tre operatori principali per estrarre sottoinsiemi di oggetti:\n\nOperatore [ ]\nQuesto operatore restituisce sempre un oggetto della stessa classe dell’originale. È utile per selezionare più elementi da un oggetto. È importante chiudere l’estrazione con ].\nOperatore [[ ]]\nQuesto operatore viene utilizzato per estrarre elementi da liste o data frame. A differenza di [ ], permette di estrarre un solo elemento alla volta e la classe dell’oggetto restituito non sarà necessariamente una lista o un data frame. L’estrazione va chiusa con ]].\nOperatore $\nCome visto in precedenza, questo operatore serve per estrarre elementi da una lista o un data frame utilizzando il loro nome letterale. Il comportamento semantico è simile a quello di [[ ]].\n\n\n7.15.1 Gli Indici di un Data Frame in R\nIn R, gli indici di un data frame sono utilizzati per selezionare righe e colonne. La sintassi generale è:\ndf[i, j]\ndove:\n\n\ni rappresenta l’indice o gli indici delle righe,\n\n\nj rappresenta l’indice o gli indici delle colonne.\n\nSe uno degli indici viene omesso, si considerano tutte le righe o tutte le colonne, a seconda della dimensione omessa.\n\n\n7.15.1.1 Esempi Pratici\n\n\nSelezione di righe specifiche su tutte le colonne\nSe vogliamo estrarre solo alcune righe, possiamo specificare gli indici delle righe nel primo argomento e lasciare vuoto il secondo. Ad esempio:\ndf[c(2, 3, 5), ]\nQuesto seleziona la seconda, terza e quinta riga del data frame df, includendo tutte le colonne.\n\n\nSelezione di colonne specifiche su tutte le righe\nPer selezionare solo alcune colonne, specifichiamo i loro indici nel secondo argomento e lasciamo vuoto il primo. Ad esempio:\ndf[, c(2, 3, 5)]\nQuesto seleziona la seconda, terza e quinta colonna del data frame df, includendo tutte le righe.\n\n\nSelezione di righe e colonne specifiche\nPossiamo combinare gli indici per selezionare una sotto-matrice specifica. Ad esempio:\ndf[c(2, 4), c(1, 3)]\nQuesto seleziona le righe 2 e 4 e le colonne 1 e 3.\n\n\n\n7.15.1.2 Ulteriori Dettagli\n\nSelezione singola di riga o colonna\nSe vogliamo estrarre una singola riga o colonna, possiamo specificare un solo valore per i o j. Ad esempio:r  df[1, ]  # Prima riga, tutte le colonne  df[, 2]  # Seconda colonna, tutte le righe\nUso di nomi invece di indici\nSe il data frame ha nomi per righe o colonne, possiamo utilizzarli per la selezione. Ad esempio:r  df[\"nome_riga\", ]        # Seleziona la riga con nome \"nome_riga\"  df[, \"nome_colonna\"]     # Seleziona la colonna con nome \"nome_colonna\"\nSelezione logica\nPossiamo utilizzare un vettore logico per selezionare righe o colonne. Ad esempio, per selezionare le righe dove il valore nella prima colonna è maggiore di 10:r  df[df[, 1] &gt; 10, ]\n\n\n7.15.1.3 Sintesi Visiva\n\n\n\n\n\n\nSintassi\nDescrizione\n\n\n\ndf[i, ]\nSeleziona la riga i con tutte le colonne.\n\n\ndf[, j]\nSeleziona la colonna j con tutte le righe.\n\n\ndf[c(i1, i2), c(j1, j2)]\nSeleziona righe e colonne specifiche.\n\n\ndf[i, j]\nSeleziona l’intersezione di righe e colonne.\n\n\ndf[ , ]\nRestituisce l’intero data frame.\n\n\n\nQuesta flessibilità rende l’indicizzazione dei data frame in R potente ed efficace per manipolare e analizzare i dati.\n\nEsempio 7.5 Consideriamo il data frame iris incluso di default in base R.\n\niris |&gt; head()\n#&gt;   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n#&gt; 1          5.1         3.5          1.4         0.2  setosa\n#&gt; 2          4.9         3.0          1.4         0.2  setosa\n#&gt; 3          4.7         3.2          1.3         0.2  setosa\n#&gt; 4          4.6         3.1          1.5         0.2  setosa\n#&gt; 5          5.0         3.6          1.4         0.2  setosa\n#&gt; 6          5.4         3.9          1.7         0.4  setosa\n\nUsiamo la funzione head() per stampare le prime 6 righe del data frame.\nL’istruzione seguente restituisce le prime tre colonne del dataset iris.\n\niris[, 1:3] |&gt; head()\n#&gt;   Sepal.Length Sepal.Width Petal.Length\n#&gt; 1          5.1         3.5          1.4\n#&gt; 2          4.9         3.0          1.4\n#&gt; 3          4.7         3.2          1.3\n#&gt; 4          4.6         3.1          1.5\n#&gt; 5          5.0         3.6          1.4\n#&gt; 6          5.4         3.9          1.7\n\nSelezione di colonne specifiche per nome:\n\niris[, c('Sepal.Length', 'Petal.Length')] |&gt; \n  head()  \n#&gt;   Sepal.Length Petal.Length\n#&gt; 1          5.1          1.4\n#&gt; 2          4.9          1.4\n#&gt; 3          4.7          1.3\n#&gt; 4          4.6          1.5\n#&gt; 5          5.0          1.4\n#&gt; 6          5.4          1.7\n\nSelezione di una singola colonna:\n\niris[, 'Petal.Length'] \n#&gt;   [1] 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 1.5 1.6 1.4 1.1 1.2 1.5 1.3\n#&gt;  [18] 1.4 1.7 1.5 1.7 1.5 1.0 1.7 1.9 1.6 1.6 1.5 1.4 1.6 1.6 1.5 1.5 1.4\n#&gt;  [35] 1.5 1.2 1.3 1.4 1.3 1.5 1.3 1.3 1.3 1.6 1.9 1.4 1.6 1.4 1.5 1.4 4.7\n#&gt;  [52] 4.5 4.9 4.0 4.6 4.5 4.7 3.3 4.6 3.9 3.5 4.2 4.0 4.7 3.6 4.4 4.5 4.1\n#&gt;  [69] 4.5 3.9 4.8 4.0 4.9 4.7 4.3 4.4 4.8 5.0 4.5 3.5 3.8 3.7 3.9 5.1 4.5\n#&gt;  [86] 4.5 4.7 4.4 4.1 4.0 4.4 4.6 4.0 3.3 4.2 4.2 4.2 4.3 3.0 4.1 6.0 5.1\n#&gt; [103] 5.9 5.6 5.8 6.6 4.5 6.3 5.8 6.1 5.1 5.3 5.5 5.0 5.1 5.3 5.5 6.7 6.9\n#&gt; [120] 5.0 5.7 4.9 6.7 4.9 5.7 6.0 4.8 4.9 5.6 5.8 6.1 6.4 5.6 5.1 5.6 6.1\n#&gt; [137] 5.6 5.5 4.8 5.4 5.6 5.1 5.1 5.9 5.7 5.2 5.0 5.2 5.4 5.1\n\noppure\n\niris$Petal.Length\n#&gt;   [1] 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 1.5 1.6 1.4 1.1 1.2 1.5 1.3\n#&gt;  [18] 1.4 1.7 1.5 1.7 1.5 1.0 1.7 1.9 1.6 1.6 1.5 1.4 1.6 1.6 1.5 1.5 1.4\n#&gt;  [35] 1.5 1.2 1.3 1.4 1.3 1.5 1.3 1.3 1.3 1.6 1.9 1.4 1.6 1.4 1.5 1.4 4.7\n#&gt;  [52] 4.5 4.9 4.0 4.6 4.5 4.7 3.3 4.6 3.9 3.5 4.2 4.0 4.7 3.6 4.4 4.5 4.1\n#&gt;  [69] 4.5 3.9 4.8 4.0 4.9 4.7 4.3 4.4 4.8 5.0 4.5 3.5 3.8 3.7 3.9 5.1 4.5\n#&gt;  [86] 4.5 4.7 4.4 4.1 4.0 4.4 4.6 4.0 3.3 4.2 4.2 4.2 4.3 3.0 4.1 6.0 5.1\n#&gt; [103] 5.9 5.6 5.8 6.6 4.5 6.3 5.8 6.1 5.1 5.3 5.5 5.0 5.1 5.3 5.5 6.7 6.9\n#&gt; [120] 5.0 5.7 4.9 6.7 4.9 5.7 6.0 4.8 4.9 5.6 5.8 6.1 6.4 5.6 5.1 5.6 6.1\n#&gt; [137] 5.6 5.5 4.8 5.4 5.6 5.1 5.1 5.9 5.7 5.2 5.0 5.2 5.4 5.1\n\nPer selezionare righe specifiche, definiamo gli indici corrispondenti. Per esempio, l’istruzione seguente restituisce le righe 1 e 3.\n\niris[c(1, 3), ]\n#&gt;   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n#&gt; 1          5.1         3.5          1.4         0.2  setosa\n#&gt; 3          4.7         3.2          1.3         0.2  setosa\n\nFiltraggio logico di righe:\n\niris[iris$Species == 'versicolor', ] |&gt; head()\n#&gt;    Sepal.Length Sepal.Width Petal.Length Petal.Width    Species\n#&gt; 51          7.0         3.2          4.7         1.4 versicolor\n#&gt; 52          6.4         3.2          4.5         1.5 versicolor\n#&gt; 53          6.9         3.1          4.9         1.5 versicolor\n#&gt; 54          5.5         2.3          4.0         1.3 versicolor\n#&gt; 55          6.5         2.8          4.6         1.5 versicolor\n#&gt; 56          5.7         2.8          4.5         1.3 versicolor\n\nRestituisce le righe con Species uguale a “versicolor”. Numero di righe e colonne del sottoinsieme:\n\ndim(iris[iris$Species == 'versicolor', ])\n#&gt; [1] 50  5\n\n\n\n7.15.2 Filtraggio Avanzato con Operatori Logici\nGli operatori logici & (AND), | (OR) e ! (NOT) permettono un filtraggio più sofisticato.\nEsempio: Filtrare le osservazioni di specie “versicolor” con lunghezza del sepalo non superiore a 5.0:\n\niris[(iris$Species == 'versicolor') & (iris$Sepal.Length &lt;= 5.0), ]\n#&gt;    Sepal.Length Sepal.Width Petal.Length Petal.Width    Species\n#&gt; 58          4.9         2.4          3.3           1 versicolor\n#&gt; 61          5.0         2.0          3.5           1 versicolor\n#&gt; 94          5.0         2.3          3.3           1 versicolor\n\nNumero di osservazioni trovate:\n\ndim(iris[(iris$Species == 'versicolor') & (iris$Sepal.Length &lt;= 5.0), ])\n#&gt; [1] 3 5",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data Science e R: un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#riflessioni-conclusive",
    "href": "chapters/R/01_r_syntax.html#riflessioni-conclusive",
    "title": "7  Data Science e R: un approccio moderno all’analisi dei dati",
    "section": "\n7.16 Riflessioni Conclusive",
    "text": "7.16 Riflessioni Conclusive\nR non è soltanto un linguaggio di programmazione per la statistica, ma rappresenta una filosofia che si fonda su tre principi chiave: apertura, collaborazione e avanzamento della conoscenza scientifica.\nPer chi si avvicina a R, sia nel campo della comunicazione sia in altri ambiti, cogliere questa filosofia è essenziale per apprezzarne appieno il valore. R promuove non solo competenze tecniche, ma anche un impegno verso pratiche di ricerca trasparente e riproducibile, che costituiscono un pilastro fondamentale per una scienza rigorosa e affidabile.\nOpen Source\nR è un software open source, liberamente accessibile a tutti. Questo significa che chiunque può visualizzarne, modificarne e distribuirne il codice sorgente, promuovendo un ambiente trasparente e collaborativo. Essendo gratuito, R garantisce accessibilità a ricercatori di tutto il mondo, indipendentemente dal budget o dal supporto istituzionale. Inoltre, grazie alla sua natura aperta, R beneficia del contributo collettivo di una comunità globale eterogenea.\nContributi della Comunità\nLa comunità di R è uno dei suoi punti di forza principali. Statistici, ricercatori e data scientist di diverse discipline arricchiscono continuamente R sviluppando pacchetti: raccolte di funzioni, dati e codice che ampliano le sue funzionalità. Questa collaborazione ha portato alla creazione di migliaia di pacchetti che coprono tecniche statistiche, metodi grafici e strumenti per la manipolazione dei dati, rendendo R uno strumento sempre più versatile e adatto a un’ampia gamma di esigenze di ricerca.\nRicerca Riproducibile\nLa ricerca riproducibile consiste nel condurre studi in modo tale che altri possano replicarne i risultati utilizzando gli stessi dati e seguendo la stessa metodologia. Questo approccio è cruciale per la validazione delle scoperte scientifiche, permettendo la verifica dei risultati e la costruzione di nuove conoscenze su basi solide.\nR facilita la ricerca riproducibile grazie a:\n\nUn ecosistema completo di pacchetti per l’analisi dei dati e la generazione di report dinamici.\n\nStrumenti come R Markdown e Quarto, che permettono di integrare testo descrittivo e codice R in un unico documento. Questa integrazione consente di documentare ogni fase del processo di ricerca—dalla pulizia dei dati all’analisi e alla presentazione dei risultati—garantendo trasparenza e replicabilità.\n\nIn conclusione, comprendere la filosofia open source di R e il suo ruolo nella promozione della ricerca riproducibile fornisce un quadro chiaro del motivo per cui R è diventato uno strumento essenziale per ricercatori e statistici di diverse discipline. Per chi opera in psicologia, sfruttare le potenzialità di R significa produrre risultati di ricerca più trasparenti, replicabili e credibili, contribuendo alla robustezza e affidabilità della conoscenza scientifica nel settore.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data Science e R: un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/R/01_r_syntax.html#informazioni-sullambiente-di-sviluppo",
    "title": "7  Data Science e R: un approccio moderno all’analisi dei dati",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] see_0.9.0        gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1\n#&gt;  [5] psych_2.4.12     scales_1.3.0     markdown_1.13    knitr_1.49      \n#&gt;  [9] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [13] purrr_1.0.2      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [17] ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.3         rlang_1.1.4       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       yaml_2.3.10       tools_4.4.2       parallel_4.4.2   \n#&gt; [21] tzdb_0.4.0        colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5      \n#&gt; [25] R6_2.5.1          lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3  \n#&gt; [29] pillar_1.10.0     gtable_0.3.6      glue_1.8.0        xfun_0.49        \n#&gt; [33] tidyselect_1.2.1  farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-166     \n#&gt; [37] rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data Science e R: un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#bibliografia",
    "href": "chapters/R/01_r_syntax.html#bibliografia",
    "title": "7  Data Science e R: un approccio moderno all’analisi dei dati",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nIrizarry, R. A. (2024). Introduction to Data Science: Data Wrangling and Visualization with R. CRC Press.\n\n\nObels, P., Lakens, D., Coles, N. A., Gottfried, J., & Green, S. A. (2020). Analysis of open data and computational reproducibility in registered reports in psychology. Advances in Methods and Practices in Psychological Science, 3(2), 229–237.\n\n\nOkoye, K., & Hosseini, S. (2024). Introduction to R Programming and RStudio Integrated Development Environment (IDE). In R Programming: Statistical Data Analysis in Research (pp. 3–24). Springer.\n\n\nWickham, H., Çetinkaya-Rundel, M., & Grolemund, G. (2023). R for data science. \" O’Reilly Media, Inc.\".",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data Science e R: un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/02_utility_functions.html",
    "href": "chapters/R/02_utility_functions.html",
    "title": "8  Utility functions in R",
    "section": "",
    "text": "8.1 Introduzione\nIn questo capitolo esamineremo le principali funzioni di utilità di R per raccogliere statistiche descrittive e altre informazioni generali sui data frame.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Utility functions in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/02_utility_functions.html#introduzione",
    "href": "chapters/R/02_utility_functions.html#introduzione",
    "title": "8  Utility functions in R",
    "section": "",
    "text": "8.1.1 Funzioni principali e loro utilizzo\n\n\n\n\n\n\nFunzione\nDescrizione\n\n\n\nsummary()\nRestituisce statistiche descrittive di base per ogni colonna di un data frame. Per le colonne numeriche, calcola valori come il minimo, massimo, media, mediana, primo e terzo quartile, e il numero di valori mancanti (se presenti). Per le colonne non numeriche, restituisce il tipo di dati (carattere, logico) e il conteggio delle categorie. Esempio: summary(iris) restituisce una sintesi delle colonne del dataset iris.\n\n\n\nstr() e glimpse()\n\nForniscono una rappresentazione sintetica delle informazioni di un data frame, come dimensione, nomi delle colonne, tipi di dati e valori iniziali. La funzione str() fa parte della configurazione base di R (pacchetto utils), mentre glimpse() è inclusa in dplyr (pacchetto tidyverse). Esempio: str(mtcars) o glimpse(mtcars).\n\n\n\nhead() e tail()\n\nPermettono di visualizzare rispettivamente le prime o ultime righe di un data frame. Utile per una rapida ispezione del contenuto. Si può specificare il numero di righe da mostrare (es. head(df, 10)), altrimenti il valore predefinito è sei righe. Esempio: head(iris) per vedere le prime righe del dataset iris.\n\n\n\nView() e view()\n\nVisualizzano un data frame in una finestra grafica tipo foglio di calcolo all’interno di RStudio. La funzione View() è parte della configurazione base di R, mentre view() è un alias fornito da tibble (pacchetto tidyverse). Utile per piccoli data frame, ma poco pratico per dataset di grandi dimensioni. Esempio: View(iris) apre il dataset iris nel visualizzatore di RStudio.\n\n\nunique()\nRestituisce i valori unici presenti in una colonna o in un vettore. Esempio: unique(iris$Species) restituisce le specie uniche nel dataset iris.\n\n\nnames()\nRestituisce i nomi delle colonne di un data frame. Esempio: names(mtcars) restituisce i nomi delle colonne del dataset mtcars.\n\n\nclass()\nIndica il tipo di dato di un oggetto in R, come numeric, character, logical, o data.frame. Esempio: class(iris) restituisce data.frame.\n\n\nlength()\nRestituisce il numero di elementi di un oggetto. Per i data frame, restituisce il numero di colonne. Esempio: length(iris) restituisce 5 (colonne).\n\n\n\nnrow() e ncol()\n\nRestituiscono rispettivamente il numero di righe e colonne di un data frame. Esempio: nrow(iris) restituisce 150 (righe), mentre ncol(iris) restituisce 5 (colonne).\n\n\n\nQuesti strumenti rappresentano la base per esplorare rapidamente i dati e comprenderne la struttura prima di passare a manipolazioni più avanzate.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Utility functions in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/02_utility_functions.html#un-esempio-concreto",
    "href": "chapters/R/02_utility_functions.html#un-esempio-concreto",
    "title": "8  Utility functions in R",
    "section": "\n8.2 Un Esempio Concreto",
    "text": "8.2 Un Esempio Concreto\nImportiamo il dataset msleep contenuto nel pacchetto ggplot2 che abbiamo caricato in precedenza:\n\ndata(msleep)\n\nEsaminiamo la struttura del data frame usando str():\n\nstr(msleep)\n#&gt; tibble [83 × 11] (S3: tbl_df/tbl/data.frame)\n#&gt;  $ name        : chr [1:83] \"Cheetah\" \"Owl monkey\" \"Mountain beaver\" \"Greater short-tailed shrew\" ...\n#&gt;  $ genus       : chr [1:83] \"Acinonyx\" \"Aotus\" \"Aplodontia\" \"Blarina\" ...\n#&gt;  $ vore        : chr [1:83] \"carni\" \"omni\" \"herbi\" \"omni\" ...\n#&gt;  $ order       : chr [1:83] \"Carnivora\" \"Primates\" \"Rodentia\" \"Soricomorpha\" ...\n#&gt;  $ conservation: chr [1:83] \"lc\" NA \"nt\" \"lc\" ...\n#&gt;  $ sleep_total : num [1:83] 12.1 17 14.4 14.9 4 14.4 8.7 7 10.1 3 ...\n#&gt;  $ sleep_rem   : num [1:83] NA 1.8 2.4 2.3 0.7 2.2 1.4 NA 2.9 NA ...\n#&gt;  $ sleep_cycle : num [1:83] NA NA NA 0.133 0.667 ...\n#&gt;  $ awake       : num [1:83] 11.9 7 9.6 9.1 20 9.6 15.3 17 13.9 21 ...\n#&gt;  $ brainwt     : num [1:83] NA 0.0155 NA 0.00029 0.423 NA NA NA 0.07 0.0982 ...\n#&gt;  $ bodywt      : num [1:83] 50 0.48 1.35 0.019 600 ...\n\noppure usando glimpse():\n\nglimpse(msleep)\n#&gt; Rows: 83\n#&gt; Columns: 11\n#&gt; $ name         &lt;chr&gt; \"Cheetah\", \"Owl monkey\", \"Mountain beaver\", \"Greater …\n#&gt; $ genus        &lt;chr&gt; \"Acinonyx\", \"Aotus\", \"Aplodontia\", \"Blarina\", \"Bos\", …\n#&gt; $ vore         &lt;chr&gt; \"carni\", \"omni\", \"herbi\", \"omni\", \"herbi\", \"herbi\", \"…\n#&gt; $ order        &lt;chr&gt; \"Carnivora\", \"Primates\", \"Rodentia\", \"Soricomorpha\", …\n#&gt; $ conservation &lt;chr&gt; \"lc\", NA, \"nt\", \"lc\", \"domesticated\", NA, \"vu\", NA, \"…\n#&gt; $ sleep_total  &lt;dbl&gt; 12.1, 17.0, 14.4, 14.9, 4.0, 14.4, 8.7, 7.0, 10.1, 3.…\n#&gt; $ sleep_rem    &lt;dbl&gt; NA, 1.8, 2.4, 2.3, 0.7, 2.2, 1.4, NA, 2.9, NA, 0.6, 0…\n#&gt; $ sleep_cycle  &lt;dbl&gt; NA, NA, NA, 0.133, 0.667, 0.767, 0.383, NA, 0.333, NA…\n#&gt; $ awake        &lt;dbl&gt; 11.9, 7.0, 9.6, 9.1, 20.0, 9.6, 15.3, 17.0, 13.9, 21.…\n#&gt; $ brainwt      &lt;dbl&gt; NA, 0.01550, NA, 0.00029, 0.42300, NA, NA, NA, 0.0700…\n#&gt; $ bodywt       &lt;dbl&gt; 50.000, 0.480, 1.350, 0.019, 600.000, 3.850, 20.490, …\n\nStampiamo le prime righe del data frame:\n\nhead(msleep)\n#&gt; # A tibble: 6 × 11\n#&gt;   name                genus      vore  order        conservation sleep_total\n#&gt;   &lt;chr&gt;               &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;        &lt;chr&gt;              &lt;dbl&gt;\n#&gt; 1 Cheetah             Acinonyx   carni Carnivora    lc                  12.1\n#&gt; 2 Owl monkey          Aotus      omni  Primates     &lt;NA&gt;                17  \n#&gt; 3 Mountain beaver     Aplodontia herbi Rodentia     nt                  14.4\n#&gt; 4 Greater short-tail… Blarina    omni  Soricomorpha lc                  14.9\n#&gt; 5 Cow                 Bos        herbi Artiodactyla domesticated         4  \n#&gt; 6 Three-toed sloth    Bradypus   herbi Pilosa       &lt;NA&gt;                14.4\n#&gt; # ℹ 5 more variables: sleep_rem &lt;dbl&gt;, sleep_cycle &lt;dbl&gt;, awake &lt;dbl&gt;,\n#&gt; #   brainwt &lt;dbl&gt;, bodywt &lt;dbl&gt;\n\noppure le ultime righe:\n\ntail(msleep)\n#&gt; # A tibble: 6 × 11\n#&gt;   name                 genus    vore  order        conservation sleep_total\n#&gt;   &lt;chr&gt;                &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt;        &lt;chr&gt;              &lt;dbl&gt;\n#&gt; 1 Tenrec               Tenrec   omni  Afrosoricida &lt;NA&gt;                15.6\n#&gt; 2 Tree shrew           Tupaia   omni  Scandentia   &lt;NA&gt;                 8.9\n#&gt; 3 Bottle-nosed dolphin Tursiops carni Cetacea      &lt;NA&gt;                 5.2\n#&gt; 4 Genet                Genetta  carni Carnivora    &lt;NA&gt;                 6.3\n#&gt; 5 Arctic fox           Vulpes   carni Carnivora    &lt;NA&gt;                12.5\n#&gt; 6 Red fox              Vulpes   carni Carnivora    &lt;NA&gt;                 9.8\n#&gt; # ℹ 5 more variables: sleep_rem &lt;dbl&gt;, sleep_cycle &lt;dbl&gt;, awake &lt;dbl&gt;,\n#&gt; #   brainwt &lt;dbl&gt;, bodywt &lt;dbl&gt;\n\nEsaminiamo le modalità della variabile qualitativa vore:\n\nunique(msleep$vore)\n#&gt; [1] \"carni\"   \"omni\"    \"herbi\"   NA        \"insecti\"\n\nSe vogliamo la numerosità di ciascuna categoria, possiamo usare table():\n\ntable(msleep$vore)\n#&gt; \n#&gt;   carni   herbi insecti    omni \n#&gt;      19      32       5      20\n\nSi noti che table() esclude i dati mancanti.\nStampiamo i nomi delle colonne del data frame:\n\nnames(msleep)\n#&gt;  [1] \"name\"         \"genus\"        \"vore\"         \"order\"       \n#&gt;  [5] \"conservation\" \"sleep_total\"  \"sleep_rem\"    \"sleep_cycle\" \n#&gt;  [9] \"awake\"        \"brainwt\"      \"bodywt\"\n\nEsaminiamo il tipo di variabile della colonna vore:\n\nclass(msleep$vore)\n#&gt; [1] \"character\"\n\nLe dimensioni del data frame sono date da:\n\ndim(msleep)\n#&gt; [1] 83 11\n\nladdove il primo valore è il numero di righe e il secondo valore è il numero di colonne.\nIl numero di elementi di un vettore è dato da:\n\nlength(msleep$vore)\n#&gt; [1] 83\n\nIn alternativa, possiamo usare nrow()\n\nnrow(msleep)\n#&gt; [1] 83\n\nper il numero di righe e ncol()\n\nncol(msleep)\n#&gt; [1] 11\n\nper il numero di colonne. In maniera equivalente:\n\ndim(msleep)[2]\n#&gt; [1] 11\n\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] see_0.9.0        gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1\n#&gt;  [5] psych_2.4.12     scales_1.3.0     markdown_1.13    knitr_1.49      \n#&gt;  [9] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [13] purrr_1.0.2      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [17] ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] utf8_1.2.4        generics_0.1.3    stringi_1.8.4     lattice_0.22-6   \n#&gt;  [5] hms_1.1.3         digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1   \n#&gt;  [9] grid_4.4.2        timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4  \n#&gt; [13] jsonlite_1.8.9    mnormt_2.1.1      cli_3.6.3         rlang_1.1.4      \n#&gt; [17] munsell_0.5.1     withr_3.0.2       tools_4.4.2       parallel_4.4.2   \n#&gt; [21] tzdb_0.4.0        colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5      \n#&gt; [25] R6_2.5.1          lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3  \n#&gt; [29] pillar_1.10.0     gtable_0.3.6      glue_1.8.0        xfun_0.49        \n#&gt; [33] tidyselect_1.2.1  farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-166     \n#&gt; [37] rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Utility functions in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/02_utility_functions.html#bibliografia",
    "href": "chapters/R/02_utility_functions.html#bibliografia",
    "title": "8  Utility functions in R",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nIrizarry, R. A. (2024). Introduction to Data Science: Data Wrangling and Visualization with R. CRC Press.\n\n\nWickham, H., Çetinkaya-Rundel, M., & Grolemund, G. (2023). R for data science. \" O’Reilly Media, Inc.\".",
    "crumbs": [
      "R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Utility functions in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_programming.html",
    "href": "chapters/R/03_r_programming.html",
    "title": "9  Programmazione in R",
    "section": "",
    "text": "9.1 Introduzione\nIn questo capitolo esploreremo tre strumenti fondamentali per la scrittura di codice in R: le funzioni, le istruzioni condizionali e i cicli. Questi elementi costituiscono la base per sviluppare script flessibili, efficienti e riutilizzabili, essenziali per ogni programmatore o analista che utilizza R.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_programming.html#funzioni",
    "href": "chapters/R/03_r_programming.html#funzioni",
    "title": "9  Programmazione in R",
    "section": "\n9.2 Funzioni",
    "text": "9.2 Funzioni\nR offre un’ampia gamma di funzioni integrate per supportare l’analisi statistica, la manipolazione dei dati e la visualizzazione grafica, rendendolo uno strumento estremamente versatile per diverse esigenze.\nEsempi di funzioni comuni includono:\n\n# Sommare numeri\nsum(1, 2, 3)  # Restituisce la somma dei numeri\n#&gt; [1] 6\n\n\n# Creare un grafico semplice\nplot(1:10, 1:10)  # Crea un grafico a dispersione dei valori\n\n\n\n\n\n\n\nIn sostanza, una funzione è un blocco di codice progettato per svolgere un’operazione specifica. Puoi pensare a una funzione come a una “black box”: fornisci un input (i dati), la funzione elabora l’informazione attraverso le sue istruzioni e restituisce un output (il risultato). Questo approccio modulare semplifica il lavoro, permettendo di riutilizzare e combinare facilmente diverse operazioni.\n\n9.2.1 Creare Funzioni Personalizzate\nLa creazione di funzioni personalizzate in R è uno strumento essenziale per migliorare la programmazione, soprattutto per gestire operazioni ripetitive o complesse. Le funzioni consentono di rendere il codice più leggibile, efficiente e riutilizzabile, promuovendo un approccio organizzato e chiaro alla risoluzione dei problemi.\n\n9.2.1.1 Vantaggi delle Funzioni Personalizzate\nL’uso di funzioni personalizzate offre numerosi benefici:\n\n\nChiarezza e leggibilità: Un nome descrittivo permette di comprendere immediatamente lo scopo della funzione, anche a distanza di tempo o per altri utenti che leggono il codice.\n\n\nManutenzione semplificata: Modificare il codice all’interno di una funzione aggiorna automaticamente tutte le sue occorrenze, riducendo il rischio di errori e semplificando il debugging.\n\n\nRiduzione degli errori: Si evitano gli errori tipici del copia-e-incolla, come omissioni o incoerenze nei programmi complessi.\n\n\nRiutilizzabilità: Una funzione ben progettata può essere utilizzata in più contesti o progetti, risparmiando tempo e sforzi.\n\n9.2.1.2 Quando Creare una Funzione?\nUn buon criterio per decidere se creare una funzione è osservare se il medesimo blocco di codice viene copiato più volte. Se ti trovi a ripetere lo stesso codice più di due volte, probabilmente è il momento di creare una funzione. Questo aiuta a scrivere codice più pulito, scalabile e professionale, migliorando anche la sostenibilità del lavoro a lungo termine.\n\n9.2.2 Sintassi di una Funzione\nLa struttura base di una funzione in R è la seguente:\nnome_funzione &lt;- function(argomenti) {\n  # Corpo della funzione\n  codice\n  return(risultato)  # Facoltativo: restituisce il valore calcolato\n}\n\n\nnome_funzione: Nome della funzione, scelto per descrivere chiaramente la sua finalità.\n\n\nargomenti: Parametri necessari per eseguire le operazioni all’interno della funzione.\n\n\ncodice: Le istruzioni che definiscono il comportamento della funzione.\n\n\nrisultato: Il valore restituito dalla funzione. Se non si usa return(), R restituisce l’ultimo valore calcolato.\n\n\nEsempio 9.1 Immaginiamo di voler creare una funzione per sommare due numeri.\nsomma_due &lt;- function(a, b) {\n  a + b  # Restituisce la somma dei due numeri\n}\nPer utilizzarla, basta richiamarla specificando i parametri:\nsomma_due(5, 3)  # Restituisce 8\nQuesto approccio aiuta a scrivere codice più leggibile e facile da gestire. Ad esempio, se in futuro volessi modificare il comportamento della somma (ad esempio, aggiungere un messaggio di log), basterà intervenire solo all’interno della funzione.\n\n\nEsempio 9.2 Immaginiamo di avere un dataset con i punteggi di 10 individui su 3 subscale di un test psicometrico. L’obiettivo è:\n\nCreare una funzione per calcolare il punteggio totale di un individuo.\nCreare una funzione per trovare il massimo punteggio totale nel campione.\nCreare una funzione per individuare chi ha ottenuto il massimo punteggio.\n\nPasso 1: Simulazione dei Dati. Simuliamo i punteggi di 10 individui su 3 subscale:\n\n# Simulazione dei punteggi\nset.seed(123)\npunteggi &lt;- data.frame(\n  individuo = paste(\"Individuo\", 1:10),\n  subscale1 = sample(30:50, 10, replace = TRUE),\n  subscale2 = sample(40:60, 10, replace = TRUE),\n  subscale3 = sample(35:55, 10, replace = TRUE)\n)\nprint(punteggi)\n#&gt;       individuo subscale1 subscale2 subscale3\n#&gt; 1   Individuo 1        44        44        48\n#&gt; 2   Individuo 2        48        58        51\n#&gt; 3   Individuo 3        43        48        45\n#&gt; 4   Individuo 4        32        42        41\n#&gt; 5   Individuo 5        39        47        55\n#&gt; 6   Individuo 6        47        46        46\n#&gt; 7   Individuo 7        40        49        49\n#&gt; 8   Individuo 8        34        48        44\n#&gt; 9   Individuo 9        49        58        47\n#&gt; 10 Individuo 10        43        43        41\n\nLa funzione sample() in R è utilizzata per estrarre casualmente un sottoinsieme di valori da un vettore. Nell’esempio sopra, sample() viene utilizzata per generare casualmente i punteggi delle subscale dei test psicometrici.\nNell’istruzione subscale1 &lt;- sample(30:50, 10, replace = TRUE)\n\n\n30:50: Rappresenta il vettore di numeri interi da cui vengono estratti i punteggi (valori possibili tra 30 e 50).\n\n10: Indica che vogliamo estrarre 10 valori.\n\nreplace = TRUE: Consente che lo stesso valore possa essere estratto più volte (estrazione con ripetizione).\n\nPasso 2: Creazione delle Funzioni.\n\n\nCalcolo del punteggio totale per ogni individuo\nQuesta funzione somma i punteggi delle subscale di un individuo:\n\ncalcola_totale &lt;- function(subscale1, subscale2, subscale3) {\n  return(subscale1 + subscale2 + subscale3)\n}\n\n\n\nTrovare il punteggio massimo nel campione\nQuesta funzione accetta un vettore di punteggi totali e restituisce il valore massimo:\n\ntrova_massimo &lt;- function(punteggi_totali) {\n  return(max(punteggi_totali))\n}\n\n\n\nIndividuare l’individuo con il punteggio massimo\nQuesta funzione accetta un data frame con i punteggi e restituisce il nome dell’individuo con il punteggio più alto:\n\ntrova_individuo_massimo &lt;- function(punteggi) {\n  punteggi_totali &lt;- rowSums(punteggi[, c(\"subscale1\", \"subscale2\", \"subscale3\")])\n  indice_massimo &lt;- which.max(punteggi_totali)\n  return(punteggi$individuo[indice_massimo])\n}\n\nLa funzione which.max() restituisce l’indice della posizione in cui si trova il valore massimo in un vettore.\n\n\nPasso 3: Applicazione delle Funzioni\n\n\nCalcolo dei punteggi totali per ogni individuo\nApplichiamo la funzione ai dati simulati:\n\npunteggi$punteggio_totale &lt;- with(\n  punteggi, calcola_totale(subscale1, subscale2, subscale3)\n )\nprint(punteggi)\n#&gt;       individuo subscale1 subscale2 subscale3 punteggio_totale\n#&gt; 1   Individuo 1        44        44        48              136\n#&gt; 2   Individuo 2        48        58        51              157\n#&gt; 3   Individuo 3        43        48        45              136\n#&gt; 4   Individuo 4        32        42        41              115\n#&gt; 5   Individuo 5        39        47        55              141\n#&gt; 6   Individuo 6        47        46        46              139\n#&gt; 7   Individuo 7        40        49        49              138\n#&gt; 8   Individuo 8        34        48        44              126\n#&gt; 9   Individuo 9        49        58        47              154\n#&gt; 10 Individuo 10        43        43        41              127\n\n\n\nTroviamo il punteggio massimo nel campione\n\nmassimo &lt;- trova_massimo(punteggi$punteggio_totale)\nprint(massimo)\n#&gt; [1] 157\n\n\n\nTroviamo chi ha il punteggio massimo\n\nindividuo_massimo &lt;- trova_individuo_massimo(punteggi)\nprint(individuo_massimo)\n#&gt; [1] \"Individuo 2\"\n\n\n\n\n\n9.2.3 Stile\nÈ consigliato di usare nomi di funzioni chiari e descrittivi, preferibilmente verbi (es. compute_mean()). Inoltre, è importante mantenere una struttura leggibile, con spazi coerenti e indentazione.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_programming.html#istruzioni-condizionali-in-r",
    "href": "chapters/R/03_r_programming.html#istruzioni-condizionali-in-r",
    "title": "9  Programmazione in R",
    "section": "\n9.3 Istruzioni Condizionali in R",
    "text": "9.3 Istruzioni Condizionali in R\nLe istruzioni condizionali permettono di introdurre logica nel tuo codice. Ad esempio, l’operazione x * y si limita a moltiplicare i valori di x e y, senza alcuna logica aggiunta. Con le istruzioni condizionali, puoi dire al programma di eseguire diverse operazioni a seconda che una condizione sia vera (TRUE) o falsa (FALSE).\nL’istruzione condizionale più comune in R è if. Può essere letta come: “Se la condizione è vera, esegui un’azione”. Con else, si estende la logica: “Se la condizione è vera, fai qualcosa; altrimenti fai qualcos’altro”.\nLa struttura generale è questa:\nif (condizione) {\n  # Codice eseguito se la condizione è TRUE\n} else {\n  # Codice eseguito se la condizione è FALSE\n}\nImmagina questa situazione:\n\n“Se un partecipante al test psicologico riporta un punteggio elevato sulla scala di ansia (es. &gt; 15), consigliagli un esercizio di rilassamento. Altrimenti, non è necessario.”\n\nVediamo come rappresentare questa situazione in R.\n\nanxiety_score &lt;- 18 # Punteggio riportato dal partecipante\n\nif (anxiety_score &gt; 15) {\n    exercise &lt;- \"rilassamento\"\n} else {\n    exercise &lt;- \"nessun esercizio\"\n}\n\nexercise\n#&gt; [1] \"rilassamento\"\n\nSe il punteggio è maggiore di 15, il risultato sarà:\n[1] \"rilassamento\"\nSe il punteggio è inferiore o uguale a 15, il risultato sarà:\n[1] \"nessun esercizio\"\n\n9.3.1 Uso di ifelse()\n\nUn’alternativa più compatta a if e else è la funzione ifelse(), utile soprattutto per vettori. Ad esempio, supponiamo di avere i punteggi di ansia di un gruppo di partecipanti e vogliamo decidere se assegnare un esercizio di rilassamento a ciascuno:\n\nanxiety_scores &lt;- c(12, 18, 9, 22, 15)\nexercises &lt;- ifelse(anxiety_scores &gt; 15, \"rilassamento\", \"nessun esercizio\")\n\nIl risultato sarà:\n\nexercises\n#&gt; [1] \"nessun esercizio\" \"rilassamento\"     \"nessun esercizio\"\n#&gt; [4] \"rilassamento\"     \"nessun esercizio\"\n\n\n9.3.2 Creare una Funzione con Istruzioni Condizionali\nLe istruzioni condizionali possono essere racchiuse in una funzione per rendere il codice più flessibile e riutilizzabile. Ad esempio, supponiamo di voler personalizzare un feedback per un partecipante in base al punteggio ottenuto in un questionario:\n\nfeedback &lt;- function(score) {\n    if (score &gt; 15) {\n        \"Consigliamo un esercizio di rilassamento.\"\n    } else if (score &gt; 10) {\n        \"Monitoriamo la situazione, ma non è necessario alcun intervento.\"\n    } else {\n        \"Nessun intervento necessario.\"\n    }\n}\n\n\nfeedback(18)\n#&gt; [1] \"Consigliamo un esercizio di rilassamento.\"\n\n\nfeedback(12)\n#&gt; [1] \"Monitoriamo la situazione, ma non è necessario alcun intervento.\"\n\n\nfeedback(8)\n#&gt; [1] \"Nessun intervento necessario.\"\n\nIn conclusione, le istruzioni condizionali come if, else e ifelse() sono strumenti fondamentali per introdurre logica e controllo nel tuo codice. Puoi usarle per prendere decisioni, gestire errori e rendere il tuo codice più flessibile ed efficiente. Creare funzioni che incorporano queste istruzioni è un passo fondamentale per scrivere codice ordinato e riutilizzabile in contesti psicologici e non solo.\n\n9.3.3 Combinare Operatori Logici in R\nFinora abbiamo creato funzioni abbastanza semplici e mirate. Ora proviamo a realizzare una funzione leggermente più complessa. Immaginiamo di voler determinare se una persona ha avuto una buona giornata basandoci su due criteri:\n\n\nLivello di stress: basso (TRUE) o alto (FALSE).\n\nLivello di supporto sociale percepito: alto (TRUE) o basso (FALSE).\n\nVogliamo creare una funzione che prenda questi due fattori e restituisca un messaggio che descrive come potrebbe essere stata la giornata della persona.\nEcco come possiamo costruire la funzione:\n\ngood_day &lt;- function(low_stress, high_support) {\n    if (low_stress == TRUE && high_support == TRUE) {\n        \"Giornata fantastica! Ti senti calmo e supportato.\"\n    } else if (low_stress == FALSE && high_support == TRUE) {\n        \"Il supporto sociale ti aiuta a gestire lo stress elevato.\"\n    } else if (low_stress == TRUE && high_support == FALSE) {\n        \"Nonostante lo stress sia basso, la mancanza di supporto sociale pesa.\"\n    } else if (low_stress == FALSE && high_support == FALSE) {\n        \"Giornata difficile: stress elevato e poco supporto sociale.\"\n    }\n}\n\nEsempi di utilizzo.\nCaso 1: Stress basso e supporto sociale alto\n\ngood_day(low_stress = TRUE, high_support = TRUE)\n#&gt; [1] \"Giornata fantastica! Ti senti calmo e supportato.\"\n\nCaso 2: Stress elevato e supporto sociale alto.\n\ngood_day(FALSE, TRUE)\n#&gt; [1] \"Il supporto sociale ti aiuta a gestire lo stress elevato.\"\n\nCaso 3: Stress basso e supporto sociale basso.\n\ngood_day(TRUE, FALSE)\n#&gt; [1] \"Nonostante lo stress sia basso, la mancanza di supporto sociale pesa.\"\n\nCaso 4: Stress elevato e supporto sociale basso.\n\ngood_day(FALSE, FALSE)\n#&gt; [1] \"Giornata difficile: stress elevato e poco supporto sociale.\"\n\nLa funzione considera tutte le combinazioni di stress e supporto sociale:\n\n\nStress basso e supporto alto: giornata ideale.\n\nStress elevato e supporto alto: il supporto aiuta a mitigare lo stress.\n\nStress basso e supporto basso: la mancanza di supporto rovina una situazione potenzialmente buona.\n\nStress elevato e supporto basso: la situazione peggiore.\n\nNell’esempio abbiamo usato i seguenti operatori logici:\n\n\n&& (AND logico): Entrambe le condizioni devono essere vere.\n\n== (uguale a): Verifica se una variabile è vera o falsa.\n\nAd esempio, questa condizione:\nif (low_stress == TRUE && high_support == TRUE)\nverifica se il livello di stress è basso e il supporto sociale è alto.\nIn conclusione, questa funzione dimostra come combinare condizioni logiche complesse utilizzando operatori logici come && (AND) e || (OR). Grazie a questi strumenti, possiamo gestire facilmente logiche più articolate, mantenendo il codice leggibile e funzionale.\n\n9.3.4 Gli operatori Logici in R\nGli operatori logici sono essenziali per definire le condizioni nelle istruzioni if. Ecco una tabella riassuntiva con i principali operatori:\n\n\n\n\n\n\n\n\nOperatore\nDescrizione tecnica\nSignificato\nEsempio\n\n\n\n&&\nAND logico\nEntrambe le condizioni devono essere vere\nif(cond1 == test && cond2 == test)\n\n\n||\nOR logico\nAlmeno una condizione deve essere vera\nif(cond1 == test || cond2 == test)\n\n\n&lt;\nMinore di\nX è minore di Y\nif(X &lt; Y)\n\n\n&gt;\nMaggiore di\nX è maggiore di Y\nif(X &gt; Y)\n\n\n&lt;=\nMinore o uguale a\nX è minore o uguale a Y\nif(X &lt;= Y)\n\n\n&gt;=\nMaggiore o uguale a\nX è maggiore o uguale a Y\nif(X &gt;= Y)\n\n\n==\nUguale a\nX è uguale a Y\nif(X == Y)\n\n\n!=\nDiverso da\nX è diverso da Y\nif(X != Y)",
    "crumbs": [
      "R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_programming.html#cicli-in-r",
    "href": "chapters/R/03_r_programming.html#cicli-in-r",
    "title": "9  Programmazione in R",
    "section": "\n9.4 Cicli in R",
    "text": "9.4 Cicli in R\nR è particolarmente efficace nell’eseguire attività ripetitive. Quando dobbiamo ripetere un’operazione più volte, possiamo utilizzare un ciclo. I cicli eseguono un insieme di istruzioni per un numero specifico di volte o fino a quando una determinata condizione non è soddisfatta.\nIn R esistono tre tipi principali di cicli:\n\n\nCiclo for: ripete un’operazione per un numero definito di iterazioni.\n\nCiclo while: continua a eseguire le istruzioni fino a quando una condizione logica è soddisfatta.\n\nCiclo repeat: itera indefinitamente fino a quando non viene esplicitamente interrotto con un’istruzione break.\n\nI cicli sono strumenti essenziali in tutti i linguaggi di programmazione, ma in R il loro utilizzo dovrebbe essere valutato attentamente, poiché spesso esistono alternative più efficienti come le funzioni della famiglia apply.\n\n9.4.1 Il ciclo for\n\nIl ciclo for è il più utilizzato per eseguire un’operazione un numero definito di volte. Ecco un esempio base:\n\nfor (i in 1:5) {\n    print(i)\n}\n#&gt; [1] 1\n#&gt; [1] 2\n#&gt; [1] 3\n#&gt; [1] 4\n#&gt; [1] 5\n\nCome funziona?\n\nL’indice i prende il primo valore della sequenza 1:5 (cioè 1).\nIl corpo del ciclo, ovvero il codice tra { }, viene eseguito.\nAl termine di ogni iterazione, i assume il valore successivo nella sequenza, e il processo si ripete fino all’ultimo valore (5 in questo caso).\n\nAggiungere logica nel corpo del ciclo\nPossiamo aggiungere operazioni all’interno del ciclo, come ad esempio sommare 1 a ogni valore:\n\nfor (i in 1:5) {\n    print(i + 1)\n}\n#&gt; [1] 2\n#&gt; [1] 3\n#&gt; [1] 4\n#&gt; [1] 5\n#&gt; [1] 6\n\n\n9.4.2 Il ciclo while\n\nIl ciclo while continua a eseguire le istruzioni fino a quando una condizione logica è soddisfatta. Ecco un esempio:\n\ni &lt;- 0\nwhile (i &lt;= 4) {\n    i &lt;- i + 1\n    print(i)\n}\n#&gt; [1] 1\n#&gt; [1] 2\n#&gt; [1] 3\n#&gt; [1] 4\n#&gt; [1] 5\n\nCome funziona?\n\nLa condizione logica (i &lt;= 4) viene verificata prima di ogni iterazione.\nSe la condizione è vera, il ciclo esegue il codice tra { }.\nQuando la condizione diventa falsa (i &gt; 4), il ciclo si interrompe.\n\n9.4.3 Ciclo repeat\n\nIl ciclo repeat esegue il codice indefinitamente, a meno che non venga interrotto con un’istruzione break:\n\ni &lt;- 0\nrepeat {\n    i &lt;- i + 1\n    print(i)\n    if (i &gt;= 5) {\n        break\n    }\n}\n#&gt; [1] 1\n#&gt; [1] 2\n#&gt; [1] 3\n#&gt; [1] 4\n#&gt; [1] 5\n\nQuando usarlo?\nIl ciclo repeat è raro e viene utilizzato solo in situazioni molto particolari. Nella maggior parte dei casi, for o while sono più adatti.\n\n9.4.4 Evitare i cicli: la famiglia di funzioni apply\n\nI cicli in R sono relativamente lenti, specialmente con dataset di grandi dimensioni. Quando possibile, è preferibile usare funzioni della famiglia apply per ottenere lo stesso risultato in modo più efficiente e con meno rischi di errore.\n\n9.4.4.1 La funzione lapply()\n\nlapply() esegue una funzione su ciascun elemento di una lista o vettore e restituisce una lista con i risultati.\nEsempio:\n\nlapply(0:4, function(a) {\n    a + 1\n})\n#&gt; [[1]]\n#&gt; [1] 1\n#&gt; \n#&gt; [[2]]\n#&gt; [1] 2\n#&gt; \n#&gt; [[3]]\n#&gt; [1] 3\n#&gt; \n#&gt; [[4]]\n#&gt; [1] 4\n#&gt; \n#&gt; [[5]]\n#&gt; [1] 5\n\n\n9.4.4.2 La funzione sapply()\n\nlapply() restituisce una lista, ma se vuoi un vettore come output, usa sapply():\n\nsapply(0:4, function(a) {\n    a + 1\n})\n#&gt; [1] 1 2 3 4 5\n\n\n9.4.5 Quando usare i cicli?\nI cicli sono utili quando:\n\nDevi simulare modelli complessi (es. modelli ricorsivi).\nHai bisogno di operazioni che dipendono dai risultati delle iterazioni precedenti.\n\nIn tutti gli altri casi, considera alternative come apply(), lapply() o funzioni simili per un codice più efficiente e meno soggetto a errori.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_programming.html#linee-guida-per-scrivere-codice",
    "href": "chapters/R/03_r_programming.html#linee-guida-per-scrivere-codice",
    "title": "9  Programmazione in R",
    "section": "\n9.5 Linee Guida per Scrivere Codice",
    "text": "9.5 Linee Guida per Scrivere Codice\nDi seguito trovi alcune linee guida per scrivere codice chiaro, conciso e riutilizzabile:\n\nEvita di ripeterti: Segui il principio Don’t Repeat Yourself (DRY). Scrivi funzioni e utilizza funzioni come map (per applicare un pezzo di codice iterativamente a tutti gli elementi di un oggetto) per evitare di copiare e incollare variazioni minime dello stesso codice in più parti del progetto.\nSegui uno stile coerente: Adotta una guida di stile per mantenere uniformità nel tuo codice. Per R, raccomandiamo la guida di stile del “tidyverse”, scritta da Hadley Wickham. Questa guida, derivata dalla Google R Style Guide, fornisce istruzioni dettagliate su sintassi del codice, nomi delle variabili, spaziature, indentazioni, commenti, convenzioni per scrivere funzioni, utilizzo delle pipe (metodo per concatenare funzioni), e altro ancora.\nCommenta abbondantemente: Usa i commenti (ad esempio, con #) per spiegare perché ogni parte del codice è necessaria e cosa fa. I commenti rendono il codice più leggibile e facilitano la manutenzione futura.\nTesta il tuo codice: Ogni volta che scrivi codice, verifica che funzioni come previsto. Puoi farlo scrivendo funzioni di test specifiche o controllando manualmente che l’output corrisponda alle aspettative. Abituati a pensare a eventuali edge cases (casi limite) in cui il tuo codice potrebbe non comportarsi come previsto.\nEsegui una revisione del codice: Quando possibile, fai revisionare il tuo codice da un’altra persona per individuare errori e incoerenze. Se non hai nessuno a disposizione, puoi rivedere il tuo codice autonomamente: rileggendo con attenzione, è sorprendente il numero di errori che si possono individuare!\n\nSeguendo queste linee guida, potrai scrivere codice più robusto, leggibile e facile da mantenere nel tempo.1",
    "crumbs": [
      "R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_programming.html#riflessioni-conclusive",
    "href": "chapters/R/03_r_programming.html#riflessioni-conclusive",
    "title": "9  Programmazione in R",
    "section": "\n9.6 Riflessioni Conclusive",
    "text": "9.6 Riflessioni Conclusive\nScrivere funzioni è un passaggio essenziale per migliorare la leggibilità, l’efficienza e la riutilizzabilità del codice. Funzioni ben progettate semplificano le modifiche, riducono errori e rendono il lavoro più chiaro, sia per te stesso che per i collaboratori futuri. Se trovi che stai copiando e incollando codice più volte, è il momento di pensare a creare una funzione.\nLe istruzioni condizionali, come if, else e ifelse(), sono fondamentali per introdurre logica e controllo nel codice. Permettono di gestire scenari diversi e prendere decisioni dinamiche, migliorando la flessibilità e l’efficienza dei tuoi script. Combinando queste istruzioni con operatori logici come && e ||, puoi affrontare situazioni complesse con un codice chiaro e leggibile.\nI cicli sono potenti strumenti per eseguire operazioni ripetitive, ma in R il loro utilizzo dovrebbe essere limitato ai casi in cui non esistono alternative più efficienti. Le funzioni apply() e simili rappresentano spesso un’opzione migliore per manipolare dati in modo più rapido e leggibile.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_programming.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/R/03_r_programming.html#informazioni-sullambiente-di-sviluppo",
    "title": "9  Programmazione in R",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] see_0.9.0        gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1\n#&gt;  [5] psych_2.4.12     scales_1.3.0     markdown_1.13    knitr_1.49      \n#&gt;  [9] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [13] purrr_1.0.2      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [17] ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.3         rlang_1.1.4       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       tools_4.4.2       parallel_4.4.2    tzdb_0.4.0       \n#&gt; [21] colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5       R6_2.5.1         \n#&gt; [25] lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.0    \n#&gt; [29] gtable_0.3.6      glue_1.8.0        xfun_0.49         tidyselect_1.2.1 \n#&gt; [33] farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-166      rmarkdown_2.29   \n#&gt; [37] compiler_4.4.2",
    "crumbs": [
      "R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_programming.html#bibliografia",
    "href": "chapters/R/03_r_programming.html#bibliografia",
    "title": "9  Programmazione in R",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nIrizarry, R. A. (2024). Introduction to Data Science: Data Wrangling and Visualization with R. CRC Press.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_programming.html#footnotes",
    "href": "chapters/R/03_r_programming.html#footnotes",
    "title": "9  Programmazione in R",
    "section": "",
    "text": "Un’ottima introduzione alle regole di stile per un progetto di analisi dei dati è fornita in questo capitolo.↩︎",
    "crumbs": [
      "R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/04_r_packages.html",
    "href": "chapters/R/04_r_packages.html",
    "title": "10  Pacchetti in R",
    "section": "",
    "text": "10.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nI pacchetti R sono estensioni del linguaggio di programmazione statistica R. Questi pacchetti forniscono una raccolta di risorse che possono essere utilizzate per ampliare le funzionalità di base di R. Ogni pacchetto generalmente include:\nI pacchetti R sono distribuiti e installati attraverso repository centralizzati, il più noto dei quali è CRAN (Comprehensive R Archive Network). CRAN garantisce la qualità e l’affidabilità dei pacchetti, sottoponendoli a controlli rigorosi prima della pubblicazione.\nLa vasta disponibilità di pacchetti è una delle ragioni principali della popolarità di R.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Pacchetti in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/04_r_packages.html#introduzione",
    "href": "chapters/R/04_r_packages.html#introduzione",
    "title": "10  Pacchetti in R",
    "section": "",
    "text": "Codice: funzioni e script scritti in R (e talvolta in altri linguaggi come C++ o Fortran) che implementano specifiche analisi o strumenti.\nDati: dataset di esempio o utili per testare e dimostrare le funzionalità del pacchetto.\nDocumentazione: file descrittivi che spiegano come utilizzare il pacchetto, spesso in formato manuale o vignette (tutorial pratici).",
    "crumbs": [
      "R",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Pacchetti in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/04_r_packages.html#installare-i-pacchetti-r",
    "href": "chapters/R/04_r_packages.html#installare-i-pacchetti-r",
    "title": "10  Pacchetti in R",
    "section": "10.2 Installare i Pacchetti R",
    "text": "10.2 Installare i Pacchetti R\nQuando installi R, vengono installati automaticamente alcuni pacchetti base. Tuttavia, hai la possibilità di aggiungere ulteriori pacchetti che trovi utili per i tuoi scopi. Questi pacchetti sono memorizzati sui server di R (mirror), e l’installazione di un nuovo pacchetto richiede una connessione internet al mirror CRAN che hai scelto durante l’installazione di R.\nPer installare un pacchetto, utilizza il comando:\ninstall.packages(\"&lt;nome_pacchetto&gt;\")\nSostituisci &lt;nome_pacchetto&gt; con il nome del pacchetto che desideri installare. Ad esempio, se vuoi installare il pacchetto rio (utile per importare i dati in R), puoi digitare:\ninstall.packages(\"rio\")   # Non dimenticare le virgolette!",
    "crumbs": [
      "R",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Pacchetti in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/04_r_packages.html#caricamento-di-un-pacchetto",
    "href": "chapters/R/04_r_packages.html#caricamento-di-un-pacchetto",
    "title": "10  Pacchetti in R",
    "section": "10.3 Caricamento di un pacchetto",
    "text": "10.3 Caricamento di un pacchetto\nOgni volta che avvii una nuova sessione di R, se desideri utilizzare un pacchetto, devi caricarlo manualmente. Questo si fa con il comando library(). Ad esempio, dopo aver installato rio, per utilizzarlo digita:\nlibrary(rio)   # Nota: le virgolette non sono necessarie, ma puoi usarle se preferisci.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Pacchetti in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/04_r_packages.html#utilizzo-delle-funzioni-di-un-pacchetto-senza-caricarlo",
    "href": "chapters/R/04_r_packages.html#utilizzo-delle-funzioni-di-un-pacchetto-senza-caricarlo",
    "title": "10  Pacchetti in R",
    "section": "10.4 Utilizzo delle funzioni di un pacchetto senza caricarlo",
    "text": "10.4 Utilizzo delle funzioni di un pacchetto senza caricarlo\nSe hai bisogno di utilizzare una funzione specifica di un pacchetto, ma sai che la userai solo una volta, puoi evitare di caricare l’intero pacchetto con library(). Ad esempio, invece di scrivere:\nlibrary(nome_pacchetto)\nfunzione_specifica(x = 2, sd = 3)\npuoi accedere direttamente alla funzione usando l’operatore ::, come indicato di segtuito:\nnome_pacchetto::funzione_specifica(x = 2, sd = 3)\nQuesto approccio è utile per funzioni che usi raramente o una sola volta. Personalmente, utilizzo :: anche quando ho già caricato il pacchetto, per ricordare ad un “me futuro” da quale pacchetto proviene una determinata funzione. Questo può rendere il codice più leggibile e comprensibile nel tempo.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Pacchetti in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/04_r_packages.html#bibliografia",
    "href": "chapters/R/04_r_packages.html#bibliografia",
    "title": "10  Pacchetti in R",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nIrizarry, R. A. (2024). Introduction to Data Science: Data Wrangling and Visualization with R. CRC Press.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Pacchetti in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_dplyr.html",
    "href": "chapters/R/05_dplyr.html",
    "title": "11  Introduzione a dplyr",
    "section": "",
    "text": "11.1 Introduzione\nL’obiettivo di questo capitolo è fornire un’introduzione alle funzioni principali del pacchetto dplyr per le operazioni di data wrangling, cioè per il preprocessing e la pulizia dei dati. In R, queste operazioni sono strettamente legate al concetto di “data tidying”, che si riferisce all’organizzazione sistematica dei dati per facilitare l’analisi.\nPer comprendere meglio il concetto di “data tidying”, possiamo rifarci a una citazione tratta dal testo di riferimento R for Data Science (2e):\nL’essenza del “data tidying” è organizzare i dati in un formato che sia facile da gestire e analizzare. Anche se gli stessi dati possono essere rappresentati in vari modi, non tutte le rappresentazioni sono ugualmente efficienti o facili da usare. Un dataset “tidy” segue tre principi fondamentali che lo rendono particolarmente pratico:\nIl pacchetto R {dplyr} e gli altri pacchetti del tidyverse sono progettati specificamente per lavorare con dati in formato “tidy”, permettendo agli utenti di eseguire operazioni di manipolazione e visualizzazione in modo più intuitivo ed efficiente.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduzione a `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_dplyr.html#introduzione",
    "href": "chapters/R/05_dplyr.html#introduzione",
    "title": "11  Introduzione a dplyr",
    "section": "",
    "text": "“Happy families are all alike; every unhappy family is unhappy in its own way.” — Leo Tolstoy\n\n\n“Tidy datasets are all alike, but every messy dataset is messy in its own way.” — Hadley Wickham\n\n\n\n\nOgni variabile è una colonna: ogni colonna nel dataset rappresenta una singola variabile.\n\nOgni osservazione è una riga: ogni riga nel dataset rappresenta un’unica osservazione.\n\nOgni valore è una cella: ogni cella del dataset contiene un singolo valore.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduzione a `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_dplyr.html#pipe",
    "href": "chapters/R/05_dplyr.html#pipe",
    "title": "11  Introduzione a dplyr",
    "section": "\n11.2 Pipe",
    "text": "11.2 Pipe\nIl pacchetto dplyr, così come l’intero ecosistema tidyverse, fa largo uso dell’operatore pipe, che consente di concatenare una sequenza di operazioni in modo leggibile ed efficiente. In R, esistono due principali notazioni per il pipe:\n\n\n|&gt;: introdotto nativamente a partire dalla versione 4.1.0 di R.\n\n%&gt;%: introdotto dal pacchetto magrittr, ed è una delle componenti centrali del tidyverse.\n\nEntrambi gli operatori permettono di ottenere risultati simili e, per la maggior parte degli utilizzi, possono essere considerati intercambiabili. Tuttavia, è importante sottolineare alcune differenze:\n\n\n|&gt; è integrato nel linguaggio R e non richiede pacchetti aggiuntivi.\n\n%&gt;%, essendo parte di magrittr, richiede che il pacchetto sia installato e caricato (library(magrittr) o automaticamente tramite tidyverse).\n\nConsideriamo l’esempio seguente (che anticipa l’uso della funzione filter() che descriveremo in seguito). Un’operazione comune è filtrare un data frame e calcolare la media di una colonna. Con il pipe, questa sequenza di operazioni diventa più leggibile:\n\n# Usando %&gt;%\niris %&gt;%\n  dplyr::filter(Species == \"setosa\") |&gt; \n  summarise(\n    mean_sepal_length = mean(Sepal.Length)\n  ) \n#&gt;   mean_sepal_length\n#&gt; 1              5.01\n\n\n# Usando |&gt;\niris |&gt; \n  dplyr::filter(Species == \"setosa\") |&gt; \n  summarise(\n    mean_sepal_length = mean(Sepal.Length)\n  ) \n#&gt;   mean_sepal_length\n#&gt; 1              5.01\n\n\n11.2.1 Cosa Fa la Pipe?\nLa pipe è uno strumento potente che permette di collegare in modo diretto l’output di una funzione come input della funzione successiva. Questo approccio:\n\nRiduce la necessità di creare variabili intermedie.\nMigliora la leggibilità del codice.\nRende il flusso delle operazioni più chiaro e lineare.\n\nOgni funzione applicata con la pipe riceve automaticamente l’output della funzione precedente come suo primo argomento. Ciò consente di scrivere sequenze di operazioni in un formato compatto e intuitivo.\nEcco un altro esempio:\n\n# Utilizzo della pipe per trasformare un dataset\ndf &lt;- data.frame(\n  id = 1:5,\n  value = c(10, 20, 30, 40, 50)\n)\n\n# Filtra i dati, seleziona colonne e calcola nuovi valori\ndf_clean &lt;- df |&gt;\n  dplyr::filter(value &gt; 20) |&gt;\n  dplyr::select(id, value) |&gt;\n  mutate(squared_value = value^2)\n\nIn questa sequenza, il dataset originale df viene filtrato, le colonne desiderate vengono selezionate e viene aggiunta una nuova colonna con il valore al quadrato.\n\nhead(df_clean)\n#&gt;   id value squared_value\n#&gt; 1  3    30           900\n#&gt; 2  4    40          1600\n#&gt; 3  5    50          2500\n\nIn sintesi, la pipe è uno strumento fondamentale per scrivere codice R moderno e leggibile, indipendentemente dal fatto che si utilizzi |&gt; o %&gt;%.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduzione a `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_dplyr.html#verbi",
    "href": "chapters/R/05_dplyr.html#verbi",
    "title": "11  Introduzione a dplyr",
    "section": "\n11.3 Verbi",
    "text": "11.3 Verbi\nLe funzioni principali (“verbi) di dplyr sono le seguenti:\n\n\n\n\n\n\nVerbo dplyr\nDescrizione\n\n\n\nselect()\nSeleziona colonne\n\n\nfilter()\nFiltra righe\n\n\narrange()\nRiordina o organizza le righe\n\n\nmutate()\nCrea nuove colonne\n\n\nsummarise()\nRiassume i valori\n\n\ngroup_by()\nConsente di eseguire operazioni di gruppo\n\n\n\nI verbi di dplyr sono suddivisi in quattro gruppi, in base all’elemento su cui operano: righe, colonne, gruppi o tabelle.\nInoltre, le diverse funzioni bind_ e _joins permettono di combinare più tibbles (ovvero, data frame) in uno solo.\nPer fare un esempio prarico, usiamo nuovamente il dataset msleep.\n\ndata(msleep)\ndim(msleep)\n#&gt; [1] 83 11\n\nEsaminiamo i dati:\n\nglimpse(msleep)\n#&gt; Rows: 83\n#&gt; Columns: 11\n#&gt; $ name         &lt;chr&gt; \"Cheetah\", \"Owl monkey\", \"Mountain beaver\", \"Greater …\n#&gt; $ genus        &lt;chr&gt; \"Acinonyx\", \"Aotus\", \"Aplodontia\", \"Blarina\", \"Bos\", …\n#&gt; $ vore         &lt;chr&gt; \"carni\", \"omni\", \"herbi\", \"omni\", \"herbi\", \"herbi\", \"…\n#&gt; $ order        &lt;chr&gt; \"Carnivora\", \"Primates\", \"Rodentia\", \"Soricomorpha\", …\n#&gt; $ conservation &lt;chr&gt; \"lc\", NA, \"nt\", \"lc\", \"domesticated\", NA, \"vu\", NA, \"…\n#&gt; $ sleep_total  &lt;dbl&gt; 12.1, 17.0, 14.4, 14.9, 4.0, 14.4, 8.7, 7.0, 10.1, 3.…\n#&gt; $ sleep_rem    &lt;dbl&gt; NA, 1.8, 2.4, 2.3, 0.7, 2.2, 1.4, NA, 2.9, NA, 0.6, 0…\n#&gt; $ sleep_cycle  &lt;dbl&gt; NA, NA, NA, 0.133, 0.667, 0.767, 0.383, NA, 0.333, NA…\n#&gt; $ awake        &lt;dbl&gt; 11.9, 7.0, 9.6, 9.1, 20.0, 9.6, 15.3, 17.0, 13.9, 21.…\n#&gt; $ brainwt      &lt;dbl&gt; NA, 0.01550, NA, 0.00029, 0.42300, NA, NA, NA, 0.0700…\n#&gt; $ bodywt       &lt;dbl&gt; 50.000, 0.480, 1.350, 0.019, 600.000, 3.850, 20.490, …\n\nLe colonne, nell’ordine, corrispondono a quanto segue:\n\n\nNome colonna\nDescrizione\n\n\n\nname\nNome comune\n\n\ngenus\nRango tassonomico\n\n\nvore\nCarnivoro, onnivoro o erbivoro?\n\n\norder\nRango tassonomico\n\n\nconservation\nStato di conservazione del mammifero\n\n\nsleep_total\nQuantità totale di sonno, in ore\n\n\nsleep_rem\nSonno REM, in ore\n\n\nsleep_cycle\nDurata del ciclo di sonno, in ore\n\n\nawake\nQuantità di tempo trascorso sveglio, in ore\n\n\nbrainwt\nPeso del cervello, in chilogrammi\n\n\nbodywt\nPeso corporeo, in chilogrammi",
    "crumbs": [
      "R",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduzione a `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_dplyr.html#righe",
    "href": "chapters/R/05_dplyr.html#righe",
    "title": "11  Introduzione a dplyr",
    "section": "\n11.4 Righe",
    "text": "11.4 Righe\nI verbi più importanti che operano sulle righe di un dataset sono filter(), che seleziona le righe da includere senza modificarne l’ordine, e arrange(), che cambia l’ordine delle righe senza alterare la selezione delle righe presenti.\n\nmsleep |&gt;\n  dplyr::filter(sleep_total &lt; 4) |&gt;\n  arrange(sleep_total)\n#&gt; # A tibble: 9 × 11\n#&gt;   name             genus         vore  order          conservation\n#&gt;   &lt;chr&gt;            &lt;chr&gt;         &lt;chr&gt; &lt;chr&gt;          &lt;chr&gt;       \n#&gt; 1 Giraffe          Giraffa       herbi Artiodactyla   cd          \n#&gt; 2 Pilot whale      Globicephalus carni Cetacea        cd          \n#&gt; 3 Horse            Equus         herbi Perissodactyla domesticated\n#&gt; 4 Roe deer         Capreolus     herbi Artiodactyla   lc          \n#&gt; 5 Donkey           Equus         herbi Perissodactyla domesticated\n#&gt; 6 African elephant Loxodonta     herbi Proboscidea    vu          \n#&gt; # ℹ 3 more rows\n#&gt; # ℹ 6 more variables: sleep_total &lt;dbl&gt;, sleep_rem &lt;dbl&gt;, …\n\nPossiamo usare filter() speficicano più di una condizione logica.\n\nmsleep |&gt;\n  dplyr::filter((sleep_total &lt; 4 & bodywt &gt; 100) | brainwt &gt; 1) |&gt;\n  arrange(sleep_total)\n#&gt; # A tibble: 7 × 11\n#&gt;   name             genus         vore  order          conservation\n#&gt;   &lt;chr&gt;            &lt;chr&gt;         &lt;chr&gt; &lt;chr&gt;          &lt;chr&gt;       \n#&gt; 1 Giraffe          Giraffa       herbi Artiodactyla   cd          \n#&gt; 2 Pilot whale      Globicephalus carni Cetacea        cd          \n#&gt; 3 Horse            Equus         herbi Perissodactyla domesticated\n#&gt; 4 Donkey           Equus         herbi Perissodactyla domesticated\n#&gt; 5 African elephant Loxodonta     herbi Proboscidea    vu          \n#&gt; 6 Asian elephant   Elephas       herbi Proboscidea    en          \n#&gt; # ℹ 1 more row\n#&gt; # ℹ 6 more variables: sleep_total &lt;dbl&gt;, sleep_rem &lt;dbl&gt;, …",
    "crumbs": [
      "R",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduzione a `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_dplyr.html#colonne",
    "href": "chapters/R/05_dplyr.html#colonne",
    "title": "11  Introduzione a dplyr",
    "section": "\n11.5 Colonne",
    "text": "11.5 Colonne\nEsistono quattro verbi principali che modificano le colonne di un dataset senza cambiare le righe:\n\n\nrelocate() cambia la posizione delle colonne;\n\nrename() modifica i nomi delle colonne;\n\nselect() seleziona le colonne da includere o escludere;\n\nmutate() crea nuove colonne a partire da quelle esistenti.\n\n\nmsleep2 &lt;- msleep |&gt;\n  mutate(\n    rem_prop = sleep_rem / sleep_total * 100\n  ) |&gt;\n  dplyr::select(name, vore, rem_prop, sleep_total) |&gt;\n  arrange(desc(rem_prop))\n\nglimpse(msleep2)\n#&gt; Rows: 83\n#&gt; Columns: 4\n#&gt; $ name        &lt;chr&gt; \"European hedgehog\", \"Thick-tailed opposum\", \"Giant ar…\n#&gt; $ vore        &lt;chr&gt; \"omni\", \"carni\", \"insecti\", \"omni\", \"carni\", \"omni\", \"…\n#&gt; $ rem_prop    &lt;dbl&gt; 34.7, 34.0, 33.7, 29.2, 28.7, 27.2, 26.4, 26.2, 25.6, …\n#&gt; $ sleep_total &lt;dbl&gt; 10.1, 19.4, 18.1, 8.9, 10.1, 18.0, 9.1, 10.3, 12.5, 8.…\n\nIn questo esempio, utilizziamo mutate() per creare una nuova colonna rem_prop che rappresenta la percentuale di sonno REM sul totale del sonno. Successivamente, select() viene utilizzato per scegliere solo alcune colonne del dataset, e infine desc(rem_prop) ordina i valori di rem_prop in ordine decrescente, dal valore maggiore a quello minore.\nPer cambiare il nome di una colonna possiamo usare rename(). Inoltre, possiamo cambiare l’ordine delle variabili con relocate().\n\nmsleep2 |&gt;\n  rename(rem_perc = rem_prop) |&gt;\n  relocate(rem_perc, .before = name)\n#&gt; # A tibble: 83 × 4\n#&gt;   rem_perc name                   vore    sleep_total\n#&gt;      &lt;dbl&gt; &lt;chr&gt;                  &lt;chr&gt;         &lt;dbl&gt;\n#&gt; 1     34.7 European hedgehog      omni           10.1\n#&gt; 2     34.0 Thick-tailed opposum   carni          19.4\n#&gt; 3     33.7 Giant armadillo        insecti        18.1\n#&gt; 4     29.2 Tree shrew             omni            8.9\n#&gt; 5     28.7 Dog                    carni          10.1\n#&gt; 6     27.2 North American Opossum omni           18  \n#&gt; # ℹ 77 more rows",
    "crumbs": [
      "R",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduzione a `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_dplyr.html#gruppi",
    "href": "chapters/R/05_dplyr.html#gruppi",
    "title": "11  Introduzione a dplyr",
    "section": "\n11.6 Gruppi",
    "text": "11.6 Gruppi\nIl verbo group_by() viene utilizzato per suddividere un dataset in gruppi, in base a una o più variabili, che siano rilevanti per l’analisi. Questo permette di eseguire operazioni di sintesi su ciascun gruppo separatamente, ottenendo informazioni aggregate.\nAd esempio, nel codice seguente:\n\nmsleep |&gt;\n  group_by(order) |&gt;\n  summarise(\n    avg_sleep = mean(sleep_total),\n    min_sleep = min(sleep_total),\n    max_sleep = max(sleep_total),\n    total = n()\n  ) |&gt;\n  arrange(desc(avg_sleep))\n#&gt; # A tibble: 19 × 5\n#&gt;   order           avg_sleep min_sleep max_sleep total\n#&gt;   &lt;chr&gt;               &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;int&gt;\n#&gt; 1 Chiroptera           19.8      19.7      19.9     2\n#&gt; 2 Didelphimorphia      18.7      18        19.4     2\n#&gt; 3 Cingulata            17.8      17.4      18.1     2\n#&gt; 4 Afrosoricida         15.6      15.6      15.6     1\n#&gt; 5 Pilosa               14.4      14.4      14.4     1\n#&gt; 6 Rodentia             12.5       7        16.6    22\n#&gt; # ℹ 13 more rows\n\n\ngroup_by(order) suddivide il dataset msleep in gruppi, ciascuno corrispondente a un valore distinto della variabile order.\n\nSuccessivamente, summarise() calcola diverse statistiche per ogni gruppo:\n\n\navg_sleep è la media del totale del sonno (sleep_total) all’interno di ciascun gruppo.\n\nmin_sleep è il valore minimo di sleep_total in ogni gruppo.\n\nmax_sleep è il valore massimo di sleep_total in ogni gruppo.\n\ntotal è il numero di osservazioni (o righe) per ciascun gruppo, calcolato con la funzione n().\n\n\nInfine, arrange(desc(avg_sleep)) ordina i risultati in ordine decrescente in base alla media del sonno totale (avg_sleep), mostrando prima i gruppi con la media di sonno più alta.\n\nQuesto tipo di approccio è utile quando si vuole analizzare come cambiano le caratteristiche dei dati a seconda dei gruppi specifici, fornendo una visione più dettagliata e utile.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduzione a `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_dplyr.html#considerazioni-conclusive",
    "href": "chapters/R/05_dplyr.html#considerazioni-conclusive",
    "title": "11  Introduzione a dplyr",
    "section": "\n11.7 Considerazioni Conclusive",
    "text": "11.7 Considerazioni Conclusive\nIl data wrangling è una delle fasi più importanti in qualsiasi pipeline di analisi dei dati. In questo capitolo abbiamo introdotto l’uso del pacchetto tidyverse di R per la manipolazione dei dati e il suo utilizzo in scenari di base. Tuttavia, il tidyverse è un ecosistema ampio e qui abbiamo trattato solo gli elementi fondamentali. Per approfondire, si consiglia di consultare ulteriori risorse come quelle disponibili sul sito web del tidyverse e il libro R for Data Science (2e), di cui esiste anche una traduzione italiana.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduzione a `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_dplyr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/R/05_dplyr.html#informazioni-sullambiente-di-sviluppo",
    "title": "11  Introduzione a dplyr",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] missForest_1.5   mice_3.17.0      see_0.9.0        gridExtra_2.3   \n#&gt;  [5] patchwork_1.3.0  bayesplot_1.11.1 psych_2.4.12     scales_1.3.0    \n#&gt;  [9] markdown_1.13    knitr_1.49       lubridate_1.9.4  forcats_1.0.0   \n#&gt; [13] stringr_1.5.1    dplyr_1.1.4      purrr_1.0.2      readr_2.1.5     \n#&gt; [17] tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0 \n#&gt; [21] rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6         shape_1.4.6.1        xfun_0.49           \n#&gt;  [4] htmlwidgets_1.6.4    lattice_0.22-6       tzdb_0.4.0          \n#&gt;  [7] vctrs_0.6.5          tools_4.4.2          generics_0.1.3      \n#&gt; [10] parallel_4.4.2       pan_1.9              pacman_0.5.1        \n#&gt; [13] pkgconfig_2.0.3      jomo_2.7-6           Matrix_1.7-1        \n#&gt; [16] rngtools_1.5.2       lifecycle_1.0.4      compiler_4.4.2      \n#&gt; [19] farver_2.1.2         munsell_0.5.1        mnormt_2.1.1        \n#&gt; [22] codetools_0.2-20     htmltools_0.5.8.1    glmnet_4.1-8        \n#&gt; [25] nloptr_2.1.1         pillar_1.10.0        MASS_7.3-61         \n#&gt; [28] doRNG_1.8.6          iterators_1.0.14     rpart_4.1.23        \n#&gt; [31] boot_1.3-31          foreach_1.5.2        mitml_0.4-5         \n#&gt; [34] nlme_3.1-166         tidyselect_1.2.1     digest_0.6.37       \n#&gt; [37] stringi_1.8.4        splines_4.4.2        rprojroot_2.0.4     \n#&gt; [40] fastmap_1.2.0        grid_4.4.2           colorspace_2.1-1    \n#&gt; [43] cli_3.6.3            magrittr_2.0.3       utf8_1.2.4          \n#&gt; [46] randomForest_4.7-1.2 survival_3.8-3       broom_1.0.7         \n#&gt; [49] withr_3.0.2          backports_1.5.0      timechange_0.3.0    \n#&gt; [52] rmarkdown_2.29       nnet_7.3-19          lme4_1.1-35.5       \n#&gt; [55] hms_1.1.3            evaluate_1.0.1       itertools_0.1-3     \n#&gt; [58] rlang_1.1.4          Rcpp_1.0.13-1        glue_1.8.0          \n#&gt; [61] minqa_1.2.8          jsonlite_1.8.9       R6_2.5.1\n\n\n\n\n\nIrizarry, R. A. (2024). Introduction to Data Science: Data Wrangling and Visualization with R. CRC Press.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduzione a `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/R/06_quarto.html",
    "href": "chapters/R/06_quarto.html",
    "title": "12  Quarto",
    "section": "",
    "text": "12.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nPreparazione del Notebook\nQuarto si inserisce nella tradizione del literate programming, un approccio introdotto da Donald Knuth negli anni ’80. Il literate programming nasce con l’idea di combinare codice e testo descrittivo in un unico documento, rendendo il programma non solo eseguibile ma anche leggibile e comprensibile agli esseri umani. Questo approccio mira a superare la separazione tra codice e documentazione, permettendo di spiegare non solo come un programma funziona, ma anche perché è stato scritto in un certo modo.\nQuesta filosofia è particolarmente rilevante nella scienza dei dati e nell’analisi statistica, dove la riproducibilità e la trasparenza sono fondamentali. In questo contesto, strumenti come Quarto giocano un ruolo chiave, permettendo di integrare codice, risultati e narrazione in un unico documento. Con Quarto, è possibile produrre report, articoli, presentazioni e altri output in diversi formati (HTML, PDF, Word, ecc.), combinando testi interpretativi, risultati numerici e grafici.\nQuarto si distingue per la sua flessibilità e per il supporto a diversi linguaggi di programmazione, tra cui R, Python e Julia. Questo strumento può essere utilizzato in tre modi principali:\nPur non essendo un pacchetto R, Quarto è uno strumento CLI (Command Line Interface). Tuttavia, grazie a RStudio, l’installazione e l’utilizzo di Quarto sono gestiti automaticamente, rendendolo accessibile anche a chi ha meno familiarità con il terminale.\nQuarto rappresenta quindi una naturale evoluzione del concetto di literate programming, combinando praticità e rigore scientifico in un unico ambiente di lavoro.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "chapters/R/06_quarto.html#introduzione",
    "href": "chapters/R/06_quarto.html#introduzione",
    "title": "12  Quarto",
    "section": "",
    "text": "Presentare conclusioni: condividere i risultati senza esporre il codice sottostante.\n\nDocumentare il processo analitico: includere sia il codice che i risultati per garantire trasparenza e riproducibilità.\n\nAnnotare l’analisi: integrare interpretazioni e decisioni prese durante il lavoro analitico.\n\n\n\n\n12.1.1 Creare un documento Quarto\nUn file Quarto ha estensione .qmd e segue questa struttura:\n\nQuesto file include:\n\nUn’intestazione YAML (metadati del documento).\nBlocchi di codice delimitati da ```.\nTesto scritto in Markdown con formattazioni semplici come titoli (# Titolo), corsivi (*testo*), ecc.\n\n12.1.2 Editor visivo e sorgente\n\n\nEditor visivo: simile a Google Docs, offre un’interfaccia WYSIWYM (What You See Is What You Mean). Consente di inserire facilmente immagini, tabelle, citazioni e altro.\n\nEditor sorgente: consente un controllo diretto sul Markdown, utile per debug e personalizzazioni avanzate.\n\n12.1.3 Blocchi di codice\nI blocchi di codice (chiamati “chunks”) eseguono codice e visualizzano i risultati. Ogni chunk è delimitato da ``` e può includere opzioni specifiche:\n#| label: esempio\n#| echo: false\n1 + 1\nLe opzioni più comuni includono:\n\n\necho: false (nasconde il codice nel report),\n\neval: false (non esegue il codice),\n\nmessage: false e warning: false (nasconde messaggi o avvisi).\n\n12.1.4 Figure\nLe figure possono essere generate tramite codice (es. ggplot()) o inserite come file esterni. Le opzioni più comuni per il controllo delle dimensioni sono:\n\n\nfig-width e fig-height (dimensioni della figura in pollici),\n\nout-width (percentuale di larghezza del documento),\n\nfig-asp (rapporto d’aspetto, es. 0.618 per il rapporto aureo).\n\nEsempio:\n#| fig-width: 6\nggplot(data, aes(x, y)) + geom_point()\n\n12.1.5 Tabelle\nLe tabelle possono essere stampate direttamente o personalizzate con funzioni come knitr::kable() o pacchetti come gt:\n\nknitr::kable(head(mtcars))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmpg\ncyl\ndisp\nhp\ndrat\nwt\nqsec\nvs\nam\ngear\ncarb\n\n\n\nMazda RX4\n21.0\n6\n160\n110\n3.90\n2.62\n16.5\n0\n1\n4\n4\n\n\nMazda RX4 Wag\n21.0\n6\n160\n110\n3.90\n2.88\n17.0\n0\n1\n4\n4\n\n\nDatsun 710\n22.8\n4\n108\n93\n3.85\n2.32\n18.6\n1\n1\n4\n1\n\n\nHornet 4 Drive\n21.4\n6\n258\n110\n3.08\n3.21\n19.4\n1\n0\n3\n1\n\n\nHornet Sportabout\n18.7\n8\n360\n175\n3.15\n3.44\n17.0\n0\n0\n3\n2\n\n\nValiant\n18.1\n6\n225\n105\n2.76\n3.46\n20.2\n1\n0\n3\n1\n\n\n\n\n\n\n12.1.6 Caching\nPer velocizzare i documenti con calcoli complessi, Quarto supporta la memorizzazione dei risultati:\n\n\ncache: true salva i risultati di un chunk, evitando di ricalcolarli se il codice non cambia.\n\ndependson specifica dipendenze tra chunk.\n\n12.1.7 Citazioni e bibliografie in Quarto\nQuarto supporta la generazione automatica di citazioni e bibliografie in formati personalizzati, come lo stile APA. Per includere riferimenti, è necessario creare un file .bib (ad esempio, references.bib) che contenga le citazioni in formato BibTeX. Puoi ottenere queste citazioni direttamente da Google Scholar o altri database accademici. Ecco un esempio:\n@article{ceccarini2024age,\n  title={Age-dependent changes in the anger superiority effect: Evidence from a visual search task},\n  author={Ceccarini, Francesco and Colpizzi, Ilaria and Caudek, Corrado},\n  journal={Psychonomic Bulletin \\& Review},\n  pages={1--10},\n  year={2024},\n  publisher={Springer}\n}\n\n12.1.7.1 Configurazione del file YAML\nNel file .qmd, aggiungi le seguenti righe all’intestazione YAML per collegare il file references.bib e configurare lo stile bibliografico:\nbibliography: references.bib\nbiblio-style: apalike\ncsl: apa.csl\n\n\nbibliography: specifica il percorso del file .bib (in questo esempio si assume che si trovi nella stessa cartella del file Quarto).\n\nbiblio-style: imposta lo stile delle citazioni (ad esempio, apalike per uno stile simile all’APA).\n\ncsl: permette di utilizzare uno stile di citazione personalizzato (es., apa.csl), che puoi scaricare facilmente da siti come Zotero Style Repository.\n\n12.1.7.2 Citazioni Inline\nAll’interno di un documento .qmd, le citazioni vengono aggiunte utilizzando il simbolo @ seguito dall’identificativo della citazione specificato nel file .bib. Ad esempio:\n... come evidenziato da @ceccarini2024age, si osserva che...\nQuarto genera automaticamente la bibliografia, includendo solo i riferimenti effettivamente citati nel documento. La bibliografia viene aggiunta alla fine del file renderizzato (ad esempio, in formato HTML o PDF).\nAd esempio, nel caso di un documento .qmd, il testo sopra sarà visualizzato così:\n\n… come evidenziato da Ceccarini et al. (2024), si osserva che…\n\nLa citazione completa sarà inclusa automaticamente nella bibliografia, posizionata alla fine della pagina web o del documento finale.1",
    "crumbs": [
      "R",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "chapters/R/06_quarto.html#riflessioni-conclusive",
    "href": "chapters/R/06_quarto.html#riflessioni-conclusive",
    "title": "12  Quarto",
    "section": "\n12.2 Riflessioni Conclusive",
    "text": "12.2 Riflessioni Conclusive\nQuarto è uno strumento potente per la creazione di documenti riproducibili e ben strutturati, integrando codice, risultati e testo descrittivo in un unico file. Questa introduzione dovrebbe essere sufficiente per iniziare a lavorare con Quarto, ma c’è ancora molto da imparare. Il modo migliore per rimanere aggiornati è consultare il sito ufficiale di Quarto: https://quarto.org.\nUn argomento importante che non abbiamo trattato qui riguarda i dettagli di come comunicare in modo accurato le proprie idee agli altri. Per migliorare le proprie capacità di scrittura, Wickham et al. (2023) consigliano due libri: Style: Lessons in Clarity and Grace di Joseph M. Williams & Joseph Bizup, e The Sense of Structure: Writing from the Reader’s Perspective di George Gopen. Una serie di brevi articoli sulla scrittura sono offerti da George Gopen e sono disponibili su https://www.georgegopen.com/litigation-articles.html.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "chapters/R/06_quarto.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/R/06_quarto.html#informazioni-sullambiente-di-sviluppo",
    "title": "12  Quarto",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] see_0.9.0        gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1\n#&gt;  [5] psych_2.4.12     scales_1.3.0     markdown_1.13    knitr_1.49      \n#&gt;  [9] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [13] purrr_1.0.2      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [17] ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.3         rlang_1.1.4       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       yaml_2.3.10       tools_4.4.2       parallel_4.4.2   \n#&gt; [21] tzdb_0.4.0        colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5      \n#&gt; [25] R6_2.5.1          lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3  \n#&gt; [29] pillar_1.10.0     gtable_0.3.6      glue_1.8.0        xfun_0.49        \n#&gt; [33] tidyselect_1.2.1  farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-166     \n#&gt; [37] rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "R",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "chapters/R/06_quarto.html#bibliografia",
    "href": "chapters/R/06_quarto.html#bibliografia",
    "title": "12  Quarto",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nCeccarini, F., Colpizzi, I., & Caudek, C. (2024). Age-dependent changes in the anger superiority effect: Evidence from a visual search task. Psychonomic Bulletin & Review, 1–10.\n\n\nWickham, H., Çetinkaya-Rundel, M., & Grolemund, G. (2023). R for data science. \" O’Reilly Media, Inc.\".",
    "crumbs": [
      "R",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "chapters/R/06_quarto.html#footnotes",
    "href": "chapters/R/06_quarto.html#footnotes",
    "title": "12  Quarto",
    "section": "",
    "text": "Si noti la citazione Ceccarini et al. (2024) nella bibliografia della presente pagina web.↩︎",
    "crumbs": [
      "R",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "chapters/R/07_environment.html",
    "href": "chapters/R/07_environment.html",
    "title": "13  L’ambiente di programmazione in R",
    "section": "",
    "text": "13.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nPreparazione del Notebook\nProgrammare presuppone necessariamente un ambiente di programmazione. Una cattiva gestione di questo ambiente può causare il malfunzionamento degli script, rendendo fondamentale imparare a gestirlo correttamente.\nL’ambiente può influenzare persino il comportamento delle funzioni più basilari. Considera il seguente esempio:\nQuesto potrebbe produrre il seguente output:\nTuttavia, modificando l’opzione di larghezza in R, il comportamento cambia:\nIn questo caso, l’output potrebbe essere:\nLa differenza è dovuta a un’opzione dell’ambiente, width, che regola il numero massimo di caratteri visualizzati per ogni riga.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>L'ambiente di programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/07_environment.html#introduzione",
    "href": "chapters/R/07_environment.html#introduzione",
    "title": "13  L’ambiente di programmazione in R",
    "section": "",
    "text": "Nota: In R, il termine “ambiente” ha un significato specifico, riferendosi allo spazio di lavoro in cui gli oggetti vengono memorizzati durante una sessione. In questo capitolo, tuttavia, il termine si riferisce allo stato complessivo del tuo computer mentre programmi, inclusa l’organizzazione dei file, la versione di R che stai usando e altre impostazioni.\n\n\nprint(1:9)\n\n[1] 1 2 3 4 5 6 7 8 9\n\n# Dopo aver modificato options(width)\noptions(width = 10)\nprint(1:9)\n\n[1] 1 2 3\n[4] 4 5 6\n[7] 7 8 9",
    "crumbs": [
      "R",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>L'ambiente di programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/07_environment.html#file-system",
    "href": "chapters/R/07_environment.html#file-system",
    "title": "13  L’ambiente di programmazione in R",
    "section": "\n13.2 File system",
    "text": "13.2 File system\nPrima di iniziare a organizzare un progetto in R, è fondamentale seguire alcune linee guida per strutturare e nominare i file in modo efficace. Spesso si tende a sottovalutare l’importanza di una buona organizzazione, ma adottare un sistema coerente può far risparmiare tempo prezioso nella ricerca e gestione dei progetti passati. Danielle Navarro ha creato una presentazione sulla struttura dei progetti, nella quale propone tre principi fondamentali per la gestione dei file:\n\nEssere gentili per le macchine.\nEssere gentili per gli esseri umani.\nFacilitare l’ordinamento e la ricerca.\n\n\n13.2.1 Essere gentili con le macchine\nLe macchine possono confondersi con spazi, caratteri speciali (come ^.*?+|$“), e lettere accentate. Per evitare problemi:\n\nUsa solo lettere minuscole, numeri, trattini _ o -.\nEvita caratteri speciali e spazi nei nomi dei file.\nUsa estensioni coerenti, come .R per gli script R.\n\nEsempi:\n# Buono\nprogetto01_analisi_dati.R\n\n# Cattivo\nProgetto \"Analisi Dati\".R\n\n13.2.2 Essere gentili con gli umani\nGli esseri umani hanno bisogno di contesto. Evita nomi vaghi e usa descrizioni significative.\n# Buono\nanalisi01_statistiche_descrittive.R\nnote02_intro_modello.docx\n\n# Cattivo\n01.R\nappunti.docx\n\n\n\n\n\n\nEvitate categoricamente l’uso di spazi nei nomi di file, cartelle o oggetti in R. Anche se il sistema operativo potrebbe consentirlo, questa pratica può generare problemi futuri, complicare il debugging e rendere il codice meno leggibile e portabile. Per evitare questi inconvenienti, adottate sempre nomi privi di spazi, preferendo separatori come trattini bassi (_) o trattini (-).\n\n\n\n\n13.2.3 Facilitare l’ordinamento e la ricerca\nSe i nomi dei file includono date, usa sempre il formato YYYY-MM-DD per permettere un ordinamento automatico.\n# Buono\n2024-01-01_analisi.R\n2024-02-15_riassunto.docx\n\n# Cattivo\n1-gennaio-2024.R\nriassunto-15-02-2024.docx\nSe devi ordinare i file in base a qualcosa di diverso dalle date, usa numeri con lo zero iniziale per mantenere l’ordine.\nreading01_shakespeare_romeo-and-juliet.docx\nreading02_shakespeare_romeo-and-juliet.docx\n...\nreading11_shakespeare_romeo-and-juliet.docx\nnotes01_shakespeare_romeo-and-juliet.docx\n...",
    "crumbs": [
      "R",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>L'ambiente di programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/07_environment.html#versioni-di-r-e-pacchetti",
    "href": "chapters/R/07_environment.html#versioni-di-r-e-pacchetti",
    "title": "13  L’ambiente di programmazione in R",
    "section": "\n13.3 Versioni di R e pacchetti",
    "text": "13.3 Versioni di R e pacchetti\nAggiornare regolarmente R e i pacchetti è essenziale per evitare bug e sfruttare le nuove funzionalità. Ecco alcune buone pratiche:\n\nEsegui update.packages() ogni poche settimane per aggiornare i pacchetti.\nAggiorna la versione di R ogni pochi mesi. Su Windows puoi usare il pacchetto installr, mentre su altri sistemi puoi scaricare l’ultima versione dal sito ufficiale di R.\nMantieni aggiornato anche il sistema operativo.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>L'ambiente di programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/07_environment.html#progetti-in-r",
    "href": "chapters/R/07_environment.html#progetti-in-r",
    "title": "13  L’ambiente di programmazione in R",
    "section": "\n13.4 Progetti in R",
    "text": "13.4 Progetti in R\nSe hai seguito i consigli finora, avrai creato una cartella per tutti i tuoi progetti di programmazione e la tua installazione di R sarà aggiornata. Ora è il momento di organizzare i tuoi progetti in R.\n\n13.4.1 Percorsi Assoluti e Relativi\nUn percorso assoluto parte dalla directory principale del tuo computer (ad esempio, / su Linux/MacOS o C:/ su Windows) e indica in modo completo e univoco la posizione di un file o di una cartella. Un percorso relativo, invece, parte dalla directory corrente del progetto o dalla directory di lavoro impostata e descrive la posizione di un file in relazione a questa.\nAd esempio, il percorso assoluto del file utilizzato per generare questa pagina HTML potrebbe essere ottenuto così:\n\nfs::path_abs(\"05_environment.qmd\")\n#&gt; /Users/corradocaudek/_repositories/psicometria-r/chapters/R/05_environment.qmd\n\nSe il progetto si trova nella cartella psicometria-r, possiamo utilizzare la funzione here() del pacchetto here per indicare la posizione del file 05_environment.qmd in modo relativo. Ecco un esempio:\nfile.exists(here::here(\"chapters\", \"R\", \"05_environment.qmd\"))\nIn questo caso, il file 05_environment.qmd è contenuto nella cartella chapters/R, che si trova all’interno della directory principale del progetto. Grazie a here(), non è necessario specificare manualmente la posizione del progetto: questa funzione identifica automaticamente la directory principale e consente di indicare solo il percorso relativo del file rispetto ad essa. In altre parole, puoi riferirti al file 05_environment.qmd semplicemente fornendo il percorso relativo all’interno della struttura del progetto, lasciando a here() il compito di gestire il contesto globale.\n\n13.4.1.1 Perché preferire i percorsi relativi?\nL’utilizzo di percorsi relativi con here() offre numerosi vantaggi:\n\n\nPortabilità: Il codice diventa più semplice da condividere, poiché non dipende dalla struttura delle directory specifica del computer su cui è stato scritto.\n\nOrganizzazione: Favorisce una struttura chiara e coerente all’interno del progetto, rendendo più facile individuare e accedere ai file.\n\nAffidabilità: Riduce il rischio di errori dovuti a percorsi assoluti errati, soprattutto quando il progetto viene spostato o condiviso.\n\n13.4.1.2 Buone pratiche\n\n\nUsare sempre percorsi relativi: Questo assicura che il progetto sia facilmente eseguibile su altri sistemi senza necessità di modifiche ai percorsi.\n\nImpostare una struttura coerente del progetto: Organizzare i file in cartelle ben definite (ad esempio, data, scripts, outputs) facilita l’uso di percorsi relativi.\n\nIn sintesi, specificare i percorsi relativi rispetto alla directory principale del progetto è una buona pratica essenziale per garantire portabilità, organizzazione e riproducibilità del lavoro.\n\n13.4.2 Creare un progetto in R\nUn progetto R è semplicemente una cartella con un file .Rproj. Puoi crearne uno con RStudio o con il pacchetto usethis.\nIn RStudio:\n\nVai su File &gt; New Project.\nSeleziona New Directory &gt; New Project.\nDai un nome al progetto e scegli la sua posizione.\n\nCon usethis:\nusethis::create_project(\"path/alla/cartella\")\nEsempio:\nusethis::create_project(\"/Users/corradocaudek/_repositories\")\nVedremo nel Capitolo 15 come organizzare i file all’interno di un progetto.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>L'ambiente di programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/07_environment.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/R/07_environment.html#informazioni-sullambiente-di-sviluppo",
    "title": "13  L’ambiente di programmazione in R",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] see_0.9.0        gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1\n#&gt;  [5] psych_2.4.12     scales_1.3.0     markdown_1.13    knitr_1.49      \n#&gt;  [9] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [13] purrr_1.0.2      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [17] ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.3         crayon_1.5.3      rlang_1.1.4      \n#&gt; [17] munsell_0.5.1     withr_3.0.2       yaml_2.3.10       tools_4.4.2      \n#&gt; [21] parallel_4.4.2    tzdb_0.4.0        colorspace_2.1-1  pacman_0.5.1     \n#&gt; [25] vctrs_0.6.5       R6_2.5.1          lifecycle_1.0.4   fs_1.6.5         \n#&gt; [29] htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.0     gtable_0.3.6     \n#&gt; [33] glue_1.8.0        xfun_0.49         tidyselect_1.2.1  farver_2.1.2     \n#&gt; [37] htmltools_0.5.8.1 nlme_3.1-166      rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "R",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>L'ambiente di programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/07_environment.html#bibliografia",
    "href": "chapters/R/07_environment.html#bibliografia",
    "title": "13  L’ambiente di programmazione in R",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nYu, B., & Barter, R. L. (2024). Veridical data science: The practice of responsible data analysis and decision making. MIT Press.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>L'ambiente di programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/08_ai.html",
    "href": "chapters/R/08_ai.html",
    "title": "14  Utilizzo di strumenti AI per la programmazione",
    "section": "",
    "text": "14.1 Introduzione\nIl panorama della programmazione sta vivendo una trasformazione radicale grazie all’avvento degli strumenti di intelligenza artificiale (AI). Questi assistenti innovativi stanno ridefinendo il modo in cui sviluppatori, ricercatori e studenti affrontano la scrittura e la comprensione del codice, con un impatto particolarmente significativo nell’ecosistema di linguaggi come R.\nL’intelligenza artificiale offre una nuova generazione di strumenti che superano i tradizionali ambienti di sviluppo. Piattaforme come ChatGPT, Google Gemini e Claude.ai sono capaci di generare codice, spiegare concetti complessi e supportare gli sviluppatori in modi prima inimmaginabili. Nell’ambiente di R, soluzioni come il pacchetto gptstudio integrano direttamente l’AI in strumenti come RStudio, aprendo nuove possibilità per l’analisi dei dati e lo sviluppo di modelli statistici.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Utilizzo di strumenti AI per la programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/08_ai.html#potenzialità-e-sfide-dellai",
    "href": "chapters/R/08_ai.html#potenzialità-e-sfide-dellai",
    "title": "14  Utilizzo di strumenti AI per la programmazione",
    "section": "14.2 Potenzialità e Sfide dell’AI",
    "text": "14.2 Potenzialità e Sfide dell’AI\nGli strumenti di intelligenza artificiale stanno rivoluzionando la programmazione in R, ma presentano anche alcune sfide. I modelli di linguaggio di grandi dimensioni (LLM) possono accelerare significativamente i flussi di lavoro, ma presentano anche alcune limitazioni intrinseche. Possono generare codice inesatto, introdurre bias involontari o produrre contenuti che richiedono una verifica accurata.\nGli strumenti di intelligenza artificiale possono fornire supporto in molteplici aree:\n\nSupporto Concettuale: Gli LLM si rivelano particolarmente utili nell’affrontare domande complesse relative a metodi statistici, algoritmi e approcci di analisi dei dati. La qualità delle risposte migliora significativamente quando le domande vengono formulate in modo chiaro e dettagliato.\nGenerazione e Completamento del Codice: Questi strumenti possono assistere gli sviluppatori nella scrittura di codice, suggerendo completamenti, identificando potenziali errori e persino generando interi script basati su descrizioni testuali.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Utilizzo di strumenti AI per la programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/08_ai.html#panoramica-comparativa-dei-principali-strumenti-ai",
    "href": "chapters/R/08_ai.html#panoramica-comparativa-dei-principali-strumenti-ai",
    "title": "14  Utilizzo di strumenti AI per la programmazione",
    "section": "14.3 Panoramica Comparativa dei Principali Strumenti AI",
    "text": "14.3 Panoramica Comparativa dei Principali Strumenti AI\n\nClaude.ai (Anthropic): Si distingue per l’affidabilità e la coerenza delle risposte. Accessibile tramite un’interfaccia web gratuita, combina una notevole capacità di comprensione contestuale con la generazione efficace di codice, rendendolo uno strumento versatile e intuitivo. -Gemini (Google): Apprezzato per la velocità e la sintesi delle risposte, è particolarmente adatto per chi cerca risultati rapidi. Tuttavia, può talvolta mostrare una mancanza di approfondimento nell’analisi, limitandone l’efficacia per compiti più complessi.\nChatGPT (OpenAI): Riconosciuto come uno standard di riferimento nella qualità delle risposte, si distingue per la capacità di affrontare una vasta gamma di argomenti con precisione. Inoltre, offre flessibilità d’uso grazie all’integrazione con diversi add-in e strumenti di terze parti, ampliandone le potenzialità in vari contesti applicativi.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Utilizzo di strumenti AI per la programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/08_ai.html#considerazioni-etiche-e-pratiche",
    "href": "chapters/R/08_ai.html#considerazioni-etiche-e-pratiche",
    "title": "14  Utilizzo di strumenti AI per la programmazione",
    "section": "14.4 Considerazioni Etiche e Pratiche",
    "text": "14.4 Considerazioni Etiche e Pratiche\nL’adozione di strumenti di intelligenza artificiale solleva questioni etiche fondamentali che richiedono una riflessione critica:\n\nTrasparenza: I dataset utilizzati per addestrare questi modelli sono spesso opachi e poco documentati, sollevando interrogativi sulla loro composizione e potenziali bias.\nEquità di Accesso: Nonostante le potenzialità rivoluzionarie, l’accesso a questi strumenti non è uniformemente distribuito, creando potenziali disuguaglianze nel mondo della ricerca e dello sviluppo.\nResponsabilità: Rimane poco chiaro come attribuire la responsabilità per i risultati generati da questi sistemi di intelligenza artificiale.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Utilizzo di strumenti AI per la programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/08_ai.html#conclusioni",
    "href": "chapters/R/08_ai.html#conclusioni",
    "title": "14  Utilizzo di strumenti AI per la programmazione",
    "section": "14.5 Conclusioni",
    "text": "14.5 Conclusioni\nGli strumenti AI stanno trasformando la programmazione, offrendo un supporto senza precedenti per la risoluzione di problemi complessi e la generazione di codice. Tuttavia, il loro utilizzo deve essere accompagnato da un approccio critico per verificare i risultati e valutare le implicazioni etiche.\nL’intelligenza artificiale non sostituirà gli sviluppatori, ma si affermerà come un alleato indispensabile per ampliare la creatività e le competenze umane, ridefinendo il modo in cui affrontiamo le sfide del futuro (Bonnefon et al., 2024; Liu & Li, 2024).",
    "crumbs": [
      "R",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Utilizzo di strumenti AI per la programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/08_ai.html#bibliografia",
    "href": "chapters/R/08_ai.html#bibliografia",
    "title": "14  Utilizzo di strumenti AI per la programmazione",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBonnefon, J.-F., Rahwan, I., & Shariff, A. (2024). The moral psychology of Artificial Intelligence. Annual Review of Psychology, 75(1), 653–675.\n\n\nLiu, J., & Li, S. (2024). Toward Artificial Intelligence-Human Paired Programming: A Review of the Educational Applications and Research on Artificial Intelligence Code-Generation Tools. Journal of Educational Computing Research, 07356331241240460.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Utilizzo di strumenti AI per la programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/eda/introduction_eda.html",
    "href": "chapters/eda/introduction_eda.html",
    "title": "EDA",
    "section": "",
    "text": "Dopo aver acquisito un dataset, è fondamentale comprendere a fondo le caratteristiche dei dati in esso contenuti. Sebbene le statistiche descrittive e altre misure numeriche siano spesso efficaci per ottenere una visione d’insieme, talvolta è un’immagine a valere più di mille parole.\nIn questa sezione della dispensa, esploreremo alcuni concetti chiave della statistica descrittiva. Oltre a fornire definizioni teoriche, presenteremo istruzioni pratiche in R per condurre analisi statistiche su dati reali. Il capitolo si concluderà con una riflessione critica sui limiti di un approccio epistemologico basato esclusivamente sull’analisi delle associazioni tra variabili, evidenziando l’importanza di indagare le cause sottostanti ai fenomeni osservati.",
    "crumbs": [
      "EDA"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html",
    "href": "chapters/eda/01_project_structure.html",
    "title": "15  Le fasi del progetto di analisi dei dati",
    "section": "",
    "text": "15.1 Introduzione\nUna gestione accurata ed efficace dei dati è fondamentale, soprattutto in discipline come la psicologia, dove l’analisi di dataset complessi è una componente centrale della ricerca. Assicurare che i dati siano raccolti con precisione, organizzati in modo chiaro e facilmente accessibili per analisi e verifiche è essenziale per preservare l’integrità del lavoro scientifico e promuovere la sua riproducibilità. Una gestione rigorosa dei dati garantisce qualità e affidabilità durante tutte le fasi del progetto, dalla raccolta alla documentazione dei processi di elaborazione e delle eventuali modifiche apportate.\nDati ben organizzati e documentati non solo semplificano e rendono più efficiente il processo di analisi, ma riducono anche il rischio di errori, migliorando l’utilizzabilità e l’interpretazione delle informazioni. Questo aspetto è particolarmente rilevante quando si lavora con dataset provenienti da fonti eterogenee o con strutture complesse. Inoltre, la trasparenza e la completezza nella gestione dei dati rappresentano una condizione imprescindibile per garantire la riproducibilità della ricerca, pilastro fondamentale della scienza.\nLa possibilità per altri ricercatori di replicare i risultati utilizzando gli stessi dati e metodi rafforza la credibilità delle conclusioni e contribuisce a costruire un progresso scientifico condiviso e solido. Una gestione dei dati responsabile, dunque, non è solo una buona pratica, ma una necessità per la produzione di conoscenze affidabili e sostenibili.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#capacità-di-gestione-dei-dati-in-r",
    "href": "chapters/eda/01_project_structure.html#capacità-di-gestione-dei-dati-in-r",
    "title": "15  Le fasi del progetto di analisi dei dati",
    "section": "\n15.2 Capacità di Gestione dei Dati in R",
    "text": "15.2 Capacità di Gestione dei Dati in R\nR è uno strumento potente e versatile, progettato per supportare ogni fase del ciclo di vita dei dati, dalla raccolta alla documentazione, rendendolo indispensabile per chiunque lavori con dati complessi.\n\n\nImportazione ed esportazione dei dati: Con pacchetti come readr e rio, R facilita l’importazione di dati da diverse fonti, tra cui file CSV, database e API web, e consente l’esportazione in formati adatti a diversi utilizzi.\n\nPulizia e preparazione dei dati: Pacchetti come dplyr, tidyr e stringr offrono strumenti intuitivi e potenti per manipolare, trasformare e preparare i dati in modo efficiente, rendendoli pronti per l’analisi.\n\nEsplorazione e sintesi: R, attraverso pacchetti come dplyr e ggplot2, permette di calcolare statistiche descrittive, individuare pattern significativi e visualizzare distribuzioni e relazioni in modo chiaro e informativo.\n\nDocumentazione dinamica: Grazie a strumenti come R Markdown e Quarto, è possibile creare documenti interattivi che integrano codice, analisi, testo esplicativo e risultati, promuovendo la riproducibilità e la trasparenza del lavoro.\n\nControllo delle versioni: L’integrazione di Git in RStudio offre un sistema di gestione delle versioni che consente di monitorare modifiche, collaborare con altri e garantire la tracciabilità del processo analitico.\n\nQueste funzionalità rendono R uno strumento essenziale per gestire i dati in modo organizzato, trasparente e ottimale, facilitando analisi rigorose e riproducibili.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#configurare-lambiente-r",
    "href": "chapters/eda/01_project_structure.html#configurare-lambiente-r",
    "title": "15  Le fasi del progetto di analisi dei dati",
    "section": "\n15.3 Configurare l’Ambiente R",
    "text": "15.3 Configurare l’Ambiente R\nPer sfruttare al meglio le potenzialità di R, è essenziale configurare correttamente RStudio e integrare i pacchetti fondamentali per la gestione dei dati. Una configurazione adeguata favorisce la riproducibilità e l’organizzazione del lavoro.\n\n15.3.1 Workspace e Cronologia\nAccedi a Tools &gt; Global Options &gt; General e modifica le seguenti impostazioni:\n\nDisabilita l’opzione Restore .RData into workspace at startup.\n\nImposta Save workspace to .RData on exit su Never.\n\nQueste configurazioni incoraggiano una gestione basata sugli script, rendendo il lavoro più trasparente e riducendo conflitti tra sessioni diverse. Ogni analisi sarà così chiaramente documentata nello script, evitando dipendenze da file temporanei o precedenti sessioni.\n\n15.3.2 Pacchetti Essenziali\nR è composto da un modulo base che fornisce le funzionalità fondamentali del linguaggio, ma la sua potenza deriva dall’enorme ecosistema di pacchetti aggiuntivi. Questi pacchetti possono essere caricati secondo necessità. Per questo corso, utilizzeremo regolarmente i seguenti pacchetti:\n\n\nhere: per una gestione ordinata dei percorsi relativi, evitando problemi legati ai percorsi assoluti.\n\n\ntidyverse: una raccolta di pacchetti per manipolazione, analisi e visualizzazione dei dati, che include dplyr, tidyr, ggplot2 e altri strumenti indispensabili.\n\nAssicurati di installarli e caricarli all’inizio di ogni script con i comandi:\n# install.packages(c(\"here\", \"tidyverse\")) \n# è solo necessario installarli una volta\nlibrary(here)\nlibrary(tidyverse)\n\n15.3.3 Gestione dei Progetti\nI progetti in RStudio rappresentano uno strumento chiave per mantenere il lavoro organizzato. Utilizzare i progetti consente di lavorare in ambienti separati, dove ogni progetto ha la propria directory dedicata.\nPer creare un nuovo progetto:\n\nVai su File &gt; New Project.\n\nSeleziona una directory specifica per il progetto.\n\nSalva tutti i file correlati (script, dati, risultati) all’interno della directory del progetto.\n\nQuesto approccio facilita la navigazione e previene errori derivanti dall’uso di file non correlati. Ogni progetto diventa così un’unità autonoma, ideale per mantenere ordine e coerenza nel lavoro.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#il-ciclo-di-vita-di-un-progetto-di-data-science",
    "href": "chapters/eda/01_project_structure.html#il-ciclo-di-vita-di-un-progetto-di-data-science",
    "title": "15  Le fasi del progetto di analisi dei dati",
    "section": "\n15.4 Il Ciclo di Vita di un Progetto di Data Science",
    "text": "15.4 Il Ciclo di Vita di un Progetto di Data Science\nI progetti di analisi dei dati seguono solitamente queste fasi (Yu & Barter, 2024):\n\n\nFormulazione del problema e raccolta dei dati: Definizione delle domande di ricerca e acquisizione dei dataset.\n\nPulizia, preprocessing e analisi esplorativa: Preparazione dei dati per l’analisi attraverso trasformazioni e sintesi.\n\nAnalisi predittiva e/o inferenziale: (Opzionale) Modelli statistici o predittivi per rispondere alle domande di ricerca.\n\nValutazione dei risultati: Interpretazione e verifica delle conclusioni tratte.\n\nComunicazione dei risultati: Presentazione dei risultati in forma visiva e narrativa.\n\nNon tutti i progetti includono la fase 3, ma quasi tutti attraversano le altre fasi, rendendo essenziale un approccio organizzato e ben strutturato.\n\n15.4.1 Fase 1: Formulazione del Problema e Raccolta dei Dati\nLa formulazione di una domanda di ricerca chiara e precisa è il primo passo per qualsiasi progetto di data science. È fondamentale che la domanda sia costruita in modo tale da poter essere risolta tramite l’analisi dei dati disponibili. Spesso, la domanda iniziale può risultare troppo vaga o irrealizzabile, rendendo necessario un processo di revisione per adattarla alle informazioni a disposizione. Questo approccio assicura che i dati raccolti o utilizzati siano adeguati per rispondere efficacemente al problema di ricerca.\nLa raccolta dei dati rappresenta una fase altrettanto cruciale del processo. In alcuni casi, i progetti sfruttano dati esistenti provenienti da repository pubblici, database interni o esperimenti passati; in altri, è necessaria una nuova raccolta di dati. Per evitare problematiche future, è essenziale pianificare con attenzione le analisi statistiche da effettuare prima di raccogliere i dati. In assenza di questa pianificazione, si rischia di ottenere dataset inadatti, privi di informazioni cruciali o non conformi alle assunzioni richieste dai modelli statistici previsti.\nUn altro aspetto chiave della raccolta dei dati è comprendere appieno i processi e le metodologie utilizzate per acquisirli. È fondamentale analizzare e documentare le tecniche impiegate, le procedure seguite e i potenziali bias che potrebbero influenzare i risultati. Questa consapevolezza contribuisce a garantire che le misure ottenute siano affidabili e che eventuali limitazioni siano considerate durante l’analisi.\n\n15.4.2 Fase 2: Pulizia dei Dati e Analisi Esplorativa\n\n15.4.2.1 Importazione ed Esportazione dei dati in R\nImportazione dei Dati\nIn R, i dati vengono solitamente caricati in un data frame. Per facilitare questo processo, il pacchetto rio fornisce la funzione universale import(), che consente di caricare dati da formati diversi (come .csv, .xlsx, .json, ecc.) senza dover usare funzioni specifiche per ogni tipo di file.\nPer garantire un’organizzazione ottimale dei file, è utile:\n\nCreare una struttura di progetto chiara, con cartelle dedicate (es. data/raw per i dati grezzi e data/processed per quelli elaborati).\n\nUsare percorsi relativi, che rendono i progetti portabili e più facilmente replicabili.\n\nIl pacchetto here semplifica la gestione dei percorsi relativi, assicurando che il codice funzioni correttamente indipendentemente dalla posizione del progetto.\nSupponiamo di avere un progetto chiamato my_project con la seguente struttura:\nmy_project/\n├── my_project.Rproj\n├── data/\n│   ├── raw/\n│   │   └── my_data.csv\n│   ├── processed/\nPer importare il file my_data.csv nella memoria di lavoro di R, possiamo usare:\nlibrary(here)\nlibrary(rio)\n\n# Importazione del file\ndf &lt;- import(here(\"data\", \"raw\", \"my_data.csv\"))\nEsportazione dei Dati\nDopo aver elaborato i dati, è importante salvarli in modo organizzato. Con il pacchetto rio, l’esportazione si effettua tramite export(). Ad esempio, per salvare un file elaborato nella cartella data/processed:\n# Esportazione del file elaborato\nexport(df, here(\"data\", \"processed\", \"my_data_processed.csv\"))\nVantaggi di un Workflow Organizzato\n\n\nPortabilità: Usando percorsi relativi con here, il progetto può essere spostato su diversi computer o condiviso senza necessità di modificare il codice.\n\n\nSemplificazione: rio elimina la necessità di ricordare funzioni specifiche per diversi tipi di file.\n\n\nRiproducibilità: Una struttura chiara e un codice ben organizzato favoriscono la replicabilità dei risultati.\n\n15.4.2.2 Pulizia dei Dati\nDopo aver definito la domanda della ricerca e avere raccolto i dati rilevanti, è il momento di pulire i dati. Un dataset pulito è ordinato, formattato in modo appropriato e ha voci non ambigue. La fase iniziale di pulizia dei dati consiste nell’identificare problemi con i dati (come formattazioni anomale e valori non validi) e modificarli in modo che i valori siano validi e formattati in modo comprensibile sia per il computer che per noi. La pulizia dei dati è una fase estremamente importante di un progetto di data science perché non solo aiuta a garantire che i dati siano interpretati correttamente dal computer, ma aiuta anche a sviluppare una comprensione dettagliata delle informazioni contenute nei dati e delle loro limitazioni.\nL’obiettivo della pulizia dei dati è creare una versione dei dati che rifletta nella maniera più fedele possibile la realtà e che sia interpretata correttamente dal computer. Per garantire che il computer utilizzi fedelmente le informazioni contenute nei dati, è necessario modificare i dati (scrivendo codice, non modificando il file dati grezzo stesso) in modo che siano in linea con ciò che il computer “si aspetta”. Tuttavia, il processo di pulizia dei dati è necessariamente soggettivo e comporta fare assunzioni sulle quantità reali sottostanti misurate e decisioni su quali modifiche siano le più sensate.\n\n15.4.2.3 Preprocessing\nIl preprocessing si riferisce al processo di modifica dei dati puliti per soddisfare i requisiti di un algoritmo specifico che si desidera applicare. Ad esempio, se si utilizza un algoritmo che richiede che le variabili siano sulla stessa scala, potrebbe essere necessario trasformarle, oppure, se si utilizza un algoritmo che non consente valori mancanti, potrebbe essere necessario imputarli o rimuoverli. Durante il preprocessing, potrebbe essere utile anche definire nuove caratteristiche/variabili utilizzando le informazioni esistenti nei dati, se si ritiene che queste possano essere utili per l’analisi.\nCome per la pulizia dei dati, non esiste un unico modo corretto per pre-elaborare un dataset, e la procedura finale comporta tipicamente una serie di decisioni che dovrebbero essere documentate nel codice e nei file di documentazione.\n\n15.4.2.4 Analisi Esplorativa dei Dati\nDopo l’acquisizione dei dati, si procede con un’Analisi Esplorativa dei Dati (EDA - Exploratory Data Analysis). Questa fase iniziale mira a far familiarizzare il ricercatore con il dataset e a scoprire pattern nascosti. Si realizza attraverso:\n\nLa costruzione di tabelle di frequenza e contingenza.\nIl calcolo di statistiche descrittive (come indici di posizione, dispersione e forma della distribuzione).\nLa creazione di rappresentazioni grafiche preliminari.\n\nL’EDA permette di generare ipotesi sui dati e di guidare le successive analisi statistiche.\n\n15.4.3 Fase 3: Analisi Predittiva e Inferenziale\nMolte domande nella data science si presentano come problemi di inferenza e/o previsione, in cui l’obiettivo principale è utilizzare dati osservati, passati o presenti, per descrivere le caratteristiche di una popolazione più ampia o per fare previsioni su dati futuri non ancora disponibili. Questo tipo di analisi è spesso orientato a supportare decisioni nel mondo reale.\n\n15.4.4 Fase 4: Valutazione dei Risultati\nIn questa fase, i risultati ottenuti vengono analizzati alla luce della domanda di ricerca iniziale. Si procede a una valutazione sia quantitativa, attraverso l’applicazione di tecniche statistiche appropriate, sia qualitativa, attraverso un’attenta riflessione critica.\n\n15.4.5 Fase 5: Comunicazione dei Risultati\nL’ultima fase di un progetto di analisi dei dati consiste nel condividere i risultati con un pubblico più ampio, il che richiede la preparazione di materiali comunicativi chiari e concisi. L’obiettivo è trasformare i risultati dell’analisi in informazioni utili per supportare il processo decisionale. Questo può includere la stesura di un articolo scientifico, la creazione di un report per un team di lavoro, o la preparazione di una presentazione con diapositive.\nLa comunicazione deve essere adattata al pubblico di riferimento. Non si deve dare per scontato che il pubblico abbia familiarità con il progetto: è fondamentale spiegare l’analisi e le visualizzazioni in modo chiaro e dettagliato. Anche se per il ricercatore il messaggio principale di una figura o diapositiva può sembrare ovvio, è sempre una buona pratica guidare il pubblico nella sua interpretazione, evitando l’uso di gergo tecnico complesso.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#organizzazione-del-progetto",
    "href": "chapters/eda/01_project_structure.html#organizzazione-del-progetto",
    "title": "15  Le fasi del progetto di analisi dei dati",
    "section": "\n15.5 Organizzazione del Progetto",
    "text": "15.5 Organizzazione del Progetto\nUn requisito fondamentale per un progetto di analisi dei dati è organizzare in modo efficiente i file sul proprio computer. Questo include i file dei dati, il codice e la documentazione del progetto. Tutti questi elementi dovrebbero essere raccolti all’interno di una singola cartella dedicata al progetto.\n\n15.5.1 Home Directory\nIn RStudio, è possibile creare un file chiamato nome_del_progetto.Rproj, che consente di configurare automaticamente la home directory del progetto, ovvero la cartella principale da cui R avvia il lavoro relativo al progetto. Per utilizzare questa funzionalità, è sufficiente aprire RStudio cliccando direttamente sul file nome_del_progetto.Rproj.\nLa home directory rappresenta il punto di riferimento principale per tutte le operazioni del progetto, come il caricamento di file, il salvataggio degli output e la gestione delle risorse.\nGrazie a questa configurazione, è possibile utilizzare percorsi relativi per accedere ai file all’interno del progetto. I percorsi relativi si basano sempre sulla cartella principale del progetto, il che rende il codice più portabile e adattabile. In pratica, chiunque scarichi il tuo progetto sarà in grado di eseguirlo senza dover modificare manualmente i percorsi dei file. Questo approccio migliora la condivisione e garantisce una maggiore riproducibilità del tuo lavoro.\n\n15.5.2 Struttura di un Progetto\nUn’adeguata organizzazione della struttura di un progetto è fondamentale per garantire chiarezza, riproducibilità e portabilità. Yu & Barter (2024) propone il seguente template per la gestione di un progetto:\n\n\n15.5.2.1 Cartelle Principali\n\n\n\ndata/:\nQuesta cartella raccoglie i dataset utilizzati nel progetto, suddivisi in:\n\n\nraw/: per i dati grezzi, che non devono mai essere modificati. Esempio: data/raw/data.csv.\n\n\nprocessed/: per i dati elaborati, cioè quelli puliti e trasformati per le analisi successive.\n\nÈ indispensabile includere un codebook nella sottocartella raw per documentare variabili, unità di misura e ogni altra informazione necessaria per comprendere i dati. Questo migliora la trasparenza e facilita la condivisione del progetto.\n\n\ndslc_documentation/:\nContiene tutti i file necessari per documentare e condurre le analisi.\n\nFile principali: possono essere in formato .qmd (Quarto per R) o .ipynb (Jupyter Notebook per Python), ordinati cronologicamente tramite un prefisso numerico (ad esempio, 01_data_cleaning.qmd, 02_analysis.qmd).\n\n\nfunctions/: una sottocartella dedicata a script con funzioni personalizzate, utili per diverse fasi del progetto. Ad esempio, .R per R o .py per Python.\n\n\n\n\n15.5.2.2 File Supplementari\n\n\n\nREADME.md:\nUn file fondamentale che descrive la struttura del progetto e offre una breve panoramica del contenuto di ogni cartella e file. Deve includere:\n\nLo scopo del progetto.\n\nUna spiegazione della struttura delle cartelle.\n\nI passaggi necessari per replicare le analisi.\n\n\n\n\n15.5.2.3 Vantaggi della Struttura Proposta\n\n\nOrganizzazione Chiara:\nSeparare i dati grezzi da quelli elaborati riduce il rischio di modificare accidentalmente le versioni originali.\nRiproducibilità:\nLa documentazione completa (codebook, file analitici e README) facilita la comprensione e la riproduzione del progetto anche a distanza di tempo o da parte di altri utenti.\nPortabilità:\nUtilizzando percorsi relativi (ad esempio, con il pacchetto here in R), l’intero progetto può essere facilmente trasferito tra utenti o computer senza modificare il codice.\nEfficienza:\nLa sottocartella functions/ consente di riutilizzare codice in più parti del progetto, migliorando la modularità e riducendo la duplicazione di script.\n\nIn conclusione, l’organizzazione del progetto secondo questo template garantisce non solo un flusso di lavoro ordinato e ben documentato, ma anche la possibilità di condividere facilmente il progetto con colleghi o team. Adottare questa struttura è un primo passo essenziale verso un’analisi dati rigorosa e riproducibile.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#riflessioni-conclusive",
    "href": "chapters/eda/01_project_structure.html#riflessioni-conclusive",
    "title": "15  Le fasi del progetto di analisi dei dati",
    "section": "\n15.6 Riflessioni Conclusive",
    "text": "15.6 Riflessioni Conclusive\nLa forza e la bellezza del codice risiedono nella sua riusabilità: una volta scritto, può essere applicato infinite volte per ottenere risultati coerenti. Se configurato correttamente, lo stesso codice applicato agli stessi dati produrrà sempre gli stessi risultati. Questo principio, noto come riproducibilità computazionale, è fondamentale per garantire la trasparenza e l’affidabilità del lavoro scientifico.\nLa riproducibilità offre numerosi vantaggi:\n\nMonitorare le modifiche del progetto\nLa possibilità di riprodurre il lavoro semplifica il monitoraggio delle evoluzioni e dei cambiamenti nel progetto. Questo consente di comprendere come il progetto si è sviluppato nel tempo, facilitando il confronto tra diverse versioni o approcci.\nRiprodurre il proprio lavoro\nIl primo beneficiario della riproducibilità sei tu stesso. Essere in grado di replicare i propri risultati è essenziale, soprattutto se in futuro sarà necessario rivedere o approfondire il lavoro. La riproducibilità garantisce che le analisi possano essere riprese con facilità e senza ambiguità.\nCostruire su basi solide\nAltri ricercatori possono utilizzare il tuo lavoro come punto di partenza, espandendolo o applicandolo a nuovi contesti. La condivisione di codice riproducibile non solo favorisce la collaborazione, ma contribuisce a creare un corpo di conoscenze più robusto e condiviso.\n\nTuttavia, rendere il codice riproducibile non è sempre semplice. Richiede attenzione nella documentazione, un’organizzazione chiara del progetto e strumenti adeguati per garantire che l’ambiente di lavoro sia stabile e replicabile. In questo capitolo, abbiamo esplorato alcune strategie e tecniche per raggiungere questi obiettivi.\n\n\n\n\n\n\nUn problema cruciale nella psicologia contemporanea è la crisi di replicabilità, che evidenzia come molti risultati di ricerca non siano replicabili (Collaboration, 2015). La riproducibilità computazionale, pur avendo un obiettivo più ristretto, si concentra sulla possibilità di ottenere gli stessi risultati applicando lo stesso codice agli stessi dati. Questo approccio, sebbene non risolva interamente la crisi, rappresenta un passo fondamentale verso una scienza più trasparente e rigorosa.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/01_project_structure.html#informazioni-sullambiente-di-sviluppo",
    "title": "15  Le fasi del progetto di analisi dei dati",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] see_0.9.0        gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1\n#&gt;  [5] psych_2.4.12     scales_1.3.0     markdown_1.13    knitr_1.49      \n#&gt;  [9] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [13] purrr_1.0.2      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [17] ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.3         rlang_1.1.4       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       yaml_2.3.10       tools_4.4.2       parallel_4.4.2   \n#&gt; [21] tzdb_0.4.0        colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5      \n#&gt; [25] R6_2.5.1          lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3  \n#&gt; [29] pillar_1.10.0     gtable_0.3.6      glue_1.8.0        xfun_0.49        \n#&gt; [33] tidyselect_1.2.1  farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-166     \n#&gt; [37] rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#bibliografia",
    "href": "chapters/eda/01_project_structure.html#bibliografia",
    "title": "15  Le fasi del progetto di analisi dei dati",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nCollaboration, O. S. (2015). Estimating the reproducibility of psychological science. Science, 349(6251), aac4716.\n\n\nYu, B., & Barter, R. L. (2024). Veridical data science: The practice of responsible data analysis and decision making. MIT Press.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html",
    "href": "chapters/eda/02_data_cleaning.html",
    "title": "16  Flusso di lavoro per la pulizia dei dati",
    "section": "",
    "text": "16.1 Introduzione\nNonostante la fase più interessante di un progetto di analisi dei dati sia quella in cui si riesce a rispondere alla domanda che ha dato avvio all’indagine, gran parte del tempo di un analista è in realtà dedicata a una fase preliminare: la pulizia e il preprocessing dei dati, operazioni che vengono svolte ancor prima dell’analisi esplorativa.\nIn questo capitolo, esamineremo un caso concreto di data cleaning e preprocessing, seguendo il tutorial di Crystal Lewis. Il problema viene presentato come segue:\nCrystal Lewis elenca i seguenti passaggi da seguire nel processo di data cleaning:\nSebbene l’ordine di questi passaggi sia flessibile e possa essere adattato alle esigenze specifiche, c’è un passaggio che non dovrebbe mai essere saltato: il primo, ovvero la revisione dei dati. Senza una revisione preliminare, l’analista rischia di sprecare ore a pulire i dati per poi scoprire che mancano dei partecipanti, che i dati non sono organizzati come previsto o, peggio ancora, che si sta lavorando con i dati sbagliati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#introduzione",
    "href": "chapters/eda/02_data_cleaning.html#introduzione",
    "title": "16  Flusso di lavoro per la pulizia dei dati",
    "section": "",
    "text": "I am managing data for a longitudinal randomized controlled trial (RCT) study. For this RCT, schools are randomized to either a treatment or control group. Students who are in a treatment school receive a program to boost their math self-efficacy. Data is collected on all students in two waves (wave 1 is in the fall of a school year, and wave 2 is collected in the spring). At this point in time, we have collected wave 1 of our student survey on a paper form and we set up a data entry database for staff to enter the information into. Data has been double-entered, checked for entry errors, and has been exported in a csv format (“w1_mathproj_stu_svy_raw.csv”) to a folder (called “data”) where it is waiting to be cleaned.\n\n\n\nRevisione dei dati.\nRegolazione del numero di casi.\nDe-identificazione dei dati.\nEliminazione delle colonne irrilevanti.\nDivisione delle colonne, se necessario.\nRidenominazione delle variabili.\nTrasformazione/normalizzazione delle variabili.\nStandardizzazione delle variabili.\nAggiornamento dei tipi di variabili, se necessario.\nRicodifica delle variabili.\nCreazione di eventuali variabili necessarie.\nGestione dei valori mancanti, se necessario.\nAggiunta di metadati, se necessario.\nValidazione dei dati.\nFusione e/o unione dei dati, se necessario.\nTrasformazione dei dati, se necessario.\nSalvataggio dei dati puliti.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#tutorial",
    "href": "chapters/eda/02_data_cleaning.html#tutorial",
    "title": "16  Flusso di lavoro per la pulizia dei dati",
    "section": "\n16.2 Tutorial",
    "text": "16.2 Tutorial\nQuesto tutorial segue i passaggi descritti da Crystal Lewis per illustrare le buone pratiche nella gestione e pulizia dei dati.\n\n16.2.1 Organizzazione dei Dati\nUn principio fondamentale nella gestione dei dati è preservare l’integrità dei dati grezzi. I dati originali non devono mai essere modificati direttamente. È quindi consigliabile strutturare i dati in una directory denominata data, suddivisa in due sottocartelle:\n\n\nraw: contiene i dati originali, mantenuti inalterati.\n\n\nprocessed: destinata ai dati ripuliti e preprocessati.\n\nAd esempio, importiamo i dati da un file denominato w1_mathproj_stu_svy_raw.csv per avviare il processo di pulizia. Tutte le operazioni dovranno essere effettuate utilizzando percorsi relativi alla home directory del progetto, che definiremo come primo passo.\n\n16.2.2 Passaggi del Tutorial\n\n16.2.2.1 Importare e Esaminare i Dati\nImportiamo i dati utilizzando la funzione import() della libreria rio e visualizziamo i primi valori di ciascuna colonna per verificarne la corretta importazione:\n\n# Importa i dati\nsvy &lt;- rio::import(here::here(\"data\", \"w1_mathproj_stu_svy_raw.csv\"))\n\n# Esamina la struttura del dataset\nglimpse(svy)\n#&gt; Rows: 6\n#&gt; Columns: 7\n#&gt; $ stu_id      &lt;int&gt; 1347, 1368, 1377, 1387, 1347, 1399\n#&gt; $ svy_date    &lt;IDate&gt; 2023-02-13, 2023-02-13, 2023-02-13, 2023-02-13, 2023-0…\n#&gt; $ grade_level &lt;int&gt; 9, 10, 9, 11, 9, 12\n#&gt; $ math1       &lt;int&gt; 2, 3, 4, 3, 2, 4\n#&gt; $ math2       &lt;chr&gt; \"1\", \"2\", \"\\n4\", \"3\", \"2\", \"1\"\n#&gt; $ math3       &lt;int&gt; 3, 2, 4, NA, 4, 3\n#&gt; $ math4       &lt;int&gt; 3, 2, 4, NA, 2, 1\n\nPer controllare visivamente i dati, possiamo esaminare le prime e le ultime righe del data frame:\n\n# Visualizza le prime righe\nsvy |&gt; \n  head()\n#&gt;   stu_id   svy_date grade_level math1 math2 math3 math4\n#&gt; 1   1347 2023-02-13           9     2     1     3     3\n#&gt; 2   1368 2023-02-13          10     3     2     2     2\n#&gt; 3   1377 2023-02-13           9     4   \\n4     4     4\n#&gt; 4   1387 2023-02-13          11     3     3    NA    NA\n#&gt; 5   1347 2023-02-14           9     2     2     4     2\n#&gt; 6   1399 2023-02-14          12     4     1     3     1\n\n# Visualizza le ultime righe\nsvy |&gt; \n  tail()\n#&gt;   stu_id   svy_date grade_level math1 math2 math3 math4\n#&gt; 1   1347 2023-02-13           9     2     1     3     3\n#&gt; 2   1368 2023-02-13          10     3     2     2     2\n#&gt; 3   1377 2023-02-13           9     4   \\n4     4     4\n#&gt; 4   1387 2023-02-13          11     3     3    NA    NA\n#&gt; 5   1347 2023-02-14           9     2     2     4     2\n#&gt; 6   1399 2023-02-14          12     4     1     3     1\n\n\n16.2.2.2 Individuare e Rimuovere i Duplicati\nIn questa fase, eseguiamo alcune modifiche necessarie al data frame, come rimuovere duplicati e ordinare i dati:\n\n\nVerifica duplicati: controlliamo i record duplicati nel dataset.\n\nRimuovi duplicati: manteniamo solo la prima occorrenza.\n\nOrdina per data: organizziamo i record in ordine crescente rispetto alla variabile svy_date.\n\nEsamina i dati puliti: controlliamo il risultato delle modifiche.\n\n\n# Identifica i duplicati basati su 'stu_id'\nduplicates &lt;- \n  svy[duplicated(svy$stu_id) | duplicated(svy$stu_id, fromLast = TRUE), ]\n\n\n# Visualizza i duplicati trovati\nduplicates\n#&gt;   stu_id   svy_date grade_level math1 math2 math3 math4\n#&gt; 1   1347 2023-02-13           9     2     1     3     3\n#&gt; 5   1347 2023-02-14           9     2     2     4     2\n\n\n# Ordina per 'svy_date' in ordine crescente\nsvy &lt;- svy[order(svy$svy_date), ]\n\n\n# Rimuove i duplicati mantenendo la prima occorrenza\nsvy &lt;- svy[!duplicated(svy$stu_id), ]\n\n\n# Esamina il dataset finale\nprint(svy)\n#&gt;   stu_id   svy_date grade_level math1 math2 math3 math4\n#&gt; 1   1347 2023-02-13           9     2     1     3     3\n#&gt; 2   1368 2023-02-13          10     3     2     2     2\n#&gt; 3   1377 2023-02-13           9     4   \\n4     4     4\n#&gt; 4   1387 2023-02-13          11     3     3    NA    NA\n#&gt; 6   1399 2023-02-14          12     4     1     3     1\n\nVerifichiamo le dimensioni del dataset pulito per assicurarci che le operazioni siano state eseguite correttamente:\n\n# Controlla il numero di righe e colonne\nsvy |&gt; \n  dim()\n#&gt; [1] 5 7\n\n\n16.2.2.3 De-identificazione dei Dati\n\n# Rimuovi la colonna 'svy_date'\nsvy &lt;- svy |&gt;\n  dplyr::select(-svy_date)\n\n# Mostra i nomi delle colonne rimaste\nnames(svy)\n#&gt; [1] \"stu_id\"      \"grade_level\" \"math1\"       \"math2\"       \"math3\"      \n#&gt; [6] \"math4\"\n\n\n16.2.2.4 Rimuovere le Colonne non Necessarie\nNel caso presente, la rimozione di colonne non è necessaria. Tuttavia, in molti progetti di analisi dei dati, soprattutto quando i dati vengono raccolti utilizzando software di terze parti o strumenti specifici per esperimenti psicologici, è comune trovarsi con colonne che non sono pertinenti allo studio in corso.\nQueste colonne possono includere dati come identificatori interni, timestamp generati automaticamente, informazioni di debug, o variabili che non sono rilevanti per l’analisi che si intende condurre. Quando tali colonne sono irrilevanti per la ricerca, possono essere rimosse per semplificare il dataset e ridurre il rischio di confusione o errori durante l’analisi. Rimuovere le colonne non necessarie non solo rende il dataset più gestibile, ma aiuta anche a focalizzare l’analisi sulle variabili che realmente importano per rispondere alle domande di ricerca.\n\n16.2.2.5 Dividere le Colonne Secondo Necessità\nNel caso presente, questa operazione non è necessaria. Tuttavia, se si lavora con un dataset che include una colonna chiamata “NomeCompleto”, contenente sia il nome che il cognome di uno studente, per esempio, è buona pratica separare questa colonna in due colonne distinte, “Nome” e “Cognome”. Questa suddivisione facilita l’analisi e la manipolazione dei dati, rendendoli più organizzati e accessibili.\n\n16.2.2.6 Rinominare le Colonne\nÈ importante assegnare nomi chiari alle colonne del dataset. Utilizzare nomi di variabili comprensibili aiuta a rendere l’analisi dei dati più intuitiva e a ridurre il rischio di errori interpretativi.\nEsempi di buone pratiche:\n\nEvita nomi di colonne come “x” o acronimi incomprensibili. Questi possono creare confusione durante l’analisi, specialmente se il dataset viene condiviso con altri ricercatori o se viene ripreso dopo un lungo periodo di tempo.\nInvece, cerca di utilizzare nomi di variabili che descrivano chiaramente il contenuto della colonna. Ad esempio, invece di “x1” o “VAR123”, un nome come “ansia_base” o “liv_autoefficacia” è molto più comprensibile e immediato.\nPer i nomi composti, utilizza un separatore come il trattino basso _. Ad esempio, se stai lavorando con dati relativi a un test psicologico, potresti avere colonne chiamate “test_ansia_pre” e “test_ansia_post” per indicare i risultati del test di ansia prima e dopo un intervento.\n\nEsempi di nomi di colonne ben scelti:\n\n\nNome generico: TS, AE\n\n\nNome migliore: tempo_studio, auto_efficacia\n\n\n\n\nNome generico: S1, S2\n\n\nNome migliore: stress_situazione1, stress_situazione2\n\n\n\n\nNome generico: Q1, Q2\n\n\nNome migliore: qualità_sonno_sett1, qualità_sonno_sett2\n\n\n\n\n16.2.2.7 Trasformare le Variabili\nNel caso presente non si applica, ma è un passo importante in molte analisi dei dati.\nEsempi di trasformazione delle variabili:\n\nLogaritmo di una variabile: Immaginiamo di avere una variabile che misura i tempi di reazione dei partecipanti a un esperimento. Se i tempi di reazione hanno una distribuzione fortemente asimmetrica (con alcuni valori molto elevati), potrebbe essere utile applicare una trasformazione logaritmica per rendere la distribuzione più simmetrica e migliorare l’interpretabilità dei risultati.\nCodifica delle variabili categoriche: Se è presente una variabile categorica come il “tipo di intervento” con valori come “cognitivo”, “comportamentale” e “farmacologico”, potrebbe essere necessario trasformare questa variabile in variabili dummy (ad esempio, intervento_cognitivo, intervento_comportamentale, intervento_farmacologico), dove ogni variabile assume il valore 0 o 1 a seconda della presenza o meno di quel tipo di intervento. Questo è utile quando si utilizzano tecniche di regressione.\n\n16.2.2.8 Standardizzazione delle Variabili\nLa standardizzazione è utile quando si desidera rendere comparabili variabili misurate su scale diverse, ad esempio per confronti tra gruppi o per inclusione in modelli di regressione.\nEsempio. Supponiamo di avere una variabile che misura il livello di ansia su una scala da 0 a 100. Per standardizzarla:\n\n\nSottrai la media del campione dalla variabile.\n\n\nDividi per la deviazione standard.\n\nIl risultato è una variabile con media pari a 0 e deviazione standard pari a 1.\nVantaggi della standardizzazione:\n\nfacilita l’interpretazione dei coefficienti in un modello di regressione;\npermette un confronto diretto tra variabili che hanno unità di misura diverse.\n\n16.2.2.9 Normalizzazione delle Variabili\n\nLa normalizzazione consiste nel ridimensionare i dati su una scala predefinita, spesso compresa tra 0 e 1. Questo processo è particolarmente utile in analisi multivariate, dove variabili con scale molto diverse potrebbero influenzare in modo sproporzionato i risultati.\nEsempio. Hai dati su:\n\n\nOre di sonno (misurate in ore, da 0 a 24).\n\n\nLivello di stress (misurato su una scala da 1 a 50).\n\n\nAuto-efficacia (misurata su una scala da 0 a 100).\n\nPer garantire che ogni variabile abbia lo stesso peso nell’analisi, puoi normalizzarle usando una formula come:\n\\[\nx_{\\text{norm}} = \\frac{x - \\text{min}(x)}{\\text{max}(x) - \\text{min}(x)} .\n\\]\nPerché Standardizzare o Normalizzare?\nTrasformare le variabili è cruciale per:\n\n\nGestire scale diverse: Riduce il rischio che variabili con valori numericamente più grandi dominino i risultati.\n\n\nGarantire validità e interpretabilità: Facilita il confronto tra dati provenienti da fonti o gruppi diversi.\n\n\nEvitare problemi numerici nei modelli statistici: Alcuni algoritmi di machine learning o tecniche di ottimizzazione richiedono che i dati siano su scale simili per funzionare correttamente.\n\nIn conclusione, la scelta tra standardizzazione e normalizzazione dipende dal contesto dell’analisi e dagli obiettivi specifici. Entrambi i processi sono strumenti indispensabili per garantire che i dati siano trattati in modo adeguato, portando a risultati robusti e facilmente interpretabili.\n\n16.2.2.10 Aggiornare i Tipi delle Variabili\nNel caso presente non è necessario. Supponiamo invece di avere una colonna in un dataset psicologico che contiene punteggi di un questionario, ma i dati sono stati importati come stringhe (testo) invece che come numeri. Per eseguire calcoli statistici, sarà necessario convertire questa colonna da stringa a numerico.\nIn R, si potrebbe usare il seguente codice:\n\n# Supponiamo di avere un data frame chiamato 'df' con una colonna 'punteggio' importata come carattere\ndf$punteggio &lt;- as.numeric(df$punteggio)\n\n# Ora la colonna 'punteggio' è stata convertita in un tipo numerico ed è possibile eseguire calcoli su di essa\n\nIn questo esempio, la funzione as.numeric() viene utilizzata per convertire la colonna punteggio in un formato numerico, permettendo di eseguire analisi quantitative sui dati.\nUn altro caso molto comune si verifica quando si importano dati da file Excel. Spesso capita che, all’interno di una cella di una colonna che dovrebbe contenere solo valori numerici, venga inserito erroneamente uno o più caratteri alfanumerici. Di conseguenza, l’intera colonna viene interpretata come di tipo alfanumerico, anche se i valori dovrebbero essere numerici. In questi casi, è fondamentale individuare la cella problematica, correggere manualmente il valore errato, e poi riconvertire l’intera colonna da alfanumerica a numerica.\n\n16.2.2.11 Ricodificare le Variabili\nAnche se in questo caso non è necessario, la ricodifica delle variabili è una pratica molto comune nelle analisi dei dati psicologici.\nPer esempio, consideriamo una variabile categoriale con modalità descritte da stringhe poco comprensibili, che vengono ricodificate con nomi più chiari e comprensibili.\nSupponiamo di avere un DataFrame chiamato df con una colonna tipo_intervento che contiene le modalità \"CT\", \"BT\", e \"MT\" per rappresentare rispettivamente “Terapia Cognitiva”, “Terapia Comportamentale” e “Terapia Mista”. Queste abbreviazioni potrebbero non essere immediatamente chiare a chiunque analizzi i dati, quindi decidiamo di ricodificarle con nomi più espliciti. Ecco come farlo in R:\n\n# Tibble chiamato 'df' con una colonna 'tipo_intervento'\ndf &lt;- tibble(tipo_intervento = c(\"CT\", \"BT\", \"MT\", \"CT\", \"BT\"))\ndf\n#&gt; # A tibble: 5 × 1\n#&gt;   tipo_intervento\n#&gt;   &lt;chr&gt;          \n#&gt; 1 CT             \n#&gt; 2 BT             \n#&gt; 3 MT             \n#&gt; 4 CT             \n#&gt; 5 BT\n\n\n# Ricodifica delle modalità della variabile 'tipo_intervento' in nomi più comprensibili\ndf &lt;- df %&gt;%\n  mutate(tipo_intervento_ricodificato = dplyr::recode(\n    tipo_intervento,\n    \"CT\" = \"Terapia Cognitiva\",\n    \"BT\" = \"Terapia Comportamentale\",\n    \"MT\" = \"Terapia Mista\"\n  ))\n\n# Mostra il tibble con la nuova colonna ricodificata\ndf\n#&gt; # A tibble: 5 × 2\n#&gt;   tipo_intervento tipo_intervento_ricodificato\n#&gt;   &lt;chr&gt;           &lt;chr&gt;                       \n#&gt; 1 CT              Terapia Cognitiva           \n#&gt; 2 BT              Terapia Comportamentale     \n#&gt; 3 MT              Terapia Mista               \n#&gt; 4 CT              Terapia Cognitiva           \n#&gt; 5 BT              Terapia Comportamentale\n\n\n16.2.2.12 Aggiungere Nuove Variabili nel Data Frame\nNel caso presente non è richiesto, ma aggiungere nuove variabili a un DataFrame è un’operazione comune durante l’analisi dei dati. Un esempio è il calcolo dell’indice di massa corporea (BMI).\nSupponiamo di avere un DataFrame chiamato df che contiene le colonne peso_kg (peso in chilogrammi) e altezza_m (altezza in metri) per ciascun partecipante a uno studio psicologico. Per arricchire il dataset, possiamo calcolare il BMI per ogni partecipante e aggiungerlo come una nuova variabile.\nIl BMI si calcola con la formula:\n\\[ \\text{BMI} = \\frac{\\text{peso in kg}}{\\text{altezza in metri}^2} .\\]\nEcco come aggiungere la nuova colonna.\n\n# Supponiamo di avere un tibble chiamato 'df' con le colonne 'peso_kg' e 'altezza_m'\ndf &lt;- tibble(\n  peso_kg = c(70, 85, 60, 95),\n  altezza_m = c(1.75, 1.80, 1.65, 1.90)\n)\ndf\n#&gt; # A tibble: 4 × 2\n#&gt;   peso_kg altezza_m\n#&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1      70      1.75\n#&gt; 2      85      1.8 \n#&gt; 3      60      1.65\n#&gt; 4      95      1.9\n\n\n# Calcola il BMI e aggiungilo come una nuova colonna 'BMI'\ndf &lt;- df %&gt;%\n  mutate(BMI = peso_kg / (altezza_m^2))\n\n# Mostra il tibble con la nuova variabile aggiunta\ndf\n#&gt; # A tibble: 4 × 3\n#&gt;   peso_kg altezza_m   BMI\n#&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1      70      1.75  22.9\n#&gt; 2      85      1.8   26.2\n#&gt; 3      60      1.65  22.0\n#&gt; 4      95      1.9   26.3\n\n\n16.2.3 Affrontare il Problema dei Dati Mancanti\nI dati mancanti sono un problema comune nelle ricerche psicologiche e in molte altre discipline. Quando mancano delle informazioni in un dataset, possono verificarsi gravi problemi per l’analisi statistica, come risultati distorti, riduzione della precisione delle stime o, in alcuni casi, l’impossibilità di applicare alcuni algoritmi.\n\n16.2.3.1 Perché i Dati Mancanti Sono un Problema?\nImmagina di voler capire il rendimento medio di una classe in un test, ma alcuni studenti hanno lasciato delle risposte in bianco. Se ignoriamo le risposte mancanti o eliminiamo gli studenti con dati incompleti, rischiamo di ottenere una stima che non rappresenta correttamente la realtà. Questo succede perché:\n\n\nBias dei risultati: Se i dati mancanti non sono casuali (ad esempio, i dati mancanti sono presenti più spesso in studenti con basso rendimento), le conclusioni possono essere errate.\n\nRiduzione della potenza statistica: Eliminare dati incompleti riduce il numero totale di osservazioni, rendendo più difficile trovare risultati significativi.\n\nImpossibilità di applicare alcuni metodi: Molti algoritmi statistici richiedono dati completi e non funzionano con valori mancanti.\n\n16.2.3.2 Come Gestire i Dati Mancanti?\nCi sono diversi modi per affrontare i dati mancanti. Vediamo prima i metodi più semplici e poi quelli più avanzati.\nEsaminiamo il data frame iniziale:\n\nsvy |&gt; \n  summary()\n#&gt;      stu_id      grade_level       math1        math2          \n#&gt;  Min.   :1347   Min.   : 9.0   Min.   :2.0   Length:5          \n#&gt;  1st Qu.:1368   1st Qu.: 9.0   1st Qu.:3.0   Class :character  \n#&gt;  Median :1377   Median :10.0   Median :3.0   Mode  :character  \n#&gt;  Mean   :1376   Mean   :10.2   Mean   :3.2                     \n#&gt;  3rd Qu.:1387   3rd Qu.:11.0   3rd Qu.:4.0                     \n#&gt;  Max.   :1399   Max.   :12.0   Max.   :4.0                     \n#&gt;                                                                \n#&gt;      math3          math4     \n#&gt;  Min.   :2.00   Min.   :1.00  \n#&gt;  1st Qu.:2.75   1st Qu.:1.75  \n#&gt;  Median :3.00   Median :2.50  \n#&gt;  Mean   :3.00   Mean   :2.50  \n#&gt;  3rd Qu.:3.25   3rd Qu.:3.25  \n#&gt;  Max.   :4.00   Max.   :4.00  \n#&gt;  NA's   :1      NA's   :1\n\nSi noti la presenza di dati mancanti sulle variabili math3 e math4.\n\ndim(svy)\n#&gt; [1] 5 6\n\n\n\nEsclusione dei Casi Incompleti (Complete Case Analysis).\nUn approccio comune, ma spesso non ideale, è quello di analizzare solo i casi completi, eliminando tutte le righe con valori mancanti. In R, questo si può fare con il seguente comando:\n\nsvy_comp &lt;- svy |&gt;\n  drop_na()\n\nIn questo modo abbiamo escluso tutte le righe nelle quali sono presenti dei dati mancanti (in questo caso, una sola riga).\n\ndim(svy_comp)\n#&gt; [1] 4 6\n\nLimite: Questo metodo può introdurre bias se i dati mancanti non sono casuali e riduce il campione, compromettendo l’affidabilità delle analisi.\n\n\nImputazione Semplice\nSostituire i valori mancanti con stime semplici:\n\n\nMedia o mediana: Per le variabili numeriche, sostituire i valori mancanti con la media o la mediana. Questo metodo è facile da implementare, ma può ridurre la variabilità nei dati.\n\nModa: Per le variabili categoriche, sostituire i valori mancanti con il valore più frequente. Tuttavia, può introdurre distorsioni se i dati sono molto eterogenei.\n\n\n\nImputazione Multipla\nUn approccio più avanzato è l’imputazione multipla, che utilizza modelli statistici per stimare i valori mancanti in modo iterativo. L’idea di base è semplice: ogni valore mancante viene stimato tenendo conto delle relazioni con tutte le altre variabili.\nVantaggi:\n\nMantiene la variabilità dei dati.\nPreserva le relazioni tra le variabili.\nRiduce il rischio di bias rispetto ai metodi semplici.\n\n\n\n16.2.3.3 Applicazione Pratica: Imputazione Multipla con mice in R\nSupponiamo di avere un dataset con alcune colonne numeriche che contengono valori mancanti. Possiamo utilizzare il pacchetto mice per imputare i dati mancanti.\nSelezioniamo le colonne numeriche da imputare.\n\nnumeric_columns &lt;- c(\"math1\", \"math2\", \"math3\", \"math4\")\nsvy &lt;- svy %&gt;%\n  mutate(across(all_of(numeric_columns), as.numeric))\n\nEseguiamo l’imputazione multipla.\n\nimputed &lt;- mice(\n  svy[numeric_columns], \n  m = 1, \n  maxit = 10, \n  method = \"norm.predict\", \n  seed = 123\n)\n#&gt; \n#&gt;  iter imp variable\n#&gt;   1   1  math3  math4\n#&gt;   2   1  math3  math4\n#&gt;   3   1  math3  math4\n#&gt;   4   1  math3  math4\n#&gt;   5   1  math3  math4\n#&gt;   6   1  math3  math4\n#&gt;   7   1  math3  math4\n#&gt;   8   1  math3  math4\n#&gt;   9   1  math3  math4\n#&gt;   10   1  math3  math4\n#&gt; Warning: Number of logged events: 2\n\nOttieniamo il dataset con i valori imputati.\n\nsvy_imputed &lt;- complete(imputed)\n\nArrotondiamo i valori imputati (se necessario).\n\nsvy_imputed &lt;- svy_imputed %&gt;%\n  mutate(across(everything(), round))\n\nSostituiamo i valori imputati nel dataset originale.\n\nsvy[numeric_columns] &lt;- svy_imputed\n\nEsaminiamo il risultato ottenuto.\n\nsvy |&gt; \n  summary()\n#&gt;      stu_id      grade_level       math1         math2         math3    \n#&gt;  Min.   :1347   Min.   : 9.0   Min.   :2.0   Min.   :1.0   Min.   :2.0  \n#&gt;  1st Qu.:1368   1st Qu.: 9.0   1st Qu.:3.0   1st Qu.:1.0   1st Qu.:3.0  \n#&gt;  Median :1377   Median :10.0   Median :3.0   Median :2.0   Median :3.0  \n#&gt;  Mean   :1376   Mean   :10.2   Mean   :3.2   Mean   :2.2   Mean   :3.2  \n#&gt;  3rd Qu.:1387   3rd Qu.:11.0   3rd Qu.:4.0   3rd Qu.:3.0   3rd Qu.:4.0  \n#&gt;  Max.   :1399   Max.   :12.0   Max.   :4.0   Max.   :4.0   Max.   :4.0  \n#&gt;      math4    \n#&gt;  Min.   :1.0  \n#&gt;  1st Qu.:2.0  \n#&gt;  Median :3.0  \n#&gt;  Mean   :2.8  \n#&gt;  3rd Qu.:4.0  \n#&gt;  Max.   :4.0\n\n\n16.2.3.4 Come Funziona l’Imputazione Multipla?\n\nOgni variabile con valori mancanti viene modellata come funzione delle altre variabili.\nI valori mancanti vengono stimati iterativamente. In ogni iterazione, si utilizza l’output precedente come input per migliorare le stime.\nDopo un numero sufficiente di iterazioni, le stime si stabilizzano (convergenza).\n\nIn conclusione, l’imputazione multipla è una tecnica avanzata che permette di gestire i dati mancanti preservando la qualità delle analisi. Rispetto ai metodi semplici, consente di mantenere la variabilità e ridurre il rischio di bias, rendendola una scelta ideale per analisi psicologiche e di ricerca.\n\n16.2.3.5 Aggiungere i Metadati\nI metadati sono informazioni che descrivono i dati stessi, come etichette di variabili, etichette di valori, informazioni sull’origine dei dati, unità di misura e altro ancora. Questi metadati sono essenziali per comprendere, documentare e condividere correttamente un dataset.\nIn R, i metadati sono gestiti in modo molto dettagliato e strutturato attraverso pacchetti come haven, labelled, e Hmisc. Questi pacchetti consentono di associare etichette ai dati, come etichette di variabili e di valori, e persino di gestire i valori mancanti con etichette specifiche.\n\n\nEtichette di variabili: Si possono aggiungere direttamente alle colonne di un DataFrame usando funzioni come labelled::set_variable_labels().\n\nEtichette di valori: Possono essere aggiunte a variabili categoriali utilizzando labelled::labelled().\n\nValori mancanti: In R, è possibile etichettare specifici valori come mancanti usando labelled::na_values&lt;-.\n\nQuesti strumenti rendono molto facile documentare un dataset all’interno del processo di analisi, assicurando che tutte le informazioni critiche sui dati siano facilmente accessibili e ben documentate.\nEsaminiamo un esempio pratico. Consideriamo nuovamente il data set svy:\n\nglimpse(svy)\n#&gt; Rows: 5\n#&gt; Columns: 6\n#&gt; $ stu_id      &lt;int&gt; 1347, 1368, 1377, 1387, 1399\n#&gt; $ grade_level &lt;int&gt; 9, 10, 9, 11, 12\n#&gt; $ math1       &lt;dbl&gt; 2, 3, 4, 3, 4\n#&gt; $ math2       &lt;dbl&gt; 1, 2, 4, 3, 1\n#&gt; $ math3       &lt;dbl&gt; 3, 2, 4, 4, 3\n#&gt; $ math4       &lt;dbl&gt; 3, 2, 4, 4, 1\n\nSi noti che la variabile math2 contiene un valore inamissibile, probabilmente un errore di battitura. Questo fa in modo che math2 sia di tipo char mentre dovrebbe essere una variabile numerica. Correggiamo.\n\n# Correzione di `math2`: Rimuovi valori non validi e converti in numerico\nsvy$math2 &lt;- gsub(\"\\\\n\", \"\", svy$math2)  # Rimuovi caratteri non validi come '\\n'\nsvy$math2 &lt;- as.numeric(svy$math2)      # Converte la variabile in numerico\n\n# Visualizzazione del dataset corretto\nprint(svy)\n#&gt;   stu_id grade_level math1 math2 math3 math4\n#&gt; 1   1347           9     2     1     3     3\n#&gt; 2   1368          10     3     2     2     2\n#&gt; 3   1377           9     4     4     4     4\n#&gt; 4   1387          11     3     3     4     4\n#&gt; 6   1399          12     4     1     3     1\n\nDefiniamo le etichette di valore per le variabili math1:math4.\n\nvalue_labels_math &lt;- set_names(\n  as.numeric(names(c(\n    `1` = \"strongly disagree\",\n    `2` = \"disagree\",\n    `3` = \"agree\",\n    `4` = \"strongly agree\"\n  ))),\n  c(\"strongly disagree\", \"disagree\", \"agree\", \"strongly agree\")\n)\n\nAggiungiamo le etichette di valore alle colonne math1:math4.\n\nsvy &lt;- svy %&gt;%\n  mutate(across(starts_with(\"math\"), ~ labelled(., labels = value_labels_math)))\n\nVerifica delle etichette.\n\nval_labels(svy$math1)\n#&gt; strongly disagree          disagree             agree    strongly agree \n#&gt;                 1                 2                 3                 4\n\n\nsvy\n#&gt;   stu_id grade_level math1 math2 math3 math4\n#&gt; 1   1347           9     2     1     3     3\n#&gt; 2   1368          10     3     2     2     2\n#&gt; 3   1377           9     4     4     4     4\n#&gt; 4   1387          11     3     3     4     4\n#&gt; 6   1399          12     4     1     3     1\n\n\n16.2.3.5.1 Utilizzo delle Etichette in R con Variabili Numeriche\nLe etichette dei valori (value labels) vengono utilizzate per rendere più leggibili e interpretabili le variabili numeriche, associando ad ogni valore un’etichetta descrittiva. Questo approccio è particolarmente utile in ambiti come la ricerca psicologica, dove le risposte ai questionari sono spesso codificate con numeri (ad esempio, 1 = “Strongly Disagree”, 2 = “Disagree”, ecc.) ma rappresentano concetti qualitativi.\nVantaggi dell’Uso delle Etichette\n\n\nChiarezza nelle Analisi: Le etichette descrittive rendono i dati più facilmente comprensibili senza dover ricordare il significato numerico di ciascun valore.\n\n\nDocumentazione Integrata: Permettono di incorporare metadati direttamente nelle variabili, migliorando la trasparenza e riducendo il rischio di interpretazioni errate.\n\nCompatibilità con Software Statistici: Molti strumenti (ad esempio, SPSS o Stata) utilizzano etichette di valori. Il pacchetto haven in R consente di gestire facilmente i dati etichettati esportati/importati da questi software.\n\nManipolazione di Variabili Etichettate\nAnche se una variabile numerica è etichettata con labelled (ad esempio, tramite il pacchetto haven), essa conserva la sua natura numerica e può essere utilizzata in calcoli, modelli statistici, e trasformazioni. Le etichette non alterano il valore sottostante, ma lo arricchiscono con informazioni aggiuntive.\nIn conclusione, le etichette dei valori migliorano l’interpretabilità dei dati senza comprometterne la manipolabilità. Questo approccio è ideale per mantenere le variabili numeriche pienamente funzionali per analisi statistiche, mentre le etichette descrittive forniscono un contesto chiaro e leggibile.\n\n16.2.3.6 Validazione dei Dati\nLa validazione dei dati è un passaggio fondamentale per garantire che il dataset soddisfi i criteri previsti e sia pronto per le analisi successive. Questo processo include il controllo della coerenza e della correttezza dei dati in base a specifiche regole definite dal dizionario dei dati. Alcune verifiche comuni includono:\n\n\nUnicità delle righe: Assicurarsi che ogni riga sia unica, verificando l’assenza di ID duplicati.\n\nValidità degli ID: Controllare che gli ID rientrino in un intervallo previsto (es. numerico).\n\nValori accettabili nelle variabili categoriali: Verificare che variabili come grade_level, int e le colonne math contengano esclusivamente valori appartenenti a un set di valori validi.\n\nIl pacchetto pointblank fornisce strumenti flessibili e intuitivi per eseguire verifiche di validazione e generare report dettagliati. Questo pacchetto consente di:\n\n\nDefinire le regole di validazione: Specificare controlli come unicità, intervalli di valori e appartenenza a insiemi predefiniti.\n\nEseguire i controlli: Applicare le regole di validazione su un dataset per identificare eventuali discrepanze.\n\nGenerare report interattivi: Creare un riepilogo chiaro e visivo dei controlli, evidenziando eventuali errori o anomalie.\n\nCon pointblank, è possibile integrare la validazione dei dati come parte di un workflow strutturato, garantendo la qualità dei dati in modo sistematico e ripetibile.\n\ncreate_agent(svy) %&gt;%\n  rows_distinct(columns = vars(stu_id)) %&gt;%\n  col_vals_between(columns = c(stu_id), \n                   left = 1300, right = 1400, na_pass = TRUE) %&gt;%\n  col_vals_in_set(columns = c(grade_level), \n                  set = c(9, 10, 11, 12, NA)) %&gt;%\n  col_vals_in_set(columns = c(int),\n                  set = c(0, 1, NA)) %&gt;%\n  col_vals_in_set(columns = c(math1:math4),\n                  set = c(1, 2, 3, 4, NA)) %&gt;%\n  interrogate()\n\n\n\n\n\n\nPointblank Validation\n\n\n\n\n[2024-12-31|09:47:48]\n\n\ndata frame svy\n\n\n\n\n\n\nSTEP\nCOLUMNS\nVALUES\nTBL\nEVAL\nUNITS\nPASS\nFAIL\nW\nS\nN\nEXT\n\n\n\n\n\n1\n\n\n\nrows_distinct\n\n\n\n rows_distinct()\n\n\n▮stu_id\n\n—\n\n\n✓\n5\n\n51\n\n\n00\n\n—\n—\n—\n—\n\n\n\n2\n\n\n\ncol_vals_between\n\n\n\n col_vals_between()\n\n\n▮stu_id\n\n\n[1,300, 1,400]\n\n\n\n✓\n5\n\n51\n\n\n00\n\n—\n—\n—\n—\n\n\n\n3\n\n\n\ncol_vals_in_set\n\n\n\n col_vals_in_set()\n\n\n▮grade_level\n\n\n9, 10, 11, 12, NA\n\n\n\n✓\n5\n\n51\n\n\n00\n\n—\n—\n—\n—\n\n\n\n4\n\n\n\ncol_vals_in_set\n\n\n\n col_vals_in_set()\n\n\n▮int\n\n\n0, 1, NA\n\n\n\n💥\n—\n—\n—\n—\n—\n—\n—\n\n\n\n5\n\n\n\ncol_vals_in_set\n\n\n\n col_vals_in_set()\n\n\n▮math1\n\n\n1, 2, 3, 4, NA\n\n\n\n✓\n5\n\n51\n\n\n00\n\n—\n—\n—\n—\n\n\n\n6\n\n\n\ncol_vals_in_set\n\n\n\n col_vals_in_set()\n\n\n▮math2\n\n\n1, 2, 3, 4, NA\n\n\n\n✓\n5\n\n51\n\n\n00\n\n—\n—\n—\n—\n\n\n\n7\n\n\n\ncol_vals_in_set\n\n\n\n col_vals_in_set()\n\n\n▮math3\n\n\n1, 2, 3, 4, NA\n\n\n\n✓\n5\n\n51\n\n\n00\n\n—\n—\n—\n—\n\n\n\n8\n\n\n\ncol_vals_in_set\n\n\n\n col_vals_in_set()\n\n\n▮math4\n\n\n1, 2, 3, 4, NA\n\n\n\n✓\n5\n\n51\n\n\n00\n\n—\n—\n—\n—\n\n\n\n\n2024-12-31 09:47:48 CET &lt; 1 s 2024-12-31 09:47:48 CET\n\n\n\n\n\n\nIl dataset ripulito soddisfa tutte le aspettative delineate da Crystal Lewis.\n\n\nCompleto: Tutti i dati raccolti sono stati inseriti e/o recuperati. Non dovrebbero esserci dati estranei che non appartengono al dataset (come duplicati o partecipanti non autorizzati).\n\nValido: Le variabili rispettano i vincoli definiti nel tuo dizionario dei dati. Ricorda che il dizionario dei dati specifica i nomi delle variabili, i tipi, i range, le categorie e altre informazioni attese.\n\nAccurato: Sebbene non sia sempre possibile determinare l’accuratezza dei valori durante il processo di pulizia dei dati (ovvero, se un valore è realmente corretto o meno), in alcuni casi è possibile valutarla sulla base della conoscenza pregressa riguardante quel partecipante o caso specifico.\n\nCoerente: I valori sono allineati tra le varie fonti. Ad esempio, la data di nascita raccolta attraverso un sondaggio studentesco dovrebbe avere un formato corrispondere alla data di nascita raccolta dal distretto scolastico.\n\nUniforme: I dati sono standardizzati attraverso i moduli e nel tempo. Ad esempio, lo stato di partecipazione ai programmi di pranzo gratuito o a prezzo ridotto è sempre fornito come una variabile numerica con la stessa rappresentazione, oppure il nome della scuola è sempre scritto in modo coerente in tutto il dataset.\n\nDe-identificato: Tutte le informazioni personali identificabili (PII) sono state rimosse dal dataset per proteggere la riservatezza dei partecipanti (se richiesto dal comitato etico/consenso informato).\n\nInterpretabile: I dati hanno nomi di variabili leggibili sia da umani che dal computer, e sono presenti etichette di variabili e valori laddove necessario per facilitare l’interpretazione.\n\nAnalizzabile: Il dataset è in un formato rettangolare (righe e colonne), leggibile dal computer e conforme alle regole di base della struttura dei dati.\n\nUna volta completati i 14 passaggi precedenti, è possibile esportare questo dataset ripulito nella cartella processed per le successive analisi statistiche.\n\n16.2.3.7 Unire e/o aggiungere dati se necessario\nIn questo passaggio, è possibile unire o aggiungere colonne o righe presenti in file diversi. È importante eseguire nuovamente i controlli di validazione dopo l’unione/aggiunta di nuovi dati.\n\n16.2.3.8 Trasformare i dati se necessario\nEsistono vari motivi per cui potrebbe essere utile memorizzare i dati in formato long o wide. In questo passaggio, è possibile ristrutturare i dati secondo le esigenze.\n\n16.2.3.9 Salvare il dataset pulito finale\nL’ultimo passaggio del processo di pulizia consiste nell’esportare o salvare il dataset pulito. Come accennato in precedenza, può essere utile esportare/salvare il dataset in più di un formato di file (ad esempio, un file .csv e un file .parquet).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#organizzazione-dei-file-e-informazioni-aggiuntive",
    "href": "chapters/eda/02_data_cleaning.html#organizzazione-dei-file-e-informazioni-aggiuntive",
    "title": "16  Flusso di lavoro per la pulizia dei dati",
    "section": "\n16.3 Organizzazione dei file e informazioni aggiuntive",
    "text": "16.3 Organizzazione dei file e informazioni aggiuntive\nInfine, è essenziale includere una documentazione adeguata per garantire che le informazioni siano interpretate correttamente, sia da altri utenti che da te stesso, se dovessi tornare a lavorare su questo progetto in futuro. La documentazione minima da fornire dovrebbe includere:\n\n\nDocumentazione a livello di progetto: Questa sezione fornisce informazioni contestuali sul perché e come i dati sono stati raccolti. È utile per chiunque voglia comprendere lo scopo e la metodologia del progetto.\n\nMetadati a livello di progetto: Se condividi i dati in un repository pubblico o privato, è importante includere metadati a livello di progetto. Questi metadati forniscono informazioni dettagliate che facilitano la ricerca, la comprensione e la consultabilità dei dati. I metadati a livello di progetto possono includere descrizioni generali del progetto, parole chiave, e riferimenti bibliografici.\n\nDizionario dei dati: Un documento che descrive tutte le variabili presenti nel dataset, inclusi i loro nomi, tipi, range di valori, categorie e qualsiasi altra informazione rilevante. Questo strumento è fondamentale per chiunque voglia comprendere o analizzare i dati.\n\nREADME: Un file che fornisce una panoramica rapida dei file inclusi nel progetto, spiegando cosa contengono e come sono interconnessi. Il README è spesso il primo documento consultato e serve a orientare l’utente tra i vari file e risorse del progetto. Questa documentazione non solo aiuta a mantenere il progetto organizzato, ma è anche cruciale per facilitare la collaborazione e l’archiviazione a lungo termine.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#dizionario-dei-dati",
    "href": "chapters/eda/02_data_cleaning.html#dizionario-dei-dati",
    "title": "16  Flusso di lavoro per la pulizia dei dati",
    "section": "\n16.4 Dizionario dei Dati",
    "text": "16.4 Dizionario dei Dati\nApprofondiamo qui il problema della creazione del Dizionario dei dati.\nUn dizionario dei dati è un documento che descrive le caratteristiche di ciascuna variabile in un dataset. Include informazioni come il nome della variabile, il tipo di dato, il range di valori, le categorie (per le variabili categoriche), e altre informazioni rilevanti. Questo strumento è essenziale per comprendere e analizzare correttamente il dataset.\nSi presti particolare attenzione alle guide di stile per la denominazione delle variabili e la codifica dei valori delle risposte.\n\n16.4.1 Esempio in R\n\nEcco come tradurre i passi per creare un dizionario dei dati in R, utilizzando il pacchetto tibble per creare il dizionario e writexl o readr per esportarlo in formato .xlsx o .csv.\n\n\nIdentificare le variabili: Elencare tutte le variabili presenti nel dataset.\n\nDescrivere ogni variabile: Per ciascuna variabile, definire il tipo (ad esempio, integer, numeric, character), il range di valori accettabili o le categorie, e fornire una descrizione chiara.\n\nSalvare il dizionario dei dati: Il dizionario può essere salvato in un file .csv o .xlsx per una facile consultazione.\n\n\nsvy\n#&gt;   stu_id grade_level math1 math2 math3 math4\n#&gt; 1   1347           9     2     1     3     3\n#&gt; 2   1368          10     3     2     2     2\n#&gt; 3   1377           9     4     4     4     4\n#&gt; 4   1387          11     3     3     4     4\n#&gt; 6   1399          12     4     1     3     1\n\nCreeremo un dizionario dei dati per un dataset di esempio e lo salveremo sia in formato CSV che Excel.\n\nlibrary(tibble)\nlibrary(readr)\nlibrary(writexl)\n\n# Creazione del Dizionario dei Dati\ndata_dict &lt;- tibble(\n  `Variable Name` = c(\n    \"stu_id\",\n    \"svy_date\",\n    \"grade_level\",\n    \"math1\",\n    \"math2\",\n    \"math3\",\n    \"math4\"\n  ),\n  `Type` = c(\n    \"integer\",\n    \"datetime\",\n    \"integer\",\n    \"integer\",\n    \"integer\",\n    \"numeric\",\n    \"numeric\"\n  ),\n  `Description` = c(\n    \"Student ID\",\n    \"Survey Date\",\n    \"Grade Level\",\n    \"Math Response 1 (1: Strongly Disagree, 4: Strongly Agree)\",\n    \"Math Response 2 (1: Strongly Disagree, 4: Strongly Agree)\",\n    \"Math Response 3 (1: Strongly Disagree, 4: Strongly Agree)\",\n    \"Math Response 4 (1: Strongly Disagree, 4: Strongly Agree)\"\n  ),\n  `Range/Values` = c(\n    \"1347-1399\",\n    \"2023-02-13 to 2023-02-14\",\n    \"9-12\",\n    \"1-4\",\n    \"1-4\",\n    \"1.0-4.0 (NA allowed)\",\n    \"1.0-4.0 (NA allowed)\"\n  )\n)\n\n# Visualizza il Dizionario dei Dati\nprint(data_dict)\n#&gt; # A tibble: 7 × 4\n#&gt;   `Variable Name` Type     Description                       `Range/Values` \n#&gt;   &lt;chr&gt;           &lt;chr&gt;    &lt;chr&gt;                             &lt;chr&gt;          \n#&gt; 1 stu_id          integer  Student ID                        1347-1399      \n#&gt; 2 svy_date        datetime Survey Date                       2023-02-13 to …\n#&gt; 3 grade_level     integer  Grade Level                       9-12           \n#&gt; 4 math1           integer  Math Response 1 (1: Strongly Dis… 1-4            \n#&gt; 5 math2           integer  Math Response 2 (1: Strongly Dis… 1-4            \n#&gt; 6 math3           numeric  Math Response 3 (1: Strongly Dis… 1.0-4.0 (NA al…\n#&gt; # ℹ 1 more row\n\n# Salva il Dizionario dei Dati in un file CSV\nwrite_csv(data_dict, here::here(\"data\", \"processed\", \"data_dictionary.csv\"))\n\n# Salva il Dizionario dei Dati in un file Excel\nwrite_xlsx(data_dict, here::here(\"data\", \"processed\", \"data_dictionary.xlsx\"))\n\nOutput Atteso: file CSV (data_dictionary.csv).\n\ndata_dict &lt;- rio::import(\n  here::here(\"data\", \"processed\", \"data_dictionary.csv\")\n)\n\n\nprint(data_dict)\n#&gt;   Variable Name     Type\n#&gt; 1        stu_id  integer\n#&gt; 2      svy_date datetime\n#&gt; 3   grade_level  integer\n#&gt; 4         math1  integer\n#&gt; 5         math2  integer\n#&gt; 6         math3  numeric\n#&gt; 7         math4  numeric\n#&gt;                                                 Description\n#&gt; 1                                                Student ID\n#&gt; 2                                               Survey Date\n#&gt; 3                                               Grade Level\n#&gt; 4 Math Response 1 (1: Strongly Disagree, 4: Strongly Agree)\n#&gt; 5 Math Response 2 (1: Strongly Disagree, 4: Strongly Agree)\n#&gt; 6 Math Response 3 (1: Strongly Disagree, 4: Strongly Agree)\n#&gt; 7 Math Response 4 (1: Strongly Disagree, 4: Strongly Agree)\n#&gt;               Range/Values\n#&gt; 1                1347-1399\n#&gt; 2 2023-02-13 to 2023-02-14\n#&gt; 3                     9-12\n#&gt; 4                      1-4\n#&gt; 5                      1-4\n#&gt; 6     1.0-4.0 (NA allowed)\n#&gt; 7     1.0-4.0 (NA allowed)\n\n\n16.4.1.1 Uso del pacchetto dataMeta\n\nIl pacchetto dataMeta è progettato per generare metadati e dizionari dei dati in modo strutturato.\n\nlibrary(dataMeta)\nlibrary(tibble)\n\n# Descrizioni delle variabili\nvariable_descriptions &lt;- c(\n  \"Student ID\",\n  \"Grade Level\",\n  \"Math Response 1 (1: Strongly Disagree, 4: Strongly Agree)\",\n  \"Math Response 2 (1: Strongly Disagree, 4: Strongly Agree)\",\n  \"Math Response 3 (1: Strongly Disagree, 4: Strongly Agree)\",\n  \"Math Response 4 (1: Strongly Disagree, 4: Strongly Agree)\"\n)\n\nvar_type &lt;- c(1, 0, 0, 0, 0, 0)\n\nlinker &lt;- build_linker(\n  svy, \n  variable_description = variable_descriptions, \n  variable_type = var_type\n)\n\ndict &lt;- build_dict(\n  my.data = svy, \n  linker = linker, \n  option_description = NULL, \n  prompt_varopts = FALSE\n)\n\nkable(dict, format = \"html\", caption = \"Data dictionary for original dataset\")\n\n\nData dictionary for original dataset\n\nvariable_name\nvariable_description\nvariable_options\n\n\n\ngrade_level\nGrade Level\n9 to 12\n\n\nmath1\nMath Response 1 (1: Strongly Disagree, 4: Strongly Agree)\n2 to 4\n\n\nmath2\nMath Response 2 (1: Strongly Disagree, 4: Strongly Agree)\n1 to 4\n\n\nmath3\nMath Response 3 (1: Strongly Disagree, 4: Strongly Agree)\n2 to 4\n\n\nmath4\nMath Response 4 (1: Strongly Disagree, 4: Strongly Agree)\n1 to 4\n\n\nstu_id\nStudent ID\n1347\n\n\n\n\n1368\n\n\n\n\n1377\n\n\n\n\n1387\n\n\n\n\n1399\n\n\n\n\n\n\n16.4.1.2 Uso del pacchetto skimr\n\nIl pacchetto skimr è utile per generare riassunti dettagliati delle variabili, che possono essere utilizzati come base per un dizionario.\n\nlibrary(skimr)\n\n# Riassunto del dataset\nskim_dict &lt;- skim(svy)\n\nkable(skim_dict, format = \"html\", caption = \"Data dictionary for original dataset\")\n\n\nData dictionary for original dataset\n\nskim_type\nskim_variable\nn_missing\ncomplete_rate\nnumeric.mean\nnumeric.sd\nnumeric.p0\nnumeric.p25\nnumeric.p50\nnumeric.p75\nnumeric.p100\nnumeric.hist\n\n\n\nnumeric\nstu_id\n0\n1\n1375.6\n19.718\n1347\n1368\n1377\n1387\n1399\n▃▁▇▃▃\n\n\nnumeric\ngrade_level\n0\n1\n10.2\n1.304\n9\n9\n10\n11\n12\n▇▃▁▃▃\n\n\nnumeric\nmath1\n0\n1\n3.2\n0.837\n2\n3\n3\n4\n4\n▃▁▇▁▇\n\n\nnumeric\nmath2\n0\n1\n2.2\n1.304\n1\n1\n2\n3\n4\n▇▃▁▃▃\n\n\nnumeric\nmath3\n0\n1\n3.2\n0.837\n2\n3\n3\n4\n4\n▃▁▇▁▇\n\n\nnumeric\nmath4\n0\n1\n2.8\n1.304\n1\n2\n3\n4\n4\n▃▃▁▃▇",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#riflessioni-conclusive",
    "href": "chapters/eda/02_data_cleaning.html#riflessioni-conclusive",
    "title": "16  Flusso di lavoro per la pulizia dei dati",
    "section": "\n16.5 Riflessioni Conclusive",
    "text": "16.5 Riflessioni Conclusive\nNel processo di analisi dei dati, la fase di pulizia e pre-elaborazione è cruciale per garantire la qualità e l’integrità dei risultati finali. Sebbene questa fase possa sembrare meno interessante rispetto all’analisi vera e propria, essa costituisce la base su cui si costruiscono tutte le successive elaborazioni e interpretazioni. Attraverso una serie di passaggi strutturati, come quelli illustrati in questo capitolo, è possibile trasformare dati grezzi e disordinati in un dataset pulito, coerente e pronto per l’analisi. La cura nella gestione dei dati, dalla rimozione di duplicati alla creazione di un dizionario dei dati, è fondamentale per ottenere risultati affidabili e riproducibili.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/02_data_cleaning.html#informazioni-sullambiente-di-sviluppo",
    "title": "16  Flusso di lavoro per la pulizia dei dati",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] skimr_2.1.5       dataMeta_0.1.1    writexl_1.5.1     pointblank_0.12.2\n#&gt;  [5] haven_2.5.4       labelled_2.13.0   mice_3.17.0       see_0.9.0        \n#&gt;  [9] gridExtra_2.3     patchwork_1.3.0   bayesplot_1.11.1  psych_2.4.12     \n#&gt; [13] scales_1.3.0      markdown_1.13     knitr_1.49        lubridate_1.9.4  \n#&gt; [17] forcats_1.0.0     stringr_1.5.1     dplyr_1.1.4       purrr_1.0.2      \n#&gt; [21] readr_2.1.5       tidyr_1.3.1       tibble_3.2.1      ggplot2_3.5.1    \n#&gt; [25] tidyverse_2.0.0   rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1  farver_2.1.2      R.utils_2.12.3    fastmap_1.2.0    \n#&gt;  [5] pacman_0.5.1      digest_0.6.37     rpart_4.1.23      timechange_0.3.0 \n#&gt;  [9] lifecycle_1.0.4   survival_3.8-3    magrittr_2.0.3    compiler_4.4.2   \n#&gt; [13] sass_0.4.9.9000   rlang_1.1.4       tools_4.4.2       gt_0.11.1        \n#&gt; [17] utf8_1.2.4        data.table_1.16.4 htmlwidgets_1.6.4 bit_4.5.0.1      \n#&gt; [21] mnormt_2.1.1      repr_1.1.7        xml2_1.3.6        withr_3.0.2      \n#&gt; [25] R.oo_1.27.0       nnet_7.3-19       grid_4.4.2        jomo_2.7-6       \n#&gt; [29] colorspace_2.1-1  iterators_1.0.14  MASS_7.3-61       cli_3.6.3        \n#&gt; [33] crayon_1.5.3      rmarkdown_2.29    generics_0.1.3    tzdb_0.4.0       \n#&gt; [37] commonmark_1.9.2  minqa_1.2.8       splines_4.4.2     parallel_4.4.2   \n#&gt; [41] base64enc_0.1-3   vctrs_0.6.5       boot_1.3-31       glmnet_4.1-8     \n#&gt; [45] Matrix_1.7-1      jsonlite_1.8.9    hms_1.1.3         bit64_4.5.2      \n#&gt; [49] mitml_0.4-5       foreach_1.5.2     glue_1.8.0        blastula_0.3.5   \n#&gt; [53] nloptr_2.1.1      pan_1.9           codetools_0.2-20  stringi_1.8.4    \n#&gt; [57] shape_1.4.6.1     gtable_0.3.6      lme4_1.1-35.5     munsell_0.5.1    \n#&gt; [61] pillar_1.10.0     htmltools_0.5.8.1 R6_2.5.1          rprojroot_2.0.4  \n#&gt; [65] vroom_1.6.5       evaluate_1.0.1    lattice_0.22-6    R.methodsS3_1.8.2\n#&gt; [69] backports_1.5.0   broom_1.0.7       Rcpp_1.0.13-1     nlme_3.1-166     \n#&gt; [73] xfun_0.49         pkgconfig_2.0.3",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#bibliografia",
    "href": "chapters/eda/02_data_cleaning.html#bibliografia",
    "title": "16  Flusso di lavoro per la pulizia dei dati",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBuchanan, E. M., Crain, S. E., Cunningham, A. L., Johnson, H. R., Stash, H., Papadatou-Pastou, M., Isager, P. M., Carlsson, R., & Aczel, B. (2021). Getting started creating data dictionaries: How to create a shareable data set. Advances in Methods and Practices in Psychological Science, 4(1), 2515245920928007.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html",
    "href": "chapters/eda/04_exploring_qualitative_data.html",
    "title": "17  Esplorare i dati qualitativi",
    "section": "",
    "text": "17.1 Introduzione\nIn questo capitolo ci concentreremo sull’analisi dei dati qualitativi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#il-dataset-penguins",
    "href": "chapters/eda/04_exploring_qualitative_data.html#il-dataset-penguins",
    "title": "17  Esplorare i dati qualitativi",
    "section": "\n17.2 Il dataset penguins\n",
    "text": "17.2 Il dataset penguins\n\nPer fornire esempi pratici, in questo capitolo utilizzeremo il dataset palmerpenguins, messo a disposizione da Allison Horst. I dati sono stati raccolti e resi disponibili da Dr. Kristen Gorman e dalla Palmer Station, parte del programma di ricerca ecologica a lungo termine Long Term Ecological Research Network. Il dataset contiene informazioni su 344 pinguini, appartenenti a 3 diverse specie, raccolte su 3 isole dell’arcipelago di Palmer, in Antartide. Per semplicità, i dati sono organizzati nel file penguins.csv.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#importare-i-dati",
    "href": "chapters/eda/04_exploring_qualitative_data.html#importare-i-dati",
    "title": "17  Esplorare i dati qualitativi",
    "section": "\n17.3 Importare i Dati",
    "text": "17.3 Importare i Dati\nPossiamo caricare i dati grezzi dal file penguins.csv in un DataFrame con il seguente comando:\n\nd &lt;- rio::import(here::here(\"data\", \"penguins.csv\"))\n\nEsaminiamo i dati.\n\nglimpse(d)\n#&gt; Rows: 344\n#&gt; Columns: 8\n#&gt; $ species           &lt;chr&gt; \"Adelie\", \"Adelie\", \"Adelie\", \"Adelie\", \"Adelie\"…\n#&gt; $ island            &lt;chr&gt; \"Torgersen\", \"Torgersen\", \"Torgersen\", \"Torgerse…\n#&gt; $ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34…\n#&gt; $ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18…\n#&gt; $ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190,…\n#&gt; $ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 34…\n#&gt; $ sex               &lt;chr&gt; \"male\", \"female\", \"female\", NA, \"female\", \"male\"…\n#&gt; $ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, …\n\nPer semplicità, rimuoviamo le righe con valori mancanti con la seguente istruzione:\n\ndf &lt;- d |&gt;\n  drop_na()",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#tabelle-di-contingenza",
    "href": "chapters/eda/04_exploring_qualitative_data.html#tabelle-di-contingenza",
    "title": "17  Esplorare i dati qualitativi",
    "section": "\n17.4 Tabelle di Contingenza",
    "text": "17.4 Tabelle di Contingenza\nUna tabella di contingenza è uno strumento utilizzato per riassumere i dati di due variabili categoriali, ovvero variabili qualitative che assumono valori all’interno di un insieme finito di categorie. In una tabella di contingenza, ogni cella mostra quante volte si è verificata una combinazione specifica di categorie per le due variabili considerate.\nPer esempio, se prendiamo in esame due variabili categoriali come “island” e “species” all’interno di un DataFrame df, ciascuna delle quali rappresenta rispettivamente l’isola di provenienza e la specie dei pinguini, possiamo costruire una tabella che mostra quante volte ciascuna combinazione di “island” e “species” appare nel nostro campione. In altre parole, la tabella di contingenza ci permette di vedere quante osservazioni ci sono per ogni combinazione di categorie tra queste due variabili. Usiamo la funzione tably() del pacchetto janitor.\n\ndf |&gt; \n  tabyl(island, species) |&gt; \n  adorn_totals(c(\"row\", \"col\")) \n#&gt;     island Adelie Chinstrap Gentoo Total\n#&gt;     Biscoe     44         0    119   163\n#&gt;      Dream     55        68      0   123\n#&gt;  Torgersen     47         0      0    47\n#&gt;      Total    146        68    119   333\n\nQuesta tabella di contingenza mostra la distribuzione di tre specie di pinguini (Adelie, Chinstrap, Gentoo) rispetto a tre isole (Biscoe, Dream, Torgersen). Ogni cella rappresenta il numero di pinguini di una determinata specie presenti su ciascuna isola. Ecco un’interpretazione dettagliata:\n\n\nIsola Biscoe: Qui troviamo 44 pinguini della specie Adelie e 119 pinguini della specie Gentoo, mentre non sono presenti pinguini Chinstrap.\n\nIsola Dream: Questa isola ospita 55 pinguini Adelie e 68 pinguini Chinstrap, ma nessun pinguino della specie Gentoo.\n\nIsola Torgersen: Su quest’isola sono presenti solo 47 pinguini della specie Adelie, e nessun pinguino delle specie Chinstrap o Gentoo.\n\nPossiamo commentare dicendo:\n\nLa specie Adelie è distribuita su tutte e tre le isole, con numeri notevoli sia su Biscoe (44), Dream (55), che Torgersen (47).\nLa specie Chinstrap si trova solo sull’isola Dream (68 esemplari) e non è presente sulle altre due isole.\nLa specie Gentoo si trova esclusivamente sull’isola Biscoe (119 esemplari), non essendo presente su Dream e Torgersen.\n\nQuesto suggerisce una distribuzione geografica specifica delle diverse specie di pinguini, con alcune specie limitate a determinate isole e altre distribuite più ampiamente.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#test-del-chi-quadrato",
    "href": "chapters/eda/04_exploring_qualitative_data.html#test-del-chi-quadrato",
    "title": "17  Esplorare i dati qualitativi",
    "section": "\n17.5 Test del Chi-Quadrato",
    "text": "17.5 Test del Chi-Quadrato\nUna tabella di contingenza, che include i totali marginali e i valori delle celle, ci permette di formulare una domanda fondamentale: “Come apparirebbe la tabella di contingenza se non ci fosse alcuna relazione tra le due variabili, ovvero la variabile riga e la variabile colonna?”.\nCome già visto in precedenza analizzando la distribuzione di probabilità congiunta, si ha indipendenza quando le probabilità congiunte sono uguali al prodotto delle probabilità marginali. Partendo dalle proporzioni marginali, possiamo quindi calcolare i valori teorici attesi in ciascuna cella della tabella di contingenza, assumendo che le due variabili siano indipendenti.\nVa sottolineato che l’indipendenza è una proprietà della popolazione, non del campione. Pertanto, nei dati campionari, ci aspettiamo che i valori osservati nelle celle della tabella differiscano leggermente dai valori teorici attesi, anche se nella popolazione le variabili sono realmente indipendenti. La discrepanza complessiva tra i valori osservati e quelli attesi, calcolati sotto l’ipotesi di indipendenza, può essere misurata utilizzando una statistica chiamata Chi-Quadrato (\\(\\chi^2\\)).\nLa formula della statistica Chi-Quadrato è:\n\\[\n\\chi^2 = \\sum \\frac{(O_i - E_i)^2}{E_i} ,\n\\]\ndove:\n\n\n\\(O_i\\) rappresenta i valori osservati nelle celle della tabella,\n\n\n\\(E_i\\) rappresenta i valori attesi nelle celle, calcolati sotto l’ipotesi di indipendenza,\n\nLa somma (\\(\\sum\\)) viene effettuata su tutte le celle della tabella.\n\n\n17.5.1 Interpretazione della Statistica Chi-Quadrato\nLa statistica Chi-Quadrato misura la discrepanza complessiva tra i valori osservati e quelli attesi. Se non ci fosse differenza tra i valori congiunti osservati e quelli teorici, la statistica Chi-Quadrato sarebbe pari a zero. All’aumentare della discrepanza tra valori osservati e attesi, il valore della statistica Chi-Quadrato aumenta.\nPer valutare l’importanza della discrepanza osservata, utilizziamo la distribuzione campionaria della statistica Chi-Quadrato. Questa distribuzione descrive la probabilità di ottenere valori della statistica Chi-Quadrato sotto l’ipotesi nulla (indipendenza tra le variabili). La forma della distribuzione dipende dai gradi di libertà (\\(\\nu\\)), che si calcolano come:\n\\[\n\\nu = (n_{\\text{righe}} - 1)(n_{\\text{colonne}} - 1) ,\n\\]\ndove \\(n_{\\text{righe}}\\) e \\(n_{\\text{colonne}}\\) rappresentano rispettivamente il numero di righe e colonne della tabella di contingenza.\n\n17.5.2 Valutazione dell’Ipotesi di Indipendenza\nLa probabilità associata a una data discrepanza (\\(\\chi^2\\)) tra valori osservati e attesi, assumendo che l’ipotesi nulla sia vera, corrisponde all’area sotto la coda destra della distribuzione Chi-Quadrato, nell’intervallo [\\(C\\), \\(+\\infty\\)]. Questa probabilità è indicata come \\(p\\)-value.\nSe il \\(p\\)-value è molto piccolo (tipicamente inferiore a una soglia predefinita, come 0.05), possiamo rifiutare l’ipotesi nulla e concludere che è improbabile che le due variabili siano indipendenti nella popolazione.\n\n17.5.3 Riepilogo dei Passaggi del Test Chi-Quadrato\n\n\nCalcolo dei Valori Attesi: Per ogni cella, calcola \\(E_i\\) utilizzando la formula:\n\\[\nE_i = \\frac{\\text{Totale della Riga} \\times \\text{Totale della Colonna}}{\\text{Totale Complessivo}}\n\\]\n\n\nCalcolo della Statistica Chi-Quadrato: Usa la formula:\n\\[\n\\chi^2 = \\sum \\frac{(O_i - E_i)^2}{E_i}\n\\]\n\nDeterminazione dei Gradi di Libertà: Calcola \\(\\nu\\) come \\((n_{\\text{righe}} - 1)(n_{\\text{colonne}} - 1)\\).\nConfronto con la Distribuzione Chi-Quadrato: Determina il \\(p\\)-value associato al valore di \\(\\chi^2\\) calcolato e valuta l’ipotesi nulla.\n\nIn conclusione, il Test Chi-Quadrato rappresenta uno strumento importante per verificare l’indipendenza tra due variabili categoriali. Grazie alla sua semplicità di applicazione e interpretazione, costituisce un metodo di analisi largamente utilizzato in ambito psicologico, sociale e statistico. Tuttavia, è importante prestare attenzione ai presupposti del test, come la sufficienza dei dati in ogni cella, per garantire risultati affidabili e interpretabili.\n\n# Creare la tabella di contingenza\nobserved &lt;- matrix(c(44, 0, 119, \n                              55, 68, 0, \n                              47, 0, 0),\n                            nrow = 3, byrow = TRUE)\n\n# Aggiungere i nomi di righe e colonne\nrownames(observed) &lt;- c(\"Biscoe\", \"Dream\", \"Torgersen\")\ncolnames(observed) &lt;- c(\"Adelie\", \"Chinstrap\", \"Gentoo\")\n\n# Visualizzare la tabella\nprint(observed)\n#&gt;           Adelie Chinstrap Gentoo\n#&gt; Biscoe        44         0    119\n#&gt; Dream         55        68      0\n#&gt; Torgersen     47         0      0\n\n\nchi_square_result &lt;- chisq.test(observed)\nchi_square_result\n#&gt; \n#&gt;  Pearson's Chi-squared test\n#&gt; \n#&gt; data:  observed\n#&gt; X-squared = 285, df = 4, p-value &lt;2e-16\n\nSvolgiamo i calcoli “a mano” usando R. Per calcolare la statistica del test del Chi-Quadrato “a mano” in R, segui questi passaggi:\nCalcoliamo i totali per righe e colonne e il totale complessivo.\n\n# Totali marginali\nrow_totals &lt;- rowSums(observed)\ncol_totals &lt;- colSums(observed)\ngrand_total &lt;- sum(observed)\n\n# Visualizzare i totali\nprint(\"Totali marginali per righe:\")\n#&gt; [1] \"Totali marginali per righe:\"\nprint(row_totals)\n#&gt;    Biscoe     Dream Torgersen \n#&gt;       163       123        47\nprint(\"Totali marginali per colonne:\")\n#&gt; [1] \"Totali marginali per colonne:\"\nprint(col_totals)\n#&gt;    Adelie Chinstrap    Gentoo \n#&gt;       146        68       119\nprint(paste(\"Totale complessivo:\", grand_total))\n#&gt; [1] \"Totale complessivo: 333\"\n\nI valori attesi si calcolano come:\n\\[\nE_{ij} = \\frac{\\text{Totale riga} \\times \\text{Totale colonna}}{\\text{Totale complessivo}} .\n\\]\n\n# Calcolo dei valori attesi\nexpected &lt;- outer(row_totals, col_totals) / grand_total\n\n# Visualizzare i valori attesi\nprint(\"Valori attesi:\")\n#&gt; [1] \"Valori attesi:\"\nprint(expected)\n#&gt;           Adelie Chinstrap Gentoo\n#&gt; Biscoe      71.5      33.3   58.2\n#&gt; Dream       53.9      25.1   44.0\n#&gt; Torgersen   20.6       9.6   16.8\n\nLa statistica Chi-Quadrato si calcola con:\n\\[\n\\chi^2 = \\sum \\frac{(O_{ij} - E_{ij})^2}{E_{ij}} .\n\\]\n\n# Calcolo della statistica Chi-Quadrato\nchi_square_stat &lt;- sum((observed - expected)^2 / expected)\n\n# Visualizzare il risultato\nprint(paste(\"Statistica Chi-Quadrato:\", chi_square_stat))\n#&gt; [1] \"Statistica Chi-Quadrato: 284.590012688092\"\n\nI gradi di libertà si calcolano come:\n\\[\ndof = (\\text{n. righe} - 1) \\times (\\text{n. colonne} - 1) .\n\\]\n\n# Calcolo dei gradi di libertà\ndof &lt;- (nrow(observed) - 1) * (ncol(observed) - 1)\n\n# Visualizzare i gradi di libertà\nprint(paste(\"Gradi di libertà:\", dof))\n#&gt; [1] \"Gradi di libertà: 4\"\n\nConfrontiamo la statistica Chi-Quadrato con la distribuzione teorica per ottenere il p-value.\n\n# Calcolo del p-value\np_value &lt;- pchisq(chi_square_stat, df = dof, lower.tail = FALSE)\n\n# Visualizzare il p-value\nprint(paste(\"p-value:\", p_value))\n#&gt; [1] \"p-value: 2.28189154098739e-60\"\n\nInterpretazione:\nIl valore-\\(p\\) risulta molto piccolo, indicando che, se le variabili Isola e Specie fossero realmente indipendenti, sarebbe estremamente improbabile osservare una distribuzione delle specie di pinguini sulle tre isole così diversa da quella teoricamente attesa. In altre parole, il valore-\\(p\\) rappresenta la probabilità di ottenere, per puro caso, una discrepanza tra i valori osservati e quelli attesi pari o superiore a quella riscontrata nei dati.\nPoiché il valore-\\(p\\) è estremamente basso, possiamo concludere che l’ipotesi di indipendenza tra le variabili Isola e Specie non è plausibile. Questo indica che la distribuzione delle specie di pinguini varia in relazione all’isola, ovvero che conoscendo l’isola è possibile prevedere la distribuzione delle specie. In altre parole, le variabili Isola e Specie sono associate.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#grafico-a-barre",
    "href": "chapters/eda/04_exploring_qualitative_data.html#grafico-a-barre",
    "title": "17  Esplorare i dati qualitativi",
    "section": "\n17.6 Grafico a barre",
    "text": "17.6 Grafico a barre\n\n17.6.1 Grafico a Barre con una Singola Variabile\nUn grafico a barre è uno strumento comunemente utilizzato per rappresentare visivamente una singola variabile categoriale. Questo tipo di grafico mostra le diverse categorie su uno degli assi (solitamente l’asse orizzontale) e utilizza barre di altezza proporzionale per rappresentare la frequenza o il conteggio di ciascuna categoria sull’altro asse (solitamente l’asse verticale).\nAd esempio, in un dataset che contiene informazioni su diverse specie di pinguini, un grafico a barre potrebbe mostrare il numero di pinguini per ciascuna specie. Le specie vengono visualizzate come etichette lungo l’asse delle ascisse, mentre l’altezza delle barre rappresenta il numero di pinguini osservati per ciascuna specie.\nIl grafico a barre consente di confrontare le dimensioni delle categorie in modo semplice e intuitivo.\nPer i dati in esame, creiamo un grafico a barre che rappresenta il numero totale di pinguini per isola.\n\nggplot(df, aes(x = island)) +\n  geom_bar(fill = palette_okabe_enhanced[1]) +\n  ggtitle(\"Numero totale di pinguini per isola\") +\n  xlab(\"Isola\") +\n  ylab(\"Numero di pinguini\") +\n  scale_fill_okabe_ito(order = c(5,1,3,4,2,6,7,8,9))\n\n\n\n\n\n\n\nUn secondo grafico a barre mostra il numero totale di pinguini per specie.\n\nggplot(df, aes(x = species)) +\n  geom_bar(fill = palette_okabe_enhanced[1]) +\n  ggtitle(\"Numero totale di pinguini per specie\") +\n  xlab(\"Specie\") +\n  ylab(\"Numero di pinguini\")\n\n\n\n\n\n\n\n\n17.6.2 Grafico a Barre con Due Variabili\nÈ possibile visualizzare contemporaneamente le distribuzioni di due variabili categoriali utilizzando un grafico a barre. Questo tipo di grafico è particolarmente utile per esaminare la relazione tra due variabili categoriali.\nIn un grafico a barre con due variabili, una delle variabili viene rappresentata sull’asse orizzontale come categoria principale, mentre la seconda variabile è distinta tramite colori diversi o barre impilate. In questo modo, possiamo confrontare facilmente le frequenze o le proporzioni delle categorie della prima variabile, osservando allo stesso tempo come sono distribuite le categorie della seconda variabile all’interno di ciascuna categoria principale.\nAd esempio, visualizziamo il numero di pinguini per specie e isola. A qusto fine possiamo creare un grafico a barre dove le isole sono rappresentate sull’asse delle ascisse e i diversi colori delle barre mostrano la distribuzione delle specie su ciascuna isola. Questo approccio consente di esplorare come le due variabili categoriali (specie e isola) interagiscono visivamente.\n\nggplot(df, aes(x = island, fill = species)) +\n  geom_bar(position = \"stack\") +\n  scale_fill_okabe_ito(order = c(5,1,3,4,2,6,7,8,9)) +\n  ggtitle(\"Numero di pinguini per specie e isola\") +\n  xlab(\"Isola\") +\n  ylab(\"Numero di pinguini\") +\n  labs(fill = \"Specie\")\n\n\n\n\n\n\n\nIn alternativa, è possibile creare un grafico a barre dove le specie sono rappresentate sull’asse delle ascisse e i diversi colori delle barre mostrano la distribuzione delle isole per ciascuna specie.\n\nggplot(df, aes(x = species, fill = island)) +\n  geom_bar(position = \"stack\") +\n  scale_fill_okabe_ito(order = c(5,1,3,4,2,6,7,8,9)) +\n  ggtitle(\"Numero di pinguini per isola e specie\") +\n  xlab(\"Specie\") +\n  ylab(\"Numero di pinguini\") +\n  labs(fill = \"Isola\")\n\n\n\n\n\n\n\nIn alternativa all’uso delle frequenze assolute, possiamo rappresentare i dati utilizzando le frequenze relative. Questo approccio permette di confrontare meglio le categorie indipendentemente dal numero totale di osservazioni. Nella figura seguente, ad esempio, viene mostrata la proporzione di pinguini di ciascuna specie per ogni isola, evidenziando la distribuzione relativa delle specie su ogni isola, anziché il conteggio assoluto. Questa rappresentazione aiuta a visualizzare le differenze nella composizione delle specie, anche se il numero complessivo di pinguini varia tra le isole.\n\nggplot(df, aes(x = island, fill = species)) +\n  geom_bar(position = \"fill\") +\n   scale_fill_okabe_ito(order = c(5,1,3,4,2,6,7,8,9)) +\n  ggtitle(\"Proporzione di pinguini per specie e isola\") +\n  xlab(\"Isola\") +\n  ylab(\"Proporzione\") +\n  labs(fill = \"Specie\")",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#mosaic-plots",
    "href": "chapters/eda/04_exploring_qualitative_data.html#mosaic-plots",
    "title": "17  Esplorare i dati qualitativi",
    "section": "\n17.7 Mosaic plots",
    "text": "17.7 Mosaic plots\nIl Mosaic plot è una tecnica di visualizzazione particolarmente adatta per rappresentare tabelle di contingenza. Questo tipo di grafico somiglia a un grafico a barre impilate standard, ma con un vantaggio importante: oltre a visualizzare la suddivisione interna delle categorie, permette di vedere anche le dimensioni relative dei gruppi della variabile principale.\nIn altre parole, il Mosaic plot non solo mostra come si distribuiscono le categorie di una variabile secondaria all’interno di ogni gruppo della variabile principale, ma fornisce anche un’idea visiva della grandezza complessiva dei gruppi. Questo lo rende uno strumento utile per analizzare e interpretare le relazioni tra due variabili categoriali, evidenziando sia la proporzione all’interno di ciascun gruppo, sia la grandezza relativa tra i gruppi stessi.\n\nmosaic(\n  ~ species + island, \n  data = df, \n  main = \"Mosaic Plot of Species and Island\",\n  shade = TRUE\n)\n\n\n\n\n\n\n\n\n\nisland: Variabile rappresentata come suddivisione orizzontale all’interno di ogni gruppo di species (variabile principale).\n\nspecies: Variabile rappresentata lungo l’asse verticale (variabile secondaria suddivisa all’interno di ogni gruppo di island).\n\n\n17.7.0.1 Interpretazione\n\n\nDimensione dei Rettangoli:\n\nLa larghezza dei rettangoli corrisponde alla dimensione relativa dei gruppi della variabile island.\nL’altezza dei rettangoli rappresenta la proporzione delle categorie di species all’interno di ciascun gruppo di island.\n\n\n\nColorazione (se shade = TRUE):\n\nI colori indicano deviazioni rispetto all’indipendenza statistica tra le variabili.\nUn rettangolo scuro rappresenta una frequenza maggiore o minore di quella attesa in caso di indipendenza tra species e island.\n\n\n\nOsservazioni Specifiche:\n\n\nRettangoli alti e larghi: Indicano una categoria di species molto rappresentata su un’isola specifica.\n\nRettangoli sottili o stretti: Indicano una rappresentazione meno significativa o assente di una specie su un’isola.\n\n\n\nIn conclusione, il Mosaic plot è uno strumento grafico efficace per analizzare le relazioni tra due variabili categoriali. Ti permette di esplorare:\n\nLa proporzione interna delle categorie.\nLe dimensioni relative dei gruppi della variabile principale.\n\nQuesto grafico è particolarmente utile per individuare schemi o associazioni, come una specie predominante su un’isola specifica o una distribuzione equilibrata tra gruppi. La sua rappresentazione intuitiva lo rende ideale per ricerche in psicologia, scienze sociali e biologia.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#proporzioni-di-riga-e-colonna",
    "href": "chapters/eda/04_exploring_qualitative_data.html#proporzioni-di-riga-e-colonna",
    "title": "17  Esplorare i dati qualitativi",
    "section": "\n17.8 Proporzioni di Riga e Colonna",
    "text": "17.8 Proporzioni di Riga e Colonna\nNelle sezioni precedenti abbiamo esaminato la visualizzazione di due variabili categoriali utilizzando grafici a barre e Mosaic plot. Tuttavia, non abbiamo ancora discusso come vengono calcolate le proporzioni mostrate in questi grafici. In questa sezione ci concentreremo sulla suddivisione frazionaria di una variabile rispetto a un’altra, esplorando come possiamo modificare la nostra tabella di contingenza per ottenere una visione più dettagliata delle proporzioni.\nQuesto ci permetterà di comprendere meglio le relazioni tra le due variabili, visualizzando non solo i conteggi assoluti, ma anche le proporzioni relative per riga o per colonna. Le proporzioni di riga mostrano la distribuzione di una variabile all’interno delle categorie di un’altra, mentre le proporzioni di colonna evidenziano la distribuzione inversa.\nCalcoliamo le proporzioni di specie per isola.\n\ndf %&gt;%\n  tabyl(island, species) %&gt;%  # Crea la tabella di contingenza\n  adorn_percentages(\"row\") %&gt;%  # Calcola le proporzioni per riga\n  adorn_totals(\"col\") %&gt;%  # Aggiunge la colonna dei totali\n  adorn_pct_formatting(digits = 2)  # Formatta le percentuali con 2 decimali\n#&gt;     island  Adelie Chinstrap Gentoo   Total\n#&gt;     Biscoe  26.99%     0.00% 73.01% 100.00%\n#&gt;      Dream  44.72%    55.28%  0.00% 100.00%\n#&gt;  Torgersen 100.00%     0.00%  0.00% 100.00%\n\nCalcoliamo nuovamente le proporzioni, ma questa volta in funzione delle colonne (per isola).\n\ndf |&gt; \n  tabyl(island, species) |&gt; \n  adorn_percentages(\"col\") |&gt; \n  adorn_totals(\"row\") |&gt; \n  adorn_pct_formatting(digits = 2) # Formatta le percentuali con 2 decimali\n#&gt;     island  Adelie Chinstrap  Gentoo\n#&gt;     Biscoe  30.14%     0.00% 100.00%\n#&gt;      Dream  37.67%   100.00%   0.00%\n#&gt;  Torgersen  32.19%     0.00%   0.00%\n#&gt;      Total 100.00%   100.00% 100.00%",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#confronto-tra-gruppi",
    "href": "chapters/eda/04_exploring_qualitative_data.html#confronto-tra-gruppi",
    "title": "17  Esplorare i dati qualitativi",
    "section": "\n17.9 Confronto tra Gruppi",
    "text": "17.9 Confronto tra Gruppi\nAlcune delle analisi più interessanti emergono confrontando i dati numerici tra diversi gruppi. In questa sezione approfondiremo alcune delle tecniche che abbiamo già esplorato per visualizzare i dati numerici di più gruppi su uno stesso grafico e introdurremo nuovi metodi per confrontare i dati numerici tra gruppi. Queste tecniche ci permetteranno di osservare meglio le differenze e le somiglianze tra gruppi, mettendo in evidenza tendenze, variazioni e altre caratteristiche rilevanti.\nQui consideriamo due variabili qualitative. Creiamo un grafico a barre per confrontare la distribuzione del genere per specie.\n\nggplot(df, aes(x = species, fill = sex)) +\n  geom_bar(position = \"dodge\") +\n  scale_fill_okabe_ito(order = c(5,1,3,4,2,6,7,8,9)) +\n  ggtitle(\"Distribuzione del genere per specie\") +\n  xlab(\"Specie\") +\n  ylab(\"Conteggio\")\n\n\n\n\n\n\n\nSpesso, i confronti più interessanti riguardano come una variabile numerica varia in base a una o più categorie. Questo tipo di analisi ci aiuta a capire differenze tra gruppi e a individuare modelli o tendenze.\nNel grafico seguente, confrontiamo la distribuzione del peso corporeo (body_mass_g) in base alla specie e al genere. Le aree colorate rappresentano come si distribuisce il peso per maschi e femmine all’interno di ciascuna specie. Le linee più strette al centro delle aree colorate aggiungono ulteriori dettagli, mostrando i valori più comuni e come si concentrano i dati per ciascun gruppo.\n\nggplot(df, aes(x = species, y = body_mass_g, fill = sex)) +\n  geom_violin(\n    position = position_dodge(width = 0.9), alpha = 0.5\n  ) +\n  geom_boxplot(\n    position = position_dodge(width = 0.9), width = 0.2, alpha = 0.8\n  ) +\n  scale_fill_okabe_ito(order = c(5,1,3,4,2,6,7,8,9)) +\n  ggtitle(\n    \"Distribuzione della massa corporea\\nin base alla specie e al genere\"\n  ) +\n  xlab(\"Specie\") +\n  ylab(\"Massa corporea (g)\") +\n  labs(fill = \"Genere\")\n\n\n\n\n\n\n\n\n\nAree colorate (grafico a violino):\n\nRappresentano l’intera distribuzione dei pesi per ogni gruppo (specie e genere). Più l’area è larga in un punto, maggiore è il numero di pinguini con quel peso.\n\n\n\nLinee strette al centro (boxplot):\n\nForniscono un riassunto visivo dei dati, mostrando dove i pesi si concentrano maggiormente e quanto variano all’interno di ciascun gruppo.\n\n\n\nCosa possiamo osservare:\n\nPossiamo vedere facilmente se i maschi e le femmine di una stessa specie tendono ad avere pesi simili o differenti, e se c’è una certa sovrapposizione tra i due gruppi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/04_exploring_qualitative_data.html#informazioni-sullambiente-di-sviluppo",
    "title": "17  Esplorare i dati qualitativi",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] grid      stats     graphics  grDevices utils     datasets  methods  \n#&gt; [8] base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] janitor_2.2.1     vcd_1.4-13        viridis_0.6.5     viridisLite_0.4.2\n#&gt;  [5] ggokabeito_0.1.0  see_0.9.0         gridExtra_2.3     patchwork_1.3.0  \n#&gt;  [9] bayesplot_1.11.1  psych_2.4.12      scales_1.3.0      markdown_1.13    \n#&gt; [13] knitr_1.49        lubridate_1.9.4   forcats_1.0.0     stringr_1.5.1    \n#&gt; [17] dplyr_1.1.4       purrr_1.0.2       readr_2.1.5       tidyr_1.3.1      \n#&gt; [21] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [25] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      xfun_0.49         htmlwidgets_1.6.4 lattice_0.22-6   \n#&gt;  [5] tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2       generics_0.1.3   \n#&gt;  [9] parallel_4.4.2    pacman_0.5.1      pkgconfig_2.0.3   R.oo_1.27.0      \n#&gt; [13] data.table_1.16.4 lifecycle_1.0.4   compiler_4.4.2    farver_2.1.2     \n#&gt; [17] munsell_0.5.1     mnormt_2.1.1      snakecase_0.11.1  htmltools_0.5.8.1\n#&gt; [21] pillar_1.10.0     MASS_7.3-63       R.utils_2.12.3    nlme_3.1-166     \n#&gt; [25] tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4     labeling_0.4.3   \n#&gt; [29] rprojroot_2.0.4   fastmap_1.2.0     colorspace_2.1-1  cli_3.6.3        \n#&gt; [33] magrittr_2.0.3    withr_3.0.2       timechange_0.3.0  rmarkdown_2.29   \n#&gt; [37] zoo_1.8-12        R.methodsS3_1.8.2 hms_1.1.3         evaluate_1.0.1   \n#&gt; [41] lmtest_0.9-40     rlang_1.1.4       glue_1.8.0        jsonlite_1.8.9   \n#&gt; [45] R6_2.5.1",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html",
    "href": "chapters/eda/05_exploring_numeric_data.html",
    "title": "18  Esplorare i dati numerici",
    "section": "",
    "text": "Introduzione\nIn questo capitolo ci concentreremo sull’analisi dei dati numerici. In particolare, esamineremo le distribuzioni di frequenza e i quantili, insieme alle tecniche di visualizzazione più comuni, come l’istogramma, l’istogramma smussato e il box-plot. Tratteremo sia gli aspetti computazionali che quelli interpretativi di queste misure, fornendo strumenti utili non solo per una comprensione personale, ma anche per la comunicazione efficace dei risultati, in particolare con chi utilizza questi dati per prendere decisioni pratiche nel mondo reale.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#i-dati-sulle-aspettative-negative-nella-depressione",
    "href": "chapters/eda/05_exploring_numeric_data.html#i-dati-sulle-aspettative-negative-nella-depressione",
    "title": "18  Esplorare i dati numerici",
    "section": "\n18.1 I dati sulle aspettative negative nella depressione",
    "text": "18.1 I dati sulle aspettative negative nella depressione\nConsideriamo i dati relativi alle aspettative negative, individuate come un meccanismo chiave nel mantenimento della depressione (Zetsche et al., 2019). Supponiamo di voler analizzare la distribuzione di una singola variabile quantitativa.\nImportiamo i dati:\n\ndf = rio::import(here::here(\"data\", \"data.mood.csv\"))\n\nPer questo esercizio, ci concentreremo sulle colonne esm_id (il codice del soggetto), group (il gruppo) e bdi (il valore BDI-II).\n\ndf &lt;- df |&gt; \n  dplyr::select(\"esm_id\", \"group\", \"bdi\")\ndf |&gt; \n  head()\n#&gt;   esm_id group bdi\n#&gt; 1     10   mdd  25\n#&gt; 2     10   mdd  25\n#&gt; 3     10   mdd  25\n#&gt; 4     10   mdd  25\n#&gt; 5     10   mdd  25\n#&gt; 6     10   mdd  25\n\nSe elenchiamo le modalità presenti in group utilizzando il metodo unique(), scopriamo che corrispondono a mdd (pazienti) e ctl (controlli sani).\n\ndf$group |&gt; \n  unique()\n#&gt; [1] \"mdd\" \"ctl\"\n\nRimuoviamo i duplicati per ottenere un unico valore BDI-II per ogni soggetto:\n\ndf &lt;- df[!duplicated(df), ]\n\nVerifichiamo di avere ottenuto il risultato desiderato.\n\ndim(df)\n#&gt; [1] 67  3\n\n\nhead(df)\n#&gt;    esm_id group bdi\n#&gt; 1      10   mdd  25\n#&gt; 15      9   mdd  30\n#&gt; 30      6   mdd  26\n#&gt; 46      7   mdd  35\n#&gt; 65     12   mdd  44\n#&gt; 83     16   mdd  30\n\nSi noti che il nuovo DataFrame (con 67 righe) conserva il “nome” delle righe (ovvero, l’indice di riga) del DataFrame originario (con 1188 righe). Per esempio, il secondo soggetto (con codice identificativo 9) si trova sulla seconda riga del DataFrame, ma il suo indice di riga è 15. Questo non ha nessuna conseguenza perché non useremo l’indice di riga nelle analisi seguenti.\nEliminiamo eventuali valori mancanti:\n\ndf &lt;- df[!is.na(df$bdi), ]\n\nOtteniamo così il DataFrame finale per gli scopi presenti (66 righe e 3 colonne):\n\ndim(df)\n#&gt; [1] 66  3\n\nStampiamo i valori BDI-II presentandoli ordinati dal più piccolo al più grande:\n\ndf$bdi |&gt; \n  sort()\n#&gt;  [1]  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  1  1  1  1  1  1\n#&gt; [25]  1  2  2  2  2  3  3  3  5  7  9 12 19 22 22 24 25 25 26 26 26 27 27 28\n#&gt; [49] 28 30 30 30 31 31 33 33 34 35 35 35 36 39 41 43 43 44\n\nNel linguaggio statistico, un’osservazione rappresenta l’informazione raccolta da un singolo individuo o entità che partecipa allo studio. Nel caso del dataset utilizzato da Zetsche et al. (2019), l’unità di osservazione è costituita dai partecipanti allo studio. Ogni riga del DataFrame, denominato df, corrisponde quindi a un individuo distinto incluso nell’analisi.\nLe variabili, invece, riflettono le diverse caratteristiche degli individui o delle entità considerate. Per i dati in esame, questo concetto si esprime così:\n\nOgni colonna di df rappresenta una variabile che descrive una specifica proprietà comune ai partecipanti.\nLe variabili sono identificate da etichette nelle colonne, come esa_id (l’identificativo del soggetto), mdd (il gruppo di appartenenza), e bdi (il punteggio del test BDI-II).\n\nIn termini simbolisi, per indicare una singola osservazione della variabile generica \\(X\\), si utilizza la notazione \\(X_i\\), dove \\(i\\) rappresenta l’indice dell’osservazione. Questo implica che abbiamo un valore diverso di \\(X\\) per ogni differente \\(i\\). Nel caso presente, con 67 osservazioni, \\(i\\) varia da 1 a 67. Così, per rappresentare la seconda osservazione (quella con \\(i=2\\)), useremo la notazione \\(X_2\\).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#distribuzioni-di-frequenza",
    "href": "chapters/eda/05_exploring_numeric_data.html#distribuzioni-di-frequenza",
    "title": "18  Esplorare i dati numerici",
    "section": "\n18.2 Distribuzioni di frequenza",
    "text": "18.2 Distribuzioni di frequenza\nCome osservato nell’output della sezione precedente, i dati grezzi non forniscono un’interpretazione immediata. Per rendere i dati più comprensibili e sintetici, è utile costruire una distribuzione di frequenza.\nUna distribuzione di frequenza mostra quante volte i valori di una variabile si verificano all’interno di intervalli specifici. Nel caso dei punteggi BDI-II, possiamo raggruppare i punteggi in quattro classi:\n\n0–13: depressione minima\n14–19: depressione lieve-moderata\n20–28: depressione moderata-severa\n29–63: depressione severa\n\nOgni classe, denotata come \\(\\Delta_i\\), rappresenta un intervallo di valori, definito come \\([a_i, b_i)\\) (aperto a destra) o \\((a_i, b_i]\\) (aperto a sinistra), dove \\(a_i\\) e \\(b_i\\) sono rispettivamente il limite inferiore e superiore della classe. A ciascuna classe si associa un’ampiezza, data da \\(b_i - a_i\\), e un valore centrale, indicato con \\(\\bar{x}_i\\). Poiché ogni osservazione \\(x_i\\) appartiene a una sola classe \\(\\Delta_i\\), possiamo calcolare le seguenti quantità:\n\n\nFrequenza assoluta \\(n_i\\): il numero di osservazioni che rientrano nella classe \\(\\Delta_i\\).\n\nProprietà: \\(n_1 + n_2 + \\dots + n_m = n\\), dove \\(n\\) è il numero totale di osservazioni.\n\n\n\nFrequenza relativa \\(f_i\\): la proporzione di osservazioni in ciascuna classe, calcolata come \\(f_i = n_i/n\\).\n\nProprietà: \\(f_1 + f_2 + \\dots + f_m = 1\\).\n\n\nFrequenza cumulata \\(N_i\\): il numero totale di osservazioni che rientrano nelle classi fino alla \\(i\\)-esima inclusa, calcolata come \\(N_i = \\sum_{j=1}^i n_j\\).\nFrequenza cumulata relativa \\(F_i\\): la somma delle frequenze relative fino alla \\(i\\)-esima classe, data da \\(F_i = \\frac{N_i}{n} = \\sum_{j=1}^i f_j\\).\n\nQueste misure permettono di riassumere in modo efficace la distribuzione dei punteggi e facilitano l’interpretazione delle caratteristiche del campione.\n\n18.2.1 Frequenze Assolute e Relative\nPer ottenere la distribuzione di frequenza assoluta e relativa dei valori BDI-II nel dataset di zetsche_2019future, è necessario aggiungere al DataFrame df una colonna contenente una variabile categoriale che classifichi ciascuna osservazione in una delle quattro classi che descrivono la gravità della depressione. Questo risultato si ottiene utilizzando la funzione cut().\nNella funzione cut():\n\nIl primo argomento, x, è un vettore unidimensionale (ad esempio, un vettore di tipo numeric o una colonna di un DataFrame) che contiene i dati da classificare.\nIl secondo argomento, breaks, definisce gli intervalli delle classi, specificandone i limiti inferiori e superiori.\nL’argomento include.lowest = TRUE garantisce che il limite inferiore dell’intervallo più basso sia incluso nella classificazione. Nel nostro caso, questo è particolarmente utile per assicurare che i valori uguali al limite inferiore siano assegnati correttamente.\n\nDi seguito, il codice per aggiungere la variabile categoriale al DataFrame:\n\n# Creare una variabile categoriale per classi di depressione\ndf &lt;- df %&gt;% \n  mutate(\n    bdi_class = cut(\n      bdi, \n      breaks = c(0, 13.5, 19.5, 28.5, 63),\n      include.lowest = TRUE\n    )\n  )\n\nQuesto codice suddivide i valori della variabile bdi in quattro intervalli corrispondenti ai livelli di gravità della depressione:\n\n0–13: depressione minima\n14–19: depressione lieve-moderata\n20–28: depressione moderata-severa\n29–63: depressione severa\n\nOgni osservazione verrà assegnata al corrispondente intervallo, creando così una nuova colonna bdi_class nel DataFrame df.\n\n18.2.1.1 Frequenze assolute\n\ntable(df$bdi_class)\n#&gt; \n#&gt;    [0,13.5] (13.5,19.5] (19.5,28.5]   (28.5,63] \n#&gt;          36           1          12          17\n\n\n18.2.1.2 Frequenze relative\n\nprop.table(table(df$bdi_class))\n#&gt; \n#&gt;    [0,13.5] (13.5,19.5] (19.5,28.5]   (28.5,63] \n#&gt;      0.5455      0.0152      0.1818      0.2576\n\n\n18.2.2 Distribuzioni congiunte\nLe variabili possono anche essere analizzate insieme tramite le distribuzioni congiunte di frequenze. Queste distribuzioni rappresentano l’insieme delle frequenze assolute o relative ad ogni possibile combinazione di valori delle variabili. Ad esempio, se l’insieme di variabili \\(V\\) è composto da due variabili, \\(X\\) e \\(Y\\), ciascuna delle quali può assumere due valori, 1 e 2, allora una possibile distribuzione congiunta di frequenze relative per \\(V\\) potrebbe essere espressa come \\(f(X = 1, Y = 1) = 0.2\\), \\(f(X = 1, Y = 2) = 0.1\\), \\(f(X = 2, Y = 1) = 0.5\\), e \\(f(X = 2, Y = 2) = 0.2\\). Come nel caso delle distribuzioni di frequenze relative di una singola variabile, le frequenze relative di una distribuzione congiunta devono sommare a 1.\nPer i dati dell’esempio precedente, la funzione prop.table() può essere utilizzata anche per produrre questo tipo di tabella: basta indicare le serie corrispondenti alle variabili considerate come valori degli argomenti bdi_class e group.\n\nprop.table(table(df$bdi_class, df$group))\n#&gt;              \n#&gt;                  ctl    mdd\n#&gt;   [0,13.5]    0.5455 0.0000\n#&gt;   (13.5,19.5] 0.0000 0.0152\n#&gt;   (19.5,28.5] 0.0000 0.1818\n#&gt;   (28.5,63]   0.0000 0.2576",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#istogramma",
    "href": "chapters/eda/05_exploring_numeric_data.html#istogramma",
    "title": "18  Esplorare i dati numerici",
    "section": "\n18.3 Istogramma",
    "text": "18.3 Istogramma\nUn istogramma rappresenta graficamente una distribuzione di frequenze. Un istogramma mostra sulle ascisse i limiti delle classi \\(\\Delta_i\\) e sulle ordinate la densità della frequenza relativa della variabile \\(X\\) nella classe \\(\\Delta_i\\). La densità della frequenza relativa è misurata dalla funzione costante a tratti \\(\\varphi_n(x)= \\frac{f_i}{b_i-a_i}\\), dove \\(f_i\\) è la frequenza relativa della classe \\(\\Delta_i\\) e \\(b_i - a_i\\) rappresenta l’ampiezza della classe. In questo modo, l’area del rettangolo associato alla classe \\(\\Delta_i\\) sull’istogramma sarà proporzionale alla frequenza relativa \\(f_i\\). È importante notare che l’area totale dell’istogramma delle frequenze relative è uguale a 1.0, poiché rappresenta la somma delle aree dei singoli rettangoli.\nPer fare un esempio, costruiamo un istogramma per i valori BDI-II di Zetsche et al. (2019). Con i quattro intervalli individuati dai cut-off del BDI-II creo una prima versione dell’istogramma – si notino le frequenze assolute sull’asse delle ordinate.\n\nggplot(df, aes(x = bdi)) +\n  geom_histogram(\n    breaks = c(0, 13.5, 19.5, 28.5, 63),\n    aes(y = after_stat(density)),\n  ) +\n  labs(\n    title = \"Istogramma delle frequenze relative\", \n    x = \"BDI-II\", \n    y = \"Densità\"\n  ) \n\n\n\n\n\n\n\nAnche se nel caso presente è sensato usare ampiezze diverse per gli intervalli delle classi, in generale gli istogrammi si costruiscono utilizzando intervalli riportati sulle ascisse con un’ampiezza uguale.\n\nggplot(df, aes(x = bdi)) +\n  geom_histogram(\n    aes(y = ..density..),\n  ) +\n  labs(\n    title = \"Istogramma delle frequenze relative\", \n    x = \"BDI-II\", \n    y = \"Densità\"\n  )\n#&gt; Warning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\n#&gt; ℹ Please use `after_stat(density)` instead.\n#&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#kernel-density-plot",
    "href": "chapters/eda/05_exploring_numeric_data.html#kernel-density-plot",
    "title": "18  Esplorare i dati numerici",
    "section": "\n18.4 Kernel density plot",
    "text": "18.4 Kernel density plot\nConfrontando le due figure precedenti, emerge chiaramente una limitazione dell’istogramma: la sua forma dipende dall’arbitrarietà con cui vengono scelti il numero e l’ampiezza delle classi, rendendo difficile interpretare correttamente la distribuzione dei dati.\nPer superare questa difficoltà, possiamo utilizzare una tecnica alternativa chiamata stima della densità kernel (KDE) – si veda l’?sec-kde. Mentre l’istogramma utilizza barre per rappresentare i dati, la KDE crea un profilo smussato che fornisce una visione più continua e meno dipendente dall’arbitrarietà delle classi.\nImmaginiamo un istogramma con classi di ampiezza molto piccola, tanto da avere una curva continua invece di barre discrete. Questo è ciò che fa la KDE: smussa il profilo dell’istogramma per ottenere una rappresentazione continua dei dati. Invece di utilizzare barre, la KDE posiziona una piccola curva (detta kernel) su ogni osservazione nel dataset. Queste curve possono essere gaussiane (a forma di campana) o di altro tipo. Ogni kernel ha un’altezza e una larghezza determinate da parametri di smussamento (o bandwidth), che controllano quanto deve essere larga e alta la curva. Tutte le curve kernel vengono sommate per creare una singola curva complessiva. Questa curva rappresenta la densità dei dati, mostrando come i dati sono distribuiti lungo il range dei valori.\nLa curva risultante dal KDE mostra la proporzione di casi per ciascun intervallo di valori. L’area sotto la curva in un determinato intervallo rappresenta la proporzione di casi della distribuzione che ricadono in quell’intervallo. Per esempio, se un intervallo ha un’area maggiore sotto la curva rispetto ad altri, significa che in quell’intervallo c’è una maggiore concentrazione di dati.\nLa curva di densità ottenuta tramite KDE fornisce dunque un’idea chiara di come i dati sono distribuiti senza dipendere dall’arbitrarietà della scelta delle classi dell’istogramma.\nCrediamo un kernel density plot per ciascuno dei due gruppi di valori BDI-II riportati da Zetsche et al. (2019).\n\nggplot(df, aes(x = bdi, fill = group)) +\n  geom_density() +\n    scale_fill_okabe_ito(order = c(5, 1, 3, 4, 2, 6, 7, 8, 9)) +\n  labs(\n    title = \"Curva di densità KDE\", \n    x = \"BDI-II\", \n    y = \"Densità\"\n  )",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#consigli-per-creare-visualizzazioni-di-dati-efficaci",
    "href": "chapters/eda/05_exploring_numeric_data.html#consigli-per-creare-visualizzazioni-di-dati-efficaci",
    "title": "18  Esplorare i dati numerici",
    "section": "\n18.5 Consigli per Creare Visualizzazioni di Dati Efficaci",
    "text": "18.5 Consigli per Creare Visualizzazioni di Dati Efficaci\nEcco alcuni suggerimenti per creare visualizzazioni di dati esplicative, efficaci e di qualità adatta alle presentazioni:\n\n\nMessaggio chiaro: Assicurati che il grafico trasmetta un messaggio chiaro e immediato (ad esempio, “Il livello di benessere psicologico dei partecipanti aumenta nel tempo”).\n\nUso del colore:\n\nUtilizza i colori in modo ponderato e con moderazione.\nNon eccedere nell’uso dei colori solo perché è possibile farlo.\nLimita l’uso a non più di cinque o sei colori in una singola figura.\nVerifica che le scelte cromatiche non distorcano le conclusioni della figura.\nEvita l’uso contemporaneo di rosso e verde nello stesso grafico, poiché queste tonalità sono difficili da distinguere per le persone daltoniche.\n\n\n\nGuidare l’attenzione:\n\nUtilizza dimensioni, colori e testo per guidare l’attenzione del pubblico.\nEvidenzia elementi particolari del grafico per enfatizzare punti chiave.\n\n\n\nGestione del sovraccarico visivo:\n\nUtilizza la trasparenza per ridurre il “sovrapplotting” (che si verifica quando ci sono molti elementi sovrapposti nel grafico, come punti o linee, rendendo difficile individuare i pattern).\nQuesta tecnica è particolarmente utile quando si visualizza una grande quantità di dati.\nSe il dataset è molto ampio e l’aggiunta di trasparenza non è sufficiente, considera la visualizzazione di un sottocampione dei dati (un campione casuale di punti dati, scelto senza sostituzione). Questa tecnica è nota come sottocampionamento.\n\n\n\nElementi testuali:\n\nI titoli, le etichette degli assi e il testo delle legende devono essere chiari e facilmente comprensibili.\nGli elementi della legenda dovrebbero essere ordinati in modo logico e coerente.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#forma-di-una-distribuzione",
    "href": "chapters/eda/05_exploring_numeric_data.html#forma-di-una-distribuzione",
    "title": "18  Esplorare i dati numerici",
    "section": "\n18.6 Forma di una Distribuzione",
    "text": "18.6 Forma di una Distribuzione\nIn statistica, la forma di una distribuzione descrive come i dati sono distribuiti intorno ai valori centrali. Si distingue tra distribuzioni simmetriche e asimmetriche, e tra distribuzioni unimodali e multimodali. Un’illustrazione grafica è fornita nella figura seguente. Nel pannello 1, la distribuzione è unimodale con asimmetria negativa; nel pannello 2, la distribuzione è unimodale con asimmetria positiva; nel pannello 3, la distribuzione è simmetrica e unimodale; nel pannello 4, la distribuzione è bimodale.\n\n\nDistribuzioni\n\nIl grafico della densità di kernel (Kernel Density Plot) dei valori BDI-II nel campione di Zetsche et al. (2019) è bimodale. Questo indica che le osservazioni della distribuzione si raggruppano in due cluster distinti: un gruppo di osservazioni tende ad avere valori BDI-II bassi, mentre l’altro gruppo tende ad avere valori BDI-II alti. Questi due cluster di osservazioni corrispondono al gruppo di controllo e al gruppo clinico nel campione di dati esaminato da Zetsche et al. (2019).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#indici-di-posizione",
    "href": "chapters/eda/05_exploring_numeric_data.html#indici-di-posizione",
    "title": "18  Esplorare i dati numerici",
    "section": "\n18.7 Indici di posizione",
    "text": "18.7 Indici di posizione\n\n18.7.1 Quantili\nLa distribuzione dei valori BDI-II di Zetsche et al. (2019) può essere sintetizzata attraverso l’uso dei quantili, che sono valori caratteristici che suddividono i dati in parti ugualmente numerose. I quartili sono tre quantili specifici: il primo quartile, \\(q_1\\), divide i dati in due parti, lasciando a sinistra il 25% del campione; il secondo quartile, \\(q_2\\), corrisponde alla mediana e divide i dati in due parti uguali; il terzo quartile lascia a sinistra il 75% del campione.\nInoltre, ci sono altri indici di posizione chiamati decili e percentili che suddividono i dati in parti di dimensioni uguali a 10% e 1%, rispettivamente.\nPer calcolare i quantili, i dati vengono prima ordinati in modo crescente e poi viene determinato il valore di \\(np\\), dove \\(n\\) è la dimensione del campione e \\(p\\) è l’ordine del quantile. Se \\(np\\) non è un intero, il valore del quantile corrisponde al valore del dato che si trova alla posizione successiva alla parte intera di \\(np\\). Se \\(np\\) è un intero, il valore del quantile corrisponde alla media dei dati nelle posizioni \\(k\\) e \\(k+1\\), dove \\(k\\) è la parte intera di \\(np\\).\nGli indici di posizione possono essere utilizzati per creare un box-plot, una rappresentazione grafica della distribuzione dei dati che è molto popolare e può essere utilizzata in alternativa ad un istogramma.\nAd esempio, per calcolare la mediana della distribuzione dei nove soggetti con un unico episodio di depressione maggiore del campione clinico di Zetsche et al. (2019), si determina il valore di \\(np = 9 \\cdot 0.5 = 4.5\\), che non è un intero. Pertanto, il valore del secondo quartile è pari al valore del dato che si trova alla posizione successiva alla parte intera di \\(np\\), ovvero \\(q_2 = x_{4 + 1} = 27\\). Per calcolare il quantile di ordine \\(2/3\\), si determina il valore di \\(np = 9 \\cdot 2/3 = 6\\), che è un intero. Quindi, il valore del quantile corrisponde alla media dei dati nelle posizioni \\(6\\) e \\(7\\), ovvero \\(q_{\\frac{2}{3}} = \\frac{1}{2} (x_{6} + x_{7}) = \\frac{1}{2} (33 + 33) = 33\\).\nUsiamo quantile() per trovare la soluzione dell’esercizio precedente.\n\nx = c(19, 26, 27, 28, 28, 33, 33, 41, 43)\nquantile(x, 2 / 3)\n#&gt; 66.66667% \n#&gt;        33",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#mostrare-i-dati",
    "href": "chapters/eda/05_exploring_numeric_data.html#mostrare-i-dati",
    "title": "18  Esplorare i dati numerici",
    "section": "\n18.8 Mostrare i dati",
    "text": "18.8 Mostrare i dati\n\n18.8.1 Diagramma a scatola\nIl box plot è uno strumento grafico che visualizza la dispersione di una distribuzione. Per creare un box plot, si disegna un rettangolo (la “scatola”) di altezza arbitraria, basato sulla distanza interquartile (IQR), che corrisponde alla differenza tra il terzo quartile (\\(q_{0.75}\\)) e il primo quartile (\\(q_{0.25}\\)). La mediana (\\(q_{0.5}\\)) è rappresentata da una linea all’interno del rettangolo.\nAi lati della scatola, vengono tracciati due segmenti di retta, detti “baffi”, che rappresentano i valori adiacenti inferiore e superiore. Il valore adiacente inferiore è il valore più basso tra le osservazioni che è maggiore o uguale al primo quartile meno 1.5 volte la distanza interquartile. Il valore adiacente superiore è il valore più alto tra le osservazioni che è minore o uguale al terzo quartile più 1.5 volte la distanza interquartile.\nSe ci sono dei valori che cadono al di fuori dei valori adiacenti, vengono chiamati “valori anomali” e sono rappresentati individualmente nel box plot per evidenziare la loro presenza e posizione. In questo modo, il box plot fornisce una rappresentazione visiva della distribuzione dei dati, permettendo di individuare facilmente eventuali valori anomali e di comprendere la dispersione dei dati.\n\nUtilizziamo un box-plot per rappresentare graficamente la distribuzione dei punteggi BDI-II nel gruppo dei pazienti e nel gruppo di controllo.\n\nggplot(df, aes(x = group, y = bdi)) +\n  geom_boxplot() +\n  labs(\n    title = \"Box plot per gruppo\", \n    x = \"Gruppo\", \n    y = \"BDI-II\"\n  )\n\n\n\n\n\n\n\nUn risultato migliore si ottiene utilizzando un grafico a violino (violin plot) e includendo anche i dati grezzi.\n\n18.8.2 Grafico a Violino\nI grafici a violino combinano le caratteristiche dei box plot e dei grafici di densità di kernel (KDE plot) per offrire una rappresentazione più dettagliata dei dati. A questi grafici vengono sovrapposti i dati grezzi, fornendo una visione completa della distribuzione e delle caratteristiche dei dati.\n\nggplot(df, aes(x = group, y = bdi, fill = group)) +\n  geom_violin() +\n  geom_dotplot(\n    binaxis = \"y\",\n    stackdir = \"center\",\n    dotsize = 0.5,\n    fill = 1\n  ) +\n    scale_fill_okabe_ito(order = c(5, 1, 3, 4, 2, 6, 7, 8, 9)) +\n  labs(\n    title = \"Violin plot con overlay dei punti grezzi\",\n    x = \"Gruppo\",\n    y = \"BDI-II\"\n  )\n#&gt; Bin width defaults to 1/30 of the range of the data. Pick better value with\n#&gt; `binwidth`.\n\n\n\n\n\n\n\n\n18.8.3 Grafico Beeswarm\nIl pacchetto {ggbeeswarm} include una funzione chiamata geom_beeswarm, che può essere utilizzata per creare un grafico beeswarm in ggplot2.\nUn grafico beeswarm è una variazione del grafico a punti che disperde i dati in modo che non si sovrappongano, rendendo visibili tutti i singoli punti dati. Questo tipo di visualizzazione è particolarmente utile quando si desidera esaminare la distribuzione e la densità di un set di dati, senza ricorrere all’uso di barre d’errore o di scatole e baffi (boxplot), mantenendo un’alta leggibilità anche quando i set di dati sono densi.\n\nggplot(df, aes(x = group, y = bdi, color = group)) +\n  geom_beeswarm(cex = 3) +\n  labs(\n    title = \"Violin plot con overlay dei punti grezzi\",\n    x = \"Gruppo\",\n    y = \"BDI-II\"\n  )",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#riflessioni-conclusive",
    "href": "chapters/eda/05_exploring_numeric_data.html#riflessioni-conclusive",
    "title": "18  Esplorare i dati numerici",
    "section": "\n18.9 Riflessioni Conclusive",
    "text": "18.9 Riflessioni Conclusive\nAbbiamo esplorato diverse tecniche per sintetizzare e visualizzare i dati, includendo distribuzioni di frequenze, istogrammi e grafici di densità. Questi strumenti sono essenziali per comprendere meglio i dati e presentare risultati in modo chiaro e informativo.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/05_exploring_numeric_data.html#informazioni-sullambiente-di-sviluppo",
    "title": "18  Esplorare i dati numerici",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] ggbeeswarm_0.7.2 ggokabeito_0.1.0 see_0.9.0        gridExtra_2.3   \n#&gt;  [5] patchwork_1.3.0  bayesplot_1.11.1 psych_2.4.12     scales_1.3.0    \n#&gt;  [9] markdown_1.13    knitr_1.49       lubridate_1.9.4  forcats_1.0.0   \n#&gt; [13] stringr_1.5.1    dplyr_1.1.4      purrr_1.0.2      readr_2.1.5     \n#&gt; [17] tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0 \n#&gt; [21] rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     R.oo_1.27.0       rprojroot_2.0.4  \n#&gt; [13] jsonlite_1.8.9    R.utils_2.12.3    mnormt_2.1.1      cli_3.6.3        \n#&gt; [17] rlang_1.1.4       R.methodsS3_1.8.2 munsell_0.5.1     withr_3.0.2      \n#&gt; [21] yaml_2.3.10       tools_4.4.2       parallel_4.4.2    tzdb_0.4.0       \n#&gt; [25] colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5       R6_2.5.1         \n#&gt; [29] lifecycle_1.0.4   htmlwidgets_1.6.4 vipor_0.4.7       beeswarm_0.4.0   \n#&gt; [33] pkgconfig_2.0.3   pillar_1.10.0     gtable_0.3.6      data.table_1.16.4\n#&gt; [37] glue_1.8.0        xfun_0.49         tidyselect_1.2.1  farver_2.1.2     \n#&gt; [41] htmltools_0.5.8.1 nlme_3.1-166      labeling_0.4.3    rmarkdown_2.29   \n#&gt; [45] compiler_4.4.2",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#bibliografia",
    "href": "chapters/eda/05_exploring_numeric_data.html#bibliografia",
    "title": "18  Esplorare i dati numerici",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nZetsche, U., Buerkner, P.-C., & Renneberg, B. (2019). Future expectations in clinical depression: biased or realistic? Journal of Abnormal Psychology, 128(7), 678–688.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html",
    "href": "chapters/eda/06_data_visualization.html",
    "title": "19  Principi della visualizzazione dei dati",
    "section": "",
    "text": "Introduzione\nPrerequisiti\nConcetti e competenze chiave\nIn questo capitolo verranno introdotti i principi fondamentali della visualizzazione dei dati, accompagnati da una descrizione concisa. Per un approfondimento su ciascun principio, si rimanda al capitolo Data Visualization del libro Introduction to Data Science.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#codificare-i-dati-attraverso-segnali-visivi",
    "href": "chapters/eda/06_data_visualization.html#codificare-i-dati-attraverso-segnali-visivi",
    "title": "19  Principi della visualizzazione dei dati",
    "section": "19.1 Codificare i dati attraverso segnali visivi",
    "text": "19.1 Codificare i dati attraverso segnali visivi\nIniziamo con una panoramica dei principali segnali visivi utilizzati per codificare i dati: posizione, lunghezza, angoli, area, luminosità e tonalità del colore. Tra questi, posizione e lunghezza sono i segnali visivi più efficaci e intuitivi, poiché il cervello umano è particolarmente abile nel riconoscere variazioni spaziali. Questo rende la posizione e la lunghezza strumenti potenti per la rappresentazione quantitativa. In altre parole, le persone riescono a confrontare con maggiore precisione altezze e lunghezze (come le barre in un barplot) rispetto ad angoli o aree (come in un grafico a torta).\nAngoli e aree, sebbene comunemente usati, sono segnali visivi meno efficaci. Grafici come i pie chart, che si basano su angoli e aree per rappresentare quantità, risultano spesso meno precisi e più difficili da interpretare, specialmente quando le differenze sono piccole. Anche l’uso dell’area, ad esempio nei bubble plot, può distorcere la percezione delle differenze tra i dati, a meno che non venga gestita correttamente. Anche se l’area di una bolla può essere proporzionale al valore rappresentato, la percezione umana tende a sovrastimare le differenze tra aree più grandi.\nLuminosità e tonalità del colore sono utili per rappresentare variabili qualitative o categoriali, ma possono risultare difficili da interpretare quando si tratta di confrontare quantità precise. Tuttavia, il colore gioca un ruolo cruciale nelle visualizzazioni multidimensionali, come le heatmap, dove è necessario rappresentare più di due variabili contemporaneamente. È importante, però, usare il colore con attenzione, soprattutto per garantire l’accessibilità a persone con problemi di daltonismo.\nLe tabelle sono utili quando si ha una quantità limitata di dati e si richiede una precisione numerica rigorosa. Tuttavia, per set di dati più grandi o per evidenziare tendenze e differenze, i grafici (come i barplot) sono generalmente più efficaci. Le tabelle non offrono lo stesso impatto visivo immediato e rendono più difficile l’individuazione di pattern complessi.\n\n19.1.1 Ulteriori considerazioni sulla scelta della visualizzazione\nLa scelta della visualizzazione più appropriata dipende sia dalla natura dei dati che dallo scopo della comunicazione. Per esempio:\n\nBarplot o dot plot sono ideali per confrontare valori quantitativi tra categorie.\nIstogrammi, boxplot e raincloud plots sono più adatti per descrivere la distribuzione di dati continui e fare confronti tra categorie.\nGrafici di dispersione (scatter plot) sono eccellenti per esplorare relazioni tra due variabili continue.\n\nLa chiarezza e la leggibilità sono principi fondamentali nella creazione di visualizzazioni efficaci. L’aggiunta di elementi visivi eccessivi, come decorazioni superflue o troppi colori, può distrarre dal messaggio principale. Un buon grafico deve essere semplice, ma allo stesso tempo completo, includendo solo gli elementi visivi necessari per trasmettere il messaggio desiderato.\nIn conclusione, scegliere i segnali visivi adeguati e il tipo di grafico più appropriato non solo migliora l’accuratezza della comunicazione, ma rende le informazioni più accessibili e comprensibili per il pubblico.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#quando-includere-lo-zero",
    "href": "chapters/eda/06_data_visualization.html#quando-includere-lo-zero",
    "title": "19  Principi della visualizzazione dei dati",
    "section": "19.2 Quando includere lo zero",
    "text": "19.2 Quando includere lo zero\nQuando si usa la lunghezza come segnale visivo, come nei barplot, è essenziale che l’asse parta da zero. Non farlo può essere fuorviante e far sembrare le differenze più grandi di quanto non siano in realtà. Questo errore viene spesso sfruttato nei media per esagerare differenze apparentemente significative.\nTuttavia, quando si usa la posizione (ad esempio in un grafico a dispersione), non è sempre necessario includere lo zero, soprattutto se l’interesse principale è il confronto tra gruppi rispetto alla variabilità interna.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#evitare-le-distorsioni",
    "href": "chapters/eda/06_data_visualization.html#evitare-le-distorsioni",
    "title": "19  Principi della visualizzazione dei dati",
    "section": "19.3 Evitare le distorsioni",
    "text": "19.3 Evitare le distorsioni\nUna distorsione comune si verifica quando le differenze tra quantità sono rappresentate utilizzando aree, come nei bubble plot, dove il raggio dei cerchi è proporzionale al dato. Il problema è che, poiché l’area di un cerchio è proporzionale al quadrato del raggio, le differenze sembrano molto più ampie di quanto siano realmente. Per evitare queste distorsioni, è meglio utilizzare la posizione o la lunghezza, come in un grafico a barre, per confrontare direttamente le quantità.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#ordinare-le-categorie",
    "href": "chapters/eda/06_data_visualization.html#ordinare-le-categorie",
    "title": "19  Principi della visualizzazione dei dati",
    "section": "19.4 Ordinare le categorie",
    "text": "19.4 Ordinare le categorie\nQuando si visualizzano categorie, come nei barplot o nei boxplot, è opportuno ordinarle in base al valore della variabile di interesse, anziché in ordine alfabetico. Questo aiuta a evidenziare pattern significativi e facilita il confronto tra categorie.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#evitare-i-dynamite-plots",
    "href": "chapters/eda/06_data_visualization.html#evitare-i-dynamite-plots",
    "title": "19  Principi della visualizzazione dei dati",
    "section": "19.5 Evitare i Dynamite Plots",
    "text": "19.5 Evitare i Dynamite Plots\nI dynamite plots, che mostrano la media e l’errore standard (o la deviazione standard), sono spesso utilizzati in psicologia ma sono fuorvianti. Questi grafici tendono a esagerare le differenze e possono indurre false interpretazioni. È preferibile mostrare tutti i dati, ad esempio tramite un dot plot, che fornisce un’immagine più chiara della distribuzione dei dati (Butler, 2022).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#facilitare-i-confronti",
    "href": "chapters/eda/06_data_visualization.html#facilitare-i-confronti",
    "title": "19  Principi della visualizzazione dei dati",
    "section": "19.6 Facilitare i confronti",
    "text": "19.6 Facilitare i confronti\nQuando si confrontano due distribuzioni, come in un istogramma, è fondamentale mantenere gli stessi assi per entrambi i grafici. Se le distribuzioni sono presentate su assi con scale diverse, il confronto diventa difficile e potrebbe portare a conclusioni errate. Allineare i grafici verticalmente o orizzontalmente consente di percepire più facilmente le differenze tra i gruppi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#trasformazioni-logaritmiche",
    "href": "chapters/eda/06_data_visualization.html#trasformazioni-logaritmiche",
    "title": "19  Principi della visualizzazione dei dati",
    "section": "19.7 Trasformazioni logaritmiche",
    "text": "19.7 Trasformazioni logaritmiche\nLe trasformazioni logaritmiche sono utili quando si lavora con dati distribuiti su più ordini di grandezza o quando le variazioni tra le quantità sono moltiplicative (West, 2022). L’uso della scala logaritmica in un grafico a barre o a dispersione può ridurre le distorsioni visive e migliorare l’interpretazione dei dati. Questo approccio è particolarmente utile quando alcuni valori estremi potrebbero dominare il grafico, nascondendo dettagli rilevanti.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#codificare-una-terza-variabile",
    "href": "chapters/eda/06_data_visualization.html#codificare-una-terza-variabile",
    "title": "19  Principi della visualizzazione dei dati",
    "section": "19.8 Codificare una terza variabile",
    "text": "19.8 Codificare una terza variabile\nPer rappresentare tre variabili, è possibile utilizzare un grafico di dispersione con variabili codificate attraverso dimensioni aggiuntive come il colore, la dimensione o la forma dei punti. Ad esempio, in un grafico che confronta aspettativa di vita e reddito, la dimensione dei punti potrebbe rappresentare la popolazione e il colore la regione geografica. Quando si utilizza il colore per rappresentare una variabile, è importante scegliere palette cromatiche accessibili anche per chi è affetto da daltonismo, evitando combinazioni problematiche come rosso-verde.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#evitare-pseudo-tre-dimensioni",
    "href": "chapters/eda/06_data_visualization.html#evitare-pseudo-tre-dimensioni",
    "title": "19  Principi della visualizzazione dei dati",
    "section": "19.9 Evitare pseudo-tre dimensioni",
    "text": "19.9 Evitare pseudo-tre dimensioni\nGrafici tridimensionali, come barre o pie chart 3D, spesso aggiungono confusione senza fornire informazioni aggiuntive significative. Sebbene visivamente accattivanti, questi grafici distorcono la percezione e rendono difficile l’interpretazione accurata dei dati. È preferibile mantenere le visualizzazioni bidimensionali, a meno che la terza dimensione non rappresenti effettivamente una variabile aggiuntiva.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#scegliere-il-numero-giusto-di-cifre-significative",
    "href": "chapters/eda/06_data_visualization.html#scegliere-il-numero-giusto-di-cifre-significative",
    "title": "19  Principi della visualizzazione dei dati",
    "section": "19.10 Scegliere il numero giusto di cifre significative",
    "text": "19.10 Scegliere il numero giusto di cifre significative\nÈ importante evitare l’uso di troppe cifre decimali nelle tabelle e nei grafici. Spesso, una o due cifre significative sono sufficienti per rappresentare accuratamente i dati, mentre l’aggiunta di cifre inutili può confondere il lettore e dare un falso senso di precisione. Limitiamoci a mostrare solo le cifre necessarie per trasmettere il messaggio in modo chiaro.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#conoscere-il-pubblico",
    "href": "chapters/eda/06_data_visualization.html#conoscere-il-pubblico",
    "title": "19  Principi della visualizzazione dei dati",
    "section": "19.11 Conoscere il pubblico",
    "text": "19.11 Conoscere il pubblico\nInfine, è fondamentale adattare la visualizzazione dei dati al pubblico di riferimento. Grafici progettati per l’analisi esplorativa interna possono contenere dettagli tecnici complessi, ma quando si comunica a un pubblico più ampio o non specializzato, è necessario semplificare. Ad esempio, utilizzare una scala logaritmica può essere utile per un pubblico esperto, ma confondere un pubblico generale. In questi casi, mantenere la scala lineare e spiegare chiaramente i dati aiuta a evitare malintesi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#riflessioni-conclusive",
    "href": "chapters/eda/06_data_visualization.html#riflessioni-conclusive",
    "title": "19  Principi della visualizzazione dei dati",
    "section": "19.12 Riflessioni Conclusive",
    "text": "19.12 Riflessioni Conclusive\nI principi di visualizzazione dei dati trattati in questo capitolo sono strumenti fondamentali per garantire chiarezza e accuratezza nella rappresentazione delle informazioni. Scelte appropriate di grafici, segnali visivi e trasformazioni facilitano la comprensione, riducendo la possibilità di distorsioni o interpretazioni errate.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#bibliografia",
    "href": "chapters/eda/06_data_visualization.html#bibliografia",
    "title": "19  Principi della visualizzazione dei dati",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nButler, R. C. (2022). Popularity leads to bad habits: Alternatives to «the statistics» routine of significance,«alphabet soup» and dynamite plots. In Annals of Applied Biology (Fasc. 2; Vol. 180, pp. 182–195). Wiley Online Library.\n\n\nHealy, K. (2018). Data visualization: a practical introduction. Princeton University Press.\n\n\nWest, R. M. (2022). Best practice in statistics: The use of log transformation. Annals of Clinical Biochemistry, 59(3), 162–165.\n\n\nWickham, H., Çetinkaya-Rundel, M., & Grolemund, G. (2023). R for data science. \" O’Reilly Media, Inc.\".\n\n\nWilke, C. O. (2019). Fundamentals of data visualization: a primer on making informative and compelling figures. O’Reilly Media.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html",
    "href": "chapters/eda/07_loc_scale.html",
    "title": "20  Indicatori di tendenza centrale e variabilità",
    "section": "",
    "text": "20.1 Introduzione\nLa visualizzazione grafica dei dati rappresenta il pilastro fondamentale di ogni analisi quantitativa. Grazie alle rappresentazioni grafiche adeguate, è possibile individuare importanti caratteristiche di una distribuzione, quali la simmetria o l’asimmetria, nonché la presenza di una o più mode. Successivamente, al fine di descrivere sinteticamente le principali caratteristiche dei dati, si rende necessario l’utilizzo di specifici indici numerici. In questo capitolo, verranno presentati i principali indicatori della statistica descrittiva.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#indici-di-tendenza-centrale",
    "href": "chapters/eda/07_loc_scale.html#indici-di-tendenza-centrale",
    "title": "20  Indicatori di tendenza centrale e variabilità",
    "section": "\n20.2 Indici di Tendenza Centrale",
    "text": "20.2 Indici di Tendenza Centrale\nGli indici di tendenza centrale sono misure statistiche che cercano di rappresentare un valore tipico o centrale all’interno di un insieme di dati. Sono utilizzati per ottenere una comprensione immediata della distribuzione dei dati senza dover analizzare l’intero insieme. Gli indici di tendenza centrale sono fondamentali nell’analisi statistica, in quanto forniscono una sintesi semplice e comprensibile delle caratteristiche principali di un insieme di dati. I principali indici di tendenza centrale sono:\n\n\nMedia: La media è la somma di tutti i valori divisa per il numero totale di valori. È spesso utilizzata come misura generale di tendenza centrale, ma è sensibile agli estremi (valori molto alti o molto bassi).\n\nMediana: La mediana è il valore che divide l’insieme di dati in due parti uguali. A differenza della media, non è influenzata da valori estremi ed è quindi più robusta in presenza di outlier.\n\nModa: La moda è il valore che appare più frequentemente in un insieme di dati. In alcuni casi, può non essere presente o esserci più di una moda.\n\nLa scelta dell’indice di tendenza centrale appropriato dipende dalla natura dei dati e dall’obiettivo dell’analisi. Ad esempio, la mediana potrebbe essere preferita alla media se l’insieme di dati contiene valori anomali che potrebbero distorcere la rappresentazione centrale. La conoscenza e l’applicazione corretta di questi indici possono fornire una preziosa intuizione sulle caratteristiche centrali di una distribuzione di dati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#moda",
    "href": "chapters/eda/07_loc_scale.html#moda",
    "title": "20  Indicatori di tendenza centrale e variabilità",
    "section": "\n20.3 Moda",
    "text": "20.3 Moda\nLa moda (\\(\\text{Mo}\\)) rappresenta il valore della variabile che compare con maggiore frequenza in una distribuzione. In altre parole, è il valore più ricorrente nei dati.\n\nNelle distribuzioni unimodali, esiste una sola moda, che coincide con il valore centrale della distribuzione più frequente.\n\nTuttavia, in alcune distribuzioni, possono emergere più di una moda, rendendole multimodali. In questi casi, la moda perde il suo significato di indicatore unico di tendenza centrale, poiché la presenza di più valori con frequenze elevate rende difficile individuare un singolo punto di riferimento.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#mediana",
    "href": "chapters/eda/07_loc_scale.html#mediana",
    "title": "20  Indicatori di tendenza centrale e variabilità",
    "section": "\n20.4 Mediana",
    "text": "20.4 Mediana\nLa mediana (\\(\\tilde{x}\\)) corrisponde al valore che divide il campione in due metà: il 50% dei dati è inferiore o uguale alla mediana e il restante 50% è superiore o uguale. A differenza della media, la mediana è meno influenzata dai valori estremi, rendendola una misura particolarmente robusta in presenza di dati asimmetrici o outlier.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#media",
    "href": "chapters/eda/07_loc_scale.html#media",
    "title": "20  Indicatori di tendenza centrale e variabilità",
    "section": "\n20.5 Media",
    "text": "20.5 Media\nLa media aritmetica di un insieme di valori rappresenta il punto centrale o il baricentro della distribuzione dei dati. È calcolata come la somma di tutti i valori divisa per il numero totale di valori, ed è espressa dalla formula:\n\\[\n\\bar{x}=\\frac{1}{n}\\sum_{i=1}^n x_i,\n\\tag{20.1}\\]\ndove \\(x_i\\) rappresenta i valori nell’insieme, \\(n\\) è il numero totale di valori, e \\(\\sum\\) indica la sommatoria.\n\n20.5.1 Proprietà della Media\nUna proprietà fondamentale della media è che la somma degli scarti di ciascun valore dalla media è zero:\n\\[\n\\sum_{i=1}^n (x_i - \\bar{x}) = 0.\\notag\n\\tag{20.2}\\]\nInfatti,\n\\[\n\\begin{aligned}\n\\sum_{i=1}^n (x_i - \\bar{x}) &= \\sum_i x_i - \\sum_i \\bar{x}\\notag\\\\\n&= \\sum_i x_i - n \\bar{x}\\notag\\\\\n&= \\sum_i x_i - \\sum_i x_i = 0.\\notag\n\\end{aligned}\n\\]\nQuesta proprietà implica che i dati sono equamente distribuiti intorno alla media.\n\n20.5.2 La media come Centro di Gravità dell’Istogramma\nLa media aritmetica può essere interpretata come il centro di gravità o il punto di equilibrio della distribuzione dei dati. In termini fisici, il centro di gravità è il punto in cui la massa di un sistema è equilibrata o concentrata.\nIn termini statistici, possiamo considerare la media come il punto in cui la distribuzione dei dati è in equilibrio. Ogni valore dell’insieme di dati può essere visto come un punto materiale con una massa proporzionale al suo valore. Se immaginiamo questi punti disposti su una linea, con valori più grandi a destra e più piccoli a sinistra, la media corrisponderà esattamente al punto in cui la distribuzione sarebbe in equilibrio.\n\n20.5.3 Principio dei Minimi Quadrati\nLa posizione della media minimizza la somma delle distanze quadrate dai dati, un principio noto come “metodo dei minimi quadrati”. Matematicamente, questo si traduce nel fatto che la somma dei quadrati degli scarti tra ciascun valore e la media è minima. Questo principio è alla base dell’analisi statistica dei modelli di regressione e conferma l’interpretazione della media come centro di gravità dell’istogramma.\n\n20.5.4 Calcolo della Media con R\n\nPer calcolare la media di un piccolo numero di valori in R, possiamo utilizzare la somma di questi valori e dividerla per il numero totale di elementi. Consideriamo ad esempio i valori 12, 44, 21, 62, 24:\n\n(12 + 44 + 21 + 62 + 24) / 5\n#&gt; [1] 32.6\n\novvero\n\nx &lt;- c(12, 44, 21, 62, 24)\nmean(x)\n#&gt; [1] 32.6\n\n\n20.5.5 Le Proporzioni Sono Medie\nSe una collezione consiste solo di uni e zeri, allora la somma della collezione è il numero di uni in essa, e la media della collezione è la proporzione di uni.\n\nzero_one &lt;- c(1, 1, 1, 0)\nresult &lt;- mean(zero_one)\nresult\n#&gt; [1] 0.75\n\nÈ possibile sostituire 1 con il valore booleano True e 0 con False:\n\nmean(c(TRUE, TRUE, TRUE, FALSE))\n#&gt; [1] 0.75\n\n\n20.5.6 Limiti della Media Aritmetica\nLa media aritmetica, tuttavia, ha alcune limitazioni: non sempre è l’indice più adeguato per descrivere accuratamente la tendenza centrale della distribuzione, specialmente quando si verificano asimmetrie o valori anomali (outlier). In queste situazioni, è più indicato utilizzare la mediana o la media spuntata (come spiegheremo successivamente).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#come-descrivere-la-tendenza-centrale-in-distribuzioni-asimmetriche",
    "href": "chapters/eda/07_loc_scale.html#come-descrivere-la-tendenza-centrale-in-distribuzioni-asimmetriche",
    "title": "20  Indicatori di tendenza centrale e variabilità",
    "section": "\n20.6 Come Descrivere la Tendenza Centrale in Distribuzioni Asimmetriche",
    "text": "20.6 Come Descrivere la Tendenza Centrale in Distribuzioni Asimmetriche\nIl diverso significato degli indici di tendenza centrale – moda, media e mediana – diventa evidente quando si analizzano distribuzioni asimmetriche. Per illustrare questo concetto, utilizzeremo i dati del Progetto Natsal, contenuti nel file sexual-partners.csv.\nNegli anni ’80, con la crescente preoccupazione per l’AIDS, le autorità sanitarie del Regno Unito si resero conto della mancanza di dati affidabili sui comportamenti sessuali della popolazione. In particolare, vi erano dubbi sulla frequenza con cui le persone cambiavano partner, sul numero di partner simultanei e sulle pratiche sessuali adottate. Questa conoscenza era essenziale per prevedere la diffusione delle malattie sessualmente trasmissibili nella società e per pianificare adeguatamente i servizi sanitari. Tuttavia, si faceva ancora riferimento ai dati raccolti da Alfred Kinsey negli Stati Uniti negli anni ’40, che non tenevano conto della rappresentatività del campione.\nA partire dalla fine degli anni ’80, vennero dunque avviati nel Regno Unito e negli Stati Uniti ampi e rigorosi studi sui comportamenti sessuali, nonostante una forte opposizione in alcuni ambienti. Nel Regno Unito, il governo guidato da Margaret Thatcher ritirò il proprio sostegno a un’importante indagine sui comportamenti sessuali all’ultimo momento. Fortunatamente, i ricercatori riuscirono a ottenere finanziamenti da enti benefici, dando vita al National Sexual Attitudes and Lifestyles Survey (Natsal). Da allora, questa indagine viene condotta ogni dieci anni, a partire dal 1990. La terza rilevazione, denominata Natsal-3, è stata effettuata intorno al 2010.\n\nPoniamoci il problema di descrivere la tendenza centrale per i dati contenuti nel file sexual-partners.csv, separatamente per maschi e femmine. Il dataset fornisce la distribuzione del numero totale dichiarato di partner sessuali di sesso opposto nella vita per uomini e donne di età compresa tra 35 e 44 anni. I dati provengono dal sondaggio Natsal-3 e corrispondono a un totale di 796 uomini e 1193 donne.\nProcediamo all’importazione dei dati per iniziare l’analisi.\n\ndf &lt;- rio::import(here::here(\"data\", \"sexual-partners.csv\"))\n\nEsaminiamo alcune righe prese a caso dal data frame df:\n\ndf[sample(1:nrow(df), size = 10, replace = FALSE), ]\n#&gt;      Gender NumPartners\n#&gt; 561     Man          15\n#&gt; 321     Man           6\n#&gt; 1177  Woman           3\n#&gt; 1098  Woman           2\n#&gt; 1252  Woman           4\n#&gt; 1170  Woman           3\n#&gt; 634     Man          21\n#&gt; 49      Man           1\n#&gt; 1152  Woman           3\n#&gt; 1327  Woman           5\n\nLa colonna Gender riporta il genere del rispondente e la colonna NumPartners il numero di partner sessuali di sesso opposto dichiarati.\nEsaminiamo la numerosità di ciascun gruppo.\n\ndf |&gt; \n  group_by(Gender) |&gt; \n  summarize(count = n())\n#&gt; # A tibble: 2 × 2\n#&gt;   Gender count\n#&gt;   &lt;chr&gt;  &lt;int&gt;\n#&gt; 1 Man      796\n#&gt; 2 Woman   1193\n\nPoniamoci innnanzitutto il problema di visualizzare i dati con un istogramma, separatamente per maschi e femmine. Per ragioni di spazio ci limiteremo ad un numero massimo di partner sessuali di 50 (ma in questo campione il numero massimo arriva a 501 per gli uomini e 550 per le donne):\n\ndf |&gt; \n  group_by(Gender) |&gt; \n  summarize(maximum = max(NumPartners))\n#&gt; # A tibble: 2 × 2\n#&gt;   Gender maximum\n#&gt;   &lt;chr&gt;    &lt;int&gt;\n#&gt; 1 Man        501\n#&gt; 2 Woman      550\n\nIniziamo calcolando la percentuale di intervistati per ciascun valore possibile della variabile “numero di partner sessuali”, compreso tra 0 e 50. Il calcolo verrà svolto in due passaggi:\n\nConteggio delle frequenze assolute: Per ogni valore della variabile “numero di partner sessuali” e per ciascun gruppo di genere (uomini e donne), contiamo quante volte quel valore compare nei dati.\nCalcolo delle percentuali relative: Per ciascun gruppo di genere, dividiamo il conteggio di ogni valore per il totale delle osservazioni nel gruppo e moltiplichiamo per 100 per ottenere la percentuale.\n\n\n# Filtra i dati troncando il numero di partner a 50\ndf_truncated &lt;- df[df$NumPartners &lt;= 50, ]\n\n# Calcola il conteggio per ciascun genere e numero di partner\ncounts_data &lt;- df_truncated %&gt;%\n  group_by(Gender, NumPartners) %&gt;%  # Raggruppa per genere e numero di partner\n  summarise(Count = n(), .groups = \"drop\")  # Conta le occorrenze\n\n# Aggiunge la percentuale relativa per ciascun genere\npercentage_data &lt;- counts_data %&gt;%\n  group_by(Gender) %&gt;%  # Raggruppa nuovamente per genere\n  mutate(Percentage = Count / sum(Count) * 100)  # Calcola la percentuale\n\nhead(percentage_data)\n#&gt; # A tibble: 6 × 4\n#&gt; # Groups:   Gender [1]\n#&gt;   Gender NumPartners Count Percentage\n#&gt;   &lt;chr&gt;        &lt;int&gt; &lt;int&gt;      &lt;dbl&gt;\n#&gt; 1 Man              0     6      0.789\n#&gt; 2 Man              1   100     13.2  \n#&gt; 3 Man              2    44      5.79 \n#&gt; 4 Man              3    39      5.13 \n#&gt; 5 Man              4    58      7.63 \n#&gt; 6 Man              5    51      6.71\n\nPossiamo ora creare gli istogrammi per maschi e femmine:\n\n# Crea l'istogramma separato per maschi e femmine\ngender_labels &lt;- c(\"Man\" = \"Uomini 35-44\", \"Woman\" = \"Donne 35-44\")\n\n# Trova il massimo valore di Percentage per impostare lo stesso limite\ny_max &lt;- max(percentage_data$Percentage)\n\n# Grafico con limiti dell'asse y uguali nei due pannelli\npercentage_data |&gt;\n  ggplot(aes(NumPartners, Percentage, fill = Gender)) +\n  geom_col(position = \"dodge\", color = \"black\") +\n  facet_wrap(~Gender, labeller = labeller(Gender = gender_labels)) +\n  scale_y_continuous(limits = c(0, y_max)) +  # Imposta i limiti dell'asse y\n  labs(\n    x = \"Numero di partner sessuali opposti dichiarati nella vita\",\n    y = \"Percentuale\"\n  ) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\nNotiamo che la distribuzione è altamente asimmetrica positiva. Come possiamo descrivere la tendenza centrale di questi dati?\nCalcoliamo gli indici di tendenza centrale all’interno dei due gruppi. Per la moda utilizziamo una funzione personalizzata:\n\n# Funzione personalizzata per calcolare la moda\nget_mode &lt;- function(x) {\n  # Calcola la tabella di frequenza e restituisce il valore con frequenza massima\n  tbl &lt;- table(x)\n  as.numeric(names(tbl)[which.max(tbl)])\n}\n\n# Calcolo delle statistiche per Gender\ndf |&gt; \n  group_by(Gender) |&gt; \n  summarise(\n    mean_sex_partner = mean(NumPartners, na.rm = TRUE),\n    median_sex_partner = median(NumPartners, na.rm = TRUE),\n    mode_sex_partner = get_mode(NumPartners)  # Usa la funzione personalizzata per la moda\n  )\n#&gt; # A tibble: 2 × 4\n#&gt;   Gender mean_sex_partner median_sex_partner mode_sex_partner\n#&gt;   &lt;chr&gt;             &lt;dbl&gt;              &lt;dbl&gt;            &lt;dbl&gt;\n#&gt; 1 Man               17.0                   8                1\n#&gt; 2 Woman              8.23                  5                1\n\nÈ evidente che, quando la distribuzione dei dati è altamente asimmetrica, come nel caso attuale, gli indici di tendenza centrale – media, mediana e moda – possono fornire risultati molto diversi, rendendo difficile individuare una misura rappresentativa della tendenza centrale.\n\nLa media risulta più elevata rispetto alla mediana e alla moda. Questo è tipico di una distribuzione asimmetrica positiva, caratterizzata da una lunga coda destra: pochi individui con valori estremamente alti influenzano la media, spostandola verso destra.\n\nLa mediana, invece, rappresenta il valore centrale della distribuzione e risulta meno influenzata dai valori estremi. Per questo motivo, è spesso più vicina alla “realtà” dei dati, offrendo una stima più robusta della tendenza centrale per la maggior parte degli individui.\n\nLa moda, infine, corrisponde al valore più frequente nella distribuzione (in questo caso, 1 partner). Tuttavia, in presenza di un’elevata dispersione dei dati, la moda può risultare poco rappresentativa della distribuzione complessiva.\n\nIn conclusione, quando la distribuzione è fortemente asimmetrica, la mediana è generalmente l’indice di tendenza centrale più appropriato. Essendo insensibile ai valori estremi, fornisce una rappresentazione più robusta della “posizione centrale” dei dati. Tuttavia, è utile integrare la mediana con la media e la moda per offrire un quadro più completo della distribuzione.\nPer una descrizione efficace della tendenza centrale in distribuzioni asimmetriche, si consiglia dunque di seguire questa procedura:\n\nutilizzare la mediana come misura principale della tendenza centrale;\n\nriportare media e moda come complemento per confrontare i risultati e interpretare eventuali differenze.\n\nÈ comunque fondamentale visualizzare la distribuzione dei dati attraverso grafici appropriati, come istogrammi o boxplot. Questi strumenti consentono di evidenziare chiaramente l’asimmetria, identificare valori estremi e comprendere meglio la struttura dei dati.\nInoltre, per arricchire i sommari numerici, è importante associare indici di dispersione che tratteremo in seguito.\n\n20.6.1 Media Spuntata\nLa media spuntata, indicata come \\(\\bar{x}_t\\) o trimmed mean, è un metodo di calcolo della media che prevede l’eliminazione di una determinata percentuale di dati estremi prima di effettuare la media aritmetica. Solitamente, viene eliminato il 10% dei dati, ovvero il 5% all’inizio e alla fine della distribuzione. Per ottenere la media spuntata, i dati vengono ordinati in modo crescente, \\(x_1 \\leq x_2 \\leq x_3 \\leq \\dots \\leq x_n\\), e quindi viene eliminato il primo 5% e l’ultimo 5% dei dati nella sequenza ordinata. Infine, la media spuntata è calcolata come la media aritmetica dei dati rimanenti. Questo approccio è utile quando ci sono valori anomali o quando la distribuzione è asimmetrica e la media aritmetica non rappresenta adeguatamente la tendenza centrale dei dati.\n\nEsempio 20.1 A titolo di esempio, procediamo al calcolo della media spuntata dei valori NumPartners per i due gruppi definiti dalla variabile Gender, escludendo il 10% dei valori più estremi.\n\nglimpse(df)\n#&gt; Rows: 1,989\n#&gt; Columns: 2\n#&gt; $ Gender      &lt;chr&gt; \"Man\", \"Man\", \"Man\", \"Man\", \"Man\", \"Man\", \"Man\", \"Man\"…\n#&gt; $ NumPartners &lt;int&gt; 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n\nUomini:\n\nsex_partners_men &lt;- df[df$Gender == \"Man\", \"NumPartners\"]\nmean(sex_partners_men, trim = 0.10, na.rm = TRUE)\n#&gt; [1] 10.6\n\nDonne:\n\nsex_partners_women &lt;- df[df$Gender == \"Woman\", \"NumPartners\"]\nmean(sex_partners_women, trim = 0.10, na.rm = TRUE)\n#&gt; [1] 6.01\n\n\n\n20.6.2 Quando Usare Media, Media Spuntata, Moda e Mediana\nLa scelta della misura di tendenza centrale più appropriata dipende dal tipo di dati, dalla distribuzione e dalla presenza di valori anomali o asimmetrie.\n\n20.6.2.1 Moda\nLa moda è il valore che compare con maggiore frequenza nei dati ed è l’unica misura di tendenza centrale utilizzabile per dati a livello nominale (categorie senza ordine) o ordinale (categorie ordinate ma senza distanza definita). Tuttavia:\n- In una distribuzione unimodale, la moda può rappresentare un indicatore significativo della tendenza centrale.\n- In distribuzioni multimodali (con più valori ricorrenti), la moda diventa meno interpretabile, poiché l’esistenza di più “picchi” rende difficile individuare un singolo valore rappresentativo.\n- Nei dati continui, la moda può non essere definita o risultare meno informativa, soprattutto in presenza di valori unici.\n\n20.6.2.2 Media\nLa media aritmetica è una misura efficace di tendenza centrale se la distribuzione è simmetrica e priva di valori anomali. In tali condizioni, la media rappresenta il “baricentro” della distribuzione, equilibrando i valori a sinistra e a destra. Tuttavia:\n\nIn distribuzioni asimmetriche o con outlier, la media è fortemente influenzata dai valori estremi e tende a spostarsi nella direzione della coda più lunga (asimmetria positiva o negativa).\n\nIn questi casi, la media potrebbe non essere rappresentativa della tendenza centrale reale.\n\n20.6.2.3 Media Spuntata\nLa media spuntata è una versione modificata della media, calcolata dopo aver rimosso una certa percentuale di valori estremi (generalmente il 5% o il 10%) sia dalla coda inferiore che da quella superiore della distribuzione. Questa misura è particolarmente utile quando:\n- La distribuzione è asimmetrica o contiene outlier, ma si desidera comunque una stima della tendenza centrale che consideri gran parte dei dati.\n- La media spuntata è meno sensibile ai valori anomali rispetto alla media tradizionale, pur mantenendo il vantaggio di considerare un’ampia porzione dei dati.\n\n20.6.2.4 Mediana\nLa mediana è il valore centrale che divide il campione in due metà: il 50% dei dati è inferiore e il restante 50% è superiore. È una misura robusta della tendenza centrale, particolarmente adatta quando:\n- La distribuzione è asimmetrica o contiene valori anomali. Poiché si basa sulla posizione dei dati e non sulle loro dimensioni, la mediana non è influenzata da valori estremi.\n- Nei dati ordinali, la mediana è spesso più appropriata della media, poiché non richiede una scala numerica con distanze precise.\n\n20.6.2.5 Quale Misura Scegliere?\n\nDistribuzioni Simmetriche:\nLa media è la scelta più appropriata, poiché riflette bene la tendenza centrale.\nDistribuzioni Asimmetriche o con Outlier:\nLa mediana è preferibile perché è robusta e meno influenzata dai valori estremi. In alternativa, si può utilizzare la media spuntata per ottenere un compromesso tra media e mediana.\nDati Categoriali:\nLa moda è l’unica misura applicabile, ma è interpretabile solo in distribuzioni unimodali.\nDistribuzioni Multimodali:\nIn questo caso, è importante visualizzare i dati (ad esempio con un istogramma) e descrivere ciascun “picco” separatamente, poiché nessuna delle misure tradizionali (media, mediana, moda) sarà sufficiente da sola per rappresentare la tendenza centrale.\n\nIn conclusione\n\nLa media è ideale per distribuzioni simmetriche senza valori estremi.\n\nLa mediana è più robusta e appropriata in caso di asimmetria o outlier.\n\nLa media spuntata rappresenta una soluzione intermedia utile nei casi con pochi valori anomali.\n\nLa moda è rilevante solo per dati nominali o ordinale, ma perde significato in distribuzioni multimodali.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#la-variabilità-nei-dati-psicologici",
    "href": "chapters/eda/07_loc_scale.html#la-variabilità-nei-dati-psicologici",
    "title": "20  Indicatori di tendenza centrale e variabilità",
    "section": "\n20.7 La Variabilità nei Dati Psicologici",
    "text": "20.7 La Variabilità nei Dati Psicologici\nSe misuriamo il livello di stress percepito da una persona dieci volte in un solo giorno, è improbabile ottenere esattamente lo stesso valore ogni volta, anche utilizzando la stessa scala. Se valutiamo il punteggio di autostima in un campione di studenti universitari utilizzando un questionario standardizzato, otterremo valori differenti per ciascun partecipante. Allo stesso modo, se registriamo il tempo di reazione in un compito cognitivo somministrato a un gruppo di persone, noteremo una variabilità nei tempi di risposta anche tra prove dello stesso individuo. La variazione è una caratteristica intrinseca dei fenomeni psicologici e comportamentali, e comprenderne a fondo la natura, le cause e i modi per descriverla è essenziale. In effetti, attribuire la variazione a determinati fattori causali – come differenze individuali, influenze ambientali o variabilità di misurazione – è uno degli obiettivi principali dell’analisi statistica. In questa sezione, esamineremo come la variazione può essere suddivisa, i due tipi principali di variazione (spiegata e non spiegata) e i metodi per descriverla sia visivamente sia numericamente.\nIn questa sezione, esamineremo come la variazione può essere suddivisa, i due tipi principali di variazione (spiegata e non spiegata) e i metodi per descriverla sia visivamente sia numericamente. Comprendere la variabilità è cruciale in psicologia, poiché molti fenomeni, come le differenze individuali o le fluttuazioni dell’umore, dipendono proprio dall’analisi della dispersione dei dati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#quantili",
    "href": "chapters/eda/07_loc_scale.html#quantili",
    "title": "20  Indicatori di tendenza centrale e variabilità",
    "section": "\n20.8 Quantili",
    "text": "20.8 Quantili\nI quantili sono valori che dividono la distribuzione dei dati in intervalli proporzionali, fornendo informazioni sulla loro variabilità e sui punti critici della distribuzione. Il quantile non interpolato di ordine \\(p\\) (\\(0 &lt; p &lt; 1\\)) è definito come il valore al di sotto del quale si trova una frazione \\(p\\) dei dati.\nLa formula per calcolare il quantile non interpolato è:\n\\[\nq_p = x_{(k)},\n\\]\ndove \\(x_{(k)}\\) è il valore \\(k\\)-esimo dell’insieme di dati ordinati in modo crescente. L’indice \\(k\\) è determinato come:\n\\[\nk = \\lceil p \\cdot n \\rceil,\n\\]\ndove \\(n\\) è il numero totale di osservazioni e \\(\\lceil \\cdot \\rceil\\) rappresenta la funzione di arrotondamento all’intero successivo.\n\nEsempio 20.2 Consideriamo il seguente insieme di dati:\n\\[\n\\{ 15, 20, 23, 25, 28, 30, 35, 40, 45, 50 \\}.\n\\]\nSupponiamo di voler calcolare il quantile di ordine 0.3 (30° percentile):\n1. I dati sono già ordinati in ordine crescente.\n2. Calcoliamo \\(k\\) come:\n\\[\n   k = \\lceil 0.3 \\cdot 10 \\rceil = \\lceil 3 \\rceil = 3.\n   \\]\n\n\nIl quantile corrisponde al terzo valore nell’insieme ordinato:\n\\[\nq_{0.3} = x_{(3)} = 23.\n\\]\n\n\n\n\n20.8.1 Quantile Interpolato\nPer valori di \\(p\\) che non corrispondono esattamente a una posizione nell’insieme di dati ordinati, si utilizza il quantile interpolato. Questo metodo stima il valore attraverso un’interpolazione lineare tra i dati adiacenti. È particolarmente utile per set di dati numerosi e viene calcolato automaticamente tramite software statistici come R o Python.\n\n20.8.2 Interpretazione dei Quantili\nI quantili completano le misure di tendenza centrale (media, mediana, moda), permettendo di esplorare la distribuzione dei dati e identificare i valori critici. In particolare:\n\nI quantili bassi (ad esempio il 10° percentile) forniscono informazioni sui valori minimi o nella parte inferiore della distribuzione.\n\nI quantili alti (ad esempio il 90° percentile) aiutano a esplorare i valori massimi o nella parte superiore della distribuzione.\n\nLa mediana è un caso particolare di quantile, corrispondente al quantile di ordine 0.5: divide la distribuzione in due parti uguali.\n\n20.8.3 Importanza dei Quantili\nL’uso congiunto di quantili e misure di tendenza centrale è fondamentale per ottenere una descrizione completa e robusta di una distribuzione, soprattutto in presenza di asimmetrie o valori anomali. Mentre la media e la mediana descrivono il comportamento “centrale” dei dati, i quantili permettono di analizzare la dispersione e identificare aree di particolare interesse nella distribuzione.\n\nEsempio 20.3 Consideriamo ora la variabile NumPartners per due gruppi definiti dalla variabile Gender (“Man” e “Woman”). Calcoleremo i quantili di ordine 0.1 e 0.9 per ciascun gruppo:\n\nIl quantile di ordine 0.1 rappresenta il valore al di sotto del quale si trova il 10% dei dati.\n\nIl quantile di ordine 0.9 rappresenta il valore al di sotto del quale si trova il 90% dei dati.\n\nCalcolo per il Gruppo “Man”:\n\n# Quantili di ordine 0.1 e 0.9 per i maschi\nquantile(df[df$Gender == \"Man\", \"NumPartners\"], probs = c(0.1, 0.9))\n#&gt;  10%  90% \n#&gt;  1.0 34.5\n\n\n10° percentile (0.1): \\(1.0\\) → Il 10% degli uomini ha dichiarato al massimo 1 partner sessuale.\n\n90° percentile (0.9): \\(34.5\\) → Il 10% degli uomini con i valori più alti ha dichiarato più di 34 partner sessuali.\n\nCalcolo per il Gruppo “Woman”:\n\n# Quantili di ordine 0.1 e 0.9 per le femmine\nquantile(df[df$Gender == \"Woman\", \"NumPartners\"], probs = c(0.1, 0.9))\n#&gt; 10% 90% \n#&gt;   1  18\n\n\n10° percentile (0.1): \\(1.0\\) → Anche per le donne, il 10% dei valori più bassi corrisponde a 1 partner sessuale.\n\n90° percentile (0.9): \\(18.0\\) → Il 10% delle donne con i valori più alti ha dichiarato più di 18 partner sessuali.\n\nI quantili calcolati forniscono una descrizione chiara della dispersione e della variabilità dei dati nei due gruppi:\n\nIl fatto che il 10° percentile sia identico per entrambi i gruppi suggerisce che una porzione simile di intervistati dichiara un numero molto basso di partner sessuali.\n\nLa differenza nel 90° percentile tra uomini e donne è significativa:\n\nPer gli uomini, il valore è più alto (\\(34.5\\)), indicando una maggiore presenza di valori estremi nella coda superiore della distribuzione.\n\nPer le donne, il valore (\\(18.0\\)) è inferiore, suggerendo una minore dispersione nella parte alta della distribuzione.\n\n\n\nQuesta differenza evidenzia una asimmetria positiva più pronunciata nel gruppo degli uomini, dove pochi individui con valori elevati “tirano” la coda della distribuzione verso destra.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#intervallo-di-variazione",
    "href": "chapters/eda/07_loc_scale.html#intervallo-di-variazione",
    "title": "20  Indicatori di tendenza centrale e variabilità",
    "section": "\n20.9 Intervallo di variazione",
    "text": "20.9 Intervallo di variazione\nL’intervallo di variazione è il più semplice tra gli indici di dispersione. Si calcola come la differenza tra il valore massimo e il valore minimo di una distribuzione:\n\\[\n\\text{Intervallo di variazione} = \\text{valore massimo} - \\text{valore minimo}.\n\\]\nTuttavia, l’intervallo di variazione presenta due limiti principali:\n\nSi basa esclusivamente su due valori della distribuzione, ignorando tutte le altre osservazioni.\nÈ altamente sensibile ai valori anomali (ad esempio, un adolescente con un punteggio di autostima molto più basso o più alto rispetto alla maggior parte del campione).\n\n\nEsempio 20.4 Supponiamo di misurare il punteggio di autostima in un campione di adolescenti. Se il punteggio massimo è 35 e il minimo è 12, l’intervallo di variazione sarà:\n\\[\n\\text{Intervallo di variazione} = 35 - 12 = 23.\n\\]",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#differenza-interquartile",
    "href": "chapters/eda/07_loc_scale.html#differenza-interquartile",
    "title": "20  Indicatori di tendenza centrale e variabilità",
    "section": "\n20.10 Differenza interquartile",
    "text": "20.10 Differenza interquartile\nUn’altra misura basata sull’ordinamento è la differenza interquartile (IQR), calcolata come la differenza tra il terzo quartile (\\(Q_3\\)) e il primo quartile (\\(Q_1\\)):\n\\[\n\\text{IQR} = Q_3 - Q_1.\n\\]\nL’IQR considera solo il 50% centrale dei dati, ignorando gli estremi, rendendolo meno sensibile ai valori anomali rispetto all’intervallo di variazione.\n\nEsempio 20.5 Supponiamo di analizzare il livello di ansia percepita in un gruppo di studenti universitari. Se il primo quartile (\\(Q_1\\)) è 25 (25% degli studenti ha un livello di ansia pari o inferiore a 25) e il terzo quartile (\\(Q_3\\)) è 40 (75% degli studenti ha un livello di ansia pari o inferiore a 40), allora:\n\\[\n\\text{IQR} = 40 - 25 = 15.\n\\]",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#la-varianza",
    "href": "chapters/eda/07_loc_scale.html#la-varianza",
    "title": "20  Indicatori di tendenza centrale e variabilità",
    "section": "\n20.11 La Varianza",
    "text": "20.11 La Varianza\nPer ottenere una misura di dispersione che consideri tutte le osservazioni, l’indice più utilizzato è la varianza. Questa misura valuta la dispersione dei dati rispetto alla media e si calcola come la media dei quadrati degli scarti di ciascun valore (\\(x_i\\)) dalla media (\\(\\bar{x}\\)):\n\\[\nS^2 = \\frac{1}{n} \\sum_{i=1}^n (x_i - \\bar{x})^2.\n\\tag{20.3}\\]\n\nEsempio 20.6 Supponiamo di calcolare il numero di ore dedicate allo studio quotidiano da un gruppo di partecipanti a un esperimento di psicologia. Se la media delle ore studiate è 4 (\\(\\bar{x} = 4\\)), la varianza misura quanto i dati si discostano da questa media. I dati con una varianza maggiore indicano una maggiore diversità nei comportamenti di studio, mentre una varianza minore suggerisce un gruppo più omogeneo.\n\n\n20.11.1 Proprietà della varianza\n\n\nUnità di misura: La varianza è espressa nell’unità di misura al quadrato dei dati originali (es. ore quadrate nel caso precedente), rendendola meno intuitiva da interpretare.\n\nSensibilità agli outlier: Poiché ogni scarto viene elevato al quadrato, i valori estremi influenzano significativamente la varianza.\n\n20.11.2 Variazione Sistematica e Non Sistematica\nNell’analisi dei dati psicologici, la variabilità può essere suddivisa in due componenti principali:\n\n\nVariazione non sistematica (rumore):\nÈ la variabilità casuale, non attribuibile a una causa specifica. Si manifesta come errori di misurazione o fluttuazioni imprevedibili che non seguono uno schema chiaro. Esempi includono:\n\nErrori casuali nel completare un test (ad esempio, distrazione momentanea).\n\nFluttuazioni dell’umore durante la giornata.\n\n\n\nVariazione sistematica (segnale):\nÈ la variabilità attribuibile a fattori specifici che influiscono in modo prevedibile sui dati. Questa componente rappresenta il “segnale” utile nell’analisi statistica. Esempi includono:\n\nIl miglioramento nei punteggi di un test di attenzione dopo una sessione di meditazione.\n\nLe differenze individuali nei livelli di self-compassion misurati da una scala psicologica.\n\n\n\nPer esempio, supponiamo di misurare il livello di stress prima e dopo una sessione di rilassamento:\n\nLa variazione sistematica rappresenta la riduzione del livello di stress dovuta all’effetto del rilassamento.\n\nLa variazione non sistematica comprende fattori casuali, come distrazioni, stanchezza momentanea o condizioni personali dei partecipanti.\n\n20.11.3 Calcolo della Varianza in R\nPer illustrare come quantificare la variabilità, utilizziamo i punteggi totali della Self-Compassion Scale su un campione di studenti universitari, forniti nel file scs_scores.csv.\nPassaggio 1: Importazione dei dati\n\nscs_df &lt;- rio::import(here::here(\"data\", \"scs_scores.csv\")) |&gt; \n  dplyr::rename(ts = scs_total_score)\nglimpse(scs_df)\n#&gt; Rows: 121\n#&gt; Columns: 7\n#&gt; $ self_kindness       &lt;int&gt; 14, 15, 19, 10, 11, 9, 19, 13, 23, 5, 14, 22, …\n#&gt; $ common_humanity     &lt;int&gt; 11, 9, 16, 11, 10, 8, 12, 12, 19, 4, 13, 18, 6…\n#&gt; $ mindfulness         &lt;int&gt; 10, 10, 16, 9, 9, 10, 8, 12, 20, 8, 15, 15, 6,…\n#&gt; $ self_judgment       &lt;int&gt; 15, 16, 13, 15, 18, 19, 11, 15, 9, 25, 17, 11,…\n#&gt; $ isolation           &lt;int&gt; 16, 11, 12, 14, 13, 16, 11, 11, 5, 20, 14, 11,…\n#&gt; $ over_identification &lt;int&gt; 14, 11, 8, 11, 14, 17, 20, 15, 7, 20, 15, 16, …\n#&gt; $ ts                  &lt;int&gt; 68, 74, 96, 68, 63, 53, 75, 74, 119, 30, 74, 9…\n\nLa colonna ts contiene i punteggi totali della scala.\nPassaggio 2: Calcolo della varianza\nUtilizzando la formula della varianza:\n\nsum((scs_df$ts - mean(scs_df$ts))^2) / length(scs_df$ts)\n#&gt; [1] 405\n\nCon la funzione var() corretta per il campione:\n\nvar(scs_df$ts) * (length(scs_df$ts) - 1) / length(scs_df$ts)\n#&gt; [1] 405\n\n\n20.11.4 Interpretazione della Varianza\nLa varianza misura la dispersione totale dei dati, che può essere scomposta in:\n\nVariazione sistematica:\nNel caso della Self-Compassion Scale, la varianza sistematica riflette le differenze tra individui nei livelli di self-compassion. Alcuni individui mostrano livelli elevati (fattore protettivo contro il disagio psicologico), mentre altri livelli più bassi.\nVariazione non sistematica:\nQuesta componente è dovuta a errori di misurazione e altre cause casuali. La psicometria presuppone che il punteggio osservato sia la somma di:\\[\n\\text{Punteggio osservato} = \\text{Punteggio vero} + \\text{Errore di misurazione}.\n\\] Esempi di errori includono distrazioni o stanchezza dei partecipanti; limitazioni della scala psicologica nella misurazione accurata del costrutto.\n\n\n20.11.5 Affidabilità e Rapporto Segnale-Rumore\nPerché uno strumento psicometrico sia considerato affidabile, almeno l’80% della varianza osservata deve essere attribuibile alla componente vera del costrutto. Questo requisito si traduce in un coefficiente di affidabilità di almeno 0.8.\n\nUn alto rapporto segnale-rumore indica che la maggior parte della variabilità osservata è dovuta a fattori sistematici (segnale) e non a errori casuali (rumore).\n\nUn basso rapporto segnale-rumore suggerisce che la variabilità casuale (rumore) è predominante e lo strumento potrebbe non essere sufficientemente preciso.\n\nLa disciplina della psicometria fornisce strumenti per:\n\n\nValutare l’affidabilità delle scale psicologiche (es. Alpha di Cronbach).\n\n\nProgettare strumenti più accurati per minimizzare la variabilità non sistematica (rumore).\n\nUno strumento affidabile assicura che i risultati riflettano con precisione le differenze reali tra gli individui e non siano influenzati da errori casuali.\n\nSupponiamo di valutare l’efficacia di un nuovo metodo di studio misurando il miglioramento in un test di comprensione:\n\nUn alto rapporto segnale-rumore (ovvero, un’alta affidabilità) indica che il miglioramento osservato è chiaramente attribuibile al metodo.\n\nUn basso rapporto segnale-rumore (bassa affidabilità) implica che la variabilità è prevalentemente casuale e l’effetto del metodo non è distinguibile dal rumore.\n\nIn conclusione, la distinzione tra variazione sistematica e non sistematica è fondamentale per l’analisi dei dati psicologici:\n\nLa variazione sistematica rappresenta il “segnale”, ossia l’effetto reale o il fattore di interesse.\n\nLa variazione non sistematica rappresenta il “rumore”, ossia la variabilità casuale o l’errore di misurazione.\n\nL’obiettivo è massimizzare il segnale e minimizzare il rumore, garantendo strumenti affidabili che consentano di ottenere risultati precisi e interpretabili.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#stima-della-varianza-della-popolazione",
    "href": "chapters/eda/07_loc_scale.html#stima-della-varianza-della-popolazione",
    "title": "20  Indicatori di tendenza centrale e variabilità",
    "section": "\n20.12 Stima della Varianza della Popolazione",
    "text": "20.12 Stima della Varianza della Popolazione\nSi noti il denominatore della formula della varianza. Nell’Equazione 20.3, ho utilizzato \\(n\\) come denominatore (l’ampiezza campionaria, ovvero il numero di osservazioni nel campione). In questo modo, otteniamo la varianza come statistica descrittiva del campione. Tuttavia, è possibile utilizzare \\(n-1\\) come denominatore alternativo:\n\\[\n\\begin{equation}\ns^2 = \\frac{1}{n-1} \\sum_{i=1}^n (x_i - \\bar{x})^2\n\\end{equation}\n\\tag{20.4}\\]\nIn questo secondo caso, otteniamo la varianza come stimatore della varianza della popolazione. Si può dimostrare che l’Equazione 20.4 fornisce una stima corretta (ovvero, non distorta) della varianza della popolazione da cui abbiamo ottenuto il campione, mentre l’Equazione 20.3 fornisce (in media) una stima troppo piccola della varianza della popolazione. Si presti attenzione alla notazione: \\(S^2\\) rappresenta la varianza come statistica descrittiva, mentre \\(s^2\\) rappresenta la varianza come stimatore.\nPer illustrare questo punto, svolgiamo una simulazione. Consideriamo la distribuzione dei punteggi del quoziente di intelligenza (QI). I valori del QI seguono una particolare distribuzione chiamata distribuzione normale, con media 100 e deviazione standard 15. La forma di questa distribuzione è illustrata nella figura seguente.\n\n# Define parameters\nx &lt;- seq(100 - 4 * 15, 100 + 4 * 15, by = 0.001)\nmu &lt;- 100\nsigma &lt;- 15\n\n# Compute the PDF\npdf &lt;- dnorm(x, mean = mu, sd = sigma)\n\n# Plot using ggplot2\ndata &lt;- tibble(x = x, pdf = pdf)\nggplot(data, aes(x = x, y = pdf)) +\n  geom_line() +\n  labs(\n    x = \"QI\", \n    y = \"Densità\", \n    title = \"Distribuzione del QI nella popolazione\"\n  ) \n\n\n\n\n\n\n\nSupponiamo di estrarre un campione casuale di 4 osservazioni dalla popolazione del quoziente di intelligenza – in altre parole, supponiamo di misurare il quoziente di intelligenza di 4 persone prese a caso dalla popolazione.\n\nset.seed(123) \nx &lt;- rnorm(4, mean = 100, sd = 15)\nprint(x)\n#&gt; [1]  91.6  96.5 123.4 101.1\n\nCalcoliamo la varianza usando \\(n\\) al denominatore. Si noti che la vera varianza del quoziente di intelligenza è \\(15^2\\) = 225.\n\nvar(x)\n#&gt; [1] 197\n\nConsideriamo ora 10 campioni casuali del QI, ciascuno di ampiezza 4.\n\nmu &lt;- 100\nsigma &lt;- 15\nsize &lt;- 4\nniter &lt;- 10\nrandom_samples &lt;- list()\n\nset.seed(123) \n\nfor (i in 1:niter) {\n  one_sample &lt;- rnorm(size, mean = mu, sd = sigma)\n  random_samples[[i]] &lt;- one_sample\n}\n\nIl primo campione è\n\nrandom_samples[1]\n#&gt; [[1]]\n#&gt; [1]  91.6  96.5 123.4 101.1\n\nIl decimo campione è\n\nrandom_samples[10]\n#&gt; [[1]]\n#&gt; [1] 108.3  99.1  95.4  94.3\n\nStampiamo i valori di tutti i 10 campioni.\n\nrs &lt;- do.call(rbind, random_samples)\nrs\n#&gt;        [,1]  [,2]  [,3]  [,4]\n#&gt;  [1,]  91.6  96.5 123.4 101.1\n#&gt;  [2,] 101.9 125.7 106.9  81.0\n#&gt;  [3,]  89.7  93.3 118.4 105.4\n#&gt;  [4,] 106.0 101.7  91.7 126.8\n#&gt;  [5,] 107.5  70.5 110.5  92.9\n#&gt;  [6,]  84.0  96.7  84.6  89.1\n#&gt;  [7,]  90.6  74.7 112.6 102.3\n#&gt;  [8,]  82.9 118.8 106.4  95.6\n#&gt;  [9,] 113.4 113.2 112.3 110.3\n#&gt; [10,] 108.3  99.1  95.4  94.3\n\nPer ciascun campione (ovvero, per ciascuna riga della matrice precedente), calcoliamo la varianza usando la formula con \\(n\\) al denominatore. Otteniamo così 10 stime della varianza della popolazione del QI.\n\nx_var &lt;- apply(rs, 1, var)  # Applica la funzione var su ciascuna riga\nprint(x_var)\n#&gt;  [1] 196.94 337.54 168.55 218.68 333.48  34.52 264.38 234.08   1.97  40.47\n\nNotiamo due cose:\n\nle stime sono molto diverse tra loro; questo fenomeno è noto con il nome di variabilità campionaria;\nin media le stime sono troppo piccole.\n\nPer aumentare la sicurezza riguardo al secondo punto menzionato in precedenza, ripeteremo la simulazione utilizzando un numero di iterazioni maggiore.\n\nmu &lt;- 100\nsigma &lt;- 15\nsize &lt;- 4\nniter &lt;- 10000\nrandom_samples &lt;- list()\n\nset.seed(123) # Replace 123 with your desired seed for reproducibility\n\nfor (i in 1:niter) {\n  one_sample &lt;- rnorm(size, mean = mu, sd = sigma)\n  random_samples[[i]] &lt;- one_sample\n}\n\nrs &lt;- do.call(rbind, random_samples)\nx_var &lt;- apply(rs, 1, var) * (size - 1) / size  # Adjust for population variance (ddof = 0)\n\nEsaminiamo la distribuzione dei valori ottenuti.\n\n# Create a data frame for plotting\ndata &lt;- data.frame(x_var = x_var)\n\n# Plot the histogram using ggplot2\nggplot(data, aes(x = x_var)) +\n  geom_histogram(alpha = 0.5, fill = \"blue\") +\n  labs(\n    x = \"Varianza\", \n    y = \"Frequenza\", \n    title = \"Varianza del QI in campioni di n = 4\"\n  )\n#&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\nLa stima più verosimile della varianza del QI è dato dalla media di questa distribuzione.\n\nmean(x_var)\n#&gt; [1] 169\n\nSi noti che il nostro spospetto è stato confermato: il valore medio della stima della varianza ottenuta con l’Equazione 20.3 è troppo piccolo rispetto al valore corretto di \\(15^2 = 225\\).\nRipetiamo ora la simulazione usando la formula della varianza con \\(n-1\\) al denominatore.\n\nset.seed(123) \n\nmu &lt;- 100\nsigma &lt;- 15\nsize &lt;- 4\nniter &lt;- 10000\nrandom_samples &lt;- list()\n\nfor (i in 1:niter) {\n  one_sample &lt;- rnorm(size, mean = mu, sd = sigma)\n  random_samples[[i]] &lt;- one_sample\n}\n\nrs &lt;- do.call(rbind, random_samples)\nx_var &lt;- apply(rs, 1, var)  # ddof = 1 is default for var in R\n\nmean(x_var)\n#&gt; [1] 225\n\nNel secondo caso, se utilizziamo \\(n-1\\) come denominatore per calcolare la stima della varianza, il valore atteso di questa stima è molto vicino al valore corretto di 225. Se il numero di campioni fosse infinito, i due valori sarebbero identici.\nIn conclusione, le due formule della varianza hanno scopi diversi. La formula della varianza con \\(n\\) al denominatore viene utilizzata come statistica descrittiva per descrivere la variabilità di un particolare campione di osservazioni. D’altro canto, la formula della varianza con \\(n-1\\) al denominatore viene utilizzata come stimatore per ottenere la migliore stima della varianza della popolazione da cui quel campione è stato estratto.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#deviazione-standard",
    "href": "chapters/eda/07_loc_scale.html#deviazione-standard",
    "title": "20  Indicatori di tendenza centrale e variabilità",
    "section": "\n20.13 Deviazione Standard",
    "text": "20.13 Deviazione Standard\nPer interpretare la varianza in modo più intuitivo, si può calcolare la deviazione standard (o scarto quadratico medio o scarto tipo) prendendo la radice quadrata della varianza. La deviazione standard è espressa nell’unità di misura originaria dei dati, a differenza della varianza che è espressa nel quadrato dell’unità di misura dei dati. La deviazione standard fornisce una misura della dispersione dei dati attorno alla media, rendendo più facile la comprensione della variabilità dei dati.\nLa deviazione standard (o scarto quadratico medio, o scarto tipo) è definita come:\n\\[\ns^2 = \\sqrt{(n-1)^{-1} \\sum_{i=1}^n (x_i - \\bar{x})^2}.\n\\tag{20.5}\\]\nQuando tutte le osservazioni sono uguali, \\(s = 0\\), altrimenti \\(s &gt; 0\\).\n\n\n\n\n\n\nIl termine standard deviation è stato introdotto in statistica da Pearson nel 1894 assieme alla lettera greca \\(\\sigma\\) che lo rappresenta. Il termine italiano “deviazione standard” ne è la traduzione più utilizzata nel linguaggio comune; il termine dell’Ente Nazionale Italiano di Unificazione è tuttavia “scarto tipo”, definito come la radice quadrata positiva della varianza.\n\n\n\nLa deviazione standard \\(s\\) dovrebbe essere utilizzata solo quando la media è una misura appropriata per descrivere il centro della distribuzione, ad esempio nel caso di distribuzioni simmetriche. Tuttavia, è importante tener conto che, come la media \\(\\bar{x}\\), anche la deviazione standard è fortemente influenzata dalla presenza di dati anomali, ovvero pochi valori che si discostano notevolmente dalla media rispetto agli altri dati della distribuzione. In presenza di dati anomali, la deviazione standard può risultare ingannevole e non rappresentare accuratamente la variabilità complessiva della distribuzione. Pertanto, è fondamentale considerare attentamente il contesto e le caratteristiche dei dati prima di utilizzare la deviazione standard come misura di dispersione. In alcune situazioni, potrebbe essere più appropriato ricorrere a misure di dispersione robuste o ad altre statistiche descrittive per caratterizzare la variabilità dei dati in modo più accurato e affidabile.\n\nEsempio 20.7 Calcoliamo la deviazione standard per i valori di self-compassion del campione di dati esaminato in precedenza. Applicando l’Equazione 20.5, per tutto il campione abbiamo\n\nsd(scs_df$ts)\n#&gt; [1] 20.2\n\n\n\n20.13.1 Interpretazione\nLa deviazione standard misura la dispersione dei dati rispetto alla media aritmetica. In termini semplici, indica quanto, in media, ciascun valore osservato si discosta dalla media del campione. Anche se è simile allo scarto semplice medio campionario (la media dei valori assoluti degli scarti rispetto alla media), la deviazione standard utilizza lo scarto quadratico medio e produce un valore leggermente diverso.\nPer esempio, consideriamo i punteggi di self-compassione di un campione di individui:\n\nEsempio 20.8 Per verificare l’interpretazione della deviazione standard, utilizziamo i valori della self-compassione.\n\nsd(scs_df$ts)\n#&gt; [1] 20.2\n\nLa deviazione standard calcolata è 20.2. Questo valore ci dice che, in media, ciascun punteggio si discosta di circa 20.2 punti dalla media aritmetica dei punteggi.\n\nValore più alto: indica maggiore dispersione dei dati intorno alla media.\nValore più basso: i dati sono più concentrati vicino alla media.\n\nSe calcoliamo anche lo scarto semplice medio campionario per confronto, otteniamo:\n\nmean(abs(scs_df$ts - mean(scs_df$ts, na.rm = TRUE)), na.rm = TRUE)\n#&gt; [1] 16.2\n\nI due valori (deviazione standard e scarto semplice medio) sono simili ma non identici, a causa delle diverse definizioni matematiche.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#deviazione-mediana-assoluta",
    "href": "chapters/eda/07_loc_scale.html#deviazione-mediana-assoluta",
    "title": "20  Indicatori di tendenza centrale e variabilità",
    "section": "\n20.14 Deviazione Mediana Assoluta",
    "text": "20.14 Deviazione Mediana Assoluta\nLa deviazione mediana assoluta (MAD) è una misura robusta di dispersione basata sulla mediana. È definita come la mediana dei valori assoluti delle deviazioni dei dati rispetto alla mediana:\n\\[\n\\text{MAD} = \\text{median} \\left( |X_i - \\text{median}(X)| \\right)\n\\tag{20.6}\\]\nLa MAD è particolarmente utile per analizzare dati contenenti outlier o distribuzioni asimmetriche, poiché è meno influenzata dai valori estremi rispetto alla deviazione standard.\n\n20.14.1 Relazione tra MAD e Deviazione Standard in una Distribuzione Normale\nQuando i dati seguono una distribuzione normale (gaussiana), esiste una relazione approssimativa tra MAD e deviazione standard. La MAD può essere convertita in una stima della deviazione standard moltiplicandola per una costante di 1.4826:\n\\[\n\\sigma \\approx k \\times \\text{MAD},\n\\]\ndove:\n\n\n\\(\\sigma\\) è la deviazione standard.\nMAD è la Mediana della Deviazione Assoluta.\n\n\\(k\\) è una costante che, per una distribuzione normale, è tipicamente presa come circa 1.4826.\n\nQuesta costante deriva dalla proprietà della distribuzione normale, in cui circa il 50% dei valori si trova entro 0.6745 deviazioni standard dalla media.\nLa formula completa per convertire la MAD in una stima della deviazione standard in una distribuzione normale è:\n\\[\n\\sigma \\approx 1.4826 \\times \\text{MAD}\n\\]\nQuesta relazione è utile per stimare la deviazione standard in modo più robusto, specialmente quando si sospetta la presenza di outlier o si ha a che fare con campioni piccoli. Di conseguenza, molti software restituiscono il valore MAD moltiplicato per questa costante per fornire un’indicazione più intuitiva della variabilità dei dati. Tuttavia, è importante notare che questa relazione si mantiene accurata solo per le distribuzioni che sono effettivamente normali. In presenza di distribuzioni fortemente asimmetriche o con elevati outlier, la deviazione standard e la MAD possono fornire indicazioni molto diverse sulla variabilità dei dati.\n\nEsempio 20.9 Per verificare questo principio, calcoliamo la deviazione mediana assoluta dei valori di self-compassion del campione esaminato:\n\n1.4826 * median(abs(scs_df$ts - median(scs_df$ts, na.rm = TRUE)), na.rm = TRUE)\n#&gt; [1] 22.2\n\nOtteniamo un valore che è simile alla deviazione standard calcolata con:\n\nsd(scs_df$ts)\n#&gt; [1] 20.2\n\nSe verifichiamo la distribuzione dei dati con un grafico della densità, possiamo osservare che i punteggi sono approssimativamente normali:\n\nggplot(scs_df, aes(x = ts)) +\n  geom_density(alpha = 0.5) +\n  labs(\n    x = \"math\", \n    y = \"Frequenza\", \n    title = \"Distribuzione dei punteggi di self-compassion\"\n  )\n\n\n\n\n\n\n\nPer ulteriori verifiche, possiamo estrarre un campione di dati da una distribuzione normale con media 100 e deviazione standard 15:\n\nset.seed(123) \nx &lt;- rnorm(10000, mean = 100, sd = 15)\n1.4826 * median(abs(x - median(x)))\n#&gt; [1] 14.9\n\nAnche in questo caso, il valore ottenuto è molto vicino alla deviazione standard reale (15), confermando la relazione tra MAD e deviazione standard in distribuzioni gaussiane.\n\n\n20.14.2 Quando Usare Deviazione Standard e MAD\n\nDeviazione standard: È la misura più appropriata per dati normalmente distribuiti e situazioni in cui l’obiettivo è descrivere la dispersione dei dati rispetto alla media. Tuttavia, è sensibile ai valori anomali (outlier).\nDeviazione mediana assoluta (MAD): È ideale quando i dati sono non normali, asimmetrici o contengono outlier. La MAD è più robusta poiché utilizza la mediana anziché la media e non è influenzata da valori estremi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#indici-di-variabilità-relativi",
    "href": "chapters/eda/07_loc_scale.html#indici-di-variabilità-relativi",
    "title": "20  Indicatori di tendenza centrale e variabilità",
    "section": "\n20.15 Indici di Variabilità Relativi",
    "text": "20.15 Indici di Variabilità Relativi\nA volte può essere necessario confrontare la variabilità di grandezze incommensurabili, ovvero di caratteri misurati con differenti unità di misura. In queste situazioni, le misure di variabilità descritte in precedenza diventano inadeguate poiché dipendono dall’unità di misura utilizzata. Per superare questo problema, si ricorre a specifici numeri adimensionali chiamati indici relativi di variabilità.\nIl più importante di questi indici è il coefficiente di variazione (\\(C_v\\)), definito come il rapporto tra la deviazione standard (\\(\\sigma\\)) e la media dei dati (\\(\\bar{x}\\)):\n\\[\nC_v = \\frac{\\sigma}{\\bar{x}}.\n\\tag{20.7}\\]\nIl coefficiente di variazione è un numero puro e permette di confrontare la variabilità di distribuzioni con unità di misura diverse.\nUn altro indice relativo di variabilità è la differenza interquartile rapportata a uno dei tre quartili (primo quartile, terzo quartile o mediana). Questo indice è definito come:\n\\[\n\\frac{x_{0.75} - x_{0.25}}{x_{0.25}}, \\qquad \\frac{x_{0.75} - x_{0.25}}{x_{0.75}}, \\qquad \\frac{x_{0.75} - x_{0.25}}{x_{0.50}}.\n\\]\nQuesti indici relativi di variabilità forniscono una misura adimensionale della dispersione dei dati, rendendo possibile il confronto tra grandezze con diverse unità di misura e facilitando l’analisi delle differenze di variabilità tra i dati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#la-fallacia-ergodica",
    "href": "chapters/eda/07_loc_scale.html#la-fallacia-ergodica",
    "title": "20  Indicatori di tendenza centrale e variabilità",
    "section": "\n20.16 La Fallacia Ergodica",
    "text": "20.16 La Fallacia Ergodica\nSebbene il concetto di “media” possa sembrare chiaro, ciò non implica che il suo utilizzo non presenti delle problematiche nell’ambito della pratica psicologica. Un aspetto su cui vale la pena soffermarsi è ciò che viene definito “fallacia ergodica”.\nIl concetto di “fallacia ergodica” (Speelman et al., 2024) si riferisce all’errore compiuto dai ricercatori quando assumono che le caratteristiche medie di un gruppo di individui possano essere applicate a ciascun individuo all’interno di quel gruppo, senza considerare le differenze individuali o le variazioni nel tempo. Questa fallacia emerge dalla pratica comune nella ricerca psicologica di raccogliere dati aggregati da gruppi di persone per stimare parametri della popolazione, al fine di confrontare comportamenti in condizioni diverse o esplorare associazioni tra diverse misurazioni della stessa persona.\nIl problema di questo approccio è che l’uso dei risultati basati sul gruppo per caratterizzare le caratteristiche degli individui o per estrapolare a persone simili a quelle del gruppo è ingiustificato, poiché le medie di gruppo possono fornire informazioni solo sui risultati collettivi, come la performance media del gruppo, e non consentono di fare affermazioni accurate sugli individui che compongono quel gruppo. La fallacia ergodica si basa sull’assunzione che per utilizzare legittimamente una statistica aggregata (ad esempio, la media) derivata da un gruppo per descrivere un individuo di quel gruppo, due condizioni devono essere soddisfatte: gli individui devono essere così simili da essere praticamente interscambiabili, e le caratteristiche degli individui devono essere temporalmente stabili.\nTuttavia, i fenomeni e i processi psicologici di interesse per i ricercatori sono per natura non uniformi tra gli individui e variabili nel tempo, sia all’interno degli individui che tra di loro. Di conseguenza, i risultati ottenuti dalla media di misure di comportamenti, cognizioni o stati emotivi di più individui non descrivono accuratamente nessuno di quegli individui in un dato momento, né possono tenere conto dei cambiamenti in quelle variabili per un individuo nel tempo.\nSpeelman et al. (2024) osservano che la stragrande maggioranza degli articoli che hanno analizzato include conclusioni nelle sezioni degli Abstract e/o delle Discussioni che implicano che i risultati trovati con dati aggregati di gruppo si applichino anche agli individui in quei gruppi e/o si applichino agli individui nella popolazione. Questa pratica riflette la fallacia ergodica, che consiste nell’assumere che i campioni siano sistemi ergodici quando non lo sono.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#riflessioni-conclusive",
    "href": "chapters/eda/07_loc_scale.html#riflessioni-conclusive",
    "title": "20  Indicatori di tendenza centrale e variabilità",
    "section": "\n20.17 Riflessioni Conclusive",
    "text": "20.17 Riflessioni Conclusive\nLe statistiche descrittive ci permettono di ottenere indicatori sintetici che riassumono i dati di una popolazione o di un campione estratto da essa. Questi indicatori includono misure di tendenza centrale, come la media, la mediana e la moda, che ci forniscono informazioni sulla posizione centrale dei dati rispetto alla distribuzione. Inoltre, ci sono gli indici di dispersione, come la deviazione standard e la varianza, che ci indicano quanto i dati si disperdono attorno alla tendenza centrale. Questi indici ci aiutano a comprendere quanto i valori si discostano dalla media, e quindi ci forniscono un’idea della variabilità dei dati. In conclusione, le statistiche descrittive ci offrono un quadro sintetico delle caratteristiche principali dei dati, consentendoci di comprendere meglio la loro distribuzione e variabilità.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/07_loc_scale.html#informazioni-sullambiente-di-sviluppo",
    "title": "20  Indicatori di tendenza centrale e variabilità",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] grid      stats     graphics  grDevices utils     datasets  methods  \n#&gt; [8] base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] vcd_1.4-13        viridis_0.6.5     viridisLite_0.4.2 ggokabeito_0.1.0 \n#&gt;  [5] see_0.9.0         gridExtra_2.3     patchwork_1.3.0   bayesplot_1.11.1 \n#&gt;  [9] psych_2.4.12      scales_1.3.0      markdown_1.13     knitr_1.49       \n#&gt; [13] lubridate_1.9.4   forcats_1.0.0     stringr_1.5.1     dplyr_1.1.4      \n#&gt; [17] purrr_1.0.2       readr_2.1.5       tidyr_1.3.1       tibble_3.2.1     \n#&gt; [21] ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] utf8_1.2.4        generics_0.1.3    stringi_1.8.4     lattice_0.22-6   \n#&gt;  [5] hms_1.1.3         digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1   \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     R.oo_1.27.0       rprojroot_2.0.4  \n#&gt; [13] jsonlite_1.8.9    R.utils_2.12.3    mnormt_2.1.1      cli_3.6.3        \n#&gt; [17] rlang_1.1.4       R.methodsS3_1.8.2 munsell_0.5.1     withr_3.0.2      \n#&gt; [21] tools_4.4.2       parallel_4.4.2    tzdb_0.4.0        colorspace_2.1-1 \n#&gt; [25] pacman_0.5.1      vctrs_0.6.5       R6_2.5.1          zoo_1.8-12       \n#&gt; [29] lifecycle_1.0.4   htmlwidgets_1.6.4 MASS_7.3-64       pkgconfig_2.0.3  \n#&gt; [33] pillar_1.10.0     gtable_0.3.6      data.table_1.16.4 glue_1.8.0       \n#&gt; [37] lmtest_0.9-40     xfun_0.49         tidyselect_1.2.1  farver_2.1.2     \n#&gt; [41] htmltools_0.5.8.1 nlme_3.1-166      labeling_0.4.3    rmarkdown_2.29   \n#&gt; [45] compiler_4.4.2",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#bibliografia",
    "href": "chapters/eda/07_loc_scale.html#bibliografia",
    "title": "20  Indicatori di tendenza centrale e variabilità",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nSpeelman, C. P., Parker, L., Rapley, B. J., & McGann, M. (2024). Most Psychological Researchers Assume Their Samples Are Ergodic: Evidence From a Year of Articles in Three Major Journals. Collabra: Psychology, 10(1).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html",
    "href": "chapters/eda/08_correlation.html",
    "title": "21  Relazioni tra variabili",
    "section": "",
    "text": "21.1 Introduzione\nNonostante sia un’operazione di base, l’analisi delle associazioni tra variabili rappresenta uno degli aspetti più controversi nell’ambito dell’analisi dei dati psicologici. Sebbene possa sembrare un passaggio naturale dopo l’analisi univariata, questo processo solleva numerose questioni metodologiche e concettuali.\nTradizionalmente, in psicologia, l’analisi delle associazioni tra variabili è stata considerata come l’obiettivo finale del processo di ricerca. Questa visione si basa sull’idea che la descrizione delle relazioni tra variabili fornisca una spiegazione esaustiva dei fenomeni psicologici. Tale approccio trova le sue radici storiche nel pensiero di Karl Pearson (1911), il quale sosteneva che la spiegazione scientifica si esaurisse una volta delineate le associazioni tra le variabili osservate:\nSebbene sia indubbio che rispondere alla seconda domanda posta da Pearson sia relativamente semplice, è altresì evidente che la nostra comprensione di un fenomeno non può dipendere unicamente dalle informazioni fornite dalle correlazioni.\nIn contrasto con questa visione tradizionale, la “Causal Revolution” propone un paradigma radicalmente diverso secondo il quale le associazioni tra variabili sono considerate come epifenomeni, mentre l’obiettivo principale della ricerca è l’identificazione e la comprensione delle relazioni causali: per comprendere veramente i fenomeni psicologici è essenziale indagare le cause sottostanti, andando oltre la mera descrizione delle associazioni.\nLa discussione dei metodi utilizzati per individuare le relazioni causali sarà trattata successivamente. In questo capitolo, ci concentreremo sui concetti statistici fondamentali necessari per descrivere le associazioni lineari tra variabili. È importante sottolineare che, sebbene esistano indici statistici per quantificare associazioni non lineari, la maggior parte degli psicologi si limita all’utilizzo di indici lineari.\nNel linguaggio comune, termini come “dipendenza”, “associazione” e “correlazione” vengono spesso usati in modo intercambiabile. Tuttavia, da un punto di vista tecnico, è importante distinguere questi concetti:\nÈ cruciale comprendere che non tutte le associazioni sono correlazioni e, soprattutto, che la correlazione non implica necessariamente causalità. Questa distinzione è fondamentale per interpretare correttamente i dati e evitare conclusioni errate sulle relazioni tra variabili.\nIn questo capitolo, esamineremo due misure statistiche fondamentali per valutare la relazione lineare tra due variabili: la covarianza e la correlazione. Questi indici ci permettono di descrivere il grado e la direzione dell’associazione lineare tra variabili, quantificando come queste variano congiuntamente.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#introduzione",
    "href": "chapters/eda/08_correlation.html#introduzione",
    "title": "21  Relazioni tra variabili",
    "section": "",
    "text": "Quanto spesso, quando è stato osservato un nuovo fenomeno, sentiamo che viene posta la domanda: ‘qual è la sua causa?’. Questa è una domanda a cui potrebbe essere assolutamente impossibile rispondere. Invece, può essere più facile rispondere alla domanda: ‘in che misura altri fenomeni sono associati con esso?’. Dalla risposta a questa seconda domanda possono risultare molte preziose conoscenze.\n\n\n\n\n\n\n\nAssociazione: questo termine indica una relazione generale tra variabili, dove la conoscenza del valore di una variabile fornisce informazioni su un’altra.\n\nCorrelazione: descrive una relazione specifica e quantificabile, indicando se due variabili tendono a variare insieme in modo sistematico. Ad esempio, in una correlazione positiva, se \\(X &gt; \\mu_X\\), è probabile che anche \\(Y &gt; \\mu_Y\\). La correlazione specifica il segno e l’intensità di una relazione lineare.\n\nDipendenza: indica una relazione causale tra le variabili, dove la variazione della variabile causale porta probabilisticamente alla variazione della variabile dipendente.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#i-dati-grezzi",
    "href": "chapters/eda/08_correlation.html#i-dati-grezzi",
    "title": "21  Relazioni tra variabili",
    "section": "\n21.2 I dati grezzi",
    "text": "21.2 I dati grezzi\nPer illustrare la correlazione e la covarianza, analizzeremo i dati raccolti da Zetsche et al. (2019) in uno studio che indaga le aspettative negative come meccanismo chiave nel mantenimento e nella reiterazione della depressione. Nello specifico, i ricercatori si sono proposti di determinare se gli individui depressi sviluppano aspettative accurate riguardo al loro umore futuro o se tali aspettative sono distortamente negative.\nUno dei loro studi ha coinvolto un campione di 30 soggetti con almeno un episodio depressivo maggiore, confrontati con un gruppo di controllo composto da 37 individui sani. La misurazione del livello di depressione è stata effettuata tramite il Beck Depression Inventory (BDI-II).\nIl BDI-II è uno strumento di autovalutazione utilizzato per valutare la gravità della depressione in adulti e adolescenti. Il test è stato sviluppato per identificare e misurare l’intensità dei sintomi depressivi sperimentati nelle ultime due settimane. I 21 item del test sono valutati su una scala a 4 punti, dove 0 rappresenta il grado più basso e 3 il grado più elevato di sintomatologia depressiva.\nNell’esercizio successivo, ci proponiamo di analizzare i punteggi di depressione BDI-II nel campione di dati fornito da Zetsche et al. (2019).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#definizione-delle-relazioni-tra-variabili",
    "href": "chapters/eda/08_correlation.html#definizione-delle-relazioni-tra-variabili",
    "title": "21  Relazioni tra variabili",
    "section": "\n21.3 Definizione delle relazioni tra variabili",
    "text": "21.3 Definizione delle relazioni tra variabili\nNel contesto delle indagini statistiche, spesso non ci limitiamo a esaminare la distribuzione di una singola variabile. Invece, il nostro interesse si concentra sulla relazione che emerge nei dati tra due o più variabili. Ma cosa significa esattamente quando diciamo che due variabili hanno una relazione?\nPer comprendere ciò, prendiamo ad esempio l’altezza e l’età tra un gruppo di bambini. In generale, è possibile notare che all’aumentare dell’età di un bambino, aumenta anche la sua altezza. Pertanto, conoscere l’età di un bambino, ad esempio tredici anni, e l’età di un altro, sei anni, ci fornisce un’indicazione su quale dei due bambini sia più alto.\nNel linguaggio statistico, definiamo questa relazione tra altezza e età come positiva, il che significa che all’aumentare dei valori di una delle variabili (in questo caso, l’età), ci aspettiamo di vedere valori più elevati anche nell’altra variabile (l’altezza). Tuttavia, esistono anche relazioni negative, in cui l’aumento di una variabile è associato a un diminuzione dell’altra (ad esempio, più età è correlata a meno pianto).\nNon si tratta solo di relazioni positive o negative; ci sono anche situazioni in cui le variabili non hanno alcuna relazione tra loro, definendo così una relazione nulla. Inoltre, le relazioni possono variare nel tempo, passando da positive a negative o da fortemente positive a appena positiva. In alcuni casi, una delle variabili può essere categorica, rendendo difficile parlare di “maggioranza” o “minoranza” ma piuttosto di “differente” (ad esempio, i bambini più grandi potrebbero semplicemente avere diverse preferenze rispetto ai bambini più piccoli, senza necessariamente essere “migliori” o “peggiori”).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#sec-scatter-plot",
    "href": "chapters/eda/08_correlation.html#sec-scatter-plot",
    "title": "21  Relazioni tra variabili",
    "section": "\n21.4 Grafico a dispersione",
    "text": "21.4 Grafico a dispersione\nIl metodo più diretto per visualizzare la relazione tra due variabili continue è tramite un grafico a dispersione, comunemente noto come “scatterplot”. Questo tipo di diagramma rappresenta le coppie di dati ottenute da due variabili, posizionandole sull’asse delle ascisse (orizzontale) e delle ordinate (verticale).\nPer rendere l’idea più chiara, consideriamo i dati dello studio condotto da Zetsche et al. (2019), in cui i ricercatori hanno utilizzato due scale psicometriche, il Beck Depression Inventory II (BDI-II) e la Center for Epidemiologic Studies Depression Scale (CES-D), per misurare il livello di depressione nei partecipanti. Il BDI-II è uno strumento di autovalutazione che valuta la presenza e l’intensità dei sintomi depressivi in pazienti adulti e adolescenti con diagnosi psichiatrica, mentre la CES-D è una scala di autovalutazione progettata per misurare i sintomi depressivi sperimentati nella settimana precedente nella popolazione generale, in particolare negli adolescenti e nei giovani adulti. Poiché entrambe le scale misurano lo stesso costrutto, ovvero la depressione, ci aspettiamo una relazione tra i punteggi ottenuti dal BDI-II e dalla CES-D. Un diagramma a dispersione ci consente di esaminare questa relazione in modo visuale e intuitivo.\n\n# Leggi i dati dal file CSV\ndf &lt;- rio::import(here::here(\"data\", \"data.mood.csv\"))\n\n# Seleziona le colonne di interesse\ndf &lt;- df |&gt;\n  dplyr::select(\"esm_id\", \"group\", \"bdi\", \"cesd_sum\")\n\n# Rimuovi le righe duplicate\ndf &lt;- df[!duplicated(df), ]\n\n# Rimuovi le righe con valori mancanti nella colonna \"bdi\"\ndf &lt;- df[!is.na(df$bdi), ]\n\nPosizionando i valori del BDI-II sull’asse delle ascisse e quelli del CES-D sull’asse delle ordinate, ogni punto sul grafico rappresenta un individuo, di cui conosciamo il livello di depressione misurato dalle due scale. È evidente che i valori delle scale BDI-II e CES-D non possono coincidere per due motivi principali: (1) la presenza di errori di misurazione e (2) l’utilizzo di unità di misura arbitrarie per le due variabili. L’errore di misurazione è una componente inevitabile che influisce in parte su qualsiasi misurazione, ed è particolarmente rilevante in psicologia, dove la precisione degli strumenti di misurazione è generalmente inferiore rispetto ad altre discipline, come la fisica. Il secondo motivo per cui i valori delle scale BDI-II e CES-D non possono essere identici è che l’unità di misura della depressione è una questione arbitraria e non standardizzata. Tuttavia, nonostante le differenze dovute agli errori di misurazione e all’uso di unità di misura diverse, ci aspettiamo che, se le due scale misurano lo stesso costrutto (la depressione), i valori prodotti dalle due scale dovrebbero essere associati linearmente tra di loro. Per comprendere meglio il concetto di “associazione lineare”, è possibile esaminare i dati attraverso l’utilizzo di un diagramma a dispersione.\n\n\n\n\n\n\n\n\nOsservando il grafico a dispersione, è evidente che i dati mostrano una tendenza a distribuirsi in modo approssimativamente lineare. In termini statistici, ciò suggerisce una relazione di associazione lineare tra i punteggi CES-D e BDI-II.\nTuttavia, è importante notare che la relazione lineare tra le due variabili è lontana dall’essere perfetta. In una relazione lineare perfetta, tutti i punti nel grafico sarebbero allineati in modo preciso lungo una retta. Nella realtà, la dispersione dei punti dal comportamento lineare ideale è evidente.\nDi conseguenza, sorge la necessità di quantificare numericamente la forza e la direzione della relazione lineare tra le due variabili e di misurare quanto i punti si discostino da una relazione lineare ideale. Esistono vari indici statistici a disposizione per raggiungere questo obiettivo.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#covarianza",
    "href": "chapters/eda/08_correlation.html#covarianza",
    "title": "21  Relazioni tra variabili",
    "section": "\n21.5 Covarianza",
    "text": "21.5 Covarianza\nIniziamo a considerare il più importante di tali indici, chiamato covarianza. In realtà la definizione di questo indice non ci sorprenderà più di tanto in quanto, in una forma solo apparentemente diversa, l’abbiamo già incontrata in precedenza. Ci ricordiamo infatti che la varianza di una generica variabile \\(X\\) è definita come la media degli scarti quadratici di ciascuna osservazione dalla media:\n\\[\nS_{XX} = \\frac{1}{n} \\sum_{i=1}^n(X_i - \\bar{X}) (X_i - \\bar{X}).\n\\]\nLa varianza viene talvolta descritta come la “covarianza di una variabile con sé stessa”. Adesso facciamo un passo ulteriore. Invece di valutare la dispersione di una sola variabile, ci chiediamo come due variabili \\(X\\) e \\(Y\\) “variano insieme” (co-variano). È facile capire come una risposta a tale domanda possa essere fornita da una semplice trasformazione della formula precedente che diventa:\n\\[\nS_{XY} = \\frac{1}{n} \\sum_{i=1}^n(X_i - \\bar{X}) (Y_i - \\bar{Y}).\n\\tag{21.1}\\]\nL’Equazione 21.1 ci fornisce la definizione della covarianza.\n\n21.5.1 Interpretazione\nPer capire il significato dell’Equazione 21.1, supponiamo di dividere il grafico riportato nella Sezione 21.4 in quattro quadranti definiti da una retta verticale passante per la media dei valori BDI-II e da una retta orizzontale passante per la media dei valori CES-D. Numeriamo i quadranti partendo da quello in basso a sinistra e muovendoci in senso antiorario.\nSe prevalgono punti nel I e III quadrante, allora la nuvola di punti avrà un andamento crescente (per cui a valori bassi di \\(X\\) tendono ad associarsi valori bassi di \\(Y\\) e a valori elevati di \\(X\\) tendono ad associarsi valori elevati di \\(Y\\)) e la covarianza avrà segno positivo. Mentre se prevalgono punti nel II e IV quadrante la nuvola di punti avrà un andamento decrescente (per cui a valori bassi di \\(X\\) tendono ad associarsi valori elevati di \\(Y\\) e a valori elevati di \\(X\\) tendono ad associarsi valori bassi di \\(Y\\)) e la covarianza avrà segno negativo. Dunque, il segno della covarianza ci informa sulla direzione della relazione lineare tra due variabili: l’associazione lineare si dice positiva se la covarianza è positiva, negativa se la covarianza è negativa.\nEsercizio. Implemento l’Equazione 21.1 in R.\n\ncov_value &lt;- function(x, y) {\n  mean_x &lt;- sum(x) / length(x)\n  mean_y &lt;- sum(y) / length(y)\n\n  sub_x &lt;- x - mean_x\n  sub_y &lt;- y - mean_y\n\n  sum_value &lt;- sum(sub_y * sub_x)\n  denom &lt;- length(x)\n\n  cov &lt;- sum_value / denom\n  return(cov)\n}\n\nPer i dati mostrati nel diagramma, la covarianza tra BDI-II e CESD è 207.4\n\nx &lt;- df$bdi\ny &lt;- df$cesd_sum\n\ncov_value(x, y)\n#&gt; [1] 207\n\nOppure, in maniera più semplice:\n\nmean((x - mean(x)) * (y - mean(y)))\n#&gt; [1] 207\n\nLo stesso risultato si ottiene con la funzione cov:\n\ncov(x, y) * (length(x) - 1) / length(x)\n#&gt; [1] 207\n\nLa funzione cov(x, y) calcola la covarianza tra due array, x e y utilizzando \\(n-1\\) al denominatore.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#correlazione",
    "href": "chapters/eda/08_correlation.html#correlazione",
    "title": "21  Relazioni tra variabili",
    "section": "\n21.6 Correlazione",
    "text": "21.6 Correlazione\nLa direzione della relazione tra le variabili è indicata dal segno della covarianza, ma il valore assoluto di questo indice non fornisce informazioni utili poiché dipende dall’unità di misura delle variabili. Ad esempio, considerando l’altezza e il peso delle persone, la covarianza sarà più grande se l’altezza è misurata in millimetri e il peso in grammi, rispetto al caso in cui l’altezza è in metri e il peso in chilogrammi. Pertanto, per descrivere la forza e la direzione della relazione lineare tra due variabili in modo adimensionale, si utilizza l’indice di correlazione.\nLa correlazione è ottenuta standardizzando la covarianza tramite la divisione delle deviazioni standard (\\(s_X\\), \\(s_Y\\)) delle due variabili:\n\\[\nr = \\frac{S_{XY}}{S_X S_Y}.\n\\tag{21.2}\\]\nLa quantità che si ottiene dall’Equazione 21.2 viene chiamata correlazione di Bravais-Pearson (dal nome degli autori che, indipendentemente l’uno dall’altro, l’hanno introdotta).\nIn maniera equivalente, per una lista di coppie di valori \\((x_1, y_1), \\dots, (x_n, y_n)\\), il coefficiente di correlazione è definito come la media del prodotto dei valori standardizzati:\n\\[\nr = \\frac{1}{n} \\sum_{i=1}^{n} \\left( \\frac{x_i - \\bar{x}}{\\sigma_x} \\right) \\left( \\frac{y_i - \\bar{y}}{\\sigma_y} \\right),\n\\tag{21.3}\\]\ndove \\(\\bar{x}\\) e \\(\\bar{y}\\) rappresentano, rispettivamente, le medie dei valori \\(x\\) e \\(y\\), e \\(\\sigma_x\\) e \\(\\sigma_y\\) sono le rispettive deviazioni standard.\nNell’Equazione 21.3, i valori \\(x_i\\) e \\(y_i\\) vengono prima standardizzati sottraendo la media e dividendo per la deviazione standard, e poi si calcola la media del prodotto di questi valori standardizzati.\n\n21.6.1 Proprietà\nIl coefficiente di correlazione ha le seguenti proprietà:\n\nha lo stesso segno della covarianza, dato che si ottiene dividendo la covarianza per due numeri positivi;\nè un numero puro, cioè non dipende dall’unità di misura delle variabili;\nassume valori compresi tra -1 e +1.\n\n21.6.2 Interpretazione\nAll’indice di correlazione possiamo assegnare la seguente interpretazione:\n\n\n\\(r_{XY} = -1\\) \\(\\rightarrow\\) perfetta relazione negativa: tutti i punti si trovano esattamente su una retta con pendenza negativa (dal quadrante in alto a sinistra al quadrante in basso a destra);\n\n\\(r_{XY} = +1\\) \\(\\rightarrow\\) perfetta relazione positiva: tutti i punti si trovano esattamente su una retta con pendenza positiva (dal quadrante in basso a sinistra al quadrante in alto a destra);\n\n\\(-1 &lt; r_{XY} &lt; +1\\) \\(\\rightarrow\\) presenza di una relazione lineare di intensità diversa;\n\n\\(r_{XY} = 0\\) \\(\\rightarrow\\) assenza di relazione lineare tra \\(X\\) e \\(Y\\).\n\nEsercizio. Per i dati riportati nel diagramma della sezione {ref}sec-zetsche-scatter, la covarianza è 207.4. Il segno positivo della covarianza ci dice che tra le due variabili c’è un’associazione lineare positiva. Per capire quale sia l’intensità della relazione lineare calcoliamo la correlazione. Essendo le deviazioni standard del BDI-II e del CES-D rispettavamente uguali a 15.37 e 14.93, la correlazione diventa uguale a \\(\\frac{207.426}{15.38 \\cdot 14.93} = 0.904.\\) Tale valore è prossimo a 1.0, il che vuol dire che i punti del diagramma a dispersione non si discostano troppo da una retta con una pendenza positiva.\nTroviamo la correlazione con la funzione corrcoef():\n\ncor(x, y)\n#&gt; [1] 0.904\n\nReplichiamo il risultato implementando l’eq. {eq}eq-cor-def:\n\ns_xy &lt;- mean((x - mean(x)) * (y - mean(y)))\ns_x &lt;- sqrt(mean((x - mean(x))^2)) # Deviazione standard popolazione\ns_y &lt;- sqrt(mean((y - mean(y))^2)) # Deviazione standard popolazione\nr_xy &lt;- s_xy / (s_x * s_y)\nprint(r_xy)\n#&gt; [1] 0.904\n\nUn altro modo ancora per trovare la correlazione tra i punteggi BDI-II e CESD è quello di applicare l’Equazione 21.3:\n\nz_x &lt;- (x - mean(x)) / sqrt(mean((x - mean(x))^2)) \n# Standardizzazione con deviazione standard popolazione\nz_y &lt;- (y - mean(y)) / sqrt(mean((y - mean(y))^2)) \n# Standardizzazione con deviazione standard popolazione\nmean(z_x * z_y)\n#&gt; [1] 0.904\n\nEsempio. Un uso interessante delle correlazioni viene fatto in un recente articolo di Guilbeault et al. (2024). Il concetto di “gender bias” si riferisce alla tendenza sistematica di favorire un sesso rispetto all’altro, spesso a scapito delle donne. Lo studio di Guilbeault et al. (2024) analizza come le immagini online influenzino la diffusione su vasta scala di questo preconcetto di genere.\nAttraverso un vasto insieme di immagini e testi raccolti online, gli autori dimostrano che sia le misurazioni basate sulle immagini che quelle basate sui testi catturano la frequenza con cui varie categorie sociali sono associate a rappresentazioni di genere, valutate su una scala da -1 (femminile) a 1 (maschile), con 0 che indica una neutralità di genere. Questo consente di quantificare il preconcetto di genere come una forma di bias statistico lungo tre dimensioni: la tendenza delle categorie sociali ad associarsi a un genere specifico nelle immagini e nei testi, la rappresentazione relativa delle donne rispetto agli uomini in tutte le categorie sociali nelle immagini e nei testi, e il confronto tra le associazioni di genere nei dati delle immagini e dei testi con la distribuzione empirica delle donne e degli uomini nella società. Il lavoro di Guilbeault et al. (2024) evidenzia che il preconcetto di genere è molto più evidente nelle immagini rispetto ai testi, come mostrato nella {numref}gender-bias-1-fig C.\nSi noti che, nel grafico della {numref}gender-bias-1-fig C, ogni punto può essere interpretato come una misura di correlazione. La misura utilizzata da Guilbeault et al. (2024) riflette il grado di associazione tra le categorie sociali e le rappresentazioni di genere presenti nelle immagini e nei testi analizzati. Quando la misura è vicina a +1, indica una forte associazione positiva tra una categoria sociale specifica e una rappresentazione di genere maschile, mentre un valore vicino a -1 indica una forte associazione negativa con una rappresentazione di genere femminile. Un valore di 0, invece, suggerisce che non vi è alcuna associazione tra la categoria sociale considerata e un genere specifico, indicando una sorta di neutralità di genere. In sostanza, questa misura di frequenza può essere interpretata come una correlazione che riflette la tendenza delle categorie sociali a essere rappresentate in un modo o nell’altro nelle immagini e nei testi analizzati, rispetto ai concetti di genere femminile e maschile.\n\n\nIl preconcetto di genere è più prevalente nelle immagini online (da Google Immagini) e nei testi online (da Google News). A. La correlazione tra le associazioni di genere nelle immagini da Google Immagini e nei testi da Google News per tutte le categorie sociali (n = 2.986), organizzate per decili. B. La forza dell’associazione di genere in queste immagini e testi online per tutte le categorie (n = 2.986), suddivisa in base al fatto che queste categorie siano inclinate verso il femminile o il maschile. C. Le associazioni di genere per un campione di occupazioni secondo queste immagini e testi online; questo campione è stato selezionato manualmente per evidenziare i tipi di categorie sociali e preconcetti di genere esaminati. (Figura tratta da Guilbeault et al. (2024)).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#correlazione-di-spearman",
    "href": "chapters/eda/08_correlation.html#correlazione-di-spearman",
    "title": "21  Relazioni tra variabili",
    "section": "\n21.7 Correlazione di Spearman",
    "text": "21.7 Correlazione di Spearman\nUn’alternativa per valutare la relazione lineare tra due variabili è il coefficiente di correlazione di Spearman, che si basa esclusivamente sull’ordine dei dati e non sugli specifici valori. Questo indice di associazione è particolarmente adatto quando gli psicologi sono in grado di misurare solo le relazioni di ordine tra diverse modalità di risposta dei soggetti, ma non l’intensità della risposta stessa. Tali variabili psicologiche che presentano questa caratteristica sono definite come “ordinali”.\n\n\n\n\n\n\nÈ importante ricordare che, nel caso di una variabile ordinale, non è possibile utilizzare le statistiche descrittive convenzionali come la media e la varianza per sintetizzare le osservazioni. Tuttavia, è possibile riassumere le osservazioni attraverso una distribuzione di frequenze delle diverse modalità di risposta. Come abbiamo appena visto, la direzione e l’intensità dell’associazione tra due variabili ordinali possono essere descritte utilizzando il coefficiente di correlazione di Spearman.\n\n\n\nPer fornire un esempio, consideriamo due variabili di scala ordinale e calcoliamo la correlazione di Spearman tra di esse.\n\ncor.test(c(1, 2, 3, 4, 5), c(5, 6, 7, 8, 7), method = \"spearman\")\n#&gt; Warning in cor.test.default(c(1, 2, 3, 4, 5), c(5, 6, 7, 8, 7), method =\n#&gt; \"spearman\"): Impossibile calcolare p-value esatti in presenza di ties\n#&gt; \n#&gt;  Spearman's rank correlation rho\n#&gt; \n#&gt; data:  c(1, 2, 3, 4, 5) and c(5, 6, 7, 8, 7)\n#&gt; S = 4, p-value = 0.09\n#&gt; alternative hypothesis: true rho is not equal to 0\n#&gt; sample estimates:\n#&gt;   rho \n#&gt; 0.821",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#oltre-la-correlazione-e-la-covarianza-quando-lassociazione-tra-variabili-è-più-complessa",
    "href": "chapters/eda/08_correlation.html#oltre-la-correlazione-e-la-covarianza-quando-lassociazione-tra-variabili-è-più-complessa",
    "title": "21  Relazioni tra variabili",
    "section": "\n21.8 Oltre la correlazione e la covarianza: quando l’associazione tra variabili è più complessa",
    "text": "21.8 Oltre la correlazione e la covarianza: quando l’associazione tra variabili è più complessa\nIn questo capitolo abbiamo introdotto due misure fondamentali per descrivere la relazione tra due variabili: covarianza e correlazione. La covarianza fornisce un’indicazione del modo in cui due variabili si discostano congiuntamente dalle proprie medie, mentre la correlazione ne standardizza i valori, permettendo un confronto più immediato tra diverse coppie di variabili e garantendo un indice compreso tra -1 e +1. Una correlazione vicina a +1 indica una forte relazione lineare positiva, vicina a -1 una forte relazione lineare negativa, mentre un valore vicino a 0 segnala l’assenza di una chiara relazione lineare.\nTuttavia, è cruciale comprendere che la correlazione descrive esclusivamente la dimensione lineare della relazione tra due variabili. Questo significa che una correlazione nulla (pari a zero) non implica affatto che non vi sia alcuna relazione tra le variabili, ma semplicemente che non esiste una relazione lineare. Possono esistere relazioni non lineari anche molto forti, non catturate da questo indice. Inoltre, altre situazioni possono trarre in inganno, come nei casi in cui i dati siano raggruppati in sottogruppi con proprietà differenti o siano frutto di particolari processi di selezione.\n\n21.8.1 Correlazione nulla e relazioni non lineari\nUna correlazione pari a zero può nascondere relazioni non lineari anche molto marcate. Per esempio, se una variabile Y aumenta solo quando X è molto alta o molto bassa, ma rimane costante per valori intermedi di X, questa curva a “U” può generare una correlazione vicina allo zero, pur esistendo un forte legame non lineare.\nUn esempio illustrativo è fornito dal cosiddetto Datasaurus Dozen, un insieme di tredici dataset con la stessa media, deviazione standard e correlazione tra le variabili, ma con distribuzioni visivamente e strutturalmente molto diverse. In ognuno di questi dataset la correlazione di Pearson è pari a zero, ma l’ispezione grafica rivela pattern e forme ben definite. Questo ci ricorda che è sempre bene accompagnare le misure numeriche con una visualizzazione grafica dei dati.\n\ndatasaurus_data &lt;- read.csv(\"../../data/datasaurus.csv\")\n\ndatasaurus_summary &lt;- datasaurus_data %&gt;%\n  group_by(dataset) %&gt;%\n  summarise(\n    x_count = n(),\n    x_mean = mean(x, na.rm = TRUE),\n    x_std = sd(x, na.rm = TRUE),\n    y_count = n(),\n    y_mean = mean(y, na.rm = TRUE),\n    y_std = sd(y, na.rm = TRUE)\n  )\n\ndatasaurus_summary\n#&gt; # A tibble: 13 × 7\n#&gt;   dataset  x_count x_mean x_std y_count y_mean y_std\n#&gt;   &lt;chr&gt;      &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 away         142   54.3  16.8     142   47.8  26.9\n#&gt; 2 bullseye     142   54.3  16.8     142   47.8  26.9\n#&gt; 3 circle       142   54.3  16.8     142   47.8  26.9\n#&gt; 4 dino         142   54.3  16.8     142   47.8  26.9\n#&gt; 5 dots         142   54.3  16.8     142   47.8  26.9\n#&gt; 6 h_lines      142   54.3  16.8     142   47.8  26.9\n#&gt; # ℹ 7 more rows\n\n\ndatasaurus_data |&gt;\n  ggplot(aes(x = x, y = y)) +\n  geom_point(alpha = 0.7) +\n  facet_wrap(~dataset, nrow = 4, ncol = 4) +\n  labs(x = NULL, y = NULL)\n\n\n\n\n\n\n\nTutti questi esempi rafforzano l’idea che l’assenza di correlazione lineare non significa assenza di relazione: potremmo avere strutture curve, pattern complessi o punti anomali (outlier) capaci di modificare radicalmente la forma della relazione tra le variabili.\nOltre alle relazioni non lineari, esistono situazioni in cui la correlazione, da sola, può fornire un’immagine distorta dei dati. Tra queste ricordiamo due fenomeni noti come il paradosso di Simpson e il paradosso di Berkson.\n\n21.8.2 Paradosso di Simpson\nIl paradosso di Simpson si verifica quando, guardando i dati raggruppati per sottogruppi, si osserva una certa relazione tra due variabili, ma aggregando i dati di tutti i sottogruppi insieme emerge una relazione opposta. In altre parole, la tendenza che appare quando si considerano i dati divisi per gruppi scompare o si inverte quando si esamina l’intero campione senza tenere conto della suddivisione in sottogruppi.\nImmaginiamo di avere due dipartimenti universitari, A e B. All’interno di ciascun dipartimento, la relazione tra il voto di laurea (X) e la performance in un successivo programma di specializzazione (Y) è positiva: all’aumentare del voto di laurea aumenta, in media, la performance nella scuola di specializzazione.\nTuttavia, supponiamo che il Dipartimento A abbia in generale voti di laurea mediamente più bassi, ma ottime performance nella specializzazione; mentre il Dipartimento B abbia voti di laurea mediamente più alti, ma performance alla specializzazione un po’ più basse. Se uniamo tutti gli studenti dei due dipartimenti senza considerarne l’appartenenza, potremmo osservare una relazione negativa tra voto di laurea e performance, sovvertendo le conclusioni tratte guardando ai singoli sottogruppi.\nEcco come possiamo simulare questi dati in R:\n\nset.seed(123)\n\n# Numero di osservazioni per dipartimento\nn &lt;- 100\n\n# Dipartimento A:\n# Voti di laurea (X) più bassi, ma performance (Y) più alta.\n# Creiamo un legame positivo tra X e Y all'interno di A.\nX_A &lt;- rnorm(n, mean = 50, sd = 5)    # Voti laurea mediamente più bassi\nY_A &lt;- X_A + rnorm(n, mean = 20, sd = 5) # Performance alta e correlata positivamente con X\n\n# Dipartimento B:\n# Voti di laurea (X) più alti, ma performance (Y) più bassa.\n# Anche qui creiamo un legame positivo tra X e Y all'interno di B, \n# ma con un offset tale che globalmente i voti alti coincidano con performance minori.\nX_B &lt;- rnorm(n, mean = 60, sd = 5)    # Voti laurea mediamente più alti\nY_B &lt;- X_B - rnorm(n, mean = 10, sd = 5) # Performance più bassa ma comunque correlata positivamente con X all’interno di B\n\n# Creiamo un dataframe con tutti i dati\ndipartimento &lt;- c(rep(\"A\", n), rep(\"B\", n))\nX &lt;- c(X_A, X_B)\nY &lt;- c(Y_A, Y_B)\ndati &lt;- data.frame(dipartimento, X, Y)\n\n# Correlazioni all'interno dei dipartimenti\ncat(\"Correlazione nel Dipartimento A:\", cor(X_A, Y_A), \"\\n\")\n#&gt; Correlazione nel Dipartimento A: 0.667\ncat(\"Correlazione nel Dipartimento B:\", cor(X_B, Y_B), \"\\n\")\n#&gt; Correlazione nel Dipartimento B: 0.693\n\n# Correlazione sull'intero dataset (senza distinguere i dipartimenti)\ncat(\"Correlazione globale:\", cor(X, Y), \"\\n\")\n#&gt; Correlazione globale: -0.335\n\n\n# Visualizziamo i dati\nggplot(dati, aes(x = X, y = Y, color = dipartimento)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  scale_fill_okabeito() + \n  labs(\n    title = \"Paradosso di Simpson\",\n    x = \"Voto di laurea\", \n    y = \"Performance nella specializzazione\",\n    color = \"Dipartimento\"\n  )\n#&gt; `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nAll’interno del Dipartimento A: la correlazione tra voto di laurea (X) e performance (Y) è positiva. Ciò significa che, per gli studenti di A, avere un voto di laurea più alto è associato a una performance maggiore nella specializzazione.\nAll’interno del Dipartimento B: la correlazione tra X e Y è anch’essa positiva, indicando che anche nel secondo dipartimento voti più alti tendono ad accompagnarsi a performance più alte.\nConsiderando entrambi i dipartimenti insieme: a causa delle differenze nei livelli medi di X e Y tra i dipartimenti, unendo i dati senza distinguere il gruppo di appartenenza otteniamo una correlazione globale negativa. Questo significa che, ignorando la suddivisione in dipartimenti, sembra che aumentare il voto di laurea sia associato a una diminuzione della performance nella specializzazione — una conclusione opposta a quella tratta dall’analisi separata dei due sottogruppi.\n\nQuesto è un esempio concreto del paradosso di Simpson: la relazione osservata in sottogruppi omogenei si inverte quando si aggregano i dati, mettendo in guardia sulla necessità di considerare con attenzione la struttura dei dati e i fattori confondenti prima di trarre conclusioni.\n\n21.8.3 Paradosso di Berkson\nIl paradosso di Berkson è un fenomeno legato alla selezione del campione. Se il dataset non è rappresentativo della popolazione generale, la relazione osservata può risultare artificiale o opposta a quella esistente su un campione più ampio. Per esempio, analizzando solo ciclisti professionisti, potremmo non vedere alcuna relazione tra VO2 max e probabilità di vincere una gara, poiché tutti hanno già superato una certa soglia di VO2 max. Considerando la popolazione generale, invece, potrebbe emergere chiaramente una relazione positiva tra questi due fattori. Questo paradosso evidenzia l’importanza di considerare il processo di selezione dei dati e di chiedersi se il campione analizzato sia adeguato a rispondere alla domanda di ricerca.\n\n21.8.4 Limiti delle statistiche riassuntive semplici\nUn esempio particolarmente famoso che dimostra i limiti delle semplici statistiche descrittive — come media, deviazione standard e correlazione — è il quartetto di Anscombe. Questo insieme di quattro piccoli dataset possiede identiche medie, varianze e correlazioni tra variabili, ma rappresenta relazioni estremamente differenti tra X e Y (Anscombe, 1973).\nImportiamo il dataset anscombe già disponibile nel pacchetto datasets di R:\n\ndata(\"anscombe\")\n\nanscombe |&gt; \n  head()\n#&gt;   x1 x2 x3 x4   y1   y2    y3   y4\n#&gt; 1 10 10 10  8 8.04 9.14  7.46 6.58\n#&gt; 2  8  8  8  8 6.95 8.14  6.77 5.76\n#&gt; 3 13 13 13  8 7.58 8.74 12.74 7.71\n#&gt; 4  9  9  9  8 8.81 8.77  7.11 8.84\n#&gt; 5 11 11 11  8 8.33 9.26  7.81 8.47\n#&gt; 6 14 14 14  8 9.96 8.10  8.84 7.04\n\nIl dataset anscombe contiene quattro serie di dati (x1, y1), (x2, y2), (x3, y3) e (x4, y4), ognuna costituita da 11 coppie di valori (x, y). Per comprendere meglio le loro caratteristiche, iniziamo calcolando alcune statistiche descrittive. La funzione apply() consente di applicare una funzione (ad esempio, mean) a tutte le colonne di un data frame. Usandola sulle colonne di anscombe, otteniamo le medie di ciascuna delle otto variabili (le quattro x e le quattro y):\n\napply(anscombe, MARGIN = 2, mean)\n#&gt;  x1  x2  x3  x4  y1  y2  y3  y4 \n#&gt; 9.0 9.0 9.0 9.0 7.5 7.5 7.5 7.5\n\nOsserviamo che le medie delle quattro variabili x sono identiche fino a sei cifre decimali, e le medie delle quattro variabili y differiscono solo in modo trascurabile (circa lo 0.01%). Analogamente, se calcoliamo le deviazioni standard per ciascuna variabile, notiamo una notevole somiglianza:\n\napply(anscombe, MARGIN = 2, sd)\n#&gt;   x1   x2   x3   x4   y1   y2   y3   y4 \n#&gt; 3.32 3.32 3.32 3.32 2.03 2.03 2.03 2.03\n\nAnche in questo caso, le deviazioni standard per le x coincidono fino alla sesta cifra decimale, mentre quelle delle y differiscono di meno dello 0.06%. Inoltre, se calcoliamo i coefficienti di correlazione tra x e y in ognuno dei quattro dataset, scopriamo che sono quasi identici:\n\n# Calcoliamo la correlazione per ciascuna coppia (x1,y1), (x2,y2), (x3,y3), (x4,y4)\nfor (i in 1:4) {\n  x_var &lt;- anscombe[[paste0(\"x\", i)]]\n  y_var &lt;- anscombe[[paste0(\"y\", i)]]\n  \n  corr_value &lt;- cor(x_var, y_var)\n  cat(\"Correlazione tra x\", i, \"e y\", i, \":\", corr_value, \"\\n\")\n}\n#&gt; Correlazione tra x 1 e y 1 : 0.816 \n#&gt; Correlazione tra x 2 e y 2 : 0.816 \n#&gt; Correlazione tra x 3 e y 3 : 0.816 \n#&gt; Correlazione tra x 4 e y 4 : 0.817\n\nSe ci limitassimo a guardare queste statistiche (media, deviazione standard, correlazione), potremmo facilmente essere indotti a concludere che i quattro dataset sono tra loro sostanzialmente indistinguibili. Tuttavia, la realtà è molto diversa. Le statistiche descrittive, prese da sole, non offrono una visione completa e possono nascondere importanti differenze nella struttura dei dati.\nQuesta differenza diventa evidente non appena decidiamo di visualizzare i dati. La rappresentazione grafica fornisce informazioni che non emergono dalle sole statistiche riassuntive:\n\nanscombe_m &lt;- tibble()\n\nfor (i in 1:4) {\n  anscombe_m &lt;- rbind(\n    anscombe_m, tibble(set = i, x = anscombe[, i], y = anscombe[, i + 4])\n  )\n}\n\nggplot(anscombe_m, aes(x, y)) +\n  geom_point(size = 3, color = \"red\", fill = \"orange\", shape = 21) +\n  geom_smooth(method = \"lm\", fill = NA, fullrange = TRUE) +\n  facet_wrap(~set, ncol = 2)\n#&gt; `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\nOsservando i grafici, notiamo subito che i quattro dataset sono profondamente diversi:\n\n\nDataset 1: Qui la relazione tra x e y è approssimativamente lineare, e la correlazione riflette in modo appropriato il legame tra le due variabili.\n\nDataset 2: Sebbene la correlazione sia simile a quella del Dataset 1, i dati mostrano una relazione curvilinea e non lineare. La semplice correlazione lineare non ne cattura la forma.\n\nDataset 3: La presenza di un singolo outlier distorce la percezione della relazione tra le variabili, altrimenti lineare. La correlazione alta è influenzata in modo sproporzionato da questo punto anomalo.\n\nDataset 4: Qui i dati non mostrano alcuna relazione lineare. La correlazione elevata è il frutto di un pattern fortemente atipico (ad esempio, una sola coppia di punti allineata).\n\nIl quartetto di Anscombe mette in luce un principio fondamentale: statistiche descrittive come media, deviazione standard e correlazione non sono sempre sufficienti per comprendere la natura dei dati. La visualizzazione grafica è essenziale per cogliere relazioni, pattern non lineari, outlier e altre caratteristiche che le semplici statistiche non riescono a rivelare. In definitiva, questo esempio dimostra che analizzare i dati soltanto attraverso poche statistiche di sintesi può portare a conclusioni fuorvianti, mentre l’integrazione con la rappresentazione grafica fornisce una visione più completa e accurata.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#riflessioni-conclusive",
    "href": "chapters/eda/08_correlation.html#riflessioni-conclusive",
    "title": "21  Relazioni tra variabili",
    "section": "\n21.9 Riflessioni Conclusive",
    "text": "21.9 Riflessioni Conclusive\nLa covarianza e la correlazione sono strumenti preziosi per capire l’intensità e la direzione lineare di una relazione tra due variabili. Tuttavia, non dobbiamo confondere la loro semplicità con completezza d’informazione. Una correlazione nulla non implica assenza di relazione, ma solo assenza di una relazione lineare. Inoltre, il paradosso di Simpson e il paradosso di Berkson dimostrano che la semplice osservazione di correlazioni può essere fuorviante se non si tiene conto della struttura dei dati o del processo di selezione del campione.\nInfine, esempi come il quartetto di Anscombe sottolineano quanto sia fondamentale accompagnare le statistiche riassuntive con analisi grafiche e un’attenzione costante ai possibili pattern non lineari, agli outlier e alle caratteristiche peculiari del dataset. Nel prossimo capitolo esamineremo approcci che consentono di avvicinarsi alla comprensione causale dei fenomeni, andando oltre la semplice osservazione dell’associazione tra variabili.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/08_correlation.html#informazioni-sullambiente-di-sviluppo",
    "title": "21  Relazioni tra variabili",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] see_0.9.0        gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1\n#&gt;  [5] psych_2.4.12     scales_1.3.0     markdown_1.13    knitr_1.49      \n#&gt;  [9] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [13] purrr_1.0.2      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [17] ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] utf8_1.2.4        generics_0.1.3    stringi_1.8.4     lattice_0.22-6   \n#&gt;  [5] hms_1.1.3         digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1   \n#&gt;  [9] grid_4.4.2        timechange_0.3.0  fastmap_1.2.0     Matrix_1.7-1     \n#&gt; [13] R.oo_1.27.0       rprojroot_2.0.4   jsonlite_1.8.9    R.utils_2.12.3   \n#&gt; [17] mgcv_1.9-1        mnormt_2.1.1      cli_3.6.3         rlang_1.1.4      \n#&gt; [21] R.methodsS3_1.8.2 splines_4.4.2     munsell_0.5.1     withr_3.0.2      \n#&gt; [25] yaml_2.3.10       tools_4.4.2       parallel_4.4.2    tzdb_0.4.0       \n#&gt; [29] colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5       R6_2.5.1         \n#&gt; [33] lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.0    \n#&gt; [37] gtable_0.3.6      data.table_1.16.4 glue_1.8.0        xfun_0.49        \n#&gt; [41] tidyselect_1.2.1  farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-166     \n#&gt; [45] labeling_0.4.3    rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#bibliografia",
    "href": "chapters/eda/08_correlation.html#bibliografia",
    "title": "21  Relazioni tra variabili",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAnscombe, F. J. (1973). Graphs in statistical analysis. The American Statistician, 27(1), 17–21.\n\n\nHamaker, E. (2024). The curious case of the cross-sectional correlation. Multivariate Behavioral Research, 59(6), 1111–1122.\n\n\nZetsche, U., Buerkner, P.-C., & Renneberg, B. (2019). Future expectations in clinical depression: biased or realistic? Journal of Abnormal Psychology, 128(7), 678–688.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html",
    "href": "chapters/eda/09_causality.html",
    "title": "22  Causalità dai dati osservazionali 🔸",
    "section": "",
    "text": "22.1 Introduzione\nLa pura osservazione dei dati può rivelare correlazioni e pattern nei dati, ma senza un’indagine sulle cause che stanno alla base di tali correlazioni, le conclusioni tratte possono essere fuorvianti o incomplete.\nRichard McElreath, nel suo libro “Statistical Rethinking” (McElreath, 2020), utilizza l’analogia dei Golem - creature potenti ma prive di saggezza - per descrivere un approccio metodologico che è stato a lungo predominante in psicologia. Questo approccio si basa esclusivamente sull’analisi delle associazioni statistiche tra variabili, trascurando considerazioni più profonde sulla causalità.\nIl metodo in questione si concentra principalmente sul test delle ipotesi nulle, senza stabilire una chiara connessione tra le domande di ricerca riguardanti relazioni causali e i test statistici impiegati. Questa disconnessione è evidente nella figura successiva, tratta da un manuale di analisi dati di impostazione frequentista, che illustra la procedura raccomandata dai sostenitori di questo approccio per descrivere le associazioni tra variabili.\nÈ importante notare come tale procedura non fornisca strumenti utili per identificare le effettive cause sottostanti ai fenomeni osservati. Questa limitazione metodologica è stata identificata come uno dei fattori principali che hanno contribuito alla crisi di replicabilità nella ricerca psicologica, come approfondito nel ?sec-crisis. L’approccio descritto, pur essendo potente nell’individuare correlazioni, manca della “saggezza” necessaria per distinguere tra semplici associazioni e vere relazioni causali, analogamente ai Golem della metafora di McElreath.\nUn problema evidenziato da McElreath (2020) è che processi causali completamente distinti possono generare la stessa distribuzione di risultati osservati. Pertanto, un approccio focalizzato esclusivamente sull’analisi delle associazioni mediante il test dell’ipotesi nulla non è in grado di distinguere tra questi diversi scenari, come spiegato nel ?sec-causal-inference-regr.\nL’approccio frequentista, che si limita a descrivere le associazioni tra le variabili, ha una scarsa capacità di rilevare le caratteristiche cruciali dei fenomeni studiati e tende a produrre un alto tasso di falsi positivi (Zwet et al., 2023). È invece necessario utilizzare una metodologia che non si limiti a confutare ipotesi nulle, ma sia in grado di sviluppare modelli causali che rispondano direttamente alle domande di ricerca. In questo capitolo, ci concentreremo sull’introduzione dei concetti fondamentali dell’analisi causale.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Causalità dai dati osservazionali 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#introduzione",
    "href": "chapters/eda/09_causality.html#introduzione",
    "title": "22  Causalità dai dati osservazionali 🔸",
    "section": "",
    "text": "Esempio di albero decisionale per la selezione di una procedura statistica appropriata. Iniziando dall’alto, l’utente risponde a una serie di domande riguardanti la misurazione e l’intento, arrivando infine al nome di una procedura. Sono possibili molti alberi decisionali simili. (Figura tratta da McElreath (2020)).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Causalità dai dati osservazionali 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#cosè-la-causalità",
    "href": "chapters/eda/09_causality.html#cosè-la-causalità",
    "title": "22  Causalità dai dati osservazionali 🔸",
    "section": "22.2 Cos’è la causalità?",
    "text": "22.2 Cos’è la causalità?\nHardt & Recht (2022) introducono il concetto di causalità distinguendo tra osservazione e azione. Ciò che vediamo nell’osservazione passiva è il modo in cui le persone seguono i loro comportamenti abituali, le loro inclinazioni naturali, proiettando lo stato del mondo su un insieme di caratteristiche che abbiamo scelto di evidenziare. Tuttavia, le domande più importanti spesso non riguardano semplici osservazioni.\n\nNon ci basta sapere che le persone che praticano regolarmente attività fisica soffrono meno d’ansia; vogliamo capire se l’attività fisica riduce effettivamente i livelli d’ansia.\nNon ci accontentiamo di osservare che chi segue una terapia cognitivo-comportamentale (CBT) presenta meno sintomi depressivi; desideriamo verificare se la CBT riduce realmente questi sintomi.\nNon ci limitiamo a constatare che l’uso frequente dei social media è associato a un calo del benessere mentale; vogliamo determinare se l’uso intensivo dei social media causa effettivamente una diminuzione del benessere mentale.\n\nAlla base, il ragionamento causale è un quadro concettuale per affrontare domande sugli effetti di azioni o interventi ipotetici. Una volta compreso quale sia l’effetto di un’azione, possiamo invertire la domanda e chiederci quale azione plausibile abbia causato un determinato evento.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Causalità dai dati osservazionali 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#effetto-causale",
    "href": "chapters/eda/09_causality.html#effetto-causale",
    "title": "22  Causalità dai dati osservazionali 🔸",
    "section": "22.3 Effetto Causale",
    "text": "22.3 Effetto Causale\nSebbene non esista una definizione univoca di causalità, possiamo concettualizzarla in modo pratico: diciamo che X causa Y se, intervenendo e modificando il valore di X (il trattamento), la distribuzione di Y cambia di conseguenza. Questa definizione sottolinea l’importanza cruciale dell’azione o dell’intervento nel determinare una relazione causale.\nQuando X è una variabile binaria, rappresentante la presenza o l’assenza del trattamento, la conseguenza dell’intervento su X è denominata effetto medio del trattamento. Questo ci indica quanto il trattamento (azione X = 1) aumenta l’aspettativa di Y rispetto all’assenza di trattamento (azione X = 0).\nÈ importante notare che gli effetti causali sono quantità relative alla popolazione. Si riferiscono a effetti mediati sull’intera popolazione in esame. Tuttavia, spesso l’effetto del trattamento può variare significativamente da un individuo all’altro o tra gruppi di individui. In questi casi, parliamo di effetti di trattamento eterogenei.\nPer chiarire questo concetto, consideriamo un esempio concreto: supponiamo che la terapia cognitivo-comportamentale (CBT) riduca l’ansia. Se un gruppo di persone ansiose non riceve alcun trattamento, i loro livelli d’ansia rimarranno presumibilmente invariati. Se invece interveniamo introducendo la CBT (modificando così il valore di X), i livelli d’ansia nel gruppo tenderanno a diminuire (cambiando quindi il valore di Y). Questo esempio illustra la distinzione tra semplice correlazione, basata sull’osservazione passiva, e causalità, che implica un’azione o un intervento.\nLa definizione di causalità può essere applicata anche per collegare variabili apparentemente distanti. Ad esempio, l’autoefficacia potrebbe non avere un effetto causale diretto sulle prestazioni accademiche. Tuttavia, se aumentiamo l’autoefficacia attraverso interventi mirati, è probabile che osserviamo un miglioramento nell’impegno allo studio. Questo aumento dell’impegno, a sua volta, tende a migliorare le prestazioni accademiche. Di conseguenza, possiamo affermare che l’autoefficacia influisce indirettamente sulle prestazioni accademiche attraverso una catena causale.\nÈ importante precisare che affermiamo l’esistenza di una relazione causale tra X e Y anche quando modificare X non porta necessariamente a un cambiamento immediato o deterministico in Y, ma altera la probabilità che Y si verifichi in un certo modo, modificando quindi la distribuzione di Y. Questa prospettiva probabilistica della causalità è particolarmente rilevante in campi come la psicologia, dove le relazioni tra variabili sono spesso complesse e influenzate da molteplici fattori.\n\n22.3.1 I Limiti dell’Osservazione\nPer comprendere i limiti dell’osservazione passiva, e quindi la necessità di comprendere le relazioni causali sottostanti, Hardt & Recht (2022) si riferiscono all’esempio storico delle ammissioni ai corsi di laurea dell’Università della California, Berkeley, nel 1973. In quell’anno, 12,763 candidati furono considerati per l’ammissione in uno dei 101 dipartimenti o major interdipartimentali. Di questi, 4,321 erano donne e 8,442 erano uomini. I dati mostrano che circa il 35% delle donne fu ammesso, rispetto al 44% degli uomini. Test di significatività statistica indicano che questa differenza non è attribuibile al caso, suggerendo una disparità nei tassi di ammissione tra i generi.\nUna tendenza simile si osserva quando si analizzano le decisioni aggregate di ammissione nei sei maggiori dipartimenti. Il tasso di ammissione complessivo per gli uomini era di circa il 44%, mentre per le donne era solo il 30%, un’altra differenza significativa. Tuttavia, poiché i dipartimenti hanno autonomia nelle loro decisioni di ammissione, è utile esaminare il possibile bias di genere a livello di singolo dipartimento.\nUomini\n\n\n\nDipartimento\nCandidati\nAmmessi (%)\n\n\n\n\nA\n825\n62\n\n\nB\n520\n60\n\n\nC\n325\n37\n\n\nD\n417\n33\n\n\nE\n191\n28\n\n\nF\n373\n6\n\n\n\nDonne\n\n\n\nDipartimento\nCandidati\nAmmessi (%)\n\n\n\n\nA\n108\n82\n\n\nB\n25\n68\n\n\nC\n593\n34\n\n\nD\n375\n35\n\n\nE\n393\n24\n\n\nF\n341\n7\n\n\n\nDall’osservazione di questi dati, emerge che quattro dei sei maggiori dipartimenti mostrano un tasso di ammissione più elevato per le donne, mentre due mostrano un tasso più elevato per gli uomini. Tuttavia, questi due dipartimenti non possono giustificare la sostanziale differenza nei tassi di ammissione osservata nei dati aggregati. Questo suggerisce che la tendenza generale di un tasso di ammissione più alto per gli uomini sembra invertita quando i dati sono disaggregati per dipartimento.\nQuesto fenomeno è noto come paradosso di Simpson, un paradosso statistico in cui una tendenza che appare in sottopopolazioni si inverte o scompare quando i dati vengono aggregati. Nel contesto attuale, il paradosso di Simpson si manifesta nel fatto che, mentre i dati aggregati sembrano indicare una discriminazione di genere contro le donne, l’analisi dei dati disaggregati per dipartimento rivela che in alcuni casi le donne sono favorite in termini di ammissioni.\nLa domanda fondamentale è se questi dati indicano effettivamente un problema di discriminazione di genere o se, come suggerito dallo studio originale, il bias di genere nelle ammissioni fosse principalmente dovuto al fatto che “le donne sono indirizzate dalla loro socializzazione e istruzione verso campi di studio generalmente più affollati, meno produttivi in termini di completamento dei diplomi, meno finanziati e che spesso offrono prospettive professionali peggiori.” In altre parole, il problema risiederebbe in differenze sistemiche e strutturali tra i campi di studio scelti dalle donne e quelli scelti dagli uomini.\nIl paradosso di Simpson crea disagio proprio perché l’intuizione suggerisce che una tendenza valida per tutte le sottopopolazioni dovrebbe esserlo anche a livello aggregato. Tuttavia, questo paradosso evidenzia un errore comune nell’interpretazione delle probabilità condizionate: confondere l’osservazione passiva con l’analisi causale. I dati che abbiamo rappresentano solo un’istantanea del comportamento normale di uomini e donne che si candidavano per l’ammissione a UC Berkeley nel 1973.\nNon possiamo trarre conclusioni definitive da questi dati. Possiamo solo riconoscere che l’analisi iniziale solleva ulteriori domande, come ad esempio la necessità di progettare nuovi studi per raccogliere dati più completi, che potrebbero portare a conclusioni più definitive. In alternativa, potremmo discutere su quale scenario sia più verosimile in base alle nostre convinzioni e alle notre ipotesi sul mondo.\nL’inferenza causale può essere utile in entrambi i casi. Da un lato, può guidare la progettazione di nuovi studi, aiutandoci a scegliere quali variabili includere, quali escludere e quali mantenere costanti. Dall’altro, i modelli causali possono fungere da meccanismo per incorporare le conoscenze scientifiche del dominio e passare da ipotesi plausibili a conclusioni plausibili.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Causalità dai dati osservazionali 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#variabili-confondenti",
    "href": "chapters/eda/09_causality.html#variabili-confondenti",
    "title": "22  Causalità dai dati osservazionali 🔸",
    "section": "22.4 Variabili confondenti",
    "text": "22.4 Variabili confondenti\nSebbene gli esperimenti controllati offrano un elevato grado di certezza nell’identificazione di queste relazioni, molte domande di ricerca non possono essere affrontate sperimentalmente a causa di limitazioni etiche o pratiche. In questi casi, i ricercatori ricorrono a disegni osservazionali, che offrono maggiore flessibilità e applicabilità. Tuttavia, l’uso di dati osservazionali comporta una sfida significativa: la difficoltà di trarre conclusioni causali affidabili.\nAl centro di questa complessità si trovano le variabili confondenti. Possiamo dire che una variabile confondente è presente quando l’associazione osservata tra due variabili X e Y non riflette accuratamente la vera relazione causale tra di esse. In altre parole, la variabile confondente influenza sia X che Y, creando l’apparenza di una relazione diretta tra le due che potrebbe essere fuorviante o inesatta.\nNegli studi osservazionali, se le variabili confondenti non vengono misurate e controllate adeguatamente, possono distorcere le stime degli effetti causali, introducendo bias nei risultati e impedendo di riflettere il vero valore dell’effetto. In pratica, la presenza di variabili confondenti può portare a conclusioni errate quando si confrontano semplicemente i risultati osservati in diversi gruppi. Ciò che si osserva nei dati potrebbe non corrispondere a ciò che accadrebbe se si potesse manipolare direttamente la variabile di interesse in un esperimento controllato.\nUn approccio apparentemente semplice per affrontare questo problema potrebbe essere quello di controllare statisticamente tutte le variabili confondenti. In questo metodo, si stima l’effetto di X su Y separatamente in ogni segmento della popolazione definito da una condizione Z = z per ogni possibile valore di z. Successivamente, si calcola la media di questi effetti stimati nelle sottopopolazioni, ponderandoli per la probabilità di Z = z nella popolazione. Tuttavia, questo metodo presenta due difficoltà fondamentali: richiede la conoscenza di tutte le possibili variabili confondenti e la capacità di misurare ciascuna di esse, cosa che spesso non è praticabile.\nIl controllo delle variabili confondenti è cruciale per stabilire relazioni causali, poiché permette di isolare gli effetti delle variabili indipendenti da quelli delle variabili confondenti che potrebbero influenzare le variabili dipendenti. Esistono due principali metodologie di controllo:\n\nIl controllo sperimentale, implementato attraverso il disegno sperimentale e basato principalmente sulla randomizzazione.\nIl controllo statistico, applicato durante l’analisi dei dati, con l’obiettivo di neutralizzare o quantificare l’influenza delle variabili estranee.\n\nA causa di queste difficoltà, l’inferenza causale basata su dati osservazionali è spesso considerata problematica, dando origine al famoso detto “la correlazione non implica causalità”. Tuttavia, è importante notare che in alcune circostanze, è possibile fare inferenze causali anche a partire da dati osservazionali.\nL’obiettivo dell’analisi causale moderna è proprio quello di fornire gli strumenti concettuali e metodologici per affrontare queste sfide. Attraverso l’uso di tecniche avanzate come i modelli causali strutturali, i grafi aciclici diretti (DAG) e i metodi di identificazione degli effetti causali, i ricercatori possono spesso superare le limitazioni dei dati osservazionali e trarre conclusioni causali più robuste.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Causalità dai dati osservazionali 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#modelli-causali-strutturali",
    "href": "chapters/eda/09_causality.html#modelli-causali-strutturali",
    "title": "22  Causalità dai dati osservazionali 🔸",
    "section": "22.5 Modelli Causali Strutturali",
    "text": "22.5 Modelli Causali Strutturali\nI modelli causali sono strumenti essenziali per l’analisi dei dati osservazionali, poiché consentono di rappresentare il processo sottostante a un fenomeno e di prevedere gli effetti di un intervento. Questi modelli non solo permettono di anticipare le conseguenze di una causa, ma offrono anche la possibilità di esplorare scenari controfattuali, immaginando esiti alternativi che si sarebbero potuti verificare in presenza di decisioni diverse.\nUn modello causale strutturale (Structural Causal Model, SCM) è un approccio che rappresenta le relazioni causali tra variabili. Esso si basa su una serie di assegnazioni che, partendo da variabili di rumore indipendenti (note anche come variabili esogene), generano una distribuzione di probabilità congiunta.\nLe variabili di rumore indipendenti svolgono un ruolo cruciale negli SCM. Esse rappresentano fonti di incertezza o variabilità all’interno del sistema e non sono influenzate da altre variabili del modello. Queste variabili sono mutuamente indipendenti, il che significa che il loro valore non fornisce informazioni sul valore delle altre.\nLa costruzione di un SCM segue una sequenza specifica: si parte dalle variabili di rumore indipendenti, si applicano una serie di assegnazioni che descrivono gli effetti causali delle variabili esogene su altre variabili, e si genera progressivamente un insieme di variabili casuali che dà origine a una distribuzione congiunta.\nIl principale vantaggio di un SCM risiede nella sua duplice natura: da un lato, fornisce una distribuzione di probabilità congiunta delle variabili, e dall’altro, descrive il processo generativo che porta alla formazione di tale distribuzione, partendo dalle variabili di rumore elementari.\nQuesta struttura consente non solo di modellare le relazioni probabilistiche tra le variabili, ma anche di rappresentare in modo esplicito i meccanismi causali che le governano.\nI SCM possono essere rappresentati graficamente attraverso Grafi Aciclici Direzionati (Directed Acyclic Graphs, DAG). Questi DAG visualizzano le relazioni causali tra le variabili all’interno di un SCM, facilitando l’identificazione delle variabili confondenti e il loro impatto sull’analisi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Causalità dai dati osservazionali 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#bias-da-variabile-omessa",
    "href": "chapters/eda/09_causality.html#bias-da-variabile-omessa",
    "title": "22  Causalità dai dati osservazionali 🔸",
    "section": "22.6 Bias da Variabile Omessa",
    "text": "22.6 Bias da Variabile Omessa\nPossiamo introdurre i DAG facendo riferiento al bias da variabile omessa (Omitted Variable Bias, o OVB; Wilms et al. (2021)). Come discusso da Byrnes & Dee (2024), l’omissione dall’analisi statistica di variabili confondenti note ma non misurate, o sconosciute e non misurate, può portare a stime errate della magnitudine degli effetti, errori nel segno delle stime (stimatori distorti), correlazioni spurie, e al mascheramento delle vere relazioni causali.\nUn illustrazione di questa situazione è fornita nella Figura 22.1. La figura mostra tre DAG che illustrano diversi scenari in cui le variabili non osservate non influenzano i risultati del modello o potrebbero creare problemi a causa della confusione. Una variabile di risposta di interesse (Y) è causata sia da una variabile misurata (X) che da una variabile non misurata (U). Nel pannello di sinistra, la variabile non osservata (U) non è una variabile confondente. Nel pannello centrale, la variabile non osservata (U) è una variabile confondente e causa il bias da variabile omessa. Nel pannello di destra la variabile non osservata (U) causa il bias da variabile omessa in maniera indiretta.\n\n\n\n\n\n\nFigura 22.1: Nel pannello di sinistra, X e U sono non correlate, quindi la mancata inclusione di U in un modello statistico aumenterebbe l’errore standard della stima (riducendo la precisione del modello) ma non porterebbe a bias nella stima dell’effetto di X su Y. Tuttavia, se U influenza anche X come nel pannello centrale, o se U e X sono influenzati da un fattore comune Z come nel pannello di destra, allora omettere U da un modello statistico causa il bias da variabile omessa nella stima dell’effetto di X su Y. I casi illustrati dal pannello centrale e dal pannello di destra sono esempi di sistemi in cui le cause comuni di confusione (U e Z rispettivamente) devono essere controllate per effettuare inferenze causali non distorte (la figura è ispirata da Byrnes & Dee (2024)).\n\n\n\nAffrontare i problemi creati dalle variabili confondenti non misurate rappresenta una sfida primaria nell’inferenza causale dai dati osservazionali. A differenza dell’errore di misurazione nelle variabili predittive, che produce un bias costante verso lo zero e può essere corretto o modellato (McElreath, 2020; Schennach, 2016), con l’OVB non possiamo conoscere la grandezza o la direzione del bias senza conoscere tutte le possibili variabili confondenti e le loro relazioni nel sistema.\nNonostante queste sfide, non è necessario abbandonare l’uso dei dati osservazionali per l’inferenza causale in psicologia. È invece necessario ricorrere all’adozione delle tecniche dei SCM per potere comunque svolgere l’inferenza causale.\nÈ evidente che questo approccio porterà a conclusioni inevitabilmente parziali, destinate ad essere perfezionate da studi successivi. Tuttavia, tale metodologia offre il vantaggio di esplicitare il “modello generativo dei dati”, ovvero la struttura causale sottostante ai fenomeni psicologici oggetto di studio.\nI progressi nella ricerca empirica conducono a una maggiore comprensione e, di conseguenza, a modifiche nelle ipotesi sui meccanismi causali. Questo processo rappresenta un’evoluzione della conoscenza scientifica. Tale sviluppo è reso possibile proprio perché le ipotesi causali sono formulate in termini di modelli formali, che descrivono in modo preciso i meccanismi ipotizzati.\nAl contrario, limitarsi alla mera descrizione delle associazioni tra variabili non consente questo tipo di avanzamento conoscitivo. La formulazione di modelli causali espliciti permette infatti di testare, raffinare e, se necessario, rivedere le ipotesi sui meccanismi sottostanti ai fenomeni osservati, portando a una comprensione più profonda e dinamica dei processi psicologici.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Causalità dai dati osservazionali 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#grafi-aciclici-diretti",
    "href": "chapters/eda/09_causality.html#grafi-aciclici-diretti",
    "title": "22  Causalità dai dati osservazionali 🔸",
    "section": "22.7 Grafi Aciclici Diretti",
    "text": "22.7 Grafi Aciclici Diretti\nI DAG sono uno strumento fondamentale per l’inferenza causale, offrendo una rappresentazione visiva delle relazioni causali ipotizzate tra variabili. Questi grafi sono definiti “diretti” perché le variabili, rappresentate da nodi, sono collegate da frecce orientate anziché da semplici linee. Sono inoltre chiamati “aciclici” poiché non è possibile tornare a un nodo di partenza seguendo il percorso delle frecce.\nIn un DAG, una freccia che va da X a Y indica un’influenza probabilistica di X su Y. La terminologia delle relazioni all’interno del grafo è importante: il nodo di origine di una freccia è chiamato “genitore”, mentre il nodo di destinazione è detto “figlio”. Quando è possibile raggiungere un nodo B partendo da un nodo A seguendo una successione di frecce, A è definito “antenato” di B, e B è considerato “discendente” di A.\nI DAG consentono di distinguere chiaramente tra cause dirette e indirette. Una causa diretta è rappresentata da un nodo genitore, mentre una causa indiretta può essere qualsiasi antenato di un nodo nel grafo causale. Questa struttura permette di differenziare efficacemente causa ed effetto basandosi sulla posizione relativa dei nodi all’interno del grafo, ovvero se un nodo è antenato o discendente di un altro.\nQuesti grafi sono particolarmente utili per identificare variabili confondenti, basandosi sulla teoria sviluppata da Judea Pearl (Pearl, 2009). È cruciale rappresentare in un DAG tutte le possibili relazioni causali, poiché l’assenza di una freccia tra due nodi implica la certezza dell’assenza di una relazione causale diretta tra le variabili corrispondenti.\nNella teoria dei DAG, due concetti fondamentali sono la d-separazione e il criterio del back-door.\n\n22.7.1 La d-separazione\nLa d-separazione ci aiuta a determinare quando due variabili in un grafo causale sono indipendenti condizionatamente a un insieme di altre variabili. Questo concetto è cruciale per comprendere come l’informazione o l’influenza si propaga tra le variabili in un modello causale.\nIn termini più semplici, la d-separazione ci permette di identificare se esiste un “blocco” nel flusso di informazioni tra due variabili, dato un certo insieme di altre variabili (che chiameremo Λ). Quando due variabili sono d-separate da Λ, significa che non c’è flusso di informazioni tra di loro, condizionatamente a Λ.\nPer comprendere meglio la d-separazione, consideriamo tre situazioni principali che possono verificarsi in un DAG:\n\nCatena (X → Z → Y): In questo caso, Z è un mediatore tra X e Y. Se Z appartiene all’insieme Λ (cioè, se controlliamo o condizioniamo su Z), blocchiamo il flusso di informazioni da X a Y attraverso questo percorso. Per esempio, se X è “esercizio fisico”, Z è “pressione sanguigna” e Y è “rischio di malattie cardiache”, controllando per la pressione sanguigna (Z) blocchiamo il percorso attraverso il quale l’esercizio fisico influenza il rischio di malattie cardiache.\nFork (X ← Z → Y): Qui, Z è una causa comune sia di X che di Y. Se Z appartiene a Λ, blocchiamo la correlazione spuria tra X e Y che deriva dalla loro causa comune. Per esempio, se Z è “status socioeconomico”, X è “livello di istruzione” e Y è “stato di salute”, controllando per lo status socioeconomico (Z) eliminiamo la correlazione apparente tra istruzione e salute che potrebbe derivare dal fatto che entrambe sono influenzate dallo status socioeconomico.\nCollider (X → Z ← Y): In questa situazione, Z è un effetto comune di X e Y. Sorprendentemente, se né Z né i suoi discendenti appartengono a Λ, il percorso è già bloccato. Controllare per Z (o i suoi discendenti) in realtà aprirebbe un percorso tra X e Y, creando una correlazione spuria. Per esempio, se X è “intelligenza”, Y è “bellezza” e Z è “successo in una carriera di attore”, controllare per il successo nella carriera di attore (Z) creerebbe una correlazione apparente tra intelligenza e bellezza, anche se queste potrebbero essere indipendenti nella popolazione generale.\n\nIn sintesi, la d-separazione ci permette di determinare, dato un certo insieme di variabili Λ, se due variabili X e Y sono indipendenti condizionatamente a Λ. Questo ci aiuta a identificare quali variabili dobbiamo controllare (e quali non dobbiamo controllare) per ottenere stime causali non distorte, facilitando così l’inferenza causale corretta. La d-separazione è quindi uno strumento potente che ci permette di leggere le indipendenze condizionali direttamente dal grafo, senza dover fare calcoli probabilistici complessi.\n\n\n22.7.2 Il criterio del back-door\nIl criterio del back-door consente di identificare un insieme di variabili che, se controllate adeguatamente, permettono di stimare gli effetti causali in modo non distorto. L’obiettivo principale di questo criterio è eliminare l’influenza di percorsi non causali tra la variabile di esposizione (causa potenziale) e l’outcome (effetto), mantenendo aperto solo il percorso causale diretto di interesse.\nIn questo contesto, due variabili sono considerate “confuse” se esiste tra di esse un percorso di tipo back-door. Un back-door path da X a Y è definito come qualsiasi percorso che inizia da X con una freccia entrante in X. Per esempio, consideriamo il seguente percorso:\nX ← A → B ← C → Y\nIn questo caso, il percorso rappresenta un flusso di informazioni da X a Y che non è causale, ma potrebbe creare l’apparenza di una relazione causale.\nPer “deconfondere” una coppia di variabili, è necessario selezionare un insieme di variabili (chiamato back-door set) che “blocchi” tutti i back-door paths tra i due nodi di interesse. Il blocco di questi percorsi avviene in modi diversi a seconda della struttura del percorso:\n\nUn back-door path che coinvolge una catena di variabili (ad esempio, A → B → C) può essere bloccato controllando per la variabile intermedia (in questo caso, B).\nUn percorso che coinvolge un “collider” (una variabile che riceve frecce da entrambe le direzioni, come in A → B ← C) è naturalmente bloccato e non permette il flusso di informazioni.\n\nÈ importante notare che bisogna prestare attenzione a non aprire involontariamente un flusso di informazioni attraverso un collider. Questo può accadere se si condiziona l’analisi sul collider stesso o su un suo discendente, il che potrebbe erroneamente aprire il percorso e introdurre bias nell’analisi.\n\n\n\n\n\n\nPunti chiave\n\n\n\n\nIl criterio del back-door aiuta a identificare il set minimale di variabili da controllare.\nNon tutte le variabili associate sia all’esposizione che all’outcome devono essere controllate; solo quelle che creano percorsi back-door.\nIn alcuni casi, potrebbe non essere necessario controllare alcuna variabile (se non ci sono percorsi back-door aperti).\nIn altri casi, potrebbe essere impossibile bloccare tutti i percorsi back-door con le variabili disponibili, indicando che l’effetto causale non può essere identificato con i dati a disposizione.\n\nUtilizzando il criterio del back-door in combinazione con i DAG, i ricercatori possono fare scelte più informate su quali variabili includere nelle loro analisi, migliorando così la validità delle loro inferenze causali.\n\n\n\n\n22.7.3 Applicazioni\nConsideriamo nuovamente la struttura causale illustrata nella Figura 22.1, pannello centrale. Dopo aver costruito un DAG come descritto nella sezione precedente, è possibile identificare le potenziali fonti di bias da variabili omesse, inclusi i confondenti non misurati (ad esempio, U). Non controllare per le variabili confondenti apre una “back-door” permettendo alla variazione confondente di influenzare la relazione tra la variabile causale e la variabile di risposta di interesse attraverso un percorso non valutato (Pearl, 2009). In altre parole, omettere una variabile confondente come U nella Figura 22.1 (pannello centrale) in un’analisi statistica significa che questa viene incorporata nel termine di errore del modello statistico, insieme alle fonti di errore casuali. La Figura 22.2 illustra le conseguenze di un confondente U che ha un effetto positivo su X ma un effetto negativo su Y. Se adattiamo un modello come mostrato nella Figura 22.2 bi, l’effetto stimato di X su Y è positivo quando si controlla per U. Tuttavia, se non si controlla per U, come mostrato nella Figura 22.2 bii, U viene incorporato nel termine di errore, inducendo una correlazione tra l’errore e X, come illustrato nella Figura 22.2 biii, portando a una stima errata. Pertanto, il termine di errore del modello e X risultano correlati, il che viola un’assunzione fondamentale dei modelli lineari (ovvero, il teorema di Gauss-Markov; Abdallah et al., 2015; Antonakis et al., 2010). Questo produce una stima errata, evidenziata in blu.\n\n\n\n\n\n\nFigura 22.2: Una visualizzazione del bias da variabile omessa e delle conseguenze per l’inferenza causale. (A) mostra un DAG di un sistema in cui X ha un effetto positivo su Y, e una variabile confondente U ha un effetto positivo su Y ma un effetto negativo su X. Le variabili non osservate (cioè non misurate) sono rappresentate in ellissi, come la variabile U e il termine di errore e nel pannello B. (B) illustra diverse stime del DAG in (A) utilizzando un’analisi del percorso. Vedi Box 1 per una breve spiegazione delle principali differenze tra DAG e diagrammi dei percorsi. Presumiamo che U non sia misurata. In (Bi), presumiamo di poter misurare e controllare U, rappresentata dalla freccia a doppia testa tra U e X, che rappresenta la correlazione tra le due variabili considerata dal modello. La variabile non misurata e è la fonte residua di variazione che si presume non sia correlata con nessun predittore. La freccia rossa rappresenta il percorso stimato. Al contrario, (Bii) e (Biii) rappresentano la realtà, dove non abbiamo una misurazione di U e non la controlliamo nel modello dei percorsi. Il ricercatore pensa di adattare il modello in (Bii) ma in realtà sta adattando il modello in (Biii), dove il termine di errore non è solo e, ma la somma di e e la variazione dovuta alla variabile omessa U. A causa di ciò, c’è un percorso diretto dal termine di errore del modello a X (e quindi X è endogeno). (C) mostra le relazioni stimate risultanti dai modelli in (Bi) rispetto a (Bii). Le linee rappresentano la relazione stimata tra X e Y dai rispettivi modelli. La linea rossa è la vera relazione causale, stimata da (Bi), mentre la linea blu contiene il bias da variabile omessa, poiché non si tiene conto della variabile confondente U, come stimato dal modello in Bii/Biii (Figura tratta da Byrnes & Dee (2024)).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Causalità dai dati osservazionali 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#commenti-e-considerazioni-finali",
    "href": "chapters/eda/09_causality.html#commenti-e-considerazioni-finali",
    "title": "22  Causalità dai dati osservazionali 🔸",
    "section": "22.8 Commenti e Considerazioni Finali",
    "text": "22.8 Commenti e Considerazioni Finali\nI diagrammi causali sono uno dei primi strumenti per identificare il bias da variabili omesse (Pearl, 1995; Pearl et al., 2016). I diagrammi causali, sotto forma di DAG, visualizzano la nostra comprensione delle relazioni causali e delle variabili confondenti all’interno di un sistema. In questo modo, i DAG chiariscono in modo trasparente le assunzioni dietro le affermazioni causali derivate dai dati e mostrano le potenziali fonti di bias derivanti da variabili confondenti.\nÈ fondamentale che i DAG includano tutte le cause comuni di un predittore e della risposta di interesse, comprendendo tutte le variabili confondenti misurate e non misurate. Questo significa che l’inferenza causale è possibile solo quando il ricercatore dispone di adeguate conoscenze del dominio.\nDopo aver costruito un DAG, è possibile determinare le potenziali fonti di bias da variabili omesse, incluse quelle derivanti da variabili confondenti non misurate (es., U nella figura fig-byrnes-dee-1, pannello centrale). Non controllare le variabili confondenti apre una “back-door” per la variazione confondente, permettendo a quest’ultima di fluire tra la variabile causale e la variabile di risposta di interesse attraverso un percorso non valutato (Pearl, 2009).\nPertanto, un diagramma causale è un primo passo fondamentale per identificare potenziali bias da variabili omesse. I DAG giustificano anche la scelta delle variabili di controllo, rendendo trasparenti le assunzioni che un ricercatore fa su come funziona il sistema oggetto di studio.\nÈ importante notare che i DAG possono essere incorretti o non includere variabili confondenti sconosciute. Infatti, un DAG rappresenta solo la comprensione attuale e le assunzioni del ricercatore riguardo alle relazioni causali all’interno di un sistema.\nUn sommario ironico di questi concetti è fornito nella vignetta di xkcd.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Causalità dai dati osservazionali 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#bibliografia",
    "href": "chapters/eda/09_causality.html#bibliografia",
    "title": "22  Causalità dai dati osservazionali 🔸",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAlexander, R. (2023). Telling Stories with Data: With Applications in R. Chapman; Hall/CRC.\n\n\nByrnes, J. E., & Dee, L. E. (2024). Causal inference with observational data and unobserved confounding variables. bioRxiv, 2024–2002.\n\n\nHardt, M., & Recht, B. (2022). Patterns, Predictions, and Actions: Foundations of Machine Learning. Princeton University Press.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nPearl, J. (1995). Causal diagrams for empirical research. Biometrika, 82(4), 669–688.\n\n\nPearl, J. (2009). Causality. Cambridge University Press.\n\n\nPearl, J., Glymour, M., & Jewell, N. P. (2016). Causal inference in statistics: A primer. John Wiley & Sons.\n\n\nRiederer, E. (2021). Causal design patterns for data analysts. https://emilyriederer.netlify.app/post/causal-design-patterns/\n\n\nSchennach, S. M. (2016). Recent advances in the measurement error literature. Annual Review of Economics, 8(1), 341–377.\n\n\nWilms, R., Mäthner, E., Winnen, L., & Lanwehr, R. (2021). Omitted variable bias: A threat to estimating causal relationships. Methods in Psychology, 5, 100075.\n\n\nZwet, E. van, Gelman, A., Greenland, S., Imbens, G., Schwab, S., & Goodman, S. N. (2023). A New Look at P Values for Randomized Clinical Trials. NEJM Evidence, 3(1), EVIDoa2300003.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Causalità dai dati osservazionali 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html",
    "href": "chapters/eda/10_estimand.html",
    "title": "23  Estimandi teorici e estimandi empirici 🔸",
    "section": "",
    "text": "23.1 Introduzione\nNei capitoli precedenti abbiamo illustrato diverse tecniche di analisi esplorativa dei dati, utili per sintetizzare ampie quantità di informazioni, rappresentare le distribuzioni delle variabili e descriverne le relazioni. In tali esempi, abbiamo dato per scontato che le variabili fossero state misurate correttamente con lo scopo di rispondere a una determinata domanda teorica. È però fondamentale interrogarsi sul legame tra le quantità che vogliamo stimare (estimandi) e la teoria che guida lo studio. Per approfondire questo aspetto, esamineremo l’articolo di Lundberg et al. (2021), “What Is Your Estimand? Defining the Target Quantity Connects Statistical Evidence to Theory”, che mette in luce quanto sia importante definire con precisione l’estimando chiave di una ricerca.\nL’estimando è la quantità che uno studio intende stimare e rappresenta il ponte tra la teoria e l’evidenza statistica. Gli autori suggeriscono un approccio metodologico in tre fasi:\nQuesto approccio consente di chiarire come le informazioni ottenute dai dati rispondano a una ben precisa domanda teorica. In breve, Lundberg et al. (2021) invitano i ricercatori a definire l’estimando teorico in modo indipendente dai modelli statistici impiegati, così da evidenziare il nesso logico fra teoria ed evidenza empirica.\nIn altre parole, non basta limitarsi a verificare se un coefficiente di regressione è “significativamente diverso da zero” basandosi solo sul modello statistico. È necessario distinguere l’obiettivo teorico della ricerca (ad esempio, studiare l’apprendimento associativo) dal modo in cui questo obiettivo viene tradotto in una misura osservabile. Un esempio concreto è fornito dal modello di Rescorla-Wagner, applicato a compiti di Probabilistic Reversal Learning (PRL): l’estimando empirico potrebbe corrispondere a parametri come il tasso di apprendimento \\(\\alpha\\) o la temperatura inversa \\(\\beta\\). Questi parametri riflettono quanto i partecipanti modifichino i valori associati agli stimoli o regolino la strategia di scelta (esplorazione rispetto a sfruttamento), come descritto nella sezione ?sec-rescorla-wagner.\nÈ importante notare che l’estimando empirico può essere stimato in modi diversi, utilizzando modelli, metodi di stima e disegni sperimentali vari. Il modello di Rescorla-Wagner è solo una possibile rappresentazione dell’apprendimento associativo, e i suoi parametri possono essere ricavati con procedure differenti. Di conseguenza, il valore numerico che descrive la capacità di apprendimento associativo dipende dal modello, dalla tecnica di stima e dal contesto sperimentale.\nIn conclusione, Lundberg et al. (2021) sottolineano l’importanza di definire l’estimando teorico prima di qualsiasi analisi, e di giustificare in modo chiaro la scelta dello specifico estimando empirico e della strategia di stima adottata. Così facendo, si evidenzia il legame tra teoria e dati, rendendo più trasparenti, coerenti e riproducibili i processi di inferenza statistica.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Estimandi teorici e estimandi empirici 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#introduzione",
    "href": "chapters/eda/10_estimand.html#introduzione",
    "title": "23  Estimandi teorici e estimandi empirici 🔸",
    "section": "",
    "text": "Definire un estimando teorico, collegato esplicitamente alla teoria che guida la ricerca.\nTradurre l’estimando teorico in un estimando empirico, cioè una misura concreta, ottenuta dai dati osservabili, che richiede l’adozione di specifiche assunzioni di identificazione.\nStimare l’estimando empirico utilizzando procedure statistiche appropriate, in modo da ricavare inferenze solide a partire dai dati.\n\n\n\n\n\n\n\n\n\n\n\nIn italiano, la traduzione comunemente usata di “estimand” nella letteratura scientifica è estimando. Questo termine viene utilizzato per riferirsi alla quantità o al parametro che si desidera stimare in un’analisi statistica.\nStimatore, invece, è la traduzione di “estimator” e si riferisce alla regola o alla funzione utilizzata per calcolare una stima basata sui dati osservati. Quindi, “estimando” e “stimatore” sono termini distinti: l’“estimando” è l’oggetto dell’inferenza statistica, mentre lo “stimatore” è il metodo o la formula usata per ottenere l’inferenza.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Estimandi teorici e estimandi empirici 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#limiti-dellapproccio-attuale",
    "href": "chapters/eda/10_estimand.html#limiti-dellapproccio-attuale",
    "title": "23  Estimandi teorici e estimandi empirici 🔸",
    "section": "23.2 Limiti dell’Approccio Attuale",
    "text": "23.2 Limiti dell’Approccio Attuale\nLundberg et al. (2021) osservano che spesso i ricercatori sociali omettono il passaggio cruciale della definizione dell’estimando, concentrandosi direttamente sui dati e sulle procedure statistiche. Questo approccio può causare una mancanza di chiarezza riguardo a ciò che si intende effettivamente stimare, limitando anche l’uso di modelli statistici alternativi che potrebbero essere più adatti a rispondere alla domanda di ricerca. Sebbene Lundberg et al. (2021) facciano riferimento alla letteratura sociologica, questi stessi argomenti sono applicabili anche alla psicologia.\nIl problema del collegamento tra estimandi teorici ed empirici (si veda la figura seguente) può essere illustrato con un esempio in psicologia riguardante l’intelligenza. La distinzione tra estimandi teorici ed empirici è cruciale: gli estimandi teorici possono includere quantità non osservabili, come i costrutti latenti, ad esempio l’intelligenza come concetto astratto. Gli estimandi empirici, invece, riguardano esclusivamente dati osservabili, come i punteggi ottenuti in un test di intelligenza.\nNel caso dell’intelligenza, la scelta dell’estimando teorico richiede un’argomentazione sostanziale riguardo alla teoria dell’intelligenza adottata e agli obiettivi della ricerca. Ad esempio, se si vuole studiare l’intelligenza generale (fattore g), bisogna chiarire come questo costrutto viene teoricamente definito e perché è rilevante per lo studio.\nD’altra parte, la scelta dell’estimando empirico richiede un’argomentazione concettuale su come i dati osservabili, come i risultati dei test di intelligenza, possano rappresentare il costrutto latente di interesse. È necessario spiegare quali dati vengono utilizzati per inferire il costrutto teorico e quali assunzioni si fanno riguardo al rapporto tra le misure osservate e il costrutto latente.\nInfine, la scelta delle strategie di stima, come l’uso di modelli di equazioni strutturali per stimare l’intelligenza generale da diversi test, è una decisione separata, che può essere in parte guidata dai dati disponibili e dalle caratteristiche della misurazione. Separare chiaramente questi passaggi aiuta i ricercatori a fare scelte informate e fondate, consente ai lettori di valutare in modo critico le affermazioni fatte e permette alla comunità scientifica di costruire su basi solide per futuri sviluppi della ricerca.\n\n\n\nTre Scelte Critiche nelle Argomentazioni delle Scienze Sociali Quantitative. La prima scelta riguarda gli estimandi teorici, che definiscono gli obiettivi dell’inferenza. È necessario un argomento che colleghi gli estimandi teorici alla teoria più ampia. La seconda scelta riguarda gli estimandi empirici, che collegano questi obiettivi ai dati osservabili. Questo collegamento richiede delle assunzioni sostanziali, che possono essere formalizzate attraverso grafici aciclici diretti. La terza scelta riguarda le strategie di stima, che determinano come verranno effettivamente utilizzati i dati. La selezione delle strategie di stima si basa sui dati disponibili (figura tratta da Lundberg et al. (2021)).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Estimandi teorici e estimandi empirici 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#definizione-dellestimando-teorico",
    "href": "chapters/eda/10_estimand.html#definizione-dellestimando-teorico",
    "title": "23  Estimandi teorici e estimandi empirici 🔸",
    "section": "23.3 Definizione dell’Estimando Teorico",
    "text": "23.3 Definizione dell’Estimando Teorico\nLa definizione dell’estimando teorico è cruciale per determinare la natura dello studio perché specifica chiaramente quale tipo di relazione tra le variabili stiamo cercando di indagare. In altre parole, l’estimando teorico indica se lo studio mira a descrivere, prevedere o stabilire una relazione causale. Vediamo come questo funziona in pratica con esempi legati all’intelligenza e all’allenamento cognitivo.\n\n23.3.1 Estimando Teorico in uno Studio Descrittivo\nUno studio descrittivo ha come obiettivo semplicemente quello di caratterizzare o descrivere una certa realtà o fenomeno senza inferire relazioni di causa-effetto. In questo caso, l’estimando teorico potrebbe essere una misura che riassume una caratteristica della popolazione.\nEsempio: Qual è il punteggio medio di intelligenza tra le persone che hanno partecipato a un programma di allenamento cognitivo rispetto a quelle che non l’hanno fatto?\nEstimando Teorico: La differenza media nei punteggi di intelligenza tra i due gruppi. Questo tipo di estimando descrive la distribuzione dei punteggi di intelligenza nei gruppi, ma non implica che l’allenamento abbia causato le differenze osservate.\n\n\n23.3.2 Estimando Teorico in uno Studio Predittivo\nUno studio predittivo si concentra sulla capacità di prevedere un risultato basato su dati osservabili. Qui, l’estimando teorico riguarda la capacità del modello di predire correttamente i risultati futuri, ma senza implicazioni causali.\nEsempio: In che misura la partecipazione a un programma di allenamento cognitivo può prevedere il punteggio di intelligenza futuro di una persona?\nEstimando Teorico: La previsione del punteggio di intelligenza basata sulla partecipazione all’allenamento cognitivo. Questo estimando si basa su modelli statistici che utilizzano variabili osservabili per fare previsioni, ma non determinano la causalità tra allenamento e punteggi di intelligenza.\n\n\n23.3.3 Estimando Teorico in uno Studio Causale\nUno studio causale cerca di stabilire un nesso diretto di causa-effetto tra variabili. L’estimando teorico in questo caso riguarda l’effetto diretto di una variabile indipendente su una variabile dipendente, tenendo conto di altre variabili confondenti.\nEsempio: L’allenamento cognitivo causa un aumento nei punteggi di intelligenza?\nEstimando Teorico: La differenza media nei punteggi di intelligenza che si attribuisce direttamente all’effetto dell’allenamento cognitivo, controllando per tutte le altre variabili confondenti. Questo estimando implica l’uso di un disegno di ricerca che isola l’effetto dell’allenamento, come un esperimento con assegnazione casuale.\n\n\n23.3.4 L’Estimando Teorico Chiarisce la Natura dello Studio\nDefinire l’estimando teorico in modo preciso aiuta a chiarire la natura dello studio perché specifica esattamente quale relazione tra le variabili viene studiata:\n\nStudi Descrittivi: L’estimando teorico è una semplice descrizione di dati, come una media o una differenza, senza inferire causalità.\nStudi Predittivi: L’estimando teorico si concentra sulla capacità di un modello di fare previsioni basate sui dati, senza implicazioni causali.\nStudi Causali: L’estimando teorico cerca di determinare l’effetto diretto di una variabile su un’altra, richiedendo un disegno di studio che possa controllare variabili confondenti per isolare la causalità.\n\nIn sintesi, l’estimando teorico orienta il ricercatore nel definire chiaramente se lo scopo dello studio è descrittivo, predittivo o causale, e guida il disegno dello studio e l’analisi dei dati di conseguenza.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Estimandi teorici e estimandi empirici 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#importanza-dei-dag-nel-contesto-degli-estimandi-teorici",
    "href": "chapters/eda/10_estimand.html#importanza-dei-dag-nel-contesto-degli-estimandi-teorici",
    "title": "23  Estimandi teorici e estimandi empirici 🔸",
    "section": "23.4 Importanza dei DAG nel Contesto degli Estimandi Teorici",
    "text": "23.4 Importanza dei DAG nel Contesto degli Estimandi Teorici\nNella figura 2 dell’articolo di Lundberg et al. (2021), i Grafici Aciclici Diretti (DAG) vengono utilizzati per illustrare le relazioni causali tra variabili all’interno di uno studio. I DAG sono strumenti visivi che aiutano i ricercatori a rappresentare e comprendere le assunzioni causali sottostanti ai loro studi, fornendo una chiara rappresentazione grafica di come le variabili si influenzano a vicenda. Questo è particolarmente importante quando si definiscono estimandi teorici, perché i DAG consentono di identificare chiaramente le variabili confondenti e di stabilire le relazioni di causalità.\nI DAG possono contribuire alla definizione degli estimandi teorici in molti modi.\n\nChiarificazione delle Relazioni Causali: I DAG aiutano a chiarire quali variabili sono considerate come cause potenziali e quali come effetti. Questo è fondamentale per definire l’estimando teorico, soprattutto in uno studio causale, dove è importante distinguere tra correlazione e causalità. Ad esempio, se si studia l’effetto dell’allenamento cognitivo sull’intelligenza, un DAG può mostrare come l’allenamento influisce direttamente sull’intelligenza, identificando al contempo variabili confondenti come il background educativo o la motivazione.\nIdentificazione delle Variabili Confondenti: Uno dei principali vantaggi dell’utilizzo dei DAG è la loro capacità di identificare le variabili confondenti che possono influenzare entrambe le variabili di interesse. Nel contesto degli estimandi teorici, riconoscere e controllare queste variabili confondenti è cruciale per stabilire una relazione causale valida. Ad esempio, un DAG potrebbe rivelare che la motivazione personale influisce sia sulla partecipazione all’allenamento cognitivo che sui punteggi di intelligenza, indicando che questa variabile deve essere controllata per ottenere un estimando causale corretto.\nGuida nella Costruzione del Disegno di Ricerca: I DAG sono strumenti utili nella pianificazione del disegno di ricerca perché aiutano a determinare quali variabili devono essere misurate e controllate. Definendo chiaramente le relazioni tra le variabili, i ricercatori possono progettare esperimenti o studi osservazionali che minimizzano i bias e migliorano la validità interna dello studio. Ad esempio, un DAG può suggerire la necessità di randomizzare l’assegnazione all’allenamento cognitivo per garantire che l’effetto osservato sui punteggi di intelligenza sia realmente causato dall’allenamento e non da un’altra variabile.\nSupporto nella Selezione delle Strategie di Stima: Una volta definite le relazioni tra le variabili attraverso un DAG, i ricercatori possono scegliere strategie di stima appropriate per gli estimandi teorici ed empirici. Per esempio, se un DAG indica che non ci sono percorsi diretti tra alcune variabili, si possono utilizzare metodi statistici che presuppongono l’indipendenza condizionale, come la regressione lineare o i modelli di equazioni strutturali.\n\nIn sintesi, nel contesto della definizione degli estimandi teorici, i DAG sono strumenti essenziali che consentono ai ricercatori di visualizzare e comprendere le relazioni causali e le variabili confondenti all’interno di uno studio. Essi facilitano la costruzione di disegni di ricerca solidi, la selezione di strategie di stima appropriate e la comunicazione chiara delle assunzioni causali sottostanti. Utilizzando i DAG, i ricercatori possono garantire che gli estimandi teorici siano ben definiti e che le inferenze tratte dai dati siano valide e affidabili.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Estimandi teorici e estimandi empirici 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#collegamento-tra-estimando-teorico-ed-empirico",
    "href": "chapters/eda/10_estimand.html#collegamento-tra-estimando-teorico-ed-empirico",
    "title": "23  Estimandi teorici e estimandi empirici 🔸",
    "section": "23.5 Collegamento tra Estimando Teorico ed Empirico",
    "text": "23.5 Collegamento tra Estimando Teorico ed Empirico\nLundberg et al. (2021) sottolineano l’importanza di collegare chiaramente l’estimando teorico all’estimando empirico, utilizzando assunzioni sostanziali e metodi appropriati per garantire che le conclusioni tratte dai dati siano valide.\nEstimando Empirico: L’estimando empirico è la quantità che viene effettivamente calcolata dai dati osservati. Mentre l’estimando teorico rappresenta l’obiettivo concettuale dello studio (come l’effetto dell’allenamento cognitivo sull’intelligenza), l’estimando empirico è ciò che viene effettivamente misurato nel contesto dei dati disponibili.\nPer tradurre un estimando teorico in uno empirico, è essenziale formulare assunzioni che rendano possibile l’inferenza causale. Queste assunzioni possono essere formalizzate attraverso l’uso dei Grafici Aciclici Diretti (DAG) per garantire che le variabili confondenti siano adeguatamente controllate. L’identificazione corretta assicura che le conclusioni derivate dai dati osservati siano valide rispetto all’effetto causale che si sta cercando di stimare.\nConsideriamo uno studio psicologico sull’effetto dell’allenamento cognitivo sui punteggi di intelligenza:\n\nEstimando Teorico: Il nostro obiettivo teorico potrebbe essere stimare l’effetto causale dell’allenamento cognitivo sull’aumento del punteggio di intelligenza in una popolazione adulta. L’estimando teorico qui sarebbe la differenza media nei punteggi di intelligenza tra gli individui che hanno partecipato all’allenamento e quelli che non lo hanno fatto, supponendo che l’unica differenza tra i gruppi sia l’allenamento stesso.\nEstimando Empirico: Per passare all’estimando empirico, dobbiamo considerare cosa possiamo effettivamente misurare. Supponiamo di avere dati da un campione di adulti, alcuni dei quali hanno partecipato all’allenamento cognitivo e altri no. L’estimando empirico potrebbe essere la differenza osservata nei punteggi di intelligenza tra questi due gruppi nel campione disponibile.\nAssunzioni per l’Identificazione:\n\nAssunzione di Nessuna Confusione (No Confounding): Dobbiamo assumere che non vi siano variabili non misurate che influenzano sia la partecipazione all’allenamento che i punteggi di intelligenza. Per esempio, la motivazione personale potrebbe influenzare sia la decisione di partecipare all’allenamento che il punteggio di intelligenza. Se questa variabile non è controllata, l’estimando empirico potrebbe sovrastimare o sottostimare l’effetto dell’allenamento.\nAssunzione di Non-Interferenza (Stable Unit Treatment Value Assumption, SUTVA): Dobbiamo assumere che la partecipazione di un individuo all’allenamento non influisca sui punteggi di intelligenza di altri individui. Questa assunzione potrebbe essere violata, ad esempio, se i partecipanti condividono tecniche apprese con amici che non hanno partecipato.\n\nUtilizzo dei DAG per la Chiarificazione:\n\nUn DAG può aiutare a visualizzare queste assunzioni mostrando le relazioni tra le variabili. In un DAG ben costruito, l’allenamento cognitivo influenzerebbe direttamente il punteggio di intelligenza, mentre altre variabili come l’educazione o la motivazione sarebbero rappresentate come confondenti da controllare. Se il DAG indica che ci sono variabili confondenti che non possiamo osservare o misurare, dovremo usare metodi statistici specifici, come i modelli di equazioni strutturali o l’uso di variabili strumentali, per isolare l’effetto dell’allenamento cognitivo.\n\n\nIn sintesi, collegare correttamente l’estimando teorico a uno empirico è un passo cruciale per garantire la validità delle inferenze causali in uno studio. Utilizzando l’esempio relativo all’effetto dell’allenamento cognitivo sull’intelligenza, possiamo vedere come le assunzioni sostanziali e gli strumenti come i DAG siano essenziali per identificare correttamente le relazioni causali e assicurare che i risultati siano interpretabili in modo affidabile.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Estimandi teorici e estimandi empirici 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#dedurre-lestimando-empirico-dai-dati-osservati",
    "href": "chapters/eda/10_estimand.html#dedurre-lestimando-empirico-dai-dati-osservati",
    "title": "23  Estimandi teorici e estimandi empirici 🔸",
    "section": "23.6 Dedurre l’Estimando Empirico dai Dati Osservati",
    "text": "23.6 Dedurre l’Estimando Empirico dai Dati Osservati\nDopo aver chiaramente definito l’estimando teorico e stabilito il collegamento con l’estimando empirico attraverso l’identificazione, il passo successivo è utilizzare tecniche statistiche per ottenere stime valide dai dati raccolti.\nRiprendiamo l’esempio psicologico sull’effetto dell’allenamento cognitivo sui punteggi di intelligenza per illustrare come l’approccio bayesiano può essere utilizzato per stimare l’estimando empirico:\n\nDefinizione dell’Estimando Empirico:\n\nL’estimando empirico in questo contesto è la differenza media nei punteggi di intelligenza tra il gruppo di individui che ha partecipato all’allenamento cognitivo e il gruppo che non ha partecipato.\n\nStrategie di Stima Appropriate:\n\nRegressione Lineare: Se ipotizziamo che i punteggi di intelligenza dipendano linearmente dalla partecipazione all’allenamento cognitivo e da altre variabili confondenti controllate, potremmo utilizzare una regressione lineare per stimare l’effetto dell’allenamento. In questa regressione, la partecipazione all’allenamento sarebbe una variabile indipendente, e i punteggi di intelligenza la variabile dipendente.\nMatching: Se i dati disponibili includono molte variabili confondenti misurate, potremmo utilizzare una tecnica di matching per creare coppie di individui simili (matchati) tra i gruppi di trattamento e controllo, basati su queste variabili. Questo metodo aiuta a bilanciare le differenze tra i gruppi che potrebbero influenzare i risultati, cercando di rendere le stime dell’effetto più affidabili.\nPropensity Score Matching: Invece di confrontare direttamente individui basandosi su caratteristiche osservabili, possiamo calcolare un punteggio di propensione per ciascun individuo, che rappresenta la probabilità di partecipare all’allenamento in base alle covariate osservate. Gli individui con punteggi di propensione simili vengono quindi confrontati, aiutando a controllare per le variabili confondenti.\nModelli di Equazioni Strutturali (SEM): Se ci sono molteplici relazioni tra variabili latenti e osservate, un modello di equazioni strutturali può essere utilizzato per stimare simultaneamente questi effetti complessi e isolare l’effetto diretto dell’allenamento cognitivo sui punteggi di intelligenza.\nRandomizzazione: In un disegno sperimentale ideale, l’assegnazione casuale dell’allenamento cognitivo elimina l’influenza delle variabili confondenti, permettendo una stima non distorta dell’effetto causale. Se i dati derivano da un esperimento randomizzato, potremmo semplicemente confrontare le medie dei due gruppi.\n\nInterpreting the Results:\n\nStime Non Distorte: Utilizzando la strategia di stima appropriata, possiamo ottenere una stima non distorta dell’effetto dell’allenamento cognitivo sui punteggi di intelligenza. Ad esempio, se utilizziamo una regressione lineare e controlliamo correttamente per tutte le variabili confondenti, l’effetto stimato rappresenterà l’effetto causale dell’allenamento.\n\n\nLa fase di stima è cruciale per trasformare i dati osservati in stime valide dell’estimando empirico. Nel contesto psicologico dell’allenamento cognitivo e dell’intelligenza, la scelta della strategia di stima appropriata dipende dalle assunzioni fatte sulla causalità e dalla natura dei dati disponibili. Utilizzando tecniche come la regressione, il matching, o i modelli di equazioni strutturali, i ricercatori possono ottenere stime precise e affidabili, garantendo che le conclusioni tratte siano valide e scientificamente robuste.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Estimandi teorici e estimandi empirici 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#implicazioni-per-la-ricerca",
    "href": "chapters/eda/10_estimand.html#implicazioni-per-la-ricerca",
    "title": "23  Estimandi teorici e estimandi empirici 🔸",
    "section": "23.7 Implicazioni per la Ricerca",
    "text": "23.7 Implicazioni per la Ricerca\nLundberg et al. (2021) sottolineano l’importanza di una chiara comunicazione e dell’uso del framework presentato per migliorare la pratica della ricerca quantitativa.\n\n23.7.1 Importanza della Trasparenza e della Chiarezza nella Ricerca\nGli autori sottolineano che per garantire la validità e la replicabilità dei risultati di ricerca, è fondamentale che i ricercatori siano trasparenti e chiari su tutte le fasi del loro lavoro. Questo significa esplicitare le assunzioni fatte, il modo in cui l’estimando teorico è stato tradotto in un estimando empirico, e come i dati sono stati analizzati.\nPer esempio, in uno studio sull’effetto di una terapia cognitivo-comportamentale (CBT) sui livelli di ansia, è essenziale che i ricercatori definiscano chiaramente l’estimando teorico, ad esempio, “l’effetto medio della CBT sulla riduzione dell’ansia nella popolazione target di adulti con disturbo d’ansia generalizzato”. Devono poi descrivere come questo estimando è stato misurato empiricamente, ad esempio, utilizzando questionari standardizzati per l’ansia prima e dopo l’intervento. Infine, devono spiegare le assunzioni fatte e le tecniche utilizzate per l’analisi dei dati, come un modello bayesiano per gestire la variabilità individuale nella risposta alla terapia.\n\n\n23.7.2 Benefici dell’Utilizzo di Estimandi Chiaramente Definiti\nL’articolo discute come l’uso di estimandi chiaramente definiti può migliorare la comprensione dei risultati e facilitare il confronto tra studi diversi. Quando i ricercatori definiscono in modo preciso ciò che stanno stimando, diventa più facile per altri replicare lo studio, confrontare risultati e costruire un corpus di conoscenza cumulativo.\nPer esempio, consideriamo due studi sull’efficacia di diversi tipi di training di memoria per migliorare le funzioni cognitive negli anziani. Se entrambi gli studi definiscono chiaramente il loro estimando teorico (ad esempio, “l’effetto del training di memoria verbale sul punteggio del test di memoria a lungo termine”) e empirico (ad esempio, “la differenza media nei punteggi del test di memoria tra il gruppo che ha ricevuto il training e un gruppo di controllo”), sarà più semplice confrontare i risultati e capire quale tipo di training è più efficace.\n\n\n23.7.3 Adattabilità e Flessibilità del Framework\nIl framework proposto dagli autori è adattabile a diversi contesti di ricerca, permettendo ai ricercatori di applicare questi principi in una varietà di studi quantitativi, indipendentemente dal dominio specifico.\nPer esempio, in uno studio che esplora l’effetto della privazione del sonno sulla capacità di attenzione nei bambini, il framework potrebbe essere utilizzato per definire l’estimando teorico come “l’effetto della privazione di 8 ore di sonno sulla capacità di mantenere l’attenzione in attività ripetitive”, e l’estimando empirico potrebbe essere “la differenza media nei punteggi di attenzione tra bambini che hanno dormito 8 ore e quelli che non hanno dormito”. Questo approccio garantisce che le conclusioni siano fondate su basi metodologiche solide e che altri ricercatori possano replicare lo studio per verificare i risultati.\n\n\n23.7.4 Implicazioni per la Ricerca Futura\nL’adozione del framework proposto da Lundberg et al. (2021) per la definizione degli estimandi teorici ed empirici, la chiara identificazione delle assunzioni e l’utilizzo di metodi di stima appropriati può migliorare la qualità e l’affidabilità della ricerca quantitativa nella psicologia e nelle scienze sociali. Questo approccio promuove una pratica di ricerca più rigorosa e trasparente.\nSe la comunità psicologica integrasse questo framework, studi sugli interventi psicologici, come quelli sulla terapia cognitivo-comportamentale (CBT) discusso nell’esempio sopra, potrebbero diventare più comparabili e replicabili. Ciò migliorerebbe la nostra comprensione dell’efficacia e dei limiti di tali interventi. Ad esempio, definendo chiaramente cosa si intende per “efficacia” della CBT (come la riduzione del punteggio su una scala di ansia standardizzata) e utilizzando metodi bayesiani per incorporare dati preesistenti e nuove osservazioni, è possibile ottenere stime più robuste e interpretabili. Queste stime rifletterebbero meglio l’efficacia reale della terapia nella pratica clinica.\nLe proposte di Lundberg et al. (2021) sono in linea con le raccomandazioni di altri studiosi. Andrew Gelman, ad esempio, sottolinea spesso l’importanza di definire con precisione cosa si sta cercando di stimare in un’analisi statistica. Gelman sostiene che una definizione vaga o mal definita dell’estimando teorico può portare a interpretazioni errate e conclusioni fuorvianti. La chiara definizione dell’estimando teorico, come evidenziato nell’articolo di Lundberg et al., è cruciale per determinare se uno studio è descrittivo, predittivo o causale, e per comprendere la natura dell’inferenza da trarre dai dati (Gelman & Imbens, 2013).\nSia McElreath (2020), nel suo testo “Statistical Rethinking,” sia Andrew Gelman, enfatizzano l’importanza dell’utilizzo dei Grafici Aciclici Diretti (DAG) per rappresentare visivamente le assunzioni causali e le relazioni tra variabili in un modello statistico. Questo tipo di approccio aiuta i ricercatori a identificare variabili confondenti e a chiarire le relazioni causali, migliorando così la validità delle inferenze.\nGelman discute anche frequentemente l’importanza della trasparenza nella comunicazione dei risultati di ricerca, un principio centrale anche nell’articolo di Lundberg et al. Egli insiste sul fatto che i ricercatori dovrebbero essere espliciti riguardo alle assunzioni fatte, ai metodi utilizzati e alle limitazioni dei loro studi (Gelman et al., 1995).\nIn sintesi, sia Lundberg et al. che altri ricercatori evidenziano l’importanza di una chiara definizione degli estimandi, dell’uso dei DAG per rappresentare le assunzioni causali e della scelta di strategie di stima appropriate. L’approccio bayesiano, in particolare, offre un metodo potente e flessibile per gestire l’incertezza e aggiornare le inferenze alla luce di nuove evidenze. Adottando queste pratiche, i ricercatori nelle scienze sociali e nella psicologia possono migliorare la validità, la replicabilità e la trasparenza delle loro ricerche, contribuendo a una conoscenza scientifica più solida e affidabile.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Estimandi teorici e estimandi empirici 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#riflessioni-conclusive",
    "href": "chapters/eda/10_estimand.html#riflessioni-conclusive",
    "title": "23  Estimandi teorici e estimandi empirici 🔸",
    "section": "23.8 Riflessioni Conclusive",
    "text": "23.8 Riflessioni Conclusive\nIn questo capitolo abbiamo esaminato l’importanza della definizione dell’estimando in uno studio quantitativo, come evidenziato nell’articolo di Lundberg et al. (2021). Il concetto centrale è la distinzione tra estimando teorico ed estimando empirico e il loro collegamento, che facilita l’interpretazione dei risultati e rende l’inferenza statistica più rigorosa.\nL’articolo propone un framework strutturato in tre fasi principali:\n\nDefinire un estimando teorico collegato alla teoria sottostante.\nTradurre questo estimando in un estimando empirico, basato su dati osservabili e assunzioni di identificazione.\nScegliere le strategie di stima adeguate per ottenere stime affidabili.\n\nL’adozione di questo approccio consente di migliorare la chiarezza e la trasparenza nella ricerca, rendendo più facili il confronto tra studi diversi e la replicabilità dei risultati. La corretta definizione dell’estimando guida l’intero processo di ricerca, dalla progettazione dello studio alla scelta delle tecniche di stima e all’interpretazione dei risultati, garantendo che la teoria e le evidenze empiriche siano strettamente collegate.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Estimandi teorici e estimandi empirici 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#bibliografia",
    "href": "chapters/eda/10_estimand.html#bibliografia",
    "title": "23  Estimandi teorici e estimandi empirici 🔸",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., Carlin, J. B., Stern, H. S., & Rubin, D. B. (1995). Bayesian data analysis. Chapman; Hall/CRC.\n\n\nGelman, A., & Imbens, G. (2013). Why ask why? Forward causal inference and reverse causal questions. National Bureau of Economic Research.\n\n\nLundberg, I., Johnson, R., & Stewart, B. M. (2021). What is your estimand? Defining the target quantity connects statistical evidence to theory. American Sociological Review, 86(3), 532–565.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Estimandi teorici e estimandi empirici 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_outlier.html",
    "href": "chapters/eda/11_outlier.html",
    "title": "24  Outlier",
    "section": "",
    "text": "24.1 Introduzione\nI dati raccolti nella vita reale spesso contengono osservazioni che, se confrontate con la maggior parte della popolazione, risultano “anomale” o “estreme”. Queste osservazioni, comunemente note come outlier, possono avere cause diverse: ad esempio, potrebbero provenire da un processo generativo differente, oppure essere semplicemente casi estremi ma comunque possibili. Definire i confini tra ciò che è “normale” e ciò che è “anormale” non è semplice.\nUna gestione non adeguata degli outlier può influenzare considerevolmente le stime statistiche, introducendo bias negli effetti misurati e riducendo la capacità predittiva dei modelli. È quindi importante affrontare il problema degli outlier con criteri chiari e strategie riproducibili. Tuttavia, nonostante siano disponibili linee guida consolidate, molti ricercatori non trattano gli outlier in modo coerente, o utilizzano approcci non appropriati (Simmons et al., 2011).\nUno dei motivi potrebbe essere la scarsa consapevolezza delle raccomandazioni esistenti o la difficoltà ad implementarle con il proprio software di analisi. In questo capitolo mostreremo come seguire le buone pratiche correnti per la rilevazione automatica e riproducibile degli outlier (Statistical Outlier Detection, SOD) in R utilizzando il pacchetto {performance} (Lüdecke et al. 2021).\nIl materiale di questo capitolo riassume l’articolo di Thériault et al. (2024).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_outlier.html#identificare-gli-outlier",
    "href": "chapters/eda/11_outlier.html#identificare-gli-outlier",
    "title": "24  Outlier",
    "section": "\n24.2 Identificare gli Outlier",
    "text": "24.2 Identificare gli Outlier\nMolti ricercatori cercano di identificare gli outlier utilizzando metodi basati sulla media (ad esempio, z-score tradizionali). Tuttavia, questi metodi non sono robusti, poiché sia la media sia la deviazione standard sono sensibili agli stessi outlier e presuppongono una distribuzione normale. Le linee guida attuali raccomandano invece metodi robusti, come quelli che si basano sulla mediana anziché sulla media (Leys et al., 2019).\nLa scelta del metodo di rilevazione outlier dipende però da vari fattori. In alcuni casi potrebbe bastare un’ispezione visiva, ma spesso si preferiscono soluzioni algoritmiche. Inoltre, il metodo da utilizzare può variare in base al tipo di test statistico o al modello di interesse. Ad esempio, nei modelli di regressione ha senso ricercare outlier che non si adattano bene al modello (outlier “model-based”), mentre altre volte si considera la distanza di una singola osservazione dal “centro” della distribuzione (outlier “distribution-based”). Queste strategie possono essere univariate (un’unica variabile) o multivariate (più variabili contemporaneamente).\nIn assenza di metodi ad hoc per modelli complessi (ad es. SEM), può essere utile cercare outlier multivariati. Per test semplici (inferenze su una media, o sul confronto tra medie, o sulle correlazioni), possono essere sufficienti metodi univariati, pur essendo meno flessibili e talvolta più inclini a falsi positivi.\nÈ importante ricordare che qualsiasi scelta resta soggettiva e dev’essere documentata in modo trasparente e riproducibile (Leys et al., 2019). Idealmente, le decisioni andrebbero prese prima della raccolta dei dati (ad esempio in una preregistrazione) e poi riportate chiaramente nell’articolo, menzionando ogni eventuale deviazione dal piano originale.\nNelle sezioni successive illustreremo vari metodi e forniremo esempi di codice R per implementarli.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_outlier.html#outlier-univariati",
    "href": "chapters/eda/11_outlier.html#outlier-univariati",
    "title": "24  Outlier",
    "section": "\n24.3 Outlier Univariati",
    "text": "24.3 Outlier Univariati\nUn approccio comune è individuare outlier in base alla distanza dal “centro” della distribuzione di una singola variabile. Il metodo dei z-score tradizionali, basati sulla media, non è robusto. Si raccomanda invece di usare la mediana e la Median Absolute Deviation (MAD) (Leys et al., 2019).\nLa funzione check_outliers() del pacchetto {performance}, con method = \"zscore_robust\", consente di individuare outlier secondo questo criterio. Ad esempio, il threshold predefinito è pari a ±3.29 MAD, ma può essere modificato.\nDi seguito un esempio con il dataset mtcars, disponibile in R. Prima creiamo degli outlier artificiali, poi utilizziamo check_outliers().\n\nhead(mtcars)\n#&gt;                    mpg cyl disp  hp drat   wt qsec vs am gear carb\n#&gt; Mazda RX4         21.0   6  160 110 3.90 2.62 16.5  0  1    4    4\n#&gt; Mazda RX4 Wag     21.0   6  160 110 3.90 2.88 17.0  0  1    4    4\n#&gt; Datsun 710        22.8   4  108  93 3.85 2.32 18.6  1  1    4    1\n#&gt; Hornet 4 Drive    21.4   6  258 110 3.08 3.21 19.4  1  0    3    1\n#&gt; Hornet Sportabout 18.7   8  360 175 3.15 3.44 17.0  0  0    3    2\n#&gt; Valiant           18.1   6  225 105 2.76 3.46 20.2  1  0    3    1\n\n\n# Create some artificial outliers and an ID column\ndata &lt;- rbind(mtcars[1:4], 42, 55)\ndata &lt;- cbind(car = row.names(data), data)\n\noutliers &lt;- check_outliers(data, method = \"zscore_robust\", ID = \"car\")\noutliers\n#&gt; 2 outliers detected: cases 33, 34.\n#&gt; - Based on the following method and threshold: zscore_robust\n#&gt;   (3.291).\n#&gt; - For variables: mpg, cyl, disp, hp.\n#&gt; \n#&gt; -----------------------------------------------------------------------------\n#&gt;  \n#&gt; The following observations were considered outliers for two or more\n#&gt;   variables by at least one of the selected methods:\n#&gt; \n#&gt;   Row car n_Zscore_robust\n#&gt; 1  33  33               2\n#&gt; 2  34  34               2\n#&gt; \n#&gt; -----------------------------------------------------------------------------\n#&gt; Outliers per variable (zscore_robust): \n#&gt; \n#&gt; $mpg\n#&gt;    Row car Distance_Zscore_robust\n#&gt; 33  33  33                   3.71\n#&gt; 34  34  34                   5.85\n#&gt; \n#&gt; $cyl\n#&gt;    Row car Distance_Zscore_robust\n#&gt; 33  33  33                   12.1\n#&gt; 34  34  34                   16.5\n\nQuesti due outlier aggiunti artificialmente vengono rilevati correttamente. Per escluderli dal dataset principale:\n\nwhich(outliers) \n#&gt; [1] 33 34\n# Restituisce i numeri di riga degli outlier\n\n\ndata_clean &lt;- data[-which(outliers), ]\n\nÈ anche possibile visualizzare gli outlier graficamente:\n\nplot(outliers)\n\n\n\n\n\n\n\nOltre al metodo MAD, check_outliers() supporta anche altri approcci univariati (basati su IQR, intervalli a densità più alta, ecc.).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_outlier.html#outlier-multivariati",
    "href": "chapters/eda/11_outlier.html#outlier-multivariati",
    "title": "24  Outlier",
    "section": "\n24.4 Outlier Multivariati",
    "text": "24.4 Outlier Multivariati\nQuando si analizzano più variabili contemporaneamente (ad esempio altezza e peso di un gruppo di persone), può risultare complesso stabilire quali osservazioni siano davvero “fuori dal comune” rispetto alla maggioranza. In questo contesto, la distanza di Mahalanobis offre un modo per individuare outlier multivariati, cioè osservazioni che si discostano notevolmente dal “centro” dei dati considerati nel loro insieme, anziché analizzare ogni variabile separatamente.\nPer comprendere intuitivamente la distanza di Mahalanobis, immaginate di avere una nube di punti che rappresentano individui, ciascuno con i propri valori di altezza e peso. Il “centro” di questa nube è un punto ideale che rappresenta una sorta di media multivariata (tenendo conto sia dell’altezza sia del peso). La distanza di Mahalanobis misura quanto ogni singolo individuo si allontana da questo centro, considerando la variabilità congiunta delle variabili (ad esempio, la correlazione tra altezza e peso). Se un individuo presenta caratteristiche molto diverse rispetto alla maggioranza, la sua distanza di Mahalanobis sarà elevata, segnalando un potenziale outlier.\n\n\n\n\n\nFigura 24.1\n\n\nTuttavia, la versione classica di questa misura non è particolarmente robusta: la presenza stessa di outlier può distorcere il calcolo del “centro” e della variabilità complessiva, rendendo meno affidabile l’individuazione di altri valori anomali. Per questo motivo, si preferisce utilizzare una variante più resistente, la Minimum Covariance Determinant (MCD), che diminuisce l’influenza degli outlier stessi nel processo di identificazione.\nAll’interno del pacchetto {performance} in R, è possibile applicare questa variante robusta utilizzando la funzione check_outliers() con l’argomento method = \"mcd\". In questo modo, è possibile individuare gli outlier multivariati in maniera più solida e coerente, anche quando si lavora con dati fortemente influenzati da valori estremi.\n\noutliers &lt;- performance::check_outliers(data, method = \"mcd\", verbose = FALSE)\noutliers\n#&gt; 2 outliers detected: cases 33, 34.\n#&gt; - Based on the following method and threshold: mcd (20).\n#&gt; - For variables: mpg, cyl, disp, hp.\n\nSi possono poi visualizzare questi outlier:\n\nplot(outliers)\n\n\n\n\n\n\n\nSono disponibili anche altre varianti multivariate documentate nella help page della funzione.\n\n24.4.1 Outlier Basati sul Modello (Model-Based)\nQuando si impiega un modello di regressione, lo scopo principale è capire la relazione tra una o più variabili predittive (ad esempio, il numero di ore di studio) e una variabile di esito (ad esempio, il punteggio a un test). In questi contesti, può capitare che alcuni punti dati, pur essendo veri e propri dati raccolti, esercitino un’influenza eccessiva sulle stime dei parametri del modello, alterando in modo significativo i risultati dell’analisi. Queste osservazioni vengono definite outlier “model-based” proprio perché il criterio per individuarle non è un semplice confronto con la media o la mediana, bensì con le previsioni del modello stesso.\nIn pratica, per ciascuna osservazione si verifica quanto i risultati previsti dal modello (le stime dei valori di esito) cambierebbero se quella specifica osservazione venisse rimossa. Se togliendo uno specifico caso il modello cambia notevolmente, allora quell’osservazione è considerata un outlier model-based. L’idea è che non ci limitiamo a guardare quanto un singolo valore sia “lontano” dagli altri in termini di distribuzione, ma verifichiamo quanto quel valore “tira” i risultati del modello nella sua direzione.\nIl pacchetto {performance} in R fornisce due metodi per individuare questo tipo di outlier. Per i modelli di regressione classici (ad esempio quelli stimati con la funzione lm() in R), è possibile utilizzare Cook’s distance (method = \"cook\"). Cook’s distance misura quanto i risultati del modello si modificherebbero rimuovendo singolarmente ogni osservazione, identificando così i casi che hanno un effetto sproporzionato sulle stime.\nPer i modelli bayesiani, che utilizzano un approccio probabilistico diverso dal classico, è disponibile invece una metrica chiamata Pareto (method = \"pareto\"). Questo indicatore è ottimizzato per valutare la sensibilità dei modelli bayesiani ad alcune osservazioni estreme, segnalando quelle che hanno un impatto potenzialmente troppo forte sulle inferenze.\nIn sintesi, utilizzare un approccio model-based significa considerare gli outlier non soltanto come valori numerici insoliti, ma come casi che, modificando eccessivamente la forma o le conclusioni del modello, ne compromettono la stabilità e l’affidabilità. L’approccio offerto da {performance} permette così di individuare queste osservazioni “critiche” in modo più mirato e consapevole.\n\nmodel &lt;- lm(disp ~ mpg * hp, data = data)\noutliers &lt;- check_outliers(model, method = \"cook\")\noutliers\n#&gt; 2 outliers detected: cases 31, 34.\n#&gt; - Based on the following method and threshold: cook (0.806).\n#&gt; - For variable: (Whole model).\n\nIn questo modo si individuano outlier che hanno un’elevata influenza sul modello.\n\n\n\n\n\n\nTabella di Riferimento\n\n\n\n\n\n\n\n\n\n\n\nTipo di Analisi\nMetodo Outlier\nThreshold Suggerito\nCodice\n\n\n\nRegressione supportata (lm)\nModel-based (Cook)\nCook: qf(0.5, ...)\n\ncheck_outliers(model, method=\"cook\")\n\n\nSEM o modello non supportato\nMultivariato (MCD)\nMCD: qchisq(1-0.001, df)\n\ncheck_outliers(data, method=\"mcd\")\n\n\nTest semplici (t, correlazioni)\nUnivariato (robust z)\n±~3.29 (MAD)\ncheck_outliers(data, method=\"zscore_robust\")\n\n\n\n\n\n\n24.4.2 Cook’s Distance vs. MCD\nLeys et al. (2018) suggeriscono di preferire la MCD alla Cook’s distance in presenza di molti outlier, poiché quest’ultima valuta l’impatto della rimozione di un’osservazione alla volta, rischiando così di lasciare il modello ancora “contaminato” da altre osservazioni anomale. D’altro canto, i metodi basati sulla distribuzione possono risultare eccessivamente rigorosi, segnalando come outlier anche casi estremi ma perfettamente in linea con il modello teorico. Quando disponibili, i metodi model-based forniscono dunque una prospettiva più informativa.\n\n24.4.3 Approccio Composito (Composite Outlier Score)\nIl pacchetto {performance} permette di combinare diversi metodi per ottenere un punteggio composito, aumentando l’affidabilità della classificazione degli outlier. Ad esempio:\n\noutliers &lt;- check_outliers(\n  model, \n  method = c(\"zscore_robust\", \"mcd\", \"cook\"), \n  verbose = FALSE\n)\nwhich(outliers)\n#&gt; [1] 31 33 34\n\nSi ottengono così osservazioni ritenute outlier da almeno la metà dei metodi utilizzati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_outlier.html#gestione-degli-outlier",
    "href": "chapters/eda/11_outlier.html#gestione-degli-outlier",
    "title": "24  Outlier",
    "section": "\n24.5 Gestione degli Outlier",
    "text": "24.5 Gestione degli Outlier\nDopo l’identificazione, come gestire gli outlier? Leys et al. (2019) distinguono tra outlier dovuti a errori (da correggere o rimuovere), outlier interessanti (potenzialmente rilevanti dal punto di vista teorico) e outlier casuali (da mantenere se compatibili con la distribuzione di interesse).\nSe gli outlier appartengono realmente alla distribuzione di interesse, vanno mantenuti. Se però provengono da un’altra distribuzione o compromettono la robustezza dei risultati, potrebbe essere giustificata la loro rimozione. In alcuni casi, si può utilizzare la “winsorizzazione”, cioè ridurre i valori estremi entro soglie stabilite, per conservare potenza statistica.\nNel pacchetto easystats, la funzione winsorize() di {datawizard} semplifica questo compito:\n\nwinsorized_data &lt;- winsorize(\n  data, \n  method = \"zscore\", \n  robust = TRUE, \n  threshold = 3\n)",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_outlier.html#importanza-della-trasparenza",
    "href": "chapters/eda/11_outlier.html#importanza-della-trasparenza",
    "title": "24  Outlier",
    "section": "\n24.6 Importanza della Trasparenza",
    "text": "24.6 Importanza della Trasparenza\nQualunque decisione va documentata chiaramente: quanti outlier sono stati individuati, con quale metodo, a quale threshold, come sono stati gestiti, e preferibilmente con il codice R utilizzato. La preregistrazione e la condivisione dei dati e del codice (ad es. su OSF) sono pratiche consigliate per garantire riproducibilità e trasparenza.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_outlier.html#riflessioni-conclusive",
    "href": "chapters/eda/11_outlier.html#riflessioni-conclusive",
    "title": "24  Outlier",
    "section": "\n24.7 Riflessioni Conclusive",
    "text": "24.7 Riflessioni Conclusive\nAbbiamo mostrato come identificare gli outlier in modo coerente e trasparente utilizzando la funzione check_outliers() del pacchetto {performance}, allineandoci alle buone pratiche correnti. Tuttavia, la buona pratica non si limita alla scelta degli algoritmi: è fondamentale anche preregistrare le decisioni, essere coerenti, trasparenti e fornire giustificazioni. Speriamo che queste linee guida e gli esempi di codice facilitino l’implementazione di procedure corrette e riproducibili per il trattamento degli outlier.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_outlier.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/11_outlier.html#informazioni-sullambiente-di-sviluppo",
    "title": "24  Outlier",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] datawizard_0.13.0  performance_0.12.4 see_0.9.0         \n#&gt;  [4] gridExtra_2.3      patchwork_1.3.0    bayesplot_1.11.1  \n#&gt;  [7] psych_2.4.12       scales_1.3.0       markdown_1.13     \n#&gt; [10] knitr_1.49         lubridate_1.9.4    forcats_1.0.0     \n#&gt; [13] stringr_1.5.1      dplyr_1.1.4        purrr_1.0.2       \n#&gt; [16] readr_2.1.5        tidyr_1.3.1        tibble_3.2.1      \n#&gt; [19] ggplot2_3.5.1      tidyverse_2.0.0    rio_1.2.3         \n#&gt; [22] here_1.0.1        \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] viridisLite_0.4.2 mnormt_2.1.1      cli_3.6.3         rlang_1.1.4      \n#&gt; [17] munsell_0.5.1     withr_3.0.2       tools_4.4.2       parallel_4.4.2   \n#&gt; [21] tzdb_0.4.0        colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5      \n#&gt; [25] R6_2.5.1          lifecycle_1.0.4   htmlwidgets_1.6.4 MASS_7.3-61      \n#&gt; [29] insight_1.0.0     pkgconfig_2.0.3   pillar_1.10.0     gtable_0.3.6     \n#&gt; [33] glue_1.8.0        xfun_0.49         tidyselect_1.2.1  farver_2.1.2     \n#&gt; [37] htmltools_0.5.8.1 nlme_3.1-166      labeling_0.4.3    rmarkdown_2.29   \n#&gt; [41] compiler_4.4.2",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_outlier.html#bibliografia",
    "href": "chapters/eda/11_outlier.html#bibliografia",
    "title": "24  Outlier",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nLeys, C., Delacre, M., Mora, Y. L., Lakens, D., & Ley, C. (2019). How to classify, detect, and manage univariate and multivariate outliers, with emphasis on pre-registration. International Review of Social Psychology, 32(1).\n\n\nLeys, C., Klein, O., Dominicy, Y., & Ley, C. (2018). Detecting multivariate outliers: Use a robust variant of the Mahalanobis distance. Journal of Experimental Social Psychology, 74, 150–156.\n\n\nSimmons, J. P., Nelson, L. D., & Simonsohn, U. (2011). False-positive psychology: Undisclosed flexibility in data collection and analysis allows presenting anything as significant. Psychological science, 22(11), 1359–1366.\n\n\nThériault, R., Ben-Shachar, M. S., Patil, I., Lüdecke, D., Wiernik, B. M., & Makowski, D. (2024). Check your outliers! An introduction to identifying statistical outliers in R with easystats. Behavior Research Methods, 56(4), 4162–4172.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/12_pixi.html",
    "href": "chapters/eda/12_pixi.html",
    "title": "25  Flusso di lavoro riproducibile 🔸",
    "section": "",
    "text": "25.1 Introduzione\nIn questo capitolo esploreremo gli strumenti essenziali per garantire che il flusso di lavoro di un progetto di analisi dei dati in R sia pienamente riproducibile.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Flusso di lavoro riproducibile 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/eda/12_pixi.html#analisi-e-flussi-di-lavoro-riproducibili",
    "href": "chapters/eda/12_pixi.html#analisi-e-flussi-di-lavoro-riproducibili",
    "title": "25  Flusso di lavoro riproducibile 🔸",
    "section": "\n25.2 Analisi e Flussi di Lavoro Riproducibili",
    "text": "25.2 Analisi e Flussi di Lavoro Riproducibili\nLa possibilità di confermare ripetutamente i risultati scientifici attraverso la replica è un principio fondamentale della scienza. Questo concetto si basa sull’idea che una verità scientifica debba resistere a ulteriori indagini da parte di altri osservatori. In ambito scientifico, è utile distinguere due aspetti legati alla replica: replicabilità e riproducibilità.\n\n\nReplicabilità: si riferisce alla capacità di ottenere risultati simili con dati diversi, ma seguendo lo stesso protocollo sperimentale.\n\nRiproducibilità: indica la capacità di ottenere gli stessi risultati utilizzando gli stessi dati e lo stesso metodo di analisi, sia dalla stessa persona che da altri.\n\n\n25.2.1 Riproducibilità dei Dati\nLa replicazione di esperimenti fisici può presentare difficoltà pratiche significative. Tuttavia, anche riprodurre semplicemente un’analisi dei dati, che sembra un compito più semplice, è spesso problematico per molteplici ragioni. Tradizionalmente, i ricercatori annotavano scrupolosamente i dettagli sperimentali nei loro taccuini di laboratorio, consentendo di replicare l’esperimento. Oggi, strumenti software moderni permettono di applicare lo stesso principio alla riproduzione dei dati: tutto il necessario per rifare l’analisi deve essere documentato in modo chiaro e centralizzato.\nQuesti strumenti non solo facilitano la ripetizione dell’analisi, ma permettono anche di migliorarla e applicarla facilmente a nuovi dati. Tuttavia, per essere riproducibile, l’analisi deve essere scritta in modo appropriato, utilizzando ambienti di programmazione statistica come R o Python, che permettono l’automazione del processo. Al contrario, software come i fogli di calcolo non sono adatti a garantire riproducibilità, perché legano i comandi a celle specifiche, rendendo l’adattamento a nuovi dati complesso e soggetto a errori.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Flusso di lavoro riproducibile 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/eda/12_pixi.html#la-crisi-della-replicazione-e-la-riproducibilità",
    "href": "chapters/eda/12_pixi.html#la-crisi-della-replicazione-e-la-riproducibilità",
    "title": "25  Flusso di lavoro riproducibile 🔸",
    "section": "\n25.3 La Crisi della Replicazione e la Riproducibilità",
    "text": "25.3 La Crisi della Replicazione e la Riproducibilità\nLa crisi della replicazione evidenzia un problema crescente nella scienza moderna: molti studi pubblicati, anche sottoposti a peer review, non sono replicabili. Studi come quello di Ioannidis (2005) e Baker (2016) denunciano che molte ricerche sperimentali e statistiche non resistono alla verifica di altri ricercatori. Questo significa che, nonostante l’apparente validità dei risultati, spesso non è possibile raggiungere le stesse conclusioni ripetendo lo studio.\nTra le cause di questa crisi figurano problematiche complesse come la molteplicità e i percorsi analitici alternativi (il cosiddetto garden of forking paths). Tuttavia, indipendentemente da queste difficoltà, un’analisi riproducibile è un requisito minimo per garantire la validità dei risultati.\n\n\n\n\n\n\nUn problema che compromette la solidità delle conclusioni di molti studi è stato definito da Andrew Gelman, della Columbia University, come il garden of forking paths (giardino dei sentieri che si biforcano). La maggior parte delle analisi richiede una serie di decisioni su come codificare i dati, identificare i fattori rilevanti e formulare (e successivamente rivedere) i modelli prima di arrivare alle analisi finali. Questo processo implica spesso l’esame dei dati per costruire una rappresentazione parsimoniosa. Ad esempio, un predittore continuo potrebbe essere suddiviso arbitrariamente in gruppi per valutare la relazione con l’esito, oppure alcune variabili potrebbero essere incluse o escluse da un modello di regressione durante una fase esplorativa.\nQuesto approccio tende a favorire risultati dei test di ipotesi che sono distorti verso il rigetto dell’ipotesi nulla, poiché le decisioni prese durante il processo possono privilegiare segnali più forti (o p-value più piccoli) rispetto ad altre alternative. Nella maggior parte dei problemi di data science, questo rappresenta una sfida importante che solleva dubbi sulla riproducibilità dei risultati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Flusso di lavoro riproducibile 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/eda/12_pixi.html#elementi-chiave-per-un-workflow-riproducibile",
    "href": "chapters/eda/12_pixi.html#elementi-chiave-per-un-workflow-riproducibile",
    "title": "25  Flusso di lavoro riproducibile 🔸",
    "section": "\n25.4 Elementi chiave per un workflow riproducibile",
    "text": "25.4 Elementi chiave per un workflow riproducibile\nUn flusso di lavoro riproducibile si compone di tre elementi fondamentali:\n\n\nAmbienti di programmazione statistica scriptabili: software come R o Python consentono di automatizzare le analisi e ridurre gli errori manuali.\n\nAnalisi riproducibili: basate sull’approccio della literate programming, dove codice e documentazione sono integrati per garantire trasparenza e comprensione.\n\nControllo di versione: sistemi come Git e piattaforme come GitHub permettono di monitorare e documentare i cambiamenti, favorendo la collaborazione e la tracciabilità.\n\nIntegrare questi componenti nella pratica quotidiana non solo migliora la qualità delle analisi, ma contribuisce a rafforzare la fiducia nella scienza.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Flusso di lavoro riproducibile 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/eda/12_pixi.html#gestione-del-workflow",
    "href": "chapters/eda/12_pixi.html#gestione-del-workflow",
    "title": "25  Flusso di lavoro riproducibile 🔸",
    "section": "\n25.5 Gestione del Workflow",
    "text": "25.5 Gestione del Workflow\nL’utilizzo di R per scrivere script che documentano le analisi dei dati è un importante passo avanti verso la riproducibilità, ma non garantisce automaticamente che il progetto possa essere replicato con successo da altri ricercatori. A conferma di ciò, uno studio condotto da Obels et al. (2020) ha analizzato la condivisione di dati e codice per articoli pubblicati come Registered Reports nella letteratura psicologica tra il 2014 e il 2018. Tentando di riprodurre i risultati principali di ciascun articolo, hanno osservato quanto segue:\n\n“Abbiamo esaminato dati e script condivisi per i Registered Reports pubblicati nella letteratura psicologica dal 2014 al 2018 e tentato di riprodurre computazionalmente i risultati principali di ciascun articolo. Dei 62 articoli che soddisfacevano i nostri criteri di inclusione, 41 mettevano a disposizione i dati e 37 gli script di analisi. Dati e codice erano condivisi per 36 articoli. Siamo riusciti a eseguire gli script per 31 analisi e a riprodurre i risultati principali di 21 articoli. Sebbene la percentuale di articoli con dati e codice condivisi (58%) e quella degli articoli riproducibili computazionalmente (58%) siano relativamente alte rispetto ad altri studi, c’è un evidente margine di miglioramento.”\n\nQuesti risultati evidenziano come, anche con dati e codice disponibili, la riproducibilità non sia garantita. Gli script possono essere incompleti o l’ambiente di sviluppo originale potrebbe non essere replicabile da altri ricercatori.\n\n25.5.1 Strumenti per la Gestione del Workflow\nPer migliorare la riproducibilità, esistono diversi strumenti per la gestione del workflow, che permettono di strutturare i progetti in modo chiaro e ripetibile:\n\n\nMake: uno strumento storico per sistemi Unix, noto per la sua portabilità e la presenza predefinita su molti sistemi.\n\nSnakemake: popolare in biologia, offre flessibilità nella gestione di workflow complessi.\n\ntargets: specifico per R, consente una gestione semplice ed efficace di workflow riproducibili in progetti di analisi dati.\n\nPixi: un workflow manager innovativo basato sull’ecosistema Conda.\n\nQuesti strumenti aiutano a coordinare i diversi passaggi di un’analisi, mantenendo traccia dei file e garantendo che ogni fase del processo sia ripetibile.\n\n25.5.1.1 Limiti degli Strumenti di Workflow Management\nL’adozione di strumenti per la gestione del workflow richiede un certo investimento iniziale. Oltre a scrivere gli script per l’analisi dei dati, è necessario sviluppare ulteriori script per definire il workflow, riorganizzando il progetto per garantire riproducibilità. Questo processo può rendere più complesso il debug e le modifiche successive, motivo per cui alcuni ricercatori possono trovare impegnativo integrare tali strumenti.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Flusso di lavoro riproducibile 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/eda/12_pixi.html#funzioni-e-astrazione",
    "href": "chapters/eda/12_pixi.html#funzioni-e-astrazione",
    "title": "25  Flusso di lavoro riproducibile 🔸",
    "section": "\n25.6 Funzioni e Astrazione",
    "text": "25.6 Funzioni e Astrazione\nIl pacchetto targets è uno strumento per R che semplifica la gestione dei workflow riproducibili. La sua utilità emerge soprattutto nei progetti complessi, dove il codice può diventare lungo e difficile da gestire.\n\n25.6.1 Gestione di codice lungo e complesso\nNel contesto di analisi dati, il codice può includere diverse sezioni che svolgono compiti specifici e spesso ripetuti, come l’importazione dei dati, la pulizia, l’analisi e la generazione di report. Man mano che il progetto cresce, tenere traccia delle diverse parti del codice e farle funzionare in sequenza può diventare complicato.\nUn codice ben scritto deve essere chiaro e comunicare il suo scopo in modo efficace. La trasparenza aumenta la possibilità che il codice sia compreso, sia dagli altri ricercatori sia da te stesso in futuro.\nUn modo efficace per affrontare la complessità è suddividere il codice in funzioni, utilizzando il concetto di astrazione per ridurre la complessità e migliorare la leggibilità.\n\n25.6.2 Funzioni: Gestire la Complessità\nUna funzione è un blocco di codice che realizza un compito specifico. Le funzioni permettono di evitare ripetizioni, rendendo il codice più compatto e leggibile. In R esistono molte funzioni integrate, come mean() per calcolare la media aritmetica, ma, come abbiamo visto in precedenza, è possibile scrivere funzioni personalizzate per compiti specifici.\nLe funzioni devono essere il più generali possibile per favorirne il riutilizzo in diversi progetti.\n\n25.6.3 Il Concetto di Astrazione\nL’astrazione consiste nel suddividere il codice complesso in compiti più piccoli e specifici, delegando i dettagli a funzioni. Questo approccio semplifica la struttura del codice principale (main script), rendendolo più leggibile e autoesplicativo (Filazzola & Lortie, 2022).\nNel main script, le funzioni sono richiamate in sequenza, mentre i dettagli sono “nascosti” nei file che contengono le definizioni delle funzioni. Ad esempio:\n\n25.6.3.1 Main Script:\nlibrary(tidyverse)\nlibrary(here)\n\nsource(\"R/functions.R\")\n\n# Importa e pulisci i dati\nraw_data &lt;- read_csv(here(\"data/raw_data.csv\"))\ncleaned_data &lt;- clean_data(raw_data)\n\n# Modello\nmy_model &lt;- fit_model(data = cleaned_data, response = \"Value\", predictor = \"Gradient\")\nsummary(my_model)\n\n# Grafico\nmy_plot &lt;- make_plot(cleaned_data)\n\n25.6.3.2 Script delle Funzioni:\nclean_data &lt;- function(data){\n  data |&gt; \n    filter(!is.na(Value)) |&gt; \n    mutate(Gradient = recode(Gradient, \"C\" = \"Control\", \"B\" = \"Treatment\")) |&gt; \n    filter(Taxon == \"SpeciesA\")\n}\n\nfit_model &lt;- function(data, response, predictor){\n  lm(as.formula(paste(response, \"~\", predictor)), data = data)\n}\n\nmake_plot &lt;- function(data){\n  ggplot(data, aes(x = Gradient, y = Value)) +\n    geom_boxplot()\n}\nQuesta separazione migliora la leggibilità, la modularità e la riutilizzabilità del codice.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Flusso di lavoro riproducibile 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/eda/12_pixi.html#introduzione-a-targets",
    "href": "chapters/eda/12_pixi.html#introduzione-a-targets",
    "title": "25  Flusso di lavoro riproducibile 🔸",
    "section": "\n25.7 Introduzione a targets\n",
    "text": "25.7 Introduzione a targets\n\ntargets è uno strumento per la gestione di pipeline in R, progettato per coordinare i diversi passaggi di un’analisi dati. Permette di automatizzare e ottimizzare il workflow, gestire le dipendenze tra i vari step, e tenere traccia degli oggetti obsoleti che necessitano di essere aggiornati. Una delle sue caratteristiche chiave è la capacità di evitare inutili ripetizioni, riducendo i tempi di esecuzione.\nIn una pipeline di targets, ogni passaggio rappresenta un “target”, che può essere un oggetto R come un dataset, un modello o una figura. Ogni target è generato da una funzione e la pipeline viene orchestrata da uno script principale chiamato _targets.R, che tiene traccia delle dipendenze tra i target e ne garantisce l’esecuzione nell’ordine corretto.\nQuesta struttura è coerente con il concetto di astrazione: suddividere il codice complesso in compiti più semplici e ben definiti.\n\n25.7.1 Quando utilizzare targets?\n\n\nCodice complesso o con lunghi tempi di esecuzione: Quando il codice richiede molto tempo per essere elaborato, targets evita di rieseguire le parti già aggiornate e supporta l’elaborazione in parallelo, ottimizzando i tempi di calcolo.\n\n\nWorkflow con dipendenze tra i passaggi: Se il flusso di lavoro include step interconnessi, targets semplifica la gestione delle dipendenze, garantendo che ogni step sia eseguito nell’ordine corretto.\n\n\nRiproducibilità dell’analisi: Automatizza il controllo dell’allineamento tra codice, dati e risultati, assicurando che il workflow sia sempre coerente e riproducibile.\n\nIn breve, targets consente di creare pipeline di analisi dati riproducibili e scalabili, migliorando l’efficienza e la gestione del workflow in R. Per un approfondimento pratico, è possibile consultare il tutorial disponibile nella pagina web The {targets} R package user manual.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Flusso di lavoro riproducibile 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/eda/12_pixi.html#pixi",
    "href": "chapters/eda/12_pixi.html#pixi",
    "title": "25  Flusso di lavoro riproducibile 🔸",
    "section": "\n25.8 Pixi",
    "text": "25.8 Pixi\nOltre a targets, vale la pena citare Pixi, un moderno workflow manager progettato per semplificare la gestione dei flussi di lavoro nei progetti di analisi dati. Pixi si distingue per la sua semplicità d’uso e la capacità di affrontare le sfide legate alla riproducibilità e all’organizzazione di progetti complessi.\nPixi è un gestore di pacchetti rapido e versatile, basato sull’ecosistema Conda, che facilita la creazione e la gestione di ambienti di sviluppo su piattaforme come Windows, macOS e Linux. Supporta un’ampia gamma di linguaggi di programmazione, tra cui Python, R, C/C++, Rust e Ruby, offrendo una grande flessibilità per progetti interdisciplinari. Una delle sue caratteristiche principali è la possibilità di creare ambienti riproducibili senza la complessità aggiuntiva di strumenti come Docker, riducendo così i tempi e gli sforzi necessari per configurare e mantenere il progetto.\nCon Pixi, una configurazione iniziale ben organizzata permette di concentrare le energie sull’analisi dei dati e sulla produzione di risultati, garantendo al contempo un workflow riproducibile e ben strutturato. Questo lo rende uno strumento ideale per migliorare l’efficienza e l’affidabilità dei progetti di analisi dati.\n\n25.8.1 Installazione di Pixi\nPer utilizzare Pixi, è necessario avere installati R, RStudio e Pixi stesso. L’installazione di Pixi è semplice seguendo le indicazioni ufficiali. Per installare Pixi, è sufficiente eseguire il seguente comando nel terminale:\ncurl -fsSL https://pixi.sh/install.sh | bash\n\n25.8.2 Struttura del Progetto\nImmaginiamo che il progetto segua questa struttura organizzativa:\ndata-analysis-project/\n│\n├── pixi.toml               # File di configurazione Pixi\n├── pixi.lock               # Lockfile per le dipendenze\n│\n├── data/                   # Directory per i dati\n│   ├── raw/                # Dati grezzi\n│   └── processed/          # Dati processati\n│\n├── src/                    # Codice sorgente in R\n│   ├── data_cleaning.R     # Script per pulizia dei dati\n│   ├── analysis.R          # Script per analisi\n│   └── visualization.R     # Script per visualizzazioni\n│\n├── reports/                # Report e output\n│   ├── figures/            # Figure generate\n│   └── report.Rmd          # Report in R Markdown\n│\n└── README.md               # Documentazione del progetto\n\n25.8.3 Configurazione di Pixi\nPer configurare Pixi, si crea un file pixi.toml nella directory principale del progetto:\n[project]\nname = \"r-data-analysis\"\ndescription = \"Progetto di analisi dati con R\"\nauthors = [\"Tuo Nome &lt;tua.email@example.com&gt;\"]\nchannels = [\"conda-forge\"]\nplatforms = [\"osx-64\", \"linux-64\",\"win-64\"]\n\n[dependencies]\nr-base = \"&gt;=4.3,&lt;5\"\nr-tidyverse = \"*\"\nr-rio= \"*\"\nr-knitr = \"*\"\nr-rmarkdown = \"*\"\nr-here = \"*\"\n\n[tasks]\nclean = \"rm -rf reports/figures/* data/processed/*\"\ndata-prep = \"Rscript src/data_cleaning.R\"\nanalysis = \"Rscript src/analysis.R\"\nreport = \"Rscript -e 'rmarkdown::render(\\\"reports/report.Rmd\\\")'\"\nall = { depends-on = [\"clean\", \"data-prep\", \"analysis\", \"report\"] }\n\n25.8.4 Script di Pulizia Dati (src/data_cleaning.R)\nUno script per pulire e organizzare i dati grezzi:\nlibrary(readr)\nlibrary(dplyr)\n\n# Caricamento dati grezzi\nraw_data &lt;- read_csv(\"data/raw/dati_esempio.csv\")\n\n# Pulizia e trasformazione dei dati\ncleaned_data &lt;- raw_data %&gt;%\n  filter(!is.na(valore)) %&gt;%\n  mutate(categoria = factor(categoria)) %&gt;%\n  group_by(categoria) %&gt;%\n  summarise(media = mean(valore, na.rm = TRUE))\n\n# Salvataggio dei dati processati\nwrite_csv(cleaned_data, \"data/processed/dati_puliti.csv\")\n\n25.8.5 Script di Analisi (src/analysis.R)\nUno script per eseguire analisi statistiche e creare visualizzazioni:\nlibrary(readr)\nlibrary(dplyr)\nlibrary(ggplot2)\n\n# Caricamento dei dati processati\ndati &lt;- read_csv(\"data/processed/dati_puliti.csv\")\n\n# Analisi statistica\nrisultati_analisi &lt;- dati %&gt;%\n  group_by(categoria) %&gt;%\n  summarise(\n    media = mean(media),\n    deviazione_standard = sd(media)\n  )\n\n# Salvataggio dei risultati\nwrite_csv(risultati_analisi, \"reports/risultati_analisi.csv\")\n\n# Creazione di un grafico\ngrafico &lt;- ggplot(dati, aes(x = categoria, y = media)) +\n  geom_bar(stat = \"identity\") +\n  ggtitle(\"Media per Categoria\")\n\n# Salvataggio del grafico\nggsave(\"reports/figures/media_categoria.png\", plot = grafico)\n\n25.8.6 Creazione di un Report (reports/report.Rmd)\nUn report generato con R Markdown per presentare i risultati dell’analisi:\n---\ntitle: \"Report di Analisi dei Dati\"\noutput: html_document\n---\n\n## Risultati dell'Analisi\n\n```\nlibrary(readr)\nlibrary(knitr)\nrisultati &lt;- read_csv(\"reports/risultati_analisi.csv\")\nkable(risultati)\n```\n\n## Grafico delle Medie per Categoria\n\n![Media per Categoria](figures/media_categoria.png)\n\n25.8.7 Esecuzione del Workflow con Pixi\nUna volta installato Pixi, puoi inizializzare un nuovo progetto con:\n# Inizializzazione del progetto\npixi init\nPer installare le dipendenze specificate in in pixi.toml, esegui:\n# Installazione delle dipendenze specificate in pixi.toml\npixi install\nQuesto comando crea un file pixi.lock che elenca tutte le dipendenze del progetto, garantendo che l’ambiente possa essere ricreato in modo identico su diverse macchine.\nPer eseguire le attività definite, utilizza:\npixi run data-prep\npixi run analysis\npixi run report\nOppure, per eseguire tutte le attività in sequenza:\npixi run all\nIl codice utilizzato in questo tutorial è disponibile nel repository GitHub dedicato.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Flusso di lavoro riproducibile 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/eda/12_pixi.html#riflessioni-conclusive",
    "href": "chapters/eda/12_pixi.html#riflessioni-conclusive",
    "title": "25  Flusso di lavoro riproducibile 🔸",
    "section": "\n25.9 Riflessioni Conclusive",
    "text": "25.9 Riflessioni Conclusive\nStrumenti di workflow management come targets e Pixi offrono soluzioni efficaci per semplificare e ottimizzare la gestione dei progetti di analisi dati in R. Automatizzando i flussi di lavoro, questi strumenti garantiscono riproducibilità, coerenza e organizzazione, riducendo la possibilità di errori. Una configurazione iniziale ben strutturata consente di focalizzarsi sull’analisi e sull’interpretazione dei dati, massimizzando l’efficienza e migliorando la qualità complessiva del processo.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Flusso di lavoro riproducibile 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/eda/12_pixi.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/12_pixi.html#informazioni-sullambiente-di-sviluppo",
    "title": "25  Flusso di lavoro riproducibile 🔸",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] see_0.9.0        gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1\n#&gt;  [5] psych_2.4.12     scales_1.3.0     markdown_1.13    knitr_1.49      \n#&gt;  [9] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [13] purrr_1.0.2      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [17] ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.3         rlang_1.1.4       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       tools_4.4.2       parallel_4.4.2    tzdb_0.4.0       \n#&gt; [21] colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5       R6_2.5.1         \n#&gt; [25] lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.0    \n#&gt; [29] gtable_0.3.6      glue_1.8.0        xfun_0.49         tidyselect_1.2.1 \n#&gt; [33] farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-166      rmarkdown_2.29   \n#&gt; [37] compiler_4.4.2",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Flusso di lavoro riproducibile 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/eda/12_pixi.html#bibliografia",
    "href": "chapters/eda/12_pixi.html#bibliografia",
    "title": "25  Flusso di lavoro riproducibile 🔸",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBaker, M. (2016). 1,500 scientists lift the lid on reproducibility. Nature, 533(7604).\n\n\nFilazzola, A., & Lortie, C. (2022). A call for clean code to effectively communicate science. Methods in Ecology and Evolution, 13(10), 2119–2128.\n\n\nIoannidis, J. P. (2005). Why most published research findings are false. PLoS medicine, 2(8), e124.\n\n\nObels, P., Lakens, D., Coles, N. A., Gottfried, J., & Green, S. A. (2020). Analysis of open data and computational reproducibility in registered reports in psychology. Advances in Methods and Practices in Psychological Science, 3(2), 229–237.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Flusso di lavoro riproducibile 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/probability/introduction_probability.html",
    "href": "chapters/probability/introduction_probability.html",
    "title": "Probabilità",
    "section": "",
    "text": "Questa sezione della dispensa introduce la teoria della probabilità, una componente essenziale per la ricerca scientifica. Nell’ambito della scienza, l’inferenza induttiva è di fondamentale importanza, e la probabilità svolge un ruolo cruciale in questo processo. Sebbene non possiamo ottenere una certezza assoluta riguardo alla veridicità di un’ipotesi o teoria, possiamo assegnare loro un grado di certezza probabilistica. L’approccio bayesiano utilizza la probabilità per quantificare il grado di fiducia che possiamo attribuire a una determinata proposizione.\nL’inferenza statistica bayesiana mira a quantificare la fiducia nell’ipotesi \\(H\\) dopo aver osservato un dato di evidenza \\(O\\). Per affrontare adeguatamente l’inferenza statistica bayesiana, è quindi essenziale avere una solida comprensione della teoria delle probabilità, almeno nei suoi concetti fondamentali.\nIn questa sezione esamineremo le definizioni di probabilità, la probabilità condizionale e il teorema di Bayes. Approfondiremo inoltre le proprietà delle variabili casuali e le principali distribuzioni di massa e densità di probabilità. Concluderemo presentando la funzione di verosimiglianza, un concetto fondamentale sia nell’inferenza bayesiana sia nell’inferenza frequentista.",
    "crumbs": [
      "Probabilità"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html",
    "href": "chapters/probability/01_intro_prob.html",
    "title": "26  Interpretazione della probabilità",
    "section": "",
    "text": "26.1 Introduzione\nNel corso di questo capitolo, esploreremo varie concezioni della probabilità, tra cui la visione classica, frequentista e bayesiana. Inoltre, introdurremo la simulazione con R per una migliore comprensione della legge dei grandi numeri, un concetto fondamentale nell’ambito della probabilità. Iniziamo introducendo il concetto di causalità.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#il-concetto-di-casualità-e-la-teoria-della-probabilità",
    "href": "chapters/probability/01_intro_prob.html#il-concetto-di-casualità-e-la-teoria-della-probabilità",
    "title": "26  Interpretazione della probabilità",
    "section": "\n26.2 Il Concetto di Casualità e la Teoria della Probabilità",
    "text": "26.2 Il Concetto di Casualità e la Teoria della Probabilità\nDavid Spiegelhalter, in un recente articolo pubblicato su Nature, descrive il concetto di probabilità partendo dall’idea di incertezza:\n\nLife is uncertain. None of us know what is going to happen. We know little of what has happened in the past, or is happening now outside our immediate experience. Uncertainty has been called the ‘conscious awareness of ignorance’ — be it of the weather tomorrow, the next Premier League champions, the climate in 2100 or the identity of our ancient ancestors (Spiegelhalter, 2024).\n\nL’incertezza può essere vista come una manifestazione della casualità, che rappresenta non solo un fenomeno, ma anche un modello concettuale per affrontare l’imprevedibilità della realtà. Attraverso il concetto di casualità, possiamo gestire e quantificare eventi che, pur essendo imprevedibili singolarmente, seguono schemi regolari e osservabili. Questo rende la casualità uno strumento fondamentale per comprendere il mondo e prendere decisioni.\n\nAttempts to put numbers on chance and uncertainty take us into the mathematical realm of probability, which today is used confidently in any number of fields (Spiegelhalter, 2024).\n\nLa teoria della probabilità fornisce una risposta matematica all’incertezza, permettendo di esprimere in termini numerici il grado di possibilità associato a un evento. Grazie a questa formalizzazione, possiamo modellare fenomeni complessi e applicare il concetto di probabilità in contesti che spaziano dalla ricerca scientifica alla vita quotidiana.\n\n26.2.1 L’Urna come Modello della Casualità\nUn classico esempio utilizzato per rappresentare la casualità è il modello dell’urna. Immaginiamo un’urna contenente palline identiche, ognuna numerata in modo univoco. Se ogni pallina ha la stessa probabilità di essere estratta, l’estrazione è considerata casuale. Anche se non possiamo prevedere quale pallina verrà estratta, sappiamo che ogni pallina ha uguali possibilità di essere selezionata.\nQuesto modello, per quanto semplice, incarna l’essenza della casualità. La sua semplicità consente di estenderne i principi a situazioni più complesse. Ad esempio, il modello dell’urna può essere utilizzato come base concettuale per comprendere processi che vanno ben oltre l’estrazione di palline, trovando applicazioni in ambiti come la statistica, la scienza e la psicologia.\n\n26.2.1.1 Applicazioni del Modello della Casualità\nIndagini statistiche\nIl campionamento casuale nelle ricerche statistiche garantisce un campione rappresentativo di una popolazione più ampia, riducendo il rischio di bias di selezione e migliorando la generalizzabilità delle conclusioni.\nSperimentazione scientifica\nLa randomizzazione è essenziale per controllare le variabili confondenti nelle sperimentazioni. Permette di attribuire le differenze osservate tra i gruppi al trattamento, riducendo l’effetto di fattori esterni.\n\nOpen any science journal, for example, and you’ll find papers liberally sprinkled with P values, confidence intervals and possibly Bayesian posterior distributions, all of which are dependent on probability (Spiegelhalter, 2024).\n\nSimulazioni\nIn discipline come fisica e psicologia, i modelli di simulazione basati sulla casualità permettono di analizzare sistemi complessi e formulare previsioni, offrendo strumenti indispensabili per la ricerca scientifica.\nNonostante la semplicità, il modello dell’urna costituisce un pilastro per comprendere e applicare il concetto di casualità in un’ampia varietà di contesti.\n\n26.2.2 Dalla Casualità alla Teoria della Probabilità\nLa teoria della probabilità si sviluppa a partire dal concetto di casualità, fornendo strumenti matematici per analizzare e quantificare rigorosamente l’incertezza. Questo approccio consente di tradurre l’intuizione in un linguaggio formale, attraverso il quale possiamo:\n\nQuantificare l’incertezza\nAssegnare un valore numerico agli esiti possibili permette di esprimere in modo preciso la probabilità di ciascun evento.\nCombinare informazioni\nCon regole come la somma e il prodotto delle probabilità, possiamo calcolare la probabilità di eventi complessi derivati da eventi più semplici.\nAggiornare le credenze\nLa teoria della probabilità, in particolare nella sua formulazione bayesiana, fornisce metodi per aggiornare razionalmente le stime di probabilità alla luce di nuove informazioni.\nPrendere decisioni informate\nValutando rischi e benefici attesi, la probabilità guida decisioni ottimali in condizioni di incertezza.\n\nIn sintesi, la casualità e la probabilità rappresentano strumenti fondamentali per navigare un mondo incerto, fornendo un linguaggio preciso per descriverlo e una struttura rigorosa per ragionare su di esso. Comprendere questi concetti è essenziale non solo per matematici o statistici, ma per chiunque voglia prendere decisioni consapevoli, sia nella ricerca che nella vita quotidiana.\nNei capitoli seguenti, esploreremo come questi principi si applichino all’analisi dei dati, con un focus sull’approccio bayesiano. Questo metodo, attraverso un processo iterativo di aggiornamento delle conoscenze, rappresenta una modalità intuitiva e potente per affrontare l’incertezza e migliorare le nostre inferenze alla luce di nuove evidenze.\n\n26.2.3 Storia e Definizioni della Probabilità\nLa probabilità è un concetto cardine nella matematica e nelle scienze, utilizzato per misurare l’incertezza e studiare fenomeni aleatori. Nel corso del tempo, la sua definizione si è evoluta, passando da intuizioni di tipo qualitativo a formulazioni formali e rigorose.\nLa probabilità nasce dal bisogno di distinguere gli eventi deterministici, il cui esito è prevedibile, da quelli casuali, caratterizzati dall’imprevedibilità. Un evento deterministico, almeno in teoria, produce sempre lo stesso risultato nelle stesse condizioni, mentre un evento casuale ha esiti che non possiamo prevedere con certezza. Questa distinzione ha portato alla necessità di quantificare l’incertezza associata agli eventi casuali, utilizzando il concetto di probabilità.\n\n26.2.4 Fonti dell’Incertezza\nL’incertezza nei fenomeni casuali può derivare da due fonti principali:\n\nIncertezza epistemica: Questa forma di incertezza è legata alla nostra conoscenza limitata. Ad esempio, in un esperimento scientifico complesso, la nostra impossibilità di controllare tutte le variabili può introdurre incertezza nei risultati.\nIncertezza ontologica: Si riferisce alla casualità intrinseca di alcuni fenomeni, come in fisica quantistica, dove l’indeterminazione sembra essere una caratteristica fondamentale della realtà stessa. Un esempio intuitivo è il lancio di un dado: indipendentemente da quanto conosciamo le condizioni, non possiamo prevedere con assoluta precisione il risultato.\n\nIl fisico danese Niels Bohr ha offerto un’interpretazione illuminante su questo tema: la fisica, secondo Bohr, non mira a rivelare una verità assoluta sulla natura, ma a capire cosa possiamo dire su di essa. Questa visione riconosce che l’incertezza – sia epistemica che ontologica – riflette i limiti del nostro linguaggio e delle nostre conoscenze. Questo approccio si allinea bene con l’interpretazione soggettiva della probabilità, secondo la quale la probabilità rappresenta il grado di fiducia che un individuo ha riguardo al verificarsi di un evento, basata sulle informazioni di cui dispone.\n\n26.2.5 Assiomatizzazione della Probabilità\nNel 1933, il matematico Andrey Kolmogorov fornì una definizione formale della probabilità, introducendo un sistema assiomatico che costituì la base della moderna teoria della probabilità. Questa formulazione ha trasformato la probabilità in una disciplina matematica rigorosa, offrendo uno strumento essenziale per quantificare l’incertezza in contesti scientifici. Da semplice metodo per analizzare i giochi d’azzardo nel XVII secolo, la probabilità è diventata una pietra miliare del ragionamento scientifico, fornendo un linguaggio universale per descrivere e analizzare l’incertezza in numerosi campi del sapere.\n\n26.2.6 La Storia della Probabilità\nLa probabilità moderna nacque da una domanda posta da Antoine Gombaud (Chevalier de Méré) a Blaise Pascal nel XVII secolo su come dividere equamente le puntate di un gioco d’azzardo interrotto.\n\n26.2.6.1 Il Problema dei Punti\nIl problema può essere riassunto come segue:\n\nImmaginiamo due persone, A e B, che partecipano a un gioco in cui il primo che vince sei round consecutivi ottiene un premio. Dopo sei round, A ha vinto cinque round e B uno. Poiché il gioco si interrompe prima di assegnare il premio, come dovrebbero dividere il premio in modo equo?\n\nQuesta domanda diede origine a una corrispondenza tra Pascal e Fermat, che svilupparono una soluzione matematica basata sulle probabilità di vittoria per ciascun giocatore. Se, per esempio, A aveva una probabilità del 97% di vincere, mentre B una del 3%, sembrava equo assegnare il 97% del premio ad A. La loro corrispondenza ispirò l’opera di Christian Huygens, “De Ratiociniis in Ludo Aleae” (1657), che rimase un riferimento in probabilità per mezzo secolo.\n\n26.2.7 Sviluppi Successivi\nNel 1713, Jacob Bernoulli pubblicò postumo “L’Arte della Congettura”, introducendo la legge dei grandi numeri e ponendo le basi per l’applicazione della probabilità al di fuori dei giochi d’azzardo, ad esempio nello studio della mortalità e della giustizia penale.\n\n26.2.8 Interpretazione Classica\nLa definizione classica di probabilità fu proposta da Pierre-Simon Laplace (1749-1827), che basò il concetto sul calcolo combinatorio. Secondo Laplace, la probabilità di un evento è data dal rapporto tra i casi favorevoli e il numero totale di casi possibili, assumendo che tutti siano equiprobabili. Ad esempio, la probabilità di ottenere un “3” lanciando un dado è \\(\\frac{1}{6}\\), poiché solo uno dei sei risultati è favorevole.\nTuttavia, questa definizione è limitata, poiché si basa sull’assunzione che ogni evento sia equiprobabile, il che non è sempre vero. Inoltre, è parzialmente circolare, poiché presuppone una conoscenza implicita del concetto di probabilità.\n\n26.2.9 Interpretazione Frequentista\nL’approccio frequentista, nato dalla necessità di evitare le limitazioni dell’interpretazione classica, definisce la probabilità come il limite della frequenza relativa con cui un evento si verifica in una serie infinita di prove. Per esempio, la probabilità di ottenere “testa” in un lancio di moneta può essere stimata come la frequenza relativa di “testa” sul totale dei lanci, quando il numero di lanci tende all’infinito. Questa definizione è utile, ma impraticabile in molte situazioni, poiché richiede un numero infinito di ripetizioni e assume che gli eventi futuri siano identici a quelli passati.\nLa figura seguente illustra la proporzione di risultati “testa” in una sequenza di lanci di una moneta equa. Si può osservare come la frequenza relativa dei risultati “testa” converga progressivamente verso il valore della probabilità teorica.\n\n\n\n\n\n\n\n\n\n26.2.10 La Legge dei Grandi Numeri\nLa simulazione precedente offre una chiara illustrazione della Legge dei Grandi Numeri, un principio fondamentale della probabilità. Questo teorema afferma che, con l’aumentare del numero di esperimenti casuali ripetuti, la stima empirica della probabilità di un evento \\(P(Y = y)\\) tende a convergere al valore teorico.\nIn termini semplici, la Legge dei Grandi Numeri garantisce che, al crescere del numero di prove, la media dei risultati osservati si avvicina progressivamente al valore atteso della variabile casuale. Questo significa che, anche se i risultati individuali possono variare in modo casuale, la media dei risultati su un gran numero di esperimenti rifletterà con sempre maggiore precisione la probabilità teorica.\nQuesto principio è fondamentale perché assicura che:\n\nCon un numero sufficiente di prove, le stime empiriche delle probabilità siano affidabili.\nI modelli probabilistici possano essere utilizzati per descrivere e prevedere fenomeni reali, nonostante la variabilità intrinseca delle osservazioni singole.\n\nFormalmente, se consideriamo una serie di variabili casuali indipendenti \\(X_1, X_2, \\ldots, X_n\\), tutte con la stessa media teorica \\(\\mu\\), la Legge dei Grandi Numeri si esprime come:\n\\[\n\\lim_{{n \\to \\infty}} P\\left(\\left|\\frac{1}{n} \\sum_{i=1}^n X_i - \\mu\\right| &lt; \\epsilon\\right) = 1,\n\\]\ndove \\(\\epsilon\\) è un numero positivo arbitrariamente piccolo e \\(P(\\cdot)\\) rappresenta la probabilità. In altre parole:\n\nMan mano che \\(n\\) (il numero di prove) diventa molto grande, la media campionaria \\(\\frac{1}{n} \\sum_{i=1}^n X_i\\) sarà sempre più vicina alla media teorica \\(\\mu\\), con una probabilità che si avvicina a 1.\n\nQuesto teorema ha implicazioni importanti nella pratica:\n\nPermette di stimare probabilità con crescente precisione al crescere delle osservazioni.\nOffre un fondamento teorico per l’utilizzo di medie campionarie in statistica e in molte applicazioni scientifiche.\n\nIn conclusione, la Legge dei Grandi Numeri è essenziale per comprendere come, nonostante la variabilità casuale nei risultati individuali, la regolarità emerge quando si considera un numero sufficientemente grande di osservazioni. Questo principio stabilisce il legame tra la teoria della probabilità e le applicazioni pratiche, garantendo che le stime empiriche, nel lungo periodo, riflettano i valori teorici con elevata precisione.\n\n26.2.11 Il Problema del Caso Singolo\nNell’approccio frequentista alla probabilità, basato sull’idea che la probabilità sia definita come la frequenza relativa di un evento osservato su un grande numero di ripetizioni, emerge una limitazione concettuale nel trattare la probabilità di eventi singolari e non ripetibili. Secondo questa prospettiva, non è rigorosamente corretto parlare di probabilità associate a eventi unici e irripetibili.\nEsempi di tali eventi includono:\n\nLa probabilità che Alcaraz vinca contro Djokovic nella finale di Wimbledon del 2023.\nLa probabilità che piova a Firenze il giorno di Ferragosto del 2025.\n\nQuesti scenari, legati a un preciso momento storico e privi di una struttura ripetitiva, non rientrano nella logica frequentista, che richiede la possibilità di osservare ripetutamente un evento per determinarne la probabilità. Infatti, nel contesto frequentista, una definizione operativa della probabilità implica un esperimento ripetibile un numero indefinito di volte in condizioni simili, una situazione non applicabile ai casi singoli.\nTuttavia, nel linguaggio comune, è frequente usare il termine “probabilità” per riferirsi anche a eventi singolari e irripetibili, come se la probabilità fosse una misura intuitiva del nostro grado di fiducia nel verificarsi di un evento. Questo uso non tecnico evidenzia una discrepanza tra il significato formale della probabilità nella teoria frequentista e l’interpretazione colloquiale del termine.\nIn conclusione, il problema del caso singolo mette in luce i limiti dell’approccio frequentista nella descrizione di eventi unici e irripetibili. Sebbene il concetto di probabilità sia ampiamente utilizzato per descrivere tali eventi nel linguaggio comune, una trattazione rigorosa richiede approcci alternativi, come l’approccio bayesiano, che permette di esprimere la probabilità come una misura soggettiva del grado di credenza, superando così la necessità di ripetizioni sperimentali.\n\n26.2.12 Collegamento tra probabilità e statistica\nDurante gli anni ’20 del Novecento, Ronald A. Fisher propose un nuovo framework teorico per l’inferenza statistica, basato sulla concettualizzazione della frequenza. Fisher introdusse concetti chiave come la massima verosimiglianza, i test di significatività, i metodi di campionamento, l’analisi della varianza e il disegno sperimentale.\nNegli anni ’30, Jerzy Neyman ed Egon Pearson fecero ulteriori progressi nel campo con lo sviluppo di una teoria della decisione statistica, basata sul principio della verosimiglianza e sull’interpretazione frequentista della probabilità. Definirono due tipologie di errori decisionali e utilizzarono il test di significatività di Fisher, interpretando i valori-\\(p\\) come indicatori dei tassi di errore a lungo termine.\n\n26.2.13 La riscoperta dei metodi Monte Carlo Markov chain\nFisher assunse una prospettiva critica nei confronti della “probabilità inversa” (ossia, i metodi bayesiani), nonostante questa fosse stata la metodologia predominante per l’inferenza statistica per quasi un secolo e mezzo. Il suo approccio frequentista ebbe un profondo impatto sullo sviluppo della statistica sia teorica che sperimentale, contribuendo a un decremento nell’utilizzo dell’inferenza basata sul metodo della probabilità inversa, originariamente proposto da Laplace.\nNel 1939, il libro di Harold Jeffreys intitolato “Theory of Probability” rappresentò una delle prime esposizioni moderne dei metodi bayesiani. Tuttavia, la rinascita del framework bayesiano fu rinviata fino alla scoperta dei metodi Monte Carlo Markov chain alla fine degli anni ’80. Questi metodi hanno reso fattibile il calcolo di risultati precedentemente non ottenibili, consentendo un rinnovato interesse e sviluppo nei metodi bayesiani. Per una storia dell’approccio bayesiano, si veda Bayesian Methods: General Background oppure Philosophy of Statistics.\n\n26.2.14 Interpretazione Soggettivista della Probabilità\nL’interpretazione soggettivista considera la probabilità non come una proprietà intrinseca degli eventi, ma come una misura del grado di credenza personale di un individuo. In questa visione, la probabilità riflette il livello di fiducia che una persona attribuisce a un evento, sulla base delle informazioni disponibili.\nUn’affermazione provocatoria in questo senso proviene da Bruno de Finetti, uno dei principali fautori di questa prospettiva:\n\n“La probabilità non esiste.”\n\nDe Finetti paragonava l’idea di una probabilità oggettiva a credenze superate come l’“Etere cosmico” o le “Fate e Streghe.” Per lui, le probabilità sono esclusivamente soggettive, rappresentando convinzioni personali che variano in base al contesto informativo. Questa visione, radicale ma influente, ha gettato le basi per lo sviluppo del pensiero probabilistico bayesiano.\nLa rilevanza contemporanea di questa prospettiva è evidente in un recente articolo pubblicato su Nature, che ribadisce l’essenza soggettiva della probabilità:\n\n[…] any numerical probability, I will argue — whether in a scientific paper, as part of weather forecasts, predicting the outcome of a sports competition or quantifying a health risk — is not an objective property of the world, but a construction based on personal or collective judgements and (often doubtful) assumptions. Furthermore, in most circumstances, it is not even estimating some underlying ‘true’ quantity. Probability, indeed, can only rarely be said to ‘exist’ at all (Spiegelhalter, 2024).\n\nLe basi dell’interpretazione soggettivista furono poste da Frank P. Ramsey nel 1926, quando definì la probabilità come grado di credenza individuale (Ramsey, 1926). Sebbene inizialmente marginale, questa concezione ha acquisito un ruolo centrale nel pensiero bayesiano.\nUna rigorosa formalizzazione matematica degli assiomi della probabilità soggettiva è stata proposta da Fishburn (Fishburn, 1986), mentre approfondimenti metodologici e applicativi si trovano nei lavori successivi di Press (Press, 2009).\nQuesta interpretazione sottolinea come la probabilità sia una costruzione umana, influenzata da giudizi, ipotesi e informazioni, più che una proprietà intrinseca della realtà.\n\n26.2.14.1 Terminologia\nIl termine “probabilità soggettiva” può talvolta suggerire una connotazione di imprecisione o mancanza di rigore scientifico. Per evitare tali fraintendimenti:\n\n\nLindley (2013) ha proposto il termine “probabilità personale,” sottolineando l’aspetto individuale ma razionale di questa concezione.\n\nHowson & Urbach (2006) preferiscono “probabilità epistemica,” evidenziando il legame con la conoscenza e l’incertezza di fronte a informazioni incomplete.\n\nQueste alternative linguistiche, adottate ad esempio da Kaplan (2023), offrono una descrizione più neutra e accessibile per discutere la probabilità soggettiva in contesti scientifici.\n\n26.2.14.2 Applicazioni\nL’interpretazione soggettivista si adatta particolarmente bene a situazioni che sfuggono all’approccio frequentista, come l’analisi di eventi singoli. Questi eventi non possono essere analizzati in termini di frequenze relative, poiché sono unici e irripetibili. L’approccio soggettivista consente invece di quantificare il grado di fiducia in base alle informazioni disponibili.\n\n26.2.15 Fondamenti Bayesiani\nL’interpretazione soggettivista bayesiana propone che:\n\nLa probabilità sia una misura del grado di fiducia che un soggetto razionale attribuisce alla validità di un’affermazione, basandosi su informazioni disponibili, generalmente insufficienti per determinare con certezza la verità o la falsità dell’affermazione stessa.\n\nQuesta definizione non si riferisce a un individuo specifico, bensì a una idealizzazione di un soggetto razionale, privo di emozioni o istinti, il cui giudizio è basato esclusivamente sulla logica e sulle evidenze disponibili.\nCome descritto da E.T. Jaynes in Probability Theory: The Logic of Science, il problema della probabilità può essere immaginato come segue:\n\nSi fornisca a un robot razionale un’informazione \\(I\\), considerata vera e completa dal robot.\nSi presenti un’affermazione \\(A\\), che nella realtà è esclusivamente vera o falsa.\nIl robot deve quantificare, nel modo più razionale possibile, il grado di incertezza riguardante la validità di \\(A\\), basandosi esclusivamente sull’informazione \\(I\\).\n\nLa probabilità di \\(A\\) dato \\(I\\) viene espressa come \\(P(A \\mid I)\\), dove:\n\n\n\\(P(A \\mid I)\\) è un numero reale compreso tra 0 e 1.\nDeve rispettare i principi della coerenza logica, ossia i postulati della teoria della probabilità.\n\nIn conclusione, l’interpretazione soggettivista trasforma la probabilità in uno strumento flessibile per affrontare situazioni di incertezza, adattandosi sia a eventi singoli che a contesti complessi. Essa consente di esprimere razionalmente le credenze personali, fornendo un quadro coerente e rigoroso per il ragionamento probabilistico.\n\n\n\n\n\n\nPer chi desidera approfondire, il primo capitolo del testo Bernoulli’s Fallacy (Clayton, 2021) offre un’introduzione molto leggibile alle tematiche della definizione della probabilità nella storia della scienza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#riflessioni-conclusive",
    "href": "chapters/probability/01_intro_prob.html#riflessioni-conclusive",
    "title": "26  Interpretazione della probabilità",
    "section": "\n26.3 Riflessioni Conclusive",
    "text": "26.3 Riflessioni Conclusive\nNel presente capitolo, si è proceduto a un’analisi filosofica della nozione di probabilità, esplorando le sue interpretazioni sia come proprietà intrinseca degli eventi sia come espressione di convinzioni soggettive in condizioni di incertezza.\nÈ stato, inoltre, introdotto il ruolo della simulazione come strumento metodologico fondamentale per l’approssimazione delle probabilità empiriche in contesti nei quali le soluzioni analitiche risultano impraticabili. Questa tecnica si rivela di estrema rilevanza in ambiti di recente sviluppo, dove la complessità dei modelli matematici richiede l’impiego di algoritmi numerici avanzati per la loro elaborazione e comprensione.\nCon le premesse sopra esposte, il capitolo successivo sarà dedicato all’analisi matematica della probabilità. Si esaminerà il modo in cui gli statistici formulano e applicano teoremi e leggi probabilistici, estendendo l’applicabilità del concetto di probabilità al di là delle teorizzazioni puramente teoriche, verso implementazioni pratiche. Questo approccio quantitativo permetterà di quantificare e gestire l’incertezza con maggiore precisione e affidabilità.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/01_intro_prob.html#informazioni-sullambiente-di-sviluppo",
    "title": "26  Interpretazione della probabilità",
    "section": "\n26.4 Informazioni sull’Ambiente di Sviluppo",
    "text": "26.4 Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] see_0.9.0        gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1\n#&gt;  [5] psych_2.4.12     scales_1.3.0     markdown_1.13    knitr_1.49      \n#&gt;  [9] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [13] purrr_1.0.2      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [17] ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.3         rlang_1.1.4       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       yaml_2.3.10       tools_4.4.2       parallel_4.4.2   \n#&gt; [21] tzdb_0.4.0        colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5      \n#&gt; [25] R6_2.5.1          lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3  \n#&gt; [29] pillar_1.10.0     gtable_0.3.6      glue_1.8.0        xfun_0.49        \n#&gt; [33] tidyselect_1.2.1  farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-166     \n#&gt; [37] labeling_0.4.3    rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#bibliografia",
    "href": "chapters/probability/01_intro_prob.html#bibliografia",
    "title": "26  Interpretazione della probabilità",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nClayton, A. (2021). Bernoulli’s Fallacy: Statistical Illogic and the Crisis of Modern Science. Columbia University Press.\n\n\nFishburn, P. C. (1986). The axioms of subjective probability. Statistical Science, 1(3), 335–345.\n\n\nHowson, C., & Urbach, P. (2006). Scientific reasoning: the Bayesian approach. Open Court Publishing.\n\n\nKaplan, D. (2023). Bayesian statistics for the social sciences. Guilford Publications.\n\n\nLindley, D. V. (2013). Understanding uncertainty. John Wiley & Sons.\n\n\nPress, S. J. (2009). Subjective and objective Bayesian statistics: Principles, models, and applications. John Wiley & Sons.\n\n\nRamsey, F. P. (1926). Truth and probability. In Readings in Formal Epistemology: Sourcebook (pp. 21–45). Springer.\n\n\nSpiegelhalter, D. (2024). Why probability probably doesn’t exist (but it is useful to act like it does). Nature, 636(8043), 560–563.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_prob_spaces.html",
    "href": "chapters/probability/02_prob_spaces.html",
    "title": "27  Misura di Probabilità",
    "section": "",
    "text": "27.1 Introduzione\nPrerequisiti\nConcetti e Competenze Chiave\nDa dove derivano matematicamente i numeri che chiamiamo “probabilità”? Per rispondere a questa domanda, in questo capitolo faremo riferimento alla trattazione di Michael Betancourt. Questo capitolo offre una versione semplificata del suo lavoro, mantenendo la notazione e le figure originali.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Misura di Probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_prob_spaces.html#insiemi-finiti",
    "href": "chapters/probability/02_prob_spaces.html#insiemi-finiti",
    "title": "27  Misura di Probabilità",
    "section": "27.2 Insiemi Finiti",
    "text": "27.2 Insiemi Finiti\nPer semplificare, Betancourt introduce i fondamenti della teoria della probabilità utilizzando uno spazio campionario composto da un numero finito di elementi.\nUn insieme finito è costituito da un numero finito di elementi distinti,\n\\[\nX = \\{x_1, ..., x_N\\}.\n\\]\nQui, l’indice numerico serve a distinguere gli \\(N\\) elementi individuali, senza implicare necessariamente un ordine particolare tra di essi. Per evitare qualsiasi presunzione di ordine, Betancourt utilizza il seguente insieme arbitrario di cinque elementi quale esempio:\n\\[\nX = \\{\\Box, \\clubsuit, \\diamondsuit, \\heartsuit, \\spadesuit\\}.\n\\]\n\n\n\n\n\n\nFigura 27.1: Un insieme finito contiene un numero finito di elementi. Questo particolare insieme ne contiene cinque.\n\n\n\nNelle applicazioni pratiche della teoria della probabilità, gli elementi astratti \\(x_{n}\\) rappresentano oggetti concreti. Tuttavia, in questo capitolo, ci si concentrerà esclusivamente sui concetti matematici, evitando qualsiasi interpretazione particolare. Quando l’insieme \\(X\\) rappresenta tutti gli oggetti di interesse in una data applicazione, viene denominato spazio campionario. Una volta definito lo spazio campionario, possiamo organizzare e manipolare i suoi elementi in vari modi.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Misura di Probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_prob_spaces.html#sottoinsiemi",
    "href": "chapters/probability/02_prob_spaces.html#sottoinsiemi",
    "title": "27  Misura di Probabilità",
    "section": "27.3 Sottoinsiemi",
    "text": "27.3 Sottoinsiemi\nUn sottoinsieme di \\(X\\) è qualsiasi collezione di elementi in \\(X\\). Per evitare ambiguità, Betancourt usa le lettere romane minuscole \\(x\\) per indicare un elemento variabile nello spazio campionario \\(X\\) e le lettere minuscole sans serif \\(\\mathsf{x}\\) per indicare un sottoinsieme variabile.\nAd esempio, \\(\\mathsf{x} = \\{\\Box, \\diamondsuit, \\heartsuit\\}\\) è un sottoinsieme di \\(X = \\{\\Box, \\clubsuit, \\diamondsuit, \\heartsuit, \\spadesuit\\}\\). Importante notare che nel concetto di sottoinsieme non esiste la nozione di molteplicità, solo di appartenenza: un sottoinsieme può includere un elemento \\(x_{n}\\) ma non può includerlo più volte.\n\n\n\n\n\n\nFigura 27.2: Un sottoinsieme \\(\\mathsf{x} \\subset X\\) è qualsiasi collezione di elementi dallo spazio campionario \\(X\\). Qui \\(\\mathsf{x} = \\{\\Box, \\diamondsuit, \\heartsuit\\}\\) contiene solo tre dei cinque elementi in $X = {, , , , }.\n\n\n\nSe \\(\\mathsf{x}\\) è un sottoinsieme dello spazio campionario \\(X\\) allora scriviamo \\(\\mathsf{x} \\subset X\\). Quando \\(\\mathsf{x}\\) contiene tutti gli elementi di \\(X\\), ovvero \\(\\mathsf{x} = X\\), allora scriviamo \\(\\mathsf{x} \\subseteq X\\).\nIndipendentemente da quanti elementi un insieme finito \\(X\\) contiene, possiamo sempre costruire tre tipi speciali di sottoinsiemi. L’insieme vuoto \\(\\emptyset = \\{\\}\\) non contiene alcun elemento. D’altra parte, l’intero insieme stesso può essere considerato un sottoinsieme contenente tutti gli elementi. Un sottoinsieme contenente un singolo elemento è denotato \\(\\{ x_{n} \\}\\) ed è chiamato insieme atomico.\nCi sono\n\\[\n{N \\choose n} = \\frac{ N! }{ n! (N - n)!}\n\\]\nmodi per selezionare \\(n\\) elementi da un insieme finito di \\(N\\) elementi totali, e quindi \\({N \\choose n}\\) sottoinsiemi totali di dimensione \\(n\\). Ad esempio, esiste un solo sottoinsieme che non contiene alcun elemento,\n\\[\n{N \\choose 0} = \\frac{ N! }{ 0! (N - 0)!} = \\frac{ N! }{ N! } = 1,\n\\]\ned è l’insieme vuoto. Allo stesso modo, esiste un solo sottoinsieme che contiene tutti gli elementi,\n\\[\n{N \\choose N} = \\frac{ N! }{ N! (N - N)!} = \\frac{ N! }{ N! } = 1,\n\\]\ned è l’insieme completo stesso. D’altra parte, ci sono\n\\[\n{N \\choose 1} = \\frac{ N! }{ 1! (N - 1)!} = N\n\\]\ninsiemi atomici distinti che contengono un solo elemento, uno per ciascun elemento in \\(X\\).\nContando tutti i sottoinsiemi di tutte le dimensioni possibili si ottiene\n\\[\n\\sum_{n = 0}^{N} {N \\choose n} = 2^{N}\n\\]\nsottoinsiemi possibili che possiamo costruire da un insieme finito con \\(N\\) elementi.\nLa collezione di tutti i sottoinsiemi è essa stessa un insieme finito con \\(2^{N}\\) elementi. Chiamiamo questo insieme insieme potenza di \\(X\\) e lo denotiamo \\(2^{X}\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Misura di Probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_prob_spaces.html#operazioni-sui-sottoinsiemi",
    "href": "chapters/probability/02_prob_spaces.html#operazioni-sui-sottoinsiemi",
    "title": "27  Misura di Probabilità",
    "section": "27.4 Operazioni sui Sottoinsiemi",
    "text": "27.4 Operazioni sui Sottoinsiemi\nPossiamo sempre costruire sottoinsiemi elemento per elemento, ma possiamo anche costruirli manipolando sottoinsiemi esistenti.\nAd esempio, dato un sottoinsieme \\(\\mathsf{x} \\subset X\\) possiamo costruire il suo complemento raccogliendo tutti gli elementi in \\(X\\) che non sono già in \\(\\mathsf{x}\\). L’insieme atomico \\(\\mathsf{x} = \\{ \\diamondsuit \\}\\) contiene l’unico elemento \\(\\diamondsuit\\) e il suo complemento contiene i rimanenti elementi \\[\n\\mathsf{x}^{c} = \\{ \\Box, \\clubsuit, \\heartsuit, \\spadesuit \\}.\n\\] Per costruzione, il complemento dell’insieme vuoto è l’intero insieme, \\(\\emptyset^{c} = X\\), e il complemento dell’insieme completo è l’insieme vuoto, \\(X^{c} = \\emptyset\\).\n\n\n\n\n\n\nFigura 27.3: Il complemento di un sottoinsieme \\(\\mathsf{x}\\) è il sottoinsieme \\(\\mathsf{x}^{c}\\) costituito da tutti gli elementi nello spazio campionario che non sono in \\(\\mathsf{x}\\).\n\n\n\nAd esempio, applicando l’operatore di complemento al sottoinsieme \\(\\mathsf{x} = \\{ \\clubsuit, \\spadesuit \\}\\) otteniamo \\[\n\\mathsf{x}^{c}\n= \\{ \\clubsuit, \\spadesuit \\}^{c}\n= \\{ \\Box, \\diamondsuit, \\heartsuit \\}.\n\\]\nPossiamo anche costruire sottoinsiemi da più di un sottoinsieme. Consideriamo, ad esempio, due sottoinsiemi \\(\\mathsf{x}_1 = \\{ \\Box, \\heartsuit \\}\\) e \\(\\mathsf{x}_2 = \\{ \\Box, \\spadesuit \\}\\). La collezione di tutti gli elementi che sono contenuti in uno qualsiasi dei due sottoinsiemi è essa stessa un sottoinsieme, \\[\n\\{ \\Box, \\heartsuit, \\spadesuit \\} \\subset X,\n\\] così come la collezione di tutti gli elementi che sono contenuti in entrambi i sottoinsiemi, \\[\n\\{ \\Box \\} \\subset X.\n\\] Questi sottoinsiemi derivati sono chiamati rispettivamente unione, \\[\n\\mathsf{x}_1 \\cup \\mathsf{x}_2\n= \\{ \\Box, \\heartsuit \\} \\cup \\{ \\Box, \\spadesuit \\}\n= \\{ \\Box, \\heartsuit, \\spadesuit \\},\n\\] e intersezione, \\[\n\\mathsf{x}_1 \\cap \\mathsf{x}_2\n= \\{ \\Box, \\heartsuit \\} \\cap \\{ \\Box, \\spadesuit \\}\n= \\{ \\Box \\}.\n\\]\n\n\n\n\n\n\nFigura 27.4: Possiamo manipolare due sottoinsiemi in vari modi per ottenere un nuovo sottoinsieme.\n\n\n\n\n\n\n\n\n\nFigura 27.5: L’unione di due sottoinsiemi, \\(\\mathsf{x}_1 \\cup \\mathsf{x}_2\\), è un sottoinsieme contenente tutti gli elementi di entrambi i sottoinsiemi in input. D’altra parte, l’intersezione di due sottoinsiemi, \\(\\mathsf{x}_1 \\cap \\mathsf{x}_2\\), è un sottoinsieme contenente solo gli elementi che compaiono in entrambi i sottoinsiemi in input.\n\n\n\nDue sottoinsiemi sono disgiunti se non condividono alcun elemento; in questo caso la loro intersezione è l’insieme vuoto, \\[\n\\mathsf{x}_{1} \\cap \\mathsf{x}_{2} = \\emptyset.\n\\] L’unione e l’intersezione di un sottoinsieme con se stesso restituiscono quel sottoinsieme, \\[\n\\mathsf{x} \\cup \\mathsf{x} = \\mathsf{x} \\cap \\mathsf{x} = \\mathsf{x}.\n\\] Poiché l’insieme vuoto non contiene alcun elemento, la sua unione con qualsiasi sottoinsieme restituisce quel sottoinsieme, \\[\n\\mathsf{x} \\cup \\emptyset = \\emptyset \\cup \\mathsf{x} = \\mathsf{x},\n\\] e la sua intersezione con qualsiasi sottoinsieme restituisce l’insieme vuoto, \\[\n\\mathsf{x} \\cap \\emptyset = \\emptyset \\cap \\mathsf{x} = \\emptyset.\n\\] Allo stesso modo, l’unione di un sottoinsieme con l’insieme completo restituisce l’insieme completo, \\[\n\\mathsf{x} \\cup X = X \\cup \\mathsf{x} = X,\n\\] e l’intersezione di un sottoinsieme con l’insieme completo restituisce quel sottoinsieme, \\[\n\\mathsf{x} \\cap X = X \\cap \\mathsf{x} = \\mathsf{x}.\n\\]",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Misura di Probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_prob_spaces.html#misura-e-probabilità-sugli-elementi",
    "href": "chapters/probability/02_prob_spaces.html#misura-e-probabilità-sugli-elementi",
    "title": "27  Misura di Probabilità",
    "section": "27.5 Misura e Probabilità sugli Elementi",
    "text": "27.5 Misura e Probabilità sugli Elementi\nDa un punto di vista matematico, la teoria della misura riguarda l’allocazione coerente di una qualche quantità astratta attraverso lo spazio campionario. Consideriamo un serbatoio (il termine standard in questo contesto sarebbe “misura totale” o “massa totale”) di una qualche quantità positiva, continua e conservata, \\(M \\in [0, \\infty]\\). Poiché \\(M\\) è conservato, qualsiasi quantità \\(m_{n}\\) che viene allocata all’elemento \\(x_{n} \\in X\\) deve essere detratta dal serbatoio, lasciando meno da allocare agli altri elementi.\nUn caso particolare si verifica quando il contenuto totale del serbatoio \\(M\\) è infinito. In questo scenario, possiamo allocare una quantità infinita dal serbatoio pur avendo ancora una quantità infinita rimanente. Allo stesso tempo, allocare una quantità infinita può esaurire completamente il serbatoio o lasciare qualsiasi quantità finita residua. L’infinito è un concetto matematicamente complesso da trattare.\n\n\n\n\n\n\nFigura 27.6: La teoria della misura riguarda l’allocazione di una qualche quantità continua e positiva \\(M\\) sugli elementi individuali dello spazio campionario.\n\n\n\nUn’allocazione esaustiva di \\(M\\) su tutto lo spazio campionario assicura che il serbatoio sia completamente svuotato. In altre parole, l’intero valore di \\(M\\) deve essere distribuito tra gli elementi \\(x_{n} \\in X\\).\nPer illustrare questo concetto, consideriamo il nostro spazio campionario dimostrativo \\(X = \\{\\Box, \\clubsuit, \\diamondsuit, \\heartsuit, \\spadesuit \\}\\). Il processo di allocazione può essere descritto come segue:\n\nAllocchiamo \\(m_\\Box\\) a \\(\\Box\\), lasciando \\(M - m_\\Box\\) nel serbatoio.\nAssegniamo \\(m_\\clubsuit\\) a \\(\\clubsuit\\), riducendo ulteriormente il contenuto del serbatoio a \\(M - m_\\Box - m_\\clubsuit\\).\nContinuiamo questo processo per \\(\\diamondsuit\\) e \\(\\heartsuit\\).\nInfine, per svuotare completamente il serbatoio, dobbiamo allocare tutto ciò che rimane a \\(\\spadesuit\\).\n\nMatematicamente, l’ammontare finale allocato a \\(\\spadesuit\\) sarà:\n\\[\nM - m_{\\Box} - m_{\\clubsuit} - m_{\\diamondsuit} - m_{\\heartsuit}.\n\\]\nQuesta allocazione finale assicura che la somma di tutte le quantità distribuite sia esattamente uguale a \\(M\\), svuotando così completamente il serbatoio.\n\n\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c)\n\n\n\n\n\n\n\n\n\n\n\n(d)\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n(e)\n\n\n\n\n\n \n\n\n\n\nFigura 27.7: Poiché la quantità totale \\(M\\) è conservata, ogni allocazione \\(m_{n}\\) a un elemento \\(x_{n} \\in X\\) riduce la quantità disponibile per l’allocazione agli altri elementi. Un’allocazione esaustiva non lascia nulla nel serbatoio iniziale dopo che ciascun elemento ha ricevuto la sua allocazione.\n\n\n\nUna misura è qualsiasi allocazione coerente della quantità \\(M\\) agli elementi di uno spazio campionario. Matematicamente, qualsiasi misura su un insieme finito può essere caratterizzata da \\(N\\) numeri \\[\n\\mu = \\{ m_{1}, \\ldots, m_{N} \\}\n\\] che soddisfano \\[\n0 \\le m_{n}\n\\] e \\[\n\\sum_{n = 1}^{N} m_{n} = M.\n\\] Ad esempio, qualsiasi misura sui cinque elementi dell’insieme \\(X = \\{\\Box, \\clubsuit, \\diamondsuit, \\heartsuit, \\spadesuit\\}\\) è specificata da cinque numeri positivi \\(\\{ m_\\Box, m_\\clubsuit, m_\\diamondsuit, m_\\heartsuit, m_\\spadesuit \\}\\) che soddisfano \\[\nm_\\Box + m_\\clubsuit + m_\\diamondsuit + m_\\heartsuit + m_\\spadesuit = M.\n\\]\n\n\n\n\n\n\nFigura 27.8: Una misura \\(\\mu\\) su un insieme finito \\(X\\) è qualsiasi allocazione coerente di \\(M\\) agli elementi $x_{n} X. Ogni misura può essere caratterizzata da \\(N\\) numeri \\(m_{n}\\) che sommano a \\(M\\), o equivalentemente una funzione che mappa ogni elemento \\(x_{n}\\) alla sua misura allocata \\(m_{n}\\).\n\n\n\nPiù grande è \\(m_{n}\\), più di \\(M\\) viene allocato all’elemento \\(x_{n}\\). Seguendo questa terminologia, chiameremo anche \\(M\\) come la misura totale e \\(m_{n}\\) come la misura allocata a \\(x_{n}\\).\nIn questa discussione, ci occuperemo solo di misure finite, dove la misura totale \\(M\\) è un numero positivo e finito (\\(0 \\leq M \\leq \\infty\\)). Non tratteremo il caso di misure infinite (\\(M = \\infty\\)), poiché richiede considerazioni più complesse che vanno oltre lo scopo di questa trattazione.\nUna misura \\(\\mu\\) su uno spazio campionario \\(X\\) può essere vista come una funzione che assegna un valore numerico non negativo (la misura) a ogni elemento dello spazio:\n\\[\n\\begin{alignat*}{6}\n\\mu :\\; & X & &\\rightarrow& \\; & [0, \\infty] &\n\\\\\n& x_{n} & &\\mapsto& & m_{n} = \\mu(x_{n}) &,\n\\end{alignat*}\n\\] dove:\n\n\\(X\\) è lo spazio campionario,\n\\(x_n\\) è un elemento di \\(X\\),\n\\(m_n\\) è la misura assegnata a \\(x_n\\).\n\nQuesto approccio funzionale ci permette di considerare ogni elemento dello spazio campionario separatamente, valutando \\(\\mu(x_{n})\\) per ciascun \\(x_{n}\\), invece di dover gestire tutte le allocazioni contemporaneamente.\nÈ importante notare che esistono molti modi diversi per distribuire una misura totale \\(M\\) tra gli elementi di un insieme finito. L’insieme di tutte le possibili misure su \\(X\\) si indica con \\(\\mathcal{M}(X)\\).\nAll’interno di questa collezione ci sono alcuni esempi notevoli. Ad esempio, una misura singolare alloca la misura totale \\(M\\) a un singolo elemento, lasciando il resto con niente. D’altra parte, una misura uniforme alloca la stessa misura \\(M / N\\) a ciascun elemento. Su insiemi finiti ci sono \\(N\\) misure singolari distinte, una per ciascun elemento distinto, e una misura uniforme unica.\n\n\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\n\nFigura 27.9: Una misura singolare (a) alloca la misura totale a un singolo elemento, mentre la misura uniforme (b) distribuisce la misura totale uniformemente a ciascun elemento.\n\n\n\nLe misure finite sono una categoria particolarmente importante nel campo della teoria della misura. Una misura si definisce finita quando la sua misura totale \\(M\\) è un numero positivo e limitato, ovvero \\(0 &lt; M &lt; \\infty\\).\nL’importanza delle misure finite risiede nella possibilità di esprimere le allocazioni in termini relativi anziché assoluti. Questo significa che possiamo rappresentare la misura di ciascun elemento come una frazione o una percentuale della misura totale, invece di usare il valore assoluto. Invece di considerare la misura assoluta allocata a ciascun elemento \\(m_{n}\\), possiamo considerare la proporzione della misura totale allocata a ciascun elemento \\[\np_{n} = m_{n} / M.\n\\] Per costruzione, le proporzioni sono confinate all’intervallo unitario \\([0, 1]\\). Come per qualsiasi quantità che assume valori in \\([0, 1]\\), possiamo rappresentare le proporzioni altrettanto bene con decimali, ad esempio \\(p_{n} = 0.2\\), e percentuali, \\(p_{n} = 20\\%\\).\nQuesto approccio relativo offre diversi vantaggi: permette di confrontare facilmente l’importanza relativa di diversi elementi, facilita la comprensione della distribuzione della misura sull’intero spazio campionario e consente di normalizzare misure diverse, rendendo più semplice il confronto tra sistemi diversi. In sintesi, le misure finite ci permettono di passare da una visione “assoluta” a una “relativa” della distribuzione della misura, offrendo una prospettiva più intuitiva e utile per l’analisi.\n\n\n\n\n\n\nFigura 27.10: Ogni misura finita può essere caratterizzata da un’allocazione proporzionale.\n\n\n\nIn altre parole, una misura proporzionale definisce la funzione \\[\n\\begin{alignat*}{6}\n\\pi :\\; & X & &\\rightarrow& \\; & [0, 1] &\n\\\\\n& x_{n} & &\\mapsto& & p_{n} = \\pi(x_{n}) &\n\\end{alignat*}\n\\] con \\[\n0 \\le p_{n} \\le 1\n\\] e \\[\n\\sum_{n = 1}^{N} p_{n} = 1.\n\\] Una collezione di variabili \\(\\{ p_{1}, \\ldots, p_{N} \\}\\) che soddisfano queste proprietà è chiamata simplex.\n\n\n\n\n\n\nFigura 27.11: Un’allocazione proporzionale è anche conosciuta come distribuzione di probabilità.\n\n\n\nPiù importante, una misura proporzionale \\(\\pi\\) è anche conosciuta come distribuzione di probabilità, e le allocazioni proporzionali \\(p_{n}\\) sono chiamate probabilità. Sebbene il termine “probabilità” sia spesso carico di significati interpretativi e filosofici, la sua struttura matematica è piuttosto semplice: su un insieme finito, una probabilità rappresenta semplicemente la proporzione di una quantità finita assegnata a ciascun elemento individuale.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Misura di Probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_prob_spaces.html#misura-e-probabilità-sui-sottoinsiemi",
    "href": "chapters/probability/02_prob_spaces.html#misura-e-probabilità-sui-sottoinsiemi",
    "title": "27  Misura di Probabilità",
    "section": "27.6 Misura e Probabilità sui Sottoinsiemi",
    "text": "27.6 Misura e Probabilità sui Sottoinsiemi\nSugli insiemi finiti, qualsiasi allocazione, sia assoluta che proporzionale, agli elementi individuali \\(x \\in X\\) determina anche un’allocazione per i sottoinsiemi \\(\\mathsf{x} \\in 2^{X}\\). La misura assegnata a un sottoinsieme è semplicemente la somma delle misure assegnate agli elementi che lo compongono. Ad esempio, la misura assegnata al sottoinsieme \\(\\mathsf{x} = \\{ \\Box, \\clubsuit, \\heartsuit \\}\\) è \\(m_{\\Box} + m_{\\clubsuit} + m_{\\heartsuit}\\).\n\n\n\n\n\n\nFigura 27.12: Su un insieme finito, un’allocazione sugli elementi individuali definisce anche un’allocazione su qualsiasi sottoinsieme.\n\n\n\nPer costruzione, qualsiasi misura sui sottoinsiemi e distribuzione di probabilità soddisfano una serie di proprietà utili. Ad esempio, per qualsiasi misura \\[\n\\mu( \\emptyset ) = 0\n\\] e \\[\n\\mu( X ) = \\sum_{n = 1}^{N} \\mu(x_{n}) = M,\n\\] mentre per qualsiasi distribuzione di probabilità abbiamo \\(\\pi( \\emptyset ) = 0\\) e \\(\\pi( X ) = 1\\).\nLe allocazioni sui sottoinsiemi si combinano in modo naturale con le operazioni sui sottoinsiemi. Consideriamo, ad esempio, i due sottoinsiemi disgiunti \\(\\mathsf{x}_{1} = \\{ \\Box, \\diamondsuit \\}\\) e \\(\\mathsf{x}_{2} = \\{ \\clubsuit, \\spadesuit \\}\\). Poiché i due sottoinsiemi sono disgiunti, la loro unione include semplicemente tutti i loro elementi:\n\\[\n\\mathsf{x}_{1} \\cup \\mathsf{x}_{2}\n=\n\\{ \\Box, \\diamondsuit \\} \\cup \\{ \\clubsuit, \\spadesuit \\}\n=\n\\{ \\Box, \\clubsuit, \\diamondsuit, \\spadesuit \\},\n\\]\ne la misura di questa unione è solo la somma delle misure dei due sottoinsiemi:\n\\[\n\\begin{align*}\n\\mu ( \\mathsf{x}_{1} \\cup \\mathsf{x}_{2} )\n&=\n\\mu ( \\{ \\Box, \\clubsuit, \\diamondsuit, \\spadesuit \\} )\n\\\\\n&=\nm_{\\Box} + m_{\\clubsuit} + m_{\\diamondsuit} + m_{\\spadesuit}\n\\\\\n&=\n( m_{\\Box} + m_{\\diamondsuit} ) + ( m_{\\clubsuit} + m_{\\spadesuit} )\n\\\\\n&=\n\\mu( \\mathsf{x}_{1} ) + \\mu( \\mathsf{x}_{2} ).\n\\end{align*}\n\\]\nPiù in generale, per qualsiasi collezione di sottoinsiemi\n\\[\n\\mathsf{x}_{1}, \\ldots, \\mathsf{x}_{K}\n\\]\nche sono reciprocamente disgiunti,\n\\[\n\\mathsf{x}_{k} \\cap \\mathsf{x}_{k'} = \\emptyset \\quad \\text{per} \\quad k \\ne k',\n\\]\nabbiamo\n\\[\n\\mu ( \\cup_{k = 1}^{K} \\mathsf{x}_{k} )\n=\n\\sum_{k = 1}^{K} \\mu ( \\mathsf{x}_{k} ).\n\\]\nIn altre parole, se possiamo scomporre un sottoinsieme in una collezione di sottoinsiemi più piccoli e disgiunti, possiamo anche scomporre la misura allocata a quel sottoinsieme iniziale nelle misure allocate ai sottoinsiemi componenti. Questa proprietà di coerenza è chiamata additività.\nUn sottoinsieme \\(\\mathsf{x}\\) e il suo complemento \\(\\mathsf{x}^{c}\\) sono sempre disgiunti, ovvero \\(\\mathsf{x} \\cap \\mathsf{x}^{c} = \\emptyset\\). Allo stesso tempo, la loro unione copre l’intero insieme: \\(\\mathsf{x} \\cup \\mathsf{x}^{c} = X\\). Di conseguenza, l’additività implica che:\n\\[\n\\begin{align*}\nM &= \\mu (X) \\\\\n  &= \\mu ( \\mathsf{x} \\cup \\mathsf{x}^{c} ) \\\\\n  &= \\mu ( \\mathsf{x} ) + \\mu ( \\mathsf{x}^{c} ),\n\\end{align*}\n\\]\nda cui segue che:\n\\[\n\\mu ( \\mathsf{x}^{c} ) = M - \\mu ( \\mathsf{x} ).\n\\]\nIn altre parole, la misura assegnata al complemento di un sottoinsieme è la misura totale meno la misura assegnata a quel sottoinsieme. Per le distribuzioni di probabilità, questo concetto è ancora più evidente:\n\\[\n\\pi ( \\mathsf{x}^{c} ) = 1 - \\pi ( \\mathsf{x} ).\n\\]\nQuando due sottoinsiemi si sovrappongono, dobbiamo considerare che la somma delle loro misure \\(\\mu (\\mathsf{x}_{1} ) + \\mu ( \\mathsf{x}_{2} )\\) conta due volte la misura degli elementi condivisi tra di essi. Ad esempio, se \\(\\mathsf{x}_{1} = \\{ \\Box, \\heartsuit \\}\\) e \\(\\mathsf{x}_{2} = \\{ \\Box, \\spadesuit \\}\\), allora l’unione include l’elemento sovrapposto \\(\\Box\\) solo una volta:\n\\[\n\\mathsf{x}_{1} \\cup \\mathsf{x}_{2} = \\{ \\Box, \\heartsuit \\} \\cup \\{ \\Box, \\spadesuit \\} = \\{ \\Box, \\heartsuit, \\spadesuit \\}.\n\\]\nDi conseguenza:\n\\[\n\\begin{align*}\n\\mu( \\mathsf{x}_{1} \\cup \\mathsf{x}_{2} ) &= \\mu( \\{ \\Box, \\heartsuit, \\spadesuit \\} ) \\\\\n&= m_{\\Box} + m_{\\heartsuit} + m_{\\spadesuit}.\n\\end{align*}\n\\]\nSommando le misure allocate ai due sottoinsiemi individualmente, tuttavia, otteniamo:\n\\[\n\\begin{align*}\n\\mu( \\mathsf{x}_{1} ) + \\mu ( \\mathsf{x}_{2} ) &= (m_{\\Box} + m_{\\heartsuit} ) + ( m_{\\Box} + m_{\\spadesuit} ) \\\\\n&= m_{\\Box} + m_{\\Box} + m_{\\heartsuit} + m_{\\spadesuit} \\\\\n&= m_{\\Box} + \\mu( \\mathsf{x}_{1} \\cup \\mathsf{x}_{2} ).\n\\end{align*}\n\\]\nL’elemento che viene contato due volte è esattamente l’unico elemento nell’intersezione dei due sottoinsiemi:\n\\[\nm_{\\Box} = \\mu( \\{ \\Box \\} ) = \\mu( \\mathsf{x}_{1} \\cap \\mathsf{x}_{2} ).\n\\]\nIn altre parole, possiamo scrivere:\n\\[\n\\mu( \\mathsf{x}_{1} ) + \\mu ( \\mathsf{x}_{2} ) = \\mu( \\mathsf{x}_{1} \\cup \\mathsf{x}_{2} ) + \\mu( \\mathsf{x}_{1} \\cap \\mathsf{x}_{2} ).\n\\]\nQuesta relazione vale per qualsiasi due sottoinsiemi, indipendentemente dalla loro sovrapposizione.\n\n\n\n\n\n\nFigura 27.13: Quando due sottoinsiemi si sovrappongono, la misura allocata a ciascuno conta doppio la misura allocata a qualsiasi elemento sovrapposto, qui \\(\\Box\\), ma la misura allocata alla loro unione no. Questo risulta in una relazione importante tra le misure allocate ai due sottoinsiemi, la misura allocata alla loro unione e la misura allocata alla loro intersezione.\n\n\n\nQueste proprietà dei sottoinsiemi ci permettono di costruire una misura in molti modi diversi, ciascuno dei quali può essere utile in circostanze diverse. Questa flessibilità è molto comoda quando si applica la teoria della misura e la teoria della probabilità nella pratica.\nAd esempio, possiamo specificare una misura in due modi principali:\n\nAllocazione globale: possiamo assegnare le misure a tutti gli elementi individuali contemporaneamente. Questo metodo considera l’intero insieme fin dall’inizio e assegna una misura a ciascun elemento.\n\n\n\n\n\n\n\nFigura 27.14: Le misure possono essere costruite specificando le allocazioni degli elementi individuali tutte insieme.\n\n\n\n\nAllocazione locale: possiamo assegnare la misura a ciascun elemento uno alla volta. Questo metodo permette di concentrarsi su un elemento alla volta, aggiungendo gradualmente le misure agli altri elementi.\n\n\n\n\n\n\n\nFigura 27.15: Allo stesso tempo, le misure possono essere costruite specificando le allocazioni degli elementi individuali uno alla volta.\n\n\n\nInoltre, non è sempre necessario partire dalle allocazioni individuali. Un altro metodo consiste nel:\n\nAllocazione iterativa: possiamo iniziare allocando la misura totale a sottoinsiemi disgiunti e poi affinare iterativamente questa allocazione suddividendo i sottoinsiemi in parti sempre più piccole fino a raggiungere gli elementi individuali.\n\n\n\n\n\n\n\nFigura 27.16: Le misure possono anche essere costruite allocando la misura totale a sottoinsiemi disgiunti e poi raffinando iterativamente tale allocazione a sottoinsiemi sempre più piccoli.\n\n\n\nQuesta flessibilità nelle modalità di costruzione delle misure è particolarmente utile perché permette di adattare l’approccio alle specifiche necessità del problema in questione. Ad esempio, nella pratica, potremmo trovare più semplice allocare inizialmente misure a grandi gruppi di elementi e poi suddividere questi gruppi, oppure potremmo voler assegnare le misure a ciascun elemento uno per uno a seconda delle esigenze del contesto.\nInfine, la definizione di misura sui sottoinsiemi \\(\\mu : 2^{X} \\rightarrow [0, \\infty]\\) è cruciale per estendere la teoria della misura oltre gli insiemi finiti. Questa estensione è necessaria per definire misure in modo coerente su insiemi matematicamente più complessi, come la retta reale.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Misura di Probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_prob_spaces.html#riflessioni-conclusive",
    "href": "chapters/probability/02_prob_spaces.html#riflessioni-conclusive",
    "title": "27  Misura di Probabilità",
    "section": "27.7 Riflessioni Conclusive",
    "text": "27.7 Riflessioni Conclusive\nIl significato applicativo delle nozioni di misura e distribuzione di probabilità è centrale per comprendere come utilizzare questi concetti nella pratica, in particolare nella statistica bayesiana. Il punto cruciale è capire cosa rappresenta \\(M\\), la “misura totale”. Nelle applicazioni bayesiane, \\(M\\) rappresenta la nostra certezza complessiva.\nQuando si lavora con distribuzioni di probabilità, stiamo effettivamente allocando questa certezza complessiva tra diversi eventi possibili. Una distribuzione (di massa) di probabilità è quindi l’allocazione relativa della nostra certezza tra un insieme di eventi disgiunti. Ogni probabilità individuale, \\(p_n\\), rappresenta la proporzione della nostra certezza totale che assegniamo a un particolare evento.\nNella teoria bayesiana, la “misura totale” \\(M\\) è interpretata come la somma totale delle probabilità, che è sempre uguale a 1. Questo riflette il fatto che la somma delle nostre certezze relative per tutti gli eventi possibili deve essere completa: siamo completamente certi che uno degli eventi nel nostro spazio campionario si verificherà.\nQuando creiamo una distribuzione di probabilità, stiamo dividendo questa certezza totale tra i vari eventi possibili nel nostro spazio campionario. Ad esempio, se stiamo analizzando un problema con cinque possibili esiti distinti, dobbiamo allocare l’intera certezza (pari a 1) tra questi esiti. Ogni valore di probabilità \\(p_n\\) rappresenta la frazione della nostra certezza totale che attribuiamo a un particolare esito.\nIn conclusione, le nozioni di misura e distribuzione di probabilità sono strumenti potenti per allocare e manipolare la nostra certezza tra diversi eventi possibili. Comprendere questi concetti è fondamentale per comprendere le applicazioni della teoria della probabilità e della statistica. La “misura totale” \\(M\\) rappresenta la nostra certezza complessiva, e le distribuzioni di probabilità ci permettono di distribuire questa certezza in modo coerente e informato tra gli eventi possibili.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Misura di Probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_prob_spaces.html#esercizi",
    "href": "chapters/probability/02_prob_spaces.html#esercizi",
    "title": "27  Misura di Probabilità",
    "section": "Esercizi",
    "text": "Esercizi\nDal testo di Blitzstein & Hwang (2019), svolgere i seguenti esercizi: 1.4.3, 1.4.4, 1.4.5, 1.4.6, 1.4.9, 1.4.12, 1.4.13.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Misura di Probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_prob_spaces.html#bibliografia",
    "href": "chapters/probability/02_prob_spaces.html#bibliografia",
    "title": "27  Misura di Probabilità",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlitzstein, J. K., & Hwang, J. (2019). Introduction to probability. CRC Press.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Misura di Probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html",
    "href": "chapters/probability/03_prob_on_general_spaces.html",
    "title": "28  Fondamenti della probabilità",
    "section": "",
    "text": "28.1 Introduzione\nNel Capitolo 27 abbiamo introdotto la teoria della misura e della probabilità su insiemi con un numero finito di elementi. Tuttavia, molti degli spazi matematici che incontriamo nelle applicazioni pratiche, come gli interi e la retta reale, non hanno un numero finito di elementi, ma piuttosto un numero numerabile infinito o addirittura non numerabile infinito di elementi. Sfortunatamente, estendere la teoria della misura e della probabilità a spazi più generali come questi non è sempre semplice.\nSenza entrare nei dettagli, è stato dimostrato che la forma più generale della teoria della misura e della probabilità applicabile a qualsiasi spazio matematico è chiamata \\(\\sigma\\)-algebra. In questo capitolo, forniremo un’introduzione intuitiva ai vincoli delle \\(\\sigma\\)-algebre ed esamineremo alcune notevoli applicazioni. In particolare, introdurremo i concetti di variabile casuale, funzioni di massa di probabilità e funzioni di ripartizione.\nQuesti concetti sono fondamentali per comprendere come la probabilità e la misura possono essere utilizzate in contesti più complessi, permettendo di estendere le nostre analisi a insiemi infiniti e spazi continui, che sono comuni nelle applicazioni psicologiche.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Fondamenti della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#sigma-algebra",
    "href": "chapters/probability/03_prob_on_general_spaces.html#sigma-algebra",
    "title": "28  Fondamenti della probabilità",
    "section": "\n28.2 \\(\\sigma\\)-Algebra",
    "text": "28.2 \\(\\sigma\\)-Algebra\nUna \\(\\sigma\\)-algebra è una struttura matematica che permette di definire in modo coerente quali sottoinsiemi di un insieme sono “misurabili”.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Fondamenti della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#definizione-di-sigma-algebra",
    "href": "chapters/probability/03_prob_on_general_spaces.html#definizione-di-sigma-algebra",
    "title": "28  Fondamenti della probabilità",
    "section": "\n28.3 Definizione di \\(\\sigma\\)-Algebra",
    "text": "28.3 Definizione di \\(\\sigma\\)-Algebra\nUna \\(\\sigma\\)-algebra è una collezione di sottoinsiemi di uno spazio \\(X\\) che soddisfa le seguenti proprietà:\n\nChiusura rispetto al complemento: Se un sottoinsieme \\(A\\) appartiene alla \\(\\sigma\\)-algebra \\(\\mathcal{F}\\), allora anche il suo complemento \\(A^c\\) appartiene a \\(\\mathcal{F}\\). Questo significa che se \\(\\mathcal{F}\\) contiene un certo sottoinsieme, deve contenere anche tutti gli elementi che non sono in quel sottoinsieme.\nChiusura rispetto alle unioni numerabili: Se una sequenza numerabile di sottoinsiemi \\(A_1, A_2, A_3, \\ldots\\) appartiene alla \\(\\sigma\\)-algebra \\(\\mathcal{F}\\), allora anche l’unione di tutti questi sottoinsiemi appartiene a \\(\\mathcal{F}\\). Questo implica che se \\(\\mathcal{F}\\) contiene una serie di sottoinsiemi, deve contenere anche il loro insieme unito.\nInclusione dello spazio campionario: Lo spazio campionario \\(X\\) stesso deve appartenere alla \\(\\sigma\\)-algebra \\(\\mathcal{F}\\). In altre parole, l’intero insieme \\(X\\) è considerato un sottoinsieme misurabile.\n\nLa chiusura in questo contesto significa che la collezione \\(\\mathcal{F}\\) è stabile rispetto a determinate operazioni insiemistiche. In particolare, se si applicano le operazioni di complemento o di unione numerabile a elementi della \\(\\sigma\\)-algebra, i risultati di queste operazioni rimarranno all’interno della stessa \\(\\sigma\\)-algebra. Questo garantisce che la \\(\\sigma\\)-algebra non “perda” elementi a causa di queste operazioni, mantenendo così la coerenza e la completezza della collezione di sottoinsiemi.\n\n28.3.1 Spazio Misurabile\nUn insieme dotato di una \\(\\sigma\\)-algebra, \\((X, \\mathcal{X})\\), è detto spazio misurabile. Gli elementi di una \\(\\sigma\\)-algebra sono noti come sottoinsiemi misurabili, mentre i sottoinsiemi non appartenenti alla \\(\\sigma\\)-algebra sono detti non misurabili. La distinzione tra sottoinsiemi misurabili e non misurabili è cruciale per evitare comportamenti anomali e controintuitivi nella teoria della misura e della probabilità.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Fondamenti della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#gli-assiomi-di-kolmogorov",
    "href": "chapters/probability/03_prob_on_general_spaces.html#gli-assiomi-di-kolmogorov",
    "title": "28  Fondamenti della probabilità",
    "section": "\n28.4 Gli Assiomi di Kolmogorov",
    "text": "28.4 Gli Assiomi di Kolmogorov\nUna volta definita una \\(\\sigma\\)-algebra, è possibile introdurre la probabilità come una misura definita su questa collezione di sottoinsiemi. Gli assiomi di Kolmogorov stabiliscono le proprietà fondamentali che ogni funzione di probabilità deve soddisfare:\n\n\nNon negatività: Per qualsiasi evento \\(A\\) nello spazio campionario \\(\\Omega\\), la probabilità di \\(A\\) è non negativa.\n\\[\nP(A) \\geq 0.\n\\]\n\n\nNormalizzazione: La probabilità dell’intero spazio campionario \\(\\Omega\\) è 1.\n\\[\nP(\\Omega) = 1.\n\\]\n\n\nAdditività numerabile: Per qualsiasi sequenza di eventi mutuamente esclusivi \\({A_i}_{i=1}^\\infty \\subset \\mathcal{F}\\) (cioè \\(A_i \\cap A_j = \\varnothing\\) per \\(i \\neq j\\)), la probabilità della loro unione è la somma delle loro probabilità.\n\\[\nP\\left(\\bigcup_{i=1}^{\\infty} A_i\\right) = \\sum_{i=1}^{\\infty} P(A_i).\n\\]\n\n\n\n28.4.1 Connessione tra \\(\\sigma\\)-Algebra e Probabilità\nGli assiomi di Kolmogorov richiedono una \\(\\sigma\\)-algebra \\(\\mathcal{F}\\) come base per definire una misura di probabilità \\(P\\). La \\(\\sigma\\)-algebra delimita l’insieme di sottoinsiemi dello spazio \\(X\\) per i quali la probabilità è ben definita.\n\n\nNon negatività La misura di probabilità assegna un valore non negativo a ogni evento in \\(\\mathcal{F}\\).\n\nNormalizzazione garantisce che \\(P(\\Omega) = 1\\), garantendo coerenza nella distribuzione della probabilità.\n\nAdditività numerabile: La chiusura della \\(\\sigma\\)-algebra rispetto alle unioni numerabili consente di applicare l’additività anche a collezioni infinite di eventi.\n\nIn sintesi, gli assiomi di Kolmogorov richiedono una \\(\\sigma\\)-algebra come struttura all’interno della quale queste proprietà valgono. La \\(\\sigma\\)-algebra è quindi la collezione di eventi per i quali la misura di probabilità è ben definita e coerente con gli assiomi di Kolmogorov.\n\n28.4.1.1 Esempio di \\(\\sigma\\)-Algebra\nConsideriamo lo spazio campionario \\(\\Omega = {1, 2, 3}\\). Una possibile \\(\\sigma\\)-algebra su \\(\\Omega\\) è:\n\\(\\mathcal{F}\\) = {\\(\\varnothing\\),{1},{2,3}, {1, 2, 3}}.\nQuesta \\(\\sigma\\)-algebra soddisfa tutte le proprietà richieste:\n\nLo spazio campionario \\(\\Omega\\) e l’insieme vuoto \\(\\varnothing\\) appartengono a \\(\\mathcal{F}\\).\nIl complemento di ogni sottoinsieme in \\(\\mathcal{F}\\) appartiene ancora a \\(\\mathcal{F}\\).\nL’unione di qualsiasi collezione di sottoinsiemi in \\(\\mathcal{F}\\) appartiene a \\(\\mathcal{F}\\).\n\nIn conclusione, la \\(\\sigma\\)-algebra è un concetto essenziale nella teoria della probabilità, poiché delimita quali eventi possono essere misurati e assegnati una probabilità. Attraverso gli assiomi di Kolmogorov, questa struttura consente di costruire un sistema probabilistico coerente, garantendo che la probabilità sia definita in modo rigoroso e che operazioni come complemento, unione e intersezione numerabili siano sempre ben poste.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Fondamenti della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#probabilità",
    "href": "chapters/probability/03_prob_on_general_spaces.html#probabilità",
    "title": "28  Fondamenti della probabilità",
    "section": "\n28.5 Probabilità",
    "text": "28.5 Probabilità\nUna volta definiti gli assiomi di Kolmogorov, è possibile introdurre formalmente il concetto di probabilità.\nLa probabilità di un evento è una misura numerica che quantifica il grado di fiducia nel verificarsi di tale evento, in accordo con gli assiomi di Kolmogorov. Più precisamente:\n\nSe \\(P(A) = 0\\), l’evento \\(A\\) è impossibile.\nSe \\(P(A) = 1\\), l’evento \\(A\\) è certo.\n\nPer indicare la probabilità che un evento \\(A\\) non si verifichi, si usa la notazione \\(P(A^c)\\), dove:\n\\[\nP(A^c) = 1 - P(A).\n\\]\n\n28.5.1 Proprietà Derivate dagli Assiomi di Kolmogorov\nGli assiomi di Kolmogorov implicano alcune proprietà fondamentali, tra cui:\n\n\n\\(P(\\varnothing) = 0\\) (la probabilità dell’evento impossibile è nulla),\n\n\\(0 \\leq P(A) \\leq 1\\) (la probabilità è sempre compresa tra 0 e 1),\n\n\\(P(A^c) = 1 - P(A)\\) (probabilità del complemento),\nSe \\(A \\subset B\\), allora \\(P(A) \\leq P(B)\\) (monotonia),\nSe \\(A \\cap B = \\varnothing\\), allora \\(P(A \\cup B) = P(A) + P(B)\\) (additività per eventi incompatibili).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Fondamenti della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#regola-della-somma",
    "href": "chapters/probability/03_prob_on_general_spaces.html#regola-della-somma",
    "title": "28  Fondamenti della probabilità",
    "section": "\n28.6 Regola della Somma",
    "text": "28.6 Regola della Somma\nLa regola della somma permette di calcolare la probabilità dell’unione di due eventi \\(A\\) e \\(B\\), cioè la probabilità che si verifichi \\(A\\) oppure \\(B\\). La formula dipende dal fatto che i due eventi siano incompatibili (mutuamente esclusivi) o meno.\n\n28.6.1 Caso 1: Eventi incompatibili\nDue eventi \\(A\\) e \\(B\\) sono detti incompatibili o mutuamente esclusivi se non possono verificarsi contemporaneamente. In altre parole, la probabilità della loro intersezione è nulla:\n\\[\nP(A \\cap B) = 0.\n\\]\nIn questo caso, la probabilità dell’unione di \\(A\\) e \\(B\\) si calcola semplicemente sommando le probabilità individuali:\n\\[\nP(A \\text{ oppure } B) = P(A) + P(B).\n\\]\n\n28.6.1.1 Rappresentazione grafica\nNei diagrammi, gli eventi incompatibili sono rappresentati come aree che non si sovrappongono. La probabilità dell’unione corrisponde alla somma delle aree associate ai due eventi.\n\n28.6.1.2 Esempio: Negazione di un evento\nUn esempio classico di eventi incompatibili si ha quando \\(B\\) è il complemento di \\(A\\), ovvero \\(B = A^c\\). Poiché \\(A\\) oppure \\(A^c\\) rappresenta l’intero spazio campionario, la loro somma deve essere uguale a 1:\n\\[\nP(A) + P(A^c) = 1.\n\\]\nDa questa relazione segue che:\n\\[\nP(A^c) = 1 - P(A).\n\\]\n\n28.6.2 Caso 2: Eventi non incompatibili\nQuando i due eventi \\(A\\) e \\(B\\) possono verificarsi contemporaneamente, si deve tener conto della probabilità della loro intersezione \\(P(A \\cap B)\\). In questo caso, la regola della somma diventa:\n\\[\nP(A \\text{ oppure } B) = P(A) + P(B) - P(A \\cap B).\n\\]\n\n28.6.2.1 Perché sottrarre \\(P(A \\cap B)\\)?\nIl termine \\(P(A \\cap B)\\) rappresenta la probabilità che entrambi gli eventi si verifichino. Poiché questa probabilità è già inclusa in \\(P(A)\\) e in \\(P(B)\\), sottrarla evita di conteggiarla due volte.\n\n28.6.2.2 Rappresentazione grafica\nIn un diagramma, gli eventi non incompatibili sono rappresentati da aree che si sovrappongono. La probabilità dell’unione corrisponde alla somma delle aree associate ai due eventi, meno l’area della sovrapposizione.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Fondamenti della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#legge-della-probabilità-totale",
    "href": "chapters/probability/03_prob_on_general_spaces.html#legge-della-probabilità-totale",
    "title": "28  Fondamenti della probabilità",
    "section": "\n28.7 Legge della Probabilità Totale",
    "text": "28.7 Legge della Probabilità Totale\nLa legge della probabilità totale consente di calcolare la probabilità di un evento \\(A\\) suddividendo lo spazio campionario in sottoinsiemi mutuamente esclusivi e completi, detti partizioni. Questo metodo è utile per decomporre un problema complesso in elementi più semplici.\n\n28.7.1 Caso base: Partizione con due eventi\nSe gli eventi \\(B\\) e \\(B^c\\) formano una partizione dello spazio campionario (ossia sono mutuamente esclusivi e la loro unione copre l’intero spazio), allora si può scrivere:\n\\[\nP(A) = P(A \\cap B) + P(A \\cap B^c).\n\\]\nIn altre parole, la probabilità di \\(A\\) è data dalla somma delle probabilità delle sue intersezioni con \\(B\\) e con il complemento di \\(B\\).\n\n28.7.2 Estensione a più eventi\nSe lo spazio campionario è suddiviso in \\(n\\) sottoinsiemi \\(B_1, B_2, \\dots, B_n\\), tali che:\n\nGli eventi \\(B_1, B_2, \\dots, B_n\\) sono mutuamente esclusivi (\\(B_i \\cap B_j = \\varnothing\\) per \\(i \\neq j\\)).\nLa loro unione copre l’intero spazio campionario (\\(\\bigcup_{i=1}^n B_i = \\Omega\\)),\n\nallora la probabilità di \\(A\\) si calcola come:\n\\[\nP(A) = P(A \\cap B_1) + P(A \\cap B_2) + \\dots + P(A \\cap B_n).\n\\]\n\n28.7.3 Applicazioni\nQuesta legge è utile nei casi in cui un problema complesso può essere scomposto in diversi scenari o categorie (\\(B_1, B_2, \\dots, B_n\\)). In pratica, permette di calcolare \\(P(A)\\) sommando le probabilità di \\(A\\) all’interno di ciascuna categoria, tenendo conto delle rispettive probabilità.\n\n28.7.4 Esempio\nImmagina che una scuola abbia due corsi, \\(B\\) e \\(B^c\\), e che un certo evento \\(A\\) (ad esempio, un esame superato) possa avvenire sia tra gli studenti del corso \\(B\\) che tra quelli di \\(B^c\\). Per calcolare la probabilità totale che \\(A\\) si verifichi, possiamo considerare separatamente i due gruppi:\n\\[\nP(A) = P(A \\cap B) + P(A \\cap B^c).\n\\]\nIn generale, la legge della probabilità totale aiuta a gestire problemi complessi e ad assicurare che ogni contributo venga considerato una sola volta, evitando duplicazioni o omissioni.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Fondamenti della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#probabilità-calcolo-combinatorio-e-simulazioni",
    "href": "chapters/probability/03_prob_on_general_spaces.html#probabilità-calcolo-combinatorio-e-simulazioni",
    "title": "28  Fondamenti della probabilità",
    "section": "\n28.8 Probabilità, Calcolo Combinatorio e Simulazioni",
    "text": "28.8 Probabilità, Calcolo Combinatorio e Simulazioni\nMolti problemi di probabilità scolastici si basano sul calcolo combinatorio per determinare la probabilità di un evento. La struttura generale di questi problemi consiste nel:\n\n\nDefinire gli eventi di successo: identificare tutte le configurazioni compatibili con l’evento di interesse.\n\nContare le possibilità: calcolare il numero di eventi di successo e rapportarlo al numero totale di eventi nello spazio campionario.\n\nAd esempio, supponiamo di avere una scatola con 10 palline numerate da 1 a 10 e di voler calcolare la probabilità di estrarre una pallina con un numero pari:\n\n\nEventi di successo: {2, 4, 6, 8, 10} (5 casi).\n\nEventi totali: {1, 2, 3, 4, 5, 6, 7, 8, 9, 10} (10 casi).\n\nLa probabilità è quindi:\n\\[\nP(\\text{numero pari}) = \\frac{\\text{numero di eventi di successo}}{\\text{numero totale di eventi}} = \\frac{5}{10} = 0.5.\n\\]\nPer problemi più complessi, come il calcolo della probabilità di ottenere una determinata combinazione di carte o di formare gruppi specifici da una popolazione, utilizziamo tecniche combinatorie più avanzate, come permutazioni e combinazioni.\n\n\n28.8.1 Gli Errori dei Grandi Matematici\nLa storia della teoria della probabilità è ricca di esempi che mostrano quanto questi problemi possano essere controintuitivi, persino per i grandi matematici. Uno di questi riguarda Jakob Bernoulli, pioniere della probabilità, nel suo libro Ars Conjectandi (1713). Un problema che affrontò riguardava il calcolo della probabilità di ottenere almeno una testa in 8 lanci di una moneta equa.\nPer risolvere il problema, è utile considerare la probabilità complementare, ovvero quella di non ottenere alcuna testa (solo croci), e poi sottrarla da 1:\n\n\nCalcolo della probabilità complementare: La probabilità di ottenere solo croci in un lancio è ( ). In 8 lanci consecutivi, questa diventa:\n\\[\nP(\\text{solo croci}) = \\left(\\frac{1}{2}\\right)^8 = \\frac{1}{256}.\n\\]\n\nCalcolo della probabilità di almeno una testa: \\[\nP(\\text{almeno una testa}) = 1 - P(\\text{solo croci}) = 1 - \\frac{1}{256} = \\frac{255}{256}.\n\\]\n\nTuttavia, Bernoulli commise un errore nel conteggio combinatorio, sottostimando la probabilità corretta. Questo errore fu poi corretto da altri matematici, come suo nipote Daniel Bernoulli, che affinò l’uso del calcolo combinatorio.\n\n28.8.2 Simulazioni Monte Carlo e Problemi Probabilistici\nUno degli aspetti più impegnativi della probabilità è che molti problemi non si prestano a soluzioni immediate o intuitive. Per affrontarli, si possono adottare due approcci principali. Il primo consiste nell’applicare i teoremi della teoria della probabilità, un metodo rigoroso ma spesso controintuitivo. Il secondo approccio è quello della simulazione Monte Carlo, che permette di ottenere una soluzione approssimata, ma molto vicina al valore reale, seguendo una procedura più accessibile e intuitiva. Questo metodo prende il nome dal famoso Casinò di Monte Carlo a Monaco, anche se può essere semplicemente definito come “metodo di simulazione.”\nLa simulazione Monte Carlo appartiene a una classe generale di metodi stocastici, che si contrappongono ai metodi deterministici. Questi metodi consentono di risolvere approssimativamente problemi analitici attraverso la generazione casuale delle quantità di interesse. Tra le tecniche comunemente utilizzate troviamo il campionamento con reinserimento, in cui la stessa unità può essere selezionata più volte, e il campionamento senza reinserimento, dove ogni unità può essere selezionata una sola volta. Questi strumenti rappresentano un mezzo potente e pratico per affrontare problemi complessi.\n\n28.8.2.1 Il Problema del Complenno\nUn esempio classico di applicazione del metodo Monte Carlo è il calcolo delle probabilità relative a vari eventi definiti attraverso il modello dell’urna, come illustrato nei problemi presentati sul sito dedicato agli esercizi. Tra questi, il celebre problema dei compleanni (si veda il sito di accompagnamento dedicato agli esercizi) evidenzia non solo l’efficacia dell’approccio simulativo nel semplificare la soluzione rispetto all’analisi formale, ma anche l’importanza delle assunzioni che entrambi i metodi condividono. In questo caso, l’assunzione è che la probabilità di nascita sia uniformemente distribuita nei 365 giorni dell’anno — un’ipotesi semplificativa che non rispecchia la realtà.\nQuesto esempio sottolinea un principio fondamentale dei modelli probabilistici (e scientifici in generale): ogni modello si basa su un insieme di ipotesi che ne delimitano la validità e l’applicabilità. Valutare criticamente la plausibilità di tali ipotesi è dunque essenziale per garantire che il modello fornisca una rappresentazione coerente e utile del fenomeno in studio.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Fondamenti della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#riflessioni-conlusive",
    "href": "chapters/probability/03_prob_on_general_spaces.html#riflessioni-conlusive",
    "title": "28  Fondamenti della probabilità",
    "section": "\n28.9 Riflessioni Conlusive",
    "text": "28.9 Riflessioni Conlusive\nDalla rigorosa applicazione del calcolo combinatorio agli approcci più intuitivi delle simulazioni Monte Carlo, la probabilità fornisce strumenti fondamentali per risolvere problemi complessi. Comprendere le probabilità ci consente di prendere decisioni informate in situazioni di incertezza e di formulare previsioni affidabili. Una solida conoscenza delle basi della probabilità ci permette di affrontare una vasta gamma di problemi e di fare scelte ponderate basate sulla probabilità dei vari esiti possibili. Tuttavia, è importante ricordare che i modelli probabilistici sono solo approssimazioni della realtà e possono essere influenzati da semplificazioni o dalle limitazioni dei dati disponibili. Pertanto, è fondamentale interpretare i risultati con cautela e avere piena consapevolezza delle assunzioni che sottendono le analisi.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Fondamenti della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/03_prob_on_general_spaces.html#informazioni-sullambiente-di-sviluppo",
    "title": "28  Fondamenti della probabilità",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] reshape2_1.4.4   see_0.9.0        gridExtra_2.3    patchwork_1.3.0 \n#&gt;  [5] bayesplot_1.11.1 psych_2.4.12     scales_1.3.0     markdown_1.13   \n#&gt;  [9] knitr_1.49       lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1   \n#&gt; [13] dplyr_1.1.4      purrr_1.0.2      readr_2.1.5      tidyr_1.3.1     \n#&gt; [17] tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3       \n#&gt; [21] here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     plyr_1.8.9        rprojroot_2.0.4  \n#&gt; [13] jsonlite_1.8.9    mnormt_2.1.1      cli_3.6.3         rlang_1.1.4      \n#&gt; [17] munsell_0.5.1     withr_3.0.2       yaml_2.3.10       tools_4.4.2      \n#&gt; [21] parallel_4.4.2    tzdb_0.4.0        colorspace_2.1-1  pacman_0.5.1     \n#&gt; [25] vctrs_0.6.5       R6_2.5.1          lifecycle_1.0.4   htmlwidgets_1.6.4\n#&gt; [29] pkgconfig_2.0.3   pillar_1.10.0     gtable_0.3.6      Rcpp_1.0.13-1    \n#&gt; [33] glue_1.8.0        xfun_0.49         tidyselect_1.2.1  farver_2.1.2     \n#&gt; [37] htmltools_0.5.8.1 nlme_3.1-166      rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Fondamenti della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#bibliografia",
    "href": "chapters/probability/03_prob_on_general_spaces.html#bibliografia",
    "title": "28  Fondamenti della probabilità",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlitzstein, J. K., & Hwang, J. (2019). Introduction to probability. CRC Press.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Fondamenti della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html",
    "href": "chapters/probability/04_conditional_prob.html",
    "title": "29  Probabilità condizionata",
    "section": "",
    "text": "29.1 Introduzione\nLa probabilità condizionata si riferisce al calcolo della probabilità di un evento, tenendo conto che un altro evento si è già verificato. Questo concetto è cruciale perché riflette come aggiorniamo le nostre credenze alla luce di nuove evidenze o informazioni. Per esempio, immaginiamo di voler stimare la probabilità di pioggia per domani. La nostra stima iniziale cambia se oggi osserviamo un cielo nuvoloso. Il fatto che oggi sia nuvoloso “condiziona” la nostra valutazione della probabilità di pioggia per domani.\nQuesto processo di aggiornamento delle nostre credenze in base a nuove osservazioni è continuo. Una nuova evidenza coerente con una credenza esistente potrebbe rafforzarla, mentre un’osservazione inaspettata potrebbe metterla in discussione. La probabilità condizionata non è solo un concetto teorico, ma ha applicazioni pratiche sia nella vita quotidiana che in ambito scientifico. In realtà, si potrebbe argomentare che tutte le probabilità sono in qualche modo condizionate da un certo contesto o da informazioni preesistenti, anche se non sempre lo specifichiamo esplicitamente.\nIn sintesi, la probabilità condizionata ci fornisce un framework per comprendere e quantificare come le nostre credenze dovrebbero evolversi man mano che acquisiamo nuove informazioni, rendendo il concetto di probabilità uno strumento dinamico e potente per gestire l’incertezza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#indipendenza-stocastica",
    "href": "chapters/probability/04_conditional_prob.html#indipendenza-stocastica",
    "title": "29  Probabilità condizionata",
    "section": "\n29.2 Indipendenza Stocastica",
    "text": "29.2 Indipendenza Stocastica\nIl concetto di indipendenza è cruciale nel contesto della probabilità condizionata, facilitando notevolmente i calcoli in numerosi problemi e indicando come la presenza di un evento non influenzi l’occorrenza di un altro.\n\n29.2.1 Indipendenza di Due Eventi\nDue eventi, \\(A\\) e \\(B\\), sono considerati indipendenti se la realizzazione di uno non altera la probabilità di occorrenza dell’altro. Formalmente, questa relazione è espressa come:\n\\[P(A \\cap B) = P(A) P(B),\\]\ndove \\(P(A \\cap B)\\) è la probabilità che \\(A\\) e \\(B\\) si verifichino contemporaneamente. Se questa condizione è verificata, denotiamo \\(A \\text{ ⫫ } B\\), indicando che \\(A\\) è indipendente da \\(B\\).\n\n29.2.2 Indipendenza di un Insieme di Eventi\nL’indipendenza stocastica è un principio fondamentale nell’applicazione statistica della probabilità. Un insieme di eventi \\(\\{ A_i : i \\in I \\}\\) è definito indipendente se per ogni sottoinsieme finito \\(J\\) di \\(I\\), la probabilità dell’intersezione degli eventi in \\(J\\) equivale al prodotto delle loro probabilità individuali:\n\\[P \\left( \\bigcap_{i \\in J} A_i \\right) = \\prod_{i \\in J} P(A_i).\\]\nQuesto implica che ogni combinazione finita di eventi nell’insieme agisce in maniera indipendente.\nL’indipendenza può essere assunta o derivata, a seconda del contesto. In alcuni modelli o situazioni, assumiamo l’indipendenza per semplificare i calcoli o per riflettere una conoscenza preesistente. In altri contesti, l’indipendenza può emergere dai dati o da altre proprietà del modello.\n\n29.2.3 Eventi Disgiunti e Indipendenza\nEventi disgiunti, o mutuamente esclusivi, sono quelli che non possono verificarsi contemporaneamente, ossia \\(\\mathbb{P}(A \\cap B) = 0\\). Se due eventi disgiunti hanno probabilità positive, essi non possono essere indipendenti, poiché l’equazione \\(P(A \\cap B) = P(A) P(B)\\) non può essere soddisfatta; \\(P(A \\cap B) = 0\\) non uguaglia \\(P(A) P(B) &gt; 0\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#probabilità-condizionata",
    "href": "chapters/probability/04_conditional_prob.html#probabilità-condizionata",
    "title": "29  Probabilità condizionata",
    "section": "\n29.3 Probabilità Condizionata",
    "text": "29.3 Probabilità Condizionata\nLa probabilità di un evento è sempre contestualizzata e varia a seconda del nostro stato di informazione. Con un insieme di informazioni disponibile, attribuiamo una probabilità specifica a un evento. Se lo stato informativo cambia, anche la probabilità associata deve essere aggiornata. In sostanza, tutte le probabilità possono essere considerate condizionate, anche se l’evento condizionante non è esplicitato.\nLa probabilità condizionata di un evento \\(A\\) dato un altro evento \\(B\\), con \\(P(B) &gt; 0\\), è definita come:\n\\[\nP(A \\mid B) = \\frac{P(A \\cap B)}{P(B)},\n\\]\ndove \\(P(A \\cap B)\\) è la probabilità congiunta di \\(A\\) e \\(B\\). Questa relazione permette di derivare la regola della moltiplicazione:\n\\[\nP(A \\cap B) = P(A \\mid B)P(B) = P(B \\mid A)P(A),\n\\]\ne una forma alternativa della legge della probabilità totale:\n\\[\nP(A) = P(A \\mid B)P(B) + P(A \\mid B^c)P(B^c),\n\\]\ndove \\(B^c\\) rappresenta il complemento di \\(B\\).\nPer spazi campionari discreti, possiamo esprimere la probabilità condizionata come:\n\\[\nP(A \\mid B) = \\frac{| A \\cap B |}{| B |}.\n\\]\nLa probabilità condizionata ricalibra lo spazio campionario, riducendolo da \\(S\\) a \\(B\\), e non è definita se \\(P(B) = 0\\).\n\nEsempio 29.1 Lanciamo due dadi equilibrati e vogliamo calcolare la probabilità che la somma dei punteggi ottenuti sia minore di 8.\nInizialmente, quando non abbiamo ulteriori informazioni, possiamo calcolare la probabilità in modo tradizionale. Ci sono 21 risultati possibili con somma minore di 8. Poiché ci sono 36 possibili combinazioni di lancio dei due dadi, la probabilità di ottenere una somma minore di 8 è 21/36, che equivale a circa 0.58.\nSupponiamo ora di sapere che la somma del lancio di due dadi ha prodotto un risultato dispari. In questo caso, ci sono solo 18 possibili combinazioni di lancio dei due dadi (dato che abbiamo escluso i risultati pari). Tra essi, vi sono 12 risultati che soddisfano la condizione per cui la somma è minore di 8. Quindi, la probabilità di ottenere una somma minore di 8 cambia da circa 0.58 a 12/18, ovvero 0.67 quando consideriamo l’informazione aggiuntiva del risultato dispari.\nSvolgiamo il problema in R:\n\nr &lt;- 1:6\nsample &lt;- expand.grid(i = r, j = r)\nsample\n#&gt;    i j\n#&gt; 1  1 1\n#&gt; 2  2 1\n#&gt; 3  3 1\n#&gt; 4  4 1\n#&gt; 5  5 1\n#&gt; 6  6 1\n#&gt; 7  1 2\n#&gt; 8  2 2\n#&gt; 9  3 2\n#&gt; 10 4 2\n#&gt; 11 5 2\n#&gt; 12 6 2\n#&gt; 13 1 3\n#&gt; 14 2 3\n#&gt; 15 3 3\n#&gt; 16 4 3\n#&gt; 17 5 3\n#&gt; 18 6 3\n#&gt; 19 1 4\n#&gt; 20 2 4\n#&gt; 21 3 4\n#&gt; 22 4 4\n#&gt; 23 5 4\n#&gt; 24 6 4\n#&gt; 25 1 5\n#&gt; 26 2 5\n#&gt; 27 3 5\n#&gt; 28 4 5\n#&gt; 29 5 5\n#&gt; 30 6 5\n#&gt; 31 1 6\n#&gt; 32 2 6\n#&gt; 33 3 6\n#&gt; 34 4 6\n#&gt; 35 5 6\n#&gt; 36 6 6\n\n\nevent &lt;- subset(sample, i + j &lt; 8)\ncat(nrow(event), \"/\", nrow(sample), \"\\n\")\n#&gt; 21 / 36\n\n\nsample_odd &lt;- subset(sample, (i + j) %% 2 != 0)\nsample_odd\n#&gt;    i j\n#&gt; 2  2 1\n#&gt; 4  4 1\n#&gt; 6  6 1\n#&gt; 7  1 2\n#&gt; 9  3 2\n#&gt; 11 5 2\n#&gt; 14 2 3\n#&gt; 16 4 3\n#&gt; 18 6 3\n#&gt; 19 1 4\n#&gt; 21 3 4\n#&gt; 23 5 4\n#&gt; 26 2 5\n#&gt; 28 4 5\n#&gt; 30 6 5\n#&gt; 31 1 6\n#&gt; 33 3 6\n#&gt; 35 5 6\n\n\nevent &lt;- subset(sample_odd, i + j &lt; 8)\ncat(nrow(event), \"/\", nrow(sample_odd), \"\\n\")\n#&gt; 12 / 18\n\nSe applichiamo l’?eq-prob-cond-def, abbiamo: \\(P(A \\cap B)\\) = 12/36, \\(P(B)\\) = 18/36 e\n\\[\nP(A \\mid B) = \\frac{12}{18}.\n\\]\nQuesto esempio illustra come la probabilità di un evento possa variare in base alle informazioni aggiuntive di cui disponiamo. Nel secondo caso, avendo l’informazione che la somma è dispari, la probabilità di ottenere una somma minore di 8 aumenta notevolmente rispetto al caso iniziale in cui non avevamo questa informazione.\n\n\nEsempio 29.2 Consideriamo uno screening per la diagnosi precoce del tumore mammario utilizzando un test con determinate caratteristiche:\n\nSensibilità del test: 90%. Questo significa che il test classifica correttamente come positivo il 90% delle donne colpite dal cancro al seno.\nSpecificità del test: 90%. Ciò indica che il test classifica correttamente come negativo il 90% delle donne che non hanno il cancro al seno.\nPrevalenza del cancro al seno nella popolazione sottoposta allo screening: 1% (0.01). Questo è il 1% delle donne che ha effettivamente il cancro al seno, mentre il restante 99% (0.99) non ne è affetto.\n\nOra cerchiamo di rispondere alle seguenti domande:\n\nQual è la probabilità che una donna scelta a caso ottenga una mammografia positiva? Poiché il 1% delle donne ha il cancro al seno, la probabilità di ottenere una mammografia positiva (test positivo) è pari alla sensibilità del test, ovvero 0.90 (cioè 90%).\nSe la mammografia è positiva, qual è la probabilità che vi sia effettivamente un tumore al seno?\n\nPer risolvere questo problema, consideriamo un campione di 1000 donne sottoposte al test di screening per il tumore al seno. Di queste 1000 donne:\n\n10 donne (1% del campione) hanno effettivamente il cancro al seno. Per queste 10 donne con il cancro, il test darà un risultato positivo (vera positività) in 9 casi (90%).\nPer le restanti 990 donne (99% del campione) che non hanno il cancro al seno, il test darà un risultato positivo (falsa positività) in 99 casi (10%).\n\nQuesta situazione può essere rappresentata graficamente nel seguente modo:\n\n\n\n\n\nFigura 29.1: Esiti della mammografia per 1000 donne.\n\n\nCombinando i due risultati precedenti, vediamo che il test dà un risultato positivo per 9 donne che hanno effettivamente il cancro al seno e per 99 donne che non lo hanno, per un totale di 108 risultati positivi su 1000. Pertanto, la probabilità di ottenere un risultato positivo al test è \\(\\frac{108}{1000}\\) = 0.108.\nTuttavia, tra le 108 donne che hanno ottenuto un risultato positivo al test, solo 9 hanno effettivamente il cancro al seno. Quindi, la probabilità di avere il cancro al seno, dato un risultato positivo al test, è pari a \\(\\frac{9}{108}\\) = 0.083, corrispondente all’8.3%.\nIn questo esempio, la probabilità dell’evento “ottenere un risultato positivo al test” è una probabilità non condizionata, poiché calcoliamo semplicemente la proporzione di risultati positivi nel campione totale. D’altra parte, la probabilità dell’evento “avere il cancro al seno, dato che il test ha prodotto un risultato positivo” è una probabilità condizionata, poiché calcoliamo la proporzione delle donne con il cancro al seno tra quelle che hanno ottenuto un risultato positivo al test.\nQuesto esempio illustra come la conoscenza di ulteriori informazioni (il risultato positivo al test) può influenzare la probabilità di un evento (avere il cancro al seno), mostrando chiaramente la differenza tra probabilità condizionate e non condizionate.\n\n\nEsempio 29.3 Il problema di Monty Hall è diventato famoso grazie alla rubrica tenuta da Marilyn vos Savant nella rivista Parade, che rispose alla seguente lettera, pubblicata il 9 settembre 1990:\n\n“Supponiamo che tu sia in un quiz televisivo, e ti venga data la scelta tra tre porte. Dietro una delle porte c’è un’auto, dietro le altre due ci sono delle capre. Tu scegli una porta, diciamo la numero 1, e il conduttore, che sa cosa c’è dietro ogni porta, apre un’altra porta, diciamo la numero 3, che contiene una capra. Il conduttore ti chiede quindi se vuoi cambiare la tua scelta e passare alla porta numero 2. È vantaggioso cambiare la scelta?” Craig. F. Whitaker, Columbia, MD\n\nLa situazione descritta nella lettera è simile a quella che i concorrenti affrontavano nel quiz televisivo degli anni ’70 Let’s Make a Deal, condotto da Monty Hall e Carol Merrill. Marilyn rispose che il concorrente dovrebbe cambiare la scelta, poiché se l’auto è dietro una delle due porte non scelte (il che è due volte più probabile rispetto alla porta inizialmente scelta), il concorrente vince cambiando porta. Tuttavia, la sua risposta suscitò una reazione a catena, con molte lettere, persino da parte di matematici, che affermavano che avesse torto. Questo episodio diede origine al problema di Monty Hall e innescò migliaia di ore di dibattiti.\nQuesto incidente sottolinea un aspetto fondamentale della probabilità: spesso, l’intuizione porta a conclusioni completamente errate. Fino a quando non si affinano le capacità nel trattare problemi di probabilità, un approccio rigoroso e sistematico è utile per evitare errori.\nChiarire il Problema\nLa lettera originale di Craig Whitaker è un po’ vaga, quindi dobbiamo fare delle ipotesi per poter modellare formalmente il gioco. Supponiamo che:\n\nL’auto sia nascosta in modo casuale ed equiprobabile dietro una delle tre porte.\nIl giocatore scelga una delle tre porte in modo casuale, indipendentemente dalla posizione dell’auto.\nDopo che il giocatore ha scelto una porta, il conduttore apre un’altra porta, che contiene una capra, e offre al giocatore la possibilità di mantenere la scelta o cambiarla.\nSe il conduttore ha la possibilità di scegliere quale porta aprire (ossia, se ci sono due capre disponibili), sceglie casualmente quale porta aprire.\n\nCon queste assunzioni, possiamo affrontare la domanda: “Qual è la probabilità che un giocatore che cambia porta vinca l’auto?”\nIl Metodo in Quattro Passi\nOgni problema di probabilità riguarda un esperimento o un processo casuale. In questi casi, il problema può essere suddiviso in quattro fasi distinte.\nPasso 1: Trovare lo Spazio Campionario\nIl primo passo è identificare tutti i possibili esiti dell’esperimento. Nel problema di Monty Hall, ci sono tre quantità determinate casualmente:\n\nLa porta che nasconde l’auto.\nLa porta scelta inizialmente dal giocatore.\nLa porta che il conduttore apre per rivelare una capra.\n\nUn diagramma ad albero può aiutarci a visualizzare il problema, dato che il numero di esiti non è troppo grande e la struttura è semplice. Il primo evento casuale è la posizione dell’auto, che rappresentiamo con tre rami in un albero. Ogni ramo corrisponde a una delle porte. La seconda quantità casuale è la porta scelta dal giocatore, rappresentata nel secondo livello dell’albero, e la terza quantità casuale è la porta che il conduttore apre, mostrata nel terzo livello.\nEcco un esempio di diagramma ad albero che rappresenta questa situazione:\n\n\n\n\n\nFigura 29.2: Il diagramma ad albero per il Problema di Monty Hall mostra le probabilità associate a ogni possibile esito. I pesi sugli archi rappresentano la probabilità di seguire quel particolare percorso, dato che ci troviamo nel nodo padre. Ad esempio, se l’auto si trova dietro la porta A, la probabilità che il giocatore scelga inizialmente la porta B è pari a 1/3. La colonna più a destra del diagramma mostra la probabilità di ciascun esito finale. Ogni probabilità di esito è calcolata moltiplicando le probabilità lungo il percorso che parte dalla radice (auto dietro una certa porta) e termina alla foglia (esito finale) (Figura tratta da Lehman, Leighton e Meyer, 2018).\n\n\nNel diagramma ad albero, i rami rappresentano le possibili combinazioni delle porte, e le foglie rappresentano gli esiti dell’esperimento. Ogni foglia dell’albero rappresenta un esito dello spazio campionario, che nel nostro caso è composto da 12 esiti. Per esempio, (Car A, Pick B, Reveal C).\nPasso 2: Definire gli Eventi di Interesse\nL’evento di interesse è “il giocatore vince cambiando porta”. Questo significa che, se la porta scelta dal giocatore inizialmente non contiene l’auto, e il giocatore decide di cambiare porta, allora vincerà. Gli esiti favorevoli sono quelli in cui la porta inizialmente scelta dal giocatore non nasconde l’auto, e cambiando porta il giocatore sceglie correttamente la porta che nasconde l’auto.\nGli esiti che soddisfano questa condizione sono:\n\n(Car A, Pick B, Reveal C)\n(Car A, Pick C, Reveal B)\n(Car B, Pick A, Reveal C)\n(Car B, Pick C, Reveal A)\n(Car C, Pick A, Reveal B)\n(Car C, Pick B, Reveal A)\n\nQuesti esiti sono 6 in totale.\nPasso 3: Calcolare le Probabilità degli Esiti\nOgni esito ha una certa probabilità di verificarsi. Il modo per determinare la probabilità di ciascun esito è moltiplicare le probabilità lungo il percorso nell’albero.\nEsempio di calcolo per l’esito (Car A, Pick B, Reveal C):\n\nLa probabilità che l’auto sia dietro la porta A è \\(\\frac{1}{3}\\).\nLa probabilità che il giocatore scelga la porta B è \\(\\frac{1}{3}\\).\nLa probabilità che il conduttore apra la porta C (che contiene una capra) è \\(1\\) (poiché il conduttore deve aprire una porta con una capra, e la porta C è l’unica possibile).\n\nLa probabilità totale per questo esito è:\n\\[\nP(\\text{Car A, Pick B, Reveal C}) = \\frac{1}{3} \\times \\frac{1}{3} \\times 1 = \\frac{1}{9}.\n\\]\nProcedendo in modo simile per tutti gli altri esiti, otteniamo le probabilità per tutti i 12 esiti.\nPasso 4: Calcolare le Probabilità degli Eventi\nLa probabilità di vincere cambiando porta è data dalla somma delle probabilità degli esiti favorevoli elencati sopra.\n\\[\n\\begin{aligned}\nP&(\\text{vincere cambiando porta}) = \\notag \\\\\n&\\quad P(\\text{Car A, Pick B, Reveal C}) + P(\\text{Car A, Pick C, Reveal B}) + \\notag\\\\  \n&\\quad P(\\text{Car B, Pick A, Reveal C}) + \\dots \\notag\n\\end{aligned}\n\\]\n\\[\n= \\frac{1}{9} + \\frac{1}{9} + \\frac{1}{9} + \\frac{1}{9} + \\frac{1}{9} + \\frac{1}{9} = \\frac{6}{9} = \\frac{2}{3}.\n\\]\nLa probabilità di vincere mantenendo la scelta originale è semplicemente il complemento:\n\\[\nP(\\text{vincere mantenendo la scelta}) = 1 - P(\\text{vincere cambiando porta}) = 1 - \\frac{2}{3} = \\frac{1}{3}.\n\\]\nLa conclusione è che il giocatore ha una probabilità di vincere pari a \\(\\frac{2}{3}\\) se cambia porta, contro una probabilità di \\(\\frac{1}{3}\\) se mantiene la sua scelta iniziale. Cambiare porta è quindi la strategia vincente. Questo risultato controintuitivo è il motivo per cui il problema di Monty Hall ha causato tanta confusione inizialmente.\nIl problema di Monty Hall è un classico esempio di probabilità condizionata perché la probabilità di vincere l’auto dipende da informazioni aggiuntive ottenute durante il gioco, cioè la porta che il conduttore apre. Inizialmente, la probabilità di trovare l’auto dietro la porta scelta dal giocatore è \\(\\frac{1}{3}\\), mentre la probabilità che l’auto sia dietro una delle altre due porte è \\(\\frac{2}{3}\\).\nQuando il conduttore apre una porta mostrando una capra, fornisce nuove informazioni che cambiano le probabilità. Questa nuova informazione condiziona la probabilità che l’auto sia dietro la porta non scelta dal giocatore, facendo sì che la probabilità di vincere cambiando porta diventi \\(\\frac{2}{3}\\). Quindi, il problema di Monty Hall è un esempio di probabilità condizionata perché l’aggiornamento delle probabilità dipende da un evento intermedio (la scelta della porta aperta dal conduttore).\n\n\nEsempio 29.4 Per confermare il risultato inaspettato del Problema di Monty Hall, è possibile eseguire una simulazione. In questa simulazione, consideriamo due scenari: uno in cui il concorrente mantiene la sua scelta iniziale e un altro in cui cambia la sua scelta dopo che Monty Hall ha svelato una capra. Ripetendo questa simulazione migliaia di volte, possiamo confrontare i risultati empirici e confermare come effettivamente il cambiamento di scelta aumenti le probabilità del concorrente di vincere l’automobile.\nDi seguito è riportato lo script di una simulazione progettata per illustrare il paradosso di Monty Hall.\n\nset.seed(123)  # For reproducibility\n\nporte &lt;- c(\"capra1\", \"capra2\", \"macchina\")  # Define the game\ncounter &lt;- 0\ncontatore_cambio &lt;- 0\nn &lt;- 10000\nporta_vincente &lt;- \"macchina\"\n\nfor (i in 1:n) {\n  scelta_casuale &lt;- sample(porte, 1)\n  porte_rimaste &lt;- porte[porte != scelta_casuale]\n  porta_rivelata &lt;- sample(porte_rimaste[porte_rimaste != porta_vincente], 1)\n  porta_alternativa &lt;- porte[porte != scelta_casuale & porte != porta_rivelata]\n  \n  if (\"macchina\" %in% porta_alternativa) {\n    contatore_cambio &lt;- contatore_cambio + 1\n  }\n  \n  if (scelta_casuale == \"macchina\") {\n    counter &lt;- counter + 1\n  }\n}\n\ncat(counter / n, \"\\n\")  # Proportion of wins without changing the door\n#&gt; 0.334\ncat(contatore_cambio / n, \"\\n\")  # Proportion of wins by changing the door\n#&gt; 0.666\n\nLa simulazione mostra che, effettivamente, la probabilità di vincere la macchina aumenta quando il concorrente sceglie di cambiare porta.\n\n\n29.3.1 Il paradosso di Simpson\nNel campo della probabilità condizionata, uno dei fenomeni più interessanti e, nel contempo, più controintuitivi, è rappresentato dal paradosso di Simpson. Il paradosso di Simpson è un fenomeno statistico in cui una tendenza che appare in diversi gruppi separati di dati scompare o si inverte quando i dati vengono combinati. Questo paradosso mette in luce l’importanza di considerare le variabili confondenti e di analizzare i dati con attenzione per evitare conclusioni errate.\n\nEsempio 29.5 Due psicoterapeuti, Rossi e Bianchi, praticano due tipi di terapie: terapia per disturbi d’ansia e coaching per migliorare le prestazioni lavorative. Ogni terapia può avere un esito positivo o negativo.\nI rispettivi bilanci dei due terapeuti sono riportati nelle seguenti tabelle.\nRossi\n\n\nTipo di terapia\nSuccesso\nFallimento\n\n\n\nDisturbi d’ansia\n70\n20\n\n\nCoaching lavorativo\n10\n0\n\n\nTotale\n80\n20\n\n\n\nBianchi\n\n\nTipo di terapia\nSuccesso\nFallimento\n\n\n\nDisturbi d’ansia\n2\n8\n\n\nCoaching lavorativo\n81\n9\n\n\nTotale\n83\n17\n\n\n\nRossi ha un tasso di successo superiore a Bianchi nella terapia per i disturbi d’ansia: 70 su 90 rispetto a 2 su 10. Anche nel coaching lavorativo, Rossi ha un tasso di successo superiore: 10 su 10 rispetto a 81 su 90. Tuttavia, se aggregiamo i dati dei due tipi di terapia per confrontare i tassi di successo globali, Rossi è efficace in 80 su 100 terapie, mentre Bianchi in 83 su 100: il tasso di successo globale di Bianchi risulta superiore!\nQuesto fenomeno è un esempio del paradosso di Simpson, dove una tendenza osservata in diversi gruppi si inverte quando i gruppi sono combinati.\nPer essere più precisi, possiamo calcolare i tassi di successo per ciascun terapeuta e per ciascun tipo di terapia, oltre al tasso di successo globale.\n\n\nRossi\n\nTasso di successo in terapia per disturbi d’ansia: \\(\\frac{70}{70+20} = \\frac{70}{90} \\approx 0.778\\)\n\nTasso di successo in coaching lavorativo: \\(\\frac{10}{10+0} = \\frac{10}{10} = 1\\)\n\nTasso di successo globale: \\(\\frac{70+10}{70+20+10+0} = \\frac{80}{100} = 0.8\\)\n\n\n\n\nBianchi\n\nTasso di successo in terapia per disturbi d’ansia: \\(\\frac{2}{2+8} = \\frac{2}{10} = 0.2\\)\n\nTasso di successo in coaching lavorativo: \\(\\frac{81}{81+9} = \\frac{81}{90} \\approx 0.9\\)\n\nTasso di successo globale: \\(\\frac{2+81}{2+8+81+9} = \\frac{83}{100} = 0.83\\)\n\n\n\n\nQuello che sta succedendo è che Rossi, presumibilmente a causa della sua reputazione come terapeuta più esperto, sta effettuando un numero maggiore di terapie per disturbi d’ansia, che sono intrinsecamente più complesse e con una probabilità di successo variabile rispetto al coaching lavorativo. Il suo tasso di successo globale è inferiore non a causa di una minore abilità in un particolare tipo di terapia, ma perché una frazione maggiore delle sue terapie riguarda casi più complessi.\nL’aggregazione dei dati tra diversi tipi di terapia presenta un quadro fuorviante delle abilità dei terapeuti perché perdiamo l’informazione su quale terapeuta tende a effettuare quale tipo di terapia. Quando sospettiamo la presenza di variabili di confondimento, come ad esempio il tipo di terapia in questo contesto, è fondamentale analizzare i dati in modo disaggregato per comprendere con precisione la dinamica in atto.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#teorema-della-probabilità-composta",
    "href": "chapters/probability/04_conditional_prob.html#teorema-della-probabilità-composta",
    "title": "29  Probabilità condizionata",
    "section": "\n29.4 Teorema della Probabilità Composta",
    "text": "29.4 Teorema della Probabilità Composta\nIl Teorema della Probabilità Composta, noto anche come regola moltiplicativa o regola della catena, permette di calcolare la probabilità congiunta di due o più eventi in termini delle loro probabilità individuali e condizionate. Questo teorema deriva direttamente dalla definizione di probabilità condizionata.\nPer due eventi \\(A\\) e \\(B\\), possiamo esprimere la probabilità congiunta \\(P(A \\cap B)\\) utilizzando la relazione:\n\\[\nP(A \\cap B) = P(B)P(A \\mid B) = P(A)P(B \\mid A).\n\\tag{29.1}\\]\nQuesta formula ci dice che la probabilità che entrambi gli eventi si verifichino è data dalla probabilità che uno dei due eventi accada, moltiplicata per la probabilità che l’altro evento si verifichi dato il primo.\nIl teorema della probabilità composta si estende facilmente al caso di \\(n\\) eventi \\(A_1, A_2, \\dots, A_n\\). In questo caso, la probabilità che tutti gli eventi si verifichino può essere scritta come:\n\\[\nP\\left( \\bigcap_{k=1}^n A_k \\right) = \\prod_{k=1}^n P\\left( A_k \\ \\Bigg\\lvert \\ \\bigcap_{j=1}^{k-1} A_j \\right).\n\\tag{29.2}\\]\nQuesto significa che per calcolare la probabilità congiunta di tutti gli eventi, dobbiamo moltiplicare:\n\nLa probabilità del primo evento.\nLa probabilità del secondo evento, condizionata al primo.\nLa probabilità del terzo evento, condizionata ai primi due.\nE così via, fino all’\\(n\\)-esimo evento, condizionato a tutti quelli precedenti.\n\nPer fare un esempio, consideriamo il caso di quattro eventi \\(A_1, A_2, A_3, A_4\\). La probabilità congiunta è:\n\\[\nP(A_1 \\cap A_2 \\cap A_3 \\cap A_4) = P(A_1) \\cdot P(A_2 \\mid A_1) \\cdot P(A_3 \\mid A_1 \\cap A_2) \\cdot P(A_4 \\mid A_1 \\cap A_2 \\cap A_3).\n\\]\nIn questa espressione:\n\nLa probabilità di \\(A_1\\) è considerata incondizionata.\nLa probabilità di \\(A_2\\) dipende da \\(A_1\\).\nLa probabilità di \\(A_3\\) dipende sia da \\(A_1\\) che da \\(A_2\\).\nLa probabilità di \\(A_4\\) dipende da tutti gli eventi precedenti.\n\nIl Teorema della Probabilità Composta è una delle basi teoriche più importanti della probabilità e viene utilizzato frequentemente in contesti come:\n\nLa modellazione di processi sequenziali o temporali.\nLa decomposizione di probabilità complesse in calcoli più semplici.\nLa teoria delle reti bayesiane e la probabilità condizionata.\n\nGrazie a questo teorema, possiamo affrontare problemi complessi frammentandoli in parti più gestibili, utilizzando le probabilità condizionate per costruire una soluzione graduale e sistematica.\n\nEsempio 29.6 Da un’urna contenente 6 palline bianche e 4 nere si estrae una pallina per volta, senza reintrodurla nell’urna. Indichiamo con \\(B_i\\) l’evento: “esce una pallina bianca alla \\(i\\)-esima estrazione” e con \\(N_i\\) l’estrazione di una pallina nera. L’evento: “escono due palline bianche nelle prime due estrazioni” è rappresentato dalla intersezione \\(\\{B_1 \\cap B_2\\}\\) e, per l’Equazione 29.1, la sua probabilità vale\n\\[\nP(B_1 \\cap B_2) = P(B_1)P(B_2 \\mid B_1).\n\\]\n\\(P(B_1)\\) vale 6/10, perché nella prima estrazione \\(\\Omega\\) è costituito da 10 elementi: 6 palline bianche e 4 nere. La probabilità condizionata \\(P(B_2 \\mid B_1)\\) vale 5/9, perché nella seconda estrazione, se è verificato l’evento \\(B_1\\), lo spazio campionario consiste di 5 palline bianche e 4 nere. Si ricava pertanto:\n\\[\nP(B_1 \\cap B_2) = \\frac{6}{10} \\cdot \\frac{5}{9} = \\frac{1}{3}.\n\\]\nIn modo analogo si ha che\n\\[\nP(N_1 \\cap N_2) = P(N_1)P(N_2 \\mid N_1) = \\frac{4}{10} \\cdot \\frac{3}{9} = \\frac{4}{30}.\n\\]\nSe l’esperimento consiste nell’estrazione successiva di 3 palline, la probabilità che queste siano tutte bianche, per l’Equazione 29.2, vale\n\\[\n\\begin{aligned}\nP(B_1 \\cap B_2 \\cap B_3) &=P(B_1)P(B_2 \\mid B_1)P(B_3 \\mid B_1 \\cap B_2) \\notag\\\\\n&=\\frac{6}{10}\\cdot\\frac{5}{9} \\cdot\\frac{4}{8} \\notag\\\\\n&= \\frac{1}{6}.\n\\end{aligned}\n\\]\nLa probabilità dell’estrazione di tre palline nere è invece:\n\\[\n\\begin{aligned}\nP(N_1 \\cap N_2 \\cap N_3) &= P(N_1)P(N_2 \\mid N_1)P(N_3 \\mid N_1 \\cap N_2)\\notag\\\\\n&= \\frac{4}{10} \\cdot \\frac{3}{9} \\cdot \\frac{2}{8} \\notag\\\\\n&= \\frac{1}{30}.\\notag\n\\end{aligned}\n\\]",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#il-teorema-della-probabilità-totale",
    "href": "chapters/probability/04_conditional_prob.html#il-teorema-della-probabilità-totale",
    "title": "29  Probabilità condizionata",
    "section": "\n29.5 Il Teorema della Probabilità Totale",
    "text": "29.5 Il Teorema della Probabilità Totale\nIl teorema della probabilità totale (o teorema delle partizioni), che abbiamo già discusso nel capitolo precedente, può essere riformulato nei termini della probabilità condizionata. Il teorema afferma che, dato uno spazio campionario \\(\\Omega\\) suddiviso in una partizione di \\(n\\) eventi mutualmente esclusivi (cioè non sovrapposti) e tali che la loro unione formi \\(\\Omega\\), è possibile calcolare la probabilità di un qualsiasi evento \\(E \\subseteq \\Omega\\) sommando la probabilità di \\(E\\) su ciascun sottoinsieme della partizione, pesata per la probabilità del sottoinsieme.\n\n29.5.1 Definizione Formale\nSiano \\(H_1, H_2, \\dots, H_n\\) eventi che costituiscono una partizione dello spazio campionario \\(\\Omega\\), ossia:\n\n\n\\(H_i \\cap H_j = \\varnothing\\) per \\(i \\neq j\\) (mutualmente esclusivi),\n\n\\(\\bigcup_{i=1}^n H_i = \\Omega\\) (copertura completa dello spazio campionario).\n\nAllora, per ogni evento \\(E \\subseteq \\Omega\\), la probabilità di \\(E\\) è data da:\n\\[\nP(E) = \\sum_{i=1}^n P(E \\mid H_i)P(H_i),\n\\tag{29.3}\\]\ndove:\n\n\n\\(P(E \\mid H_i)\\) è la probabilità condizionata di \\(E\\) dato che si è verificato l’evento \\(H_i\\),\n\n\\(P(H_i)\\) è la probabilità dell’evento \\(H_i\\).\n\nIl teorema afferma dunque che la probabilità di un evento \\(E\\) può essere calcolata considerando il contributo di ciascun sottoinsieme della partizione. Ogni termine nella somma rappresenta la probabilità di \\(E\\) “passando” attraverso un sottoinsieme \\(H_i\\), pesata per la probabilità che \\(H_i\\) si verifichi.\nIl teorema della probabilità totale è cruciale in molte applicazioni della probabilità, in particolare:\n\n\nTeorema di Bayes: Fornisce il denominatore necessario per normalizzare la probabilità condizionata e garantire che la distribuzione a posteriori sia valida.\n\nProblemi con partizioni: È utile per calcolare la probabilità di un evento \\(E\\) quando si conoscono le probabilità condizionate \\(P(E \\mid H_i)\\) e le probabilità dei sottoinsiemi \\(P(H_i)\\).\n\nNella sua forma più semplice, l’applicazione del teorema si basa su una partizione dello spazio campionario \\(\\Omega\\) in due sottoinsiemi disgiunti, \\(H_1\\) e \\(H_2\\).\n\n\n\n\n\nFigura 29.3: Partizione dello spazio campionario in due sottoinsiemi.\n\n\nLa probabilità di un evento \\(E\\) può essere calcolata come\n\\[\nP(E) = P(E \\cap H_1) + P(E \\cap H_2),\n\\]\novvero\n\\[\nP(E) = P(E \\mid H_1) P(H_1) + P(E \\mid H_2) P(H_2).\n\\]\nIn sintesi, l’Equazione 29.3 ci consente di calcolare probabilità complesse sfruttando partizioni dello spazio campionario. È particolarmente utile quando \\(P(E \\mid H_i)\\) e \\(P(H_i)\\) sono disponibili, consentendo una valutazione della probabilità di \\(E\\).\n\nEsempio 29.7 Abbiamo tre urne, ciascuna delle quali contiene 100 palline:\n\nUrna 1: 75 palline rosse e 25 palline blu,\nUrna 2: 60 palline rosse e 40 palline blu,\nUrna 3: 45 palline rosse e 55 palline blu.\n\nUna pallina viene estratta a caso da un’urna anch’essa scelta a caso. Qual è la probabilità che la pallina estratta sia di colore rosso?\nSia \\(R\\) l’evento “la pallina estratta è rossa” e sia \\(U_i\\) l’evento che corrisponde alla scelta dell’\\(i\\)-esima urna. Sappiamo che\n\\[\nP(R \\mid U_1) = 0.75, \\quad P(R \\mid U_2) = 0.60, \\quad P(R \\mid U_3) = 0.45.\n\\]\nGli eventi \\(U_1\\), \\(U_2\\) e \\(U_3\\) costituiscono una partizione dello spazio campione in quanto \\(U_1\\), \\(U_2\\) e \\(U_3\\) sono eventi mutualmente esclusivi ed esaustivi, ovvero \\(P(U_1 \\cup U_2 \\cup U_3) = 1.0\\). In base al teorema della probabilità totale, la probabilità di estrarre una pallina rossa è dunque\n\\[\n\\begin{split}\nP(R) &= P(R \\mid U_1)P(U_1) + P(R \\mid U_2)P(U_2) + P(R \\mid U_3)P(U_3) \\\\\n&= 0.75 \\cdot \\frac{1}{3}+0.60 \\cdot \\frac{1}{3}+0.45 \\cdot \\frac{1}{3} \\\\\n&=0.60.\n\\end{split}\n\\]",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#indipendenza-e-probabilità-condizionata",
    "href": "chapters/probability/04_conditional_prob.html#indipendenza-e-probabilità-condizionata",
    "title": "29  Probabilità condizionata",
    "section": "\n29.6 Indipendenza e Probabilità Condizionata",
    "text": "29.6 Indipendenza e Probabilità Condizionata\nL’indipendenza tra due eventi \\(A\\) e \\(B\\) può essere interpretata intuitivamente attraverso la probabilità condizionata. Due eventi sono indipendenti se il verificarsi di uno non influenza la probabilità di verificarsi dell’altro. In altre parole, conoscere che \\(B\\) è accaduto non modifica la probabilità di \\(A\\), e viceversa.\nQuesta relazione può essere formalizzata con le seguenti equazioni:\n\\[\nP(A \\mid B) = \\frac{P(A \\cap B)}{P(B)} = P(A),\n\\]\n\\[\nP(B \\mid A) = \\frac{P(A \\cap B)}{P(A)} = P(B).\n\\]\nPertanto, \\(A\\) e \\(B\\) sono indipendenti se e solo se:\n\\[\nP(A \\mid B) = P(A),\n\\]\n\\[\nP(B \\mid A) = P(B).\n\\]\nQueste condizioni significano che la probabilità di \\(A\\) non cambia, indipendentemente dal fatto che \\(B\\) sia accaduto, e lo stesso vale per \\(B\\).\n\n\n\n\n\n\n\n29.6.1 Indipendenza di Tre Eventi\nLa definizione di indipendenza si estende naturalmente a tre eventi \\(A\\), \\(B\\), e \\(C\\), ma con condizioni aggiuntive. Tre eventi sono indipendenti se:\n\n\nOgni coppia di eventi è indipendente:\n\\[\n\\begin{align}\nP(A \\cap B) &= P(A) P(B), \\\\\nP(A \\cap C) &= P(A) P(C), \\\\\nP(B \\cap C) &= P(B) P(C).\n\\end{align}\n\\]\n\n\nLa probabilità congiunta di tutti e tre gli eventi è uguale al prodotto delle loro probabilità individuali:\n\\[\nP(A \\cap B \\cap C) = P(A) P(B) P(C).\n\\]\n\n\nLe prime tre condizioni verificano l’indipendenza a coppie (indipendenza a due a due), mentre l’ultima condizione garantisce che i tre eventi siano completamente indipendenti. È importante notare che l’indipendenza a due a due non implica necessariamente l’indipendenza completa: per essere indipendenti nel senso completo, tutte e quattro le condizioni devono essere soddisfatte.\nIn sintesi, l’indipendenza tra eventi implica che il verificarsi di uno di essi non fornisce alcuna informazione sulla probabilità del verificarsi degli altri. Nel caso di due eventi, questa proprietà si traduce nell’invarianza della probabilità condizionata. Per tre o più eventi, l’indipendenza richiede sia l’indipendenza a coppie sia la condizione più forte sull’intersezione di tutti gli eventi.\nQuesti concetti sono fondamentali nella probabilità e nella statistica, poiché semplificano molti calcoli e forniscono una base per modelli più complessi.\n\nEsempio 29.8 Consideriamo un esempio utilizzando un mazzo di 52 carte. Ogni seme contiene 13 carte e ci sono 4 regine in totale. Definiamo i seguenti eventi:\n\nEvento A: pescare una carta di picche,\nEvento B: pescare una regina.\n\nProbabilità con un mazzo completo\nIn un mazzo completo, la probabilità di pescare una carta di picche (\\(P(A)\\)) è \\(\\frac{13}{52} = \\frac{1}{4}\\), poiché ci sono 13 picche su 52 carte totali. La probabilità di pescare una regina (\\(P(B)\\)) è \\(\\frac{4}{52} = \\frac{1}{13}\\), poiché ci sono 4 regine su 52 carte.\nOra consideriamo la probabilità congiunta di pescare la regina di picche (\\(P(AB)\\)). Poiché esiste solo una regina di picche nel mazzo, la probabilità di pescare questa specifica carta è \\(\\frac{1}{52}\\).\nSecondo la definizione di indipendenza, se gli eventi \\(A\\) e \\(B\\) sono indipendenti, allora:\n\\[ P(AB) = P(A)P(B) \\]\nCalcoliamo \\(P(A)P(B)\\):\n\\[ P(A)P(B) = \\left( \\frac{1}{4} \\right) \\left( \\frac{1}{13} \\right) = \\frac{1}{52} \\]\nPoiché \\(P(AB) = \\frac{1}{52}\\) è uguale a \\(P(A)P(B)\\), possiamo affermare che gli eventi \\(A\\) e \\(B\\) sono indipendenti con un mazzo completo di 52 carte.\nProbabilità dopo la rimozione di una carta\nConsideriamo ora un mazzo con una carta in meno, ad esempio il due di quadri, riducendo il numero totale di carte a 51. Ricalcoliamo le probabilità con questo mazzo ridotto:\nLa probabilità di pescare la regina di picche (\\(P(AB)\\)) è ora \\(\\frac{1}{51}\\), poiché ci sono 51 carte nel mazzo.\nRicalcoliamo anche \\(P(A)\\) e \\(P(B)\\):\n\n\n\\(P(A)\\) diventa \\(\\frac{13}{51}\\), poiché ci sono ancora 13 picche, ma su 51 carte.\n\n\\(P(B)\\) diventa \\(\\frac{4}{51}\\), poiché ci sono ancora 4 regine, ma su 51 carte.\n\nOra calcoliamo il prodotto \\(P(A)P(B)\\) con queste nuove probabilità:\n\\[ P(A)P(B) = \\left( \\frac{13}{51} \\right) \\left( \\frac{4}{51} \\right) = \\frac{52}{2601} \\]\nConfrontiamo \\(P(AB)\\) e \\(P(A)P(B)\\):\n\\[ \\frac{1}{51} \\neq \\frac{52}{2601} \\]\nPoiché \\(\\frac{1}{51} \\neq \\frac{52}{2601}\\), gli eventi \\(A\\) e \\(B\\) non sono più indipendenti dopo la rimozione del due di quadri.\nQuesto esempio mostra come l’indipendenza tra due eventi dipenda dal contesto. Con un mazzo completo, i due eventi sono indipendenti. Tuttavia, rimuovendo una carta dal mazzo, le probabilità cambiano e gli eventi non sono più indipendenti. Questo evidenzia l’importanza di considerare la composizione e le condizioni iniziali quando si analizzano probabilità e indipendenza. Modifiche nella composizione del mazzo possono alterare le probabilità, influenzando le relazioni di indipendenza tra eventi specifici.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#riflessioni-conclusive",
    "href": "chapters/probability/04_conditional_prob.html#riflessioni-conclusive",
    "title": "29  Probabilità condizionata",
    "section": "\n29.7 Riflessioni Conclusive",
    "text": "29.7 Riflessioni Conclusive\nLa probabilità condizionata è uno dei concetti fondamentali della statistica, poiché fornisce il quadro teorico necessario per comprendere l’indipendenza statistica e molte altre relazioni tra eventi e variabili.\nUn punto chiave è che l’indipendenza implica l’assenza di una associazione tra due variabili. Nei capitoli successivi esploreremo strumenti per misurare la correlazione correlazione, ovvero la presenza e l’intensità di una relazione lineare tra di esse.\nLa probabilità condizionata ha inoltre permesso di riformulare la legge della probabilità totale, che consente di scomporre probabilità complesse utilizzando partizioni dello spazio campionario. Questa legge si rivela cruciale per il teorema di Bayes, uno degli strumenti cardine dell’inferenza statistica.\nIn particolare, nel contesto dell’inferenza bayesiana, il condizionamento assume un ruolo fondamentale. Grazie a questo principio, è possibile aggiornare continuamente le credenze o le incertezze riguardo a ipotesi, integrando nuove informazioni man mano che diventano disponibili. Questa capacità di adattamento rende l’inferenza bayesiana uno strumento estremamente flessibile e potente, capace di modellare situazioni complesse e dinamiche.\nIn sintesi, la probabilità condizionata non solo è essenziale per comprendere l’indipendenza statistica, ma costituisce anche la base di metodi inferenziali avanzati, come l’inferenza bayesiana. Attraverso di essa, possiamo costruire modelli che evolvono e migliorano con l’aggiunta di nuove informazioni, rendendo l’analisi statistica uno strumento dinamico e versatile per interpretare il mondo reale.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/04_conditional_prob.html#informazioni-sullambiente-di-sviluppo",
    "title": "29  Probabilità condizionata",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] see_0.9.0        gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1\n#&gt;  [5] psych_2.4.12     scales_1.3.0     markdown_1.13    knitr_1.49      \n#&gt;  [9] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [13] purrr_1.0.2      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [17] ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.3         rlang_1.1.4       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       yaml_2.3.10       tools_4.4.2       parallel_4.4.2   \n#&gt; [21] tzdb_0.4.0        colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5      \n#&gt; [25] R6_2.5.1          lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3  \n#&gt; [29] pillar_1.10.0     gtable_0.3.6      glue_1.8.0        xfun_0.49        \n#&gt; [33] tidyselect_1.2.1  farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-166     \n#&gt; [37] rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#bibliografia",
    "href": "chapters/probability/04_conditional_prob.html#bibliografia",
    "title": "29  Probabilità condizionata",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlitzstein, J. K., & Hwang, J. (2019). Introduction to probability. CRC Press.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_random_var.html",
    "href": "chapters/probability/05_random_var.html",
    "title": "30  Variabili casuali",
    "section": "",
    "text": "30.1 Introduzione\nFinora, ci siamo concentrati sulle probabilità degli eventi. Ad esempio, abbiamo calcolato la probabilità di vincere il gioco di Monty Hall o di avere una rara condizione medica dato che il test è risultato positivo. Ma, in molti casi, vorremmo sapere di più. Ad esempio, quanti concorrenti devono giocare al gioco di Monty Hall fino a quando uno di loro finalmente vince? Quanto durerà questa condizione? Quanto perderò giocando d’azzardo con un dado sbilanciato tutta la notte? Per rispondere a queste domande, dobbiamo lavorare con le variabili casuali. In questo capitolo, introduciamo le variabili casuali e le loro proprietà.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_random_var.html#definizione",
    "href": "chapters/probability/05_random_var.html#definizione",
    "title": "30  Variabili casuali",
    "section": "\n30.2 Definizione",
    "text": "30.2 Definizione\nLe variabili casuali sono risultati numerici derivanti da processi aleatori. Esse ci consentono di trasformare risultati qualitativi (ad esempio \\(X = \\{\\Box, \\clubsuit, \\diamondsuit, \\heartsuit, \\spadesuit\\}\\)) in valori numerici, semplificando così l’analisi matematica.\nFormalmente, una variabile casuale è definita come una funzione che associa ogni elemento di uno spazio campionario \\(S\\) a un valore in un sottoinsieme dei numeri reali \\(\\mathbb{R}\\). Questa definizione consente di esprimere numericamente gli esiti di un fenomeno aleatorio, associando un valore specifico a ciascun possibile risultato dell’esperimento.\n\nEsempio 30.1 Un esempio è la variabile casuale \\(X\\), che rappresenta il risultato del lancio di un dado. Se definiamo \\(X = 1\\) per indicare che il risultato del lancio è un numero dispari (1, 3 o 5) e \\(X = 0\\) per indicare che il risultato è un numero pari (2, 4 o 6), abbiamo trasformato un’osservazione fisica (il lancio del dado) in un valore numerico che rappresenta una determinata categoria di eventi.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_random_var.html#tipologie-di-variabili-casuali",
    "href": "chapters/probability/05_random_var.html#tipologie-di-variabili-casuali",
    "title": "30  Variabili casuali",
    "section": "\n30.3 Tipologie di Variabili Casuali",
    "text": "30.3 Tipologie di Variabili Casuali\nLe variabili casuali possono essere suddivise in due categorie principali: discrete e continue. Una variabile casuale discreta assume valori all’interno di un insieme finito o al massimo numerabile, il che significa che i suoi possibili esiti possono essere contati, anche se l’insieme è infinito. Al contrario, una variabile casuale continua può assumere un’infinità di valori all’interno di un intervallo, essendo in grado di coprire ogni punto di quell’intervallo senza interruzioni.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_random_var.html#convenzioni-notazionali",
    "href": "chapters/probability/05_random_var.html#convenzioni-notazionali",
    "title": "30  Variabili casuali",
    "section": "\n30.4 Convenzioni Notazionali",
    "text": "30.4 Convenzioni Notazionali\nNella teoria della probabilità, è usuale adottare una specifica convenzione di notazione per le variabili casuali e i loro esiti. Comunemente, si utilizzano le lettere maiuscole, come \\(X\\), per indicare una variabile casuale, ovvero un concetto che rappresenta una serie di possibili esiti di un fenomeno aleatorio. D’altro canto, la corrispondente lettera minuscola, \\(x\\) nel nostro esempio, è impiegata per denotare una specifica realizzazione o un esito particolare che la variabile casuale può assumere. Questa distinzione aiuta a chiarire se si sta parlando della variabile casuale nel suo insieme (\\(X\\)) o di un suo specifico valore (\\(x\\)).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_random_var.html#variabili-casuali-multiple",
    "href": "chapters/probability/05_random_var.html#variabili-casuali-multiple",
    "title": "30  Variabili casuali",
    "section": "\n30.5 Variabili casuali multiple",
    "text": "30.5 Variabili casuali multiple\nNella teoria della probabilità, le variabili casuali spesso interagiscono o si combinano tra loro. Consideriamo l’esempio di tre lanci di una moneta bilanciata, rappresentati da variabili casuali indipendenti \\(X_1\\), \\(X_2\\), e \\(X_3\\). Per ogni lancio:\n\n\n\\(P(X_n = 1)\\) (testa) = 0.5,\n\n\\(P(X_n = 0)\\) (croce) = 0.5,\n\ndove \\(n = 1, 2, 3\\).\nCombinando queste variabili, possiamo creare nuove variabili casuali. Ad esempio, definiamo \\(Z\\) come la somma dei risultati:\n\\[\nZ = X_1 + X_2 + X_3.\n\\]\n\\(Z\\) è una variabile casuale discreta che rappresenta il numero totale di teste ottenute nei tre lanci. I suoi possibili valori sono 0, 1, 2, e 3.\nQuesto esempio illustra come variabili casuali indipendenti possano essere combinate per creare nuove variabili casuali.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_random_var.html#distribuzione-di-probabilità",
    "href": "chapters/probability/05_random_var.html#distribuzione-di-probabilità",
    "title": "30  Variabili casuali",
    "section": "\n30.6 Distribuzione di Probabilità",
    "text": "30.6 Distribuzione di Probabilità\nLa distribuzione di probabilità descrive come le probabilità si distribuiscono tra i possibili esiti associati a una variabile casuale. In precedenza, abbiamo introdotto il concetto di distribuzione di probabilità applicato agli elementi e ai sottoinsiemi dello spazio campionario di un esperimento casuale. Ora estendiamo questo concetto alle variabili casuali, con una differenza fondamentale: nel caso delle variabili casuali, gli elementi dello spazio campionario vengono mappati su numeri, mentre in precedenza potevano rappresentare altre categorie, come colori, oggetti o nomi.\n\n30.6.1 Parallelo tra Spazio Campionario e Variabili Casuali\n\nDistribuzione di probabilità nello spazio campionario: Ogni esperimento casuale ha uno spazio campionario, cioè l’insieme degli esiti possibili. Ad esempio, consideriamo un’urna contenente tre palline di colori diversi: \\(\\{\\text{rosso}, \\text{blu}, \\text{verde}\\}\\). Se estraiamo una pallina a caso, ogni colore può essere associato a una probabilità, ad esempio: \\[\nP(\\text{rosso}) = 0.4, \\quad P(\\text{blu}) = 0.3, \\quad P(\\text{verde}) = 0.3.\n\\]\n\nDistribuzione di probabilità di una variabile casuale: Una variabile casuale trasforma questi esiti in numeri. Ad esempio, definiamo una variabile casuale \\(X\\) che assegna un valore numerico ai colori estratti:\n\\[\nX(\\text{rosso}) = 1, \\quad X(\\text{blu}) = 2, \\quad X(\\text{verde}) = 3.\n\\]\nLa distribuzione di probabilità di \\(X\\) descrive come le probabilità sono distribuite tra i numeri \\(\\{1, 2, 3\\}\\):\n\\[\nP(X = 1) = 0.4, \\quad P(X = 2) = 0.3, \\quad P(X = 3) = 0.3.\n\\]\n\n\n30.6.2 Distribuzioni di Probabilità: Discrete e Continue\nCome per lo spazio campionario, anche per le variabili casuali distinguiamo tra distribuzioni discrete e distribuzioni continue, a seconda della natura della variabile casuale:\n\nDistribuzioni discrete: Si applicano a variabili casuali discrete, che possono assumere un insieme finito o numerabile di valori. L’esempio sopra, con i colori delle palline trasformati in numeri, è una distribuzione discreta. La funzione di massa di probabilità (PMF) assegna una probabilità a ciascun valore possibile.\n\nDistribuzioni continue: Si applicano a variabili casuali continue, che possono assumere un numero infinito di valori in un intervallo. Ad esempio, consideriamo l’altezza delle persone in una popolazione. Definiamo una variabile casuale \\(X\\) che rappresenta l’altezza in centimetri. In questo caso, la distribuzione di \\(X\\) è descritta da una funzione di densità di probabilità (PDF), che non assegna probabilità a valori specifici ma descrive la probabilità per intervalli, ad esempio:\n\\[\nP(170 \\leq X \\leq 180).\n\\]\n\n\n\nIn sintesi, la distribuzione di probabilità delle variabili casuali estende il concetto di distribuzione nello spazio campionario a un contesto numerico. Questo permette di analizzare e modellare fenomeni reali in cui gli esiti possono essere rappresentati quantitativamente, sia per variabili discrete che continue, offrendo un quadro unificato per descrivere la probabilità.\n\n30.6.3 Supporto della Variabile Casuale\nIl supporto di una variabile casuale è l’insieme di tutti i valori che la variabile può effettivamente assumere. Ad esempio:\n\nper un dado a sei facce: {1, 2, 3, 4, 5, 6};\nper una distribuzione gaussiana: l’intero insieme dei numeri reali.\n\n30.6.4 Assegnazione di Probabilità\n\nPer variabili discrete: si specifica la probabilità di ogni possibile valore.\nPer variabili continue: si utilizza la densità di probabilità per calcolare la probabilità di intervalli di valori.\n\n\nEsempio 30.2 Consideriamo l’esperimento casuale costituito dal lancio di due dadi equilibrati. Definiamo la variabile casuale \\(X\\) come la somma dei punti ottenuti dai due dadi.\nLo spazio campionario \\(S\\) è l’insieme di tutte le possibili coppie ordinate \\((a,b)\\), dove \\(a\\) e \\(b\\) rappresentano i risultati del primo e del secondo dado rispettivamente:\n\\[\nS = {(1,1), (1,2), ..., (1,6), (2,1), (2,2), ..., (2,6), ..., (6,1), (6,2), ..., (6,6)}.\n\\]\nIn totale, ci sono 6 × 6 = 36 possibili esiti.\nLa variabile casuale \\(X\\) è definita come la somma dei punti dei due dadi. Quindi:\n\\[\nX = a + b, \\quad \\text{dove } (a,b) \\in S.\n\\]\n\\(X\\) può assumere valori interi da 2 (1+1) a 12 (6+6).\nLa distribuzione della variabile casuale \\(X\\) è una funzione che associa a ogni possibile valore di \\(X\\) la sua probabilità. In questo caso, poiché \\(X\\) è discreta, usiamo una funzione di massa di probabilità.\nPer calcolare la probabilità di ogni valore di \\(X\\), contiamo il numero di casi favorevoli e lo dividiamo per il numero totale di casi possibili (36).\n\n\n\n\n\n\n\n\nX\nCasi favorevoli\nNumero di casi\nProbabilità P(X = x)\n\n\n\n2\n(1,1)\n1\n1/36\n\n\n3\n(1,2), (2,1)\n2\n2/36 = 1/18\n\n\n4\n(1,3), (2,2), (3,1)\n3\n3/36 = 1/12\n\n\n5\n(1,4), (2,3), (3,2), (4,1)\n4\n4/36 = 1/9\n\n\n6\n(1,5), (2,4), (3,3), (4,2), (5,1)\n5\n5/36\n\n\n7\n(1,6), (2,5), (3,4), (4,3), (5,2), (6,1)\n6\n6/36 = 1/6\n\n\n8\n(2,6), (3,5), (4,4), (5,3), (6,2)\n5\n5/36\n\n\n9\n(3,6), (4,5), (5,4), (6,3)\n4\n4/36 = 1/9\n\n\n10\n(4,6), (5,5), (6,4)\n3\n3/36 = 1/12\n\n\n11\n(5,6), (6,5)\n2\n2/36 = 1/18\n\n\n12\n(6,6)\n1\n1/36\n\n\n\nQuesta tabella rappresenta la distribuzione completa della variabile casuale \\(X\\).\nIn conclusione, la distribuzione di una variabile casuale discreta, come nell’esempio della somma dei punti di due dadi, fornisce una descrizione completa delle proprietà probabilistiche della variabile. Essa associa a ogni possibile valore della variabile la sua probabilità di verificarsi.\nIn questo caso, la distribuzione ci dice, per esempio, che la probabilità di ottenere una somma di 7 è 1/6, la più alta tra tutti i possibili risultati. Questo è dovuto al fatto che ci sono più combinazioni che producono una somma di 7 rispetto a qualsiasi altro risultato.\nLa distribuzione ci permette di rispondere a domande come:\n\nQual è la probabilità di ottenere una somma pari? (Sommando le probabilità di 2, 4, 6, 8, 10, 12).\nQual è la probabilità di ottenere una somma maggiore o uguale a 10? (Sommando le probabilità di 10, 11, 12).\n\nLa distribuzione di massa di probabilità della variabile casuale \\(X\\) può essere rappresentata visivamente utilizzando un istogramma. Un istogramma permette di vedere immediatamente la probabilità associata a ciascun valore di \\(X\\), rendendo chiaro quali risultati sono più probabili e quali lo sono meno.\nLe istruzioni R necessarie per generare questo istogramma sono fornite di seguito.\n\n\n# Valori possibili della variabile casuale X\nvalori_X &lt;- c(2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12)\n\n# Probabilità associate a ciascun valore di X\nprobabilita_X &lt;- c(\n  1 / 36,\n  2 / 36,\n  3 / 36,\n  4 / 36,\n  5 / 36,\n  6 / 36,\n  5 / 36,\n  4 / 36,\n  3 / 36,\n  2 / 36,\n  1 / 36\n)\n\ndat &lt;- data.frame(\n  Valore = valori_X,\n  Probabilità = probabilita_X\n)\n\nggplot(dat, aes(x = Valore, y = Probabilità)) +\n  geom_bar(\n    stat = \"identity\"\n    ) +\n  labs(\n    x = \"Valore della variabile casuale X\",\n    y = \"Probabilità P(X = x)\",\n    title = \"Distribuzione di Massa di Probabilità\\ndella Variabile Casuale X\"\n  )",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_random_var.html#funzione-di-distribuzione-cumulativa-cdf",
    "href": "chapters/probability/05_random_var.html#funzione-di-distribuzione-cumulativa-cdf",
    "title": "30  Variabili casuali",
    "section": "\n30.7 Funzione di Distribuzione Cumulativa (CDF)",
    "text": "30.7 Funzione di Distribuzione Cumulativa (CDF)\nLa Funzione di Distribuzione Cumulativa (CDF) è uno strumento fondamentale nella teoria della probabilità per descrivere la distribuzione di una variabile casuale.\n\n30.7.1 Definizione\nPer una variabile casuale \\(X\\), la funzione di distribuzione cumulativa \\(F(x)\\) è definita come:\n\\[\nF(x) = P(X \\leq x),\n\\]\ndove:\n\n\n\\(X\\) è la variabile casuale.\n\n\\(P(X \\leq x)\\) rappresenta la probabilità che \\(X\\) assuma un valore minore o uguale a \\(x\\).\n\nIn altre parole, \\(F(x)\\) quantifica la probabilità cumulativa dall’estremo inferiore dello spazio di probabilità fino al punto \\(x\\).\n\n30.7.2 Proprietà della CDF\n\n\nMonotonia non decrescente:\n\nPer \\(x_1 &lt; x_2\\), \\(F(x_1) \\leq F(x_2)\\).\nLa CDF non diminuisce mai quando ci si sposta da sinistra a destra lungo l’asse \\(x\\).\n\n\n\nNormalizzazione:\n\n\n\\(\\lim_{{x \\to -\\infty}} F(x) = 0 \\quad \\text{e} \\quad \\lim_{{x \\to +\\infty}} F(x) = 1\\).\nLa CDF parte da 0 quando \\(x\\) tende a \\(-\\infty\\) e raggiunge 1 quando \\(x\\) tende a \\(+\\infty\\).\n\n\n\nContinuità a destra:\n\n\n\\(F(x) = \\lim_{{y \\to x^+}} F(y)\\).\nLa CDF è continua da destra, il che significa che non presenta salti improvvisi quando ci si avvicina a un punto da destra.\n\n\n\n30.7.3 CDF per Variabili Casuali Discrete\nPer una variabile casuale discreta \\(X\\), la CDF (anche chiamata funzione di ripartizione cumulativa) è definita come:\n\\[\nF(x) = P(X \\leq x) = \\sum_{x_i \\leq x} P(X = x_i),\n\\]\ndove la somma è calcolata su tutti i valori \\(x_i\\) minori o uguali a \\(x\\).\n\n30.7.4 Importanza e Applicazioni\n\nLa CDF offre una rappresentazione visiva di come le probabilità si accumulano lungo l’intero intervallo dei possibili valori della variabile casuale.\nLa CDF permette di calcolare facilmente la probabilità che \\(X\\) cada in un intervallo specifico:\n\n\\[\nP(a &lt; X \\leq b) = F(b) - F(a).\n\\]\n\nLa CDF è utilizzata in vari metodi di generazione di variabili casuali, come il metodo della trasformazione inversa.\nLe CDF facilitano il confronto tra diverse distribuzioni di probabilità, consentendo di valutare differenze nelle loro caratteristiche cumulative.\n\nIn conclusione, la CDF è uno strumento versatile e potente che fornisce una descrizione completa della distribuzione di probabilità di una variabile casuale, sia essa discreta o continua.\n\nEsempio 30.3 Nel caso del lancio di due dadi, con la variabile casuale \\(Z\\) definita come la somma dei loro valori, la funzione di distribuzione cumulativa \\(F(z)\\) può essere illustrata come segue:\n\n\n\\(z\\)\n\\(P(Z = z)\\)\n\\(F(z)\\)\n\n\n\n2\n\\(\\frac{1}{36}\\)\n\\(\\frac{1}{36}\\)\n\n\n3\n\\(\\frac{2}{36}\\)\n\\(\\frac{3}{36}\\)\n\n\n4\n\\(\\frac{3}{36}\\)\n\\(\\frac{6}{36}\\)\n\n\n5\n\\(\\frac{4}{36}\\)\n\\(\\frac{10}{36}\\)\n\n\n6\n\\(\\frac{5}{36}\\)\n\\(\\frac{15}{36}\\)\n\n\n7\n\\(\\frac{6}{36}\\)\n\\(\\frac{21}{36}\\)\n\n\n8\n\\(\\frac{5}{36}\\)\n\\(\\frac{26}{36}\\)\n\n\n9\n\\(\\frac{4}{36}\\)\n\\(\\frac{30}{36}\\)\n\n\n10\n\\(\\frac{3}{36}\\)\n\\(\\frac{33}{36}\\)\n\n\n11\n\\(\\frac{2}{36}\\)\n\\(\\frac{35}{36}\\)\n\n\n12\n\\(\\frac{1}{36}\\)\n\\(\\frac{36}{36}\\)\n\n\n\nIn questa tabella:\n\n\n\\(P(Z = z)\\) rappresenta la probabilità che la somma dei due dadi sia esattamente \\(z\\).\n\n\\(F(z)\\) è la funzione di distribuzione cumulativa, che fornisce la probabilità che la somma \\(Z\\) sia minore o uguale a \\(z\\).\n\nQuesta tabella mostra come le probabilità cumulative si accumulano per la variabile casuale \\(Z\\), evidenziando la distribuzione delle somme possibili quando si lanciano due dadi. Ad esempio, \\(F(7) = \\frac{21}{36}\\) indica che la probabilità che la somma sia 7 o inferiore è \\(\\frac{21}{36}\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_random_var.html#trovare-la-distribuzione-di-probabilità-attraverso-una-simulazione",
    "href": "chapters/probability/05_random_var.html#trovare-la-distribuzione-di-probabilità-attraverso-una-simulazione",
    "title": "30  Variabili casuali",
    "section": "\n30.8 Trovare la Distribuzione di Probabilità attraverso una Simulazione",
    "text": "30.8 Trovare la Distribuzione di Probabilità attraverso una Simulazione\nLa distribuzione di probabilità teorica per il lancio di due dadi può essere calcolata analiticamente, ma un’alternativa altrettanto valida è ottenere una stima empirica tramite simulazione. Questo approccio consiste nel ripetere l’esperimento casuale un numero elevato di volte e analizzare le frequenze relative dei risultati ottenuti. Aumentando il numero di simulazioni, la distribuzione empirica tende a convergere verso quella teorica.\nDi seguito vedremo come implementare una simulazione in R per calcolare la distribuzione empirica di probabilità dei risultati ottenuti sommando i punteggi di due dadi.\n\nEsempio 30.4 Iniziamo definendo una funzione che simula il lancio di un dado a sei facce, restituendo un valore casuale tra 1 e 6.\n\n# Funzione per simulare il lancio di un dado\nroll_die &lt;- function() {\n  sample(1:6, size = 1)\n}\n\nPossiamo ora definire una funzione che calcola la somma dei valori di due dadi lanciati simultaneamente. La funzione accetta come argomento il numero di ripetizioni da effettuare e restituisce un vettore contenente i risultati.\n\n# Funzione per simulare il lancio di due dadi per n volte\nroll_two_dice &lt;- function(n) {\n  map_dbl(1:n, ~ roll_die() + roll_die())\n}\n\nUtilizziamo la funzione appena definita per simulare 100.000 lanci di due dadi. Memorizziamo i risultati in un oggetto res e visualizziamo i primi 20 valori.\n\n# Numero di simulazioni\nnrolls &lt;- 100000\n\n# Simula i risultati del lancio di due dadi\nres &lt;- roll_two_dice(nrolls)\n\n# Visualizza i primi 20 risultati\ncat(res[1:20], \"\\n\")\n#&gt; 6 2 6 4 5 6 10 4 4 4 9 10 6 7 3 8 9 6 10 7\n\nUtilizzando il tidyverse, possiamo creare un DataFrame contenente i risultati della simulazione e calcolare la distribuzione empirica delle probabilità. Per fare ciò, calcoliamo le frequenze assolute dei risultati, le normalizziamo dividendo per il numero totale di simulazioni e assicuriamo che siano rappresentati tutti i possibili valori (da 2 a 12).\n\n# Converti i risultati in un DataFrame (tibble)\ndf &lt;- tibble(y = res)\n\n# Calcola la distribuzione empirica delle probabilità\nempirical_probs &lt;- df %&gt;%\n  count(y) %&gt;%                             # Calcola le frequenze assolute\n  complete(y = 2:12, fill = list(n = 0)) %&gt;% # Assicura che tutti i valori siano inclusi\n  mutate(prob = n / nrolls)                # Calcola le probabilità relative\n\n# Visualizza la distribuzione empirica\nempirical_probs %&gt;%\n  dplyr::select(y, prob)\n#&gt; # A tibble: 11 × 2\n#&gt;       y   prob\n#&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1     2 0.0282\n#&gt; 2     3 0.0566\n#&gt; 3     4 0.0849\n#&gt; 4     5 0.111 \n#&gt; 5     6 0.139 \n#&gt; 6     7 0.165 \n#&gt; # ℹ 5 more rows\n\nIl risultato finale è una tabella che mostra i valori possibili (da 2 a 12) e la loro probabilità empirica stimata. Questa distribuzione empirica dovrebbe essere molto simile alla distribuzione teorica, specialmente considerando un numero elevato di simulazioni.\nQuesto approccio dimostra come sia possibile utilizzare la simulazione per approssimare distribuzioni di probabilità, una tecnica particolarmente utile quando la soluzione analitica non è immediatamente disponibile.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_random_var.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/05_random_var.html#informazioni-sullambiente-di-sviluppo",
    "title": "30  Variabili casuali",
    "section": "\n30.9 Informazioni sull’Ambiente di Sviluppo",
    "text": "30.9 Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] see_0.9.0        gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1\n#&gt;  [5] psych_2.4.12     scales_1.3.0     markdown_1.13    knitr_1.49      \n#&gt;  [9] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [13] purrr_1.0.2      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [17] ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.3         rlang_1.1.4       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       yaml_2.3.10       tools_4.4.2       parallel_4.4.2   \n#&gt; [21] tzdb_0.4.0        colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5      \n#&gt; [25] R6_2.5.1          lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3  \n#&gt; [29] pillar_1.10.0     gtable_0.3.6      glue_1.8.0        xfun_0.49        \n#&gt; [33] tidyselect_1.2.1  farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-166     \n#&gt; [37] labeling_0.4.3    rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_random_var.html#bibliografia",
    "href": "chapters/probability/05_random_var.html#bibliografia",
    "title": "30  Variabili casuali",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlitzstein, J. K., & Hwang, J. (2019). Introduction to probability. CRC Press.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_expval_var.html",
    "href": "chapters/probability/06_expval_var.html",
    "title": "31  Proprietà delle variabili casuali",
    "section": "",
    "text": "31.1 Introduzione\nPrerequisiti\nPrima di affrontare il presente capitolo, è essenziale leggere la sezione ?sec-calculus.\nConcetti e Competenze Chiave\nPreparazione del Notebook\nSintetizzare la distribuzione di una variabile casuale attraverso indicatori caratteristici è spesso molto utile. Questi indicatori consentono di cogliere le principali proprietà della distribuzione, come la posizione centrale (ovvero il “baricentro”) e la variabilità (ossia la dispersione attorno al centro). In questo modo, è possibile ottenere una descrizione sintetica e significativa della distribuzione di probabilità della variabile casuale.\nIn questo capitolo, introdurremo i concetti fondamentali di valore atteso e varianza di una variabile casuale, che sono strumenti essenziali per comprendere e riassumere le proprietà di una distribuzione probabilistica.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_expval_var.html#valore-atteso",
    "href": "chapters/probability/06_expval_var.html#valore-atteso",
    "title": "31  Proprietà delle variabili casuali",
    "section": "\n31.2 Valore Atteso",
    "text": "31.2 Valore Atteso\nQuando vogliamo comprendere il comportamento tipico di una variabile casuale, ci interessa spesso determinare il suo “valore tipico”. Tuttavia, questa nozione può essere interpretata in diversi modi:\n\n\nMedia: La somma dei valori divisa per il numero dei valori.\n\nMediana: Il valore centrale della distribuzione, quando i dati sono ordinati in senso crescente o decrescente.\n\nModa: Il valore che si verifica con maggiore frequenza.\n\nAd esempio, per il set di valori \\(\\{3, 1, 4, 1, 5\\}\\), la media è \\(\\frac{3+1+4+1+5}{5} = 2.8\\), la mediana è 3, e la moda è 1. Tuttavia, quando ci occupiamo di variabili casuali, anziché di semplici sequenze di numeri, diventa necessario chiarire cosa intendiamo per “valore tipico” in questo contesto. Questo ci porta alla definizione formale del valore atteso.\n\nDefinizione 31.1 Sia \\(X\\) una variabile casuale discreta che assume i valori \\(x_1, \\dots, x_n\\) con probabilità \\(P(X = x_i) = p(x_i)\\). Il valore atteso di \\(X\\), denotato con \\(\\mathbb{E}(X)\\), è definito come:\n\\[\n\\mathbb{E}(X) = \\sum_{i=1}^n x_i \\cdot p(x_i).\n\\]\n\nIn altre parole, il valore atteso (noto anche come speranza matematica o aspettazione) di una variabile casuale è la somma di tutti i valori che la variabile può assumere, ciascuno ponderato dalla probabilità con cui esso si verifica.\n\nEsempio 31.1 Calcoliamo il valore atteso della variabile casuale \\(X\\) corrispondente al lancio di una moneta equilibrata, dove testa corrisponde a \\(X = 1\\) e croce corrisponde a \\(X = 0\\):\n\\[\n\\mathbb{E}(X) = \\sum_{i=1}^{2} x_i \\cdot P(x_i) = 0 \\cdot \\frac{1}{2} + 1 \\cdot \\frac{1}{2} = 0.5.\n\\]\n\n\nEsempio 31.2 Calcoliamo il valore atteso della variabile casuale \\(X\\) che rappresenta la somma dei punti ottenuti dal lancio di due dadi equilibrati a sei facce.\nLa variabile casuale \\(X\\) può assumere i seguenti valori:\n\\[\n\\{2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12\\}.\n\\]\nLa probabilità associata a ciascun valore è data dalla distribuzione di massa di probabilità. Ad esempio, il valore \\(X = 2\\) si ottiene solo se entrambi i dadi mostrano 1, quindi ha probabilità:\n\\[\nP(X = 2) = \\frac{1}{36}.\n\\]\nAnalogamente, \\(X = 7\\) può essere ottenuto con sei combinazioni diverse: (1,6), (2,5), (3,4), (4,3), (5,2), (6,1), quindi:\n\\[\nP(X = 7) = \\frac{6}{36}.\n\\]\nLa distribuzione di massa di probabilità completa è: $$\nP(X) = {, , , , , , , , , , }. $$\nIl valore atteso \\(\\mathbb{E}[X]\\) è definito come:\n\\[\n\\mathbb{E}[X] = \\sum_{x} x \\cdot P(X = x).\n\\]\nApplicando questa formula:\n\\[\n\\mathbb{E}[X] = 2 \\cdot \\frac{1}{36} + 3 \\cdot \\frac{2}{36} + 4 \\cdot \\frac{3}{36} + \\cdots + 12 \\cdot \\frac{1}{36} = 7.\n\\]\nEcco come calcolarlo utilizzando R:\n\n# Valori di X e le loro probabilità\nvalori &lt;- 2:12\nprob &lt;- c(1, 2, 3, 4, 5, 6, 5, 4, 3, 2, 1) / 36\n\n# Calcolo del valore atteso\nvalore_atteso &lt;- sum(valori * prob)\nvalore_atteso\n#&gt; [1] 7\n\nIl risultato sarà: \\[\n\\mathbb{E}[X] = 7.\n\\]\nPer rappresentare graficamente la distribuzione di massa di probabilità:\n\n# Creazione di un data frame\ndati &lt;- data.frame(Valore = valori, Probabilità = prob)\n\n# Plot\nggplot(dati, aes(x = Valore, y = Probabilità)) +\n  geom_col() +\n  labs(\n    title = \"Distribuzione di Massa di Probabilità per X\",\n    x = \"Valore della Somma (X)\",\n    y = \"Probabilità\"\n  ) \n\n\n\n\n\n\n\n\n\n31.2.1 Interpretazione\nIl valore atteso di una variabile casuale corrisponde alla media aritmetica di un ampio numero di realizzazioni indipendenti della variabile stessa.\nPer chiarire questo concetto, consideriamo nuovamente l’esempio del lancio di due dadi bilanciati a sei facce, dove la variabile casuale \\(X\\) rappresenta la “somma dei due dadi”. Simuliamo un grande numero di realizzazioni indipendenti di \\(X\\).\n\nset.seed(123)  \nx_samples &lt;- sample(valori, size = 1e6, replace = TRUE, prob = prob)\n\nL’istruzione sample(x, size = 1e6, replace = TRUE, prob = px)) utilizza R per generare un array di 1.000.000 di elementi (specificato dal parametro size), selezionati casualmente dall’array x secondo le probabilità specificate nell’array px.\nQuando il numero di realizzazioni indipendenti è sufficientemente grande, la media aritmetica dei campioni generati si avvicina al valore atteso della variabile casuale:\n\nmean(x_samples)\n#&gt; [1] 7\n\nQuesto risultato conferma che il valore atteso \\(\\mathbb{E}[X] = 7\\) rappresenta la somma media dei punti ottenuti nel lancio di due dadi equilibrati su un numero elevato di prove. Anche se ogni singola somma può variare tra 2 e 12, in media ci aspettiamo una somma di 7.\n\n31.2.2 Proprietà del Valore Atteso\nUna delle proprietà più importanti del valore atteso è la sua linearità: il valore atteso della somma di due variabili casuali è uguale alla somma dei loro rispettivi valori attesi:\n\\[\n\\mathbb{E}(X + Y) = \\mathbb{E}(X) + \\mathbb{E}(Y).\n\\tag{31.1}\\]\nQuesta proprietà, espressa dalla formula sopra, è intuitiva quando \\(X\\) e \\(Y\\) sono variabili casuali indipendenti, ma è valida anche nel caso in cui \\(X\\) e \\(Y\\) siano correlate.\nInoltre, se moltiplichiamo una variabile casuale per una costante \\(c\\), il valore atteso del prodotto è uguale alla costante moltiplicata per il valore atteso della variabile casuale:\n\\[\n\\mathbb{E}(cY) = c \\mathbb{E}(Y).\n\\tag{31.2}\\]\nQuesta proprietà ci dice che una costante può essere “estratta” dall’operatore di valore atteso, e si applica a qualunque numero di variabili casuali.\nUn’altra proprietà significativa riguarda il prodotto di variabili casuali indipendenti. Se \\(X\\) e \\(Y\\) sono indipendenti, allora il valore atteso del loro prodotto è uguale al prodotto dei loro valori attesi:\n\\[\n\\mathbb{E}(XY) = \\mathbb{E}(X) \\mathbb{E}(Y).\n\\tag{31.3}\\]\nInfine, consideriamo la media aritmetica \\(\\bar{X} = \\frac{X_1 + \\ldots + X_n}{n}\\) di \\(n\\) variabili casuali indipendenti con la stessa distribuzione e con valore atteso \\(\\mu\\). Il valore atteso della media aritmetica è:\n\\[\n\\mathbb{E}(\\bar{X}) = \\frac{1}{n} \\left(\\mathbb{E}(X_1) + \\dots + \\mathbb{E}(X_n)\\right) = \\frac{1}{n} \\cdot n \\cdot \\mathbb{E}(X) = \\mu.\n\\]\nQuesto risultato conferma che la media aritmetica di un campione di variabili casuali indipendenti ha lo stesso valore atteso della distribuzione originaria, rendendo il valore atteso uno strumento cruciale per l’analisi statistica e probabilistica.\n\nEsempio 31.3 Consideriamo il seguente esperimento casuale. Sia \\(Y\\) il numero che si ottiene dal lancio di un dado equilibrato a sei facce e \\(Y\\) il numero di teste prodotto dal lancio di una moneta equilibrata (0 oppure 1). Troviamo il valore atteso di \\(X+Y\\).\nPer risolvere il problema iniziamo a costruire lo spazio campione dell’esperimento casuale.\n\n\n\n\n\n\n\n\n\n\n\n\\(x /\\ y\\)\n1\n2\n3\n4\n5\n6\n\n\n\n0\n(0, 1)\n(0, 2)\n(0, 3)\n(0, 4)\n(0, 5)\n(0, 6)\n\n\n1\n(1, 1)\n(1, 2)\n(1, 3)\n(1, 4)\n(1, 5)\n(1, 6)\n\n\n\novvero\n\n\n\\(x /\\ y\\)\n1\n2\n3\n4\n5\n6\n\n\n\n0\n1\n2\n3\n4\n5\n6\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\nIl risultato del lancio del dado è indipendente dal risultato del lancio della moneta. Pertanto, ciascun evento elementare dello spazio campione avrà la stessa probabilità di verificarsi, ovvero \\(P(\\omega) = \\frac{1}{12}\\). Il valore atteso di \\(X+Y\\) è dunque uguale a:\n\\[\n\\mathbb{E}(X+Y) = 1 \\cdot \\frac{1}{12} + 2 \\cdot \\frac{1}{12} + \\dots + 7 \\cdot \\frac{1}{12} = 4.0.\n\\]\nSi ottiene lo stesso risultato usando l’Equazione 31.1:\n\\[\n\\mathbb{E}(X+Y) = \\mathbb{E}(X) + E(Y) = 3.5 + 0.5 = 4.0.\n\\]\n\n\nEsempio 31.4 Svolgiamo ora l’esercizio in R\n\ncoin &lt;- 0:1  # Valori della moneta: testa (0) e croce (1)\ndie &lt;- 1:6   # Valori del dado: da 1 a 6\n\n# Creazione del campione come combinazione di valori (moneta, dado)\nsample &lt;- expand.grid(coin = coin, die = die)\nprint(sample)\n#&gt;    coin die\n#&gt; 1     0   1\n#&gt; 2     1   1\n#&gt; 3     0   2\n#&gt; 4     1   2\n#&gt; 5     0   3\n#&gt; 6     1   3\n#&gt; 7     0   4\n#&gt; 8     1   4\n#&gt; 9     0   5\n#&gt; 10    1   5\n#&gt; 11    0   6\n#&gt; 12    1   6\n\n\npx &lt;- numeric()  # Vettore per memorizzare le probabilità\n\nfor (i in 1:7) {\n  # Filtrare le combinazioni in cui la somma è uguale a 'i'\n  event &lt;- subset(sample, coin + die == i)\n  # Calcolare la probabilità\n  prob &lt;- nrow(event) / nrow(sample)\n  px &lt;- c(px, prob)\n  \n  # Stampare la probabilità\n  cat(sprintf(\"P(X + Y = %d) = %d / %d\\n\", i, nrow(event), nrow(sample)))\n}\n#&gt; P(X + Y = 1) = 1 / 12\n#&gt; P(X + Y = 2) = 2 / 12\n#&gt; P(X + Y = 3) = 2 / 12\n#&gt; P(X + Y = 4) = 2 / 12\n#&gt; P(X + Y = 5) = 2 / 12\n#&gt; P(X + Y = 6) = 2 / 12\n#&gt; P(X + Y = 7) = 1 / 12\n\n\nx &lt;- 1:7  # Valori della variabile casuale (somma di moneta e dado)\nexpected_value &lt;- sum(x * px)\nexpected_value\n#&gt; [1] 4\n\n\n\nEsempio 31.5 Consideriamo le variabili casuali \\(X\\) e \\(Y\\) definite nel caso del lancio di tre monete equilibrate, dove \\(X\\) conta il numero delle teste nei tre lanci e \\(Y\\) conta il numero delle teste al primo lancio. Si calcoli il valore atteso di \\(Z = X \\cdot Y\\).\nLa distribuzione di probabilità congiunta \\(P(X, Y)\\) è fornita nella tabella seguente.\n\n\n\\(x /\\ y\\)\n0\n1\n\\(p(Y)\\)\n\n\n\n0\n1/8\n0\n1/8\n\n\n1\n2/8\n1/8\n3/8\n\n\n2\n1/8\n2/8\n3/8\n\n\n3\n0\n1/8\n1/8\n\n\n\\(p(y)\\)\n4/8\n4/8\n1.0\n\n\n\nIl calcolo del valore atteso di \\(XY\\) si riduce a\n\\[\n\\mathbb{E}(Z) = 1 \\cdot \\frac{1}{8} + 2 \\cdot \\frac{2}{8} + 3 \\cdot \\frac{1}{8} = 1.0.\n\\]\nSi noti che le variabili casuali \\(Y\\) e \\(Y\\) non sono indipendenti. Dunque non possiamo usare l’Equazione 31.3. Infatti, il valore atteso di \\(X\\) è\n\\[\n\\mathbb{E}(X) = 1 \\cdot \\frac{3}{8} + 2 \\cdot \\frac{3}{8} + 3 \\cdot \\frac{1}{8} = 1.5\n\\]\ne il valore atteso di \\(Y\\) è\n\\[\n\\mathbb{E}(Y) = 0 \\cdot \\frac{4}{8} + 1 \\cdot \\frac{4}{8} = 0.5.\n\\]\nPerciò\n\\[\n1.5 \\cdot 0.5 \\neq 1.0.\n\\]\n\n\n31.2.3 Variabili casuali continue\nNel caso di una variabile casuale continua \\(X\\), il valore atteso è definito come:\n\\[\n\\mathbb{E}(X) = \\int_{-\\infty}^{+\\infty} x \\cdot p(x) \\, \\mathrm{d}x.\n\\]\nAnche in questo contesto, il valore atteso rappresenta una media ponderata dei valori di \\(x\\), dove ogni possibile valore di \\(x\\) è ponderato in base alla densità di probabilità \\(p(x)\\).\nL’integrale può essere interpretato analogamente a una somma continua, in cui \\(x\\) rappresenta la posizione delle barre infinitamente strette di un istogramma, e \\(p(x)\\) rappresenta l’altezza di tali barre. La notazione \\(\\int_{-\\infty}^{+\\infty}\\) indica che si sta sommando il contributo di ogni valore possibile di \\(x\\) lungo l’intero asse reale.\nQuesta interpretazione rende chiaro come l’integrale calcoli una somma ponderata che si estende su tutti i possibili valori di \\(x\\), fornendo una misura centrale della distribuzione della variabile casuale continua. Per ulteriori dettagli sulla notazione dell’integrale, si veda l’?sec-calculus.\n\n31.2.3.1 Moda\nUn’altra misura di tendenza centrale delle variabili casuali continue è la moda. La moda di \\(Y\\) individua il valore \\(y\\) più plausibile, ovvero il valore \\(y\\) che massimizza la funzione di densità \\(p(y)\\):\n\\[\nMo(Y) = \\text{argmax}_y p(y).\n\\tag{31.4}\\]\n\n\n\n\n\n\nLa notazione \\(\\text{argmax}_y p(y)\\) significa: il valore \\(y\\) tale per cui la funzione \\(p(y)\\) assume il suo valore massimo.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_expval_var.html#varianza",
    "href": "chapters/probability/06_expval_var.html#varianza",
    "title": "31  Proprietà delle variabili casuali",
    "section": "\n31.3 Varianza",
    "text": "31.3 Varianza\nDopo il valore atteso, la seconda proprietà più importante di una variabile casuale è la varianza.\n\nDefinizione 31.2 Se \\(X\\) è una variabile casuale discreta con distribuzione \\(p(x)\\), la varianza di \\(X\\), denotata con \\(\\mathbb{V}(X)\\), è definita come:\n\\[\n\\mathbb{V}(X) = \\mathbb{E}\\Big[\\big(X - \\mathbb{E}(X)\\big)^2\\Big].\n\\tag{31.5}\\]\n\nIn altre parole, la varianza misura la deviazione media quadratica dei valori della variabile rispetto alla sua media. Se denotiamo il valore atteso di \\(X\\) con \\(\\mu = \\mathbb{E}(X)\\), la varianza \\(\\mathbb{V}(X)\\) diventa il valore atteso di \\((X - \\mu)^2\\).\n\n31.3.1 Interpretazione della Varianza\nLa varianza rappresenta una misura della “dispersione” dei valori di \\(X\\) intorno al suo valore atteso. Quando calcoliamo la varianza, stiamo effettivamente misurando quanto i valori di \\(X\\) tendono a differire dalla media \\(\\mu\\).\nPer capire meglio, consideriamo la variabile casuale \\(X - \\mathbb{E}(X)\\), detta scarto o deviazione dalla media. Questa variabile rappresenta le “distanze” tra i valori di \\(X\\) e il valore atteso \\(\\mathbb{E}(X)\\). Tuttavia, poiché lo scarto può essere positivo o negativo, la media dello scarto è sempre zero, il che lo rende inadatto a quantificare la dispersione.\nPer risolvere questo problema, eleviamo al quadrato gli scarti, ottenendo \\((X - \\mathbb{E}(X))^2\\), che rende tutte le deviazioni positive. La varianza è quindi la media di questi scarti al quadrato, fornendo una misura efficace della dispersione complessiva dei valori di \\(X\\) rispetto alla sua media.\nQuesto concetto è fondamentale per comprendere la variabilità di una distribuzione e per applicare strumenti statistici che richiedono una conoscenza approfondita della distribuzione dei dati.\n\nEsempio 31.6 Posta \\(S\\) uguale alla somma dei punti ottenuti nel lancio di due dadi equilibrati, si calcoli la varianza di \\(S\\).\nLa variabile casuale \\(S\\) ha la seguente distribuzione di probabilità:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(s\\)\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\\(P(S = s)\\)\n\\(\\frac{1}{36}\\)\n\\(\\frac{2}{36}\\)\n\\(\\frac{3}{36}\\)\n\\(\\frac{4}{36}\\)\n\\(\\frac{5}{36}\\)\n\\(\\frac{6}{36}\\)\n\\(\\frac{5}{36}\\)\n\\(\\frac{4}{36}\\)\n\\(\\frac{3}{36}\\)\n\\(\\frac{2}{36}\\)\n\\(\\frac{1}{36}\\)\n\n\nEssendo \\(\\mathbb{E}(S) = 7\\), la varianza diventa\n\\[\n\\begin{align}\n\\mathbb{V}(S) &= \\sum \\left(s - \\mathbb{E}(S)\\right)^2 \\cdot P(s) \\notag\\\\\n&= (2 - 7)^2 \\cdot \\frac{1}{36} + (3-7)^2 \\cdot \\frac{3}{36} + \\dots + (12 - 7)^2 \\cdot \\frac{1}{36} \\notag\\\\\n&= 5.8333.\\notag\n\\end{align}\n\\]\n\n\nEsempio 31.7 Svolgiamo l’esercizio in R\n\n# Definire i valori di x e le loro probabilità px\nx &lt;- 2:12\npx &lt;- c(\n  1 / 36, 2 / 36, 3 / 36, 4 / 36, 5 / 36, 6 / 36,\n  5 / 36, 4 / 36, 3 / 36, 2 / 36, 1 / 36\n)\n\n# Calcolare il valore atteso\nex &lt;- sum(x * px)\nex\n#&gt; [1] 7\n\nApplichiamo l’Equazione 31.5:\n\n# Calcolo della varianza utilizzando la definizione\nvariance &lt;- sum((x - ex)^2 * px)\nvariance\n#&gt; [1] 5.83\n\nUsiamo la funzione var() di rv_discrete:\n\n# Calcolo della varianza con pesi\nvariance_check &lt;- weighted.mean((x - ex)^2, w = px)\nvariance_check\n#&gt; [1] 5.83\n\n\n\n31.3.2 Formula Alternativa per la Varianza\nEsiste un metodo più semplice e diretto per calcolare la varianza di una variabile casuale \\(X\\):\n\\[\n\\begin{align}\n\\mathbb{E}\\Big[\\big(X - \\mathbb{E}(X)\\big)^2\\Big] &= \\mathbb{E}\\big(X^2 - 2Y\\mathbb{E}(X) + \\mathbb{E}(X)^2\\big) \\notag\\\\\n&= \\mathbb{E}(X^2) - 2\\mathbb{E}(Y)\\mathbb{E}(X) + \\mathbb{E}(X)^2,\n\\end{align}\n\\]\ndove \\(\\mathbb{E}(X)\\) è una costante. Semplificando ulteriormente, otteniamo:\n\\[\n\\mathbb{V}(X) = \\mathbb{E}(X^2) - \\big(\\mathbb{E}(X)\\big)^2.\n\\tag{31.6}\\]\nIn altre parole, la varianza è data dalla differenza tra la media dei quadrati dei valori di \\(X\\) e il quadrato della media di \\(X\\).\nQuesta formula è utile perché permette di calcolare la varianza senza dover prima determinare lo scarto quadratico medio per ciascun valore di \\(X\\). Invece, si può calcolare direttamente la media dei quadrati e sottrarre il quadrato della media, il che spesso semplifica i calcoli e riduce il rischio di errori.\n\nEsempio 31.8 Consideriamo la variabile casuale \\(X\\) che corrisponde al numero di teste che si osservano nel lancio di una moneta truccata con probabilità di testa uguale a 0.8. Si trovi la varianza di \\(Y\\).\nIl valore atteso di \\(X\\) è\n\\[\n\\mathbb{E}(X) = 0 \\cdot 0.2 + 1 \\cdot 0.8 = 0.8.\n\\]\nUsando la formula tradizionale della varianza otteniamo:\n\\[\n\\mathbb{V}(X) = (0 - 0.8)^2 \\cdot 0.2 + (1 - 0.8)^2 \\cdot 0.8 = 0.16.\n\\]\nLo stesso risultato si trova con la formula alternativa della varianza. Il valore atteso di \\(X^2\\) è\n\\[\n\\mathbb{E}(X^2) = 0^2 \\cdot 0.2 + 1^2 \\cdot 0.8 = 0.8.\n\\]\ne la varianza diventa\n\\[\n\\mathbb{V}(X) = \\mathbb{E}(X^2) - \\big(\\mathbb{E}(Y) \\big)^2 = 0.8 - 0.8^2 = 0.16.\n\\]\n\n\nEsempio 31.9 Svolgiamo l’esercizio in R:\n\n# Definire i valori di x e le probabilità px\nx &lt;- c(0, 1)\npx &lt;- c(0.2, 0.8)\n\n# Calcolare il risultato\nresult &lt;- sum(x^2 * px) - (sum(x * px))^2\nresult\n#&gt; [1] 0.16\n\n\n\n31.3.3 Proprietà\nSegno della varianza. La varianza di una variabile aleatoria non è mai negativa, ed è zero solamente quando la variabile assume un solo valore.\nInvarianza per traslazione. La varianza è invariante per traslazione, che lascia fisse le distanze dalla media, e cambia quadraticamente per riscalamento:\n\\[\n\\mathbb{V}(a + bX) = b^2\\mathbb{V}(X).\n\\]\nDimostrazione. Iniziamo a scrivere\n\\[\n(aX+b)-{\\mathbb{E}}[aX+b]=aX+b-a{\\mathbb{E}}[X]-b=a(X-{\\mathbb  {E}}[X]).\n\\]\nQuindi\n\\[\n\\sigma _{{aX+b}}^{2}={\\mathbb{E}}[a^{2}(X-{\\mathbb  {E}}[X])^{2}]=a^{2}\\sigma _{X}^{2}.\n\\]\nEsaminiamo una dimostrazione numerica.\n\n# Definire i valori di x\nx &lt;- c(2, 1, 4, 7)\n\n# Calcolare y\ny &lt;- 100 + 2 * x\n\n# Verificare la relazione tra le varianze\nresult &lt;- var(y) == 2^2 * var(x)\nresult\n#&gt; [1] TRUE\n\nVarianza della somma di due variabili indipendenti. La varianza della somma di due variabili indipendenti o anche solo incorrelate è pari alla somma delle loro varianze:\n\\[\n\\mathbb{V}(X+Y) = \\mathbb{V}(X) + \\mathbb{V}(Y).\n\\]\nDimostrazione. Se \\(\\mathbb{E}(X) = \\mathbb{E}(Y) = 0\\), allora \\(\\mathbb{E}(X+Y) = 0\\) e\n\\[\\mathbb{V}(X+Y) = \\mathbb{E}((X+Y)^2) = \\mathbb{E}(X^2) + 2 \\mathbb{E}(XY) + \\mathbb{E}(Y^2).\\]\nSiccome le variabili sono indipendenti risulta \\(\\mathbb{E}(XY) = \\mathbb{E}(X)\\mathbb{E}(Y) = 0\\).\nVarianza della differenza di due variabili indipendenti. La varianza della differenza di due variabili indipendenti è pari alla somma delle loro varianze:\n\\[\n\\mathbb{V}(X-Y) = \\mathbb{V}(X) + \\mathbb{V}(Y).\n\\]\nDimostrazione.\n\\[\n\\mathbb{V}(X-Y) = \\mathbb{V}(X +(-Y)) = \\mathbb{V}(X) + \\mathbb{V}(-Y) = \\mathbb{V}(X) + \\mathbb{V}(Y).\n\\]\nVarianza della somma di due variabili non indipendenti. Se \\(X\\) e \\(Y\\) non sono indipendenti, la formula viene corretta dalla loro covarianza:\n\\[\n\\mathbb{V}(X+Y) = \\mathbb{V}(X) + \\mathbb{V}(Y) + 2 Cov(X,Y),\n\\]\ndove \\(Cov(X,Y) = \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y)\\).\nUna dimostrazione numerica di questo principio è fornita sotto.\n\n# Definire i valori di x e y\nx &lt;- c(2, 1, 4, 7)\ny &lt;- c(1, 3, 5, 11)\n\n# Calcolare la varianza di x + y con ddof = 0\nvar_x_y &lt;- mean((x + y - mean(x + y))^2)\nvar_x_y\n#&gt; [1] 35.2\n\n\n# Definire i valori di x e y\nx &lt;- c(2, 1, 4, 7)\ny &lt;- c(1, 3, 5, 11)\n\n# Calcolo della varianza combinata\nresult &lt;- mean((x - mean(x))^2) + \n          mean((y - mean(y))^2) + \n          2 * cov(x, y) * (length(x) - 1) / length(x)\nresult\n#&gt; [1] 35.2\n\nVarianza della media di variabili indipendenti. La media aritmetica \\(\\textstyle {\\bar  {X}}={\\frac  {X_{1}+\\ldots +X_{n}}{n}}\\) di \\(n\\) variabili casuali indipendenti aventi la medesima distribuzione, ha varianza\n\\[\n\\mathbb{V}(\\bar{X}) = \\frac{1}{n^2} \\mathbb{V}(X_1)+ \\dots \\mathbb{V}(X_n) = \\frac{1}{n^2} n \\mathbb{V}(X) = \\frac{1}{n} \\mathbb{V}(X).\n\\]\nIl principio precedente è illustrato dalla seguente simulazione.\n\n# Creare la popolazione\nset.seed(123)  # Per riproducibilità\npopulation &lt;- rnorm(10000, mean = 50, sd = 10)\n\n# Definire dimensione del campione e numero di campioni\nsample_size &lt;- 30\nnum_samples &lt;- 100000\n\n# Creare un vettore per memorizzare le medie campionarie\nsample_means &lt;- numeric(num_samples)\n\n# Generare i campioni e calcolare le medie\nfor (i in 1:num_samples) {\n  sample &lt;- sample(population, size = sample_size, replace = TRUE)\n  sample_means[i] &lt;- mean(sample)\n}\n\n# Calcolare la varianza delle medie campionarie\nsampling_dist_mean_var &lt;- var(sample_means) * ((num_samples - 1) / num_samples)  # ddof = 0\nsampling_dist_mean_var\n#&gt; [1] 3.33\n\nIl valore teorico della varianza della distribuzione campionaria della media è\n\n10^2 / 30\n#&gt; [1] 3.33\n\n\n31.3.4 Variabili casuali continue\nPer una variabile casuale continua \\(X\\), la varianza è definita come:\n\\[\n\\mathbb{V}(X) = \\int_{-\\infty}^{+\\infty} \\large[x - \\mathbb{E}(X)\\large]^2 p(x) \\,\\operatorname {d}\\!x.\n\\tag{31.7}\\]\nAnalogamente al caso discreto, la varianza di una variabile casuale continua \\(X\\) una misura della dispersione, ovvero la “distanza” media quadratica attesa dei valori \\(x\\) rispetto alla loro media \\(\\mathbb{E}(X)\\). In altre parole, la varianza quantifica quanto i valori della variabile casuale si discostano tipicamente dal loro valore medio.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_expval_var.html#deviazione-standard",
    "href": "chapters/probability/06_expval_var.html#deviazione-standard",
    "title": "31  Proprietà delle variabili casuali",
    "section": "\n31.4 Deviazione Standard",
    "text": "31.4 Deviazione Standard\nQuando si lavora con le varianze, i valori sono elevati al quadrato, il che può rendere i numeri significativamente più grandi (o più piccoli) rispetto ai dati originali. Per riportare questi valori all’unità di misura della scala originale, si prende la radice quadrata della varianza. Il risultato ottenuto è chiamato deviazione standard ed è comunemente indicato con la lettera greca \\(\\sigma\\).\n\nDefinizione 31.3 La deviazione standard, o scarto quadratico medio, è definita come la radice quadrata della varianza:\n\\[\n\\sigma_X = \\sqrt{\\mathbb{V}(X)}.\n\\]\n\nCome nella statistica descrittiva, la deviazione standard di una variabile casuale fornisce una misura della dispersione, ossia la “distanza” tipica o prevista dei valori \\(x\\) rispetto alla loro media.\n\nEsempio 31.10 Per i dadi equilibrati dell’esempio precedente, la deviazione standard della variabile casuale \\(S\\) è pari a \\(\\sqrt{5.833} = 2.415\\). Questo valore indica quanto i risultati della somma dei due dadi tendono a variare attorno alla loro media.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_expval_var.html#standardizzazione",
    "href": "chapters/probability/06_expval_var.html#standardizzazione",
    "title": "31  Proprietà delle variabili casuali",
    "section": "\n31.5 Standardizzazione",
    "text": "31.5 Standardizzazione\n\nDefinizione 31.4 Data una variabile casuale \\(X\\), si dice variabile standardizzata di \\(X\\) l’espressione\n\\[\nZ = \\frac{X - \\mathbb{E}(X)}{\\sigma_X}.\n\\tag{31.8}\\]\n\nSolitamente, una variabile standardizzata viene denotata con la lettera \\(Z\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_expval_var.html#il-teorema-di-chebyshev",
    "href": "chapters/probability/06_expval_var.html#il-teorema-di-chebyshev",
    "title": "31  Proprietà delle variabili casuali",
    "section": "\n31.6 Il Teorema di Chebyshev",
    "text": "31.6 Il Teorema di Chebyshev\nIl Teorema di Chebyshev ci permette di stimare la probabilità che una variabile aleatoria si discosti dal suo valore atteso (media) di una certa quantità. In altre parole, ci fornisce un limite superiore alla probabilità che una variabile aleatoria assuma valori “estremi”.\nIl teorema di Chebyshev afferma che, per qualsiasi variabile aleatoria X con media E(X) e varianza Var(X), e per qualsiasi numero reale k &gt; 0, si ha:\n\\[\nP(|X - E(X)| ≥ kσ) ≤ 1/k^2,\n\\]\ndove:\n\nP(|X - E(X)| ≥ kσ) è la probabilità che lo scarto assoluto tra X e la sua media sia maggiore o uguale a k volte la deviazione standard (σ).\nσ è la radice quadrata della varianza, ovvero la deviazione standard.\n\nCosa ci dice questo teorema?\n\n\nLimite superiore: Il teorema ci fornisce un limite superiore alla probabilità che una variabile aleatoria si discosti dalla sua media di più di k deviazioni standard.\n\nQualsiasi distribuzione: La bellezza di questo teorema è che vale per qualsiasi distribuzione di probabilità, a patto che la media e la varianza esistano.\n\nUtilizzo: Il teorema di Chebyshev è molto utile quando non conosciamo la distribuzione esatta di una variabile aleatoria, ma conosciamo la sua media e la sua varianza.\n\nIn sintesi, il teorema di Chebyshev ci fornisce un limite superiore alla probabilità che una variabile aleatoria si discosti dalla sua media di una certa quantità, in base alla sua varianza. Il teorema di Chebyshev ci permette quindi di fare inferenze sulla distribuzione di una variabile aleatoria anche quando abbiamo informazioni limitate.\n\nEsempio 31.11 Supponiamo di avere una variabile aleatoria X con media 100 e varianza 25. Vogliamo stimare la probabilità che X assuma valori al di fuori dell’intervallo [90, 110]. In questo caso, k = 2 (poiché 10 è uguale a 2 volte la deviazione standard, che è 5). Applicando il teorema di Chebyshev, otteniamo:\nP(|X - 100| ≥ 10) ≤ 1/2^2 = 0.25\nQuindi, possiamo affermare con certezza che al massimo il 25% dei valori di X saranno al di fuori dell’intervallo [90, 110].",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_expval_var.html#momenti-di-variabili-casuali",
    "href": "chapters/probability/06_expval_var.html#momenti-di-variabili-casuali",
    "title": "31  Proprietà delle variabili casuali",
    "section": "\n31.7 Momenti di variabili casuali",
    "text": "31.7 Momenti di variabili casuali\n\nDefinizione 31.5 Si chiama momento di ordine \\(q\\) di una v.c. \\(X\\), dotata di densità \\(p(x)\\), la quantità\n\\[\n\\mathbb{E}(X^q) = \\int_{-\\infty}^{+\\infty} x^q p(x) \\; dx.\n\\tag{31.9}\\]\nSe \\(X\\) è una v.c. discreta, i suoi momenti valgono:\n\\[\n\\mathbb{E}(X^q) = \\sum_i x_i^q P(x_i),\n\\tag{31.10}\\]\ndove:\n\n\n\\(E(X^q)\\) rappresenta il valore atteso di \\(X\\) elevato alla \\(q\\)-esima potenza.\n\n\\(x_i\\) sono i possibili valori della variabile discreta.\n\n\\(P(x_i)\\) è la probabilità associata a ciascun valore discreto.\n\n\nI momenti sono parametri statistici che forniscono informazioni importanti sulle caratteristiche di una variabile casuale. Tra questi, i più noti e utilizzati sono:\n\nIl momento del primo ordine (\\(q\\) = 1): corrisponde al valore atteso (o media) della variabile casuale \\(X\\).\nIl momento del secondo ordine (\\(q\\) = 2): quando calcolato rispetto alla media, corrisponde alla varianza.\n\nPer i momenti di ordine superiore al primo, è comune calcolarli rispetto al valore medio di \\(X\\). Questo si ottiene applicando una traslazione: \\(x_0 = x − \\mathbb{E}(X)\\), dove \\(x_0\\) rappresenta lo scarto dalla media. In particolare, il momento centrale del secondo ordine, calcolato con questa traslazione, corrisponde alla definizione di varianza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_expval_var.html#alcuni-esempi-in-r",
    "href": "chapters/probability/06_expval_var.html#alcuni-esempi-in-r",
    "title": "31  Proprietà delle variabili casuali",
    "section": "\n31.8 Alcuni esempi in R",
    "text": "31.8 Alcuni esempi in R\nIn R, possiamo calcolare il valore atteso e la varianza di variabili casuali discrete utilizzando vettori di valori e probabilità.\nConsideriamo una variabile casuale \\(X\\) che rappresenta i valori ottenuti dal lancio di un dado non equilibrato, con valori possibili da 0 a 6, e con la seguente distribuzione di massa di probabilità: 0.1, 0.2, 0.3, 0.1, 0.1, 0.0, 0.2.\nIniziamo a definire un vettore che contiene i valori della v.c.:\n\nx &lt;- 0:6\nprint(x)\n#&gt; [1] 0 1 2 3 4 5 6\n\nIl vettore px conterrà le probabilità associate ai valori x:\n\npx &lt;- c(0.1, 0.2, 0.3, 0.1, 0.1, 0.0, 0.2)\nprint(px)\n#&gt; [1] 0.1 0.2 0.3 0.1 0.1 0.0 0.2\n\nControlliamo che la somma sia 1:\n\nsum(px)\n#&gt; [1] 1\n\nCalcoliamo il valore atteso di \\(X\\) implementando la formula del valore atteso utilizzando i vettori x e px:\n\nx_ev &lt;- sum(x * px)\nx_ev\n#&gt; [1] 2.7\n\nCalcoliamo la varianza di \\(X\\) usando i vettori x e px:\n\nx_var &lt;- sum((x - x_ev)^2 * px)\nx_var\n#&gt; [1] 3.81\n\nCalcoliamo la deviazione standard di \\(X\\) prendendo la radice quadrata della varianza:\n\nx_sd &lt;- sqrt(x_var)\nx_sd\n#&gt; [1] 1.95\n\nPer rappresentare graficamente la distribuzione di massa, possiamo usare ggplot2:\n\ndf &lt;- data.frame(x = x, pmf = px)\nggplot(df, aes(x = x, y = pmf)) +\n  geom_point(color = \"#832F2B\", size = 3) +\n  geom_segment(aes(xend = x, yend = 0), linewidth = 1) +\n  labs(title = \"Distribuzione di massa di probabilità\", \n       x = \"Valori\", y = \"Probabilità\")\n\n\n\n\n\n\n\nQuesto codice calcola il valore atteso, la varianza e la deviazione standard di una variabile casuale discreta e rappresenta graficamente la distribuzione di massa, tutto in R.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_expval_var.html#riflessioni-conclusive",
    "href": "chapters/probability/06_expval_var.html#riflessioni-conclusive",
    "title": "31  Proprietà delle variabili casuali",
    "section": "\n31.9 Riflessioni Conclusive",
    "text": "31.9 Riflessioni Conclusive\nIn conclusione, i concetti di valore atteso e varianza sono fondamentali per comprendere il comportamento delle variabili casuali. Il valore atteso fornisce una misura centrale, rappresentando il “valore tipico” che ci si aspetta di osservare, mentre la varianza quantifica la dispersione dei valori attorno a questa media, offrendo una visione più completa della distribuzione. Questi strumenti sono essenziali per l’analisi e la modellizzazione statistica, fornendo le basi per valutare e interpretare la variabilità nei fenomeni aleatori.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_expval_var.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/06_expval_var.html#informazioni-sullambiente-di-sviluppo",
    "title": "31  Proprietà delle variabili casuali",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.17.0      see_0.9.0        gridExtra_2.3    patchwork_1.3.0 \n#&gt;  [5] bayesplot_1.11.1 psych_2.4.12     scales_1.3.0     markdown_1.13   \n#&gt;  [9] knitr_1.49       lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1   \n#&gt; [13] dplyr_1.1.4      purrr_1.0.2      readr_2.1.5      tidyr_1.3.1     \n#&gt; [17] tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3       \n#&gt; [21] here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      shape_1.4.6.1     xfun_0.49         htmlwidgets_1.6.4\n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2      \n#&gt;  [9] generics_0.1.3    parallel_4.4.2    pan_1.9           pacman_0.5.1     \n#&gt; [13] pkgconfig_2.0.3   jomo_2.7-6        Matrix_1.7-1      lifecycle_1.0.4  \n#&gt; [17] compiler_4.4.2    farver_2.1.2      munsell_0.5.1     mnormt_2.1.1     \n#&gt; [21] codetools_0.2-20  htmltools_0.5.8.1 yaml_2.3.10       glmnet_4.1-8     \n#&gt; [25] nloptr_2.1.1      pillar_1.10.0     MASS_7.3-61       iterators_1.0.14 \n#&gt; [29] rpart_4.1.23      boot_1.3-31       foreach_1.5.2     mitml_0.4-5      \n#&gt; [33] nlme_3.1-166      tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4    \n#&gt; [37] labeling_0.4.3    splines_4.4.2     rprojroot_2.0.4   fastmap_1.2.0    \n#&gt; [41] grid_4.4.2        colorspace_2.1-1  cli_3.6.3         magrittr_2.0.3   \n#&gt; [45] survival_3.8-3    broom_1.0.7       withr_3.0.2       backports_1.5.0  \n#&gt; [49] timechange_0.3.0  rmarkdown_2.29    nnet_7.3-19       lme4_1.1-35.5    \n#&gt; [53] hms_1.1.3         evaluate_1.0.1    rlang_1.1.4       Rcpp_1.0.13-1    \n#&gt; [57] glue_1.8.0        minqa_1.2.8       jsonlite_1.8.9    R6_2.5.1",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_bayes_theorem.html",
    "href": "chapters/probability/07_bayes_theorem.html",
    "title": "32  Il teorema di Bayes",
    "section": "",
    "text": "32.1 Introduzione\nIl teorema di Bayes offre una soluzione ottimale ai problemi induttivi, che spaziano dall’identificazione della struttura tridimensionale del mondo basata su dati sensoriali limitati, all’inferenza dei pensieri altrui a partire dal loro comportamento. Questa regola si rivela particolarmente utile in situazioni in cui i dati osservati sono insufficienti per distinguere in modo definitivo tra diverse ipotesi.\nNonostante ciò, tutte le previsioni basate su questo metodo mantengono un certo grado di incertezza. Anche se l’universo fosse completamente deterministico, la nostra conoscenza di esso rimarrebbe imperfetta: non possiamo conoscere la posizione e lo stato di ogni singola particella che lo compone. Le informazioni a nostra disposizione sono inevitabilmente parziali e imprecise, ottenute attraverso i nostri sensi limitati.\nLa vita reale non è paragonabile a una partita di scacchi, un gioco con informazioni perfette che può essere “risolto” in linea di principio. Assomiglia piuttosto al poker, dove le decisioni vengono prese utilizzando le informazioni limitate a disposizione dei giocatori. Questo capitolo si concentra sull’equazione che ci permette di fare proprio questo: il teorema di Bayes. Esso descrive come modifichiamo le nostre convinzioni riguardo a un’ipotesi in una situazione in cui i dati disponibili non consentono una decisione certa.\nQuesto processo è noto come inferenza induttiva, che ci permette di trarre conclusioni generali da dati specifici e limitati. Il teorema di Bayes fornisce quindi un framework matematico per aggiornare le nostre credenze alla luce di nuove evidenze, permettendoci di prendere decisioni informate in un mondo caratterizzato dall’incertezza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_bayes_theorem.html#una-rivoluzione-nel-pensiero-probabilistico",
    "href": "chapters/probability/07_bayes_theorem.html#una-rivoluzione-nel-pensiero-probabilistico",
    "title": "32  Il teorema di Bayes",
    "section": "\n32.2 Una Rivoluzione nel Pensiero Probabilistico",
    "text": "32.2 Una Rivoluzione nel Pensiero Probabilistico\nNel cuore del XVIII secolo, un ecclesiastico presbiteriano di nome Thomas Bayes gettò le basi per una delle più importanti rivoluzioni nel campo della statistica e del calcolo delle probabilità. Il suo contributo, noto oggi come teorema di Bayes, non solo ha trasformato il modo in cui comprendiamo e applichiamo la probabilità, ma continua a influenzare profondamente la scienza moderna e la tecnologia, inclusa l’intelligenza artificiale (Chivers, 2024).\nThomas Bayes nacque in una famiglia benestante e ricevette un’educazione di alto livello, studiando teologia a Edimburgo per prepararsi alla vita da ecclesiastico. Come nota il suo biografo Bellhouse, Bayes “non sembrava un accademico moderno. Era più un dilettante, un virtuoso. Lo faceva per il proprio piacere piuttosto che avere un’agenda di ricerca.”\nBayes pubblicò due opere principali durante la sua vita:\n\nUna di teologia, “Divine benevolence: Or, an attempt to prove that the principal end of the divine providence and government is the happiness of his creatures”, nel 1731.\nUna difesa del calcolo newtoniano, “An Introduction to the Doctrine of Fluxions”, in risposta a una critica del filosofo George Berkeley.\n\nTuttavia, fu il suo lavoro postumo, “An Essay towards Solving a Problem in the Doctrine of Chances”, pubblicato nel 1763 nella rivista Philosophical Transactions, a cambiare per sempre il corso della teoria della probabilità.\nBellhouse nota che l’interesse di Bayes per la matematica era tipico del suo tempo: “Nel XVIII secolo, i ricchi si dedicavano alla scienza. È un po’ come i ricchi di oggi che si dedicano agli sport.” Ma forse Bellhouse si riferiva solo al suo tempo: oggi i ricchi sembrano interessarsi solo ai social media.\nIl contributo di Bayes non fu tanto matematico quanto filosofico. David Spiegelhalter, ex presidente della Royal Statistical Society, spiega che per Bayes “la probabilità è un’espressione della nostra mancanza di conoscenza sul mondo.” Questa visione introduce l’idea rivoluzionaria che la probabilità sia soggettiva, un’espressione della nostra conoscenza limitata e delle nostre supposizioni sulla verità, piuttosto che una proprietà oggettiva della realtà.\nPer illustrare questo concetto, Bayes utilizzò l’esempio di un tavolo nascosto alla vista su cui vengono lanciate delle palle. Una palla bianca viene lanciata in modo tale che la sua posizione finale sia completamente casuale. Quando la palla bianca si ferma, viene rimossa e si traccia una linea sul tavolo nel punto in cui si trovava. La posizione della linea non è nota. Successivamente, un certo numero di palle rosse viene lanciato sul tavolo. Viene comunicato solo quante palle si trovano a sinistra della linea e quante a destra. Il compito è stimare la posizione della linea. La soluzione proposta da Bayes utilizza non solo i dati osservati (il numero di palle rosse a sinistra e a destra della linea), ma anche le convinzioni iniziali (il “prior”).\nRichard Price (1723-1791), un altro ecclesiastico nonconformista, ebbe un ruolo cruciale nella diffusione del lavoro di Thomas Bayes. Molto più noto del suo amico, Price era ben inserito nei circoli intellettuali dell’epoca. Era in contatto con diversi Padri Fondatori della Rivoluzione Americana, tra cui Thomas Jefferson e Benjamin Franklin, così come John Adams, il secondo presidente degli Stati Uniti. Supportava attivamente la rivoluzione americana, pubblicando un influente opuscolo Observations on the Nature of Civil Liberty, the Principles of Government, and the Justice and Policy of the War with America nel 1776. Era amico di filosofi come David Hume e Adam Smith.\nPrice è importante in questa storia come colui che portò all’attenzione pubblica il lavoro di Bayes: mostrò il saggio al fisico John Canton nel 1761, dopo la morte di Bayes, e lo fece pubblicare nelle Philosophical Transactions della Royal Society due anni dopo. Parte del motivo per cui ci volle tanto tempo per pubblicarlo era che Price non si limitò a correggere refusi e virgole fuori posto. Price aveva una visione propria del lavoro: mentre Bayes scrisse la prima metà del saggio, la seconda metà, contenente tutte le possibili applicazioni pratiche del teorema, fu tutta opera di Price. Bayes non aveva interesse per le statistiche applicate: il suo lavoro, in questo e in tutti gli altri articoli, era “tutta teoria senza alcun accenno di applicazione.” Ma Price fu – come dice lo storico della statistica Stephen Stigler – “il primo bayesiano.”\nSebbene il lavoro di Bayes sia rimasto nell’ombra per decenni, con Pierre-Simon Laplace che giunse indipendentemente a conclusioni simili nel 1774 e le espanse nella sua “Théorie analytique des probabilités” del 1812, l’importanza del teorema di Bayes è oggi indiscutibile. Esso fornisce un meccanismo matematico per aggiornare le probabilità di un’ipotesi in base a nuove evidenze, riflettendo un approccio dinamico e iterativo alla conoscenza.\nNel panorama contemporaneo, il teorema di Bayes trova applicazioni in ogni campo della scienza e della tecnologia. È particolarmente rilevante nel campo dell’intelligenza artificiale, dove modelli linguistici avanzati come ChatGPT e Claude utilizzano principi bayesiani per fare previsioni e prendere decisioni.\nIn conclusione, il teorema di Bayes, nato dalle riflessioni di un ministro presbiteriano del XVIII secolo, ha trasformato il nostro modo di comprendere la probabilità e di aggiornare le nostre conoscenze. La sua rilevanza universale nella comprensione e previsione dei fenomeni è tale che, come afferma Brian Clegg nel suo libro “Everything is predictable: how bayesian statistics explain our world”, la statistica bayesiana è diventata uno strumento fondamentale per spiegare il nostro mondo (Chivers, 2024).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_bayes_theorem.html#la-regola-di-bayes",
    "href": "chapters/probability/07_bayes_theorem.html#la-regola-di-bayes",
    "title": "32  Il teorema di Bayes",
    "section": "\n32.3 La Regola di Bayes",
    "text": "32.3 La Regola di Bayes\nL’inferenza bayesiana si basa su una formula fondamentale nota come regola di Bayes. Sebbene sia un semplice risultato della teoria delle probabilità, la sua applicazione ha implicazioni profonde in molti campi, inclusi la scienza cognitiva e l’apprendimento automatico. Supponiamo di avere due variabili casuali, \\(A\\) e \\(B\\). Un principio della probabilità, chiamato regola della catena, ci consente di esprimere la probabilità congiunta di queste due variabili \\(P(A, B)\\) come il prodotto della probabilità condizionale di \\(A\\) dato \\(B\\) e della probabilità marginale di \\(B\\). In termini formali:\n\\[\nP(A, B) = P(A \\mid B) P(B).\n\\tag{32.1}\\]\nNon vi è nulla di speciale nel trattare \\(A\\) prima di \\(B\\); possiamo infatti scrivere anche:\n\\[\nP(A, B) = P(B \\mid A) P(A).\n\\tag{32.2}\\]\nDalle due equazioni precedenti possiamo derivare la regola di Bayes riorganizzando i termini:\n\\[\nP(B \\mid A) = \\frac{P(A \\mid B) P(B)}{P(A)}.\n\\tag{32.3}\\]\nQuesta espressione, nota come regola di Bayes, ci permette di calcolare la probabilità condizionale di \\(B\\) dato \\(A\\), usando la probabilità condizionale opposta \\(P(A \\mid B)\\), la probabilità a priori \\(P(B)\\) e la probabilità marginale \\(P(A)\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_bayes_theorem.html#applicazioni-della-regola-di-bayes",
    "href": "chapters/probability/07_bayes_theorem.html#applicazioni-della-regola-di-bayes",
    "title": "32  Il teorema di Bayes",
    "section": "\n32.4 Applicazioni della Regola di Bayes",
    "text": "32.4 Applicazioni della Regola di Bayes\nLa forza della regola di Bayes si manifesta pienamente quando viene applicata al contesto dell’inferenza. Supponiamo di avere un agente che cerca di inferire quale processo ha generato alcuni dati \\(D\\). Indichiamo con \\(H\\) un’ipotesi su tale processo. L’agente usa le probabilità per rappresentare il grado di credenza in \\(H\\) e nelle ipotesi alternative \\(H'\\). La probabilità a priori \\(P(H)\\) rappresenta la credenza che l’agente attribuisce a \\(H\\) prima di osservare i dati.\nQuando l’agente osserva i nuovi dati \\(D\\), aggiorna la credenza ottenendo la probabilità a posteriori \\(P(H \\mid D)\\). La regola di Bayes permette di calcolare questa probabilità come segue:\n\\[\nP(H \\mid D) = \\frac{P(D \\mid H) P(H)}{P(D)}.\n\\tag{32.4}\\]\nIn questa equazione:\n\n\n\\(P(D \\mid H)\\): la verosimiglianza, ovvero la probabilità di osservare i dati \\(D\\) assumendo che l’ipotesi \\(H\\) sia vera. Questa componente valuta quanto l’ipotesi predice i dati osservati.\n\n\\(P(H)\\): la probabilità a priori di \\(H\\).\n\n\\(P(D)\\): la probabilità marginale dei dati, calcolata sommando (o integrando) le probabilità congiunte per tutte le ipotesi \\(H'\\).\n\n\n\n32.4.1 La Marginalizzazione\nLa probabilità marginale di \\(D\\), necessaria per normalizzare la distribuzione a posteriori, si ottiene considerando tutte le ipotesi possibili \\(H'\\). Per ipotesi discrete, la somma è:\n\\[\nP(D) = \\sum_{H' \\in H} P(D \\mid H') P(H').\n\\]\nSostituendo questa espressione nella regola di Bayes otteniamo:\n\\[\nP(H \\mid D) = \\frac{P(D \\mid H) P(H)}{\\sum_{H' \\in H} P(D \\mid H') P(H')}.\n\\tag{32.5}\\]\nNel caso continuo, la somma è sostituita da un integrale:\n\\[\nP(H \\mid D) = \\frac{P(D \\mid H) P(H)}{\\int P(D \\mid H') P(H') \\, dH'}.\n\\tag{32.6}\\]\n\n32.4.2 Componenti Chiave della Formula di Bayes\nLa regola di Bayes si basa su tre componenti principali:\n\n\nProbabilità a Priori \\(P(H)\\): La credenza iniziale sull’ipotesi \\(H\\), basata su informazioni preesistenti.\n\nVerosimiglianza \\(P(D \\mid H)\\): La probabilità dei dati osservati \\(D\\), dato che \\(H\\) sia vera. Misura quanto \\(H\\) spiega \\(D\\).\n\nProbabilità a Posteriori \\(P(H \\mid D)\\): La credenza aggiornata in \\(H\\) dopo aver osservato \\(D\\).\n\nGrazie alla regola di Bayes, possiamo aggiornare costantemente le nostre credenze man mano che nuove informazioni diventano disponibili. Questo processo dinamico di aggiornamento ci permette di affinare le nostre convinzioni e le nostre previsioni, rendendo il modello bayesiano particolarmente utile nelle situazioni in cui le informazioni sono incomplete o incerte. Questo approccio non solo ci consente di prendere decisioni più informate, ma ci permette anche di sviluppare modelli più accurati della realtà basati sulle evidenze.\n\n32.4.3 Applicazioni dei modelli bayesiani\nCome discusso da Griffiths et al. (2024), negli ultimi anni, i modelli bayesiani hanno acquisito un’importanza crescente in vari campi delle scienze cognitive. Questi modelli sono stati applicati allo studio dell’apprendimento animale (Courville, Daw, & Touretzky, 2006), dell’apprendimento induttivo umano e della generalizzazione (Tenenbaum, Griffiths, & Kemp, 2006), della percezione visiva (Yuille & Kersten, 2006), del controllo motorio (Kording & Wolpert, 2006), della memoria semantica (Steyvers, Griffiths, & Dennis, 2006), dell’acquisizione e del processamento del linguaggio (Chater & Manning, 2006; Xu & Tenenbaum, in press), del ragionamento simbolico (Oaksford & Chater, 2001), dell’apprendimento causale (Steyvers, Tenenbaum, Wagenmakers, & Blum, 2003; Griffiths & Tenenbaum, 2005, 2007a), e della cognizione sociale (Baker, Tenenbaum, & Saxe, 2007), tra molti altri argomenti.\nDietro questi diversi programmi di ricerca emerge una domanda centrale: come fa la mente umana ad andare oltre i dati dell’esperienza? In altre parole, come riesce la mente a costruire modelli complessi e astratti del mondo, partendo solo da dati sparsi e rumorosi, osservati attraverso i nostri sensi? La risposta proposta dall’approccio bayesiano è che la mente umana utilizza un processo di inferenza probabilistica per aggiornare le proprie credenze sulla base delle nuove evidenze, creando così modelli del mondo sempre più accurati e raffinati.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_bayes_theorem.html#test-medici",
    "href": "chapters/probability/07_bayes_theorem.html#test-medici",
    "title": "32  Il teorema di Bayes",
    "section": "\n32.5 Test medici",
    "text": "32.5 Test medici\nIl modo più comune per spiegare il teorema di Bayes è attraverso i test medici.\n\nEsempio 32.1 Prendiamo come esempio il caso della mammografia e la diagnosi del cancro al seno che abbiamo già discusso in precedenza. Supponiamo di avere un test di mammografia con una sensibilità del 90% e una specificità del 90%. Questo significa che:\n\nIn presenza di cancro al seno, la probabilità che il test lo rilevi correttamente è del 90%.\nIn assenza di cancro al seno, la probabilità che il test confermi correttamente l’assenza della malattia è del 90%.\n\nIn altri termini, il test ha un tasso di falsi negativi del 10% e un tasso di falsi positivi anch’esso del 10%.\nDefiniamo due ipotesi:\n\n\n\\(M^+\\): presenza della malattia\n\n\\(M^-\\): assenza della malattia\n\nL’evidenza è rappresentata dal risultato positivo di un test di mammografia, che indichiamo con \\(T^+\\).\nApplicando il teorema di Bayes, possiamo calcolare la probabilità di avere il cancro al seno dato un risultato positivo al test, come segue:\n\\[\nP(M^+ \\mid T^+) = \\frac{P(T^+ \\mid M^+) \\cdot P(M^+)}{P(T^+ \\mid M^+) \\cdot P(M^+) + P(T^+ \\mid M^-) \\cdot P(M^-)},\n\\]\ndove:\n\n\\(P(M^+ \\mid T^+)\\) è la probabilità di avere il cancro (\\(M^+\\)) dato un risultato positivo al test (\\(T^+\\)).\n\\(P(T^+ \\mid M^+)\\) rappresenta la sensibilità del test, ovvero la probabilità che il test risulti positivo in presenza effettiva del cancro. In questo caso, è pari a 0.90.\n\\(P(M^+)\\) è la probabilità a priori che una persona abbia il cancro, ovvero la prevalenza della malattia nella popolazione.\n\n\\(P(T^+ \\mid M^-)\\) indica la probabilità di un falso positivo, cioè la probabilità che il test risulti positivo in assenza di cancro. Con una specificità del 90%, questa probabilità si calcola come:\n\\[\nP(T^+ \\mid M^-) = 1 - \\text{Specificità} = 1 - 0.90 = 0.10\n\\]\nQuesto significa che c’è una probabilità del 10% che il test diagnostichi erroneamente la presenza del cancro in una persona sana.\n\n\\(P(M^-)\\) è la probabilità a priori che una persona non sia affetta da cancro prima di effettuare il test.\n\nQuesta formulazione del teorema di Bayes ci permette di calcolare la probabilità effettiva di avere il cancro al seno, dato un risultato positivo al test di mammografia, tenendo conto sia della sensibilità e specificità del test, sia della prevalenza della malattia nella popolazione.\nInserendo nella formula i del problema, otteniamo:\n\\[\n\\begin{align}\nP(M^+ \\mid T^+) &= \\frac{0.9 \\cdot 0.01}{0.9 \\cdot 0.01 + 0.1 \\cdot 0.99} \\notag\\\\\n&= \\frac{9}{108} \\notag\\\\\n&\\approx 0.083.\\notag\n\\end{align}\n\\]\nI calcoli effettuati evidenziano come, in presenza di una mammografia positiva ottenuta con un test avente sensibilità e specificità pari al 90%, la probabilità di effettiva positività al tumore al seno si attesta intorno all’8.3%. Tale risultato conferma quanto precedentemente ottenuto nel ?sec-cond-prob, attraverso un metodo di calcolo alternativo.\n\n\n32.5.1 Il Valore Predittivo di un Test di Laboratorio\nPer semplicità, possiamo riscrivere il teorema di Bayes in due modi distinti per calcolare ciò che viene chiamato valore predittivo del test positivo e valore predittivo del test negativo.\nLa comprensione di tre elementi è fondamentale per questo calcolo: la prevalenza della malattia, la sensibilità e la specificità del test.\n\nPrevalenza: Si riferisce alla percentuale di individui in una popolazione affetti da una certa malattia in un determinato momento. Viene espressa come percentuale o frazione della popolazione. Per esempio, una prevalenza dello 0,5% indica che su mille persone, cinque sono affette dalla malattia.\n\nSensibilità: Indica la capacità del test di identificare correttamente la malattia negli individui malati. Viene calcolata come la frazione di veri positivi (individui malati correttamente identificati) sul totale degli individui malati. La formula della sensibilità (\\(Sens\\)) è la seguente:\n\\[ \\text{Sensibilità} = \\frac{TP}{TP + FN}, \\]\ndove \\(TP\\) rappresenta i veri positivi e \\(FN\\) i falsi negativi. Pertanto, la sensibilità misura la probabilità che il test risulti positivo se la malattia è effettivamente presente.\n\n\nSpecificità: Misura la capacità del test di riconoscere gli individui sani, producendo un risultato negativo per chi non è affetto dalla malattia. Si calcola come la frazione di veri negativi (individui sani correttamente identificati) sul totale degli individui sani. La specificità (\\(Spec\\)) si definisce come:\n\\[ \\text{Specificità} = \\frac{TN}{TN + FP}, \\]\ndove \\(TN\\) sono i veri negativi e \\(FP\\) i falsi positivi. Così, la specificità rappresenta la probabilità che il test risulti negativo in assenza della malattia.\n\n\nQuesta tabella riassume la terminologia:\n\n\n\n\n\n\n\n\n\n\\(T^+\\)\n\\(T^-\\)\nTotale\n\n\n\n\\(M^+\\)\n\n\\(P(T^+ \\cap M^+)\\)  (Sensibilità)\n\n\\(P(T^- \\cap M^+)\\)  (1 - Sensibilità)\n\\(P(M^+)\\)\n\n\n\\(M^-\\)\n\n\\(P(T^+ \\cap M^-)\\)  (1 - Specificità)\n\n\\(P(T^- \\cap M^-)\\)  (Specificità)\n\\(P(M^-)\\)\n\n\nTotale\n\\(P(T^+)\\)\n\\(P(T^-)\\)\n1\n\n\n\ndove \\(T^+\\) e \\(T^-\\) indicano rispettivamente un risultato positivo o negativo del test, mentre \\(M^+\\) e \\(M^-\\) la presenza o assenza effettiva della malattia. In questa tabella, i totali marginali rappresentano:\n\n\nTotale per \\(M^+\\) e \\(M^-\\) (ultima colonna): La probabilità totale di avere la malattia (\\(P(M^+)\\)) e la probabilità totale di non avere la malattia (\\(P(M^-)\\)), rispettivamente. Questi valori sono calcolati sommando le probabilità all’interno di ciascuna riga.\n\nTotale per \\(T^+\\) e \\(T^-\\) (ultima riga): La probabilità totale di un risultato positivo al test (\\(P(T^+)\\)) e la probabilità totale di un risultato negativo al test (\\(P(T^-)\\)), rispettivamente. Questi valori sono calcolati sommando le probabilità all’interno di ciascuna colonna.\n\nTotale generale (angolo in basso a destra): La somma di tutte le probabilità, che per definizione è 1, rappresentando l’intera popolazione o il set di casi considerati.\n\nMediante il teorema di Bayes, possiamo usare queste informazioni per stimare la probabilità post-test di avere o non avere la malattia basandoci sul risultato del test.\nIl valore predittivo positivo (VPP) del test, cioè la probabilità post-test che un individuo sia malato dato un risultato positivo del test, è calcolato come:\n\\[\nP(M^+ \\mid T^+) = \\frac{P(T^+ \\mid M^+) \\cdot P(M^+)}{P(T^+ \\mid M^+) \\cdot P(M^+) + P(T^+ \\mid M^-) \\cdot P(M^-)}.\n\\]\novvero,\n\\[ VPP = \\frac{(\\text{Sensibilità} \\times \\text{Prevalenza})}{(\\text{Sensibilità} \\times \\text{Prevalenza}) + (1 - \\text{Specificità}) \\times (1 - \\text{Prevalenza})} \\]\nAnalogamente, il valore predittivo negativo (VPN), che è la probabilità che un individuo non sia malato dato un risultato negativo del test, si calcola come:\n\\[\nP(M^- \\mid T^-) = \\frac{P(T^- \\mid M^-) \\cdot (1 - P(M^+))}{P(T^- \\mid M^-) \\cdot (1 - P(M^+)) + P(T^- \\mid M^+) \\cdot P(M^+)}.\n\\]\novvero,\n\\[ NPV = \\frac{\\text{Specificità} \\cdot (1 - \\text{Prevalenza})}{\\text{Specificità} \\cdot (1 - \\text{Prevalenza}) + (1 - \\text{Sensibilità}) \\cdot \\text{Prevalenza}}. \\]\n\nEsempio 32.2 Implementiamo le formule del valore predittivo positivo e del valore predittivo negativo del test in R e usiamo gli stessi dati dell’esercizio precedente.\n\npositive_predictive_value_of_diagnostic_test &lt;- function(sens, spec, prev) {\n  (sens * prev) / (sens * prev + (1 - spec) * (1 - prev))\n}\n\nnegative_predictive_value_of_diagnostic_test &lt;- function(sens, spec, prev) {\n  (spec * (1 - prev)) / (spec * (1 - prev) + (1 - sens) * prev)\n}\n\nInseriamo i dati del problema.\n\nsens = 0.9  # sensibilità\nspec = 0.9  # specificità\nprev = 0.01  # prevalenza\n\nIl valore predittivo del test positivo è:\n\nres_pos &lt;- positive_predictive_value_of_diagnostic_test(sens, spec, prev)\ncat(sprintf(\"P(M+ | T+) = %.3f\\n\", res_pos))\n#&gt; P(M+ | T+) = 0.083\n\nIl valore predittivo del test negativo è:\n\nres_neg &lt;- negative_predictive_value_of_diagnostic_test(sens, spec, prev)\ncat(sprintf(\"P(M- | T-) = %.3f\\n\", res_neg))\n#&gt; P(M- | T-) = 0.999\n\n\n\nEsempio 32.3 La simulazione seguente ha lo scopo di aiutare a visualizzare il teorema di Bayes, utilizzando come esempio gli stessi dati della mammografia che abbiamo analizzato in precedenza.\n\n# Parametri\nsensitivity &lt;- 0.90  # Sensibilità del test (P(T+ | M+))\nspecificity &lt;- 0.90  # Specificità del test (P(T- | M-))\nprev_cancer &lt;- 0.01  # Prevalenza (P(M+))\n\n# Simulazione per una popolazione di 100.000 persone\nN_mammography &lt;- 100000\n\n# Generazione del campione casuale\nset.seed(123)\noutcome_mammography &lt;- sample(\n  c(\"Cancer\", \"Healthy\"), \n  N_mammography, \n  replace = TRUE, \n  prob = c(prev_cancer, 1 - prev_cancer)\n)\n\n# Conteggio delle persone con e senza cancro\nN_C &lt;- sum(outcome_mammography == \"Cancer\")\nN_H &lt;- sum(outcome_mammography == \"Healthy\")\n\n# Simulazione dei risultati del test\ntest_mammography &lt;- character(N_mammography)\ntest_mammography[outcome_mammography == \"Cancer\"] &lt;- sample(\n  c(\"+\", \"-\"), \n  N_C, \n  replace = TRUE, \n  prob = c(sensitivity, 1 - sensitivity)\n)\ntest_mammography[outcome_mammography == \"Healthy\"] &lt;- sample(\n  c(\"-\", \"+\"), \n  N_H, \n  replace = TRUE, \n  prob = c(specificity, 1 - specificity)\n)\n\n# Creazione di un data frame per memorizzare i risultati\ndf_mammography &lt;- tibble(\n  outcome = outcome_mammography,\n  test = test_mammography\n)\n\n# Creazione di una tabella di contingenza\ncontingency_table_mammography &lt;- df_mammography %&gt;%\n  count(outcome, test) %&gt;%\n  pivot_wider(names_from = test, values_from = n, values_fill = 0)\n\ncontingency_table_mammography\n#&gt; # A tibble: 2 × 3\n#&gt;   outcome   `+`   `-`\n#&gt;   &lt;chr&gt;   &lt;int&gt; &lt;int&gt;\n#&gt; 1 Cancer    911   114\n#&gt; 2 Healthy  9897 89078\n\n\n# Calcolo delle probabilità basate sulla tabella di contingenza\n\n# Veri positivi (cancro e risultato positivo al test)\ntrue_positives &lt;- contingency_table_mammography %&gt;%\n  filter(outcome == \"Cancer\") %&gt;%\n  pull(`+`)\n\n# Falsi positivi (sani e risultato positivo al test)\nfalse_positives &lt;- contingency_table_mammography %&gt;%\n  filter(outcome == \"Healthy\") %&gt;%\n  pull(`+`)\n\n# Frequenza totale dei risultati positivi\ntotal_positives &lt;- true_positives + false_positives\n\n# Applicazione del teorema di Bayes sui dati simulati\nP_M_given_T &lt;- true_positives / total_positives\nP_M_given_T\n#&gt; [1] 0.0843\n\nUtilizzando i dati della simulazione, la probabilità che una persona abbia il cancro al seno dato un risultato positivo al test è molto vicina al valore teorico calcolato in precedenza (circa 8.3%). Se eseguissimo la simulazione nuovamente, il valore ottenuto potrebbe variare leggermente a causa della casualità intrinseca nel campionamento. Tuttavia, ripetendo la simulazione molte volte, i risultati tenderanno a convergere verso il valore teorico, grazie alla legge dei grandi numeri. Questo conferma che il modello teorico è coerente con i risultati simulati.\n\n\nEsempio 32.4 Poniamoci il problema di capire quanto sia affidabile un test per l’HIV. Per fare questo, utilizzeremo le seguenti informazioni (Petersen, 2024):\n\n\nTasso di base dell’HIV (P(HIV)): 0.3% (0.003). Questa è la probabilità che una persona nella popolazione generale abbia l’HIV.\n\nSensibilità del test (P(Test+ HIV)): 95% (0.95). Questa è la probabilità che il test risulti positivo se la persona ha effettivamente l’HIV.\n\nSpecificità del test (P(Test- ¬HIV)): 99.28% (0.9928). Questa è la probabilità che il test risulti negativo se la persona non ha l’HIV.\n\nCalcolo della probabilità di HIV dato un test positivo.\nPer calcolare la probabilità di avere l’HIV dato un test positivo (P(HIV Test+)), utilizziamo il teorema di Bayes:\n\\[\nP(HIV \\mid Test+) = \\frac{P(Test+ \\mid HIV) \\times P(HIV)}{P(Test+)}.\n\\]\nAbbiamo bisogno di calcolare il denominatore, ovvero la probabilità complessiva di ottenere un test positivo (P(Test+)). Questo valore include sia i veri positivi che i falsi positivi:\n\\[\nP(Test+) = P(Test+ \\mid HIV) \\times P(HIV) + P(Test+ \\mid \\neg HIV) \\times P(\\neg HIV),\n\\]\ndove:\n\n\n\\(P(Test+ \\mid \\neg HIV) = 1 - P(Test- \\mid \\neg HIV) = 1 - 0.9928 = 0.0072\\) (tasso di falsi positivi),\n\n\\(P(\\neg HIV) = 1 - P(HIV) = 1 - 0.003 = 0.997\\).\n\nCalcoliamo \\(P(Test+)\\):\n\\[\nP(Test+) = (0.95 \\times 0.003) + (0.0072 \\times 0.997) \\approx 0.010027.\n\\]\nOra possiamo calcolare \\(P(HIV \\mid Test+)\\):\n\\[\nP(HIV \\mid Test+) = \\frac{0.95 \\times 0.003}{0.010027} \\approx 0.2844 \\text{ o 28.44\\%}.\n\\]\nQuindi, se il test risulta positivo, la probabilità di avere l’HIV è circa il 28.44%.\nCalcolo della probabilità di un secondo test positivo.\nDopo un primo test positivo, la probabilità di avere l’HIV è aumentata al 28.44%. Ora calcoleremo la probabilità che un secondo test risulti positivo e la conseguente probabilità di avere l’HIV dopo due test positivi consecutivi.\nPer calcolare \\(P(\\text{Secondo Test+})\\), consideriamo due scenari:\n\nLa persona ha effettivamente l’HIV:\n\nProbabilità: \\(P(HIV \\mid Test+) = 0.2844\\).\nProbabilità di un test positivo: \\(P(\\text{Test+} \\mid HIV) = 0.95\\) (sensibilità del test).\n\n\nLa persona non ha l’HIV:\n\nProbabilità: \\(P(\\neg HIV \\mid Test+) = 1 - P(HIV \\mid Test+) = 0.7156\\).\nProbabilità di un test positivo: \\(P(\\text{Test+} \\mid \\neg HIV) = 0.0072\\) (tasso di falsi positivi).\n\n\n\nUtilizziamo la formula della probabilità totale:\n\\[\n\\begin{aligned}\nP(\\text{Secondo Test+}) &= P(\\text{Test+} \\mid HIV) \\times P(HIV \\mid Test+) + \\\\\n&\\quad P(\\text{Test+} \\mid \\neg HIV) \\times P(\\neg HIV \\mid Test+).\n\\end{aligned}\n\\]\nSostituendo i valori:\n\\[\nP(\\text{Secondo Test+}) = (0.95 \\times 0.2844) + (0.0072 \\times 0.7156) \\approx 0.2753.\n\\]\nApplichiamo nuovamente il teorema di Bayes per calcolare la probabilità di avere l’HIV dopo un secondo test positivo:\n\\[\nP(HIV \\mid \\text{Secondo Test+}) = \\frac{P(\\text{Secondo Test+} \\mid HIV) \\times P(HIV \\mid Test+)}{P(\\text{Secondo Test+})}.\n\\]\nSostituendo i valori:\n\\[\nP(HIV \\mid \\text{Secondo Test+}) = \\frac{0.95 \\times 0.2844}{0.2753} \\approx 0.981.\n\\]\nDopo un secondo test positivo, la probabilità di avere l’HIV aumenta significativamente, passando dal 28.44% al 98.1%. Questo aumento drastico dimostra l’importanza di:\n\nConsiderare il tasso di base (prevalenza) nella popolazione.\nAggiornare progressivamente le probabilità con nuove evidenze.\nInterpretare i risultati di test diagnostici multipli in modo bayesiano.\n\nL’analisi evidenzia come l’accumulo di evidenze attraverso test ripetuti, in linea con i principi del teorema di Bayes, possa portare a una stima molto più accurata della probabilità di avere una condizione medica, riducendo significativamente l’incertezza iniziale.\n\n\nEsempio 32.5 Consideriamo ora un altro esempio relativo ai test medici e analizziamo i risultati del test antigenico rapido per il virus SARS-CoV-2 alla luce del teorema di Bayes. Questo test può essere eseguito mediante tampone nasale, tampone naso-orofaringeo o campione di saliva. L’Istituto Superiore di Sanità, nel documento pubblicato il 5 novembre 2020, sottolinea che, fino a quel momento, i dati disponibili sui vari test erano quelli forniti dai produttori: la sensibilità varia tra il 70% e l’86%, mentre la specificità si attesta tra il 95% e il 97%.\nPrendiamo un esempio specifico: nella settimana tra il 17 e il 23 marzo 2023, in Italia, il numero di individui positivi al virus è stato stimato essere di 138.599 (fonte: Il Sole 24 Ore). Questo dato corrisponde a una prevalenza di circa lo 0,2% su una popolazione totale di circa 59 milioni di persone.\n\n prev = 138599 / 59000000\n prev\n#&gt; [1] 0.00235\n\nL’obiettivo è determinare la probabilità di essere effettivamente affetti da Covid-19, dato un risultato positivo al test antigenico rapido, ossia \\(P(M^+ \\mid T^+)\\). Per raggiungere questo scopo, useremo la formula relativa al valore predittivo positivo del test.\n\n# Calcolo della sensibilità e specificità medie\nsens &lt;- (0.7 + 0.86) / 2  # sensibilità\nspec &lt;- (0.95 + 0.97) / 2 # specificità\n\n# Calcolo del valore predittivo positivo\nres_pos &lt;- positive_predictive_value_of_diagnostic_test(sens, spec, prev)\ncat(sprintf(\"P(M+ | T+) = %.3f\\n\", res_pos))\n#&gt; P(M+ | T+) = 0.044\n\nPertanto, se il risultato del tampone è positivo, la probabilità di essere effettivamente affetti da Covid-19 è solo del 4.4%.\nSe la prevalenza fosse 100 volte superiore (cioè, pari al 23.5%), la probabilità di avere il Covid-19, dato un risultato positivo del tampone, aumenterebbe notevolmente e sarebbe pari a circa l’86%.\n\n# Calcolo della prevalenza aumentata di 100 volte\nprev &lt;- 138599 / 59000000 * 100\n\n# Calcolo del valore predittivo positivo\nres_pos &lt;- positive_predictive_value_of_diagnostic_test(sens, spec, prev)\ncat(sprintf(\"P(M+ | T+) = %.3f\\n\", res_pos))\n#&gt; P(M+ | T+) = 0.857\n\nSe il risultato del test fosse negativo, considerando la prevalenza stimata del Covid-19 nella settimana dal 17 al 23 marzo 2023, la probabilità di non essere infetto sarebbe del 99.9%.\n\n# Calcolo della sensibilità, specificità e prevalenza\nsens &lt;- (0.7 + 0.86) / 2  # sensibilità\nspec &lt;- (0.95 + 0.97) / 2  # specificità\nprev &lt;- 138599 / 59000000  # prevalenza\n\n# Calcolo del valore predittivo negativo\nres_neg &lt;- negative_predictive_value_of_diagnostic_test(sens, spec, prev)\ncat(sprintf(\"P(M- | T-) = %.3f\\n\", res_neg))\n#&gt; P(M- | T-) = 0.999\n\nTuttavia, un’esito del genere non dovrebbe sorprenderci, considerando che la prevalenza della malattia è molto bassa; in altre parole, il risultato negativo conferma una situazione già presunta prima di sottoporsi al test. Il vero ostacolo, specialmente nel caso di malattie rare come il Covid-19 in quel periodo specifico, non risiede tanto nell’asserire l’assenza della malattia quanto piuttosto nel confermarne la presenza.\n\n\nEsempio 32.6 Consideriamo le persone in attesa di un figlio. Il teorema di Bayes gioca un ruolo cruciale nell’interpretazione dei test prenatali non invasivi (NIPT), un esame del sangue materno usato per rilevare anomalie cromosomiche fetali. Sebbene il NIPT sia spesso pubblicizzato con un’accuratezza del 99%, la sua affidabilità varia significativamente a seconda della condizione testata e della popolazione esaminata.\nParametri chiave del NIPT:\n\n\nSensibilità:\n\nSindrome di Down: 99%\nSindrome di Edwards: 97%\nSindrome di Patau: 91%\n\n\nSpecificità: circa 99.9% per tutte le condizioni citate\n\nPrevalenza nelle nascite:\n\nSindrome di Down: 1 su 700 (0.14%)\nSindrome di Edwards: 1 su 5,000 (0.02%)\nSindrome di Patau: 1 su 10,000 (0.01%)\n\n\n\nNonostante l’alta sensibilità e specificità, il VPP può essere sorprendentemente basso, soprattutto nella popolazione generale. Questo implica che molti risultati positivi potrebbero essere falsi positivi, in particolare per le condizioni più rare.\nPer calcolare il VPP, utilizziamo il teorema di Bayes:\n\\[ VPP = \\frac{(\\text{Sensibilità} \\times \\text{Prevalenza})}{(\\text{Sensibilità} \\times \\text{Prevalenza}) + (1 - \\text{Specificità}) \\times (1 - \\text{Prevalenza})} \\]\nApplicando questa formula alla popolazione generale:\n\nSindrome di Down: \\[ VPP = \\frac{(0.99 \\times 0.0014)}{(0.99 \\times 0.0014) + (1 - 0.999) \\times (1 - 0.0014)} \\approx 58\\% \\]\nSindrome di Edwards: \\[ VPP = \\frac{(0.97 \\times 0.0002)}{(0.97 \\times 0.0002) + (1 - 0.999) \\times (1 - 0.0002)} \\approx 16.2\\% \\]\nSindrome di Patau: \\[ VPP = \\frac{(0.91 \\times 0.0001)}{(0.91 \\times 0.0001) + (1 - 0.999) \\times (1 - 0.0001)} \\approx 8.3\\% \\]\n\nQuesti calcoli rivelano VPP molto bassi, specialmente per condizioni molto rare come la sindrome di Patau. Anche in questo caso, dunque, il teorema di Bayes ci mostra che la probabilità che un risultato positivo sia effettivamente corretto dipende non solo dall’accuratezza del test, ma anche dalla prevalenza della condizione nella popolazione testata. Per questo motivo, il NIPT risulta più affidabile nelle categorie ad alto rischio.\nIn conclusione, mentre il NIPT è uno strumento prezioso per lo screening prenatale, è fondamentale interpretare i risultati con cautela, considerando il contesto specifico di ogni paziente e la prevalenza della condizione nella popolazione di riferimento.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_bayes_theorem.html#la-fallacia-del-procuratore",
    "href": "chapters/probability/07_bayes_theorem.html#la-fallacia-del-procuratore",
    "title": "32  Il teorema di Bayes",
    "section": "\n32.6 La Fallacia del Procuratore",
    "text": "32.6 La Fallacia del Procuratore\nIl teorema di Bayes non è rilevante solo in ambito medico; è altrettanto cruciale nel contesto legale, dove un errore logico noto come fallacia del procuratore può avere conseguenze significative. Questa fallacia si verifica quando si confonde la probabilità di un risultato dato un evento con la probabilità dell’evento dato il risultato. In ambito giudiziario, ciò accade spesso quando si scambia la probabilità di ottenere una corrispondenza del DNA se una persona è innocente con la probabilità che una persona sia innocente dato che il test del DNA ha prodotto una corrispondenza.\n\nEsempio 32.7 Supponiamo che un test del DNA venga utilizzato per identificare un sospetto in una popolazione di 65 milioni di persone. Consideriamo i seguenti parametri:\n\n\nSensibilità: \\(P(T^+ \\mid C) = 99\\%\\), ovvero la probabilità che il test identifichi correttamente il colpevole.\n\nSpecificità: \\(P(T^- \\mid I) = 99.99997\\%\\), ovvero la probabilità che il test identifichi correttamente un innocente.\n\nPrevalenza: \\(P(C) = \\frac{1}{65.000.000}\\), ovvero la probabilità a priori che una persona qualsiasi sia il colpevole.\n\nUn campione di DNA è stato trovato sulla scena del crimine e confrontato con quello di una persona nel database. Determiniamo la probabilità che questa persona sia effettivamente il colpevole, dato che il test è positivo (\\(T^+\\)).\nPasso 1: Calcolo della Probabilità del Test Positivo \\(P(T^+)\\).\nLa probabilità di ottenere un test positivo (\\(T^+\\)) è data dalla somma delle probabilità di un risultato positivo per un colpevole e per un innocente:\n\\[\nP(T^+) = P(T^+ \\mid C) \\cdot P(C) + P(T^+ \\mid I) \\cdot P(I),\n\\]\ndove \\(P(I) = 1 - P(C)\\) è la probabilità che una persona sia innocente e \\(P(T^+ \\mid I) = 1 - \\text{Specificità}\\).\nSostituiamo i valori noti:\n\\[\nP(T^+) = 0.99 \\cdot \\frac{1}{65.000.000} + (1 - 0.9999997) \\cdot \\frac{64.999.999}{65.000.000}.\n\\]\nEseguiamo i calcoli:\n\\[\nP(T^+) \\approx 0.99 \\cdot 1.5385 \\times 10^{-8} + 0.0000003 \\cdot 0.9999999,\n\\]\n\\[\nP(T^+) \\approx 1.5231 \\times 10^{-8} + 2.9999997 \\times 10^{-7},\n\\]\n\\[\nP(T^+) \\approx 3.1523 \\times 10^{-7}.\n\\]\nPasso 2: Probabilità Condizionale che il Sospetto sia Colpevole Dato un Test Positivo.\nUtilizzando il teorema di Bayes, la probabilità a posteriori che il sospetto sia colpevole, dato un test positivo, è:\n\\[\nP(C \\mid T^+) = \\frac{P(T^+ \\mid C) \\cdot P(C)}{P(T^+)}.\n\\]\nSostituiamo i valori calcolati:\n\\[\nP(C \\mid T^+) = \\frac{0.99 \\cdot \\frac{1}{65.000.000}}{3.1523 \\times 10^{-7}},\n\\]\n\\[\nP(C \\mid T^+) = \\frac{0.99 \\cdot 1.5385 \\times 10^{-8}}{3.1523 \\times 10^{-7}},\n\\]\n\\[\nP(C \\mid T^+) \\approx 0.0483.\n\\]\nLa probabilità che il sospetto sia effettivamente il colpevole, dato che il test del DNA è positivo, è quindi circa 4.83%, nonostante la specificità estremamente elevata del test.\nQuesto risultato dimostra quanto sia importante considerare la bassa prevalenza del colpevole nella popolazione. Affermare, ad esempio, che “c’è solo una probabilità su 3 milioni che il sospetto sia innocente” confonde la specificità del test (\\(P(T^- \\mid I)\\)) con la probabilità condizionale di colpevolezza (\\(P(C \\mid T^+)\\)).\nIn realtà, la probabilità che il sospetto sia colpevole dato un test positivo è molto più bassa, a causa della prevalenza estremamente ridotta. Questo errore logico può portare a gravi ingiustizie, poiché non si considera che i falsi positivi diventano statisticamente più rilevanti quando il numero di innocenti testati è molto alto.\nPer chiarire, confondere \\(P(T^+ \\mid I)\\) con \\(P(I \\mid T^+)\\) è analogo a confondere “Quanto è probabile che il DNA di una persona corrisponda al campione, se è innocente?” con “Quanto è probabile che una persona sia innocente, dato che il suo DNA corrisponde al campione?”.\nIn conclusione, la fallacia del procuratore mette in evidenza l’importanza di interpretare correttamente i risultati dei test probabilistici in contesti legali. L’uso del teorema di Bayes è essenziale per evitare errori logici e per garantire che le decisioni siano basate su una comprensione accurata delle probabilità condizionali.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_bayes_theorem.html#probabilità-inversa",
    "href": "chapters/probability/07_bayes_theorem.html#probabilità-inversa",
    "title": "32  Il teorema di Bayes",
    "section": "\n32.7 Probabilità Inversa",
    "text": "32.7 Probabilità Inversa\nGli esempi precedenti evidenziano la differenza tra due domande fondamentali. La prima è: “Qual è la probabilità di osservare un determinato risultato, supponendo che una certa ipotesi sia vera?” La seconda, invece, è: “Qual è la probabilità che un’ipotesi sia vera, dato il risultato osservato?”\nUn esempio che risponde alla prima domanda potrebbe essere questo: supponiamo che la probabilità di ottenere testa nel lancio di una moneta sia 0.5 (ipotesi). Qual è la probabilità di ottenere 0 teste in cinque lanci?\nPer la seconda domanda, un esempio potrebbe essere: supponiamo di aver ottenuto 0 teste in 5 lanci di una moneta (evidenza). Qual è la probabilità che la moneta sia effettivamente bilanciata, alla luce di questa osservazione?\nPer molto tempo, lo studio della probabilità si è concentrato principalmente sulla prima domanda. Tuttavia, nel XVIII secolo, il reverendo Thomas Bayes iniziò a riflettere sulla seconda domanda, dando origine a quello che oggi chiamiamo probabilità inversa.\nQuesto approccio ha generato numerose controversie nella storia della statistica, in gran parte perché influenza molti ambiti. Ad esempio, possiamo chiederci: quanto è probabile che un’ipotesi scientifica sia vera, dato il risultato di un esperimento? Per stimare questa probabilità — un compito che molti scienziati ritengono essenziale per la statistica moderna — è necessario fare uso del teorema di Bayes e delle probabilità a priori.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_bayes_theorem.html#riflessioni-conclusive",
    "href": "chapters/probability/07_bayes_theorem.html#riflessioni-conclusive",
    "title": "32  Il teorema di Bayes",
    "section": "\n32.8 Riflessioni Conclusive",
    "text": "32.8 Riflessioni Conclusive\nIn questo capitolo abbiamo esplorato vari esempi, principalmente nel campo medico e forense, per illustrare come il teorema di Bayes permetta di combinare le informazioni derivate dalle osservazioni con le conoscenze precedenti (priori), aggiornando così il nostro grado di convinzione rispetto a un’ipotesi. Il teorema di Bayes fornisce un meccanismo razionale, noto come “aggiornamento bayesiano”, che ci consente di ricalibrare le nostre convinzioni iniziali alla luce di nuove evidenze.\nUna lezione fondamentale che il teorema di Bayes ci insegna, sia nella ricerca scientifica che nella vita quotidiana, è che spesso non ci interessa tanto conoscere la probabilità che qualcosa accada assumendo vera un’ipotesi, quanto piuttosto la probabilità che un’ipotesi sia vera, dato che abbiamo osservato una certa evidenza. In altre parole, la forza del teorema di Bayes sta nella sua capacità di affrontare direttamente il problema inverso, cioè come dedurre la verità di un’ipotesi a partire dalle osservazioni.\nIl framework bayesiano per l’inferenza probabilistica offre un approccio generale per comprendere come i problemi di induzione possano essere risolti in linea di principio e, forse, anche come possano essere affrontati dalla mente umana.\nIn questo capitolo ci siamo concentrati sull’applicazione del teorema di Bayes utilizzando probabilità puntuali. Tuttavia, il teorema esprime pienamente il suo potenziale quando sia l’evidenza che i gradi di certezza a priori delle ipotesi sono rappresentati attraverso distribuzioni di probabilità continue. Questo sarà l’argomento centrale nella prossima sezione della dispensa, dove approfondiremo il flusso di lavoro bayesiano e l’uso di distribuzioni continue nell’aggiornamento bayesiano.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_bayes_theorem.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/07_bayes_theorem.html#informazioni-sullambiente-di-sviluppo",
    "title": "32  Il teorema di Bayes",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] see_0.9.0        gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1\n#&gt;  [5] psych_2.4.12     scales_1.3.0     markdown_1.13    knitr_1.49      \n#&gt;  [9] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [13] purrr_1.0.2      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [17] ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] utf8_1.2.4        generics_0.1.3    stringi_1.8.4     lattice_0.22-6   \n#&gt;  [5] hms_1.1.3         digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1   \n#&gt;  [9] grid_4.4.2        timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4  \n#&gt; [13] jsonlite_1.8.9    mnormt_2.1.1      cli_3.6.3         rlang_1.1.4      \n#&gt; [17] munsell_0.5.1     withr_3.0.2       yaml_2.3.10       tools_4.4.2      \n#&gt; [21] parallel_4.4.2    tzdb_0.4.0        colorspace_2.1-1  pacman_0.5.1     \n#&gt; [25] vctrs_0.6.5       R6_2.5.1          lifecycle_1.0.4   htmlwidgets_1.6.4\n#&gt; [29] pkgconfig_2.0.3   pillar_1.10.0     gtable_0.3.6      glue_1.8.0       \n#&gt; [33] xfun_0.49         tidyselect_1.2.1  farver_2.1.2      htmltools_0.5.8.1\n#&gt; [37] nlme_3.1-166      rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_bayes_theorem.html#bibliografia",
    "href": "chapters/probability/07_bayes_theorem.html#bibliografia",
    "title": "32  Il teorema di Bayes",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nChivers, T. (2024). Everything is Predictable: How Bayesian Statistics Explain Our World. Simon; Schuster.\n\n\nGriffiths, T. L., Chater, N., & Tenenbaum, J. B. (2024). Bayesian models of cognition: reverse engineering the mind. MIT Press.\n\n\nPetersen, I. T. (2024). Principles of psychological assessment: With applied examples in R. CRC Press.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html",
    "href": "chapters/probability/08_sampling_distr.html",
    "title": "33  Stime, stimatori e parametri",
    "section": "",
    "text": "33.1 Introduzione\nIn questo capitolo, approfondiremo il concetto di distribuzione campionaria che costituisce uno dei pilastri dell’inferenza statistica frequentista. La distribuzione campionaria ci permette di comprendere come le stime dei parametri della popolazione, come la media o la varianza, cambiano da campione a campione. In particolare, la distribuzione campionaria ci consente di stabilire delle proprietà probabilistiche delle stime campionarie, come ad esempio la loro media e la loro varianza. Queste proprietà verranno utilizzate per costruire gli strumenti fondamentali dell’inferenza frequentista: gli intervalli di fiducia e i test di ipotesi.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#popolazione-e-campioni",
    "href": "chapters/probability/08_sampling_distr.html#popolazione-e-campioni",
    "title": "33  Stime, stimatori e parametri",
    "section": "\n33.2 Popolazione e campioni",
    "text": "33.2 Popolazione e campioni\nNell’analisi dei dati, l’obiettivo spesso è comprendere una quantità specifica a livello di popolazione, ma in genere abbiamo accesso solo a un campione di osservazioni. La quantità sconosciuta che vogliamo determinare viene chiamata parametro. Quando usiamo i dati del campione per calcolare una misura di questo parametro, la misura ottenuta è chiamata stima, e la formula che utilizziamo per ottenerla è conosciuta come stimatore. In termini formali, uno stimatore è una funzione dei dati osservati, utilizzata per fornire un’approssimazione del parametro di interesse.\nIn pratica, quando analizziamo un campione di dati, il nostro obiettivo è inferire determinate proprietà della popolazione intera dalla quale il campione è stato tratto. Il parametro è l’indicatore numerico di queste proprietà, ma poiché spesso non possiamo calcolarlo direttamente sulla popolazione, ricorriamo alle osservazioni del campione per stimarlo. La stima, quindi, rappresenta il valore approssimato del parametro ottenuto dal campione, mentre lo stimatore è la regola o la formula matematica che usiamo per arrivare a questa approssimazione.\nÈ importante riconoscere che le stime non corrispondono mai esattamente ai parametri che vogliamo comprendere. In altre parole, le stime sono solo approssimazioni del parametro a causa della natura aleatoria del campionamento.\n\n33.2.1 La relazione tra stime e parametri\nIn questo capitolo, ci concentreremo sulla relazione tra le stime ottenute dai campioni e i parametri della popolazione, esplorando in particolare la connessione tra la media di un campione e la media della popolazione, denotata con \\(\\mu\\). Il nostro obiettivo è capire e caratterizzare l’incertezza che deriva dalla natura aleatoria delle stime, e per farlo, adotteremo l’approccio frequentista, facendo uso dello strumento statistico chiamato distribuzione campionaria.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#la-distribuzione-campionaria",
    "href": "chapters/probability/08_sampling_distr.html#la-distribuzione-campionaria",
    "title": "33  Stime, stimatori e parametri",
    "section": "\n33.3 La Distribuzione Campionaria",
    "text": "33.3 La Distribuzione Campionaria\nPer illustrare il concetto di distribuzione campionaria, possiamo iniziare considerando un caso semplice e specifico: una popolazione finita di dimensioni ridotte. Sebbene stiamo esaminando un caso particolare, è fondamentale notare che le proprietà e i principi che analizzeremo in questo contesto sono perfettamente applicabili a popolazioni di qualsiasi dimensione.\nLa distribuzione campionaria ci dà una visione della variazione che potremmo aspettarci nelle stime derivate da diversi campioni estratti dalla stessa popolazione. Ogni volta che preleviamo un campione, otteniamo una stima diversa per il parametro di interesse (come la media). La distribuzione campionaria ci mostra come queste stime sono distribuite e ci aiuta a comprendere quanto siano affidabili.\nIn termini pratici, se vogliamo calcolare la media della popolazione, non possiamo farlo direttamente (a meno di non avere accesso all’intera popolazione). Invece, possiamo estrarre un campione casuale e calcolare la media del campione come stima di \\(\\mu\\). Tuttavia, un altro campione fornirà una stima leggermente diversa. La distribuzione campionaria ci aiuta a capire quanto queste stime varino da campione a campione e ci fornisce un quadro completo dell’incertezza legata al processo di stima.\nNella simulazione seguente, ipotizziamo la seguente popolazione:\n\nx &lt;- c(2, 4.5, 5, 5.5)\nx\n#&gt; [1] 2.0 4.5 5.0 5.5\n\nL’istogramma seguente descrive la distribuzione della popolazione.\n\nggplot(data.frame(x = x), aes(x)) +\n  geom_histogram(\n    bins = 5,\n    aes(y = after_stat(density))\n  )\n\n\n\n\n\n\n\nStampiamo gli intervalli utilizzati per l’istogramma.\n\n# Calcolo degli intervalli e delle frequenze per l'istogramma\nhist_data &lt;- hist(x, breaks = 5, plot = FALSE)\n\n# Stampa degli intervalli e delle frequenze relative\ncat(\"Intervalli utilizzati per l'istogramma:\", hist_data$breaks, \"\\n\")\n#&gt; Intervalli utilizzati per l'istogramma: 2 2.5 3 3.5 4 4.5 5 5.5\ncat(\"Frequenze relative utilizzate per l'istogramma:\", hist_data$density, \"\\n\")\n#&gt; Frequenze relative utilizzate per l'istogramma: 0.5 0 0 0 0.5 0.5 0.5\n\n\n# Calcolo delle frequenze assolute\nhist_data_abs &lt;- hist(x, breaks = 5, plot = FALSE)\n\n# Stampa delle frequenze assolute\ncat(\"Frequenze assolute utilizzate per l'istogramma:\", hist_data_abs$counts, \"\\n\")\n#&gt; Frequenze assolute utilizzate per l'istogramma: 1 0 0 0 1 1 1\n\nCalcoliamo la media e la varianza della popolazione. Media:\n\nmean_x &lt;- mean(x) # Media della popolazione\nmean_x\n#&gt; [1] 4.25\n\nVarianza:\n\nvar_x &lt;- var(x) * ((length(x) - 1) / length(x)) # Varianza popolazione\nvar_x\n#&gt; [1] 1.81\n\nConsideriamo tutti i possibili campioni di dimensione \\(n = 2\\) che possono essere estratti dalla popolazione rappresentata dal vettore x. Per generare questi campioni, utilizziamo la funzione expand.grid in R, che consente di creare tutte le combinazioni possibili di valori, includendo le ripetizioni.\nIl risultato sarà un data frame con 16 righe e 2 colonne, dove ogni riga rappresenta una coppia possibile di valori estratti dal vettore x. Questo risultato è in linea con il principio del calcolo combinatorio: quando selezioniamo \\(n\\) elementi da un insieme di \\(k\\) elementi e permettiamo ripetizioni, il numero totale di combinazioni è dato da \\(k^n\\). Nel nostro caso, con \\(k = 4\\) e \\(n = 2\\), otteniamo:\n\\[\n4^2 = 16 \\text{ combinazioni}.\n\\]\nUtilizzando expand.grid, possiamo verificare questo risultato in R:\n\n# Generazione delle combinazioni con ripetizione\nsamples &lt;- expand.grid(x, x)\n\n# Visualizzazione del risultato\nprint(samples)\n#&gt;    Var1 Var2\n#&gt; 1   2.0  2.0\n#&gt; 2   4.5  2.0\n#&gt; 3   5.0  2.0\n#&gt; 4   5.5  2.0\n#&gt; 5   2.0  4.5\n#&gt; 6   4.5  4.5\n#&gt; 7   5.0  4.5\n#&gt; 8   5.5  4.5\n#&gt; 9   2.0  5.0\n#&gt; 10  4.5  5.0\n#&gt; 11  5.0  5.0\n#&gt; 12  5.5  5.0\n#&gt; 13  2.0  5.5\n#&gt; 14  4.5  5.5\n#&gt; 15  5.0  5.5\n#&gt; 16  5.5  5.5\n\nIl data frame risultante mostrerà tutte le possibili coppie \\((x_1, x_2)\\), dove \\(x_1\\) e \\(x_2\\) possono essere scelti indipendentemente dalla popolazione \\(x = \\{2, 4.5, 5, 5.5\\}\\).\nPer calcolare la media di ogni campione di ampiezza \\(n = 2\\), possiamo utilizzare la funzione rowMeans, che calcola la media per ogni riga di una matrice. In questo modo, otteniamo un vettore contenente la media di ciascuna coppia di valori. Questo insieme di valori costituisce la distribuzione campionaria delle medie dei campioni di ampiezza \\(n = 2\\) che possono essere estratti dalla popolazione x.\n\n# Calcolare la media di ciascun campione\nsample_means &lt;- rowMeans(samples)\nprint(sample_means)\n#&gt;  [1] 2.00 3.25 3.50 3.75 3.25 4.50 4.75 5.00 3.50 4.75 5.00 5.25 3.75 5.00\n#&gt; [15] 5.25 5.50\n\nUna rappresentazione grafica della distribuzione campionaria delle medie dei campioni di ampiezza \\(n = 2\\) che possono essere estratti dalla popolazione x è fornita qui sotto.\n\n# Istogramma delle medie campionarie\nggplot(data.frame(sample_means), aes(x = sample_means)) +\n  geom_histogram(\n    bins = 5,\n    aes(y = after_stat(density))\n)\n\n\n\n\n\n\n\nMostriamo qui nuovamente la lista di tutti i possibili campioni di ampiezza 2 insieme alla media di ciascun campione.\n\n# Creare un data frame con i campioni e le loro medie\ndf &lt;- data.frame(\n  Samples = apply(samples, 1, paste, collapse = \", \"),\n  x_bar = rowMeans(samples)\n)\nprint(df)\n#&gt;     Samples x_bar\n#&gt; 1      2, 2  2.00\n#&gt; 2    4.5, 2  3.25\n#&gt; 3      5, 2  3.50\n#&gt; 4    5.5, 2  3.75\n#&gt; 5    2, 4.5  3.25\n#&gt; 6  4.5, 4.5  4.50\n#&gt; 7    5, 4.5  4.75\n#&gt; 8  5.5, 4.5  5.00\n#&gt; 9      2, 5  3.50\n#&gt; 10   4.5, 5  4.75\n#&gt; 11     5, 5  5.00\n#&gt; 12   5.5, 5  5.25\n#&gt; 13   2, 5.5  3.75\n#&gt; 14 4.5, 5.5  5.00\n#&gt; 15   5, 5.5  5.25\n#&gt; 16 5.5, 5.5  5.50\n\nProcediamo ora al calcolo della media della distribuzione campionaria delle medie di campioni di ampiezza \\(n = 2\\) che possono essere estratti dalla popolazione x.\n\n# Calcolare la media delle medie campionarie\nmean(sample_means)\n#&gt; [1] 4.25\n\nSi noti che questo valore coincide con la media della popolazione. In generale, infatti, possiamo dire quanto segue.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#valore-atteso-della-media-campionaria",
    "href": "chapters/probability/08_sampling_distr.html#valore-atteso-della-media-campionaria",
    "title": "33  Stime, stimatori e parametri",
    "section": "\n33.4 Valore Atteso della Media Campionaria",
    "text": "33.4 Valore Atteso della Media Campionaria\nIl valore atteso della media campionaria è una proprietà fondamentale in statistica. Supponiamo che \\(X_1, X_2, \\ldots, X_n\\) siano variabili aleatorie indipendenti e identicamente distribuite (iid), con valore atteso \\(\\mu\\) e varianza \\(\\sigma^2\\). La media campionaria è definita come:\n\\[\n\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i.\n\\]\nVogliamo dimostrare che il valore atteso della media campionaria \\(\\mathbb{E}(\\bar{X})\\) coincide con il valore atteso delle singole variabili, cioè \\(\\mu\\).\n\n\n33.4.1 Dimostrazione\nApplichiamo le proprietà della speranza matematica per calcolare \\(\\mathbb{E}(\\bar{X})\\):\n\\[\n\\begin{align*}\n\\mathbb{E}(\\bar{X}) & = \\mathbb{E}\\left(\\frac{1}{n} \\sum_{i=1}^n X_i\\right) & \\text{(definizione di media campionaria)} \\\\\n& = \\frac{1}{n} \\mathbb{E}\\left(\\sum_{i=1}^n X_i\\right) & \\text{(linearità della speranza)} \\\\\n& = \\frac{1}{n} \\sum_{i=1}^n \\mathbb{E}(X_i) & \\text{(speranza della somma)} \\\\\n& = \\frac{1}{n} \\sum_{i=1}^n \\mu & \\text{(tutte le $X_i$ hanno valore atteso $\\mu$)} \\\\\n& = \\frac{1}{n} \\cdot n \\cdot \\mu & \\text{(semplificazione della somma)} \\\\\n& = \\mu.\n\\end{align*}\n\\]\n\n33.4.2 Interpretazione\nAbbiamo dimostrato che il valore atteso della media campionaria è uguale al valore atteso delle singole variabili. In termini pratici, ciò implica che la media campionaria è un stimatore non distorto del valore atteso della popolazione: anche se la media campionaria può variare a seconda del campione, in media si avvicina sempre al valore atteso della popolazione, \\(\\mu\\).\nQuesta proprietà è una delle basi della statistica inferenziale. La media campionaria è uno degli stimatori più utilizzati in pratica proprio perché, oltre a essere non distorta, presenta altre proprietà utili, come l’efficienza (soprattutto per \\(n\\) grande).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#varianza-della-media-campionaria",
    "href": "chapters/probability/08_sampling_distr.html#varianza-della-media-campionaria",
    "title": "33  Stime, stimatori e parametri",
    "section": "\n33.5 Varianza della media campionaria",
    "text": "33.5 Varianza della media campionaria\nDato che le variabili \\(X_1, X_2, \\ldots, X_n\\) sono indipendenti ed identicamente distribuite (iid) con valore atteso \\(\\mu\\) e varianza \\(\\sigma^2\\), possiamo calcolare la varianza della media campionaria \\(\\bar{X}\\) come segue:\n\\[\n\\begin{align*}\n\\text{Var}(\\bar{X}) & = \\text{Var}\\left(\\frac{1}{n} \\sum_{i=1}^n X_i\\right) \\\\\n& = \\frac{1}{n^2} \\text{Var}\\left(\\sum_{i=1}^n X_i\\right) \\\\\n& = \\frac{1}{n^2} \\sum_{i=1}^n \\text{Var}(X_i) \\quad \\text{(dato che le $X_i$ sono indipendenti, i termini incrociati si annullano)} \\\\\n& = \\frac{1}{n^2} \\sum_{i=1}^n \\sigma^2 \\\\\n& = \\frac{1}{n^2} \\cdot n \\cdot \\sigma^2 \\\\\n& = \\frac{\\sigma^2}{n}\n\\end{align*}\n\\]\nQuindi, la varianza della media campionaria di \\(n\\) variabili iid è uguale alla varianza di ciascuna variabile singola divisa per \\(n\\), che in questo caso è \\(\\sigma^2/n\\).\nQuesto risultato riflette un’importante proprietà statistica:\n\nall’aumentare di \\(n\\), la varianza della media campionaria diminuisce, rendendo la media campionaria una stima più precisa del valore atteso \\(\\mu\\). La riduzione della varianza è proporzionale a \\(1/n\\), quindi raddoppiare il campione riduce la varianza della media campionaria di un fattore 2.\n\nIn conclusione, la formula \\(\\text{Var}(\\bar{X}) = \\frac{\\sigma^2}{n}\\) mostra che la precisione della media campionaria aumenta con la dimensione del campione, poiché la varianza diminuisce. Questo principio è alla base dell’importanza di campioni più grandi nella stima statistica.\n\n33.5.1 Applicazione\nAnalizziamo l’esempio in dettaglio per comprendere meglio i concetti relativi alle medie campionarie e al loro rapporto con la popolazione.\n\n\n33.5.1.1 Varianza delle Medie Campionarie\nLa varianza delle medie campionarie, calcolata empiricamente, può essere ottenuta direttamente dai dati:\n\nvar(x) * ((length(x) - 1) / length(x)) / 2\n#&gt; [1] 0.906\n\nQuesto calcolo riflette la formula per la varianza della media campionaria, dove il fattore (((x) - 1) / (x)) corregge per il fatto che stiamo lavorando con una popolazione finita. In alternativa, possiamo calcolare lo stesso valore prendendo la varianza delle medie di tutti i campioni (16 in questo caso):\n\nvar(sample_means) * ((length(sample_means) - 1) / length(sample_means))\n#&gt; [1] 0.906\n\nEntrambi i calcoli forniscono risultati coerenti con la teoria, dimostrando che la varianza delle medie campionarie è inferiore a quella della popolazione.\n\n33.5.1.2 Analisi di un Campione Specifico\nPrendiamo ora un campione particolare dalla popolazione:\n\nobserved_sample &lt;- c(5, 5.5)\nprint(observed_sample)\n#&gt; [1] 5.0 5.5\n\n\n\nMedia del Campione\nLa media del campione viene calcolata come segue:\n\n\nsample_mean &lt;- mean(observed_sample)\nprint(sample_mean)\n#&gt; [1] 5.25\n\nLa media campionaria (\\(\\bar{x} = 5.25\\)) è diversa dalla media della popolazione (\\(\\mu = 4.25\\)), come è atteso per un singolo campione.\n\n\nDeviazione Standard del Campione\nLa deviazione standard del campione è calcolata utilizzando la formula corretta per la varianza campionaria:\n\n\nsample_sd &lt;- sqrt(var(observed_sample) / 2)\nprint(sample_sd)\n#&gt; [1] 0.25\n\nAnche la deviazione standard del campione è diversa dalla deviazione standard della popolazione:\n\nsqrt(var(x) * (length(x) - 1) / length(x))\n#&gt; [1] 1.35\n\nQuesto risultato riflette il fatto che un singolo campione non riproduce perfettamente le proprietà della popolazione, ma le medie campionarie aggregate tendono a rifletterle meglio.\n\n33.5.2 Risultati Centrali\nDall’analisi delle medie campionarie emergono due risultati fondamentali:\n\n\nMedia delle Medie Campionarie e Media della Popolazione\nLa media della distribuzione delle medie campionarie coincide con la media della popolazione:\n\\[\n\\mathbb{E}(\\bar{X}_n) = \\mu.\n\\]\n\n\nVarianza delle Medie Campionarie\nLa varianza delle medie campionarie è inferiore alla varianza della popolazione ed è pari a:\n\\[\n\\mathbb{V}(\\bar{X}_n) = \\frac{\\sigma^2}{n}.\n\\]\n\n\nQuesti risultati dimostrano empiricamente come le medie campionarie rappresentino una stima non distorta della media della popolazione e diventino più precise all’aumentare della dimensione del campione \\(n\\).\n\n33.5.3 Forma della Distribuzione delle Medie Campionarie\nIl comportamento della distribuzione delle medie campionarie dipende dalla distribuzione della popolazione:\n\n\nDistribuzione Normale: Se la popolazione segue una distribuzione normale, le medie campionarie seguiranno anch’esse una distribuzione normale, indipendentemente dalla dimensione del campione.\n\nDistribuzione Non Normale: Se la popolazione non segue una distribuzione normale, il Teorema del Limite Centrale garantisce che, per dimensioni del campione sufficientemente grandi, la distribuzione delle medie campionarie tenderà a una distribuzione normale.\n\n\nIn conclusione, l’analisi delle medie campionarie ci fornisce una comprensione fondamentale dei principi statistici alla base dell’inferenza. La convergenza delle medie campionarie alla media della popolazione e la riduzione della loro varianza con l’aumentare di \\(n\\) sono concetti chiave che supportano molte tecniche di stima e test statistici. Inoltre, il ruolo del Teorema del Limite Centrale evidenzia la robustezza di questi principi, indipendentemente dalla forma della distribuzione di partenza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#errore-standard-e-rappresentazione-dellincertezza-inferenziale",
    "href": "chapters/probability/08_sampling_distr.html#errore-standard-e-rappresentazione-dellincertezza-inferenziale",
    "title": "33  Stime, stimatori e parametri",
    "section": "\n33.6 Errore standard e rappresentazione dell’incertezza inferenziale",
    "text": "33.6 Errore standard e rappresentazione dell’incertezza inferenziale\nNella statistica inferenziale, l’errore standard è una misura frequentemente utilizzata per rappresentare l’incertezza legata a un parametro stimato, conosciuta anche come incertezza inferenziale. L’errore standard quantifica quanto possa variare la stima di una statistica da un campione all’altro; un errore standard minore indica una stima più precisa, mentre uno maggiore implica maggiore incertezza. Spesso, le rappresentazioni grafiche includono gli errori standard nella forma di “media più o meno uno (o due) errori standard.” Questa espressione fornisce una gamma di valori entro cui è plausibile che ricada il valore vero del parametro della popolazione.\nL’uso dell’errore standard nei grafici non è soltanto una convenzione; esso è uno strumento per quantificare e visualizzare l’incertezza inferenziale. Contribuisce alla comprensione dell’affidabilità delle stime ottenute dai dati campionari, permettendo di valutare quanto le stime possano variare se si prendesse un altro campione dalla stessa popolazione. Tuttavia, è importante notare che questo utilizzo dell’errore standard può essere problematico (Ward & Mann, 2022).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#legge-dei-grandi-numeri",
    "href": "chapters/probability/08_sampling_distr.html#legge-dei-grandi-numeri",
    "title": "33  Stime, stimatori e parametri",
    "section": "\n33.7 Legge dei Grandi Numeri",
    "text": "33.7 Legge dei Grandi Numeri\nLa Legge dei Grandi Numeri (LLN) è un principio fondamentale della teoria delle probabilità che stabilisce come, incrementando il numero \\(n\\) di osservazioni, la media campionaria \\(\\bar{X}_n\\) tenda asintoticamente alla media teorica \\(\\mu\\). La LLN si articola in due varianti: la versione “forte” e quella “debole”, le quali differiscono per il tipo di convergenza verso la media attesa.\n\n33.7.1 Versione Forte della Legge dei Grandi Numeri (SLLN)\nLa SLLN afferma che la media campionaria $ {X}_n $ converge quasi certamente alla media teorica \\(\\mu\\), ovvero la convergenza avviene con probabilità 1. Questo implica che, per quasi ogni possibile sequenza di eventi nell’insieme campionario \\(S\\), \\(\\bar{X}_n(s)\\) tende a \\(\\mu\\), ad eccezione di un insieme di eventi \\(B_0\\) la cui probabilità è zero. In termini tecnici, si dice che \\(\\bar{X}_n\\) converge a \\(\\mu\\) “quasi certamente”.\n\n33.7.2 Versione Debole della Legge dei Grandi Numeri (WLLN)\nLa WLLN afferma che, per ogni \\(\\epsilon &gt; 0\\), la probabilità che la media campionaria \\(\\bar{X}_n\\) si discosti da \\(\\mu\\) di una quantità maggiore di \\(\\epsilon\\) tende a zero all’aumentare di \\(n\\). Questo fenomeno è definito come convergenza in probabilità verso la media teorica \\(\\mu\\).\n\n33.7.3 Implicazioni e Applicazioni\nLa Legge dei Grandi Numeri riveste un ruolo cruciale nel campo delle simulazioni, della statistica e, più in generale, nelle discipline scientifiche. La generazione di dati attraverso numerose repliche indipendenti di un esperimento, sia in ambito simulativo che empirico, implica l’utilizzo della media campionaria come stima affidabile della media teorica della variabile di interesse. In pratica, la LLN fornisce una base teorica per l’affidabilità delle stime medie ottenute da grandi campioni di dati, sottolineando come, a fronte di un numero elevato di osservazioni, le fluttuazioni casuali tendano ad annullarsi, convergendo verso un valore stabile e prevedibile.\n\nEsempio 33.1 Siano \\(X_1, X_2, \\ldots\\) variabili aleatorie indipendenti e identicamente distribuite secondo una distribuzione di Bernoulli con parametro \\(1/2\\). Interpretando gli \\(X_j\\) come indicatori di “Testa” in una sequenza di lanci di una moneta equa, \\(\\bar{X}_n\\) rappresenta la proporzione di “Testa” dopo \\(n\\) lanci. La Legge Forte dei Grandi Numeri (SLLN) afferma che, con probabilità 1, la sequenza di variabili aleatorie \\(\\bar{X}_1, \\bar{X}_2, \\bar{X}_3, \\ldots\\) convergerà a \\(1/2\\) quando si cristallizza in una sequenza di numeri reali. Matematicamente parlando, esistono scenari improbabili come una sequenza infinita di “Testa” (HHHHHH…) o sequenze irregolari come HHTHHTHHTHHT…, ma queste hanno una probabilità collettiva di zero di verificarsi. La Legge Debole dei Grandi Numeri (WLLN) stabilisce che, per ogni \\(\\epsilon &gt; 0\\), la probabilità che \\(\\bar{X}_n\\) sia distante più di \\(\\epsilon\\) da \\(1/2\\) può essere resa arbitrariamente piccola aumentando \\(n\\).\nCome illustrazione, abbiamo simulato sei sequenze di lanci di una moneta equa e, per ciascuna sequenza, abbiamo calcolato \\(\\bar{X}_n\\) in funzione di \\(n\\). Ovviamente, nella realtà non possiamo effettuare un numero infinito di lanci, quindi ci siamo fermati dopo 300 lanci. Il grafico seguente mostra \\(\\bar{X}_n\\) in funzione di $ n $ per ciascuna delle sei sequenze. All’inizio, notiamo una certa variazione nella proporzione cumulativa di “Testa”. Tuttavia, con l’aumentare del numero di lanci, la varianza $ ({X}_n) $ diminuisce progressivamente e \\(\\bar{X}_n\\) tende a \\(1/2\\).\n\n# Numero di sequenze\nnum_sequences &lt;- 6\n# Numero di lanci\nnum_tosses &lt;- 300\n\n# Creare un data frame per contenere i risultati\nresults &lt;- data.frame(Toss = numeric(), Proportion = numeric(), Sequence = character())\n\n# Loop attraverso ciascuna sequenza\nfor (i in 1:num_sequences) {\n  # Generare una sequenza di lanci di moneta equa (Testa=1, Croce=0)\n  coin_tosses &lt;- sample(c(0, 1), num_tosses, replace = TRUE)\n  \n  # Calcolare la proporzione cumulativa di Teste\n  running_proportion &lt;- cumsum(coin_tosses) / seq_along(coin_tosses)\n  \n  # Aggiungere i risultati al data frame\n  results &lt;- rbind(\n    results,\n    data.frame(\n      Toss = seq_along(coin_tosses),\n      Proportion = running_proportion,\n      Sequence = paste(\"Sequence\", i)\n    )\n  )\n}\n\n# Creare il grafico con ggplot2\nggplot(results, aes(x = Toss, y = Proportion, color = Sequence)) +\n  geom_line() +\n  geom_hline(yintercept = 0.5, color = \"red\", linetype = \"dashed\") +\n  labs(\n    x = \"Number of Tosses\",\n    y = \"Running Proportion of Heads\",\n    title = \"Running Proportion of Heads in Six Sequences of Fair Coin Tosses\",\n    color = \"Sequence\"\n  )",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#teorema-del-limite-centrale",
    "href": "chapters/probability/08_sampling_distr.html#teorema-del-limite-centrale",
    "title": "33  Stime, stimatori e parametri",
    "section": "\n33.8 Teorema del Limite Centrale",
    "text": "33.8 Teorema del Limite Centrale\nIl teorema del limite centrale è un risultato fondamentale in statistica che è stato dimostrato per la prima volta da Laplace nel 1812. Esso fornisce una spiegazione matematica per il motivo per cui la distribuzione normale appare così frequentemente nei fenomeni naturali. Ecco la formulazione essenziale.\nSupponiamo di avere una sequenza di variabili aleatorie indipendenti ed identicamente distribuite (i.i.d.), \\(Y = Y_1, \\dots, Y_i, \\ldots, Y_n\\), ciascuna con valore atteso \\(\\mathbb{E}(Y_i) = \\mu\\) e deviazione standard \\(SD(Y_i) = \\sigma\\). Definiamo una nuova variabile casuale come la media aritmetica di queste variabili:\n\\[\nZ = \\frac{1}{n} \\sum_{i=1}^n Y_i.\n\\]\nAllora, quando \\(n\\) tende all’infinito, la distribuzione di \\(Z\\) convergerà a una distribuzione normale con media \\(\\mu\\) e deviazione standard ridotta di un fattore \\(\\frac{1}{\\sqrt{n}}\\):\n\\[\np_Z(z) \\rightarrow \\mathcal{N}\\left(z \\ \\Bigg| \\ \\mu, \\, \\frac{\\sigma}{\\sqrt{n}}\\right).\n\\]\n\n33.8.1 Significato e generalizzazione\nIl TLC non si applica solo alle variabili casuali con la stessa distribuzione, ma può essere esteso a variabili casuali indipendenti con aspettative e varianze finite. La potenza del teorema sta nella sua capacità di descrivere fenomeni che sono il risultato di molteplici effetti additivi indipendenti. Anche se questi effetti possono avere distribuzioni diverse, la loro somma tende a una distribuzione normale.\nAd esempio, l’altezza degli esseri umani adulti può essere vista come la somma di molti fattori genetici e ambientali indipendenti. Indipendentemente dalla distribuzione individuale di questi fattori, la loro combinazione tende a formare una distribuzione normale. Questa universalità rende la distribuzione normale una buona approssimazione per molti fenomeni naturali.\n\nEsempio 33.2 Per visualizzare il TLC in azione, si può condurre una simulazione. Immaginiamo una popolazione distribuita in maniera uniforme. Estraiamo 300 campioni di dimensione \\(n\\) = 30 da questa popolazione e osserviamo come la distribuzione campionaria di tali medie converga a una distribuzione normale. Questa simulazione fornirà un’illustrazione concreta dell’efficacia del TLC nell’approssimare distribuzioni reali.\n\n# Set the random seed for reproducibility\nset.seed(42)\n\n# Generate a non-normally distributed population\npopulation &lt;- runif(5000, min = 0, max = 1)\n\n# Create a histogram of the population\npar(mfrow = c(1, 2))  # Set up a 1x2 grid for plotting\n\n# Plot the histogram of the population\nhist(population, breaks = 30, prob = TRUE, main = \"Population Distribution\",\n     xlab = \"Value\", col = \"lightblue\")\n\n# Step 2 and 3: Draw random samples and calculate sample means\nsample_size &lt;- 30\nnum_samples &lt;- 300\n\n# Empty vector to store sample means\nsample_means &lt;- c()\n\nfor (i in 1:num_samples) {\n  # Take a random sample\n  sample &lt;- sample(population, size = sample_size, replace = TRUE)\n  \n  # Calculate the mean of the sample\n  sample_means[i] &lt;- mean(sample)\n}\n\n# For sample\nx_bar &lt;- mean(sample_means)\nstd &lt;- sd(sample_means)\n\nprint('Sample Mean and Variance')\n#&gt; [1] \"Sample Mean and Variance\"\nprint(x_bar)\n#&gt; [1] 0.501\nprint(std**2)\n#&gt; [1] 0.00275\n\n# For Population\nmu &lt;- mean(population)\nsigma &lt;- sd(population)\n\nprint('Population Mean and Variance')\n#&gt; [1] \"Population Mean and Variance\"\nprint(mu)\n#&gt; [1] 0.503\nprint((sigma**2)/sample_size)\n#&gt; [1] 0.00282\n\n# Plot the histogram of sample means\nhist(sample_means, breaks = 30, prob = TRUE, main = \"Distribution of Sample Means\",\n     xlab = \"Sample Mean\", col = \"lightgreen\")\n\n# Overlay density curves\ncurve(dnorm(x, mean = x_bar, sd = std), col = \"black\", lwd = 2, add = TRUE)\n\n# Add labels and legends\nlegend(\"topright\", legend = c(\"Distribution Curve\"),\n       col = c(\"black\"), lwd = 2)\n\n# Reset the plot layout\npar(mfrow = c(1, 1))\n\n\n\n\n\n\n\n\nIn conclusione, il teorema del limite centrale (TLC) stabilisce che, a meno che non si stia lavorando con campioni estremamente piccoli, è possibile approssimare con buona precisione la distribuzione campionaria della media dei campioni utilizzando la distribuzione Normale. Questo vale indipendentemente dalla forma specifica della distribuzione della popolazione da cui sono tratti i campioni. In altre parole, quando si lavora con campioni di dimensioni sufficienti, il TLC offre una formula concreta per descrivere la forma della distribuzione campionaria della media dei campioni. Ciò avviene anche se non si hanno informazioni dettagliate sulla popolazione, come la media \\(\\mu\\) e la deviazione standard \\(\\sigma\\), ed è espresso dalla relazione \\(\\bar{X} \\sim \\mathcal{N}(\\mu, \\sigma/\\sqrt{n})\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#distribuzioni-campionarie-di-altre-statistiche",
    "href": "chapters/probability/08_sampling_distr.html#distribuzioni-campionarie-di-altre-statistiche",
    "title": "33  Stime, stimatori e parametri",
    "section": "\n33.9 Distribuzioni campionarie di altre statistiche",
    "text": "33.9 Distribuzioni campionarie di altre statistiche\nIn precedenza abbiamo descritto la distribuzione campionaria della media dei campioni. Ma ovviamente è possibile costruire la distribuzione campionaria di altre statistiche campionarie. Ad esempio, la figura seguente mostra l’approssimazione empirica della distribuzione campionaria del valore massimo del campione. È chiaro che, se da ciascun campione estraiamo il valore massimo, il valore atteso della distribuzione campionaria di questa statistica sarà maggiore della media della popolazione.\n\n# Definire una distribuzione normale con media 100 e deviazione standard 15\nmu &lt;- 100\nsigma &lt;- 15\nx &lt;- seq(mu - 3 * sigma, mu + 3 * sigma, length.out = 100)\ny &lt;- dnorm(x, mean = mu, sd = sigma)\n\n# Simulare 10.000 esperimenti con 5 soggetti ciascuno e trovare il massimo punteggio per ciascun esperimento\nset.seed(123)  # Per riproducibilità\nsample_maxes &lt;- replicate(10000, max(rnorm(5, mean = mu, sd = sigma)))\n\n# Creare un istogramma della distribuzione dei massimi campionari insieme alla distribuzione della popolazione\n\n# Creare il data frame per il grafico\ndata &lt;- data.frame(SampleMaxes = sample_maxes)\ndensity_data &lt;- data.frame(x = x, y = y)\n\nggplot(data, aes(x = SampleMaxes)) +\n  geom_histogram(\n    aes(y = ..density..),\n    bins = 30,\n    alpha = 0.7\n  ) +\n  geom_line(data = density_data, aes(x = x, y = y), size = 1) +\n  labs(\n    title = \"Distribuzione dei massimi campionari\",\n    x = \"Massimo campionario\",\n    y = \"Densità\"\n  ) \n#&gt; Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#&gt; ℹ Please use `linewidth` instead.\n#&gt; Warning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\n#&gt; ℹ Please use `after_stat(density)` instead.\n\n\n\n\n\n\n\nLa distribuzione campionaria della varianza dei campioni è particolarmente interessante. Usiamo la formula della statistica descrittiva, ovvero\n\\[\nS^2 = \\frac{\\sum_{i=1}^n (Y_i - \\bar{Y})^2}{n}.\n\\]\nUna volta compresa la procedura, possiamo creare un grafico che rappresenta l’approssimazione empirica della distribuzione campionaria della varianza dei punteggi del quoziente di intelligenza. Sapendo che la varianza della popolazione è uguale a \\(15^2\\), abbiamo utilizzato la simulazione per stimare la varianza della popolazione. Tuttavia, il risultato ottenuto è stato interessante: in media, l’utilizzo della formula precedente ha portato a una stima della varianza della popolazione troppo piccola. Gli statistici chiamano questa discrepanza distorsione, ovvero quando il valore atteso di uno stimatore non coincide con il parametro.\n\n# Definire una distribuzione normale con media 100 e deviazione standard 15\nmu &lt;- 100\nsigma &lt;- 15\nx &lt;- seq(0, 30, length.out = 100)\ny &lt;- dnorm(x, mean = mu, sd = sigma)\n\n# Simulare 10.000 esperimenti con 5 soggetti ciascuno e calcolare la varianza per ciascun esperimento\nset.seed(123)  # Per riproducibilità\nsample_vars &lt;- replicate(10000, var(rnorm(5, mean = mu, sd = sigma)))\n\n# Creare un istogramma della distribuzione delle varianze campionarie\n\ndata &lt;- data.frame(SampleVars = sample_vars)\n\nggplot(data, aes(x = SampleVars)) +\n  geom_histogram(\n    aes(y = ..density..),\n    bins = 30,\n    alpha = 0.7\n  ) +\n  labs(\n    title = \"Distribuzione delle varianze campionarie\",\n    x = \"Varianza campionaria\",\n    y = \"Densità\"\n  ) \n\n\n\n\n\n\n\n\n# Calcolare la media delle varianze campionarie\nmean(sample_vars)\n#&gt; [1] 226\n\nAbbiamo già visto come questo problema trova una semplice soluzione nel momento in cui usiamo \\(n-1\\) al denominatore.\n\n# Definire una distribuzione normale con media 100 e deviazione standard 15\nmu &lt;- 100\nsigma &lt;- 15\nx &lt;- seq(0, 30, length.out = 100)\ny &lt;- dnorm(x, mean = mu, sd = sigma)\n\n# Simulare 10.000 esperimenti con 5 soggetti ciascuno e calcolare la varianza corretta per ciascun esperimento\nset.seed(123)  # Per riproducibilità\nsample_vars &lt;- replicate(10000, var(rnorm(5, mean = mu, sd = sigma)))\n\n# Creare un istogramma della distribuzione delle varianze campionarie\ndata &lt;- data.frame(SampleVars = sample_vars)\n\nggplot(data, aes(x = SampleVars)) +\n  geom_histogram(\n    aes(y = ..density..),\n    bins = 30,\n    alpha = 0.7\n  ) +\n  labs(\n    title = \"Distribuzione delle varianze campionarie\",\n    x = \"Varianza campionaria\",\n    y = \"Densità\"\n  ) \n\n\n\n\n\n\n\n\n# Calcolare la media delle varianze campionarie\nmean(sample_vars)\n#&gt; [1] 226\n\nLa differenza tra la stima di un parametro e il valore vero del parametro è chiamata errore della stima. Uno stimatore si dice non distorto (unbiased) se la media delle sue stime su molteplici campioni ipotetici è uguale al valore del parametro che si vuole stimare. In altre parole, l’errore medio di stima è zero.\nIn questo capitolo abbiamo visto che \\(\\frac{\\sum_{i=1}^n{X_i}}{n}\\) è uno stimatore non distorto di \\(\\mu\\) e che \\(\\frac{\\sum_{i=1}^n{(^2)}}{n-1}\\) è uno stimatore non distorto di \\(\\sigma^2\\). Questo significa che tali stimatori hanno una distribuzione campionaria centrata sul vero valore del parametro.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#riflessioni-conclusive",
    "href": "chapters/probability/08_sampling_distr.html#riflessioni-conclusive",
    "title": "33  Stime, stimatori e parametri",
    "section": "\n33.10 Riflessioni Conclusive",
    "text": "33.10 Riflessioni Conclusive\nIn generale, i parametri della popolazione sono sconosciuti, ma possiamo stimarli utilizzando le informazioni del campione. Di seguito viene presentata una tabella che riassume i simboli comuni utilizzati per indicare le quantità note e sconosciute nel contesto dell’inferenza statistica. Questo ci aiuterà a tenere traccia di ciò che sappiamo e ciò che non sappiamo.\n\n\n\n\n\n\n\nSimbolo\nNome\nÈ qualcosa che conosciamo?\n\n\n\n\\(s\\)\nDeviazione standard del campione\nSì, la calcoliamo dai dati grezzi\n\n\n\\(\\sigma\\)\nDeviazione standard della popolazione\nNo, tranne in casi particolari o nelle simulazioni\n\n\n\\(\\hat{\\sigma}\\)\nStima della deviazione standard della popolazione\nSì, ma non è uguale a \\(\\sigma\\)\n\n\n\n\\(s^2\\)\nVarianza del campione\nSì, la calcoliamo dai dati grezzi\n\n\n\\(\\sigma^2\\)\nVarianza della popolazione\nNo, tranne in casi particolari o nelle simulazioni\n\n\n\\(\\hat{\\sigma}^2\\)\nStima della varianza della popolazione\nSì, ma non è uguale a \\(\\sigma^2\\)\n\n\n\n\nUtilizzando le informazioni di un campione casuale di ampiezza \\(n\\):\n\nLa stima migliore che possiamo ottenere per la media \\(\\mu\\) della popolazione è la media del campione \\(\\bar{Y}\\).\nLa stima migliore che possiamo ottenere per la varianza \\(\\sigma^2\\) della popolazione è:\n\n\\[\n\\hat{\\sigma}^2 = \\frac{1}{n-1} \\sum_{i=1}^n (Y_i - \\bar{Y})^2.\n\\]",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/08_sampling_distr.html#informazioni-sullambiente-di-sviluppo",
    "title": "33  Stime, stimatori e parametri",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] see_0.9.0        gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1\n#&gt;  [5] psych_2.4.12     scales_1.3.0     markdown_1.13    knitr_1.49      \n#&gt;  [9] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [13] purrr_1.0.2      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [17] ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.3         rlang_1.1.4       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       yaml_2.3.10       tools_4.4.2       parallel_4.4.2   \n#&gt; [21] tzdb_0.4.0        colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5      \n#&gt; [25] R6_2.5.1          lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3  \n#&gt; [29] pillar_1.10.0     gtable_0.3.6      glue_1.8.0        xfun_0.49        \n#&gt; [33] tidyselect_1.2.1  farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-166     \n#&gt; [37] labeling_0.4.3    rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#bibliografia",
    "href": "chapters/probability/08_sampling_distr.html#bibliografia",
    "title": "33  Stime, stimatori e parametri",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nWard, A., & Mann, T. (2022). Control yourself: Broad implications of narrowed attention. Perspectives on Psychological Science, 17(6), 1692–1703.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html",
    "href": "chapters/probability/09_joint_prob.html",
    "title": "34  Probabilità congiunta",
    "section": "",
    "text": "34.1 Introduzione\nPrerequisiti\nConcetti e Competenze Chiave\nPreparazione del Notebook\nIn questo capitolo ci proponiamo di analizzare in dettaglio il concetto di probabilità congiunta, focalizzando l’attenzione sul caso di variabili aleatorie discrete. La probabilità congiunta rappresenta la misura della probabilità che due o più eventi si verifichino simultaneamente.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#funzione-di-probabilità-congiunta",
    "href": "chapters/probability/09_joint_prob.html#funzione-di-probabilità-congiunta",
    "title": "34  Probabilità congiunta",
    "section": "\n34.2 Funzione di Probabilità Congiunta",
    "text": "34.2 Funzione di Probabilità Congiunta\nFinora abbiamo analizzato la probabilità associata a un singolo evento, o più precisamente, a un singolo valore assunto da una variabile aleatoria. Tuttavia, spesso siamo interessati a studiare la relazione tra due o più eventi. La funzione di probabilità congiunta ci permette di estendere il concetto di probabilità al caso di più variabili aleatorie, descrivendo la probabilità che queste assumano specifici valori contemporaneamente.\n\n34.2.1 Esempio: Lancio di Tre Monete Equilibrate\nPer comprendere meglio il concetto di probabilità congiunta, immaginiamo di lanciare tre monete. Tutti i possibili risultati di questo esperimento (ad esempio, tre teste, due teste e una croce, ecc.) costituiscono quello che chiamiamo spazio campionario. In questo caso, lo spazio campionario \\(\\Omega\\) è dato da:\n\\[\n\\Omega = \\{TTT, TTC, TCT, CTT, CCT, CTC, TCC, CCC\\},\n\\]\ndove \\(T\\) indica “testa” e \\(C\\) indica “croce”. Assumendo che ogni lancio sia indipendente dagli altri, ogni risultato nello spazio campionario \\(\\Omega\\) ha la stessa probabilità di verificarsi, ovvero \\(1/8\\).\nDefiniamo ora le seguenti variabili casuali sullo spazio campionario \\(\\Omega\\):\n\n\n\\(X \\in \\{0, 1, 2, 3\\}\\) rappresenta il numero totale di teste ottenute nei tre lanci.\n\n\\(Y \\in \\{0, 1\\}\\) indica se il primo lancio ha dato testa (\\(1\\)) oppure croce (\\(0\\)).\n\nLa tabella seguente mostra lo spazio campionario con i valori di \\(X\\) e \\(Y\\) associati a ciascun esito, insieme alla probabilità di ciascun evento \\(\\omega\\):\n\n\n\\(\\omega\\)\n\\(X\\)\n\\(Y\\)\n\\(P(\\omega)\\)\n\n\n\n\n\\(\\omega_1\\) = TTT\n3\n1\n1/8\n\n\n\n\\(\\omega_2\\) = TTC\n2\n1\n1/8\n\n\n\n\\(\\omega_3\\) = TCT\n2\n1\n1/8\n\n\n\n\\(\\omega_4\\) = CTT\n2\n0\n1/8\n\n\n\n\\(\\omega_5\\) = CCT\n1\n0\n1/8\n\n\n\n\\(\\omega_6\\) = CTC\n1\n0\n1/8\n\n\n\n\\(\\omega_7\\) = TCC\n1\n1\n1/8\n\n\n\n\\(\\omega_8\\) = CCC\n0\n0\n1/8\n\n\n\nOra possiamo determinare la probabilità congiunta per ogni coppia \\((X, Y)\\), che rappresenta la probabilità di ottenere un determinato numero di teste \\(X\\) e un determinato risultato per il primo lancio \\(Y\\). Ad esempio:\n\\[P(X=0, Y=0) = P(\\text{CCC}) = 1/8,\\]\ne così via per le altre coppie.\nLe probabilità congiunte per tutte le possibili combinazioni \\((X, Y)\\) sono calcolate come segue:\n\\[\n\\begin{aligned}\nP(X = 0, Y = 0) &= 1/8, \\\\\nP(X = 1, Y = 0) &= P(\\text{CCT}) + P(\\text{CTC}) = 1/4, \\\\\nP(X = 1, Y = 1) &= P(\\text{TCC}) = 1/8, \\\\\nP(X = 2, Y = 0) &= P(\\text{CTT}) = 1/8, \\\\\nP(X = 2, Y = 1) &= P(\\text{TTC}) + P(\\text{TCT}) = 1/4, \\\\\nP(X = 3, Y = 1) &= P(\\text{TTT}) = 1/8.\n\\end{aligned}\n\\]\nQueste probabilità costituiscono la distribuzione di probabilità congiunta delle variabili casuali \\(X\\) (numero di teste) e \\(Y\\) (testa al primo lancio). Questa distribuzione fornisce un quadro completo delle probabilità per tutte le combinazioni di risultati di queste due variabili.\n\n34.2.2 Definizione: Funzione di Probabilità Congiunta\nLa funzione di probabilità congiunta di due variabili casuali \\(X\\) e \\(Y\\) associa a ogni coppia \\((x, y)\\) una probabilità \\(P(X = x, Y = y)\\).\n\n34.2.3 Proprietà\nUna distribuzione di probabilità congiunta deve soddisfare:\n\n\n\\(0 \\leq P(x_i, y_j) \\leq 1\\) per ogni coppia \\((x_i, y_j)\\),\n\n\\(\\sum_{i} \\sum_{j} P(x_i, y_j) = 1\\), ovvero la somma delle probabilità su tutte le coppie deve essere 1.\n\n34.2.4 Calcolo della Probabilità di Eventi Specifici\nData la distribuzione di probabilità congiunta, possiamo determinare la probabilità di eventi definiti in termini delle variabili aleatorie \\(X\\) e \\(Y\\). Ad esempio, per trovare la probabilità che \\(X + Y \\leq 1\\), sommiamo le probabilità di tutte le coppie \\((x, y)\\) che soddisfano questa condizione, ottenendo \\(P(X+Y \\leq 1) = 3/8\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#marginalizzazione",
    "href": "chapters/probability/09_joint_prob.html#marginalizzazione",
    "title": "34  Probabilità congiunta",
    "section": "\n34.3 Marginalizzazione",
    "text": "34.3 Marginalizzazione\nImmagina di condurre uno studio sul livello di stress tra studenti universitari, raccogliendo dati su variabili come l’anno di corso, il genere, il supporto sociale e il livello di stress. Se desideri comprendere come il livello di stress varia in funzione dell’anno di corso, indipendentemente dal genere e dal supporto sociale, puoi utilizzare la marginalizzazione.\nLa marginalizzazione consente di ottenere una distribuzione di probabilità focalizzata su una o più variabili di interesse, “eliminando” dal calcolo le variabili non rilevanti. Nel nostro esempio, per ottenere la distribuzione marginale del livello di stress rispetto all’anno di corso, occorre sommare (o integrare, nel caso di variabili continue) le probabilità associate a tutte le combinazioni di genere e supporto sociale, mantenendo fisso l’anno di corso. In questo modo, otteniamo una distribuzione che descrive come il livello di stress varia solo in relazione all’anno di corso.\nIl termine “marginalizzazione” deriva dalle tabelle di contingenza: quando rappresentiamo una distribuzione di probabilità congiunta in una tabella, le probabilità marginali—che descrivono la distribuzione di una variabile indipendentemente dalle altre—si trovano nei margini della tabella (ovvero nelle righe e colonne finali).\n\n34.3.1 Formalizzazione della Marginalizzazione\nData una distribuzione di probabilità congiunta \\(P(X, Y)\\) di due variabili casuali \\(X\\) e \\(Y\\), possiamo ottenere la distribuzione marginale di \\(X\\) sommando tutte le probabilità associate a \\(Y\\). Formalmente:\n\\[\nP(X = x) = \\sum_y P(X = x, Y = y),\n\\]\ndove \\(P(X = x, Y = y)\\) rappresenta la probabilità congiunta di \\(X\\) e \\(Y\\). La marginalizzazione garantisce inoltre che le distribuzioni siano normalizzate, cioè che le somme delle probabilità marginali per ciascuna variabile siano uguali a 1:\n\\[\n\\sum_x P(X = x) = 1 \\quad \\text{e} \\quad \\sum_y P(Y = y) = 1.\n\\]\nNel caso di variabili continue, questa operazione di somma viene sostituita dall’integrazione.\nPer chiarire, consideriamo il seguente esempio. Supponiamo di studiare l’efficacia di una terapia cognitivo-comportamentale per l’ansia, includendo variabili come l’età dei partecipanti e il livello iniziale di ansia. Se vogliamo valutare l’efficacia della terapia a prescindere dall’età e dal livello di ansia iniziale, marginalizziamo rispetto a queste due variabili, ottenendo così una distribuzione che riflette solo l’associazione tra terapia e riduzione dell’ansia.\nIn sintesi, la marginalizzazione:\n\npermette di estrarre distribuzioni di probabilità per variabili specifiche, “dimenticando” quelle non rilevanti;\nconsiste nel sommare o integrare le probabilità attraverso tutte le possibili combinazioni delle variabili non rilevanti, concentrandosi su quelle di interesse.\n\nIn conclusione, la marginalizzazione è uno strumento essenziale per l’analisi statistica, facilitando lo studio delle relazioni tra variabili complesse e aiutandoci a isolare gli effetti delle variabili di interesse in modo rigoroso.\n\nEsempio 34.1 Per fare un esempio, prendiamo come riferimento l’esperimento del lancio di tre monete equilibrate descritto precedentemente. Per calcolare le probabilità marginali di \\(X\\) e \\(Y\\), sommiamo le probabilità congiunte su una dimensione. La probabilità marginale di \\(X\\), \\(P_X\\), si ottiene sommando le probabilità lungo le colonne per ciascun valore fisso di \\(X\\); analogamente, la probabilità marginale di \\(Y\\), \\(P_Y\\), si calcola sommando le probabilità lungo le righe per ciascun valore fisso di \\(Y\\).\nLa tabella seguente mostra la distribuzione di probabilità congiunta \\(P(X, Y)\\) e le probabilità marginali \\(P(X)\\) e \\(P(Y)\\):\n\n\n\\(x \\setminus y\\)\n0\n1\n\\(P(x)\\)\n\n\n\n0\n1/8\n0\n1/8\n\n\n1\n2/8\n1/8\n3/8\n\n\n2\n1/8\n2/8\n3/8\n\n\n3\n0\n1/8\n1/8\n\n\n\\(P(y)\\)\n4/8\n4/8\n1.0\n\n\n\n\n\n34.3.2 Marginalizzazione per Variabili Casuali Continue\nNell’ambito della statistica bayesiana, il concetto di marginalizzazione gioca un ruolo cruciale. Un esempio di equazione che emerge da questo processo è:\n\\[\np(y) = \\int_{\\theta} p(y, \\theta) \\, d\\theta = \\int_{\\theta} p(y \\mid \\theta) p(\\theta) \\, d\\theta,\n\\]\ndove \\(y\\) e \\(\\theta\\) sono variabili casuali continue, con \\(y\\) che rappresenta i dati osservati e \\(\\theta\\) i parametri di un modello statistico. Questa equazione illustra come, in un contesto continuo, la marginalizzazione possa essere vista come l’estensione dell’approccio discreto a un continuum di valori per le variabili in esame.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#indipendenza-tra-variabili-casuali",
    "href": "chapters/probability/09_joint_prob.html#indipendenza-tra-variabili-casuali",
    "title": "34  Probabilità congiunta",
    "section": "\n34.4 Indipendenza tra Variabili Casuali",
    "text": "34.4 Indipendenza tra Variabili Casuali\nL’indipendenza tra variabili casuali è un concetto fondamentale in statistica e probabilità, parallelo all’idea di indipendenza tra eventi. Due variabili casuali si considerano indipendenti quando l’informazione su una non altera in alcun modo la distribuzione di probabilità dell’altra. Questa sezione offre una formalizzazione dell’indipendenza tra due variabili casuali discrete, basata sulla loro distribuzione di probabilità congiunta.\n\n34.4.1 Definizione di Indipendenza\nDue variabili casuali \\(X\\) e \\(Y\\), con una distribuzione congiunta, sono definite indipendenti se, e solo se, per ogni coppia di valori \\((x, y)\\) si verifica che:\n\\[\nP_{X, Y}(x, y) = P_X(x) \\cdot P_Y(y).\n\\]\nIn termini pratici, ciò significa che se \\(X\\) e \\(Y\\) sono variabili casuali discrete indipendenti, la loro distribuzione di probabilità congiunta è il prodotto delle rispettive distribuzioni di probabilità marginali. Se invece \\(P_{X, Y}(x, y) \\neq P_X(x) \\cdot P_Y(y)\\), le variabili non sono indipendenti e si dicono associate o dipendenti.\nQuesto concetto si applica anche alle variabili casuali continue, mantenendo la stessa logica: l’indipendenza si verifica quando la funzione di densità congiunta è il prodotto delle funzioni di densità marginali.\n\n34.4.2 Associazione tra Variabili Casuali\nQuando due variabili casuali non sono indipendenti, si descrivono come associate o dipendenti. In questo contesto, è utile introdurre il concetto di covarianza (e correlazione) come misura del grado di associazione lineare tra due variabili casuali. La covarianza e la correlazione quantificano in che modo la variazione di una variabile è associata alla variazione dell’altra, fornendo un indice della loro interdipendenza lineare.\nRiepilogando, l’indipendenza tra variabili casuali è un concetto chiave per comprendere le relazioni tra fenomeni aleatori. Riconoscere se due variabili sono indipendenti o associate è fondamentale per l’analisi statistica e per la modellazione di relazioni causali o di correlazione tra variabili.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#covarianza",
    "href": "chapters/probability/09_joint_prob.html#covarianza",
    "title": "34  Probabilità congiunta",
    "section": "\n34.5 Covarianza",
    "text": "34.5 Covarianza\nLa covarianza è un parametro statistico che quantifica il grado e la direzione della relazione lineare tra due variabili casuali, \\(X\\) e \\(Y\\). In termini semplici, misura come le variazioni di una variabile si accompagnano a quelle dell’altra. Per esempio, considerando l’altezza e il peso di giraffe, scopriremmo che queste due misure tendono ad aumentare insieme, evidenziando così una covarianza positiva. La covarianza è denotata come \\(Cov(X, Y) = \\sigma_{xy}\\).\n\n34.5.1 Definizione di Covarianza\nLa covarianza tra due variabili casuali \\(X\\) e \\(Y\\) è definita come:\n\\[\nCov(X, Y) = \\mathbb{E}\\left[\\left(X - \\mathbb{E}[X]\\right) \\left(Y - \\mathbb{E}[Y]\\right)\\right],\n\\]\ndove \\(\\mathbb{E}[X]\\) e \\(\\mathbb{E}[Y]\\) rappresentano i valori attesi (o medie) di \\(X\\) ed \\(Y\\), rispettivamente.\nIn termini più espliciti, la covarianza può essere espressa come:\n\\[\nCov(X, Y) = \\sum_{(x, y) \\in \\Omega} (x - \\mu_X) (y - \\mu_Y) f(x, y),\n\\]\ndove \\(\\mu_X\\) e \\(\\mu_Y\\) sono le medie di \\(X\\) ed \\(Y\\), e \\(f(x, y)\\) è la funzione di probabilità congiunta delle variabili.\nQuesta definizione mostra una stretta analogia con la varianza, che è la covarianza di una variabile con se stessa:\n\\[\n\\mathbb{V}(X) = Cov(X, X).\n\\]\nInoltre, la covarianza può essere calcolata attraverso la relazione:\n\\[\nCov(X, Y) = \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y).\n\\]\n\n34.5.2 Dimostrazione\nLa formula alternativa per la covarianza si dimostra come segue:\n\\[\n\\begin{align}\nCov(X, Y) &= \\mathbb{E}\\left[\\left(X - \\mathbb{E}[X]\\right) \\left(Y - \\mathbb{E}[Y]\\right)\\right]\\\\\n&= \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y).\n\\end{align}\n\\]\n\n34.5.3 Esempio di Calcolo della Covarianza\nConsideriamo le variabili casuali \\(X\\) e \\(Y\\) con medie \\(\\mu_X = 1.5\\) e \\(\\mu_Y = 0.5\\). La covarianza di \\(X\\) e \\(Y\\) si calcola come:\n\\[\nCov(X, Y) = \\sum_{(x, y) \\in \\Omega} (x - \\mu_X) (y - \\mu_Y) f(x, y) = \\frac{1}{4}.\n\\]\nQuesto risultato si può ottenere anche dalla formula alternativa, calcolando prima \\(\\mathbb{E}(XY)\\):\n\\[\n\\mathbb{E}(XY) = 1.0.\n\\]\nAllora, la covarianza tra \\(X\\) e \\(Y\\) è:\n\\[\nCov(X, Y) = 1 - 1.5 \\cdot 0.5 = 0.25.\n\\]\n\nEsempio 34.2 Per calcolare la covarianza \\(Cov(X, Y)\\) in R, consideriamo l’esempio in cui \\(X\\) è il numero totale di teste che si ottiene dal lancio di tre monete equilibrate e \\(Y\\) è il risultato del primo lancio (testa = 1, croce = 0). Procediamo creando il prodotto cartesiano di tutti i possibili valori di \\(X\\) e \\(Y\\).\n\n# Creare il prodotto cartesiano di X (c3) e Y (c1)\nc3 &lt;- 0:3  # Numero totale di teste possibili\nc1 &lt;- 0:1  # Risultato del primo lancio (0 = croce, 1 = testa)\nsample &lt;- expand.grid(c1 = c1, c3 = c3)\nsample\n#&gt;   c1 c3\n#&gt; 1  0  0\n#&gt; 2  1  0\n#&gt; 3  0  1\n#&gt; 4  1  1\n#&gt; 5  0  2\n#&gt; 6  1  2\n#&gt; 7  0  3\n#&gt; 8  1  3\n\nIl primo numero di ogni coppia rappresenta il valore di \\(Y\\), mentre il secondo rappresenta il valore di \\(X\\). Tuttavia, queste coppie \\((X, Y)\\) non hanno tutte la stessa probabilità di verificarsi. La probabilità associata a ciascuna coppia è data dai seguenti valori: \\(1/8, 2/8, 1/8, 0, 0, 1/8, 2/8, 1/8\\). Questa è la distribuzione di massa di probabilità congiunta delle variabili casuali \\(X\\) e \\(Y\\). Applicando la formula per la covarianza:\n[ Cov(X, Y) = _{i=1}^n (X_i - E[X])(Y_i - E[Y]) P(X_i, Y_i) ]\nCalcoliamo la covarianza in R:\n\n# Probabilità di ogni coppia (X, Y)\npmf &lt;- c(1 / 8, 2 / 8, 1 / 8, 0, 0, 1 / 8, 2 / 8, 1 / 8)\n\n# Calcolo della covarianza\nres &lt;- c()\nfor (i in 1:nrow(sample)) {\n  res &lt;- c(res, (sample$c1[i] - 0.5) * (sample$c3[i] - 1.5) * pmf[i])\n}\n\n# Somma dei prodotti ponderati\ncovariance &lt;- sum(res)\ncovariance\n#&gt; [1] -0.125\n\nLa covarianza tra \\(X\\) e \\(Y\\) è dunque uguale a \\(-0.125\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#correlazione",
    "href": "chapters/probability/09_joint_prob.html#correlazione",
    "title": "34  Probabilità congiunta",
    "section": "\n34.6 Correlazione",
    "text": "34.6 Correlazione\nMentre la covarianza fornisce un’indicazione della tendenza di due variabili casuali a variare insieme, essa è influenzata dalle unità di misura delle variabili, rendendo difficile valutare l’intensità della loro relazione lineare. Per ovviare a questo, si utilizza la correlazione, che normalizza la covarianza attraverso le deviazioni standard delle variabili, offrendo così una misura standardizzata dell’associazione lineare tra di esse.\n\nDefinizione 34.1 Il coefficiente di correlazione tra due variabili casuali \\(X\\) e \\(Y\\), denotato come \\(\\rho(X,Y)\\) o \\(\\rho_{X,Y}\\), è definito come:\n\\[\n\\rho(X,Y) = \\frac{Cov(X,Y)}{\\sqrt{\\mathbb{V}(X)\\mathbb{V}(Y)}},\n\\]\ndove \\(\\mathbb{V}(X)\\) e \\(\\mathbb{V}(Y)\\) rappresentano le varianze di \\(X\\) e \\(Y\\), rispettivamente.\n\nIl coefficiente di correlazione \\(\\rho_{xy}\\) è un valore adimensionale, ovvero non dipende dalle unità di misura delle variabili, e varia nell’intervallo \\(-1 \\leq \\rho \\leq 1\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#proprietà-1",
    "href": "chapters/probability/09_joint_prob.html#proprietà-1",
    "title": "34  Probabilità congiunta",
    "section": "\n34.7 Proprietà",
    "text": "34.7 Proprietà\n\n\nCovarianza con una Costante: La covarianza tra una variabile aleatoria \\(X\\) e una costante \\(c\\) è sempre nulla: \\(Cov(c, X) = 0\\).\n\nSimmetria: La covarianza è simmetrica: \\(Cov(X,Y) = Cov(Y,X)\\).\n\nIntervallo di Correlazione: Il coefficiente di correlazione \\(\\rho\\) varia tra -1 e 1: \\(-1 \\leq \\rho(X,Y) \\leq 1\\).\n\nIndipendenza dalle Unità di Misura: La correlazione è indipendente dalle unità di misura: \\(\\rho(aX, bY) = \\rho(X,Y)\\) per ogni \\(a, b &gt; 0\\).\n\nRelazione Lineare Perfetta: Se \\(Y = a + bX\\) è una funzione lineare di \\(X\\), allora \\(\\rho(X,Y) = \\pm 1\\), a seconda del segno di \\(b\\).\n\nCovarianza e Costanti: La covarianza tra \\(X\\) e \\(Y\\), ciascuna moltiplicata per una costante, è \\(Cov(aX, bY) = ab \\, Cov(X,Y)\\).\n\nVarianza della Somma/Differenza: \\(\\mathbb{V}(X \\pm Y) = \\mathbb{V}(X) + \\mathbb{V}(Y) \\pm 2Cov(X,Y)\\).\n\nCovarianza e Somma di Variabili: \\(Cov(X + Y, Z) = Cov(X,Z) + Cov(Y,Z)\\).\n\nVarianza di una Somma di Variabili Aleatorie: Per variabili aleatorie \\(X_1, \\dots, X_n\\), si ha \\(\\mathbb{V}(\\sum_{i=1}^n X_i) = \\sum_{i=1}^n \\mathbb{V}(X_i) + 2\\sum_{i&lt;j} Cov(X_i, X_j)\\).\n\nCovarianza e Somme di Prodotti: \\(Cov(\\sum_{i=1}^n a_i X_i, \\sum_{j=1}^m b_j Y_j) = \\sum_{i=1}^n \\sum_{j=1}^m a_i b_j Cov(X_i, Y_j)\\).\n\nIndipendenza e Covarianza di Somme: Se \\(X_1, X_2, \\dots, X_n\\) sono indipendenti, allora \\(Cov(\\sum_{i=1}^n a_i X_i, \\sum_{j=1}^n b_j X_j) = \\sum_{i=1}^n a_i b_i \\mathbb{V}(X_i)\\).\n\n\n34.7.1 Incorrelazione\nDue variabili casuali \\(X\\) ed \\(Y\\) si dicono incorrelate, o linearmente indipendenti, se la loro covarianza è nulla:\n\\[\nCov(X,Y) = \\mathbb{E}[(X - \\mu_X)(Y - \\mu_Y)] = 0,\n\\]\nequivalente a dire che \\(\\rho_{XY} = 0\\) e \\(\\mathbb{E}(XY) = \\mathbb{E}(X)\\mathbb{E}(Y)\\).\nQuesta condizione indica una forma di indipendenza più debole rispetto all’indipendenza stocastica. Tuttavia, \\(Cov(X, Y) = 0\\) non implica necessariamente che \\(X\\) ed \\(Y\\) siano stocasticamente indipendenti.\n\nEsempio 34.3 Consideriamo una distribuzione di probabilità congiunta di due variabili aleatorie, \\(X\\) e \\(Y\\), definita come:\n\\[\nf_{XY}(x,y) = \\left\\{\n\\begin{array}{ll}\n\\frac{1}{4} & \\text{per } (x,y) \\in \\{(0,0), (1,1), (1, -1), (2,0) \\}, \\\\\n0 & \\text{altrimenti.}\n\\end{array}\n\\right.\n\\]\nQuesto implica che le variabili aleatorie \\(X\\) e \\(Y\\) assumono valori specifici con probabilità uniforme solo per determinate coppie \\((x, y)\\) e zero in tutti gli altri casi.\nDistribuzioni Marginali\nLa distribuzione marginale di \\(X\\) si ottiene sommando le probabilità congiunte su tutti i possibili valori di \\(Y\\), e viceversa per \\(Y\\). Le distribuzioni marginali risultano essere:\n\n\nPer \\(X\\):\n\\[\nf_X(x) = \\left\\{\n\\begin{array}{ll}\n\\frac{1}{4} & \\text{per } x=0, \\\\\n\\frac{1}{2} & \\text{per } x=1, \\\\\n\\frac{1}{4} & \\text{per } x=2.\n\\end{array}\n\\right.\n\\]\n\n\nPer \\(Y\\):\n\\[\nf_Y(y) = \\left\\{\n\\begin{array}{ll}\n\\frac{1}{4} & \\text{per } y=-1, \\\\\n\\frac{1}{2} & \\text{per } y=0, \\\\\n\\frac{1}{4} & \\text{per } y=1.\n\\end{array}\n\\right.\n\\]\n\n\nMedie e Varianze\nCalcoliamo ora le medie e le varianze di \\(X\\) e \\(Y\\):\n\n\nMedia di \\(X\\):\n\\[\n\\mathbb{E}(X) = 0 \\cdot \\frac{1}{4} + 1 \\cdot \\frac{1}{2} + 2 \\cdot \\frac{1}{4} = 1.\n\\]\n\n\nVarianza di \\(X\\):\n\\[\n\\mathbb{V}(X) = \\left(0^2 \\cdot \\frac{1}{4} + 1^2 \\cdot \\frac{1}{2} + 2^2 \\cdot \\frac{1}{4}\\right) - \\mathbb{E}(X)^2 = \\frac{3}{2} - 1 = \\frac{1}{2}.\n\\]\n\n\nMedia di \\(Y\\):\n\\[\n\\mathbb{E}(Y) = (-1) \\cdot \\frac{1}{4} + 0 \\cdot \\frac{1}{2} + 1 \\cdot \\frac{1}{4} = 0.\n\\]\n\n\nVarianza di \\(Y\\):\n\\[\n\\mathbb{V}(Y) = \\left((-1)^2 \\cdot \\frac{1}{4} + 0^2 \\cdot \\frac{1}{2} + 1^2 \\cdot \\frac{1}{4}\\right) - \\mathbb{E}(Y)^2 = \\frac{1}{2}.\n\\]\n\n\nCovarianza tra X e Y\nLa covarianza si calcola come:\n\\[\nCov(X,Y) = \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y),\n\\]\ndove \\(\\mathbb{E}(XY)\\) si trova sommando il prodotto delle coppie di valori \\((x, y)\\) per la loro probabilità congiunta:\n\\[\n\\mathbb{E}(XY) = 0.\n\\]\nDi conseguenza, la covarianza tra \\(X\\) e \\(Y\\) è zero:\n\\[\nCov(X,Y) = 0 - 1 \\cdot 0 = 0.\n\\]\nConclusioni\nSebbene \\(X\\) e \\(Y\\) siano incorrelate (covarianza nulla), ciò non implica la loro indipendenza. L’indipendenza richiede che la funzione di probabilità congiunta si possa esprimere come il prodotto delle funzioni di probabilità marginali per ogni \\(x\\) e \\(y\\), condizione che non si verifica in questo caso. Quindi, nonostante l’assenza di correlazione, \\(X\\) e \\(Y\\) non sono indipendenti, dimostrando che l’incorrelazione non garantisce l’indipendenza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#variabili-continue",
    "href": "chapters/probability/09_joint_prob.html#variabili-continue",
    "title": "34  Probabilità congiunta",
    "section": "\n34.8 Variabili continue",
    "text": "34.8 Variabili continue\nConsideriamo ora le distribuzioni di densità. Nella figura successiva, tratta da Martin (2024), vediamo una rappresentazione della relazione tra la probabilità congiunta \\(p(A,B)\\), le probabilità marginali \\(p(A)\\) e \\(p(B)\\), e le probabilità condizionali \\(p(A \\mid B)\\).\n\n\nDistribuzioni di densità (figura tratta da Martin (2024)).\n\n\nProbabilità congiunta \\(p(A,B)\\): rappresenta la probabilità che A e B assumano certi valori contemporaneamente. Per le variabili continue, questa è data dall’integrazione della funzione di densità congiunta su un’area o volume di interesse.\nProbabilità marginale \\(p(A)\\) e \\(p(B)\\): è la probabilità di osservare un particolare valore di A (o B) indipendentemente dal valore di B (o A). Si ottiene integrando la funzione di densità congiunta sull’intero intervallo di valori dell’altra variabile.\nProbabilità condizionale \\(p(A \\mid B)\\): esprime la probabilità di A dato B. Si calcola dividendo la probabilità congiunta per la probabilità marginale di B, applicando la definizione di probabilità condizionale anche nel contesto continuo.\n\nLa transizione dal trattamento delle variabili discrete a quello delle variabili continue richiede un cambiamento di strumenti matematici da somme ad integrali, ma i concetti fondamentali di probabilità congiunta, marginale e condizionale rimangono applicabili.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#riflessioni-conclusive",
    "href": "chapters/probability/09_joint_prob.html#riflessioni-conclusive",
    "title": "34  Probabilità congiunta",
    "section": "\n34.9 Riflessioni Conclusive",
    "text": "34.9 Riflessioni Conclusive\nIn alcune situazioni, ogni singolo elemento di una popolazione può essere associato a diverse variabili casuali. Ad esempio, consideriamo l’elenco di tutti gli studenti iscritti a un’università e immaginiamo di selezionare uno studente a caso per misurare la sua altezza e il suo peso. In questo caso, ogni individuo della popolazione è associato a due variabili casuali, l’altezza e il peso. Quando si hanno due o più variabili casuali associate ad ogni elemento di una popolazione, è possibile studiare la distribuzione congiunta di tali variabili casuali. In questo capitolo abbiamo esaminato come rappresentare la distribuzione di massa di probabilità congiunta di due variabili casuali discrete e come ottenere le distribuzioni marginali delle due variabili. Inoltre, abbiamo discusso i concetti di incorrelazione e indipendenza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/09_joint_prob.html#informazioni-sullambiente-di-sviluppo",
    "title": "34  Probabilità congiunta",
    "section": "\n34.10 Informazioni sull’Ambiente di Sviluppo",
    "text": "34.10 Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.17.0      see_0.9.0        gridExtra_2.3    patchwork_1.3.0 \n#&gt;  [5] bayesplot_1.11.1 psych_2.4.12     scales_1.3.0     markdown_1.13   \n#&gt;  [9] knitr_1.49       lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1   \n#&gt; [13] dplyr_1.1.4      purrr_1.0.2      readr_2.1.5      tidyr_1.3.1     \n#&gt; [17] tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3       \n#&gt; [21] here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      shape_1.4.6.1     xfun_0.49         htmlwidgets_1.6.4\n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2      \n#&gt;  [9] generics_0.1.3    parallel_4.4.2    pan_1.9           pacman_0.5.1     \n#&gt; [13] pkgconfig_2.0.3   jomo_2.7-6        Matrix_1.7-1      lifecycle_1.0.4  \n#&gt; [17] compiler_4.4.2    farver_2.1.2      munsell_0.5.1     mnormt_2.1.1     \n#&gt; [21] codetools_0.2-20  htmltools_0.5.8.1 yaml_2.3.10       glmnet_4.1-8     \n#&gt; [25] nloptr_2.1.1      pillar_1.10.0     MASS_7.3-61       iterators_1.0.14 \n#&gt; [29] rpart_4.1.23      boot_1.3-31       foreach_1.5.2     mitml_0.4-5      \n#&gt; [33] nlme_3.1-166      tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4    \n#&gt; [37] splines_4.4.2     rprojroot_2.0.4   fastmap_1.2.0     grid_4.4.2       \n#&gt; [41] colorspace_2.1-1  cli_3.6.3         magrittr_2.0.3    survival_3.8-3   \n#&gt; [45] broom_1.0.7       withr_3.0.2       backports_1.5.0   timechange_0.3.0 \n#&gt; [49] rmarkdown_2.29    nnet_7.3-19       lme4_1.1-35.5     hms_1.1.3        \n#&gt; [53] evaluate_1.0.1    rlang_1.1.4       Rcpp_1.0.13-1     glue_1.8.0       \n#&gt; [57] minqa_1.2.8       jsonlite_1.8.9    R6_2.5.1",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#bibliografia",
    "href": "chapters/probability/09_joint_prob.html#bibliografia",
    "title": "34  Probabilità congiunta",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nMartin, O. (2024). Bayesian analysis with python. Packt Publishing Ltd.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_prob_distributions.html",
    "href": "chapters/probability/10_prob_distributions.html",
    "title": "35  Distribuzioni di massa e di densità",
    "section": "",
    "text": "35.1 Introduzione\nLa data science mira a comprendere e prevedere fenomeni, compresi quelli futuri, mediante l’impiego di modelli probabilistici e dati empirici. Tale capacità predittiva si fonda sulla conoscenza approfondita della popolazione di riferimento, senza la necessità di esaminare ogni singolo risultato possibile. In statistica, questa conoscenza viene formalizzata attraverso le distribuzioni di probabilità, uno strumento essenziale per analizzare e modellare i dati.\nUna distribuzione di probabilità, indicata formalmente come \\(p(x)\\), è associata a una variabile casuale \\(X\\) e descrive la variabilità osservabile in una popolazione. Essa fornisce un modello teorico per quantificare la probabilità di osservare ciascun valore possibile di \\(X\\), permettendo di caratterizzare l’incertezza legata al fenomeno in analisi.\nAd esempio, se si seleziona casualmente un’osservazione dalla popolazione, la distribuzione \\(p(x)\\) indica la probabilità che la variabile casuale \\(X\\) assuma un determinato valore. In tal modo, la distribuzione riassume matematicamente le informazioni sulle frequenze o probabilità associate ai possibili esiti, offrendo un quadro generalizzabile del fenomeno studiato.\nTuttavia, è fondamentale sottolineare che \\(p(x)\\) non rappresenta la popolazione reale nella sua interezza, ma costituisce un modello statistico, ovvero una rappresentazione semplificata della realtà. Questo modello consente di generalizzare le osservazioni disponibili e di formulare previsioni su eventi futuri con un approccio rigoroso. La distribuzione di probabilità non mira a catturare ogni dettaglio, ma piuttosto a fornire una descrizione essenziale e funzionale del fenomeno.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Distribuzioni di massa e di densità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_prob_distributions.html#variabili-casuali-discrete-e-continue",
    "href": "chapters/probability/10_prob_distributions.html#variabili-casuali-discrete-e-continue",
    "title": "35  Distribuzioni di massa e di densità",
    "section": "\n35.2 Variabili Casuali Discrete e Continue",
    "text": "35.2 Variabili Casuali Discrete e Continue\nUn elemento fondamentale nella comprensione delle distribuzioni di probabilità è la distinzione tra variabili casuali discrete e continue, poiché le distribuzioni associate differiscono significativamente.\n\n35.2.1 Distribuzioni di Massa di Probabilità (Discrete)\nLe distribuzioni di probabilità discrete descrivono fenomeni aleatori che generano un numero finito o numerabile di esiti possibili. Queste distribuzioni sono particolarmente utili per modellare eventi che si verificano in contesti discreti, come il numero di successi in un esperimento o la selezione casuale da un insieme di opzioni finite.\nIn una distribuzione di massa di probabilità, a ciascun valore di una variabile casuale discreta \\(X\\) è associata una probabilità ben definita. Ad esempio, consideriamo un dado sbilanciato con la seguente distribuzione di probabilità:\n\n\nValore di \\(X\\)\n\nProbabilità \\(p(x)\\)\n\n\n\n\n1\n0.10\n\n\n2\n0.15\n\n\n3\n0.20\n\n\n4\n0.25\n\n\n5\n0.20\n\n\n6\n0.10\n\n\n\nPossiamo rappresentare questa distribuzione empiricamente generando 1000 lanci del dado e creando un diagramma a barre, in cui l’altezza di ciascuna barra rappresenta la frequenza relativa osservata. In R:\n\n# Dati\nset.seed(123)\nprob &lt;- c(0.10, 0.15, 0.20, 0.25, 0.20, 0.10)\nlanci &lt;- sample(1:6, size = 1000, replace = TRUE, prob = prob)\n\n# Creazione di un data frame\ndf &lt;- data.frame(Valore = factor(lanci))\n\n# Creazione del diagramma a barre\nggplot(df, aes(x = Valore)) +\n  geom_bar(aes(y = after_stat(count) / sum(after_stat(count))), fill = \"skyblue\") +\n  labs(\n    title = \"Distribuzione empirica dei lanci\",\n    x = \"Valore\",\n    y = \"Frequenza relativa\"\n  )\n\n\n\n\n\n\n\nCon un numero infinito di osservazioni, la distribuzione empirica si avvicinerebbe alla distribuzione di massa di probabilità teorica.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Distribuzioni di massa e di densità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_prob_distributions.html#distribuzioni-di-densità-di-probabilità-continue",
    "href": "chapters/probability/10_prob_distributions.html#distribuzioni-di-densità-di-probabilità-continue",
    "title": "35  Distribuzioni di massa e di densità",
    "section": "\n35.3 Distribuzioni di Densità di Probabilità (Continue)",
    "text": "35.3 Distribuzioni di Densità di Probabilità (Continue)\nLe densità di probabilità descrivono variabili casuali continue, cioè variabili che possono assumere un numero infinito di valori all’interno di un intervallo. A differenza delle distribuzioni discrete, dove una funzione di massa di probabilità fornisce la probabilità esatta di ogni valore discreto, una densità di probabilità \\(f(x)\\) rappresenta la probabilità che la variabile casuale assuma valori in un dato intervallo. La probabilità per un intervallo \\([a, b]\\) è data dall’area sotto la curva di densità tra \\(a\\) e \\(b\\):\n\\[\nP(a \\leq X \\leq b) = \\int_a^b f(x) \\, dx.\n\\]\n\n35.3.1 Esempio pratico: quoziente intellettivo (QI)\nConsideriamo una variabile casuale che rappresenta il quoziente intellettivo (QI) in una popolazione. I valori di QI sono tipicamente distribuiti secondo una distribuzione normale, con una media di \\(100\\) e una deviazione standard di \\(15\\). Possiamo approssimare la densità teorica attraverso un istogramma dei dati simulati.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Distribuzioni di massa e di densità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_prob_distributions.html#dagli-istogrammi-alle-densità",
    "href": "chapters/probability/10_prob_distributions.html#dagli-istogrammi-alle-densità",
    "title": "35  Distribuzioni di massa e di densità",
    "section": "\n35.4 Dagli istogrammi alle densità",
    "text": "35.4 Dagli istogrammi alle densità\nUn istogramma divide i dati in intervalli (o “classi”) di ampiezza \\(\\Delta\\) e rappresenta graficamente le frequenze relative dei valori in ciascun intervallo. L’area di ogni barra è proporzionale alla frequenza relativa, mentre la sua altezza è proporzionale alla densità relativa. Con un numero crescente di osservazioni \\(M\\) e una larghezza degli intervalli \\(\\Delta \\to 0\\), il profilo dell’istogramma tende a una curva continua, detta funzione di densità di probabilità \\(f(x)\\).\nAd esempio, nella statistica descrittiva, abbiamo già incontrato rappresentazioni simili alla densità di probabilità, come il kernel density plot (KDE). Questo metodo non parametrico stima la funzione di densità a partire dai dati osservati.\n\n\n35.4.1 Simulazione: distribuzione del QI\n\n35.4.1.1 Caso 1: campione piccolo\nIniziamo simulando un campione di 50 individui. Creiamo un istogramma e lo confrontiamo con la densità teorica stimata.\n\n# Parametri della distribuzione normale\nmu &lt;- 100\nsigma &lt;- 15\nsize &lt;- 50\n\n# Generare i dati\nset.seed(123)\nx &lt;- rnorm(size, mean = mu, sd = sigma)\n\n# Istogramma e densità\ndata_frame &lt;- data.frame(X = x)\nxmin &lt;- min(x)\nxmax &lt;- max(x)\ndensity_data &lt;- data.frame(\n  X = seq(xmin, xmax, length.out = 100),\n  Density = dnorm(seq(xmin, xmax, length.out = 100), mean = mu, sd = sigma)\n)\n\nggplot(data_frame, aes(x = X)) +\n  geom_histogram(\n    aes(y = after_stat(density)), # Uso di after_stat() al posto di ..density..\n    bins = 25,\n    fill = \"blue\",\n    alpha = 0.6\n  ) +\n  geom_line(\n    data = density_data,\n    aes(x = X, y = Density),\n    color = \"black\",\n    size = 1\n  ) +\n  labs(\n    title = \"Distribuzione del QI (50 osservazioni)\",\n    x = \"Valori del QI\",\n    y = \"Densità\"\n  ) \n#&gt; Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#&gt; ℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\nCon un campione di piccole dimensioni, l’istogramma non corrisponde perfettamente alla densità teorica. L’approssimazione migliora aumentando il numero di osservazioni.\n\n35.4.1.2 Caso 2: campione grande\nRipetiamo la simulazione con 20.000 individui per osservare una maggiore corrispondenza tra istogramma e densità teorica.\n\n# Generare un campione più grande\nsize &lt;- 20000\nset.seed(123)\nx &lt;- rnorm(size, mean = mu, sd = sigma)\n\n# Aggiornare media e deviazione standard\nmu &lt;- mean(x)\nsigma &lt;- sd(x)\n\n# Creare il grafico\ndata_frame &lt;- data.frame(X = x)\nxmin &lt;- min(x)\nxmax &lt;- max(x)\ndensity_data &lt;- data.frame(\n  X = seq(xmin, xmax, length.out = 100),\n  Density = dnorm(seq(xmin, xmax, length.out = 100), mean = mu, sd = sigma)\n)\n\nggplot(data_frame, aes(x = X)) +\n  geom_histogram(\n    aes(y = after_stat(density)), # Uso di after_stat() al posto di ..density..\n    bins = 25,\n    fill = \"blue\",\n    alpha = 0.6\n  ) +\n  geom_line(\n    data = density_data,\n    aes(x = X, y = Density),\n    color = \"black\",\n    size = 1\n  ) +\n  labs(\n    title = sprintf(\"Distribuzione del QI (%d osservazioni)\", size),\n    x = \"Valori del QI\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\nCon un campione di grandi dimensioni, l’istogramma riflette molto meglio la densità teorica. La funzione di densità rappresenta quindi un’astrazione continua dell’istogramma.\n\n35.4.2 Interpretazione della funzione di densità\nLa funzione di densità è una curva che approssima il profilo di un istogramma quando:\n\n\nIl numero di osservazioni tende a infinito: le frequenze relative si avvicinano alle probabilità teoriche.\n\nGli intervalli sono infinitamente piccoli: il profilo dell’istogramma diventa continuo.\n\nIn un istogramma, l’area di ciascuna barra rappresenta la probabilità stimata che la variabile casuale assuma un valore compreso in quell’intervallo. Analogamente, nella densità di probabilità, l’area sotto la curva per un intervallo \\([a, b]\\) rappresenta la probabilità di osservare un valore in quell’intervallo.\nIn conclusione, la funzione di densità di probabilità è uno strumento fondamentale per modellare fenomeni reali. Consente di passare da una rappresentazione discreta (istogramma) a una continua, rendendo possibile l’analisi di variabili casuali continue con maggiore precisione e flessibilità.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Distribuzioni di massa e di densità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_prob_distributions.html#parametri",
    "href": "chapters/probability/10_prob_distributions.html#parametri",
    "title": "35  Distribuzioni di massa e di densità",
    "section": "\n35.5 Parametri",
    "text": "35.5 Parametri\nLe distribuzioni di probabilità, siano esse discrete o continue, sono definite da uno o più parametri, che ne determinano le proprietà fondamentali e permettono di modellare in modo preciso fenomeni reali. I parametri rappresentano valori numerici che influenzano il comportamento della distribuzione, come la posizione, la dispersione, la forma e altre caratteristiche specifiche.\nI parametri delle distribuzioni sono utilizzati per descrivere proprietà essenziali della variabile casuale, consentendo di adattare il modello probabilistico al fenomeno in analisi. Ecco alcune delle proprietà principali influenzate dai parametri:\n\n\nPosizione (o tendenza centrale): Indica il valore attorno al quale si concentra la distribuzione. Ad esempio, nella distribuzione normale, la media (\\(\\mu\\)) rappresenta il centro della distribuzione.\n\nDispersione: Misura quanto i valori della distribuzione si allontanano dalla posizione centrale. Ad esempio, nella distribuzione normale, la deviazione standard (\\(\\sigma\\)) controlla la larghezza della curva.\n\nForma: Determina l’asimmetria o la curtosi della distribuzione. Alcune distribuzioni, come quella gamma o beta, hanno parametri specifici per regolare la forma.\n\nProbabilità specifiche: Nelle distribuzioni discrete, i parametri possono determinare la probabilità di specifici eventi. Ad esempio, nella distribuzione binomiale, il parametro \\(p\\) rappresenta la probabilità di successo in ciascun tentativo.\n\nLa capacità di manipolare i parametri consente di adattare la distribuzione a diversi contesti e di catturare meglio le caratteristiche dei dati reali. Nella pratica, stimare accuratamente i parametri di una distribuzione è essenziale per comprendere e modellare i fenomeni studiati, nonché per formulare previsioni affidabili. Questi parametri sono spesso stimati a partire dai dati osservati mediante metodi statistici come la massima verosimiglianza o i metodi bayesiani.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Distribuzioni di massa e di densità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_prob_distributions.html#il-paradosso-delle-variabili-casuali-continue",
    "href": "chapters/probability/10_prob_distributions.html#il-paradosso-delle-variabili-casuali-continue",
    "title": "35  Distribuzioni di massa e di densità",
    "section": "\n35.6 Il Paradosso delle Variabili Casuali Continue",
    "text": "35.6 Il Paradosso delle Variabili Casuali Continue\nConsideriamo la probabilità che una variabile casuale continua assuma un valore specifico, come ad esempio un QI esattamente uguale a 100. Intuitivamente, potremmo pensare che sia possibile calcolare questa probabilità. Tuttavia, sorprendentemente, la risposta è:\n\\[\nP(X = 100) = 0.\n\\]\nQuesto risultato deriva dal fatto che, per una variabile casuale continua, la probabilità di un singolo valore è sempre pari a zero. Se così non fosse, ogni possibile valore all’interno del dominio della variabile dovrebbe avere una probabilità positiva. Ma se sommiamo tutte queste probabilità, il totale sarebbe maggiore di uno, il che è impossibile, dato che la somma delle probabilità per una variabile casuale deve essere esattamente uno.\n\n\n35.6.1 L’Interpretazione delle Probabilità per Variabili Continue\nNel caso delle variabili casuali continue, rinunciamo al concetto di probabilità associata a un singolo valore. Invece, consideriamo la probabilità di osservare un valore all’interno di un intervallo. Ad esempio, la probabilità che il QI sia compreso tra 95 e 105 si calcola come:\n\\[\nP(95 \\leq X \\leq 105) = \\int_{95}^{105} f(x) \\, dx,\n\\]\ndove \\(f(x)\\) è la funzione di densità di probabilità (PDF). La probabilità per un valore esatto, come \\(P(X = 100)\\), corrisponde all’area sotto la curva di densità in un singolo punto, che è sempre zero.\nQuesta caratteristica introduce due conseguenze fondamentali:\n\n\nLe probabilità si calcolano solo per intervalli di valori, non per punti specifici.\n\nEventi con probabilità zero non sono impossibili: il fatto che un evento abbia probabilità zero non implica che non possa verificarsi.\n\n35.6.2 Il Paradosso della Probabilità Zero\nDa questa concezione emerge un apparente paradosso: se la probabilità che il QI sia esattamente 100 è zero, come possiamo osservare un valore specifico nella realtà? Questo problema ci conduce a due domande cruciali:\n\nÈ possibile confrontare le “possibilità” di eventi diversi che hanno tutti probabilità zero?\nCome può l’unione di infiniti eventi con probabilità zero (ogni valore specifico in un intervallo) risultare in un evento con probabilità certa (qualsiasi valore nell’intervallo)?\n\n35.6.3 Un’Analogia: Il Paradosso di Zenone\nQuesto paradosso richiama il celebre paradosso di Zenone sulla freccia: se in ogni istante la freccia è ferma, come può essa muoversi? In entrambi i casi, affrontiamo un’apparente contraddizione: come può la somma di infiniti “nulla” (probabilità zero o stati di immobilità) dare origine a “qualcosa” (probabilità certa o movimento)?\nLa soluzione risiede nella teoria dell’integrazione. La somma degli infiniti contributi infinitesimali di probabilità lungo un intervallo non è “nulla”, ma costituisce l’area totale sotto la curva di densità, che rappresenta una probabilità positiva.\n\n35.6.4 La Prospettiva degli Infinitesimi\nNegli anni ’60, il matematico Abraham Robinson introdusse una teoria rigorosa degli infinitesimi, numeri infinitamente piccoli ma non nulli. Applicando questa idea alle variabili casuali continue, possiamo reinterpretare il concetto di probabilità zero:\n\nLa probabilità di un singolo valore non è realmente zero, ma infinitesimale.\nL’unione di infiniti eventi con probabilità infinitesimale risulta in una probabilità finita e positiva, come accade per un intervallo.\n\nQuesta prospettiva consente di confrontare eventi che la teoria classica assegna a probabilità zero, distinguendoli in base alla loro “grandezza infinitesimale”.\nIn conclusione, il “paradosso della probabilità zero” non è un vero paradosso, ma piuttosto un limite delle nostre intuizioni quando affrontiamo concetti continui. La teoria moderna degli infinitesimi e l’analisi matematica ci forniscono strumenti potenti per risolvere queste apparenti contraddizioni. Comprendendo che la probabilità è distribuita in modo continuo lungo un intervallo, possiamo superare la difficoltà concettuale di assegnare probabilità a eventi infinitamente piccoli, pur mantenendo coerenza con i principi fondamentali della teoria della probabilità.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Distribuzioni di massa e di densità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_prob_distributions.html#la-funzione-di-ripartizione-per-una-variabile-casuale-continua",
    "href": "chapters/probability/10_prob_distributions.html#la-funzione-di-ripartizione-per-una-variabile-casuale-continua",
    "title": "35  Distribuzioni di massa e di densità",
    "section": "\n35.7 La funzione di ripartizione per una variabile casuale continua",
    "text": "35.7 La funzione di ripartizione per una variabile casuale continua\nPer le variabili casuali continue, la funzione di ripartizione (ovvero, la distribuzione cumulativa) è definita esattamente come nel caso delle variabili casuali discrete:\n\\[\nF_{\\Theta}(\\theta) = P(\\Theta \\leq \\theta).\n\\]\nCioè, è la probabilità che la variabile casuale \\(\\Theta\\) assuma un valore minore di o uguale a \\(\\theta\\).\nCome nel caso discreto, la funzione di ripartizione di una v.c. continua può essere utilizzata per calcolare la probabilità che la v.c. assuma valori in un certo intervallo.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Distribuzioni di massa e di densità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_prob_distributions.html#interpretazioni-bayesiana-e-frequentista-della-funzione-di-densità-di-probabilità-pdf",
    "href": "chapters/probability/10_prob_distributions.html#interpretazioni-bayesiana-e-frequentista-della-funzione-di-densità-di-probabilità-pdf",
    "title": "35  Distribuzioni di massa e di densità",
    "section": "\n35.8 Interpretazioni Bayesiana e Frequentista della Funzione di Densità di Probabilità (PDF)",
    "text": "35.8 Interpretazioni Bayesiana e Frequentista della Funzione di Densità di Probabilità (PDF)\nIn questo capitolo, abbiamo introdotto la funzione di densità di probabilità come limite del profilo di un istogramma, una descrizione intuitiva e utile per comprendere il concetto di densità. Questa interpretazione corrisponde, tuttavia, alla visione frequentista della densità di probabilità. Nella statistica Bayesiana, l’interpretazione è diversa e merita una spiegazione separata.\nNell’approccio Bayesiano, un parametro è considerato una “variabile casuale” che segue una distribuzione di valori, anziché un valore fisso. La Figura 35.1, vedi 35.1 illustra le diverse interpretazioni di una PDF per una quantità reale \\(x\\). Queste interpretazioni valgono sia che \\(x\\) rappresenti un parametro incognito sia che si tratti di un dato osservato.\nNel pannello di sinistra, vediamo l’interpretazione frequentista di \\(p(x)\\): la PDF rappresenta una collezione ipotetica di ripetizioni di esperimenti, in cui \\(x\\) può assumere diversi valori. La PDF corrisponde quindi a un istogramma limite di questi valori, distribuiti secondo \\(p(x)\\).\nIl pannello di destra, invece, raffigura l’interpretazione Bayesiana, in cui la PDF rappresenta l’incertezza sul valore di \\(x\\) per un singolo caso specifico. In questo caso, la probabilità si distribuisce lungo i possibili valori che \\(x\\) potrebbe assumere, visualizzata dalla sfumatura lungo l’asse \\(x\\).\nIn altre parole, nell’interpretazione frequentista, è il valore di \\(x\\) a essere distribuito in \\(p(x)\\) (attraverso ripetizioni dell’esperimento), mentre nell’interpretazione Bayesiana è la probabilità stessa a distribuirsi sui possibili valori di \\(x\\) nel caso analizzato. Una PDF Bayesiana può essere vista come analoga a una densità di materia \\(\\rho(x)\\) in meccanica classica: è la probabilità che si distribuisce lungo i possibili valori, e non i valori stessi di \\(x\\).\n\n\n\n\n\nFigura 35.1: Interpretazioni frequentista e bayesiana di una PDF (curva blu) per una quantità reale \\(x\\). A sinistra: interpretazione frequentista come istogramma limite dei valori di \\(x\\) nelle ripetizioni; i valori di \\(x\\) sono distribuiti secondo la PDF. A destra: interpretazione bayesiana, con \\(x\\) che assume un valore fisso ma incerto per il caso specifico (rappresentato dal punto sull’asse \\(x\\)), con la probabilità distribuita sui valori possibili (raffigurata con una sfumatura lungo l’asse \\(x\\)). (Figura tratta da Loredo & Wolpert, 2024)",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Distribuzioni di massa e di densità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_prob_distributions.html#riflessioni-conclusive",
    "href": "chapters/probability/10_prob_distributions.html#riflessioni-conclusive",
    "title": "35  Distribuzioni di massa e di densità",
    "section": "\n35.9 Riflessioni Conclusive",
    "text": "35.9 Riflessioni Conclusive\nLa funzione di densità di probabilità (PDF) è un concetto centrale nella descrizione di variabili casuali continue, permettendo di calcolare le probabilità come aree sotto una curva in intervalli specifici. Questo approccio sostituisce l’idea di assegnare probabilità a singoli valori, un’operazione impossibile nel contesto continuo.\nUn risultato fondamentale della PDF è che la probabilità di osservare un valore esatto è pari a zero. Questo non implica l’impossibilità dell’evento, ma riflette la struttura continua della distribuzione: l’intervallo, per quanto piccolo, è sempre necessario per assegnare una probabilità positiva. Ad esempio, possiamo calcolare la probabilità che una variabile sia compresa tra 95 e 105, ma non esattamente uguale a 100.\n\n35.9.1 Implicazioni e Interpretazioni\n\n\nProbabilità per intervalli: La PDF permette di quantificare la probabilità in termini di intervalli, superando i limiti del calcolo sui singoli valori.\n\nApparenti paradossi: L’apparente paradosso della probabilità zero – come l’unione di infiniti punti con probabilità zero possa generare un evento certo – viene risolto comprendendo che tali probabilità si riferiscono alla somma delle aree infinitesimali sotto la curva.\n\n35.9.2 Riflessione Filosofica: Dal “Nulla” al “Qualcosa”\nIl problema della probabilità zero ricorda il paradosso di Zenone sulla freccia: se la freccia è ferma in ogni istante, come può muoversi? Allo stesso modo, la somma di infiniti punti con probabilità zero può produrre una probabilità totale positiva. La soluzione risiede nella teoria dell’integrazione: la somma di contributi infinitesimali lungo un intervallo costruisce la probabilità complessiva.\n\n35.9.3 Nuove Prospettive: Gli Infinitesimi\nUna visione alternativa è offerta dalla teoria degli infinitesimi di Abraham Robinson, che reinterpreta gli eventi con probabilità zero come aventi una probabilità infinitesimale, non nulla. Questa teoria distingue tra eventi con diversa “grandezza infinitesimale” e chiarisce come l’unione di infiniti eventi infinitesimali possa produrre una probabilità totale unitaria.\n\n35.9.4 Conclusione\nLa PDF non è solo uno strumento matematico, ma anche un ponte concettuale che collega il finito all’infinito e il discreto al continuo. Comprendere questi concetti aiuta non solo a risolvere problemi tecnici, ma anche a sviluppare un’intuizione più profonda sulle strutture sottostanti alla probabilità e alla matematica continua.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Distribuzioni di massa e di densità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_prob_distributions.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/10_prob_distributions.html#informazioni-sullambiente-di-sviluppo",
    "title": "35  Distribuzioni di massa e di densità",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] see_0.9.0        gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1\n#&gt;  [5] psych_2.4.12     scales_1.3.0     markdown_1.13    knitr_1.49      \n#&gt;  [9] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [13] purrr_1.0.2      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [17] ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.3         rlang_1.1.4       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       yaml_2.3.10       tools_4.4.2       parallel_4.4.2   \n#&gt; [21] tzdb_0.4.0        colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5      \n#&gt; [25] R6_2.5.1          lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3  \n#&gt; [29] pillar_1.10.0     gtable_0.3.6      glue_1.8.0        xfun_0.49        \n#&gt; [33] tidyselect_1.2.1  farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-166     \n#&gt; [37] labeling_0.4.3    rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Distribuzioni di massa e di densità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_prob_distributions.html#bibliografia",
    "href": "chapters/probability/10_prob_distributions.html#bibliografia",
    "title": "35  Distribuzioni di massa e di densità",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlitzstein, J. K., & Hwang, J. (2019). Introduction to probability. CRC Press.\n\n\nLoredo, T. J., & Wolpert, R. L. (2024). Bayesian inference: more than Bayes’s theorem. Frontiers in Astronomy and Space Sciences, 11, 1326926.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Distribuzioni di massa e di densità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html",
    "href": "chapters/probability/11_discr_rv_distr.html",
    "title": "36  Distribuzioni di v.c. discrete",
    "section": "",
    "text": "36.1 Introduzione\nÈ importante distinguere tra variabili casuali discrete e continue, perché le distribuzioni di probabilità associate sono molto diverse nei due casi.\nIn questo capitolo ci focalizzeremo sulle distribuzioni di probabilità discrete, strumenti fondamentali per modellare fenomeni aleatori che generano un numero finito o numerabile di possibili esiti. Queste distribuzioni risultano particolarmente efficaci per descrivere eventi che si verificano in contesti discreti, come il numero di successi in un esperimento, l’occorrenza di un evento, o la selezione casuale da un insieme di opzioni finite. Di seguito, presentiamo una panoramica delle distribuzioni che verranno trattate.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#introduzione",
    "href": "chapters/probability/11_discr_rv_distr.html#introduzione",
    "title": "36  Distribuzioni di v.c. discrete",
    "section": "",
    "text": "Distribuzione di Bernoulli\n\n\n\nDescrizione: Modella esperimenti con due soli possibili esiti, spesso denominati “successo” e “fallimento”.\n\nApplicazioni: Processi che coinvolgono eventi binari, come l’esito di una moneta lanciata o la risposta a una domanda dicotomica.\n\nParametro: La probabilità di successo (\\(p\\)).\n\nImportanza: Costituisce la base teorica per molte altre distribuzioni discrete.\n\n\n\nDistribuzione Binomiale\n\n\n\nDescrizione: Descrive il numero totale di successi in un numero fisso di prove Bernoulliane indipendenti.\n\nApplicazioni: Esperimenti che coinvolgono ripetizioni di un processo binario, come il numero di voti favorevoli in un gruppo o il numero di sintomi in un campione di pazienti.\n\nParametri: Probabilità di successo (\\(p\\)) e numero di prove (\\(n\\)).\n\nImportanza: Modella fenomeni ripetuti in condizioni identiche, fornendo una struttura per analisi probabilistiche più complesse.\n\n\n\nDistribuzione di Poisson\n\n\n\nDescrizione: Modella il numero di eventi che si verificano in un intervallo fisso di tempo o spazio, quando tali eventi sono rari e indipendenti.\n\nApplicazioni: Il numero di episodi di ansia acuta riportati da un individuo in un periodo di una settimana; il numero di interazioni sociali spontanee di un bambino con un disturbo dello spettro autistico durante una sessione di osservazione; la frequenza di lapsus verbali durante una presentazione pubblica; il numero di sogni vividi riportati durante una serie di notti consecutive in uno studio sul sonno.\n\nParametro: Il tasso medio di eventi per unità di tempo o spazio (\\(\\lambda\\)).\n\nImportanza: È cruciale per analizzare processi psicologici o comportamentali rari ma importanti, permettendo di comprendere i meccanismi sottostanti e di modellare la variabilità osservata in contesti clinici, sperimentali o quotidiani.\n\n\n\nDistribuzione Uniforme Discreta\n\n\n\nDescrizione: Ogni evento ha la stessa probabilità di verificarsi, all’interno di un intervallo discreto finito.\n\nApplicazioni: La scelta casuale di uno stimolo da una lista di parole equiprobabili in un esperimento di memoria; l’assegnazione casuale di partecipanti a gruppi sperimentali in uno studio di psicologia sociale. La selezione casuale di un’immagine tra un insieme di stimoli visivi utilizzati in una ricerca sull’attenzione; la probabilità uniforme che un partecipante scelga una delle opzioni in un questionario a risposte multiple quando non ha preferenze o conoscenze specifiche.\n\nParametri: L’intervallo di supporto della distribuzione, ad esempio il numero totale di opzioni disponibili o di stimoli tra cui scegliere.\n\nImportanza: È utile come modello di riferimento in situazioni in cui si assume che i partecipanti non abbiano preferenze o che l’incertezza sia massima. Questo tipo di distribuzione aiuta a comprendere il comportamento casuale e a definire un punto di partenza per analisi più complesse.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#distribuzioni-in-r",
    "href": "chapters/probability/11_discr_rv_distr.html#distribuzioni-in-r",
    "title": "36  Distribuzioni di v.c. discrete",
    "section": "\n36.2 Distribuzioni in R",
    "text": "36.2 Distribuzioni in R\nIn R, per ogni distribuzione sono disponibili quattro funzioni principali, i cui nomi iniziano con le lettere:\n\n\nd (density): per calcolare i valori teorici relativi alla distribuzione,\n\n\np (probability): per ottenere la probabilità cumulativa,\n\n\nq (quantile): per determinare i quantili,\n\n\nr (random): per generare campioni casuali.\n\nIl pacchetto di base stats include numerose funzioni dedicate alle principali distribuzioni statistiche, permettendo di calcolare valori teorici e simulare dati in modo semplice e flessibile. Per ulteriori dettagli sulle distribuzioni disponibili e sull’uso delle relative funzioni, è possibile consultare la documentazione con il comando ?Distributions.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#distribuzione-di-bernoulli",
    "href": "chapters/probability/11_discr_rv_distr.html#distribuzione-di-bernoulli",
    "title": "36  Distribuzioni di v.c. discrete",
    "section": "\n36.3 Distribuzione di Bernoulli",
    "text": "36.3 Distribuzione di Bernoulli\nIn statistica, un esperimento che ammette solo due esiti possibili è modellato attraverso quella che viene chiamata “prova Bernoulliana”. Un esempio tipico è il lancio di una moneta, che può dare come risultato testa o croce.\n\nDefinizione 36.1 Una variabile casuale \\(X\\) che assume valori in \\(\\{0, 1\\}\\) è detta variabile di Bernoulli. La sua distribuzione di probabilità è definita come:\n\\[\nP(X \\mid \\theta) =\n  \\begin{cases}\n    p     & \\text{se $X = 1$ (successo)}, \\\\\n    1 - p & \\text{se $X = 0$ (insuccesso)},\n  \\end{cases}\n\\]\ndove \\(0 \\leq p \\leq 1\\). Il parametro \\(p\\) rappresenta la probabilità del “successo” (\\(X = 1\\)), mentre \\(1 - p\\) è la probabilità dell’“insuccesso” (\\(X = 0\\)).\n\nLa distribuzione di Bernoulli descrive quindi un contesto in cui la probabilità di osservare l’esito 1 è \\(p\\) e quella di osservare l’esito 0 è \\(1 - p\\). Viene utilizzata per modellare situazioni binarie, come una risposta “sì” o “no”, oppure un “successo” o “insuccesso”.\nCalcolando il valore atteso e la varianza, otteniamo:\n\\[\n\\begin{align}\n\\mathbb{E}(X) &= 0 \\cdot P(X=0) + 1 \\cdot P(X=1) = p, \\\\\n\\mathbb{V}(X) &= (0 - p)^2 \\cdot P(X=0) + (1 - p)^2 \\cdot P(X=1) = p(1-p).\n\\end{align}\n\\tag{36.1}\\]\n\n\n\n\n\n\nDimostrazione\n\n\n\nEsaminiamo la dimostrazione algebrica del calcolo della varianza.\nEspandiamo il calcolo della somma, considerando i due possibili valori di \\(X\\) (0 e 1).\n\n\nPrimo termine (\\(X = 0\\)):\n\\[\n(0 - \\mathbb{E}(X))^2 \\cdot P(X = 0) = (0 - p)^2 \\cdot (1 - p).\n\\]\nSemplificando \\((0 - p)^2 = p^2\\), quindi:\n\\[\n(0 - \\mathbb{E}(X))^2 \\cdot P(X = 0) = p^2 \\cdot (1 - p).\n\\]\n\n\nSecondo termine (\\(X = 1\\)):\n\\[\n(1 - \\mathbb{E}(X))^2 \\cdot P(X = 1) = (1 - p)^2 \\cdot p.\n\\]\nSemplificando \\((1 - p)^2 = 1 - 2p + p^2\\), quindi:\n\\[\n(1 - \\mathbb{E}(X))^2 \\cdot P(X = 1) = (1 - 2p + p^2) \\cdot p = p - 2p^2 + p^3.\n\\]\n\n\nSomma dei termini\nOra sommiamo i due contributi:\n\\[\n\\mathbb{V}(X) = p^2 \\cdot (1 - p) + (p - 2p^2 + p^3).\n\\]\nEspandendo il primo termine:\n\\[\np^2 \\cdot (1 - p) = p^2 - p^3.\n\\]\nSomma completa:\n\\[\n\\mathbb{V}(X) = (p^2 - p^3) + (p - 2p^2 + p^3).\n\\]\n\n\nRaggruppiamo i termini\n\\[\n\\mathbb{V}(X) = p - p^2.\n\\]\nRisultato finale:\n\\[\n\\mathbb{V}(X) = p(1 - p).\n\\]\n\n\nIn sintesi, la varianza di una variabile aleatoria binaria \\(X\\), distribuita secondo Bernoulli con parametro \\(p\\), è data da \\(p(1-p)\\).\n\n\nTale risultato mostra come la varianza massima si ottenga per \\(p = 0.5\\), condizione che corrisponde alla massima incertezza intrinseca nel processo, ossia quando la probabilità di successo eguaglia quella di insuccesso.\n\n# Valori di p tra 0 e 1\np &lt;- seq(0, 1, length.out = 100)\nvariance &lt;- p * (1 - p)\ndata &lt;- data.frame(p = p, Variance = variance)\n\n# Creazione del grafico\nggplot(data, aes(x = p, y = Variance)) +\n  geom_line(color = \"blue\", linewidth = 1.2) +\n  labs(\n    x = expression(p),\n    y = \"Varianza\",\n    title = \"Varianza di una Variabile Bernoulliana in funzione di p\"\n  )\n\n\n\n\n\n\n\n\n36.3.1 Notazione\nPer indicare che la variabile casuale \\(X\\) segue una distribuzione Bernoulliana di parametro \\(p\\) Utilizziamo la notazione \\(X \\sim \\mathcal{Bern}(p)\\), o in maniera equivalente \\(\\mathcal{Bern}(X \\mid p)\\).\n\nEsempio 36.1 Nel caso del lancio di una moneta equilibrata, la variabile di Bernoulli assume i valori \\(0\\) e \\(1\\) con uguale probabilità di \\(\\frac{1}{2}\\). Pertanto, la funzione di massa di probabilità assegna una probabilità di \\(\\frac{1}{2}\\) sia per \\(X = 0\\) che per \\(X = 1\\), mentre la funzione di distribuzione cumulativa risulta essere \\(\\frac{1}{2}\\) per \\(X = 0\\) e \\(1\\) per \\(X = 1\\).\nGeneriamo dei valori casuali dalla distribuzione di Bernoulli. Iniziamo con un singolo valore:\n\n# Probabilità di successo\np &lt;- 0.5\n\n# Genera un singolo valore\nbernoulli_sample &lt;- rbinom(n = 1, size = 1, prob = p)\nprint(bernoulli_sample)\n#&gt; [1] 1\n\n# Genera un campione di 10 valori\nbernoulli_sample &lt;- rbinom(n = 10, size = 1, prob = p)\nprint(bernoulli_sample)\n#&gt;  [1] 1 0 1 1 1 1 0 1 1 0",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#distribuzione-binomiale",
    "href": "chapters/probability/11_discr_rv_distr.html#distribuzione-binomiale",
    "title": "36  Distribuzioni di v.c. discrete",
    "section": "\n36.4 Distribuzione Binomiale",
    "text": "36.4 Distribuzione Binomiale\nLa distribuzione binomiale è una distribuzione di probabilità discreta che modella il numero di successi \\(y\\) in un numero fissato \\(n\\) di prove di Bernoulli indipendenti e identiche, dove ciascuna prova ha solo due esiti possibili: “successo” (rappresentato da “1”) con probabilità \\(p\\) o “insuccesso” (rappresentato da “0”) con probabilità \\(1 - p\\). La notazione utilizzata è la seguente:\n\\[\nY \\sim \\mathcal{Binom}(n, p).\n\\]\n\nDefinizione 36.2 La distribuzione binomiale descrive la probabilità di osservare esattamente \\(y\\) successi in \\(n\\) prove di Bernoulli indipendenti:\n\\[\nP(Y = y) = \\binom{n}{y} p^{y} (1 - p)^{n - y} = \\frac{n!}{y!(n - y)!} p^{y} (1 - p)^{n - y},\n\\tag{36.2}\\]\ndove \\(\\binom{n}{y}\\), noto come coefficiente binomiale, rappresenta il numero di modi possibili per ottenere \\(y\\) successi in \\(n\\) prove, e \\(p\\) è la probabilità di successo in ciascuna prova.\n\nLa distribuzione binomiale si presta bene a esempi classici come il lancio ripetuto di una moneta o l’estrazione di biglie da un’urna. Ad esempio, nel caso del lancio di una moneta, questa distribuzione descrive la probabilità di ottenere un determinato numero di “teste” in un certo numero di lanci, con ogni lancio che segue una distribuzione di Bernoulli con probabilità di successo \\(p\\).\nUna caratteristica interessante della distribuzione binomiale è la sua proprietà di riproducibilità: se due variabili casuali indipendenti, \\(y_1\\) e \\(y_2\\), seguono entrambe distribuzioni binomiali con lo stesso parametro \\(p\\), ma con un diverso numero di prove (\\(n_1\\) e \\(n_2\\)), la loro somma, \\(y = y_1 + y_2\\), sarà ancora distribuita binomialmente, con parametri \\(n_1 + n_2\\) e \\(p\\).\n\n36.4.1 Calcolo delle Probabilità\nPer chiarire il calcolo delle probabilità nella distribuzione binomiale, consideriamo una serie di prove di Bernoulli. Supponiamo di avere \\(n\\) prove, con \\(y\\) successi. La configurazione di questi risultati può essere rappresentata come:\n\\[\n\\overbrace{SS\\dots S}^\\text{$y$ successi} \\overbrace{II\\dots I}^\\text{$n - y$ insuccessi}\n\\]\nLa probabilità di ottenere esattamente \\(y\\) successi in una sequenza specifica di prove è pari a:\n\\[\np^y \\cdot (1 - p)^{n - y},\n\\]\ndove \\(p^y\\) è la probabilità di ottenere \\(y\\) successi, e \\((1 - p)^{n - y}\\) è la probabilità di ottenere \\(n - y\\) insuccessi.\nTuttavia, siamo interessati alla probabilità complessiva di ottenere esattamente \\(y\\) successi in qualsiasi ordine. Il numero di modi in cui ciò può avvenire è dato dal coefficiente binomiale \\(\\binom{n}{y}\\), che rappresenta tutte le possibili disposizioni dei successi e degli insuccessi nelle \\(n\\) prove.\nQuindi, moltiplicando la probabilità di una singola sequenza per il numero di sequenze possibili, otteniamo la probabilità di osservare esattamente \\(y\\) successi:\n\\[\nP(Y = y) = \\binom{n}{y} p^y (1 - p)^{n - y}.\n\\]\nQuesto risultato corrisponde alla formula della distribuzione binomiale.\n\n36.4.2 Caso particolare \\(n = 1\\)\n\nOra consideriamo il caso particolare in cui \\(n = 1\\). Quando \\(n = 1\\), il coefficiente binomiale diventa:\n\\[\n\\binom{1}{k} = \\frac{1!}{k! (1-k)!}.\n\\]\nEspandiamo i fattoriali per i due possibili valori di \\(k\\), che può assumere solo 0 o 1 (poiché \\(k \\in \\{0, 1, \\dots, n\\}\\)).\nCaso 1: \\(k = 0\\)\n\\[\n\\binom{1}{0} = \\frac{1!}{0! (1-0)!} = \\frac{1}{1 \\cdot 1} = 1.\n\\]\nQuindi, per \\(k = 0\\): \\[\nP(X = 0) = \\binom{1}{0} p^0 (1-p)^{1-0} = 1 \\cdot 1 \\cdot (1-p) = 1-p.\n\\]\nCaso 2: \\(k = 1\\)\n\\[\n\\binom{1}{1} = \\frac{1!}{1! (1-1)!} = \\frac{1}{1 \\cdot 1} = 1.\n\\]\nQuindi, per \\(k = 1\\): \\[\nP(X = 1) = \\binom{1}{1} p^1 (1-p)^{1-1} = 1 \\cdot p \\cdot 1 = p.\n\\]\nIn conclusione, la PMF per la distribuzione binomiale con \\(n = 1\\) diventa:\n\\[\nP(X = k) =\n\\begin{cases}\n1-p, & \\text{se } k = 0, \\\\\np, & \\text{se } k = 1.\n\\end{cases}\n\\]\nQuesta è esattamente la PMF della distribuzione di Bernoulli con parametro \\(p\\):\n\\[\nP(X = x) = p^x (1-p)^{1-x}, \\quad x \\in \\{0, 1\\}.\n\\]\nPertanto, la distribuzione binomiale con \\(n = 1\\) è equivalente alla distribuzione di Bernoulli con parametro \\(p\\).\n\n36.4.3 Applicazioni Pratiche della Distribuzione Binomiale\nConsideriamo un esempio pratico per illustrare l’applicazione della distribuzione binomiale. Supponiamo di osservare 2 successi in 4 prove Bernoulliane, dove la probabilità di successo in ogni prova è \\(p = 0.2\\). La probabilità di ottenere questo risultato specifico è calcolata utilizzando l’eq. {eq}eq-binom-distr:\n\\[\nP(Y=2) = \\frac{4!}{2!(4-2)!} \\cdot 0.2^{2} \\cdot (1-0.2)^{4-2} = 0.1536.\n\\]\nQuesto calcolo può essere replicato in Python. Utilizzando il modulo math, possiamo calcolare direttamente:\n\n# Parametri\nn &lt;- 4\np &lt;- 0.2\ny &lt;- 2\n\n# Probabilità di ottenere esattamente y successi\nprob &lt;- choose(n, y) * p^y * (1 - p)^(n - y)\nprint(prob)\n#&gt; [1] 0.154\n\nIn alternativa, possiamo sfruttare la libreria SciPy per eseguire calcoli analoghi. SciPy offre una vasta gamma di funzioni per la gestione delle distribuzioni statistiche, tra cui la distribuzione binomiale.\n\n# Probabilità di ottenere esattamente y successi\nprob &lt;- choose(n, y) * p^y * (1 - p)^(n - y)\nprint(prob)\n#&gt; [1] 0.154\n\nUtilizzando dbinom(y, n, p), possiamo trovare le probabilità per ogni possibile valore \\(y\\) in una distribuzione binomiale di parametri \\(n = 4\\) e \\(\\theta = 0.2\\):\n\n# Usando la funzione dbinom\nprob &lt;- dbinom(x = y, size = n, prob = p)\nprint(prob)\n#&gt; [1] 0.154\n\nVisualizziamo la distribuzione di massa di probabilità:\n\ny &lt;- 0:n  # Numero di successi\nprobabilities &lt;- dbinom(y, size = n, prob = p)  # Probabilità associate\n\n# Preparare i dati in un data frame\ndf &lt;- data.frame(Successi = y, Probabilità = probabilities)\n\ndf |&gt; \n  ggplot(aes(x = Successi, y = Probabilità)) +\n    geom_segment(aes(xend = Successi, yend = 0), lwd = 1.2, color = \"blue\") +\n    geom_point(size = 3, color = \"blue\") +\n    labs(\n      x = \"Numero di Successi y\",\n      y = \"Probabilità\",\n      title = paste(\"Distribuzione Binomiale: n =\", n, \", p =\", p)\n  )\n\n\n\n\n\n\n\nUn campione casuale si ottiene con rbinom():\n\nset.seed(42)\nsamples &lt;- rbinom(n = 30, size = 5, prob = 0.5)\nprint(samples)\n#&gt;  [1] 4 4 2 4 3 3 3 1 3 3 2 3 4 2 2 4 5 1 2 3 4 1 5 4 1 3 2 4 2 4\n\nPer esplorare ulteriormente, consideriamo la distribuzione di probabilità di diverse distribuzioni binomiali per due valori di \\(n\\) e \\(\\theta\\). La seguente visualizzazione mostra come cambia la distribuzione al variare di \\(\\theta\\):\n\n# Parametri\nn &lt;- 20\np_values &lt;- seq(0.3, 0.9, by = 0.3) # Valori di probabilità\ny &lt;- 0:25 # Numero di successi\n\n# Creazione di un data frame per tutte le distribuzioni\ndf &lt;- data.frame()\n\nfor (p in p_values) {\n  binom_dist &lt;- dbinom(y, size = n, prob = p)\n  df &lt;- rbind(df, data.frame(y = y, Prob = binom_dist, p = factor(p)))\n}\n\n# Grafico con ggplot2\ndf |&gt; \n  ggplot(aes(x = y, y = Prob, color = p)) +\n    geom_point() +\n    geom_line() +\n    labs(\n      x = \"Numero di successi y\", \n      y = \"Probabilità\",\n      title = \"Distribuzione binomiale al variare di p\",\n      color = expression(theta)\n  )\n\n\n\n\n\n\n\nConsideriamo un altro esempio. Lanciando \\(5\\) volte una moneta onesta, qual è la probabilità che esca testa almeno due volte? Troviamo la soluzione usando stats.binom.pmf().\n\n# Calcolo della somma delle probabilità\nresult &lt;- dbinom(2, size = 5, prob = 0.5) +\n          dbinom(3, size = 5, prob = 0.5) +\n          dbinom(4, size = 5, prob = 0.5) +\n          dbinom(5, size = 5, prob = 0.5)\n\nprint(result)\n#&gt; [1] 0.812\n\nOppure, in modo più compatto:\n\n# Valori di interesse\nresult &lt;- sum(dbinom(2:5, size = 5, prob = 0.5))\nprint(result)\n#&gt; [1] 0.812\n\nRappresentiamo graficamente la funzione di ripartizione per una Binomiale di ordine \\(n\\) = 5 e \\(\\theta\\) = 0.5.\n\n# Parametri\nn &lt;- 5\np &lt;- 0.5\ny &lt;- 0:n\n\n# Calcolo della funzione di ripartizione cumulativa\ncdf_values &lt;- pbinom(y, size = n, prob = p)\n\n# Creazione del data frame per ggplot2\ndf &lt;- data.frame(y = y, cdf = cdf_values)\n\n# Grafico\ndf |&gt; \n  ggplot(aes(x = y, y = cdf)) +\n    geom_line() +\n    geom_point() +\n    geom_hline(yintercept = 1, color = \"black\", alpha = 0.7, linetype = \"dashed\") +\n    labs(\n      title = paste(\"Funzione di ripartizione binomiale: n =\", n, \", p =\", p),\n      x = \"y\",\n      y = \"Probabilità\"\n    )\n\n\n\n\n\n\n\nUn’altra funzione utile è quella che permette di trovare il numero di successi associato a una data probabilità cumulativa nella coda sinistra di una distribuzione binomiale. Questo si ottiene utilizzando la funzione qbinom, che rappresenta l’inversa della funzione di distribuzione cumulativa (CDF).\nAd esempio, consideriamo una distribuzione binomiale con \\(n = 5\\) prove e probabilità di successo \\(p = 0.5\\). Supponiamo di voler calcolare il numero minimo di successi per cui la probabilità cumulativa è almeno \\(1 - 0.8125 = 0.1875\\). Possiamo farlo nel seguente modo:\n\n# Probabilità target\ntarget_probability &lt;- 1 - 0.8125\n\n# Numero di successi corrispondente alla probabilità target\nresult &lt;- qbinom(target_probability, size = 5, prob = 0.5)\n\nprint(result)\n#&gt; [1] 1\n\nIn questo esempio, il valore restituito è \\(1\\), che indica che almeno 1 successo soddisfa la condizione di una probabilità cumulativa di \\(0.1875\\).\n\n36.4.4 Altro esempio\nConsideriamo ora una distribuzione binomiale con \\(n = 10\\) prove e probabilità di successo \\(p = 0.2\\). Per calcolare la probabilità cumulativa \\(P(Y \\leq 4)\\), ovvero la probabilità di ottenere al massimo 4 successi su 10 tentativi, possiamo utilizzare la funzione pbinom:\n\n# Calcolo della probabilità cumulativa\ntarget_probability &lt;- pbinom(4, size = 10, prob = 0.2)\nprint(target_probability)\n#&gt; [1] 0.967\n\nIl risultato rappresenta la probabilità cumulativa associata a 4 o meno successi.\nSe invece vogliamo determinare il numero di successi corrispondente a questa probabilità cumulativa, possiamo utilizzare la funzione inversa qbinom:\n\n# Calcolo del numero di successi associato alla probabilità cumulativa\nresult &lt;- qbinom(target_probability, size = 10, prob = 0.2)\nprint(result)\n#&gt; [1] 4\n\nIn questo caso, il valore restituito rappresenta il numero massimo di successi \\(Y\\) per cui la probabilità cumulativa è uguale o inferiore a \\(target\\_probability\\). Questo è particolarmente utile per interpretare i risultati di una distribuzione binomiale in termini di successi associati a determinate probabilità cumulative.\n\n36.4.5 Valore atteso e deviazione standard\nLa media (numero atteso di successi in \\(n\\) prove) e la deviazione standard di una distribuzione binomiale si calcolano nel seguente modo:\n\\[\n\\begin{align}\n\\mu    &= np,  \\notag \\\\\n\\sigma &= \\sqrt{np(1-p)}.\n\\end{align}\n\\tag{36.3}\\]\nDimostrazione. Dato che \\(Y\\) rappresenta la somma di \\(n\\) prove di Bernoulli indipendenti \\(Y_i\\), possiamo scrivere:\n\\[\n\\begin{align}\n\\mathbb{E}(Y) &= \\mathbb{E}\\left( \\sum_{i=1}^n Y_i \\right) = \\sum_{i=1}^n \\mathbb{E}(Y_i) = np, \\\\\n\\mathbb{V}(Y) &= \\mathbb{V} \\left( \\sum_{i=1}^n Y_i \\right) = \\sum_{i=1}^n \\mathbb{V}(Y_i) = np(1-p).\n\\end{align}\n\\]\nPertanto, la deviazione standard è data da \\(\\sigma = \\sqrt{np(1-p)}\\).\nPer esempio, prendiamo in considerazione il caso di un esperimento in cui vengono lanciate quattro monete, ciascuna con una probabilità di ottenere testa (successo) pari a \\(p = 0.2\\). Calcoliamo il valore atteso e la varianza per questo esperimento.\nIl valore atteso, \\(\\mu\\), rappresenta il numero medio di teste che ci aspettiamo di ottenere in ciascun lancio. Per la distribuzione binomiale, questo è dato da \\(\\mu = n p\\), dove \\(n\\) è il numero di prove (lanci di monete). Nel nostro caso, con \\(n = 4\\) e \\(p = 0.2\\), abbiamo:\n\\[\n\\mu = n p = 4 \\times 0.2 = 0.8.\n\\]\nQuesto significa che, in media, ci aspettiamo di ottenere circa 0.8 teste per ogni serie di quattro lanci.\nPer quanto riguarda la varianza, che misura quanto i risultati individuali tendono a differire dalla media, nella distribuzione binomiale è calcolata come \\(n p (1-p)\\). Pertanto, per il nostro esperimento:\n\\[\n\\text{Varianza} = n p (1-p) = 4 \\times 0.2 \\times (1 - 0.2) = 0.64.\n\\]\nLa varianza di 0.64 suggerisce una certa dispersione intorno al valore medio di 0.8 teste.\nPer confermare queste aspettative teoriche, possiamo eseguire una simulazione. Creiamo una serie di esperimenti simulati in cui lanciamo quattro monete per un gran numero di volte, registrando il numero di teste ottenute in ogni serie. Calcoliamo poi la media e la varianza dei risultati ottenuti per vedere quanto si avvicinano ai valori teorici calcolati.\n\nset.seed(42)\n\n# Genera un campione di 1.000.000 di valori dalla distribuzione binomiale\nx &lt;- rbinom(n = 1000000, size = 4, prob = 0.2)\n\n\nmean(x)\n#&gt; [1] 0.8\n\n\nvar(x)\n#&gt; [1] 0.639\n\n\n36.4.6 Funzioni R associate alle distribuzioni di probabilità\nLa seguente tabella riassume le funzioni di R utilizzate per manipolare le distribuzioni di probabilità, illustrando i casi della distribuzione Binomiale e della Normale.\n\n\n\n\n\n\n\nTipo\nEsempio: Binomiale (\\(y \\mid n, p\\))\nEsempio: Normale (\\(y \\mid \\mu, \\sigma\\))\n\n\n\nFunzione di verosimiglianza\ndbinom(y, size = n, prob = p)\ndnorm(y, mean = μ, sd = σ)\n\n\nProb \\(Y = y\\)\n\ndbinom(y, size = n, prob = p)\nNon definita (variabili continue hanno pdf, non pmf)\n\n\nProb \\(Y \\geq y, Y \\leq y, y_1 &lt; Y &lt; y_2\\)\n\n\npbinom(y, size = n, prob = p) o 1 - pbinom(y - 1, ...)\n\n\npnorm(y, mean = μ, sd = σ) o 1 - pnorm(y, ...)\n\n\n\nInversa della CDF\nqbinom(q, size = n, prob = p)\nqnorm(q, mean = μ, sd = σ)\n\n\nGenerazione di dati simulati\nrbinom(n, size = trials, prob = p)\nrnorm(n, mean = μ, sd = σ)\n\n\n\nIn seguito, useremo altre distribuzioni come Uniforme, Beta, ecc., ognuna delle quali ha un proprio insieme di funzioni disponibili in R. La sintassi segue uno schema generale comune:\n\n\nd*: Calcola la funzione di densità di probabilità (per distribuzioni continue) o di massa (per distribuzioni discrete). Esempi: dbinom, dnorm.\n\np*: Calcola la funzione di ripartizione cumulativa (CDF). Esempi: pbinom, pnorm.\n\nq*: Calcola l’inversa della funzione di ripartizione cumulativa (quantile function). Esempi: qbinom, qnorm.\n\nr*: Genera campioni casuali secondo una determinata distribuzione. Esempi: rbinom, rnorm.\n\n\nEsercizio 36.1  \n\nCalcolare la probabilità di esattamente \\(y = 3\\) successi su \\(n = 5\\) prove con \\(p = 0.5\\):\n\n\ndbinom(3, size = 5, prob = 0.5)\n#&gt; [1] 0.312\n\n\nCalcolare la probabilità cumulativa \\(P(Y \\leq 3)\\):\n\n\npbinom(3, size = 5, prob = 0.5)\n#&gt; [1] 0.812\n\n\nCalcolare il valore minimo \\(y\\) tale che \\(P(Y \\leq y) \\geq 0.9\\):\n\n\nqbinom(0.9, size = 5, prob = 0.5)\n#&gt; [1] 4\n\n\nGenerare un campione di 100 numeri casuali da una distribuzione binomiale:\n\n\nrbinom(100, size = 5, prob = 0.5)\n#&gt;   [1] 2 2 4 1 3 2 3 2 2 2 3 3 3 3 1 4 1 1 0 2 2 2 4 1 2 3 3 1 5 2 3 3 0 3 2\n#&gt;  [36] 3 4 2 3 3 3 3 1 5 3 3 2 3 1 2 1 3 3 2 2 4 1 4 2 3 1 4 2 2 3 4 1 1 4 2\n#&gt;  [71] 3 2 3 3 3 1 4 4 3 3 4 3 3 3 2 2 3 3 2 4 4 3 2 2 0 3 1 3 1 2",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#distribuzione-discreta-uniforme",
    "href": "chapters/probability/11_discr_rv_distr.html#distribuzione-discreta-uniforme",
    "title": "36  Distribuzioni di v.c. discrete",
    "section": "\n36.5 Distribuzione Discreta Uniforme",
    "text": "36.5 Distribuzione Discreta Uniforme\nLa distribuzione discreta uniforme è un tipo particolare di distribuzione di probabilità, dove ogni risultato in un insieme finito e discreto \\(S\\) ha la stessa probabilità \\(p\\) di verificarsi. Questa distribuzione è caratterizzata dalla sua semplicità e dalla sua proprietà fondamentale di equiprobabilità.\nConsideriamo un esempio pratico con una variabile casuale discreta \\(X\\), che può assumere valori nell’insieme \\(\\{1, 2, \\dots, N\\}\\). Un’istanza classica di questa distribuzione si verifica quando si sceglie casualmente un numero intero tra 1 e \\(N\\), inclusi. Se \\(X\\) rappresenta il numero selezionato, allora la somma delle probabilità di tutti i possibili valori di \\(X\\) deve totalizzare 1, come indicato dalla formula di normalizzazione:\n\\[\n\\sum_{i=1}^N P(X_i) = Np = 1.\n\\]\nDi conseguenza, la probabilità che \\(X\\) assuma un valore specifico \\(x\\) è uniformemente distribuita:\n\\[\nP(X = x) = \\frac{1}{N},\n\\]\nindicando che ogni evento ha la stessa probabilità di verificarsi.\nIl valore atteso, o la media, di \\(X\\) ci dà un’idea del risultato medio atteso e si calcola come:\n\\[\n\\mathbb{E}(X) = \\sum_{x=1}^N x \\cdot \\frac{1}{N} = \\frac{1}{N} \\cdot \\sum_{x=1}^N x.\n\\]\nA questo punto, dobbiamo calcolare la somma \\(\\sum_{x=1}^{N} x\\), che è la somma dei primi \\(N\\) numeri naturali. Questa somma è data dalla formula:\n\\[\n\\sum_{x=1}^{N} x = \\frac{N(N + 1)}{2}.\n\\]\nSostituendo questa formula nel nostro calcolo del valore atteso, otteniamo:\n\\[\n\\mathbb{E}(X) = \\frac{1}{N} \\cdot \\frac{N(N + 1)}{2} = \\frac{N + 1}{2}.\n\\]\nQuindi, abbiamo dimostrato che il valore atteso $ (X) $ per una variabile casuale \\(X\\) che assume valori interi uniformemente distribuiti da 1 a \\(N\\) è \\(\\frac{N + 1}{2}\\).\nPer determinare quanto i valori di \\(X\\) si disperdono attorno al valore medio, calcoliamo la varianza. Il primo passo è calcolare \\(\\mathbb{E}(X^2)\\), il valore atteso del quadrato di \\(X\\). Per una variabile casuale discreta uniforme, questo si ottiene moltiplicando ogni valore al quadrato per la sua probabilità (che è \\(1/N\\) per tutti i valori) e sommando i risultati:\n\\[\n\\mathbb{E}(X^2) = \\frac{1}{N} \\cdot \\sum_{x=1}^N x^2\n\\]\nUsando l’identità per la somma dei quadrati dei primi \\(N\\) numeri naturali:\n\\[\n1^2 + 2^2 + \\dots + N^2 = \\frac{N(N + 1)(2N + 1)}{6}\n\\]\npossiamo sostituirla per trovare \\(\\mathbb{E}(X^2)\\):\n\\[\n\\mathbb{E}(X^2) = \\frac{1}{N} \\cdot \\frac{N(N + 1)(2N + 1)}{6} = \\frac{(N + 1)(2N + 1)}{6}\n\\]\nLa varianza di \\(X\\), denotata con \\(\\mathbb{V}(X)\\), si calcola usando la formula:\n\\[\n\\mathbb{V}(X) = \\mathbb{E}(X^2) - [\\mathbb{E}(X)]^2\n\\]\nAbbiamo già stabilito che \\(\\mathbb{E}(X) = \\frac{N + 1}{2}\\) e \\(\\mathbb{E}(X^2) = \\frac{(N + 1)(2N + 1)}{6}\\). Sostituendo questi valori nella formula della varianza, otteniamo:\n\\[\n\\mathbb{V}(X) = \\frac{(N + 1)(2N + 1)}{6} - \\left(\\frac{N + 1}{2}\\right)^2\n\\]\nPer semplicare l’espressione della varianza, dobbiamo sottrarre il quadrato di \\(\\mathbb{E}(X)\\) da \\(\\mathbb{E}(X^2)\\):\n\\[\n\\begin{align*}\n\\mathbb{V}(X) &= \\frac{(N + 1)(2N + 1)}{6} - \\left(\\frac{N + 1}{2}\\right)^2 \\\\\n&= \\frac{(N + 1)(2N + 1)}{6} - \\frac{(N + 1)^2}{4} \\\\\n&= \\frac{2(N + 1)(2N + 1)}{12} - \\frac{3(N + 1)^2}{12} \\\\\n&= \\frac{(N + 1)(2(2N + 1) - 3(N + 1))}{12} \\\\\n&= \\frac{(N + 1)(4N + 2 - 3N - 3)}{12} \\\\\n&= \\frac{(N + 1)(N - 1)}{12}\n\\end{align*}\n\\]\nQuindi, la varianza \\(\\mathbb{V}(X)\\) di una variabile casuale uniforme discreta \\(X\\) che assume valori da 1 a \\(N\\) è \\(\\frac{(N + 1)(N - 1)}{12}\\), il che mostra come la dispersione dei valori attorno al loro valore medio dipenda dalla grandezza di \\(N\\). Questa formula fornisce la varianza di una variabile casuale in una distribuzione discreta uniforme, offrendo una misura quantitativa della dispersione dei valori attorno al loro valore medio.\n\n36.5.1 Distribuzione di Poisson\nLa distribuzione di Poisson è utilizzata per modellare il numero di eventi che si verificano in un determinato intervallo di tempo o spazio, con eventi indipendenti e un tasso costante di occorrenza.\nLa funzione di massa di probabilità (PMF) è data da:\n\\[\nP(Y = y \\mid \\lambda) = \\frac{\\lambda^y \\cdot e^{-\\lambda}}{y!}, \\quad y = 0, 1, 2, \\ldots\n\\]\ndove \\(\\lambda\\) rappresenta il tasso medio di eventi e \\(y\\) è il numero di eventi.\n\n36.5.1.1 Proprietà principali\n\n\nMedia: \\(\\mathbb{E}[Y] = \\lambda\\)\n\n\nVarianza: \\(\\text{Var}(Y) = \\lambda\\)\n\n\nDi seguito, presentiamo esempi di calcolo e simulazione con R.\n\n36.5.1.2 Grafico della distribuzione di Poisson con \\(\\lambda = 2\\)\n\n\n# Parametro lambda\nlambda &lt;- 2\n\n# Valori di y (numero di eventi)\ny &lt;- 0:10\n\n# Calcolo delle probabilità\nprobabilities &lt;- dpois(y, lambda = lambda)\n\n# Grafico della funzione di massa di probabilità\nbarplot(probabilities, names.arg = y, col = \"blue\", \n        xlab = \"Numero di eventi (k)\", ylab = \"Probabilità\", \n        main = \"Distribuzione di Massa di Probabilità di Poisson\")\n\n\n\n\n\n\n\n\n36.5.1.3 Calcolo della probabilità per un numero specifico di eventi\nPer calcolare la probabilità di osservare esattamente 3 eventi con \\(\\lambda = 2\\):\n\nprob &lt;- dpois(3, lambda = 2)\nprint(prob)\n#&gt; [1] 0.18\n\n\n36.5.1.4 Calcolo della probabilità cumulativa \\(P(Y \\leq 3)\\)\n\nPer calcolare \\(P(Y \\leq 3)\\), la probabilità cumulativa:\n\ncum_prob &lt;- ppois(3, lambda = 2)\nprint(cum_prob)\n#&gt; [1] 0.857\n\n\n36.5.1.5 Trovare il quantile corrispondente a una probabilità data\nPer trovare il numero massimo di eventi per cui la probabilità cumulativa è al massimo \\(0.8125\\):\n\nquantile &lt;- qpois(0.8125, lambda = 2)\nprint(quantile)\n#&gt; [1] 3\n\n\n36.5.1.6 Generazione di numeri casuali\nPer generare un campione di 1.000.000 di osservazioni da una distribuzione di Poisson con \\(\\lambda = 2\\):\n\nset.seed(42)\nsample &lt;- rpois(1000000, lambda = 2)\n\n# Calcolo di media e varianza del campione\nmean_sample &lt;- mean(sample)\nvar_sample &lt;- var(sample)\n\nprint(mean_sample)\n#&gt; [1] 2\nprint(var_sample)\n#&gt; [1] 2\n\n\nEsercizio 36.2 Consideriamo un ospedale con una media storica di 4,5 nascite al giorno. Qual è la probabilità che nascano esattamente 6 bambini in un giorno?\n\n# Calcolo della probabilità\nlambda &lt;- 4.5\nprob &lt;- dpois(6, lambda = lambda)\nprint(prob)\n#&gt; [1] 0.128\n\nSimuliamo 365 giorni di nascite e confrontiamo la proporzione di giorni con esattamente 6 nascite:\n\nset.seed(42)\nn_days &lt;- 365\nsimulated_births &lt;- rpois(n_days, lambda = lambda)\n\n# Proporzione di giorni con esattamente 6 nascite\nproportion_six_births &lt;- mean(simulated_births == 6)\nprint(proportion_six_births)\n#&gt; [1] 0.14\n\nIstogramma delle nascite simulate:\n\nhist(simulated_births, breaks = seq(-0.5, max(simulated_births) + 0.5, by = 1), \n     col = \"blue\", xlab = \"Numero di nascite per giorno\", \n     ylab = \"Frequenza\", main = \"365 nascite simulate (Poisson)\")\n\n\n\n\n\n\n\nProbabilità di più di 6 nascite in un giorno. Per calcolare la probabilità teorica \\(P(Y &gt; 6)\\):\n\nprob_more_than_six &lt;- 1 - ppois(6, lambda = lambda)\nprint(prob_more_than_six)\n#&gt; [1] 0.169\n\nProporzione simulata di più di 6 nascite:\n\nproportion_more_than_six &lt;- mean(simulated_births &gt; 6)\nprint(proportion_more_than_six)\n#&gt; [1] 0.17",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#distribuzione-beta-binomiale",
    "href": "chapters/probability/11_discr_rv_distr.html#distribuzione-beta-binomiale",
    "title": "36  Distribuzioni di v.c. discrete",
    "section": "\n36.6 Distribuzione Beta-Binomiale",
    "text": "36.6 Distribuzione Beta-Binomiale\nLa distribuzione beta-binomiale rappresenta una estensione della distribuzione binomiale che tiene conto della variabilità nella probabilità di successo tra i vari tentativi. Viene descritta da tre parametri principali: \\(N\\), \\(\\alpha\\) e \\(\\beta\\).\nNel dettaglio, la funzione di massa di probabilità per la distribuzione beta-binomiale è data da:\n\\[\n\\text{BetaBinomiale}(y | N, \\alpha, \\beta) = \\binom{N}{y} \\cdot \\frac{B(y + \\alpha, N - y + \\beta)}{B(\\alpha, \\beta)},\n\\tag{36.4}\\]\ndove:\n\n\n\\(y\\) indica il numero di successi osservati.\n\n\\(N\\) rappresenta il numero totale di tentativi.\n\n\\(\\alpha\\) e \\(\\beta\\) sono i parametri della distribuzione beta, che modellano la variabilità nella probabilità di successo tra i tentativi.\n\nLa funzione \\(B(u, v)\\), nota come funzione beta, è definita tramite l’uso della funzione gamma \\(\\Gamma\\), secondo la formula:\n\\[\nB(u, v) = \\frac{\\Gamma(u) \\Gamma(v)}{\\Gamma(u + v)},\n\\]\ndove la funzione gamma \\(\\Gamma\\) generalizza il concetto di fattoriale a numeri reali e complessi.\nL’importanza della distribuzione beta-binomiale deriva dalla sua capacità di modellare situazioni in cui la probabilità di successo non è fissa, ma segue una distribuzione di probabilità, specificatamente una distribuzione beta. Ciò la rende particolarmente adatta per applicazioni in cui le probabilità di successo cambiano in maniera incerta da un tentativo all’altro, come può avvenire in contesti di ricerca clinica o in studi comportamentali. Rispetto alla distribuzione binomiale, che assume una probabilità di successo costante per tutti i tentativi, la beta-binomiale offre una rappresentazione più realistica e flessibile per dati empirici che presentano variabilità nelle probabilità di successo.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#la-distribuzione-categorica",
    "href": "chapters/probability/11_discr_rv_distr.html#la-distribuzione-categorica",
    "title": "36  Distribuzioni di v.c. discrete",
    "section": "\n36.7 La Distribuzione Categorica",
    "text": "36.7 La Distribuzione Categorica\nLa distribuzione categorica è una distribuzione di probabilità discreta utilizzata per modellare eventi con più esiti distinti e non ordinati. È una generalizzazione della distribuzione Bernoulliana, che si limita a due esiti (successo e fallimento), ed è utile in situazioni in cui un evento può produrre uno tra molti esiti, ciascuno con una probabilità associata.\n\n36.7.1 Definizione e Funzione di Massa di Probabilità\nLa distribuzione categorica può essere caratterizzata dalla sua funzione di massa di probabilità (PMF):\n\\[\np(X = x) = \\mathcal{Categorical}(X \\mid p) = \\prod_{k=1}^K p_k^{I_{x=k}},\n\\]\ndove:\n\n\n\\(K\\) è il numero di esiti possibili,\n\n\\(p_k\\) è la probabilità associata al \\(k\\)-esimo esito,\n\n\\(I_{x=k}\\) è una funzione indicatrice che vale 1 se \\(x = k\\) e 0 altrimenti.\n\nLe probabilità \\(p_k\\) formano un vettore:\n\\[\np =\n\\begin{pmatrix}\np_1\\\\\np_2\\\\\n\\dots \\\\\np_K\n\\end{pmatrix},\n\\]\nche soddisfa la condizione:\n\\[\n\\sum_{k=1}^K p_k = 1.\n\\]\nIn altre parole, la somma delle probabilità di tutti i possibili esiti è pari a 1, come richiesto da qualsiasi distribuzione di probabilità.\n\n36.7.2 Proprietà Principali\n\nEsiti Multipli: La distribuzione categorica è adatta per modellare eventi con più di due esiti distinti. Un esempio classico è il lancio di un dado a sei facce, dove ciascun esito ha una probabilità di \\(\\frac{1}{6}\\) nel caso di un dado equo.\nGeneralizzazione della Distribuzione Bernoulliana: La distribuzione categorica è una generalizzazione della distribuzione Bernoulliana. In particolare, la distribuzione Bernoulliana rappresenta un caso speciale della distribuzione categorica con due sole categorie (\\(K = 2\\)), come il risultato di un lancio di una moneta (testa o croce).\nProbabilità in Forma di Simplex: Le probabilità degli esiti nella distribuzione categorica sono rappresentate da un vettore simplex. Un simplex è un vettore di probabilità non negative che sommano a 1, rispettando la condizione fondamentale delle distribuzioni di probabilità.\n\n36.7.3 Utilizzo della Distribuzione Categorica in Stan\nIn Stan, la distribuzione categorica è impiegata per modellare la probabilità di un singolo esito tra diversi possibili risultati. Questo è particolarmente utile in contesti come le catene di Markov, dove ogni stato può evolvere verso uno tra molti altri stati con una certa probabilità.\nAd esempio, supponiamo di avere una matrice di transizione \\(P\\) che descrive le probabilità di passaggio tra stati in una catena di Markov. Ogni riga della matrice \\(P\\) rappresenta una distribuzione categorica, in cui le voci corrispondono alle probabilità di transizione dallo stato corrente agli stati successivi. La distribuzione categorical può essere utilizzata per modellare la probabilità di osservare una specifica transizione.\nConsideriamo un esempio pratico: se uno studente si trova nello stato \\(A\\) al tempo \\(t\\), e le probabilità di transizione agli stati \\(A\\), \\(B\\) e \\(C\\) sono rispettivamente \\(0.7\\), \\(0.2\\) e \\(0.1\\), possiamo modellare la probabilità che l’evento successivo sia una transizione verso uno di questi stati usando la distribuzione categorica:\n\\[\nX \\sim \\text{categorical}(0.7, 0.2, 0.1)\n\\]\nQui, la variabile aleatoria \\(X\\) segue una distribuzione categorical con le probabilità assegnate ai tre possibili esiti (stati \\(A\\), \\(B\\), e \\(C\\)). Questo consente di simulare il prossimo stato in base alle probabilità specificate.\n\n36.7.3.1 Applicazione nelle Catene di Markov\nLa distribuzione categorical è particolarmente efficace nei modelli di catene di Markov, dove descrive le transizioni tra stati in un sistema dinamico. Ogni transizione tra stati è trattata come un evento discreto con più esiti possibili, ciascuno con la propria probabilità. Questo approccio è utile per modellare sistemi con molteplici stati e transizioni complesse, garantendo flessibilità e precisione nella simulazione delle dinamiche del sistema.\nIn sintesi, la distribuzione categorica in Stan permette di modellare eventi con molteplici esiti in modo semplice ed efficace, rendendola uno strumento prezioso per descrivere fenomeni dinamici, come le catene di Markov o qualsiasi altro processo con transizioni probabilistiche tra stati.\nDi seguito, esaminiamo come simulare una distribuzione categorica utilizzando numpy e come creare un istogramma per visualizzare la distribuzione di massa:\n\n# Definire le probabilità della distribuzione categorica\nprobabilities &lt;- c(0.6, 0.3, 0.1)  # Le probabilità per ciascun esito\n\n# Definire le categorie\ncategories &lt;- c(\"A\", \"B\", \"C\")\n\n# Numero di campioni da generare\nn_samples &lt;- 1000\n\n# Simulare la distribuzione categorica\nset.seed(123)  # Per riproducibilità\nsamples &lt;- sample(categories, size = n_samples, replace = TRUE, prob = probabilities)\n\nggplot(data.frame(samples = samples), aes(x = samples)) +\n  geom_bar(fill = \"skyblue\", color = \"black\") +\n  scale_x_discrete(labels = categories) +\n  labs(\n    x = \"Categorie\", \n    y = \"Frequenza\", \n    title = \"Istogramma della Distribuzione Categorica Simulata\"\n) \n\n\n\n\n\n\n\nConcludiamo chiarendo la relazione tra la distribuzione categorica e quella multinomiale.\nLa distribuzione categorica descrive l’esito di una singola prova con \\(K\\) categorie, ciascuna con una probabilità associata. È una generalizzazione della distribuzione Bernoulliana, che prevede solo due esiti (successo o fallimento).\n\n36.7.4 Implementazioni in R\n\n\nsample: Permette di campionare da una distribuzione categorica, restituendo uno o più esiti in base alle probabilità specificate. Ad esempio:\nsample(categories, size = n, replace = TRUE, prob = probabilities)\nDove categories è un vettore di esiti, n è il numero di campioni, e probabilities definisce le probabilità associate a ciascun esito.\n\n\nrmultinom: Funzione per la distribuzione multinomiale. Può essere utilizzata per simulare una distribuzione categorica impostando il numero di prove \\(n = 1\\). Ad esempio:\nrmultinom(1, size = 1, prob = probabilities)\nQui, probabilities specifica le probabilità per ciascun esito. Restituisce il numero di successi per ciascuna categoria in una matrice.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#la-distribuzione-geometrica",
    "href": "chapters/probability/11_discr_rv_distr.html#la-distribuzione-geometrica",
    "title": "36  Distribuzioni di v.c. discrete",
    "section": "\n36.8 La Distribuzione Geometrica",
    "text": "36.8 La Distribuzione Geometrica\nLa distribuzione geometrica è una distribuzione discreta che modella il numero di tentativi necessari per ottenere il primo successo in una sequenza di prove Bernoulliane indipendenti. Ogni prova ha due possibili esiti: successo (con probabilità \\(p\\)) o fallimento (con probabilità \\(1 - p\\)).\nIn termini pratici, la distribuzione geometrica può essere utilizzata per rispondere alla domanda: “Quante prove falliscono prima di ottenere il primo successo?”.\n\n36.8.1 Funzione di Massa di Probabilità\nLa funzione di massa di probabilità (PMF) della distribuzione geometrica è definita come:\n\\[\nP(X = k) = (1 - p)^{k-1} \\cdot p\n\\]\ndove:\n\n\n\\(X\\) è il numero di tentativi fino al primo successo (incluso il tentativo in cui si ottiene il successo).\n\n\\(p\\) è la probabilità di successo in ogni prova.\n\n\\(k\\) è il numero di prove necessarie per ottenere il primo successo (un numero intero positivo, \\(k \\geq 1\\)).\n\n36.8.2 Proprietà della Distribuzione Geometrica\n\n\nValore Atteso (Media): La media del numero di prove fino al primo successo è data da:\n\n\\[\n\\mathbb{E}[X] = \\frac{1}{p}.\n\\]\nQuesto significa che, in media, ci si aspetta di avere \\(\\frac{1}{p}\\) prove prima di ottenere un successo.\n\n\nVarianza: La varianza della distribuzione geometrica è:\n\n\\[\n\\text{Var}(X) = \\frac{1 - p}{p^2}.\n\\]\n\n\nMemoria Assente: La distribuzione geometrica ha una proprietà interessante chiamata “assenza di memoria”. Ciò significa che, dato che non si è verificato alcun successo fino a un certo punto, la probabilità di successo nelle prove future è indipendente dal passato e rimane sempre \\(p\\).\n\n36.8.3 Applicazione nel Modello\nAd esempio, supponiamo di voler modellare quanti giorni passano prima che un animale venga adottato in un rifugio. Se la probabilità giornaliera di essere adottato è \\(p\\), la distribuzione geometrica può dirci quanto tempo ci aspettiamo prima che l’adozione avvenga. Se, ad esempio, \\(p = 0.2\\), significa che c’è il 20% di probabilità di adozione ogni giorno, e possiamo modellare il numero di giorni fino all’adozione usando una distribuzione geometrica.\nNel nostro modello di adozione, stiamo utilizzando la distribuzione geometrica per modellare i giorni fino all’adozione. La probabilità \\(p\\) rappresenta la probabilità giornaliera che un animale venga adottato, e la distribuzione geometrica ci permette di modellare il numero di giorni fino a quando avviene il successo (adozione).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#riflessioni-conclusive",
    "href": "chapters/probability/11_discr_rv_distr.html#riflessioni-conclusive",
    "title": "36  Distribuzioni di v.c. discrete",
    "section": "\n36.9 Riflessioni Conclusive",
    "text": "36.9 Riflessioni Conclusive\nIn questo capitolo, abbiamo esplorato diverse distribuzioni discrete fondamentali, ciascuna con le sue specifiche applicazioni e peculiarità. Abbiamo iniziato con la distribuzione Bernoulliana, che modella esperimenti con due possibili esiti, come il lancio di una moneta. Abbiamo poi approfondito la distribuzione Binomiale, una generalizzazione della Bernoulliana, che si focalizza sul conteggio del numero di successi in un dato numero di prove indipendenti.\nAbbiamo anche esaminato la distribuzione Beta-Binomiale, che estende ulteriormente il modello Binomiale incorporando la variabilità nella probabilità di successo, e la distribuzione di Poisson, utilizzata per modellare il numero di eventi che si verificano in un intervallo di tempo o spazio, quando questi eventi sono rari e indipendenti.\nInfine, abbiamo discusso la distribuzione Discreta Uniforme, che attribuisce la stessa probabilità a ogni evento in un insieme finito e discreto. Questa distribuzione è particolarmente utile quando non abbiamo ragioni per assegnare probabilità diverse ai diversi esiti.\nQueste distribuzioni formano il cuore dell’analisi statistica discreta e trovano applicazione in un’ampia gamma di settori. In particolare, nel contesto dell’analisi bayesiana, la comprensione della distribuzione Binomiale e Beta-Binomiale è cruciale, poiché queste distribuzioni forniscono le basi per l’aggiornamento bayesiano, un concetto chiave che sarà esplorato nei capitoli successivi.\nPer coloro interessati a tecniche più avanzate, la generazione di valori casuali a partire da queste distribuzioni è trattata nell’appendice {ref}rng-appendix. Questa sezione fornisce strumenti e approfondimenti utili per l’applicazione pratica di questi modelli probabilistici.\nIn conclusione, le distribuzioni discrete forniscono strumenti essenziali e versatili per modellare e analizzare fenomeni caratterizzati da eventi distinti e quantificabili. La comprensione approfondita di queste distribuzioni è cruciale per chiunque desideri esplorare il vasto campo della probabilità e della statistica.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#esercizi",
    "href": "chapters/probability/11_discr_rv_distr.html#esercizi",
    "title": "36  Distribuzioni di v.c. discrete",
    "section": "\n36.10 Esercizi",
    "text": "36.10 Esercizi\n\nEsercizio 36.3 Per ciascuna delle distribuzioni di massa di probabilità discusse, utilizzare R per:\n\ncreare un grafico della funzione, scegliendo opportunamente i parametri;\nestrarre un campione di 1000 valori casuali dalla distribuzione e visualizzarlo con un istogramma;\ncalcolare la media e la deviazione standard dei campioni e confrontarle con i valori teorici attesi;\nstimare l’intervallo centrale del 94% utilizzando i campioni simulati;\ndeterminare i quantili della distribuzione per gli ordini 0.05, 0.25, 0.75 e 0.95;\nscegliendo un valore della distribuzione pari alla media più una deviazione standard, calcolare la probabilità che la variabile aleatoria assuma un valore minore o uguale a questo valore.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/11_discr_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "title": "36  Distribuzioni di v.c. discrete",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] see_0.9.0        gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1\n#&gt;  [5] psych_2.4.12     scales_1.3.0     markdown_1.13    knitr_1.49      \n#&gt;  [9] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [13] purrr_1.0.2      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [17] ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.3         rlang_1.1.4       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       yaml_2.3.10       tools_4.4.2       parallel_4.4.2   \n#&gt; [21] tzdb_0.4.0        colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5      \n#&gt; [25] R6_2.5.1          lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3  \n#&gt; [29] pillar_1.10.0     gtable_0.3.6      glue_1.8.0        xfun_0.49        \n#&gt; [33] tidyselect_1.2.1  farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-166     \n#&gt; [37] labeling_0.4.3    rmarkdown_2.29    compiler_4.4.2\n\n\n\n\n\nBlitzstein, J. K., & Hwang, J. (2019). Introduction to probability. CRC Press.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html",
    "href": "chapters/probability/12_cont_rv_distr.html",
    "title": "37  Distribuzioni di v.c. continue",
    "section": "",
    "text": "37.1 Introduzione\nAnalogamente a quanto avviene per le variabili casuali discrete, anche per le variabili casuali continue possiamo rappresentare la variabilità all’interno di una popolazione attraverso un modello statistico, ma in questo caso utilizziamo le densità di probabilità – si veda il Capitolo 35. Mentre le distribuzioni di probabilità discrete si applicano a fenomeni con un numero finito o numerabile di esiti, le densità di probabilità descrivono variabili casuali che possono assumere un continuum di valori.\nLa funzione di densità di probabilità \\(f(x)\\) associata a una variabile casuale continua \\(X\\) rappresenta la distribuzione della probabilità all’interno della popolazione. Questa funzione non fornisce la probabilità esatta di un singolo valore, ma piuttosto la probabilità di osservare valori di \\(X\\) all’interno di un intervallo specifico. Così come per le distribuzioni discrete, anche le densità di probabilità costituiscono un modello della popolazione, una rappresentazione matematica che ci consente di fare previsioni e di comprendere meglio i fenomeni aleatori continui.\nIniziamo con la distribuzione continua uniforme.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#introduzione",
    "href": "chapters/probability/12_cont_rv_distr.html#introduzione",
    "title": "37  Distribuzioni di v.c. continue",
    "section": "",
    "text": "37.1.1 Distribuzione Uniforme\nLa distribuzione uniforme è una delle più semplici funzioni di densità di probabilità. Consideriamo di nuovo l’esperimento dello spinner introdotto in precedenza. Simuliamo 20 valori che potrebbero essere ottenuti facendo ruotare lo spinner e li rappresentiamo con un istogramma.\n\n37.1.1.1 Simulazione di 20 valori\n\n# Simulazione di 20 valori\nset.seed(123)\nspinner_results &lt;- runif(20, min = 0, max = 360)\nprint(spinner_results)\n#&gt;  [1] 103.5 283.8 147.2 317.9 338.6  16.4 190.1 321.3 198.5 164.4 344.5 163.2\n#&gt; [13] 243.9 206.1  37.1 323.9  88.6  15.1 118.1 343.6\n\nggplot(data.frame(Valori = spinner_results), aes(x = Valori)) +\n  geom_histogram(binwidth = 10, fill = \"skyblue\", color = \"black\", alpha = 0.5) +\n  labs(x = \"Risultato dello spinner\", y = \"Frequenza relativa\",\n       title = \"Istogramma dei risultati (20 simulazioni)\") \n\n\n\n\n\n\n\nNonostante possiamo pensare che ogni risultato tra 0 e 360 sia ugualmente probabile, l’istogramma non lo suggerisce chiaramente con solo 20 osservazioni. Simuliamo ora 100.000 ripetizioni.\n\n37.1.1.2 Simulazione di 100.000 valori\n\n# Simulazione di 100.000 valori\nspinner_results_large &lt;- runif(100000, min = 0, max = 360)\n\n# Istogramma\nggplot(data.frame(Valori = spinner_results_large), aes(x = Valori)) +\n  geom_histogram(binwidth = 10, fill = \"skyblue\", color = \"black\", alpha = 0.5) +\n  labs(x = \"Risultato dello spinner\", y = \"Frequenza relativa\",\n       title = \"Istogramma dei risultati (100.000 simulazioni)\") \n\n\n\n\n\n\n\nIn questo caso, anche se ci sono variazioni nelle altezze delle barre (bin di ampiezza pari a 10), la forma generale dell’istogramma appare piuttosto uniforme su tutto l’intervallo \\([0, 360]\\). Con un numero enorme di risultati, l’istogramma si avvicinerebbe alla funzione di densità uniforme mostrata di seguito.\n\n37.1.1.3 Funzione di densità uniforme\n\n# Curva della funzione di densità uniforme\nx &lt;- seq(0, 360, length.out = 100)\ndensity_uniform &lt;- dunif(x, min = 0, max = 360)\n\nggplot(data.frame(x = x, y = density_uniform), aes(x = x, y = y)) +\n  geom_line(size = 1, color = \"blue\") +\n  labs(x = \"x\", y = \"p(x)\", title = \"Funzione di densità uniforme\") \n#&gt; Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#&gt; ℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\nQuando la variabile casuale \\(X\\) è continua, come nel caso dello spinner, la probabilità è rappresentata da una curva, la funzione di densità di probabilità. Poiché lo spinner copre l’intervallo \\([0, 360]\\), la probabilità che \\(X\\) sia compreso in questo intervallo è pari a 1. La densità costante è quindi:\n\n1 / 360\n#&gt; [1] 0.00278\n\n\n37.1.1.4 Probabilità in un intervallo specifico\nLa probabilità di ottenere un valore tra 150 e 250, \\(P(150 &lt; X &lt; 250)\\), è data dall’area sottesa alla curva in quell’intervallo. L’altezza della curva è \\(1/360\\), mentre la base è \\(250 - 150 = 100\\). Quindi:\n\n100 * (1 / 360)\n#&gt; [1] 0.278\n\nPer calcolare la probabilità, si possono utilizzare le funzioni di distribuzione cumulative:\n\npunif(250, min = 0, max = 360) - punif(150, min = 0, max = 360)\n#&gt; [1] 0.278\n\n\n37.1.1.5 Visualizzazione dell’intervallo di probabilità\n\n# Visualizzazione della probabilità nell'intervallo [150, 250]\nx &lt;- seq(0, 360, length.out = 1000)\nfx &lt;- dunif(x, min = 0, max = 360)\n\nggplot(data.frame(x = x, fx = fx), aes(x = x, y = fx)) +\n  geom_line(size = 1, color = \"blue\") +\n  geom_area(data = subset(data.frame(x = x, fx = fx), x &gt;= 150 & x &lt;= 250),\n            aes(x = x, y = fx), fill = \"gray\", alpha = 0.5) +\n  labs(x = \"x\", y = \"p(x)\", title = \"Probabilità per l'intervallo [150, 250]\")\n\n\n\n\n\n\n\nIn maniera più formale possiamo dire che la distribuzione continua uniforme è una distribuzione di probabilità continua che assegna lo stesso grado di fiducia a tutti i possibili valori di una variabile definita in un certo intervallo \\(S=[a,b]\\subset {\\mathbb  {R}}\\). La distribuzione continua uniforme viene indicata con \\({\\mathcal  {U}}(a,b)={\\mathcal  {U}}([a,b])\\). Come intervallo \\([a,b]\\) viene spesso preso l’intervallo unitario \\(I=[0,1]\\).\nLa densità di probabilità di una variabile casuale continua uniforme \\({\\mathcal  {U}}(a,b)\\) è\n\\[\nf(x)={\\frac  {1}{b-a}} \\quad \\text{su}\\; [a, b].\n\\]\nIl suo valore attesto è\n\\[\n\\displaystyle E(X)={\\frac {1}{2}}(b+a).\n\\]\nLa sua varianza è\n\\[\nV(X)={\\frac {1}{12}}(b-a)^{2}.\n\\]\nIn R, è possibile manipolare la distribuzione uniforme utilizzando le funzioni della famiglia runif, dunif, punif e qunif. Di default, queste funzioni lavorano con la distribuzione uniforme standard \\(\\mathcal{U}(0,1)\\).\n\n37.1.2 Funzione di densità di probabilità (PDF)\nLa funzione dunif() calcola l’ordinata della funzione di densità per i valori di input specificati. Per esempio, esaminiamo la densità di \\(\\mathcal{U}(0,1)\\) per i valori 0.5, 0.8 e 1.2. Ci aspettiamo di ottenere 1 per i primi due valori e 0 per 1.2, che è fuori dall’intervallo \\([0, 1]\\).\n\ndunif(c(0.5, 0.8, 1.2), min = 0, max = 1)\n#&gt; [1] 1 1 0\n\n\n37.1.3 Funzione di ripartizione (CDF)\nLa funzione punif() restituisce il valore della funzione di ripartizione. Per esempio, per \\(\\mathcal{U}(0,1)\\) nei punti 0.5 e 0.8:\n\npunif(c(0.5, 0.8), min = 0, max = 1)\n#&gt; [1] 0.5 0.8\n\n\n37.1.4 Calcolo della probabilità in un intervallo\nUtilizzando la funzione di ripartizione, possiamo calcolare la probabilità che la variabile casuale continua assuma un valore in un intervallo specificato. Per esempio, per \\(\\mathcal{U}(0,1)\\) troviamo \\(P(0.5 &lt; X &lt; 0.8)\\):\n\npunif(0.8, min = 0, max = 1) - punif(0.5, min = 0, max = 1)\n#&gt; [1] 0.3\n\n\n37.1.5 Calcolo dei quantili\nLa funzione qunif() restituisce i quantili della distribuzione uniforme, ovvero il valore della variabile casuale \\(X\\) in corrispondenza del valore della funzione di ripartizione fornito in input. Per esempio, troviamo i quantili di ordine 0.5 e 0.8 di \\(\\mathcal{U}(0,1)\\):\n\nqunif(c(0.5, 0.8), min = 0, max = 1)\n#&gt; [1] 0.5 0.8\n\n\n37.1.6 Simulazione di valori casuali\nLa funzione runif() consente di generare numeri casuali dalla distribuzione uniforme. Per esempio, simuliamo 5 valori casuali da \\(\\mathcal{U}(0,1)\\):\n\nset.seed(123)  # Per la riproducibilità\nrunif(5, min = 0, max = 1)\n#&gt; [1] 0.288 0.788 0.409 0.883 0.940\n\n\n37.1.7 Valore atteso\nPer verificare il valore atteso di 100,000 realizzazioni di \\(\\mathcal{U}(0,1)\\):\n\nmean(runif(100000, min = 0, max = 1))\n#&gt; [1] 0.499\n\n\n37.1.8 Varianza\nPer calcolare la varianza di 100,000 realizzazioni di \\(\\mathcal{U}(0,1)\\):\n\nvar(runif(100000, min = 0, max = 1))\n#&gt; [1] 0.0834\n\nConfrontiamo il valore teorico della varianza per \\(\\mathcal{U}(0,1)\\), che è \\(1/12\\):\n\n1 / 12\n#&gt; [1] 0.0833\n\nIn conclusione, le funzioni della famiglia runif, dunif, punif e qunif in R consentono di manipolare e analizzare la distribuzione uniforme.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-esponenziale",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-esponenziale",
    "title": "37  Distribuzioni di v.c. continue",
    "section": "\n37.2 Distribuzione esponenziale",
    "text": "37.2 Distribuzione esponenziale\nUn’altra distribuzione di densità molto semplice è la distribuzione esponenziale. La distribuzione esponenziale viene spesso utilizzata per modellare il tempo trascorso prima che un evento si verifichi (tempo di attesa).\nLa distribuzione esponenziale è l’unica distribuzione di probabilità continua che possiede la proprietà di assenza di memoria. Ad esempio, ipotizziamo che il tempo necessario affinché un bicchiere da vino si rompa dopo il primo utilizzo segua una distribuzione esponenziale. Supponiamo inoltre che ci sia un bicchiere da vino che non si è rotto dopo 3 anni dal primo utilizzo. L’assenza di memoria significa che la probabilità che questo bicchiere da vino non si rompa nel prossimo anno è la stessa della probabilità che un altro bicchiere da vino nuovo non si rompa nel primo anno di utilizzo.\nChiamiamo \\(X\\) il tempo di attesa. Sia \\(\\mu = \\mathbb{E}(X)\\) il tempo di attesa medio. La funzione di densità esponenziale è\n\\[\nf(x) = \\lambda {\\rm e}^{-\\lambda x}, \\quad \\text{con} \\; \\lambda = 1/\\mu,\\, \\lambda &gt; 0,\\, x &gt; 0,\n\\tag{37.1}\\]\novvero\n\\[\nf(x) = \\frac{1}{\\mu} {\\rm e}^{-x/\\mu}.\n\\]\nLa media di una distribuzione esponenziale è\n\\[\nE(X) = \\frac{1}{\\lambda}.\n\\]\nLa varianza di una distribuzione esponenziale è\n\\[\nV(X) = \\mu = \\frac{1}{\\lambda^2}.\n\\]\nLa deviazione standard è dunque uguale alla media:\n\\[\n\\sigma_X = \\frac{1}{\\lambda} = \\mu.\n\\]\nAd esempio, il tempo di attesa della pubblicazione del voto di un esame scritto segue una distribuzione esponenziale. Supponiamo che, in questo Corso di Laurea, il tempo di attesa medio per conoscere il risultato di un esame scritto sia di 4 giorni. La funzione esponenziale diventa\n\\[\nf(x) = \\frac{1}{4} \\exp^{-x/4}.\n\\]\n\n37.2.1 Grafico della funzione di densità esponenziale\nLa densità esponenziale è definita da \\(f(x) = \\lambda e^{-\\lambda x}\\). In R, possiamo disegnarla con:\n\n# Parametri della distribuzione\nmu &lt;- 4  # Media\nlambda &lt;- 1 / mu  # Tasso (1 / media)\nstdev &lt;- 1 / lambda  # Deviazione standard\n\n# Generare valori per x\nx &lt;- seq(0, 20, by = 0.01)\n\n# Calcolare la densità\npdf &lt;- dexp(x, rate = lambda)\n\n# Grafico della densità\nggplot(data.frame(x, pdf), aes(x = x, y = pdf)) +\n  geom_line(size = 1, color = \"blue\") +\n  labs(x = \"x\", y = \"f(x)\", title = \"Funzione di densità della distribuzione esponenziale\") \n\n\n\n\n\n\n\n\n37.2.2 Probabilità che \\(X \\leq 1.5\\)\n\nLa probabilità \\(P(X \\leq 1.5)\\) è calcolata con la funzione di ripartizione pexp():\n\n# Probabilità che X &lt;= 1.5\npexp(1.5, rate = lambda)\n#&gt; [1] 0.313\n\nVisualizzazione dell’area sottesa:\n\nggplot(data.frame(x, pdf), aes(x = x, y = pdf)) +\n  geom_line(size = 1, color = \"blue\") +\n  geom_area(data = subset(data.frame(x, pdf), x &lt;= 1.5), aes(x = x, y = pdf), fill = \"gray\", alpha = 0.5) +\n  labs(x = \"x\", y = \"f(x)\", title = \"Probabilità P(X &lt;= 1.5)\") \n\n\n\n\n\n\n\n\n37.2.3 Probabilità che \\(1 \\leq X \\leq 6\\)\n\nLa probabilità \\(P(1 \\leq X \\leq 6)\\) si calcola come differenza di funzioni di ripartizione:\n\n# Probabilità che 1 &lt;= X &lt;= 6\npexp(6, rate = lambda) - pexp(1, rate = lambda)\n#&gt; [1] 0.556\n\nVisualizzazione dell’area sottesa:\n\nggplot(data.frame(x, pdf), aes(x = x, y = pdf)) +\n  geom_line(size = 1, color = \"blue\") +\n  geom_area(data = subset(data.frame(x, pdf), x &gt;= 1 & x &lt;= 6), aes(x = x, y = pdf), fill = \"gray\", alpha = 0.5) +\n  labs(x = \"x\", y = \"f(x)\", title = \"Probabilità P(1 &lt;= X &lt;= 6)\")\n\n\n\n\n\n\n\n\n37.2.4 Probabilità che \\(X \\geq 5.5\\)\n\nLa probabilità \\(P(X \\geq 5.5)\\) si ottiene con l’evento complementare \\(1 - P(X \\leq 5.5)\\) oppure con 1 - pexp():\n\n# Complemento\n1 - pexp(5.5, rate = lambda)\n#&gt; [1] 0.253\n\n# Alternativa con funzione di sopravvivenza\npexp(5.5, rate = lambda, lower.tail = FALSE)\n#&gt; [1] 0.253\n\nVisualizzazione dell’area sottesa:\n\nggplot(data.frame(x, pdf), aes(x = x, y = pdf)) +\n  geom_line(size = 1, color = \"blue\") +\n  geom_area(data = subset(data.frame(x, pdf), x &gt;= 5.5), aes(x = x, y = pdf), fill = \"gray\", alpha = 0.5) +\n  labs(x = \"x\", y = \"f(x)\", title = \"Probabilità P(X &gt;= 5.5)\") \n\n\n\n\n\n\n\n\n37.2.5 Istogramma di valori simulati\nSimuliamo 1.000.000 di valori casuali da una distribuzione esponenziale con parametro \\(\\lambda = 1/4\\), quindi costruiamo l’istogramma sovrapponendo la densità teorica.\n\n# Simulazione di valori casuali\nset.seed(123)\nsamples &lt;- rexp(1000000, rate = lambda)\n\n# Istogramma con densità sovrapposta\nggplot(data.frame(samples), aes(x = samples)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 100, fill = \"skyblue\", color = \"black\", alpha = 0.5) +\n  geom_line(data = data.frame(x, pdf), aes(x = x, y = pdf), color = \"red\", size = 1) +\n  xlim(0, 20) +\n  labs(x = \"Tempo di attesa\", y = \"Frequenza relativa\",\n       title = \"Istogramma dei valori simulati con densità teorica\")\n#&gt; Warning: Removed 6631 rows containing non-finite outside the scale range\n#&gt; (`stat_bin()`).\n#&gt; Warning: Removed 2 rows containing missing values or values outside the scale range\n#&gt; (`geom_bar()`).\n\n\n\n\n\n\n\nQuesti esempi replicano tutte le funzionalità dell’implementazione Python utilizzando R e producono grafici chiari e ben definiti.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-gaussiana",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-gaussiana",
    "title": "37  Distribuzioni di v.c. continue",
    "section": "\n37.3 Distribuzione Gaussiana",
    "text": "37.3 Distribuzione Gaussiana\nLa più importante distribuzione di densità è la Gaussiana. Non c’è un’unica distribuzione gaussiana (o Normale): la distribuzione gaussiana è una famiglia di distribuzioni. Tali distribuzioni sono dette “gaussiane” in onore di Carl Friedrich Gauss (uno dei più grandi matematici della storia il quale, tra le altre cose, scoprì l’utilità di tale funzione di densità per descrivere gli errori di misurazione). Adolphe Quetelet, il padre delle scienze sociali quantitative, fu il primo ad applicare tale funzione di densità alle misurazioni dell’uomo. Karl Pearson usò per primo il termine “distribuzione normale” anche se ammise che questa espressione “ha lo svantaggio di indurre le persone a credere che le altre distribuzioni, in un senso o nell’altro, non siano normali.”\n\n37.3.1 Limite delle distribuzioni binomiali\nIniziamo con un un breve excursus storico. Nel 1733, Abraham de Moivre notò che, aumentando il numero di prove di una distribuzione binomiale, la distribuzione risultante diventava quasi simmetrica e a forma campanulare. Per esempio, con 10 prove e una probabilità di successo di 0.9, la distribuzione è chiaramente asimmetrica.\n\n# Parametri\nn &lt;- 10\np &lt;- 0.9\n\n# Calcolare la distribuzione binomiale\nr_values &lt;- 0:n\ndist &lt;- dbinom(r_values, size = n, prob = p)\n\n# Grafico\nggplot(data.frame(Successi = r_values, Probabilità = dist), aes(x = Successi, y = Probabilità)) +\n  geom_bar(stat = \"identity\", fill = \"skyblue\", color = \"black\") +\n  labs(title = \"Distribuzione Binomiale: n = 10, p = 0.9\", x = \"Numero di Successi\", y = \"Probabilità\") \n\n\n\n\n\n\n\nQuando il numero di prove N viene aumentato di un fattore di 100 a N = 1000, mantenendo costante la probabilità di successo del 90%, si osserva che la distribuzione assume una forma campanulare quasi simmetrica. Questa osservazione porta a una scoperta di de Moivre: quando N diventa grande, la funzione gaussiana, nonostante rappresenti la densità di variabili casuali continue, offre una buona approssimazione alla funzione di massa di probabilità binomiale.\n\n# Parametri aggiornati\nn &lt;- 1000\n\n# Calcolare la distribuzione\nr_values &lt;- 850:950  # Intervallo per una migliore visualizzazione\ndist &lt;- dbinom(r_values, size = n, prob = p)\n\n# Grafico\nggplot(data.frame(Successi = r_values, Probabilità = dist), aes(x = Successi, y = Probabilità)) +\n  geom_bar(stat = \"identity\", fill = \"skyblue\", color = \"black\") +\n  labs(\n    title = \"Distribuzione Binomiale: n = 1000, p = 0.9\", \n    x = \"Numero di Successi\", \n    y = \"Probabilità\"\n  ) \n\n\n\n\n\n\n\nLa distribuzione Normale fu scoperta da Gauss nel 1809. Il Paragrafo successivo illustra come si possa giungere alla Normale mediante una simulazione.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#la-normale-prodotta-con-una-simulazione",
    "href": "chapters/probability/12_cont_rv_distr.html#la-normale-prodotta-con-una-simulazione",
    "title": "37  Distribuzioni di v.c. continue",
    "section": "\n37.4 La Normale prodotta con una simulazione",
    "text": "37.4 La Normale prodotta con una simulazione\nIl libro “Rethinking Statistics” di McElreath (2020) spiega come sia possibile ottenere la distribuzione normale attraverso una simulazione. Immaginiamo di avere duemila persone che si trovano allineate su una linea di partenza. Quando viene dato il segnale di partenza, ogni persona lancia una moneta e compie un passo avanti o indietro a seconda del risultato del lancio. La lunghezza di ogni passo può variare da 0 a 1 metro. Ogni persona lancia la moneta 16 volte e quindi compie 16 passi.\nI risultati ottenuti da una serie di passeggiate casuali si traducono in varie distanze dall’origine, che è il punto da cui si parte, contrassegnato come zero, dopo un numero specificato di passi. Queste distanze sono rappresentate numericamente. Al termine di queste passeggiate, non è possibile determinare la posizione esatta di ogni individuo, ma è possibile descrivere accuratamente le caratteristiche della distribuzione delle 1000 distanze dall’origine.\nAd esempio, è possibile prevedere con precisione la frazione di individui che si sono mossi verso in avanti o indietro, o la proporzione di persone che si troveranno a una distanza specifica dal punto di partenza, come a 1.5 metri dall’origine. Queste previsioni sono fattibili perché la distribuzione delle distanze segue una distribuzione Normale.\nIl codice presentato di seguito genera passeggiate casuali utilizzando un generatore di numeri casuali e ne traccia i percorsi risultanti. Il codice inizia inizializzando un oggetto generatore di numeri casuali con la funzione np.random.default_rng() della libreria numpy. Questo generatore sarà usato per produrre numeri casuali uniformemente distribuiti tra -1 e 1, simulando così il lancio di una moneta.\nLa variabile steps specifica il numero di passi per ogni passeggiata casuale, mentre repetitions indica il numero di passeggiate da generare. La variabile show_steps è un elenco di numeri di passi in cui il codice traccerà linee verticali sul grafico.\nSuccessivamente, il codice crea un array bidimensionale di NumPy chiamato x con righe pari a steps + 1 e colonne pari a repetitions. La prima colonna di questo array è riempita di zeri, e le colonne rimanenti sono riempite con la somma cumulativa dei passi, ottenuti da numeri casuali uniformemente distribuiti generati dal generatore di numeri casuali. Questo array verrà utilizzato per memorizzare le posizioni della passeggiata casuale ad ogni passo.\nIl codice poi prepara una figura per tracciare tutte le passeggiate casuali. Il codice traccia anche la prima passeggiata casuale in nero.\n\n# Parametri\nnumero_passi &lt;- 16\nripetizioni &lt;- 1000\npunti_da_evidenziare &lt;- c(4, 8, 16)\n\n# Generare passeggiate casuali\nset.seed(123)\nx &lt;- matrix(0, nrow = numero_passi + 1, ncol = ripetizioni)\n\nfor (i in 1:ripetizioni) {\n  passi &lt;- runif(numero_passi, min = -1, max = 1)\n  x[-1, i] &lt;- cumsum(passi)\n}\n\n# Grafico delle passeggiate casuali\ndf &lt;- data.frame(\n  Passo = rep(0:numero_passi, times = ripetizioni), \n  Distanza = as.vector(x)\n)\n\n# Grafico delle passeggiate casuali\nggplot(\n  df, \n  aes(\n    x = Passo, \n    y = Distanza, \n    group = rep(1:ripetizioni, each = numero_passi + 1))\n  ) +\n  geom_line(color = \"blue\", alpha = 0.05) +\n  geom_line(\n    data = data.frame(Passo = 0:numero_passi, Distanza = x[, 1], group = 1), \n    aes(x = Passo, y = Distanza, group = group), color = \"black\") +\n  geom_vline(\n    xintercept = punti_da_evidenziare, \n    linetype = \"dashed\", \n    color = \"black\", \n    alpha = 0.5) +\n  labs(\n    title = \"Passeggiate Casuali\", \n    x = \"Numero di Passi\", \n    y = \"Distanza dall'Origine\"\n  ) \n\n\n\n\n\n\n\nIl grafico riportato qui sotto visualizza la distribuzione dei passi a partire dalla linea mediana dopo 4, 8 e 16 lanci di moneta/passi. Quello che si nota è che, man mano che procediamo nel numero di passi, le densità iniziano a somigliare alla curva a campana associata alle distribuzioni Gaussiane.\n\ndensities &lt;- lapply(punti_da_evidenziare, function(step) {\n  data.frame(Posizione = x[step + 1, ], Passo = step)\n})\n\ndensities &lt;- bind_rows(densities)\n\nggplot(densities, aes(x = Posizione, fill = as.factor(Passo))) +\n  geom_density(alpha = 0.6) +\n  facet_wrap(~ Passo, scales = \"free\") +\n  labs(\n    title = \"Densità delle Posizioni\",\n    x = \"Posizione\",\n    y = \"Densità\",\n    fill = \"Passo\"  # Etichetta per la legenda\n  ) +\n  theme(\n    legend.position = \"bottom\"  # Sposta la legenda in basso\n  )\n\n\n\n\n\n\n\nLa chiarezza dell’informazione presentata nei grafici precedenti può essere migliorata utilizzando un KDE plot.\n\n# Generare i dati\nposizioni &lt;- apply(matrix(runif(numero_passi * ripetizioni, min = -1, max = 1), nrow = numero_passi), 2, sum)\n\n# Calcolare media e deviazione standard\nmedia &lt;- mean(posizioni)\ndev_std &lt;- sd(posizioni)\n\n# Generare la curva normale\nvalori &lt;- seq(min(posizioni), max(posizioni), length.out = 1000)\ndensità_normale &lt;- dnorm(valori, mean = media, sd = dev_std)\n\n# Grafico\nggplot(data.frame(Posizione = posizioni), aes(x = Posizione)) +\n  geom_density(fill = \"skyblue\", alpha = 0.5) +\n  geom_line(data = data.frame(Posizione = valori, Densità = densità_normale), aes(x = Posizione, y = Densità), color = \"red\", linetype = \"dashed\") +\n  labs(title = \"Confronto tra Passeggiate Casuali e Normale\", x = \"Posizione\", y = \"Densità\") \n\n\n\n\n\n\n\nQuesta simulazione in luce un principio fondamentale della teoria delle probabilità: ogni processo che coinvolge la somma di una sequenza di valori casuali, tutti estratti dalla stessa distribuzione, inevitabilmente tende verso una distribuzione normale, comunemente conosciuta come curva gaussiana. Questa tendenza si verifica indipendentemente dalla configurazione iniziale della distribuzione di partenza, che può essere uniforme, come nell’esempio menzionato, o di qualsiasi altro tipo. La forma specifica della distribuzione iniziale influisce sulla velocità con cui si verifica questa convergenza verso il comportamento gaussiano, con variazioni significative nella velocità di convergenza: alcuni processi possono manifestare una convergenza lenta, mentre altri possono convergere estremamente rapidamente. Un esempio emblematico di questo fenomeno è rappresentato dal dispositivo conosciuto come Galton box, il quale offre una rappresentazione visiva e fisica di come la somma di valori casuali generi una distribuzione normale.\nUn modo per razionalizzare la distribuzione Gaussiana è quello di pensare alle medie. Qualunque sia il valore medio della distribuzione di origine, ogni campione da essa può essere considerato una fluttuazione rispetto a quel valore medio. Tuttavia, quando sommiamo queste fluttuazioni insieme, esse si annullano a vicenda. E, facendo ciò, queste fluttuazioni convergono eventualmente alla media delle osservazioni collettive. Non importa quale sia la forma della distribuzione sottostante. A seconda della forma, le somme cumulative convergeranno inevitabilmente sulla media, alcune distribuzioni più lentamente di altre.\nDal punto di vista formale, possiamo definire una variabile casuale continua \\(Y\\) come avente una distribuzione normale se la sua densità di probabilità è distribuita secondo la seguente equazione\n\\[\nf(y; \\mu, \\sigma) = {1 \\over {\\sigma\\sqrt{2\\pi} }} \\exp \\left\\{-\\frac{(y -  \\mu)^2}{2 \\sigma^2} \\right\\},\n\\tag{37.2}\\]\ndove \\(\\mu \\in \\mathbb{R}\\) e \\(\\sigma &gt; 0\\) sono i parametri della distribuzione.\nLa densità normale è unimodale e simmetrica con una caratteristica forma a campana e con il punto di massima densità in corrispondenza di \\(\\mu\\).\nIl significato dei parametri \\(\\mu\\) e \\(\\sigma\\) che appaiono nell’eq. {eq}eq-normal-formula viene chiarito dalla dimostrazione che\n\\[\n\\mathbb{E}(Y) = \\mu, \\qquad \\mathbb{V}(Y) = \\sigma^2.\n\\]\nLa rappresentazione grafica di quattro densità Normali con medie -1, -0.5, 0, 1 e con deviazioni standard 0.25, 0.5, 1 e 2 è fornita nella figura seguente.\n\n# Definire l'intervallo di x\nx &lt;- seq(-5, 6, by = 0.001)\n\n# Parametri della distribuzione normale\nmus &lt;- c(-1.0, -0.5, 0.0, 1.0)\nsigmas &lt;- c(0.25, 0.5, 1, 2)\n\n# Creare un data frame per tutte le combinazioni di mu e sigma\ndata &lt;- do.call(rbind, lapply(1:length(mus), function(i) {\n  data.frame(\n    x = x,\n    f_x = dnorm(x, mean = mus[i], sd = sigmas[i]),\n    mu = mus[i],\n    sigma = sigmas[i]\n  )\n}))\n\n# Grafico\nggplot(data, aes(x = x, y = f_x, color = factor(mu), linetype = factor(sigma))) +\n  geom_line(size = 1) +\n  labs(\n    x = \"x\",\n    y = \"f(x)\",\n    color = expression(mu),\n    linetype = expression(sigma),\n    title = \"Distribuzioni Normali con Diversi Parametri\"\n  ) +\n  theme(legend.position = \"top\")\n\n\n\n\n\n\n\n\n37.4.1 Concentrazione\nÈ istruttivo osservare il grado di concentrazione della distribuzione Normale attorno alla media:\n\\[\n\\begin{align}\nP(\\mu - \\sigma &lt; Y &lt; \\mu + \\sigma) &= P (-1 &lt; Z &lt; 1) \\simeq 0.683, \\notag\\\\\nP(\\mu - 2\\sigma &lt; Y &lt; \\mu + 2\\sigma) &= P (-2 &lt; Z &lt; 2) \\simeq 0.956, \\notag\\\\\nP(\\mu - 3\\sigma &lt; Y &lt; \\mu + 3\\sigma) &= P (-3 &lt; Z &lt; 3) \\simeq 0.997. \\notag\n\\end{align}\n\\]\nSi noti come un dato la cui distanza dalla media è superiore a 3 volte la deviazione standard presenti un carattere di eccezionalità perché meno del 0.3% dei dati della distribuzione Normale presentano questa caratteristica.\nPer indicare la distribuzione Normale si usa la notazione \\(\\mathcal{N}(\\mu, \\sigma)\\).\n\n37.4.2 Funzione di ripartizione\nIl valore della funzione di ripartizione di \\(Y\\) nel punto \\(y\\) è l’area sottesa alla curva di densità \\(f(y)\\) nella semiretta \\((-\\infty, y]\\). Non esiste alcuna funzione elementare per la funzione di ripartizione\n\\[\nF(y) = \\int_{-\\infty}^y {1 \\over {\\sigma\\sqrt{2\\pi} }} \\exp \\left\\{-\\frac{(y - \\mu)^2}{2\\sigma^2} \\right\\} dy,\n\\] (eq-gaussian-rip-formula)\npertanto le probabilità \\(P(Y &lt; y)\\) vengono calcolate mediante integrazione numerica approssimata. I valori della funzione di ripartizione di una variabile casuale Normale sono dunque forniti da un software.\nEcco l’equivalente in R utilizzando le funzioni per la distribuzione normale e il pacchetto ggplot2 per i grafici.\n\n37.4.3 Generazione di Valori Casuali\nIn R, la funzione rnorm() genera valori casuali dalla distribuzione normale. Ad esempio, per ottenere un singolo valore casuale dalla \\(\\mathcal{N}(100, 15)\\):\n\n# Generare un singolo valore casuale\nset.seed(123)  # Per la riproducibilità\nrnorm(1, mean = 100, sd = 15)\n#&gt; [1] 91.6\n\nPer estrarre 10 valori casuali dalla stessa distribuzione:\n\n# Generare 10 valori casuali\nset.seed(123)\nqi &lt;- rnorm(10, mean = 100, sd = 15)\nprint(qi)\n#&gt;  [1]  91.6  96.5 123.4 101.1 101.9 125.7 106.9  81.0  89.7  93.3\n\n\n37.4.4 Funzione di Ripartizione (CDF)\nPer calcolare la probabilità che un’osservazione casuale abbia un valore minore o uguale a 115, utilizziamo pnorm():\n\n# Probabilità che X &lt;= 115\npnorm(115, mean = 100, sd = 15)\n#&gt; [1] 0.841\n\n\n37.4.5 Visualizzazione dell’Area Sottesa alla Funzione di Densità\nPossiamo visualizzare l’area sottesa utilizzando ggplot2:\n\n# Parametri\nmu &lt;- 100\nsigma &lt;- 15\n\n# Intervallo di x\nx &lt;- seq(mu - 3 * sigma, mu + 3 * sigma, length.out = 1000)\n\n# Densità\nfx &lt;- dnorm(x, mean = mu, sd = sigma)\n\n# Grafico\nggplot(data.frame(x, fx), aes(x = x, y = fx)) +\n  geom_line(color = \"blue\") +\n  geom_area(\n    data = subset(data.frame(x, fx), x &lt;= 115), \n    aes(x = x, y = fx), fill = \"gray\", alpha = 0.5\n  ) +\n  labs(title = \"Funzione di Densità Normale\", x = \"x\", y = \"f(x)\") \n\n\n\n\n\n\n\n\n37.4.6 Calcolo dell’Integrale con integrate\n\nPossiamo calcolare l’area sotto la curva manualmente utilizzando la funzione integrate:\n\n# Definizione della funzione gaussiana\ngaussian &lt;- function(x, mu, sigma) {\n  (1 / (sqrt(2 * pi) * sigma)) * exp(-((x - mu)^2) / (2 * sigma^2))\n}\n\n# Calcolo dell'area\nresult &lt;- integrate(gaussian, lower = -Inf, upper = 115, mu = 100, sigma = 15)\nprint(paste(\"Il risultato è\", result$value, \"con errore\", result$abs.error))\n#&gt; [1] \"Il risultato è 0.84134474610298 con errore 3.76616994661114e-06\"\n\n\n37.4.7 Proporzione di Valori Maggiori di 130\nCalcoliamo \\(P(X &gt; 130)\\) utilizzando il complementare della funzione di ripartizione:\n\n# Probabilità che X &gt; 130\n1 - pnorm(130, mean = 100, sd = 15)\n#&gt; [1] 0.0228\n\nPossiamo anche utilizzare la funzione di sopravvivenza 1 - pnorm():\n\n# Funzione di sopravvivenza\npnorm(130, mean = 100, sd = 15, lower.tail = FALSE)\n#&gt; [1] 0.0228\n\nVisualizzazione:\n\nggplot(data.frame(x, fx), aes(x = x, y = fx)) +\n  geom_line(color = \"blue\") +\n  geom_area(\n    data = subset(data.frame(x, fx), x &gt;= 130), \n    aes(x = x, y = fx), fill = \"gray\", alpha = 0.5\n  ) +\n  labs(title = \"Area Sottesa per X &gt;= 130\", x = \"x\", y = \"f(x)\") \n\n\n\n\n\n\n\n\n37.4.8 Funzione di Quantile (PPF)\nLa funzione qnorm() restituisce il quantile della distribuzione normale. Ad esempio:\n\n# Quantile corrispondente al 97.725%\nqnorm(1 - 0.022750131948179195, mean = 100, sd = 15)\n#&gt; [1] 130\n\nIn conclusione, le funzioni rnorm, dnorm, pnorm, e qnorm in R forniscono gli strumenti necessari per manipolare la distribuzione normale.\n\n37.4.9 Distribuzione Normale standard\nLa distribuzione Normale di parametri \\(\\mu = 0\\) e \\(\\sigma = 1\\) viene detta distribuzione Normale standard. La famiglia Normale è l’insieme avente come elementi tutte le distribuzioni Normali con parametri \\(\\mu\\) e \\(\\sigma\\) diversi. Tutte le distribuzioni Normali si ottengono dalla Normale standard mediante una trasformazione lineare: se \\(Y \\sim \\mathcal{N}(\\mu_Y, \\sigma_Y)\\) allora\n\\[\nX = a + b Y \\sim \\mathcal{N}(\\mu_X = a+b \\mu_Y, \\sigma_X = \\left|b\\right|\\sigma_Y).\n\\]\nL’area sottesa alla curva di densità di \\(\\mathcal{N}(\\mu, \\sigma)\\) nella semiretta \\((-\\infty, y]\\) è uguale all’area sottesa alla densità Normale standard nella semiretta \\((-\\infty, z]\\), in cui \\(z = (y -\\mu_Y )/\\sigma_Y\\) è il punteggio standard di \\(Y\\). Per la simmetria della distribuzione, l’area sottesa nella semiretta \\([1, \\infty)\\) è uguale all’area sottesa nella semiretta \\((-\\infty, 1]\\) e quest’ultima coincide con \\(F(-1)\\). Analogamente, l’area sottesa nell’intervallo \\([y_a, y_b]\\), con \\(y_a &lt; y_b\\), è pari a \\(F(z_b) - F(z_a)\\), dove \\(z_a\\) e \\(z_b\\) sono i punteggi standard di \\(y_a\\) e \\(y_b\\).\nSi ha anche il problema inverso rispetto a quello del calcolo delle aree: dato un numero \\(0 \\leq p \\leq 1\\), il problema è quello di determinare un numero \\(z \\in \\mathbb{R}\\) tale che \\(P(Z &lt; z) = p\\). Il valore \\(z\\) cercato è detto quantile di ordine \\(p\\) della Normale standard e può essere trovato mediante un software.\nSupponiamo che l’altezza degli individui adulti segua la distribuzione Normale di media \\(\\mu = 1.7\\) m e deviazione standard \\(\\sigma = 0.1\\) m. Vogliamo sapere la proporzione di individui adulti con un’altezza compresa tra \\(1.7\\) e \\(1.8\\) m.\nIl problema ci chiede di trovare l’area sottesa alla distribuzione \\(\\mathcal{N}(\\mu = 1.7, \\sigma = 0.1)\\) nell’intervallo \\([1.7, 1.8]\\):\n\n# Parametri della distribuzione\nmu &lt;- 1.7\nsigma &lt;- 0.1\n\n# Calcolare la probabilità cumulativa\nprob &lt;- pnorm(1.8, mean = mu, sd = sigma) - pnorm(1.7, mean = mu, sd = sigma)\nprint(prob)\n#&gt; [1] 0.341\n\n\n# Generare dati\nx &lt;- seq(mu - 3 * sigma, mu + 3 * sigma, length.out = 1000)\nfx &lt;- dnorm(x, mean = mu, sd = sigma)\n\n# Creare il grafico\nggplot(data.frame(x, fx), aes(x = x, y = fx)) +\n  geom_line(color = \"blue\") +\n  geom_area(data = subset(data.frame(x, fx), x &gt;= 1.7 & x &lt;= 1.8), \n            aes(x = x, y = fx), fill = \"gray\", alpha = 0.5) +\n  labs(title = \"Funzione di Densità Normale\", \n       x = \"Altezza (m)\", \n       y = \"Densità\")\n\n\n\n\n\n\n\nIn maniera equivalente, possiamo standardizzare i valori che delimitano l’intervallo considerato e utilizzare la funzione di ripartizione della normale standardizzata. I limiti inferiore e superiore dell’intervallo sono\n\\[\nz_{\\text{inf}} = \\frac{1.7 - 1.7}{0.1} = 0, \\quad z_{\\text{sup}} = \\frac{1.8 - 1.7}{0.1} = 1.0,\n\\]\nquindi otteniamo\n\n# Standardizzazione\nz_inf &lt;- (1.7 - mu) / sigma\nz_sup &lt;- (1.8 - mu) / sigma\n\n# Calcolo con la normale standardizzata\nprob_standard &lt;- pnorm(z_sup, mean = 0, sd = 1) - pnorm(z_inf, mean = 0, sd = 1)\nprint(prob_standard)\n#&gt; [1] 0.341\n\nIl modo più semplice per risolvere questo problema resta comunque quello di rendersi conto che la probabilità richiesta non è altro che la metà dell’area sottesa dalle distribuzioni Normali nell’intervallo \\([\\mu - \\sigma, \\mu + \\sigma]\\), ovvero \\(0.683/2\\).\nConsideriamo ora la visualizzazione della PDF, la CDF e l’inverso della CDF della distribuzione normale.\n\n# Parametri della distribuzione\nmu &lt;- 100\nsigma &lt;- 15\n\n# Generare intervalli di valori\nx &lt;- seq(mu - 3 * sigma, mu + 3 * sigma, length.out = 1000)\nprobabilities &lt;- seq(0.01, 0.99, length.out = 100)\n\n# Calcolo delle funzioni\npdf &lt;- dnorm(x, mean = mu, sd = sigma)\ncdf &lt;- pnorm(x, mean = mu, sd = sigma)\nppf &lt;- qnorm(probabilities, mean = mu, sd = sigma)\n\n# Creare i grafici con ggplot2\nlibrary(gridExtra)\n\n# Grafico della PDF\npdf_plot &lt;- ggplot(data.frame(x, pdf), aes(x = x, y = pdf)) +\n  geom_line(color = \"blue\") +\n  labs(title = \"PDF\", x = \"Valori\", y = \"Probabilità\")\n\n# Grafico della CDF\ncdf_plot &lt;- ggplot(data.frame(x, cdf), aes(x = x, y = cdf)) +\n  geom_line(color = \"orange\") +\n  labs(title = \"CDF\", x = \"Valori\", y = \"Cumulativa\")\n\n# Grafico dell'inversa della CDF\nppf_plot &lt;- ggplot(data.frame(Probabilità = probabilities, Valori = ppf), aes(x = Probabilità, y = Valori)) +\n  geom_line(color = \"green\") +\n  labs(title = \"Inverse CDF\", x = \"Probabilità\", y = \"Valori\") \n\n# Mostrare i grafici\ngrid.arrange(pdf_plot, cdf_plot, ppf_plot, ncol = 3)\n\n\n\n\n\n\n\nDovrebbe essere chiaro dalla figura che queste sono tre diverse modalità di osservare la stessa informazione.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-chi-quadrato",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-chi-quadrato",
    "title": "37  Distribuzioni di v.c. continue",
    "section": "\n37.5 Distribuzione Chi-quadrato",
    "text": "37.5 Distribuzione Chi-quadrato\nDalla Normale deriva la distribuzione \\(\\chi^2\\). La distribuzione \\(\\chi^2_{~k}\\) con \\(k\\) gradi di libertà descrive la variabile casuale\n\\[\nZ_1^2 + Z_2^2 + \\dots + Z_k^2,\n\\]\ndove \\(Z_1, Z_2, \\dots, Z_k\\) sono variabili casuali i.i.d. che seguono la distribuzione Normale standard \\(\\mathcal{N}(0, 1)\\). La variabile casuale chi-quadrato dipende dal parametro intero positivo \\(\\nu = k\\) che ne identifica il numero di gradi di libertà. La densità di probabilità di \\(\\chi^2_{~\\nu}\\) è\n\\[\nf(x) = C_{\\nu} x^{\\nu/2-1} \\exp (-x/2), \\qquad \\text{se } x &gt; 0,\n\\]\ndove \\(C_{\\nu}\\) è una costante positiva.\nUsiamo la definizione precedente per definire empiricamente la distribuzione della variabile chi-quadrato con 3 gradi di libertà.\n\n# Impostare il seed per la riproducibilità\nset.seed(1234)\n\n# Generare 1000 valori casuali per 3 variabili gaussiane standardizzate\nn &lt;- 1000\nvar1 &lt;- rnorm(n, mean = 0, sd = 1)\nvar2 &lt;- rnorm(n, mean = 0, sd = 1)\nvar3 &lt;- rnorm(n, mean = 0, sd = 1)\n\n# Calcolare la somma dei quadrati delle 3 variabili\nchi_sq_values &lt;- var1^2 + var2^2 + var3^2\n\n# Creare un dataframe per ggplot\ndata &lt;- data.frame(chi_sq_values = chi_sq_values)\n\n# Creare l'istogramma con ggplot\nggplot(data, aes(x = chi_sq_values)) +\n  geom_histogram(\n    aes(y = after_stat(density)), \n    bins = 30, fill = \"lightblue\", color = \"black\", alpha = 0.7\n    ) +\n  stat_function(fun = dchisq, args = list(df = 3), color = \"red\", size = 1) +\n  labs(\n    title = \"Distribuzione Chi-Quadrato (df = 3)\",\n    x = \"Valore\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\nL’istogramma descrive i valori empirici; la curva continua rossa è la distribuzione teorica.\nLa media dei valori empirici è:\n\nmean(chi_sq_values)\n#&gt; [1] 2.98\n\nLa varianza empirica è\n\nvar(chi_sq_values)\n#&gt; [1] 5.97\n\n\n37.5.1 Grafico delle Distribuzioni Chi-Quadrato per Vari Valori di \\(\\nu\\)\n\nIn R, utilizziamo dchisq() per calcolare la funzione di densità della distribuzione chi-quadrato e ggplot2 per creare il grafico.\n\n# Intervallo di x\nx &lt;- seq(0, 40, by = 0.1)\n\n# Valori di gradi di libertà\nnus &lt;- c(2, 4, 8, 16)\n\n# Creazione del data frame per il grafico\ndata &lt;- do.call(rbind, lapply(nus, function(nu) {\n  data.frame(x = x, f_x = dchisq(x, df = nu), nu = as.factor(nu))\n}))\n\n# Grafico\nggplot(data, aes(x = x, y = f_x, color = nu)) +\n  geom_line(size = 1) +\n  labs(\n    title = \"Distribuzioni Chi-Quadrato per Diversi Valori di \\u03bd\",\n    x = \"x\",\n    y = \"f(x)\",\n    color = expression(nu)\n  ) \n\n\n\n\n\n\n\n\n37.5.2 Proprietà della Distribuzione Chi-Quadrato\n\n\nAsimmetria: La distribuzione \\(\\chi^2_{\\nu}\\) è asimmetrica.\n\nMedia: Il valore atteso di una variabile \\(\\chi^2_{\\nu}\\) è uguale a \\(\\nu\\).\n\nVarianza: La varianza è pari a \\(2\\nu\\).\n\nConvergenza: Per \\(k \\to \\infty\\), \\(\\chi^2_{\\nu} \\to \\mathcal{N}(\\nu, 2\\nu)\\).\n\nSomma di variabili: La somma di variabili \\(\\chi^2_{\\nu}\\) indipendenti con gradi di libertà diversi segue una distribuzione \\(\\chi^2_{m}\\), dove \\(m\\) è la somma dei gradi di libertà.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-t-di-student",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-t-di-student",
    "title": "37  Distribuzioni di v.c. continue",
    "section": "\n37.6 Distribuzione \\(t\\) di Student",
    "text": "37.6 Distribuzione \\(t\\) di Student\nLa distribuzione \\(t\\) di Student deriva dalle distribuzioni Normale e Chi-quadrato, ed è una delle distribuzioni fondamentali in statistica inferenziale, specialmente per problemi che coinvolgono campioni di dimensioni limitate.\n\n37.6.1 Definizione Formale\nSe \\(Z \\sim \\mathcal{N}(0, 1)\\) (distribuzione Normale standard) e \\(W \\sim \\chi^2_{\\nu}\\) (distribuzione Chi-quadrato con \\(\\nu\\) gradi di libertà) sono due variabili casuali indipendenti, allora la variabile casuale\n\\[\nT = \\frac{Z}{\\sqrt{\\frac{W}{\\nu}}} ,\n\\]\nsegue una distribuzione \\(t\\) di Student con \\(\\nu\\) gradi di libertà. Si indica come \\(T \\sim t_{\\nu}\\).\n\n37.6.2 Proprietà della Distribuzione \\(t\\) di Student\n\n\nForma della distribuzione:\n\nLa distribuzione \\(t\\) è simile alla distribuzione Normale standard (\\(\\mathcal{N}(0, 1)\\)), ma presenta code più pesanti, che diventano più leggere all’aumentare di \\(\\nu\\).\nPer \\(\\nu \\to \\infty\\), la distribuzione \\(t\\) converge alla distribuzione Normale standard.\n\n\n\nCode più pesanti:\n\nA causa della presenza della variabile Chi-quadrato nel denominatore, la distribuzione \\(t\\) di Student ha una maggiore dispersione rispetto alla Normale.\nLe code pesanti riflettono una maggiore probabilità di valori estremi rispetto alla Normale.\n\n\n\nMedia e varianza:\n\nLa media è \\(0\\), come nella Normale.\nLa varianza è maggiore di \\(1\\) per \\(\\nu &gt; 1\\) ed è definita come \\(\\frac{\\nu}{\\nu - 2}\\) per \\(\\nu &gt; 2\\). Non è definita per \\(\\nu \\leq 2\\).\n\n\n\nApplicazioni:\n\nLa distribuzione \\(t\\) è utilizzata per costruire intervalli di confidenza e testare ipotesi quando la varianza della popolazione è sconosciuta e deve essere stimata dal campione.\n\n\n\n\n37.6.3 Differenze tra la Distribuzione \\(t\\) e la Normale\n\n\n\n\n\n\n\nCaratteristica\nDistribuzione Normale\nDistribuzione \\(t\\) di Student\n\n\n\nForma\nSimmetrica, campana\nSimmetrica, campana\n\n\nCode\nSottili\nPesanti\n\n\nDipendenza dai gradi di libertà\nNo\nSì\n\n\nConvergenza\nNon cambia\nCon \\(\\nu \\to \\infty\\), converge alla Normale\n\n\n\n\n37.6.4 Visualizzazione della Distribuzione \\(t\\)\n\nEcco un esempio in R per confrontare graficamente la distribuzione \\(t\\) di Student con diversi gradi di libertà con la distribuzione Normale standard:\n\n# Creazione dei dati\nx &lt;- seq(-4, 4, length.out = 1000)\ndf &lt;- c(1, 2, 5, 10) # Gradi di libertà\n\n# Dataframe con curve di densità\ndata &lt;- data.frame(\n  x = rep(x, length(df) + 1),\n  density = c(\n    dnorm(x),\n    dt(x, df[1]),\n    dt(x, df[2]),\n    dt(x, df[3]),\n    dt(x, df[4])\n  ),\n  distribution = rep(c(\"Normale\", paste(\"t (df =\", df, \")\")), each = length(x))\n)\n\n# Plot\nggplot(data, aes(x = x, y = density, color = distribution)) +\n  geom_line(size = 1) +\n  labs(\n    title = \"Distribuzione Normale e distribuzioni t di Student\",\n    x = \"Valore\",\n    y = \"Densità\",\n    color = \"Distribuzione\"\n  ) \n\n\n\n\n\n\n\nIn conclusione, la distribuzione \\(t\\) di Student è essenziale per le analisi statistiche su piccoli campioni, grazie alla sua capacità di gestire l’incertezza legata alla stima della varianza. Sebbene assomigli alla distribuzione Normale, le sue code più pesanti rendono i test statistici più robusti in condizioni di varianza incerta.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#funzione-beta-di-eulero",
    "href": "chapters/probability/12_cont_rv_distr.html#funzione-beta-di-eulero",
    "title": "37  Distribuzioni di v.c. continue",
    "section": "\n37.7 Funzione Beta di Eulero",
    "text": "37.7 Funzione Beta di Eulero\nLa funzione Beta di Eulero è una funzione matematica, non una densità di probabilità. La menzioniamo qui perché viene utilizzata nella densità di probabilità Beta. La funzione Beta di Eulero, comunemente indicata con il simbolo \\(B(\\alpha, \\beta)\\), si può scrivere in molti modi diversi; per i nostri scopi la presentiamo così:\n\\[\n\\mathcal{B}(\\alpha, \\beta) = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)}\\,,\n\\]\ndove \\(\\Gamma(x)\\) è la funzione Gamma, ovvero il fattoriale discendente, cioè\n\\[\n(x-1)(x-2)\\ldots (x-n+1)\\notag\\,.\n\\]\nPer esempio, posti \\(\\alpha = 3\\) e \\(\\beta = 9\\), la funzione Beta di Eulero assume il valore:\n\nalpha &lt;- 3\nbeta &lt;- 9\n\nbeta_function &lt;- gamma(alpha) * gamma(beta) / gamma(alpha + beta)\nbeta_function\n#&gt; [1] 0.00202\n\nLo stesso risultato si ottiene usando direttamente la funzione beta in R:\n\nbeta(alpha, beta)\n#&gt; [1] 0.00202\n\nOppure calcolandolo manualmente:\n\n(factorial(alpha - 1) * factorial(beta - 1)) / factorial(alpha + beta - 1)\n#&gt; [1] 0.00202",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-beta",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-beta",
    "title": "37  Distribuzioni di v.c. continue",
    "section": "\n37.8 Distribuzione Beta",
    "text": "37.8 Distribuzione Beta\nLa distribuzione di probabilità Beta, denotata comunemente come \\(\\mathcal{Beta}(\\alpha, \\beta)\\), è utilizzata per modellare fenomeni che sono espressi in percentuali o proporzioni. Un aspetto cruciale di questa distribuzione è la sua definizione esclusiva nell’intervallo \\((0, 1)\\). In pratica, ciò significa che essa considera valori compresi strettamente tra 0 e 1, escludendo sia lo 0 che l’1 come estremi.\n\n37.8.1 Definizione Formale\nConsideriamo una variabile casuale \\(\\theta\\), la quale può assumere qualunque valore nell’intervallo aperto \\((0, 1)\\). Se diciamo che \\(\\theta\\) segue una distribuzione Beta con parametri \\(\\alpha\\) e \\(\\beta\\) (indicato come \\(\\theta \\sim \\mathcal{Beta}(\\alpha, \\beta)\\)), intendiamo che la sua funzione di densità è descritta dalla seguente formula:\n\\[\n\\mathcal{Beta}(\\theta \\mid \\alpha, \\beta) = \\frac{1}{B(\\alpha, \\beta)}\\theta^{\\alpha-1} (1-\\theta)^{\\beta-1} =  \\frac{\\Gamma(\\alpha+ \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}\\theta^{\\alpha-1} (1-\\theta)^{\\beta-1} \\quad \\text{per } \\theta \\in (0, 1)\\,,\n\\]\ndove \\(B(\\alpha, \\beta)\\) è la funzione beta di Eulero, definita come \\(\\frac{\\Gamma(\\alpha) \\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)}\\).\n\n37.8.2 I Parametri \\(\\alpha\\) e \\(\\beta\\)\n\nI parametri \\(\\alpha\\) e \\(\\beta\\) giocano un ruolo cruciale nella distribuzione Beta, influenzando direttamente la sua forma e il suo comportamento. È essenziale che entrambi questi parametri siano positivi.\n\n37.8.3 Intuizione e Collegamento con la Distribuzione Binomiale\nLa distribuzione Beta può essere meglio compresa quando la si osserva in relazione con la distribuzione binomiale. Mentre la distribuzione binomiale modella il numero di successi in una serie di prove, la distribuzione Beta si focalizza sulla probabilità di successo in queste prove.\nNel contesto della distribuzione binomiale, la probabilità di successo è un parametro fisso; nella distribuzione Beta, questa probabilità diventa una variabile aleatoria.\n\n37.8.4 Interpretazione dei Parametri \\(\\alpha\\) e \\(\\beta\\)\n\nI parametri \\(\\alpha\\) e \\(\\beta\\) possono essere interpretati come rappresentanti il numero di successi e insuccessi, rispettivamente. Questa interpretazione è analoga ai termini \\(n\\) e \\(n-x\\) nella distribuzione binomiale.\nLa scelta di \\(\\alpha\\) e \\(\\beta\\) dipende dall’aspettativa iniziale della probabilità di successo: - Se si presume un’alta probabilità di successo (ad esempio, 90%), si potrebbe scegliere \\(\\alpha = 90\\) e \\(\\beta = 10\\). - Al contrario, per una bassa aspettativa di successo, si potrebbe impostare \\(\\alpha = 10\\) e \\(\\beta = 90\\).\nUn aumento di \\(\\alpha\\) (successi) sposta la distribuzione verso destra, mentre un aumento di \\(\\beta\\) (insuccessi) la sposta verso sinistra. Inoltre, se sia \\(\\alpha\\) sia \\(\\beta\\) aumentano, la distribuzione diventa più stretta, indicando una maggiore certezza.\nQuesta interpretazione consente di utilizzare la distribuzione Beta per esprimere le nostre credenze a priori riguardo a una sequenza di prove di Bernoulli, dove il rapporto tra successi e tentativi totali è dato da:\n\\[\n\\frac{\\text{Numero di successi}}{\\text{Numero di successi} + \\text{Numero di insuccessi}} = \\frac{\\alpha}{\\alpha + \\beta}\\notag\\,.\n\\]\nAl variare di \\(\\alpha\\) e \\(\\beta\\) si ottengono molte distribuzioni di forma diversa; un’illustrazione è fornita dalla seguente GIF animata.\nLa figura seguente mostra la distribuzione \\(Beta(x \\mid \\alpha, \\beta)\\) per \\(\\alpha\\) = 0.5, 5.0, 1.0, 2.0, 2.0 e \\(\\beta\\) = 5, 1.0, 3.0, 2.0, 5.0.\n\n# Define the parameters\nx &lt;- seq(0, 1, length.out = 200)\nalphas &lt;- c(0.5, 5.0, 1.0, 2.0, 2.0)\nbetas &lt;- c(0.5, 1.0, 3.0, 2.0, 5.0)\n\n# Create a data frame for plotting\ndf &lt;- do.call(rbind, lapply(1:length(alphas), function(i) {\n  data.frame(\n    x = x,\n    density = dbeta(x, alphas[i], betas[i]),\n    label = paste0(\"α = \", alphas[i], \", β = \", betas[i])\n  )\n}))\n\nggplot(df, aes(x = x, y = density, color = label)) +\n  geom_line(size = 1) +\n  labs(\n    x = \"x\",\n    y = \"f(x)\",\n    title = \"Distribuzioni Beta\"\n  ) +\n  ylim(0, 4.5) +\n  theme(\n    legend.title = element_blank(),\n    legend.position = \"top\"\n  )\n#&gt; Warning: Removed 6 rows containing missing values or values outside the scale range\n#&gt; (`geom_line()`).\n\n\n\n\n\n\n\n\n37.8.5 Costante di normalizzazione\nLa relazione \\(\\frac{1}{B(\\alpha, \\beta)} = \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}\\) definisce il reciproco della funzione Beta di Eulero, \\(B(\\alpha, \\beta)\\), come una costante di normalizzazione. Qui, \\(\\Gamma(\\cdot)\\) denota la funzione Gamma di Eulero. Questa costante di normalizzazione garantisce che\n\\[\n\\int_0^1 \\theta^{\\alpha-1} (1-\\theta)^{\\beta-1} d\\theta = 1\\,,\n\\]\nper \\(\\alpha, \\beta &gt; 0\\). Questa integrazione conferma che \\(\\theta^{\\alpha-1} (1-\\theta)^{\\beta-1}\\), quando moltiplicata per la costante di normalizzazione, forma una densità di probabilità che si estende sull’intervallo \\([0,1]\\), con l’area sottesa dalla curva (l’integrale) uguale a 1.\nAd esempio, con \\(\\alpha = 3\\) e \\(\\beta = 9\\), possiamo calcolare il risultato integrando la funzione \\((p^{\\alpha - 1} \\cdot (1 - p)^{\\beta - 1})\\) su \\([0, 1]\\), usando la funzione integrate in R:\n\n# Definizione della funzione da integrare\nintegrand &lt;- function(p, a, b) {\n  p^(a - 1) * (1 - p)^(b - 1)\n}\n\n# Parametri\na &lt;- 3\nb &lt;- 9\n\n# Calcolo dell'integrale\nresult &lt;- integrate(integrand, lower = 0, upper = 1, a = a, b = b)\nresult$value  # Valore dell'integrale\n#&gt; [1] 0.00202\n\nOtteniamo lo stesso risultato calcolando esplicitamente la funzione Beta di Eulero:\n\n# Calcolo usando la funzione Gamma\nresult_gamma &lt;- gamma(a) * gamma(b) / gamma(a + b)\nresult_gamma\n#&gt; [1] 0.00202\n\nOppure utilizzando la funzione beta già disponibile in R:\n\n# Calcolo con la funzione beta\nresult_beta &lt;- beta(a, b)\nresult_beta\n#&gt; [1] 0.00202\n\nQuesti approcci mostrano che i diversi metodi producono lo stesso valore per la funzione Beta di Eulero.\n\n37.8.6 Proprietà\nIl valore atteso, la moda e la varianza di una densità di probabilità Beta sono dati dalle seguenti equazioni:\n\\[\n\\mathbb{E}(\\theta) = \\frac{\\alpha}{\\alpha+\\beta}\\,,\n\\] (eq-beta-mean)\n\\[\nMo(\\theta) = \\frac{\\alpha-1}{\\alpha+\\beta-2}\\,,\n\\] (eq-beta-mode)\n\\[\n\\mathbb{V}(\\theta) = \\frac{\\alpha \\beta}{(\\alpha+\\beta)^2 (\\alpha+\\beta+1)}\\,.\n\\] (eq-beta-var)\nUsando le formule precedenti, possiamo definire una funzione beta_mean_mode_variance() in R per calcolare la media, la moda e la varianza di una distribuzione di probabilità Beta:\n\n# Funzione per calcolare media, moda e varianza della distribuzione Beta\nbeta_mean_mode_variance &lt;- function(alpha, beta) {\n  mean &lt;- alpha / (alpha + beta)\n  mode &lt;- ifelse(alpha &gt; 1 & beta &gt; 1, (alpha - 1) / (alpha + beta - 2), NA) # Moda definita solo per alpha, beta &gt; 1\n  variance &lt;- (alpha * beta) / ((alpha + beta)^2 * (alpha + beta + 1))\n  list(mean = mean, mode = mode, variance = variance)\n}\n\n# Esempio di utilizzo\nalpha &lt;- 7\nbeta &lt;- 3\nresult &lt;- beta_mean_mode_variance(alpha, beta)\n\n# Stampa dei risultati\ncat(sprintf(\"Mean: %.2f, Mode: %.2f, Variance: %.4f\\n\", result$mean, result$mode, result$variance))\n#&gt; Mean: 0.70, Mode: 0.75, Variance: 0.0191\n\n\n37.8.7 Risultati\nLa funzione calcola: - Media: \\(\\mu = \\frac{\\alpha}{\\alpha + \\beta}\\), - Moda: \\(\\frac{\\alpha - 1}{\\alpha + \\beta - 2}\\) (definita solo per \\(\\alpha &gt; 1\\) e \\(\\beta &gt; 1\\)), - Varianza: \\(\\frac{\\alpha \\cdot \\beta}{(\\alpha + \\beta)^2 \\cdot (\\alpha + \\beta + 1)}\\).\nSe \\(\\alpha\\) o \\(\\beta\\) sono inferiori o uguali a 1, la moda non è definita.\n\n37.8.8 Distribuzione a priori coniugata\nLa distribuzione Beta rappresenta una prior coniugata ottimale per una gamma di distribuzioni legate a eventi di successo e fallimento, quali le distribuzioni Bernoulli, Binomiale, Binomiale Negativa e Geometrica, nell’ambito dell’inferenza Bayesiana. Questa caratteristica di prior coniugata rende il calcolo della distribuzione a posteriori particolarmente efficiente, poiché permette di bypassare onerose computazioni numeriche tipicamente associate all’inferenza Bayesiana.\nPrendiamo, ad esempio, il caso in cui la distribuzione Beta, espressa come Beta(α, β), venga adottata come prior nel contesto di una distribuzione Binomiale. Questa scelta metodologica ci assicura che la distribuzione a posteriori manterrà la forma funzionale della distribuzione Beta. Ciò significa che, una volta raccolti i dati, l’aggiornamento a posteriori può essere eseguito semplicemente aggiungendo il numero di successi osservati (x) e il numero di fallimenti (n-x) ai parametri α e β del prior, rispettivamente. In tal modo, si ottiene una distribuzione a posteriori Beta con parametri aggiornati (α+x, β+n-x), senza la necessità di compiere la moltiplicazione tra la funzione di verosimiglianza e il prior.\n\n\n\n\n\n\nÈ importante prestare attenzione all’uso del termine “Beta” in questo contesto, poiché assume significati differenti a seconda del riferimento: - La distribuzione Beta, che descrive una distribuzione di probabilità continua. - La funzione Beta, una funzione matematica speciale. - Il parametro β, che insieme ad α, definisce i parametri specifici della distribuzione Beta.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-di-cauchy",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-di-cauchy",
    "title": "37  Distribuzioni di v.c. continue",
    "section": "\n37.9 Distribuzione di Cauchy",
    "text": "37.9 Distribuzione di Cauchy\nLa distribuzione di Cauchy è un caso speciale della distribuzione di \\(t\\) di Student con 1 grado di libertà. È definita da una densità di probabilità che corrisponde alla seguente funzione, dipendente da due parametri \\(\\alpha\\) e \\(\\beta\\),\n\\[\nf(x \\mid \\alpha, \\beta) = \\frac{1}{\\pi \\beta \\left[1 + \\left( \\frac{x - \\alpha}{\\beta} \\right)^2\\right]}.\n\\tag{37.3}\\]\nIl grafico mostra alcune distribuzioni di Cauchy con \\(\\alpha\\) = 0., 0., 0., -2.0 e \\(\\beta\\) = .5, 1., 2., 1.0.\n\n# Definire i parametri\nx &lt;- seq(-5, 5, length.out = 500)\nalphas &lt;- c(0.0, 0.0, 0.0, -2.0)\nbetas &lt;- c(0.5, 1.0, 2.0, 1.0)\n\n# Creare un data frame per i risultati\ndf &lt;- do.call(rbind, lapply(1:length(alphas), function(i) {\n  data.frame(\n    x = x,\n    density = dcauchy(x, location = alphas[i], scale = betas[i]),\n    label = paste0(\"α = \", alphas[i], \", β = \", betas[i])\n  )\n}))\n\nggplot(df, aes(x = x, y = density, color = label)) +\n  geom_line(size = 1) +\n  labs(\n    x = \"x\",\n    y = \"f(x)\",\n    title = \"Distribuzioni di Cauchy con diversi parametri\"\n  ) +\n  theme(\n    legend.title = element_blank(),\n    legend.position = \"top\"\n  )",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-gamma",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-gamma",
    "title": "37  Distribuzioni di v.c. continue",
    "section": "\n37.10 Distribuzione Gamma",
    "text": "37.10 Distribuzione Gamma\nLa distribuzione Gamma è ampiamente utilizzata nella statistica bayesiana come distribuzione a priori per parametri che sono strettamente positivi, come tassi o varianze. È particolarmente utile nella modellazione di variabili che rappresentano tempi di attesa o qualsiasi altra quantità che può assumere solo valori positivi. La densità di probabilità Gamma gioca un ruolo fondamentale nella modellazione del tempo di attesa per l’occorrenza di un certo numero di eventi indipendenti e rari, rendendola adatta per processi di Poisson generalizzati.\nLa distribuzione Gamma può essere vista come una generalizzazione della distribuzione esponenziale. Più precisamente, la distribuzione esponenziale è un caso speciale della distribuzione Gamma. Se sommiamo \\(n\\) variabili casuali indipendenti, ciascuna delle quali segue una distribuzione esponenziale con parametro \\(\\lambda\\), il risultato segue una distribuzione Gamma con parametri \\(n\\) (numero di variabili sommate) e \\(\\lambda\\) (tasso esponenziale). Questo si formalizza come:\n\\[\n\\text{Gamma}(n, \\lambda) = \\sum_{i=1}^n \\text{Esponenziale}(\\lambda).\n\\]\nIn particolare, la distribuzione Gamma con parametro di forma 1, ovvero \\(\\text{Gamma}(1, \\lambda)\\), corrisponde esattamente a una distribuzione esponenziale con parametro \\(\\lambda\\), cioè:\n\\[\n\\text{Gamma}(1, \\lambda) = \\text{Esponenziale}(\\lambda).\n\\]\nLa distribuzione Gamma è anche legata alla distribuzione normale in alcuni contesti. Sebbene non vi sia una relazione diretta e semplice tra una distribuzione Gamma e una normale, un caso specifico è quando il parametro di forma \\(n\\) è molto grande (cioè \\(n \\to \\infty\\)). In questo caso, la distribuzione Gamma può essere approssimata da una distribuzione normale tramite il teorema del limite centrale. Più precisamente, quando \\(n\\) è grande, una Gamma di parametri \\(n\\) e \\(\\lambda\\) converge approssimativamente a una normale con media \\(n/\\lambda\\) e varianza \\(n/\\lambda^2\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#parametrizzazione",
    "href": "chapters/probability/12_cont_rv_distr.html#parametrizzazione",
    "title": "37  Distribuzioni di v.c. continue",
    "section": "\n37.11 Parametrizzazione",
    "text": "37.11 Parametrizzazione\nLa distribuzione Gamma è caratterizzata da due parametri principali: \\(\\alpha\\) e \\(\\beta\\), noti rispettivamente come parametro di forma e parametro di tasso (o, alternativamente, si può usare \\(\\theta = \\frac{1}{\\beta}\\), il parametro di scala).\n\n37.11.1 Parametro di forma (\\(\\alpha\\))\nIl parametro di forma, \\(\\alpha\\), determina la forma generale della curva della distribuzione:\n\nSe \\(\\alpha = 1\\), la distribuzione Gamma si riduce a una distribuzione esponenziale, con la funzione di densità \\(f(x) = \\beta e^{-\\beta x}\\).\nSe \\(\\alpha &gt; 1\\), la distribuzione presenta un picco (modalità) attorno a \\((\\alpha - 1) \\cdot \\theta\\), indicando una distribuzione più concentrata attorno a un valore medio.\nSe \\(\\alpha &lt; 1\\), la distribuzione è inclinata verso destra, con una coda lunga che si estende verso valori più bassi, mostrando una maggiore probabilità di valori piccoli di \\(x\\).\n\nIl parametro \\(\\alpha\\) può essere interpretato come il numero di “eventi” che ci si aspetta si verifichino prima di raggiungere un certo tempo di attesa, in contesti di modelli di Poisson generalizzati. Ad esempio, se la distribuzione Gamma modella il tempo di attesa per l’arrivo di un certo numero di eventi, \\(\\alpha\\) indica il numero di eventi attesi.\nMan mano che \\(\\alpha\\) aumenta, la distribuzione si sposta verso destra e diventa più simmetrica. Per valori alti di \\(\\alpha\\), la distribuzione Gamma si avvicina a una distribuzione normale.\n\n37.11.2 Parametro di scala (\\(\\theta\\)) o tasso (\\(\\beta\\))\nIl parametro \\(\\theta\\) (o, alternativamente, \\(\\beta\\)) controlla la scala temporale o la larghezza della distribuzione:\n\nIl parametro di scala \\(\\theta\\) è inversamente proporzionale al parametro di tasso \\(\\beta\\). Un valore più grande di \\(\\theta\\) (o un valore più piccolo di \\(\\beta\\)) produce una curva più piatta, indicando una maggiore variabilità (dispersione) nel tempo di attesa.\nUn valore più piccolo di \\(\\theta\\) (o più grande di \\(\\beta\\)) rende la curva più appuntita, indicando una minore variabilità.\n\nNel contesto del tempo di attesa, \\(\\theta\\) agisce come un fattore di scala: un valore grande di \\(\\theta\\) indica un periodo di tempo più lungo tra gli eventi, mentre un valore piccolo di \\(\\theta\\) indica un periodo di tempo più breve.\n\n37.11.3 Formula della funzione di densità di probabilità\nLa funzione di densità di probabilità (PDF) della distribuzione Gamma è data da:\n\\[\nf(x \\mid \\alpha, \\theta) = \\frac{x^{\\alpha-1} e^{-\\frac{x}{\\theta}}}{\\theta^\\alpha \\Gamma(\\alpha)},\n\\]\ndove:\n\n\n\\(x\\) è la variabile casuale continua, con \\(x &gt; 0\\),\n\n\\(\\alpha\\) è il parametro di forma,\n\n\\(\\theta\\) è il parametro di scala (alternativamente si può usare \\(\\beta = \\frac{1}{\\theta}\\), il parametro di tasso),\n\n\\(\\Gamma(\\alpha)\\) è la funzione Gamma di Eulero, che generalizza il fattoriale per numeri reali e complessi. Per numeri interi \\(n\\), si ha \\(\\Gamma(n) = (n-1)!\\), ma per argomenti generali \\(\\alpha\\), la funzione Gamma è definita come:\n\n\\[\n\\Gamma(\\alpha) = \\int_0^\\infty x^{\\alpha-1} e^{-x} dx.\n\\]\n\n37.11.4 Media e varianza della distribuzione Gamma\nLe espressioni per la media e la varianza della distribuzione Gamma in funzione di \\(\\alpha\\) e \\(\\theta\\) (o \\(\\beta\\)) sono:\n\nMedia (\\(\\mu\\)):\n\n\\[\n\\mu = \\alpha \\cdot \\theta = \\frac{\\alpha}{\\beta}.\n\\]\n\nVarianza (\\(\\sigma^2\\)): \\[\n\\sigma^2 = \\alpha \\cdot \\theta^2 = \\frac{\\alpha}{\\beta^2}.\n\\]\n\n\nIn sintesi, il parametro di forma \\(\\alpha\\) controlla la forma generale della distribuzione, mentre il parametro di scala \\(\\theta\\) (o tasso \\(\\beta\\)) regola la dispersione o variabilità. Questa parametrizzazione è largamente utilizzata, in particolare nella statistica bayesiana, dove la distribuzione Gamma può servire da distribuzione a priori per parametri positivi, come varianze o tassi di processi stocastici.\nPer esempio, qui è riportata la distribuzione Gamma di parametri \\(\\alpha\\) = 3 e \\(\\beta\\) = 5/3.\n\n37.11.5 Calcolo della Media e della Deviazione Standard per la Distribuzione Gamma\nLa distribuzione Gamma è definita dai parametri \\(\\alpha\\) (shape) e \\(\\beta\\) (rate). La media e la deviazione standard della distribuzione possono essere calcolate come segue:\n\n\nMedia: \\(\\mu = \\frac{\\alpha}{\\beta}\\)\n\n\nDeviazione Standard: \\(\\sigma = \\sqrt{\\frac{\\alpha}{\\beta^2}}\\)\n\n\n\n37.11.5.1 Calcolo in R\n\n# Parametri della distribuzione Gamma\nalpha &lt;- 3\nbeta &lt;- 5 / 3\n\n# Calcolo della media\nmean &lt;- alpha / beta\ncat(\"Mean:\", mean, \"\\n\")\n#&gt; Mean: 1.8\n\n# Calcolo della deviazione standard\nsigma &lt;- sqrt(alpha / beta^2)\ncat(\"Standard Deviation:\", sigma, \"\\n\")\n#&gt; Standard Deviation: 1.04\n\n\n37.11.6 Generazione di Dati dalla Distribuzione Gamma e Visualizzazione\n\n37.11.6.1 Generazione di dati\nIn R, possiamo utilizzare la funzione rgamma() per generare dati da una distribuzione Gamma specificando i parametri shape (\\(\\alpha\\)) e rate (\\(\\beta\\)).\n\n37.11.6.2 Plot della Distribuzione\n\n# Generazione di dati\nset.seed(123)  # Per riproducibilità\ndata &lt;- rgamma(100000, shape = alpha, rate = beta)\n\n# Creazione di un data frame per ggplot\ndf &lt;- data.frame(values = data)\n\n# Istogramma dei dati generati\nggplot(df, aes(x = values)) +\n  geom_histogram(aes(y = ..density..), bins = 30, fill = \"green\", alpha = 0.6) +\n  stat_function(fun = function(x) dgamma(x, shape = alpha, rate = beta),\n                color = \"red\", size = 1, linetype = \"solid\") +\n  labs(\n    x = \"Valore\",\n    y = \"Densità di probabilità\",\n    title = \"Distribuzione Gamma con α=3 e β=5/3\"\n  ) \n#&gt; Warning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\n#&gt; ℹ Please use `after_stat(density)` instead.\n\n\n\n\n\n\n\nSpiegazione del Codice.\n\n\nCalcolo della media e della deviazione standard:\n\nLa media è calcolata come il rapporto tra i parametri \\(\\alpha\\) e \\(\\beta\\).\nLa deviazione standard è la radice quadrata del rapporto tra \\(\\alpha\\) e \\(\\beta^2\\).\n\n\n\nGenerazione dei dati:\n\n\nrgamma(n, shape, rate) genera \\(n\\) osservazioni dalla distribuzione Gamma specificata.\n\n\n\nVisualizzazione:\n\nL’istogramma rappresenta i dati generati.\nLa funzione dgamma(x, shape, rate) calcola la densità teorica, che viene tracciata sopra l’istogramma per confrontare i dati simulati con la distribuzione teorica.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-esponenziale-1",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-esponenziale-1",
    "title": "37  Distribuzioni di v.c. continue",
    "section": "\n37.12 Distribuzione Esponenziale",
    "text": "37.12 Distribuzione Esponenziale\nLa distribuzione esponenziale è una distribuzione di probabilità continua che descrive la “durata di vita” di un fenomeno che non invecchia (ossia la distribuzione esponenziale è priva di memoria).\nLa distribuzione esponenziale (o di Laplace) può anche essere ricavata come la distribuzione di probabilità di una variabile aleatoria definita come somma dei quadrati di due variabili aleatorie normali standardizzate (ossia con valore atteso zero e varianza unitaria); dunque è riconducibile a un caso particolare di distribuzione del chi-quadro, essendo, quest’ultima, la distribuzione di probabilità della variabile aleatoria costruita come la somma dei quadrati di \\(n\\) variabili aleatorie indipendenti normali e standardizzate.\nLa distribuzione esponenziale con parametro \\({\\displaystyle \\lambda &gt;0}\\), ha funzione di densità di probabilità:\n\\[\n{\\displaystyle f(x;\\lambda )={\\begin{cases}\\lambda e^{-\\lambda x}&x&gt;0,\\\\0&x\\leq 0.\\end{cases}}}.\n\\]\nUna variabile aleatoria con distribuzione esponenziale di parametro \\({\\displaystyle \\lambda }\\) ha\n\nvalore atteso \\({\\displaystyle E[X]=1/\\lambda }\\),\nvarianza \\({\\displaystyle {\\text{Var}}(X)=1/\\lambda ^{2}}.\\)\n\n\nPer fare un esempio, consideriamo il punteggio totale della scala psicologica di Kessler (K6), una misura standardizzata utilizzata dal NHIS per lo screening del disagio psicologico. La K6 include sei item relativi alla sintomatologia depressiva e ansiosa e valuta il disagio psicologico aspecifico degli ultimi 30 giorni. Gli item sono valutati su una scala Likert a 5 punti, che va da “mai” (=0) a “sempre” (=4). I punteggi totali variano da 0 a 24. Secondo Tomitaka et al. (2019), il punteggio totale della K6 segue una distribuzione esponenziale, con punteggi di cut-off per disagio psicologico moderato e grave corrispondenti a punteggi di 5 e 13, rispettivamente. Dallo studio emerge che il punteggio medio del totale della K6 nella popolazione americana è di 2.5. La corrispondente distribuzione esponenziale è rappresentata di seguito.\n\n# Parametri della distribuzione Esponenziale\nmean &lt;- 2.5\nlambda &lt;- 1 / mean  # Lambda è l'inverso della media\n\n# Creazione del vettore x\nx &lt;- seq(0.001, 22, length.out = 100)\n\n# Calcolo della densità\npdf &lt;- dexp(x, rate = lambda)\n\n# Creazione del data frame per ggplot\ndf &lt;- data.frame(x = x, pdf = pdf)\n\n# Tracciamento del grafico\nlibrary(ggplot2)\nggplot(df, aes(x = x, y = pdf)) +\n  geom_line(color = \"blue\", size = 1) +\n  labs(\n    x = \"x\",\n    y = \"f(x)\",\n    title = \"Distribuzione Esponenziale\"\n  ) +\n  annotate(\"text\", x = 10, y = max(pdf)/2, label = paste0(\"λ = \", round(lambda, 2)), size = 5, color = \"blue\")",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#riflessioni-conclusive-in-r",
    "href": "chapters/probability/12_cont_rv_distr.html#riflessioni-conclusive-in-r",
    "title": "37  Distribuzioni di v.c. continue",
    "section": "\n37.13 Riflessioni Conclusive in R",
    "text": "37.13 Riflessioni Conclusive in R\nLa statistica bayesiana utilizza le distribuzioni di probabilità per la stima dei parametri e dell’incertezza. Possiamo considerare le distribuzioni di probabilità come “mattoncini” con cui costruire modelli statistici, dai più semplici ai più complessi. R offre strumenti per generare campioni casuali e calcolare densità, probabilità cumulate, e quantili per molte distribuzioni di probabilità.\n\n37.13.1 Generazione di Campioni\nIn R, possiamo generare campioni da diverse distribuzioni utilizzando le funzioni rnorm, runif, rt, rbeta, e rgamma. Ad esempio:\nDistribuzione Normale:\nset.seed(42)  # Per garantire la riproducibilità\nmedia &lt;- 0\ndeviazione_standard &lt;- 1\ncampione_normale &lt;- rnorm(100, mean = media, sd = deviazione_standard)\nDistribuzione Uniforme:\na &lt;- 0\nb &lt;- 10\ncampione_uniforme &lt;- runif(100, min = a, max = b)\nDistribuzione t di Student:\ngradi_libertà &lt;- 10\ncampione_t &lt;- rt(100, df = gradi_libertà)\nDistribuzione Beta:\nalpha &lt;- 2\nbeta_param &lt;- 5\ncampione_beta &lt;- rbeta(100, shape1 = alpha, shape2 = beta_param)\nDistribuzione Gamma:\nforma &lt;- 2\nscala &lt;- 1\ncampione_gamma &lt;- rgamma(100, shape = forma, rate = 1 / scala)\n\n\n37.13.1.1 Calcolo della Densità\nPossiamo calcolare la densità utilizzando le funzioni dnorm, dunif, dt, dbeta, e dgamma. Ad esempio:\nDistribuzione Normale:\nx &lt;- seq(media - 4 * deviazione_standard, media + 4 * deviazione_standard, length.out = 100)\npdf_normale &lt;- dnorm(x, mean = media, sd = deviazione_standard)\nDistribuzione Uniforme:\nx &lt;- seq(a, b, length.out = 100)\npdf_uniforme &lt;- dunif(x, min = a, max = b)\nDistribuzione t di Student:\nx &lt;- seq(-5, 5, length.out = 100)\npdf_t &lt;- dt(x, df = gradi_libertà)\nDistribuzione Beta:\nx &lt;- seq(0, 1, length.out = 100)\npdf_beta &lt;- dbeta(x, shape1 = alpha, shape2 = beta_param)\nDistribuzione Gamma:\nx &lt;- seq(0, 10, length.out = 100)\npdf_gamma &lt;- dgamma(x, shape = forma, rate = 1 / scala)\n\n37.13.1.2 Calcolo dei Quantili\nI quantili si calcolano con le funzioni qnorm, qunif, qt, qbeta, e qgamma. Ad esempio:\nDistribuzione Normale:\nprobabilità &lt;- 0.5\nquantile_normale &lt;- qnorm(probabilità, mean = media, sd = deviazione_standard)\nDistribuzione Uniforme:\nquantile_uniforme &lt;- qunif(probabilità, min = a, max = b)\nDistribuzione t di Student:\nquantile_t &lt;- qt(probabilità, df = gradi_libertà)\nDistribuzione Beta:\nquantile_beta &lt;- qbeta(probabilità, shape1 = alpha, shape2 = beta_param)\nDistribuzione Gamma:\nquantile_gamma &lt;- qgamma(probabilità, shape = forma, rate = 1 / scala)\n\n37.13.1.3 Calcolo delle Probabilità Cumulate\nLe probabilità cumulate si calcolano con le funzioni pnorm, punif, pt, pbeta, e pgamma. Ad esempio:\nDistribuzione Normale:\nquantile &lt;- 0\nprobabilità_normale &lt;- pnorm(quantile, mean = media, sd = deviazione_standard)\nDistribuzione Uniforme:\nprobabilità_uniforme &lt;- punif(quantile, min = a, max = b)\nDistribuzione t di Student:\nprobabilità_t &lt;- pt(quantile, df = gradi_libertà)\nDistribuzione Beta:\nprobabilità_beta &lt;- pbeta(quantile, shape1 = alpha, shape2 = beta_param)\nDistribuzione Gamma:\nprobabilità_gamma &lt;- pgamma(quantile, shape = forma, rate = 1 / scala)\n\nCon questi strumenti, R consente di generare, visualizzare e analizzare campioni da una vasta gamma di distribuzioni di probabilità, fornendo un potente supporto all’inferenza bayesiana e alla modellazione statistica.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#esercizi",
    "href": "chapters/probability/12_cont_rv_distr.html#esercizi",
    "title": "37  Distribuzioni di v.c. continue",
    "section": "\n37.14 Esercizi",
    "text": "37.14 Esercizi\n\nEsercizio 37.1 Per ciascuna delle distribuzioni di massa di probabilità discusse, utilizza R per:\n\ncreare un grafico della funzione, scegliendo opportunamente i parametri;\nestrarre un campione di 1000 valori casuali dalla distribuzione e visualizzarlo con un istogramma;\ncalcolare la media e la deviazione standard dei campioni e confrontarle con i valori teorici attesi;\nstimare l’intervallo centrale del 94% utilizzando i campioni simulati;\ndeterminare i quantili della distribuzione per gli ordini 0.05, 0.25, 0.75 e 0.95;\nscegliendo un valore della distribuzione pari alla media più una deviazione standard, calcolare la probabilità che la variabile aleatoria assuma un valore minore o uguale a questo valore.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/12_cont_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "title": "37  Distribuzioni di v.c. continue",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] see_0.9.0        gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1\n#&gt;  [5] psych_2.4.12     scales_1.3.0     markdown_1.13    knitr_1.49      \n#&gt;  [9] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [13] purrr_1.0.2      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [17] ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.3         rlang_1.1.4       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       yaml_2.3.10       tools_4.4.2       parallel_4.4.2   \n#&gt; [21] tzdb_0.4.0        colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5      \n#&gt; [25] R6_2.5.1          lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3  \n#&gt; [29] pillar_1.10.0     gtable_0.3.6      glue_1.8.0        xfun_0.49        \n#&gt; [33] tidyselect_1.2.1  farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-166     \n#&gt; [37] labeling_0.4.3    rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#bibliografia",
    "href": "chapters/probability/12_cont_rv_distr.html#bibliografia",
    "title": "37  Distribuzioni di v.c. continue",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlitzstein, J. K., & Hwang, J. (2019). Introduction to probability. CRC Press.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nTomitaka, S., Kawasaki, Y., Ide, K., Akutagawa, M., Ono, Y., & Furukawa, T. A. (2019). Distribution of psychological distress is stable in recent decades and follows an exponential pattern in the US population. Scientific reports, 9(1), 11982.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_gauss.html",
    "href": "chapters/probability/13_gauss.html",
    "title": "38  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "",
    "text": "38.1 Introduzione\nNell’analisi dei dati numerici, un aspetto cruciale da affrontare è l’imprecisione delle misurazioni, una caratteristica intrinseca dei dati reali. Anche in condizioni ottimali, le misure sono soggette a incertezze: i dati rappresentano sempre una stima approssimativa della realtà, accurata solo entro un certo margine (ad esempio, pochi punti percentuali). Inoltre, in molti contesti, come quelli demografici, commerciali o sociali, i dati possono essere arrotondati intenzionalmente o risultare imprecisi a causa di stime indirette, incompletezza delle informazioni o altri fattori.\nRiconoscere e gestire questa incertezza è una componente essenziale del processo analitico. Gli strumenti statistici forniscono un framework formale per descrivere e quantificare l’incertezza, consentendo di trarre inferenze robuste dai dati. Tra le distribuzioni di probabilità, la distribuzione normale (o gaussiana) occupa un posto centrale per la sua ubiquità e versatilità. Spesso rappresentata dalla caratteristica “curva a campana,” questa distribuzione è utilizzata per descrivere molte variabili naturali. Quando i dati approssimano una distribuzione normale, gran parte dei valori si concentra intorno alla media, con una diminuzione progressiva della probabilità di valori estremi.\nUna delle proprietà più utili della distribuzione normale è la possibilità di esprimere affermazioni quantitative rigorose. Ad esempio, si può calcolare la probabilità che un valore cada entro un determinato intervallo dalla media utilizzando parametri semplici come media (\\(\\mu\\)) e deviazione standard (\\(\\sigma\\)):\npnorm(1) - pnorm(-1)\n#&gt; [1] 0.683\npnorm(3) - pnorm(-3)\n#&gt; [1] 0.997\nQuesti calcoli costituiscono la base della “regola delle tre sigma,” una strategia utilizzata per identificare valori anomali (outlier), come discusso nel Capitolo 24. Tuttavia, tale regola può risultare fuorviante se i dati non seguono effettivamente una distribuzione normale.\nLa densità della distribuzione normale è definita dalla formula:\n\\[\np(x) = \\frac{1}{\\sqrt{2\\pi}\\,\\sigma} \\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right),\n\\]\ndove \\(\\mu\\) rappresenta la media e \\(\\sigma\\) la deviazione standard. Conoscere questi due parametri permette di calcolare proprietà fondamentali della distribuzione e di stimare probabilità associate a intervalli specifici.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_gauss.html#introduzione",
    "href": "chapters/probability/13_gauss.html#introduzione",
    "title": "38  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "",
    "text": "Circa il 68.3% dei valori cade entro una deviazione standard dalla media:\n\n\n\nCirca il 99.7% cade entro tre deviazioni standard:\n\n\n\n\n\n\n\n38.1.1 Gaussianità e Inferenza Statistica\nLa distribuzione normale è particolarmente rilevante per molti metodi statistici, in particolare nell’approccio frequentista. Gran parte dei test di ipotesi e delle procedure inferenziali assume che i dati siano distribuiti normalmente, una condizione necessaria per derivare formalmente i risultati di molti test. Ad esempio, i test t di Student e l’ANOVA richiedono la normalità delle variabili o dei residui. Quando questa assunzione è soddisfatta, tali strumenti offrono inferenze precise e affidabili.\nTuttavia, se i dati non sono gaussiani, molti test perdono validità. Sebbene si siano proposti approcci che dimostrano la robustezza di alcuni test a deviazioni moderate dalla normalità (Shatz, 2024), tale robustezza non è garantita in tutte le situazioni. Inoltre, l’enfasi sui valori-p complica la questione, poiché violazioni dell’assunzione di normalità possono compromettere l’interpretazione di questi indicatori.\nUna strategia comune per affrontare la non-gaussianità è l’applicazione di trasformazioni dei dati, come la trasformazione logaritmica o quella della radice quadrata, per avvicinare i dati alla distribuzione normale (Osborne, 2002). Ad esempio, distribuzioni asimmetriche come quelle dei tempi di reazione possono essere rese più gaussiane attraverso trasformazioni adeguate, rendendo applicabili i test frequentisti standard. Tuttavia, l’uso delle trasformazioni ha un costo: la perdita di interpretabilità. Se i dati originali avevano un significato chiaro e intuitivo, la trasformazione può rendere i risultati più difficili da collegare al fenomeno studiato.\nIn questo capitolo, esploreremo come verificare se i dati seguono una distribuzione normale, discuteremo l’impatto di questa assunzione sui metodi frequentisti e valuteremo il ruolo delle trasformazioni. Il nostro obiettivo è fornire al data analyst una guida pratica per decidere come trattare i dati non gaussiani, considerando sia i vantaggi che i limiti di ciascun approccio.\n\n38.1.2 L’assunzione di Gaussianità: Quando è valida?\nSebbene la distribuzione normale sia spesso un buon modello per i dati numerici, non è sempre una rappresentazione adeguata. Questo può dipendere da caratteristiche intrinseche dei dati, come asimmetrie, code lunghe o la presenza di valori anomali. Valutare l’appropriatezza dell’assunzione di normalità è un passaggio critico in qualsiasi analisi statistica.\nPer diagnosticare la normalità, presenteremo tre strumenti grafici:\n\n\nIstogrammi, una visualizzazione semplice ma spesso limitata.\n\nGrafici di densità, che forniscono un confronto più fluido rispetto agli istogrammi.\n\nQQ-plot (Quantile-Quantile plot), uno strumento visivo particolarmente efficace per rilevare deviazioni dalla normalità.\n\nQuesti strumenti possono anche essere affiancati da test formali per consentire una diagnosi robusta e guidare le decisioni sul trattamento dei dati.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_gauss.html#istogramma",
    "href": "chapters/probability/13_gauss.html#istogramma",
    "title": "38  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "\n38.2 Istogramma",
    "text": "38.2 Istogramma\nPer illustrare il concetto, utilizziamo un set di dati simulati che hanno proprietà simili a quelle dei tempi di reazione. Creeremo un istogramma e vi sovrapporremo la curva di densità normale calcolata in base ai dati.\n\n# Dati simulati di tempi di reazione\nset.seed(123)\nrt &lt;- c(rexp(100, rate = 0.2), 50, 60) # Aggiunti valori estremi\n\n# Calcolare la media e la deviazione standard per sovrapporre la densità normale\nmean_rt &lt;- mean(rt, na.rm = TRUE)\nsd_rt &lt;- sd(rt, na.rm = TRUE)\n\n# Creare l'istogramma e sovrapporre la densità normale\nggplot(tibble(rt=rt), aes(x = rt)) +\n  geom_histogram(\n    aes(y = ..density..),\n    bins = 30, color = \"black\"\n  ) +\n  stat_function(\n    fun = dnorm,\n    args = list(mean = mean_rt, sd = sd_rt),\n    size = 1\n  ) +\n  labs(\n    title = \"Istogramma dei Tempi di Reazione\\ne Densità Normale\",\n    x = \"Tempi di Reazione\",\n    y = \"Densità\"\n  )\n#&gt; Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#&gt; ℹ Please use `linewidth` instead.\n#&gt; Warning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\n#&gt; ℹ Please use `after_stat(density)` instead.\n\n\n\n\n\n\n\nL’istogramma mostra la distribuzione empirica dei dati, mentre la curva rossa rappresenta la densità normale con la stessa media e deviazione standard. Nel nostro caso, è evidente una discrepanza tra la distribuzione empirica e la densità normale, indicando che l’assunzione di normalità non è appropriata.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_gauss.html#grafico-di-densità",
    "href": "chapters/probability/13_gauss.html#grafico-di-densità",
    "title": "38  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "\n38.3 Grafico di densità",
    "text": "38.3 Grafico di densità\nUn grafico di densità è una versione lisciata dell’istogramma che facilita il confronto con la distribuzione normale. Utilizzando il dataset precedente, possiamo creare un grafico di densità sovrapposto alla curva gaussiana.\n\nggplot(tibble(rt=rt), aes(x = rt)) +\n  geom_density(alpha = 0.5) +\n  stat_function(\n    fun = dnorm,\n    args = list(mean = mean_rt, sd = sd_rt),\n    size = 1\n  ) +\n  labs(\n    title = \"Grafico di Densità del Peso dei Pulcini e\\nDensità Normale\",\n    x = \"Peso\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\nAnche questa rappresentazione rende chiaro come l’assunzione di normalità non sia appropriata.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_gauss.html#diagramma-quantile-quantile",
    "href": "chapters/probability/13_gauss.html#diagramma-quantile-quantile",
    "title": "38  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "\n38.4 Diagramma quantile-quantile",
    "text": "38.4 Diagramma quantile-quantile\nIl diagramma quantile-quantile (QQ-plot) è lo strumento più utile per analizzare visivamente la conformità di un dataset a una distribuzione teorica, in particolare alla distribuzione normale. Il QQ-plot è una tecnica essenziale per chi lavora con dati che si presume seguano una distribuzione specifica, e rappresenta un passaggio cruciale in molte analisi statistiche, soprattutto per verificare l’assunto di normalità.\nUn QQ-plot permette di:\n\n\nValutare graficamente la normalità dei dati: Se i punti nel diagramma seguono approssimativamente una linea retta, i dati possono essere considerati normalmente distribuiti. In caso contrario, il QQ-plot rivela deviazioni dalla normalità, come code pesanti o asimmetrie.\n\nConfrontare distribuzioni: Il QQ-plot non si limita solo alla distribuzione normale, ma può essere utilizzato per confrontare la distribuzione del campione con qualsiasi distribuzione teorica, facilitando l’analisi di dati con forme di distribuzione complesse.\n\nIdentificare outlier: Gli outlier nei dati saranno visibili come punti che si discostano significativamente dalla linea retta del QQ-plot.\n\nIl QQ-plot è costruito tracciando i quantili del campione contro i quantili teorici di una distribuzione di riferimento. L’interpretazione è piuttosto semplice:\n\nSe il campione segue la distribuzione teorica, i punti nel QQ-plot si allineano lungo una linea retta di pendenza 1 (e intercetta 0 nel caso di distribuzione normale standardizzata).\nLa deviazione dalla linea retta indica differenze nella distribuzione del campione rispetto alla distribuzione teorica:\n\n\nIntercetta diversa da 0: indica che la media del campione differisce dalla media della distribuzione teorica.\n\nPendenza diversa da 1: indica una differenza nella varianza tra il campione e la distribuzione teorica.\n\nCurve: indicano deviazioni sistematiche, come code pesanti o distribuzioni asimmetriche.\n\n\n\nNella discussione seguente, costruiremo e analizzeremo QQ-plot per tre casi tipici:\n\n\nCampione con stessa media e varianza della distribuzione teorica.\n\nCampione con media diversa ma stessa varianza.\n\nCampione con media e varianza diverse.\n\nSimuleremo i dati, li ordineremo, calcoleremo manualmente i quantili teorici e infine utilizzeremo librerie specializzate per replicare e confrontare i risultati. Questo approccio pratico ci permetterà di comprendere a fondo l’utilità e il funzionamento del QQ-plot.\n\n38.4.1 Comprendere e Costruire un QQ-Plot (Distribuzione Normale)\nUn QQ-plot (Quantile-Quantile plot) è uno strumento grafico utilizzato per confrontare la distribuzione di un campione con una distribuzione teorica, spesso la distribuzione normale. Il QQ-plot aiuta a visualizzare se un dataset segue una distribuzione specifica, tracciando i quantili del campione contro i quantili della distribuzione teorica.\n\n38.4.2 Passi per Costruire un QQ-Plot\n\n\nOrdinare i Dati: Disporre i dati del campione in ordine crescente.\n\nDeterminare i Quantili Teorici: Per una distribuzione normale, i quantili corrispondono all’inverso della funzione di distribuzione cumulativa (CDF) della distribuzione normale.\n\nConfrontare i Quantili: Tracciare i quantili del campione rispetto ai quantili della distribuzione teorica. Se il campione proviene dalla distribuzione teorica, i punti dovrebbero trovarsi approssimativamente su una linea retta.\n\n38.4.3 Caso 1: Campione con Stessa Media e Varianza della Distribuzione Normale\nSupponiamo che il campione provenga da una distribuzione normale \\(N(\\mu = 0, \\sigma^2 = 1)\\), esattamente come la distribuzione teorica.\n\n38.4.3.1 Simulazione dei Dati\nIniziamo simulando un piccolo dataset da \\(N(0, 1)\\):\n\n# Generiamo 20 punti dati da N(0, 1)\nset.seed(42)  # Per garantire la riproducibilità\ndati_campione &lt;- rnorm(20, mean = 0, sd = 1)\n\n# Ordiniamo i dati del campione\ncampione_ordinato &lt;- sort(dati_campione)\n\n# Calcoliamo i quantili teorici da N(0, 1)\nquantili_teorici &lt;- qnorm((seq(1, 20) - 0.5) / 20)\n\n# Tracciamo il QQ-plot\nplot(quantili_teorici, campione_ordinato,\n     xlab = \"Quantili Teorici\", ylab = \"Quantili del Campione\",\n     main = \"QQ-Plot: Stessa Media e Varianza\", pch = 16)\nabline(0, 1, lwd = 2)  # Linea y = x\n\n\n\n\n\n\n\nIn questo caso, i punti del QQ-plot dovrebbero allinearsi alla linea rossa, indicando che la distribuzione del campione corrisponde a quella teorica.\n\n38.4.4 Caso 2: Campione con Media Diversa (Intercetta ≠ 0)\nSimuliamo un campione da \\(N(2, 1)\\), con una media diversa ma la stessa varianza:\n\n# Generiamo 20 punti dati da N(2, 1)\ndati_campione_media_spostata &lt;- rnorm(20, mean = 2, sd = 1)\n\n# Ordiniamo i dati del campione\ncampione_ordinato_media_spostata &lt;- sort(dati_campione_media_spostata)\n\n# Tracciamo il QQ-plot\nplot(quantili_teorici, campione_ordinato_media_spostata,\n     xlab = \"Quantili Teorici\", ylab = \"Quantili del Campione\",\n     main = \"QQ-Plot: Media Diversa (Intercetta ≠ 0)\", pch = 16)\nabline(0, 1, lwd = 2)  # Linea y = x\n\n\n\n\n\n\n\nIn questo caso, i punti dovrebbero seguire una linea retta ma essere spostati verticalmente, indicando una media diversa (intercetta ≠ 0).\n\n38.4.5 Caso 3: Campione con Media e Varianza Diverse (Pendenza ≠ 1)\nSimuliamo un campione da \\(N(2, 2^2)\\), con una media e una varianza diverse:\n\n# Generiamo 20 punti dati da N(2, 2^2)\ndati_campione_varianza_spostata &lt;- rnorm(20, mean = 2, sd = 2)\n\n# Ordiniamo i dati del campione\ncampione_ordinato_varianza_spostata &lt;- sort(dati_campione_varianza_spostata)\n\n# Tracciamo il QQ-plot\nplot(quantili_teorici, campione_ordinato_varianza_spostata,\n     xlab = \"Quantili Teorici\", ylab = \"Quantili del Campione\",\n     main = \"QQ-Plot: Media e Varianza Diverse (Pendenza ≠ 1)\", pch = 16)\nabline(0, 1, lwd = 2)  # Linea y = x\n\n\n\n\n\n\n\nIn questo caso, i punti si discosteranno sia verticalmente (per la media diversa) sia rispetto alla pendenza della linea (per la varianza diversa).\n\n38.4.6 Calcolo Manuale del QQ-Plot\nPer ciascun caso sopra, i passaggi sono i seguenti:\n\n\nOrdinamento dei dati del campione: Questo fornisce i quantili del campione.\n\nCalcolo dei quantili teorici: Utilizzando la funzione inversa della CDF per la distribuzione normale.\n\nEsempio in R:\n\n# Calcolo manuale dei quantili teorici\nquantili_teorici_manuali &lt;- function(n) {\n  sapply(1:n, function(i) qnorm((i - 0.5) / n))\n}\n\nn &lt;- length(dati_campione)\nquantili_teorici_calcolati &lt;- quantili_teorici_manuali(n)\nquantili_teorici_calcolati\n#&gt;  [1] -1.9600 -1.4395 -1.1503 -0.9346 -0.7554 -0.5978 -0.4538 -0.3186 -0.1891\n#&gt; [10] -0.0627  0.0627  0.1891  0.3186  0.4538  0.5978  0.7554  0.9346  1.1503\n#&gt; [19]  1.4395  1.9600\n\n\n38.4.7 Utilizzo di Funzioni Specializzate\nIn R, il pacchetto base offre la funzione qqnorm() per generare QQ-plot. Ad esempio:\n\n# Generazione del QQ-plot con qqnorm\nqqnorm(dati_campione, main = \"QQ-Plot: Stessa Media e Varianza\")\nqqline(dati_campione, lwd = 2)  # Linea di riferimento\n\n\n\n\n\n\n\nPossiamo ripetere lo stesso per i campioni con media e varianza spostate.\n\nQuesto approccio fornisce un’analisi completa della corrispondenza tra distribuzioni teoriche e campioni simulati utilizzando QQ-plot.\nPer concludere, esaminiamo la distribuzione dei tempi di reazione simulati con il qq-plot.\n\nqqnorm(rt, main = \"Tempi di Reazione\")\n\n\n\n\n\n\n\nIl diagramma quantile-quantile rende molto chiaro che la distribuzione del peso dei pulcini non è gaussiana.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_gauss.html#valutare-la-normalità-test-statistici",
    "href": "chapters/probability/13_gauss.html#valutare-la-normalità-test-statistici",
    "title": "38  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "\n38.5 Valutare la Normalità: Test Statistici",
    "text": "38.5 Valutare la Normalità: Test Statistici\nSebbene esistano numerosi test statistici formali per valutare la conformità dei dati alla distribuzione normale, questi sono spesso troppo conservativi o sensibili a lievi deviazioni, e nella pratica sono frequentemente sostituiti da metodi visivi più flessibili ed efficaci.\nIn R sono disponibili diversi test per verificare la normalità dei dati. Di seguito presentiamo i più comuni, insieme a un esempio pratico basato sul dataset ChickWeight.\n\n38.5.1 Test di Shapiro-Wilk\nIl test di Shapiro-Wilk è uno dei test più utilizzati per verificare la normalità. Valuta l’ipotesi nulla che i dati seguano una distribuzione normale.\n\nshapiro_test &lt;- shapiro.test(rt)\nshapiro_test\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  rt\n#&gt; W = 0.6, p-value = 5e-16\n\n\nIl p-value è inferiore a 0.05 → Rifiutiamo l’ipotesi nulla, i dati non sono normali.\nIl p-value è maggiore di 0.05 → Non rifiutiamo l’ipotesi nulla, i dati possono essere considerati normali.\n\n38.5.2 Test di Kolmogorov-Smirnov\nQuesto test confronta la distribuzione cumulativa dei dati con una distribuzione teorica, come la normale. Tuttavia, è meno sensibile rispetto al test di Shapiro-Wilk.\n\nks_test &lt;- ks.test(\n  rt, \n  \"pnorm\", \n  mean = mean(rt), \n  sd = sd(rt)\n)\nks_test\n#&gt; \n#&gt;  Asymptotic one-sample Kolmogorov-Smirnov test\n#&gt; \n#&gt; data:  rt\n#&gt; D = 0.3, p-value = 5e-06\n#&gt; alternative hypothesis: two-sided\n\nIl test di Kolmogorov-Smirnov è più adatto per grandi dataset, ma è noto per essere eccessivamente conservativo.\n\n38.5.3 Limitazioni dei test statistici\nNonostante la loro precisione formale, i test statistici per la normalità notevoli limitazioni:\n\nEccessiva sensibilità ai grandi campioni: Quando il campione è ampio, anche lievi deviazioni dalla normalità, non rilevanti per l’analisi, possono portare a un risultato di non-normalità.\nMancanza di sensibilità nei piccoli campioni: Con campioni ridotti, i test possono mancare di potere statistico, portando a falsi negativi (ovvero, non rilevare deviazioni significative dalla normalità).\n\n\nset.seed(123)\nshapiro.test(rchisq(20, 4))\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  rchisq(20, 4)\n#&gt; W = 0.9, p-value = 0.3\n\nIn questo esempio, vediamo come, con un campione di 20 osservazioni da una distribuzione \\(\\chi^2_4\\) si produca un falso negativo.\n\n\nDifficoltà interpretative: Un p-value elevato non implica che i dati siano esattamente normali; semplicemente, non c’è evidenza sufficiente per rifiutare l’ipotesi di normalità.\n\nI metodi visivi, sebbene meno formali, sono spesso più pratici ed efficaci per diagnosticare deviazioni dalla normalità.I metodi visivi sono preferibili sono preferibili perché\n\nforniscono una diagnosi immediata, che consente di identificare deviazioni rilevanti senza dipendere da un p-value.\nrivelano non solo se i dati non sono normali, ma anche come e dove differiscono dalla normalità (ad esempio, asimmetria o code pesanti).\noffrono indicazioni utili anche in presenza di grandi campioni, dove i test statistici possono risultare eccessivamente conservativi.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_gauss.html#trasformazione-dei-dati-affrontare-la-non-normalità",
    "href": "chapters/probability/13_gauss.html#trasformazione-dei-dati-affrontare-la-non-normalità",
    "title": "38  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "\n38.6 Trasformazione dei dati: affrontare la non-normalità",
    "text": "38.6 Trasformazione dei dati: affrontare la non-normalità\nQuando i dati non rispettano l’assunzione di normalità, è possibile utilizzare diverse strategie per affrontare questa violazione. Una delle più comuni è l’uso di trasformazioni dei dati, che permettono di adattare la distribuzione dei dati a una forma più vicina a quella normale, mantenendo comunque la validità dell’analisi che richiede l’assunzione di normalità. Due approcci comuni sono Winsorizing e trimming.\n\n38.6.1 Winsorizing e Trimming\nQuesti metodi si concentrano sulla gestione degli outlier, ossia valori estremi che possono distorcere la distribuzione dei dati. Entrambi gli approcci presumono che la non-normalità sia dovuta a dati contaminanti e agiscono in modo differente:\n\n\nWinsorizing: Sostituisce i valori estremi con valori meno estremi, come i percentili limite della distribuzione.\n\nTrimming: Rimuove completamente i valori estremi dalla distribuzione.\n\nConsideriamo i seguenti dati di esempio:\n\ndati &lt;- c(\n  1.0, 2.2, 3.0, 3.1, 4.0, 4.0, 4.1, 5.3, 6.5, 8.3,\n  10.9, 20.4, 21.4, 34.\n)\n\n# Winsorizing al 20%\ndati_winsorized &lt;- winsorize(\n  dati,\n  method = \"percentile\", percentile = 20\n)\nprint(dati_winsorized)\n#&gt;  [1]  3.0  3.0  3.0  3.1  4.0  4.0  4.1  5.3  6.5  8.3 10.9 20.4 20.4 20.4\n\n\n# Trimming al 20%\ndati_trimmed &lt;- dati[\n  dati &gt;= quantile(dati, 0.2) & dati &lt;= quantile(dati, 0.8)\n]\nprint(dati_trimmed)\n#&gt; [1]  3.1  4.0  4.0  4.1  5.3  6.5  8.3 10.9\n\n\n\nDati Winsorized: I valori estremi (inferiori e superiori ai percentili 20° e 80°) sono sostituiti dai valori limite.\n\nDati Trimmed: I valori fuori dai percentili 20° e 80° sono completamente rimossi.\n\nQuesti metodi riducono l’impatto degli outlier, ma possono introdurre bias se i valori estremi sono effettivamente parte della popolazione target.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_gauss.html#trasformazioni-comuni",
    "href": "chapters/probability/13_gauss.html#trasformazioni-comuni",
    "title": "38  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "\n38.7 Trasformazioni comuni",
    "text": "38.7 Trasformazioni comuni\nQuando i dati non rispettano l’assunzione di normalità, è possibile applicare trasformazioni matematiche per modificarne la forma e migliorare l’adattamento a una distribuzione normale. Di seguito, presentiamo le trasformazioni più utilizzate.\nTrasformazione logaritmica.\nLa trasformazione logaritmica è particolarmente utile per variabili con asimmetria positiva (code lunghe a destra), come i tempi di reazione.\n\n# Trasformazione logaritmica\ndati_log &lt;- log(rt)\nplot(density(dati_log), main = \"Densità dei dati log-transformati\")\n\n\n\n\n\n\n\nTrasformazione radice quadrata.\nAdatta per variabili di conteggio o proporzioni con valori vicini a zero.\n\ndati_sqrt &lt;- sqrt(rt)\nplot(density(dati_sqrt), main = \"Densità dei dati trasformati con radice quadrata\")\n\n\n\n\n\n\n\nTrasformazione inversa.\nEfficace per dati con forte asimmetria positiva, ma può complicare l’interpretazione.\n\ndati_inv &lt;- 1 / rt\nplot(density(dati_inv), main = \"Densità dei dati trasformati inversamente\")\n\n\n\n\n\n\n\nTrasformazione Box-Cox.\nLa trasformazione Box-Cox è una tecnica parametrica che generalizza le precedenti. Utilizza il massimo della verosimiglianza per determinare la trasformazione ottimale per normalizzare i dati. La funzione di trasformazione dipende da un parametro \\(\\lambda\\):\n\\[\ny(\\lambda) =\n\\begin{cases}\n\\frac{y^\\lambda - 1}{\\lambda} & \\text{se } \\lambda \\neq 0, \\\\\n\\log(y) & \\text{se } \\lambda = 0.\n\\end{cases}\n\\]\n\nb &lt;- boxcox(lm(rt ~ 1))\n\n\n\n\n\n\n\n\n# Exact lambda\nlambda &lt;- b$x[which.max(b$y)]\nlambda\n#&gt; [1] 0.182\n\nTrasformiamo i dati utilizzando lambda.\n\nrt_boxcox &lt;- (rt^lambda - 1) / lambda\nrt_boxcox |&gt; head()\n#&gt; [1]  1.645  1.168  2.261 -1.568 -1.133  0.479\n\n\nplot(\n  density(rt_boxcox), \n  main = \"Densità dei dati trasformati con Box-Cox\"\n)\n\n\n\n\n\n\n\n\n# Generazione del QQ-plot con qqnorm\nqqnorm(rt_boxcox, main = \"QQ-Plot\")\nqqline(rt_boxcox, lwd = 2) \n\n\n\n\n\n\n\n\n\n38.7.1 Pro e contro delle trasformazioni\nVantaggi:\nLe trasformazioni dei dati offrono molteplici benefici nell’analisi statistica. In primo luogo, possono migliorare l’aderenza alla normalità, un requisito fondamentale per l’applicazione di molti test statistici. Inoltre, contribuiscono a stabilizzare la varianza e a mitigare l’impatto dei valori estremi, riducendo il rischio che questi ultimi influenzino eccessivamente i risultati. Tali vantaggi migliorano la robustezza e l’accuratezza delle analisi.\nSvantaggi:\nNonostante i benefici, le trasformazioni presentano limitazioni rilevanti. La perdita di interpretabilità è uno degli aspetti più critici: i risultati su dati trasformati possono risultare meno intuitivi. Ad esempio, in un modello di regressione applicato a dati trasformati con il logaritmo, il coefficiente rappresenta un cambiamento percentuale anziché assoluto, rendendo l’interpretazione meno diretta per i non esperti.\nInoltre, l’applicazione di una trasformazione deve essere attentamente motivata in base alla natura dei dati e agli obiettivi dell’analisi. Una trasformazione inappropriata può introdurre distorsioni indesiderate, compromettendo la validità dei risultati e portando a conclusioni fuorvianti. Per questo motivo, è essenziale valutare attentamente i costi e i benefici della trasformazione nel contesto specifico della ricerca.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_gauss.html#riflessioni-conclusive",
    "href": "chapters/probability/13_gauss.html#riflessioni-conclusive",
    "title": "38  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "\n38.8 Riflessioni Conclusive",
    "text": "38.8 Riflessioni Conclusive\nLa verifica della normalità dei dati e l’eventuale utilizzo di trasformazioni matematiche costituiscono fasi fondamentali nell’analisi statistica. Sebbene i test formali (come Shapiro-Wilk o Kolmogorov-Smirnov) offrano una valutazione strutturata, essi possono risultare troppo sensibili, portando a rigettare l’assunto di normalità anche in presenza di lievi deviazioni non rilevanti dal punto di vista pratico. In questi casi, l’impiego di strumenti visivi—come istogrammi, grafici di densità o QQ-plot—si rivela spesso più informativo e flessibile, consentendo di individuare la natura e l’entità delle deviazioni.\nLe trasformazioni dei dati rappresentano una strategia utile per normalizzare la distribuzione, ma richiedono una scelta oculata. È essenziale verificare che la trasformazione adottata non comprometta il significato teorico della variabile in esame. Quando l’interpretabilità risulta compromessa, potrebbe essere preferibile ricorrere a metodi robusti o modelli alternativi (ad esempio, approcci bayesiani) che non presuppongono la normalità. In definitiva, la decisione finale dipenderà dal contesto di ricerca, dalla natura dei dati e dagli obiettivi analitici, privilegiando sempre un equilibrio tra rigore statistico e interpretabilità dei risultati.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_gauss.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/13_gauss.html#informazioni-sullambiente-di-sviluppo",
    "title": "38  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] MASS_7.3-61       datawizard_0.13.0 see_0.9.0         gridExtra_2.3    \n#&gt;  [5] patchwork_1.3.0   bayesplot_1.11.1  psych_2.4.12      scales_1.3.0     \n#&gt;  [9] markdown_1.13     knitr_1.49        lubridate_1.9.4   forcats_1.0.0    \n#&gt; [13] stringr_1.5.1     dplyr_1.1.4       purrr_1.0.2       readr_2.1.5      \n#&gt; [17] tidyr_1.3.1       tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0  \n#&gt; [21] rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.3         rlang_1.1.4       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       yaml_2.3.10       tools_4.4.2       parallel_4.4.2   \n#&gt; [21] tzdb_0.4.0        colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5      \n#&gt; [25] R6_2.5.1          lifecycle_1.0.4   htmlwidgets_1.6.4 insight_1.0.0    \n#&gt; [29] pkgconfig_2.0.3   pillar_1.10.0     gtable_0.3.6      glue_1.8.0       \n#&gt; [33] xfun_0.49         tidyselect_1.2.1  farver_2.1.2      htmltools_0.5.8.1\n#&gt; [37] nlme_3.1-166      labeling_0.4.3    rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_gauss.html#bibliografia",
    "href": "chapters/probability/13_gauss.html#bibliografia",
    "title": "38  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nOsborne, J. (2002). Notes on the use of data transformations. Practical Assessment, Research, and Evaluation, 8(1).\n\n\nShatz, I. (2024). Assumption-checking rather than (just) testing: The importance of visualization and effect size in statistical diagnostics. Behavior Research Methods, 56(2), 826–845.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_likelihood.html",
    "href": "chapters/probability/14_likelihood.html",
    "title": "39  La verosimiglianza",
    "section": "",
    "text": "39.1 Introduzione\nPrerequisiti\nConcetti e Competenze Chiave\nPreparazione del Notebook\nI ricercatori utilizzano modelli con diverse strutture funzionali per descrivere e prevedere il comportamento dei dati. La scelta del modello più adatto si basa sul confronto tra le previsioni teoriche e i dati osservati: il modello che produce previsioni più vicine ai dati osservati viene considerato il migliore per rappresentare il fenomeno studiato. In questo processo, la funzione di verosimiglianza svolge un ruolo centrale, quantificando la probabilità che i dati osservati siano compatibili con un modello specifico e i suoi parametri.\nLa funzione di verosimiglianza rappresenta il meccanismo generativo dei dati, collegando i parametri del modello alle osservazioni empiriche. Tuttavia, essa non costituisce da sola un modello scientifico completo. Un modello scientifico include infatti altri elementi, come i priori (in un approccio bayesiano), che rappresentano le ipotesi iniziali sui parametri prima dell’osservazione dei dati, e la modellazione dell’errore di misurazione, che tiene conto delle imperfezioni nei dati raccolti.\nIn un approccio bayesiano, i priori si combinano con la verosimiglianza per generare la distribuzione a posteriori, che aggiorna le conoscenze sui parametri alla luce dei dati osservati. Questo passaggio è cruciale per il confronto tra modelli, poiché i priori possono influenzare significativamente le conclusioni.\nUn modello scientifico può anche includere la modellazione dell’errore di misurazione per spiegare le discrepanze tra i dati osservati e il processo reale. Questo aspetto è fondamentale per garantire che il modello sia in grado di catturare sia le osservazioni che le loro imprecisioni.\nIn sintesi, la funzione di verosimiglianza descrive come i dati potrebbero essere generati da un modello dato un insieme di parametri, ma un modello scientifico completo include ulteriori componenti, come i priori e la modellazione dell’errore, per rendere la rappresentazione del fenomeno più accurata. Questo capitolo si propone di approfondire il concetto di verosimiglianza e il suo ruolo nell’inferenza statistica.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_likelihood.html#il-principio-della-verosimiglianza-e-la-sua-formalizzazione",
    "href": "chapters/probability/14_likelihood.html#il-principio-della-verosimiglianza-e-la-sua-formalizzazione",
    "title": "39  La verosimiglianza",
    "section": "\n39.2 Il Principio della Verosimiglianza e la sua Formalizzazione",
    "text": "39.2 Il Principio della Verosimiglianza e la sua Formalizzazione\nLa funzione di verosimiglianza è strettamente collegata alla funzione di densità (o massa) di probabilità, ma i due concetti hanno interpretazioni distinte:\n\nLa funzione di densità di probabilità descrive la probabilità di osservare un determinato insieme di dati, assumendo che i parametri siano noti e fissi.\nLa funzione di verosimiglianza considera i dati osservati come fissi e varia i parametri, valutando quanto ciascun valore dei parametri spieghi i dati.\n\nLa relazione tra queste due funzioni può essere formalizzata come segue:\n\\[\nL(\\theta \\mid y) \\propto p(y \\mid \\theta),\n\\]\ndove \\(L(\\theta \\mid y)\\) è la verosimiglianza dei parametri \\(\\theta\\) dati i dati \\(y\\), e \\(p(y \\mid \\theta)\\) rappresenta la probabilità di osservare i dati \\(y\\) dato un certo \\(\\theta\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_likelihood.html#verosimiglianza-binomiale",
    "href": "chapters/probability/14_likelihood.html#verosimiglianza-binomiale",
    "title": "39  La verosimiglianza",
    "section": "\n39.3 Verosimiglianza Binomiale",
    "text": "39.3 Verosimiglianza Binomiale\nConsideriamo un esempio pratico: il lancio di una moneta. Supponiamo di osservare 23 teste su 30 lanci. La probabilità di osservare esattamente questo risultato, data una probabilità di successo \\(\\theta\\), può essere calcolata utilizzando la funzione di massa della distribuzione binomiale:\n\\[\nP(Y = y) = \\binom{n}{y} \\theta^y (1 - \\theta)^{n - y},\n\\]\ndove:\n\n\n\\(n\\) è il numero totale di lanci,\n\n\\(y\\) è il numero di successi osservati,\n\n\\(\\theta\\) è la probabilità di successo per ogni lancio.\n\nLa funzione di verosimiglianza, invece, si concentra sull’identificazione dei valori di \\(\\theta\\) che meglio spiegano i dati osservati. Per la distribuzione binomiale, la funzione di verosimiglianza si scrive come:\n\\[\n\\mathcal{L}(\\theta \\mid y) = \\theta^y (1 - \\theta)^{n - y}.\n\\]\nQui, il coefficiente binomiale \\(\\binom{n}{y}\\) può essere omesso perché non dipende da \\(\\theta\\) e quindi non influisce sulla stima del parametro.\n\n39.3.1 Verosimiglianza per il Lancio di una Moneta\nSupponiamo che:\n\n\n\\(n = 30\\) (numero di lanci),\n\n\\(y = 23\\) (numero di teste osservate).\n\nLa funzione di verosimiglianza diventa:\n\\[\n\\mathcal{L}(\\theta \\mid y) = \\theta^{23} (1 - \\theta)^7.\n\\]\nQuesto ci permette di calcolare la verosimiglianza per diversi valori di \\(\\theta\\), determinando quale valore rende i dati osservati più plausibili. Ad esempio, possiamo simulare 100 valori equidistanti di \\(\\theta\\) nell’intervallo ([0, 1]) e calcolare la funzione di verosimiglianza per ciascun valore.\nIn R, possiamo calcolare la funzione di verosimiglianza per \\(n = 30\\), \\(y = 23\\), e una griglia di valori di \\(\\theta\\) come segue:\n\n# Parametri\nn &lt;- 30\ny &lt;- 23\n\n# Definizione dei valori di theta\ntheta &lt;- seq(0, 1, length.out = 100)\n\n# Calcolo della verosimiglianza\nlikelihood &lt;- theta^y * (1 - theta)^(n - y)\n\n# Visualizzazione della funzione di verosimiglianza\nggplot(\n  data.frame(theta, likelihood), \n  aes(x = theta, y = likelihood)) +\n  geom_line(color = \"blue\") +\n  labs(\n    title = \"Funzione di Verosimiglianza\",\n    x = \"Valore di θ\",\n    y = \"Verosimiglianza\"\n  ) \n\n\n\n\n\n\n\n\n39.3.2 Interpretazione della Verosimiglianza\n\n\nValore di \\(\\theta\\): La funzione di verosimiglianza indica quali valori di \\(\\theta\\) sono più plausibili dati i dati osservati.\n\nStima di Massima Verosimiglianza (MLE): Il valore di \\(\\theta\\) che massimizza la funzione di verosimiglianza è detto stima di massima verosimiglianza. Nel nostro esempio, possiamo individuare questo valore esplorando numericamente i punti di massimo della curva.\n\nIn pratica, per identificare numericamente il valore ottimale di \\(\\theta\\), si può utilizzare un approccio computazionale che identifica il massimo della verosimiglianza.\n\n# Calcolo delle probabilità binomiali\nl &lt;- dbinom(y, size = n, prob = theta)\n\n# Individuazione dell'indice massimo\nmax_index &lt;- which.max(l)\n\n# Recupero del valore corrispondente di theta\ntheta[max_index]\n#&gt; [1] 0.768\n\nSpiegazione:\n\n\ndbinom(y, size = n, prob = theta) calcola la probabilità binomiale per ogni valore di theta.\n\nwhich.max(l) restituisce l’indice del valore massimo nella distribuzione di probabilità calcolata.\n\ntheta[max_index] seleziona il valore di theta corrispondente all’indice massimo.\n\nQuesto approccio illustra come la funzione di verosimiglianza aiuti a stimare parametri incogniti e a valutare la plausibilità relativa di diversi modelli statistici, basandosi esclusivamente sui dati osservati.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_likelihood.html#la-funzione-di-log-verosimiglianza",
    "href": "chapters/probability/14_likelihood.html#la-funzione-di-log-verosimiglianza",
    "title": "39  La verosimiglianza",
    "section": "\n39.4 La Funzione di Log-Verosimiglianza",
    "text": "39.4 La Funzione di Log-Verosimiglianza\nLa log-verosimiglianza è il logaritmo naturale della funzione di verosimiglianza:\n\\[\n\\ell(\\theta) = \\log \\mathcal{L}(\\theta \\mid y).\n\\]\nQuesta trasformazione è utile per semplificare i calcoli e migliorare la stabilità numerica, specialmente con dataset di grandi dimensioni.\nEsempio grafico per i valori di log-verosimiglianza:\n\n# Parametri\nn &lt;- 30\nr &lt;- 23\n\n# Genera la sequenza per theta\ntheta &lt;- seq(0, 1, length.out = 100)\n\n# Calcolo della log-verosimiglianza\nlog_likelihood &lt;- dbinom(r, size = n, prob = theta, log = TRUE)\n\n# Creazione del grafico\nplot(\n  theta, log_likelihood, type = \"l\",\n  main = \"Funzione di log-verosimiglianza\",\n  xlab = \"Valore della variabile casuale theta [0, 1]\",\n  ylab = \"Log-verosimiglianza\"\n)\n\n\n\n\n\n\n\nIl massimo della log-verosimiglianza replica il risultato trovato in precedenza con la funzione di verosimiglianza.\n\n# Calcolo della log-verosimiglianza per ogni valore di theta\nlog_likelihood &lt;- dbinom(r, size = n, prob = theta, log = TRUE)\n\n# Trova l'indice del valore massimo\nmax_index &lt;- which.max(log_likelihood)\n\n# Valore di theta corrispondente al massimo\ntheta[max_index]\n#&gt; [1] 0.768",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_likelihood.html#verosimiglianza-congiunta",
    "href": "chapters/probability/14_likelihood.html#verosimiglianza-congiunta",
    "title": "39  La verosimiglianza",
    "section": "\n39.5 Verosimiglianza Congiunta",
    "text": "39.5 Verosimiglianza Congiunta\nNell’inferenza statistica basata sulla verosimiglianza, è comune incontrare situazioni in cui si dispone di più osservazioni indipendenti, tutte generate dallo stesso processo probabilistico. Ad esempio, raccogliamo un insieme di dati $ Y = [y_1, y_2, , y_n] $, dove ciascun valore è osservato indipendentemente e segue la stessa distribuzione binomiale. Questo scenario, noto come condizione di indipendenza e identica distribuzione (IID), è frequente nelle applicazioni pratiche.\n\n39.5.1 Calcolo della Verosimiglianza Congiunta\nPer considerare congiuntamente tutte le osservazioni, calcoliamo la probabilità congiunta di osservare $ y_1, y_2, , y_n $, data una comune probabilità di successo \\(\\theta\\). Grazie all’indipendenza delle osservazioni, questa probabilità si esprime come il prodotto delle probabilità individuali:\n\\[\np(y_1, y_2, \\ldots, y_n \\mid \\theta) = \\prod_{i=1}^{n} p(y_i \\mid \\theta) = \\prod_{i=1}^{n} \\text{Binomiale}(y_i \\mid \\theta).\n\\]\nLa verosimiglianza congiunta è quindi:\n\\[\n\\mathcal{L}(\\theta \\mid Y) = \\prod_{i=1}^{n} \\mathcal{L}(\\theta \\mid y_i) = \\prod_{i=1}^{n} p(y_i \\mid \\theta).\n\\]\nQuesta funzione misura la plausibilità complessiva del parametro \\(\\theta\\) rispetto all’intero insieme di dati \\(Y\\). Il valore di \\(\\theta\\) che massimizza la verosimiglianza congiunta è noto come stimatore di massima verosimiglianza (MLE) e rappresenta il parametro che rende i dati osservati più plausibili.\n\n39.5.2 Log-Verosimiglianza Congiunta\nPoiché il prodotto delle probabilità può diventare numericamente instabile, lavoriamo spesso con la log-verosimiglianza, che trasforma il prodotto in una somma:\n\\[\n\\log \\mathcal{L}(\\theta \\mid Y) = \\sum_{i=1}^{n} \\log p(y_i \\mid \\theta).\n\\]\nIn un esempio pratico con dati raggruppati, consideriamo quattro gruppi di osservazioni binomiali indipendenti:\n\n\nGruppo 1: 30 prove con 23 successi\n\nGruppo 2: 28 prove con 20 successi\n\nGruppo 3: 40 prove con 29 successi\n\nGruppo 4: 36 prove con 29 successi\n\nLa log-verosimiglianza congiunta è:\n\\[\n\\log \\mathcal{L}(\\theta) = \\sum_{i=1}^{4} \\left[ y_i \\log(\\theta) + (n_i - y_i) \\log(1 - \\theta) \\right],\n\\]\ndove $ n_i $ e $ y_i $ rappresentano rispettivamente il numero di prove e di successi nel gruppo \\(i\\)-esimo.\n\n39.5.3 Implementazione in R\nPer calcolare la log-verosimiglianza congiunta, definiamo una funzione che accetta \\(\\theta\\) e i dati dei gruppi:\n\nlog_verosimiglianza_congiunta &lt;- function(theta, dati) {\n  # Evita valori problematici per log(0)\n  theta &lt;- pmax(pmin(theta, 1 - 1e-10), 1e-10)\n  \n  # Calcolo della log-verosimiglianza\n  log_likelihood &lt;- 0\n  for (gruppo in dati) {\n    n &lt;- gruppo[1]\n    y &lt;- gruppo[2]\n    log_likelihood &lt;- log_likelihood + y * log(theta) + (n - y) * log(1 - theta)\n  }\n  \n  return(-log_likelihood) # Negativo per ottimizzazione\n}\n\nI dati dei gruppi sono rappresentati come segue:\n\ndati_gruppi &lt;- list(c(30, 23), c(28, 20), c(40, 29), c(36, 29))\n\n\n39.5.4 Ottimizzazione per trovare \\(\\theta\\)\n\nUtilizziamo l’algoritmo di ottimizzazione optim per stimare il valore di \\(\\theta\\) che massimizza la log-verosimiglianza:\n\nresult &lt;- optim(\n  par = 0.5,                        # Valore iniziale\n  fn = log_verosimiglianza_congiunta, \n  dati = dati_gruppi,               # Dati\n  method = \"L-BFGS-B\",              # Metodo con vincoli\n  lower = 0,                        # Limite inferiore\n  upper = 1                         # Limite superiore\n)\n\n# Valore ottimale di theta\nresult$par\n#&gt; [1] 0.754\n\n\n39.5.5 Visualizzazione della log-verosimiglianza\nCalcoliamo e tracciamo la log-verosimiglianza negativa per un intervallo di valori di \\(\\theta\\):\n\ntheta_values &lt;- seq(0.01, 0.99, length.out = 100)\n\nlog_likelihood_values &lt;- sapply(theta_values, function(theta) {\n  log_verosimiglianza_congiunta(theta, dati_gruppi)\n})\n\nggplot(\n  data.frame(theta = theta_values, log_likelihood = log_likelihood_values), \n  aes(x = theta, y = log_likelihood)) +\n  geom_line(color = \"blue\") +\n  labs(\n    title = \"Funzione di Log-verosimiglianza Congiunta\",\n    x = \"Theta\",\n    y = \"Log-verosimiglianza Negativa\"\n  ) \n\n\n\n\n\n\n\nIn conclusione, l’analisi della verosimiglianza congiunta consente di stimare con precisione il parametro \\(\\theta\\) considerando tutte le osservazioni contemporaneamente. La log-verosimiglianza, grazie alla sua stabilità numerica e alla semplicità di calcolo, è uno strumento potente per l’inferenza statistica. Utilizzando tecniche di ottimizzazione, possiamo identificare il valore di \\(\\theta\\) che meglio spiega i dati osservati, ottenendo stime affidabili anche in contesti complessi.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_likelihood.html#la-verosimiglianza-marginale",
    "href": "chapters/probability/14_likelihood.html#la-verosimiglianza-marginale",
    "title": "39  La verosimiglianza",
    "section": "\n39.6 La Verosimiglianza Marginale",
    "text": "39.6 La Verosimiglianza Marginale\nLa verosimiglianza marginale è un concetto fondamentale nell’inferenza bayesiana. Essa permette di calcolare la probabilità complessiva di osservare un determinato risultato, tenendo conto di tutte le possibili incertezze sui parametri del modello. Questo è particolarmente rilevante quando il parametro di interesse, \\(\\theta\\), non è considerato un valore fisso, ma è descritto da una distribuzione di probabilità.\nIn pratica, la verosimiglianza marginale valuta la compatibilità dei dati con il modello, integrando su tutti i possibili valori di \\(\\theta\\), ciascuno pesato dalla sua probabilità a priori.\n\n39.6.1 Caso con Parametri Discreti\nConsideriamo un esempio semplice in cui \\(\\theta\\) può assumere un insieme discreto di valori. Ad esempio, in una sequenza di prove binomiali con \\(k = 7\\) successi su \\(n = 10\\) prove, e con \\(\\theta \\in \\{0.1, 0.5, 0.9\\}\\), la verosimiglianza marginale è calcolata come:\n\\[\np(k = 7 \\mid n = 10) = \\sum_{\\theta \\in \\{0.1, 0.5, 0.9\\}} \\binom{10}{7} \\theta^7 (1 - \\theta)^3 p(\\theta),\n\\]\ndove \\(p(\\theta)\\) rappresenta la probabilità a priori associata a ciascun valore discreto di \\(\\theta\\). In questo caso, la verosimiglianza marginale è la somma delle probabilità di osservare i dati, pesata dalla probabilità a priori di ciascun valore di \\(\\theta\\).\n\n39.6.2 Caso con Parametri Continui\nNella maggior parte delle applicazioni, \\(\\theta\\) varia continuamente all’interno di un intervallo, ad esempio \\([0, 1]\\) per un parametro binomiale. In tal caso, la verosimiglianza marginale è calcolata mediante un’integrazione:\n\\[\np(k = 7 \\mid n = 10) = \\int_{0}^{1} \\binom{10}{7} \\theta^7 (1 - \\theta)^3 p(\\theta) \\, d\\theta,\n\\]\ndove \\(p(\\theta)\\) è la densità a priori di \\(\\theta\\). Questa formula combina le probabilità condizionali dei dati dati \\(\\theta\\) con le probabilità a priori, integrando su tutti i possibili valori di \\(\\theta\\).\n\n39.6.3 Calcolo Numerico della Verosimiglianza Marginale\nPer calcolare la verosimiglianza marginale con \\(\\theta\\) continuo, possiamo utilizzare l’integrazione numerica. In R, il pacchetto stats offre strumenti utili come la funzione integrate. Ecco un esempio concreto:\n\n# Definizione della funzione di verosimiglianza\nlikelihood &lt;- function(theta) {\n  dbinom(x = 7, size = 10, prob = theta)\n}\n\n# Calcolo della verosimiglianza marginale con integrazione numerica\nmarginal_likelihood &lt;- integrate(likelihood, lower = 0, upper = 1)$value\n\n# Stampa del risultato\ncat(\"La verosimiglianza marginale è:\", marginal_likelihood, \"\\n\")\n#&gt; La verosimiglianza marginale è: 0.0909\n\n\n39.6.4 Interpretazione della Verosimiglianza Marginale\nLa verosimiglianza marginale rappresenta la capacità complessiva del modello di spiegare i dati, tenendo conto dell’incertezza sui parametri. Dal punto di vista geometrico, può essere interpretata come l’area sottesa alla funzione di verosimiglianza ponderata dalla distribuzione a priori di \\(\\theta\\).\nTuttavia, è importante chiarire che la verosimiglianza marginale non è una probabilità dei dati dato un valore specifico di \\(\\theta\\). Piuttosto, essa considera tutte le possibili incertezze sui parametri, fornendo una misura complessiva della compatibilità del modello con i dati.\n\n39.6.5 Ruolo nell’Inferenza Bayesiana\nLa verosimiglianza marginale assume un ruolo chiave nell’inferenza bayesiana come fattore di normalizzazione nella formula di Bayes:\n\\[\np(\\theta \\mid D) = \\frac{p(D \\mid \\theta) p(\\theta)}{p(D)},\n\\]\ndove \\(p(D)\\), ossia la verosimiglianza marginale, garantisce che la distribuzione posteriore \\(p(\\theta \\mid D)\\) sia una distribuzione di probabilità valida, con un’area totale pari a 1.\nIn conclusione, la verosimiglianza marginale è uno strumento fondamentale per valutare il modello nel suo complesso, integrando informazioni sui parametri e sulla loro incertezza. In particolare:\n\n\nPer parametri discreti, si calcola sommando le probabilità di ciascun valore di \\(\\theta\\), ponderate dalla loro probabilità a priori.\n\nPer parametri continui, si utilizza l’integrazione per ottenere una misura globale della compatibilità del modello con i dati.\n\nQuesta misura non solo consente di confrontare modelli diversi, ma garantisce anche la validità della distribuzione a posteriori nell’inferenza bayesiana. Grazie a strumenti computazionali, possiamo calcolare la verosimiglianza marginale anche in situazioni complesse, fornendo una base solida per analisi statistiche rigorose e flessibili.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_likelihood.html#modello-gaussiano-e-verosimiglianza",
    "href": "chapters/probability/14_likelihood.html#modello-gaussiano-e-verosimiglianza",
    "title": "39  La verosimiglianza",
    "section": "\n39.7 Modello Gaussiano e Verosimiglianza",
    "text": "39.7 Modello Gaussiano e Verosimiglianza\nIn questa sezione analizziamo il caso di una distribuzione gaussiana per calcolare la funzione di verosimiglianza. Inizieremo con una singola osservazione e successivamente estenderemo l’analisi a un insieme di osservazioni indipendenti e identicamente distribuite (IID).\n\n39.7.1 Caso di una Singola Osservazione\nConsideriamo una singola osservazione $ y $, ad esempio il Quoziente Intellettivo (QI) di un individuo, che supponiamo seguire una distribuzione normale. La funzione di verosimiglianza per $ y $ esprime la plausibilità di diversi valori del parametro \\(\\mu\\) (media), dato il valore osservato, assumendo che la deviazione standard \\(\\sigma\\) sia nota.\n\n39.7.1.1 Definizione della Verosimiglianza\nLa funzione di densità di probabilità gaussiana è definita come:\n\\[\nf(y \\mid \\mu, \\sigma) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left(-\\frac{(y-\\mu)^2}{2\\sigma^2}\\right),\n\\]\ndove \\(y\\) è il valore osservato, \\(\\mu\\) è la media e \\(\\sigma\\) è la deviazione standard.\n\n39.7.1.2 Esempio con R\nSupponiamo di osservare un valore $ y = 114 $ e di assumere che \\(\\sigma = 15\\). Esploriamo i valori di \\(\\mu\\) in un intervallo compreso tra 70 e 160 per determinare quale valore massimizza la verosimiglianza.\n\n# Parametri iniziali\ny_obs &lt;- 114\nsigma &lt;- 15\nmu_values &lt;- seq(70, 160, length.out = 1000)\n\n# Calcolo della funzione di verosimiglianza\nlikelihood &lt;- dnorm(y_obs, mean = mu_values, sd = sigma)\n\n# Visualizzazione della funzione di verosimiglianza\nlibrary(ggplot2)\nggplot(data.frame(mu = mu_values, likelihood = likelihood), aes(x = mu, y = likelihood)) +\n  geom_line(color = \"blue\") +\n  labs(\n    title = \"Funzione di Verosimiglianza per QI = 114\",\n    x = \"Valore di μ (media)\",\n    y = \"Verosimiglianza\"\n  )\n\n\n\n\n\n\n\n\n39.7.1.3 Calcolo del Valore Ottimale\nPer determinare il valore di \\(\\mu\\) che massimizza la verosimiglianza, individuiamo il massimo della curva.\n\n# Identificazione del massimo\nmu_optimal &lt;- mu_values[which.max(likelihood)]\ncat(\"Il valore ottimale di μ è:\", mu_optimal, \"\\n\")\n#&gt; Il valore ottimale di μ è: 114\n\nIl valore di \\(\\mu\\) che massimizza la verosimiglianza è $ = 114 $, coincidente con il valore osservato.\n\n39.7.2 Log-Verosimiglianza\nIn alternativa, possiamo lavorare con la log-verosimiglianza, una trasformazione utile per semplificare i calcoli numerici e migliorare la stabilità computazionale:\n\\[\n\\log L(\\mu \\mid y, \\sigma) = -\\frac{1}{2} \\log(2\\pi) - \\log(\\sigma) - \\frac{(y - \\mu)^2}{2\\sigma^2}.\n\\]\nQuesta funzione è equivalente alla funzione di verosimiglianza per determinare il valore di \\(\\mu\\) che meglio si adatta ai dati.\n\n39.7.2.1 Calcolo della Log-Verosimiglianza con R\n\n# Funzione di log-verosimiglianza negativa\nnegative_log_likelihood &lt;- function(mu, y, sigma) {\n  0.5 * log(2 * pi) + log(sigma) + ((y - mu)^2) / (2 * sigma^2)\n}\n\n# Ottimizzazione per trovare il massimo della log-verosimiglianza\nresult &lt;- optim(\n  par = 100,  # Valore iniziale per μ\n  fn = negative_log_likelihood,\n  y = y_obs,\n  sigma = sigma,\n  method = \"L-BFGS-B\",\n  lower = 70,\n  upper = 160\n)\n\n# Risultato dell'ottimizzazione\nmu_max_loglik &lt;- result$par\ncat(\"Il valore ottimale di μ basato sulla log-verosimiglianza è:\", mu_max_loglik, \"\\n\")\n#&gt; Il valore ottimale di μ basato sulla log-verosimiglianza è: 114\n\nIl valore di \\(\\mu\\) che massimizza la log-verosimiglianza è $ = 114 $, confermando che, in presenza di una singola osservazione, il valore ottimale coincide con l’osservazione stessa.\nIn conclusione, l’analisi della funzione di verosimiglianza nel caso gaussiano mostra che:\n\nLa funzione di verosimiglianza rappresenta la plausibilità dei parametri del modello dato il valore osservato.\nLa log-verosimiglianza è una trasformazione utile per calcoli più stabili e semplificati.\nNel caso di una singola osservazione e deviazione standard nota, il valore di \\(\\mu\\) che massimizza la verosimiglianza coincide con il valore osservato \\(y\\).\n\n39.7.3 Campione Indipendente di Osservazioni da una Distribuzione Normale\nConsideriamo un campione composto da \\(n\\) osservazioni indipendenti e identicamente distribuite (IID), ognuna derivante da una distribuzione normale con media \\(\\mu\\) e deviazione standard \\(\\sigma\\). La distribuzione è rappresentata da:\n\\[\nX \\sim N(\\mu, \\sigma^2),\n\\]\ndove \\(y_i\\) indica ogni osservazione del campione.\nLa densità di probabilità congiunta per il campione è il prodotto delle densità delle singole osservazioni:\n\\[\np(y_1, y_2, \\ldots, y_n \\mid \\mu, \\sigma) = \\prod_{i=1}^n p(y_i \\mid \\mu, \\sigma).\n\\]\nDi conseguenza, la funzione di verosimiglianza è:\n\\[\n\\mathcal{L}(\\mu, \\sigma \\mid y) = \\prod_{i=1}^n \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp \\left( -\\frac{(y_i - \\mu)^2}{2\\sigma^2} \\right).\n\\]\nPer semplificare i calcoli, si considera il logaritmo della funzione di verosimiglianza:\n\\[\n\\log \\mathcal{L}(\\mu, \\sigma \\mid y) = -\\frac{n}{2} \\log(2\\pi) - n \\log(\\sigma) - \\frac{1}{2\\sigma^2} \\sum_{i=1}^n (y_i - \\mu)^2.\n\\]\n\n39.7.3.1 Esempio Pratico\nSupponiamo di misurare i punteggi del BDI-II su un campione di 30 partecipanti. I dati sono i seguenti:\n\n# Dati osservati\ny &lt;- c(\n  26, 35, 30, 25, 44, 30, 33, 43, 22, 43, \n  24, 19, 39, 31, 25, 28, 35, 30, 26, 31, \n  41, 36, 26, 35, 33, 28, 27, 34, 27, 22\n)\n\nAssumiamo che la deviazione standard \\(\\sigma\\) sia nota e pari alla deviazione standard campionaria (\\(\\sigma = 6.50\\)).\nDefiniamo una funzione per calcolare la log-verosimiglianza dato un valore di \\(\\mu\\):\n\nlog_likelihood &lt;- function(mu, y, sigma) {\n  n &lt;- length(y)\n  term1 &lt;- -n * log(sigma) - n * log(sqrt(2 * pi))\n  term2 &lt;- -sum((y - mu)^2) / (2 * sigma^2)\n  return(term1 + term2)\n}\n\nDefiniamo un intervallo per \\(\\mu\\), centrato sulla media campionaria:\n\n# Parametri\nsigma &lt;- 6.50\nmu_range &lt;- seq(mean(y) - 2 * sigma, mean(y) + 2 * sigma, length.out = 1000)\n\n# Calcolo della log-verosimiglianza per ogni valore di mu\nlog_lik_values &lt;- sapply(mu_range, log_likelihood, y = y, sigma = sigma)\n\nTracciamo la funzione di log-verosimiglianza per i diversi valori di \\(\\mu\\):\n\nggplot(\n  data.frame(mu = mu_range, log_likelihood = log_lik_values), \n  aes(x = mu, y = log_likelihood)) +\n  geom_line(color = \"blue\") +\n  labs(\n    title = \"Funzione di Log-Verosimiglianza\",\n    x = \"Valore di μ\",\n    y = \"Log-Verosimiglianza\"\n  ) +\n  geom_vline(xintercept = mean(y), linetype = \"dashed\", color = \"red\", alpha = 0.7) \n\n\n\n\n\n\n\nUtilizziamo l’ottimizzazione numerica per trovare il valore di \\(\\mu\\) che massimizza la log-verosimiglianza:\n\n# Definizione della funzione negativa per l'ottimizzazione\nnegative_log_likelihood &lt;- function(mu, y, sigma) {\n  -log_likelihood(mu, y, sigma)\n}\n\n# Ottimizzazione\nresult &lt;- optim(\n  par = mean(y),  # Punto di partenza\n  fn = negative_log_likelihood,\n  y = y,\n  sigma = sigma,\n  method = \"L-BFGS-B\",\n  lower = min(mu_range),\n  upper = max(mu_range)\n)\n\n# Risultato\nmu_optimal &lt;- result$par\ncat(\"Il valore ottimale di μ è:\", mu_optimal, \"\\n\")\n#&gt; Il valore ottimale di μ è: 30.9\n\nInterpretazione dei risultati:\n\n\nStima di Massima Verosimiglianza (MLE): La media campionaria \\(\\bar{y}\\) rappresenta la stima di massima verosimiglianza (MLE) per \\(\\mu\\). Questo risultato è coerente con la proprietà della distribuzione normale.\n\nCurva della Log-Verosimiglianza: La curva mostra la “plausibilità relativa” dei diversi valori di \\(\\mu\\) alla luce dei dati osservati.\n\nOttimizzazione Numerica: Il valore di \\(\\mu\\) che massimizza la funzione di log-verosimiglianza è il valore che meglio spiega i dati osservati.\n\nIn conclusione, la log-verosimiglianza è uno strumento essenziale per stimare i parametri di una distribuzione normale:\n\nLa stima di massima verosimiglianza per \\(\\mu\\) coincide con la media campionaria.\nVisualizzare la log-verosimiglianza aiuta a comprendere la plausibilità dei parametri.\nL’ottimizzazione numerica fornisce una soluzione precisa ed efficiente per trovare il massimo della log-verosimiglianza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_likelihood.html#riflessioni-conclusive",
    "href": "chapters/probability/14_likelihood.html#riflessioni-conclusive",
    "title": "39  La verosimiglianza",
    "section": "\n39.8 Riflessioni Conclusive",
    "text": "39.8 Riflessioni Conclusive\nLa funzione di verosimiglianza rappresenta un elemento cruciale che collega i dati osservati ai parametri di un modello statistico. Essa fornisce una misura della plausibilità dei dati in relazione a diversi valori possibili dei parametri del modello. La strutturazione di una funzione di verosimiglianza richiede la considerazione di tre componenti fondamentali: il modello statistico che si presume abbia generato i dati, l’insieme di valori possibili per i parametri di tale modello e le osservazioni empiriche che effettivamente abbiamo a disposizione.\nLa funzione di verosimiglianza è centrale nella pratica dell’inferenza statistica. Essa ci permette di quantificare quanto bene differenti set di parametri potrebbero aver generato i dati osservati. Questo è fondamentale sia per la selezione del modello che per la stima dei parametri, e pertanto è indispensabile per un’analisi dati rigorosa e per un’interpretazione accurata dei risultati.\nUn’applicazione pratica e illustrativa dei principi esposti in questo capitolo è fornita nella sezione sul modello Rescorla-Wagner, che è un esempio di come la teoria della verosimiglianza possa essere applicata per affrontare questioni empiriche in psicologia.\nIn sintesi, la comprensione e l’applicazione appropriata della funzione di verosimiglianza sono passaggi essenziali nel processo di analisi dati. Essa costituisce uno strumento indispensabile per chi è impegnato nella ricerca empirica e nell’interpretazione di dati complessi.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_likelihood.html#esercizi",
    "href": "chapters/probability/14_likelihood.html#esercizi",
    "title": "39  La verosimiglianza",
    "section": "\n39.9 Esercizi",
    "text": "39.9 Esercizi\n\nEsercizio 39.1 Spiega ciascuno dei concetti seguenti con una frase:\n\nprobabilità.\nfunzione di massa di probabilità.\nfunzione di densità di probabilità.\ndistribuzione di probabilità.\ndistribuzione di probabilità discreta.\ndistribuzione di probabilità continua.\nfunzione di distribuzione cumulativa (cdf).\nverosimiglianza\n\n\n\n\n\n\n\n\nAll’esame ti verrà chiesto di:\n\nCalcolare la funzione di verosimiglianza binomiale e riportare il valore della funzione in corrispondenza di specifici valori \\(\\theta\\).\nCalcolare la funzione di verosimiglianza del modello gaussiano, per \\(\\sigma\\) noto, e riportare il valore della funzione in corrispondenza di specifici valori \\(\\mu\\).\nCalcolare la stima di massima verosimiglianza.\nRispondere a domande che implicano una adeguata comprensione del concetto di funzione di verosimiglianza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_likelihood.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/14_likelihood.html#informazioni-sullambiente-di-sviluppo",
    "title": "39  La verosimiglianza",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pointblank_0.12.2 haven_2.5.4       labelled_2.13.0   mice_3.17.0      \n#&gt;  [5] see_0.9.0         gridExtra_2.3     patchwork_1.3.0   bayesplot_1.11.1 \n#&gt;  [9] psych_2.4.12      scales_1.3.0      markdown_1.13     knitr_1.49       \n#&gt; [13] lubridate_1.9.4   forcats_1.0.0     stringr_1.5.1     dplyr_1.1.4      \n#&gt; [17] purrr_1.0.2       readr_2.1.5       tidyr_1.3.1       tibble_3.2.1     \n#&gt; [21] ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      shape_1.4.6.1     xfun_0.49         htmlwidgets_1.6.4\n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2      \n#&gt;  [9] generics_0.1.3    parallel_4.4.2    pan_1.9           pacman_0.5.1     \n#&gt; [13] pkgconfig_2.0.3   jomo_2.7-6        Matrix_1.7-1      lifecycle_1.0.4  \n#&gt; [17] compiler_4.4.2    farver_2.1.2      munsell_0.5.1     mnormt_2.1.1     \n#&gt; [21] codetools_0.2-20  htmltools_0.5.8.1 yaml_2.3.10       glmnet_4.1-8     \n#&gt; [25] nloptr_2.1.1      pillar_1.10.0     MASS_7.3-61       iterators_1.0.14 \n#&gt; [29] rpart_4.1.23      boot_1.3-31       foreach_1.5.2     mitml_0.4-5      \n#&gt; [33] nlme_3.1-166      tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4    \n#&gt; [37] labeling_0.4.3    splines_4.4.2     rprojroot_2.0.4   fastmap_1.2.0    \n#&gt; [41] grid_4.4.2        blastula_0.3.5    colorspace_2.1-1  cli_3.6.3        \n#&gt; [45] magrittr_2.0.3    survival_3.8-3    broom_1.0.7       withr_3.0.2      \n#&gt; [49] backports_1.5.0   timechange_0.3.0  rmarkdown_2.29    nnet_7.3-19      \n#&gt; [53] lme4_1.1-35.5     hms_1.1.3         evaluate_1.0.1    rlang_1.1.4      \n#&gt; [57] Rcpp_1.0.13-1     glue_1.8.0        minqa_1.2.8       jsonlite_1.8.9   \n#&gt; [61] R6_2.5.1",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_simulation.html",
    "href": "chapters/probability/15_simulation.html",
    "title": "40  Simulazioni",
    "section": "",
    "text": "40.1 Introduzione\nPrerequisiti\nConcetti e Competenze Chiave\nPreparazione del Notebook\nIn questo capitolo, discuteremo alcuni esercizi di simulazione presentati da Gelman et al. (2021) nel quinto capitolo del loro libro. Gli autori sottolineano che simulare variabili casuali è essenziale nelle statistiche applicate per diversi motivi:",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_simulation.html#introduzione",
    "href": "chapters/probability/15_simulation.html#introduzione",
    "title": "40  Simulazioni",
    "section": "",
    "text": "Comprensione della variazione casuale: I modelli di probabilità imitano la variabilità del mondo reale. La simulazione aiuta a sviluppare intuizioni sulle oscillazioni casuali nel breve termine e sui loro effetti nel lungo termine.\nDistribuzione campionaria: Simulare dati consente di approssimare la distribuzione campionaria, trasferendo questa approssimazione alle stime e alle procedure statistiche.\nPrevisioni probabilistiche: I modelli di regressione producono previsioni probabilistiche. La simulazione è il metodo più generale per rappresentare l’incertezza nelle previsioni.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_simulation.html#esempio-1-quante-bambine-su-400-nascite",
    "href": "chapters/probability/15_simulation.html#esempio-1-quante-bambine-su-400-nascite",
    "title": "40  Simulazioni",
    "section": "\n40.2 Esempio 1: Quante bambine su 400 nascite?",
    "text": "40.2 Esempio 1: Quante bambine su 400 nascite?\nSupponiamo che la probabilità di nascita di una bambina sia \\(p\\) = 0.488. Se in un ospedale nascono 400 bambini in un anno, quante saranno bambine? Possiamo simulare questo processo usando una distribuzione binomiale, ripetendo la simulazione 10,000 volte.\n\n# Numero di simulazioni\nn_sims &lt;- 10000\n\n# Probabilità di nascita di una bambina\np_girl &lt;- 0.488\n\n# Simulazione del numero di bambine\nset.seed(123)\nn_girls &lt;- rbinom(n_sims, size = 400, prob = p_girl)\n\n# Visualizzazione dell'istogramma\nggplot(data.frame(n_girls), aes(x = n_girls)) +\n  geom_histogram(binwidth = 5, fill = \"blue\", color = \"black\", alpha = 0.6) +\n  labs(\n    title = \"Distribuzione del Numero di Bambine su 400 Nascite\",\n    x = \"Numero di Bambine\",\n    y = \"Frequenza\"\n  )",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_simulation.html#simulazione-di-probabilità-continue",
    "href": "chapters/probability/15_simulation.html#simulazione-di-probabilità-continue",
    "title": "40  Simulazioni",
    "section": "\n40.3 Simulazione di probabilità continue",
    "text": "40.3 Simulazione di probabilità continue\nGelman et al. (2021) dimostrano come sia possibile incorporare anche distribuzioni di probabilità continue nei tipi di simulazioni discusse nella sezione precedente. Forniscono il seguente esempio di un modello misto discreto/continuo: il 52% degli adulti negli Stati Uniti sono donne e il 48% sono uomini. L’altezza degli uomini segue approssimativamente una distribuzione normale con una media di 69.1 pollici e una deviazione standard di 2.9 pollici; per le donne, la media è 63.7 pollici e la deviazione standard è 2.7 pollici. Ecco il codice per generare l’altezza di un adulto scelto casualmente:\n\nsimulate_height &lt;- function(N) {\n  gender &lt;- rbinom(N, size = 1, prob = 0.48) # 1 = uomo, 0 = donna\n  height &lt;- ifelse(\n    gender == 1,\n    rnorm(N, mean = 69.1, sd = 2.9),\n    rnorm(N, mean = 63.7, sd = 2.7)\n  )\n  return(mean(height))\n}\n\nSupponiamo di selezionare 10 adulti a caso. Cosa possiamo dire della loro altezza media?\n\nset.seed(123)\nn_sims &lt;- 10000\navg_heights &lt;- replicate(n_sims, simulate_height(10))\n\n# Visualizzazione dell'istogramma\nggplot(data.frame(avg_heights), aes(x = avg_heights)) +\n  geom_histogram(binwidth = 0.2, fill = \"blue\", color = \"black\", alpha = 0.6) +\n  labs(\n    title = \"Distribuzione dell'Altezza Media di 10 Adulti\",\n    x = \"Altezza Media\",\n    y = \"Frequenza\"\n  )",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_simulation.html#sommario-di-una-simulazione-con-media-e-mediana",
    "href": "chapters/probability/15_simulation.html#sommario-di-una-simulazione-con-media-e-mediana",
    "title": "40  Simulazioni",
    "section": "\n40.4 Sommario di una simulazione con media e mediana",
    "text": "40.4 Sommario di una simulazione con media e mediana\nQuando le nostre distribuzioni sono costruite come simulazioni al computer, può essere conveniente riassumerle in qualche modo. Tipicamente, riassumiamo la posizione di una distribuzione con la sua media o mediana.\nLa variazione nella distribuzione è tipicamente riassunta dalla deviazione standard, ma spesso preferiamo usare la deviazione mediana assoluta. Se la mediana di un insieme di simulazioni \\(z_1, \\ldots, z_n\\) è \\(M\\), allora la deviazione mediana assoluta è:\n\\[ \\text{mad} = \\text{mediana}_{n} |z_i - M| \\]\nTuttavia, poiché siamo abituati a lavorare con le deviazioni standard, quando calcoliamo la deviazione mediana assoluta, la riscaliamo moltiplicandola per 1.483, il che riproduce la deviazione standard nel caso speciale della distribuzione normale:\n\\[ 1.483 * \\text{median}(|y - \\text{median}(z)|) \\]\nPreferiamo tipicamente i riassunti basati sulla mediana perché sono più stabili computazionalmente, e riscaliamo il riassunto basato sulla mediana della variazione come descritto sopra in modo da essere comparabile alla deviazione standard, che sappiamo già interpretare nella pratica statistica usuale.\nEcco come implementare quanto sopra in R per i dati relativi all’altezza media di 10 adulti.\n\n# Calcolo della media e mediana\nmean_avg_height &lt;- mean(avg_heights)\nmedian_avg_height &lt;- median(avg_heights)\n\n# Calcolo della deviazione standard\nsd_avg_height &lt;- sd(avg_heights)\n\n# Calcolo della MAD (Deviazione Mediana Assoluta)\nmad_avg_height &lt;- median(abs(avg_heights - median_avg_height)) * 1.483\n\n# Risultati\ncat(\"Mean:\", mean_avg_height, \"\\n\")\n#&gt; Mean: 66.3\ncat(\"Median:\", median_avg_height, \"\\n\")\n#&gt; Median: 66.3\ncat(\"Standard Deviation:\", sd_avg_height, \"\\n\")\n#&gt; Standard Deviation: 1.23\ncat(\"MAD (scaled):\", mad_avg_height, \"\\n\")\n#&gt; MAD (scaled): 1.23\n\n\n40.4.1 Intervalli di Incertezza\nPer rappresentare l’incertezza, possiamo calcolare intervalli centrali al 50% e al 95%.\n\n# Intervalli di incertezza\nlower_50 &lt;- quantile(avg_heights, 0.25)\nupper_50 &lt;- quantile(avg_heights, 0.75)\n\nlower_95 &lt;- quantile(avg_heights, 0.025)\nupper_95 &lt;- quantile(avg_heights, 0.975)\n\ncat(\"50% Interval:\", lower_50, \"-\", upper_50, \"\\n\")\n#&gt; 50% Interval: 65.5 - 67.1\ncat(\"95% Interval:\", lower_95, \"-\", upper_95, \"\\n\")\n#&gt; 95% Interval: 63.9 - 68.8\n\nEcco come interpretarli.\nIntervallo centrale al 50%.\n\nContiene i valori centrali che coprono il 50% della distribuzione. Questo intervallo si estende dal primo quartile (25° percentile) al terzo quartile (75° percentile).\nIndica la fascia di valori in cui si trovano i risultati “più comuni” o tipici. È una misura di variabilità concentrata nella parte centrale della distribuzione, meno sensibile a valori estremi.\n\nPer le altezze medie simulate di 10 adulti, un intervallo centrale al 50% che va da 65 a 67 pollici indica che metà delle medie osservate si trova in questo intervallo.\n\n\n\nIntervallo centrale al 95%.\n\nContiene il 95% della distribuzione simulata, lasciando solo il 2.5% dei valori al di sotto e il 2.5% al di sopra dell’intervallo. Questo intervallo si calcola tra il 2.5° percentile e il 97.5° percentile.\nIndica una fascia più ampia che cattura quasi tutti i valori plausibili, inclusi quelli meno probabili ma comunque possibili.\n\nPer le altezze medie simulate, un intervallo al 95% che va da 64 a 68 pollici significa che, in quasi tutte le simulazioni, l’altezza media si trova in questo intervallo, con poche eccezioni.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_simulation.html#commenti-e-considerazioni-finali",
    "href": "chapters/probability/15_simulation.html#commenti-e-considerazioni-finali",
    "title": "40  Simulazioni",
    "section": "\n40.5 Commenti e Considerazioni Finali",
    "text": "40.5 Commenti e Considerazioni Finali\nLo scopo della simulazione di dati fittizi non è fornire intuizioni sui dati o sul problema reale in esame, ma piuttosto valutare le proprietà dei metodi statistici utilizzati, partendo da un modello generativo ipotizzato. Le simulazioni sono cruciali nella pratica della ricerca. Molti autori suggeriscono che dovrebbero essere eseguite prima di raccogliere i dati di uno studio, per valutare, tra le altre cose, se la dimensione campionaria prevista fornisce un potere statistico sufficiente per rispondere alla domanda della ricerca (Gelman & Brown, 2024).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_simulation.html#esercizi",
    "href": "chapters/probability/15_simulation.html#esercizi",
    "title": "40  Simulazioni",
    "section": "\n40.6 Esercizi",
    "text": "40.6 Esercizi\n\nEsercizio 40.1 Immagina il caso di 220 studenti che devono sostenere tre prove in itinere in un corso. Il voto finale è la media dei voti ottenuti in queste tre prove. Le distribuzioni dei voti per le prove sono descritte come segue:\n\nPrima prova: I voti sono distribuiti secondo una gaussiana con media 24. Il 15% degli studenti ottiene un voto inferiore a 18.\nSeconda prova: I voti sono distribuiti secondo una gaussiana con media 25. Il 10% degli studenti ottiene un voto inferiore a 18.\nTerza prova: I voti sono distribuiti secondo una gaussiana con media 26. Solo il 5% degli studenti ottiene un voto inferiore a 18.\n\nDei 220 studenti iniziali:\n\nIl 10% non partecipa alla prima prova.\nUn ulteriore 5% non partecipa alla seconda prova.\n\nPer ottenere il voto finale, uno studente deve partecipare a tutte e tre le prove.\nUtilizzando una simulazione, trova la media finale dei voti e calcola l’intervallo di incertezza al 90% per la stima della media.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_simulation.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/15_simulation.html#informazioni-sullambiente-di-sviluppo",
    "title": "40  Simulazioni",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] see_0.9.0        gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1\n#&gt;  [5] psych_2.4.12     scales_1.3.0     markdown_1.13    knitr_1.49      \n#&gt;  [9] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [13] purrr_1.0.2      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [17] ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.3         rlang_1.1.4       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       yaml_2.3.10       tools_4.4.2       parallel_4.4.2   \n#&gt; [21] tzdb_0.4.0        colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5      \n#&gt; [25] R6_2.5.1          lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3  \n#&gt; [29] pillar_1.10.0     gtable_0.3.6      glue_1.8.0        xfun_0.49        \n#&gt; [33] tidyselect_1.2.1  farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-166     \n#&gt; [37] labeling_0.4.3    rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_simulation.html#bibliografia",
    "href": "chapters/probability/15_simulation.html#bibliografia",
    "title": "40  Simulazioni",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., & Brown, N. J. (2024). How statistical challenges and misreadings of the literature combine to produce unreplicable science: An example from psychology.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other stories. Cambridge University Press.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/introduction_bayes_inference.html",
    "href": "chapters/bayesian_inference/introduction_bayes_inference.html",
    "title": "Introduzione",
    "section": "",
    "text": "In questa sezione della dispensa, esamineremo l’inferenza bayesiana applicata a modelli statistici in cui si stima un unico parametro scalare, cioè quando l’estimando \\(\\theta\\) è unidimensionale. In questo capitolo, consideriamo quattro modelli unidimensionali fondamentali e ampiamente utilizzati: il modello binomiale, il modello normale, il modello di Poisson e il modello esponenziale. Approfondiremo il processo di aggiornamento bayesiano, analizzando due metodi principali per derivare la distribuzione a posteriori: l’approssimazione numerica attraverso il metodo basato su griglia e l’utilizzo delle distribuzioni coniugate, in cui una specifica combinazione di distribuzione a priori e verosimiglianza consente una derivazione analitica della distribuzione a posteriori. Inoltre, considereremo l’influenza della scelta della distribuzione a priori sulla distribuzione a posteriori e discuteremo le tecniche utili per sintetizzare e interpretare quest’ultima in modo efficace.",
    "crumbs": [
      "Inferenza",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html",
    "href": "chapters/bayesian_inference/01_intro_bayes.html",
    "title": "41  La quantificazione dell’incertezza",
    "section": "",
    "text": "41.1 Introduzione\nPrerequisiti\nConcetti e Competenze Chiave\nPreparazione del Notebook\nL’approccio bayesiano non si limita all’applicazione del Teorema di Bayes, ma si distingue per una gestione esplicita dell’incertezza e per l’uso delle distribuzioni di probabilità per rappresentare stime e soluzioni. Il processo di modellazione bayesiana, noto come workflow bayesiano (Baribault & Collins, 2023), comprende più fasi iterative: dalla costruzione del modello, all’applicazione del Teorema di Bayes, fino all’analisi critica dei risultati. Questo approccio permette un continuo affinamento delle stime, adattandole alle nuove evidenze.\nL’obiettivo dell’approccio bayesiano non è scoprire una “verità assoluta”, ma aggiornare razionalmente le credenze riguardo a un’ipotesi integrando nuove informazioni. In psicologia, dove le misurazioni sono soggette a incertezza e i fenomeni complessi, questa capacità è cruciale.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#introduzione",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#introduzione",
    "title": "41  La quantificazione dell’incertezza",
    "section": "",
    "text": "“Quindi non avete una sola risposta alle vostre domande?”\n“Adson, se l’avessi insegnerei teologia a Parigi.”\n“A Parigi hanno sempre la risposta vera?”\n“Mai,” disse Guglielmo, “ma sono molto sicuri dei loro errori.”\n(Umberto Eco: Il Nome della Rosa)",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#il-valore-dellincertezza",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#il-valore-dellincertezza",
    "title": "41  La quantificazione dell’incertezza",
    "section": "\n41.2 Il Valore dell’Incertezza",
    "text": "41.2 Il Valore dell’Incertezza\nIn psicologia e in altre scienze sociali, l’informazione è spesso incompleta, e le variabili di interesse sono latenti o difficili da osservare direttamente. L’inferenza bayesiana offre un quadro metodologico per rappresentare e affrontare questa incertezza, permettendo di modellare ciò che non si conosce come una variabile aleatoria che può essere aggiornata man mano che si acquisiscono nuovi dati (Jaynes, 2003).\nDiversamente dai modelli deterministici, che assumono la possibilità di prevedere i risultati con certezza date tutte le informazioni, i modelli bayesiani accolgono e gestiscono l’incertezza, caratteristica fondamentale in psicologia. Molti fenomeni psicologici coinvolgono variabili latenti – come l’ansia, la motivazione o l’autostima – che non possono essere osservate direttamente. L’approccio bayesiano consente di rappresentare tali variabili in modo flessibile, integrando evidenze precedenti con i dati attuali.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#interpretazione-frequentista-vs.-bayesiana-dellincertezza",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#interpretazione-frequentista-vs.-bayesiana-dellincertezza",
    "title": "41  La quantificazione dell’incertezza",
    "section": "\n41.3 Interpretazione Frequentista vs. Bayesiana dell’Incertezza",
    "text": "41.3 Interpretazione Frequentista vs. Bayesiana dell’Incertezza\n\nInterpretazione Frequentista: Immaginiamo di misurare la frequenza di un evento psicologico, come un livello di ansia oltre una certa soglia, in un grande campione di individui simili. Secondo i frequentisti, si potrebbe interpretare l’incertezza come la frequenza relativa dell’evento in situazioni simili nel lungo periodo. Tuttavia, questa interpretazione presenta due problemi principali: non è possibile osservare un evento infinite volte in condizioni identiche, e il “gruppo di riferimento” (o reference class) – cioè, le condizioni simili rilevanti – può essere difficile da definire precisamente.\nInterpretazione Bayesiana: Un’interpretazione bayesiana dell’incertezza riguarda invece il grado di credenza soggettiva. Supponiamo che uno psicologo creda con il 10% di fiducia che un individuo avrà un punteggio d’ansia superiore a una certa soglia. Questo grado di fiducia può essere aggiornato man mano che si raccolgono nuove informazioni, utilizzando il Teorema di Bayes per calcolare probabilità a posteriori. A differenza dell’approccio frequentista, l’incertezza bayesiana descrive una credenza soggettiva che può essere costantemente aggiornata.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#esempi-psicologici-dellinferenza-bayesiana",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#esempi-psicologici-dellinferenza-bayesiana",
    "title": "41  La quantificazione dell’incertezza",
    "section": "\n41.4 Esempi Psicologici dell’Inferenza Bayesiana",
    "text": "41.4 Esempi Psicologici dell’Inferenza Bayesiana\nEsempio 1: Misurare l’Ansia con Questionari\nQuando si misura l’ansia tramite un questionario, la stima è soggetta a incertezza per vari motivi: 1. Risposte Soggettive: L’interpretazione delle domande può variare tra individui e può essere influenzata dallo stato d’animo. 2. Misurazioni Incomplete: Un questionario può non cogliere tutte le sfumature dell’ansia. 3. Rumore nei Dati: Errori minori, come distrazioni durante la compilazione, possono influire sulla precisione dei risultati.\nCon l’approccio bayesiano, è possibile combinare credenze a priori basate su ricerche precedenti con i dati raccolti per ottenere una stima aggiornata. Ad esempio, se si dispone di una distribuzione di probabilità iniziale sull’ansia, questa distribuzione può essere aggiornata man mano che si raccolgono più dati, permettendo una stima più accurata del livello di ansia effettivo.\nEsempio 2: Effetto del Rinforzo Negativo sulla Motivazione\nConsideriamo uno studio sull’effetto del rinforzo negativo sulla motivazione in un compito. La “motivazione interna” è una variabile latente, non osservabile direttamente. Possiamo inferirla, però, tramite misure indirette, come il tempo trascorso sul compito o la velocità di risposta. Un modello bayesiano consente di collegare queste variabili osservabili alla motivazione latente, rappresentando l’incertezza sia nella variabilità individuale sia nell’effetto del rinforzo negativo. Man mano che vengono raccolti nuovi dati, il modello bayesiano aggiorna le stime di motivazione e permette di esprimere in modo rigoroso la probabilità che un cambiamento osservato sia effettivamente dovuto al rinforzo negativo.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#inferenza-bayesiana-e-incertezza-nelle-stime",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#inferenza-bayesiana-e-incertezza-nelle-stime",
    "title": "41  La quantificazione dell’incertezza",
    "section": "\n41.5 Inferenza Bayesiana e Incertezza nelle Stime",
    "text": "41.5 Inferenza Bayesiana e Incertezza nelle Stime\nL’inferenza bayesiana utilizza le probabilità per aggiornare le credenze sui parametri di un modello basandosi sui dati osservati. Queste credenze sono rappresentate da distribuzioni di probabilità, e l’ampiezza di queste distribuzioni riflette l’incertezza associata alle stime. In psicologia, dove spesso si lavora con campioni limitati e misurazioni indirette di variabili latenti, questa gestione dell’incertezza è fondamentale per interpretare i risultati in modo robusto e realistico.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#il-modello-bayesiano",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#il-modello-bayesiano",
    "title": "41  La quantificazione dell’incertezza",
    "section": "\n41.6 Il Modello Bayesiano",
    "text": "41.6 Il Modello Bayesiano\nUn modello statistico combina una distribuzione probabilistica con ipotesi sui parametri per descrivere un fenomeno osservato. Ad esempio, possiamo modellare il lancio di una moneta equa con un modello binomiale, in cui la probabilità \\(\\theta\\) è fissata a 0.5, oppure modellare l’altezza degli uomini italiani con un modello normale, in cui \\(\\mu\\) è 183 cm e \\(\\sigma\\) è 5 cm. In termini bayesiani, il modello statistico include tre componenti principali:\n\nDistribuzione a Priori (Prior): Rappresenta le credenze iniziali sui valori dei parametri del modello, informate da ricerche precedenti o da assunzioni neutre.\nVerosimiglianza (Likelihood): Descrive la probabilità di osservare i dati dati i parametri del modello, riflettendo il processo che genera i dati.\nDistribuzione a Posteriori (Posterior): È la distribuzione aggiornata dei parametri dopo aver osservato i dati, ottenuta combinando la prior e la verosimiglianza mediante il teorema di Bayes. La posterior rappresenta la conoscenza aggiornata dopo aver integrato le informazioni fornite dai dati.\n\nLa modellazione bayesiana descrive il processo generativo che ha prodotto i dati osservati, incorporando l’incertezza nei parametri e aggiornando continuamente le stime man mano che emergono nuovi dati. Questo approccio è particolarmente utile in contesti come la psicologia, dove i fenomeni complessi e le variabili latenti rendono necessario modellare l’incertezza in modo esplicito.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#componenti-chiave-della-modellazione-probabilistica",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#componenti-chiave-della-modellazione-probabilistica",
    "title": "41  La quantificazione dell’incertezza",
    "section": "\n41.7 Componenti Chiave della Modellazione Probabilistica",
    "text": "41.7 Componenti Chiave della Modellazione Probabilistica\n\nVariabili Aleatorie: Quantità incerte che assumono diversi valori secondo una distribuzione di probabilità. Ad esempio, il livello di depressione di un paziente può essere trattato come una variabile aleatoria.\nDistribuzioni di Probabilità: Descrivono come i valori di una variabile aleatoria sono distribuiti. Ad esempio, una distribuzione normale può essere utilizzata per modellare la variabilità dell’ansia in una popolazione.\nInferenza Bayesiana: Aggiorna la distribuzione di probabilità delle variabili di interesse sulla base dei nuovi dati, migliorando progressivamente le stime.\n\nEsempio: Inferenza sul Livello di Depressione\nIn uno studio clinico sulla depressione, possiamo utilizzare l’inferenza bayesiana per stimare il livello di depressione di un paziente partendo da una distribuzione a priori informata da studi precedenti. Ogni nuovo dato raccolto (come punteggi a questionari o osservazioni) permette di aggiornare questa stima, affinando progressivamente la comprensione del fenomeno.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#il-potere-dellaggiornamento-bayesiano",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#il-potere-dellaggiornamento-bayesiano",
    "title": "41  La quantificazione dell’incertezza",
    "section": "\n41.8 Il Potere dell’Aggiornamento Bayesiano",
    "text": "41.8 Il Potere dell’Aggiornamento Bayesiano\nIl vero punto di forza della modellazione bayesiana risiede nella sua capacità di aggiornare continuamente le credenze sui parametri del modello man mano che si raccolgono nuovi dati. Questo processo iterativo, basato sul teorema di Bayes, consente di integrare sia le credenze iniziali (a priori) sia le evidenze empiriche (verosimiglianza) per ottenere stime sempre più precise.\nEsempio Intuitivo: Il Globo Terrestre\nUn esempio intuitivo per spiegare l’aggiornamento bayesiano è quello proposto da McElreath (2020). Supponiamo di voler stimare la proporzione della superficie terrestre coperta d’acqua. L’esperimento consiste nel lanciare un globo terrestre in aria, afferrarlo e osservare se la superficie sotto il dito è acqua o terra. Dopo ogni osservazione, possiamo aggiornare le nostre credenze sulla proporzione d’acqua (p).\nIniziamo con una distribuzione a priori che assegna la stessa probabilità a tutti i valori possibili di \\(p\\) (proporzione d’acqua). Dopo il primo lancio, in cui osserviamo acqua (“W”), la probabilità che \\(p\\) sia zero diminuisce, mentre quella che \\(p\\) sia maggiore aumenta. Man mano che raccogliamo più dati, la distribuzione si aggiorna, riducendo l’incertezza e convergendo verso una stima più precisa di \\(p\\).\nCon l’aumento dei dati osservati, la distribuzione a posteriori si concentra sempre di più attorno ai valori di \\(p\\) che meglio spiegano i dati. Questo processo rappresenta il continuo affinamento delle stime bayesiane, che diventano più accurate man mano che le evidenze si accumulano.\nIn sintesi, l’aggiornamento bayesiano fornisce un quadro flessibile e sistematico per trattare l’incertezza e integrare nuove informazioni. È particolarmente utile nelle scienze psicologiche e sociali, dove la complessità e la variabilità dei fenomeni rendono difficile ottenere stime precise. Questo approccio consente di migliorare costantemente la comprensione dei fenomeni, adattando le credenze man mano che emergono nuovi dati.\n\n\n\n\n\n\n\n\nIl grafico precedente illustra un processo di aggiornamento bayesiano, in cui vengono progressivamente aggiornate le credenze sulla proporzione di superficie coperta d’acqua (\\(p\\)) del globo terrestre, man mano che vengono raccolti nuovi dati.\nL’esperimento prevede il lancio di un globo terrestre per osservare se la superficie sotto il dito è acqua (“W”) o terra (“L”). Dopo ogni lancio, le probabilità sui possibili valori di \\(p\\) vengono aggiornate sulla base delle osservazioni, utilizzando il teorema di Bayes. Il processo è visualizzato attraverso una serie di grafici, organizzati in una griglia 3x3, con ogni pannello che rappresenta un’osservazione aggiuntiva.\n\nLinee tratteggiate: Ogni curva tratteggiata in un pannello rappresenta la distribuzione di probabilità a posteriori (posterior) derivata dal pannello precedente. In altre parole, questa è la distribuzione che incorpora tutte le osservazioni fino a quel momento.\nLinee continue: Ogni curva continua rappresenta la nuova distribuzione a posteriori, aggiornata dopo aver aggiunto una nuova osservazione. Questa curva combina la distribuzione a priori (che coincide con la curva tratteggiata dal pannello precedente) e la nuova evidenza.\n\n\n\nPrimo Pannello (Osservazione: W)\n\nLa prima osservazione è “acqua” (W). La distribuzione a priori è uniforme, poiché non ci sono informazioni iniziali. Dopo aver osservato acqua, la distribuzione a posteriori si aggiorna: la probabilità che \\(p = 0\\) (nessuna acqua) è ora zero, e la curva si sposta verso destra, indicando che è più probabile che \\(p\\) sia maggiore di 0.\n\n\n\nSecondo Pannello (Osservazione: L)\n\nLa seconda osservazione è “terra” (L). La curva si sposta leggermente verso sinistra, poiché è ora meno probabile che \\(p\\) sia molto alto (vicino a 1). La probabilità che \\(p\\) sia 0.5 diventa massima, in quanto abbiamo osservato una volta acqua e una volta terra.\n\n\n\nTerzo Pannello (Osservazione: W)\n\nIl terzo lancio produce di nuovo acqua. La curva si sposta nuovamente verso destra, con un picco vicino a \\(p = 0.75\\), riflettendo che abbiamo osservato acqua due volte su tre. La distribuzione si aggiorna in base alla nuova evidenza.\n\n\n\nPannelli Successivi\n\nOgni nuovo pannello segue lo stesso schema: la distribuzione a priori (linea tratteggiata) viene aggiornata con la nuova osservazione (linea continua). Se viene osservata acqua (W), il picco della distribuzione si sposta a destra; se viene osservata terra (L), il picco si sposta a sinistra. In ogni caso, la curva diventa progressivamente più “appuntita”, indicando che l’incertezza sulla vera proporzione di acqua diminuisce con l’aumentare del numero di osservazioni.\n\n\n\nL’aspetto fondamentale dell’approccio bayesiano è che ogni distribuzione a posteriori aggiornata (linea continua) diventa la nuova distribuzione a priori per la successiva osservazione. Questo processo iterativo permette di apprendere progressivamente dai dati, integrando ogni nuova informazione per affinare la stima di \\(p\\). Alla fine, la distribuzione diventa sempre più concentrata intorno al valore più probabile di \\(p\\), man mano che raccogliamo più dati.\nIn conclusione, l’esempio illustra come l’aggiornamento bayesiano modifichi le nostre credenze sulla proporzione d’acqua (\\(p\\)) sulla superficie del globo, basandosi sulle osservazioni raccolte. Ogni curva rappresenta la sintesi delle conoscenze attuali, combinando le osservazioni precedenti con l’ultima evidenza raccolta. Il grafico dimostra visivamente come l’approccio bayesiano consenta di trattare l’incertezza e aggiornare le stime in modo coerente e progressivo.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#il-processo-generatore-dei-dati",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#il-processo-generatore-dei-dati",
    "title": "41  La quantificazione dell’incertezza",
    "section": "\n41.9 Il Processo Generatore dei Dati",
    "text": "41.9 Il Processo Generatore dei Dati\nNel contesto dell’aggiornamento bayesiano, è fondamentale fare un’assunzione su quale modello statistico descriva il processo generatore dei dati, ossia il meccanismo che collega i parametri sconosciuti ai dati osservati. Questo modello è rappresentato dalla funzione di verosimiglianza, che descrive la probabilità di osservare i dati per ogni possibile valore del parametro incognito. Ad esempio, nel caso di esperimenti bernoulliani come quello dei lanci del globo, ogni prova può risultare in un successo (acqua) o in un fallimento (terra), e l’obiettivo è stimare la probabilità di successo, \\(\\theta\\).\nIl processo generatore dei dati per questo tipo di esperimento è ben descritto da una distribuzione binomiale, che modella il numero di successi osservati in una serie di prove indipendenti, ciascuna caratterizzata dalla stessa probabilità \\(\\theta\\). In questo contesto, \\(\\theta\\) rappresenta la proporzione di superficie coperta d’acqua sul globo, e l’assunzione chiave è che essa rimanga costante durante l’intero esperimento.\n\n\n\n\n\nFigura 41.1: Gli stessi dati possono essere coerenti con diverse ipotesi riguardanti il processo che li ha generati(Figura tratta da Freiesleben & Molnar, 2024).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#aggiornamento-bayesiano-e-processo-generatore",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#aggiornamento-bayesiano-e-processo-generatore",
    "title": "41  La quantificazione dell’incertezza",
    "section": "\n41.10 Aggiornamento Bayesiano e Processo Generatore",
    "text": "41.10 Aggiornamento Bayesiano e Processo Generatore\nL’aggiornamento bayesiano permette di modificare le nostre credenze riguardo al valore del parametro \\(\\theta\\) man mano che osserviamo nuovi dati. Il punto di partenza è una distribuzione a priori su \\(\\theta\\), che può riflettere la nostra ignoranza (ad esempio, una distribuzione uniforme, che assegna uguale probabilità a tutti i valori di \\(\\theta\\) tra 0 e 1) o conoscenze preesistenti. Nel nostro esempio con il globo, possiamo iniziare con una distribuzione a priori uniforme, che indica che ogni proporzione di acqua è inizialmente considerata ugualmente probabile.\nMan mano che raccogliamo dati (ad esempio, 6 successi su 9 lanci), applichiamo il Teorema di Bayes per combinare la distribuzione a priori con la verosimiglianza dei dati osservati, ottenendo una distribuzione a posteriori che rappresenta le nostre credenze aggiornate su \\(\\theta\\). La distribuzione a posteriori riflette le informazioni aggiunte dai dati e fornisce una stima aggiornata e più precisa di \\(\\theta\\).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#interpretazione-della-distribuzione-a-posteriori",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#interpretazione-della-distribuzione-a-posteriori",
    "title": "41  La quantificazione dell’incertezza",
    "section": "\n41.11 Interpretazione della Distribuzione a Posteriori",
    "text": "41.11 Interpretazione della Distribuzione a Posteriori\nLa distribuzione a posteriori ci permette di fare inferenze più solide su \\(\\theta\\). In particolare, possiamo calcolare:\n\n\nModa: Il valore di \\(\\theta\\) con la massima probabilità, che indica la stima più plausibile.\n\nMedia o Mediana: Altre misure riassuntive della distribuzione a posteriori, che possono fornire ulteriori informazioni sull’intervallo di valori probabili per \\(\\theta\\).\n\nL’incertezza sulla stima è rappresentata dall’ampiezza della distribuzione a posteriori. Se la distribuzione è stretta, significa che l’incertezza è bassa, mentre una distribuzione più ampia indica una maggiore incertezza. Con l’aumento dei dati osservati, la distribuzione tende a concentrarsi intorno a un intervallo ristretto, riducendo l’incertezza e migliorando la precisione della stima.\nNel caso del globo, ad esempio, se osserviamo che la distribuzione a posteriori ha un picco vicino a \\(\\theta = 0.67\\), possiamo concludere che la probabilità più plausibile per la proporzione di acqua sul globo è circa 67%. Inoltre, se la distribuzione a posteriori è stretta, possiamo essere più sicuri di questa stima, mentre se è più ampia, la nostra incertezza sarà maggiore.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#influenza-delle-distribuzioni-a-priori",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#influenza-delle-distribuzioni-a-priori",
    "title": "41  La quantificazione dell’incertezza",
    "section": "\n41.12 Influenza delle Distribuzioni a Priori",
    "text": "41.12 Influenza delle Distribuzioni a Priori\nIn questo esempio, abbiamo utilizzato una distribuzione a priori uniforme, che esprime una totale mancanza di conoscenza iniziale su \\(\\theta\\). Tuttavia, in contesti in cui abbiamo informazioni preesistenti, è possibile utilizzare distribuzioni a priori più informative. Ad esempio, se sappiamo da studi precedenti che circa il 70% della superficie terrestre è coperta d’acqua, possiamo utilizzare una distribuzione a priori che rifletta questa conoscenza. Questo tipo di distribuzione a priori informativa può rendere l’aggiornamento bayesiano più efficiente, portando a stime più precise con meno dati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#vantaggi-dellaggiornamento-bayesiano",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#vantaggi-dellaggiornamento-bayesiano",
    "title": "41  La quantificazione dell’incertezza",
    "section": "\n41.13 Vantaggi dell’Aggiornamento Bayesiano",
    "text": "41.13 Vantaggi dell’Aggiornamento Bayesiano\nUno dei principali vantaggi dell’approccio bayesiano è che ogni nuova osservazione aggiorna automaticamente le credenze preesistenti, integrando le informazioni precedenti con i nuovi dati. Questo processo consente un apprendimento iterativo e progressivo, che diventa più efficiente man mano che si accumulano dati. Inoltre, la flessibilità nella scelta della distribuzione a priori consente al ricercatore di adattare l’inferenza bayesiana al contesto specifico, migliorando ulteriormente la precisione delle stime.\nIn sintesi, il processo generatore dei dati, modellato tramite la verosimiglianza, gioca un ruolo centrale nell’aggiornamento bayesiano. Nel caso del globo, abbiamo modellato il fenomeno utilizzando una distribuzione binomiale e, attraverso l’applicazione del Teorema di Bayes, abbiamo aggiornato progressivamente le nostre credenze sulla proporzione di acqua osservata. Il risultato è una stima sempre più precisa di \\(\\theta\\), con una distribuzione a posteriori che riflette sia le osservazioni passate sia le nuove evidenze, riducendo progressivamente l’incertezza.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#riflessioni-conclusive",
    "title": "41  La quantificazione dell’incertezza",
    "section": "\n41.14 Riflessioni Conclusive",
    "text": "41.14 Riflessioni Conclusive\nNegli ultimi anni, i metodi bayesiani stanno acquisendo sempre più importanza nel campo dell’inferenza statistica, anche in discipline come la psicologia. Questa diffusione è favorita dall’accesso a risorse educative e a testi fondamentali, come quelli di Albert & Hu (2019), Johnson et al. (2022), McElreath (2020) e Kruschke (2014), che hanno reso la modellizzazione bayesiana più accessibile, chiarendo i concetti centrali in modo pratico e comprensibile.\nL’approccio bayesiano si distingue dalla metodologia frequentista tradizionale per la sua capacità di trattare i parametri di interesse come quantità probabilistiche. Invece di considerare i parametri come valori fissi e sconosciuti (come avviene nel paradigma frequentista), il bayesianesimo assegna ai parametri una distribuzione a priori, che rappresenta le credenze iniziali del ricercatore. Man mano che nuovi dati vengono raccolti, queste credenze vengono aggiornate tramite il teorema di Bayes, portando a una distribuzione a posteriori che riflette sia le informazioni pregresse sia l’evidenza empirica. Questa distribuzione aggiornata consente di esprimere l’incertezza sui parametri in modo più completo e informato.\nUno dei principali vantaggi dell’approccio bayesiano è la sua capacità di combinare conoscenze pregresse con nuove osservazioni in modo fluido e sistematico. Ogni nuova informazione arricchisce e raffina le stime, rendendole più accurate e interpretabili nel contesto del problema specifico. Questo non solo migliora la precisione delle inferenze, ma permette anche una migliore comprensione dell’incertezza che circonda i parametri studiati.\nIn definitiva, l’inferenza bayesiana non è solo uno strumento analitico, ma un approccio dinamico che incoraggia un’interazione continua tra teoria ed evidenza. Offrendo una flessibilità unica e una gestione esplicita dell’incertezza, il bayesianesimo si rivela un metodo potente per supportare il processo decisionale in contesti complessi, rendendo le sue applicazioni particolarmente rilevanti in campi come la psicologia, dove l’incertezza è una componente inevitabile dell’analisi dei dati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#informazioni-sullambiente-di-sviluppo",
    "title": "41  La quantificazione dell’incertezza",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.17.0      see_0.9.0        gridExtra_2.3    patchwork_1.3.0 \n#&gt;  [5] bayesplot_1.11.1 psych_2.4.12     scales_1.3.0     markdown_1.13   \n#&gt;  [9] knitr_1.49       lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1   \n#&gt; [13] dplyr_1.1.4      purrr_1.0.2      readr_2.1.5      tidyr_1.3.1     \n#&gt; [17] tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3       \n#&gt; [21] here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      shape_1.4.6.1     xfun_0.49         htmlwidgets_1.6.4\n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2      \n#&gt;  [9] generics_0.1.3    parallel_4.4.2    pan_1.9           pacman_0.5.1     \n#&gt; [13] pkgconfig_2.0.3   jomo_2.7-6        Matrix_1.7-1      lifecycle_1.0.4  \n#&gt; [17] compiler_4.4.2    farver_2.1.2      munsell_0.5.1     mnormt_2.1.1     \n#&gt; [21] codetools_0.2-20  htmltools_0.5.8.1 yaml_2.3.10       glmnet_4.1-8     \n#&gt; [25] nloptr_2.1.1      pillar_1.10.0     MASS_7.3-61       iterators_1.0.14 \n#&gt; [29] rpart_4.1.23      boot_1.3-31       foreach_1.5.2     mitml_0.4-5      \n#&gt; [33] nlme_3.1-166      tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4    \n#&gt; [37] splines_4.4.2     rprojroot_2.0.4   fastmap_1.2.0     grid_4.4.2       \n#&gt; [41] colorspace_2.1-1  cli_3.6.3         magrittr_2.0.3    survival_3.8-3   \n#&gt; [45] broom_1.0.7       withr_3.0.2       backports_1.5.0   timechange_0.3.0 \n#&gt; [49] rmarkdown_2.29    nnet_7.3-19       lme4_1.1-35.5     hms_1.1.3        \n#&gt; [53] evaluate_1.0.1    rlang_1.1.4       Rcpp_1.0.13-1     glue_1.8.0       \n#&gt; [57] minqa_1.2.8       jsonlite_1.8.9    R6_2.5.1",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#bibliografia",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#bibliografia",
    "title": "41  La quantificazione dell’incertezza",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAlbert, J., & Hu, J. (2019). Probability and Bayesian Modeling. CRC Press.\n\n\nBaribault, B., & Collins, A. G. (2023). Troubleshooting Bayesian cognitive models. Psychological Methods.\n\n\nFreiesleben, T., & Molnar, C. (2024). Supervised Machine Learning for Science: How to stop worrying and love your black box. https://ml-science-book.com/\n\n\nGoligher, E. C., Heath, A., & Harhay, M. O. (2024). Bayesian statistics for clinical research. The Lancet, 404(10457), 1067–1076. https://doi.org/10.1016/S0140-6736(24)00055-9\n\n\nJaynes, E. T. (2003). Probability theory: The logic of science. Cambridge University Press.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nKruschke, J. (2014). Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan. Academic Press.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_bayesian_inference.html",
    "href": "chapters/bayesian_inference/02_bayesian_inference.html",
    "title": "42  Inferenza bayesiana",
    "section": "",
    "text": "42.1 Introduzione\nPrerequisiti\nConcetti e Competenze Chiave\nPreparazione del Notebook\nQuesto capitolo approfondisce i concetti introdotti nel capitolo precedente, presentando l’aggiornamento bayesiano in modo più formale e dettagliato.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_bayesian_inference.html#paradigma-bayesiano",
    "href": "chapters/bayesian_inference/02_bayesian_inference.html#paradigma-bayesiano",
    "title": "42  Inferenza bayesiana",
    "section": "\n42.2 Paradigma Bayesiano",
    "text": "42.2 Paradigma Bayesiano\nL’approccio bayesiano alla statistica si fonda sull’idea di rappresentare la conoscenza a priori sui parametri che governano un fenomeno attraverso distribuzioni di probabilità. Queste distribuzioni a priori riflettono le credenze iniziali del ricercatore riguardo ai parametri, prima di osservare i dati. Quando nuovi dati vengono raccolti, l’informazione fornita da tali dati viene integrata nel modello tramite la funzione di verosimiglianza, che rappresenta la probabilità di osservare quei dati dati i parametri ipotizzati.\nAttraverso l’applicazione del Teorema di Bayes, le credenze a priori vengono aggiornate combinando la distribuzione a priori con la verosimiglianza dei dati. Questo processo produce la distribuzione a posteriori, che rappresenta una nuova e più informata stima dei parametri, tenendo conto sia delle credenze iniziali sia dei dati osservati.\nL’approccio bayesiano richiede un cambiamento di prospettiva rispetto ai metodi classici di stima dei parametri. Non ci si limita più a trovare un singolo valore “ottimale” per i parametri del modello. Invece, l’obiettivo è determinare l’intera distribuzione a posteriori dei parametri, che descrive in modo completo lo stato di conoscenza attuale. Solo questa distribuzione fornisce una rappresentazione adeguata dell’incertezza associata ai parametri, permettendo di quantificare non solo quali valori sono più probabili, ma anche l’ampiezza dell’incertezza su tali stime.\n\n42.2.1 Vantaggi dell’Approccio Bayesiano\nUn aspetto distintivo dell’inferenza bayesiana è la sua capacità di gestire l’incertezza in modo esplicito. Invece di limitarsi a una singola stima puntuale, l’approccio bayesiano considera l’intero spettro di valori possibili per i parametri e le loro rispettive probabilità. Questo consente una rappresentazione più ricca delle informazioni disponibili e una valutazione più robusta delle ipotesi.\nInoltre, l’approccio bayesiano è altamente flessibile, permettendo di incorporare informazioni precedenti sotto forma di distribuzioni a priori. In contesti in cui si dispone di conoscenze pregresse, come dati di studi precedenti o teorie consolidate, questa caratteristica offre un vantaggio notevole rispetto agli approcci frequentisti, che non integrano facilmente tali informazioni.\nIn conclusione, il paradigma bayesiano offre una visione più ampia e completa dell’incertezza e della variabilità dei parametri rispetto ai metodi tradizionali, rappresentando un quadro teorico e pratico fondamentale per l’inferenza statistica e la modellazione.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_bayesian_inference.html#densità-di-probabilità",
    "href": "chapters/bayesian_inference/02_bayesian_inference.html#densità-di-probabilità",
    "title": "42  Inferenza bayesiana",
    "section": "\n42.3 Densità di Probabilità",
    "text": "42.3 Densità di Probabilità\nNei capitoli precedenti abbiamo esaminato alcuni esempi di funzioni di densità di probabilità (PDF). Ma quali sono le caratteristiche generali di una PDF?\nSe \\(X\\) è una variabile casuale con una funzione di densità di probabilità \\(p(x)\\), la probabilità che \\(X\\) assuma un valore nell’intervallo \\((a, b)\\) può essere calcolata come:\n\\[\np(X \\in (a,b)) = \\int_a^b p(x)dx.\n\\]\nPer variabili discrete, l’integrazione si trasforma in una somma.\n\n42.3.1 Le Regole di Somma e Prodotto\nDate due variabili casuali continue \\(x\\) e \\(y\\), le regole di somma e prodotto per le densità di probabilità si esprimono come:\n\\[\n\\begin{align*}\np(y) = \\int p(x,y)dx \\quad &\\text{- regola della somma},\\\\\np(x,y) = p(y|x) p(x) = p(x|y) p(y) \\quad &\\text{- regola del prodotto}.\n\\end{align*}\n\\]\nLa probabilità \\(p(y)\\) è chiamata probabilità marginale.\nLa regola del prodotto specifica che la distribuzione congiunta di due variabili può essere espressa come il prodotto di una distribuzione condizionata \\(p(y \\mid x)\\) e una distribuzione marginale \\(p(x)\\), o viceversa.\n\n42.3.2 La Distribuzione Marginale\nLa distribuzione marginale si riferisce alla distribuzione di probabilità di una variabile quando si tiene conto di tutte le possibili variazioni dell’altra variabile in una distribuzione congiunta. In altre parole, essa descrive la probabilità di una variabile indipendentemente dall’altra.\nConsideriamo due variabili correlate, \\(x\\) e \\(y\\). Possiamo esprimere la relazione tra di esse con la regola del prodotto:\n\\[\np(x, y) = p(y \\mid x)p(x),\n\\]\ndove \\(p(y \\mid x)\\) è la probabilità di \\(y\\) dato un certo valore di \\(x\\), e \\(p(x)\\) è la distribuzione di probabilità di \\(x\\).\nPer ottenere la distribuzione marginale di \\(y\\), dobbiamo sommare o integrare \\(p(y \\mid x)\\) su tutti i possibili valori di \\(x\\):\n\\[\np(y) = \\int p(y \\mid x)p(x)dx.\n\\]\nIn questo modo, la distribuzione marginale di \\(y\\) rappresenta la probabilità di \\(y\\), tenendo conto di tutte le possibili variazioni di \\(x\\).\n\n42.3.3 Il Teorema di Bayes\nDalla regola di prodotto, e sfruttando la proprietà di simmetria \\(p(x \\mid y)p(y) = p(y \\mid x)p(x)\\), deriviamo immediatamente la regola di Bayes:\n\\[\np(y \\mid x) = \\frac{p(x \\mid y)p(y)}{p(x)} = \\frac{p(x \\mid y)p(y)}{\\int p(x \\mid y)p(y)dy}.\n\\]\nQuesta formula è l’elemento chiave nell’inferenza bayesiana, poiché definisce la densità a posteriori di \\(y\\), \\(p(y \\mid x)\\), dopo aver incorporato l’informazione \\(x\\) attraverso il modello di probabilità condizionata \\(p(x \\mid y)\\). La probabilità marginale di \\(x\\), \\(p(x)\\), funge da costante di normalizzazione, garantendo che \\(p(y \\mid x)\\) sia una corretta funzione di densità di probabilità.\n\n42.3.4 Modellizzazione e Inferenza Bayesiana\nLa modellizzazione bayesiana consiste nel descrivere matematicamente tutti i dati osservabili \\(y\\) e i parametri non osservabili, detti anche parametri “latenti” \\(\\theta\\), definendo la distribuzione congiunta di dati e parametri \\(p(y, \\theta)\\).\nSi costruiscono modelli probabilistici per le quantità osservate condizionate ai parametri \\(p(y \\mid \\theta)\\) e per le quantità non osservate, rappresentate dalla distribuzione a priori \\(p(\\theta)\\), che rappresenta le nostre conoscenze precedenti sui parametri. Questi due elementi vengono combinati, seguendo la regola del prodotto, per formare una distribuzione congiunta:\n\\[\np(y, \\theta) = p(y \\mid \\theta)p(\\theta).\n\\]\n\n42.3.5 Il Modello Osservazionale\nLa funzione\n\\[\np(y \\mid \\theta)\n\\]\nè un modello probabilistico dei dati osservati che mette in relazione \\(y\\) con i parametri sconosciuti \\(\\theta\\) che vogliamo stimare. Questo modello rappresenta l’evidenza fornita dai dati e costituisce la principale fonte di informazione. In questo contesto, viene chiamato funzione di verosimiglianza (likelihood). È importante notare che la funzione di verosimiglianza nel contesto bayesiano non è diversa da quella utilizzata nell’approccio frequentista: in entrambi i casi collega i dati osservati ai parametri sconosciuti.\n\n42.3.6 La Distribuzione a Priori\nLa distribuzione\n\\[\np(\\theta)\n\\]\nrappresenta la distribuzione a priori dei parametri, che codifica le conoscenze preesistenti sui parametri stessi. Questa distribuzione a priori può essere informativa o non informativa, a seconda della quantità di informazioni affidabili che si possiedono sui parametri. Uno degli aspetti principali che differenziano l’approccio bayesiano da quello frequentista è l’uso delle distribuzioni di probabilità per i parametri sconosciuti. Queste distribuzioni vengono poi combinate con la funzione di verosimiglianza per ottenere una distribuzione a posteriori, che incorpora sia le informazioni precedenti che le evidenze fornite dai nuovi dati.\n\n42.3.7 Inferenza sui Parametri\nOttenere la distribuzione a posteriori dei parametri sconosciuti è l’elemento centrale dell’approccio bayesiano. Riformulando la regola di Bayes in termini di \\(y\\) e \\(\\theta\\), otteniamo una formula che ci mostra come calcolare la distribuzione a posteriori:\n\\[\np(\\theta \\mid y) = \\frac{p(y \\mid \\theta)p(\\theta)}{p(y)} = \\frac{p(y \\mid \\theta)p(\\theta)}{\\int p(y \\mid \\theta)p(\\theta) d\\theta}.\n\\]\nIl denominatore della regola di Bayes,\n\\[\np(y) = \\int p(y \\mid \\theta)p(\\theta) d \\theta,\n\\]\nè chiamato verosimiglianza marginale, poiché integra la verosimiglianza rispetto all’informazione a priori sui parametri. Questa quantità è anche nota come evidenza del modello e serve a normalizzare la distribuzione a posteriori, rendendola una vera distribuzione di probabilità. L’inferenza finale sarà un compromesso tra l’evidenza fornita dai dati e l’informazione a priori disponibile.\n\n42.3.8 Inferenza bayesiana in sintesi: verosimiglianza, prior, posteriore\nPer riassumere, ecco tutti i componenti fondamentali dell’inferenza bayesiana.\nIl teorema di Bayes, espresso in termini di dati \\(y\\) e parametri del modello \\(\\theta\\), è\n\\[\np(\\theta \\mid y) = \\frac{p(y \\mid \\theta)p(\\theta)}{p(y)},\n\\]\ndove:\n\nIl denominatore \\(p(y)\\) è la costante di normalizzazione o evidenza.\n\n\\(p(\\theta)\\) rappresenta il prior, ovvero le credenze iniziali sui parametri.\n\n\\(p(y \\mid \\theta)\\) è la verosimiglianza, che collega i dati osservati ai parametri del modello.\n\n\\(p(\\theta \\mid y)\\) è la distribuzione a posteriori, che rappresenta le credenze aggiornate sui parametri dopo aver osservato i dati.\n\nLa distribuzione a posteriori riassume il nostro stato di credenza sui possibili valori di \\(\\theta\\), aggiornato sulla base delle evidenze fornite dai dati.\nSi noti che \\(p(y)\\) non dipende dai parametri \\(\\theta\\). Pertanto, in molte situazioni pratiche, è sufficiente calcolare la distribuzione a posteriori fino a una costante. Per questo motivo, spesso la regola di Bayes viene riassunta come:\n\\[p(\\theta \\mid y) \\propto p(y \\mid \\theta)p(\\theta).\\]\nIn questa forma, si ignora il denominatore poiché è una costante (indipendente da \\(\\theta\\)).\n\n42.3.9 Il Ruolo dei Priors\nUna delle caratteristiche distintive dell’approccio bayesiano è l’incorporazione delle conoscenze a priori riguardo ai parametri del modello. Dichiarare questi priors ci obbliga a esplicitare tutte le assunzioni che facciamo sulla struttura del modello e sui suoi parametri. Allo stesso tempo, i priors sono spesso oggetto di critica nell’inferenza bayesiana a causa della soggettività che possono introdurre.\nTuttavia, l’inferenza bayesiana offre alcuni vantaggi meno evidenti a prima vista, tra cui:\n\nla capacità di lavorare efficacemente con piccoli set di dati,\nla capacità di eseguire la regolarizzazione del modello.\n\nQuesti aspetti rendono l’approccio bayesiano particolarmente utile in situazioni in cui i dati sono scarsi o le assunzioni esplicite sul modello possono contribuire a migliorare le previsioni.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_bayesian_inference.html#inferenza-predittiva",
    "href": "chapters/bayesian_inference/02_bayesian_inference.html#inferenza-predittiva",
    "title": "42  Inferenza bayesiana",
    "section": "\n42.4 Inferenza Predittiva",
    "text": "42.4 Inferenza Predittiva\nLa distribuzione a posteriori dei parametri può essere utilizzata per modellare l’incertezza nelle previsioni \\(\\tilde{y}\\) relative a nuove osservazioni. La distribuzione predittiva a posteriori di \\(\\tilde{y}\\) si ottiene marginalizzando la distribuzione congiunta delle previsioni \\(\\tilde{y}\\) e dei parametri \\(\\theta\\) rispetto ai parametri del modello:\n\\[\np(\\tilde{y} \\mid y) = \\int p(\\tilde{y}, \\theta \\mid y)d \\theta = \\int p(\\tilde{y} \\mid \\theta, y)p(\\theta|y)d\\theta.\n\\]\nIn questo modo, la distribuzione predittiva può essere vista come una media delle previsioni del modello \\(p(\\tilde{y} \\mid \\theta, y)\\) ponderata sulla distribuzione a posteriori dei parametri del modello \\(p(\\theta \\mid y)\\). Questo consente di incorporare l’incertezza sui parametri nel processo di previsione, rendendo le stime più robuste.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_bayesian_inference.html#come-possiamo-eseguire-linferenza-bayesiana",
    "href": "chapters/bayesian_inference/02_bayesian_inference.html#come-possiamo-eseguire-linferenza-bayesiana",
    "title": "42  Inferenza bayesiana",
    "section": "\n42.5 Come possiamo eseguire l’inferenza bayesiana?",
    "text": "42.5 Come possiamo eseguire l’inferenza bayesiana?\nEsistono due approcci principali per determinare la distribuzione posteriore:\n\nApproccio Analitico (o Coniugato): Questo metodo è applicabile quando la distribuzione a priori scelta e la funzione di verosimiglianza appartengono alla stessa famiglia di distribuzioni, definite coniugate. In questi casi, la distribuzione posteriore può essere calcolata analiticamente, ovvero attraverso formule matematiche esatte. L’approccio coniugato è computazionalmente efficiente ma presenta una limitazione significativa: è applicabile solo in situazioni in cui si può assumere una coniugazione tra la distribuzione a priori e la verosimiglianza. Di conseguenza, trova un impiego limitato nelle analisi di dati reali, dove spesso le assunzioni di coniugazione risultano troppo restrittive.\nApproccio Numerico: Quando non è possibile ottenere una forma analitica chiusa per la distribuzione posteriore, a causa della complessità del modello o della mancanza di coniugazione tra la distribuzione a priori e la verosimiglianza, si ricorre a metodi numerici. Questi algoritmi consentono di ottenere una stima approssimata, ma spesso accurata, della distribuzione posteriore.\n\n\n42.5.1 Metodi Numerici\nLe catene di Markov Monte Carlo (MCMC) sono una classe di algoritmi ampiamente utilizzati in questo contesto. Essi costruiscono una catena di Markov che converge alla distribuzione posteriore desiderata. Tra i metodi MCMC più comuni troviamo:\n\n\nMetropolis-Hastings: Un algoritmo generale che consente di campionare da una vasta gamma di distribuzioni posteriori.\n\nGibbs Sampling: Un caso particolare di Metropolis-Hastings, particolarmente efficiente quando la distribuzione congiunta è difficile da campionare direttamente, ma le distribuzioni condizionali sono note.\n\nOltre alle MCMC, esistono altre tecniche numeriche:\n\n\nVariational Bayes: Questo approccio consiste nel trovare la distribuzione \\(q(z)\\) che meglio approssima la distribuzione posteriore \\(p(z \\mid x)\\), secondo un criterio di divergenza (ad esempio, la divergenza di Kullback-Leibler). L’obiettivo è trasformare il problema di inferenza esatta in un problema di ottimizzazione. Variational Bayes offre spesso una soluzione più veloce rispetto alle MCMC, ma l’approssimazione può essere meno accurata in alcuni casi.\n\nLaplace approximation: Questa tecnica consiste nell’approssimare la distribuzione posteriore con una distribuzione normale centrata sul massimo a posteriori (MAP) e con matrice di covarianza pari all’inverso della matrice di Hessiano negativa calcolata nel MAP. L’approssimazione di Laplace è computazionalmente efficiente, ma è valida solo localmente attorno al MAP e può portare a stime inaccurate della varianza posteriore.\n\nVantaggi:\n\nVersatilità: L’approccio numerico è applicabile a una vasta gamma di modelli e distribuzioni.\nFlessibilità: Consente di incorporare facilmente informazioni a priori complesse.\n\nSvantaggi:\n\nCosto computazionale: Può richiedere un tempo di calcolo considerevole, soprattutto per modelli complessi o grandi dataset.\nTuning: La scelta dei parametri degli algoritmi MCMC (ad esempio, la proposta iniziale) può influenzare la convergenza e l’efficienza del campionamento.\n\nIn sintesi, l’approccio numerico offre una soluzione generale e flessibile per l’inferenza bayesiana, ma richiede una maggiore attenzione alla scelta degli algoritmi e alla valutazione della convergenza delle catene.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_bayesian_inference.html#programmazione-probabilistica",
    "href": "chapters/bayesian_inference/02_bayesian_inference.html#programmazione-probabilistica",
    "title": "42  Inferenza bayesiana",
    "section": "\n42.6 Programmazione Probabilistica",
    "text": "42.6 Programmazione Probabilistica\nI linguaggi di programmazione probabilistica (PPL) rappresentano un’importante innovazione nella modellazione bayesiana, facilitando l’uso di tecniche di approssimazione numerica per stimare le distribuzioni posteriori. Grazie ai PPL, la modellizzazione probabilistica diventa più accessibile, riducendo le barriere tecniche e computazionali. Questi strumenti consentono di definire modelli in modo dichiarativo, descrivendo le relazioni tra le variabili in termini probabilistici senza doversi occupare dei dettagli algoritmici sottostanti. In altre parole, i PPL permettono ai ricercatori di concentrarsi sull’espressione del modello, lasciando ai linguaggi il compito di gestire l’implementazione computazionale.\nTra i PPL più utilizzati troviamo:\n\n\nStan: Uno dei linguaggi più popolari, noto per la sua efficienza e flessibilità.\n\nPyMC: Molto utilizzato nell’ecosistema Python, offre un’interfaccia user-friendly per la modellazione bayesiana.\n\nTensorFlow: Un framework che combina un approccio probabilistico con le reti neurali.\n\n\n42.6.1 Vantaggi della Programmazione Probabilistica in Psicologia\nLa programmazione probabilistica offre numerosi vantaggi per la ricerca psicologica, in particolare per l’analisi di processi complessi come l’apprendimento, le emozioni e il comportamento. Alcuni dei principali vantaggi includono:\n\nFlessibilità: I PPL, come Stan, Pyro, Numpyro, PyMC e Turing.jl, offrono un quadro flessibile per la definizione e la personalizzazione dei modelli probabilistici. In psicologia, questa flessibilità è cruciale, poiché i modelli devono adattarsi a una vasta gamma di processi mentali e comportamentali che variano tra individui e contesti.\nQuantificazione dell’Incertezza: La programmazione probabilistica permette di rappresentare esplicitamente e quantificare l’incertezza, un aspetto fondamentale in psicologia, dove molte variabili di interesse, come stati emotivi o atteggiamenti, sono latenti e soggette a incertezza. Incorporare questa incertezza nei modelli consente di ottenere stime più realistiche e affidabili.\nValidazione del Modello: I PPL facilitano la validazione dei modelli psicologici, consentendo ai ricercatori di confrontare le previsioni dei modelli con i dati osservati. Tecniche come i posterior predictive checks permettono di valutare la qualità e l’affidabilità del modello, contribuendo a una maggiore solidità delle conclusioni.\nModellazione Gerarchica: Molti studi psicologici raccolgono dati a più livelli (ad esempio, misurazioni ripetute per individuo, sessioni sperimentali, contesti diversi). I PPL semplificano la costruzione e l’analisi di modelli gerarchici, catturando la variabilità sia intra- che inter-individuale.\nSelezione e Confronto dei Modelli: In psicologia è spesso necessario confrontare modelli con strutture diverse o ipotesi alternative. I PPL permettono di confrontare le capacità predittive dei modelli in modo sistematico e rigoroso, supportando la scelta del modello più adatto basandosi sull’accuratezza predittiva e non solo sulla complessità.\nComunicazione Trasparente: La programmazione probabilistica favorisce la trasparenza nella modellizzazione. I ricercatori possono specificare chiaramente le assunzioni del modello, i prior e le funzioni di verosimiglianza, rendendo più facile la comunicazione e la collaborazione con altri esperti.\nLibrerie Estensibili: I PPL offrono librerie estese e strumenti avanzati per lo sviluppo di modelli, l’inferenza e la visualizzazione. Questo riduce il carico computazionale e di implementazione, rendendo più agevole l’analisi di dati complessi tipici della psicologia sperimentale e clinica.\n\n42.6.2 Come Funzionano i PPL?\nI linguaggi di programmazione probabilistica richiedono semplicemente la descrizione del modello probabilistico. Successivamente, utilizzano algoritmi di inferenza, come le catene di Markov Monte Carlo (MCMC) o l’inferenza variazionale, per stimare la distribuzione posteriore delle variabili di interesse. Ciò consente ai ricercatori di ottenere stime delle variabili sconosciute e di valutare l’incertezza associata.\nIn conclusione, i linguaggi di programmazione probabilistica hanno trasformato il modo in cui affrontiamo l’inferenza bayesiana, rendendola più accessibile e potente. Grazie alla loro semplicità d’uso e alla potenza computazionale, i PPL hanno reso l’inferenza bayesiana uno strumento sempre più diffuso in molte discipline, inclusa la psicologia. Questo approccio facilita la modellazione di fenomeni complessi e l’analisi rigorosa di dati, offrendo un metodo efficace per rispondere a domande di ricerca psicologica in modo trasparente e accurato.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_bayesian_inference.html#notazione",
    "href": "chapters/bayesian_inference/02_bayesian_inference.html#notazione",
    "title": "42  Inferenza bayesiana",
    "section": "\n42.7 Notazione",
    "text": "42.7 Notazione\nIn seguito, utilizzeremo \\(y\\) per rappresentare i dati osservati e \\(\\theta\\) per indicare i parametri sconosciuti di un modello statistico. Entrambi, \\(y\\) e \\(\\theta\\), saranno trattati come variabili casuali. Utilizzeremo \\(x\\) per denotare le quantità note, come i predittori di un modello lineare.\nÈ comune scrivere modelli statistici utilizzando la seguente notazione:\n\\[\n\\begin{aligned}\ny & \\sim \\mathrm{normal}(\\mu, \\sigma) \\\\\n\\mu & \\sim \\mathrm{normal}(0, 10) \\\\\n\\sigma & \\sim \\mathrm{normal}^+(\\sigma \\mid  0, 1),\n\\end{aligned}\n\\]\ndove il simbolo \\(\\sim\\) è chiamato tilde (\\sim in LaTeX).\nIn generale, possiamo leggere \\(\\sim\\) come “è distribuito come”, e questa notazione è usata come una scorciatoia per definire distribuzioni. L’esempio sopra può essere scritto anche come:\n\\[\n\\begin{aligned}\n   p(y \\mid \\mu, \\sigma) & = \\mathrm{normal}(y \\mid  \\mu, \\sigma)\\\\\n   p(\\mu) & = \\mathrm{normal}(\\mu \\mid 0, 10)\\\\\n   p(\\sigma) & = \\mathrm{normal}^+(\\sigma \\mid  0, 1).\n\\end{aligned}\n\\]",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_bayesian_inference.html#addendum-la-verosimiglianza-marginale",
    "href": "chapters/bayesian_inference/02_bayesian_inference.html#addendum-la-verosimiglianza-marginale",
    "title": "42  Inferenza bayesiana",
    "section": "\n42.8 Addendum: La Verosimiglianza Marginale",
    "text": "42.8 Addendum: La Verosimiglianza Marginale\nNella discussione precedente, abbiamo introdotto la verosimiglianza marginale \\(p(y)\\) come una costante di normalizzazione. Ma perché è così importante normalizzare la distribuzione posteriore? La verosimiglianza marginale rappresenta la probabilità dei dati osservati, integrata su tutti i possibili valori del parametro \\(\\theta\\). In altre parole, esprime la probabilità di osservare i dati senza fare riferimento a un particolare valore del parametro.\nPer comprendere intuitivamente, immagina di voler stimare la temperatura media di una stanza. Usando un termometro, ottieni una misurazione, ma sei consapevole che variabili come la posizione del termometro o l’ora del giorno potrebbero influenzare la lettura. La verosimiglianza marginale è equivalente a considerare la probabilità di ottenere una certa misurazione, prendendo in considerazione tutte queste possibili variabili.\nSenza la normalizzazione, la somma delle probabilità assegnate ai diversi valori del parametro non sarebbe uguale a 1, il che significherebbe che non avremmo una distribuzione di probabilità valida. Questo renderebbe difficile interpretare correttamente i risultati. La verosimiglianza marginale agisce come una costante di normalizzazione, garantendo che l’area sotto la curva della distribuzione posteriore sia esattamente pari a 1, come richiesto da una distribuzione di probabilità.\nLa verosimiglianza marginale si calcola integrando (o sommando, nel caso di parametri discreti) la funzione di verosimiglianza rispetto a tutti i possibili valori del parametro, pesando ciascun valore con la sua probabilità a priori.\nConsideriamo un esempio con una variabile casuale binomiale \\(Y\\), la cui funzione di massa di probabilità (PMF) \\(p(Y)\\) dipende dal parametro \\(\\theta\\). Supponiamo che \\(\\theta\\) possa assumere uno tra tre valori specifici: 0.1, 0.5 o 0.9, ciascuno con una probabilità a priori di \\(\\frac{1}{3}\\).\nSe i dati indicano \\(n = 10\\) prove e \\(k = 7\\) successi, la funzione di verosimiglianza è data da:\n\\[\np(k = 7, n = 10 \\mid \\theta) = \\binom{10}{7} \\theta^7 (1 - \\theta)^3.\n\\]\nPer calcolare la verosimiglianza marginale \\(p(k = 7, n = 10)\\), marginalizziamo su \\(\\theta\\), valutando la verosimiglianza per ciascun valore di \\(\\theta\\), moltiplicando per la probabilità a priori di ciascun \\(\\theta\\), e sommando i risultati:\n\\[\np(k = 7, n = 10) = \\sum_{i=1}^{3} p(k = 7, n = 10 \\mid \\theta_i) \\cdot p(\\theta_i).\n\\]\nSostituendo i valori di \\(\\theta\\) e le probabilità corrispondenti:\n\\[\np(k = 7, n = 10) = \\frac{1}{3} \\binom{10}{7} 0.1^7 (1 - 0.1)^3 + \\frac{1}{3} \\binom{10}{7} 0.5^7 (1 - 0.5)^3 + \\frac{1}{3} \\binom{10}{7} 0.9^7 (1 - 0.9)^3.\n\\]\nQuesto calcolo dimostra come la marginalizzazione su \\(\\theta\\) incorpori tutte le sue possibili variazioni, ottenendo una stima complessiva che tiene conto dell’incertezza su \\(\\theta\\).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_bayesian_inference.html#implementazione-in-r",
    "href": "chapters/bayesian_inference/02_bayesian_inference.html#implementazione-in-r",
    "title": "42  Inferenza bayesiana",
    "section": "\n42.9 Implementazione in R",
    "text": "42.9 Implementazione in R\nPer calcolare la verosimiglianza marginale in R, possiamo distinguere tra il caso discreto (in cui \\(\\theta\\) assume valori specifici) e il caso continuo (in cui \\(\\theta\\) è trattato come una variabile continua su un intervallo). Per il caso discreto, sommiamo direttamente i contributi della funzione di verosimiglianza pesati dalla probabilità a priori. Per il caso continuo, utilizziamo l’integrazione numerica.\n\n42.9.1 Caso discreto\nNel caso in cui \\(\\theta\\) assuma valori discreti, possiamo implementare il calcolo della verosimiglianza marginale sommando i prodotti della verosimiglianza \\(p(k \\mid \\theta)\\) e della probabilità a priori \\(p(\\theta)\\):\n\n# Funzione di verosimiglianza per il caso binomiale\nlikelihood_binomial &lt;- function(theta, k, n) {\n  return(choose(n, k) * (theta^k) * ((1 - theta)^(n - k)))\n}\n\n# Valori di theta e probabilità a priori\ntheta_values &lt;- c(0.1, 0.5, 0.9)\nprior &lt;- rep(1 / length(theta_values), length(theta_values)) # Prior uniforme\nk &lt;- 7\nn &lt;- 10\n\n# Calcolo della verosimiglianza marginale discreta\nmarginal_likelihood_discrete &lt;- sum(prior * sapply(theta_values, likelihood_binomial, k = k, n = n))\n\ncat(sprintf(\"Likelihood Marginale (discreta): %.4f\\n\", marginal_likelihood_discrete))\n#&gt; Likelihood Marginale (discreta): 0.0582\n\nIl risultato rappresenta la verosimiglianza marginale calcolata sommando i contributi discreti.\n\n42.9.2 Caso continuo\nNel caso in cui \\(\\theta\\) sia una variabile continua definita su \\([0, 1]\\), utilizziamo l’integrazione numerica per calcolare la verosimiglianza marginale. L’approccio assume una distribuzione a priori uniforme su \\([0, 1]\\) (se non diversamente specificato):\n\n# Funzione per il calcolo della verosimiglianza marginale continua\nlikelihood_binomial_continuous &lt;- function(theta, k, n) {\n  # La verosimiglianza è 0 per valori di theta fuori dall'intervallo [0, 1]\n  theta[theta &lt; 0 | theta &gt; 1] &lt;- 0\n  return(choose(n, k) * (theta^k) * ((1 - theta)^(n - k)))\n}\n\n# Parametri\nk &lt;- 7\nn &lt;- 10\n\n# Calcolo dell'integrale numerico\nmarginal_likelihood_continuous &lt;- \n  integrate(\n    function(theta) likelihood_binomial_continuous(theta, k, n), \n    lower = 0, \n    upper = 1\n  )$value\n\ncat(\n  sprintf(\n    \"Likelihood Marginale (continua): %.4f\\n\", \n    marginal_likelihood_continuous)\n)\n#&gt; Likelihood Marginale (continua): 0.0909\n\nQui l’integrazione numerica restituisce la verosimiglianza marginale considerando \\(\\theta\\) come una variabile continua.\n\n42.9.3 Caso continuo con prior Beta\nPer utilizzare una distribuzione a priori diversa (ad esempio, una distribuzione Beta), è necessario moltiplicare la funzione di verosimiglianza per la densità della distribuzione a priori:\n\n# Funzione prior Beta\nprior_beta &lt;- function(theta, alpha, beta) {\n  return(dbeta(theta, alpha, beta))\n}\n\n# Funzione combinata di verosimiglianza e prior\nlikelihood_with_beta_prior &lt;- function(theta, k, n, alpha_prior, beta_prior) {\n  # La verosimiglianza è 0 per valori di theta fuori dall'intervallo [0, 1]\n  valid_theta &lt;- (theta &gt;= 0 & theta &lt;= 1)\n  likelihood &lt;- ifelse(valid_theta, choose(n, k) * (theta^k) * ((1 - theta)^(n - k)), 0)\n  prior &lt;- ifelse(valid_theta, prior_beta(theta, alpha_prior, beta_prior), 0)\n  return(likelihood * prior)\n}\n\n# Parametri\nalpha_prior &lt;- 2\nbeta_prior &lt;- 2\nk &lt;- 7\nn &lt;- 10\n\n# Calcolo dell'integrale numerico con prior Beta\nmarginal_likelihood_continuous_beta &lt;- integrate(\n  function(theta) likelihood_with_beta_prior(theta, k, n, alpha_prior, beta_prior),\n  lower = 0, upper = 1\n)$value\n\ncat(sprintf(\"Likelihood Marginale con prior Beta: %.4f\\n\", marginal_likelihood_continuous_beta))\n#&gt; Likelihood Marginale con prior Beta: 0.1119\n\nIn questo caso, la distribuzione a priori Beta(2,2) dà maggiore peso ai valori centrali di \\(\\theta\\), riflettendo una conoscenza a priori che privilegia valori intermedi. Il calcolo combina la verosimiglianza e il prior per fornire una verosimiglianza marginale ponderata.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_bayesian_inference.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/02_bayesian_inference.html#riflessioni-conclusive",
    "title": "42  Inferenza bayesiana",
    "section": "\n42.10 Riflessioni Conclusive",
    "text": "42.10 Riflessioni Conclusive\nAl cuore della ricerca scientifica c’è una domanda del tipo: “dimmi qualcosa sulla variabile \\(\\theta\\) dato che ho osservato i dati \\(D\\) e ho una certa conoscenza del meccanismo sottostante che genera i dati”. La regola di Bayes fornisce la seguente risposta:\n\\[\np(\\theta \\mid D) = \\frac{p(D \\mid\\theta) p(\\theta)}{p(D)} = \\frac{p(D \\mid \\theta) p(\\theta)}{\\int_\\theta p(D \\mid\\theta) p(\\theta) d\\theta}.\n\\]\nQuesta equazione mostra come, partendo da un modello generativo \\(p(D \\mid\\theta)\\) dei dati osservati e abbinato a una credenza a priori \\(p(\\theta)\\) su quali valori della variabile \\(\\theta\\) siano plausibili, possiamo inferire la distribuzione a posteriori \\(p(\\theta \\mid D)\\) della variabile alla luce dei dati osservati.\nLa stima MAP (Massimo A Posteriori), che corrisponde al valore di \\(\\theta\\) che massimizza la distribuzione a posteriori, rappresenta una stima puntuale del parametro:\n\\[\n\\theta^* = \\arg \\max_\\theta p(\\theta \\mid D).\n\\]\nNel caso di un prior non informativo (piatto), la stima MAP coincide con la stima di massima verosimiglianza, ovvero il valore di \\(\\theta\\) che massimizza la probabilità che il modello generi i dati osservati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_bayesian_inference.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/02_bayesian_inference.html#informazioni-sullambiente-di-sviluppo",
    "title": "42  Inferenza bayesiana",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.17.0      see_0.9.0        gridExtra_2.3    patchwork_1.3.0 \n#&gt;  [5] bayesplot_1.11.1 psych_2.4.12     scales_1.3.0     markdown_1.13   \n#&gt;  [9] knitr_1.49       lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1   \n#&gt; [13] dplyr_1.1.4      purrr_1.0.2      readr_2.1.5      tidyr_1.3.1     \n#&gt; [17] tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3       \n#&gt; [21] here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      shape_1.4.6.1     xfun_0.49         htmlwidgets_1.6.4\n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2      \n#&gt;  [9] generics_0.1.3    parallel_4.4.2    pan_1.9           pacman_0.5.1     \n#&gt; [13] pkgconfig_2.0.3   jomo_2.7-6        Matrix_1.7-1      lifecycle_1.0.4  \n#&gt; [17] compiler_4.4.2    farver_2.1.2      munsell_0.5.1     mnormt_2.1.1     \n#&gt; [21] codetools_0.2-20  htmltools_0.5.8.1 yaml_2.3.10       glmnet_4.1-8     \n#&gt; [25] nloptr_2.1.1      pillar_1.10.0     MASS_7.3-61       iterators_1.0.14 \n#&gt; [29] rpart_4.1.23      boot_1.3-31       foreach_1.5.2     mitml_0.4-5      \n#&gt; [33] nlme_3.1-166      tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4    \n#&gt; [37] splines_4.4.2     rprojroot_2.0.4   fastmap_1.2.0     grid_4.4.2       \n#&gt; [41] colorspace_2.1-1  cli_3.6.3         magrittr_2.0.3    survival_3.8-3   \n#&gt; [45] broom_1.0.7       withr_3.0.2       backports_1.5.0   timechange_0.3.0 \n#&gt; [49] rmarkdown_2.29    nnet_7.3-19       lme4_1.1-35.5     hms_1.1.3        \n#&gt; [53] evaluate_1.0.1    rlang_1.1.4       Rcpp_1.0.13-1     glue_1.8.0       \n#&gt; [57] minqa_1.2.8       jsonlite_1.8.9    R6_2.5.1",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_bayesian_inference.html#bibliografia",
    "href": "chapters/bayesian_inference/02_bayesian_inference.html#bibliografia",
    "title": "42  Inferenza bayesiana",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html",
    "href": "chapters/bayesian_inference/03_subj_prop.html",
    "title": "43  Pensare ad una proporzione in termini soggettivi",
    "section": "",
    "text": "43.1 Introduzione\nL’inferenza bayesiana è un metodo di inferenza statistica che utilizza la probabilità per aggiornare le credenze sui parametri di un modello, sulla base di nuove evidenze o dati osservati. Essa fornisce un quadro concettuale per stimare variabili sconosciute, tenendo conto dell’incertezza. Attraverso un modello che descrive le dipendenze tra variabili aleatorie, la teoria della probabilità può essere impiegata per inferire tutte le quantità sconosciute. In questo approccio, tutte le incertezze, sia nelle osservazioni che nei parametri del modello, sono trattate come distribuzioni di probabilità.\nIn sintesi, l’inferenza bayesiana è il processo di deduzione delle proprietà di una distribuzione di probabilità a partire dai dati, utilizzando il teorema di Bayes. Questo processo incorpora l’idea che la probabilità rappresenti una misura della fiducia su una previsione o un risultato.\nQuesto capitolo ha lo scopo di esplorare in dettaglio il concetto di aggiornamento bayesiano, illustrandolo con un esempio concreto in un contesto semplificato. L’obiettivo è dimostrare come le credenze preesistenti sulla probabilità di un parametro \\(\\theta\\) possano essere aggiornate attraverso l’osservazione di nuovi dati.\nIl primo passo nell’inferenza bayesiana consiste nel rappresentare le credenze iniziali, formulate prima di raccogliere i dati, tramite una distribuzione a priori. La distribuzione a priori riflette le nostre conoscenze o ipotesi preesistenti su \\(\\theta\\) e può variare in base al contesto o alle informazioni pregresse disponibili.\nUna volta ottenuti nuovi dati, il passaggio successivo è l’aggiornamento delle credenze tramite la distribuzione a posteriori. Questo aggiornamento si ottiene moltiplicando la distribuzione a priori per la verosimiglianza dei dati osservati, il che riflette quanto i dati supportino un determinato valore di \\(\\theta\\). Il prodotto di questi due termini fornisce una misura delle credenze aggiornate, che viene successivamente normalizzata per garantire che il risultato sia una distribuzione di probabilità valida (ovvero, che l’area sotto la curva sia pari a 1).\nIl capitolo si concentra sul modello binomiale. Questo modello è utilizzato per stimare una proporzione sconosciuta basata su una serie di dati binari \\(y_1, \\ldots, y_n\\), ciascuno dei quali può assumere valore 0 o 1.\nInizieremo esplorando un esempio in cui la distribuzione a priori di \\(\\theta\\) è discreta, un caso in cui i valori possibili di \\(\\theta\\) sono limitati a un insieme finito di opzioni. Successivamente, discuteremo scenari in cui la distribuzione a priori è continua, ampliando il modello per affrontare casi più complessi e realistici. Questo approccio progressivo consente di acquisire una comprensione graduale dei concetti centrali dell’inferenza bayesiana e del loro utilizzo pratico nel contesto di problemi statistici reali.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#introduzione",
    "href": "chapters/bayesian_inference/03_subj_prop.html#introduzione",
    "title": "43  Pensare ad una proporzione in termini soggettivi",
    "section": "",
    "text": "L’unica cosa rilevante è l’incertezza – il grado della nostra conoscenza e ignoranza. Il fatto che gli eventi considerati siano in qualche modo determinati, o conosciuti da altre persone, non ha alcuna importanza.\n(Bruno deFinetti)",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#verosimiglianza-binomiale",
    "href": "chapters/bayesian_inference/03_subj_prop.html#verosimiglianza-binomiale",
    "title": "43  Pensare ad una proporzione in termini soggettivi",
    "section": "\n43.2 Verosimiglianza Binomiale",
    "text": "43.2 Verosimiglianza Binomiale\nLa distribuzione binomiale offre un modello naturale per dati che derivano da una sequenza di \\(n\\) prove indipendenti e identicamente distribuite, dove ciascuna prova dà origine a uno dei due possibili esiti, convenzionalmente etichettati come ‘successo’ e ‘fallimento’. Grazie al fatto che le prove sono iid, i dati possono essere riassunti dal numero totale di successi nelle \\(n\\) prove, che denotiamo con \\(y\\). Il parametro \\(\\theta\\) rappresenta la proporzione di successi nella popolazione o, equivalentemente, la probabilità di successo in ciascuna prova. Il modello di campionamento binomiale è:\n\\[\np(y \\mid \\theta) = \\text{Bin}(y \\mid n, \\theta) = \\binom{n}{y} \\theta^y (1 - \\theta)^{n-y},\n\\]\ndove nella parte sinistra dell’equazione non si indica la dipendenza da \\(n\\) perché viene considerato parte del disegno sperimentale e fissato; tutte le probabilità discusse per questo problema sono considerate condizionate su \\(n\\), cioè assumono che il numero totale di prove sia fissato e noto.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#applicazione-specifica-del-modello-binomiale",
    "href": "chapters/bayesian_inference/03_subj_prop.html#applicazione-specifica-del-modello-binomiale",
    "title": "43  Pensare ad una proporzione in termini soggettivi",
    "section": "\n43.3 Applicazione Specifica del Modello Binomiale",
    "text": "43.3 Applicazione Specifica del Modello Binomiale\nIn questo capitolo, esaminiamo un’applicazione specifica del modello binomiale per valutare la prestazione di un partecipante in un classico esperimento di psicologia, noto come Go/No-Go task (Shiffrin & Schneider, 1977). In questo tipo di compito, ai partecipanti viene richiesto di rispondere a determinati stimoli (prove Go) e di trattenere la risposta ad altri stimoli (prove No-Go). Ad esempio, i partecipanti possono vedere una serie di lettere presentate su uno schermo e devono premere un pulsante quando vedono qualsiasi lettera tranne una specifica lettera bersaglio (ad esempio, la lettera “X”). In questo esperimento, ogni prova rappresenta un evento di tipo bernoulliano con due possibili esiti: o il partecipante risponde correttamente o commette un errore. I ricercatori analizzano la percentuale di risposte corrette e di inibizioni, concentrandosi in particolare sulla capacità del partecipante di controllare l’impulso di rispondere durante le prove No-Go.\nConsideriamo un piccolo numero di prove No-Go di un partecipante, dove i risultati sono: 1, 0, 1, 1, 1, 0, 1, 0, 1. Qui, il valore “1” indica che il partecipante è stato in grado di inibire la risposta, mentre “0” indica che non è riuscito a farlo. L’obiettivo dell’analisi è quantificare l’incertezza nella stima di \\(\\theta\\), che rappresenta la proporzione di risposte corrette nel compito No-Go, ovvero la capacità inibitoria del partecipante.\nConsideriamo questi dati come una sequenza di 9 prove bernoulliane indipendenti. Utilizzando il modello binomiale, stimiamo la probabilità \\(\\theta\\) che il partecipante riesca a controllare il proprio impulso di rispondere durante le prove No-Go e quantifichiamo l’incertezza associata a questa stima.\n\n43.3.1 Flusso di Lavoro Bayesiano\nMcElreath (2020) descrive il flusso di lavoro bayesiano attraverso una serie di passaggi chiari e ben definiti. Ecco una spiegazione semplificata ma formale, adatta per studenti universitari senza esperienza precedente nell’ambito.\n\n\nDefinizione di un Modello Generativo per i Dati\nUn modello generativo rappresenta il processo attraverso cui i dati vengono prodotti. Per esempio, nel caso di un compito No-Go, ogni prova può essere considerata come un esperimento di tipo Bernoulli, che può produrre due possibili risultati:\n\n\nSuccesso: inibizione della risposta corretta (rappresentata da 1).\n\n\nErrore: mancata inibizione della risposta (rappresentata da 0).\n\nDenotiamo con \\(\\theta\\) la probabilità di inibire correttamente la risposta. Il modello generativo è quindi formalizzato come:\n\\[\nX_i \\sim \\text{Bernoulli}(\\theta),\n\\]\ndove \\(i = 1, 2, \\dots, 9\\) indica le prove eseguite, e \\(X_i\\) rappresenta l’esito di ciascuna prova.\n\n\nDefinizione di uno Stimatore per il Parametro di Interesse\nLo stimatore è uno strumento che ci permette di calcolare una stima del parametro di interesse (in questo caso \\(\\theta\\)) basandoci sui dati raccolti.\n\n\n\\(\\theta\\) rappresenta la probabilità di successo, ovvero di inibire correttamente la risposta.\n\nOltre a stimare \\(\\theta\\), è importante quantificare l’incertezza della stima utilizzando i dati a disposizione.\n\n\n\nSviluppo di un Metodo Statistico per la Stima di \\(\\theta\\)\nUtilizziamo un approccio bayesiano per stimare \\(\\theta\\). Questo approccio combina:\n\n\nUna distribuzione a priori: rappresenta le convinzioni iniziali su \\(\\theta\\). Scegliamo una distribuzione Beta \\(\\text{Beta}(1, 1)\\), che corrisponde a una distribuzione uniforme, per indicare che non abbiamo informazioni iniziali preferenziali.\n\n\nLa verosimiglianza: rappresenta quanto i dati osservati siano compatibili con diversi valori di \\(\\theta\\). Per 6 successi e 3 errori, la verosimiglianza è data da una distribuzione binomiale:\\[\nL(\\theta) = {9 \\choose 6} \\theta^{6} (1-\\theta)^{3}.\n\\]\n\n\nLa distribuzione a posteriori: si ottiene aggiornando la distribuzione a priori con i dati osservati, tramite il teorema di Bayes:\\[\n\\text{Posteriore} \\propto \\text{Verosimiglianza} \\times \\text{Priori}.\n\\]\n\n\n\n\nValidazione del Modello Tramite Simulazioni\nPrima di applicare il modello ai dati reali, verifichiamo che il modello sia realistico attraverso:\n\n\nSimulazioni predittive a priori: servono per controllare se il modello è in grado di generare dati plausibili.\n\n\nSimulazioni predittive a posteriori: valutano se il modello, una volta adattato ai dati osservati, può riprodurre risultati simili a quelli effettivamente ottenuti.\n\n\n\nAnalisi e Sintesi dei Risultati\nUna volta adattato il modello ai dati reali:\n\nUtilizziamo metodi computazionali come il Monte Carlo a catene di Markov (MCMC) per calcolare la distribuzione a posteriori.\n\nRiassumiamo i risultati tramite statistiche descrittive, come media, mediana e intervalli di credibilità, per fare inferenze su \\(\\theta\\).\n\n\n\nIn questo capitolo, mostreremo come calcolare numericamente la distribuzione a posteriori di \\(\\theta\\). Nei capitoli successivi esploreremo in dettaglio ogni fase del flusso di lavoro bayesiano descritto da McElreath (2020).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#metodo-basato-su-griglia-nellaggiornamento-bayesiano",
    "href": "chapters/bayesian_inference/03_subj_prop.html#metodo-basato-su-griglia-nellaggiornamento-bayesiano",
    "title": "43  Pensare ad una proporzione in termini soggettivi",
    "section": "\n43.4 Metodo Basato su Griglia nell’Aggiornamento Bayesiano",
    "text": "43.4 Metodo Basato su Griglia nell’Aggiornamento Bayesiano\nDopo aver discusso l’aggiornamento bayesiano e come permette di raffinare le nostre convinzioni preesistenti alla luce di nuove evidenze, esploreremo ora una tecnica specifica per realizzare questo aggiornamento: il metodo basato su griglia.\nIl metodo basato su griglia è un approccio semplice e intuitivo per stimare la distribuzione a posteriori, particolarmente utile quando non sono disponibili soluzioni analitiche esatte o si desidera evitare l’uso di algoritmi computazionali complessi. La procedura si articola nei seguenti passi:\n\n\nSelezione di un intervallo per il parametro: Basandosi sulle convinzioni a priori, si definisce un intervallo ragionevole per il parametro di interesse.\n\nCreazione di una griglia di punti: Su questo intervallo, si distribuiscono una serie di punti, di solito equidistanti tra loro.\n\nCalcolo della posteriori per ogni punto: Per ogni punto della griglia, si moltiplica la verosimiglianza per il prior corrispondente.\n\nNormalizzazione dei risultati: Per garantire che la somma delle probabilità sia pari a 1, si normalizzano i valori ottenuti dividendo ciascun punto per l’area totale sottesa dalla curva della distribuzione a posteriori.\n\nAttraverso questo metodo, si ottiene una rappresentazione approssimativa ma illustrativa della distribuzione a posteriori. Questo approccio offre un modo accessibile per visualizzare e comprendere il processo di aggiornamento bayesiano.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-discreta",
    "href": "chapters/bayesian_inference/03_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-discreta",
    "title": "43  Pensare ad una proporzione in termini soggettivi",
    "section": "\n43.5 Aggiornamento Bayesiano con una Distribuzione a Priori Discreta",
    "text": "43.5 Aggiornamento Bayesiano con una Distribuzione a Priori Discreta\n\n43.5.1 Distribuzione a priori\nQuando non disponiamo di informazioni specifiche preliminari su \\(\\theta\\), potremmo inizialmente assegnare un valore di 0.5, suggerendo una probabilità a priori uniforme tra le due alternative (la capacità di inibire la risposta e la mancanza di questa capacità in una prova del compito Go/No-Go). Tuttavia, questo valore non rappresenta adeguatamente l’intero spettro della nostra incertezza iniziale.\nPer riflettere meglio questa incertezza, utilizziamo una distribuzione a priori discreta, che assegna una probabilità distinta a ciascun valore plausibile di \\(\\theta\\). Questo approccio ci permette di quantificare le nostre convinzioni preliminari sulla distribuzione di questi valori.\nSupponiamo di considerare undici possibili valori per \\(\\theta\\), che variano da 0 a 1 con incrementi di 0.1. Possiamo attribuire a ciascun valore una probabilità a priori uguale, creando così una distribuzione uniforme, oppure scegliere una distribuzione non uniforme che meglio rifletta le nostre aspettative sui valori di \\(\\theta\\) più probabili.\nDopo aver osservato i dati — nel nostro caso, 6 successi in 9 prove — applichiamo il teorema di Bayes per trasformare la distribuzione a priori in una distribuzione a posteriori. Questo processo consiste nel combinare la probabilità a priori di \\(\\theta\\) con la verosimiglianza dei dati per produrre una probabilità a posteriori aggiornata per \\(\\theta\\).\n\n43.5.2 Distribuzione a Posteriori\nLa distribuzione a posteriori combina le informazioni a priori con i dati osservati, aggiornando le nostre credenze riguardo al parametro \\(\\theta\\). Vediamo passo passo come implementare il calcolo della distribuzione a posteriori e delle relative quantità in R, partendo dalla rappresentazione discreta di \\(\\theta\\).\n\n43.5.2.1 1. Definizione di \\(\\theta\\)\n\nIniziamo definendo un insieme discreto di valori per \\(\\theta\\).\n\ntheta &lt;- seq(0, 1, by = 0.1)\ntheta\n#&gt;  [1] 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0\n\n\n43.5.2.2 2. Distribuzione a Priori Uniforme\nSe non abbiamo motivi per preferire alcuni valori di \\(\\theta\\), assegniamo probabilità uguali a tutti i valori. Standardizziamo la distribuzione affinché le probabilità si sommino a 1.\n\nunif_prior &lt;- rep(1 / length(theta), length(theta))\nprint(unif_prior)\n#&gt;  [1] 0.0909 0.0909 0.0909 0.0909 0.0909 0.0909 0.0909 0.0909 0.0909 0.0909\n#&gt; [11] 0.0909\n\n\nsum(unif_prior) # Verifica che le probabilità sommino a 1\n#&gt; [1] 1\n\nVisualizziamo questa distribuzione a priori uniforme:\n\nggplot(data.frame(theta, unif_prior), aes(x = theta, y = unif_prior)) +\n  geom_segment(aes(xend = theta, yend = 0), linetype = \"solid\", size = 1.2) +\n  labs(\n    title = \"Distribuzione a Priori (Uniforme)\",\n    x = expression(theta),\n    y = \"Probabilità\"\n  )\n#&gt; Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#&gt; ℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n43.5.2.3 3. Distribuzione a Priori Non Uniforme\nSe riteniamo più probabili i valori centrali di \\(\\theta\\), definiamo una distribuzione a priori discreta non uniforme:\n\n# Dati per il grafico\ntheta &lt;- seq(0, 1, length.out = 11)  # Valori di theta\nnot_unif_prior &lt;- \n  c(0, 0.05, 0.05, 0.05, 0.175, 0.175, 0.175, 0.175, 0.05, 0.05, 0.05)  \n# Probabilità\n\n# Creazione del grafico\nggplot(\n  data.frame(theta, not_unif_prior), \n  aes(x = theta, y = not_unif_prior)) +\n  geom_segment(\n    aes(xend = theta, yend = 0), linetype = \"solid\", size = 1.2) +\n  labs(\n    title = \"Distribuzione a Priori (Non Uniforme)\",\n    x = expression(theta),\n    y = \"Probabilità\"\n  )\n\n\n\n\n\n\n\n\n43.5.2.4 4. Calcolo della Verosimiglianza\nLa funzione di verosimiglianza per il modello binomiale è definita come segue:\n\nlikelihood &lt;- dbinom(6, size = 9, prob = theta)\n\n\nlikelihood &lt;- likelihood / sum(likelihood) # Normalizzazione\n\n\nggplot(\n  data.frame(theta, likelihood), \n  aes(x = theta, y = likelihood)) +\n  geom_segment(\n    aes(xend = theta, yend = 0), linetype = \"solid\", size = 1.2) +\n  labs(\n    title = \"Funzione di Verosimiglianza\",\n    x = expression(theta),\n    y = expression(L(theta))\n  )\n\n\n\n\n\n\n\n\n43.5.2.5 5. Distribuzione a Posteriori\nLa distribuzione a posteriori si calcola moltiplicando elemento per elemento la distribuzione a priori e la verosimiglianza, quindi dividendo per la probabilità marginale dei dati (normalizzazione).\n\npost &lt;- (not_unif_prior * likelihood) / sum(not_unif_prior * likelihood)\nprint(post)\n#&gt;  [1] 0.00e+00 2.12e-05 9.52e-04 7.27e-03 9.00e-02 1.99e-01 3.04e-01 3.23e-01\n#&gt;  [9] 6.09e-02 1.54e-02 0.00e+00\n\n\nsum(post) # Verifica che sommi a 1\n#&gt; [1] 1\n\nVisualizziamo la distribuzione a posteriori:\n\nggplot(\n  data.frame(theta, post), \n  aes(x = theta, y = post)) +\n  geom_segment(\n    aes(xend = theta, yend = 0), linetype = \"solid\", size = 1.2) +\n  labs(\n    title = \"Distribuzione a Posteriori\",\n    x = expression(theta),\n    y = expression(f(theta))\n  )\n\n\n\n\n\n\n\n\n43.5.2.6 6. Quantità a Posteriori\n\n\nMedia a Posteriori: Calcolata come il valore atteso di \\(\\theta\\) sotto la distribuzione a posteriori.\n\n\nposterior_mean &lt;- sum(theta * post)\nposterior_mean\n#&gt; [1] 0.609\n\n\n\nVarianza a Posteriori: Calcolata come la varianza della distribuzione a posteriori.\n\n\nposterior_variance &lt;- sum((theta^2) * post) - posterior_mean^2\nposterior_variance\n#&gt; [1] 0.0134\n\n\n\nModa a Posteriori: Il valore di \\(\\theta\\) con la probabilità più alta.\n\n\nposterior_mode &lt;- theta[which.max(post)]\nposterior_mode\n#&gt; [1] 0.7\n\nIn sintesi, abbiamo calcolato la distribuzione a posteriori di \\(\\theta\\) utilizzando una distribuzione a priori discreta non uniforme e osservando 6 successi su 9 prove. Abbiamo derivato quantità statistiche come media, varianza e moda a posteriori. Questo processo dimostra come l’inferenza bayesiana aggiorni le credenze a priori in base ai dati osservati, offrendo una visione quantitativamente informata del parametro \\(\\theta\\).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-continua",
    "href": "chapters/bayesian_inference/03_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-continua",
    "title": "43  Pensare ad una proporzione in termini soggettivi",
    "section": "\n43.6 Aggiornamento Bayesiano con una Distribuzione a Priori Continua",
    "text": "43.6 Aggiornamento Bayesiano con una Distribuzione a Priori Continua\nPassiamo ora all’aggiornamento bayesiano utilizzando una distribuzione a priori continua, in particolare la distribuzione Beta. Questo approccio è particolarmente utile poiché consente di rappresentare \\(\\theta\\) come una variabile continua definita nell’intervallo [0, 1].\n\n43.6.1 Definizione della Distribuzione Beta\nIniziamo con una distribuzione Beta simmetrica, Beta(2, 2), e calcoliamo la sua densità di probabilità su un intervallo continuo di valori \\(\\theta\\).\n\n# Parametri della distribuzione Beta\nalpha &lt;- 2\nbeta &lt;- 2\n\n# Valori di theta\ntheta &lt;- seq(0, 1, length.out = 1000)\n\n# Densità di probabilità della distribuzione Beta\npdf &lt;- dbeta(theta, alpha, beta)\n\n# Grafico della distribuzione Beta\nggplot(\n  data.frame(theta, pdf), \n  aes(x = theta, y = pdf)) +\n  geom_line(size = 1.2) +\n  labs(\n    title = \"Funzione di Densità di Probabilità Beta(2, 2)\",\n    x = expression(theta),\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\n\n43.6.2 Distribuzione a Priori Non Simmetrica\nConsideriamo una distribuzione a priori non simmetrica, Beta(2, 5), per rappresentare credenze che privilegiano valori bassi di \\(\\theta\\).\n\n# Parametri della distribuzione Beta non simmetrica\nalpha &lt;- 2\nbeta &lt;- 5\n\n# Valori di theta e densità di probabilità\ntheta &lt;- seq(0, 1, length.out = 100)  # Valori di theta\npdf &lt;- dbeta(theta, alpha, beta)  # Densità di probabilità Beta(2, 5)\n\n# Creazione del grafico\nggplot(data.frame(theta, pdf), aes(x = theta, y = pdf)) +\n  geom_line(size = 1.2) +\n  labs(\n    title = \"Funzione di Densità di Probabilità Beta(2, 5)\",\n    x = expression(theta),\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\n\n43.6.3 Verosimiglianza\nConsideriamo un esperimento con 9 prove e 6 successi, modellato con una distribuzione binomiale. Calcoliamo la funzione di verosimiglianza normalizzata.\n\n# Parametri dell'esperimento\nn &lt;- 9\nk &lt;- 6\n\n# Calcolo della verosimiglianza\nlikelihood &lt;- dbinom(k, size = n, prob = theta)\nlikelihood &lt;- likelihood / sum(likelihood) # Normalizzazione\n\n# Grafico della verosimiglianza\nggplot(\n  data.frame(theta, likelihood), \n  aes(x = theta, y = likelihood)) +\n  geom_line(size = 1.2) +\n  labs(\n    title = \"Funzione di Verosimiglianza\",\n    x = expression(theta),\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\n\n43.6.4 Distribuzione a Posteriori\nLa distribuzione a posteriori si ottiene moltiplicando la distribuzione a priori per la verosimiglianza e normalizzando il risultato.\n\n# Calcolo della distribuzione a priori Beta(2, 5)\nprior &lt;- dbeta(theta, shape1 = 2, shape2 = 5)\nprior &lt;- prior / sum(prior)\n\n# Calcolo della distribuzione a posteriori\nposterior &lt;- (prior * likelihood) / sum(prior * likelihood)\n\n\n# Uniamo tutti i dati in un dataframe per ggplot2\ndat &lt;- tibble(\n  theta, \n  prior, \n  likelihood, \n  posterior\n)\n\n# Preparazione dei dati per il plot\nlong_data &lt;- dat |&gt; \n  pivot_longer(\n    cols = c(prior, likelihood, posterior),\n    names_to = \"distribution\",\n    values_to = \"density\"\n  )\n\n# Grafico\nggplot(long_data, aes(x = theta, y = density, color = distribution)) +\n  geom_line(size = 1.2) +\n  scale_color_manual(\n    values = c(\"prior\" = \"blue\", \"likelihood\" = \"red\", \"posterior\" = \"green\"),\n    labels = c(\"Prior\", \"Likelihood\", \"Posterior\"),\n    breaks = c(\"prior\", \"likelihood\", \"posterior\")\n  ) +\n  labs(\n    title = \"Distribuzioni Bayesiane\",\n    x = expression(theta),\n    y = \"Densità\"\n  ) +\n  theme(legend.position = \"bottom\") \n\n\n\n\n\n\n\n\n43.6.5 Quantità a Posteriori\nCalcoliamo alcune quantità riassuntive dalla distribuzione a posteriori.\n\nMedia a Posteriori\n\n\nposterior_mean &lt;- sum(theta * posterior)\nposterior_mean\n#&gt; [1] 0.5\n\n\nDeviazione Standard a Posteriori\n\n\nposterior_sd &lt;- sqrt(sum((theta^2) * posterior) - posterior_mean^2)\nposterior_sd\n#&gt; [1] 0.121\n\n\nModa a Posteriori\n\n\nposterior_mode &lt;- theta[which.max(posterior)]\nposterior_mode\n#&gt; [1] 0.495\n\n\n43.6.6 Campionamento dalla Distribuzione a Posteriori\nPossiamo generare campioni casuali dalla distribuzione a posteriori per effettuare inferenze.\n\n# Campionamento casuale basato sul posterior\nset.seed(123)\nsamples &lt;- sample(theta, size = 10000, prob = posterior, replace = TRUE)\n\n# Creazione dell'istogramma e della curva di densità\ndata_frame_samples &lt;- data.frame(samples)\n\n# Grafico con ggplot\nggplot(data_frame_samples, aes(x = samples)) +\n  geom_histogram(\n    aes(y = ..density..), bins = 20, \n    fill = \"gray\", color = \"black\") +\n  geom_density(color = \"black\", size = 1.2) +\n  labs(\n    title = \"Distribuzione dei Campioni dalla Posteriori\",\n    x = expression(theta),\n    y = \"Densità\"\n  )\n#&gt; Warning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\n#&gt; ℹ Please use `after_stat(density)` instead.\n\n\n\n\n\n\n\n\n43.6.6.1 Intervalli di Credibilità\nCalcoliamo l’intervallo di credibilità al 94%.\n\ncredible_interval &lt;- quantile(samples, probs = c(0.03, 0.97))\ncredible_interval\n#&gt;    3%   97% \n#&gt; 0.273 0.727\n\nSe desideriamo calcolare l’intervallo di densità più alta (HPDI), possiamo utilizzare pacchetti aggiuntivi come HDInterval.\n\n# Calcolo HPDI (richiede il pacchetto HDInterval)\nhdi(samples, credMass = 0.94)\n#&gt; lower upper \n#&gt; 0.283 0.727 \n#&gt; attr(,\"credMass\")\n#&gt; [1] 0.94\n\nIn sintesi, questo approccio dimostra l’applicazione del metodo bayesiano con distribuzioni a priori continue, utilizzando sia formule analitiche che campionamento. I risultati mostrano come possiamo ottenere credenze aggiornate su \\(\\theta\\) e riassumerle con quantità come media, moda e intervalli di credibilità.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#metodo-basato-su-griglia",
    "href": "chapters/bayesian_inference/03_subj_prop.html#metodo-basato-su-griglia",
    "title": "43  Pensare ad una proporzione in termini soggettivi",
    "section": "\n43.7 Metodo basato su griglia",
    "text": "43.7 Metodo basato su griglia\nIl metodo utilizzato in questo capitolo per generare la distribuzione a posteriori è noto come metodo basato su griglia. Questo metodo numerico esatto si basa sul calcolo della distribuzione a posteriori mediante una griglia di punti uniformemente spaziati. Nonostante la maggior parte dei parametri sia continua, l’approssimazione della distribuzione a posteriori può essere ottenuta considerando soltanto una griglia finita di valori dei parametri. Il metodo segue quattro fasi:\n\nFissare una griglia discreta di possibili valori dei parametri.\nValutare la distribuzione a priori e la funzione di verosimiglianza per ciascun valore della griglia.\nCalcolare l’approssimazione della densità a posteriori, ottenuta moltiplicando la distribuzione a priori per la funzione di verosimiglianza per ciascun valore della griglia e normalizzando i prodotti in modo che la loro somma sia uguale a 1.\nSelezionare \\(n\\) valori casuali dalla griglia per ottenere un campione casuale della densità a posteriori normalizzata.\n\nQuesto metodo può essere potenziato aumentando il numero di punti nella griglia, ma il limite principale risiede nel fatto che all’aumentare della dimensionalità dello spazio dei parametri, il numero di punti necessari per una stima accurata cresce in modo esponenziale, rendendo il metodo impraticabile per problemi complessi.\nIn sintesi, l’approccio basato sulla griglia è intuitivo e non richiede competenze di programmazione avanzate per l’implementazione. Inoltre, fornisce un risultato che può essere considerato, per tutti gli scopi pratici, come un campione casuale estratto dalla distribuzione di probabilità a posteriori condizionata ai dati. Tuttavia, questo metodo è limitato a causa della maledizione della dimensionalità1, il che significa che può essere applicato soltanto a modelli statistici semplici con non più di due parametri. Di conseguenza, in pratica, è spesso sostituito da altre tecniche più efficienti, poiché i modelli impiegati in psicologia richiedono frequentemente la stima di centinaia o anche migliaia di parametri.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/03_subj_prop.html#riflessioni-conclusive",
    "title": "43  Pensare ad una proporzione in termini soggettivi",
    "section": "\n43.8 Riflessioni Conclusive",
    "text": "43.8 Riflessioni Conclusive\nIn questo capitolo, abbiamo esplorato l’aggiornamento bayesiano utilizzando una distribuzione a priori discreta, accennando brevemente al caso delle distribuzioni a priori continue. Quando si affrontano scenari con distribuzioni a priori continue, l’elaborazione della distribuzione a posteriori generalmente richiede la risoluzione di un integrale che, nella maggior parte dei casi, non ammette una soluzione analitica. Tuttavia, ci sono eccezioni notevoli, come nell’inferenza relativa alle proporzioni, dove la distribuzione a priori è modellata come una distribuzione Beta e la funzione di verosimiglianza segue una distribuzione binomiale. In queste circostanze particolari, è possibile derivare analiticamente la distribuzione a posteriori. L’analisi dettagliata di questo caso sarà trattata nel capitolo successivo.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#esercizi",
    "href": "chapters/bayesian_inference/03_subj_prop.html#esercizi",
    "title": "43  Pensare ad una proporzione in termini soggettivi",
    "section": "\n43.9 Esercizi",
    "text": "43.9 Esercizi\n\nEsercizio 43.1 Viene chieso di calcolare la distribuzione a posteriori della probabilità che uno studio condivida i materiali di ricerca utilizzando il metodo basato su griglia. Si utilizzeranno dati reali per motivare e costruire una distribuzione a priori discretizzata.\nIn uno studio sull’analisi delle pratiche di trasparenza e riproducibilità nella ricerca in psicologia, Hardwicke et al. (2022) hanno riportato che la condivisione dei materiali di ricerca è stata rilevata nel 14% dei casi (26 su 183 studi), con un intervallo di confidenza al 95% pari a [10%, 19%]. Questo suggerisce che la condivisione di materiali è rara.\nIspirandoti ai risultati di questo studio, costruisci una distribuzione a priori per la probabilità \\(\\theta\\) che uno studio condivida i materiali di ricerca. Per semplicità, discretizza \\(\\theta\\) in 10 livelli equispaziati: \\(0.05, 0.15, 0.25, 0.35, 0.45, 0.55, 0.65, 0.75, 0.85, 0.95\\).\nAttribuisci le seguenti probabilità a priori ai 10 livelli, basandoti sull’informazione che la condivisione dei materiali è un evento raro ma non trascurabile: \\(0.05, 0.20, 0.30, 0.15, 0.10, 0.08, 0.05, 0.03, 0.02, 0.02\\).\nSupponiamo che siano stati osservati 20 studi su 100 che hanno condiviso i materiali di ricerca. Calcola la distribuzione a posteriori utilizzando il metodo basato su griglia. Calcola la media della distribuzione a posteriori e l’intervallo di credibilità al 89%.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/03_subj_prop.html#informazioni-sullambiente-di-sviluppo",
    "title": "43  Pensare ad una proporzione in termini soggettivi",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] HDInterval_0.2.4 see_0.9.0        gridExtra_2.3    patchwork_1.3.0 \n#&gt;  [5] bayesplot_1.11.1 psych_2.4.12     scales_1.3.0     markdown_1.13   \n#&gt;  [9] knitr_1.49       lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1   \n#&gt; [13] dplyr_1.1.4      purrr_1.0.2      readr_2.1.5      tidyr_1.3.1     \n#&gt; [17] tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3       \n#&gt; [21] here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.3         rlang_1.1.4       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       tools_4.4.2       parallel_4.4.2    tzdb_0.4.0       \n#&gt; [21] colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5       R6_2.5.1         \n#&gt; [25] lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.0    \n#&gt; [29] gtable_0.3.6      glue_1.8.0        xfun_0.49         tidyselect_1.2.1 \n#&gt; [33] farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-166      labeling_0.4.3   \n#&gt; [37] rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#bibliografia",
    "href": "chapters/bayesian_inference/03_subj_prop.html#bibliografia",
    "title": "43  Pensare ad una proporzione in termini soggettivi",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAlbert, J., & Hu, J. (2019). Probability and Bayesian Modeling. CRC Press.\n\n\nHardwicke, T. E., Thibault, R. T., Kosie, J. E., Wallach, J. D., Kidwell, M. C., & Ioannidis, J. P. (2022). Estimating the prevalence of transparency and reproducibility-related research practices in psychology (2014–2017). Perspectives on Psychological Science, 17(1), 239–251.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nShiffrin, R. M., & Schneider, W. (1977). Controlled and automatic human information processing: II. Perceptual learning, automatic attending and a general theory. Psychological Review, 84(2), 127–190.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#footnotes",
    "href": "chapters/bayesian_inference/03_subj_prop.html#footnotes",
    "title": "43  Pensare ad una proporzione in termini soggettivi",
    "section": "",
    "text": "Per comprendere la maledizione della dimensionalità, possiamo considerare l’esempio di una griglia di 100 punti equispaziati. Nel caso di un solo parametro, sarebbe necessario calcolare solo 100 valori. Tuttavia, se abbiamo due parametri, il numero di valori da calcolare diventa \\(100^2\\). Se invece abbiamo 10 parametri, il numero di valori da calcolare sarebbe di \\(10^{10}\\). È evidente che la quantità di calcoli richiesta diventa troppo grande persino per un computer molto potente. Pertanto, per modelli che richiedono la stima di un numero significativo di parametri, è necessario utilizzare un approccio diverso.↩︎",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_grid_gauss.html",
    "href": "chapters/bayesian_inference/04_grid_gauss.html",
    "title": "44  Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "",
    "text": "44.1 Introduzione\nIn questo capitolo, estenderemo la discussione precedente sul calcolo della distribuzione a posteriori utilizzando il metodo basato su griglia, applicandolo questa volta a un caso con verosimiglianza gaussiana. In particolare, ci concentreremo su come costruire un modello gaussiano per descrivere l’intelligenza.\nImmaginiamo di condurre uno studio sulla plusdotazione, considerando l’approccio psicometrico. Secondo questo approccio, una persona è considerata plusdotata se ha un QI (Quoziente Intellettivo) di 130 o superiore (Robinson, Zigler, & Gallagher, 2000). Anche se l’uso di un QI di 130 come soglia è il criterio più comune, non è universalmente accettato. L’intelligenza nei bambini plusdotati non è solo superiore rispetto a quella dei loro pari, ma è qualitativamente diversa (Lubart & Zenasni, 2010). I bambini plusdotati tendono a mostrare caratteristiche come un vocabolario ampio, un linguaggio molto sviluppato, processi di ragionamento avanzati, eccellente memoria, vasti interessi, forte curiosità, empatia, capacità di leadership, abilità visive elevate, impegno in situazioni sfidanti e un forte senso di giustizia (Song & Porath, 2005).\nNella simulazione che seguirà, assumeremo che i dati provengano da una distribuzione normale. Per semplicità, considereremo che la deviazione standard sia nota e pari a 5. Il parametro della media sarà l’oggetto della nostra inferenza.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_grid_gauss.html#dati",
    "href": "chapters/bayesian_inference/04_grid_gauss.html#dati",
    "title": "44  Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "\n44.2 Dati",
    "text": "44.2 Dati\nSupponiamo di avere un campione di 10 osservazioni. I dati saranno generati casualmente da una distribuzione normale con media 130 e deviazione standard 5.\n\nset.seed(123) # Per la riproducibilità\nvera_media &lt;- 130 # Media vera\nsigma_conosciuta &lt;- 5 # Deviazione standard conosciuta\ndimensione_campione &lt;- 10 # Dimensione del campione\n\n# Generare un campione\ncampione &lt;- round(rnorm(n = dimensione_campione, mean = vera_media, sd = sigma_conosciuta))\ncampione\n#&gt;  [1] 127 129 138 130 131 139 132 124 127 128",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_grid_gauss.html#griglia",
    "href": "chapters/bayesian_inference/04_grid_gauss.html#griglia",
    "title": "44  Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "\n44.3 Griglia",
    "text": "44.3 Griglia\nCreiamo ora una griglia di 100 valori compresi tra 110 e 150.\n\nmu_griglia &lt;- seq(110, 150, length.out = 100)\nmu_griglia\n#&gt;   [1] 110 110 111 111 112 112 112 113 113 114 114 114 115 115 116 116 116\n#&gt;  [18] 117 117 118 118 118 119 119 120 120 121 121 121 122 122 123 123 123\n#&gt;  [35] 124 124 125 125 125 126 126 127 127 127 128 128 129 129 129 130 130\n#&gt;  [52] 131 131 131 132 132 133 133 133 134 134 135 135 135 136 136 137 137\n#&gt;  [69] 137 138 138 139 139 139 140 140 141 141 142 142 142 143 143 144 144\n#&gt;  [86] 144 145 145 146 146 146 147 147 148 148 148 149 149 150 150",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_grid_gauss.html#calcolo-della-verosimiglianza",
    "href": "chapters/bayesian_inference/04_grid_gauss.html#calcolo-della-verosimiglianza",
    "title": "44  Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "\n44.4 Calcolo della Verosimiglianza",
    "text": "44.4 Calcolo della Verosimiglianza\nPer ogni valore della griglia, calcoliamo la verosimiglianza complessiva come prodotto delle densità di probabilità.\n\nlikelihood &lt;- sapply(mu_griglia, function(mu) {\n    prod(dnorm(campione, mean = mu, sd = sigma_conosciuta))\n})\nlikelihood\n#&gt;   [1] 5.29e-50 1.41e-48 3.50e-47 8.17e-46 1.79e-44 3.66e-43 7.02e-42\n#&gt;   [8] 1.26e-40 2.12e-39 3.35e-38 4.94e-37 6.84e-36 8.87e-35 1.08e-33\n#&gt;  [15] 1.23e-32 1.31e-31 1.30e-30 1.22e-29 1.07e-28 8.77e-28 6.74e-27\n#&gt;  [22] 4.86e-26 3.28e-25 2.07e-24 1.23e-23 6.81e-23 3.54e-22 1.72e-21\n#&gt;  [29] 7.85e-21 3.35e-20 1.34e-19 5.03e-19 1.77e-18 5.82e-18 1.79e-17\n#&gt;  [36] 5.18e-17 1.40e-16 3.55e-16 8.42e-16 1.87e-15 3.90e-15 7.61e-15\n#&gt;  [43] 1.39e-14 2.38e-14 3.82e-14 5.74e-14 8.08e-14 1.07e-13 1.32e-13\n#&gt;  [50] 1.52e-13 1.65e-13 1.68e-13 1.60e-13 1.42e-13 1.19e-13 9.29e-14\n#&gt;  [57] 6.81e-14 4.67e-14 3.01e-14 1.81e-14 1.02e-14 5.40e-15 2.67e-15\n#&gt;  [64] 1.24e-15 5.39e-16 2.19e-16 8.37e-17 2.99e-17 1.00e-17 3.14e-18\n#&gt;  [71] 9.22e-19 2.54e-19 6.54e-20 1.58e-20 3.57e-21 7.56e-22 1.50e-22\n#&gt;  [78] 2.79e-23 4.86e-24 7.93e-25 1.21e-25 1.74e-26 2.33e-27 2.93e-28\n#&gt;  [85] 3.45e-29 3.80e-30 3.93e-31 3.80e-32 3.45e-33 2.93e-34 2.33e-35\n#&gt;  [92] 1.74e-36 1.21e-37 7.93e-39 4.86e-40 2.79e-41 1.50e-42 7.56e-44\n#&gt;  [99] 3.57e-45 1.58e-46",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_grid_gauss.html#calcolo-della-distribuzione-a-posteriori",
    "href": "chapters/bayesian_inference/04_grid_gauss.html#calcolo-della-distribuzione-a-posteriori",
    "title": "44  Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "\n44.5 Calcolo della Distribuzione a Posteriori",
    "text": "44.5 Calcolo della Distribuzione a Posteriori\nImpostiamo una prior uniforme e calcoliamo la distribuzione a posteriori normalizzata.\n\nprior &lt;- rep(1, length(mu_griglia)) # Prior uniforme\nposterior_non_norm &lt;- likelihood * prior\nposterior &lt;- posterior_non_norm / sum(posterior_non_norm) # Normalizzazione\n\nVisualizzazione:\n\nplot(mu_griglia, posterior,\n    type = \"l\", main = \"Distribuzione a Posteriori della Media\",\n    xlab = \"Media\", ylab = \"Probabilità\"\n)\n\n\n\n\n\n\n\n\n44.5.1 Aggiunta di una Prior Informativa\nUsiamo una prior gaussiana con media 140 e deviazione standard 3.\n\nprior &lt;- dnorm(mu_griglia, mean = 140, sd = 3)\n\nposterior_non_norm &lt;- likelihood * prior\nposterior &lt;- posterior_non_norm / sum(posterior_non_norm)\n\n# Grafico\nplot(mu_griglia, posterior,\n    type = \"l\", col = \"blue\", lwd = 2,\n    main = \"Distribuzione a Posteriori e Prior della Media\",\n    xlab = \"Media\", ylab = \"Densità\"\n)\nlines(mu_griglia, prior / sum(prior), col = \"red\", lty = 2)\nlegend(\"topright\", legend = c(\"Posterior\", \"Prior\"), col = c(\"blue\", \"red\"), lty = c(1, 2))",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_grid_gauss.html#campionamento-dalla-posterior",
    "href": "chapters/bayesian_inference/04_grid_gauss.html#campionamento-dalla-posterior",
    "title": "44  Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "\n44.6 Campionamento dalla Posterior",
    "text": "44.6 Campionamento dalla Posterior\nGeneriamo un campione dalla distribuzione a posteriori.\n\nset.seed(123)\nindice_campionato &lt;- sample(1:length(mu_griglia), size = 1000, replace = TRUE, prob = posterior)\nmedia_campionata &lt;- mu_griglia[indice_campionato]\n\n# Istogramma dei campioni\nhist(media_campionata,\n    main = \"Campionamento dalla Posterior\", xlab = \"Media\",\n    breaks = 20, col = \"lightblue\", border = \"white\"\n)\n\n# Media e intervallo di credibilità\nmean(media_campionata)\n#&gt; [1] 133\nquantile(media_campionata, c(0.03, 0.97))\n#&gt;  3% 97% \n#&gt; 130 135",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_grid_gauss.html#calcolo-della-log-verosimiglianza",
    "href": "chapters/bayesian_inference/04_grid_gauss.html#calcolo-della-log-verosimiglianza",
    "title": "44  Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "\n44.7 Calcolo della Log-Verosimiglianza",
    "text": "44.7 Calcolo della Log-Verosimiglianza\nUtilizziamo i logaritmi per migliorare la stabilità numerica.\n\nlog_likelihood &lt;- sapply(mu_griglia, function(mu) {\n    sum(dnorm(campione, mean = mu, sd = sigma_conosciuta, log = TRUE))\n})\n\nlog_prior &lt;- dnorm(mu_griglia, mean = 140, sd = 3, log = TRUE)\n\nlog_posterior_non_norm &lt;- log_likelihood + log_prior\nlog_posterior &lt;- log_posterior_non_norm - max(log_posterior_non_norm) # Stabilizzazione\nposterior &lt;- exp(log_posterior) / sum(exp(log_posterior))\n\n# Grafico\nplot(mu_griglia, posterior,\n    type = \"l\", col = \"darkgreen\", lwd = 2,\n    main = \"Distribuzione a Posteriori con Log-Verosimiglianza\",\n    xlab = \"Media\", ylab = \"Probabilità\"\n)",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_grid_gauss.html#estensione-alla-deviazione-standard-ignota",
    "href": "chapters/bayesian_inference/04_grid_gauss.html#estensione-alla-deviazione-standard-ignota",
    "title": "44  Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "\n44.8 Estensione alla Deviazione Standard Ignota",
    "text": "44.8 Estensione alla Deviazione Standard Ignota\nPer una griglia bidimensionale di valori di \\(\\mu\\) e \\(\\sigma\\):\n\n# Define the grid for mu and sigma\nmu_griglia &lt;- seq(110, 150, length.out = 100)\nsigma_griglia &lt;- seq(1, 10, length.out = 50)\n\n# Create combinations of mu and sigma using expand.grid\ngrid &lt;- expand.grid(mu = mu_griglia, sigma = sigma_griglia)\n\n# Compute the log-likelihood for each combination of mu and sigma\nlog_likelihood &lt;- apply(grid, 1, function(params) {\n    mu &lt;- params[1]\n    sigma &lt;- params[2]\n    sum(dnorm(campione, mean = mu, sd = sigma, log = TRUE))\n})\n\n# Reshape log-likelihood into a matrix\nlog_likelihood_2d &lt;- matrix(log_likelihood, nrow = length(mu_griglia), ncol = length(sigma_griglia))\n\n# Compute priors for mu and sigma\nlog_prior_mu &lt;- dnorm(mu_griglia, mean = 140, sd = 5, log = TRUE)\nlog_prior_sigma &lt;- dnorm(sigma_griglia, mean = 5, sd = 2, log = TRUE)\n\n# Combine priors into a grid\nlog_prior_2d &lt;- outer(log_prior_mu, log_prior_sigma, \"+\")\n\n# Compute log-posterior\nlog_posterior_2d &lt;- log_likelihood_2d + log_prior_2d\nlog_posterior_2d &lt;- log_posterior_2d - max(log_posterior_2d) # Stabilize\nposterior_2d &lt;- exp(log_posterior_2d)\nposterior_2d &lt;- posterior_2d / sum(posterior_2d) # Normalize\n\n# Convert posterior_2d to a data frame for visualization\nlibrary(reshape2)\nposterior_df &lt;- melt(posterior_2d)\nnames(posterior_df) &lt;- c(\"mu_idx\", \"sigma_idx\", \"posterior\")\nposterior_df$mu &lt;- mu_griglia[posterior_df$mu_idx]\nposterior_df$sigma &lt;- sigma_griglia[posterior_df$sigma_idx]\n\n# Plot the posterior distribution\nlibrary(ggplot2)\nggplot(posterior_df, aes(x = mu, y = sigma, fill = posterior)) +\n    geom_tile() +\n    scale_fill_viridis_c() +\n    labs(\n        title = \"Distribuzione a Posteriori Bidimensionale\",\n        x = \"Media ($\\\\mu$)\", y = \"Deviazione Standard ($\\\\sigma$)\"\n    )",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_grid_gauss.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/04_grid_gauss.html#riflessioni-conclusive",
    "title": "44  Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "\n44.9 Riflessioni Conclusive",
    "text": "44.9 Riflessioni Conclusive\nQuando si passa alla stima simultanea di più parametri, come la media (\\(\\mu\\)) e la deviazione standard (\\(\\sigma\\)), l’analisi diventa notevolmente più complessa. Questo perché occorre considerare un numero molto maggiore di combinazioni di parametri rispetto alla stima di un solo parametro, aumentando così il carico computazionale. Inoltre, la scelta delle priors per ciascun parametro richiede particolare attenzione, poiché queste influenzeranno in modo diretto le stime a posteriori.\nIn scenari dove lo spazio dei parametri è multidimensionale o quando l’esplorazione della griglia diventa impraticabile, l’uso di metodi avanzati come il campionamento di Markov Chain Monte Carlo (MCMC) diventa indispensabile. Questi metodi permettono di campionare in modo efficiente dalla distribuzione a posteriori, senza la necessità di esplorare esplicitamente ogni combinazione possibile di parametri, rendendo l’analisi più gestibile anche in contesti complessi.\nIn conclusione, l’estensione dell’approccio bayesiano a problemi con più parametri sconosciuti richiede un’attenzione ancora maggiore nella definizione dello spazio dei parametri, nella selezione delle priors appropriate e nel calcolo delle distribuzioni a posteriori. L’adozione di tecniche come l’MCMC può facilitare questo processo, permettendo di affrontare in modo efficiente problemi che altrimenti sarebbero proibitivi dal punto di vista computazionale.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_grid_gauss.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/04_grid_gauss.html#informazioni-sullambiente-di-sviluppo",
    "title": "44  Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] reshape2_1.4.4   see_0.9.0        gridExtra_2.3    patchwork_1.3.0 \n#&gt;  [5] bayesplot_1.11.1 psych_2.4.12     scales_1.3.0     markdown_1.13   \n#&gt;  [9] knitr_1.49       lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1   \n#&gt; [13] dplyr_1.1.4      purrr_1.0.2      readr_2.1.5      tidyr_1.3.1     \n#&gt; [17] tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3       \n#&gt; [21] here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     plyr_1.8.9        rprojroot_2.0.4  \n#&gt; [13] jsonlite_1.8.9    viridisLite_0.4.2 mnormt_2.1.1      cli_3.6.3        \n#&gt; [17] rlang_1.1.4       munsell_0.5.1     withr_3.0.2       yaml_2.3.10      \n#&gt; [21] tools_4.4.2       parallel_4.4.2    tzdb_0.4.0        colorspace_2.1-1 \n#&gt; [25] pacman_0.5.1      vctrs_0.6.5       R6_2.5.1          lifecycle_1.0.4  \n#&gt; [29] htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.0     gtable_0.3.6     \n#&gt; [33] Rcpp_1.0.13-1     glue_1.8.0        xfun_0.49         tidyselect_1.2.1 \n#&gt; [37] farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-166      labeling_0.4.3   \n#&gt; [41] rmarkdown_2.29    compiler_4.4.2\n\n\n\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_conjugate_families_1.html",
    "href": "chapters/bayesian_inference/05_conjugate_families_1.html",
    "title": "45  Distribuzioni coniugate (1)",
    "section": "",
    "text": "45.1 Introduzione\nIn questo capitolo, esploriamo il concetto di distribuzioni a priori coniugate e il loro ruolo nell’inferenza bayesiana. Utilizzando il modello beta-binomiale come esempio paradigmatico, dimostreremo come queste distribuzioni semplifichino l’analisi attraverso calcoli analitici diretti. L’uso di una distribuzione a priori coniugata non solo rende l’inferenza più agevole, ma fornisce anche una chiara visione del modo in cui le credenze a priori influenzano le conclusioni.\nPer favorire la comprensione, procederemo in tre fasi principali:",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_conjugate_families_1.html#introduzione",
    "href": "chapters/bayesian_inference/05_conjugate_families_1.html#introduzione",
    "title": "45  Distribuzioni coniugate (1)",
    "section": "",
    "text": "Introduzione del modello beta-binomiale.\nAnalisi della distribuzione Beta e del suo ruolo come distribuzione a priori.\nDescrizione del processo di aggiornamento bayesiano e dei vantaggi derivanti dall’uso di distribuzioni coniugate.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_conjugate_families_1.html#il-modello-beta-binomiale",
    "href": "chapters/bayesian_inference/05_conjugate_families_1.html#il-modello-beta-binomiale",
    "title": "45  Distribuzioni coniugate (1)",
    "section": "\n45.2 Il Modello Beta-Binomiale",
    "text": "45.2 Il Modello Beta-Binomiale\nIl modello beta-binomiale è un esempio classico per analizzare una proporzione \\(\\theta\\), ossia la probabilità di successo in una sequenza di prove binarie (ad esempio, successo/fallimento). Supponiamo di osservare \\(y\\) successi su \\(n\\) prove, dove ogni prova è indipendente e con la stessa probabilità di successo \\(\\theta\\), che appartiene all’intervallo \\([0,1]\\).\nLa funzione di verosimiglianza, basata sulla distribuzione binomiale, è espressa come:\n\\[\n\\text{Bin}(y \\mid n, \\theta) = \\binom{n}{y} \\theta^y (1 - \\theta)^{n - y},\n\\]\ndove \\(\\binom{n}{y}\\) è il coefficiente binomiale che conta il numero di modi in cui \\(y\\) successi possono verificarsi in \\(n\\) prove.\nPer modellare la nostra conoscenza preliminare su \\(\\theta\\), scegliamo una distribuzione a priori Beta, che rappresenta un’ampia gamma di credenze iniziali con parametri flessibili.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_conjugate_families_1.html#la-distribuzione-beta-un-prior-flessibile",
    "href": "chapters/bayesian_inference/05_conjugate_families_1.html#la-distribuzione-beta-un-prior-flessibile",
    "title": "45  Distribuzioni coniugate (1)",
    "section": "\n45.3 La Distribuzione Beta: Un Prior Flessibile",
    "text": "45.3 La Distribuzione Beta: Un Prior Flessibile\nLa distribuzione Beta è definita come:\n\\[\n\\text{Beta}(\\theta \\mid \\alpha, \\beta) = \\frac{1}{B(\\alpha, \\beta)} \\theta^{\\alpha - 1} (1 - \\theta)^{\\beta - 1}, \\quad \\text{con } \\theta \\in (0, 1),\n\\]\ndove:\n\n\\(\\alpha &gt; 0\\) e \\(\\beta &gt; 0\\) sono i iperparametri, che determinano la forma della distribuzione.\n\n\\(B(\\alpha, \\beta)\\) è la funzione Beta di Eulero, calcolata come:\n\\[\n  B(\\alpha, \\beta) = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)},\n  \\]\ndove \\(\\Gamma(x)\\) è la funzione Gamma, una generalizzazione del fattoriale.\n\n\n\n45.3.1 Interpretazione Intuitiva di \\(\\alpha\\) e \\(\\beta\\)\n\nNel contesto bayesiano:\n\n\n\\(\\alpha -1\\) rappresenta il numero ipotetico di “successi” a priori.\n\n\\(\\beta -1\\) rappresenta il numero ipotetico di “fallimenti” a priori.\n\nAd esempio:\n\nUna distribuzione Beta(1, 1) è uniforme (0 successi a priori e 0 fallimenti), indicando totale incertezza iniziale (assenza di credenze informate).\nUna distribuzione Beta(10, 20) rappresenta una conoscenza a priori basata su 9 successi e 19 fallimenti ipotizzati, indicando una convinzione iniziale relativamente solida, poiché deriva da un totale di 28 osservazioni virtuali che riflettono le credenze precedenti.\n\nQuesta interpretazione consente di calibrare le credenze a priori in base all’evidenza disponibile o alla fiducia nella stima.\n\n45.3.2 Flessibilità della Distribuzione Beta\nLa distribuzione Beta è estremamente versatile:\n\n\nForma: Valori diversi di \\(\\alpha\\) e \\(\\beta\\) producono distribuzioni simmetriche, asimmetriche o uniformi.\n\nForza del prior: Valori elevati di \\(\\alpha\\) e \\(\\beta\\) riducono la varianza, riflettendo credenze più forti.\n\nQuesta flessibilità rende la distribuzione Beta una scelta ideale per rappresentare credenze iniziali su proporzioni.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_conjugate_families_1.html#aggiornamento-bayesiano",
    "href": "chapters/bayesian_inference/05_conjugate_families_1.html#aggiornamento-bayesiano",
    "title": "45  Distribuzioni coniugate (1)",
    "section": "\n45.4 Aggiornamento Bayesiano",
    "text": "45.4 Aggiornamento Bayesiano\nL’aggiornamento bayesiano combina le informazioni iniziali (priori) con i dati osservati (verosimiglianza) per produrre una nuova distribuzione delle credenze (posteriori). Nel caso del modello beta-binomiale, questo processo è particolarmente semplice grazie alla “coniugazione”: il prior Beta e la verosimiglianza Binomiale producono una distribuzione a posteriori che appartiene ancora alla famiglia Beta.\n\n45.4.1 Problema\nSe osserviamo \\(y\\) successi su \\(n\\) prove, vogliamo aggiornare il nostro prior Beta con i dati osservati per ottenere una distribuzione a posteriori Beta. I parametri aggiornati della distribuzione a posteriori sono:\n\\[\n\\alpha' = \\alpha + y, \\quad \\beta' = \\beta + n - y.\n\\]\nVediamo in dettaglio come si arriva a questo risultato.\n\n45.4.2 Passaggi dell’Aggiornamento Bayesiano\n1. Formula di Bayes\nLa regola di Bayes afferma che:\n\\[\n\\text{Posterior} \\propto \\text{Prior} \\times \\text{Verosimiglianza},\n\\]\ndove \\(\\propto\\) indica “proporzionale a”. Qui ci concentriamo sui termini che dipendono dal parametro di interesse, \\(\\theta\\), la probabilità di successo.\n2. Espressione del Prior\nIl prior è una distribuzione Beta, definita come:\n\\[\n\\text{Prior} = \\theta^{\\alpha-1} (1-\\theta)^{\\beta-1},\n\\]\ndove:\n\n\n\\(\\theta\\) rappresenta la probabilità di successo,\n\n\\(\\alpha\\) e \\(\\beta\\) sono parametri che descrivono le nostre convinzioni iniziali:\n\n\n\\(\\alpha\\): il numero di successi attesi prima di osservare i dati,\n\n\\(\\beta\\): il numero di insuccessi attesi prima di osservare i dati.\n\n\n\n3. Espressione della Verosimiglianza\nLa verosimiglianza è data dalla distribuzione Binomiale, che rappresenta la probabilità di osservare \\(y\\) successi su \\(n\\) prove:\n\\[\n\\text{Verosimiglianza} = \\theta^y (1-\\theta)^{n-y},\n\\]\ndove:\n\n\n\\(y\\) è il numero di successi osservati,\n\n\\(n\\) è il numero totale di prove,\n\n\\(\\theta\\) è la probabilità di successo (il parametro che stiamo aggiornando).\n\n4. Moltiplicazione di Prior e Verosimiglianza\nCombinando prior e verosimiglianza, otteniamo:\n\\[\n\\text{Posterior} \\propto \\underbrace{\\theta^{\\alpha-1} (1-\\theta)^{\\beta-1}}_{\\text{Prior}} \\times \\underbrace{\\theta^y (1-\\theta)^{n-y}}_{\\text{Verosimiglianza}}.\n\\]\n5. Raggruppamento dei termini\nMoltiplicando i termini simili, raggruppiamo gli esponenti di \\(\\theta\\) e \\(1-\\theta\\):\n\\[\n\\text{Posterior} \\propto \\theta^{(\\alpha-1) + y} (1-\\theta)^{(\\beta-1) + (n-y)}.\n\\]\n6. Forma finale\nSemplificando gli esponenti:\n\\[\n\\text{Posterior} \\propto \\theta^{\\alpha + y - 1} (1-\\theta)^{\\beta + n - y - 1}.\n\\]\nQuesta è la forma di una distribuzione Beta con nuovi parametri:\n\\[\n\\alpha' = \\alpha + y, \\quad \\beta' = \\beta + n - y.\n\\]\n7. Normalizzazione\nPer trasformare questa espressione in una distribuzione di probabilità vera e propria, dobbiamo dividere per una costante di normalizzazione. La funzione Beta, \\(B(\\alpha', \\beta')\\), normalizza la distribuzione:\n\\[\np(\\theta | y, n) = \\frac{\\theta^{\\alpha' - 1} (1-\\theta)^{\\beta' - 1}}{B(\\alpha', \\beta')},\n\\]\ndove \\(B(\\alpha', \\beta')\\) è definita come:\n\\[\nB(\\alpha', \\beta') = \\int_0^1 \\theta^{\\alpha' - 1} (1-\\theta)^{\\beta' - 1} \\, d\\theta.\n\\]\nTuttavia, non dobbiamo calcolarla esplicitamente poiché sappiamo già che il risultato è una distribuzione Beta.\n8. Parametri aggiornati\nIn conclusione, i parametri aggiornati sono:\n\n\nNuovo \\(\\alpha'\\): \\(\\alpha + y\\), che somma al vecchio \\(\\alpha\\) il numero di successi osservati (\\(y\\)).\n\nNuovo \\(\\beta'\\): \\(\\beta + n - y\\), che somma al vecchio \\(\\beta\\) il numero di insuccessi osservati (\\(n-y\\)).\n\n45.4.3 Vantaggi del Modello Beta-Binomiale\nIl modello beta-binomiale presenta diversi vantaggi:\n\n\nSemplicità analitica: La distribuzione a posteriori appartiene alla stessa famiglia della distribuzione a priori, evitando calcoli complessi.\n\nInterpretazione trasparente: L’aggiornamento dei parametri \\(\\alpha\\) e \\(\\beta\\) mostra chiaramente come i dati influenzino le credenze.\n\nNonostante la semplicità, le distribuzioni a priori coniugate non sempre rappresentano credenze realistiche. Tecniche moderne come il campionamento Monte Carlo consentono di usare distribuzioni a priori più complesse, ma il modello beta-binomiale rimane un esempio didattico fondamentale per comprendere l’inferenza bayesiana.\nIn conclusione, il modello beta-binomiale illustra chiaramente come le distribuzioni a priori coniugate possano semplificare l’inferenza bayesiana e fornire una comprensione intuitiva dell’interazione tra prior e dati. Questo modello rappresenta un punto di partenza ideale per approfondire l’approccio bayesiano e prepararsi a concetti più avanzati.\n\nEsempio 45.1 In un esempio ispirato da McElreath (2020) nel suo libro “Statistical Rethinking”, consideriamo un esperimento dove otteniamo 6 successi (indicati come “acqua”) su un totale di 9 prove (immaginate come lanci di un mappamondo). La verosimiglianza binomiale per questo esperimento è data da:\n\\[\n\\theta^y (1-\\theta)^{n-y},\n\\]\ndove \\(y = 6\\) è il numero di successi e \\(n = 9\\) è il numero totale di prove.\nSe scegliamo una distribuzione a priori Beta con parametri \\(\\alpha = 2\\) e \\(\\beta = 2\\), possiamo utilizzare l’aggiornamento bayesiano per calcolare i parametri della distribuzione a posteriori, dato l’esito delle nostre prove. L’applicazione del teorema di Bayes porta a una distribuzione a posteriori Beta con i parametri aggiornati \\(\\alpha' = \\alpha + y = 8\\) e \\(\\beta' = \\beta + n - y = 5\\).\nOra, vediamo come visualizzare le tre distribuzioni di interesse: la distribuzione a priori Beta(\\(2, 2\\)), la verosimiglianza binomiale per \\(y=6\\) e \\(n=9\\), e la distribuzione a posteriori Beta(\\(8, 5\\)).\n\n# Definizione dei parametri\nalpha_prior &lt;- 2\nbeta_prior &lt;- 2\ny &lt;- 6\nn &lt;- 9\n\n# Parametri della distribuzione a posteriori\nalpha_post &lt;- alpha_prior + y\nbeta_post &lt;- beta_prior + n - y\n\n# Creiamo una sequenza di valori di theta\ntheta &lt;- seq(0, 1, length.out = 1000) # Maggiore risoluzione\n\n# Calcoliamo le PDF\nprior_pdf &lt;- dbeta(theta, shape1 = alpha_prior, shape2 = beta_prior)\nlikelihood &lt;- theta^y * (1 - theta)^(n - y)\n\n# Normalizziamo la verosimiglianza usando il metodo trapezoidale\nlikelihood_integral &lt;- sum(likelihood) * (theta[2] - theta[1]) # Approssimazione numerica dell'integrale\nnormalized_likelihood &lt;- likelihood / likelihood_integral\n\nposterior_pdf &lt;- dbeta(theta, shape1 = alpha_post, shape2 = beta_post)\n\n# Disegniamo le distribuzioni\nplot(theta, prior_pdf,\n    type = \"l\", col = \"blue\", lwd = 2,\n    ylim = c(0, max(c(prior_pdf, normalized_likelihood, posterior_pdf))),\n    xlab = expression(theta), ylab = \"Densità\",\n    main = \"Distribuzioni Prior, Likelihood e Posterior\"\n)\nlines(theta, normalized_likelihood, col = \"green\", lwd = 2, lty = 2)\nlines(theta, posterior_pdf, col = \"red\", lwd = 2)\nlegend(\"topleft\",\n    legend = c(\n        sprintf(\"Prior Beta(%d, %d)\", alpha_prior, beta_prior),\n        \"Likelihood (normalizzata)\",\n        sprintf(\"Posterior Beta(%d, %d)\", alpha_post, beta_post)\n    ),\n    col = c(\"blue\", \"green\", \"red\"),\n    lty = c(1, 2, 1), lwd = 2\n)\n\n\n\n\n\n\n\nIn questo codice, la funzione trapezoid viene usata per calcolare l’integrale della funzione di verosimiglianza non normalizzata su θ, fornendo il fattore di normalizzazione. Dividendo la funzione di verosimiglianza per questo fattore, otteniamo una funzione di verosimiglianza normalizzata, il cui integrale su [0, 1] è uguale a 1. La normalizzazione della verosimiglianza è eseguita solo a scopo di visualizzazione, per facilitare il confronto tra le curve.\n\n\nEsempio 45.2 Esaminiamo ora un esempio discuso da Johnson et al. (2022). In uno studio molto famoso, Stanley Milgram ha studiato la propensione delle persone a obbedire agli ordini delle figure di autorità, anche quando tali ordini potrebbero danneggiare altre persone (Milgram 1963). Nell’articolo, Milgram descrive lo studio come\n\nconsistente nell’ordinare a un soggetto ingenuo di somministrare una scossa elettrica a una vittima. Viene utilizzato un generatore di scosse simulato, con 30 livelli di tensione chiaramente contrassegnati che vanno da IS a 450 volt. Lo strumento porta delle designazioni verbali che vanno da Scossa Lieve a Pericolo: Scossa Grave. Le risposte della vittima, che è un complice addestrato dell’esperimentatore, sono standardizzate. Gli ordini di somministrare scosse vengono dati al soggetto ingenuo nel contesto di un ‘esperimento di apprendimento’ apparentemente organizzato per studiare gli effetti della punizione sulla memoria. Man mano che l’esperimento procede, al soggetto ingenuo viene ordinato di somministrare scosse sempre più intense alla vittima, fino al punto di raggiungere il livello contrassegnato Pericolo: Scossa Grave.\n\nIn altre parole, ai partecipanti allo studio veniva dato il compito di testare un altro partecipante (che in realtà era un attore addestrato) sulla loro capacità di memorizzare una serie di item. Se l’attore non ricordava un item, al partecipante veniva ordinato di somministrare una scossa all’attore e di aumentare il livello della scossa con ogni fallimento successivo. I partecipanti non erano consapevoli del fatto che le scosse fossero finte e che l’attore stesse solo fingendo di provare dolore dalla scossa.\nNello studio di Milgram, 26 partecipanti su 40 hanno somministrato scosse al livello “Pericolo: Scossa Grave”. Il problema richiede di costruire la distribuzione a posteriori della probabilità \\(\\theta\\) di infliggere una scossa a l livello “Pericolo: Scossa Grave”, ipotizzando che uno studio precedente aveva stabilito che \\(\\theta\\) segue una distribuzione Beta(1, 10).\nIniziamo a fornire una rappresentazione grafica della distribuzione a priori.\n\n# Impostazione dei parametri della distribuzione Beta\nalpha &lt;- 1\nbeta_val &lt;- 10\n\n# Creazione di valori x per il plot\nx_values &lt;- seq(0, 1, length.out = 1000)\n\n# Calcolo della densità di probabilità per ogni valore di x\nbeta_pdf &lt;- dbeta(x_values, shape1 = alpha, shape2 = beta_val)\n\n# Plot della densità di probabilità\ncolor_fill &lt;- \"#b97c7c\"\nplot(x_values, beta_pdf,\n    type = \"l\", col = color_fill, lwd = 2,\n    main = \"Distribuzione Beta(1, 10)\",\n    xlab = \"x\", ylab = \"Densità di probabilità\"\n)\nlegend(\"topright\", legend = \"Beta(1, 10)\", col = color_fill, lwd = 2)\n\n\n\n\n\n\n\nLa distribuzione a posteriori segue una distribuzione Beta con parametri aggiornati:\n\ny &lt;- 26\nn &lt;- 40\n\nalpha_prior &lt;- 1\nbeta_prior &lt;- 10\n\nalpha_post &lt;- alpha_prior + y\nbeta_post &lt;- beta_prior + n - y\n\nalpha_post\n#&gt; [1] 27\nbeta_post\n#&gt; [1] 24\n\nCreazione di un grafico per la distribuzione a posteriori:\n\n# Creazione di valori x per il plot\nx_values &lt;- seq(0, 1, length.out = 1000)\n\n# Calcolo della densità di probabilità per ogni valore di x\nbeta_pdf &lt;- dbeta(x_values, alpha_post, beta_post)\n\n# Plot della densità di probabilità\nplot(x_values, beta_pdf,\n    type = \"l\", col = \"blue\", lwd = 2,\n    main = \"Distribuzione Beta(27, 24)\", xlab = expression(theta), ylab = \"Densità di probabilità\"\n)\nlegend(\"topright\", legend = \"Beta(27, 24)\", col = \"blue\", lwd = 2)\n\n\n\n\n\n\n\nCalcolo della media a posteriori di \\(\\theta\\):\n\nalpha_post / (alpha_post + beta_post)\n#&gt; [1] 0.529\n\nCalcolo della moda a posteriori:\n\n(alpha_post - 1) / (alpha_post + beta_post - 2)\n#&gt; [1] 0.531\n\nCalcolo della probabilità che \\(\\theta &gt; 0.6\\):\n\npbeta(0.6, alpha_post, beta_post, lower.tail = FALSE)\n#&gt; [1] 0.156\n\nOvvero:\n\n1 - pbeta(0.6, alpha_post, beta_post)\n#&gt; [1] 0.156\n\nEseguiamo il problema utilizzando il metodo basato su griglia. Definiamo la griglia di interesse:\n\ntheta &lt;- seq(0, 1, length.out = 100)\n\nCreiamo la distribuzione a priori:\n\nprior &lt;- dbeta(theta, alpha_prior, beta_prior)\n\nplot(theta, prior / sum(prior),\n    type = \"h\", col = \"blue\", lwd = 2,\n    main = \"Distribuzione a priori\", xlab = expression(theta), ylab = \"Probabilità\"\n)\n\n\n\n\n\n\n\nCreiamo la verosimiglianza:\n\nlk &lt;- dbinom(y, n, theta)\n\nplot(theta, lk / sum(lk),\n    type = \"h\", col = \"red\", lwd = 2,\n    main = \"Verosimiglianza\", xlab = expression(theta), ylab = \"Probabilità\"\n)\n\n\n\n\n\n\n\nCalcoliamo la distribuzione a posteriori:\n\npost &lt;- (prior * lk) / sum(prior * lk)\n\nplot(theta, post,\n    type = \"h\", col = \"green\", lwd = 2,\n    main = \"Distribuzione a posteriori\", xlab = expression(theta), ylab = \"Probabilità\"\n)\n\n\n\n\n\n\n\nEstrazione di un campione dalla distribuzione a posteriori:\n\nsamples &lt;- sample(theta, size = 1e6, replace = TRUE, prob = post)\n\nTroviamo la media a posteriori:\n\nmean(samples)\n#&gt; [1] 0.529\n\nCalcoliamo la probabilità che \\(\\theta &gt; 0.6\\):\n\nmean(samples &gt; 0.6)\n#&gt; [1] 0.153\n\nQuesto codice mantiene la struttura logica del problema e produce risultati equivalenti utilizzando R.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_conjugate_families_1.html#principali-distribuzioni-coniugate",
    "href": "chapters/bayesian_inference/05_conjugate_families_1.html#principali-distribuzioni-coniugate",
    "title": "45  Distribuzioni coniugate (1)",
    "section": "\n45.5 Principali distribuzioni coniugate",
    "text": "45.5 Principali distribuzioni coniugate\nEsistono altre combinazioni di verosimiglianza e distribuzione a priori che producono una distribuzione a posteriori con la stessa forma della distribuzione a priori. Ecco alcune delle più note coniugazioni tra modelli statistici e distribuzioni a priori:\n\nNel modello Normale-Normale \\(\\mathcal{N}(\\mu, \\sigma^2_0)\\), la distribuzione a priori è \\(\\mathcal{N}(\\mu_0, \\tau^2)\\) e la distribuzione a posteriori è \\(\\mathcal{N}\\left(\\frac{\\mu_0\\sigma^2 + \\bar{y}n\\tau^2}{\\sigma^2 + n\\tau^2}, \\frac{\\sigma^2\\tau^2}{\\sigma^2 + n\\tau^2} \\right)\\).\nNel modello Poisson-gamma \\(\\text{Po}(\\theta)\\), la distribuzione a priori è \\(\\Gamma(\\lambda, \\delta)\\) e la distribuzione a posteriori è \\(\\Gamma(\\lambda + n \\bar{y}, \\delta +n)\\).\nNel modello esponenziale \\(\\text{Exp}(\\theta)\\), la distribuzione a priori è \\(\\Gamma(\\lambda, \\delta)\\) e la distribuzione a posteriori è \\(\\Gamma(\\lambda + n, \\delta +n\\bar{y})\\).\nNel modello uniforme-Pareto \\(\\text{U}(0, \\theta)\\), la distribuzione a priori è \\(\\text{Pa}(\\alpha, \\varepsilon)\\) e la distribuzione a posteriori è \\(\\text{Pa}(\\alpha + n, \\max(y_{(n)}, \\varepsilon))\\).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_conjugate_families_1.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/05_conjugate_families_1.html#riflessioni-conclusive",
    "title": "45  Distribuzioni coniugate (1)",
    "section": "\n45.6 Riflessioni Conclusive",
    "text": "45.6 Riflessioni Conclusive\nIn conclusione, l’utilizzo di priori coniugati presenta vantaggi e svantaggi. Cominciamo con i vantaggi principali. Il principale vantaggio dell’adozione di distribuzioni a priori coniugate risiede nella loro capacità di rendere l’analisi della distribuzione a posteriori trattabile da un punto di vista analitico. Ad esempio, nel corso di questo capitolo abbiamo esaminato come sia possibile formulare la distribuzione a posteriori in seguito a un esperimento composto da una serie di prove di Bernoulli (con una verosimiglianza binomiale), utilizzando una distribuzione Beta sia per la prior che per il posteriore.\nTuttavia, è cruciale riconoscere che i modelli basati sul concetto di famiglie coniugate presentano delle limitazioni intrinseche. Le distribuzioni coniugate a priori sono disponibili solamente per distribuzioni di verosimiglianza di base e relativamente semplici. Per modelli complessi e più realistici, la ricerca di priori coniugati diventa spesso un compito estremamente arduo, limitando quindi la loro utilità. Inoltre, anche quando le distribuzioni a priori coniugate sono disponibili, un modello che ne fa uso potrebbe non essere sufficientemente flessibile per adattarsi alle nostre credenze iniziali. Ad esempio, un modello basato su una distribuzione normale è sempre unimodale e simmetrico rispetto alla media \\(\\mu\\). Tuttavia, se le nostre conoscenze iniziali non sono simmetriche o non seguono una distribuzione unimodale, la scelta di una distribuzione a priori normale potrebbe non risultare la più adeguata (Johnson et al., 2022).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_conjugate_families_1.html#esercizi",
    "href": "chapters/bayesian_inference/05_conjugate_families_1.html#esercizi",
    "title": "45  Distribuzioni coniugate (1)",
    "section": "\n45.7 Esercizi",
    "text": "45.7 Esercizi\n\nEsercizio 45.1 Si consideri lo studio “An excess of positive results: Comparing the standard psychology literature with registered reports” di Scheel et al. (2021). In questo lavoro, gli autori confrontano il tasso di risultati positivi \\(\\theta\\) ottenuti in studi psicologici pubblicati senza preregistrazione con quelli pubblicati con preregistrazione. Si utilizzi il tasso di successo riportato negli studi preregistrati per costruire una distribuzione a priori per il parametro \\(\\theta\\).\nSecondo i risultati degli studi preregistrati, gli autori riscontrano un tasso di successo del 43.66%, con un intervallo di confidenza al 95% [CI] = [31.91, 55.95]. Sulla base di questi dati, si costruisca una distribuzione beta come distribuzione a priori per \\(\\theta\\), seguendo il metodo illustrato da Johnson et al. (2022).\nSuccessivamente, utilizzando questa distribuzione beta come distribuzione a priori, si determini la distribuzione a posteriori utilizzando il metodo delle famiglie coniugate per due scenari distinti, basati su 152 studi osservati: (a) Un tasso di successo del 60% (b) Un tasso di successo del 96% (come riportato per gli studi non preregistrati da Scheel et al. (2021)).\nInfine, si commentino i risultati derivanti dall’analisi delle distribuzioni a posteriori ottenute per entrambi gli scenari.\n\n\nEsercizio 45.2 Tra i fattori che possono influenzare il rapporto tra i sessi alla nascita c’è la condizione materna di placenta previa, una condizione insolita della gravidanza in cui la placenta è impiantata in basso nell’utero, impedendo un normale parto vaginale del feto. Uno studio condotto in Germania ha esaminato il sesso dei neonati in casi di placenta previa e ha riscontrato che, su un totale di 980 nascite, 437 erano femmine.\nQuanta evidenza fornisce questo studio a supporto dell’ipotesi che la proporzione di nascite femminili nella popolazione di placenta previa sia inferiore a 0.485, che rappresenta la proporzione di nascite femminili nella popolazione generale? (Esercizio tratto da Gelman et al. (1995))\n\n\nEsercizio 45.3 Per valutare la sensibilità della soluzione precedente alla scelta della distribuzione a priori, ripetere l’esercizio utilizzando come distribuzione a priori per la proporzione di nascite femminili una distribuzione Beta(48.5, 51.5). Questa distribuzione è centrata su 0.485 e concentra la maggior parte della sua massa nell’intervallo [0.385, 0.585]. Interpretare i risultati ottenuti.\n\n\nEsercizio 45.4 In uno studio recente, Gori et al. (2024) hanno esaminato un campione di 202 adulti italiani e hanno riscontrato una prevalenza di mancini del 6.4%. Una meta-analisi di Papadatou-Pastou et al. (2020), condotta su un totale di 2,396,170 soggetti, riporta che la proporzione di mancini varia tra il 9.3% e il 18.1%, a seconda di come viene misurata la lateralità manuale. Inoltre, Papadatou-Pastou et al. (2020) mostrano che la prevalenza della lateralità manuale varia tra i paesi e nel tempo. Considerata questa incertezza, si determini la distribuzione a posteriori che combina i dati dello studio di Gori et al. (2024) con le informazioni pregresse fornite da Papadatou-Pastou et al. (2020). Le informazioni di Papadatou-Pastou et al. (2020) possono essere espresse in termini di una distribuzione Beta(8, 60).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_conjugate_families_1.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/05_conjugate_families_1.html#informazioni-sullambiente-di-sviluppo",
    "title": "45  Distribuzioni coniugate (1)",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.17.0      see_0.9.0        gridExtra_2.3    patchwork_1.3.0 \n#&gt;  [5] bayesplot_1.11.1 psych_2.4.12     scales_1.3.0     markdown_1.13   \n#&gt;  [9] knitr_1.49       lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1   \n#&gt; [13] dplyr_1.1.4      purrr_1.0.2      readr_2.1.5      tidyr_1.3.1     \n#&gt; [17] tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3       \n#&gt; [21] here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      shape_1.4.6.1     xfun_0.49         htmlwidgets_1.6.4\n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2      \n#&gt;  [9] generics_0.1.3    parallel_4.4.2    pan_1.9           pacman_0.5.1     \n#&gt; [13] pkgconfig_2.0.3   jomo_2.7-6        Matrix_1.7-1      lifecycle_1.0.4  \n#&gt; [17] compiler_4.4.2    farver_2.1.2      munsell_0.5.1     mnormt_2.1.1     \n#&gt; [21] codetools_0.2-20  htmltools_0.5.8.1 yaml_2.3.10       glmnet_4.1-8     \n#&gt; [25] nloptr_2.1.1      pillar_1.10.0     MASS_7.3-61       iterators_1.0.14 \n#&gt; [29] rpart_4.1.23      boot_1.3-31       foreach_1.5.2     mitml_0.4-5      \n#&gt; [33] nlme_3.1-166      tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4    \n#&gt; [37] splines_4.4.2     rprojroot_2.0.4   fastmap_1.2.0     grid_4.4.2       \n#&gt; [41] colorspace_2.1-1  cli_3.6.3         magrittr_2.0.3    survival_3.8-3   \n#&gt; [45] broom_1.0.7       withr_3.0.2       backports_1.5.0   timechange_0.3.0 \n#&gt; [49] rmarkdown_2.29    nnet_7.3-19       lme4_1.1-35.5     hms_1.1.3        \n#&gt; [53] evaluate_1.0.1    rlang_1.1.4       Rcpp_1.0.13-1     glue_1.8.0       \n#&gt; [57] minqa_1.2.8       jsonlite_1.8.9    R6_2.5.1",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_conjugate_families_1.html#bibliografia",
    "href": "chapters/bayesian_inference/05_conjugate_families_1.html#bibliografia",
    "title": "45  Distribuzioni coniugate (1)",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., Carlin, J. B., Stern, H. S., & Rubin, D. B. (1995). Bayesian data analysis. Chapman; Hall/CRC.\n\n\nGori, B., Grippo, A., Focardi, M., & Lolli, F. (2024). The Italian version of Edinburgh Handedness Inventory: Translation, transcultural adaptation, and validation in healthy subjects. Laterality, 29(2), 151–168.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nPapadatou-Pastou, M., Ntolka, E., Schmitz, J., Martin, M., Munafò, M. R., Ocklenburg, S., & Paracchini, S. (2020). Human handedness: A meta-analysis. Psychological bulletin, 146(6), 481–524.\n\n\nScheel, A. M., Schijen, M. R., & Lakens, D. (2021). An excess of positive results: Comparing the standard psychology literature with registered reports. Advances in Methods and Practices in Psychological Science, 4(2), 25152459211007467.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_conjugate_families_2.html",
    "href": "chapters/bayesian_inference/06_conjugate_families_2.html",
    "title": "46  Distribuzioni coniugate (2)",
    "section": "",
    "text": "46.1 Introduzione\nLa statistica bayesiana ci permette di aggiornare le nostre credenze iniziali o conoscenze a priori sulla distribuzione di un parametro (in questo caso, la media della popolazione) in base ai dati osservati. Questo processo di aggiornamento ci porta a ottenere una distribuzione a posteriori che riflette una nuova comprensione del parametro, integrata con le informazioni fornite dal campione.\nIl concetto fondamentale è che, attraverso l’aggiornamento bayesiano, l’incertezza sulla stima del parametro si riduce. Questo è dovuto al fatto che l’informazione aggiuntiva fornita dai dati osservati consente di “restringere” la distribuzione a posteriori rispetto alla distribuzione a priori, riducendo così la varianza (o deviazione standard) della distribuzione del parametro di interesse.\nIn questo capitolo, approfondiremo il tema delle famiglie coniugate (Capitolo 45), focalizzandoci sul modello normale-normale. Una caratteristica distintiva di questo modello è la sua capacità di auto-coniugazione rispetto a una funzione di verosimiglianza gaussiana. In termini più semplici, se la funzione di verosimiglianza segue una distribuzione gaussiana, l’adozione di una distribuzione a priori gaussiana per la media garantisce che anche la distribuzione a posteriori mantenga la sua forma gaussiana.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_conjugate_families_2.html#perché-usare-la-distribuzione-normale",
    "href": "chapters/bayesian_inference/06_conjugate_families_2.html#perché-usare-la-distribuzione-normale",
    "title": "46  Distribuzioni coniugate (2)",
    "section": "\n46.2 Perché Usare la Distribuzione Normale?",
    "text": "46.2 Perché Usare la Distribuzione Normale?\nSpesso, quando la distribuzione a posteriori è nota per essere unimodale e simmetrica, possiamo modellarla efficacemente con una distribuzione normale, anche se sappiamo che la sua forma è solo approssimativamente normale. Nei casi in cui il ricercatore abbia un’idea approssimativa di dove sia centrato un parametro sconosciuto, la distribuzione normale fornisce un metodo utile per modellare questa stima, permettendo di descrivere il livello di incertezza tramite il termine di varianza della distribuzione normale. Questa convenienza può offrire buone approssimazioni alla densità a posteriori desiderata, con la consapevolezza che, con l’aumentare dei dati osservati, tali assunzioni perdono di importanza.\nCome dimostrato di seguito, il modello normale bayesiano possiede proprietà frequentiste desiderabili. Sebbene l’enfasi nell’analisi bayesiana non sia sulle stime puntuali, si può dimostrare che, con campioni sempre più grandi, la media della distribuzione a posteriori bayesiana si avvicina alla stima di massima verosimiglianza. Questa proprietà esiste perché la distribuzione a posteriori è un compromesso ponderato tra la distribuzione a priori specificata dall’utente, che in questo capitolo è normale, e la funzione di verosimiglianza derivata dai dati, anch’essa normale in questo capitolo. Con l’aumentare delle dimensioni del campione, la verosimiglianza diventa sempre più dominante in questa ponderazione.\nNel caso di una media normale, illustrato qui, la varianza della distribuzione di campionamento frequentista diminuisce con l’aumento della dimensione del campione. Nel contesto bayesiano, la riduzione della varianza media dalla funzione di verosimiglianza alla fine prevale anche su una varianza a priori deliberatamente grande. Pertanto, se si prevede che la dimensione del dataset sia grande, i ricercatori possono permettersi di essere liberali nella specificazione della varianza a priori.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_conjugate_families_2.html#distribuzione-a-posteriori-in-un-contesto-normale-con-varianza-nota",
    "href": "chapters/bayesian_inference/06_conjugate_families_2.html#distribuzione-a-posteriori-in-un-contesto-normale-con-varianza-nota",
    "title": "46  Distribuzioni coniugate (2)",
    "section": "\n46.3 Distribuzione a Posteriori in un Contesto Normale con Varianza Nota",
    "text": "46.3 Distribuzione a Posteriori in un Contesto Normale con Varianza Nota\nConsideriamo un insieme di dati \\(y = [y_1, y_2, \\ldots, y_n]\\), composto da \\(n\\) osservazioni indipendenti e identicamente distribuite (i.i.d.) secondo una distribuzione normale \\(\\mathcal{N}(\\mu, \\sigma^2)\\). In questo scenario, il nostro obiettivo è stimare il valore del parametro \\(\\mu\\), che rappresenta la media della popolazione da cui provengono i dati.\n\n46.3.1 Distribuzione a Priori\nNell’approccio bayesiano, assumiamo una conoscenza iniziale sul parametro \\(\\mu\\) mediante una distribuzione a priori. In questo caso, utilizziamo una distribuzione normale coniugata, ovvero una distribuzione normale con media \\(\\mu_0\\) e varianza \\(\\sigma_0^2\\). Questa scelta riflette la nostra incertezza iniziale su \\(\\mu\\).\n\n46.3.2 Funzione di Verosimiglianza\nLa funzione di verosimiglianza, denotata da \\(p(y | \\mu, \\sigma)\\), rappresenta la probabilità di osservare i dati \\(y\\) dato il valore del parametro \\(\\mu\\) e la varianza nota \\(\\sigma^2\\). Per una distribuzione normale i.i.d., la funzione di verosimiglianza è data da:\n\\[\np(y | \\mu, \\sigma) = \\prod_{i=1}^n \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp\\left(-\\frac{(y_i - \\mu)^2}{2\\sigma^2}\\right).\n\\]\n\n46.3.3 Teorema di Bayes e Distribuzione a Posteriori\nIl teorema di Bayes combina la distribuzione a priori con la funzione di verosimiglianza per ottenere la distribuzione a posteriori del parametro \\(\\mu\\), data l’evidenza osservata \\(y\\):\n\\[\np(\\mu | y) = \\frac{ p(y | \\mu) p(\\mu) }{ p(y) }.\n\\]\nPoiché la distribuzione a priori e la funzione di verosimiglianza sono entrambe distribuzioni normali, la distribuzione a posteriori risulterà anch’essa una distribuzione normale con media a posteriori \\(\\mu_p\\) e varianza a posteriori \\(\\sigma_p^2\\).\n\n46.3.4 Formula per la Media a Posteriori (\\(\\mu_p\\))\nLa media a posteriori \\(\\mu_p\\) rappresenta la stima aggiornata del parametro \\(\\mu\\) alla luce delle informazioni contenute nei dati osservati. La sua formula è:\n\\[\n\\mu_p = \\frac{\\frac{1}{\\sigma_0^2} \\mu_0 + \\frac{n}{\\sigma^2} \\bar{y}}{\\frac{1}{\\sigma_0^2} + \\frac{n}{\\sigma^2}},\n\\]\ndove \\(\\bar{y}\\) rappresenta la media campionaria:\n\\[\n\\bar{y} = \\frac{\\sum_{i=1}^n y_i}{n}.\n\\]\nOsserviamo che \\(\\mu_p\\) è una combinazione ponderata tra la media a priori \\(\\mu_0\\) e la media campionaria \\(\\bar{y}\\). Il peso di \\(\\bar{y}\\) aumenta con il numero di osservazioni \\(n\\), mentre il peso di \\(\\mu_0\\) diminuisce. Questo riflette il fatto che con più dati, la nostra fiducia nella media campionaria cresce, mentre l’incertezza a priori diminuisce.\n\n46.3.5 Formula per la Varianza a Posteriori (\\(\\sigma_p^2\\))\nLa varianza a posteriori \\(\\sigma_p^2\\) rappresenta l’incertezza residua sulla stima del parametro \\(\\mu\\) dopo aver incorporato le informazioni dai dati. La sua formula è:\n\\[\n\\sigma_p^2 = \\frac{1}{\\frac{1}{\\sigma_0^2} + \\frac{n}{\\sigma^2}}.\n\\]\nRispetto alla varianza a priori \\(\\sigma_0^2\\), la varianza a posteriori \\(\\sigma_p^2\\) è sempre inferiore o uguale. In altre parole, l’incertezza sulla stima di \\(\\mu\\) si riduce con l’aumentare del numero di osservazioni. La varianza a posteriori rappresenta un bilanciamento tra l’incertezza a priori (\\(\\sigma_0^2\\)) e l’informazione derivata dai dati (\\(\\sigma^2/n\\)).\nIn sintesi, nel caso normale-normale con varianza nota, la distribuzione a posteriori risulta essere una distribuzione normale con una media e una varianza che riflettono un’integrazione bilanciata tra l’informazione a priori e quella ottenuta dai dati osservati. Questo approccio garantisce una stima aggiornata e affinata del parametro \\(\\mu\\) che migliora con l’aumento del numero di osservazioni.\n\nEsempio 46.1 I test standard di QI sono progettati per misurare l’intelligenza con una media di 100 e una deviazione standard di 15. Tuttavia, si dice anche che questi test presentino bias culturali che favoriscono alcuni gruppi rispetto ad altri. Un’ulteriore complicazione si verifica quando i punteggi di QI vengono aggregati a livello nazionale, poiché le caratteristiche interne ai paesi vengono mascherate. Questo esempio analizza i dati di QI raccolti a livello internazionale (Lynn e Vanhanen, 2001) per 80 paesi da fonti nazionali pubblicate e discussi da Gill (2015). L’idea chiave nella descrizione della distribuzione a posteriori è se le differenze tra le nazioni alterano la parametrizzazione prevista.\nI dati di Lynn e Vanhanen (2001) sono forniti di seguito:\n\n\n\n\n\n\n\n\n\n\n\n\nPaese\nIQ\nPaese\nIQ\nPaese\nIQ\nPaese\nIQ\n\n\n\nArgentina\n96\nAustralia\n98\nAustria\n102\nBarbados\n78\n\n\nBelgium\n100\nBrazil\n87\nBulgaria\n93\nCanada\n97\n\n\nChina\n100\nCongo (Br.)\n73\nCongo (Zr.)\n65\nCroatia\n90\n\n\nCuba\n85\nCzech Repub.\n97\nDenmark\n98\nEcuador\n80\n\n\nEgypt\n83\nEq. Guinea\n59\nEthiopia\n63\nFiji\n84\n\n\nFinland\n97\nFrance\n98\nGermany\n102\nGhana\n71\n\n\nGreece\n92\nGuatemala\n79\nGuinea\n66\nHong Kong\n107\n\n\nHungary\n99\nIndia\n81\nIndonesia\n89\nIran\n84\n\n\nIraq\n87\nIreland\n93\nIsrael\n94\nItaly\n102\n\n\nJamaica\n72\nJapan\n105\nKenya\n72\nKorea (S.)\n106\n\n\nLebanon\n86\nMalaysia\n92\nMarshall I.\n84\nMexico\n87\n\n\nMorocco\n85\nNepal\n78\nNetherlands\n102\nNew Zealand\n100\n\n\nNigeria\n67\nNorway\n98\nPeru\n90\nPhilippines\n86\n\n\nPoland\n99\nPortugal\n95\nPuerto Rico\n84\nQatar\n78\n\n\nRomania\n94\nRussia\n96\nSamoa\n87\nSierra Leone\n64\n\n\nSingapore\n103\nSlovakia\n96\nSlovenia\n95\nSouth Africa\n72\n\n\nSpain\n97\nSudan\n72\nSuriname\n89\nSweden\n101\n\n\nSwitzerland\n101\nTaiwan\n104\nTanzania\n72\nThailand\n91\n\n\nTonga\n87\nTurkey\n90\nUganda\n73\nU.K.\n100\n\n\nU.S.\n98\nUruguay\n96\nZambia\n77\nZimbabwe\n66\n\n\n\nImplementiamo le informazioni necessarie in Python.\n\n# Dati IQ delle 80 nazioni\niq &lt;- c(\n  96, 100, 100, 85, 83, 97, 92, 99, 87, 72, 86, 85, 67, 99, 94, 103, 97, 101, 87, 98,\n  87, 73, 97, 59, 98, 79, 81, 93, 105, 92, 78, 98, 95, 96, 72, 104, 90, 96, 98, 102,\n  78, 90, 63, 84, 84, 107, 86, 102, 106, 94, 102, 72, 101, 89, 72, 101, 91, 100, 100,\n  66, 107, 86, 78, 84, 78, 64, 72, 101, 91, 100, 67, 86\n)\n\n\n# Numero di osservazioni\nn &lt;- length(iq)\n\n# Media campionaria\ny_bar &lt;- mean(iq)\n\n# Deviazione standard nota\nsigma &lt;- 15\n\n# Parametri a priori\nmu_0 &lt;- 100\nsigma_0 &lt;- 15\n\nCalcoliamo la media a posteriori con la formula discussa in precedenza\n\\[\n\\mu_p = \\frac{\\frac{1}{\\sigma_0^2}\\mu_0 + \\frac{n}{\\sigma^2}\\bar{y}}{\\frac {1}{\\sigma_0^2} + \\frac{n}{\\sigma^2}}\n\\]\ndove:\n\n\n\\(\\mu_0\\) è la media a priori\n\n\\(\\sigma_0\\) è la deviazione standard a priori\n\n\\(n\\) è il numero di osservazioni\n\n\\(\\sigma\\) è la deviazione standard delle osservazioni (nota)\n\n\\(\\bar{y}\\) è la media campionaria\n\n\nmu_p &lt;- ((1 / sigma_0^2) * mu_0 + (n / sigma^2) * y_bar) /\n  ((1 / sigma_0^2) + (n / sigma^2))\nprint(paste(\"Media a posteriori (mu_p):\", round(mu_p, 2)))\n#&gt; [1] \"Media a posteriori (mu_p): 89.36\"\n\nCalcoliamo la varianza a posteriori\n\\[\n\\sigma_p^2 = \\frac{1}{\\frac {1}{\\sigma_0^2}+ \\frac{n}{\\sigma^2}}\n\\]\n\nsigma_p_sq &lt;- 1 / ((1 / sigma_0^2) + (n / sigma^2))\nsigma_p &lt;- sqrt(sigma_p_sq)\nprint(paste(\"Varianza a posteriori (sigma_p_sq):\", round(sigma_p_sq, 2)))\n#&gt; [1] \"Varianza a posteriori (sigma_p_sq): 3.08\"\n\nGeneriamo una rappresentazione grafica della distribuzione a posteriori della media del IQ sulla base dei dati osservati, avendo assunto mu_0 = 100 e sigma_0 = 15 per la distribuzione a priori.\n\n# Definizione dei valori sull'asse x\nx &lt;- seq(mu_p - 4 * sigma_p, mu_p + 4 * sigma_p, length.out = 1000)\n\n# Calcolo della densità di probabilità\npdf &lt;- dnorm(x, mean = mu_p, sd = sigma_p)\n\n# Creazione del grafico\nggplot(data.frame(x = x, pdf = pdf), aes(x = x, y = pdf)) +\n  geom_line(color = \"blue\", size = 1) +\n  geom_area(aes(fill = \"Posterior\"), alpha = 0.2) +\n  scale_fill_manual(values = c(\"blue\")) +\n  labs(\n    title = \"Distribuzione a Posteriori\",\n    x = \"Media del Quoziente di Intelligenza\",\n    y = \"Densità di probabilità\"\n  )\n#&gt; Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#&gt; ℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\nL’analisi condotta mediante un modello bayesiano basato sulla distribuzione normale ha prodotto un risultato interessante: la media stimata della distribuzione a posteriori del QI si attesta a 89.36, un valore sensibilmente inferiore ai 100 punti previsti come media standard.\nTuttavia, per un’interpretazione completa di questo dato, è fondamentale adottare un approccio critico che consideri alcuni aspetti cruciali:\n\nLa media a posteriori è ottenuta aggregando i dati QI di 80 nazioni diverse. Questo processo può innescare un effetto di aggregazione, dove la media “smussata” risultante non rispecchia accuratamente la distribuzione del QI a livello individuale in ogni singola nazione. Di conseguenza, le differenze tra le nazioni in termini di QI medio e variabilità potrebbero essere mascherate da questa media aggregata.\nÈ importante sottolineare che la media a posteriori viene calcolata utilizzando dati non ponderati per ogni nazione. Ciò significa che nazioni con popolazioni più piccole, anche se con punteggi QI mediamente più alti o più bassi, hanno lo stesso impatto sulla media aggregata rispetto a nazioni con popolazioni più grandi. Questo aspetto potrebbe ulteriormente distorcere la rappresentazione della vera distribuzione globale del QI.\nLa deviazione osservata dalla media standard di 100 potrebbe non riflettere esclusivamente differenze nell’intelligenza media tra le nazioni, ma anche differenze nei contesti sanitari, sociologici e politici in cui i test sono stati somministrati. Fattori quali l’accesso all’istruzione, la qualità della nutrizione e l’esposizione a stimoli cognitivi possono influenzare i punteggi QI ottenuti e contribuire alla variabilità osservata tra le nazioni.\nInoltre, è fondamentale considerare la possibilità di un bias culturale intrinseco allo strumento stesso. I test del QI sono stati originariamente progettati per un contesto specifico (paese industrializzato di lingua inglese) e potrebbero non essere adatti o culturalmente sensibili a contesti differenti. Questo potrebbe portare a una sottostima dei punteggi QI in alcune nazioni e influenzare la media a posteriori aggregata.\n\nQuesti risultati evidenziano l’importanza di un’attenta considerazione dei fattori metodologici quando si interpretano dati di test del QI a livello trans-culturale. L’effetto di aggregazione, l’utilizzo di medie non ponderate, le differenze nei contesti e il potenziale bias culturale richiedono un’analisi più approfondita che consideri questi fattori e utilizzi metodi statistici più sofisticati per ottenere una comprensione più completa delle differenze nel QI tra le nazioni.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_conjugate_families_2.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/06_conjugate_families_2.html#riflessioni-conclusive",
    "title": "46  Distribuzioni coniugate (2)",
    "section": "\n46.4 Riflessioni Conclusive",
    "text": "46.4 Riflessioni Conclusive\nIn questo capitolo, abbiamo approfondito il meccanismo dell’aggiornamento bayesiano attraverso l’implementazione del modello normale-normale. Il processo inizia definendo una distribuzione a priori per \\(\\mu\\), specificata da una media \\(\\mu_0\\) e una varianza \\(\\sigma_0^2\\). Dopo l’acquisizione di nuovi dati, ipotizzando che seguano una distribuzione Normale con media campionaria \\(\\bar{y}\\) e varianza nota \\(\\sigma^2\\), implementiamo il teorema normale-normale per derivare la distribuzione a posteriori del parametro.\nLa media della distribuzione a posteriori, denotata come \\(\\mu_{\\text{post}}\\), si configura come una media ponderata tra la media a priori \\(\\mu_0\\) e la media campionaria \\(\\bar{y}\\), dove il peso assegnato a ciascuna media è determinato dalle rispettive varianze \\(\\sigma_0^2\\) e \\(\\sigma^2\\) della distribuzione a priori e dei dati osservati. Analogamente, la varianza a posteriori \\(\\sigma_{\\text{post}}^2\\) è determinata utilizzando un’espressione che incorpora entrambe le varianze.\nIn sintesi, l’adozione del modello normale-normale in un contesto bayesiano facilita il calcolo delle distribuzioni a posteriori, grazie alla scelta di una distribuzione a priori Normale che mantiene la proprietà di coniugatezza, semplificando così l’intero processo analitico.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_conjugate_families_2.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/06_conjugate_families_2.html#informazioni-sullambiente-di-sviluppo",
    "title": "46  Distribuzioni coniugate (2)",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.17.0      see_0.9.0        gridExtra_2.3    patchwork_1.3.0 \n#&gt;  [5] bayesplot_1.11.1 psych_2.4.12     scales_1.3.0     markdown_1.13   \n#&gt;  [9] knitr_1.49       lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1   \n#&gt; [13] dplyr_1.1.4      purrr_1.0.2      readr_2.1.5      tidyr_1.3.1     \n#&gt; [17] tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3       \n#&gt; [21] here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      shape_1.4.6.1     xfun_0.49         htmlwidgets_1.6.4\n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2      \n#&gt;  [9] generics_0.1.3    parallel_4.4.2    pan_1.9           pacman_0.5.1     \n#&gt; [13] pkgconfig_2.0.3   jomo_2.7-6        Matrix_1.7-1      lifecycle_1.0.4  \n#&gt; [17] compiler_4.4.2    farver_2.1.2      munsell_0.5.1     mnormt_2.1.1     \n#&gt; [21] codetools_0.2-20  htmltools_0.5.8.1 yaml_2.3.10       glmnet_4.1-8     \n#&gt; [25] nloptr_2.1.1      pillar_1.10.0     MASS_7.3-61       iterators_1.0.14 \n#&gt; [29] rpart_4.1.23      boot_1.3-31       foreach_1.5.2     mitml_0.4-5      \n#&gt; [33] nlme_3.1-166      tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4    \n#&gt; [37] labeling_0.4.3    splines_4.4.2     rprojroot_2.0.4   fastmap_1.2.0    \n#&gt; [41] grid_4.4.2        colorspace_2.1-1  cli_3.6.3         magrittr_2.0.3   \n#&gt; [45] survival_3.8-3    broom_1.0.7       withr_3.0.2       backports_1.5.0  \n#&gt; [49] timechange_0.3.0  rmarkdown_2.29    nnet_7.3-19       lme4_1.1-35.5    \n#&gt; [53] hms_1.1.3         evaluate_1.0.1    rlang_1.1.4       Rcpp_1.0.13-1    \n#&gt; [57] glue_1.8.0        minqa_1.2.8       jsonlite_1.8.9    R6_2.5.1",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_conjugate_families_2.html#bibliografia",
    "href": "chapters/bayesian_inference/06_conjugate_families_2.html#bibliografia",
    "title": "46  Distribuzioni coniugate (2)",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGill, J. (2015). Bayesian methods: A social and behavioral sciences approach (3rd Edition). Chapman; Hall/CRC.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_summary_posterior.html",
    "href": "chapters/bayesian_inference/07_summary_posterior.html",
    "title": "47  Sintesi a posteriori",
    "section": "",
    "text": "47.1 Introduzione\nIn questo capitolo, concentriamo la nostra attenzione sulla sintesi dell’informazione racchiusa nella distribuzione a posteriori, la quale rappresenta il nostro livello di incertezza riguardo al parametro o ai parametri incogniti oggetto dell’inferenza.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_summary_posterior.html#riepilogo-numerico",
    "href": "chapters/bayesian_inference/07_summary_posterior.html#riepilogo-numerico",
    "title": "47  Sintesi a posteriori",
    "section": "\n47.2 Riepilogo numerico",
    "text": "47.2 Riepilogo numerico\nLa distribuzione a posteriori contiene in sé tutte le informazioni disponibili sui potenziali valori del parametro. Nel caso di un parametro unidimensionale o bidimensionale, possiamo rappresentare la distribuzione a posteriori mediante un grafico \\(p(\\theta \\mid y)\\).\nTuttavia, quando ci troviamo di fronte a vettori di parametri con più di due dimensioni, risulta vantaggioso eseguire una sintesi numerica della distribuzione a posteriori. Possiamo distinguere due forme di sintesi numerica della distribuzione a posteriori:\n\nStima puntuale;\nIntervallo di credibilità.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_summary_posterior.html#stima-puntuale",
    "href": "chapters/bayesian_inference/07_summary_posterior.html#stima-puntuale",
    "title": "47  Sintesi a posteriori",
    "section": "\n47.3 Stima puntuale",
    "text": "47.3 Stima puntuale\nNel contesto dell’inferenza bayesiana, il processo di stima del valore più credibile del parametro \\(\\theta\\) tramite la distribuzione a posteriori si avvale di tre statistiche: la moda, la mediana e la media, la cui scelta è guidata dalla forma della distribuzione a posteriori. Queste statistiche sono utilizzate per ottenere una stima puntuale della tendenza centrale della distribuzione a posteriori, che a sua volta fornisce il “valore più credibile” del parametro. Questo valore rappresenta la stima a cui attribuiamo il massimo grado di fiducia soggettiva, basandoci sui dati osservati e sulle nostre credenze a priori.\n\n\nModa (Massimo a posteriori, MAP):\nLa moda rappresenta il valore più probabile di un parametro, ovvero quello che massimizza la distribuzione a posteriori. Questo valore è noto come “massimo a posteriori” (MAP). La stima MAP prende origine dalla stima di massima verosimiglianza (MLE), che cerca il valore di \\(\\theta\\), denotato come \\(\\hat{\\theta}_{ML}\\), che massimizza la funzione di verosimiglianza \\(L(\\theta \\mid y)\\):\n\n\n\\[\n\\hat{\\theta}_{ML} = \\arg \\max_\\theta L(\\theta \\mid y).\n\\]\nNell’inferenza bayesiana, \\(\\theta\\) è considerato una variabile casuale, e si specifica una distribuzione a priori su \\(\\theta\\) per riflettere l’incertezza sul suo valore. Integrando l’informazione a priori nella funzione di verosimiglianza, si ottiene la formula per la stima MAP:\n\\[\n\\hat{\\theta}_{MAP} = \\arg \\max_\\theta L(\\theta \\mid y)p(\\theta).\n\\]\nQuesta formula evidenzia che la stima MAP corrisponde al valore che massimizza la densità a posteriori di \\(\\theta\\) dati i dati osservati \\(y\\), ovvero il valore che rappresenta la moda della distribuzione a posteriori.\nSebbene il concetto di MAP sia intuitivo, presenta diversi problemi che ne limitano l’uso nella pratica.\nLa prima difficoltà è di tipo computazionale: con i metodi MCMC comunemente utilizzati per stimare le distribuzioni a posteriori, è molto difficile individuare con precisione la posizione esatta del MAP nello spazio delle distribuzioni posteriori.\nIl secondo problema è legato all’uso dell’inferenza bayesiana in modelli complessi e in situazioni non asintotiche. In questi casi, la verosimiglianza o la distribuzione a posteriori possono avere forme irregolari o non normali. Se la distribuzione a posteriori è molto asimmetrica, il MAP potrebbe non rappresentare adeguatamente dove si concentra la maggior parte della probabilità. Di conseguenza, il MAP non sempre fornisce un’idea accurata del comportamento complessivo della distribuzione a posteriori.\n\n\nMedia a posteriori:\n\nLa media a posteriori è il valore atteso del parametro \\(\\theta\\), calcolato sulla base della distribuzione a posteriori. In termini matematici, nel caso continuo, è espressa dalla formula:\n\\[\nE(\\theta \\mid y) = \\int_{-\\infty}^{\\infty} \\theta \\, p(\\theta \\mid y) \\, d\\theta.\n\\]\n\n\nMediana:\n\nLa mediana è il valore del parametro per cui il 50% della massa di probabilità a posteriori si distribuisce equamente a sinistra e a destra. È una misura robusta della tendenza centrale, particolarmente utile in presenza di distribuzioni asimmetriche o multimodali, dove la moda potrebbe non fornire una stima accurata del valore più probabile del parametro.\nPer valutare l’incertezza associata al parametro \\(\\theta\\), è utile calcolare la varianza a posteriori. Questa varianza è basata sulla tendenza centrale definita dalla media a posteriori, e la sua radice quadrata fornisce la deviazione standard a posteriori, che misura l’incertezza a posteriori relativa a \\(\\theta\\), espressa nelle stesse unità di misura dei dati. La formula per la varianza a posteriori è data da:\n\\[\nV(\\theta|y) = E[((\\theta - E[(\\theta|y)])^2 |y) = \\int_{-\\infty}^{\\infty} (\\theta - E[\\theta | y])^2 p(\\theta | y) d\\theta = E[\\theta^2 |y] - E[\\theta|y]^2.\n\\]\nIn sintesi, la media, la moda e la mediana a posteriori, insieme alla varianza a posteriori, forniscono una descrizione comprensiva del comportamento della distribuzione a posteriori di \\(\\theta\\), permettendoci di derivare stime puntuali e misurare l’incertezza associata a \\(\\theta\\) in modo informativo.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_summary_posterior.html#intervallo-di-credibilità",
    "href": "chapters/bayesian_inference/07_summary_posterior.html#intervallo-di-credibilità",
    "title": "47  Sintesi a posteriori",
    "section": "\n47.4 Intervallo di credibilità",
    "text": "47.4 Intervallo di credibilità\nNell’inferenza bayesiana, l’intervallo di credibilità è uno strumento utilizzato per definire un intervallo che contiene una determinata percentuale della massa della distribuzione a posteriori del parametro \\(\\theta\\). Questo intervallo riflette l’incertezza associata alla stima del parametro: un intervallo più ampio suggerisce una maggiore incertezza. Lo scopo principale dell’intervallo di credibilità è fornire una misura quantitativa dell’incertezza riguardante \\(\\theta\\).\nA differenza degli intervalli di confidenza frequentisti, non esiste un unico intervallo di credibilità per un dato livello di confidenza \\((1 - \\alpha) \\cdot 100\\%\\). In effetti, è possibile costruire un numero infinito di tali intervalli. Per questo motivo, è necessario stabilire criteri aggiuntivi per selezionare l’intervallo di credibilità più appropriato. Tra le opzioni più comuni ci sono l’intervallo di credibilità simmetrico e l’intervallo di massima densità posteriore (HPD).\n\n\nIntervallo di Credibilità Simmetrico:\n\nQuesto tipo di intervallo è centrato rispetto al punto di stima puntuale. Se \\(\\hat{\\theta}\\) rappresenta la stima del parametro, l’intervallo simmetrico avrà la forma \\((\\hat{\\theta} - a, \\hat{\\theta} + a)\\), dove \\(a\\) è un valore positivo scelto in modo tale che la massa totale inclusa sia pari a \\((1 - \\alpha)\\). Più formalmente, un intervallo di credibilità simmetrico al livello \\(\\alpha\\) può essere espresso come:\n\\[\nI_{\\alpha} = [q_{\\alpha/2}, q_{1 - \\alpha/2}],\n\\]\ndove \\(q_z\\) rappresenta il quantile \\(z\\) della distribuzione a posteriori. Ad esempio, un intervallo di credibilità simmetrico al 94% sarà:\n\\[\nI_{0.06} = [q_{0.03}, q_{0.97}],\n\\]\ndove il 3% della massa a posteriori si trova in ciascuna delle due code della distribuzione.\n\n\nIntervallo di Credibilità Più Stretto (Intervallo di Massima Densità Posteriore, HPD):\n\nL’intervallo di massima densità posteriore (HPD) è l’intervallo più stretto possibile che contiene il \\((1 - \\alpha) \\cdot 100\\%\\) della massa a posteriori. A differenza dell’intervallo simmetrico, l’HPD include tutti i valori di \\(\\theta\\) che hanno la maggiore densità a posteriori. Per costruirlo, si disegna una linea orizzontale sulla distribuzione a posteriori e si regola l’altezza della linea in modo che l’area sotto la curva corrisponda a \\((1 - \\alpha)\\). L’HPD risulta essere il più stretto tra tutti gli intervalli possibili per lo stesso livello di confidenza. Nel caso di una distribuzione a posteriori unimodale e simmetrica, l’HPD coincide con l’intervallo di credibilità simmetrico.\n\n47.4.1 Interpretazione\nIl calcolo degli intervalli di credibilità, in particolare dell’intervallo di massima densità posteriore (HPD), richiede spesso l’uso di software statistici avanzati. Questo perché determinare manualmente tali intervalli può essere complicato, soprattutto nei modelli bayesiani con distribuzioni posteriori complesse o quando sono necessarie simulazioni numeriche per stimare la distribuzione a posteriori.\nUn aspetto cruciale dell’inferenza bayesiana riguarda l’interpretazione dell’incertezza. Nel contesto frequentista, si considera il parametro, come ad esempio la media della popolazione \\(\\mu\\), come un valore fisso ma sconosciuto. L’inferenza frequentista si basa sull’immaginare un numero infinito di campioni ripetuti dalla popolazione. Per ogni campione, si può calcolare una media campionaria \\(\\bar{x}\\) e formare un intervallo di confidenza al \\(100(1-\\alpha)\\%\\). L’interpretazione corretta in termini frequentisti è che, nel lungo periodo, il \\(100(1-\\alpha)\\%\\) degli intervalli di confidenza costruiti con questo metodo conterrà il vero valore del parametro \\(\\mu\\). Tuttavia, per un singolo intervallo calcolato, la probabilità che contenga effettivamente \\(\\mu\\) è o 0 o 1, poiché \\(\\mu\\) è considerato un valore fisso.\nNel framework bayesiano, invece, il parametro è trattato come una variabile aleatoria con una distribuzione di probabilità. Campionando dalla distribuzione a posteriori dei parametri, possiamo ottenere quantili che ci permettono di calcolare direttamente la probabilità che un parametro rientri in un determinato intervallo. Ad esempio, un intervallo di credibilità al 95% indica che c’è una probabilità del 95% che il parametro sia contenuto all’interno di quell’intervallo, data l’evidenza osservata. Questa interpretazione differisce profondamente da quella frequentista e risulta più intuitiva, poiché riflette direttamente il grado di incertezza che abbiamo riguardo al parametro.\nIn sintesi, mentre l’intervallo di confidenza frequentista riguarda la ripetizione ipotetica del campionamento, l’intervallo di credibilità bayesiano fornisce una misura diretta dell’incertezza attuale sul valore di un parametro, basata sui dati osservati e sulle informazioni a priori. Questo approccio è spesso considerato più vicino al senso comune quando si tratta di interpretare la probabilità associata ai parametri.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_summary_posterior.html#verifica-di-ipotesi-bayesiana",
    "href": "chapters/bayesian_inference/07_summary_posterior.html#verifica-di-ipotesi-bayesiana",
    "title": "47  Sintesi a posteriori",
    "section": "\n47.5 Verifica di ipotesi bayesiana",
    "text": "47.5 Verifica di ipotesi bayesiana\nL’inferenza bayesiana può essere applicata anche nel contesto della verifica di ipotesi, in un approccio noto come verifica di ipotesi bayesiana. In questo tipo di inferenza, l’obiettivo è valutare la plausibilità che un parametro \\(\\theta\\) assuma valori all’interno di un determinato intervallo. Ad esempio, possiamo voler sapere quanto è probabile che \\(\\theta\\) sia maggiore di 0.5 o che rientri in un intervallo specifico, come [0.5, 1.0].\nIn questo approccio, si calcola la probabilità a posteriori che \\(\\theta\\) si trovi all’interno dell’intervallo di interesse. Questa probabilità viene ottenuta integrando la distribuzione a posteriori su tale intervallo. Quindi, invece di rifiutare o accettare un’ipotesi come nel test di ipotesi frequentista, la verifica di ipotesi bayesiana fornisce una misura diretta della probabilità che un parametro rientri in un intervallo specifico, dato l’evidenza osservata e le informazioni a priori.\nIn altre parole, questo approccio consente di quantificare la nostra incertezza rispetto all’affermazione che \\(\\theta\\) rientri in un certo intervallo, fornendo una probabilità che rappresenta direttamente la plausibilità di quell’ipotesi.\n\nEsempio 47.1 Per illustrare l’approccio bayesiano, consideriamo i dati relativi ai punteggi del BDI-II (Beck Depression Inventory - Second Edition) di 30 soggetti clinici, come riportato nello studio condotto da Zetsche et al. (2019). Il BDI-II è uno strumento per valutare la gravità dei sintomi depressivi.\nI punteggi del BDI-II per i 30 soggetti sono:\n\n# Dati del BDI-II\nbdi &lt;- c(\n  26, 35, 30, 25, 44, 30, 33, 43, 22, 43, \n  24, 19, 39, 31, 25, 28, 35, 30, 26, 31, \n  41, 36, 26, 35, 33, 28, 27, 34, 27, 22\n)\nbdi\n#&gt;  [1] 26 35 30 25 44 30 33 43 22 43 24 19 39 31 25 28 35 30 26 31 41 36 26 35\n#&gt; [25] 33 28 27 34 27 22\n\nUn punteggio BDI-II \\(\\geq 30\\) indica un livello grave di depressione. Nel nostro campione, 17 pazienti su 30 manifestano un livello grave:\n\n# Conteggio di depressione grave\nsum(bdi &gt;= 30)\n#&gt; [1] 17\n\n\n47.5.1 Stima della Distribuzione a Posteriori\nSupponiamo di voler stimare la probabilità \\(\\theta\\) di depressione grave nei pazienti clinici utilizzando una distribuzione a priori \\(Beta(8, 2)\\). I dati possono essere visti come una sequenza di prove Bernoulliane indipendenti, dove la presenza di depressione grave è un “successo”. La verosimiglianza è quindi binomiale con parametri \\(n = 30\\) e \\(y = 17\\).\nCon una distribuzione a priori \\(Beta(8, 2)\\), la distribuzione a posteriori di \\(\\theta\\) sarà:\n\\[\n\\text{Beta}(\\alpha = 8 + 17, \\beta = 2 + 30 - 17) = \\text{Beta}(25, 15).\n\\]\n\n47.5.1.1 Tracciamo la Distribuzione a Posteriori\n\n# Parametri della distribuzione Beta\nalpha &lt;- 25\nbeta &lt;- 15\n\n# Calcolo della densità per valori di theta\ntheta &lt;- seq(0, 1, length.out = 200)\nposterior_density &lt;- dbeta(theta, alpha, beta)\n\n# Grafico della distribuzione a posteriori\nggplot(data = data.frame(theta, posterior_density), aes(x = theta, y = posterior_density)) +\n  geom_line(color = \"blue\") +\n  labs(\n    title = \"Distribuzione a Posteriori Beta(25, 15)\",\n    x = expression(theta),\n    y = \"Densità di probabilità\"\n  ) \n\n\n\n\n\n\n\n\n47.5.2 Stime Puntuali\n\n\nMedia a Posteriori\nLa media della distribuzione a posteriori è calcolata come:\n\n\\[\n\\mathbb{E}(\\theta | y = 17) = \\frac{\\alpha}{\\alpha + \\beta} = \\frac{25}{25 + 15} = 0.625.\n\\]\nIn R:\n\n# Calcolo della media a posteriori\nposterior_mean &lt;- alpha / (alpha + beta)\nposterior_mean\n#&gt; [1] 0.625\n\n\n\nModa a Posteriori (MAP)\nLa moda della distribuzione a posteriori è:\n\n\\[\nMo(\\theta | y = 17) = \\frac{\\alpha - 1}{\\alpha + \\beta - 2} = \\frac{25 - 1}{25 + 15 - 2} = 0.6316.\n\\]\nIn R:\n\n# Calcolo della moda a posteriori\nposterior_mode &lt;- (alpha - 1) / (alpha + beta - 2)\nposterior_mode\n#&gt; [1] 0.632\n\n\n\nMediana a Posteriori\nLa mediana si ottiene utilizzando la funzione di distribuzione cumulativa inversa:\n\n\n# Calcolo della mediana a posteriori\nposterior_median &lt;- qbeta(0.5, alpha, beta)\nposterior_median\n#&gt; [1] 0.627\n\n\n47.5.3 Intervallo di Credibilità\nL’intervallo di credibilità simmetrico al 94% è dato dai percentili 3% e 97%:\n\n# Intervallo di credibilità simmetrico al 94%\ncred_interval &lt;- qbeta(c(0.03, 0.97), alpha, beta)\ncred_interval\n#&gt; [1] 0.478 0.761\n\nPossiamo interpretare questo intervallo come segue: c’è una certezza soggettiva del 94% che \\(\\theta\\) sia compreso tra 0.478 e 0.761.\n\n47.5.4 Verifica di Ipotesi Bayesiana\nInfine, calcoliamo la probabilità che \\(\\theta &gt; 0.5\\):\n\\[\nP(\\theta &gt; 0.5 | y = 17) = \\int_{0.5}^1 f(\\theta | y = 17) d\\theta.\n\\]\nIn R:\n\n# Probabilità P(theta &gt; 0.5)\nprob_theta_greater_0_5 &lt;- pbeta(0.5, alpha, beta, lower.tail = FALSE)\nprob_theta_greater_0_5\n#&gt; [1] 0.946\n\nIn conclusione, utilizzando un approccio bayesiano, abbiamo stimato la distribuzione a posteriori di \\(\\theta\\), ottenuto stime puntuali e costruito intervalli di credibilità. Abbiamo inoltre calcolato la probabilità che \\(\\theta\\) superi una soglia specifica, mostrando la flessibilità e l’interpretabilità delle analisi bayesiane.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_summary_posterior.html#sintesi-della-distribuzione-a-posteriori-questioni-multivariate",
    "href": "chapters/bayesian_inference/07_summary_posterior.html#sintesi-della-distribuzione-a-posteriori-questioni-multivariate",
    "title": "47  Sintesi a posteriori",
    "section": "\n47.6 Sintesi della distribuzione a posteriori: questioni multivariate",
    "text": "47.6 Sintesi della distribuzione a posteriori: questioni multivariate\nQuando si affronta un’analisi bayesiana con più parametri, la complessità aumenta. Le principali difficoltà riguardano le interazioni tra i parametri e il modo in cui queste influenzano le distribuzioni marginali. Questi fattori possono complicare notevolmente la sintesi della distribuzione a posteriori e, se non considerati attentamente, possono portare a interpretazioni errate.\n\n47.6.1 Correlazioni nascoste e distribuzioni marginali\nUn problema comune nelle analisi con più parametri è rappresentato dalle correlazioni tra i parametri. Le distribuzioni marginali a posteriori, spesso riportate nei riassunti statistici, possono essere molto fuorvianti se considerate isolatamente. Quando i parametri sono fortemente correlati, le distribuzioni marginali possono apparire piatte o poco informative, inducendo a pensare che non ci sia molta informazione nella verosimiglianza.\nTuttavia, le correlazioni tra parametri possono restringere notevolmente lo spazio delle combinazioni plausibili, escludendo vaste aree dello spazio dei parametri. Questo significa che, nonostante le marginali possano sembrare non informative, l’analisi congiunta dei parametri può rivelare una struttura sottostante che riduce l’incertezza su specifiche combinazioni. Pertanto, è essenziale esaminare le correlazioni congiunte tra i parametri per ottenere una visione più completa dell’incertezza.\nCon un numero maggiore di parametri, anche i grafici di correlazione bidimensionali possono diventare limitati, poiché potrebbero esistere correlazioni di ordine superiore che non emergono in rappresentazioni a due dimensioni.\n\n47.6.2 Correlazioni non lineari\nUn’altra difficoltà significativa riguarda le correlazioni non lineari tra i parametri. Quando queste correlazioni sono presenti, il massimo delle distribuzioni marginali non coincide necessariamente con il massimo della distribuzione congiunta. Per esempio, se due parametri presentano una correlazione complessa, come una forma a “banana”, il massimo delle distribuzioni marginali potrebbe trovarsi in una posizione diversa rispetto al massimo globale della distribuzione congiunta.\nQuesto fenomeno rende più difficile sintetizzare correttamente la distribuzione a posteriori. In tali casi, la stima del massimo a posteriori (MAP) o altri riassunti, come gli intervalli di credibilità (CI) o gli intervalli di massima densità a posteriori (HPD), calcolati sulle marginali, potrebbero essere fuorvianti. Quando la distribuzione a posteriori è asimmetrica nello spazio multivariato, le distribuzioni marginali non catturano adeguatamente le relazioni tra i parametri. Questa è una fonte comune di confusione, poiché si tende a sottovalutare l’importanza della struttura multivariata nella distribuzione a posteriori.\n\n47.6.3 Strategie per affrontare queste sfide\n\n\nConfronto tra distribuzioni predittive:\n\nConfrontare la distribuzione predittiva a priori con quella a posteriori offre una visione più completa della riduzione dell’incertezza.\nQuesto approccio è particolarmente utile in presenza di parametri multipli e correlazioni complesse, poiché la distribuzione predittiva a posteriori incorpora le interazioni tra i parametri, fornendo una rappresentazione più accurata della plausibilità dei diversi valori parametrici.\n\n\n\nAnalisi congiunta:\n\nEsaminare le distribuzioni congiunte dei parametri, oltre alle distribuzioni marginali.\nUtilizzare grafici di dispersione bivariati o multivariati per visualizzare le relazioni tra i parametri.\nTecniche avanzate di visualizzazione, come i pair plots o le heatmap, possono essere utili per esplorare relazioni in spazi ad alta dimensionalità.\n\n\n\nMisure di dipendenza:\n\nUtilizzare misure di dipendenza non lineare, come la correlazione di Spearman o l’informazione mutua, che possono catturare relazioni complesse che le misure lineari tradizionali potrebbero non rilevare.\n\n\n\nAnalisi di sensibilità:\n\nCondurre un’analisi di sensibilità per valutare come i cambiamenti in un parametro influenzano gli altri parametri e le previsioni del modello. Questo permette di capire meglio le relazioni tra i parametri e il loro impatto sulle inferenze.\n\n\n\nTecniche di riduzione della dimensionalità:\n\nQuando ci sono molti parametri, l’uso di metodi come l’analisi delle componenti principali (PCA) può aiutare a identificare strutture latenti e ridurre la complessità del problema, facilitando l’interpretazione dei risultati.\n\n\n\nIn sintesi, l’analisi multivariata in un contesto bayesiano richiede particolare attenzione nella sintesi delle distribuzioni a posteriori. Le distribuzioni marginali possono fornire informazioni utili, ma spesso nascondono importanti correlazioni e strutture di dipendenza tra i parametri. Un’analisi completa dovrebbe combinare l’esame delle marginali con una valutazione attenta delle relazioni congiunte tra i parametri, utilizzando tecniche di visualizzazione e misure di dipendenza adeguate. Questo approccio integrato permette di comprendere più a fondo la distribuzione a posteriori e di trarre inferenze più robuste e accurate.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_summary_posterior.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/07_summary_posterior.html#riflessioni-conclusive",
    "title": "47  Sintesi a posteriori",
    "section": "\n47.7 Riflessioni Conclusive",
    "text": "47.7 Riflessioni Conclusive\nIn conclusione, la distribuzione a posteriori rappresenta la nostra conoscenza aggiornata sui parametri sconosciuti. L’impiego delle statistiche descrittive e l’analisi degli intervalli di credibilità contribuiscono a tracciare un quadro completo della distribuzione a posteriori e delle nostre inferenze riguardo al parametro di interesse.\nLe stime puntuali, ottenute attraverso statistiche descrittive come media, mediana o moda a posteriori, offrono una singola valutazione numerica del parametro ignoto. Gli intervalli di credibilità forniscono un intervallo di valori all’interno del quale si ritiene, con un certo grado di probabilità soggettiva, che il parametro incognito possa rientrare. Questi intervalli quantificano l’incertezza associata al parametro e consentono di esprimere il livello di fiducia soggettiva riguardo ai possibili valori del parametro dopo l’analisi dei dati. Abbiamo inoltre esaminato il concetto di test di ipotesi bayesiano, il quale può essere condotto agevolmente calcolando l’area appropriata sotto la distribuzione a posteriori, in accordo con l’ipotesi in questione.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_summary_posterior.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/07_summary_posterior.html#informazioni-sullambiente-di-sviluppo",
    "title": "47  Sintesi a posteriori",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.17.0      see_0.9.0        gridExtra_2.3    patchwork_1.3.0 \n#&gt;  [5] bayesplot_1.11.1 psych_2.4.12     scales_1.3.0     markdown_1.13   \n#&gt;  [9] knitr_1.49       lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1   \n#&gt; [13] dplyr_1.1.4      purrr_1.0.2      readr_2.1.5      tidyr_1.3.1     \n#&gt; [17] tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3       \n#&gt; [21] here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      shape_1.4.6.1     xfun_0.49         htmlwidgets_1.6.4\n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2      \n#&gt;  [9] generics_0.1.3    parallel_4.4.2    pan_1.9           pacman_0.5.1     \n#&gt; [13] pkgconfig_2.0.3   jomo_2.7-6        Matrix_1.7-1      lifecycle_1.0.4  \n#&gt; [17] compiler_4.4.2    farver_2.1.2      munsell_0.5.1     mnormt_2.1.1     \n#&gt; [21] codetools_0.2-20  htmltools_0.5.8.1 yaml_2.3.10       glmnet_4.1-8     \n#&gt; [25] nloptr_2.1.1      pillar_1.10.0     MASS_7.3-61       iterators_1.0.14 \n#&gt; [29] rpart_4.1.23      boot_1.3-31       foreach_1.5.2     mitml_0.4-5      \n#&gt; [33] nlme_3.1-166      tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4    \n#&gt; [37] labeling_0.4.3    splines_4.4.2     rprojroot_2.0.4   fastmap_1.2.0    \n#&gt; [41] grid_4.4.2        colorspace_2.1-1  cli_3.6.3         magrittr_2.0.3   \n#&gt; [45] survival_3.8-3    broom_1.0.7       withr_3.0.2       backports_1.5.0  \n#&gt; [49] timechange_0.3.0  rmarkdown_2.29    nnet_7.3-19       lme4_1.1-35.5    \n#&gt; [53] hms_1.1.3         evaluate_1.0.1    rlang_1.1.4       Rcpp_1.0.13-1    \n#&gt; [57] glue_1.8.0        minqa_1.2.8       jsonlite_1.8.9    R6_2.5.1",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_summary_posterior.html#bibliografia",
    "href": "chapters/bayesian_inference/07_summary_posterior.html#bibliografia",
    "title": "47  Sintesi a posteriori",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nZetsche, U., Buerkner, P.-C., & Renneberg, B. (2019). Future expectations in clinical depression: biased or realistic? Journal of Abnormal Psychology, 128(7), 678–688.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html",
    "title": "48  L’influenza della distribuzione a priori",
    "section": "",
    "text": "48.1 Introduzione\nConsideriamo un semplice scenario medico: un paziente si presenta dal dottore con un mal di testa. Il medico, per formulare una diagnosi accurata, dovrà considerare diversi fattori. Possiamo immaginare due medici con approcci leggermente differenti:\nQuale dei due medici è in grado di fornire una diagnosi più precisa? La risposta risiede nel concetto di probabilità a priori (o semplicemente prior), ovvero le credenze che un individuo ha su un evento prima di osservare nuovi dati.\nNel contesto medico, la storia clinica del paziente rappresenta una preziosa fonte di informazioni a priori. Conoscere gli antecedenti sanitari di un individuo permette al medico di formulare ipotesi più plausibili sulla causa del mal di testa. In termini bayesiani, i priori agiscono come una sorta di “lente” attraverso cui vengono interpretati i nuovi dati (in questo caso, i risultati dei test).\nQuando prendiamo decisioni nella vita quotidiana, utilizziamo costantemente le nostre conoscenze pregresse per interpretare nuove informazioni. Ad esempio, se vediamo una persona che indossa un camice bianco in un ospedale, inferiamo che si tratti di un medico, basandoci sulla nostra esperienza e sulle associazioni mentali che abbiamo costruito nel tempo. Questo processo di inferenza è molto simile a quello che avviene nell’aggiornamento bayesiano.\nLa scelta dei priori ha un impatto fondamentale sulla qualità delle inferenze che possiamo trarre dai dati. Questo capitolo si focalizza sull’importanza e sulle implicazioni che derivano dalla scelta dei priori sul processo di aggiornamento bayesiano. Per illustrare questi concetti, esamineremo alcuni esempi discussi da Johnson et al. (2022).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#introduzione",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#introduzione",
    "title": "48  L’influenza della distribuzione a priori",
    "section": "",
    "text": "Medico 1: Si basa principalmente sui risultati di test specifici, senza considerare una storia clinica pregressa del paziente.\n\nMedico 2: Oltre ai test, tiene conto della storia clinica del paziente, cercando di individuare eventuali fattori di rischio o condizioni preesistenti che potrebbero essere correlate al mal di testa.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#la-distribuzione-a-priori",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#la-distribuzione-a-priori",
    "title": "48  L’influenza della distribuzione a priori",
    "section": "\n48.2 La Distribuzione a Priori",
    "text": "48.2 La Distribuzione a Priori\nLa distribuzione a priori gioca un ruolo centrale nell’approccio bayesiano, poiché rappresenta le nostre conoscenze pregresse o le ipotesi sui parametri del modello prima di osservare i dati. Questo concetto è fondamentale perché permette di integrare le informazioni disponibili in precedenza con i dati osservati, fornendo così una stima più precisa e robusta dei parametri. Le distribuzioni a priori possono variare a seconda del grado di certezza che si attribuisce ai valori dei parametri.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#tipologie-di-distribuzioni-a-priori",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#tipologie-di-distribuzioni-a-priori",
    "title": "48  L’influenza della distribuzione a priori",
    "section": "\n48.3 Tipologie di Distribuzioni a Priori",
    "text": "48.3 Tipologie di Distribuzioni a Priori\nLa scelta della distribuzione a priori (nota come elicitazione della prior) è uno dei passaggi cruciali nell’analisi bayesiana ed è spesso vista come la fase più controversa, poiché è considerata “soggettiva”. Tuttavia, è importante sottolineare che la scelta della prior non è necessariamente soggettiva. A differenza dell’approccio frequentista, l’approccio bayesiano incoraggia la raccolta e l’integrazione di tutte le informazioni conosciute sul parametro in anticipo. Questo può essere fatto in modo oggettivo, basandosi su evidenze pregresse o raccomandazioni consolidate.\nEsistono tre principali categorie di distribuzioni a priori.\n\nDistribuzioni a Priori Non Informative. Le distribuzioni a priori non informative sono caratterizzate da una totale mancanza di conoscenza pregressa e assegnano la stessa credibilità a tutti i valori dei parametri. Un esempio comune di distribuzione a priori non informativa è la distribuzione uniforme, basata sul “Principio della Ragione Insufficiente” formulato da Laplace. Secondo questo principio, in assenza di evidenze rilevanti pregresse, tutte le possibili configurazioni dei parametri sono considerate equiprobabili.\n\nDistribuzioni a Priori Debolmente Informative. Le distribuzioni a priori debolmente informative consentendo di integrare una quantità limitata di informazioni pregresse nei modelli statistici. Queste distribuzioni sono progettate per riflettere le nostre assunzioni su quali possono essere i valori “ragionevoli” dei parametri del modello, tenendo conto delle incertezze presenti nell’analisi. L’uso di informazioni a priori debolmente informative può contribuire a migliorare la stabilità dell’analisi senza influenzare in modo significativo le conclusioni derivate da essa.\nLe distribuzioni a priori debolmente informative hanno la caratteristica di non “spostare” in modo significativo la distribuzione a posteriori in una direzione specifica. In altre parole, sono centrate su valori “neutri” dei parametri. Ad esempio, quando si trattano parametri che possono assumere valori positivi o negativi, la distribuzione a priori debolmente informativa potrebbe essere centrata sullo zero. Nel caso di parametri che rappresentano proporzioni, essa potrebbe essere centrata su 0.5.\nTuttavia, ciò che rende queste distribuzioni debolmente informative è la specifica definizione di un intervallo “plausibile” di valori dei parametri. Questo intervallo indica quali valori dei parametri sono considerati plausibili e quali sono invece considerati implausibili. Ad esempio, una distribuzione a priori debolmente informativa potrebbe suggerire che valori estremamente grandi o estremamente bassi dei parametri sono poco plausibili, concentrandosi su un intervallo più stretto di valori considerati ragionevoli.\nIn sintesi, le distribuzioni a priori debolmente informative sono utilizzate per incorporare informazioni pregresse limitate nei modelli bayesiani, contribuendo a stabilizzare le stime dei parametri senza influenzare in modo significativo le conclusioni derivate dai dati. Queste distribuzioni definiscono un intervallo plausibile di valori dei parametri, aiutando a guidare l’analisi verso soluzioni più verosimili senza imporre vincoli eccessivi sui risultati.\n\n\nDistribuzioni a Priori Informativa. Le conoscenze pregresse, acquisite attraverso ricerche precedenti, pareri esperti o una combinazione di entrambi, possono essere meticolosamente integrate nel processo di analisi mediante l’incorporazione nelle distribuzioni a priori. Queste distribuzioni sono comunemente conosciute come distribuzioni a priori informative. Esse rappresentano un mezzo per codificare in modo sistematico informazioni concrete e rilevanti che possono avere un notevole impatto sull’analisi statistica, fornendo una solida base di conoscenza su cui fondare l’inferenza bayesiana.\nLe distribuzioni a priori informative possono derivare da una vasta gamma di fonti, comprese ricerche pregresse, pareri di esperti nel campo e altre fonti affidabili. Questo approccio offre un metodo strutturato per integrare in modo coerente le conoscenze pregresse nel processo di analisi statistica. L’incorporazione di queste informazioni aggiuntive contribuisce notevolmente a migliorare la robustezza e l’accuratezza delle conclusioni derivate dai dati, fornendo una solida base empirica su cui basare le stime dei parametri del modello e le decisioni basate sull’analisi bayesiana.\nNell’ambito della ricerca psicologica, l’utilizzo di distribuzioni a priori informative è attualmente poco diffuso, tuttavia emergono segnali che all’interno della comunità statistica sta crescendo l’interesse per questa pratica, considerandola come un avanzamento promettente nel campo della data science.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#limportanza-della-prior-in-base-ai-dati",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#limportanza-della-prior-in-base-ai-dati",
    "title": "48  L’influenza della distribuzione a priori",
    "section": "\n48.4 L’importanza della Prior in base ai Dati",
    "text": "48.4 L’importanza della Prior in base ai Dati\nUn aspetto cruciale da considerare è che l’influenza della prior diminuisce all’aumentare del numero di dati osservati. In altre parole, con un numero infinito di dati, la verosimiglianza diventa estremamente precisa (o “affilata”), rendendo la scelta della prior irrilevante, a patto che la prior non assegni probabilità zero a regioni dello spazio parametri dove la verosimiglianza è positiva.\nTuttavia, la prior assume un’importanza fondamentale quando si lavora con dataset di piccole dimensioni. In questi casi, la distribuzione a priori può avere un’influenza significativa sulle stime, poiché i dati da soli non sono sufficienti per ottenere stime precise.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#effetti-del-cambiamento-di-scala-dei-parametri",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#effetti-del-cambiamento-di-scala-dei-parametri",
    "title": "48  L’influenza della distribuzione a priori",
    "section": "\n48.5 Effetti del Cambiamento di Scala dei Parametri",
    "text": "48.5 Effetti del Cambiamento di Scala dei Parametri\nUn altro aspetto da tenere a mente è che le priors possono cambiare quando si modificano le scale dei parametri. Se un parametro viene riscalato, ad esempio passando da metri a chilometri, anche la prior deve essere riscalata di conseguenza per mantenere la coerenza dell’inferenza.\n\n48.5.1 Scala e invariabilità della scelta delle distribuzioni a priori\nLa scelta delle distribuzioni a priori non informative non è sempre banale e non può sempre essere rappresentata da una prior piatta. Per capire questo concetto, è fondamentale comprendere il ruolo della scala. Vediamo un esempio per chiarire meglio questo aspetto.\nImmaginiamo di avere un dataset che contiene la media dei diametri di alcuni alberi, e vogliamo stimare la media di questi diametri utilizzando un metodo bayesiano. Prima di osservare i dati, dobbiamo specificare la nostra distribuzione a priori, poiché non vogliamo che i dati influenzino la nostra scelta. Supponiamo di scegliere una distribuzione a priori piatta tra 1 cm e 10 cm, per evitare di introdurre bias:\n\n# Creazione di un vettore da 1 a 5\nvalori &lt;- 1:5\n# Creazione di un vettore di 5 elementi, tutti uguali a 1/5\npesoPrior &lt;- rep(1/5, 5)\n# Mostra i risultati\npesoPrior\n#&gt; [1] 0.2 0.2 0.2 0.2 0.2\n\nIn questo caso, stiamo assegnando la stessa probabilità a ciascun diametro compreso tra 1 e 10 cm, senza dare più peso a un valore rispetto a un altro. Questa sembra una scelta ragionevole e “non informativa”, poiché non stiamo preferendo nessun diametro in particolare.\nOra, supponiamo di voler modificare leggermente la nostra analisi e di misurare la grandezza degli alberi in termini di area basale (cioè la sezione trasversale dell’albero alla base), che è proporzionale al quadrato del diametro (cioè \\(x^2\\)). Poiché abbiamo già specificato la nostra distribuzione a priori in termini di diametro, dovremmo trasformare questa distribuzione in modo coerente con la nuova scala (area basale).\nIl problema che emerge è il seguente: quando riscaliamo l’asse \\(x\\) per riflettere l’area basale (cioè, passiamo da cm a cm\\(^2\\)), i valori più grandi diventano più ampi (poiché l’area cresce con il quadrato del diametro), mentre i valori più piccoli diventano più stretti. Se vogliamo mantenere la stessa distribuzione a priori in termini di probabilità, dobbiamo modificare il peso di ciascun valore.\nDi conseguenza, una distribuzione a priori che inizialmente era piatta (uguale per tutti i valori di diametro) non rimane piatta dopo la trasformazione in area basale. I valori più grandi ora hanno un peso minore, mentre i valori più piccoli hanno un peso maggiore. Questo dimostra che una distribuzione a priori non può essere piatta per tutte le possibili trasformazioni dei parametri.\n\n48.5.2 Il concetto di invariabilità della scala\nUna delle chiavi per definire correttamente le distribuzioni a priori non informative è l’invariabilità rispetto alle trasformazioni dei parametri. Se possiamo scegliere liberamente come rappresentare i parametri (ad esempio, in termini di diametro o area basale), la nostra distribuzione a priori dovrebbe essere definita in modo che sia coerente indipendentemente dalla scala scelta.\n\n48.5.3 Attenzione alle trasformazioni dei parametri\nUn secondo messaggio importante riguarda la cautela nelle trasformazioni dei parametri nell’analisi bayesiana. Quando cambiamo i parametri del nostro modello, non stiamo semplicemente osservando un singolo valore, ma una distribuzione intera. La forma di questa distribuzione può cambiare notevolmente con la trasformazione dei parametri.\nAd esempio, se si sta conducendo uno studio psicologico e si vuole misurare un parametro legato alla gravità di un disturbo (ad esempio, la gravità della depressione su una scala numerica), e poi si decide di trasformare la scala in un’unità diversa (ad esempio, un punteggio quadratico per evidenziare differenze estreme), la distribuzione a priori che sembrava ragionevole prima della trasformazione potrebbe non esserlo più dopo. Questo significa che bisogna prestare attenzione a come si scelgono le priors e come queste si comportano sotto diverse rappresentazioni del problema.\nIn conclusione, la scelta delle distribuzioni a priori non può essere fatta superficialmente. Deve essere considerata con attenzione, tenendo conto delle possibili trasformazioni dei parametri e assicurandosi che le priors siano coerenti rispetto alla scala scelta. Questo rende evidente che le priors non informative non sono sempre piatte, e la loro scelta deve tenere conto della struttura del problema e delle variabili coinvolte.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#scelte-predefinite-per-le-distribuzioni-a-priori-non-informative",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#scelte-predefinite-per-le-distribuzioni-a-priori-non-informative",
    "title": "48  L’influenza della distribuzione a priori",
    "section": "\n48.6 Scelte predefinite per le distribuzioni a priori non informative",
    "text": "48.6 Scelte predefinite per le distribuzioni a priori non informative\nUna delle domande più ricorrenti nell’inferenza bayesiana riguarda la scelta delle distribuzioni a priori non informative. La risposta, però, è piuttosto complessa: non esiste una soluzione generalmente accettata. Questo è particolarmente importante perché, mentre le priors informative possono essere basate su conoscenze pregresse, una prior non informativa deve essere scelta con cura per evitare di influenzare eccessivamente i risultati.\nUna delle proposte più famose, che soddisfa molte delle proprietà desiderabili, è la prior di Jeffreys, definita come:\n\\[\np(\\phi) \\propto \\sqrt{ \\det (F(\\phi)) },\n\\]\ndove \\(F(\\phi)\\) è la matrice di informazione di Fisher, che misura quanto la verosimiglianza cambia quando variano i parametri. La prior di Jeffreys ha due caratteristiche fondamentali:\n\n\nInvarianza rispetto alla riscalatura dei parametri: Ciò significa che se trasformiamo la scala del parametro, la prior si adatta automaticamente, rimanendo coerente con il problema.\n\nProporzionalità all’influenza dei parametri sulla verosimiglianza: Parametri che influenzano maggiormente la verosimiglianza hanno una prior più informativa.\n\nQuesti aspetti sembrano coprire molti dei criteri comunemente accettati per la scelta delle distribuzioni a priori non informative. Tuttavia, la prior di Jeffreys presenta alcuni problemi nei modelli multivariati e gerarchici, il che limita la sua applicabilità come soluzione universale.\n\n48.6.1 Scelte predefinite comuni per le priors non informative\nNonostante le difficoltà legate alla prior di Jeffreys, sono emerse alcune scelte predefinite comuni per le priors non informative, basate su intuizioni derivanti proprio da questa distribuzione. Di seguito sono elencate alcune di queste scelte:\n\n\nParametri di scala (es. coefficiente angolare o intercetta in una regressione):\n\nPer i parametri di scala, che influenzano l’output in modo lineare, si utilizzano comunemente priors piatte o quasi piatte. Queste possono essere distribuzioni uniformi con limiti fissati o, più comunemente, una distribuzione normale ampia.\nUn esempio di prior modificata è l’uso di una normalità centrata su un valore neutro, come 0, per ottenere l’analogo bayesiano della regressione Lasso o Ridge, che introduce una penalizzazione sui parametri (Park & Casella, 2008; Kyung et al., 2010).\n\nSe questa penalizzazione è lieve, si parla di priors debolmente regolarizzanti.\nSe è forte, si parla di priors di riduzione (shrinkage), che possono essere fisse o adattative:\n\n\nShrinkage fisso: la forza della riduzione (ad es. controllata dalla deviazione standard nella prior normale) rimane costante.\n\nShrinkage adattativo: la prior di riduzione si adatta tramite un iperparametro (hyperprior), il che consente al modello di decidere autonomamente la forza della riduzione.\n\n\n\n\n\n\n\nParametri di varianza (es. la deviazione standard in una regressione lineare):\n\nPer i parametri di varianza, si utilizzano spesso priors che decrescono all’aumentare del valore. Un esempio classico è la prior di Jeffrey’s, che per la varianza assume la forma \\(1/x\\), oppure la distribuzione inversa-gamma, molto comune per via della sua proprietà di coniugazione, che semplifica il calcolo bayesiano.\n\n\n\nIperparametri di varianza nei modelli gerarchici:\n\nNei modelli gerarchici, gli iperparametri di varianza vengono trattati con priors decrescenti come l’inversa-gamma o la distribuzione half-t (Gelman, 2006). Queste priors sono progettate per gestire la varianza tra gruppi in modo efficace.\n\n\n\nDistribuzioni binomiali:\n\nPer una distribuzione binomiale, la prior di Jeffreys corrisponde a una distribuzione Beta(1/2, 1/2), che è considerata una buona scelta predefinita non informativa. Questo tipo di prior assegna un peso equo alle possibili probabilità di successo, riflettendo una distribuzione equilibrata senza favorire un particolare risultato.\n\n\n\n48.6.2 Attenzione alle trasformazioni dei parametri\nUn aspetto importante da considerare nell’uso delle priors non informative è che la loro forma può cambiare significativamente in seguito a trasformazioni dei parametri. Per esempio, passando dalla scala lineare alla scala quadratica di un parametro, la prior può assumere una forma diversa e introdurre involontariamente un bias. Pertanto, è essenziale prestare attenzione a come i parametri sono scalati e trasformati nel modello.\n\n48.6.3 Analisi di sensibilità\nInfine, quando si è incerti sulla scelta della prior, un buon approccio consiste nel condurre un’analisi di sensibilità. Questa tecnica prevede di variare la prior e osservare come ciò influenzi i risultati. Se i risultati sono robusti rispetto a diverse scelte di prior, ciò suggerisce che la prior scelta non sta influenzando in modo eccessivo l’inferenza finale. Questo è particolarmente utile nei casi in cui si dispone di pochi dati, situazione in cui la prior può avere un impatto maggiore.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#priori-coniugate",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#priori-coniugate",
    "title": "48  L’influenza della distribuzione a priori",
    "section": "\n48.7 Priori coniugate",
    "text": "48.7 Priori coniugate\nUna distribuzione a priori è detta coniugata rispetto a una funzione di verosimiglianza se la distribuzione a posteriori risultante ha la stessa forma funzionale della distribuzione a priori. In altre parole, la distribuzione a priori e quella a posteriori appartengono alla stessa famiglia di distribuzioni. Questo è particolarmente utile perché, quando si usano priori coniugate, si ottiene una distribuzione a posteriori che può essere espressa in forma chiusa, rendendo possibile risolverla analiticamente.\nUn esempio tipico è quello delle funzioni di verosimiglianza appartenenti alla famiglia esponenziale, per le quali esiste sempre una distribuzione a priori coniugata. Questo è uno dei motivi per cui le distribuzioni della famiglia esponenziale sono così rilevanti: in modelli semplici, l’uso di una prior coniugata consente di ottenere una soluzione analitica per la distribuzione a posteriori, noto come modello coniugato-esponenziale.\nTradizionalmente, si preferiva specificare priori coniugate quando possibile, proprio per la semplicità analitica che garantivano. Tuttavia, l’importanza delle priors coniugate è diminuita con l’evoluzione dei metodi di campionamento. Oggi, la maggior parte dei campionatori moderni (come i metodi MCMC) non richiede più la coniugazione per funzionare in modo efficiente, e l’uso di priors non coniugate è diventato comune senza compromettere la qualità delle stime.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#simulazioni",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#simulazioni",
    "title": "48  L’influenza della distribuzione a priori",
    "section": "\n48.8 Simulazioni",
    "text": "48.8 Simulazioni\nIn questa sezione, esploriamo come le distribuzioni a priori influenzano la distribuzione a posteriori attraverso una serie di simulazioni. La formula di Bayes, \\(p(\\theta \\mid y) \\propto p(\\theta) \\times p(y \\mid \\theta)\\), evidenzia come la distribuzione a posteriori sia il risultato della combinazione tra la distribuzione a priori e la funzione di verosimiglianza basata sui dati osservati. Se abbiamo le valutazioni puntuali della verosimiglianza e della distribuzione a priori, possiamo moltiplicarle punto per punto per ottenere la distribuzione a posteriori.\n\n48.8.1 Verosimiglianza Binomiale con Distribuzioni a Priori Arbitrari\nConsideriamo un caso in cui la verosimiglianza è binomiale, ma utilizziamo distribuzioni a priori non coniugate. Supponiamo che i dati consistano in 6 successi su 9 prove di tipo bernoulliano. Confronteremo l’effetto di tre distribuzioni a priori diverse sulla distribuzione a posteriori e analizzeremo come ciascuna influisce sull’inferenza finale.\n\n48.8.1.1 Creazione della Griglia e Calcolo della Verosimiglianza\nIniziamo definendo una griglia di valori per \\(\\theta\\) e calcolando la verosimiglianza a ciascun punto della griglia.\n\n# Dati\nsuccess &lt;- 6\ntosses &lt;- 9\n\n# Griglia di valori per theta\ngrid_points &lt;- 100\np_grid &lt;- seq(0, 1, length.out = grid_points)\n\n# Verosimiglianza binomiale\nlikelihood &lt;- dbinom(success, tosses, p_grid)\n\n\n48.8.1.2 Funzione per Calcolare e Visualizzare la Posteriori\nDefiniamo una funzione che calcola la distribuzione a posteriori in base alla verosimiglianza e al priore fornito. La funzione visualizza anche il priore, la verosimiglianza e la distribuzione a posteriori.\n\ncomputePosterior &lt;- function(likelihood, prior, p_grid) {\n  # Calcolo della distribuzione a posteriori non normalizzata\n  unstd_posterior &lt;- likelihood * prior\n  \n  # Normalizzazione\n  posterior &lt;- unstd_posterior / sum(unstd_posterior)\n  \n  # Visualizzazione\n  par(mfrow = c(1, 3))\n  plot(\n    p_grid, \n    prior, \n    type = \"l\", \n    main = \"Prior\", \n    xlab = expression(theta), \n    ylab = \"Densità\"\n  )\n  plot(\n    p_grid, \n    likelihood, \n    type = \"l\", \n    main = \"Likelihood\", \n    xlab = expression(theta), \n    ylab = \"Densità\"\n  )\n  plot(\n    p_grid, \n    posterior, \n    type = \"l\", \n    main = \"Posterior\", \n    xlab = expression(theta), \n    ylab = \"Densità\"\n  )\n  \n  return(posterior)\n}\n\n\n48.8.2 Esempio 1: Priore Uniforme\nIl nostro primo priore è una distribuzione uniforme: \\(p(\\theta) = 1\\). Questo riflette una completa mancanza di informazioni a priori sulla probabilità di successo \\(\\theta\\).\n\n# Priore uniforme\nprior1 &lt;- rep(1, grid_points)\n\n# Calcolo e visualizzazione della distribuzione a posteriori\nposterior1 &lt;- computePosterior(likelihood, prior1, p_grid)\n\n\n\n\n\n\n\nCome previsto, la distribuzione a posteriori coincide con la verosimiglianza (a parte un fattore di scala), poiché non abbiamo aggiunto informazioni.\n\n48.8.3 Esempio 2: Priore a Gradino\nIl secondo priore è una funzione a gradino che riflette la convinzione che \\(\\theta\\) sia almeno \\(0.5\\). Questo priore esprime la credenza che il successo (“testa”) sia più probabile, ma non specifica di quanto.\n\n# Priore a gradino\nprior2 &lt;- ifelse(p_grid &gt;= 0.5, 1, 0)\n\n# Calcolo e visualizzazione della distribuzione a posteriori\nposterior2 &lt;- computePosterior(likelihood, prior2, p_grid)\n\n\n\n\n\n\n\nLa distribuzione a posteriori risultante esclude completamente i valori di \\(\\theta\\) inferiori a 0.5, coerentemente con le ipotesi del priore.\n\n48.8.4 Esempio 3: Priore Esponenziale\nIl terzo priore è una distribuzione centrata su 0.5, con un rapido decadimento esponenziale su entrambi i lati. Questo priore riflette la convinzione che \\(\\theta\\) sia vicina a 0.5.\n\n# Priore esponenziale\nprior3 &lt;- exp(-5 * abs(p_grid - 0.5))\n\n# Calcolo e visualizzazione della distribuzione a posteriori\nposterior3 &lt;- computePosterior(likelihood, prior3, p_grid)\n\n\n\n\n\n\n\nQuesto priore “attrare” la distribuzione a posteriori verso 0.5, a meno che i dati non forniscano evidenze contrarie molto forti.\n\n48.8.5 Analisi del Modello Beta-Binomiale\nConsideriamo ora il caso coniugato, in cui il priore è una distribuzione Beta e i dati seguono una distribuzione Binomiale.\nDefiniamo una funzione per visualizzare le distribuzioni del modello Beta-Binomiale: priore, verosimiglianza e posteriore.\n\nplot_beta_binomial &lt;- function(alpha, beta, y = NULL, n = NULL) {\n  # Griglia di valori per theta\n  theta &lt;- seq(0, 1, length.out = 100)\n  \n  # Priore\n  prior_density &lt;- dbeta(theta, alpha, beta)\n  \n  # Verosimiglianza scalata\n  if (!is.null(y) && !is.null(n)) {\n    likelihood &lt;- dbinom(y, n, theta)\n    scaled_likelihood &lt;- likelihood / max(likelihood)\n    posterior_alpha &lt;- alpha + y\n    posterior_beta &lt;- beta + n - y\n    posterior_density &lt;- dbeta(theta, posterior_alpha, posterior_beta)\n  }\n  \n  # Grafico\n  plot(\n    theta, \n    prior_density, \n    type = \"l\", \n    col = \"blue\", \n    ylim = c(0, max(prior_density, posterior_density)), \n    main = \"Beta-Binomial Model\", \n    xlab = expression(theta), \n    ylab = \"Density\"\n  )\n  if (!is.null(y) && !is.null(n)) {\n    lines(theta, scaled_likelihood, col = \"orange\", lwd = 2)\n    lines(theta, posterior_density, col = \"green\", lwd = 2)\n    legend(\n      \"topright\", \n      legend = c(\"Prior\", \"Likelihood (scaled)\", \"Posterior\"), \n      col = c(\"blue\", \"orange\", \"green\"), \n      lty = 1, \n      bty = \"n\")\n  }\n}\n\n\n48.8.5.1 Priore Uniforme\n\nplot_beta_binomial(alpha = 1, beta = 1, y = 15, n = 20)\n\n\n\n\n\n\n\n\n48.8.5.2 Priore Informativo (Beta(2, 2))\n\nplot_beta_binomial(alpha = 2, beta = 2, y = 15, n = 20)\n\n\n\n\n\n\n\n\n48.8.5.3 Priore Fortemente Informativo (Beta(2, 5))\n\nplot_beta_binomial(alpha = 2, beta = 5, y = 15, n = 20)\n\n\n\n\n\n\n\nIn conclusione, abbiamo esplorato come i priori influenzano la distribuzione a posteriori in contesti binomiali, dimostrando che l’influenza del priore è maggiore nei campioni piccoli e diminuisce con campioni di grandi dimensioni. L’analisi bayesiana consente un’integrazione flessibile delle conoscenze pregresse con i dati osservati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#connessione-tra-intuizioni-e-teoria",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#connessione-tra-intuizioni-e-teoria",
    "title": "48  L’influenza della distribuzione a priori",
    "section": "\n48.9 Connessione tra Intuizioni e Teoria",
    "text": "48.9 Connessione tra Intuizioni e Teoria\nL’equilibrio tra la distribuzione a priori e le evidenze provenienti dai dati, come dimostrato negli esempi precedenti, non solo rispecchia le nostre intuizioni, ma rappresenta anche una necessità matematica. Questo concetto diventa chiaro esaminando la formula del valore atteso della distribuzione a posteriori nel contesto del caso beta-binomiale, che può essere riscritta come segue:\n\\[\n\\begin{align}\n\\mathbb{E}_{\\text{post}} &[\\text{Beta}(\\alpha + y, \\beta + n - y)] = \\frac{\\alpha + y}{\\alpha + \\beta + n} \\\\\n&= \\frac{a+b}{a+b+n} \\cdot \\frac{a}{a+b} + \\frac{n}{a+b+n} \\cdot \\frac{y}{n}.\n\\end{align}\n\\]\nL’equazione precedente rivela che il valore atteso a posteriori si ottiene come una media ponderata tra il valore atteso a priori \\(\\left( \\frac{\\alpha}{\\alpha+\\beta}\\right)\\) e la proporzione osservata dei successi \\(\\left(\\frac{y}{n}\\right)\\). I pesi sono dati da \\(\\left( \\frac{\\alpha+\\beta}{\\alpha+\\beta+n}\\right)\\) e \\(\\left( \\frac{n}{\\alpha+\\beta+n}\\right)\\). Pertanto, quando il numero di osservazioni \\(n\\) è significativo rispetto alla somma dei parametri \\(\\alpha + \\beta\\), la distribuzione a posteriori sarà principalmente influenzata dai dati osservati e in minor misura dalle credenze a priori. Al contrario, se \\(n\\) è piccolo rispetto a \\(\\alpha + \\beta\\), i dati avranno un peso inferiore rispetto alle credenze a priori.\nQueste considerazioni indicano come scegliere i parametri \\(\\alpha\\) e \\(\\beta\\): se desideriamo rappresentare una totale ignoranza sul fenomeno, una scelta coerente è \\(\\alpha = \\beta = 1\\) (attribuiamo uguale credibilità a ogni valore di \\(\\theta\\)). Se, invece, possediamo forti credenze a priori, possiamo selezionare \\(\\alpha\\) in modo da eguagliare il valore atteso a priori, mentre \\(\\alpha + \\beta\\) rifletterà l’importanza attribuita all’informazione a priori: maggiore è il valore di \\(\\alpha + \\beta\\), maggiore sarà il numero di dati necessari per influenzare significativamente la distribuzione a posteriori rispetto a quella a priori. In situazioni in cui \\(n\\) è considerevolmente grande, la distribuzione a posteriori avrà un impatto ridotto sulla distribuzione a priori, a meno che non si facciano scelte estreme per i parametri a priori.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#conflitto-tra-prior-e-verosimiglianza",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#conflitto-tra-prior-e-verosimiglianza",
    "title": "48  L’influenza della distribuzione a priori",
    "section": "\n48.10 Conflitto tra Prior e Verosimiglianza",
    "text": "48.10 Conflitto tra Prior e Verosimiglianza\nEsaminiamo ora un altro esempio proposto da McElreath:\n\nLesson: Don’t trust intuition, for even simple prior+likelihood scenarios defy it. Four examples below, each producing radically different posteriors. Can you guess what each does?\n\n\nNella figura successiva vediamo la risposta alla domanda precedente.\n\nMcElreath descrive le caratteristiche di quattro diversi modelli in cui si combinano distribuzioni normali (Gaussiane) e Student-t (con 2 gradi di libertà) per il prior e la likelihood. La distribuzione gaussiana ha code molto sottili, mentre quella di Student-t ha code più spesse.\n\n\nIn Alto a Sinistra: Prior Normale, Likelihood Normale\n\ny ~ Normal(mu,1)\nmu ~ Normal(10,1)\n\nIn questo scenario classico di aggiornamento bayesiano, il posterior risulta essere un compromesso tra il prior e la likelihood. La distribuzione normale, con le sue code sottili, contribuisce a un aggiornamento più “prevedibile” e concentrato attorno al valore medio.\n\n\nIn Alto a Destra: Prior Student, Likelihood Student (df=2)\n\ny ~ Student(2,mu,1)\nmu ~ Student(2,10,1)\n\nIn questo caso, entrambe le distribuzioni hanno code più spesse. La presenza di “extra massa” nelle code significa che ciascuna distribuzione trova il modo dell’altra più plausibile, portando a una media che non rappresenta il miglior “compromesso”. Questo scenario risulta in una maggiore incertezza e un posterior meno definito.\n\n\nIn Basso a Sinistra: Prior Student, Likelihood Normale\n\ny ~ Normal(mu,1)\nmu ~ Student(2,10,1)\n\nQui, la likelihood normale, con le sue code sottili, tende a dominare. Essa è molto scettica nei confronti del prior con code spesse, ma il prior di Student-t non è sorpreso dalla likelihood. Questo porta a un posterior che è più influenzato dalla likelihood normale.\n\n\nIn Basso a Destra: Prior Normale, Likelihood Student\n\ny ~ Student(2,mu,1)\nmu ~ Normal(10,1)\n\nIn questo ultimo scenario, è il prior normale a dominare. Il ragionamento è simile a quello del caso precedente, ma in senso inverso. Il prior normale, con le sue code sottili, impone una maggiore influenza sul posterior, rendendolo meno influenzato dalle code più spesse della likelihood di Student-t.\n\n\nIn sintesi, la combinazione di queste due distribuzioni in diversi modi porta a risultati di aggiornamento bayesiano molto differenti, a seconda di quale tra prior e likelihood abbia le code più spesse e quindi eserciti una maggiore influenza sul posterior.\nIn conclusione, questo esercizio mostra come, ad eccezione del caso gaussiano, i risultati non sono affatto intuitivi. Pertanto, in contesti come questi, affidarsi esclusivamente alle proprie intuizioni non è una scelta consigliabile. È invece fondamentale procedere con l’esecuzione dei calcoli.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#riflessioni-conclusive",
    "title": "48  L’influenza della distribuzione a priori",
    "section": "\n48.11 Riflessioni Conclusive",
    "text": "48.11 Riflessioni Conclusive\nLa scelta della distribuzione a priori è uno degli aspetti più cruciali nell’inferenza bayesiana. Da un lato, le priors non informative possono essere utilizzate per minimizzare l’influenza delle conoscenze pregresse, permettendo ai dati osservati di guidare l’inferenza. Dall’altro, le priors informative sono estremamente utili quando si dispone di informazioni affidabili sui parametri, consentendo una stima più precisa. È importante ricordare che, con un gran numero di dati, l’influenza della prior tende a ridursi, mentre nei contesti con pochi dati la scelta della prior può avere un impatto significativo.\nUn aspetto essenziale dell’approccio bayesiano, come evidenziato nell’esempio di Johnson (2022), è che il processo di aggiornamento bayesiano riflette il modo in cui le persone ragionano intuitivamente: di fronte a evidenze deboli, le credenze rimangono stabili, mentre nuove informazioni robuste portano a un aggiornamento significativo delle credenze. Questo meccanismo formalizza in modo quantitativo e rigoroso le intuizioni che utilizziamo quotidianamente. Al contrario, l’approccio frequentista ignora le conoscenze pregresse, il che può portare a cambiamenti nelle inferenze senza tener conto delle credenze già esistenti.\nTuttavia, come evidenziato dagli esempi di McElreath, la situazione può essere più complessa nei modelli non coniugati, dove l’intuizione può fallire nel prevedere correttamente la distribuzione a posteriori. Questo ci ricorda che il contesto e la struttura del modello giocano un ruolo determinante nell’inferenza bayesiana.\n\n48.11.1 Il Ruolo della Prior nella Regolarizzazione\nNel contesto bayesiano, le distribuzioni a priori debolmente informative fungono da meccanismo di regolarizzazione, limitando l’influenza delle osservazioni estreme e garantendo inferenze più stabili. Questo approccio è ormai ampiamente accettato nella comunità statistica, poiché permette di ottenere risultati più prudenti senza introdurre un forte bias.\n\n48.11.2 L’Importanza dei Prior Informativi\nNegli ultimi anni, l’uso di priori informativi ha guadagnato maggiore attenzione, soprattutto grazie all’integrazione delle conoscenze esperte nel processo inferenziale. Questa pratica, nota come elicitazione della conoscenza esperta, richiede un rigoroso approccio metodologico per evitare bias cognitivi e assicurare che le informazioni pregresse siano incorporate in modo accurato. Questo è particolarmente rilevante in campi come la psicologia, dove spesso la base teorica è incerta, e l’elicitazione esperta può contribuire a migliorare la solidità delle analisi bayesiane (O’Hagan, 2019).\n\n48.11.3 Conclusioni Finali\nIn conclusione, la scelta delle prior deve essere ponderata attentamente in base alla disponibilità di dati e al contesto dell’analisi. Sebbene l’uso di priors non informative possa sembrare una scelta “neutra”, è spesso sub-ottimale. Le priors debolmente informative rappresentano lo standard attuale, poiché favoriscono un’inferenza più robusta grazie alla loro capacità di regolarizzare l’influenza dei dati. Infine, l’uso di priori informativi, sviluppati attraverso protocolli rigorosi di elicitazione esperta, è una frontiera in crescita nell’analisi bayesiana, poiché consente di sfruttare al meglio le conoscenze pregresse per migliorare la qualità delle inferenze e ridurre l’incertezza.\nQuesto approccio, che bilancia conoscenza pregressa e nuovi dati, permette di sviluppare modelli bayesiani più solidi e informati, riflettendo accuratamente sia l’incertezza sia la competenza specifica del dominio di studio.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#informazioni-sullambiente-di-sviluppo",
    "title": "48  L’influenza della distribuzione a priori",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.17.0      see_0.9.0        gridExtra_2.3    patchwork_1.3.0 \n#&gt;  [5] bayesplot_1.11.1 psych_2.4.12     scales_1.3.0     markdown_1.13   \n#&gt;  [9] knitr_1.49       lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1   \n#&gt; [13] dplyr_1.1.4      purrr_1.0.2      readr_2.1.5      tidyr_1.3.1     \n#&gt; [17] tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3       \n#&gt; [21] here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      shape_1.4.6.1     xfun_0.49         htmlwidgets_1.6.4\n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2      \n#&gt;  [9] generics_0.1.3    parallel_4.4.2    pan_1.9           pacman_0.5.1     \n#&gt; [13] pkgconfig_2.0.3   jomo_2.7-6        Matrix_1.7-1      lifecycle_1.0.4  \n#&gt; [17] compiler_4.4.2    farver_2.1.2      munsell_0.5.1     mnormt_2.1.1     \n#&gt; [21] codetools_0.2-20  htmltools_0.5.8.1 yaml_2.3.10       glmnet_4.1-8     \n#&gt; [25] nloptr_2.1.1      pillar_1.10.0     MASS_7.3-61       iterators_1.0.14 \n#&gt; [29] rpart_4.1.23      boot_1.3-31       foreach_1.5.2     mitml_0.4-5      \n#&gt; [33] nlme_3.1-166      tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4    \n#&gt; [37] splines_4.4.2     rprojroot_2.0.4   fastmap_1.2.0     grid_4.4.2       \n#&gt; [41] colorspace_2.1-1  cli_3.6.3         magrittr_2.0.3    survival_3.8-3   \n#&gt; [45] broom_1.0.7       withr_3.0.2       backports_1.5.0   timechange_0.3.0 \n#&gt; [49] rmarkdown_2.29    nnet_7.3-19       lme4_1.1-35.5     hms_1.1.3        \n#&gt; [53] evaluate_1.0.1    rlang_1.1.4       Rcpp_1.0.13-1     glue_1.8.0       \n#&gt; [57] minqa_1.2.8       jsonlite_1.8.9    R6_2.5.1",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#bibliografia",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#bibliografia",
    "title": "48  L’influenza della distribuzione a priori",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A. (2006). Prior distributions for variance parameters in hierarchical models (comment on article by Browne and Draper). Bayesian Analysis, 1(3), 515–534. https://doi.org/10.1214/06-BA117A\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nO’Hagan, A. (2019). Expert knowledge elicitation: subjective but scientific. The American Statistician, 73(sup1), 69–81.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_gamma_poisson_model.html",
    "href": "chapters/bayesian_inference/09_gamma_poisson_model.html",
    "title": "49  Modello coniugato Gamma-Poisson 🔸",
    "section": "",
    "text": "49.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nPreparazione del Notebook\nIn psicologia, le variabili di conteggio (\\(y\\)), che indicano il numero di occorrenze di un evento, trovano ampio impiego in diversi ambiti. Ad esempio, sono usate per quantificare la frequenza dei sintomi di un disturbo o per analizzare le frequenze delle parole negli studi di psicolinguistica. Queste variabili, assumendo valori discreti, richiedono modelli statistici specifici.\nQuesto capitolo si focalizza sulla stima del tasso medio di incidenza (\\(\\lambda_i\\)) di tali eventi, ovvero sul numero medio di occorrenze per unità di misura. Adotteremo un approccio bayesiano, utilizzando il modello di Poisson per descrivere la distribuzione di probabilità delle variabili di conteggio. In particolare, esploreremo la derivazione analitica della distribuzione a posteriori del parametro \\(\\lambda_i\\), considerando una distribuzione a priori Gamma. Successivamente, verificheremo la validità dei risultati analitici mediante simulazioni Monte Carlo.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_gamma_poisson_model.html#distribuzione-di-poisson",
    "href": "chapters/bayesian_inference/09_gamma_poisson_model.html#distribuzione-di-poisson",
    "title": "49  Modello coniugato Gamma-Poisson 🔸",
    "section": "\n49.2 Distribuzione di Poisson",
    "text": "49.2 Distribuzione di Poisson\nLa distribuzione di Poisson è un modello probabilistico utilizzato per descrivere il numero di eventi che si verificano in un intervallo di tempo o spazio fisso, partendo dall’assunto che tali eventi si verifichino con una frequenza media costante e in modo indipendente rispetto al tempo trascorso dall’ultimo evento. Se un dato \\(y\\) segue una distribuzione di Poisson con parametro \\(\\lambda\\), allora la probabilità di osservare un singolo valore \\(y_i\\) è data da:\n\\[\nf(y_i \\mid \\lambda) = \\frac{e^{-\\lambda} \\lambda^{y_i}}{y_i!},\n\\]\ndove \\(\\lambda &gt; 0\\) rappresenta la frequenza media di occorrenza degli eventi e \\(y_i\\) è il numero di eventi osservati. La distribuzione di Poisson ha la caratteristica che sia il valore atteso che la varianza di una variabile casuale \\(Y\\) che segue questa distribuzione sono pari a \\(\\lambda\\), cioè \\(E(Y) = \\lambda\\) e \\(\\text{Var}(Y) = \\lambda\\).\n\n49.2.1 Simulazione\nPer capire meglio come funziona la distribuzione di Poisson, immaginiamo un paziente con un disturbo ossessivo-compulsivo. Supponiamo che in media questo paziente ripeta un’azione compulsiva 2 volte ogni ora. In questo caso, il parametro della distribuzione di Poisson è λ = 2.\nLa probabilità di osservare esattamente \\(k\\) eventi in un’ora è calcolata dalla formula:\n\\[\nf(k | \\lambda) = \\frac{e^{-\\lambda} \\lambda^k}{k!}.\n\\]\nNel caso specifico con \\(\\lambda = 2\\), le probabilità per i primi valori di \\(k\\) sono:\n\nLa probabilità di osservare 0 eventi in un’ora è \\(\\frac{e^{-2} \\cdot 2^0}{0!} = e^{-2} \\approx 0{.}1353\\).\nLa probabilità di osservare 1 evento in un’ora è \\(\\frac{e^{-2} \\cdot 2^1}{1!} = 2e^{-2} \\approx 0{.}2707\\).\nLa probabilità di osservare 2 eventi in un’ora è \\(\\frac{e^{-2} \\cdot 2^2}{2!} = 2e^{-2} \\approx 0{.}2707\\).\nE così via per \\(k = 3\\), \\(k = 4\\), \\(\\dots\\)\n\nQuesto esempio illustra come la distribuzione di Poisson possa essere utilizzata per modellare il numero di eventi rari che si verificano in un intervallo temporale fisso, con una frequenza media nota.\nSvolgiamo ora i calcoli utilizzando la funzione dpois in R:\n\nlam_true &lt;- 2\n# Creazione di un vettore di valori da 0 a 9\nk_values &lt;- 0:9\n\n# Calcolo delle probabilità per ogni valore in k_values\nprobabilities &lt;- dpois(k_values, lambda = lam_true)\n\n# Stampa delle probabilità\nfor (i in seq_along(k_values)) {\n  cat(sprintf(\"Probabilità di %d eventi: %.4f\\n\", k_values[i], probabilities[i]))\n}\n#&gt; Probabilità di 0 eventi: 0.1353\n#&gt; Probabilità di 1 eventi: 0.2707\n#&gt; Probabilità di 2 eventi: 0.2707\n#&gt; Probabilità di 3 eventi: 0.1804\n#&gt; Probabilità di 4 eventi: 0.0902\n#&gt; Probabilità di 5 eventi: 0.0361\n#&gt; Probabilità di 6 eventi: 0.0120\n#&gt; Probabilità di 7 eventi: 0.0034\n#&gt; Probabilità di 8 eventi: 0.0009\n#&gt; Probabilità di 9 eventi: 0.0002\n\n\n49.2.2 Creazione del grafico della funzione di massa di probabilità\nIl seguente codice R genera il grafico della funzione di massa di probabilità (PMF) di una distribuzione di Poisson con parametro \\(\\lambda = 2\\):\n\n# Definiamo il parametro lambda\nlambd &lt;- 2\n\n# Generiamo i valori sull'asse x (numero di eventi)\nx &lt;- 0:9  # Possiamo aumentare o diminuire il range a seconda delle esigenze\n\n# Calcoliamo le probabilità corrispondenti utilizzando la funzione dpois\ny &lt;- dpois(x, lambda = lambd)\n\n# Creiamo il grafico a barre\nbarplot(\n  height = y,\n  names.arg = x,\n  col = \"lightblue\",\n  xlab = \"Numero di eventi\",\n  ylab = \"Probabilità\",\n  main = \"Distribuzione di Poisson (λ = 2)\"\n)",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_gamma_poisson_model.html#verosimiglianza-per-un-campione-di-osservazioni",
    "href": "chapters/bayesian_inference/09_gamma_poisson_model.html#verosimiglianza-per-un-campione-di-osservazioni",
    "title": "49  Modello coniugato Gamma-Poisson 🔸",
    "section": "\n49.3 Verosimiglianza per un Campione di Osservazioni",
    "text": "49.3 Verosimiglianza per un Campione di Osservazioni\nConsideriamo un campione di \\(n\\) osservazioni indipendenti e identicamente distribuite, \\(y_1, y_2, \\dots, y_n\\), tratto da una distribuzione di Poisson con parametro \\(\\lambda\\). La funzione di verosimiglianza \\(f(y \\mid \\lambda)\\) rappresenta la probabilità congiunta di osservare esattamente questi valori dato un particolare valore di \\(\\lambda\\).\nMatematicamente, la verosimiglianza si esprime come:\n\\[\nf(y \\mid \\lambda) = \\prod_{i=1}^{n} \\frac{e^{-\\lambda} \\lambda^{y_i}}{y_i!}\n= \\frac{e^{-n\\lambda} \\lambda^{\\sum_{i=1}^n y_i}}{\\prod_{i=1}^{n} y_i!}.\n\\]\nQuesta funzione misura la compatibilità tra i dati osservati e un dato valore di \\(\\lambda\\). Valori di \\(\\lambda\\) che rendono più alta la verosimiglianza sono quelli che meglio spiegano i dati osservati.\nLa funzione di verosimiglianza descrive quanto sia plausibile un valore specifico di \\(\\lambda\\) dato il campione di dati osservati \\(y_1, y_2, \\dots, y_n\\). Per ogni possibile valore di \\(\\lambda\\), la funzione fornisce una misura della compatibilità tra il valore ipotizzato e i dati. In altre parole, essa risponde alla domanda: quanto bene questo valore di \\(\\lambda\\) spiega i dati osservati?\nPer semplificare i calcoli ed evitare problemi di overflow numerico, è comune utilizzare il logaritmo naturale della funzione di verosimiglianza, chiamato log-verosimiglianza. La log-verosimiglianza per il modello di Poisson si ottiene come:\n\\[\n\\log f(y \\mid \\lambda) = -n\\lambda + \\left(\\sum_{i=1}^n y_i \\right) \\log \\lambda - \\sum_{i=1}^n \\log(y_i!).\n\\]\nL’uso del logaritmo trasforma il prodotto nella somma, facilitando le analisi e la stima dei parametri.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_gamma_poisson_model.html#distribuzione-gamma",
    "href": "chapters/bayesian_inference/09_gamma_poisson_model.html#distribuzione-gamma",
    "title": "49  Modello coniugato Gamma-Poisson 🔸",
    "section": "\n49.4 Distribuzione Gamma",
    "text": "49.4 Distribuzione Gamma\nLa distribuzione Gamma riveste un ruolo centrale nel modello coniugato Gamma-Poisson, poiché funge da distribuzione a priori per il parametro di tasso \\(\\lambda\\) della distribuzione di Poisson. La sua scelta è motivata dalla proprietà di coniugatezza, che consente di ottenere una distribuzione a posteriori appartenente alla stessa famiglia della prior, semplificando significativamente i calcoli inferenziali e aggiornando in modo diretto le credenze alla luce dei dati osservati.\nLa funzione di densità della distribuzione Gamma è definita come:\n\\[\nf(x \\mid \\alpha, \\beta) = \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)} x^{\\alpha - 1} e^{-\\beta x},\n\\]\ndove:\n\n\n\\(\\alpha\\) (detto parametro di forma) determina la forma della distribuzione: valori più elevati di \\(\\alpha\\) tendono a rendere la distribuzione più simmetrica;\n\n\\(\\beta\\) (detto parametro di tasso o scala inversa) controlla la scala: valori più elevati di \\(\\beta\\) concentrano maggiormente la massa di probabilità vicino all’origine.\n\nAd esempio:\n\nUna distribuzione Gamma con \\(\\alpha = 2\\) e \\(\\beta = 3\\) rappresenta un processo in cui eventi relativamente rari si verificano occasionalmente.\nUna distribuzione Gamma con \\(\\alpha = 10\\) e \\(\\beta = 1\\) descrive un processo più regolare, con eventi che si verificano con maggiore frequenza e prevedibilità.\n\n\n\n\n\n\n\nIn R, la parametrizzazione della distribuzione Gamma utilizza direttamente il parametro \\(\\beta\\) come tasso (\\(rate\\)), che è l’inverso del parametro di scala (\\(scale = 1 / \\beta\\)) utilizzato in Scipy.\n\n\n\nPer calcolare la densità di probabilità in R, si utilizza:\ndgamma(x, shape = alpha, rate = beta)\n\n# Definizione dei parametri\nalpha &lt;- 2\nbeta &lt;- 3\n\n# Generazione dei valori di x\nx &lt;- seq(0, 3, length.out = 500)\n\n# Calcolo della densità di probabilità\npdf &lt;- dgamma(x, shape = alpha, rate = beta)\n\n# Creazione del grafico\nplot(\n  x, pdf,\n  type = \"l\",\n  col = \"blue\",\n  lwd = 2,\n  xlab = \"x\",\n  ylab = \"Densità di probabilità\",\n  main = expression(\"Distribuzione Gamma (\" ~ alpha == 2 ~ \",\" ~ beta == 3 ~ \")\")\n)\ngrid()\n\n\n\n\n\n\n\nQuesto grafico mostra la densità di una distribuzione Gamma con \\(\\alpha = 2\\) e \\(\\beta = 3\\), calcolata su un intervallo \\([0, 3]\\).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_gamma_poisson_model.html#metodo-basato-su-griglia",
    "href": "chapters/bayesian_inference/09_gamma_poisson_model.html#metodo-basato-su-griglia",
    "title": "49  Modello coniugato Gamma-Poisson 🔸",
    "section": "\n49.5 Metodo Basato su Griglia",
    "text": "49.5 Metodo Basato su Griglia\nSupponiamo di voler calcolare la distribuzione a posteriori del parametro \\(\\lambda\\) di un modello di Poisson, con una distribuzione a priori Gamma. Utilizziamo un approccio numerico basato sulla discretizzazione dello spazio dei parametri.\nConsideriamo i seguenti dati osservati:\n\n# Dati osservati\ny &lt;- c(2, 1, 3, 2, 2, 1, 1, 1)\n\nAdotteremo questa distribuzione a priori:\n\n# Parametri della distribuzione a priori Gamma\nalpha_prior &lt;- 9\nbeta_prior &lt;- 2\n\n# Griglia dei valori di lambda\nlambda_grid &lt;- seq(0.01, 10, length.out = 1000)\n\n# Calcolo della densità della distribuzione a priori\nprior &lt;- dgamma(lambda_grid, shape = alpha_prior, rate = beta_prior)\n\n# Plot della distribuzione a priori\nplot(\n  lambda_grid, prior, type = \"l\", col = \"blue\",\n  xlab = expression(lambda),\n  ylab = \"Densità di probabilità\",\n  main = \"Distribuzione Gamma a Priori\"\n)\nabline(v = alpha_prior / beta_prior, col = \"red\", lty = 2, lwd = 2)\nabline(v = mean(y), col = \"green\", lty = 2, lwd = 2)\nlegend(\"topright\", legend = c(\"Media Gamma\", \"Media Campionaria\"),\n       col = c(\"red\", \"green\"), lty = 2, lwd = 2)\ngrid()\n\n\n\n\n\n\n\nCalcoliamo la verosimiglianza:\n\n# Inizializzazione della verosimiglianza\nlikelihood &lt;- rep(1, length(lambda_grid))\n\n# Calcolo iterativo della verosimiglianza\nfor (yi in y) {\n  likelihood &lt;- likelihood * dpois(yi, lambda = lambda_grid)\n}\n\nCalcoliamo la distribuzione a posteriori non normalizzata:\n\nposterior_unnormalized &lt;- likelihood * prior\n\nNormalizzazione della distribuzione a posteriori:\n\n# Fattore di normalizzazione\nnormalization_factor &lt;- sum(posterior_unnormalized * diff(lambda_grid)[1])\n\n# Distribuzione a posteriori normalizzata\nposterior &lt;- posterior_unnormalized / normalization_factor\n\nCreiamo un grafico delle distribuzioni a priori e a posteriori:\n\nplot(\n  lambda_grid, posterior, type = \"l\", col = \"blue\",\n  xlab = expression(lambda),\n  ylab = \"Densità di probabilità\",\n  main = \"Distribuzione a Posteriori di Lambda\"\n)\nlines(lambda_grid, prior, col = \"red\", lty = 2, lwd = 2)\nlegend(\"topright\", legend = c(\"Posteriori\", \"A Priori\"),\n       col = c(\"blue\", \"red\"), lty = c(1, 2), lwd = 2)\ngrid()\n\n\n\n\n\n\n\nIn conclusione,\n\nla distribuzione a posteriori è spostata a sinistra rispetto a quella a priori, indicando che i dati suggeriscono un valore più basso per \\(\\lambda\\).\nla distribuzione a posteriori è più stretta rispetto a quella a priori, indicando una riduzione dell’incertezza.\n\nQuesto approccio numerico consente di esplorare come le osservazioni aggiornano la nostra credenza sul parametro \\(\\lambda\\), evidenziando la potenza del metodo bayesiano.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_gamma_poisson_model.html#modello-coniugato-gamma-poission",
    "href": "chapters/bayesian_inference/09_gamma_poisson_model.html#modello-coniugato-gamma-poission",
    "title": "49  Modello coniugato Gamma-Poisson 🔸",
    "section": "\n49.6 Modello Coniugato Gamma-Poission",
    "text": "49.6 Modello Coniugato Gamma-Poission\nPer calcolare analiticamente la distribuzione a posteriori nel contesto di un modello gamma-Poisson possiamo seguire un processo diretto. Il modello Gamma-Poisson è coniugato, il che significa che la distribuzione a posteriori sarà ancora una distribuzione Gamma.\nSeguendo il teorema di Bayes, possiamo scrivere la distribuzione a posteriori come:\n\\(f(\\lambda \\mid y) \\propto f(y \\mid \\lambda) \\cdot f(\\lambda) ,\\)\ndove \\(f(\\lambda \\mid y)\\) è la distribuzione a posteriori, \\(f(y \\mid \\lambda)\\) è la verosimiglianza e \\(f(\\lambda)\\) è la distribuzione a priori.\nDefiniamo la verosimiglianza (distribuzione di Poisson):\n\\(f(y \\mid \\lambda) = \\prod_{i=1}^n \\frac{e^{-\\lambda}\\lambda^{y_i}}{y_i!} = \\frac{e^{-n\\lambda}\\lambda^{\\sum_{i=1}^n y_i}}{\\prod_{i=1}^n y_i!}.\\)\nDefiniamo la distribuzione a priori (distribuzione Gamma):\n\\(f(\\lambda) = \\frac{b^a}{\\Gamma(a)}\\lambda^{a-1}e^{-b\\lambda}.\\)\nOra, moltiplichiamo la verosimiglianza per la distribuzione a priori:\n\\(f(\\lambda|y) \\propto \\frac{e^{-n\\lambda}\\lambda^{\\sum_{i=1}^n y_i}}{\\prod_{i=1}^n y_i!} \\cdot \\frac{b^a}{\\Gamma(a)}\\lambda^{a-1}e^{-b\\lambda}.\\)\nSemplifichiamo, eliminando i termini costanti (che non dipendono da \\(\\lambda\\)):\n\\(f(\\lambda \\mid y) \\propto e^{-n\\lambda}\\lambda^{\\sum_{i=1}^n y_i} \\cdot \\lambda^{a-1}e^{-b\\lambda}.\\)\nRaggruppiamo i termini:\n\\(f(\\lambda|y) \\propto \\lambda^{\\sum_{i=1}^n y_i} \\cdot \\lambda^{a-1} \\cdot e^{-n\\lambda} \\cdot e^{-b\\lambda}.\\)\nSemplifichiamo ulteriormente:\n\\(f(\\lambda \\mid y) \\propto \\lambda^{\\sum_{i=1}^n y_i + a - 1} \\cdot e^{-(n+b)\\lambda}.\\)\nRiconosciamo che questa è la forma di una distribuzione Gamma con nuovi parametri:\n\\(f(\\lambda \\mid y) \\propto \\lambda^{(\\sum_{i=1}^n y_i + a) - 1} \\cdot e^{-(n+b)\\lambda}.\\)\nQuindi, la distribuzione a posteriori è una Gamma con parametri:\n\n\n\\(\\alpha_{post} = a + \\sum_{i=1}^n y_i\\),\n\n\\(\\beta_{post} = b + n\\),\n\ndove:\n\n\n\\(a\\) e \\(b\\) sono i parametri della distribuzione Gamma a priori,\n\n\\(\\sum_{i=1}^n y_i\\) è la somma di tutte le osservazioni,\n\n\\(n\\) è il numero di osservazioni.\n\nQuesta derivazione mostra come la distribuzione a posteriori mantiene la forma di una Gamma, ma con parametri aggiornati che incorporano l’informazione dai dati osservati.\nConsideriamo nuovamente l’esempio precedente. Utilizzando i parametri aggiornati, rappresentiamo graficamente la distribuzione a posteriori:\n\n# Parametri aggiornati della distribuzione a posteriori Gamma\nalpha_post &lt;- alpha_prior + sum(y)\nbeta_post &lt;- beta_prior + length(y)\n\n# Distribuzione a posteriori analitica\nposterior_analytic &lt;- dgamma(lambda_grid, shape = alpha_post, rate = beta_post)\n\n# Plot della distribuzione a posteriori analitica\nplot(\n  lambda_grid, posterior_analytic, type = \"l\", col = \"blue\",\n  xlab = expression(lambda),\n  ylab = \"Densità di probabilità\",\n  main = \"Distribuzione a Posteriori Analitica Gamma-Poisson\"\n)\nabline(v = alpha_post / beta_post, col = \"red\", lty = 2) # Media a posteriori\nlegend(\n  \"topright\",\n  legend = c(\"Distribuzione a Posteriori\", \"Media a Posteriori\"),\n  col = c(\"blue\", \"red\"),\n  lty = c(1, 2)\n)\n\n\n\n\n\n\n\nIl grafico mostra la distribuzione a posteriori analitica del parametro di tasso \\(\\lambda\\) di un modello di Poisson, ottenuta utilizzando una distribuzione a priori Gamma e aggiornando i parametri alla luce dei dati osservati. La distribuzione a posteriori è calcolata come una Gamma aggiornata con i parametri \\(\\alpha_{\\text{post}}\\) e \\(\\beta_{\\text{post}}\\), e rappresenta la nostra conoscenza aggiornata dopo aver visto i dati. I risultati analitici concordano con quelli ottenuti tramite simulazione.\nProcediamo ora con il calcolo della soluzione analitica per la media della distribuzione a posteriori del parametro \\(\\lambda\\):\n\n# Media della distribuzione a posteriori\nposterior_mean &lt;- alpha_post / beta_post\ncat(sprintf(\"Media a Posteriori = %.3f\\n\", posterior_mean))\n#&gt; Media a Posteriori = 2.200\n\n# Parametri della distribuzione a posteriori\ncat(sprintf(\"Shape (α) = %.1f\\n\", alpha_post))\n#&gt; Shape (α) = 22.0\ncat(sprintf(\"Rate (β) = %.1f\\n\", beta_post))\n#&gt; Rate (β) = 10.0\n\nPossiamo calcolare la probabilità di qualsiasi evento di interesse. Per esempio, ci possiamo chiedere quale sia la probabilità di osservare più di 3 compulsioni per ora:\n\n# Probabilità di osservare più di 3 eventi\nprob_y_greater_than_3 &lt;- 1 - pgamma(3, shape = alpha_post, rate = beta_post)\ncat(sprintf(\"Probabilità di osservare più di 3 eventi = %.3f\\n\", prob_y_greater_than_3))\n#&gt; Probabilità di osservare più di 3 eventi = 0.054",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_gamma_poisson_model.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/09_gamma_poisson_model.html#riflessioni-conclusive",
    "title": "49  Modello coniugato Gamma-Poisson 🔸",
    "section": "\n49.7 Riflessioni Conclusive",
    "text": "49.7 Riflessioni Conclusive\nIl modello Gamma-Poisson offre un framework robusto per l’inferenza bayesiana su dati di conteggio in psicologia. Partendo da una distribuzione a priori Gamma, che rappresenta la nostra conoscenza iniziale sul tasso medio, siamo in grado di aggiornare questa conoscenza alla luce dei dati osservati, ottenendo una distribuzione a posteriori che riflette in modo più preciso la realtà sottostante. Questo approccio permette di quantificare l’incertezza associata alle nostre stime e di prendere decisioni informate sulla base dei dati disponibili.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_gamma_poisson_model.html#esercizi",
    "href": "chapters/bayesian_inference/09_gamma_poisson_model.html#esercizi",
    "title": "49  Modello coniugato Gamma-Poisson 🔸",
    "section": "\n49.8 Esercizi",
    "text": "49.8 Esercizi\n\nEsercizio 49.1 Consideriamo uno studio longitudinale su coppie, dove i partecipanti registrano quotidianamente la frequenza con cui nascondono il loro comportamento di fumo al partner. Basandoci sui dati di Scholz et al. (2021), assumiamo che il tasso medio di nascondere il fumo sia di 1.52 volte al giorno. Supponiamo di avere i seguenti dati giornalieri per un partecipante:\n\nGiorno 1: 2 volte.\nGiorno 2: 0 volte.\nGiorno 3: 1 volta.\nGiorno 4: 3 volte.\n\nUtilizzare un modello Gamma-Poisson per stimare la distribuzione a posteriori del tasso individuale di nascondere il fumo per un partecipante specifico, dato il suo insieme di osservazioni giornaliere.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_gamma_poisson_model.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/09_gamma_poisson_model.html#informazioni-sullambiente-di-sviluppo",
    "title": "49  Modello coniugato Gamma-Poisson 🔸",
    "section": "\n49.9 Informazioni sull’Ambiente di Sviluppo",
    "text": "49.9 Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.17.0      see_0.9.0        gridExtra_2.3    patchwork_1.3.0 \n#&gt;  [5] bayesplot_1.11.1 psych_2.4.12     scales_1.3.0     markdown_1.13   \n#&gt;  [9] knitr_1.49       lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1   \n#&gt; [13] dplyr_1.1.4      purrr_1.0.2      readr_2.1.5      tidyr_1.3.1     \n#&gt; [17] tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3       \n#&gt; [21] here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      shape_1.4.6.1     xfun_0.49         htmlwidgets_1.6.4\n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2      \n#&gt;  [9] generics_0.1.3    parallel_4.4.2    pan_1.9           pacman_0.5.1     \n#&gt; [13] pkgconfig_2.0.3   jomo_2.7-6        Matrix_1.7-1      lifecycle_1.0.4  \n#&gt; [17] compiler_4.4.2    farver_2.1.2      munsell_0.5.1     mnormt_2.1.1     \n#&gt; [21] codetools_0.2-20  htmltools_0.5.8.1 yaml_2.3.10       glmnet_4.1-8     \n#&gt; [25] nloptr_2.1.1      pillar_1.10.0     MASS_7.3-61       iterators_1.0.14 \n#&gt; [29] rpart_4.1.23      boot_1.3-31       foreach_1.5.2     mitml_0.4-5      \n#&gt; [33] nlme_3.1-166      tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4    \n#&gt; [37] splines_4.4.2     rprojroot_2.0.4   fastmap_1.2.0     grid_4.4.2       \n#&gt; [41] colorspace_2.1-1  cli_3.6.3         magrittr_2.0.3    survival_3.8-3   \n#&gt; [45] broom_1.0.7       withr_3.0.2       backports_1.5.0   timechange_0.3.0 \n#&gt; [49] rmarkdown_2.29    nnet_7.3-19       lme4_1.1-35.5     hms_1.1.3        \n#&gt; [53] evaluate_1.0.1    rlang_1.1.4       Rcpp_1.0.13-1     glue_1.8.0       \n#&gt; [57] minqa_1.2.8       jsonlite_1.8.9    R6_2.5.1",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_gamma_poisson_model.html#bibliografia",
    "href": "chapters/bayesian_inference/09_gamma_poisson_model.html#bibliografia",
    "title": "49  Modello coniugato Gamma-Poisson 🔸",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nScholz, U., Stadler, G., Berli, C., Lüscher, J., & Knoll, N. (2021). How do people experience and respond to social control from their partner? Three daily diary studies. Frontiers in Psychology, 11, 613546.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_gamma_exponential_model.html",
    "href": "chapters/bayesian_inference/10_gamma_exponential_model.html",
    "title": "50  Modello gamma-esponenziale 🔸",
    "section": "",
    "text": "50.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nPreparazione del Notebook\nNell’inferenza bayesiana, il modello coniugato Gamma-Esponenziale rappresenta un approccio analitico efficace per l’analisi di dati che seguono una distribuzione esponenziale. Questa distribuzione è comunemente utilizzata per modellare i tempi di attesa tra eventi in processi di Poisson, come ad esempio gli intervalli tra arrivi in un sistema a coda o la durata di eventi psicologici.\nConsideriamo, ad esempio, un esperimento in psicologia in cui si misurano i tempi di insorgenza di episodi di ansia in seguito a un evento stressante. In questo caso, si può ipotizzare che i tempi di insorgenza siano distribuiti esponenzialmente. Il parametro \\(\\lambda\\) della distribuzione esponenziale rappresenta il tasso medio con cui si verificano gli episodi di ansia.\nIl modello coniugato Gamma-Esponenziale consente di stimare il parametro \\(\\lambda\\) utilizzando i dati osservati. La distribuzione a priori Gamma viene utilizzata per rappresentare l’incertezza iniziale su \\(\\lambda\\), mentre la distribuzione esponenziale modella i dati osservati. Grazie a questa coniugazione, l’aggiornamento delle credenze sul parametro \\(\\lambda\\) avviene in modo semplice e analitico, permettendo di ottenere una stima bayesiana del tasso medio di occorrenza degli episodi di ansia, fornendo così una descrizione probabilistica accurata del fenomeno in esame.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Modello gamma-esponenziale 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_gamma_exponential_model.html#introduzione",
    "href": "chapters/bayesian_inference/10_gamma_exponential_model.html#introduzione",
    "title": "50  Modello gamma-esponenziale 🔸",
    "section": "",
    "text": "50.1.1 Il Modello Matematico\nCaso singolo. Supponiamo di osservare un singolo tempo di attesa \\(y_1\\) prima che si verifichi un evento, come un episodio di disagio psicologico. Assumiamo che questo tempo di attesa segua una distribuzione esponenziale con parametro \\(\\lambda\\). La funzione di densità di probabilità (pdf) della distribuzione esponenziale è data da:\n\\[\nf(y_1 \\mid \\lambda) = \\lambda e^{-\\lambda y_1},\n\\]\ndove:\n\n\n\\(y_1\\) rappresenta il tempo di attesa,\n\n\\(\\lambda\\) è il parametro della distribuzione, che rappresenta il tasso medio con cui gli eventi si verificano per unità di tempo.\n\nIn questa distribuzione, \\(\\lambda\\) è il tasso di occorrenza o tasso di decadimento, ed è l’inverso del tempo medio di attesa. Più precisamente:\n\nIl tempo medio di attesa è il valore medio del tempo che trascorre prima che l’evento si verifichi (ad esempio, quanto tempo ci si aspetta in media prima che arrivi un autobus).\nIl parametro \\(\\lambda\\) rappresenta la frequenza con cui l’evento si verifica per unità di tempo, e quindi \\(\\lambda = \\frac{1}{\\text{tempo medio}}\\).\n\nPertanto, nella funzione esponenziale \\(f(y_1 \\mid \\lambda) = \\lambda e^{-\\lambda y_1}\\), il parametro \\(\\lambda\\) è inversamente proporzionale al tempo medio di attesa: più grande è \\(\\lambda\\), più breve è il tempo medio di attesa tra gli eventi.\nQuesta funzione descrive la probabilità di osservare un tempo di attesa esattamente uguale a \\(y_1\\), dato un valore specifico di \\(\\lambda\\). Per la distribuzione esponenziale, la media è \\(\\frac{1}{\\lambda}\\) e la varianza è \\(\\frac{1}{\\lambda^2}\\), il che riflette l’influenza del tasso \\(\\lambda\\) sulla dispersione dei tempi di attesa.\nPer fare un esempio, supponiamo che il tempo medio di attesa sia 2 ore. In questo caso, il parametro \\(\\lambda\\) (l’inverso del tempo medio di attesa) è \\(\\frac{1}{2}\\).\n\n# Parametro lambda (l'inverso del tempo medio di attesa)\nlambda_value &lt;- 1 / 2\n\nDisegniamo la funzione di densità esponenziale per tempi di attesa compresi tra 0 e 10 ore.\n\n# Creazione dei valori di y1 su cui valutare la funzione\ny1_values &lt;- seq(0, 10, length.out = 500) # Intervallo da 0 a 10 ore\n\n# Definizione della funzione di densità esponenziale\nexponential_density &lt;- function(y1, lambda_value) {\n  lambda_value * exp(-lambda_value * y1)\n}\n\n# Calcolo dei valori di f(y1 | lambda)\nf_values &lt;- exponential_density(y1_values, lambda_value)\n\n# Creazione del grafico\nplot(\n  y1_values, f_values,\n  type = \"l\", lwd = 2,\n  main = expression(paste(\n    \"Funzione di Densità Esponenziale con \",\n    lambda, \" = 1/2\"\n  )),\n  xlab = \"Tempo di attesa (ore)\", ylab = \"Densità\"\n)\nlegend(\"topright\",\n  legend = expression(f(y[1] ~ \"|\" ~ lambda) == lambda ~ e^(-lambda * y[1])),\n  lty = 1, bty = \"n\"\n)\n\n\n\n\n\n\n\nQuesto codice crea un grafico della funzione di densità esponenziale per \\(\\lambda = 1/2\\) e tempi di attesa compresi tra 0 e 10 ore.\nIl caso di \\(n\\) osservazioni indipendenti. Consideriamo ora un campione di \\(n\\) osservazioni indipendenti \\(y_1, y_2, \\dots, y_n\\). L’indipendenza tra le osservazioni implica che il tempo di attesa osservato per un evento non influisce sulla probabilità di osservare altri tempi di attesa.\nPoiché le osservazioni sono indipendenti, la probabilità congiunta di osservare tutti i tempi di attesa nel campione è il prodotto delle probabilità individuali. Di conseguenza, la funzione di verosimiglianza per l’intero campione è data da:\n\\[\nf(y_1, y_2, \\dots, y_n \\mid \\lambda) = f(y_1 \\mid \\lambda) \\cdot f(y_2 \\mid \\lambda) \\cdot \\dots \\cdot f(y_n \\mid \\lambda).\n\\]\nSostituendo la funzione di densità della distribuzione esponenziale per ciascuna osservazione, otteniamo:\n\\[\nf(y \\mid \\lambda) = \\lambda e^{-\\lambda y_1} \\cdot \\lambda e^{-\\lambda y_2} \\cdot \\dots \\cdot \\lambda e^{-\\lambda y_n}.\n\\]\nRaccogliendo i termini comuni, possiamo riscrivere la funzione di verosimiglianza come:\n\\[\nf(y \\mid \\lambda) = \\lambda^n e^{-\\lambda (y_1 + y_2 + \\dots + y_n)}.\n\\]\nUtilizzando la notazione di sommatoria, possiamo esprimere la funzione di verosimiglianza in modo compatto come:\n\\[\nf(y \\mid \\lambda) = \\lambda^n e^{-\\lambda \\sum_{i=1}^{n} y_i}.\n\\]\nLa funzione di verosimiglianza \\(f(y \\mid \\lambda)\\) rappresenta la probabilità di osservare il campione \\(y_1, y_2, \\dots, y_n\\) dato un particolare valore del parametro \\(\\lambda\\). Un valore più alto della verosimiglianza indica una maggiore plausibilità del valore di \\(\\lambda\\), dato il campione osservato.\nSpesso è più conveniente lavorare con il logaritmo della funzione di verosimiglianza, poiché il logaritmo trasforma i prodotti in somme, semplificando i calcoli. Il logaritmo della funzione di verosimiglianza è:\n\\[\n\\log L(\\lambda \\mid y_1, y_2, \\dots, y_n) = n \\log \\lambda - \\lambda \\sum_{i=1}^{n} y_i.\n\\]\nQuesta forma semplificata della log-verosimiglianza è utile per stimare il parametro \\(\\lambda\\) tramite tecniche come la massimizzazione della verosimiglianza.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Modello gamma-esponenziale 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_gamma_exponential_model.html#aggiornare-le-nostre-credenze-con-linferenza-bayesiana",
    "href": "chapters/bayesian_inference/10_gamma_exponential_model.html#aggiornare-le-nostre-credenze-con-linferenza-bayesiana",
    "title": "50  Modello gamma-esponenziale 🔸",
    "section": "\n50.2 Aggiornare le Nostre Credenze con l’Inferenza Bayesiana",
    "text": "50.2 Aggiornare le Nostre Credenze con l’Inferenza Bayesiana\nNell’approccio bayesiano, non consideriamo solo i dati, ma anche le nostre conoscenze a priori sul parametro \\(\\lambda\\). Assegniamo a \\(\\lambda\\) una distribuzione a priori, tipicamente una distribuzione Gamma. Combinando la verosimiglianza con la distribuzione a priori, otteniamo la distribuzione a posteriori di \\(\\lambda\\), che rappresenta la nostra conoscenza aggiornata alla luce dei dati. La proprietà della coniugazione assicura che la distribuzione a posteriori sia anch’essa una Gamma, facilitando i calcoli.\nPer fare un esempio concreto, simuleremo un campione di dati. Immaginiamo di raccogliere dati che rappresentano il tempo, misurato in ore, che intercorre tra episodi di ansia in individui con disturbi d’ansia. La distribuzione esponenziale può essere utilizzata per modellare questo tempo di attesa tra un episodio di ansia e il successivo. Ad esempio, possiamo ipotizzare che, una volta concluso un episodio, l’insorgenza del prossimo segua un processo stocastico con un tasso costante, indipendentemente dal tempo trascorso dall’episodio precedente. In questo contesto, il parametro \\(\\lambda\\) della distribuzione esponenziale rappresenta il tasso medio di occorrenza degli episodi di ansia, ossia quanti episodi ci si aspetta in media in una certa unità di tempo (ad esempio, in un giorno).\nSe \\(\\lambda\\) è elevato, ciò indica che gli episodi di ansia sono più frequenti, con tempi di attesa più brevi tra un episodio e l’altro.\n\n# Impostiamo il seed per rendere i risultati riproducibili\nset.seed(42)\n\n# Parametro medio (tempo medio di attesa in ore)\nmean_time &lt;- 3.0\nlambda_param &lt;- 1 / mean_time # Parametro lambda per la distribuzione esponenziale\n\n# Numero di osservazioni nel campione\nn &lt;- 15\n\n# Generazione del campione casuale\ny &lt;- round(rexp(n, rate = lambda_param))\ny\n#&gt;  [1] 1 2 1 0 1 4 1 1 4 2 4 7 0 0 4\n\nImmaginiamo che questi dati rappresentino il tempo di attesa in ore tra episodi di ansia in 15 individui con disturbi d’ansia. Il tempo di attesa medio è:\n\nmean_time_observed &lt;- mean(y)\nmean_time_observed\n#&gt; [1] 2.13\n\nIl tasso di occorrenza, \\(\\lambda\\), calcolato sulla base dei dati osservati è:\n\nlambda_estimated &lt;- 1 / mean_time_observed\nlambda_estimated\n#&gt; [1] 0.469\n\nOra possiamo procedere a trovare la distribuzione a posteriori per il tasso di occorrenza \\(\\lambda\\).\n\n50.2.1 Passi per definire un prior debolmente informativo\nIl primo passo consiste nel definire una distribuzione a priori per \\(\\lambda\\), il tasso di occorrenza degli episodi di ansia in individui con disturbi d’ansia. Se disponiamo di poche informazioni a priori riguardo al valore di \\(\\lambda\\), possiamo adottare una distribuzione a priori debolmente informativa. Un prior debolmente informativo ha lo scopo di esercitare una minima influenza sull’inferenza, consentendo ai dati osservati di guidare principalmente la stima del parametro.\nLa distribuzione a priori coniugata per la distribuzione esponenziale è la distribuzione Gamma. Un prior debolmente informativo per \\(\\lambda\\) potrebbe essere impostato in modo tale da riflettere una conoscenza vaga, con una media che rappresenta un tempo di attesa ragionevole (basato su qualche informazione preliminare o ipotesi generale), ma con una varianza ampia, in modo da non vincolare eccessivamente l’inferenza.\nSupponiamo di voler impostare una distribuzione a priori per il tasso di occorrenza \\(\\lambda\\), in modo tale che il tempo medio di attesa sia 3.33 ore, con una deviazione standard ampia, ad esempio 5 ore. Poiché \\(\\lambda\\) rappresenta il tasso di occorrenza (ovvero l’inverso del tempo medio di attesa), dobbiamo applicare la distribuzione Gamma ai valori di \\(\\lambda\\), non direttamente ai tempi di attesa.\nI parametri della distribuzione Gamma, \\(\\alpha\\) (forma) e \\(\\beta\\) (tasso), sono dati da:\n\n\\(\\alpha_{\\text{prior}} = 0.45\\)\n\\(\\beta_{\\text{prior}} = 1.5\\)\n\nVerifichiamo che questi parametri corrispondano alla media e alla varianza desiderate.\n\n# Parametri della distribuzione Gamma\nalpha_prior &lt;- 0.45 # Forma\nbeta_prior &lt;- 1.5 # Tasso (inverso della scala)\n\n# Calcolo della media e della varianza della distribuzione Gamma per λ\nmean_lambda &lt;- alpha_prior / beta_prior\nvariance_lambda &lt;- alpha_prior / (beta_prior^2)\n\n# Calcolo della media del tempo di attesa (E[Y] = 1 / E[λ])\nmean_waiting_time &lt;- 1 / mean_lambda\n\n# Stampiamo la media e la varianza di λ e del tempo di attesa\ncat(\"Media di λ:\", mean_lambda, \"\\n\")\n#&gt; Media di λ: 0.3\ncat(\"Varianza di λ:\", variance_lambda, \"\\n\")\n#&gt; Varianza di λ: 0.2\ncat(\"Media del tempo di attesa:\", mean_waiting_time, \"ore\\n\")\n#&gt; Media del tempo di attesa: 3.33 ore\n\nLa media del tempo di attesa è 3.33 ore, come desiderato. La varianza del tempo di attesa richiede un calcolo più complesso e non è semplicemente l’inverso della varianza di \\(\\lambda\\).\n\n50.2.2 Visualizzazione della Distribuzione a Priori\nDisegniamo la funzione di densità della distribuzione Gamma per \\(\\lambda\\), utilizzando i parametri specificati.\n\n# Creazione dei valori x per il grafico\nx &lt;- seq(0, 2, length.out = 500)\n\n# Funzione di densità della distribuzione Gamma con i parametri dati\ngamma_pdf &lt;- dgamma(x, shape = alpha_prior, rate = beta_prior)\n\n# Creazione del grafico\nplot(x, gamma_pdf,\n  type = \"l\", lwd = 2,\n  main = bquote(\"Funzione di Densità Gamma con \" ~ alpha == .(alpha_prior) ~ \",\" ~ beta == .(beta_prior)),\n  xlab = expression(lambda),\n  ylab = \"Densità di probabilità\"\n)\nlegend(\n  \"topright\",\n  legend = \"Distribuzione a Priori\",\n  lty = 1,\n  lwd = 2,\n  bty = \"n\"\n)",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Modello gamma-esponenziale 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_gamma_exponential_model.html#metodo-basato-su-griglia",
    "href": "chapters/bayesian_inference/10_gamma_exponential_model.html#metodo-basato-su-griglia",
    "title": "50  Modello gamma-esponenziale 🔸",
    "section": "\n50.3 Metodo Basato su Griglia",
    "text": "50.3 Metodo Basato su Griglia\nPoniamoci l’obiettivo di utilizzare il metodo basato su griglia per derivare la distribuzione a posteriori del parametro \\(\\lambda\\) della distribuzione esponenziale. Iniziamo creando una griglia per \\(\\lambda\\) nell’intervallo [0.01, 2].\n\n# Evitiamo zero per evitare divisione per zero\nlambda_grid &lt;- seq(0.01, 2, length.out = 1000)\n\n\n50.3.1 Calcolo della Distribuzione a Priori\n\n# Calcolo della distribuzione a priori\nprior &lt;- dgamma(lambda_grid, shape = alpha_prior, rate = beta_prior)\n\n\n50.3.2 Calcolo della Verosimiglianza\nImmaginiamo di avere i seguenti dati, che rappresentano i tempi di attesa (in ore) tra episodi di ansia per 15 individui:\n\n# Impostiamo il seed per rendere i risultati riproducibili\nset.seed(42)\n\n# Parametro medio (tempo medio di attesa in ore)\nmean_time &lt;- 3.0\nlambda_param &lt;- 1 / mean_time # Parametro λ per la distribuzione esponenziale\n\n# Numero di osservazioni nel campione\nn &lt;- 15\n\n# Generazione del campione casuale\ny &lt;- round(rexp(n, rate = lambda_param))\ny\n#&gt;  [1] 1 2 1 0 1 4 1 1 4 2 4 7 0 0 4\n\nCalcoliamo la log-verosimiglianza per ciascun valore di \\(\\lambda\\) nella griglia:\n\n# Calcolo della log-verosimiglianza per ciascun valore di lambda\nlog_likelihood &lt;- sapply(\n  lambda_grid,\n  function(lam) sum(dexp(y, rate = lam, log = TRUE))\n)\n\n\n50.3.3 Calcolo della Distribuzione a Posteriori\nCalcoliamo la distribuzione a posteriori non normalizzata in logaritmo per evitare problemi di underflow numerico:\n\n# Calcolo del log-posteriori non normalizzato\nlog_posterior_unnormalized &lt;- log_likelihood + log(prior)\n\n# Normalizzazione per stabilità numerica\nlog_posterior_unnormalized &lt;- log_posterior_unnormalized - max(log_posterior_unnormalized)\n\n# Convertiamo in scala normale\nposterior_unnormalized &lt;- exp(log_posterior_unnormalized)\n\nNormalizziamo la distribuzione a posteriori:\n\n# Calcolo del passo nella griglia\ndelta_lambda &lt;- diff(lambda_grid)[1] # Assumendo che la griglia sia equispaziata\n\n# Normalizzazione della distribuzione a posteriori\nposterior &lt;-\n  posterior_unnormalized / sum(posterior_unnormalized * delta_lambda)\n\n\n50.3.4 Visualizzazione dei Risultati\n\n# Grafico della distribuzione a posteriori e a priori\nplot(lambda_grid, posterior,\n  type = \"l\",\n  lwd = 2,\n  xlab = expression(lambda),\n  ylab = \"Densità di probabilità\",\n  main = \"Distribuzione a Posteriori di λ\"\n)\nlines(lambda_grid, prior, lwd = 2, lty = 2)\nlegend(\"topright\",\n  legend = c(\"Posteriori\", \"Priori\"),\n  lty = c(1, 2), \n  lwd = 2, \n  bty = \"n\"\n)\n\n\n\n\n\n\n\nDal grafico, possiamo osservare come la distribuzione a posteriori di \\(\\lambda\\) sia aggiornata rispetto alla distribuzione a priori in base ai dati osservati. La distribuzione a posteriori riflette sia le informazioni a priori sia l’evidenza fornita dai dati, fornendo una stima aggiornata del tasso di occorrenza degli episodi di ansia.\n\n50.3.5 Calcolo della Media e Varianza Posteriori\nPossiamo calcolare la media e la varianza a posteriori di \\(\\lambda\\) utilizzando la distribuzione a posteriori calcolata sulla griglia.\n\n# Calcolo della media a posteriori di λ\nposterior_mean_lambda &lt;- sum(lambda_grid * posterior * delta_lambda)\n\n# Calcolo della varianza a posteriori di λ\nposterior_variance_lambda &lt;-\n  sum((lambda_grid - posterior_mean_lambda)^2 * posterior * delta_lambda)\n\n# Stampiamo i risultati\ncat(\"Media a posteriori di λ:\", posterior_mean_lambda, \"\\n\")\n#&gt; Media a posteriori di λ: 0.461\ncat(\"Varianza a posteriori di λ:\", posterior_variance_lambda, \"\\n\")\n#&gt; Varianza a posteriori di λ: 0.0138\n\n\n50.3.6 Stima del Tempo di Attesa Medio a Posteriori\nUtilizzando la media a posteriori di \\(\\lambda\\), possiamo stimare il tempo di attesa medio a posteriori:\n\n# Stima del tempo di attesa medio a posteriori\nposterior_mean_waiting_time &lt;- 1 / posterior_mean_lambda\ncat(\"Tempo di attesa medio a posteriori:\", posterior_mean_waiting_time, \"ore\\n\")\n#&gt; Tempo di attesa medio a posteriori: 2.17 ore\n\nIn conclusione, attraverso il metodo basato su griglia, abbiamo derivato la distribuzione a posteriori del tasso di occorrenza \\(\\lambda\\), tenendo conto della nostra conoscenza a priori e dei dati osservati. Questo approccio ci permette di aggiornare le nostre credenze su \\(\\lambda\\) in modo coerente con l’evidenza empirica, fornendo stime più accurate e affidabili.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Modello gamma-esponenziale 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_gamma_exponential_model.html#modello-coniugato-gamma-esponenziale",
    "href": "chapters/bayesian_inference/10_gamma_exponential_model.html#modello-coniugato-gamma-esponenziale",
    "title": "50  Modello gamma-esponenziale 🔸",
    "section": "\n50.4 Modello Coniugato Gamma-Esponenziale",
    "text": "50.4 Modello Coniugato Gamma-Esponenziale\nQuando utilizziamo una distribuzione \\(\\text{Gamma}(\\alpha, \\beta)\\) come distribuzione coniugata a priori, la distribuzione a posteriori risulta anch’essa essere una distribuzione Gamma, con parametri aggiornati \\(\\alpha + n\\) e \\(\\beta + \\sum_{i=1}^{n} x_{i}\\).\nIn altre parole, se il parametro \\(\\lambda\\) della distribuzione esponenziale segue una distribuzione a priori Gamma con parametri \\(\\alpha\\) e \\(\\beta\\), allora, dopo aver osservato un campione di \\(n\\) osservazioni \\(x_1, x_2, \\dots, x_n\\), la distribuzione a posteriori di \\(\\lambda\\) sarà ancora una distribuzione Gamma, ma con i parametri aggiornati:\n\\[\n\\lambda \\mid x \\sim \\text{Gamma}(\\alpha + n, \\beta + \\sum_{i=1}^{n} x_{i}).\n\\]\nQuesto aggiornamento dei parametri è una conseguenza della proprietà coniugata della distribuzione Gamma rispetto alla distribuzione esponenziale.\n\n50.4.1 Dimostrazione del Modello Coniugato Gamma-Esponenziale\nPer dimostrare questo risultato, partiamo dal teorema di Bayes:\n\\[\nf(\\lambda \\mid x) \\propto f(x \\mid \\lambda) \\cdot f(\\lambda),\n\\]\ndove \\(f(\\lambda \\mid x)\\) è la distribuzione a posteriori di \\(\\lambda\\) dato il campione \\(x\\), \\(f(x \\mid \\lambda)\\) è la verosimiglianza basata sul campione \\(x\\), e \\(f(\\lambda)\\) è la distribuzione a priori di \\(\\lambda\\).\nLa funzione di verosimiglianza per un campione di \\(n\\) osservazioni indipendenti \\(x_1, x_2, \\dots, x_n\\), che seguono una distribuzione esponenziale con parametro \\(\\lambda\\), è data da:\n\\[\nf(x \\mid \\lambda) = \\prod_{i=1}^{n} \\lambda e^{-\\lambda x_i} = \\lambda^n e^{-\\lambda \\sum_{i=1}^{n} x_i}.\n\\]\nSupponiamo che il parametro \\(\\lambda\\) segua una distribuzione a priori Gamma con parametri \\(\\alpha\\) e \\(\\beta\\):\n\\[\nf(\\lambda) = \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)} \\lambda^{\\alpha - 1} e^{-\\beta \\lambda}.\n\\]\nMoltiplicando la verosimiglianza per la distribuzione a priori, otteniamo la distribuzione a posteriori:\n\\[\nf(\\lambda \\mid x) \\propto \\lambda^n e^{-\\lambda \\sum_{i=1}^{n} x_i} \\cdot \\lambda^{\\alpha - 1} e^{-\\beta \\lambda}.\n\\]\nSemplificando, si ottiene:\n\\[\nf(\\lambda \\mid x) \\propto \\lambda^{n + \\alpha - 1} e^{-\\lambda \\left(\\beta + \\sum_{i=1}^{n} x_i\\right)}.\n\\]\nQuesta espressione corrisponde alla forma di una distribuzione Gamma con parametri aggiornati:\n\nparametro della forma (alpha): \\(\\alpha_{\\text{post}} = \\alpha + n\\);\nparametro della scala (beta): \\(\\beta_{\\text{post}} = \\beta + \\sum_{i=1}^{n} x_i\\).\n\nQuindi, la distribuzione a posteriori di \\(\\lambda\\) dato il campione \\(x\\) segue una distribuzione Gamma con parametri aggiornati:\n\\[\n\\lambda \\mid x \\sim \\text{Gamma}(\\alpha + n, \\beta + \\sum_{i=1}^{n} x_i).\n\\]\nQuesta derivazione mostra come l’informazione contenuta nei dati osservati venga incorporata nei parametri della distribuzione a posteriori, mantenendo la forma della distribuzione a priori grazie alla proprietà coniugata.\n\n50.4.2 Calcolo dei Parametri Aggiornati\nPer il caso dell’esempio in discussione:\n\nIl numero di osservazioni nel campione \\(n\\) è 15;\nLa somma delle osservazioni nel campione è:\n\n\\[\n\\sum_{i=1}^{n} y_i =\n1 + 9 + 4 + 3 + 1 + 1 + 0 + 6 + 3 + 4 + 0 + 11 + 5 + 1 + 1 = 50.\n\\]\nLa distribuzione a posteriori per \\(\\lambda\\) segue una distribuzione Gamma aggiornata con i seguenti parametri:\n\\[\n\\alpha_{\\text{post}} = \\alpha_{\\text{prior}} + n,\n\\]\n\\[\n\\beta_{\\text{post}} = \\beta_{\\text{prior}} + \\sum_{i=1}^{n} y_i.\n\\]\nUsando i valori \\(\\alpha_{\\text{prior}} = 0.009\\) e \\(\\beta_{\\text{prior}} = 0.03\\), otteniamo:\n\\[\n\\alpha_{\\text{post}} = 0.009 + 15 = 15.009,\n\\]\n\\[\n\\beta_{\\text{post}} = 0.03 + 50 = 50.03.\n\\]\n\n# Dati iniziali\nalpha_prior &lt;- 0.009\nbeta_prior &lt;- 0.03\nn &lt;- 15\ny &lt;- c(1, 9, 4, 3, 1, 1, 0, 6, 3, 4, 0, 11, 5, 1, 1)\nsum_y &lt;- sum(y)\n\n# Parametri aggiornati\nalpha_post &lt;- alpha_prior + n\nbeta_post &lt;- beta_prior + sum_y\n\n# Stampa dei parametri aggiornati\ncat(sprintf(\"alpha_post = %.3f; beta_post = %.3f\\n\", alpha_post, beta_post))\n#&gt; alpha_post = 15.009; beta_post = 50.030\n\nGeneriamo il grafico della distribuzione a posteriori.\n\n# Griglia di valori di lambda per il grafico\nlambda_grid &lt;- seq(0, 2, length.out = 1000)\n\n# Calcolo della densità della distribuzione Gamma a posteriori\nposterior_pdf &lt;- dgamma(lambda_grid, shape = alpha_post, rate = beta_post)\n\n# Creazione del grafico\nplot(\n  lambda_grid, posterior_pdf,\n  type = \"l\", lwd = 2,\n  main = bquote(\n    \"Distribuzione Gamma a Posteriori con \" ~ alpha[post] ==\n      .(alpha_post) ~ \",\" ~ beta[post] == .(beta_post)\n  ),\n  xlab = expression(lambda), ylab = \"Densità di probabilità\"\n)\nlegend(\n  \"topright\",\n  legend = bquote(\n    Gamma(alpha[post] == .(alpha_post) ~ \",\" ~ beta[post] == .(beta_post))\n  ),\n  lty = 1,\n  lwd = 2,\n  bty = \"n\"\n)\n\n\n\n\n\n\n\n\n50.4.3 Calcolo della Media e della Varianza a Posteriori\nLa media e la varianza della distribuzione a posteriori sono calcolate come:\n\\[\n\\text{E}[\\lambda \\mid y] = \\frac{\\alpha_{\\text{post}}}{\\beta_{\\text{post}}},\n\\]\n\\[\n\\text{Var}[\\lambda \\mid y] = \\frac{\\alpha_{\\text{post}}}{\\beta_{\\text{post}}^2}.\n\\]\nIn R:\n\n# Calcolo della media e della varianza a posteriori\nposterior_mean &lt;- alpha_post / beta_post\nposterior_variance &lt;- alpha_post / (beta_post^2)\n\n# Stampa dei risultati\ncat(sprintf(\"Media a posteriori di λ: %.3f\\n\", posterior_mean))\n#&gt; Media a posteriori di λ: 0.300\ncat(sprintf(\"Varianza a posteriori di λ: %.6f\\n\", posterior_variance))\n#&gt; Varianza a posteriori di λ: 0.005996\n\nLa distribuzione a posteriori di \\(\\lambda\\) è aggiornata in base ai dati osservati e al prior. La media a posteriori rappresenta la stima del tasso di occorrenza degli episodi di ansia, mentre la varianza riflette l’incertezza nella stima.\n\n\nMedia a Posteriori: La media a posteriori di \\(\\lambda\\) è circa 0.3, indicando un tasso di occorrenza medio di 0.3 episodi per ora.\n\nVarianza a Posteriori: La varianza di 0.006 riflette una moderata incertezza nella stima di \\(\\lambda\\).\n\nQuesti risultati evidenziano come la distribuzione Gamma aggiornata combini informazioni a priori e dati osservati per ottenere stime robuste del tasso di occorrenza \\(\\lambda\\).\n\n50.4.4 Trasformazione della media e della varianza\nPer interpretare questi risultati in termini di tempi di attesa, dobbiamo trasformare i valori sulla scala inversa, cioè passare dal tasso \\(\\lambda\\) ai tempi di attesa \\(T = \\frac{1}{\\lambda}\\).\nLa media del tempo di attesa \\(T\\) è l’inverso della media del tasso di occorrenza \\(\\lambda\\). Pertanto, la media dei tempi di attesa sarà:\n\\[\n\\text{E}[T \\mid y] = \\frac{1}{\\text{E}[\\lambda \\mid y]} = \\frac{1}{0.3} \\approx 3.33 \\, \\text{ore}.\n\\]\nPer la varianza del tempo di attesa, dobbiamo applicare una trasformazione più complessa. La varianza del tempo di attesa \\(T\\) è legata alla varianza di \\(\\lambda\\) da:\n\\[\n\\text{Var}(T) = \\frac{\\text{Var}[\\lambda \\mid y]}{(\\text{E}[\\lambda \\mid y])^4}.\n\\]\nSostituendo i valori calcolati per la varianza e la media di \\(\\lambda\\), otteniamo:\n\\[\n\\text{Var}(T) \\approx \\frac{0.006}{(0.3)^4} \\approx 24.59 \\, \\text{ore}.\n\\]\nIn conclusione,\n\nla media del tempo di attesa a posteriori è di circa 3.33 ore;\nla varianza del tempo di attesa a posteriori è di circa 24.59 ore, che indica una certa dispersione dei tempi di attesa, con alcuni episodi che possono verificarsi molto più rapidamente o più lentamente rispetto alla media. Si noti che la distribuzione a posteriori è più concentrata rispetto al prior, poiché incorpora l’informazione aggiuntiva proveniente dai dati osservati.\n\nQuesta trasformazione ci permette di interpretare i risultati sulla scala dei tempi di attesa, che è più intuitiva per descrivere fenomeni psicologici come l’insorgenza di episodi di ansia.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Modello gamma-esponenziale 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_gamma_exponential_model.html#applicazioni",
    "href": "chapters/bayesian_inference/10_gamma_exponential_model.html#applicazioni",
    "title": "50  Modello gamma-esponenziale 🔸",
    "section": "\n50.5 Applicazioni",
    "text": "50.5 Applicazioni\nUna volta ottenuta la distribuzione a posteriori per λ, possiamo utilizzarla per rispondere a domande probabilistiche relative ai tempi di attesa tra episodi di ansia. Questo approccio ci consente di calcolare probabilità aggiornate alla luce dei dati osservati, rispecchiando meglio l’incertezza e le informazioni disponibili. Ad esempio, possiamo stimare la probabilità di osservare tempi di attesa compresi tra 2 e 5 ore.\nPer risolvere questo problema possiamo usare il metodo Monte Carlo:\n\nGeneriamo un gran numero di campioni dalla distribuzione Gamma a posteriori di \\(\\lambda\\), usando i parametri \\(\\alpha_{\\text{posteriori}}\\) e \\(\\beta_{\\text{posteriori}}\\).\nConvertiamo ciascun \\(\\lambda\\) campionato in un tempo di attesa \\(T = \\frac{1}{\\lambda}\\).\nCalcoliamo le probabilità richieste (ad esempio, \\(P(T &gt; 2)\\) e \\(P(T &lt; 5)\\)) semplicemente contando le proporzioni di campioni che soddisfano tali condizioni.\n\n\n50.5.1 Simulazione con Monte Carlo\nUtilizziamo i parametri posteriori della distribuzione Gamma per simulare campioni di \\(\\lambda\\) e calcolare la probabilità che il tempo di attesa tra due episodi di ansia sia compreso tra 2 e 5 ore.\n\n# Parametri posteriori per la distribuzione Gamma\nalpha_post &lt;- 15.009\nbeta_post &lt;- 50.03\n\n# Numero di campioni da generare\nn_samples &lt;- 100000\n\n# Simulazione di campioni dalla distribuzione Gamma per λ\nlambda_samples &lt;- rgamma(n_samples, shape = alpha_post, rate = beta_post)\n\n# Conversione dei campioni di λ in tempi di attesa T = 1/λ\nwaiting_time_samples &lt;- 1 / lambda_samples\n\n# Calcolo della probabilità che il tempo di attesa sia compreso tra 2 e 5 ore\nprob_between_2_and_5_mc &lt;-\n  mean(waiting_time_samples &gt;= 2 & waiting_time_samples &lt;= 5)\n\n# Stampa del risultato\ncat(sprintf(\"Probabilità che il tempo di attesa sia tra 2 e 5 ore: %.4f\\n\", prob_between_2_and_5_mc))\n#&gt; Probabilità che il tempo di attesa sia tra 2 e 5 ore: 0.9027\n\nLa probabilità che il tempo di attesa tra due episodi di ansia sia compreso tra 2 e 5 ore è di circa 0.9029, ovvero il 90.3%. Questa stima si basa su campioni simulati dalla distribuzione a posteriori di \\(\\lambda\\), trasformati nei corrispondenti tempi di attesa. L’approccio Monte Carlo è utile per calcolare probabilità che coinvolgono trasformazioni non lineari, come nel caso del tempo di attesa.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Modello gamma-esponenziale 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_gamma_exponential_model.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/10_gamma_exponential_model.html#riflessioni-conclusive",
    "title": "50  Modello gamma-esponenziale 🔸",
    "section": "\n50.6 Riflessioni Conclusive",
    "text": "50.6 Riflessioni Conclusive\nIl modello esponenziale si rivela uno strumento utile e versatile nella ricerca psicologica, in particolare per la modellazione di fenomeni caratterizzati da tempi di attesa o durate di eventi. È applicabile in vari contesti, tra cui l’analisi dei tempi di reazione, lo studio degli intervalli tra episodi di ansia o depressione e, più in generale, in tutti quei processi psicologici che possono essere descritti come il tempo trascorso fino al verificarsi di un evento.\nUn aspetto particolarmente vantaggioso dell’uso di modelli basati sulla distribuzione esponenziale nell’inferenza bayesiana è la possibilità di utilizzare le famiglie coniugate. Nella famiglia coniugata Gamma-Esponenziale, la distribuzione a priori Gamma per il tasso \\(\\lambda\\) si aggiorna in modo analitico quando si osservano nuovi dati esponenziali. Questo rende i calcoli bayesiani particolarmente efficienti e semplici da implementare, poiché la distribuzione a posteriori rimane della stessa forma della distribuzione a priori (ossia, una Gamma). Tale proprietà coniugata consente di ottenere una stima aggiornata del tasso \\(\\lambda\\) e di fare inferenze accurate sui tempi di attesa futuri.\nLa combinazione tra la distribuzione esponenziale e il prior Gamma non solo semplifica l’inferenza, ma fornisce anche una struttura interpretativa chiara. Ad esempio, il parametro \\(\\lambda\\), che rappresenta il tasso di occorrenza di un fenomeno, viene aggiornato sulla base dell’evidenza osservata, consentendo una stima dinamica della frequenza con cui gli episodi si verificano. Questo approccio bayesiano offre un’interpretazione probabilistica naturale dei tempi di attesa futuri, rispecchiando l’incertezza presente nei dati.\nInoltre, grazie alla flessibilità del metodo Monte Carlo, è possibile simulare campioni dalla distribuzione a posteriori di \\(\\lambda\\) e ottenere stime precise per una vasta gamma di probabilità, come la probabilità che il tempo di attesa sia compreso tra intervalli specifici. Questo approccio simulativo permette di rispondere a domande specifiche relative ai processi psicologici, ad esempio la probabilità che un episodio di ansia duri più di un certo numero di ore.\nIn conclusione, il modello esponenziale, integrato in un framework bayesiano con famiglie coniugate, rappresenta un utile strumento per la ricerca psicologica. Offre un modo rigoroso per modellare e analizzare dati su tempi di attesa e durate, fornendo al contempo una base solida per l’inferenza e la previsione dei processi psicologici.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Modello gamma-esponenziale 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_gamma_exponential_model.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/10_gamma_exponential_model.html#informazioni-sullambiente-di-sviluppo",
    "title": "50  Modello gamma-esponenziale 🔸",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] see_0.9.0        gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1\n#&gt;  [5] psych_2.4.12     scales_1.3.0     markdown_1.13    knitr_1.49      \n#&gt;  [9] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [13] purrr_1.0.2      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [17] ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.3         rlang_1.1.4       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       tools_4.4.2       parallel_4.4.2    tzdb_0.4.0       \n#&gt; [21] colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5       R6_2.5.1         \n#&gt; [25] lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.0    \n#&gt; [29] gtable_0.3.6      glue_1.8.0        xfun_0.49         tidyselect_1.2.1 \n#&gt; [33] farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-166      rmarkdown_2.29   \n#&gt; [37] compiler_4.4.2",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Modello gamma-esponenziale 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_post_pred_distr.html",
    "href": "chapters/bayesian_inference/11_post_pred_distr.html",
    "title": "51  Distribuzione predittiva a posteriori",
    "section": "",
    "text": "51.1 Introduzione\nNel contesto dell’inferenza bayesiana, uno degli obiettivi principali è non solo stimare i parametri di un modello (ad esempio, la probabilità \\(p\\) di successo in un esperimento binomiale) ma anche fare previsioni su dati futuri basandosi su ciò che abbiamo osservato. La distribuzione predittiva a posteriori risponde proprio a questa esigenza, combinando:\nIn termini semplici, la distribuzione predittiva a posteriori ci dice quali risultati futuri sono plausibili, dato ciò che sappiamo dai dati osservati e dal modello.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_post_pred_distr.html#introduzione",
    "href": "chapters/bayesian_inference/11_post_pred_distr.html#introduzione",
    "title": "51  Distribuzione predittiva a posteriori",
    "section": "",
    "text": "La nostra incertezza sui parametri descritta dalla distribuzione a posteriori.\nLa variabilità intrinseca del processo che genera i dati futuri.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_post_pred_distr.html#definizione-formale",
    "href": "chapters/bayesian_inference/11_post_pred_distr.html#definizione-formale",
    "title": "51  Distribuzione predittiva a posteriori",
    "section": "\n51.2 Definizione Formale",
    "text": "51.2 Definizione Formale\nSupponiamo di avere un insieme di dati osservati \\(y = \\{y_1, y_2, \\ldots, y_n\\}\\), generati da un modello che dipende da un parametro sconosciuto \\(\\theta\\). Il parametro \\(\\theta\\) può rappresentare qualsiasi caratteristica del modello, come una probabilità di successo, una media, o un coefficiente in un modello di regressione. Inizialmente, la nostra conoscenza su \\(\\theta\\) è rappresentata dalla distribuzione a priori \\(p(\\theta)\\), che riflette ciò che sappiamo (o non sappiamo) su \\(\\theta\\) prima di osservare i dati.\nDopo aver osservato i dati \\(y\\), possiamo aggiornare la nostra conoscenza su \\(\\theta\\) utilizzando la formula di Bayes per calcolare la distribuzione a posteriori \\(p(\\theta \\mid y)\\):\n\\[\np(\\theta \\mid y) = \\frac{p(y \\mid \\theta) p(\\theta)}{p(y)},\n\\]\ndove:\n\n\\(p(\\theta \\mid y)\\): la distribuzione a posteriori rappresenta la nostra conoscenza aggiornata su \\(\\theta\\) dopo aver osservato i dati.\n\\(p(y \\mid \\theta)\\): la verosimiglianza è la probabilità di osservare i dati dati i parametri del modello.\n\\(p(\\theta)\\): la distribuzione a priori rappresenta la conoscenza iniziale su \\(\\theta\\).\n\n\\(p(y)\\): l’evidenza è la probabilità totale dei dati osservati, calcolata come:\n\\[\np(y) = \\int p(y \\mid \\theta) p(\\theta) \\, d\\theta.\n\\]\n\n\n\n\n51.2.1 Previsione di Nuovi Dati\n\nQuando vogliamo prevedere un nuovo dato, indicato con \\(\\tilde{y}\\), la nostra attenzione si sposta sulla distribuzione predittiva a posteriori, \\(p(\\tilde{y} \\mid y)\\).\n\n51.2.1.1 Cosa rappresenta \\(\\tilde{y}\\)?\n\n\n\\(\\tilde{y}\\) rappresenta un dato futuro o non osservato. Ad esempio, se i dati \\(y\\) rappresentano il numero di successi osservati in una serie di lanci di una moneta, \\(\\tilde{y}\\) potrebbe rappresentare il numero di successi in una nuova serie di lanci.\nL’obiettivo è stimare \\(p(\\tilde{y} \\mid y)\\), cioè la probabilità del nuovo dato \\(\\tilde{y}\\) dato ciò che abbiamo osservato in \\(y\\).\n\n51.2.1.2 Cosa rappresenta \\(p(\\tilde{y} \\mid \\theta)\\)?\n\n\n\\(p(\\tilde{y} \\mid \\theta)\\) è la probabilità del nuovo dato \\(\\tilde{y}\\) dato un particolare valore del parametro \\(\\theta\\).\nAd esempio, in un modello binomiale, \\(p(\\tilde{y} \\mid \\theta)\\) corrisponde alla probabilità di ottenere \\(\\tilde{y}\\) successi su \\(n_{\\text{new}}\\) prove, data la probabilità di successo \\(\\theta\\).\n\n51.2.1.3 Combinazione di \\(p(\\tilde{y} \\mid \\theta)\\) con \\(p(\\theta \\mid y)\\)\n\nPoiché non conosciamo esattamente \\(\\theta\\), dobbiamo considerare tutte le possibili ipotesi su \\(\\theta\\), pesandole in base alla loro probabilità a posteriori \\(p(\\theta \\mid y)\\). Questo porta alla formula per la distribuzione predittiva a posteriori:\n\\[\np(\\tilde{y} \\mid y) = \\int p(\\tilde{y} \\mid \\theta) p(\\theta \\mid y) \\, d\\theta.\n\\]\n\n51.2.1.4 Interpretazione\n\nLa distribuzione predittiva a posteriori, \\(p(\\tilde{y} \\mid y)\\), rappresenta la nostra miglior stima della probabilità del nuovo dato \\(\\tilde{y}\\), tenendo conto sia dei dati osservati \\(y\\) sia dell’incertezza su \\(\\theta\\).\n\n51.2.2 Caso Discreto\nSe il parametro \\(\\theta\\) assume un numero finito di valori, l’integrale si semplifica in una somma:\n\\[\np(\\tilde{y} \\mid y) = \\sum_{\\theta} p(\\tilde{y} \\mid \\theta) p(\\theta \\mid y).\n\\]\nQuesto approccio è utile nei modelli discreti o quando si approssimano i parametri con un numero finito di valori campionati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_post_pred_distr.html#il-caso-beta-binomiale",
    "href": "chapters/bayesian_inference/11_post_pred_distr.html#il-caso-beta-binomiale",
    "title": "51  Distribuzione predittiva a posteriori",
    "section": "\n51.3 Il Caso Beta-Binomiale",
    "text": "51.3 Il Caso Beta-Binomiale\nConsideriamo un classico esperimento binomiale: lanciare una moneta \\(n\\) volte e osservare il numero di successi \\(y\\) (ad esempio, il numero di “teste”). In un contesto bayesiano, il processo di analisi si articola in tre fasi:\n\n\nDistribuzione a Priori: Prima di osservare i dati, formuliamo una distribuzione a priori sulla probabilità \\(p\\) di successo, che riflette le nostre conoscenze iniziali (o la loro assenza). Una scelta comune è la distribuzione Beta(\\(\\alpha, \\beta\\)), perché è flessibile e ben definita per probabilità. Per esempio:\n\n\n\\(\\alpha\\) rappresenta il numero “fittizio” di successi osservati.\n\n\\(\\beta\\) rappresenta il numero “fittizio” di insuccessi osservati.\n\n\n\nDistribuzione a Posteriori: Dopo aver osservato \\(y\\) successi su \\(n\\) prove, aggiorniamo la distribuzione a priori combinandola con i dati osservati, ottenendo la distribuzione a posteriori di \\(p\\):\n\\[\n\\alpha_{\\text{post}} = \\alpha_{\\text{prior}} + y, \\quad \\beta_{\\text{post}} = \\beta_{\\text{prior}} + (n - y).\n\\]\nQuesta distribuzione rappresenta ciò che sappiamo di \\(p\\) dopo aver osservato i dati.\n\n\nDistribuzione Predittiva a Posteriori: Per prevedere il numero di successi futuri \\(y_{\\text{new}}\\) in un nuovo esperimento con \\(n_{\\text{new}}\\) prove, combiniamo la distribuzione a posteriori di \\(p\\) con la variabilità intrinseca del processo binomiale. In pratica:\n\nCampioniamo \\(p\\) dalla distribuzione a posteriori (\\(p \\sim \\text{Beta}(\\alpha_{\\text{post}}, \\beta_{\\text{post}})\\)).\nUsiamo ciascun campione di \\(p\\) per simulare nuovi dati (\\(y_{\\text{new}} \\sim \\text{Binomiale}(n_{\\text{new}}, p)\\)).\n\n\n\nQuesto processo tiene conto sia dell’incertezza sui parametri (\\(p\\)) sia della variabilità intrinseca nei dati futuri.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_post_pred_distr.html#simulazione-della-distribuzione-predittiva-a-posteriori",
    "href": "chapters/bayesian_inference/11_post_pred_distr.html#simulazione-della-distribuzione-predittiva-a-posteriori",
    "title": "51  Distribuzione predittiva a posteriori",
    "section": "\n51.4 Simulazione della Distribuzione Predittiva a Posteriori",
    "text": "51.4 Simulazione della Distribuzione Predittiva a Posteriori\n\n51.4.1 Impostazione dei Parametri\n\nSupponiamo di aver osservato \\(y = 70\\) successi su \\(n = 100\\) prove.\nUtilizziamo una distribuzione a priori Beta(\\(2, 2\\)), che rappresenta una conoscenza iniziale debolmente informativa, con una leggera preferenza per \\(p \\approx 0.5\\).\n\n51.4.2 Calcolo della Distribuzione a Posteriori\n\n\nAggiorniamo la distribuzione a priori con i dati osservati. I parametri aggiornati sono:\n\\[\n\\alpha_{\\text{post}} = \\alpha_{\\text{prior}} + y = 2 + 70 = 72, \\quad \\beta_{\\text{post}} = \\beta_{\\text{prior}} + (n - y) = 2 + 30 = 32.\n\\]\n\nLa distribuzione a posteriori è quindi \\(p \\sim \\text{Beta}(72, 32)\\), che descrive la probabilità aggiornata di successo basata sui dati.\n\n51.4.3 Simulazione dei Dati Futuri\n\nGeneriamo \\(n_{\\text{sim}} = 1000\\) campioni di \\(p\\) dalla distribuzione a posteriori Beta(72, 32).\n\nPer ogni campione di \\(p\\), simuliamo \\(y_{\\text{new}}\\), il numero di successi futuri su \\(n_{\\text{new}} = 10\\) prove, utilizzando la distribuzione binomiale:\n\\[\ny_{\\text{new}} \\sim \\text{Binomiale}(n_{\\text{new}} = 10, p).\n\\]\n\n\nInfine, convertiamo \\(y_{\\text{new}}\\) in proporzioni predette:\n\\[\n\\text{Proporzione predetta} = \\frac{y_{\\text{new}}}{n_{\\text{new}}}.\n\\]\n\n\n\n# Impostazione del seed per riproducibilità\nset.seed(123)\n\n# Parametri osservati\ny &lt;- 70\nn &lt;- 100\n\n# Parametri a priori\nalpha_prior &lt;- 2\nbeta_prior &lt;- 2\n\n# Calcolo dei parametri a posteriori\nalpha_post &lt;- alpha_prior + y\nbeta_post &lt;- beta_prior + (n - y)\n\n# Simulazione della distribuzione a posteriori\np_samples &lt;- rbeta(1000, alpha_post, beta_post)\n\n# Simulazione di nuovi dati per n_new = 10\ny_preds &lt;- sapply(p_samples, function(p) {\n  rbinom(1, 10, p)\n})\n\n# Calcolo delle proporzioni predette\nprop_preds &lt;- y_preds / 10\n\n\n51.4.4 Risultati Attesi\n\n\nDistribuzione a Posteriori di \\(p\\):\n\nCentrata attorno a \\(0.7\\), con una varianza ridotta grazie alla dimensione del campione \\(n = 100\\).\n\n\n\nDistribuzione Predittiva per \\(n_{\\text{new}} = 10\\):\n\nVariabilità più ampia rispetto a \\(p\\), dovuta al numero ridotto di prove (\\(n_{\\text{new}} = 10\\)).\nRiflette sia l’incertezza su \\(p\\) sia la variabilità intrinseca dei dati futuri.\n\n\n\n\n# Visualizzazione\npar(mfrow = c(1, 2))\ncurve(dbeta(x, alpha_prior, beta_prior), from = 0, to = 1, \n      main = \"Distribuzione a Priori\", col = \"blue\", lwd = 2)\ncurve(dbeta(x, alpha_post, beta_post), from = 0, to = 1, \n      main = \"Distribuzione a Posteriori\", col = \"red\", lwd = 2)\n\n\n\n\n\n\n\n\nhist(prop_preds, breaks = 20, col = \"lightblue\", freq = FALSE,\n     main = \"Distribuzione Predittiva (n_new = 10)\",\n     xlab = \"Proporzione di Successi\")\nabline(v = y / n, col = \"blue\", lwd = 3, lty = 2)\n\n\n\n\n\n\n\n\n51.4.5 Spiegazione del Codice\nSimulazione di nuovi dati per \\(n_{\\text{new}} = 10\\):\ny_preds &lt;- sapply(p_samples, function(p) {\n  rbinom(1, 10, p)\n})\n\n\np_samples contiene \\(1000\\) valori di \\(p\\) simulati dalla distribuzione Beta(72, 32).\nPer ciascun \\(p\\), rbinom(1, 10, p) genera un valore di \\(y_{\\text{new}}\\), simulando il numero di successi futuri su \\(n_{\\text{new}} = 10\\) prove.\n\nRisultato: un vettore di 1000 valori di \\(y_{\\text{new}}\\), uno per ciascun campione di \\(p\\).\nCalcolo delle proporzioni predette:\nprop_preds &lt;- y_preds / 10\n\nDivide ciascun valore di \\(y_{\\text{new}}\\) per \\(n_{\\text{new}} = 10\\), ottenendo le proporzioni di successi predette.\n\nRisultato: un vettore di 1000 proporzioni predette (\\(y_{\\text{new}} / n_{\\text{new}}\\)).\n\n51.4.6 Interpretazione\n\nLa distribuzione a posteriori di \\(p\\), Beta(72, 32), è centrata attorno a \\(p \\approx 0.7\\), coerente con i dati osservati (\\(y / n = 0.7\\)).\nLe proporzioni predette mostrano la variabilità combinata dell’incertezza su \\(p\\) (dalla distribuzione a posteriori) e della variabilità binomiale per un campione futuro di 10 prove.\nL’istogramma delle proporzioni predette è più ampio rispetto alla distribuzione a posteriori di \\(p\\), riflettendo l’incertezza aggiuntiva derivante dal numero ridotto di prove (\\(n_{\\text{new}} = 10\\)).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_post_pred_distr.html#posterior-predictive-check-pp-check",
    "href": "chapters/bayesian_inference/11_post_pred_distr.html#posterior-predictive-check-pp-check",
    "title": "51  Distribuzione predittiva a posteriori",
    "section": "\n51.5 Posterior Predictive Check (PP-Check)",
    "text": "51.5 Posterior Predictive Check (PP-Check)\nLa distribuzione predittiva a posteriori ottenuta dalla simulazione (\\(n_{\\text{new}} = 10\\)) può essere utilizzata per effettuare un Posterior Predictive Check (PP-Check). Questo controllo confronta i dati osservati con i dati simulati dal modello per verificare se il modello è in grado di riprodurre caratteristiche rilevanti dei dati osservati.\nIn questa simulazione, il Posterior Predictive-Check suggerisce che il modello è ben specificato per i dati osservati (\\(y = 70\\), \\(n = 100\\)): la proporzione osservata (\\(0.7\\)) è vicina al centro della distribuzione predittiva. Questo significa che il modello può essere considerato valido per fare previsioni sui dati futuri, almeno nel contesto specificato.\n\n\n\n\n\n\nIl fatto che la distribuzione predittiva a posteriori rappresenti accuratamente la proporzione osservata può sembrare ovvio nel caso presente. Questo avviene perché stiamo lavorando con un modello semplice e ben specificato, utilizzato qui con l’intento di chiarire la logica del concetto di distribuzione predittiva a posteriori. Tuttavia, nei modelli più complessi, tipici delle indagini psicologiche, la corrispondenza tra i dati osservati e quelli predetti dal modello non può mai essere data per scontata. È essenziale verificarla attraverso la distribuzione predittiva a posteriori.\nSe i dati osservati non sono ben rappresentati dalla distribuzione predittiva a posteriori, ciò indica che il modello non è adeguato a spiegare i dati e necessita di revisione. Questo processo di verifica non solo garantisce la coerenza del modello con i dati disponibili, ma consente anche di identificare eventuali aree problematiche nella specificazione del modello, come prior inappropriati o assunzioni non realistiche. In definitiva, il confronto tra i dati osservati e quelli predetti è un passo fondamentale per la validazione di modelli complessi in contesti psicologici e scientifici.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_post_pred_distr.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/11_post_pred_distr.html#riflessioni-conclusive",
    "title": "51  Distribuzione predittiva a posteriori",
    "section": "\n51.6 Riflessioni Conclusive",
    "text": "51.6 Riflessioni Conclusive\nLa distribuzione predittiva a posteriori è uno strumento centrale nell’inferenza bayesiana, poiché consente di fare previsioni sui dati futuri integrando l’incertezza sui parametri del modello con la variabilità intrinseca del processo generativo. Questa capacità va oltre la semplice stima dei parametri, permettendo di confrontare le previsioni del modello con i dati reali, un passaggio fondamentale per verificare la coerenza e l’utilità del modello stesso.\nNel flusso di lavoro bayesiano, la distribuzione predittiva a posteriori svolge un ruolo chiave nella valutazione del modello. Ad esempio, consente di effettuare controlli predittivi a posteriori per identificare discrepanze tra i dati osservati e quelli previsti. Tali controlli aiutano a diagnosticare problemi di specificazione del modello, a valutare l’adeguatezza delle scelte a priori e a guidare eventuali revisioni del modello.\nInoltre, il caso beta-binomiale utilizzato in questo capitolo rappresenta un esempio intuitivo e potente: evidenzia come l’incertezza sui parametri possa essere tradotta in previsioni probabilistiche robuste, senza la necessità di fare assunzioni rigide o non realistiche. Questo approccio non solo formalizza l’incertezza in modo rigoroso, ma permette anche di comunicare le previsioni in modo trasparente e interpretabile, caratteristiche essenziali in ambito decisionale e scientifico.\nIn sintesi, la distribuzione predittiva a posteriori è un elemento fondamentale della modellazione bayesiana, che lega l’inferenza paramatrica alla previsione empirica, contribuendo a rendere l’intero processo inferenziale più affidabile, interpretabile e applicabile a scenari complessi.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_post_pred_distr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/11_post_pred_distr.html#informazioni-sullambiente-di-sviluppo",
    "title": "51  Distribuzione predittiva a posteriori",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] see_0.9.0        gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1\n#&gt;  [5] psych_2.4.12     scales_1.3.0     markdown_1.13    knitr_1.49      \n#&gt;  [9] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [13] purrr_1.0.2      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [17] ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.3         rlang_1.1.4       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       yaml_2.3.10       tools_4.4.2       parallel_4.4.2   \n#&gt; [21] tzdb_0.4.0        colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5      \n#&gt; [25] R6_2.5.1          lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3  \n#&gt; [29] pillar_1.10.0     gtable_0.3.6      glue_1.8.0        xfun_0.49        \n#&gt; [33] tidyselect_1.2.1  farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-166     \n#&gt; [37] rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_post_pred_distr.html#bibliografia",
    "href": "chapters/bayesian_inference/11_post_pred_distr.html#bibliografia",
    "title": "51  Distribuzione predittiva a posteriori",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nSchoot, R. van de, Depaoli, S., King, R., Kramer, B., Märtens, K., Tadesse, M. G., Vannucci, M., Gelman, A., Veen, D., Willemsen, J., et al. (2021). Bayesian statistics and modelling. Nature Reviews Methods Primers, 1(1), 1.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/introduction_mcmc.html",
    "href": "chapters/mcmc/introduction_mcmc.html",
    "title": "Introduzione",
    "section": "",
    "text": "In questa sezione della dispensa, ci concentreremo sulle procedure Monte Carlo a catena di Markov, con particolare attenzione all’algoritmo di Metropolis, che consente di approssimare la distribuzione a posteriori quando non è possibile ottenere una soluzione analitica. Esploreremo il concetto di predizione bayesiana, fondamentale per la costruzione della distribuzione predittiva a posteriori, e discuteremo anche la distribuzione predittiva a priori. Applicheremo l’inferenza bayesiana a diversi contesti, tra cui la stima di una proporzione, il confronto tra due proporzioni, la stima di una media da una distribuzione normale e il confronto tra due medie. Esamineremo inoltre il modello bayesiano di Poisson per l’analisi delle frequenze. Infine, introdurremo il modello gerarchico bayesiano, uno strumento potente per affrontare situazioni in cui le osservazioni sono strutturate su diversi livelli di incertezza.",
    "crumbs": [
      "MCMC",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html",
    "href": "chapters/mcmc/01_metropolis.html",
    "title": "52  L’algoritmo di Metropolis-Hastings",
    "section": "",
    "text": "52.1 Introduzione\nIn precedenza, abbiamo esplorato diversi esempi di inferenza bayesiana riguardanti la distribuzione a posteriori di un singolo parametro, come nel caso del modello bernoulliano. Abbiamo anche trattato metodi come l’approssimazione tramite griglia e l’utilizzo dei priori coniugati per ottenere o approssimare la distribuzione a posteriori. In questo capitolo, ci concentreremo sul metodo di simulazione Monte Carlo a Catena di Markov (MCMC).\nIl metodo MCMC è una tecnica computazionale utilizzata per approssimare distribuzioni di probabilità complesse, generando una sequenza di campioni (correlati) attraverso una catena di Markov, in cui ogni campione viene ottenuto tramite una transizione iterativa con probabilità attentamente progettate.\nIl metodo MCMC rappresenta l’approccio moderno per approssimare distribuzioni a posteriori complesse. L’idea di base è simile al concetto di considerare la distribuzione a posteriori come una popolazione da cui estraiamo campioni ripetutamente. Con un numero sufficientemente grande di campioni (ad esempio 1000), la distribuzione del campione si avvicina molto alla distribuzione della popolazione, consentendo stime affidabili dei parametri incogniti.\nUna differenza rispetto all’analogia precedente è che i campioni generati con MCMC sono correlati: se il primo campione ha un valore alto, anche il successivo ha maggiori probabilità di essere alto. Questo accade perché non abbiamo un modo diretto per estrarre campioni dalla distribuzione a posteriori, che spesso ha una forma molto complessa; utilizziamo invece algoritmi che ci permettono di arrivarci indirettamente. La correlazione tra i campioni non rappresenta un problema rilevante, ma rende necessario estrarre un numero maggiore di campioni per compensare questa correlazione e ottenere stime accurate.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#il-denominatore-bayesiano",
    "href": "chapters/mcmc/01_metropolis.html#il-denominatore-bayesiano",
    "title": "52  L’algoritmo di Metropolis-Hastings",
    "section": "\n52.2 Il denominatore bayesiano",
    "text": "52.2 Il denominatore bayesiano\nNell’approccio bayesiano, l’obiettivo principale è determinare la distribuzione a posteriori \\(p(\\theta \\mid y)\\) di un parametro \\(\\theta\\), utilizzando i dati osservati \\(y\\) e la distribuzione a priori \\(p(\\theta)\\). Questo si ottiene attraverso il teorema di Bayes:\n\\[\np(\\theta \\mid y) = \\frac{p(y \\mid \\theta) p(\\theta)}{\\int p(y \\mid \\theta) p(\\theta) d\\theta}.\n\\]\nIl denominatore \\(\\int p(y \\mid \\theta) p(\\theta) d\\theta\\) rappresenta la probabilità marginale di \\(y\\), chiamata evidenza. Tale integrale garantisce che \\(p(\\theta \\mid y)\\) sia una distribuzione di probabilità valida. Tuttavia, il calcolo di questo integrale è spesso complesso, soprattutto in modelli articolati o ad alta dimensionalità, rendendo difficile ottenere una rappresentazione esplicita della distribuzione a posteriori.\nUna possibile semplificazione analitica è l’uso di distribuzioni a priori coniugate, che offrono una soluzione esatta per la distribuzione a posteriori. Tuttavia, questo approccio è limitato a casi specifici e impone forti vincoli sulla scelta delle distribuzioni a priori e delle verosimiglianze.\nUn approccio più generale è ricorrere a soluzioni numeriche. In precedenza abbiamo discusso il metodo di campionamento a griglia. Tuttavia, i metodi di campionamento a griglia, sebbene efficaci per modelli con pochi parametri, diventano impraticabili man mano che il numero di parametri aumenta, poiché richiedono una copertura densa dell’intero spazio parametrico. Di conseguenza, per modelli più complessi e con più parametri, si rende necessario un metodo che possa esplorare lo spazio dei parametri in maniera più efficiente.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#il-metodo-monte-carlo-e-le-sue-limitazioni",
    "href": "chapters/mcmc/01_metropolis.html#il-metodo-monte-carlo-e-le-sue-limitazioni",
    "title": "52  L’algoritmo di Metropolis-Hastings",
    "section": "\n52.3 Il metodo Monte Carlo e le sue limitazioni",
    "text": "52.3 Il metodo Monte Carlo e le sue limitazioni\nIl metodo Monte Carlo fornisce una soluzione a questo problema generando campioni casuali dalla distribuzione a posteriori \\(p(\\theta \\mid y)\\). L’idea centrale è semplice: se possiamo generare un numero sufficiente di campioni casuali dalla distribuzione a posteriori, possiamo usare questi campioni per stimare le proprietà d’interesse, come la media o la varianza del parametro \\(\\theta\\). Questa procedura ci permette di evitare il calcolo diretto dell’integrale complicato nel denominatore del teorema di Bayes.\nPer esempio, se fossimo in grado di generare una serie di campioni \\(\\theta^{(1)}, \\theta^{(2)}, \\dots, \\theta^{(T)}\\) dalla distribuzione a posteriori, potremmo approssimare il valore atteso di \\(\\theta\\) con la media campionaria:\n\\[\n\\mathbb{E}[\\theta] \\approx \\frac{1}{T} \\sum_{t=1}^T \\theta^{(t)}.\n\\]\nTuttavia, un problema significativo nei metodi Monte Carlo tradizionali è che generare campioni indipendenti dalla distribuzione a posteriori non è semplice, soprattutto quando questa distribuzione ha una forma complessa, è multimodale o definita su spazi di alta dimensionalità. Le regioni di alta densità, che contribuiscono maggiormente al valore dell’integrale, possono essere difficili da individuare e campionare adeguatamente. Per ottenere una buona copertura dello spazio dei parametri, sarebbe necessario generare un numero enorme di campioni, rendendo il metodo Monte Carlo inefficiente e computazionalmente oneroso.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#perché-i-metodi-mcmc-sono-necessari",
    "href": "chapters/mcmc/01_metropolis.html#perché-i-metodi-mcmc-sono-necessari",
    "title": "52  L’algoritmo di Metropolis-Hastings",
    "section": "\n52.4 Perché i metodi MCMC sono necessari",
    "text": "52.4 Perché i metodi MCMC sono necessari\nÈ qui che entrano in gioco i Metodi Monte Carlo a Catena di Markov (MCMC). Questi metodi risolvono il problema generando campioni dipendenti dalla distribuzione a posteriori, sfruttando la struttura di una catena di Markov. A differenza dei campioni indipendenti utilizzati nei metodi Monte Carlo tradizionali, i metodi MCMC costruiscono una sequenza di campioni, in cui ciascun campione dipende dal precedente. Questa dipendenza permette di esplorare in modo più efficiente le regioni di alta densità della distribuzione a posteriori, riducendo il numero di campioni necessari per ottenere stime accurate.\nIn pratica, MCMC consente di evitare di campionare inutilmente da regioni di bassa densità, concentrandosi invece sulle aree più rilevanti della distribuzione. Questo approccio è particolarmente potente nei contesti ad alta dimensionalità o in presenza di distribuzioni multimodali, dove i metodi Monte Carlo tradizionali risulterebbero inefficaci o richiederebbero un numero sproporzionato di campioni.\nIn sintesi, i metodi Monte Carlo classici sono limitati quando si tratta di campionare da distribuzioni complesse e multidimensionali. I metodi MCMC, invece, offrono una soluzione efficiente e flessibile, permettendo di esplorare le distribuzioni a posteriori anche in contesti complessi, senza la necessità di campionare indipendentemente ogni punto. Nel prossimo paragrafo introdurremo i concetti fondamentali delle catene di Markov e vedremo come queste vengono utilizzate nei metodi MCMC per campionare efficacemente da distribuzioni a posteriori difficili da trattare analiticamente.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#le-catene-di-markov",
    "href": "chapters/mcmc/01_metropolis.html#le-catene-di-markov",
    "title": "52  L’algoritmo di Metropolis-Hastings",
    "section": "\n52.5 Le Catene di Markov",
    "text": "52.5 Le Catene di Markov\nLe catene di Markov, introdotte da Andrey Markov nel 1906, rappresentano un’estensione della legge dei grandi numeri per descrivere sequenze di variabili casuali non indipendenti (per maggiori dettagli, si veda l’?sec-appendix-markov-first-order). Nella statistica tradizionale, si lavora spesso con sequenze di variabili casuali indipendenti e identicamente distribuite (i.i.d.), come \\(X_0, X_1, \\ldots, X_n, \\ldots\\), dove ogni variabile è indipendente dalle altre e segue la stessa distribuzione. Tuttavia, nei modelli più realistici che descrivono fenomeni complessi, l’indipendenza tra variabili è un’assunzione troppo rigida e spesso irrealistica.\nLe catene di Markov superano questo limite introducendo una dipendenza locale, detta dipendenza a un passo, formalizzata nella cosiddetta proprietà di Markov. Secondo questa proprietà, il valore futuro di una variabile casuale \\(X_{n+1}\\) dipende unicamente dal valore attuale \\(X_n\\), ignorando tutta la storia precedente della catena. Questo permette di semplificare notevolmente i calcoli relativi alle probabilità condizionali. La proprietà di Markov è formalmente espressa come:\n\\[\nP(X_{n+1} = j | X_n = i, X_{n-1} = i_{n-1}, \\ldots, X_0 = i_0) = P(X_{n+1} = j | X_n = i).\n\\]\nIn altre parole, la previsione di un evento futuro dipende soltanto dallo stato attuale e non da tutti gli eventi precedenti, semplificando così il processo di modellazione. Questa caratteristica rende le catene di Markov particolarmente utili per descrivere sistemi dinamici in cui gli eventi successivi sono influenzati solo dallo stato immediatamente precedente.\n\n52.5.1 Catene di Markov e Metodi MCMC\nLe catene di Markov sono fondamentali nei metodi Monte Carlo a Catena di Markov (MCMC) perché forniscono un modo efficiente per generare sequenze di campioni che approssimano distribuzioni di probabilità complesse. Mentre i metodi Monte Carlo classici generano campioni indipendenti, i metodi MCMC costruiscono una sequenza di campioni dipendenti attraverso una catena di Markov, in cui ciascun campione è ottenuto in base al campione precedente. Questo approccio consente di concentrarsi sulle regioni di alta probabilità della distribuzione, migliorando l’efficienza del campionamento.\nPer esempio, consideriamo una distribuzione di probabilità \\(P(x_1, x_2, ..., x_n)\\) definita su un insieme di variabili \\(x_1, x_2, ..., x_n\\). Nei metodi MCMC, si genera una sequenza di configurazioni \\(\\{x(0)\\}, \\{x(1)\\}, \\{x(2)\\}, \\dots\\), tale che la frequenza con cui ogni configurazione \\(\\{x\\}\\) viene visitata è proporzionale alla sua probabilità \\(P(x)\\). In questo modo, le configurazioni più probabili vengono visitate più spesso, garantendo che l’algoritmo converga alla distribuzione di interesse.\n\n52.5.2 Condizioni fondamentali per le Catene di Markov\nAffinché un algoritmo MCMC funzioni correttamente e converga alla distribuzione desiderata, la catena di Markov deve soddisfare alcune condizioni fondamentali:\n\n\nProprietà di Markov: La prossima configurazione dipende solo dalla configurazione attuale, non dalla storia passata. Questo garantisce che l’evoluzione della catena sia “locale” e non influenzata dagli stati remoti.\n\nIrriducibilità: Ogni configurazione della catena può essere raggiunta da qualsiasi altra in un numero finito di passi. Ciò assicura che l’intero spazio dei parametri possa essere esplorato.\n\nAperiodicità: La catena non segue cicli fissi e non ritorna sistematicamente allo stesso stato dopo un certo numero di passi. Questo garantisce che la catena possa esplorare lo spazio dei parametri in modo casuale.\n\nCondizione di bilanciamento dettagliato: La probabilità di passare da uno stato a un altro deve essere bilanciata dalla probabilità di tornare allo stato iniziale, assicurando così che la distribuzione di equilibrio della catena sia proprio la distribuzione a posteriori desiderata.\n\n52.5.3 Algoritmi MCMC\nEsistono diversi algoritmi basati su MCMC, ognuno con caratteristiche specifiche:\n\nMetropolis-Hastings: Questo è uno degli algoritmi più noti. Si basa sulla generazione di una configurazione proposta che viene accettata o rifiutata in base a un criterio di probabilità. Se la configurazione proposta ha una probabilità più alta, viene accettata; se ha una probabilità più bassa, può essere accettata con una certa probabilità, che dipende dal rapporto tra le probabilità delle due configurazioni.\nGibbs Sampling: In questo algoritmo, le variabili vengono aggiornate una alla volta, campionando ogni variabile dalla sua distribuzione condizionale data la configurazione corrente delle altre variabili. È particolarmente utile quando le distribuzioni condizionali sono note o facili da campionare.\nHamiltonian Monte Carlo (HMC): Utilizza principi della meccanica hamiltoniana per esplorare lo spazio dei parametri in modo più efficiente, considerando non solo le probabilità, ma anche le “forze” che muovono i campioni attraverso lo spazio dei parametri. Questo approccio è particolarmente vantaggioso per modelli complessi e ad alta dimensionalità, poiché consente di generare campioni lontani dallo stato corrente senza ricorrere a piccoli passi.\n\nIn sintesi, le catene di Markov forniscono il fondamento teorico e pratico per i metodi MCMC, offrendo un modo efficiente per esplorare lo spazio dei parametri nei modelli complessi. Grazie alle proprietà specifiche delle catene di Markov, i metodi MCMC permettono di affrontare problemi di inferenza bayesiana che sarebbero intrattabili con approcci analitici o con i metodi Monte Carlo classici. Essendo flessibili e potenti, le catene di Markov continueranno a essere uno strumento fondamentale nella statistica e nella scienza dei dati.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#estrazione-di-campioni-dalla-distribuzione-a-posteriori",
    "href": "chapters/mcmc/01_metropolis.html#estrazione-di-campioni-dalla-distribuzione-a-posteriori",
    "title": "52  L’algoritmo di Metropolis-Hastings",
    "section": "\n52.6 Estrazione di campioni dalla distribuzione a posteriori",
    "text": "52.6 Estrazione di campioni dalla distribuzione a posteriori\nIn questo capitolo presenteremo l’algoritmo di Metropolis, che è uno dei più semplici e potenti metodi MCMC. Sfruttando la struttura delle catene di Markov, esplora in modo efficiente lo spazio dei parametri, permettendo di ottenere campioni dalla distribuzione a posteriori anche in casi complessi, dove i metodi analitici falliscono. In sostanza, il MCMC genera un gran numero di valori per il parametro \\(\\theta\\) che, nel loro insieme, approssimano la distribuzione di interesse \\(p(\\theta \\mid y)\\). A questo fine, il capitolo è strutturato in varie sezioni che facilitano la comprensione progressiva del tema.\n\nInizieremo discutendo di come la distribuzione a posteriori possa essere approssimata mediante tecniche di simulazione convenzionali. Questa prima parte presuppone che la distribuzione target, o “a posteriori,” sia già conosciuta o disponibile per l’analisi.\nIn seguito, passeremo a illustrare come l’algoritmo di Metropolis possa essere utilizzato per affrontare situazioni in cui la distribuzione a posteriori non è direttamente nota. In questi casi, spesso abbiamo a disposizione informazioni riguardanti la distribuzione a priori e la funzione di verosimiglianza, che possono essere utilizzate per ottenere un’approssimazione efficace della distribuzione a posteriori.\n\nA titolo esemplificativo, utilizzeremo il dataset moma_sample.csv, il quale costituisce un campione casuale di 100 artisti provenienti dal Museo di Arte Moderna di New York (MoMA) e contiene diverse informazioni relative a ciascun artista.\nIl nostro interesse è focalizzato sulla determinazione della probabilità che un artista presente nel MoMA appartenga alla generazione X o a una generazione successiva (nati dopo il 1965). Questa probabilità sarà indicata come \\(\\pi\\).\nImportiamo i dati.\n\nmoma_sample &lt;- rio::import(here::here(\"data\", \"moma_sample.csv\"))\n\nEsaminiamo le prime cinque righe del DataFrame.\n\nmoma_sample |&gt; \n  head()\n#&gt;                artist  country birth death alive  genx gender count\n#&gt; 1        Ad Gerritsen    dutch  1940  2015 FALSE FALSE   male     1\n#&gt; 2 Kirstine Roepstorff   danish  1972    NA  TRUE  TRUE female     3\n#&gt; 3    Lisa Baumgardner american  1958  2015 FALSE FALSE female     2\n#&gt; 4         David Bates american  1952    NA  TRUE FALSE   male     1\n#&gt; 5          Simon Levy american  1946    NA  TRUE FALSE   male     1\n#&gt; 6      Pierre Mercure canadian  1927  1966 FALSE FALSE   male     8\n#&gt;   year_acquired_min year_acquired_max\n#&gt; 1              1981              1981\n#&gt; 2              2005              2005\n#&gt; 3              2016              2016\n#&gt; 4              2001              2001\n#&gt; 5              2012              2012\n#&gt; 6              2008              2008\n\nDai dati osserviamo che solo 14 artisti su 100 appartengono alla generazione X o a una generazione successiva.\n\n# Calcoliamo la distribuzione delle generazioni\nresult &lt;- table(moma_sample$genx)\nresult\n#&gt; \n#&gt; FALSE  TRUE \n#&gt;    86    14\n\nIl valore campionato \\(y = 14\\) riflette le caratteristiche del campione che è stato osservato. Tuttavia, poiché il MOMA contiene opere di migliaia di artisti, sorge una domanda riguardante il vero valore di \\(\\theta\\) (la probabilità di appartenere alla generazione X o a una generazione successiva) all’interno di questa popolazione.\nPossiamo interpretare i dati \\(y = 14\\) come l’esito di una variabile casuale Binomiale con parametri \\(N = 100\\) e \\(\\theta\\) sconosciuto.\nSupponiamo che le nostre credenze pregresse riguardo a \\(\\theta\\) possano essere modellate attraverso una distribuzione Beta(4, 6).\nSfruttando le proprietà delle distribuzioni coniugate, possiamo calcolare esattamente la distribuzione a posteriori:\n# Y ~ Binomiale(100, π)\n# θ ~ Beta(4, 6)\n# Posteriori: θ | (Y = 14) ~ Beta(4 + 14, 6 + 100 - 14) → Beta(18, 92)\nNella figura seguente, è rappresentata la distribuzione a posteriori del parametro \\(\\theta\\), insieme alla distribuzione a priori specificata.\n\n# Generiamo la sequenza dei valori per θ\nx &lt;- seq(0, 1, length.out = 1000)\n\n# Calcoliamo le densità della prior e della posterior\nprior_density &lt;- dbeta(x, 4, 6)\nposterior_density &lt;- dbeta(x, 18, 92)\n\n# Creiamo il grafico\nplot(\n  x, prior_density,\n  type = \"l\", col = \"blue\", lwd = 2,\n  ylim = c(0, max(c(prior_density, posterior_density))),\n  xlab = \"Valore del Parametro\",\n  ylab = \"Densità\",\n  main = \"Densità a Priori e a Posteriori\"\n)\nlines(x, posterior_density, col = \"red\", lwd = 2)\npolygon(\n  c(x, rev(x)), c(prior_density, rep(0, length(x))),\n  col = adjustcolor(\"blue\", alpha.f = 0.5), border = NA\n)\npolygon(\n  c(x, rev(x)), c(posterior_density, rep(0, length(x))),\n  col = adjustcolor(\"red\", alpha.f = 0.5), border = NA\n)\nlegend(\"topright\",\n  legend = c(\"Prior: Beta(4, 6)\", \"Posterior: Beta(18, 92)\"),\n  fill = c(\n    adjustcolor(\"blue\", alpha.f = 0.5),\n    adjustcolor(\"red\", alpha.f = 0.5)\n  ), border = NA\n)\n\n\n\n\n\n\n\nIn questo grafico, la curva blu rappresenta la distribuzione a priori \\(\\text{Beta}(4, 6)\\), mentre la curva rossa mostra la distribuzione a posteriori \\(\\text{Beta}(18, 92)\\). La sovrapposizione delle aree evidenzia come l’evidenza fornita dai dati modifichi la conoscenza iniziale sul parametro \\(\\theta\\).\nSe vogliamo conoscere il valore della media a posteriori di \\(\\theta\\), il risultato esatto è\n\\[\n\\bar{\\theta}_{post} = \\frac{\\alpha}{\\alpha + \\beta} = \\frac{18}{18 + 92} \\approx 0.1636.\n\\]\n\n52.6.1 Simulazione con distribuzione target nota\nUsiamo ora una simulazione numerica per stimare la media a posteriori di \\(\\theta\\). Conoscendo la forma della distribuzione a posteriori \\(Beta(18, 92)\\), possiamo generare un campione di osservazioni casuali da questa distribuzione. Successivamente, calcoliamo la media delle osservazioni ottenute per ottenere un’approssimazione della media a posteriori.\nSe vogliamo ottenere un risultato approssimato con un numero limitato di campioni (ad esempio, 10), possiamo utilizzare la seguente simulazione:\n\n# Generiamo 10 campioni dalla distribuzione Beta(18, 92)\nset.seed(1)  # Per riproducibilità\ny &lt;- rbeta(10, shape1 = 18, shape2 = 92)\ny\n#&gt;  [1] 0.140 0.171 0.132 0.177 0.132 0.184 0.196 0.152 0.242 0.180\n\n\n# Calcoliamo la media dei campioni\nmean(y)\n#&gt; [1] 0.171\n\nTuttavia, con soli 10 campioni, l’approssimazione potrebbe non essere molto accurata. Aumentando il numero di campioni, ad esempio a 10.000, possiamo ottenere una stima molto più precisa:\n\n# Generiamo 10.000 campioni e calcoliamo la media\nset.seed(123)  # Per riproducibilità\nmean(rbeta(10000, shape1 = 18, shape2 = 92))\n#&gt; [1] 0.164\n\nQuando il numero di campioni dalla distribuzione a posteriori diventa molto grande, la media campionaria converge al valore atteso della distribuzione della popolazione. Questo principio non si applica solo alla media, ma anche ad altre statistiche descrittive come la moda e la varianza.\nÈ importante sottolineare che l’applicazione della simulazione di Monte Carlo è efficace per calcolare distribuzioni a posteriori solo quando conosciamo la distribuzione stessa e possiamo utilizzare funzioni Python per estrarre campioni casuali da tale distribuzione. Ciò è stato possibile nel caso della distribuzione a posteriori \\(Beta(18, 92)\\).\nTuttavia, questa situazione ideale non si verifica sempre nella pratica, poiché le distribuzioni a priori coniugate alla verosimiglianza sono spesso rare. Per esempio, nel caso di una verosimiglianza binomiale e una distribuzione a priori gaussiana, l’espressione\n\\[\np(\\theta \\mid y) = \\frac{\\mathrm{e}^{-(\\theta - 1 / 2)^2} \\theta^y (1 - \\theta)^{n - y}} {\\int_0^1 \\mathrm{e}^{-(t - 1 / 2)^2} t^y (1 - t)^{n - y} dt}\n\\]\nrende impossibile calcolare analiticamente la distribuzione a posteriori di \\(\\theta\\), precludendo quindi l’utilizzo diretto di Python per generare campioni casuali.\nIn queste circostanze, però, è possibile ottenere campioni casuali dalla distribuzione a posteriori mediante l’uso di metodi Monte Carlo basati su Catena di Markov (MCMC). Gli algoritmi MCMC, come ad esempio l’algoritmo Metropolis, costituiscono una classe di metodi che consentono di estrarre campioni casuali dalla distribuzione a posteriori senza richiedere la conoscenza della sua rappresentazione analitica. Le tecniche MCMC sono ampiamente adottate per risolvere problemi di inferenza bayesiana e rappresentano il principale strumento computazionale per ottenere stime approssimate di distribuzioni a posteriori in situazioni complesse e non analiticamente trattabili.\n\n52.6.2 Algoritmo di Metropolis\nL’algoritmo di Metropolis appartiene alla famiglia dei metodi Monte Carlo basati su catene di Markov (MCMC), sfruttando le proprietà di queste catene per generare campioni da una distribuzione target. Il suo obiettivo principale è di esplorare lo spazio dei parametri in modo efficiente, producendo campioni che approssimano la distribuzione a posteriori di interesse.\n\n52.6.3 Principio di Funzionamento\nL’algoritmo inizia da un valore iniziale per i parametri e, in ogni iterazione, genera un nuovo campione tramite una distribuzione di proposta (solitamente una distribuzione normale centrata sul valore corrente). Successivamente, decide se accettare il nuovo campione in base al confronto tra le densità posteriori del nuovo campione e di quello precedente. Questa accettazione avviene in modo probabilistico, favorendo campioni con una densità più alta ma consentendo anche l’accettazione di campioni peggiori per evitare che la catena rimanga bloccata in minimi locali.\n\n52.6.4 Burn-in e Convergenza\nPoiché i primi campioni potrebbero non rappresentare bene la distribuzione target, si esclude spesso una porzione iniziale della catena (fase di burn-in). Con il progredire delle iterazioni, i campioni si distribuiscono in accordo con la distribuzione stazionaria desiderata, indipendentemente dallo stato iniziale scelto. Questo processo permette di esplorare lo spazio dei parametri in modo efficiente.\n\n52.6.5 Meccanismo di Accettazione e Rifiuto\nL’algoritmo di Metropolis bilancia due esigenze opposte:\n\n\nEsplorazione di nuove aree dello spazio dei parametri.\n\nSfruttamento delle informazioni già acquisite dai campioni precedenti.\n\nUtilizzando una regola probabilistica per accettare campioni peggiori (con minore densità a posteriori), l’algoritmo evita di restare intrappolato in minimi locali, esplorando così in modo più completo l’intera distribuzione.\n\n52.6.6 Passaggi Fondamentali dell’Algoritmo di Metropolis\n\n\nScelta di uno stato iniziale \\(\\theta_1\\) e impostazione del contatore \\(t = 1\\).\n\nQuesto è il punto di partenza della catena, dove \\(\\theta_1\\) rappresenta il primo campione.\n\n\n\nProposta di un nuovo campione \\(\\theta_p\\).\n\nUn nuovo valore \\(\\theta_p\\) viene generato da una distribuzione di proposta \\(g(\\theta_p \\mid \\theta_t)\\), solitamente una distribuzione normale centrata sul campione corrente \\(\\theta_t\\) con una deviazione standard \\(\\tau\\) che controlla l’ampiezza dei passi.\n\n\n\nVerifica dei vincoli del campione proposto.\n\nSe il nuovo campione deve rispettare dei vincoli (ad esempio, essere compreso tra 0 e 1 per probabilità), campioni non validi vengono automaticamente rifiutati.\n\n\n\nCalcolo del rapporto di accettazione \\(\\alpha\\).\n\nSi calcola \\(\\alpha = \\frac{p(\\theta_p \\mid y)}{p(\\theta_t \\mid y)}\\), che rappresenta il rapporto tra le densità a posteriori del nuovo campione \\(\\theta_p\\) e del campione corrente \\(\\theta_t\\). Questo valore guida la decisione di accettazione.\n\n\n\nDecisione di accettazione.\n\nSe \\(\\alpha \\geq 1\\), il nuovo campione \\(\\theta_p\\) viene accettato incondizionatamente.\nSe \\(\\alpha &lt; 1\\), il campione \\(\\theta_p\\) viene accettato con probabilità \\(\\alpha\\). In caso di rifiuto, si mantiene il campione corrente \\(\\theta_t\\) per la prossima iterazione.\n\n\n\nRipetizione del processo.\n\nSi ripetono i passaggi dal 2 al 5 fino a ottenere il numero desiderato di campioni.\n\n\n\n52.6.7 Dettagli Aggiuntivi\n\nDistribuzione di proposta: La distribuzione di proposta \\(g(\\theta_p \\mid \\theta_t)\\) genera nuovi campioni attorno a \\(\\theta_t\\). Tipicamente si usa una normale \\(N(\\theta_t, \\tau)\\), dove \\(\\tau\\) controlla quanto il nuovo campione si discosta da quello corrente. Scegliere un \\(\\tau\\) troppo piccolo può rendere l’esplorazione lenta, mentre un \\(\\tau\\) troppo grande può far rifiutare troppi campioni, riducendo l’efficienza.\nRapporto di accettazione \\(\\alpha\\): Se il nuovo campione ha una densità a posteriori maggiore del campione corrente, viene sempre accettato. Se ha una densità inferiore, viene accettato con probabilità \\(\\alpha\\), il che consente di esplorare anche regioni meno probabili della distribuzione.\nAccettazione probabilistica: Accettare campioni peggiori occasionalmente aiuta l’algoritmo a evitare di bloccarsi in minimi locali. Questo è uno dei punti di forza dell’algoritmo di Metropolis, che garantisce una buona esplorazione dello spazio dei parametri.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#esempio-di-implementazione",
    "href": "chapters/mcmc/01_metropolis.html#esempio-di-implementazione",
    "title": "52  L’algoritmo di Metropolis-Hastings",
    "section": "\n52.7 Esempio di Implementazione",
    "text": "52.7 Esempio di Implementazione\nPer questa simulazione, adattiamo l’approccio proposto da Elizaveta Semenova, implementando l’algoritmo di Metropolis-Hastings in R. Cominciamo definendo alcune funzioni fondamentali.\nDefiniamo una funzione prior che calcola la densità della distribuzione Beta(4, 6) per un dato valore di \\(\\theta\\):\n\n# Definizione della distribuzione a priori (Beta(4, 6))\nprior &lt;- function(p) {\n  dbeta(p, shape1 = 4, shape2 = 6)\n}\n\nDefiniamo la funzione likelihood, che calcola la densità della verosimiglianza binomiale per 14 successi su 100 prove:\n\n# Definizione della funzione di verosimiglianza (Binomiale \n# con y = 14 su n = 100)\nlikelihood &lt;- function(p) {\n  y &lt;- 14\n  n &lt;- 100\n  dbinom(y, size = n, prob = p)\n}\n\nDefiniamo la funzione posterior, che calcola la densità della distribuzione a posteriori non normalizzata come prodotto tra la distribuzione a priori e la verosimiglianza:\n\n# Definizione della distribuzione a posteriori (non normalizzata)\nposterior &lt;- function(p) {\n  likelihood(p) * prior(p)\n}\n\nLa distribuzione proposta sarà una distribuzione normale centrata sullo stato corrente con una deviazione standard specificata:\n\n# Distribuzione proposta (normale centrata sullo stato corrente)\nproposal_distribution &lt;- function(current_state, proposal_sigma) {\n  rnorm(1, mean = current_state, sd = proposal_sigma)\n}\n\nDefiniamo infine la distribuzione target, che corrisponde alla distribuzione a posteriori:\n\n# Distribuzione target, equivalente alla distribuzione a posteriori\ntarget_distribution &lt;- function(p) {\n  posterior(p)\n}\n\nProcediamo ora con l’implementazione dell’algoritmo di Metropolis-Hastings, considerando i dati relativi agli artisti della Generazione X presenti al MoMA. La distribuzione a priori per \\(\\theta\\) è modellata come una Beta(4, 6).\n\n# Algoritmo di Metropolis-Hastings\nmetropolis_hastings &lt;- function(num_samples, initial_state, proposal_sigma) {\n  # Inizializza lo stato corrente e la lista dei campioni\n  samples &lt;- numeric(num_samples)\n  current_state &lt;- initial_state\n\n  for (i in seq_len(num_samples)) {\n    # Proponi un nuovo stato dalla distribuzione proposta\n    proposed_state &lt;- proposal_distribution(current_state, proposal_sigma)\n\n    # Verifica che il valore proposto sia tra 0 e 1\n    if (proposed_state &gt;= 0 && proposed_state &lt;= 1) {\n      # Calcola il rapporto di accettazione\n      acceptance_ratio &lt;- min(\n        1,\n        target_distribution(proposed_state) / target_distribution(current_state)\n      )\n\n      # Accetta o rifiuta lo stato proposto\n      if (runif(1) &lt; acceptance_ratio) {\n        current_state &lt;- proposed_state\n      }\n    }\n\n    # Registra lo stato corrente (accettato o rifiutato)\n    samples[i] &lt;- current_state\n  }\n\n  return(samples)\n}\n\n\n\n\n\n\n\nPunti Chiave dell’Algoritmo\n\n\n\n\n\nGenerazione dei nuovi stati: Ogni nuovo stato viene proposto campionando da una distribuzione normale centrata sullo stato corrente. Questo approccio consente un’esplorazione sistematica dello spazio dei parametri.\n\n\nControllo dei limiti: Gli stati proposti devono rientrare nell’intervallo [0, 1], poiché rappresentano probabilità. Questo assicura che i valori generati siano validi nel contesto dell’analisi.\n\n\nRapporto di accettazione: La decisione di accettare o rifiutare un nuovo stato è basata sul confronto tra la densità a posteriori del nuovo stato e quella dello stato corrente. Stati più probabili vengono sempre accettati, mentre quelli meno probabili sono accettati con una probabilità proporzionale.\n\n\nMemorizzazione degli stati: Ogni iterazione salva lo stato corrente, sia che il nuovo stato venga accettato sia che venga rifiutato, garantendo una catena continua di valori.\n\n\n\nQuesta implementazione fornisce una stima robusta della distribuzione a posteriori utilizzando una combinazione di una distribuzione a priori e dei dati osservati.\nLa distribuzione normale utilizzata per la proposta è simmetrica, soddisfacendo i requisiti dell’algoritmo di Metropolis. Questa simmetria garantisce che la probabilità di proporre uno stato \\(\\theta_p\\) partendo da \\(\\theta_t\\) sia uguale alla probabilità inversa, assicurando l’equilibrio dettagliato necessario per la corretta convergenza della catena Markoviana.\n\n52.7.1 Esecuzione dell’Algoritmo\n\n# Parametri dell'algoritmo\nnum_samples &lt;- 10000\ninitial_state &lt;- 0.5\nproposal_sigma &lt;- 0.1\n\n# Esecuzione del campionamento\nset.seed(123)  # Per riproducibilità\nsamples &lt;- metropolis_hastings(num_samples, initial_state, proposal_sigma)\n\n\n52.7.2 Analisi dei Risultati\nScartiamo i primi 5000 campioni per considerare solo quelli generati dopo il burn-in:\n\nburnin &lt;- floor(num_samples * 0.5)\npost_burnin_samples &lt;- samples[-seq_len(burnin)]\n\nCalcoliamo la media e la deviazione standard dei campioni:\n\n# Media a posteriori\nmean(post_burnin_samples)\n#&gt; [1] 0.163\n\n# Deviazione standard a posteriori\nsd(post_burnin_samples)\n#&gt; [1] 0.0354\n\nVisualizziamo l’evoluzione della catena per i primi 200 campioni e per quelli post-burn-in:\n\n# Trace plot dei primi 200 campioni\nplot(\n  samples[1:200], \n  type = \"l\", \n  main = \"Trace Plot (Primi 200 Campioni)\",\n  xlab = \"Iterazioni\", \n  ylab = expression(theta)\n)\n\n\n\n\n\n\n\n\n# Trace plot dopo il burn-in\nplot(\n  post_burnin_samples, \n  type = \"l\", \n  main = \"Trace Plot (Post Burn-in)\",\n  xlab = \"Iterazioni\", \n  ylab = expression(theta)\n)\n\n\n\n\n\n\n\nSovrapponiamo la distribuzione analitica \\(\\text{Beta}(18, 92)\\) all’istogramma dei campioni post-burn-in:\n\n# Istogramma e distribuzione analitica\nhist(\n  post_burnin_samples, \n  breaks = 20, \n  probability = TRUE, \n  col = \"lightblue\",\n  main = \"Istogramma e Distribuzione Posteriori\", \n  xlab = expression(theta)\n)\ncurve(\n  dbeta(x, 18, 92), \n  add = TRUE, \n  col = \"red\", \n  lwd = 2\n)\nlegend(\n  \"topright\", \n  legend = c(\"Istogramma MCMC\", \"Beta(18, 92)\"),\n  col = c(\"lightblue\", \"red\"), lwd = 2, fill = c(\"lightblue\", NA)\n)\n\n\n\n\n\n\n\nCalcoliamo l’intervallo di credibilità al 94%:\n\nquantile(post_burnin_samples, probs = c(0.03, 0.97))\n#&gt;    3%   97% \n#&gt; 0.102 0.235\n\nQuesta implementazione in R dimostra come utilizzare l’algoritmo di Metropolis per stimare una distribuzione a posteriori e analizzare i risultati in modo dettagliato e riproducibile.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#catene-di-markov-e-convergenza",
    "href": "chapters/mcmc/01_metropolis.html#catene-di-markov-e-convergenza",
    "title": "52  L’algoritmo di Metropolis-Hastings",
    "section": "\n52.8 Catene di Markov e Convergenza",
    "text": "52.8 Catene di Markov e Convergenza\nNell’ambito delle simulazioni Monte Carlo, una catena rappresenta una sequenza di valori campionati dall’algoritmo durante le sue iterazioni. Ogni valore nella catena corrisponde a un possibile stato del sistema che stiamo modellando. In altre parole, una catena traccia il percorso che l’algoritmo segue nello spazio dei parametri, esplorando le diverse configurazioni possibili.\nPer verificare se l’algoritmo ha raggiunto la convergenza e se i campioni generati rappresentano effettivamente la distribuzione di interesse, è utile eseguire multiple catene. Ogni catena parte da un punto iniziale diverso nello spazio dei parametri.\nI vantaggi delle multiple catene:\n\n\nDiagnostica della convergenza: Confrontando le diverse catene, possiamo valutare se si stabilizzano verso la stessa distribuzione. Se le catene si mescolano bene, ovvero si intersecano frequentemente nel grafico dei valori campionati (trace plot), è un forte indicatore di convergenza.\n\nRobustezza: L’utilizzo di multiple catene rende l’analisi meno sensibile alla scelta del punto di partenza. Se una singola catena potesse rimanere “intrappolata” in una regione dello spazio dei parametri, multiple catene aumentano la probabilità di esplorare lo spazio in modo più completo.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#diagnostiche-della-soluzione-mcmc",
    "href": "chapters/mcmc/01_metropolis.html#diagnostiche-della-soluzione-mcmc",
    "title": "52  L’algoritmo di Metropolis-Hastings",
    "section": "\n52.9 Diagnostiche della soluzione MCMC",
    "text": "52.9 Diagnostiche della soluzione MCMC\n\n52.9.1 Stazionarietà e Convergenza\nUn aspetto cruciale nell’analisi delle catene di Markov MCMC è la convergenza alla distribuzione stazionaria. Intuitivamente, la catena converge quando i campioni generati rappresentano fedelmente la distribuzione di interesse, indipendentemente dal punto di partenza. Questo fenomeno è spesso indicato come “mixing”.\n\n52.9.1.1 Valutazione Visuale: Trace Plots e Grafici di Densità\n\n\nTrace Plots: Questi grafici visualizzano l’evoluzione dei parametri nel tempo. Una catena convergente mostra tracce stabili e senza trend evidenti. Tracce irregolari o con andamenti sistematici suggeriscono problemi di convergenza.\n\nGrafici di Densità: Confrontando i grafici di densità dei campioni con la distribuzione teorica, è possibile valutare visivamente se la catena sta esplorando adeguatamente lo spazio dei parametri. Una buona convergenza si manifesta con una sovrapposizione significativa tra i due grafici.\n\nSegni di Convergenza:\n\n\nStabilità: I valori campionati oscillano attorno a un valore medio costante, senza trend marcati.\n\nOmogeneità: La variabilità dei campioni rimane relativamente uniforme nel tempo.\n\nAssenza di Periodicità: Non si osservano pattern ciclici o ripetitivi.\n\nIn sintesi, i trace plots e i grafici di densità offrono strumenti visivi rapidi per valutare la convergenza di una catena di Markov MCMC. Una convergenza soddisfacente è fondamentale per garantire la validità delle inferenze statistiche basate sui campioni generati.\n\n52.9.2 Autocorrelazione nelle catene di Markov MCMC\nA differenza dei generatori di numeri casuali indipendenti, gli algoritmi MCMC producono una sequenza di campioni correlati. Ogni valore campionato dipende da quello precedente, formando una catena di Markov. Questa interdipendenza è un aspetto fondamentale dell’MCMC.\nL’autocorrelazione quantifica il grado di dipendenza tra valori distanti di una certa quantità (detta lag) nella catena. Un’alta autocorrelazione a lag bassi indica una forte dipendenza tra campioni successivi. Al contrario, una rapida diminuzione dell’autocorrelazione al crescere del lag suggerisce che la catena “miscela” bene, ovvero esplora lo spazio dei parametri in modo efficiente.\n\n\nLag 1: Misura la correlazione tra valori consecutivi nella catena.\n\nLag 2: Misura la correlazione tra valori separati da un passo intermedio.\n\nLag k: Generalizza il concetto ai valori separati da k passi.\n\nUn correlogramma è un grafico che mostra l’autocorrelazione in funzione del lag. Un decadimento rapido dell’autocorrelazione verso zero indica una buona convergenza della catena.\nL’autocorrelazione di ordine \\(k\\) è data da \\(\\rho_k\\) e può essere stimata come:\n\\[\n\\begin{align}\n\\rho_k &= \\frac{Cov(\\theta_m, \\theta_{m+k})}{Var(\\theta_m)}\\notag\\\\\n&= \\frac{\\sum_{m=1}^{n-k}(\\theta_m - \\bar{\\theta})(\\theta_{m-k} - \\bar{\\theta})}{\\sum_{m=1}^{n-k}(\\theta_m - \\bar{\\theta})^2} \\qquad\\text{con }\\quad \\bar{\\theta} = \\frac{1}{n}\\sum_{m=1}^{n}\\theta_m.\n\\end{align}\n\\tag{52.1}\\]\n\n52.9.3 Esempio di Simulazione di Dati Autocorrelati\nPer fare un esempio pratico, creiamo un vettore di dati autocorrelati:\n\n# Creiamo un vettore di dati\nx &lt;- c(22, 24, 25, 25, 28, 29, 34, 37, 40, 44, 51, 48, 47, 50, 51)\nx\n#&gt;  [1] 22 24 25 25 28 29 34 37 40 44 51 48 47 50 51\n\n\n52.9.3.1 Calcolo dell’Autocorrelazione\nL’autocorrelazione di ordine 1 è la correlazione tra ciascun elemento e il successivo nella sequenza. In R possiamo utilizzare la funzione acf() per calcolare l’autocorrelazione.\n\n# Calcolo dell'autocorrelazione\nacf_values &lt;- acf(x, plot = FALSE)\nacf_values\n#&gt; \n#&gt; Autocorrelations of series 'x', by lag\n#&gt; \n#&gt;      0      1      2      3      4      5      6      7      8      9 \n#&gt;  1.000  0.832  0.656  0.491  0.279  0.031 -0.165 -0.304 -0.401 -0.458 \n#&gt;     10     11 \n#&gt; -0.450 -0.369\n\nNell’esempio, il vettore x rappresenta una serie temporale di 15 elementi. Il calcolo dell’autocorrelazione restituisce i seguenti valori per i primi ritardi (lag):\n\n\n0.8317: autocorrelazione di ordine 1 (lag = 1),\n\n0.6563: autocorrelazione di ordine 2 (lag = 2),\n\n0.4910: autocorrelazione di ordine 3 (lag = 3),\necc.\n\n52.9.3.2 Specifica del Numero di Ritardi (Lag)\nPossiamo limitare il numero di ritardi calcolati utilizzando l’argomento lag.max nella funzione acf():\n\n# Calcolo dell'autocorrelazione per i primi 4 lag\nacf(x, lag.max = 4, plot = FALSE)\n#&gt; \n#&gt; Autocorrelations of series 'x', by lag\n#&gt; \n#&gt;     0     1     2     3     4 \n#&gt; 1.000 0.832 0.656 0.491 0.279\n\n\n52.9.3.3 Grafico della Funzione di Autocorrelazione (Correlogramma)\nIn R possiamo creare un correlogramma con la funzione acf():\n\n# Correlogramma per la serie temporale\nacf(x, main = \"Correlogramma della Serie Temporale\", lag.max = 9)\n\n\n\n\n\n\n\n\n52.9.4 Analisi della Catena di Markov\nApplichiamo lo stesso approccio alla catena di Markov ottenuta precedentemente, considerando i campioni post burn-in:\n\n# Definizione dei campioni post burn-in\npost_burnin_samples &lt;- samples[-seq_len(burnin)]\n\n# Correlogramma per i campioni post burn-in\nacf(\n  post_burnin_samples, \n  main = \"Correlogramma della Catena Post Burn-in\", \n  lag.max = 9\n)\n\n\n\n\n\n\n\nIn situazioni ideali, l’autocorrelazione diminuisce rapidamente, diventando insignificante per piccoli lag. Questo comportamento è un’indicazione del “mixing” efficace della catena, ossia della sua convergenza alla distribuzione stazionaria.\n\n52.9.5 Sottocampionamento (Thinning)\nPer ridurre l’autocorrelazione, possiamo applicare una strategia di sottocampionamento (thinning), memorizzando solo ogni \\(m\\)-esimo campione.\n\n# Sottocampionamento con un fattore di 5\nthin &lt;- 5\nsampsthin &lt;- \n  post_burnin_samples[seq(1, length(post_burnin_samples), by = thin)]\n\n# Correlogramma per i campioni sottocampionati\nacf(\n  sampsthin, \n  main = \"Correlogramma con Sottocampionamento (Thinning)\", \n  lag.max = 9\n)\n\n\n\n\n\n\n\nIn conclusione, il correlogramma con thinning mostra che l’autocorrelazione diminuisce più rapidamente rispetto ai campioni originali, suggerendo che la strategia di sottocampionamento è efficace nel migliorare l’indipendenza tra i campioni successivi. Questo migliora la qualità delle inferenze basate sulla catena di Markov.\n\n52.9.5.1 Tasso di accettazione\nQuando si utilizza l’algoritmo Metropolis, è importante monitorare il tasso di accettazione e assicurarsi che sia nell’intervallo ottimale. Se si accetta quasi sempre il candidato proposto, probabilmente significa che, in ogni iterazione, la catena salta solo di un piccolo passo (in modo che il rapporto di accettazione sia vicino a 1 ogni volta). Di conseguenza, la catena impiegherà molte iterazioni per raggiungere altre regioni della distribuzione stazionaria e i campioni consecutivi saranno molto fortemente correlati. D’altra parte, se il tasso di accettazione è molto basso, la catena rimarrà bloccata nella stessa posizione per molte iterazioni prima di spostarsi verso uno stato diverso. Per l’algoritmo Metropolis base con un singolo parametro con una distribuzione proposta Gaussiana normale, un tasso di accettazione ottimale è compreso tra il 40% e il 50%.\n\n52.9.6 Test Statistici per la Convergenza\nOltre agli approcci grafici, esistono test statistici specifici che possono aiutare a determinare se la catena ha raggiunto uno stato stazionario.\n\n52.9.6.1 Test di Geweke\nIl test di Geweke è una procedura che confronta le medie di due segmenti della catena di campionamento, tipicamente il primo 10% e l’ultimo 50% dei campioni, dopo aver escluso un iniziale periodo di “burn-in” (una fase iniziale durante la quale la catena potrebbe non essere ancora convergente). La premessa di base è che, se la catena è in uno stato stazionario, le medie di questi due segmenti dovrebbero essere sostanzialmente uguali. Differenze significative tra queste medie possono indicare che la catena non ha ancora raggiunto la convergenza.\n\n52.9.6.2 Geweke Z-score\nUna variante del test di Geweke è lo z-score di Geweke, che offre un modo quantitativo per valutare le differenze tra i segmenti della catena. Questo test calcola uno z-score che confronta le medie dei due segmenti tenendo conto della varianza. Un valore di z-score:\n\n\nAl di sotto di 2 (in valore assoluto) suggerisce che non ci sono differenze significative tra i segmenti, indicando che la catena potrebbe essere in stato stazionario.\n\nSuperiore a 2 (in valore assoluto) indica che esiste una differenza significativa tra i segmenti, suggerendo che la catena non ha raggiunto la convergenza e potrebbe essere necessario un periodo di burn-in più esteso.\n\nEntrambi i metodi forniscono strumenti utili per valutare la convergenza delle catene MCMC. È importante notare che nessun test può garantire con certezza la convergenza, ma l’utilizzo congiunto di approcci grafici e test statistici può offrire una buona indicazione dello stato della catena.\n\n52.9.7 Dimensione del campione effettiva (ESS)\nLa correlazione tra campioni consecutivi in una catena MCMC riduce l’informazione effettiva contenuta in ogni iterazione. La dimensione del campione effettiva (ESS) quantifica questa perdita di informazione dovuta alla dipendenza tra i campioni, stimando il numero equivalente di campioni indipendenti. Un valore basso di ESS indica una forte correlazione tra i campioni e una convergenza più lenta della catena.\nL’ESS descrive l’efficacia del campionamento dipendente in termini di campioni indipendenti estratti dalla stessa distribuzione. Rappresenta un indicatore dell’efficienza del campionamento e dell’autocorrelazione della catena.\nLa formula per stimare la dimensione del campione effettiva (ESS) di una catena di Markov è:\n\\[\n\\text{ESS} = \\frac{N}{1 + 2 \\sum_{t=1}^{T} \\rho_t},\n\\]\ndove:\n\n\n\\(N\\) è il numero totale di campioni nella catena,\n\n\\(T\\) è il lag, ovvero il numero massimo di termini di autocorrelazione considerati,\n\n\\(\\rho_t\\) è l’autocorrelazione al lag \\(t\\), ossia la correlazione tra due campioni consecutivi separati da \\(t\\) iterazioni.\n\nIn pratica, \\(T\\) viene scelto in modo tale che \\(\\rho_T\\) sia sufficientemente piccolo, indicando che l’autocorrelazione è quasi svanita. La somma \\(\\sum_{t=1}^T \\rho_t\\) viene quindi troncata approssimativamente a \\(T\\), poiché i contributi delle autocorrelazioni successive diventano trascurabili.\n\n52.9.8 Calcolo della Statistica di Gelman-Rubin (\\(\\hat{R}\\))\nPer calcolare la statistica di Gelman-Rubin (spesso indicata come \\(\\hat{R}\\)), è necessario eseguire più catene e confrontare la variabilità all’interno di ciascuna catena con la variabilità tra le catene. Ecco i passaggi per calcolare \\(\\hat{R}\\):\n\nEsegui \\(m\\) catene di Markov di lunghezza \\(n\\), dove \\(m\\) è solitamente maggiore di 1.\nPer ciascun parametro scalare \\(\\theta\\), calcola la varianza all’interno delle catene (\\(W\\)) e la varianza tra le catene (\\(B\\)).\nCalcola la varianza combinata \\(\\hat{V}\\) come media ponderata delle varianze all’interno delle catene.\nCalcola il fattore di riduzione della scala potenziale \\(\\hat{R}\\) come la radice quadrata del rapporto tra la varianza combinata \\(\\hat{V}\\) e la varianza all’interno delle catene \\(W\\):\n\n\\[\n\\hat{R} = \\sqrt{\\frac{\\hat{V}}{W}}.\n\\]\n\nSe \\(\\hat{R}\\) è vicino a 1, ciò indica che le catene sono in convergenza.\n\nLa statistica di Gelman-Rubin \\(\\hat{R}\\) è una misura di convergenza per le catene di Markov. Essa quantifica il grado di accordo tra più catene, fornendo uno strumento diagnostico per valutare la convergenza nelle simulazioni MCMC.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#vantaggi-del-campionamento-mcmc-rispetto-alle-soluzioni-analitiche",
    "href": "chapters/mcmc/01_metropolis.html#vantaggi-del-campionamento-mcmc-rispetto-alle-soluzioni-analitiche",
    "title": "52  L’algoritmo di Metropolis-Hastings",
    "section": "\n52.10 Vantaggi del Campionamento MCMC rispetto alle Soluzioni Analitiche",
    "text": "52.10 Vantaggi del Campionamento MCMC rispetto alle Soluzioni Analitiche\nIl campionamento MCMC offre notevoli vantaggi pratici rispetto alle soluzioni analitiche nella statistica bayesiana, in particolare quando si tratta di manipolare distribuzioni a posteriori. Sebbene l’impossibilità di calcolare analiticamente la distribuzione a posteriori sia spesso la motivazione principale per l’uso di MCMC, i benefici di questo approccio si estendono ben oltre questa necessità (Bürkner, 2024).\n\n52.10.1 Facilità di Manipolazione e Flessibilità\nIl vantaggio chiave del campionamento MCMC risiede nella semplicità con cui si possono manipolare i campioni ottenuti. Mentre le densità calcolate analiticamente possono richiedere trasformazioni matematiche complesse, i campioni MCMC possono essere facilmente trasformati con operazioni dirette. Questa flessibilità si manifesta in diversi aspetti:\n\n\nTrasformazioni di Variabili: Consideriamo un caso in cui siamo interessati alla varianza residua (\\(\\sigma^2\\)) in un modello, ma abbiamo campioni solo della deviazione standard residua (\\(\\sigma\\)). Con il campionamento MCMC, la trasformazione è immediata:\n\n\\[\n(\\sigma^{(s)})^2 = \\sigma^{2(s)},\n\\]\ndove \\(s\\) indica il singolo campione. Questa operazione si traduce semplicemente nell’elevare al quadrato ogni campione di \\(\\sigma\\), ottenendo direttamente campioni validi di \\(\\sigma^2\\). In contrasto, con una densità analitica di \\(\\sigma\\), la trasformazione richiederebbe l’applicazione dell’aggiustamento del Jacobiano, un processo matematicamente più complesso.\n\n\nCombinazione di Parametri: Il MCMC semplifica notevolmente la combinazione di parametri in modelli statistici. Per una quantità \\(\\theta\\) che dipende da parametri \\(\\beta_1\\) e \\(\\beta_2\\) attraverso una funzione \\(f\\), possiamo calcolare:\n\n\\[\n\\theta^{(s)} = f(\\beta_1^{(s)}, \\beta_2^{(s)}).\n\\]\nQuesta operazione si estende facilmente a combinazioni complesse e funzioni non lineari, contrastando nettamente con la complessità di derivare analiticamente la distribuzione di \\(\\theta\\).\nIn conclusione, il campionamento MCMC non è solo una necessità quando le soluzioni analitiche sono introvabili, ma offre vantaggi in termini di facilità di manipolazione, flessibilità computazionale e applicabilità pratica.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#caso-normale-normale-con-soluzione-analitica",
    "href": "chapters/mcmc/01_metropolis.html#caso-normale-normale-con-soluzione-analitica",
    "title": "52  L’algoritmo di Metropolis-Hastings",
    "section": "\n52.11 Caso Normale-Normale con Soluzione Analitica",
    "text": "52.11 Caso Normale-Normale con Soluzione Analitica\nConsideriamo un caso normale-normale per cui possiamo derivare una soluzione analitica. Supponiamo che il prior sia distribuito secondo \\(\\mathcal{N}(30, 5^2)\\).\nDefiniamo le funzioni per il prior, la verosimiglianza e il posterior non normalizzato.\n\n# Prior: Normal(30, 5^2)\nprior &lt;- function(mu) {\n  dnorm(mu, mean = 30, sd = 5)\n}\n\n# Likelihood: Normal(mu, sigma^2) con sigma calcolata dai dati\nlikelihood &lt;- function(mu, data) {\n  sigma &lt;- sd(data)  # Deviazione standard dei dati\n  prod(dnorm(data, mean = mu, sd = sigma))\n}\n\n# Posterior non normalizzato\nposterior &lt;- function(mu, data) {\n  likelihood(mu, data) * prior(mu)\n}\n\nImplementiamo l’algoritmo di Metropolis per il caso normale-normale:\n\n# Algoritmo di Metropolis\nmetropolis_for_normal &lt;- function(nsamp, xinit, data) {\n  samples &lt;- numeric(nsamp)\n  x_prev &lt;- xinit\n  \n  for (i in seq_len(nsamp)) {\n    x_star &lt;- rnorm(1, mean = x_prev, sd = 0.5)  # Proposta\n    if (runif(1) &lt; min(1, posterior(x_star, data) / posterior(x_prev, data))) {\n      x_prev &lt;- x_star\n    }\n    samples[i] &lt;- x_prev\n  }\n  \n  samples\n}\n\nUtilizziamo un campione di 30 valori BDI-II forniti da Zetsche et al. (2019):\n\n# Dati osservati\ny &lt;- c(\n  26, 35, 30, 25, 44, 30, 33, 43, 22, 43, 24, 19, 39, 31, 25, \n  28, 35, 30, 26, 31, 41, 36, 26, 35, 33, 28, 27, 34, 27, 22\n)\n\nEsecuzione dell’algoritmo:\n\nsamples &lt;- metropolis_for_normal(100000, mean(y), y)\n\nNel caso normale-normale, il posterior può essere calcolato analiticamente come segue:\n\n# Parametri del prior\nmu_prior &lt;- 30\nstd_prior &lt;- 5\nvar_prior &lt;- std_prior^2\n\n# Calcolo dei parametri posterior\nn &lt;- length(y)\nsum_y &lt;- sum(y)\nvar_data &lt;- var(y)\n\nmu_post &lt;- (mu_prior / var_prior + sum_y / var_data) / (1 / var_prior + n / var_data)\nvar_post &lt;- 1 / (1 / var_prior + n / var_data)\nstd_post &lt;- sqrt(var_post)\n\nmu_post\n#&gt; [1] 30.9\nstd_post\n#&gt; [1] 1.17\n\nVisualizziamo i risultati con un istogramma dei campioni MCMC e la curva della distribuzione analitica:\n\n# Campioni post burn-in\nburnin &lt;- floor(length(samples) * 0.5)\npost_samples &lt;- samples[-seq_len(burnin)]\n\n# Dati per la curva analitica\nx &lt;- seq(mu_post - 4 * std_post, mu_post + 4 * std_post, length.out = 1000)\nanalytical_posterior &lt;- dnorm(x, mean = mu_post, sd = std_post)\n\n# Creazione del grafico\nggplot() +\n  geom_histogram(aes(x = post_samples, y = ..density..), bins = 30, fill = \"blue\", alpha = 0.4) +\n  geom_line(aes(x = x, y = analytical_posterior), color = \"red\", size = 1) +\n  labs(title = \"Distribuzione Posterior: MCMC vs Analitico\",\n       x = expression(mu), y = \"Densità\") \n#&gt; Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#&gt; ℹ Please use `linewidth` instead.\n#&gt; Warning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\n#&gt; ℹ Please use `after_stat(density)` instead.\n\n\n\n\n\n\n\nTroviamo le proprietà del Posterior derivato con MCMC:\n\nmean(samples)\n#&gt; [1] 30.9\n\n\nsd(samples)\n#&gt; [1] 1.18\n\nIn conclusione, questo esempio mostra come applicare l’algoritmo di Metropolis per stimare una distribuzione a posteriori e come confrontare i risultati del sampling con la soluzione analitica, confermando la coerenza tra le due tecniche.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#riflessioni-conclusive",
    "href": "chapters/mcmc/01_metropolis.html#riflessioni-conclusive",
    "title": "52  L’algoritmo di Metropolis-Hastings",
    "section": "\n52.12 Riflessioni Conclusive",
    "text": "52.12 Riflessioni Conclusive\nIn molti casi, la distribuzione a posteriori dei parametri di un modello statistico non ha una forma analitica risolvibile. Per affrontare questa limitazione, si utilizzano metodi Monte Carlo basati su catene di Markov (MCMC). Questi algoritmi permettono di campionare efficacemente dalla distribuzione a posteriori, anche per modelli complessi, generando una sequenza di valori che approssima la distribuzione desiderata. L’algoritmo di Metropolis-Hastings (Hastings, 1970), un’estensione dell’algoritmo di Metropolis originale (Metropolis et al., 1953), è uno dei metodi MCMC più ampiamente utilizzati.\nIn sintesi, l’algoritmo segue questi passaggi principali:\n\n\nGenerazione del nuovo stato proposto: Si crea un nuovo stato vicino a quello corrente utilizzando una distribuzione di proposta.\n\nConfronto tra densità posteriori: Si confrontano le densità a posteriori del nuovo stato proposto e dello stato corrente.\n\nAccettazione probabilistica: Il nuovo stato viene sempre accettato se ha una densità posteriore maggiore, oppure accettato con una certa probabilità se ha una densità minore.\n\nBurn-in e tasso di accettazione: I primi campioni vengono scartati (fase di burn-in) per garantire che la catena abbia raggiunto la distribuzione stazionaria, e si monitora il tasso di accettazione per ottimizzare l’efficienza del campionamento.\n\nQuesto approccio consente di ottenere campioni che approssimano la distribuzione a posteriori, ma l’algoritmo di Metropolis può presentare limiti di efficienza, soprattutto per problemi ad alta dimensionalità o distribuzioni con geometrie complesse. Un aspetto cruciale è il tasso di accettazione, che rappresenta il rapporto tra il numero di proposte accettate e il numero totale di proposte. Un tasso troppo basso può indicare che la catena esplora lo spazio dei parametri in modo inefficiente, mentre un tasso troppo alto può segnalare che i passi effettuati sono troppo piccoli per consentire una buona esplorazione.\nRispetto alle varianti più moderne, l’algoritmo di Metropolis tende a essere meno efficiente. Metodi come il No-U-Turn Sampler (NUTS) e l’Hamiltonian Monte Carlo (HMC) offrono miglioramenti significativi, specialmente in spazi di parametri di grandi dimensioni. NUTS, ad esempio, viene utilizzato in strumenti avanzati come Stan e PyMC (Hoffman et al., 2014), permettendo un’esplorazione più rapida e accurata della distribuzione a posteriori.\nTra gli altri algoritmi MCMC degni di nota troviamo il campionatore di Gibbs (Geman & Geman, 1984) e l’Hamiltonian Monte Carlo (Duane et al., 1987). Questi metodi, insieme a Metropolis-Hastings, formano la base di numerose tecniche moderne per il campionamento da distribuzioni complesse. Per un approfondimento dettagliato sulle tecniche MCMC, si consiglia di consultare Hanada & Matsuura (2022).",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/01_metropolis.html#informazioni-sullambiente-di-sviluppo",
    "title": "52  L’algoritmo di Metropolis-Hastings",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] cmdstanr_0.8.1.9000 see_0.9.0           gridExtra_2.3      \n#&gt;  [4] patchwork_1.3.0     bayesplot_1.11.1    psych_2.4.12       \n#&gt;  [7] scales_1.3.0        markdown_1.13       knitr_1.49         \n#&gt; [10] lubridate_1.9.4     forcats_1.0.0       stringr_1.5.1      \n#&gt; [13] dplyr_1.1.4         purrr_1.0.2         readr_2.1.5        \n#&gt; [16] tidyr_1.3.1         tibble_3.2.1        ggplot2_3.5.1      \n#&gt; [19] tidyverse_2.0.0     rio_1.2.3           here_1.0.1         \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tensorA_0.36.2.1     generics_0.1.3       stringi_1.8.4       \n#&gt;  [4] lattice_0.22-6       hms_1.1.3            digest_0.6.37       \n#&gt;  [7] magrittr_2.0.3       evaluate_1.0.1       grid_4.4.2          \n#&gt; [10] timechange_0.3.0     fastmap_1.2.0        R.oo_1.27.0         \n#&gt; [13] rprojroot_2.0.4      jsonlite_1.8.9       R.utils_2.12.3      \n#&gt; [16] backports_1.5.0      abind_1.4-8          mnormt_2.1.1        \n#&gt; [19] cli_3.6.3            rlang_1.1.4          R.methodsS3_1.8.2   \n#&gt; [22] munsell_0.5.1        withr_3.0.2          tools_4.4.2         \n#&gt; [25] parallel_4.4.2       tzdb_0.4.0           checkmate_2.3.2     \n#&gt; [28] colorspace_2.1-1     pacman_0.5.1         posterior_1.6.0     \n#&gt; [31] vctrs_0.6.5          R6_2.5.1             lifecycle_1.0.4     \n#&gt; [34] htmlwidgets_1.6.4    pkgconfig_2.0.3      pillar_1.10.0       \n#&gt; [37] gtable_0.3.6         data.table_1.16.4    glue_1.8.0          \n#&gt; [40] xfun_0.49            tidyselect_1.2.1     farver_2.1.2        \n#&gt; [43] htmltools_0.5.8.1    nlme_3.1-166         labeling_0.4.3      \n#&gt; [46] rmarkdown_2.29       compiler_4.4.2       distributional_0.5.0",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#bibliografia",
    "href": "chapters/mcmc/01_metropolis.html#bibliografia",
    "title": "52  L’algoritmo di Metropolis-Hastings",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBürkner, P.-C. (2024). The brms Book: Applied Bayesian Regression Modelling Using R and Stan (Early Draft). https://paulbuerkner.com/software/brms-book\n\n\nDuane, S., Kennedy, A. D., Pendleton, B. J., & Roweth, D. (1987). Hybrid monte carlo. Physics letters B, 195(2), 216–222.\n\n\nGeman, S., & Geman, D. (1984). Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images. IEEE Transactions on pattern analysis and machine intelligence, 6, 721–741.\n\n\nHanada, M., & Matsuura, S. (2022). MCMC from Scratch. Springer.\n\n\nHastings, W. K. (1970). Monte Carlo sampling methods using Markov chains and their applications. Biometrika, 57(1), 97–109.\n\n\nHoffman, M. D., Gelman, A., et al. (2014). The No-U-Turn sampler: adaptively setting path lengths in Hamiltonian Monte Carlo. Journal of Machine Learning Research, 15(1), 1593–1623.\n\n\nMetropolis, N., Rosenbluth, A. W., Rosenbluth, M. N., Teller, A. H., & Teller, E. (1953). Equation of state calculations by fast computing machines. The Journal of Chemical Physics, 21(6), 1087–1092.\n\n\nZetsche, U., Buerkner, P.-C., & Renneberg, B. (2019). Future expectations in clinical depression: biased or realistic? Journal of Abnormal Psychology, 128(7), 678–688.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_ppl.html",
    "href": "chapters/mcmc/02_ppl.html",
    "title": "53  Linguaggi di programmazione probabilistici",
    "section": "",
    "text": "53.1 Cos’è la programmazione probabilistica\nLa programmazione probabilistica è un paradigma della programmazione informatica che consente di creare modelli e algoritmi capaci di gestire l’incertezza e la casualità. Combina i principi della teoria delle probabilità con la programmazione, permettendo di costruire sistemi in grado di ragionare su dati incerti e di prendere decisioni informate. Questo approccio consente di esprimere modelli complessi in modo naturale e intuitivo, facilitando il processo di inferenza bayesiana.\nLa programmazione probabilistica si colloca all’intersezione tra algoritmi di machine learning, statistica e linguaggi di programmazione. I suoi obiettivi principali sono semplificare il processo di inferenza e automatizzarlo.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Linguaggi di programmazione probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_ppl.html#perché-abbiamo-bisogno-della-programmazione-probabilistica",
    "href": "chapters/mcmc/02_ppl.html#perché-abbiamo-bisogno-della-programmazione-probabilistica",
    "title": "53  Linguaggi di programmazione probabilistici",
    "section": "53.2 Perché abbiamo bisogno della programmazione probabilistica?",
    "text": "53.2 Perché abbiamo bisogno della programmazione probabilistica?\nScrivere un proprio campionatore per l’inferenza bayesiana è un compito estremamente difficile. Richiede competenze matematiche avanzate e una profonda conoscenza degli algoritmi di campionamento (sia MCMC che approssimati). Inoltre, ci sono numerosi problemi potenziali legati alla stabilità numerica e ai costi computazionali. Questo significa che per riuscirci bisogna essere allo stesso tempo degli ottimi sviluppatori e degli esperti statistici.\nÈ però possibile delegare tutti questi compiti a un sistema che li automatizzi, permettendoci di concentrarci sulla risoluzione dei problemi scientifici.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Linguaggi di programmazione probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_ppl.html#linguaggi-di-programmazione-probabilistica-ppls",
    "href": "chapters/mcmc/02_ppl.html#linguaggi-di-programmazione-probabilistica-ppls",
    "title": "53  Linguaggi di programmazione probabilistici",
    "section": "53.3 Linguaggi di programmazione probabilistica (PPLs)",
    "text": "53.3 Linguaggi di programmazione probabilistica (PPLs)\nIn questa sezione esamineremo il panorama moderno dei linguaggi di programmazione probabilistica (PPLs) e, nella sezione successiva, esploreremo le funzionalità di uno di questi, Stan.\n\n53.3.1 Linguaggi di Programmazione Probabilistica (PPL)\nUn linguaggio di programmazione probabilistica (PPL) consente di formalizzare modelli bayesiani e di eseguire inferenze utilizzando algoritmi avanzati. L’utente deve semplicemente definire il modello, selezionare un campionatore e avviare il processo di inferenza.\nIn generale, le funzionalità fondamentali richieste a un PPL sono:\n\ngenerare valori casuali da distribuzioni probabilistiche;\ncondizionare variabili su dati osservati.\n\nI primi linguaggi di programmazione probabilistica, come BUGS e WinBUGS, hanno gettato le basi offrendo tre capacità essenziali:\n\nrandom: per definire variabili casuali.\nconstraint: per vincolare variabili ai dati osservati.\ninfer: per calcolare e restituire la distribuzione delle variabili di interesse.\n\nNel corso del tempo, l’elenco dei PPL disponibili si è notevolmente ampliato, comprendendo una vasta gamma di strumenti in continua evoluzione. Ecco alcuni esempi rappresentativi:\n\nBUGS, WinBUGS, JAGS\nStan\nPyMC3, PyMC4, PyMC\nNimble\nPyro, NumPyro\nEdward, TensorFlow Probability, Edward 2\nGen\nTuring\nStheno\nSOSS\nOmega\nInfer.NET",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Linguaggi di programmazione probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_ppl.html#come-scegliere-un-ppl",
    "href": "chapters/mcmc/02_ppl.html#come-scegliere-un-ppl",
    "title": "53  Linguaggi di programmazione probabilistici",
    "section": "53.4 Come scegliere un PPL?",
    "text": "53.4 Come scegliere un PPL?\nDal punto di vista pratico, come si può decidere quale linguaggio di programmazione probabilistica utilizzare? Ecco alcuni fattori chiave da considerare:\n\nDocumentazione: La presenza di risorse ben strutturate, come guide, tutorial e documentazione ufficiale, è essenziale per facilitare l’apprendimento e migliorare la produttività. Un PPL con documentazione chiara e completa è sempre preferibile, specialmente per chi è alle prime armi.\nPerformance: Alcuni PPL sono ottimizzati per offrire prestazioni superiori, ad esempio mediante l’elaborazione parallela o l’uso di acceleratori hardware come le GPU. Valuta le prestazioni in relazione alla complessità e alla scala dei modelli che desideri costruire.\nFunzionalità: È importante verificare se il PPL offre un’ampia gamma di distribuzioni probabilistiche e campionatori, oltre a strumenti avanzati per personalizzare i modelli e implementare inferenze specifiche.\nSupporto della comunità: Una comunità attiva può fare la differenza quando incontri difficoltà. Forum, gruppi di discussione e risorse condivise dagli utenti (come esempi pratici o risposte a domande frequenti) sono fondamentali per risolvere problemi in modo rapido e imparare dalle esperienze di altri.\nIntegrazione: Considera quanto bene il PPL si integra con gli strumenti e i framework già in uso. Per esempio, se utilizzi librerie per la manipolazione dei dati, la visualizzazione o il machine learning, come pandas, ggplot o TensorFlow, verifica che il PPL scelto supporti queste interazioni senza complicazioni.\n\n\n53.4.1 API\nI linguaggi di programmazione probabilistica (PPL) permettono agli utenti di definire con precisione le caratteristiche dei priori, della verosimiglianza e dell’intero modello bayesiano. Inoltre, offrono strumenti per effettuare le necessarie trasformazioni sui dati, garantendo la flessibilità richiesta per affrontare una vasta gamma di problemi statistici. Tuttavia, anche se i PPL cercano di semplificare queste operazioni, l’utente deve comunque scrivere codice che rispetti i vincoli sintattici e logici specifici del linguaggio. Questo richiede non solo competenze di programmazione, ma anche una buona conoscenza dei principi statistici e bayesiani.\nPer venire incontro a utenti che desiderano utilizzare l’inferenza bayesiana senza doversi addentrare nella programmazione, sono state sviluppate interfacce di alto livello. Queste interfacce permettono di specificare modelli statistici comuni in modo intuitivo, utilizzando una sintassi semplificata. Sebbene offrano meno controllo sui dettagli tecnici del modello, garantiscono comunque la possibilità di personalizzare elementi cruciali, come i priori e la verosimiglianza, rendendo l’inferenza bayesiana accessibile anche a chi non ha competenze di programmazione.\n\n\n53.4.2 Principali Interfacce di Alto Livello\nTra le interfacce più popolari troviamo:\n\nbrms: utilizza Stan come motore sottostante per eseguire l’inferenza.\nBambi: si basa su PyMC per eseguire l’inferenza bayesiana.\n\nEntrambe queste librerie adottano una sintassi semplificata, nota come sintassi di Wilkinson (Wilkinson & Rogers, 1973). Questo approccio consente di specificare modelli in modo dichiarativo, usando una struttura simile a quella adottata da pacchetti R come lm (per modelli di regressione lineare) o lme4 (per modelli multilivello con lmer).\nAd esempio, in brms è possibile specificare un modello di regressione lineare con una sintassi simile a questa:\nfit &lt;- brm(y ~ x1 + x2, data = dataset)\nIn questo esempio y ~ x1 + x2 definisce la relazione tra la variabile dipendente (y) e le variabili indipendenti (x1 e x2).\n\n\n53.4.3 Vantaggi delle Interfacce di Alto Livello\n\nAccessibilità: Riduzione della complessità sintattica, rendendo l’inferenza bayesiana più accessibile a un pubblico più ampio, inclusi studenti e ricercatori con competenze di programmazione limitate.\nFlessibilità: Sebbene più semplici, le interfacce consentono di specificare prior distribuiti in modo personalizzato e di modificare molteplici aspetti del modello.\nEfficienza: Automatizzano molti passaggi tecnici, permettendo di concentrarsi sulla definizione del modello e sull’interpretazione dei risultati.\nCompatibilità: Integrazione con strumenti statistici familiari, come il framework di modelli lineari in R.\n\nIn questo corso, utilizzeremo principalmente brms per specificare e stimare modelli di regressione lineare e multilivello, sfruttandone la sintassi intuitiva e l’integrazione con R. Negli approfondimenti, invece, esploreremo come scrivere direttamente modelli in Stan, per comprendere meglio le basi dei PPL e avere maggiore controllo sui dettagli tecnici.\nQuesta combinazione ci permetterà di bilanciare semplicità e potenza, rendendo l’inferenza bayesiana sia accessibile che personalizzabile, a seconda delle esigenze specifiche del progetto o dell’analisi.\n\n\n53.4.4 Introduzione alla sintassi di Wilkinson\nLa sintassi di Wilkinson in R fornisce un modo semplice ed efficace per specificare modelli di regressione lineare, consentendo di descrivere relazioni tra una variabile dipendente (risposta) e una o più variabili indipendenti (predittori) utilizzando una notazione simbolica. Questa sintassi si allinea direttamente al modello matematico, rendendo immediata la corrispondenza tra i termini simbolici e il codice.\n\n53.4.4.1 Modello simbolico e modello Wilkinson\nSupponiamo di voler specificare un modello di regressione lineare multipla con la seguente formula:\n\\[\ny_i = \\alpha + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\varepsilon_i ,\n\\]\ndove:\n\n\\(y_i\\) è la variabile dipendente per l’osservazione \\(i\\),\n\\(\\alpha\\) è l’intercetta,\n\\(\\beta_1\\) e \\(\\beta_2\\) sono i coefficienti di regressione per i predittori \\(x_1\\) e \\(x_2\\),\n\\(\\varepsilon_i\\) rappresenta l’errore residuo, normalmente distribuito (\\(\\varepsilon_i \\sim \\mathcal{N}(0, \\sigma^2)\\)).\n\nIn R, questo modello può essere specificato con la sintassi Wilkinson:\ny ~ x1 + x2\n\n\n53.4.4.2 Dettaglio dei componenti\n\nIntercetta implicita:\nLa sintassi R include automaticamente l’intercetta (\\(\\alpha\\)) quando si utilizza il simbolo +. Ad esempio:\ny ~ x1 + x2\nequivale al modello: \\[\ny_i = \\alpha + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\varepsilon_i\n\\]\nEsclusione dell’intercetta:\nSe si desidera escludere l’intercetta (\\(\\alpha\\)), si utilizza - 1 nella specifica:\ny ~ x1 + x2 - 1\nQuesto produce un modello senza intercetta: \\[\ny_i = \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\varepsilon_i\n\\]\nInclusione esplicita dell’intercetta:\nAnche se è implicita, l’intercetta può essere specificata esplicitamente con 1 +:\ny ~ 1 + x1 + x2\nQuesto è equivalente al modello con intercetta implicita.\nInterazione tra predittori:\nLa sintassi Wilkinson consente anche di specificare interazioni. Ad esempio, un’interazione tra \\(x_1\\) e \\(x_2\\):\ny ~ x1 * x2\nEspande automaticamente il modello per includere: \\[\ny_i = \\alpha + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\beta_3 (x_{1i} \\cdot x_{2i}) + \\varepsilon_i\n\\]\n\n\n\n53.4.4.3 Esempio pratico\nSupponiamo di avere un dataset con una variabile dipendente y e due predittori x1 e x2. Ecco come specificare e adattare un modello di regressione lineare multipla in R:\n# Specifica del modello\nmodello &lt;- lm(y ~ x1 + x2, data = dataset)\n\n# Sommario del modello\nsummary(modello)\nQuesto codice:\n\nSpecifica un modello con intercetta e due predittori.\nAdatta il modello ai dati contenuti in dataset.\nCalcola i coefficienti (\\(\\alpha, \\beta_1, \\beta_2\\)), i valori di errore standard, i p-value (frequentisti) e altre statistiche di sintesi.\n\nIn sintesi, la sintassi di Wilkinson in R permette di esprimere modelli di regressione lineare in modo conciso e leggibile, rendendo il passaggio dal modello matematico al codice intuitivo e diretto.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Linguaggi di programmazione probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_ppl.html#riflessioni-conclusive",
    "href": "chapters/mcmc/02_ppl.html#riflessioni-conclusive",
    "title": "53  Linguaggi di programmazione probabilistici",
    "section": "53.5 Riflessioni Conclusive",
    "text": "53.5 Riflessioni Conclusive\nI linguaggi di programmazione probabilistica (PPL) rappresentano strumenti potenti per la specificazione completa e flessibile di modelli bayesiani, consentendo agli utenti di definire ogni aspetto del modello, dai priori alla verosimiglianza, fino agli algoritmi di inferenza. Strumenti come Stan e PyMC permettono un controllo dettagliato sui modelli, rendendoli ideali per analisi avanzate e progetti personalizzati.\nTuttavia, questo livello di controllo richiede competenze di programmazione e una comprensione approfondita della statistica bayesiana. Per superare queste barriere e rendere l’inferenza bayesiana accessibile a un pubblico più ampio, sono state sviluppate interfacce di alto livello come brms (basata su Stan) e Bambi (basata su PyMC). Questi strumenti semplificano enormemente il processo, consentendo agli utenti di specificare modelli statistici complessi senza la necessità di scrivere codice dettagliato, grazie a una sintassi intuitiva come quella di Wilkinson.\nIn sintesi:\n\nI PPL offrono flessibilità massima e un controllo completo, ma richiedono esperienza nella programmazione.\nLe interfacce di alto livello rendono possibile l’inferenza bayesiana anche a chi preferisce evitare la programmazione, garantendo un compromesso tra semplicità e capacità di personalizzazione.\n\nLa scelta tra un PPL e un’interfaccia di alto livello dipende quindi dalle esigenze specifiche: chi necessita di modelli estremamente personalizzati e complessi opterà per un PPL come Stan o PyMC, mentre chi desidera facilità d’uso senza rinunciare alla potenza dell’inferenza bayesiana troverà in brms o Bambi strumenti ideali. In ogni caso, la crescente disponibilità di strumenti e risorse rende oggi l’inferenza bayesiana più accessibile che mai, anche per chi non ha un background tecnico avanzato.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Linguaggi di programmazione probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_ppl.html#bibliografia",
    "href": "chapters/mcmc/02_ppl.html#bibliografia",
    "title": "53  Linguaggi di programmazione probabilistici",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nWilkinson, G., & Rogers, C. (1973). Symbolic description of factorial models for analysis of variance. Journal of the Royal Statistical Society Series C: Applied Statistics, 22(3), 392–399.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Linguaggi di programmazione probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_language.html",
    "href": "chapters/mcmc/03_stan_language.html",
    "title": "54  Linguaggio Stan 🔸",
    "section": "",
    "text": "54.1 Introduzione\nStan è un linguaggio di programmazione probabilistica (PPL) progettato per l’inferenza bayesiana su modelli complessi. Tra le sue caratteristiche principali, Stan implementa un algoritmo avanzato chiamato No-U-Turn Sampler (NUTS), che ottimizza il metodo Hamiltonian Monte Carlo (HMC). Questa tecnica rappresenta un’evoluzione rispetto all’algoritmo di Metropolis (Capitolo 52), tradizionalmente utilizzato per generare campioni da distribuzioni a posteriori. Sebbene entrambi gli approcci producano lo stesso risultato finale, NUTS riduce drasticamente il numero di iterazioni necessarie per raggiungere la convergenza, soprattutto nei modelli ad alta dimensionalità.\nDal punto di vista concettuale, NUTS e Metropolis mirano a costruire una catena di Markov che converga alla distribuzione a posteriori target. Tuttavia, NUTS lo fa in modo molto più efficiente, rendendolo la scelta preferita quando si analizzano modelli complessi. Stan combina questa efficienza con un’interfaccia flessibile, compatibile con diverse piattaforme come R, Python e Julia. In questo corso, useremo cmdstanr, l’interfaccia R per Stan. Oltre a cmdstanr, esistono altre interfacce come CmdStanPy per Python e Stan.jl per Julia, che facilitano l’integrazione di Stan nei flussi di lavoro di programmazione.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Linguaggio Stan 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_language.html#stan-e-la-programmazione-probabilistica",
    "href": "chapters/mcmc/03_stan_language.html#stan-e-la-programmazione-probabilistica",
    "title": "54  Linguaggio Stan 🔸",
    "section": "\n54.2 Stan e la Programmazione Probabilistica",
    "text": "54.2 Stan e la Programmazione Probabilistica\nLa programmazione probabilistica unisce principi di statistica bayesiana e linguaggi di programmazione, semplificando lo sviluppo di modelli complessi. In un linguaggio PPL come Stan, l’utente deve solo specificare le distribuzioni a priori e la funzione di verosimiglianza. L’inferenza viene poi gestita automaticamente dal linguaggio, che utilizza metodi avanzati di campionamento come NUTS per produrre campioni dalla distribuzione a posteriori.\nUn programma Stan è strutturato in blocchi. Ogni blocco ha una funzione specifica, come dichiarare i dati (data), definire i parametri (parameters), specificare la densità del modello (model) e generare quantità derivate (generated quantities). Questa struttura modulare rende Stan intuitivo e adattabile a un’ampia gamma di applicazioni.\nLe variabili in Stan devono essere dichiarate con tipi specifici (int per interi, real per numeri reali, vector per vettori, ecc.) e possono avere vincoli, come lower=0 o upper=1, per garantire che i loro valori rispettino determinati limiti. Questo approccio, noto come tipizzazione statica, rende i programmi Stan robusti e meno soggetti a errori.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Linguaggio Stan 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_language.html#esecuzione-di-stan-con-cmdstanr",
    "href": "chapters/mcmc/03_stan_language.html#esecuzione-di-stan-con-cmdstanr",
    "title": "54  Linguaggio Stan 🔸",
    "section": "\n54.3 Esecuzione di Stan con CmdStanR",
    "text": "54.3 Esecuzione di Stan con CmdStanR\nPer eseguire un modello Stan, utilizzeremo qui l’interfaccia cmdstanr, che integra CmdStan in R. L’esempio seguente illustra come generare dati simulati da una distribuzione binomiale e analizzare un problema inverso, stimando il parametro di successo \\(\\theta\\).\n\n54.3.1 Simulazione in Avanti\nLa simulazione in avanti consiste nel generare dati simulati da un modello probabilistico noto. Supponiamo di voler simulare i risultati di uno studio con \\(N = 100\\) prove e una probabilità di successo \\(\\theta = 0.3\\). Il codice Stan per questa simulazione è il seguente:\ndata {\n  int&lt;lower=0&gt; N;                   // Numero di prove\n  real&lt;lower=0, upper=1&gt; theta;     // Probabilità di successo\n}\ngenerated quantities {\n  int&lt;lower=0, upper=N&gt; y;          // Numero di successi\n  y = binomial_rng(N, theta);\n}\nPer eseguire il modello in R con cmdstanr dobbiamo compilare il modello:\n\nmodel1 &lt;- cmdstan_model(here(\"stan\", \"binomial-rng.stan\"))\n\nDefinire i dati:\n\ndata_list &lt;- list(N = 100, theta = 0.3)\n\nEseguire il campionamento:\n\nfit1 &lt;- model1$sample(\n  data = data_list, \n  fixed_param = TRUE, \n  seed = 123,\n  show_messages = FALSE )\n\nEstrazione dei risultati:\n\ny_samples &lt;- fit1$draws(variables = \"y\", format = \"matrix\")[, 1]\ny_samples\n#&gt; # A draws_matrix: 1000 iterations, 4 chains, and 1 variables\n#&gt;     variable\n#&gt; draw  y\n#&gt;   1  28\n#&gt;   2  34\n#&gt;   3  31\n#&gt;   4  29\n#&gt;   5  26\n#&gt;   6  25\n#&gt;   7  31\n#&gt;   8  28\n#&gt;   9  30\n#&gt;   10 36\n#&gt; # ... with 3990 more draws\n\nLa simulazione in avanti ci permette di generare dati simulati per esplorare il comportamento del modello sotto specifiche ipotesi sui parametri.\n\n54.3.2 Problema Inverso\nNel problema inverso, l’obiettivo è stimare i parametri di un modello a partire dai dati osservati.\nSupponiamo di analizzare la proporzione di artisti della Generazione X presenti al MoMA, dove 14 artisti su 100 appartengono a questa generazione. Utilizzeremo una distribuzione Beta(4, 6) come prior per il parametro \\(\\theta\\), la probabilità che un artista appartenga alla Generazione X. Il modello Stan corrispondente è il seguente:\ndata {\n  int&lt;lower=0&gt; N;                // Numero di osservazioni\n  int&lt;lower=0, upper=N&gt; y;       // Numero di successi\n  real&lt;lower=0&gt; alpha_prior;     // Parametro alpha del prior Beta\n  real&lt;lower=0&gt; beta_prior;      // Parametro beta del prior Beta\n}\nparameters {\n  real&lt;lower=0, upper=1&gt; theta;  // Probabilità di successo\n}\nmodel {\n  theta ~ beta(alpha_prior, beta_prior);  // Prior\n  y ~ binomial(N, theta);                 // Verosimiglianza\n}\nSupponiamo di osservare 14 successi su 100 prove e vogliamo stimare la probabilità di successo \\(\\theta\\). In questo esempio, imponiamo su \\(\\theta\\) un prior debolmente informativo, Beta(2, 2).\nPer eseguire il modello e stimare \\(\\theta\\) dobbiamo specificare i dati in un formato appropriato per Stan:\n\nstan_data &lt;- list(\n  N = 100, \n  y = 14, \n  alpha_prior = 2, \n  beta_prior = 2\n)\n\nCompiliamo il modello:\n\nmodel2 &lt;- cmdstan_model(here(\"stan\", \"moma_model.stan\"))\n\nEseguiamo il campionamento:\n\nfit2 &lt;- model2$sample(\n  data = stan_data, \n  iter_warmup = 2000, \n  iter_sampling = 2000, \n  seed = 42,\n  show_messages = FALSE \n)\n\nIl metodo sample() esegue il modello Stan utilizzando un algoritmo a campionamento iterativo (di solito Hamiltonian Monte Carlo). Durante il burn-in (prime iterazioni), i campioni potrebbero non rappresentare accuratamente la distribuzione a posteriori. Questi campioni iniziali vengono scartati e solo quelli successivi sono utilizzati per costruire stime dalla distribuzione a posteriori.\nRecuperiamo i campioni di theta dall’oggetto fit2:\n\ntheta2_samples &lt;- fit2$draws(variables = \"theta\", format = \"array\")\ndim(theta2_samples)\n#&gt; [1] 2000    4    1\n\nQuesto indica la struttura dell’array estratto dal modello Stan. Significa che il campionamento ha prodotto 2000 iterazioni per ciascuna delle 4 catene. L’ultimo valore (1) rappresenta il numero di variabili monitorate nel modello (in questo caso, una sola variabile). Quindi, il formato dell’array è (iterazioni, catene, variabili).\n\ntheta2_samples |&gt; \n  glimpse()\n#&gt;  'draws_array' num [1:2000, 1:4, 1] 0.132 0.144 0.134 0.143 0.116 ...\n#&gt;  - attr(*, \"dimnames\")=List of 3\n#&gt;   ..$ iteration: chr [1:2000] \"1\" \"2\" \"3\" \"4\" ...\n#&gt;   ..$ chain    : chr [1:4] \"1\" \"2\" \"3\" \"4\"\n#&gt;   ..$ variable : chr \"theta\"\n\nPer maneggiare più facilmente i campioni a posteriori possiamo convertire l’oggetto theta2_samples in un vettore:\n\ntheta2_vector &lt;- as.vector(theta2_samples)\nlength(theta2_vector)\n#&gt; [1] 8000\n\n\ntheta2_vector |&gt; \n  head()\n#&gt; [1] 0.132 0.144 0.134 0.143 0.116 0.211\n\nPer analizzare i campioni generati, possiamo utilizzare istogrammi e tracce MCMC.. Creiamo un istogramma della distribuzione a posteriori di \\(\\theta\\):\n\nggplot(data.frame(theta = theta2_vector), aes(x = theta)) +\n  geom_histogram(bins = 30, fill = \"slateblue\", color = \"black\", alpha = 0.5) +\n  labs(\n    title = \"Distribuzione a Posteriori di Theta\",\n    x = \"Theta\",\n    y = \"Frequenza\"\n  )\n\n\n\n\n\n\n\nLo stesso risultato può essere ottenuto con le funzioni di bayesplot che prende come argomento l’oggetto fit2, senza bisogno di altre trasformazioni:\n\nmcmc_hist(fit2$draws(\"theta\"))\n#&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\nQuesto grafico ci permette di visualizzare la distribuzione a posteriori, valutando sia la modalità (valore più probabile) che l’incertezza (larghezza della distribuzione):\n\nse l’istogramma mostra una distribuzione stretta attorno a un valore, significa che c’è poca incertezza nella stima di \\(\\theta\\).\nuna distribuzione ampia indica maggiore incertezza, suggerendo che i dati osservati non forniscono una stima precisa di \\(\\theta\\).\n\nSi noti come la stima putuale a posteriori e l’intervallo di credibilità riproducono i valori ottenuti utilizzando l’algoritmo di Metropolis (Capitolo 52).\nIn alternativa, è possibile visualizzare la distribuzione a posteriori di theta utilizzando stime della densità kernel al posto degli istogrammi, distinguendo i risultati per ciascuna catena:\n\nbayesplot::mcmc_dens_overlay(fit2$draws(\"theta\"))\n\n\n\n\n\n\n\nUsando la funzione mcmc_trace() possiamo ottenere un trace plot di theta:\n\n bayesplot::mcmc_trace(fit2$draws(\"theta\"), n_warmup=2000)\n\n\n\n\n\n\n\n\nbayesplot::mcmc_intervals(fit2$draws(\"theta\"), prob_outer = 0.94)",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Linguaggio Stan 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_language.html#diagnostiche-di-campionamento",
    "href": "chapters/mcmc/03_stan_language.html#diagnostiche-di-campionamento",
    "title": "54  Linguaggio Stan 🔸",
    "section": "\n54.4 Diagnostiche di Campionamento",
    "text": "54.4 Diagnostiche di Campionamento\nPer valutare la qualità del campionamento, possiamo utilizzare la statistica \\(\\widehat{R}\\).\n\nrhats &lt;- rhat(fit2$draws(\"theta\"))\nprint(rhats)\n#&gt; [1] 1\n\n\nbayesplot::mcmc_rhat(rhats)\n\n\n\n\n\n\n\nUn valore di \\(\\widehat{R}\\) vicino a 1 indica che le catene sono convergenti.\nÈ anche possibile considerare il numero effettivo di campioni (\\(N_{\\text{eff}}\\)): un \\(N_{\\text{eff}}\\) elevato suggerisce una stima precisa dei parametri.\n\nfit2$summary()\n#&gt; # A tibble: 2 × 10\n#&gt;   variable    mean  median     sd    mad       q5     q95  rhat ess_bulk\n#&gt;   &lt;chr&gt;      &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 lp__     -45.2   -44.9   0.731  0.324  -46.6    -44.7    1.00    3699.\n#&gt; 2 theta      0.153   0.152 0.0354 0.0353   0.0991   0.215  1.00    2553.\n#&gt; # ℹ 1 more variable: ess_tail &lt;dbl&gt;\n\nLe colonne dell’output di summary() rappresentano:\n\n\nmean e median: Media e mediana della distribuzione a posteriori. Per theta, la media è 0.153 e la mediana è simile (0.152), suggerendo una distribuzione abbastanza simmetrica.\n\nsd: Deviazione standard della distribuzione (0.0354 per theta).\n\nmad: Deviazione assoluta mediana, una misura di dispersione robusta (simile alla deviazione standard in questo caso).\n\nq5 e q95: Quantili al 5% e al 95%, che definiscono un intervallo di credibilità al 90% per theta (\\([0.0991, 0.215]\\)).\n\nrhat: Statistica di convergenza. Un valore di 1 indica che le catene sono ben miscelate e hanno raggiunto la convergenza.\n\ness_bulk: Dimensione campionaria effettiva, che misura il numero di campioni indipendenti. È alta per entrambe le variabili (3699 per lp__ e 2553 per theta), segnalando un’efficienza del campionamento.\n\n\n54.4.1 Dimensione del Campione Effettivo ed Errore Monte Carlo\nQuando si utilizzano metodi basati su catene di Markov (MCMC), i campioni successivi possono essere correlati. La dimensione del campione effettivo (\\(N_{\\text{eff}}\\)) misura il numero di campioni indipendenti equivalenti e viene calcolata come:\n\\[\nN_{\\text{eff}} = \\frac{M}{\\text{IAT}},\n\\]\ndove \\(\\text{IAT}\\) è il tempo di autocorrelazione integrata. Un \\(N_{\\text{eff}}\\) elevato indica che il campionamento è efficace, riducendo l’errore Monte Carlo. Stan riporta anche l’errore standard MCMC per ogni parametro, dato da:\n\\[\n\\text{mcmc-se} = \\frac{\\text{sd}[\\Theta \\mid Y = y]}{\\sqrt{N_{\\text{eff}}}}.\n\\]\nQuesto valore riflette la precisione delle stime ottenute.\n\n54.4.2 Divergenze, max_treedepth e Efficienza\nLa qualità del campionamento viene ulteriormente verificata mediante la funzione diagnostic_summary():\n\nfit2$diagnostic_summary()\n#&gt; $num_divergent\n#&gt; [1] 0 0 0 0\n#&gt; \n#&gt; $num_max_treedepth\n#&gt; [1] 0 0 0 0\n#&gt; \n#&gt; $ebfmi\n#&gt; [1] 1.18 1.03 1.13 1.14\n\n\nnum_divergent: Mostra il numero di transizioni divergenti per ciascuna catena. Valori pari a 0 indicano che non ci sono stati problemi di campionamento (assenza di transizioni divergenti).\nnum_max_treedepth: Indica il numero di transizioni che hanno raggiunto la profondità massima dell’albero in NUTS. Valori pari a 0 segnalano che il modello è stato esplorato correttamente senza limitazioni imposte dalla profondità dell’albero.\nebfmi: Efficienza dell’Hamiltonian Monte Carlo calcolata tramite il Energy Bayesian Fraction of Missing Information (EBFMI). Tutti i valori sono superiori a 1, indicando un campionamento efficace e nessun problema con l’esplorazione dello spazio dei parametri.\n\nNel caso presente, i risultati ottenuti mostrano che il campionamento è stato efficace:\n\nLe catene hanno convergenza (\\(\\hat{R} = 1\\)).\nNon ci sono stati problemi tecnici come transizioni divergenti o massima profondità raggiunta.\nLe diagnostiche di efficienza (\\(N_{\\text{eff}}\\), EBFMI) confermano un campionamento affidabile.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Linguaggio Stan 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_language.html#verifica-dei-priors",
    "href": "chapters/mcmc/03_stan_language.html#verifica-dei-priors",
    "title": "54  Linguaggio Stan 🔸",
    "section": "\n54.5 Verifica dei Priors",
    "text": "54.5 Verifica dei Priors\nPossiamo verificare se i nostri priors sono adeguati calcolando la probabilità a priori dei parametri di interesse. Ad esempio, nel nostro campione, sappiamo che la proporzione di artisti appartenenti alla Generazione X è 0.14. È importante che i priors consentano configurazioni ragionevoli dei dati ma escludano scenari chiaramente assurdi, basandosi sulla nostra esperienza del dominio. Per verificare se i nostri priors soddisfano questo requisito, possiamo effettuare un prior predictive check.\nPer condurre un prior predictive check, utilizziamo lo stesso modello usato in precedenza, inseriamo i parametri di interesse nel blocco generated_quantities e rimuoviamo il termine relativo alla distribuzione di campionamento (ossia la verosimiglianza) dal modello. Senza la verosimiglianza, i parametri non vengono adattati ai dati e vengono quindi campionati dalla loro distribuzione a priori. Il codice Stan rimane identico a quello finale, ma senza la riga y ~ binomial(N, theta);. Un trucco utile per semplificare i prior predictive check è aggiungere uno switch compute_likelihood ai dati, come mostrato di seguito:\nif (compute_likelihood == 1)\n  y ~ binomial(N, theta);\nCompilazione del modello:\n\nmodel3 &lt;- cmdstan_model(here(\"stan\", \"moma_model_prior.stan\"))\n\n\nmodel3$print()\n#&gt; data {\n#&gt;   int&lt;lower=0&gt; N;\n#&gt;   int&lt;lower=0, upper=N&gt; y;\n#&gt;   int&lt;lower=0&gt; alpha_prior;\n#&gt;   int&lt;lower=0&gt; beta_prior;\n#&gt;   int&lt;lower=0, upper=1&gt; compute_likelihood; // Flag to control likelihood inclusion\n#&gt; }\n#&gt; parameters {\n#&gt;   real&lt;lower=0, upper=1&gt; theta;\n#&gt; }\n#&gt; model {\n#&gt;   theta ~ beta(alpha_prior, beta_prior); // Prior for theta\n#&gt;   \n#&gt;   if (compute_likelihood == 1) {\n#&gt;     y ~ binomial(N, theta); // Likelihood is only included if compute_likelihood == 1\n#&gt;   }\n#&gt; }\n#&gt; generated quantities {\n#&gt;   int&lt;lower=0, upper=N&gt; y_rep;\n#&gt;   int&lt;lower=0, upper=1&gt; theta_gt_025 = theta &gt; 0.25; // Indicator if theta &gt; 0.25\n#&gt;   y_rep = binomial_rng(N, theta); // Simulated data for posterior predictive check\n#&gt; }\n\nQuesto ci consente di utilizzare lo stesso file Stan per eseguire sia i prior predictive check che l’inferenza, semplicemente modificando il valore di compute_likelihood.\nDefiniamo il dizionario dei dati:\n\nstan_data3 &lt;- list(\n  N = 9, # Number of trials\n  y = 0, # Placeholder, not used during prior predictive checks\n  alpha_prior = 2,\n  beta_prior = 2,\n  compute_likelihood = 0 \n  # Set to 0 to disable likelihood for prior predictive check\n)\n\nEseguiamo il campionamento utilizzando solo la distribuzione a priori:\n\n# Campionamento dalla distribuzione a priori (compute_likelihood settato a 0)\nfit3 = model3$sample(\n  data=stan_data3,\n  chains=4,\n  iter_warmup=500,\n  iter_sampling=1000,\n  seed=123,\n  show_message=FALSE\n)\n\nEstraiamo i campioni a priori per il parametro \\(\\theta\\):\n\ntheta3_samples &lt;- as.vector(\n  fit3$draws(variables = \"theta\", format = \"array\")\n)\n\nInfine, creiamo un istogramma per visualizzare la distribuzione a priori di \\(\\theta\\):\n\n# Conversione dei campioni in un vettore per ggplot2\ntheta3_vector &lt;- as.vector(theta3_samples)\n\n# Creazione dell'istogramma\nggplot(data.frame(theta = theta3_vector), aes(x = theta)) +\n  geom_histogram(bins = 30, alpha = 0.5) +\n  labs(\n    title = \"Istogramma della distribuzione a priori di theta\",\n    x = \"Valori di theta\",\n    y = \"Frequenza\"\n  )\n\n\n\n\n\n\n\nIn conclusione, osserviamo che la distribuzione a priori per \\(\\theta\\) include la proporzione campionaria, ma la maggior parte della massa di probabilità si concentra su valori più elevati. Questo suggerisce che la scelta della distribuzione Beta come prior potrebbe non essere completamente ottimale per rappresentare il parametro in questione. Sarà necessario valutare se un prior diverso potrebbe migliorare l’inferenza, garantendo una rappresentazione più accurata delle conoscenze a priori e dei dati osservati.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Linguaggio Stan 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_language.html#stime-puntuali-bayesiane",
    "href": "chapters/mcmc/03_stan_language.html#stime-puntuali-bayesiane",
    "title": "54  Linguaggio Stan 🔸",
    "section": "\n54.6 Stime Puntuali Bayesiane",
    "text": "54.6 Stime Puntuali Bayesiane\nIn un contesto bayesiano, una stima puntuale di un parametro \\(\\Theta\\), condizionata sui dati osservati \\(Y = y\\), è un valore singolo \\(\\hat{\\theta} \\in \\mathbb{R}^D\\) che sintetizza la distribuzione a posteriori \\(p(\\theta \\mid y)\\). La stima puntuale non cattura tutta l’incertezza, ma rappresenta un riassunto della distribuzione a posteriori. Nella statistica, la notazione \\(\\hat{\\theta}\\) è convenzionale per indicare una stima di \\(\\theta\\). Esistono diverse modalità di stima puntuale, ognuna delle quali minimizza una specifica funzione di perdita. Di seguito, esaminiamo la media posteriori, la mediana posteriori e la moda posteriori, discutendo anche le loro proprietà e il loro uso pratico.\n\n54.6.1 Stimatore della Media Posteriori\nLo stimatore della media posteriori è uno dei più comuni in ambito bayesiano. La media posteriori è definita come:\n\\[\n\\widehat{\\theta} = \\mathbb{E}[\\Theta \\mid Y = y] = \\int_{\\Theta} \\theta \\cdot p(\\theta \\mid y) \\, \\mathrm{d}\\theta.\n\\]\nIn pratica, la media è calcolata come la media campionaria dei campioni \\(\\theta^{(m)}\\) estratti dalla distribuzione a posteriori, ovvero:\n\\[\n\\widehat{\\theta} \\approx \\frac{1}{M} \\sum_{m=1}^M \\theta^{(m)},\n\\]\ndove \\(\\theta^{(m)} \\sim p(\\theta \\mid y)\\). Questo metodo sfrutta l’aspettativa condizionale, un concetto chiave dell’inferenza bayesiana. In R, la media posteriori può essere calcolata con:\n\ntheta_hat &lt;- mean(theta2_vector)\ntheta_hat\n#&gt; [1] 0.153\n\nOppure possiamo usare la funzione summary() applicata all’oggetto fit2:\n\nfit2$summary()\n#&gt; # A tibble: 2 × 10\n#&gt;   variable    mean  median     sd    mad       q5     q95  rhat ess_bulk\n#&gt;   &lt;chr&gt;      &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 lp__     -45.2   -44.9   0.731  0.324  -46.6    -44.7    1.00    3699.\n#&gt; 2 theta      0.153   0.152 0.0354 0.0353   0.0991   0.215  1.00    2553.\n#&gt; # ℹ 1 more variable: ess_tail &lt;dbl&gt;\n\n\n54.6.2 Stimatore della Mediana Posteriori\nUn’altra stima puntuale è la mediana posteriori, \\(\\theta^+\\). Essa è definita come il valore che divide la distribuzione a posteriori in due parti uguali, cioè:\n\\[\n\\Pr[\\Theta \\leq \\theta^+] = \\frac{1}{2}.\n\\]\nLa mediana posteriori è calcolata ordinando i campioni e identificando il punto centrale. In R, può essere calcolata con:\n\ntheta_plus &lt;- median(theta2_vector)\ntheta_plus\n#&gt; [1] 0.152\n\nSe la distribuzione a posteriori è simmetrica, media e mediana coincideranno o saranno molto simili. Tuttavia, per distribuzioni asimmetriche, la mediana è più robusta, in quanto minimizza l’errore assoluto atteso rispetto alla media.\n\n54.6.3 Stimatore della Moda Posteriori\nLa moda posteriori rappresenta il valore di \\(\\theta\\) che massimizza la densità a posteriori. Formalmente, è definita come:\n\\[\n\\theta^* = \\operatorname{arg\\,max}_\\theta p(\\theta \\mid y).\n\\]\nQuesta stima, spesso chiamata Maximum A Posteriori (MAP), si focalizza sul punto più probabile della distribuzione. Tuttavia, la moda non tiene conto della variabilità e non minimizza una funzione di perdita basata sui valori veri dei parametri. È meno comune rispetto a media e mediana, soprattutto per distribuzioni non unimodali o altamente asimmetriche.\n\n54.6.4 Proprietà degli Stimatori Bayesiani\nOgni stimatore presenta vantaggi e limitazioni:\n\nLa media posteriori minimizza l’errore quadratico medio atteso. Tuttavia, è sensibile ai valori estremi, specialmente per distribuzioni con code ampie.\nLa mediana posteriori minimizza l’errore assoluto atteso, rendendola più robusta ai valori anomali.\nLa moda posteriori non considera l’incertezza, ma è utile per individuare il valore più probabile.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Linguaggio Stan 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_language.html#quantili-e-intervalli-di-credibilità",
    "href": "chapters/mcmc/03_stan_language.html#quantili-e-intervalli-di-credibilità",
    "title": "54  Linguaggio Stan 🔸",
    "section": "\n54.7 Quantili e Intervalli di Credibilità",
    "text": "54.7 Quantili e Intervalli di Credibilità\nI quantili offrono una descrizione dettagliata della distribuzione a posteriori, fornendo informazioni sulle sue diverse sezioni. Gli intervalli di credibilità, in particolare, rappresentano una porzione specificata della massa di probabilità della distribuzione. Ad esempio, un intervallo di credibilità al 90% è delimitato dai quantili al 5% e al 95%, che includono il 90% della massa di probabilità totale, lasciando il 5% fuori da ciascun lato.\n\n54.7.1 Calcolo dei Quantili con quantile()\n\nIn R, i quantili possono essere calcolati direttamente sui campioni estratti dalla distribuzione a posteriori:\n\nquantile_05 &lt;- quantile(theta2_vector, 0.05)\nquantile_95 &lt;- quantile(theta2_vector, 0.95)\nc(quantile_05, quantile_95)\n#&gt;     5%    95% \n#&gt; 0.0991 0.2153\n\nQuesto calcolo restituisce i limiti inferiori e superiori dell’intervallo di credibilità al 90% della distribuzione di \\(\\theta\\), con il 5% della probabilità distribuito rispettivamente sotto e sopra l’intervallo.\n\n54.7.2 Uso di posterior_interval() con rstanarm\n\nUn metodo alternativo è utilizzare la funzione posterior_interval() del pacchetto rstanarm, che calcola automaticamente gli intervalli di credibilità. Tuttavia, questa funzione richiede che i campioni siano forniti in formato matrice. Pertanto, è necessario estrarre i campioni come matrice da un oggetto di cmdstanr.\nEcco il processo completo:\n\nEstrazione dei Campioni come Matrice\n\nUsiamo l’opzione format = \"matrix\" per convertire i campioni estratti in una matrice compatibile con posterior_interval():\n\ntheta_draws_matrix &lt;- fit2$draws(\"theta\", format = \"matrix\")\n\n\nCalcolo degli Intervalli di Credibilità\n\nUna volta convertiti i campioni, possiamo calcolare l’intervallo di credibilità al 90% con:\n\nrstanarm::posterior_interval(theta_draws_matrix, prob = 0.90)\n#&gt;           5%   95%\n#&gt; theta 0.0991 0.215\n\n\nAlternative con Altri Pacchetti\n\nÈ possibile eseguire il calcolo in modo simile usando il pacchetto rstantools:\n\nrstantools::posterior_interval(\n  fit2$draws(\"theta\", format = \"matrix\"), \n  prob = 0.90\n)\n#&gt;           5%   95%\n#&gt; theta 0.0991 0.215\n\nIn sintesi, entrambi i metodi — quantile() e posterior_interval() — forniscono una stima accurata degli intervalli di credibilità. Il primo approccio offre flessibilità ed è utile per analisi rapide, mentre il secondo è più strutturato e fornisce un’interfaccia standardizzata per analisi bayesiane avanzate.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Linguaggio Stan 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_language.html#riflessioni-conclusive",
    "href": "chapters/mcmc/03_stan_language.html#riflessioni-conclusive",
    "title": "54  Linguaggio Stan 🔸",
    "section": "\n54.8 Riflessioni Conclusive",
    "text": "54.8 Riflessioni Conclusive\nStan, grazie alla sua implementazione dell’algoritmo NUTS, offre un framework potente e flessibile per l’inferenza bayesiana. Attraverso una combinazione di modelli probabilistici ben strutturati, diagnostica avanzata e strumenti di visualizzazione, è possibile affrontare con successo problemi complessi, dalle simulazioni in avanti alle stime inverse dei parametri.\nAbbiamo visto come il pacchetto bayesplot offra varie funzioni per visualizzare le distribuzioni a posteriori dei parametri del modello.\nLa scelta dello stimatore dipende dal contesto e dalle proprietà della distribuzione a posteriori. La media è preferita per la sua capacità di minimizzare l’errore quadratico medio, mentre la mediana è utile per la sua robustezza. La moda può essere utile per individuare il valore più probabile, ma è meno comune nell’analisi bayesiana. La comprensione del bias, dell’errore Monte Carlo e della dimensione del campione effettivo è cruciale per valutare la qualità delle stime e interpretare correttamente i risultati.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Linguaggio Stan 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_language.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/03_stan_language.html#informazioni-sullambiente-di-sviluppo",
    "title": "54  Linguaggio Stan 🔸",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] report_0.5.9        parameters_0.24.0   performance_0.12.4 \n#&gt;  [4] modelbased_0.8.9    insight_1.0.0       effectsize_1.0.0   \n#&gt;  [7] datawizard_0.13.0   correlation_0.8.6   bayestestR_0.15.0  \n#&gt; [10] easystats_0.7.3     posterior_1.6.0     cmdstanr_0.8.1.9000\n#&gt; [13] see_0.9.0           gridExtra_2.3       patchwork_1.3.0    \n#&gt; [16] bayesplot_1.11.1    psych_2.4.12        scales_1.3.0       \n#&gt; [19] markdown_1.13       knitr_1.49          lubridate_1.9.4    \n#&gt; [22] forcats_1.0.0       stringr_1.5.1       dplyr_1.1.4        \n#&gt; [25] purrr_1.0.2         readr_2.1.5         tidyr_1.3.1        \n#&gt; [28] tibble_3.2.1        ggplot2_3.5.1       tidyverse_2.0.0    \n#&gt; [31] rio_1.2.3           here_1.0.1         \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;   [1] tensorA_0.36.2.1     rstudioapi_0.17.1    jsonlite_1.8.9      \n#&gt;   [4] magrittr_2.0.3       TH.data_1.1-2        estimability_1.5.1  \n#&gt;   [7] nloptr_2.1.1         farver_2.1.2         rmarkdown_2.29      \n#&gt;  [10] vctrs_0.6.5          minqa_1.2.8          base64enc_0.1-3     \n#&gt;  [13] htmltools_0.5.8.1    curl_6.0.1           distributional_0.5.0\n#&gt;  [16] StanHeaders_2.32.10  htmlwidgets_1.6.4    plyr_1.8.9          \n#&gt;  [19] sandwich_3.1-1       emmeans_1.10.6       zoo_1.8-12          \n#&gt;  [22] igraph_2.1.2         mime_0.12            lifecycle_1.0.4     \n#&gt;  [25] pkgconfig_2.0.3      colourpicker_1.3.0   Matrix_1.7-1        \n#&gt;  [28] R6_2.5.1             fastmap_1.2.0        shiny_1.10.0        \n#&gt;  [31] digest_0.6.37        colorspace_2.1-1     ps_1.8.1            \n#&gt;  [34] rprojroot_2.0.4      crosstalk_1.2.1      labeling_0.4.3      \n#&gt;  [37] timechange_0.3.0     abind_1.4-8          compiler_4.4.2      \n#&gt;  [40] withr_3.0.2          backports_1.5.0      inline_0.3.20       \n#&gt;  [43] shinystan_2.6.0      QuickJSR_1.4.0       pkgbuild_1.4.5      \n#&gt;  [46] MASS_7.3-61          loo_2.8.0            gtools_3.9.5        \n#&gt;  [49] tools_4.4.2          httpuv_1.6.15        threejs_0.3.3       \n#&gt;  [52] glue_1.8.0           nlme_3.1-166         promises_1.3.2      \n#&gt;  [55] grid_4.4.2           checkmate_2.3.2      reshape2_1.4.4      \n#&gt;  [58] generics_0.1.3       gtable_0.3.6         tzdb_0.4.0          \n#&gt;  [61] data.table_1.16.4    hms_1.1.3            utf8_1.2.4          \n#&gt;  [64] pillar_1.10.0        later_1.4.1          splines_4.4.2       \n#&gt;  [67] lattice_0.22-6       survival_3.8-3       tidyselect_1.2.1    \n#&gt;  [70] miniUI_0.1.1.1       V8_6.0.0             stats4_4.4.2        \n#&gt;  [73] xfun_0.49            rstanarm_2.32.1      matrixStats_1.4.1   \n#&gt;  [76] DT_0.33              rstan_2.32.6         stringi_1.8.4       \n#&gt;  [79] boot_1.3-31          yaml_2.3.10          pacman_0.5.1        \n#&gt;  [82] evaluate_1.0.1       codetools_0.2-20     cli_3.6.3           \n#&gt;  [85] RcppParallel_5.1.9   shinythemes_1.2.0    xtable_1.8-4        \n#&gt;  [88] munsell_0.5.1        processx_3.8.4       Rcpp_1.0.13-1       \n#&gt;  [91] coda_0.19-4.1        parallel_4.4.2       rstantools_2.4.0    \n#&gt;  [94] dygraphs_1.1.1.6     lme4_1.1-35.5        mvtnorm_1.3-2       \n#&gt;  [97] xts_0.14.1           rlang_1.1.4          multcomp_1.4-26     \n#&gt; [100] mnormt_2.1.1         shinyjs_2.1.0",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Linguaggio Stan 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_summary_posterior.html",
    "href": "chapters/mcmc/04_stan_summary_posterior.html",
    "title": "55  Metodi di sintesi della distribuzione a posteriori 🔸",
    "section": "",
    "text": "55.1 Introduzione\nPrerequisiti\nConcetti e Competenze Chiave\nPreparazione del Notebook\nL’obiettivo di questo capitolo è illustrare come sintetizzare una distribuzione a posteriori ottenuta attraverso il campionamento MCMC (Markov Chain Monte Carlo). Questa tecnica è fondamentale nell’inferenza bayesiana moderna, permettendo di comprendere e interpretare i parametri di interesse in modo probabilistico.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_summary_posterior.html#introduzione",
    "href": "chapters/mcmc/04_stan_summary_posterior.html#introduzione",
    "title": "55  Metodi di sintesi della distribuzione a posteriori 🔸",
    "section": "",
    "text": "55.1.1 Cos’è la Distribuzione a Posteriori?\nLa distribuzione a posteriori rappresenta la nostra conoscenza aggiornata sui parametri di interesse. Essa combina l’informazione iniziale (distribuzione a priori) con le evidenze empiriche (dati osservati) attraverso il modello statistico. È un concetto chiave che distingue l’approccio bayesiano dall’inferenza classica.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_summary_posterior.html#sintesi-della-distribuzione-a-posteriori",
    "href": "chapters/mcmc/04_stan_summary_posterior.html#sintesi-della-distribuzione-a-posteriori",
    "title": "55  Metodi di sintesi della distribuzione a posteriori 🔸",
    "section": "\n55.2 Sintesi della Distribuzione a Posteriori",
    "text": "55.2 Sintesi della Distribuzione a Posteriori\nIl risultato di un’analisi bayesiana è una distribuzione a posteriori, contenente tutte le informazioni sui parametri dati un modello e un insieme di dati. Pertanto, riassumere la distribuzione a posteriori significa sintetizzare le conseguenze logiche del modello e dei dati analizzati. È prassi comune riportare, per ciascun parametro, una misura di posizione centrale (come la media, la moda o la mediana) per fornire un’idea della localizzazione della distribuzione, accompagnata da una misura di dispersione, quale la deviazione standard, per quantificare l’incertezza delle stime. La deviazione standard è adeguata per distribuzioni simili alla normale, ma può risultare fuorviante per distribuzioni di altra natura, come quelle asimmetriche.\nPer riassumere la dispersione di una distribuzione a posteriori, si utilizza spesso l’Intervallo di Densità Più Alta (HDI, Highest-Density Interval). L’HDI è l’intervallo più breve che contiene una data porzione della densità di probabilità. Ad esempio, se diciamo che l’HDI al 95% per un’analisi è [2, 5], intendiamo che, secondo i nostri dati e modello, il parametro in questione si trova tra 2 e 5 con una probabilità di 0.95. Non vi è nulla di particolare nella scelta del 95%, del 50% o di qualsiasi altro valore; siamo liberi di scegliere, ad esempio, l’intervallo HDI all’89% o al 94% secondo le nostre preferenze. Idealmente, le giustificazioni per queste scelte dovrebbero dipendere dal contesto e non essere automatiche, ma è accettabile stabilire un valore comune come il 95%.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_summary_posterior.html#campionamento-con-stan",
    "href": "chapters/mcmc/04_stan_summary_posterior.html#campionamento-con-stan",
    "title": "55  Metodi di sintesi della distribuzione a posteriori 🔸",
    "section": "\n55.3 Campionamento con Stan",
    "text": "55.3 Campionamento con Stan\nA scopo illustrativo, immaginiamo di aver condotto un’analisi campionando casualmente 100 opere dal Museum of Modern Art (MoMA) e di aver riscontrato che 14 sono di artisti della Generazione X. Utilizzeremo un modello Beta-Binomiale per affrontare questo problema. Il parametro θ rappresenterà la proporzione di artisti della Generazione X. Adotteremo una distribuzione a priori Beta(4, 6), che riflette un’aspettativa iniziale basata su conoscenze pregresse. I dati osservati (14 opere su 100) verranno utilizzati per aggiornare questa distribuzione iniziale.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_summary_posterior.html#implementazione-in-stan",
    "href": "chapters/mcmc/04_stan_summary_posterior.html#implementazione-in-stan",
    "title": "55  Metodi di sintesi della distribuzione a posteriori 🔸",
    "section": "\n55.4 Implementazione in Stan",
    "text": "55.4 Implementazione in Stan\nIl seguente codice Stan definisce il nostro modello probabilistico:\n\n# Path to the Stan file\nstan_file &lt;- here::here(\"stan\", \"moma.stan\")\n\n# Create a CmdStanModel object\nmod &lt;- cmdstan_model(stan_file)\n\n\nmod$print()\n#&gt; data {\n#&gt;   int&lt;lower=0&gt; N;           // Numero totale di prove\n#&gt;   int&lt;lower=0&gt; y;           // Numero di successi osservati\n#&gt;   real&lt;lower=0&gt; alpha_prior; // Parametro alpha della distribuzione Beta a priori\n#&gt;   real&lt;lower=0&gt; beta_prior;  // Parametro beta della distribuzione Beta a priori\n#&gt; }\n#&gt; \n#&gt; parameters {\n#&gt;   real&lt;lower=0, upper=1&gt; theta; // Probabilità di successo\n#&gt; }\n#&gt; \n#&gt; model {\n#&gt;   // Distribuzione a priori Beta\n#&gt;   theta ~ beta(alpha_prior, beta_prior);\n#&gt;   \n#&gt;   // Likelihood binomiale\n#&gt;   y ~ binomial(N, theta);\n#&gt; }\n#&gt; \n#&gt; generated quantities {\n#&gt;   real log_lik; // Log-verosimiglianza\n#&gt;   log_lik = binomial_lpmf(y | N, theta);\n#&gt; }\n\nProcediamo con l’implementazione pratica del modello per stimare la proporzione di artisti della Generazione X (θ) al MoMA.\nDefiniamo i dati osservati e i parametri della distribuzione a priori:\n\nN &lt;- 100\ny &lt;- 14\n\nstan_data &lt;- list(\n  N = N,\n  y = y,\n  alpha_prior = 4,\n  beta_prior = 6\n)\n\nEseguiamo il campionamento utilizzando il modello compilato in precedenza:\n\nfit &lt;- mod$sample(\n  data = stan_data,\n  seed = 123,\n  chains = 4,\n  parallel_chains = 4,\n  iter_sampling = 2000, \n  iter_warmup = 2000,\n  show_messages = FALSE\n)\n\nPer evitare di dover ripetere il campionamento (che può essere computazionalmente costoso), possiamo salvare l’oggetto fit su disco utilizzando la funzione qsave() del pacchetto qs. Questo garantisce un caricamento rapido e senza perdita di dati.\n\n# Save the object to a file.\nqs::qsave(x = fit, file = \"fit_moma.qs\")\n\nSe in seguito vogliamo analizzare i risultati senza dover ripetere il campionamento, possiamo leggere l’oggetto salvato direttamente nel nostro ambiente R:\n\n# Read the object.\nfit2 &lt;- qs::qread(\"fit_moma.qs\")\n\nL’oggetto fit2 è identico a fit e contiene tutte le informazioni relative al modello, ai parametri, ai campioni e ai metadati.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_summary_posterior.html#analisi-della-distribuzione-a-posteriori",
    "href": "chapters/mcmc/04_stan_summary_posterior.html#analisi-della-distribuzione-a-posteriori",
    "title": "55  Metodi di sintesi della distribuzione a posteriori 🔸",
    "section": "\n55.5 Analisi della distribuzione a posteriori",
    "text": "55.5 Analisi della distribuzione a posteriori\nLa distribuzione a posteriori rappresenta la nostra conoscenza aggiornata riguardo al valore del parametro \\(\\theta\\) dopo aver osservato i dati. Combina le nostre credenze a priori riguardo al parametro (la distribuzione a priori) con le nuove evidenze fornite dai dati osservati (la funzione di verosimiglianza) per ottenere una nuova distribuzione che riflette la nostra comprensione aggiornata del parametro, ovvero la distribuzione a posteriori.\nLa distribuzione a posteriori ci dice quanto sia probabile ogni possibile valore del parametro alla luce dei dati osservati. Un picco stretto indica che i dati sono molto informativi rispetto al parametro, portando a una maggiore certezza nella sua stima. Un picco largo, invece, indica maggiore incertezza.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_summary_posterior.html#esaminare-i-valori-della-distribuzione-a-posteriori",
    "href": "chapters/mcmc/04_stan_summary_posterior.html#esaminare-i-valori-della-distribuzione-a-posteriori",
    "title": "55  Metodi di sintesi della distribuzione a posteriori 🔸",
    "section": "\n55.6 Esaminare i Valori della Distribuzione a Posteriori",
    "text": "55.6 Esaminare i Valori della Distribuzione a Posteriori\nDopo aver eseguito il campionamento con Stan, possiamo esaminare i valori della distribuzione a posteriori accedendo ai campioni generati.\n\n55.6.1 Estrarre i Campioni in un Oggetto draws_array\n\nIl metodo fit$draws() restituisce i campioni in un oggetto tridimensionale del tipo draws_array, che fa parte del pacchetto posterior.\n\n# Estrazione dei campioni posteriori in formato array (default)\ndraws_arr &lt;- fit2$draws()  \nstr(draws_arr)  # Struttura dell'oggetto\n#&gt;  'draws_array' num [1:2000, 1:4, 1:3] -50 -49.7 -49 -49.1 -51.4 ...\n#&gt;  - attr(*, \"dimnames\")=List of 3\n#&gt;   ..$ iteration: chr [1:2000] \"1\" \"2\" \"3\" \"4\" ...\n#&gt;   ..$ chain    : chr [1:4] \"1\" \"2\" \"3\" \"4\"\n#&gt;   ..$ variable : chr [1:3] \"lp__\" \"theta\" \"log_lik\"\n\nL’output sarà un array 3D con le dimensioni iterazioni × catene × variabili, ovvero il formato standard per i campioni MCMC.\nPer verificare le dimensioni dell’array:\n\ndim(draws_arr)\n#&gt; [1] 2000    4    3\n\nAd esempio, se l’output di dim(draws_arr) restituisce (2000, 4, 3), le dimensioni si riferiscono a:\n\n\n2000: Numero di iterazioni di campionamento per ciascuna catena, specificato dall’argomento iter_sampling = 2000 durante il campionamento.\n\n4: Numero di catene eseguite in parallelo, specificato da chains = 4.\n\n3: Numero di parametri o quantità campionate, inclusi:\n\nParametri definiti nel blocco parameters del modello Stan.\nQuantità trasformate (transformed parameters).\nQuantità generate (generated quantities).\n\n\n\n55.6.2 Interpretazione della Struttura\nL’array 3D permette di accedere ai campioni in modo organizzato:\n\n\nPrima dimensione: Iterazioni per ciascuna catena (es. draws_arr[1,,] restituisce i valori della prima iterazione di tutte le catene).\n\nSeconda dimensione: Catene (es. draws_arr[,1,] restituisce tutti i campioni della prima catena).\n\nTerza dimensione: Variabili campionate (es. draws_arr[,,1] restituisce i valori della prima variabile in tutte le iterazioni e catene).\n\n55.6.3 Accesso ai Parametri\nPer accedere ai campioni di un parametro specifico, possiamo utilizzare il nome del parametro con il metodo fit$draws(format = \"matrix\") o fit$draws(format = \"df\").\n\n# Estrazione dei campioni in formato data frame\ndraws_df &lt;- fit2$draws(format = \"df\")\n\n# Visualizza i primi campioni della variabile \"theta\"\nhead(draws_df$theta)\n#&gt; [1] 0.1188 0.1252 0.1680 0.1477 0.0971 0.0867\n\n\n55.6.4 Sintesi dei Campioni\nPer riassumere i campioni della distribuzione a posteriori:\n\nfit2$summary()\n#&gt; # A tibble: 3 × 10\n#&gt;   variable    mean  median     sd    mad      q5     q95  rhat ess_bulk\n#&gt;   &lt;chr&gt;      &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 lp__     -49.5   -49.2   0.697  0.292  -50.9   -49.0    1.00    3699.\n#&gt; 2 theta      0.164   0.162 0.0345 0.0339   0.112   0.225  1.00    2813.\n#&gt; 3 log_lik   -2.78   -2.46  0.827  0.397   -4.48   -2.17   1.00    3803.\n#&gt; # ℹ 1 more variable: ess_tail &lt;dbl&gt;\n\n\n55.6.5 Vantaggi del Formato draws_array\n\nIl formato draws_array è particolarmente utile per:\n\n\nAnalisi avanzate: Permette di accedere direttamente a specifiche iterazioni, catene e parametri.\n\nVisualizzazioni: È compatibile con funzioni di plotting del pacchetto bayesplot.\n\nControlli diagnostici: Facilita l’analisi della convergenza e della miscelazione delle catene.\n\nCon questa struttura, possiamo esplorare in dettaglio la distribuzione a posteriori generata dal modello Stan.\n\nfit2$metadata()$model_params\n#&gt; [1] \"lp__\"    \"theta\"   \"log_lik\"\n\nRecuperiamo i campioni posteriori per theta:\n\ndraws_df &lt;- fit2$draws(format = \"df\")\nhead(draws_df)\n#&gt; # A draws_df: 6 iterations, 1 chains, and 3 variables\n#&gt;   lp__ theta log_lik\n#&gt; 1  -50 0.119    -2.4\n#&gt; 2  -50 0.125    -2.3\n#&gt; 3  -49 0.168    -2.5\n#&gt; 4  -49 0.148    -2.2\n#&gt; 5  -51 0.097    -3.1\n#&gt; 6  -52 0.087    -3.7\n#&gt; # ... hidden reserved variables {'.chain', '.iteration', '.draw'}\n\n\ndraws_df$theta |&gt;\n  head()\n#&gt; [1] 0.1188 0.1252 0.1680 0.1477 0.0971 0.0867\n\n\nlength(draws_df$theta)\n#&gt; [1] 8000\n\nGeneriamo un istogramma della distribuzione a posteriori di theta:\n\ndraws_df |&gt;\n  ggplot(aes(theta)) +\n  geom_histogram()\n#&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\nIn alternativa, possiamo passare l’oggetto fit$draws(\"theta\") alla funzione mcmc_hist() di bayesplot:\n\nmcmc_hist(fit2$draws(\"theta\"))\n#&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\nOppure possiamo usare la funzione mcmc_dens_overlay():\n\nmcmc_dens_overlay(fit2$draws(\"theta\"))\n\n\n\n\n\n\n\nLa traccia del campionamento si ottiene nel modo seguente:\n\nmcmc_trace(fit2$draws(\"theta\"))\n\n\n\n\n\n\n\nConfrontiamo la distribuzione a posteriori con la distribuzione a priori di \\(\\theta\\).\n\n# Parameters of the Beta distribution\nalpha &lt;- 4\nbeta_param &lt;- 6\n\n# Create a data frame for the prior Beta distribution\nx &lt;- seq(0, 1, length.out = 1000)\nprior_pdf &lt;- dbeta(x, alpha, beta_param)\nprior_df &lt;- data.frame(theta = x, density = prior_pdf, distribution = \"Prior\")\n\n# Extract posterior draws of theta and calculate density\nposterior_theta &lt;- as.vector(fit2$draws(\"theta\")) # Assuming `fit2$draws(\"theta\")` works\nposterior_density &lt;- density(posterior_theta)\nposterior_df &lt;- data.frame(\n  theta = posterior_density$x,\n  density = posterior_density$y,\n  distribution = \"Posterior\"\n)\n\n# Combine the prior and posterior data\ncombined_df &lt;- bind_rows(prior_df, posterior_df)\n\n# Plot using ggplot2\nggplot(combined_df, aes(x = theta, y = density, color = distribution)) +\n  geom_line(size = 1.2) +\n  labs(\n    x = expression(theta),\n    y = \"Density\",\n    title = \"Prior and Posterior Distributions\"\n  ) +\n  scale_color_manual(\n    values = c(\"Prior\" = \"black\", \"Posterior\" = \"red\"),\n    name = \"Distribution\"\n  ) +\n  theme(\n    legend.position = \"top\",\n    plot.title = element_text(hjust = 0.5)\n  )\n#&gt; Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#&gt; ℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\nNel caso presente, la distribuzione a posteriori differisce in maniera importante dalla distribuzione a priori. Ciò indica che i dati hanno avuto un forte impatto sulle nostre credenze riguardo al valore del parametro.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_summary_posterior.html#intervallo-di-credibilità",
    "href": "chapters/mcmc/04_stan_summary_posterior.html#intervallo-di-credibilità",
    "title": "55  Metodi di sintesi della distribuzione a posteriori 🔸",
    "section": "\n55.7 Intervallo di Credibilità",
    "text": "55.7 Intervallo di Credibilità\nGli intervalli di credibilità sono uno strumento fondamentale nell’inferenza bayesiana per riassumere l’incertezza sui parametri stimati. Esistono due metodi principali per calcolare gli intervalli di credibilità:\n\n\nHighest Density Interval (HDI): definisce l’intervallo più stretto che contiene la probabilità specificata, includendo le aree di maggiore densità della distribuzione a posteriori.\n\nEqual-tailed Interval (ETI): lascia una probabilità uguale (ad esempio, il 2,5% per un intervallo al 95%) in entrambe le code della distribuzione.\n\nQuesti metodi producono risultati identici in caso di distribuzioni simmetriche ma differiscono per distribuzioni asimmetriche. Di seguito vediamo come interpretare e calcolare questi intervalli.\nDistribuzione Simmetrica\nCon una distribuzione a posteriori simmetrica, come quella normale, gli intervalli HDI ed ETI coincidono.\nEsempio di calcolo:\n\n# Genera una distribuzione normale\nposterior &lt;- distribution_normal(1000)\n\n# Calcola HDI ed ETI\nci_hdi &lt;- ci(posterior, method = \"HDI\")\nci_eti &lt;- ci(posterior, method = \"ETI\")\n\n# Visualizza la distribuzione con i limiti degli intervalli\nout &lt;- estimate_density(posterior, extend = TRUE)\nggplot(out, aes(x = x, y = y)) +\n  geom_area(fill = \"orange\") +\n  # HDI in blu\n  geom_vline(xintercept = ci_hdi$CI_low, color = \"royalblue\", linewidth = 3) +\n  geom_vline(xintercept = ci_hdi$CI_high, color = \"royalblue\", linewidth = 3) +\n  # ETI in rosso\n  geom_vline(xintercept = ci_eti$CI_low, color = \"red\", linewidth = 1) +\n  geom_vline(xintercept = ci_eti$CI_high, color = \"red\", linewidth = 1)\n\n\n\n\n\n\n\nDistribuzione Asimmetrica\nQuando la distribuzione a posteriori è asimmetrica, come una distribuzione beta, l’HDI è generalmente più stretto rispetto all’ETI poiché privilegia le regioni di maggiore densità.\nEsempio di calcolo:\n\n# Genera una distribuzione beta\nposterior &lt;- distribution_beta(1000, 6, 2)\n\n# Calcola HDI ed ETI\nci_hdi &lt;- ci(posterior, method = \"HDI\")\nci_eti &lt;- ci(posterior, method = \"ETI\")\n\n# Visualizza la distribuzione con i limiti degli intervalli\nout &lt;- estimate_density(posterior, extend = TRUE)\nggplot(out, aes(x = x, y = y)) +\n  geom_area(fill = \"orange\") +\n  # HDI in blu\n  geom_vline(xintercept = ci_hdi$CI_low, color = \"royalblue\", linewidth = 3) +\n  geom_vline(xintercept = ci_hdi$CI_high, color = \"royalblue\", linewidth = 3) +\n  # ETI in rosso\n  geom_vline(xintercept = ci_eti$CI_low, color = \"red\", linewidth = 1) +\n  geom_vline(xintercept = ci_eti$CI_high, color = \"red\", linewidth = 1)\n\n\n\n\n\n\n\n\n55.7.1 Interpretazione dell’Intervallo di Credibilità\nL’intervallo di credibilità bayesiano offre una chiara interpretazione probabilistica: dato il modello e i dati, c’è una probabilità specificata (ad esempio, il 94%) che il parametro si trovi all’interno dell’intervallo calcolato.\n\n55.7.2 Calcolo degli intervalli in R\n\n\nHDI:\n\n\nbayestestR::ci(fit2$draws(\"theta\"), method = \"HDI\")\n#&gt; Highest Density Interval\n#&gt; \n#&gt; Parameter |      95% HDI\n#&gt; ------------------------\n#&gt; theta     | [0.10, 0.23]\n\n\n\nETI:\n\n\nbayestestR::ci(fit2$draws(\"theta\"), method = \"ETI\")\n#&gt; Equal-Tailed Interval\n#&gt; \n#&gt; Parameter |      95% ETI\n#&gt; ------------------------\n#&gt; theta     | [0.10, 0.24]\n\n\n55.7.3 Visualizzazione grafica\nUtilizzando il pacchetto bayesplot possiamo rappresentare la distribuzione a posteriori con l’HDI:\n\nmcmc_areas(fit2$draws(\"theta\"), \n           prob = 0.94) +  # Specifica il livello dell'HDI\n  ggtitle(\"Distribuzione a Posteriori di Theta con HDI al 94%\") +\n  xlab(expression(theta)) +\n  ylab(\"Densità\")\n\n\n\n\n\n\n\n\n55.7.4 Confronto con gli Intervalli di Confidenza Frequentisti\nGli intervalli di credibilità bayesiani si distinguono nettamente dagli intervalli di confidenza frequentisti. Mentre gli intervalli frequentisti si basano su una prospettiva a lungo termine (ovvero, il 95% degli intervalli costruiti su infiniti campioni includerebbe il vero valore), gli intervalli bayesiani:\n\n\nHanno una chiara interpretazione probabilistica: dato il modello e i dati, indicano direttamente la probabilità che il parametro sia nell’intervallo.\n\nIncorporano credenze a priori, combinate con l’evidenza fornita dai dati.\n\n55.7.5 Scelta del Livello dell’Intervallo (89% vs 95%)\nUna discussione comune nell’inferenza bayesiana riguarda il livello predefinito degli intervalli. Sebbene il 95% sia un valore convenzionale mutuato dal frequentismo, alcune evidenze suggeriscono che livelli più bassi (ad esempio, 89%) possano essere più stabili per le distribuzioni a posteriori, specialmente con un numero limitato di campioni posteriori (Kruschke, 2014).\n\n\nVantaggi del 95%:\n\nRelazione intuitiva con la deviazione standard.\nMaggiore probabilità di includere 0, rendendo le analisi più conservative.\n\n\n\nVantaggi dell’89%:\n\nMaggiore stabilità con campioni posteriori limitati.\nEvita l’arbitrarietà del valore 95% (McElreath, 2018).\n\n\n\nIn conclusione, la scelta tra HDI e ETI, così come il livello dell’intervallo, dipende dagli obiettivi e dal contesto dell’analisi. Gli intervalli di credibilità offrono un approccio flessibile e intuitivo per sintetizzare l’incertezza, adattandosi alle esigenze di analisi sia esplorative che confermative.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_summary_posterior.html#test-di-ipotesi-bayesiane",
    "href": "chapters/mcmc/04_stan_summary_posterior.html#test-di-ipotesi-bayesiane",
    "title": "55  Metodi di sintesi della distribuzione a posteriori 🔸",
    "section": "\n55.8 Test di Ipotesi Bayesiane",
    "text": "55.8 Test di Ipotesi Bayesiane\nIn alcune situazioni, descrivere semplicemente la distribuzione a posteriori potrebbe non essere sufficiente. Potremmo dover prendere decisioni pratiche basate sulle inferenze, traducendo stime continue in scelte binarie. Ad esempio, possiamo voler determinare se una terapia è efficace, se un intervento ha avuto successo, o se una proporzione supera una soglia di rilevanza pratica.\nSupponiamo di voler verificare se, nel Museum of Modern Art (MoMA), gli artisti della generazione X (nati tra il 1965 e il 1980) rappresentano meno del 10% del corpus esposto. Analizzando un campione casuale di 100 opere e utilizzando un prior basato su convinzioni pregresse, stimiamo la distribuzione a posteriori della proporzione di artisti, \\(\\theta\\). L’intervallo di credibilità (Credible Interval, CI) al 94% risulta compreso tra 0.104 e 0.235.\nLa nostra ipotesi iniziale è che la proporzione di artisti della generazione X sia inferiore al 10%, cioè \\(\\theta &lt; 0.1\\). Tuttavia, il fatto che l’intero intervallo di credibilità al 94% si trovi sopra la soglia del 10% contraddice questa ipotesi. Per quantificare ulteriormente la compatibilità dei dati con questa ipotesi, calcoliamo la probabilità a posteriori che \\(\\theta &lt; 0.1\\).\n\nfit2$summary(\"theta\", pr_lt_01 = ~ mean(. &lt;= 0.1))\n#&gt; # A tibble: 1 × 2\n#&gt;   variable pr_lt_01\n#&gt;   &lt;chr&gt;       &lt;dbl&gt;\n#&gt; 1 theta      0.0213\n\nLa probabilità a posteriori che \\(\\theta &lt; 0.1\\)** è molto bassa, ovvero \\(P(\\theta &lt; 0.1) = 0.0213\\), fornendo ulteriori evidenze contro l’ipotesi che gli artisti della generazione X rappresentino meno del 10% del corpus esposto.\nIn sintesi, sulla base dei dati e del modello, l’ipotesi che gli artisti della generazione X rappresentino meno del 10% non è supportata. Al contrario, i dati indicano, con un livello di certezza soggettiva del 94%, che la proporzione di artisti appartenenti a questa generazione è molto probabilmente superiore al 10%.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_summary_posterior.html#riflessioni-conclusive",
    "href": "chapters/mcmc/04_stan_summary_posterior.html#riflessioni-conclusive",
    "title": "55  Metodi di sintesi della distribuzione a posteriori 🔸",
    "section": "\n55.9 Riflessioni conclusive",
    "text": "55.9 Riflessioni conclusive\nLa crescente popolarità dei metodi bayesiani in psicologia e nelle scienze sociali è stata fortemente influenzata dalla (ri)scoperta di algoritmi numerici capaci di stimare le distribuzioni a posteriori dei parametri del modello a partire dai dati osservati. Prima di questi sviluppi, ottenere misure riassuntive delle distribuzioni a posteriori, soprattutto per modelli complessi con molti parametri, era praticamente impossibile.\nQuesto capitolo fornisce un’introduzione a cmdstanr, che permette di compilare ed eseguire modelli probabilistici espressi in linguaggio Stan. Grazie a questa tecnologia, è possibile generare una stima della distribuzione a posteriori attraverso il campionamento Markov Chain Monte Carlo (MCMC), rivoluzionando la capacità di effettuare inferenze bayesiane e rendendo l’analisi di modelli complessi più accessibile e gestibile.\nInoltre, nel capitolo sono state presentate diverse strategie per la trasformazione della distribuzione a posteriori e sono state esplorate modalità per ottenere intervalli di credibilità. Successivamente, è stata discussa l’analisi delle ipotesi a posteriori, che consente di confrontare due ipotesi contrapposte riguardanti il parametro \\(\\theta\\).",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_summary_posterior.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/04_stan_summary_posterior.html#informazioni-sullambiente-di-sviluppo",
    "title": "55  Metodi di sintesi della distribuzione a posteriori 🔸",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] insight_1.0.0       bayestestR_0.15.0   rstanarm_2.32.1    \n#&gt;  [4] Rcpp_1.0.13-1       qs_0.27.2           posterior_1.6.0    \n#&gt;  [7] cmdstanr_0.8.1.9000 see_0.9.0           gridExtra_2.3      \n#&gt; [10] patchwork_1.3.0     bayesplot_1.11.1    psych_2.4.12       \n#&gt; [13] scales_1.3.0        markdown_1.13       knitr_1.49         \n#&gt; [16] lubridate_1.9.4     forcats_1.0.0       stringr_1.5.1      \n#&gt; [19] dplyr_1.1.4         purrr_1.0.2         readr_2.1.5        \n#&gt; [22] tidyr_1.3.1         tibble_3.2.1        ggplot2_3.5.1      \n#&gt; [25] tidyverse_2.0.0     rio_1.2.3           here_1.0.1         \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] mnormt_2.1.1         inline_0.3.20        rlang_1.1.4         \n#&gt;  [4] magrittr_2.0.3       ggridges_0.5.6       matrixStats_1.4.1   \n#&gt;  [7] compiler_4.4.2       loo_2.8.0            vctrs_0.6.5         \n#&gt; [10] reshape2_1.4.4       pkgconfig_2.0.3      fastmap_1.2.0       \n#&gt; [13] backports_1.5.0      labeling_0.4.3       utf8_1.2.4          \n#&gt; [16] threejs_0.3.3        promises_1.3.2       rmarkdown_2.29      \n#&gt; [19] tzdb_0.4.0           ps_1.8.1             nloptr_2.1.1        \n#&gt; [22] xfun_0.49            jsonlite_1.8.9       later_1.4.1         \n#&gt; [25] parallel_4.4.2       R6_2.5.1             dygraphs_1.1.1.6    \n#&gt; [28] stringi_1.8.4        StanHeaders_2.32.10  boot_1.3-31         \n#&gt; [31] rstan_2.32.6         zoo_1.8-12           base64enc_0.1-3     \n#&gt; [34] pacman_0.5.1         splines_4.4.2        httpuv_1.6.15       \n#&gt; [37] Matrix_1.7-1         igraph_2.1.2         timechange_0.3.0    \n#&gt; [40] tidyselect_1.2.1     abind_1.4-8          yaml_2.3.10         \n#&gt; [43] stringfish_0.16.0    codetools_0.2-20     miniUI_0.1.1.1      \n#&gt; [46] processx_3.8.4       curl_6.0.1           pkgbuild_1.4.5      \n#&gt; [49] lattice_0.22-6       plyr_1.8.9           shiny_1.10.0        \n#&gt; [52] withr_3.0.2          evaluate_1.0.1       survival_3.8-3      \n#&gt; [55] RcppParallel_5.1.9   xts_0.14.1           pillar_1.10.0       \n#&gt; [58] tensorA_0.36.2.1     checkmate_2.3.2      DT_0.33             \n#&gt; [61] stats4_4.4.2         shinyjs_2.1.0        distributional_0.5.0\n#&gt; [64] generics_0.1.3       rprojroot_2.0.4      hms_1.1.3           \n#&gt; [67] rstantools_2.4.0     munsell_0.5.1        minqa_1.2.8         \n#&gt; [70] RApiSerialize_0.1.4  gtools_3.9.5         xtable_1.8-4        \n#&gt; [73] glue_1.8.0           tools_4.4.2          shinystan_2.6.0     \n#&gt; [76] data.table_1.16.4    lme4_1.1-35.5        colourpicker_1.3.0  \n#&gt; [79] grid_4.4.2           QuickJSR_1.4.0       crosstalk_1.2.1     \n#&gt; [82] datawizard_0.13.0    colorspace_2.1-1     nlme_3.1-166        \n#&gt; [85] cli_3.6.3            V8_6.0.0             gtable_0.3.6        \n#&gt; [88] digest_0.6.37        htmlwidgets_1.6.4    farver_2.1.2        \n#&gt; [91] htmltools_0.5.8.1    lifecycle_1.0.4      mime_0.12           \n#&gt; [94] MASS_7.3-61          shinythemes_1.2.0",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_mcmc_prediction.html",
    "href": "chapters/mcmc/06_mcmc_prediction.html",
    "title": "56  La predizione bayesiana 🔸",
    "section": "",
    "text": "56.1 Preparazione del Notebook\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(cmdstanr, posterior, bayestestR)",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>La predizione bayesiana 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_mcmc_prediction.html#introduzione",
    "href": "chapters/mcmc/06_mcmc_prediction.html#introduzione",
    "title": "56  La predizione bayesiana 🔸",
    "section": "\n56.2 Introduzione",
    "text": "56.2 Introduzione\nIn questo capitolo esamineremo in dettaglio le distribuzioni predittive a priori e a posteriori. La distribuzione predittiva a priori rappresenta le aspettative sui dati prima di qualsiasi osservazione reale, riflettendo le conoscenze preesistenti e le ipotesi sui parametri del modello. Essa fornisce un’indicazione delle caratteristiche che i dati potrebbero assumere in base al modello. Confrontare queste previsioni con i dati effettivamente osservati consente di valutare la validità delle ipotesi incorporate nel modello.\nLa distribuzione predittiva è spesso di maggiore interesse rispetto alla distribuzione a posteriori. Mentre la distribuzione a posteriori descrive l’incertezza sui parametri (ad esempio, la proporzione di palline rosse in un’urna), la distribuzione predittiva descrive l’incertezza sugli eventi futuri (ad esempio, il colore della pallina che verrà estratta in futuro). Questa differenza è cruciale, soprattutto quando si tratta di prevedere gli effetti di un intervento, come la somministrazione di un trattamento a un paziente.\nLa distribuzione predittiva a posteriori è inoltre fondamentale per valutare quanto le previsioni del modello siano coerenti con i dati osservati. Se le previsioni del modello risultano allineate con i dati raccolti, il modello può essere considerato accurato nel rappresentare il processo generativo sottostante. Questo confronto è essenziale per convalidare il modello e assicurarsi che le ipotesi riflettano adeguatamente la realtà osservata.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>La predizione bayesiana 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_mcmc_prediction.html#sec-posterior-predictive-distribution",
    "href": "chapters/mcmc/06_mcmc_prediction.html#sec-posterior-predictive-distribution",
    "title": "56  La predizione bayesiana 🔸",
    "section": "\n56.3 La distribuzione predittiva a posteriori",
    "text": "56.3 La distribuzione predittiva a posteriori\nLa distribuzione predittiva a posteriori offre una valutazione critica della coerenza tra i dati reali e quelli simulati dal modello (Gelman & Shalizi, 2013). Confrontando direttamente i dati osservati con quelli generati dal modello, essa permette di identificare eventuali discrepanze che potrebbero segnalare problemi nella specificazione del modello. In pratica, la PPC (Posterior Predictive Check) funge da test diagnostico, consentendo di rilevare e correggere eventuali carenze nel modello, migliorandone così le capacità predittive.\nPer comprendere meglio il concetto, consideriamo la distribuzione predittiva a posteriori in termini di un modello coniugato normale-normale. Supponiamo di voler predire la media di una distribuzione normale futura, basandoci sui dati osservati e sulle nostre conoscenze a priori. La PPD ci offre uno strumento per calcolare queste probabilità, combinando le informazioni provenienti dai dati osservati con quelle fornite dalla distribuzione a priori.\nAd esempio, immaginiamo di aver raccolto dati sulle altezze di 100 persone, ottenendo una media campionaria di 170 cm e una deviazione standard campionaria di 10 cm. Il nostro obiettivo è stimare la media delle altezze in un futuro campione di \\(n=100\\) persone. La nostra conoscenza a priori sulla media delle altezze è rappresentata da una distribuzione normale con media 175 cm e deviazione standard di 5 cm.\nIn termini di notazione, possiamo esprimere questa distribuzione come \\(P(\\tilde{y} \\mid \\theta=\\theta_1)\\), dove \\(\\tilde{y}\\) rappresenta un nuovo dato che è diverso dai dati attuali \\(y\\), e \\(\\theta_1\\) è la media a posteriori. Tuttavia, in statistica bayesiana, è fondamentale incorporare tutta l’incertezza nei risultati. Poiché \\(\\theta_1\\) è solo uno dei possibili valori per \\(\\theta\\), dovremmo includere ogni valore di \\(\\theta\\) per la nostra previsione. Per ottenere la migliore previsione, possiamo “mediare” le previsioni attraverso i diversi valori di \\(\\theta\\), ponderando ciascun valore secondo la sua probabilità a posteriori.\nLa distribuzione risultante è la distribuzione predittiva a posteriori, che in notazione matematica è data da:\n\\[ P(\\tilde{y} \\mid y) = \\int_\\theta p(\\tilde{y} \\mid \\theta, y) p(\\theta \\mid y) d\\theta. \\]\nIn questo modo, la distribuzione predittiva a posteriori combina le informazioni dai dati osservati con la conoscenza a priori, fornendo una previsione che riflette l’incertezza associata a tutti i possibili valori dei parametri del modello.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>La predizione bayesiana 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_mcmc_prediction.html#distribuzione-predittiva-a-posteriori-nel-modello-normale-normale",
    "href": "chapters/mcmc/06_mcmc_prediction.html#distribuzione-predittiva-a-posteriori-nel-modello-normale-normale",
    "title": "56  La predizione bayesiana 🔸",
    "section": "\n56.4 Distribuzione predittiva a posteriori nel modello normale-normale",
    "text": "56.4 Distribuzione predittiva a posteriori nel modello normale-normale\nNel modello coniugato normale-normale, se i dati osservati \\(Y = \\{y_1, y_2, ..., y_n\\}\\) sono modellati come provenienti da una distribuzione normale con media \\(\\mu\\) e varianza \\(\\sigma^2\\), e assumendo una distribuzione a priori normale per \\(\\mu\\), la distribuzione a posteriori di \\(\\mu\\) sarà anch’essa normale.\n\n56.4.1 Formule della distribuzione predittiva a posteriori\nDato che:\n\nI dati osservati \\(y_i \\sim \\mathcal{N}(\\mu, \\sigma^2)\\)\n\nLa prior per \\(\\mu\\) è \\(\\mu \\sim \\mathcal{N}(\\mu_0, \\tau_0^2)\\)\n\n\nLa distribuzione a posteriori per \\(\\mu\\) sarà:\n\\[\n\\mu \\mid Y \\sim \\mathcal{N}(\\mu_n, \\tau_n^2)\n\\]\ndove:\n\\[\n\\mu_n = \\frac{\\tau_0^2 \\bar{y} + \\sigma^2 \\mu_0}{\\tau_0^2 + \\sigma^2}\n\\]\nin cui \\(\\bar{y}\\) è la media campionaria dei dati osservati, e\n\\[\n\\tau_n^2 = \\frac{\\tau_0^2 \\sigma^2}{\\tau_0^2 + \\sigma^2} .\n\\]\n\nEsempio 56.1 Consideriamo che:\n\n\n\\(\\mu_0 = 175\\) cm (media a priori)\n\n\\(\\tau_0 = 5\\) cm (deviazione standard a priori)\n\n\\(\\bar{y} = 170\\) cm (media campionaria)\n\n\\(\\sigma = 10\\) cm (deviazione standard campionaria)\n\n\\(n = 100\\) (numero di osservazioni)\n\nI parametri della distribuzione a posteriori sono:\n\\[\n\\mu_n = \\frac{(5^2 \\cdot 170) + (10^2 \\cdot 175)}{5^2 + 10^2} = \\frac{42500 + 175000}{25 + 100} = \\frac{217500}{125} = 174 \\quad \\text{cm}\n\\]\n\\[\n\\tau_n^2 = \\frac{5^2 \\cdot 10^2}{5^2 + 10^2} = \\frac{2500}{125} = 20 \\quad \\text{cm}^2 \\Rightarrow \\tau_n = \\sqrt{20} \\approx 4.47 \\quad \\text{cm}\n\\]\nPertanto, la distribuzione a posteriori per \\(\\mu\\) è:\n\\[\n\\mu \\mid Y \\sim \\mathcal{N}(174, 4.47^2)\n\\]\nPer la distribuzione predittiva a posteriori, dobbiamo considerare anche la varianza della distribuzione futura. Se stiamo predicendo per \\(n_{\\text{fut}}=100\\) nuove osservazioni, la varianza della media predittiva sarà:\n\\[\n\\sigma_{\\text{pred}}^2 = \\tau_n^2 + \\frac{\\sigma^2}{n_{\\text{fut}}}\n\\]\n\\[\n\\sigma_{\\text{pred}}^2 = 20 + \\frac{10^2}{100} = 20 + 1 = 21 \\quad \\text{cm}^2 \\Rightarrow \\sigma_{\\text{pred}} = \\sqrt{21} \\approx 4.58 \\quad \\text{cm}\n\\]\nQuindi, la distribuzione predittiva a posteriori è:\n\\[\n\\tilde{Y} \\sim \\mathcal{N}(174, 4.58^2)\n\\]\n\n56.5 Implementazione con cmdstanr\n\nPer illustrare come viene generata la distribuzione predittiva a posteriori nel contesto del modello normale-normale, possiamo utilizzare cmdstanr per eseguire l’analisi. Il codice seguente mostra come configurare il modello e generare previsioni.\n\n# Dati osservati\nset.seed(123)  # Imposta il seed per la riproducibilità\ny_observed &lt;- rnorm(100, 170, 10)\nmean_y &lt;- mean(y_observed)\nstd_y &lt;- sd(y_observed)\n\n# Parametri a priori\nmu_0 &lt;- 175\ntau_0 &lt;- 5\n\n# Parametri posteriori\ntau_n_sq &lt;- (tau_0^2 * std_y^2) / (tau_0^2 + std_y^2)\ntau_n &lt;- sqrt(tau_n_sq)\nmu_n &lt;- (tau_0^2 * mean_y + std_y^2 * mu_0) / (tau_0^2 + std_y^2)\n\n# Parametri predittivi\nn_fut &lt;- 100\nsigma_pred_sq &lt;- tau_n_sq + (std_y^2 / n_fut)\nsigma_pred &lt;- sqrt(sigma_pred_sq)\nmu_pred &lt;- mu_n\n\n# Simulazioni\ny_pred_samples &lt;- rnorm(1000, mu_pred, sigma_pred)\n\n# Dati per ggplot\ndata &lt;- data.frame(Heights = y_pred_samples)\n\n# Grafico\np &lt;- ggplot(data, aes(x = Heights)) +\n  geom_histogram(\n    aes(y = ..density..), \n    bins = 30, \n    fill = \"gray\", \n    colour = \"gray\", \n    alpha = 0.5\n  ) +\n  geom_density(colour = \"black\", size = 1.5) +\n  geom_vline(\n    xintercept = mu_pred, \n    colour = \"gray\", \n    linetype = \"dashed\", \n    size = 1\n  ) +\n  labs(title = \"Posterior Predictive Distribution for Heights\",\n       x = \"Heights (cm)\",\n       y = \"Density\") +\n  theme(legend.position = \"none\")\n#&gt; Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#&gt; ℹ Please use `linewidth` instead.\n\n# Visualizza il grafico\nprint(p)\n#&gt; Warning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\n#&gt; ℹ Please use `after_stat(density)` instead.\n\n\n\n\n\n\n\nQuesto codice produce un grafico che illustra visivamente la distribuzione predittiva a posteriori per le altezze nel nostro campione di 100 nuove osservazioni, tenendo conto sia dei dati osservati che delle nostre aspettative iniziali.\nIn sintesi, la distribuzione predittiva a posteriori è stata generata nel modo seguente:\n\nCampioniamo un valore \\(\\mu\\) dalla distribuzione a posteriori di \\(\\mu\\).\nCampioniamo un valore \\(\\sigma\\) dalla distribuzione a posteriori di \\(\\sigma\\).\nUtilizziamo questi valori per generare un campione dalla distribuzione normale con parametri \\(\\mu\\) e \\(\\sigma\\).\nRipetiamo questo processo molte volte.\n\nLa distribuzione dei valori ottenuti da questi campionamenti costituisce la distribuzione predittiva a posteriori.\n\n56.6 Metodo MCMC\nQuando usiamo un PPL come Stan, la distribuzione predittiva viene stimata mediante il campionamento da una catena di Markov, che è particolarmente utile in scenari complessi dove l’analisi analitica potrebbe essere impraticabile. Attraverso i metodi MCMC, si stimano le potenziali osservazioni future \\(p(\\tilde{y} \\mid y)\\), indicate come \\(p(y^{rep} \\mid y)\\), seguendo questi passaggi:\n\nSi campiona \\(\\theta_i \\sim p(\\theta \\mid y)\\): Viene selezionato casualmente un valore del parametro (o dei parametri) dalla distribuzione a posteriori.\nSi campiona \\(y^{rep} \\sim p(y^{rep} \\mid \\theta_i)\\): Viene scelta casualmente un’osservazione dalla funzione di verosimiglianza, condizionata al valore del parametro (o dei parametri)ottenuto nel passo precedente.\n\nRipetendo questi due passaggi un numero sufficiente di volte, l’istogramma risultante approssimerà la distribuzione predittiva a posteriori.\nEsaminiamo ora come ottenere la distribuzione predittiva a posteriori con Stan per i dati dell’esempio precedente. Iniziamo creando le distribuzioni a posteriori di \\(\\mu\\) e \\(\\sigma\\).\nDefiniamo un dizionario che contiene i dati.\n\nstan_data_gauss = list(\n  N = length(y_observed),\n  y = y_observed,\n  mu_prior = 180,\n  sigma_prior = 20,\n  sigma_prior_mean = 10,\n  sigma_prior_sd = 3\n)\n\n\ny_mean = mean(y_observed)\ny_std = sd(y_observed)\n\ny_mean\n#&gt; [1] 171\ny_std\n#&gt; [1] 9.13\n\nCompiliamo e stampiamo il modello Stan:\n\n# Path to the Stan file\nstan_file &lt;- here::here(\"stan\", \"gaussian_model.stan\")\n\n# Create a CmdStanModel object\nmod &lt;- cmdstan_model(stan_file)\n\n\nmod$print()\n#&gt; data {\n#&gt;   int&lt;lower=0&gt; N; // number of observations\n#&gt;   vector[N] y; // observed data\n#&gt;   real mu_prior; // prior mean for mu\n#&gt;   real&lt;lower=0&gt; sigma_prior; // prior standard deviation for mu\n#&gt;   real&lt;lower=0&gt; sigma_prior_mean; // prior mean for sigma\n#&gt;   real&lt;lower=0&gt; sigma_prior_sd; // prior standard deviation for sigma\n#&gt; }\n#&gt; parameters {\n#&gt;   real mu; // parameter of interest\n#&gt;   real&lt;lower=0&gt; sigma; // parameter for the standard deviation\n#&gt; }\n#&gt; model {\n#&gt;   mu ~ normal(mu_prior, sigma_prior); // prior for mu\n#&gt;   sigma ~ normal(sigma_prior_mean, sigma_prior_sd); // prior for sigma\n#&gt;   y ~ normal(mu, sigma); // likelihood\n#&gt; }\n#&gt; generated quantities {\n#&gt;   array[N] real y_rep;\n#&gt;   for (n in 1 : N) {\n#&gt;     y_rep[n] = normal_rng(mu, sigma);\n#&gt;   }\n#&gt; }\n\nEseguiamo il campionamento MCMC:\n\nfit &lt;- mod$sample(\n  data = stan_data_gauss,\n  seed = 123,\n  chains = 4,\n  parallel_chains = 4,\n  iter_sampling = 2000, \n  iter_warmup = 2000,\n  show_messages = FALSE\n)\n\nUn sommario delle distribuzioni a posteriori dei parametri si ottiene nel modo seguente:\n\nfit$summary(c(\"mu\", \"sigma\"))\n#&gt; # A tibble: 2 × 10\n#&gt;   variable   mean median    sd   mad     q5   q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 mu       171.   171.   0.932 0.943 169.   172.   1.00    7321.    5508.\n#&gt; 2 sigma      9.27   9.23 0.652 0.647   8.28  10.4  1.00    6675.    5412.\n\nEstraiamo i dati prodotti dal modello y_rep e i dati osservati y:\n\n# Extract posterior predictive samples for y_rep\ny_rep &lt;- fit$draws(variables = \"y_rep\", format = \"draws_matrix\")\n\n# Extract observed data\ny_obs &lt;- stan_data_gauss$y\n\nConvertiamo y_rep in una matrice per compatibilità con {bayesplot}.\n\n# Convert y_rep to a matrix\ny_rep_matrix &lt;- as.matrix(y_rep)\n\nGeneriamo il posterior predictive chech plot:\n\n# Posterior predictive check plot\nset.seed(123)\nselected_indices &lt;- sample(nrow(y_rep_matrix), 50)\nppc_dens_overlay(y = y_obs, yrep = y_rep_matrix[selected_indices, ])\n\n\n\n\n\n\n\nLa distribuzione predittiva a posteriori è utilizzata per eseguire i controlli predittivi a posteriori (PPC), noti come Posterior Predictive Checks. I PPC consistono in un confronto grafico tra \\(p(y^{rep} \\mid y)\\), ossia la distribuzione delle osservazioni future previste, e i dati osservati \\(y\\). Questo confronto visivo permette di valutare se il modello utilizzato è adeguato per descrivere le proprietà dei dati osservati.\nOltre al confronto grafico tra le distribuzioni \\(p(y)\\) e \\(p(y^{rep})\\), è possibile effettuare un confronto tra le distribuzioni di varie statistiche descrittive calcolate su diversi campioni \\(y^{rep}\\) e le corrispondenti statistiche calcolate sui dati osservati. Tipicamente, vengono considerate statistiche descrittive come la media, la varianza, la deviazione standard, il minimo o il massimo, ma è possibile confrontare qualsiasi altra statistica rilevante.\nI controlli predittivi a posteriori offrono un valido strumento per un’analisi critica delle prestazioni del modello e, se necessario, per apportare eventuali modifiche o considerare modelli alternativi più adatti ai dati in esame.\n\n56.7 Distribuzione Predittiva a Priori\nLa verifica predittiva a priori è un metodo fondamentale per esplorare le implicazioni dei tuoi prior. Genera dati simulati basandosi unicamente sui prior, ignorando completamente i dati osservati. Questo permette di rispondere a domande cruciali come:\n\nI dati generati dal prior riflettono scenari plausibili?\nIl prior è troppo restrittivo o troppo ampio rispetto ai dati attesi?\n\nQuesta verifica è particolarmente utile per identificare eventuali incongruenze o assunzioni non realistiche prima di raccogliere i dati osservati.\n\n56.7.1 Modello Beta-Binomiale\nIniziamo con il caso più semplice. Il modello beta-binomiale è un esempio classico per illustrare la verifica predittiva a priori. In questo modello:\n\n\ntheta rappresenta la probabilità di successo.\nIl prior su theta è distribuito secondo una distribuzione Beta parametrizzata da alpha_prior e beta_prior.\nI dati (y) seguono una distribuzione Bernoulliana condizionata su theta.\n\nIl modello Stan per l’inferenza sui dati osservati è il seguente:\ndata {\n  int&lt;lower=0&gt; N;             // Numero di osservazioni\n  array[N] int&lt;lower=0, upper=1&gt; y; // Dati osservati (successi)\n  real&lt;lower=0&gt; alpha_prior;  // Parametro alpha del prior Beta\n  real&lt;lower=0&gt; beta_prior;   // Parametro beta del prior Beta\n}\nparameters {\n  real&lt;lower=0, upper=1&gt; theta; // Probabilità di successo\n}\nmodel {\n  theta ~ beta(alpha_prior, beta_prior); // Prior su theta\n  y ~ bernoulli(theta);                  // Likelihood\n}\nPer eseguire la simulazione dalla distribuzione predittiva a priori, rimuoviamo il blocco model e utilizziamo generated quantities per simulare:\n\nl’estrazione di un valore per theta dalla distribuzione Beta specificata dai parametri del prior;\nla generazione di successi simulati (y_sim) dalla distribuzione Bernoulliana condizionata su theta.\n\nCompiliamo il modello:\n\n# Create a CmdStanModel object\nmod_prior &lt;- cmdstan_model(here::here(\"stan\", \"betabinomial_prior.stan\"))\n\nEsaminiamo il modello:\n\nmod_prior$print()\n#&gt; data {\n#&gt;   int&lt;lower=0&gt; N;             // Numero di osservazioni\n#&gt;   real&lt;lower=0&gt; alpha_prior;  // Parametro alpha del prior Beta\n#&gt;   real&lt;lower=0&gt; beta_prior;   // Parametro beta del prior Beta\n#&gt; }\n#&gt; generated quantities {\n#&gt;   real&lt;lower=0, upper=1&gt; theta_prior;    // Valore estratto da Beta(alpha_prior, beta_prior)\n#&gt;   array[N] int&lt;lower=0, upper=1&gt; y_sim;  // Osservazioni simulate\n#&gt;   \n#&gt;   theta_prior = beta_rng(alpha_prior, beta_prior); // Generazione di theta\n#&gt;   for (n in 1:N) {\n#&gt;     y_sim[n] = bernoulli_rng(theta_prior); // Simulazione dei successi\n#&gt;   }\n#&gt; }\n\nIn questo script abbiamo\n\n\neliminato il blocco model: Questo blocco serve per l’inferenza Bayesiana, ma non è necessario per generare dati a priori.\n\naggiunto il blocco generated quantities: In questo blocco generiamo quantità di interesse, come i dati simulati y_sim e il valore di theta estratto dalla distribuzione a priori.\n\nutilizzato la funzione beta_rng per estrarre un valore per theta dalla distribuzione \\(\\mathcal{Beta}\\) definita dai parametri alpha_prior e beta_prior. Questo valore rappresenta una possibile realizzazione del parametro prima di osservare i dati.\n\nutilizzato la funzione binomial_rng per simulare N osservazioni dalla distribuzione binomiale. Il parametro di successo theta è fissato al valore estratto theta_prior.\n\nIn sostanza, questo codice ci permette di generare un dataset simulato che potrebbe essere osservato se il processo stocastico fosse governato unicamente dai parametri specificati nella distribuzione a priori. In questo modo, possiamo valutare le proprietà del modello e la sua capacità di generare dati simili a quelli reali, prima ancora di avere a disposizione i dati osservati.\nLa distribuzione a priori rappresenta la nostra conoscenza o credenza sul valore del parametro theta prima di osservare i dati. Scegliendo diversi valori per alpha_prior e beta_prior, possiamo specificare diverse distribuzioni a priori e quindi esplorare come queste influenzano i risultati della simulazione.\nI dati richiesti dal modello vengono specificati nel modo seguente:\n\n# Dati osservati\nN &lt;- 100               # Numero di osservazioni\n\n# Parametri del prior\nalpha_prior &lt;- 4\nbeta_prior &lt;- 6\n\n# Dati per Stan\nstan_data_prior &lt;- list(\n  N = N, \n  alpha_prior = alpha_prior, \n  beta_prior = beta_prior\n)\n\nEseguiamo il campionamento:\n\n# Simulazione del prior\nfit_prior &lt;- mod_prior$sample(\n  data = stan_data_prior,\n  chains = 4, \n  iter_sampling = 1000, \n  iter_warmup = 0,\n  fixed_param = TRUE, \n  show_messages = FALSE\n)\n\nSi noti l’argomento fixed_param = TRUE in quanto nessun parametro viene aggiornato.\nEstraiamo i campioni a posteriori e visualizziamo i risultati:\n\n# Estraiamo theta_prior e y_sim\ntheta_prior &lt;- fit_prior$draws(\"theta_prior\")\ny_sim &lt;- fit_prior$draws(\"y_sim\")\n\nGeneriamo la distribuzione a priori di theta:\n\n# Distribuzione a priori di theta\nhist(\n  theta_prior, \n  main = \"Distribuzione a priori di theta\", \n  xlab = \"theta\", \n  freq = FALSE\n)\n\n\n\n\n\n\n\nCostruiamo la distribuzione predittiva a priori della proporzione di successi:\n\n# Distribuzione dei successi simulati\ny_sim_mean &lt;- rowMeans(y_sim)\nhist(\n  y_sim_mean, \n  breaks = 20, \n  main = \"Distribuzione predittiva a priori\", \n  xlab = \"Proporzione di successi\", \n  freq = FALSE\n)\n\n\n\n\n\n\n\nLa distribuzione predittiva a priori mostra che i dati simulati riflettono il comportamento atteso dato il prior. Per il prior \\(\\mathcal{Beta}(4, 6)\\):\n\nLa media attesa di theta è \\(\\mathbb{E}[\\theta] = \\frac{\\alpha}{\\alpha + \\beta} = 0.4\\).\nLa varianza attesa è \\(\\text{Var}(\\theta) = \\frac{\\alpha \\beta}{(\\alpha + \\beta)^2 (\\alpha + \\beta + 1)}\\).\n\nCon 14 successi su 100 osservazioni reali, corrispondenti a una proporzione di 0.14, notiamo che:\n\nIl prior \\(\\mathcal{Beta}(4, 6)\\) è informativo, con un centro più alto rispetto ai dati osservati.\nSe vogliamo un prior meno concentrato (ad esempio \\(\\mathcal{Beta}(2, 2)\\)), i dati avranno un peso maggiore.\n\nIn conclusione,\n\nutilizzare un prior informativo è appropriato se abbiamo conoscenze precedenti robuste;\nse vogliamo un prior che lasci maggior spazio ai dati osservati, potremmo scegliere distribuzioni più ampie come \\(\\mathcal{Beta}(2, 2)\\).\n\nLa verifica predittiva a priori è uno strumento potente per convalidare queste scelte.\n\n56.7.2 Modello Gaussiano\nConsideriamo un secondo esempio, facciamo riferimento al caso discusso in precedenza dove veniva considerato un campione di dati gaussiani e un modello gaussiano in cui le distribuzioni a priori per μ e σ erano gaussiane.\nCompiliamo e stampiamo il modello Stan per generare la distribuzione predittiva a priori:\n\nmod_gauss_prior &lt;- cmdstan_model(\n  here::here(\"stan\", \"gaussian_model_prior.stan\")\n)\n\n\nmod_gauss_prior$print()\n#&gt; data {\n#&gt;   int&lt;lower=0&gt; N; // number of observations\n#&gt;   real mu_prior; // prior mean for mu\n#&gt;   real&lt;lower=0&gt; sigma_prior; // prior standard deviation for mu\n#&gt;   real&lt;lower=0&gt; sigma_prior_mean; // prior mean for sigma\n#&gt;   real&lt;lower=0&gt; sigma_prior_sd; // prior standard deviation for sigma\n#&gt; }\n#&gt; generated quantities {\n#&gt;   real mu = normal_rng(mu_prior, sigma_prior); // prior draw for mu\n#&gt;   real&lt;lower=0&gt; sigma = normal_rng(sigma_prior_mean, sigma_prior_sd); // prior draw for sigma\n#&gt;   array[N] real y_rep;\n#&gt;   for (n in 1 : N) {\n#&gt;     y_rep[n] = normal_rng(mu, sigma);\n#&gt;   }\n#&gt; }\n\n\nstan_data_gauss &lt;- list(\n  N = 100,\n  mu_prior = 180,\n  sigma_prior = 20,\n  sigma_prior_mean = 10,\n  sigma_prior_sd = 3\n)\n\nEseguiamo il campionamento MCMC:\n\nfit_gauss_prior &lt;- mod_gauss_prior$sample(\n  data = stan_data_gauss,\n  chains = 4, \n  iter_sampling = 1000, \n  iter_warmup = 0,\n  fixed_param = TRUE, # Nessun parametro aggiornato\n  show_messages = FALSE\n)\n\nUn sommario delle distribuzioni a posteriori dei parametri si ottiene nel modo seguente:\n\n# Estrai i campioni per mu e sigma\ndraws &lt;- fit_gauss_prior$draws(c(\"mu\", \"sigma\"))\nprint(draws)\n#&gt; # A draws_array: 1000 iterations, 4 chains, and 2 variables\n#&gt; , , variable = mu\n#&gt; \n#&gt;          chain\n#&gt; iteration   1   2   3   4\n#&gt;         1 190 173 231 189\n#&gt;         2 179 193 188 190\n#&gt;         3 198 167 156 180\n#&gt;         4 181 174 168 180\n#&gt;         5 176 220 133 169\n#&gt; \n#&gt; , , variable = sigma\n#&gt; \n#&gt;          chain\n#&gt; iteration    1    2    3    4\n#&gt;         1  9.0  5.2 13.2  8.4\n#&gt;         2  9.3  7.0 10.9  8.6\n#&gt;         3  8.5  4.7 10.8 10.6\n#&gt;         4  9.8  6.3  6.8  8.1\n#&gt;         5 17.0 11.1 12.2  9.9\n#&gt; \n#&gt; # ... with 995 more iterations\n\nEstraiamo i campioni per mu e sigma:\n\ndraws &lt;- fit_gauss_prior$draws(c(\"mu\", \"sigma\"))\n\nConvertiamo i campioni in data frame:\n\ndraws_df &lt;- as_draws_df(draws)\n\nCreaiamo un grafico della distribuzione a priori di mu:\n\ndraws_df |&gt; \n  ggplot(aes(x = mu)) +\n    geom_density(fill = \"gray\", alpha = 0.5) +\n    labs(title = \"Distribuzione Predittiva a Priori di Mu\",\n         x = \"Mu\",\n         y = \"Densità\")\n#&gt; Warning: Removed 3 rows containing non-finite outside the scale range\n#&gt; (`stat_density()`).\n\n\n\n\n\n\n\nDistribuzione a priori di sigma:\n\ndraws_df |&gt; \n  ggplot(aes(x = sigma)) +\n    geom_density(fill = \"lightgray\", alpha = 0.5) +\n    labs(title = \"Distribuzione Predittiva a Priori di Sigma\",\n         x = \"Sigma\",\n         y = \"Densità\")\n#&gt; Warning: Removed 3 rows containing non-finite outside the scale range\n#&gt; (`stat_density()`).\n\n\n\n\n\n\n\nIl grafico della distribuzione predittiva a priori ci mostra che i prior utilizzati nel codice Stan implicano una distribuzione della variabile di interesse y che è approssimativamente normale con media di 180 e deviazione standard di 22. Questo prior predictive check garantisce che le distribuzioni a priori dei parametri mu e sigma siano realistiche e adeguate per l’analisi dei dati considerati. Un discorso simile si può fare per sigma. Questo passaggio consente di identificare e correggere eventuali ipotesi errate prima di procedere con l’analisi dei dati osservati, migliorando così la validità dei risultati ottenuti.\n\n56.8 Riflessioni Conclusive\nLe distribuzioni predittive a priori e a posteriori, pur essendo generate in modo simile, differiscono per la fonte di informazione utilizzata nella loro costruzione.\n\nDistribuzione Predittiva a Priori: Questa distribuzione rappresenta le nostre aspettative sui dati prima che qualsiasi osservazione effettiva sia disponibile. Per costruirla, prendiamo i valori dei parametri dalla distribuzione a priori e li utilizziamo nella funzione di verosimiglianza per generare dati simulati. La distribuzione risultante di questi dati generati è la distribuzione predittiva a priori, che riflette le nostre conoscenze e incertezze iniziali, prima di osservare i dati reali.\nDistribuzione Predittiva a Posteriori: Dopo aver osservato i dati, aggiorniamo le nostre credenze sui parametri utilizzando il teorema di Bayes, ottenendo così la distribuzione a posteriori dei parametri. La distribuzione predittiva a posteriori viene quindi generata prendendo valori dei parametri dalla distribuzione a posteriori, che ora incorpora l’informazione ottenuta dai dati osservati, e utilizzandoli nella funzione di verosimiglianza per generare nuovi dati simulati. Questa distribuzione riflette le nostre previsioni sui dati futuri o non osservati, dopo aver tenuto conto dei dati già raccolti.\n\nLa differenza principale tra queste due distribuzioni predittive risiede nella distribuzione dei parametri utilizzata: nella distribuzione predittiva a priori si utilizzano i parametri estratti dal prior, mentre nella distribuzione predittiva a posteriori si utilizzano i parametri estratti dal posterior. La distribuzione predittiva a posteriori è generalmente più informativa poiché integra i dati osservati, migliorando le previsioni future.\nÈ cruciale per l’integrità del modello che la distribuzione predittiva a posteriori sia coerente con la distribuzione dei dati osservati. Per verificare questa coerenza, si utilizzano le verifiche predittive a posteriori, confrontando la distribuzione predittiva con i dati empirici tramite tecniche come le stime di densità kernel (KDE). Questo confronto permette di valutare quanto bene il modello riesca ad approssimare la struttura reale dei dati e la sua capacità di fornire previsioni affidabili.\nAd esempio, consideriamo un modello gaussiano con varianza \\(\\sigma^2\\) nota:\n\\[\n\\begin{aligned}\n  y\\sim \\mathop{\\mathrm{N}}(\\theta,\\sigma^2),\n\\end{aligned}\n\\]\ndove \\(\\sigma^2\\) descrive l’incertezza aleatoria. Usando un prior uniforme, la distribuzione a posteriori per \\(\\theta\\) sarà:\n\\[\n\\begin{aligned}\n  p(\\theta|y) \\sim \\mathop{\\mathrm{N}}(\\theta|\\bar{y},\\sigma^2/n),\n\\end{aligned}\n\\]\ndove \\(\\sigma^2/n\\) rappresenta l’incertezza epistemica legata a \\(\\theta\\). La distribuzione predittiva a posteriori per un nuovo valore \\(\\tilde{y}\\) sarà:\n\\[\n\\begin{aligned}\n  p(\\tilde{y}|y) \\sim \\mathop{\\mathrm{N}}(\\tilde{y}|\\bar{y},\\sigma^2+\\sigma^2/n),\n\\end{aligned}\n\\]\nIn questo caso, l’incertezza totale è data dalla somma dell’incertezza epistemica (\\(\\sigma^2/n\\)) e dell’incertezza aleatoria (\\(\\sigma^2\\)).\nInformazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] bayestestR_0.15.0   posterior_1.6.0     cmdstanr_0.8.1.9000\n#&gt;  [4] see_0.9.0           gridExtra_2.3       patchwork_1.3.0    \n#&gt;  [7] bayesplot_1.11.1    psych_2.4.12        scales_1.3.0       \n#&gt; [10] markdown_1.13       knitr_1.49          lubridate_1.9.4    \n#&gt; [13] forcats_1.0.0       stringr_1.5.1       dplyr_1.1.4        \n#&gt; [16] purrr_1.0.2         readr_2.1.5         tidyr_1.3.1        \n#&gt; [19] tibble_3.2.1        ggplot2_3.5.1       tidyverse_2.0.0    \n#&gt; [22] rio_1.2.3           here_1.0.1         \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6         tensorA_0.36.2.1     xfun_0.49           \n#&gt;  [4] htmlwidgets_1.6.4    insight_1.0.0        processx_3.8.4      \n#&gt;  [7] lattice_0.22-6       tzdb_0.4.0           vctrs_0.6.5         \n#&gt; [10] tools_4.4.2          ps_1.8.1             generics_0.1.3      \n#&gt; [13] parallel_4.4.2       pacman_0.5.1         pkgconfig_2.0.3     \n#&gt; [16] data.table_1.16.4    checkmate_2.3.2      distributional_0.5.0\n#&gt; [19] lifecycle_1.0.4      compiler_4.4.2       farver_2.1.2        \n#&gt; [22] munsell_0.5.1        mnormt_2.1.1         htmltools_0.5.8.1   \n#&gt; [25] yaml_2.3.10          pillar_1.10.0        abind_1.4-8         \n#&gt; [28] nlme_3.1-166         tidyselect_1.2.1     digest_0.6.37       \n#&gt; [31] stringi_1.8.4        reshape2_1.4.4       labeling_0.4.3      \n#&gt; [34] rprojroot_2.0.4      fastmap_1.2.0        grid_4.4.2          \n#&gt; [37] colorspace_2.1-1     cli_3.6.3            magrittr_2.0.3      \n#&gt; [40] utf8_1.2.4           withr_3.0.2          backports_1.5.0     \n#&gt; [43] timechange_0.3.0     rmarkdown_2.29       matrixStats_1.4.1   \n#&gt; [46] hms_1.1.3            evaluate_1.0.1       rlang_1.1.4         \n#&gt; [49] Rcpp_1.0.13-1        glue_1.8.0           jsonlite_1.8.9      \n#&gt; [52] plyr_1.8.9           R6_2.5.1\n\nBibliografia\n\n\n\n\n\n\nGelman, A., & Shalizi, C. R. (2013). Philosophy and the practice of Bayesian statistics. British Journal of Mathematical and Statistical Psychology, 66(1), 8–38.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>La predizione bayesiana 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_mcmc_prediction.html#implementazione-con-cmdstanr",
    "href": "chapters/mcmc/06_mcmc_prediction.html#implementazione-con-cmdstanr",
    "title": "56  La predizione bayesiana 🔸",
    "section": "\n56.5 Implementazione con cmdstanr\n",
    "text": "56.5 Implementazione con cmdstanr\n\nPer illustrare come viene generata la distribuzione predittiva a posteriori nel contesto del modello normale-normale, possiamo utilizzare cmdstanr per eseguire l’analisi. Il codice seguente mostra come configurare il modello e generare previsioni.\n\n# Dati osservati\nset.seed(123)  # Imposta il seed per la riproducibilità\ny_observed &lt;- rnorm(100, 170, 10)\nmean_y &lt;- mean(y_observed)\nstd_y &lt;- sd(y_observed)\n\n# Parametri a priori\nmu_0 &lt;- 175\ntau_0 &lt;- 5\n\n# Parametri posteriori\ntau_n_sq &lt;- (tau_0^2 * std_y^2) / (tau_0^2 + std_y^2)\ntau_n &lt;- sqrt(tau_n_sq)\nmu_n &lt;- (tau_0^2 * mean_y + std_y^2 * mu_0) / (tau_0^2 + std_y^2)\n\n# Parametri predittivi\nn_fut &lt;- 100\nsigma_pred_sq &lt;- tau_n_sq + (std_y^2 / n_fut)\nsigma_pred &lt;- sqrt(sigma_pred_sq)\nmu_pred &lt;- mu_n\n\n# Simulazioni\ny_pred_samples &lt;- rnorm(1000, mu_pred, sigma_pred)\n\n# Dati per ggplot\ndata &lt;- data.frame(Heights = y_pred_samples)\n\n# Grafico\np &lt;- ggplot(data, aes(x = Heights)) +\n  geom_histogram(\n    aes(y = ..density..), \n    bins = 30, \n    fill = \"gray\", \n    colour = \"gray\", \n    alpha = 0.5\n  ) +\n  geom_density(colour = \"black\", size = 1.5) +\n  geom_vline(\n    xintercept = mu_pred, \n    colour = \"gray\", \n    linetype = \"dashed\", \n    size = 1\n  ) +\n  labs(title = \"Posterior Predictive Distribution for Heights\",\n       x = \"Heights (cm)\",\n       y = \"Density\") +\n  theme(legend.position = \"none\")\n#&gt; Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#&gt; ℹ Please use `linewidth` instead.\n\n# Visualizza il grafico\nprint(p)\n#&gt; Warning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\n#&gt; ℹ Please use `after_stat(density)` instead.\n\n\n\n\n\n\n\nQuesto codice produce un grafico che illustra visivamente la distribuzione predittiva a posteriori per le altezze nel nostro campione di 100 nuove osservazioni, tenendo conto sia dei dati osservati che delle nostre aspettative iniziali.\nIn sintesi, la distribuzione predittiva a posteriori è stata generata nel modo seguente:\n\nCampioniamo un valore \\(\\mu\\) dalla distribuzione a posteriori di \\(\\mu\\).\nCampioniamo un valore \\(\\sigma\\) dalla distribuzione a posteriori di \\(\\sigma\\).\nUtilizziamo questi valori per generare un campione dalla distribuzione normale con parametri \\(\\mu\\) e \\(\\sigma\\).\nRipetiamo questo processo molte volte.\n\nLa distribuzione dei valori ottenuti da questi campionamenti costituisce la distribuzione predittiva a posteriori.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>La predizione bayesiana 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_mcmc_prediction.html#metodo-mcmc",
    "href": "chapters/mcmc/06_mcmc_prediction.html#metodo-mcmc",
    "title": "56  La predizione bayesiana 🔸",
    "section": "\n56.6 Metodo MCMC",
    "text": "56.6 Metodo MCMC\nQuando usiamo un PPL come Stan, la distribuzione predittiva viene stimata mediante il campionamento da una catena di Markov, che è particolarmente utile in scenari complessi dove l’analisi analitica potrebbe essere impraticabile. Attraverso i metodi MCMC, si stimano le potenziali osservazioni future \\(p(\\tilde{y} \\mid y)\\), indicate come \\(p(y^{rep} \\mid y)\\), seguendo questi passaggi:\n\nSi campiona \\(\\theta_i \\sim p(\\theta \\mid y)\\): Viene selezionato casualmente un valore del parametro (o dei parametri) dalla distribuzione a posteriori.\nSi campiona \\(y^{rep} \\sim p(y^{rep} \\mid \\theta_i)\\): Viene scelta casualmente un’osservazione dalla funzione di verosimiglianza, condizionata al valore del parametro (o dei parametri)ottenuto nel passo precedente.\n\nRipetendo questi due passaggi un numero sufficiente di volte, l’istogramma risultante approssimerà la distribuzione predittiva a posteriori.\nEsaminiamo ora come ottenere la distribuzione predittiva a posteriori con Stan per i dati dell’esempio precedente. Iniziamo creando le distribuzioni a posteriori di \\(\\mu\\) e \\(\\sigma\\).\nDefiniamo un dizionario che contiene i dati.\n\nstan_data_gauss = list(\n  N = length(y_observed),\n  y = y_observed,\n  mu_prior = 180,\n  sigma_prior = 20,\n  sigma_prior_mean = 10,\n  sigma_prior_sd = 3\n)\n\n\ny_mean = mean(y_observed)\ny_std = sd(y_observed)\n\ny_mean\n#&gt; [1] 171\ny_std\n#&gt; [1] 9.13\n\nCompiliamo e stampiamo il modello Stan:\n\n# Path to the Stan file\nstan_file &lt;- here::here(\"stan\", \"gaussian_model.stan\")\n\n# Create a CmdStanModel object\nmod &lt;- cmdstan_model(stan_file)\n\n\nmod$print()\n#&gt; data {\n#&gt;   int&lt;lower=0&gt; N; // number of observations\n#&gt;   vector[N] y; // observed data\n#&gt;   real mu_prior; // prior mean for mu\n#&gt;   real&lt;lower=0&gt; sigma_prior; // prior standard deviation for mu\n#&gt;   real&lt;lower=0&gt; sigma_prior_mean; // prior mean for sigma\n#&gt;   real&lt;lower=0&gt; sigma_prior_sd; // prior standard deviation for sigma\n#&gt; }\n#&gt; parameters {\n#&gt;   real mu; // parameter of interest\n#&gt;   real&lt;lower=0&gt; sigma; // parameter for the standard deviation\n#&gt; }\n#&gt; model {\n#&gt;   mu ~ normal(mu_prior, sigma_prior); // prior for mu\n#&gt;   sigma ~ normal(sigma_prior_mean, sigma_prior_sd); // prior for sigma\n#&gt;   y ~ normal(mu, sigma); // likelihood\n#&gt; }\n#&gt; generated quantities {\n#&gt;   array[N] real y_rep;\n#&gt;   for (n in 1 : N) {\n#&gt;     y_rep[n] = normal_rng(mu, sigma);\n#&gt;   }\n#&gt; }\n\nEseguiamo il campionamento MCMC:\n\nfit &lt;- mod$sample(\n  data = stan_data_gauss,\n  seed = 123,\n  chains = 4,\n  parallel_chains = 4,\n  iter_sampling = 2000, \n  iter_warmup = 2000,\n  show_messages = FALSE\n)\n\nUn sommario delle distribuzioni a posteriori dei parametri si ottiene nel modo seguente:\n\nfit$summary(c(\"mu\", \"sigma\"))\n#&gt; # A tibble: 2 × 10\n#&gt;   variable   mean median    sd   mad     q5   q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 mu       171.   171.   0.932 0.943 169.   172.   1.00    7321.    5508.\n#&gt; 2 sigma      9.27   9.23 0.652 0.647   8.28  10.4  1.00    6675.    5412.\n\nEstraiamo i dati prodotti dal modello y_rep e i dati osservati y:\n\n# Extract posterior predictive samples for y_rep\ny_rep &lt;- fit$draws(variables = \"y_rep\", format = \"draws_matrix\")\n\n# Extract observed data\ny_obs &lt;- stan_data_gauss$y\n\nConvertiamo y_rep in una matrice per compatibilità con {bayesplot}.\n\n# Convert y_rep to a matrix\ny_rep_matrix &lt;- as.matrix(y_rep)\n\nGeneriamo il posterior predictive chech plot:\n\n# Posterior predictive check plot\nset.seed(123)\nselected_indices &lt;- sample(nrow(y_rep_matrix), 50)\nppc_dens_overlay(y = y_obs, yrep = y_rep_matrix[selected_indices, ])\n\n\n\n\n\n\n\nLa distribuzione predittiva a posteriori è utilizzata per eseguire i controlli predittivi a posteriori (PPC), noti come Posterior Predictive Checks. I PPC consistono in un confronto grafico tra \\(p(y^{rep} \\mid y)\\), ossia la distribuzione delle osservazioni future previste, e i dati osservati \\(y\\). Questo confronto visivo permette di valutare se il modello utilizzato è adeguato per descrivere le proprietà dei dati osservati.\nOltre al confronto grafico tra le distribuzioni \\(p(y)\\) e \\(p(y^{rep})\\), è possibile effettuare un confronto tra le distribuzioni di varie statistiche descrittive calcolate su diversi campioni \\(y^{rep}\\) e le corrispondenti statistiche calcolate sui dati osservati. Tipicamente, vengono considerate statistiche descrittive come la media, la varianza, la deviazione standard, il minimo o il massimo, ma è possibile confrontare qualsiasi altra statistica rilevante.\nI controlli predittivi a posteriori offrono un valido strumento per un’analisi critica delle prestazioni del modello e, se necessario, per apportare eventuali modifiche o considerare modelli alternativi più adatti ai dati in esame.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>La predizione bayesiana 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_mcmc_prediction.html#distribuzione-predittiva-a-priori",
    "href": "chapters/mcmc/06_mcmc_prediction.html#distribuzione-predittiva-a-priori",
    "title": "56  La predizione bayesiana 🔸",
    "section": "\n56.7 Distribuzione Predittiva a Priori",
    "text": "56.7 Distribuzione Predittiva a Priori\nLa verifica predittiva a priori è un metodo fondamentale per esplorare le implicazioni dei tuoi prior. Genera dati simulati basandosi unicamente sui prior, ignorando completamente i dati osservati. Questo permette di rispondere a domande cruciali come:\n\nI dati generati dal prior riflettono scenari plausibili?\nIl prior è troppo restrittivo o troppo ampio rispetto ai dati attesi?\n\nQuesta verifica è particolarmente utile per identificare eventuali incongruenze o assunzioni non realistiche prima di raccogliere i dati osservati.\n\n56.7.1 Modello Beta-Binomiale\nIniziamo con il caso più semplice. Il modello beta-binomiale è un esempio classico per illustrare la verifica predittiva a priori. In questo modello:\n\n\ntheta rappresenta la probabilità di successo.\nIl prior su theta è distribuito secondo una distribuzione Beta parametrizzata da alpha_prior e beta_prior.\nI dati (y) seguono una distribuzione Bernoulliana condizionata su theta.\n\nIl modello Stan per l’inferenza sui dati osservati è il seguente:\ndata {\n  int&lt;lower=0&gt; N;             // Numero di osservazioni\n  array[N] int&lt;lower=0, upper=1&gt; y; // Dati osservati (successi)\n  real&lt;lower=0&gt; alpha_prior;  // Parametro alpha del prior Beta\n  real&lt;lower=0&gt; beta_prior;   // Parametro beta del prior Beta\n}\nparameters {\n  real&lt;lower=0, upper=1&gt; theta; // Probabilità di successo\n}\nmodel {\n  theta ~ beta(alpha_prior, beta_prior); // Prior su theta\n  y ~ bernoulli(theta);                  // Likelihood\n}\nPer eseguire la simulazione dalla distribuzione predittiva a priori, rimuoviamo il blocco model e utilizziamo generated quantities per simulare:\n\nl’estrazione di un valore per theta dalla distribuzione Beta specificata dai parametri del prior;\nla generazione di successi simulati (y_sim) dalla distribuzione Bernoulliana condizionata su theta.\n\nCompiliamo il modello:\n\n# Create a CmdStanModel object\nmod_prior &lt;- cmdstan_model(here::here(\"stan\", \"betabinomial_prior.stan\"))\n\nEsaminiamo il modello:\n\nmod_prior$print()\n#&gt; data {\n#&gt;   int&lt;lower=0&gt; N;             // Numero di osservazioni\n#&gt;   real&lt;lower=0&gt; alpha_prior;  // Parametro alpha del prior Beta\n#&gt;   real&lt;lower=0&gt; beta_prior;   // Parametro beta del prior Beta\n#&gt; }\n#&gt; generated quantities {\n#&gt;   real&lt;lower=0, upper=1&gt; theta_prior;    // Valore estratto da Beta(alpha_prior, beta_prior)\n#&gt;   array[N] int&lt;lower=0, upper=1&gt; y_sim;  // Osservazioni simulate\n#&gt;   \n#&gt;   theta_prior = beta_rng(alpha_prior, beta_prior); // Generazione di theta\n#&gt;   for (n in 1:N) {\n#&gt;     y_sim[n] = bernoulli_rng(theta_prior); // Simulazione dei successi\n#&gt;   }\n#&gt; }\n\nIn questo script abbiamo\n\n\neliminato il blocco model: Questo blocco serve per l’inferenza Bayesiana, ma non è necessario per generare dati a priori.\n\naggiunto il blocco generated quantities: In questo blocco generiamo quantità di interesse, come i dati simulati y_sim e il valore di theta estratto dalla distribuzione a priori.\n\nutilizzato la funzione beta_rng per estrarre un valore per theta dalla distribuzione \\(\\mathcal{Beta}\\) definita dai parametri alpha_prior e beta_prior. Questo valore rappresenta una possibile realizzazione del parametro prima di osservare i dati.\n\nutilizzato la funzione binomial_rng per simulare N osservazioni dalla distribuzione binomiale. Il parametro di successo theta è fissato al valore estratto theta_prior.\n\nIn sostanza, questo codice ci permette di generare un dataset simulato che potrebbe essere osservato se il processo stocastico fosse governato unicamente dai parametri specificati nella distribuzione a priori. In questo modo, possiamo valutare le proprietà del modello e la sua capacità di generare dati simili a quelli reali, prima ancora di avere a disposizione i dati osservati.\nLa distribuzione a priori rappresenta la nostra conoscenza o credenza sul valore del parametro theta prima di osservare i dati. Scegliendo diversi valori per alpha_prior e beta_prior, possiamo specificare diverse distribuzioni a priori e quindi esplorare come queste influenzano i risultati della simulazione.\nI dati richiesti dal modello vengono specificati nel modo seguente:\n\n# Dati osservati\nN &lt;- 100               # Numero di osservazioni\n\n# Parametri del prior\nalpha_prior &lt;- 4\nbeta_prior &lt;- 6\n\n# Dati per Stan\nstan_data_prior &lt;- list(\n  N = N, \n  alpha_prior = alpha_prior, \n  beta_prior = beta_prior\n)\n\nEseguiamo il campionamento:\n\n# Simulazione del prior\nfit_prior &lt;- mod_prior$sample(\n  data = stan_data_prior,\n  chains = 4, \n  iter_sampling = 1000, \n  iter_warmup = 0,\n  fixed_param = TRUE, \n  show_messages = FALSE\n)\n\nSi noti l’argomento fixed_param = TRUE in quanto nessun parametro viene aggiornato.\nEstraiamo i campioni a posteriori e visualizziamo i risultati:\n\n# Estraiamo theta_prior e y_sim\ntheta_prior &lt;- fit_prior$draws(\"theta_prior\")\ny_sim &lt;- fit_prior$draws(\"y_sim\")\n\nGeneriamo la distribuzione a priori di theta:\n\n# Distribuzione a priori di theta\nhist(\n  theta_prior, \n  main = \"Distribuzione a priori di theta\", \n  xlab = \"theta\", \n  freq = FALSE\n)\n\n\n\n\n\n\n\nCostruiamo la distribuzione predittiva a priori della proporzione di successi:\n\n# Distribuzione dei successi simulati\ny_sim_mean &lt;- rowMeans(y_sim)\nhist(\n  y_sim_mean, \n  breaks = 20, \n  main = \"Distribuzione predittiva a priori\", \n  xlab = \"Proporzione di successi\", \n  freq = FALSE\n)\n\n\n\n\n\n\n\nLa distribuzione predittiva a priori mostra che i dati simulati riflettono il comportamento atteso dato il prior. Per il prior \\(\\mathcal{Beta}(4, 6)\\):\n\nLa media attesa di theta è \\(\\mathbb{E}[\\theta] = \\frac{\\alpha}{\\alpha + \\beta} = 0.4\\).\nLa varianza attesa è \\(\\text{Var}(\\theta) = \\frac{\\alpha \\beta}{(\\alpha + \\beta)^2 (\\alpha + \\beta + 1)}\\).\n\nCon 14 successi su 100 osservazioni reali, corrispondenti a una proporzione di 0.14, notiamo che:\n\nIl prior \\(\\mathcal{Beta}(4, 6)\\) è informativo, con un centro più alto rispetto ai dati osservati.\nSe vogliamo un prior meno concentrato (ad esempio \\(\\mathcal{Beta}(2, 2)\\)), i dati avranno un peso maggiore.\n\nIn conclusione,\n\nutilizzare un prior informativo è appropriato se abbiamo conoscenze precedenti robuste;\nse vogliamo un prior che lasci maggior spazio ai dati osservati, potremmo scegliere distribuzioni più ampie come \\(\\mathcal{Beta}(2, 2)\\).\n\nLa verifica predittiva a priori è uno strumento potente per convalidare queste scelte.\n\n56.7.2 Modello Gaussiano\nConsideriamo un secondo esempio, facciamo riferimento al caso discusso in precedenza dove veniva considerato un campione di dati gaussiani e un modello gaussiano in cui le distribuzioni a priori per μ e σ erano gaussiane.\nCompiliamo e stampiamo il modello Stan per generare la distribuzione predittiva a priori:\n\nmod_gauss_prior &lt;- cmdstan_model(\n  here::here(\"stan\", \"gaussian_model_prior.stan\")\n)\n\n\nmod_gauss_prior$print()\n#&gt; data {\n#&gt;   int&lt;lower=0&gt; N; // number of observations\n#&gt;   real mu_prior; // prior mean for mu\n#&gt;   real&lt;lower=0&gt; sigma_prior; // prior standard deviation for mu\n#&gt;   real&lt;lower=0&gt; sigma_prior_mean; // prior mean for sigma\n#&gt;   real&lt;lower=0&gt; sigma_prior_sd; // prior standard deviation for sigma\n#&gt; }\n#&gt; generated quantities {\n#&gt;   real mu = normal_rng(mu_prior, sigma_prior); // prior draw for mu\n#&gt;   real&lt;lower=0&gt; sigma = normal_rng(sigma_prior_mean, sigma_prior_sd); // prior draw for sigma\n#&gt;   array[N] real y_rep;\n#&gt;   for (n in 1 : N) {\n#&gt;     y_rep[n] = normal_rng(mu, sigma);\n#&gt;   }\n#&gt; }\n\n\nstan_data_gauss &lt;- list(\n  N = 100,\n  mu_prior = 180,\n  sigma_prior = 20,\n  sigma_prior_mean = 10,\n  sigma_prior_sd = 3\n)\n\nEseguiamo il campionamento MCMC:\n\nfit_gauss_prior &lt;- mod_gauss_prior$sample(\n  data = stan_data_gauss,\n  chains = 4, \n  iter_sampling = 1000, \n  iter_warmup = 0,\n  fixed_param = TRUE, # Nessun parametro aggiornato\n  show_messages = FALSE\n)\n\nUn sommario delle distribuzioni a posteriori dei parametri si ottiene nel modo seguente:\n\n# Estrai i campioni per mu e sigma\ndraws &lt;- fit_gauss_prior$draws(c(\"mu\", \"sigma\"))\nprint(draws)\n#&gt; # A draws_array: 1000 iterations, 4 chains, and 2 variables\n#&gt; , , variable = mu\n#&gt; \n#&gt;          chain\n#&gt; iteration   1   2   3   4\n#&gt;         1 190 173 231 189\n#&gt;         2 179 193 188 190\n#&gt;         3 198 167 156 180\n#&gt;         4 181 174 168 180\n#&gt;         5 176 220 133 169\n#&gt; \n#&gt; , , variable = sigma\n#&gt; \n#&gt;          chain\n#&gt; iteration    1    2    3    4\n#&gt;         1  9.0  5.2 13.2  8.4\n#&gt;         2  9.3  7.0 10.9  8.6\n#&gt;         3  8.5  4.7 10.8 10.6\n#&gt;         4  9.8  6.3  6.8  8.1\n#&gt;         5 17.0 11.1 12.2  9.9\n#&gt; \n#&gt; # ... with 995 more iterations\n\nEstraiamo i campioni per mu e sigma:\n\ndraws &lt;- fit_gauss_prior$draws(c(\"mu\", \"sigma\"))\n\nConvertiamo i campioni in data frame:\n\ndraws_df &lt;- as_draws_df(draws)\n\nCreaiamo un grafico della distribuzione a priori di mu:\n\ndraws_df |&gt; \n  ggplot(aes(x = mu)) +\n    geom_density(fill = \"gray\", alpha = 0.5) +\n    labs(title = \"Distribuzione Predittiva a Priori di Mu\",\n         x = \"Mu\",\n         y = \"Densità\")\n#&gt; Warning: Removed 3 rows containing non-finite outside the scale range\n#&gt; (`stat_density()`).\n\n\n\n\n\n\n\nDistribuzione a priori di sigma:\n\ndraws_df |&gt; \n  ggplot(aes(x = sigma)) +\n    geom_density(fill = \"lightgray\", alpha = 0.5) +\n    labs(title = \"Distribuzione Predittiva a Priori di Sigma\",\n         x = \"Sigma\",\n         y = \"Densità\")\n#&gt; Warning: Removed 3 rows containing non-finite outside the scale range\n#&gt; (`stat_density()`).\n\n\n\n\n\n\n\nIl grafico della distribuzione predittiva a priori ci mostra che i prior utilizzati nel codice Stan implicano una distribuzione della variabile di interesse y che è approssimativamente normale con media di 180 e deviazione standard di 22. Questo prior predictive check garantisce che le distribuzioni a priori dei parametri mu e sigma siano realistiche e adeguate per l’analisi dei dati considerati. Un discorso simile si può fare per sigma. Questo passaggio consente di identificare e correggere eventuali ipotesi errate prima di procedere con l’analisi dei dati osservati, migliorando così la validità dei risultati ottenuti.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>La predizione bayesiana 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_mcmc_prediction.html#riflessioni-conclusive",
    "href": "chapters/mcmc/06_mcmc_prediction.html#riflessioni-conclusive",
    "title": "56  La predizione bayesiana 🔸",
    "section": "\n56.8 Riflessioni Conclusive",
    "text": "56.8 Riflessioni Conclusive\nLe distribuzioni predittive a priori e a posteriori, pur essendo generate in modo simile, differiscono per la fonte di informazione utilizzata nella loro costruzione.\n\nDistribuzione Predittiva a Priori: Questa distribuzione rappresenta le nostre aspettative sui dati prima che qualsiasi osservazione effettiva sia disponibile. Per costruirla, prendiamo i valori dei parametri dalla distribuzione a priori e li utilizziamo nella funzione di verosimiglianza per generare dati simulati. La distribuzione risultante di questi dati generati è la distribuzione predittiva a priori, che riflette le nostre conoscenze e incertezze iniziali, prima di osservare i dati reali.\nDistribuzione Predittiva a Posteriori: Dopo aver osservato i dati, aggiorniamo le nostre credenze sui parametri utilizzando il teorema di Bayes, ottenendo così la distribuzione a posteriori dei parametri. La distribuzione predittiva a posteriori viene quindi generata prendendo valori dei parametri dalla distribuzione a posteriori, che ora incorpora l’informazione ottenuta dai dati osservati, e utilizzandoli nella funzione di verosimiglianza per generare nuovi dati simulati. Questa distribuzione riflette le nostre previsioni sui dati futuri o non osservati, dopo aver tenuto conto dei dati già raccolti.\n\nLa differenza principale tra queste due distribuzioni predittive risiede nella distribuzione dei parametri utilizzata: nella distribuzione predittiva a priori si utilizzano i parametri estratti dal prior, mentre nella distribuzione predittiva a posteriori si utilizzano i parametri estratti dal posterior. La distribuzione predittiva a posteriori è generalmente più informativa poiché integra i dati osservati, migliorando le previsioni future.\nÈ cruciale per l’integrità del modello che la distribuzione predittiva a posteriori sia coerente con la distribuzione dei dati osservati. Per verificare questa coerenza, si utilizzano le verifiche predittive a posteriori, confrontando la distribuzione predittiva con i dati empirici tramite tecniche come le stime di densità kernel (KDE). Questo confronto permette di valutare quanto bene il modello riesca ad approssimare la struttura reale dei dati e la sua capacità di fornire previsioni affidabili.\nAd esempio, consideriamo un modello gaussiano con varianza \\(\\sigma^2\\) nota:\n\\[\n\\begin{aligned}\n  y\\sim \\mathop{\\mathrm{N}}(\\theta,\\sigma^2),\n\\end{aligned}\n\\]\ndove \\(\\sigma^2\\) descrive l’incertezza aleatoria. Usando un prior uniforme, la distribuzione a posteriori per \\(\\theta\\) sarà:\n\\[\n\\begin{aligned}\n  p(\\theta|y) \\sim \\mathop{\\mathrm{N}}(\\theta|\\bar{y},\\sigma^2/n),\n\\end{aligned}\n\\]\ndove \\(\\sigma^2/n\\) rappresenta l’incertezza epistemica legata a \\(\\theta\\). La distribuzione predittiva a posteriori per un nuovo valore \\(\\tilde{y}\\) sarà:\n\\[\n\\begin{aligned}\n  p(\\tilde{y}|y) \\sim \\mathop{\\mathrm{N}}(\\tilde{y}|\\bar{y},\\sigma^2+\\sigma^2/n),\n\\end{aligned}\n\\]\nIn questo caso, l’incertezza totale è data dalla somma dell’incertezza epistemica (\\(\\sigma^2/n\\)) e dell’incertezza aleatoria (\\(\\sigma^2\\)).",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>La predizione bayesiana 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_mcmc_prediction.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/06_mcmc_prediction.html#informazioni-sullambiente-di-sviluppo",
    "title": "56  La predizione bayesiana 🔸",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] bayestestR_0.15.0   posterior_1.6.0     cmdstanr_0.8.1.9000\n#&gt;  [4] see_0.9.0           gridExtra_2.3       patchwork_1.3.0    \n#&gt;  [7] bayesplot_1.11.1    psych_2.4.12        scales_1.3.0       \n#&gt; [10] markdown_1.13       knitr_1.49          lubridate_1.9.4    \n#&gt; [13] forcats_1.0.0       stringr_1.5.1       dplyr_1.1.4        \n#&gt; [16] purrr_1.0.2         readr_2.1.5         tidyr_1.3.1        \n#&gt; [19] tibble_3.2.1        ggplot2_3.5.1       tidyverse_2.0.0    \n#&gt; [22] rio_1.2.3           here_1.0.1         \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6         tensorA_0.36.2.1     xfun_0.49           \n#&gt;  [4] htmlwidgets_1.6.4    insight_1.0.0        processx_3.8.4      \n#&gt;  [7] lattice_0.22-6       tzdb_0.4.0           vctrs_0.6.5         \n#&gt; [10] tools_4.4.2          ps_1.8.1             generics_0.1.3      \n#&gt; [13] parallel_4.4.2       pacman_0.5.1         pkgconfig_2.0.3     \n#&gt; [16] data.table_1.16.4    checkmate_2.3.2      distributional_0.5.0\n#&gt; [19] lifecycle_1.0.4      compiler_4.4.2       farver_2.1.2        \n#&gt; [22] munsell_0.5.1        mnormt_2.1.1         htmltools_0.5.8.1   \n#&gt; [25] yaml_2.3.10          pillar_1.10.0        abind_1.4-8         \n#&gt; [28] nlme_3.1-166         tidyselect_1.2.1     digest_0.6.37       \n#&gt; [31] stringi_1.8.4        reshape2_1.4.4       labeling_0.4.3      \n#&gt; [34] rprojroot_2.0.4      fastmap_1.2.0        grid_4.4.2          \n#&gt; [37] colorspace_2.1-1     cli_3.6.3            magrittr_2.0.3      \n#&gt; [40] utf8_1.2.4           withr_3.0.2          backports_1.5.0     \n#&gt; [43] timechange_0.3.0     rmarkdown_2.29       matrixStats_1.4.1   \n#&gt; [46] hms_1.1.3            evaluate_1.0.1       rlang_1.1.4         \n#&gt; [49] Rcpp_1.0.13-1        glue_1.8.0           jsonlite_1.8.9      \n#&gt; [52] plyr_1.8.9           R6_2.5.1",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>La predizione bayesiana 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_mcmc_prediction.html#bibliografia",
    "href": "chapters/mcmc/06_mcmc_prediction.html#bibliografia",
    "title": "56  La predizione bayesiana 🔸",
    "section": "Bibliografia",
    "text": "Bibliografia",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>La predizione bayesiana 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html",
    "href": "chapters/mcmc/07_bayesian_workflow.html",
    "title": "57  Flusso di lavoro bayesiano",
    "section": "",
    "text": "57.1 Introduzione\nL’applicazione dell’inferenza bayesiana nella risoluzione di problemi reali richiede un approccio strutturato e multidisciplinare, noto come workflow bayesiano. Questo processo iterativo e complesso va ben oltre la semplice applicazione della regola di Bayes, che pur costituendo il fondamento teorico dell’inferenza bayesiana, rappresenta solo il punto di partenza di un percorso analitico più articolato.\nIl workflow bayesiano include molteplici fasi interconnesse, tra cui:\nPer esempio, immaginiamo di voler valutare l’efficacia di un intervento psicologico. Il ricercatore deve affrontare diverse decisioni: quali variabili includere (covariate), come modellare i dati gerarchici (ad esempio, individui e gruppi), e quali distribuzioni utilizzare per rappresentare incertezze (priori). Queste decisioni, lungi dall’essere definitive, richiedono continui aggiustamenti basati sui risultati intermedi.\nUn ulteriore aspetto critico è la gestione di possibili problemi computazionali. Ad esempio, il campionamento MCMC (Markov Chain Monte Carlo) potrebbe non convergere correttamente, richiedendo modifiche al modello o all’approccio algoritmico. Inoltre, il workflow bayesiano non si limita alla stima dei parametri: include la valutazione della capacità del modello di fare previsioni attendibili e il confronto tra modelli alternativi.\nInfine, è fondamentale bilanciare la complessità del modello con la rilevanza pratica dei risultati. Modelli troppo semplici possono portare a conclusioni distorte, mentre modelli troppo complessi possono diventare difficili da interpretare. Il workflow bayesiano aiuta i ricercatori a navigare queste sfide, fornendo un quadro metodologico flessibile e iterativo.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html#introduzione",
    "href": "chapters/mcmc/07_bayesian_workflow.html#introduzione",
    "title": "57  Flusso di lavoro bayesiano",
    "section": "",
    "text": "Costruzione iterativa del modello: Definizione e revisione di modelli probabilistici che rappresentano i processi generativi dei dati.\nVerifica e validazione: Controllo della qualità delle stime e valutazione delle capacità predittive del modello.\nRisultati e interpretazione: Confronto tra modelli alternativi per trarre conclusioni solide.\nGestione di problemi computazionali: Identificazione e soluzione di eventuali difficoltà nell’adattamento del modello.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html#principi-del-workflow-bayesiano",
    "href": "chapters/mcmc/07_bayesian_workflow.html#principi-del-workflow-bayesiano",
    "title": "57  Flusso di lavoro bayesiano",
    "section": "57.2 Principi del workflow bayesiano",
    "text": "57.2 Principi del workflow bayesiano\nUn workflow è una sequenza strutturata di passi che definisce cosa costituisce una “buona pratica” in un determinato ambito. Nel contesto dell’inferenza bayesiana, il workflow si ispira a concetti come il Ciclo di Box e le più recenti estensioni proposte da studiosi come Gelman e Riha.\n\n57.2.1 Il Ciclo di Box\nGeorge Box, uno dei pionieri della statistica moderna, ha sviluppato negli anni ’60 un approccio ciclico alla modellizzazione statistica, noto come Ciclo di Box. Questo paradigma sottolinea che la modellizzazione non è un processo lineare, ma un ciclo continuo di miglioramento.\n\n\n\nFigura tratta da Blei (2014).\n\n\nIl Ciclo di Box si articola in una serie di fasi iterative:\n\nFormulazione del modello: Si costruisce un modello basato sulle conoscenze disponibili e sui dati osservati.\nInferenza: Si stimano i parametri del modello e si valutano le incertezze associate.\nValutazione del modello: Si verifica quanto il modello si adatta ai dati.\nRevisione del modello: Si corregge il modello in base alle discrepanze identificate.\n\nQuesto approccio iterativo è il cuore del workflow bayesiano. La capacità dell’inferenza bayesiana di aggiornare le credenze a priori alla luce di nuovi dati lo rende particolarmente adatto a essere integrato nel Ciclo di Box. Più recentemente, Gelman et al. (2020) hanno proposto una versione estesa del Ciclo di Box, fornendo una guida dettagliata per implementare un workflow bayesiano completo.\n\n\n\nFigura tratta da Gelman et al. (2020).",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html#costruzione-iterativa-del-modello",
    "href": "chapters/mcmc/07_bayesian_workflow.html#costruzione-iterativa-del-modello",
    "title": "57  Flusso di lavoro bayesiano",
    "section": "57.3 Costruzione iterativa del modello",
    "text": "57.3 Costruzione iterativa del modello\nIl processo di costruzione di un modello bayesiano può essere descritto attraverso i seguenti passaggi:\n\nComprensione del fenomeno e formulazione del problema: Il punto di partenza è definire chiaramente la domanda di ricerca. L’obiettivo non è semplicemente descrivere correlazioni tra variabili, ma comprendere i meccanismi generativi dei dati.\nFormulazione matematica: Si costruisce un modello probabilistico che rappresenti il processo generativo, spesso utilizzando linguaggi probabilistici (PPL) come Stan o PyMC.\nImplementazione: Il modello viene tradotto in codice utilizzando interfacce software come R, Python o Julia, che permettono di adattare modelli complessi ai dati.\nVerifiche predittive a priori: Si simulano dati basandosi sulle distribuzioni a priori per verificare che i parametri scelti siano ragionevoli.\nAdattamento del modello: Si utilizza un algoritmo di campionamento per stimare i parametri del modello dai dati osservati (ad esempio, cmdstanr o cmdstanpy).\nDiagnostiche di convergenza: Si verifica che le catene MCMC abbiano raggiunto la convergenza, utilizzando strumenti come il valore R-hat.\nVerifiche predittive a posteriori: Si generano dati simulati a partire dalla distribuzione a posteriori per confrontarli con i dati reali e valutare la bontà del modello.\nIterazione: Sulla base dei risultati, il modello viene raffinato e migliorato.\n\nQuesto processo iterativo consente di costruire modelli che siano sia robusti sia interpretabili.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html#analisi-multiverso",
    "href": "chapters/mcmc/07_bayesian_workflow.html#analisi-multiverso",
    "title": "57  Flusso di lavoro bayesiano",
    "section": "57.4 Analisi Multiverso",
    "text": "57.4 Analisi Multiverso\nL’analisi multiverso, introdotta recentemente (Riha et al., 2024), amplia il workflow bayesiano, permettendo di esplorare simultaneamente molteplici modelli alternativi. Ogni modello rappresenta una combinazione unica di scelte modellistiche (ad esempio, covariate, distribuzioni a priori, o assunzioni sul processo generativo).\nI vantaggi principali dell’analisi multiverso includono:\n\nTrasparenza: Documenta tutte le scelte di modellizzazione.\nEsplorazione completa: Riduce il rischio di trascurare ipotesi rilevanti.\nConfronto diretto: Permette di identificare i modelli più adatti basandosi su criteri come l’Expected Log-Predictive Density (ELPD).\nRobustezza: Esamina come le conclusioni cambiano tra diversi modelli.\nReplicabilità: Fornisce informazioni dettagliate per riprodurre l’analisi e i risultati.\n\nQuesto approccio incorpora anche verifiche computazionali e analisi di sensibilità. Le prime identificano i modelli che necessitano di ulteriori verifiche per garantire l’affidabilità dei risultati, mentre le seconde esaminano la robustezza delle conclusioni rispetto alle diverse scelte di modellazione e all’influenza delle priori sulle stime posteriori.\nTuttavia, la generazione di numerosi modelli può complicare la gestione e l’interpretazione dei risultati. Per affrontare questa sfida, Riha et al. (2024) propongono un metodo di “iterative filtering” che comprende:\n\nCreazione di un multiverso iniziale di modelli.\nValutazione delle capacità predittive attraverso controlli predittivi posteriori (PPC) e calcolo dell’expected log point-wise predictive density (elpd).\nVerifica della qualità computazionale, esaminando convergenza ed efficienza del campionamento MCMC.\nFiltraggio iterativo basato su criteri di qualità predefiniti.\nPossibilità di estendere il multiverso e ripetere il processo.\n\nQuesto approccio mantiene i vantaggi della multiverse analysis riducendo al contempo la complessità attraverso un filtraggio sistematico. Il risultato è un workflow bayesiano più robusto e informativo, che bilancia la necessità di considerare molteplici ipotesi modellistiche con l’esigenza pratica di focalizzarsi sui modelli più promettenti per il problema in esame.\nUno dei casi di studio esaminati da Riha et al. (2024) riguarda l’analisi del numero di crisi epilettiche in relazione a diverse variabili (covariate) e scelte di modellazione. I dati utilizzati provengono dallo studio di Leppik et al. (1987) e sono disponibili nel pacchetto R brms.\nSono stati confrontati 24 modelli statistici, ciascuno con una specifica formulazione matematica (illustrata nella Tabella seguente). La scelta dei modelli ha riguardato diverse combinazioni di covariate e di distribuzioni di probabilità per descrivere il fenomeno in esame.\n\n\n\nTabella 1 ricavata da Riha et al. (2024).\n\n\nPer valutare la capacità predittiva dei modelli, è stato utilizzato il criterio ELPD (Expected Log-Predictive Density). I risultati sono riportati nel grafico seguente.\n\n\n\nFigura 12 ricavata da Riha et al. (2024).\n\n\nCome si può osservare, i modelli presentano performance predittive differenti.\nOltre all’ELPD, sono stati condotti controlli predittivi posteriori (PPC) per valutare la plausibilità dei modelli rispetto ai dati osservati. I risultati dei PPC sono visualizzati nella figura seguente.\n\n\n\nFigura 13 ricavata da Riha et al. (2024).\n\n\nIl modello selezionato è quello che ha mostrato il miglior valore di ELPD, evidenziando una buona capacità predittiva. Inoltre, i controlli PPC hanno confermato la plausibilità del modello rispetto ai dati osservati. Infine, il modello selezionato non ha presentato problemi computazionali durante la stima dei parametri.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html#riflessioni-conclusive",
    "href": "chapters/mcmc/07_bayesian_workflow.html#riflessioni-conclusive",
    "title": "57  Flusso di lavoro bayesiano",
    "section": "57.5 Riflessioni Conclusive",
    "text": "57.5 Riflessioni Conclusive\nIl workflow bayesiano rappresenta una strategia strutturata e iterativa per affrontare l’analisi dei dati complessi. Attraverso strumenti come le verifiche predittive e l’analisi multiverso, consente di sviluppare modelli solidi e capaci di adattarsi a nuovi dati e conoscenze. La sua integrazione con linguaggi come Stan o PyMC ne facilita l’applicazione, rendendolo un approccio essenziale per la ricerca moderna.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html#bibliografia",
    "href": "chapters/mcmc/07_bayesian_workflow.html#bibliografia",
    "title": "57  Flusso di lavoro bayesiano",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlei, D. M. (2014). Build, compute, critique, repeat: Data analysis with latent variable models. Annual Review of Statistics and Its Application, 1(1), 203–232.\n\n\nBulbulia, J. A. (2023). A workflow for causal inference in cross-cultural psychology. Religion, Brain & Behavior, 13(3), 291–306.\n\n\nGelman, A., Vehtari, A., Simpson, D., Margossian, C. C., Carpenter, B., Yao, Y., Kennedy, L., Gabry, J., Bürkner, P.-C., & Modrák, M. (2020). Bayesian workflow. arXiv preprint arXiv:2011.01808.\n\n\nLeppik, I., Dreifuss, F., Porter, R., Bowman, T., Santilli, N., Jacobs, M., Crosby, C., Cloyd, J., Stackman, J., Graves, N., et al. (1987). A controlled study of progabide in partial seizures: methodology and results. Neurology, 37(6), 963–963.\n\n\nRiha, A. E., Siccha, N., Oulasvirta, A., & Vehtari, A. (2024). Supporting Bayesian modelling workflows with iterative filtering for multiverse analysis. arXiv preprint arXiv:2404.01688.\n\n\nSteegen, S., Tuerlinckx, F., Gelman, A., & Vanpaemel, W. (2016). Increasing transparency through a multiverse analysis. Perspectives on Psychological Science, 11(5), 702–712.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/18_cmdstanr_intro.html",
    "href": "chapters/mcmc/18_cmdstanr_intro.html",
    "title": "58  Introduzione a CmdStanR 🔸",
    "section": "",
    "text": "58.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nPreparazione del Notebook\nRiprendiamo l’analisi dei dati fittizi di un compito Go/No-go, in cui sono state registrate 6 risposte corrette su 9 prove, già discussa in precedenza. In questa sezione, utilizzeremo il pacchetto cmdstanr in R, invece di cmdstanpy in Python, per eseguire l’analisi. L’obiettivo di questo capitolo è mostrare come utilizzare CmdStan attraverso il linguaggio R, offrendo un’alternativa all’uso di Python.\nIn R, i dati vengono salvati in una lista, che equivale a un dizionario in Python.\ndata_list &lt;- list(\n    \"N\" = 9,\n    \"y\" = 6\n)\nSuccessivamente, specifichiamo il percorso del file contenente lo script Stan. È importante notare che lo script Stan rimane identico indipendentemente dall’interfaccia utilizzata, sia essa R o Python.\nfile &lt;- file.path(here::here(\"stan\", \"go_nogo_model.stan\"))\nfile\n\n[1] \"/Users/corradocaudek/_repositories/psicometria-r/stan/go_nogo_model.stan\"",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>Introduzione a CmdStanR 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/18_cmdstanr_intro.html#compilazione-del-modello",
    "href": "chapters/mcmc/18_cmdstanr_intro.html#compilazione-del-modello",
    "title": "58  Introduzione a CmdStanR 🔸",
    "section": "\n58.2 Compilazione del modello",
    "text": "58.2 Compilazione del modello\nPer compilare il modello, utilizziamo la funzione cmdstan_model(), che crea un nuovo oggetto CmdStanModel a partire da un file contenente un programma Stan.\n\nmod &lt;- cmdstan_model(file)\n\nDopo aver compilato il modello, possiamo stamparne le informazioni.\n\nmod$print()\n\ndata {\n  int&lt;lower=1&gt; N;\n  int&lt;lower=0&gt; y;\n}\nparameters {\n  real&lt;lower=0, upper=1&gt; p;\n}\nmodel {\n  y ~ binomial(N, p); // Likelihood\n  p ~ beta(1, 1); // Prior\n}\ngenerated quantities {\n  int&lt;lower=0, upper=1&gt; p_gt_chance = p &gt; 0.5;\n}",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>Introduzione a CmdStanR 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/18_cmdstanr_intro.html#esecuzione-dellalgoritmo-mcmc",
    "href": "chapters/mcmc/18_cmdstanr_intro.html#esecuzione-dellalgoritmo-mcmc",
    "title": "58  Introduzione a CmdStanR 🔸",
    "section": "\n58.3 Esecuzione dell’algoritmo MCMC",
    "text": "58.3 Esecuzione dell’algoritmo MCMC\nIl metodo $sample() sugli oggetti CmdStanModel esegue l’algoritmo MCMC predefinito di Stan. L’argomento data accetta una lista di oggetti R con nomi specificati.\n\nfit &lt;- mod$sample(\n    data = data_list,\n    seed = 123,\n    chains = 4,\n    parallel_chains = 4\n)",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>Introduzione a CmdStanR 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/18_cmdstanr_intro.html#statistiche-riassuntive-del-posterior",
    "href": "chapters/mcmc/18_cmdstanr_intro.html#statistiche-riassuntive-del-posterior",
    "title": "58  Introduzione a CmdStanR 🔸",
    "section": "\n58.4 Statistiche riassuntive del posterior",
    "text": "58.4 Statistiche riassuntive del posterior\nIl metodo $summary() chiama la funzione summarise_draws() dal pacchetto posterior. Il primo argomento specifica le variabili da riassumere, e gli argomenti successivi sono passati a posterior::summarise_draws() per specificare quali statistiche calcolare, l’uso di più core, ecc.\n\nfit$summary(variables = c(\"p\"))\n\n# A tibble: 1 × 10\n  variable  mean median    sd   mad    q5   q95  rhat ess_bulk ess_tail\n  &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 p        0.636  0.647 0.141 0.148 0.389 0.854  1.00    1372.    1351.\n\n\nÈ possibile utilizzare una formula per riassumere funzioni arbitrarie, come ad esempio la probabilità che \\(p\\) sia minore o uguale a 0.5.\n\nfit$summary(\"p\", pr_lt_half = ~ mean(. &lt;= 0.5))\n\n# A tibble: 1 × 2\n  variable pr_lt_half\n  &lt;chr&gt;         &lt;dbl&gt;\n1 p             0.176",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>Introduzione a CmdStanR 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/18_cmdstanr_intro.html#estrazione-dei-campioni-posteriori",
    "href": "chapters/mcmc/18_cmdstanr_intro.html#estrazione-dei-campioni-posteriori",
    "title": "58  Introduzione a CmdStanR 🔸",
    "section": "\n58.5 Estrazione dei campioni posteriori",
    "text": "58.5 Estrazione dei campioni posteriori\n\n58.5.1 Estrazione dei campioni\nIl metodo $draws() può essere utilizzato per estrarre i campioni posteriori in formati supportati dal pacchetto posterior. Qui dimostriamo i formati draws_array e draws_df.\n\n# default is a 3-D draws_array object from the posterior package\n# iterations x chains x variables\ndraws_arr &lt;- fit$draws() # or format=\"array\"\nstr(draws_arr)\n\n 'draws_array' num [1:1000, 1:4, 1:3] -7.21 -8.34 -9.16 -7.22 -7.21 ...\n - attr(*, \"dimnames\")=List of 3\n  ..$ iteration: chr [1:1000] \"1\" \"2\" \"3\" \"4\" ...\n  ..$ chain    : chr [1:4] \"1\" \"2\" \"3\" \"4\"\n  ..$ variable : chr [1:3] \"lp__\" \"p\" \"p_gt_chance\"\n\n\nOppure, possiamo usare as_draws_df() per creare un data frame:\n\ndraws &lt;- as_draws_df(fit)\nhead(draws)\n\n# A draws_df: 6 iterations, 1 chains, and 3 variables\n  lp__    p p_gt_chance\n1 -7.2 0.63           1\n2 -8.3 0.41           0\n3 -9.2 0.34           0\n4 -7.2 0.66           1\n5 -7.2 0.63           1\n6 -7.2 0.64           1\n# ... hidden reserved variables {'.chain', '.iteration', '.draw'}\n\n\nLo stesso risultato si ottiene nel modo seguente:\n\ndraws_df &lt;- as_draws_df(draws_arr)\nhead(draws_df)\n\n# A draws_df: 6 iterations, 1 chains, and 3 variables\n  lp__    p p_gt_chance\n1 -7.2 0.63           1\n2 -8.3 0.41           0\n3 -9.2 0.34           0\n4 -7.2 0.66           1\n5 -7.2 0.63           1\n6 -7.2 0.64           1\n# ... hidden reserved variables {'.chain', '.iteration', '.draw'}\n\n\nUna volta creato un data frame, possiamo facilmente calcolare le statistiche descrittive. Per esempio:\n\ndraws_df$p |&gt;\n    mean()\n\n[1] 0.6364032\n\n\nIn questo modo possiamo calcolare la probabilità che, ad esempio, \\(p\\) sia compreso tra 0.5 e 0.75:\n\ndraws_df |&gt;\n    summarise(\n        p_between_0.5_and_0.75 = mean(p &gt; 0.5 & p &lt; 0.75)\n    )\n\n# A tibble: 1 × 1\n  p_between_0.5_and_0.75\n                   &lt;dbl&gt;\n1                  0.595\n\n\n\npartion_vector &lt;- c(\"italic(p)&lt;0.5\", \"{0.5&lt;italic(p)}&lt;0.75\", \"lower~80*'%'\", \"middle~80*'%'\")\n\ndraws_df |&gt;\n    mutate(\n        `italic(p)&lt;0.5` = p &lt; 0.5,\n        `{0.5&lt;italic(p)}&lt;0.75` = p &gt; 0.5 & p &lt; 0.75,\n        `lower~80*'%'` = p &lt; quantile(p, probs = 0.8),\n        `middle~80*'%'` = p &gt; quantile(p, probs = 0.1) & p &lt; quantile(p, probs = 0.9)\n    ) |&gt;\n    pivot_longer(cols = `italic(p)&lt;0.5`:`middle~80*'%'`) |&gt;\n    mutate(name = factor(name, levels = partion_vector)) |&gt;\n    ggplot(aes(x = p, fill = value)) +\n    geom_histogram(boundary = 0, binwidth = 0.01) +\n    scale_x_continuous(expression(proportion ~ water ~ (italic(p))), limits = 0:1) +\n    scale_y_continuous(NULL, breaks = NULL) +\n    scale_fill_viridis_d(end = 0.6, breaks = NULL) +\n    facet_wrap(~name, labeller = label_parsed)\n\nWarning: Dropping 'draws_df' class as required metadata was removed.\n\n\n\n\n\n\n\n\n\n58.5.2 Visualizzazione dei campioni\nVisualizzare le distribuzioni posteriori è semplice: basta passare l’oggetto restituito dal metodo $draws() direttamente alle funzioni di plotting del pacchetto bayesplot.\n\nmcmc_hist(fit$draws(\"p\"))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>Introduzione a CmdStanR 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/18_cmdstanr_intro.html#diagnostica-del-campionatore",
    "href": "chapters/mcmc/18_cmdstanr_intro.html#diagnostica-del-campionatore",
    "title": "58  Introduzione a CmdStanR 🔸",
    "section": "\n58.6 Diagnostica del campionatore",
    "text": "58.6 Diagnostica del campionatore\nIl metodo $sampler_diagnostics() estrae i valori dei parametri del campionatore (come treedepth__, divergent__, ecc.) in formati supportati dal pacchetto posterior.\n\nstr(fit$sampler_diagnostics(format = \"df\"))\n\ndraws_df [4,000 × 9] (S3: draws_df/draws/tbl_df/tbl/data.frame)\n $ treedepth__  : num [1:4000] 2 1 1 2 1 2 2 1 1 2 ...\n $ divergent__  : num [1:4000] 0 0 0 0 0 0 0 0 0 0 ...\n $ energy__     : num [1:4000] 7.21 8.57 9.3 9.06 7.23 ...\n $ accept_stat__: num [1:4000] 1 0.762 0.816 1 0.999 ...\n $ stepsize__   : num [1:4000] 0.937 0.937 0.937 0.937 0.937 ...\n $ n_leapfrog__ : num [1:4000] 3 3 1 3 3 3 3 1 1 3 ...\n $ .chain       : int [1:4000] 1 1 1 1 1 1 1 1 1 1 ...\n $ .iteration   : int [1:4000] 1 2 3 4 5 6 7 8 9 10 ...\n $ .draw        : int [1:4000] 1 2 3 4 5 6 7 8 9 10 ...\n\n\n\nfit$diagnostic_summary()\n\n$num_divergent\n[1] 0 0 0 0\n\n$num_max_treedepth\n[1] 0 0 0 0\n\n$ebfmi\n[1] 1.1950436 0.9774677 1.2009506 0.9659775\n\n\nQuesto processo consente di esaminare in dettaglio le prestazioni del campionatore e di verificare eventuali problemi o inefficienze durante l’esecuzione del modello.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>Introduzione a CmdStanR 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/18_cmdstanr_intro.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/18_cmdstanr_intro.html#informazioni-sullambiente-di-sviluppo",
    "title": "58  Introduzione a CmdStanR 🔸",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n\nR version 4.4.2 (2024-10-31)\nPlatform: aarch64-apple-darwin20\nRunning under: macOS Sequoia 15.2\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n\nlocale:\n[1] C/UTF-8/C/C/C/C\n\ntime zone: Europe/Rome\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] here_1.0.1          bayesplot_1.11.1    posterior_1.6.0    \n [4] cmdstanr_0.8.1.9000 lubridate_1.9.4     forcats_1.0.0      \n [7] stringr_1.5.1       dplyr_1.1.4         purrr_1.0.2        \n[10] readr_2.1.5         tidyr_1.3.1         tibble_3.2.1       \n[13] ggplot2_3.5.1       tidyverse_2.0.0    \n\nloaded via a namespace (and not attached):\n [1] tensorA_0.36.2.1     utf8_1.2.4           generics_0.1.3      \n [4] stringi_1.8.4        hms_1.1.3            digest_0.6.37       \n [7] magrittr_2.0.3       evaluate_1.0.1       grid_4.4.2          \n[10] timechange_0.3.0     fastmap_1.2.0        plyr_1.8.9          \n[13] rprojroot_2.0.4      jsonlite_1.8.9       processx_3.8.4      \n[16] backports_1.5.0      ps_1.8.1             viridisLite_0.4.2   \n[19] scales_1.3.0         abind_1.4-8          cli_3.6.3           \n[22] rlang_1.1.4          munsell_0.5.1        withr_3.0.2         \n[25] yaml_2.3.10          tools_4.4.2          reshape2_1.4.4      \n[28] tzdb_0.4.0           checkmate_2.3.2      colorspace_2.1-1    \n[31] vctrs_0.6.5          R6_2.5.1             matrixStats_1.4.1   \n[34] lifecycle_1.0.4      htmlwidgets_1.6.4    pkgconfig_2.0.3     \n[37] pillar_1.10.0        gtable_0.3.6         Rcpp_1.0.13-1       \n[40] data.table_1.16.4    glue_1.8.0           xfun_0.49           \n[43] tidyselect_1.2.1     knitr_1.49           farver_2.1.2        \n[46] htmltools_0.5.8.1    labeling_0.4.3       rmarkdown_2.29      \n[49] compiler_4.4.2       distributional_0.5.0",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>Introduzione a CmdStanR 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/introduction_linear_models.html",
    "href": "chapters/linear_models/introduction_linear_models.html",
    "title": "Introduzione",
    "section": "",
    "text": "Gli obiettivi di questo insegnamento riguardano i casi più semplici di inferenza statistica, cioè l’inferenza su una singola media, la differenza tra due medie, e l’analisi del modello di regressione lineare (bivariato e multiplo) con predittori sia quantitativi sia qualitativi.\nTradizionalmente, l’inferenza su una media o sulla differenza tra due medie viene affrontata tramite il test t di Student, in un’ottica frequentista. In una prospettiva più moderna, tuttavia, questi argomenti possono essere inquadrati nel framework generale del modello lineare. Di conseguenza, in questa sezione della dispensa presenteremo il modello lineare sia dal punto di vista bayesiano sia frequentista, mostrando come l’inferenza su una o due medie rappresenti in realtà un caso particolare di questo impianto metodologico.",
    "crumbs": [
      "Regressione",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html",
    "href": "chapters/linear_models/01_reglin_frequentist.html",
    "title": "59  La regressione lineare bivariata: un approccio frequentista",
    "section": "",
    "text": "59.1 Introduzione\nLa regressione è un metodo fondamentale che consente ai ricercatori di riassumere come le previsioni o i valori medi di una variabile risultato (dipendente) variano in funzione di un insieme di predittori (indipendenti). Grazie alla sua versatilità, la regressione è utilizzata in un’ampia gamma di contesti, dai modelli predittivi alla valutazione degli effetti causali.\nSecondo Gelman et al. (2021), i principali utilizzi della regressione includono:\nIn tutti questi contesti, è cruciale che il modello includa tutte le variabili rilevanti. Ad esempio, in uno studio sull’efficacia di una terapia per la depressione, fattori come età, condizioni di salute preesistenti e supporto sociale devono essere inclusi nel modello per evitare conclusioni fuorvianti.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#introduzione",
    "href": "chapters/linear_models/01_reglin_frequentist.html#introduzione",
    "title": "59  La regressione lineare bivariata: un approccio frequentista",
    "section": "",
    "text": "Previsione: Modellare osservazioni esistenti o prevedere nuovi dati, sia continui che categoriali.\n\nAd esempio: prevedere punteggi futuri in un test, monitorare il benessere psicologico in uno studio longitudinale o classificare individui in base alla probabilità di successo in un compito cognitivo.\n\n\n\nEsplorazione delle associazioni: Quantificare il grado di relazione tra una o più variabili indipendenti e un risultato.\n\nAd esempio: studiare i tratti di personalità associati alla resilienza allo stress, analizzare la relazione tra stili di attaccamento infantile e capacità relazionali in età adulta, o valutare l’impatto di fattori socio-economici sullo sviluppo cognitivo nei bambini.\n\n\n\nEstrapolazione: Generalizzare i risultati osservati in un campione a una popolazione più ampia.\n\nAd esempio: stimare l’efficacia di una terapia testata su studenti universitari per la popolazione generale, oppure prevedere l’impatto di un intervento scolastico su un intero distretto partendo dai risultati osservati in alcune scuole.\n\n\n\nInferenza causale: Stimare gli effetti di un trattamento o intervento.\n\nAd esempio: valutare l’efficacia di un programma di mindfulness sui livelli di ansia, stimare l’impatto di una tecnica psicoterapeutica per il disturbo post-traumatico da stress o determinare l’effetto di un intervento educativo su una popolazione diversificata.\n\n\n\n\n\n\n59.1.1 Approccio frequentista\nI modelli lineari hanno una lunga storia nella statistica. Come riportato da Stigler (1986), il metodo dei minimi quadrati per adattare un modello di regressione lineare bivariata fu introdotto nel XVIII secolo per problemi di analisi dei dati in astronomia. Ad esempio, gli astronomi lo utilizzavano per determinare il moto della Luna o per modellare i movimenti non periodici di Giove e Saturno. In quel contesto, l’omogeneità dei dati raccolti direttamente dagli astronomi favorì l’adozione di questi metodi, in netto contrasto con le scienze sociali, dove la variabilità dei dati raccolti ritardava l’adozione della regressione.\n\n59.1.2 Il modello lineare bivariato\nNel contesto frequentista, il modello di regressione lineare bivariata consente di predire una variabile continua \\(y\\) sulla base di un singolo predittore continuo \\(x\\). La relazione tra le due variabili è espressa dall’equazione della retta di regressione:\n\\[\ny_i = a + b x_i + e_i, \\quad i = 1, \\dots, n,\n\\tag{59.1}\\]\ndove:\n\n\n\\(a\\) è l’intercetta (valore atteso di \\(y\\) quando \\(x = 0\\)),\n\n\\(b\\) è la pendenza della retta (coefficiente di regressione, che misura il cambiamento atteso in \\(y\\) per unità di incremento in \\(x\\)),\n\n\\(e_i\\) è l’errore residuo (la differenza tra il valore osservato di \\(y_i\\) e il valore predetto dal modello).\n\n\n\n59.1.2.1 Aspetti principali\n\nStima dei coefficienti\nI coefficienti \\(a\\) e \\(b\\) vengono stimati mediante il metodo dei minimi quadrati, che minimizza la somma dei quadrati degli errori residui (\\(\\sum e_i^2\\)).\n\nInterpretazione dei coefficienti\n\n\n\\(a\\): rappresenta il valore medio previsto di \\(y\\) quando \\(x = 0\\).\n\n\n\\(b\\): indica la variazione media prevista in \\(y\\) per ogni unità di variazione in \\(x\\).\n\n\n\nValutazione del modello\nLa bontà di adattamento del modello viene valutata attraverso:\n\nL’indice di determinazione (\\(R^2\\)), che misura la proporzione della varianza di \\(y\\) spiegata dal modello.\nL’analisi dei residui, che verifica la presenza di eventuali pattern non catturati dal modello.\n\n\n\n\nQuesto capitolo illustrerà come applicare e interpretare il modello di regressione bivariata, collegandolo successivamente al modello lineare multiplo e agli approcci più avanzati per l’inferenza causale.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#la-predizione-dellintelligenza",
    "href": "chapters/linear_models/01_reglin_frequentist.html#la-predizione-dellintelligenza",
    "title": "59  La regressione lineare bivariata: un approccio frequentista",
    "section": "\n59.2 La Predizione dell’Intelligenza",
    "text": "59.2 La Predizione dell’Intelligenza\nNella presente discussione, esamineremo i dati kidiq che consistono in una raccolta di dati provenienti da una survey su donne adulte americane e i loro figli, selezionati da un sotto-campione del National Longitudinal Survey of Youth (Gelman et al., 2021).\nNello specifico, ci concentreremo sulla relazione tra il punteggio di intelligenza del bambino (kid_score) e quello della madre (mom_iq). Ci proponiamo di valutare se e in quale misura l’intelligenza della madre possa prevedere l’intelligenza del bambino. Per fare ciò, inizieremo ad importare i dati nell’ambiente R.\n\n# Caricamento dei dati\nkidiq &lt;- rio::import(here::here(\"data\", \"kidiq.dta\"))\n\n\n# Anteprima dei dati\nhead(kidiq)\n#&gt;   kid_score mom_hs mom_iq mom_work mom_age\n#&gt; 1        65      1  121.1        4      27\n#&gt; 2        98      1   89.4        4      25\n#&gt; 3        85      1  115.4        4      27\n#&gt; 4        83      1   99.4        3      25\n#&gt; 5       115      1   92.7        4      27\n#&gt; 6        98      0  107.9        1      18\n\nUn diagramma a dispersione per i dati di questo campione suggerisce la presenza di un’associazione positiva tra l’intelligenza del bambino (kid_score) e l’intelligenza della madre (mom_iq).\n\nggplot(kidiq, aes(x = mom_iq, y = kid_score)) +\n  geom_point(alpha = 0.4) +\n  labs(x = \"QI della madre\", y = \"QI del bambino\") +\n  ggtitle(\"Diagramma a dispersione\")",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#stima-del-modello-di-regressione-lineare",
    "href": "chapters/linear_models/01_reglin_frequentist.html#stima-del-modello-di-regressione-lineare",
    "title": "59  La regressione lineare bivariata: un approccio frequentista",
    "section": "\n59.3 Stima del modello di regressione lineare",
    "text": "59.3 Stima del modello di regressione lineare\nCalcoliamo i coefficienti della retta di regressione utilizzando la funzione lm.\n\n# Modello di regressione lineare\nmod &lt;- lm(kid_score ~ mom_iq, data = kidiq)\n\n\n# Coefficienti stimati\ncoef(mod)\n#&gt; (Intercept)      mom_iq \n#&gt;       25.80        0.61\n\nCi sono però infinite rette che, in linea di principio, possono essere usate per “approssimare” la nube di punti nel diagramma a dispersione. È dunque necessario introdurre dei vincoli per selezionare una di queste possibili rette. Il vincolo che viene introdotto dal modello di regressione è quello di costringere la retta a passare per il punto \\((\\bar{x}, \\bar{y})\\).\n\n# Calcola le medie per mom_iq e kid_score\nmean_x &lt;- mean(kidiq$mom_iq, na.rm = TRUE)\nmean_y &lt;- mean(kidiq$kid_score, na.rm = TRUE)\n\n# Aggiungi il punto medio al grafico\nggplot(kidiq, aes(x = mom_iq, y = kid_score)) +\n  geom_point(alpha = 0.4) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"blue\") +\n  annotate(\n    \"point\", x = mean_x, y = mean_y, color = \"red\", size = 5, \n    shape = 4, stroke = 3) +\n  labs(x = \"QI della madre\", y = \"QI del bambino\") +\n  ggtitle(\"Retta di regressione\")\n#&gt; `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\nUna retta di regressione che passa per il punto medio \\((\\bar{x}, \\bar{y})\\) (che rappresenta il centro di massa dei dati) è preferibile dal punto di vista statistico poiché minimizza la somma dei quadrati degli errori residui.\nIl campione è costituito da \\(n\\) coppie di osservazioni (\\(x, y\\)).\n\\[\n\\begin{array}{cc}\n\\hline\nx_1 & y_1 \\\\\nx_2 & y_2 \\\\\nx_3 & y_3 \\\\\n\\vdots & \\vdots \\\\\nx_n & y_n \\\\\n\\hline\n\\end{array}\n\\]\nPer ciascuna coppia di valori \\(x_i, y_i\\), il modello di regressione si aspetta che il valore \\(y_i\\) sia associato al corrispondente valore \\(x_i\\) come indicato dalla seguente equazione\n\\[\n\\begin{equation}\n\\mathbb{E}(y_i) = a + b x_i ,\n\\end{equation}\n\\tag{59.2}\\]\novvero:\n\\[\n\\begin{array}{ccc}\n\\hline\nx_i & y_i & \\mathbb{E}(y_i) = a + b x_i \\\\\n\\hline\nx_1 & y_1 & a + b x_1 \\\\\nx_2 & y_2 & a + b x_2 \\\\\nx_3 & y_3 & a + b x_3 \\\\\n\\vdots & \\vdots & \\vdots \\\\\nx_n & y_n & a + b x_n \\\\\n\\hline\n\\end{array}\n\\]\nI valori \\(y_i\\) corrispondono, nell’esempio che stiamo discutendo, alla variabile kid_score. I primi 10 valori della variabile \\(y\\) sono i seguenti:\n\nkidiq$kid_score[0:10]\n#&gt;  [1]  65  98  85  83 115  98  69 106 102  95\n\nPer fare riferimento a ciascuna osservazione usiamo l’indice \\(i\\). Quindi, ad esempio, \\(y_2\\) è uguale a\n\nkidiq$kid_score[2]\n#&gt; [1] 98\n\nIl modello di regressione lineare bivariata, rappresentato dall’equazione \\(y_i = a + b x_i + e_i\\), descrive la relazione tra le variabili \\(x\\) e \\(y\\), dove \\(y\\) è la variabile dipendente (nel nostro esempio, la variabile kid_score) e \\(x\\) è la variabile indipendente (nel nostro esempio, la variabile mom_iq).\nIl valore di \\(y\\) è la somma di due componenti:\n\nla componente deterministica, \\(\\hat{y}_i = a + b x_i\\), rappresenta la porzione della \\(y\\) che è prevedibile conoscendo il valore di \\(x\\);\nla componente aleatoria, \\(e_i\\), rappresenta la porzione della \\(y\\) che non è prevedibile dal modello.\n\nIl modello lineare cerca di trovare i coefficienti \\(a\\) e \\(b\\) che permettono di prevedere la componente deterministica di \\(y\\) conoscendo il valore di \\(x\\). Tuttavia, poiché la retta è solo un’approssimazione della relazione tra \\(x\\) e \\(y\\), la componente deterministica rappresenta solo una stima approssimata della vera relazione tra le due variabili.\nPer valutare l’accuratezza del modello di regressione lineare, è necessario calcolare il residuo\n\\[\ne_i = y_i - (a + b x_i) ,\n\\tag{59.3}\\]\novvero la differenza tra il valore osservato di \\(y\\) e il valore previsto dal modello, \\(\\hat{y}\\). La dimensione del residuo indica quanto la componente aleatoria contribuisce al valore osservato di \\(y\\).\nIl modello di regressione lineare ha tre obiettivi (Fox, 2015):\n\nil primo è quello di trovare i coefficienti \\(a\\) e \\(b\\) che permettono di prevedere la componente deterministica di \\(y\\) conoscendo il valore di \\(x\\);\nil secondo obiettivo è quello di valutare l’accuratezza della predizione fornita dal modello di regressione lineare;\ninfine, il terzo obiettivo è quello dell’inferenza, ovvero quello di capire quali relazioni esistono tra la relazione tra \\(x\\) e \\(y\\) osservata nel campione e la relazione tra le due variabili nella popolazione.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#stima-dei-coefficienti-di-regressione",
    "href": "chapters/linear_models/01_reglin_frequentist.html#stima-dei-coefficienti-di-regressione",
    "title": "59  La regressione lineare bivariata: un approccio frequentista",
    "section": "\n59.4 Stima dei coefficienti di regressione",
    "text": "59.4 Stima dei coefficienti di regressione\nIn breve, stiamo cercando di descrivere una relazione tra due variabili, il QI della madre e il QI del bambino, utilizzando un modello di regressione lineare. L’equazione lineare che descrive la relazione tra le due variabili è della forma \\(\\hat{y}_i = a_i + bx_i\\), dove \\(\\hat{y}_i\\) rappresenta la previsione per il QI del bambino \\(i\\)-esimo, \\(a_i\\) e \\(b\\) sono i coefficienti di regressione che vogliamo trovare e \\(x_i\\) è il QI della madre del bambino \\(i\\)-esimo.\nPer trovare i coefficienti di regressione, dobbiamo introdurre dei vincoli per limitare lo spazio delle possibili soluzioni. Il primo vincolo è che la retta di regressione deve passare per il baricentro del grafico a dispersione. Il secondo vincolo è che vogliamo minimizzare la somma dei quadrati dei residui, ovvero la differenza tra il valore osservato e il valore previsto dal modello. I coefficienti di regressione che soddisfano questi vincoli si chiamano coefficienti dei minimi quadrati.\nIl problema di trovare i coefficienti di regressione \\(a\\) e \\(b\\) che minimizzano la somma dei quadrati dei residui ha una soluzione analitica. Questa soluzione si ottiene trovando il punto di minimo di una superficie tridimensionale che rappresenta la somma dei quadrati dei residui. Il punto di minimo è quello per cui il piano tangente alla superficie nelle due direzioni \\(a\\) e \\(b\\) è piatto, cioè le derivate parziali rispetto ad \\(a\\) e \\(b\\) sono uguali a zero. In pratica, ciò significa risolvere un sistema di equazioni lineari con due incognite \\(a\\) e \\(b\\), noto come equazioni normali.\nLa soluzione delle equazioni normali ci fornisce i coefficienti di regressione stimati, che minimizzano la somma dei quadrati dei residui. La formula per il coefficiente \\(a\\) è\n\\[\na = \\bar{y} - b \\bar{x} ,\n\\tag{59.4}\\]\nla formula per il coefficiente \\(b\\) è\n\\[\nb = \\frac{Cov(x, y)}{Var(x)},\n\\tag{59.5}\\]\ndove \\(\\bar{x}\\) e \\(\\bar{y}\\) sono le medie delle variabili \\(x\\) e \\(y\\), \\(Cov(x,y)\\) è la covarianza tra \\(x\\) e \\(y\\) e \\(Var(x)\\) è la varianza di \\(x\\).\nQueste equazioni rappresentano la stima dei minimi quadrati dei coefficienti di regressione che ci permettono di trovare la retta che minimizza la somma dei quadrati dei residui.\n\n59.4.1 Calcolo manuale dei coefficienti di regressione\nCalcoliamo i coefficientii dei minimi quadrati con l’Equazione 59.4 e l’Equazione 59.5:\n\n# Calcolo manuale dei coefficienti\ncov_xy &lt;- cov(kidiq$kid_score, kidiq$mom_iq)  # Covarianza tra le due variabili\nvar_x &lt;- var(kidiq$mom_iq)  # Varianza della variabile indipendente\nb &lt;- cov_xy / var_x  # Pendenza (coefficiente b)\nb\n#&gt; [1] 0.61\n\n\n# Intercetta (coefficiente a)\na &lt;- mean(kidiq$kid_score) - b * mean(kidiq$mom_iq)\na\n#&gt; [1] 25.8\n\nI risultati replicano quelli ottenuti in precedenza con lm().\n\n59.4.2 Interpretazione\nIl coefficiente \\(a\\) indica l’intercetta della retta di regressione nel diagramma a dispersione. Questo valore rappresenta il punto in cui la retta di regressione interseca l’asse \\(y\\) del sistema di assi cartesiani. Tuttavia, in questo caso specifico, il valore di \\(a\\) non è di particolare interesse poiché corrisponde al valore della retta di regressione quando l’intelligenza della madre è pari a 0, il che non ha senso nella situazione reale. Successivamente, vedremo come è possibile trasformare i dati per fornire un’interpretazione utile del coefficiente \\(a\\).\nInvece, il coefficiente \\(b\\) indica la pendenza della retta di regressione, ovvero di quanto aumenta (se \\(b\\) è positivo) o diminuisce (se \\(b\\) è negativo) la retta di regressione in corrispondenza di un aumento di 1 punto della variabile \\(x\\). Nel caso specifico del QI delle madri e dei loro figli, il coefficiente \\(b\\) ci indica che un aumento di 1 punto del QI delle madri è associato, in media, a un aumento di 0.61 punti del QI dei loro figli.\nIn pratica, il modello di regressione lineare cerca di prevedere le medie dei punteggi del QI dei figli in base al QI delle madri. Ciò significa che non è in grado di prevedere esattamente il punteggio di ciascun bambino in funzione del QI della madre, ma solo una stima della media dei punteggi dei figli quando il QI delle madri aumenta o diminuisce di un punto.\nIl coefficiente \\(b\\) ci dice di quanto aumenta (o diminuisce) in media il QI dei figli per ogni unità di aumento (o diminuzione) del QI della madre. Nel nostro caso, se il QI della madre aumenta di un punto, il QI dei figli aumenta in media di 0.61 punti.\nÈ importante comprendere che il modello statistico di regressione lineare non è in grado di prevedere il valore preciso di ogni singolo bambino, ma solo una stima della media dei punteggi del QI dei figli quando il QI delle madri aumenta o diminuisce. Questa stima è basata su una distribuzione di valori possibili che si chiama distribuzione condizionata \\(p(y \\mid x_i)\\).\nUna rappresentazione grafica del valore predetto dal modello di regressione, \\(\\hat{y}_i = a + bx_i\\) è stato fornito in precedenza. Il diagramma presenta ciascun valore \\(\\hat{y}_i = a + b x_i\\) in funzione di \\(x_i\\). I valori predetti dal modello di regressione sono i punti che stanno sulla retta di regressione.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#residui",
    "href": "chapters/linear_models/01_reglin_frequentist.html#residui",
    "title": "59  La regressione lineare bivariata: un approccio frequentista",
    "section": "\n59.5 Residui",
    "text": "59.5 Residui\nIn precedenza abbiamo detto che il residuo, ovvero la componente di ciascuna osservazione \\(y_i\\) che non viene predetta dal modello di regressione, corrisponde alla distanza verticale tra il valore \\(y_i\\) osservato e il valore \\(\\hat{y}_i\\) predetto dal modello di regressione:\n\\[\ne_i = y_i - (a + b x_i).\n\\]\nPer fare un esempio numerico, consideriamo il punteggio osservato del QI del primo bambino.\n\nkidiq$kid_score[1]\n#&gt; [1] 65\n\nIl QI della madre è\n\nkidiq$mom_iq[1]\n#&gt; [1] 121\n\nPer questo bambino, il valore predetto dal modello di regressione è\n\na + b * kidiq$mom_iq[1]\n#&gt; [1] 99.7\n\nL’errore che compiamo per predire il QI del bambino utilizzando il modello di regressione (ovvero, il residuo) è\n\nkidiq$kid_score[1] - (a + b * kidiq$mom_iq[1])\n#&gt; [1] -34.7\n\nPer tutte le osservazioni abbiamo\n\nres &lt;- kidiq$kid_score - (a + b * kidiq$mom_iq)\n\nÈ una proprietà del modello di regressione (calcolato con il metodo dei minimi quadrati) che la somma dei residui sia uguale a zero.\n\nsum(res)\n#&gt; [1] 1.44e-11\n\nQuesto significa che ogni valore osservato \\(y_i\\) viene scomposto dal modello di regressione in due componenti distinte. La componente deterministica \\(\\hat{y}_i\\), che è predicibile da \\(x_i\\), è data da \\(\\hat{y}_i = a + b x_i\\). Il residuo, invece, è dato da \\(e_i = y_i - \\hat{y}_i\\). La somma di queste due componenti, ovviamente, riproduce il valore osservato.\n\n# Creazione di un data frame con i valori calcolati\ndf &lt;- data.frame(\n  kid_score = kidiq$kid_score,\n  mom_iq = kidiq$mom_iq,\n  y_hat = a + b * kidiq$mom_iq,\n  e = kidiq$kid_score - (a + b * kidiq$mom_iq),\n  y_hat_plus_e = (a + b * kidiq$mom_iq) + (kidiq$kid_score - (a + b * kidiq$mom_iq))\n)\n\n# Visualizzazione dei primi 6 valori\nhead(df)\n#&gt;   kid_score mom_iq y_hat      e y_hat_plus_e\n#&gt; 1        65  121.1  99.7 -34.68           65\n#&gt; 2        98   89.4  80.3  17.69           98\n#&gt; 3        85  115.4  96.2 -11.22           85\n#&gt; 4        83   99.4  86.5  -3.46           83\n#&gt; 5       115   92.7  82.4  32.63          115\n#&gt; 6        98  107.9  91.6   6.38           98",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#trasformazione-dei-dati",
    "href": "chapters/linear_models/01_reglin_frequentist.html#trasformazione-dei-dati",
    "title": "59  La regressione lineare bivariata: un approccio frequentista",
    "section": "\n59.6 Trasformazione dei dati",
    "text": "59.6 Trasformazione dei dati\nIn generale, per variabili a livello di scala ad intervalli, l’intercetta del modello di regressione lineare non ha un’interpretazione utile. Questo perché l’intercetta indica il valore atteso di \\(y\\) quando \\(x = 0\\), ma in caso di variabili a scala di intervalli, il valore “0” di \\(x\\) è arbitrario e non corrisponde ad un “assenza” della variabile \\(x\\). Ad esempio, un QI della madre pari a 0 non indica un’assenza di intelligenza, ma solo un valore arbitrario del test usato per misurare il QI. Quindi, sapere il valore medio del QI dei bambini quando il QI della madre è 0 non è di alcun interesse.\nPer fornire all’intercetta del modello di regressione un’interpretazione più utile, dobbiamo trasformare le osservazioni di \\(x\\). Per esempio, esprimiamo \\(x\\) come differenza dalla media. Chiamiamo questa nuova variabile \\(xd\\):\n\nkidiq$xd &lt;- kidiq$mom_iq - mean(kidiq$mom_iq)\n\nkidiq |&gt; \n  head()\n#&gt;   kid_score mom_hs mom_iq mom_work mom_age     xd\n#&gt; 1        65      1  121.1        4      27  21.12\n#&gt; 2        98      1   89.4        4      25 -10.64\n#&gt; 3        85      1  115.4        4      27  15.44\n#&gt; 4        83      1   99.4        3      25  -0.55\n#&gt; 5       115      1   92.7        4      27  -7.25\n#&gt; 6        98      0  107.9        1      18   7.90\n\nSe ora usiamo le coppie di osservazioni \\((xd_i, y_i)\\), il diagramma a dispersione assume la forma seguente.\n\n# Aggiungiamo una nuova variabile centrata (scarti dalla media)\nkidiq &lt;- kidiq %&gt;%\n  mutate(xd = mom_iq - mean(mom_iq))\n\n# Calcolo della retta di regressione\nb &lt;- cov(kidiq$xd, kidiq$kid_score) / var(kidiq$xd)\na &lt;- mean(kidiq$kid_score) - b * mean(kidiq$xd)\n\n# Grafico con ggplot2\nggplot(kidiq, aes(x = xd, y = kid_score)) +\n  geom_point(alpha = 0.4) +  # Punti del grafico\n  geom_abline(intercept = a, slope = b, color = \"blue\") +  # Retta di regressione\n  labs(\n    x = \"QI della madre (scarti dalla media)\", \n    y = \"QI del bambino\"\n  ) +\n  ggtitle(\"Retta di regressione sui dati centrati\")\n\n\n\n\n\n\n\nIn pratica, abbiamo spostato tutti i punti del grafico lungo l’asse delle \\(x\\), in modo tale che la media dei valori di \\(x\\) sia uguale a 0. Questo non ha cambiato la forma dei punti nel grafico, ma ha solo spostato l’origine dell’asse \\(x\\). La pendenza della linea di regressione tra \\(x\\) e \\(y\\) rimane la stessa, sia per i dati originali che per quelli trasformati. L’unica cosa che cambia è il valore dell’intercetta della linea di regressione, che ora ha un’interpretazione più significativa.\n\nfm1 &lt;- lm(kid_score ~ xd, data = kidiq)\ncoef(fm1)\n#&gt; (Intercept)          xd \n#&gt;       86.80        0.61\n\nL’intercetta rappresenta il punto in cui la retta di regressione incontra l’asse \\(y\\) nel diagramma a dispersione. Nel caso dei dati trasformati, abbiamo spostato la nube di punti lungo l’asse \\(x\\) di una quantità pari a \\(x - \\bar{x}\\), ma le relazioni spaziali tra i punti rimangono invariate. Pertanto, la pendenza della retta di regressione non cambia rispetto ai dati non trasformati. Tuttavia, il valore dell’intercetta viene influenzato dalla trasformazione. In particolare, poiché \\(xd = 0\\) corrisponde a \\(x = \\bar{x}\\) nei dati grezzi, l’intercetta del modello di regressione lineare calcolata sui dati trasformati corrisponde al valore atteso di \\(y\\) quando \\(x\\) assume il valore medio sulla scala dei dati grezzi. In altre parole, l’intercetta del modello di regressione lineare sui dati trasformati rappresenta il valore atteso del QI dei bambini corrispondente al QI medio delle madri.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#il-metodo-dei-minimi-quadrati",
    "href": "chapters/linear_models/01_reglin_frequentist.html#il-metodo-dei-minimi-quadrati",
    "title": "59  La regressione lineare bivariata: un approccio frequentista",
    "section": "\n59.7 Il metodo dei minimi quadrati",
    "text": "59.7 Il metodo dei minimi quadrati\nPer stimare i coefficienti \\(a\\) e \\(b\\), possiamo minimizzare la somma dei quadrati dei residui tra i valori osservati \\(y_i\\) e quelli previsti \\(a + b x_i\\).\nIniziamo con il creare una griglia per i valori di \\(b\\). Supponiamo che il valore di \\(a\\) sia noto (\\(a = 25.79978\\)). Usiamo R per creare una griglia di valori possibili per \\(b\\).\n\n# Griglia di valori per b\nb_grid &lt;- seq(0, 1, length.out = 1001)\na &lt;- 25.79978  # Intercetta nota\n\nDefiniamo ora una funzione che calcola la somma dei quadrati dei residui (\\(SSE\\)) per ciascun valore di \\(b\\).\n\n# Funzione per la somma dei quadrati dei residui\nsse &lt;- function(a, b, x, y) {\n  sum((y - (a + b * x))^2)\n}\n\nApplichiamo la funzione sse alla griglia di valori \\(b\\) per calcolare la somma dei quadrati dei residui per ogni valore di \\(b\\).\n\n# Calcolo di SSE per ciascun valore di b\nsse_vals &lt;- sapply(\n  b_grid, \n  function(b) sse(a, b, kidiq$mom_iq, kidiq$kid_score)\n)\n\n\n\nsapply:\n\nÈ una funzione di R che applica una funzione ad ogni elemento di un vettore (o lista) e restituisce i risultati in un vettore.\nQui, applica la funzione sse a ciascun valore di \\(b\\) contenuto in b_grid.\n\n\n\nfunction(b):\n\nÈ una funzione anonima definita al volo per specificare come calcolare \\(SSE\\) per ciascun valore di \\(b\\).\nAll’interno, viene chiamata la funzione sse(a, b, x, y) con i seguenti parametri:\n\n\na: il valore dell’intercetta (fissato in precedenza o noto).\n\nb: il valore corrente nella griglia b_grid.\n\nx: la variabile indipendente del dataset (kidiq$mom_iq).\n\ny: la variabile dipendente del dataset (kidiq$kid_score).\n\n\n\n\nIl risultato è un vettore, sse_vals, che contiene i valori di \\(SSE\\) corrispondenti a ciascun valore di \\(b\\) in b_grid.\n\nTracciamo un grafico che mostra la somma dei quadrati dei residui (\\(SSE\\)) in funzione dei valori di \\(b\\), evidenziando il minimo.\n\n# Identificazione del valore di b che minimizza SSE\nb_min &lt;- b_grid[which.min(sse_vals)]\n\n# Creazione del dataframe per ggplot\ndat &lt;- data.frame(b_grid = b_grid, sse_vals = sse_vals)\n\n# Genera il grafico\nggplot(dat, aes(x = b_grid, y = sse_vals)) +\n  geom_line(color = \"blue\", linewidth = 1) +  \n  annotate(\n    \"point\", x = b_min, y = min(sse_vals),\n    color = \"red\", size = 3\n  ) +  # Punto minimo\n  labs(\n    x = expression(paste(\"Possibili valori di \", hat(beta))),\n    y = \"Somma dei quadrati dei residui (SSE)\",\n    title = \"Minimizzazione dei residui quadratici\"\n  ) +\n  annotate(\n    \"text\", x = b_min, y = min(sse_vals), \n    label = expression(hat(beta)), color = \"red\", vjust = -1, hjust = 0.5\n  )\n#&gt; Warning in is.na(x): is.na() applicato ad un oggetto di tipo 'expression'\n#&gt; (ne lista, ne vettore)\n\n\n\n\n\n\n\nInfine, identifichiamo il valore di \\(b\\) che minimizza la somma dei quadrati dei residui.\n\nb_min\n#&gt; [1] 0.61\n\nCon questa simulazione, abbiamo stimato il coefficiente \\(b\\) minimizzando la somma dei quadrati dei residui.\nQuesto approccio può essere esteso per stimare simultaneamente entrambi i coefficienti (\\(a\\) e \\(b\\)) utilizzando metodi di ottimizzazione più avanzati, come optim in R.\n\noptim_result &lt;- optim(\n  par = c(a = 25, b = 0.5),  # Valori iniziali\n  fn = function(params) {\n    a &lt;- params[1]\n    b &lt;- params[2]\n    sse(a, b, kidiq$mom_iq, kidiq$kid_score)\n  }\n)\n\n# Coefficienti stimati\noptim_result$par\n#&gt;     a     b \n#&gt; 25.79  0.61\n\nQuesta simulazione illustra come, tramite il metodo dei minimi quadrati, sia possibile stimare i parametri di un modello bivariato di regressione.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#lerrore-standard-della-regressione",
    "href": "chapters/linear_models/01_reglin_frequentist.html#lerrore-standard-della-regressione",
    "title": "59  La regressione lineare bivariata: un approccio frequentista",
    "section": "\n59.8 L’errore standard della regressione",
    "text": "59.8 L’errore standard della regressione\nIl secondo obiettivo del modello di regressione lineare è quello di misurare quanto della variabilità di \\(y\\) possa essere spiegata dalla variabilità di \\(x\\) per ogni osservazione. L’indice di bontà di adattamento del modello viene fornito dalla deviazione standard dei residui, chiamata anche errore standard della stima (o errore standard della regressione), \\(s_e\\).\nPer calcolare \\(s_e\\), si sommano i quadrati dei residui \\(e_i\\) per ogni osservazione e si divide per \\(n-2\\), dove \\(n\\) rappresenta la numerosità del campione e \\(2\\) il numero di coefficienti stimati nel modello di regressione. Si prende poi la radice quadrata del risultato:\n\\[\n\\sqrt{\\frac{1}{n-2} \\sum_{i=1}^n \\big(y_i - (\\hat{a} + \\hat{b}x_i)\\big)^2},\n\\tag{59.6}\\]\nL’indice \\(s_e\\) possiede la stessa unità di misura di \\(y\\) ed è una stima della deviazione standard dei residui nella popolazione.\nIllustriamo il calcolo di \\(s_e\\) con i dati a disposizione. I residui \\(e\\) possono essere calcolati sottraendo ai valori osservati \\(y_i\\) i valori predetti dal modello \\(a + b x_i\\):\n\n# Calcolo dei residui\ne &lt;- kidiq$kid_score - (a + b * kidiq$mom_iq)\n\n# Mostriamo i primi 10 residui\nhead(e, 10)\n#&gt;  [1] -34.68  17.69 -11.22  -3.46  32.63   6.38 -41.52   3.86  26.41  11.21\n\nCalcoliamo il valore medio assoluto dei residui per avere un’indicazione della deviazione media rispetto alla retta di regressione.\n\n# Media assoluta dei residui\nmean(abs(e))\n#&gt; [1] 14.5\n\nL’errore standard della stima \\(s_e\\) si calcola come la radice quadrata della somma dei quadrati dei residui divisa per \\(n-2\\):\n\n# Calcolo di s_e\nse &lt;- sqrt(sum(e^2) / (length(e) - 2))\nse\n#&gt; [1] 18.3\n\nNotiamo che il valore medio assoluto dei residui e l’errore standard \\(s_e\\) non sono identici, ma hanno lo stesso ordine di grandezza. \\(s_e\\) è una misura più rigorosa della deviazione standard dei residui.\nQuesta analisi dimostra come \\(s_e\\) consenta di valutare quanto le previsioni del modello si discostino (in media) dai dati osservati.\n\n59.8.1 Sottostima dell’Errore nel Modello di Regressione\nCome discusso da Gelman et al. (2021), l’errore standard della regressione tende a sottostimare la vera deviazione standard \\(\\sigma\\) dell’errore nel modello di regressione nella popolazione. Questa sottostima è dovuta al fenomeno del sovradimensionamento, dato che i parametri \\(a\\) e \\(b\\) sono stimati utilizzando gli stessi \\(n\\) punti dati su cui vengono calcolati i residui. In altre parole, i residui non sono del tutto indipendenti dal modello.\nUn approccio alternativo per valutare l’errore predittivo e mitigare il problema del sovradimensionamento è la validazione incrociata. In particolare, l’approccio leave-one-out (LOOCV) offre una soluzione semplice ed efficace. Questo metodo consiste nell’adattare il modello \\(n\\) volte, escludendo ogni volta un punto dati, adattando il modello ai rimanenti \\(n-1\\) punti, e utilizzando tale modello per predire l’osservazione esclusa.\n\n59.8.1.1 Procedura Leave-One-Out:\n\n\nPer \\(i = 1, \\ldots, n\\):\n\nAdatta il modello \\(y = a + bx + \\text{errore}\\) ai \\(n-1\\) punti dati \\((x, y)_j, j \\neq i\\). Denomina i coefficienti stimati come \\(\\hat{a}_{-i}\\) e \\(\\hat{b}_{-i}\\).\n\nCalcola il residuo validato incrociato:\n\\[\ne_{\\text{CV}} = y_i - (\\hat{a}_{-i} + \\hat{b}_{-i} x_i).\n\\]\n\nSalva il residuo al quadrato per il calcolo successivo.\n\n\n\nCalcola infine la stima di \\(\\sigma_{\\text{CV}}\\) come:\n\\[\n\\sigma_{\\text{CV}} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n e_{\\text{CV}}^2}.\n\\]\n\n\n59.8.1.2 Applicazione Pratica:\nEcco un esempio applicato al modello che predice l’intelligenza del bambino (\\(\\texttt{kid\\_score}\\)) in funzione dell’intelligenza della madre (\\(\\texttt{mom\\_iq}\\)) utilizzando il dataset kidiq.\n\noptions(round = 5)\n\n# Array per salvare i residui validati incrociati\nresiduals_cv &lt;- numeric(nrow(kidiq))\n\n# Loop per la validazione incrociata leave-one-out\nfor (i in 1:nrow(kidiq)) {\n  # Dati di training escludendo l'i-esimo punto\n  train_data &lt;- kidiq[-i, ]\n  test_data &lt;- kidiq[i, ]\n  \n  # Addestramento del modello\n  model &lt;- lm(kid_score ~ mom_iq, data = train_data)\n  \n  # Predizione sull'i-esimo punto\n  y_pred &lt;- predict(model, newdata = test_data)\n  \n  # Calcolo del residuo validato incrociato\n  residual_cv &lt;- test_data$kid_score - y_pred\n  residuals_cv[i] &lt;- residual_cv^2\n}\n\n# Calcolo di sigma_cv\nsigma_cv &lt;- sqrt(mean(residuals_cv))\n\ncat(\"Stima di σ_CV:\", sigma_cv, \"\\n\")\n#&gt; Stima di σ_CV: 18.3\n\nCalcoliamo ora la stima tradizionale di \\(\\sigma\\) utilizzando il modello completo e confrontiamola con \\(\\sigma_{\\text{CV}}\\).\n\n# Modello completo\nfm2 &lt;- lm(kid_score ~ mom_iq, data = kidiq)\n\n# Stima tradizionale dell'errore standard della regressione\nres &lt;- summary(fm2)\ncat(\"Errore standard della regressione (tradizionale):\", res$sigma, \"\\n\")\n#&gt; Errore standard della regressione (tradizionale): 18.3\n\nNel caso analizzato, i valori stimati di \\(\\sigma_{\\text{CV}}\\) e \\(\\hat{\\sigma}_e\\) tradizionale possono risultare molto simili. Tuttavia, in generale, la stima di \\(\\sigma_{\\text{CV}}\\) tende a essere leggermente superiore, in quanto riflette meglio l’errore predittivo su dati non utilizzati per adattare il modello. Questo rende \\(\\sigma_{\\text{CV}}\\) una misura più robusta e conservativa dell’incertezza del modello.\nIn conclusione, la validazione incrociata, e in particolare l’approccio LOOCV, rappresenta uno strumento importante per valutare le performance predittive di un modello di regressione e per ottenere stime più affidabili della deviazione standard dell’errore.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#indice-di-determinazione",
    "href": "chapters/linear_models/01_reglin_frequentist.html#indice-di-determinazione",
    "title": "59  La regressione lineare bivariata: un approccio frequentista",
    "section": "\n59.9 Indice di determinazione",
    "text": "59.9 Indice di determinazione\nUn importante risultato dell’analisi di regressione riguarda la scomposizione della varianza della variabile dipendente \\(y\\) in due componenti: la varianza spiegata dal modello e la varianza residua. Questa scomposizione è descritta mediante l’indice di determinazione \\(R^2\\), che fornisce una misura della bontà di adattamento del modello ai dati del campione.\nPer una generica osservazione \\(x_i, y_i\\), la deviazione di \\(y_i\\) rispetto alla media \\(\\bar{y}\\) può essere espressa come la somma di due componenti: il residuo \\(e_i=y_i- \\hat{y}_i\\) e lo scarto di \\(\\hat{y}_i\\) rispetto alla media \\(\\bar{y}\\):\n\\[\ny_i - \\bar{y} = (y_i- \\hat{y}_i) + (\\hat{y}_i - \\bar{y}) = e_i + (\\hat{y}_i - \\bar{y}).\n\\]\nLa varianza totale di \\(y\\) può quindi essere scritta come:\n\\[\n\\sum_{i=1}^{n}(y_i - \\bar{y})^2 = \\sum_{i=1}^{n}(e_i + (\\hat{y}_i - \\bar{y}))^2.\n\\]\nSviluppando il quadrato e sommando, si ottiene:\n\\[\n\\sum_{i=1}^{n}(y_i - \\bar{y})^2 = \\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2 + \\sum_{i=1}^{n}(\\hat{y}_i - \\bar{y})^2.\n\\tag{59.7}\\]\nIl primo termine rappresenta la varianza residua, mentre il secondo termine rappresenta la varianza spiegata dal modello. Questa scomposizione della devianza va sotto il nome di teorema della scomposizione della devianza.\nL’indice di determinazione \\(R^2\\) è definito come il rapporto tra la varianza spiegata e la varianza totale:\n\\[\nR^2 = \\frac{\\sum_{i=1}^{n}(\\hat{y}_i - \\bar{y})^2}{\\sum_{i=1}^{n}(y_i - \\bar{y})^2}.\n\\tag{59.8}\\]\nQuesto indice varia tra 0 e 1 e indica la frazione di varianza totale di \\(y\\) spiegata dal modello di regressione lineare. Un valore alto di \\(R^2\\) indica che il modello di regressione lineare si adatta bene ai dati, in quanto una grande parte della varianza di \\(y\\) è spiegata dalla variabile indipendente \\(x\\).\nPer l’esempio in discussione, possiamo calcolare la devianza totale, la devianza spiegata e l’indice di determinazione \\(R^2\\) come segue:\nLa devianza totale misura la variabilità complessiva dei punteggi osservati \\(y\\) rispetto alla loro media:\n\n# Devianza totale\ndev_t &lt;- sum((kidiq$kid_score - mean(kidiq$kid_score))^2)\ndev_t\n#&gt; [1] 180386\n\nLa devianza spiegata misura la variabilità che il modello è in grado di spiegare, considerando i valori predetti \\(a + b x\\):\n\n# Devianza spiegata\ndev_r &lt;- sum(((a + b * kidiq$mom_iq) - mean(kidiq$kid_score))^2)\ndev_r\n#&gt; [1] 36249\n\nL’indice \\(R^2\\) è il rapporto tra la devianza spiegata e la devianza totale, e indica la frazione della variabilità totale che è spiegata dal modello di regressione:\n\n# Indice di determinazione\nR2 &lt;- dev_r / dev_t\nround(R2, 3)\n#&gt; [1] 0.201\n\nPer verificare i calcoli, utilizziamo il modello di regressione lineare in R e leggiamo \\(R^2\\) direttamente dal sommario del modello:\n\n# Modello di regressione lineare\nmod &lt;- lm(kid_score ~ mom_iq, data = kidiq)\n\n# Sommario del modello per leggere R^2\nsummary(mod)$r.squared\n#&gt; [1] 0.201\n\nIl risultato mostra che circa il 20% della variabilità nei punteggi del QI dei bambini è spiegabile conoscendo il QI delle madri. Questo significa che il modello cattura una porzione rilevante della relazione, ma lascia anche spazio a fattori non inclusi nel modello che influenzano il QI dei bambini.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#inferenza-sul-modello-di-regressione",
    "href": "chapters/linear_models/01_reglin_frequentist.html#inferenza-sul-modello-di-regressione",
    "title": "59  La regressione lineare bivariata: un approccio frequentista",
    "section": "\n59.10 Inferenza sul modello di regressione",
    "text": "59.10 Inferenza sul modello di regressione\nIl terzo obiettivo del modello di regressione è l’inferenza. Nell’approccio frequentista, l’inferenza viene effettuata calcolando la distribuzione campionaria dei parametri e gli intervalli di fiducia per i parametri. Ad esempio, se si vuole determinare se la pendenza della retta di regressione è maggiore di zero, si calcola l’intervallo di fiducia al 95% per il parametro \\(\\beta\\). Se l’intervallo non include lo zero e se il limite inferiore dell’intervallo è maggiore di zero, si conclude che c’è evidenza di un’associazione lineare positiva tra \\(x\\) e \\(y\\) con un grado di confidenza del 95%.1 Il prossimo capitolo spiegherà come effettuare l’inferenza sui coefficienti del modello di regressione lineare in un contesto bayesiano.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#riflessioni-conclusive",
    "href": "chapters/linear_models/01_reglin_frequentist.html#riflessioni-conclusive",
    "title": "59  La regressione lineare bivariata: un approccio frequentista",
    "section": "\n59.11 Riflessioni Conclusive",
    "text": "59.11 Riflessioni Conclusive\nIl modello lineare bivariato è uno strumento fondamentale nell’analisi delle relazioni tra due variabili e rappresenta una pietra miliare dell’approccio frequentista. Questo capitolo ha mostrato come il modello consenta di quantificare il grado di associazione tra una variabile indipendente \\(x\\) e una variabile dipendente \\(y\\), utilizzando una relazione lineare.\nGrazie all’approccio frequentista, abbiamo imparato a stimare i coefficienti \\(a\\) (intercetta) e \\(b\\) (pendenza) attraverso il metodo dei minimi quadrati, che minimizza la somma dei quadrati dei residui per trovare la retta che meglio approssima i dati osservati. Inoltre, l’indice di determinazione (\\(R^2\\)) ci ha permesso di valutare la bontà di adattamento del modello e di quantificare quanta parte della variabilità di \\(y\\) è spiegata dalla variabile \\(x\\).\nIn pratica, il modello lineare bivariato consente di rispondere a domande fondamentali, come:\n\nSe il valore della variabile indipendente aumenta o diminuisce, come si comporta la variabile dipendente?\nQual è l’intensità e il segno della relazione tra le due variabili?\n\nLa semplicità del modello lo rendono uno strumento utile non solo per descrivere e analizzare relazioni tra variabili, ma anche per effettuare previsioni. Pur limitandosi a un singolo predittore, il modello lineare bivariato fornisce una base per comprendere relazioni più complesse, come quelle coinvolgenti più variabili indipendenti (regressione multivariata).\nL’approccio frequentista offre una metodologia consolidata per stimare i parametri e valutare il modello, fornendo inferenze utili per analisi pratiche e decisioni informate. Con una solida comprensione di questi concetti, si è pronti a esplorare modelli lineari più complessi e a estendere queste tecniche a scenari più articolati.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/01_reglin_frequentist.html#informazioni-sullambiente-di-sviluppo",
    "title": "59  La regressione lineare bivariata: un approccio frequentista",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] broom_1.0.7      see_0.9.0        gridExtra_2.3    patchwork_1.3.0 \n#&gt;  [5] bayesplot_1.11.1 psych_2.4.12     scales_1.3.0     markdown_1.13   \n#&gt;  [9] knitr_1.49       lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1   \n#&gt; [13] dplyr_1.1.4      purrr_1.0.2      readr_2.1.5      tidyr_1.3.1     \n#&gt; [17] tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3       \n#&gt; [21] here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     Matrix_1.7-1      R.oo_1.27.0      \n#&gt; [13] rprojroot_2.0.4   jsonlite_1.8.9    R.utils_2.12.3    backports_1.5.0  \n#&gt; [17] mgcv_1.9-1        mnormt_2.1.1      cli_3.6.3         rlang_1.1.4      \n#&gt; [21] R.methodsS3_1.8.2 splines_4.4.2     munsell_0.5.1     withr_3.0.2      \n#&gt; [25] tools_4.4.2       parallel_4.4.2    tzdb_0.4.0        colorspace_2.1-1 \n#&gt; [29] pacman_0.5.1      vctrs_0.6.5       R6_2.5.1          lifecycle_1.0.4  \n#&gt; [33] htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.0     gtable_0.3.6     \n#&gt; [37] glue_1.8.0        haven_2.5.4       xfun_0.49         tidyselect_1.2.1 \n#&gt; [41] farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-166      labeling_0.4.3   \n#&gt; [45] rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#bibliografia",
    "href": "chapters/linear_models/01_reglin_frequentist.html#bibliografia",
    "title": "59  La regressione lineare bivariata: un approccio frequentista",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nCaudek, C., & Luccio, R. (2001). Statistica per psicologi (III rist. 2023, Vol. 11, p. 320). Laterza.\n\n\nFox, J. (2015). Applied regression analysis and generalized linear models. Sage publications.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other stories. Cambridge University Press.\n\n\nStigler, S. (1986). The History of Statistics. Belknap Harvard.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#footnotes",
    "href": "chapters/linear_models/01_reglin_frequentist.html#footnotes",
    "title": "59  La regressione lineare bivariata: un approccio frequentista",
    "section": "",
    "text": "Per un approfondimento sull’approccio frequentista alla regressione, si veda, per esempio, Caudek & Luccio (2001).↩︎",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_reglin_bayes.html",
    "href": "chapters/linear_models/02_reglin_bayes.html",
    "title": "60  Modello bayesiano di regressione lineare bivariata",
    "section": "",
    "text": "60.1 Introduzione\nIn questa sezione della dispensa, esploreremo il modello di regressione lineare bivariata bayesiano, confrontandolo con l’approccio frequentista.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_reglin_bayes.html#introduzione",
    "href": "chapters/linear_models/02_reglin_bayes.html#introduzione",
    "title": "60  Modello bayesiano di regressione lineare bivariata",
    "section": "",
    "text": "60.1.1 Modello di Regressione Bayesiano\nL’approccio bayesiano si distingue dai metodi dei minimi quadrati o della massima verosimiglianza, poiché combina le informazioni derivanti dai dati con conoscenze preesistenti, rappresentate da distribuzioni a priori. Questo processo produce distribuzioni a posteriori che aggiornano le credenze iniziali dopo l’osservazione dei dati, superando i limiti delle stime puntuali dei metodi classici.\nNel contesto di un modello lineare bayesiano, indichiamo con \\(y\\) la variabile di risposta, con \\(x\\) le variabili predittive, e con \\(i\\) l’indice delle osservazioni, da 1 al numero totale di dati.\n\n60.1.2 Verosimiglianza\nNel modello bayesiano bivariato, la relazione tra la variabile \\(y\\) e la variabile \\(x\\) è descritta dalla verosimiglianza:\n\\[\ny \\sim \\text{Normale}(\\alpha + \\beta x, \\sigma).\n\\]\nCiò implica che i valori osservati di \\(y\\) sono distribuiti attorno alla retta di regressione \\(\\alpha + \\beta x\\), con una deviazione standard \\(\\sigma\\). Ogni osservazione è quindi una combinazione lineare dell’intercetta \\(\\alpha\\), del coefficiente \\(\\beta\\) che moltiplica la variabile predittiva, e di un termine di errore distribuito normalmente.\n\n60.1.3 Distribuzioni a Priori\nPer definire il modello bayesiano, si specificano distribuzioni a priori per i parametri \\(\\alpha\\), \\(\\beta\\) e \\(\\sigma\\). Sebbene siano possibili prior uniformi, che esprimono una totale assenza di conoscenza iniziale, è preferibile adottare prior debolmente informativi per garantire maggiore robustezza. Per esempio:\n\\[\n\\alpha \\sim \\mathcal{N}(0, 2.5), \\quad \\beta \\sim \\mathcal{N}(0, 2.5), \\quad \\sigma \\sim \\text{Cauchy}(0, 2.5).\n\\]\nQueste distribuzioni riflettono ipotesi iniziali ragionevoli senza introdurre eccessiva informazione a priori.\n\n60.1.4 Distribuzioni a Posteriori\nLe distribuzioni a posteriori sono ottenute combinando la verosimiglianza dei dati con le distribuzioni a priori tramite il teorema di Bayes. Esse rappresentano lo stato aggiornato delle conoscenze sui parametri, integrando l’informazione empirica con le ipotesi iniziali. L’approccio bayesiano non si limita a fornire stime puntuali, ma restituisce una descrizione completa dell’incertezza associata ai parametri sotto forma di distribuzioni probabilistiche.\nNel contesto di un modello di regressione bivariata, le distribuzioni a posteriori dei parametri \\(\\alpha\\) (intercetta), \\(\\beta\\) (coefficiente angolare), e \\(\\sigma\\) (deviazione standard residua) vengono stimate utilizzando algoritmi MCMC (Markov Chain Monte Carlo). Questi algoritmi consentono di campionare iterativamente dalle distribuzioni a posteriori, garantendo una stima accurata anche in modelli complessi.\nNella sezione successiva, esploreremo come utilizzare la funzione brm() del pacchetto brms per implementare un modello di regressione bayesiano e ottenere le stime a posteriori, analizzandone le proprietà e le implicazioni.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_reglin_bayes.html#adattare-una-retta-di-regressione-a-dati-simulati",
    "href": "chapters/linear_models/02_reglin_bayes.html#adattare-una-retta-di-regressione-a-dati-simulati",
    "title": "60  Modello bayesiano di regressione lineare bivariata",
    "section": "\n60.2 Adattare una Retta di Regressione a Dati Simulati",
    "text": "60.2 Adattare una Retta di Regressione a Dati Simulati\nDefiniamo i parametri e simuliamo i dati.\n\nset.seed(123)\n\n# Definizione delle variabili\nx &lt;- 1:100\nn &lt;- length(x)\na &lt;- 1.5\nb &lt;- 0.5\nsigma &lt;- 10\n\n# Generazione di y\ny &lt;- a + b * x + rnorm(n, 0, sigma)\n\n# Creazione del dataframe\nfake &lt;- tibble(x = x, y = y)\nhead(fake)\n#&gt; # A tibble: 6 × 2\n#&gt;       x      y\n#&gt;   &lt;int&gt;  &lt;dbl&gt;\n#&gt; 1     1 -3.60 \n#&gt; 2     2  0.198\n#&gt; 3     3 18.6  \n#&gt; 4     4  4.21 \n#&gt; 5     5  5.29 \n#&gt; 6     6 21.7\n\nIniziamo adattando ai dati un modello frequentista:\n\nfm1 &lt;- lm(y ~ x, data = fake)\n\n\nsummary(fm1)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = y ~ x, data = fake)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -24.536  -5.524  -0.346   6.485  20.949 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)\n#&gt; (Intercept)   1.1360     1.8429    0.62     0.54\n#&gt; x             0.5251     0.0317   16.57   &lt;2e-16\n#&gt; \n#&gt; Residual standard error: 9.15 on 98 degrees of freedom\n#&gt; Multiple R-squared:  0.737,  Adjusted R-squared:  0.734 \n#&gt; F-statistic:  275 on 1 and 98 DF,  p-value: &lt;2e-16\n\nPer ottenere l’intervallo di confidenza (nel senso frequentista) della stima dei parametri usiamo:\n\nconfint(fm1, level = 0.95)\n#&gt;              2.5 % 97.5 %\n#&gt; (Intercept) -2.521  4.793\n#&gt; x            0.462  0.588\n\nAdattiamo ora ai dati un modello di regressione bayesiano utilizzando brms. Si noti che, anche in questo caso, usiamo la sintassi di Wilkinson y ~ x, come per lm(). Eseguiamo il campionamento:\n\nfm2 &lt;- brm(\n  y ~ x, \n  data = fake,\n  backend = \"cmdstanr\"\n)\n\nCome discusso nell’analisi dell’algoritmo di Metropolis, il primo passo è esaminare le tracce dei parametri per verificare la convergenza dell’algoritmo. La convergenza può essere considerata raggiunta se le catene (nel caso di brm, sono 4 per impostazione predefinita) risultano ben mescolate. Questo si manifesta in un trace plot che mostra una distribuzione uniforme e casuale dei campioni attorno a un valore centrale, senza pattern evidenti o tendenze sistematiche.\nLe tracce dei parametri si ottengono nel modo seguente:\n\nmcmc_trace(\n  fm2, \n  pars = c(\"b_Intercept\", \"b_x\", \"sigma\"),\n  facet_args = list(nrow = 3)\n)\n\n\n\n\n\n\n\nGli istogrammi delle distribuzioni a posteriori dei parametri si generano nel modo seguente:\n\nmcmc_hist(\n  fm2, \n  pars =c(\"b_Intercept\", \"b_x\", \"sigma\"),\n  facet_args = list(nrow = 3)\n)\n#&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\nPer valutare l’autocorrelazione tra i campioni a posteriori del parametro beta, possiamo utilizzare il seguente comando:\n\nmcmc_acf(fm2, \"b_x\")\n\n\n\n\n\n\n\nL’autocorrelazione fornisce informazioni sulla dipendenza tra campioni successivi nella catena di Markov. È normale che i campioni successivi non siano completamente indipendenti, poiché le catene di Markov generano campioni correlati per costruzione. Tuttavia, se l’algoritmo ha raggiunto la convergenza, l’autocorrelazione dovrebbe diminuire rapidamente e diventare trascurabile dopo un numero relativamente piccolo di lag. Questo significa che, dopo un certo numero di passi, i campioni diventano progressivamente meno correlati tra loro, comportandosi in modo simile a campioni indipendenti estratti dalla distribuzione target.\nUn’elevata autocorrelazione su lag più lunghi potrebbe invece indicare problemi di mescolamento delle catene o una mancata convergenza, richiedendo ulteriori verifiche o aggiustamenti, come l’aumento del numero di iterazioni o una diversa parametrizzazione del modello.\nNel caso presente, notiamo una rapida diminuzione dell’autocorrelazione in funzione del numero di passi. Ciò è indicativo del fatto che la convergenza è stata raggiunta.\nUna sintesi numerica dei risultati si trova nel modo seguente:\n\nsummary(fm2)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: y ~ x \n#&gt;    Data: fake (Number of observations: 100) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept     1.14      1.84    -2.44     4.79 1.00     3775     2784\n#&gt; x             0.53      0.03     0.46     0.59 1.00     4041     3082\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     9.25      0.65     8.07    10.63 1.00     3963     2940\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nConfrontiamo le stime ottenute con i valori reali dei parametri simulati. L’intercetta è stata stimata attorno a 1.14, con un’incertezza al 95% che varia tra -2.4 e 4.8. Questo risultato rientra negli intervalli di credibilità previsti, confermando l’accuratezza del modello. Analogamente, per la pendenza \\(b\\), l’intervallo di credibilità al 95% include il valore reale simulato, dimostrando come le stime bayesiane riflettano accuratamente l’incertezza sui parametri.\nSe si utilizza la funzione conditional_effects() viene prodotto un grafico che rappresenta la relazione stimata tra il predittore \\(x\\) e la variabile di risposta \\(y\\).\n\nconditional_effects(fm2) |&gt;\n  plot(points = TRUE)\n\n\n\n\n\n\n\n\n\nLinea stimata (effetto medio):\n\nLa linea centrale del grafico rappresenta il valore medio previsto di\\(y\\) per ogni valore di\\(x\\), dato dalla relazione\\(y = \\alpha + \\beta x\\).\nQuesta linea è calcolata usando i valori medi a posteriori stimati per\\(\\alpha\\) e\\(\\beta\\).\n\n\n\nBande di incertezza (intervalli di credibilità):\n\nLe bande attorno alla linea rappresentano gli intervalli di credibilità (ad esempio, al 95%). Questi mostrano l’incertezza associata alle stime del modello per ogni valore di\\(x\\).\nPiù strette sono le bande, maggiore è la certezza del modello riguardo alla relazione stimata.\n\n\n\nDati osservati:\n\nI punti rappresentano i valori effettivi di\\(y\\) osservati nei dati. Questo consente di confrontare visivamente come i dati reali si allineano con le previsioni del modello.\n\n\n\nIl grafico consente\n\nuna verifica visiva della relazione stimata tra\\(y\\) e\\(x\\);\ndi identificazione di eventuali discrepanze tra i dati osservati e le previsioni del modello;\nuna rappresentazione dell’incertezza nelle stime.\n\nAd esempio, il grafico può mostrare se\\(x\\) ha un effetto credibile su\\(y\\) e con quale livello di incertezza. Se l’effetto di\\(x\\) è debole o nullo, la linea stimata sarà piatta (vicina a zero) e le bande di incertezza saranno ampie.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_reglin_bayes.html#simulazione-di-livelli-di-copertura",
    "href": "chapters/linear_models/02_reglin_bayes.html#simulazione-di-livelli-di-copertura",
    "title": "60  Modello bayesiano di regressione lineare bivariata",
    "section": "\n60.3 Simulazione di Livelli di Copertura",
    "text": "60.3 Simulazione di Livelli di Copertura\nVerifichiamo la copertura degli intervalli di credibilità al 95% attraverso simulazioni ripetute.\n\nset.seed(42)\n# Parametri veri\na_true &lt;- 0.2\nb_true &lt;- 0.3\nsigma_true &lt;- 0.5\n# Numero di simulazioni\nnum_simulations &lt;- 1000\n# Conteggio delle coperture\ncoverage_a &lt;- 0\ncoverage_b &lt;- 0\nfor (i in 1:num_simulations) {\n  # Generazione dei dati\n  x &lt;- 1:20\n  y &lt;- a_true + b_true * x + sigma_true * rnorm(length(x))\n  # Adattamento del modello\n  fit &lt;- lm(y ~ x)\n  ci &lt;- confint(fit) # Intervalli di confidenza\n  # Verifica delle coperture\n  if (ci[1,1] &lt;= a_true & ci[1, 2] &gt;= a_true) {\n    coverage_a &lt;- coverage_a + 1\n  }\n  if (ci[2,1] &lt;= b_true & ci[2, 2] &gt;= b_true) {\n    coverage_b &lt;- coverage_b + 1\n  }\n}\n\n\n# Risultati\ncat(\"Coverage for a:\", coverage_a / num_simulations, \"\\n\")\n#&gt; Coverage for a: 0.952\ncat(\"Coverage for b:\", coverage_b / num_simulations, \"\\n\")\n#&gt; Coverage for b: 0.955\n\nI risultati indicano che i livelli di copertura empirici ottenuti con l’approccio frequentista corrispondono strettamente ai livelli teorici attesi.\nPer proseguire, ripeteremo la simulazione adottando un approccio bayesiano. Useremo la funzione brm() del pacchetto brms al posto di lm().\n#| message: false\n#| warning: false\n#| output: false\n#| \n# Definizione dei parametri\nset.seed(23)\nn_fake &lt;- 1000\ncover_68 &lt;- rep(NA, n_fake)\ncover_95 &lt;- rep(NA, n_fake)\na &lt;- 0.2 # Intercetta vera\nb &lt;- 0.3 # Pendenza vera\nsigma &lt;- 0.5 # Deviazione standard vera\nx &lt;- 1:20 # Variabile indipendente\nn &lt;- length(x) # Numero di osservazioni\n\n# Ciclo per simulazioni\nfor (s in 1:n_fake) {\n  # Generazione dei dati\n  y &lt;- a + b * x + rnorm(n, 0, sigma)\n  fake &lt;- data.frame(x = x, y = y)\n\n  # Adattamento del modello con brms\n  fit &lt;- brm(\n    bf(y ~ 1 + x, center = FALSE),\n    data = fake,\n    family = gaussian(),\n    prior = c(\n      prior(normal(0, 2.5), class = \"b\", coef = \"Intercept\"), # Prior per alpha\n      prior(normal(0, 2.5), class = \"b\", coef = \"x\"), # Prior per beta\n      prior(cauchy(0, 2.5), class = \"sigma\") # Prior per sigma\n    ),\n    seed = 42,\n    iter = 2000, \n    chains = 2, \n    refresh = 0, # Suppress console output\n    backend = \"cmdstanr\"\n  )\n\n  # Estrazione dei coefficienti stimati e delle deviazioni standard\n  posterior_summary &lt;- summary(fit)$fixed\n  b_hat &lt;- posterior_summary[\"x\", \"Estimate\"]\n  b_se &lt;- posterior_summary[\"x\", \"Est.Error\"]\n\n  # Calcolo della copertura\n  cover_68[s] &lt;- abs(b - b_hat) &lt; b_se\n  cover_95[s] &lt;- abs(b - b_hat) &lt; 2 * b_se\n}\n# Summarize the coverage results\nmean_cover_68 &lt;- mean(cover_68, na.rm = TRUE)\nmean_cover_95 &lt;- mean(cover_95, na.rm = TRUE)\ncat(\"Coverage for 68% interval:\", mean_cover_68, \"\\n\")\ncat(\"Coverage for 95% interval:\", mean_cover_95, \"\\n\")\nQuesta seconda simulazione evidenzia che anche i livelli di copertura empirici ottenuti con l’approccio bayesiano si avvicinano ai valori teorici previsti.\nI risultati ottenuti confermano l’efficacia degli intervalli di confidenza e di credibilità stimati attraverso i modelli frequentisti e bayesiani.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_reglin_bayes.html#confronti-non-effetti",
    "href": "chapters/linear_models/02_reglin_bayes.html#confronti-non-effetti",
    "title": "60  Modello bayesiano di regressione lineare bivariata",
    "section": "\n60.4 Confronti, non Effetti",
    "text": "60.4 Confronti, non Effetti\nGelman et al. (2021) sottolineano che i coefficienti di regressione sono spesso denominati “effetti”, ma questa terminologia può trarre in inganno. Gli “effetti”, infatti, implicano una relazione causale. Tuttavia, ciò che un modello di regressione stima non è necessariamente un effetto causale, ma piuttosto un pattern osservazionale. In particolare, ciò che osserviamo è che la media della variabile dipendente nella sottopopolazione con \\(X = x + 1\\) è spesso maggiore o minore (a seconda del segno di \\(\\beta\\)) rispetto alla media della sottopopolazione con \\(X = x\\).\nLa regressione è uno strumento matematico utilizzato principalmente per fare previsioni. I coefficienti di regressione devono quindi essere interpretati come confronti medi. Solo in circostanze specifiche, quando la regressione descrive un processo causale ben definito, è possibile interpretarli come effetti. Tuttavia, questa interpretazione causale deve essere giustificata dal disegno dello studio e non può essere dedotta unicamente dall’uso del modello statistico.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_reglin_bayes.html#riflessioni-conclusive",
    "href": "chapters/linear_models/02_reglin_bayes.html#riflessioni-conclusive",
    "title": "60  Modello bayesiano di regressione lineare bivariata",
    "section": "\n60.5 Riflessioni Conclusive",
    "text": "60.5 Riflessioni Conclusive\nIn questo capitolo abbiamo adottato un approccio bayesiano per stimare i parametri di un modello di regressione bivariato. È emerso che, quando i prior sono debolmente informativi, le stime bayesiane tendono a coincidere con quelle ottenute tramite l’approccio frequentista. Tuttavia, il valore dell’approccio bayesiano risiede non solo nella stima dei parametri, ma anche nella possibilità di incorporare conoscenze a priori e di rappresentare esplicitamente l’incertezza nelle stime.\nAl di là della scelta tra approccio frequentista e bayesiano, è cruciale riflettere sul ruolo dei modelli statistici nella ricerca scientifica, in particolare nel contesto psicologico. Come evidenziato da Alexander (2023), i modelli statistici non sono strumenti per rivelare una verità assoluta, ma mezzi per interpretare i dati e costruire significato a partire da essi. Essi non rappresentano la realtà in modo fedele, ma piuttosto funzionano come “lenti” attraverso le quali possiamo mettere a fuoco aspetti specifici del fenomeno studiato.\nI modelli statistici possono essere utilizzati principalmente per due scopi distinti ma complementari: inferenza e previsione.\n\nPrevisione: mira a descrivere le associazioni tra variabili, consentendo di formulare stime future basate sui dati disponibili. È un processo empirico, in cui la bontà del modello viene valutata sulla sua capacità di fare previsioni accurate.\nInferenza: si concentra sull’individuazione di relazioni causali tra variabili. Questo tipo di analisi richiede una progettazione rigorosa, come esperimenti controllati o disegni quasi-sperimentali, e una chiara giustificazione delle ipotesi del modello. La regressione, in particolare, può supportare inferenze causali solo se accompagnata da un contesto teorico robusto e da dati appropriati.\n\nÈ fondamentale ricordare che la regressione rappresenta una forma di media ponderata e, di conseguenza, i suoi risultati possono essere influenzati da bias intrinseci e dalle caratteristiche specifiche del dataset. Pertanto:\n\nLa qualità dei risultati dipende dalla qualità dei dati e dalla correttezza delle ipotesi del modello.\nÈ importante considerare potenziali fonti di bias, come la selezione dei dati, variabili confondenti non incluse nel modello, o ipotesi non verificate sulla linearità delle relazioni.\n\nIn conclusione, l’adozione di un modello statistico non è un fine in sé, ma uno strumento per esplorare, interpretare e comprendere il fenomeno di interesse. Sia che si utilizzi un approccio bayesiano o frequentista, il successo dell’analisi dipende dalla capacità di integrare i risultati quantitativi con una riflessione teorica critica e da un’attenzione costante alla validità delle ipotesi e delle conclusioni.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_reglin_bayes.html#come-installare-cmdstan",
    "href": "chapters/linear_models/02_reglin_bayes.html#come-installare-cmdstan",
    "title": "60  Modello bayesiano di regressione lineare bivariata",
    "section": "\n60.6 Come installare CmdStan",
    "text": "60.6 Come installare CmdStan\n\nAssicurati di aver installato l’ultima versione di R. Se non lo hai già fatto, scarica e installa la versione più recente seguendo le istruzioni disponibili su https://www.r-project.org/.\nCmdStanR è un’interfaccia leggera per utilizzare Stan con R.\nInstalla il pacchetto cmdstanr seguendo le istruzioni disponibili nella guida Getting Started with CmdStanR.\nVerifica che il tuo toolchain (gli strumenti di compilazione necessari) sia configurato correttamente eseguendo:\n\ncheck_cmdstan_toolchain()\nSu macOS e Linux, questa configurazione dovrebbe essere già pronta di default.\n\nProcedi con l’installazione di CmdStan utilizzando il comando seguente (specificando il numero di core da utilizzare per la compilazione, ad esempio cores = 2):\n\ninstall_cmdstan(cores = 2)\n\n60.6.1 Windows\nSu Windows è necessario installare RTools e configurare PATH:\n\n\nInstallazione di RTools:\n\nVai su https://cran.r-project.org/bin/windows/Rtools/\nScarica la versione di RTools compatibile con la tua versione di R (Generalmente, RTools 4.3 per R 4.3.x, RTools 4.2 per R 4.2.x, etc.)\nEsegui l’installer scaricato\nIMPORTANTE: Durante l’installazione, seleziona la casella “Add rtools to system PATH”\n\n\n\nVerifica dell’installazione e configurazione del PATH:\n\nApri PowerShell o Command Prompt\nVerifica se RTools è nel PATH digitando:\n\ngcc --version\nSe vedi la versione di gcc, RTools è nel PATH.\n\n\nSe RTools non è nel PATH, devi aggiungerlo manualmente:\n\nCerca “Impostazioni di Sistema” in Windows\nClicca su “Impostazioni di sistema avanzate”\nClicca su “Variabili d’ambiente”\nNella sezione “Variabili di sistema”, trova “Path”\nClicca “Modifica”\n\nClicca “Nuovo” e aggiungi questi percorsi (sostituisci X.X con la tua versione di RTools):\nC:\\rtools4X\\mingw64\\bin\nC:\\rtools4X\\usr\\bin\n\n\n\n\nVerifica finale:\n\nChiudi e riapri il terminale\nProva questi comandi:\n\ngcc --version\nmake --version\nSe entrambi i comandi mostrano le versioni, l’installazione è completa.\n\n\nTest in R:\n\nApri R o RStudio\nEsegui:\n\nSys.which(\"make\")\nDovrebbe mostrare il percorso di make.\n\n\nProblemi comuni:\n\nSe i comandi non vengono riconosciuti dopo aver aggiunto il PATH, prova a riavviare il computer.\nSe usi RStudio, potrebbe essere necessario riavviarlo dopo aver modificato il PATH.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_reglin_bayes.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/02_reglin_bayes.html#informazioni-sullambiente-di-sviluppo",
    "title": "60  Modello bayesiano di regressione lineare bivariata",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] rstan_2.32.6        StanHeaders_2.32.10 brms_2.22.8        \n#&gt;  [4] Rcpp_1.0.13-1       posterior_1.6.0     cmdstanr_0.8.1.9000\n#&gt;  [7] see_0.9.0           gridExtra_2.3       patchwork_1.3.0    \n#&gt; [10] bayesplot_1.11.1    psych_2.4.12        scales_1.3.0       \n#&gt; [13] markdown_1.13       knitr_1.49          lubridate_1.9.4    \n#&gt; [16] forcats_1.0.0       stringr_1.5.1       dplyr_1.1.4        \n#&gt; [19] purrr_1.0.2         readr_2.1.5         tidyr_1.3.1        \n#&gt; [22] tibble_3.2.1        ggplot2_3.5.1       tidyverse_2.0.0    \n#&gt; [25] rio_1.2.3           here_1.0.1         \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1     farver_2.1.2         loo_2.8.0           \n#&gt;  [4] fastmap_1.2.0        TH.data_1.1-2        tensorA_0.36.2.1    \n#&gt;  [7] pacman_0.5.1         digest_0.6.37        timechange_0.3.0    \n#&gt; [10] estimability_1.5.1   lifecycle_1.0.4      survival_3.8-3      \n#&gt; [13] processx_3.8.4       magrittr_2.0.3       compiler_4.4.2      \n#&gt; [16] rlang_1.1.4          tools_4.4.2          yaml_2.3.10         \n#&gt; [19] data.table_1.16.4    labeling_0.4.3       bridgesampling_1.1-2\n#&gt; [22] htmlwidgets_1.6.4    curl_6.0.1           pkgbuild_1.4.5      \n#&gt; [25] mnormt_2.1.1         plyr_1.8.9           abind_1.4-8         \n#&gt; [28] multcomp_1.4-26      withr_3.0.2          stats4_4.4.2        \n#&gt; [31] grid_4.4.2           inline_0.3.20        xtable_1.8-4        \n#&gt; [34] colorspace_2.1-1     emmeans_1.10.6       MASS_7.3-61         \n#&gt; [37] cli_3.6.3            mvtnorm_1.3-2        rmarkdown_2.29      \n#&gt; [40] generics_0.1.3       RcppParallel_5.1.9   reshape2_1.4.4      \n#&gt; [43] tzdb_0.4.0           splines_4.4.2        parallel_4.4.2      \n#&gt; [46] matrixStats_1.4.1    vctrs_0.6.5          V8_6.0.0            \n#&gt; [49] Matrix_1.7-1         sandwich_3.1-1       jsonlite_1.8.9      \n#&gt; [52] hms_1.1.3            glue_1.8.0           codetools_0.2-20    \n#&gt; [55] ps_1.8.1             distributional_0.5.0 stringi_1.8.4       \n#&gt; [58] gtable_0.3.6         QuickJSR_1.4.0       munsell_0.5.1       \n#&gt; [61] pillar_1.10.0        htmltools_0.5.8.1    Brobdingnag_1.2-9   \n#&gt; [64] R6_2.5.1             rprojroot_2.0.4      evaluate_1.0.1      \n#&gt; [67] lattice_0.22-6       backports_1.5.0      rstantools_2.4.0    \n#&gt; [70] coda_0.19-4.1        nlme_3.1-166         checkmate_2.3.2     \n#&gt; [73] xfun_0.49            zoo_1.8-12           pkgconfig_2.0.3",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_reglin_bayes.html#bibliografia",
    "href": "chapters/linear_models/02_reglin_bayes.html#bibliografia",
    "title": "60  Modello bayesiano di regressione lineare bivariata",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAlexander, R. (2023). Telling Stories with Data: With Applications in R. Chapman; Hall/CRC.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other stories. Cambridge University Press.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_synt_sugar.html",
    "href": "chapters/linear_models/03_synt_sugar.html",
    "title": "61  Zucchero sintattico",
    "section": "",
    "text": "61.1 Introduzione\nI modelli lineari sono così ampiamente utilizzati che sono stati sviluppati appositamente una sintassi, dei metodi e delle librerie per la regressione. Una di queste librerie è brms (Bayesian Regression Models using Stan), già introdotta nel Capitolo 60. brms è un pacchetto R progettato per adattare modelli gerarchici generalizzati lineari (di cui il modello lineare bivariato è un caso particolare), utilizzando una sintassi simile a quella presente nei pacchetti R, come lme4, nlme, rstanarm. brms si basa su Stan, ma offre un’API di livello superiore.\nIn questo capitolo esploreremo in maniera dettagliata come condurre un’analisi di regressione utilizzando brms invece di Stan.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_synt_sugar.html#interfaccia-brms",
    "href": "chapters/linear_models/03_synt_sugar.html#interfaccia-brms",
    "title": "61  Zucchero sintattico",
    "section": "\n61.2 Interfaccia brms\n",
    "text": "61.2 Interfaccia brms\n\nPer fare un esempio, applicheremo il modello di regressione bivariato alla relazione tra altezza e peso. I dati contenuti nel file Howell_18.csv sono parte di un censimento parziale della popolazione !Kung San dell’area di Dobe, raccolti tramite interviste condotte da Nancy Howell alla fine degli anni ’60 (McElreath, 2020). I !Kung San sono una delle popolazioni di raccoglitori-cacciatori più conosciute del ventesimo secolo e sono stati oggetto di numerosi studi antropologici. In questa analisi, consideriamo un sottocampione di dati relativi alla popolazione adulta (di età superiore ai 18 anni).\nImportiamo i dati contenuti nel file Howell_18.csv.\n\ndf &lt;- rio::import(here::here(\"data\", \"Howell_18.csv\"))\n\n\ndf |&gt; \n  head()\n#&gt;   height weight age male\n#&gt; 1    152   47.8  63    1\n#&gt; 2    140   36.5  63    0\n#&gt; 3    137   31.9  65    0\n#&gt; 4    157   53.0  41    1\n#&gt; 5    145   41.3  51    0\n#&gt; 6    164   63.0  35    1\n\nGeneriamo un diagramma a dispersione tra le variabili height (altezza) e weight (peso):\n\nggplot(df, aes(x = weight, y = height)) +\n  geom_point() +  \n  labs(x = \"Weight\", y = \"Height\") \n\n\n\n\n\n\n\nbrms si concentra sui modelli di regressione, e questa specializzazione permette di adottare una sintassi più semplice, conosciuta come sintassi di Wilkinson (Wilkinson & Rogers, 1973).\nAd esempio, il modello \\(y = \\alpha + \\beta x + \\varepsilon\\) si implementa come segue:\na_model = brm(y ∼ 1 + x, data = df)\nNella sintassi di Wilkinson, il simbolo tilde (∼) separa la variabile dipendente (a sinistra) dalle variabili indipendenti (a destra). In questo caso, stiamo specificando solo la media (\\(\\mu\\)) della \\(y\\).\nbrms assume di default che la distribuzione di verosimiglianza sia gaussiana, ma è possibile modificarla tramite l’argomento family.\nLa notazione 1 si riferisce all’intercetta. L’intercetta viene inclusa di default. Per cui il modello precedente si può anche scrivere, in maniera equivalente, come\na_model = brm(y ∼ x, data = df)\nSe desideriaamo escludere l’intercetta dal modello, possiamo farlo in questo modo\nno_intercept_model = brm(y ∼ 0 + x, data = df)\noppure in questo modo\nno_intercept_model = brm(y ∼ -1 + x, data = df)\nPer includere ulteriori variabili nel modello, possiamo procedere così:\nmodel_2 = brm(\"y ∼ x + z\", data)\nbrms consente anche di includere effetti a livello di gruppo (gerarchici). Ad esempio, se desideriamo un modello ad effetti misti nel quale abbiamo un effetto diverso di \\(x\\) in ciascun gruppo g, possiamo usare la seguente sintassi:\nmodel_h = brm(y ∼ x + z + (x | g), data = df)\nLa sintassi di Wilkinson non specifica le distribuzioni a priori, ma solo come le variabili dipendenti e indipendenti sono collegate. brms definirà automaticamente delle distribuzioni a priori debolmente informative per noi, rendendo superflua la loro definizione esplicita. Tuttavia, se preferiamo avere un maggiore controllo, possiamo specificarle manualmente, come vedremo in seguito.\n\n61.2.1 Centrare le Variabili\nPer interpretare più facilmente l’intercetta, centriamo la variabile weight rispetto alla media del campione:\n\ndf$weight_c = df$weight - mean(df$weight)\n\nOra, l’intercetta (\\(\\alpha\\)) rappresenterà l’altezza media quando il peso corrisponde alla media del campione.\nAdattiamo un modello lineare con la variabile weight centrata e esaminiamo i risultati:\n\nfit_1 = brm(\n  bf(height ~ 1 + weight_c, center = FALSE), \n  data = df, \n  backend = \"cmdstanr\", \n  silent = 0\n)\n\nLe tracce dei parametri si ottengono nel modo seguente:\n\nmcmc_trace(\n  fit_1, \n  pars = c(\"b_Intercept\", \"b_weight_c\", \"sigma\"),\n  facet_args = list(nrow = 3)\n)\n\n\n\n\n\n\n\n\nsummary(fit_1)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: height ~ 1 + weight_c \n#&gt;    Data: df (Number of observations: 352) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept   154.60      0.27   154.07   155.13 1.00     3812     2738\n#&gt; weight_c      0.91      0.04     0.82     0.99 1.00     3810     3168\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     5.10      0.19     4.74     5.48 1.00     3855     3153\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nLa stima dell’intercetta \\(\\alpha\\) = 154.60 suggerisce che, per le persone con un peso corrispondente al valore medio del campione analizzato, l’altezza prevista è di 154.60 cm.\nPossiamo confrontare i risultati ottenuti da brm() con quelli prodotti dall’appriccio frequentista:\n\nfit_2 &lt;- lm(height ~ 1 + weight_c, data = df)\n\n\nsummary(fit_2)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = height ~ 1 + weight_c, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -19.746  -2.884   0.022   3.142  14.774 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)\n#&gt; (Intercept)  154.597      0.271   570.2   &lt;2e-16\n#&gt; weight_c       0.905      0.042    21.5   &lt;2e-16\n#&gt; \n#&gt; Residual standard error: 5.09 on 350 degrees of freedom\n#&gt; Multiple R-squared:  0.57,   Adjusted R-squared:  0.568 \n#&gt; F-statistic:  463 on 1 and 350 DF,  p-value: &lt;2e-16\n\nAnche in questo caso, l’uso di prior debolmente informativi fa in modo che i risultati dei due approcci siano praticamente equivalenti.\n\n61.2.2 Visualizzazione dei Risultati\nPer comprendere la relazione stimata, utilizziamo la funzione conditional_effects:\n\nconditional_effects(fit_1, effects = \"weight_c\")\n\n\n\n\n\n\n\nIl grafico generato mostra:\n\nMedia posteriore: La linea rappresenta la stima centrale dell’altezza per un dato peso.\nIntervallo di densità più alta (HDI): L’area evidenziata intorno alla linea mostra l’incertezza delle stime con un intervallo di probabilità del 95%.\n\nSe si desidera modificare la percentuale dell’intervallo di credibilità, è possibile farlo utilizzando l’argomento prob, per esempio:\n\nconditional_effects(fit_1, effects = \"weight_c\", prob = 0.89)",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_synt_sugar.html#distribuzione-a-posteriori-dei-parametri",
    "href": "chapters/linear_models/03_synt_sugar.html#distribuzione-a-posteriori-dei-parametri",
    "title": "61  Zucchero sintattico",
    "section": "\n61.3 Distribuzione a Posteriori dei Parametri",
    "text": "61.3 Distribuzione a Posteriori dei Parametri\nPer esaminare la distribuzione a posteriori dei parametri usiamo la funzione mcmc_plot():\n\nmcmc_plot(fit_1, type = \"dens\")\n\n\n\n\n\n\n\nEsaminiamo in maggiori dettagli il sommario numerico dei parametri stimati:\n\ndraws &lt;- posterior::as_draws(fit_1, variable = \"^b_\", regex = TRUE)\nposterior::summarise_draws(draws, \"mean\", \"sd\", \"mcse_mean\", \"mcse_sd\")\n#&gt; # A tibble: 2 × 5\n#&gt;   variable       mean     sd mcse_mean  mcse_sd\n#&gt;   &lt;chr&gt;         &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 b_Intercept 155.    0.269   0.00437  0.00426 \n#&gt; 2 b_weight_c    0.906 0.0428  0.000693 0.000586\n\nUtilizziamo la funzione as_draws() che trasforma un oggetto R in un formato compatibile con posterior. Gli argomenti variable = \"^b_\" e regex = TRUEconsentono di selezionare solo i parametri il cui nome inizia con b_: nel nostro caso saranno l’intercetta e la pendenza del modello di regressione lineare.\nSuccessivamente usiamo la funzione summarise_draws() con gli argomenti specificati per un sommario della distribuzione a posteriori dei parametri prescelti.\n\n61.3.1 Spiegazione di mcse_mean e mcse_sd\n\nI valori mcse_mean e mcse_sd sono le Monte Carlo Standard Errors (errori standard Monte Carlo) per la stima della media (mean) e della deviazione standard (sd), rispettivamente. Questi valori quantificano l’incertezza associata al processo di campionamento effettuato durante l’analisi bayesiana, in particolare quando si utilizzano algoritmi Monte Carlo come MCMC (Markov Chain Monte Carlo).\n\n61.3.1.1 mcse_mean\n\n\nRappresenta l’errore standard Monte Carlo per la stima della media.\nIndica quanto la media stimata (\\(\\text{mean}\\)) potrebbe variare a causa della finitezza dei campioni generati dall’algoritmo MCMC.\nUn valore di mcse_mean basso rispetto alla deviazione standard (\\(\\text{sd}\\)) suggerisce che il numero di campioni generati è sufficiente per ottenere una stima accurata della media.\n\n61.3.1.2 mcse_sd\n\n\nRappresenta l’errore standard Monte Carlo per la stima della deviazione standard.\nIndica quanto potrebbe variare la stima della deviazione standard (\\(\\text{sd}\\)) a causa del numero finito di campioni generati.\nAnche qui, un valore basso di mcse_sd rispetto alla sd suggerisce che l’incertezza introdotta dal campionamento è trascurabile.\n\n61.3.2 Come interpretarli?\n\n\nProporzione rispetto alla sd:\n\n\nmcse_mean e mcse_sd dovrebbero essere molto più piccoli rispetto ai rispettivi parametri (mean e sd), idealmente almeno un ordine di grandezza inferiore.\nAd esempio, per b_Intercept, mcse_mean = 0.0044 è molto più piccolo rispetto a sd = 0.2695, indicando che la stima della media è robusta.\n\n\n\nIndicazione della qualità del campionamento:\n\nValori alti di mcse_mean o mcse_sd rispetto alla sd potrebbero indicare che il numero di iterazioni MCMC non è sufficiente, che le catene non sono ben mescolate o che ci sono problemi di convergenza.\n\n\n\nIn sintesi, mcse_mean e mcse_sd sono utili per valutare l’affidabilità delle stime derivate dal campionamento Monte Carlo. Se questi valori sono bassi, possiamo essere confidenti che il numero di campioni è sufficiente per rappresentare accuratamente la distribuzione a posteriori.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_synt_sugar.html#specificare-i-priors",
    "href": "chapters/linear_models/03_synt_sugar.html#specificare-i-priors",
    "title": "61  Zucchero sintattico",
    "section": "\n61.4 Specificare i Priors",
    "text": "61.4 Specificare i Priors\nSe vogliamo personalizzare i priors, possiamo utilizzare la funzione get_prior per esplorare quelli predefiniti:\n\nget_prior(height ~ 1 + weight_c, data = df)\n#&gt;                     prior     class     coef group resp dpar nlpar lb ub\n#&gt;  student_t(3, 154.3, 8.5) Intercept                                     \n#&gt;                    (flat)         b                                     \n#&gt;                    (flat)         b weight_c                            \n#&gt;      student_t(3, 0, 8.5)     sigma                                 0   \n#&gt;        source\n#&gt;       default\n#&gt;       default\n#&gt;  (vectorized)\n#&gt;       default\n\n\n\nprior: descrive il prior predefinito assegnato a ciascun parametro del modello. Ad esempio:\n\n\nstudent_t(3, 154.3, 8.5): prior t di Student per l’intercetta con 3 gradi di libertà, una media di 154.3, e una scala di 8.5.\n\n(flat): prior piatto (non informativo) per i coefficienti delle variabili predittive, come \\(b\\) e \\(b_{weight_c}\\).\n\nstudent_t(3, 0, 8.5): prior t di Student per il parametro \\(\\sigma\\) (deviazione standard residua), centrato su 0 con una scala di 8.5.\n\n\n\nclass: identifica la classe di parametro a cui il prior si applica:\n\n\nIntercept: prior per l’intercetta (\\(\\alpha\\)).\n\nb: prior per i coefficienti delle variabili predittive (\\(\\beta\\)).\n\nsigma: prior per il parametro della deviazione standard residua (\\(\\sigma\\)).\n\n\n\ncoef: specifica a quale predittore si riferisce il prior, se applicabile. Ad esempio:\n\nVuoto per l’intercetta (poiché non dipende da un predittore specifico).\n\nweight_c per il coefficiente relativo al predittore weight_c.\n\n\n\nlb e ub: rappresentano rispettivamente i limiti inferiori (lower bound) e superiori (upper bound) per il prior, se specificati. Ad esempio:\n\nPer sigma, il limite inferiore è \\(0\\), dato che la deviazione standard non può essere negativa.\n\n\n\nsource: indica l’origine del prior. Se il prior è predefinito (default), il valore sarà default. Se un prior è specificato manualmente dall’utente, sarà indicato come tale.\n\nOra impostiamo priors espliciti e adattiamo un nuovo modello:\n\nprior_guassian &lt;-\n  prior(normal(160, 10), class = \"b\", coef = \"Intercept\") +\n  prior(normal(0, 5), class = \"b\", coef = \"weight_c\") +\n  prior(cauchy(0, 5), class = \"sigma\")\n\n\nfit_2 = brm(\n  bf(height ~ 1 + weight_c, center = FALSE), \n  prior = prior_guassian,\n  data = df, \n  backend = \"cmdstanr\", \n  silent = 0\n)\n\nOtteniamo un sommario numerico dei parametri stimati:\n\ndraws &lt;- posterior::as_draws(fit_2, variable = \"^b_\", regex = TRUE)\nposterior::summarise_draws(draws, \"mean\", \"sd\", \"mcse_mean\", \"mcse_sd\")\n#&gt; # A tibble: 2 × 5\n#&gt;   variable       mean     sd mcse_mean  mcse_sd\n#&gt;   &lt;chr&gt;         &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 b_Intercept 155.    0.272   0.00449  0.00440 \n#&gt; 2 b_weight_c    0.905 0.0413  0.000717 0.000651\n\nI prior che abbiamo specificato non cambiano in maniera rilevante la soluzione a posteriori.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_synt_sugar.html#predizioni-predittive-a-posteriori",
    "href": "chapters/linear_models/03_synt_sugar.html#predizioni-predittive-a-posteriori",
    "title": "61  Zucchero sintattico",
    "section": "\n61.5 Predizioni Predittive a Posteriori",
    "text": "61.5 Predizioni Predittive a Posteriori\nUn aspetto fondamentale nella valutazione di un modello statistico, sia frequentista che bayesiano, è verificare quanto bene i dati osservati siano rappresentati dalle predizioni del modello. Tuttavia, l’approccio e l’interpretazione differiscono tra i due paradigmi.\n\n61.5.1 Confronto Frequentista\nNel caso frequentista, si confrontano i valori predetti dal modello, \\(\\hat{y} = \\hat{\\alpha} + \\hat{\\beta}x\\), con i dati osservati. Questo confronto si basa sull’analisi di: - La vicinanza della retta di regressione stimata ai dati osservati. - L’eventuale presenza di pattern nei dati che si discostano da un andamento lineare. - La variazione della dispersione dei valori di \\(y\\) rispetto a \\(x\\) (ad esempio, per verificare l’ipotesi di omoschedasticità).\n\n61.5.2 Approccio Bayesiano\nNell’approccio bayesiano, si eseguono le stesse verifiche di base, ma l’analisi si arricchisce attraverso l’uso delle Predizioni Predittive a Posteriori (Posterior Predictive Checks, PPCs). Questo metodo consente di confrontare i dati osservati con dati simulati dal modello, utilizzando l’incertezza stimata nelle distribuzioni a posteriori dei parametri.\n\n61.5.3 Costruzione delle Predizioni Predittive a Posteriori\nNel caso di un modello bivariato, il processo per generare un grafico delle Predizioni Predittive a Posteriori è il seguente:\n\nDati osservati: Si parte dall’istogramma lisciato dei dati osservati, che rappresenta la distribuzione empirica di \\(y\\).\n\nSimulazione di dati predetti:\n\nSi estrae un campione casuale di valori \\(\\alpha'\\), \\(\\beta'\\), e \\(\\sigma'\\) dalle distribuzioni a posteriori dei parametri (\\(\\alpha\\), \\(\\beta\\), e \\(\\sigma\\)).\nUsando questi valori, si calcolano dati simulati da una distribuzione normale: \\[\ny_{\\text{sim}} \\sim \\mathcal{N}(\\alpha' + \\beta'x, \\sigma')\n\\] dove \\(x\\) sono i valori predittori osservati.\n\n\nCreazione di istogrammi: Per ogni campione simulato, si costruisce un istogramma lisciato che rappresenta la distribuzione predetta dal modello.\nRipetizione: Il processo viene ripetuto più volte, generando molti istogrammi lisciati.\nConfronto: Tutti gli istogrammi predetti vengono sovrapposti all’istogramma dei dati osservati. Questo consente di confrontare visivamente la capacità del modello di rappresentare la distribuzione dei dati.\n\n61.5.4 Interpretazione\n\n\nBuona corrispondenza: Se gli istogrammi lisciati dei dati simulati si sovrappongono bene all’istogramma dei dati osservati, significa che il modello è in grado di rappresentare adeguatamente il campione corrente.\n\nDiscrepanze: Se vi sono discrepanze sistematiche (ad esempio, picchi o code mancanti nei dati predetti rispetto agli osservati), ciò indica che il modello potrebbe non essere adeguato o che vi sono aspetti dei dati non catturati dal modello.\n\nL’approccio delle Predizioni Predittive a Posteriori è particolarmente potente perché:\n\nIntegra l’incertezza nei parametri del modello.\nPermette di verificare non solo la bontà di adattamento complessiva, ma anche specifici aspetti delle distribuzioni predette.\nÈ visivo e intuitivo, facilitando l’identificazione di discrepanze tra modello e dati.\n\nIn conclusione, le Predizioni Predittive a Posteriori forniscono un modo robusto per valutare l’adeguatezza di un modello bayesiano rispetto ai dati osservati. Se il modello riproduce bene la distribuzione dei dati osservati, si può concludere che è adatto almeno per il campione corrente. In caso contrario, potrebbe essere necessario rivedere le specifiche del modello, come i priors o la struttura delle variabili.\nVerifichiamo dunque le predizioni del modello confrontandole con i dati osservati del campione corrente:\n\npp_check(fit_2)\n#&gt; Using 10 posterior draws for ppc type 'dens_overlay' by default.\n\n\n\n\n\n\n\nNel caso presente, vi è una buona corrispondenza tra i dati simulati dal modello e i dati osservati.\nIl grafico seguente analizza gli errori del modello rispetto alla retta di regressione stimata.\n\npp_check(fit_1, type = \"error_scatter_avg\")\n#&gt; Using all posterior draws for ppc type 'error_scatter_avg' by default.\n\n\n\n\n\n\n\nQuesto comando utilizza la funzione pp_check() per produrre un grafico che mostra i residui bayesiani, ovvero le differenze tra i dati osservati e quelli predetti dal modello. Nel tipo specifico di grafico scelto (\"error_scatter_avg\"), i residui sono rappresentati rispetto ai valori predetti, consentendo di valutare visivamente se sono distribuiti in modo uniforme.\nDal grafico, si osserva che i residui bayesiani appaiono distribuiti in modo omogeneo rispetto alla retta di regressione (che non è direttamente mostrata nel grafico). Questo suggerisce che:\n\nIl modello cattura correttamente la relazione tra la variabile predittiva e la variabile di risposta.\nNon ci sono pattern sistematici nei residui, come deviazioni non lineari o variazioni della dispersione (eteroschedasticità).\n\nSe fossero presenti pattern evidenti nei residui (ad esempio, una struttura curva o una variazione sistematica della dispersione), ciò indicherebbe che il modello potrebbe non essere adeguato, richiedendo una rivalutazione della sua struttura (ad esempio, aggiungendo termini non lineari o trasformando le variabili).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_synt_sugar.html#regressione-robusta",
    "href": "chapters/linear_models/03_synt_sugar.html#regressione-robusta",
    "title": "61  Zucchero sintattico",
    "section": "\n61.6 Regressione Robusta",
    "text": "61.6 Regressione Robusta\nIn questa sezione introduciamo la regressione robusta. Lo scopo è quello di mostrare quanto sia facile modificare il modello definito da brm per specificare una diversa distribuzione degli errori. Questo non è possibile nel caso dell’approccio frequentista.\nI modelli robusti sono utili in presenza di outlier. Ad esempio, introduciamo un outlier nei dati:\n\ndf_outlier &lt;- df\ndf_outlier$height[1] &lt;- 200\ndf_outlier$weight_c[1] &lt;- -15\n\n\ndf_outlier |&gt; \n  ggplot(aes(x = weight_c, y = height)) +\n    geom_point() +  \n    labs(x = \"Weight\", y = \"Height\") \n\n\n\n\n\n\n\nNotiamo come la presenza di un solo outlier introduce una distorsione nei risultati:\n\nfit_3 = brm(\n  bf(height ~ 1 + weight_c, center = FALSE), \n  prior = prior_guassian,\n  data = df_outlier, \n  backend = \"cmdstanr\", \n  silent = 0\n)\n\n\ndraws &lt;- posterior::as_draws(fit_3, variable = \"^b_\", regex = TRUE)\nposterior::summarise_draws(draws, \"mean\", \"sd\", \"mcse_mean\", \"mcse_sd\")\n#&gt; # A tibble: 2 × 5\n#&gt;   variable       mean     sd mcse_mean  mcse_sd\n#&gt;   &lt;chr&gt;         &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 b_Intercept 155.    0.315   0.00479  0.00457 \n#&gt; 2 b_weight_c    0.846 0.0492  0.000773 0.000774\n\nAdattiamo ora un modello robusto utilizzando una distribuzione \\(t\\) di Student:\n\nfit_4 = brm(\n  bf(height ~ 1 + weight_c, center = FALSE), \n  prior = prior_guassian,\n  family = student(),\n  data = df_outlier, \n  backend = \"cmdstanr\", \n  silent = 0\n)\n\nI risultati mostrano che il modello \\(t\\) è meno influenzato dagli outlier rispetto al modello gaussiano.\n\ndraws &lt;- posterior::as_draws(fit_4, variable = \"^b_\", regex = TRUE)\nposterior::summarise_draws(draws, \"mean\", \"sd\", \"mcse_mean\", \"mcse_sd\")\n#&gt; # A tibble: 2 × 5\n#&gt;   variable       mean     sd mcse_mean  mcse_sd\n#&gt;   &lt;chr&gt;         &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 b_Intercept 155.    0.268   0.00425  0.00441 \n#&gt; 2 b_weight_c    0.922 0.0395  0.000650 0.000630\n\nIl parametro \\(\\nu\\) della \\(t\\) di Student viene stimato dal modello. Nel caso presente\n\ndraws &lt;- posterior::as_draws(fit_4, variable = \"nu\")\nposterior::summarise_draws(draws, \"mean\", \"sd\", \"mcse_mean\", \"mcse_sd\")\n#&gt; # A tibble: 1 × 5\n#&gt;   variable  mean    sd mcse_mean mcse_sd\n#&gt;   &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 nu        6.15  1.74    0.0307  0.0424\n\nCon un parametro \\(\\nu\\) = 6, la \\(t\\) di Student ha delle “code” molto maggiori di una gaussiana, e questo le consene di “assorbire” gli outliers in maniera maggiore che la gaussiana.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_synt_sugar.html#indice-di-determinazione-bayesiano",
    "href": "chapters/linear_models/03_synt_sugar.html#indice-di-determinazione-bayesiano",
    "title": "61  Zucchero sintattico",
    "section": "\n61.7 Indice di Determinazione Bayesiano",
    "text": "61.7 Indice di Determinazione Bayesiano\nCon il pacchetto brms, possiamo calcolare il Bayes \\(R^2\\), che rappresenta l’equivalente bayesiano del classico indice di determinazione \\(R^2\\). Questo indice quantifica la proporzione di varianza spiegata dal modello, tenendo conto dell’incertezza intrinseca delle stime bayesiane.\nIl comando per calcolarlo è:\n\nbayes_R2(fit_4)\n#&gt;    Estimate Est.Error Q2.5 Q97.5\n#&gt; R2    0.501    0.0198 0.46 0.537\n\nIl comando restituisce un tibble (una tabella ordinata) con le seguenti informazioni:\n\n\nEstimate: La stima media del Bayes \\(R^2\\), cioè la proporzione di varianza spiegata dal modello, basata sulle distribuzioni a posteriori dei parametri.\n\nEst.Error: L’errore standard associato alla stima del \\(R^2\\).\n\nQ2.5 e Q97.5: I limiti inferiore e superiore dell’intervallo di credibilità al 95% per il Bayes \\(R^2\\). Questi valori indicano l’incertezza sul \\(R^2\\), riflettendo la distribuzione a posteriori.\n\nNel caso presente\n\n\nStima del \\(R^2\\): Il modello spiega in media circa il 50% della varianza osservata nella variabile dipendente.\n\nErrore Standard: L’incertezza sulla stima è relativamente bassa (±0.02).\n\nIntervallo di Credibilità: C’è un 95% di probabilità che il vero valore del \\(R^2\\) si trovi tra 0.457 e 0.537.\n\n\n61.7.1 Differenze rispetto al Frequentista \\(R^2\\)\n\n\n\nIncertezza: Il Bayes \\(R^2\\) include un’intera distribuzione a posteriori, permettendo di rappresentare l’incertezza attraverso l’intervallo di credibilità. Questo non è possibile con il \\(R^2\\) frequentista, che fornisce una stima puntuale.\n\nPriors: Il Bayes \\(R^2\\) è influenzato dai priors scelti per i parametri del modello, il che consente una maggiore flessibilità e incorpora conoscenze preesistenti.\n\nIn conclusione, il Bayes \\(R^2\\) è uno strumento potente per valutare l’adattamento di un modello bayesiano, permettendo di quantificare non solo la proporzione di varianza spiegata, ma anche l’incertezza associata alla stima.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_synt_sugar.html#riflessioni-conclusive",
    "href": "chapters/linear_models/03_synt_sugar.html#riflessioni-conclusive",
    "title": "61  Zucchero sintattico",
    "section": "\n61.8 Riflessioni conclusive",
    "text": "61.8 Riflessioni conclusive\nQuesto capitolo ha mostrato come utilizzare brms per costruire e interpretare modelli lineari, evidenziando le sue capacità di gestione dei priors, diagnostica e modellizzazione robusta. Grazie alla sua semplicità e flessibilità, brms rappresenta un potente strumento per l’inferenza bayesiana.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_synt_sugar.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/03_synt_sugar.html#informazioni-sullambiente-di-sviluppo",
    "title": "61  Zucchero sintattico",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] rstan_2.32.6        StanHeaders_2.32.10 cmdstanr_0.8.1.9000\n#&gt;  [4] posterior_1.6.0     brms_2.22.8         Rcpp_1.0.13-1      \n#&gt;  [7] see_0.9.0           gridExtra_2.3       patchwork_1.3.0    \n#&gt; [10] bayesplot_1.11.1    psych_2.4.12        scales_1.3.0       \n#&gt; [13] markdown_1.13       knitr_1.49          lubridate_1.9.4    \n#&gt; [16] forcats_1.0.0       stringr_1.5.1       dplyr_1.1.4        \n#&gt; [19] purrr_1.0.2         readr_2.1.5         tidyr_1.3.1        \n#&gt; [22] tibble_3.2.1        ggplot2_3.5.1       tidyverse_2.0.0    \n#&gt; [25] rio_1.2.3           here_1.0.1         \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1     farver_2.1.2         loo_2.8.0           \n#&gt;  [4] R.utils_2.12.3       fastmap_1.2.0        TH.data_1.1-2       \n#&gt;  [7] tensorA_0.36.2.1     pacman_0.5.1         digest_0.6.37       \n#&gt; [10] timechange_0.3.0     estimability_1.5.1   lifecycle_1.0.4     \n#&gt; [13] processx_3.8.4       survival_3.8-3       magrittr_2.0.3      \n#&gt; [16] compiler_4.4.2       rlang_1.1.4          tools_4.4.2         \n#&gt; [19] utf8_1.2.4           yaml_2.3.10          data.table_1.16.4   \n#&gt; [22] labeling_0.4.3       bridgesampling_1.1-2 htmlwidgets_1.6.4   \n#&gt; [25] curl_6.0.1           pkgbuild_1.4.5       mnormt_2.1.1        \n#&gt; [28] plyr_1.8.9           abind_1.4-8          multcomp_1.4-26     \n#&gt; [31] withr_3.0.2          R.oo_1.27.0          stats4_4.4.2        \n#&gt; [34] grid_4.4.2           inline_0.3.20        xtable_1.8-4        \n#&gt; [37] colorspace_2.1-1     emmeans_1.10.6       MASS_7.3-61         \n#&gt; [40] cli_3.6.3            mvtnorm_1.3-2        rmarkdown_2.29      \n#&gt; [43] generics_0.1.3       RcppParallel_5.1.9   reshape2_1.4.4      \n#&gt; [46] tzdb_0.4.0           splines_4.4.2        parallel_4.4.2      \n#&gt; [49] matrixStats_1.4.1    vctrs_0.6.5          V8_6.0.0            \n#&gt; [52] Matrix_1.7-1         sandwich_3.1-1       jsonlite_1.8.9      \n#&gt; [55] hms_1.1.3            glue_1.8.0           ps_1.8.1            \n#&gt; [58] codetools_0.2-20     distributional_0.5.0 stringi_1.8.4       \n#&gt; [61] gtable_0.3.6         QuickJSR_1.4.0       munsell_0.5.1       \n#&gt; [64] pillar_1.10.0        htmltools_0.5.8.1    Brobdingnag_1.2-9   \n#&gt; [67] R6_2.5.1             rprojroot_2.0.4      evaluate_1.0.1      \n#&gt; [70] lattice_0.22-6       R.methodsS3_1.8.2    backports_1.5.0     \n#&gt; [73] rstantools_2.4.0     coda_0.19-4.1        nlme_3.1-166        \n#&gt; [76] checkmate_2.3.2      xfun_0.49            zoo_1.8-12          \n#&gt; [79] pkgconfig_2.0.3",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_synt_sugar.html#bibliografia",
    "href": "chapters/linear_models/03_synt_sugar.html#bibliografia",
    "title": "61  Zucchero sintattico",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nWilkinson, G., & Rogers, C. (1973). Symbolic description of factorial models for analysis of variance. Journal of the Royal Statistical Society Series C: Applied Statistics, 22(3), 392–399.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_one_mean.html",
    "href": "chapters/linear_models/04_one_mean.html",
    "title": "62  Inferenza bayesiana su una media",
    "section": "",
    "text": "62.1 Preparazione del Notebook\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(cmdstanr, posterior, bayestestR, brms)",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_one_mean.html#introduzione",
    "href": "chapters/linear_models/04_one_mean.html#introduzione",
    "title": "62  Inferenza bayesiana su una media",
    "section": "\n62.2 Introduzione",
    "text": "62.2 Introduzione\nL’obiettivo principale di questo capitolo è esaminare un contesto che abbiamo già preso in considerazione in precedenza: ci troviamo di fronte a un campione di dati misurati su una scala a intervalli o rapporti e desideriamo effettuare inferenze sulla media della popolazione da cui il campione è stato estratto. Tuttavia, anziché procedere con una derivazione analitica della distribuzione a posteriori della media della popolazione, in questo caso utilizzeremo brms.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_one_mean.html#il-modello-normale",
    "href": "chapters/linear_models/04_one_mean.html#il-modello-normale",
    "title": "62  Inferenza bayesiana su una media",
    "section": "\n62.3 Il modello Normale",
    "text": "62.3 Il modello Normale\nI priori coniugati Normali di una Normale non richiedono l’approssimazione numerica ottenuta mediante metodi MCMC. In questo capitolo, tuttavia, ripetiamo l’esercizio descritto nel Capitolo 46 usando brms.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_one_mean.html#un-esempio-concreto",
    "href": "chapters/linear_models/04_one_mean.html#un-esempio-concreto",
    "title": "62  Inferenza bayesiana su una media",
    "section": "\n62.4 Un esempio concreto",
    "text": "62.4 Un esempio concreto\nPer applicare il modello Normale, utilizzeremo i dati del censimento parziale dell’area di Dobe dei !Kung San, raccolti attraverso interviste condotte da Nancy Howell alla fine degli anni ’60. I !Kung San sono una suddivisione della popolazione San, che vive nel deserto del Kalahari, tra Namibia, Botswana e Angola, e mantengono un’economia basata su caccia e raccolta. Riprodurremo l’analisi descritta da McElreath (2020), esaminando unicamente i valori dell’altezza di individui di età superiore ai 18 anni.\n\ndf &lt;- rio::import(here::here(\"data\", \"Howell_18.csv\"))\ndf |&gt; \n  head()\n#&gt;   height weight age male\n#&gt; 1    152   47.8  63    1\n#&gt; 2    140   36.5  63    0\n#&gt; 3    137   31.9  65    0\n#&gt; 4    157   53.0  41    1\n#&gt; 5    145   41.3  51    0\n#&gt; 6    164   63.0  35    1\n\nIl campione include 352 osservazioni:\n\nlength(df$height)\n#&gt; [1] 352\n\n\nggplot(df, aes(x = height)) +\n  geom_histogram(binwidth = 5, color = \"black\", fill = \"lightgray\") +\n  labs(title = \"Istogramma di Height\", x = \"Altezza (cm)\", y = \"Frequenza\")\n\n\n\n\n\n\n\nCome indicato dall’istogramma, i dati sono approssimativamente distribuiti in maniera gaussiana:\n\ndf |&gt;\n  ggplot(aes(sample = height)) +\n  stat_qq() +\n  stat_qq_line(colour = \"red\") +\n  labs(\n    title = \"Normal Q-Q plot\",\n    x = \"Teorici (Z-score)\",\n    y = \"Valori osservati\"\n  )\n\n\n\n\n\n\n\nIn realtà, dal Q-Q plot si nota un piccolo scostamento sistematico. Quando la retta che approssima i punti empirici risulta più piatta rispetto alla diagonale teorica (che avrebbe pendenza 1 se i dati fossero perfettamente normali), la distribuzione empirica risulta meno dispersa di una Gaussiana di riferimento: i quantili empirici aumentano più lentamente di quelli teorici, indicando una varianza leggermente inferiore (o code meno ampie). Nel caso presente, tuttavia, questo scostamento è di modesta entità e si può comunque procedere all’adattamento di un modello gaussiano.\nLa media dei valori dell’altezza nel campione è:\n\nmean(df$height)\n#&gt; [1] 155\n\ncon una deviazione standard pari a:\n\nsd(df$height)\n#&gt; [1] 7.74",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_one_mean.html#modello-frequentista-semplice",
    "href": "chapters/linear_models/04_one_mean.html#modello-frequentista-semplice",
    "title": "62  Inferenza bayesiana su una media",
    "section": "\n62.5 Modello frequentista semplice",
    "text": "62.5 Modello frequentista semplice\nIniziamo con un modello frequentista molto semplice, in cui ipotizziamo che ogni osservazione \\(y_i\\) sia generata dal modello:\n\\[\ny_i = \\alpha + \\varepsilon_i,\n\\]\ndove \\(\\varepsilon_i\\) è un errore aleatorio con media zero (ad esempio, \\(\\varepsilon_i \\sim \\mathcal{N}(0, \\sigma^2)\\)) e \\(\\alpha\\) è la sola incognita (intercetta). Poiché non ci interessa includere altre variabili predittive, stiamo stimando semplicemente la media di \\(y\\).\nLa stima di \\(\\alpha\\) è basata sul principio di massima verosimiglianza, senza informazioni a priori. In R, con l’approccio frequentista, ci basta usare:\n\nfm1 &lt;- lm(\n  formula = height ~ 1, \n  data = df\n)\n\nQui, height ~ 1 indica che vogliamo un modello con sola intercetta (nessuna covariata). Analizziamo il risultato:\n\nsummary(fm1)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = height ~ 1, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -18.072  -6.007  -0.292   6.058  24.473 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)\n#&gt; (Intercept)  154.597      0.413     375   &lt;2e-16\n#&gt; \n#&gt; Residual standard error: 7.74 on 351 degrees of freedom\n\n\n\nsummary(fm1) mostra la stima puntuale di \\(\\alpha\\) (che è la media campionaria di height) assieme ad altri indicatori (p-value, R-squared e così via, anche se in questo caso non ha senso parlare di R-squared con un solo parametro).\n\n\n62.5.1 Intervallo di confidenza al 95%\nPer ottenere l’intervallo di confidenza (nel senso frequentista) della stima di \\(\\alpha\\), usiamo:\n\nconfint(fm1, level = 0.95)\n#&gt;             2.5 % 97.5 %\n#&gt; (Intercept)   154    155\n\nQuesto produce l’intervallo di confidenza al 95% basato su procedure di inferenza classica (stima della varianza e dell’errore standard di \\(\\alpha\\)).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_one_mean.html#modello-bayesiano-senza-specificare-priori-priori-uniformi",
    "href": "chapters/linear_models/04_one_mean.html#modello-bayesiano-senza-specificare-priori-priori-uniformi",
    "title": "62  Inferenza bayesiana su una media",
    "section": "\n62.6 Modello bayesiano senza specificare priori (priori uniformi)",
    "text": "62.6 Modello bayesiano senza specificare priori (priori uniformi)\nOra vogliamo replicare lo stesso modello usando un approccio bayesiano con il pacchetto brms. Se non specifichiamo esplicitamente la distribuzione a priori di \\(\\alpha\\), brms usa di default un priore piatto (o debolmente informativo), di fatto molto simile a non avere un’informazione a priori.\nIl codice è analogo:\n\nfm2 &lt;- brm(\n  formula = height ~ 1, \n  data = df,\n  backend = \"cmdstanr\"\n)\n\n\nAnche qui, il modello è \\(y_i = \\alpha + \\varepsilon_i\\), ma gestito in modo bayesiano.\n\nsummary(fm2) mostrerà la posterior mean (o mediana, a seconda dei parametri di configurazione) per \\(\\alpha\\), l’errore standard e l’intervallo di credibilità.\n\n\nsummary(fm2)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: height ~ 1 \n#&gt;    Data: df (Number of observations: 352) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept   154.60      0.41   153.78   155.40 1.00     3721     2649\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     7.77      0.30     7.21     8.38 1.00     3227     2526\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n62.6.1 Intervallo di credibilità\nL’output di summary(fm2) presenta di default l’intervallo di credibilità al 95%. Questo valore può essere modificato con l’argomento prob =, ad esempio summary(fm2, prob = 0.90) per un 90% di credibilità.\nIn assenza di un priore informativo, la distribuzione a posteriori è sostanzialmente uguale a quella massima verosimiglianza (più un’eventuale correzione di normalizzazione), quindi i risultati numerici corrispondono molto da vicino a quelli ottenuti dal metodo frequentista. Piccole discrepanze sono dovute alle approssimazioni MCMC.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_one_mean.html#differenze-di-interpretazione-degli-intervalli",
    "href": "chapters/linear_models/04_one_mean.html#differenze-di-interpretazione-degli-intervalli",
    "title": "62  Inferenza bayesiana su una media",
    "section": "\n62.7 Differenze di interpretazione degli intervalli",
    "text": "62.7 Differenze di interpretazione degli intervalli\n\n\nApproccio frequentista:\n\nL’intervallo di confidenza (ad esempio \\([153.78, 155.41]\\)) è un procedimento statistico che, se ripetuto molte volte su campioni diversi, “catturerà” il vero valore di \\(\\alpha\\) nel 95% dei casi. In altre parole, è un’affermazione sul metodo di costruzione dell’intervallo, non sull’incertezza del parametro in sé.\n\nNon è lecito dire “c’è il 95% di probabilità che \\(\\alpha\\) stia nell’intervallo \\([153.78, 155.41]\\)”. La probabilità si riferisce alla procedura di campionamento dei dati, non al parametro (che nel frequentismo è considerato fisso e ignoto).\n\n\n\nApproccio bayesiano:\n\nL’intervallo di credibilità \\([153.78, 155.41]\\) al 95% dice che, dati i dati osservati e la prior (qui praticamente uniforme), c’è il 95% di probabilità che \\(\\alpha\\) appartenga a quell’intervallo.\n\nQui la probabilità è assegnata direttamente al parametro \\(\\alpha\\), perché nella prospettiva bayesiana il parametro è visto come una variabile aleatoria che riflette la nostra incertezza prima dell’osservazione dei dati (prior) e dopo l’osservazione dei dati (posterior).\n\n\n\nIn sintesi:\n\n\nFrequentista: l’intervallo di fiducia è una proprietà della procedura di stima; il parametro è fisso, i dati sono casuali.\n\n\nBayesiano: l’intervallo di credibilità è una proprietà della distribuzione a posteriori; il parametro è casuale (nel senso che abbiamo incertezza su di esso), e i dati sono osservati.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_one_mean.html#riportare-i-risultati",
    "href": "chapters/linear_models/04_one_mean.html#riportare-i-risultati",
    "title": "62  Inferenza bayesiana su una media",
    "section": "\n62.8 Riportare i Risultati",
    "text": "62.8 Riportare i Risultati\nNel caso frequentista, il risultato può essere riportato nel modo seguente:\n\nL’analisi ha fornito una stima puntuale di α pari a 154.6, con un intervallo di confidenza al 95% compreso tra [153.8; 155.4].\n\nNel caso bayesiano:\n\nL’analisi bayesiana, condotta con una prior non informativa, ha restituito una stima a posteriori di α pari a 154.6, con un intervallo di credibilità al 95% [153.8; 155.4].",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_one_mean.html#conclusioni-intermedie",
    "href": "chapters/linear_models/04_one_mean.html#conclusioni-intermedie",
    "title": "62  Inferenza bayesiana su una media",
    "section": "\n62.9 Conclusioni Intermedie",
    "text": "62.9 Conclusioni Intermedie\n\nCon lm() (modello lineare frequen­tista), otteniamo la stima di \\(\\alpha\\) con massima verosimiglianza e un intervallo di confidenza al 95%.\n\nCon brm() e un priore piatto (o molto debole), il risultato numerico è essenzialmente lo stesso, ma la filosofia interpretativa dell’intervallo \\([153.78, 155.41]\\) cambia.\n\nSe volessimo aggiungere informazioni a priori, potremmo specificare un priore su \\(\\alpha\\) in brm(), e otterremmo stime a posteriori diverse dalle frequentiste, soprattutto se i dati sono poco informativi.\n\nIn questo modo, abbiamo mostrato come lo stesso modello (una semplice stima di media) produca numeri quasi identici in ottica frequentista e bayesiana se il priore è non informativo, pur differendo profondamente nell’interpretazione degli intervalli risultanti.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_one_mean.html#modello-bayesiano-con-prior",
    "href": "chapters/linear_models/04_one_mean.html#modello-bayesiano-con-prior",
    "title": "62  Inferenza bayesiana su una media",
    "section": "\n62.10 Modello Bayesiano con Prior",
    "text": "62.10 Modello Bayesiano con Prior\nImpostiamo una distribuzione a priori \\(\\mathcal{N}(181, 30)\\) per il parametro \\(\\mu\\) e una distribuzione a priori \\(\\mathcal{N}(0, 20)\\) per il parametro \\(\\sigma\\). Seguendo McElreath (2020), ho impostato la distribuzione a priori per \\(\\mu\\) sul valore della mia altezza, per incorporare nel modello le mie conoscenze precedenti rispetto ai valori dell’altezza.\nPertanto, il modello Normale si definisce nel modo seguente:\n\\[\n\\begin{align}\nY_i &\\sim \\mathcal{N}(\\mu, \\sigma) \\notag\\\\\n\\mu &\\sim \\mathcal{N}(181, 30) \\notag\\\\\n\\sigma &\\sim \\mathcal{N}(0, 20) \\notag\n\\end{align}\n\\]\nCon questa specifica del modello:\n\nLa variabile casuale \\(Y_i\\) segue una distribuzione normale con parametri \\(\\mu\\) e \\(\\sigma\\).\nIl parametro \\(\\mu\\) ha una distribuzione a priori normale con media 181 e deviazione standard 30.\nIl parametro \\(\\sigma\\) ha una distribuzione a priori normale con deviazione standard 20, troncata inferiormente a 0.\n\nPer \\(\\sigma\\), la normale troncata con deviazione standard pari a 20 permette una grande variabilità, garantendo valori positivi per la deviazione standard della distribuzione normale di \\(Y_i\\). I parametri \\(\\mu\\) e \\(\\sigma\\) sono sconosciuti e rappresentano l’oggetto dell’inferenza.\n\nfm3 &lt;- brm(\n  formula = height ~ 1,   # Modello con sola intercetta (mu)\n  data    = df,\n  family  = gaussian(),   # Distribuzione Normale\n  prior   = c(\n    prior(normal(181, 30), class = \"Intercept\"),  # Prior su mu\n    prior(normal(0, 20),   class = \"sigma\")       # Prior su sigma\n  ),\n  chains  = 4,\n  iter    = 2000,\n  seed    = 1234,\n  backend = \"cmdstanr\"\n)\n\n\nsummary(fm3)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: height ~ 1 \n#&gt;    Data: df (Number of observations: 352) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept   154.60      0.41   153.80   155.41 1.00     3156     2659\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     7.77      0.29     7.20     8.38 1.00     3256     2596\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nAnche usando questi prior debolmente informativi per \\(\\alpha\\) e \\(\\sigma\\), l’intervallo a posteriori per \\(\\alpha\\) coincide con quello frequentista.\nCalcoliamo ora l’intervallo di credibilità all’89%:\n\nsummary(fm3, prob = 0.89)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: height ~ 1 \n#&gt;    Data: df (Number of observations: 352) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-89% CI u-89% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept   154.60      0.41   153.94   155.27 1.00     3156     2659\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-89% CI u-89% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     7.77      0.29     7.32     8.25 1.00     3256     2596\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nIl risultato ottenuto replica i valori riportati da McElreath (2020) nella sua discussione dell’analisi di questi dati, anche se McElreath usa una procedura bayesiana diversa da quella presentata qui. McElreath (2020) giustifica la scelta dell’89% nel modo seguente:\n\nWhy 89%? It’s just the default. It displays a quite wide interval, so it shows a high-probability range of parameter values. If you want another interval, such as the conventional and mindless 95%, you can use precis(m4.1,prob=0.95). But I don’t recommend 95% intervals, because readers will have a hard time not viewing them as significance tests. 89 is also a prime number, so if someone asks you to justify it, you can stare at them meaningfully and incant, “Because it is prime.” That’s no worse justification than the conventional justification for 95%.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_one_mean.html#funzioni-bayesplot",
    "href": "chapters/linear_models/04_one_mean.html#funzioni-bayesplot",
    "title": "62  Inferenza bayesiana su una media",
    "section": "\n62.11 Funzioni bayesplot\n",
    "text": "62.11 Funzioni bayesplot\n\nIl pacchetto bayesplot mette a disposizione un insieme di funzioni molto utili per visualizzare la distribuzione a posteriori di uno o più parametri e per verificare la bontà di adattamento del modello ai dati.\n\n62.11.1 Traceplot\nUn traceplot consente di verificare la convergenza delle catene MCMC e di controllare l’autocorrelazione dei campioni a posteriori. Nel seguente esempio, si mostrano le tracce (i valori campionati lungo le iterazioni) per i parametri “Intercept” e “sigma”:\n\nmcmc_trace(\n  fm3, \n  pars = c(\"Intercept\", \"sigma\"),\n  facet_args = list(nrow = 2)\n)\n\n\n\n\n\n\n\n\nL’asse orizzontale indica il numero di iterazione MCMC,\n\nL’asse verticale mostra il valore assunto dal parametro in quella iterazione,\n\nAvere catene che si mescolano bene e appaiono “stazionarie” (senza trend crescenti o calanti) è un buon segnale di convergenza.\n\n62.11.2 Distribuzione a posteriori di un singolo parametro\nSe vogliamo visualizzare la distribuzione a posteriori di un singolo parametro (ad esempio l’intercetta, qui chiamata “b_Intercept” nel modello brms), possiamo usare:\n\nmcmc_areas(fm3, regex_pars = \"b_Intercept\", prob = 0.89)\n\n\n\n\n\n\n\n\nViene mostrata la densità a posteriori, con un’area evidenziata corrispondente all’89% di credibilità (specificabile con prob = 0.89 o un altro valore).\n\nSe desideriamo un intervallo di credibilità al 95%, useremo prob = 0.95.\n\n62.11.3 Rappresentazione congiunta di due parametri\nPer studiare la relazione tra due parametri (ad esempio “Intercept” e “sigma”):\n\nmcmc_scatter(fm3, pars = c(\"Intercept\", \"sigma\"))\n\n\n\n\n\n\n\n\nSi ottiene un diagramma di dispersione dei campioni a posteriori sui due assi, uno per ciascun parametro, con eventuali isodensità che mostrano le aree più probabili nella distribuzione congiunta.\n\n62.11.4 Posterior Predictive Check\nLa funzione pp_check() è essenziale per valutare se il modello è in grado di riprodurre i dati osservati:\n\npp_check(fm3)\n#&gt; Using 10 posterior draws for ppc type 'dens_overlay' by default.\n\n\n\n\n\n\n\n\nQuesta funzione genera un confronto tra la distribuzione dei dati reali (rappresentati, ad esempio, con una linea nera su un istogramma) e la distribuzione di diversi dataset simulati dal modello, sfruttando la distribuzione a posteriori dei parametri (\\(\\alpha\\), \\(\\sigma\\), ecc.).\n\nPoiché il modello bayesiano è generativo, possiamo campionare nuovi dati “fittizi” a partire da ogni draw della posterior: in questo modo otteniamo molteplici dataset simulati, ognuno generato con un diverso valore di \\(\\alpha\\) e \\(\\sigma\\) estratto dalle distribuzioni posteriori.\n\nNel grafico prodotto da pp_check(), i dati osservati compaiono spesso come linea continua nera, mentre i dati simulati dal modello (ad esempio, 8 repliche di default) sono mostrati in colori più chiari o linee semitrasparenti. Se la distribuzione empirica si sovrappone bene a quelle generate, significa che il modello spiega adeguatamente i dati.\n\nNel nostro caso, notiamo che le distribuzioni simulate risultano molto simili a quella osservata, indicando che la stima di \\(\\alpha\\) e \\(\\sigma\\) cattura in modo soddisfacente la variabilità dei dati.\n\nSe invece avessimo osservato discrepanze sistematiche (ad esempio, dati reali con code più pesanti, oppure un picco in posizioni diverse rispetto alle distribuzioni simulate), ci saremmo insospettiti riguardo all’adeguatezza del modello. In situazioni del genere, conviene rivedere le assunzioni (e.g. normalità, varianza costante, eventuali covariate assenti, ecc.) prima di trarre conclusioni dai risultati a posteriori.\n\n\nIn sintesi, il pacchetto bayesplot fornisce strumenti fondamentali per:\n\n\nValutare la convergenza delle catene MCMC (traceplot, autocorrelation plots),\n\n\nEsplorare la distribuzione a posteriori dei parametri (mcmc_areas, mcmc_density, mcmc_scatter, …),\n\n\nVerificare la bontà del modello rispetto ai dati osservati mediante posterior predictive checks (pp_check).\n\nQueste analisi grafiche forniscono informazioni cruciali sia sulla qualità del campionamento (e dunque sulla stabilità delle stime) sia sull’adeguatezza delle ipotesi modellistiche adottate.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_one_mean.html#lapproccio-tradizionale",
    "href": "chapters/linear_models/04_one_mean.html#lapproccio-tradizionale",
    "title": "62  Inferenza bayesiana su una media",
    "section": "\n62.12 L’approccio Tradizionale",
    "text": "62.12 L’approccio Tradizionale\nPrima dell’avvento dei metodi bayesiani e di altri approcci moderni, l’inferenza sulla media di una popolazione veniva spesso affrontata ricorrendo al test t di Student.\n\n62.12.1 La statistica T di Student\nIl test si basa sulla seguente statistica:\n\\[\nT = \\frac{\\bar{X} - \\mu_0}{s / \\sqrt{n}},\n\\]\ndove:\n\n\n\\(\\bar{X}\\) è la media campionaria di \\(n\\) osservazioni,\n\n\n\\(\\mu_0\\) è il valore ipotizzato dalla cosiddetta “ipotesi nulla” (solitamente \\(\\mu_0 = 0\\), ma può essere qualsiasi valore di riferimento),\n\n\n\\(s\\) è la deviazione standard campionaria corretta (ovvero stimatore di \\(\\sigma\\)),\n\n\n\\(n\\) è la dimensione del campione.\n\nQuando \\(\\sigma\\) (deviazione standard vera) è sconosciuta e sostituita da \\(s\\), la statistica \\(\\,T\\) segue (in teoria) una distribuzione t di Student con \\(n - 1\\) gradi di libertà:\n\\[\nT \\sim t_{(n-1)}.\n\\]\n\n62.12.2 Collegamento con la distribuzione Z\nSe \\(\\sigma\\) fosse nota, useremmo la statistica:\n\\[\nZ = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}},\n\\]\nla quale segue una distribuzione Normale Standard (\\(Z \\sim \\mathcal{N}(0,1)\\)). Quando invece \\(\\sigma\\) è sostituita da \\(s\\), la distribuzione di questa statistica diventa una t di Student (che, per \\(n\\) grande, si avvicina molto alla \\(\\mathcal{N}(0,1)\\)).\n\n62.12.3 Intervallo di confidenza\nCon il test t di Student, si ottiene anche il tradizionale intervallo di confidenza al 95% per \\(\\mu\\):\n\\[\n\\bar{X} \\pm t_{0.975,\\,n-1} \\cdot \\frac{s}{\\sqrt{n}},\n\\]\ndove \\(t_{0.975,\\,n-1}\\) è il quantile al 97.5% della distribuzione t con \\(n-1\\) gradi di libertà (circa 2.0 se \\(n\\) è sufficientemente grande, mentre 1.96 è il valore per la distribuzione normale standard).\n\n62.12.3.1 Esempio in R\nNell’esempio riportato, se vogliamo costruire l’intervallo di confidenza al 95% manualmente, possiamo scrivere:\n\nmean(df$height) + c(-1, 1) * \n  qt(0.975, length(df$height) - 1) * \n  (sd(df$height) / sqrt(length(df$height)))\n#&gt; [1] 154 155\n\noppure usare direttamente la funzione:\n\nt.test(df$height, mu = 0)\n#&gt; \n#&gt;  One Sample t-test\n#&gt; \n#&gt; data:  df$height\n#&gt; t = 375, df = 351, p-value &lt;2e-16\n#&gt; alternative hypothesis: true mean is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  154 155\n#&gt; sample estimates:\n#&gt; mean of x \n#&gt;       155\n\nche restituisce sia il valore della statistica T, sia l’intervallo di confidenza e il p-value del test t (ipotizzando, in questo esempio, \\(\\mu_0 = 0\\) come ipotesi nulla).\n\n62.12.4 Confronto con il modello di regressione a sola intercetta\nSi noti che i risultati (media stimata e intervallo di confidenza) coincidono con quanto si otterrebbe usando una regressione lineare con sola intercetta (come lm(height ~ 1, data=df)) e richiedendo l’intervallo di confidenza con confint(). Sia il test \\(t\\) di Student sia la regressione lineare semplice (senza covariate) condividono infatti le stesse assunzioni di base e forniscono risultati equivalenti per quanto riguarda l’inferenza sulla media.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_one_mean.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/04_one_mean.html#informazioni-sullambiente-di-sviluppo",
    "title": "62  Inferenza bayesiana su una media",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] rstan_2.32.6        StanHeaders_2.32.10 brms_2.22.8        \n#&gt;  [4] Rcpp_1.0.13-1       bayestestR_0.15.0   posterior_1.6.0    \n#&gt;  [7] cmdstanr_0.8.1.9000 see_0.9.0           gridExtra_2.3      \n#&gt; [10] patchwork_1.3.0     bayesplot_1.11.1    psych_2.4.12       \n#&gt; [13] scales_1.3.0        markdown_1.13       knitr_1.49         \n#&gt; [16] lubridate_1.9.4     forcats_1.0.0       stringr_1.5.1      \n#&gt; [19] dplyr_1.1.4         purrr_1.0.2         readr_2.1.5        \n#&gt; [22] tidyr_1.3.1         tibble_3.2.1        ggplot2_3.5.1      \n#&gt; [25] tidyverse_2.0.0     rio_1.2.3           here_1.0.1         \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1     farver_2.1.2         loo_2.8.0           \n#&gt;  [4] R.utils_2.12.3       fastmap_1.2.0        TH.data_1.1-2       \n#&gt;  [7] tensorA_0.36.2.1     pacman_0.5.1         digest_0.6.37       \n#&gt; [10] timechange_0.3.0     estimability_1.5.1   lifecycle_1.0.4     \n#&gt; [13] processx_3.8.4       survival_3.8-3       magrittr_2.0.3      \n#&gt; [16] compiler_4.4.2       rlang_1.1.4          tools_4.4.2         \n#&gt; [19] yaml_2.3.10          data.table_1.16.4    labeling_0.4.3      \n#&gt; [22] bridgesampling_1.1-2 htmlwidgets_1.6.4    curl_6.0.1          \n#&gt; [25] pkgbuild_1.4.5       mnormt_2.1.1         plyr_1.8.9          \n#&gt; [28] abind_1.4-8          multcomp_1.4-26      withr_3.0.2         \n#&gt; [31] R.oo_1.27.0          stats4_4.4.2         grid_4.4.2          \n#&gt; [34] inline_0.3.20        xtable_1.8-4         colorspace_2.1-1    \n#&gt; [37] ggridges_0.5.6       emmeans_1.10.6       MASS_7.3-61         \n#&gt; [40] insight_1.0.0        cli_3.6.3            mvtnorm_1.3-2       \n#&gt; [43] rmarkdown_2.29       generics_0.1.3       RcppParallel_5.1.9  \n#&gt; [46] reshape2_1.4.4       tzdb_0.4.0           splines_4.4.2       \n#&gt; [49] parallel_4.4.2       matrixStats_1.4.1    vctrs_0.6.5         \n#&gt; [52] V8_6.0.0             Matrix_1.7-1         sandwich_3.1-1      \n#&gt; [55] jsonlite_1.8.9       hms_1.1.3            glue_1.8.0          \n#&gt; [58] ps_1.8.1             codetools_0.2-20     distributional_0.5.0\n#&gt; [61] stringi_1.8.4        gtable_0.3.6         QuickJSR_1.4.0      \n#&gt; [64] munsell_0.5.1        pillar_1.10.0        htmltools_0.5.8.1   \n#&gt; [67] Brobdingnag_1.2-9    R6_2.5.1             rprojroot_2.0.4     \n#&gt; [70] evaluate_1.0.1       lattice_0.22-6       R.methodsS3_1.8.2   \n#&gt; [73] backports_1.5.0      rstantools_2.4.0     coda_0.19-4.1       \n#&gt; [76] nlme_3.1-166         checkmate_2.3.2      xfun_0.49           \n#&gt; [79] zoo_1.8-12           pkgconfig_2.0.3",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_one_mean.html#bibliografia",
    "href": "chapters/linear_models/04_one_mean.html#bibliografia",
    "title": "62  Inferenza bayesiana su una media",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean_stan.html",
    "href": "chapters/linear_models/05_one_mean_stan.html",
    "title": "63  Inferenza bayesiana su una media (Stan) 🔸",
    "section": "",
    "text": "63.1 Preparazione del Notebook\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(cmdstanr, posterior, bayestestR)",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Inferenza bayesiana su una media (Stan) 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean_stan.html#introduzione",
    "href": "chapters/linear_models/05_one_mean_stan.html#introduzione",
    "title": "63  Inferenza bayesiana su una media (Stan) 🔸",
    "section": "\n63.2 Introduzione",
    "text": "63.2 Introduzione\nL’obiettivo di questo capitolo è replicare l’analisi del capitolo precedente usando Stan direttamente.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Inferenza bayesiana su una media (Stan) 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean_stan.html#un-esempio-concreto",
    "href": "chapters/linear_models/05_one_mean_stan.html#un-esempio-concreto",
    "title": "63  Inferenza bayesiana su una media (Stan) 🔸",
    "section": "\n63.3 Un esempio concreto",
    "text": "63.3 Un esempio concreto\nPer applicare il modello Normale, utilizzeremo i dati del censimento parziale dell’area di Dobe dei !Kung San, raccolti attraverso interviste condotte da Nancy Howell alla fine degli anni ’60. Riprodurremo l’analisi descritta da McElreath (2020), esaminando unicamente i valori dell’altezza di individui di età superiore ai 18 anni.\n\ndf &lt;- rio::import(here::here(\"data\", \"Howell_18.csv\"))\n\nIl campione include 352 osservazioni:\n\nlength(df$height)\n#&gt; [1] 352\n\nLa media dei valori dell’altezza nel campione è:\n\nmean(df$height)\n#&gt; [1] 155\n\ncon una deviazione standard pari a:\n\nsd(df$height)\n#&gt; [1] 7.74\n\n\n63.3.1 Modello di Base\nImpostiamo una distribuzione a priori \\(\\mathcal{N}(181, 30)\\) per il parametro \\(\\mu\\) e una distribuzione a priori \\(\\mathcal{N}(0, 20)\\) per il parametro \\(\\sigma\\). Seguendo McElreath (2020), ho impostato la distribuzione a priori per \\(\\mu\\) sul valore della mia altezza, per incorporare nel modello le mie conoscenze precedenti rispetto ai valori dell’altezza.\nPertanto, il modello Normale si definisce nel modo seguente:\n\\[\n\\begin{align}\nY_i &\\sim \\mathcal{N}(\\mu, \\sigma) \\notag\\\\\n\\mu &\\sim \\mathcal{N}(181, 30) \\notag\\\\\n\\sigma &\\sim \\mathcal{N}(0, 20) \\notag\n\\end{align}\n\\]\nCon questa specifica del modello:\n\nLa variabile casuale \\(Y_i\\) segue una distribuzione normale con parametri \\(\\mu\\) e \\(\\sigma\\).\nIl parametro \\(\\mu\\) ha una distribuzione a priori normale con media 181 e deviazione standard 30.\nIl parametro \\(\\sigma\\) ha una distribuzione a priori normale con deviazione standard 20, troncata inferiormente a 0.\n\nPer \\(\\sigma\\), la normale troncata con deviazione standard pari a 20 permette una grande variabilità, garantendo valori positivi per la deviazione standard della distribuzione normale di \\(Y_i\\). I parametri \\(\\mu\\) e \\(\\sigma\\) sono sconosciuti e rappresentano l’oggetto dell’inferenza.\n\n# Path to the Stan file\nstan_file &lt;- here::here(\"stan\", \"gaussian_height.stan\")\n\n# Create a CmdStanModel object\nmod &lt;- cmdstan_model(stan_file)\n\n\nmod$print()\n#&gt; data {\n#&gt;     int&lt;lower=1&gt; N;\n#&gt;     vector[N] y;\n#&gt; }\n#&gt; parameters {\n#&gt;     real mu;\n#&gt;     real&lt;lower=0&gt; sigma;\n#&gt; }\n#&gt; model {\n#&gt;   y ~ normal(mu, sigma);\n#&gt;   sigma ~ normal(0, 20);\n#&gt;   mu ~ normal(181, 30);\n#&gt; }\n\nCreaiamo un dizionario con i dati in formato appropriato per Stan:\n\nstan_data = list(\n  N = length(df$height),\n  y = df$height\n)\n\nEseguiamo il campionamento:\n\nfit &lt;- mod$sample(\n  data = stan_data,\n  seed = 123,\n  chains = 4,\n  parallel_chains = 4,\n  iter_sampling = 2000, \n  iter_warmup = 2000,\n  show_messages = FALSE\n)\n\nEsaminiamo le distribuzioni a posteriori dei due parametri oggetto dell’inferenza insieme alle loro tracce (cioè i vettori dei campioni dei parametri \\(\\mu\\) e \\(\\sigma\\) prodotti dalla procedura di campionamento MCMC) mediante un trace plot .\n\nmcmc_trace(fit$draws(c(\"mu\", \"sigma\")))\n\n\n\n\n\n\n\nGli istogrammi delle distribuzioni a posteriori si ottengono nel modo seguente:\n\nmcmc_hist(fit$draws(c(\"mu\", \"sigma\")))\n#&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\nUna sintesi delle distribuzioni a posteriori dei parametri si ottiene nel modo seguente.\n\nfit$summary(c(\"mu\", \"sigma\"))\n#&gt; # A tibble: 2 × 10\n#&gt;   variable   mean median    sd   mad     q5    q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 mu       155.   155.   0.421 0.415 154.   155.    1.00    6854.    5308.\n#&gt; 2 sigma      7.77   7.76 0.295 0.290   7.31   8.27  1.00    6442.    5030.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Inferenza bayesiana su una media (Stan) 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean_stan.html#parametrizzazione-non-centrata",
    "href": "chapters/linear_models/05_one_mean_stan.html#parametrizzazione-non-centrata",
    "title": "63  Inferenza bayesiana su una media (Stan) 🔸",
    "section": "\n63.4 Parametrizzazione Non Centrata",
    "text": "63.4 Parametrizzazione Non Centrata\nNella versione precedente del modello Normale abbiamo specificato le distribuzioni a priori per i parametri oggetto dell’inferenza (\\(\\mu\\) e \\(\\sigma\\)) sulla scala dei dati grezzi osservati, i quali hanno una media di 154.6 e una deviazione standard di 7.7. Sul parametro \\(\\mu\\) abbiamo imposto una distribuzione a priori normale con media 181 e deviazione standard 30, e sul parametro \\(\\sigma\\) abbiamo imposto una distribuzione a priori normale con media 0 e deviazione standard 20. Queste distribuzioni a priori sono specifiche per ciascun particolare campione che possiamo osservare.\nÈ possibile usare un approccio diverso, che consente di definire delle distribuzioni a priori sui parametri che sono indipendenti dal particolare campione che osserviamo. Questa procedura è chiamata “parametrizzazione non centrata” (non-centered parametrization). In questo modello, utilizziamo variabili latenti \\(\\mu_{\\text{raw}}\\) e \\(\\sigma_{\\text{raw}}\\), che seguono una distribuzione normale standard:\n\\[\n\\begin{align}\n\\mu_{\\text{raw}} &\\sim \\mathcal{N}(0, 1) \\notag\\\\\n\\sigma_{\\text{raw}} &\\sim \\mathcal{N}(0, 1) \\notag\n\\end{align}\n\\]\nQueste variabili vengono poi trasformate per ottenere i parametri \\(\\mu\\) e \\(\\sigma\\) sulla scala originale:\n\\[\n\\begin{align}\n\\mu &= y_{\\text{mean}} + y_{\\text{sd}} \\cdot \\mu_{\\text{raw}} \\notag\\\\\n\\sigma &= y_{\\text{sd}} \\cdot \\sigma_{\\text{raw}} \\notag\n\\end{align}\n\\]\ndove:\n\n\n\\(y_{\\text{mean}}\\) è la media dei dati osservati \\(y\\).\n\n\\(y_{\\text{sd}}\\) è la deviazione standard dei dati osservati \\(y\\).\n\nDi seguito è riportato il codice Stan per questo modello con la parametrizzazione non centrata:\n\n# Path to the Stan file\nstan_file &lt;- here::here(\"stan\", \"gaussian_ncp.stan\")\n\n# Create a CmdStanModel object\nmod_ncp &lt;- cmdstan_model(stan_file)\n\n\nmod_ncp$print()\n#&gt; data {\n#&gt;     int&lt;lower=1&gt; N;\n#&gt;     vector[N] y;\n#&gt; }\n#&gt; transformed data {\n#&gt;     real y_mean = mean(y);\n#&gt;     real y_sd = sd(y);\n#&gt; }\n#&gt; parameters {\n#&gt;     real mu_raw;\n#&gt;     real&lt;lower=0&gt; sigma_raw;\n#&gt; }\n#&gt; transformed parameters {\n#&gt;     real mu;\n#&gt;     real&lt;lower=0&gt; sigma;\n#&gt;     mu = y_mean + y_sd * mu_raw;\n#&gt;     sigma = y_sd * sigma_raw;\n#&gt; }\n#&gt; model {\n#&gt;     // Priors:\n#&gt;     mu_raw ~ normal(0, 1);\n#&gt;     sigma_raw ~ normal(0, 1);\n#&gt;     // Likelihood:\n#&gt;     y ~ normal(mu, sigma);\n#&gt; }\n#&gt; generated quantities {\n#&gt;     vector[N] y_rep;\n#&gt;     for (n in 1:N) {\n#&gt;         y_rep[n] = normal_rng(mu, sigma);\n#&gt;     }\n#&gt; }\n\nEcco una spiegazione dettagliata del modello Stan con parametrizzazione non centrata.\n\n\nBlocco Dati:\n\n\nint&lt;lower=1&gt; N;: Il numero totale di prove o osservazioni.\n\nvector[N] y;: Il vettore dei punteggi osservati per ciascuna prova. Questi punteggi sono sulla loro scala originale e non standardizzati.\n\n\n\nBlocco Dati Trasformati:\n\n\nreal y_mean = mean(y);: La media dei dati osservati y.\n\nreal y_sd = sd(y);: La deviazione standard dei dati osservati y.\n\n\n\nBlocco Parametri:\n\n\nreal mu_raw;: Un parametro latente che segue una distribuzione normale standard.\n\nreal&lt;lower=0&gt; sigma_raw;: Un parametro latente che segue una distribuzione normale standard vincolata a essere positiva.\n\n\n\nBlocco Parametri Trasformati:\n\nreal mu;: La media della distribuzione normale per y sulla sua scala originale.\nreal&lt;lower=0&gt; sigma;: La deviazione standard della distribuzione normale per y sulla sua scala originale.\n\nQuesti parametri trasformati sono definiti come:\nmu = y_mean + y_sd * mu_raw;\nsigma = y_sd * sigma_raw;\n\n\n\n\nLa parametrizzazione non centrata comporta la riparametrizzazione del modello in termini di variabili standardizzate (mu_raw e sigma_raw) e poi la loro trasformazione di nuovo sulla scala originale dei dati. Questo approccio spesso porta a una migliore efficienza di campionamento e proprietà di convergenza, specialmente nei modelli gerarchici.\n\n\nParametri Latenti (mu_raw e sigma_raw):\n\n\nmu_raw ~ normal(0, 1);: mu_raw è una variabile normale standardizzata.\n\nsigma_raw ~ normal(0, 1);: sigma_raw è una variabile normale standardizzata vincolata a essere positiva.\n\n\n\nTrasformazione alla Scala Originale:\n\n\nmu = y_mean + y_sd * mu_raw;: Questo scala e trasla mu_raw alla posizione e scala dei dati osservati y.\n\nsigma = y_sd * sigma_raw;: Questo scala sigma_raw alla scala dei dati osservati y.\n\n\n\nLa dichiarazione della verosimiglianza y ~ normal(mu, sigma); indica che i dati osservati y seguono una distribuzione normale con media mu e deviazione standard sigma. Ecco perché ha senso anche se y è sulla sua scala originale:\n\n\nDati Osservati sulla Scala Originale: I dati osservati y sono sulla loro scala originale.\n\nParametri sulla Scala Originale: I parametri mu e sigma, dopo la trasformazione nel blocco transformed parameters, sono anch’essi sulla scala originale di y.\n\nQuindi, la dichiarazione y ~ normal(mu, sigma); specifica correttamente che i dati osservati y (sulla loro scala originale) sono modellati da una distribuzione normale con media mu e deviazione standard sigma, entrambe sulla scala originale di y.\nInfine, il blocco generated quantities viene utilizzato per i controlli predittivi posteriori generando nuovi dati (y_rep) dalla distribuzione posteriore dei parametri (mu e sigma):\ngenerated quantities {\n    vector[N] y_rep;\n    for (n in 1:N) {\n        y_rep[n] = normal_rng(mu, sigma);\n    }\n}\n\n\ny_rep: Questo genera punti dati replicati dalla distribuzione normale con la media posteriore mu e la deviazione standard posteriore sigma. Questo ti permette di confrontare le previsioni del modello con i dati osservati per eseguire controlli predittivi posteriori.\n\nEseguiamo il campionamento MCMC per il modello che segue una parametrizzazione non centrata:\n\nfit_ncp &lt;- mod_ncp$sample(\n  data = stan_data,\n  seed = 123,\n  chains = 4,\n  parallel_chains = 4,\n  iter_sampling = 2000, \n  iter_warmup = 2000,\n  show_messages = FALSE\n)\n\nEsaminiamo la distribuzioni a posteriori e le tracce dei parametri \\(\\mu\\) e \\(\\sigma\\):\n\nmcmc_hist(fit_ncp$draws(c(\"mu\", \"sigma\")))\n#&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nmcmc_trace(fit_ncp$draws(c(\"mu\", \"sigma\")))\n\n\n\n\n\n\n\nOtteniamo una sintesi delle distribuzioni a posteriori dei parametri:\n\nfit_ncp$summary(c(\"mu\", \"sigma\"))\n#&gt; # A tibble: 2 × 10\n#&gt;   variable   mean median    sd   mad     q5    q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 mu       155.   155.   0.412 0.415 154.   155.    1.00    5880.    4902.\n#&gt; 2 sigma      7.76   7.75 0.292 0.291   7.30   8.26  1.00    7200.    5446.\n\nI risultati sono molto simili a quelli ottenuti in precedenza.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Inferenza bayesiana su una media (Stan) 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean_stan.html#posterior-predictive-check",
    "href": "chapters/linear_models/05_one_mean_stan.html#posterior-predictive-check",
    "title": "63  Inferenza bayesiana su una media (Stan) 🔸",
    "section": "\n63.5 Posterior predictive check",
    "text": "63.5 Posterior predictive check\nUno dei vantaggi del toolkit bayesiano è che una volta ottenuta la distribuzione a posteriori congiunta dei parametri p(θ|Y) è possibile utilizzarla per generare le previsioni p(Ỹ). Matematicamente, questo può essere fatto calcolando:\n\\[\np(\\tilde{y} \\mid y) = \\int p(\\tilde{y} \\mid \\theta) p(\\theta \\mid y) d\\theta.\n\\]\nQuesta distribuzione è nota come distribuzione predittiva posteriore. È predittiva perché viene utilizzata per fare previsioni e posteriore perché è calcolata utilizzando la distribuzione posteriore. Quindi possiamo pensare a questa come la distribuzione dei dati futuri dati il modello e i dati osservati.\nUtilizzando Stan è facile per ottenere campioni predittivi posteriori: non è necessario calcolare alcun integrale. Dobbiamo convertire l’oggetto creato dalla funzione sample() nel formato richesto da {bayesplot}. Estraiamo i dati prodotti dal modello y_rep e i dati osservati y:\n\n# Extract posterior predictive samples for y_rep\ny_rep &lt;- fit_ncp$draws(variables = \"y_rep\", format = \"draws_matrix\")\n\n# Extract observed data\ny_obs &lt;- stan_data$y\n\nConvertiamo y_rep in una matrice per compatibilità con {bayesplot}.\n\n# Convert y_rep to a matrix\ny_rep_matrix &lt;- as.matrix(y_rep)\n\nGeneriamo il posterior predictive chech plot:\n\n# Posterior predictive check plot\nset.seed(123)\nselected_indices &lt;- sample(nrow(y_rep_matrix), 50)\nppc_dens_overlay(y = y_obs, yrep = y_rep_matrix[selected_indices, ])\n\n\n\n\n\n\n\nUn uso comune della distribuzione predittiva posteriore è quello di eseguire controlli predittivi posteriori. Questi sono un insieme di test che possono essere utilizzati per verificare se il modello è una buona rappresentazione dei dati. Nella figura, la linea nera rappresenta una KDE (Kernel Density Estimation) dei dati, mentre le linee grigie sono KDE calcolate da ciascuno dei 50 campioni predittivi posteriori. Le linee grigie riflettono l’incertezza associata alla distribuzione dei dati previsti.\nDato che il tracciato del KDE plot è contenuto nell’insieme di profili dei KDE plot dei campioni predittivi a posteriori, si può concludere che il modello utilizzato offre una rappresentazione adeguata dei dati ed è utile per la maggior parte delle analisi. Tuttavia, è importante considerare che potrebbero esistere altri modelli in grado di adattarsi meglio all’intero dataset. Esploreremo ora come poter sviluppare un modello alternativo.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Inferenza bayesiana su una media (Stan) 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean_stan.html#modello-robusto",
    "href": "chapters/linear_models/05_one_mean_stan.html#modello-robusto",
    "title": "63  Inferenza bayesiana su una media (Stan) 🔸",
    "section": "\n63.6 Modello “robusto”",
    "text": "63.6 Modello “robusto”\nNon è necessario presupporre che i dati seguano una distribuzione gaussiana. Le lievi deviazioni dalla gaussianità possono essere considerate attraverso l’utilizzo della distribuzione t di Student, che è particolarmente utile quando queste deviazioni si manifestano nelle code della distribuzione, come sembra essere il caso in questa situazione. Pertanto, proponiamo di adottare un modello ‘robusto’, maggiormente adatto a gestire osservazioni che si discostano dalla normalità nelle code della distribuzione.\nLa distribuzione \\(t\\) di Student è caratterizzata dal parametro \\(\\nu\\), noto come ‘gradi di libertà’. Quando \\(\\nu\\) è pari o superiore a 30, la distribuzione t di Student diventa quasi indistinguibile da una distribuzione normale.\n\n# Creare una funzione per generare dati di distribuzione t per un dato numero di gradi di libertà (nu)\ngenerate_t_data &lt;- function(nu, n = 1000) {\n  x &lt;- seq(-5, 5, length.out = n)\n  y &lt;- dt(x, df = nu)\n  data.frame(x = x, y = y, nu = as.factor(nu))\n}\n\n# Valori di nu\nnu_values &lt;- c(1, 2, 10, Inf)  # Include infinito direttamente nella lista\n\n# Genera i dati per ciascun nu\ndata_list &lt;- lapply(nu_values, generate_t_data)\ndata &lt;- do.call(rbind, data_list)\n\n# Crea il grafico\np &lt;- ggplot(data, aes(x = x, y = y, color = nu, group = nu)) +\n  geom_line() +\n  scale_color_manual(values = c(\"#F8766D\", \"#00BA38\", \"#619CFF\", \"black\")) +  # Personalizza i colori\n  labs(title = \"Densità della Distribuzione t di Student\",\n       x = \"x\",\n       y = \"Densità\",\n       color = \"Gradi di libertà ν\")\n\n# Stampa il grafico\nprint(p)\n\n\n\n\n\n\n\nTuttavia, le code della distribuzione t di Student risultano più pesanti rispetto a quelle della normale quando \\(\\nu\\) è basso. Pertanto, proponiamo di assegnare a \\(\\nu\\) una distribuzione a priori che concentri la maggior parte della sua massa su valori bassi, come ad esempio una distribuzione esponenziale con un parametro di rate pari a 1/30.\n\n# Definisci il parametro di rate per la distribuzione esponenziale\nrate &lt;- 1 / 30\n\n# Genera campioni dalla distribuzione esponenziale\nsamples &lt;- rexp(10000, rate = rate)\n\n# Crea l'istogramma dei campioni\np &lt;- ggplot(data.frame(Values = samples), aes(x = Values)) +\n  geom_histogram(aes(y = ..density..), bins = 50, alpha = 0.75, fill = \"lightgray\") +\n  ggtitle(\"Exponential Distribution (λ = 1/30)\") +\n  xlab(\"Values\") +\n  ylab(\"Density\") +\n  theme(legend.position = \"none\") + \n  geom_density(col = \"black\", size = 1) # Aggiunge una linea di densità per il confronto\n#&gt; Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#&gt; ℹ Please use `linewidth` instead.\n\n# Visualizza il grafico\nprint(p)\n#&gt; Warning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\n#&gt; ℹ Please use `after_stat(density)` instead.\n\n\n\n\n\n\n\n\n# Path to the Stan file\nstan_file &lt;- here::here(\"stan\", \"student-model.stan\")\n\n# Create a CmdStanModel object\nmod_t &lt;- cmdstan_model(stan_file)\n\n\nmod_t$print()\n#&gt; data {\n#&gt;     int&lt;lower=1&gt; N;  // Numero totale di prove\n#&gt;     vector[N] y;  // Punteggio in ciascuna prova\n#&gt; }\n#&gt; transformed data {\n#&gt;     real y_mean = mean(y);  // Media dei dati osservati\n#&gt;     real y_sd = sd(y);  // Deviazione standard dei dati osservati\n#&gt; }\n#&gt; parameters {\n#&gt;     real mu_raw;  // Parametro latente standardizzato per mu\n#&gt;     real&lt;lower=0&gt; sigma_raw;  // Parametro latente standardizzato per sigma\n#&gt;     real&lt;lower=1&gt; nu;  // Gradi di libertà per la distribuzione t di Student\n#&gt; }\n#&gt; transformed parameters {\n#&gt;     real mu;  // Media sulla scala originale\n#&gt;     real&lt;lower=0&gt; sigma;  // Deviazione standard sulla scala originale\n#&gt;     mu = y_mean + y_sd * mu_raw;\n#&gt;     sigma = y_sd * sigma_raw;\n#&gt; }\n#&gt; model {\n#&gt;     // Distribuzioni a priori non centrate\n#&gt;     mu_raw ~ normal(0, 1);\n#&gt;     sigma_raw ~ normal(0, 1);\n#&gt;     nu ~ exponential(1.0 / 30.0);  // Prior esponenziale per i gradi di libertà\n#&gt;     // Verosimiglianza\n#&gt;     y ~ student_t(nu, mu, sigma);\n#&gt; }\n#&gt; generated quantities {\n#&gt;     vector[N] y_rep;\n#&gt;     for (n in 1:N) {\n#&gt;         y_rep[n] = student_t_rng(nu, mu, sigma);\n#&gt;     }\n#&gt; }\n\nEseguiamo il campionamento MCMC:\n\nfit_t &lt;- mod_t$sample(\n  data = stan_data,\n  seed = 123,\n  chains = 4,\n  parallel_chains = 4,\n  iter_sampling = 2000, \n  iter_warmup = 2000,\n  show_messages = FALSE\n)\n\nEsaminiamo la distribuzioni a posteriori e le tracce dei parametri \\(\\mu\\) e \\(\\sigma\\):\n\nmcmc_hist(fit_t$draws(c(\"mu\", \"sigma\")))\n#&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nmcmc_trace(fit_t$draws(c(\"mu\", \"sigma\")))\n\n\n\n\n\n\n\nGeneriamo la distribuzione predittiva a posteriori.\n\n# Extract posterior predictive samples for y_rep\ny_rep &lt;- fit_t$draws(variables = \"y_rep\", format = \"draws_matrix\")\n# Convert y_rep to a matrix\ny_rep_matrix &lt;- as.matrix(y_rep)\n# Posterior predictive check plot\nselected_indices &lt;- sample(nrow(y_rep_matrix), 50)\nppc_dens_overlay(y = y_obs, yrep = y_rep_matrix[selected_indices, ])\n\n\n\n\n\n\n\nLa figura illustra che la situazione è analoga a quella del caso gaussiano. Questo non è sorprendente, dato che i dati relativi all’altezza si distribuiscono in maniera gaussiana nella popolazione. Pertanto, l’impiego della distribuzione \\(t\\) di Student o della distribuzione normale producono risultati sostanzialmente equivalenti in questo contesto.\n\nfit_t$summary(c(\"mu\", \"sigma\"))\n#&gt; # A tibble: 2 × 10\n#&gt;   variable   mean median    sd   mad     q5    q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 mu       155.   155.   0.413 0.409 154.   155.    1.00    7996.    6269.\n#&gt; 2 sigma      7.64   7.62 0.306 0.301   7.16   8.16  1.00    6869.    5961.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Inferenza bayesiana su una media (Stan) 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean_stan.html#riflessioni-conclusive",
    "href": "chapters/linear_models/05_one_mean_stan.html#riflessioni-conclusive",
    "title": "63  Inferenza bayesiana su una media (Stan) 🔸",
    "section": "\n63.7 Riflessioni Conclusive",
    "text": "63.7 Riflessioni Conclusive\nIn questo capitolo abbiamo esplorato il metodo per calcolare l’intervallo di credibilità per la media di una variabile casuale normale utilizzando Stan. Inoltre, abbiamo illustrato come sia possibile ampliare l’inferenza sulla media utilizzando un modello robusto basato sulla distribuzione t di Student.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Inferenza bayesiana su una media (Stan) 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean_stan.html#esercizi",
    "href": "chapters/linear_models/05_one_mean_stan.html#esercizi",
    "title": "63  Inferenza bayesiana su una media (Stan) 🔸",
    "section": "\n63.8 Esercizi",
    "text": "63.8 Esercizi\n\nEsercizio 63.1 Utilizzando i dati dell’esempio sui bambini plusdotati discusso nella ?sec-grid-gauss, impiegare Stan per replicare i risultati ottenuti con il metodo basato su griglia.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Inferenza bayesiana su una media (Stan) 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean_stan.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/05_one_mean_stan.html#informazioni-sullambiente-di-sviluppo",
    "title": "63  Inferenza bayesiana su una media (Stan) 🔸",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] bayestestR_0.15.0   posterior_1.6.0     cmdstanr_0.8.1.9000\n#&gt;  [4] see_0.9.0           gridExtra_2.3       patchwork_1.3.0    \n#&gt;  [7] bayesplot_1.11.1    psych_2.4.12        scales_1.3.0       \n#&gt; [10] markdown_1.13       knitr_1.49          lubridate_1.9.4    \n#&gt; [13] forcats_1.0.0       stringr_1.5.1       dplyr_1.1.4        \n#&gt; [16] purrr_1.0.2         readr_2.1.5         tidyr_1.3.1        \n#&gt; [19] tibble_3.2.1        ggplot2_3.5.1       tidyverse_2.0.0    \n#&gt; [22] rio_1.2.3           here_1.0.1         \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6         tensorA_0.36.2.1     xfun_0.49           \n#&gt;  [4] htmlwidgets_1.6.4    insight_1.0.0        processx_3.8.4      \n#&gt;  [7] lattice_0.22-6       tzdb_0.4.0           ps_1.8.1            \n#&gt; [10] vctrs_0.6.5          tools_4.4.2          generics_0.1.3      \n#&gt; [13] parallel_4.4.2       pacman_0.5.1         pkgconfig_2.0.3     \n#&gt; [16] R.oo_1.27.0          data.table_1.16.4    checkmate_2.3.2     \n#&gt; [19] distributional_0.5.0 lifecycle_1.0.4      compiler_4.4.2      \n#&gt; [22] farver_2.1.2         munsell_0.5.1        mnormt_2.1.1        \n#&gt; [25] htmltools_0.5.8.1    yaml_2.3.10          pillar_1.10.0       \n#&gt; [28] R.utils_2.12.3       abind_1.4-8          nlme_3.1-166        \n#&gt; [31] tidyselect_1.2.1     digest_0.6.37        stringi_1.8.4       \n#&gt; [34] reshape2_1.4.4       labeling_0.4.3       rprojroot_2.0.4     \n#&gt; [37] fastmap_1.2.0        grid_4.4.2           colorspace_2.1-1    \n#&gt; [40] cli_3.6.3            magrittr_2.0.3       utf8_1.2.4          \n#&gt; [43] withr_3.0.2          backports_1.5.0      timechange_0.3.0    \n#&gt; [46] rmarkdown_2.29       matrixStats_1.4.1    R.methodsS3_1.8.2   \n#&gt; [49] hms_1.1.3            evaluate_1.0.1       rlang_1.1.4         \n#&gt; [52] Rcpp_1.0.13-1        glue_1.8.0           jsonlite_1.8.9      \n#&gt; [55] plyr_1.8.9           R6_2.5.1",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Inferenza bayesiana su una media (Stan) 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean_stan.html#bibliografia",
    "href": "chapters/linear_models/05_one_mean_stan.html#bibliografia",
    "title": "63  Inferenza bayesiana su una media (Stan) 🔸",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Inferenza bayesiana su una media (Stan) 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_prediction_stan.html",
    "href": "chapters/linear_models/06_prediction_stan.html",
    "title": "64  Predizione e inferenza 🔸",
    "section": "",
    "text": "64.1 Introduzione\nGelman et al. (2021) osservano che l’inferenza bayesiana si sviluppa in tre passaggi fondamentali, che vanno oltre la stima classica. In primo luogo, i dati e il modello vengono combinati per formare una distribuzione a posteriori, che solitamente viene riassunta tramite le distribuzioni a posteriori dei parametri del modello. In secondo luogo, è possibile propagare l’incertezza presente in questa distribuzione, ottenendo previsioni basate su simulazioni per risultati non osservati o futuri, tenendo conto dell’incertezza nei parametri del modello. Infine, è possibile integrare ulteriori informazioni nel modello utilizzando una distribuzione a priori. Questo capitolo si concentra sui temi della previsione e dell’inferenza.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>Predizione e inferenza 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_prediction_stan.html#predizione",
    "href": "chapters/linear_models/06_prediction_stan.html#predizione",
    "title": "64  Predizione e inferenza 🔸",
    "section": "\n64.2 Predizione",
    "text": "64.2 Predizione\nPer discutere i temi della predizione e dell’inferenza bayesiana nel contesto del modello bayesiano di regressione lineare bivariata, esamineremo nuovamente il set di esaminati nel ?sec-bivariate-bayesian-regression e relativi alla relazione tra Tense Arousal e ansia di stato.\n\ndf &lt;- rio::import(here::here(\"data\", \"affect.csv\")) |&gt; \n  dplyr::select(state1, TA1)\ndf |&gt; \n  head()\n#&gt;   state1 TA1\n#&gt; 1     41  11\n#&gt; 2     26   5\n#&gt; 3     31   8\n#&gt; 4     28   8\n#&gt; 5     47  12\n#&gt; 6     43  10\n\nConsideriamo il modello bayesiano di regressione lineare bivariata che include prior uniformi per i parametri \\(\\alpha\\), \\(\\beta\\) e \\(\\sigma\\) che abbiamo discusso nel ?sec-bivariate-bayesian-regression. Compiliamo il modello.\n\nmodel &lt;- cmdstan_model(here::here(\"stan\", \"arousal_model_prior_raw.stan\"))\n\nIl modello ha questa forma:\n\nmodel$print()\n#&gt; data {\n#&gt;   int&lt;lower=1&gt; N; // numero totale di osservazioni \n#&gt;   vector[N] y; // variabile di risposta\n#&gt;   vector[N] x; // variabile predittore\n#&gt; }\n#&gt; parameters {\n#&gt;   real alpha; // intercetta\n#&gt;   real beta; // coefficiente angolare\n#&gt;   real&lt;lower=0&gt; sigma; // deviazione standard residua\n#&gt; }\n#&gt; model {\n#&gt;   // distribuzioni a priori\n#&gt;   alpha ~ normal(0, 5.0);\n#&gt;   beta ~ normal(0, 2.5);\n#&gt;   sigma ~ cauchy(0, 5.0);\n#&gt;   // verosimiglianza\n#&gt;   y ~ normal(alpha + beta * x, sigma);\n#&gt; }\n\nSistemiamo i dati in un dizionario come richiesto dal modello Stan.\n\nstan_data = list(\n  N = length(df$TA1),\n  x = df$state1,\n  y = df$TA1\n)\n\nEseguiamo il campionamento MCMC.\n\nfit1 &lt;- model$sample(\n  data = stan_data,\n  seed = 123,\n  iter_warmup = 2000,\n  iter_sampling = 2000,\n  show_message = FALSE\n)\n\nEsaminiamo le distribuzioni a posteriori dei parametri:\n\nfit1$summary(variables = c(\"alpha\", \"beta\", \"sigma\"))\n#&gt; # A tibble: 3 × 10\n#&gt;   variable  mean median     sd    mad     q5   q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 alpha    1.47   1.48  1.22   1.19   -0.528 3.46   1.00    2644.    3145.\n#&gt; 2 beta     0.269  0.269 0.0286 0.0279  0.223 0.316  1.00    2671.    3143.\n#&gt; 3 sigma    2.70   2.68  0.222  0.216   2.37  3.09   1.00    3463.    3616.\n\nIl punto importante qui è che la distribuzione a posteriori non fornisce solo informazioni sui singoli parametri, ma anche sulle loro interdipendenze. Queste relazioni sono riflesse nei campioni a posteriori, che possono essere trasformati in vari modi. Ad esempio, possiamo calcolare la predizione a posteriori del modello lineare per il valore atteso di Tense Arousal quando l’ansia di stato è pari a 30 usando il seguente comando nel blocco generated quantities:\npred = alpha + beta * 30;\nModifichiamo il modello Stan che include la specifica di distribuzioni debolmente informative sui parametri \\(\\alpha\\), \\(\\beta\\) e \\(\\sigma\\) per aggiungere questo comando nel blocco generated quantities e compiliamo il modello.\n\nmodel2 &lt;- cmdstan_model(here::here(\"stan\", \"arousal_model2.stan\"))\n\nIl modello ha questa forma:\n\nmodel2$print()\n#&gt; data {\n#&gt;   int&lt;lower=1&gt; N; // numero totale di osservazioni \n#&gt;   vector[N] y; // variabile di risposta\n#&gt;   vector[N] x; // variabile predittore\n#&gt; }\n#&gt; parameters {\n#&gt;   real alpha; // intercetta\n#&gt;   real beta; // coefficiente angolare\n#&gt;   real&lt;lower=0&gt; sigma; // deviazione standard residua\n#&gt; }\n#&gt; model {\n#&gt;   // distribuzioni a priori\n#&gt;   alpha ~ normal(0, 5.0);\n#&gt;   beta ~ normal(0, 2.5);\n#&gt;   sigma ~ cauchy(0, 5.0);\n#&gt;   // verosimiglianza\n#&gt;   y ~ normal(alpha + beta * x, sigma);\n#&gt; }\n#&gt; generated quantities {\n#&gt;   real pred; // predizione\n#&gt;   \n#&gt;   pred = alpha + beta * 30;\n#&gt; }\n\nIn questo modello Stan aggiornato, il blocco generated quantities calcola la predizione a posteriori pred per una variabile predittore con valore 30. Questa modifica permette di ottenere la distribuzione a posteriori della predizione per un valore specifico del predittore.\nEseguiamo il campionamento.\n\nfit2 &lt;- model2$sample(\n  data = stan_data,\n  seed = 123,\n  iter_warmup = 2000,\n  iter_sampling = 2000,\n  show_message = FALSE\n)\n\nEsaminiamo la stima a posteriori del valore atteso di Tense Arousal quando l’ansia di stato è pari a 30. Questa analisi fornirà sia una stima puntuale di Tense Arousal che una misura dell’incertezza associata, rappresentata dall’intervallo di credibilità al livello di confidenza scelto.\n\nfit2$summary(variables = \"pred\")\n#&gt; # A tibble: 1 × 10\n#&gt;   variable  mean median    sd   mad    q5   q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 pred      9.54   9.54 0.442 0.431  8.82  10.3  1.00    3443.    4427.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>Predizione e inferenza 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_prediction_stan.html#quantificazione-dellincertezza",
    "href": "chapters/linear_models/06_prediction_stan.html#quantificazione-dellincertezza",
    "title": "64  Predizione e inferenza 🔸",
    "section": "\n64.3 Quantificazione dell’incertezza",
    "text": "64.3 Quantificazione dell’incertezza\nPer quantificare l’incertezza complessiva nelle predizioni del modello, possiamo calcolare la distribuzione a posteriori delle predizioni per tutti i valori di \\(x\\) del campione. Questo ci permette di ottenere sia le stime puntuali delle predizioni sia una misura dell’incertezza associata.\nPer fare ciò, modifichiamo il blocco generated quantities nel seguente modo:\ngenerated quantities {\n  vector[N] y_rep; // Predizioni a posteriori per ciascun valore di x\n  \n  for (n in 1:N) {\n    y_rep[n] = normal_rng(alpha + beta * x[n], sigma);\n  }\n}\nEsaminiamo le modifiche:\n\n\nDichiarazione del vettore y_rep:\n\n\nvector[N] y_rep;: Dichiara un vettore y_rep di lunghezza N per contenere le predizioni a posteriori per ciascun valore di x.\n\n\n\nCiclo for per generare le predizioni:\n\n\nfor (n in 1:N): Itera su tutte le osservazioni.\n\ny_rep[n] = normal_rng(alpha + beta * x[n], sigma);: Per ogni valore di x[n], genera una predizione dalla distribuzione normale con media alpha + beta * x[n] e deviazione standard sigma. La funzione normal_rng genera numeri casuali dalla distribuzione normale specificata, rappresentando l’incertezza nelle predizioni.\n\n\n\nQuesto approccio consente di ottenere la distribuzione a posteriori delle predizioni, fornendo una visione completa dell’incertezza associata. Dalla distribuzione a posteriori di y_rep, possiamo calcolare sia la stima puntuale (come la media o la mediana delle predizioni) sia gli intervalli di credibilità (come l’intervallo al 95%) per ogni valore di x. Questo offre una misura dell’incertezza delle predizioni, riflettendo la variabilità e l’affidabilità del modello.\nModifichiamo il modello imponendo distribuzioni a priori debolmente informative sui parametri:\n\nPer \\(\\alpha\\) e \\(\\beta\\), utilizziamo una distribuzione Normale centrata su 0 con una deviazione standard di 2.\nPer \\(\\sigma\\), utilizziamo una distribuzione di Cauchy centrata su 0 con una scala di 2.\n\n\nmodel3 &lt;- cmdstan_model(here::here(\"stan\", \"arousal_model3.stan\"))\n\nIl modello ha questa forma:\n\nmodel3$print()\n#&gt; data {\n#&gt;   int&lt;lower=1&gt; N; // numero totale di osservazioni \n#&gt;   vector[N] y; // variabile di risposta\n#&gt;   vector[N] x; // variabile predittore\n#&gt; }\n#&gt; parameters {\n#&gt;   real alpha; // intercetta\n#&gt;   real beta; // coefficiente angolare\n#&gt;   real&lt;lower=0&gt; sigma; // deviazione standard residua\n#&gt; }\n#&gt; model {\n#&gt;   // distribuzioni a priori\n#&gt;   alpha ~ normal(0, 5.0);\n#&gt;   beta ~ normal(0, 1.0);\n#&gt;   sigma ~ cauchy(0, 1.0);\n#&gt;   // verosimiglianza\n#&gt;   y ~ normal(alpha + beta * x, sigma);\n#&gt; }\n#&gt; generated quantities {\n#&gt;   vector[N] y_rep; // variabili predette\n#&gt;   \n#&gt;   for (n in 1 : N) {\n#&gt;     y_rep[n] = normal_rng(alpha + beta * x[n], sigma);\n#&gt;   }\n#&gt; }\n\nEseguiamo il campionamento.\n\nfit3 &lt;- model3$sample(\n  data = stan_data,\n  seed = 123,\n  iter_warmup = 2000,\n  iter_sampling = 2000,\n  show_message = FALSE\n)\n\nEsaminiamo la distribuzione a posteriori dei parametri.\n\nfit3$summary(variables = c(\"alpha\", \"beta\", \"sigma\"))\n#&gt; # A tibble: 3 × 10\n#&gt;   variable  mean median     sd    mad     q5   q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 alpha    1.44   1.42  1.23   1.19   -0.545 3.47   1.00    2185.    2421.\n#&gt; 2 beta     0.270  0.270 0.0287 0.0277  0.222 0.317  1.00    2050.    2391.\n#&gt; 3 sigma    2.68   2.66  0.219  0.220   2.35  3.06   1.00    3724.    3418.\n\n\n64.3.1 Manipolare le Stime a Posteriori dei Parametri\nCostruiamo un grafico che rappresenta i valori osservati e la linea di regressione stimata tramite un modello bayesiano. Al grafico aggiungeremo diverse linee di regressione, ognuna basata su valori campionati casualmente dalla distribuzione a posteriori dei parametri \\(\\alpha\\) e \\(\\beta\\).\n\n64.3.1.1 Recuperare le Stime a Posteriori\nCon cmdstanr, i risultati del campionamento sono accessibili come oggetti draws_matrix, draws_array, o draws_df. Per estrarre le distribuzioni a posteriori di specifici parametri, possiamo usare il metodo draws() o as_draws_df(). Ad esempio, per estrarre i campioni di \\(\\alpha\\) e \\(\\beta\\) dall’oggetto fit3, utilizziamo:\n\n# Estrazione dei campioni a posteriori\nalpha_samples &lt;- as_draws_df(fit3)$alpha\nbeta_samples &lt;- as_draws_df(fit3)$beta\n\nStampiamo i primi 20 valori di alpha_samples per verificare:\n\nhead(alpha_samples, 20)\n#&gt;  [1]  2.0171  2.3731  1.1427  2.8008  3.1059  1.7701  1.7726  0.5296  1.8151\n#&gt; [10]  0.0353  0.1250  0.7225 -0.0975 -0.3649  0.0669 -1.4457 -2.3480 -1.8796\n#&gt; [19] -1.9525 -0.1565\n\n\n64.3.1.2 Calcolare le Stime Puntuali\nPossiamo calcolare la media a posteriori dei parametri per stimare la retta di regressione media:\n\nmean_alpha &lt;- mean(alpha_samples)\nmean_beta &lt;- mean(beta_samples)\n\ncat(\"Mean alpha:\", mean_alpha, \"\\nMean beta:\", mean_beta)\n#&gt; Mean alpha: 1.44 \n#&gt; Mean beta: 0.27\n\n\n64.3.1.3 Grafico della Regressione con Incertezza\nSovrapponiamo una retta di regressione media e linee basate sui campioni a posteriori:\n\n# Dati osservati\nx &lt;- df$state1\ny &lt;- df$TA1\n\n# Creazione del data frame per ggplot\nplot_data &lt;- data.frame(x = x, y = y)\n\n# Costruzione del grafico\nggplot(plot_data, aes(x = x, y = y)) +\n  geom_point(color = \"blue\", size = 1) +\n  # Linee di regressione basate sui campioni\n  geom_abline(aes(intercept = mean_alpha, slope = mean_beta),\n              color = \"red\", size = 1, alpha = 0.8) +\n  lapply(1:300, function(i) {\n    geom_abline(aes(intercept = alpha_samples[i], slope = beta_samples[i]),\n                color = \"gray\", alpha = 0.1)\n  }) +\n  labs(\n    title = \"Regressione con Incertezza Posteriori\",\n    x = \"State Anxiety\",\n    y = \"Tense Arousal\"\n  ) \n#&gt; Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#&gt; ℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n64.3.1.4 Incertezza delle Predizioni con \\(\\texttt{y\\_rep}\\)\n\nUn approccio alternativo consiste nel rappresentare l’incertezza delle predizioni usando \\(\\texttt{y\\_rep}\\), la distribuzione a posteriori delle osservazioni simulate:\n\n# Estrazione dei campioni posteriori di y_rep\ny_rep_samples &lt;- as_draws_df(fit3)\ny_rep_matrix &lt;- y_rep_samples[, grep(\"y_rep\", colnames(y_rep_samples))]\n#&gt; Warning: Dropping 'draws_df' class as required metadata was removed.\n\n# Compute posterior mean and intervals\ny_rep_mean &lt;- colMeans(y_rep_matrix)\ny_rep_lower &lt;- apply(y_rep_matrix, 2, quantile, 0.025)\ny_rep_upper &lt;- apply(y_rep_matrix, 2, quantile, 0.975)\n\n# Create plot_data with y_rep summaries\nplot_data &lt;- data.frame(\n  x = df$state1,\n  y = df$TA1,\n  y_rep_mean = y_rep_mean,\n  y_rep_lower = y_rep_lower,\n  y_rep_upper = y_rep_upper\n)\n\nggplot(plot_data, aes(x = x, y = y)) +\n  geom_point(color = \"blue\", size = 1) +\n  geom_line(aes(y = y_rep_mean), color = \"red\", size = 1, alpha = 0.8) +\n  geom_ribbon(aes(ymin = y_rep_lower, ymax = y_rep_upper),\n              fill = \"gray\", alpha = 0.3) +\n  labs(\n    title = \"Incertezza delle Predizioni del Modello\",\n    x = \"State Anxiety\",\n    y = \"Tense Arousal\"\n  ) \n\n\n\n\n\n\n\n\n64.3.1.5 Confronto tra Approcci\n\n\nDistribuzioni a Posteriori di \\(\\alpha\\) e \\(\\beta\\):\n\nVisualizza l’incertezza nei parametri del modello (\\(\\alpha\\) e \\(\\beta\\)).\nLe linee di regressione rappresentano variazioni nella pendenza e intercetta dovute all’incertezza dei parametri.\n\n\n\nDistribuzione a Posteriori di \\(\\texttt{y\\_rep}\\):\n\nInclude sia l’incertezza dei parametri sia la variabilità residua (\\(\\sigma\\)).\nFornisce una descrizione più completa dell’incertezza predittiva.\n\n\n\nEntrambi gli approcci sono utili per esplorare diverse sfaccettature dell’incertezza nel modello bayesiano.\nNel primo approccio, calcoliamo l’incertezza delle predizioni utilizzando le distribuzioni a posteriori di alpha e beta. Questo metodo consiste nel generare predizioni lineari per ciascun campione a posteriori di alpha e beta, tracciando quindi le linee di regressione risultanti. Questo ci permette di vedere come varia la linea di regressione in base alle incertezze nei parametri alpha e beta. Questo metodo visualizza come l’incertezza nei parametri del modello si traduce in incertezza nelle predizioni.\nNel secondo approccio, descriviamo l’incertezza delle predizioni utilizzando direttamente la distribuzione a posteriori di y_rep. In questo caso, generiamo predizioni per ciascun valore osservato di x nel modello Stan, tenendo conto delle distribuzioni a posteriori dei parametri del modello. Questo metodo visualizza direttamente l’incertezza nelle predizioni, tenendo conto delle variazioni nei dati osservati e delle distribuzioni a posteriori dei parametri.\nLe due descrizioni dell’incertezza delle predizioni del modello sono diverse perché riflettono aspetti differenti della distribuzione a posteriori:\n\nDistribuzione a posteriori di alpha e beta: Questo approccio considera solo l’incertezza nei parametri del modello (alpha e beta). Le linee di regressione tracciate variano in base a questi parametri, ma non tengono conto dell’incertezza residua (sigma).\nDistribuzione a posteriori di y_rep: Questo approccio include non solo l’incertezza nei parametri alpha e beta, ma anche l’incertezza residua (sigma). La distribuzione di y_rep riflette la variabilità totale nel modello, inclusa la variabilità nei dati osservati. Pertanto, l’incertezza nelle predizioni è maggiore perché tiene conto di tutte le fonti di variabilità.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>Predizione e inferenza 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_prediction_stan.html#posterior-predictive-check",
    "href": "chapters/linear_models/06_prediction_stan.html#posterior-predictive-check",
    "title": "64  Predizione e inferenza 🔸",
    "section": "\n64.4 Posterior-predictive check",
    "text": "64.4 Posterior-predictive check\nIl Posterior Predictive Check (PPC) è un passaggio cruciale nella modellazione bayesiana, che ci permette di valutare quanto bene il modello si adatta ai dati osservati, tenendo conto delle informazioni aggiornate dai dati stessi. L’idea alla base del PPC è confrontare le predizioni del modello, basate sulla distribuzione a posteriori dei parametri, con i dati reali, per vedere se il modello riesce a catturare correttamente le caratteristiche dei dati osservati.\n\nDopo aver adattato il modello ai dati, otteniamo campioni dai parametri a posteriori (\\(\\alpha\\), \\(\\beta\\), \\(\\sigma\\)). Questi campioni riflettono le nostre credenze aggiornate sui parametri, basate sia sulle distribuzioni a priori che sui dati osservati.\nUtilizzando i campioni della distribuzione a posteriori, simuliamo nuovi dati predetti (\\(y_{rep}\\)). Questi dati simulati rappresentano le previsioni del modello, date le nostre stime a posteriori dei parametri.\nConfrontiamo le osservazioni simulate (\\(y_{rep}\\)) con i dati osservati reali (\\(y\\)). Il PPC plot ci permette di vedere se il modello, con i parametri aggiornati, è in grado di riprodurre correttamente i dati osservati.\n\nPer creare il PPC plot, usiamo ArviZ. Creiamo un oggetto InferenceData che contiene sia le predizioni a posteriori che i dati osservati, organizzati nel formato richiesto da ArviZ.\n\n# Estrai i campioni y_rep\ny_rep &lt;- fit3$draws(\"y_rep\", format = \"matrix\")\n\n# Crea il plot di controllo posteriore predittivo\nppc_plot &lt;- ppc_dens_overlay(stan_data$y, y_rep[1:100, ])\nprint(ppc_plot)\n\n\n\n\n\n\n\nIl Posterior Predictive Check è uno strumento potente per verificare la validità del modello dopo l’analisi, assicurando che le predizioni del modello siano realistiche e che riflettano accuratamente le osservazioni effettive.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>Predizione e inferenza 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_prediction_stan.html#riflessioni-conclusive",
    "href": "chapters/linear_models/06_prediction_stan.html#riflessioni-conclusive",
    "title": "64  Predizione e inferenza 🔸",
    "section": "\n64.5 Riflessioni Conclusive",
    "text": "64.5 Riflessioni Conclusive\nIn questo capitolo, abbiamo approfondito i temi della predizione bayesiana nel contesto del modello di regressione bivariato, evidenziando l’importanza delle verifiche predittive a priori e a posteriori per la valutazione e la validazione del modello.\nAbbiamo visto come il Prior Predictive Check sia essenziale per verificare che le distribuzioni a priori siano appropriate per il modello e i dati del campione. Questo passaggio consente di esaminare se le ipotesi iniziali sono coerenti con la conoscenza preesistente e con i risultati attesi. Un’adeguata verifica predittiva a priori aiuta a prevenire l’adozione di distribuzioni a priori che possano portare a previsioni irrealistiche o fuorvianti. Se le predizioni basate sulle distribuzioni a priori risultano incompatibili con ciò che ci si aspetta dai dati, è un segnale che le distribuzioni a priori devono essere riviste.\nSuccessivamente, abbiamo esaminato il Posterior Predictive Check come strumento per valutare la capacità del modello di adattarsi ai dati osservati. Dopo aver integrato le informazioni dei dati con le distribuzioni a priori, il posterior predictive check permette di confrontare le predizioni del modello con i dati effettivamente osservati. Se il modello è adeguato, le sue predizioni dovrebbero essere in linea con i dati reali. Tuttavia, se emerge una discrepanza sostanziale tra le predizioni e i dati osservati, questo è un chiaro segnale che il modello potrebbe non essere appropriato per il fenomeno in esame e potrebbe richiedere una revisione. Tale revisione può comportare la modifica delle assunzioni di base, l’inclusione di nuovi predittori, o l’adozione di un modello completamente diverso.\nIn conclusione, l’approccio bayesiano alla predizione e alla verifica dei modelli offre un framework robusto e flessibile per l’analisi statistica. I prior e posterior predictive checks non sono semplici passaggi tecnici, ma costituiscono una parte integrante del processo di modellizzazione, assicurando che il modello non solo sia ben adattato ai dati, ma anche che le sue assunzioni siano giustificate e realistiche. L’utilizzo di questi strumenti permette di costruire modelli che siano coerenti con la realtà che intendono rappresentare.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>Predizione e inferenza 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_prediction_stan.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/06_prediction_stan.html#informazioni-sullambiente-di-sviluppo",
    "title": "64  Predizione e inferenza 🔸",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] posterior_1.6.0     cmdstanr_0.8.1.9000 see_0.9.0          \n#&gt;  [4] gridExtra_2.3       patchwork_1.3.0     bayesplot_1.11.1   \n#&gt;  [7] psych_2.4.12        scales_1.3.0        markdown_1.13      \n#&gt; [10] knitr_1.49          lubridate_1.9.4     forcats_1.0.0      \n#&gt; [13] stringr_1.5.1       dplyr_1.1.4         purrr_1.0.2        \n#&gt; [16] readr_2.1.5         tidyr_1.3.1         tibble_3.2.1       \n#&gt; [19] ggplot2_3.5.1       tidyverse_2.0.0     rio_1.2.3          \n#&gt; [22] here_1.0.1         \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6         tensorA_0.36.2.1     xfun_0.49           \n#&gt;  [4] htmlwidgets_1.6.4    processx_3.8.4       lattice_0.22-6      \n#&gt;  [7] tzdb_0.4.0           vctrs_0.6.5          tools_4.4.2         \n#&gt; [10] ps_1.8.1             generics_0.1.3       parallel_4.4.2      \n#&gt; [13] pacman_0.5.1         pkgconfig_2.0.3      R.oo_1.27.0         \n#&gt; [16] data.table_1.16.4    checkmate_2.3.2      distributional_0.5.0\n#&gt; [19] lifecycle_1.0.4      compiler_4.4.2       farver_2.1.2        \n#&gt; [22] munsell_0.5.1        mnormt_2.1.1         htmltools_0.5.8.1   \n#&gt; [25] yaml_2.3.10          pillar_1.10.0        R.utils_2.12.3      \n#&gt; [28] abind_1.4-8          nlme_3.1-166         tidyselect_1.2.1    \n#&gt; [31] digest_0.6.37        stringi_1.8.4        reshape2_1.4.4      \n#&gt; [34] labeling_0.4.3       rprojroot_2.0.4      fastmap_1.2.0       \n#&gt; [37] grid_4.4.2           colorspace_2.1-1     cli_3.6.3           \n#&gt; [40] magrittr_2.0.3       utf8_1.2.4           withr_3.0.2         \n#&gt; [43] backports_1.5.0      timechange_0.3.0     rmarkdown_2.29      \n#&gt; [46] matrixStats_1.4.1    R.methodsS3_1.8.2    hms_1.1.3           \n#&gt; [49] evaluate_1.0.1       rlang_1.1.4          Rcpp_1.0.13-1       \n#&gt; [52] glue_1.8.0           jsonlite_1.8.9       plyr_1.8.9          \n#&gt; [55] R6_2.5.1",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>Predizione e inferenza 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_prediction_stan.html#bibliografia",
    "href": "chapters/linear_models/06_prediction_stan.html#bibliografia",
    "title": "64  Predizione e inferenza 🔸",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other stories. Cambridge University Press.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>Predizione e inferenza 🔸</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html",
    "href": "chapters/linear_models/07_two_means.html",
    "title": "65  Confronto tra le medie di due gruppi",
    "section": "",
    "text": "65.1 Introduzione\nSpesso, ci troviamo ad affrontare la necessità di confrontare due gruppi di dati. Potrebbe interessarci sapere se la media di un gruppo è maggiore o diversa rispetto a quella di un altro gruppo. Per effettuare tale confronto, è fondamentale utilizzare un modello statistico, poiché le vere differenze tra i gruppi sono spesso accompagnate da rumore di misurazione o fluttuazioni casuali del fenomeno in esame. Questo rende difficile trarre conclusioni basandosi unicamente sulle differenze calcolate dai dati osservati.\nIl metodo tradizionale per confrontare statisticamente due o più gruppi è quello di utilizzare un test di ipotesi statistico. Questo approccio prevede l’individuazione di un’ipotesi nulla, che solitamente afferma che non ci sono differenze tra i gruppi, e l’utilizzo di una statistica test per determinare se i dati osservati sono plausibili sotto questa ipotesi. L’ipotesi nulla viene rifiutata quando la statistica test calcolata supera una soglia predefinita.\nTuttavia, i test di ipotesi possono essere complessi e i risultati spesso soggetti a interpretazioni errate. La scelta delle specifiche del test statistico (ad esempio, quale test utilizzare, quale ipotesi nulla testare, quale livello di significatività adottare) è spesso arbitraria e basata su convenzioni piuttosto che sulla specificità del problema o delle decisioni da prendere (Johnson, 1999). Inoltre, i risultati forniti dai test sono spesso indiretti, incompleti e tendono a sovrastimare le evidenze contro l’ipotesi nulla (Goodman, 1999).\nUn approccio più informativo ed efficace per il confronto tra gruppi è quello basato sulla stima invece che sul test dell’ipotesi nulla, ed è guidato dalla probabilità bayesiana anziché dalla frequentista. In pratica, invece di testare se ci sono differenze tra i gruppi, si cerca di ottenere una stima di quanto siano effettivamente diversi. Questo approccio è intrinsecamente più informativo. Inoltre, viene inclusa una stima dell’incertezza associata a tale differenza, che tiene conto sia dell’incertezza dovuta alla nostra mancanza di conoscenza dei parametri del modello (incertezza epistemica) sia dell’incertezza causata dalla variabilità intrinseca del sistema (incertezza aleatoria).\nPer affrontare tale problema possiamo usare un modello di regressione. In questo caso, anziché calcolare direttamente la differenza tra le medie, si introduce una variabile indicatrice (o “dummy”) \\(D\\) nel modello di regressione, come segue:\n\\[\ny_i = \\alpha + \\gamma D_i + \\varepsilon_i.\n\\]\nLa variabile indicatrice \\(D\\) specifica l’appartenenza ai gruppi attraverso valori binari: 0 per il gruppo di riferimento e 1 per il gruppo di confronto, definita come:\n\\[\nD_i =\n\\begin{cases}\n0 & \\text{se l'osservazione } i \\text{ appartiene al gruppo 0,} \\\\\n1 & \\text{se l'osservazione } i \\text{ appartiene al gruppo 1.}\n\\end{cases}\n\\]\nEntrambi i metodi sono appropriati per studiare la differenza tra le medie di due gruppi indipendenti. Tuttavia, il modello di regressione offre maggiore flessibilità e possibilità di estensione. Questa metodologia consente di includere ulteriori variabili esplicative, migliorando la comprensione dei fattori che influenzano l’esito di interesse. Tale flessibilità diventa particolarmente utile per esplorare come altre variabili incidano sulla differenza tra le medie o per analizzare contemporaneamente più variabili.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#regressione-bayesiana-per-due-gruppi-indipendenti",
    "href": "chapters/linear_models/07_two_means.html#regressione-bayesiana-per-due-gruppi-indipendenti",
    "title": "65  Confronto tra le medie di due gruppi",
    "section": "\n65.2 Regressione bayesiana per due gruppi indipendenti",
    "text": "65.2 Regressione bayesiana per due gruppi indipendenti\nIn un approccio bayesiano, il modello di regressione può essere espresso come:\n\\[\n\\begin{align*}\ny_i & \\sim \\mathcal{N}(\\mu_i, \\sigma), \\\\\n\\mu_i & = \\alpha + \\gamma D_i.\n\\end{align*}\n\\]\nIn questo modello:\n\n\n\\(\\alpha\\) rappresenta l’intercetta, corrispondente alla media del gruppo con \\(D = 0\\) (gruppo di riferimento),\n\n\\(\\gamma\\) quantifica la differenza attesa tra le medie dei due gruppi,\n\n\\(\\sigma\\) rappresenta la deviazione standard associata agli errori casuali.\n\nPer il gruppo di riferimento (\\(D = 0\\)), il modello si riduce a:\n\\[\n\\begin{align*}\ny_i & \\sim \\mathcal{N}(\\mu_i, \\sigma), \\\\\n\\mu_i & = \\alpha.\n\\end{align*}\n\\]\nIn questo caso, \\(\\alpha\\) rappresenta direttamente la media del gruppo 0.\nPer il gruppo di confronto (\\(D = 1\\)), il modello diventa:\n\\[\n\\begin{align*}\ny_i & \\sim \\mathcal{N}(\\mu_i, \\sigma), \\\\\n\\mu_i & = \\alpha + \\gamma.\n\\end{align*}\n\\]\nQui, \\(\\alpha + \\gamma\\) rappresenta la media del gruppo 1, mentre \\(\\gamma\\) riflette la differenza tra la media del gruppo 1 e quella del gruppo 0.\nDi conseguenza, l’analisi della differenza tra le medie dei due gruppi si traduce nell’inferenza sul parametro \\(\\gamma\\). In un contesto bayesiano, ciò comporta l’esame della distribuzione a posteriori di \\(\\gamma\\), che consente di effettuare confronti diretti e di valutare l’incertezza associata alla stima di tale differenza.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#un-esempio-illustrativo",
    "href": "chapters/linear_models/07_two_means.html#un-esempio-illustrativo",
    "title": "65  Confronto tra le medie di due gruppi",
    "section": "\n65.3 Un esempio illustrativo",
    "text": "65.3 Un esempio illustrativo\nConsideriamo il dataset relativo al quoziente di intelligenza (QI) di un campione di bambini, distinguendo tra quelli le cui madri hanno completato la scuola superiore e quelli le cui madri non l’hanno completata. Vediamo come implementare l’analisi descritta sopra passo per passo.\n\n65.3.1 Esplorazione iniziale dei dati\nCarichiamo i dati e osserviamo una sintesi delle prime righe per capire la struttura del dataset:\n\nkidiq &lt;- rio::import(here::here(\"data\", \"kidiq.dta\"))\nkidiq |&gt; \n  head()\n#&gt;   kid_score mom_hs mom_iq mom_work mom_age\n#&gt; 1        65      1  121.1        4      27\n#&gt; 2        98      1   89.4        4      25\n#&gt; 3        85      1  115.4        4      27\n#&gt; 4        83      1   99.4        3      25\n#&gt; 5       115      1   92.7        4      27\n#&gt; 6        98      0  107.9        1      18\n\nSuccessivamente, analizziamo la distribuzione dei bambini nei due gruppi, in base all’educazione delle madri:\n\nkidiq |&gt; \n  group_by(mom_hs) |&gt; \n  summarize(\n    n = n()\n)\n#&gt; # A tibble: 2 × 2\n#&gt;   mom_hs     n\n#&gt;    &lt;dbl&gt; &lt;int&gt;\n#&gt; 1      0    93\n#&gt; 2      1   341\n\nI risultati mostrano che:\n\n\n93 bambini hanno madri che non hanno completato la scuola superiore.\n\n341 bambini hanno madri diplomate.\n\nCalcoliamo le medie e le deviazioni standard del QI dei bambini per ciascun gruppo:\n\nsummary_stats &lt;- kidiq %&gt;%\n  group_by(mom_hs) %&gt;%\n  summarise(\n    mean_kid_score = mean(kid_score, na.rm = TRUE),\n    sd_kid_score = sd(kid_score, na.rm = TRUE)\n  )\nsummary_stats\n#&gt; # A tibble: 2 × 3\n#&gt;   mom_hs mean_kid_score sd_kid_score\n#&gt;    &lt;dbl&gt;          &lt;dbl&gt;        &lt;dbl&gt;\n#&gt; 1      0           77.5         22.6\n#&gt; 2      1           89.3         19.0\n\nLa differenza tra le medie può essere calcolata direttamente come:\n\nmean(kidiq[kidiq$mom_hs == 1, ]$kid_score) - \n  mean(kidiq[kidiq$mom_hs == 0, ]$kid_score)\n#&gt; [1] 11.8\n\nQuesta analisi preliminare evidenzia la differenza media tra i gruppi.\nPer comprendere meglio la distribuzione dei dati, utilizziamo un violin plot, che mostra la densità stimata dei punteggi del QI nei due gruppi:\n\nggplot(kidiq, aes(x = as.factor(mom_hs), y = kid_score)) +\n  geom_violin(trim = FALSE) + \n  labs(\n    x = \"Livello di istruzione della madre\",\n    y = \"QI del bambino\",\n    title = \"Distribuzione dei punteggi QI in base all'istruzione materna\"\n  ) +\n  scale_x_discrete(labels = c(\"0\" = \"Non diplomata\", \"1\" = \"Diplomata\"))",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#modello-di-regressione-bayesiana",
    "href": "chapters/linear_models/07_two_means.html#modello-di-regressione-bayesiana",
    "title": "65  Confronto tra le medie di due gruppi",
    "section": "\n65.4 Modello di regressione bayesiana",
    "text": "65.4 Modello di regressione bayesiana\nUtilizziamo il pacchetto bambi per costruire un modello di regressione bayesiano, che esprime il punteggio del QI come funzione della variabile indicatrice mom_hs (0 = non diplomata, 1 = diplomata). La sintassi è semplice e le distribuzioni a priori sono selezionate automaticamente.\nDefiniamo e stimiamo il modello:\n\nfit_1 &lt;- brm(\n  kid_score ~ mom_hs, \n  backend = \"cmdstanr\", \n  silent = 0,\n  data = kidiq\n)\n\n\n65.4.1 Analisi dei risultati\n\n65.4.1.1 Riassunto dei parametri del modello\nIspezioniamo i parametri posteriori principali del modello:\n\ndraws &lt;- posterior::as_draws(fit_1, variable = \"^b_\", regex = TRUE)\nposterior::summarise_draws(draws, \"mean\", \"sd\", \"mcse_mean\", \"mcse_sd\")\n#&gt; # A tibble: 2 × 5\n#&gt;   variable     mean    sd mcse_mean mcse_sd\n#&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 b_Intercept  77.5  2.12    0.0325  0.0340\n#&gt; 2 b_mom_hs     11.8  2.36    0.0358  0.0361\n\n\n65.4.1.2 Intervallo di credibilità\nCalcoliamo l’intervallo di credibilità a densità massima (HDI) per il parametro associato a mom_hs, utilizzando un livello di credibilità del 89%:\n\nbayestestR::hdi(fit_1, parameters = \"mom_hs\", ci = 0.89)\n#&gt; Highest Density Interval\n#&gt; \n#&gt; Parameter |       89% HDI\n#&gt; -------------------------\n#&gt; mom_hs    | [8.18, 15.79]\n\n\n65.4.1.3 Verifica del modello\nEffettuiamo un controllo grafico per confrontare i dati osservati con quelli predetti dal modello:\n\npp_check(fit_1)\n#&gt; Using 10 posterior draws for ppc type 'dens_overlay' by default.\n\n\n\n\n\n\n\n\n65.4.1.4 R² bayesiano\nInfine, calcoliamo il coefficiente di determinazione (Bayesiano \\(R^2\\)) per valutare la capacità del modello di spiegare la variabilità nei dati:\n\nbayes_R2(fit_1)\n#&gt;    Estimate Est.Error   Q2.5 Q97.5\n#&gt; R2    0.058    0.0211 0.0216 0.103\n\nQuesto esempio dimostra come l’analisi di regressione bayesiana consenta di replicare e approfondire i risultati ottenuti in precedenza. Il modello non solo stima la differenza tra i gruppi, ma offre anche un quadro completo dell’incertezza associata, evidenziando la flessibilità e la potenza di questo approccio.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#una-parametrizzazione-alternativa",
    "href": "chapters/linear_models/07_two_means.html#una-parametrizzazione-alternativa",
    "title": "65  Confronto tra le medie di due gruppi",
    "section": "\n65.5 Una Parametrizzazione Alternativa",
    "text": "65.5 Una Parametrizzazione Alternativa\nPoiché il posterior predictive check (pp-check) ha evidenziato una leggera discrepanza tra i valori osservati (\\(y\\)) e quelli predetti dal modello, consideriamo una parametrizzazione alternativa. Adottiamo un modello gaussiano esteso con un parametro aggiuntivo per modellare l’asimmetria nella distribuzione, utilizzando una famiglia di distribuzioni skew-normal.\nEcco come definiamo e stimiamo il nuovo modello:\n\nfit_2 &lt;- brm(\n  kid_score ~ mom_hs, \n  family = skew_normal(),\n  backend = \"cmdstanr\", \n  silent = 0,\n  data = kidiq\n)\n\n\n65.5.1 Verifica del modello\nDopo aver stimato il modello, eseguiamo nuovamente il pp-check per confrontare i dati osservati con quelli predetti:\n\npp_check(fit_2)\n#&gt; Using 10 posterior draws for ppc type 'dens_overlay' by default.\n\n\n\n\n\n\n\nI risultati mostrano un miglioramento nell’adattamento del modello, indicando che l’aggiunta del parametro per l’asimmetria ha contribuito a ridurre le discrepanze.\n\n65.5.2 Valutazione delle stime\nAnalizziamo le stime posteriori dei parametri per verificare eventuali variazioni rispetto al modello precedente:\n\ndraws &lt;- posterior::as_draws(fit_2, variable = \"^b_\", regex = TRUE)\nposterior::summarise_draws(draws, \"mean\", \"sd\", \"mcse_mean\", \"mcse_sd\")\n#&gt; # A tibble: 2 × 5\n#&gt;   variable     mean    sd mcse_mean mcse_sd\n#&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 b_Intercept 79.2   1.96    0.0312  0.0305\n#&gt; 2 b_mom_hs     9.64  2.20    0.0350  0.0347\n\n\n65.5.3 Intervallo di credibilità\nCalcoliamo l’intervallo di credibilità a densità massima (HDI) per il parametro associato a mom_hs:\n\nbayestestR::hdi(fit_2, parameters = \"mom_hs\", ci = 0.89)\n#&gt; Highest Density Interval\n#&gt; \n#&gt; Parameter |       89% HDI\n#&gt; -------------------------\n#&gt; mom_hs    | [6.03, 13.07]\n\n\n65.5.4 Valutazione della variabilità spiegata\nInfine, calcoliamo il coefficiente di determinazione Bayesiano (\\(R^2\\)) per quantificare la capacità del modello di spiegare la variabilità nei dati:\n\nbayes_R2(fit_2)\n#&gt;    Estimate Est.Error   Q2.5  Q97.5\n#&gt; R2   0.0399    0.0168 0.0122 0.0766\n\nIn conclusioni, il modello con distribuzione skew-normal offre un adattamento migliore rispetto al modello gaussiano standard, come evidenziato dal pp-check. Tuttavia, le stime posteriori dei parametri differiscono solo marginalmente rispetto al modello precedente. Questo suggerisce che, sebbene l’aggiunta dell’asimmetria migliori l’adattamento, l’effetto sulla stima della relazione tra kid_score e mom_hs è limitato.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#prior-predictive-checks",
    "href": "chapters/linear_models/07_two_means.html#prior-predictive-checks",
    "title": "65  Confronto tra le medie di due gruppi",
    "section": "\n65.6 Prior Predictive Checks",
    "text": "65.6 Prior Predictive Checks\nIl punto di partenza per valutare le prestazioni predittive dei priori consiste nell’effettuare controlli predittivi grafici sui priori. In brms, questi controlli possono essere eseguiti in modo quasi identico ai posterior predictive checks. Basta indicare a brms di ignorare i dati durante il campionamento, concentrandosi unicamente sui priori. Per fare ciò, è fondamentale che tutti i parametri abbiano priori propri e, idealmente, non eccessivamente ampi o poco plausibili.\nPartiamo specificando priori debolmente informativi per il nostro modello gaussiano applicato ai dati kidiq. Esaminiamo prima i priori predefiniti da brms:\n\nget_prior(kid_score ~ mom_hs, data = kidiq)\n#&gt;                   prior     class   coef group resp dpar nlpar lb ub\n#&gt;  student_t(3, 90, 19.3) Intercept                                   \n#&gt;                  (flat)         b                                   \n#&gt;                  (flat)         b mom_hs                            \n#&gt;   student_t(3, 0, 19.3)     sigma                               0   \n#&gt;        source\n#&gt;       default\n#&gt;       default\n#&gt;  (vectorized)\n#&gt;       default\n\n\n65.6.1 Specifica dei Priori\nModifichiamo i priori predefiniti per utilizzare prior debolmente informativi personalizzati:\n\nprior_gaussian &lt;- \n  prior(normal(90, 20), class = \"b\", coef = \"Intercept\") +\n  prior(normal(0, 15), class = \"b\", coef = \"mom_hs\") +\n  prior(cauchy(0, 20), class = \"sigma\")\n\n\n65.6.2 Aggiunta dei Priori al Modello\nAggiungiamo i priori definiti alla funzione brm:\n\nfit_3 &lt;- brm(\n  bf(kid_score ~ 1 + mom_hs, center = FALSE), \n  kid_score ~ mom_hs, \n  prior = prior_gaussian,\n  family = gaussian(),\n  backend = \"cmdstanr\", \n  silent = 0,\n  data = kidiq\n)\n\nLe stime a posteriori per i parametri \\(\\alpha\\) e \\(\\beta\\) corrispondono ai valori ottenuti in precedenza:\n\ndraws &lt;- posterior::as_draws(fit_3, variable = \"^b_\", regex = TRUE)\nposterior::summarise_draws(draws, \"mean\", \"sd\", \"mcse_mean\", \"mcse_sd\")\n#&gt; # A tibble: 2 × 5\n#&gt;   variable     mean    sd mcse_mean mcse_sd\n#&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 b_Intercept  77.9  2.01    0.0515  0.0384\n#&gt; 2 b_mom_hs     11.3  2.24    0.0582  0.0410\n\n\n65.6.3 Esame della Distribuzione Predittiva a Priori\nPer generare campioni unicamente dalla distribuzione dei priori, specifichiamo l’argomento sample_prior = \"only\":\n\nfit_4 &lt;- brm(\n  bf(kid_score ~ 1 + mom_hs, center = FALSE), \n  kid_score ~ mom_hs, \n  prior = prior_gaussian,\n  family = gaussian(),\n  backend = \"cmdstanr\", \n  silent = 0,\n  data = kidiq,\n  sample_prior = \"only\"\n)\n\nQuando analizziamo il sommario del modello, osserviamo che i valori stimati dai “posteriori” riflettono effettivamente i priori:\n\nsummary(fit_4)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: kid_score ~ 1 + mom_hs \n#&gt;          autocor ~ tructure(list(), class = \"formula\", .Environment = &lt;environment&gt;)\n#&gt;    Data: kidiq (Number of observations: 434) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept    90.42     20.10    51.41   131.31 1.00     3307     2776\n#&gt; mom_hs       -0.13     14.77   -29.07    28.42 1.00     3747     3211\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma   106.28   1207.48     0.78   496.64 1.00     3509     2332\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nPossiamo utilizzare pp_check per visualizzare i prior predictive checks:\n\npp_check(fit_4, ndraws = 100) + xlim(10, 180)\n#&gt; Warning: Removed 5952 rows containing non-finite outside the scale range\n#&gt; (`stat_density()`).\n\n\n\n\n\n\n\nLa distribuzione predittiva a priori risulta più ampia rispetto alla distribuzione dei dati osservati, ma rimane comunque dello stesso ordine di grandezza. Questo è esattamente ciò che ci aspettiamo: i priori dovrebbero essere abbastanza ampi da consentire flessibilità, ma non così eccessivi da risultare irrealistici. Sebbene questo controllo non garantisca con certezza che tutti i priori siano ragionevoli, è utile per identificare priori potenzialmente troppo ampi o poco informativi.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#massima-verosimiglianza",
    "href": "chapters/linear_models/07_two_means.html#massima-verosimiglianza",
    "title": "65  Confronto tra le medie di due gruppi",
    "section": "\n65.7 Massima Verosimiglianza",
    "text": "65.7 Massima Verosimiglianza\nIn questa sezione confrontiamo diverse metodologie per stimare e testare la differenza tra due gruppi, adottando un approccio basato sulla massima verosimiglianza e confrontandolo sia con il test \\(t\\) di Student che con l’approccio bayesiano.\n\n65.7.1 Modello di Regressione\nUtilizziamo un modello lineare per stimare la differenza tra i due gruppi nel dataset kidiq, in cui il punteggio di QI del bambino (kid_score) è predetto dall’istruzione della madre (mom_hs):\n\nfm &lt;- lm(kid_score ~ mom_hs, data = kidiq)\nsummary(fm)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = kid_score ~ mom_hs, data = kidiq)\n#&gt; \n#&gt; Residuals:\n#&gt;    Min     1Q Median     3Q    Max \n#&gt; -57.55 -13.32   2.68  14.68  58.45 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)\n#&gt; (Intercept)    77.55       2.06   37.67   &lt;2e-16\n#&gt; mom_hs         11.77       2.32    5.07    6e-07\n#&gt; \n#&gt; Residual standard error: 19.9 on 432 degrees of freedom\n#&gt; Multiple R-squared:  0.0561, Adjusted R-squared:  0.0539 \n#&gt; F-statistic: 25.7 on 1 and 432 DF,  p-value: 5.96e-07\n\nIl modello calcola i parametri utilizzando la massimizzazione della funzione di verosimiglianza. I coefficienti stimati hanno la seguente interpretazione:\n\n\nIntercetta: rappresenta la media del punteggio QI per i bambini con madri non diplomate (mom_hs = 0).\n\nCoefficiente di mom_hs: rappresenta la differenza attesa nel punteggio medio di QI tra i bambini con madri diplomate (mom_hs = 1) e quelli con madri non diplomate.\n\n65.7.2 Test \\(t\\) di Student\nUn altro approccio frequente per confrontare due gruppi indipendenti è il test \\(t\\) di Student. Questo test verifica l’ipotesi nulla che le medie delle due popolazioni siano uguali:\n\nt.test(kid_score ~ mom_hs, data = kidiq)\n#&gt; \n#&gt;  Welch Two Sample t-test\n#&gt; \n#&gt; data:  kid_score by mom_hs\n#&gt; t = -5, df = 130, p-value = 1e-05\n#&gt; alternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  -16.83  -6.71\n#&gt; sample estimates:\n#&gt; mean in group 0 mean in group 1 \n#&gt;            77.5            89.3\n\nI risultati del test includono:\n\n\nStatistica t: quantifica la differenza standardizzata tra le medie dei gruppi.\n\np-value: la probabilità di osservare una differenza almeno così estrema se l’ipotesi nulla fosse vera.\n\nIntervallo di fiducia frequentista: l’intervallo in cui è plausibile trovare la differenza media vera tra i gruppi.\n\n65.7.3 Equivalenza tra Modello di Regressione e Test \\(t\\)\n\nIl test \\(t\\) di Student è matematicamente equivalente al test frequentista sull’ipotesi che il coefficiente di regressione associato a mom_hs sia pari a zero. Entrambi assumono che i dati siano gaussiani e che le varianze dei gruppi siano uguali (o usano un’adeguata correzione in caso di varianze non uguali).\nNel caso del modello lineare, la stima puntuale della differenza tra i gruppi e l’intervallo di fiducia coincidono con quelli del test \\(t\\). Questo dimostra come il test \\(t\\) possa essere considerato una formulazione specifica del modello lineare per due gruppi.\n\n65.7.4 Confronto con l’Approccio Bayesiano\nNell’approccio bayesiano, abbiamo calcolato la differenza tra i due gruppi utilizzando priori debolmente informativi e stimando una distribuzione a posteriori per il parametro di interesse:\n\nfit_1 &lt;- brm(\n  kid_score ~ mom_hs, \n  data = kidiq,\n  backend = \"cmdstanr\"\n)\n\nI risultati del modello bayesiano sono:\n\n\nSimili ai metodi frequentisti quando i priori sono debolmente informativi e il campione è grande.\n\nPiù informativi, in quanto forniscono una distribuzione a posteriori per la differenza tra i gruppi, invece di limitarsi a un valore puntuale e un intervallo di fiducia (per un approfondimento, si veda Kruschke, 2013).\n\n65.7.5 Differenze Chiave tra i Metodi\n\n\nTest \\(t\\) di Student:\n\nOffre una statistica test e un intervallo di fiducia frequentista.\nÈ rapido e semplice da calcolare per due gruppi indipendenti.\nNon consente di incorporare informazioni a priori.\n\n\n\nModello di Regressione:\n\nFornisce una maggiore flessibilità, permettendo di includere ulteriori predittori e interazioni.\nÈ matematicamente equivalente al test \\(t\\) per due gruppi indipendenti.\n\n\n\nApproccio Bayesiano:\n\nConsente di combinare i dati osservati con informazioni a priori.\nProduce una distribuzione a posteriori che può essere utilizzata per testare ipotesi e calcolare probabilità.\nÈ particolarmente utile con campioni piccoli o quando si vuole includere conoscenze pregresse.\n\n\n\nIn conclusioni, sebbene il test \\(t\\) e il modello di regressione basato sulla massima verosimiglianza producano risultati identici per due gruppi, l’approccio bayesiano si distingue per la sua flessibilità e capacità di incorporare informazioni a priori. In questo caso, utilizzando dei prior debolmente informativi, i risultati di tutti e tre i metodi sono coerenti, evidenziando che la differenza tra i due gruppi può essere stimata in modo robusto con ciascun approccio.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#test-di-ipotesi-bayesiano",
    "href": "chapters/linear_models/07_two_means.html#test-di-ipotesi-bayesiano",
    "title": "65  Confronto tra le medie di due gruppi",
    "section": "\n65.8 Test di Ipotesi Bayesiano",
    "text": "65.8 Test di Ipotesi Bayesiano\nNel contesto bayesiano, il test di ipotesi non si basa sul rifiuto o accettazione di un’ipotesi nulla come avviene nei test frequentisti. Invece, si calcolano le probabilità a posteriori associate a specifiche ipotesi, fornendo un quadro più intuitivo e flessibile.\nUn test bayesiano di ipotesi consiste nel determinare la probabilità che un parametro, come \\(\\beta_{mean\\_diff}\\) (la differenza tra le medie dei due gruppi), sia maggiore di un valore specifico \\(\\mu_0\\). Qui, \\(\\mu_0\\) rappresenta un valore arbitrario scelto in base all’ipotesi che desideriamo testare.\nAd esempio, possiamo calcolare la probabilità che la differenza tra i due gruppi sia maggiore di 10. Questo si traduce matematicamente nella probabilità a posteriori:\n\\[\nP(\\beta_{mean\\_diff} &gt; 10 \\mid \\text{dati}).\n\\]\nCon il pacchetto brms, tale calcolo è molto semplice grazie alla funzione hypothesis():\n\nhypothesis(fit_1, \"mom_hs &gt; 10\")\n#&gt; Hypothesis Tests for class b:\n#&gt;          Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio\n#&gt; 1 (mom_hs)-(10) &gt; 0     1.72      2.31    -2.05     5.59       3.31\n#&gt;   Post.Prob Star\n#&gt; 1      0.77     \n#&gt; ---\n#&gt; 'CI': 90%-CI for one-sided and 95%-CI for two-sided hypotheses.\n#&gt; '*': For one-sided hypotheses, the posterior probability exceeds 95%;\n#&gt; for two-sided hypotheses, the value tested against lies outside the 95%-CI.\n#&gt; Posterior probabilities of point hypotheses assume equal prior probabilities.\n\nL’output della funzione hypothesis() fornisce diverse informazioni utili:\n\nProbabilità a posteriori: La probabilità che \\(\\beta_{mean\\_diff}\\) sia maggiore di 10, calcolata sulla base della distribuzione a posteriori stimata dal modello.\nIntervallo di Credibilità: Un intervallo intorno al valore stimato di \\(\\beta_{mean\\_diff}\\) che contiene una percentuale specificata di probabilità (es. 89% di default).\nBayes Factor (opzionale): In alcuni casi, viene calcolato un Bayes Factor per confrontare la plausibilità dell’ipotesi testata con la sua negazione (es. \\(P(\\beta_{mean\\_diff} &gt; 10)\\) contro \\(P(\\beta_{mean\\_diff} \\leq 10)\\)).\n\n\n65.8.1 Vantaggi del Test Bayesiano\n\n\nInformazione Diretta: Fornisce una probabilità interpretabile, come “c’è una probabilità del 95% che la differenza tra i due gruppi sia maggiore di 10”.\n\nFlessibilità: Permette di testare qualsiasi valore ipotizzato per \\(\\mu_0\\), senza vincoli legati all’ipotesi nulla.\n\nNessun Valore Critico Arbitrario: Non richiede una soglia convenzionale (es. \\(p &lt; 0.05\\)) per giudicare i risultati.\n\n65.8.2 Confronto con i Test Frequentisti\nNel test frequentista, il risultato sarebbe espresso come un \\(p\\)-value che indica la probabilità di ottenere dati così estremi (o più) sotto l’ipotesi nulla \\(\\beta_{mean\\_diff} \\leq \\mu_0\\). Tuttavia, il \\(p\\)-value non quantifica direttamente la probabilità che l’ipotesi alternativa sia vera, a differenza dell’approccio bayesiano.\nIn conclusioni, il test di ipotesi bayesiano, come mostrato in questo esempio, rappresenta un approccio intuitivo e informativo per valutare ipotesi sui parametri di un modello, superando alcune delle limitazioni concettuali dei test frequentisti.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#riflessioni-conclusive",
    "href": "chapters/linear_models/07_two_means.html#riflessioni-conclusive",
    "title": "65  Confronto tra le medie di due gruppi",
    "section": "\n65.9 Riflessioni Conclusive",
    "text": "65.9 Riflessioni Conclusive\nIn questo capitolo abbiamo esplorato le numerose funzionalità offerte da brms per la modellazione bayesiana, dimostrando come questo pacchetto consenta di implementare analisi sofisticate in modo intuitivo e flessibile. Abbiamo visto come specificare modelli, eseguire controlli predittivi sui priori e posteriori, testare ipotesi bayesiane e interpretare i risultati in termini probabilistici. La semplicità della sintassi e l’automatizzazione di aspetti complessi, come la scelta dei priori, rendono brms uno strumento potente e accessibile per affrontare una vasta gamma di problemi statistici, permettendo di ottenere inferenze solide e interpretabili con un approccio moderno e rigoroso.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/07_two_means.html#informazioni-sullambiente-di-sviluppo",
    "title": "65  Confronto tra le medie di due gruppi",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] rstan_2.32.6        StanHeaders_2.32.10 insight_1.0.0      \n#&gt;  [4] bayestestR_0.15.0   brms_2.22.8         Rcpp_1.0.13-1      \n#&gt;  [7] posterior_1.6.0     cmdstanr_0.8.1.9000 see_0.9.0          \n#&gt; [10] gridExtra_2.3       patchwork_1.3.0     bayesplot_1.11.1   \n#&gt; [13] psych_2.4.12        scales_1.3.0        markdown_1.13      \n#&gt; [16] knitr_1.49          lubridate_1.9.4     forcats_1.0.0      \n#&gt; [19] stringr_1.5.1       dplyr_1.1.4         purrr_1.0.2        \n#&gt; [22] readr_2.1.5         tidyr_1.3.1         tibble_3.2.1       \n#&gt; [25] ggplot2_3.5.1       tidyverse_2.0.0     rio_1.2.3          \n#&gt; [28] here_1.0.1         \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] mnormt_2.1.1         inline_0.3.20        sandwich_3.1-1      \n#&gt;  [4] rlang_1.1.4          magrittr_2.0.3       multcomp_1.4-26     \n#&gt;  [7] matrixStats_1.4.1    compiler_4.4.2       loo_2.8.0           \n#&gt; [10] vctrs_0.6.5          reshape2_1.4.4       pkgconfig_2.0.3     \n#&gt; [13] fastmap_1.2.0        backports_1.5.0      labeling_0.4.3      \n#&gt; [16] utf8_1.2.4           rmarkdown_2.29       tzdb_0.4.0          \n#&gt; [19] haven_2.5.4          ps_1.8.1             xfun_0.49           \n#&gt; [22] jsonlite_1.8.9       parallel_4.4.2       R6_2.5.1            \n#&gt; [25] stringi_1.8.4        estimability_1.5.1   zoo_1.8-12          \n#&gt; [28] pacman_0.5.1         R.utils_2.12.3       Matrix_1.7-1        \n#&gt; [31] splines_4.4.2        timechange_0.3.0     tidyselect_1.2.1    \n#&gt; [34] abind_1.4-8          yaml_2.3.10          codetools_0.2-20    \n#&gt; [37] curl_6.0.1           processx_3.8.4       pkgbuild_1.4.5      \n#&gt; [40] plyr_1.8.9           lattice_0.22-6       withr_3.0.2         \n#&gt; [43] bridgesampling_1.1-2 coda_0.19-4.1        evaluate_1.0.1      \n#&gt; [46] survival_3.8-3       RcppParallel_5.1.9   pillar_1.10.0       \n#&gt; [49] tensorA_0.36.2.1     checkmate_2.3.2      stats4_4.4.2        \n#&gt; [52] distributional_0.5.0 generics_0.1.3       rprojroot_2.0.4     \n#&gt; [55] hms_1.1.3            rstantools_2.4.0     munsell_0.5.1       \n#&gt; [58] xtable_1.8-4         glue_1.8.0           emmeans_1.10.6      \n#&gt; [61] tools_4.4.2          data.table_1.16.4    mvtnorm_1.3-2       \n#&gt; [64] grid_4.4.2           QuickJSR_1.4.0       datawizard_0.13.0   \n#&gt; [67] colorspace_2.1-1     nlme_3.1-166         cli_3.6.3           \n#&gt; [70] Brobdingnag_1.2-9    V8_6.0.0             gtable_0.3.6        \n#&gt; [73] R.methodsS3_1.8.2    digest_0.6.37        TH.data_1.1-2       \n#&gt; [76] htmlwidgets_1.6.4    farver_2.1.2         htmltools_0.5.8.1   \n#&gt; [79] R.oo_1.27.0          lifecycle_1.0.4      MASS_7.3-61",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#bibliografia",
    "href": "chapters/linear_models/07_two_means.html#bibliografia",
    "title": "65  Confronto tra le medie di due gruppi",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nKruschke, J. K. (2013). Bayesian estimation supersedes the t test. Journal of Experimental Psychology: General, 142(2), 573–603.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_two_means_stan.html",
    "href": "chapters/linear_models/08_two_means_stan.html",
    "title": "66  Confronto tra due gruppi",
    "section": "",
    "text": "66.1 Introduzione\nL’obiettivo di questo capitolo è di ampliare la discussione del ?sec-stan-one-mean, affrontando il confronto tra le medie di due gruppi indipendenti.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_two_means_stan.html#stima-bayesiana-e-test-dellipotesi-nulla",
    "href": "chapters/linear_models/08_two_means_stan.html#stima-bayesiana-e-test-dellipotesi-nulla",
    "title": "66  Confronto tra due gruppi",
    "section": "\n66.2 Stima bayesiana e test dell’ipotesi nulla",
    "text": "66.2 Stima bayesiana e test dell’ipotesi nulla\nSpesso, ci troviamo ad affrontare la necessità di confrontare due gruppi di dati. Potrebbe interessarci sapere se la media di un gruppo è maggiore o diversa rispetto a quella di un altro gruppo. Per effettuare tale confronto, è fondamentale utilizzare un modello statistico, poiché le vere differenze tra i gruppi sono spesso accompagnate da rumore di misurazione o fluttuazioni casuali del fenomeno in esame. Questo rende difficile trarre conclusioni basandosi unicamente sulle differenze calcolate dai dati osservati.\nIl metodo tradizionale per confrontare statisticamente due o più gruppi è quello di utilizzare un test statistico. Questo approccio prevede l’individuazione di un’ipotesi nulla, che solitamente afferma che non ci sono differenze tra i gruppi, e l’utilizzo di una statistica test per determinare se i dati osservati sono plausibili sotto questa ipotesi. L’ipotesi nulla viene rifiutata quando la statistica test calcolata supera una soglia predefinita.\nTuttavia, i test di ipotesi possono essere complessi e i risultati spesso soggetti a interpretazioni errate. La scelta delle specifiche del test statistico (ad esempio, quale test utilizzare, quale ipotesi nulla testare, quale livello di significatività adottare) è spesso arbitraria e basata su convenzioni piuttosto che sulla specificità del problema o delle decisioni da prendere (Johnson, 1999). Inoltre, i risultati forniti dai test sono spesso indiretti, incompleti e tendono a sovrastimare le evidenze contro l’ipotesi nulla (Goodman, 1999).\nUn approccio più informativo ed efficace per il confronto tra gruppi è quello basato sulla stima invece che sul test dell’ipotesi nulla, ed è guidato dalla probabilità bayesiana anziché dalla frequentista. In pratica, invece di testare se ci sono differenze tra i gruppi, si cerca di ottenere una stima di quanto siano effettivamente diversi. Questo approccio è intrinsecamente più informativo. Inoltre, viene inclusa una stima dell’incertezza associata a tale differenza, che tiene conto sia dell’incertezza dovuta alla nostra mancanza di conoscenza dei parametri del modello (incertezza epistemica) sia dell’incertezza causata dalla variabilità intrinseca del sistema (incertezza aleatoria).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_two_means_stan.html#un-esempio-illustrativo",
    "href": "chapters/linear_models/08_two_means_stan.html#un-esempio-illustrativo",
    "title": "66  Confronto tra due gruppi",
    "section": "\n66.3 Un esempio illustrativo",
    "text": "66.3 Un esempio illustrativo\nIn questo esempio, l’obiettivo è stimare la differenza tra le medie del quoziente di intelligenza dei bambini di due gruppi distinti in base al livello di scolarità della madre. Il primo gruppo include i bambini la cui madre non ha completato le scuole superiori, mentre il secondo gruppo comprende quelli la cui madre ha ottenuto il diploma superiore. Per questo, useremo i dati kidiq e un modello bayesiano al fine di ottenere una stima affidabile della differenza tra le medie dei due gruppi nella popolazione. I dati utilizzati sono forniti da Gelman e Hill (2007) e costituiscono un sottocampione estratto dal National Longitudinal Survey of Youth.\nImportiamo i dati in R.\n\ndf &lt;- rio::import(here::here(\"data\", \"kidiq.dta\"))\ndf |&gt; \n  head()\n#&gt;   kid_score mom_hs mom_iq mom_work mom_age\n#&gt; 1        65      1  121.1        4      27\n#&gt; 2        98      1   89.4        4      25\n#&gt; 3        85      1  115.4        4      27\n#&gt; 4        83      1   99.4        3      25\n#&gt; 5       115      1   92.7        4      27\n#&gt; 6        98      0  107.9        1      18\n\nIl dataset contiene le seguenti colonne:\n\n“kid_score”: il quoziente intellettivo (QI) dei bambini. È una misura dell’intelligenza del bambino.\n“mom_hs”: una variabile binaria che indica se la madre del bambino ha completato o meno la scuola superiore. Può assumere i valori 0 o 1, dove 0 rappresenta “no” (la madre non ha completato la scuola superiore) e 1 rappresenta “sì” (la madre ha completato la scuola superiore).\n\nCi sono 93 bambini la cui madre non ha completato la scuola superiore e 341 bambini la cui madre ha ottenuto il diploma di scuola superiore.\n\ndf |&gt; \n  group_by(mom_hs) |&gt; \n  summarize(\n    n = n()\n  )\n#&gt; # A tibble: 2 × 2\n#&gt;   mom_hs     n\n#&gt;    &lt;dbl&gt; &lt;int&gt;\n#&gt; 1      0    93\n#&gt; 2      1   341\n\nLe statistiche descrittive si ottengono nel modo seguente.\n\ndf |&gt; \n  group_by(mom_hs) |&gt; \n  summarize(\n    avg = mean(kid_score),\n    std = sd(kid_score)\n  )\n#&gt; # A tibble: 2 × 3\n#&gt;   mom_hs   avg   std\n#&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1      0  77.5  22.6\n#&gt; 2      1  89.3  19.0\n\nI bambini la cui madre ha completato le superiori tendono ad avere un QI maggiore di 11.8 punti rispetto ai bambini la cui madre non ha concluso le superiori.\n\nmean(df[df$mom_hs == 1, ]$kid_score) - mean(df[df$mom_hs == 0, ]$kid_score)\n#&gt; [1] 11.8\n\nCreiamo due vettori che contengono il QI dei bambini dei due gruppi.\n\n# Vector of kid_score when mom_hs is 1\nkid_score_mom_hs_1 = df[df$mom_hs == 1, ]$kid_score\n\n# Vector of kid_score when mom_hs is 0\nkid_score_mom_hs_0 = df[df$mom_hs == 0, ]$kid_score",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_two_means_stan.html#dimensione-delleffetto",
    "href": "chapters/linear_models/08_two_means_stan.html#dimensione-delleffetto",
    "title": "66  Confronto tra due gruppi",
    "section": "\n66.4 Dimensione dell’effetto",
    "text": "66.4 Dimensione dell’effetto\nNel caso presente, la differenza tra le medie dei due gruppi è di 11.8 punti sulla scala del QI, e potrebbe sembrare un risultato rilevante, considerando che la metrica del QI è facilmente interpretabile. Tuttavia, è importante notare che il test utilizzato in questo studio non è il WISC, che ha una distribuzione normale con media 100 e deviazione standard 15, ma il test PIAT.\nIn generale, è difficile comprendere il significato di una differenza tra le medie di due gruppi quando viene presentata solo come valore assoluto, soprattutto quando le varianze dei gruppi sono diverse. Per ottenere una misura più informativa, è necessario considerare sia la differenza tra le medie dei gruppi che l’incertezza associata a queste stime delle medie della popolazione. L’indice statistico che soddisfa questo scopo è noto come “dimensione dell’effetto” (effect size).\nLa dimensione dell’effetto è una misura della forza dell’associazione osservata, che tiene conto sia della grandezza della differenza tra i gruppi attesi che dell’incertezza sui dati. Tra gli indici più comunemente utilizzati per quantificare la dimensione dell’effetto, vi è l’indice \\(d\\) di Cohen.\nNel caso di due medie, questo indice è dato da:\n\\[\nd={\\frac {{\\bar {x}}_{1}-{\\bar {x}}_{2}}{s}},\n\\]\nladdove\n\\[\ns={\\sqrt {\\frac {(n_{1}-1)s_{1}^{2}+(n_{2}-1)s_{2}^{2}}{n_{1}+n_{2}-2}}}\n\\]\ne la varianza di ciascun gruppo è calcolata come\n\\[\ns_{1}^{2}={\\frac {1}{n_{1}-1}}\\sum _{i=1}^{n_{1}}(x_{1,i}-{\\bar {x}}_{1})^{2}.\n\\]\nSolitamente, l’indice \\(d\\) di Cohen si interpreta usando la metrica seguente:\n\n\nDimensione dell’effetto\n\\(d\\)\n\n\n\nVery small\n0.01\n\n\nSmall\n0.20\n\n\nMedim\n0.50\n\n\nLarge\n0.80\n\n\nVery large\n1.20\n\n\nHuge\n2.0\n\n\n\nPer una trattazione bayesiana della stima della dimensione dell’effetto, si veda Kruschke (2014).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_two_means_stan.html#modello-bayesiano",
    "href": "chapters/linear_models/08_two_means_stan.html#modello-bayesiano",
    "title": "66  Confronto tra due gruppi",
    "section": "\n66.5 Modello bayesiano",
    "text": "66.5 Modello bayesiano\nIl modello bayesiano per il confronto tra le medie di due gruppi indipendenti comprende la definizione della verosimiglianza per i dati di ciascun gruppo e la descrizione delle distribuzioni a priori dei parametri rilevanti. Inoltre, in questo caso, abbiamo incluso anche la stima della dimensione dell’effetto, che ci permette di valutare la forza dell’associazione osservata tra i gruppi, tenendo conto dell’incertezza sui dati.\nCreiamo un dizonario con i dati rilevanti.\n\nstan_data = list(\n    N1 = length(kid_score_mom_hs_1), \n    N2 = length(kid_score_mom_hs_0), \n    y1 = kid_score_mom_hs_1,\n    y2 = kid_score_mom_hs_0\n)",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_two_means_stan.html#modello-stan",
    "href": "chapters/linear_models/08_two_means_stan.html#modello-stan",
    "title": "66  Confronto tra due gruppi",
    "section": "\n66.6 Modello Stan",
    "text": "66.6 Modello Stan\nPer analizzare questi dati ci serviremo del seguente modello Stan.\n\n# Path to the Stan file\nstan_file &lt;- here::here(\"stan\", \"kid-score.stan\")\n\n# Create a CmdStanModel object\nmod &lt;- cmdstan_model(stan_file)\n\n\nmod$print()\n#&gt; data {\n#&gt;   int&lt;lower=0&gt; N1;  // number of observations (group 1)\n#&gt;   int&lt;lower=0&gt; N2;  // number of observations (group 2)\n#&gt;   vector[N1] y1;  // response times (group 1)\n#&gt;   vector[N2] y2;  // response times (group 2)\n#&gt; }\n#&gt; \n#&gt; parameters {\n#&gt;   real mu_1;  // mean of group 1\n#&gt;   real mu_2;  // mean of group 2\n#&gt;   real&lt;lower=0&gt; sigma_1;  // standard deviation of group 1\n#&gt;   real&lt;lower=0&gt; sigma_2;  // standard deviation of group 2\n#&gt; }\n#&gt; \n#&gt; transformed parameters {\n#&gt;   real delta;  // difference in means\n#&gt;   real cohen_d;  // Cohen's d effect size\n#&gt;   delta = mu_1 - mu_2;\n#&gt;   cohen_d = delta / sqrt((sigma_1^2 + sigma_2^2) / 2);\n#&gt; }\n#&gt; \n#&gt; model {\n#&gt;   // Priors\n#&gt;   mu_1 ~ normal(80, 20);  // Prior for mean of group 1\n#&gt;   mu_2 ~ normal(80, 20);  // Prior for mean of group 2\n#&gt;   sigma_1 ~ normal(0, 10);  // Prior for standard deviation of group 1\n#&gt;   sigma_2 ~ normal(0, 10);  // Prior for standard deviation of group 2\n#&gt; \n#&gt;   // Likelihood\n#&gt;   y1 ~ normal(mu_1, sigma_1);\n#&gt;   y2 ~ normal(mu_2, sigma_2);\n#&gt; }\n#&gt; \n#&gt; generated quantities {\n#&gt;   vector[N1] y1_rep;  // replicated data for group 1\n#&gt;   vector[N2] y2_rep;  // replicated data for group 2\n#&gt;   for (i in 1:N1) {\n#&gt;     y1_rep[i] = normal_rng(mu_1, sigma_1);\n#&gt;   }\n#&gt;   for (i in 1:N2) {\n#&gt;     y2_rep[i] = normal_rng(mu_2, sigma_2);\n#&gt;   }\n#&gt; }\n\nNel nostro modello:\n\n\nN1 è il numero di osservazioni nel primo gruppo (bambini le cui madri hanno completato le superiori)\n\nN2 è il numero di osservazioni nel secondo gruppo (bambini le cui madri non hanno completato le superiori)\n\ny1 è un vettore contenente i valori di QI per il primo gruppo\n\ny2 è un vettore contenente i valori di QI per il secondo gruppo\n\n\n\n\n\n\n\nSpiegazione del modello\n\n\n\nParametri\n\n\nmu_1 e mu_2: Rappresentano le medie dei valori di QI per i due gruppi.\n\nsigma_1 e sigma_2: Rappresentano le deviazioni standard dei valori dei QI per i due gruppi.\n\nParametri trasformati\n\n\ndelta: È la differenza tra le medie dei due gruppi (mu_1 - mu_2).\n\ncohen_d: È la dimensione dell’effetto di Cohen, che quantifica la differenza tra i gruppi in unità di deviazione standard.\n\nPrior\nImpostiamo delle prior per i parametri:\nmu_1 ~ normal(80, 20);\nmu_2 ~ normal(80, 20);\nsigma_1 ~ normal(0, 10);\nsigma_2 ~ normal(0, 10);\nQueste prior riflettono le nostre conoscenze o supposizioni iniziali sui possibili valori di questi parametri. Per esempio, ci aspettiamo che i QI medi siano intorno a 80, ma con una certa variabilità.\nLikelihood\ny1 ~ normal(mu_1, sigma_1);\ny2 ~ normal(mu_2, sigma_2);\nQuesta parte del modello descrive come i dati osservati (y1 e y2) sono generati, date le medie e le deviazioni standard per ciascun gruppo. Assumiamo che i valori del QI seguano una distribuzione normale in ciascun gruppo.\nQuantità generate\ny1_rep[i] = normal_rng(mu_1, sigma_1);\ny2_rep[i] = normal_rng(mu_2, sigma_2);\nQueste righe generano dati “replicati” basati sul modello stimato. Questi possono essere utilizzati per il controllo del modello (posterior predictive checks).\n\n\nI risultati si interpretano nel modo seguente:\n\n\nmu_1 e mu_2: Ci dicono i valori QI medi stimati per ciascun gruppo.\n\nsigma_1 e sigma_2: Ci dicono quanto variano i valori del QI all’interno di ciascun gruppo.\n\ndelta: Ci dice quanto è grande la differenza nei valori dei QI medi tra i due gruppi.\n\ncohen_d: Ci fornisce una misura standardizzata della dimensione dell’effetto.\n\nIn sintesi, questo modello ci permette di:\n\nStimare i valori dei QI medi e la loro variabilità per ciascun gruppo.\nQuantificare la differenza tra i gruppi e la sua incertezza.\nCalcolare una misura standardizzata della dimensione dell’effetto (Cohen’s d).\nGenerare previsioni basate sul modello per future osservazioni.\n\nIl vantaggio principale di questo approccio bayesiano è che otteniamo distribuzioni di probabilità complete per tutti i parametri di interesse, permettendoci di fare affermazioni probabilistiche sulla differenza tra i gruppi e sulla dimensione dell’effetto.\nEseguiamo il campionamento MCMC:\n\nfit &lt;- mod$sample(\n  data = stan_data,\n  seed = 123,\n  chains = 4,\n  parallel_chains = 4,\n  iter_sampling = 5000, \n  iter_warmup = 2000,\n  adapt_delta = 0.99,\n  show_messages = FALSE\n)\n\n\n66.6.1 Risultati\nEsaminiamo la traccia del parametro di interesse:\n\nmcmc_trace(fit$draws(\"cohen_d\"))\n\n\n\n\n\n\n\nGeneriamo un istogramma della distribuzione a posteriori del \\(d\\) di Cohen:\n\nmcmc_hist(\n  fit$draws(\"cohen_d\")\n) +\n  ggtitle(\"Istogramma della distribuzione a posteriori del d di Cohen\") +\n  xlab(\"Valori\") +\n  ylab(\"Frequenza\")\n#&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\nUn sommario numerico del \\(d\\) di Cohen si ottiene nel modo seguente:\n\nfit$summary(\"cohen_d\")\n#&gt; # A tibble: 1 × 10\n#&gt;   variable  mean median    sd   mad    q5   q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 cohen_d  0.566  0.566 0.124 0.123 0.363 0.769  1.00   18906.   14125.\n\nL’intervallo di credibilità a densità più alta si ottiene nel modo seguente:\n\nbayestestR::ci(fit$draws(\"cohen_d\"), method = \"HDI\")\n#&gt; Highest Density Interval\n#&gt; \n#&gt; Parameter |      95% HDI\n#&gt; ------------------------\n#&gt; cohen_d   | [0.32, 0.80]\n\nLe distribuzioni predittive a posteriori sono adeguate, senza essere perfette.\nEstraiamo i dati prodotti dal modello y1_rep e i dati osservati y1:\n\n# Extract posterior predictive samples for y1_rep\ny1_rep &lt;- fit$draws(variables = \"y1_rep\", format = \"draws_matrix\")\n\n# Extract observed data\ny1_obs &lt;- stan_data$y1\n\nConvertiamo y1_rep in una matrice per compatibilità con {bayesplot}.\n\n# Convert y1_rep to a matrix\ny1_rep_matrix &lt;- as.matrix(y1_rep)\n\nGeneriamo il posterior predictive chech plot:\n\n# Posterior predictive check plot\nset.seed(123)\nselected_indices &lt;- sample(nrow(y1_rep_matrix), 50)\nppc_dens_overlay(y = y1_obs, yrep = y1_rep_matrix[selected_indices, ])",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_two_means_stan.html#modello-robusto",
    "href": "chapters/linear_models/08_two_means_stan.html#modello-robusto",
    "title": "66  Confronto tra due gruppi",
    "section": "\n66.7 Modello Robusto",
    "text": "66.7 Modello Robusto\nUn modello bayesiano robusto per il confronto tra due medie indipendenti può gestire deviazioni standard disuguali e outlier sostituendo la verosimiglianza normale con quella della distribuzione t di Student. Utilizzare una distribuzione t di Student al posto di una normale rende il modello più resistente agli outlier. La distribuzione t di Student ha code più pesanti rispetto alla normale, il che significa che è meno influenzata da valori estremi nei dati. Questo è particolarmente utile quando si sospetta la presenza di outlier nei dati o quando le deviazioni standard tra i gruppi sono disuguali. In questo modo, il modello bayesiano robusto offre stime più affidabili delle medie e delle deviazioni standard dei gruppi, nonché della differenza tra le medie e della dimensione dell’effetto.\n\n# Path to the Stan file\nstan_file &lt;- here::here(\"stan\", \"kid-score-t.stan\")\n\n# Create a CmdStanModel object\nmod_t &lt;- cmdstan_model(stan_file)\n\n\nmod_t$print()\n#&gt; data {\n#&gt;   int&lt;lower=0&gt; N1;  // number of observations (group 1)\n#&gt;   int&lt;lower=0&gt; N2;  // number of observations (group 2)\n#&gt;   vector[N1] y1;  // response time (group 1)\n#&gt;   vector[N2] y2;  // response time (group 2)\n#&gt; }\n#&gt; parameters {\n#&gt;   real mu_2;  // mean of group 2\n#&gt;   real delta;  // difference in means\n#&gt;   real&lt;lower=0&gt; sigma_1;  // scale parameter for group 1\n#&gt;   real&lt;lower=0&gt; sigma_2;  // scale parameter for group 2\n#&gt;   real&lt;lower=1&gt; nu;  // degrees of freedom of student's t distribution\n#&gt; }\n#&gt; transformed parameters {\n#&gt;   real mu_1 = mu_2 + delta; \n#&gt; }\n#&gt; model {\n#&gt;   y1 ~ student_t(nu, mu_1, sigma_1);\n#&gt;   y2 ~ student_t(nu, mu_2, sigma_2);\n#&gt;   // priors\n#&gt;   mu_2 ~ normal(80, 20);\n#&gt;   delta ~ normal(0, 10);\n#&gt;   sigma_1 ~ normal(0, 10);\n#&gt;   sigma_2 ~ normal(0, 10);\n#&gt;   nu ~ gamma(2, 0.1);\n#&gt; }\n#&gt; generated quantities {\n#&gt;   vector[N1] y1rep;\n#&gt;   vector[N2] y2rep;\n#&gt;   real pooled_sd = sqrt((sigma_1^2 + sigma_2^2) / 2);\n#&gt;   real cohen_d = delta / pooled_sd;\n#&gt;   \n#&gt;   for (i in 1:N1) {\n#&gt;     y1rep[i] = student_t_rng(nu, mu_1, sigma_1);\n#&gt;   }\n#&gt;   for (i in 1:N2) {\n#&gt;     y2rep[i] = student_t_rng(nu, mu_2, sigma_2);\n#&gt;   }\n#&gt; }\n\nNel caso presente, usare un modello robusto non produce nessuna differenza rispetto al modello precedente in quanto non ci sono deviazoni importanti rispetto alla gaussianità e le due deviazioni standard sono simili.\n\nfit_t &lt;- mod_t$sample(\n  data = stan_data,\n  seed = 123,\n  chains = 4,\n  parallel_chains = 4,\n  iter_sampling = 5000, \n  iter_warmup = 2000,\n  adapt_delta = 0.99,\n  show_messages = FALSE\n)\n\n\nfit_t$summary(\"cohen_d\")\n#&gt; # A tibble: 1 × 10\n#&gt;   variable  mean median    sd   mad    q5   q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 cohen_d  0.551  0.551 0.127 0.126 0.342 0.760  1.00    9904.   10452.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_two_means_stan.html#modello-con-iper-priors",
    "href": "chapters/linear_models/08_two_means_stan.html#modello-con-iper-priors",
    "title": "66  Confronto tra due gruppi",
    "section": "\n66.8 Modello con Iper-priors",
    "text": "66.8 Modello con Iper-priors\nIl seguente modello bayesiano per il confronto tra due medie indipendenti utilizza una distribuzione di Student’s t per gestire deviazioni standard disuguali e outlier. Inoltre, include iper-priors per una maggiore flessibilità nella definizione dei parametri delle distribuzioni a priori, che vengono stimate dai dati. Questo approccio permette di incorporare in modo più efficace le incertezze sui parametri dei priors stessi, migliorando la robustezza del modello.\n\n# Path to the Stan file\nstan_file &lt;- here::here(\"stan\", \"kid-score-h.stan\")\n\n# Create a CmdStanModel object\nmod_h &lt;- cmdstan_model(stan_file)\n\n\nfit_h &lt;- mod_h$sample(\n  data = stan_data,\n  seed = 123,\n  chains = 4,\n  parallel_chains = 4,\n  iter_sampling = 5000, \n  iter_warmup = 2000,\n  adapt_delta = 0.99,\n  show_messages = FALSE\n)\n\nAnche in questo caso, la risposta non cambia:\n\nfit_h$summary(\"cohen_d\")\n#&gt; # A tibble: 1 × 10\n#&gt;   variable  mean median    sd   mad    q5   q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 cohen_d  0.555  0.556 0.125 0.125 0.349 0.761  1.00    9452.   11689.\n\nIl nostro obiettivo è comprendere se le medie dei due gruppi sono diverse, e l’incertezza associata alla stima a posteriori del parametro delta è fondamentale per rispondere a questa domanda.\n\nfit_h$summary(\"delta\")\n#&gt; # A tibble: 1 × 10\n#&gt;   variable  mean median    sd   mad    q5   q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 delta     11.2   11.2  2.47  2.46  7.14  15.3  1.00    9362.   11431.\n\nSe l’intervallo di credibilità associato a delta non include lo 0, allora possiamo concludere con un certo grado di sicurezza che le medie dei due gruppi sono diverse. In altre parole, se l’intervallo di credibilità non contiene lo 0, allora ci sono prove convincenti che le medie dei due gruppi sono diverse.\nNel caso presente, l’intervallo di credibilità al 95% non include lo 0. Pertanto, possiamo concludere, con un livello di sicurezza soggettivo del 95%, che il QI dei bambini le cui madri hanno completato le scuole superiori tende ad essere più elevato rispetto a quello dei bambini le cui madri non hanno completato le scuole superiori.\nPossiamo dunque concludere che, per ciò che concerne l’effetto della scolarità della madre sul quoziente di intelligenza del bambino, la dimensione dell’effetto è “media”.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_two_means_stan.html#verifica-di-ipotesi-bayesiana",
    "href": "chapters/linear_models/08_two_means_stan.html#verifica-di-ipotesi-bayesiana",
    "title": "66  Confronto tra due gruppi",
    "section": "\n66.9 Verifica di ipotesi bayesiana",
    "text": "66.9 Verifica di ipotesi bayesiana\nCome ulteriore approfondimento di questa analisi statistica, possiamo esaminare l’approccio bayesiano equivalente al test di ipotesi tradizionale.\nDopo aver ottenuto un campione dalla distribuzione a posteriori del parametro di interesse \\(\\mu\\) per ciascun gruppo, possiamo porci la domanda: qual è la probabilità che il QI di un bambino in un gruppo sia maggiore di quello di un bambino nell’altro gruppo? Per rispondere a questa domanda, utilizzeremo campioni casuali dalle distribuzioni a posteriori dei parametri. Confronteremo le coppie di valori campionati dalle due distribuzioni a posteriori del parametro di interesse e calcoleremo la media di tali confronti. Questo ci fornirà un’indicazione sulla probabilità che il QI di un bambino in un gruppo sia maggiore di quello di un bambino nell’altro gruppo, basandoci sulla distribuzione a posteriori dei parametri stimati dal modello.\nPer eseguire un test d’ipotesi per calcolare la probabilità che $ _1 &gt; _2 $ utilizzando il modello Stan fornito e cmdstanpy, è necessario estrarre i campioni posteriori per i parametri \\(\\mu_1\\) e \\(\\mu_2\\) dopo aver adattato il modello. Successivamente, è possibile calcolare la probabilità basandosi sui campioni posteriori. Ad esempio, ci possiamo chiedere quale sia la probabilità che un bambino la cui madre ha completato la scuola superiore abbia un QI maggiore di un bambino la cui madre non ha completato la scuola superiore.\n\nposterior &lt;- fit$draws(\n  variables = c(\"mu_1\", \"mu_2\", \"delta\"), format = \"draws_df\"\n)\nposterior$mu_1 &lt;- posterior$mu_2 + posterior$delta\n\nprob_mu1_greater_mu2 &lt;- mean(posterior$mu_1 &gt; posterior$mu_2)\ncat(sprintf(\"Probability that mu_1 &gt; mu_2: %.4f\\n\", prob_mu1_greater_mu2))\n#&gt; Probability that mu_1 &gt; mu_2: 1.0000\n\nUna tale probabilità è effettivamente uguale a 1 il che conferma il risultato precedente, ovvero l’iportanza del livello di istruzione della madre per il QI del figlio.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_two_means_stan.html#riflessioni-conclusive",
    "href": "chapters/linear_models/08_two_means_stan.html#riflessioni-conclusive",
    "title": "66  Confronto tra due gruppi",
    "section": "\n66.10 Riflessioni conclusive",
    "text": "66.10 Riflessioni conclusive\nIn questo capitolo abbiamo esaminato la procedura bayesiana per calcolare la distribuzione a posteriori della differenza tra le medie di due gruppi indipendenti. Inoltre, abbiamo esplorato il calcolo della dimensione dell’effetto in termini bayesiani. Nell’esempio trattato, abbiamo considerato il caso in cui la verosimiglianza è descritta da una distribuzione Gaussiana. Tuttavia, va sottolineato che la scelta di una distribuzione specifica per la verosimiglianza non è vincolante nella statistica bayesiana. È possibile utilizzare qualsiasi distribuzione di probabilità, purché sia adeguata ai dati del campione.\nNel caso del confronto tra le medie di due gruppi indipendenti, una distribuzione molto utilizzata è la distribuzione \\(t\\) di Student. Questa distribuzione è particolarmente vantaggiosa quando si desidera condurre un’analisi statistica “robusta”, ovvero un’analisi che non sia influenzata da osservazioni anomale o outlier presenti nei dati. Per questo motivo, la distribuzione \\(t\\) di Student è spesso preferita quando si lavora con dati che potrebbero contenere valori anomali.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_two_means_stan.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/08_two_means_stan.html#informazioni-sullambiente-di-sviluppo",
    "title": "66  Confronto tra due gruppi",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] bayestestR_0.15.0   posterior_1.6.0     cmdstanr_0.8.1.9000\n#&gt;  [4] see_0.9.0           gridExtra_2.3       patchwork_1.3.0    \n#&gt;  [7] bayesplot_1.11.1    psych_2.4.12        scales_1.3.0       \n#&gt; [10] markdown_1.13       knitr_1.49          lubridate_1.9.4    \n#&gt; [13] forcats_1.0.0       stringr_1.5.1       dplyr_1.1.4        \n#&gt; [16] purrr_1.0.2         readr_2.1.5         tidyr_1.3.1        \n#&gt; [19] tibble_3.2.1        ggplot2_3.5.1       tidyverse_2.0.0    \n#&gt; [22] rio_1.2.3           here_1.0.1         \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6         tensorA_0.36.2.1     xfun_0.49           \n#&gt;  [4] htmlwidgets_1.6.4    insight_1.0.0        processx_3.8.4      \n#&gt;  [7] lattice_0.22-6       tzdb_0.4.0           ps_1.8.1            \n#&gt; [10] vctrs_0.6.5          tools_4.4.2          generics_0.1.3      \n#&gt; [13] datawizard_0.13.0    parallel_4.4.2       pacman_0.5.1        \n#&gt; [16] pkgconfig_2.0.3      R.oo_1.27.0          data.table_1.16.4   \n#&gt; [19] checkmate_2.3.2      distributional_0.5.0 lifecycle_1.0.4     \n#&gt; [22] compiler_4.4.2       farver_2.1.2         munsell_0.5.1       \n#&gt; [25] mnormt_2.1.1         htmltools_0.5.8.1    yaml_2.3.10         \n#&gt; [28] pillar_1.10.0        R.utils_2.12.3       abind_1.4-8         \n#&gt; [31] nlme_3.1-166         tidyselect_1.2.1     digest_0.6.37       \n#&gt; [34] stringi_1.8.4        reshape2_1.4.4       labeling_0.4.3      \n#&gt; [37] rprojroot_2.0.4      fastmap_1.2.0        grid_4.4.2          \n#&gt; [40] colorspace_2.1-1     cli_3.6.3            magrittr_2.0.3      \n#&gt; [43] utf8_1.2.4           withr_3.0.2          backports_1.5.0     \n#&gt; [46] timechange_0.3.0     rmarkdown_2.29       matrixStats_1.4.1   \n#&gt; [49] R.methodsS3_1.8.2    hms_1.1.3            evaluate_1.0.1      \n#&gt; [52] haven_2.5.4          rlang_1.1.4          Rcpp_1.0.13-1       \n#&gt; [55] glue_1.8.0           jsonlite_1.8.9       plyr_1.8.9          \n#&gt; [58] R6_2.5.1",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_two_means_stan.html#bibliografia",
    "href": "chapters/linear_models/08_two_means_stan.html#bibliografia",
    "title": "66  Confronto tra due gruppi",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBland, J. M., & Altman, D. G. (2011). Comparisons within randomised groups can be very misleading. Bmj, 342.\n\n\nKruschke, J. (2014). Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan. Academic Press.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_sample_size.html",
    "href": "chapters/linear_models/09_sample_size.html",
    "title": "67  Disegno della ricerca e potere statistico",
    "section": "",
    "text": "67.1 Introduzione\nLa potenza statistica è definita come la probabilità, calcolata prima che uno studio venga condotto, che un determinato confronto raggiunga un livello predefinito di “significatività statistica” (tipicamente un p-value inferiore a 0,05), dato un effetto reale ipotizzato. Per calcolare la potenza, si parte da un’ipotesi sulla dimensione dell’effetto, si fanno assunzioni sulla variabilità dei dati e sulla dimensione del campione, e si utilizzano calcoli probabilistici per determinare la probabilità che il p-value sia inferiore alla soglia stabilita.\nLa visione convenzionale sconsiglia di condurre studi con bassa potenza, poiché hanno basse probabilità di “successo”. Tuttavia, in casi in cui i costi sono molto bassi rispetto ai potenziali benefici, un ricercatore potrebbe decidere di correre il rischio. Come vedremo, però, questa scelta può nascondere insidie significative.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>Disegno della ricerca e potere statistico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_sample_size.html#la-maledizione-del-vincitore-negli-studi-a-bassa-potenza",
    "href": "chapters/linear_models/09_sample_size.html#la-maledizione-del-vincitore-negli-studi-a-bassa-potenza",
    "title": "67  Disegno della ricerca e potere statistico",
    "section": "\n67.2 La maledizione del vincitore negli studi a bassa potenza",
    "text": "67.2 La maledizione del vincitore negli studi a bassa potenza\nIn uno studio con bassa potenza, il “successo” apparente di un risultato statisticamente significativo può essere ingannevole. Quando il segnale è debole e il rumore elevato, i risultati significativi tendono a essere erronei (esagerati o nel segno sbagliato), con scarse probabilità di replicabilità. Questi errori sono noti come errori di tipo M (esagerazione della dimensione dell’effetto) e di tipo S (errore nel segno dell’effetto). Di conseguenza, uno studio a bassa potenza rischia di generare informazioni fuorvianti, contribuendo alla crisi di replicazione.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>Disegno della ricerca e potere statistico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_sample_size.html#stimare-la-dimensione-del-campione",
    "href": "chapters/linear_models/09_sample_size.html#stimare-la-dimensione-del-campione",
    "title": "67  Disegno della ricerca e potere statistico",
    "section": "\n67.3 Stimare la dimensione del campione",
    "text": "67.3 Stimare la dimensione del campione\nPrima di raccogliere dati, è utile stimare la dimensione del campione necessaria per ottenere un certo livello di precisione o per garantire una potenza desiderata. Vediamo i calcoli dettagliati.\n\n67.3.1 Determinazione della dimensione del campione per un errore standard specifico\nSupponiamo di voler stimare un valore medio \\(\\theta\\) della popolazione utilizzando un campione casuale di dimensione \\(n\\). La stima \\(\\bar{y}\\), cioè la media campionaria, ha un errore standard dato da:\n\\[\n\\text{s.e.}(\\bar{y}) = \\frac{\\sigma}{\\sqrt{n}},\n\\]\ndove:\n\n\n\\(\\text{s.e.}(\\bar{y})\\) è l’errore standard della media campionaria,\n\n\\(\\sigma\\) è la deviazione standard della popolazione,\n\n\\(n\\) è la dimensione del campione.\n\nSe vogliamo ottenere un errore standard specifico, denotato con \\(\\text{s.e.}\\), impostiamo l’equazione:\n\\[\n\\text{s.e.} = \\frac{\\sigma}{\\sqrt{n}}.\n\\]\nPer risolvere rispetto a \\(n\\), procediamo come segue:\n\nMoltiplichiamo entrambi i lati per \\(\\sqrt{n}\\) per eliminare il denominatore: \\[\n\\text{s.e.} \\cdot \\sqrt{n} = \\sigma.\n\\]\nDividiamo entrambi i lati per \\(\\text{s.e.}\\): \\[\n\\sqrt{n} = \\frac{\\sigma}{\\text{s.e.}}.\n\\]\nEleviamo al quadrato entrambi i lati per eliminare la radice: \\[\nn = \\left(\\frac{\\sigma}{\\text{s.e.}}\\right)^2.\n\\]\n\nQuesta formula ci dice che la dimensione del campione necessaria per ottenere un determinato errore standard è proporzionale al quadrato del rapporto tra la deviazione standard \\(\\sigma\\) e l’errore standard desiderato \\(\\text{s.e.}\\).\n\n67.3.2 Dimensione del campione per una potenza dell’80%\nSupponiamo ora di voler determinare la dimensione del campione necessaria per ottenere l’80% di potenza nel distinguere un valore \\(\\theta\\) dalla media ipotizzata \\(\\theta_0\\).\nL’errore standard della differenza \\(\\theta - \\theta_0\\) è dato da:\n\\[\n\\text{s.e.} = \\frac{\\sigma}{\\sqrt{n}}.\n\\]\nPer ottenere l’80% di potenza, vogliamo che la differenza osservata \\(\\theta - \\theta_0\\) sia sufficientemente grande da essere rilevata con il livello di significatività prefissato (ad esempio, 5%).\n\n67.3.2.1 Passaggi algebrici per derivare la formula:\n\nPer una potenza dell’80%, la differenza \\(\\theta - \\theta_0\\) deve essere almeno 2,8 volte l’errore standard, dove il valore \\(2.8\\) è dato dalla somma dei quantili della distribuzione normale per il 95% di confidenza (\\(1.96\\)) e per l’80% di potenza (\\(0.84\\)): \\[\n\\theta - \\theta_0 = 2.8 \\cdot \\frac{\\sigma}{\\sqrt{n}}.\n\\]\nRisolviamo per \\(\\sqrt{n}\\): \\[\n\\sqrt{n} = \\frac{2.8 \\cdot \\sigma}{\\theta - \\theta_0}.\n\\]\nEleviamo al quadrato entrambi i lati: \\[\nn = \\left(\\frac{2.8 \\cdot \\sigma}{\\theta - \\theta_0}\\right)^2.\n\\]\n\nQuesta formula fornisce la dimensione del campione necessaria per ottenere l’80% di potenza, dove \\(2.8\\) rappresenta il valore soglia della distribuzione normale standard.\n\n67.3.2.2 Esempio pratico\nSe vogliamo distinguere \\(\\theta\\) da \\(\\theta_0\\) con \\(\\sigma = 10\\) e una differenza minima rilevabile di \\(\\theta - \\theta_0 = 5\\), possiamo calcolare \\(n\\) come segue:\n\\[\nn = \\left(\\frac{2.8 \\cdot 10}{5}\\right)^2 = \\left(5.6\\right)^2 = 31.36.\n\\]\nArrotondando, servono almeno 32 osservazioni.\n\n67.3.3 Correzione per campioni piccoli e distribuzione t\nPer studi con pochi gradi di libertà, l’incertezza sulla stima di \\(\\sigma\\) aumenta, e la distribuzione t di Student diventa più appropriata. In questi casi, il valore \\(2.8\\) deve essere sostituito con un valore più grande, dipendente dai gradi di libertà, per compensare l’incertezza aggiuntiva.\nAd esempio, per uno studio che confronta due gruppi di 6 pazienti ciascuno, i gradi di libertà sono 10. In R, la somma dei quantili della distribuzione t con 10 gradi di libertà per l’80% di potenza e il 95% di confidenza è \\(3.1\\), quindi \\(2.8\\) viene sostituito da \\(3.1\\) nei calcoli per la potenza dell’80%.\n\n# Gradi di libertà\ndf &lt;- 10\n\n# Calcola il quantile per l'80% di potenza (quindi 0.8) e il 95% di confidenza (quindi 0.975)\nt_value_80 &lt;- qt(0.8, df)\nt_value_95 &lt;- qt(0.975, df)\n\n# Somma dei due quantili\nt_total &lt;- t_value_80 + t_value_95\nt_total\n#&gt; [1] 3.11\n\nEseguendo questo codice in R, otteniamo il valore 3.107, che sostituisce il valore \\(2.8\\) nei calcoli per la potenza dell’80% quando si lavora con piccoli campioni e si utilizza la distribuzione t invece della normale standard.\n\n67.3.4 Nota\nQuesto esempio evidenzia come la distribuzione t tenga conto della maggiore variabilità introdotta dalla stima della deviazione standard in campioni di piccole dimensioni, aumentando leggermente il valore soglia richiesto per la potenza desiderata.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>Disegno della ricerca e potere statistico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_sample_size.html#confronto-di-medie",
    "href": "chapters/linear_models/09_sample_size.html#confronto-di-medie",
    "title": "67  Disegno della ricerca e potere statistico",
    "section": "\n67.4 Confronto di Medie",
    "text": "67.4 Confronto di Medie\nEsaminiamo ora il caso del confronto tra le medie di due gruppi indipendenti. Vogliamo determinare la dimensione del campione necessaria per rilevare una differenza significativa \\(\\Delta\\) tra le due medie con una potenza statistica dell’80%.\n\n67.4.1 Errore Standard della Differenza tra Due Medie\nL’errore standard della differenza tra le medie campionarie \\(\\bar{y}_1\\) e \\(\\bar{y}_2\\) è dato da:\n\\[\n\\text{s.e.}(\\bar{y}_1 - \\bar{y}_2) = \\sqrt{\\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}},\n\\]\ndove:\n\n\n\\(\\sigma_1^2\\) e \\(\\sigma_2^2\\) sono le varianze delle popolazioni dei due gruppi,\n\n\\(n_1\\) e \\(n_2\\) sono le dimensioni dei campioni nei due gruppi.\n\n\n67.4.1.1 Caso di Varianze e Dimensioni del Campione Uguali\nSe assumiamo che:\n\nle varianze sono uguali: \\(\\sigma_1 = \\sigma_2 = \\sigma\\),\nle dimensioni dei campioni sono uguali: \\(n_1 = n_2 = n\\),\n\nl’errore standard diventa:\n\n\nSostituiamo le varianze e le dimensioni dei campioni:\n\\[\n\\text{s.e.} = \\sqrt{\\frac{\\sigma^2}{n} + \\frac{\\sigma^2}{n}} = \\sqrt{\\frac{2\\sigma^2}{n}}.\n\\]\n\n\nSemplifichiamo l’espressione:\n\\[\n\\text{s.e.} = \\frac{\\sqrt{2}\\sigma}{\\sqrt{n}}.\n\\]\n\n\n67.4.2 Dimensione del Campione per un Errore Standard Specifico\nSe desideriamo ottenere un errore standard specifico \\(\\text{s.e.}\\), possiamo determinare la dimensione del campione \\(n\\) seguendo questi passaggi:\n\n\nPartiamo dall’espressione dell’errore standard:\n\\[\n\\text{s.e.} = \\frac{\\sqrt{2}\\sigma}{\\sqrt{n}}.\n\\]\n\n\nRisolviamo per \\(\\sqrt{n}\\):\n\\[\n\\sqrt{n} = \\frac{\\sqrt{2}\\sigma}{\\text{s.e.}}.\n\\]\n\n\nEleviamo al quadrato entrambi i membri:\n\\[\nn = \\left( \\frac{\\sqrt{2}\\sigma}{\\text{s.e.}} \\right)^2 = \\frac{2\\sigma^2}{\\text{s.e.}^2}.\n\\]\n\n\n67.4.3 Dimensione del Campione per una Differenza \\(\\Delta\\) con l’80% di Potenza\nPer garantire una potenza dell’80% nel rilevare una differenza \\(\\Delta\\) tra le due medie, seguiamo questi passaggi:\n\n67.4.3.1 Determinazione del Valore Critico\nPer un test bilaterale al livello di significatività del 5%, i valori critici della distribuzione normale standard sono:\n\n\n\\(z_{\\alpha/2} = 1.96\\) (per il 95% di confidenza),\n\n\\(z_{\\text{potenza}} = 0.84\\) (per l’80% di potenza).\n\nLa somma totale è:\n\\[\nz_{\\text{totale}} = z_{\\alpha/2} + z_{\\text{potenza}} = 1.96 + 0.84 = 2.8.\n\\]\n\n67.4.3.2 Relazione tra \\(\\Delta\\) ed Errore Standard\nLa differenza minima rilevabile \\(\\Delta\\) è legata all’errore standard dalla relazione:\n\n\nImpostiamo l’equazione:\n\\[\n\\Delta = z_{\\text{totale}} \\times \\text{s.e.} = 2.8 \\times \\text{s.e.}.\n\\]\n\n\nSostituiamo l’espressione per \\(\\text{s.e.}\\):\n\\[\n\\Delta = 2.8 \\times \\frac{\\sqrt{2}\\sigma}{\\sqrt{n}}.\n\\]\n\n\nCalcoliamo il coefficiente:\n\\[\n2.8 \\times \\sqrt{2} = 2.8 \\times 1.4142 \\approx 3.96.\n\\]\nQuindi:\n\\[\n\\Delta = 3.96 \\times \\frac{\\sigma}{\\sqrt{n}}.\n\\]\n\n\nRisolviamo per \\(\\sqrt{n}\\):\n\\[\n\\sqrt{n} = \\frac{3.96 \\sigma}{\\Delta}.\n\\]\n\n\nEleviamo al quadrato entrambi i membri:\n\\[\nn = \\left( \\frac{3.96 \\sigma}{\\Delta} \\right)^2.\n\\]\n\n\n67.4.4 Formula Finale per la Dimensione del Campione\nLa dimensione del campione necessaria per ciascun gruppo è data da:\n\\[\nn = \\left( \\frac{3.96 \\sigma}{\\Delta} \\right)^2.\n\\]\nPer semplificare i calcoli, possiamo arrotondare \\(3.96\\) a \\(4\\):\n\\[\nn = \\left( \\frac{4 \\sigma}{\\Delta} \\right)^2.\n\\]\nNota Importante: Questa formula si applica quando:\n\n\nLe varianze delle popolazioni sono uguali (\\(\\sigma_1 = \\sigma_2 = \\sigma\\)).\n\nLe dimensioni dei campioni nei due gruppi sono uguali (\\(n_1 = n_2 = n\\)).\n\nIl totale dei campioni è \\(N = 2n\\).\n\n67.4.5 Interpretazione della Formula\n\n\nSe la deviazione standard \\(\\sigma\\) è elevata: C’è maggiore variabilità nei dati, quindi è necessario un campione più grande per rilevare una differenza \\(\\Delta\\) con la stessa potenza.\n\nSe la differenza \\(\\Delta\\) è piccola: Serve un campione più grande per garantire che la differenza sia rilevabile con l’80% di potenza.\n\n67.4.6 Esempio Pratico\nSupponiamo di voler rilevare una differenza \\(\\Delta = 5\\) unità tra due gruppi, con una deviazione standard comune \\(\\sigma = 10\\) unità.\nCalcolo della dimensione del campione per ciascun gruppo:\n\n\nUtilizziamo la formula:\n\\[\nn = \\left( \\frac{4 \\times 10}{5} \\right)^2 = \\left( \\frac{40}{5} \\right)^2 = \\left( 8 \\right)^2 = 64.\n\\]\n\n\nRisultato:\n\n\n64 partecipanti per gruppo.\n\nTotale di 128 partecipanti.\n\n\n\n67.4.7 Caso con Campione Totale Fissato\nSe il campione totale è fissato a \\(n\\), con dimensioni dei gruppi \\(n_1 = n_2 = n/2\\), l’errore standard cambia leggermente.\n\n67.4.7.1 Calcolo dell’Errore Standard\n\n\nSostituiamo \\(n_1 = n_2 = n/2\\) nell’errore standard:\n\\[\n\\text{s.e.} = \\sqrt{\\frac{\\sigma^2}{n/2} + \\frac{\\sigma^2}{n/2}} = \\sqrt{2 \\times \\frac{\\sigma^2}{n/2}}.\n\\]\n\n\nSemplifichiamo l’espressione:\n\\[\n\\text{s.e.} = \\sqrt{\\frac{4\\sigma^2}{n}} = \\frac{2\\sigma}{\\sqrt{n}}.\n\\]\n\n\n67.4.7.2 Dimensione del Campione\n\n\nRelazione tra \\(\\Delta\\) ed errore standard:\n\\[\n\\Delta = 2.8 \\times \\text{s.e.} = 2.8 \\times \\frac{2\\sigma}{\\sqrt{n}} = \\frac{5.6 \\sigma}{\\sqrt{n}}.\n\\]\n\n\nRisolviamo per \\(\\sqrt{n}\\):\n\\[\n\\sqrt{n} = \\frac{5.6 \\sigma}{\\Delta}.\n\\]\n\n\nEleviamo al quadrato:\n\\[\nn = \\left( \\frac{5.6 \\sigma}{\\Delta} \\right)^2.\n\\]\n\n\nIn questo scenario, la dimensione totale del campione è \\(n\\), con \\(n/2\\) partecipanti per ciascun gruppo.\n\n67.4.8 Scelta della Formula Adeguata\n\n\nSe \\(n\\) rappresenta la dimensione del campione per gruppo:\n\\[\nn = \\left( \\frac{4 \\sigma}{\\Delta} \\right)^2.\n\\]\n\n\nSe \\(n\\) rappresenta la dimensione totale del campione:\n\\[\nn = \\left( \\frac{5.6 \\sigma}{\\Delta} \\right)^2.\n\\]\n\n\nAssicurarsi di chiarire come si definisce \\(n\\) è fondamentale per applicare correttamente le formule.\n\n67.4.9 Sintesi\n\n\nVarianze e dimensioni uguali nei due gruppi semplificano i calcoli.\n\nLa dimensione del campione aumenta con l’aumentare della deviazione standard \\(\\sigma\\) e con la diminuzione della differenza \\(\\Delta\\) che si vuole rilevare.\n\nEssere chiari sulla definizione di \\(n\\) (per gruppo o totale) evita errori nei calcoli.\n\n\nEsempio 67.1 Se la differenza \\(\\Delta\\) che vogliamo rilevare è pari a metà della deviazione standard (\\(\\Delta = 0.5\\sigma\\)), allora la formula ci dirà quanti partecipanti sono necessari in ciascun gruppo per rilevare questa differenza con l’80% di potenza. Ad esempio, se \\(\\Delta = 0.5\\sigma\\), la dimensione totale del campione sarà:\n\\[\nn = \\left(\\frac{5.6 \\sigma}{0.5\\sigma}\\right)^2 = (11.2)^2 = 125.44 \\approx 126.\n\\]\nQuindi, servirebbero 63 partecipanti per gruppo.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>Disegno della ricerca e potere statistico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_sample_size.html#riflessioni-conclusive",
    "href": "chapters/linear_models/09_sample_size.html#riflessioni-conclusive",
    "title": "67  Disegno della ricerca e potere statistico",
    "section": "\n67.5 Riflessioni Conclusive",
    "text": "67.5 Riflessioni Conclusive\nLa determinazione della dimensione del campione è un passaggio cruciale nella progettazione degli studi, poiché garantisce che le inferenze siano robuste e i risultati affidabili. Questo capitolo ha mostrato come le caratteristiche dei dati, come la deviazione standard e la differenza attesa tra i gruppi, influenzino direttamente la dimensione del campione necessaria per ottenere una potenza statistica adeguata. Inoltre, l’attenzione ai dettagli, come l’uso della distribuzione t per piccoli campioni, sottolinea l’importanza di considerare le fonti di variabilità e incertezza nei calcoli. Pianificare con rigore la dimensione del campione non solo aumenta la probabilità di rilevare effetti significativi, ma contribuisce anche a ridurre il rischio di risultati fuorvianti, migliorando così la qualità complessiva della ricerca scientifica.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>Disegno della ricerca e potere statistico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_sample_size.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/09_sample_size.html#informazioni-sullambiente-di-sviluppo",
    "title": "67  Disegno della ricerca e potere statistico",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pointblank_0.12.2 haven_2.5.4       labelled_2.13.0   mice_3.17.0      \n#&gt;  [5] see_0.9.0         gridExtra_2.3     patchwork_1.3.0   bayesplot_1.11.1 \n#&gt;  [9] psych_2.4.12      scales_1.3.0      markdown_1.13     knitr_1.49       \n#&gt; [13] lubridate_1.9.4   forcats_1.0.0     stringr_1.5.1     dplyr_1.1.4      \n#&gt; [17] purrr_1.0.2       readr_2.1.5       tidyr_1.3.1       tibble_3.2.1     \n#&gt; [21] ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      shape_1.4.6.1     xfun_0.49         htmlwidgets_1.6.4\n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2      \n#&gt;  [9] generics_0.1.3    parallel_4.4.2    pan_1.9           pacman_0.5.1     \n#&gt; [13] pkgconfig_2.0.3   jomo_2.7-6        Matrix_1.7-1      lifecycle_1.0.4  \n#&gt; [17] compiler_4.4.2    farver_2.1.2      munsell_0.5.1     mnormt_2.1.1     \n#&gt; [21] codetools_0.2-20  htmltools_0.5.8.1 glmnet_4.1-8      nloptr_2.1.1     \n#&gt; [25] pillar_1.10.0     MASS_7.3-61       iterators_1.0.14  rpart_4.1.23     \n#&gt; [29] boot_1.3-31       foreach_1.5.2     mitml_0.4-5       nlme_3.1-166     \n#&gt; [33] tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4     splines_4.4.2    \n#&gt; [37] rprojroot_2.0.4   fastmap_1.2.0     grid_4.4.2        blastula_0.3.5   \n#&gt; [41] colorspace_2.1-1  cli_3.6.3         magrittr_2.0.3    survival_3.8-3   \n#&gt; [45] broom_1.0.7       withr_3.0.2       backports_1.5.0   timechange_0.3.0 \n#&gt; [49] rmarkdown_2.29    nnet_7.3-19       lme4_1.1-35.5     hms_1.1.3        \n#&gt; [53] evaluate_1.0.1    rlang_1.1.4       Rcpp_1.0.13-1     glue_1.8.0       \n#&gt; [57] minqa_1.2.8       jsonlite_1.8.9    R6_2.5.1",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>Disegno della ricerca e potere statistico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_sample_size.html#bibliografia",
    "href": "chapters/linear_models/09_sample_size.html#bibliografia",
    "title": "67  Disegno della ricerca e potere statistico",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other stories. Cambridge University Press.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>Disegno della ricerca e potere statistico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_1via.html",
    "href": "chapters/linear_models/10_anova_1via.html",
    "title": "68  ANOVA ad una via",
    "section": "",
    "text": "68.1 Preparazione del Notebook\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(cmdstanr, posterior, bayestestR, brms, emmeans)",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_1via.html#introduzione",
    "href": "chapters/linear_models/10_anova_1via.html#introduzione",
    "title": "68  ANOVA ad una via",
    "section": "\n68.2 Introduzione",
    "text": "68.2 Introduzione\nNel Capitolo ?? abbiamo visto come costruire regressori fittizi (dummy) per rappresentare l’effetto di variabili categoriche (fattori) a due livelli. Consideriamo ora il caso di un singolo fattore con più di due livelli. Per esempio, nel caso di una classificazione a tre categorie, possiamo adottare il modello\n\\[\nY_i = \\alpha + \\gamma_1 D_{i1} + \\gamma_2 D_{i2} + \\varepsilon_i,\n\\tag{68.1}\\]\nutilizzando la seguente codifica per i regressori dummy:\n\\[\n\\begin{array}{c|cc}\n\\text{Gruppo} & D_1 & D_2 \\\\\n\\hline\n1 & 1 & 0 \\\\\n2 & 0 & 1 \\\\\n3 & 0 & 0\n\\end{array}\n\\tag{68.2}\\]\nL’aspettativa della variabile di risposta in ciascun gruppo (cioè in ciascuna categoria o livello del fattore) corrisponde alla media di popolazione del gruppo, indicata con \\(\\mu_j\\) per il gruppo \\(j\\). Poiché l’errore \\(\\varepsilon\\) ha media zero, in base alle usuali ipotesi del modello lineare, prendendo l’aspettativa di entrambi i membri dell’equazione (8.1) si ottengono le relazioni seguenti tra le medie di gruppo e i parametri:\n\\[\n\\begin{aligned}\n\\text{Gruppo 1: } \\mu_1 &= \\alpha + \\gamma_1 \\cdot 1 + \\gamma_2 \\cdot 0 = \\alpha + \\gamma_1, \\\\\n\\text{Gruppo 2: } \\mu_2 &= \\alpha + \\gamma_1 \\cdot 0 + \\gamma_2 \\cdot 1 = \\alpha + \\gamma_2, \\\\\n\\text{Gruppo 3: } \\mu_3 &= \\alpha + \\gamma_1 \\cdot 0 + \\gamma_2 \\cdot 0 = \\alpha.\n\\end{aligned}\n\\tag{68.3}\\]\nQui troviamo tre parametri \\((\\alpha, \\gamma_1, \\gamma_2)\\) e tre medie di gruppo, per cui è possibile risolvere in modo univoco i parametri in termini delle medie di gruppo:\n\\[\n\\alpha = \\mu_3, \\quad \\gamma_1 = \\mu_1 - \\mu_3, \\quad \\gamma_2 = \\mu_2 - \\mu_3.\n\\tag{68.4}\\]\nNon sorprende che \\(\\alpha\\) rappresenti la media della categoria di riferimento (il Gruppo 3), mentre \\(\\gamma_1\\) e \\(\\gamma_2\\) descrivono quanto le altre due medie di gruppo si discostino dalla media della categoria di riferimento.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_1via.html#simulazione",
    "href": "chapters/linear_models/10_anova_1via.html#simulazione",
    "title": "68  ANOVA ad una via",
    "section": "\n68.3 Simulazione",
    "text": "68.3 Simulazione\nPer esaminare un’applicazione pratica, simuliamo i dati di un fattore con 3 livelli:\n\n# Imposta un seme per riproducibilità (opzionale)\nset.seed(123)\n\n# Definiamo il numero di osservazioni per ogni gruppo\nn &lt;- 30\n\n# Definiamo le medie\nmean_control &lt;- 30\nmean_psico1  &lt;- 25\nmean_psico2  &lt;- 20\n\n# Definiamo la deviazione standard (ipotizziamo la stessa per tutti i gruppi)\nsd_value &lt;- 5\n\n# Generiamo i dati casuali da distribuzioni normali\ncontrollo     &lt;- rnorm(n, mean_control, sd_value)\npsicoterapia1 &lt;- rnorm(n, mean_psico1,  sd_value)\npsicoterapia2 &lt;- rnorm(n, mean_psico2,  sd_value)\n\n# Creiamo un data frame con due colonne:\n# - \"condizione\": indica il gruppo (controllo / psicoterapia1 / psicoterapia2)\n# - \"punteggio\":  contiene i dati numerici generati\ndf &lt;- data.frame(\n  condizione = rep(c(\"controllo\", \"psicoterapia1\", \"psicoterapia2\"), each = n),\n  punteggio  = c(controllo, psicoterapia1, psicoterapia2)\n)\n\n\nhead(df)\n#&gt;   condizione punteggio\n#&gt; 1  controllo      27.2\n#&gt; 2  controllo      28.8\n#&gt; 3  controllo      37.8\n#&gt; 4  controllo      30.4\n#&gt; 5  controllo      30.6\n#&gt; 6  controllo      38.6\n\n\ntail(df)\n#&gt;       condizione punteggio\n#&gt; 85 psicoterapia2      18.9\n#&gt; 86 psicoterapia2      21.7\n#&gt; 87 psicoterapia2      25.5\n#&gt; 88 psicoterapia2      22.2\n#&gt; 89 psicoterapia2      18.4\n#&gt; 90 psicoterapia2      25.7\n\nEsaminiamo la distribuzione dei dati nei tre gruppi:\n\nggplot(df, aes(x = condizione, y = punteggio, fill = condizione)) +\n  # Il violin plot\n  geom_violin(trim = FALSE) +\n  # Boxplot interno al violino\n  geom_boxplot(width = 0.2, outlier.shape = NA) +\n  labs(\n    title = \"Depressione in funzione del gruppo\",\n    x = \"Gruppo\",\n    y = \"Depressione\"\n  ) +\n  # Rimuovi la legenda \n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\nCalcoliamo le medie dei gruppi:\n\ndf |&gt; \n  group_by(condizione) |&gt; \n  summarize(\n    avg = mean(punteggio),\n    std = sd(punteggio)\n  )\n#&gt; # A tibble: 3 × 3\n#&gt;   condizione      avg   std\n#&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 controllo      29.8  4.91\n#&gt; 2 psicoterapia1  25.9  4.18\n#&gt; 3 psicoterapia2  20.1  4.35\n\nNel caso presente, desideriamo creare due variabili dummy per codificare il fattore \\(`condizione`\\), assumendo come gruppo di riferimento (baseline) la categoria controllo. Ecco come procedere:\n\ndf$condizione &lt;- factor(df$condizione)\ndf$condizione &lt;- relevel(df$condizione, ref = \"controllo\")\ncontrasts(df$condizione)\n#&gt;               psicoterapia1 psicoterapia2\n#&gt; controllo                 0             0\n#&gt; psicoterapia1             1             0\n#&gt; psicoterapia2             0             1\n\nCon questa impostazione, il modello di regressione assume la forma:\n\\[\nY_i = \\beta_0 \\;+\\; \\beta_1 \\,(\\text{psicoterapia1}_i) \\;+\\; \\beta_2 \\,(\\text{psicoterapia2}_i) \\;+\\; \\varepsilon_i,\n\\]\ndove:\n\n\n\\(\\beta_0\\) (l’intercetta) rappresenta la media della condizione di controllo.\n\n\n\\(\\beta_1\\) indica la differenza tra la media del gruppo psicoterapia1 e la media del gruppo controllo.\n\n\n\\(\\beta_2\\) indica la differenza tra la media del gruppo psicoterapia2 e la media del gruppo controllo.\n\nLe variabili \\(\\text{psicoterapia1}_i\\) e \\(\\text{psicoterapia2}_i\\) sono i regressori dummy (0/1) che R crea per i due gruppi di psicoterapia, mentre \\(\\varepsilon_i\\) è il termine di errore.\nIn particolare, nei vari gruppi:\n\nGruppo di controllo: \\(\\text{psicoterapia1}_i = 0\\) e \\(\\text{psicoterapia2}_i = 0\\).\\[\nE[Y_{\\text{controllo}}] = \\beta_0.\n\\]\nGruppo psicoterapia1: \\(\\text{psicoterapia1}_i = 1\\) e \\(\\text{psicoterapia2}_i = 0\\).\\[\nE[Y_{\\text{psicoterapia1}}] = \\beta_0 + \\beta_1.\n\\]\nGruppo psicoterapia2: \\(\\text{psicoterapia1}_i = 0\\) e \\(\\text{psicoterapia2}_i = 1\\).\\[\nE[Y_{\\text{psicoterapia2}}] = \\beta_0 + \\beta_2.\n\\]\n\nIn altre parole, \\(\\beta_1\\) e \\(\\beta_2\\) misurano rispettivamente di quanto la media di psicoterapia1 e di psicoterapia2 si discostino dalla media del gruppo di riferimento (controllo).\n\n\n68.3.1 Stima del modello e interpretazione dei coefficienti\nPer verificare quanto detto, stimiamo il modello di regressione con l’approccio frequentista:\n\nfm1 &lt;- lm(punteggio ~ condizione, data = df)\nsummary(fm1)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = punteggio ~ condizione, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -11.668  -2.620  -0.183   2.681  10.128 \n#&gt; \n#&gt; Coefficients:\n#&gt;                         Estimate Std. Error t value Pr(&gt;|t|)\n#&gt; (Intercept)               29.764      0.819   36.33  &lt; 2e-16\n#&gt; condizionepsicoterapia1   -3.873      1.159   -3.34   0.0012\n#&gt; condizionepsicoterapia2   -9.642      1.159   -8.32  1.1e-12\n#&gt; \n#&gt; Residual standard error: 4.49 on 87 degrees of freedom\n#&gt; Multiple R-squared:  0.446,  Adjusted R-squared:  0.434 \n#&gt; F-statistic: 35.1 on 2 and 87 DF,  p-value: 6.75e-12\n\nPossiamo anche calcolare le medie empiriche di ciascun gruppo:\n\nout &lt;- tapply(df$punteggio, df$condizione, mean)\nout\n#&gt;     controllo psicoterapia1 psicoterapia2 \n#&gt;          29.8          25.9          20.1\n\ne quindi le differenze rispetto al controllo:\n\nout[2] - out[1]  # Differenza psico1 - controllo\n#&gt; psicoterapia1 \n#&gt;         -3.87\nout[3] - out[1]  # Differenza psico2 - controllo\n#&gt; psicoterapia2 \n#&gt;         -9.64\n\nLe stime dei coefficienti ottenute da summary(fm1) coincideranno con queste differenze (a meno di arrotondamenti). In altre parole, l’inferenza (frequentista o bayesiana) sul coefficiente \\(\\beta_j\\) corrisponde all’inferenza su tale scostamento tra medie.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_1via.html#contrasti-personalizzati",
    "href": "chapters/linear_models/10_anova_1via.html#contrasti-personalizzati",
    "title": "68  ANOVA ad una via",
    "section": "\n68.4 Contrasti personalizzati",
    "text": "68.4 Contrasti personalizzati\nQuando abbiamo un fattore con tre livelli — ad esempio, controllo, psicoterapia1 e psicoterapia2 — esistono vari schemi di codifica per le variabili dummy. Scegliere lo schema di codifica adeguato significa decidere come interpretare i coefficienti del modello. Per esempio, se vogliamo rispondere alla domanda «la media congiunta delle due psicoterapie è minore (o maggiore) della media del controllo?», possiamo definire un contrasto lineare ad hoc che confronti il gruppo controllo con la media delle due psicoterapie.\n\n68.4.1 Possibili approcci\n\n\nCreare un contrasto lineare ad hoc che confronti \\(\\{\\text{psicoterapia1}, \\text{psicoterapia2}\\}\\) con controllo.\n\n\nRaggruppare i due livelli di psicoterapia in un nuovo fattore binario (controllo vs. psicoterapia) e condurre un test su questo fattore a due livelli (ma in questo modo si perderebbe la distinzione tra “psicoterapia1” e “psicoterapia2”).\n\nIl metodo più flessibile è definire direttamente contrasti personalizzati sul fattore a tre livelli. In tal modo, possiamo gestire contemporaneamente più confronti, ad esempio:\n\n\nContrasto 1: controllo vs. media (psicoterapia1, psicoterapia2)\n\n\nContrasto 2: psicoterapia1 vs. psicoterapia2\n\n\n\n68.4.2 Contrasti personalizzati in R\nObiettivo: definire due contrasti ortogonali per confrontare (1) il gruppo di controllo con la media delle due psicoterapie e (2) psicoterapia1 con psicoterapia2.\n\n68.4.3 Contrasto 1: Controllo vs. (psico1 + psico2)\n\n\nContrasto “grezzo” (non normalizzato):\n\\[\n  (-2,\\; +1,\\; +1)\n  \\quad \\text{con} \\quad -2 + 1 + 1 = 0.\n\\]\nSe usassimo questi pesi direttamente, il coefficiente stimato \\(\\beta_1\\) sarebbe proporzionale alla differenza tra la media del controllo e la media delle due psicoterapie. Tuttavia, il passo da controllo (\\(-2\\)) a ciascuna psicoterapia (\\(+1\\)) è di 3 unità, il che può rendere il coefficiente meno intuitivo da leggere.\n\nNormalizzazione\nPossiamo dividere ogni valore di \\((-2, +1, +1)\\) per la somma assoluta (o per la radice della somma dei quadrati, o per un altro fattore) al fine di ottenere contrasti più semplici.\nAd esempio, se dividiamo \\((-2, +1, +1)\\) per 3, otteniamo \\(\\bigl(-\\tfrac{2}{3}, +\\tfrac{1}{3}, +\\tfrac{1}{3}\\bigr)\\). In tal caso, passare da controllo a psicoterapia fa variare il contrasto di 1 (anziché di 3).\n\n68.4.4 Contrasto 2: psico1 vs. psico2\n\n\nContrasto “grezzo”:\n\\[\n   (\\,0,\\; +1,\\; -1\\,)\n   \\quad \\text{con} \\quad 0 + 1 + (-1) = 0.\n\\]\nQuesto pesi confrontano direttamente psicoterapia1 con psicoterapia2.\n\nNormalizzazione (opzionale)\nPossiamo anche qui dividere per la radice della somma dei quadrati \\(\\sqrt{(0^2 + 1^2 + (-1)^2)}= \\sqrt{2}\\), oppure lasciare i pesi così (poiché qui già passare da p1 a p2 equivale a 2 unità, e potrebbe essere chiaro abbastanza).\n\nNel codice seguente, si è scelto di riscalare (o “normalizzare”) i pesi in modo leggermente diverso, ottenendo numeri come 0.6667 e -0.3333. L’importante è che:\n\nLa somma dei pesi in ciascun contrasto rimanga 0.\n\nI due contrasti siano ortogonali (i prodotti incrociati dei pesi per ogni livello sommano a 0).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_1via.html#codice-r-per-impostare-e-verificare-i-contrasti",
    "href": "chapters/linear_models/10_anova_1via.html#codice-r-per-impostare-e-verificare-i-contrasti",
    "title": "68  ANOVA ad una via",
    "section": "\n68.5 Codice R per impostare e verificare i Contrasti",
    "text": "68.5 Codice R per impostare e verificare i Contrasti\nDi seguito mostriamo un esempio concreto. Prima descriviamo la matrice di contrasti “grezza” e poi quella normalizzata usata nel codice.\n\n68.5.1 Matrice di contrasti “grezza”\n\n# Contrasto 1 (grezzo):  -2, +1, +1\n# Contrasto 2 (grezzo):   0, +1, -1\n\nmy_contrasts_raw &lt;- matrix(c(\n  -2,  0,  # controllo\n   1, +1,  # psicoterapia1\n   1, -1   # psicoterapia2\n), ncol = 2, byrow = TRUE)\n\ncolnames(my_contrasts_raw) &lt;- c(\"Ctrl_vs_PsicoMean\", \"P1_vs_P2\")\nrownames(my_contrasts_raw) &lt;- c(\"controllo\",\"psicoterapia1\",\"psicoterapia2\")\nmy_contrasts_raw\n#&gt;               Ctrl_vs_PsicoMean P1_vs_P2\n#&gt; controllo                    -2        0\n#&gt; psicoterapia1                 1        1\n#&gt; psicoterapia2                 1       -1\n\n\n68.5.2 Matrice di contrasti “normalizzata” (quella effettivamente nel codice)\nNel codice che segue, i pesi sono stati riscalati per avere differenze di “1” anziché “3” o “2” quando si passa da un gruppo all’altro. Puoi notare, per il primo contrasto, i valori \\((+0.6667, -0.3333, -0.3333)\\) invece di \\((+1, -0.5, -0.5)\\) o \\((-2, +1, +1)\\). Sono solo versioni multiplicativamente equivalenti.\n\nset.seed(123)\n\n# Esempio: definizione della matrice di contrasti\nmy_contrasts &lt;- matrix(c(\n  0.6667,  0,    # controllo  = +0.6667\n  -0.3333, 0.5,  # p1         = -0.3333\n  -0.3333, -0.5  # p2         = -0.3333\n), ncol = 2, byrow = TRUE)\n\ncolnames(my_contrasts) &lt;- c(\"Ctrl_vs_PsicoMean\", \"P1_vs_P2\")\nrownames(my_contrasts) &lt;- c(\"controllo\", \"psicoterapia1\", \"psicoterapia2\")\n\n# Verifica: ogni colonna deve sommare a 0\ncolSums(my_contrasts)  # dovrebbero essere circa (0, 0)\n#&gt; Ctrl_vs_PsicoMean          P1_vs_P2 \n#&gt;             1e-04             0e+00\n\n# Verifica: i due contrasti sono ortogonali?\nsum(my_contrasts[,1] * my_contrasts[,2])  # dovrebbe essere 0\n#&gt; [1] 0\n\n\n68.5.3 Applicazione al modello\n\n# 1) Convertiamo 'condizione' in fattore (se non già fattore)\ndf$condizione &lt;- factor(df$condizione)\n\n# 2) Assegnamo la matrice di contrasti al fattore\ncontrasts(df$condizione) &lt;- my_contrasts\n\n# 3) Stimiamo il modello di regressione lineare\nmod_custom &lt;- lm(punteggio ~ condizione, data = df)\n\n# 4) Esaminiamo il riepilogo\nsummary(mod_custom)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = punteggio ~ condizione, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -11.668  -2.620  -0.183   2.681  10.128 \n#&gt; \n#&gt; Coefficients:\n#&gt;                             Estimate Std. Error t value Pr(&gt;|t|)\n#&gt; (Intercept)                   25.259      0.473   53.40  &lt; 2e-16\n#&gt; condizioneCtrl_vs_PsicoMean    6.758      1.003    6.73  1.7e-09\n#&gt; condizioneP1_vs_P2             5.770      1.159    4.98  3.2e-06\n#&gt; \n#&gt; Residual standard error: 4.49 on 87 degrees of freedom\n#&gt; Multiple R-squared:  0.446,  Adjusted R-squared:  0.434 \n#&gt; F-statistic: 35.1 on 2 and 87 DF,  p-value: 6.75e-12",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_1via.html#interpretazione-dei-coefficienti",
    "href": "chapters/linear_models/10_anova_1via.html#interpretazione-dei-coefficienti",
    "title": "68  ANOVA ad una via",
    "section": "\n68.6 Interpretazione dei coefficienti",
    "text": "68.6 Interpretazione dei coefficienti\n\nIntercetta (\\(\\hat{\\alpha}\\))\nIn base allo schema di contrasti adottato, può non coincidere con la media effettiva di uno dei tre gruppi. Spesso rappresenta una qualche combinazione lineare delle medie di controllo, psicoterapia1 e psicoterapia2.\n\nPrimo coefficiente (“Ctrl_vs_PsicoMean”)\nConfronta la media del gruppo di controllo con la media (eventualmente pesata) delle due psicoterapie.\n\nSe è positivo, il controllo ha una media maggiore rispetto a quella (combinata) delle psicoterapie.\n\nSe è negativo, indica il contrario (psicoterapie &gt; controllo).\n\n\n\nSecondo coefficiente (“P1_vs_P2”)\nConfronta direttamente psicoterapia1 con psicoterapia2.\n\nSe è positivo, psicoterapia1 ha un punteggio maggiore (in media) di psicoterapia2.\n\nSe è negativo, psicoterapia2 supera psicoterapia1.\n\n\n\nPer controllare manualmente queste differenze, puoi calcolare:\n\n\n\\(\\text{controllo} - \\frac{\\text{psicoterapia1} + \\text{psicoterapia2}}{2}\\):\n\n\nout[1] - (out[2] + out[3]) / 2\n#&gt; controllo \n#&gt;      6.76\n\ndove out[i] è la media empirica del gruppo \\(i\\).\n\n\n\\(\\text{psicoterapia1} - \\text{psicoterapia2}\\):\n\n\nout[2] - out[3]\n#&gt; psicoterapia1 \n#&gt;          5.77\n\nIn sintesi,\n\nLa matrice grezza \\(\\begin{pmatrix} -2 & 0 \\\\ 1 & 1 \\\\ 1 & -1 \\end{pmatrix}\\) e la matrice normalizzata (con valori decimali) rappresentano lo stesso schema di contrasti, ma con differenti scale numeriche.\n\nL’aspetto essenziale è che ciascun contrasto sommi a 0 e che i due contrasti siano ortogonali (prodotto incrociato dei pesi = 0), garantendo interpretazioni indipendenti.\n\nNormalizzare i pesi modifica il valore numerico dei coefficienti, ma non la loro significatività statistica.\n\nScegliendo opportunamente la matrice dei contrasti, possiamo verificare se la media congiunta di psicoterapia1 e psicoterapia2 differisce da quella di controllo e, contemporaneamente, se psicoterapia1 differisce da psicoterapia2. L’eventuale normalizzazione dei pesi non incide sulle conclusioni del test, ma influenza la scala numerica dei coefficienti.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_1via.html#pacchetto-emmeans",
    "href": "chapters/linear_models/10_anova_1via.html#pacchetto-emmeans",
    "title": "68  ANOVA ad una via",
    "section": "\n68.7 Pacchetto emmeans\n",
    "text": "68.7 Pacchetto emmeans\n\nLe stesse analisi descritte sopra possono essere svolte utilizzando le funzioni del pacchetto emmeans. L’idea è:\n\nStimare un modello lineare (come prima).\n\nCalcolare le stime delle medie marginali (le “means” del fattore condizione) tramite emmeans().\n\nDefinire i contrasti di interesse con la funzione contrast().\n\nIn questo modo, è possibile ottenere stime delle medie di ciascun gruppo e confrontarle (ad esempio “controllo” vs. “media delle psicoterapie” o “psicoterapia1” vs. “psicoterapia2”), anche in forma di test statistici (p-value, intervalli di confidenza, ecc.).\n\n68.7.1 Preparazione del modello\nUsiamo ora un modello bayesiano, con prior non informativi o debolmente informativi:\n\nmod &lt;- brm(punteggio ~ condizione, data = df, backend = \"cmdstanr\")\n\n\nsummary(mod)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: punteggio ~ condizione \n#&gt;    Data: df (Number of observations: 90) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;                             Estimate Est.Error l-95% CI u-95% CI Rhat\n#&gt; Intercept                      25.25      0.49    24.31    26.18 1.00\n#&gt; condizioneCtrl_vs_PsicoMean     6.75      1.01     4.82     8.71 1.00\n#&gt; condizioneP1_vs_P2              5.81      1.20     3.42     8.20 1.00\n#&gt;                             Bulk_ESS Tail_ESS\n#&gt; Intercept                       5158     3133\n#&gt; condizioneCtrl_vs_PsicoMean     4635     2754\n#&gt; condizioneP1_vs_P2              4703     3121\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     4.53      0.34     3.93     5.28 1.00     3130     2786\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n68.7.2 Calcolo delle medie marginali con emmeans\n\nCalcoliamo le stime delle medie (ls-means) per ciascun livello di ‘condizione’:\n\nem &lt;- emmeans(mod, specs = \"condizione\")\nem\n#&gt;  condizione    emmean lower.HPD upper.HPD\n#&gt;  controllo       29.8      28.2      31.4\n#&gt;  psicoterapia1   25.9      24.2      27.5\n#&gt;  psicoterapia2   20.1      18.4      21.7\n#&gt; \n#&gt; Point estimate displayed: median \n#&gt; HPD interval probability: 0.95\n\nQuesto oggetto em contiene le medie stimate (e i relativi errori standard) per i tre gruppi: “controllo”, “psicoterapia1” e “psicoterapia2”.\n\n68.7.3 Confronti (pairwise) tra i gruppi\nConfronti a coppie tra tutti i livelli di ‘condizione’ (psicoterapia1 vs controllo, ecc.):\n\npairs(em)\n#&gt;  contrast                      estimate lower.HPD upper.HPD\n#&gt;  controllo - psicoterapia1         3.85      1.63      6.11\n#&gt;  controllo - psicoterapia2         9.65      7.31     12.01\n#&gt;  psicoterapia1 - psicoterapia2     5.80      3.36      8.13\n#&gt; \n#&gt; Point estimate displayed: median \n#&gt; HPD interval probability: 0.95\n\n\n68.7.4 Contrasti personalizzati\nReplichiamo i contrasti “ad hoc” (“controllo vs (psico1+psico2)” e “psicoterapia1 vs psicoterapia2”) utilizzati in precedenza:\n\n# Definiamo i contrasti desiderati\nmy_list &lt;- list(\n  \"Ctrl_vs_PsicoMean\" = \n    c(\"controllo\" = 1, \"psicoterapia1\" = -0.5, \"psicoterapia2\" = -0.5),\n  \"P1_vs_P2\"          = \n    c(\"controllo\" = 0,  \"psicoterapia1\" = 1,    \"psicoterapia2\" = -1)\n)\n\ncontrast(em, method = my_list)\n#&gt;  contrast          estimate lower.HPD upper.HPD\n#&gt;  Ctrl_vs_PsicoMean     6.74      4.72      8.61\n#&gt;  P1_vs_P2              5.80      3.36      8.13\n#&gt; \n#&gt; Point estimate displayed: median \n#&gt; HPD interval probability: 0.95",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_1via.html#altre-opzioni-utili-di-emmeans",
    "href": "chapters/linear_models/10_anova_1via.html#altre-opzioni-utili-di-emmeans",
    "title": "68  ANOVA ad una via",
    "section": "\n68.8 Altre opzioni utili di emmeans\n",
    "text": "68.8 Altre opzioni utili di emmeans\n\n\n\nCredibility intervals:\n\n\nconfint( contrast(em, method = my_list) )\n#&gt;  contrast          estimate lower.HPD upper.HPD\n#&gt;  Ctrl_vs_PsicoMean     6.74      4.72      8.61\n#&gt;  P1_vs_P2              5.80      3.36      8.13\n#&gt; \n#&gt; Point estimate displayed: median \n#&gt; HPD interval probability: 0.95\n\nper intervalli di confidenza dei contrasti specificati.\n\n\nTest corretti per confronti multipli:\n\n\ncontrast(em, method = my_list, adjust = \"bonferroni\")\n#&gt;  contrast          estimate lower.HPD upper.HPD\n#&gt;  Ctrl_vs_PsicoMean     6.74      4.72      8.61\n#&gt;  P1_vs_P2              5.80      3.36      8.13\n#&gt; \n#&gt; Point estimate displayed: median \n#&gt; HPD interval probability: 0.95\n\no altre correzioni (ad es. \"holm\", \"sidak\", \"none\").\n\n\nVisualizzazione:\nIl pacchetto emmeans ha anche funzioni per la visualizzazione (plot(em), pwpp(), ecc.).\n\n\n\nplot(em)\n\n\n\n\n\n\n\nIn conclusione, usare emmeans semplifica notevolmente:\n\n\nIl calcolo delle medie stimate (o “ls-means”) di ciascun livello di un fattore in un modello lineare (o GLM, o mixed model, ecc.).\n\n\nLa definizione di contrasti personalizzati, senza dover ridefinire manualmente la matrice di contrasti nel modello (come si fa con contrasts(fattore) &lt;- ...).\n\n\nLa produzione di test e intervalli di confidenza per i confronti desiderati, integrando anche correzioni per confronti multipli se necessario.\n\nIn questo modo, è possibile ottenere esattamente gli stessi risultati che otterresti impostando manualmente i contrasti a livello di design matrix, ma con un approccio più flessibile e con meno passaggi.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_1via.html#riflessioni-conclusive",
    "href": "chapters/linear_models/10_anova_1via.html#riflessioni-conclusive",
    "title": "68  ANOVA ad una via",
    "section": "\n68.9 Riflessioni Conclusive",
    "text": "68.9 Riflessioni Conclusive\nL’ANOVA ad una via non è altro che l’applicazione del modello di regressione al caso di una variabile dipendente quantitativa e di un fattore con più di due livelli. L’aspetto più utile dell’ANOVA riguarda i contrasti, ovvero specifiche ipotesi sulla differenza tra le medie.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_1via.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/10_anova_1via.html#informazioni-sullambiente-di-sviluppo",
    "title": "68  ANOVA ad una via",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] rstan_2.32.6        StanHeaders_2.32.10 emmeans_1.10.6     \n#&gt;  [4] brms_2.22.8         Rcpp_1.0.13-1       bayestestR_0.15.0  \n#&gt;  [7] posterior_1.6.0     cmdstanr_0.8.1.9000 see_0.9.0          \n#&gt; [10] gridExtra_2.3       patchwork_1.3.0     bayesplot_1.11.1   \n#&gt; [13] psych_2.4.12        scales_1.3.0        markdown_1.13      \n#&gt; [16] knitr_1.49          lubridate_1.9.4     forcats_1.0.0      \n#&gt; [19] stringr_1.5.1       dplyr_1.1.4         purrr_1.0.2        \n#&gt; [22] readr_2.1.5         tidyr_1.3.1         tibble_3.2.1       \n#&gt; [25] ggplot2_3.5.1       tidyverse_2.0.0     rio_1.2.3          \n#&gt; [28] here_1.0.1         \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1     farver_2.1.2         loo_2.8.0           \n#&gt;  [4] fastmap_1.2.0        TH.data_1.1-2        tensorA_0.36.2.1    \n#&gt;  [7] pacman_0.5.1         digest_0.6.37        timechange_0.3.0    \n#&gt; [10] estimability_1.5.1   lifecycle_1.0.4      processx_3.8.4      \n#&gt; [13] survival_3.8-3       magrittr_2.0.3       compiler_4.4.2      \n#&gt; [16] rlang_1.1.4          tools_4.4.2          utf8_1.2.4          \n#&gt; [19] yaml_2.3.10          data.table_1.16.4    labeling_0.4.3      \n#&gt; [22] bridgesampling_1.1-2 htmlwidgets_1.6.4    curl_6.0.1          \n#&gt; [25] pkgbuild_1.4.5       mnormt_2.1.1         plyr_1.8.9          \n#&gt; [28] abind_1.4-8          multcomp_1.4-26      withr_3.0.2         \n#&gt; [31] stats4_4.4.2         grid_4.4.2           inline_0.3.20       \n#&gt; [34] xtable_1.8-4         colorspace_2.1-1     MASS_7.3-61         \n#&gt; [37] insight_1.0.0        cli_3.6.3            mvtnorm_1.3-2       \n#&gt; [40] rmarkdown_2.29       generics_0.1.3       RcppParallel_5.1.9  \n#&gt; [43] reshape2_1.4.4       tzdb_0.4.0           splines_4.4.2       \n#&gt; [46] parallel_4.4.2       matrixStats_1.4.1    vctrs_0.6.5         \n#&gt; [49] V8_6.0.0             Matrix_1.7-1         sandwich_3.1-1      \n#&gt; [52] jsonlite_1.8.9       hms_1.1.3            glue_1.8.0          \n#&gt; [55] ps_1.8.1             codetools_0.2-20     distributional_0.5.0\n#&gt; [58] stringi_1.8.4        gtable_0.3.6         QuickJSR_1.4.0      \n#&gt; [61] munsell_0.5.1        pillar_1.10.0        htmltools_0.5.8.1   \n#&gt; [64] Brobdingnag_1.2-9    R6_2.5.1             rprojroot_2.0.4     \n#&gt; [67] evaluate_1.0.1       lattice_0.22-6       backports_1.5.0     \n#&gt; [70] rstantools_2.4.0     coda_0.19-4.1        nlme_3.1-166        \n#&gt; [73] checkmate_2.3.2      xfun_0.49            zoo_1.8-12          \n#&gt; [76] pkgconfig_2.0.3",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_1via.html#bibliografia",
    "href": "chapters/linear_models/10_anova_1via.html#bibliografia",
    "title": "68  ANOVA ad una via",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_anova_2vie.html",
    "href": "chapters/linear_models/11_anova_2vie.html",
    "title": "69  ANOVA ad due vie",
    "section": "",
    "text": "69.1 Introduzione\nL’ANOVA a due o più vie estende il caso dell’ANOVA ad una via alla presenza di molteplici criteri di classificazione. Qui ci concentreremo sull’ANOVA a due vie.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>ANOVA ad due vie</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_anova_2vie.html#introduzione",
    "href": "chapters/linear_models/11_anova_2vie.html#introduzione",
    "title": "69  ANOVA ad due vie",
    "section": "",
    "text": "69.1.1 Pattern delle medie nella classificazione a due vie\nImmaginiamo di disporre delle medie di popolazione. La notazione per la classificazione a due vie è illustrata nella seguente tabella:\n\n\n\nC1\nC2\n…\nCc\nTotale colonna\n\n\n\nR1\nµ11\nµ12\n…\nµ1c\nµ1:\n\n\nR2\nµ21\nµ22\n…\nµ2c\nµ2:\n\n\n…\n…\n…\n…\n…\n…\n\n\nRr\nµr1\nµr2\n…\nµrc\nµr:\n\n\n————\n——-\n——-\n——\n——-\n—————-\n\n\nTotale riga\nµ:1\nµ:2\n…\nµ:c\nµ::\n\n\n\nQui, i fattori \\(R\\) e \\(C\\) (così denominati in riferimento alle righe e alle colonne della tabella delle medie) presentano rispettivamente \\(r\\) e \\(c\\) categorie. Indichiamo le categorie dei fattori come \\(R_j\\) e \\(C_k\\).\nAll’interno di ogni cella del disegno sperimentale—cioè per ciascuna combinazione di categorie \\(\\{R_j, C_k\\}\\) dei due fattori—si trova una media di popolazione \\(\\mu_{jk}\\) relativa alla variabile di risposta.\nPer descrivere le medie su righe, colonne e quella complessiva, utilizziamo la notazione a “punti”:\n\\[\n\\mu_{j:} \\;=\\; \\frac{\\sum_{k=1}^{c} \\mu_{jk}}{c}\n\\quad\\text{(media marginale sulla riga $j$)},\n\\]\n\\[\n\\mu_{:k} \\;=\\; \\frac{\\sum_{j=1}^{r} \\mu_{jk}}{r}\n\\quad\\text{(media marginale sulla colonna $k$)},\n\\]\n\\[\n\\mu_{::} \\;=\\; \\frac{\\sum_{j=1}^{r}\\sum_{k=1}^{c} \\mu_{jk}}{r\\,c}\n\\;=\\; \\frac{\\sum_{j=1}^{r} \\mu_{j:}}{r}\n\\;=\\; \\frac{\\sum_{k=1}^{c} \\mu_{:k}}{c}\n\\quad\\text{(media generale, o grand mean)}.\n\\]\n\n69.1.2 Effetti principali e interazione\nSe i fattori \\(R\\) e \\(C\\) non interagiscono nel determinare la variabile di risposta, allora l’effetto di uno di essi, a parità di categoria dell’altro, rimane costante. In termini pratici, la differenza fra le medie di cella \\(\\mu_{jk} - \\mu_{j'k}\\)—quando confrontiamo due categorie di \\(R\\), ad esempio \\(R_j\\) e \\(R_{j'}\\)—è la stessa per tutte le categorie di \\(C\\) (cioè per \\(k = 1, 2, \\dots, c\\)).\nDi conseguenza, la differenza fra le medie nelle righe è uguale alla differenza fra le corrispondenti medie marginali di riga:\n\\[\n\\mu_{jk} - \\mu_{j'k} \\;=\\; \\mu_{jk'} - \\mu_{j'k'} \\;=\\; \\mu_{j:} - \\mu_{j':}\n\\quad\\text{per ogni } j, j' \\text{ e } k, k'.\n\\]\nUn altro modo di vedere questa assenza di interazione è attraverso i profili di medie di cella, che in questo caso risultano “paralleli”. Se i profili sono paralleli, allora la differenza fra \\(\\mu_{j1}\\) e \\(\\mu_{j2}\\) (categorie \\(C_1\\) e \\(C_2\\)) resta costante fra le diverse righe \\(j = 1, 2\\), e coincide con la differenza fra le medie marginali di colonna, \\(\\mu_{:1} - \\mu_{:2}\\).\nL’interazione è un concetto simmetrico: se il fattore \\(R\\) interagisce con il fattore \\(C\\), vale anche il contrario. Quando non si verifica interazione, l’effetto principale (o main effect) di ogni fattore corrisponde semplicemente alla differenza fra le medie marginali di popolazione relative a quel fattore.\nLa figura seguente presentata diversi scenari possibili.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>ANOVA ad due vie</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_anova_2vie.html#simulazione",
    "href": "chapters/linear_models/11_anova_2vie.html#simulazione",
    "title": "69  ANOVA ad due vie",
    "section": "\n69.2 Simulazione",
    "text": "69.2 Simulazione\nPer fare un esempio concreto, simuliamo dei dati seguendo lo schema utilizzato con l’ANOVA ad una via. In questo caso, aggiungiamo un secondo fattore: la gravità dei sintomi.\n\n# Imposta un seme per riproducibilità (opzionale)\nset.seed(123)\n\n# Definiamo il numero di osservazioni per ogni cella\nn &lt;- 30\n\n# Definiamo le categorie dei fattori\ngravita &lt;- c(\"molto_gravi\", \"poco_gravi\")\ncondizione &lt;- c(\"controllo\", \"psicoterapia1\", \"psicoterapia2\")\n\n# Definiamo la deviazione standard (ipotizziamo la stessa per tutte le celle)\nsd_value &lt;- 5\n\n# Definiamo le medie attese per ciascuna combinazione (gravita x condizione)\n# Esempio:\n# - Pazienti molto gravi:  (controllo=30, psico1=25, psico2=20)\n# - Pazienti poco gravi:   (controllo=25, psico1=20, psico2=15)\n\nmean_table &lt;- matrix(\n  c(30, 25, 20,  # molto_gravi\n    25, 20, 15), # poco_gravi\n  nrow = 2,      # 2 righe per \"molto_gravi\" e \"poco_gravi\"\n  ncol = 3,      # 3 colonne per \"controllo\", \"psicoterapia1\", \"psicoterapia2\"\n  byrow = TRUE\n)\n\n# Crea un data frame vuoto che riempiremo con i dati simulati\ndf &lt;- data.frame()\n\nfor (i in seq_along(gravita)) {\n  for (j in seq_along(condizione)) {\n    # Estraiamo la media corrispondente alla combinazione (i, j)\n    current_mean &lt;- mean_table[i, j]\n    \n    # Generiamo 'n' osservazioni normali con media = current_mean e sd = sd_value\n    simulated_data &lt;- rnorm(n, mean = current_mean, sd = sd_value)\n    \n    # Creiamo un data frame temporaneo per questa combinazione\n    temp_df &lt;- data.frame(\n      gravita    = gravita[i],\n      condizione = condizione[j],\n      punteggio  = simulated_data\n    )\n    \n    # Append al data frame finale\n    df &lt;- rbind(df, temp_df)\n  }\n}\n\nEsaminiamo le medie:\n\n# Esempio di sintesi statistica\naggregate(punteggio ~ gravita + condizione, data = df, mean)\n#&gt;       gravita    condizione punteggio\n#&gt; 1 molto_gravi     controllo      29.8\n#&gt; 2  poco_gravi     controllo      24.5\n#&gt; 3 molto_gravi psicoterapia1      25.9\n#&gt; 4  poco_gravi psicoterapia1      19.1\n#&gt; 5 molto_gravi psicoterapia2      20.1\n#&gt; 6  poco_gravi psicoterapia2      15.8\n\nRappresentiamo graficamente la distribuzione dei dati nelle varie condizioni:\n\nggplot(df, aes(x = condizione, y = punteggio, fill = gravita)) +\n  geom_boxplot(position = position_dodge()) +\n  labs(title = \"Simulazione dati: Effetto gravità e condizione\",\n       x = \"Condizione sperimentale\",\n       y = \"Punteggio\")\n\n\n\n\n\n\n\nAddattiamo ai dati un modello bayesiano:\n\nmod &lt;- brm(\n  punteggio ~ gravita * condizione, \n  data = df,\n  backend = \"cmdstanr\"\n)\n\nEsaminiamo le stime del modello:\n\nconditional_effects(mod, \"condizione:gravita\")\n\n\n\n\n\n\n\nUn sommario delle stime a posteriori si ottiene nel modo seguente:\n\nsummary(mod)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: punteggio ~ gravita * condizione \n#&gt;    Data: df (Number of observations: 180) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;                                           Estimate Est.Error l-95% CI\n#&gt; Intercept                                    29.75      0.87    27.98\n#&gt; gravitapoco_gravi                            -5.21      1.26    -7.69\n#&gt; condizionepsicoterapia1                      -3.86      1.24    -6.30\n#&gt; condizionepsicoterapia2                      -9.62      1.25   -12.01\n#&gt; gravitapoco_gravi:condizionepsicoterapia1    -1.59      1.78    -5.15\n#&gt; gravitapoco_gravi:condizionepsicoterapia2     0.84      1.78    -2.75\n#&gt;                                           u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept                                    31.44 1.00     1825     2640\n#&gt; gravitapoco_gravi                            -2.70 1.00     1739     2341\n#&gt; condizionepsicoterapia1                      -1.48 1.00     1926     2679\n#&gt; condizionepsicoterapia2                      -7.15 1.00     2277     2289\n#&gt; gravitapoco_gravi:condizionepsicoterapia1     1.97 1.00     1616     2097\n#&gt; gravitapoco_gravi:condizionepsicoterapia2     4.28 1.00     1996     2809\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     4.79      0.26     4.32     5.34 1.00     3257     2645\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nL’esame dell’output precedente mostra come sia difficile rispondere alle domende di interesse mediante l’esame dei singoli coefficienti. Per valutare gli effetti principali e la presenza di interazione si usa invece un metodo basato sul confronto tra modelli.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>ANOVA ad due vie</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_anova_2vie.html#confronto-tra-modelli",
    "href": "chapters/linear_models/11_anova_2vie.html#confronto-tra-modelli",
    "title": "69  ANOVA ad due vie",
    "section": "\n69.3 Confronto tra Modelli",
    "text": "69.3 Confronto tra Modelli\nIl test degli effetti principali e dell’interazione viene eseguito, nell’approccio frequentista, calcolando R^2 per i vari modelli per poi fare una differenza tra gli R^2 pesati per i gradi di libertà. Questa differenza si distribuisce come F e quindi disponiamo di una distribuzione campionaria nota per questa statistica. Il test si fa nel solito modo, ovvero ci si chiede se la differenza in R^2 osservata è sufficientemente piccola da potere essere attribuita al caso, sotto l’ipotesi che i due modelli sono equivalenti, oppure no.\nI test bayesiani si basano su una logica diversa, anche se ha alcuni punti in comune. Il confronto tra modelli si basa su una quantità chiamata LOO (Leave-One-Out cross-validation).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>ANOVA ad due vie</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_anova_2vie.html#cosè-loo-leave-one-out-cross-validation",
    "href": "chapters/linear_models/11_anova_2vie.html#cosè-loo-leave-one-out-cross-validation",
    "title": "69  ANOVA ad due vie",
    "section": "\n69.4 Cos’è LOO (Leave-One-Out cross-validation)?",
    "text": "69.4 Cos’è LOO (Leave-One-Out cross-validation)?\nLOO è un metodo per stimare quanto bene un modello predice nuovi dati. In particolare, misura quanto il modello è in grado di generalizzare oltre i dati usati per costruirlo.\n\nCome funziona:\nSi rimuove iterativamente una osservazione dal dataset, si stima il modello sui dati rimanenti e si valuta quanto bene il modello predice l’osservazione esclusa. Questo processo viene ripetuto per tutte le osservazioni.\nNel contesto Bayesiano:\nPoiché ricalcolare il modello per ogni possibile sottogruppo di dati sarebbe computazionalmente oneroso, si usa una stima approssimativa di LOO basata sul concetto di PSIS-LOO (Pareto Smoothed Importance Sampling). Questa stima è disponibile direttamente in brms tramite il comando loo().",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>ANOVA ad due vie</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_anova_2vie.html#indicatori-principali-nei-risultati-di-loo",
    "href": "chapters/linear_models/11_anova_2vie.html#indicatori-principali-nei-risultati-di-loo",
    "title": "69  ANOVA ad due vie",
    "section": "\n69.5 Indicatori principali nei risultati di LOO\n",
    "text": "69.5 Indicatori principali nei risultati di LOO\n\n\nelpd (expected log predictive density):\nÈ la somma logaritmica delle probabilità predittive del modello per ogni osservazione, calcolata dopo aver escluso quella stessa osservazione. Valori più alti indicano un modello che predice meglio.\nelpd_diff:\nDifferenza di elpd tra due modelli. Se \\(\\text{elpd}_{\\text{model1}} &gt; \\text{elpd}_{\\text{model2}}\\), il modello 1 è preferito.\nse_diff (standard error of difference):\nL’incertezza associata a elpd_diff. Se |elpd_diff| è molto piccolo rispetto a se_diff, la differenza tra i modelli non è considerata robusta.\n\n\nNel caso presente, confrontiamo due modelli:\n\n\nmod1: Modello completo (con interazione).\n\n\nmod: Modello senza interazione (solo effetti principali).\n\n\nmod1 &lt;- brm(\n  punteggio ~ gravita + condizione, \n  data = df,\n  backend = \"cmdstanr\"\n)\n\n\n69.5.1 Confronto LOO\n\n# Confronto via LOO\nloo_full &lt;- loo(mod)\nloo_noint  &lt;- loo(mod1)\nloo_compare(loo_full, loo_noint)\n#&gt;      elpd_diff se_diff\n#&gt; mod1  0.0       0.0   \n#&gt; mod  -1.0       1.5\n\n\nelpd_diff = -0.9: Il modello con interazione (mod) ha un elpd leggermente più basso rispetto al modello senza interazione (mod1). Questo significa che il modello senza interazione è leggermente preferibile in termini di capacità predittiva sui nuovi dati.\nse_diff = 1.5: L’incertezza associata alla differenza di elpd è molto più grande della differenza stessa (elpd_diff / se_diff). Questo implica che non c’è evidenza sufficiente per concludere che uno dei due modelli sia chiaramente migliore.\n\nIn conclusione,\n\nIl modello senza interazione (mod1) è leggermente preferibile in termini di LOO-IC, ma la differenza è trascurabile e non robusta, data l’elevata incertezza (se_diff = 1.5).\n\nInterpretazione pratica:\n\nNon ci sono prove sufficienti per preferire il modello con interazione (mod) rispetto al modello senza interazione (mod1).\nIn assenza di altre considerazioni teoriche che giustifichino l’inclusione dell’interazione, il modello più semplice (mod1, senza interazione) è probabilmente una scelta migliore.\n\n\n\nSi procede in un modo simile per i test degli effetti principali. In quel caso potremmo confrontrare un modello con gli effetti additivi dei due fattori con un modello con un unico fattore.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>ANOVA ad due vie</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_anova_2vie.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/11_anova_2vie.html#informazioni-sullambiente-di-sviluppo",
    "title": "69  ANOVA ad due vie",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] rstan_2.32.6         StanHeaders_2.32.10  bridgesampling_1.1-2\n#&gt;  [4] loo_2.8.0            emmeans_1.10.6       brms_2.22.8         \n#&gt;  [7] Rcpp_1.0.13-1        bayestestR_0.15.0    posterior_1.6.0     \n#&gt; [10] cmdstanr_0.8.1.9000  see_0.9.0            gridExtra_2.3       \n#&gt; [13] patchwork_1.3.0      bayesplot_1.11.1     psych_2.4.12        \n#&gt; [16] scales_1.3.0         markdown_1.13        knitr_1.49          \n#&gt; [19] lubridate_1.9.4      forcats_1.0.0        stringr_1.5.1       \n#&gt; [22] dplyr_1.1.4          purrr_1.0.2          readr_2.1.5         \n#&gt; [25] tidyr_1.3.1          tibble_3.2.1         ggplot2_3.5.1       \n#&gt; [28] tidyverse_2.0.0      rio_1.2.3            here_1.0.1          \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1     farver_2.1.2         fastmap_1.2.0       \n#&gt;  [4] TH.data_1.1-2        tensorA_0.36.2.1     pacman_0.5.1        \n#&gt;  [7] digest_0.6.37        timechange_0.3.0     estimability_1.5.1  \n#&gt; [10] lifecycle_1.0.4      processx_3.8.4       survival_3.8-3      \n#&gt; [13] magrittr_2.0.3       compiler_4.4.2       rlang_1.1.4         \n#&gt; [16] tools_4.4.2          yaml_2.3.10          data.table_1.16.4   \n#&gt; [19] labeling_0.4.3       htmlwidgets_1.6.4    curl_6.0.1          \n#&gt; [22] pkgbuild_1.4.5       mnormt_2.1.1         plyr_1.8.9          \n#&gt; [25] abind_1.4-8          multcomp_1.4-26      withr_3.0.2         \n#&gt; [28] stats4_4.4.2         grid_4.4.2           inline_0.3.20       \n#&gt; [31] xtable_1.8-4         colorspace_2.1-1     MASS_7.3-61         \n#&gt; [34] insight_1.0.0        cli_3.6.3            mvtnorm_1.3-2       \n#&gt; [37] rmarkdown_2.29       generics_0.1.3       RcppParallel_5.1.9  \n#&gt; [40] reshape2_1.4.4       tzdb_0.4.0           splines_4.4.2       \n#&gt; [43] parallel_4.4.2       matrixStats_1.4.1    vctrs_0.6.5         \n#&gt; [46] V8_6.0.0             Matrix_1.7-1         sandwich_3.1-1      \n#&gt; [49] jsonlite_1.8.9       hms_1.1.3            glue_1.8.0          \n#&gt; [52] ps_1.8.1             codetools_0.2-20     distributional_0.5.0\n#&gt; [55] stringi_1.8.4        gtable_0.3.6         QuickJSR_1.4.0      \n#&gt; [58] munsell_0.5.1        pillar_1.10.0        htmltools_0.5.8.1   \n#&gt; [61] Brobdingnag_1.2-9    R6_2.5.1             rprojroot_2.0.4     \n#&gt; [64] evaluate_1.0.1       lattice_0.22-6       backports_1.5.0     \n#&gt; [67] rstantools_2.4.0     coda_0.19-4.1        nlme_3.1-166        \n#&gt; [70] checkmate_2.3.2      xfun_0.49            zoo_1.8-12          \n#&gt; [73] pkgconfig_2.0.3",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>ANOVA ad due vie</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_anova_2vie.html#bibliografia",
    "href": "chapters/linear_models/11_anova_2vie.html#bibliografia",
    "title": "69  ANOVA ad due vie",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>ANOVA ad due vie</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/introduction_entropy.html",
    "href": "chapters/entropy/introduction_entropy.html",
    "title": "Introduzione",
    "section": "",
    "text": "In questa sezione della dispensa, esploreremo il tema cruciale della validazione di un modello statistico e del confronto tra modelli. Vedremo come sia necessario trovare un equilibrio tra due dimensioni: la capacità del modello di predire accuratamente i dati osservati nel campione e la sua capacità di generalizzarsi a campioni diversi.",
    "crumbs": [
      "Entropia",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html",
    "href": "chapters/entropy/01_entropy.html",
    "title": "70  Entropia",
    "section": "",
    "text": "70.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nPreparazione del Notebook\nIn questo capitolo, descriveremo il concetto di entropia, una misura fondamentale sviluppata nell’ambito della teoria dell’informazione. L’entropia ci permette di quantificare l’incertezza associata a una distribuzione di probabilità e, di conseguenza, la quantità di informazione che un evento ci fornisce.\nL’entropia è legata alla nostra capacità di prevedere l’esito di un evento: più un risultato è imprevedibile, maggiore sarà l’entropia. In termini più generali, l’entropia di una variabile casuale misura quanto è incerto o “sorprendente” il valore che essa assumerà in media. Se ogni possibile esito ha la stessa probabilità di verificarsi, l’entropia sarà massima. Se invece alcuni esiti sono molto più probabili di altri, l’entropia diminuirà, poiché l’incertezza complessiva è ridotta.\nUn’intuizione sull’entropia può essere ottenuta considerando il seguente esempio. Pensiamo a un sacchetto di palline colorate. Se il sacchetto contiene solo palline di un unico colore, possiamo essere sicuri di quale pallina estrarremo ogni volta. Non c’è alcuna incertezza o sorpresa, quindi l’entropia è pari a zero. Tuttavia, se il sacchetto contiene un numero uguale di palline di diversi colori, ogni estrazione è un’incognita: l’incertezza è massima e, di conseguenza, lo è anche l’entropia.\nIl concetto di entropia va ben oltre questo semplice esempio. Esso si applica a qualunque situazione in cui ci sia un insieme di risultati possibili con probabilità diverse. In questo capitolo, ci concentreremo sul significato matematico dell’entropia, esplorando come può essere calcolata per diverse distribuzioni di probabilità e come essa si collega alla quantità di informazione che un sistema può fornire. Inizieremo con esempi semplici, come l’entropia di una moneta equa o di un dado, per poi estendere il concetto a situazioni più complesse.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#introduzione",
    "href": "chapters/entropy/01_entropy.html#introduzione",
    "title": "70  Entropia",
    "section": "",
    "text": "Information is the resolution of uncertainty.\n(Shannon C, 1948)",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#che-cosè-linformazione",
    "href": "chapters/entropy/01_entropy.html#che-cosè-linformazione",
    "title": "70  Entropia",
    "section": "\n70.2 Che cos’è l’Informazione?",
    "text": "70.2 Che cos’è l’Informazione?\nL’informazione è solitamente misurata in bit, e un bit di informazione permette di scegliere tra due alternative ugualmente probabili. La parola bit deriva da binary digit (cioè uno zero o un uno).\nPer capire come l’informazione possa essere misurata in bit, consideriamo il seguente esempio discusso da Stone (2022). Immagina di trovarti ad un incrocio e di dover scegliere una strada tra due possibilità. Ogni volta che incontri un incrocio, devi prendere una decisione: andare a destra o a sinistra. Ogni decisione può essere rappresentata da un bit di informazione: 0 per sinistra, 1 per destra.\nConsideriamo un percorso con più incroci, come quello rappresentato nell’immagine. Ogni percorso completo può essere codificato da una sequenza di bit, dove ogni bit corrisponde ad una decisione presa in un incrocio. Ad esempio, per raggiungere il punto D011, la sequenza di bit corretta è 011.\n\n# Definizione degli archi e delle etichette\nedges &lt;- data.frame(\n  from = c(\n    \"A\", \"A\", \"B0\", \"B0\", \"B1\", \"B1\",\n    \"C00\", \"C00\", \"C01\", \"C01\", \"C10\", \"C10\", \"C11\", \"C11\"\n  ),\n  to = c(\n    \"B0\", \"B1\", \"C00\", \"C01\", \"C10\", \"C11\",\n    \"D000\", \"D001\", \"D010\", \"D011\", \"D100\", \"D101\", \"D110\", \"D111\"\n  ),\n  label = c(\n    \"0\", \"1\", \"0\", \"1\", \"0\", \"1\",\n    \"0\", \"1\", \"0\", \"1\", \"0\", \"1\", \"0\", \"1\"\n  )\n)\n\n# Creazione del grafo diretto\nG &lt;- graph_from_data_frame(edges, directed = TRUE)\n\n# Visualizzazione del grafo usando ggraph\nggraph(G, layout = \"dendrogram\", circular = FALSE) +\n  geom_edge_link(\n    aes(label = label),\n    angle_calc = \"along\", label_dodge = unit(2, \"mm\"),\n    arrow = arrow(length = unit(4, \"mm\"), type = \"closed\")\n  ) +\n  geom_node_point(size = 5, color = \"lightblue\") +\n  geom_node_text(aes(label = name), repel = TRUE, size = 3.5) +\n  labs(title = \"Albero delle possibilità per 3 bit di informazione\") +\n  theme(plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\"))\n\n\n\n\n\n\n\nQuanti bit sono necessari per identificare una destinazione specifica?\nOgni bit raddoppia il numero di possibili percorsi. Quindi, se abbiamo \\(n\\) bit, possiamo identificare \\(2^n\\) destinazioni distinte. Viceversa, se conosciamo il numero di destinazioni \\(m\\), possiamo calcolare il numero di bit necessari utilizzando la formula:\n\\[\nn = \\log_2 m.\n\\]\nNel nostro esempio, abbiamo 8 destinazioni finali. Pertanto, sono necessari \\(\\log_2 8 = 3\\) bit per identificarne una in modo univoco.\nCosa rappresenta un bit in questo contesto?\nUn bit rappresenta un’unità elementare di informazione. In questo caso, ogni bit risponde alla domanda: “Devo andare a destra o a sinistra?”.\nPerché utilizziamo i logaritmi?\nIl logaritmo in base 2 ci permette di calcolare l’esponente a cui elevare 2 per ottenere un dato numero. In altre parole, ci dice quanti bit sono necessari per rappresentare un certo numero di destinazioni. Per l’esempio considerato, per arrivare a \\(D011\\) partendo da \\(A\\), sono necessarie 3 domande la cui risposta binaria è destra/sinistra.\nIn sintesi, esiste una relazione diretta tra il numero di bit di informazione e il numero di possibili destinazioni in un percorso decisionale binario. Ogni bit ci permette di fare una scelta tra due alternative, raddoppiando così il numero di possibili percorsi.\nPer ricapitolare:\n\nAbbiamo visto che per raggiungere il punto D011 partendo da A, abbiamo bisogno di prendere tre decisioni binarie (sinistra o destra) in corrispondenza di tre incroci.\nOgni decisione binaria può essere rappresentata da un bit (0 o 1). Quindi, per l’intero percorso, abbiamo bisogno di una sequenza di tre bit: 011.\nPer rispondere alla domanda “Come andare da A a D011?”, abbiamo dunque bisogno di 3 bit di informazione.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#la-sorpresa-e-linformazione-di-shannon",
    "href": "chapters/entropy/01_entropy.html#la-sorpresa-e-linformazione-di-shannon",
    "title": "70  Entropia",
    "section": "\n70.3 La Sorpresa e l’Informazione di Shannon",
    "text": "70.3 La Sorpresa e l’Informazione di Shannon\nNel primo esempio, abbiamo visto come l’informazione possa essere misurata in bit, dove ogni bit corrisponde a una decisione binaria che ci aiuta a raggiungere una destinazione specifica in un percorso. Tuttavia, la quantità di informazione può variare anche in base alla probabilità con cui certi eventi o scelte si verificano. È qui che entra in gioco il concetto di informazione di Shannon, che prende in considerazione la sorpresa associata a un risultato.\nImmaginiamo, ad esempio, di avere una moneta che cade testa il 90% delle volte. Poiché il risultato “testa” è molto probabile, non ci sorprenderebbe molto ottenerlo. Al contrario, il risultato “croce”, che accade solo il 10% delle volte, ci sorprenderà di più. Più improbabile è un risultato, maggiore sarà la sorpresa nel vederlo.\nIn termini di informazione, possiamo dire che risultati meno probabili forniscono più informazione, perché ci sorprendono di più. Una prima idea per misurare questa sorpresa è definirla come inversamente proporzionale alla probabilità del risultato: \\(1/p(x)\\). Tuttavia, Shannon ha dimostrato che è più utile esprimere la sorpresa come il logaritmo di \\(1/p(x)\\). Questo ci porta alla definizione dell’informazione di Shannon, che si misura in bit (se usiamo il logaritmo in base 2, lo stesso utilizzato per misurare i percorsi nel primo esempio). L’informazione di Shannon per un risultato \\(x\\) è quindi:\n\\[\nh(x) = \\log_2 \\frac{1}{p(x)} = -\\log_2 p(x) \\text{ bit}.\n\\tag{70.1}\\]\nIn questo modo, vediamo che l’informazione associata a un evento dipende dalla sua probabilità: eventi meno probabili portano più informazione, e viceversa.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#sorpresa-e-probabilità",
    "href": "chapters/entropy/01_entropy.html#sorpresa-e-probabilità",
    "title": "70  Entropia",
    "section": "\n70.4 Sorpresa e Probabilità",
    "text": "70.4 Sorpresa e Probabilità\nPer comprendere pienamente la sorpresa, dobbiamo conoscere le probabilità dei diversi risultati. Questo significa che l’informazione di Shannon dipende dalla distribuzione di probabilità \\(p(X)\\) della variabile aleatoria \\(X\\). In altre parole, per misurare quanta informazione otteniamo da un risultato, dobbiamo sapere quanto è probabile ciascun possibile esito.\nUn modo per stimare queste probabilità è osservare i risultati di un esperimento ripetuto nel tempo. Utilizzando le osservazioni, possiamo stimare la probabilità di ciascun risultato e quindi calcolare l’informazione di Shannon associata. Questo approccio ci permette di collegare il concetto di informazione misurata in bit (come nel primo esempio sugli incroci) con la sorpresa generata da eventi più o meno probabili.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#entropia-come-media-dellinformazione-di-shannon",
    "href": "chapters/entropy/01_entropy.html#entropia-come-media-dellinformazione-di-shannon",
    "title": "70  Entropia",
    "section": "\n70.5 Entropia come Media dell’Informazione di Shannon",
    "text": "70.5 Entropia come Media dell’Informazione di Shannon\nQuando si lavora con fenomeni aleatori, spesso non ci interessa solo la sorpresa associata a un singolo risultato, ma piuttosto la sorpresa media che si può ottenere considerando tutti i possibili risultati di una variabile. Questa sorpresa media è chiamata entropia e si indica con \\(H(X)\\). L’entropia ci dà una misura della quantità di incertezza (o informazione potenziale) contenuta in una variabile aleatoria \\(X\\), la cui distribuzione di probabilità è data da \\(p(X)\\).\nL’entropia rappresenta quindi la quantità media di informazione che otteniamo osservando i risultati della variabile \\(X\\). Se, ad esempio, lanciamo una moneta molte volte, l’entropia della distribuzione dei risultati riflette la media delle informazioni di Shannon ottenute da ciascun lancio. In altre parole, ci dice quanto ci aspettiamo di “imparare” in media da ogni lancio.\nMatematicamente, l’entropia può essere approssimata dalla media delle informazioni di Shannon associate a ciascun possibile risultato \\(x_i\\):\n\\[\nH(X) \\approx \\frac{1}{n} \\sum_{i=1}^{n} h(x_i).\n\\tag{70.2}\\]\nIn questa formula, \\(h(x_i)\\) è l’informazione di Shannon di un singolo risultato \\(x_i\\), come discusso in precedenza. L’entropia, quindi, non si riferisce a un evento specifico, ma alla sorpresa media che ci aspettiamo quando osserviamo ripetutamente una variabile aleatoria. Più equilibrata è la distribuzione delle probabilità dei risultati (ad esempio, se tutti i risultati sono ugualmente probabili), maggiore sarà l’entropia, perché ciascun risultato fornisce una quantità simile di informazione. Al contrario, se alcuni risultati sono molto più probabili di altri (ad esempio, una moneta truccata che dà quasi sempre “testa”), l’entropia sarà minore, poiché otteniamo meno informazione da ogni osservazione.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#entropia-di-una-moneta-equa",
    "href": "chapters/entropy/01_entropy.html#entropia-di-una-moneta-equa",
    "title": "70  Entropia",
    "section": "\n70.6 Entropia di una Moneta Equa",
    "text": "70.6 Entropia di una Moneta Equa\nSe una moneta è equa, allora \\(p(x_h) = 0.5\\) e la sorpresa di osservare una testa è\n\\[\n\\begin{align}\nh(x_h) &= \\log_2 \\frac{1}{p(x_h)} \\notag\\\\\n       &= \\log_2(1/0.5) = 1 \\text{ bit}.\\notag\n\\end{align}\n\\]\nDato che \\(p(x_t) = 0.5\\), la sorpresa di osservare una testa (o una croce) è di un bit.\nPossiamo trovare la sorpresa media lanciando la moneta, diciamo, 100 volte, misurando la sorpresa di ogni risultato e poi calcolando la media dei 100 risultati. Se lanciamo una moneta 100 volte, ci aspettiamo di osservare testa circa 50 volte e croce circa 50 volte. Se osserviamo esattamente 50 teste e 50 croci, la quantità media di sorpresa diventa\n\\[\n\\begin{align}\nH(X) &= \\frac{1}{100} \\left( \\sum_{i=1}^{50} \\log_2 \\frac{1}{p(x_h)} + \\sum_{i=1}^{50} \\log_2 \\frac{1}{p(x_t)} \\right)\\notag\\\\\n&=1 \\text{ bit per lancio della moneta}\\notag.\n\\end{align}\n\\]\nIn sintesi, poiché la quantità di sorpresa o informazione di Shannon fornita dall’osservazione del risultato di ogni lancio di questa moneta equa è di un bit, ne segue che l’informazione media \\(H(X)\\) di ogni lancio è anch’essa di un bit.\n\n70.6.1 Interpretazione dell’Entropia (1)\nSe consideriamo una distribuzione di probabilità uniforme, una variabile con entropia \\(H(X)\\) espressa in bit fornisce sufficiente informazione (nel senso della teoria dell’informazione di Shannon) per distinguere tra \\(m = 2^{H(X)}\\) alternative ugualmente probabili. In altre parole, l’entropia misura la quantità di informazione contenuta in una variabile, esprimendola in termini di quante scelte ugualmente probabili sono possibili per quella variabile.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#entropia-di-una-moneta-sbilanciata",
    "href": "chapters/entropy/01_entropy.html#entropia-di-una-moneta-sbilanciata",
    "title": "70  Entropia",
    "section": "\n70.7 Entropia di una moneta sbilanciata",
    "text": "70.7 Entropia di una moneta sbilanciata\nUna moneta sbilanciata ha una quantità media di informazione (o incertezza) inferiore rispetto a una moneta equa.\nLa sorpresa associata a testa è:\n\\[\nh(\\text{testa}) = \\log\\left(\\frac{1}{0.9}\\right) = 0.15 \\text{ bit},\n\\]\nmentre la sorpresa associata a croce è maggiore:\n\\[\nh(\\text{croce}) = \\log\\left(\\frac{1}{0.1}\\right) = 3.32 \\text{ bit}.\n\\]\n\n70.7.1 Interpretazione dell’Entropia (2)\nSe immaginiamo di lanciare la moneta tante volte, la sorpresa media o entropia di questa moneta, considerando considerando \\(p(\\text{testa}) = 0.9\\) e \\(p(\\text{croce}) = 0.1\\), è:\n\\[H(X) = 0.9 \\log_2 \\frac{1}{0.9} + 0.1 \\log_2 \\frac{1}{0.1} = 0.469 \\text{ bit per lancio}.\\]\nL’incertezza media per questa moneta sbilanciata è dunque inferiore a quella di una moneta equa (che ha un’entropia di 1 bit), anche se l’incertezza associata all’esito meno probabile (croce) è maggiore (3.32 bit) rispetto a quella di una moneta equa (1 bit). In generale, nessuna moneta sbilanciata può avere un’entropia media maggiore di quella di una moneta equa.\nPoiché \\(p(\\text{testa}) = 0.9\\) e \\(p(\\text{croce}) = 0.1\\), possiamo scrivere la formula dell’entropia come:\n\\[\nH(X) = p(\\text{testa}) \\log\\left(\\frac{1}{p(\\text{testa})}\\right) + p(\\text{croce}) \\log\\left(\\frac{1}{p(\\text{croce})}\\right) = 0.469 \\text{ bit per lancio}.\n\\]\nPer semplificare ulteriormente, possiamo rappresentare l’entropia sommando sui due possibili esiti (testa e croce):\n\\[\nH(X) = \\sum_{i=1}^{2} p(x_i) \\log\\left(\\frac{1}{p(x_i)}\\right) = 0.469 \\text{ bit per lancio}.\n\\]\nQuesta entropia di 0.469 bit implica che l’informazione contenuta in 1.000 lanci di questa moneta potrebbe essere rappresentata usando solo 469 bit binari, cioè \\(1000 \\times 0.469\\).\nPossiamo interpretare questo risultato considerando l’entropia nei termini di un numero di alternative ugualmente probabili. La variabile \\(X\\), che rappresenta il lancio della moneta, potrebbe essere vista come equivalente a una variabile che può assumere:\n\\[\nm = 2^{H(X)} = 2^{0.469} \\approx 1.38 \\text{ valori equiprobabili}.\n\\]\nA prima vista, questo risultato può sembrare strano, dato che stiamo considerando una moneta, che ha solo due esiti possibili. Tuttavia, interpretare l’entropia nei termini di un numero equivalente di valori ugualmente probabili ci offre un’intuizione sull’informazione rappresentata da una variabile. Un modo per pensare a questo concetto è di immaginare che una moneta con entropia \\(H(X) = 0.469\\) bit abbia la stessa quantità di incertezza di un dado ipotetico con 1.38 facce.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#caratteristiche-dellentropia",
    "href": "chapters/entropy/01_entropy.html#caratteristiche-dellentropia",
    "title": "70  Entropia",
    "section": "\n70.8 Caratteristiche dell’Entropia",
    "text": "70.8 Caratteristiche dell’Entropia\n\nEntropia Massima: L’entropia raggiunge il suo valore massimo quando tutti gli esiti di un evento hanno la stessa probabilità di verificarsi. In questa situazione, l’incertezza è massima, poiché nessun indizio ci permette di prevedere quale sarà il risultato. Questo rappresenta il massimo grado di imprevedibilità.\nEntropia Minima: L’entropia è minima quando l’esito di un evento è completamente certo (con probabilità pari a 1) o impossibile (con probabilità pari a 0). In questi casi, non esiste incertezza né sorpresa, e quindi non c’è alcuna informazione aggiuntiva da ottenere osservando il risultato.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#additività-dellentropia-per-eventi-indipendenti",
    "href": "chapters/entropy/01_entropy.html#additività-dellentropia-per-eventi-indipendenti",
    "title": "70  Entropia",
    "section": "\n70.9 Additività dell’Entropia per Eventi Indipendenti",
    "text": "70.9 Additività dell’Entropia per Eventi Indipendenti\nL’entropia è additiva nel caso di eventi indipendenti. Ciò significa che, se si verificano due o più eventi indipendenti, l’entropia totale della loro combinazione è pari alla somma delle entropie di ciascun evento considerato singolarmente. Questa proprietà deriva dall’additività dei logaritmi, che permette di sommare le entropie individuali per ottenere l’entropia complessiva.\n\n70.9.1 Stimare l’Entropia da una Distribuzione di Probabilità\nConsideriamo una variabile casuale discreta \\(X\\), che rappresenta una serie di eventi distinti, ciascuno con una probabilità associata. Per una variabile discreta \\(X\\) con possibili valori \\(x_1, x_2, \\dots, x_n\\) e una funzione di massa di probabilità \\(p(x) = \\Pr\\{X = x\\}\\), l’entropia \\(H(X)\\) misura l’incertezza complessiva associata a questa distribuzione di probabilità e si calcola con la formula:\n\\[\n\\begin{equation}\nH(X) = -\\sum_{x \\in X} p(x) \\log_2 p(x).\n\\end{equation}\n\\tag{70.3}\\]\nIn questo contesto, l’entropia \\(H(X)\\) rappresenta l’incertezza media relativa alla collezione di eventi descritti dalla variabile \\(X\\). La formula fornisce una somma pesata delle sorprese associate a ciascun esito, dove la sorpresa di un risultato \\(x\\) dipende dalla sua improbabilità, calcolata come \\(-\\log_2 p(x)\\). Il segno negativo è necessario perché i logaritmi di probabilità, essendo inferiori a 1, sono negativi; il segno negativo li trasforma in valori positivi, che rappresentano correttamente la sorpresa o l’informazione associata.\nOgni termine della somma, \\(-p(x) \\log_2 p(x)\\), esprime la quantità di informazione o sorpresa relativa a un singolo evento, ponderata dalla sua probabilità \\(p(x)\\). Quanto più uniformemente distribuite sono le probabilità degli eventi, tanto maggiore sarà l’entropia complessiva. Al contrario, se uno o più eventi sono molto più probabili rispetto agli altri, l’entropia sarà inferiore, riflettendo una minore incertezza.\nIn sintesi, l’entropia \\(H(X)\\) misura l’incertezza complessiva associata alla distribuzione di probabilità di una variabile casuale discreta \\(X\\). Essa quantifica la sorpresa media che ci si può aspettare quando si osserva un evento estratto casualmente da questa collezione.\n\nEsempio 70.1 Supponiamo di avere un dado con otto facce. Ci sono \\(m = 8\\) esiti possibili:\n\\[\nA_x = \\{1,2,3,4,5,6,7,8\\}.\n\\]\nPoiché il dado è equo, tutti gli otto esiti hanno la stessa probabilità di \\(p(x) = 1/8\\), definendo così una distribuzione di probabilità uniforme:\n\\[\np(X) = \\left\\{\\frac{1}{8}, \\frac{1}{8}, \\frac{1}{8}, \\frac{1}{8}, \\frac{1}{8}, \\frac{1}{8}, \\frac{1}{8}, \\frac{1}{8}\\right\\}.\n\\]\nL’entropia di questa distribuzione può essere calcolata come:\n\\[\nH(X) = - \\sum_{i=1}^{8} \\frac{1}{8} \\log_2 \\frac{1}{8} = \\log_2 8 = 3 \\text{ bit}.\n\\]\nPoiché l’informazione associata a ciascun esito è esattamente 3 bit, anche l’entropia media è di 3 bit, che rappresenta l’incertezza complessiva della variabile \\(X\\).\nDato che \\(X\\) ha un’entropia di \\(H(X) = 3\\) bit, possiamo dire che \\(X\\) può rappresentare fino a:\n\\[\nm = 2^{H(X)} = 2^3 = 8\n\\]\nesiti equiprobabili.\n\n\nEsempio 70.2 Sia \\(X\\) una variabile casuale discreta che può assumere i valori \\(a, b, c,\\) e \\(d\\) con una distribuzione di probabilità di massa \\(p(a) = \\frac{1}{2}\\), \\(p(b) = \\frac{1}{4}\\), \\(p(c) = \\frac{1}{8}\\), e \\(p(d) = \\frac{1}{8}\\), rispettivamente. L’entropia di \\(X\\), che misura l’incertezza associata alla distribuzione di probabilità, è calcolata come:\n\\[\nH(X) = -\\left(\\frac{1}{2} \\log_2 \\frac{1}{2} + \\frac{1}{4} \\log_2 \\frac{1}{4} + \\frac{1}{8} \\log_2 \\frac{1}{8} + \\frac{1}{8} \\log_2 \\frac{1}{8}\\right).\n\\]\nCalcolando i singoli termini, otteniamo:\n\\[\nH(X) = -\\left(\\frac{1}{2} \\cdot (-1) + \\frac{1}{4} \\cdot (-2) + \\frac{1}{8} \\cdot (-3) + \\frac{1}{8} \\cdot (-3)\\right) = \\frac{7}{4} \\text{ bits}.\n\\]\nÈ importante notare che l’entropia \\(H(X)\\) dipende esclusivamente dalla distribuzione di probabilità dei valori di \\(X\\) e non dai valori stessi.\n\n\n70.9.2 Stimare l’Entropia in un Campione di Osservazioni\nL’entropia può essere calcolata non solo per distribuzioni teoriche, ma anche per campioni di dati osservati. In questo caso, l’entropia ci fornisce una misura di quanto sia incerta o imprevedibile la distribuzione dei valori all’interno del campione.\n\nEsempio 70.3 Per comprendere meglio questo concetto, possiamo calcolare l’entropia associata a insiemi di osservazioni. Consideriamo i due vettori seguenti:\n\\[\n\\begin{align}\nx &= \\{1, 2, 3, 3, 3, 3, 2, 1, 3, 3, 2, 1, 1, 4, 4, 3, 1, 2\\}, \\notag\\\\\ny &= \\{3, 4, 1, 1, 1, 1, 4, 3, 1, 1, 4, 3, 3, 2, 2, 1, 3, 4\\}. \\notag\n\\end{align}\n\\]\nTroviamo l’entropia associata a ciascuno di essi.\n\n# Definisco i vettori\nx &lt;- c(1, 2, 3, 3, 3, 3, 2, 1, 3, 3, 2, 1, 1, 4, 4, 3, 1, 2)\ny &lt;- c(3, 4, 1, 1, 1, 1, 4, 3, 1, 1, 4, 3, 3, 2, 2, 1, 3, 4)\n\n# Calcolo il numero di occorrenze di ciascun valore\nx_counts &lt;- table(x)\ny_counts &lt;- table(y)\n\n# Calcolo le probabilità\nx_probabilities &lt;- as.numeric(x_counts) / length(x)\ny_probabilities &lt;- as.numeric(y_counts) / length(y)\n\n# Funzione per calcolare l'entropia\ncalculate_entropy &lt;- function(probabilities) {\n  -sum(probabilities * log2(probabilities))\n}\n\n# Calcolo manualmente l'entropia\nx_entropy &lt;- calculate_entropy(x_probabilities)\ny_entropy &lt;- calculate_entropy(y_probabilities)\n\n# Risultati\nlist(x_entropy = x_entropy, y_entropy = y_entropy)\n#&gt; $x_entropy\n#&gt; [1] 1.88\n#&gt; \n#&gt; $y_entropy\n#&gt; [1] 1.88\n\nEntrambi i vettori hanno la stessa entropia di 1.8776 bit.\n\n\nEsempio 70.4 Consideriamo un gioco con due giocatori. In questo gioco, vengono considerate solo le 13 carte del seme di quadri da un mazzo standard di 52 carte, e si suppone che ognuna di queste carte abbia la stessa probabilità di essere scelta. Il primo giocatore sceglie una carta tra le 13 carte di quadri. Il secondo giocatore deve indovinare quale carta di quadri è stata scelta facendo domande a cui il primo giocatore risponderà esclusivamente con “sì” o “no”. L’obiettivo è determinare il numero minimo di domande necessarie per identificare esattamente la carta scelta.\nIn questa situazione, la scelta del primo giocatore può essere rappresentata come un vettore one-hot di dimensione 13: \\(X = (x_1, \\dots, x_{13}) \\in \\{0, 1\\}^{13}\\), dove esattamente un elemento \\(x_i\\) è uguale a 1 (indica la carta scelta), mentre gli altri sono uguali a 0. Quindi ci sono 13 possibili scelte.\nL’incertezza associata alla scelta casuale di una carta tra le 13 disponibili è quantificata dall’entropia. Poiché tutte le carte hanno la stessa probabilità di essere selezionate, l’entropia della distribuzione uniforme è data dalla formula:\n\\[\nH(X) = \\log_2 13 \\approx 3.7 \\text{ bit}.\n\\]\nQuesta quantità rappresenta l’incertezza iniziale, ovvero il numero di bit di informazione necessari per determinare esattamente quale delle 13 carte è stata scelta.\nOgni risposta data dal primo giocatore (“sì” o “no”) fornisce 1 bit di informazione, poiché riduce il numero di possibilità di circa la metà. Dato che l’incertezza iniziale è di circa 3.7 bit, il numero minimo di domande necessarie è:\n\\[\n\\frac{3.7}{1} = 3.7 \\text{ risposte},\n\\]\nche in pratica significa che saranno necessarie almeno 4 domande per determinare con certezza la carta scelta.\nPer esempio, possiamo dividere il set iniziale \\(E^{(0)}\\), formato dalle 13 carte di quadri, in due sottoinsiemi:\n\\[\nE_1^{(0)} = \\{1, 2, 3, 4, 5, 6, 7\\}, \\quad E_2^{(0)} = \\{8, 9, 10, 11, 12, 13\\}.\n\\]\nLa prima domanda potrebbe essere: “La carta scelta si trova in \\(E_1^{(0)}\\)?”.\n\nSe la risposta è sì, eliminiamo \\(E_2^{(0)}\\);\nSe la risposta è no, eliminiamo \\(E_1^{(0)}\\).\n\nIn entrambi i casi, ci resta un nuovo set \\(E^{(1)}\\) contenente al massimo 7 carte. Ripetiamo il processo dividendo nuovamente in due sottoinsiemi. Nel caso peggiore, possiamo dividere \\(E^{(1)}\\) in:\n\\[\nE_1^{(1)} = \\{1, 2, 3, 4\\}, \\quad E_2^{(1)} = \\{5, 6, 7\\},\n\\]\ne chiedere se la carta scelta è in \\(E_1^{(1)}\\).\nDopo ogni domanda, riduciamo progressivamente il set di possibili carte fino ad arrivare a una singola carta. Con la quarta domanda possiamo determinare esattamente quale carta è stata scelta.\nIn questo modo, abbiamo confermato che il numero minimo di domande per identificare la carta è 4, dato che l’entropia iniziale della scelta tra 13 carte è di circa 3.7 bit.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#entropia-di-una-variabile-casuale-continua",
    "href": "chapters/entropy/01_entropy.html#entropia-di-una-variabile-casuale-continua",
    "title": "70  Entropia",
    "section": "\n70.10 Entropia di una Variabile Casuale Continua",
    "text": "70.10 Entropia di una Variabile Casuale Continua\nNel caso delle variabili casuali continue, il concetto di entropia viene generalizzato sostituendo la somma con un integrale. Questo è necessario perché le variabili continue possono assumere un numero infinito di valori all’interno di un intervallo.\nPer una variabile casuale continua \\(X\\) con una funzione di densità di probabilità \\(p(x)\\), l’entropia (nota anche come entropia differenziale) è definita dalla seguente formula:\n\\[ H(X) = -\\int p(x) \\log_2(p(x)) \\, dx, \\]\ndove:\n\n\n\\(p(x)\\) è la funzione di densità di probabilità di \\(X\\),\nl’integrale è calcolato su tutto il dominio di \\(X\\).\n\nL’entropia di una variabile casuale continua fornisce una misura dell’incertezza o della sorpresa associata alla distribuzione della variabile. Come nel caso discreto, l’entropia continua quantifica l’incertezza associata a \\(X\\). Una PDF molto concentrata (ad esempio, una distribuzione con picchi stretti) implica bassa entropia, poiché l’evento è più prevedibile. Una PDF distribuita uniformemente implica alta entropia, poiché l’evento è meno prevedibile.\nIl segno negativo assicura che l’entropia sia una quantità positiva, in quanto \\(\\log_2(p(x))\\) è negativo per \\(p(x)\\) compreso tra 0 e 1.\nEsempi relativi al calcolo dell’entropia nel caso di variabili continue sono fornite nel ?sec-entropy-rv-cont.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#la-codifica-huffman",
    "href": "chapters/entropy/01_entropy.html#la-codifica-huffman",
    "title": "70  Entropia",
    "section": "\n70.11 La Codifica Huffman",
    "text": "70.11 La Codifica Huffman\nLa codifica Huffman è un metodo utilizzato per rappresentare gli esiti di una variabile casuale in un formato binario, ottimizzando la lunghezza del codice necessario per descrivere questi esiti. Questo algoritmo crea una rappresentazione binaria che permette di comprimere i dati senza perdita di informazioni, utilizzando una codifica efficiente basata sulla frequenza dei simboli.\nNella codifica Huffman, i simboli più frequenti sono rappresentati da codici binari più brevi, mentre i simboli meno frequenti sono rappresentati da codici più lunghi. Questo approccio assicura che la lunghezza media del codice per rappresentare una sequenza di simboli sia la più corta possibile, ottimizzando così lo spazio necessario per la memorizzazione o la trasmissione dei dati. In questo modo, la codifica Huffman riesce a ridurre la quantità di bit necessari per codificare una variabile casuale, rispettando il principio della teoria dell’informazione che lega la probabilità di un simbolo alla lunghezza del codice a esso associato.\nLa codifica Huffman può essere descritta nel modo seguente.\n\n\nCreazione della lista di simboli e frequenze:\n\nIn questa fase, si analizza il testo o i dati da comprimere.\nSi conta quante volte appare ogni simbolo (che può essere un carattere, una parola, o qualsiasi unità di informazione).\nSi crea una tabella che elenca ogni simbolo unico e la sua frequenza di apparizione.\nPer esempio, in un testo, potremmo avere: A: 10, B: 5, C: 12, D: 3, E: 15.\n\n\n\nCostruzione dell’albero binario:\n\nSi inizia creando un nodo foglia per ogni simbolo. Ogni nodo contiene il simbolo e la sua frequenza.\nPoi si segue questo processo iterativo:\n\nSi selezionano i due nodi con le frequenze più basse.\nSi crea un nuovo nodo padre che ha questi due come figli.\nLa frequenza del nuovo nodo padre è la somma delle frequenze dei figli.\nSi aggiunge questo nuovo nodo all’insieme dei nodi disponibili.\nSi ripete finché non rimane un solo nodo (la radice dell’albero).\n\n\nDurante questo processo, i simboli più frequenti tendono a rimanere vicini alla radice, mentre quelli meno frequenti si trovano più in profondità nell’albero.\n\n\n\nAssegnazione dei codici:\n\nUna volta costruito l’albero, si assegna un bit ‘0’ a ogni ramo sinistro e un bit ‘1’ a ogni ramo destro.\nPer trovare il codice di un simbolo, si parte dalla radice e si segue il percorso fino alla foglia corrispondente, registrando i bit incontrati lungo il cammino.\nI simboli più frequenti avranno codici più corti (più vicini alla radice), mentre quelli meno frequenti avranno codici più lunghi.\n\n\n\nIn conclusione, la codifica Huffman è un metodo di compressione dei dati che utilizza le proprietà della probabilità e della teoria dell’informazione per creare una rappresentazione binaria ottimizzata, riducendo così la quantità di dati necessari per rappresentare una sequenza di simboli.\n\nEsempio 70.5 Supponiamo di avere questi simboli e le loro rispettive frequenze:\n\nA: 20\nB: 10\nC: 8\nD: 5\n\nVogliamo generare i codici di Huffman per ciascun simbolo, ottimizzando la rappresentazione dei dati affinché i simboli più frequenti abbiano codici più brevi.\nPassaggi per creare l’albero di Huffman:\n\n\nCreazione dei nodi foglia\nCreiamo un nodo foglia per ogni simbolo, dove il numero rappresenta la frequenza:\n\n(A:20), (B:10), (C:8), (D:5)\n\n\n\nCostruzione dell’albero\nCombiniamo i due nodi con le frequenze più basse e ripetiamo fino a ottenere un unico albero:\n\nCombiniamo D (5) e C (8): il nuovo nodo avrà una frequenza pari alla somma delle due, ovvero 13.\nRisultato: ((D:5, C:8):13)\nCombiniamo il nodo appena creato (D,C:13) con B (10): il nuovo nodo avrà frequenza 23.\nRisultato: (B:10, (D:5, C:8):13):23\nCombiniamo il nodo appena creato (B,(D,C):23) con A (20): il nuovo nodo sarà la radice dell’albero con frequenza totale 43.\nRisultato: (A:20, (B:10, (D:5, C:8):13):23):43\n\n\n\nAlbero di Huffman risultante\nL’albero finale sarà:\n       (43)\n      /    \\\n    (20)   (23)\n     |     /   \\\n     A   (10)  (13)\n          |    /  \\\n          B   (5) (8)\n              |    |\n              D    C\nCosa rappresentano i numeri nei nodi?\n\nNei nodi foglia (es. A, B, C, D), il numero rappresenta la frequenza di quel simbolo.\nNei nodi interni, il numero rappresenta la somma delle frequenze dei nodi figli. Ad esempio:\n\nIl nodo 13 rappresenta la somma delle frequenze di C (8) e D (5).\nIl nodo 23 rappresenta la somma delle frequenze di B (10) e (D,C:13).\n\n\n\nGenerazione dei codici\nPer generare i codici di Huffman, seguiamo queste regole:\n\nOgni volta che scendiamo a sinistra, aggiungiamo uno 0 al codice.\nOgni volta che scendiamo a destra, aggiungiamo un 1.\n\nDall’albero otteniamo:\n\nA: 0 (si raggiunge scendendo a sinistra dalla radice)\nB: 10 (si raggiunge scendendo a destra, poi a sinistra)\nD: 110 (si raggiunge scendendo a destra, poi a destra, infine a sinistra)\nC: 111 (si raggiunge scendendo a destra, poi a destra, infine a destra)\n\nIn conclusione, questo esempio mostra come la codifica di Huffman assegna codici più brevi ai simboli più frequenti (es. A) e codici più lunghi ai simboli meno frequenti (es. C e D). Il risultato ottimizza la lunghezza totale del messaggio codificato.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#lentropia-come-lunghezza-media-del-codice-binario",
    "href": "chapters/entropy/01_entropy.html#lentropia-come-lunghezza-media-del-codice-binario",
    "title": "70  Entropia",
    "section": "\n70.12 L’Entropia come Lunghezza Media del Codice Binario",
    "text": "70.12 L’Entropia come Lunghezza Media del Codice Binario\nL’entropia, in termini di teoria dell’informazione, rappresenta la quantità media di informazione necessaria per descrivere gli esiti di una variabile casuale. In altre parole, può essere interpretata come la lunghezza media del codice binario utilizzato per rappresentare questi esiti, tenendo conto delle loro probabilità.\nConsideriamo una variabile casuale discreta \\(X\\) che può assumere quattro valori: \\(A, B, C,\\) e \\(D\\), con le seguenti probabilità:\n\n\\(p(A) = 0.4\\)\n\\(p(B) = 0.3\\)\n\\(p(C) = 0.2\\)\n\\(p(D) = 0.1\\)\n\nUtilizzando la codifica Huffman per questa variabile casuale, otteniamo i seguenti codici binari:\n\n\n\\(A\\) = “0”\n\n\\(B\\) = “10”\n\n\\(C\\) = “110”\n\n\\(D\\) = “111”\n\nLa lunghezza media del codice in bit può essere calcolata come segue:\n\\[\n\\begin{align}\n\\text{Lunghezza media} &= p(A) \\times \\text{lunghezza di } A + p(B) \\times \\text{lunghezza di } B\\notag \\\\\n&\\quad + p(C) \\times \\text{lunghezza di } C\\notag + p(D) \\times \\text{lunghezza di } D\\notag.\n\\end{align}\n\\]\nSostituendo i valori delle probabilità e le lunghezze dei codici:\n\\[\n\\begin{align}\n\\text{Lunghezza media} &= (0.4 \\times 1) + (0.3 \\times 2) + (0.2 \\times 3) + (0.1 \\times 3)\\notag\\\\\n&= 0.4 + 0.6 + 0.6 + 0.3 = 1.9 \\text{ bit}.\\notag\n\\end{align}\n\\]\nPossiamo replicare questo risultato usando una funzione R:\n\nhuffman_encoding &lt;- function(probabilities) {\n  # Creazione della coda con priorità (min-heap) per costruire\n  # l'albero di Huffman\n  heap &lt;- lapply(\n    names(probabilities), function(symbol) {\n      list(\n        weight = probabilities[[symbol]],\n        nodes = list(list(symbol = symbol, code = \"\"))\n      )\n    }\n  )\n\n  # Funzione per ordinare la heap in base ai pesi\n  sort_heap &lt;- function(heap) {\n    heap[order(sapply(heap, function(x) x$weight))]\n  }\n  heap &lt;- sort_heap(heap)\n\n  # Costruzione dell'albero di Huffman\n  while (length(heap) &gt; 1) {\n    # Estrarre i due nodi con peso minimo\n    lo &lt;- heap[[1]]\n    hi &lt;- heap[[2]]\n    heap &lt;- heap[-(1:2)]\n\n    # Aggiornare i codici per i simboli nei nodi estratti\n    lo$nodes &lt;- lapply(\n      lo$nodes,\n      function(node) {\n        node$code &lt;- paste0(\"0\", node$code)\n        node\n      }\n    )\n\n    hi$nodes &lt;- lapply(\n      hi$nodes,\n      function(node) {\n        node$code &lt;- paste0(\"1\", node$code)\n        node\n      }\n    )\n\n    # Aggiungere il nuovo nodo combinato alla heap\n    new_node &lt;- list(\n      weight = lo$weight + hi$weight,\n      nodes = c(lo$nodes, hi$nodes)\n    )\n    heap &lt;- c(heap, list(new_node))\n    heap &lt;- sort_heap(heap)\n  }\n\n  # Estrazione del dizionario dei codici di Huffman\n  huffman_dict &lt;- heap[[1]]$nodes\n  huffman_dict &lt;- huffman_dict[\n    order(\n      sapply(huffman_dict, function(node) nchar(node$code))\n    )\n  ]\n\n  # Calcolo della lunghezza media del codice\n  avg_length &lt;- sum(\n    sapply(\n      huffman_dict, function(node) {\n        probabilities[[node$symbol]] * nchar(node$code)\n      }\n    )\n  )\n\n  list(avg_length = avg_length, huffman_dict = huffman_dict)\n}\n\n\n# Distribuzione di probabilità di una variabile casuale discreta\nprobabilities &lt;- list(A = 0.4, B = 0.3, C = 0.2, D = 0.1)\n\n# Calcolo della lunghezza media del codice di Huffman\nresult &lt;- huffman_encoding(probabilities)\n\n# Visualizzazione dei risultati\ncat(\n  sprintf(\n    \"Lunghezza media del codice di Huffman: %.2f bit/simbolo\\n\",\n    result$avg_length\n  )\n)\n#&gt; Lunghezza media del codice di Huffman: 1.90 bit/simbolo\n\ncat(\"Codici di Huffman per ciascun simbolo:\\n\")\n#&gt; Codici di Huffman per ciascun simbolo:\n\nfor (node in result$huffman_dict) {\n  cat(sprintf(\"%s: %s\\n\", node$symbol, node$code))\n}\n#&gt; A: 0\n#&gt; B: 10\n#&gt; D: 110\n#&gt; C: 111\n\nCalcoliamo ora l’entropia \\(H(X)\\) della variabile casuale \\(X\\):\n\\[\n\\begin{align}\nH(X) &= -\\sum p(x) \\log_2 p(x) \\notag\\\\\n     &= -(0.4 \\log_2 0.4 + 0.3 \\log_2 0.3 + 0.2 \\log_2 0.2 + 0.1 \\log_2 0.1)\\notag\\\\\n     &= 1.8465 \\text{ bit}.\n\\end{align}\n\\]\nIn questo esempio, l’entropia è \\(H(X) = 1.8465\\) bit. La lunghezza media del codice Huffman calcolata è di \\(1.9\\) bit, un valore molto vicino all’entropia. Questo ci permette di interpretare l’entropia come la lunghezza media teorica minima del codice binario necessario per rappresentare la variabile casuale \\(X\\). Possiamo affermare che la codifica di Huffman è quasi ottimale, poiché si avvicina molto al limite inferiore stabilito dall’entropia. In altre parole, l’entropia rappresenta effettivamente la lunghezza minima media del codice binario necessaria per descrivere la distribuzione di probabilità di una variabile casuale.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#applicazioni-psicologiche",
    "href": "chapters/entropy/01_entropy.html#applicazioni-psicologiche",
    "title": "70  Entropia",
    "section": "\n70.13 Applicazioni Psicologiche",
    "text": "70.13 Applicazioni Psicologiche\nUn esempio di applicazione dell’entropia dell’informazione in psicologia riguarda dell’effetto della sorpresa nello studio dell’umore. La sorpresa, o entropia, è stata documentata sia in laboratorio che in contesti naturali come un fattore che influenza le emozioni. Ad esempio, Spector (1956) osservò l’effetto della probabilità a priori sulla soddisfazione dei soggetti in risposta a una promozione lavorativa. I risultati indicano che gli esiti meno probabili a priori (e quindi più sorprendenti quando si verificano) hanno un impatto maggiore sull’umore. In altre parole, quando un evento inatteso e sorprendente si verifica, esso tende a influenzare l’umore in modo più forte rispetto a eventi previsti e probabili.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#riflessioni-conclusive",
    "href": "chapters/entropy/01_entropy.html#riflessioni-conclusive",
    "title": "70  Entropia",
    "section": "\n70.14 Riflessioni Conclusive",
    "text": "70.14 Riflessioni Conclusive\nIn questo capitolo, abbiamo esplorato il concetto di entropia, sottolineando il suo ruolo cruciale nella quantificazione dell’incertezza all’interno delle distribuzioni di probabilità. Nel prossimo capitolo, vedremo come l’entropia possa essere utilizzata per valutare la “distanza” tra un modello teorico e i dati empirici. A tal fine, introdurremo la divergenza di Kullback-Leibler, una misura che quantifica le discrepanze tra due distribuzioni di probabilità.\nConcludiamo il capitolo con una riflessione tratta da Paradoxes in probability theory and mathematical statistics di Gabor Székely, che ci ricorda come la quantificazione dell’informazione non sia sempre un processo lineare o intuitivo:\n\nThe last paradox in this book is a quotation from my late professor Alfréd Rényi. “Since I started to deal with information theory I have often meditated upon the conciseness of poems; how can a single line of verse contain far more ‘information’ than a highly concise telegram of the same length. The surprising richness of meaning of literary works seems to be in contradiction with the laws of information theory. The key to this paradox is, I think, the notion of ‘resonance’. The writer does not merely give us information, but also plays on the strings of the language with such virtuosity, that our mind, and even the subconscious self resonate. A poet can recall chains of ideas, emotions and memories with a wellturned word. In this sense, writing is magic.”\n\nQuesta citazione ci invita a riflettere sulla natura dell’informazione. Ci ricorda che, mentre la teoria dell’informazione fornisce strumenti potenti per quantificare e analizzare l’incertezza e la complessità, esistono forme di comunicazione e espressione che trascendono le misure puramente quantitative. La “risonanza” di cui parla Rényi suggerisce che l’impatto e il significato dell’informazione possono dipendere non solo dal suo contenuto oggettivo, ma anche dal modo in cui essa interagisce con le nostre esperienze, emozioni e conoscenze pregresse.\nQuesta prospettiva ci incoraggia a mantenere un approccio critico nell’applicazione dei concetti di teoria dell’informazione, riconoscendo sia il loro potere analitico che i loro limiti intrinseci nell’interpretazione di fenomeni complessi.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/entropy/01_entropy.html#informazioni-sullambiente-di-sviluppo",
    "title": "70  Entropia",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] ggrepel_0.9.6    ggraph_2.2.1     igraph_2.1.2     see_0.9.0       \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.4.12    \n#&gt;  [9] scales_1.3.0     markdown_1.13    knitr_1.49       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.2     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6       xfun_0.49          htmlwidgets_1.6.4 \n#&gt;  [4] lattice_0.22-6     tzdb_0.4.0         vctrs_0.6.5       \n#&gt;  [7] tools_4.4.2        generics_0.1.3     parallel_4.4.2    \n#&gt; [10] pacman_0.5.1       pkgconfig_2.0.3    lifecycle_1.0.4   \n#&gt; [13] compiler_4.4.2     farver_2.1.2       munsell_0.5.1     \n#&gt; [16] mnormt_2.1.1       ggforce_0.4.2      graphlayouts_1.2.1\n#&gt; [19] htmltools_0.5.8.1  yaml_2.3.10        pillar_1.10.0     \n#&gt; [22] MASS_7.3-61        cachem_1.1.0       viridis_0.6.5     \n#&gt; [25] nlme_3.1-166       tidyselect_1.2.1   digest_0.6.37     \n#&gt; [28] stringi_1.8.4      labeling_0.4.3     polyclip_1.10-7   \n#&gt; [31] rprojroot_2.0.4    fastmap_1.2.0      grid_4.4.2        \n#&gt; [34] colorspace_2.1-1   cli_3.6.3          magrittr_2.0.3    \n#&gt; [37] tidygraph_1.3.1    withr_3.0.2        timechange_0.3.0  \n#&gt; [40] rmarkdown_2.29     hms_1.1.3          memoise_2.0.1     \n#&gt; [43] evaluate_1.0.1     viridisLite_0.4.2  rlang_1.1.4       \n#&gt; [46] Rcpp_1.0.13-1      glue_1.8.0         tweenr_2.0.3      \n#&gt; [49] jsonlite_1.8.9     R6_2.5.1",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#bibliografia",
    "href": "chapters/entropy/01_entropy.html#bibliografia",
    "title": "70  Entropia",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nSpector, A. J. (1956). Expectations, fulfillment, and morale. The Journal of Abnormal and Social Psychology, 52(1), 51–56.\n\n\nStone, J. V. (2022). Information theory: a tutorial introduction, 2nd edition.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/introduction_frequentist_inference.html",
    "href": "chapters/frequentist_inference/introduction_frequentist_inference.html",
    "title": "Introduzione",
    "section": "",
    "text": "Nell’inferenza statistica esistono due approcci principali: la statistica frequentista e la statistica bayesiana. Entrambi i metodi permettono di trarre conclusioni sulla popolazione di interesse analizzando i dati, stimare quantità sconosciute, fare previsioni e testare ipotesi. Tuttavia, differiscono nell’interpretazione della probabilità e nell’integrazione di conoscenze precedenti ed evidenze.\nLa statistica bayesiana interpreta la probabilità come una misura di convinzione o grado di certezza riguardo a un evento. Questo approccio consente di incorporare conoscenze pregresse ed evidenze nell’analisi statistica utilizzando il teorema di Bayes. In questo contesto, il valore vero di un parametro della popolazione è trattato come una variabile casuale, che viene costantemente aggiornata man mano che nuovi dati vengono raccolti. Ciò porta alla formazione di una distribuzione completa nello spazio dei parametri, nota come distribuzione a posteriori, utilizzabile per fare previsioni probabilistiche e quantificare l’incertezza associata.\nD’altra parte, la statistica frequentista interpreta la probabilità come la frequenza relativa a lungo termine di un evento in un numero infinito di prove. Questo approccio si basa sull’idea che il vero valore di un parametro della popolazione sia fisso ma sconosciuto e debba essere stimato dai dati. In questo contesto, le inferenze statistiche vengono ottenute dai dati osservati utilizzando varie tecniche statistiche e facendo alcune assunzioni riguardo al processo sottostante che genera i dati.\nIn questa sezione della dispensa esamineremo i metodi frequentisti della stima puntuale, degli intervalli di confidenza e del test di ipotesi.",
    "crumbs": [
      "Frequentismo",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html",
    "title": "71  Introduzione all’inferenza frequentista",
    "section": "",
    "text": "71.1 Introduzione\nCi sono due approcci principali per l’inferenza statistica: la statistica frequentista e la statistica bayesiana. Questi metodi consentono di fare conclusioni sulla popolazione di interesse attraverso l’analisi dei dati. Entrambi gli approcci sono usati per stimare quantità sconosciute, fare previsioni e testare ipotesi, ma differiscono nella loro interpretazione della probabilità e in come integrano le conoscenze precedenti ed evidenze.\nNella statistica frequentista, la probabilità viene interpretata come la frequenza relativa a lungo termine di un evento in un numero infinito di prove. Questo approccio si basa sull’idea che il vero valore di un parametro della popolazione sia fisso, ma sconosciuto e debba essere stimato dai dati. In questo contesto, le inferenze statistiche vengono ottenute a partire dai dati osservati, mediante l’utilizzo di tecniche come la stima puntuale, gli intervalli di confidenza e il test di ipotesi, e facendo alcune assunzioni riguardo al processo sottostante che genera i dati.\nD’altra parte, la statistica bayesiana interpreta la probabilità come una misura di convinzione o grado di certezza riguardo a un evento (Jaynes, 2003). Questo approccio consente di incorporare conoscenze pregresse ed evidenze nell’analisi statistica attraverso l’uso del teorema di Bayes. In questo contesto, il vero valore di un parametro della popolazione è trattato come una variabile casuale e viene continuamente aggiornato man mano che vengono raccolti nuovi dati. Ciò porta alla formazione di una distribuzione completa nello spazio dei parametri, nota come distribuzione a posteriori, che può essere utilizzata per fare previsioni probabilistiche e quantificare l’incertezza associata.\nIn questo capitolo, approfondiremo il concetto di distribuzione campionaria che costituisce uno dei pilastri dell’inferenza statistica frequentista. La distribuzione campionaria ci permette di comprendere come le stime dei parametri della popolazione, come la media o la varianza, cambiano da campione a campione. In particolare, la distribuzione campionaria ci consente di stabilire delle proprietà probabilistiche delle stime campionarie, come ad esempio la loro media e la loro varianza. Queste proprietà sono utili per costruire gli intervalli di fiducia e i test di ipotesi che costituiscono gli strumenti principali dell’inferenza statistica frequentista.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#i-frequentisti-sono-razzisti",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#i-frequentisti-sono-razzisti",
    "title": "71  Introduzione all’inferenza frequentista",
    "section": "\n71.2 I Frequentisti sono Razzisti?",
    "text": "71.2 I Frequentisti sono Razzisti?\nNel ?sec-bayes_theorem, abbiamo esaminato le origini storiche e il contesto culturale che ha contribuito all’interpretazione applicativa del teorema di Bayes fornita da Richard Price. Queste origini sono legate alle idee alla base della rivoluzione americana, rappresentando quello che potremmo definire il “lato luminoso” del liberalismo moderno.\nLe origini culturali dell’approccio frequentista, invece, sono diametralmente opposte e strettamente connesse a quella che potremmo chiamare la “parte oscura” della modernità. Si potrebbe dire che l’avversione per la soggettività abbia guidato l’ascesa del frequentismo.\nFrancis Galton (1822-1911) fu un uomo straordinario sotto molti aspetti. Cugino di Charles Darwin e medico qualificato, ereditò una fortuna che gli permise di dedicarsi liberamente ai suoi interessi. Esplorò l’Africa, ricevendo una medaglia dalla Royal Geographical Society, e diede un importante contributo alla meteorologia, notando per primo il fenomeno degli “anticicloni”. Tuttavia, il suo contributo più significativo riguardò l’uso della statistica nello studio degli esseri umani, in particolare nell’analisi della trasmissione ereditaria del talento.\nGalton trascorse gran parte della sua carriera all’University College di Londra, dove fece numerose scoperte. Tra queste, un importante contributo riguardava la distribuzione normale. Fu anche il primo a spiegare il concetto che oggi conosciamo come “regressione verso la media”, da lui chiamato “regressione verso la mediocrità”.\nIl suo interesse per l’ereditarietà del talento portò Francis Galton a scrivere il libro Hereditary Genius, in cui analizzava come individui brillanti tendessero a concentrarsi in specifiche famiglie. Fu lui a coniare l’espressione “nature and nurture” per riferirsi ai due fattori fondamentali che influenzano lo sviluppo umano: l’ereditarietà (ciò che oggi chiamiamo genetica) e l’ambiente.\nTuttavia, Galton non si limitò a osservare e documentare la distribuzione dell’intelligenza. Il suo obiettivo era ambizioso e controverso: creare una scienza per il “miglioramento della specie umana”, che egli chiamò “eugenetica”. Promuoveva l’idea di incoraggiare la riproduzione tra le famiglie considerate di maggior successo e, al contrario, di scoraggiarla tra quelle ritenute meno fortunate.\nVa però sottolineato che Galton abbracciava idee profondamente razziste. In una lettera pubblicata sul Times di Londra, descrisse gli africani come “inferiori” e li definì “selvaggi pigri e chiacchieroni”. Gli arabi, secondo lui, erano “poco più che consumatori della produzione altrui”. Proponeva inoltre di consegnare l’Africa orientale ai cinesi, che giudicava “inclini alla menzogna e alla servilità” ma anche, a suo dire, “naturalmente industriosi e amanti dell’ordine”. Per Galton, gli anglosassoni rappresentavano la razza migliore esistente, sebbene ritenesse che gli antichi ateniesi fossero stati il vertice dell’umanità.\nIl lavoro di Galton ispirò una generazione successiva di statistici, in particolare Karl Pearson (1857-1936) e Ronald Fisher (1890-1962). Come Galton, Fisher e Pearson erano brillanti, ma condividevano anche le sue idee razziste, considerate inaccettabili sia per gli standard attuali che per quelli del loro tempo.\nKarl Pearson, poliedrico studioso e innovatore, divenne professore di matematica applicata all’UCL nel 1885, seguendo le orme di Francis Galton. Dopo la morte di quest’ultimo, ereditò la cattedra di eugenetica, istituita e finanziata da Galton stesso. Pearson fondò la rivista di statistica Biometrika e diede un contributo fondamentale alla disciplina, sviluppando il test del chi quadrato e coniando il termine “deviazione standard”.\nRonald Fisher, più giovane, succedette a Pearson come professore di eugenetica presso l’UCL. Considerato un gigante della teoria statistica, Fisher contribuì in modo decisivo allo sviluppo della disciplina, inventando o perfezionando strumenti fondamentali come l’analisi della varianza (ANOVA), il concetto di “significatività statistica” e il metodo della massima verosimiglianza (MLE).\nTutti questi ricercatori cercarono di allontanare la statistica dall’approccio soggettivo di Laplace e Bayes. Come Galton, sia Pearson che Fisher erano convinti sostenitori dell’eugenetica.\nÈ interessante riflettere su quanto le idee di Galton, Pearson e Fisher sull’eugenetica possano aver influenzato le loro visioni scientifiche. Secondo alcuni studiosi, la storia della statistica e quella dell’eugenetica sono strettamente intrecciate. Fisher, e in misura minore Pearson, rigettavano il bayesianesimo perché desideravano conferire un fondamento apparentemente “oggettivo” alle loro idee eugenetiche. Se fosse stata la scienza a “dimostrare” che alcune razze erano inferiori ad altre, o che la riproduzione tra i poveri dovesse essere scoraggiata, queste teorie sarebbero state presentate come indiscutibili. Il bayesianesimo, con la sua componente intrinseca di soggettività, rappresentava una minaccia a questa pretesa di oggettività.\nQuanto dovremmo considerare le implicazioni storiche ed etiche quando valutiamo la statistica frequentista? Chivers (2024) risponde così: è indubbio che una parte dell’ideologia razziale nazista possa essere ricondotta a Galton senza troppe difficoltà. Tuttavia, questa riflessione, per quanto cruciale dal punto di vista storico ed etico, non è direttamente rilevante in ambito strettamente statistico. La domanda fondamentale rimane: “Quale approccio è corretto?” o, meglio ancora, “Quale approccio è più utile?”, anziché chiedersi “Quale approccio ha avuto i sostenitori più discutibili?”.\nPur riconoscendo il valore di questa risposta in termini di focalizzazione sulla metodologia, ritengo che sia intrinsecamente inadeguata. Consideriamo uno scenario ipotetico: supponiamo che in una “torre d’avorio” – che sia la statistica, l’accademia o la scienza in generale – la teoria A risulti più efficace della teoria B. Tuttavia, al di fuori di questo contesto isolato, la teoria A comporta conseguenze etiche inaccettabili, mentre la teoria B no. Dovremmo davvero accettare A semplicemente perché funziona meglio in un sistema chiuso e teorico? La mia risposta è un categorico no.\nLe cosiddette “torri d’avorio” sono costruzioni ideologiche che non rispecchiano la realtà. Non esiste una netta separazione tra “dentro” e “fuori”: scienza ed etica non operano in compartimenti stagni, ma interagiscono costantemente. L’idea di giudicare una teoria esclusivamente sulla base della sua efficacia all’interno di un contesto limitato ignora le sue implicazioni più ampie e potenzialmente dannose.\nNel caso specifico del frequentismo, è evidente – come dimostreremo in seguito – che questo approccio non solo presenta implicazioni etiche problematiche, ma è anche intrinsecamente fallace dal punto di vista metodologico. La sua supposta efficacia in un ambito ristretto è un’illusione che non regge a un’analisi critica più ampia. Non possiamo, né dobbiamo, separare l’efficacia teorica dalle conseguenze pratiche ed etiche. Il frequentismo fallisce su entrambi i fronti: morale e scientifico. Difenderlo, quindi, risulta insostenibile in ogni contesto.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#stime-stimatori-e-parametri",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#stime-stimatori-e-parametri",
    "title": "71  Introduzione all’inferenza frequentista",
    "section": "\n71.3 Stime, stimatori e parametri",
    "text": "71.3 Stime, stimatori e parametri\nSpostiamo ora il discorso da un piano culturale ad un piano strettamente statistico. Consideriamo il concetto di stima statistica.\nQuando si analizzano i dati, solitamente si è interessati a una quantità a livello di popolazione; tuttavia, di solito si ha accesso solo a un campione di osservazioni. La quantità sconosciuta di nostro interesse viene chiamata parametro. La statistica che calcoliamo utilizzando i dati del campione viene chiamata stima, e la formula che la produce viene chiamata stimatore. Formalmente, uno stimatore è una funzione dei dati osservati utilizzata per produrre una stima di un parametro.\nIn altre parole, quando analizziamo un campione di dati, vogliamo inferire alcune proprietà della popolazione di cui il campione è rappresentativo. Il parametro rappresenta la misura di tali proprietà, ma spesso non è possibile calcolarlo direttamente sulla popolazione. Pertanto, lo stimiamo utilizzando le osservazioni del campione. La stima è quindi l’approssimazione del valore del parametro che otteniamo dal nostro campione, mentre lo stimatore è la formula matematica utilizzata per calcolare questa stima.\nTuttavia, le stime non sono necessariamente identiche ai parametri di nostro interesse. Le stime presentano una certa incertezza dovuta alla variabilità del campionamento. In questo capitolo esamineremo come l’approccio frequentista quantifica l’incertezza nelle nostre stime, in modo da poter trarre conclusioni sul parametro.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#distribuzione-campionaria",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#distribuzione-campionaria",
    "title": "71  Introduzione all’inferenza frequentista",
    "section": "\n71.4 Distribuzione campionaria",
    "text": "71.4 Distribuzione campionaria\nIn questo capitolo esploreremo come la media di un campione casuale può essere utilizzata per stimare la media \\(\\mu\\) di una popolazione. Per valutare l’incertezza di questa stima, ci avvaliamo del concetto di distribuzione campionaria, un’importante idea dell’approccio frequentista.\nPer introdurre il concetto, utilizzeremo una popolazione finita di piccole dimensioni, pur sapendo che le proprietà illustrate valgono anche per popolazioni di dimensioni maggiori.\n\n71.4.1 Esempio introduttivo\nConsideriamo la seguente popolazione:\n\nx &lt;- c(2, 4.5, 5, 5.5)\nx\n#&gt; [1] 2.0 4.5 5.0 5.5\n\nL’istogramma sottostante rappresenta la distribuzione di frequenza della popolazione:\n\nhist(\n  x, breaks = 5, \n  freq = FALSE, \n  main = \"Distribuzione della popolazione\", \n  xlab = \"Valori\"\n)\n\n\n\n\n\n\n\nCalcoliamo la media e la varianza della popolazione:\n\nmean(x)  # Media\n#&gt; [1] 4.25\nvar(x)   # Varianza\n#&gt; [1] 2.42\n\n\n71.4.2 Campionamento\nSupponiamo ora di estrarre tutti i possibili campioni di dimensione \\(n = 2\\) dalla popolazione. Per generare queste combinazioni:\n\nsamples &lt;- expand.grid(x, x)\nsamples\n#&gt;    Var1 Var2\n#&gt; 1   2.0  2.0\n#&gt; 2   4.5  2.0\n#&gt; 3   5.0  2.0\n#&gt; 4   5.5  2.0\n#&gt; 5   2.0  4.5\n#&gt; 6   4.5  4.5\n#&gt; 7   5.0  4.5\n#&gt; 8   5.5  4.5\n#&gt; 9   2.0  5.0\n#&gt; 10  4.5  5.0\n#&gt; 11  5.0  5.0\n#&gt; 12  5.5  5.0\n#&gt; 13  2.0  5.5\n#&gt; 14  4.5  5.5\n#&gt; 15  5.0  5.5\n#&gt; 16  5.5  5.5\n\nOgni riga rappresenta un campione possibile. Calcoliamo il numero totale di campioni:\n\nnrow(samples)\n#&gt; [1] 16\n\nOra calcoliamo la media di ciascun campione, ottenendo la distribuzione campionaria delle medie per \\(n = 2\\):\n\nsample_means &lt;- rowMeans(samples)\nsample_means\n#&gt;  [1] 2.00 3.25 3.50 3.75 3.25 4.50 4.75 5.00 3.50 4.75 5.00 5.25 3.75 5.00\n#&gt; [15] 5.25 5.50\n\n\n71.4.3 Visualizzazione della distribuzione campionaria\nPossiamo rappresentare graficamente questa distribuzione:\n\nhist(\n  sample_means, \n  breaks = 5, \n  freq = FALSE, \n  main = \"Distribuzione campionaria delle medie (n = 2)\", \n  xlab = \"Media campionaria\"\n)\n\n\n\n\n\n\n\n\n71.4.4 Verifiche teoriche\n\n71.4.4.1 Media della distribuzione campionaria\nLa media della distribuzione campionaria deve essere uguale alla media della popolazione:\n\nmean(x)  # Media della popolazione\n#&gt; [1] 4.25\nmean(sample_means)  # Media della distribuzione campionaria\n#&gt; [1] 4.25\n\n\n71.4.4.2 Varianza della distribuzione campionaria\nLa varianza della distribuzione campionaria deve essere pari alla varianza della popolazione divisa per \\(n\\):\n\n# Evito la divisione per (n - 1)\nvariance &lt;- function(x) {\n  mean((x - mean(x))^2)\n}\n\n\nvariance(x) / 2  # Varianza teorica\n#&gt; [1] 0.906\nvariance(sample_means)  # Varianza empirica\n#&gt; [1] 0.906\n\n\n71.4.5 Esempio di campione osservato\nConsideriamo un singolo campione, ad esempio \\(\\{5, 5.5\\}\\):\n\nobserved_sample &lt;- c(5, 5.5)\nobserved_sample\n#&gt; [1] 5.0 5.5\n\nTroviamo la sua media e deviazione standard:\n\nmean(observed_sample)  # Media del campione\n#&gt; [1] 5.25\nsqrt(variance(observed_sample))    # Deviazione standard del campione\n#&gt; [1] 0.25\n\nConfrontiamo questi valori con quelli della popolazione:\n\nmean(x)  # Media della popolazione\n#&gt; [1] 4.25\nsqrt(variance(x))     # Deviazione standard della popolazione\n#&gt; [1] 1.35\n\nIn conclusione, dalla simulazione emergono due risultati fondamentali:\n\n\nLa media della distribuzione campionaria coincide con la media della popolazione. Questo significa che, se si considera la media \\(\\bar{X}_n\\) di campioni casuali di ampiezza \\(n\\), il valore atteso di \\(\\bar{X}_n\\) è uguale alla media della popolazione \\(\\mu\\). Formalmente:\n\\[\n\\mathbb{E}(\\bar{X}_n) = \\frac{1}{n} \\mathbb{E}(S_n) = \\frac{1}{n} n \\mu = \\mu,\n\\] dove \\(\\mathbb{E}(\\cdot)\\) rappresenta il valore atteso e \\(S_n\\) la somma delle osservazioni nel campione.\n\n\nLa varianza della distribuzione campionaria è inferiore alla varianza della popolazione. In particolare, la varianza delle medie campionarie è data dalla varianza della popolazione divisa per l’ampiezza del campione, ovvero:\n\\[\n\\mathbb{V}(\\bar{X}) = \\frac{\\sigma^2}{n}.\n\\]\n\n\n\n\n\n\n\n\nIl secondo risultato sopra può essere dimostrato come segue.\nSia \\(X_1, X_2, \\dots, X_n\\) un campione casuale di \\(n\\) osservazioni indipendenti estratte da una popolazione con media \\(\\mu\\) e varianza \\(\\sigma^2\\). La media campionaria è definita come:\n\\[\n\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i.\n\\]\nPer definizione, la varianza di \\(\\bar{X}\\) è:\n\\[\n\\mathbb{V}(\\bar{X}) = \\mathbb{V}\\left(\\frac{1}{n} \\sum_{i=1}^n X_i\\right).\n\\]\nPoiché una costante moltiplicata da una variabile aleatoria può essere “estratta” dalla varianza, otteniamo:\n\\[\n\\mathbb{V}(\\bar{X}) = \\frac{1}{n^2} \\mathbb{V}\\left(\\sum_{i=1}^n X_i\\right).\n\\]\nOra dobbiamo calcolare \\(\\mathbb{V}\\left(\\sum_{i=1}^n X_i\\right)\\). Le variabili \\(X_1, X_2, \\dots, X_n\\) sono indipendenti, quindi la varianza della somma è la somma delle varianze:\n\\[\n\\mathbb{V}\\left(\\sum_{i=1}^n X_i\\right) = \\sum_{i=1}^n \\mathbb{V}(X_i).\n\\]\nPoiché tutte le variabili \\(X_i\\) hanno la stessa varianza \\(\\sigma^2\\):\n\\[\n\\mathbb{V}\\left(\\sum_{i=1}^n X_i\\right) = n \\sigma^2.\n\\]\nSostituendo nella formula precedente, otteniamo:\n\\[\n\\mathbb{V}(\\bar{X}) = \\frac{1}{n^2} \\cdot n \\sigma^2 = \\frac{\\sigma^2}{n}.\n\\]\nIn generale, dunque, per un campione di ampiezza \\(n\\), vale la relazione \\(\\mathbb{V}(\\bar{X}) = \\frac{\\sigma^2}{n}\\).\n\n\n\n\n71.4.6 Proprietà della distribuzione campionaria\nInfine, osserviamo una proprietà fondamentale della distribuzione campionaria:\n\nSe la popolazione segue una distribuzione normale, allora anche la distribuzione delle medie campionarie seguirà una distribuzione normale, indipendentemente dall’ampiezza del campione.\nSe invece la popolazione non segue una distribuzione normale, il teorema del limite centrale garantisce che, all’aumentare della dimensione del campione \\(n\\), la distribuzione campionaria delle medie tenderà a una distribuzione normale.\n\nQueste proprietà sono centrali in molti metodi statistici, poiché consentono di fare inferenza sulla popolazione utilizzando campioni.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#teorema-del-limite-centrale",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#teorema-del-limite-centrale",
    "title": "71  Introduzione all’inferenza frequentista",
    "section": "\n71.5 Teorema del Limite Centrale",
    "text": "71.5 Teorema del Limite Centrale\nEsaminiamo ora più in dettaglio il Teorema del Limite Centrale (TLC). Nel 1812, Laplace dimostrò il TLC, che afferma che la somma di una sequenza di variabili casuali indipendenti tende a distribuirsi secondo una distribuzione Normale. Inoltre, il TLC stabilisce i parametri della distribuzione Normale risultante in base ai valori attesi e alle varianze delle variabili casuali sommate.\n\nTeorema 71.1 Si supponga che \\(Y = Y_1, \\dots, Y_i, \\ldots, Y_n\\) sia una sequenza di v.a. i.i.d. (variabili aleatorie identicamente distribuite e indipendenti) con \\(\\mathbb{E}(Y_i) = \\mu\\) e \\(SD(Y_i) = \\sigma\\). Si definisca una nuova variabile casuale come:\n\\[\nZ = \\frac{1}{n} \\sum_{i=1}^n Y_i.\n\\]\nCon \\(n \\rightarrow \\infty\\), \\(Z\\) tenderà a seguire una distribuzione Normale con lo stesso valore atteso di \\(Y_i\\) e una deviazione standard ridotta di un fattore pari a \\(\\frac{1}{\\sqrt{n}}\\):\n\\[\np_Z(z) \\rightarrow \\mathcal{N}\\left(z \\ \\Bigg| \\ \\mu, \\, \\frac{\\sigma}{\\sqrt{n}} \\right).\n\\]\n\nIl TLC può essere generalizzato a variabili casuali che non sono identicamente distribuite, a condizione che siano indipendenti e abbiano aspettative e varianze finite. Molti fenomeni naturali, come l’altezza degli adulti, sono il risultato di una combinazione di effetti additivi relativamente piccoli. Questi effetti, indipendentemente dalla loro distribuzione individuale, tendono a portare alla normalità della distribuzione risultante. Questa è la ragione per cui la distribuzione normale fornisce una buona approssimazione per la distribuzione di molti fenomeni naturali.\n\n71.5.1 Illustrazione del TLC\nPer dimostrare il Teorema del Limite Centrale, consideriamo una popolazione iniziale con una distribuzione fortemente asimmetrica: una distribuzione Beta con parametri \\(\\alpha = 2\\) e \\(\\beta = 1\\). Estraiamo 50.000 campioni casuali di ampiezza \\(n\\) da questa popolazione e costruiamo la distribuzione campionaria delle medie.\nDefiniamo una funzione per simulare e visualizzare la distribuzione campionaria per diversi valori di \\(n\\):\n\n# Parametri della distribuzione Beta\nalpha &lt;- 2\nbeta &lt;- 1\n\n# Funzione per simulare e visualizzare la distribuzione campionaria\nplot_samples &lt;- function(n) {\n  # Media e deviazione standard della distribuzione Beta\n  mu &lt;- alpha / (alpha + beta)\n  sigma &lt;- sqrt(alpha * beta / ((alpha + beta)^2 * (alpha + beta + 1)))\n  \n  # Generazione di 50.000 campioni casuali di dimensione n\n  sample_means &lt;- replicate(50000, mean(rbeta(n, alpha, beta)))\n  \n  # Dati per la distribuzione normale teorica\n  x &lt;- seq(mu - 3 * sigma, mu + 3 * sigma, length.out = 100)\n  y &lt;- dnorm(x, mean = mu, sd = sigma / sqrt(n))\n  \n  # Creazione del grafico\n  hist(\n    sample_means, \n    breaks = 50, \n    probability = TRUE, \n    main = paste(\"Ampiezza campionaria =\", n), \n    xlab = \"Media campionaria\", \n    ylab = \"Densità\"\n  )\n  lines(x, y, col = \"black\", lwd = 2)\n}\n\n\n71.5.2 Visualizzazione per diverse dimensioni campionarie\n\nAmpiezza campionaria \\(n = 1\\)\n\nSe \\(n = 1\\), la distribuzione campionaria delle medie coincide con la popolazione di partenza.\n\nplot_samples(1)\n\n\n\n\n\n\n\n\nAmpiezza campionaria \\(n = 2\\)\n\nPer \\(n = 2\\), la distribuzione delle medie dei campioni inizia ad avvicinarsi alla normalità.\n\nplot_samples(2)\n\n\n\n\n\n\n\n\nAmpiezza campionaria \\(n = 4\\)\n\nPer \\(n = 4\\), l’approssimazione alla distribuzione normale migliora.\n\nplot_samples(4)\n\n\n\n\n\n\n\n\nAmpiezza campionaria \\(n = 30\\)\n\nPer \\(n = 30\\), la distribuzione campionaria delle medie è ben approssimata dalla normale.\n\nplot_samples(30)\n\n\n\n\n\n\n\nIn conclusione, il Teorema del Limite Centrale (TLC) afferma che, indipendentemente dalla forma della distribuzione della popolazione:\n\nPer campioni di dimensione sufficiente, la distribuzione campionaria delle medie \\(\\bar{X}\\) tende a una distribuzione normale.\n\nLa media \\(\\mu\\) e la deviazione standard \\(\\sigma\\) della popolazione determinano la distribuzione delle medie campionarie come segue:\n\\[\n\\bar{X} \\sim \\mathcal{N}(\\mu, \\sigma / \\sqrt{n}),\n\\]\ndove \\(n\\) è l’ampiezza del campione.\n\n\nQuesta proprietà ha implicazioni fondamentali:\n\nLa normalità emergente giustifica l’uso della distribuzione normale anche quando i dati non sono inizialmente normali.\nIl TLC fornisce una formula esplicita per calcolare l’errore standard \\(\\sigma / \\sqrt{n}\\), che quantifica la precisione della media campionaria come stima della media della popolazione.\n\n71.5.3 Applicazioni in psicologia\nMolti fenomeni psicologici che misuriamo (ad esempio, il QI come media di molte abilità cognitive) derivano dalla media di più variabili, e quindi seguono la distribuzione normale grazie al TLC. Questo spiega perché la distribuzione normale appare così frequentemente nei dati sperimentali di psicologia e in molte altre discipline scientifiche.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#distribuzioni-campionarie-di-altre-statistiche",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#distribuzioni-campionarie-di-altre-statistiche",
    "title": "71  Introduzione all’inferenza frequentista",
    "section": "\n71.6 Distribuzioni campionarie di altre statistiche",
    "text": "71.6 Distribuzioni campionarie di altre statistiche\nAbbiamo già analizzato la distribuzione campionaria della media dei campioni. Tuttavia, è possibile costruire distribuzioni campionarie per altre statistiche campionarie. Ad esempio, consideriamo la distribuzione campionaria del valore massimo e della varianza.\n\n71.6.1 Distribuzione campionaria del valore massimo\nSupponiamo di avere una popolazione normalmente distribuita con media \\(\\mu = 100\\) e deviazione standard \\(\\sigma = 15\\). Generiamo 10.000 campioni casuali di ampiezza \\(n = 5\\) e calcoliamo il valore massimo per ogni campione.\n\n71.6.1.1 Simulazione e visualizzazione\n\nset.seed(123)  # Per risultati riproducibili\n\n# Parametri della distribuzione\nmu &lt;- 100\nsigma &lt;- 15\n\n# Simulazione: calcolo del valore massimo per ciascun campione\nn_samples &lt;- 10000\nsample_maxes &lt;- replicate(\n  n_samples, \n  max(rnorm(5, mean = mu, sd = sigma))\n)\n\n# Istogramma della distribuzione campionaria del valore massimo\nhist(\n  sample_maxes, \n  breaks = 50, \n  probability = TRUE, \n  main = \"Distribuzione campionaria del valore massimo\",\n  xlab = \"Valore massimo\", \n  ylab = \"Densità\"\n)\n\n# Sovrapposizione della distribuzione normale della popolazione\ncurve(dnorm(x, mean = mu, sd = sigma), add = TRUE, col = \"black\", lwd = 2)\n\n\n\n\n\n\n\nOsserviamo che il valore atteso della distribuzione campionaria del massimo è maggiore della media della popolazione \\(\\mu\\).\n\n71.6.2 Distribuzione campionaria della varianza\nUn’altra statistica interessante è la varianza campionaria. La formula della varianza campionaria, basata sulla statistica descrittiva, è:\n\\[\nS^2 = \\frac{\\sum_{i=1}^n (Y_i - \\bar{Y})^2}{n}.\n\\]\nCalcoliamo la distribuzione campionaria della varianza per campioni di ampiezza \\(n = 5\\).\n\n71.6.2.1 Simulazione e visualizzazione\n\nset.seed(123)\n\n# Simulazione: calcolo della varianza per ciascun campione\nsample_vars &lt;- replicate(\n  n_samples, \n  variance(rnorm(5, mean = mu, sd = sigma))\n)\n\n# Istogramma della distribuzione campionaria della varianza\nhist(\n  sample_vars, \n  breaks = 50, \n  probability = TRUE, \n  main = \"Distribuzione campionaria della varianza\",\n  xlab = \"Varianza\", ylab = \"Densità\"\n)\n\n\n\n\n\n\n\n\n# Media empirica della varianza campionaria\nmean(sample_vars)\n#&gt; [1] 181\n\nSappiamo che la varianza della popolazione è \\(\\sigma^2 = 15^2 = 225\\). Tuttavia, il valore medio empirico delle varianze campionarie calcolate con \\(S^2\\) risulta minore di 225. Questo avviene perché lo stimatore \\(S^2\\) è distorto.\n\n71.6.3 Correzione della distorsione\nPer eliminare la distorsione, utilizziamo il seguente stimatore della varianza della popolazione:\n\\[\ns^2 = \\frac{\\sum_{i=1}^n (Y_i - \\bar{Y})^2}{n-1}.\n\\]\n\n71.6.3.1 Verifica con simulazione\n\nset.seed(123)\n\n# Simulazione: calcolo della varianza con la correzione\nsample_vars_unbiased &lt;- replicate(\n  n_samples, \n  var(rnorm(5, mean = mu, sd = sigma))\n)\n\n# Istogramma della distribuzione campionaria della varianza corretta\nhist(\n  sample_vars_unbiased, \n  breaks = 50, \n  probability = TRUE, \n  main = \"Distribuzione campionaria della varianza (corretta)\",\n  xlab = \"Varianza\", \n  ylab = \"Densità\"\n)\n\n\n\n\n\n\n\n\n# Media empirica della varianza corretta\nmean(sample_vars_unbiased)\n#&gt; [1] 226\n\nCon questo stimatore, la media della distribuzione campionaria coincide con la varianza reale della popolazione \\(\\sigma^2 = 225\\).\nIn conclusione:\n\nLa distribuzione campionaria del massimo mostra che il valore massimo dei campioni è, in media, maggiore della media della popolazione.\nLa varianza campionaria non corretta (\\(S^2\\)) è uno stimatore distorto, poiché il suo valore atteso non coincide con la varianza della popolazione.\nLo stimatore corretto \\(s^2\\), che utilizza il divisore \\(n - 1\\), elimina la distorsione e fornisce una stima non distorta della varianza della popolazione.\n\nIn generale, uno stimatore è considerato non distorto quando il valore atteso delle sue stime coincide con il valore reale del parametro. Nel caso della media campionaria e della varianza corretta, entrambi gli stimatori sono non distorti.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#riflessioni-conclusive",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#riflessioni-conclusive",
    "title": "71  Introduzione all’inferenza frequentista",
    "section": "\n71.7 Riflessioni Conclusive",
    "text": "71.7 Riflessioni Conclusive\nIn generale, i parametri della popolazione sono sconosciuti, ma possiamo stimarli utilizzando le informazioni del campione. Di seguito viene presentata una tabella che riassume i simboli comuni utilizzati per indicare le quantità note e sconosciute nel contesto dell’inferenza statistica. Questo ci aiuterà a tenere traccia di ciò che sappiamo e ciò che non sappiamo.\n\n\n\n\n\n\n\nSimbolo\nNome\nÈ qualcosa che conosciamo?\n\n\n\n\\(s\\)\nDeviazione standard del campione\nSì, la calcoliamo dai dati grezzi\n\n\n\\(\\sigma\\)\nDeviazione standard della popolazione\nNo, tranne in casi particolari o nelle simulazioni\n\n\n\\(\\hat{\\sigma}\\)\nStima della deviazione standard della popolazione\nSì, ma non è uguale a \\(\\sigma\\)\n\n\n\n\\(s^2\\)\nVarianza del campione\nSì, la calcoliamo dai dati grezzi\n\n\n\\(\\sigma^2\\)\nVarianza della popolazione\nNo, tranne in casi particolari o nelle simulazioni\n\n\n\\(\\hat{\\sigma}^2\\)\nStima della varianza della popolazione\nSì, ma non è uguale a \\(\\sigma^2\\)\n\n\n\n\n\nUtilizzando le informazioni di un campione casuale di ampiezza \\(n\\):\n\nLa stima migliore che possiamo ottenere per la media \\(\\mu\\) della popolazione è la media del campione \\(\\bar{Y}\\).\nLa stima migliore che possiamo ottenere per la varianza \\(\\sigma^2\\) della popolazione è:\n\n\\[\n\\hat{\\sigma}^2 = \\frac{1}{n-1} \\sum_{i=1}^n (Y_i - \\bar{Y})^2.\n\\]",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#informazioni-sullambiente-di-sviluppo",
    "title": "71  Introduzione all’inferenza frequentista",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] see_0.9.0        gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1\n#&gt;  [5] psych_2.4.12     scales_1.3.0     markdown_1.13    knitr_1.49      \n#&gt;  [9] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [13] purrr_1.0.2      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [17] ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.3         rlang_1.1.4       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       yaml_2.3.10       tools_4.4.2       parallel_4.4.2   \n#&gt; [21] tzdb_0.4.0        colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5      \n#&gt; [25] R6_2.5.1          lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3  \n#&gt; [29] pillar_1.10.0     gtable_0.3.6      glue_1.8.0        xfun_0.49        \n#&gt; [33] tidyselect_1.2.1  farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-166     \n#&gt; [37] rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#bibliografia",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#bibliografia",
    "title": "71  Introduzione all’inferenza frequentista",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nChivers, T. (2024). Everything is Predictable: How Bayesian Statistics Explain Our World. Simon; Schuster.\n\n\nJaynes, E. T. (2003). Probability theory: The logic of science. Cambridge University Press.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html",
    "href": "chapters/frequentist_inference/02_conf_interv.html",
    "title": "72  Intervalli di fiducia",
    "section": "",
    "text": "72.1 Introduzione\nGli intervalli di confidenza sono uno strumento fondamentale nell’inferenza statistica frequentista. Essi consentono di stimare un parametro sconosciuto di una popolazione, come la media \\(\\mu\\), tenendo conto dell’incertezza derivante dal fatto che la stima si basa su un campione. Questo materiale didattico si propone di spiegare in modo dettagliato e chiaro la costruzione di un intervallo di confidenza per la media di una popolazione, sia nel caso di varianza nota sia in quello di varianza incognita.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#inferenza-statistica-frequentista-e-media-campionaria",
    "href": "chapters/frequentist_inference/02_conf_interv.html#inferenza-statistica-frequentista-e-media-campionaria",
    "title": "72  Intervalli di fiducia",
    "section": "\n72.2 Inferenza Statistica Frequentista e Media Campionaria",
    "text": "72.2 Inferenza Statistica Frequentista e Media Campionaria\nQuando estraiamo un campione casuale semplice \\(X_1, X_2, \\dots, X_n\\) da una popolazione con media \\(\\mu\\) e varianza \\(\\sigma^2\\), la media campionaria \\(\\bar{X}\\) è definita come:\n\\[\n\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i.\n\\]\nLa media campionaria \\(\\bar{X}\\) è una variabile casuale perché dipende dai valori osservati nel campione, che sono essi stessi casuali. Le proprietà della media campionaria sono le seguenti:\n\n\nMedia della distribuzione campionaria: \\(E[\\bar{X}] = \\mu\\). La media campionaria è uno stimatore non distorto della media della popolazione.\n\nVarianza della distribuzione campionaria: \\(\\text{Var}(\\bar{X}) = \\frac{\\sigma^2}{n}\\). Questo significa che la precisione di \\(\\bar{X}\\) come stima di \\(\\mu\\) aumenta con il numero di osservazioni \\(n\\).\n\nQueste proprietà sono fondamentali per calcolare un intervallo di confidenza, poiché ci permettono di descrivere la distribuzione di \\(\\bar{X}\\).",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#intervallo-di-confidenza-per-la-media-caso-di-varianza-nota",
    "href": "chapters/frequentist_inference/02_conf_interv.html#intervallo-di-confidenza-per-la-media-caso-di-varianza-nota",
    "title": "72  Intervalli di fiducia",
    "section": "\n72.3 Intervallo di Confidenza per la Media: Caso di Varianza Nota",
    "text": "72.3 Intervallo di Confidenza per la Media: Caso di Varianza Nota\nSupponiamo che la popolazione sia distribuita normalmente con media \\(\\mu\\) e varianza \\(\\sigma^2\\), e che \\(\\sigma^2\\) sia nota. La distribuzione della media campionaria \\(\\bar{X}\\) è anch’essa normale:\n\\[\n\\bar{X} \\sim \\mathcal{N}\\left(\\mu, \\frac{\\sigma^2}{n}\\right).\n\\]\n\n72.3.1 Passo 1: Standardizzazione della Media Campionaria\nPer lavorare con una distribuzione normale standard (media 0 e varianza 1), standardizziamo \\(\\bar{X}\\) utilizzando la formula:\n\\[\nZ = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}}.\n\\]\nQui, \\(\\sigma / \\sqrt{n}\\) è la deviazione standard della distribuzione campionaria di \\(\\bar{X}\\).\nDopo questa trasformazione, la variabile \\(Z\\) segue una distribuzione normale standard:\n\\[\nZ \\sim \\mathcal{N}(0, 1).\n\\]\n\n72.3.2 Passo 2: Determinazione del Livello di Confidenza\nScegliamo un livello di confidenza \\(\\gamma\\), ad esempio \\(\\gamma = 0.95\\). Per una distribuzione normale standard, troviamo il valore critico \\(z\\) tale che la probabilità tra \\(-z\\) e \\(+z\\) sia pari al livello di confidenza:\n\\[\nP(-z \\leq Z \\leq z) = \\gamma.\n\\]\nPer un livello di confidenza del 95%, \\(z \\approx 1.96\\).\n\n72.3.3 Passo 3: Formulazione dell’Intervallo di Confidenza\nPartiamo dalla probabilità per \\(Z\\):\n\\[\nP(-z \\leq Z \\leq z) = \\gamma.\n\\]\nSostituiamo la definizione di \\(Z\\):\n\\[\nP\\left(-z \\leq \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}} \\leq z\\right) = \\gamma.\n\\]\nMoltiplichiamo tutti i membri per \\(\\sigma / \\sqrt{n}\\) per rimuovere il denominatore:\n\\[\nP\\left(-z \\cdot \\frac{\\sigma}{\\sqrt{n}} \\leq \\bar{X} - \\mu \\leq z \\cdot \\frac{\\sigma}{\\sqrt{n}}\\right) = \\gamma.\n\\]\nAggiungiamo \\(\\mu\\) a tutti i membri per isolare \\(\\mu\\):\n\\[\nP\\left(\\bar{X} - z \\cdot \\frac{\\sigma}{\\sqrt{n}} \\leq \\mu \\leq \\bar{X} + z \\cdot \\frac{\\sigma}{\\sqrt{n}}\\right) = \\gamma.\n\\]\n\n72.3.4 Passo 4: Limiti dell’Intervallo di Confidenza\nDefiniamo i limiti inferiore e superiore dell’intervallo di confidenza:\n\\[\n\\hat{a} = \\bar{X} - z \\cdot \\frac{\\sigma}{\\sqrt{n}}, \\quad \\hat{b} = \\bar{X} + z \\cdot \\frac{\\sigma}{\\sqrt{n}}.\n\\]\nL’intervallo di confidenza per \\(\\mu\\) è quindi:\n\\[\n(\\hat{a}, \\hat{b}) = \\left(\\bar{X} - z \\cdot \\frac{\\sigma}{\\sqrt{n}}, \\bar{X} + z \\cdot \\frac{\\sigma}{\\sqrt{n}}\\right).\n\\]",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#intervallo-di-confidenza-per-la-media-caso-di-varianza-incognita",
    "href": "chapters/frequentist_inference/02_conf_interv.html#intervallo-di-confidenza-per-la-media-caso-di-varianza-incognita",
    "title": "72  Intervalli di fiducia",
    "section": "\n72.4 Intervallo di Confidenza per la Media: Caso di Varianza Incognita",
    "text": "72.4 Intervallo di Confidenza per la Media: Caso di Varianza Incognita\nNella maggior parte dei casi pratici, la varianza \\(\\sigma^2\\) non è nota. In questi casi, stimiamo \\(\\sigma\\) con la deviazione standard campionaria \\(s\\) e utilizziamo la distribuzione t di Student, che tiene conto dell’incertezza aggiuntiva.\n\n72.4.1 Passo 1: Distribuzione t di Student\nLa statistica che seguiamo è:\n\\[\nT = \\frac{\\bar{X} - \\mu}{s / \\sqrt{n}},\n\\]\ndove \\(T\\) segue una distribuzione t con \\(n-1\\) gradi di libertà.\n\n72.4.2 Passo 2: Costruzione dell’Intervallo di Confidenza\nAnalogamente al caso precedente, costruiamo l’intervallo partendo da:\n\\[\nP(-t^\\ast \\leq T \\leq t^\\ast) = \\gamma,\n\\]\ndove \\(t^\\ast\\) è il valore critico della distribuzione t per il livello di confidenza \\(\\gamma\\) e \\(n-1\\) gradi di libertà.\nSostituendo \\(T\\):\n\\[\nP\\left(-t^\\ast \\leq \\frac{\\bar{X} - \\mu}{s / \\sqrt{n}} \\leq t^\\ast\\right) = \\gamma.\n\\]\nMoltiplichiamo per \\(s / \\sqrt{n}\\):\n\\[\nP\\left(-t^\\ast \\cdot \\frac{s}{\\sqrt{n}} \\leq \\bar{X} - \\mu \\leq t^\\ast \\cdot \\frac{s}{\\sqrt{n}}\\right) = \\gamma.\n\\]\nAggiungiamo \\(\\mu\\):\n\\[\nP\\left(\\bar{X} - t^\\ast \\cdot \\frac{s}{\\sqrt{n}} \\leq \\mu \\leq \\bar{X} + t^\\ast \\cdot \\frac{s}{\\sqrt{n}}\\right) = \\gamma.\n\\]\n\n72.4.3 Passo 3: Limiti dell’Intervallo\nI limiti dell’intervallo sono:\n\\[\n\\hat{a} = \\bar{X} - t^\\ast \\cdot \\frac{s}{\\sqrt{n}}, \\quad \\hat{b} = \\bar{X} + t^\\ast \\cdot \\frac{s}{\\sqrt{n}}.\n\\]\nIn conclusione, gli intervalli di confidenza forniscono un modo per quantificare l’incertezza nelle stime di parametri sconosciuti. La loro costruzione dipende dalla distribuzione campionaria dello stimatore e dall’informazione disponibile sulla varianza.\n\n72.4.4 Applicabilità e Limitazioni\n\nIl metodo presuppone che la popolazione segua una distribuzione normale e è valido anche per campioni di piccole dimensioni (ad esempio, \\(n &lt; 30\\)) prelevati da tale popolazione.\nSe la popolazione non è normalmente distribuita e la dimensione del campione è ridotta, questo metodo potrebbe non essere idoneo.\nTuttavia, per campioni di grandi dimensioni (\\(n \\geq 30\\)), questo approccio rimane valido per la stima dell’intervallo di confidenza grazie al teorema del limite centrale, che si applica anche a popolazioni con distribuzioni non normali.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#livello-di-copertura",
    "href": "chapters/frequentist_inference/02_conf_interv.html#livello-di-copertura",
    "title": "72  Intervalli di fiducia",
    "section": "\n72.5 Livello di Copertura",
    "text": "72.5 Livello di Copertura\nPer interpretare correttamente gli intervalli di fiducia è fondamentale considerare il concetto di “livello di copertura”. Questo livello indica la frequenza con cui l’intervallo di fiducia include il valore reale del parametro della popolazione, in una serie di esperimenti ripetuti.\nEsempio di Livello di Copertura:\n\nSe il livello di copertura è del 95%, significa che, nel lungo periodo, il 95% degli intervalli di fiducia costruiti conterrà il valore vero del parametro.\nImportante: Questo non implica che ci sia una probabilità del 95% che il valore vero del parametro cada in un particolare intervallo di fiducia. Infatti, il parametro della popolazione è un valore fisso e non soggetto a probabilità; piuttosto, l’incertezza risiede nell’intervallo di fiducia stesso.\n\nCome Funziona la Copertura:\n\nNel contesto frequentista, la “probabilità” si riferisce alla frequenza a lungo termine di un certo evento in un gran numero di ripetizioni dell’esperimento.\nNel caso degli intervalli di fiducia, l’“esperimento” è l’estrazione di un campione dalla popolazione, e l’“evento” è la generazione di un intervallo di fiducia che contiene il valore vero del parametro.\nIl livello di copertura, generalmente indicato come \\(1-\\alpha\\), rappresenta la probabilità a lungo termine che intervalli di fiducia costruiti con questa metodologia includano il vero valore del parametro.\n\n\n72.5.1 Simulazione\n\nPer illustrare questo concetto, eseguiamo una simulazione con la popolazione degli adulti maschi italiani, assunta come normalmente distribuita con media 175 cm e varianza 49 cm².\nEseguiamo 1000 ripetizioni di un esperimento, estraendo ogni volta un campione di 30 individui.\nPer ciascun campione, calcoliamo l’intervallo di fiducia al 95% usando la formula:\n\n\\[\n\\bar{X} \\pm t \\frac{s}{\\sqrt{n}},\n\\]\ndove \\(\\bar{X}\\) è la media campionaria, \\(s\\) è la deviazione standard campionaria e \\(t\\) è il valore critico della distribuzione t-Student per \\(n-1\\) gradi di libertà al livello di significatività \\(\\alpha/2 = 0.025\\). - Registriamo i limiti di ciascun intervallo e controlliamo quanti di essi includono effettivamente il vero valore medio della popolazione.\nAttraverso questa simulazione, possiamo visualizzare concretamente il concetto di livello di copertura e la sua importanza nella statistica frequentista.\nIn questa simulazione, genereremo 1000 campioni casuali di dimensione \\(n = 30\\) da una distribuzione normale con media \\(\\mu = 175\\) e deviazione standard \\(\\sigma = 7\\). Successivamente, calcoleremo gli intervalli di confidenza al 95% per ciascun campione e valuteremo il livello di copertura.\n\nset.seed(123)  # Per riproducibilità\n\n# Parametri della distribuzione\nmu &lt;- 175\nsigma &lt;- 7\nn &lt;- 30\nn_samples &lt;- 1000\n\n# Generazione dei campioni\nsamples &lt;- replicate(n_samples, rnorm(n, mean = mu, sd = sigma))\ndim(samples)  # Verifica dimensioni: 30 righe per 1000 colonne\n#&gt; [1]   30 1000\n\nIl primo campione di ampiezza \\(n = 30\\) che abbiamo ottenuto è il seguente:\n\nsamples[, 1]  # Primo campione\n#&gt;  [1] 171 173 186 175 176 187 178 166 170 172 184 178 178 176 171 188 178 161\n#&gt; [19] 180 172 168 173 168 170 171 163 181 176 167 184\n\nStampiamo le medie dei primi dieci campioni:\n\nsample_means &lt;- colMeans(samples)  # Medie di tutti i campioni\nsample_means[1:10]  # Prime dieci medie\n#&gt;  [1] 175 176 175 174 174 176 175 174 175 177\n\nTroviamo il valore critico della distribuzione \\(t\\) di Student con \\(n - 1\\) gradi di libertà e livello di confidenza del 95% (\\(\\alpha = 0.05\\)):\n\nalpha &lt;- 0.05\nt_critical &lt;- qt(1 - alpha / 2, df = n - 1)  # Valore critico\nt_critical\n#&gt; [1] 2.05\n\nUtilizzando il valore critico \\(t\\), calcoliamo 1000 intervalli di confidenza per la media della popolazione:\n\n# Calcolo della deviazione standard campionaria\nsample_sds &lt;- apply(samples, 2, sd)\n\n# Ampiezza degli intervalli\ninterval_width &lt;- t_critical * sample_sds / sqrt(n)\n\n# Limiti degli intervalli di confidenza\nCI_low &lt;- sample_means - interval_width\nCI_high &lt;- sample_means + interval_width\n\nTroviamo il livello di copertura, ovvero la proporzione di intervalli di confidenza che contengono il vero valore della media della popolazione \\(\\mu\\):\n\ncoverage &lt;- mean(CI_low &lt; mu & mu &lt; CI_high)  # Proporzione di copertura\ncoverage\n#&gt; [1] 0.956\n\nIn conclusione, ripetendo la simulazione per 1000 campioni, abbiamo ottenuto un livello di copertura molto vicino al valore nominale di \\(1 - \\alpha = 0.95\\). Questo risultato dimostra che, con un campione di dimensione \\(n = 30\\), gli intervalli di confidenza al 95% calcolati utilizzando la distribuzione \\(t\\) di Student forniscono stime accurate della media della popolazione.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#il-concetto-di-livello-di-confidenza",
    "href": "chapters/frequentist_inference/02_conf_interv.html#il-concetto-di-livello-di-confidenza",
    "title": "72  Intervalli di fiducia",
    "section": "\n72.6 Il Concetto di Livello di Confidenza",
    "text": "72.6 Il Concetto di Livello di Confidenza\nGli intervalli di confidenza sono range di valori che, con una certa sicurezza statistica, si ritiene includano il parametro di interesse.\nSecondo l’approccio frequentista, l’intervallo di confidenza si deve considerare come una metodologia:\n\nSe ripetiamo l’esperimento (estrarre un campione e calcolare l’intervallo di confidenza) molte volte, il metodo produce un intervallo che coprirà il valore vero del parametro nel 95% dei casi, assumendo un livello di confidenza del 95%.\n\n\n72.6.1 Un Malinteso Comune nell’Interpretazione degli Intervalli di Confidenza\nÈ inesatto affermare che un determinato intervallo di confidenza contenga il valore vero di un parametro con una probabilità del 95%. Questo è un errore diffuso, persino tra i ricercatori, che spesso interpretano l’intervallo di confidenza come indicativo della probabilità che il parametro (ad esempio, la media della popolazione \\(\\mu\\)) si trovi effettivamente all’interno di un dato intervallo (es. \\([\\hat{a}, \\hat{b}]\\)).\nLa descrizione corretta è la seguente:\n\n“La metodologia impiegata per calcolare l’intervallo \\([\\hat{a}, \\hat{b}]\\) ha il 95% di probabilità di generare un intervallo che include il vero valore del parametro”.\nCiò significa che l’intervallo di confidenza non esprime una probabilità circa la posizione precisa del parametro, ma riflette la probabilità che la procedura adottata per determinarlo generi un intervallo che lo includa.\n\nIn conclusione, l’intervallo di confidenza ci fornisce una garanzia statistica riguardo alla affidabilità del metodo usato per la sua stima, piuttosto che sulla esatta ubicazione del parametro in questione.\n\n72.6.2 Fraintendimenti Comuni sugli Intervalli di Confidenza\nNel loro lavoro, Hoekstra et al. (2014) evidenziano come, nonostante l’ampio riconoscimento dei limiti dei test di ipotesi nulle, gli intervalli di confidenza siano spesso consigliati per l’inferenza statistica. Anche l’American Psychological Association (APA) suggerisce che gli intervalli di confidenza siano “in generale, la migliore strategia di reportistica”. Tuttavia, Hoekstra et al. (2014) sottolineano che queste raccomandazioni non considerano la difficoltà nel fornire una corretta interpretazione degli intervalli di confidenza.\nPer indagare l’interpretazione degli intervalli di confidenza, Hoekstra et al. (2014) hanno condotto uno studio con due domande principali:\n\nQuanto frequentemente intervalli di confidenza sono mal interpretati da studenti e ricercatori?\nL’esperienza nella ricerca riduce le interpretazioni errate degli intervalli di confidenza?\n\nPrima di presentare lo studio, {cite}hoekstra2014robust ricordano qual è l’interpretazione corretta degli intervalli di confidenza.\n\nA CI is a numerical interval constructed around the estimate of a parameter. Such an interval does not, however, directly indicate a property of the parameter; instead, it indicates a property of the procedure, as is typical for a frequentist technique. Specifically, we may find that a particular procedure, when used repeatedly across a series of hypothetical data sets (i.e., the sample space), yields intervals that contain the true parameter value in 95% of the cases. When such a procedure is applied to a particular data set, the resulting interval is said to be a 95% CI. The key point is that the CIs do not provide for a statement about the parameter as it relates to the particular sample at hand; instead, they provide for a statement about the performance of the procedure of drawing such intervals in repeated use. Hence, it is incorrect to interpret a CI as the probability that the true value is within the interval (e.g., Berger & Wolpert, 1988). As is the case with \\(p\\)-values, CIs do not allow one to make probability statements about parameters or hypotheses.\n\nNel loro studio, Hoekstra et al. (2014) hanno presentato un questionario a 596 partecipanti, tra cui studenti universitari e ricercatori, con le seguenti affermazioni riguardanti l’interpretazione degli intervalli di confidenza.\n\nProfessor Bumbledorf conducts an experiment, analyzes the data, and reports: “The 95% confidence interval for the mean ranges from 0.1 to 0.4.” Please mark each of the statements below as ‘true’ or ‘false’.\n\n\n\nThe probability that the true mean is greater than 0 is at least 95%.\nThe probability that the true mean equals 0 is smaller than 5%.\nThe “null hypothesis” that the true mean equals 0 is likely to be incorrect.\nThere is a 95% probability that the true mean lies between 0.1 and 0.4.\nWe can be 95% confident that the true mean lies between 0.1 and 0.4.\nIf we were to repeat the experiment over and over, then 95% of the time the true mean falls between 0.1 and 0.4.\n\n\nSorprendentemente, anche se tutte le sei affermazioni nel questionario sono errate, molti partecipanti hanno concordato con esse. I risultati mostrano che, in media, i partecipanti hanno concordato con circa 3.5 affermazioni errate su 6. Non è stata rilevata una differenza di rilievo nell’interpretazione degli intervalli di confidenza tra studenti e ricercatori, suggerendo che l’esperienza nella ricerca non migliora la comprensione di questo concetto.\nI risultati indicano che molte persone interpretano erroneamente gli intervalli di confidenza, e che anche l’esperienza nella ricerca non garantisce una migliore comprensione. Questo solleva dubbi sull’efficacia degli intervalli di confidenza frequentisti e suggerisce che gli “intervalli di credibilità” bayesiani possano rappresentare un’alternativa più vantaggiosa. Quest’ultimi tendono ad essere più intuitivi e di più facile interpretazione corretta.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#confronto-tra-intervalli-frequentisti-e-bayesiani",
    "href": "chapters/frequentist_inference/02_conf_interv.html#confronto-tra-intervalli-frequentisti-e-bayesiani",
    "title": "72  Intervalli di fiducia",
    "section": "\n72.7 Confronto tra Intervalli Frequentisti e Bayesiani",
    "text": "72.7 Confronto tra Intervalli Frequentisti e Bayesiani\nConcludiamo questo capitolo esaminando le differenze tra l’intervallo di confidenza frequentista e l’intervallo di credibilità bayesiano, utilizzando lo stesso set di dati per entrambi i calcoli.\n\n72.7.1 Intervallo di confidenza frequentista\nImmaginiamo di avere un gruppo di 20 osservazioni relative alla performance in un test cognitivo. Il nostro obiettivo è stimare la media della popolazione da cui queste osservazioni sono tratte. Supponiamo che i dati provengano da una distribuzione normale con media \\(\\mu = 50\\) e deviazione standard \\(\\sigma = 10\\).\n\nset.seed(123)  # Per risultati riproducibili\n\n# Parametri della popolazione\nsample_size &lt;- 20\nmu &lt;- 50\nsigma &lt;- 10\n\n# Simulazione del campione\nsample_data &lt;- rnorm(sample_size, mean = mu, sd = sigma)\nprint(sample_data)\n#&gt;  [1] 44.4 47.7 65.6 50.7 51.3 67.2 54.6 37.3 43.1 45.5 62.2 53.6 54.0 51.1\n#&gt; [15] 44.4 67.9 55.0 30.3 57.0 45.3\n\nVisualizziamo la distribuzione dei dati:\n\nhist(\n  sample_data, \n  probability = TRUE, \n  main = \"Distribuzione dei dati campionari\", \n  xlab = \"Valori\", \n  ylab = \"Densità\"\n)\n\n\n\n\n\n\n\nLa media campionaria (\\(\\hat{\\mu}\\)) viene calcolata come:\n\\[\n\\hat{\\mu} = \\frac{1}{n} \\sum_{i=1}^n X_i\n\\]\nIn R:\n\nsample_mean &lt;- mean(sample_data)\nsample_mean\n#&gt; [1] 51.4\n\nLa deviazione standard campionaria (\\(s\\)) si calcola come:\n\\[\ns = \\sqrt{\\frac{\\sum_{i=1}^n (X_i - \\bar{X})^2}{n-1}}\n\\]\nIn R:\n\nvariance &lt;- function(x) {\n  sum((x - mean(x))^2) / length(x)\n}\n\nsample_sd &lt;- sqrt(variance(sample_data))  # Deviazione standard campionaria\nsample_sd\n#&gt; [1] 9.48\n\nL’errore standard della media (\\(SE\\)) è:\n\\[\nSE = \\frac{s}{\\sqrt{n}}\n\\]\nIn R:\n\nstandard_error &lt;- sample_sd / sqrt(sample_size)\nstandard_error\n#&gt; [1] 2.12\n\nUn intervallo di confidenza è definito come:\n\\[\n\\bar{X} \\pm t_{\\text{critico}} \\cdot SE\n\\]\ndove \\(t_{\\text{critico}}\\) è il valore critico della distribuzione \\(t\\) di Student per un livello di confidenza del 95% (\\(\\alpha = 0.05\\)) e \\(n-1\\) gradi di libertà. In R:\n\nalpha &lt;- 0.05\ndf &lt;- sample_size - 1\nt_critical &lt;- qt(1 - alpha / 2, df)\nt_critical\n#&gt; [1] 2.09\n\nCalcoliamo il margine di errore:\n\nmargin_of_error &lt;- t_critical * standard_error\nmargin_of_error\n#&gt; [1] 4.44\n\nCalcoliamo i limiti inferiore e superiore dell’intervallo di confidenza:\n\nconfidence_interval &lt;- \n  c(sample_mean - margin_of_error, sample_mean + margin_of_error)\nconfidence_interval\n#&gt; [1] 47.0 55.9\n\nPossiamo interpretare questo risultato dicendo che la procedura utilizzata per calcolare l’intervallo include il valore vero della media della popolazione nel 95% dei casi.\nCreiamo un grafico per mostrare la distribuzione dei dati, la media campionaria e l’intervallo di confidenza:\n\nhist(\n  sample_data, \n  probability = TRUE, \n  main = \"Intervallo di Confidenza per la Media\", \n  xlab = \"Valori\", \n  ylab = \"Densità\"\n)\nabline(v = sample_mean, col = \"blue\", lwd = 2, lty = 2)  # Media campionaria\nabline(v = confidence_interval, col = \"darkgreen\", lwd = 2)  # Limiti dell'intervallo\nlegend(\n  \"topright\", \n  legend = c(\"Media campionaria\", \"Intervallo di Confidenza\"),\n  col = c(\"blue\", \"darkgreen\"), \n  lty = c(2, 1), \n  lwd = 2\n)\n\n\n\n\n\n\n\n\n72.7.2 Intervallo di Credibilità Bayesiano\nPer determinare l’intervallo di credibilità bayesiano, utilizziamo un modello Bayesiano che assume una distribuzione normale per i dati osservati. Le distribuzioni a priori sono scelte in modo da riflettere una conoscenza preliminare debolmente informativa:\n\n\nDistribuzione a priori di \\(\\mu\\): Normale centrata su \\(\\mu_0 = 0\\) con deviazione standard ampia (\\(\\sigma_0 = 200\\)).\n\nDistribuzione a priori di \\(\\sigma\\): Normale troncata positiva (\\(\\text{HalfNormal}\\)) con deviazione standard di 100.\n\nQueste scelte sono progettate per minimizzare l’introduzione di bias, mantenendo l’analisi conservativa.\nL’intervallo di credibilità calcolato fornisce una gamma di valori entro cui si trova il parametro \\(\\mu\\) con un grado di credenza del 95%, date le informazioni a priori e i dati osservati.\n\n72.7.3 Confronto tra i Due Approcci\nIntervallo di Credibilità Bayesiano:\n\nRappresenta il grado di credenza (posteriori) che il parametro \\(\\mu\\) si trovi all’interno dell’intervallo calcolato.\nDipende sia dai dati osservati sia dalle distribuzioni a priori utilizzate nel modello, che possono influenzare il risultato in base alla loro specificità o vaghezza.\n\nIntervallo di Confidenza Frequentista:\n\nNon esprime la probabilità che il parametro \\(\\mu\\) appartenga a un determinato intervallo.\nSi riferisce invece alla procedura di costruzione dell’intervallo: se il campionamento fosse ripetuto infinite volte, il 95% degli intervalli costruiti conterrebbe il vero valore di \\(\\mu\\).\n\nIn sintesi:\n\nL’intervallo di credibilità bayesiano fornisce una stima probabilistica diretta e interpretabile della posizione di \\(\\mu\\), basata su dati osservati e informazioni a priori.\nL’intervallo di confidenza frequentista, invece, valuta la affidabilità della procedura nel lungo termine, senza fare affermazioni dirette sulla probabilità che il parametro rientri nell’intervallo specifico.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#riflessioni-conclusive",
    "href": "chapters/frequentist_inference/02_conf_interv.html#riflessioni-conclusive",
    "title": "72  Intervalli di fiducia",
    "section": "\n72.8 Riflessioni Conclusive",
    "text": "72.8 Riflessioni Conclusive\nCome sottolineato da Hoekstra et al. (2014), è comune riscontrare fraintendimenti riguardo agli intervalli di fiducia. Il “livello di confidenza del 95%” è da interpretarsi come la probabilità a lungo termine che, in una serie di intervalli di fiducia calcolati, il 95% di essi includa il vero valore del parametro sconosciuto. Tuttavia, per un singolo intervallo di fiducia, non è possibile dichiarare con sicurezza che questo contenga effettivamente il parametro di interesse. In altre parole, la certezza sulla presenza del parametro sconosciuto all’interno di un dato intervallo di fiducia non è garantita per ogni singolo caso analizzato.\nÈ inoltre inesatto presumere che esista un legame diretto tra la varianza e la media di un campione, ipotizzando che un intervallo di fiducia più ristretto implichi maggiore precisione. Nella prospettiva frequentista, la “precisione” è strettamente legata al livello di copertura a lungo termine assicurato dal metodo usato per creare gli intervalli di fiducia. Questo concetto non si applica al singolo intervallo di fiducia osservato. Dunque, un intervallo di fiducia che si presenta estremamente ristretto potrebbe in realtà essere significativamente lontano dal valore vero del parametro non noto.\nÈ importante sottolineare che l’approccio frequentista offre un metodo per calcolare gli intervalli di confidenza per una vasta gamma di statistiche. Questo include, ad esempio, la stima dell’intervallo di confidenza per la differenza tra due medie, per una proporzione o per la differenza tra due proporzioni. Ecco le formule per calcolare gli intervalli di confidenza per i casi menzionati:\nIntervallo di confidenza per la differenza tra due medie.\nSe abbiamo due campioni indipendenti di dimensione \\(n_1\\) e \\(n_2\\), con medie \\(\\bar{x}_1\\) e \\(\\bar{x}_2\\) e deviazioni standard \\(s_1\\) e \\(s_2\\), l’intervallo di confidenza per la differenza tra le medie è calcolato come:\n\\[\n(\\bar{x}_1 - \\bar{x}_2) \\pm t_{\\alpha/2} \\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}},\n\\]\ndove \\(t_{\\alpha/2}\\) è il valore critico della distribuzione t di Student con \\(\\alpha/2\\) di probabilità di coda e gradi di libertà \\(df = n_1 + n_2 - 2\\).\nIntervallo di confidenza per una proporzione.\nPer stimare l’intervallo di confidenza per una proporzione \\(p\\) in un campione binomiale di dimensione \\(n\\), la formula è:\n\\[\n\\hat{p} \\pm z_{\\alpha/2} \\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}},\n\\]\ndove \\(\\hat{p}\\) è la proporzione campionaria e \\(z_{\\alpha/2}\\) è il valore critico della distribuzione normale standard con \\(\\alpha/2\\) di probabilità di coda.\nIntervallo di confidenza per la differenza tra due proporzioni.\nPer stimare l’intervallo di confidenza per la differenza tra due proporzioni \\(p_1\\) e \\(p_2\\) in due campioni binomiali di dimensioni \\(n_1\\) e \\(n_2\\), la formula è:\n\\[\n(\\hat{p}_1 - \\hat{p}_2) \\pm z_{\\alpha/2} \\sqrt{\\frac{\\hat{p}_1(1 - \\hat{p}_1)}{n_1} + \\frac{\\hat{p}_2(1 - \\hat{p}_2)}{n_2}},\n\\]\ndove \\(\\hat{p}_1\\) e \\(\\hat{p}_2\\) sono le proporzioni campionarie e \\(z_{\\alpha/2}\\) è il valore critico della distribuzione normale standard con \\(\\alpha/2\\) di probabilità di coda.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/02_conf_interv.html#informazioni-sullambiente-di-sviluppo",
    "title": "72  Intervalli di fiducia",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] bayestestR_0.15.0   posterior_1.6.0     cmdstanr_0.8.1.9000\n#&gt;  [4] see_0.9.0           gridExtra_2.3       patchwork_1.3.0    \n#&gt;  [7] bayesplot_1.11.1    psych_2.4.12        scales_1.3.0       \n#&gt; [10] markdown_1.13       knitr_1.49          lubridate_1.9.4    \n#&gt; [13] forcats_1.0.0       stringr_1.5.1       dplyr_1.1.4        \n#&gt; [16] purrr_1.0.2         readr_2.1.5         tidyr_1.3.1        \n#&gt; [19] tibble_3.2.1        ggplot2_3.5.1       tidyverse_2.0.0    \n#&gt; [22] rio_1.2.3           here_1.0.1         \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tensorA_0.36.2.1     generics_0.1.3       stringi_1.8.4       \n#&gt;  [4] lattice_0.22-6       hms_1.1.3            digest_0.6.37       \n#&gt;  [7] magrittr_2.0.3       evaluate_1.0.1       grid_4.4.2          \n#&gt; [10] timechange_0.3.0     fastmap_1.2.0        rprojroot_2.0.4     \n#&gt; [13] jsonlite_1.8.9       backports_1.5.0      abind_1.4-8         \n#&gt; [16] mnormt_2.1.1         cli_3.6.3            rlang_1.1.4         \n#&gt; [19] munsell_0.5.1        withr_3.0.2          yaml_2.3.10         \n#&gt; [22] tools_4.4.2          parallel_4.4.2       tzdb_0.4.0          \n#&gt; [25] checkmate_2.3.2      colorspace_2.1-1     pacman_0.5.1        \n#&gt; [28] vctrs_0.6.5          R6_2.5.1             lifecycle_1.0.4     \n#&gt; [31] htmlwidgets_1.6.4    insight_1.0.0        pkgconfig_2.0.3     \n#&gt; [34] pillar_1.10.0        gtable_0.3.6         glue_1.8.0          \n#&gt; [37] xfun_0.49            tidyselect_1.2.1     farver_2.1.2        \n#&gt; [40] htmltools_0.5.8.1    nlme_3.1-166         rmarkdown_2.29      \n#&gt; [43] compiler_4.4.2       distributional_0.5.0",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#bibliografia",
    "href": "chapters/frequentist_inference/02_conf_interv.html#bibliografia",
    "title": "72  Intervalli di fiducia",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nHoekstra, R., Morey, R. D., Rouder, J. N., & Wagenmakers, E.-J. (2014). Robust misinterpretation of confidence intervals. Psychonomic Bulletin & Review, 21(5), 1157–1164.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html",
    "href": "chapters/frequentist_inference/03_sample_size.html",
    "title": "73  La grandezza del campione",
    "section": "",
    "text": "73.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nPreparazione del Notebook\nLa scelta della dimensione campionaria è cruciale per garantire che i risultati di uno studio siano affidabili, bilanciando precisione e costi. In questo capitolo, analizzeremo come calcolare la dimensione campionaria necessaria per stimare la media di una popolazione con un margine di errore prefissato e un determinato livello di confidenza. Utilizzeremo un esempio psicologico per illustrare il processo e fornire implementazioni in R.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>73</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html#la-logica-dietro-la-scelta-della-dimensione-campionaria",
    "href": "chapters/frequentist_inference/03_sample_size.html#la-logica-dietro-la-scelta-della-dimensione-campionaria",
    "title": "73  La grandezza del campione",
    "section": "\n73.2 La Logica Dietro la Scelta della Dimensione Campionaria",
    "text": "73.2 La Logica Dietro la Scelta della Dimensione Campionaria\nIn psicologia, stimare la media di una variabile (ad esempio, il punteggio medio di una scala psicometrica) è un’operazione comune. Campioni più grandi garantiscono:\n\n\nStime più precise: La varianza dell’estimatore diminuisce con l’aumentare della dimensione campionaria.\n\nMaggiore fiducia nei risultati: Il margine di errore si restringe.\n\nTuttavia, i campioni più grandi comportano costi più elevati in termini di tempo e risorse. Pertanto, il problema si riduce spesso a determinare il campione più piccolo che garantisce la precisione richiesta.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>73</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html#calcolo-della-dimensione-campionaria-derivazione-della-formula",
    "href": "chapters/frequentist_inference/03_sample_size.html#calcolo-della-dimensione-campionaria-derivazione-della-formula",
    "title": "73  La grandezza del campione",
    "section": "\n73.3 Calcolo della Dimensione Campionaria: Derivazione della Formula",
    "text": "73.3 Calcolo della Dimensione Campionaria: Derivazione della Formula\nPer campioni sufficientemente grandi, la media stimata \\(\\bar{X}\\) segue una distribuzione normale:\n\\[\n\\bar{X} \\sim \\mathcal{N}\\left(\\mu, \\frac{\\sigma^2}{n}\\right),\n\\]\ndove \\(n\\) è la dimensione del campione, \\(\\mu\\) è la vera media della popolazione e \\(\\sigma^2\\) è la varianza della popolazione.\nIl nostro obiettivo è trovare la dimensione campionaria \\(n\\) tale che:\n\\[\nP\\left(|\\bar{X} - \\mu| &lt; E\\right) \\geq 0.95,\n\\]\ndove:\n\n\n\\(\\bar{X}\\) è la media campionaria,\n\n\\(\\mu\\) è la media della popolazione,\n\n\\(E\\) è il margine di errore massimo accettabile.\n\nSappiamo che, per il teorema centrale del limite o per le proprietà della distribuzione normale:\n\\[\n\\bar{X} \\sim \\mathcal{N}\\left(\\mu, \\frac{\\sigma^2}{n}\\right),\n\\]\ndove \\(\\sigma^2\\) è la varianza della popolazione e \\(n\\) è la dimensione campionaria.\nPer trasformare in termini della variabile standardizzata \\(Z\\), utilizziamo:\n\\[\nZ = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}},\n\\]\nche implica:\n\\[\n\\bar{X} \\sim \\mathcal{N}\\left(0, 1\\right).\n\\]\nPertanto, la probabilità richiesta si riscrive:\n\\[\nP\\left(|\\bar{X} - \\mu| &lt; E\\right) = P\\left(|Z| &lt; z_{0.025}\\right),\n\\]\ndove \\(z_{0.025} = 1.96\\) è il quantile superiore della distribuzione normale standard, corrispondente a un livello di confidenza del \\(95\\%\\).\nDalla definizione della variabile standardizzata:\n\\[\nZ = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}},\n\\]\npossiamo ricavare la relazione per il margine di errore:\n\\[\n|\\bar{X} - \\mu| &lt; E \\implies Z = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}} \\implies |\\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}}| &lt; \\frac{E}{\\sigma / \\sqrt{n}}.\n\\]\nSostituendo la condizione \\(|Z| &lt; z_{0.025}\\), otteniamo:\n\\[\n\\frac{E}{\\sigma / \\sqrt{n}} = z_{0.025}.\n\\]\nMoltiplichiamo entrambi i membri per \\(\\sigma / \\sqrt{n}\\):\n\\[\nE = z_{0.025} \\cdot \\frac{\\sigma}{\\sqrt{n}}.\n\\]\nIsoliamo \\(\\sqrt{n}\\) dividendo entrambi i membri per \\(z_{0.025} \\cdot \\sigma\\):\n\\[\n\\sqrt{n} = \\frac{z_{0.025} \\cdot \\sigma}{E}.\n\\]\nPer ottenere \\(n\\), eleviamo entrambi i membri al quadrato:\n\\[\nn = \\left(\\frac{z_{0.025} \\cdot \\sigma}{E}\\right)^2.\n\\]\nIn conclusione, la dimensione campionaria minima \\(n\\) necessaria per soddisfare il margine di errore \\(E\\) e il livello di confidenza richiesto è:\n\\[\nn = \\left(\\frac{z_{0.025} \\cdot \\sigma}{E}\\right)^2.\n\\]",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>73</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html#stima-della-media-del-punteggio-di-autostima",
    "href": "chapters/frequentist_inference/03_sample_size.html#stima-della-media-del-punteggio-di-autostima",
    "title": "73  La grandezza del campione",
    "section": "\n73.4 Stima della Media del Punteggio di Autostima",
    "text": "73.4 Stima della Media del Punteggio di Autostima\nPer fare un esempio, immaginiamo di voler stimare la media del punteggio di autostima in una popolazione di giovani adulti. Utilizziamo la Rosenberg Self-Esteem Scale (RSES), che assegna un punteggio compreso tra 0 e 30.\nDettagli del problema:\n\nDeviazione standard del punteggio: \\(\\sigma = 6\\) (stimata da studi precedenti).\nMargine di errore massimo accettabile: \\(E = 2\\).\nLivello di confidenza: \\(95\\%\\).\n\nImplementiamo in R la formula derivata in precedenza.\n\n# Parametri del problema\nsigma &lt;- 6     # Deviazione standard del punteggio RSES\nE &lt;- 2         # Margine di errore desiderato\nz_alpha &lt;- qnorm(0.975)  # Quantile superiore della distribuzione normale (95% confidenza)\n\n# Calcolo della dimensione campionaria\nn &lt;- (z_alpha * sigma / E)^2\nn &lt;- ceiling(n)  # Arrotondamento all'intero successivo\nn\n#&gt; [1] 35\n\nIn conclusione, la dimensione campionaria minima necessaria per stimare la media del punteggio di autostima con un margine di errore massimo di 2 punti e un livello di confidenza del 95% è \\(n = 35\\).\n\n73.4.1 Approfondimenti\n\n\nPrecisione e Livello di Confidenza\nAumentando \\(n\\), la varianza di \\(\\bar{X}\\) diminuisce:\n\\[\n\\text{Var}(\\bar{X}) = \\frac{\\sigma^2}{n}.\n\\]\nQuesto restringe l’intervallo di confidenza e migliora la precisione.\n\nCosto e Praticità\nUn campione più grande aumenta i costi. È importante trovare il giusto compromesso tra precisione e fattibilità.\nAdattamento ad Altri Livelli di Confidenza\nPer altri livelli di confidenza, basta modificare il quantile \\(z_{\\alpha/2}\\). Ad esempio, per un livello di confidenza del 99%, \\(z_{0.005} \\approx 2.576\\).",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>73</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html#riflessioni-conclusive",
    "href": "chapters/frequentist_inference/03_sample_size.html#riflessioni-conclusive",
    "title": "73  La grandezza del campione",
    "section": "\n73.5 Riflessioni Conclusive",
    "text": "73.5 Riflessioni Conclusive\nDeterminare la dimensione del campione è essenziale per ogni studio psicologico. Un approccio matematico rigoroso ci permette di bilanciare la precisione delle stime con i vincoli di risorse.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>73</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/03_sample_size.html#informazioni-sullambiente-di-sviluppo",
    "title": "73  La grandezza del campione",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] see_0.9.0        gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1\n#&gt;  [5] psych_2.4.12     scales_1.3.0     markdown_1.13    knitr_1.49      \n#&gt;  [9] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [13] purrr_1.0.2      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [17] ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.3         rlang_1.1.4       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       yaml_2.3.10       tools_4.4.2       parallel_4.4.2   \n#&gt; [21] tzdb_0.4.0        colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5      \n#&gt; [25] R6_2.5.1          lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3  \n#&gt; [29] pillar_1.10.0     gtable_0.3.6      glue_1.8.0        xfun_0.49        \n#&gt; [33] tidyselect_1.2.1  farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-166     \n#&gt; [37] rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>73</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html",
    "title": "\n74  Significatività statistica\n",
    "section": "",
    "text": "74.1 Introduzione\nIl test di ipotesi è un metodo fondamentale della ricerca scientifica, utilizzato per fare inferenze sui parametri della popolazione a partire dai dati campionari. Nel contesto della psicologia, questo approccio viene frequentemente impiegato per valutare l’efficacia di interventi psicologici, confrontare teorie o approcci, analizzare l’influenza di variabili psicologiche su comportamenti e processi cognitivi, e approfondire i meccanismi alla base di fenomeni complessi come apprendimento, memoria ed emozioni.\nIn questo capitolo ci focalizzeremo sul test di ipotesi frequentista, un metodo largamente utilizzato ma non privo di limiti. È importante sottolineare che la comunità statistica sconsiglia di affidarsi esclusivamente a questo approccio come criterio decisionale per valutare la validità di un risultato sperimentale.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#introduzione",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#introduzione",
    "title": "\n74  Significatività statistica\n",
    "section": "",
    "text": "74.1.1 Significatività Statistica: Un Concetto da Riconsiderare\nTradizionalmente, un risultato è considerato “statisticamente significativo” se la probabilità che sia dovuto al caso è bassa, il che suggerisce che il risultato sia stabile o reale. Al contrario, risultati “non significativi” vengono spesso etichettati come privi di valore e ignorati. Questa semplificazione, però, può portare a gravi fraintendimenti. Ad esempio:\n\n\nDipendenza dal campione: La significatività statistica è fortemente influenzata dalla dimensione del campione; risultati apparentemente “significativi” possono emergere anche da effetti molto piccoli in campioni ampi.\n\nRisultati non significativi: Un risultato non significativo non implica che l’effetto sia nullo o irrilevante.\n\nScelte soggettive: Livelli di confidenza e test statistici differenti possono influenzare l’esito dell’analisi, portando a interpretazioni arbitrarie.\n\n74.1.2 Limiti e Applicazioni del Metodo Frequentista\nL’approccio frequentista non sempre mantiene la “promessa” di fornire una base oggettiva per la decisione statistica. Spesso, nella pratica scientifica, il ricorso esclusivo alla significatività statistica conduce a risultati opposti a quelli desiderati, aumentando il rischio di pubblicare risultati non replicabili o di trascurare evidenze importanti.\nIn alternativa, è più utile considerare il risultato osservato nel contesto scientifico più ampio, integrandolo con altre analisi. Questo approccio critico e completo consente di superare i limiti della significatività statistica e di interpretare i risultati con maggiore rigore.\n\n74.1.3 Un Caso Specifico: La Media del Campione\nInfine, analizzeremo il caso della media campionaria come stimatore della media della popolazione, discutendone i limiti e le applicazioni nel contesto della statistica inferenziale frequentista. Questo esempio ci permetterà di evidenziare aspetti pratici e teorici del test di ipotesi e di riflettere su come migliorare l’interpretazione dei risultati nella ricerca psicologica.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#il-test-di-ipotesi",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#il-test-di-ipotesi",
    "title": "\n74  Significatività statistica\n",
    "section": "\n74.2 Il Test di Ipotesi",
    "text": "74.2 Il Test di Ipotesi\nIl test di ipotesi è un metodo statistico utilizzato per valutare se i dati sono coerenti con l’ipotesi nulla (\\(H_0\\)). L’ipotesi nulla solitamente afferma che non vi è alcun effetto o differenza significativa, mentre l’ipotesi alternativa (\\(H_1\\)) rappresenta l’affermazione che si desidera testare. I dati del campione vengono analizzati per determinare se forniscono prove sufficienti per rifiutare l’ipotesi nulla. Un passaggio cruciale consiste nel calcolare il value-p.\n\n74.2.1 La procedura di Test di Ipotesi\nPasso 1: Formulare l’ipotesi nulla (\\(H_0\\)) e l’ipotesi alternativa (\\(H_1\\)) basandosi sulla domanda di ricerca.\nPasso 2: Stabilire un livello di significatività, α (solitamente 0.05).\nPasso 3: Selezionare il Test Statistico appropriato, verificare eventuali assunzioni e calcolare il test statistico.\nPasso 4: Decidere se il risultato è “statisticamente significativo” secondo (a) la regione di rifiuto o (b) il valore-p.\n\nL’approccio della regione di rifiuto. Basandosi sulla distribuzione campionaria nota del test statistico, la regione di rifiuto è un insieme di valori per il test statistico per i quali l’ipotesi nulla viene rifiutata. Se il valore osservato del test statistico rientra nella regione di rifiuto, allora si rifiuta l’ipotesi nulla.\nL’approccio del valore-p. Il valore-p è la probabilità di ottenere i risultati osservati, o risultati ancora più estremi, se l’ipotesi nulla è vera.\n\nConfrontiamo il valore-p calcolato con il livello di significatività α:\n\nSe il valore-p &lt; α, si rifiuta l’ipotesi nulla (\\(H_0\\)).\nSe il valore-p ≥ α, non si rifiuta l’ipotesi nulla (\\(H_0\\)).",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#il-test-di-ipotesi-nel-contesto-frequentista",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#il-test-di-ipotesi-nel-contesto-frequentista",
    "title": "\n74  Significatività statistica\n",
    "section": "\n74.3 Il Test di Ipotesi nel Contesto Frequentista",
    "text": "74.3 Il Test di Ipotesi nel Contesto Frequentista\nSi noti che i metodi bayesiani e frequentisti non sono semplicemente due approcci diversi per rispondere alla stessa domanda, ma formulano domande fondamentalmente diverse. Pertanto, per comprendere il test di ipotesi frequentista, è essenziale chiarire cosa si intende per valore-p.\nL’American Statistical Association (ASA) definisce il valore-p come:\n\nthe probability under a specified statistical model that a statistical summary of the data (e.g., the sample mean difference between two compared groups) would be equal to or more extreme than its observed value (Wasserstein e Lazar 2016).\n\nQuesta definizione può risultare difficile da comprendere perché contiene concetti complessi come “probabilità” e “modello statistico specificato”. Per capire meglio cosa rappresenta un valore-p, è necessario esaminare attentamente entrambi questi concetti. Questo ci porterà anche a una comprensione più profonda di altri concetti fondamentali per l’inferenza frequentista e ci aiuterà a distinguere tra inferenza frequentista e inferenza bayesiana.\nUna distinzione fondamentale tra l’approccio frequentista e quello bayesiano riguarda l’interpretazione della probabilità: il primo si basa sulla frequenza relativa degli eventi nel lungo periodo, mentre il secondo si basa sulla “certezza soggettiva” o sul grado di fiducia che un individuo attribuisce a un evento specifico.\nChiarito che la probabilità assume significati diversi nei contesti frequentista e bayesiano, possiamo chiederci quale nozione di probabilità sia implicita nella definizione del valore-p fornita dall’ASA. La visione comune suggerisce che si riferisca alle frequenze relative. Ma frequenze relative di cosa e ripetizioni di cosa?\nPossiamo riformulare la definizione dell’ASA in questo modo:\n\nIl valore-p si riferisce alla frequenza relativa di ottenere un riassunto statistico dei dati grande quanto o più grande del valore osservato in ripetizioni ipotetiche di un esperimento descritto da un modello statistico specificato.\n\nQuindi, l’approccio frequentista può essere descritto come un metodo per stimare il valore di un parametro attraverso esperimenti ipotetici, confrontando i nostri dati con i risultati di tali esperimenti per giudicare se i nostri dati sono sorprendenti o meno.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#applicazione-alla-media-campionaria",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#applicazione-alla-media-campionaria",
    "title": "\n74  Significatività statistica\n",
    "section": "\n74.4 Applicazione alla Media Campionaria",
    "text": "74.4 Applicazione alla Media Campionaria\nIn questo capitolo ci concentreremo sull’applicazione del processo di test di ipotesi frequentista alla media campionaria. Vedremo come la media di un campione possa essere impiegata per trarre inferenze sulla media di una popolazione, analizzandone limiti e possibili utilizzi nell’ambito dell’inferenza statistica frequentista.\nI test su uno o due campioni (one-sample e two-sample tests) hanno rappresentato le prime fondamenta dell’analisi statistica dei dati. Al giorno d’oggi, tuttavia, i nostri disegni sperimentali tendono a essere più complessi di quanto questi semplici test possano gestire. Nonostante ciò, tali test – in particolare il celebre t-test di Student – costituiscono ancora un’ottima porta d’ingresso alla modellazione statistica, poiché i principi su cui si basano sono relativamente intuitivi e consentono di familiarizzare con il processo di verifica dell’ipotesi.\nPer comprendere meglio i valori-p e la verifica del test di ipotesi, può essere molto utile ricorrere a simulazioni. Attraverso queste ultime è possibile ricreare condizioni sperimentali ipotetiche e osservare la variabilità dei risultati, fornendo così una prospettiva più chiara sulle implicazioni della statistica frequentista.\n\n74.4.1 La Distribuzione della Media Campionaria\nQuando consideriamo la media campionaria come stima della media di una popolazione, assumiamo che questa popolazione segua una distribuzione normale. Vogliamo quindi esplorare la distribuzione della media campionaria (\\(\\bar{X}\\)), che descrive la variazione di \\(\\bar{X}\\) attraverso infiniti campioni di dimensione \\(n\\). Abbiamo già dimostrato che, se la popolazione è normalmente distribuita, anche la distribuzione campionaria di \\(\\bar{X}\\) seguirà una distribuzione normale, con media \\(\\mu\\) (la media della popolazione) e deviazione standard \\(\\frac{\\sigma}{\\sqrt{n}}\\) (dove \\(\\sigma\\) è la deviazione standard della popolazione e \\(n\\) è la dimensione del campione).\n\n74.4.2 Test di Ipotesi sulla Media Campionaria\nSupponendo di conoscere \\(\\sigma\\) ma non \\(\\mu\\), utilizziamo i test di ipotesi per indagare quanto la media campionaria osservata si discosti da un valore ipotetico \\(\\mu_0\\), specificato dall’ipotesi nulla. Questo processo ci permette di valutare la plausibilità di \\(\\mu_0\\) come vera media della popolazione.\n\n74.4.3 Calcolo della Statistica del Test\nPer valutare quanto la media campionaria osservata si discosti dall’ipotesi nulla che propone \\(\\mu = \\mu_0\\), standardizziamo \\(\\bar{X}\\) usando la formula:\n\\[\nZ = \\frac{\\bar{X} - \\mu_0}{\\sigma/\\sqrt{n}}\n\\]\nQuesta trasformazione produce una variabile \\(Z\\) che segue una distribuzione normale standard \\(\\mathcal{N}(0, 1)\\). Valori estremi di \\(Z\\) (sia molto grandi che molto piccoli) suggeriscono che la media campionaria osservata è incompatibile con \\(\\mu_0\\), portando al rigetto dell’ipotesi nulla.\n\n74.4.3.1 Simulazione\nPer illustrare quanto espresso sopra attraverso una simulazione, consideriamo un esempio numerico. Supponiamo che \\(\\mu_0 = 100\\), \\(\\sigma = 15\\) e \\(n = 30\\). Vogliamo calcolare il valore-p per l’evento \\(\\bar{X} &gt; 105\\).\nLa simulazione può essere eseguita come segue:\n\n# To make the simulation reproducible\nset.seed(123)\n\nmu_0 &lt;- 100\nsigma &lt;- 15\nn &lt;- 30\nn_sim &lt;- 10000  # Number of simulations\n\n# Generate n_sim sample means from a N(mu_0, sigma/sqrt(n))\nsample_means &lt;- rnorm(n_sim, mean = mu_0, sd = sigma / sqrt(n))\n\n# Calculate the p-value as the proportion of sample means &gt; 105\np_value &lt;- mean(sample_means &gt; 105)\n\n# Print the p-value\nprint(p_value)\n#&gt; [1] 0.0339\n\nQuesto script simula la distribuzione campionaria di \\(\\bar{X}\\) sotto l’ipotesi nulla che \\(\\mu = \\mu_0\\) e calcola il valore-p per l’evento \\(\\bar{X} &gt; 105\\). Il valore-p indica la probabilità di osservare un valore di \\(\\bar{X}\\) così estremo (o più estremo) se l’ipotesi nulla fosse vera.\nIl risultato della simulazione può essere confrontato con il calcolo teorico del valore-p usando la distribuzione normale standard. Il valore \\(Z\\) per \\(\\bar{X} = 120\\) è calcolato come:\n\\[\nZ = \\frac{105 - 100}{15/\\sqrt{30}}\n\\]\nPossiamo usare la funzione stats.norm.sf() per trovare l’area sotto la curva normale standard a destra di questo valore \\(Z\\), che corrisponde al valore-p teorico.\n\n# Calculate the Z-score\nZ &lt;- (105 - 100) / (15 / sqrt(30))\nprint(Z)\n#&gt; [1] 1.83\n\n\n# Calculate the upper tail probability\nupper_tail_prob &lt;- pnorm(Z, lower.tail = FALSE)\n\nprint(upper_tail_prob)\n#&gt; [1] 0.0339\n\nOppure, in maniera equivalente\n\n# Calculate the upper tail probability\nupper_tail_prob &lt;- 1 - pnorm(105, mean = 100, sd = 15 / sqrt(30))\nprint(upper_tail_prob)\n#&gt; [1] 0.0339\n\nIl calcolo teorico mostra che il valore \\(Z\\) per una media campionaria di 105 è 1.82. Questo valore indica una deviazione sostanziale dalla media ipotizzata sotto l’ipotesi nulla (\\(\\mu_0 = 100\\)). Tale deviazione può essere quantificata dalla “sorpresa” indicata dal valore-p, dove valori-p piccoli rappresentano una maggiore sorpresa. Il valore-p ottenuto, pari a 0.0339, indica un elevato grado di sorpresa: come mostrato dalla simulazione, un valore di 105 o superiore si verifica solo nel 3.4% dei casi se l’esperimento viene ripetuto numerose volte sotto l’ipotesi nulla. Questo suggerisce che un risultato del genere è altamente improbabile se l’ipotesi nulla fosse vera.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#applicazioni-pratiche",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#applicazioni-pratiche",
    "title": "\n74  Significatività statistica\n",
    "section": "\n74.5 Applicazioni pratiche",
    "text": "74.5 Applicazioni pratiche\nNella precedente discussione, abbiamo supposto \\(\\sigma\\) nota. Tuttavia, poiché di solito non conosciamo il valore di \\(\\sigma\\) nella pratica, dobbiamo stimarlo utilizzando la deviazione standard campionaria \\(s\\). Pertanto, al posto di \\(\\sigma\\), possiamo utilizzare \\(s\\), ottenendo così la statistica:\n\\[\nT = \\frac{\\bar{X} - \\mu_0}{\\frac{s}{\\sqrt{n}}}.\n\\]\nSi può dimostrare che la statistica \\(T\\) segue una distribuzione \\(t\\) di Student con \\(n-1\\) gradi di libertà se il campione casuale è stato estratto da una popolazione normale.\nA questo punto, possiamo applicare la stessa logica descritta in precedenza e possiamom basarci sulla statistica \\(T\\) per testare un’ipotesi sulla media della popolazione. Utilizzando il valore critico appropriato dalla distribuzione \\(t\\) di Student con \\(n-1\\) gradi di libertà e un livello di significatività predefinito, possiamo determinare se i dati osservati supportano o respingono l’ipotesi nulla sulla media della popolazione.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#ipotesi-statistiche",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#ipotesi-statistiche",
    "title": "\n74  Significatività statistica\n",
    "section": "\n74.6 Ipotesi statistiche",
    "text": "74.6 Ipotesi statistiche\nEsaminiamo in maggior dettaglio la procedura di test di ipotesi statistiche nel contesto frequentista. Definiamo innanzitutto l’ipotesi statistica come una dichiarazione riguardante la distribuzione di probabilità di una variabile casuale. Tale ipotesi può riguardare la forma funzionale della distribuzione o i parametri che la caratterizzano.\nIn particolare, l’ipotesi che riguarda i parametri di una o più popolazioni viene denominata ipotesi nulla e viene rappresentata come \\(H_0\\). Per un parametro sconosciuto \\(\\theta\\), l’ipotesi nulla viene formulata come:\n\\[\nH_0: \\theta \\in \\Theta_0 \\subset \\Theta,\n\\]\ndove \\(\\Theta_0\\) è un sottoinsieme del dominio \\(\\Theta\\), che rappresenta tutti i possibili valori del parametro \\(\\theta\\) coerenti con il modello statistico adottato. L’ipotesi nulla può essere semplice se \\(\\Theta_0\\) contiene un unico elemento, oppure composta se contiene più di un elemento.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#i-passi-di-un-test-di-ipotesi",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#i-passi-di-un-test-di-ipotesi",
    "title": "\n74  Significatività statistica\n",
    "section": "\n74.7 I passi di un test di ipotesi",
    "text": "74.7 I passi di un test di ipotesi\nPer prendere una decisione tra accettare o respingere l’ipotesi nulla, i frequentisti utilizzano un test statistico. Un test statistico frequentista ci permette di valutare se i dati osservati forniscono prove sufficienti per respingere o accettare un’ipotesi riguardante una proprietà di una popolazione di interesse e si può descrivere nel modo seguente.\nIniziamo formulando l’ipotesi nulla \\(H_0\\), che rappresenta un’affermazione specifica sulla popolazione. L’ipotesi alternativa \\(H_1\\) viene formulata come l’evento complementare rispetto all’evento specificato dall’ipotesi nulla. Successivamente, definiamo una statistica campionaria \\(\\mathcal{G}_n(X_1, \\dots, X_n)\\) che viene calcolata a partire dai dati campionari e che ha una distribuzione nota quando l’ipotesi nulla è vera.\nSuccessivamente, suddividiamo l’insieme di tutte le possibili realizzazioni della statistica \\(\\mathcal{G}_n\\) in due insiemi disgiunti: la “regione di accettazione” \\(\\mathcal{A}\\) e la sua regione complementare, la “regione di rifiuto” \\(\\mathcal{R}\\). La regione di accettazione rappresenta l’insieme dei valori che la statistica può assumere sotto l’ipotesi nulla, mentre la regione di rifiuto rappresenta l’insieme dei valori che la statistica può assumere se l’ipotesi nulla è falsa.\nInfine, selezioniamo un livello di significatività \\(\\alpha\\), che rappresenta la massima probabilità di respingere erroneamente l’ipotesi nulla quando questa è vera. Se l’osservazione della statistica \\(\\mathcal{G}_n\\) rientra nella regione di accettazione, allora l’ipotesi nulla non viene respinta; altrimenti, viene respinta a favore dell’ipotesi alternativa.\nIn sintesi, il test statistico ci consente di stabilire se i dati osservati forniscono sufficienti evidenze per rifiutare l’ipotesi nulla a favore dell’ipotesi alternativa.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#ipotesi-alternativa",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#ipotesi-alternativa",
    "title": "\n74  Significatività statistica\n",
    "section": "\n74.8 Ipotesi alternativa",
    "text": "74.8 Ipotesi alternativa\nDurante un test di ipotesi, dopo aver definito l’ipotesi nulla \\(H_0\\), possono essere considerate diverse ipotesi alternative \\(H_1\\). Le ipotesi alternative più comuni si suddividono in tre tipi:\n\n\n\\(H_1: \\theta \\neq \\theta_0\\),\n\n\\(H_1: \\theta &gt; \\theta_0\\),\n\n\\(H_1: \\theta &lt; \\theta_0\\).\n\nQueste corrispondono rispettivamente a un test bidirezionale, un test unilaterale superiore (o destro) e un test unilaterale inferiore (o sinistro).\nLa scelta dell’ipotesi alternativa determina la definizione della regione di rifiuto \\(\\mathcal{R}\\) dell’ipotesi nulla \\(H_0\\). La regione di rifiuto rappresenta i valori estremi della distribuzione, nella direzione dell’ipotesi alternativa \\(H_1\\). Nel caso di un test unilaterale inferiore, \\(\\mathcal{R}\\) si trova nella coda sinistra della distribuzione, nell’intervallo [\\(-\\infty\\), \\(\\theta_0\\)]. Nel caso di un test unilaterale superiore, \\(\\mathcal{R}\\) si trova nella coda destra della distribuzione, nell’intervallo [\\(\\theta_0\\), \\(\\infty\\)].\nI valori critici sono i valori che delimitano la regione di rifiuto \\(\\mathcal{R}\\) in un test unilaterale e i valori che delimitano le regioni di rifiuto \\(\\mathcal{R}\\) in un test bidirezionale. Il risultato di un test viene considerato statisticamente significativo se il valore della statistica del test si trova nella regione di rifiuto \\(\\mathcal{R}\\).",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#valore-p",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#valore-p",
    "title": "\n74  Significatività statistica\n",
    "section": "\n74.9 Valore-p",
    "text": "74.9 Valore-p\nIl valore-p è definito come la probabilità che la statistica del test assuma un valore uguale o più estremo di quello osservato, considerando la distribuzione campionaria costruita assumendo come vera l’ipotesi nulla. La significatività statistica viene convenzionalmente definita come un valore-p inferiore a 0.05, indicando che l’evidenza osservata è improbabile da ottenere se l’ipotesi nulla è vera. Se il risultato osservato non raggiunge la significatività statistica, significa che la stima non è statisticamente significativa e che il valore osservato può essere spiegato da una semplice variazione casuale.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#un-esempio-motivante",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#un-esempio-motivante",
    "title": "\n74  Significatività statistica\n",
    "section": "\n74.10 Un esempio motivante",
    "text": "74.10 Un esempio motivante\nPer esplorare il concetto di significatività statistica, possiamo prendere in considerazione uno studio svolto da Mehr et al. (2016) sul ruolo della musica nella trasmissione di messaggi sociali ai bambini. La musica è una forma d’arte presente in molte attività quotidiane e può trasmettere informazioni relative alla cultura e all’appartenenza sociale. Gli autori dello studio hanno voluto indagare se i bambini di soli 5 mesi avessero una preferenza per individui sconosciuti che cantavano loro una canzone familiare rispetto ad altri individui sconosciuti che cantavano una canzone simile, ma con una diversa melodia.\nDalle analisi condotte da Mehr et al. (2016) è emerso che la preferenza dei bambini si manifestava solo quando la canzone veniva cantata dai loro genitori durante la fase di familiarizzazione, ma non quando la stessa canzone veniva cantata da un estraneo. Secondo gli autori, questo dimostra che il significato sociale è un elemento chiave nella preferenza dei bambini, oltre alla familiarità con la canzone.\n\n74.10.1 Domanda della ricerca e ipotesi statistiche\nLa ricerca condotta da Mehr et al. (2016) si è concentrata sullo studio dell’influenza della musica sui messaggi sociali trasmessi ai bambini molto piccoli. Tuttavia, come molte altre ipotesi psicologiche, l’ipotesi principale non può essere valutata direttamente in termini quantitativi. Pertanto, i ricercatori devono formulare ipotesi statistiche, che, sebbene non coincidano con l’ipotesi della ricerca, possono essere esaminate in termini probabilistici.\nPer chiarire questo punto, consideriamo l’esperimento condotto sui bambini da Mehr et al. (2016). Dopo la fase di familiarizzazione con la canzone di prova, i bambini partecipanti sono stati sottoposti a un test in laboratorio, durante il quale sono stati mostrati due video. Nel primo video, un estraneo cantava la canzone di prova, mentre nel secondo video, un altro individuo cantava una canzone simile ma non familiare ai bambini. I ricercatori hanno misurato il tempo in cui i bambini fissavano ciascun video. Nel primo esperimento, la variabile dipendente era la media delle proporzioni di tempo che i bambini fissavano il video “familiare” rispetto al tempo di fissazione totale. Poiché l’ipotesi principale non può essere valutata direttamente, i ricercatori hanno formulato ipotesi statistiche che possono essere esaminate in termini probabilistici.\nPoiché nei tipici esperimenti psicologici, come nel caso della ricerca di Mehr et al. (2016), l’ipotesi della ricerca non può essere valutata direttamente, è necessario stabilire una connessione tra l’ipotesi della ricerca e l’ipotesi statistica. Nel caso specifico, ci sono tre possibili scenari da considerare:\n\nNel caso in cui i bambini non mostrino alcuna preferenza tra i due tipi di video-registrazione, la media delle proporzioni di tempo di fissazione per la popolazione sarà uguale a \\(\\mu = 0.5\\), in quanto i tempi di fissazione saranno uguali in media per le due video-registrazioni.\nSe invece gli autori della ricerca hanno ragione, i bambini mostreranno una preferenza per il video con la canzone familiare rispetto a quello con la canzone non familiare. In questo caso, l’ipotesi statistica sarà \\(\\mu &gt; 0.5\\), dove \\(\\mu = 0.5\\) rappresenta il livello di probabilità casuale.\nInfine, una terza possibilità è che i bambini siano maggiormente attratti da una melodia non familiare, contrariamente a quanto suggerito dagli autori della ricerca. In tal caso, l’ipotesi statistica diventa \\(\\mu &lt; 0.5\\).\n\nLe tre ipotesi precedenti sono esempi di ipotesi statistiche, che sono delle affermazioni riguardanti i valori di un parametro di un modello statistico. Nel caso dell’esperimento di Mehr et al. (2016), il modello statistico riguarda la distribuzione delle proporzioni dei tempi di fissazione di una popolazione virtuale di infiniti bambini di sei mesi di età. Ogni bambino avrà una proporzione di tempi di fissazione diversa dagli altri bambini. Il modello statistico descritto dai ricercatori rappresenta la distribuzione dei possibili valori della proporzione del tempo di fissazione nei confronti del video “familiare”. I dati raccolti dagli sperimentatori corrispondono alla media della proporzione del tempo di fissazione del video “familiare” e possono essere messi in relazione con il modello statistico.\n\n74.10.2 Domanda della ricerca e ipotesi statistiche\nLa distinzione tra l’ipotesi della ricerca e l’ipotesi statistica è cruciale durante il test delle ipotesi. L’ipotesi della ricerca riguarda l’affermazione che si intende testare sulla natura dei fenomeni psicologici, mentre l’ipotesi statistica riguarda il modello generativo dei dati, ovvero le proprietà della popolazione. Nel caso dell’esperimento condotto da Mehr e colleghi, l’ipotesi della ricerca afferma che la preferenza sociale dei bambini è influenzata dalla musica e, in particolare, dalla familiarità con i materiali musicali. L’ipotesi statistica, invece, sostiene che la media della proporzione del tempo di fissazione dei bambini sul video “familiare” sia maggiore di 0.5.\nI test di ipotesi vengono applicati alle ipotesi statistiche, non alle ipotesi della ricerca. Ciò significa che se l’esperimento non viene condotto nella maniera appropriata, il collegamento tra l’ipotesi statistica e la domanda della ricerca può essere spezzato. Ad esempio, se l’attore che canta la melodia familiare assomiglia ad uno dei genitori del bambino, mentre l’altro attore ha un aspetto molto diverso, allora potrebbe essere facile trovare evidenze a supporto dell’ipotesi statistica secondo cui la proporzione media del tempo di fissazione dei bambini nei confronti del video “familiare” è maggiore di 0.5, ma ciò non avrebbe nulla a che fare con la domanda della ricerca.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#ipotesi-nulla-e-ipotesi-alternativa",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#ipotesi-nulla-e-ipotesi-alternativa",
    "title": "\n74  Significatività statistica\n",
    "section": "\n74.11 Ipotesi nulla e ipotesi alternativa",
    "text": "74.11 Ipotesi nulla e ipotesi alternativa\nFino a qui il ragionamento è stato semplice: il ricercatore ha un’ipotesi a proposito dei fenomeni psicologici e a tale ipotesi di ricerca corrisponde un’ipotesi statistica che riguarda il meccanismo generativo dei dati. Se il fenomeno psicologico possiede le proprietà suggerite dall’ipotesi della ricerca, allora il ricercatore può aspettarsi che i dati osservati abbiano alcune specifiche caratteristiche. A questo punto, però, il ragionamento diventa contro-intuitivo perché non è possibile verificare direttamente l’ipotesi statistica che corrisponde alla domanda della ricerca.\n\n74.11.1 Apagogia\nIn linea di principio, non è mai possibile dimostrare direttamente la verità di una proposizione. Tuttavia, possiamo dimostrare la sua verità in modo indiretto, ovvero provando la falsità della sua proposizione complementare.\nL’esempio classico è il seguente. Consideriamo la seguente proposizione: “Tutti i cigni sono bianchi” (questo è l’esempio ornitologico preferito da Popper). L’osservazione di un numero qualsiasi di cigni bianchi non è sufficiente a dimostrare la verità di questa proposizione – infatti, ci potrebbe essere da qualche parte un cigno non bianco che non abbiamo osservato (e infatti c’è). D’altra parte, invece, l’osservazione di un solo cigno che non sia bianco (ovvero, per esempio, l’osservazione di un cigno nero proveniente dall’Australia) può falsificare la proposizione considerata. Questa è la logica del falsificazionismo di Popper.\nQuesto modo di pensare è stato trasferito nella procedura di test di ipotesi di stampo frequentista. Dato che non possiamo dimostrare vera l’ipotesi statistica associata alla domanda della ricerca, seguiamo il percorso opposto. Ovvero, ci poniamo l’obiettivo di dimostrare falso l’evento complementare a quello specificato dall’ipotesi statistica associata alla domanda della ricerca. L’ipotesi statistica che vorremmo falsificare si chiama “ipotesi nulla” e viene denotata con \\(H_0\\). Nel caso dell’esempio che stiamo discutendo, l’ipotesi nulla è: \\(\\mu \\leq 0.5\\). Si noti che l’ipotesi nulla include tutte le possibili ipotesi statistiche che si possono formulare (ovvero, \\(\\mu = 0.5\\) e \\(\\mu &lt; 0.5\\)), ad eccezione di quella che è associata all’ipotesi della ricerca (ovvero, \\(\\mu &gt; 0.5\\)). Questo definisce, nel caso presente, un test unilaterale.\nIn pratica, ciò che stiamo facendo è dividere tutti i possibili valori di \\(\\mu\\) in due gruppi: quei valori che sono coerenti con l’ipotesi della ricerca (ovvero, i valori che specificano l’ipotesi alternativa, denotata con \\(H_1\\)) e quei valori che non sono coerenti con l’ipotesi della ricerca (ovvero, i valori che specificano l’ipotesi nulla).\nAvendo detto questo, la cosa importante da riconoscere è che l’obiettivo di un test di ipotesi frequentista non è quello di dimostrare che l’ipotesi alternativa è (probabilmente) vera; l’obiettivo è mostrare che l’ipotesi nulla è (probabilmente) falsa. La maggior parte delle persone ritiene che questo modo di ragionare sia piuttosto strano.\n\n74.11.2 La similitudine del processo penale\nUn test di ipotesi è spesso comparato ad un processo penale, dove l’ipotesi nulla rappresenta l’imputato, il ricercatore il pubblico ministero, e il test statistico il giudice. Così come in un processo penale, anche in un test di ipotesi c’è una presunzione di innocenza, dove l’ipotesi nulla viene considerata vera a meno che il ricercatore non dimostri, con evidenza al di là di ogni ragionevole dubbio, che è falsa. Il ricercatore progetta l’esperimento in modo da massimizzare la possibilità che i dati producano una condanna dell’ipotesi nulla. Il test statistico, rappresentato dal giudice in questa metafora, stabilisce le regole che devono essere seguite per giungere al verdetto e tali regole sono pensate per proteggere l’ipotesi nulla. In particolare, sono studiate per garantire che la probabilità di una condanna sia bassa se l’ipotesi nulla è effettivamente vera. È importante sottolineare che l’ipotesi nulla deve essere protetta, poiché il ricercatore sta cercando di dimostrare che essa è falsa.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#due-tipi-di-errori",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#due-tipi-di-errori",
    "title": "\n74  Significatività statistica\n",
    "section": "\n74.12 Due tipi di errori",
    "text": "74.12 Due tipi di errori\nPrima di entrare nei dettagli su come viene costruito un test statistico è utile capire la logica su cui esso è basato. In precedenza abbiamo paragonato il test di ipotesi nulla ad un processo penale, ma ora dobbiamo essere più espliciti. Idealmente, vorremmo costruire il nostro test in modo da non commettere errori. Sfortunatamente, però, questo non è possibile: a volte il ricercatore è sfortunato e finisce per prendere la decisione sbagliata, anche se adotta un processo decisionale razionale. Ad esempio, può succedere che una moneta venga lanciata 10 volte di fila e produca testa tutte le 10 volte. Ciò sembra fornire una prova molto forte del fatto che la moneta è sbilanciata, ma c’è una possibilità su 1024 che ciò accada anche se la moneta è equilibrata. In altre parole, nella vita reale dobbiamo sempre accettare la possibilità che le nostre scelte siano sbagliate, anche quando sembrano ragionevoli. Di conseguenza, l’obiettivo dei test delle ipotesi statistiche non è quello di eliminare completamente gli errori (questo è impossibile), ma di ridurre gli errori al minimo.\nA questo punto, dobbiamo precisare meglio cosa intendiamo per “errori”. Iniziamo con il rendere esplicito quello che è ovvio: l’ipotesi nulla può essere vera o falsa, e il nostro test ci può condurre a rifiutare l’ipotesi nulla o a non rifiutarla. La decisione di rigettare o non rigettare l’ipotesi nulla ci espone dunque al rischio di commettere uno di due tipi di errore, come indicato nella figura seguente. L’errore di I tipo, denotato con \\(\\alpha\\), è quello che commettiamo se rigettiamo l’ipotesi nulla quando essa è vera; l’errore di II tipo, denotato con \\(\\beta\\), è quello che commettiamo se accettiamo l’ipotesi nulla mentre invece è vera l’ipotesi alternativa.\n\n\n74.12.1 Errore di I tipo: la protezione dei diritti dell’imputato\nIn precedenza abbiamo paragonato il test statistico ad un processo penale. Infatti, un processo penale richiede che si stabilisca la colpevolezza dell’imputato “oltre ogni ragionevole dubbio”. Le regole del processo penale sono state progettate per garantire che non ci sia (quasi) nessuna possibilità di condannare ingiustamente un imputato innocente: il processo penale è progettato (almeno in teoria) per proteggere i diritti dell’imputato. Detto in altri termini, il processo penale non mette sullo stesso piano i due tipi di errore che si possono commettere: punire un innocente o assolvere un colpevole. L’errore che consiste nel punire un innocente viene considerato assai più grave di quello che porta ad assolvere un colpevole.\nUn test statistico fa praticamente la stessa cosa: i test di ipotesi statistiche sono costruiti in modo tale da controllare la probabilità di un errore di I tipo, con l’obiettivo di mantenerla al di sotto di una certa soglia prefissata. Questa probabilità, denotata con \\(\\alpha\\), viene chiamata “livello di significatività del test”. Usando parole diverse, possiamo dire che un test di ipotesi ha un livello di significatività \\(\\alpha\\) se il tasso di errore di I tipo non è più grande di \\(\\alpha\\). Per convenzione, i ricercatori fanno uso di tre diversi livelli \\(\\alpha\\): 0.05, 0.01 e 0.001.\n\n74.12.2 Errore di II tipo: l’asimmetria del giudizio\nChe dire del tasso di errore di II tipo? In realtà, vorremmo tenere anche quello sotto controllo e denotiamo la probabilità di un errore di II tipo con \\(\\beta\\). Il livello d’errore \\(\\beta\\) viene raramente discusso ed è molto più comune fare riferimento alla potenza del test, che è la probabilità dell’evento complementare, ovvero la probabilità con cui rifiutiamo l’ipotesi nulla quando è realmente falsa, ovvero \\(1-\\beta\\). Un test viene detto “potente” quando è caratterizzato da un piccolo valore \\(\\beta\\) pur mantenendo il livello \\(\\alpha\\) sotto una piccola soglia di probabilità prefissata.\nSi noti l’asimmetria qui rivelata: i test di ipotesi sono progettati per garantire che il livello \\(\\alpha\\) sia mantenuto sotto la soglia prefissata, ma non esiste alcuna corrispondente garanzia a proposito di \\(\\beta\\). Sicuramente è preferibile che il tasso di errore di II tipo sia piccolo, e in generale i ricercatori cercano di progettare i loro esperimenti in maniera tale da avere una ragionevole potenza del test (\\(1 - \\beta\\)) – questo si ottiene utilizzando un campione sufficientemente grande – ma nella logica della costruzione del test di ipotesi questo aspetto è secondario rispetto alla necessità di controllare il tasso di errore di I tipo.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#come-si-costruisce-un-test-di-ipotesi",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#come-si-costruisce-un-test-di-ipotesi",
    "title": "\n74  Significatività statistica\n",
    "section": "\n74.13 Come si costruisce un test di ipotesi?",
    "text": "74.13 Come si costruisce un test di ipotesi?\nRitorniamo all’esempio relativo allo studio di Mehr et al. (2016). In questo caso, sulla base all’ipotesi della ricerca, l’ipotesi nulla può essere formulata come \\(H_0: \\mu \\leq 0.5\\). Esaminando un campione di 32 bambini di età media pari a 5.6 mesi, Mehr et al. (2016) hanno scoperto che, in media, i bambini dirigevano lo sguardo verso il video “familiare” nel 56% del tempo totale di fissazione. Dunque, la media campionaria è \\(\\bar{X} = 0.56\\) Questo è il valore campionario rilevante per il test dell’ipotesi nulla.\nIngenuamente, potremmo pensare che, per decidere se \\(H_0\\) sia falsa o meno, sia sufficiente confrontare la proporzione calcolata nel campione con il valore \\(\\pi\\) specificato dall’ipotesi nulla. Nel caso presente, l’ipotesi nulla non specifica un unico valore \\(\\mu\\) ma bensì un intervallo di valori: \\([0, 0.5]\\). I dati campionari specificano un valore \\(\\bar{X} = 0.56\\), ovvero un valore che non è incluso nell’intervallo specificato da \\(H_0\\). Questo è incoraggiante. Se invece avessimo osservato \\(\\bar{X} = 0.41\\), per esempio, allora non ci sarebbe stato nient’altro da dire: se i dati osservati sono compatibili con \\(H_0\\) non c’è bisogno di eseguire alcun test statistico – abbiamo già trovato la risposta alla domanda della ricerca.\n\n74.13.1 La variabilità campionaria\nNel caso dell’esperimento di Mehr et al. (2016) che stiamo discutendo, \\(\\bar{X}\\) non cade nell’intervallo specificato da \\(H_0\\). Sulla base del valore osservato \\(\\bar{X} = 0.56\\) possiamo dunque concludere che \\(H_0\\) è falsa? Non così presto. Non è sufficiente trovare una differenza \\(\\bar{X} - \\mu\\) nella direzione giusta (cioè positiva, nel nostro caso). È anche necessario tenere in considerazione il fenomeno della variabilità campionaria.\nInfatti, la media \\(\\bar{X}\\) osservata in ogni singolo campione di ampiezza \\(n=32\\) è una variabile aleatoria: in ciascun possibile campione di ampiezza 32 i bambini si comportano in maniera diversa e, di conseguenza, \\(\\bar{X}\\) assumerà un valore diverso da campione a campione. Le statistiche campionarie – nel nostro caso la media \\(\\bar{X}\\) – sono di necessità diverse dai parametri. Ciò a cui noi siamo interessati è la media della popolazione, ovvero \\(\\mu\\), ma sfortunatamente conosciamo solo una sua realizzazione campionaria, ovvero \\(\\bar{X}\\).\nRisulta dunque chiaro che la nostra decisione rispetto ad \\(H_0\\) non può essere unicamente basata sulla differenza tra \\(\\bar{X} - \\mu\\). Infatti, è ragionevole pensare che, indipendentemente dal fatto che l’ipotesi nulla sia vera o meno, in alcuni campioni la differenza \\(\\bar{X} - \\mu\\) sarà positive mentre in altri campioni sarà negativa. Dobbiamo dunque trovare una procedura che riduca la possibilità di rifiutare \\(H_0\\) per effetto del caso soltanto. Possiamo (e dobbiamo) fare di meglio che considerare unicamente la differenza \\(\\bar{X} - \\mu\\).\n\n74.13.2 Le distribuzioni delle statistiche test\nIl metodo seguito dall’approccio frequentista per affrontare questo problema è quello di costruire la distribuzione della statistica test \\(\\mathcal{G}_n\\), rilevante per il test di \\(H_0\\), assumendo come vera l’ipotesi nulla. Questo è il concetto più contro-intuitivo di tutta la procedura di test di ipotesi dell’approccio frequentista. Esaminiamolo più in dettaglio.\nLo scopo della procedura di test statistici dell’approccio frequentista non è quello di verificare l’ipotesi alternativa: questo non è logicamente possibile. Invece, come suggerito dalla similitudine del processo penale all’ipotesi nulla, l’approccio frequentista si pone l’obiettivo di determinare se ci siano indizi sufficienti per “condannare” l’ipotesi nulla, ovvero, per rigettarla. In questa reductio ad absurdum, la “presunzione di innocenza” di \\(H_0\\) corrisponde all’idea che dobbiamo assumere come vera l’ipotesi nulla fino a prova contraria.\nNell’esempio che stiamo discutendo, assumere come vera l’ipotesi nulla significa assumere che il parametro \\(\\mu\\) (la media della popolazione) sia uguale a 0.5. Sulla base di questa assunzione, per i dati dell’esempio presente, è possibile costruire la distribuzione delle medie dei campioni di ampiezza 32. Standardizzando poi la media del campione, è possibile stabilire quanto sia “distante” dal valore atteso della distribuzione campionaria costruita assumento come vera \\(H_0\\).\nLa standardizzazione di \\(\\bar{X}\\) si effettua mediante il rapporto\n\\[\nT = \\frac{\\bar{X} - \\mu}{\\frac{s}{\\sqrt{n}}},\n\\]\ndove \\(\\bar{X}\\) è la media del campione (nel nostro caso, 0.56), \\(s\\) è la deviazione standard del campione (gli autori riportano \\(s\\) = 0.179) e \\(n\\) è l’ampiezza del campione (ovvero, \\(n\\) = 32). Per il caso presente otteniamo:\n\nT &lt;- (0.56 - 0.50) / (0.179 / sqrt(32))\nprint(T)\n#&gt; [1] 1.9\n\n\n74.13.3 Regioni di rifiuto e regioni di non rifiuto\nConoscendo la distribuzione dei valori della statistica test (distribuzione determinata assumendo come vera \\(H_0\\)) diventa poi possibile dividere l’insieme dei valori possibili di \\(\\mathcal{G}_n\\) (il nome che abbiamo assegnato ad una generica statistica test) in due regioni: i valori che ci portano a rigettare \\(H_0\\) (regione di rifiuto) e quelli che non ci consentono di rigettare \\(H_0\\) (regione di non rifiuto).\nPer decidere quanto deve essere grande la regione di rifiuto di \\(H_0\\) è sufficiente collocare nella regione di rifiuto i valori estremi della statistica test \\(\\mathcal{G}_n\\), ovvero quelli che sarebbe molto improbabile osservare se \\(H_0\\) fosse vera.\n\n74.13.4 Quando rifiutare l’ipotesi nulla\nSupponiamo che la figura seguente rappresenti la distribuzione campionaria della statistica test \\(\\mathcal{G}_n\\).\n\nSe i dati producono la statistica test \\(\\mathcal{G}_n^1\\), non possiamo rifiutare l’ipotesi nulla \\(H_0\\). Se invece i dati producono \\(\\mathcal{G}_n^2\\) allora possiamo rifiutare l’ipotesi nulla in favore dell’ipotesi alternativa. Ci sono varie cose da notare.\n\nLa regione di rifiuto è costituita da valori lontani dal centro della distribuzione campionaria della statistica test, la quale è stata costruita assumendo come vera \\(H_0\\).\nLa regione di rifiuto è situata nelle code della distribuzione. Vedremo in seguito anche degli esempi di regioni di rifiuto unilaterali.\nIn questa discussione, l’ipotesi alternativa non è menzionata. Rifiutiamo o non rifiutiamo \\(H_0\\) basandoci unicamente sulla distribuzione campionaria \\(f(\\mathcal{G}_n \\mid H_0)\\), cioè sulla probabilità della statistica test condizionata all’ipotesi nulla \\(H_0\\). L’ipotesi alternativa \\(H_1\\) viene presa in considerazione quando si sceglie dove posizionare la regione di rifiuto di \\(H_0\\), ma formalmente non gioca alcun ruolo nel rigettare o meno \\(H_0\\).\n\n74.13.5 Specificazione delle regioni di rifiuto\nL’ipotesi alternativa \\(H_1\\) può assumere forme diverse e ciò conduce a specificazioni diverse della regione di rifiuto \\(\\mathcal{R}\\) di \\(H_0\\). La regione di rifiuto \\(\\mathcal{R}\\) dell’ipotesi nulla corrisponde ai valori collocati agli estremi della distribuzione secondo la direzione dell’ipotesi alternativa \\(H_1\\).\n\nSe l’ipotesi alternativa è \\(H_1: \\theta \\neq \\theta_0\\) (dove \\(\\theta\\) è un generico parametro e \\(\\theta_0\\) è uno specifico valore del parametro), allora le evidenze coerenti con l’ipotesi alternativa (e che portano al rigetto di \\(H_0\\)) sono contenute negli intervalli \\([-\\infty, \\theta_0]\\) e \\([\\theta_0, +\\infty]\\).\nSe l’ipotesi alternativa è \\(H_1: \\theta &lt; \\theta_0\\), allora le evidenze coerenti con l’ipotesi alternativa (e che portano al rigetto di \\(H_0\\)) sono contenute nell’intervallo \\([-\\infty, \\theta_0]\\) e l’intera regione di rifiuto \\(\\mathcal{R}\\) è collocata nella coda di sinistra della distribuzione.\nSe l’ipotesi alternativa è \\(H_1: \\theta &gt; \\theta_0\\), allora le evidenze coerenti con l’ipotesi alternativa (e che portano al rigetto di \\(H_0\\)) sono contenute nell’intervallo \\([\\theta_0, \\infty]\\) e l’intera regione di rifiuto \\(\\mathcal{R}\\) è collocata nella coda di destra della distribuzione.\n\nSi chiamano valori critici i valori che delimitano la regione di rifiuto \\(\\mathcal{R}\\) in un test unilaterale e i valori che delimitano le regioni di rifiuto \\(\\mathcal{R}\\) in un test bilaterale. In un test bidirezionale, i valori critici lasciano in ciascuna delle due code della distribuzione della statistica test una probabilità pari a \\(\\alpha/2\\); in un test unidirezionale lasciano una probabilità pari ad \\(\\alpha\\) in una sola coda. Il risultato di un test si dice statisticamente significativo quando il valore della statistica test ricade nella regione di rifiuto \\(\\mathcal{R}\\).\n\n74.13.6 La decisione statistica\nIl processo di decisione statistica viene descritto da von Mises (1964) nel modo seguente:\n\nControllare (checking) o saggiare (testing) ha la forma seguente: se il “risultato osservato” ha una ‘piccola’ probabilità subordinatamente all’ipotesi assunta, respingiamo l’ipotesi. (p. 441)\n\nOvviamente l’ipotesi a cui von Mises fa riferimento è l’ipotesi nulla.\nIn pratica, possiamo decidere se rigettare o meno l’ipotesi nulla in due modi: determinando se la statistica test \\(\\mathcal{G}_n\\) cade o meno nella regione di rifiuto (come abbiamo descritto sopra) o confrontando il valore-\\(p\\) con \\(\\alpha\\) – i due metodi sono equivalenti.\nIl valore-p rappresenta la probabilità di osservare un valore della statistica test \\(\\mathcal{G}_n\\) pari a quello effettivamente osservato, o maggiore, quanto l’ipotesi nulla è vera. Se il valore-\\(p\\) è minore del livello di significatività \\(\\alpha\\), allora la statistica test cade nella regione di rifiuto di \\(H_0\\) e ciò conduce al rifiuto dell’ipotesi nulla. Tali concetti sono riassunti nella tabella seguente.\n\nPer l’esempio in discussione, la statistica \\(T\\) calcolata sopra si distribuisce come \\(t\\) di Student con \\(\\nu = 31\\) gradi di libertà. Il valore-p corrisponde dunque all’area sottesa ad una \\(t_{31}\\) nell’intervallo \\([1.896, +\\infty]\\) (test unidirezionale destro), ovvero\n\n# Calculate the upper tail probability for the t-distribution\np &lt;- 1 - pt(T, df = 31)\nprint(p)\n#&gt; [1] 0.0336\n\nDato che il valore-p è minore di \\(\\alpha = 0.05\\), Mehr et al. (2016) rifiutano \\(H_0\\) (cioè che la proporzione media del tempo di fissazione dei bambini nei confronti del video “familiare” sia 0.5, o minore) e concludono che i bambini mostrano una preferenza per il video familiare.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#potenza-del-test",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#potenza-del-test",
    "title": "\n74  Significatività statistica\n",
    "section": "\n74.14 Potenza del test",
    "text": "74.14 Potenza del test\nRitorniamo ora al concetto di potenza del test. Il livello di significatività e la potenza del test vengono usati per quantificare la qualità dell’inferenza statistica. Idealmente, la procedura di test di ipotesi non dovrebbe giungere alla conclusione sbagliata. Ovvero, non dovrebbe respingere \\(H_0\\) quando essa è vera e dovrebbe respingere \\(H_0\\) in favore dell’alternativa quando \\(H_1\\) è vera. Ma questi sono solo due dei quattro esiti che, in principio, sono possibili, e corrispondono alle probabilità indicate di seguito.\n\nPossiamo pensare a \\(H_0\\) come all’ipotesi che descrive l’evento “nulla di interessante sta succedendo” – ad esempio, “la moneta è bilanciata”, “il trattamento non è migliore del placebo”, ecc. – e pensare ad \\(H_1\\) come al caso contrario, ovvero: “sta accadendo qualcosa di interessante”. Quindi la potenza del test, ovvero la probabilità \\(1 - \\beta\\) di rigettare \\(H_0\\) quando essa è falsa, corrisponde alla probabilità di rilevare qualcosa di interessante, quando qualcosa di interessante è effettivamente successo, mentre il livello di significatività corrisponde alla probabilità di affermare che qualcosa di interessante si è verificato, quando in realtà non è successo nulla di interessante.\nIl calcolo della potenza di un test è spesso difficile, perché richiede la conoscenza della distribuzione campionaria di \\(\\mathcal{G}_n\\) quando è vera l’ipotesi alternativa \\(H_1\\). Tipicamente possiamo aumentare la potenza di un test aumentando la numerosità del campione in maniera tale da diminuire la varianza delle distribuzioni della statistica test condizionate a \\(H_0\\) e ad \\(H_1\\). In un disegno sperimentale è importante determinare in anticipo il numero di prove o dei soggetti necessari per raggiungere la potenza desiderata.\n\n74.14.1 Neyman e Fisher\nLa procedura di test di ipotesi statistiche descritta sopra combina due approcci teorici diversi, proposti da Sir Ronald Fisher e Jerzy Neyman. La storia di questi due approcci non è lineare, poiché Fisher e Neyman hanno modificato le loro opinioni nel tempo, senza mai fornire una “verità definitiva” su come interpretare il loro lavoro.\nIn sintesi, Fisher considerava che il ricercatore avesse un’unica ipotesi (quella nulla) e che lo scopo fosse verificare se i dati fossero coerenti o meno con essa. In questo senso, il valore-\\(p\\) rappresenta la probabilità di osservare, sotto l’ipotesi nulla, il risultato ottenuto o uno ancora più estremo. Se il valore-\\(p\\) è piccolo, Fisher rifiutava l’ipotesi nulla. Tuttavia, poiché non venivano formulate altre ipotesi, non c’era modo di “accettare l’alternativa”.\nAl contrario, Neyman adottava un approccio più formale rispetto a Fisher e pensava che lo scopo della verifica delle ipotesi fosse quello di prendere decisioni. Secondo Neyman, il problema era decidere se accettare l’ipotesi nulla o l’alternativa e il test serviva a stabilire quale supporto venisse fornito alle due alternative. Per questo motivo, era fondamentale specificare in modo preciso l’ipotesi alternativa. Nel suo approccio, il valore-\\(p\\) non misurava la probabilità del risultato del test o di uno più estremo sotto l’ipotesi nulla, ma forniva una descrizione astratta dei “possibili test” che portavano all’accettazione dell’ipotesi nulla o dell’alternativa.\nAttualmente ci troviamo in una situazione strana e ambigua, dove sono presenti elementi di entrambi gli approcci. La procedura di verifica di ipotesi statistiche distingue tra un’ipotesi nulla e un’ipotesi alternativa, seguendo la visione di Neyman, ma definisce il valore-\\(p\\) in termini di dati estremi, come avrebbe fatto Fisher, in confronto con un livello \\(\\alpha\\) stabilito da Neyman. Alcuni test statistici specificano in modo chiaro l’ipotesi alternativa, mentre altri sono più vaghi in merito, adottando l’approccio di Fisher. Inoltre, c’è disaccordo tra i ricercatori riguardo alla possibilità di “accettare l’alternativa”, a seconda che si segua Neyman o Fisher. Questa confusione costituisce il “peccato originale” della procedura di verifica di ipotesi statistiche. Tuttavia, ci sono motivi più specifici per cui questo approccio, noto come significatività statistica, viene criticato da molti ricercatori come una delle cause principali della crisi della replicabilità dei risultati della ricerca in psicologia e in altri campi. Nel capitolo ?sec-errors-s-m esploreremo queste ragioni in dettaglio.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#la-storia-del-test-dellipotesi-nulla-di-fisher-e-le-sue-contraddizioni",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#la-storia-del-test-dellipotesi-nulla-di-fisher-e-le-sue-contraddizioni",
    "title": "\n74  Significatività statistica\n",
    "section": "\n74.15 La Storia del Test dell’Ipotesi Nulla di Fisher e le Sue Contraddizioni",
    "text": "74.15 La Storia del Test dell’Ipotesi Nulla di Fisher e le Sue Contraddizioni\nConcludiamo l’analisi della procedura dei test di ipotesi statistici esaminando l’evento che ha ispirato Ronald A. Fisher a sviluppare la sua teoria dell’inferenza statistica, focalizzata sul test dell’ipotesi nulla. Questo episodio è descritto dettagliatamente da Etz et al. (2018). L’aneddoto riguarda un tè che Fisher aveva offerto alla sua collega, la Dott.ssa Muriel Bristol. Durante la preparazione della bevanda, la Dr.ssa Bristol contestò il metodo adottato da Fisher, asserendo che il tè avrebbe avuto un gusto migliore se il latte fosse stato versato prima dell’acqua bollente. Per verificare l’affermazione della Dr.ssa Bristol, Fisher ideò un esperimento di discriminazione sensoriale. Nei test condotti, la Dr.ssa Bristol fu in grado di individuare correttamente il processo di preparazione del tè in cinque occasioni su sei.\nQuesto risultato pose Fisher di fronte a un interrogativo: la sua collega stava semplicemente facendo una supposizione fortunata, oppure era effettivamente in grado di discernere tra le due diverse modalità di preparazione? Per risolvere questa questione, Fisher elaborò la sua metodologia per il test dell’ipotesi nulla. Utilizzò un valore-\\(p\\) calcolato sulla base della probabilità dell’evento osservato, nonché di qualsiasi altro evento più estremo che potrebbe verificarsi sotto l’ipotesi nulla.\nTuttavia, è stato fatto notare che l’approccio di Fisher al test dell’ipotesi nulla può essere insufficiente e portare a conclusioni errate (Etz et al., 2018). Una delle questioni fondamentali riguarda la definizione di un evento “più estremo” rispetto a quello osservato.\nSupponiamo che lo scopo dell’esperimento casuale sia di determinare l’accuratezza delle riposte della Dr.ssa Bristol in esattamente sei tentativi (e non di più). In tale caso, con 5 risposte corrette, il valore-\\(p\\) è pari a 0.109, che non è statisticamente significativo. In questo scenario, secondo la logica di Fisher, non si dovrebbe respingere l’ipotesi nulla che la Dr. Bristol stesse semplicemente indovinando.\nSupponiamo ora che lo scopo dell’esperimento casuale sia di continuare a servire tè fino a quando la Dr.ssa Bristol non abbia raggiunto cinque risposte corrette (un risultato che, per coincidenza, si è verificato dopo sei tentativi). Se analizziamo i dati in questo secondo scenario, il valore-\\(p\\) diventa pari a 0.031, che è statisticamente significativo. In quest’ultimo caso, l’ipotesi nulla verrebbe respinta.\nQuello che emerge è che, nonostante i dati osservati nei due scenari siano identici, giungiamo a conclusioni opposte come conseguenza delle diverse modalità di campionamento impiegate. Questa variabilità è problematica poiché il valore-\\(p\\), e quindi la nostra valutazione delle capacità discriminative della Dr.ssa Bristol, dipendono non solo dai dati effettivamente raccolti, ma anche dal disegno sperimentale adottato. Questa constatazione mette in discussione la robustezza del test dell’ipotesi nulla come strumento fondamentale per l’inferenza scientifica.\nPer illustrare il problema, svolgiamo i calcoli utilizzando le distribuzioni statistiche richieste per i due tipi di campionamento: la distribuzione binomiale e la distribuzione geometrica negativa.\n\n74.15.1 Distribuzione Binomiale\nLa distribuzione binomiale è la distribuzione da utilizzare quando il numero di tentativi è prefissato e conosciuto a priori. Nel contesto dell’esempio del tè, assumiamo che siano state servite esattamente sei tazze. La formula per determinare la probabilità di registrare esattamente \\(k\\) successi in \\(n\\) tentativi è la seguente:\n\\[\nP(X = k) = \\binom{n}{k} \\times p^k \\times (1-p)^{(n-k)}\n\\]\nQui, \\(\\binom{n}{k}\\) rappresenta il coefficiente binomiale, \\(p\\) è la probabilità di un singolo successo (ossia di indovinare correttamente la preparazione del tè), e \\((1-p)\\) è la probabilità di un singolo fallimento.\nPer calcolare il valore-\\(p\\) in questo specifico contesto, dobbiamo sommare le probabilità di ottenere un risultato di 5 o più estremo su un totale di 6 tentativi.\n\n# Parameters\nn_binomial &lt;- 6  # Number of fixed trials for the binomial distribution\nn_success &lt;- 5  # Desired number of successes\np &lt;- 0.5  # Probability of success\n\n# Calculate the p-value for the binomial distribution\np_value_binomial &lt;- 1 - pbinom(n_success - 1, size = n_binomial, prob = p)\n\np_value_binomial\n#&gt; [1] 0.109\n\n\n74.15.2 Distribuzione Geometrica Negativa\nNel contesto dell’esperimento del tè, quando il test continua fino al raggiungimento di un numero prefissato di successi (nel nostro caso, cinque identificazioni corrette), la distribuzione di riferimento appropriata è la distribuzione geometrica negativa.\nLa distribuzione geometrica negativa modella il numero di fallimenti \\(k\\) che si verificano prima di ottenere un numero prefissato \\(r\\) di successi in una sequenza di prove indipendenti di Bernoulli, dove ogni prova ha probabilità di successo \\(p\\).\nLa probabilità di osservare esattamente \\(k\\) fallimenti prima di ottenere \\(r\\) successi è data da:\n\\[\nP(X = k) = \\binom{k+r-1}{k} p^r (1-p)^k,\n\\]\ndove:\n\n\n\\(k\\) è il numero di fallimenti,\n\n\\(r\\) è il numero di successi desiderato,\n\n\\(p\\) è la probabilità di successo in ogni prova,\n\n\\(\\binom{k+r-1}{k}\\) è il coefficiente binomiale che rappresenta il numero di modi possibili in cui \\(k\\) fallimenti e \\(r\\) successi possono essere ordinati.\n\nNel nostro caso specifico:\n\n\n\\(r = 5\\) (successi desiderati),\n\n\\(p = 0.5\\) (probabilità di indovinare correttamente sotto l’ipotesi nulla),\n\n\\(k\\) varia da 0 a 1 (possibili fallimenti prima del quinto successo).\n\nIl valore-p si calcola sommando le probabilità per tutti i casi “più estremi” di quello osservato:\n\\[\n\\text{valore-p} = \\sum_{k=0}^{1} \\binom{k+5-1}{k} (0.5)^5 (0.5)^k.\n\\]\nImplementazione:\n\n# Parameters\nn_binomial &lt;- 6  # Number of fixed trials for the binomial distribution\nn_success &lt;- 5  # Desired number of successes\np &lt;- 0.5  # Probability of success (guessing the tea cup)\n\n# Calculate the p-value for the negative binomial distribution\np_value_geom_corrected &lt;- 0\nfor (k in 0:(n_binomial - n_success - 1)) {  # Number of failures before the 5th success\n  p_value_geom_corrected &lt;- p_value_geom_corrected + \n    choose(k + n_success - 1, k) * ((1 - p)^k) * (p^n_success)\n}\n\np_value_geom_corrected\n#&gt; [1] 0.0312\n\nIn conclusione,\n\nper la distribuzione binomiale, il p-value è \\(0.109\\), che non è statisticamente significativo (dato che è maggiore di 0.05); quindi, secondo Fisher, in questo caso non dovremmo rigettare l’ipotesi nulla che Dr. Bristol stia indovinando.\nper la distribuzione geometrica negativa, il p-value è \\(0.031\\), che è statisticamente significativo (dato che è minore di 0.05); in questo caso, dovremmo rigettare l’ipotesi nulla, suggerendo che Dr. Bristol non sta semplicemente indovinando.\n\nLa presente discussione mostra che, in base alla procedura del test dell’ipotesi nulla, la stessa sequenza di eventi (5 successi su 6 tentativi) può portare a conclusioni opposte a seconda delle ipotesi sul processo di campionamento. Questo paradosso è uno dei motivi (per ulteriori critiche, si veda Wasserstein & Lazar (2016); Benjamin et al. (2018)) per cui l’inferenza bayesiana è diventata più popolare negli ultimi anni come quadro alternativo per il test delle ipotesi e la stima dei parametri.\n\n74.15.3 Approccio Bayesiano\nNel loro lavoro, Etz et al. (2018) propongono un’alternativa bayesiana per risolvere il problema esaminato da Fisher. Questa soluzione bayesiana evita le contraddizioni che emergono quando si cercano di definire “risultati più estremi” che non sono stati osservati. L’approccio bayesiano si focalizza esclusivamente sui dati effettivamente raccolti e utilizza queste osservazioni per aggiornare le probabilità iniziali (o “a priori”) associate a diverse ipotesi. Il processo si basa sulla regola di Bayes e si sviluppa in tre fasi principali:\n\nStabilire Probabilità a Priori: Iniziamo assegnando una distribuzione di probabilità a priori a tutti i possibili tassi di successo che la Dr. Bristol potrebbe avere. Questo include una probabilità specifica per l’ipotesi nulla, che suggerisce che la Dr. Bristol stia semplicemente indovinando (con un tasso di successo del 50%).\nAggiornare le Probabilità con Dati Osservati: Utilizziamo i dati raccolti nell’esperimento per aggiornare le nostre probabilità a priori. Questo aggiornamento è fatto utilizzando la regola di Bayes.\nCalcolare il Fattore di Bayes: Questa metrica ci dice quanto i dati osservati influenzano le probabilità delle diverse ipotesi. Un Fattore di Bayes molto maggiore di 1 indicherebbe un forte supporto per l’ipotesi alternativa rispetto all’ipotesi nulla.\n\nNel caso specifico, il Fattore di Bayes calcolato è risultato essere circa 147.33, un valore notevolmente alto. Questo suggerisce che i dati osservati sono molto più compatibili con l’ipotesi che la Dr.ssa Bristol possa effettivamente distinguere tra le diverse preparazioni del tè, piuttosto che con l’ipotesi che stia indovinando.\nEtz et al. (2018) concludono che l’approccio bayesiano offre un quadro più robusto e coerente per il test delle ipotesi. A differenza del metodo frequentista, esso non dipende dalla definizione di “risultati più estremi” non osservati e si concentra invece esclusivamente sui dati effettivamente raccolti. Questa focalizzazione, in generale, rende l’approccio bayesiano una soluzione più solida per valutare le ipotesi scientifiche. Per una rivisitazione bayesiana dell’esperimento “The Lady Tasting Tea”, si veda anche la discussione di Doorn et al. (2020).",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#malintesi-sul-valore-p",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#malintesi-sul-valore-p",
    "title": "\n74  Significatività statistica\n",
    "section": "\n74.16 Malintesi sul valore-p",
    "text": "74.16 Malintesi sul valore-p\nSono diffusi molti malintesi sul valore-p. Ne esaminiamo qui quelli più comuni.\nMalinteso 1: Un valore p non significativo significa che l’ipotesi nulla è vera.\nIl malinteso che un valore p non significativo (p &gt; 0.05) implichi l’assenza di effetto o la verità dell’ipotesi nulla è diffuso e porta a conclusioni errate. La chiave per evitare questo errore sta nel comprendere che i valori p riflettono la probabilità dei dati osservati sotto l’ipotesi nulla, e non la probabilità dell’ipotesi stessa. Un valore p elevato non dimostra che l’ipotesi nulla sia vera, ma indica semplicemente che i dati osservati non sono sufficientemente insoliti da rifiutare l’ipotesi nulla con un livello di confidenza predefinito.\nRisultati non significativi possono verificarsi anche quando esiste un effetto reale, ma i dati non sono abbastanza estremi da superare la soglia di significatività statistica.\nInvece di concludere affrettatamente l’assenza di effetto da un valore p non significativo, dovremmo riconoscere l’ambiguità e considerare altre possibilità. Dichiarazioni come “non c’era differenza” dovrebbero essere riformulate in termini di assenza di differenza statisticamente significativa, lasciando aperta la questione dell’esistenza di un effetto reale.\nL’approccio bayesiano offre una prospettiva diversa che può essere particolarmente utile per interpretare risultati non significativi. A differenza dei valori p, che si limitano a valutare la probabilità dei dati sotto l’ipotesi nulla, l’inferenza bayesiana permette di calcolare direttamente la probabilità delle ipotesi date i dati.\nL’approccio bayesiano, quindi, non si limita a rifiutare o non rifiutare l’ipotesi nulla, ma quantifica la forza dell’evidenza a favore di un’ipotesi rispetto all’altra, fornendo una conclusione più informativa rispetto al semplice “non posso rifiutare l’ipotesi nulla”.\nMalintesto 2: Un valore p significativo significa che l’ipotesi nulla è falsa.\nCome spiegato in precedenza, il valore-p quantifica la “sorpresa” suscitata dai dati, alla luce dell’ipotesi nulla. Non ci dice niente sull’ipotesi che abbiamo assunto per quantificare la “sorpresa”.\nMalinteso 3: Un valore p significativo significa che è stato scoperto un effetto importante.\nLa distinzione tra “significatività statistica” e “rilevanza pratica” è fondamentale: mentre la prima indica semplicemente che un risultato è improbabile sotto l’ipotesi nulla, la seconda valuta l’effetto nel contesto di applicazioni reali e le sue implicazioni.\nUn effetto statisticamente significativo non garantisce che l’effetto abbia un impatto pratico notevole o utile.\nInoltre, al di là della significatività pratica, l’abitudine di molti psicologi di escludere i predittori che non risultano “statisticamente significativi” è un grossolano errore: la significatività statistica non può essere usata come un metodo per la selezione di variabili in un modello statistico.\nUn p &lt; 0.05 indica che, se l’ipotesi nulla è vera, abbiamo osservato dati che dovrebbero essere considerati sorprendenti. Tuttavia, solo perché i dati sono sorprendenti, non significa che dobbiamo preoccuparcene. È principalmente l’etichetta verbale “significativo” che causa confusione qui: in un contesto frequentista, un effetto “significativo” è un effetto “sorprendente” alla luce di \\(H_0\\), non è necessariamente un effetto “importante”.\nMalinteso 4: Se avete osservato un risultato significativo, la probabilità che abbiate commesso un errore di Tipo 1 (un falso positivo) è del 5%.\nIl malinteso che la presenza di un risultato significativo (per esempio, p &lt; 0.05) indichi una probabilità del 5% di aver commesso un errore di Tipo 1 (falso positivo) riflette una comprensione errata della statistica frequentista. La probabilità del 5% si riferisce al tasso di errore di Tipo 1, che è la proporzione di volte che potremmo aspettarci di rifiutare erroneamente l’ipotesi nulla se questa fosse vera, su molteplici ripetizioni dell’esperimento sotto le stesse condizioni. In altre parole, se potessimo ripetere lo stesso studio infinite volte, osserveremmo risultati falsamente positivi nel 5% di questi studi, assumendo che l’ipotesi nulla sia effettivamente vera in ogni caso.\nTuttavia, una volta che abbiamo raccolto i dati e ottenuto un risultato significativo in un unico studio, non possiamo dire che “la probabilità che questo particolare risultato sia un errore di Tipo 1 è del 5%”. In realtà, in quel momento specifico, l’evento (commettere un errore di Tipo 1) è già accaduto o non è accaduto; la probabilità associata a quel singolo risultato non è più applicabile nel modo in cui potremmo aspettarci intuitivamente. Il risultato è, per così dire, una realtà fissa: o abbiamo rilevato un effetto che in realtà non esiste (errore di Tipo 1), oppure abbiamo correttamente identificato un effetto reale. Senza ulteriori esperimenti o dati, non possiamo determinare con certezza in quale di queste categorie cade il nostro risultato.\nIn breve, il tasso del 5% di errore di Tipo 1 non si applica retroattivamente a un singolo risultato ottenuto, ma piuttosto descrive il comportamento a lungo termine di un test statistico sotto ripetute campionature. Questa distinzione è cruciale per una corretta interpretazione dei risultati degli esperimenti e sottolinea l’importanza di non sovrastimare la certezza di un singolo risultato statistico significativo.\nMalinteso 5: Uno meno il valore p è la probabilità che l’effetto si replichi quando ripetuto.\nIl concetto che 1 meno il valore p rappresenti la probabilità di replicazione di un effetto è un malinteso diffuso. In realtà, la probabilità di replicazione di un effetto non può essere direttamente calcolata dal valore p di un singolo studio a causa della complessità dei fattori coinvolti, tra cui la vera differenza media tra i gruppi. La potenza statistica di un test, che dipende dalla dimensione dell’effetto, dalla dimensione del campione e dal livello di significatività α, fornisce una stima della probabilità di rilevare un effetto significativo se questo effetto esiste davvero. Tuttavia, osservare un effetto significativo in un unico studio (ad esempio, p = 0.03) non significa che vi sia una probabilità del 97% che tale effetto si replichi in studi futuri. La possibilità di replicare un risultato dipende dalla presenza di un vero effetto e dalla potenza statistica del test originale.\nIn sintesi, la replicabilità di un effetto è influenzata da molti fattori e non può essere inferita semplicemente dal valore p di un singolo risultato. La comprensione e l’interpretazione corrette della replicabilità richiedono un’analisi dettagliata della potenza statistica e della dimensione dell’effetto, oltre che della consistenza dei risultati attraverso studi multipli.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#informazioni-sullambiente-di-sviluppo",
    "title": "\n74  Significatività statistica\n",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.17.0      see_0.9.0        gridExtra_2.3    patchwork_1.3.0 \n#&gt;  [5] bayesplot_1.11.1 psych_2.4.12     scales_1.3.0     markdown_1.13   \n#&gt;  [9] knitr_1.49       lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1   \n#&gt; [13] dplyr_1.1.4      purrr_1.0.2      readr_2.1.5      tidyr_1.3.1     \n#&gt; [17] tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3       \n#&gt; [21] here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      shape_1.4.6.1     xfun_0.49         htmlwidgets_1.6.4\n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2      \n#&gt;  [9] generics_0.1.3    parallel_4.4.2    pan_1.9           pacman_0.5.1     \n#&gt; [13] pkgconfig_2.0.3   jomo_2.7-6        Matrix_1.7-1      lifecycle_1.0.4  \n#&gt; [17] compiler_4.4.2    farver_2.1.2      munsell_0.5.1     mnormt_2.1.1     \n#&gt; [21] codetools_0.2-20  htmltools_0.5.8.1 glmnet_4.1-8      nloptr_2.1.1     \n#&gt; [25] pillar_1.10.0     MASS_7.3-61       iterators_1.0.14  rpart_4.1.23     \n#&gt; [29] boot_1.3-31       foreach_1.5.2     mitml_0.4-5       nlme_3.1-166     \n#&gt; [33] tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4     splines_4.4.2    \n#&gt; [37] rprojroot_2.0.4   fastmap_1.2.0     grid_4.4.2        colorspace_2.1-1 \n#&gt; [41] cli_3.6.3         magrittr_2.0.3    survival_3.8-3    broom_1.0.7      \n#&gt; [45] withr_3.0.2       backports_1.5.0   timechange_0.3.0  rmarkdown_2.29   \n#&gt; [49] nnet_7.3-19       lme4_1.1-35.5     hms_1.1.3         evaluate_1.0.1   \n#&gt; [53] rlang_1.1.4       Rcpp_1.0.13-1     glue_1.8.0        minqa_1.2.8      \n#&gt; [57] jsonlite_1.8.9    R6_2.5.1",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#bibliografia",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#bibliografia",
    "title": "\n74  Significatività statistica\n",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBenjamin, D. J., Berger, J. O., Johannesson, M., Nosek, B. A., Wagenmakers, E.-J., Berk, R., Bollen, K. A., Brembs, B., Brown, L., Camerer, C., et al. (2018). Redefine statistical significance. Nature Human Behaviour, 2(1), 6–10.\n\n\nDoorn, J. van, Matzke, D., & Wagenmakers, E.-J. (2020). An in-class demonstration of Bayesian inference. Psychology Learning & Teaching, 19(1), 36–45.\n\n\nEtz, A., Gronau, Q. F., Dablander, F., Edelsbrunner, P. A., & Baribault, B. (2018). How to become a Bayesian in eight easy steps: An annotated reading list. Psychonomic bulletin & review, 25(1), 219–234.\n\n\nMehr, S. A., Song, L. A., & Spelke, E. S. (2016). For 5-month-old infants, melodies are social. Psychological Science, 27(4), 486–501.\n\n\nWasserstein, R. L., & Lazar, N. A. (2016). The ASA’s statement on p-values: context, process, and purpose. The American Statistician, 70(2), 129–133.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html",
    "title": "\n75  Test t di Student per campioni indipendenti\n",
    "section": "",
    "text": "75.1 Introduzione\nIn questo capitolo, esamineremo il test \\(t\\) di Student per campioni indipendenti, uno dei test statistici frequentisti più ampiamente utilizzati nella pratica.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html#applicazioni-del-test-t-di-student",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html#applicazioni-del-test-t-di-student",
    "title": "\n75  Test t di Student per campioni indipendenti\n",
    "section": "\n75.2 Applicazioni del Test t di Student",
    "text": "75.2 Applicazioni del Test t di Student\nIl test t di Student per due campioni indipendenti è un metodo statistico utilizzato per determinare se le medie di due campioni indipendenti sono significativamente diverse. Questo test si applica quando i due campioni sono estratti da popolazioni diverse e non vi è alcuna correlazione tra le osservazioni di un campione e quelle dell’altro.\nPer condurre il test t di Student per due campioni indipendenti, calcoliamo la differenza tra le medie dei due campioni e le stime delle varianze campionarie delle rispettive popolazioni. L’ipotesi nulla del test è che le medie dei due campioni siano uguali, mentre l’ipotesi alternativa a due code è che le medie dei due campioni siano diverse. La statistica del test t viene calcolata come il rapporto tra la differenza delle medie campionarie e la deviazione standard media campionaria.\nSuccessivamente, confrontiamo la statistica t con la distribuzione t di Student con \\(n_1 + n_2 - 2\\) gradi di libertà, dove \\(n_1\\) e \\(n_2\\) sono le dimensioni dei due campioni. Calcoliamo quindi il valore-p dalla distribuzione t per determinare la significatività del test.\nEsistono due approcci per stimare la varianza. Se assumiamo che le due popolazioni abbiano la stessa varianza (omoschedasticità), utilizziamo una stima pooled della varianza. Questo metodo è considerato efficiente quando l’omoschedasticità è verificata (argomento correction = False in pg.ttest()). Invece, se supponiamo che le due popolazioni abbiano varianze diverse, utilizziamo due stime separate delle varianze per i due campioni, chiamato test di Welch (argomento correction = True in pg.ttest()). Questo approccio è più robusto quando le varianze dei due gruppi sono significativamente diverse.\nLe principali assunzioni del test t di Student per due campioni indipendenti sono l’indipendenza dei due campioni e la normalità della distribuzione delle popolazioni da cui sono stati estratti i campioni.\nDi seguito è riportato il calcolo della stima della deviazione standard pooled, utilizzata per standardizzare la differenza tra le medie dei due campioni quando l’assunzione di omoschedasticità è verificata:\n\\[\ns_p = \\sqrt{\\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2}},\n\\]\ndove \\(s_p\\) è la deviazione standard pooled, \\(n\\) e \\(m\\) sono le dimensioni dei due campioni, \\(s^2_0\\) e \\(s^2_1\\) sono le varianze campionarie dei due gruppi.\nLa statistica del test t è quindi calcolata come:\n\\[\nt = \\frac{\\bar{x}_1 - \\bar{x}_2}{s_p \\sqrt{1/n_1 + 1/n_2}},\n\\]\ndove \\(\\bar{x}_1\\) e \\(\\bar{x}_2\\) sono le medie campionarie dei due gruppi.\n\n75.2.1 Dimostrazione\nPer dimostrare come calcolare la varianza della differenza tra due medie campionarie, supponiamo di avere due campioni casuali indipendenti \\(X_1, X_2, \\dots, X_n\\) e \\(Y_1, Y_2, \\dots, Y_m\\) che sono estratti dalla stessa popolazione con media \\(\\mu\\) e varianza \\(\\sigma^2\\). Definiamo \\(\\bar{X}\\) e \\(\\bar{Y}\\) come le medie campionarie di questi due campioni, rispettivamente.\nLe medie campionarie \\(\\bar{X}\\) e \\(\\bar{Y}\\) sono date da:\n\\[\n\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i\n\\] \\[\n\\bar{Y} = \\frac{1}{m} \\sum_{j=1}^m Y_j\n\\]\nLe medie campionarie \\(\\bar{X}\\) e \\(\\bar{Y}\\) sono entrambe stimatori non distorti della media della popolazione \\(\\mu\\). Le loro varianze sono date da:\n\\[\n\\text{Var}(\\bar{X}) = \\frac{\\sigma^2}{n}\n\\]\n\\[\n\\text{Var}(\\bar{Y}) = \\frac{\\sigma^2}{m}\n\\]\nSiamo interessati a calcolare la varianza della differenza \\(\\bar{X} - \\bar{Y}\\). Utilizzando le proprietà di varianza per combinazioni lineari di variabili aleatorie indipendenti, otteniamo:\n\\[\n\\text{Var}(\\bar{X} - \\bar{Y}) = \\text{Var}(\\bar{X}) + \\text{Var}(\\bar{Y})\n\\]\ndato che i termini incrociati si annullano per l’indipendenza di \\(\\bar{X}\\) e \\(\\bar{Y}\\). Sostituendo le varianze di \\(\\bar{X}\\) e \\(\\bar{Y}\\) abbiamo:\n\\[\n\\text{Var}(\\bar{X} - \\bar{Y}) = \\frac{\\sigma^2}{n} + \\frac{\\sigma^2}{m}\n\\]\n\\[\n\\text{Var}(\\bar{X} - \\bar{Y}) = \\sigma^2 \\left(\\frac{1}{n} + \\frac{1}{m}\\right)\n\\]\nQuindi, la varianza della differenza tra le due medie campionarie è una combinazione delle varianze delle singole medie, ponderate in base alle dimensioni dei campioni corrispondenti.\nPer giungere alla formula del test \\(t\\) di Student per due campioni indipendenti dobbiamo considerare l’incertezza aggiuntiva che deriva dal fatto che non conosciamo \\(\\sigma\\). Il modo migliore di stimare \\(\\sigma\\) è quello di utilizzare le due deviazioni standard dei campioni (calcolate come stimatori della varianza della popolazione) ponderate per i rispettivi gradi di libertà, come indicato in precedenza per la deviazione standard pooled:\n\\[\ns_p = \\sqrt{\\frac{(n - 1)s^2_x + (m - 1)s^2_y}{n + m - 2}},\n\\]\ndove \\(s_x\\) e \\(s_y\\) sono le deviazioni standard dei due campioni, e \\(n\\) e \\(m\\) sono le numerosità dei due campioni.\n\n75.2.2 Un esempio concreto\nEsaminiamo un esempio concreto. Supponiamo di disporre di nove misure del peso per un gruppo di donne e di nove misure di peso per un gruppo di uomini. Ci chiediamo se, nella popolazione, la media del peso dei due gruppi sia diversa.\nCreiamo due array con i dati e li inseriamo in un DataFrame.\n\nwomen_weight &lt;- c(38.9, 61.2, 73.3, 21.8, 63.4, 64.6, 48.4, 48.8, 48.5)\nmen_weight &lt;- c(67.8, 60, 63.4, 76, 89.4, 73.3, 67.3, 61.3, 62.4)\n\nweight &lt;- c(women_weight, men_weight)\nprint(weight)\n#&gt;  [1] 38.9 61.2 73.3 21.8 63.4 64.6 48.4 48.8 48.5 67.8 60.0 63.4 76.0 89.4\n#&gt; [15] 73.3 67.3 61.3 62.4\n\nCreazione di una variabile che specifica l’appartenenza al gruppo:\n\n# Creazione della variabile is_female\nis_female &lt;- rep(c(1, 0), each = 9)  # 1 = Femmina, 0 = Maschio\nis_female\n#&gt;  [1] 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0\n\n\n75.2.3 Creazione del DataFrame\n\n# Creazione del DataFrame\ndf &lt;- data.frame(is_female = is_female, weight = weight)\nprint(df)\n#&gt;    is_female weight\n#&gt; 1          1   38.9\n#&gt; 2          1   61.2\n#&gt; 3          1   73.3\n#&gt; 4          1   21.8\n#&gt; 5          1   63.4\n#&gt; 6          1   64.6\n#&gt; 7          1   48.4\n#&gt; 8          1   48.8\n#&gt; 9          1   48.5\n#&gt; 10         0   67.8\n#&gt; 11         0   60.0\n#&gt; 12         0   63.4\n#&gt; 13         0   76.0\n#&gt; 14         0   89.4\n#&gt; 15         0   73.3\n#&gt; 16         0   67.3\n#&gt; 17         0   61.3\n#&gt; 18         0   62.4\n\nKDE Plot per tutto il campione\n\n# Calcolo della densità\ndensity &lt;- density(df$weight)\ndensity_df &lt;- data.frame(x = density$x, y = density$y)\n\n# Plot KDE\nggplot(density_df, aes(x = x, y = y)) +\n  geom_line() +\n  labs(x = \"Weight\", y = \"Density\")\n\n\n\n\n\n\n\nEstrazione dei dati per i due gruppi\n\n# Valori di peso per i due gruppi\nweight_f &lt;- df$weight[df$is_female == 1]\nweight_m &lt;- df$weight[df$is_female == 0]\n\nCalcolo della deviazione standard pooled\n\n# Numeratore della deviazione standard pooled\ns_pool_num &lt;- ((length(weight_f) - 1) * var(weight_f)) +\n              ((length(weight_m) - 1) * var(weight_m))\n\n# Denominatore della deviazione standard pooled\ns_pool_denom &lt;- length(weight_f) + length(weight_m) - 2\n\n# Deviazione standard pooled\ns_pool &lt;- sqrt(s_pool_num / s_pool_denom)\ns_pool\n#&gt; [1] 12.9\n\nCalcolo della statistica t:\n\n# Numeratore della statistica t\nt_num &lt;- mean(weight_f) - mean(weight_m)\n\n# Denominatore della statistica t\nt_denom &lt;- s_pool * sqrt(1 / length(weight_f) + 1 / length(weight_m))\n\n# Statistica t\nT &lt;- t_num / t_denom\nT\n#&gt; [1] -2.78\n\nGradi di libertà:\n\n# Gradi di libertà\ndf &lt;- length(weight_f) + length(weight_m) - 2\ndf\n#&gt; [1] 16\n\nCalcolo del valore p:\n\n# Valore p\np_value &lt;- 2 * pt(T, df = df, lower.tail = FALSE)\np_value\n#&gt; [1] 1.99\n\nTest t con la funzione t.test in R:\n\n# Test t senza correzione di Welch\nres &lt;- t.test(weight_f, weight_m, var.equal = TRUE)\nprint(res)\n#&gt; \n#&gt;  Two Sample t-test\n#&gt; \n#&gt; data:  weight_f and weight_m\n#&gt; t = -3, df = 16, p-value = 0.01\n#&gt; alternative hypothesis: true difference in means is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  -29.75  -4.03\n#&gt; sample estimates:\n#&gt; mean of x mean of y \n#&gt;      52.1      69.0\n\n# Interpretazione: Possiamo rifiutare l'ipotesi nulla di uguaglianza delle medie.\n\nTest t con la correzione di Welch\n\n# Test t con correzione di Welch\nres_welch &lt;- t.test(weight_f, weight_m, var.equal = FALSE)\nprint(res_welch)\n#&gt; \n#&gt;  Welch Two Sample t-test\n#&gt; \n#&gt; data:  weight_f and weight_m\n#&gt; t = -3, df = 13, p-value = 0.02\n#&gt; alternative hypothesis: true difference in means is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  -30.0  -3.8\n#&gt; sample estimates:\n#&gt; mean of x mean of y \n#&gt;      52.1      69.0\n\n# Con correzione di Welch, il p-value può risultare più alto a causa della stima aggiustata dei gradi di libertà.\n\nIn conclusione, i risultati del test t confermano quanto trovato attraverso i calcoli manuali. Con un livello di confidenza del 95%, possiamo concludere che il peso medio degli uomini è significativamente superiore al peso medio delle donne nella popolazione analizzata. La correzione di Welch offre una stima più robusta dei gradi di libertà in caso di varianze disuguali, ma non modifica sostanzialmente la statistica test.\nQuesta traduzione mantiene la logica originale del codice Python, adattandola all’ambiente R e utilizzando librerie native per una migliore leggibilità e funzionalità.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html#interpretazione-dei-risultati",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html#interpretazione-dei-risultati",
    "title": "\n75  Test t di Student per campioni indipendenti\n",
    "section": "\n75.3 Interpretazione dei Risultati",
    "text": "75.3 Interpretazione dei Risultati\nIl test t di Student per campioni indipendenti ha generato un p-valore di 0.013, inferiore alla soglia di significatività di α = 0.05. Questo indica che la differenza osservata tra i gruppi è statisticamente significativa. Tuttavia, anziché limitarci a etichettare il risultato come “statisticamente significativo”, è importante considerare cosa implica questo esito nel contesto della ricerca.\nIn sostanza, il basso p-valore ci porta a rifiutare l’ipotesi nulla, suggerendo che è improbabile che le differenze osservate nei dati siano dovute al caso. Questo ci permette di concludere con una certa fiducia che esiste una differenza reale tra le medie delle popolazioni da cui i campioni sono stati estratti. Questa interpretazione apre la strada a ulteriori indagini sulle cause di tale differenza e sulle loro implicazioni teoriche o pratiche.\nSe il p-valore fosse stato superiore alla soglia di significatività α, avremmo interpretato il risultato in modo diverso. Un p-valore maggiore di α indica che i dati osservati non sono incompatibili con l’ipotesi nulla. In altre parole, non avremmo avuto motivi statistici sufficienti per rifiutare l’ipotesi nulla. Tuttavia, è importante sottolineare che questo non equivale a dimostrare che l’ipotesi nulla sia vera; piuttosto, i dati non forniscono evidenza sufficiente per confutarla.\nIn pratica, la non rifiutazione dell’ipotesi nulla significa che i dati sono compatibili sia con l’ipotesi nulla sia con altre possibili ipotesi sulle caratteristiche della popolazione. Di conseguenza, in assenza di evidenza contraria, ci asteniamo dal fare affermazioni conclusive e manteniamo una posizione di neutralità riguardo l’ipotesi nulla, rimanendo aperti alla possibilità di ulteriori indagini e dati futuri che potrebbero chiarire meglio la questione.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html#riportare-i-risultati",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html#riportare-i-risultati",
    "title": "\n75  Test t di Student per campioni indipendenti\n",
    "section": "\n75.4 Riportare i risultati",
    "text": "75.4 Riportare i risultati\nPer riportare i risultati si può usare un testo come quello seguente:\n\nAbbiamo condotto un test \\(t\\) di Student per campioni indipendenti per confrontare le medie dei due gruppi. I risultati indicano una differenza tra le medie dei gruppi (\\(t\\)(16) = 2.78, \\(p\\) = 0.013). L’intervallo di confidenza al 95% per la differenza delle medie è tra 4.03 e 29.75. L’ampiezza dell’effetto, misurata con Cohen’s \\(d\\), è stata di 1.31, indicando un effetto grande secondo le convenzioni comunemente accettate. La potenza statistica del test, calcolata post hoc, è stata del 74.4%, indicando una buona probabilità di rilevare un effetto, se presente.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html#test-unidirezionali-e-bidirezionali",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html#test-unidirezionali-e-bidirezionali",
    "title": "\n75  Test t di Student per campioni indipendenti\n",
    "section": "\n75.5 Test Unidirezionali e Bidirezionali",
    "text": "75.5 Test Unidirezionali e Bidirezionali\nIl criterio secondo il quale un p-valore inferiore a α indica una “significatività statistica” è comune sia nei test bidirezionali sia nei test unidirezionali, ma l’applicazione differisce a seconda della natura dell’ipotesi testata.\n\n75.5.1 Test Bidirezionale\nNel caso di un test bidirezionale, le ipotesi sono formulate come segue: - Ipotesi nulla (H₀): \\(\\mu_1 = \\mu_2\\) (cioè, \\(\\mu_1 - \\mu_2 = 0\\)); si assume uguaglianza delle varianze (\\(\\sigma^2_1 = \\sigma^2_2\\)). - Ipotesi alternativa (H₁): \\(\\mu_1 \\neq \\mu_2\\); ancora con uguaglianza delle varianze.\nLa statistica test è calcolata come $ {Y}_1 - {Y}_2 $, dove \\(\\bar{Y}_1\\) e \\(\\bar{Y}_2\\) sono le medie campionarie dei due gruppi. La regione di rifiuto dell’ipotesi nulla è equamente divisa tra le due code della distribuzione della statistica test, con α/2 per coda.\n\n75.5.2 Test Unidirezionale\nPer i test unidirezionali, la direzione della differenza che si sta testando è cruciale:\n\n\nQuando si testa se \\(\\mu_1\\) è minore di \\(\\mu_2\\):\n\n\nIpotesi nulla (H₀): \\(\\mu_1 \\geq \\mu_2\\);\n\nIpotesi alternativa (H₁): \\(\\mu_1 &lt; \\mu_2\\).\n\nLa statistica test è calcolata come $ {Y}_1 - {Y}_2 $. Se questa differenza è significativamente negativa (cioè cade nella coda sinistra oltre il valore critico), supporta H₁.\n\n\nQuando si testa se \\(\\mu_1\\) è maggiore di \\(\\mu_2\\):\n\n\nIpotesi nulla (H₀): \\(\\mu_1 \\leq \\mu_2\\);\n\nIpotesi alternativa (H₁): \\(\\mu_1 &gt; \\mu_2\\).\n\nAnche qui, la statistica test è $ {Y}_1 - {Y}_2 $. Un risultato che supera il valore critico nella coda destra indica supporto per H₁.\n\n\nIn ogni tipo di test unidirezionale, la regione di rifiuto occupa l’intero α dell’area sotto la curva di densità, ma è posizionata completamente nella coda specificata dall’ipotesi alternativa.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html#considerazioni-sugli-errori-di-tipo-i-e-tipo-ii",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html#considerazioni-sugli-errori-di-tipo-i-e-tipo-ii",
    "title": "\n75  Test t di Student per campioni indipendenti\n",
    "section": "\n75.6 Considerazioni sugli Errori di Tipo I e Tipo II",
    "text": "75.6 Considerazioni sugli Errori di Tipo I e Tipo II\nLa scelta di un livello di significatività \\(\\alpha = 0.05\\) implica che, nel contesto di un test d’ipotesi, esiste una probabilità del 5% di commettere un errore di Tipo I. Questo tipo di errore si verifica quando l’ipotesi nulla è vera ma, a causa della variabilità casuale nei dati del campione, otteniamo risultati abbastanza estremi da rifiutare erroneamente \\(H_0\\).\nUn errore di Tipo II, invece, si verifica quando l’ipotesi nulla è falsa, ma i dati del campione non sono sufficientemente estremi da giustificare il suo rifiuto. La probabilità di commettere un errore di Tipo II è spesso influenzata dalla dimensione del campione: campioni più piccoli tendono ad avere una potenza statistica inferiore, aumentando il rischio di non rifiutare \\(H_0\\) quando sarebbe appropriato farlo. La potenza statistica di un test, che rappresenta la probabilità di rifiutare correttamente l’ipotesi nulla quando è falsa, può essere stimata, ma questa stima può diventare complessa.\nPer i modelli statistici complessi, la stima della potenza può essere particolarmente difficile. Non solo i calcoli possono essere intricati, ma non esiste un metodo unico e standardizzato per effettuare tali stime, richiedendo l’introduzione di diverse assunzioni.\nLa funzione t.test offre un modo per calcolare la potenza di un test in contesti di test statistici relativamente semplici.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html#informazioni-sullambiente-di-sviluppo",
    "title": "\n75  Test t di Student per campioni indipendenti\n",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.17.0      see_0.9.0        gridExtra_2.3    patchwork_1.3.0 \n#&gt;  [5] bayesplot_1.11.1 psych_2.4.12     scales_1.3.0     markdown_1.13   \n#&gt;  [9] knitr_1.49       lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1   \n#&gt; [13] dplyr_1.1.4      purrr_1.0.2      readr_2.1.5      tidyr_1.3.1     \n#&gt; [17] tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3       \n#&gt; [21] here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      shape_1.4.6.1     xfun_0.49         htmlwidgets_1.6.4\n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2      \n#&gt;  [9] generics_0.1.3    parallel_4.4.2    pan_1.9           pacman_0.5.1     \n#&gt; [13] pkgconfig_2.0.3   jomo_2.7-6        Matrix_1.7-1      lifecycle_1.0.4  \n#&gt; [17] compiler_4.4.2    farver_2.1.2      munsell_0.5.1     mnormt_2.1.1     \n#&gt; [21] codetools_0.2-20  htmltools_0.5.8.1 glmnet_4.1-8      nloptr_2.1.1     \n#&gt; [25] pillar_1.10.0     MASS_7.3-61       iterators_1.0.14  rpart_4.1.23     \n#&gt; [29] boot_1.3-31       foreach_1.5.2     mitml_0.4-5       nlme_3.1-166     \n#&gt; [33] tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4     labeling_0.4.3   \n#&gt; [37] splines_4.4.2     rprojroot_2.0.4   fastmap_1.2.0     grid_4.4.2       \n#&gt; [41] colorspace_2.1-1  cli_3.6.3         magrittr_2.0.3    survival_3.8-3   \n#&gt; [45] broom_1.0.7       withr_3.0.2       backports_1.5.0   timechange_0.3.0 \n#&gt; [49] rmarkdown_2.29    nnet_7.3-19       lme4_1.1-35.5     hms_1.1.3        \n#&gt; [53] evaluate_1.0.1    rlang_1.1.4       Rcpp_1.0.13-1     glue_1.8.0       \n#&gt; [57] minqa_1.2.8       jsonlite_1.8.9    R6_2.5.1",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html#bibliografia",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html#bibliografia",
    "title": "\n75  Test t di Student per campioni indipendenti\n",
    "section": "Bibliografia",
    "text": "Bibliografia",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/introduction_replication_crisis.html",
    "href": "chapters/replication_crisis/introduction_replication_crisis.html",
    "title": "Introduzione",
    "section": "",
    "text": "Bibliografia\nIn psicologia, nelle scienze sociali e in altre discipline è in corso una Riforma Metodologica, scaturita da una profonda crisi che ha colpito la scienza contemporanea: la crisi di replicazione dei risultati delle ricerche. Un esempio emblematico è rappresentato dal sito Retraction Watch, che monitora le ritrattazioni di studi scientifici. Questa crisi mina la credibilità della ricerca scientifica e ha spinto a una revisione radicale delle metodologie alla base delle scienze psicologiche e di altre discipline affini (Korbmacher et al., 2023). Le cause della crisi di replicazione sono molteplici: frodi, pratiche di ricerca scorrette e incentivi distorti offerti dal sistema accademico. Una delle cause più rilevanti per un corso sull’analisi dei dati psicologici è l’uso delle tecniche inferenziali di stampo frequentista, che ha contribuito alla proliferazione di pubblicazioni contenenti falsi positivi.\nUn articolo di Altmejd et al. (2019) identifica alcuni fattori semplici ma altamente predittivi della replicabilità degli studi: il campione era di dimensioni adeguate? I ricercatori hanno ottenuto un risultato appena sotto la soglia di significatività di p = 0.05? (Spesso un articolo può rivendicare un risultato “significativo” se questa soglia viene raggiunta, e molti utilizzano vari trucchi statistici per superare tale limite.) Lo studio ha rilevato un effetto sull’intera popolazione studiata o ha individuato un “effetto di interazione” (ad esempio, un effetto presente solo in un segmento più piccolo della popolazione), che è molto meno probabile che si riproduca?\nÈ emerso inoltre che prevedere la replicazione di uno studio è sorprendentemente semplice. Non è necessario un approfondimento della metodologia statistica né un esame rigoroso dei dati, né tantomeno una scrupolosa analisi delle teorie più esoteriche per individuare errori sottili: questi articoli presentano problemi evidenti, a livello superficiale. Uno studio pubblicato su Nature ha coinvolto scienziati in una scommessa su quali studi di scienze sociali sarebbero stati replicati. Camerer et al. (2018) ha scoperto che le previsioni degli scienziati in questo mercato delle scommesse erano estremamente accurate nel determinare quali articoli avrebbero avuto successo nella replicazione.\nUlteriori ricerche hanno dimostrato che non è nemmeno necessario consultare esperti del settore per indovinare quali studi resisteranno a un esame rigoroso. Uno studio di Hoogeveen et al. (2020) ha coinvolto partecipanti senza un background professionale nelle scienze sociali, chiedendo loro di leggere articoli di psicologia e prevedere se questi si sarebbero replicati. “I non-esperti senza una formazione professionale nelle scienze sociali sono in grado di prevedere la replicabilità degli studi con una precisione superiore al caso,” conclude lo studio, “basandosi esclusivamente su semplici descrizioni verbali degli studi.”\nSebbene i non esperti non siano stati altrettanto precisi nelle loro previsioni rispetto agli scienziati nello studio pubblicato su Nature, il fatto che siano comunque riusciti a individuare molte replicazioni fallite suggerisce che molti di questi studi presentano difetti evidenti, riconoscibili anche da chi non è un addetto ai lavori.\nLa pubblicazione di un articolo peer-reviewed non rappresenta l’ultimo passo del processo scientifico. Dopo la pubblicazione, altri studi potrebbero citare l’articolo originale, diffondendo eventuali errori o fraintendimenti. Uno studio di Yang et al. (2020) mostra che non esiste alcuna correlazione tra la replicabilità di uno studio e la sua frequenza di citazione. “Gli studi falliti si diffondono nella letteratura scientifica con la stessa rapidità degli studi replicabili,” affermano Yang et al. (2020). Questo solleva una domanda: se gli scienziati sono abbastanza bravi nel prevedere se uno studio si replicherà, perché sono altrettanto inclini a citare studi non replicabili quanto quelli validi?\nQueste considerazioni suggeriscono che la crisi di replicazione non richiede solo una revisione metodologica, ma è il sintomo di un sistema scientifico che necessita di un ripensamento più ampio. Le riviste scientifiche non sono sufficientemente responsabili per la pubblicazione di articoli discutibili, e il sistema accademico promuove incentivi distorti. In alcuni casi, la cultura accademica sembra addirittura incentivare la produzione di ricerche di bassa qualità. La pressione a pubblicare un elevato numero di articoli favorisce chi riesce a farlo rapidamente, spesso ricorrendo a “scorciatoie”. Di conseguenza, si è creato un sistema in cui gli incentivi continuano a promuovere la cattiva ricerca, nonostante si comprenda sempre meglio cosa costituisca una ricerca di qualità.\nIn questa sezione della dispensa, ci concentreremo su uno dei problemi che stanno alla base della crisi della riproducibilità dei risultati della ricerca, ovvero i limiti dell’inferenza frequentista (Baker, 2016). Analizzeremo gli errori di tipo S e di tipo M, concetti introdotti da Gelman & Carlin (2014), che hanno contribuito a migliorare la comprensione dei limiti della statistica frequentista. Inoltre, discuteremo alcuni possibili metodi per affrontare la crisi e le implicazioni che derivano dall’integrità della ricerca.",
    "crumbs": [
      "Crisi",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/introduction_replication_crisis.html#bibliografia",
    "href": "chapters/replication_crisis/introduction_replication_crisis.html#bibliografia",
    "title": "Introduzione",
    "section": "",
    "text": "Altmejd, A., Dreber, A., Forsell, E., Huber, J., Imai, T., Johannesson, M., Kirchler, M., Nave, G., & Camerer, C. (2019). Predicting the replicability of social science lab experiments. PloS one, 14(12), e0225826.\n\n\nBaker, M. (2016). Reproducibility Crisis. Nature, 533(7604), 452–454.\n\n\nCamerer, C. F., Dreber, A., Holzmeister, F., Ho, T.-H., Huber, J., Johannesson, M., Kirchler, M., Nave, G., Nosek, B. A., Pfeiffer, T., et al. (2018). Evaluating the replicability of social science experiments in Nature and Science between 2010 and 2015. Nature human behaviour, 2(9), 637–644.\n\n\nGelman, A., & Carlin, J. (2014). Beyond Power Calculations: Assessing Type S (Sign) and Type M (Magnitude) Errors. Perspectives on Psychological Science, 9(6), 641–651.\n\n\nHoogeveen, S., Sarafoglou, A., & Wagenmakers, E.-J. (2020). Laypeople can predict which social-science studies will be replicated successfully. Advances in Methods and Practices in Psychological Science, 3(3), 267–285.\n\n\nKorbmacher, M., Azevedo, F., Pennington, C. R., Hartmann, H., Pownall, M., Schmidt, K., Elsherif, M., Breznau, N., Robertson, O., Kalandadze, T., et al. (2023). The replication crisis has led to positive structural, procedural, and community changes. Communications Psychology, 1(1), 3.\n\n\nYang, Y., Youyou, W., & Uzzi, B. (2020). Estimating the deep replicability of scientific findings using human and artificial intelligence. Proceedings of the National Academy of Sciences, 117(20), 10762–10768.",
    "crumbs": [
      "Crisi",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html",
    "href": "chapters/replication_crisis/01_crisis.html",
    "title": "76  La crisi della replicazione",
    "section": "",
    "text": "76.1 Introduzione\nIl presente capitolo introduce la crisi di replicazione che affligge la ricerca psicologica, analizzandone le cause precipue e ponendo in rilievo il ruolo che l’approccio statistico frequentista ha avuto nel concorrere a tale problematica. Il contenuto di questo capitolo costituisce una sintesi rielaborata del testo A student’s guide to open science: Using the replication crisis to reform psychology (Pennington, 2023).",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#cosa-dovrebbe-essere-la-scienza",
    "href": "chapters/replication_crisis/01_crisis.html#cosa-dovrebbe-essere-la-scienza",
    "title": "76  La crisi della replicazione",
    "section": "\n76.2 Cosa dovrebbe essere la scienza",
    "text": "76.2 Cosa dovrebbe essere la scienza\nPennington (2023) avvia la sua discussione sulla crisi di replicazione delineando le caratteristiche di uno scenario “ideale” cui la prassi scientifica dovrebbe aspirare. Affinché la psicologia possa essere considerata una disciplina scientifica a pieno titolo, è imprescindibile l’adesione ai principi di replicabilità e riproducibilità. In altri termini, qualora un effetto sia reale e robusto, qualsiasi ricercatore, a parità di procedure e con un’adeguata dimensione campionaria, dovrebbe essere in grado di rilevarlo. Ulteriori attributi auspicabili della ricerca scientifica sono i seguenti:\n\n\nCredibile: La scienza dovrebbe essere credibile, non incredibile. Gli scienziati dovrebbero essere disposti a sottoporre le loro affermazioni e scoperte a un esame equo e rigoroso.\n\n\nAffidabile: I risultati scientifici dovrebbero essere riportati in modo accurato. Il pubblico dovrebbe poterli considerare attendibili e usarli per prendere decisioni informate.\n\n\nTrasparente: La scienza dovrebbe essere assolutamente chiara. I metodi e i risultati scientifici dovrebbero essere descritti in dettaglio, permettendo repliche indipendenti, valutazioni e l’accumulo di conoscenze.\n\n\nAccessibile: La scienza dovrebbe essere accessibile a tutti. Sia i ricercatori sia il pubblico generale dovrebbero poter accedere, leggere e valutare facilmente i risultati scientifici.\n\n\nInclusiva: La scienza dovrebbe essere diversificata e inclusiva. Gli scienziati appartenenti a gruppi sottorappresentati dovrebbero avere pari opportunità di partecipazione e accesso.\n\n\nCollaborativa: La scienza dovrebbe massimizzare l’uso delle risorse disponibili, incoraggiando la cooperazione tra ricercatori piuttosto che la competizione, per produrre lavori di alta qualità.\n\n\nAutocorrettiva: La scienza dovrebbe basarsi su prove accurate nel perseguimento della conoscenza. Gli errori riscontrati negli articoli dovrebbero essere corretti e spiegati, rendendo questa pratica normale nel processo scientifico.\n\nA questo punto, Pennington (2023) propone una riflessione retorica: “Immaginate di chiudere gli occhi e visualizzare uno scienziato stereotipato. Quale immagine vi si presenta? Quali azioni compie? Quali sono i suoi comportamenti?”.\nL’autore offre la propria visualizzazione: “Io vedo un uomo bianco, di mezza età, all’interno di un laboratorio contrassegnato da un grande cartello con la scritta ‘DIVIETO DI ACCESSO!’. I suoi risultati rappresentano un tesoro personale, gelosamente custodito, precluso a qualsiasi osservatore esterno. Egli teme che qualcuno possa appropriarsi delle sue brillanti intuizioni, replicare il suo lavoro o tentare di riprodurne i risultati. Si tratta della sua scienza, non di una scienza condivisa.”\nTale rappresentazione incarna una scienza priva di trasparenza, accessibilità e spirito collaborativo.\nNella psicologia contemporanea è in corso un ampio dibattito su quali cambiamenti siano necessari per superare le criticità emerse negli ultimi anni e promuovere una scienza più rigorosa e affidabile. Nonostante la scienza si fondi su principi chiave, come replicabilità e riproducibilità, la prassi scientifica non è sempre stata coerente con questi ideali. Questa discrepanza ha portato a ciò che molti definiscono una crisi nella psicologia moderna.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#la-crisi-della-replicazione-in-psicologia",
    "href": "chapters/replication_crisis/01_crisis.html#la-crisi-della-replicazione-in-psicologia",
    "title": "76  La crisi della replicazione",
    "section": "\n76.3 La Crisi della Replicazione in Psicologia",
    "text": "76.3 La Crisi della Replicazione in Psicologia\nNegli ultimi decenni, la psicologia si è trovata al centro di una crisi che ha messo in discussione molte delle sue basi epistemologiche e metodologiche: la crisi della replicazione. Questo fenomeno indica l’incapacità di replicare con successo un’ampia parte degli studi pubblicati, con implicazioni rilevanti per la cultura accademica e il modo di concepire la ricerca scientifica (Parsons et al., 2022).\nPer fallimento della replicazione si intende il caso in cui uno studio, ripetuto da altri ricercatori seguendo le stesse procedure e utilizzando campioni simili, non riesce a ottenere risultati comparabili a quelli originali. Questo ha portato alla luce problemi sistemici legati alla metodologia di ricerca, all’interpretazione dei dati e alle dinamiche del sistema accademico. La crisi della replicazione ha dunque evidenziato la necessità di un cambiamento strutturale nella pratica scientifica, sottolineando l’urgenza di un approccio più trasparente, rigoroso e collaborativo.\nNelle sezioni seguenti vengono presentati gli eventi chiave di quella che possiamo chiamare la storia della crisi della replicazione.\n\n76.3.1 2005: “Perché la maggior parte dei risultati pubblicati è falsa” (Ioannidis)\nUn primo momento cruciale è stato l’articolo di “Why Most Published Research Findings Are False” (Ioannidis, 2005) che ha evidenziato come molti risultati scientifici fossero in realtà falsi positivi. Ioannidis attribuì questo fenomeno a campioni di piccole dimensioni, un’eccessiva enfasi sui valori-p per indicare significatività, flessibilità nei metodi di analisi e la competizione per produrre risultati “innovativi”. Questo articolo ha messo in luce problemi che trascendono la psicologia, ma che in seguito sarebbero emersi come centrali anche per questa disciplina.\n\n76.3.2 2011: Lo Studio di Daryl Bem, “Feeling the Future”\nUno degli eventi più controversi è stato lo studio di Daryl Bem “Feeling the Future” (Bem, 2011), che suggeriva l’esistenza della precognizione, ovvero la capacità di “sentire” eventi futuri. Attraverso nove esperimenti, Bem pubblicò risultati statisticamente significativi che sembravano sfidare le leggi della causalità.\nLo studio di Bem si inseriva nella tradizione degli esperimenti di “priming”, una tecnica ampiamente utilizzata in psicologia sociale dagli anni ’70. Gli esperimenti di priming tipicamente coinvolgevano studenti universitari, remunerati con modeste somme o crediti accademici. I partecipanti venivano esposti a determinati concetti per poi osservare come questi influenzassero il loro comportamento successivo. Un celebre esempio è lo studio di John Bargh del 1996, che dimostrò come l’esposizione a parole associate all’età avanzata inducesse i soggetti a camminare più lentamente (Bargh et al., 1996). Un altro studio del 2006 rivelò che il priming con concetti legati al denaro rendeva le persone meno propense ad aiutare gli altri. Questi studi sembravano dimostrare una straordinaria malleabilità della mente umana, suggerendo che il nostro comportamento potesse essere inconsciamente manipolato da sottili segnali ambientali. Tuttavia, lo studio di Bem introdusse un elemento nuovo in questo paradigma sperimentale.\nTra i vari esperimenti condotti da Bem, uno in particolare si distingueva. I soggetti venivano esposti a una parola con connotazione positiva o negativa e successivamente dovevano valutare rapidamente la piacevolezza di alcune immagini. Fin qui, nulla di insolito. La svolta radicale consisteva nel fatto che in metà delle prove, il priming avveniva dopo che i soggetti avevano già visto e valutato l’immagine (Bem, 2011).\nSorprendentemente, i risultati mostravano che il priming funzionava anche in queste condizioni: i partecipanti erano più veloci a giudicare piacevoli le immagini quando successivamente venivano esposti a una parola positiva. Questo effetto risultava statisticamente significativo, con un p-value di 0.01, sufficiente secondo gli standard correnti per rifiutare l’ipotesi nulla.\nBem interpretò questi risultati come prova della chiaroveggenza, una conclusione che suscitò notevoli controversie e ridicolizzò la psicologia. Gli altri otto esperimenti dello studio, tutti basati su classici paradigmi della psicologia sociale con l’ordine temporale invertito, mostrarono risultati altrettanto statisticamente significativi.\nQuesti risultati ponevano la comunità scientifica di fronte a un dilemma: accettare l’esistenza di fenomeni paranormali o mettere in discussione le pratiche statistiche e metodologiche consolidate nella disciplina. Bem stesso continua a sostenere la validità dei suoi risultati come prova dell’esistenza di capacità precognitive.\nSebbene pubblicato su una rivista prestigiosa, lo studio sollevò enormi dubbi metodologici. Le repliche successive non riuscirono a confermare i risultati di Bem, mostrando come pratiche discutibili, quali il p-hacking (modifiche al metodo di analisi per ottenere risultati significativi), potessero produrre falsi positivi apparentemente robusti.\n\n76.3.3 2011: Il Caso di Frode di Diederik Stapel\nNello stesso anno, Diederik Stapel, una figura di spicco della psicologia sociale, fu accusato di aver falsificato dati in decine di studi pubblicati. Tra i suoi esperimenti più famosi vi era quello secondo cui ambienti disordinati aumenterebbero il razzismo. Un altro studio suggeriva che mangiare carne rendeva le persone più antisociali. Tuttavia, si scoprì che per quegli studi, e molti altri, non aveva mai condotto gli esperimenti né raccolto i dati. Li aveva semplicemente inventati. A volte le frodi accadono. Stapel fu scoperto (alla fine), licenziato e decine dei suoi articoli furono ritirati. Questo scandalo scosse profondamente la comunità accademica e divenne un simbolo della crisi.\n\n76.3.4 2011: La Meta-ricerca e le Pratiche di Ricerca Discutibili (QRPs)\nLa meta-ricerca è un campo di studio che si concentra sul modo in cui viene condotta la ricerca scientifica. Comprende temi come i metodi, la trasparenza nella comunicazione, la riproducibilità, la valutazione e i sistemi di incentivi che regolano la scienza (Ioannidis et al., 2015). Questo ambito è emerso con urgenza dopo una serie di casi controversi e di frodi conclamate, come gli studi di Daryl Bem e Diederik Stapel, che hanno evidenziato falle nei processi di ricerca. I ricercatori hanno così iniziato ad analizzare pratiche note come Questionable Research Practices (QRPs, Pratiche di Ricerca Discutibili), che sfruttano aree grigie nelle norme scientifiche per raccogliere e analizzare i dati.\nSimmons et al. (2011) hanno dimostrato come la flessibilità nella raccolta, analisi e comunicazione dei dati permetta ai ricercatori di far apparire “significativo” praticamente qualsiasi risultato. Tra le pratiche discusse, spiccano:\n\n\nOptional stopping: Interrompere la raccolta dei dati non appena si raggiunge la significatività statistica, invece di seguire un piano prestabilito.\n\n\nP-hacking: Condurre molteplici test non pianificati, selezionando variabili o analisi solo quando producono un valore p inferiore a 0.05.\n\n\nHARKing (Hypothesizing After Results are Known): Modificare le ipotesi a posteriori per adattarle ai risultati ottenuti, presentandole come ipotesi iniziali.\n\nQueste pratiche non solo compromettono l’integrità scientifica, ma rendono estremamente facile produrre falsi positivi. Per dimostrarlo, Simmons e colleghi hanno condotto simulazioni al computer e due esperimenti, rivelando quanto fosse “troppo facile” raccogliere prove a sostegno di ipotesi false.\nLa portata di queste pratiche è sorprendente. Simmons et al. hanno scoperto che:\n\nUsare una sola QRP può quasi raddoppiare il tasso di falsi positivi, portandolo dal 5% al 10%.\n\nCombinare più QRPs può far salire questa percentuale oltre il 60%.\n\nPer sottolineare il problema, i ricercatori hanno dimostrato, in modo volutamente ironico, che ascoltare la canzone dei Beatles “When I’m Sixty-Four” potrebbe far apparire le persone più giovani di quanto fossero prima di ascoltarla. Questa dimostrazione satirica evidenziava che inseguire la significatività statistica senza un rigore metodologico può produrre risultati assurdi.\nJohn et al. (2012) hanno condotto un’indagine su larga scala, intervistando 2000 ricercatori per comprendere la diffusione delle QRPs. Con un approccio innovativo, hanno chiesto ai partecipanti non solo di riferire le proprie pratiche, ma anche quelle dei colleghi. I risultati sono stati sconvolgenti:\n\nOltre il 60% degli intervistati ha ammesso di non aver riportato tutte le variabili dipendenti misurate.\n\nPiù del 50% ha interrotto la raccolta dati non appena ottenuti risultati significativi (optional stopping).\n\nPiù del 40% ha selezionato e riportato solo esperimenti “riusciti”.\n\nSorprendentemente, i ricercatori tendevano a dichiarare che i colleghi adottavano queste pratiche più frequentemente di loro stessi. Molti giustificavano queste pratiche come “norme accademiche” del tempo.\nLa meta-ricerca ha giocato un ruolo cruciale nell’aprire gli occhi della comunità scientifica sui pericoli di queste decisioni apparentemente “banali”. In un contesto in cui le QRPs erano ampiamente accettate, la meta-ricerca ha evidenziato come queste pratiche possano seriamente danneggiare il progresso scientifico. Grazie al movimento dell’Open Science, si stanno introducendo norme che migliorano la credibilità della ricerca, spostando l’enfasi dalla produzione di risultati “significativi” alla conduzione di studi rigorosi e trasparenti.\n\n76.3.5 2012: La Crisi di Fiducia della Psicologia\nSiamo nel 2012, un anno segnato da una serie di eventi che spingono Harold Pashler ed Eric-Jan Wagenmakers a dichiarare che la psicologia sta affrontando una “crisi di fiducia”. In un numero speciale della rivista Perspectives on Psychological Science (PoPs), i due autori raccolgono una molteplicità di prospettive sulla nascente crisi della replicazione, cercando di individuarne le cause e le implicazioni.\nLe reazioni alla crisi sono variegate e, in alcuni casi, contrastanti. Alcuni studiosi sostengono che le affermazioni di una crisi siano premature (Stroebe e Strack, 2014) e che i problemi di replicazione non siano un fenomeno nuovo (Spellman, 2015). Altri, invece, sottolineano come incentivare e valorizzare gli studi di replicazione rappresenti un metodo efficace e diretto per migliorare la qualità della scienza psicologica (Koole e Lakens, 2012).\nIl numero speciale evidenzia anche iniziative in corso per affrontare il problema. Tra queste, l’Open Science Collaboration (OSC), un progetto di larga scala avviato nel 2012, si propone di verificare empiricamente se la psicologia sia effettivamente alle prese con una crisi della replicazione. L’obiettivo del progetto è ambizioso: replicare numerosi studi pubblicati per valutare la robustezza dei risultati originari. Sebbene i risultati di questa iniziativa non fossero ancora disponibili al momento della pubblicazione del numero speciale, il progetto rappresentava già una pietra miliare per la disciplina.\nNonostante le preoccupazioni, il numero speciale si chiude con una nota positiva, destinata a risuonare nella comunità scientifica. I casi di frode, le pratiche di ricerca discutibili (QRPs) e i fallimenti nei tentativi di replicazione, sebbene dannosi, hanno aperto la strada a una riflessione critica. Questo processo ha permesso alla psicologia di affrontare i propri limiti, correggere errori, superare i bias e costruire una letteratura più affidabile e trasparente.\nQuesto periodo storico segna un punto di svolta: la crisi di fiducia ha messo in discussione le fondamenta della disciplina, ma ha anche creato l’opportunità per un rinnovamento scientifico, stimolando pratiche più rigorose e una maggiore attenzione alla replicabilità e alla trasparenza.\n\n76.3.6 2014: Il Progetto “Many Labs”\nNel 2014 fu pubblicato il primo tentativo su larga scala di replicare risultati psicologici: il progetto “Many Labs”. Questo imponente sforzo collaborativo, guidato da Klein et al. (2014), testò la replicabilità di 13 risultati classici della psicologia, coinvolgendo 6344 partecipanti in 12 paesi. Gli studi selezionati rispettavano tre criteri principali: erano relativamente brevi, avevano un design semplice e potevano essere facilmente condotti online.\nTra i fenomeni esaminati figurava la fallacia del costo irrecuperabile (sunk cost fallacy), secondo cui le persone tendono a proseguire un’attività quando vi hanno già investito tempo, sforzi o denaro. Un esempio classico: se hai acquistato un biglietto per vedere la tua squadra di calcio preferita e, il giorno della partita, inizia a piovere a dirotto, sarai più propenso a partecipare perché hai già speso i soldi per il biglietto (Oppenheimer e Monin, 2009).\nAltri studi replicati includevano:\n\nL’influenza del framing dei guadagni e delle perdite sul rischio (Tversky e Kahneman, 1981).\n\nLe differenze di genere negli atteggiamenti impliciti verso la matematica e le arti (Nosek et al., 2002).\n\nI risultati sembravano promettenti: il 77% degli studi replicò con successo i risultati originali (10 su 13). Tuttavia, non tutti gli studi fornirono lo stesso livello di evidenza. Ad esempio:\n\nUno studio sull’efficacia del contatto sociale immaginato nel ridurre i pregiudizi (Husnu e Crisp, 2010) mostrò supporto limitato, con solo 4 campioni su 36 che evidenziarono un effetto significativo.\n\nDue studi di priming non furono replicati. Nel primo, i ricercatori non trovarono che l’esposizione alla bandiera americana aumentasse il conservatorismo (Carter et al., 2011). Nel secondo, il priming con concetti legati al denaro non portò a un incremento delle credenze o dei comportamenti capitalistici (Caruso et al., 2013).\n\nSebbene i risultati fossero accolti come una vittoria per la replicabilità, alcuni ricercatori sottolinearono limiti nel progetto Many Labs 1. Gli stessi autori riconobbero che molti degli studi selezionati erano già noti per essere altamente replicabili. Secondo alcuni critici, il principale contributo di questo progetto era dimostrare che almeno dieci effetti psicologici erano replicabili, ma non forniva una panoramica più ampia sulla replicabilità complessiva nella psicologia (Yarkoni, 2013).\nQuesto progetto rappresentò comunque un passo fondamentale per affrontare la crisi della replicazione, sottolineando l’importanza della collaborazione scientifica e del rigore metodologico.\n\n76.3.7 2015: Il Progetto di Riproducibilità della Open Science Collaboration\nNel 2015, la Open Science Collaboration (OSC) pubblicò i risultati del Reproducibility Project: Psychology, dimostrando che la buona scienza richiede tempo e rigore. Superando i limiti del progetto Many Labs 1, un team composto da oltre 270 ricercatori internazionali si impegnò a replicare 100 studi scelti casualmente da riviste di punta nel campo della psicologia.\nPer garantire risultati solidi e inattaccabili, il team adottò una metodologia rigorosa:\n- Consultazione con gli autori originali: gli autori degli studi originali furono coinvolti per confermare il design sperimentale e ridurre al minimo eventuali discrepanze.\n- Aumento delle dimensioni campionarie: i campioni furono ampliati per garantire una potenza statistica sufficiente.\n- Registrazione preventiva dei metodi: i piani di analisi e raccolta dati furono registrati in anticipo per prevenire bias da parte dei ricercatori.\nGli studi selezionati per la replicazione includevano domande di ricerca come:\n- La convinzione che il comportamento umano sia predeterminato incoraggia il tradimento?\n- I bambini seguono automaticamente lo sguardo per trovare oggetti nascosti?\n- È possibile osservare un “effetto after-motion” da fotografie fisse che rappresentano movimento?\nI risultati del progetto fecero scalpore e conquistarono i titoli dei giornali a livello globale. Solo il 36% degli studi replicò con successo, ottenendo un valore-p inferiore a 0.05. La psicologia sociale si rivelò particolarmente problematica, con un tasso di replicazione del 25%, rispetto al 50% degli studi di psicologia cognitiva.\nPer contestualizzare questi numeri, se gli effetti originali fossero stati realmente validi, il tasso minimo di replicazione atteso sarebbe stato dell’89% (Field et al., 2019). Anche tra gli studi replicati, le dimensioni degli effetti risultarono dimezzate rispetto a quelle riportate negli studi originali.\nQuesti risultati provocarono una forte reazione nella comunità scientifica. Ci si chiedeva: era la fine della psicologia? La disciplina avrebbe mai recuperato credibilità? Sebbene i dati fossero allarmanti, aprirono un dibattito più ampio. Come sottolineato da Kuhn (1962) e Redish et al. (2018), fallimenti nella replicazione possono segnare l’inizio di una rivoluzione scientifica, stimolando un ripensamento dei metodi, delle ipotesi e delle pratiche di ricerca.\nIl Reproducibility Project: Psychology non solo mise in luce le fragilità della disciplina, ma divenne un punto di partenza per migliorare la trasparenza, la collaborazione e la robustezza nella ricerca psicologica.\n\n76.3.8 2015: 1500 Scienziati Sollevano il Velo sulla Riproducibilità\nI risultati del progetto dell’Open Science Collaboration (2015) colpirono il mondo della psicologia come un fulmine a ciel sereno. Molti risultati psicologici, considerati affidabili, crollarono improvvisamente, generando un’ondata di discussioni nei dipartimenti universitari: quale sarebbe stato il prossimo “effetto” a fallire? Tuttavia, nonostante la psicologia fosse diventata l’emblema delle repliche fallite, presto si comprese che non era un problema esclusivo della disciplina.\nNel 2016, Baker condusse un’indagine su 1500 scienziati provenienti da diverse discipline, tra cui chimica, medicina, fisica e ingegneria, per esplorare le preoccupazioni riguardo alla replicazione e alla riproducibilità. I risultati furono sorprendenti: circa il 90% dei partecipanti concordò sull’esistenza di una crisi di riproducibilità, definita come significativa dal 52% e lieve dal 38%.\nUn dato particolarmente allarmante emerse dall’indagine:\n\nIn media, il 40% degli scienziati aveva riscontrato difficoltà nel riprodurre i propri esperimenti.\n\nQuesta percentuale saliva a oltre il 60% quando si tentava di riprodurre gli esperimenti di altri ricercatori.\n\nTra le discipline, la chimica risultò la più problematica, con oltre l’85% dei ricercatori che riportavano fallimenti nel riprodurre i risultati altrui.\nL’articolo di Baker riportava anche esperienze personali che riflettevano il senso di smarrimento generato da questa crisi. Il professor Marcus Munafò, per esempio, descrisse così il suo percorso:\n\n“Ho cercato di replicare ciò che dalla letteratura sembrava semplice, ma non ci sono riuscito. Ho avuto una crisi di fiducia, e poi ho scoperto che questa esperienza non era affatto rara.” (Baker, 2016, p. 452)\n\nL’indagine di Baker non si limitò a evidenziare il problema, ma esplorò anche le possibili cause della crisi, come pratiche metodologiche inadeguate e pressioni accademiche, offrendo al contempo suggerimenti per interventi correttivi.\nL’indagine segnò un momento cruciale: la crisi della riproducibilità, inizialmente confinata a discussioni accademiche, raggiunse una visibilità globale. Non era più solo un problema della psicologia, ma un fenomeno che colpiva l’intero mondo scientifico, portando con sé la necessità di una trasformazione radicale delle pratiche di ricerca.\nQuesto evento contribuì a consolidare il riconoscimento della crisi della riproducibilità come una sfida centrale per tutta la scienza, spingendo verso un cambiamento culturale che mettesse al centro trasparenza, rigore e collaborazione.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#la-cultura-della-frode-nel-sistema-accademico",
    "href": "chapters/replication_crisis/01_crisis.html#la-cultura-della-frode-nel-sistema-accademico",
    "title": "76  La crisi della replicazione",
    "section": "\n76.4 La Cultura della Frode nel Sistema Accademico",
    "text": "76.4 La Cultura della Frode nel Sistema Accademico\nIn alcuni casi, la crisi della replicazione si intreccia con episodi di frode scientifica, rivelando un lato oscuro della ricerca accademica. Uno degli aspetti più preoccupanti è che il sistema accademico, con i suoi meccanismi di incentivo basati su pubblicazioni frequenti e finanziamenti competitivi, può indirettamente favorire comportamenti disonesti. Questo sistema, orientato al publish or perish (pubblica o scompari), crea pressioni che talvolta spingono i ricercatori a compromettere l’integrità scientifica per raggiungere i propri obiettivi di carriera.\n\n76.4.1 Il Caso Brian Wansink\nUn caso emblematico è quello di Brian Wansink, ex ricercatore di spicco alla Cornell University, che ricevette cospicui finanziamenti federali durante l’amministrazione Obama. I suoi studi sul comportamento alimentare, come quello sugli uomini che mangiano di più in presenza di donne o sull’effetto dei nomi “attraenti” dati alle verdure sul consumo da parte dei bambini, attirarono grande attenzione mediatica ma si rivelarono in seguito non replicabili. Le conseguenze per Wansink furono severe: diciotto suoi articoli furono ritirati, sette ricevettero “espressioni di preoccupazione”, e quindici furono corretti. Nel 2019, Wansink si dimise dalla Cornell University dopo essere stato giudicato colpevole di cattiva condotta scientifica.\n\n76.4.2 Il Caso Sylvain Lesné\nUn altro esempio rilevante riguarda Sylvain Lesné e i suoi coautori che, nel 2006, pubblicarono su Nature un importante articolo sul morbo di Alzheimer. Questo lavoro era fondamentale per lo sviluppo dell’ipotesi amiloide, un meccanismo proposto per spiegare come la malattia affligge le sue vittime. La ricerca sulla malattia di Alzheimer, che colpisce oltre 50 milioni di persone nel mondo, ha ricevuto oltre un miliardo di dollari in finanziamenti governativi fino al 2022, incoraggiata da studi come quello di Lesné.\nNel 2022, il neuroscienziato Matthew Schrag scoprì immagini manipolate in questo e in molti altri articoli di Lesné, inclusi quelli che sostenevano l’ipotesi amiloide. Le immagini erano state manualmente modificate e accorpate per mostrare falsamente supporto alle ipotesi degli articoli. Queste frodi passarono inosservate attraverso i processi di peer review formali di Nature e di altre sei riviste accademiche, venendo infine scoperte solo tramite canali non ufficiali.\nLe conseguenze di queste scoperte furono lente e frammentarie. Gli altri coautori dell’articolo del 2006 alla fine accettarono di ritirarlo, ma non Lesné stesso. La lentezza della risposta a queste evidenze di frode, e il fatto che Lesné continui a essere finanziato dal National Institutes of Health e impiegato presso l’Università del Minnesota, dimostra un fallimento sistemico nell’affrontare la cattiva condotta scientifica.\n\n76.4.3 Altri Casi di Rilievo\nNel mondo accademico, diversi altri recenti scandali hanno messo in luce il problema della frode scientifica e le sue conseguenze spesso limitate per i responsabili. Ecco alcuni casi emblematici:\n\nMarc Tessier-Lavigne, ex presidente della Stanford University: Nel 2023, fu costretto a dimettersi dopo la rivelazione di dati falsificati in sue ricerche precedenti presso Genentech. Nonostante lo scandalo, Tessier-Lavigne ha subito conseguenze minime, diventando successivamente CEO di una nuova azienda di ricerca farmacologica. Lo scandalo fu portato alla luce grazie all’indagine condotta da Theo Baker, uno studente diciassettenne di Stanford.\n\nDan Ariely e Francesca Gino: Questi due rinomati psicologi, noti per le loro ricerche sulla disonestà e il comportamento non etico, sono stati coinvolti in uno scandalo di frode scientifica.\n\nDan Ariely, nel 2021, fu implicato nella fabbricazione di dati in un articolo del 2012 sulla disonestà.\nFrancesca Gino, docente presso la Harvard Business School, è stata accusata di aver presentato lavori contenenti risultati falsificati. Il sito del Dipartimento ora riporta che è in “administrative leave”.\n\n\n\nL’inefficacia delle istituzioni accademiche nel gestire la frode scientifica sembra riflettere un problema culturale di carattere sistemico. Gli incentivi attuali favoriscono la pubblicazione di risultati positivi e innovativi, spesso a scapito dell’integrità scientifica. Gli studiosi che resistono a queste pressioni rischiano di essere emarginati, mentre chi adotta pratiche discutibili per ottenere risultati desiderati viene premiato con finanziamenti, promozioni e prestigio accademico.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#cosa-significa-fallimento-della-replicazione",
    "href": "chapters/replication_crisis/01_crisis.html#cosa-significa-fallimento-della-replicazione",
    "title": "76  La crisi della replicazione",
    "section": "\n76.5 Cosa Significa “Fallimento della Replicazione”?",
    "text": "76.5 Cosa Significa “Fallimento della Replicazione”?\nIl fallimento della replicazione non coincide necessariamente con l’idea che il fenomeno studiato sia inesistente. Al contrario, le cause di un esito negativo in un tentativo di replicazione possono essere molteplici e spesso difficili da individuare con precisione. Comprendere queste ragioni è fondamentale per identificare le criticità metodologiche, migliorare il rigore scientifico e favorire il progresso della conoscenza. Al di là dei casi evidenti di frode, i fallimenti della replicazione rappresentano un’opportunità per riflettere sulla qualità delle pratiche di ricerca.\n\n76.5.1 Possibili Cause di Fallimento nella Replicazione\n\nFalsi positivi nello studio originale\nUn fallimento può indicare che lo studio originale abbia rilevato un effetto inesistente per puro caso. Questo rischio è particolarmente elevato in studi con campioni di piccole dimensioni e bassa potenza statistica, dove gli effetti riportati risultano spesso sovrastimati o instabili.\n\nFalsi negativi nella replica\nIl fallimento può derivare da un falso negativo, ovvero la mancata rilevazione di un effetto realmente esistente. Le cause principali includono:\n\nDifferenze metodologiche o di popolazione tra studio originale e replica.\n\nConfondenti metodologici o una potenza statistica insufficiente.\n\nPresenza di variabili moderatrici che influenzano l’intensità dell’effetto in determinati contesti.\n\n\n\n76.5.2 La Scienza tra Incertezza e Riproducibilità\nLa scienza raramente offre certezze assolute. Come evidenziato dall’Open Science Collaboration, un singolo studio, sia esso originale o di replica, non è sufficiente a fornire una risposta definitiva. Solo replicazioni multiple e sistematiche possono distinguere effetti reali da errori casuali, offrendo una visione più affidabile di un fenomeno. Questo approccio richiede tempo e risorse, ma rappresenta il cuore del metodo scientifico.\n\n76.5.3 Psicologia e Altri Campi\nSebbene la crisi della replicazione sia stata ampiamente discussa in psicologia, problemi simili affliggono molte altre discipline scientifiche. Studi di replicazione hanno evidenziato risultati preoccupanti: in oncologia, meno della metà degli studi replicati ha prodotto risultati coerenti, con tassi di riproducibilità estremamente bassi in alcuni casi; nelle neuroscienze, i tentativi di replicare correlazioni cervello-comportamento hanno mostrato un altissimo tasso di insuccesso. Anche in discipline come l’economia e la filosofia sperimentale, pur registrando tassi di replicazione relativamente più elevati, permangono dubbi sulla selezione degli studi replicati e sulla rappresentatività dei risultati (Pennington, 2023).\nQuesti dati dimostrano che la problematica della replicazione non è esclusiva della psicologia, ma comune a diverse aree del sapere. Tuttavia, sollevano anche un interrogativo critico: è corretto parlare di “crisi” o si tratta piuttosto di una fase di trasformazione necessaria per migliorare il rigore e la trasparenza nella ricerca scientifica?",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#dibattito-sulla-natura-della-crisi",
    "href": "chapters/replication_crisis/01_crisis.html#dibattito-sulla-natura-della-crisi",
    "title": "76  La crisi della replicazione",
    "section": "\n76.6 Dibattito sulla Natura della Crisi",
    "text": "76.6 Dibattito sulla Natura della Crisi\nIl tema della crisi della replicazione ha suscitato un dibattito acceso e opinioni contrastanti all’interno della comunità scientifica:\n\nApproccio alle repliche: Alcuni ricercatori ritengono che le repliche esatte siano poco significative, preferendo le repliche concettuali che possano approfondire la comprensione di un fenomeno. Altri, invece, sostengono che solo repliche rigorose ed esatte siano in grado di verificare la robustezza di un effetto, garantendo maggiore affidabilità.\nInterpretazione dei dati dell’Open Science Collaboration (OSC): Il tasso di successo delle repliche riportato dall’OSC, pari al 36%, ha alimentato ulteriori discussioni. Alcuni attribuiscono questo risultato a differenze metodologiche tra studi originali e tentativi di replica, come campioni diversi o contesti modificati. Tuttavia, ricerche successive hanno smentito queste ipotesi, indicando che tali variazioni non spiegano interamente i bassi tassi di replicazione.\n\nInvece di considerare i fallimenti di replicazione come una crisi, molti studiosi li interpretano come un’opportunità per rafforzare la scienza. La replicazione, infatti, rappresenta un elemento fondamentale del metodo scientifico: permette di identificare i limiti di un fenomeno e di migliorare la comprensione delle condizioni in cui si manifesta. Ogni fallimento diventa, così, uno stimolo per il progresso.\nQuesta visione ha dato origine a un movimento noto come “rivoluzione della credibilità”, che punta a migliorare la qualità della ricerca attraverso trasparenza, autocorrezione e valorizzazione delle repliche. Progetti come il Loss of Confidence dimostrano che riconoscere i limiti e le incertezze degli studi precedenti non rappresenta una debolezza, ma un segno di integrità scientifica.\nIl passaggio dalla percezione di crisi a una rivoluzione della credibilità rappresenta un profondo cambiamento culturale nella comunità accademica. La scienza non è un processo statico, ma un percorso dinamico che evolve grazie al confronto critico e alla riflessione. In questa prospettiva, ogni fallimento nella replicazione non è un punto d’arrivo, ma un trampolino di lancio verso una conoscenza più affidabile e trasparente.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#cause-della-crisi",
    "href": "chapters/replication_crisis/01_crisis.html#cause-della-crisi",
    "title": "76  La crisi della replicazione",
    "section": "\n76.7 Cause della Crisi",
    "text": "76.7 Cause della Crisi\n\n76.7.1 Incentivi Accademici e la Quantità che Sovrasta la Qualità\nPer comprendere i problemi legati alla ricerca, è necessario analizzare da vicino il contesto in cui operano i ricercatori. Nonostante l’immagine idealizzata degli scienziati come obiettivi e razionali, non dobbiamo dimenticare che sono anche esseri umani, con ambizioni di carriera, responsabilità economiche e pressioni lavorative. Le loro performance sono continuamente valutate: oltre a insegnare e gestire incarichi amministrativi, devono pubblicare articoli in riviste di alto livello e ottenere finanziamenti per sostenere i propri gruppi di ricerca. Questo sistema incentiva la quantità a scapito della qualità, alimentando una mentalità di “pubblica o perisci”.\nQuesta pressione genera un paradosso: ciò che è vantaggioso per la carriera di uno scienziato spesso non coincide con ciò che è meglio per il progresso scientifico. Le motivazioni intrinseche di fare buona scienza vengono sopraffatte da motivazioni estrinseche legate a metriche di produttività. Non sorprende che oltre il 60% dei ricercatori identifichi questa pressione come la causa principale dei problemi di replicazione e riproducibilità.\n\n76.7.2 Bias Cognitivi e Distorsioni nella Ricerca\nI bias cognitivi rappresentano un ulteriore ostacolo alla qualità della ricerca. Tra i principali si trovano:\n\n\nBias di conferma: la tendenza a cercare o interpretare informazioni che confermano le proprie ipotesi iniziali, trascurando dati contrari.\n\nApofenia: il riconoscimento di schemi in dati casuali, spesso combinato con una preferenza per risultati positivi.\n\nBias retrospettivo: la convinzione che un evento fosse prevedibile solo dopo che si è verificato, portando i ricercatori a presentare risultati in modo fuorviante.\n\nQuesti bias favoriscono la ricerca di risultati positivi a scapito di quelli nulli o contrari, contribuendo a creare un problema più grande: il bias di pubblicazione.\n\n76.7.3 Bias di Pubblicazione e il Problema dei “File Drawer”\nIl sistema di pubblicazione accademica incentiva risultati innovativi e positivi, spesso trascurando studi con risultati nulli o repliche. Questo bias, noto come file drawer problem, descrive la tendenza a relegare nei “cassetti” studi non statisticamente significativi, rendendoli inaccessibili e distorcendo la letteratura scientifica.\nIn psicologia, l’impatto di questo fenomeno è particolarmente grave. Studi hanno rilevato che oltre il 90% degli articoli in psicologia riporta risultati positivi, una percentuale notevolmente più alta rispetto ad altre discipline. Questo non solo crea una rappresentazione distorta della realtà, ma amplifica il rischio di undead theories, teorie prive di solide basi empiriche che continuano a dominare il dibattito scientifico.\n\n76.7.4 Pratiche di Ricerca Dubbiamente Etiche\nLa pressione a pubblicare ha portato all’emergere di comportamenti noti come Questionable Research Practices (QRPs). Tra questi:\n\n\nP-hacking: manipolazione dei dati o analisi fino a ottenere un p-value significativo (&lt; 0.05).\n\nHARKing (Hypothesizing After Results are Known): modificare l’ipotesi iniziale per adattarla ai risultati ottenuti.\n\nStopping opzionale: interrompere la raccolta dei dati quando si raggiunge un p-value desiderato.\n\nQueste pratiche, pur non essendo sempre considerate frodi, distorcono i risultati e compromettono la replicabilità degli studi, creando teorie difficili da falsificare.\n\n76.7.5 La Centralità dei Valori-p e la Crisi della Significatività Statistica\nIl valore-p, elemento centrale della metodologia scientifica basata sull’ipotesi nulla (Null Hypothesis Significance Testing), è diventato una “valuta” per la pubblicazione. Tuttavia, affidarsi esclusivamente ai valori-p presenta gravi limiti:\n\n\nParadosso di Lindley: con campioni di grandi dimensioni, valori-p vicini a 0.05 possono supportare l’ipotesi nulla invece di confutarla.\n\nDistorsioni da QRPs: l’utilizzo di pratiche discutibili può produrre falsi positivi statisticamente significativi.\n\nBenché alcuni studiosi abbiano proposto l’abbassamento della soglia di significatività statistica a 0.005 o l’integrazione dei valori-p con stime degli effetti e intervalli di confidenza, il punto centrale continua ad essere il fatto che l’enfasi dovrebbe spostarsi dai risultati statistici alla qualità metodologica degli studi.\nPer affrontare questi problemi, è necessario un cambiamento culturale e strutturale. La trasparenza, l’autocorrezione e l’adozione di pratiche come la preregistrazione degli studi possono aiutare a ridurre l’impatto dei bias e delle QRPs. Inoltre, incentivare repliche rigorose e promuovere un sistema di pubblicazione che premi la qualità rispetto alla quantità sono passi fondamentali per migliorare la credibilità della scienza.\n\n76.7.6 Campioni Troppo Piccoli\nUno dei fattori chiave che contribuiscono alla crisi della replicazione in psicologia è l’uso di campioni di dimensioni ridotte. Questo approccio ha permesso ai ricercatori di massimizzare la quantità di pubblicazioni a scapito della qualità e dell’affidabilità degli effetti rilevati. Higginson e Munafò (2016) sottolineano come questo fenomeno rappresenti una “selezione naturale della cattiva scienza”, dove incentivi strutturali premiano metodologie di ricerca poco rigorose.\nContrariamente a quanto si potrebbe pensare, ottenere un effetto significativo con un campione piccolo non garantisce che lo stesso effetto rimanga significativo con un campione più grande. Questo problema è strettamente legato alla potenza statistica, che rappresenta la probabilità, nel lungo periodo, di rifiutare correttamente l’ipotesi nulla quando l’ipotesi alternativa è vera. Una potenza statistica bassa comporta un’elevata probabilità di errori di Tipo II (falsi negativi) e, allo stesso tempo, riduce la probabilità che un risultato significativo rifletta un effetto reale.\nIn psicologia, la potenza statistica viene solitamente fissata a un minimo dell’80%, il che significa che, nel lungo termine, uno studio dovrebbe avere l’80% di possibilità di rilevare un effetto reale. Tuttavia, molti studi più datati raramente menzionano la potenza statistica, nonostante il concetto sia noto dagli anni ’30. Questo ha contribuito a generare una letteratura scientifica con effetti sovrastimati o poco affidabili.\nIn un approccio frequentista, per calcolare la potenza di uno studio, è necessario conoscere almeno due dei seguenti tre parametri: dimensione dell’effetto atteso, criterio di significatività e dimensione del campione pianificata. Per esempio, un ricercatore che si aspetta di trovare un effetto “medio” (Cohen’s d = 0.50) con un criterio di significatività di p &lt; .05 può determinare la dimensione del campione necessaria per garantire una potenza sufficiente. Tuttavia, molti studi psicologici hanno ignorato questo tipo di pianificazione, basandosi su campioni troppo piccoli per rilevare effetti affidabili.\nL’uso di campioni piccoli, combinato con pratiche discutibili di ricerca (Questionable Research Practices, QRPs) e bias di pubblicazione, ha portato a una letteratura scientifica piena di effetti inflazionati. Ad esempio, meta-analisi iniziali sul concetto di esaurimento dell’ego (ego depletion) stimavano un effetto medio (d = 0.62). Tuttavia, repliche successive hanno trovato effetti molto più piccoli, spesso inferiori a d = 0.10. Allo stesso modo, il progetto dell’Open Science Collaboration (2015) ha evidenziato che le dimensioni degli effetti nelle repliche erano, in media, dimezzate rispetto agli studi originali.\nCampioni di piccole dimensioni non solo riducono la probabilità di rilevare effetti reali, ma compromettono anche la credibilità dei risultati significativi. Una bassa potenza statistica mina l’obiettivo fondamentale della ricerca scientifica, limitando la capacità di trarre conclusioni solide e contribuendo alla crisi della replicazione. Per migliorare la qualità della scienza, è essenziale adottare pratiche di ricerca più rigorose, pianificando adeguatamente la dimensione del campione e garantendo una potenza statistica sufficiente.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#la-misurazione-un-problema-sottovalutato",
    "href": "chapters/replication_crisis/01_crisis.html#la-misurazione-un-problema-sottovalutato",
    "title": "76  La crisi della replicazione",
    "section": "\n76.8 La Misurazione: Un Problema Sottovalutato",
    "text": "76.8 La Misurazione: Un Problema Sottovalutato\nOltre alle dimensioni campionarie inadeguate, la psicologia potrebbe soffrire di problemi legati alla misurazione. Per rispondere a domande scientifiche, i ricercatori devono definire e misurare con precisione il costrutto oggetto di indagine. Ad esempio, per investigare se una mentalità di crescita possa migliorare l’intelligenza, un ricercatore deve prima definire e poi misurare sia la mentalità che l’intelligenza. Tuttavia, la misurazione è un processo complesso e impegnativo.\nL’intelligenza è un costrutto latente, il che significa che, a differenza dell’altezza di una persona, non può essere osservata o misurata direttamente. Gli psicologi inferiscono l’intelligenza stimando il quoziente intellettivo (QI) di un individuo, basandosi sulle risposte a numerose domande di un test di intelligenza, adattate all’età del partecipante. Ma come possiamo sapere se il QI rappresenta un buon indicatore dell’intelligenza? È necessario valutare la validità di costrutto, definita come la capacità di una misura di comportarsi in modo coerente con le ipotesi teoriche (Cronbach e Meehl, 1955; Fink, 2010). Alcuni ricercatori hanno sostenuto che una spiegazione spesso trascurata della crisi della replicazione risieda nella scarsa validità di costrutto delle nostre misure (Lilienfeld e Strother, 2020; Loken e Gelman, 2017).\nPer evidenziare il problema della misurazione in psicologia, Flake e colleghi hanno condotto una revisione di articoli pubblicati in una rivista prestigiosa. La loro analisi ha mostrato che molte scale di misurazione utilizzate non avevano una chiara fonte dichiarata, mentre altre erano state sviluppate senza una documentazione adeguata. Inoltre, una parte significativa delle scale citate era stata modificata rispetto alla versione originale, rendendo sconosciute le loro proprietà psicometriche.\nGli autori hanno anche rilevato l’uso di Pratiche di Misurazione Discutibili (Questionable Measurement Practices, QMPs), che includono la mancata divulgazione di informazioni sulla validità delle misure quando questa non risulta soddisfacente. Questi problemi suggeriscono che molti costrutti psicologici non siano adeguatamente validati, un fattore che potrebbe contribuire alle difficoltà di replicazione degli studi.\nAltri ricercatori hanno argomentato che problemi di validità interna ed esterna possano contribuire alla crisi della replicazione (Fabrigar et al., 2020). La validità interna si riferisce a come uno studio stabilisce una relazione di causa-effetto tra le variabili indipendenti e dipendenti (Cook e Campbell, 1979). Fabrigar et al. suggeriscono che un tentativo di replicazione possa fallire se:\n\nLo studio originale ha sofferto di minacce alla validità che hanno causato un effetto spurio (alta validità interna nella replica).\nI ricercatori introducono elementi assenti nello studio originale (bassa validità interna nella replica).\n\nLa validità esterna riguarda la possibilità di generalizzare i risultati di uno studio ad altri contesti o popolazioni. Questo può influenzare le repliche se, ad esempio, la replica viene condotta su una popolazione diversa o se i materiali dello studio sono tradotti da un’altra lingua, causando incomprensioni nei partecipanti.\nPer sintetizzare questi problemi, Flake e Fried (2020) li definiscono “measurement schmeasurement”, espressione che descrive la mancanza di attenzione verso la validità delle misure nella scienza psicologica. Se le misure utilizzate in uno studio non sono valide, ne consegue che anche i risultati e le conclusioni tratte non possono essere considerati affidabili. Quando tali studi vengono replicati, potrebbero essere destinati al fallimento ancor prima di iniziare.\n\n76.8.1 Privilegiare la novità a scapito della replicazione\nLa psicologia sperimentale nasce alla fine del XIX secolo con la fondazione del primo laboratorio dedicato alla ricerca psicologica da parte di Wilhelm Wundt nel 1879. Tuttavia, nonostante più di un secolo di progresso scientifico, oggi la psicologia si trova ad affrontare una crisi di replicazione. Una delle ragioni principali risiede nella scarsa attenzione dedicata agli studi di replicazione, che non sono mai stati valorizzati né premiati adeguatamente nelle scienze sociali.\nL’attuale cultura della pubblicazione accademica privilegia risultati nuovi e positivi, rendendo gli studi di replicazione e i risultati nulli una rarità. Questa tendenza riflette quello che Antonakis (2017) definisce significosis – un’attenzione sproporzionata verso risultati significativi – e neofilia – un’eccessiva enfasi sulla novità. Tale dinamica non è nuova; già Sterling (1959) avvertiva che i ricercatori potevano testare ripetutamente un’ipotesi fino a ottenere, per puro caso, un risultato significativo, pubblicando poi questi risultati senza verificarli attraverso replicazioni. In mancanza di tali verifiche, un intero campo di studio rischia di poggiare su un numero allarmante di affermazioni false.\nQuesto squilibrio non riguarda solo la letteratura scientifica, ma si manifesta anche nei progetti di ricerca degli studenti. Ad esempio, le tesi di laurea in psicologia spesso consistono in progetti empirici condotti in solitudine, senza finanziamenti e con tempistiche ristrette. Tali progetti, per loro natura, soffrono degli stessi problemi riscontrati nella letteratura più ampia: campioni insufficienti, studi sottopotenziati e un’elevata probabilità di falsi positivi. Se questi studi vengono pubblicati selettivamente, si premia la fortuna più che la qualità della ricerca. Iniziative come il Collaborative Replications and Education Project (CREP), che incoraggiano gli studenti a condurre studi di replicazione come parte del loro percorso formativo, mirano a contrastare questa tendenza e promuovere una cultura scientifica più solida e collaborativa.\n\n76.8.2 La scienza non si autocorregge come dovrebbe\nUn principio cardine della scienza è l’autocorrezione, ma nella pratica accademica moderna, questo processo sembra spesso ostacolato da incentivi e preoccupazioni reputazionali. I ricercatori, pressati dalle scadenze per nuovi progetti o richieste di finanziamento, raramente dedicano il tempo necessario a rivedere e correggere i propri lavori passati. Questo mancato impegno rappresenta una delle spiegazioni della crisi di replicazione.\nUn esempio significativo è il Registered Replication Report dello studio di Srull e Wyer (1979), replicato da McCarthy et al. (2018). Lo studio originale aveva mostrato che il priming con stimoli aggressivi portava i partecipanti a interpretare un comportamento ambiguo come più ostile. Tuttavia, il tentativo di replicazione ha rilevato un effetto trascurabile. Una possibile spiegazione è che alcune statistiche dello studio originale fossero riportate in modo errato, un errore che, nonostante tutto, non è mai stato corretto. Similmente, altri casi documentano gravi discrepanze nei dati riportati in letteratura, come dimostrato da van der Zee et al. (2017) nel loro riesame di articoli del Cornell Food Lab, che ha rivelato oltre 150 incongruenze.\nLa microbiologa Elizabeth Bik ha inoltre evidenziato che la manipolazione di immagini scientifiche è diventata una forma emergente di cattiva condotta, volta a rendere i risultati più impressionanti o a mascherare dati problematici. Sebbene alcuni casi di manipolazione portino a ritrazioni o correzioni, il lavoro di revisione è spesso svolto da altri ricercatori come attività volontaria, suggerendo che la scienza sia più “eterocorrettiva” che autocorrettiva.\nNonostante le difficoltà, il processo di autocorrezione è fondamentale per il progresso scientifico. Vazire (2020) sostiene che il disagio provocato dalla revisione critica sia salutare e necessiti di una maggiore umiltà intellettuale da parte dei ricercatori. Questo include il riconoscimento pubblico delle limitazioni dei propri studi e, quando necessario, la pubblicazione di correzioni o dichiarazioni di perdita di fiducia nei risultati originali.\n\n76.8.3 La scienza chiusa come ostacolo alla replicazione\nUn altro importante ostacolo alla replicazione è la mancanza di trasparenza e dettaglio negli studi precedenti. La scienza chiusa, in cui i dati e i metodi sono trattati come ricette segrete, rende difficile, se non impossibile, ricreare esperimenti e verificare analisi. Questa opacità riguarda vari aspetti della ricerca, dai materiali utilizzati ai dati raccolti, fino alle decisioni analitiche prese durante lo studio.\nPer esempio, le decisioni prese durante l’analisi dei dati – come la gestione dei valori anomali o le correzioni per analisi multiple – possono influenzare significativamente i risultati. Se tali decisioni non vengono riportate in modo trasparente, gli altri ricercatori incontreranno grandi difficoltà nel riprodurre gli stessi risultati. Questo fenomeno è noto come il giardino dei sentieri che si biforcano (garden of forking paths), dove una moltitudine di scelte non documentate porta a risultati divergenti.\nLa soluzione appare ovvia: rendere i dati e i metodi apertamente disponibili. Tuttavia, la condivisione dei dati è tutt’altro che una pratica comune, nonostante i progressi tecnici che ne facilitano l’implementazione. Le ragioni per non condividere i dati possono essere valide, come considerazioni etiche per garantire l’anonimato dei partecipanti, ma queste dovrebbero sempre essere dichiarate esplicitamente.\nQuesti ostacoli evidenziano come la cultura scientifica debba evolversi verso una maggiore trasparenza e collaborazione, affrontando le limitazioni strutturali che contribuiscono alla crisi di replicazione. Solo così la scienza può continuare a correggersi e avanzare in modo affidabile.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#il-progetto-di-riproducibilità",
    "href": "chapters/replication_crisis/01_crisis.html#il-progetto-di-riproducibilità",
    "title": "76  La crisi della replicazione",
    "section": "\n76.9 Il Progetto di Riproducibilità",
    "text": "76.9 Il Progetto di Riproducibilità\n\n76.9.1 L’Iniziativa di Brian Nosek\nNel 2011, Brian Nosek dell’Università della Virginia avviò il Progetto di Riproducibilità (Collaboration, 2015), coinvolgendo 270 ricercatori nel tentativo di replicare cento studi di psicologia. L’obiettivo era ripetere gli esperimenti originali, utilizzando gli stessi metodi ma con nuovi campioni, per verificare la solidità e la replicabilità dei risultati precedentemente pubblicati.\nI risultati di questo imponente lavoro, pubblicati nel 2015, furono a dir poco sconvolgenti. Dei cento studi esaminati, ben novantasette avevano inizialmente riportato risultati statisticamente significativi. Tuttavia, il team di Nosek riuscì a replicare questi risultati solo in trentasei casi. Non solo: le dimensioni degli effetti nelle replicazioni risultarono, in media, dimezzate rispetto agli studi originali. Inoltre, più della metà di queste dimensioni degli effetti cadeva al di fuori degli intervalli di confidenza al 95% riportati nei lavori originali.\n\n76.9.2 Studi Successivi\nQuesti risultati sono stati ulteriormente corroborati da numerosi studi successivi, tra cui una ricerca più recente basata su tecniche di machine learning, che ha esaminato studi di psicologia pubblicati in sei importanti riviste nell’arco di vent’anni. Questa ricerca suggerisce che poco più della metà di questi articoli di psicologia non supererebbe i test di replicazione (Youyou et al., 2023). Discipline come la psicologia sociale sono state oggetto di particolare preoccupazione, con un tasso di replicazione del solo 25% riportato dal Progetto di Riproducibilità (Collaboration, 2015). Questo dato è in linea con il lavoro di Youyou et al. (2023), che ha mostrato come la replicabilità degli articoli di psicologia vari considerevolmente per sottocampo, con la psicologia sociale che mostra un tasso di replicazione stimato del 37%, un risultato leggermente più incoraggiante rispetto a quanto riportato in precedenza, ma ancora tra i più bassi dei sottocampi esaminati. Altri settori come la psicologia dello sviluppo, cognitiva e clinica hanno mostrato tassi di replicazione stimati rispettivamente del 36%, 42% e 44%, mentre aree come la psicologia delle organizzazioni e della personalità hanno mostrato tassi leggermente più incoraggianti (50% e 55%, rispettivamente). Complessivamente, le evidenze suggeriscono che le preoccupazioni diffuse sulla robustezza e replicabilità dei risultati della ricerca psicologica siano fondate. Sebbene il problema non sia limitato esclusivamente alla psicologia, le questioni rilevate in questo campo hanno ricevuto notevole attenzione a causa dell’apparente portata del fenomeno.\nQuesti risultati confermavano in modo drammatico le previsioni formulate anni prima da John Ioannidis e Dennis Lindley. Le loro avvertenze riguardo alla possibilità che una larga parte, se non la maggioranza, dei risultati scientifici pubblicati potesse essere falsa, si rivelavano ora profetiche.\nIl Progetto di Riproducibilità di Nosek ha segnato un punto di svolta nel dibattito sulla crisi della replicazione in psicologia e, più in generale, nelle scienze sociali e biomediche. Ha evidenziato non solo la fragilità di molti risultati ritenuti consolidati, ma anche la necessità di un riesame critico delle pratiche di ricerca e pubblicazione scientifica. Questo ripensamento delle metodologie scientifiche è ancora in atto.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#cause-profonde-della-crisi-della-replicazione",
    "href": "chapters/replication_crisis/01_crisis.html#cause-profonde-della-crisi-della-replicazione",
    "title": "76  La crisi della replicazione",
    "section": "\n76.10 Cause Profonde della Crisi della Replicazione",
    "text": "76.10 Cause Profonde della Crisi della Replicazione\nLa crisi della replicazione in psicologia e in altre scienze ha radici profonde e non può essere attribuita esclusivamente a pratiche di ricerca disoneste. Diverse cause immediate sono state identificate, tra cui:\n\n\nPressione a pubblicare (“publish or perish”): L’intensa pressione sui ricercatori a pubblicare prolificamente è un fattore importante che può contribuire a molti dei problemi legati alla crisi della replicazione. La cultura del “publish or perish” mette i ricercatori sotto stress continuo per produrre risultati significativi e pubblicarli rapidamente (Gopalakrishna et al., 2022; Grimes et al., 2018).\n\nRicerca della novità a ogni costo e incentivi accademici distorti: La ricerca di risultati innovativi e il valore eccessivo attribuito alle scoperte significative incentivano pratiche di ricerca distorte. Questo include la sovrarappresentazione dei risultati positivi e la mancanza di rigore metodologico (Ferguson & Heene, 2012; Ware & Munafò, 2015).\n\nBassa potenza statistica e scarsità di sforzi di replicazione: Molti studi soffrono di bassa potenza statistica, il che rende difficile ottenere risultati affidabili. Inoltre, la mancanza di sforzi di replicazione contribuisce a mantenere e diffondere risultati non replicabili.\n\nMancanza di trasparenza nella reportistica: La reportistica selettiva e la flessibilità non dichiarata nei metodi e nei dati sono pratiche comuni che compromettono l’integrità scientifica. Inoltre, la riluttanza a condividere dati e materiali e il bias di pubblicazione, per cui i risultati nulli hanno meno probabilità di essere pubblicati rispetto a quelli statisticamente significativi, aggravano il problema (Bruton et al., 2020; Nosek et al., 2012).\n\n\n76.10.1 La Probabilità Inversa\nOltre a questi fattori, alcuni studiosi sostengono che la radice della crisi della replicazione sia ancora più profonda e risieda nell’approccio statistico stesso, ampiamente adottato dalla comunità scientifica (Chivers, 2024; Gelman & Loken, 2014; Loken & Gelman, 2017). Questo punto di vista suggerisce che le difficoltà nella replicazione dei risultati non siano solo il prodotto di comportamenti individuali discutibili, ma derivino in larga parte da un’interpretazione e un’applicazione problematica dei metodi statistici.\nPer comprendere meglio questa questione, dobbiamo tornare alle basi della statistica inferenziale. L’approccio frequentista, dominante nella ricerca scientifica, si basa sulle probabilità di campionamento. Questo metodo, che risale a Jakob Bernoulli nel XVIII secolo, calcola la probabilità di osservare certi dati assumendo che una determinata ipotesi sia vera. Il famoso “p-value” è un esempio di questa logica: esso indica la probabilità di ottenere risultati estremi quanto o più estremi di quelli osservati, supponendo che l’ipotesi nulla sia vera.\nTuttavia, questo approccio ha un limite fondamentale: non ci dice direttamente quanto è probabile che la nostra ipotesi sia vera alla luce dei dati raccolti. In altre parole, non fornisce una “probabilità inferenziale”, cioè la probabilità che l’ipotesi sia corretta in base ai risultati ottenuti. Qui entra in gioco l’approccio bayesiano. Il teorema di Bayes offre un metodo per calcolare proprio questa probabilità inferenziale. L’approccio bayesiano tiene conto non solo dei dati osservati, ma anche delle conoscenze pregresse (le “prior”) relative all’ipotesi in esame.\nLa differenza tra questi due approcci è cruciale. Mentre il p-value ci dice quanto sono improbabili i nostri dati se l’ipotesi nulla è vera, l’approccio bayesiano ci fornisce la probabilità che la nostra ipotesi sia vera alla luce dei dati raccolti e delle conoscenze precedenti.\n\n76.10.2 Implicazioni per la Pratica Scientifica\nQuesta distinzione ha implicazioni profonde per la pratica scientifica. L’uso esclusivo dell’approccio frequentista può portare a sovrastimare la forza delle evidenze a favore di un’ipotesi, specialmente quando si lavora con campioni piccoli o si conducono molti test statistici, come spesso accade in psicologia.\nAlcune soluzioni proposte per affrontare la crisi della replicazione includono:\n\nAbbassare la soglia di significatività statistica, rendendo più difficile dichiarare un risultato “significativo”.\nRichiedere la preregistrazione delle ipotesi per prevenire l’HARKing (Hypothesizing After Results are Known).\nFar sì che le riviste accettino gli articoli basandosi sui metodi piuttosto che sui risultati, per evitare il bias verso la pubblicazione di risultati solo “positivi” o “nuovi”.\n\nTuttavia, queste soluzioni, pur utili, non affrontano il problema fondamentale dell’interpretazione delle evidenze statistiche. L’adozione di un approccio bayesiano offre una soluzione più radicale, fornendo un quadro più completo e realistico della forza delle evidenze a favore o contro un’ipotesi scientifica.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#guardare-i-dati",
    "href": "chapters/replication_crisis/01_crisis.html#guardare-i-dati",
    "title": "76  La crisi della replicazione",
    "section": "\n76.11 Guardare i Dati",
    "text": "76.11 Guardare i Dati\nConsideriamo una simulazione, ispirata da Lakens (2015), che illustra come una pratica apparentemente innocua – osservare i risultati man mano che vengono raccolti nell’approccio frequentista – possa avere conseguenze significative sulle conclusioni di uno studio. In particolare, questa pratica può influire sulla probabilità di ottenere un risultato statisticamente significativo.\nNella simulazione seguente, due campioni casuali vengono estratti dalla stessa popolazione normale di partenza. Di conseguenza, l’“ipotesi nulla” è vera: non c’è differenza tra le medie delle popolazioni. Tuttavia, a causa della variabilità campionaria, il p-valore risulta fortemente influenzato da ogni singola osservazione aggiunta al campione.\n\nsimulate_t_tests &lt;- function(seed, max_sample_size, mu = 0, sigma = 1) {\n  set.seed(seed)\n\n  # Intervallo di grandezza campionaria\n  sample_sizes &lt;- seq(2, max_sample_size, by = 2)\n  p_values &lt;- numeric(length(sample_sizes))\n\n  # Genera due campioni grandi iniziali da una distribuzione normale\n  full_sample1 &lt;- rnorm(max_sample_size, mean = mu, sd = sigma)\n  full_sample2 &lt;- rnorm(max_sample_size, mean = mu, sd = sigma)\n\n  # Simulazione\n  for (i in seq_along(sample_sizes)) {\n    n &lt;- sample_sizes[i]\n\n    # Estrai sottoinsiemi incrementali dai campioni completi\n    sample1 &lt;- full_sample1[1:n]\n    sample2 &lt;- full_sample2[1:n]\n\n    # Esegui il t-test per il confronto delle medie di due gruppi indipendenti\n    t_test &lt;- t.test(sample1, sample2, var.equal = TRUE)\n    p_values[i] &lt;- t_test$p.value\n  }\n\n  # Crea il grafico del p-valore in funzione della grandezza campionaria\n  plot(\n    sample_sizes, p_values, type = \"l\", col = \"#b97c7c\",\n    xlab = \"Grandezza Campionaria\", ylab = \"P-valore\",\n    main = \"P-valore in funzione della grandezza campionaria\"\n  )\n  abline(h = 0.05, col = \"#8f2727\", lty = 2, lwd = 1.5)\n  legend(\"topright\", legend = \"Significatività a 0.05\", col = \"#8f2727\", lty = 2, cex = 0.8)\n}\n\nNelle due simulazioni seguenti, osserviamo come il p-valore cambi progressivamente aumentando la dimensione dei campioni casuali da \\(n = 2\\) a \\(n = 300\\). È evidente come il p-valore vari drasticamente con l’aggiunta di nuove osservazioni ai campioni. Inoltre, in alcune configurazioni, il p-valore può scendere al di sotto della soglia critica di 0.05 per puro caso. Se un ricercatore interrompesse la raccolta dei dati in quel momento, otterrebbe un risultato “statisticamente significativo”, pur avendo campioni estratti dalla stessa popolazione.\n\nsimulate_t_tests(seed = 1234, max_sample_size = 300, mu = 0, sigma = 2)\nsimulate_t_tests(seed = 2, max_sample_size = 300, mu = 0, sigma = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuesta simulazione mette in evidenza una limitazione fondamentale dell’approccio frequentista: ogni test statistico considera esclusivamente i dati del campione corrente, ignorando le conoscenze accumulate in precedenza. Questo rende il processo decisionale estremamente volatile, poiché, teoricamente, ad ogni nuovo studio si “dimentica” tutta l’informazione derivante dagli studi precedenti.\n\n76.11.1 Analisi Bayesiana\nL’approccio bayesiano offre una soluzione elegante a questo problema. Nel framework bayesiano, la distribuzione a posteriori (cioè, la nostra convinzione aggiornata dopo aver osservato i dati) bilancia sempre l’informazione a priori (ciò che sapevamo prima dell’esperimento) con la verosimiglianza (ciò che i dati ci dicono). Questo equilibrio è particolarmente prezioso quando i dati sono deboli o contengono molto rumore, come nel caso dei dati della simulazione che stiamo discutendo. In tali situazioni, l’informazione a priori assume un ruolo più rilevante, impedendo conclusioni affrettate basate su dati poco informativi.\nPer illustrare questa differenza, consideriamo l’analisi bayesiana dei dati simulati in precedenza. Se questi dati vengono analizzati con l’approccio frequentista, forniscono un risultato “statisticamente significativo”, suggerendo una differenza tra i due gruppi.\nTuttavia, analizzando gli stessi dati con un approccio bayesiano, otteniamo un intervallo di credibilità al 95% compreso tra -0.52 e 1.12. Poiché questo intervallo include lo zero, possiamo affermare, con un livello di certezza soggettiva del 95%, che non c’è una differenza sostanziale tra le medie delle due popolazioni da cui sono stati estratti i campioni.\nQuesta discrepanza nei risultati evidenzia un punto cruciale: l’approccio bayesiano è più resistente ai falsi positivi in presenza di dati rumorosi o campioni piccoli. Invece di forzare una decisione binaria (significativo/non significativo) basata su una soglia arbitraria, l’analisi bayesiana fornisce una rappresentazione più sfumata e realistica dell’incertezza associata alle nostre conclusioni.\nInoltre, l’approccio bayesiano offre il vantaggio di essere cumulativo: ogni nuovo studio non parte da zero, ma incorpora naturalmente le conoscenze precedenti attraverso la distribuzione a priori.\n\n# Imposta il seme per la riproducibilità\nset.seed(12)\n\n# Parametri della distribuzione normale\nmu &lt;- 0\nsigma &lt;- 2\nmax_sample_size &lt;- 50\n\n# Genera due campioni indipendenti\nfull_sample1 &lt;- rnorm(max_sample_size, mean = mu, sd = sigma)\nfull_sample2 &lt;- rnorm(max_sample_size, mean = mu, sd = sigma)\n\n\n# Prepara i dati per Stan\nstan_data &lt;- list(\n  N1 = length(full_sample1),\n  N2 = length(full_sample2),\n  y1 = full_sample1,\n  y2 = full_sample2\n)\n\n# Visualizza i dati preparati\nprint(stan_data)\n#&gt; $N1\n#&gt; [1] 50\n#&gt; \n#&gt; $N2\n#&gt; [1] 50\n#&gt; \n#&gt; $y1\n#&gt;  [1] -2.9611  3.1543 -1.9135 -1.8400 -3.9953 -0.5446 -0.6307 -1.2565 -0.2129\n#&gt; [10]  0.8560 -1.5554 -2.5878 -1.5591  0.0239 -0.3048 -1.4069  2.3778  0.6810\n#&gt; [19]  1.0139 -0.5866  0.4473  4.0144  2.0240 -0.6049 -2.0505 -0.5348 -0.3982\n#&gt; [28]  0.2622  0.2916  0.7241  1.3480  4.1441 -1.0821 -2.1410 -0.7449 -0.9703\n#&gt; [37]  0.5496 -0.9590  1.5962 -2.0089  0.2100 -2.3120  1.1563 -3.1913 -0.6170\n#&gt; [46]  0.8989 -1.9541  0.3800  1.4629 -0.9852\n#&gt; \n#&gt; $y2\n#&gt;  [1] -0.08537 -0.22534  0.91365  4.04067 -2.10178  1.46930  1.07850 -2.62855\n#&gt;  [9] -0.50008  0.62841  0.81309  1.98884  1.71154  0.39426  1.66865  1.69358\n#&gt; [17]  3.90821 -4.29852  1.94224  2.29012 -1.05080  0.50064 -0.85881 -0.36504\n#&gt; [25] -0.20662 -1.26768 -2.54211 -0.76790  1.03351 -0.35594  0.00852 -2.54812\n#&gt; [33] -0.40422  2.32893 -0.04676  1.79431 -0.35345  2.22742 -1.08378 -1.92680\n#&gt; [41]  0.75290 -1.96935  1.79512  0.25853  2.06741 -0.68458  0.90456 -1.38948\n#&gt; [49] -0.47803 -2.01460\n\n\n# Path to the Stan file\nstan_file &lt;- here::here(\"stan\", \"two_means_diff.stan\")\n\n# Create a CmdStanModel object\nmod &lt;- cmdstan_model(stan_file)\nmod$code() # Stampa il codice del modello\n#&gt;  [1] \"data {\"                                                                \n#&gt;  [2] \"  int&lt;lower=0&gt; N1; // Numero di osservazioni nel gruppo 1\"             \n#&gt;  [3] \"  int&lt;lower=0&gt; N2; // Numero di osservazioni nel gruppo 2\"             \n#&gt;  [4] \"  vector[N1] y1; // Dati del gruppo 1\"                                 \n#&gt;  [5] \"  vector[N2] y2; // Dati del gruppo 2\"                                 \n#&gt;  [6] \"}\"                                                                     \n#&gt;  [7] \"parameters {\"                                                          \n#&gt;  [8] \"  real mu1; // Media del gruppo 1\"                                     \n#&gt;  [9] \"  real delta; // Differenza tra le medie\"                              \n#&gt; [10] \"  real&lt;lower=0&gt; sigma; // Deviazione standard comune\"                  \n#&gt; [11] \"  real&lt;lower=0&gt; nu; // Gradi di libertà per la distribuzione t\"        \n#&gt; [12] \"}\"                                                                     \n#&gt; [13] \"transformed parameters {\"                                              \n#&gt; [14] \"  real mu2; // Media del gruppo 2\"                                     \n#&gt; [15] \"  mu2 = mu1 + delta;\"                                                  \n#&gt; [16] \"}\"                                                                     \n#&gt; [17] \"model {\"                                                               \n#&gt; [18] \"  // Priori\"                                                           \n#&gt; [19] \"  mu1 ~ normal(0, 5);\"                                                 \n#&gt; [20] \"  delta ~ normal(0, 2); // Priore su delta\"                            \n#&gt; [21] \"  sigma ~ cauchy(0, 5);\"                                               \n#&gt; [22] \"  nu ~ gamma(2, 0.1); // Priore sulla t-student\"                       \n#&gt; [23] \"  \"                                                                    \n#&gt; [24] \"  // Verosimiglianza\"                                                  \n#&gt; [25] \"  y1 ~ student_t(nu, mu1, sigma);\"                                     \n#&gt; [26] \"  y2 ~ student_t(nu, mu2, sigma);\"                                     \n#&gt; [27] \"}\"                                                                     \n#&gt; [28] \"generated quantities {\"                                                \n#&gt; [29] \"  real diff; // Differenza tra le medie (alias di delta per chiarezza)\"\n#&gt; [30] \"  diff = delta;\"                                                       \n#&gt; [31] \"}\"\n\nEsegui il campionamento:\n\nfit &lt;- mod$sample(\n  data = stan_data,\n  seed = 123,\n  chains = 4,\n  iter_sampling = 2000,\n  iter_warmup = 1000,\n  show_messages = FALSE\n)\n\nRiassumi i risultati per mu1, mu2 e delta:\n\nfit_summary &lt;- fit$summary(variables = c(\"mu1\", \"mu2\", \"delta\"))\nprint(fit_summary)\n#&gt; # A tibble: 3 × 10\n#&gt;   variable   mean median    sd   mad      q5    q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 mu1      -0.313 -0.312 0.241 0.238 -0.707  0.0818  1.00    5378.    5491.\n#&gt; 2 mu2       0.164  0.166 0.246 0.248 -0.235  0.568   1.00    9428.    6234.\n#&gt; 3 delta     0.477  0.474 0.341 0.344 -0.0887 1.04    1.00    5155.    5260.\n\nEstrai i campioni di delta:\n\ndelta_samples &lt;- fit$draws(variables = \"delta\", format = \"matrix\")[, 1]\n\nDisegna la distribuzione a posteriori di delta:\n\ndelta_df &lt;- data.frame(delta = delta_samples)\n\nggplot(delta_df, aes(x = delta)) +\n  geom_histogram(aes(y = ..density..), bins = 30, fill = \"#b97c7c\", alpha = 0.75) +\n  geom_vline(\n    xintercept = mean(delta_samples),\n    linetype = \"dashed\",\n    linewidth = 1.2,\n    label = paste(\"Mean:\", round(mean(delta_samples), 2))\n  ) +\n  labs(\n    x = \"delta\",\n    y = \"Density\",\n    title = \"Posterior distribution of delta\"\n  ) \n#&gt; Warning in geom_vline(xintercept = mean(delta_samples), linetype =\n#&gt; \"dashed\", : Ignoring unknown parameters: `label`\n#&gt; Warning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\n#&gt; ℹ Please use `after_stat(density)` instead.\n\n\n\n\n\n\n\nPuoi calcolare l’intervallo di credibilità usando per un intervallo al 95%:\n\nquantile(delta_samples, probs = c(0.025, 0.975))\n#&gt;   2.5%  97.5% \n#&gt; -0.187  1.155",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#il-giardino-dei-sentieri-che-si-biforcano",
    "href": "chapters/replication_crisis/01_crisis.html#il-giardino-dei-sentieri-che-si-biforcano",
    "title": "76  La crisi della replicazione",
    "section": "\n76.12 Il Giardino dei Sentieri che si Biforcano",
    "text": "76.12 Il Giardino dei Sentieri che si Biforcano\nLo psicologo Paul Meehl condusse uno studio su un campione di cinquantasettamila studenti delle scuole superiori del Minnesota, indagando su variabili quali religione, abitudini nel tempo libero, ordine di nascita, numero di fratelli, piani post-diploma e numerosi altri aspetti (Meehl, 2012). Complessivamente, le diverse risposte dei partecipanti potevano essere combinate in 990 modi distinti, permettendo analisi del tipo: “Gli studenti appassionati di cucina hanno una maggiore probabilità di essere figli unici?” o “Gli studenti provenienti da famiglie battiste sono più inclini a partecipare a club politici scolastici?”. Meehl evidenziò che, analizzando i dati, il 92% di queste possibili combinazioni risultava in correlazioni statisticamente significative. Queste differenze, sebbene reali, presumibilmente derivano da cause multifattoriali e complesse.\nAndrew Gelman ha denominato questo fenomeno “Il Giardino dei Sentieri che si Biforcano” [Garden of Forking Paths; Gelman & Loken (2013)], riferendosi ai molteplici gradi di libertà a disposizione del ricercatore nell’analisi dei dati. Come nell’esempio di Meehl, è possibile esaminare le differenze intergruppo (se questo è l’oggetto di interesse) da molteplici prospettive. Con un campione sufficientemente ampio, alcune di queste differenze risulteranno “statisticamente significative”. Ciò indica che, in quello specifico campione, quel particolare aspetto dei dati è rilevante. Tuttavia, questa differenza “statisticamente significativa” non sarà necessariamente generalizzabile ad un altro campione, il quale presenterà le proprie idiosincrasie.\nIn altri termini, come sottolineato da Gelman, l’approccio basato sul test dell’ipotesi nulla si limita a “descrivere il rumore”. Da un punto di vista teorico, simili esercizi statistici risultano privi di valore euristico e non contribuiscono in nessun modo all’avanzamento delle conoscenze sul fenomeno oggetto di studio.\nIn un’ottica di inferenza statistica, questo problema è riconducibile al concetto di “p-hacking” o “data dredging”, dove l’esplorazione esaustiva di molteplici ipotesi statistiche su un singolo set di dati può portare a falsi positivi e a una sovrastima della significatività statistica.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#garbage-in-garbage-out",
    "href": "chapters/replication_crisis/01_crisis.html#garbage-in-garbage-out",
    "title": "76  La crisi della replicazione",
    "section": "\n76.13 Garbage In, Garbage Out",
    "text": "76.13 Garbage In, Garbage Out\nLa natura della statistica frequentista impone di prendere una decisione dicotomica: o si rifiuta l’ipotesi nulla o non la si rifiuta. Ciò implica che o esiste un effetto reale, oppure non esiste. Con un campione abbastanza grande, è inevitabile trovare qualche effetto, anche se di minima entità.\nUn approccio bayesiano, invece, permette di stimare la dimensione dell’effetto e di fornire una distribuzione di probabilità. Una distribuzione di probabilità è una rappresentazione grafica delle diverse possibilità che potrebbero verificarsi. In questo contesto, si tratta della “probabilità inversa”, ovvero della plausibilità dell’ipotesi alla luce dei dati osservati e delle conoscenze pregresse. Qui, il parametro \\(\\delta\\) rappresenta la differenza tra le due medie ed è il parametro di interesse. Le credenze precedenti su \\(\\delta\\) sono espresse tramite una distribuzione a priori: in questo caso, una distribuzione Normale centrata su 0 con una deviazione standard di 2. La distribuzione a posteriori rappresenta la nostra conoscenza aggiornata su \\(\\delta\\) dopo l’aggiornamento bayesiano. Il parametro \\(\\delta\\) è la nostra ipotesi sulla differenza tra le due medie, e l’inferenza bayesiana riguarda il cambiamento della nostra credenza dopo aver osservato i dati.\nL’approccio frequentista, al contrario, produce una decisione dicotomica che non modifica la nostra concezione dell’ipotesi dopo aver osservato i dati. Assume una determinata ipotesi come vera e verifica se i dati sono coerenti con essa. Tramite il concetto binario di “significatività statistica”, non si modificano le ipotesi di interesse, ma si accettano o si rifiutano le ipotesi nulle.\nSebbene l’approccio frequentista sia spesso considerato “ingenuo” da molti ricercatori, adottare l’approccio bayesiano non rappresenta una soluzione miracolosa ai problemi della scienza contemporanea. Risolve alcuni problemi, ma non altri. In particolare, non affronta la questione degli incentivi accademici che favoriscono la pubblicazione di un elevato numero di articoli, indipendentemente dalla loro qualità. Un principio fondamentale della ricerca è “Garbage in, garbage out”. Se i dati derivano da un disegno di ricerca fallace o poco creativo, se la ricerca non ha un solido fondamento teorico capace di avanzare le nostre conoscenze, o se la qualità delle misurazioni è insufficiente, i dati raccolti sono puro rumore. Nessun metodo statistico, nemmeno quello bayesiano, può trasformare la spazzatura in oro.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#esercizi",
    "href": "chapters/replication_crisis/01_crisis.html#esercizi",
    "title": "76  La crisi della replicazione",
    "section": "\n76.14 Esercizi",
    "text": "76.14 Esercizi\n\nEsercizio 76.1 Esistono numerosi esempi di ricerche che non riescono a essere replicate (posso citare anche uno studio di replicazione che ho condotto io stesso: Caudek et al. (2017)). Un recente caso emblematico è rappresentato dallo studio di Karataş & Cutright (2023) e dal successivo tentativo di replicazione condotto da Moore et al. (2024). Analizzando le quattro principali argomentazioni sollevate da Gelman & Brown (2024) per criticare lo studio di Aungle & Langer (2023), si offra un’interpretazione del perché lo studio di Karataş & Cutright (2023) non sia stato replicato con successo.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/replication_crisis/01_crisis.html#informazioni-sullambiente-di-sviluppo",
    "title": "76  La crisi della replicazione",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] posterior_1.6.0     cmdstanr_0.8.1.9000 see_0.9.0          \n#&gt;  [4] gridExtra_2.3       patchwork_1.3.0     bayesplot_1.11.1   \n#&gt;  [7] psych_2.4.12        scales_1.3.0        markdown_1.13      \n#&gt; [10] knitr_1.49          lubridate_1.9.4     forcats_1.0.0      \n#&gt; [13] stringr_1.5.1       dplyr_1.1.4         purrr_1.0.2        \n#&gt; [16] readr_2.1.5         tidyr_1.3.1         tibble_3.2.1       \n#&gt; [19] ggplot2_3.5.1       tidyverse_2.0.0     rio_1.2.3          \n#&gt; [22] here_1.0.1         \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tensorA_0.36.2.1     utf8_1.2.4           generics_0.1.3      \n#&gt;  [4] stringi_1.8.4        lattice_0.22-6       hms_1.1.3           \n#&gt;  [7] digest_0.6.37        magrittr_2.0.3       evaluate_1.0.1      \n#&gt; [10] grid_4.4.2           timechange_0.3.0     fastmap_1.2.0       \n#&gt; [13] rprojroot_2.0.4      jsonlite_1.8.9       processx_3.8.4      \n#&gt; [16] backports_1.5.0      ps_1.8.1             abind_1.4-8         \n#&gt; [19] mnormt_2.1.1         cli_3.6.3            rlang_1.1.4         \n#&gt; [22] munsell_0.5.1        withr_3.0.2          yaml_2.3.10         \n#&gt; [25] tools_4.4.2          parallel_4.4.2       tzdb_0.4.0          \n#&gt; [28] checkmate_2.3.2      colorspace_2.1-1     pacman_0.5.1        \n#&gt; [31] vctrs_0.6.5          R6_2.5.1             matrixStats_1.4.1   \n#&gt; [34] lifecycle_1.0.4      htmlwidgets_1.6.4    pkgconfig_2.0.3     \n#&gt; [37] pillar_1.10.0        gtable_0.3.6         data.table_1.16.4   \n#&gt; [40] glue_1.8.0           xfun_0.49            tidyselect_1.2.1    \n#&gt; [43] farver_2.1.2         htmltools_0.5.8.1    nlme_3.1-166        \n#&gt; [46] labeling_0.4.3       rmarkdown_2.29       compiler_4.4.2      \n#&gt; [49] distributional_0.5.0",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#bibliografia",
    "href": "chapters/replication_crisis/01_crisis.html#bibliografia",
    "title": "76  La crisi della replicazione",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAungle, P., & Langer, E. (2023). Physical healing as a function of perceived time. Scientific Reports, 13(1), 22432.\n\n\nBargh, J. A., Chen, M., & Burrows, L. (1996). Automaticity of social behavior: Direct effects of trait construct and stereotype activation on action. Journal of Personality and Social Psychology, 71(2), 230–244.\n\n\nBem, D. J. (2011). Feeling the future: experimental evidence for anomalous retroactive influences on cognition and affect. Journal of Personality and Social Psychology, 100(3), 407–425.\n\n\nBruton, S. V., Medlin, M., Brown, M., & Sacco, D. F. (2020). Personal motivations and systemic incentives: Scientists on questionable research practices. Science and Engineering Ethics, 26(3), 1531–1547.\n\n\nCaudek, C., Lorenzino, M., & Liperoti, R. (2017). Delta plots do not reveal response inhibition in lying. Consciousness and Cognition, 55, 232–244.\n\n\nChivers, T. (2024). Everything is Predictable: How Bayesian Statistics Explain Our World. Simon; Schuster.\n\n\nCollaboration, O. S. (2015). Estimating the reproducibility of psychological science. Science, 349(6251), aac4716.\n\n\nFerguson, C. J., & Heene, M. (2012). A vast graveyard of undead theories: Publication bias and psychological science’s aversion to the null. Perspectives on Psychological Science, 7(6), 555–561.\n\n\nGelman, A., & Brown, N. J. (2024). How statistical challenges and misreadings of the literature combine to produce unreplicable science: An example from psychology.\n\n\nGelman, A., & Loken, E. (2013). The garden of forking paths: Why multiple comparisons can be a problem, even when there is no «fishing expedition» or «p-hacking» and the research hypothesis was posited ahead of time. Department of Statistics, Columbia University, 348(1-17), 3.\n\n\nGelman, A., & Loken, E. (2014). The statistical crisis in science. American scientist, 102(6), 460–465.\n\n\nGopalakrishna, G., Ter Riet, G., Vink, G., Stoop, I., Wicherts, J. M., & Bouter, L. M. (2022). Prevalence of questionable research practices, research misconduct and their potential explanatory factors: A survey among academic researchers in The Netherlands. PloS one, 17(2), e0263023.\n\n\nGrimes, D. R., Bauch, C. T., & Ioannidis, J. P. (2018). Modelling science trustworthiness under publish or perish pressure. Royal Society open science, 5(1), 171511.\n\n\nIoannidis, J. P. (2005). Why most published research findings are false. PLoS medicine, 2(8), e124.\n\n\nKarataş, M., & Cutright, K. M. (2023). Thinking about God increases acceptance of artificial intelligence in decision-making. Proceedings of the National Academy of Sciences, 120(33), e2218961120.\n\n\nLakens, D. (2015). On the challenges of drawing conclusions from p-values just below 0.05. PeerJ, 3, e1142.\n\n\nLoken, E., & Gelman, A. (2017). Measurement Error and the Replication Crisis. Science, 355(6325), 584–585.\n\n\nMeehl, P. E. (2012). Why summaries of research on psychological theories are often uninterpretable. In Improving inquiry in social science (pp. 13–59). Routledge.\n\n\nMoore, D. A., Schroeder, J., Bailey, E. R., Gershon, R., Moore, J. E., & Simmons, J. P. (2024). Does thinking about God increase acceptance of artificial intelligence in decision-making? Proceedings of the National Academy of Sciences, 121(31), e2402315121.\n\n\nNosek, B. A., Spies, J. R., & Motyl, M. (2012). Scientific utopia: II. Restructuring incentives and practices to promote truth over publishability. Perspectives on Psychological Science, 7(6), 615–631.\n\n\nPennington, C. (2023). A student’s guide to open science: Using the replication crisis to reform psychology. McGraw-Hill Education (UK).\n\n\nWare, J. J., & Munafò, M. R. (2015). Significance chasing in research practice: causes, consequences and possible solutions. Addiction, 110(1), 4–8.\n\n\nYouyou, W., Yang, Y., & Uzzi, B. (2023). A discipline-wide investigation of the replicability of Psychology papers over the past two decades. Proceedings of the National Academy of Sciences, 120(6), e2208863120.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html",
    "title": "77  Limiti dell’inferenza frequentista",
    "section": "",
    "text": "Introduzione\nPrerequisiti\nConcetti e Competenze Chiave\nIn questa sezione della dispensa abbiamo esaminato il metodo “tradizionale” per il test di significatività dell’ipotesi nulla (NHST). Comprendere la logica alla base dell’approccio NHST è essenziale poiché questo è stato l’approccio predominante alla statistica inferenziale fin dalla sua introduzione all’inizio del XX secolo e la maggior parte dei ricercatori ancora si affida a questa procedura per analizzare i dati. Tuttavia, recentemente, l’approccio NHST è stato oggetto di aspre critiche, poiché molti ricercatori hanno iniziato a pensare che questo approccio possa creare più problemi di quanti ne risolva. Pertanto, è importante conoscere le critiche mosse alla procedura inferenziale NHST all’interno della comunità scientifica. In questa sezione esamineremo alcuni dei dubbi sorti riguardo a questo approccio.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#luso-del-valore-p-nel-mondo-della-ricerca",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#luso-del-valore-p-nel-mondo-della-ricerca",
    "title": "77  Limiti dell’inferenza frequentista",
    "section": "77.1 L’uso del valore-\\(p\\) nel mondo della ricerca",
    "text": "77.1 L’uso del valore-\\(p\\) nel mondo della ricerca\nNel suo articolo “Statistical Errors” (2014), Nuzzo evidenzia i limiti dell’approccio NHST nella pratica scientifica Nuzzo (2014). Infatti, sebbene il valore-\\(p\\) sia stato introdotto da Ronald Fisher negli anni ’20, egli non lo ha mai concepito come un test formale. Invece, Fisher lo considerava uno strumento informale per valutare se l’evidenza empirica fosse significativa in un senso colloquiale, ovvero meritevole di attenzione. In pratica, Fisher suggeriva di assumere un’ipotesi nulla e di calcolare la probabilità di osservare un risultato altrettanto estremo o più estremo di quello trovato, se il risultato fosse completamente dovuto alla sola variabilità campionaria. Sebbene sia possibile calcolare il valore-\\(p\\) tramite una procedura matematica, per Fisher esso era solo uno strumento da utilizzare all’interno di un processo decisionale non numerico, in grado di combinare le evidenze empiriche attuali con le conoscenze pregresse del ricercatore. In altre parole, il valore-\\(p\\) rappresentava uno strumento da utilizzare all’interno del processo decisionale, non la conclusione del processo decisionale stesso.\nVerso la fine degli anni ’20, Jerzy Neyman e Egon Pearson, rivali di Fisher, formalizzarono le procedure di decisione statistica con l’obiettivo di renderle “rigorose e oggettive”. In particolare, introdussero i concetti di potere statistico e di falso positivo, ma non utilizzarono la nozione di valore-\\(p\\) come aveva fatto Fisher.\nLe divergenze tra i tre autori portarono a un acceso dibattito, in cui Neyman criticò il lavoro di Fisher come matematicamente “peggiore dell’inutilità”, mentre Fisher definì l’approccio di Neyman “infantile” e “orribile per la libertà intellettuale dell’occidente”.\nDurante questo dibattito, altri autori iniziarono a scrivere manuali di statistica per fornire uno strumento di lavoro ai ricercatori. Poiché molti di questi autori non erano statistici e avevano solo una comprensione superficiale della distinzione tra i vari approcci, crearono un sistema ibrido che utilizzava il valore-\\(p\\) proposto da Fisher all’interno del “sistema rigoroso” proposto da Neyman e Pearson. È in questo contesto che la soglia di un valore-\\(p\\) pari a 0.05 venne definita come “statisticamente significativa”.\nTuttavia, dal punto di vista storico, il valore-\\(p\\) proposto da Fisher aveva un significato molto diverso da quello che viene attribuito oggi nel mondo della ricerca. Come abbiamo visto, il valore-\\(p\\) era solo uno strumento informale utilizzato da Fisher all’interno di un processo decisionale più ampio, e il suo uso all’interno del sistema ibrido creato dai manuali di statistica era privo di giustificazione e fondamento.\nNel 2016 l’American Statistical Association ha pubblicato un articolo nel quale si esprime una grande preoccupazione per l’uso inappropriato che viene fatto del valore-\\(p\\) nella pratica scientifica odierna Wasserstein & Lazar (2016):\n\n\\(P\\)-values do not measure the probability that the studied hypothesis is true, or the probability that the data were produced by random chance alone. Researchers often wish to turn a \\(p\\)-value into a statement about the truth of a null hypothesis, or about the probability that random chance produced the observed data. The \\(p\\)-value is neither. It is a statement about data in relation to a specified hypothetical explanation, and is not a statement about the explanation itself.\n\nL’articolo prosegue affermando che:\n\nScientific conclusions and business or policy decisions should not be based only on whether a \\(p\\)-value passes a specific threshold. Practices that reduce data analysis or scientific inference to mechanical “bright-line” rules (such as “\\(p &lt; 0.05\\)”) for justifying scientific claims or conclusions can lead to erroneous beliefs and poor decision making. A conclusion does not immediately become ‘true’ on one side of the divide and ‘false’ on the other. Researchers should bring many contextual factors into play to derive scientific inferences, including the design of a study, the quality of the measurements, the external evidence for the phenomenon under study, and the validity of assumptions that underlie the data analysis. Pragmatic considerations often require binary, ‘yes-no’ decisions, but this does not mean that \\(p\\)-values alone can ensure that a decision is correct or incorrect. The widespread use of “statistical significance” (generally interpreted as ) as a license for making a claim of a scientific finding (or implied truth) leads to considerable distortion of the scientific process.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#p-hacking",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#p-hacking",
    "title": "77  Limiti dell’inferenza frequentista",
    "section": "77.2 \\(P\\)-hacking",
    "text": "77.2 \\(P\\)-hacking\nLa pratica del \\(P\\)-hacking rappresenta la principale fallacia associata all’utilizzo del valore-\\(p\\) ed è nota anche come “\\(P\\)-hacking”, “data-dredging”, “snooping”, “fishing”, “significance-chasing” o “double-dipping”. Secondo Uri Simonsohn, docente presso l’Università della Pennsylvania, il \\(P\\)-hacking consiste nel tentativo di provare diverse ipotesi finché non si ottiene il risultato desiderato. Ad esempio, si potrebbe dire: “Quel risultato sembra essere stato ottenuto attraverso il \\(p\\)-hacking, gli autori hanno eliminato una delle condizioni in modo che il valore-\\(p\\) complessivo fosse inferiore a 0.05” oppure “Lei è una \\(p\\)-hacker, controlla sempre i dati mentre vengono raccolti”.\nQuesta pratica ha l’effetto di trasformare uno studio esplorativo, che dovrebbe essere sempre interpretato con cautela, in uno studio (apparentemente) confermativo, il cui risultato appare “robusto”, ma che in realtà ha una probabilità pressoché nulla di essere replicato in studi successivi. Secondo le simulazioni di Simonsohn, il cambiamento di poche decisioni nel processo di analisi dei dati può aumentare fino al 60% il tasso di falsi positivi in un singolo studio.\nIl \\(P\\)-hacking è diffuso soprattutto negli studi che tentano di dimostrare piccoli effetti usando dati molto rumorosi. Un’analisi della letteratura psicologica ha mostrato che i valori-\\(p\\) riportati dagli psicologi tendono a concentrarsi su valori appena superiori alla soglia minima dello 0.05. Questo risultato può essere interpretato come conseguenza della pratica del \\(P\\)-hacking: i ricercatori eseguono molteplici test statistici fino a trovare uno che risulta “statisticamente significativo” e poi riportano solo quello. Come mostra la figura seguente, questa pratica non riguarda solo la psicologia, ma è diffusa in tutti i campi della ricerca scientifica.\n\n\n\nDistribuzione dei valori-\\(p\\) nelle pubblicazioni scientifiche di economia, psicologia e biologia.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#critiche-al-valore-p",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#critiche-al-valore-p",
    "title": "77  Limiti dell’inferenza frequentista",
    "section": "77.3 Critiche al valore-\\(p\\)",
    "text": "77.3 Critiche al valore-\\(p\\)\nIl valore-\\(p\\) è stato paragonato a creature noiose e ostinate come le zanzare, ai vestiti nuovi dell’imperatore, ovvero alla tendenza di non voler riconoscere evidenti problemi, ma preferire di far finta di nulla, o ad un intellectual rake sterile, che non porta alcun frutto. Si è anche ironizzato sul fatto che la procedura di statistical hypothesis inference testing venga chiamata così solo per l’acronimo che produce.\nIl valore-\\(p\\) incoraggia un modo di pensare errato, spostando l’attenzione dal problema centrale della ricerca, ovvero la forza della manipolazione sperimentale, alla dimostrazione di una falsa ipotesi che si sa a priori essere falsa (l’ipotesi nulla). Ad esempio, uno studio con più di 19.000 individui ha dimostrato che coloro che incontrano il loro partner online hanno una probabilità minore di divorziare (\\(p &lt;\\) 0,002) e sono più soddisfatti della loro vita matrimoniale (\\(p &lt;\\) 0,001) rispetto a chi non si è conosciuto online. Questo può sembrare un risultato interessante, ma senza considerare la dimensione dell’effetto, ovvero il tasso di divorzio che scende dal 7.67% al 5.96% e l’aumento dell’indice di soddisfazione matrimoniale da 5.48 a 5.64 su una scala a sette punti, il risultato perde di interesse. In generale, la domanda cruciale non è “c’è un effetto o no?” ma piuttosto “qual è la dimensione dell’effetto?”.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#leffetto-sperimentale-è-esattamente-nullo",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#leffetto-sperimentale-è-esattamente-nullo",
    "title": "77  Limiti dell’inferenza frequentista",
    "section": "77.4 L’effetto sperimentale è esattamente nullo?",
    "text": "77.4 L’effetto sperimentale è esattamente nullo?\nUna delle critiche più frequenti alla logica di verifica delle ipotesi statistiche riguarda l’assunzione irrealistica che l’effetto della manipolazione sperimentale sia “esattamente” nullo. Ad esempio, la fisica ci insegna che lo spostamento di un grammo di massa in una stella distante qualche anno luce dalla Terra può influenzare il movimento delle molecole di un gas sulla Terra Borel (1914). Questo ci suggerisce che ogni manipolazione sperimentale produca, in qualche modo, un effetto. Pertanto, secondo Andrew Gelman, il problema non è dimostrare falsa l’ipotesi nulla, ovvero che la manipolazione sperimentale non produca alcun effetto, ma piuttosto valutare se la dimensione dell’effetto è sufficientemente grande da avere un impatto pratico e se l’effetto sia riproducibile. In questo senso, la logica di verifica dell’ipotesi nulla può essere problematica, soprattutto quando si lavora con piccoli campioni e piccoli effetti, come nella maggior parte degli studi in psicologia, poiché può portare ad una sovrastima della dimensione dell’effetto e ad una visione binaria del risultato (vero/falso), invece di concentrarsi sulla stima non distorta della dimensione effettiva dell’effetto.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#attenti-al-valore-p",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#attenti-al-valore-p",
    "title": "77  Limiti dell’inferenza frequentista",
    "section": "77.5 Attenti al valore-\\(p\\)!",
    "text": "77.5 Attenti al valore-\\(p\\)!\nConsideriamo il seguente problema. Eseguiamo un \\(t\\)-test per due campioni indipendenti e sottoponiamo a verifica l’ipotesi nulla dell’eguaglianza delle due medie. Sia \\(\\alpha = 0.05\\). Otteniamo un valore-\\(p\\) di \\(0.04\\). Qual è la probabilità che i due campioni siano tratti da distribuzioni con la stessa media?\n\n\\(19/20; \\quad\\) (b) \\(1/19; \\quad\\) (c) \\(1/20; \\quad\\) (d) \\(95/100; \\quad\\) (e) sconosciuta.\n\nLa risposta corretta è: (e) sconosciuta. La statistica frequentista definisce le probabilità dei dati condizionatamente alle ipotesi (assunte come vere). Non consente di stabilire la probabilità di un’ipotesi.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#la-crisi-della-riprodicibilità-dei-risultati-della-ricerca",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#la-crisi-della-riprodicibilità-dei-risultati-della-ricerca",
    "title": "77  Limiti dell’inferenza frequentista",
    "section": "77.6 La crisi della riprodicibilità dei risultati della ricerca",
    "text": "77.6 La crisi della riprodicibilità dei risultati della ricerca\nNegli ultimi anni, la mancanza di replicabilità dei risultati della ricerca - inclusa la ricerca psicologica - è diventata un tema di grande rilevanza. In questo contesto, è stato evidenziato che alcuni aspetti del metodo scientifico, in particolare il concetto di valore-p e la pratica di verificare la significatività dell’ipotesi nulla (NHST, Null Hypothesis Significance Testing), potrebbero contribuire a questa “crisi della ricerca scientifica”. Un’analisi più approfondita di questo problema è stata fornita da Gelman (2016), il quale sostiene che la pratica della NHST sia intrinsecamente problematica. Infatti, essa incoraggia il ricercatore a cercare di rigettare un’ipotesi “fantoccio” (straw-man) che è certamente falsa a priori o, almeno, poco interessante dal punto di vista scientifico, a favore di un’ipotesi alternativa che il ricercatore preferisce. In generale, sembra più ragionevole affermare che la differenza tra due condizioni sia molto piccola, piuttosto che affermare che sia esattamente uguale a zero.\nSpesso nei libri di statistica viene trasmesso il messaggio che la NHST sia una forma di “alchimia” che cerca di trasformare la casualità in una sorta di certezza, con l’uso di termini come “confidenza” e “significatività” Gelman (2016). Il processo di raccolta dei dati, analisi e inferenza statistica che ne segue viene poi riassunto in una conclusione espressa in termini di valore-p e di intervallo di confidenza che escludono lo zero. Tuttavia, ciò può dare l’impressione errata che il ricercatore abbia una comprensione completa delle proprietà del fenomeno in questione. Il problema principale della NHST è che spesso produce risultati “statisticamente significativi” in situazioni in cui le caratteristiche del fenomeno non giustificano la conclusione a cui il ricercatore arriva. Questo può portare alla non replicabilità dei risultati della ricerca.\nLa comunità degli statistici ha evidenziato come la non replicabilità dei risultati delle ricerche sia particolarmente evidente quando i ricercatori, utilizzando la metodologia NHST, giungono a conclusioni errate basate sull’osservazione di piccoli campioni con effetti di dimensioni ridotte. Queste condizioni, insieme ad altre, rendono estremamente problematica l’applicazione della NHST. Purtroppo, queste situazioni descrivono molte delle ricerche recenti in psicologia.\nLa statistica è stata definita come un metodo per prendere decisioni razionali in situazioni di incertezza. Gli statistici consigliano ai ricercatori di non solo diventare esperti nelle tecniche statistiche, ma anche di imparare a convivere con l’incertezza, nonostante la sempre crescente sofisticazione delle tecniche disponibili. Convivere con l’incertezza implica evitare di pensare che ottenere un valore-\\(p\\) “statisticamente significativo” significhi risolvere un problema scientifico. Come possiamo allora avere fiducia in ciò che abbiamo appreso dai dati? Una possibile strategia è la replicazione e la convalida esterna, ma nella ricerca in psicologia e nelle scienze sociali, questo può spesso essere difficile da perseguire a causa degli oneri elevati che comporta. Il problema di quali strumenti metodologici e metodi statistici siano più appropriati per indagare sui fenomeni psicologici, senza essere ingannati, rimane dunque un problema aperto.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#commenti-e-considerazioni-finali",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#commenti-e-considerazioni-finali",
    "title": "77  Limiti dell’inferenza frequentista",
    "section": "77.7 Commenti e considerazioni finali",
    "text": "77.7 Commenti e considerazioni finali\nNon possiamo concludere senza sottolineare la controversia che circonda la nozione di valore-\\(p\\). Pur essendo ancora ampiamente utilizzato e spesso interpretato erroneamente, il valore-\\(p\\) conferisce solo una patina di legittimità ai risultati di studi dubbi, incoraggia cattive pratiche di ricerca e promuove la produzione di falsi positivi. Inoltre, è difficile comprendere appieno il significato di questa nozione. Anche gli esperti, quando chiamati a fornire una definizione di valore-\\(p\\), spesso sbagliano la risposta. Ciò che i ricercatori vogliono sapere è se i risultati della ricerca sono corretti o meno, ma il valore-\\(p\\) non fornisce questa informazione. Non dice nulla sulla dimensione dell’effetto, sulla forza dell’evidenza o sulla probabilità che il risultato sia stato ottenuto casualmente. Quindi, qual è il suo significato? Stuart Buck risponde così:\n\nImagine that you have a coin that you suspect is weighted toward heads. (Your null hypothesis is then that the coin is fair.) You flip it 100 times and get more heads than tails. The \\(p\\)-value won’t tell you whether the coin is fair, but it will tell you the probability that you’d get at least as many heads as you did if the coin was fair. That’s it – nothing more.\n\nIn sintesi, possiamo concludere che il valore-\\(p\\) risponde a una domanda molto specifica che non ha alcuna rilevanza per la validità scientifica dei risultati della ricerca. In un’epoca in cui la crisi della riproducibilità dei risultati è sempre più evidente Baker (2016), il test dell’ipotesi nulla e gli intervalli di confidenza frequentisti sono stati identificati come una delle principali cause del problema, spingendo molti ricercatori a cercare soluzioni alternative.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#bibliografia",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#bibliografia",
    "title": "77  Limiti dell’inferenza frequentista",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBaker, M. (2016). Reproducibility Crisis. Nature, 533(7604), 452–454.\n\n\nBorel, E. (1914). Introduction Géométrique. G. Villars, New York.\n\n\nGelman, A. (2016). Commentary on «Crisis in Science? Or Crisis in Statistics! Mixed Messages in Statistics with Impact on Science». Journal of Statistical Research, 48-50(1), 11–12.\n\n\nGoligher, E. C., Heath, A., & Harhay, M. O. (2024). Bayesian statistics for clinical research. The Lancet, 404(10457), 1067–1076. https://doi.org/10.1016/S0140-6736(24)00055-9\n\n\nNuzzo, R. (2014). Statistical Errors. Nature, 506(7487), 150–152.\n\n\nWasserstein, R. L., & Lazar, N. A. (2016). The ASA’s statement on p-values: context, process, and purpose. The American Statistician, 70(2), 129–133.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html",
    "href": "chapters/replication_crisis/03_effect_size.html",
    "title": "\n78  La grandezza dell’effetto\n",
    "section": "",
    "text": "78.1 Introduzione\nLa dimensione dell’effetto (effect size) è un concetto fondamentale nella metodologia della ricerca, utilizzato per quantificare la forza della relazione statistica tra due variabili. Questa misura rappresenta l’entità dell’effetto di un intervento o di un trattamento in modo standardizzato, descrivendo in termini quantitativi l’importanza di un fenomeno osservato.\nÈ cruciale distinguere tra la dimensione dell’effetto e la significatività statistica. Un risultato può essere “statisticamente significativo” pur avendo un effetto di piccole dimensioni, e viceversa. La conoscenza di uno di questi concetti non fornisce automaticamente informazioni sull’altro, evidenziando la necessità di considerare entrambi gli aspetti nell’analisi dei dati.\nL’importanza della dimensione dell’effetto è ampiamente riconosciuta nel campo della ricerca scientifica. Il manuale dell’American Psychological Association (APA) del 2010 ne sottolinea la rilevanza, raccomandando di riportare questa misura negli studi pubblicati. Di conseguenza, la maggior parte degli articoli nelle riviste associate all’APA include la dimensione dell’effetto, generalmente indicata tra parentesi accanto al valore di p.\nNonostante la sua importanza e la prassi di riportarla, la psicologia scientifica spesso mostra una carenza nella corretta valutazione e interpretazione delle dimensioni dell’effetto. Molti ricercatori si limitano a comunicare questi valori senza esaminarli approfonditamente, portando a conclusioni che possono risultare superficiali, poco informative, fuorvianti o addirittura errate. Questa tendenza rivela una sottovalutazione sistematica e una diffusa incomprensione delle dimensioni dell’effetto, anche tra i professionisti della ricerca.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html#misurazione-delleffetto-approcci-e-applicazioni",
    "href": "chapters/replication_crisis/03_effect_size.html#misurazione-delleffetto-approcci-e-applicazioni",
    "title": "\n78  La grandezza dell’effetto\n",
    "section": "\n78.2 Misurazione dell’Effetto: Approcci e Applicazioni",
    "text": "78.2 Misurazione dell’Effetto: Approcci e Applicazioni\nTra le metriche più adottate per quantificare la dimensione dell’effetto si annoverano il \\(d\\) di Cohen e l’\\(r\\) di Pearson. Il \\(d\\) di Cohen è prevalentemente impiegato per descrivere le differenze tra le medie di gruppi sperimentali, quantificando questa differenza in termini di una deviazione standard aggregata.\nLa differenza standardizzata delle medie tra due gruppi può essere calcolata con la seguente formula (equazione 5.1, Glass et al., 1981),\n\\[\nd_p = \\frac{M_1 - M_2}{S_p}.\n\\]\nUn valore positivo di \\(d_p\\) indica che la media del gruppo 1 è maggiore della media del gruppo 2. Dividere la differenza delle medie per la deviazione standard combinata, \\(S_p\\), è la formulazione classica del \\(d\\) di Cohen. La deviazione standard combinata, \\(S_p\\), può essere calcolata come la radice quadrata della varianza media (ponderata per i gradi di libertà, \\(df = n-1\\)) del gruppo 1 e del gruppo 2 (pp. 108, Glass et al., 1981):\n\\[\nS_p = \\sqrt{\\frac{(n_1 - 1) S_1^2 + (n_2 - 1) S_2^2}{n_1 + n_2 - 2}}.\n\\]\nSi noti che il termine varianza si riferisce al quadrato della deviazione standard (\\(S^2\\)). Il \\(d_p\\) di Cohen è correlato alla statistica t di un test t per campioni indipendenti. Infatti, possiamo calcolare il valore di \\(d_p\\) a partire dalla statistica \\(t\\) con la seguente formula (equazione 5.3, Glass et al., 1981):\n\\[\nd = t \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}.\n\\]\nL’errore standard corrispondente di \\(d_p\\) è,\n\\[\nSE_{d_p} = \\sqrt{\\frac{n_1 + n_2}{n_1 n_2} + \\frac{d_p^2}{2(n_1 + n_2)}}.\n\\]\nLa statistica \\(r\\) di Pearson, d’altro canto, viene utilizzato per esprimere il grado di previsione di una variabile attraverso un’altra, fornendo una misura della correlazione. È interessante notare come queste due misure possano essere convertite l’una nell’altra attraverso la relazione:\n\\[\nd = \\frac{2r}{\\sqrt{1-r^2}}.\n\\]",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html#interpretare-la-dimensione-delleffetto",
    "href": "chapters/replication_crisis/03_effect_size.html#interpretare-la-dimensione-delleffetto",
    "title": "\n78  La grandezza dell’effetto\n",
    "section": "\n78.3 Interpretare la Dimensione dell’Effetto",
    "text": "78.3 Interpretare la Dimensione dell’Effetto\nL’interpretazione delle dimensioni dell’effetto solitamente avviene in due modi comuni: uno è privo di significato e l’altro è seriamente fuorviante.\n\n\nGli Standard di Cohen. Funder (2019) affermano che l’interpretazione più ampiamente utilizzata ma priva di senso delle dimensioni dell’effetto richiama gli standard stabiliti da Jacob Cohen (1977, 1988). Cohen ha fissato i valori di r di .10, .30 e .50 come soglie per effetti piccoli, medi e grandi, rispettivamente. Tuttavia, Cohen stesso ha dichiarato che queste soglie dovrebbero essere utilizzate solo in assenza di una base migliore e in seguito ha espresso rammarico per averle proposte.\nI termini “piccolo”, “medio” e “grande” sono privi di significato senza un contesto di riferimento. È necessario rispondere a due domande fondamentali: (a) piccolo, medio o grande rispetto a cosa? e (b) piccolo, medio o grande a quale scopo?\n\n\nElevare al Quadrato la Correlazione. Secondo Funder & Ozer (2019), un altro metodo comune per valutare la dimensione dell’effetto è ancora più problematico: elevare al quadrato il valore di r. Ad esempio, un r di .30 elevato al quadrato produce .09, interpretato come “proporzione di varianza spiegata”. Questa conversione spesso viene riportata con la parola “solo”, come in “la correlazione di .30 ha spiegato solo il 9% della varianza”.\nNon esiste una giustificazione valida per considerare r² come una misura appropriata della dimensione dell’effetto. La statistica r corrisponde alla pendenza di regressione quando entrambe le variabili sono standardizzate, mentre r² è molto meno interpretabile perché riflette la proporzione di varianza in una variabile spiegata da un’altra.\nUn esempio illustrativo è fornito da Darlington (1990). Immaginiamo un gioco in cui si lanciano prima un nickel (5¢) e poi un dime (10¢), ricevendo un pagamento di 5¢ o 10¢ rispettivamente se la moneta mostra testa. Le correlazioni tra il valore del nickel e il pagamento (r = .4472) e tra il valore del dime e il pagamento (r = .8944) sono calcolate. Elevando al quadrato queste correlazioni, si ottiene che i nickel spiegano il 20% della varianza nel pagamento, mentre i dime spiegano l’80%. Tuttavia, interpretare questi valori come indicazione che i dime contano quattro volte tanto quanto i nickel è fuorviante. Le correlazioni originali (.8944 è esattamente il doppio di .4472) offrono un confronto più informativo. In conclusione, elevare al quadrato r per valutare la dimensione dell’effetto non solo è poco informativo, ma può anche essere fuorviante.\n\n\n\n78.3.1 Alternative migliori\nÈ cruciale interpretare le dimensioni degli effetti in modo che ne arricchisca il significato. Funder & Ozer (2019) propongono due strategie principali: l’adozione di benchmark (criteri di riferimento) e la valutazione delle implicazioni pratiche dei risultati.\n\nUtilizzare criteri di riferimento significa confrontare l’entità di un risultato con quella di risultati ben noti e ampiamente compresi. Simile al modo in cui giudichiamo l’altezza di una persona basandoci su confronti con altri, i ricercatori possono ottenere una percezione accurata dell’importanza di un risultato confrontandolo con la dimensione di effetti noti, sia quelli tipici del campo di studio sia quelli emersi da ricerche passate.\nUn approccio al benchmarking può includere l’analisi di risultati considerati “classici” nel campo di interesse o la considerazione di dimensioni dell’effetto per risultati che hanno ottenuto un solido consenso nella comunità psicologica.\nIn un’ottica più ampia, alcuni ricercatori hanno proposto benchmark per la dimensione dell’effetto calcolando medie su vasti corpi di letteratura. Ad esempio, uno studio di psicologia sociale ha esaminato 708 correlazioni ottenute meta-analiticamente, rivelando che la dimensione media dell’effetto \\(r\\) era di .19.\nLa conoscenza comune o i risultati di ricerche non psicologiche possono offrire benchmark per valutare la forza di una relazione tra variabili. Un esempio è l’efficacia degli antistaminici contro il comune raffreddore, che corrisponde a un \\(r\\) di .11, mentre l’effetto degli anti-infiammatori non steroidei (come l’ibuprofene) sul dolore è di \\(r = .14\\).\n\nTali confronti illustrano come l’interpretazione delle dimensioni dell’effetto possa essere notevolmente approfondita e resa più significativa attraverso il riferimento a benchmark consolidati o intuitivamente comprensibili, sia dentro che fuori il campo della psicologia. Questo metodo consente di inserire i risultati di nuove ricerche in un contesto più vasto, favorendo una valutazione più consapevole della loro rilevanza relativa.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html#raccomandazioni-per-la-pratica-di-ricerca",
    "href": "chapters/replication_crisis/03_effect_size.html#raccomandazioni-per-la-pratica-di-ricerca",
    "title": "\n78  La grandezza dell’effetto\n",
    "section": "\n78.4 Raccomandazioni per la Pratica di Ricerca",
    "text": "78.4 Raccomandazioni per la Pratica di Ricerca\nFunder & Ozer (2019) concludono il loro articolo con una serie di raccomandazioni per migliorare la pratica di riportare le dimensioni degli effetti negli studi scientifici.\nRiportare sempre e in modo evidente le dimensioni degli effetti. Ogni studio dovrebbe evidenziare chiaramente le dimensioni degli effetti. Una conseguenza di questa raccomandazione è che la dimensione del campione di uno studio deve essere adeguata affinché la stima della dimensione dell’effetto sia affidabile.\nCondurre studi con campioni ampi. Studi con campioni ampi sono ideali. Sebbene questo non sia sempre fattibile con certi tipi di ricerca o popolazioni specifiche, dovrebbe essere una priorità aumentare il più possibile la dimensione del campione.\nRiportare le dimensioni degli effetti in termini utili nel contesto. Il coefficiente di correlazione \\(r\\) di Pearson, essendo una misura standardizzata della dimensione dell’effetto, non fornisce informazioni sulle unità di misura dello studio. Pertanto, è necessario utilizzare misure delle dimensioni degli effetti che siano utili nel contesto specifico dello studio, come differenze medie o coefficienti di regressione grezzi, accanto a misure standardizzate, quando possibile.\nEvitare terminologia vuota. Si dovrebbe smettere di elevare al quadrato i valori di \\(r\\) per minimizzare l’apparente piccola percentuale di varianza spiegata e di utilizzare senza riflettere le linee guida di J. Cohen (1977, 1988), che lo stesso Cohen ha successivamente disconosciuto. Idealmente, termini come “piccolo” e “grande” dovrebbero essere eliminati dal vocabolario delle dimensioni degli effetti, poiché sono etichette soggettive e spesso arbitrarie che non aggiungono informazioni utili ai risultati quantitativi.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html#commenti-e-considerazioni-finali",
    "href": "chapters/replication_crisis/03_effect_size.html#commenti-e-considerazioni-finali",
    "title": "\n78  La grandezza dell’effetto\n",
    "section": "\n78.5 Commenti e considerazioni finali",
    "text": "78.5 Commenti e considerazioni finali\nLa sovrastima della grandezza dell’effetto in psicologia costituisce un problema diffuso. Un principio fondamentale della psicologia sociale e dell’economia comportamentale, almeno come viene presentato nei media e insegnato in molte scuole di business, è che piccoli “nudge” o spinte gentili, spesso cose che potremmo pensare non ci influenzino affatto, possono avere grandi effetti sul comportamento. Questo ha portato a numerose affermazioni sensazionalistiche, come l’idea che le elezioni siano decise da partite di football, o che la presentazione subliminale di una faccina sorridente possa causare enormi cambiamenti negli atteggiamenti verso l’immigrazione.\nIl modello di mondo alla base di queste affermazioni non è solo “l’effetto farfalla”, ovvero che piccoli cambiamenti possono avere grandi effetti, ma piuttosto che piccoli cambiamenti possono avere effetti grandi e prevedibili. È quello che a volte viene chiamato il modello “a pulsante” delle scienze sociali: l’idea che se fai X, puoi aspettarti di vedere Y.\nTuttavia, questa visione presenta diversi problemi:\n\nSovrastima degli effetti: Molti studi riportano effetti sorprendentemente grandi per interventi minimi, che spesso non vengono replicati in studi successivi.\nMancanza di considerazione delle interazioni: Se esistessero molti effetti grandi e prevedibili sul comportamento, questi interferirebbero tra loro, rendendo difficile osservare effetti coerenti nei dati osservazionali.\nInstabilità: Un sistema sociale con molti effetti grandi e prevedibili sarebbe instabile e difficile da studiare.\nGeneralizzazione eccessiva: Spesso si tende a generalizzare risultati ottenuti in condizioni di laboratorio molto specifiche a contesti più ampi e complessi della vita reale.\nBias di pubblicazione: Gli studi che riportano effetti grandi e statisticamente significativi hanno maggiori probabilità di essere pubblicati, creando una rappresentazione distorta della realtà.\n\nÈ importante sottolineare che la psicologia descrive molti fenomeni robusti, per esempio nella psicologia clinica e nella psicologia della percezione. Tuttavia, è fondamentale adottare un approccio più cauto e sfumato nell’interpretazione e nella comunicazione dei risultati della ricerca psicologica. La consapevolezza di questo problema ha portato a una maggiore enfasi sulla replicabilità degli studi, sull’uso di campioni più ampi e su metodi statistici più robusti. Inoltre, sta emergendo un approccio più critico e riflessivo nella comunità scientifica, che riconosce la complessità dei fenomeni psicologici e la necessità di evitare semplificazioni eccessive.\nIn conclusione, mentre la psicologia offre preziose intuizioni sul comportamento umano, è essenziale mantenere un sano scetticismo verso affermazioni di effetti grandi e facilmente ottenibili. La realtà è spesso più complessa e sfumata di quanto suggerito da titoli sensazionalistici o da singoli studi.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/replication_crisis/03_effect_size.html#informazioni-sullambiente-di-sviluppo",
    "title": "\n78  La grandezza dell’effetto\n",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pointblank_0.12.2 haven_2.5.4       labelled_2.13.0   mice_3.17.0      \n#&gt;  [5] see_0.9.0         gridExtra_2.3     patchwork_1.3.0   bayesplot_1.11.1 \n#&gt;  [9] psych_2.4.12      scales_1.3.0      markdown_1.13     knitr_1.49       \n#&gt; [13] lubridate_1.9.4   forcats_1.0.0     stringr_1.5.1     dplyr_1.1.4      \n#&gt; [17] purrr_1.0.2       readr_2.1.5       tidyr_1.3.1       tibble_3.2.1     \n#&gt; [21] ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      shape_1.4.6.1     xfun_0.49         htmlwidgets_1.6.4\n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2      \n#&gt;  [9] generics_0.1.3    parallel_4.4.2    pan_1.9           pacman_0.5.1     \n#&gt; [13] pkgconfig_2.0.3   jomo_2.7-6        Matrix_1.7-1      lifecycle_1.0.4  \n#&gt; [17] compiler_4.4.2    farver_2.1.2      munsell_0.5.1     mnormt_2.1.1     \n#&gt; [21] codetools_0.2-20  htmltools_0.5.8.1 glmnet_4.1-8      nloptr_2.1.1     \n#&gt; [25] pillar_1.10.0     MASS_7.3-61       iterators_1.0.14  rpart_4.1.23     \n#&gt; [29] boot_1.3-31       foreach_1.5.2     mitml_0.4-5       nlme_3.1-166     \n#&gt; [33] tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4     splines_4.4.2    \n#&gt; [37] rprojroot_2.0.4   fastmap_1.2.0     grid_4.4.2        blastula_0.3.5   \n#&gt; [41] colorspace_2.1-1  cli_3.6.3         magrittr_2.0.3    survival_3.8-3   \n#&gt; [45] broom_1.0.7       withr_3.0.2       backports_1.5.0   timechange_0.3.0 \n#&gt; [49] rmarkdown_2.29    nnet_7.3-19       lme4_1.1-35.5     hms_1.1.3        \n#&gt; [53] evaluate_1.0.1    rlang_1.1.4       Rcpp_1.0.13-1     glue_1.8.0       \n#&gt; [57] minqa_1.2.8       jsonlite_1.8.9    R6_2.5.1",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html#bibliografia",
    "href": "chapters/replication_crisis/03_effect_size.html#bibliografia",
    "title": "\n78  La grandezza dell’effetto\n",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nFunder, D. C., & Ozer, D. J. (2019). Evaluating effect size in psychological research: Sense and nonsense. Advances in Methods and Practices in Psychological Science, 2(2), 156–168.\n\n\nGlass, G. V., McGaw, B., & Smith, M. L. (1981). Meta-analysis in Social Research. Sage Publications.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html",
    "href": "chapters/replication_crisis/04_s_m_errors.html",
    "title": "\n79  Errori di segno e errori di grandezza\n",
    "section": "",
    "text": "79.1 Introduzione\nIn questo capitolo verrà esaminata la relazione tra la crisi della replicabilità e la procedura di decisione statistica dell’approccio frequentista. In particolare, verranno discussi gli errori di tipo M (magnitude) e di tipo S (sign) che sono stati discussi da Loken & Gelman (2017).",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>79</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#il-filtro-della-significatività-statistica",
    "href": "chapters/replication_crisis/04_s_m_errors.html#il-filtro-della-significatività-statistica",
    "title": "\n79  Errori di segno e errori di grandezza\n",
    "section": "\n79.2 Il Filtro della Significatività Statistica",
    "text": "79.2 Il Filtro della Significatività Statistica\nNel ?sec-crisis abbiamo esaminato come la pratica scientifica contemporanea sia spesso compromessa da casi di frode, principalmente a causa delle notevoli implicazioni economiche legate alla pubblicazione su riviste scientifiche prestigiose. Questo problema è frequentemente sottovalutato, poiché le riviste sono riluttanti ad ammettere la necessità di correzioni o ritrattazioni degli articoli già pubblicati.\nLa frode scientifica rappresenta una minaccia evidente alla riproducibilità dei risultati, pilastro fondamentale del metodo scientifico. Tuttavia, le difficoltà nel replicare i risultati pubblicati non sono attribuibili esclusivamente alla frode o a “pratiche di ricerca disoneste” (Nelson et al., 2018). Un problema intrinseco riguarda il metodo statistico ampiamente adottato dai ricercatori: l’approccio del test di ipotesi nulla e della significatività statistica di stampo fisheriano. Secondo questo metodo, i risultati che non raggiungono la “significatività statistica” dovrebbero essere scartati, mentre quelli che la superano possono essere considerati credibili, basandosi unicamente su questo criterio (Wagenmakers et al., 2008).\nTuttavia, l’idea che la significatività statistica sia un filtro affidabile per distinguere i risultati di ricerca “validi” da quelli “non validi” è fondamentalmente errata. Numerose evidenze dimostrano la fallacia di questo approccio. Per approfondire questo aspetto, esamineremo lo studio di Loken & Gelman (2017), che mette in luce la relazione tra la crisi della replicabilità e la procedura di decisione statistica dell’approccio frequentista.\nUno dei principali problemi evidenziati dallo studio di Loken & Gelman (2017) è che, in contesti di ricerca complessi, la significatività statistica fornisce prove molto deboli riguardo al segno o all’entità di eventuali effetti sottostanti. In altre parole, il raggiungimento della significatività statistica non garantisce né la rilevanza né la consistenza dei risultati ottenuti.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>79</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#errori-di-tipo-m-e-s",
    "href": "chapters/replication_crisis/04_s_m_errors.html#errori-di-tipo-m-e-s",
    "title": "\n79  Errori di segno e errori di grandezza\n",
    "section": "\n79.3 Errori di tipo M e S\n",
    "text": "79.3 Errori di tipo M e S\n\nPer evidenziare le implicazioni del processo decisionale basato sulla significatività statistica, gli autori di Loken & Gelman (2017) hanno condotto una simulazione. In questa simulazione, hanno immaginato una ricerca ipotetica in cui un effetto reale, seppur molto debole, era presente, ma difficilmente individuabile senza una grande quantità di dati. I ricercatori hanno quindi cercato di rilevare questo effetto utilizzando l’approccio frequentista e valutando la significatività statistica.\nI risultati della simulazione hanno rivelato che, anche quando un effetto reale ma debole era presente, l’approccio frequentista tendeva a individuare un effetto significativo solo in una piccola percentuale dei casi. Inoltre, quando veniva individuato un effetto significativo, la sua stima di grandezza risultava molto imprecisa e instabile.\nIn altre parole, la significatività statistica fornisce solo un’indicazione generale sulla presenza o assenza di un effetto, ma non offre informazioni precise sulla sua dimensione o replicabilità. Questo problema diventa ancora più evidente quando si considera che molte ricerche in psicologia e scienze sociali utilizzano campioni relativamente piccoli, e gli effetti osservati in tali studi tendono ad essere molto modesti. In tali contesti, l’approccio frequentista rischia di fornire prove molto deboli e instabili riguardo alla presenza o assenza di un effetto, mettendo a rischio la replicabilità e l’affidabilità dei risultati della ricerca.\nRiproduciamo qui, in maniera semplificata, la simulazione condotta da Loken & Gelman (2017). Iniziamo ad importare le librerie necessarie.\nSupponiamo di considerare due campioni casuali indipendenti di dimensioni \\(n_1 = 20\\) e \\(n_2 = 25\\), estratti dalle distribuzioni normali \\(\\mathcal{N}(102, 10)\\) e \\(\\mathcal{N}(100, 10)\\) rispettivamente. La dimensione effettiva dell’effetto per la differenza tra le medie di questi due campioni è rappresentata da \\(d\\), calcolato attraverso la formula:\n\\[\nd = \\frac{\\bar{y}_1 - \\bar{y}_2}{s_p},\n\\]\ndove \\(\\bar{y}_1\\) e \\(\\bar{y}_2\\) sono le medie campionarie dei due gruppi, mentre \\(s_p\\) è la deviazione standard combinata definita come:\n\\[\ns_p = \\sqrt{\\frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1 + n_2 - 2}},\n\\]\ncon \\(s_1\\) e \\(s_2\\) rappresentanti le deviazioni standard campionarie dei due gruppi.\nNel caso specifico preso in esame, la dimensione effettiva dell’effetto è molto piccola, indicando che la differenza osservata tra le medie manca di significatività pratica. Questo suggerisce che la distinzione tra i due gruppi non ha un impatto sostanziale nella pratica.\n\n# Parametri\nmu_1 &lt;- 102  # Media del primo gruppo\nmu_2 &lt;- 100  # Media del secondo gruppo\nsigma &lt;- 10  # Deviazione standard comune\nn1 &lt;- 20     # Numero di osservazioni nel primo gruppo\nn2 &lt;- 25     # Numero di osservazioni nel secondo gruppo\n\n# Calcolo della differenza media\nmean_difference &lt;- abs(mu_1 - mu_2)\n\n# Calcolo della deviazione standard pooled\npooled_sd &lt;- sqrt(((n1 - 1) * sigma^2 + (n2 - 1) * sigma^2) / (n1 + n2 - 2))\n\n# Calcolo di Cohen's d\ncohen_d &lt;- mean_difference / pooled_sd\n\n# Output del risultato\ncat(\"Dimensione dell'effetto (Cohen's d):\", cohen_d, \"\\n\")\n#&gt; Dimensione dell'effetto (Cohen's d): 0.2\n\nEsaminiamo ora quali sarebbero le conclusioni derivanti dall’approccio frequentista mediante la procedura di decisione statistica in queste circostanze. Consideriamo una simulazione in cui vengono estratti due campioni: uno composto da 20 osservazioni dalla prima popolazione e l’altro da 25 osservazioni dalla seconda popolazione. Successivamente, viene eseguito il test \\(t\\) di Student.\nNell’approccio frequentista, se il valore-\\(p\\) risulta essere superiore a 0.05, i risultati vengono considerati non significativi e quindi scartati. Al contrario, se il valore-\\(p\\) è inferiore a 0.05, il risultato è considerato “pubblicabile” e si conclude che esiste una differenza significativa tra i due gruppi.\nPer comprendere appieno le conclusioni ottenute mediante la procedura frequentista in questa situazione, è necessario ripetere il processo sopra descritto per un ampio numero di iterazioni, ad esempio 50,000 volte. Questo implica che il processo di estrazione dei campioni e il calcolo dei valori-\\(p\\) vengono ripetuti numerose volte al fine di ottenere una visione completa delle possibili distribuzioni dei risultati.\n\n# Parametri\nn_samples &lt;- 50000\nmu_1 &lt;- 102\nmu_2 &lt;- 100\nsigma &lt;- 10\nn1 &lt;- 20\nn2 &lt;- 25\n\n# Inizializzazione del risultato\nres &lt;- c()\n\n# Simulazioni\nset.seed(123)  # Per la riproducibilità\nfor (i in 1:n_samples) {\n  # Generazione dei campioni casuali\n  y1 &lt;- rnorm(n1, mean = mu_1, sd = sigma)\n  y2 &lt;- rnorm(n2, mean = mu_2, sd = sigma)\n  \n  # Calcolo della dimensione dell'effetto\n  y1bar &lt;- mean(y1)\n  y2bar &lt;- mean(y2)\n  v1 &lt;- var(y1)\n  v2 &lt;- var(y2)\n  s &lt;- sqrt(((n1 - 1) * v1 + (n2 - 1) * v2) / (n1 + n2 - 2))\n  efsize &lt;- (y1bar - y2bar) / s\n  \n  # Calcolo del valore p\n  t_test &lt;- t.test(y1, y2, var.equal = TRUE)\n  \n  # Salvataggio della dimensione dell'effetto solo per risultati \"statisticamente significativi\"\n  if (t_test$p.value &lt; 0.05) {\n    res &lt;- c(res, efsize)\n  }\n}\n\n\nres_df &lt;- data.frame(effect_size = res)\n\nggplot(res_df, aes(x = effect_size)) +\n  geom_histogram(bins = 20, fill = \"blue\", color = \"black\", alpha = 0.7) +\n  geom_vline(\n    xintercept = 0.2, color = \"red\", linetype = \"dashed\", \n    size = 1.2, label = \"True Effect Size\") +\n  labs(\n    x = \"Effect Size\",\n    y = \"Frequency\",\n    title = \"Histogram of Effect Sizes for 'Statistically Significant' Results\"\n  ) \n#&gt; Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#&gt; ℹ Please use `linewidth` instead.\n#&gt; Warning in geom_vline(xintercept = 0.2, color = \"red\", linetype = \"dashed\",\n#&gt; : Ignoring unknown parameters: `label`\n\n\n\n\n\n\n\nCome sottolineato da Loken & Gelman (2017), l’utilizzo dell’approccio frequentista nella procedura di decisione statistica può portare a due tipi di errori significativi. Il primo errore, noto come “magnitude”, si manifesta nel fatto che i risultati pubblicati tendono a sovrastimare la vera grandezza dell’effetto. Nella simulazione effettuata, sebbene la vera grandezza dell’effetto fosse modesta (0.2), la media della grandezza dell’effetto per i risultati dichiarati “statisticamente significativi” era di circa 0.8, indicando una grandezza dell’effetto “ampia”.\nIl secondo errore, denominato “segno”, si verifica in alcune situazioni in cui, a causa della variabilità campionaria, viene commesso un errore nella direzione dell’effetto. In tali circostanze, il ricercatore potrebbe erroneamente concludere che \\(\\mu_2 &gt; \\mu_1\\), quando in realtà non è così. È importante notare che, anche in questi casi, la grandezza dell’effetto viene sovrastimata in termini assoluti.\nÈ interessante notare che le stesse conclusioni si applicherebbero anche se avessimo considerato l’intervallo di confidenza per la differenza tra le medie. In sintesi, l’approccio frequentista introduce un errore sistematico nella stima della grandezza dell’effetto, che è la quantità più importante che il ricercatore deve stimare. In alcune situazioni, può persino causare errori nella stima della direzione dell’effetto.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>79</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#riflessioni-conclusive",
    "href": "chapters/replication_crisis/04_s_m_errors.html#riflessioni-conclusive",
    "title": "\n79  Errori di segno e errori di grandezza\n",
    "section": "\n79.4 Riflessioni Conclusive",
    "text": "79.4 Riflessioni Conclusive\nIn conclusione, l’approccio frequentista non fornisce un metodo affidabile per valutare i risultati della ricerca e determinare la loro attendibilità o la necessità di scartarli [gelman2014beyond; Loken & Gelman (2017)]. Questa mancanza di affidabilità deriva dall’introduzione di errori sistematici nella stima delle dimensioni dell’effetto, che può anche portare a errori nella direzione dell’effetto in alcune circostanze. Di conseguenza, non sembra esserci motivo valido per continuare a impiegare questo approccio.\nAl contrario, l’adozione dell’approccio bayesiano sembra offrire risultati più precisi e affidabili nella valutazione dei dati di ricerca. Tale approccio considera la probabilità delle ipotesi alla luce dei dati osservati, evitando gli errori intrinseci dell’approccio frequentista e fornendo una base più solida per le decisioni sulla validità dei risultati.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>79</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#esercizi",
    "href": "chapters/replication_crisis/04_s_m_errors.html#esercizi",
    "title": "\n79  Errori di segno e errori di grandezza\n",
    "section": "\n79.5 Esercizi",
    "text": "79.5 Esercizi\n\nEsercizio 79.1 Esegui una simulazione con 10.000 ripetizioni (nrep = 10000) in cui vengono estratti due campioni casuali dalla stessa popolazione normale con media 0 e deviazione standard 10. Per ogni simulazione, esegui un t-test per confrontare le medie di due gruppi indipendenti.\n\nProporzione di risultati statisticamente significativi: Calcola la proporzione di risultati in cui si ottiene un risultato statisticamente significativo (p &lt; 0.05) in questa condizione in cui i campioni provengono dalla stessa popolazione, e quindi non c’è una differenza reale tra i gruppi. Questo ti darà un’idea della frequenza dei falsi positivi.\nGrandezza dell’effetto media: Calcola la grandezza dell’effetto (d di Cohen) media, considerando solo quei test in cui si è ottenuta una differenza statisticamente significativa. Questo valore ti mostrerà quanto grande appare l’effetto quando il risultato è significativo, nonostante la realtà sia priva di un effetto reale.\nRipetizione della simulazione con diverse grandezze campionarie: Ripeti la simulazione usando due diverse dimensioni campionarie: 20 osservazioni per gruppo e 200 osservazioni per gruppo. Confronta i risultati per capire come la dimensione del campione influenzi la proporzione di falsi positivi e la grandezza dell’effetto media.\nInterpretazione dei risultati: Interpreta i risultati alla luce del concetto del “filtro della significatività statistica”. Questo concetto suggerisce che tra tutti gli studi effettuati, tendono ad essere pubblicati e riportati solo quelli che ottengono risultati statisticamente significativi. Di conseguenza, i risultati significativi pubblicati possono sovrastimare la vera grandezza dell’effetto o indicare erroneamente che un effetto esiste quando in realtà non c’è. Questa simulazione dovrebbe mostrare come, anche in assenza di una differenza reale tra gruppi, si possano ottenere risultati apparentemente significativi con una certa frequenza, soprattutto quando la dimensione campionaria è piccola.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>79</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/replication_crisis/04_s_m_errors.html#informazioni-sullambiente-di-sviluppo",
    "title": "\n79  Errori di segno e errori di grandezza\n",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] see_0.9.0        gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1\n#&gt;  [5] psych_2.4.12     scales_1.3.0     markdown_1.13    knitr_1.49      \n#&gt;  [9] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [13] purrr_1.0.2      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [17] ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.3         rlang_1.1.4       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       yaml_2.3.10       tools_4.4.2       parallel_4.4.2   \n#&gt; [21] tzdb_0.4.0        colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5      \n#&gt; [25] R6_2.5.1          lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3  \n#&gt; [29] pillar_1.10.0     gtable_0.3.6      glue_1.8.0        xfun_0.49        \n#&gt; [33] tidyselect_1.2.1  farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-166     \n#&gt; [37] labeling_0.4.3    rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>79</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#bibliografia",
    "href": "chapters/replication_crisis/04_s_m_errors.html#bibliografia",
    "title": "\n79  Errori di segno e errori di grandezza\n",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nLoken, E., & Gelman, A. (2017). Measurement Error and the Replication Crisis. Science, 355(6325), 584–585.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nNelson, L. D., Simmons, J., & Simonsohn, U. (2018). Psychology’s renaissance. Annual review of psychology, 69(1), 511–534.\n\n\nWagenmakers, E.-J., Lee, M., Lodewyckx, T., & Iverson, G. J. (2008). Bayesian versus frequentist inference. Bayesian evaluation of informative hypotheses, 181–207.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>79</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/05_p_values.html",
    "href": "chapters/replication_crisis/05_p_values.html",
    "title": "\n80  La fragilità del p-valore\n",
    "section": "",
    "text": "80.1 Introduzione\nIl codice seguente è ispirato da un post sul blog di Andrew Gelman.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>La fragilità del *p*-valore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/05_p_values.html#simulazione",
    "href": "chapters/replication_crisis/05_p_values.html#simulazione",
    "title": "\n80  La fragilità del p-valore\n",
    "section": "\n80.2 Simulazione",
    "text": "80.2 Simulazione\nLa seguente simulazione ha l’obiettivo di mostrare quanto i p-valori possano essere “fragili” e variare notevolmente da campione a campione, anche quando i dati provengono da una distribuzione con parametri molto simili. Questo serve a dimostrare che il p-valore, spesso usato per determinare la significatività statistica di un effetto, può essere influenzato pesantemente dalla variabilità campionaria, soprattutto in campioni di piccole dimensioni o con effetti deboli. Gelman esprime questo concetto dicendo che\n\nthe difference between “significant” and “not significant” is not itself statistically significant.\n\n\n80.2.1 Logica della Simulazione\n\n\nObiettivo:\n\nDimostrare la variabilità dei p-valori calcolati per diversi campioni estratti da una popolazione con una media molto vicina a zero.\nMostrare come, nonostante l’effetto vero sia piccolo, i p-valori possano essere significativamente diversi tra loro, a seconda della variabilità e delle dimensioni del campione.\n\n\n\nSetup della Simulazione:\n\nGeneriamo \\(J = 10\\) campioni indipendenti, ognuno con un numero ridotto di osservazioni (\\(n = 10\\)), per massimizzare la variabilità dei risultati.\nOgni campione è generato da una distribuzione normale con una media vera di \\(\\mu = 0.05\\) e una deviazione standard di \\(\\sigma = 0.1\\). Questi parametri sono scelti per rendere la media dei campioni vicina a zero e, al tempo stesso, abbastanza variabile.\n\n\n\nCalcolo della media campionaria:\n\nPer ciascun campione, calcoliamo la media (\\(\\hat{\\mu}\\)) e la deviazione standard (\\(\\hat{\\sigma}\\)).\nLa media del campione (\\(\\hat{\\mu}\\)) è utilizzata come stima del parametro.\n\n\n\nCalcolo del p-valore:\n\nApplichiamo un t-test per ciascun campione per verificare l’ipotesi nulla (\\(H_0\\)) che la media del campione sia zero.\n\nIl p-valore viene calcolato utilizzando la formula classica del t-test:\n\\[\nt = \\frac{\\hat{\\mu}}{\\frac{\\hat{\\sigma}}{\\sqrt{n}}}\n\\]\ndove:\n\n\n\\(\\hat{\\mu}\\) è la media del campione,\n\n\\(\\hat{\\sigma}\\) è la deviazione standard del campione,\n\n\\(n\\) è il numero di osservazioni per campione.\n\n\n\nSuccessivamente, il p-valore è calcolato come:\n\\[\n\\text{p-value} = 2 \\times (1 - \\text{CDF}(|t|))\n\\]\ndove \\(\\text{CDF}\\) è la funzione cumulativa della distribuzione t con \\(n-1\\) gradi di libertà.\n\n\n\n\n80.2.2 Descrizione della Sintassi\nIl codice R è strutturato come segue:\n\nGenerazione dei campioni:\n\n\nCreiamo una lista di campioni (10 campioni in totale), ognuno con 10 osservazioni, utilizzando la distribuzione normale con media 0.05 e deviazione standard 0.1.\n\n\n\nCalcolo delle medie e dei p-valori:\n\nIteriamo su ciascun campione per calcolare la media (\\(\\hat{\\mu}\\)) e la deviazione standard (\\(\\hat{\\sigma}\\)).\nCalcoliamo il valore statistico \\(t\\) e il corrispondente p-valore utilizzando la distribuzione t.\n\n\n\nStampa dei risultati:\n\nI p-valori vengono arrotondati e stampati per osservare quanto siano variabili.\n\n\n\n\n# Imposta il seme per riproducibilità\nset.seed(1234)\n\n# Parametri della simulazione\nJ &lt;- 10              # Numero di campioni indipendenti\nn &lt;- 10              # Numero di osservazioni per campione\ntrue_mean &lt;- 0.05    # Media vera della popolazione\ntrue_sd &lt;- 0.1       # Deviazione standard della popolazione\n\n# Genera i campioni casuali\nsamples &lt;- replicate(J, rnorm(n, mean = true_mean, sd = true_sd), simplify = FALSE)\n\n# Calcola statistiche campionarie e p-valori\nresults &lt;- lapply(samples, function(sample) {\n  sample_mean &lt;- mean(sample)                         # Media campionaria\n  sample_sd &lt;- sd(sample)                             # Deviazione standard campionaria\n  t_statistic &lt;- sample_mean / (sample_sd / sqrt(n))  # Statistica t\n  p_value &lt;- 2 * (1 - pt(abs(t_statistic), df = n - 1))  # p-valore bilaterale\n  list(mean = sample_mean, sd = sample_sd, t = t_statistic, p_value = p_value)\n})\n\n# Converti i risultati in un data frame per facilitarne la visualizzazione\nresults_df &lt;- do.call(rbind, lapply(results, as.data.frame))\nrownames(results_df) &lt;- paste(\"C\", 1:J)\n\n# Visualizza i risultati\nprint(results_df)\n#&gt;         mean     sd      t p_value\n#&gt; C 1   0.0117 0.0996  0.371 0.71918\n#&gt; C 2   0.0382 0.1067  1.131 0.28718\n#&gt; C 3   0.0112 0.0666  0.532 0.60758\n#&gt; C 4  -0.0266 0.0894 -0.941 0.37112\n#&gt; C 5  -0.0110 0.0787 -0.441 0.66955\n#&gt; C 6   0.0221 0.1186  0.590 0.56994\n#&gt; C 7   0.1117 0.1144  3.086 0.01301\n#&gt; C 8   0.0458 0.0924  1.567 0.15157\n#&gt; C 9   0.0342 0.0735  1.470 0.17575\n#&gt; C 10  0.1061 0.0984  3.409 0.00776\n\n\nggplot(results_df, aes(x = rownames(results_df), y = p_value)) +\n  geom_point(size = 3, color = \"blue\") +\n  geom_hline(yintercept = 0.05, linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Variabilità dei p-valori nei campioni\",\n    x = \"Campioni\",\n    y = \"p-valore\"\n  ) \n\n\n\n\n\n\n\nImmaginiamo che questo sia un esperimento reale. Alcuni campioni potrebbero mostrare risultati compatibili con il puro rumore, altri fornire deboli indicazioni contro l’ipotesi nulla, mentre altri ancora potrebbero sembrare altamente significativi dal punto di vista statistico. Verrebbe naturale cercare di categorizzare questi risultati in qualche modo. Tuttavia, la differenza tra “significativo” e “non significativo” non è di per sé statisticamente significativa. Ad esempio, si potrebbe essere tentati di considerare rilevante una differenza tra un p-valore di 0.336 e uno di 0.003, ma non è così.\nQuesto scenario estremo riflette una situazione in cui non c’è una reale variazione sottostante. Se si utilizzasse un modello multilivello, probabilmente emergerebbe l’assenza di una variazione effettiva significativa.\n\n80.2.3 Punti chiave:\n\nIl p-valore descrive solo l’ipotesi nulla: È una misura relativa all’assenza di effetto, ma non ha necessariamente un significato diretto rispetto a un effetto reale, anche se piccolo.\nIl p-valore è altamente variabile: Essendo una trasformazione non lineare dello z-score (che ha un’interpretazione più chiara), il p-valore può comportarsi in modi non intuitivi, soprattutto con campioni piccoli.\nLe simulazioni sono istruttive: Anche esperimenti semplici come questo possono essere estremamente utili per comprendere le limitazioni e l’interpretazione dei risultati.\n\n80.2.4 Un avvertimento importante:\nAnche le inferenze bayesiane sono soggette a variabilità. Qualsiasi sintesi dei dati porta con sé un certo grado di incertezza. Il problema non risiede nei p-valori in sé, ma nel loro utilizzo scorretto. Interpretare un p-valore come una dichiarazione forte sulla realtà, invece di considerarlo un riassunto rumoroso di un esperimento specifico, è un errore comune.\nAllo stesso modo, fraintendimenti e sovrainterpretazioni possono verificarsi anche con approcci bayesiani. Ad esempio, l’adattamento di un modello con prior non informativi e l’interpretazione della probabilità posteriore di un parametro (ad esempio, maggiore di zero) sulla base di una soglia arbitraria può portare a conclusioni altrettanto problematiche. Questi risultati ci ricordano l’importanza di una sana cautela nell’interpretazione statistica, indipendentemente dal metodo utilizzato.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>La fragilità del *p*-valore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/05_p_values.html#riflessioni-conclusive",
    "href": "chapters/replication_crisis/05_p_values.html#riflessioni-conclusive",
    "title": "\n80  La fragilità del p-valore\n",
    "section": "\n80.3 Riflessioni Conclusive",
    "text": "80.3 Riflessioni Conclusive\nLa simulazione mostra che, nonostante le medie dei campioni siano generate con una distribuzione simile, i p-valori possono variare drasticamente. Questo effetto è amplificato dalla scelta di campioni piccoli e di una media vera molto vicina all’ipotesi nulla (zero). Dimostra quanto il p-valore possa essere influenzato da piccole variazioni nei dati e perché non sia sempre un indicatore affidabile per valutare l’efficacia o la presenza di un effetto.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>La fragilità del *p*-valore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/05_p_values.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/replication_crisis/05_p_values.html#informazioni-sullambiente-di-sviluppo",
    "title": "\n80  La fragilità del p-valore\n",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] see_0.9.0        gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1\n#&gt;  [5] psych_2.4.12     scales_1.3.0     markdown_1.13    knitr_1.49      \n#&gt;  [9] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [13] purrr_1.0.2      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [17] ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.3         rlang_1.1.4       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       tools_4.4.2       parallel_4.4.2    tzdb_0.4.0       \n#&gt; [21] colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5       R6_2.5.1         \n#&gt; [25] lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.0    \n#&gt; [29] gtable_0.3.6      glue_1.8.0        xfun_0.49         tidyselect_1.2.1 \n#&gt; [33] farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-166      labeling_0.4.3   \n#&gt; [37] rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>La fragilità del *p*-valore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/05_p_values.html#bibliografia",
    "href": "chapters/replication_crisis/05_p_values.html#bibliografia",
    "title": "\n80  La fragilità del p-valore\n",
    "section": "Bibliografia",
    "text": "Bibliografia",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>La fragilità del *p*-valore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html",
    "href": "chapters/replication_crisis/06_changes.html",
    "title": "81  Riforma",
    "section": "",
    "text": "81.1 Introduzione\nLa crisi della riproducibilità ha portato a una profonda riflessione sullo stato della ricerca nelle scienze comportamentali, cognitive e sociali. La scoperta che molti studi pubblicati non erano replicabili ha scosso la fiducia nella ricerca scientifica e ha messo in evidenza le carenze metodologiche e strutturali che affliggono il sistema accademico. Di fronte a questa crisi, sono state avanzate diverse proposte di riforma volte a migliorare la qualità e l’affidabilità della ricerca scientifica.\nSecondo Korbmacher et al. (2023) sono neccessarie riforme strutturali, cambiamenti procedurali e cambiamenti nella comunità scientifica.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>81</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#riforme-strutturali",
    "href": "chapters/replication_crisis/06_changes.html#riforme-strutturali",
    "title": "81  Riforma",
    "section": "81.2 Riforme Strutturali",
    "text": "81.2 Riforme Strutturali\n\n81.2.1 Integrazione della Riproducibilità nei Curriculum Educativi\nUna delle principali proposte per affrontare la crisi della riproducibilità è l’integrazione delle pratiche di riproducibilità nei curriculum educativi delle scienze psicologiche e affini. Attualmente, molti programmi di formazione non pongono sufficiente enfasi sull’importanza della replicabilità e della trasparenza nella ricerca. Incorporare queste tematiche nei corsi di metodologia della ricerca può sensibilizzare le nuove generazioni di ricercatori alla necessità di adottare pratiche più rigorose e trasparenti. Ad esempio, alcuni programmi universitari hanno iniziato a includere repliche di studi famosi come parte del percorso formativo degli studenti, offrendo loro l’opportunità di comprendere meglio i limiti e le potenzialità del processo scientifico.\n\n\n81.2.2 Incentivi per la Scienza Aperta\nOltre alla formazione, un altro aspetto cruciale è la riforma dei sistemi di incentivazione accademica. Tradizionalmente, il sistema accademico ha privilegiato la quantità di pubblicazioni e la novità dei risultati, piuttosto che la loro qualità e replicabilità. Per promuovere pratiche di scienza aperta, come la preregistrazione degli studi e la condivisione aperta dei dati, si propone l’introduzione di riconoscimenti ufficiali, come badge di “open science” o crediti accademici per la pubblicazione di rapporti registrati. Questi cambiamenti potrebbero favorire una maggiore adozione di pratiche che promuovono la trasparenza e rafforzano la fiducia nella ricerca scientifica.\nA tal proposito, è interessante considerare uno studio di Scheel et al. (2021). Gli autori hanno confrontato i risultati di rapporti registrati pubblicati (N = 71) con un campione casuale di studi ipotetico-deduttivi della letteratura standard (N = 152) in psicologia. Analizzando la prima ipotesi di ciascun articolo, hanno riscontrato che il 96% dei risultati nei rapporti standard erano positivi, contro solo il 44% nei rapporti registrati.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>81</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#cambiamenti-procedurali",
    "href": "chapters/replication_crisis/06_changes.html#cambiamenti-procedurali",
    "title": "81  Riforma",
    "section": "81.3 Cambiamenti Procedurali",
    "text": "81.3 Cambiamenti Procedurali\n\n81.3.1 Mercati di Previsione per la Credibilità della Ricerca\nI mercati di previsione sono stati proposti come uno strumento innovativo per valutare la credibilità della ricerca. In questi mercati, esperti e non esperti scommettono sulla probabilità che i risultati di determinati studi siano replicabili. Questo approccio ha dimostrato di avere un’elevata accuratezza nella classificazione della replicabilità degli studi, offrendo un metodo alternativo e complementare alla replicazione diretta. I mercati di previsione potrebbero essere particolarmente utili in contesti in cui la raccolta dati è costosa o difficile da realizzare, fornendo una prima indicazione sulla solidità dei risultati di ricerca.\n\n\n81.3.2 Strumenti di Valutazione Statistica\nUn’altra proposta riguarda l’adozione di nuovi strumenti di valutazione statistica per identificare e correggere il bias di pubblicazione e migliorare la potenza degli studi. Strumenti come la curva-p e la curva-z sono stati sviluppati per analizzare la distribuzione dei valori p e identificare eventuali distorsioni nei risultati pubblicati. Inoltre, alcuni studiosi hanno suggerito di abbassare il livello di significatività statistica standard da 0,05 a 0,005 per ridurre il tasso di falsi positivi e aumentare la robustezza dei risultati. Queste proposte, sebbene non risolutive, rappresentano passi importanti verso una maggiore precisione nelle analisi statistiche.\n\n\n81.3.3 Analisi Multiverso\nL’analisi multiverso è un’altra proposta innovativa che mira a gestire la molteplicità di scelte analitiche possibili in un singolo studio. Questa tecnica prevede l’esecuzione di molteplici analisi su uno stesso dataset, variando i parametri e le scelte metodologiche, per testare la stabilità dei risultati. L’adozione di questo approccio permette di evidenziare quanto i risultati siano sensibili alle scelte analitiche, contribuendo a una maggiore trasparenza e affidabilità nelle conclusioni tratte dagli studi.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>81</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#cambiamenti-nella-comunità",
    "href": "chapters/replication_crisis/06_changes.html#cambiamenti-nella-comunità",
    "title": "81  Riforma",
    "section": "81.4 Cambiamenti nella Comunità",
    "text": "81.4 Cambiamenti nella Comunità\n\n81.4.1 Big Team Science\nIl concetto di “Big Team Science” rappresenta un cambiamento significativo nella modalità di condurre ricerca. Questo approccio prevede la collaborazione su larga scala tra scienziati di diversi paesi e discipline, con l’obiettivo di replicare studi, raccogliere grandi campioni e condividere risorse. Questo modello di lavoro collettivo non solo aumenta l’efficienza della ricerca, ma promuove anche una maggiore diversità nei campioni e nei team di ricerca. Tuttavia, esistono anche criticità, come la possibilità di perpetuare disuguaglianze tra ricercatori di paesi sviluppati e in via di sviluppo, e la difficoltà nel riconoscere adeguatamente i contributi individuali all’interno di grandi consorzi.\n\n\n81.4.2 Collaborazioni Avversariali\nLe collaborazioni avversariali rappresentano un altro approccio interessante per migliorare la qualità della ricerca. In queste collaborazioni, ricercatori con visioni teoriche contrastanti lavorano insieme per progettare e condurre studi che testino le loro ipotesi in modo rigoroso. Questo tipo di collaborazione può ridurre i bias personali e promuovere un confronto costruttivo, portando a conclusioni più solide e condivise all’interno della comunità scientifica.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>81</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#crisi-della-generalizzabilità",
    "href": "chapters/replication_crisis/06_changes.html#crisi-della-generalizzabilità",
    "title": "81  Riforma",
    "section": "81.5 Crisi della generalizzabilità",
    "text": "81.5 Crisi della generalizzabilità\nYarkoni (2022) affronta la questione critica della scarsa validità delle inferenze quantitative presenti nella letteratura psicologica pubblicata proponendo tre strategie principali che, se adottate, potrebbero migliorare significativamente la qualità della ricerca in psicologia.\n\n81.5.1 Do Something Else\nIl primo suggerimento dell’autore è quello di considerare la possibilità di abbandonare la ricerca psicologica quantitativa laddove risulti troppo difficile estrarre conclusioni significative e generalizzabili da effetti complessi e variabili. L’autore critica la tendenza nella psicologia (e in altre discipline) di concludere ogni contributo di ricerca con una nota positiva o “costruttiva”, indipendentemente dalla realtà delle evidenze raccolte. Secondo l’autore, non è realistico pensare che ogni domanda di ricerca meriti una risposta empirica, soprattutto quando le risorse necessarie per ottenere risultati minimamente informativi superano di gran lunga gli standard convenzionali. In queste circostanze, potrebbe essere più saggio riconoscere i limiti della ricerca e, in alcuni casi, scegliere percorsi di carriera alternativi, specialmente per i ricercatori alle prime armi, che potrebbero trovare prospettive di carriera migliori al di fuori dell’accademia.\n\n\n81.5.2 Abbracciare l’Analisi Qualitativa\nLa seconda opzione proposta è continuare a fare ricerca psicologica, ma abbandonando in gran parte i metodi statistici inferenziali a favore di metodi qualitativi. L’autore sostiene che gran parte di ciò che attualmente passa per scienza quantitativa in psicologia sia in realtà un’analisi qualitativa mascherata. Alcune teorie psicologiche, secondo l’autore, non traggono beneficio da un’analisi quantitativa poiché sono o troppo vaghe o troppo ovvie per essere falsificabili attraverso procedure statistiche. L’autore suggerisce che in molti casi l’analisi qualitativa potrebbe fornire risposte più profonde e significative rispetto a un approccio quantitativo superficiale, evitando così l’illusione di una precisione scientifica inesistente.\nIn un approccio qualitativo, i ricercatori potrebbero concentrarsi sulla descrizione e sull’esplorazione delle relazioni tra variabili senza cercare di trarre conclusioni causali definitive. L’autore menziona l’esempio della rivista Basic and Applied Social Psychology, che ha bandito l’uso dei p-value, come un esempio di come l’abbandono della statistica inferenziale possa essere gestito in modo costruttivo. Sebbene questa mossa sia stata accolta con scetticismo, l’autore suggerisce che, se affrontata correttamente, potrebbe essere un passo positivo verso una maggiore integrità nella ricerca psicologica.\n\n\n81.5.3 Adottare Standard Migliori\nLa terza e ultima strategia consiste nel migliorare gli standard della ricerca quantitativa in psicologia per renderla più rigorosa e affidabile. L’autore propone diverse pratiche che, se implementate, potrebbero migliorare la qualità e la validità delle inferenze psicologiche:\n\nInferenze più conservative: I ricercatori dovrebbero evitare di fare generalizzazioni ampie basate su dati limitati e dovrebbero esplicitamente indicare quando stanno speculando al di là dei dati disponibili. La formulazione di titoli di articoli e affermazioni dovrebbe riflettere in modo più accurato la portata dei risultati ottenuti.\nRicerca descrittiva: L’autore esorta a prendere più seriamente la ricerca descrittiva, che si concentra sulla caratterizzazione delle relazioni tra variabili senza ricorrere a spiegazioni causali. Questo tipo di ricerca può fornire un’importante base empirica che è spesso trascurata a favore di teorie semplificate e sovrastimate.\nModelli statistici più espansivi: I ricercatori dovrebbero abituarsi a utilizzare modelli statistici che considerino una più ampia gamma di variabili e fattori, oltre a includere effetti random per elementi come stimoli, compiti e siti di ricerca. Questo approccio richiede l’uso di modelli misti che permettano di gestire la complessità della realtà psicologica in modo più adeguato.\nProgettare con la variazione in mente: Yarkoni (2022) sostiene l’importanza di progettare studi che abbraccino la variabilità naturale delle condizioni sperimentali, piuttosto che cercare di controllare rigidamente ogni variabile. Questo approccio, sebbene più costoso in termini di risorse, permetterebbe di ottenere risultati più generalizzabili e utili.\nStime della varianza: Un maggiore enfasi dovrebbe essere posta sull’analisi dele componenti della varianza piuttosto che sulle stime puntuali. Questo permetterebbe di comprendere meglio l’importanza relativa delle diverse fonti di variazione nei dati e di pianificare studi futuri in modo più informato.\nPredizioni più rischiose: Yarkoni (2022) incoraggia i ricercatori a formulare predizioni teoriche che comportino un alto grado di rischio. Predizioni più precise e rischiose ridurrebbero le preoccupazioni sulla generalizzabilità, poiché solo modelli teorici accurati sarebbero in grado di fare previsioni con tale precisione.\nUtilità predittiva pratica: Infine, Yarkoni (2022) suggerisce un approccio più pragmatico che si concentri sull’utilità pratica delle predizioni piuttosto che su considerazione puramente teoriche. Invece di chiedersi se un fenomeno esiste, dovremmo chiederci se possiamo costruire modelli che predicano efficacemente comportamenti rilevanti in situazioni specifiche.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>81</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#sviluppare-teorie-formali",
    "href": "chapters/replication_crisis/06_changes.html#sviluppare-teorie-formali",
    "title": "81  Riforma",
    "section": "81.6 Sviluppare teorie formali",
    "text": "81.6 Sviluppare teorie formali\nOltre alle carenze metodologiche o statistiche, è stato spesso sottolineato che la crisi di replicabilità che affligge le scienze psicologiche trova le sue radici nella mancanza di un quadro teorico cumulativo. Senza un quadro teorico generale che generi ipotesi in diversi ambiti, i programmi empirici si sviluppano a partire da intuizioni personali e teorie popolari influenzate culturalmente. Fornendo strumenti per formulare previsioni chiare, anche attraverso l’uso di modelli formali, i quadri teorici stabiliscono aspettative che permettono di determinare se un nuovo risultato conferma le ricerche esistenti, integrandosi con esse, oppure se è inaspettato e, pertanto, richiede ulteriori verifiche e approfondimenti (Muthukrishna & Henrich, 2019).",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>81</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#riflessioni-conclusive",
    "href": "chapters/replication_crisis/06_changes.html#riflessioni-conclusive",
    "title": "81  Riforma",
    "section": "81.7 Riflessioni Conclusive",
    "text": "81.7 Riflessioni Conclusive\nL’ampio utilizzo dei test statistici frequentisti in psicologia risulta spesso fuorviante, poiché attribuisce un’apparenza di rigore scientifico a inferenze che, in realtà, sono principalmente qualitative. Si rende quindi necessaria una profonda riforma delle pratiche di ricerca, volta a promuovere una maggiore trasparenza e precisione, oltre a incoraggiare la disponibilità a mettere in discussione e abbandonare approcci metodologici che non superano una rigorosa analisi critica (Yarkoni, 2022).\nLa crisi di replicabilità ha spinto verso una serie di riforme con il potenziale di trasformare positivamente la ricerca psicologica. Tra queste iniziative vi sono la promozione della scienza aperta, l’adozione di standard metodologici più rigorosi e una maggiore attenzione a pratiche di ricerca che privilegiano la qualità e la replicabilità dei risultati rispetto alla loro quantità e novità. Sebbene questi cambiamenti possano sembrare meno spettacolari rispetto ai metodi attualmente utilizzati, essi rappresentano un percorso fondamentale per garantire la credibilità e la sostenibilità a lungo termine della disciplina.\nAffinché queste riforme abbiano un impatto duraturo, è essenziale un cambiamento strutturale a tutti i livelli della comunità scientifica:\n\nI ricercatori devono impegnarsi ad adottare pratiche più rigorose e trasparenti, privilegiando la solidità metodologica e la replicabilità dei loro studi.\nGli enti finanziatori devono incentivare la qualità e la replicabilità degli studi, piuttosto che premiare esclusivamente la produzione di risultati innovativi o appariscenti.\nLe istituzioni accademiche devono rivedere i criteri di valutazione del merito scientifico, dando maggior peso all’impatto a lungo termine delle ricerche e alla loro solidità metodologica.\nLe riviste scientifiche devono assicurarsi che i risultati pubblicati siano realmente robusti e generalizzabili, anziché limitarsi a privilegiare i risultati nuovi o sorprendenti.\n\nQuesti cambiamenti, sebbene complessi e talvolta impopolari, sono fondamentali per ristabilire la fiducia nel processo scientifico e per garantire che la ricerca psicologica continui a offrire contributi utili e affidabili nella comprensione della mente umana e del comportamento.\nIn conclusione, la sfida posta dalla crisi di replicabilità offre un’opportunità unica per ridefinire e rafforzare le fondamenta metodologiche della ricerca psicologica. Abbracciando questi cambiamenti, la psicologia può emergere come una disciplina più robusta, trasparente e affidabile, capace di fornire intuizioni utili e durature sul funzionamento della mente e del comportamento umano.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>81</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#bibliografia",
    "href": "chapters/replication_crisis/06_changes.html#bibliografia",
    "title": "81  Riforma",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nKorbmacher, M., Azevedo, F., Pennington, C. R., Hartmann, H., Pownall, M., Schmidt, K., Elsherif, M., Breznau, N., Robertson, O., Kalandadze, T., et al. (2023). The replication crisis has led to positive structural, procedural, and community changes. Communications Psychology, 1(1), 3.\n\n\nMuthukrishna, M., & Henrich, J. (2019). A problem in theory. Nature Human Behaviour, 3(3), 221–229.\n\n\nScheel, A. M., Schijen, M. R., & Lakens, D. (2021). An excess of positive results: Comparing the standard psychology literature with registered reports. Advances in Methods and Practices in Psychological Science, 4(2), 25152459211007467.\n\n\nYarkoni, T. (2022). The generalizability crisis. Behavioral and Brain Sciences, 45, e1.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>81</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/07_piranha.html",
    "href": "chapters/replication_crisis/07_piranha.html",
    "title": "82  Il Problema del priming: sfide e paradossi nella psicologia sociale",
    "section": "",
    "text": "82.1 Introduzione\nUn recente articolo di Tosh et al. (2025) affronta una questione centrale per la psicologia e la crisi della replicabilità: il cosiddetto “problema del piranha.” L’argomento riguarda la convinzione, diffusa in molti studi psicologici, che piccoli interventi (o “nudges”), apparentemente insignificanti, possano generare effetti notevoli sul comportamento. L’articolo dimostra formalmente, con il supporto del teorema di Van der Corput (Tao, 2014), che se tali effetti fossero davvero così grandi e consistenti, allora sarebbe possibile manipolare il comportamento umano in modi empiricamente irrealistici.\nIn altre parole, la letteratura psicologica spesso riporta effetti di dimensioni tali che richiederebbero assunzioni incompatibili con le evidenze empiriche. Questi risultati suggeriscono che le affermazioni di grandi effetti indipendenti sono più probabilmente attribuibili a problemi metodologici, come bassa potenza statistica o “gradi di libertà del ricercatore” (Simmons et al., 2011).",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>Il Problema del priming: sfide e paradossi nella psicologia sociale</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/07_piranha.html#il-problema-del-piranha",
    "href": "chapters/replication_crisis/07_piranha.html#il-problema-del-piranha",
    "title": "82  Il Problema del priming: sfide e paradossi nella psicologia sociale",
    "section": "82.2 Il problema del piranha",
    "text": "82.2 Il problema del piranha\nTosh et al. (2025) evidenziano che, in un sistema complesso, se molte variabili esplicative hanno un forte impatto su una singola variabile di esito, queste devono inevitabilmente mostrare interazioni o correlazioni rilevanti tra loro.\n\n82.2.1 Punti chiave del problema\n\nEffetti ampi e interazioni: Il “problema del piranha” sottolinea che è improbabile che molte variabili esplicative abbiano effetti ampi e indipendenti su una singola variabile di esito all’interno di un sistema stabile. Questo principio si basa sulla disuguaglianza di Van der Corput, che dimostra come l’aumento del numero di variabili con grandi effetti richieda una considerazione delle loro interazioni. Tali interazioni generano una rete complessa di influenze, rendendo difficile isolare l’impatto di un singolo fattore. Gli effetti osservati in un dato studio potrebbero non essere generalizzabili, poiché dipendono dai livelli di altre variabili presenti nello stesso contesto.\nAnalogia con i piranha: L’analogia del piranha descrive un sistema sovraffollato di variabili esplicative con grandi effetti, che interagiscono tra loro fino a ridurre la stabilità complessiva. Proprio come i piranha in un acquario competono tra loro fino a ridurre il loro numero, un sistema con molte variabili di forte impatto tende a generare interazioni che limitano la prevedibilità e la stabilità del sistema. In altre parole, gli effetti individuali vengono alterati, ridotti o cancellati attraverso la competizione tra variabili.\n\n\n\n82.2.2 Rilevanza per la crisi di replicabilità\nIl problema del piranha offre una prospettiva cruciale per comprendere le cause della crisi di replicabilità nelle scienze sociali e biologiche. Secondo Tosh et al. (2025), questa crisi non è attribuibile soltanto a problemi metodologici come la bassa potenza statistica, ma riflette un limite intrinseco dell’idea stessa che numerosi grandi effetti indipendenti possano coesistere in un sistema complesso.\nI teoremi discussi nell’articolo dimostrano che un sistema stabile non può contenere numerosi effetti forti e indipendenti senza generare predizioni empiricamente insostenibili. Ciò implica che la ricerca di molteplici “grandi effetti” rischia di essere basata su assunzioni irrealistiche riguardo alla natura delle interazioni tra variabili.\nIl problema del piranha è particolarmente rilevante per la psicologia, dove spesso si cercano numerose cause indipendenti per spiegare fenomeni complessi. Tosh et al. (2025) mettono in discussione non tanto i singoli effetti riportati, quanto l’assunzione di base secondo cui il comportamento umano e le interazioni sociali sarebbero influenzati da un gran numero di effetti indipendenti.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>Il Problema del priming: sfide e paradossi nella psicologia sociale</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/07_piranha.html#il-priming-nella-psicologia-sociale",
    "href": "chapters/replication_crisis/07_piranha.html#il-priming-nella-psicologia-sociale",
    "title": "82  Il Problema del priming: sfide e paradossi nella psicologia sociale",
    "section": "82.3 Il priming nella psicologia sociale",
    "text": "82.3 Il priming nella psicologia sociale\nUno degli esempi analizzati da Tosh et al. (2025) riguarda la ricerca sul priming sociale, una linea di indagine ampiamente discussa e criticata nella psicologia sociale. Gli autori utilizzano uno studio classico per illustrare le loro argomentazioni: un esperimento del 1996 condotto da Bargh et al. (1996), in cui i partecipanti riorganizzavano frasi contenenti parole associate alla vecchiaia (ad esempio, “Florida” o “solo”). I risultati riportavano che questi partecipanti camminavano più lentamente rispetto a un gruppo di controllo, con una riduzione del 13% nella velocità di camminata (Bargh et al., 1996).\nL’idea che una manipolazione così semplice possa produrre un effetto tanto marcato è stata successivamente oggetto di numerose critiche. I tentativi di replicare lo studio non hanno avuto successo, e il lavoro di Bargh et al. (1996) è ora considerato un esempio emblematico di risultati impossibili da replicare. Questo studio rappresenta solo uno dei molti casi in cui sono stati riportati effetti sorprendentemente grandi per manipolazioni apparentemente insignificanti.\nTosh et al. (2025) sostengono che, se davvero piccoli interventi (nudges) producono effetti così rilevanti, emergerebbe inevitabilmente il problema delle interazioni con numerosi altri fattori già noti per influire sul comportamento umano. La letteratura psicologica include infatti studi che attribuiscono grandi effetti a fattori come ormoni, immagini subliminali, notizie di partite di calcio o attacchi di squali, incontri casuali con sconosciuti, stato socioeconomico dei genitori, condizioni meteorologiche, l’ultima cifra dell’età, il genere del nome di un uragano, e molti altri. Secondo gli autori, se tutti questi fattori influenzassero realmente un singolo esito, le loro interazioni diventerebbero incredibilmente complesse e imprevedibili, rendendo impossibile individuare effetti stabili e replicabili.\nPer illustrare l’assurdità di alcuni di questi risultati, Tosh et al. (2025) propongono un esempio ipotetico. Supponiamo che 100 nudges producano ciascuno un effetto del 13% sulla velocità di camminata, come riportato da Bargh et al. (1996) Se questi effetti fossero indipendenti, l’effetto combinato sarebbe enorme: la velocità di camminata potrebbe facilmente raddoppiare, dimezzarsi o variare ancora di più. Tuttavia, tali variazioni sono empiricamente irrealistiche. In altre parole, le assunzioni su cui si basano molte di queste ricerche porterebbero a predizioni che non trovano riscontro nei dati osservabili.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>Il Problema del priming: sfide e paradossi nella psicologia sociale</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/07_piranha.html#conclusione",
    "href": "chapters/replication_crisis/07_piranha.html#conclusione",
    "title": "82  Il Problema del priming: sfide e paradossi nella psicologia sociale",
    "section": "82.4 Conclusione",
    "text": "82.4 Conclusione\nIl “problema del piranha” evidenzia i limiti intrinseci nell’assumere che numerosi effetti indipendenti e di grande entità possano coesistere all’interno di un sistema complesso. In realtà, tali effetti devono necessariamente interagire tra loro o essere correlati, rendendo improbabile la loro indipendenza. Questa dinamica crea instabilità nel sistema e porta a variazioni degli effetti nel tempo o tra popolazioni, compromettendo la possibilità di generalizzarne i risultati.\nTosh et al. (2025) suggeriscono che molti risultati pubblicati, che riportano effetti improbabilmente grandi, siano attribuibili non tanto a reali fenomeni psicologici, quanto a problemi metodologici, come bassa potenza statistica e i “gradi di libertà del ricercatore” (Simmons et al., 2011). La proliferazione di questi risultati contribuisce alla crisi di replicabilità, poiché i presunti effetti si rivelano spesso instabili o non replicabili.\nLa consapevolezza dei limiti imposti dal problema del piranha invita la ricerca psicologica a focalizzarsi maggiormente sulla robustezza metodologica, sull’identificazione di effetti plausibili e sulla considerazione delle interazioni tra variabili. Piuttosto che cercare di identificare molteplici grandi effetti, è essenziale riconoscere che un sistema complesso, per essere stabile e prevedibile, richiede un approccio che consideri l’interdipendenza delle variabili e la struttura complessiva del sistema. Questo approccio può contribuire a migliorare la validità e la replicabilità della ricerca nelle scienze sociali.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>Il Problema del priming: sfide e paradossi nella psicologia sociale</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/07_piranha.html#bibliografia",
    "href": "chapters/replication_crisis/07_piranha.html#bibliografia",
    "title": "82  Il Problema del priming: sfide e paradossi nella psicologia sociale",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBargh, J. A., Chen, M., & Burrows, L. (1996). Automaticity of social behavior: Direct effects of trait construct and stereotype activation on action. Journal of Personality and Social Psychology, 71(2), 230–244.\n\n\nSimmons, J. P., Nelson, L. D., & Simonsohn, U. (2011). False-positive psychology: Undisclosed flexibility in data collection and analysis allows presenting anything as significant. Psychological science, 22(11), 1359–1366.\n\n\nTosh, C., Greengard, P., Goodrich, B., Gelman, A., Vehtari, A., & Hsu, D. (2025). The Piranha Problem: Large Effects Swimming in a Small Pond. Notices of the American Mathematical Society.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>Il Problema del priming: sfide e paradossi nella psicologia sociale</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/08_integrity.html",
    "href": "chapters/replication_crisis/08_integrity.html",
    "title": "83  Integrità della ricerca",
    "section": "",
    "text": "83.1 Introduzione\nL’integrità della ricerca si basa su principi e standard professionali che mirano a garantire l’affidabilità e la qualità della ricerca, distinguendosi dall’etica della ricerca, che si focalizza su principi morali. La condivisione dei dati, il consenso informato, e la trasparenza nelle pratiche di ricerca sono elementi chiave. I codici di condotta sono essenziali per orientare i comportamenti etici, tanto dei ricercatori quanto delle istituzioni. Le pratiche di ricerca discutibili, la fabbricazione e falsificazione dei dati, il plagio, e la gestione dei conflitti di interesse sono sfide da affrontare per mantenere l’integrità della ricerca. È fondamentale promuovere una cultura di ricerca che privilegi l’onestà, la trasparenza e il rispetto dei principi etici.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>83</span>  <span class='chapter-title'>Integrità della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/08_integrity.html#standard-professionali-nei-codici-di-condotta-per-lintegrità-della-ricerca",
    "href": "chapters/replication_crisis/08_integrity.html#standard-professionali-nei-codici-di-condotta-per-lintegrità-della-ricerca",
    "title": "83  Integrità della ricerca",
    "section": "83.2 Standard Professionali nei Codici di Condotta per l’Integrità della Ricerca",
    "text": "83.2 Standard Professionali nei Codici di Condotta per l’Integrità della Ricerca\nNel campo della ricerca, è essenziale aderire a principi di condotta responsabile. Questi principi, comunemente definiti come buone pratiche di ricerca, stabiliscono gli standard professionali che mirano a ottimizzare qualità e affidabilità degli studi condotti. Se è vero che le idee di base su cosa costituisca una buona pratica di ricerca rimangono relativamente stabili nel tempo, la loro applicazione pratica si evolve in risposta ai cambiamenti sociali, politici e tecnologici. Un esempio lampante di questo adattamento è la crescente enfasi sulla condivisione dei dati di ricerca, facilitata oggi dall’esistenza di repository online gratuiti, che ha portato a un’aspettativa diffusa di massima trasparenza e accessibilità dei dati raccolti. Molto incoraggiata è anche la “buona pratica” corrispondente alla condivisione del codice utilizzato dai ricercatori per analizzare i dati raccolti.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>83</span>  <span class='chapter-title'>Integrità della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/08_integrity.html#differenziazione-tra-integrità-e-etica-della-ricerca",
    "href": "chapters/replication_crisis/08_integrity.html#differenziazione-tra-integrità-e-etica-della-ricerca",
    "title": "83  Integrità della ricerca",
    "section": "83.3 Differenziazione tra Integrità e Etica della Ricerca",
    "text": "83.3 Differenziazione tra Integrità e Etica della Ricerca\nL’integrità della ricerca si fonda su standard professionali e si distingue nettamente dall’etica della ricerca, che si basa su principi morali quali l’autonomia, la beneficenza, la non-maleficenza e la giustizia. Questi ultimi si traducono in pratiche specifiche, come il consenso informato e la garanzia di verità e confidenzialità nei confronti dei partecipanti. L’adozione di tali principi etici implica l’obbligo per i ricercatori di evitare studi che possano arrecare danno o risultare eccessivamente onerosi per i soggetti coinvolti.\nI codici di condotta per l’integrità della ricerca variano leggermente tra le diverse fonti. Ad esempio, Il codice di condotta europeo per l’integrità della ricerca enfatizza l’importanza di principi come l’onestà, la trasparenza, l’accuratezza, la responsabilità, l’affidabilità, il rispetto e l’indipendenza. Questi principi sono interpretati in termini di comportamenti specifici attesi sia dai ricercatori sia dalle istituzioni di ricerca, come la condivisione dei dati di ricerca nel rispetto delle normative sulla protezione dei dati, come il GDPR europeo.\nUn esempio pratico della variazione degli standard nei codici di condotta è rappresentato dall’evoluzione della condivisione dei dati di ricerca. In precedenza, la condivisione dei dati poteva essere limitata dalla mancanza di infrastrutture adeguate. Oggi, l’accesso facilitato attraverso i repository online e la pressione esercitata dalle riviste scientifiche e dai finanziatori della ricerca hanno reso la condivisione dei dati una pratica standard, riflettendo un cambiamento verso una maggiore apertura e trasparenza nella ricerca.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>83</span>  <span class='chapter-title'>Integrità della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/08_integrity.html#pressioni-e-sfide-nelladesione-ai-codici-di-condotta",
    "href": "chapters/replication_crisis/08_integrity.html#pressioni-e-sfide-nelladesione-ai-codici-di-condotta",
    "title": "83  Integrità della ricerca",
    "section": "83.4 Pressioni e Sfide nell’Adesione ai Codici di Condotta",
    "text": "83.4 Pressioni e Sfide nell’Adesione ai Codici di Condotta\nNonostante l’esistenza di questi codici, i ricercatori, specialmente quelli in fase iniziale della loro carriera, possono trovarsi sotto pressione da parte dei supervisori per adottare comportamenti che si discostano dagli standard stabiliti, spesso a causa della competitività nel campo scientifico e del sistema di valutazione basato sul numero di pubblicazioni. Queste dinamiche possono indurre a pratiche di ricerca discutibili (PRD), che includono la pubblicazione selettiva dei risultati e l’uso di analisi dei dati flessibili per aumentare artificialmente la probabilità di ottenere risultati statisticamente significativi.\nPer mantenere l’integrità della ricerca, è fondamentale creare un ambiente di lavoro che valorizzi l’apertura, l’inclusività e la discussione franca delle pressioni e delle sfide etiche. Questo implica non solo l’adesione ai codici di condotta esistenti ma anche l’impegno attivo delle istituzioni di ricerca nel promuovere la formazione etica e l’integrità tra i ricercatori. Attraverso un tale approccio, la comunità scientifica può aspirare a una ricerca di alta qualità che sia sia eticamente responsabile sia metodologicamente solida.\nÈ degno di nota che Nature, una delle riviste scientifiche più prestigiose al mondo, abbia recentemente promosso il gioco da tavolo Publish or Perish. La descrizione del gioco è particolarmente provocatoria:\n\n“Falsificare dati, screditare altri scienziati, pubblicare una montagna di articoli che ricevono una torre di citazioni: i cinici potrebbero descrivere questi come passi necessari per raggiungere il successo accademico.”\n\nQuesta mossa solleva importanti questioni sullo stato attuale della ricerca scientifica. Non solo il mondo accademico sembra fornire inventivi distorti, ma anche il sistema economico delle riviste scientifiche presenta una componente di monetizzazione che appare in conflitto con gli obiettivi fondamentali della ricerca scientifica. Questo porta all’accettazione di pratiche disoneste, perché funzionali allo status quo.\nIn questo panorama complesso, emergono voci di dissenso che auspicano e si impegnano per una riforma del mondo pragmatico della scienza (McElreath, 2020; Smaldino & McElreath, 2016). Questa situazione invita a una riflessione profonda sulla necessità di bilanciare la produttività accademica con l’etica e la qualità della ricerca, nonché sul ruolo delle riviste scientifiche nel plasmare il panorama della ricerca contemporanea.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>83</span>  <span class='chapter-title'>Integrità della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/08_integrity.html#bibliografia",
    "href": "chapters/replication_crisis/08_integrity.html#bibliografia",
    "title": "83  Integrità della ricerca",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nSmaldino, P. E., & McElreath, R. (2016). The natural selection of bad science. Royal Society open science, 3(9), 160384.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>83</span>  <span class='chapter-title'>Integrità della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/epiloque/epiloque.html",
    "href": "chapters/epiloque/epiloque.html",
    "title": "Considerazioni Conclusive",
    "section": "",
    "text": "Limiti dell’Inferenza Frequentista\nL’inferenza bayesiana offre un modo rigoroso e trasparente per integrare conoscenze pregresse e dati empirici nell’analisi psicologica. A differenza degli approcci frequentisti, l’approccio bayesiano ci permette di quantificare l’incertezza e di costruire modelli che riflettono le nostre aspettative a priori. Questa flessibilità è particolarmente utile in psicologia, dove le teorie e le ipotesi giocano un ruolo fondamentale nella guida della ricerca. L’approccio bayesiano rende esplicita la nostra assunzione iniziale e ci permette di valutare l’impatto dei dati sulla nostra comprensione dei fenomeni psicologici.\nNel corso di questa trattazione, abbiamo esaminato i limiti dell’inferenza frequentista, in particolare quando viene impiegata come “filtro” per distinguere i risultati scientifici rilevanti da quelli trascurabili. L’eccessiva dipendenza dai valori-p è stata oggetto di critiche per la sua associazione con inferenze inadeguate; gli effetti possono essere notevolmente sovrastimati, talvolta persino nella direzione errata, quando la stima è vincolata alla significatività statistica in presenza di dati altamente variabili (Loken & Gelman, 2017).\nLa persistenza e la resistenza del valore-p come indicatore di significatività sono sorprendenti, nonostante le critiche di lunga data e i dibattiti sul suo uso improprio e sulla sua errata interpretazione (Gardner e Altman, 1986; Cohen, 1994; Anderson et al., 2000; Fidler et al., 2004; Finch et al., 2004). Il continuo uso di questa tenacia può offrire spunti su come tali indici, insieme alle euristiche utilizzate per interpretarli (ad esempio, l’assegnazione di soglie come 0.05, 0.01 e 0.001 per determinati livelli di significatività), siano adottati dai ricercatori per ottenere una comprensione intuitiva, sebbene eccessivamente semplificata, della struttura dei loro dati. Inoltre, l’uso di un simile indice risulta particolarmente rilevante in contesti che richiedono decisioni e relative giustificazioni (ad esempio, in ambito medico).\nPurtroppo, queste euristiche sono diventate estremamente rigide, e il raggiungimento della significatività si è trasformato in un obiettivo fine a se stesso, piuttosto che in uno strumento per comprendere i dati (Cohen, 1994; Kirk, 1996). Ciò è particolarmente problematico considerando che i valori-p possono essere utilizzati solo per rifiutare l’ipotesi nulla e non per accettarla come vera, poiché un risultato statisticamente non significativo non implica l’assenza di differenze tra gruppi o l’assenza di un effetto di un trattamento (Wagenmakers, 2007; Amrhein et al., 2019).\nI fraintendimenti e l’uso improprio dei valori-p, il cosiddetto “p-hacking” (Simmons et al., 2011), hanno incentivato pratiche scientifiche discutibili, contribuendo in modo rilevante alla crisi di riproducibilità nella scienza psicologica (Chambers et al., 2014; Szucs e Ioannidis, 2016).",
    "crumbs": [
      "Epilogo",
      "Considerazioni Conclusive"
    ]
  },
  {
    "objectID": "chapters/epiloque/epiloque.html#la-crisi-della-replicabilità",
    "href": "chapters/epiloque/epiloque.html#la-crisi-della-replicabilità",
    "title": "Considerazioni Conclusive",
    "section": "La Crisi della Replicabilità",
    "text": "La Crisi della Replicabilità\nLa crisi della replicabilità rappresenta una sfida non solo per la ricerca psicologica, ma anche per l’applicazione pratica delle sue teorie. Quando i risultati degli studi non possono essere replicati in contesti diversi, si mette in dubbio la validità e l’affidabilità delle teorie psicologiche su cui si basano gli interventi clinici e le politiche pubbliche. Questo non solo mina la fiducia nella scienza psicologica, ma limita anche la capacità dei professionisti di sviluppare trattamenti efficaci e basati sull’evidenza. Pertanto, è fondamentale che la comunità scientifica adotti pratiche di ricerca rigorose e trasparenti per garantire che le scoperte siano replicabili e applicabili nel mondo reale.",
    "crumbs": [
      "Epilogo",
      "Considerazioni Conclusive"
    ]
  },
  {
    "objectID": "chapters/epiloque/epiloque.html#come-uscirne",
    "href": "chapters/epiloque/epiloque.html#come-uscirne",
    "title": "Considerazioni Conclusive",
    "section": "Come uscirne?",
    "text": "Come uscirne?\nL’abbandono dell’inferenza frequentista a favore dei metodi bayesiani, per ragioni quali la maggiore flessibilità, una migliore accuratezza in presenza di dati rumorosi e campioni piccoli, una minore predisposizione agli errori di tipo I, la possibilità di incorporare conoscenze pregresse nell’analisi e la chiarezza e facilità di interpretazione dei risultati (Kruschke, 2010; Kruschke et al., 2012; Etz e Vandekerckhove, 2016; Wagenmakers et al., 2016, 2018; Dienes e Mclatchie, 2018), è una delle strategie proposte per affrontare la crisi della replicabilità nella ricerca psicologica. Tuttavia, sebbene questo cambiamento sia rilevante, non è sufficiente da solo. I problemi più profondi derivano anche da un sistema accademico caratterizzato da incentivi distorti, come la pressione a pubblicare risultati significativi, e dalla riluttanza delle riviste scientifiche a riconoscere e affrontare casi di frode o a ritirare articoli quando necessario.\nUna proposta su cui insiste molto McElreath (2020) è quella di passare da un approccio descrittivo della relazione tra variabili — tipico dei modelli lineari e dei modelli lineari generalizzati — a una prospettiva che miri a descrivere formalmente il meccanismo generatore dei dati sottostante al fenomeno in esame. In questo contesto, il ricercatore dovrebbe formulare ipotesi esplicite sul processo che genera i dati e fornire un test quantitativo di tali ipotesi. Questo approccio porta naturalmente alla pratica del confronto tra modelli, un metodo che abbiamo discusso in diversi capitoli di questo testo. Tale confronto può essere effettuato utilizzando tecniche come la validazione incrociata bayesiana Leave-One-Out (LOO), che permette di valutare la robustezza dei modelli e la loro capacità di generalizzare a nuovi dati. Ma si tengano anche a mente i limiti di tale approccio (Navarro, 2019).\nUn altro approccio attuale per superare la cosiddetta “junk science” (Calin-Jageman & Caldwell, 2014; Gelman & Weakliem, 2009; Jung et al., 2014), che troppo spesso affligge la psicologia e non solo, è la “rivoluzione causale”. Questo movimento si concentra sul tentativo di comprendere e identificare le relazioni causali in contesti naturali, superando l’arbitrarietà e l’artificialità degli esperimenti di laboratorio tradizionali. La “rivoluzione causale” ha molto in comune con l’approccio di McElreath (2020), poiché anche qui si richiede ai ricercatori di formulare ipotesi causali in maniera esplicita e di confrontare modelli alternativi che rappresentano diverse ipotesi sui rapporti causali. Questo approccio non solo migliora la comprensione dei fenomeni studiati, ma aumenta anche la credibilità e la replicabilità dei risultati scientifici.\nQuesti cambiamenti prevedono anche una profonda revisione dei metodi didattici e dei programmi dei corsi, in cui si insegna agli studenti come formulare inferenze basate sui dati empirici raccolti in psicologia. Questo tema è stato approfondito da studiosi come Mine Dogucu [Johnson et al. (2022); dogucu2022current; rosenberg2022making; dogucu2021web]. Come dovrebbe ormai essere evidente al lettore, il presente testo ha accettato questa sfida.",
    "crumbs": [
      "Epilogo",
      "Considerazioni Conclusive"
    ]
  },
  {
    "objectID": "chapters/epiloque/epiloque.html#conclusioni",
    "href": "chapters/epiloque/epiloque.html#conclusioni",
    "title": "Considerazioni Conclusive",
    "section": "Conclusioni",
    "text": "Conclusioni\nL’approccio bayesiano rappresenta una risorsa fondamentale per l’analisi dei dati psicologici, offrendo strumenti avanzati per gestire l’incertezza, integrare conoscenze pregresse e adattarsi a modelli complessi. La sua capacità di fornire previsioni robuste e aggiornare continuamente le ipotesi alla luce di nuovi dati lo rende particolarmente adatto per esplorare e comprendere la mente umana e il comportamento in tutte le loro sfaccettature.\nTuttavia, per affrontare la crisi della replicabilità e migliorare la qualità della ricerca scientifica in psicologia, non è sufficiente adottare esclusivamente metodi bayesiani. È essenziale combinare questi metodi con altre pratiche rigorose e principi metodologici solidi. Tra queste pratiche, la formalizzazione dei modelli generativi consente di descrivere chiaramente i processi sottostanti che generano i dati, migliorando la trasparenza e la validità delle inferenze. Inoltre, il confronto rigoroso tra modelli, ad esempio tramite tecniche di validazione incrociata, aiuta a determinare quale modello meglio rappresenta i dati e a evitare interpretazioni errate.\nInfine, l’adozione di una prospettiva causale esplicita è cruciale per identificare correttamente le relazioni di causa-effetto, evitando l’arbitrarietà e l’artificialità degli esperimenti tradizionali. Solo attraverso un approccio integrato, che combini l’inferenza bayesiana con queste pratiche metodologiche avanzate, sarà possibile progredire verso una scienza psicologica più affidabile e riproducibile, capace di fornire una comprensione più profonda e accurata del comportamento umano.",
    "crumbs": [
      "Epilogo",
      "Considerazioni Conclusive"
    ]
  },
  {
    "objectID": "chapters/epiloque/epiloque.html#bibliografia",
    "href": "chapters/epiloque/epiloque.html#bibliografia",
    "title": "Considerazioni Conclusive",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nCalin-Jageman, R. J., & Caldwell, T. L. (2014). Replication of the superstition and performance study by Damisch, Stoberock, and Mussweiler (2010). Social Psychology.\n\n\nGelman, A., & Weakliem, D. (2009). Of beauty, sex and power: Too little attention has been paid to the statistical challenges in estimating small effects. American Scientist, 97(4), 310–316.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nJung, K., Shavitt, S., Viswanathan, M., & Hilbe, J. M. (2014). Female hurricanes are deadlier than male hurricanes. Proceedings of the National Academy of Sciences, 111(24), 8782–8787.\n\n\nLoken, E., & Gelman, A. (2017). Measurement Error and the Replication Crisis. Science, 355(6325), 584–585.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nNavarro, D. J. (2019). Between the devil and the deep blue sea: Tensions between scientific judgement and statistical model selection. Computational Brain & Behavior, 2(1), 28–34.",
    "crumbs": [
      "Epilogo",
      "Considerazioni Conclusive"
    ]
  },
  {
    "objectID": "chapters/appendix/a02_shell.html",
    "href": "chapters/appendix/a02_shell.html",
    "title": "84  La Shell",
    "section": "",
    "text": "84.1 Che cos’è una Shell?\nUna shell è un programma che riceve comandi dall’utente tramite tastiera (o da file) e li passa al sistema operativo per l’esecuzione. Può essere accessibile tramite un terminale (o un emulatore di terminale).",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>La Shell</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a02_shell.html#che-cosè-una-shell",
    "href": "chapters/appendix/a02_shell.html#che-cosè-una-shell",
    "title": "84  La Shell",
    "section": "",
    "text": "84.1.1 Breve Storia della Shell\n\n1971: Ken Thompson di Bell Labs sviluppa la shell per UNIX.\n1977: Stephen Bourne introduce la Bourne shell (sh).\nDopo il 1977: Viene sviluppata la C shell (csh) e tcsh.\nBash: Sviluppata da Brian Fox come sostituto migliorato della Bourne shell.\n1990: Paul Falsted sviluppa Zsh, che diventa la shell predefinita per macOS dal 2019.\n\n\n\n84.1.2 Windows vs macOS/Linux\n\nWindows 10: È possibile utilizzare Bash attivando il Windows Subsystem for Linux. Tuttavia, l’ambiente preferito è solitamente PowerShell.\nmacOS/Linux: Zsh è la shell predefinita in entrambi i sistemi. È consigliabile sfruttare l’applicazione warp per un’esperienza utente moderna e ottimizzata.\n\n\n\n84.1.3 Comandi di Base Unix\n\npwd: Mostra il percorso della directory corrente.\nls: Elenca file e cartelle nella directory corrente.\ncd: Cambia directory. Senza argomenti, ti porta alla directory home.\nmkdir: Crea una nuova directory.\nrmdir: Rimuove una directory vuota.\nImportante: Evitare spazi nei nomi di file e cartelle.\n\n\n84.1.3.1 Gestione File\n\nmv: Rinomina o sposta file (usa \\ o '' per i nomi di file con spazi).\ncp: Copia file o cartelle (usa -r per le cartelle).\nrm: Rimuove file o cartelle (usa -i per confermare prima di eliminare).\n\n\n\n84.1.3.2 Visualizzazione e Manipolazione Contenuti dei File\n\nless / more: Visualizza il contenuto dei file con possibilità di navigazione.\ncat: Mostra l’intero contenuto di un file.\nhead: Mostra le prime righe di un file.\ntail: Mostra le ultime righe di un file.\n\n\n\n\n84.1.4 Comandi di Base PowerShell\nPer adattare i comandi Unix per l’utilizzo in PowerShell di Windows, molti dei comandi rimangono simili grazie alla natura cross-platform di PowerShell e alla sua flessibilità nel gestire sia gli stili di comando Unix che quelli tradizionali di Windows. Ecco come si traducono i comandi:\n\nGet-Location o semplicemente pwd: Mostra il percorso della directory corrente, simile a pwd in Unix.\nGet-ChildItem o semplicemente ls: Elenca file e cartelle nella directory corrente, equivalente a ls in Unix.\nSet-Location o semplicemente cd: Cambia directory. cd senza argomenti ti porta alla directory home in PowerShell con cd ~.\nNew-Item -ItemType Directory -Name 'nomeDirectory': Crea una nuova directory, simile a mkdir in Unix.\nRemove-Item -Path 'nomeDirectory' -Force: Rimuove una directory, anche se non vuota. Equivalente a rmdir in Unix, ma più potente perché può rimuovere anche directory con contenuti utilizzando il parametro -Force.\n\n\n84.1.4.1 Gestione File\n\nMove-Item -Path 'origine' -Destination 'destinazione': Rinomina o sposta file, equivalente a mv in Unix.\nCopy-Item -Path 'origine' -Destination 'destinazione': Copia file o cartelle, simile a cp in Unix. Usa -Recurse per copiare cartelle.\nRemove-Item -Path 'file' -Force: Rimuove file o cartelle, simile a rm in Unix. Usa -Force per rimuovere senza conferme e -Recurse per rimuovere cartelle con contenuti.\n\n\n\n84.1.4.2 Visualizzazione e Manipolazione Contenuti dei File\n\nGet-Content 'file' | More: Visualizza il contenuto dei file con possibilità di navigazione, simile a less/more in Unix.\nGet-Content 'file': Mostra l’intero contenuto di un file, equivalente a cat in Unix.\nGet-Content 'file' -Head &lt;numero&gt;: Mostra le prime righe di un file, simile a head in Unix.\nGet-Content 'file' -Tail &lt;numero&gt;: Mostra le ultime righe di un file, equivalente a tail in Unix.\n\n\n\n\n\n\n\nÈ cruciale familiarizzarsi con l’utilizzo dei percorsi relativi per semplificare gli spostamenti tra le diverse directory. L’impiego dei percorsi relativi rende il processo di navigazione più intuitivo e meno incline agli errori.\n\nNomi Chiari e Concisi: Evitate di includere spazi nei nomi dei file e delle cartelle. Preferite l’utilizzo di trattini bassi (_) per separare le parole e mantenere una struttura leggibile e facilmente comprensibile.\nEvitare Caratteri Speciali: È importante evitare l’inserimento di caratteri speciali come asterischi (*), dollari ($), slash (/, \\), punti (.), virgole (,), punti e virgole (;), parentesi (()), parentesi quadre ([]), parentesi graffe ({}), ampersand (&), barre verticali (|), punti esclamativi (!), punti interrogativi (?) nei nomi dei file e delle cartelle. Talvolta, anche l’uso del trattino (-) può causare problemi; quindi è consigliabile evitarlo. Questi caratteri possono generare problemi di compatibilità con alcuni sistemi operativi o applicazioni, rendendo più complessa la gestione dei file.\nDifferenziazione tra Maiuscole e Minuscole: Unix distingue tra maiuscole e minuscole (tratta le lettere come oggetti distinti), mentre Windows non lo fa. Per evitare confusioni, è consigliabile adottare una politica conservativa: considerate i nomi che differiscono solo per la case delle lettere come distinti.\n\nSeguendo questi consigli, è possibile ottimizzare notevolmente l’organizzazione e la gestione dei propri file, migliorando l’efficienza del lavoro e riducendo il rischio di errori.\n\n\n\nCon la pratica, la riga di comando diventa uno strumento molto efficiente. Questa breve guida fornisce le basi per iniziare a esplorare e gestire i file dal terminale, offrendo una base di partenza per ulteriori apprendimenti. La familiarità con la shell è fondamentale nella data science.",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>La Shell</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a10_math_symbols.html",
    "href": "chapters/appendix/a10_math_symbols.html",
    "title": "85  Simbologia di base",
    "section": "",
    "text": "Per una scrittura più sintetica possono essere utilizzati alcuni simboli matematici.\n\n\\(\\log(x)\\): il logaritmo naturale di \\(x\\).\nL’operatore logico booleano \\(\\land\\) significa “e” (congiunzione forte) mentre il connettivo di disgiunzione \\(\\lor\\) significa “o” (oppure) (congiunzione debole).\nIl quantificatore esistenziale \\(\\exists\\) vuol dire “esiste almeno un” e indica l’esistenza di almeno una istanza del concetto/oggetto indicato. Il quantificatore esistenziale di unicità \\(\\exists!\\) (“esiste soltanto un”) indica l’esistenza di esattamente una istanza del concetto/oggetto indicato. Il quantificatore esistenziale \\(\\nexists\\) nega l’esistenza del concetto/oggetto indicato.\nIl quantificatore universale \\(\\forall\\) vuol dire “per ogni.”\n\\(\\mathcal{A, S}\\): insiemi.\n\\(x \\in A\\): \\(x\\) è un elemento dell’insieme \\(A\\).\nL’implicazione logica “\\(\\Rightarrow\\)” significa “implica” (se …allora). \\(P \\Rightarrow Q\\) vuol dire che \\(P\\) è condizione sufficiente per la verità di \\(Q\\) e che \\(Q\\) è condizione necessaria per la verità di \\(P\\).\nL’equivalenza matematica “\\(\\iff\\)” significa “se e solo se” e indica una condizione necessaria e sufficiente, o corrispondenza biunivoca.\nIl simbolo \\(\\vert\\) si legge “tale che.”\nIl simbolo \\(\\triangleq\\) (o \\(:=\\)) si legge “uguale per definizione.”\nIl simbolo \\(\\Delta\\) indica la differenza fra due valori della variabile scritta a destra del simbolo.\nIl simbolo \\(\\propto\\) si legge “proporzionale a.”\nIl simbolo \\(\\approx\\) si legge “circa.”\nIl simbolo \\(\\in\\) della teoria degli insiemi vuol dire “appartiene” e indica l’appartenenza di un elemento ad un insieme. Il simbolo \\(\\notin\\) vuol dire “non appartiene.”\nIl simbolo \\(\\subseteq\\) si legge “è un sottoinsieme di” (può coincidere con l’insieme stesso). Il simbolo \\(\\subset\\) si legge “è un sottoinsieme proprio di.”\nIl simbolo \\(\\#\\) indica la cardinalità di un insieme.\nIl simbolo \\(\\cap\\) indica l’intersezione di due insiemi. Il simbolo \\(\\cup\\) indica l’unione di due insiemi.\nIl simbolo \\(\\emptyset\\) indica l’insieme vuoto o evento impossibile.\nIn matematica, \\(\\mbox{argmax}\\) identifica l’insieme dei punti per i quali una data funzione raggiunge il suo massimo. In altre parole, \\(\\mbox{argmax}_x f(x)\\) è l’insieme dei valori di \\(x\\) per i quali \\(f(x)\\) raggiunge il valore più alto.\n\\(a, c, \\alpha, \\gamma\\): scalari.\n\\(\\boldsymbol{x}, \\boldsymbol{y}\\): vettori.\n\\(\\boldsymbol{X}, \\boldsymbol{Y}\\): matrici.\n\\(X \\sim p\\): la variabile casuale \\(X\\) si distribuisce come \\(p\\).\n\\(p(\\cdot)\\): distribuzione di massa o di densità di probabilità.\n\\(p(y \\mid \\boldsymbol{x})\\): la probabilità o densità di \\(y\\) dato \\(\\boldsymbol{x}\\), ovvero \\(p(y = \\boldsymbol{Y} \\mid x = \\boldsymbol{X})\\).\n\\(f(x)\\): una funzione arbitraria di \\(x\\).\n\\(f(\\boldsymbol{X}; \\theta, \\gamma)\\): \\(f\\) è una funzione di \\(\\boldsymbol{X}\\) con parametri \\(\\theta, \\gamma\\). Questa notazione indica che \\(\\boldsymbol{X}\\) sono i dati che vengono passati ad un modello di parametri \\(\\theta, \\gamma\\).\n\\(\\mathcal{N}(\\mu, \\sigma^2)\\): distribuzione gaussiana di media \\(\\mu\\) e varianza \\(sigma^2\\).\n\\(\\mbox{Beta}(\\alpha, \\beta)\\): distribuzione Beta di parametri \\(\\alpha\\) e \\(\\beta\\).\n\\(\\mathcal{U}(a, b)\\): distribuzione uniforme con limite inferiore \\(a\\) e limite superiore \\(b\\).\n\\(\\mbox{Cauchy}(\\alpha, \\beta)\\): distribuzione di Cauchy di parametri \\(\\alpha\\) (posizione: media) e \\(\\beta\\) (scala: radice quadrata della varianza).\n\\(\\mathcal{B}(p)\\): distribuzione di Bernoulli di parametro \\(p\\) (probabilità di successo).\n\\(\\mbox{Bin}(n, p)\\): distribuzione binomiale di parametri \\(n\\) (numero di prove) e \\(p\\) (probabilità di successo).\n\\(\\mathbb{KL} (p \\mid\\mid q)\\): la divergenza di Kullback-Leibler da \\(p\\) a \\(q\\).",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>85</span>  <span class='chapter-title'>Simbologia di base</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html",
    "href": "chapters/appendix/a11_numbers.html",
    "title": "86  Numeri e intervalli",
    "section": "",
    "text": "86.1 Numeri binari\nI numeri binari rappresentano il sistema numerico più elementare utilizzato in informatica, poiché sono composti unicamente da due simboli: 0 e 1. Questa caratteristica li rende particolarmente adatti alla rappresentazione di situazioni dicotomiche (vero/falso, presente/assente) e consente ai computer di operare rapidamente ed efficacemente sui dati.\nUn esempio semplice d’impiego dei valori logici binari si ottiene quando raccogliamo risposte a una domanda chiusa. Immaginiamo, ad esempio, di porre la domanda “Ti piacciono i mirtilli?” a 10 studenti. Se le risposte vengono memorizzate in R come valori logici (TRUE per “Sì” e FALSE per “No”), potremmo avere:\nopinion &lt;- c(TRUE, FALSE, TRUE, TRUE, TRUE, FALSE, TRUE, TRUE, TRUE, FALSE)\nopinion\n\n [1]  TRUE FALSE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE FALSE\nIn questo caso, TRUE e FALSE corrispondono a 1 e 0 rispettivamente quando utilizzati in operazioni numeriche. Lo stesso avviene in Python, dove True è interpretato come 1 e False come 0. Questa rappresentazione binaria permette di ottenere facilmente statistiche sintetiche. Per esempio, per calcolare la proporzione di risposte positive rispetto al totale, è sufficiente sommare i valori (contando così il numero di TRUE) e dividere per la lunghezza del vettore:\nsum(opinion) / length(opinion)\n\n[1] 0.7\nQuesto fornisce immediatamente la percentuale di studenti che hanno risposto “Sì” alla domanda.",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>86</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#numeri-interi",
    "href": "chapters/appendix/a11_numbers.html#numeri-interi",
    "title": "86  Numeri e intervalli",
    "section": "\n86.2 Numeri interi",
    "text": "86.2 Numeri interi\nI numeri interi sono caratterizzati dall’assenza di componenti decimali. Essi includono sia i numeri naturali (1, 2, 3, …), tradizionalmente utilizzati per il conteggio, sia i loro opposti negativi. L’insieme dei numeri naturali è indicato con \\(\\mathbb{N}\\), mentre l’insieme dei numeri interi (che include i numeri naturali, i loro negativi e lo zero) si denota con \\(\\mathbb{Z}\\):\n\\[\n\\mathbb{Z} = \\{0, \\pm 1, \\pm 2, \\pm 3, \\dots\\}\n\\]",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>86</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#numeri-razionali",
    "href": "chapters/appendix/a11_numbers.html#numeri-razionali",
    "title": "86  Numeri e intervalli",
    "section": "\n86.3 Numeri razionali",
    "text": "86.3 Numeri razionali\nI numeri razionali sono quei numeri che possono essere espressi come il rapporto tra due numeri interi, con il denominatore diverso da zero. Essi formano l’insieme:\n\\[\n\\mathbb{Q} = \\left\\{\\frac{m}{n} \\mid m,n \\in \\mathbb{Z}, n \\neq 0\\right\\}.\n\\]\nPoiché ogni numero naturale è anche un intero, e ogni intero può essere rappresentato come razionale (ad esempio \\(5 = \\frac{5}{1}\\)), si ha una catena d’inclusioni tra i diversi insiemi di numeri:\n\\[\n\\mathbb{N} \\subseteq \\mathbb{Z} \\subseteq \\mathbb{Q}.\n\\]\nSe si desidera considerare solo i numeri razionali non negativi, si utilizza la notazione:\n\\[\n\\mathbb{Q}^+ = \\{q \\in \\mathbb{Q} \\mid q \\geq 0\\}.\n\\]",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>86</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#numeri-irrazionali",
    "href": "chapters/appendix/a11_numbers.html#numeri-irrazionali",
    "title": "86  Numeri e intervalli",
    "section": "\n86.4 Numeri irrazionali",
    "text": "86.4 Numeri irrazionali\nNon tutti i numeri possono essere espressi come rapporto di due interi. I numeri che non hanno questa proprietà sono detti irrazionali. Essi non possono essere scritti in forma frazionaria e la loro espansione decimale è infinita e non periodica. Esempi tipici di numeri irrazionali sono:\n\n\\(\\sqrt{2}\\)\n\\(\\sqrt{3}\\)\n\\(\\pi = 3.141592...\\)",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>86</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#numeri-reali",
    "href": "chapters/appendix/a11_numbers.html#numeri-reali",
    "title": "86  Numeri e intervalli",
    "section": "\n86.5 Numeri reali",
    "text": "86.5 Numeri reali\nI numeri razionali non coprono tutti i possibili punti sulla retta reale. Per rappresentare ogni possibile misura, grandezza o punto su una linea continua, si considerano i numeri reali, denotati con \\(\\mathbb{R}\\). L’insieme dei numeri reali comprende sia i razionali sia gli irrazionali:\n\\[\n\\mathbb{N} \\subseteq \\mathbb{Z} \\subseteq \\mathbb{Q} \\subseteq \\mathbb{R}.\n\\]\nIn statistica, la precisione con cui si esprime una misura è spesso legata al numero di cifre decimali utilizzate, sfruttando così appieno la “continuità” offerta dai numeri reali.",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>86</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#intervalli-numerici",
    "href": "chapters/appendix/a11_numbers.html#intervalli-numerici",
    "title": "86  Numeri e intervalli",
    "section": "\n86.6 Intervalli Numerici",
    "text": "86.6 Intervalli Numerici\nDefinizione: Un intervallo numerico è un sottoinsieme connesso della retta reale. Intuitivamente, rappresenta tutti i numeri reali compresi tra due estremi, che possono o meno essere inclusi nell’intervallo stesso.\nClassificazione degli intervalli: Gli intervalli vengono classificati in base all’inclusione o meno degli estremi:\n\n\nIntervallo chiuso: Include entrambi gli estremi. Si indica con \\([a, b]\\) e rappresenta l’insieme dei numeri reali \\(x\\) tali che \\(a \\leq x \\leq b\\).\n\nIntervallo aperto: Non include alcun estremo. Si indica con \\((a, b)\\) e rappresenta l’insieme dei numeri reali \\(x\\) tali che \\(a &lt; x &lt; b\\).\n\nIntervalli semiaperti:\n\n\nChiuso a sinistra e aperto a destra: Include l’estremo sinistro ma non quello destro. Si indica con \\([a, b)\\) e rappresenta l’insieme dei numeri reali \\(x\\) tali che \\(a \\leq x &lt; b\\).\n\nAperto a sinistra e chiuso a destra: Include l’estremo destro ma non quello sinistro. Si indica con \\((a, b]\\) e rappresenta l’insieme dei numeri reali \\(x\\) tali che \\(a &lt; x \\leq b\\).\n\n\n\nTabella riassuntiva:\n\n\nIntervallo\nNotazione\nCondizione\n\n\n\nChiuso\n\\([a, b]\\)\n\\(a \\leq x \\leq b\\)\n\n\nAperto\n\\((a, b)\\)\n\\(a &lt; x &lt; b\\)\n\n\nChiuso a sinistra, aperto a destra\n\\([a, b)\\)\n\\(a \\leq x &lt; b\\)\n\n\nAperto a sinistra, chiuso a destra\n\\((a, b]\\)\n\\(a &lt; x \\leq b\\)\n\n\n\nOsservazioni: * La scelta della notazione con parentesi quadre o tonde indica rispettivamente l’inclusione o l’esclusione degli estremi.",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>86</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a12_sum_notation.html",
    "href": "chapters/appendix/a12_sum_notation.html",
    "title": "87  Sommatorie",
    "section": "",
    "text": "87.1 Manipolazione di somme\nLe somme si incontrano costantemente in svariati contesti matematici e statistici quindi abbiamo bisogno di una notazione adeguata che ci consenta di gestirle. La somma dei primi \\(n\\) numeri interi può essere scritta come \\(1+2+\\dots+(n-1)+n\\), dove `\\(\\dots\\)’ ci dice di completare la sequenza definita dai termini che vengono prima e dopo. Ovviamente, una notazione come \\(1+7+\\dots+73.6\\) non avrebbe alcun senso senza qualche altro tipo di precisazione. In generale, nel seguito incontreremo delle somme nella forma\n\\[\nx_1+x_2+\\dots+x_n,\n\\]\ndove \\(x_n\\) è un numero che è stato definito altrove. La notazione precedente, che fa uso dei tre puntini di sospensione, è utile in alcuni contesti ma in altri risulta ambigua. Pertanto la notazione di uso corrente è del tipo\n\\[\n\\sum_{i=1}^n x_i\n\\] e si legge “sommatoria per \\(i\\) che va da \\(1\\) a \\(n\\) di \\(x_i\\)”. Il simbolo \\(\\sum\\) (lettera sigma maiuscola dell’alfabeto greco) indica l’operazione di somma, il simbolo \\(x_i\\) indica il generico addendo della sommatoria, le lettere \\(1\\) ed \\(n\\) indicano i cosiddetti estremi della sommatoria, ovvero l’intervallo (da \\(1\\) fino a \\(n\\) estremi inclusi) in cui deve variare l’indice \\(i\\) allorché si sommano gli addendi \\(x_i\\). Solitamente l’estremo inferiore è \\(1\\) ma potrebbe essere qualsiasi altri numero \\(m &lt; n\\). Quindi\n\\[\n\\sum_{i=1}^n x_i = x_1 + x_{2} + \\dots + x_{n}.\n\\]\nPer esempio, se i valori \\(x\\) sono \\(\\{3, 11, 4, 7\\}\\), si avrà\n\\[\n\\sum_{i=1}^4 x_i = 3+11+4+7 = 25\n\\]\nladdove \\(x_1 = 3\\), \\(x_2 = 11\\), eccetera. La quantità \\(x_i\\) nella formula precedente si dice l’argomento della sommatoria, mentre la variabile \\(i\\), che prende i valori naturali successivi indicati nel simbolo, si dice indice della sommatoria.\nLa notazione di sommatoria può anche essere fornita nella forma seguente\n\\[\n\\sum_{P(i)} x_i\n\\]\ndove \\(P(i)\\) è qualsiasi proposizione riguardante \\(i\\) che può essere vera o falsa. Quando è ovvio che si vogliono sommare tutti i valori di \\(n\\) osservazioni, la notazione può essere semplificata nel modo seguente: \\(\\sum_{i} x_i\\) oppure \\(\\sum x_i\\). Al posto di \\(i\\) si possono trovare altre lettere: \\(k, j, l, \\dots\\),.\nÈ conveniente utilizzare le seguenti regole per semplificare i calcoli che coinvolgono l’operatore della sommatoria.",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>Sommatorie</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a12_sum_notation.html#manipolazione-di-somme",
    "href": "chapters/appendix/a12_sum_notation.html#manipolazione-di-somme",
    "title": "87  Sommatorie",
    "section": "",
    "text": "87.1.1 Proprietà 1\nLa sommatoria di \\(n\\) valori tutti pari alla stessa costante \\(a\\) è pari a \\(n\\) volte la costante stessa:\n\\[\n\\sum_{i=1}^{n} a = \\underbrace{a + a + \\dots + a} = {n\\text{ volte } a} = n a.\n\\]\n\n\n87.1.2 Proprietà 2 (proprietà distributiva)\nNel caso in cui l’argomento contenga una costante, è possibile riscrivere la sommatoria. Ad esempio con\n\\[\n\\sum_{i=1}^{n} a x_i = a x_1 + a x_2 + \\dots + a x_n\n\\]\nè possibile raccogliere la costante \\(a\\) e fare \\(a(x_1 +x_2 + \\dots + x_n)\\). Quindi possiamo scrivere\n\\[\n\\sum_{i=1}^{n} a x_i = a \\sum_{i=1}^{n} x_i.\n\\]\n\n\n87.1.3 Proprietà 3 (proprietà associativa)\nNel caso in cui\n\\[\n\\sum_{i=1}^{n} (a + x_i) = (a + x_1) + (a + x_1) + \\dots  (a + x_n)\n\\]\nsi ha che\n\\[\n\\sum_{i=1}^{n} (a + x_i) = n a + \\sum_{i=1}^{n} x_i.\n\\]\nÈ dunque chiaro che in generale possiamo scrivere\n\\[\n\\sum_{i=1}^{n} (x_i + y_i) = \\sum_{i=1}^{n} x_i + \\sum_{i=1}^{n} y_i.\n\\]\n\n\n87.1.4 Proprietà 4\nSe deve essere eseguita un’operazione algebrica (innalzamento a potenza, logaritmo, ecc.) sull’argomento della sommatoria, allora tale operazione algebrica deve essere eseguita prima della somma. Per esempio,\n\\[\n\\sum_{i=1}^{n} x_i^2 = x_1^2 + x_2^2 + \\dots + x_n^2 \\neq \\left(\\sum_{i=1}^{n} x_i \\right)^2.\n\\]\n\n\n87.1.5 Proprietà 5\nNel caso si voglia calcolare \\(\\sum_{i=1}^{n} x_i y_i\\), il prodotto tra i punteggi appaiati deve essere eseguito prima e la somma dopo:\n\\[\n\\sum_{i=1}^{n} x_i y_i = x_1 y_1 + x_2 y_2 + \\dots + x_n y_n,\n\\]\ninfatti, \\(a_1 b_1 + a_2 b_2 \\neq (a_1 + a_2)(b_1 + b_2)\\).",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>Sommatorie</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a12_sum_notation.html#doppia-sommatoria",
    "href": "chapters/appendix/a12_sum_notation.html#doppia-sommatoria",
    "title": "87  Sommatorie",
    "section": "87.2 Doppia sommatoria",
    "text": "87.2 Doppia sommatoria\nÈ possibile incontrare la seguente espressione in cui figurano una doppia sommatoria e un doppio indice:\n\\[\n\\sum_{i=1}^{n}\\sum_{j=1}^{m} x_{ij}.\n\\]\nLa doppia sommatoria comporta che per ogni valore dell’indice esterno, \\(i\\) da \\(1\\) ad \\(n\\), occorre sviluppare la seconda sommatoria per \\(j\\) da \\(1\\) ad \\(m\\). Quindi,\n\\[\n\\sum_{i=1}^{3}\\sum_{j=4}^{6} x_{ij} = (x_{1, 4} + x_{1, 5} + x_{1, 6}) + (x_{2, 4} + x_{2, 5} + x_{2, 6}) + (x_{3, 4} + x_{3, 5} + x_{3, 6}).\n\\]\nUn caso particolare interessante di doppia sommatoria è il seguente:\n\\[\n\\sum_{i=1}^{n}\\sum_{j=1}^{n} x_i y_j\n\\]\nSi può osservare che nella sommatoria interna (quella che dipende dall’indice \\(j\\)), la quantità \\(x_i\\) è costante, ovvero non dipende dall’indice (che è \\(j\\)). Allora possiamo estrarre \\(x_i\\) dall’operatore di sommatoria interna e scrivere\n\\[\n\\sum_{i=1}^{n} \\left( x_i \\sum_{j=1}^{n} y_j \\right).\n\\]\nAllo stesso modo si può osservare che nell’argomento della sommatoria esterna la quantità costituita dalla sommatoria in \\(j\\) non dipende dall’indice \\(i\\) e quindi questa quantità può essere estratta dalla sommatoria esterna. Si ottiene quindi\n\\[\n\\sum_{i=1}^{n}\\sum_{j=1}^{n} x_i y_j = \\sum_{i=1}^{n} \\left( x_i \\sum_{j=1}^{n} y_j \\right) = \\sum_{i=1}^{n} x_i \\sum_{j=1}^{n} y_j.\n\\]\nFacciamo un esercizio. Verifichiamo quanto detto sopra nel caso particolare di \\(x = \\{2, 3, 1\\}\\) e \\(y = \\{1, 4, 9\\}\\), svolgendo prima la doppia sommatoria per poi verificare che quanto così ottenuto sia uguale al prodotto delle due sommatorie.\n\\[\n\\begin{align}\n\\sum_{i=1}^3 \\sum_{j=1}^3 x_i y_j &= x_1y_1 + x_1y_2 + x_1y_3 +\nx_2y_1 + x_2y_2 + x_2y_3 +\nx_3y_1 + x_3y_2 + x_3y_3 \\notag\\\\\n&= 2 \\times (1+4+9) + 3 \\times (1+4+9) + 2 \\times (1+4+9) = 84,\\notag\n\\end{align}\n\\]\novvero\n\\[\n(2 + 3 + 1) \\times (1+4+9) = 84.\n\\]",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>Sommatorie</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html",
    "href": "chapters/appendix/a13_sets.html",
    "title": "88  Insiemi",
    "section": "",
    "text": "88.1 Diagrammi di Eulero-Venn\nUn insieme (o collezione, classe, gruppo, …) è stato definito da Georg Cantor nel modo seguente:\nMentre non è rilevante la natura degli oggetti che costituiscono l’insieme, ciò che importa è distinguere se un dato oggetto appartenga o meno ad un insieme. Deve essere vera una delle due possibilità: il dato oggetto è un elemento dell’insieme considerato oppure non è elemento dell’insieme considerato. Due insiemi \\(A\\) e \\(B\\) si dicono uguali se sono formati dagli stessi elementi, anche se disposti in ordine diverso: \\(A=B\\). Due insiemi \\(A\\) e \\(B\\) si dicono diversi se non contengono gli stessi elementi: \\(A \\neq B\\). Ad esempio, i seguenti insiemi sono uguali:\n\\[\n\\{1, 2, 3\\} = \\{3, 1, 2\\} = \\{1, 3, 2\\}= \\{1, 1, 1, 2, 3, 3, 3\\}.\n\\]\nGli insiemi sono denotati da una lettera maiuscola, mentre le lettere minuscole, di solito, designano gli elementi di un insieme. Per esempio, un generico insieme \\(A\\) si indica con\n\\[\nA = \\{a_1, a_2, \\dots, a_n\\}, \\quad \\text{con } n &gt; 0.\n\\]\nLa scrittura \\(a \\in A\\) dice che \\(a\\) è un elemento di \\(A\\). Per dire che \\(b\\) non è un elemento di \\(A\\) si scrive \\(b \\notin A.\\)\nPer quegli insiemi i cui elementi soddisfano una certa proprietà che li caratterizza, tale proprietà può essere usata per descrivere più sinteticamente l’insieme:\n\\[\nA = \\{x ~\\vert~ \\text{proprietà posseduta da } x\\},\n\\]\nche si legge come “\\(A\\) è l’insieme degli elementi \\(x\\) per cui è vera la proprietà indicata.” Per esempio, per indicare l’insieme \\(A\\) delle coppie di numeri reali \\((x,y)\\) che appartengono alla parabola \\(y = x^2 + 1\\) si può scrivere:\n\\[\nA = \\{(x,y) ~\\vert~ y = x^2 + 1\\}.\n\\]\nDati due insiemi \\(A\\) e \\(B\\), diremo che \\(A\\) è un sottoinsieme di \\(B\\) se e solo se tutti gli elementi di \\(A\\) sono anche elementi di \\(B\\):\n\\[\nA \\subseteq B \\iff (\\forall x \\in A \\Rightarrow x \\in B).\n\\]\nSe esiste almeno un elemento di \\(B\\) che non appartiene ad \\(A\\) allora diremo che \\(A\\) è un sottoinsieme proprio di \\(B\\):\n\\[\nA \\subset B \\iff (A \\subseteq B, \\exists~ x \\in B ~\\vert~ x \\notin A).\n\\]\nUn altro insieme, detto insieme delle parti, o insieme potenza, che si associa all’insieme \\(A\\) è l’insieme di tutti i sottoinsiemi di \\(A\\), inclusi l’insieme vuoto e \\(A\\) stesso. Per esempio, per l’insieme \\(A = \\{a, b, c\\}\\), l’insieme delle parti è:\n\\[\n\\mathcal{P}(A) = \\{\n\\emptyset, \\{a\\}, \\{b\\}, \\{c\\},\n\\{a, b\\}, \\{a, c\\}, \\{c, b\\},\n\\{a, b, c\\}\n\\}.\n\\]\nI diagrammi di Venn sono uno strumento grafico molto utile per rappresentare gli insiemi e per verificare le proprietà delle operazioni tra di essi. Questi diagrammi prendono il nome dal matematico inglese del 19° secolo John Venn, anche se rappresentazioni simili erano già state utilizzate in precedenza da Leibniz e Eulero.\nI diagrammi di Venn rappresentano gli insiemi come regioni del piano delimitate da una curva chiusa. Nel caso di insiemi finiti, è possibile evidenziare alcuni elementi di un insieme tramite punti, e in alcuni casi possono essere evidenziati tutti gli elementi degli insiemi considerati.\nIn sostanza, questi diagrammi sono un modo visuale per rappresentare le proprietà degli insiemi e delle operazioni tra di essi. Sono uno strumento molto utile per visualizzare la relazione tra gli insiemi e per capire meglio come si combinano gli elementi all’interno di essi.",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>88</span>  <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html#appartenenza-ad-un-insieme",
    "href": "chapters/appendix/a13_sets.html#appartenenza-ad-un-insieme",
    "title": "88  Insiemi",
    "section": "\n88.2 Appartenenza ad un insieme",
    "text": "88.2 Appartenenza ad un insieme\nUsiamo ora R\n\nSet1 &lt;- c(1, 2)\nprint(Set1)\n\n[1] 1 2\n\nprint(class(Set1))\n\n[1] \"numeric\"\n\n\n\nmy_list &lt;- c(1, 2, 3, 4)\nmy_set_from_list &lt;- unique(my_list)\nprint(my_set_from_list)\n\n[1] 1 2 3 4\n\n\nL’appartenenza ad un insieme si verifica con %in%.\n\nmy_set &lt;- c(1, 3, 5)\nprint(\"Ecco il mio insieme:\")\n\n[1] \"Ecco il mio insieme:\"\n\nprint(my_set)\n\n[1] 1 3 5\n\nprint(\"1 appartiene all'insieme:\")\n\n[1] \"1 appartiene all'insieme:\"\n\nprint(1 %in% my_set)\n\n[1] TRUE\n\nprint(\"2 non appartiene all'insieme:\")\n\n[1] \"2 non appartiene all'insieme:\"\n\nprint(2 %in% my_set)\n\n[1] FALSE\n\nprint(\"4 NON appartiene all'insieme:\")\n\n[1] \"4 NON appartiene all'insieme:\"\n\nprint(!(4 %in% my_set))\n\n[1] TRUE",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>88</span>  <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html#relazioni-tra-insiemi",
    "href": "chapters/appendix/a13_sets.html#relazioni-tra-insiemi",
    "title": "88  Insiemi",
    "section": "\n88.3 Relazioni tra insiemi",
    "text": "88.3 Relazioni tra insiemi\nEsaminiamo le funzioni Python per descrivere le relazioni tra insiemi. In particolare, dopo avere definito l’insieme universo e l’insieme vuoto, considereremo la relazione di inclusione che conduce al concetto di sottoinsieme. Analogamente si definisce il concetto di sovrainsieme. Mostreremo anche come valutare se due insiemi sono disgiunti (si dicono disgiunti gli insiemi con intersezione vuota).\n\nUniv &lt;- 0:10\nSuper &lt;- Univ[Univ %% 2 == 0]\nDisj &lt;- Univ[Univ %% 2 == 1]\nSub &lt;- c(4, 6)\nNull &lt;- Univ[Univ &gt; 10]\n\n\nprint(\"Insieme Universo (tutti gli interi positivi fino a 10):\")\n\n[1] \"Insieme Universo (tutti gli interi positivi fino a 10):\"\n\nprint(Univ)\n\n [1]  0  1  2  3  4  5  6  7  8  9 10\n\nprint(\"Tutti gli interi positivi pari fino a 10:\")\n\n[1] \"Tutti gli interi positivi pari fino a 10:\"\n\nprint(Super)\n\n[1]  0  2  4  6  8 10\n\nprint(\"Tutti gli interi positivi dispari fino a 10:\")\n\n[1] \"Tutti gli interi positivi dispari fino a 10:\"\n\nprint(Disj)\n\n[1] 1 3 5 7 9\n\nprint(\"Insieme di due elementi, 4 e 6:\")\n\n[1] \"Insieme di due elementi, 4 e 6:\"\n\nprint(Sub)\n\n[1] 4 6\n\nprint(\"Un insieme vuoto:\")\n\n[1] \"Un insieme vuoto:\"\n\nprint(Null)\n\ninteger(0)\n\n\n\nprint('È \"Super\" un sovrainsieme di \"Sub\"?')\n\n[1] \"È \\\"Super\\\" un sovrainsieme di \\\"Sub\\\"?\"\n\nprint(all(Sub %in% Super))\n\n[1] TRUE\n\nprint('È \"Super\" un sottoinsieme di \"Univ\"?')\n\n[1] \"È \\\"Super\\\" un sottoinsieme di \\\"Univ\\\"?\"\n\nprint(all(Super %in% Univ))\n\n[1] TRUE\n\nprint('È \"Sub\" un sovrainsieme di \"Super\"?')\n\n[1] \"È \\\"Sub\\\" un sovrainsieme di \\\"Super\\\"?\"\n\nprint(all(Super %in% Sub))\n\n[1] FALSE\n\nprint('Sono \"Super\" e \"Disj\" insiemi disgiunti?')\n\n[1] \"Sono \\\"Super\\\" e \\\"Disj\\\" insiemi disgiunti?\"\n\nprint(length(intersect(Super, Disj)) == 0)\n\n[1] TRUE",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>88</span>  <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html#operazioni-tra-insiemi",
    "href": "chapters/appendix/a13_sets.html#operazioni-tra-insiemi",
    "title": "88  Insiemi",
    "section": "\n88.4 Operazioni tra insiemi",
    "text": "88.4 Operazioni tra insiemi\nSi definisce intersezione di \\(A\\) e \\(B\\) l’insieme \\(A \\cap B\\) di tutti gli elementi \\(x\\) che appartengono ad \\(A\\) e contemporaneamente a \\(B\\):\n\\[\nA \\cap B = \\{x ~\\vert~ x \\in A \\land x \\in B\\}.\n\\]\nSi definisce unione di \\(A\\) e \\(B\\) l’insieme \\(A \\cup B\\) di tutti gli elementi \\(x\\) che appartengono ad \\(A\\) o a \\(B\\), cioè\n\\[\nA \\cup B = \\{x ~\\vert~ x \\in A \\lor x \\in B\\}.\n\\]\nDifferenza. Si indica con \\(A \\setminus B\\) l’insieme degli elementi di \\(A\\) che non appartengono a \\(B\\):\n\\[\nA \\setminus B = \\{x ~\\vert~ x \\in A \\land x \\notin B\\}.\n\\]\nInsieme complementare. Nel caso che sia \\(B \\subseteq A\\), l’insieme differenza \\(A \\setminus B\\) è detto insieme complementare di \\(B\\) in \\(A\\) e si indica con \\(B^C\\).\nDato un insieme \\(S\\), una partizione di \\(S\\) è una collezione di sottoinsiemi di \\(S\\), \\(S_1, \\dots, S_k\\), tali che\n\\[\nS = S_1 \\cup S_2 \\cup \\dots S_k\n\\]\ne\n\\[\nS_i \\cap S_j, \\quad \\text{con } i \\neq j.\n\\]\nLa relazione tra unione, intersezione e insieme complementare è data dalle leggi di DeMorgan:\n\\[\n(A \\cup B)^c = A^c \\cap B^c,\n\\]\n\\[\n(A \\cap B)^c = A^c \\cup B^c.\n\\]\nIn tutte le seguenti figure, \\(S\\) è la regione delimitata dal rettangolo, \\(L\\) è la regione all’interno del cerchio di sinistra e \\(R\\) è la regione all’interno del cerchio di destra. La regione evidenziata mostra l’insieme indicato sotto ciascuna figura.\n\n\nDiagrammi di Venn\n\nI diagrammi di Eulero-Venn che illustrano le leggi di DeMorgan sono forniti nella figura seguente.\n\n\nLeggi di DeMorgan\n\nVediamo ora come si eseguono le operazioni tra insiemi con R.\nIntersezione.\n\nS1 &lt;- seq(1, 10, by = 3)\nS2 &lt;- 1:6\nS_intersection &lt;- intersect(S1, S2)\nprint(\"Intersezione di S1 e S2:\")\n\n[1] \"Intersezione di S1 e S2:\"\n\nprint(S_intersection)\n\n[1] 1 4\n\n\nUnione. Si noti che il connettivo logico | corrisponde all’unione.\n\nS_union &lt;- union(S1, S2)\nprint(\"Unione di S1 e S2:\")\n\n[1] \"Unione di S1 e S2:\"\n\nprint(S_union)\n\n[1]  1  4  7 10  2  3  5  6\n\n\nInsieme complementare.\n\nS &lt;- seq(0, 20, by = 2)\nS_complement &lt;- setdiff(0:20, S)\nprint(\"S è l'insieme dei numeri interi pari tra 0 e 20:\")\n\n[1] \"S è l'insieme dei numeri interi pari tra 0 e 20:\"\n\nprint(S)\n\n [1]  0  2  4  6  8 10 12 14 16 18 20\n\nprint(\"S_complement è l'insieme dei numeri interi dispari tra 0 e 20:\")\n\n[1] \"S_complement è l'insieme dei numeri interi dispari tra 0 e 20:\"\n\nprint(S_complement)\n\n [1]  1  3  5  7  9 11 13 15 17 19\n\n\n\nprint(\"È l'unione di S e S_complement uguale a tutti i numeri interi tra 0 e 20?\")\n\n[1] \"È l'unione di S e S_complement uguale a tutti i numeri interi tra 0 e 20?\"\n\nprint(setequal(union(S, S_complement), 0:20))\n\n[1] TRUE\n\n\nDifferenza tra insiemi.\n\nS1 &lt;- seq(0, 30, by = 3)\nS2 &lt;- seq(0, 30, by = 5)\nprint(\"Differenza tra S2 e S1:\")\n\n[1] \"Differenza tra S2 e S1:\"\n\nprint(setdiff(S2, S1))\n\n[1]  5 10 20 25\n\nprint(\"Differenza tra S1 e S2:\")\n\n[1] \"Differenza tra S1 e S2:\"\n\nprint(setdiff(S1, S2))\n\n[1]  3  6  9 12 18 21 24 27\n\n\nDifferenza simmetrica. La differenza simmetrica, indicata con il simbolo Δ, è un’operazione insiemistica definita come unione tra la differenza tra il primo e il secondo insieme e la differenza tra il secondo e il primo insieme. In modo equivalente, la differenza simmetrica equivale all’unione tra i due insiemi meno la loro intersezione.\n\nsym_diff &lt;- union(setdiff(S1, S2), setdiff(S2, S1))\nprint(\"Differenza simmetrica:\")\n\n[1] \"Differenza simmetrica:\"\n\nprint(sym_diff)\n\n [1]  3  6  9 12 18 21 24 27  5 10 20 25",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>88</span>  <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html#coppie-ordinate-e-prodotto-cartesiano",
    "href": "chapters/appendix/a13_sets.html#coppie-ordinate-e-prodotto-cartesiano",
    "title": "88  Insiemi",
    "section": "\n88.5 Coppie ordinate e prodotto cartesiano",
    "text": "88.5 Coppie ordinate e prodotto cartesiano\nUna coppia ordinata \\((x,y)\\) è l’insieme i cui elementi sono \\(x \\in A\\) e \\(y \\in B\\) e nella quale \\(x\\) è la prima componente (o prima coordinata) e \\(y\\) la seconda. L’insieme di tutte le coppie ordinate costruite a partire dagli insiemi \\(A\\) e \\(B\\) viene detto prodotto cartesiano:\n\\[\nA \\times B = \\{(x, y) ~\\vert~ x \\in A \\land y \\in B\\}.\n\\]\nAd esempio, sia \\(A = \\{1, 2, 3\\}\\) e \\(B = \\{a, b\\}\\). Allora,\n\\[\n\\{1, 2\\} \\times \\{a, b, c\\} = \\{(1, a), (1, b), (1, c), (2, a), (2, b), (2, c)\\}.\n\\]\nPiù in generale, un prodotto cartesiano di \\(n\\) insiemi può essere rappresentato da un array di \\(n\\) dimensioni, dove ogni elemento è una ennupla o tupla ordinata (ovvero, una collezione o un elenco ordinato di \\(n\\) oggetti). Una n-pla ordinata si distingue da un insieme di \\(n\\) elementi in quanto fra gli elementi di un insieme non è dato alcun ordine. Inoltre gli elementi di una ennupla possono anche essere ripetuti. Essendo la n-pla un elenco ordinato, in generale di ogni suo elemento è possibile dire se sia il primo, il secondo, il terzo, eccetera, fino all’n-esimo. Il prodotto cartesiano prende il nome da René Descartes la cui formulazione della geometria analitica ha dato origine al concetto.\n\nA &lt;- c(\"a\", \"b\", \"c\")\nS &lt;- 1:3\ncartesian_product &lt;- expand.grid(A, S)\nprint(\"Prodotto cartesiano di A e S:\")\n\n[1] \"Prodotto cartesiano di A e S:\"\n\nprint(cartesian_product)\n\n  Var1 Var2\n1    a    1\n2    b    1\n3    c    1\n4    a    2\n5    b    2\n6    c    2\n7    a    3\n8    b    3\n9    c    3\n\n\nSi definisce cardinalità (o potenza) di un insieme finito il numero degli elementi dell’insieme. Viene indicata con \\(\\vert A\\vert, \\#(A)\\) o \\(\\text{c}(A)\\).\n\nprint(\"La cardinalità dell'insieme prodotto cartesiano è:\")\n\n[1] \"La cardinalità dell'insieme prodotto cartesiano è:\"\n\nprint(nrow(cartesian_product))\n\n[1] 9\n\n\nPotenza del prodotto cartesiano\n\nA &lt;- c(\"Head\", \"Tail\")\np2 &lt;- expand.grid(A, A)\nprint(\"Il quadrato dell'insieme A è un insieme che contiene:\")\n\n[1] \"Il quadrato dell'insieme A è un insieme che contiene:\"\n\nprint(nrow(p2))\n\n[1] 4\n\nprint(p2)\n\n  Var1 Var2\n1 Head Head\n2 Tail Head\n3 Head Tail\n4 Tail Tail\n\n\n\np3 &lt;- expand.grid(A, A, A)\nprint(\"L'insieme A elevato alla terza potenza è costituito da:\")\n\n[1] \"L'insieme A elevato alla terza potenza è costituito da:\"\n\nprint(nrow(p3))\n\n[1] 8\n\nprint(p3)\n\n  Var1 Var2 Var3\n1 Head Head Head\n2 Tail Head Head\n3 Head Tail Head\n4 Tail Tail Head\n5 Head Head Tail\n6 Tail Head Tail\n7 Head Tail Tail\n8 Tail Tail Tail",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>88</span>  <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html",
    "href": "chapters/appendix/a14_combinatorics.html",
    "title": "89  Calcolo combinatorio",
    "section": "",
    "text": "89.1 Principio della somma\nIl calcolo combinatorio si occupa di determinare il numero di modi in cui è possibile combinare, ordinare o disporre elementi di uno o più insiemi, seguendo regole predefinite. Molti problemi di probabilità richiedono l’applicazione di tecniche combinatorie per calcolare le probabilità di eventi complessi. In questo capitolo, esploreremo le nozioni fondamentali del calcolo combinatorio, mettendo in relazione i suoi concetti con i vari metodi di campionamento dall’urna. Descriveremo i principi della somma e del prodotto che costituiscono le basi del calcolo combinatorio e trovano applicazione in problemi più complessi, come permutazioni, disposizioni e combinazioni.\nIl principio della somma si applica quando un insieme può essere suddiviso in sottoinsiemi disgiunti (cioè senza sovrapposizioni). In questo caso, il numero totale di elementi è dato dalla somma degli elementi dei sottoinsiemi:\n\\[\nn_{\\text{tot}} = n_1 + n_2 + \\dots + n_k .\n\\]",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#principio-della-somma",
    "href": "chapters/appendix/a14_combinatorics.html#principio-della-somma",
    "title": "89  Calcolo combinatorio",
    "section": "",
    "text": "Esempio 89.1 Un distributore contiene tre diversi scomparti di caramelle:\n\nScomparto A: 10 caramelle alla menta,\nScomparto B: 8 caramelle alla frutta,\nScomparto C: 12 caramelle al cioccolato.\n\nQuante caramelle diverse ci sono in totale nel distributore?\nSecondo il principio della somma, il totale è dato dalla somma delle caramelle nei tre scomparti:\n\\[\nn_{\\text{tot}} = n_A + n_B + n_C .\n\\]\nCalcolo in R:\n\nA &lt;- 10\nB &lt;- 8\nC &lt;- 12\n\ntotale_caramelle &lt;- A + B + C\ntotale_caramelle\n#&gt; [1] 30\n\nRisultato: Nel distributore ci sono 30 caramelle in totale.",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#principio-del-prodotto",
    "href": "chapters/appendix/a14_combinatorics.html#principio-del-prodotto",
    "title": "89  Calcolo combinatorio",
    "section": "\n89.2 Principio del prodotto",
    "text": "89.2 Principio del prodotto\nIl principio del prodotto si applica quando un’operazione può essere suddivisa in più fasi indipendenti, ciascuna con un numero di possibilità specifico. Il numero totale di combinazioni è dato dal prodotto delle possibilità offerte da ciascuna fase:\n\\[\nn_{\\text{tot}} = n_1 \\cdot n_2 \\cdot \\dots \\cdot n_k .\n\\]\n\nEsempio 89.2 Poniamo di avere quattro urne:\n\nUrna A: 5 palline,\n\nUrna B: 6 palline,\n\nUrna C: 3 palline,\n\nUrna D: 2 palline.\n\nVogliamo formare insiemi di due palline, ciascuna estratta da urne differenti.\nSecondo il principio del prodotto, per ogni coppia di urne, il numero di combinazioni è dato dal prodotto delle palline nelle due urne. Successivamente, usiamo il principio della somma per sommare tutte le possibilità.\n\\[\nn_{\\text{tot}} = AB + AC + AD + BC + BD + CD\n\\]\nCalcolo in R:\n\nAB &lt;- 5 * 6\nAC &lt;- 5 * 3\nAD &lt;- 5 * 2\nBC &lt;- 6 * 3\nBD &lt;- 6 * 2\nCD &lt;- 3 * 2\n\ntotale_insiemi &lt;- AB + AC + AD + BC + BD + CD\ntotale_insiemi\n#&gt; [1] 91\n\nRisultato: Si possono formare 91 insiemi di due palline, ciascuna estratta da urne differenti.\n\n\n89.2.1 Il modello dell’urna e i metodi di campionamento\nI problemi combinatori spesso si riducono a modelli di estrazione di palline da urne, con quattro principali varianti:\n\n\nCon ripetizione e ordine: ogni estrazione rimette la pallina nell’urna (campionamento Bernoulliano).\n\nSenza ripetizione e con ordine: ogni estrazione rimuove la pallina.\n\nCon ripetizione e senza ordine: si considerano le combinazioni, ignorando l’ordine.\n\nSenza ripetizione e senza ordine: si contano le combinazioni senza rimettere la pallina.\n\n\nEsempio 89.3  \n\nurna &lt;- c(\"a\", \"b\", \"c\")\n\n# Con ripetizione e ordine\ncampionamento1 &lt;- expand.grid(urna, urna) |&gt;\n    rename(Elemento1 = Var1, Elemento2 = Var2)\n\n# Senza ripetizione e con ordine\ncampionamento2 &lt;- permutations(n = length(urna), r = 2, v = urna) |&gt;\n    as.data.frame() |&gt;\n    rename(Elemento1 = V1, Elemento2 = V2)\n\n# Con ripetizione e senza ordine\ncampionamento3 &lt;- combinations(\n    n = length(urna), r = 2, v = urna, repeats.allowed = TRUE\n) |&gt;\n    as.data.frame() |&gt;\n    rename(Elemento1 = V1, Elemento2 = V2)\n\n# Senza ripetizione e senza ordine\ncampionamento4 &lt;- combinations(n = length(urna), r = 2, v = urna) |&gt;\n    as.data.frame() |&gt;\n    rename(Elemento1 = V1, Elemento2 = V2)\n\n# Risultati\nlist(\n    `Con ripetizione e ordine` = campionamento1,\n    `Senza ripetizione e con ordine` = campionamento2,\n    `Con ripetizione e senza ordine` = campionamento3,\n    `Senza ripetizione e senza ordine` = campionamento4\n)\n#&gt; $`Con ripetizione e ordine`\n#&gt;   Elemento1 Elemento2\n#&gt; 1         a         a\n#&gt; 2         b         a\n#&gt; 3         c         a\n#&gt; 4         a         b\n#&gt; 5         b         b\n#&gt; 6         c         b\n#&gt; 7         a         c\n#&gt; 8         b         c\n#&gt; 9         c         c\n#&gt; \n#&gt; $`Senza ripetizione e con ordine`\n#&gt;   Elemento1 Elemento2\n#&gt; 1         a         b\n#&gt; 2         a         c\n#&gt; 3         b         a\n#&gt; 4         b         c\n#&gt; 5         c         a\n#&gt; 6         c         b\n#&gt; \n#&gt; $`Con ripetizione e senza ordine`\n#&gt;   Elemento1 Elemento2\n#&gt; 1         a         a\n#&gt; 2         a         b\n#&gt; 3         a         c\n#&gt; 4         b         b\n#&gt; 5         b         c\n#&gt; 6         c         c\n#&gt; \n#&gt; $`Senza ripetizione e senza ordine`\n#&gt;   Elemento1 Elemento2\n#&gt; 1         a         b\n#&gt; 2         a         c\n#&gt; 3         b         c\n\n\n\n89.2.2 Permutazioni Semplici\nLe permutazioni rappresentano tutte le disposizioni possibili di un insieme di \\(n\\) elementi distinti, considerando l’ordine. Il numero totale di permutazioni è dato dalla formula:\n\\[\nP_n = n!\n\\]\ndove \\(n!\\) (n fattoriale) indica il prodotto di tutti i numeri interi da 1 a \\(n\\):\n\\[\nn! = n \\cdot (n-1) \\cdot (n-2) \\cdot \\dots \\cdot 1 .\n\\]\n\nEsempio 89.4 Calcoliamo tutte le permutazioni possibili per un insieme di tre elementi distinti \\(\\{a, b, c\\}\\). Il numero di permutazioni atteso è:\n\\[\nP_3 = 3! = 3 \\cdot 2 \\cdot 1 = 6 .\n\\]\nImplementazione in R:\n\n# Insieme di partenza\nA &lt;- c(\"a\", \"b\", \"c\")\n\n# Calcolo delle permutazioni\nperm &lt;- permutations(n = length(A), r = length(A), v = A)\n\n# Visualizzazione delle permutazioni\nprint(perm)\n#&gt;      [,1] [,2] [,3]\n#&gt; [1,] \"a\"  \"b\"  \"c\" \n#&gt; [2,] \"a\"  \"c\"  \"b\" \n#&gt; [3,] \"b\"  \"a\"  \"c\" \n#&gt; [4,] \"b\"  \"c\"  \"a\" \n#&gt; [5,] \"c\"  \"a\"  \"b\" \n#&gt; [6,] \"c\"  \"b\"  \"a\"\n\n# Verifica del numero di permutazioni\nnrow(perm)\n#&gt; [1] 6\n\nLe permutazioni dell’insieme sono:\n\\[\n  \\begin{aligned}\n  &\\{a, b, c\\}, \\{a, c, b\\}, \\{b, a, c\\}, \\{b, c, a\\}, \\{c, a, b\\}, \\{c, b, a\\} .\n  \\end{aligned}\n  \\]\nIl numero totale è \\(P_3 = 6\\).\n\n\n\n89.2.2.1 Caratteristiche delle Permutazioni\nLe permutazioni rappresentano un caso di campionamento senza ripetizione con ordine:\n\n\nSenza ripetizione: Ogni elemento può essere utilizzato una sola volta.\n\nCon ordine: La disposizione degli elementi è importante.\n\n\n89.2.3 Disposizioni Semplici\nLe disposizioni semplici sono sequenze ordinate di \\(k\\) elementi scelti da un insieme di \\(n\\) elementi distinti. Il numero totale di disposizioni si calcola con la formula:\n\\[\nD_{n,k} = \\frac{n!}{(n-k)!}\n\\]\ndove:\n\n\n\\(n!\\) (fattoriale di \\(n\\)) è il prodotto dei numeri interi da 1 a \\(n\\),\n\n\\((n-k)!\\) rappresenta il fattoriale della differenza tra il numero totale di elementi e quelli scelti.\n\n\nEsempio 89.5 Consideriamo l’insieme\\(\\{a, b, c\\}\\) (\\(n = 3\\)) e calcoliamo tutte le disposizioni possibili di 2 elementi (\\(k = 2\\)).\nIl numero di disposizioni atteso è:\n\\[\nD_{3,2} = \\frac{3!}{(3-2)!} = \\frac{3 \\cdot 2 \\cdot 1}{1} = 6 .\n\\]\nImplementazione in R:\n\n# Insieme di partenza\nA &lt;- c(\"a\", \"b\", \"c\")\n\n# Calcolo delle disposizioni di 2 elementi\ndisp &lt;- permutations(n = length(A), r = 2, v = A)\n\n# Visualizzazione delle disposizioni\nprint(disp)\n#&gt;      [,1] [,2]\n#&gt; [1,] \"a\"  \"b\" \n#&gt; [2,] \"a\"  \"c\" \n#&gt; [3,] \"b\"  \"a\" \n#&gt; [4,] \"b\"  \"c\" \n#&gt; [5,] \"c\"  \"a\" \n#&gt; [6,] \"c\"  \"b\"\n\n# Verifica del numero di disposizioni\nnrow(disp)\n#&gt; [1] 6\n\n\nLe disposizioni di 2 elementi sono: \\[\n\\{a, b\\}, \\{a, c\\}, \\{b, a\\}, \\{b, c\\}, \\{c, a\\}, \\{c, b\\} .\n\\]\n\nIl numero totale è \\(D_{3,2} = 6\\).\n\n\n\n\n89.2.3.1 Caratteristiche delle Disposizioni Semplici\nLe disposizioni semplici rappresentano un caso di campionamento senza ripetizione e con ordine:\n\n\nSenza ripetizione: Ogni elemento può essere utilizzato una sola volta.\n\nCon ordine: La disposizione degli elementi selezionati è importante.\n\n\n89.2.4 Combinazioni Semplici\nLe combinazioni semplici rappresentano i modi di selezionare \\(k\\) elementi da un insieme di \\(n\\) elementi senza considerare l’ordine. Il numero totale di combinazioni si calcola con la formula:\n\\[\nC_{n,k} = \\binom{n}{k} = \\frac{n!}{k!(n-k)!}\n\\]\ndove:\n\n\n\\(n!\\) è il fattoriale di \\(n\\),\n\n\\(k!\\) è il fattoriale di \\(k\\),\n\n\\((n-k)!\\) è il fattoriale della differenza tra il numero totale di elementi e quelli scelti.\n\n\n\nEsempio 89.6 Consideriamo l’insieme \\(\\{a, b, c\\}\\) (\\(n = 3\\)) e calcoliamo tutte le combinazioni possibili di 2 elementi (\\(k = 2\\)).\nIl numero di combinazioni atteso è:\n\\[\nC_{3,2} = \\binom{3}{2} = \\frac{3!}{2! \\cdot (3-2)!} = \\frac{3 \\cdot 2 \\cdot 1}{2 \\cdot 1 \\cdot 1} = 3 .\n\\]\nImplementazione in R:\n\n# Insieme di partenza\nA &lt;- c(\"a\", \"b\", \"c\")\n\n# Calcolo delle combinazioni di 2 elementi\ncomb &lt;- combinations(n = length(A), r = 2, v = A)\n\n# Visualizzazione delle combinazioni\nprint(comb)\n#&gt;      [,1] [,2]\n#&gt; [1,] \"a\"  \"b\" \n#&gt; [2,] \"a\"  \"c\" \n#&gt; [3,] \"b\"  \"c\"\n\n# Verifica del numero di combinazioni\nnrow(comb)\n#&gt; [1] 3\n\n\nLe combinazioni di 2 elementi sono: \\[\n\\{a, b\\}, \\{a, c\\}, \\{b, c\\} .\n\\]\n\nIl numero totale è \\(C_{3,2} = 3\\).\n\n\n\n\n89.2.4.1 Caratteristiche delle Combinazioni Semplici\nLe combinazioni semplici rappresentano un caso di campionamento senza ripetizione e senza ordine:\n\n\nSenza ripetizione: Ogni elemento può essere selezionato una sola volta.\n\nSenza ordine: L’ordine degli elementi selezionati non ha importanza (\\(\\{a, b\\}\\) è uguale a\\(\\{b, a\\}\\)).\n\n\nQuesto capitolo ha illustrato i legami tra i metodi del calcolo combinatorio e le diverse modalità di campionamento, mostrando come implementare questi concetti in R.",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#bibliografia",
    "href": "chapters/appendix/a14_combinatorics.html#bibliografia",
    "title": "89  Calcolo combinatorio",
    "section": "Bibliografia",
    "text": "Bibliografia",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a15_calculus.html",
    "href": "chapters/appendix/a15_calculus.html",
    "title": "90  Per liberarvi dai terrori preliminari",
    "section": "",
    "text": "90.1 Integrali\nFornisco qui la traduzione del capitolo Per liberarvi dai terrori preliminari di Calculus made easy.",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>Per liberarvi dai terrori preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a15_calculus.html#integrali",
    "href": "chapters/appendix/a15_calculus.html#integrali",
    "title": "90  Per liberarvi dai terrori preliminari",
    "section": "",
    "text": "Il terrore preliminare, che impedisce a molti studenti anche solo di tentare di imparare l’analisi, può essere abolito una volta per tutte semplicemente affermando qual è il significato – in termini di buon senso – dei due simboli principali che sono usati nell’analisi matematica.\nQuesti terribili simboli sono:\n\n\\(d\\) che significa semplicemente “un po’ di”. Quindi \\(\\operatorname{d}\\!x\\) significa un po’ di \\(x\\); o \\(\\operatorname{d}\\!u\\) significa un po’ di \\(u\\). I matematici pensano che sia più educato dire “un elemento di” invece di “un po’ di”. Fai come ti pare. Ma scoprirai che questi piccoli pezzi (o elementi) possono essere considerati indefinitamente piccoli.\n\\(\\int\\) che è semplicemente una S allungata, e può essere chiamata (se volete) “la somma di”. Quindi \\(\\int \\operatorname{d}\\!x\\) significa la somma di tutti i pezzettini di \\(x\\); oppure \\(\\int \\operatorname{d}\\!t\\) significa la somma di tutti i pezzettini di \\(t\\). I matematici chiamano questo simbolo “l’integrale di”. Ora qualsiasi sciocco può vedere che se \\(x\\) è considerato come composto da tanti piccoli pezzetti, ognuno dei quali è chiamato \\(\\operatorname{d}\\!x\\), se li sommi tutti insieme ottieni la somma di tutti i \\(\\operatorname{d}\\!x\\), (che è la stessa cosa dell’insieme di \\(x\\)). La parola “integrale” significa semplicemente “il tutto”. Se pensi alla durata di un’ora, puoi (se vuoi) pensarla come suddivisa in 3600 piccoli pezzetti chiamati secondi. L’insieme dei 3600 pezzetti sommati fa un’ora. Quando vedrete un’espressione che inizia con questo simbolo terrificante, d’ora in poi saprete che è stato messo lì semplicemente per darvi l’istruzione che ora dovete eseguire (se potete) l’operazione di sommare tutti i piccoli pezzetti che sono indicati dai simboli che seguono.\n\nÈ tutto.\n\n\n\n\n90.1.1 Verifica con Simulazioni in R\nPer calcolare e visualizzare l’integrale di una funzione di densità, possiamo utilizzare R. Per fare un esempio, consideriamo la funzione di densità gaussiana. La funzione di densità gaussiana è definita dalla seguente formula:\n\\[\nf(x; \\mu, \\sigma) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} e^{-\\frac{(x - \\mu)^2}{2 \\sigma^2}}.\n\\]\nIn R:\n\ngaussian &lt;- function(x, mu, sigma) {\n  1 / (sigma * sqrt(2 * pi)) * exp(-((x - mu)^2) / (2 * sigma^2))\n}\n\nDefiniamo i parametri e generiamo i valori per il calcolo della funzione di densità su un intervallo:\n\nmu &lt;- 0      # Media\nsigma &lt;- 1   # Deviazione standard\na &lt;- -10     # Limite inferiore\nb &lt;- 10      # Limite superiore\nn &lt;- 10000   # Numero di punti\n\nx_range &lt;- seq(a, b, length.out = n)  # Valori x\nfx &lt;- gaussian(x_range, mu, sigma)   # Ordinata della funzione\n\nVisualizziamo la funzione:\n\nlibrary(ggplot2)\nlibrary(scales)\n\nggplot(data.frame(x = x_range, fx = fx), aes(x, fx)) +\n  geom_line(color = \"blue\") +\n  labs(\n    title = \"Funzione di densità gaussiana\", \n    x = \"x\", \n    y = \"f(x)\"\n  )\n\n\n\n\n\n\n\nCreiamo una funzione per approssimare l’integrale sommando i prodotti \\(\\Delta x \\cdot f(x)\\):\n\nintegral_approximation &lt;- function(f, a, b, n) {\n  delta &lt;- (b - a) / n\n  sum(delta * f)\n}\n\n# Calcolo dell'integrale approssimato\napprox &lt;- integral_approximation(fx, a, b, n)\napprox\n\n[1] 0.9999\n\n\nConfrontiamo il risultato con il calcolo fornito da R:\n\nintegrate(\n  function(x) gaussian(x, mu, sigma),\n  lower = a,\n  upper = b\n)\n\n1 with absolute error &lt; 7.4e-05\n\n\nCalcoliamo l’area sotto la curva in intervalli di interesse. Ad esempio, per \\([-1.96, 1.96]\\), che corrisponde al 95% dell’area nella distribuzione normale standard:\n\na &lt;- -1.96\nb &lt;- 1.96\nx_range &lt;- seq(a, b, length.out = n)\nfx &lt;- gaussian(x_range, mu, sigma)\n\napprox &lt;- integral_approximation(fx, a, b, n)\napprox\n\n[1] 0.9499321\n\n\nConfrontiamo con il risultato fornito da integrate():\n\nintegrate(\n  function(x) gaussian(x, mu, sigma),\n  lower = a,\n  upper = b\n)\n\n0.9500042 with absolute error &lt; 1e-11\n\n\nVerifichiamo l’area sotto la curva per \\([-1, 1]\\), che rappresenta circa il 68% dell’area totale:\n\na &lt;- -1.0\nb &lt;- 1.0\nx_range &lt;- seq(a, b, length.out = n)\nfx &lt;- gaussian(x_range, mu, sigma)\n\napprox &lt;- integral_approximation(fx, a, b, n)\napprox\n\n[1] 0.6826696\n\n\nConfronto:\n\nintegrate(\n  function(x) gaussian(x, mu, sigma),\n  lower = a,\n  upper = b\n)\n\n0.6826895 with absolute error &lt; 7.6e-15\n\n\nIn sintesi, questo approccio dimostra come calcolare l’integrale di una funzione di densità in un intervallo utilizzando sia un metodo approssimativo basato sulla somma dei rettangoli sia il metodo numerico integrato. In entrambi i casi, l’obiettivo è calcolare l’area sotto la curva, che corrisponde all’integrale della funzione di densità.",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>Per liberarvi dai terrori preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a15_calculus.html#potenze",
    "href": "chapters/appendix/a15_calculus.html#potenze",
    "title": "90  Per liberarvi dai terrori preliminari",
    "section": "\n90.2 Potenze",
    "text": "90.2 Potenze\nLe potenze sono un’operazione matematica che rappresenta un prodotto ripetuto. Si indicano generalmente come:\n\\[\na^n,\n\\]\ndove:\n\n\n\\(a\\) è la base,\n\n\\(n\\) è l’esponente.\n\nLa potenza rappresenta il prodotto della base \\(a\\) ripetuto \\(n\\) volte.\n\n90.2.1 Definizione di potenza\n\\[\na^n = \\underbrace{a \\cdot a \\cdot \\dots \\cdot a}_{n \\text{ fattori}} \\quad \\text{con } n \\in \\mathbb{N}.\n\\]\nAd esempio:\n\n\n\\(2^3 = 2 \\cdot 2 \\cdot 2 = 8\\),\n\n\\(3^4 = 3 \\cdot 3 \\cdot 3 \\cdot 3 = 81\\).\n\n\n90.2.2 Proprietà delle potenze\n\n\nMoltiplicazione di potenze con la stessa base:\n\\[\na^m \\cdot a^n = a^{m+n}\n\\]\nEsempio: \\(2^3 \\cdot 2^2 = 2^{3+2} = 2^5 = 32\\).\n\n\nDivisione di potenze con la stessa base:\n\\[\n\\frac{a^m}{a^n} = a^{m-n}, \\quad \\text{con } m \\geq n.\n\\]\nEsempio: \\(\\frac{5^4}{5^2} = 5^{4-2} = 5^2 = 25\\).\n\n\nPotenze di potenze:\n\\[\n(a^m)^n = a^{m \\cdot n}.\n\\]\nEsempio: \\((3^2)^3 = 3^{2 \\cdot 3} = 3^6 = 729\\).\n\n\nProdotto di potenze con basi diverse ma lo stesso esponente:\n\\[\na^n \\cdot b^n = (a \\cdot b)^n.\n\\]\nEsempio: \\(2^3 \\cdot 3^3 = (2 \\cdot 3)^3 = 6^3 = 216\\).\n\n\nDivisione di potenze con basi diverse ma lo stesso esponente:\n\\[\n\\frac{a^n}{b^n} = \\left(\\frac{a}{b}\\right)^n.\n\\]\nEsempio: \\(\\frac{4^2}{2^2} = \\left(\\frac{4}{2}\\right)^2 = 2^2 = 4\\).\n\n\nEsponente zero:\n\\[\na^0 = 1, \\quad \\text{con } a \\neq 0.\n\\]\nEsempio: \\(5^0 = 1\\).\n\n\nEsponente negativo:\n\\[\na^{-n} = \\frac{1}{a^n}.\n\\]\nEsempio: \\(2^{-3} = \\frac{1}{2^3} = \\frac{1}{8}\\).\n\n\nRadice come potenza frazionaria:\n\\[\na^{\\frac{1}{n}} = \\sqrt[n]{a}, \\quad a^{\\frac{m}{n}} = \\sqrt[n]{a^m}.\n\\]\nEsempio: \\(8^{\\frac{1}{3}} = \\sqrt[3]{8} = 2\\).\n\n\n\n90.2.3 Esempi pratici\n\n\nCalcolo semplice:\n\\[\n4^3 = 4 \\cdot 4 \\cdot 4 = 64.\n\\]\n\n\nUtilizzo delle proprietà:\n\\[\n3^5 \\cdot 3^2 = 3^{5+2} = 3^7 = 2187.\n\\]\n\n\nDivisione:\n\\[\n\\frac{6^4}{6^2} = 6^{4-2} = 6^2 = 36.\n\\]\n\n\nEsponente negativo:\n\\[\n10^{-2} = \\frac{1}{10^2} = \\frac{1}{100} = 0.01.\n\\]\n\n\nRadice come potenza:\n\\[\n16^{\\frac{1}{2}} = \\sqrt{16} = 4.\n\\]\n\n\n\n90.2.4 Nota sui numeri razionali e reali\n\nLe potenze con esponenti interi sono definite per ogni base.\nLe potenze con esponenti frazionari o reali richiedono che la base sia positiva per evitare ambiguità.",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>Per liberarvi dai terrori preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a15_calculus.html#logaritmi",
    "href": "chapters/appendix/a15_calculus.html#logaritmi",
    "title": "90  Per liberarvi dai terrori preliminari",
    "section": "\n90.3 Logaritmi",
    "text": "90.3 Logaritmi\nIl logaritmo è una funzione matematica che risponde alla domanda: “quante volte devo moltiplicare un certo numero (chiamato”base”) per ottenere un altro numero?” Matematicamente, questo è espresso come:\n\\[\n\\log_b(a) = x \\iff b^x = a\n\\]\nAd esempio, \\(\\log_2(8) = 3\\) perché \\(2^3 = 8\\).\nNel contesto dei logaritmi, i valori molto piccoli (compresi tra 0 e 1) diventano più grandi (in termini assoluti) e negativi quando applichiamo una funzione logaritmica. Questo è utile per stabilizzare i calcoli, specialmente quando lavoriamo con prodotti di numeri molto piccoli che potrebbero portare a problemi di underflow.\nPer esempio:\n\n\\(\\log(1) = 0\\)\n\\(\\log(0.1) = -1\\)\n\\(\\log(0.01) = -2\\)\n\\(\\log(0.001) = -3\\)\n\nCome si può vedere, i valori assoluti dei logaritmi crescono man mano che il numero originale si avvicina a zero.\nUna delle proprietà più utili dei logaritmi è che consentono di trasformare un prodotto in una somma:\n\\[\n\\log_b(a \\times c) = \\log_b(a) + \\log_b(c)\n\\]\nQuesta proprietà è estremamente utile in calcoli complessi, come nella statistica bayesiana, dove il prodotto di molte probabilità potrebbe diventare un numero molto piccolo e causare problemi numerici.\nUn’altra proprietà utile dei logaritmi è che un rapporto tra due numeri diventa la differenza dei loro logaritmi:\n\\[\n\\log_b\\left(\\frac{a}{c}\\right) = \\log_b(a) - \\log_b(c)\n\\]\nAnche questa proprietà è molto utilizzata in matematica, specialmente in situazioni in cui è necessario normalizzare i dati.\nIn sintesi, i logaritmi sono strumenti potenti per semplificare e stabilizzare i calcoli matematici. Essi consentono di lavorare più agevolmente con numeri molto grandi o molto piccoli e di trasformare operazioni complesse come prodotti e divisioni in somme e differenze, rendendo i calcoli più gestibili e meno inclini a errori numerici.",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>Per liberarvi dai terrori preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a44_montecarlo.html",
    "href": "chapters/appendix/a44_montecarlo.html",
    "title": "91  Simulazione Monte Carlo",
    "section": "",
    "text": "91.1 Funzioni in R\nIl Metodo Monte Carlo utilizza simulazioni casuali per risolvere problemi complessi. È applicato in numerosi ambiti per calcolare stime quando non è possibile ottenere soluzioni analitiche semplici.\nPer fare un esempio semplice, stimiamo π con il Metodo Monte Carlo. Per fare questo, calcoleremo approssimativamente π simulando il rapporto tra l’area di un cerchio e quella di un quadrato circoscritto.\nDefiniamo una funzione per verificare se un punto è all’interno del cerchio e una per stimare \\(\\pi\\) e generare una figura visualizzabile nel file HTML.\n# Funzione per verificare se un punto è dentro il cerchio\nin_circle &lt;- function(x, y, r) {\n  sqrt(x^2 + y^2) &lt;= r\n}\n\n# Funzione per stimare π e creare una figura\napprox_pi &lt;- function(r, n) {\n  # Genera punti casuali\n  points &lt;- data.frame(\n    x = runif(n, 0, r),\n    y = runif(n, 0, r)\n  )\n  \n  # Determina se i punti sono dentro il cerchio\n  points &lt;- points %&gt;%\n    mutate(in_circle = in_circle(x, y, r),\n           color = ifelse(in_circle, \"inside\", \"outside\"))\n  \n  # Conta i punti dentro il cerchio\n  count &lt;- sum(points$in_circle)\n  \n  # Calcola π\n  pi_approx &lt;- 4 * count / n\n  \n  # Genera il grafico\n  ggplot(points, aes(x, y, color = color)) +\n    geom_point(size = 1, alpha = 0.5) +\n    labs(\n      title = paste(\"Monte Carlo Approximation of π ≈\", round(pi_approx, 3)),\n      subtitle = paste(count, \"points inside the circle out of\", n, \"total points\"),\n      x = \"x\",\n      y = \"y\"\n    ) +\n    coord_equal() \n}\nEseguiamo la simulazione per diverse dimensioni del campione:\n# Simulazioni con diverse quantità di punti\nr &lt;- 1\nn_points &lt;- c(50, 500, 5000)\n\n# Ciclo per calcolare π e generare i grafici\nfor (n in n_points) {\n  cat(\"Stima di π con\", n, \"punti:\\n\")\n  print(approx_pi(r, n))\n}\n#&gt; Stima di π con 50 punti:\n#&gt; Stima di π con 500 punti:\n#&gt; Stima di π con 5000 punti:",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>Simulazione Monte Carlo</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a44_montecarlo.html#simulazione-di-monte-carlo-in-stan",
    "href": "chapters/appendix/a44_montecarlo.html#simulazione-di-monte-carlo-in-stan",
    "title": "91  Simulazione Monte Carlo",
    "section": "\n91.2 Simulazione di Monte Carlo in Stan",
    "text": "91.2 Simulazione di Monte Carlo in Stan\nSimuliamo π utilizzando Stan, un potente strumento per la modellazione probabilistica. Definiamo il modello in Stan come segue:\ngenerated quantities {\n  real x = uniform_rng(0, 1);\n  real y = uniform_rng(0, 1);\n  int inside = x^2 + y^2 &lt;= 1;\n  real pi_estimate = 4 * inside;\n}\nUtilizziamo il pacchetto cmdstanr per compilare ed eseguire il modello Stan.\n\n# Definisce il modello Stan\nstan_code &lt;- \"\ngenerated quantities {\n  real x = uniform_rng(0, 1);\n  real y = uniform_rng(0, 1);\n  int inside = x^2 + y^2 &lt;= 1;\n  real pi_estimate = 4 * inside;\n}\n\"\n\n# Scrive il modello su un file temporaneo\nwriteLines(stan_code, con = \"monte_carlo_pi.stan\")\n\n# Compila il modello\nmodel &lt;- cmdstan_model(\"monte_carlo_pi.stan\")\n\n# Esegue il campionamento\nsamples &lt;- model$sample(\n  chains = 1, \n  iter_sampling = 10000, \n  iter_warmup = 0, \n  seed = 42, \n  fixed_param = TRUE, \n  show_messages = FALSE\n)\n\n# Analisi dei risultati\npi_samples &lt;- samples$draws(variables = \"pi_estimate\", format = \"df\")\n\n# Calcolo di π stimato\npi_est &lt;- mean(pi_samples$pi_estimate)\ncat(\"Stima di π:\", round(pi_est, 3), \"\\n\")\n#&gt; Stima di π: 3.15\n\nQuesta combinazione di R e Stan dimostra l’efficacia e la flessibilità del Metodo Monte Carlo e delle sue varianti. Sia per problemi semplici come la stima di \\(\\pi\\), sia per applicazioni più complesse come l’integrazione e l’importance sampling, questi strumenti offrono soluzioni potenti e scalabili.",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>Simulazione Monte Carlo</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a46_stan_lang.html",
    "href": "chapters/appendix/a46_stan_lang.html",
    "title": "92  Linguaggio Stan",
    "section": "",
    "text": "92.1 Interfaccia cmdstanr\nÈ possibile accedere al linguaggio Stan tramite diverse interfacce:\nInoltre, vengono fornite interfacce di livello superiore con i pacchetti che utilizzano Stan come backend, sia in Python che in Linguaggio \\(\\mathsf{R}\\):\nNegli esempi di questa dispensa verrà utilizzata l’interfaccia cmdstanr. CmdStanR è un’interfaccia R per Stan che consente di definire, eseguire e analizzare modelli bayesiani in modo semplice ed efficace. Questa libreria integra l’interfaccia a riga di comando di CmdStan con una serie di funzioni R intuitive, che permettono di gestire modelli, dati e risultati dell’inferenza a posteriori.\nPer installare CmdStanR, è possibile seguire la guida ufficiale disponibile a questo link.",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>92</span>  <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a46_stan_lang.html#codice-stan",
    "href": "chapters/appendix/a46_stan_lang.html#codice-stan",
    "title": "92  Linguaggio Stan",
    "section": "92.2 Codice Stan",
    "text": "92.2 Codice Stan\nStan consente agli utenti di definire un modello bayesiano attraverso il linguaggio Stan. Questo modello, di solito, viene salvato in un file di testo con estensione .stan.\nIl codice Stan deve poi essere compilato. Il processo di compilazione di un modello in Stan avviene in due fasi: innanzitutto, Stan traduce il modello dal formato .stan in codice C++, il quale viene successivamente compilato in codice macchina.\nDopo la compilazione del modello (ovvero, dopo che il codice macchina è stato generato), l’utente può utilizzare l’interfaccia prescelta (per esempio, CmdStan) per campionare la distribuzione definita dal modello e per eseguire altri calcoli correlati al modello stesso.\nIl codice Stan è costituito da una serie di blocchi che vengono usati per specificare un modello statistico. In ordine, questi blocchi sono:\nfunctions {\n  // ... function declarations and definitions ...\n}\ndata {\n  // ... declarations ...\n}\ntransformed data {\n   // ... declarations ... statements ...\n}\nparameters {\n   // ... declarations ...\n}\ntransformed parameters {\n   // ... declarations ... statements ...\n}\nmodel {\n   // ... declarations ... statements ...\n}\ngenerated quantities {\n   // ... declarations ... statements ...\n}\nQuesti blocchi devono sempre essere in questo ordine, ma non tutti i programmi Stan richiedono tutti i blocchi.\n\n92.2.1 Blocco data\nNel blocco data vengono specificate le variabili di input utilizzate nel modello Stan. Per ogni variabile, è necessario definire il tipo di dato, le dimensioni e, se necessario, applicare vincoli sui valori che tali variabili possono assumere.\nEsempio di blocco data:\ndata {\n  int&lt;lower=0&gt; ntrials; // Numero di prove\n  int&lt;lower=0&gt; y;       // Successi osservati\n  real&lt;lower=0&gt; alpha_prior; // Parametro alpha per il prior Beta\n  real&lt;lower=0&gt; beta_prior;  // Parametro beta per il prior Beta\n}\nStan offre diversi tipi di dati per le variabili, tra cui:\n\nint: Rappresenta numeri interi senza parte decimale. Esempio: int N = 10;.\nreal: Rappresenta numeri reali, inclusi i decimali. Esempio: real pi = 3.14159;.\nvector: Un vettore unidimensionale di numeri reali. Esempio: vector[3] y;.\nmatrix: Una matrice bidimensionale di numeri reali. Esempio: matrix[2,3] A;.\narray: Tipo generico per contenere elementi di qualsiasi tipo, incluso array di array. Esempio: array[3] int my_array;.\n\n\n92.2.1.1 Dichiarazione di dimensioni e applicazione di vincoli\nQuando si dichiara una variabile, è essenziale specificarne le dimensioni e, se appropriato, applicare vincoli sui valori che può assumere. I vincoli più comuni sono:\n\nlower: Specifica il valore minimo.\nupper: Specifica il valore massimo.\n\nEsempio di variabile reale compresa tra 0 e 1:\nreal&lt;lower=0, upper=1&gt; x;\n\n\n\n92.2.2 Tipi di Dati in Stan\n\n92.2.2.1 Interi\nLe variabili intere vengono dichiarate con la parola chiave int. Per dichiarare un intero positivo, si aggiunge un vincolo inferiore:\nint&lt;lower=1&gt; N;\n\n\n92.2.2.2 Reali\nLe variabili reali, dichiarate con real, possono essere vincolate allo stesso modo degli interi:\nreal&lt;lower=0&gt; sigma;\n\n\n92.2.2.3 Tipi di Dati Vettoriali e Matriciali\n\nVector: Rappresenta una sequenza unidimensionale di numeri reali. Esempio: vector[3] u;.\nMatrix: Una matrice bidimensionale di numeri reali. Esempio: matrix[3, 3] A;.\n\nLe variabili vettoriali e matriciali possono contenere solo valori reali, non interi, e sono trattate come strutture dati distinte dagli array.\n\n92.2.2.3.1 Vettori\nI vettori in Stan sono vettori colonna. Esempio di vettore reale di lunghezza 3:\nvector[3] u;\n\n\n92.2.2.3.2 Matrici\nLe matrici vengono dichiarate specificando il numero di righe e colonne:\nmatrix[3, 3] A;\nmatrix[M, N] B;\nLe dimensioni devono essere definite come variabili intere nel blocco dati.\n\n\n\n92.2.2.4 Array\nGli array possono contenere variabili di qualsiasi tipo (inclusi array di array). Ad esempio, un array di interi:\narray[5] int n;\nGli array multidimensionali sono array di array. Un array bidimensionale di interi si dichiara così:\narray[3, 4] int a;\n\n\n\n92.2.3 Indicizzazione e Miscelazione dei Tipi\n\nStan indicizza vettori, matrici e array a partire da 1.\nNon è possibile assegnare tra loro variabili di tipo array, vettore o matrice, anche se hanno le stesse dimensioni.\n\n\n\n92.2.4 Liste in CmdStanR\nQuando si forniscono dati a Stan tramite CmdStanR, questi devono essere organizzati in una lista R. Ogni elemento della lista corrisponde a una variabile dichiarata nel blocco data di Stan, e il valore associato rappresenta i dati forniti al modello.\nEsempio di lista:\ndata_list &lt;- list(\n  ntrials = 100,\n  y = 45,\n  alpha_prior = 2.0,\n  beta_prior = 5.0\n)\nQuesta struttura consente di mappare correttamente i dati alle variabili definite nel modello Stan.\nIn Stan, ogni variabile deve avere un tipo di dato ben definito, con la possibilità di applicare vincoli per garantire validità e coerenza. I tipi principali includono numeri interi, numeri reali, vettori, matrici e array, ciascuno progettato per supportare operazioni specifiche e migliorare l’efficienza computazionale.\n\n\n92.2.5 Blocco parameters\nI parametri da stimare sono definiti all’interno del blocco parameters.\nAd esempio, consideriamo il seguente codice, dove viene dichiarata la variabile theta per rappresentare una probabilità. Si notino i vincoli che specificano che i valori possibili per theta devono essere contenuti nell’intervallo [0, 1].\nparameters {\n  real&lt;lower=0, upper=1&gt; theta; // Parametro stimato, limitato tra 0 e 1\n}\n\n\n92.2.6 Blocco model\nLa sezione model è il cuore di un modello Stan, dove si specificano le relazioni statistiche tra i dati osservati e i parametri incogniti. In questa sezione, si definisce la verosimiglianza, ovvero la distribuzione di probabilità dei dati condizionata dai parametri, e si assegnano le distribuzioni a priori ai parametri stessi.\n\nLa verosimiglianza modella il processo generativo dei dati. Essa descrive come i dati osservati si sarebbero potuti generare a partire da specifici valori dei parametri. In Stan, la verosimiglianza viene specificata utilizzando il simbolo ~ (tilde).\nLe distribuzioni a priori riflettono le nostre conoscenze o credenze a priori sui parametri prima di osservare i dati. Esse agiscono come regolarizzatori, prevenendo sovrastima o sottostima dei parametri.\n\nAd esempio, nel codice seguente\nmodel {\n  // Modello Beta-Binomiale\n  theta ~ beta(alpha_prior, beta_prior); // Distribuzione a priori di theta\n  y ~ binomial(ntrials, theta); // Verosimiglianza binomiale\n}\n\ntheta ~ beta(alpha_prior, beta_prior);: Questa riga assegna una distribuzione a priori Beta al parametro theta, con parametri di forma alpha_prior e beta_prior.\ny ~ binomial(ntrials, theta);: Questa riga specifica che i dati osservati y seguono una distribuzione binomiale con ntrials prove e probabilità di successo theta.\n\nIn generale, possiamo leggere il simbolo ~ come “è distribuito come”. Pertanto, l’esempio sopra può essere scritto anche come:\n\\[\np(\\theta \\mid \\alpha_p, \\beta_p) = \\text{Beta}(\\alpha_p, \\beta_p)\n\\]\ne\n\\[\np(y \\mid \\theta) = \\text{Binomiale}(y \\mid n, \\theta).\n\\]\nLa notazione compatta usata da Stan facilita la definizione delle relazioni probabilistiche nel modello.\nIn assenza di specifiche, Stan assume una distribuzione non informativa, ovvero una distribuzione a priori uniforme tra meno infinito e più infinito. Per ulteriori raccomandazioni sulle scelte delle distribuzioni a priori, è possibile consultare questo link.\nIn sintesi, la sezione model definisce il modello statistico completo, combinando la nostra conoscenza a priori sui parametri (attraverso le distribuzioni a priori) con le informazioni contenute nei dati (attraverso la verosimiglianza). Stan utilizza poi tecniche di inferenza Bayesiana per stimare i valori più probabili dei parametri alla luce dei dati osservati.\n\n\n92.2.7 Blocchi opzionali\nCi sono inoltre tre blocchi opzionali:\n\nIl blocco transformed data consente il pre-processing dei dati. È possibile trasformare i parametri del modello; solitamente ciò viene fatto nel caso dei modelli più avanzati per consentire un campionamento MCMC più efficiente.\nIl blocco transformed parameters consente la manipolazione dei parametri prima del calcolo della distribuzione a posteriori.\nIl blocco generated quantities consente il post-processing riguardante qualsiasi quantità che non fa parte del modello ma può essere calcolata a partire dai parametri del modello, per ogni iterazione dell’algoritmo. Esempi includono la generazione dei campioni a posteriori e le dimensioni degli effetti.\n\n\n\n92.2.8 Sintassi\nIl codice Stan richiede i punti e virgola (;) alla fine di ogni istruzione di assegnazione. Questo accade per le dichiarazioni dei dati, per le dichiarazioni dei parametri e ovunque si acceda ad un elemento di un tipo data e lo si assegni a qualcos’altro. I punti e virgola non sono invece richiesti all’inizio di un ciclo o di un’istruzione condizionale, dove non viene assegnato nulla.\nIn Stan, qualsiasi stringa che segue il marcatore // denota un commento e viene ignorata dal programma.\nUna descrizione dettagliata della sintassi del linguaggio Stan è disponibile al seguente link.",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>92</span>  <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a50_lin_fun.html",
    "href": "chapters/appendix/a50_lin_fun.html",
    "title": "93  La funzione lineare",
    "section": "",
    "text": "93.1 Concetto di Funzione\nNello studio dei fenomeni naturali e nella risoluzione di problemi tecnici e matematici, è spesso necessario considerare la variazione di una grandezza come dipendente dalla variazione di un’altra. Ad esempio, nello studio del moto, il percorso compiuto da un oggetto può essere visto come una grandezza variabile in funzione del tempo: il cammino percorso è, dunque, una funzione del tempo.\nQuesta considerazione ci conduce alla seguente definizione:\nSe a ogni valore della variabile \\(x\\) (all’interno di un certo intervallo) corrisponde un valore ben definito di un’altra variabile \\(y\\), allora si dice che \\(y\\) è una funzione di \\(x\\). In notazione funzionale si scrive:\n\\[\ny = f(x) \\quad \\text{o anche} \\quad y = \\varphi(x).\n\\]\nLa variabile \\(x\\) è detta variabile indipendente o argomento della funzione. La relazione che lega \\(x\\) a \\(y\\) si chiama relazione funzionale. La lettera \\(f\\) nella notazione \\(y = f(x)\\) indica che per ottenere il valore di \\(y\\) a partire da \\(x\\) è necessario applicare una certa “regola” o “operazione”. In modo analogo, si possono utilizzare anche altre notazioni come \\(u = \\varphi(x)\\).\nLa notazione \\(y = C\\), dove \\(C\\) è una costante, indica una funzione il cui valore rimane invariato per qualunque valore di \\(x\\).\nL’insieme dei valori di \\(x\\) per cui la funzione \\(y = f(x)\\) è definita si chiama dominio di definizione della funzione.\nSe per valori crescenti della variabile indipendente \\(x\\) anche il valore della funzione \\(y = f(x)\\) aumenta, allora la funzione si dice crescente. Analogamente, se a valori crescenti di \\(x\\) corrispondono valori decrescenti della funzione \\(y = f(x)\\), la funzione si dice decrescente.",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>93</span>  <span class='chapter-title'>La funzione lineare</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a50_lin_fun.html#la-retta",
    "href": "chapters/appendix/a50_lin_fun.html#la-retta",
    "title": "93  La funzione lineare",
    "section": "93.2 La Retta",
    "text": "93.2 La Retta\nLa funzione lineare è definita come:\n\\[\nf(x) = a + b x,\n\\]\ndove \\(a\\) e \\(b\\) sono costanti. Il grafico di tale funzione è una retta. Qui, \\(b\\) è detto coefficiente angolare, mentre \\(a\\) è l’intercetta con l’asse delle \\(y\\). In altri termini, la retta interseca l’asse \\(y\\) nel punto \\((0, a)\\).\nPer comprendere il ruolo di \\(a\\) e \\(b\\), consideriamo prima il caso particolare:\n\\[\ny = b x.\n\\]\nQuesta espressione rappresenta una proporzionalità diretta tra \\(x\\) e \\(y\\): al crescere di \\(x\\), \\(y\\) varia in proporzione. Nel caso generale:\n\\[\ny = a + b x,\n\\]\nil termine \\(a\\) “trasla” verticalmente il grafico, aggiungendo una costante a ogni valore \\(b x\\).\nIl segno del coefficiente \\(b\\) determina il comportamento della funzione lineare:\n\nSe \\(b &gt; 0\\), il valore di \\(y\\) aumenta all’aumentare di \\(x\\).\n\nSe \\(b &lt; 0\\), il valore di \\(y\\) diminuisce all’aumentare di \\(x\\).\n\nSe \\(b = 0\\), il grafico è una retta orizzontale e \\(y\\) rimane costante.\n\nPossiamo dare un’interpretazione geometrica ancora più intuitiva se consideriamo variazioni (incrementi) di \\(x\\). Preso un punto \\(x_0\\) e aggiungendo un piccolo incremento \\(\\varepsilon\\), definiamo:\n\\[\n\\Delta x = (x_0 + \\varepsilon) - x_0 = \\varepsilon,\n\\] \\[\n\\Delta y = f(x_0 + \\varepsilon) - f(x_0).\n\\]\nIl coefficiente angolare \\(b\\) può essere interpretato come il rapporto tra la variazione di \\(y\\) e la variazione di \\(x\\):\n\\[\nb = \\frac{\\Delta y}{\\Delta x} = \\frac{f(x_0 + \\varepsilon) - f(x_0)}{(x_0 + \\varepsilon) - x_0}.\n\\]\nQuesto rapporto è costante e non dipende dalla scelta di \\(x_0\\) o di \\(\\varepsilon\\). In particolare, se scegliamo \\(\\Delta x = 1\\), il coefficiente angolare \\(b\\) rappresenta semplicemente di quanto varia \\(y\\) quando \\(x\\) aumenta di un’unità.\n\n\n\n\n\n\n\nFigura 93.1: La funzione lineare \\(y = a + bx\\).\n\n\n\nCome mostrato in figura, il coefficiente \\(b\\) indica la pendenza della retta, ossia quanto “ripida” è la sua inclinazione rispetto all’asse orizzontale.",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>93</span>  <span class='chapter-title'>La funzione lineare</span>"
    ]
  }
]