# Modelli probabilistici {#sec-prob-models}

::: callout-important
## In questo capitolo imparerai a

- comprendere come gli esperimenti casuali possono essere modellati matematicamente e come tale modellizzazione ci permetta di calcolare diverse propriet√† di interesse per questi esperimenti.
:::

::: callout-tip
## Prerequisiti

- Leggere il capitolo *Probability Models* del testo di @kroese2025statistical.
- Studiare l'@sec-apx-sets.
- Studiare l'@sec-apx-combinatorics. 
:::

::: callout-caution
## Preparazione del Notebook

```{r}
here::here("code", "_common.R") |>
  source()

# Load packages
if (!requireNamespace("pacman")) install.packages("pacman")
pacman::p_load(readr, VennDiagram)
```
:::

## Introduzione

Dopo aver esaminato il *significato filosofico* della probabilit√† nel @sec-prob-interpretation, questo capitolo ne sviluppa una trattazione pi√π formale, creando un collegamento tra la riflessione teorica e gli strumenti operativi. Partendo dalla definizione di **esperimento casuale** ‚Äì come il lancio di una moneta o la somministrazione di un test psicologico ‚Äì costruiremo un framework matematico per analizzare e quantificare le propriet√† di tali esperimenti. In particolare, approfondiremo i concetti di **spazio campionario**, **eventi** e **propriet√† della probabilit√†**, fornendo le basi per un‚Äôinterpretazione rigorosa dei fenomeni complessi in psicologia e nelle scienze sociali.

::: callout-tip
## Domande introduttive

Prima di esaminare in maniera pi√π formale le basi della teoria della probabilit√†, consideriamo un classico problema della teoria della probabilit√†: 

üîç *"Quante persone servono in una stanza perch√© ci sia almeno il 50% di probabilit√† che due condividano lo stesso compleanno?"*  

Questo problema, noto come **problema dei compleanni**, fu introdotto dal matematico Richard von Mises nel 1932. La sua soluzione sfida l‚Äôintuizione e rivela quanto le probabilit√† combinatorie possano essere ingannevoli.

Rispondi alle seguenti domande. 

1. Con quante persone pensi si superi il 50% di probabilit√†? (23? 100? 180?)
2. Con 30 persone, quale probabilit√† stimi? (10%? 50%? 70%?)

Scrivi le tue risposte su un foglietto senza condividere con i compagni.

**Per svolgere un esercizio in classe**, compila il seguente [modulo](https://docs.google.com/forms/d/e/1FAIpQLScRZBPFsdT2P13BmcT5N6z7aQLf8YCkBcvc_jQXEM6x8SdcJg/viewform?usp=header) su Google Forms. 
:::

## Esperimenti Casuali

Il concetto fondamentale della probabilit√† √® l‚Äô**esperimento casuale**, ovvero un procedimento il cui esito non pu√≤ essere previsto con certezza, ma che pu√≤ essere analizzato quantitativamente. Alcuni esempi di esperimenti casuali includono:

1. Lanciare un dado e osservare il numero ottenuto sulla faccia superiore.
2. Estrarre una carta a caso da un mazzo e registrarne il seme e il valore.
3. Misurare il livello di stress percepito da un gruppo di individui in un determinato contesto, come durante un esame o un evento stressante.
4. Contare il numero di risposte corrette fornite dai partecipanti a un test di memoria entro un tempo prestabilito.
5. Selezionare casualmente 50 persone e determinare quante mostrano una predisposizione alla creativit√†, misurata attraverso un questionario standardizzato.
6. Scegliere a caso dieci individui e valutare il loro grado di introversione mediante uno strumento di autovalutazione psicologica.
7. Selezionare casualmente 50 persone e contare quante sono mancine.
8. Scegliere a caso dieci individui e misurarne l‚Äôaltezza.

L‚Äôanalisi probabilistica ha lo scopo di comprendere il comportamento di tali esperimenti attraverso la costruzione di modelli matematici. Una volta formalizzato matematicamente un esperimento casuale, √® possibile calcolare grandezze di interesse, come probabilit√† ed aspettative. Questi modelli possono essere implementati al computer per simulare l‚Äôesperimento e analizzarne i risultati. Inoltre, la modellizzazione matematica degli esperimenti casuali costituisce la base della statistica, disciplina che permette di confrontare diversi modelli e identificare quello pi√π adeguato ai dati osservati.


### Il Lancio di una Moneta

Uno degli esperimenti casuali pi√π semplici e fondamentali √® il **lancio ripetuto di una moneta**. Molti concetti chiave della teoria della probabilit√† possono essere illustrati partendo da questo esperimento elementare. Per studiarne il comportamento, possiamo simularlo al computer utilizzando il linguaggio R. 

Di seguito, un semplice script in R simula **100 lanci** di una moneta equa (cio√® con probabilit√† uguali di ottenere Testa o Croce) e rappresenta graficamente la distribuzione dei risultati mediante un diagramma a barre.

```{r}
set.seed(123) # Imposta il seed per garantire la riproducibilit√†
x <- runif(100) < 0.5 # Genera 100 numeri casuali e verifica se sono minori di 0.5
x
```

Nel codice, la funzione `runif` genera 100 numeri casuali distribuiti uniformemente nell'intervallo [0, 1]. Confrontando ciascun numero con 0.5, otteniamo un vettore logico che rappresenta il risultato di ogni lancio: **Testa** (TRUE) o **Croce** (FALSE). 


```{r}
t <- 1:100 # Sequenza degli indici dei lanci

# Creazione del dataframe per ggplot2
dat <- tibble(
  Lancio = t,
  Risultato = ifelse(x, "Testa", "Croce")
)
head(dat)
```

Il grafico a barre mostra la distribuzione osservata degli esiti.

```{r}
# Creazione del grafico a barre della distribuzione dei risultati
dat |>
  ggplot(aes(x = Risultato)) +
  geom_bar(aes(y = after_stat(prop), group = 1),
           fill = "lightblue", color = "black", width = 0.5) +
  labs(
    title = "Distribuzione dei risultati del lancio della moneta",
    x = "Risultato",
    y = "Frequenza relativa"
  )
```

Un aspetto rilevante di questo esperimento √® l'**andamento della proporzione osservata di esiti "Testa"** in funzione del numero di lanci. Il grafico riportato di seguito illustra l‚Äôevoluzione della **media cumulativa** degli esiti "Testa", che, in accordo con la legge dei grandi numeri, dovrebbe convergere al valore teorico di **0.5**.

```{r}
y <- cumsum(x) / t # Calcola la media cumulativa delle Teste

# Creazione del dataframe per il grafico della media mobile
data_mean <- tibble(
  Lancio = t, 
  Media_Testa = y
)

# Creazione del grafico della media cumulativa
data_mean |>
  ggplot(
    aes(x = Lancio, y = Media_Testa)
  ) +
  geom_line(linewidth = 1.5) +
  geom_hline(yintercept = 0.5, linetype = "dashed", color = "red") +
  labs(
    title = "Media cumulativa del numero di Teste",
    x = "Numero di lanci",
    y = "Frequenza cumulativa di Teste"
  )
```

::: {.callout-tip title="Media cumulata" collapse="true"}
La **media cumulata** (o **cumulativa**) √® una media che si calcola progressivamente, aggiungendo un nuovo dato alla volta e ricalcolando la media considerando **tutti i valori precedenti** insieme al nuovo.  
In pratica, mostra come la media si evolve man mano che vengono inclusi nuovi dati nella serie.

**Come si calcola?**  

1. Al primo dato, la media cumulata √® il dato stesso.  
2. Al secondo dato, √® la media tra il primo e il secondo.  
3. Al terzo dato, √® la media tra il primo, il secondo e il terzo.  
4. E cos√¨ via...  

**Formula intuitiva**:  

$$
\text{Media cumulata al passo } n = \frac{\text{somma di tutti i dati fino al passo } n}{n}
$$

**Esempio pratico**:  
Supponiamo di avere i voti di uno studente in 3 verifiche:  

- Verifica 1: 7  
- Verifica 2: 6  
- Verifica 3: 8  

Le **medie cumulate** saranno:  

- Dopo la 1¬™ verifica: $\frac{7}{1} = 7$.  
- Dopo la 2¬™ verifica: $\frac{7 + 6}{2} = 6.5$.  
- Dopo la 3¬™ verifica: $\frac{7 + 6 + 8}{3} = 7$.

**A cosa serve?**  

- **Tracciare l'andamento** nel tempo (es.: mostrare come la frequenza di "Testa" si avvicina gradualmente al 50% teorico man mano che aumentano i lanci).  
- **Lisciare le fluttuazioni**: riduce l‚Äôimpatto di picchi temporanei, mostrando un trend pi√π stabile.  
- **Valutare prestazioni progressive** (es.: un atleta che migliora gradualmente).  
:::

Il grafico mostra come la media delle Teste oscilla inizialmente a causa della variabilit√† intrinseca dell'esperimento, ma **tende progressivamente a stabilizzarsi intorno a 0.5**. Questo fenomeno √® un esempio della **Legge dei Grandi Numeri**, secondo cui, ripetendo un esperimento casuale un numero sempre maggiore di volte, la frequenza relativa di un evento si avvicina alla sua probabilit√† teorica.

### Domande di Interesse

L‚Äôesperimento casuale del lancio di una moneta porta a numerose domande, tra cui:

- Qual √® la probabilit√† di ottenere un certo numero $x$ di Teste in 100 lanci?
- Qual √® il numero atteso di Teste in un esperimento di 100 lanci?

Dal punto di vista statistico, quando osserviamo i risultati di un esperimento reale (ad esempio, 100 lanci di una moneta), possiamo anche porci domande come:

- La moneta √® davvero equa o √® sbilanciata?
- Qual √® il miglior metodo per stimare la probabilit√† $p$ di ottenere Testa dalla sequenza osservata di lanci?
- Quanto √® precisa la stima ottenuta e con quale livello di incertezza?

Questi interrogativi costituiscono la base della **statistica inferenziale**, che permette di testare ipotesi sulla probabilit√† di un evento e stimare parametri sconosciuti sulla base di dati osservati.

### **Modellizzazione**

La descrizione matematica di un esperimento casuale si basa su tre elementi fondamentali:

1. **Lo spazio campionario**: rappresenta l'insieme di tutti i possibili esiti dell'esperimento. Nel caso di esperimenti semplici, lo spazio campionario √® immediato da individuare, mentre in situazioni pi√π complesse √® necessario applicare i principi del calcolo combinatorio.  

2. **Gli eventi**: sono sottoinsiemi dello spazio campionario e rappresentano gli esiti di interesse. Per analizzare e manipolare gli eventi, utilizziamo gli strumenti della teoria degli insiemi.  

3. **La probabilit√†**: assegna un valore numerico a ciascun evento, indicando la sua probabilit√† di verificarsi. L'assegnazione delle probabilit√† avviene secondo gli assiomi di Kolmogorov.  

Nei paragrafi seguenti, analizzeremo ciascuna di queste componenti in dettaglio.

## Spazio Campionario

Anche se non possiamo prevedere con esattezza l‚Äôesito di un singolo esperimento casuale, possiamo comunque definire tutti i risultati che potrebbero verificarsi. L‚Äôinsieme completo di questi esiti possibili si chiama **spazio campionario**.

::: {#def-}
Lo *spazio campionario* $\Omega$ di un esperimento casuale √® l‚Äôinsieme di tutti i possibili esiti dell‚Äôesperimento.
:::

### Esempi di Spazi Campionari

Consideriamo lo spazio campionario di alcuni esperimenti casuali.

1. Lancio di due dadi consecutivi:
   $$
   \Omega = \{(1,1), (1,2), \dots, (6,6)\}.
   $$

2. Tempo di reazione a uno stimolo visivo:
   $$\Omega = \mathbb{R}^+,$$
   ovvero l‚Äôinsieme dei numeri reali positivi.

3. Numero di errori in un test di memoria a breve termine:
   $$\Omega = \{0, 1, 2, \dots\}.$$

4. Misurazione delle altezze di dieci persone:
   $$\Omega = \{(x_1, \dots, x_{10}) : x_i \ge 0, \; i=1,\dots,10\} \subset \mathbb{R}^{10}.$$

## Eventi

Solitamente non siamo interessati a un singolo esito, ma a un insieme di essi. Un **evento** √® un sottoinsieme dello spazio campionario a cui possiamo assegnare una probabilit√†.

::: {#def-}
Un *evento* √® un sottoinsieme $A \subseteq \Omega$ al quale viene assegnata una probabilit√†. Indichiamo gli eventi con lettere maiuscole $A, B, C, \dots$. Diciamo che l‚Äôevento $A$ si verifica se l‚Äôesito dell‚Äôesperimento appartiene a $A$.
:::

### Esempi di Eventi

Consideriamo alcuni possibili eventi definiti sugli spazi campionari descritti sopra.

1. Lancio di due dadi consecutivi.  
   *Evento:* "La somma dei due dadi √® uguale a 7"  
   $$
   A = \{(1,6), (2,5), (3,4), (4,3), (5,2), (6,1)\}.
   $$

2. Tempo di reazione a uno stimolo visivo.  
   *Evento:* "Il tempo di reazione √® inferiore a 2 secondi"  
   $$
   A = [0, 2).
   $$

3. Numero di errori in un test di memoria a breve termine.  
   *Evento:* "Il numero di errori √® al massimo 3"  
   $$
   A = \{0, 1, 2, 3\}.
   $$

4. Misurazione delle altezze di dieci persone.  
   *Evento:* "Almeno due persone hanno un‚Äôaltezza superiore a 180 cm"  
   $$
   A = \{(x_1, \dots, x_{10}) : \text{almeno due } x_i > 180\}.
   $$

Questi esempi mostrano come gli eventi possano essere definiti in modo diverso a seconda della natura dello spazio campionario e del contesto di interesse.

::: {#exm-}
Supponiamo di lanciare una moneta tre volte e di annotare se esce Testa ($H$) o Croce ($T$) in ogni lancio. Lo spazio campionario √®:

$$
\Omega = \{HHH, HHT, HTH, HTT, THH, THT, TTH, TTT\},
$$

dove, ad esempio, $HTH$ indica che il primo lancio d√† Testa, il secondo Croce e il terzo Testa.

Un‚Äôalternativa √® rappresentare lo spazio campionario come l‚Äôinsieme dei vettori binari di lunghezza 3, $\{0,1\}^3$, dove Testa ($H$) corrisponde a 1 e Croce ($T$) a 0.

L‚Äôevento $A$ "il terzo lancio √® Testa" si esprime come:

$$
A = \{HHH, HTH, THH, TTH\}.
$$
:::

## Operazioni sugli Eventi

Poich√© gli eventi sono definiti come insiemi, possiamo applicare loro le classiche operazioni insiemistiche.

**Unione** ($\cup$). 
L'unione di due eventi $A$ e $B$ √® l'insieme di tutti gli esiti che appartengono almeno a uno dei due:

$$
A \cup B = \{\omega \in \Omega : \omega \in A \text{ oppure } \omega \in B\}.
$$

**Intersezione** ($\cap$).
L'intersezione di due eventi √® l'insieme degli esiti comuni:

$$
A \cap B = \{\omega \in \Omega : \omega \in A \text{ e } \omega \in B\}.
$$

**Complemento** ($A^c$). 
Il complemento di un evento $A$ √® l'insieme di tutti gli esiti che non appartengono ad $A$:

$$
A^c = \{\omega \in \Omega : \omega \notin A\}.
$$

**Eventi mutuamente esclusivi.**
Due eventi sono **mutuamente esclusivi** se non hanno esiti in comune, ovvero:

$$
A \cap B = \emptyset.
$$

::: {#exm-}

```{r}
# Universo
U <- 1:10  

# Definizione degli insiemi A e B
A <- c(1, 2, 3, 4, 5)
B <- c(4, 5, 6, 7, 8)

# Calcolare l'unione, l'intersezione e il complemento relativo a un universo U
union_AB <- union(A, B)
intersect_AB <- intersect(A, B)
complement_A <- setdiff(U, A)
complement_B <- setdiff(U, B)

# Visualizzazione testuale
cat("Unione A ‚à™ B:", union_AB, "\n")
cat("Intersezione A ‚à© B:", intersect_AB, "\n")
cat("Complemento di A:", complement_A, "\n")
cat("Complemento di B:", complement_B, "\n")
```

```{r}
# Visualizzazione con diagrammi di Venn
venn.plot <- draw.pairwise.venn(
  area1 = length(A),
  area2 = length(B),
  cross.area = length(intersect_AB),
  category = c("A", "B"),
  fill = c("blue", "red"),
  alpha = 0.5,
  cat.col = c("blue", "red")
)
grid.draw(venn.plot)
```

```{r}
# Esempio di eventi mutualmente esclusivi
C <- c(9, 10)  # Insieme disgiunto da A e B
intersect_AC <- intersect(A, C)  # Deve essere vuoto

cat("Intersezione A ‚à© C (eventi mutualmente esclusivi):", intersect_AC, "\n")
```

```{r}
# Visualizzazione di eventi mutualmente esclusivi
venn.plot2 <- draw.pairwise.venn(
  area1 = length(A),
  area2 = length(C),
  cross.area = 0,  # Nessuna intersezione
  category = c("A", "C"),
  fill = c("blue", "green"),
  alpha = 0.5,
  cat.col = c("blue", "green")
)
grid.draw(venn.plot2)
```
:::

### Propriet√† Fondamentali delle Operazioni su Eventi

- **Idempotenza:**
  $$
  A \cup A = A, \quad A \cap A = A.
  $$

- **Leggi di De Morgan:**
  $$
  (A \cup B)^c = A^c \cap B^c, \quad (A \cap B)^c = A^c \cup B^c.
  $$

- **Unione e Intersezione con l‚Äôinsieme vuoto:**
  $$
  A \cup \emptyset = A, \quad A \cap \emptyset = \emptyset.
  $$

- **Unione e Intersezione con lo spazio campionario:**
  $$
  A \cup \Omega = \Omega, \quad A \cap \Omega = A.
  $$

Queste operazioni forniscono la base per costruire e manipolare eventi in contesti probabilistici, permettendo di calcolare probabilit√† e prendere decisioni basate sull‚Äôanalisi degli esiti possibili.

::: {#exm-}
Per gli insiemi definiti nell'esempio precedente, possiamo verificare la prima legge di De Morgan in R confrontando il complemento dell'unione con l'intersezione dei complementi:

- complemento dell'unione: $(A \cup B)^c$,
- intersezione dei complementi: $A^c \cap B^c$.

Eseguiamo i calcoli in R:

```{r}
# Complemento dell'unione: (A ‚à™ B)^c
setdiff(U, union(A, B))
```

```{r}
# Intersezione dei complementi: A^c ‚à© B^c
intersect(setdiff(U, A), setdiff(U, B))
```

Secondo la legge di De Morgan, i due risultati devono coincidere.
:::


::: {#exm-}
Consideriamo l'esperimento del lancio di due dadi. Lo spazio campionario $\Omega$ √® costituito da tutte le possibili coppie di risultati che possono verificarsi. Ogni dado ha 6 facce, quindi lo spazio campionario √®:

$$
\Omega = \{(1,1), (1,2), \dots, (6,6)\},
$$

per un totale di $6 \times 6 = 36$ esiti possibili.

Siamo interessati all'evento $A$: "la somma dei due dadi √® almeno 10". Questo evento include tutte le coppie di risultati la cui somma √® 10, 11 o 12. Gli esiti che soddisfano questa condizione sono:

$$
A = \{(4,6), (5,5), (5,6), (6,4), (6,5), (6,6)\}.
$$

Ecco come generare lo spazio campionario in R in modo algoritmico e definire l'evento "la somma dei due dadi √® almeno 10":

Lo spazio campionario $\Omega$ √® costituito da tutte le possibili coppie di risultati del lancio di due dadi. In R, possiamo generarlo utilizzando la funzione `expand.grid`, che crea tutte le combinazioni possibili tra i valori dei due dadi.

```{r}
# Generazione dello spazio campionario Omega
dado <- 1:6 # Facce di un dado
Omega <- expand.grid(Dado1 = dado, Dado2 = dado) # Tutte le combinazioni possibili
```

L'output sar√† una tabella con 36 righe, una per ogni combinazione possibile:

```{r}
# Visualizzazione dello spazio campionario
print(Omega)
```

L'evento $A$ √® definito come "la somma dei due dadi √® almeno 10". Per identificare queste combinazioni, aggiungiamo una colonna che calcola la somma dei due dadi e filtriamo le righe in cui la somma √® maggiore o uguale a 10.

```{r}
# Aggiunta di una colonna per la somma dei due dadi
Omega$Somma <- Omega$Dado1 + Omega$Dado2

# Definizione dell'evento A: somma dei due dadi almeno 10
A <- Omega[Omega$Somma >= 10, ]
```

L'output sar√† un data frame con le combinazioni in cui la somma √® almeno 10:

```{r}
# Visualizzazione dell'evento A
print(A)
```

In sintesi, 

- lo spazio campionario $\Omega$ √® stato generato algoritmicamente utilizzando `expand.grid`;
- l'evento $A$ √® stato definito filtrando le combinazioni in cui la somma dei due dadi √® almeno 10.
:::

::: {#exm-}
Consideriamo un esperimento in cui lanciamo una moneta tre volte consecutivamente. Ogni lancio pu√≤ risultare in **Testa (H)** o **Croce (T)**. Lo spazio campionario $\Omega$ √® costituito da tutte le possibili sequenze di risultati dei tre lanci. Ci sono $2^3 = 8$ possibili esiti, che possono essere rappresentati come:

$$
\Omega = \{\text{HHH}, \text{HHT}, \text{HTH}, \text{HTT}, \text{THH}, \text{THT}, \text{TTH}, \text{TTT}\}.
$$

Vogliamo definire in R l'evento $A$: "Il terzo lancio della moneta dia Testa (H)". Questo evento include tutte le sequenze in cui il terzo carattere √® "H".

In R, possiamo rappresentare lo spazio campionario $\Omega$ come un vettore di stringhe, dove ogni stringa corrisponde a una sequenza di risultati.

```{r}
# Definizione dello spazio campionario Omega
omega <- c("HHH", "HHT", "HTH", "HTT", "THH", "THT", "TTH", "TTT")
omega
```

L'evento $A$ √® costituito da tutte le sequenze in cui il **terzo lancio √® Testa (H)**. Per identificare queste sequenze, utilizziamo la funzione `substr`, che estrae il terzo carattere da ciascuna stringa e verifica se √® uguale a "H".

```{r}
# Definizione dell'evento A: terzo lancio √® Testa (H)
A <- omega[substr(omega, 3, 3) == "H"]
```

Spiegazione del codice:

- `substr(omega, 3, 3)` estrae il terzo carattere da ciascuna stringa nel vettore `omega`.
- `substr(omega, 3, 3) == "H"` crea un vettore logico (vero/falso) che indica se il terzo carattere √® "H".
- `omega[...]` filtra il vettore `omega`, mantenendo solo le sequenze che soddisfano la condizione.

L'output sar√†:

```{r}
# Visualizzazione dell'evento A
A
```

Queste sono le sequenze in cui il terzo lancio √® Testa (H).

In sintesi, 

- lo spazio campionario $\Omega$ √® stato definito come un vettore di stringhe in R;
- l'evento $A$ √® stato costruito filtrando le sequenze in cui il terzo carattere √® "H", utilizzando la funzione `substr(x, start, stop)`;
- l'evento $A$ corrisponde alle sequenze: **HHH**, **HTH**, **THH**, **TTH**.

Questo esercizio illustra come definire e manipolare eventi in R, utilizzando operazioni di base su stringhe e vettori.
:::

::: {#exm-}
Consideriamo l‚Äôesperimento del lancio consecutivo di due dadi. Lo spazio campionario $\Omega$ √® costituito da tutte le possibili coppie di risultati:

$$
\Omega = \{(1, 1), (1, 2), \dots, (6, 6)\}.
$$

Definiamo due eventi:

1. **Evento $A$**: "Il primo dado mostra un 6".  
   Questo evento include tutte le coppie in cui il primo dado √® 6:  
   $$
   A = \{(6, 1), (6, 2), (6, 3), (6, 4), (6, 5), (6, 6)\}.
   $$

2. **Evento $B$**: "Il secondo dado mostra un 6".  
   Questo evento include tutte le coppie in cui il secondo dado √® 6:  
   $$
   B = \{(1, 6), (2, 6), (3, 6), (4, 6), (5, 6), (6, 6)\}.
   $$

L‚Äô**intersezione $A \cap B$** rappresenta l‚Äôevento in cui **entrambi i dadi mostrano un 6**:

$$
A \cap B = \{(6, 6)\}.
$$

**Implementazione in R**

Per analizzare gli eventi legati al lancio di due dadi, utilizziamo R per simulare lo spazio campionario e manipolare gli eventi.

**1. Generazione dello spazio campionario**  
La funzione `expand.grid` crea tutte le combinazioni possibili tra gli elementi di due vettori. Nel nostro caso, generiamo tutte le coppie (Dado1, Dado2):

```{r}
# Definizione delle facce dei dadi (1-6)
dado <- 1:6

# Creazione di tutte le 36 combinazioni possibili
Omega <- expand.grid(
  Dado1 = dado,
  Dado2 = dado
)

# Visualizzazione delle prime 6 righe
head(Omega)
```

**2. Definizione degli eventi**  

**Evento A** - "Primo dado = 6":  
Filtriamo le righe dove la colonna `Dado1` √® uguale a 6:

```{r}
A <- Omega[Omega$Dado1 == 6, ] # Selezione condizionale
print("Evento A:")
A
```

**Evento B** - "Secondo dado = 6":  
Filtriamo le righe dove la colonna `Dado2` √® uguale a 6:

```{r}
B <- Omega[Omega$Dado2 == 6, ]
print("Evento B:")
B
```

**3. Calcolo dell'intersezione A ‚à© B**  

**Metodo 1: Funzione `intersect()`**  
La funzione base `intersect()` confronta intere righe tra due dataframe e restituisce quelle comuni:

```{r}
A_intersezione_B <- intersect(A, B)
print("Intersezione con intersect():")
A_intersezione_B
```

**Metodo 2: Funzione `merge()`**  
La funzione base `merge()` esegue una join naturale sulle colonne con lo stesso nome:

```{r}
A_intersezione_B <- merge(A, B)
print("Intersezione con merge():")
A_intersezione_B
```

**Metodo 3: Pacchetto `dplyr`**  
La funzione `inner_join()` mantiene solo le righe presenti in entrambi i dataframe:

```{r}
A_intersezione_B <- inner_join(A, B, by = c("Dado1", "Dado2"))
print("Intersezione con dplyr:")
A_intersezione_B
```

In sintesi,

- lo spazio campionario $\Omega$ √® stato generato algoritmicamente in R;
- gli eventi $A$ e $B$ sono stati definiti filtrando lo spazio campionario;
- l'intersezione $A \cap B$ corrisponde all'evento in cui entrambi i dadi mostrano un 6: $\{(6, 6)\}.$
:::


## Probabilit√† {#sec-probabilita}

Il terzo elemento fondamentale del modello probabilistico √® la **funzione di probabilit√†**, che quantifica numericamente la possibilit√† di occorrenza degli eventi.

::: {.definition title="Funzione di Probabilit√† (Kolmogorov)" #def-probabilita}
Una *probabilit√†* $P$ √® una funzione $P: \mathcal{F} \to [0,1]$ definita su una $\sigma$-algebra $\mathcal{F}$ di sottoinsiemi di $\Omega$. A ogni evento $A \in \mathcal{F}$, la funzione assegna un valore reale compreso tra 0 e 1, rispettando i seguenti **assiomi di Kolmogorov**:

1. **Non-negativit√†**  
   Per ogni $A \subseteq \Omega$, si richiede che $0 \leq P(A) \leq 1$.

2. **Normalizzazione (evento certo)**  
   $P(\Omega) = 1$.

3. **Additivit√† numerabile**  
   Se $A_1, A_2, \dots$ sono eventi mutuamente esclusivi (cio√® $A_i \cap A_j = \emptyset$ per $i \neq j$), allora:
   $$
   P\!\Bigl(\bigcup_{i=1}^{\infty} A_i\Bigr) \;=\; \sum_{i=1}^{\infty} P(A_i).
   $$

In altre parole, una misura di probabilit√† non solo assegna numeri nell‚Äôintervallo $[0,1]$ a ogni evento, ma richiede che l‚Äôevento ‚Äúcerto‚Äù $\Omega$ abbia probabilit√† 1 e che la probabilit√† di un‚Äôunione numerabile di eventi disgiunti sia la somma delle loro probabilit√†. Queste condizioni garantiscono la coerenza formale e l‚Äôinterpretazione intuitiva del concetto di probabilit√†.
:::

### Interpretazione degli Assiomi di Kolmogorov

1. **Assioma 1 (Non-negativit√† e limiti 0‚Äì1)**  
   La probabilit√† di un evento √® sempre un numero reale compreso tra 0 e 1. Se la probabilit√† √® 0, l‚Äôevento pu√≤ considerarsi *impossibile*; se √® 1, l‚Äôevento √® *certo*.  
   **Esempio**: Nel lancio di un dado a sei facce, l‚Äôevento *‚ÄúEsce 7‚Äù* non pu√≤ verificarsi e ha probabilit√† 0, mentre l‚Äôevento *‚ÄúEsce un numero tra 1 e 6‚Äù* ha probabilit√† 1.

2. **Assioma 2 (Evento certo)**  
   Lo *spazio campionario* $\Omega$ √® l‚Äôinsieme di tutti i possibili esiti dell‚Äôesperimento. Poich√© in ogni prova deve accadere almeno uno degli esiti contenuti in $\Omega$, la probabilit√† di $\Omega$ √® necessariamente 1.  
   **Esempio**: Nel lancio di un dado, lo spazio campionario $\Omega$ √® $\{1,2,3,4,5,6\}$. L‚Äôevento ‚Äúesce un numero tra 1 e 6‚Äù coincide con l‚Äôintero spazio campionario, quindi $P(\Omega) = 1$.

3. **Assioma 3 (Additivit√† per eventi incompatibili)**  
   Se due o pi√π eventi sono mutuamente esclusivi (o incompatibili) ‚Äî cio√® non possono verificarsi contemporaneamente ‚Äî la probabilit√† della loro unione √® la somma delle probabilit√† di ciascuno.  
   **Esempio**: Con un dado, l‚Äôevento *‚Äúesce un numero pari‚Äù* e l‚Äôevento *‚Äúesce un numero dispari‚Äù* non possono verificarsi nello stesso lancio. Di conseguenza,  
   $$
   P(\text{‚Äúpari‚Äù} \cup \text{‚Äúdispari‚Äù}) \;=\; P(\text{‚Äúpari‚Äù}) + P(\text{‚Äúdispari‚Äù})\,.
   $$

Questi assiomi assicurano che la probabilit√†, intesa come funzione che assegna valori tra 0 e 1 a ogni evento, rispetti la coerenza matematica e l‚Äôinterpretazione intuitiva: non esistono eventi ‚Äúnegativi‚Äù o ‚Äúpi√π che certi‚Äù, e la probabilit√† totale dell‚Äôintero spazio dei possibili risultati deve sempre essere uguale a 1.

### Propriet√† Fondamentali {#subsec-proprieta}

Dagli assiomi di Kolmogorov discendono alcune propriet√† fondamentali che descrivono come la probabilit√† si comporti in varie situazioni. Le principali sono elencate di seguito.

::: {.theorem #thm-proprieta-probabilita}
Siano $A$ e $B$ eventi qualsiasi nello spazio campionario $\Omega$. Allora valgono le seguenti relazioni:

1. **Probabilit√† dell‚Äôevento impossibile**  
   $$
   P(\emptyset) = 0.
   $$
   Poich√© l‚Äôinsieme vuoto non include alcun esito sperimentale, non pu√≤ mai verificarsi.

2. **Monotonicit√†**  
   $$
   A \subseteq B \quad \Longrightarrow \quad P(A) \le P(B).
   $$
   Se un evento √® interamente contenuto in un altro, non pu√≤ avere probabilit√† maggiore dell‚Äôevento che lo comprende.

3. **Probabilit√† del complementare**  
   $$
   P(A^c) = 1 - P(A).
   $$
   Poich√© $A$ e il suo complementare $A^c$ coprono l‚Äôintero spazio $\Omega$, la probabilit√† di $A^c$ √® la parte ‚Äúrimanente‚Äù fino a 1.

4. **Regola dell‚Äôinclusione‚Äìesclusione**  
   $$
   P(A \cup B) \;=\; P(A) + P(B) \;-\; P(A \cap B).
   $$
   Per calcolare la probabilit√† dell‚Äôunione di due eventi qualsiasi, si sommano le probabilit√† di ciascun evento e si sottrae la probabilit√† della loro intersezione (altrimenti verrebbe conteggiata due volte).
:::

## Spazi Discreti vs. Continui {#case-discreto-continuo}

La natura dello spazio campionario determina come definiamo e calcoliamo le probabilit√†. Distinguiamo i due casi fondamentali: lo spazio campionario **discreto** 

$$
\Omega = \{a_1, a_2, \dots, a_n\} \quad \text{oppure} \quad \Omega = \{a_1, a_2, \dots\}
$$

e lo spazio campionario **continuo**

$$
\Omega = \mathbb{R} .
$$

### Spazi Campionari Discreti

**Caratteristiche**:  

- Gli esiti sono **numerabili** (finiti o infiniti ma separabili).  
- Esempi:  
  - Lancio di un dado: $\Omega = \{1, 2, 3, 4, 5, 6\}$.  
  - Numero di clienti in un negozio in un'ora: $\Omega = \{0, 1, 2, \dots\}$.  

**Definizione di Probabilit√†**:  

- Assegniamo una **probabilit√† puntuale** $p_i \geq 0$ a ogni esito $\omega_i$, con: 

  $$
  \sum_{\text{tutti gli } i} p_i = 1 \quad \text{(normalizzazione)}.
  $$  
  
- La probabilit√† di un evento $A$ si ottiene **sommando** le probabilit√† degli esiti in $A$:  

  $$
  P(A) = \sum_{\omega_i \in A} p_i.
  $$  

::: {#exm-}  
**Lancio di un dado equilibrato.**

- La probabilit√† di ciascuna faccia √® uniforme: $p_i = \frac{1}{6}$, con $i = 1, 2, \dots, 6$.
- Consideriamo l‚Äôevento $A = \text{‚ÄúEsce un numero pari"}$.  
- Pertanto, calcoliamo la probabilit√† di $A$:

$$
P(A) = p_2 + p_4 + p_6 = \frac{1}{6} + \frac{1}{6} + \frac{1}{6} = \frac{3}{6} = \frac{1}{2}.
$$

L‚Äôevento $A$ ha dunque probabilit√† $\frac{1}{2}$.
:::

### Spazi Campionari Continui

**Caratteristiche**:  

- Gli esiti sono **non numerabili** (infiniti e "densi").  
- Esempi:  
  - tempo di attesa all‚Äôautobus: $\Omega = [0, \infty)$;  
  - altezza di una persona: $\Omega = [50\, \text{cm}, 250\, \text{cm}]$.  

**Definizione di Probabilit√†**:  

- Usiamo una **funzione di densit√† di probabilit√† (PDF)** $f(x) \geq 0$, con:  
  $$
  \int_{-\infty}^{\infty} f(x)\, dx = 1 \quad \text{(normalizzazione)}.
  $$  
- La probabilit√† di un evento $A$ si ottiene **integrando** la PDF su $A$:  
  $$
  P(A) = \int_{A} f(x)\, dx.
  $$  

::: {#exm-}  
**Misurazione dell‚Äôaltezza** degli uomini adulti, modellata come variabile aleatoria continua $X$ (in cm) con distribuzione normale $\mathcal{N}(170, 7^2)$ (si veda la Sezione [@sec-prob-cont-prob-distr]):

La **funzione di densit√†** (PDF) corrispondente √®:

$$
f(x) 
= \frac{1}{7\sqrt{2\pi}} \exp\!\Bigl(-\frac{(x - 170)^2}{2 \cdot 7^2}\Bigr),
\quad
X \sim \mathcal{N}(170,\, 7^2).
$$

**Evento di interesse:**  
$$
A = \text{‚ÄúAltezza compresa tra 160 cm e 180 cm‚Äù}.
$$

**Calcolo della probabilit√†:**  
La probabilit√† di $A$ √® l‚Äôarea sotto la curva della densit√† tra 160 cm e 180 cm:

$$
P(A) \;=\; \int_{160}^{180} \frac{1}{7\sqrt{2\pi}}
\exp\!\Bigl(-\frac{(x - 170)^2}{98}\Bigr)\,\mathrm{d}x.
$$

In alternativa, si pu√≤ scrivere:

$$
P(160 \leq X \leq 180) \;\approx\; 0.847 \quad (84.7\%).
$$

Pi√π avanti vedremo come calcolare facilmente questa probabilit√† tramite **R**, ad esempio con il comando:

```{r}
pnorm(180, 170, 7) - pnorm(160, 170, 7)
```

Questo codice restituisce la differenza tra le funzioni di ripartizione (CDF) a 180 e a 160, corrispondente proprio all‚Äôarea desiderata sotto la PDF.
:::

### Confronto Chiave

| Caratteristica               | Spazio Discreto                     | Spazio Continuo                     |  
|-------------------------------|--------------------------------------|--------------------------------------|  
| **Esiti**                     | Numerabili (es: 1, 2, 3)            | Non numerabili (es: intervalli)     |  
| **Probabilit√† di un singolo punto** | $P(\{\omega_i\}) = p_i$ ($\geq$ 0)       | $P(\{x\}) = 0$ (sempre zero)        |  
| **Strumento matematico**      | Somma $\sum$                         | Integrale $\int$                     |  
| **Esempi comuni**             | Dadi, monete, conteggi              | Misure fisiche, tempi, temperature  |  

::: {.callout-warning}
## Propriet√† della PDF

- Negli spazi continui, la PDF **non √® una probabilit√†** (pu√≤ essere > 1), ma la sua area sottesa su un intervallo fornisce la probabilit√†.  
- Per eventi continui, ha senso solo calcolare probabilit√† su **intervalli** (es: $P(160 \leq X \leq 180)$).  
:::

## Dai Concetti Base alle Propriet√† Fondamentali della Probabilit√†

Abbiamo visto come un esperimento casuale possa essere formalizzato matematicamente attraverso tre elementi chiave:

- **Spazio campionario** ($\Omega$): l'insieme di tutti i possibili esiti dell'esperimento.
- **Eventi**: sottoinsiemi di $\Omega$ che rappresentano combinazioni di esiti di interesse.
- **Probabilit√†**: una funzione $P$ che assegna a ogni evento un valore numerico compreso tra 0 e 1, misurandone il grado di verosimiglianza.

Partendo da queste definizioni, √® possibile derivare propriet√† essenziali per il calcolo e l'analisi probabilistica. Queste propriet√† consentono di determinare la probabilit√† di eventi complessi a partire da eventi elementari e di stabilire relazioni logiche tra di essi.

In questo corso, approfondiremo quattro teoremi fondamentali:

1. teorema della somma;
2. teorema del prodotto;
3. teorema della probabilit√† totale; 
4. teorema di Bayes.

L‚Äôintroduzione di operazioni sugli eventi (unione, intersezione, complemento) e delle propriet√† della probabilit√† (teorema della somma, probabilit√† condizionata, teorema della probabilit√† totale, ...) ci consente di costruire modelli probabilistici pi√π complessi e applicabili a problemi reali.  

Qui di seguito, approfondiamo il teorema della somma.

## Teorema della Somma

Il teorema della somma (o **regola additiva**) permette di determinare la probabilit√† che si verifichi **almeno uno** tra due eventi $A$ e $B$. La sua formulazione dipende dalla relazione tra i due eventi:

**Caso 1: Eventi Mutuamente Esclusivi.** 
Se $A$ e $B$ **non possono verificarsi insieme** (ossia $A \cap B = \emptyset$), la probabilit√† dell'unione √® la somma delle singole probabilit√†: 

$$
P(A \cup B) = P(A) + P(B).
$$ {#eq-theorem-sum-disjoint}

**Caso 2: Eventi Non Esclusivi.**
Se $A$ e $B$ **possono coesistere**, √® necessario evitare di contare due volte la loro intersezione: 

$$
P(A \cup B) = P(A) + P(B) - P(A \cap B).
$$ {#eq-theorem-sum-not-disjoint}

**Perch√© questa differenza?**  
La probabilit√† √® una funzione d'insieme coerente con le operazioni insiemistiche. L'addizione diretta $P(A) + P(B)$ conteggia due volte gli esiti comuni a $A$ e $B$ (rappresentati da $A \cap B$). La sottrazione di $P(A \cap B)$ garantisce che ogni esito sia considerato una sola volta.

Il teorema della somma sottolinea come le operazioni logiche tra eventi (unione, intersezione) si riflettano in relazioni algebriche tra le loro probabilit√†, fornendo uno strumento operativo per modellare scenari reali.

::: {#exm-}
In uno studio sulla salute mentale, supponiamo di avere i seguenti dati relativi a un campione di partecipanti:  

- la probabilit√† che un individuo soffra di **ansia** √® $P(A) = 0.30$;  
- la probabilit√† che un individuo soffra di **depressione** √® $P(B) = 0.25$; 
- la probabilit√† che un individuo soffra **contemporaneamente** di ansia e depressione √® $P(A \cap B) = 0.15$.  

Vogliamo calcolare la probabilit√† che un individuo soffra di **almeno uno** dei due disturbi (ansia o depressione), ovvero $P(A \cup B)$.  

Utilizziamo la **regola della somma per eventi non mutuamente esclusivi**:  

$$
P(A \cup B) = P(A) + P(B) - P(A \cap B)
$$

Svolgiamo questo calcolo in R:

```{r}
# Definiamo le probabilit√†
P_A <- 0.30 # Probabilit√† di soffrire di ansia
P_B <- 0.25 # Probabilit√† di soffrire di depressione
P_A_intersect_B <- 0.15 # Probabilit√† di soffrire di entrambi i disturbi

# Applichiamo la formula della regola della somma
P_A_union_B <- P_A + P_B - P_A_intersect_B
P_A_union_B
```

**Interpretazione:**
il **40%** dei partecipanti soffre di almeno uno tra ansia e depressione. L‚Äôintersezione $P(A \cap B) = 0.15$ √® fondamentale, poich√© senza sottrarla avremmo contato due volte i soggetti che soffrono contemporaneamente di entrambi i disturbi.
:::

## Probabilit√†, Calcolo Combinatorio e Simulazioni

In molti problemi di probabilit√†, soprattutto quelli di taglio scolastico o introduttivo, si assume che ogni *evento elementare* abbia la **stessa probabilit√†** di verificarsi (*equiprobabilit√†*). In queste situazioni, il **calcolo combinatorio** risulta particolarmente utile per determinare la probabilit√† di un evento, poich√© basta:

1. **Definire gli eventi di successo**: identificare tutte le configurazioni compatibili con l‚Äôevento di interesse.  
2. **Contare le possibilit√†**: calcolare il numero di eventi di successo e rapportarlo al numero totale di eventi nello spazio campionario.

::: {.example #exm-}
**Estrazione di una pallina da un‚Äôurna**

Supponiamo di avere un‚Äôurna con 10 palline numerate da 1 a 10, da cui estraiamo una sola pallina in modo casuale. Assumendo che ogni pallina abbia la stessa probabilit√† di essere estratta, calcoliamo la probabilit√† di estrarre un numero pari.

- **Eventi di successo**: $\{\;2, 4, 6, 8, 10\}$ (5 casi)  
- **Eventi totali**: $\{\;1, 2, 3, 4, 5, 6, 7, 8, 9, 10\}$ (10 casi)

La probabilit√† cercata √® quindi:

$$
P(\text{numero pari}) \;=\; \frac{\text{numero di eventi di successo}}{\text{numero totale di eventi}}
\;=\; \frac{5}{10} \;=\; 0.5.
$$
:::

Nelle applicazioni pi√π complesse, come il calcolo della probabilit√† di ottenere una determinata combinazione di carte o il formare gruppi specifici partendo da una popolazione, utilizzeremo tecniche combinatorie pi√π avanzate ‚Äî ad esempio permutazioni e combinazioni (si veda la Sezione [@sec-apx-combinatorics]) ‚Äî che consentono di contare in modo sistematico gli eventi possibili e quelli di successo.

### Simulazioni Monte Carlo

Uno degli aspetti pi√π impegnativi della probabilit√† √® che molti problemi non si prestano a soluzioni immediate o intuitive. Per affrontarli, si possono adottare due approcci principali. Il primo consiste nell'applicare i teoremi della teoria della probabilit√†, un metodo rigoroso ma spesso controintuitivo. Il secondo approccio √® quello della simulazione Monte Carlo, che permette di ottenere una soluzione approssimata, ma molto vicina al valore reale, seguendo una procedura pi√π accessibile e intuitiva. Questo metodo prende il nome dal famoso Casin√≤ di Monte Carlo a Monaco, anche se pu√≤ essere semplicemente definito come "metodo di simulazione."

La simulazione Monte Carlo appartiene a una classe generale di metodi stocastici che si contrappongono ai metodi deterministici. Questi metodi consentono di risolvere approssimativamente problemi analitici attraverso la generazione casuale delle quantit√† di interesse. Tra le tecniche comunemente utilizzate troviamo il **campionamento con reinserimento**, in cui la stessa unit√† pu√≤ essere selezionata pi√π volte, e il **campionamento senza reinserimento**, dove ogni unit√† pu√≤ essere selezionata una sola volta. Questi strumenti rappresentano un mezzo potente e pratico per affrontare problemi complessi.

### Il Problema dei Complenni 

Un esempio classico di applicazione del metodo Monte Carlo √® il calcolo delle probabilit√† relative a vari eventi definiti attraverso il modello dell'urna. Tra questi, abbiamo il celebre **problema dei compleanni**. 

Il **problema dei compleanni** esplora la probabilit√† che, in un gruppo di $n$ persone, almeno due persone condividano la stessa data di nascita. Supponendo che i compleanni siano distribuiti uniformemente su 365 giorni (ignorando anni bisestili), il problema sorprende molte persone per il fatto che gi√† con 23 persone la probabilit√† di una coincidenza √® superiore al 50%.

#### Soluzione analitica

Questo problema pu√≤ essere risolto utilizzando il concetto di **probabilit√† complementari**. Infatti, il problema pu√≤ essere visto da due prospettive complementari:

- **Caso 1**: tutti i compleanni sono **diversi** (nessuna persona condivide il compleanno con un'altra);
- **Caso 2**: **almeno due persone** condividono lo stesso compleanno.

Questi due casi sono **mutuamente esclusivi** (non possono verificarsi contemporaneamente) ed **esaustivi** (coprono tutte le possibilit√†). Pertanto, la somma delle loro probabilit√† deve essere uguale a 1:

$$
P(\text{almeno un compleanno in comune}) = 1 - P(\text{nessun compleanno in comune}).
$$

In altre parole, per calcolare la probabilit√† che **almeno due persone abbiano lo stesso compleanno**, possiamo prima calcolare la probabilit√† che **tutti i compleanni siano diversi** e poi sottrarre questo valore da 1.

**Caso 1: probabilit√† che tutti i compleanni siano diversi.**

Per calcolare $P(\text{nessun compleanno in comune})$, seguiamo questo ragionamento:

- **Prima persona**: Pu√≤ scegliere liberamente un giorno del calendario. Ci sono **365 possibilit√†** (ignoriamo gli anni bisestili per semplicit√†).
  
- **Seconda persona**: Deve avere un compleanno diverso dalla prima persona. Quindi, ci sono **364 giorni disponibili**.

- **Terza persona**: Deve avere un compleanno diverso dai primi due. Ci sono **363 giorni disponibili**.

Questo processo continua fino alla $n$-esima persona, che avr√† $365 - n + 1$ giorni disponibili.

La probabilit√† che **tutti i compleanni siano diversi** si ottiene moltiplicando le probabilit√† individuali di ogni persona di avere un compleanno diverso dai precedenti. Poich√© ogni scelta √® indipendente, possiamo scrivere:

$$
P(\text{nessun compleanno in comune}) = \frac{365}{365} \cdot \frac{364}{365} \cdot \frac{363}{365} \cdot \ldots \cdot \frac{365-n+1}{365}.
$$

Questo prodotto pu√≤ essere espresso in forma compatta utilizzando il fattoriale:

$$
P(\text{nessun compleanno in comune}) = \frac{365!}{(365-n)! \cdot 365^n} ,
$$

dove:

- $365!$ √® il fattoriale di 365 (il prodotto di tutti i numeri interi da 1 a 365).
- $(365-n)!$ √® il fattoriale di $365 - n$.
- $365^n$ rappresenta tutte le possibili combinazioni di compleanni per $n$ persone.

**Caso 2. Probabilit√† di almeno un compleanno in comune.**

Ora che abbiamo calcolato la probabilit√† che tutti i compleanni siano diversi, possiamo trovare la probabilit√† che **almeno due persone abbiano lo stesso compleanno** come il complemento:

$$
P(\text{almeno un compleanno in comune}) = 1 - P(\text{nessun compleanno in comune}).
$$

Sostituendo l'espressione precedente, otteniamo:

$$
P(\text{almeno un compleanno in comune}) = 1 - \frac{365!}{(365-n)! \cdot 365^n}.
$$

Ora che abbiamo le formule per i due eventi complementari, come funzione di $n$, applichiamole al caso specifico in cui $n$ = 23. Questo √® un valore interessante perch√©, come vedremo, la probabilit√† che almeno due persone su 23 condividano lo stesso compleanno supera il 50%.

La formula per la probabilit√† che tutti i compleanni siano diversi √®:

$$
P(\text{nessun compleanno in comune}) = \frac{365!}{(365-n)! \cdot 365^n}.
$$

Per $n = 23$, sostituiamo il valore nella formula:

$$
P(\text{nessun compleanno in comune}) = \frac{365!}{(365-23)! \cdot 365^{23}}.
$$

Semplifichiamo:

$$
P(\text{nessun compleanno in comune}) = \frac{365!}{342! \cdot 365^{23}}.
$$

Utilizzando R, troviamo:

```{r}
# Numero di persone
n <- 23

# Calcolo della probabilit√† che tutti abbiano compleanni diversi
numeratore <- prod(365:(365 - n + 1))
denominatore <- 365^n

P_diversi <- numeratore / denominatore
P_diversi  # stampa la probabilit√†
```

$$
P(\text{nessun compleanno in comune}) \approx 0{,}4927.
$$

Ci√≤ implica che la probabilit√† che **23 persone** abbiano **compleanni distinti** sia approssimativamente **0.4927** (pari al **49.27%**).  

La probabilit√† che **almeno due persone** (su 23) condividano lo stesso compleanno corrisponde al complemento della probabilit√† appena calcolata:  

$$
P(\text{almeno un compleanno in comune}) = 1 - P(\text{nessun compleanno in comune}).
$$  

Sostituendo il valore ottenuto:  

$$
P(\text{almeno un compleanno in comune}) = 1 - 0{.}4927 = 0{.}5073.
$$  

**Risultato finale:**  
Con $n = 23$, la probabilit√† che **almeno una coppia** condivida il compleanno supera il **50%**, attestandosi intorno a **0.5073** (50.73%). Questo esito √® spesso sorprendente, poich√© intuitivamente si tende a sottostimare l‚Äôeffetto della **combinatoria**: sebbene 23 possano sembrare poche, le $\binom{23}{2} = 253$ possibili coppie rendono statisticamente probabile una corrispondenza.  


#### Soluzione con Simulazione in R

Per risolvere il problema tramite simulazione, possiamo generare gruppi casuali di $n$ persone, assegnando loro un compleanno casuale tra 1 e 365. Per ogni gruppo, verifichiamo se almeno due persone condividono lo stesso compleanno.

Ecco il codice R:

```{r}
# Numero di simulazioni
num_simulazioni <- 10000

# Funzione per simulare il problema del compleanno
simula_compleanno <- function(n) {
  # Conta il numero di successi (almeno un compleanno in comune)
  successi <- 0

  # Loop per il numero di simulazioni
  for (i in 1:num_simulazioni) {
    # Genera n compleanni casuali
    compleanni <- sample(1:365, n, replace = TRUE)

    # Verifica se ci sono duplicati
    if (any(duplicated(compleanni))) {
      successi <- successi + 1
    }
  }

  # Calcola la probabilit√† stimata
  return(successi / num_simulazioni)
}
```

Proviamo con diversi valori di n.

```{r}
set.seed(123) # Fissiamo il seme per la riproducibilit√†
risultati <- sapply(1:50, simula_compleanno)

# Creiamo un data frame con i risultati
df <- data.frame(
  n = 1:50,
  prob = risultati
)

# Creiamo il grafico
ggplot(df, aes(x = n, y = prob)) +
  geom_line(color = "blue") +
  geom_point(color = "blue") +
  geom_hline(yintercept = 0.5, color = "red", linetype = "dashed") +
  labs(
    x = "Numero di persone (n)",
    y = "Probabilit√† stimata",
    title = "Problema del Compleanno (Simulazione)"
  )
```

1. **Simulazioni**: Per ogni gruppo di $n$, si eseguono 10000 simulazioni, in cui si generano $n$ compleanni casuali tra 1 e 365.
2. **Duplicati**: La funzione duplicated() verifica se ci sono compleanni ripetuti.
3. **Calcolo della probabilit√†**: La proporzione di simulazioni in cui si verifica almeno un compleanno condiviso rappresenta la probabilit√† stimata.
4. **Visualizzazione**: Si tracciano le probabilit√† per diversi valori di $n$, evidenziando il punto in cui la probabilit√† supera il 50%.

Risultati attesi:

- con circa 23 persone, la probabilit√† stimata sar√† superiore a 0.5;
- il grafico mostra una curva crescente con un rapido aumento della probabilit√† per $n$ piccoli e un asintoto vicino a 1 per $n$ grandi.

Questo approccio permette di comprendere intuitivamente il problema e di verificare i risultati teorici con la simulazione.

#### Assunzioni

Il problema dei compleanni evidenzia non solo l'efficacia dell'approccio simulativo nel semplificare la soluzione rispetto all'analisi formale, ma anche l'importanza delle assunzioni che entrambi i metodi condividono. In questo caso, l'assunzione √® che la probabilit√† di nascita sia **uniformemente distribuita** nei 365 giorni dell'anno ‚Äî un'[ipotesi semplificativa](https://www.ons.gov.uk/peoplepopulationandcommunity/birthsdeathsandmarriages/livebirths/articles/howpopularisyourbirthday/2015-12-18) che non rispecchia la realt√†.

Questo esempio sottolinea un principio fondamentale dei modelli probabilistici (e scientifici in generale): **ogni modello si basa su un insieme di assunzioni che ne delimitano la validit√† e l'applicabilit√†**. Valutare criticamente la plausibilit√† di tali assunzioni √® dunque essenziale per garantire che il modello fornisca una rappresentazione utile del fenomeno studiato. 

## Riflessioni Conclusive  

La teoria della probabilit√† fornisce un quadro rigoroso per descrivere e analizzare fenomeni caratterizzati dall‚Äôincertezza. In questo capitolo abbiamo introdotto i concetti fondamentali del calcolo delle probabilit√†, evidenziando come la modellazione matematica degli esperimenti casuali consenta di quantificare e prevedere eventi incerti. Abbiamo esplorato strumenti essenziali come la **definizione di spazio campionario**, la **nozione di evento** e le **regole della probabilit√†**, illustrando il loro utilizzo sia attraverso esempi teorici sia mediante simulazioni computazionali.  

Un aspetto cruciale della modellazione probabilistica √® il ruolo delle **assunzioni** su cui si basano i modelli. Ogni modello probabilistico si fonda su ipotesi specifiche riguardanti la natura del fenomeno studiato e il modo in cui gli esiti vengono generati. Queste ipotesi determinano non solo la validit√† del modello, ma anche il tipo di risposte che esso pu√≤ fornire. Ad esempio, nel problema del compleanno, abbiamo ipotizzato che i compleanni siano distribuiti in modo uniforme nei 365 giorni dell'anno. Sebbene questa assunzione semplifichi notevolmente i calcoli, sappiamo che nella realt√† esistono fluttuazioni stagionali nelle nascite che possono influenzare le probabilit√† effettive.  

Questo ci porta a una considerazione pi√π ampia: **la probabilit√† non √® solo un insieme di formule, ma uno strumento per rappresentare l‚Äôincertezza e prendere decisioni informate**. Tuttavia, l‚Äôaccuratezza di qualsiasi modello probabilistico dipende strettamente dalla plausibilit√† delle ipotesi adottate. Modelli diversi, basati su ipotesi differenti, possono portare a risultati diversi, e l‚Äôinterpretazione dei risultati deve sempre tenere conto di queste assunzioni.  

In definitiva, lo studio della probabilit√† non si limita alla manipolazione di formule, ma richiede un‚Äôattenta riflessione sulla relazione tra modelli teorici e fenomeni reali. Una comprensione critica delle assunzioni alla base di un modello √® essenziale per applicare correttamente i concetti probabilistici in contesti pratici, sia in ambito scientifico che nelle decisioni quotidiane.

::: callout-tip
## Risposte alle domande iniziali

Il 92% delle persone sovrastima il numero necessario per la prima domanda e sottostima la seconda probabilit√†. Questo problema mostra come l‚Äôintuizione umana fallisca con eventi apparentemente "rari".

1. La risposta √® 23 persone.
2. La probabilit√† √® $\sim 0.7$
:::

## Esercizi

::: {.callout-tip title="Esercizio" collapse="true"}
Qui di seguito sono presentati una serie di esercizi sbasati sulla **Satisfaction with Life Scale (SWLS)**. 

**Esercizi sullo Spazio Campionario e Eventi**

1. **Definizione dello Spazio Campionario**  
   Supponiamo che i punteggi della Satisfaction with Life Scale (SWLS) siano numeri interi compresi tra **5 e 35**.  
   
   - Qual √® lo **spazio campionario** $\Omega$ per questo esperimento?
   - Se hai raccolto i dati di **15 studenti**, come potresti rappresentare lo spazio campionario con i loro punteggi osservati?

2. **Definizione di un Evento**  
   Consideriamo l‚Äôevento **A**: "Uno studente ha un punteggio SWLS superiore a 25". 
   
   - Esprimi l‚Äôevento A come un sottoinsieme dello spazio campionario.
   - Se tra i 15 studenti osservati, 4 hanno punteggi superiori a 25, qual √® la proporzione sperimentale per l‚Äôevento A?

3. **Eventi Complementari**  
   Definiamo l‚Äôevento **B**: "Uno studente ha un punteggio SWLS inferiore o uguale a 25".  
   
   - Scrivi l‚Äôevento **B** in relazione all‚Äôevento **A**.
   - Qual √® la probabilit√† empirica di **B**, sapendo che 4 studenti hanno punteggi superiori a 25?

**Esercizi sulle Operazioni tra Eventi**

4. **Unione di Eventi**  
   Definiamo due eventi:  
   
   - **A**: "Il punteggio SWLS √® superiore a 25".  
   - **C**: "Il punteggio SWLS √® inferiore a 15".  
   - Scrivi l‚Äôevento **A ‚à™ C** ("Lo studente ha un punteggio **maggiore di 25 o minore di 15**").
   - Se nel campione di 15 studenti, **4 studenti hanno punteggi superiori a 25** e **3 hanno punteggi inferiori a 15**, qual √® la proporzione empirica di **A ‚à™ C**?

5. **Intersezione di Eventi e Eventi Disgiunti**  
   Supponiamo che l‚Äôevento **D** sia: "Uno studente ha un punteggio pari a 20".  
   
   - L‚Äôevento **D** e l‚Äôevento **A** sono disgiunti?
   - Se nessuno degli studenti ha ottenuto esattamente 20, qual √® la probabilit√† empirica di **A ‚à© D**?

**Esercizi sulle Regole della Probabilit√†**
6. **Probabilit√† dell‚ÄôUnione di Eventi**  
   Supponiamo di avere:  
   
   - **P(A) = 0.3** (probabilit√† che un punteggio sia superiore a 25).  
   - **P(C) = 0.2** (probabilit√† che un punteggio sia inferiore a 15).  
   - **P(A ‚à© C) = 0** (perch√© un punteggio non pu√≤ essere contemporaneamente superiore a 25 e inferiore a 15).  
   - Usa la regola dell‚Äôunione per calcolare **P(A ‚à™ C)**.

7. **Probabilit√† Condizionata**  
   Consideriamo:  
   
   - **P(A) = 0.3** (probabilit√† che un punteggio sia superiore a 25).  
   - **P(E) = 0.5** (probabilit√† che uno studente abbia pi√π di 20 anni).  
   - **P(A | E) = 0.4** (probabilit√† che un soggetto con pi√π di 20 anni abbia un punteggio superiore a 25).  
   - Usa la formula della probabilit√† condizionata per calcolare **P(A ‚à© E)**.

**Esercizi su Permutazioni e Combinazioni**

8. **Selezione Casuale di Studenti**  
   Dal campione di **15 studenti**, supponiamo di voler selezionare casualmente **3 studenti** per partecipare a un‚Äôintervista sulla loro soddisfazione di vita.  
   
   - Quanti modi ci sono per selezionare **3 studenti su 15**?

9. **Ordinare gli Studenti per Discussione**  
   Supponiamo di voler formare un piccolo gruppo di discussione con **3 studenti**, scegliendoli **in ordine di intervento**.  
   - Quante diverse sequenze di 3 studenti possiamo ottenere?

10. **Formare Coppie di Studenti**  
    Se vogliamo formare **coppie di studenti** per un esercizio collaborativo, senza considerare l‚Äôordine, quanti modi ci sono per farlo?
:::

::: {.callout-tip title="Soluzione" collapse="true"}
**1. Definizione dello Spazio Campionario**  

- Lo **spazio campionario** $\Omega$ per questo esperimento √® l'insieme di tutti i possibili punteggi della Satisfaction with Life Scale (SWLS), quindi:  

  $$ \Omega = \{5, 6, 7, ..., 35\} $$
  
- Se abbiamo raccolto i dati di 15 studenti con punteggi osservati $\{27, 21, 15, 30, 18, 23, 26, 35, 20, 22, 19, 25, 32, 29, 28\}$, possiamo considerare $\Omega$ come questo insieme specifico.

**2. Definizione di un Evento**  

- L‚Äôevento $A$ "Uno studente ha un punteggio SWLS superiore a 25" √® il sottoinsieme: 

  $$ A = \{27, 30, 26, 35, 32, 29, 28\}$$
  
- Se 7 studenti su 15 hanno punteggi superiori a 25, la probabilit√† empirica √®:  

  $$ P(A) = \frac{7}{15} = 0.467 $$

**3. Eventi Complementari** 

- L‚Äôevento complementare $B$ "Uno studente ha un punteggio SWLS inferiore o uguale a 25" √®:  

  $$ B = \{21, 15, 18, 23, 20, 22, 19, 25\}$$
  
- Se 8 studenti su 15 rientrano in $B$, la probabilit√† empirica √®:  

  $$ P(B) = 1 - P(A) = \frac{8}{15} = 0.533 $$

**Soluzioni agli Esercizi sulle Operazioni tra Eventi**

**4. Unione di Eventi**  

- L‚Äôevento $A \cup C$ ("Lo studente ha un punteggio maggiore di 25 o minore di 15") √®:  

  $$ A \cup C = \{27, 30, 26, 35, 32, 29, 28, 15\}$$
  
- Se 8 studenti su 15 appartengono a $A \cup C$, la probabilit√† empirica √®:  

  $$ P(A \cup C) = \frac{8}{15} = 0.533 $$

**5. Intersezione di Eventi e Eventi Disgiunti**  

- L‚Äôevento $D$ "Uno studente ha un punteggio pari a 20" √® $D = \{20\}$.
- L‚Äôevento $A \cap D$ √® l‚Äôinsieme degli elementi comuni a $A$ e $D$, ma $D$ non ha elementi in $A$, quindi:  

  $$ A \cap D = \emptyset $$  
  
- Essendo $A \cap D = \emptyset$, gli eventi sono **disgiunti** e $P(A \cap D) = 0$.

**Soluzioni agli Esercizi sulle Regole della Probabilit√†**

**6. Probabilit√† dell‚ÄôUnione di Eventi**  

Usiamo la formula:  

$$ P(A \cup C) = P(A) + P(C) - P(A \cap C) $$

Dato che $P(A \cap C) = 0$, abbiamo:  

$$ P(A \cup C) = 0.3 + 0.2 - 0 = 0.5 $$

**7. Probabilit√† Condizionata**  

La probabilit√† congiunta $P(A \cap E)$ si calcola con:  

$$ P(A \cap E) = P(A | E) \cdot P(E) $$

Sostituendo i valori:  

$$ P(A \cap E) = 0.4 \times 0.5 = 0.2 $$

**Soluzioni agli Esercizi su Permutazioni e Combinazioni**

**8. Selezione Casuale di Studenti**  

Il numero di modi per scegliere 3 studenti su 15 (combinazioni) √®: 

$$ C_{15,3} = \frac{15!}{3!(15-3)!} = \frac{15!}{3!12!} = \frac{15 \times 14 \times 13}{3 \times 2 \times 1} = 455 $$

**9. Ordinare gli Studenti per Discussione**  

Il numero di modi per scegliere e ordinare 3 studenti su 15 (disposizioni) √®:

$$ D_{15,3} = \frac{15!}{(15-3)!} = \frac{15!}{12!} = 15 \times 14 \times 13 = 2730 $$

**10. Formare Coppie di Studenti**  

Il numero di modi per formare coppie (combinazioni di 2 studenti su 15) √®: 

$$ C_{15,2} = \frac{15!}{2!(15-2)!} = \frac{15 \times 14}{2 \times 1} = 105 $$
:::

## Bibliografia {.unnumbered}
