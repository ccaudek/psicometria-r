[
  {
    "objectID": "chapters/linear_models/12_two_proportions.html",
    "href": "chapters/linear_models/12_two_proportions.html",
    "title": "74  Confronto tra due proporzioni indipendenti",
    "section": "",
    "text": "74.1 Introduzione\nSupponiamo di voler capire se due gruppi di persone hanno la stessa probabilità di “successo” in una certa attività. Per esempio, vogliamo sapere se due trattamenti diversi portano alla stessa percentuale di guarigione, oppure se studenti che seguono due metodi di studio differenti superano un esame con la stessa frequenza.\nQuando il risultato per ogni persona è un valore binario — successo o insuccesso, sì o no, guarito o non guarito — possiamo usare un modello statistico chiamato regressione logistica.\nIn particolare, se i due gruppi sono indipendenti e distinti (cioè ogni persona appartiene a uno solo dei due gruppi), possiamo usare una versione semplice della regressione logistica con una sola variabile esplicativa binaria (una “dummy”).\nAdottando un approccio bayesiano, possiamo:",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#introduzione",
    "href": "chapters/linear_models/12_two_proportions.html#introduzione",
    "title": "74  Confronto tra due proporzioni indipendenti",
    "section": "",
    "text": "rendere esplicita l’incertezza sulle nostre ipotesi iniziali tramite le distribuzioni a priori;\n\ndescrivere l’intera gamma di risultati plausibili, ottenendo una distribuzione a posteriori dei parametri invece di un singolo valore “stimato”.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#la-struttura-dei-dati",
    "href": "chapters/linear_models/12_two_proportions.html#la-struttura-dei-dati",
    "title": "74  Confronto tra due proporzioni indipendenti",
    "section": "\n74.2 La struttura dei dati",
    "text": "74.2 La struttura dei dati\nConsideriamo i dati che raccogliamo:\n\nogni partecipante è identificato da un indice \\(i = 1, 2, \\dots, N\\);\n\nper ciascuno osserviamo un esito binario:\n\\[\ny_i =\n  \\begin{cases}\n    1 & \\text{se c’è un successo},\\\\\n    0 & \\text{se c’è un insuccesso}.\n  \\end{cases}\n\\]\n\nogni partecipante appartiene a uno e un solo gruppo. Chiamiamo gruppo 0 il primo gruppo (ad esempio, il gruppo di controllo) e gruppo 1 il secondo gruppo (ad esempio, il gruppo che riceve un trattamento sperimentale).\n\nPer rappresentare questa appartenenza al gruppo, definiamo una variabile indicatrice:\n\\[\nD_i =\n  \\begin{cases}\n    0 & \\text{se il partecipante è nel gruppo 0},\\\\\n    1 & \\text{se il partecipante è nel gruppo 1}.\n  \\end{cases}\n\\]\nQuesta variabile ci permette di costruire un modello che distingue i due gruppi.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#un-modello-statistico-per-dati-binari",
    "href": "chapters/linear_models/12_two_proportions.html#un-modello-statistico-per-dati-binari",
    "title": "74  Confronto tra due proporzioni indipendenti",
    "section": "\n74.3 Un modello statistico per dati binari",
    "text": "74.3 Un modello statistico per dati binari\nPoiché il risultato \\(y\\_i\\) può essere solo 0 o 1, possiamo descriverlo con una distribuzione di Bernoulli, che rappresenta proprio questo tipo di variabili:\n\\[\ny_i \\sim \\text{Bernoulli}(p_i),\n\\]\ndove \\(p\\_i\\) è la probabilità che il partecipante \\(i\\) ottenga un successo (cioè che \\(y_i = 1\\)).\nA questo punto potremmo pensare di modellare direttamente \\(p_i\\) come una funzione di \\(D_i\\). Ma c’è un problema tecnico importante.\n\n74.3.1 Perché non modelliamo direttamente la probabilità \\(p_i\\)?\nLe probabilità devono sempre stare tra 0 e 1. Ma se usassimo un modello lineare classico (come \\(p\\_i = \\alpha + \\gamma D_i\\)), potremmo ottenere dei valori fuori da questo intervallo — ad esempio, una “probabilità” negativa o maggiore di 1, che non ha senso.\nPer evitare questo, si usa una trasformazione matematica chiamata logit, che ha due proprietà molto utili:\n\naccetta in ingresso solo valori tra 0 e 1 (cioè le probabilità),\nrestituisce un numero reale qualsiasi, da \\(-\\infty\\) a \\(+\\infty\\).\n\nLa trasformazione logit è definita così:\n\\[\n\\text{logit}(p_i) = \\log\\left(\\frac{p_i}{1 - p_i}\\right) .\n\\]\nQuesta quantità si chiama log-odds e rappresenta il logaritmo del rapporto tra la probabilità di successo e quella di insuccesso.\nEsempio:\n\nse \\(p_i = 0.5\\), allora \\(\\text{logit}(p_i) = \\log(1) = 0\\);\nse \\(p_i = 0.8\\), allora \\(\\text{logit}(p_i) = \\log(4) \\approx 1.39\\);\nse \\(p_i = 0.2\\), allora \\(\\text{logit}(p_i) = \\log(0.25) \\approx -1.39\\).\n\nGrazie a questa trasformazione, possiamo costruire un modello lineare senza rischiare di ottenere valori fuori dall’intervallo [0,1].",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#il-modello-di-regressione-logistica",
    "href": "chapters/linear_models/12_two_proportions.html#il-modello-di-regressione-logistica",
    "title": "74  Confronto tra due proporzioni indipendenti",
    "section": "\n74.4 Il modello di regressione logistica",
    "text": "74.4 Il modello di regressione logistica\nMettiamo insieme tutti i pezzi. Il nostro modello diventa:\n\\[\n\\begin{aligned}\ny_i &\\sim \\text{Bernoulli}(p_i), \\\\\n\\text{logit}(p_i) &= \\alpha + \\gamma D_i.\n\\end{aligned}\n\\]\nVediamo cosa significano i due parametri del modello:\n\n\n\\(\\alpha\\) è il log-odds di successo per il gruppo 0 (quando \\(D_i = 0\\)).\n\n\nLa probabilità di successo corrispondente si ottiene con la funzione logistica:\n\\[\np_0 = \\frac{e^{\\alpha}}{1 + e^{\\alpha}} = \\text{logistic}(\\alpha) .\n\\]\n\n\n\n\n\\(\\gamma\\) rappresenta la differenza nei log-odds tra il gruppo 1 e il gruppo 0.\n\n\nIl log-odds nel gruppo 1 è quindi $+ $, e la probabilità è:\n\\[\np_1 = \\frac{e^{\\alpha + \\gamma}}{1 + e^{\\alpha + \\gamma}} = \\text{logistic}(\\alpha + \\gamma) .\n\\]\n\n\n\n\n\n74.4.1 Interpretazione pratica\n\nSe \\(\\gamma &gt; 0\\), il gruppo 1 ha una probabilità di successo più alta rispetto al gruppo 0.\nSe \\(\\gamma &lt; 0\\), il gruppo 1 ha una probabilità più bassa.\nSe \\(\\gamma = 0\\), i due gruppi hanno la stessa probabilità di successo.\n\n74.4.2 Vantaggi dell’approccio bayesiano\nIn un’analisi bayesiana, non ci limitiamo a stimare un singolo valore per \\(\\gamma\\). Invece, otteniamo una distribuzione completa che rappresenta tutte le ipotesi plausibili sui valori di \\(\\gamma\\), tenendo conto:\n\ndella variabilità nei dati,\ndelle nostre ipotesi iniziali (le distribuzioni a priori),\ne delle informazioni che emergono dai dati osservati.\n\nQuesto ci permette di rispondere a domande come:\n\nQuanto è probabile che \\(\\gamma\\) sia maggiore di 0?\nQual è l’intervallo più credibile in cui può trovarsi \\(\\gamma\\) con il 95% di probabilità?\nQual è la probabilità che la differenza tra i gruppi sia sostanziale, non solo presente?\n\n74.4.3 Dai Logit alle Probabilità\nUna volta stimati i coefficienti del modello di regressione logistica — in particolare, l’intercetta \\(\\beta\\_0\\) e uno o più coefficienti \\(\\beta_j\\) associati ai predittori — questi si trovano sulla scala dei log-odds (cioè su scala logit). Per ottenere le probabilità previste per ciascuna combinazione di valori dei predittori, è sufficiente applicare la funzione logistica inversa, definita come:\n\\[\np = \\text{logistic}(\\eta) = \\frac{1}{1 + e^{-\\eta}},\n\\]\ndove \\(\\eta = \\beta_0 + \\beta_1 x_1 + \\dots + \\beta_k x_k\\) è il valore del predittore lineare per una certa combinazione dei predittori. Ad esempio, se si ha solo una variabile binaria \\(x\\) che vale 0 (gruppo di riferimento) o 1 (gruppo trattato), allora le probabilità nei due gruppi sono:\n\ngruppo di riferimento: \\(p_0 = \\frac{1}{1 + e^{-\\beta_0}}\\)\n\ngruppo trattamento:    \\(p_1 = \\frac{1}{1 + e^{-(\\beta\\_0 + \\beta_1)}}\\)\n\n\nIn questo modo, si può interpretare il modello non solo in termini di log-odds, ma anche come probabilità di successo, rendendo più intuitivo il significato pratico dei risultati.\n\n74.4.4 Inferenza bayesiana\n\n\nScelta delle prior\n\nUn’opzione comune è usare prior debolmente informative, ad esempio \\(\\alpha\\sim\\mathcal N(0,\\,2.5)\\) e \\(\\gamma\\sim\\mathcal N(0,\\,2.5)\\). Queste varianze larghe lasciano che i dati “parlino”, ma impediscono che le probabilità si avvicinino troppo a 0 o 1 senza evidenza.\n\n\n\nCalcolo della distribuzione a posteriori\n\nSi usa normalmente l’algoritmo MCMC (per es. No‑U‑Turn Sampler di Stan).\nOtteniamo campioni \\(\\{\\alpha^{(s)},\\gamma^{(s)}\\}_{s=1}^S\\).\n\n\n\nQuantità derivate di interesse\n\nProbabilità nei due gruppi: \\(p_0^{(s)}=\\operatorname{logistic}(\\alpha^{(s)})\\), \\(p_1^{(s)}=\\operatorname{logistic}(\\alpha^{(s)}+\\gamma^{(s)})\\).\n\nDifferenza di probabilità: \\(\\Delta^{(s)} = p_1^{(s)}-p_0^{(s)}\\). Mostra quanto, in media, il gruppo 1 supera (o non supera) il gruppo 0 in termini di proporzione.\n\nRapporto di odds: \\(\\text{OR}^{(s)} = e^{\\gamma^{(s)}}\\). Se \\(\\text{OR}=2\\) significa che gli odds di successo nel gruppo 1 sono il doppio di quelli nel gruppo 0.\n\n\n\nSintesi dei risultati\n\nMedia (o mediana) a posteriori per \\(p_0, p_1, \\Delta, \\text{OR}\\).\nIntervalli di credibilità al 95 %: tagliamo il 2.5 % di campioni in ciascuna coda.\nProbabilità che \\(\\Delta&gt;0\\) o che \\(\\text{OR}&gt;1\\): basta contare la frazione di campioni corrispondenti.\n\n\n\n74.4.5 Perché tutto questo funziona?\n\nIl logit “apre” l’intervallo (0, 1) rendendo possibile usare un modello lineare.\n\nLa regressione logistica con una dummy è l’esatto equivalente, in termini di parametri, al test bayesiano sulle due proporzioni, ma:\n\nconsente estensioni (più covariate, effetti casuali, interazioni);\npermette di riportare risultati direttamente interpretabili (differenza di probabilità, OR, predicted probabilities).\n\n\nL’approccio bayesiano produce output che si leggono come “date le nostre ipotesi preliminari e i dati, la plausibilità che la vera differenza di probabilità stia in questo intervallo è 95 %”, concetto spesso più intuitivo del valore‑p.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#inferenza-sulle-proporzioni",
    "href": "chapters/linear_models/12_two_proportions.html#inferenza-sulle-proporzioni",
    "title": "74  Confronto tra due proporzioni indipendenti",
    "section": "\n74.5 Inferenza sulle proporzioni",
    "text": "74.5 Inferenza sulle proporzioni\nIl confronto tra le proporzioni di due gruppi indipendenti può essere affrontato sia con un approccio frequentista, basato sulla distribuzione campionaria, sia con un approccio bayesiano. Vediamo i due approcci in dettaglio.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#approccio-frequentista",
    "href": "chapters/linear_models/12_two_proportions.html#approccio-frequentista",
    "title": "74  Confronto tra due proporzioni indipendenti",
    "section": "\n74.6 Approccio Frequentista",
    "text": "74.6 Approccio Frequentista\nQuando vogliamo confrontare le probabilità di successo in due gruppi distinti, possiamo analizzare la differenza tra le proporzioni di successo osservate. L’approccio frequentista affronta il problema studiando la distribuzione campionaria di questa differenza.\n\n74.6.1 Modello di riferimento\nSupponiamo di avere due gruppi indipendenti. In ciascun gruppo osserviamo esiti binari, come “successo” (1) o “insuccesso” (0), per ogni partecipante. Formalmente:\n\\[\nY_1 \\sim \\text{Bernoulli}(p_1), \\quad Y_2 \\sim \\text{Bernoulli}(p_2),\n\\]\ndove \\(p_1\\) e \\(p_2\\) sono le probabilità di successo nella popolazione del primo e del secondo gruppo, rispettivamente.\n\n74.6.2 Obiettivo dell’inferenza\nSiamo interessati a stimare e fare inferenza sulla differenza tra le due proporzioni:\n\\[\n\\Delta = p_1 - p_2.\n\\]\nPoiché non conosciamo \\(p_1\\) e \\(p_2\\), li stimiamo usando le proporzioni campionarie:\n\\[\n\\hat{p}_1 = \\frac{X_1}{n_1}, \\quad \\hat{p}_2 = \\frac{X_2}{n_2}, \\quad \\text{e dunque} \\quad \\hat{\\Delta} = \\hat{p}_1 - \\hat{p}_2.\n\\]\n\n74.6.3 Proprietà della distribuzione campionaria\nPer capire se la differenza osservata tra \\(\\hat{p}_1\\) e \\(\\hat{p}_2\\) è attribuibile al caso oppure riflette una differenza reale tra i gruppi, analizziamo la distribuzione campionaria di \\(\\hat{\\Delta}\\).\n\n74.6.3.1 Valore atteso\nIl valore atteso della differenza stimata è:\n\\[\nE(\\hat{p}_1 - \\hat{p}_2) = p_1 - p_2,\n\\]\ncioè, in media, la stima è corretta (è uno stimatore non distorto).\n\n\n\n\n\n\nDimostrazione\n\n\n\n\n\nSupponiamo di voler confrontare le proporzioni di successo in due popolazioni distinte. Sia:\n\n\n\\(X_1\\) il numero di successi osservati in un campione di dimensione \\(n_1\\) estratto dalla prima popolazione, in cui la proporzione di successo è \\(p_1\\);\n\n\\(X_2\\) il numero di successi osservati in un campione di dimensione \\(n_2\\) estratto dalla seconda popolazione, con proporzione di successo \\(p_2\\).\n\nAssumiamo che i due campioni siano indipendenti.\nLe proporzioni campionarie, che stimano rispettivamente \\(p_1\\) e \\(p_2\\), sono definite come:\n\\[\n\\hat{p}_1 = \\frac{X_1}{n_1}, \\quad \\hat{p}_2 = \\frac{X_2}{n_2}.\n\\]\nPoiché \\(X_1 \\sim \\text{Binomiale}(n_1, p_1)\\) e \\(X_2 \\sim \\text{Binomiale}(n_2, p_2)\\), possiamo determinare i valori attesi di \\(X_1\\) e \\(X_2\\) ricordando che per una variabile binomiale \\(X \\sim \\text{Bin}(n, p)\\), il valore atteso è:\n\\[\n\\mathbb{E}(X) = n p.\n\\]\nUna variabile binomiale può essere vista come la somma di \\(n\\) variabili di Bernoulli indipendenti:\n\\[\nX = X_1 + X_2 + \\dots + X_n, \\quad \\text{con } X_i \\sim \\text{Bernoulli}(p).\n\\]\nPer la linearità del valore atteso:\n\\[\n\\mathbb{E}(X) = \\sum_{i=1}^n \\mathbb{E}(X_i) = \\sum_{i=1}^n p = n p.\n\\]\nApplicando questa proprietà ai nostri due campioni:\n\\[\n\\mathbb{E}(X_1) = n_1 p_1, \\quad \\mathbb{E}(X_2) = n_2 p_2.\n\\]\nPer la prima proporzione campionaria:\n\\[\n\\mathbb{E}(\\hat{p}_1) = \\mathbb{E}\\left( \\frac{X_1}{n_1} \\right) = \\frac{1}{n_1} \\mathbb{E}(X_1) = \\frac{n_1 p_1}{n_1} = p_1.\n\\]\nAnalogamente, per la seconda:\n\\[\n\\mathbb{E}(\\hat{p}_2) = \\mathbb{E}\\left( \\frac{X_2}{n_2} \\right) = \\frac{1}{n_2} \\mathbb{E}(X_2) = \\frac{n_2 p_2}{n_2} = p_2.\n\\]\nDunque, sia \\(\\hat{p}_1\\) che \\(\\hat{p}_2\\) sono stimatori non distorti delle rispettive proporzioni della popolazione.\nInfine, calcoliamo il valore atteso della differenza tra le due proporzioni campionarie:\n\\[\n\\mathbb{E}(\\hat{p}_1 - \\hat{p}_2) = \\mathbb{E}(\\hat{p}_1) - \\mathbb{E}(\\hat{p}_2) = p_1 - p_2.\n\\]\nIn conclusione, la differenza tra le proporzioni campionarie, \\(\\hat{p}_1 - \\hat{p}_2\\), è uno stimatore non distorto della differenza tra le vere proporzioni, \\(p_1 - p_2\\).\n\n\n\n\n74.6.3.2 Varianza\nAssumendo che i campioni siano indipendenti, la varianza della differenza stimata è la somma delle varianze delle due proporzioni:\n\\[\n\\operatorname{Var}(\\hat{p}_1 - \\hat{p}_2) = \\frac{p_1(1 - p_1)}{n_1} + \\frac{p_2(1 - p_2)}{n_2}.\n\\]\nQuesta formula ci dice quanto può variare la differenza stimata da un campione all’altro.\nPoiché \\(p_1\\) e \\(p_2\\) sono ignoti, nella pratica li sostituiamo con le proporzioni osservate \\(\\hat{p}_1\\) e \\(\\hat{p}_2\\) per stimare la varianza.\n\n\n\n\n\n\nDimostrazione\n\n\n\n\n\nConsideriamo due campioni indipendenti:\n\nIl primo campione è estratto da una popolazione in cui la proporzione di successi è \\(p_1\\). Il numero di successi osservati è una variabile casuale \\(X_1 \\sim \\text{Binomiale}(n_1, p_1)\\).\nIl secondo campione proviene da una popolazione con proporzione di successi \\(p_2\\), e il numero di successi osservati è \\(X_2 \\sim \\text{Binomiale}(n_2, p_2)\\).\n\nDefiniamo le proporzioni campionarie (ovvero gli stimatori di \\(p_1\\) e \\(p_2\\)) come:\n\\[\n\\hat{p}_1 = \\frac{X_1}{n_1}, \\qquad \\hat{p}_2 = \\frac{X_2}{n_2}.\n\\]\nVogliamo calcolare la varianza della differenza tra le proporzioni campionarie:\n\\[\n\\operatorname{Var}(\\hat{p}_1 - \\hat{p}_2).\n\\]\nSe \\(Y\\) e \\(Z\\) sono variabili casuali indipendenti, allora:\n\\[\n\\operatorname{Var}(Y - Z) = \\operatorname{Var}(Y) + \\operatorname{Var}(Z).\n\\]\nNel nostro caso, \\(\\hat{p}_1\\) e \\(\\hat{p}_2\\) derivano da due campioni indipendenti, quindi possiamo applicare questa proprietà:\n\\[\n\\operatorname{Var}(\\hat{p}_1 - \\hat{p}_2) = \\operatorname{Var}(\\hat{p}_1) + \\operatorname{Var}(\\hat{p}_2).\n\\]\nPer calcolare \\(\\operatorname{Var}(\\hat{p})\\), partiamo dalla definizione di \\(\\hat{p} = X/n\\), dove \\(X \\sim \\text{Binomiale}(n, p)\\).\nÈ noto che la varianza di una binomiale (si veda Capitolo 39) è:\n\\[\n\\operatorname{Var}(X) = n p (1 - p).\n\\]\nOra applichiamo la proprietà di omogeneità della varianza: se \\(Y = cX\\), allora \\(\\operatorname{Var}(Y) = c^2 \\operatorname{Var}(X)\\). Quindi:\n\\[\n\\operatorname{Var}(\\hat{p}) = \\operatorname{Var}\\left(\\frac{X}{n}\\right) = \\frac{1}{n^2} \\cdot \\operatorname{Var}(X) = \\frac{1}{n^2} \\cdot n p (1 - p) = \\frac{p(1 - p)}{n}.\n\\]\nApplichiamo questa formula a ciascun campione:\n\\[\n\\operatorname{Var}(\\hat{p}_1) = \\frac{p_1 (1 - p_1)}{n_1}, \\qquad \\operatorname{Var}(\\hat{p}_2) = \\frac{p_2 (1 - p_2)}{n_2}.\n\\]\nSostituendo i valori ottenuti:\n\\[\n\\operatorname{Var}(\\hat{p}_1 - \\hat{p}_2) = \\frac{p_1 (1 - p_1)}{n_1} + \\frac{p_2 (1 - p_2)}{n_2}.\n\\]\nQuesta espressione rappresenta la varianza teorica della differenza tra le proporzioni campionarie, assumendo che i veri valori di \\(p_1\\) e \\(p_2\\) siano noti.\nNella realtà, i parametri \\(p_1\\) e \\(p_2\\) non sono noti, e quindi dobbiamo usare le stime campionarie al loro posto. Otteniamo così uno stimatore della varianza:\n\\[\n\\widehat{\\operatorname{Var}}(\\hat{p}_1 - \\hat{p}_2) = \\frac{\\hat{p}_1 (1 - \\hat{p}_1)}{n_1} + \\frac{\\hat{p}_2 (1 - \\hat{p}_2)}{n_2}.\n\\]\n\n\n\n\n74.6.4 Approssimazione normale\nQuando i campioni sono sufficientemente grandi, possiamo applicare il Teorema del Limite Centrale, che ci assicura che la distribuzione della differenza \\(\\hat{p}_1 - \\hat{p}_2\\) si avvicina a una distribuzione normale:\n\\[\n\\hat{p}_1 - \\hat{p}_2 \\sim \\mathcal{N}\\left(p_1 - p_2,\\ \\sqrt{\\frac{p_1(1 - p_1)}{n_1} + \\frac{p_2(1 - p_2)}{n_2}}\\right).\n\\tag{74.1}\\]\nNell’approccio frequentista, questa approssimazione è alla base della costruzione di:\n\n\nintervalli di confidenza per \\(p_1 - p_2\\),\n\ntest di ipotesi per verificare se la differenza tra le proporzioni è nulla.\n\n74.6.5 Test dell’ipotesi nulla\nLa formula Equazione 74.1 descrive la la distribuzione asintotica della differenza tra due proporzioni senza assumere che \\(p_1 = p_2\\). Si usa tipicamente per:\n\ncostruire intervalli di confidenza per \\(p_1 - p_2\\),\neffettuare test di ipotesi bilaterali, quando non si assume che le due proporzioni siano uguali sotto l’ipotesi nulla.\n\nIn alternativa, la formula\n\\[\n\\text{SE}_{\\text{pooled}} = \\sqrt{p_{\\text{pool}}(1 - p_{\\text{pool}})\\left(\\frac{1}{n_1} + \\frac{1}{n_2}\\right)}\n\\tag{74.2}\\]\nsi usa solo per testare l’ipotesi nulla \\(H_0: p_1 = p_2\\), ovvero sotto l’assunzione che \\(p_1 = p_2 = p\\), si stima questo valore comune con la proporzione combinata (pooled):\n\\[\n\\hat{p}_{\\text{pool}} = \\frac{x_1 + x_2}{n_1 + n_2}\n\\]\ne si calcola il test z usando questa stima comune.\n\n74.6.6 Quale formula usare e quando?\n\n\n\n\n\n\nScopo\nFormula da usare\n\n\n\nTest dell’ipotesi nulla \\(H_0: p_1 = p_2\\)\n\n✅ Usa la formula con pooled proportion\n\n\n\nCostruire intervallo di confidenza per \\(p_1 - p_2\\)\n\n✅ Usa la formula senza pooling, con \\(\\hat{p}_1\\) e \\(\\hat{p}_2\\)",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#un-esempio-illustrativo-studio-su-bambini-lavoratori-e-scolari",
    "href": "chapters/linear_models/12_two_proportions.html#un-esempio-illustrativo-studio-su-bambini-lavoratori-e-scolari",
    "title": "74  Confronto tra due proporzioni indipendenti",
    "section": "\n74.7 Un esempio illustrativo: studio su bambini lavoratori e scolari",
    "text": "74.7 Un esempio illustrativo: studio su bambini lavoratori e scolari\nPer mettere in pratica quanto detto, consideriamo un caso reale tratto dallo studio di Banerjee et al. (2025), che ha confrontato le abilità matematiche di:\n\n\nbambini lavoratori nei mercati di Kolkata e Delhi;\n\nbambini scolarizzati che non lavorano.\n\nL’obiettivo era valutare se le competenze sviluppate nel lavoro quotidiano (come dare il resto, sommare prezzi, ecc.) si trasferiscono al contesto scolastico e viceversa.\n\n74.7.1 Risultati principali\n\nI bambini lavoratori si sono dimostrati molto abili nel risolvere problemi matematici concreti, ma hanno faticato con problemi presentati in forma astratta (come quelli scolastici).\nAl contrario, i bambini scolarizzati se la sono cavata meglio con problemi astratti, ma sono risultati poco efficaci nei problemi concreti del mercato.\n\nVediamo i dati raccolti per due tipi di problemi:\n\n74.7.2 Problemi astratti\n\n\nGruppo\nSuccessi\nProve totali\nProporzione\n\n\n\nBambini lavoratori\n670\n1488\n0.45\n\n\nBambini scolarizzati\n320\n542\n0.59\n\n\n\n74.7.3 Problemi di mercato\n\n\nGruppo\nSuccessi\nProve totali\nProporzione\n\n\n\nBambini lavoratori\n134\n373\n0.36\n\n\nBambini scolarizzati\n3\n271\n0.01",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#applicazione-dellapproccio-frequentista",
    "href": "chapters/linear_models/12_two_proportions.html#applicazione-dellapproccio-frequentista",
    "title": "74  Confronto tra due proporzioni indipendenti",
    "section": "\n74.8 Applicazione dell’approccio frequentista",
    "text": "74.8 Applicazione dell’approccio frequentista\n\n74.8.1 Confronto per i problemi astratti\nVogliamo verificare se la differenza tra 0.45 (lavoratori) e 0.59 (scolarizzati) è spiegabile dal caso.\nIpotesi.\n\n\n\\(H_0\\): \\(p_1 = p_2\\) (nessuna differenza tra i gruppi);\n\n\\(H_1\\): \\(p_1 \\ne p_2\\) (esiste una differenza).\n\nCalcolo.\n\n\nProporzione combinata (pooled):\n\\[\n\\hat{p} = \\frac{670 + 320}{1488 + 542} = \\frac{990}{2030} \\approx 0.487.\n\\]\n\n\nVarianza stimata della differenza:\n\\[\n\\text{Var} = \\hat{p}(1 - \\hat{p}) \\left( \\frac{1}{1488} + \\frac{1}{542} \\right) \\approx 0.000629.\n\\]\n\nDeviazione standard: $ $.\n\nStatistica z:\n\\[\nz = \\frac{0.45 - 0.59}{0.0251} \\approx -5.58.\n\\]\n\n\nIl valore z è molto lontano da 0: la probabilità di osservare una tale differenza per caso (p-value) è inferiore a 0.0001. Possiamo quindi rifiutare l’ipotesi nulla.\n\n74.8.2 Confronto per i problemi di mercato\nDati:\n\nLavoratori: 134 su 373 (\\(\\hat{p}_1 = 0.36\\))\nScolarizzati: 3 su 271 (\\(\\hat{p}_2 = 0.01\\))\n\nRipetiamo i passaggi:\n\n\\(\\hat{p} = \\frac{137}{644} \\approx 0.213\\)\n\\(\\text{Var} \\approx 0.001067\\)\nDeviazione standard: \\(\\sqrt{0.001067} \\approx 0.0327\\)\n\nStatistica z:\n\\[\nz = \\frac{0.36 - 0.01}{0.0327} \\approx 10.70\n\\]\n\n\nAnche qui, il p-value è praticamente zero: le differenze sono molto più grandi di quanto ci si aspetti per puro caso.\nIn sintesi, l’approccio frequentista ci consente di:\n\nstimare la differenza tra le proporzioni,\nquantificare l’incertezza (varianza e intervallo di confidenza),\ntestare ipotesi sul fatto che la differenza sia zero o meno.\n\nIn entrambi i confronti (problemi astratti e problemi concreti), abbiamo trovato evidenze chiare di una differenza tra i due gruppi.\n\n74.8.3 Svolgimento con R\nDi seguito mostriamo due modalità per replicare i calcoli in R: (1) passo passo usando le formule manuali, (2) usando la funzione prop.test() di R. Verranno illustrate entrambe le analisi: quella per i problemi astratti e quella per i problemi matematici di mercato.\n\n74.8.3.1 Problemi astratti\nDati\n\nBambini lavoratori (gruppo 1): 670 successi su 1488 prove.\nBambini scolarizzati (gruppo 2): 320 successi su 542 prove.\n\n\n# Dati\nX1 &lt;- 670\nn1 &lt;- 1488\nX2 &lt;- 320\nn2 &lt;- 542\n\n# Proporzioni campionarie\np1 &lt;- X1 / n1\np2 &lt;- X2 / n2\n\n# Proporzione pooled (combinata)\np_pool &lt;- (X1 + X2) / (n1 + n2)\n\n# Differenza fra le proporzioni\ndiff_p &lt;- p1 - p2\n\n# Calcolo della varianza della differenza (usando la formula per due proporzioni)\nvar_diff &lt;- p_pool * (1 - p_pool) * (1/n1 + 1/n2)\n\n# Deviazione standard della differenza\nsd_diff &lt;- sqrt(var_diff)\n\n# Statistica z\nz_value &lt;- diff_p / sd_diff\n\n# p-value (test a due code)\np_value &lt;- 2 * pnorm(abs(z_value), lower.tail = FALSE)\n\n# Visualizzazione risultati\nz_value\n#&gt; [1] -5.588\np_value\n#&gt; [1] 2.295e-08\n\n\n74.8.3.2 Analisi con funzione prop.test()\n\nPer ottenere direttamente il test di confronto di due proporzioni, possiamo usare la funzione prop.test di R. Attenzione che, di default, prop.test effettua una correzione per la continuità (Yates), che in questo contesto disattiviamo per confrontare i risultati con i calcoli manuali (impostando correct = FALSE).\n\n# Confronto due proporzioni senza correzione per la continuità\ntest_astratti &lt;- prop.test(\n  x = c(X1, X2),\n  n = c(n1, n2),\n  alternative = \"two.sided\",\n  correct = FALSE\n)\n\ntest_astratti\n#&gt; \n#&gt;  2-sample test for equality of proportions without continuity\n#&gt;  correction\n#&gt; \n#&gt; data:  c(X1, X2) out of c(n1, n2)\n#&gt; X-squared = 31, df = 1, p-value = 2e-08\n#&gt; alternative hypothesis: two.sided\n#&gt; 95 percent confidence interval:\n#&gt;  -0.18864 -0.09163\n#&gt; sample estimates:\n#&gt; prop 1 prop 2 \n#&gt; 0.4503 0.5904\n\n\n74.8.3.3 Problemi matematici di mercato\n\n# Dati\nX1_m &lt;- 134\nn1_m &lt;- 373\nX2_m &lt;- 3\nn2_m &lt;- 271\n\n# Proporzioni campionarie\np1_m &lt;- X1_m / n1_m\np2_m &lt;- X2_m / n2_m\n\n# Proporzione pooled\np_pool_m &lt;- (X1_m + X2_m) / (n1_m + n2_m)\n\n# Differenza di proporzioni\ndiff_p_m &lt;- p1_m - p2_m\n\n# Varianza della differenza (usando la proporzione pooled)\nvar_diff_m &lt;- p_pool_m * (1 - p_pool_m) * (1/n1_m + 1/n2_m)\n\n# Deviazione standard\nsd_diff_m &lt;- sqrt(var_diff_m)\n\n# Statistica z\nz_value_m &lt;- diff_p_m / sd_diff_m\n\n# p-value (test a due code)\np_value_m &lt;- 2 * pnorm(abs(z_value_m), lower.tail = FALSE)\n\n# Visualizzazione risultati\nz_value_m\n#&gt; [1] 10.66\np_value_m\n#&gt; [1] 1.581e-26\n\nAnalogamente a quanto fatto per i problemi astratti:\n\n# Confronto due proporzioni\ntest_mercato &lt;- prop.test(\n  x = c(X1_m, X2_m),\n  n = c(n1_m, n2_m),\n  alternative = \"two.sided\",\n  correct = FALSE\n)\n\ntest_mercato\n#&gt; \n#&gt;  2-sample test for equality of proportions without continuity\n#&gt;  correction\n#&gt; \n#&gt; data:  c(X1_m, X2_m) out of c(n1_m, n2_m)\n#&gt; X-squared = 114, df = 1, p-value &lt;2e-16\n#&gt; alternative hypothesis: two.sided\n#&gt; 95 percent confidence interval:\n#&gt;  0.2979 0.3984\n#&gt; sample estimates:\n#&gt;  prop 1  prop 2 \n#&gt; 0.35925 0.01107\n\n\n74.8.3.3.1 Interpretazione dei risultati\n\n\nProblemi astratti\n\nStatistica z (calcolo manuale): circa -5.58\n\np-value: molto piccolo (&lt;&lt; 0.001)\n\nConclusione: rifiutiamo \\(H_0\\) e concludiamo che la differenza tra le proporzioni di successo dei bambini lavoratori e scolarizzati sono degne di nota.\n\n\n\nProblemi matematici di mercato\n\nStatistica z (calcolo manuale): circa 10.70\n\np-value: estremamente piccolo (&lt;&lt; 0.001)\n\nConclusione: rifiutiamo \\(H_0\\) e concludiamo che anche in questo caso le differenze tra le proporzioni di successo dei due gruppi sono degne di nota.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#approccio-bayesiano",
    "href": "chapters/linear_models/12_two_proportions.html#approccio-bayesiano",
    "title": "74  Confronto tra due proporzioni indipendenti",
    "section": "\n74.8 Approccio Bayesiano",
    "text": "74.8 Approccio Bayesiano\nÈ possibile applicare l’approccio bayesiano al problema dell’inferenza sulla differenza tra due proporzioni indipendenti utilizzando un modello di regressione con una variabile indicatrice (dummy) per distinguere i due gruppi. Per fare un esempio, consideriamo qui i problemi astratti. Utilizziamo il pacchetto brms per stimare il modello, con distribuzioni a priori debolmente informative specificate di default.\n\n74.8.1 Dati\n\n# Successi e denominatori\nx_work   &lt;- 670 ; n_work   &lt;- 1488\nx_non    &lt;- 320 ; n_non    &lt;-  542\n\ndat_a &lt;- tibble(\n  count = c(x_work, x_non),\n  tot   = c(n_work, n_non),\n  group = factor(c(\"working\", \"non-working\"),\n                 levels = c(\"non-working\", \"working\"))  # “non-working” livello di riferimento\n)\n\ndat_a\n#&gt; # A tibble: 2 × 3\n#&gt;   count   tot group      \n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;      \n#&gt; 1   670  1488 working    \n#&gt; 2   320   542 non-working\n\n\n74.8.2 Prior debolmente informativi\n\n\nNormal (0, 2.5) sul logit corrisponde ai suggerimenti di Gelman et al. per logistic regression: – copre probabilità grossolanamente tra 0.004 e 0.996 sull’intercetta; – per il coefficiente di gruppo equivale a un odds-ratio plausibile entro ~ e±5.\n\n\npriors &lt;- c(\n  prior(normal(0, 2.5), class = \"Intercept\"),\n  prior(normal(0, 2.5), class = \"b\")\n)\n\n\n74.8.3 Stima del modello\n\nfit_a &lt;- brm(\n  count | trials(tot) ~ group,\n  data      = dat_a,\n  family    = binomial(),\n  prior     = priors,\n  backend   = \"cmdstanr\",\n  seed      = 1234,\n  iter      = 4000, chains = 4, cores = 4,\n  sample_prior = \"yes\"   # utile per i PPC sui prior\n)\n\nControlla rapidamente la convergenza:\n\nprint(fit_a, digits = 3)\n#&gt;  Family: binomial \n#&gt;   Links: mu = logit \n#&gt; Formula: count | trials(tot) ~ group \n#&gt;    Data: dat_a (Number of observations: 2) \n#&gt;   Draws: 4 chains, each with iter = 4000; warmup = 2000; thin = 1;\n#&gt;          total post-warmup draws = 8000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;              Estimate Est.Error l-95% CI u-95% CI  Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept       0.369     0.086    0.201    0.539 1.000     3230     3722\n#&gt; groupworking   -0.569     0.100   -0.766   -0.368 1.001     3929     3843\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\n\npp_check(fit_a, type = \"bars\")   \n\n\n\n\n\n\n\n\n74.8.4 Dalla scala logit alla scala delle probabilità\nIl modello stima\n\\[\n\\operatorname{logit}(p_i)=\\beta_0+\\beta_1\\; \\mathbf 1_{\\text{working},i},\n\\]\nperciò:\n\n\n\n\n\n\nParametro\nSignificato\n\n\n\nβ₀ (b_Intercept)\nlog-odds di successo per non-working\n\n\n\nβ₁ (b_groupworking)\ndifferenza di log-odds fra working e non-working\n\n\n\n\nPer ottenere proporzioni e differenza assoluta (Δ) dobbiamo trasformare ogni draw con l’inversa del logit, plogis().\n\npost &lt;- as_draws_df(fit_a, \n                    variables = c(\"b_Intercept\", \"b_groupworking\")) %&gt;% \n  mutate(\n    p_non  = plogis(b_Intercept),                       # Pr(corretto | non-working)\n    p_work = plogis(b_Intercept + b_groupworking),      # Pr(corretto | working)\n    diff   = p_non - p_work                             # risk-difference\n  )\n\nPerché non basta sottrarre β₁?\nPerché β₁ è una differenza di log-odds. La quantità di interesse qui è la differenza di probabilità. Le due scale sono non lineari e non confrontabili senza trasformazione.\n\n74.8.5 Sintesi della risk–difference\n\n\nsummary_diff &lt;- post %&gt;% \n  summarise(\n    mean     = mean(diff),\n    sd       = sd(diff),\n    `2.5%`   = quantile(diff, .025),\n    `97.5%`  = quantile(diff, .975),\n    prob_gt0 = mean(diff &gt; 0)      # P(Δ &gt; 0 | dati, prior)\n  )\n\nprint(summary_diff, digits = 3)\n#&gt; # A tibble: 1 × 5\n#&gt;    mean     sd `2.5%` `97.5%` prob_gt0\n#&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 0.141 0.0244 0.0918   0.188        1\n\n\n\nΔ (media)\nSD\n95 % CrI\nP(Δ &gt; 0)\n\n\n0.140\n0.025\n0.090 – 0.190\n1.000\n\n\nIl risultato replica quanto ottenuto con prop.test() (0.14 ± 0.025, IC 0.09–0.19).\n\n74.8.6 Confronto con l’approccio frequentista\n\nprop.test(c(x_work, x_non), c(n_work, n_non), correct = FALSE)\n#&gt; \n#&gt;  2-sample test for equality of proportions without continuity\n#&gt;  correction\n#&gt; \n#&gt; data:  c(x_work, x_non) out of c(n_work, n_non)\n#&gt; X-squared = 31, df = 1, p-value = 2e-08\n#&gt; alternative hypothesis: two.sided\n#&gt; 95 percent confidence interval:\n#&gt;  -0.18864 -0.09163\n#&gt; sample estimates:\n#&gt; prop 1 prop 2 \n#&gt; 0.4503 0.5904\n\n` Le due analisi coincidono: i bambini non-working hanno ~ 14 punti percentuali in più di probabilità di rispondere correttamente.\n\n74.8.7 Perché preferire il Bayesiano?\n\n\nNiente “ipotesi nulla” irreale – lavoriamo direttamente con la distribuzione di Δ.\n\nInterpretazione pronta – il 95 % CrI dice che, dati e prior, Δ è fra 9 e 19 punti %.\n\nFlessibilità – possiamo integrare conoscenza pregressa, fare previsioni, decision-making, ecc.\n\nCon prior debolmente informativi i risultati restano virtualmente identici all’approccio frequentista; in dataset più piccoli o modelli più complessi, la stabilizzazione offerta dai prior diventa però cruciale.\n\n74.8.8 Intervallo di credibilità a densità più alta\nPer ottenere l’intervallo di credibilità (Highest Density Interval, HDI) sulla scala delle probabilità (e non su quella logit), è necessario trasformare manualmente i draw a livello di probabilità e poi calcolare l’HDI su quei valori trasformati. In altre parole:\n\n\nestraiamo i draw posteriori di b_Intercept e b_groupworking;\n\n\ntrasformiamo i valori con la funzione logit-inversa (\\(\\operatorname{logistic}(x) = 1/(1+e^{-x})\\)) per ottenere le probabilità;\n\n\nse ci concentriamo sul solo effetto sulla scala della probabilità (e.g. differenza fra i due gruppi), calcoliamo la differenza tra la probabilità del gruppo “working” e quella del gruppo “reference” per ciascun draw;\n\n\napplichiamo hdi() su queste grandezze trasformate.\n\nDi seguito è fornito il codice R con il workflow completo.\n\nEstrazione draw posteriori.\n\n\npost &lt;- as_draws_df(fit_a)\n\n\n\nCalcolo delle probabilità per ciascun draw. La variabile ‘group’ abbia due livelli:\n\n“working” (effetto =&gt; b_groupworking)\n“non-working” (riferimento =&gt; b_Intercept)\n\n\n\n\npost &lt;- post %&gt;%\n  dplyr::mutate(\n    p_ref      = plogis(b_Intercept),                       # probabilità (referenza)\n    p_working  = plogis(b_Intercept + b_groupworking),      # prob. gruppo working\n    diff_working_ref = p_working - p_ref                    # differenza\n  )\n\n\nCalcolo dell’HDI sull’effetto (o sulle probabilità).\n\n\nHDI per la probabilità del gruppo “working”.\n\n\nhdi_working_prob &lt;- hdi(post$p_working, ci = 0.95)\nhdi_working_prob\n#&gt; 95% HDI: [0.43, 0.48]\n\n\nHDI per la probabilità del gruppo “non-working” (riferimento).\n\n\nhdi_ref_prob &lt;- hdi(post$p_ref, ci = 0.95)\nhdi_ref_prob\n#&gt; 95% HDI: [0.55, 0.63]\n\n\nHDI della differenza fra le due probabilità.\n\n\nhdi_diff &lt;- hdi(post$diff_working_ref, ci = 0.89)\nhdi_diff\n#&gt; 89% HDI: [-0.18, -0.10]\n\nInterpretazione\n\n\nhdi_working_prob fornisce l’HDI al 95% (o al livello che specificato) della probabilità di “successo” del gruppo “working”.\n\n\nhdi_ref_prob fa lo stesso per il gruppo di riferimento.\n\n\nhdi_diff restituisce l’HDI della differenza in probabilità tra “working” e “reference” (\\(p_{\\text{working}} - p_{\\text{reference}}\\)).\n\nIn questo modo ottieniamo l’intervallo di credibilità (HDI) sulla scala delle probabilità.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#riflessioni-conclusive",
    "href": "chapters/linear_models/12_two_proportions.html#riflessioni-conclusive",
    "title": "74  Confronto tra due proporzioni indipendenti",
    "section": "\n74.9 Riflessioni Conclusive",
    "text": "74.9 Riflessioni Conclusive\nIn questo capitolo abbiamo esplorato il confronto tra due proporzioni adottando sia l’approccio frequentista sia quello bayesiano. L’obiettivo principale era valutare se la proporzione di successi in un gruppo differisse da quella osservata nell’altro gruppo, e con quale grado di incertezza.\nNella procedura classica frequentista (test per due proporzioni), si calcola una statistica di test (ad esempio, un test z) e il relativo p-value, ossia la probabilità di osservare un risultato così estremo (o più) assumendo che le due proporzioni reali siano uguali (ipotesi nulla).\n\n\nIntervallo di confidenza: È possibile costruire un intervallo di confidenza (IC) per la differenza tra le due proporzioni. L’interpretazione frequentista di tale IC, però, si basa su un’ipotetica ripetizione di campionamenti ed è focalizzata sull’eventuale rifiuto o meno dell’ipotesi che la differenza sia zero.\n\n\nLimiti interpretativi: L’approccio frequentista si fonda sul concetto di ipotesi nulla “nessuna differenza” e non fornisce una probabilità diretta di quanto la differenza vera sia maggiore o minore di un certo valore, limitandosi a indicare se i dati sono inusuali qualora la differenza fosse zero.\n\nGrazie alla regola di Bayes, combiniamo informazioni a priori (sul probabile valore delle proporzioni) con i dati osservati, per ottenere una distribuzione a posteriori della differenza tra le due proporzioni. Questa distribuzione descrive i valori plausibili della differenza, insieme alle relative credibilità (probabilità).\n\n\nCredible Interval o Highest Density Interval (HDI): Al posto di un intervallo di confidenza, l’approccio bayesiano fornisce un intervallo di credibilità. Ad esempio, un 95% HDI indica i valori della differenza tra le proporzioni che cumulativamente contengono il 95% della probabilità a posteriori. È un costrutto immediatamente interpretabile: “Abbiamo una probabilità del 95% che la differenza vera cada all’interno di questo intervallo”.\n\n\nFlessibilità e interpretazione diretta: L’approccio bayesiano permette di rispondere in modo più naturale a domande come: “Qual è la probabilità che la differenza fra le due proporzioni sia maggiore di 0?” oppure “Qual è la probabilità che la proporzione di un gruppo superi quella dell’altro di almeno una certa soglia rilevante?”.\n\nConfronto tra i due approcci:\n\n\nInterpretazione dei risultati: Il p-value frequentista ci dice quanto il dato sia “improbabile” sotto l’ipotesi di uguaglianza delle proporzioni; il Bayesianesimo risponde direttamente a quanto è plausibile ogni possibile valore di differenza.\n\n\nCentralità dell’ipotesi nulla: Nel frequentismo, l’ipotesi nulla (differenza = 0) è centrale. Nel modello bayesiano, è invece possibile assegnare direttamente probabilità alla differenza e alla sua distanza da zero, evitando un focus eccessivo sull’uguaglianza perfetta delle due proporzioni.\n\n\nRuolo dei priors: L’uso di priors (non informativi o informativi) può influire sulle stime bayesiane quando i dati sono scarsi, rendendo evidente la necessità di scelte trasparenti e ben motivate. Tuttavia, con campioni ampi, l’influenza dei priors tende a ridursi e la stima a posteriori è dominata dai dati.\n\n\nCompletezza dell’inferenza: L’approccio bayesiano consente di integrare nuove informazioni e di aggiornare la distribuzione a posteriori man mano che arrivano dati aggiuntivi. Al contrario, l’approccio frequentista non fornisce un meccanismo diretto di “aggiornamento” delle stime alla luce di nuovi dati.\n\nIn sintesi,\n\n\napproccio frequentista: Si tratta di una metodologia consolidata e standard nella ricerca; fornisce risultati in termini di p-value e IC, ma l’interpretazione del p-value e dell’IC resta legata a procedure di campionamento ipotetico.\n\n\napproccio bayesiano: Offre una maniera più intuitiva di quantificare l’incertezza, assegnando probabilità dirette ai possibili valori di differenza fra le due proporzioni. Consente di formulare domande più specifiche (es. la probabilità che la differenza superi un valore definito) e di integrare in modo naturale informazioni a priori.\n\nNella pratica della ricerca, l’approccio frequentista rimane diffuso. Tuttavia, l’inferenza bayesiana fornisce un quadro interpretativo più ricco e flessibile. Utilizzare entrambi i metodi, quando appropriato, può potenziare l’analisi e la comprensione dei dati, permettendo di trarre conclusioni più robuste e trasparenti.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/12_two_proportions.html#informazioni-sullambiente-di-sviluppo",
    "title": "74  Confronto tra due proporzioni indipendenti",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] insight_1.2.0     bayestestR_0.15.3 posterior_1.6.1   cmdstanr_0.9.0   \n#&gt;  [5] brms_2.22.0       Rcpp_1.0.14       thematic_0.1.6    MetBrewer_0.2.0  \n#&gt;  [9] ggokabeito_0.1.0  see_0.11.0        gridExtra_2.3     patchwork_1.3.0  \n#&gt; [13] bayesplot_1.12.0  psych_2.5.3       scales_1.4.0      markdown_2.0     \n#&gt; [17] knitr_1.50        lubridate_1.9.4   forcats_1.0.0     stringr_1.5.1    \n#&gt; [21] dplyr_1.1.4       purrr_1.0.4       readr_2.1.5       tidyr_1.3.1      \n#&gt; [25] tibble_3.2.1      ggplot2_3.5.2     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [29] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1     farver_2.1.2         loo_2.8.0           \n#&gt;  [4] fastmap_1.2.0        tensorA_0.36.2.1     pacman_0.5.1        \n#&gt;  [7] digest_0.6.37        timechange_0.3.0     estimability_1.5.1  \n#&gt; [10] lifecycle_1.0.4      StanHeaders_2.32.10  processx_3.8.6      \n#&gt; [13] magrittr_2.0.3       compiler_4.5.0       rlang_1.1.6         \n#&gt; [16] tools_4.5.0          utf8_1.2.5           yaml_2.3.10         \n#&gt; [19] data.table_1.17.2    labeling_0.4.3       bridgesampling_1.1-2\n#&gt; [22] htmlwidgets_1.6.4    curl_6.2.2           pkgbuild_1.4.7      \n#&gt; [25] mnormt_2.1.1         plyr_1.8.9           RColorBrewer_1.1-3  \n#&gt; [28] abind_1.4-8          withr_3.0.2          stats4_4.5.0        \n#&gt; [31] grid_4.5.0           colorspace_2.1-1     inline_0.3.21       \n#&gt; [34] xtable_1.8-4         emmeans_1.11.1       cli_3.6.5           \n#&gt; [37] mvtnorm_1.3-3        rmarkdown_2.29       generics_0.1.4      \n#&gt; [40] RcppParallel_5.1.10  rstudioapi_0.17.1    reshape2_1.4.4      \n#&gt; [43] tzdb_0.5.0           rstan_2.32.7         parallel_4.5.0      \n#&gt; [46] matrixStats_1.5.0    vctrs_0.6.5          V8_6.0.3            \n#&gt; [49] Matrix_1.7-3         jsonlite_2.0.0       hms_1.1.3           \n#&gt; [52] glue_1.8.0           codetools_0.2-20     ps_1.9.1            \n#&gt; [55] distributional_0.5.0 stringi_1.8.7        gtable_0.3.6        \n#&gt; [58] QuickJSR_1.7.0       pillar_1.10.2        htmltools_0.5.8.1   \n#&gt; [61] Brobdingnag_1.2-9    R6_2.6.1             rprojroot_2.0.4     \n#&gt; [64] evaluate_1.0.3       lattice_0.22-7       backports_1.5.0     \n#&gt; [67] rstantools_2.4.0     coda_0.19-4.1        nlme_3.1-168        \n#&gt; [70] checkmate_2.3.2      xfun_0.52            pkgconfig_2.0.3",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#bibliografia",
    "href": "chapters/linear_models/12_two_proportions.html#bibliografia",
    "title": "74  Confronto tra due proporzioni indipendenti",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBanerjee, A. V., Bhattacharjee, S., Chattopadhyay, R., Duflo, E., Ganimian, A. J., Rajah, K., & Spelke, E. S. (2025). Children’s arithmetic skills do not transfer between applied and academic mathematics. Nature, 1–9.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#un-esempio-illustrativo-studio-su-bambini-lavoratori-e-scolarizzati",
    "href": "chapters/linear_models/12_two_proportions.html#un-esempio-illustrativo-studio-su-bambini-lavoratori-e-scolarizzati",
    "title": "74  Confronto tra due proporzioni indipendenti",
    "section": "\n74.7 Un esempio illustrativo: studio su bambini lavoratori e scolarizzati",
    "text": "74.7 Un esempio illustrativo: studio su bambini lavoratori e scolarizzati\nPer mettere in pratica quanto detto, consideriamo un caso reale tratto dallo studio di Banerjee et al. (2025), che ha confrontato le abilità matematiche di:\n\n\nbambini lavoratori nei mercati di Kolkata e Delhi;\n\nbambini scolarizzati che non lavorano.\n\nL’obiettivo era valutare se le competenze sviluppate nel lavoro quotidiano (come dare il resto, sommare prezzi, ecc.) si trasferiscono al contesto scolastico e viceversa.\n\n74.7.1 Risultati principali\n\nI bambini lavoratori si sono dimostrati molto abili nel risolvere problemi matematici concreti, ma hanno faticato con problemi presentati in forma astratta (come quelli scolastici).\nAl contrario, i bambini scolarizzati se la sono cavata meglio con problemi astratti, ma sono risultati poco efficaci nei problemi concreti del mercato.\n\nVediamo i dati raccolti per due tipi di problemi:\n\n74.7.2 Problemi astratti\n\n\nGruppo\nSuccessi\nProve totali\nProporzione\n\n\n\nBambini lavoratori\n670\n1488\n0.45\n\n\nBambini scolarizzati\n320\n542\n0.59\n\n\n\n74.7.3 Problemi di mercato\n\n\nGruppo\nSuccessi\nProve totali\nProporzione\n\n\n\nBambini lavoratori\n134\n373\n0.36\n\n\nBambini scolarizzati\n3\n271\n0.01",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/probability/introduction_probability.html",
    "href": "chapters/probability/introduction_probability.html",
    "title": "Probabilità",
    "section": "",
    "text": "Questa sezione della dispensa introduce la teoria della probabilità, una componente essenziale per la ricerca scientifica. Nell’ambito della scienza, l’inferenza induttiva è di fondamentale importanza, e la probabilità svolge un ruolo cruciale in questo processo. Poiché la scienza non può garantire verità assolute, ma solo approssimazioni corroborate da evidenze, la probabilità diventa lo strumento chiave per quantificare il grado di incertezza associato a un’ipotesi, a una previsione o a un modello. Due scuole di pensiero dominano questo scenario: l’approccio bayesiano, che interpreta la probabilità come misura soggettiva del grado di fiducia in una proposizione, e l’approccio frequentista, che la definisce come frequenza relativa di un evento osservabile in condizioni ripetute. Sebbene queste prospettive differiscano radicalmente nell’interpretazione filosofica, entrambe poggiano sullo stesso formalismo matematico. Padroneggiare i concetti fondamentali della probabilità è dunque essenziale per comprendere sia gli strumenti dell’inferenza bayesiana, sia quelli classici dell’analisi statistica.\nQuesta sezione fornisce le basi teoriche necessarie per navigare entrambi i paradigmi. Partiremo dalle definizioni di probabilità e dalle sue regole fondamentali, per poi introdurre concetti come la probabilità condizionale e il teorema di Bayes, che stanno alla base dell’aggiornamento delle credenze alla luce di nuovi dati. Esploreremo inoltre le proprietà delle variabili casuali, distinguendo tra distribuzioni discrete (a massa di probabilità) e continue (a densità di probabilità). Infine, discuteremo la funzione di verosimiglianza, comune alle due scuole: mentre i bayesiani la integrano con informazioni a priori per costruire distribuzioni posteriori, i frequentisti ne sfruttano il principio della massima verosimiglianza per stimare parametri in modo puramente empirico, senza assumere conoscenze preliminari.",
    "crumbs": [
      "Probabilità"
    ]
  },
  {
    "objectID": "chapters/probability/12_discr_rv_distr.html",
    "href": "chapters/probability/12_discr_rv_distr.html",
    "title": "39  Distribuzioni di v.c. discrete",
    "section": "",
    "text": "39.1 Introduzione\nÈ importante distinguere tra variabili casuali discrete e continue, perché le distribuzioni di probabilità associate sono molto diverse nei due casi si veda il 31.\nIn questo capitolo ci focalizzeremo sulle distribuzioni di probabilità discrete, strumenti fondamentali per modellare fenomeni aleatori che generano un numero finito o numerabile di possibili esiti. Queste distribuzioni risultano particolarmente efficaci per descrivere eventi che si verificano in contesti discreti, come il numero di successi in un esperimento, l’occorrenza di un evento, o la selezione casuale da un insieme di opzioni finite.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_discr_rv_distr.html#introduzione",
    "href": "chapters/probability/12_discr_rv_distr.html#introduzione",
    "title": "39  Distribuzioni di v.c. discrete",
    "section": "",
    "text": "39.1.1 Panoramica delle Distribuzioni Discrete\nDi seguito, vengono presentate alcune delle principali distribuzioni discrete utilizzate in statistica e nella ricerca psicologica Ogni distribuzione è descritta in termini di caratteristiche fondamentali, applicazioni pratiche e importanza teorica.\n\n39.1.1.1 Distribuzione Uniforme Discreta\n\n\nDescrizione: La distribuzione uniforme discreta rappresenta situazioni in cui tutti gli eventi all’interno di un insieme finito hanno la stessa probabilità di verificarsi.\n\nApplicazioni: Si applica in contesti di scelta casuale equiprobabile, come:\n\nLa selezione casuale di uno stimolo da una lista di parole in un esperimento di memoria.\nL’assegnazione casuale di partecipanti a gruppi sperimentali in uno studio di psicologia sociale.\nLa scelta di un’immagine tra un insieme di stimoli visivi in una ricerca sull’attenzione.\nLa probabilità uniforme che un partecipante scelga una delle opzioni in un questionario a risposte multiple, in assenza di preferenze o conoscenze specifiche.\n\n\n\nParametri:\n\nIntervallo di supporto: l’insieme finito di valori possibili (ad esempio, \\(\\{1, 2, \\dots, k\\}\\)).\n\n\n\nImportanza: Funziona come modello di riferimento in situazioni di massima incertezza o mancanza di preferenze. È utile per definire un punto di partenza in analisi più complesse e per studiare comportamenti casuali.\n\n39.1.1.2 Distribuzione di Bernoulli\n\n\nDescrizione: La distribuzione di Bernoulli modella esperimenti con due possibili esiti, generalmente etichettati come “successo” (con probabilità \\(p\\)) e “fallimento” (con probabilità \\(1-p\\)).\n\nApplicazioni: Si applica a situazioni binarie, come il lancio di una moneta (testa/croce), la risposta a domande dicotomiche (sì/no), o l’esito di un evento che può verificarsi o meno.\n\nParametro:\n\n\n\\(p\\): probabilità di successo.\n\n\n\nImportanza: Costituisce la base per molte altre distribuzioni discrete, come la distribuzione binomiale e geometrica. È fondamentale per comprendere fenomeni con esiti dichotomici.\n\n39.1.1.3 Distribuzione Binomiale\n\n\nDescrizione: La distribuzione binomiale descrive il numero totale di successi in un numero fisso \\(n\\) di prove indipendenti, ciascuna governata da una distribuzione di Bernoulli con probabilità di successo \\(p\\).\n\nApplicazioni: Viene utilizzata per analizzare processi ripetuti con esiti binari, ad esempio:\n\nIl numero di voti favorevoli in un campione di opinione.\nIl numero di sintomi osservati in un gruppo di pazienti.\nIl conteggio di errori in un test di accuratezza.\n\n\n\nParametri:\n\n\n\\(n\\): numero di prove.\n\n\\(p\\): probabilità di successo in ogni prova.\n\n\n\nImportanza: Fornisce uno strumento essenziale per modellare fenomeni ripetuti in condizioni identiche, consentendo analisi probabilistiche avanzate e previsioni statistiche.\n\n39.1.1.4 Distribuzione di Poisson\n\n\nDescrizione: La distribuzione di Poisson modella il numero di eventi che si verificano in un intervallo fissato di tempo o spazio, quando tali eventi sono rari, indipendenti e accadono a un tasso medio costante \\(\\lambda\\).\n\nApplicazioni: Trova impiego in contesti dove gli eventi sono sporadici ma prevedibili, ad esempio:\n\nIl numero di episodi di ansia riportati in una settimana.\nIl numero di interazioni sociali spontanee di un bambino con disturbo dello spettro autistico durante una sessione di osservazione.\nLa frequenza di lapsus verbali durante una presentazione pubblica.\nIl numero di sogni vividi riportati durante una serie di notti consecutive in uno studio sul sonno.\n\n\n\nParametro:\n\n\n\\(\\lambda\\): tasso medio di eventi per unità di tempo o spazio.\n\n\n\nImportanza: È cruciale per analizzare fenomeni psicologici o comportamentali rari ma significativi. Aiuta a comprendere i meccanismi sottostanti e a modellare la variabilità osservata in contesti clinici, sperimentali o quotidiani.\n\nIn conclusione, le distribuzioni discrete sopra descritte rappresentano strumenti fondamentali per modellare una vasta gamma di fenomeni osservati in ambito scientifico, psicologico e applicativo. Ciascuna distribuzione offre una cornice teorica ben definita per interpretare e analizzare situazioni caratterizzate da variabili aleatorie discrete, fornendo così le basi per inferenze statistiche robuste e previsioni quantitative affidabili.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_discr_rv_distr.html#distribuzioni-in-r",
    "href": "chapters/probability/12_discr_rv_distr.html#distribuzioni-in-r",
    "title": "39  Distribuzioni di v.c. discrete",
    "section": "\n39.2 Distribuzioni in R",
    "text": "39.2 Distribuzioni in R\nIn R, per ogni distribuzione sono disponibili quattro funzioni principali, i cui nomi iniziano con le lettere:\n\n\nd (density): per calcolare i valori teorici relativi alla distribuzione,\n\n\np (probability): per ottenere la probabilità cumulativa,\n\n\nq (quantile): per determinare i quantili,\n\n\nr (random): per generare campioni casuali.\n\nIl pacchetto di base stats include numerose funzioni dedicate alle principali distribuzioni statistiche, permettendo di calcolare valori teorici e simulare dati in modo semplice e flessibile. Per ulteriori dettagli sulle distribuzioni disponibili e sull’uso delle relative funzioni, è possibile consultare la documentazione con il comando ?Distributions.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_discr_rv_distr.html#distribuzione-uniforme-discreta-1",
    "href": "chapters/probability/12_discr_rv_distr.html#distribuzione-uniforme-discreta-1",
    "title": "39  Distribuzioni di v.c. discrete",
    "section": "\n39.3 Distribuzione Uniforme Discreta",
    "text": "39.3 Distribuzione Uniforme Discreta\nLa distribuzione uniforme discreta è una delle più semplici e intuitive distribuzioni di probabilità. È utilizzata per modellare situazioni in cui tutti gli esiti possibili sono ugualmente probabili. Si applica, ad esempio, quando si estrae un numero a caso da un insieme finito di interi senza alcuna preferenza.\n\nDefinizione 39.1 Sia \\(X\\) una variabile casuale che può assumere i valori interi da 1 a \\(N\\), tutti con la stessa probabilità. Allora diciamo che \\(X\\) ha una distribuzione uniforme discreta sull’intervallo \\(\\{1, 2, \\dots, N\\}\\). In simboli:\n\\[\nX \\sim \\text{Uniforme Discreta}(1, N) .\n\\]\nPoiché ci sono \\(N\\) valori possibili e ciascuno ha la stessa probabilità, ogni valore ha probabilità:\n\\[\nP(X = x) = \\frac{1}{N}, \\quad \\text{per } x \\in \\{1, 2, \\dots, N\\}.\n\\]\n\n\n39.3.1 Proprietà di normalizzazione\nLa somma delle probabilità di tutti gli esiti deve essere pari a 1:\n\\[\n\\sum_{x = 1}^{N} P(X = x) = \\sum_{x = 1}^{N} \\frac{1}{N} = \\frac{1}{N} \\cdot N = 1.\n\\]\nQuesta è una proprietà fondamentale di ogni distribuzione di probabilità.\n\n39.3.2 Valore atteso\nIl valore atteso (o media) ci dice qual è il risultato medio atteso nel lungo periodo. Si calcola come:\n\\[\n\\mathbb{E}(X) = \\sum_{x = 1}^{N} x \\cdot P(X = x) = \\frac{1}{N} \\sum_{x = 1}^{N} x.\n\\]\nLa somma dei primi \\(N\\) numeri naturali è:\n\\[\n\\sum_{x = 1}^{N} x = \\frac{N(N + 1)}{2}.\n\\]\nQuindi:\n\\[\n\\mathbb{E}(X) = \\frac{1}{N} \\cdot \\frac{N(N + 1)}{2} = \\frac{N + 1}{2}.\n\\]\nIn conclusione, il valore atteso di una variabile uniforme discreta su \\(\\{1, \\dots, N\\}\\) è \\(\\frac{N + 1}{2}\\).\n\n39.3.3 Varianza\nLa varianza della distribuzione uniforme discreta è:\n\\[\n\\mathbb{V}(X) = \\frac{(N + 1)(N - 1)}{12}.\n\\]\n\n\n\n\n\n\nDimostrazione\n\n\n\n\n\nLa varianza misura quanto i valori di \\(X\\) si discostano in media dalla media \\(\\mathbb{E}(X)\\). Si calcola come:\n\\[\n\\mathbb{V}(X) = \\mathbb{E}(X^2) - \\left[\\mathbb{E}(X)\\right]^2.\n\\]\n\nCalcolo di \\(\\mathbb{E}(X^2)\\).\n\nPoiché tutti i valori hanno la stessa probabilità \\(\\frac{1}{N}\\), otteniamo:\n\\[\n\\mathbb{E}(X^2) = \\frac{1}{N} \\sum_{x = 1}^{N} x^2.\n\\]\nLa somma dei quadrati dei primi \\(N\\) interi è:\n\\[\n\\sum_{x = 1}^{N} x^2 = \\frac{N(N + 1)(2N + 1)}{6}\n\\]\n(per una dimostrazione, si veda la pagina di Wikipedia sui numeri piramidali quadrati).\nQuindi:\n\\[\n\\mathbb{E}(X^2) = \\frac{1}{N} \\cdot \\frac{N(N + 1)(2N + 1)}{6} = \\frac{(N + 1)(2N + 1)}{6}.\n\\]\n\nCalcolo della varianza.\n\nSostituendo nella formula della varianza:\n\\[\n\\begin{align*}\n\\mathbb{V}(X) &= \\frac{(N + 1)(2N + 1)}{6} - \\left(\\frac{N + 1}{2}\\right)^2 \\\\\n&= \\frac{(N + 1)(2N + 1)}{6} - \\frac{(N + 1)^2}{4}\n\\end{align*}\n\\]\nPer semplificare, portiamo tutto allo stesso denominatore:\n\\[\n\\begin{align*}\n\\mathbb{V}(X) &= \\frac{2(N + 1)(2N + 1)}{12} - \\frac{3(N + 1)^2}{12} \\\\\n&= \\frac{(N + 1) \\left[2(2N + 1) - 3(N + 1)\\right]}{12} \\\\\n&= \\frac{(N + 1)(4N + 2 - 3N - 3)}{12} \\\\\n&= \\frac{(N + 1)(N - 1)}{12}.\n\\end{align*}\n\\]\nIn conclusione, la varianza della distribuzione uniforme discreta è:\n\\[\n\\mathbb{V}(X) = \\frac{(N + 1)(N - 1)}{12}.\n\\]\n\n\n\nIn sintesi, per una variabile casuale \\(X\\) uniformemente distribuita su \\(\\{1, 2, \\dots, N\\}\\):\n\n\nProprietà\nFormula\n\n\n\nMedia\n\\(\\mathbb{E}(X) = \\dfrac{N + 1}{2}\\)\n\n\nVarianza\n\\(\\mathbb{V}(X) = \\dfrac{(N + 1)(N - 1)}{12}\\)\n\n\n\nQuesta distribuzione è utile ogni volta che non c’è alcuna ragione per preferire un valore a un altro all’interno di un insieme finito di numeri interi.\n\nEsempio 39.1 Supponiamo che \\(X\\) sia una variabile casuale con distribuzione uniforme discreta tra 1 e 10, ovvero:\n\\[\nX \\sim \\text{Uniforme Discreta}(1, 10) .\n\\]\nVogliamo:\n\ngenerare un grande campione casuale,\ncalcolare la media e la varianza osservate,\nconfrontarle con i valori teorici.\n\nCodice R.\n\nset.seed(123)  # Per rendere la simulazione riproducibile\n\n# Parametro N\nN &lt;- 10\n\n# Simulazione: 100.000 osservazioni dalla distribuzione uniforme discreta\nx &lt;- sample(1:N, size = 100000, replace = TRUE)\n\n# Media e varianza empiriche\nmedia_empirica &lt;- mean(x)\nvarianza_empirica &lt;- var(x)\n\n# Valori teorici\nmedia_teorica &lt;- (N + 1) / 2\nvarianza_teorica &lt;- ((N + 1) * (N - 1)) / 12\n\n# Risultati\ntibble(\n  `Media empirica` = media_empirica,\n  `Media teorica` = media_teorica,\n  `Varianza empirica` = varianza_empirica,\n  `Varianza teorica` = varianza_teorica\n)\n#&gt; # A tibble: 1 × 4\n#&gt;   `Media empirica` `Media teorica` `Varianza empirica` `Varianza teorica`\n#&gt;              &lt;dbl&gt;           &lt;dbl&gt;               &lt;dbl&gt;              &lt;dbl&gt;\n#&gt; 1             5.51             5.5                8.26               8.25\n\nCon un campione molto grande, le statistiche empiriche (cioè calcolate dai dati simulati) saranno molto vicine ai valori teorici:\n\n\n\nValore\n\n\n\nMedia teorica\n5.5\n\n\nMedia empirica\n≈ 5.5\n\n\nVarianza teorica\n8.25\n\n\nVarianza empirica\n≈ 8.25\n\n\n\n\nIn sintesi, a simulazione conferma che:\n\nla media empirica converge verso \\(\\mathbb{E}(X) = \\frac{N + 1}{2}\\),\nla varianza empirica converge verso \\(\\mathbb{V}(X) = \\frac{(N + 1)(N - 1)}{12}\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_discr_rv_distr.html#distribuzione-di-bernoulli-1",
    "href": "chapters/probability/12_discr_rv_distr.html#distribuzione-di-bernoulli-1",
    "title": "39  Distribuzioni di v.c. discrete",
    "section": "\n39.4 Distribuzione di Bernoulli",
    "text": "39.4 Distribuzione di Bernoulli\nIn statistica, un esperimento che ammette solo due esiti possibili è modellato attraverso quella che viene chiamata “prova Bernoulliana”. Un esempio tipico è il lancio di una moneta, che può dare come risultato testa o croce.\n\nDefinizione 39.2 Una variabile casuale \\(X\\) che assume valori in \\(\\{0, 1\\}\\) è detta variabile di Bernoulli. La sua distribuzione di probabilità è definita come:\n\\[\nP(X \\mid \\theta) =\n  \\begin{cases}\n    p     & \\text{se $X = 1$ (successo)}, \\\\\n    1 - p & \\text{se $X = 0$ (insuccesso)},\n  \\end{cases}\n\\]\ndove \\(0 \\leq p \\leq 1\\). Il parametro \\(p\\) rappresenta la probabilità del “successo” (\\(X = 1\\)), mentre \\(1 - p\\) è la probabilità dell’“insuccesso” (\\(X = 0\\)).\n\nLa distribuzione di Bernoulli descrive quindi un contesto in cui la probabilità di osservare l’esito 1 è \\(p\\) e quella di osservare l’esito 0 è \\(1 - p\\). Viene utilizzata per modellare situazioni binarie, come una risposta “sì” o “no”, oppure un “successo” o “insuccesso”.\nCalcolando il valore atteso e la varianza, otteniamo:\n\\[\n\\begin{align}\n\\mathbb{E}(X) &= 0 \\cdot P(X=0) + 1 \\cdot P(X=1) = p, \\\\\n\\mathbb{V}(X) &= (0 - p)^2 \\cdot P(X=0) + (1 - p)^2 \\cdot P(X=1) = p(1-p).\n\\end{align}\n\\tag{39.1}\\]\n\n\n\n\n\n\nDimostrazione\n\n\n\nEsaminiamo la dimostrazione algebrica del calcolo della varianza.\nEspandiamo il calcolo della somma, considerando i due possibili valori di \\(X\\) (0 e 1).\n\n\nPrimo termine (\\(X = 0\\)):\n\\[\n(0 - \\mathbb{E}(X))^2 \\cdot P(X = 0) = (0 - p)^2 \\cdot (1 - p).\n\\]\nSemplificando \\((0 - p)^2 = p^2\\), quindi:\n\\[\n(0 - \\mathbb{E}(X))^2 \\cdot P(X = 0) = p^2 \\cdot (1 - p).\n\\]\n\n\nSecondo termine (\\(X = 1\\)):\n\\[\n(1 - \\mathbb{E}(X))^2 \\cdot P(X = 1) = (1 - p)^2 \\cdot p.\n\\]\nSemplificando \\((1 - p)^2 = 1 - 2p + p^2\\), quindi:\n\\[\n(1 - \\mathbb{E}(X))^2 \\cdot P(X = 1) = (1 - 2p + p^2) \\cdot p = p - 2p^2 + p^3.\n\\]\n\n\nSomma dei termini\nOra sommiamo i due contributi:\n\\[\n\\mathbb{V}(X) = p^2 \\cdot (1 - p) + (p - 2p^2 + p^3).\n\\]\nEspandendo il primo termine:\n\\[\np^2 \\cdot (1 - p) = p^2 - p^3.\n\\]\nSomma completa:\n\\[\n\\mathbb{V}(X) = (p^2 - p^3) + (p - 2p^2 + p^3).\n\\]\n\n\nRaggruppiamo i termini\n\\[\n\\mathbb{V}(X) = p - p^2.\n\\]\nRisultato finale:\n\\[\n\\mathbb{V}(X) = p(1 - p).\n\\]\n\n\nIn sintesi, la varianza di una variabile aleatoria binaria \\(X\\), distribuita secondo Bernoulli con parametro \\(p\\), è data da \\(p(1-p)\\).\n\n\nTale risultato mostra come la varianza massima si ottenga per \\(p = 0.5\\), condizione che corrisponde alla massima incertezza intrinseca nel processo, ossia quando la probabilità di successo eguaglia quella di insuccesso.\n\n# Valori di p tra 0 e 1\np &lt;- seq(0, 1, length.out = 100)\nvariance &lt;- p * (1 - p)\ndata &lt;- data.frame(p = p, Variance = variance)\n\n# Creazione del grafico\nggplot(data, aes(x = p, y = Variance)) +\n  geom_line(color = okabe_ito_palette[2], linewidth = 1.2) +\n  labs(\n    x = expression(p),\n    y = \"Varianza\",\n    title = \"Varianza di una Variabile Bernoulliana in funzione di p\"\n  )\n\n\n\n\n\n\n\n\n39.4.1 Notazione\nPer indicare che la variabile casuale \\(X\\) segue una distribuzione Bernoulliana di parametro \\(p\\) Utilizziamo la notazione \\(X \\sim \\mathcal{Bern}(p)\\), o in maniera equivalente \\(\\mathcal{Bern}(X \\mid p)\\).\n\nEsempio 39.2 Nel caso del lancio di una moneta equilibrata, la variabile di Bernoulli assume i valori \\(0\\) e \\(1\\) con uguale probabilità di \\(\\frac{1}{2}\\). Pertanto, la funzione di massa di probabilità assegna una probabilità di \\(\\frac{1}{2}\\) sia per \\(X = 0\\) che per \\(X = 1\\), mentre la funzione di distribuzione cumulativa risulta essere \\(\\frac{1}{2}\\) per \\(X = 0\\) e \\(1\\) per \\(X = 1\\).\nGeneriamo dei valori casuali dalla distribuzione di Bernoulli. Iniziamo con un singolo valore:\n\n# Probabilità di successo\np &lt;- 0.5\n\n# Genera un singolo valore\nbernoulli_sample &lt;- rbinom(n = 1, size = 1, prob = p)\nprint(bernoulli_sample)\n#&gt; [1] 1\n\n# Genera un campione di 10 valori\nbernoulli_sample &lt;- rbinom(n = 10, size = 1, prob = p)\nprint(bernoulli_sample)\n#&gt;  [1] 1 0 1 1 1 1 0 1 1 0",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_discr_rv_distr.html#distribuzione-binomiale-1",
    "href": "chapters/probability/12_discr_rv_distr.html#distribuzione-binomiale-1",
    "title": "39  Distribuzioni di v.c. discrete",
    "section": "\n39.5 Distribuzione Binomiale",
    "text": "39.5 Distribuzione Binomiale\nLa distribuzione binomiale è una distribuzione di probabilità discreta che modella il numero di successi \\(y\\) in un numero fissato \\(n\\) di prove di Bernoulli indipendenti e identiche, dove ciascuna prova ha solo due esiti possibili: “successo” (rappresentato da “1”) con probabilità \\(p\\) o “insuccesso” (rappresentato da “0”) con probabilità \\(1 - p\\). La notazione utilizzata è la seguente:\n\\[\nY \\sim \\mathcal{Binom}(n, p).\n\\]\n\nDefinizione 39.3 La distribuzione binomiale descrive la probabilità di osservare esattamente \\(y\\) successi in \\(n\\) prove di Bernoulli indipendenti:\n\\[\nP(Y = y) = \\binom{n}{y} p^{y} (1 - p)^{n - y} = \\frac{n!}{y!(n - y)!} p^{y} (1 - p)^{n - y},\n\\tag{39.2}\\]\ndove \\(\\binom{n}{y}\\), noto come coefficiente binomiale, rappresenta il numero di modi possibili per ottenere \\(y\\) successi in \\(n\\) prove, e \\(p\\) è la probabilità di successo in ciascuna prova.\n\nLa distribuzione binomiale si presta bene a esempi classici come il lancio ripetuto di una moneta o l’estrazione di biglie da un’urna. Ad esempio, nel caso del lancio di una moneta, questa distribuzione descrive la probabilità di ottenere un determinato numero di “teste” in un certo numero di lanci, con ogni lancio che segue una distribuzione di Bernoulli con probabilità di successo \\(p\\).\nUna caratteristica interessante della distribuzione binomiale è la sua proprietà di riproducibilità: se due variabili casuali indipendenti, \\(y_1\\) e \\(y_2\\), seguono entrambe distribuzioni binomiali con lo stesso parametro \\(p\\), ma con un diverso numero di prove (\\(n_1\\) e \\(n_2\\)), la loro somma, \\(y = y_1 + y_2\\), sarà ancora distribuita binomialmente, con parametri \\(n_1 + n_2\\) e \\(p\\).\n\n\n\n\n\n\nDimostrazione\n\n\n\nPer chiarire il calcolo delle probabilità nella distribuzione binomiale, consideriamo una serie di prove di Bernoulli. Supponiamo di avere \\(n\\) prove indipendenti, ciascuna con probabilità \\(p\\) di successo, e di osservare esattamente \\(y\\) successi.\nUna possibile configurazione dei risultati può essere rappresentata come:\n\\[\n\\overbrace{SS\\dots S}^\\text{$y$ successi} \\, \\overbrace{II\\dots I}^\\text{$n - y$ insuccessi}\n\\]\nLa probabilità di ottenere esattamente \\(y\\) successi in una sequenza specifica (cioè in un ordine fissato) è:\n\\[\np^y \\cdot (1 - p)^{n - y},\n\\]\ndove \\(p^y\\) è la probabilità dei \\(y\\) successi e \\((1 - p)^{n - y}\\) quella dei \\(n - y\\) insuccessi.\nTuttavia, ciò che ci interessa è la probabilità complessiva di ottenere \\(y\\) successi in qualsiasi ordine. In altre parole, vogliamo calcolare la probabilità dell’unione di tutte le possibili sequenze di \\(n\\) prove che contengono esattamente \\(y\\) successi.\nIl numero di tali sequenze è dato dal coefficiente binomiale \\(\\binom{n}{y}\\), che rappresenta il numero di modi diversi in cui possiamo scegliere le \\(y\\) posizioni dei successi tra le \\(n\\) prove.\nMoltiplicando la probabilità di una singola sequenza per il numero totale di sequenze possibili, otteniamo la funzione di probabilità della distribuzione binomiale:\n\\[\nP(Y = y) = \\binom{n}{y} p^y (1 - p)^{n - y}.\n\\]\n\n\n\n39.5.1 Caso particolare \\(n = 1\\)\n\nOra consideriamo il caso particolare in cui \\(n = 1\\). Quando \\(n = 1\\), il coefficiente binomiale diventa:\n\\[\n\\binom{1}{y} = \\frac{1!}{y! (1-y)!}.\n\\]\nEspandiamo i fattoriali per i due possibili valori di \\(y\\), che può assumere solo 0 o 1 (poiché \\(y \\in \\{0, 1, \\dots, n\\}\\)).\nCaso 1: \\(y = 0\\)\n\\[\n\\binom{1}{0} = \\frac{1!}{0! (1-0)!} = \\frac{1}{1 \\cdot 1} = 1.\n\\]\nQuindi, per \\(y = 0\\): \\[\nP(Y = 0) = \\binom{1}{0} p^0 (1-p)^{1-0} = 1 \\cdot 1 \\cdot (1-p) = 1-p.\n\\]\nCaso 2: \\(y = 1\\)\n\\[\n\\binom{1}{1} = \\frac{1!}{1! (1-1)!} = \\frac{1}{1 \\cdot 1} = 1.\n\\]\nQuindi, per \\(y = 1\\): \\[\nP(Y = 1) = \\binom{1}{1} p^1 (1-p)^{1-1} = 1 \\cdot p \\cdot 1 = p.\n\\]\nIn conclusione, la PMF per la distribuzione binomiale con \\(n = 1\\) diventa:\n\\[\nP(Y = y) =\n\\begin{cases}\n1-p, & \\text{se } y = 0, \\\\\np, & \\text{se } y = 1.\n\\end{cases}\n\\]\nQuesta è esattamente la PMF della distribuzione di Bernoulli con parametro \\(p\\):\n\\[\nP(Y = y) = p^y (1-p)^{1-y}, \\quad y \\in \\{0, 1\\}.\n\\]\nPertanto, la distribuzione binomiale con \\(n = 1\\) è equivalente alla distribuzione di Bernoulli con parametro \\(p\\).\n\n39.5.2 Applicazioni Pratiche della Distribuzione Binomiale\nPer illustrare l’applicazione della distribuzione binomiale, consideriamo un esempio semplice. Supponiamo di osservare 2 successi su 4 prove di Bernoulli, dove la probabilità di successo in ogni prova è \\(p = 0.2\\). La probabilità di ottenere esattamente questo risultato si calcola con la formula:\n\\[\nP(Y = 2) = \\binom{4}{2} \\cdot 0.2^2 \\cdot (1 - 0.2)^{2} = 0.1536.\n\\]\nIn R, questo calcolo si può fare in modo diretto:\n\n# Parametri\nn &lt;- 4\np &lt;- 0.2\ny &lt;- 2\n\n# Calcolo della probabilità esatta\nprob &lt;- choose(n, y) * p^y * (1 - p)^(n - y)\nprint(prob)\n#&gt; [1] 0.1536\n\nIn alternativa, possiamo usare la funzione dbinom() per ottenere la stessa probabilità:\n\nprob &lt;- dbinom(x = y, size = n, prob = p)\nprint(prob)\n#&gt; [1] 0.1536\n\n\n39.5.2.1 Visualizzazione della distribuzione di probabilità\nPossiamo rappresentare graficamente la distribuzione di massa di probabilità per tutti i possibili valori di \\(y\\) da \\(0\\) a \\(n\\):\n\ny &lt;- 0:n\nprobabilities &lt;- dbinom(y, size = n, prob = p)\n\ndf &lt;- data.frame(Successi = y, Probabilità = probabilities)\n\ndf |&gt;\n  ggplot(aes(x = Successi, y = Probabilità)) +\n    geom_segment(\n      aes(xend = Successi, yend = 0), lwd = 1.2, \n      color = okabe_ito_palette[2]\n      ) +\n    geom_point(size = 3, color = okabe_ito_palette[2]) +\n    labs(\n      x = \"Numero di successi y\",\n      y = \"Probabilità\",\n      title = paste(\"Distribuzione binomiale: n =\", n, \", p =\", p)\n    )\n\n\n\n\n\n\n\n\n39.5.2.2 Generazione di un campione casuale\nLa funzione rbinom() permette di generare un campione casuale da una distribuzione binomiale:\n\nset.seed(42)\nsamples &lt;- rbinom(n = 30, size = 5, prob = 0.5)\nprint(samples)\n#&gt;  [1] 4 4 2 4 3 3 3 1 3 3 2 3 4 2 2 4 5 1 2 3 4 1 5 4 1 3 2 4 2 4\n\n\n39.5.2.3 Variazione della distribuzione al variare di \\(p\\)\n\nPer esplorare l’effetto di diversi valori di \\(p\\) sulla forma della distribuzione, possiamo visualizzare più curve binomiali per \\(n = 20\\) e \\(p\\) variabile:\n\nn &lt;- 20\np_values &lt;- seq(0.3, 0.9, by = 0.3)\ny &lt;- 0:25\n\ndf &lt;- data.frame()\n\nfor (p in p_values) {\n  binom_dist &lt;- dbinom(y, size = n, prob = p)\n  df &lt;- rbind(df, data.frame(y = y, Prob = binom_dist, p = factor(p)))\n}\n\ndf |&gt;\n  ggplot(aes(x = y, y = Prob, color = p)) +\n    geom_point() +\n    geom_line() +\n    labs(\n      x = \"Numero di successi y\",\n      y = \"Probabilità\",\n      title = \"Distribuzioni binomiali con diversi valori di p\",\n      color = expression(p)\n    )\n\n\n\n\n\n\n\n\n39.5.2.4 Funzione di ripartizione cumulativa\nPossiamo anche rappresentare la funzione di distribuzione cumulativa (CDF) per \\(n = 5\\) e \\(p = 0.5\\):\n\nn &lt;- 5\np &lt;- 0.5\ny &lt;- 0:n\n\ncdf_values &lt;- pbinom(y, size = n, prob = p)\ndf &lt;- data.frame(y = y, cdf = cdf_values)\n\ndf |&gt;\n  ggplot(aes(x = y, y = cdf)) +\n    geom_line() +\n    geom_point() +\n    geom_hline(\n      yintercept = 1, linetype = \"dashed\", color = \"black\", alpha = 0.7\n    ) +\n    labs(\n      title = paste(\"Funzione di ripartizione: n =\", n, \", p =\", p),\n      x = \"Numero di successi y\",\n      y = \"Probabilità cumulativa\"\n    )\n\n\n\n\n\n\n\n\nEsempio 39.3 Supponiamo di lanciare una moneta equa (cioè con probabilità \\(p = 0.5\\) di ottenere testa) 5 volte. Vogliamo calcolare la probabilità di ottenere almeno 2 teste, ovvero:\n\\[\nP(Y \\geq 2) = P(Y = 2) + P(Y = 3) + P(Y = 4) + P(Y = 5).\n\\]\nPossiamo sommare direttamente queste probabilità usando dbinom():\n\nresult &lt;- sum(dbinom(2:5, size = 5, prob = 0.5))\nprint(result)\n#&gt; [1] 0.8125\n\nUn modo alternativo, più efficiente, consiste nel calcolare il complemento della probabilità di ottenere meno di 2 teste (cioè 0 o 1):\n\\[\nP(Y \\geq 2) = 1 - P(Y \\leq 1)\n\\]\nIn R, possiamo usare la funzione pbinom() per calcolare questa probabilità cumulativa:\n\nresult &lt;- 1 - pbinom(q = 1, size = 5, prob = 0.5)\nprint(result)\n#&gt; [1] 0.8125\n\nEntrambi i metodi restituiscono lo stesso risultato numerico, ma il secondo è spesso preferibile quando \\(n\\) è grande o quando si vuole calcolare una probabilità di coda.\n\n\n39.5.2.5 Quantili di una distribuzione binomiale\nHai perfettamente ragione — grazie per l’osservazione!\nInfatti, con i parametri size = 5, prob = 0.5 e target_probability = 0.60, la funzione qbinom() restituisce 3, non 2. Questo perché qbinom() restituisce il più piccolo valore di \\(y\\) tale che \\(P(Y \\leq y) \\geq p\\). Verifichiamolo in R:\npbinom(2, 5, 0.5)  # = 0.5\npbinom(3, 5, 0.5)  # = 0.8125\nQuindi:\n\n\n\\(P(Y \\leq 2) = 0.5\\) → troppo poco\n\n\\(P(Y \\leq 3) = 0.8125\\) → supera il 60%\n\nPertanto, qbinom(0.6, 5, 0.5) restituisce 3.\n\n39.5.2.6 Quantili di una distribuzione binomiale\nLa funzione qbinom() permette di calcolare il quantile di una distribuzione binomiale, cioè il numero minimo di successi \\(y\\) tale che la probabilità cumulativa \\(P(Y \\leq y)\\) sia maggiore o uguale a una certa soglia.\nAd esempio, supponiamo di voler sapere qual è il numero minimo di successi tale che la probabilità cumulativa sia almeno 60%. Possiamo usare:\n\n# Probabilità cumulativa desiderata\ntarget_probability &lt;- 0.60\n\n# Calcolo del quantile\nresult &lt;- qbinom(p = target_probability, size = 5, prob = 0.5)\nprint(result)\n#&gt; [1] 3\n\nIl risultato è 3, il che significa che:\n\\[\nP(Y \\leq 3) = 0.8125 \\geq 0.60,\n\\]\nmentre\n\\[\nP(Y \\leq 2) = 0.5 &lt; 0.60.\n\\]\nQuindi, servono almeno 3 successi per superare la soglia del 60% di probabilità cumulativa.\n\n🔎 qbinom(p, size, prob) restituisce il più piccolo valore di \\(y\\) tale che \\(P(Y \\leq y) \\geq p\\).\n\n\n39.5.2.7 Rappresentazione grafica del quantile\nPer visualizzare il comportamento della funzione di ripartizione cumulativa e individuare il quantile per \\(p = 0.60\\), possiamo usare il seguente codice in R:\n\n# Parametri\nn &lt;- 5\np &lt;- 0.5\ntarget_probability &lt;- 0.60\n\n# Asse y: numero di successi\ny &lt;- 0:n\n\n# Calcolo dei valori cumulativi\ncdf &lt;- pbinom(y, size = n, prob = p)\n\n# Calcolo del quantile\nq &lt;- qbinom(target_probability, size = n, prob = p)\n\n# Data frame\ndf &lt;- data.frame(Successi = y, CDF = cdf)\n\n# Grafico\ndf |&gt;\n  ggplot(aes(x = Successi, y = CDF)) +\n  geom_step(direction = \"hv\", linewidth = 1.1) +\n  geom_point(size = 2) +\n  geom_hline(\n    yintercept = target_probability, linetype = \"dashed\", color = \"red\"\n  ) +\n  geom_vline(xintercept = q, linetype = \"dotted\", color = \"blue\") +\n  annotate(\n    \"text\",\n    x = q + 0.4, y = 0.05, label = paste(\"quantile =\", q),\n    color = \"blue\"\n  ) +\n  annotate(\n    \"text\",\n    x = 0.5, y = target_probability + 0.05,\n    label = paste(\"soglia =\", target_probability), color = \"red\"\n  ) +\n  labs(\n    title = paste(\n      \"Funzione di ripartizione cumulativa (n =\", n, \", p =\", p, \")\"\n    ),\n    x = \"Numero di successi\",\n    y = \"Probabilità cumulativa\"\n  ) +\n  ylim(0, 1.05)\n\n\n\n\n\n\n\nIn questo grafico:\n\nla linea rossa tratteggiata rappresenta la soglia di probabilità desiderata (es. 0.60);\nla linea blu tratteggiata verticale indica il quantile corrispondente, cioè il più piccolo valore di \\(y\\) per cui \\(P(Y \\leq y) \\geq 0.60\\);\nil valore calcolato è 3, quindi con al massimo 3 successi, la probabilità cumulativa supera il 60%.\n\n\nEsempio 39.4 Consideriamo una distribuzione binomiale con \\(n = 10\\) prove e probabilità di successo \\(p = 0.2\\). Supponiamo di voler calcolare la probabilità di ottenere al massimo 4 successi. In termini matematici, vogliamo calcolare:\n\\[\nP(Y \\leq 4) .\n\\]\nIn R, questo si ottiene con la funzione pbinom():\n\n# Calcolo della probabilità cumulativa fino a 4 successi\np_cumulativa &lt;- pbinom(4, size = 10, prob = 0.2)\nprint(p_cumulativa)\n#&gt; [1] 0.9672\n\nIl risultato indica che c’è circa l’97% di probabilità di ottenere 4 o meno successi su 10 prove, quando la probabilità di successo in ciascuna prova è 0.2.\nOra facciamo il passaggio inverso: immaginiamo di conoscere la probabilità cumulativa (per esempio, 0.97) e vogliamo sapere quanti successi bisogna considerare per raggiungere quella probabilità.\nPer questo usiamo la funzione qbinom(), che ci restituisce il più piccolo numero di successi \\(y\\) tale che \\(P(Y \\leq y) \\geq\\) quella probabilità:\n\n# Calcolo del numero di successi associato alla probabilità cumulativa\nnumero_successi &lt;- qbinom(p_cumulativa, size = 10, prob = 0.2)\nprint(numero_successi)\n#&gt; [1] 4\n\nIl valore ottenuto sarà 4, cioè il minimo numero di successi per cui la probabilità cumulativa è almeno il 97%.\nRiepilogo concetti chiave:\n\n\npbinom(y, n, p) calcola la probabilità di ottenere al massimo \\(y\\) successi;\n\nqbinom(prob, n, p) calcola il numero minimo di successi necessari per raggiungere almeno quella probabilità.\n\nIn sintesi, pbinom() e qbinom() sono strumenti complementari: pbinom ci dà la probabilità di ottenere fino a un certo numero di successi, mentre qbinom ci dice fino a quanti successi possiamo ottenere per raggiungere una certa probabilità. Nell’analisi di una distribuzione binomiale (e di molte altre distribuzioni) queste funzioni aiutano a calcolare e interpretare facilmente probabilità cumulate e quantili in R, rendendo più semplice l’analisi di eventi aleatori.\n\n\n39.5.3 Valore atteso e deviazione standard nella distribuzione binomiale\nNella distribuzione binomiale, possiamo calcolare facilmente due quantità molto importanti:\n\n\nil valore atteso (o media), che ci dice quanti successi ci aspettiamo in media su un certo numero di prove;\n\nla deviazione standard, che ci dice quanto i risultati tendono a variare attorno alla media.\n\nLe formule sono le seguenti:\n\\[\n\\text{Media (valore atteso):} \\quad \\mu = n p ,\n\\tag{39.3}\\]\n\\[\n\\text{Deviazione standard:} \\quad \\sigma = \\sqrt{n p (1 - p)} ,\n\\tag{39.4}\\]\ndove:\n\n\n\\(n\\) è il numero di prove (per esempio, il numero di lanci di una moneta),\n\n\\(p\\) è la probabilità di successo in ogni prova.\n\n\n\n\n\n\n\nDimostrazione.\nLa variabile \\(Y\\) rappresenta il numero di successi in \\(n\\) prove di Bernoulli indipendenti. Possiamo scriverla come somma di \\(n\\) variabili casuali indipendenti:\n\\[\nY = Y_1 + Y_2 + \\cdots + Y_n,\n\\]\ndove ciascuna \\(Y_i \\sim \\text{Bernoulli}(p)\\), cioè:\n\\[\nY_i =\n\\begin{cases}\n1 & \\text{con probabilità } p \\\\\n0 & \\text{con probabilità } 1 - p\n\\end{cases}\n\\]\nValore atteso di \\(Y_i\\).\nPer definizione del valore atteso:\n\\[\n\\mathbb{E}(Y_i) = 1 \\cdot p + 0 \\cdot (1 - p) = p.\n\\]\nValore atteso di \\(Y_i^2\\).\nPoiché \\(Y_i\\) assume solo i valori 0 e 1, si ha \\(Y_i^2 = Y_i\\). Quindi:\n\\[\n\\mathbb{E}(Y_i^2) = \\mathbb{E}(Y_i) = p.\n\\]\nLa varianza di una variabile casuale si definisce come:\n\\[\n\\operatorname{Var}(Y_i) = \\mathbb{E}(Y_i^2) - [\\mathbb{E}(Y_i)]^2.\n\\]\nSostituendo i valori trovati sopra:\n\\[\n\\operatorname{Var}(Y_i) = p - p^2 = p(1 - p).\n\\]\nRicordiamo che \\(Y = \\sum_{i=1}^{n} Y_i\\) e che le \\(Y_i\\) sono indipendenti. Una proprietà fondamentale della varianza è che se \\(Z_1, \\dots, Z_n\\) sono indipendenti:\n\\[\n\\operatorname{Var}(Z_1 + \\cdots + Z_n) = \\operatorname{Var}(Z_1) + \\cdots + \\operatorname{Var}(Z_n).\n\\]\nApplichiamola al nostro caso:\n\\[\n\\operatorname{Var}(Y) = \\sum_{i=1}^{n} \\operatorname{Var}(Y_i).\n\\]\nPoiché tutte le \\(Y_i\\) hanno la stessa varianza \\(p(1 - p)\\), la somma diventa:\n\\[\n\\operatorname{Var}(Y) = n \\cdot p(1 - p).\n\\]\nAbbiamo dimostrato da definizione che, se \\(Y \\sim \\text{Bin}(n, p)\\), allora:\n\\[\n\\operatorname{Var}(Y) = n \\cdot p \\cdot (1 - p).\n\\]\nQuesta formula descrive la dispersione attesa nel numero di successi su \\(n\\) prove indipendenti, ciascuna con probabilità di successo \\(p\\).\n\n\n\n\nEsempio 39.5 Supponiamo di lanciare 4 volte una moneta truccata che ha una probabilità di successo (es. ottenere testa) pari a \\(p = 0.2\\).\nVogliamo calcolare:\n\nla media attesa del numero di teste,\nla varianza,\ne la deviazione standard.\n\n\nCalcolo del valore atteso (media):\n\n\\[\n\\mu = n \\cdot p = 4 \\cdot 0.2 = 0.8 .\n\\]\nQuindi, in media, ci aspettiamo di ottenere 0.8 teste ogni 4 lanci (cioè meno di 1, ma ricordiamo che si tratta di una media).\n\nCalcolo della varianza:\n\n\\[\n\\text{Varianza} = n \\cdot p \\cdot (1 - p) = 4 \\cdot 0.2 \\cdot 0.8 = 0.64 .\n\\]\n\nCalcolo della deviazione standard:\n\n\\[\n\\sigma = \\sqrt{0.64} \\approx 0.8 .\n\\]\nLa deviazione standard ci dà un’idea della variabilità dei risultati: in questo caso, i valori osservati (numero di teste su 4 lanci) si discostano dalla media di circa 0.8 in media.\n\n\n39.5.4 Verifica con una simulazione in R\nPer vedere se i calcoli teorici dell’Esempio 39.5 funzionano anche nella pratica, possiamo simulare l’esperimento in R: lanciamo 4 monete, ma lo facciamo tantissime volte (ad esempio 1 milione) e calcoliamo la media e la varianza dei risultati ottenuti.\n\nset.seed(42)\n\n# Generiamo 1 milione di esperimenti: 4 lanci con probabilità di successo 0.2\nx &lt;- rbinom(n = 1e6, size = 4, prob = 0.2)\n\n# Calcoliamo la media empirica\nmean(x)\n#&gt; [1] 0.8002\n# [1] circa 0.8\n\n# Calcoliamo la varianza empirica\nvar(x)\n#&gt; [1] 0.639\n# [1] circa 0.64\n\nCome possiamo vedere, i risultati ottenuti dalla simulazione sono molto vicini ai valori teorici: la media è circa \\(\\mu = 0.8\\) e la varianza circa \\(0.64\\), proprio come previsto dalle formule.\nQuesto non solo conferma che le formule per media e varianza nella distribuzione binomiale sono corrette, ma ci aiuta anche a capire meglio cosa significano:\n\nil valore atteso rappresenta la media dei risultati se ripetiamo l’esperimento moltissime volte;\n\nla varianza (e la sua radice quadrata, la deviazione standard) misura quanto i risultati si allontanano dalla media.\n\nLa simulazione mostra quindi in modo concreto che il valore atteso e la varianza descrivono il comportamento “medio” della variabile aleatoria, quando viene osservata in un numero molto grande di situazioni. In altre parole, questi concetti non sono solo teorici: ci dicono cosa aspettarci nella pratica, se ripetiamo molte volte lo stesso esperimento.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_discr_rv_distr.html#funzioni-r-per-le-distribuzioni-di-probabilità",
    "href": "chapters/probability/12_discr_rv_distr.html#funzioni-r-per-le-distribuzioni-di-probabilità",
    "title": "39  Distribuzioni di v.c. discrete",
    "section": "\n39.6 Funzioni R per le distribuzioni di probabilità",
    "text": "39.6 Funzioni R per le distribuzioni di probabilità\nIn R, le distribuzioni di probabilità (sia discrete che continue) sono gestite in modo sistematico. Per ogni distribuzione, esistono quattro funzioni principali, ognuna con un prefisso diverso che indica il tipo di operazione desiderata:\n\n\nd*: calcola la densità (per distribuzioni continue) o la probabilità (per distribuzioni discrete);\n\n\np*: calcola la funzione di ripartizione cumulativa (CDF), cioè \\(P(Y \\leq y)\\);\n\n\nq*: calcola la funzione quantile (inversa della CDF);\n\n\nr*: genera valori casuali secondo la distribuzione specificata.\n\nQuesta struttura è identica per tutte le distribuzioni implementate in R. La tabella seguente mostra un confronto tra le funzioni disponibili per due distribuzioni fondamentali: la binomiale (discreta) e la normale (continua).\n\n\n\n\n\n\n\nTipo di funzione\nBinomiale (\\(Y \\sim \\text{Bin}(n, p)\\))\nNormale (\\(Y \\sim \\mathcal{N}(\\mu, \\sigma)\\))\n\n\n\nDensità o probabilità esatta\ndbinom(y, size = n, prob = p)\ndnorm(y, mean = mu, sd = sigma)\n\n\n\\(P(Y = y)\\)\ndbinom(...)\n❌ Non definita: per variabili continue si usa la densità\n\n\nProbabilità cumulativa\npbinom(y, size = n, prob = p)\npnorm(y, mean = mu, sd = sigma)\n\n\n\\(P(Y \\geq y)\\)\n1 - pbinom(y - 1, ...)\n1 - pnorm(y, ...)\n\n\n\\(P(y_1 &lt; Y &lt; y_2)\\)\npbinom(y2, ...) - pbinom(y1, ...)\npnorm(y2, ...) - pnorm(y1, ...)\n\n\nQuantile (inversa della CDF)\nqbinom(q, size = n, prob = p)\nqnorm(q, mean = mu, sd = sigma)\n\n\nSimulazione di dati casuali\nrbinom(n, size = trials, prob = p)\nrnorm(n, mean = mu, sd = sigma)\n\n\n\n\n\n\n\n\n\nNota\n\n\n\n\nPer le distribuzioni discrete (come la binomiale), dbinom(y, ...) restituisce la probabilità esatta di osservare il valore \\(y\\): ad esempio, \\(P(Y = 2)\\).\nPer le distribuzioni continue (come la normale), dnorm(y, ...) restituisce la densità in \\(y\\), che non rappresenta direttamente una probabilità, ma è utile per visualizzare la forma della distribuzione.\nLe probabilità cumulative (funzioni p*) e i quantili (funzioni q*) sono sempre definiti, sia per distribuzioni discrete che continue.\nLa generazione di dati casuali con r* è molto utile per simulazioni e verifiche empiriche.\n\nPiù avanti, vedremo altre distribuzioni (Uniforme, Beta, Poisson, ecc.), tutte con lo stesso schema di funzioni: d, p, q, r.\nQuesta coerenza rende molto semplice imparare a usare le distribuzioni in R: una volta compreso lo schema, lo si può applicare a qualsiasi caso.\n\n\n\nEsempio 39.6  \n\nCalcolare la probabilità di esattamente \\(y = 3\\) successi su \\(n = 5\\) prove con \\(p = 0.5\\):\n\n\ndbinom(3, size = 5, prob = 0.5)\n#&gt; [1] 0.3125\n\n\nCalcolare la probabilità cumulativa \\(P(Y \\leq 3)\\):\n\n\npbinom(3, size = 5, prob = 0.5)\n#&gt; [1] 0.8125\n\n\nCalcolare il valore minimo \\(y\\) tale che \\(P(Y \\leq y) \\geq 0.9\\):\n\n\nqbinom(0.9, size = 5, prob = 0.5)\n#&gt; [1] 4\n\n\nGenerare un campione di 100 numeri casuali da una distribuzione binomiale:\n\n\nrbinom(100, size = 5, prob = 0.5)\n#&gt;   [1] 2 2 4 1 3 2 3 2 2 2 3 3 3 3 1 4 1 1 0 2 2 2 4 1 2 3 3 1 5 2 3 3 0 3 2\n#&gt;  [36] 3 4 2 3 3 3 3 1 5 3 3 2 3 1 2 1 3 3 2 2 4 1 4 2 3 1 4 2 2 3 4 1 1 4 2\n#&gt;  [71] 3 2 3 3 3 1 4 4 3 3 4 3 3 3 2 2 3 3 2 4 4 3 2 2 0 3 1 3 1 2",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_discr_rv_distr.html#distribuzione-di-poisson-1",
    "href": "chapters/probability/12_discr_rv_distr.html#distribuzione-di-poisson-1",
    "title": "39  Distribuzioni di v.c. discrete",
    "section": "\n39.7 Distribuzione di Poisson",
    "text": "39.7 Distribuzione di Poisson\nLa distribuzione di Poisson è utilizzata per modellare il numero di eventi che si verificano in un determinato intervallo di tempo o spazio, con eventi indipendenti e un tasso costante di occorrenza.\nLa funzione di massa di probabilità (PMF) è data da:\n\\[\nP(Y = y \\mid \\lambda) = \\frac{\\lambda^y \\cdot e^{-\\lambda}}{y!}, \\quad y = 0, 1, 2, \\ldots\n\\]\ndove \\(\\lambda\\) rappresenta il tasso medio di eventi e \\(y\\) è il numero di eventi.\nLa distribuzione di Poisson può essere derivata come il limite di una distribuzione binomiale quando il numero di prove, \\(n\\), tende all’infinito e la probabilità di successo in ciascuna prova, \\(p\\), tende a zero, in modo tale che \\(np = \\lambda\\).\n\n\n\n\n\n\nDimostrazione\n\n\n\nPartiamo dalla funzione di probabilità binomiale:\n\\[\np(k) = \\frac{n!}{k!(n - k)!} p^k (1 - p)^{n - k}.\n\\]\nImpostiamo \\(np = \\lambda\\), il che implica che \\(p = \\frac{\\lambda}{n}\\). Sostituendo \\(p\\) con \\(\\frac{\\lambda}{n}\\) nella formula binomiale, otteniamo:\n\\[\np(k) = \\frac{n!}{k!(n - k)!} \\left(\\frac{\\lambda}{n}\\right)^k \\left(1 - \\frac{\\lambda}{n}\\right)^{n - k}.\n\\]\nOra, separiamo i termini per rendere più chiara la semplificazione. Possiamo riscrivere \\(\\left(\\frac{\\lambda}{n}\\right)^k\\) come \\(\\frac{\\lambda^k}{n^k}\\), e \\(\\left(1 - \\frac{\\lambda}{n}\\right)^{n - k}\\) come \\(\\left(1 - \\frac{\\lambda}{n}\\right)^n \\cdot \\left(1 - \\frac{\\lambda}{n}\\right)^{-k}\\). Quindi, l’espressione diventa:\n\\[\np(k) = \\frac{n!}{k!(n - k)!} \\cdot \\frac{\\lambda^k}{n^k} \\cdot \\left(1 - \\frac{\\lambda}{n}\\right)^n \\cdot \\left(1 - \\frac{\\lambda}{n}\\right)^{-k}.\n\\]\nOra, separiamo ulteriormente i termini:\n\\[\np(k) = \\frac{\\lambda^k}{k!} \\cdot \\frac{n!}{(n - k)! n^k} \\cdot \\left(1 - \\frac{\\lambda}{n}\\right)^n \\cdot \\left(1 - \\frac{\\lambda}{n}\\right)^{-k}.\n\\]\nQuesto passaggio mostra come la funzione di probabilità binomiale, sotto le condizioni \\(np = \\lambda\\) e \\(n \\to \\infty\\), si trasformi gradualmente nella forma che conduce alla distribuzione di Poisson.\nQuando \\(n \\to \\infty\\):\n\\[\n\\frac{\\lambda}{n} \\to 0\n\\]\n\\[\n\\frac{n!}{(n - k)! n^k} \\to 1\n\\]\n\\[\n\\left(1 - \\frac{\\lambda}{n}\\right)^n \\to e^{-\\lambda}\n\\]\n\\[\n\\left(1 - \\frac{\\lambda}{n}\\right)^{-k} \\to 1\n\\]\nSi ottiene quindi:\n\\[\np(k) \\to \\frac{\\lambda^k e^{-\\lambda}}{k!}\n\\]\nche è la funzione di Poisson.\n\n\n\n\n\n\n\n\nDimostrazione\n\n\n\nAnalizziamo il limite:\n\\[\n\\left(1 - \\frac{\\lambda}{n}\\right)^n \\to e^{-\\lambda} \\quad \\text{quando} \\quad n \\to \\infty.\n\\]\nUn limite fondamentale in analisi matematica è:\n\\[\n\\lim_{n \\to \\infty} \\left(1 + \\frac{a}{n}\\right)^n = e^a,\n\\]\ndove \\(e\\) è la base del logaritmo naturale (\\(e \\approx 2.71828\\)) e \\(a\\) è una costante. Questo limite è alla base della definizione della funzione esponenziale.\nNel nostro caso, abbiamo l’espressione:\n\\[\n\\left(1 - \\frac{\\lambda}{n}\\right)^n .\n\\]\nNotiamo che questa è molto simile al limite notevole, ma con un segno negativo. Possiamo riscriverla come:\n\\[\n\\left(1 - \\frac{\\lambda}{n}\\right)^n = \\left(1 + \\frac{-\\lambda}{n}\\right)^n.\n\\]\nApplicando il limite notevole con \\(a = -\\lambda\\), otteniamo:\n\\[\n\\lim_{n \\to \\infty} \\left(1 + \\frac{-\\lambda}{n}\\right)^n = e^{-\\lambda}.\n\\]\nQuindi, quando \\(n\\) diventa molto grande, l’espressione \\(\\left(1 - \\frac{\\lambda}{n}\\right)^n\\) si avvicina sempre di più a \\(e^{-\\lambda}\\).\n\n\n\n39.7.1 Proprietà principali\n\n\nMedia: \\(\\mathbb{E}[Y] = \\lambda\\)\n\n\nVarianza: \\(\\text{Var}(Y) = \\lambda\\)\n\n\nDi seguito, presentiamo esempi di calcolo e simulazione con R.\n\n39.7.2 Grafico della distribuzione di Poisson con \\(\\lambda = 2\\)\n\n\n# Parametro lambda\nlambda &lt;- 2\n\n# Valori di y (numero di eventi)\ny &lt;- 0:10\n\n# Calcolo delle probabilità\nprobabilities &lt;- dpois(y, lambda = lambda)\n\n# Creazione di un dataframe per ggplot\ndata &lt;- data.frame(\n  Numero_eventi = y,\n  Probabilita = probabilities\n)\n\n# Grafico della funzione di massa di probabilità \nggplot(data, aes(x = Numero_eventi, y = Probabilita)) +\n  geom_col(fill = okabe_ito_palette[2]) +  \n  labs(\n    title = \"Distribuzione di Massa di Probabilità di Poisson\",\n    x = \"Numero di eventi (k)\",\n    y = \"Probabilità\"\n  ) \n\n\n\n\n\n\n\n\n39.7.3 Calcolo della probabilità per un numero specifico di eventi\nPer calcolare la probabilità di osservare esattamente 3 eventi con \\(\\lambda = 2\\):\n\nprob &lt;- dpois(3, lambda = 2)\nprint(prob)\n#&gt; [1] 0.1804\n\n\n39.7.4 Calcolo della probabilità cumulativa \\(P(Y \\leq 3)\\)\n\nPer calcolare \\(P(Y \\leq 3)\\), la probabilità cumulativa:\n\ncum_prob &lt;- ppois(3, lambda = 2)\nprint(cum_prob)\n#&gt; [1] 0.8571\n\n\n39.7.5 Trovare il quantile corrispondente a una probabilità data\nPer trovare il numero massimo di eventi per cui la probabilità cumulativa è al massimo \\(0.8125\\):\n\nquantile &lt;- qpois(0.8125, lambda = 2)\nprint(quantile)\n#&gt; [1] 3\n\n\n39.7.6 Generazione di numeri casuali\nPer generare un campione di 1.000.000 di osservazioni da una distribuzione di Poisson con \\(\\lambda = 2\\):\n\nset.seed(42)\nsample &lt;- rpois(1000000, lambda = 2)\n\n# Calcolo di media e varianza del campione\nmean_sample &lt;- mean(sample)\nvar_sample &lt;- var(sample)\n\nprint(mean_sample)\n#&gt; [1] 2\nprint(var_sample)\n#&gt; [1] 1.996\n\n\nEsempio 39.7 Un esempio classico dell’uso della distribuzione di Poisson viene dalla Seconda Guerra Mondiale.\nIl contesto storico. Tra il 1944 e il 1945, Londra fu colpita da centinaia di missili V1 e V2 lanciati dalla Germania nazista. Le autorità britanniche si chiesero se i bombardamenti seguissero una strategia mirata: i missili venivano forse lanciati intenzionalmente su certi quartieri? O si trattava invece di un comportamento casuale, come se fossero stati distribuiti a caso?\nPer rispondere a questa domanda, il Ministero della Guerra britannico divise Londra in 576 aree di uguale superficie (ogni area misurava 0.25 km²) e registrò quanti missili avevano colpito ciascuna area. I dati furono poi analizzati dal matematico R. D. Clarke, che li pubblicò nel 1946.\nI dati osservati. Ecco una sintesi della distribuzione osservata:\n\n\nMissili per area\nNumero di aree\nFrequenza relativa\n\n\n\n0\n229\n0.398\n\n\n1\n211\n0.367\n\n\n2\n93\n0.161\n\n\n3\n35\n0.061\n\n\n4\n7\n0.012\n\n\n≥5\n1\n0.002\n\n\n\nIl numero medio di missili per area era \\(\\lambda \\approx 0.93\\). L’idea era confrontare queste frequenze con le probabilità teoriche previste da una distribuzione di Poisson con media \\(\\lambda = 0.93\\).\nInterpretazione con la distribuzione di Poisson. Utilizzando la funzione dpois() in R, possiamo calcolare le probabilità teoriche per ciascun valore osservato, da 0 a 4 missili per area (valori superiori sono troppo rari per essere trattati separatamente).\n\n# Parametro medio osservato\nlambda &lt;- 0.93\n\n# Valori possibili di missili per area\ny &lt;- 0:4\n\n# Probabilità teoriche secondo la distribuzione di Poisson\nprob_teoriche &lt;- dpois(y, lambda = lambda)\n\n# Aggiungiamo la probabilità per y &gt;= 5\nprob_teoriche &lt;- c(prob_teoriche, 1 - sum(prob_teoriche))  # y &gt;= 5\n\n# Visualizziamo\ndata.frame(\n  Missili_per_area = c(0:4, \"&gt;=5\"),\n  Probabilita_teorica = round(prob_teoriche, 3)\n)\n#&gt;   Missili_per_area Probabilita_teorica\n#&gt; 1                0               0.395\n#&gt; 2                1               0.367\n#&gt; 3                2               0.171\n#&gt; 4                3               0.053\n#&gt; 5                4               0.012\n#&gt; 6              &gt;=5               0.003\n\nConfrontando le probabilità teoriche della Poisson con quelle osservate nei dati reali, i risultati erano sorprendentemente simili. Questo suggeriva che i missili non erano lanciati su bersagli specifici, ma seguivano un comportamento statisticamente compatibile con una distribuzione casuale.\n\n# Frequenze osservate (dati originali di Clarke, 1946)\nfrequenze_osservate &lt;- c(229, 211, 93, 35, 7, 1)\nvalori_missili &lt;- c(0, 1, 2, 3, 4, \"≥5\")\n\n# Calcolo frequenze teoriche con Poisson (lambda = 0.93)\nlambda &lt;- 0.93\nprob_teoriche &lt;- dpois(0:4, lambda)\nprob_teoriche &lt;- c(prob_teoriche, 1 - sum(prob_teoriche))  # Per y &gt;= 5\n\n# Numero totale di aree (come somma delle osservazioni)\nn_aree &lt;- sum(frequenze_osservate)\n\n# Frequenze attese = probabilità teoriche * numero totale di aree\nfrequenze_attese &lt;- round(prob_teoriche * n_aree)\n\n# Costruzione del data frame\ndf &lt;- data.frame(\n  Missili_per_area = factor(valori_missili, levels = c(\"0\", \"1\", \"2\", \"3\", \"4\", \"≥5\")),\n  Osservate = frequenze_osservate,\n  Attese = frequenze_attese\n)\n\n# Conversione in formato lungo per ggplot2\ndf_long &lt;- reshape2::melt(df, id.vars = \"Missili_per_area\", variable.name = \"Tipo\", value.name = \"Frequenza\")\n\n# Creazione del grafico\nggplot(df_long, aes(x = Missili_per_area, y = Frequenza, fill = Tipo)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(\n    title = \n      \"Distribuzione dei missili su Londra:\\nosservato vs atteso (Poisson)\",\n    x = \"Numero di missili per area\",\n    y = \"Numero di aree\",\n    fill = \"Frequenza\"\n  ) \n\n\n\n\n\n\n\n\nLe barre blu rappresentano le frequenze osservate (quante aree hanno ricevuto 0, 1, 2… missili).\nLe barre rosse mostrano le frequenze attese se i missili fossero stati lanciati in modo completamente casuale, seguendo una distribuzione di Poisson con \\(\\lambda = 0.93\\).\n\nLa sovrapposizione tra i due andamenti è molto buona, il che rafforza l’idea che i bombardamenti fossero distribuiti casualmente — senza un pattern strategico apparente.\nCosa ci insegna questo esempio?\n\nLa distribuzione di Poisson è adatta quando vogliamo modellare eventi rari e indipendenti nello spazio o nel tempo.\nI dati dei missili su Londra mostrano come un fenomeno che a prima vista potrebbe sembrare non casuale (per via della concentrazione locale degli eventi) possa invece essere ben descritto da un modello probabilistico semplice, se considerato su una scala adatta.\n\n\n\nEsempio 39.8 Supponiamo di avere osservato, nel corso degli anni, che la frequenza relativa di bocciature all’esame di Psicometria è di circa 10% (cioè \\(p = 0.1\\)). Tuttavia, il numero di studenti iscritti a ciascun appello varia in modo estremo: al primo appello dell’anno partecipano più di 200 studenti, mentre negli ultimi appelli solo 2 o 3.\nQuesto rende inadeguato l’uso della distribuzione binomiale, che richiede un numero di prove (\\(n\\)) fisso o noto per ciascun appello.\nIn questi casi, possiamo modellare il numero di bocciature per appello usando una distribuzione di Poisson.\nPer ogni appello, possiamo stimare \\(\\lambda\\) moltiplicando il numero di studenti iscritti (\\(n\\)) per la frequenza attesa di bocciature (\\(p = 0.1\\)). A quel punto, il numero di bocciature osservate può essere approssimato da:\n\\[\nY \\sim \\text{Poisson}(\\lambda = n \\cdot p) .\n\\]\nQuindi la distribuzione cambia da appello ad appello, perché \\(\\lambda\\) cambia con \\(n\\), ma il modello rimane Poissoniano.\nSupponiamo di avere osservato i seguenti dati.\n\n\n\n\n\n\n\n\nAppello\nNumero iscritti (\\(n\\))\n\\(\\lambda = n \\cdot p\\)\nDistribuzione di bocciature\n\n\n\n1\n220\n\\(220 \\cdot 0.1 = 22\\)\n\\(Y \\sim \\text{Poisson}(22)\\)\n\n\n2\n95\n\\(95 \\cdot 0.1 = 9.5\\)\n\\(Y \\sim \\text{Poisson}(9.5)\\)\n\n\n8\n3\n\\(3 \\cdot 0.1 = 0.3\\)\n\\(Y \\sim \\text{Poisson}(0.3)\\)\n\n\n\nPer ogni appello, possiamo usare la funzione dpois() in R per calcolare la probabilità di osservare un certo numero di bocciature, dato il valore di \\(\\lambda\\) specifico per quell’appello.\nAd esempio, possiamo chiederci quale sia la probabilità che, nel secondo appello (95 iscritti), si registrino esattamente 8 bocciature.\n\nlambda &lt;- 95 * 0.1  # = 9.5\ndpois(8, lambda = lambda)\n#&gt; [1] 0.1232\n\nQuesta funzione calcola \\(P(Y = 8)\\) per una variabile \\(Y \\sim \\text{Poisson}(9.5)\\), cioè la probabilità di osservare esattamente 8 bocciature su 95 iscritti.\nSupponiamo di voler simulare il numero di bocciature in 8 appelli con numeri di iscritti variabili. Possiamo fare così:\n\nset.seed(42)\n\n# Numero iscritti per ciascun appello\nn_iscritti &lt;- c(220, 95, 60, 45, 20, 12, 6, 3)\n\n# Probabilità storica di bocciatura\np &lt;- 0.1\n\n# Parametri lambda per ogni appello\nlambda &lt;- n_iscritti * p\n\n# Simulazione delle bocciature per ciascun appello\nbocciature &lt;- rpois(length(lambda), lambda = lambda)\n\ndata.frame(\n  Appello = 1:8, \n  Iscritti = n_iscritti, \n  Lambda = lambda, \n  Bocciature = bocciature\n)\n#&gt;   Appello Iscritti Lambda Bocciature\n#&gt; 1       1      220   22.0         28\n#&gt; 2       2       95    9.5          8\n#&gt; 3       3       60    6.0          8\n#&gt; 4       4       45    4.5          5\n#&gt; 5       5       20    2.0          2\n#&gt; 6       6       12    1.2          2\n#&gt; 7       7        6    0.6          0\n#&gt; 8       8        3    0.3          0\n\n📈 Visualizzazione.\n\ndf &lt;- data.frame(Appello = factor(1:8), Bocciature = bocciature)\n\nggplot(df, aes(x = Appello, y = Bocciature)) +\n  geom_col(fill = okabe_ito_palette[2]) +\n  labs(\n    title = \"Bocciature attese per ciascun appello\",\n    x = \"Appello\",\n    y = \"Numero di bocciature\"\n  )\n\n\n\n\n\n\n\nIn sintesi,\n\nquando il numero di studenti iscritti a un appello non è noto a priori o varia fortemente, non è adeguato usare la distribuzione binomiale;\nse conosciamo la frequenza relativa di bocciature (es. \\(p = 0.1\\)), possiamo usare la distribuzione di Poisson con \\(\\lambda = n \\cdot p\\), adattandola a ciascun appello;\nquesto approccio è particolarmente utile per fare stima e simulazione del numero di bocciature attese, senza dover modellare tutti i singoli esiti.\n\n\n\nEsempio 39.9 Uno degli esempi più comuni per introdurre la distribuzione di Poisson riguarda il numero di nascite giornaliere in un ospedale.\nSupponiamo che, in un grande ospedale, la media storica sia di 4.5 nascite al giorno. Possiamo allora descrivere il numero di nascite in un giorno con una variabile casuale Poisson con parametro \\(\\lambda = 4.5\\):\n\\[\nY \\sim \\text{Poisson}(\\lambda = 4.5) .\n\\]\nCi chiediamo, ad esempio: qual è la probabilità che in un giorno nascano esattamente 6 bambini?\nPossiamo calcolarla con la funzione dpois():\n\n# Parametro medio: 4.5 nascite al giorno\nlambda &lt;- 4.5\n\n# Probabilità di osservare esattamente 6 nascite\nprob &lt;- dpois(6, lambda = lambda)\nprint(prob)\n#&gt; [1] 0.1281\n\nQuesto valore rappresenta la probabilità che, in un giorno qualsiasi, si verifichino esattamente 6 nascite.\nSimulazione. Simuliamo ora il numero di nascite in 365 giorni consecutivi, supponendo che la media rimanga costante a 4.5:\n\nset.seed(42)  # Per rendere i risultati riproducibili\n\nn_days &lt;- 365\nsimulated_births &lt;- rpois(n_days, lambda = lambda)\n\n# Proporzione di giorni con esattamente 6 nascite\nproportion_six_births &lt;- mean(simulated_births == 6)\nprint(proportion_six_births)\n#&gt; [1] 0.1397\n\nQuesto ci dice, tra i 365 giorni simulati, quanta parte dell’anno ha avuto esattamente 6 nascite. Il valore ottenuto può essere confrontato con la probabilità teorica calcolata prima.\nVisualizzazione. Possiamo rappresentiamo graficamente i dati simulati con un istogramma:\n\n# Costruzione del data frame\ndata &lt;- data.frame(Nascite = simulated_births)\n\n# Istogramma\nggplot(data, aes(x = Nascite)) +\n  geom_histogram(\n    breaks = seq(-0.5, max(simulated_births) + 0.5, by = 1),\n    fill = okabe_ito_palette[2],\n    color = \"black\"\n  ) +\n  labs(\n    title = \"Distribuzione simulata delle nascite in 365 giorni\",\n    x = \"Numero di nascite per giorno\",\n    y = \"Frequenza (numero di giorni)\"\n  )\n\n\n\n\n\n\n\nL’istogramma mostra quante volte si sono verificati 0, 1, 2, …, 10 o più nascite in un giorno, evidenziando la variabilità naturale attorno alla media.\nCalcoliamo ora quanto è probabile che si verifichino più di 6 nascite in un giorno.\nProbabilità teorica:\n\nprob_more_than_six &lt;- 1 - ppois(6, lambda = lambda)\nprint(prob_more_than_six)\n#&gt; [1] 0.1689\n\nProporzione osservata nella simulazione:\n\nproportion_more_than_six &lt;- mean(simulated_births &gt; 6)\nprint(proportion_more_than_six)\n#&gt; [1] 0.1699\n\nIl confronto tra probabilità teorica e proporzione simulata mostra come la distribuzione di Poisson riproduca bene i fenomeni reali, quando gli eventi sono indipendenti, discreti e relativamente frequenti ma non troppo.\n\n\nEsempio 39.10 Questo esempio è tratto dal celebre lavoro di Ladislaus von Bortkiewicz del 1898, spesso citato come una delle prime applicazioni reali della distribuzione di Poisson.\nVon Bortkiewicz studiò un evento piuttosto inusuale: le morti causate da calci di cavallo all’interno della cavalleria dell’esercito prussiano. L’obiettivo era capire se questi eventi, seppur rari, potessero essere considerati casuali e indipendenti, oppure se fossero distribuiti in modo irregolare e non prevedibile.\nPer farlo, raccolse i dati su 10 squadroni osservati per 20 anni consecutivi, ottenendo così 200 unità di osservazione, che possiamo chiamare “squadroni-anno”.\nI dati raccolti. Per ogni squadrone-anno, fu registrato il numero di morti per calci di cavallo. I dati furono poi raggruppati per numero di decessi:\n\n\n\n\n\n\n\n\nNumero di decessi annui\nFrequenza osservata\nFrequenza relativa\nProbabilità teorica (Poisson)\n\n\n\n0\n109\n0.545\n0.543\n\n\n1\n65\n0.325\n0.331\n\n\n2\n22\n0.110\n0.101\n\n\n3\n3\n0.015\n0.021\n\n\n4\n1\n0.005\n0.003\n\n\n\n\n\nFrequenza osservata: Quante volte ciascun numero di decessi è stato osservato tra i 200 squadroni-anno.\n\nFrequenza relativa: Frequenza osservata divisa per 200.\n\nProbabilità teorica: Calcolata con la distribuzione di Poisson con parametro \\(\\lambda = 0.61\\), pari alla media osservata dei decessi annui.\n\nLa distribuzione di Poisson è perfetta per questo tipo di situazione perché:\n\nstiamo contando il numero di eventi rari (decessi accidentali),\nche si verificano in unità di tempo o spazio fisse (lo “squadrone-anno”),\ne presumiamo che questi eventi siano indipendenti tra loro.\n\nIn questo caso, \\(\\lambda = 0.61\\) rappresenta il numero medio di decessi per squadrone in un anno. La variabilità intorno a questo valore può essere descritta dalla distribuzione di Poisson, che assegna a ciascun possibile numero di decessi (0, 1, 2, …) una probabilità teorica.\nConfronto tra dati osservati e modello di Poisson. Come si può notare dalla tabella, le frequenze osservate sono sorprendentemente simili alle probabilità teoriche ottenute dal modello di Poisson. Ad esempio:\n\nla proporzione di squadroni-anno con zero decessi è 0.545, contro una probabilità teorica di 0.543;\nper un decesso, la frequenza relativa è 0.325, vicina alla probabilità teorica di 0.331;\nanche le classi meno frequenti (2, 3 e 4 decessi) sono coerenti con i valori attesi.\n\nQuesto esempio dimostra che la distribuzione di Poisson non solo è utile per modellare eventi rari, ma fornisce anche una buona descrizione quantitativa del comportamento osservato nel mondo reale.\nIn sintesi,\n\nil lavoro di von Bortkiewicz è uno dei primi esempi storici di modellizzazione di dati reali con la teoria delle probabilità;\nla distribuzione di Poisson si è rivelata efficace nel descrivere un fenomeno raro, ma regolare, suggerendo che i decessi fossero eventi casuali e indipendenti, non dovuti a fattori sistematici;\nancora oggi, questo esempio viene usato per insegnare che anche gli eventi accidentali e poco frequenti possono essere prevedibili in media e descritti in modo elegante da un modello probabilistico.\n\nQui di seguito viene fornito il codice R che riproduce l’analisi di von Bortkiewicz, calcola le probabilità teoriche secondo la distribuzione di Poisson con parametro \\(\\lambda = 0.61\\) e confronta visivamente le frequenze osservate con le frequenze attese.\n\n# Dati osservati da von Bortkiewicz\ndecessi &lt;- 0:4\nfrequenze_osservate &lt;- c(109, 65, 22, 3, 1)\nn_total &lt;- sum(frequenze_osservate)  # Totale = 200 squadroni-anno\n\n# Frequenze relative\nfrequenze_relative &lt;- frequenze_osservate / n_total\n\nCalcolo delle probabilità teoriche con la distribuzione di Poisson:\n\n# Parametro medio osservato\nlambda &lt;- 0.61\n\n# Calcolo delle probabilità teoriche di Poisson\nprob_poisson &lt;- dpois(decessi, lambda = lambda)\n\nConfronto: osservato vs teorico.\n\n# Frequenze attese = probabilità teoriche * numero totale di casi\nfrequenze_attese &lt;- round(prob_poisson * n_total)\n\n# Creazione del data frame per il confronto\ndf &lt;- data.frame(\n  Decessi = factor(decessi),\n  Osservato = frequenze_osservate,\n  Atteso = frequenze_attese\n)\ndf\n#&gt;   Decessi Osservato Atteso\n#&gt; 1       0       109    109\n#&gt; 2       1        65     66\n#&gt; 3       2        22     20\n#&gt; 4       3         3      4\n#&gt; 5       4         1      1\n\nVisualizzazione: confronto tra frequenze osservate e attese.\n\n# Conversione da wide a long format con pivot_longer()\ndf_long &lt;- df |&gt; \n  pivot_longer(\n    cols = c(Osservato, Atteso),\n    names_to = \"Tipo\",\n    values_to = \"Frequenza\"\n  )\n\n# Mostra le prime righe\nhead(df_long)\n#&gt; # A tibble: 6 × 3\n#&gt;   Decessi Tipo      Frequenza\n#&gt;   &lt;fct&gt;   &lt;chr&gt;         &lt;dbl&gt;\n#&gt; 1 0       Osservato       109\n#&gt; 2 0       Atteso          109\n#&gt; 3 1       Osservato        65\n#&gt; 4 1       Atteso           66\n#&gt; 5 2       Osservato        22\n#&gt; 6 2       Atteso           20\n\n\n# Grafico a barre affiancate\nggplot(df_long, aes(x = Decessi, y = Frequenza, fill = Tipo)) +\n  geom_bar(stat = \"identity\", position = \"dodge\", color = \"black\") +\n  labs(\n    title = \"Confronto tra frequenze osservate e attese (Poisson)\",\n    subtitle = expression(lambda == 0.61 ~ \"(von Bortkiewicz, 1898)\"),\n    x = \"Numero di decessi per squadrone-anno\",\n    y = \"Frequenza\",\n    fill = \"Tipo\"\n  ) \n\n\n\n\n\n\n\n\nLe barre blu mostrano i dati osservati da von Bortkiewicz.\nLe barre rosse indicano le frequenze attese se il numero di decessi segue una distribuzione di Poisson con media \\(\\lambda = 0.61\\).\nLa buona corrispondenza visiva tra le due serie supporta l’idea che i decessi siano eventi rari, indipendenti e distribuiti casualmente.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_discr_rv_distr.html#distribuzione-beta-binomiale",
    "href": "chapters/probability/12_discr_rv_distr.html#distribuzione-beta-binomiale",
    "title": "39  Distribuzioni di v.c. discrete",
    "section": "\n39.8 Distribuzione Beta-Binomiale",
    "text": "39.8 Distribuzione Beta-Binomiale\nLa distribuzione beta-binomiale rappresenta una estensione della distribuzione binomiale che tiene conto della variabilità nella probabilità di successo tra i vari tentativi. Viene descritta da tre parametri principali: \\(N\\), \\(\\alpha\\) e \\(\\beta\\).\nNel dettaglio, la funzione di massa di probabilità per la distribuzione beta-binomiale è data da:\n\\[\n\\text{BetaBinomiale}(y | N, \\alpha, \\beta) = \\binom{N}{y} \\cdot \\frac{B(y + \\alpha, N - y + \\beta)}{B(\\alpha, \\beta)},\n\\tag{39.5}\\]\ndove:\n\n\n\\(y\\) indica il numero di successi osservati.\n\n\\(N\\) rappresenta il numero totale di tentativi.\n\n\\(\\alpha\\) e \\(\\beta\\) sono i parametri della distribuzione beta, che modellano la variabilità nella probabilità di successo tra i tentativi.\n\nLa funzione \\(B(u, v)\\), nota come funzione beta, è definita tramite l’uso della funzione gamma \\(\\Gamma\\), secondo la formula:\n\\[\nB(u, v) = \\frac{\\Gamma(u) \\Gamma(v)}{\\Gamma(u + v)},\n\\]\ndove la funzione gamma \\(\\Gamma\\) generalizza il concetto di fattoriale a numeri reali e complessi.\nL’importanza della distribuzione beta-binomiale deriva dalla sua capacità di modellare situazioni in cui la probabilità di successo non è fissa, ma segue una distribuzione di probabilità, specificatamente una distribuzione beta. Ciò la rende particolarmente adatta per applicazioni in cui le probabilità di successo cambiano in maniera incerta da un tentativo all’altro, come può avvenire in contesti di ricerca clinica o in studi comportamentali. Rispetto alla distribuzione binomiale, che assume una probabilità di successo costante per tutti i tentativi, la beta-binomiale offre una rappresentazione più realistica e flessibile per dati empirici che presentano variabilità nelle probabilità di successo.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_discr_rv_distr.html#riflessioni-conclusive",
    "href": "chapters/probability/12_discr_rv_distr.html#riflessioni-conclusive",
    "title": "39  Distribuzioni di v.c. discrete",
    "section": "\n39.9 Riflessioni Conclusive",
    "text": "39.9 Riflessioni Conclusive\nIn questo capitolo, abbiamo approfondito alcune delle distribuzioni discrete più importanti, ognuna con caratteristiche uniche e campi di applicazione specifici. Abbiamo iniziato con la distribuzione di Bernoulli, che modella esperimenti con due soli esiti possibili, per poi passare alla distribuzione Binomiale, che generalizza la Bernoulli considerando un numero fisso di prove indipendenti. Successivamente, abbiamo esaminato la distribuzione di Poisson, utile per descrivere eventi rari in un intervallo di tempo o spazio, e la distribuzione Beta-Binomiale, un’estensione della Binomiale che incorpora la variabilità nella probabilità di successo, rendendola particolarmente adatta per modellare situazioni in cui tale probabilità non è fissa. Infine, abbiamo discusso la distribuzione Discreta Uniforme, che assegna la stessa probabilità a ciascun evento in un insieme finito e discreto.\nQueste distribuzioni rappresentano il fondamento dell’analisi statistica discreta e trovano applicazione in numerosi ambiti. In particolare, nel contesto dell’inferenza bayesiana, la comprensione della distribuzione Binomiale e della sua estensione Beta-Binomiale è essenziale. Queste distribuzioni, infatti, forniscono gli strumenti necessari per l’aggiornamento bayesiano, un processo chiave che permette di rivedere le nostre credenze iniziali alla luce di nuovi dati. Questo concetto sarà ulteriormente esplorato nei capitoli successivi, dove approfondiremo come le distribuzioni a priori e a posteriori interagiscono nel quadro bayesiano.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_discr_rv_distr.html#esercitazione-in-classe",
    "href": "chapters/probability/12_discr_rv_distr.html#esercitazione-in-classe",
    "title": "39  Distribuzioni di v.c. discrete",
    "section": "\n39.10 Esercitazione in Classe",
    "text": "39.10 Esercitazione in Classe\nValutate le emozioni che verranno presentate sullo schermo usando questo link.\nScala di risposta:\n\nRabbia: 1\nDisgusto: 2\nPaura: 3\nFelicità: 4\nTristezza: 5",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_discr_rv_distr.html#esercizi",
    "href": "chapters/probability/12_discr_rv_distr.html#esercizi",
    "title": "39  Distribuzioni di v.c. discrete",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nPer ciascuna delle distribuzioni di massa di probabilità discusse, utilizzare R per:\n\ncreare un grafico della funzione, scegliendo opportunamente i parametri;\nestrarre un campione di 1000 valori casuali dalla distribuzione e visualizzarlo con un istogramma;\ncalcolare la media e la deviazione standard dei campioni e confrontarle con i valori teorici attesi;\nstimare l’intervallo centrale del 94% utilizzando i campioni simulati;\ndeterminare i quantili della distribuzione per gli ordini 0.05, 0.25, 0.75 e 0.95;\nscegliendo un valore della distribuzione pari alla media più una deviazione standard, calcolare la probabilità che la variabile aleatoria assuma un valore minore o uguale a questo valore.\n\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nEsercizi sulla distribuzione binomiale, risolvibili usando R, sono disponibili sulla seguente pagina web.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_discr_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/12_discr_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "title": "39  Distribuzioni di v.c. discrete",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] reshape2_1.4.4   thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0\n#&gt;  [5] see_0.11.0       gridExtra_2.3    patchwork_1.3.0  bayesplot_1.12.0\n#&gt;  [9] psych_2.5.3      scales_1.4.0     markdown_2.0     knitr_1.50      \n#&gt; [13] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [17] purrr_1.0.4      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [21] ggplot2_3.5.2    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] utf8_1.2.5         generics_0.1.4     stringi_1.8.7     \n#&gt;  [4] lattice_0.22-7     hms_1.1.3          digest_0.6.37     \n#&gt;  [7] magrittr_2.0.3     evaluate_1.0.3     grid_4.5.0        \n#&gt; [10] timechange_0.3.0   RColorBrewer_1.1-3 fastmap_1.2.0     \n#&gt; [13] plyr_1.8.9         rprojroot_2.0.4    jsonlite_2.0.0    \n#&gt; [16] mnormt_2.1.1       cli_3.6.5          rlang_1.1.6       \n#&gt; [19] withr_3.0.2        yaml_2.3.10        tools_4.5.0       \n#&gt; [22] parallel_4.5.0     tzdb_0.5.0         pacman_0.5.1      \n#&gt; [25] vctrs_0.6.5        R6_2.6.1           lifecycle_1.0.4   \n#&gt; [28] htmlwidgets_1.6.4  pkgconfig_2.0.3    pillar_1.10.2     \n#&gt; [31] gtable_0.3.6       Rcpp_1.0.14        glue_1.8.0        \n#&gt; [34] xfun_0.52          tidyselect_1.2.1   rstudioapi_0.17.1 \n#&gt; [37] farver_2.1.2       htmltools_0.5.8.1  nlme_3.1-168      \n#&gt; [40] labeling_0.4.3     rmarkdown_2.29     compiler_4.5.0",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_discr_rv_distr.html#bibliografia",
    "href": "chapters/probability/12_discr_rv_distr.html#bibliografia",
    "title": "39  Distribuzioni di v.c. discrete",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlitzstein, J. K., & Hwang, J. (2019). Introduction to probability. CRC Press.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#un-esempio-illustrativo",
    "href": "chapters/linear_models/12_two_proportions.html#un-esempio-illustrativo",
    "title": "74  Confronto tra due proporzioni indipendenti",
    "section": "\n74.7 Un esempio Illustrativo",
    "text": "74.7 Un esempio Illustrativo\nPer mettere in pratica quanto detto, consideriamo un caso reale tratto dallo studio di Banerjee et al. (2025). In questo studio vengono confrontate le abilità matematiche di:\n\n\nbambini lavoratori nei mercati di Kolkata e Delhi;\n\nbambini scolarizzati che non lavorano.\n\nL’obiettivo era valutare se le competenze sviluppate nel lavoro quotidiano (come dare il resto, sommare prezzi, ecc.) si trasferiscono al contesto scolastico e viceversa.\nI risultati principali mostrano come:\n\ni bambini lavoratori si sono dimostrati molto abili nel risolvere problemi matematici concreti, ma hanno faticato con problemi presentati in forma astratta (come quelli scolastici);\nal contrario, i bambini scolarizzati se la sono cavata meglio con problemi astratti, ma sono risultati poco efficaci nei problemi concreti del mercato.\n\nVediamo i dati raccolti per due tipi di problemi:\nProblemi astratti.\n\n\nGruppo\nSuccessi\nProve totali\nProporzione\n\n\n\nBambini lavoratori\n670\n1488\n0.45\n\n\nBambini scolarizzati\n320\n542\n0.59\n\n\n\nProblemi di mercato.\n\n\nGruppo\nSuccessi\nProve totali\nProporzione\n\n\n\nBambini lavoratori\n134\n373\n0.36\n\n\nBambini scolarizzati\n3\n271\n0.01\n\n\n\n\n74.7.1 Confronto per i problemi astratti\nUtilizzando l’approccio frequentista, vogliamo verificare se la differenza tra 0.45 (lavoratori) e 0.59 (scolarizzati) è spiegabile dal caso.\nIpotesi.\n\n\n\\(H_0\\): \\(p_1 = p_2\\) (nessuna differenza tra i gruppi);\n\n\\(H_1\\): \\(p_1 \\ne p_2\\) (esiste una differenza).\n\nCalcolo.\n\n\nProporzione combinata (pooled):\n\\[\n\\hat{p} = \\frac{670 + 320}{1488 + 542} = \\frac{990}{2030} \\approx 0.487.\n\\]\n\n\nVarianza stimata della differenza:\n\\[\n\\text{Var} = \\hat{p}(1 - \\hat{p}) \\left( \\frac{1}{1488} + \\frac{1}{542} \\right) \\approx 0.000629.\n\\]\n\nDeviazione standard: $ $.\n\nStatistica z:\n\\[\nz = \\frac{0.45 - 0.59}{0.0251} \\approx -5.58.\n\\]\n\n\nIl valore z è molto lontano da 0: la probabilità di osservare una tale differenza per caso (p-value) è inferiore a 0.0001. Possiamo quindi rifiutare l’ipotesi nulla.\n\n74.7.2 Confronto per i problemi di mercato\nDati:\n\nLavoratori: 134 su 373 (\\(\\hat{p}_1 = 0.36\\))\nScolarizzati: 3 su 271 (\\(\\hat{p}_2 = 0.01\\))\n\nRipetiamo i passaggi:\n\n\\(\\hat{p} = \\frac{137}{644} \\approx 0.213\\)\n\\(\\text{Var} \\approx 0.001067\\)\nDeviazione standard: \\(\\sqrt{0.001067} \\approx 0.0327\\)\n\nStatistica z:\n\\[\nz = \\frac{0.36 - 0.01}{0.0327} \\approx 10.70\n\\]\n\n\nAnche qui, il p-value è praticamente zero: le differenze sono molto più grandi di quanto ci si aspetti per puro caso.\nIn sintesi, l’approccio frequentista ci consente di:\n\nstimare la differenza tra le proporzioni,\nquantificare l’incertezza (varianza e intervallo di confidenza),\ntestare ipotesi sul fatto che la differenza sia zero o meno.\n\nIn entrambi i confronti (problemi astratti e problemi concreti), abbiamo trovato evidenze chiare di una differenza tra i due gruppi.\n\n74.7.3 Svolgimento con R\nDi seguito mostriamo due modalità per replicare i calcoli in R: (1) passo passo usando le formule manuali, (2) usando la funzione prop.test() di R. Verranno illustrate entrambe le analisi: quella per i problemi astratti e quella per i problemi matematici di mercato.\n\n74.7.3.1 Problemi astratti\nDati\n\nBambini lavoratori (gruppo 1): 670 successi su 1488 prove.\nBambini scolarizzati (gruppo 2): 320 successi su 542 prove.\n\n\n##  Dati\nx_work   &lt;- 670   # successi (risposte corrette) tra i lavoratori\nn_work   &lt;- 1488  # totale lavoratori\n\nx_school &lt;- 320   # successi tra i non-lavoratori (scolarizzati)\nn_school &lt;- 542   # totale non-lavoratori\n\n##  Differenza di proporzioni \np_work   &lt;- x_work   / n_work\np_school &lt;- x_school / n_school\nrd       &lt;- p_school - p_work          \n\n##  Errore standard\n##  - Pooled SE per lo z-test (ipotesi H0: p1 = p2)\n##  - Unpooled SE per l’intervallo di confidenza\np_pool   &lt;- (x_work + x_school) / (n_work + n_school)\nse_test  &lt;- sqrt(p_pool * (1 - p_pool) * (1/n_work + 1/n_school))  # usato solo per lo z-test\nse_ci    &lt;- sqrt(p_work * (1 - p_work) / n_work +\n                 p_school * (1 - p_school) / n_school)  # migliore per il 95 % CI\n\n##  Inferenza\nz        &lt;- rd / se_test\np_value  &lt;- 2 * pnorm(-abs(z))\n\nalpha    &lt;- .05\nz_crit   &lt;- qnorm(1 - alpha/2)\nci_low   &lt;- rd - z_crit * se_ci\nci_high  &lt;- rd + z_crit * se_ci\n\n##  Stampa risultati\ncat(\n  sprintf(\n    \"Differenza assoluta:  %0.3f\\nErrore standard (CI): %0.3f\\nZ-test:            %0.2f\\nP-value:           %.3g\\n95%% CI:            [%0.2f, %0.2f]\\n\",\n    rd, se_ci, z, p_value, ci_low, ci_high\n  )\n)\n#&gt; Differenza assoluta:  0.140\n#&gt; Errore standard (CI): 0.025\n#&gt; Z-test:            5.59\n#&gt; P-value:           2.3e-08\n#&gt; 95% CI:            [0.09, 0.19]\n\nI valori ottenuti, 95% CI: 0.09 to 0.19, replicano quanto riportato da Banerjee et al. (2025) (la piccola differenza tra i risultati dipende dal fatto che gli autori hanno usato un metodo basato sulla regressione):\n\nOverall, 59% of non-working children correctly solved these problems compared with 45% of working children (β = –0.14, s.e.m. = 0.03, 95% CI = –0.20 to –0.08, P &lt; 0.001; Fig. 4, left).\n\n\n74.7.3.2 Analisi con funzione prop.test()\n\nPer ottenere direttamente il test di confronto di due proporzioni, possiamo usare la funzione prop.test di R. Attenzione che, di default, prop.test effettua una correzione per la continuità (Yates), che in questo contesto disattiviamo per confrontare i risultati con i calcoli manuali (impostando correct = FALSE).\n\n# Dati\nx  &lt;- c(670, 320)      # successi   (lavoratori, non-lavoratori)\nn  &lt;- c(1488, 542)     # denominatori\n\n# Test χ² / z-test per p1 = p2  ── senza correzione di continuità\nout &lt;- prop.test(x, n, correct = FALSE)\n\nout\n#&gt; \n#&gt;  2-sample test for equality of proportions without continuity\n#&gt;  correction\n#&gt; \n#&gt; data:  x out of n\n#&gt; X-squared = 31, df = 1, p-value = 2e-08\n#&gt; alternative hypothesis: two.sided\n#&gt; 95 percent confidence interval:\n#&gt;  -0.18864 -0.09163\n#&gt; sample estimates:\n#&gt; prop 1 prop 2 \n#&gt; 0.4503 0.5904\n\nInterpretazione dei risultati.\n\nIl test dell’ipotesi nulla porta al rifiuto di \\(H_0\\), suggerendo che le proporzioni di successo nei due gruppi non sono uguali.\nL’intervallo di confidenza calcolato non include lo zero, indicando che la differenza osservata è incompatibile con l’assenza di effetto.\nPossiamo quindi concludere che esiste una differenza rilevante tra le proporzioni di successo dei bambini lavoratori e di quelli scolarizzati.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Psicometria",
    "section": "",
    "text": "Informazioni Generali",
    "crumbs": [
      "Informazioni Generali"
    ]
  },
  {
    "objectID": "index.html#informazioni-generali",
    "href": "index.html#informazioni-generali",
    "title": "Psicometria",
    "section": "",
    "text": "Anno Accademico: 2024-2025\nCodice Insegnamento: B000286 (coorte L-Z)\nOrario:\n📅 Lunedì e Martedì (8:30-10:30)\n📅 Giovedì (11:30-13:30)\n📍 Plesso Didattico La Torretta",
    "crumbs": [
      "Informazioni Generali"
    ]
  },
  {
    "objectID": "index.html#panoramica-del-corso",
    "href": "index.html#panoramica-del-corso",
    "title": "Psicometria",
    "section": "Panoramica del Corso",
    "text": "Panoramica del Corso\nIl corso offre una formazione teorico-pratica nell’analisi dei dati psicologici, con particolare attenzione alle applicazioni in R. Vengono affrontati temi come analisi descrittiva, esplorazione dei dati, flusso di lavoro, organizzazione di progetti e modelli statistici di base, sia bayesiani che frequentisti. Grande enfasi è posta sulle buone pratiche di Open Science, promuovendo trasparenza e riproducibilità nelle analisi.\nIl corso integra questi argomenti in un percorso didattico che combina lezioni teoriche, esercitazioni pratiche e momenti di riflessione critica. Gli studenti saranno così preparati ad applicare l’analisi dei dati sia in contesti accademici che pratici.\n\n📚 Syllabus dettagliato\n📅 Calendario delle lezioni",
    "crumbs": [
      "Informazioni Generali"
    ]
  },
  {
    "objectID": "index.html#licenza-duso",
    "href": "index.html#licenza-duso",
    "title": "Psicometria",
    "section": "Licenza d’Uso",
    "text": "Licenza d’Uso\n\n\n\nCC BY 4.0\n\n\nI materiali sono rilasciati con licenza CC BY 4.0. È consentito qualsiasi utilizzo previa attribuzione. Per usi commerciali o derivati, consultare le linee guida complete.",
    "crumbs": [
      "Informazioni Generali"
    ]
  }
]