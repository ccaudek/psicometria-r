---
execute:
  freeze: auto
---

# Inferenza bayesiana {#sec-bayes-inference}


::: callout-important
## In questo capitolo approfondirai i seguenti concetti fondamentali:  

- distribuzione marginale;
- approccio analitico e numerico per determinare la distribuzione a posteriori;
- linguaggi di programmazione probabilistici;
- inferenza predittiva.
::: 

::: callout-tip
## Prerequisiti

- Leggere il capitolo *Bayes' Rule* del testo di @Johnson2022bayesrules.
- Leggere *Navigating the Bayes maze: The psychologist's guide to Bayesian statistics, a hands-on tutorial with R code* [@alter2025navigating].
:::

::: callout-caution
## Preparazione del Notebook

```{r}
here::here("code", "_common.R") |> 
  source()
```
:::

## Introduzione

Questo capitolo si propone di approfondire i concetti introdotti nel precedente, presentando in modo formale e dettagliato il processo di **aggiornamento bayesiano**. L'obiettivo è fornire una comprensione chiara e strutturata di come l'inferenza bayesiana possa essere applicata per valutare teorie e modelli scientifici, migliorando la nostra capacità di comprendere e prevedere fenomeni complessi.

### Il Ruolo delle Teorie e dei Modelli nella Scienza

La scienza ha raggiunto alcuni dei suoi più grandi successi attraverso la formulazione di leggi, modelli e teorie che hanno permesso di spiegare e prevedere fenomeni naturali. Ad esempio, le leggi della meccanica di Newton, il modello atomico di Bohr e la teoria della relatività di Einstein hanno rivoluzionato la nostra comprensione della fisica. Allo stesso modo, le leggi dell'ereditarietà di Mendel, la teoria della selezione naturale di Darwin e le scoperte di Crick e Watson nella biologia molecolare hanno chiarito i meccanismi dell'evoluzione e della trasmissione dei tratti genetici. Anche nel campo delle scienze sociali, pionieri come Von Neumann, Savage e Arrow hanno sviluppato teorie della scelta razionale che spiegano il comportamento umano in termini di credenze e preferenze, fornendo un quadro teorico per il processo decisionale in condizioni di incertezza.

Questa breve rassegna non intende sminuire l'importanza del lavoro sperimentale, ma piuttosto sottolineare come teorie e modelli siano strumenti fondamentali per organizzare la conoscenza, fare previsioni e trasferire intuizioni da un dominio all'altro. La valutazione critica di queste teorie e modelli è quindi un aspetto centrale del ragionamento scientifico.

#### L'Inferenza Bayesiana come Strumento per il Ragionamento Scientifico

Questa sezione della dispensa esamina il contributo dell'inferenza bayesiana alla valutazione delle teorie scientifiche. Pur senza sostenere che il ragionamento scientifico sia esclusivamente bayesiano, si propone che i modelli bayesiani possano illuminare numerosi aspetti del processo scientifico, offrendo una comprensione più approfondita dei meccanismi che rendono la scienza così efficace. In questa introduzione, presenteremo i principi fondamentali e le basi filosofiche dell'inferenza bayesiana, nonché alcune tecniche di ragionamento che saranno utili nel corso dei capitoli successivi. 

### La Dimensione Statistica dell'Inferenza Bayesiana: Probabilità e Gradi di Credenza

Nella scienza, così come nella vita quotidiana, spesso ci troviamo a valutare ipotesi con diversi gradi di credibilità. Ad esempio, consideriamo la domanda su quale nazione vincerà il Campionato Mondiale di Calcio del 2026. Potremmo ritenere la Grecia un candidato molto improbabile, l'Inghilterra non del tutto implausibile, e l'Italia, la Francia o la Germania come favoriti. Questo esempio illustra che lo stato epistemico di un'ipotesi non è una questione di "vero o falso", ma piuttosto di gradazione. È qui che entra in gioco l'approccio bayesiano: i bayesiani utilizzano il concetto di **grado di credenza** per descrivere gli atteggiamenti epistemici riguardo a proposizioni incerte, e rappresentano questi gradi di credenza attraverso una struttura matematica specifica: le **funzioni di probabilità**. Questi due presupposti modellistici sono gli elementi centrali dell'inferenza bayesiana.

In altre parole, i bayesiani considerano le probabilità come espressioni di incertezza soggettiva—un'interpretazione che risale a Thomas Bayes (1701–1761). Il calcolo delle probabilità ha una lunga storia come strumento per gestire l'incertezza soggettiva, ed è uno dei paradigmi dominanti nella psicologia del ragionamento umano (ad esempio, Oaksford e Chater, 2000). Le applicazioni scientifiche dell'inferenza bayesiana sono numerose e spaziano dalla filogenetica alla meccanica quantistica, dall'inferenza statistica all'induzione causale (ad esempio, Bernardo e Smith, 1994; Spirtes et al., 2000). Il ragionamento bayesiano è anche ampiamente utilizzato in filosofia, specialmente in epistemologia e nei fondamenti della teoria delle decisioni (ad esempio, Bovens e Hartmann, 2003; Pettigrew, 2015).

L'inferenza bayesiana, grazie alla sua **prominenza** in una vasta gamma di teorie scientifiche e alla sua **versatilità applicativa**, si propone come un **paradigma generale e unificante** per il ragionamento scientifico. La sua capacità di modellare l'incertezza in modo rigoroso e intuitivo la rende uno strumento predefinito per affrontare problemi complessi in contesti multidisciplinari. 

I **successi storici** dei modelli bayesiani, uniti alla loro **ampia diffusione** in campi che spaziano dalla biologia alla fisica, dalla psicologia all'economia, ne evidenziano l'efficacia come framework per lo studio del ragionamento scientifico. Inoltre, considerazioni di natura pratica—come la **semplicità degli assiomi probabilistici** e l'esistenza di una **teoria matematica solida e ben sviluppata**—contribuiscono a rafforzare ulteriormente la validità dell'approccio bayesiano. Queste caratteristiche lo rendono non solo uno strumento potente, ma anche accessibile e coerente, favorendone l'adozione come **filosofia della scienza** capace di integrare e armonizzare diverse discipline sotto un'unica logica di ragionamento.

### La Funzione di Probabilità e il Ruolo delle Proposizioni nel Ragionamento Scientifico

Per comprendere come l'inferenza bayesiana si applichi al ragionamento scientifico, è fondamentale chiarire il concetto di **funzione di probabilità** e il suo legame con le **proposizioni**. Una **funzione di probabilità** $p: \mathcal{L} \rightarrow [0, 1]$ è una struttura matematica che assegna un valore numerico, compreso tra 0 e 1, a ciascuna proposizione all'interno di un **algebra di proposizioni** $\mathcal{L}$. Questo valore rappresenta il **grado di credenza** che un agente razionale attribuisce alla verità di una proposizione, dove 0 indica assenza di credenza e 1 indica certezza assoluta.

#### Cosa Sono le Proposizioni e Come Si Relazionano alle Teorie Scientifiche?

Le **proposizioni** sono enunciati dichiarativi che possono essere veri o falsi. Nel contesto scientifico, le proposizioni spesso rappresentano **ipotesi**, **affermazioni teoriche** o **predizioni** derivate da modelli. Ad esempio, in psicologia, una proposizione potrebbe essere: "Il rinforzo positivo aumenta la probabilità che un comportamento venga ripetuto" ; in fisica, una proposizione potrebbe essere "la velocità della luce nel vuoto è costante"; in biologia, "il DNA è il materiale genetico ereditario"; in economia, "l'aumento della domanda porta a un aumento del prezzo, a parità di altre condizioni". 

Queste proposizioni non sono isolate, ma sono parte di un sistema più ampio di conoscenza, organizzato in **teorie scientifiche**. Una teoria scientifica è un insieme coerente di proposizioni che spiega e predice fenomeni osservabili. L'inferenza bayesiana fornisce un metodo per aggiornare i gradi di credenza nelle proposizioni che compongono una teoria, alla luce di nuove evidenze empiriche.

#### Come Funziona la Funzione di Probabilità?

La funzione di probabilità opera su un'algebra di proposizioni, il che significa che non solo assegna gradi di credenza a singole proposizioni, ma anche a combinazioni logiche di proposizioni (ad esempio, congiunzioni, disgiunzioni e negazioni). Questo è formalizzato attraverso i **tre assiomi della probabilità**:

1. **Normalizzazione**: $p(\top) = 1$, dove $\top$ rappresenta una **tautologia** (una proposizione sempre vera). Questo assioma stabilisce che la massima credenza (1) è assegnata a una proposizione certamente vera.
   
2. **Complementarità**: $p(\neg A) = 1 - p(A)$. Questo assioma esprime che la credenza nella negazione di una proposizione $A$ è complementare alla credenza in $A$ stessa. Se crediamo che $A$ sia vera con probabilità 0.7, allora crediamo che $\neg A$ sia vera con probabilità 0.3.

3. **Additività**: Per un insieme di proposizioni mutualmente esclusive $A_1, A_2, A_3, \ldots$, vale $p\left(\bigvee_{n \in \mathbb{N}} A_n\right) = \sum_{n=1}^{\infty} p(A_n)$. Questo assioma garantisce che la probabilità di una disgiunzione di proposizioni mutualmente esclusive (cioè, che non possono essere vere simultaneamente) sia uguale alla somma delle probabilità delle singole proposizioni.

#### Esempi di Applicazione alle Teorie Scientifiche: Un Caso Psicologico

Consideriamo un esempio tratto dalla **psicologia cognitiva**, in cui una teoria afferma che "l'esposizione a stimoli positivi migliora l'umore e riduce i sintomi della depressione". Questa teoria può essere scomposta in diverse proposizioni, come:

- **$A$**: "L'esposizione a stimoli positivi migliora l'umore."
- **$B$**: "L'esposizione a stimoli positivi riduce i sintomi della depressione."
- **$C$**: "L'effetto degli stimoli positivi è duraturo nel tempo."

Attraverso l'inferenza bayesiana, possiamo assegnare gradi di credenza iniziali (a priori) a ciascuna di queste proposizioni, basandoci su conoscenze pregresse o evidenze preliminari. Ad esempio, supponiamo di avere le seguenti probabilità iniziali:

- $p(A) = 0.7$: crediamo che l'esposizione a stimoli positivi migliori l'umore con una probabilità del 70%.
- $p(B) = 0.5$: siamo meno certi che riduca i sintomi della depressione, assegnando una probabilità del 50%.
- $p(C) = 0.4$: dubitiamo che l'effetto sia duraturo, con una probabilità del 40%.

Ora, supponiamo di condurre un esperimento in cui partecipanti esposti a stimoli positivi mostrano un miglioramento significativo dell'umore e una riduzione dei sintomi depressivi, senza evidenza di effetti temporanei. Alla luce di questi nuovi dati, possiamo aggiornare le nostre credenze utilizzando il teorema di Bayes. 

- Se i dati supportano fortemente la proposizione $A$, la probabilità a posteriori $p(A \mid \text{dati})$ potrebbe aumentare a 0.9.
- Allo stesso modo, se i dati mostrano una chiara riduzione dei sintomi depressivi, la probabilità $p(B \mid \text{dati})$ potrebbe salire a 0.7.
- Tuttavia, se i dati non mostrano effetti duraturi, la probabilità $p(C \mid \text{dati})$ potrebbe rimanere bassa, ad esempio 0.3.

Questo processo di aggiornamento bayesiano ci permette di affinare le nostre credenze in modo dinamico, integrando nuove evidenze empiriche con le conoscenze pregresse. In questo modo, l'inferenza bayesiana non solo quantifica l'incertezza, ma fornisce anche un quadro chiaro e sistematico per valutare la validità delle proposizioni che compongono una teoria scientifica, sia in psicologia che in altre discipline.

#### Perché Questa Struttura è Utile per il Ragionamento Scientifico?

La funzione di probabilità e i suoi assiomi forniscono un **quadro formale e rigoroso** per rappresentare e aggiornare le credenze in modo coerente. Questo è particolarmente utile nel contesto scientifico, dove le teorie sono spesso soggette a revisione alla luce di nuove evidenze. L'approccio bayesiano permette di quantificare l'incertezza e di integrare in modo sistematico informazioni provenienti da diverse fonti, rendendo il processo di aggiornamento delle credenze trasparente e logicamente fondato.

In sintesi, la funzione di probabilità non è solo uno strumento matematico, ma un **ponte tra il linguaggio formale della logica e la pratica scientifica**, permettendo di modellare il ragionamento incerto in modo preciso e intuitivo.

### Argomenti a Favore della Probabilità come Misura di Credenza

Gli argomenti a favore della probabilità come misura di credenza razionale si basano su tre approcci principali, ciascuno dei quali offre una prospettiva diversa ma complementare sul perché i gradi di credenza debbano seguire le regole della probabilità. 

1. **Argomenti della Scommessa Olandese (Dutch Book)**: Questi argomenti mostrano che se una persona ha gradi di credenza che non rispettano le regole della probabilità, può essere indotta a fare scommesse che la portano inevitabilmente a una perdita sicura, indipendentemente dall'esito degli eventi (Ramsey, 1926; De Finetti, 1972; Savage, 1954). In altre parole, credenze non probabilistiche rendono l'individuo vulnerabile a situazioni in cui perderà sempre, il che è considerato irrazionale.

2. **Argomenti Decisionistici**: Questi argomenti si basano sulla teoria della decisione razionale (Savage, 1954; von Neumann/Morgenstern). Secondo questa prospettiva, un agente razionale agisce in modo da massimizzare la propria utilità attesa, calcolata in base ai propri gradi di credenza. Se i gradi di credenza non sono probabilistici, l'agente non può massimizzare correttamente l'utilità attesa, portando a decisioni incoerenti o subottimali.

3. **Argomenti Epistemici**: Questi argomenti si concentrano sull'accuratezza delle credenze rispetto alla verità (Cox, 1946; Joyce, 1998, 2009; Pettigrew, 2016). Sostengono che i gradi di credenza probabilistici sono quelli che minimizzano l'inaccuratezza, nel senso che sono i più vicini alla verità oggettiva. In altre parole, credere in modo probabilistico è il modo migliore per avvicinarsi alla verità.

In sintesi, questi tre tipi di argomenti convergono nel sostenere che i gradi di credenza razionali debbano essere probabilistici. Sebbene nessuno di essi sia definitivo da solo, insieme forniscono un forte sostegno all'idea che la probabilità sia lo strumento giusto per modellare le credenze razionali. L'inferenza bayesiana, che si basa su questi principi, è quindi uno strumento potente per comprendere e formalizzare il ragionamento scientifico e decisionale.

### Il Paradigma dell'Inferenza Bayesiana

L'inferenza bayesiana si basa sull'idea che la probabilità misuri il grado di certezza soggettiva riguardo a un'ipotesi o alla plausibilità di un valore per un parametro sconosciuto. Il cuore di questo approccio è l'**aggiornamento continuo**: le credenze iniziali (**priori**) vengono riviste alla luce di nuove informazioni provenienti dai dati, producendo credenze aggiornate (**posteriori**).

Ad esempio, immaginiamo di lanciare una moneta 10 volte e osservare 8 testa ($y = 8$). Vogliamo stabilire se la moneta sia equilibrata ($p = 0.5$). Per rispondere a questa domanda, definiamo un **modello generativo dei dati**, utilizzando il modello binomiale caratterizzato da $p$, la probabilità di ottenere testa. Questo parametro è l'oggetto della nostra inferenza.

### Approccio Classico: Massima Verosimiglianza

Nel contesto classico, uno dei metodi più utilizzati è la **massima verosimiglianza**, che stima $p$ come il rapporto tra successi e tentativi: $\hat{p} = y/N = 0.8$. Sebbene semplice, questa stima puntuale non fornisce informazioni sull'incertezza di $p$ né sulla plausibilità di valori alternativi.

### Probabilità e Incertezza nell'Approccio Bayesiano

Secondo l'approccio bayesiano, la probabilità rappresenta una misura soggettiva della credibilità di un evento, ipotesi o parametro, basata sull'evidenza disponibile e sulle conoscenze pregresse (Kruschke, 2015). Ad esempio, la probabilità che un nuovo trattamento sia efficace è intesa come il grado di fiducia che attribuiamo a questa ipotesi, considerando sia i dati sia le informazioni pregresse.

La conoscenza a priori su un evento, ipotesi o parametro è descritta da una **distribuzione a priori**, indicata come $p(\theta)$. Questa distribuzione riflette ciò che riteniamo plausibile prima di osservare i dati. Quando raccogliamo nuove informazioni, rivediamo le nostre credenze, ridistribuendo la credibilità su tutto il range di valori possibili del parametro. Questo processo di aggiornamento produce la **distribuzione a posteriori**, denotata come $p(\theta \mid \text{dati})$, che rappresenta la nostra credenza aggiornata (Gelman, Hill e Vehtari, 2020).

Un aspetto filosofico e matematico distintivo dell'approccio bayesiano è la concezione del parametro d'interesse come una variabile casuale che può assumere valori differenti, anziché come un valore fisso (come avviene nel paradigma frequentista). Questa prospettiva permette di trattare il parametro come una distribuzione, fornendo una rappresentazione più flessibile delle incertezze.

Ad esempio, se tracciassimo la distribuzione a posteriori, l'asse $x$ rappresenterebbe l'intero intervallo di valori possibili per il parametro, mentre l'asse $y$ indicherebbe la densità di probabilità associata a ciascun valore. Il valore "utilizzabile" più credibile è spesso quello che massimizza la distribuzione (moda), o la sua media o mediana.

### Approccio Bayesiano: Priori e Posteriori

Il **teorema di Bayes** formalizza il processo di aggiornamento delle credenze, combinando le informazioni iniziali con quelle fornite dai dati. L'equazione fondamentale è:

$$
p(\theta \mid \text{dati}) = \frac{p(\theta) \cdot p(\text{dati} \mid \theta)}{p(\text{dati})},
$$

dove:

- $p(\theta)$ è la distribuzione **a priori**, che rappresenta ciò che sappiamo del parametro prima di osservare i dati.
- $p(\text{dati} \mid \theta)$ è la **verosimiglianza**, che descrive la probabilità di osservare i dati dati i valori ipotizzati del parametro.
- $p(\text{dati})$ è la probabilità marginale dei dati.

La distribuzione **a posteriori** $p(\theta \mid \text{dati})$ riflette la combinazione delle credenze iniziali con le informazioni derivanti dai dati osservati.

**Esempio: Moneta con $y = 8$ e $N = 10$.** Supponiamo di adottare una distribuzione a priori uniforme su $[0, 1]$, che attribuisce la stessa plausibilità a tutti i valori di $p$. Osservando $y = 8$ testa su $N = 10$ lanci, la verosimiglianza $p(y \mid \theta)$ sarà determinata dal modello binomiale. Combinando prior e verosimiglianza attraverso il teorema di Bayes otteniamo:

$$
p(\theta \mid y) \propto p(y \mid \theta) p(\theta).
$$

La distribuzione a posteriori risultante ci consente di:
1. Calcolare stime plausibili di $p$, come la mediana o la moda.
2. Quantificare l'incertezza su $p$, ad esempio tramite varianza o intervalli di credibilità.

Questo processo fornisce un quadro completo che integra informazioni iniziali e nuove evidenze, superando i limiti delle stime puntuali della massima verosimiglianza.

## Un'introduzione ai Priori

### Priori Non Informativi 

Come suggerisce il nome, i **priori non informativi** (Flat Priors) sono generalmente privi di informazioni specifiche. Esistono diverse tipologie di distribuzioni a priori non informative, ma la loro distinzione dettagliata esula dallo scopo di questa trattazione. Sono spesso definiti **flat priors** perché la loro funzione di densità di probabilità appare come una linea orizzontale quando rappresentata graficamente. Questa distribuzione, classificata come uniforme, assegna la stessa probabilità a tutti i possibili valori del parametro, riflettendo così un'ignoranza totale riguardo al parametro (Fox, 2022).

In generale, l'uso di priori non informativi è sconsigliato, a meno che non si abbia effettivamente nessuna conoscenza preliminare o convinzione riguardo ai valori probabili del parametro (Johnson et al., 2022; McElreath, 2020). Infatti, in alcuni casi, l'uso di un prior non informativo porta a una distribuzione a posteriori identica alla funzione di verosimiglianza, con stime dei parametri indistinguibili da quelle ottenute con l'approccio frequentista della massima verosimiglianza. Di conseguenza, l'adozione di un'inferenza bayesiana in tali contesti potrebbe essere non giustificata, poiché il concetto di priors è centrale nella statistica bayesiana.

### Priori Debolmente Informativi 

Spesso non abbiamo una conoscenza precisa del parametro d'interesse, ma solo un'idea generale o vincoli noti (ad esempio, l'associazione positiva tra ore di studio e punteggio in un test di matematica). In tali situazioni, possiamo utilizzare **priori debolmente informativi** (anche detti vaguely informative o default priors). Questi prior incorporano informazioni generali o vincoli sul parametro senza influenzare in modo eccessivo i risultati della posteriori. 

I priori debolmente informativi (Default Priors) rappresentano un compromesso tra l'integrazione di conoscenze pregresse e l'evitare bias significativi, permettendo ai dati di "dominare" i risultati (Fox, 2022; Gelman, Hill e Vehtari, 2020). Sono particolarmente utili quando le informazioni preliminari sono limitate o quando si desidera ridurre al minimo l'impatto di credenze iniziali forti.

### Priori Informativi

Diversamente dai priori debolmente informativi o non informativi, i **priori informativi** trasmettono informazioni deliberate e specifiche sul parametro d'interesse. Questi priori si basano su conoscenze consolidate, risultati di studi precedenti o opinioni di esperti e hanno un'influenza maggiore sulla distribuzione a posteriori rispetto ai priori default o flat (Fox, 2022). 

I priori informativi sono particolarmente utili in presenza di campioni ridotti, poiché restringono lo spazio credibile del parametro e consentono intervalli di incertezza più stretti (Kruschke, 2015). Tuttavia, richiedono una definizione accurata, basata su evidenze solide.

## Costante di Normalizzazione e Priori Coniugati

Nell'equazione del teorema di Bayes:

$$
p(\theta \mid \text{dati}) \propto p(\theta) \cdot p(\text{dati} \mid \theta),
$$

la **costante di normalizzazione**, indicata come $p(\text{dati})$, rappresenta la probabilità incondizionata di osservare i dati. Questo termine, che assicura che le probabilità sommino a 1, è calcolato considerando tutte le possibili combinazioni di dati, indipendentemente dai valori del parametro o dall'ipotesi specifica. La normalizzazione rende le distribuzioni risultanti delle probabilità standardizzate e utilizzabili.

In alcuni casi, combinare un prior con la funzione di verosimiglianza produce una distribuzione a posteriori della stessa famiglia del prior. Ad esempio, se il prior è una distribuzione normale e la verosimiglianza è anch'essa normale, il risultato sarà una distribuzione a posteriori normale. In tali casi, il prior è detto **coniugato** rispetto alla funzione di verosimiglianza (Kruschke, 2015). 

L'uso di priori coniugati semplifica notevolmente i calcoli bayesiani (Fox, 2022), evitando di dover calcolare integrali complessi per la normalizzazione. Tuttavia, quando ciò non è possibile e non esistono soluzioni in forma chiusa, si può ricorrere a metodi approssimativi come il campionamento casuale simulato, noto come **Markov-Chain Monte Carlo (MCMC)**. Questo metodo permette di stimare la distribuzione a posteriori anche in situazioni con parametri multipli o integrali ad alta dimensionalità.

## Implementazione e Calcolo nell’Inferenza Bayesiana

Per calcolare la distribuzione a posteriori nell’inferenza bayesiana, si possono seguire due principali approcci: **analitico** e **numerico**. Entrambi presentano vantaggi e limitazioni, e la scelta dipende dalla complessità del modello e dalla natura dei dati.

### Approccio Analitico (o Coniugato)

L’approccio analitico si basa sulla relazione **coniugata** tra la distribuzione a priori e la funzione di verosimiglianza. In questi casi:

- **Calcolo diretto**: La distribuzione a posteriori può essere determinata esattamente tramite formule matematiche.
- **Efficienza computazionale**: Non richiede metodi iterativi complessi, risultando rapido e semplice.

**Esempio**: Una distribuzione a priori Beta combinata con una verosimiglianza binomiale produce una distribuzione a posteriori ancora Beta. Questo è ideale per modelli semplici come l’inferenza sulla probabilità di successo di una moneta.

**Limitazioni**:

- Applicabile solo a modelli semplici e specifici.
- Non adatto a modelli complessi o dati reali che richiedono maggiore flessibilità.

### Approccio Numerico

Quando il calcolo analitico non è possibile, si utilizzano metodi numerici per approssimare la distribuzione a posteriori. Questi metodi sono più versatili e gestiscono modelli complessi, anche se a un costo computazionale maggiore.

#### Metodi Basati su Catene di Markov Monte Carlo (MCMC)

Gli algoritmi MCMC approssimano la distribuzione a posteriori tramite il campionamento iterativo:

- **Metropolis-Hastings**: Adatto a distribuzioni generiche, richiede la definizione di una funzione proposta.
- **Gibbs Sampling**: Efficace quando le distribuzioni condizionali sono note, anche se la distribuzione congiunta è complicata.

MCMC rappresenta la distribuzione a posteriori come un insieme di campioni, consentendo di stimare forma, centro e variabilità della distribuzione stessa. Con abbastanza iterazioni, questa approssimazione diventa accurata.

**Pratiche comuni in MCMC**:

- **Warm-up (o burn-in)**: Una fase iniziale in cui i campioni sono scartati per consentire all’algoritmo di stabilizzarsi e raggiungere la distribuzione target.
- **Thinning**: Riduce l’autocorrelazione nei campioni selezionando solo uno ogni *n* (es. ogni 5° campione), migliorando l’efficienza e l’indipendenza dei campioni.

### Altri Metodi Numerici

- **Variational Bayes**: Approssima la distribuzione a posteriori risolvendo un problema di ottimizzazione, minimizzando la divergenza di Kullback-Leibler tra una distribuzione proposta $q(z)$ e la distribuzione reale $p(z \mid x)$. È veloce ma meno preciso rispetto a MCMC.
- **Approssimazione di Laplace**: Semplifica la distribuzione a posteriori approssimandola con una normale centrata sul valore MAP, utile ma meno accurata per distribuzioni non gaussiane.

**Vantaggi e Svantaggi degli Approcci Numerici**

- **Vantaggi**:
  - Applicabilità a modelli complessi.
  - Flessibilità nell’incorporare informazioni a priori dettagliate.

- **Svantaggi**:
  - Richiedono risorse computazionali elevate.
  - Necessitano di un tuning accurato degli algoritmi (es. scelte iniziali in MCMC).

### Linguaggi di Programmazione Probabilistica (PPL)

I linguaggi di programmazione probabilistica semplificano l’implementazione dei metodi numerici, automatizzando il processo di inferenza bayesiana. Permettono ai ricercatori di concentrarsi sulla modellizzazione, lasciando ai PPL la gestione dell’inferenza.

#### PPL più Diffusi

- **Stan**: Efficiente e flessibile, ampiamente utilizzato in ambiti accademici.
- **PyMC**: Un’opzione user-friendly per la comunità Python.
- **TensorFlow Probability**: Combina modellizzazione probabilistica e apprendimento automatico.

I PPL consentono di definire il modello probabilistico e delegare l’inferenza agli algoritmi numerici sottostanti (MCMC o inferenza variazionale). Questo rende l’inferenza bayesiana più accessibile e applicabile a una vasta gamma di problemi, inclusi quelli in psicologia.

### Notazione

Nella formulazione dei modelli bayesiani utilizziamo la seguente notazione:

- **$y$**: Dati osservati.
- **$\theta$**: Parametri sconosciuti.
- **$x$**: Quantità note (es. predittori).

Esempio di modello:

$$
\begin{aligned}
y & \sim \mathrm{normal}(\mu, \sigma), \\
\mu & \sim \mathrm{normal}(0, 10), \\
\sigma & \sim \mathrm{normal}^+(\sigma \mid 0, 1),
\end{aligned}
$$

dove il simbolo $\sim$ indica *"è distribuito come"*. La stessa espressione può essere scritta in termini di probabilità:

$$
\begin{aligned}
p(y \mid \mu, \sigma) & = \mathrm{normal}(y \mid \mu, \sigma), \\
p(\mu) & = \mathrm{normal}(\mu \mid 0, 10), \\
p(\sigma) & = \mathrm{normal}^+(\sigma \mid 0, 1).
\end{aligned}
$$

### Approfondimenti sull’MCMC

L’MCMC è un argomento vasto e complesso, con una ricca letteratura dedicata. La sua essenza consiste nel campionamento iterativo dalla distribuzione a posteriori per stimarne forma, centro e variabilità. 

Ogni campione rappresenta un possibile valore del parametro d’interesse, e i campioni successivi dipendono dai precedenti, come i collegamenti di una catena. La convergenza alla distribuzione a posteriori richiede molte iterazioni e più catene per verificare l’affidabilità dell’approssimazione. Nonostante la complessità, l’MCMC è uno strumento indispensabile per l’inferenza bayesiana moderna.

## Riflessioni Conclusive

Al cuore della ricerca scientifica c'è una domanda del tipo: "dimmi qualcosa sulla variabile $\theta$ dato che ho osservato i dati $D$ e ho una certa conoscenza del meccanismo sottostante che genera i dati". La regola di Bayes fornisce la seguente risposta:

$$
p(\theta \mid D) = \frac{p(D \mid\theta) p(\theta)}{p(D)} = \frac{p(D \mid \theta) p(\theta)}{\int_\theta p(D \mid\theta) p(\theta) d\theta}.
$$

Questa equazione mostra come, partendo da un modello generativo $p(D \mid\theta)$ dei dati osservati e abbinato a una credenza a priori $p(\theta)$ su quali valori della variabile $\theta$ siano plausibili, possiamo inferire la distribuzione a posteriori $p(\theta \mid D)$ della variabile alla luce dei dati osservati.

La stima MAP (Massimo A Posteriori), che corrisponde al valore di $\theta$ che massimizza la distribuzione a posteriori, rappresenta una stima puntuale del parametro:

$$
\theta^* = \arg \max_\theta p(\theta \mid D).
$$

Nel caso di un prior non informativo (piatto), la stima MAP coincide con la stima di massima verosimiglianza, ovvero il valore di $\theta$ che massimizza la probabilità che il modello generi i dati osservati.


## Informazioni sull'Ambiente di Sviluppo {.unnumbered} 

```{r}
sessionInfo()
```

## Bibliografia {.unnumbered}

