# Confronto tra le medie di due gruppi {#sec-linear-models-two-groups}

::: callout-note
## In questo capitolo imparerai a

- condurre un confronto bayesiano tra le medie di due gruppi utilizzando la  funzione `brm()` del pacchetto **brms**.
:::

::: callout-tip
## Prerequisiti

- Consultare l'articolo "Bayesian estimation supersedes the t test" [@kruschke2013bayesian]. 
:::

::: callout-important
## Preparazione del Notebook

```{r}
here::here("code", "_common.R") |> 
  source()

# Load packages
if (!requireNamespace("pacman")) install.packages("pacman")
pacman::p_load(cmdstanr, posterior, brms, bayestestR, insight)
```
:::

## Introduzione

Nella ricerca psicologica è comune voler **confrontare due gruppi** per verificare se, ad esempio, uno dei due presenta una media più elevata su una certa variabile. Tuttavia, le differenze osservate nei dati non riflettono sempre differenze reali: possono derivare anche da **fluttuazioni casuali**, errori di misurazione o **variabilità intrinseca nei processi psicologici**. Per valutare in modo rigoroso se una differenza osservata è compatibile con una reale differenza tra gruppi, è necessario ricorrere a un modello statistico.

Il metodo tradizionale prevede l’uso di un **test di ipotesi**, in cui si formula un’**ipotesi nulla** (ad esempio: “non c’è differenza tra i gruppi”) e si calcola una **statistica test** per verificare quanto i dati siano compatibili con essa. Se la statistica supera una soglia prestabilita (tipicamente associata a un livello di significatività), si rifiuta l’ipotesi nulla.

Questo approccio, però, ha alcune limitazioni. Come sottolineano @johnson1999insignificance e @goodman1999toward, la procedura è spesso influenzata da **convenzioni arbitrarie** (come il livello di significatività o la scelta del test) e produce un risultato binario (rifiuto o meno dell’ipotesi nulla), che può essere **di difficile interpretazione** e soggetto a **fraintendimenti**.

### Un'alternativa più informativa: la stima bayesiana

Un approccio più trasparente e informativo consiste nel **passare dal test alla stima**: invece di domandarci *“Esiste una differenza?”*, ci chiediamo *“Quanto è grande la differenza tra i gruppi?”* e *“Quanto siamo incerti su questa stima?”*.

In questo contesto, l’approccio **bayesiano** offre un quadro concettualmente più chiaro, perché consente di quantificare esplicitamente l’**incertezza**. In particolare, distingue due tipi fondamentali di incertezza:

* **Incertezza aleatoria** (*aleatory uncertainty*): è l’incertezza dovuta alla **variabilità intrinseca** nei dati, cioè al fatto che gli individui all’interno di ciascun gruppo sono naturalmente diversi tra loro. È una proprietà del fenomeno osservato.
* **Incertezza epistemica** (*epistemic uncertainty*): riflette la nostra **ignoranza o mancanza di conoscenza** sul vero valore della differenza tra i gruppi. È una proprietà del nostro stato di informazione e può essere ridotta raccogliendo più dati o integrando conoscenze pregresse.

Nel paradigma bayesiano, l’incertezza epistemica è modellata in modo diretto tramite la **distribuzione a posteriori**, che combina i dati osservati con eventuali **conoscenze pregresse** espresse sotto forma di prior. Questo permette di ottenere una stima probabilistica della differenza tra gruppi, assieme a un **intervallo di credibilità**, che indica dove si concentra la maggior parte della nostra incertezza residua.

In questo capitolo, esploreremo come applicare questo approccio per il confronto tra due gruppi, utilizzando strumenti bayesiani che consentono di rappresentare chiaramente ciò che sappiamo — e ciò che non sappiamo — sulla differenza che ci interessa stimare.

## Regressione bayesiana per il confronto tra due gruppi

Dopo aver introdotto l’approccio bayesiano come un’alternativa più informativa rispetto ai test di ipotesi, vediamo ora **come modellare la differenza tra due gruppi** utilizzando un semplice modello di regressione. Anche se il termine "regressione" può sembrare tecnico, in questo contesto si tratta di un modo molto naturale per rappresentare il confronto tra due medie.

Supponiamo di avere una variabile quantitativa $y$ (ad esempio, un punteggio cognitivo o un indice di stress), e di voler confrontare i valori medi di $y$ in due gruppi distinti. Per rappresentare l’appartenenza di ciascun individuo a uno dei due gruppi, introduciamo una **variabile indicatrice (dummy)** $D_i$, definita nel seguente modo:

* $D_i = 0$ per gli individui del **gruppo di riferimento** (ad esempio, il gruppo di controllo),
* $D_i = 1$ per gli individui del **gruppo di confronto** (ad esempio, il gruppo sperimentale).

Il modello assume la forma:

$$
y_i = \alpha + \gamma D_i + \varepsilon_i,
$$

dove:

* $y_i$ è il valore osservato per l’individuo $i$,
* $\alpha$ è la **media del gruppo di riferimento** ($D_i = 0$),
* $\gamma$ rappresenta la **differenza tra le medie** dei due gruppi,
* $\varepsilon_i \sim \mathcal{N}(0, \sigma^2)$ è un termine di errore casuale, che rappresenta la variabilità individuale non spiegata dal gruppo.

In questo modello:

* Se $D_i = 0$, allora $\mu_i = \alpha$, cioè la media del gruppo di riferimento.
* Se $D_i = 1$, allora $\mu_i = \alpha + \gamma$, cioè la media del gruppo di confronto.

Il parametro $\gamma$ è quindi l’elemento centrale dell’inferenza: **misura la differenza tra le due medie**, e l’obiettivo dell’analisi è stimarne il valore e la relativa incertezza.


### Formulazione bayesiana del modello

Nel quadro bayesiano, il confronto tra due gruppi può essere formalizzato nel seguente modo:

$$
\begin{aligned}
y_i &\sim \mathcal{N}(\mu_i, \sigma), \\
\mu_i &= \alpha + \gamma D_i,
\end{aligned}
$$

dove ogni osservazione $y_i$ è modellata come proveniente da una distribuzione normale con media $\mu_i$ e deviazione standard $\sigma$. Il valore della media $\mu_i$ dipende dal gruppo a cui appartiene l’individuo, indicato dalla variabile dummy $D_i$.

Come visto in precedenza:

* per il gruppo di riferimento ($D_i = 0$), la media è $\mu_i = \alpha$;
* per il gruppo di confronto ($D_i = 1$), la media è $\mu_i = \alpha + \gamma$.

Il parametro $\gamma$ esprime quindi la **differenza tra le due medie** e rappresenta il principale oggetto di interesse dell’analisi.

La differenza rispetto all’approccio frequentista non riguarda la forma del modello, che è la stessa, ma l’**interpretazione dell’inferenza**. In ambito frequentista si ottiene una stima puntuale e un intervallo di confidenza, ma non si può attribuire una probabilità alla veridicità di una certa ipotesi sul parametro. Nel paradigma bayesiano, invece, otteniamo una **distribuzione a posteriori** per ciascun parametro, che riflette il nostro grado di incertezza **dopo aver osservato i dati**, integrando anche eventuali informazioni a priori.

Nel caso di $\gamma$, questa distribuzione ci permette di:

* individuare i valori più plausibili per la differenza tra i gruppi;
* stimare direttamente la **probabilità che $\gamma$ sia maggiore o minore di zero**, ossia che esista una vera differenza (in un verso o nell’altro);
* calcolare un **intervallo di credibilità** (ad esempio al 95%), che ci indica dove si concentra la maggior parte della probabilità a posteriori.

In conclusione, la regressione bayesiana con variabile dummy fornisce una struttura semplice ma potente per confrontare due gruppi, arricchita dalla possibilità di rappresentare in modo diretto e trasparente l’incertezza sulla stima della differenza. Questo rende il modello particolarmente utile in ambito psicologico, dove è spesso cruciale ragionare in termini di **gradualità dell’evidenza** e non di risposte sì/no.
Ecco una versione rivista e migliorata della sezione sull’approccio frequentista, con maggiore chiarezza espositiva, uno stile più didattico e una transizione più naturale verso il confronto con l’approccio bayesiano. Tutte le informazioni originali sono mantenute, ma riorganizzate per migliorarne la leggibilità e la comprensione:


## Approccio frequentista

Nel paradigma frequentista, l’inferenza sulla differenza tra due gruppi si basa sulla **distribuzione campionaria** della differenza tra le medie. L’idea di fondo è che, se ripetessimo il campionamento molte volte, otterremmo valori diversi per la differenza tra le medie campionarie, e questa variabilità può essere descritta attraverso una distribuzione probabilistica.

Supponiamo di avere due popolazioni normali e indipendenti:

$$
Y_1 \sim \mathcal{N}(\mu_1, \sigma_1^2) \quad \text{e} \quad Y_2 \sim \mathcal{N}(\mu_2, \sigma_2^2)
$$

e di osservare due campioni indipendenti, rispettivamente di dimensione $n_1$ e $n_2$.

Se assumiamo inoltre che le varianze siano uguali ($\sigma_1^2 = \sigma_2^2 = \sigma^2$), possiamo utilizzare una versione semplificata del modello.

### Statistica di interesse

Il nostro obiettivo è stimare la **differenza tra le medie** delle due popolazioni, ovvero:

$$
\mu_1 - \mu_2.
$$

La stima di questa quantità è data dalla **differenza tra le medie campionarie**:

$$
\bar{Y}_1 - \bar{Y}_2.
$$

### Proprietà della statistica campionaria

#### Valore atteso

Nel caso di due campioni indipendenti:

$$
E(\bar{Y}_1 - \bar{Y}_2) = \mu_1 - \mu_2.
$$

::: {.callout-important title="Dimostrazione" collapse="true"}

Si parte dalla definizione di media campionaria per ciascun gruppo e si applica la linearità dell’operatore valore atteso:

$$
E(\bar{Y}_1 - \bar{Y}_2) = E(\bar{Y}_1) - E(\bar{Y}_2) = \mu_1 - \mu_2.
$$

:::

#### Varianza

La varianza della differenza tra le medie campionarie è:

$$
\operatorname{Var}(\bar{Y}_1 - \bar{Y}_2) = \frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}.
$$

::: {.callout-important title="Dimostrazione" collapse="true"}

Poiché i due campioni sono indipendenti, la varianza della differenza si ottiene sommando le varianze delle due medie:

$$
\operatorname{Var}(\bar{Y}_1) = \frac{\sigma_1^2}{n_1}, \quad \operatorname{Var}(\bar{Y}_2) = \frac{\sigma_2^2}{n_2}
$$

quindi:

$$
\operatorname{Var}(\bar{Y}_1 - \bar{Y}_2) = \frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}.
$$

:::

Se assumiamo varianze uguali ($\sigma_1 = \sigma_2 = \sigma$), possiamo scrivere:

$$
\operatorname{Var}(\bar{Y}_1 - \bar{Y}_2) = \sigma^2 \left( \frac{1}{n_1} + \frac{1}{n_2} \right).
$$

Poiché $\sigma^2$ è sconosciuta, la si stima tramite la **varianza pooled**:

$$
s_p^2 = \frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2},
$$

dove $s_1^2$ e $s_2^2$ sono le varianze campionarie:

$$
s_j^2 = \frac{1}{n_j - 1} \sum_{i=1}^{n_j} (y_{j,i} - \bar{y}_j)^2, \quad j = 1,2.
$$

### Distribuzione della statistica

Sotto l’ipotesi di normalità e indipendenza, e assumendo varianze uguali, la statistica $\bar{Y}_1 - \bar{Y}_2$ segue (almeno approssimativamente) una distribuzione normale:

$$
\bar{Y}_1 - \bar{Y}_2 \sim \mathcal{N} \left( \mu_1 - \mu_2,\ \sigma \sqrt{ \frac{1}{n_1} + \frac{1}{n_2} } \right).
$$

Questa proprietà permette di costruire un **intervallo di confidenza al 95%** per la differenza tra le medie, oppure di effettuare un **test t per due campioni indipendenti**, basato sulla seguente statistica:

$$
t = \frac{(\bar{Y}_1 - \bar{Y}_2) - (\mu_1 - \mu_2)}{s_p \sqrt{ \frac{1}{n_1} + \frac{1}{n_2} }}.
$$

Questa statistica segue, sotto l’ipotesi nulla $\mu_1 = \mu_2$, una distribuzione t di Student con $n_1 + n_2 - 2$ gradi di libertà.


## Differenze interpretative tra approccio frequentista e bayesiano

Il confronto tra i due approcci non riguarda soltanto le formule utilizzate, ma soprattutto il **modo in cui si interpreta il risultato** dell’analisi:

* **Approccio frequentista**: l’intervallo di confidenza al 95% indica che, se ripetessimo l’esperimento moltissime volte, il 95% degli intervalli costruiti in questo modo conterrebbero la vera differenza tra $\mu_1$ e $\mu_2$. Tuttavia, **non possiamo dire** che c’è il 95% di probabilità che un dato intervallo contenga la vera differenza — perché nel frequentismo i parametri sono fissi, e solo i dati sono considerati aleatori.

* **Approccio bayesiano**: l’intervallo di credibilità al 95% indica che, **dato il nostro stato di conoscenza attuale**, c’è il 95% di probabilità che la differenza tra i gruppi si trovi in quell’intervallo. Qui la probabilità è attribuita al **valore stesso del parametro**, che è trattato come una variabile aleatoria soggetta a incertezza epistemica.

Questa distinzione può sembrare sottile, ma ha importanti conseguenze pratiche. Mentre l’approccio frequentista impone un’interpretazione indiretta dell’intervallo (basata su procedure ripetute), quello bayesiano consente di **formulare affermazioni probabilistiche dirette** sui parametri, e quindi **sul fenomeno psicologico in studio**.


### Sintesi

| Aspetto                         | Approccio frequentista                          | Approccio bayesiano                        |
| ------------------------------- | ----------------------------------------------- | ------------------------------------------ |
| Stima della differenza          | $\bar{Y}_1 - \bar{Y}_2$                     | Distribuzione a posteriori di $\gamma$   |
| Incertezza                      | Intervallo di confidenza                        | Intervallo di credibilità                  |
| Interpretazione dell’intervallo | Valido in media su ripetizioni dell’esperimento | Valido condizionatamente ai dati osservati |
| Ruolo del parametro             | Fisso ma ignoto                                 | Variabile aleatoria                        |
| Uso di informazioni pregresse   | Non previsto                                    | Esplicito tramite prior                    |

Nelle sezioni successive vedremo **come implementare entrambi gli approcci in R**, e come confrontare i risultati ottenuti.


## Un esempio illustrativo

Dopo aver introdotto i due approcci — frequentista e bayesiano — e discusso come ciascuno tratti il problema del confronto tra due gruppi, passiamo ora a un esempio concreto che li metta a confronto sullo stesso set di dati.

Analizzeremo un campione di dati relativi al **quoziente intellettivo (QI)** di bambini, suddivisi in due gruppi in base al livello di istruzione delle madri:

* **madri diplomate** (hanno completato la scuola superiore),
* **madri non diplomate** (non hanno completato la scuola superiore).

La **domanda centrale** è: *nella popolazione, il QI medio dei bambini varia a seconda che la madre abbia o meno un diploma?*

Questo esempio ci guiderà attraverso l’implementazione pratica e il confronto tra i due approcci inferenziali.

### Esplorazione iniziale dei dati

Carichiamo i dati e visualizziamo le prime righe per comprenderne la struttura:

```{r}
kidiq <- rio::import(here::here("data", "kidiq.dta"))
kidiq |> 
  head()
```

Esploriamo poi le statistiche descrittive nei due gruppi:

```{r}
kidiq |> 
  group_by(mom_hs) |> 
  summarize(
    avg = mean(kid_score),
    std = sd(kid_score),
    n = n()
)
```

I risultati mostrano:

* **93 bambini** con madri **non diplomate**,
* **341 bambini** con madri **diplomate**,

con QI medi e deviazioni standard diverse tra i due gruppi.

La differenza osservata tra le medie può essere calcolata direttamente:

```{r}
mean(kidiq[kidiq$mom_hs == 1, ]$kid_score) - mean(kidiq[kidiq$mom_hs == 0, ]$kid_score)
```

Questa analisi preliminare suggerisce una differenza tra i gruppi. Ma è sufficiente a concludere che esiste una vera differenza nella popolazione? Per rispondere, confrontiamo i due approcci.


## Confronto tra approccio frequentista e bayesiano

### Approccio frequentista

L’approccio frequentista si fonda sulla **distribuzione campionaria** della differenza tra le medie osservate:

$$
\bar{Y}_1 - \bar{Y}_2 \sim \mathcal{N}\left( \mu_1 - \mu_2,\ \sqrt{ \frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2} } \right).
$$

Se assumiamo **varianze uguali**, stimiamo la varianza comune con la **varianza pooled**:

$$
s_p^2 = \frac{ (n_1 - 1)s_1^2 + (n_2 - 1)s_2^2 }{n_1 + n_2 - 2}.
$$

#### Applicazione ai dati

Usiamo i seguenti valori osservati:

* **madri diplomate**: $n_1 = 341$, $\bar{Y}_1 = 89.3$, $s_1 = 19.0$,
* **madri non diplomate**: $n_2 = 93$, $\bar{Y}_2 = 77.5$, $s_2 = 22.6$.

Calcoliamo la probabilità, sotto l’ipotesi nulla ($\mu_1 = \mu_2$), di osservare una differenza di almeno 5 punti:

```{r}
mean_1 <- 89.3
std_1 <- 19.0
n_1 <- 341

mean_2 <- 77.5
std_2 <- 22.6
n_2 <- 93

pooled_var <- (((n_1 - 1) * std_1^2) + ((n_2 - 1) * std_2^2)) / (n_1 + n_2 - 2)
std_diff <- sqrt(pooled_var / n_1 + pooled_var / n_2)

pnorm(5, mean = 0, sd = std_diff, lower.tail = FALSE)
```

Il risultato rappresenta il **p-value**: la probabilità di osservare una differenza così grande (o più) **se la vera differenza fosse zero**.

### Approccio bayesiano

Nel paradigma bayesiano, non partiamo da un’ipotesi nulla. Invece, costruiamo un **modello probabilistico** che stima direttamente la distribuzione a posteriori della differenza tra i gruppi.

Formuliamo un semplice modello di regressione con variabile dummy:

$$
\begin{aligned}
y_i &\sim \mathcal{N}(\mu_i, \sigma), \\
\mu_i &= \alpha + \gamma D_i,
\end{aligned}
$$

dove:

* $\alpha$ è la media per le madri non diplomate,
* $\gamma$ è la **differenza tra i gruppi** (cioè, l’effetto dell’istruzione della madre),
* $\sigma$ è la deviazione standard residua.

#### Stima del modello

```{r}
#| output: false
fit_1 <- brm(
  kid_score ~ mom_hs, 
  data = kidiq, 
  backend = "cmdstanr",
  silent = 0
)
```

#### Probabilità che la differenza superi 5 punti

```{r}
posterior_samples <- as_draws_df(fit_1)
mean(posterior_samples$b_mom_hs > 5)
```

Questo calcolo fornisce una **stima diretta** della probabilità che la differenza tra i gruppi ($\gamma$) superi 5 punti.


### Visualizzazione delle distribuzioni

```{r}
ggplot(kidiq, aes(x = as.factor(mom_hs), y = kid_score)) +
  geom_violin(trim = FALSE, fill = "skyblue") +
  geom_boxplot(width = 0.1, outlier.shape = NA, fill = "white", color = "black") +
  labs(
    x = "Livello di istruzione della madre",
    y = "QI del bambino",
    title = "Distribuzione dei punteggi QI\nin base all'istruzione materna"
  ) +
  scale_x_discrete(labels = c("0" = "Non diplomata", "1" = "Diplomata"))
```

Il grafico mostra chiaramente una differenza tra i gruppi, con una maggiore concentrazione di punteggi elevati tra i figli di madri diplomate.


### Differenze concettuali tra gli approcci

| Aspetto              | Frequentista                                                         | Bayesiano                                                  |
| -------------------- | -------------------------------------------------------------------- | ---------------------------------------------------------- |
| Ipotesi iniziale     | $\mu_1 = \mu_2$ (ipotesi nulla)                                  | Nessuna ipotesi nulla                                      |
| Obiettivo            | Valutare quanto è improbabile la differenza osservata sotto $H_0$ | Stimare la probabilità della differenza tra gruppi         |
| Interpretazione      | Il p-value è condizionato da $H_0$                                | La probabilità di $\gamma > 5$ è condizionata dai dati |
| Incertezza           | Intervallo di confidenza                                             | Intervallo di credibilità                                  |
| Conoscenza pregressa | Non utilizzata                                                       | Integrabile tramite prior                                  |


### Quale approccio scegliere?

L’approccio **frequentista** è utile quando si vuole valutare la compatibilità dei dati con l’ipotesi di nessuna differenza, ma questa ipotesi è spesso irrealistica: due gruppi difficilmente saranno identici in ogni contesto reale.

L’approccio **bayesiano** offre vantaggi notevoli:

* **non assume** che la differenza sia nulla,
* fornisce stime probabilistiche **dirette e interpretabili**,
* permette di incorporare conoscenze pregresse (o usare prior debolmente informativi),
* quantifica in modo chiaro l’incertezza nella stima della differenza.


### Approfondimenti bayesiani

#### Intervallo di credibilità all’89%

```{r}
bayestestR::hdi(fit_1, parameters = "mom_hs", ci = 0.89)
```

#### Verifica predittiva

```{r}
pp_check(fit_1)
```

Il modello predice abbastanza bene la distribuzione osservata, ma si notano lievi discrepanze nelle code.


## Una parametrizzazione alternativa: modello skew-normal

Per migliorare l’adattamento, usiamo una distribuzione **skew-normal** che consente di modellare l’asimmetria:

```{r}
#| output: false
fit_2 <- brm(
  kid_score ~ mom_hs, 
  family = skew_normal(),
  backend = "cmdstanr", 
  silent = 0,
  data = kidiq
)
```

### Controllo predittivo

```{r}
pp_check(fit_2)
```

Il modello skew-normal mostra un migliore adattamento alle code della distribuzione osservata.

### Stime posteriori

```{r}
draws <- posterior::as_draws(fit_2, variable = "^b_", regex = TRUE)
posterior::summarise_draws(draws, "mean", "sd", "mcse_mean", "mcse_sd")
```

### Intervallo di credibilità per la differenza

```{r}
bayestestR::hdi(fit_2, parameters = "mom_hs", ci = 0.89)
```

### Variabilità spiegata

```{r}
bayes_R2(fit_2)
```


### Sintesi

In questo esempio, entrambi i modelli suggeriscono una differenza nei punteggi QI tra i due gruppi. Tuttavia, l’approccio bayesiano fornisce:

* una **valutazione diretta della probabilità** che la differenza sia superiore a una soglia,
* una rappresentazione **esplicita dell’incertezza**,
* una maggiore **flessibilità modellistica** (es. skew-normal).

In ambito psicologico, dove è spesso più utile stimare la grandezza di un effetto e comprendere il grado di incertezza, l’approccio bayesiano offre strumenti più adatti a una comunicazione chiara, informativa e interpretabile.


## Prior Predictive Checks

Un aspetto cruciale della modellazione bayesiana consiste nel chiedersi: **che tipo di dati ci aspettiamo di osservare sulla base dei soli prior, prima ancora di vedere i dati reali?** Questo processo prende il nome di **prior predictive check**, ovvero controllo predittivo a priori.

Attraverso questo controllo, possiamo **verificare se i prior specificati producono previsioni compatibili con il fenomeno che stiamo studiando**. In pratica, simuliamo dati fittizi partendo esclusivamente dalla distribuzione a priori dei parametri, senza usare alcuna informazione osservata.

In `brms`, questa operazione è analoga ai *posterior predictive checks*, con una differenza fondamentale: istruiamo il pacchetto a **campionare solo dai prior**, ignorando temporaneamente i dati. Questo richiede che **tutti i parametri abbiano prior esplicitamente definiti** e, idealmente, che tali prior siano anche **plausibili**.


### Specifica dei prior

Applichiamo questo processo a un modello gaussiano sui dati `kidiq`. Cominciamo ispezionando i **prior predefiniti** che `brms` seleziona automaticamente:

```{r}
get_prior(kid_score ~ mom_hs, data = kidiq)
```

Li sostituiamo con **prior debolmente informativi** ma più riflessivi, basati su conoscenza generale:

```{r}
prior_gaussian <- 
  prior(normal(90, 20), class = "b", coef = "Intercept") +
  prior(normal(0, 15), class = "b", coef = "mom_hs") +
  prior(cauchy(0, 20), class = "sigma")
```

Questi prior riflettono ipotesi deboli ma ragionevoli:

* **Intercetta (β₀)**: il QI medio della popolazione è plausibilmente intorno a 90, ma lasciamo ampia incertezza.
* **Effetto di `mom_hs` (β₁)**: l'effetto dell’istruzione materna potrebbe essere vicino a zero, ma è libero di essere anche ampio (positivo o negativo).
* **Deviazione standard (σ)**: ci aspettiamo variabilità sostanziale, ma sempre positiva, coerente con il QI.


### Stima del modello con prior espliciti

Fit del modello ai dati, utilizzando i prior appena definiti:

```{r}
#| output: false
fit_3 <- brm(
  bf(kid_score ~ 1 + mom_hs, center = FALSE), 
  data = kidiq,
  prior = prior_gaussian,
  family = gaussian(),
  backend = "cmdstanr", 
  silent = 0
)
```

Visualizziamo le stime posteriori dei parametri $\beta_0$ e $\beta_1$:

```{r}
draws <- posterior::as_draws(fit_3, variable = "^b_", regex = TRUE)
posterior::summarise_draws(draws, "mean", "sd", "mcse_mean", "mcse_sd")
```

### Simulazione dalla distribuzione a priori

Ora eseguiamo un vero e proprio **prior predictive check**: chiediamo a `brms` di ignorare i dati e campionare *solo* dai prior, generando simulazioni sulla base delle ipotesi a priori.

```{r}
#| output: false
fit_4 <- brm(
  bf(kid_score ~ 1 + mom_hs, center = FALSE), 
  data = kidiq,
  prior = prior_gaussian,
  family = gaussian(),
  backend = "cmdstanr", 
  silent = 0,
  sample_prior = "only"
)
```

Poiché i dati non sono utilizzati, i parametri stimati riflettono esattamente i prior:

```{r}
summary(fit_4)
```

### Visualizzazione del prior predictive check

Usiamo `pp_check()` per visualizzare le distribuzioni simulate:

```{r}
pp_check(fit_4, ndraws = 100) + xlim(10, 180)
```

Nel grafico, la distribuzione dei punteggi simulati (in blu) rappresenta le predizioni del modello **prima di vedere i dati**. L’obiettivo è verificare **se queste simulazioni sono compatibili con la scala del fenomeno osservato**.

Nel nostro esempio, i dati simulati si estendono su un range ampio (in linea con la variabilità attesa del QI), ma restano entro limiti plausibili. Questo suggerisce che i prior scelti sono **sufficientemente flessibili** da coprire l’intervallo di valori attesi, senza però generare predizioni assurde (come QI negativi o superiori a 200 con alta probabilità).


### Perché i prior predictive checks sono importanti?

* Ci permettono di **verificare visivamente le implicazioni dei prior** prima di usare i dati.
* Ci aiutano a **diagnosticare prior inadeguati**, troppo vaghi (che generano predizioni implausibili) o troppo stretti (che limitano eccessivamente le possibili inferenze).
* Sono particolarmente utili in contesti con **campioni piccoli o informazione limitata**, in cui i prior possono influenzare fortemente i risultati.

> ⚠️ Anche prior che sembrano ragionevoli “sulla carta” possono produrre risultati irrealistici una volta combinati con la struttura del modello. Per questo motivo, il controllo predittivo a priori è una **verifica fondamentale** nella costruzione di un buon modello bayesiano.


In sintesi, i *prior predictive checks* offrono una lente critica con cui valutare **se ciò che crediamo prima di osservare i dati** è coerente con ciò che potremmo realisticamente osservare. Questa fase, spesso trascurata, rappresenta un passaggio chiave nella costruzione di modelli bayesiani robusti e trasparenti.


## Esempio con prior informativi

Un ulteriore approfondimento dell’approccio bayesiano riguarda l’uso di **prior informativi**, ossia distribuzioni a priori costruite sulla base di evidenze precedenti, conoscenza teorica o risultati di studi passati.

Immaginiamo, ad esempio, che studi precedenti abbiano suggerito che i figli di madri diplomate tendano ad avere, in media, un **QI superiore di circa 10 punti** rispetto ai figli di madri non diplomate. Possiamo incorporare questa conoscenza specificando un prior normale centrato su 10 per il coefficiente associato a `mom_hs`, con una deviazione standard di 5 per rappresentare un’incertezza moderata:

```{r}
#| output: false
fit_5 <- brm(
  kid_score ~ mom_hs,
  data = kidiq,
  prior = c(set_prior("normal(10, 5)", class = "b", coef = "mom_hs")),
  backend = "cmdstanr",
  silent = 0
)
```

```{r}
summary(fit_5)
```

In questo caso, la distribuzione a posteriori per il parametro \$\beta\_1\$ rifletterà una **combinazione dell’evidenza fornita dai dati** e **della conoscenza pregressa espressa nel prior**. Quando i dati sono abbondanti e informativi (come in questo esempio), l’influenza del prior tende a ridursi, ma in campioni più piccoli può risultare sostanziale, rendendo il ruolo del prior ancora più importante.


### Test di ipotesi bayesiano con `hypothesis()`

Il pacchetto `brms` consente di eseguire test di ipotesi direttamente sulla distribuzione a posteriori tramite il comando `hypothesis()`. Questo strumento è particolarmente utile per valutare se un parametro supera (o è inferiore a) una soglia di interesse:

```{r}
hypothesis(fit_1, "mom_hs > 5")
```

Il risultato di questo test fornisce:

* La **probabilità a posteriori** che il parametro sia maggiore di 5,
* L’**intervallo di credibilità** (ad esempio, al 90%) entro cui si trova il parametro con elevata probabilità,
* Una **valutazione sintetica dell’evidenza**, formulata in termini diretti.

A differenza del *p*-value frequentista, che esprime quanto sarebbe raro ottenere un certo risultato *se* l’ipotesi nulla fosse vera, l’approccio bayesiano permette di affermare, ad esempio:

> *C’è una probabilità del 98% che la differenza media tra i gruppi superi i 5 punti.*

Questa modalità comunicativa è **più intuitiva e direttamente interpretabile**, ed evita l’ambiguità che spesso accompagna i *p*-value.


## Riflessioni Conclusive

In questo capitolo abbiamo esplorato il paradigma bayesiano attraverso l’uso del pacchetto **brms**, mostrando passo dopo passo come:

* formulare un modello statistico flessibile,
* specificare prior deboli o informativi,
* eseguire inferenze interpretabili in termini probabilistici,
* diagnosticare il comportamento del modello attraverso verifiche predittive,
* confrontare i risultati bayesiani con l’approccio frequentista.

L’approccio bayesiano si distingue non solo per la forma dei risultati, ma per il **cambio di prospettiva epistemologica** che propone: invece di chiederci se un effetto “esiste” o meno secondo un criterio arbitrario (es. $\alpha = 0.05$), ci invita a formulare e aggiornare credenze sulla base dei dati osservati, e a **quantificare direttamente la nostra incertezza**.

In sintesi, l’inferenza bayesiana:

* consente di ottenere **intervalli di credibilità** con interpretazioni dirette e trasparenti,
* permette di esprimere **probabilità su parametri o ipotesi**, come la probabilità che una differenza sia maggiore di un valore rilevante,
* integra in modo naturale e controllato **informazioni pregresse**, attraverso la scelta dei prior,
* si adatta con grande flessibilità a **modelli più complessi** o a strutture dati non ideali (asimmetrie, varianze eterogenee, piccoli campioni).

Inoltre, strumenti come `pp_check()` e i **prior predictive checks** permettono di validare le assunzioni del modello in modo visivo e intuitivo, facilitando la costruzione di modelli più robusti e coerenti.

> L’approccio bayesiano non è semplicemente un’alternativa tecnica, ma una **cornice concettuale più coerente e informativa** per rispondere a domande complesse nel contesto della ricerca psicologica e sociale.

In conclusione, il pacchetto **brms** rende la modellazione bayesiana accessibile e potente, offrendo un’interfaccia intuitiva per definire, stimare e interpretare modelli complessi. Più che un semplice strumento computazionale, `brms` è un **alleato metodologico** che permette di adottare un modo di ragionare più flessibile, trasparente e rigoroso.

Questo capitolo ha posto le basi per utilizzare il pensiero bayesiano nella pratica, non solo per "ottenere risultati", ma per **pensare in modo più critico e profondo** all’incertezza, alla variabilità e al significato delle evidenze empiriche.

## Informazioni sull'Ambiente di Sviluppo {.unnumbered} 

```{r}
sessionInfo()
```

## Bibliografia {.unnumbered}

