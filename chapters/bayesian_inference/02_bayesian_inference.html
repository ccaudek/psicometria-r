<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="it" xml:lang="it"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<meta name="author" content="Corrado Caudek">
<title>42&nbsp; Inferenza bayesiana</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>

<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../chapters/bayesian_inference/03_subj_prop.html" rel="next">
<link href="../../chapters/bayesian_inference/01_intro_bayes.html" rel="prev">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-f7890bc79a3f65ef06a5b1c5352a79fb.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark-977d937b251e2ed3bf977ac42bcf4d56.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-d49b56d3e35d452f999b5a62cbdb201d.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark-744dfb578d2f27956ecc45a15ae97852.min.css" rel="prefetch" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Nessun risultato",
    "search-matching-documents-text": "documenti trovati",
    "search-copy-link-title": "Copiare il link nella ricerca",
    "search-hide-matches-text": "Nascondere i risultati aggiuntivi",
    "search-more-match-text": "ci sono altri risultati in questo documento",
    "search-more-matches-text": "ulteriori risultati in questo documento",
    "search-clear-button-title": "Pulire",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancellare",
    "search-submit-button-title": "Inviare",
    "search-label": "Ricerca"
  }
}</script><script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script><script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>
</head>
<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Attiva/disattiva la barra laterale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../chapters/bayesian_inference/introduction_bayes_inference.html">Inferenza</a></li><li class="breadcrumb-item"><a href="../../chapters/bayesian_inference/02_bayesian_inference.html"><span class="chapter-number">42</span>&nbsp; <span class="chapter-title">Inferenza bayesiana</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Attiva/disattiva la barra laterale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Ricerca" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../../">Psicometria</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/ccaudek/psicometria-r/" title="Eseguire il codice" class="quarto-navigation-tool px-1" aria-label="Eseguire il codice"><i class="bi bi-github"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Attiva/disattiva la modalitÃ  oscura"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Attiva/disattiva la modalitÃ  lettore">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Ricerca"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Benvenuti</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../prefazione.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Prefazione</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false">
 <span class="menu-text">Calendario</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../programmazione2024.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Incontri</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../chapters/key_notions/introduction_key_notions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Fondamenti</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/key_notions/01_uncertainty.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Abbracciare lâ€™incertezza</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/key_notions/02_key_notions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Concetti chiave</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/key_notions/03_design.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Campionamento, metodologia sperimentale e studi osservazionali</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/key_notions/04_measurement.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">La misurazione in psicologia</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/key_notions/05_data_analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../chapters/R/introduction_r_lang.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">R</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/R/01_r_syntax.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Data Science e R: un approccio moderno allâ€™analisi dei dati</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/R/02_utility_functions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Utility functions in R</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/R/03_r_programming.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Programmazione in R</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/R/04_r_packages.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Pacchetti in R</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/R/05_dplyr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Introduzione a <code>dplyr</code></span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/R/06_quarto.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Quarto</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/R/07_environment.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Lâ€™ambiente di programmazione in R</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/R/08_ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Utilizzo di strumenti AI per la programmazione</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../chapters/eda/introduction_eda.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">EDA</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/01_project_structure.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Le fasi del progetto di analisi dei dati</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/02_data_cleaning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Flusso di lavoro per la pulizia dei dati</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/04_exploring_qualitative_data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Esplorare i dati qualitativi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/05_exploring_numeric_data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Esplorare i dati numerici</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/06_data_visualization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Principi della visualizzazione dei dati</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/07_loc_scale.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Indicatori di tendenza centrale e variabilitÃ </span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/08_correlation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Relazioni tra variabili</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/09_causality.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">CausalitÃ  dai dati osservazionali ðŸ”¸</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/10_estimand.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Estimandi teorici e estimandi empirici ðŸ”¸</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/11_outlier.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Outlier</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/12_pixi.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Flusso di lavoro riproducibile ðŸ”¸</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../chapters/probability/introduction_probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ProbabilitÃ </span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/01_intro_prob.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Interpretazione della probabilitÃ </span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/02_prob_spaces.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Misura di ProbabilitÃ </span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/03_prob_on_general_spaces.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Fondamenti della probabilitÃ </span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/04_conditional_prob.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">ProbabilitÃ  condizionata</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/05_random_var.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Variabili casuali</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/06_expval_var.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">ProprietÃ  delle variabili casuali</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/07_bayes_theorem.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">Il teorema di Bayes</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/08_sampling_distr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">Stime, stimatori e parametri</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/09_joint_prob.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">34</span>&nbsp; <span class="chapter-title">ProbabilitÃ  congiunta</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/10_prob_distributions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">35</span>&nbsp; <span class="chapter-title">Distribuzioni di massa e di densitÃ </span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/11_discr_rv_distr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">36</span>&nbsp; <span class="chapter-title">Distribuzioni di v.c. discrete</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/12_cont_rv_distr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">37</span>&nbsp; <span class="chapter-title">Distribuzioni di v.c. continue</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/13_gauss.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">38</span>&nbsp; <span class="chapter-title">Assunzione di gaussianitÃ  e trasformazioni dei dati</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/14_likelihood.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">39</span>&nbsp; <span class="chapter-title">La verosimiglianza</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/15_simulation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">40</span>&nbsp; <span class="chapter-title">Simulazioni</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">Inferenza</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/introduction_bayes_inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/01_intro_bayes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">41</span>&nbsp; <span class="chapter-title">La quantificazione dellâ€™incertezza</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/02_bayesian_inference.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">42</span>&nbsp; <span class="chapter-title">Inferenza bayesiana</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/03_subj_prop.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">43</span>&nbsp; <span class="chapter-title">Pensare ad una proporzione in termini soggettivi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/04_grid_gauss.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">44</span>&nbsp; <span class="chapter-title">Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/05_conjugate_families_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">45</span>&nbsp; <span class="chapter-title">Distribuzioni coniugate (1)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/06_conjugate_families_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">46</span>&nbsp; <span class="chapter-title">Distribuzioni coniugate (2)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/07_summary_posterior.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">47</span>&nbsp; <span class="chapter-title">Sintesi a posteriori</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/08_balance_prior_post.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">48</span>&nbsp; <span class="chapter-title">Lâ€™influenza della distribuzione a priori</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/09_gamma_poisson_model.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">49</span>&nbsp; <span class="chapter-title">Modello coniugato Gamma-Poisson ðŸ”¸</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/10_gamma_exponential_model.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">50</span>&nbsp; <span class="chapter-title">Modello gamma-esponenziale ðŸ”¸</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/11_post_pred_distr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">51</span>&nbsp; <span class="chapter-title">Distribuzione predittiva a posteriori</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="false">
 <span class="menu-text">MCMC</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/introduction_mcmc.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/01_metropolis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">52</span>&nbsp; <span class="chapter-title">Lâ€™algoritmo di Metropolis-Hastings</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/02_ppl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">53</span>&nbsp; <span class="chapter-title">Linguaggi di programmazione probabilistici</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/03_stan_language.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">54</span>&nbsp; <span class="chapter-title">Linguaggio Stan ðŸ”¸</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/04_stan_summary_posterior.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">55</span>&nbsp; <span class="chapter-title">Metodi di sintesi della distribuzione a posteriori ðŸ”¸</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/06_mcmc_prediction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">56</span>&nbsp; <span class="chapter-title">La predizione bayesiana ðŸ”¸</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/07_bayesian_workflow.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">57</span>&nbsp; <span class="chapter-title">Flusso di lavoro bayesiano</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/18_cmdstanr_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">58</span>&nbsp; <span class="chapter-title">Introduzione a CmdStanR ðŸ”¸</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="false">
 <span class="menu-text">Regressione</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/introduction_linear_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/01_reglin_frequentist.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">59</span>&nbsp; <span class="chapter-title">La regressione lineare bivariata: un approccio frequentista</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/02_reglin_bayes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">60</span>&nbsp; <span class="chapter-title">Modello bayesiano di regressione lineare bivariata</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/03_synt_sugar.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">61</span>&nbsp; <span class="chapter-title">Zucchero sintattico</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/04_one_mean.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">62</span>&nbsp; <span class="chapter-title">Inferenza bayesiana su una media</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/05_one_mean_stan.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">63</span>&nbsp; <span class="chapter-title">Inferenza bayesiana su una media (Stan) ðŸ”¸</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/06_prediction_stan.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">64</span>&nbsp; <span class="chapter-title">Predizione e inferenza ðŸ”¸</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/07_two_means.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">65</span>&nbsp; <span class="chapter-title">Confronto tra le medie di due gruppi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/08_two_means_stan.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">66</span>&nbsp; <span class="chapter-title">Confronto tra due gruppi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/09_sample_size.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">67</span>&nbsp; <span class="chapter-title">Disegno della ricerca e potere statistico</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/10_anova_1via.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">68</span>&nbsp; <span class="chapter-title">ANOVA ad una via</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/11_anova_2vie.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">69</span>&nbsp; <span class="chapter-title">ANOVA ad due vie</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="false">
 <span class="menu-text">Entropia</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/entropy/introduction_entropy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/entropy/01_entropy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">70</span>&nbsp; <span class="chapter-title">Entropia</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="false">
 <span class="menu-text">Frequentismo</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/frequentist_inference/introduction_frequentist_inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/frequentist_inference/01_intro_frequentist.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">71</span>&nbsp; <span class="chapter-title">Introduzione allâ€™inferenza frequentista</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/frequentist_inference/02_conf_interv.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">72</span>&nbsp; <span class="chapter-title">Intervalli di fiducia</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/frequentist_inference/03_sample_size.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">73</span>&nbsp; <span class="chapter-title">La grandezza del campione</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/frequentist_inference/04_test_ipotesi.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">74</span>&nbsp; <span class="chapter-title">SignificativitÃ  statistica</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/frequentist_inference/05_two_ind_samples.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">75</span>&nbsp; <span class="chapter-title">Test t di Student per campioni indipendenti</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="false">
 <span class="menu-text">Crisi</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-11" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/introduction_replication_crisis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/01_crisis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">76</span>&nbsp; <span class="chapter-title">La crisi della replicazione</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/02_limits_stat_freq.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">77</span>&nbsp; <span class="chapter-title">Limiti dellâ€™inferenza frequentista</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/03_effect_size.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">78</span>&nbsp; <span class="chapter-title">La grandezza dellâ€™effetto</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/04_s_m_errors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">79</span>&nbsp; <span class="chapter-title">Errori di segno e errori di grandezza</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/05_p_values.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">80</span>&nbsp; <span class="chapter-title">La fragilitÃ  del <em>p</em>-valore</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/06_changes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">81</span>&nbsp; <span class="chapter-title">Riforma</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/07_piranha.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">82</span>&nbsp; <span class="chapter-title">Il Problema del priming: sfide e paradossi nella psicologia sociale</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/08_integrity.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">83</span>&nbsp; <span class="chapter-title">IntegritÃ  della ricerca</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="false">
 <span class="menu-text">Epilogo</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-12" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/epiloque/epiloque.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Considerazioni Conclusive</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" role="navigation" aria-expanded="false">
 <span class="menu-text">Appendice</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-13" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a02_shell.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">84</span>&nbsp; <span class="chapter-title">La Shell</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a10_math_symbols.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">85</span>&nbsp; <span class="chapter-title">Simbologia di base</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a11_numbers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">86</span>&nbsp; <span class="chapter-title">Numeri e intervalli</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a12_sum_notation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">87</span>&nbsp; <span class="chapter-title">Sommatorie</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a13_sets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">88</span>&nbsp; <span class="chapter-title">Insiemi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a14_combinatorics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">89</span>&nbsp; <span class="chapter-title">Calcolo combinatorio</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a15_calculus.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">90</span>&nbsp; <span class="chapter-title">Per liberarvi dai terrori preliminari</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a44_montecarlo.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">91</span>&nbsp; <span class="chapter-title">Simulazione Monte Carlo</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a46_stan_lang.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">92</span>&nbsp; <span class="chapter-title">Linguaggio Stan</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a50_lin_fun.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">93</span>&nbsp; <span class="chapter-title">La funzione lineare</span></span></a>
  </div>
</li>
      </ul>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Indice</h2>
   
  <ul>
<li><a href="#introduzione" id="toc-introduzione" class="nav-link active" data-scroll-target="#introduzione"><span class="header-section-number">42.1</span> Introduzione</a></li>
  <li>
<a href="#paradigma-bayesiano" id="toc-paradigma-bayesiano" class="nav-link" data-scroll-target="#paradigma-bayesiano"><span class="header-section-number">42.2</span> Paradigma Bayesiano</a>
  <ul class="collapse">
<li><a href="#vantaggi-dellapproccio-bayesiano" id="toc-vantaggi-dellapproccio-bayesiano" class="nav-link" data-scroll-target="#vantaggi-dellapproccio-bayesiano"><span class="header-section-number">42.2.1</span> Vantaggi dellâ€™Approccio Bayesiano</a></li>
  </ul>
</li>
  <li>
<a href="#densit%C3%A0-di-probabilit%C3%A0" id="toc-densitÃ -di-probabilitÃ " class="nav-link" data-scroll-target="#densit%C3%A0-di-probabilit%C3%A0"><span class="header-section-number">42.3</span> DensitÃ  di ProbabilitÃ </a>
  <ul class="collapse">
<li><a href="#le-regole-di-somma-e-prodotto" id="toc-le-regole-di-somma-e-prodotto" class="nav-link" data-scroll-target="#le-regole-di-somma-e-prodotto"><span class="header-section-number">42.3.1</span> Le Regole di Somma e Prodotto</a></li>
  <li><a href="#la-distribuzione-marginale" id="toc-la-distribuzione-marginale" class="nav-link" data-scroll-target="#la-distribuzione-marginale"><span class="header-section-number">42.3.2</span> La Distribuzione Marginale</a></li>
  <li><a href="#il-teorema-di-bayes" id="toc-il-teorema-di-bayes" class="nav-link" data-scroll-target="#il-teorema-di-bayes"><span class="header-section-number">42.3.3</span> Il Teorema di Bayes</a></li>
  <li><a href="#modellizzazione-e-inferenza-bayesiana" id="toc-modellizzazione-e-inferenza-bayesiana" class="nav-link" data-scroll-target="#modellizzazione-e-inferenza-bayesiana"><span class="header-section-number">42.3.4</span> Modellizzazione e Inferenza Bayesiana</a></li>
  <li><a href="#il-modello-osservazionale" id="toc-il-modello-osservazionale" class="nav-link" data-scroll-target="#il-modello-osservazionale"><span class="header-section-number">42.3.5</span> Il Modello Osservazionale</a></li>
  <li><a href="#la-distribuzione-a-priori" id="toc-la-distribuzione-a-priori" class="nav-link" data-scroll-target="#la-distribuzione-a-priori"><span class="header-section-number">42.3.6</span> La Distribuzione a Priori</a></li>
  <li><a href="#inferenza-sui-parametri" id="toc-inferenza-sui-parametri" class="nav-link" data-scroll-target="#inferenza-sui-parametri"><span class="header-section-number">42.3.7</span> Inferenza sui Parametri</a></li>
  <li><a href="#inferenza-bayesiana-in-sintesi-verosimiglianza-prior-posteriore" id="toc-inferenza-bayesiana-in-sintesi-verosimiglianza-prior-posteriore" class="nav-link" data-scroll-target="#inferenza-bayesiana-in-sintesi-verosimiglianza-prior-posteriore"><span class="header-section-number">42.3.8</span> Inferenza bayesiana in sintesi: verosimiglianza, prior, posteriore</a></li>
  <li><a href="#il-ruolo-dei-priors" id="toc-il-ruolo-dei-priors" class="nav-link" data-scroll-target="#il-ruolo-dei-priors"><span class="header-section-number">42.3.9</span> Il Ruolo dei Priors</a></li>
  </ul>
</li>
  <li><a href="#inferenza-predittiva" id="toc-inferenza-predittiva" class="nav-link" data-scroll-target="#inferenza-predittiva"><span class="header-section-number">42.4</span> Inferenza Predittiva</a></li>
  <li>
<a href="#come-possiamo-eseguire-linferenza-bayesiana" id="toc-come-possiamo-eseguire-linferenza-bayesiana" class="nav-link" data-scroll-target="#come-possiamo-eseguire-linferenza-bayesiana"><span class="header-section-number">42.5</span> Come possiamo eseguire lâ€™inferenza bayesiana?</a>
  <ul class="collapse">
<li><a href="#metodi-numerici" id="toc-metodi-numerici" class="nav-link" data-scroll-target="#metodi-numerici"><span class="header-section-number">42.5.1</span> Metodi Numerici</a></li>
  </ul>
</li>
  <li>
<a href="#programmazione-probabilistica" id="toc-programmazione-probabilistica" class="nav-link" data-scroll-target="#programmazione-probabilistica"><span class="header-section-number">42.6</span> Programmazione Probabilistica</a>
  <ul class="collapse">
<li><a href="#vantaggi-della-programmazione-probabilistica-in-psicologia" id="toc-vantaggi-della-programmazione-probabilistica-in-psicologia" class="nav-link" data-scroll-target="#vantaggi-della-programmazione-probabilistica-in-psicologia"><span class="header-section-number">42.6.1</span> Vantaggi della Programmazione Probabilistica in Psicologia</a></li>
  <li><a href="#come-funzionano-i-ppl" id="toc-come-funzionano-i-ppl" class="nav-link" data-scroll-target="#come-funzionano-i-ppl"><span class="header-section-number">42.6.2</span> Come Funzionano i PPL?</a></li>
  </ul>
</li>
  <li><a href="#notazione" id="toc-notazione" class="nav-link" data-scroll-target="#notazione"><span class="header-section-number">42.7</span> Notazione</a></li>
  <li><a href="#addendum-la-verosimiglianza-marginale" id="toc-addendum-la-verosimiglianza-marginale" class="nav-link" data-scroll-target="#addendum-la-verosimiglianza-marginale"><span class="header-section-number">42.8</span> Addendum: La Verosimiglianza Marginale</a></li>
  <li>
<a href="#implementazione-in-r" id="toc-implementazione-in-r" class="nav-link" data-scroll-target="#implementazione-in-r"><span class="header-section-number">42.9</span> Implementazione in R</a>
  <ul class="collapse">
<li><a href="#caso-discreto" id="toc-caso-discreto" class="nav-link" data-scroll-target="#caso-discreto"><span class="header-section-number">42.9.1</span> Caso discreto</a></li>
  <li><a href="#caso-continuo" id="toc-caso-continuo" class="nav-link" data-scroll-target="#caso-continuo"><span class="header-section-number">42.9.2</span> Caso continuo</a></li>
  <li><a href="#caso-continuo-con-prior-beta" id="toc-caso-continuo-con-prior-beta" class="nav-link" data-scroll-target="#caso-continuo-con-prior-beta"><span class="header-section-number">42.9.3</span> Caso continuo con prior Beta</a></li>
  </ul>
</li>
  <li><a href="#riflessioni-conclusive" id="toc-riflessioni-conclusive" class="nav-link" data-scroll-target="#riflessioni-conclusive"><span class="header-section-number">42.10</span> Riflessioni Conclusive</a></li>
  <li><a href="#informazioni-sullambiente-di-sviluppo" id="toc-informazioni-sullambiente-di-sviluppo" class="nav-link" data-scroll-target="#informazioni-sullambiente-di-sviluppo">Informazioni sullâ€™Ambiente di Sviluppo</a></li>
  <li><a href="#bibliografia" id="toc-bibliografia" class="nav-link" data-scroll-target="#bibliografia">Bibliografia</a></li>
  </ul><div class="toc-actions"><ul><li><a href="https://github.com/ccaudek/psicometria-r/blob/main/chapters/bayesian_inference/02_bayesian_inference.qmd" class="toc-action"><i class="bi bi-github"></i>Mostra il codice</a></li><li><a href="https://github.com/ccaudek/psicometria-r/issues/new" class="toc-action"><i class="bi empty"></i>Segnala un problema</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../chapters/bayesian_inference/introduction_bayes_inference.html">Inferenza</a></li><li class="breadcrumb-item"><a href="../../chapters/bayesian_inference/02_bayesian_inference.html"><span class="chapter-number">42</span>&nbsp; <span class="chapter-title">Inferenza bayesiana</span></a></li></ol></nav><div class="quarto-title">
<h1 class="title"><span id="sec-bayes-inference" class="quarto-section-identifier"><span class="chapter-number">42</span>&nbsp; <span class="chapter-title">Inferenza bayesiana</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header><p><strong>Prerequisiti</strong></p>
<ul>
<li>Leggere il capitolo <em>Bayesâ€™ Rule</em> del testo di <span class="citation" data-cites="Johnson2022bayesrules">Johnson et al. (<a href="#ref-Johnson2022bayesrules" role="doc-biblioref">2022</a>)</span>.</li>
</ul>
<p><strong>Concetti e Competenze Chiave</strong></p>
<ul>
<li>Distribuzione marginale.</li>
<li>Approccio analitico e numerico per determinare la distribuzione a posteriori.</li>
<li>Linguaggi di programmazione probabilistici.</li>
<li>Inferenza predittiva.</li>
</ul>
<p><strong>Preparazione del Notebook</strong></p>
<div class="cell">
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">here</span><span class="fu">::</span><span class="fu"><a href="https://here.r-lib.org//reference/here.html">here</a></span><span class="op">(</span><span class="st">"code"</span>, <span class="st">"_common.R"</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/source.html">source</a></span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Load packages</span></span>
<span><span class="kw">if</span> <span class="op">(</span><span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/base/ns-load.html">requireNamespace</a></span><span class="op">(</span><span class="st">"pacman"</span><span class="op">)</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/utils/install.packages.html">install.packages</a></span><span class="op">(</span><span class="st">"pacman"</span><span class="op">)</span></span>
<span><span class="fu">pacman</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/pacman/man/p_load.html">p_load</a></span><span class="op">(</span><span class="va">mice</span><span class="op">)</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="introduzione" class="level2" data-number="42.1"><h2 data-number="42.1" class="anchored" data-anchor-id="introduzione">
<span class="header-section-number">42.1</span> Introduzione</h2>
<p>Questo capitolo approfondisce i concetti introdotti nel capitolo precedente, presentando lâ€™aggiornamento bayesiano in modo piÃ¹ formale e dettagliato.</p>
</section><section id="paradigma-bayesiano" class="level2" data-number="42.2"><h2 data-number="42.2" class="anchored" data-anchor-id="paradigma-bayesiano">
<span class="header-section-number">42.2</span> Paradigma Bayesiano</h2>
<p>Lâ€™approccio bayesiano alla statistica si fonda sullâ€™idea di rappresentare la conoscenza a priori sui parametri che governano un fenomeno attraverso distribuzioni di probabilitÃ . Queste distribuzioni a priori riflettono le credenze iniziali del ricercatore riguardo ai parametri, prima di osservare i dati. Quando nuovi dati vengono raccolti, lâ€™informazione fornita da tali dati viene integrata nel modello tramite la funzione di verosimiglianza, che rappresenta la probabilitÃ  di osservare quei dati dati i parametri ipotizzati.</p>
<p>Attraverso lâ€™applicazione del Teorema di Bayes, le credenze a priori vengono aggiornate combinando la distribuzione a priori con la verosimiglianza dei dati. Questo processo produce la distribuzione a posteriori, che rappresenta una nuova e piÃ¹ informata stima dei parametri, tenendo conto sia delle credenze iniziali sia dei dati osservati.</p>
<p>Lâ€™approccio bayesiano richiede un cambiamento di prospettiva rispetto ai metodi classici di stima dei parametri. Non ci si limita piÃ¹ a trovare un singolo valore â€œottimaleâ€ per i parametri del modello. Invece, lâ€™obiettivo Ã¨ determinare lâ€™intera distribuzione a posteriori dei parametri, che descrive in modo completo lo stato di conoscenza attuale. Solo questa distribuzione fornisce una rappresentazione adeguata dellâ€™incertezza associata ai parametri, permettendo di quantificare non solo quali valori sono piÃ¹ probabili, ma anche lâ€™ampiezza dellâ€™incertezza su tali stime.</p>
<section id="vantaggi-dellapproccio-bayesiano" class="level3" data-number="42.2.1"><h3 data-number="42.2.1" class="anchored" data-anchor-id="vantaggi-dellapproccio-bayesiano">
<span class="header-section-number">42.2.1</span> Vantaggi dellâ€™Approccio Bayesiano</h3>
<p>Un aspetto distintivo dellâ€™inferenza bayesiana Ã¨ la sua capacitÃ  di gestire lâ€™incertezza in modo esplicito. Invece di limitarsi a una singola stima puntuale, lâ€™approccio bayesiano considera lâ€™intero spettro di valori possibili per i parametri e le loro rispettive probabilitÃ . Questo consente una rappresentazione piÃ¹ ricca delle informazioni disponibili e una valutazione piÃ¹ robusta delle ipotesi.</p>
<p>Inoltre, lâ€™approccio bayesiano Ã¨ altamente flessibile, permettendo di incorporare informazioni precedenti sotto forma di distribuzioni a priori. In contesti in cui si dispone di conoscenze pregresse, come dati di studi precedenti o teorie consolidate, questa caratteristica offre un vantaggio notevole rispetto agli approcci frequentisti, che non integrano facilmente tali informazioni.</p>
<p>In conclusione, il paradigma bayesiano offre una visione piÃ¹ ampia e completa dellâ€™incertezza e della variabilitÃ  dei parametri rispetto ai metodi tradizionali, rappresentando un quadro teorico e pratico fondamentale per lâ€™inferenza statistica e la modellazione.</p>
</section></section><section id="densitÃ -di-probabilitÃ " class="level2" data-number="42.3"><h2 data-number="42.3" class="anchored" data-anchor-id="densitÃ -di-probabilitÃ ">
<span class="header-section-number">42.3</span> DensitÃ  di ProbabilitÃ </h2>
<p>Nei capitoli precedenti abbiamo esaminato alcuni esempi di <font color="orange">funzioni di densitÃ  di probabilitÃ  (PDF)</font>. Ma quali sono le caratteristiche generali di una PDF?</p>
<p>Se <span class="math inline">\(X\)</span> Ã¨ una variabile casuale con una funzione di densitÃ  di probabilitÃ  <span class="math inline">\(p(x)\)</span>, la probabilitÃ  che <span class="math inline">\(X\)</span> assuma un valore nellâ€™intervallo <span class="math inline">\((a, b)\)</span> puÃ² essere calcolata come:</p>
<p><span class="math display">\[
p(X \in (a,b)) = \int_a^b p(x)dx.
\]</span></p>
<p>Per variabili discrete, lâ€™integrazione si trasforma in una somma.</p>
<section id="le-regole-di-somma-e-prodotto" class="level3" data-number="42.3.1"><h3 data-number="42.3.1" class="anchored" data-anchor-id="le-regole-di-somma-e-prodotto">
<span class="header-section-number">42.3.1</span> Le Regole di Somma e Prodotto</h3>
<p>Date due variabili casuali continue <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span>, le regole di somma e prodotto per le densitÃ  di probabilitÃ  si esprimono come:</p>
<p><span class="math display">\[
\begin{align*}
p(y) = \int p(x,y)dx \quad &amp;\text{- regola della somma},\\
p(x,y) = p(y|x) p(x) = p(x|y) p(y) \quad &amp;\text{- regola del prodotto}.
\end{align*}
\]</span></p>
<p>La probabilitÃ  <span class="math inline">\(p(y)\)</span> Ã¨ chiamata <font color="orange">probabilitÃ  marginale</font>.</p>
<p>La regola del prodotto specifica che la distribuzione congiunta di due variabili puÃ² essere espressa come il prodotto di una distribuzione condizionata <span class="math inline">\(p(y \mid x)\)</span> e una distribuzione marginale <span class="math inline">\(p(x)\)</span>, o viceversa.</p>
</section><section id="la-distribuzione-marginale" class="level3" data-number="42.3.2"><h3 data-number="42.3.2" class="anchored" data-anchor-id="la-distribuzione-marginale">
<span class="header-section-number">42.3.2</span> La Distribuzione Marginale</h3>
<p>La distribuzione marginale si riferisce alla distribuzione di probabilitÃ  di una variabile quando si tiene conto di tutte le possibili variazioni dellâ€™altra variabile in una distribuzione congiunta. In altre parole, essa descrive la probabilitÃ  di una variabile indipendentemente dallâ€™altra.</p>
<p>Consideriamo due variabili correlate, <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span>. Possiamo esprimere la relazione tra di esse con la <font color="orange">regola del prodotto</font>:</p>
<p><span class="math display">\[
p(x, y) = p(y \mid x)p(x),
\]</span></p>
<p>dove <span class="math inline">\(p(y \mid x)\)</span> Ã¨ la probabilitÃ  di <span class="math inline">\(y\)</span> dato un certo valore di <span class="math inline">\(x\)</span>, e <span class="math inline">\(p(x)\)</span> Ã¨ la distribuzione di probabilitÃ  di <span class="math inline">\(x\)</span>.</p>
<p>Per ottenere la distribuzione marginale di <span class="math inline">\(y\)</span>, dobbiamo sommare o integrare <span class="math inline">\(p(y \mid x)\)</span> su tutti i possibili valori di <span class="math inline">\(x\)</span>:</p>
<p><span class="math display">\[
p(y) = \int p(y \mid x)p(x)dx.
\]</span></p>
<p>In questo modo, la distribuzione marginale di <span class="math inline">\(y\)</span> rappresenta la probabilitÃ  di <span class="math inline">\(y\)</span>, tenendo conto di tutte le possibili variazioni di <span class="math inline">\(x\)</span>.</p>
</section><section id="il-teorema-di-bayes" class="level3" data-number="42.3.3"><h3 data-number="42.3.3" class="anchored" data-anchor-id="il-teorema-di-bayes">
<span class="header-section-number">42.3.3</span> Il Teorema di Bayes</h3>
<p>Dalla regola di prodotto, e sfruttando la proprietÃ  di simmetria <span class="math inline">\(p(x \mid y)p(y) = p(y \mid x)p(x)\)</span>, deriviamo immediatamente la regola di Bayes:</p>
<p><span class="math display">\[
p(y \mid x) = \frac{p(x \mid y)p(y)}{p(x)} = \frac{p(x \mid y)p(y)}{\int p(x \mid y)p(y)dy}.
\]</span></p>
<p>Questa formula Ã¨ lâ€™elemento chiave nellâ€™inferenza bayesiana, poichÃ© definisce la densitÃ  a posteriori di <span class="math inline">\(y\)</span>, <span class="math inline">\(p(y \mid x)\)</span>, dopo aver incorporato lâ€™informazione <span class="math inline">\(x\)</span> attraverso il modello di probabilitÃ  condizionata <span class="math inline">\(p(x \mid y)\)</span>. La probabilitÃ  marginale di <span class="math inline">\(x\)</span>, <span class="math inline">\(p(x)\)</span>, funge da costante di normalizzazione, garantendo che <span class="math inline">\(p(y \mid x)\)</span> sia una corretta funzione di densitÃ  di probabilitÃ .</p>
</section><section id="modellizzazione-e-inferenza-bayesiana" class="level3" data-number="42.3.4"><h3 data-number="42.3.4" class="anchored" data-anchor-id="modellizzazione-e-inferenza-bayesiana">
<span class="header-section-number">42.3.4</span> Modellizzazione e Inferenza Bayesiana</h3>
<p>La modellizzazione bayesiana consiste nel descrivere matematicamente tutti i dati osservabili <span class="math inline">\(y\)</span> e i parametri non osservabili, detti anche parametri â€œlatentiâ€ <span class="math inline">\(\theta\)</span>, definendo la distribuzione congiunta di dati e parametri <span class="math inline">\(p(y, \theta)\)</span>.</p>
<p>Si costruiscono modelli probabilistici per le quantitÃ  osservate condizionate ai parametri <span class="math inline">\(p(y \mid \theta)\)</span> e per le quantitÃ  non osservate, rappresentate dalla distribuzione a priori <span class="math inline">\(p(\theta)\)</span>, che rappresenta le nostre conoscenze precedenti sui parametri. Questi due elementi vengono combinati, seguendo la regola del prodotto, per formare una distribuzione congiunta:</p>
<p><span class="math display">\[
p(y, \theta) = p(y \mid \theta)p(\theta).
\]</span></p>
</section><section id="il-modello-osservazionale" class="level3" data-number="42.3.5"><h3 data-number="42.3.5" class="anchored" data-anchor-id="il-modello-osservazionale">
<span class="header-section-number">42.3.5</span> Il Modello Osservazionale</h3>
<p>La funzione</p>
<p><span class="math display">\[
p(y \mid \theta)
\]</span></p>
<p>Ã¨ un <font color="orange">modello probabilistico dei dati osservati</font> che mette in relazione <span class="math inline">\(y\)</span> con i parametri sconosciuti <span class="math inline">\(\theta\)</span> che vogliamo stimare. Questo modello rappresenta lâ€™evidenza fornita dai dati e costituisce la principale fonte di informazione. In questo contesto, viene chiamato <font color="orange">funzione di verosimiglianza</font> (<em>likelihood</em>). Ãˆ importante notare che la funzione di verosimiglianza nel contesto bayesiano non Ã¨ diversa da quella utilizzata nellâ€™approccio frequentista: in entrambi i casi collega i dati osservati ai parametri sconosciuti.</p>
</section><section id="la-distribuzione-a-priori" class="level3" data-number="42.3.6"><h3 data-number="42.3.6" class="anchored" data-anchor-id="la-distribuzione-a-priori">
<span class="header-section-number">42.3.6</span> La Distribuzione a Priori</h3>
<p>La distribuzione</p>
<p><span class="math display">\[
p(\theta)
\]</span></p>
<p>rappresenta la <font color="orange">distribuzione a priori</font> dei parametri, che codifica le conoscenze preesistenti sui parametri stessi. Questa distribuzione a priori puÃ² essere <font color="orange">informativa</font> o <font color="orange">non informativa</font>, a seconda della quantitÃ  di informazioni affidabili che si possiedono sui parametri. Uno degli aspetti principali che differenziano lâ€™approccio bayesiano da quello frequentista Ã¨ lâ€™uso delle distribuzioni di probabilitÃ  per i parametri sconosciuti. Queste distribuzioni vengono poi combinate con la funzione di verosimiglianza per ottenere una distribuzione a posteriori, che incorpora sia le informazioni precedenti che le evidenze fornite dai nuovi dati.</p>
</section><section id="inferenza-sui-parametri" class="level3" data-number="42.3.7"><h3 data-number="42.3.7" class="anchored" data-anchor-id="inferenza-sui-parametri">
<span class="header-section-number">42.3.7</span> Inferenza sui Parametri</h3>
<p>Ottenere la distribuzione a posteriori dei parametri sconosciuti Ã¨ lâ€™elemento centrale dellâ€™approccio bayesiano. Riformulando la regola di Bayes in termini di <span class="math inline">\(y\)</span> e <span class="math inline">\(\theta\)</span>, otteniamo una formula che ci mostra come calcolare la distribuzione a posteriori:</p>
<p><span class="math display">\[
p(\theta \mid y) = \frac{p(y \mid \theta)p(\theta)}{p(y)} = \frac{p(y \mid \theta)p(\theta)}{\int p(y \mid \theta)p(\theta) d\theta}.
\]</span></p>
<p>Il denominatore della regola di Bayes,</p>
<p><span class="math display">\[
p(y) = \int p(y \mid \theta)p(\theta) d \theta,
\]</span></p>
<p>Ã¨ chiamato <font color="orange">verosimiglianza marginale</font>, poichÃ© integra la verosimiglianza rispetto allâ€™informazione a priori sui parametri. Questa quantitÃ  Ã¨ anche nota come <font color="orange">evidenza</font> del modello e serve a normalizzare la distribuzione a posteriori, rendendola una vera distribuzione di probabilitÃ . Lâ€™inferenza finale sarÃ  un compromesso tra lâ€™evidenza fornita dai dati e lâ€™informazione a priori disponibile.</p>
</section><section id="inferenza-bayesiana-in-sintesi-verosimiglianza-prior-posteriore" class="level3" data-number="42.3.8"><h3 data-number="42.3.8" class="anchored" data-anchor-id="inferenza-bayesiana-in-sintesi-verosimiglianza-prior-posteriore">
<span class="header-section-number">42.3.8</span> Inferenza bayesiana in sintesi: verosimiglianza, prior, posteriore</h3>
<p>Per riassumere, ecco tutti i componenti fondamentali dellâ€™inferenza bayesiana.</p>
<p>Il teorema di Bayes, espresso in termini di dati <span class="math inline">\(y\)</span> e parametri del modello <span class="math inline">\(\theta\)</span>, Ã¨</p>
<p><span class="math display">\[
p(\theta \mid y) = \frac{p(y \mid \theta)p(\theta)}{p(y)},
\]</span></p>
<p>dove:</p>
<ul>
<li>Il denominatore <span class="math inline">\(p(y)\)</span> Ã¨ la costante di normalizzazione o <em>evidenza</em>.</li>
<li>
<span class="math inline">\(p(\theta)\)</span> rappresenta il <em>prior</em>, ovvero le credenze iniziali sui parametri.</li>
<li>
<span class="math inline">\(p(y \mid \theta)\)</span> Ã¨ la <em>verosimiglianza</em>, che collega i dati osservati ai parametri del modello.</li>
<li>
<span class="math inline">\(p(\theta \mid y)\)</span> Ã¨ la <em>distribuzione a posteriori</em>, che rappresenta le credenze aggiornate sui parametri dopo aver osservato i dati.</li>
</ul>
<p>La distribuzione a posteriori riassume il nostro stato di credenza sui possibili valori di <span class="math inline">\(\theta\)</span>, aggiornato sulla base delle evidenze fornite dai dati.</p>
<p>Si noti che <span class="math inline">\(p(y)\)</span> non dipende dai parametri <span class="math inline">\(\theta\)</span>. Pertanto, in molte situazioni pratiche, Ã¨ sufficiente calcolare la distribuzione a posteriori fino a una costante. Per questo motivo, spesso la regola di Bayes viene riassunta come:</p>
<p><span class="math display">\[p(\theta \mid y) \propto p(y \mid \theta)p(\theta).\]</span></p>
<p>In questa forma, si ignora il denominatore poichÃ© Ã¨ una costante (indipendente da <span class="math inline">\(\theta\)</span>).</p>
</section><section id="il-ruolo-dei-priors" class="level3" data-number="42.3.9"><h3 data-number="42.3.9" class="anchored" data-anchor-id="il-ruolo-dei-priors">
<span class="header-section-number">42.3.9</span> Il Ruolo dei Priors</h3>
<p>Una delle caratteristiche distintive dellâ€™approccio bayesiano Ã¨ lâ€™incorporazione delle conoscenze a priori riguardo ai parametri del modello. Dichiarare questi priors ci obbliga a esplicitare tutte le assunzioni che facciamo sulla struttura del modello e sui suoi parametri. Allo stesso tempo, i priors sono spesso oggetto di critica nellâ€™inferenza bayesiana a causa della soggettivitÃ  che possono introdurre.</p>
<p>Tuttavia, lâ€™inferenza bayesiana offre alcuni vantaggi meno evidenti a prima vista, tra cui:</p>
<ul>
<li>la capacitÃ  di lavorare efficacemente con piccoli set di dati,</li>
<li>la capacitÃ  di eseguire la regolarizzazione del modello.</li>
</ul>
<p>Questi aspetti rendono lâ€™approccio bayesiano particolarmente utile in situazioni in cui i dati sono scarsi o le assunzioni esplicite sul modello possono contribuire a migliorare le previsioni.</p>
</section></section><section id="inferenza-predittiva" class="level2" data-number="42.4"><h2 data-number="42.4" class="anchored" data-anchor-id="inferenza-predittiva">
<span class="header-section-number">42.4</span> Inferenza Predittiva</h2>
<p>La distribuzione a posteriori dei parametri puÃ² essere utilizzata per modellare lâ€™incertezza nelle previsioni <span class="math inline">\(\tilde{y}\)</span> relative a nuove osservazioni. La <font color="orange">distribuzione predittiva a posteriori</font> di <span class="math inline">\(\tilde{y}\)</span> si ottiene marginalizzando la distribuzione congiunta delle previsioni <span class="math inline">\(\tilde{y}\)</span> e dei parametri <span class="math inline">\(\theta\)</span> rispetto ai parametri del modello:</p>
<p><span class="math display">\[
p(\tilde{y} \mid y) = \int p(\tilde{y}, \theta \mid y)d \theta = \int p(\tilde{y} \mid \theta, y)p(\theta|y)d\theta.
\]</span></p>
<p>In questo modo, la distribuzione predittiva puÃ² essere vista come una media delle previsioni del modello <span class="math inline">\(p(\tilde{y} \mid \theta, y)\)</span> ponderata sulla distribuzione a posteriori dei parametri del modello <span class="math inline">\(p(\theta \mid y)\)</span>. Questo consente di incorporare lâ€™incertezza sui parametri nel processo di previsione, rendendo le stime piÃ¹ robuste.</p>
</section><section id="come-possiamo-eseguire-linferenza-bayesiana" class="level2" data-number="42.5"><h2 data-number="42.5" class="anchored" data-anchor-id="come-possiamo-eseguire-linferenza-bayesiana">
<span class="header-section-number">42.5</span> Come possiamo eseguire lâ€™inferenza bayesiana?</h2>
<p>Esistono due approcci principali per determinare la distribuzione posteriore:</p>
<ol type="1">
<li><p><strong>Approccio Analitico (o Coniugato)</strong>: Questo metodo Ã¨ applicabile quando la distribuzione a priori scelta e la funzione di verosimiglianza appartengono alla stessa famiglia di distribuzioni, definite <em>coniugate</em>. In questi casi, la distribuzione posteriore puÃ² essere calcolata analiticamente, ovvero attraverso formule matematiche esatte. Lâ€™approccio coniugato Ã¨ computazionalmente efficiente ma presenta una limitazione significativa: Ã¨ applicabile solo in situazioni in cui si puÃ² assumere una coniugazione tra la distribuzione a priori e la verosimiglianza. Di conseguenza, trova un impiego limitato nelle analisi di dati reali, dove spesso le assunzioni di coniugazione risultano troppo restrittive.</p></li>
<li><p><strong>Approccio Numerico</strong>: Quando non Ã¨ possibile ottenere una forma analitica chiusa per la distribuzione posteriore, a causa della complessitÃ  del modello o della mancanza di coniugazione tra la distribuzione a priori e la verosimiglianza, si ricorre a metodi numerici. Questi algoritmi consentono di ottenere una stima approssimata, ma spesso accurata, della distribuzione posteriore.</p></li>
</ol>
<section id="metodi-numerici" class="level3" data-number="42.5.1"><h3 data-number="42.5.1" class="anchored" data-anchor-id="metodi-numerici">
<span class="header-section-number">42.5.1</span> Metodi Numerici</h3>
<p>Le catene di Markov Monte Carlo (MCMC) sono una classe di algoritmi ampiamente utilizzati in questo contesto. Essi costruiscono una catena di Markov che converge alla distribuzione posteriore desiderata. Tra i metodi MCMC piÃ¹ comuni troviamo:</p>
<ul>
<li>
<em>Metropolis-Hastings</em>: Un algoritmo generale che consente di campionare da una vasta gamma di distribuzioni posteriori.</li>
<li>
<em>Gibbs Sampling</em>: Un caso particolare di Metropolis-Hastings, particolarmente efficiente quando la distribuzione congiunta Ã¨ difficile da campionare direttamente, ma le distribuzioni condizionali sono note.</li>
</ul>
<p>Oltre alle MCMC, esistono altre tecniche numeriche:</p>
<ul>
<li>
<em>Variational Bayes</em>: Questo approccio consiste nel trovare la distribuzione <span class="math inline">\(q(z)\)</span> che meglio approssima la distribuzione posteriore <span class="math inline">\(p(z \mid x)\)</span>, secondo un criterio di divergenza (ad esempio, la divergenza di Kullback-Leibler). Lâ€™obiettivo Ã¨ trasformare il problema di inferenza esatta in un problema di ottimizzazione. Variational Bayes offre spesso una soluzione piÃ¹ veloce rispetto alle MCMC, ma lâ€™approssimazione puÃ² essere meno accurata in alcuni casi.</li>
<li>
<em>Laplace approximation</em>: Questa tecnica consiste nellâ€™approssimare la distribuzione posteriore con una distribuzione normale centrata sul massimo a posteriori (MAP) e con matrice di covarianza pari allâ€™inverso della matrice di Hessiano negativa calcolata nel MAP. Lâ€™approssimazione di Laplace Ã¨ computazionalmente efficiente, ma Ã¨ valida solo localmente attorno al MAP e puÃ² portare a stime inaccurate della varianza posteriore.</li>
</ul>
<p>Vantaggi:</p>
<ul>
<li>VersatilitÃ : Lâ€™approccio numerico Ã¨ applicabile a una vasta gamma di modelli e distribuzioni.</li>
<li>FlessibilitÃ : Consente di incorporare facilmente informazioni a priori complesse.</li>
</ul>
<p>Svantaggi:</p>
<ul>
<li>Costo computazionale: PuÃ² richiedere un tempo di calcolo considerevole, soprattutto per modelli complessi o grandi dataset.</li>
<li>Tuning: La scelta dei parametri degli algoritmi MCMC (ad esempio, la proposta iniziale) puÃ² influenzare la convergenza e lâ€™efficienza del campionamento.</li>
</ul>
<p>In sintesi, lâ€™approccio numerico offre una soluzione generale e flessibile per lâ€™inferenza bayesiana, ma richiede una maggiore attenzione alla scelta degli algoritmi e alla valutazione della convergenza delle catene.</p>
</section></section><section id="programmazione-probabilistica" class="level2" data-number="42.6"><h2 data-number="42.6" class="anchored" data-anchor-id="programmazione-probabilistica">
<span class="header-section-number">42.6</span> Programmazione Probabilistica</h2>
<p>I linguaggi di programmazione probabilistica (PPL) rappresentano unâ€™importante innovazione nella modellazione bayesiana, facilitando lâ€™uso di tecniche di approssimazione numerica per stimare le distribuzioni posteriori. Grazie ai PPL, la modellizzazione probabilistica diventa piÃ¹ accessibile, riducendo le barriere tecniche e computazionali. Questi strumenti consentono di definire modelli in modo dichiarativo, descrivendo le relazioni tra le variabili in termini probabilistici senza doversi occupare dei dettagli algoritmici sottostanti. In altre parole, i PPL permettono ai ricercatori di concentrarsi sullâ€™espressione del modello, lasciando ai linguaggi il compito di gestire lâ€™implementazione computazionale.</p>
<p>Tra i PPL piÃ¹ utilizzati troviamo:</p>
<ul>
<li>
<strong>Stan</strong>: Uno dei linguaggi piÃ¹ popolari, noto per la sua efficienza e flessibilitÃ .</li>
<li>
<strong>PyMC</strong>: Molto utilizzato nellâ€™ecosistema Python, offre unâ€™interfaccia user-friendly per la modellazione bayesiana.</li>
<li>
<strong>TensorFlow</strong>: Un framework che combina un approccio probabilistico con le reti neurali.</li>
</ul>
<section id="vantaggi-della-programmazione-probabilistica-in-psicologia" class="level3" data-number="42.6.1"><h3 data-number="42.6.1" class="anchored" data-anchor-id="vantaggi-della-programmazione-probabilistica-in-psicologia">
<span class="header-section-number">42.6.1</span> Vantaggi della Programmazione Probabilistica in Psicologia</h3>
<p>La programmazione probabilistica offre numerosi vantaggi per la ricerca psicologica, in particolare per lâ€™analisi di processi complessi come lâ€™apprendimento, le emozioni e il comportamento. Alcuni dei principali vantaggi includono:</p>
<ul>
<li><p><strong>FlessibilitÃ </strong>: I PPL, come Stan, Pyro, Numpyro, PyMC e Turing.jl, offrono un quadro flessibile per la definizione e la personalizzazione dei modelli probabilistici. In psicologia, questa flessibilitÃ  Ã¨ cruciale, poichÃ© i modelli devono adattarsi a una vasta gamma di processi mentali e comportamentali che variano tra individui e contesti.</p></li>
<li><p><strong>Quantificazione dellâ€™Incertezza</strong>: La programmazione probabilistica permette di rappresentare esplicitamente e quantificare lâ€™incertezza, un aspetto fondamentale in psicologia, dove molte variabili di interesse, come stati emotivi o atteggiamenti, sono latenti e soggette a incertezza. Incorporare questa incertezza nei modelli consente di ottenere stime piÃ¹ realistiche e affidabili.</p></li>
<li><p><strong>Validazione del Modello</strong>: I PPL facilitano la validazione dei modelli psicologici, consentendo ai ricercatori di confrontare le previsioni dei modelli con i dati osservati. Tecniche come i <em>posterior predictive checks</em> permettono di valutare la qualitÃ  e lâ€™affidabilitÃ  del modello, contribuendo a una maggiore soliditÃ  delle conclusioni.</p></li>
<li><p><strong>Modellazione Gerarchica</strong>: Molti studi psicologici raccolgono dati a piÃ¹ livelli (ad esempio, misurazioni ripetute per individuo, sessioni sperimentali, contesti diversi). I PPL semplificano la costruzione e lâ€™analisi di modelli gerarchici, catturando la variabilitÃ  sia intra- che inter-individuale.</p></li>
<li><p><strong>Selezione e Confronto dei Modelli</strong>: In psicologia Ã¨ spesso necessario confrontare modelli con strutture diverse o ipotesi alternative. I PPL permettono di confrontare le capacitÃ  predittive dei modelli in modo sistematico e rigoroso, supportando la scelta del modello piÃ¹ adatto basandosi sullâ€™accuratezza predittiva e non solo sulla complessitÃ .</p></li>
<li><p><strong>Comunicazione Trasparente</strong>: La programmazione probabilistica favorisce la trasparenza nella modellizzazione. I ricercatori possono specificare chiaramente le assunzioni del modello, i <em>prior</em> e le funzioni di verosimiglianza, rendendo piÃ¹ facile la comunicazione e la collaborazione con altri esperti.</p></li>
<li><p><strong>Librerie Estensibili</strong>: I PPL offrono librerie estese e strumenti avanzati per lo sviluppo di modelli, lâ€™inferenza e la visualizzazione. Questo riduce il carico computazionale e di implementazione, rendendo piÃ¹ agevole lâ€™analisi di dati complessi tipici della psicologia sperimentale e clinica.</p></li>
</ul></section><section id="come-funzionano-i-ppl" class="level3" data-number="42.6.2"><h3 data-number="42.6.2" class="anchored" data-anchor-id="come-funzionano-i-ppl">
<span class="header-section-number">42.6.2</span> Come Funzionano i PPL?</h3>
<p>I linguaggi di programmazione probabilistica richiedono semplicemente la descrizione del modello probabilistico. Successivamente, utilizzano algoritmi di inferenza, come le catene di Markov Monte Carlo (MCMC) o lâ€™inferenza variazionale, per stimare la distribuzione posteriore delle variabili di interesse. CiÃ² consente ai ricercatori di ottenere stime delle variabili sconosciute e di valutare lâ€™incertezza associata.</p>
<p>In conclusione, i linguaggi di programmazione probabilistica hanno trasformato il modo in cui affrontiamo lâ€™inferenza bayesiana, rendendola piÃ¹ accessibile e potente. Grazie alla loro semplicitÃ  dâ€™uso e alla potenza computazionale, i PPL hanno reso lâ€™inferenza bayesiana uno strumento sempre piÃ¹ diffuso in molte discipline, inclusa la psicologia. Questo approccio facilita la modellazione di fenomeni complessi e lâ€™analisi rigorosa di dati, offrendo un metodo efficace per rispondere a domande di ricerca psicologica in modo trasparente e accurato.</p>
</section></section><section id="notazione" class="level2" data-number="42.7"><h2 data-number="42.7" class="anchored" data-anchor-id="notazione">
<span class="header-section-number">42.7</span> Notazione</h2>
<p>In seguito, utilizzeremo <span class="math inline">\(y\)</span> per rappresentare i dati osservati e <span class="math inline">\(\theta\)</span> per indicare i parametri sconosciuti di un modello statistico. Entrambi, <span class="math inline">\(y\)</span> e <span class="math inline">\(\theta\)</span>, saranno trattati come variabili casuali. Utilizzeremo <span class="math inline">\(x\)</span> per denotare le quantitÃ  note, come i predittori di un modello lineare.</p>
<p>Ãˆ comune scrivere modelli statistici utilizzando la seguente notazione:</p>
<p><span class="math display">\[
\begin{aligned}
y &amp; \sim \mathrm{normal}(\mu, \sigma) \\
\mu &amp; \sim \mathrm{normal}(0, 10) \\
\sigma &amp; \sim \mathrm{normal}^+(\sigma \mid  0, 1),
\end{aligned}
\]</span></p>
<p>dove il simbolo <span class="math inline">\(\sim\)</span> Ã¨ chiamato <em>tilde</em> (<code>\sim</code> in LaTeX).</p>
<p>In generale, possiamo leggere <span class="math inline">\(\sim\)</span> come <em>â€œÃ¨ distribuito comeâ€</em>, e questa notazione Ã¨ usata come una scorciatoia per definire distribuzioni. Lâ€™esempio sopra puÃ² essere scritto anche come:</p>
<p><span class="math display">\[
\begin{aligned}
   p(y \mid \mu, \sigma) &amp; = \mathrm{normal}(y \mid  \mu, \sigma)\\
   p(\mu) &amp; = \mathrm{normal}(\mu \mid 0, 10)\\
   p(\sigma) &amp; = \mathrm{normal}^+(\sigma \mid  0, 1).
\end{aligned}
\]</span></p>
</section><section id="addendum-la-verosimiglianza-marginale" class="level2" data-number="42.8"><h2 data-number="42.8" class="anchored" data-anchor-id="addendum-la-verosimiglianza-marginale">
<span class="header-section-number">42.8</span> Addendum: La Verosimiglianza Marginale</h2>
<p>Nella discussione precedente, abbiamo introdotto la verosimiglianza marginale <span class="math inline">\(p(y)\)</span> come una costante di normalizzazione. Ma <font color="orange">perchÃ© Ã¨ cosÃ¬ importante normalizzare la distribuzione posteriore?</font> La verosimiglianza marginale rappresenta la probabilitÃ  dei dati osservati, integrata su tutti i possibili valori del parametro <span class="math inline">\(\theta\)</span>. In altre parole, esprime la probabilitÃ  di osservare i dati senza fare riferimento a un particolare valore del parametro.</p>
<p>Per comprendere intuitivamente, immagina di voler stimare la temperatura media di una stanza. Usando un termometro, ottieni una misurazione, ma sei consapevole che variabili come la posizione del termometro o lâ€™ora del giorno potrebbero influenzare la lettura. La verosimiglianza marginale Ã¨ equivalente a considerare la probabilitÃ  di ottenere una certa misurazione, prendendo in considerazione tutte queste possibili variabili.</p>
<p>Senza la normalizzazione, la somma delle probabilitÃ  assegnate ai diversi valori del parametro non sarebbe uguale a 1, il che significherebbe che non avremmo una distribuzione di probabilitÃ  valida. Questo renderebbe difficile interpretare correttamente i risultati. La verosimiglianza marginale agisce come una costante di normalizzazione, garantendo che lâ€™area sotto la curva della distribuzione posteriore sia esattamente pari a 1, come richiesto da una distribuzione di probabilitÃ .</p>
<p>La verosimiglianza marginale si calcola integrando (o sommando, nel caso di parametri discreti) la funzione di verosimiglianza rispetto a tutti i possibili valori del parametro, pesando ciascun valore con la sua probabilitÃ  a priori.</p>
<p>Consideriamo un esempio con una variabile casuale binomiale <span class="math inline">\(Y\)</span>, la cui funzione di massa di probabilitÃ  (PMF) <span class="math inline">\(p(Y)\)</span> dipende dal parametro <span class="math inline">\(\theta\)</span>. Supponiamo che <span class="math inline">\(\theta\)</span> possa assumere uno tra tre valori specifici: 0.1, 0.5 o 0.9, ciascuno con una probabilitÃ  a priori di <span class="math inline">\(\frac{1}{3}\)</span>.</p>
<p>Se i dati indicano <span class="math inline">\(n = 10\)</span> prove e <span class="math inline">\(k = 7\)</span> successi, la funzione di verosimiglianza Ã¨ data da:</p>
<p><span class="math display">\[
p(k = 7, n = 10 \mid \theta) = \binom{10}{7} \theta^7 (1 - \theta)^3.
\]</span></p>
<p>Per calcolare la verosimiglianza marginale <span class="math inline">\(p(k = 7, n = 10)\)</span>, marginalizziamo su <span class="math inline">\(\theta\)</span>, valutando la verosimiglianza per ciascun valore di <span class="math inline">\(\theta\)</span>, moltiplicando per la probabilitÃ  a priori di ciascun <span class="math inline">\(\theta\)</span>, e sommando i risultati:</p>
<p><span class="math display">\[
p(k = 7, n = 10) = \sum_{i=1}^{3} p(k = 7, n = 10 \mid \theta_i) \cdot p(\theta_i).
\]</span></p>
<p>Sostituendo i valori di <span class="math inline">\(\theta\)</span> e le probabilitÃ  corrispondenti:</p>
<p><span class="math display">\[
p(k = 7, n = 10) = \frac{1}{3} \binom{10}{7} 0.1^7 (1 - 0.1)^3 + \frac{1}{3} \binom{10}{7} 0.5^7 (1 - 0.5)^3 + \frac{1}{3} \binom{10}{7} 0.9^7 (1 - 0.9)^3.
\]</span></p>
<p>Questo calcolo dimostra come la marginalizzazione su <span class="math inline">\(\theta\)</span> incorpori tutte le sue possibili variazioni, ottenendo una stima complessiva che tiene conto dellâ€™incertezza su <span class="math inline">\(\theta\)</span>.</p>
</section><section id="implementazione-in-r" class="level2" data-number="42.9"><h2 data-number="42.9" class="anchored" data-anchor-id="implementazione-in-r">
<span class="header-section-number">42.9</span> Implementazione in R</h2>
<p>Per calcolare la verosimiglianza marginale in R, possiamo distinguere tra il caso discreto (in cui <span class="math inline">\(\theta\)</span> assume valori specifici) e il caso continuo (in cui <span class="math inline">\(\theta\)</span> Ã¨ trattato come una variabile continua su un intervallo). Per il caso discreto, sommiamo direttamente i contributi della funzione di verosimiglianza pesati dalla probabilitÃ  a priori. Per il caso continuo, utilizziamo lâ€™integrazione numerica.</p>
<section id="caso-discreto" class="level3" data-number="42.9.1"><h3 data-number="42.9.1" class="anchored" data-anchor-id="caso-discreto">
<span class="header-section-number">42.9.1</span> Caso discreto</h3>
<p>Nel caso in cui <span class="math inline">\(\theta\)</span> assuma valori discreti, possiamo implementare il calcolo della verosimiglianza marginale sommando i prodotti della verosimiglianza <span class="math inline">\(p(k \mid \theta)\)</span> e della probabilitÃ  a priori <span class="math inline">\(p(\theta)\)</span>:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Funzione di verosimiglianza per il caso binomiale</span></span>
<span><span class="va">likelihood_binomial</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">theta</span>, <span class="va">k</span>, <span class="va">n</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/function.html">return</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Special.html">choose</a></span><span class="op">(</span><span class="va">n</span>, <span class="va">k</span><span class="op">)</span> <span class="op">*</span> <span class="op">(</span><span class="va">theta</span><span class="op">^</span><span class="va">k</span><span class="op">)</span> <span class="op">*</span> <span class="op">(</span><span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">theta</span><span class="op">)</span><span class="op">^</span><span class="op">(</span><span class="va">n</span> <span class="op">-</span> <span class="va">k</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Valori di theta e probabilitÃ  a priori</span></span>
<span><span class="va">theta_values</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.1</span>, <span class="fl">0.5</span>, <span class="fl">0.9</span><span class="op">)</span></span>
<span><span class="va">prior</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">theta_values</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">theta_values</span><span class="op">)</span><span class="op">)</span> <span class="co"># Prior uniforme</span></span>
<span><span class="va">k</span> <span class="op">&lt;-</span> <span class="fl">7</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">10</span></span>
<span></span>
<span><span class="co"># Calcolo della verosimiglianza marginale discreta</span></span>
<span><span class="va">marginal_likelihood_discrete</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">prior</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">sapply</a></span><span class="op">(</span><span class="va">theta_values</span>, <span class="va">likelihood_binomial</span>, k <span class="op">=</span> <span class="va">k</span>, n <span class="op">=</span> <span class="va">n</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sprintf.html">sprintf</a></span><span class="op">(</span><span class="st">"Likelihood Marginale (discreta): %.4f\n"</span>, <span class="va">marginal_likelihood_discrete</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; Likelihood Marginale (discreta): 0.0582</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Il risultato rappresenta la verosimiglianza marginale calcolata sommando i contributi discreti.</p>
</section><section id="caso-continuo" class="level3" data-number="42.9.2"><h3 data-number="42.9.2" class="anchored" data-anchor-id="caso-continuo">
<span class="header-section-number">42.9.2</span> Caso continuo</h3>
<p>Nel caso in cui <span class="math inline">\(\theta\)</span> sia una variabile continua definita su <span class="math inline">\([0, 1]\)</span>, utilizziamo lâ€™integrazione numerica per calcolare la verosimiglianza marginale. Lâ€™approccio assume una distribuzione a priori uniforme su <span class="math inline">\([0, 1]\)</span> (se non diversamente specificato):</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Funzione per il calcolo della verosimiglianza marginale continua</span></span>
<span><span class="va">likelihood_binomial_continuous</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">theta</span>, <span class="va">k</span>, <span class="va">n</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="co"># La verosimiglianza Ã¨ 0 per valori di theta fuori dall'intervallo [0, 1]</span></span>
<span>  <span class="va">theta</span><span class="op">[</span><span class="va">theta</span> <span class="op">&lt;</span> <span class="fl">0</span> <span class="op">|</span> <span class="va">theta</span> <span class="op">&gt;</span> <span class="fl">1</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fl">0</span></span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/function.html">return</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Special.html">choose</a></span><span class="op">(</span><span class="va">n</span>, <span class="va">k</span><span class="op">)</span> <span class="op">*</span> <span class="op">(</span><span class="va">theta</span><span class="op">^</span><span class="va">k</span><span class="op">)</span> <span class="op">*</span> <span class="op">(</span><span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">theta</span><span class="op">)</span><span class="op">^</span><span class="op">(</span><span class="va">n</span> <span class="op">-</span> <span class="va">k</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Parametri</span></span>
<span><span class="va">k</span> <span class="op">&lt;-</span> <span class="fl">7</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">10</span></span>
<span></span>
<span><span class="co"># Calcolo dell'integrale numerico</span></span>
<span><span class="va">marginal_likelihood_continuous</span> <span class="op">&lt;-</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/integrate.html">integrate</a></span><span class="op">(</span></span>
<span>    <span class="kw">function</span><span class="op">(</span><span class="va">theta</span><span class="op">)</span> <span class="fu">likelihood_binomial_continuous</span><span class="op">(</span><span class="va">theta</span>, <span class="va">k</span>, <span class="va">n</span><span class="op">)</span>, </span>
<span>    lower <span class="op">=</span> <span class="fl">0</span>, </span>
<span>    upper <span class="op">=</span> <span class="fl">1</span></span>
<span>  <span class="op">)</span><span class="op">$</span><span class="va">value</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/sprintf.html">sprintf</a></span><span class="op">(</span></span>
<span>    <span class="st">"Likelihood Marginale (continua): %.4f\n"</span>, </span>
<span>    <span class="va">marginal_likelihood_continuous</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Likelihood Marginale (continua): 0.0909</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Qui lâ€™integrazione numerica restituisce la verosimiglianza marginale considerando <span class="math inline">\(\theta\)</span> come una variabile continua.</p>
</section><section id="caso-continuo-con-prior-beta" class="level3" data-number="42.9.3"><h3 data-number="42.9.3" class="anchored" data-anchor-id="caso-continuo-con-prior-beta">
<span class="header-section-number">42.9.3</span> Caso continuo con prior Beta</h3>
<p>Per utilizzare una distribuzione a priori diversa (ad esempio, una distribuzione Beta), Ã¨ necessario moltiplicare la funzione di verosimiglianza per la densitÃ  della distribuzione a priori:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Funzione prior Beta</span></span>
<span><span class="va">prior_beta</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">theta</span>, <span class="va">alpha</span>, <span class="va">beta</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/function.html">return</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Beta.html">dbeta</a></span><span class="op">(</span><span class="va">theta</span>, <span class="va">alpha</span>, <span class="va">beta</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Funzione combinata di verosimiglianza e prior</span></span>
<span><span class="va">likelihood_with_beta_prior</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">theta</span>, <span class="va">k</span>, <span class="va">n</span>, <span class="va">alpha_prior</span>, <span class="va">beta_prior</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="co"># La verosimiglianza Ã¨ 0 per valori di theta fuori dall'intervallo [0, 1]</span></span>
<span>  <span class="va">valid_theta</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="va">theta</span> <span class="op">&gt;=</span> <span class="fl">0</span> <span class="op">&amp;</span> <span class="va">theta</span> <span class="op">&lt;=</span> <span class="fl">1</span><span class="op">)</span></span>
<span>  <span class="va">likelihood</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">valid_theta</span>, <span class="fu"><a href="https://rdrr.io/r/base/Special.html">choose</a></span><span class="op">(</span><span class="va">n</span>, <span class="va">k</span><span class="op">)</span> <span class="op">*</span> <span class="op">(</span><span class="va">theta</span><span class="op">^</span><span class="va">k</span><span class="op">)</span> <span class="op">*</span> <span class="op">(</span><span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">theta</span><span class="op">)</span><span class="op">^</span><span class="op">(</span><span class="va">n</span> <span class="op">-</span> <span class="va">k</span><span class="op">)</span><span class="op">)</span>, <span class="fl">0</span><span class="op">)</span></span>
<span>  <span class="va">prior</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">valid_theta</span>, <span class="fu">prior_beta</span><span class="op">(</span><span class="va">theta</span>, <span class="va">alpha_prior</span>, <span class="va">beta_prior</span><span class="op">)</span>, <span class="fl">0</span><span class="op">)</span></span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/function.html">return</a></span><span class="op">(</span><span class="va">likelihood</span> <span class="op">*</span> <span class="va">prior</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Parametri</span></span>
<span><span class="va">alpha_prior</span> <span class="op">&lt;-</span> <span class="fl">2</span></span>
<span><span class="va">beta_prior</span> <span class="op">&lt;-</span> <span class="fl">2</span></span>
<span><span class="va">k</span> <span class="op">&lt;-</span> <span class="fl">7</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">10</span></span>
<span></span>
<span><span class="co"># Calcolo dell'integrale numerico con prior Beta</span></span>
<span><span class="va">marginal_likelihood_continuous_beta</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/integrate.html">integrate</a></span><span class="op">(</span></span>
<span>  <span class="kw">function</span><span class="op">(</span><span class="va">theta</span><span class="op">)</span> <span class="fu">likelihood_with_beta_prior</span><span class="op">(</span><span class="va">theta</span>, <span class="va">k</span>, <span class="va">n</span>, <span class="va">alpha_prior</span>, <span class="va">beta_prior</span><span class="op">)</span>,</span>
<span>  lower <span class="op">=</span> <span class="fl">0</span>, upper <span class="op">=</span> <span class="fl">1</span></span>
<span><span class="op">)</span><span class="op">$</span><span class="va">value</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sprintf.html">sprintf</a></span><span class="op">(</span><span class="st">"Likelihood Marginale con prior Beta: %.4f\n"</span>, <span class="va">marginal_likelihood_continuous_beta</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; Likelihood Marginale con prior Beta: 0.1119</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In questo caso, la distribuzione a priori Beta(2,2) dÃ  maggiore peso ai valori centrali di <span class="math inline">\(\theta\)</span>, riflettendo una conoscenza a priori che privilegia valori intermedi. Il calcolo combina la verosimiglianza e il prior per fornire una verosimiglianza marginale ponderata.</p>
</section></section><section id="riflessioni-conclusive" class="level2" data-number="42.10"><h2 data-number="42.10" class="anchored" data-anchor-id="riflessioni-conclusive">
<span class="header-section-number">42.10</span> Riflessioni Conclusive</h2>
<p>Al cuore della ricerca scientifica câ€™Ã¨ una domanda del tipo: â€œdimmi qualcosa sulla variabile <span class="math inline">\(\theta\)</span> dato che ho osservato i dati <span class="math inline">\(D\)</span> e ho una certa conoscenza del meccanismo sottostante che genera i datiâ€. La regola di Bayes fornisce la seguente risposta:</p>
<p><span class="math display">\[
p(\theta \mid D) = \frac{p(D \mid\theta) p(\theta)}{p(D)} = \frac{p(D \mid \theta) p(\theta)}{\int_\theta p(D \mid\theta) p(\theta) d\theta}.
\]</span></p>
<p>Questa equazione mostra come, partendo da un modello generativo <span class="math inline">\(p(D \mid\theta)\)</span> dei dati osservati e abbinato a una credenza a priori <span class="math inline">\(p(\theta)\)</span> su quali valori della variabile <span class="math inline">\(\theta\)</span> siano plausibili, possiamo inferire la distribuzione a posteriori <span class="math inline">\(p(\theta \mid D)\)</span> della variabile alla luce dei dati osservati.</p>
<p>La stima MAP (Massimo A Posteriori), che corrisponde al valore di <span class="math inline">\(\theta\)</span> che massimizza la distribuzione a posteriori, rappresenta una stima puntuale del parametro:</p>
<p><span class="math display">\[
\theta^* = \arg \max_\theta p(\theta \mid D).
\]</span></p>
<p>Nel caso di un prior non informativo (piatto), la stima MAP coincide con la stima di massima verosimiglianza, ovvero il valore di <span class="math inline">\(\theta\)</span> che massimizza la probabilitÃ  che il modello generi i dati osservati.</p>
</section><section id="informazioni-sullambiente-di-sviluppo" class="level2 unnumbered"><h2 class="unnumbered anchored" data-anchor-id="informazioni-sullambiente-di-sviluppo">Informazioni sullâ€™Ambiente di Sviluppo</h2>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/sessionInfo.html">sessionInfo</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">#&gt; R version 4.4.2 (2024-10-31)</span></span>
<span><span class="co">#&gt; Platform: aarch64-apple-darwin20</span></span>
<span><span class="co">#&gt; Running under: macOS Sequoia 15.2</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Matrix products: default</span></span>
<span><span class="co">#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib </span></span>
<span><span class="co">#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; locale:</span></span>
<span><span class="co">#&gt; [1] C/UTF-8/C/C/C/C</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; time zone: Europe/Rome</span></span>
<span><span class="co">#&gt; tzcode source: internal</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; attached base packages:</span></span>
<span><span class="co">#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; other attached packages:</span></span>
<span><span class="co">#&gt;  [1] mice_3.17.0      see_0.9.0        gridExtra_2.3    patchwork_1.3.0 </span></span>
<span><span class="co">#&gt;  [5] bayesplot_1.11.1 psych_2.4.12     scales_1.3.0     markdown_1.13   </span></span>
<span><span class="co">#&gt;  [9] knitr_1.49       lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1   </span></span>
<span><span class="co">#&gt; [13] dplyr_1.1.4      purrr_1.0.2      readr_2.1.5      tidyr_1.3.1     </span></span>
<span><span class="co">#&gt; [17] tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3       </span></span>
<span><span class="co">#&gt; [21] here_1.0.1      </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; loaded via a namespace (and not attached):</span></span>
<span><span class="co">#&gt;  [1] gtable_0.3.6      shape_1.4.6.1     xfun_0.49         htmlwidgets_1.6.4</span></span>
<span><span class="co">#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2      </span></span>
<span><span class="co">#&gt;  [9] generics_0.1.3    parallel_4.4.2    pan_1.9           pacman_0.5.1     </span></span>
<span><span class="co">#&gt; [13] pkgconfig_2.0.3   jomo_2.7-6        Matrix_1.7-1      lifecycle_1.0.4  </span></span>
<span><span class="co">#&gt; [17] compiler_4.4.2    farver_2.1.2      munsell_0.5.1     mnormt_2.1.1     </span></span>
<span><span class="co">#&gt; [21] codetools_0.2-20  htmltools_0.5.8.1 yaml_2.3.10       glmnet_4.1-8     </span></span>
<span><span class="co">#&gt; [25] nloptr_2.1.1      pillar_1.10.0     MASS_7.3-61       iterators_1.0.14 </span></span>
<span><span class="co">#&gt; [29] rpart_4.1.23      boot_1.3-31       foreach_1.5.2     mitml_0.4-5      </span></span>
<span><span class="co">#&gt; [33] nlme_3.1-166      tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4    </span></span>
<span><span class="co">#&gt; [37] splines_4.4.2     rprojroot_2.0.4   fastmap_1.2.0     grid_4.4.2       </span></span>
<span><span class="co">#&gt; [41] colorspace_2.1-1  cli_3.6.3         magrittr_2.0.3    survival_3.8-3   </span></span>
<span><span class="co">#&gt; [45] broom_1.0.7       withr_3.0.2       backports_1.5.0   timechange_0.3.0 </span></span>
<span><span class="co">#&gt; [49] rmarkdown_2.29    nnet_7.3-19       lme4_1.1-35.5     hms_1.1.3        </span></span>
<span><span class="co">#&gt; [53] evaluate_1.0.1    rlang_1.1.4       Rcpp_1.0.13-1     glue_1.8.0       </span></span>
<span><span class="co">#&gt; [57] minqa_1.2.8       jsonlite_1.8.9    R6_2.5.1</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section><section id="bibliografia" class="level2 unnumbered"><h2 class="unnumbered anchored" data-anchor-id="bibliografia">Bibliografia</h2>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2" role="list">
<div id="ref-Johnson2022bayesrules" class="csl-entry" role="listitem">
Johnson, A. A., Ott, M., &amp; Dogucu, M. (2022). <em><span>Bayes Rules! An Introduction to Bayesian Modeling with R</span></em>. CRC Press.
</div>
</div>
</section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "î§‹";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copiato!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copiato!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/ccaudek\.github\.io\/psicometria-r\/intro\.html");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="../../chapters/bayesian_inference/01_intro_bayes.html" class="pagination-link" aria-label="La quantificazione dell'incertezza">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">41</span>&nbsp; <span class="chapter-title">La quantificazione dellâ€™incertezza</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../chapters/bayesian_inference/03_subj_prop.html" class="pagination-link" aria-label="Pensare ad una proporzione in termini soggettivi">
        <span class="nav-page-text"><span class="chapter-number">43</span>&nbsp; <span class="chapter-title">Pensare ad una proporzione in termini soggettivi</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer"><div class="nav-footer">
    <div class="nav-footer-left">
<p><strong>Psicometria</strong> Ã¨ una risorsa didattica creata per il corso di Scienze e Tecniche Psicologiche dellâ€™UniversitÃ  degli Studi di Firenze.</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/ccaudek/psicometria-r/blob/main/chapters/bayesian_inference/02_bayesian_inference.qmd" class="toc-action"><i class="bi bi-github"></i>Mostra il codice</a></li><li><a href="https://github.com/ccaudek/psicometria-r/issues/new" class="toc-action"><i class="bi empty"></i>Segnala un problema</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>Realizzato con <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>


</body></html>