# Introduzione all'inferenza frequentista {#sec-freq-intro}

::: callout-important
## In questo capitolo imparerai a

- Comprendere il background storico da cui si è sviluppato l'approccio frequentista.
- Comprendere il concetto di distribuzione campionaria.
- Familiarizzare con le proprietà della distribuzione campionaria della media dei campioni.
- Comprendere il teorema del limite centrale.
- Acquisire conoscenze sulle proprietà della distribuzione campionaria della varianza.
:::

::: callout-tip
## Prerequisiti

- Leggere il capitolo *Sampling* di [Statistical Inference via Data Science: A ModernDive into R and the Tidyverse (Second Edition)](https://moderndive.com/v2/).
:::

::: callout-caution
## Preparazione del Notebook

```{r}
here::here("code", "_common.R") |> 
  source()
```
:::

## Introduzione 

Ci sono due approcci principali per l'inferenza statistica: la statistica frequentista e la statistica bayesiana. Questi metodi consentono di fare conclusioni sulla popolazione di interesse attraverso l'analisi dei dati. Entrambi gli approcci sono usati per stimare quantità sconosciute, fare previsioni e testare ipotesi, ma differiscono nella loro interpretazione della probabilità e in come integrano le conoscenze precedenti ed evidenze.

Nella statistica frequentista, la probabilità viene interpretata come la frequenza relativa a lungo termine di un evento in un numero infinito di prove. Questo approccio si basa sull'idea che il vero valore di un parametro della popolazione sia fisso, ma sconosciuto e debba essere stimato dai dati. In questo contesto, le inferenze statistiche vengono ottenute a partire dai dati osservati, mediante l'utilizzo di tecniche come la stima puntuale, gli intervalli di confidenza e il test di ipotesi, e facendo alcune assunzioni riguardo al processo sottostante che genera i dati.

D'altra parte, la statistica bayesiana interpreta la probabilità come una misura di convinzione o grado di certezza riguardo a un evento [@jaynes2003probability]. Questo approccio consente di incorporare conoscenze pregresse ed evidenze nell'analisi statistica attraverso l'uso del teorema di Bayes. In questo contesto, il vero valore di un parametro della popolazione è trattato come una variabile casuale e viene continuamente aggiornato man mano che vengono raccolti nuovi dati. Ciò porta alla formazione di una distribuzione completa nello spazio dei parametri, nota come distribuzione a posteriori, che può essere utilizzata per fare previsioni probabilistiche e quantificare l'incertezza associata.

In questo capitolo, approfondiremo il concetto di **distribuzione campionaria** che costituisce uno dei pilastri dell'inferenza statistica frequentista. La distribuzione campionaria ci permette di comprendere come le stime dei parametri della popolazione, come la media o la varianza, cambiano da campione a campione. In particolare, la distribuzione campionaria ci consente di stabilire delle proprietà probabilistiche delle stime campionarie, come ad esempio la loro media e la loro varianza. Queste proprietà sono utili per costruire gli intervalli di fiducia e i test di ipotesi che costituiscono gli strumenti principali dell'inferenza statistica frequentista.

## I Frequentisti sono Razzisti?

Nel @sec-prob-bayes-theorem, abbiamo esaminato le origini storiche e il contesto culturale che ha contribuito all'interpretazione applicativa del teorema di Bayes fornita da Richard Price. Queste origini sono legate alle idee alla base della rivoluzione americana, rappresentando quello che potremmo definire il "lato luminoso" del liberalismo moderno.

Le origini culturali dell'approccio frequentista, invece, sono diametralmente opposte e strettamente connesse a quella che potremmo chiamare la "parte oscura" della modernità. Si potrebbe dire che l'avversione per la soggettività abbia guidato l'ascesa del frequentismo.

Francis Galton (1822-1911) fu un uomo straordinario sotto molti aspetti. Cugino di Charles Darwin e medico qualificato, ereditò una fortuna che gli permise di dedicarsi liberamente ai suoi interessi. Esplorò l'Africa, ricevendo una medaglia dalla Royal Geographical Society, e diede un importante contributo alla meteorologia, notando per primo il fenomeno degli "anticicloni". Tuttavia, il suo contributo più significativo riguardò l'uso della statistica nello studio degli esseri umani, in particolare nell'analisi della trasmissione ereditaria del talento.

Galton trascorse gran parte della sua carriera all'University College di Londra, dove fece numerose scoperte. Tra queste, un importante contributo riguardava la distribuzione normale. Fu anche il primo a spiegare il concetto che oggi conosciamo come "regressione verso la media", da lui chiamato "regressione verso la mediocrità".

Il suo interesse per l'ereditarietà del talento portò Francis Galton a scrivere il libro *Hereditary Genius*, in cui analizzava come individui brillanti tendessero a concentrarsi in specifiche famiglie. Fu lui a coniare l'espressione "nature and nurture" per riferirsi ai due fattori fondamentali che influenzano lo sviluppo umano: l'ereditarietà (ciò che oggi chiamiamo genetica) e l'ambiente.

Tuttavia, Galton non si limitò a osservare e documentare la distribuzione dell'intelligenza. Il suo obiettivo era ambizioso e controverso: creare una scienza per il "miglioramento della specie umana", che egli chiamò "eugenetica". Promuoveva l'idea di incoraggiare la riproduzione tra le famiglie considerate di maggior successo e, al contrario, di scoraggiarla tra quelle ritenute meno fortunate.

Va però sottolineato che Galton abbracciava idee profondamente razziste. In una lettera pubblicata sul *Times* di Londra, descrisse gli africani come "inferiori" e li definì "selvaggi pigri e chiacchieroni". Gli arabi, secondo lui, erano "poco più che consumatori della produzione altrui". Proponeva inoltre di consegnare l'Africa orientale ai cinesi, che giudicava "inclini alla menzogna e alla servilità" ma anche, a suo dire, "naturalmente industriosi e amanti dell'ordine". Per Galton, gli anglosassoni rappresentavano la razza migliore esistente, sebbene ritenesse che gli antichi ateniesi fossero stati il vertice dell’umanità.

Il lavoro di Galton ispirò una generazione successiva di statistici, in particolare Karl Pearson (1857-1936) e Ronald Fisher (1890-1962). Come Galton, Fisher e Pearson erano brillanti, ma condividevano anche le sue idee razziste, considerate inaccettabili sia per gli standard attuali che per quelli del loro tempo.

Karl Pearson, poliedrico studioso e innovatore, divenne professore di matematica applicata all'UCL nel 1885, seguendo le orme di Francis Galton. Dopo la morte di quest’ultimo, ereditò la cattedra di eugenetica, istituita e finanziata da Galton stesso. Pearson fondò la rivista di statistica Biometrika e diede un contributo fondamentale alla disciplina, sviluppando il test del chi quadrato e coniando il termine "deviazione standard".

Ronald Fisher, più giovane, succedette a Pearson come professore di eugenetica presso l'UCL. Considerato un gigante della teoria statistica, Fisher contribuì in modo decisivo allo sviluppo della disciplina, inventando o perfezionando strumenti fondamentali come l'analisi della varianza (ANOVA), il concetto di "significatività statistica" e il metodo della massima verosimiglianza (MLE).

Tutti questi ricercatori cercarono di allontanare la statistica dall'approccio soggettivo di Laplace e Bayes. Come Galton, sia Pearson che Fisher erano convinti sostenitori dell'eugenetica.

È interessante riflettere su quanto le idee di Galton, Pearson e Fisher sull'eugenetica possano aver influenzato le loro visioni scientifiche. Secondo alcuni studiosi, la storia della statistica e quella dell'eugenetica sono strettamente intrecciate. Fisher, e in misura minore Pearson, rigettavano il bayesianesimo perché desideravano conferire un fondamento apparentemente "oggettivo" alle loro idee eugenetiche. Se fosse stata la scienza a "dimostrare" che alcune razze erano inferiori ad altre, o che la riproduzione tra i poveri dovesse essere scoraggiata, queste teorie sarebbero state presentate come indiscutibili. Il bayesianesimo, con la sua componente intrinseca di soggettività, rappresentava una minaccia a questa pretesa di oggettività.

Quanto dovremmo tenere in considerazione le implicazioni storiche ed etiche quando valutiamo la statistica frequentista? @chivers2024everything risponde così: è indubbio che parte dell'ideologia razziale nazista possa essere collegata alle idee di Galton senza particolari difficoltà. Tuttavia, per quanto questa riflessione sia cruciale dal punto di vista storico ed etico, essa non è direttamente pertinente nell'analisi strettamente statistica. La domanda centrale rimane: "Quale approccio metodologico è corretto?" o, ancora meglio, "Quale approccio si dimostra più utile?". Interrogarsi su "Quale approccio ha avuto i sostenitori più discutibili?" rischia di allontanarsi dal cuore del dibattito statistico.

Pur riconoscendo il merito di questa risposta nel mantenere l’attenzione sulla metodologia, ritengo che sia intrinsecamente insufficiente. Consideriamo un esempio ipotetico: supponiamo che in una “torre d’avorio” – che rappresenti la statistica, l’accademia o la scienza in senso lato – la teoria A risulti più efficace della teoria B. Tuttavia, al di fuori di questo contesto isolato, la teoria A genera conseguenze etiche inaccettabili, mentre la teoria B no. Dovremmo davvero scegliere la teoria A semplicemente perché funziona meglio in un sistema chiuso e teorico? La mia risposta è un netto e inequivocabile no.

Le cosiddette “torri d’avorio” sono costrutti ideologici che non trovano riscontro nella realtà. Non esiste una rigida separazione tra ciò che accade “all’interno” e “all’esterno”: scienza ed etica non sono domini isolati, ma sfere che si intrecciano costantemente. Valutare una teoria esclusivamente sulla base della sua efficacia in un contesto ristretto equivale a ignorarne le implicazioni più ampie, spesso con conseguenze potenzialmente dannose.

Nel caso specifico del frequentismo, è evidente – come mostrerò in seguito – che questo approccio non solo presenta implicazioni etiche discutibili, ma è anche intrinsecamente debole dal punto di vista metodologico. La sua presunta superiorità all’interno di un ambito limitato è un’illusione che non resiste a un’analisi critica più ampia. Non possiamo, né dobbiamo, separare l’efficacia teorica dalle conseguenze pratiche ed etiche.

Il frequentismo fallisce su entrambi i fronti: morale e scientifico. Sostenere tale approccio significa perpetuare un paradigma insostenibile, incapace di rispondere alle esigenze della scienza moderna e della responsabilità sociale. Pertanto, la sua difesa non può essere giustificata in alcun contesto.

## Stime, stimatori e parametri

Spostiamo ora il discorso da un piano culturale ad un piano strettamente statistico. Consideriamo il concetto di *stima statistica*.

Quando si analizzano i dati, solitamente si è interessati a una quantità a livello di popolazione; tuttavia, di solito si ha accesso solo a un campione di osservazioni. La quantità sconosciuta di nostro interesse viene chiamata *parametro*. La statistica che calcoliamo utilizzando i dati del campione viene chiamata *stima*, e la formula che la produce viene chiamata *stimatore*. Formalmente, uno stimatore è una funzione dei dati osservati utilizzata per produrre una stima di un parametro.

In altre parole, quando analizziamo un campione di dati, vogliamo inferire alcune proprietà della popolazione di cui il campione è rappresentativo. Il parametro rappresenta la misura di tali proprietà, ma spesso non è possibile calcolarlo direttamente sulla popolazione. Pertanto, lo stimiamo utilizzando le osservazioni del campione. La stima è quindi l'approssimazione del valore del parametro che otteniamo dal nostro campione, mentre lo stimatore è la formula matematica utilizzata per calcolare questa stima.

Tuttavia, le stime non sono necessariamente identiche ai parametri di nostro interesse. Le stime presentano una certa incertezza dovuta alla variabilità del campionamento. In questo capitolo esamineremo come l'approccio frequentista quantifica l'incertezza nelle nostre stime, in modo da poter trarre conclusioni sul parametro.

## Distribuzione campionaria

In questo capitolo esploreremo come la media di un campione casuale può essere utilizzata per stimare la media $\mu$ di una popolazione. Per valutare l'incertezza di questa stima, ci avvaliamo del concetto di *distribuzione campionaria*, un'importante idea dell'approccio frequentista.

Per introdurre il concetto, utilizzeremo una popolazione finita di piccole dimensioni, pur sapendo che le proprietà illustrate valgono anche per popolazioni di dimensioni maggiori.

### Esempio introduttivo

Consideriamo la seguente popolazione:

```{r}
x <- c(2, 4.5, 5, 5.5)
x
```

L'istogramma sottostante rappresenta la distribuzione di frequenza della popolazione:

```{r}
hist(
  x, breaks = 5, 
  freq = FALSE, 
  main = "Distribuzione della popolazione", 
  xlab = "Valori"
)
```

Calcoliamo la media e la varianza della popolazione:

```{r}
mean(x)  # Media
var(x)   # Varianza
```

### Campionamento

Supponiamo ora di estrarre tutti i possibili campioni di dimensione $n = 2$ dalla popolazione. Per generare queste combinazioni:

```{r}
samples <- expand.grid(x, x)
samples
```

Ogni riga rappresenta un campione possibile. Calcoliamo il numero totale di campioni:

```{r}
nrow(samples)
```

Ora calcoliamo la media di ciascun campione, ottenendo la distribuzione campionaria delle medie per $n = 2$:

```{r}
sample_means <- rowMeans(samples)
sample_means
```

### Visualizzazione della distribuzione campionaria

Possiamo rappresentare graficamente questa distribuzione:

```{r}
hist(
  sample_means, 
  breaks = 5, 
  freq = FALSE, 
  main = "Distribuzione campionaria delle medie (n = 2)", 
  xlab = "Media campionaria"
)
```

### Verifiche teoriche

#### Media della distribuzione campionaria

La media della distribuzione campionaria deve essere uguale alla media della popolazione:

```{r}
mean(x)  # Media della popolazione
mean(sample_means)  # Media della distribuzione campionaria
```

#### Varianza della distribuzione campionaria

La varianza della distribuzione campionaria deve essere pari alla varianza della popolazione divisa per $n$:

```{r}
# Evito la divisione per (n - 1)
variance <- function(x) {
  mean((x - mean(x))^2)
}
```

```{r}
variance(x) / 2  # Varianza teorica
variance(sample_means)  # Varianza empirica
```

### Esempio di campione osservato

Consideriamo un singolo campione, ad esempio $\{5, 5.5\}$:

```{r}
observed_sample <- c(5, 5.5)
observed_sample
```

Troviamo la sua media e deviazione standard:

```{r}
mean(observed_sample)  # Media del campione
sqrt(variance(observed_sample))    # Deviazione standard del campione
```

Confrontiamo questi valori con quelli della popolazione:

```{r}
mean(x)  # Media della popolazione
sqrt(variance(x))     # Deviazione standard della popolazione
```

In conclusione, dalla simulazione emergono due risultati fondamentali:

1. **La media della distribuzione campionaria** coincide con la media della popolazione. Questo significa che, se si considera la media $\bar{X}_n$ di campioni casuali di ampiezza $n$, il valore atteso di $\bar{X}_n$ è uguale alla media della popolazione $\mu$. Formalmente:

   $$
   \mathbb{E}(\bar{X}_n) = \frac{1}{n} \mathbb{E}(S_n) = \frac{1}{n} n \mu = \mu,
   $$
   dove $\mathbb{E}(\cdot)$ rappresenta il valore atteso e $S_n$ la somma delle osservazioni nel campione.

2. **La varianza della distribuzione campionaria** è inferiore alla varianza della popolazione. In particolare, la varianza delle medie campionarie è data dalla varianza della popolazione divisa per l'ampiezza del campione, ovvero:

   $$
   \mathbb{V}(\bar{X}) = \frac{\sigma^2}{n}.
   $$

::: {.callout-note}
Il secondo risultato sopra può essere dimostrato come segue.

Sia $X_1, X_2, \dots, X_n$ un campione casuale di $n$ osservazioni indipendenti estratte da una popolazione con media $\mu$ e varianza $\sigma^2$. La media campionaria è definita come:

$$
\bar{X} = \frac{1}{n} \sum_{i=1}^n X_i.
$$
  
Per definizione, la varianza di $\bar{X}$ è:

$$
\mathbb{V}(\bar{X}) = \mathbb{V}\left(\frac{1}{n} \sum_{i=1}^n X_i\right).
$$
  
Poiché una costante moltiplicata da una variabile aleatoria può essere "estratta" dalla varianza, otteniamo:

$$
\mathbb{V}(\bar{X}) = \frac{1}{n^2} \mathbb{V}\left(\sum_{i=1}^n X_i\right).
$$
  
Ora dobbiamo calcolare $\mathbb{V}\left(\sum_{i=1}^n X_i\right)$. Le variabili $X_1, X_2, \dots, X_n$ sono indipendenti, quindi la varianza della somma è la somma delle varianze:

$$
\mathbb{V}\left(\sum_{i=1}^n X_i\right) = \sum_{i=1}^n \mathbb{V}(X_i).
$$
  
Poiché tutte le variabili $X_i$ hanno la stessa varianza $\sigma^2$:

$$
\mathbb{V}\left(\sum_{i=1}^n X_i\right) = n \sigma^2.
$$
  
Sostituendo nella formula precedente, otteniamo:

$$
\mathbb{V}(\bar{X}) = \frac{1}{n^2} \cdot n \sigma^2 = \frac{\sigma^2}{n}.
$$

In generale, dunque, per un campione di ampiezza $n$, vale la relazione $\mathbb{V}(\bar{X}) = \frac{\sigma^2}{n}$.
   
:::

### Proprietà  della distribuzione campionaria

Infine, osserviamo una proprietà fondamentale della distribuzione campionaria:

- Se la popolazione segue una **distribuzione normale**, allora anche la distribuzione delle medie campionarie seguirà una distribuzione normale, indipendentemente dall'ampiezza del campione.

- Se invece la popolazione **non segue una distribuzione normale**, il **teorema del limite centrale** garantisce che, all'aumentare della dimensione del campione $n$, la distribuzione campionaria delle medie tenderà a una distribuzione normale.

Queste proprietà sono centrali in molti metodi statistici, poiché consentono di fare inferenza sulla popolazione utilizzando campioni.

## Teorema del Limite Centrale

Esaminiamo ora più in dettaglio il Teorema del Limite Centrale (TLC). Nel 1812, Laplace dimostrò il TLC, che afferma che la somma di una sequenza di variabili casuali indipendenti tende a distribuirsi secondo una distribuzione Normale. Inoltre, il TLC stabilisce i parametri della distribuzione Normale risultante in base ai valori attesi e alle varianze delle variabili casuali sommate.

::: {#thm-}
Si supponga che $Y = Y_1, \dots, Y_i, \ldots, Y_n$ sia una sequenza di v.a. i.i.d. (variabili aleatorie identicamente distribuite e indipendenti) con $\mathbb{E}(Y_i) = \mu$ e $SD(Y_i) = \sigma$. Si definisca una nuova variabile casuale come:

$$
Z = \frac{1}{n} \sum_{i=1}^n Y_i.
$$

Con $n \rightarrow \infty$, $Z$ tenderà a seguire una distribuzione Normale con lo stesso valore atteso di $Y_i$ e una deviazione standard ridotta di un fattore pari a $\frac{1}{\sqrt{n}}$:

$$
p_Z(z) \rightarrow \mathcal{N}\left(z \ \Bigg| \ \mu, \, \frac{\sigma}{\sqrt{n}} \right).
$$
:::

Il TLC può essere generalizzato a variabili casuali che non sono identicamente distribuite, a condizione che siano indipendenti e abbiano aspettative e varianze finite. Molti fenomeni naturali, come l'altezza degli adulti, sono il risultato di una combinazione di effetti additivi relativamente piccoli. Questi effetti, indipendentemente dalla loro distribuzione individuale, tendono a portare alla normalità della distribuzione risultante. Questa è la ragione per cui la distribuzione normale fornisce una buona approssimazione per la distribuzione di molti fenomeni naturali.

### Illustrazione del TLC

Per dimostrare il Teorema del Limite Centrale, consideriamo una popolazione iniziale con una distribuzione fortemente asimmetrica: una distribuzione Beta con parametri $\alpha = 2$ e $\beta = 1$. Estraiamo 50.000 campioni casuali di ampiezza $n$ da questa popolazione e costruiamo la distribuzione campionaria delle medie.

Definiamo una funzione per simulare e visualizzare la distribuzione campionaria per diversi valori di $n$:

```{r}
# Parametri della distribuzione Beta
alpha <- 2
beta <- 1

# Funzione per simulare e visualizzare la distribuzione campionaria
plot_samples <- function(n) {
  # Media e deviazione standard della distribuzione Beta
  mu <- alpha / (alpha + beta)
  sigma <- sqrt(alpha * beta / ((alpha + beta)^2 * (alpha + beta + 1)))
  
  # Generazione di 50.000 campioni casuali di dimensione n
  sample_means <- replicate(50000, mean(rbeta(n, alpha, beta)))
  
  # Dati per la distribuzione normale teorica
  x <- seq(mu - 3 * sigma, mu + 3 * sigma, length.out = 100)
  y <- dnorm(x, mean = mu, sd = sigma / sqrt(n))
  
  # Creazione del grafico
  hist(
    sample_means, 
    breaks = 50, 
    probability = TRUE, 
    main = paste("Ampiezza campionaria =", n), 
    xlab = "Media campionaria", 
    ylab = "Densità"
  )
  lines(x, y, col = "black", lwd = 2)
}
```

### Visualizzazione per diverse dimensioni campionarie

1. **Ampiezza campionaria $n = 1$**

Se $n = 1$, la distribuzione campionaria delle medie coincide con la popolazione di partenza.

```{r}
plot_samples(1)
```

2. **Ampiezza campionaria $n = 2$**

Per $n = 2$, la distribuzione delle medie dei campioni inizia ad avvicinarsi alla normalità.

```{r}
plot_samples(2)
```

3. **Ampiezza campionaria $n = 4$**

Per $n = 4$, l'approssimazione alla distribuzione normale migliora.

```{r}
plot_samples(4)
```

4. **Ampiezza campionaria $n = 30$**

Per $n = 30$, la distribuzione campionaria delle medie è ben approssimata dalla normale.

```{r}
plot_samples(30)
```

In conclusione, il **Teorema del Limite Centrale (TLC)** afferma che, indipendentemente dalla forma della distribuzione della popolazione:

- Per campioni di dimensione sufficiente, la distribuzione campionaria delle medie $\bar{X}$ tende a una distribuzione normale.
- La media $\mu$ e la deviazione standard $\sigma$ della popolazione determinano la distribuzione delle medie campionarie come segue:

  $$
  \bar{X} \sim \mathcal{N}(\mu, \sigma / \sqrt{n}),
  $$
  
  dove $n$ è l'ampiezza del campione.

Questa proprietà ha implicazioni fondamentali:

1. La **normalità emergente** giustifica l'uso della distribuzione normale anche quando i dati non sono inizialmente normali.
2. Il TLC fornisce una formula esplicita per calcolare l'**errore standard** $\sigma / \sqrt{n}$, che quantifica la precisione della media campionaria come stima della media della popolazione.


### Applicazioni in psicologia

Molti fenomeni psicologici che misuriamo (ad esempio, il QI come media di molte abilità cognitive) derivano dalla media di più variabili, e quindi seguono la distribuzione normale grazie al TLC. Questo spiega perché la distribuzione normale appare così frequentemente nei dati sperimentali di psicologia e in molte altre discipline scientifiche.

## Distribuzioni campionarie di altre statistiche

Abbiamo già analizzato la distribuzione campionaria della media dei campioni. Tuttavia, è possibile costruire distribuzioni campionarie per altre statistiche campionarie. Ad esempio, consideriamo la distribuzione campionaria del valore massimo e della varianza.

### Distribuzione campionaria del valore massimo

Supponiamo di avere una popolazione normalmente distribuita con media $\mu = 100$ e deviazione standard $\sigma = 15$. Generiamo 10.000 campioni casuali di ampiezza $n = 5$ e calcoliamo il valore massimo per ogni campione. 

#### Simulazione e visualizzazione

```{r}
set.seed(123)  # Per risultati riproducibili

# Parametri della distribuzione
mu <- 100
sigma <- 15

# Simulazione: calcolo del valore massimo per ciascun campione
n_samples <- 10000
sample_maxes <- replicate(
  n_samples, 
  max(rnorm(5, mean = mu, sd = sigma))
)

# Istogramma della distribuzione campionaria del valore massimo
hist(
  sample_maxes, 
  breaks = 50, 
  probability = TRUE, 
  main = "Distribuzione campionaria del valore massimo",
  xlab = "Valore massimo", 
  ylab = "Densità"
)

# Sovrapposizione della distribuzione normale della popolazione
curve(dnorm(x, mean = mu, sd = sigma), add = TRUE, col = "black", lwd = 2)
```

Osserviamo che il valore atteso della distribuzione campionaria del massimo è maggiore della media della popolazione $\mu$.

### Distribuzione campionaria della varianza

Un'altra statistica interessante è la varianza campionaria. La formula della varianza campionaria, basata sulla statistica descrittiva, è:

$$
S^2 = \frac{\sum_{i=1}^n (Y_i - \bar{Y})^2}{n}.
$$

Calcoliamo la distribuzione campionaria della varianza per campioni di ampiezza $n = 5$.

#### Simulazione e visualizzazione

```{r}
set.seed(123)

# Simulazione: calcolo della varianza per ciascun campione
sample_vars <- replicate(
  n_samples, 
  variance(rnorm(5, mean = mu, sd = sigma))
)

# Istogramma della distribuzione campionaria della varianza
hist(
  sample_vars, 
  breaks = 50, 
  probability = TRUE, 
  main = "Distribuzione campionaria della varianza",
  xlab = "Varianza", ylab = "Densità"
)
```

```{r}
# Media empirica della varianza campionaria
mean(sample_vars)
```

Sappiamo che la varianza della popolazione è $\sigma^2 = 15^2 = 225$. Tuttavia, il valore medio empirico delle varianze campionarie calcolate con $S^2$ risulta minore di 225. Questo avviene perché lo stimatore $S^2$ è distorto.

### Correzione della distorsione

Per eliminare la distorsione, utilizziamo il seguente stimatore della varianza della popolazione:

$$
s^2 = \frac{\sum_{i=1}^n (Y_i - \bar{Y})^2}{n-1}.
$$

#### Verifica con simulazione

```{r}
set.seed(123)

# Simulazione: calcolo della varianza con la correzione
sample_vars_unbiased <- replicate(
  n_samples, 
  var(rnorm(5, mean = mu, sd = sigma))
)

# Istogramma della distribuzione campionaria della varianza corretta
hist(
  sample_vars_unbiased, 
  breaks = 50, 
  probability = TRUE, 
  main = "Distribuzione campionaria della varianza (corretta)",
  xlab = "Varianza", 
  ylab = "Densità"
)
```

```{r}
# Media empirica della varianza corretta
mean(sample_vars_unbiased)
```

Con questo stimatore, la media della distribuzione campionaria coincide con la varianza reale della popolazione $\sigma^2 = 225$.

In conclusione:

1. La **distribuzione campionaria del massimo** mostra che il valore massimo dei campioni è, in media, maggiore della media della popolazione.
2. La **varianza campionaria non corretta** ($S^2$) è uno stimatore distorto, poiché il suo valore atteso non coincide con la varianza della popolazione.
3. Lo stimatore corretto $s^2$, che utilizza il divisore $n - 1$, elimina la distorsione e fornisce una stima non distorta della varianza della popolazione.

In generale, uno stimatore è considerato **non distorto** quando il valore atteso delle sue stime coincide con il valore reale del parametro. Nel caso della media campionaria e della varianza corretta, entrambi gli stimatori sono non distorti.

## Riflessioni Conclusive

In generale, i parametri della popolazione sono sconosciuti, ma possiamo stimarli utilizzando le informazioni del campione. Di seguito viene presentata una tabella che riassume i simboli comuni utilizzati per indicare le quantità note e sconosciute nel contesto dell'inferenza statistica. Questo ci aiuterà a tenere traccia di ciò che sappiamo e ciò che non sappiamo.

|Simbolo          | Nome           | È qualcosa che conosciamo?     |
|:----------------|:-------------|:--------------------|
|$s$              |Deviazione standard del campione    |Sì, la calcoliamo dai dati grezzi |
|$\sigma$         |Deviazione standard della popolazione  | No, tranne in casi particolari o nelle simulazioni  |
|$\hat{\sigma}$  | Stima della deviazione standard della popolazione | Sì, ma non è uguale a $\sigma$ |
|$s^2$            | Varianza del campione    |Sì, la calcoliamo dai dati grezzi |
|$\sigma^2$       | Varianza della popolazione  | No, tranne in casi particolari o nelle simulazioni  |
|$\hat{\sigma}^2$ | Stima della varianza della popolazione  | Sì, ma non è uguale a $\sigma^2$  |
: {tbl-colwidths="[10, 40, 50]"}

\
Utilizzando le informazioni di un campione casuale di ampiezza $n$:

- La stima migliore che possiamo ottenere per la media $\mu$ della popolazione è la media del campione $\bar{Y}$.
- La stima migliore che possiamo ottenere per la varianza $\sigma^2$ della popolazione è:

$$
\hat{\sigma}^2 = \frac{1}{n-1} \sum_{i=1}^n (Y_i - \bar{Y})^2.
$$

## Esercizi

::: {.callout-important title="Problemi 1" collapse="true"}
**Parte 1: Popolazione di Piccole Dimensioni**
Si consideri una popolazione con i seguenti valori:

$$
x = \{2, 4.5, 5, 5.5\}
$$

1. Calcolare la media e la varianza della popolazione.
2. Estrarre tutti i possibili campioni di ampiezza $n = 2$ con ripetizione e calcolare la media di ciascun campione.
3. Rappresentare graficamente la distribuzione campionaria delle medie.
4. Calcolare la probabilità che la media campionaria sia inferiore a 3:
   - Esattamente, utilizzando la distribuzione campionaria.
   - Approssimativamente, assumendo una distribuzione normale se il campione fosse sufficientemente grande.

**Parte 2: Popolazione di Grandi Dimensioni**

Si consideri ora una popolazione più grande, generata da una distribuzione normale con media $\mu = 10$ e deviazione standard $\sigma = 3$.

1. Generare una popolazione di 1000 osservazioni.
2. Calcolare la media e la varianza della popolazione.
3. Estrarre 10.000 campioni casuali di ampiezza $n = 15$ e calcolare la media campionaria per ciascun campione.
4. Rappresentare graficamente la distribuzione campionaria delle medie.
5. Calcolare la probabilità che la media campionaria sia inferiore a 9:
   - Esattamente, utilizzando la distribuzione campionaria.
   - Approssimativamente, utilizzando la distribuzione normale.

**Obiettivo**: Verificare sperimentalmente le proprietà della distribuzione campionaria della media e confrontare i risultati con le previsioni teoriche fornite dal Teorema del Limite Centrale.
:::

::: {.callout-tip title="Soluzioni 1" collapse="true"}
Proprietà della Distribuzione Campionaria della Media

1. Media: La media della distribuzione campionaria coincide con la media della popolazione:

2. Varianza: La varianza della distribuzione campionaria è pari alla varianza della popolazione divisa per la dimensione del campione:

3. Forma:

- Se la popolazione segue una distribuzione normale, anche la distribuzione campionaria della media sarà normale.
- Se la popolazione non è normale, il Teorema del Limite Centrale garantisce che la distribuzione campionaria della media sarà approssimativamente normale per campioni di dimensioni sufficientemente grandi ($n \geq 30$).

Definiamo una popolazione e calcoliamo i parametri:

```{r}
# Popolazione
x <- c(2, 4.5, 5, 5.5)
mean(x)  # Media della popolazione
var(x)   # Varianza della popolazione
```

Estrarre tutti i possibili campioni di ampiezza $n = 2$ e calcolare la media di ciascun campione:

```{r}
# Tutti i campioni di ampiezza 2
samples <- expand.grid(x, x)
sample_means <- rowMeans(samples)

# Visualizzare la distribuzione campionaria
df <- data.frame(sample_means = sample_means)

ggplot(df, aes(x = sample_means)) +
  geom_histogram(aes(y = after_stat(density)), bins = 5, fill = "blue", alpha = 0.6) +
  geom_density(color = "red", size = 1) +
  labs(
    title = "Distribuzione campionaria delle medie",
    x = "Media campionaria",
    y = "Densità"
  )
```

Calcoliamo la probabilità che, all'interno della distribuzione campionaria, la media del campione sia minore di 3. Troviamo il valore esatto nella simulazione. Approssimiamo il valore esatto con il valore atteso se il campione fosse sufficientemente grande da poter assumere una distribuzione campionaria normale:

```{r}
# Probabilità esatta dalla distribuzione campionaria
exact_probability <- mean(sample_means < 3)
exact_probability

# Approssimazione tramite distribuzione normale
mu <- mean(x)  # Media della popolazione
sigma <- sqrt(var(x) / 2)  # Deviazione standard della distribuzione campionaria
approx_probability <- pnorm(3, mean = mu, sd = sigma)
approx_probability
```

Ripetiamo ora l'esempio, mantenendo la stessa struttura della simulazione, ma considerando una popolazione più grande tale per cui si possa estrarre un campione di ampiezza 15:

```{r}
# Nuova popolazione
set.seed(123)
x_large <- rnorm(1000, mean = 10, sd = 3)  # Popolazione più grande
mean(x_large)  # Media della popolazione
var(x_large)   # Varianza della popolazione

# Estrazione di campioni di ampiezza 15
samples_large <- replicate(10000, mean(sample(x_large, size = 15)))

# Creazione del data frame per ggplot2
df_large <- data.frame(sample_means = samples_large)

# Visualizzazione con ggplot2
ggplot(df_large, aes(x = sample_means)) +
  geom_histogram(aes(y = after_stat(density)), bins = 50, fill = "blue", alpha = 0.6) +
  geom_density(color = "red", size = 1) +
  labs(
    title = "Distribuzione campionaria delle medie (n = 15)",
    x = "Media campionaria",
    y = "Densità"
  )
```

```{r}
# Probabilità esatta dalla simulazione
exact_probability_large <- mean(samples_large < 9)
exact_probability_large
```

```{r}
# Approssimazione tramite distribuzione normale
mu_large <- mean(x_large)
sigma_large <- sqrt(var(x_large) / 15)
approx_probability_large <- pnorm(9, mean = mu_large, sd = sigma_large)
approx_probability_large
```
:::


::: {.callout-important title="Problemi 2" collapse="true"}
**Distribuzione Campionaria della Differenza tra Medie**

L’obiettivo di questo esercizio è esplorare le proprietà della distribuzione campionaria della differenza tra medie campionarie, analizzando sia il caso di popolazioni finite di piccole dimensioni sia il caso di popolazioni più grandi, con distribuzioni normali.

**Esercizio 1: Simulazione con Popolazioni di Piccole Dimensioni**

Consideriamo due popolazioni finite composte da un numero limitato di elementi:

- **Popolazione 1:** $x_1 = \{2, 4.5, 5, 6\}$
- **Popolazione 2:** $x_2 = \{3, 3.5, 4, 7\}$

#### **Compiti:**
1. **Calcolo dei parametri delle popolazioni:**  
   - Determinare la media e la varianza di entrambe le popolazioni.
   
2. **Estrazione di campioni:**  
   - Estrarre tutti i possibili campioni di ampiezza $n = 2$ con ripetizione da entrambe le popolazioni.
   - Calcolare la media campionaria di ciascun campione.

3. **Distribuzione campionaria della differenza tra le medie:**  
   - Calcolare la differenza tra le medie di tutti i possibili campioni ottenuti dalle due popolazioni.
   - Rappresentare graficamente la distribuzione della differenza tra le medie.

4. **Probabilità della differenza tra le medie:**  
   - Calcolare la probabilità che la differenza tra le medie campionarie sia maggiore di 1.

**Esercizio 2: Simulazione con Popolazioni di Grande Dimensione**

Consideriamo ora due popolazioni più grandi, distribuite normalmente:

- **Popolazione 1:** $X_1 \sim N(10, 4^2)$ (media = 10, deviazione standard = 4)
- **Popolazione 2:** $X_2 \sim N(8, 3^2)$ (media = 8, deviazione standard = 3)

**Compiti:**

1. **Generazione delle popolazioni:**  
   - Creare due popolazioni casuali di 10.000 osservazioni ciascuna, distribuite normalmente.

2. **Estrazione di campioni:**  
   - Estrarre 10.000 campioni casuali di ampiezza $n_1 = 15$ dalla prima popolazione e $n_2 = 20$ dalla seconda popolazione.
   - Calcolare la media di ciascun campione.

3. **Distribuzione campionaria della differenza tra le medie:**  
   - Calcolare la differenza tra le medie campionarie ottenute dalle due popolazioni.
   - Rappresentare graficamente la distribuzione della differenza tra le medie.

4. **Probabilità della differenza tra le medie:**  
   - Calcolare la probabilità che la differenza tra le medie campionarie sia maggiore di 2 in due modi:
     - **Metodo empirico:** utilizzando la distribuzione ottenuta nella simulazione.
     - **Metodo teorico:** approssimando la distribuzione con una normale e calcolando la probabilità con la formula teorica della varianza della differenza tra le medie.

**Domande di Discussione**

1. Come cambia la forma della distribuzione campionaria al variare delle dimensioni dei campioni $n_1$ e $n_2$?
2. La probabilità stimata tramite simulazione coincide con quella calcolata utilizzando l’approssimazione normale? Perché?
3. Cosa accadrebbe alla distribuzione campionaria se le popolazioni originali non fossero normali? Quale sarebbe il ruolo del Teorema del Limite Centrale?
:::

::: {.callout-tip title="Soluzioni 2" collapse="true"}
**Esercizio 1: Simulazione con Popolazioni di Piccola Dimensione**

Supponiamo di avere due popolazioni finite definite come segue:

- Popolazione 1: $x_1 = \{2, 4.5, 5, 6\}$
- Popolazione 2: $x_2 = \{3, 3.5, 4, 7\}$

1. Calcola le medie e le varianze delle due popolazioni:

```{r}
# Popolazione 1
x1 <- c(2, 4.5, 5, 6)
mean(x1)  # Media di x1
var(x1)   # Varianza di x1
```

```{r}
# Popolazione 2
x2 <- c(3, 3.5, 4, 7)
mean(x2)  # Media di x2
var(x2)   # Varianza di x2
```

2. Estrai tutti i possibili campioni di ampiezza $n = 2$ da entrambe le popolazioni:
   
```{r}
# Tutti i campioni di ampiezza 2
samples1 <- expand.grid(x1, x1)
samples2 <- expand.grid(x2, x2)

# Medie campionarie
sample_means1 <- rowMeans(samples1)
sample_means2 <- rowMeans(samples2)
```

3. Calcola la differenza tra le medie campionarie di ciascuna combinazione di campioni:
   
```{r}
# Differenze tra le medie campionarie
sample_diff <- as.vector(outer(sample_means1, sample_means2, "-"))
```

4. Visualizza la distribuzione campionaria della differenza tra le medie:
   
```{r}
# Istogramma della differenza tra medie campionarie

# Creazione del data frame per ggplot2
df_diff <- data.frame(sample_diff = sample_diff)

# Visualizzazione con ggplot2
ggplot(df_diff, aes(x = sample_diff)) +
  geom_histogram(aes(y = after_stat(density)), bins = 10, fill = "blue", alpha = 0.6) +
  geom_density(color = "red", size = 1) +
  labs(
    title = "Distribuzione campionaria della differenza tra medie",
    x = "Differenza campionaria",
    y = "Densità"
  )
```

5. Calcola la probabilità che la differenza campionaria sia maggiore di 1:

```{r}
# Probabilità esatta dalla distribuzione campionaria
exact_probability <- mean(sample_diff > 1)
exact_probability
```

**Esercizio 2: Simulazione con Popolazioni di Grande Dimensione**

Ora considera due popolazioni più grandi con distribuzioni normali:

- Popolazione 1: $X_1 \sim N(10, 4^2)$
- Popolazione 2: $X_2 \sim N(8, 3^2)$

1. Genera due popolazioni casuali:

```{r}
set.seed(123)
pop1 <- rnorm(10000, mean = 10, sd = 4)
pop2 <- rnorm(10000, mean = 8, sd = 3)
```

2. Estrai 10.000 campioni casuali di ampiezza $n_1 = 15$ e $n_2 = 20$ rispettivamente:
   
```{r}
# Estrazione di campioni e calcolo delle medie
sample_means1 <- replicate(10000, mean(sample(pop1, size = 15)))
sample_means2 <- replicate(10000, mean(sample(pop2, size = 20)))
```

3. Calcola la differenza tra le medie campionarie:
   
```{r}
# Differenze tra medie campionarie
sample_diff_large <- sample_means1 - sample_means2
```

4. Visualizza la distribuzione campionaria della differenza tra le medie:
   
```{r}
# Istogramma della distribuzione campionaria

# Creazione del data frame per ggplot2
df_diff_large <- data.frame(sample_diff = sample_diff_large)

# Visualizzazione con ggplot2
ggplot(df_diff_large, aes(x = sample_diff)) +
  geom_histogram(aes(y = after_stat(density)), bins = 50, fill = "blue", alpha = 0.6) +
  geom_density(color = "red", size = 1) +
  labs(
    title = "Distribuzione campionaria della differenza tra medie (n1 = 15, n2 = 20)",
    x = "Differenza campionaria",
    y = "Densità"
  )
```

5. Calcola la probabilità che la differenza campionaria sia maggiore di 2 utilizzando:

   - la simulazione;
   - l'approssimazione normale.
   
```{r}
# Probabilità esatta
exact_probability_large <- mean(sample_diff_large > 2)
exact_probability_large
```

```{r}
# Approssimazione normale
mu_diff <- 10 - 8  # Differenza tra le medie delle popolazioni
sigma_diff <- sqrt(4^2 / 15 + 3^2 / 20)  # Deviazione standard della differenza
approx_probability_large <- 1 - pnorm(2, mean = mu_diff, sd = sigma_diff)
approx_probability_large
```

**Domande di Discussione.**

1. Come cambia la forma della distribuzione campionaria al variare delle dimensioni campionarie $n_1$ e $n_2$?
2. La probabilità calcolata tramite simulazione coincide con quella calcolata tramite approssimazione normale? Perché?
3. Cosa accadrebbe alla distribuzione campionaria se le popolazioni originali non fossero normali?
:::


::: {.callout-important title="Problemi 3" collapse="true"}
**Problema: Distribuzione Campionaria di una Proporzione**

L'obiettivo di questo esercizio è esplorare la distribuzione campionaria di una proporzione campionaria $\hat{p}$ e verificare l'applicabilità dell'approssimazione normale per grandi dimensioni campionarie, come previsto dal Teorema del Limite Centrale.

**Situazione**

Supponiamo di avere una popolazione infinita in cui ciascun individuo può appartenere a una di due categorie: "successo" (codificato come 1) o "insuccesso" (codificato come 0). La probabilità di successo nella popolazione è data da $p = 0.6$.

**Compiti**

1. **Definizione della popolazione e dei parametri:**  
   - La popolazione ha una proporzione di successi pari a $p = 0.6$.
   - La deviazione standard teorica della distribuzione campionaria della proporzione è calcolata come:  
     $$
     \text{SD}(\hat{p}) = \sqrt{\frac{p(1 - p)}{n}}
     $$
   - Si fissi una dimensione campionaria pari a $n = 100$.

2. **Simulazione di campioni:**  
   - Generare 10.000 campioni casuali di ampiezza $n = 100$.
   - Per ogni campione, calcolare la proporzione campionaria $\hat{p}$, cioè la frazione di successi nel campione.

3. **Distribuzione campionaria delle proporzioni:**  
   - Rappresentare graficamente la distribuzione delle proporzioni campionarie con un istogramma.
   - Sovrapporre la distribuzione normale teorica $N(p, \text{SD}(\hat{p}))$ per confrontare l'andamento empirico con quello teorico.

4. **Analisi della distribuzione:**  
   - Valutare se la distribuzione campionaria ottenuta rispetta l’approssimazione normale.
   - Riflettere su come la dimensione del campione e il valore di $p$ influenzano questa approssimazione.

**Domande di Discussione**

1. La distribuzione campionaria delle proporzioni $\hat{p}$ sembra approssimarsi a una distribuzione normale? Perché?
2. Cosa accadrebbe se la dimensione del campione fosse più piccola, ad esempio $n = 30$?
3. Se la probabilità di successo $p$ fosse molto vicina a 0 o 1, l'approssimazione normale sarebbe ancora valida? Perché?
:::

::: {.callout-tip title="Soluzioni 3" collapse="true"}
La distribuzione campionaria di una proporzione descrive come la proporzione campionaria ($\hat{p}$) varia tra campioni di una popolazione. Per campioni grandi, il Teorema del Limite Centrale garantisce che la distribuzione campionaria di $\hat{p}$ può essere approssimata con una distribuzione normale.

1. **Supponiamo una popolazione infinita** in cui la probabilità di successo ($p$) è $p = 0.6$. Scegli una dimensione campionaria $n = 100$.
2. Simula 10.000 campioni casuali di ampiezza $n$ e calcola le proporzioni campionarie ($\hat{p}$).
3. Confronta l'istogramma delle proporzioni campionarie con la distribuzione normale teorica approssimativa.

```{r}
# Parametri della popolazione
p <- 0.6  # Probabilità di successo nella popolazione
n <- 100  # Dimensione del campione

# Simulazione di 10.000 campioni
set.seed(123)
sample_props <- replicate(10000, mean(rbinom(n, size = 1, prob = p)))

# Creazione di un data frame per ggplot2
df_props <- data.frame(sample_props = sample_props)

# Parametri della distribuzione normale teorica
mean_theoretical <- p
sd_theoretical <- sqrt(p * (1 - p) / n)

# Visualizzazione con ggplot2
ggplot(df_props, aes(x = sample_props)) +
  geom_histogram(aes(y = after_stat(density)), bins = 40, fill = "blue", alpha = 0.6) +
  stat_function(
    fun = dnorm,
    args = list(mean = mean_theoretical, sd = sd_theoretical),
    color = "red",
    size = 1
  ) +
  labs(
    title = "Distribuzione campionaria di una proporzione (n = 100)",
    x = "Proporzione campionaria (\u0302p)",
    y = "Densità"
  ) 
```

1. **Popolazione e parametri**:
   - La popolazione è definita da $p = 0.6$.
   - La deviazione standard teorica della distribuzione campionaria è calcolata come $\text{SD}(\hat{p}) = \sqrt{\frac{p(1-p)}{n}}$.

2. **Simulazione**:
   - Per ogni campione, i successi ($0$ o $1$) sono generati con `rbinom`, e la proporzione campionaria $\hat{p}$ è calcolata come media.

3. **Grafico**:
   - L'istogramma delle proporzioni campionarie è sovrapposto alla curva normale teorica ($N(p, \text{SD}(\hat{p}))$).

**Domande di Discussione.**

1. La distribuzione campionaria di $\hat{p}$ sembra approssimarsi a una distribuzione normale? Perché?
2. Cosa accadrebbe se $n$ fosse più piccolo (es. $n = 30$)?
3. Se $p$ fosse più vicino a $0$ o $1$, l'approssimazione normale sarebbe ancora valida? Spiega. 
:::

::: {.callout-important title="Problemi 4" collapse="true"}
**Problema: Distribuzione Campionaria della Differenza tra Due Proporzioni**

L'obiettivo di questo esercizio è esplorare la distribuzione campionaria della differenza tra due proporzioni campionarie, $\hat{p}_1 - \hat{p}_2$, ottenute da due campioni indipendenti estratti da popolazioni diverse. Per campioni sufficientemente grandi, il Teorema del Limite Centrale garantisce che la distribuzione di $\hat{p}_1 - \hat{p}_2$ può essere approssimata con una distribuzione normale.

**Situazione**

Abbiamo due popolazioni con proporzioni di successo diverse:

- **Popolazione 1** ha una proporzione di successo $p_1 = 0.6$.
- **Popolazione 2** ha una proporzione di successo $p_2 = 0.4$.

Vogliamo studiare il comportamento della distribuzione campionaria della differenza tra le proporzioni campionarie quando preleviamo campioni indipendenti da ciascuna popolazione.

**Compiti**

1. **Definizione delle popolazioni e dei parametri:**  
   - La proporzione di successi nelle due popolazioni è $p_1 = 0.6$ e $p_2 = 0.4$.
   - Entrambi i campioni hanno dimensione $n_1 = n_2 = 150$.
   - La deviazione standard teorica della distribuzione campionaria della differenza tra proporzioni è calcolata come:
     $$
     \text{SD}(\hat{p}_1 - \hat{p}_2) = \sqrt{\frac{p_1 (1-p_1)}{n_1} + \frac{p_2 (1-p_2)}{n_2}}
     $$

2. **Simulazione di campioni:**  
   - Generare 10.000 campioni indipendenti di ampiezza $n_1 = 150$ dalla prima popolazione e $n_2 = 150$ dalla seconda popolazione.
   - Calcolare la proporzione campionaria $\hat{p}_1$ e $\hat{p}_2$ per ciascun campione.
   - Calcolare la differenza tra le proporzioni campionarie.

3. **Distribuzione campionaria della differenza tra le proporzioni:**  
   - Rappresentare graficamente la distribuzione di $\hat{p}_1 - \hat{p}_2$ con un istogramma.
   - Sovrapporre la distribuzione normale teorica $N(p_1 - p_2, \text{SD}(\hat{p}_1 - \hat{p}_2))$ per confrontare l'andamento empirico con quello teorico.

4. **Calcolo della probabilità che la differenza tra proporzioni sia maggiore di un valore specifico:**  
   - **Metodo empirico:** calcolare la proporzione di campioni in cui $\hat{p}_1 - \hat{p}_2 > 0.1$.
   - **Metodo teorico:** utilizzare la distribuzione normale approssimata per stimare la probabilità che $\hat{p}_1 - \hat{p}_2 > 0.1$.

**Domande di Discussione**

1. L'approssimazione normale è valida in questo caso? Perché?
2. Come cambierebbe la distribuzione campionaria se la dimensione del campione $n_1$ o $n_2$ fosse più piccola?
3. Se i valori di $p_1$ o $p_2$ fossero più vicini a 0 o 1, come cambierebbe la probabilità calcolata e l'accuratezza dell'approssimazione normale?
:::

::: {.callout-tip title="Soluzioni 4" collapse="true"}
La distribuzione campionaria della differenza tra due proporzioni ($\hat{p}_1 - \hat{p}_2$) descrive come la differenza tra le proporzioni campionarie varia tra due campioni indipendenti estratti da due popolazioni.

Per campioni grandi, il Teorema del Limite Centrale garantisce che $\hat{p}_1 - \hat{p}_2$ segue approssimativamente una distribuzione normale con media e varianza calcolate dalle proporzioni della popolazione.

Obiettivo:

1. Simulare due popolazioni con proporzioni $p_1$ e $p_2$.
2. Estrarre campioni indipendenti da ciascuna popolazione.
3. Calcolare la distribuzione campionaria di $\hat{p}_1 - \hat{p}_2$.
4. Calcolare la probabilità che la differenza campionaria sia maggiore di un valore specifico (es. $0.1$).

Parametri del Problema:

- Popolazione 1: $p_1 = 0.6$
- Popolazione 2: $p_2 = 0.4$
- Dimensione campionaria: $n_1 = n_2 = 150$
- Valore specifico: $0.1$

```{r}
# Parametri delle due popolazioni
p1 <- 0.6  # Proporzione di successi nella Popolazione 1
p2 <- 0.4  # Proporzione di successi nella Popolazione 2
n1 <- 150  # Dimensione campionaria per la Popolazione 1
n2 <- 150  # Dimensione campionaria per la Popolazione 2

# Simulazione di 10.000 campioni indipendenti
set.seed(123)
sample_p1 <- replicate(10000, mean(rbinom(n1, size = 1, prob = p1)))
sample_p2 <- replicate(10000, mean(rbinom(n2, size = 1, prob = p2)))

# Calcolo della differenza tra proporzioni campionarie
sample_diff <- sample_p1 - sample_p2

# Parametri teorici della distribuzione normale approssimata
mean_diff <- p1 - p2
sd_diff <- sqrt((p1 * (1 - p1) / n1) + (p2 * (1 - p2) / n2))

# Creazione del data frame per ggplot2
df_diff <- data.frame(sample_diff = sample_diff)

# Visualizzazione con ggplot2
ggplot(df_diff, aes(x = sample_diff)) +
  geom_histogram(
    aes(y = after_stat(density)), bins = 40, fill = "blue", alpha = 0.6
  ) +
  stat_function(
    fun = dnorm,
    args = list(mean = mean_diff, sd = sd_diff),
    color = "red",
    size = 1
  ) +
  labs(
    title = "Distribuzione campionaria della differenza tra proporzioni",
    x = "Differenza campionaria (p1 - p2)",
    y = "Densità"
  )
```

```{r}
# Calcolo della probabilità che la differenza sia maggiore di 0.1
exact_probability <- mean(sample_diff > 0.1)
exact_probability
```

```{r}
# Approssimazione tramite distribuzione normale
approx_probability <- 1 - pnorm(0.1, mean = mean_diff, sd = sd_diff)
approx_probability
```

1. **Parametri delle popolazioni**:
   - Due popolazioni con proporzioni $p_1 = 0.6$ e $p_2 = 0.4$.
   - Dimensioni campionarie $n_1 = n_2 = 150$.

2. **Simulazione**:
   - Per ogni campione, i successi ($0$ o $1$) sono generati con `rbinom`.
   - Calcoliamo le proporzioni campionarie e la differenza tra di esse.

3. **Distribuzione teorica**:
   - Media teorica: $p_1 - p_2$.
   - Deviazione standard teorica: $\sqrt{\frac{p_1 (1-p_1)}{n_1} + \frac{p_2 (1-p_2)}{n_2}}$.

4. **Visualizzazione**:
   - Un istogramma di $\hat{p}_1 - \hat{p}_2$ sovrapposto alla curva della distribuzione normale teorica.

5. **Calcolo della probabilità**:
   - Probabilità esatta dalla simulazione: proporzione di $\hat{p}_1 - \hat{p}_2 > 0.1$.
   - Probabilità approssimata dalla distribuzione normale.

**Domande di Discussione.**

1. L'approssimazione normale è valida in questo caso? Perché?
2. Come cambierebbe la distribuzione campionaria se $n_1$ o $n_2$ fossero più piccoli?
3. Come influenzerebbe la probabilità calcolata un valore $p_1$ o $p_2$ più vicino a $0$ o $1$? 
:::

## Informazioni sull'Ambiente di Sviluppo {.unnumbered}

```{r}
sessionInfo()
```

## Bibliografia {.unnumbered}

