# Confronto tra le medie di due gruppi {#sec-linear-models-two-groups}

::: callout-note
## In questo capitolo imparerai a

- condurre un confronto bayesiano tra le medie di due gruppi utilizzando la  funzione `brm()` del pacchetto **brms**.
:::

::: callout-tip
## Prerequisiti

- Consultare l'articolo "Bayesian estimation supersedes the t test" [@kruschke2013bayesian]. 
:::

::: callout-important
## Preparazione del Notebook

```{r}
here::here("code", "_common.R") |> 
  source()

# Load packages
if (!requireNamespace("pacman")) install.packages("pacman")
pacman::p_load(cmdstanr, posterior, brms, bayestestR, insight)
```
:::

## Introduzione

Uno degli obiettivi fondamentali nella ricerca psicologica è comprendere se e quanto due gruppi differiscano tra loro. Ad esempio, potremmo chiederci se un trattamento ha prodotto un cambiamento nel comportamento, se un gruppo clinico mostra livelli più elevati di ansia rispetto a un gruppo di controllo, o se due condizioni sperimentali generano risposte differenti. In tutti questi casi, l’interesse non riguarda soltanto la presenza di una differenza, ma anche la sua grandezza e l’incertezza con cui possiamo stimarla.

L'approccio classico a tali quesiti si fonda sul test d'ipotesi frequentista, che assume come punto di partenza l'assenza di differenze tra i gruppi – la cosiddetta ipotesi nulla. Attraverso questo metodo, si valuta quanto i dati osservati siano compatibili con tale ipotesi, ottenendo come risultato il p-value, ovvero la probabilità di osservare un effetto altrettanto estremo o più estremo sotto l'ipotesi nulla.

Tuttavia, questa metodologia presenta diversi problemi. Innanzitutto, riduce l'analisi a una decisione binaria – "significativo" o "non significativo" – basata su soglie arbitrarie come il convenzionale p < 0.05, senza offrire una reale comprensione della grandezza dell'effetto. Inoltre, il p-value è spesso frainteso: molti ricercatori lo interpretano erroneamente come la probabilità che l'ipotesi nulla sia vera, oppure come la probabilità che l'ipotesi alternativa sia corretta, quando in realtà esso rappresenta soltanto la probabilità dei dati osservati dato che l'ipotesi nulla sia vera [@greenland2016statistical]. Un ulteriore limite è che il p-value non fornisce una misura diretta dell'incertezza associata alla stima dell'effetto, né tiene conto in modo trasparente della variabilità intrinseca ai dati [@wasserstein2016asa].

Proprio per queste ragioni, negli ultimi anni si è diffuso un interesse crescente verso  l'inferenza bayesiana, che permette un'analisi più ricca e informativa. A differenza del metodo frequentista, che si concentra sul rifiutare o meno un'ipotesi nulla, l'approccio bayesiano sposta l'attenzione sulla stima dell'effetto e sulla quantificazione dell'incertezza. Invece di produrre un semplice verdetto binario, restituisce una distribuzione di probabilità per i parametri di interesse, mostrando in modo esplicito quanto ancora non sappiamo dopo aver osservato i dati. Questa caratteristica è particolarmente preziosa in psicologia, dove l'eterogeneità tra individui e persino all'interno dello stesso individuo nel tempo è la norma. 

Mentre il metodo frequentista si limita a valutare la compatibilità dei dati con un'ipotesi fissa, l'approccio bayesiano offre strumenti più potenti. Consente, ad esempio, di calcolare direttamente la probabilità che un trattamento sia effettivamente migliore di un altro, di esplorare un'intera gamma di possibili effetti anziché focalizzarsi solo sul confronto con l'ipotesi nulla, e di integrare in modo rigoroso conoscenze precedenti per ottenere stime più robuste, soprattutto quando i dati disponibili sono pochi.

In questo capitolo esploreremo come modellare la differenza tra due medie utilizzando un modello di regressione con variabile indicatrice, un approccio formalmente equivalente al classico t-test ma che, nell'ambito bayesiano, permette una stima più flessibile e informativa. Vedremo come l'inferenza bayesiana fornisca strumenti più intuitivi per interpretare l'incertezza e supportare decisioni fondate nella ricerca psicologica, superando molti dei limiti dell'approccio tradizionale.

## Regressione bayesiana per confrontare due gruppi

Per confrontare due gruppi in un'ottica bayesiana, possiamo utilizzare un semplice modello di regressione lineare. Questo approccio, concettualmente simile al classico t-test, ci permette però di ottenere stime probabilistiche più ricche e interpretabili. Immaginiamo di voler verificare se un nuovo trattamento psicologico (gruppo sperimentale) sia più efficace di un trattamento standard (gruppo di controllo). Possiamo modellare i punteggi osservati come:

$$
y_i = \alpha + \gamma D_i + \varepsilon_i,
$$

dove:

* $y_i$ è il punteggio osservato per l’individuo $i$;
* $D_i$ è una variabile dummy: 0 per il gruppo di riferimento (es. controllo), 1 per il gruppo sperimentale;
* $\alpha$ rappresenta la media del gruppo di riferimento;
* $\gamma$ è la differenza tra le medie (l’effetto che ci interessa stimare);
* $\varepsilon_i$ è un errore casuale con deviazione standard $\sigma$.

A differenza dell’approccio frequentista, che tratta $\alpha$, $\gamma$ e $\sigma$ come valori fissi da stimare, il metodo bayesiano li considera variabili aleatorie, a cui assegniamo distribuzioni iniziali (prior) basate su conoscenze pregresse o su assunzioni poco informative. Dopo aver osservato i dati, queste distribuzioni vengono aggiornate, producendo le distribuzioni a posteriori, che riflettono la nostra incertezza sui parametri alla luce dell’evidenza empirica.

La distribuzione a posteriori di $\gamma$ è particolarmente informativa, perché ci dice quanto sia plausibile ogni possibile valore della differenza tra i gruppi. Questo ci permette di:

- calcolare direttamente la probabilità che l’effetto sia positivo, negativo o superiore a una soglia rilevante (ad esempio, "Qual è la probabilità che il trattamento sperimentale sia almeno 5 punti migliore del controllo?");
- ottenere intervalli di credibilità (es. 95%), che indicano un intervallo di valori in cui, con alta probabilità, cade il vero effetto;
- confrontare i risultati con le nostre aspettative teoriche, verificando se i dati supportano, indeboliscono o ribaltano le ipotesi iniziali.

A differenza del p-value, che fornisce solo una misura di "quanto estremi sono i dati sotto l’ipotesi nulla", l’approccio bayesiano ci dà una misura diretta della plausibilità delle nostre ipotesi, in un linguaggio probabilistico più intuitivo e meno vincolato a soglie arbitrarie.

### L’approccio frequentista e bayesiano a confronto  

Mentre il metodo bayesiano tratta i parametri come variabili aleatorie e quantifica l’incertezza attraverso distribuzioni di probabilità, l’**approccio frequentista** adotta una prospettiva radicalmente diversa. In questa visione, i dati sono considerati variabili (frutto di un campionamento casuale), mentre i parametri (come la differenza tra medie) sono fissi ma sconosciuti. L’inferenza si basa sul comportamento delle statistiche in un ipotetico universo di esperimenti ripetuti all’infinito.  

Un esempio emblematico è l’**intervallo di confidenza al 95%**: nella logica frequentista, esso non rappresenta la probabilità che il parametro vero cada in un certo range, ma indica che, se ripetessimo l’esperimento infinite volte, il 95% di tali intervalli *conterrebbe* il valore vero. Questo concetto, però, è spesso frainteso: nel singolo studio, non possiamo dire che abbiamo il 95% di fiducia nell’intervallo calcolato. Allo stesso modo, il **p-value** non è la probabilità che l’ipotesi nulla sia vera, ma solo la probabilità di osservare dati altrettanto estremi *ammesso che l’ipotesi nulla sia corretta*.  

Nel confronto tra due gruppi, il frequentista calcola una statistica *t* e la confronta con una distribuzione teorica, chiedendosi: *"Se non ci fosse alcun effetto, quanto sarebbero rari i dati che ho osservato?"*. La risposta, però, non ci dice nulla sulla *grandezza pratica dell’effetto* né sulla sua **plausibilità reale**.  

## Un esempio illustrativo: il ruolo dell’istruzione materna

Dopo aver discusso le differenze tra approccio frequentista e bayesiano, vediamo ora come questi due modi di inferire si comportano su un caso reale. Utilizzeremo un dataset classico in psicologia dello sviluppo, che riporta i punteggi di **quoziente intellettivo (QI)** di bambini, insieme a informazioni sul **livello di istruzione della madre**.

La domanda che ci poniamo è semplice, ma rilevante: *i figli di madri diplomate (che hanno completato la scuola superiore) mostrano in media un QI diverso rispetto ai figli di madri non diplomate?*

### Esplorazione iniziale dei dati

Importiamo il dataset e verifichiamo la struttura delle variabili:

```{r}
kidiq <- rio::import(here::here("data", "kidiq.dta"))
glimpse(kidiq)
```

Calcoliamo alcune statistiche descrittive per ciascun gruppo:

```{r}
kidiq |> 
  group_by(mom_hs) |> 
  summarise(
    n = n(),
    media_QI = mean(kid_score),
    sd_QI = sd(kid_score)
  )
```

Vediamo così che il campione include **93 bambini** con madri non diplomate e **341 con madri diplomate**, con una differenza apparente nei punteggi medi di QI. Ma questa differenza è solo un effetto casuale, o riflette una tendenza reale nella popolazione?

Per rispondere, analizziamo il problema utilizzando entrambi gli approcci.

## Due strade per lo stesso problema

### Approccio frequentista

Per valutare se la differenza osservata è compatibile con l’ipotesi che non ci sia alcuna differenza nella popolazione, applichiamo il **t-test per campioni indipendenti**:

```{r}
t.test(
  kid_score ~ mom_hs, 
  data = kidiq, 
  var.equal = TRUE
)
```

Questa funzione restituisce la stima della differenza media, l'intervallo di confidenza al 95%, e il valore del **p-value**. Il p-value rappresenta la probabilità di osservare una differenza almeno così grande *se* non ci fosse alcuna differenza reale nella popolazione (cioè sotto l’ipotesi nulla $\mu_1 = \mu_2$).

È una misura indiretta dell’evidenza contro l’ipotesi nulla: più è piccolo il p-value, meno plausibile appare l’ipotesi di assenza di differenza. Ma, come abbiamo visto nei capitoli precedenti, questo tipo di inferenza è vincolato da assunzioni forti e da interpretazioni spesso controintuitive.

Nel prossimo paragrafo, analizzeremo lo stesso problema con l’approccio bayesiano, per ottenere una visione più continua e informativa dell’incertezza sulla differenza tra i gruppi.


### Approccio bayesiano

A differenza dell’approccio frequentista, che parte da un’ipotesi nulla e valuta la compatibilità dei dati con essa, il paradigma bayesiano si concentra direttamente sull’effetto che vogliamo stimare. Non ci si chiede se la differenza tra gruppi "esiste", ma quanto è plausibile e quanto è incerta.

Per farlo, costruiamo un modello probabilistico che descriva la relazione tra il QI dei bambini e il livello di istruzione materna. Il modello è una semplice regressione con variabile dummy:

$$
y_i \sim \mathcal{N}(\mu_i, \sigma), \quad \mu_i = \alpha + \gamma D_i,
$$

dove:

* $y_i$ è il punteggio di QI del bambino $i$,
* $D_i = 0$ se la madre non è diplomata, $1$ se è diplomata,
* $\alpha$ rappresenta il QI medio per i figli di madri non diplomate,
* $\gamma$ rappresenta la differenza tra i gruppi,
* $\sigma$ è la deviazione standard residua.

#### Stima del modello con `brms`

Stimiamo il modello utilizzando il pacchetto `brms`, che permette di ottenere direttamente la distribuzione a posteriori dei parametri:

```{r}
#| output: false
fit_1 <- brm(
  kid_score ~ mom_hs,
  data = kidiq,
  backend = "cmdstanr",
  silent = 0
)
```

Una volta ottenuti i campioni a posteriori, possiamo rispondere in modo diretto alla domanda: *qual è la probabilità che la differenza media tra i due gruppi superi una soglia di interesse, ad esempio 5 punti?*

```{r}
posterior_samples <- as_draws_df(fit_1)
mean(posterior_samples$b_mom_hs > 5)
```

Questo valore non è un p-value, ma una vera probabilità condizionata ai dati osservati. Ad esempio, un risultato pari a 0.96 può essere interpretato come: *"dato il nostro modello e i dati disponibili, c’è una probabilità del 96% che i figli di madri diplomate abbiano in media un QI superiore di almeno 5 punti"*.

### Visualizzare la variabilità nei dati

Un grafico aiuta a rappresentare non solo le medie, ma anche la distribuzione dei punteggi all’interno di ciascun gruppo:

```{r}
ggplot(kidiq, aes(x = as.factor(mom_hs), y = kid_score)) +
  geom_violin(trim = FALSE, fill = "skyblue") +
  geom_boxplot(width = 0.1, outlier.shape = NA, fill = "white", color = "black") +
  labs(
    x = "Istruzione materna",
    y = "QI del bambino",
    title = "Distribuzione dei punteggi QI\nper livello di istruzione della madre"
  ) +
  scale_x_discrete(labels = c("0" = "Non diplomata", "1" = "Diplomata"))
```

Il grafico evidenzia che, pur in presenza di una differenza tra le medie, esiste una notevole sovrapposizione tra i gruppi. Questo riflette la naturale variabilità dei dati psicologici e rende evidente perché la sola media non basta: è l’intera distribuzione che ci interessa comprendere.

## Cosa cambia davvero tra i due approcci?

Entrambi gli approcci usano gli stessi dati e, in presenza di campioni ampi e modelli lineari semplici, spesso portano a conclusioni numericamente simili. Tuttavia, ciò che cambia profondamente è il significato dei risultati.

| Aspetto                 | Frequentista                                                       | Bayesiano                                            |
| ----------------------- | ------------------------------------------------------------------ | ---------------------------------------------------- |
| Ipotesi di partenza     | Assume $\mu_1 = \mu_2$ (ipotesi nulla)                         | Nessuna ipotesi nulla                                |
| Obiettivo               | Verificare se la differenza osservata è improbabile sotto $H_0$ | Stimare la probabilità della differenza tra i gruppi |
| Interpretazione         | Il p-value è una probabilità *condizionata da $H_0$*            | La probabilità è *condizionata dai dati osservati*   |
| Rappresentazione        | Intervallo di confidenza                                           | Intervallo di credibilità                            |
| Uso dei dati precedenti | Non previsto                                                       | Integrabile tramite prior                            |

Il bayesianesimo, in questo contesto, non è solo una tecnica alternativa, ma un modo diverso di porre le domande e interpretare le risposte. Invece di dire *"questa differenza è significativa?"*, possiamo chiedere *"quanto è plausibile, alla luce dei dati, che la differenza superi una soglia rilevante?"*

Nel prossimo paragrafo, estenderemo questa analisi esplorando la sensibilità del modello bayesiano rispetto alla scelta dei prior e approfondiremo strumenti diagnostici che ci aiutano a valutare quanto il modello rifletta davvero i dati.


## Approfondimenti bayesiani: dalla flessibilità alla coerenza

Il confronto tra i gruppi sul QI ci ha già mostrato i vantaggi dell’inferenza bayesiana: la possibilità di quantificare direttamente l’incertezza sulla differenza tra le medie e di stimare probabilità a posteriori interpretabili. In questa sezione vediamo come l’approccio bayesiano permetta di **raffinare il modello** e **verificare la coerenza delle ipotesi** con i dati, prima e dopo l’osservazione.

### Intervallo di credibilità e verifica predittiva

Una volta stimato il modello, possiamo calcolare un **intervallo di credibilità all’89%**, una soglia suggerita in ambito didattico per sottolineare che non si tratta di una soglia “speciale”, ma di un’espressione quantitativa dell’incertezza residua:

```{r}
bayestestR::hdi(fit_1, parameters = "mom_hs", ci = 0.89)
```

Per valutare se il modello riproduce adeguatamente i dati, possiamo utilizzare la **verifica predittiva a posteriori**:

```{r}
pp_check(fit_1)
```

Nel nostro caso, il modello riproduce bene la forma generale della distribuzione osservata, ma si notano leggere discrepanze nelle code. Questo suggerisce che la distribuzione normale, pur efficace, potrebbe essere migliorata per catturare l’asimmetria presente nei dati.


### Flessibilità modellistica: usare una distribuzione skew-normal

Per rappresentare meglio la **variabilità asimmetrica**, possiamo utilizzare una **distribuzione skew-normal**, che generalizza la normale consentendo una coda più estesa da un lato:

```{r}
#| output: false
fit_2 <- brm(
  kid_score ~ mom_hs, 
  family = skew_normal(),
  backend = "cmdstanr", 
  data = kidiq
)
```

Il modello skew-normal migliora l’adattamento ai dati, come evidenziato da `pp_check(fit_2)`, che mostra una maggiore sovrapposizione tra predizioni e osservazioni.

```{r}
pp_check(fit_2)
```

## Verifica predittiva a priori (Prior Predictive Check)

Un passaggio fondamentale nella costruzione di modelli bayesiani consiste nel chiedersi: **quali dati ci aspetteremmo di vedere, se avessimo solo i prior e nessun dato reale?**

Con il **prior predictive check**, simuliamo dati fittizi basati unicamente sulle distribuzioni a priori, per verificare se le nostre ipotesi iniziali sono **compatibili con la scala e la natura del fenomeno psicologico in esame**.

Per esempio, possiamo specificare prior debolmente informativi ma plausibili:

```{r}
prior_gaussian <- 
  prior(normal(90, 20), class = "Intercept") +
  prior(normal(0, 15), class = "b", coef = "mom_hs") +
  prior(cauchy(0, 20), class = "sigma")
```

Poi stimiamo un modello basato **solo su questi prior**, ignorando i dati:

```{r}
#| output: false
fit_prior <- brm(
  kid_score ~ mom_hs,
  data = kidiq,
  prior = prior_gaussian,
  family = gaussian(),
  backend = "cmdstanr",
  sample_prior = "only"
)
```

Visualizzando i dati simulati:

```{r}
pp_check(fit_prior, ndraws = 100) + xlim(10, 180)
```

possiamo verificare se i prior generano predizioni realistiche. In questo caso, vediamo che i valori simulati si distribuiscono su un intervallo ampio ma plausibile, coerente con ciò che sappiamo sul QI. Questo indica che i prior non sono né troppo restrittivi né irrealistici.

## Incorporare conoscenza pregressa: prior informativi

Quando disponiamo di evidenze precedenti (ad esempio, studi che indicano un effetto medio dell’istruzione materna di circa 10 punti QI), possiamo formalizzarle con un prior informativo:

```{r}
#| output: false
fit_3 <- brm(
  kid_score ~ mom_hs,
  data = kidiq,
  prior = c(set_prior("normal(10, 5)", class = "b", coef = "mom_hs")),
  backend = "cmdstanr"
)
```

```{r}
summary(fit_3)
```

Se i dati confermano il pattern, la distribuzione a posteriori sarà **simile a quella ottenuta con prior deboli**. Ma in campioni piccoli o più rumorosi, questo tipo di informazione può fare una grande differenza, aiutando a stabilizzare l’inferenza.

## Test di ipotesi bayesiano

Infine, possiamo formulare **ipotesi probabilistiche direttamente interpretabili**, come:

*Qual è la probabilità che la differenza tra i gruppi superi i 5 punti?*

```{r}
hypothesis(fit_1, "mom_hs > 5")
```

A differenza del *p*-value, il risultato fornisce una risposta diretta: ad esempio, una probabilità del 98% che l’effetto sia maggiore di 5. Questo è il tipo di affermazione che possiamo portare **nella discussione scientifica o clinica**, senza bisogno di traduzioni arbitrarie.


::: {.callout-tip}
## Approfondimento statistico (opzionale)

Consideriamo ora le basi statistiche su cui si basa l'approccio frequentista. Nel paradigma frequentista, l’inferenza sulla differenza tra due gruppi si basa sulla **distribuzione campionaria** della differenza tra le medie. L’idea di fondo è che, se ripetessimo il campionamento molte volte, otterremmo valori diversi per la differenza tra le medie campionarie, e questa variabilità può essere descritta attraverso una distribuzione probabilistica.

Supponiamo di avere due popolazioni normali e indipendenti:

$$
Y_1 \sim \mathcal{N}(\mu_1, \sigma_1^2) \quad \text{e} \quad Y_2 \sim \mathcal{N}(\mu_2, \sigma_2^2)
$$

e di osservare due campioni indipendenti, rispettivamente di dimensione $n_1$ e $n_2$.

Se assumiamo inoltre che le varianze siano uguali ($\sigma_1^2 = \sigma_2^2 = \sigma^2$), possiamo utilizzare una versione semplificata del modello.

### Statistica di interesse

Il nostro obiettivo è stimare la **differenza tra le medie** delle due popolazioni, ovvero:

$$
\mu_1 - \mu_2.
$$

La stima di questa quantità è data dalla **differenza tra le medie campionarie**:

$$
\bar{Y}_1 - \bar{Y}_2.
$$

### Proprietà della statistica campionaria

#### Valore atteso

Nel caso di due campioni indipendenti:

$$
E(\bar{Y}_1 - \bar{Y}_2) = \mu_1 - \mu_2.
$$

::: {.callout-important title="Dimostrazione" collapse="true"}

Si parte dalla definizione di media campionaria per ciascun gruppo e si applica la linearità dell’operatore valore atteso:

$$
E(\bar{Y}_1 - \bar{Y}_2) = E(\bar{Y}_1) - E(\bar{Y}_2) = \mu_1 - \mu_2.
$$

:::

#### Varianza

La varianza della differenza tra le medie campionarie è:

$$
\operatorname{Var}(\bar{Y}_1 - \bar{Y}_2) = \frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}.
$$

::: {.callout-important title="Dimostrazione" collapse="true"}

Poiché i due campioni sono indipendenti, la varianza della differenza si ottiene sommando le varianze delle due medie:

$$
\operatorname{Var}(\bar{Y}_1) = \frac{\sigma_1^2}{n_1}, \quad \operatorname{Var}(\bar{Y}_2) = \frac{\sigma_2^2}{n_2}
$$

quindi:

$$
\operatorname{Var}(\bar{Y}_1 - \bar{Y}_2) = \frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}.
$$

:::

Se assumiamo varianze uguali ($\sigma_1 = \sigma_2 = \sigma$), possiamo scrivere:

$$
\operatorname{Var}(\bar{Y}_1 - \bar{Y}_2) = \sigma^2 \left( \frac{1}{n_1} + \frac{1}{n_2} \right).
$$

Poiché $\sigma^2$ è sconosciuta, la si stima tramite la **varianza pooled**:

$$
s_p^2 = \frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2},
$$

dove $s_1^2$ e $s_2^2$ sono le varianze campionarie:

$$
s_j^2 = \frac{1}{n_j - 1} \sum_{i=1}^{n_j} (y_{j,i} - \bar{y}_j)^2, \quad j = 1,2.
$$

### Distribuzione della statistica

Sotto l’ipotesi di normalità e indipendenza, e assumendo varianze uguali, la statistica $\bar{Y}_1 - \bar{Y}_2$ segue (almeno approssimativamente) una distribuzione normale:

$$
\bar{Y}_1 - \bar{Y}_2 \sim \mathcal{N} \left( \mu_1 - \mu_2,\ \sigma \sqrt{ \frac{1}{n_1} + \frac{1}{n_2} } \right).
$$

Questa proprietà permette di costruire un **intervallo di confidenza al 95%** per la differenza tra le medie, oppure di effettuare un **test t per due campioni indipendenti**, basato sulla seguente statistica:

$$
t = \frac{(\bar{Y}_1 - \bar{Y}_2) - (\mu_1 - \mu_2)}{s_p \sqrt{ \frac{1}{n_1} + \frac{1}{n_2} }}.
$$

Questa statistica segue, sotto l’ipotesi nulla $\mu_1 = \mu_2$, una distribuzione t di Student con $n_1 + n_2 - 2$ gradi di libertà.
:::

## Riflessioni conclusive: ragionare con l’incertezza

Il confronto tra due medie è un problema classico dell’analisi statistica. Ma il modo in cui lo affrontiamo riflette due visioni profondamente diverse dell’inferenza. L’approccio frequentista interpreta i dati alla luce di una procedura ipotetica: si domanda quanto una differenza osservata sarebbe rara se, in realtà, non ci fosse alcuna differenza nella popolazione. Il risultato, spesso riassunto in un p-value, è una misura indiretta e condizionata da un’ipotesi che, nella pratica psicologica, è raramente realistica.

L’approccio bayesiano, invece, sposta il focus: non interroga la compatibilità dei dati con un mondo ipotetico, ma costruisce una rappresentazione probabilistica della nostra incertezza rispetto ai parametri del modello. Il punto centrale non è più la validità dell’ipotesi nulla, ma la plausibilità, l’ampiezza e la rilevanza della differenza osservata, data l’evidenza disponibile e — se dichiarate — le conoscenze pregresse.

Utilizzando `brms`, abbiamo visto come questa prospettiva si traduca operativamente in modelli che restituiscono intere distribuzioni a posteriori, anziché singole stime. Abbiamo potuto:

* quantificare la probabilità che una differenza superi una soglia rilevante;
* ottenere intervalli di credibilità che esprimono in modo diretto l’incertezza residua;
* diagnosticare il comportamento del modello con controlli predittivi, sia posteriori che a priori;
* integrare conoscenze precedenti in modo esplicito, tramite la definizione di prior informativi.

In contesti come la psicologia — dove i dati sono rumorosi, la variabilità tra individui è elevata, e le ipotesi raramente sono nette — questo tipo di inferenza offre un vantaggio cruciale: non riduce la complessità empirica a una dicotomia (significativo / non significativo), ma la rappresenta in termini di gradiente, compatibilità, e margine d’incertezza.

L’inferenza bayesiana, dunque, non è semplicemente un’alternativa metodologica: è una cornice epistemologica che incoraggia un uso più riflessivo dei dati. Invece di trattare l’analisi statistica come un rituale decisionale, invita a formulare domande più articolate: *quale differenza è compatibile con i dati? quanto siamo incerti? quale informazione pregressa siamo disposti a includere?*

In definitiva, questo capitolo ha mostrato che ragionare in termini bayesiani significa non solo ottenere risultati più interpretabili, ma anche *modellare in modo esplicito il nostro stato di conoscenza*, rendendo visibile — e quindi discutibile e migliorabile — il grado di fiducia che attribuiamo alle nostre conclusioni. In psicologia, dove i fenomeni sono complessi e l’incertezza è inevitabile, questo rappresenta non un lusso, ma una necessità.



## Informazioni sull'Ambiente di Sviluppo {.unnumbered} 

```{r}
sessionInfo()
```

## Bibliografia {.unnumbered}

