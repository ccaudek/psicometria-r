# Modello di Poisson (1) {#sec-mcmc-poisson-1}


*Preparazione del Notebook*

```{r}
here::here("code", "_common.R") |> 
  source()

if (!requireNamespace("pacman")) install.packages("pacman")
pacman::p_load(cmdstanr, posterior, bayesplot, ggplot2, dplyr, tibble)
conflicts_prefer(posterior::ess_bulk)
conflicts_prefer(posterior::ess_tail)
```


## Introduzione {.unnumbered .unlisted}

::: {.lead}
In questo capitolo affrontiamo un primo esempio di modellazione con *Stan*, il linguaggio di programmazione che useremo per costruire modelli statistici e fare inferenza bayesiana. L’idea di base è di riprendere un problema che abbiamo già studiato con metodi analitici e con il metodo su griglia – il modello *Gamma–Poisson* – e di risolverlo ora attraverso il campionamento MCMC. In questo modo potremo confrontare i risultati e, allo stesso tempo, iniziare a familiarizzare con Stan.
:::


## Dal modello teorico al modello computazionale

Supponiamo di avere osservazioni che rappresentano il numero di volte in cui si verifica un certo evento in un intervallo di tempo: ad esempio, il numero di compulsioni registrate da un paziente in otto momenti diversi della giornata, oppure il numero di telefonate ricevute da un centralino in altrettanti turni orari. I dati a nostra disposizione sono i seguenti:

```{r}
y <- c(2, 1, 3, 2, 2, 1, 1, 1)
```

Abbiamo quindi $N = 8$ osservazioni. Vogliamo stimare $\lambda$, cioè il tasso medio di occorrenza degli eventi. L’ipotesi di partenza è che i dati seguano una distribuzione di **Poisson**, che è la distribuzione di riferimento per fenomeni di conteggio. La formula della Poisson è:

$$
P(y_i \mid \lambda) = \frac{\lambda^{y_i} e^{-\lambda}}{y_i!}, \quad y_i \in \mathbb{N},\ \lambda > 0.
$$

Questa formula ci dice che la probabilità di osservare un certo numero di eventi dipende da un unico parametro, $\lambda$, che rappresenta proprio il tasso medio.

Per condurre un’analisi bayesiana abbiamo bisogno anche di specificare una distribuzione a priori su $\lambda$. In questo caso scegliamo una *Gamma*, che si combina molto bene con la Poisson perché le due distribuzioni sono coniugate. La densità della Gamma è la seguente:

$$
p(\lambda) = \frac{\beta^{\alpha}}{\Gamma(\alpha)} \lambda^{\alpha - 1} e^{-\beta \lambda}, \quad \lambda > 0.
$$

I due parametri $\alpha$ e $\beta$ regolano rispettivamente la forma e la concentrazione della distribuzione. Nel nostro esempio poniamo $\alpha = 9$ e $\beta = 2$. In questo modo, il valore medio della priori è $\alpha / \beta = 4.5$, cioè la nostra convinzione iniziale è che il numero medio di eventi sia attorno a 4 o 5, pur lasciando spazio all’incertezza.


## Scrivere il modello in Stan

Ora traduciamo queste idee in Stan. Un modello in Stan è diviso in blocchi. Nel blocco *data* indichiamo i dati osservati e i parametri noti, nel blocco *parameters* i parametri che vogliamo stimare, e nel blocco *model* specifichiamo la struttura probabilistica del modello, cioè la priori e la verosimiglianza.

Il modello Stan è quindi:

```stan
data {
  int<lower=0> N;                // numero di osservazioni
  array[N] int<lower=0> y;       // dati osservati
  real<lower=0> alpha_prior;     // parametro alpha della Gamma
  real<lower=0> beta_prior;      // parametro beta della Gamma
}
parameters {
  real<lower=0> lambda;          // parametro di interesse
}
model {
  lambda ~ gamma(alpha_prior, beta_prior);   // priori
  y ~ poisson(lambda);                       // verosimiglianza
}
generated quantities {
  real alpha_post = alpha_prior + sum(y);    // parametri posteriori teorici
  real beta_post  = beta_prior + N;
}
```

In questo esempio aggiungiamo anche una sezione “generated quantities”, dove calcoliamo i parametri della distribuzione a posteriori teorica. Non è strettamente necessario, ma ci serve per fare il confronto con quanto otterremo dal campionamento MCMC.


## Preparare i dati ed eseguire il modello in R

Dopo aver scritto il file Stan e salvato con estensione `.stan`, lo possiamo compilare ed eseguire in R con il pacchetto *cmdstanr*.

```{r}
stan_file <- here::here("stan", "gamma_poisson_mcmc.stan")
mod <- cmdstan_model(stan_file)

N <- length(y)
alpha_prior <- 9
beta_prior <- 2

stan_data <- list(N = N, y = y, alpha_prior = alpha_prior, beta_prior = beta_prior)
```

Una volta preparati i dati, lanciamo il campionamento:

```{r}
#| output: false

fit <- mod$sample(
  data = stan_data,
  seed = 123,
  chains = 4,
  parallel_chains = 4,
  iter_sampling = 3000,
  iter_warmup = 2000,
  show_messages = FALSE
)
```

A questo punto Stan ci restituisce una grande quantità di campioni dalla distribuzione a posteriori del parametro $\lambda$. Con questi campioni possiamo fare analisi numeriche e grafiche.


## Analizzare i risultati

Per prima cosa estraiamo i campioni di $\lambda$:

```{r}
lambda_samples <- as.vector(fit$draws("lambda"))
```

In parallelo, possiamo calcolare i parametri della distribuzione Gamma che rappresenta la soluzione analitica a posteriori. Sono:

```{r}
alpha_post <- alpha_prior + sum(y)
beta_post  <- beta_prior + N
```

Per visualizzare i risultati, tracciamo un istogramma dei campioni MCMC e vi sovrapponiamo la curva della distribuzione Gamma a posteriori teorica:

```{r}
lambda_samples_df <- data.frame(lambda_samples = lambda_samples)

ggplot(lambda_samples_df, aes(x = lambda_samples)) +
  geom_histogram(aes(y = after_stat(density)), bins = 50, fill = "skyblue", alpha = 0.7) +
  stat_function(
    fun = function(x) dgamma(x, shape = alpha_post, rate = beta_post),
    color = "red", linewidth = 1.2
  ) +
  labs(
    title = "Distribuzione a posteriori di λ",
    x = "λ",
    y = "Densità"
  )
```

Il grafico mostra che i campioni prodotti da Stan si distribuiscono esattamente come la curva teorica della distribuzione Gamma, confermando che il nostro modello è stato specificato correttamente.

Possiamo anche calcolare un intervallo di credibilità per $\lambda$. Ad esempio, prendiamo il 94% centrale della distribuzione:

```{r}
quantile(lambda_samples, probs = c(0.03, 0.97))
```

Il risultato è che il valore medio stimato di $\lambda$ è circa 2.2, e che con un grado di certezza soggettivo del 94% possiamo dire che si trova tra 1.4 e 3.1.



## Riflessioni conclusive

In questo capitolo abbiamo fatto un passo importante: abbiamo visto come tradurre un modello probabilistico relativamente semplice in Stan, come eseguire il campionamento MCMC, e come confrontare i risultati con la soluzione analitica. Questo esempio ci ha permesso di verificare che Stan funziona correttamente, perché in questo caso conoscevamo già la distribuzione a posteriori esatta.

L’aspetto davvero interessante, però, è che la stessa procedura può essere usata anche quando la soluzione analitica non esiste. Nei capitoli successivi incontreremo modelli più complessi, in cui la coniugatezza non ci aiuta più e non abbiamo formule chiuse per la distribuzione a posteriori. In quei casi, il campionamento MCMC sarà lo strumento indispensabile per fare inferenza bayesiana.


## Informazioni sull’ambiente di sviluppo {.unnumbered .unlisted}

```{r}
sessionInfo()
```


## Bibliografia {.unnumbered .unlisted}

