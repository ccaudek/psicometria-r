# Estensioni {#sec-formal-models-developments}

::: {.epigraph}
> “People change over time. ... describing and explaining change over time must focus on dynamics in response to environmental cues and competing internal states. That is, we must include time and change over time in our models.”
>
> -- **Wilt, J.**, It's about time: Emphasizing temporal dynamics in [personality] (2003)
:::

## Introduzione {.unnumbered .unlisted}

<p class="capo">
  <span class="capo-initial" data-bg="1">S</span>
eguendo la discussione di @knight2023tutorial, in questo capitolo estenderemo il modello di gruppo esaminato nel capitolo precedente in modo da esaminare il modello a livello individuale, nel quale si stima un $\alpha$ e un $\beta$ per ogni partecipante; il modello gerarchico (multilevel), nel quale i parametri individuali sono estratti da una distribuzione comune (ad esempio, una distribuzione normale); il modello per gruppi noti, in cui si confrontano i parametri tra le condizioni sperimentali (ad esempio, il gruppo "approach" vs. il gruppo "avoidance").
</p>

### Panoramica del capitolo {.unnumbered .unlisted}

* Stima dei parametri a livello individuale (un $\alpha$ e un $\beta$ per ogni soggetto).  
* Estensione gerarchica: parametri individuali come estratti da distribuzioni di popolazione.  
* Inclusione di gruppi noti: confronto dei parametri tra condizioni sperimentali.  
* Confronto tra modelli tramite ELPD e LOO-CV.  
* Vantaggi dello shrinkage e implicazioni per l’analisi psicologica. 


::: {.callout-caution collapse=true title="Preparazione del Notebook"}

```{r}
here::here("code", "_common.R") |> 
  source()

suppressPackageStartupMessages({
  library(cmdstanr)
  library(bayesplot)
  library(tidybayes)
  library(posterior)
  library(loo)
  library(patchwork)
  library(conflicted)
})

conflicts_prefer(loo::loo)
conflicts_prefer(dplyr::count)
```
:::


## Person-Level Model

Nel *Group-Level Model* (o modello di gruppo) abbiamo stimato un unico set di parametri $(\alpha, \beta)$ per tutti i partecipanti, ignorando le differenze individuali.  Possiamo però estendere il modello per stimare un valore distinto di $\alpha$ e $\beta$ per ciascun soggetto: è il *Person-Level Model*.  

In questo caso, ogni partecipante ha i propri parametri di aggiornamento e drift, mentre $\sigma$ (la variabilità residua) resta comune. Questo approccio permette di descrivere l’eterogeneità individuale, ma senza ancora introdurre alcuna “condivisione di forza” tra soggetti (caratteristica del modello gerarchico che vedremo in seguito).

### Preparazione dei dati

```{r}
# Caricamento del dataset
dat <- rio::import("data/goal_data.csv")

# Ordina i dati per soggetto e per trial
dat <- dat |> 
  arrange(subject, trial)

# (Opzionale) Verifica che l'ordinamento sia corretto
str(dat)
```

```{r}
table(dat$subject)  # restituisce il numero di trial per soggetto
```

```{r}
# 1) Ordina per soggetto e trial
dat <- dat %>% arrange(subject, trial)

# 2) Salva scale originali (per eventuale back-transform)
goal_mean <- mean(dat$goal, na.rm = TRUE); goal_sd <- sd(dat$goal, na.rm = TRUE)
perf_mean <- mean(dat$performance, na.rm = TRUE); perf_sd <- sd(dat$performance, na.rm = TRUE)

# 3) Standardizza
dat <- dat %>%
  mutate(
    goal_z = (goal - goal_mean) / goal_sd,
    perf_z = (performance - perf_mean) / perf_sd
  )

# 4) Lista per Stan (condition è opzionale qui: non usata nel baseline)
stan_data <- list(
  subject       = dat$subject,
  trial         = dat$trial,
  observed_goal = dat$goal_z,
  performance   = dat$perf_z,
  Nsubj         = dplyr::n_distinct(dat$subject),
  Ntotal        = nrow(dat)
)

str(stan_data)
```


### Definizione del modello Stan

```{r}
stancode <- "
data {
  int<lower=1> Ntotal;                 // es. 600
  int<lower=1> Nsubj;                  // es. 60
  array[Ntotal] int<lower=1> subject;  // indice soggetto (1..Nsubj)
  array[Ntotal] int<lower=1> trial;    // 1..T per ciascun soggetto (ordinati)
  vector[Ntotal] observed_goal;        // Z-score
  vector[Ntotal] performance;          // Z-score
}

parameters {
  vector[Nsubj] alpha;                 // guadagno per soggetto
  vector[Nsubj] beta;                  // drift per soggetto
  real<lower=1e-6> sigma;              // dev. std residua (comune)
}

transformed parameters {
  vector[Ntotal] ghat;                 // traiettoria predetta

  for (i in 1:Ntotal) {
    if (trial[i] == 1) {
      // reset a inizio soggetto: primo stato = prima osservazione
      ghat[i] = observed_goal[i];
    } else {
      int s = subject[i];
      // ricorsione: usa predizione e performance del trial precedente (stesso soggetto se i dati sono ordinati)
      ghat[i] = ghat[i - 1]
                + alpha[s] * (performance[i - 1] - ghat[i - 1])
                + beta[s];
    }
  }
}

model {
  // Priors semplici coerenti con z-score
  alpha ~ normal(0, 1);
  beta  ~ normal(0, 1);
  sigma ~ normal(0, 1);   // half-normal(1) per via del lower bound

  // Likelihood
  observed_goal ~ normal(ghat, sigma);
}

generated quantities {
  vector[Ntotal] yrep;
  vector[Ntotal] log_lik;

  for (i in 1:Ntotal) {
    yrep[i]   = normal_rng(ghat[i], sigma);
    log_lik[i] = normal_lpdf(observed_goal[i] | ghat[i], sigma);
  }
}
"
```

Questo modello presuppone che i dati siano *ordinati per soggetto e per trial*, altrimenti la dinamica `i - 1` non corrisponde al trial precedente dello stesso soggetto. 
Esaminiamo in dettaglio cosa significano `alpha[subject[i]]` e `beta[subject[i]]`. Nel modello Stan, ogni trial `i` è associato a un certo soggetto. Questa informazione è contenuta nel vettore:

```stan
array[Ntotal] int<lower=1> subject;
```

```{r}
stan_data$subject
```

Ogni elemento `subject[i]` ci dice *a quale soggetto appartiene il trial `i`*, usando un numero intero da `1` a `Nsubj`. Quindi se `subject[137] == 24`, significa che il 137-esimo trial è del soggetto 24.

Ora, se abbiamo un vettore di parametri specifici per ogni soggetto

```stan
vector[Nsubj] alpha;
vector[Nsubj] beta;
```

allora

* `alpha[subject[i]]` significa: prendi il valore del parametro `alpha` associato al soggetto a cui appartiene il trial `i`;
* lo stesso vale per `beta[subject[i]]`.

Per esempio, supponiamo

```stan
subject = [1, 1, 1, 2, 2, 3, 3]
alpha = [0.5, 0.8, 1.1]  // Tre soggetti: 1, 2, 3
```

allora

* `alpha[subject[4]] = alpha[2] = 0.8`, perché il 4° trial è del soggetto 2.
* `beta[subject[6]] = beta[3] = ...`, perché il 6° trial è del soggetto 3.

In sintesi, la sintassi `alpha[subject[i]]` (e `beta[subject[i]]`) indica: “Nel trial `i`, usa il valore del parametro `alpha` (o `beta`) del soggetto indicato da `subject[i]`”. È un modo compatto per associare ogni osservazione ai parametri della persona corrispondente.


### Compilazione ed esecuzione del modello  

```{r}
#| output: false
stanmod <- cmdstan_model(
  write_stan_file(stancode),
  compile = TRUE
)
```

```{r}
#| output: false
fit1 <- stanmod$sample(
  data = stan_data,
  iter_warmup = 1000,
  iter_sampling = 4000,
  chains = 4,
  parallel_chains = 4,
  refresh = 1000,
  seed = 4790
)
```


### Analisi dei risultati

Questo modello genera un insieme di campioni posteriori per i parametri $\alpha$ e $\beta$, uno per ciascun partecipante. I primi due grafici mostrano gli intervalli credibili al 95% per $\alpha$ e $\beta$ relativi a ogni partecipante. Come si può osservare, emerge un'eterogeneità tra i partecipanti sia per il parametro $\alpha$ che per $\beta$. Il pannello di destra mostra i parametri $\alpha$ e $\beta$ di ciascun partecipante tracciati l'uno contro l'altro (con le croci che rappresentano gli intervalli credibili per ciascun parametro).


```{r}
# Estrazione dei campioni
standraws <- fit1$draws(format = "draws_matrix")
```

```{r}
# Statistiche descrittive
standraws |> 
  subset_draws(variable = c("alpha", "beta", "sigma")) |> 
  summarise_draws(
    mean,
    ~ quantile(.x, probs = c(0.025, 0.5, 0.975))
  ) |> 
  print()
```

```{r}
#extract posterior samples for person-level parameters
posteriors_person = spread_draws(fit1, alpha[subject], beta[subject])
```

```{r}
# Calcolo media e intervallo credibile al 95% per ciascun soggetto
CIs_person <- posteriors_person %>%
  group_by(subject) %>%
  summarise(
    across(c(alpha, beta), list(
      lower = ~quantile(.x, 0.025),
      mean  = ~mean(.x),
      upper = ~quantile(.x, 0.975)
    ), .names = "{.col}_{.fn}")
  ) %>%
  arrange(alpha_mean) %>%
  mutate(alpha_order = row_number()) %>%
  arrange(beta_mean) %>%
  mutate(beta_order = row_number())
```


```{r}
plot_person_alpha = ggplot(data=CIs_person) +
  geom_point(aes(y=alpha_order,x=alpha_mean)) +
  geom_errorbarh(aes(y=alpha_order,xmin=alpha_lower,xmax=alpha_upper),color="red") +
  labs(x= expression(alpha) ,y="Subject") 

plot_person_beta <- ggplot(data = CIs_person) +
  geom_point(aes(y = beta_order, x = beta_mean)) +
  geom_errorbarh(aes(y = beta_order, xmin = beta_lower, xmax = beta_upper), color = "red") +
  # geom_density(data = posteriors_person, aes(x = beta), fill = "blue", alpha = 0.15, inherit.aes = FALSE) +
  labs(x = expression(beta), y = "Subject") 

plot_person_alphabeta = ggplot(data=CIs_person) +
  geom_point(aes(x=alpha_mean,y=beta_mean)) +
  geom_errorbar(aes(x=alpha_mean,ymin=beta_lower,ymax=beta_upper),color="red",alpha=0.25) +
  geom_errorbarh(aes(y=beta_mean,xmin=alpha_lower,xmax=alpha_upper),color="red",alpha=0.25) +
  labs(x= expression(alpha) ,y=expression(beta)) 
```

```{r}
plot_person_alpha 
```


```{r}
plot_person_beta 
```

```{r}
plot_person_alphabeta
```


## Modello gerarchico

Stimare i parametri per ogni partecipante separatamente (come nel *Person-Level Model*) permette di rappresentare le differenze individuali, ma presenta un limite cruciale: le stime restano isolate. Analizzare i dati *persona per persona* equivale a fare tante analisi indipendenti quanti sono i soggetti, senza “riutilizzare” le informazioni presenti negli altri individui. Questo riduce il potere statistico, aumenta la variabilità delle stime quando i dati per soggetto sono pochi e rende più difficile trarre conclusioni a livello di popolazione.

In molti contesti, però, l’interesse del ricercatore non è solo descrivere le differenze tra individui, ma anche cogliere regolarità comuni alla popolazione. Per questo i **modelli gerarchici bayesiani** (o *multilevel*) offrono una soluzione particolarmente efficace (Turner et al., 2013; Vincent, 2016; Kruschke & Vanpaemel, 2015).

L’idea di fondo è semplice:

* i parametri individuali (es. $\alpha_s, \beta_s$) sono trattati come *variabili casuali*, non come quantità del tutto indipendenti;
* ciascuno di essi è estratto da una distribuzione a livello di popolazione, descritta da iper-parametri ($\alpha_{\text{mean}}, \alpha_{\text{sd}}$, ecc.);
* in questo modo, le stime individuali sono “informate” sia dai dati del singolo soggetto sia dalla tendenza generale osservata nel campione (Lewandowsky & Farrell, 2011).

Il risultato è una *regolarizzazione*: i valori estremi vengono attenuati verso la media di popolazione (*shrinkage*), riducendo il rischio che stime instabili o rumorose abbiano troppo peso. Si ottengono così inferenze più robuste e interpretabili, specialmente in campioni piccoli o con dati per soggetto limitati (Boehm et al., 2018; Rouder & Lu, 2005).


### Definizione del modello Stan

```{r}
stancode <- "
data {
  int<lower=1> Ntotal;
  int<lower=1> Nsubj;
  array[Ntotal] int<lower=1> subject;
  array[Ntotal] int<lower=1> trial;
  vector[Ntotal] observed_goal;   // z-score
  vector[Ntotal] performance;     // z-score
}

parameters {
  // Iper-parametri di popolazione
  real alpha_mean;
  real<lower=0> alpha_sd;
  real beta_mean;
  real<lower=0> beta_sd;

  // Non-centrato: fattori standard per i soggetti
  vector[Nsubj] alpha_raw;
  vector[Nsubj] beta_raw;

  real<lower=1e-6> sigma;
}

transformed parameters {
  // Ricostruzione parametri individuali
  vector[Nsubj] alpha_unconstrained = alpha_mean + alpha_sd * alpha_raw;
  vector[Nsubj] beta  = beta_mean  + beta_sd  * beta_raw;

  // Vincolo morbido su alpha per stabilità
  vector[Nsubj] alpha = 0.95 * tanh(alpha_unconstrained);

  vector[Ntotal] ghat;

  for (i in 1:Ntotal) {
    if (trial[i] == 1) {
      ghat[i] = observed_goal[i];
    } else {
      int s = subject[i];
      ghat[i] = ghat[i - 1]
                + alpha[s] * (performance[i - 1] - ghat[i - 1])
                + beta[s];
    }
  }
}

model {
  // Iper-priori debolmente informativi (coerenti con z-score)
  alpha_mean ~ normal(0, 0.5);
  alpha_sd   ~ exponential(1);
  beta_mean  ~ normal(0, 0.5);
  beta_sd    ~ exponential(1);

  alpha_raw  ~ normal(0, 1);
  beta_raw   ~ normal(0, 1);

  sigma ~ student_t(3, 0, 0.5);

  // Likelihood
  observed_goal ~ normal(ghat, sigma);
}

generated quantities {
  vector[Ntotal] yrep;
  vector[Ntotal] log_lik;
  for (i in 1:Ntotal) {
    yrep[i]    = normal_rng(ghat[i], sigma);
    log_lik[i] = normal_lpdf(observed_goal[i] | ghat[i], sigma);
  }
}
"
```


### Differenza chiave rispetto al modello precedente

Nel *Person-Level Model* i parametri individuali sono stimati in modo indipendente; qui, invece, valgono relazioni del tipo:

$$
\alpha_s \sim \mathcal{N}(\alpha_{\text{mean}}, \alpha_{\text{sd}}), \quad
\beta_s \sim \mathcal{N}(\beta_{\text{mean}}, \beta_{\text{sd}})
$$

Questa struttura gerarchica introduce un livello di vincolo che collega i soggetti tra loro. Il vantaggio è duplice:

1. si mantengono le differenze individuali;
2. si sfrutta la somiglianza tra soggetti per ottenere stime più stabili e inferenze a livello di popolazione.


### Compilazione ed esecuzione

```{r}
#| output: false
stanmod <- cmdstan_model(
  write_stan_file(stancode),
  compile = TRUE
)
```

```{r}
#| output: false
fit2 <- stanmod$sample(
  data = stan_data,
  iter_warmup = 1000,
  iter_sampling = 4000,
  chains = 4, parallel_chains = 4,
  seed = 4790,
  refresh = 500,
  adapt_delta = 0.995,  # riduce divergenze
  max_treedepth = 15
)
```


### Analisi dei risultati

Eseguiamo l'analisi dei risultati seguendo lo schema usato sopra.

```{r}
# Estrazione dei campioni posteriori come matrice (opzionale)
standraws <- fit2$draws(format = "draws_matrix")
```

```{r}
# Statistiche descrittive aggregate
standraws |> 
  subset_draws(variable = c("alpha", "beta", "sigma", "alpha_mean", "beta_mean", "alpha_sd", "beta_sd")) |> 
  summarise_draws(
    mean,
    ~ quantile(.x, probs = c(0.025, 0.5, 0.975))
  )
```

```{r}
# Estrai le draw per i parametri individuali (alpha e beta per ciascun soggetto)
posteriors_person <- spread_draws(fit2, alpha[subject], beta[subject])
```

```{r}
# Calcolo degli intervalli credibili per ciascun soggetto
CIs_person <- posteriors_person %>%
  group_by(subject) %>%
  summarise(
    across(c(alpha, beta), list(
      lower = ~quantile(.x, 0.025),
      mean  = ~mean(.x),
      upper = ~quantile(.x, 0.975)
    ), .names = "{.col}_{.fn}")
  ) %>%
  arrange(alpha_mean) %>%
  mutate(alpha_order = row_number()) %>%
  arrange(beta_mean) %>%
  mutate(beta_order = row_number())
```


```{r}
# Grafico: intervalli credibili per alpha
plot_person_alpha <- ggplot(CIs_person) +
  geom_point(aes(y = alpha_order, x = alpha_mean)) +
  geom_errorbarh(aes(y = alpha_order, xmin = alpha_lower, xmax = alpha_upper), color = "red") +
  labs(x = expression(alpha), y = "Soggetto") 

# Grafico: intervalli credibili per beta
plot_person_beta <- ggplot(CIs_person) +
  geom_point(aes(y = beta_order, x = beta_mean)) +
  geom_errorbarh(aes(y = beta_order, xmin = beta_lower, xmax = beta_upper), color = "red") +
  labs(x = expression(beta), y = "Soggetto") 

# Grafico: relazione tra alpha e beta per ciascun soggetto
plot_person_alphabeta <- ggplot(CIs_person) +
  geom_point(aes(x = alpha_mean, y = beta_mean)) +
  geom_errorbar(aes(x = alpha_mean, ymin = beta_lower, ymax = beta_upper), color = "red", alpha = 0.25) +
  geom_errorbarh(aes(y = beta_mean, xmin = alpha_lower, xmax = alpha_upper), color = "red", alpha = 0.25) +
  labs(x = expression(alpha), y = expression(beta)) 
```

```{r}
plot_person_alpha 
```

```{r}
plot_person_beta 
```

```{r}
plot_person_alphabeta
```

Infine, calcoliamo le stime a posteriori degli iper-parametri:

```{r}
# Riassunto per alpha_mean e beta_mean con intervallo al 95%
standraws |>
  subset_draws(variable = c("alpha_mean", "beta_mean")) |>
  summarise_draws(
    mean,
    ~quantile(.x, probs = c(0.025, 0.975))
  )
```

#### Interpretazione

Il modello gerarchico bayesiano fornisce inferenze a *due livelli*:

* **Livello individuale**: parametri $\alpha_s$ e $\beta_s$ per ciascun partecipante, con i relativi intervalli credibili.
* **Livello di popolazione**: distribuzioni a priori/posteriori degli iper-parametri $\alpha_{\text{mean}}, \alpha_{\text{sd}}, \beta_{\text{mean}}, \beta_{\text{sd}}$, più il parametro residuo $\sigma$.

I grafici per $\alpha$ e $\beta$ mostrano chiaramente l’eterogeneità interindividuale, mentre gli iper-parametri descrivono la tendenza generale.

Rispetto a un modello puramente individuale, gli intervalli credibili delle stime soggettive risultano *meno dispersi e più regolari*. Questo fenomeno è noto come *shrinkage*: le stime dei singoli soggetti sono “attirate” verso la media della popolazione, riducendo l’impatto dei dati rumorosi o scarsi.

Nel grafico bivariato, lo shrinkage si traduce in una distribuzione più compatta dei punti attorno al centro della distribuzione collettiva. L’effetto principale è una maggiore *robustezza* delle inferenze: le stime estreme vengono mitigate, la variabilità non plausibile è penalizzata e la capacità di generalizzare a nuovi dati risulta rafforzata (Boehm et al., 2018).


## Differenze tra gruppi

In questo terzo modello estendiamo la struttura gerarchica introducendo le *condizioni sperimentali* (*approach* vs *avoidance*). L’idea è che i parametri individuali $\alpha_s$ e $\beta_s$ non siano estratti da un’unica distribuzione comune, ma da **distribuzioni diverse a seconda del gruppo** di appartenenza del soggetto.

In questo modo possiamo stimare, per ciascuna condizione, una media e una deviazione standard a livello di popolazione:

* $\alpha_{\text{mean},c}, \alpha_{\text{sd},c}$
* $\beta_{\text{mean},c}, \beta_{\text{sd},c}$
  con $c \in \{1,2\}$.


### Preparazione dei dati

```{r}
# 1) Ordina per soggetto e trial
dat <- dat %>% arrange(subject, trial)

# 2) Codifica la condizione come intero (1 = approach, 2 = avoidance)
dat <- dat %>%
  mutate(cond_id = as.integer(factor(condition)))

# Verifica che ogni soggetto appartenga a una sola condizione
chk <- dat %>% distinct(subject, cond_id) %>% count(subject) %>% filter(n > 1)
stopifnot(nrow(chk) == 0)  # se fallisce, il design non è between-subject

# 3) Standardizza goal e performance su tutto il dataset
goal_mean <- mean(dat$goal, na.rm = TRUE); goal_sd <- sd(dat$goal, na.rm = TRUE)
perf_mean <- mean(dat$performance, na.rm = TRUE); perf_sd <- sd(dat$performance, na.rm = TRUE)

dat <- dat %>%
  mutate(
    goal_z = (goal - goal_mean) / goal_sd,
    perf_z = (performance - perf_mean) / perf_sd
  )

# 4) Vettore che assegna a ciascun soggetto la sua condizione
subjects <- sort(unique(dat$subject))
subj_cond <- dat %>%
  group_by(subject) %>%
  summarise(cond = first(cond_id), .groups = "drop") %>%
  arrange(subject) %>%
  pull(cond)

# 5) Lista per Stan
stan_data <- list(
  Ntotal        = nrow(dat),
  Nsubj         = length(subjects),
  C             = length(unique(dat$cond_id)),   # numero condizioni
  subject       = dat$subject,
  trial         = dat$trial,
  observed_goal = dat$goal_z,
  performance   = dat$perf_z,
  subj_cond     = subj_cond
)

str(stan_data)
```


### Definizione del modello Stan

```{r}
stancode <- "
// Modello gerarchico con iper-parametri specifici per condizione
data {
  int<lower=1> Ntotal;
  int<lower=1> Nsubj;
  int<lower=1> C;                            // numero condizioni
  array[Ntotal] int<lower=1> subject;        // 1..Nsubj
  array[Ntotal] int<lower=1> trial;          // 1..T all'interno di soggetto
  vector[Ntotal] observed_goal;              // z-score
  vector[Ntotal] performance;                // z-score
  array[Nsubj] int<lower=1, upper=C> subj_cond; // condizione per soggetto
}

parameters {
  // Iper-parametri per condizione
  vector[C] alpha_mean;
  vector<lower=0>[C] alpha_sd;
  vector[C] beta_mean;
  vector<lower=0>[C] beta_sd;

  // Non-centrato: fattori standard per soggetti
  vector[Nsubj] alpha_raw;
  vector[Nsubj] beta_raw;

  real<lower=1e-6> sigma;
}

transformed parameters {
  vector[Nsubj] alpha_uncon;
  vector[Nsubj] beta;
  vector[Nsubj] alpha;           
  vector[Ntotal] ghat;

  // Ricostruzione dei parametri individuali in base alla condizione
  for (s in 1:Nsubj) {
    int c = subj_cond[s];
    alpha_uncon[s] = alpha_mean[c] + alpha_sd[c] * alpha_raw[s];
    beta[s]        = beta_mean[c]  + beta_sd[c]  * beta_raw[s];
    alpha[s]       = 0.95 * tanh(alpha_uncon[s]); // vincolo di stabilità
  }

  // Dinamica
  for (i in 1:Ntotal) {
    if (trial[i] == 1) {
      ghat[i] = observed_goal[i];
    } else {
      int s = subject[i];
      ghat[i] = ghat[i - 1]
                + alpha[s] * (performance[i - 1] - ghat[i - 1])
                + beta[s];
    }
  }
}

model {
  // Iper-priori debolmente informativi
  alpha_mean ~ normal(0, 0.5);
  alpha_sd   ~ exponential(1);
  beta_mean  ~ normal(0, 0.5);
  beta_sd    ~ exponential(1);

  alpha_raw  ~ normal(0, 1);
  beta_raw   ~ normal(0, 1);

  sigma ~ student_t(3, 0, 0.5);

  // Likelihood
  observed_goal ~ normal(ghat, sigma);
}

generated quantities {
  vector[Ntotal] yrep;
  vector[Ntotal] log_lik;
  for (i in 1:Ntotal) {
    yrep[i]    = normal_rng(ghat[i], sigma);
    log_lik[i] = normal_lpdf(observed_goal[i] | ghat[i], sigma);
  }
}
"
```

### Come funziona la distinzione tra gruppi

1. **Assegnazione condizione**
   Nel blocco `data`, il vettore `subj_cond` assegna a ciascun soggetto il numero della condizione (1 = *approach*, 2 = *avoidance*).

2. **Parametri di gruppo**
   Gli iper-parametri `alpha_mean[c]`, `alpha_sd[c]`, `beta_mean[c]`, `beta_sd[c]` sono specifici per condizione. Ad esempio:

   * `alpha_mean[1]` = media di $\alpha$ per il gruppo *approach*
   * `alpha_mean[2]` = media di $\alpha$ per il gruppo *avoidance*

3. **Parametri individuali**
   In `transformed parameters`, i parametri dei singoli soggetti vengono generati in base alla condizione di appartenenza.
   Così, i soggetti *approach* e quelli *avoidance* condividono rispettivamente due diverse distribuzioni di partenza.

In sintesi, il modello permette di stimare non solo le differenze tra individui, ma anche **le differenze sistematiche tra condizioni sperimentali**.


### Compilazione ed esecuzione

```{r}
#| output: false
stanmod <- cmdstan_model(write_stan_file(stancode), compile = TRUE)
```

```{r}
#| output: false
fit3 <- stanmod$sample(
  data = stan_data,
  iter_warmup = 1000,
  iter_sampling = 5000,
  chains = 4, parallel_chains = 4,
  seed = 123,
  adapt_delta = 0.999,   # ↑ riduce divergenze
  max_treedepth = 15
)
```







### Risultati

#### Ispezione rapida delle variabili (opzionale)

```{r}
draws_df <- as_draws_df(fit3$draws())   # oppure: fit3$draws(format = "df")
names(draws_df)[grepl("alpha_mean|beta_mean|alpha\\[|beta\\[", names(draws_df))]
```

#### Differenze tra condizioni sugli iper-parametri

Per comodità, recuperiamo le **etichette di condizione** dalla tabella dei dati (assumendo `cond_id = 1`→“approach”, `cond_id = 2`→“avoidance”; adattale se l’ordine/fattore è diverso nel tuo dataset):

```{r}
cond_labels <- dat %>%
  distinct(cond_id, condition) %>%
  arrange(cond_id) %>%
  pull(condition)

cond_labels
# Esempio atteso: c("approach", "avoidance")
```

**Contrasto su α (media per condizione)**

```{r}
delta_alpha <- fit3 |>
  spread_draws(alpha_mean[cond]) |>
  mutate(cond = factor(cond, levels = 1:2, labels = cond_labels)) |>
  pivot_wider(names_from = cond, values_from = alpha_mean, names_prefix = "alpha_mean_") |>
  mutate(delta_alpha_mean = .data[[paste0("alpha_mean_", cond_labels[2])]] -
                           .data[[paste0("alpha_mean_", cond_labels[1])]])

delta_alpha |> 
  summarise(
    mean   = mean(delta_alpha_mean),
    low95  = quantile(delta_alpha_mean, 0.025),
    upp95  = quantile(delta_alpha_mean, 0.975),
    p_lt0  = mean(delta_alpha_mean < 0)         # P(Δ < 0 | dati)
  )
```

**Contrasto su β (media per condizione)**

```{r}
delta_beta <- fit3 |>
  spread_draws(beta_mean[cond]) |>
  mutate(cond = factor(cond, levels = 1:2, labels = cond_labels)) |>
  pivot_wider(names_from = cond, values_from = beta_mean, names_prefix = "beta_mean_") |>
  mutate(delta_beta_mean = .data[[paste0("beta_mean_", cond_labels[2])]] -
                          .data[[paste0("beta_mean_", cond_labels[1])]])

delta_beta |> 
  summarise(
    mean   = mean(delta_beta_mean),
    low95  = quantile(delta_beta_mean, 0.025),
    upp95  = quantile(delta_beta_mean, 0.975),
    p_lt0  = mean(delta_beta_mean < 0)          # P(Δ < 0 | dati)
  )
```

> Nota: il segno di Δ è definito come **condizione 2 − condizione 1**. Se vuoi l’opposto, scambia i termini.

#### Visualizzazione delle posterior per le medie di condizione

```{r}
post_alpha <- fit3 |>
  spread_draws(alpha_mean[cond]) |>
  mutate(parameter = "alpha_mean",
         condition = factor(cond, levels = 1:2, labels = cond_labels)) |>
  rename(value = alpha_mean)

post_beta <- fit3 |>
  spread_draws(beta_mean[cond]) |>
  mutate(parameter = "beta_mean",
         condition = factor(cond, levels = 1:2, labels = cond_labels)) |>
  rename(value = beta_mean)

posterior_both <- bind_rows(post_alpha, post_beta)

ggplot(posterior_both, aes(x = value, fill = condition)) +
  geom_density(alpha = 0.6) +
  facet_wrap(~parameter, scales = "free") +
  labs(x = "Posterior mean", y = "Density", fill = "Condition") +
  theme(legend.position = "top")
```

#### Interpretazione

* Riporta per ciascun parametro ($\alpha$ e $\beta$) **la differenza di media tra condizioni** (Δ = condizione$_2$ − condizione$_1$), l’**intervallo credibile al 95%** e la **probabilità a posteriori** che Δ sia negativa (o positiva, a seconda dell’ipotesi).
* **Se l’intervallo credibile include 0**, le evidenze per una differenza sistematica sono deboli con questo modello e questi dati: la direzione suggerita dalla media può essere interessante, ma **incerta**.
* **Se l’intervallo credibile esclude 0**, puoi parlare di una differenza credibile tra condizioni per quel parametro, e la probabilità a posteriori (es. $P(\Delta<0)$) quantifica la forza di questa evidenza.
* La **densità delle posterior** per $\alpha_{\text{mean}}$ e $\beta_{\text{mean}}$ per ciascuna condizione aiuta a verificare **quanto** e **in che direzione** le distribuzioni si separano.

> Suggerimento per il testo del manoscritto:
> *“We estimated condition-specific population means for the learning rate ($\alpha$) and drift ($\beta$). The posterior contrast $\Delta = \mu_{\text{cond2}} - \mu_{\text{cond1}}$ yielded $\Delta_\alpha = \hat{m}$ \[95% CrI: $l, u$], $P(\Delta_\alpha < 0) = p$; and $\Delta_\beta = \hat{m}'$ \[95% CrI: $l', u'$], $P(\Delta_\beta < 0) = p'$. While point estimates suggested \[direzione], the credible intervals \[include/escludono] zero, indicating \[weak/credible] evidence for a condition effect.”*






```{r}
# Calcola probabilità a posteriori per delta_alpha_mean < 0 e delta_beta_mean < 0
# (supponiamo che draws_df contenga le colonne `alpha_mean[1]`, `alpha_mean[2]`, ecc.)

# Calcola e stampa probabilità a posteriori
prob_delta_alpha_neg <- mean(draws_df$`alpha_mean[2]` - draws_df$`alpha_mean[1]` < 0)
prob_delta_beta_neg  <- mean(draws_df$`beta_mean[2]` - draws_df$`beta_mean[1]` < 0)

cat("P(delta_alpha_mean < 0):", round(prob_delta_alpha_neg, 3), "\n")
cat("P(delta_beta_mean < 0):", round(prob_delta_beta_neg, 3), "\n")
```

```{r}
# Costruisci una tabella riassuntiva con la dimensione dell'effetto
summary_df <- tibble(
  parameter = c("alpha_mean", "beta_mean"),
  delta_mean = c(
    mean(draws_df$`alpha_mean[2]` - draws_df$`alpha_mean[1]`),
    mean(draws_df$`beta_mean[2]` - draws_df$`beta_mean[1]`)
  ),
  lower_95 = c(
    quantile(draws_df$`alpha_mean[2]` - draws_df$`alpha_mean[1]`, 0.025),
    quantile(draws_df$`beta_mean[2]` - draws_df$`beta_mean[1]`, 0.025)
  ),
  upper_95 = c(
    quantile(draws_df$`alpha_mean[2]` - draws_df$`alpha_mean[1]`, 0.975),
    quantile(draws_df$`beta_mean[2]` - draws_df$`beta_mean[1]`, 0.975)
  ),
  prob_below_0 = c(
    prob_delta_alpha_neg,
    prob_delta_beta_neg
  )
)

summary_df
```


```{r}
# Grafico a barre con intervallo credibile

summary_df |> 
  ggplot(aes(x = parameter, y = delta_mean)) +
  geom_bar(stat = "identity", fill = "steelblue", width = 0.5) +
  geom_errorbar(aes(ymin = lower_95, ymax = upper_95), width = 0.2) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(
    x = "Parametro",
    y = "Differenza media\n(cond2 - cond1)"
  ) 
```


Per quantificare la differenza tra condizioni sugli iper-parametri di popolazione, abbiamo calcolato il contrasto $\Delta = \text{cond2} - \text{cond1}$ (applicato alle medie di condizione $\alpha_{\text{mean}}$ e $\beta_{\text{mean}}$). Nel nostro codice, **cond2 − cond1** corrisponde a *(avoidance − approach)*\*.

Il calcolo diretto sui draw posteriori restituisce:

* **$\Delta_{\alpha}$** (*avoidance − approach*): media = **−0.247**, CrI 95% = **\[−0.481, −0.035]**, $P(\Delta_{\alpha}<0)=$**0.989**.
  → Evidenza **credibile** di una media di $\alpha$ più bassa in *avoidance* rispetto ad *approach*. Poiché i dati sono standardizzati, l’ordine di grandezza è \~**0.25 SD**: un effetto non enorme ma non trascurabile.

* **$\Delta_{\beta}$** (*avoidance − approach*): media = **−0.126**, CrI 95% = **\[−0.251, 0.002]**, $P(\Delta_{\beta}<0)=$**0.974**.
  → La massa a sinistra di zero è elevata, ma il **95% CrI include lo zero** per un soffio: l’evidenza a favore di $\beta$ più bassa in *avoidance* è **suggestiva ma non conclusiva** con questa soglia di credibilità.

\* *Nota*: se l’ordinamento dei livelli del fattore fosse diverso nel dataset, occorre aggiornare le etichette (il codice di preparazione dati lo rende esplicito).

#### Come leggere il grafico a barre

Il grafico riassume per ciascun parametro la **differenza media a posteriori** (barra) con il **95% CrI** (linee).
La linea tratteggiata a $0$ indica “assenza di differenza” tra condizioni:

* Per $\alpha$, l’intervallo è interamente **sotto** lo zero → differenza credibile a favore di *approach* (valori medi più alti di $\alpha$ in *approach*).
* Per $\beta$, la barra è sotto lo zero ma l’intervallo **tocca** lo zero → la direzione è coerente con $\alpha$, ma l’incertezza non consente un’affermazione forte al 95%.

#### Significato sostantivo

* **$\alpha$ (tasso di aggiornamento)**: in *avoidance* i partecipanti aggiornano **più lentamente** (valori medi più bassi di $\alpha$) rispetto ad *approach*. In termini standardizzati, l’effetto medio è \~0.25 SD: **moderato**.
* **$\beta$ (drift/termine di tendenza)**: tendenza **coerente** (più basso in *avoidance*), ma evidenza **debole** al 95%.

#### Nota metodologica e onestà interpretativa

* Le stime derivano da un **modello gerarchico** (non-centrato), con priors debolmente informativi e dati z-standardizzati; le conclusioni sono **model-based**.
* Riportare **sia** il 95% CrI **sia** la probabilità a posteriori $P(\Delta<0)$ aiuta a distinguere **direzione** dell’effetto (qui molto probabile negativa) da **forza dell’evidenza** ai livelli di credibilità scelti.
* Se la **rilevanza pratica** è cruciale, si può integrare con una ROPE (es. $[-0.1, 0.1]$ in unità z) per quantificare quanta parte della distribuzione di $\Delta$ ricade in una “zona di equivalenza pratica”.

#### Box (per il manoscritto)

> *“We contrasted condition-specific population means (avoidance − approach). For the learning rate, $\Delta_\alpha = -0.247$ \[95% CrI: −0.481, −0.035], $P(\Delta_\alpha<0)=0.989$; for the drift, $\Delta_\beta = -0.126$ \[95% CrI: −0.251, 0.002], $P(\Delta_\beta<0)=0.974$. Thus, while point estimates consistently favored lower values under avoidance, only the effect on $\alpha$ reached credible separation from zero at the 95% level.”*




## Confronto tra modelli

Per valutare quale modello descriva meglio i dati abbiamo utilizzato la cross-validazione leave-one-out (LOO-CV), che stima la expected log predictive density (ELPD). Un ELPD più alto indica predizioni più accurate.

```{r}
log_lik1 <- fit1$draws(variables = "log_lik", format = "matrix")
log_lik2 <- fit2$draws(variables = "log_lik", format = "matrix")
log_lik3 <- fit3$draws(variables = "log_lik", format = "matrix")

# Calcola LOO per ciascun modello
loo1 <- loo(log_lik1)
loo2 <- loo(log_lik2)
loo3 <- loo(log_lik3)

# Confronto tra i modelli
model_comparison <- loo_compare(loo1, loo2, loo3)
print(model_comparison)
```

Il modello **gerarchico con condizione (Model 3)** ottiene la predizione migliore. Tuttavia, il confronto con il **modello gerarchico senza condizione (Model 2)** mostra una differenza di ELPD pari a −4.7, con un errore standard di 3.9. Questa differenza è **piccola rispetto all’incertezza della stima**, quindi non possiamo affermare con sicurezza che includere la condizione migliori la predizione, anche se la tendenza è in quella direzione.

Diverso il discorso per il **modello non gerarchico (Model 1)**: la perdita di ELPD rispetto a Model 3 è molto ampia (−23.3, con SE = 7.6). In questo caso la differenza è sufficientemente grande da concludere che Model 1 produce predizioni nettamente peggiori.


#### Cosa impariamo

1. **La gerarchia è cruciale**: i modelli gerarchici (Model 2 e 3) descrivono i dati molto meglio del modello non gerarchico. Questo conferma l’importanza di “condividere informazione” tra soggetti per ottenere stime più stabili e predizioni più accurate.

2. **L’effetto della condizione è plausibile, ma non certo**: il modello con condizione (Model 3) tende a comportarsi meglio, ma il vantaggio rispetto al modello gerarchico semplice (Model 2) non è statisticamente robusto. Questo risultato è coerente con le stime dei parametri: la differenza tra condizioni sembra più marcata per $\alpha$, meno per $\beta$.

3. **Scelta del modello**:

   * Se l’obiettivo principale è la parsimonia, Model 2 è già soddisfacente.
   * Se vogliamo testare esplicitamente l’effetto della condizione, Model 3 è preferibile, anche se il guadagno predittivo rimane incerto.




## Riflessioni conclusive {.unnumbered .unlisted}

In questo capitolo abbiamo esplorato tre approcci bayesiani progressivamente più sofisticati per modellare l'aggiornamento degli obiettivi, dimostrando come l'aumento controllato della complessità strutturale possa arricchire significativamente l'analisi psicologica. Il percorso è partito da un modello individuale semplice, per passare a una struttura gerarchica che capitalizza le similarità tra partecipanti, fino ad arrivare a un framework che incorpora esplicitamente le differenze tra condizioni sperimentali.

L'analisi comparativa ha evidenziato come la struttura gerarchica offra vantaggi sostanziali in termini di capacità predittiva, come confermato dai valori ELPD. Questo approccio implementa efficacemente il principio dello shrinkage, stabilizzando le stime soprattutto quando i dati per singolo soggetto sono limitati - situazione frequente nella ricerca psicologica.

Un risultato particolarmente interessante emerge dal modello con gruppi sperimentali, che ha permesso di quantificare le differenze sistematiche nei parametri cognitivi tra condizioni. Sebbene questi effetti non raggiungano la significatività statistica convenzionale, le probabilità a posteriori superiori al 96% forniscono un supporto quantificabile alle ipotesi direzionali, mostrando la potenza dell'inferenza bayesiana nel cogliere sfumature spesso trascurate dai metodi frequentisti.

Dal punto di vista metodologico, questo percorso dimostra l'importanza di:

- progettare strutture modellistiche che riflettano accuratamente le dipendenze naturali tra le osservazioni;
- incorporare sistematicamente le informazioni sperimentali nei livelli iperparametrici;
- bilanciare complessità e generalizzazione attraverso confronti basati su evidenza predittiva.

Il modello presentato - autoregressivo non lineare a tempo discreto in un framework bayesiano multilivello - si conferma come una cornice flessibile ed efficace per rappresentare processi dinamici che evolvono nel tempo, variano tra individui e differiscono tra gruppi sperimentali. Le tecniche illustrate in questo capitolo pongono solide basi per affrontare scenari ancor più complessi, come i modelli di miscela per classificazioni non supervisionate [per approfondimenti, si veda il tutorial di @knight2023tutorial].


::: {.callout-note collapse=true title="Informazioni sull'ambiente di sviluppo"}
```{r}
sessionInfo()
```
:::

## Bibliografia {.unnumbered .unlisted}
