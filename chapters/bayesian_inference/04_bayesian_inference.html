<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="it" xml:lang="it"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<meta name="author" content="Corrado Caudek">
<title>46&nbsp; Inferenza bayesiana – Psicometria</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>

<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../chapters/bayesian_inference/05_subj_prop.html" rel="next">
<link href="../../chapters/bayesian_inference/03_statistical_models.html" rel="prev">
<link href="../../style/gauss.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-5ce6d56fc2a85cf1942de8a9da5c14ea.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-3f72b9a39ab085079172b95de82a88dc.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Nessun risultato",
    "search-matching-documents-text": "documenti trovati",
    "search-copy-link-title": "Copiare il link nella ricerca",
    "search-hide-matches-text": "Nascondere i risultati aggiuntivi",
    "search-more-match-text": "ci sono altri risultati in questo documento",
    "search-more-matches-text": "ulteriori risultati in questo documento",
    "search-clear-button-title": "Pulire",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancellare",
    "search-submit-button-title": "Inviare",
    "search-label": "Ricerca"
  }
}</script><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-QT5S3P9D31"></script><script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-QT5S3P9D31', { 'anonymize_ip': true});
</script><script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script><script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>
</head>
<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Attiva/disattiva la barra laterale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../chapters/bayesian_inference/introduction_bayes_inference.html">Inferenza</a></li><li class="breadcrumb-item"><a href="../../chapters/bayesian_inference/04_bayesian_inference.html"><span class="chapter-number">46</span>&nbsp; <span class="chapter-title">Inferenza bayesiana</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Attiva/disattiva la barra laterale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Ricerca" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../../">Psicometria</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/ccaudek/psicometria-r/" title="Eseguire il codice" class="quarto-navigation-tool px-1" aria-label="Eseguire il codice"><i class="bi bi-github"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Attiva/disattiva la modalità lettore">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Ricerca"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Informazioni Generali</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../prefazione.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Prefazione</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../chapters/key_notions/introduction_key_notions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Fondamenti</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/key_notions/01_data_analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">La crisi di replicazione e la riforma metodologica in psicologia</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/key_notions/02_key_notions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Concetti chiave</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/key_notions/03_design.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Campionamento, metodologia sperimentale e studi osservazionali</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/key_notions/04_measurement.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">La misurazione in psicologia</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/key_notions/05_cognitive_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Dalla descrizione alla spiegazione: modelli meccanicistici e computazionali in psicologia</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../chapters/R/introduction_r_lang.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">R</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/R/01_r_syntax.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Un approccio moderno all’analisi dei dati</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/R/02_utility_functions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Utility functions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/R/03_r_programming.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Programmazione</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/R/04_r_packages.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Pacchetti</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/R/05_dplyr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Introduzione a <code>dplyr</code></span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/R/06_quarto.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Quarto</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/R/07_environment.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">L’ambiente di programmazione</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/R/08_ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Utilizzo di strumenti AI</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../chapters/eda/introduction_eda.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">EDA</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/01_project_structure.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Le fasi del progetto di analisi dei dati</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/02_data_cleaning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Flusso di lavoro per la pulizia dei dati</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/04_exploring_qualitative_data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Esplorare i dati qualitativi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/05_exploring_numeric_data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Esplorare i dati numerici</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/06_data_visualization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Principi della visualizzazione dei dati</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/07_loc_scale.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Indicatori di tendenza centrale e variabilità</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/07a_introduction_normal_distribution.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Introduzione alla distribuzione normale</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/08_correlation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Relazioni tra variabili</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/09_causality.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Causalità dai dati osservazionali</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/10_estimand.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Estimandi teorici e estimandi empirici</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/11_outlier.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Outlier</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../chapters/probability/introduction_probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Probabilità</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/01_intro_prob.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Interpretazione della probabilità</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/02_probability_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Modelli probabilistici</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/03_prob_spaces.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">La Probabilità come misura della certezza razionale: un’interpretazione Bayesiana</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/04_sigma-algebra.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Dal Discreto al Continuo: la <span class="math inline">\(\sigma\)</span>-algebra</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/05_conditional_prob.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Probabilità condizionata</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/06_bayes_theorem.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Il teorema di Bayes</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/07_random_var.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Variabili casuali</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/08_prob_distributions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">Distribuzioni di massa e di densità</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/09_expval_var.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">Proprietà delle variabili casuali</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/10_sampling_distr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">34</span>&nbsp; <span class="chapter-title">Stime, stimatori e parametri</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/11a_joint_prob.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">35</span>&nbsp; <span class="chapter-title">Probabilità congiunta</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/11b_cov_cor.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">36</span>&nbsp; <span class="chapter-title">Covarianza e correlazione</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/11c_joint_prob_cont.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">37</span>&nbsp; <span class="chapter-title">Caso continuo</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/12a_intro_distributions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">38</span>&nbsp; <span class="chapter-title">Introduzione alle distribuzioni di probabilità</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/12_discr_rv_distr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">39</span>&nbsp; <span class="chapter-title">Distribuzioni di v.c. discrete</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/13_cont_rv_distr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">40</span>&nbsp; <span class="chapter-title">Distribuzioni di v.c. continue</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/14_gauss.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">41</span>&nbsp; <span class="chapter-title">Assunzione di gaussianità e trasformazioni dei dati</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/15_likelihood.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">42</span>&nbsp; <span class="chapter-title">La verosimiglianza</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Inferenza</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/introduction_bayes_inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/01_uncertainty.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">43</span>&nbsp; <span class="chapter-title">Abbracciare l’incertezza</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/02_intro_bayes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">44</span>&nbsp; <span class="chapter-title">La quantificazione dell’incertezza</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/03_statistical_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">45</span>&nbsp; <span class="chapter-title">Modelli statistici</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/04_bayesian_inference.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">46</span>&nbsp; <span class="chapter-title">Inferenza bayesiana</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/05_subj_prop.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">47</span>&nbsp; <span class="chapter-title">Aggiornare le credenze su un parametro: dal prior alla posterior</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/07_conjugate_families_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">48</span>&nbsp; <span class="chapter-title">Distribuzioni coniugate (1)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/08_conjugate_families_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">49</span>&nbsp; <span class="chapter-title">Distribuzioni coniugate (2)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/09_summary_posterior.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">50</span>&nbsp; <span class="chapter-title">Sintesi a posteriori</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/10_balance_prior_post.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">51</span>&nbsp; <span class="chapter-title">L’influenza della distribuzione a priori</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/11_gamma_poisson_model.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">52</span>&nbsp; <span class="chapter-title">Modello coniugato Gamma-Poisson</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/12_gamma_exponential_model.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">53</span>&nbsp; <span class="chapter-title">Modello gamma-esponenziale</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/13_prior_pred_check.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">54</span>&nbsp; <span class="chapter-title">Controllo predittivo a priori (Prior Predictive Check)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/14_post_pred_distr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">55</span>&nbsp; <span class="chapter-title">Distribuzione predittiva a posteriori</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="false">
 <span class="menu-text">MCMC</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/introduction_mcmc.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/01_metropolis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">56</span>&nbsp; <span class="chapter-title">L’algoritmo di Metropolis-Hastings</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/02_ppl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">57</span>&nbsp; <span class="chapter-title">Linguaggi di programmazione probabilistici</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/07_bayesian_workflow.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">58</span>&nbsp; <span class="chapter-title">Flusso di lavoro bayesiano</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="false">
 <span class="menu-text">Regressione</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/introduction_linear_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/01_reglin_frequentist.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">59</span>&nbsp; <span class="chapter-title">La regressione lineare bivariata</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/02_regr_toward_mean.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">60</span>&nbsp; <span class="chapter-title">La regressione verso la media</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/03_reglin_bayes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">61</span>&nbsp; <span class="chapter-title">Modello bayesiano di regressione lineare bivariata</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/04_synt_sugar.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">62</span>&nbsp; <span class="chapter-title">Zucchero sintattico</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/04a_stan_regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">63</span>&nbsp; <span class="chapter-title">Regressione lineare in Stan</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/05_one_mean.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">64</span>&nbsp; <span class="chapter-title">Inferenza bayesiana su una media</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/07_two_means.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">65</span>&nbsp; <span class="chapter-title">Confronto tra le medie di due gruppi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/07a_effect_size.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">66</span>&nbsp; <span class="chapter-title">La grandezza dell’effetto: valutare la rilevanza pratica</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/08_sample_size.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">67</span>&nbsp; <span class="chapter-title">Pianificazione della dimensione campionaria</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/09_anova_1via.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">68</span>&nbsp; <span class="chapter-title">ANOVA ad una via</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/10_anova_2vie.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">69</span>&nbsp; <span class="chapter-title">ANOVA ad due vie</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/11_one_proportion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">70</span>&nbsp; <span class="chapter-title">Inferenza sulle proporzioni</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/12_two_proportions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">71</span>&nbsp; <span class="chapter-title">Confronto tra due proporzioni indipendenti</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/13_poisson_model.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">72</span>&nbsp; <span class="chapter-title">Modello di Poisson</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="false">
 <span class="menu-text">Entropia</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/entropy/01_entropy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">73</span>&nbsp; <span class="chapter-title">Entropia e informazione di Shannon</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/entropy/02_kl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">74</span>&nbsp; <span class="chapter-title">La divergenza di Kullback-Leibler</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/entropy/03_model_comparison.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">75</span>&nbsp; <span class="chapter-title">Valutare i modelli bayesiani: Log-Score, LPPD, ELPD e LOO-CV</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="false">
 <span class="menu-text">Modelli</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/formal_models/introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/formal_models/01_dynamic_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">76</span>&nbsp; <span class="chapter-title">Il modello di revisione degli obiettivi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/formal_models/02_dynamic_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">77</span>&nbsp; <span class="chapter-title">Estensioni</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/formal_models/03_rescorla_wagner.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">78</span>&nbsp; <span class="chapter-title">Il modello di Rescorla–Wagner</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="false">
 <span class="menu-text">Decisioni</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/decision_analysis/01_study_method.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">79</span>&nbsp; <span class="chapter-title">Analisi delle decisioni</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="false">
 <span class="menu-text">Missing</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-11" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/missing/01_mnar_stan.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">80</span>&nbsp; <span class="chapter-title">Dati mancanti in psicologia: identificare e modellare i casi MNAR con un approccio Bayesiano in Stan</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="false">
 <span class="menu-text">Frequentismo</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-12" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/frequentist_inference/introduction_frequentist_inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/frequentist_inference/01_intro_frequentist.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">81</span>&nbsp; <span class="chapter-title">Inferenza frequentista</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/frequentist_inference/01a_stime_parametri.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">82</span>&nbsp; <span class="chapter-title">Stime, stimatori e parametri</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/frequentist_inference/02_conf_interv.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">83</span>&nbsp; <span class="chapter-title">Intervalli di fiducia</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/frequentist_inference/03_sample_size.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">84</span>&nbsp; <span class="chapter-title">La grandezza del campione</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/frequentist_inference/04_test_ipotesi.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">85</span>&nbsp; <span class="chapter-title">Significatività statistica</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/frequentist_inference/05_two_ind_samples.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">86</span>&nbsp; <span class="chapter-title">Test t di Student per campioni indipendenti</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" role="navigation" aria-expanded="false">
 <span class="menu-text">Crisi</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-13" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/introduction_replication_crisis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/01_crisis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">87</span>&nbsp; <span class="chapter-title">La crisi della replicazione</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/02_limits_stat_freq.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">88</span>&nbsp; <span class="chapter-title">Limiti dell’inferenza frequentista</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/03_effect_size.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">89</span>&nbsp; <span class="chapter-title">La grandezza dell’effetto</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/04_s_m_errors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">90</span>&nbsp; <span class="chapter-title">Errori di segno e errori di grandezza</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/05_p_values.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">91</span>&nbsp; <span class="chapter-title">La fragilità del <em>p</em>-valore</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/06_changes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">92</span>&nbsp; <span class="chapter-title">Riforma</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/07_piranha.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">93</span>&nbsp; <span class="chapter-title">Il Problema del priming: sfide e paradossi nella psicologia sociale</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/08_degrees_of_freedom.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">94</span>&nbsp; <span class="chapter-title">I gradi di libertà del ricercatore</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/09_integrity.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">95</span>&nbsp; <span class="chapter-title">Integrità della ricerca</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-14" role="navigation" aria-expanded="false">
 <span class="menu-text">Epilogo</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-14" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-14" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/epiloque/epiloque.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Considerazioni Conclusive</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-15" role="navigation" aria-expanded="false">
 <span class="menu-text">Appendici</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-15" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-15" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a01_shell.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">La Shell</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a01a_files.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Cartelle e documenti</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a02_math_symbols.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Simbologia di base</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a03_latex.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Equazioni Matematiche in LaTeX</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a11_numbers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">E</span>&nbsp; <span class="chapter-title">Numeri e intervalli</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a12_sum_notation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">F</span>&nbsp; <span class="chapter-title">Sommatorie</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a13_sets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">G</span>&nbsp; <span class="chapter-title">Insiemi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a14_combinatorics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">H</span>&nbsp; <span class="chapter-title">Calcolo combinatorio</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a15_calculus.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">I</span>&nbsp; <span class="chapter-title">Per liberarvi dai terrori preliminari</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a47_first_order_markov.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">J</span>&nbsp; <span class="chapter-title">Catene di Markov</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a50_lin_fun.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">K</span>&nbsp; <span class="chapter-title">La funzione lineare</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a71_install_cmdstan.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">L</span>&nbsp; <span class="chapter-title">Come installare CmdStan</span></span></a>
  </div>
</li>
      </ul>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Indice</h2>
   
  <ul class="collapse">
<li><a href="#introduzione" id="toc-introduzione" class="nav-link active" data-scroll-target="#introduzione"><span class="header-section-number">46.1</span> Introduzione</a></li>
  <li><a href="#dove-si-colloca-linferenza-nel-processo-di-ricerca" id="toc-dove-si-colloca-linferenza-nel-processo-di-ricerca" class="nav-link" data-scroll-target="#dove-si-colloca-linferenza-nel-processo-di-ricerca"><span class="header-section-number">46.2</span> Dove si colloca l’inferenza nel processo di ricerca?</a></li>
  <li><a href="#il-teorema-di-bayes-come-regola-di-aggiornamento" id="toc-il-teorema-di-bayes-come-regola-di-aggiornamento" class="nav-link" data-scroll-target="#il-teorema-di-bayes-come-regola-di-aggiornamento"><span class="header-section-number">46.3</span> Il teorema di Bayes come regola di aggiornamento</a></li>
  <li><a href="#un-esempio-intuitivo-la-moneta-sbilanciata" id="toc-un-esempio-intuitivo-la-moneta-sbilanciata" class="nav-link" data-scroll-target="#un-esempio-intuitivo-la-moneta-sbilanciata"><span class="header-section-number">46.4</span> Un esempio intuitivo: la moneta sbilanciata</a></li>
  <li><a href="#perch%C3%A9-usare-le-probabilit%C3%A0-come-gradi-di-credenza" id="toc-perché-usare-le-probabilità-come-gradi-di-credenza" class="nav-link" data-scroll-target="#perch%C3%A9-usare-le-probabilit%C3%A0-come-gradi-di-credenza"><span class="header-section-number">46.5</span> Perché usare le probabilità come gradi di credenza?</a></li>
  <li><a href="#il-paradigma-dellinferenza-bayesiana" id="toc-il-paradigma-dellinferenza-bayesiana" class="nav-link" data-scroll-target="#il-paradigma-dellinferenza-bayesiana"><span class="header-section-number">46.6</span> Il Paradigma dell’Inferenza Bayesiana</a></li>
  <li><a href="#unintroduzione-ai-priori" id="toc-unintroduzione-ai-priori" class="nav-link" data-scroll-target="#unintroduzione-ai-priori"><span class="header-section-number">46.7</span> Un’introduzione ai Priori</a></li>
  <li><a href="#quando-il-calcolo-si-complica-mcmc" id="toc-quando-il-calcolo-si-complica-mcmc" class="nav-link" data-scroll-target="#quando-il-calcolo-si-complica-mcmc"><span class="header-section-number">46.8</span> Quando il calcolo si complica: MCMC</a></li>
  <li><a href="#riflessioni-conclusive" id="toc-riflessioni-conclusive" class="nav-link" data-scroll-target="#riflessioni-conclusive"><span class="header-section-number">46.9</span> Riflessioni Conclusive</a></li>
  <li><a href="#esercizi" id="toc-esercizi" class="nav-link" data-scroll-target="#esercizi">Esercizi</a></li>
  <li><a href="#informazioni-sullambiente-di-sviluppo" id="toc-informazioni-sullambiente-di-sviluppo" class="nav-link" data-scroll-target="#informazioni-sullambiente-di-sviluppo">Informazioni sull’Ambiente di Sviluppo</a></li>
  <li><a href="#bibliografia" id="toc-bibliografia" class="nav-link" data-scroll-target="#bibliografia">Bibliografia</a></li>
  </ul><div class="toc-actions"><ul class="collapse"><li><a href="https://github.com/ccaudek/psicometria-r/blob/main/chapters/bayesian_inference/04_bayesian_inference.qmd" class="toc-action"><i class="bi bi-github"></i>Mostra il codice</a></li><li><a href="https://github.com/ccaudek/psicometria-r/issues/new" class="toc-action"><i class="bi empty"></i>Segnala un problema</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../chapters/bayesian_inference/introduction_bayes_inference.html">Inferenza</a></li><li class="breadcrumb-item"><a href="../../chapters/bayesian_inference/04_bayesian_inference.html"><span class="chapter-number">46</span>&nbsp; <span class="chapter-title">Inferenza bayesiana</span></a></li></ol></nav><div class="quarto-title">
<h1 class="title"><span id="sec-bayes-inference" class="quarto-section-identifier"><span class="chapter-number">46</span>&nbsp; <span class="chapter-title">Inferenza bayesiana</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header><div class="callout callout-style-simple callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
In questo capitolo approfondirai i seguenti concetti fondamentali:
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>distribuzione marginale;</li>
<li>approccio analitico e numerico per determinare la distribuzione a posteriori;</li>
<li>linguaggi di programmazione probabilistici;</li>
<li>inferenza predittiva.</li>
</ul>
</div>
</div>
<div class="callout callout-style-simple callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Prerequisiti
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Leggere il capitolo <em>Bayes’ Rule</em> del testo di <span class="citation" data-cites="Johnson2022bayesrules">Johnson et al. (<a href="#ref-Johnson2022bayesrules" role="doc-biblioref">2022</a>)</span>.</li>
<li>Leggere <em>Navigating the Bayes maze: The psychologist’s guide to Bayesian statistics, a hands-on tutorial with R code</em> <span class="citation" data-cites="alter2025navigating">(<a href="#ref-alter2025navigating" role="doc-biblioref">Alter et al., 2025</a>)</span>.</li>
<li>Leggere <em>Ten quick tips to get you started with Bayesian statistics</em> <span class="citation" data-cites="gimenez2025ten">(<a href="#ref-gimenez2025ten" role="doc-biblioref">Gimenez et al., 2025</a>)</span>.</li>
</ul>
</div>
</div>
<div class="callout callout-style-simple callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Preparazione del Notebook
</div>
</div>
<div class="callout-body-container callout-body">
<div class="cell">
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">here</span><span class="fu">::</span><span class="fu"><a href="https://here.r-lib.org/reference/here.html">here</a></span><span class="op">(</span><span class="st">"code"</span>, <span class="st">"_common.R"</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/source.html">source</a></span><span class="op">(</span><span class="op">)</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
<section id="introduzione" class="level2" data-number="46.1"><h2 data-number="46.1" class="anchored" data-anchor-id="introduzione">
<span class="header-section-number">46.1</span> Introduzione</h2>
<p>Negli ultimi vent’anni l’inferenza bayesiana è passata da “curiosità matematica” a strumento di lavoro quotidiano in campi che vanno dalla biologia all’economia, dalla medicina alle scienze cognitive. In psicologia la sua popolarità è legata a due vantaggi pratici:</p>
<ul>
<li>integrare conoscenze pregresse (p.e. studi precedenti, expertise clinica) all’interno dell’analisi;</li>
<li>gestire al meglio campioni piccoli o rumorosi, frequenti nei contesti sperimentali e clinici.</li>
</ul>
<p>Per uno studente di psicologia la curva di apprendimento può sembrare ripida. Non è così: i concetti chiave si acquisiscono gradualmente e si ripagano in fretta. In questo capitolo mostreremo come.</p>
</section><section id="dove-si-colloca-linferenza-nel-processo-di-ricerca" class="level2" data-number="46.2"><h2 data-number="46.2" class="anchored" data-anchor-id="dove-si-colloca-linferenza-nel-processo-di-ricerca">
<span class="header-section-number">46.2</span> Dove si colloca l’inferenza nel processo di ricerca?</h2>
<p>Richiamiamo il diagramma di modellizzazione e analisi introdotto in <a href="03_statistical_models.html#fig-modeling-analysis" class="quarto-xref">Figura&nbsp;<span>45.1</span></a>. L’inferenza occupa la parte centrale: partendo dai <strong>dati osservati</strong> vogliamo trarre conclusioni sul <strong>modello</strong> e sui suoi <strong>parametri</strong> <span class="math inline">\(\boldsymbol\theta\)</span>. Esistono due cornici teoriche:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 41%">
<col style="width: 31%">
<col style="width: 27%">
</colgroup>
<thead><tr class="header">
<th></th>
<th>Statistica Bayesiana</th>
<th>Statistica Frequentista</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><strong>Natura di <span class="math inline">\(\boldsymbol\theta\)</span></strong></td>
<td>variabile aleatoria con distribuzione <em>a priori</em>
</td>
<td>valore fisso ma ignoto</td>
</tr>
<tr class="even">
<td><strong>Uso di informazioni pregresse</strong></td>
<td>sì (explicita nella prior)</td>
<td>no (basata solo sui dati)</td>
</tr>
<tr class="odd">
<td><strong>Obiettivi tipici</strong></td>
<td>posteriore, previsione, decisione</td>
<td>stima, test d’ipotesi</td>
</tr>
<tr class="even">
<td><strong>Fondamento concettuale</strong></td>
<td>probabilità come grado di credenza soggettivo</td>
<td>probabilità come frequenza a lungo termine</td>
</tr>
</tbody>
</table>
<p>Nel prosieguo ci concentreremo sul paradigma bayesiano, rimandando alla sezione … per il frequentista.</p>
</section><section id="il-teorema-di-bayes-come-regola-di-aggiornamento" class="level2" data-number="46.3"><h2 data-number="46.3" class="anchored" data-anchor-id="il-teorema-di-bayes-come-regola-di-aggiornamento">
<span class="header-section-number">46.3</span> Il teorema di Bayes come regola di aggiornamento</h2>
<p>L’idea centrale è semplice: <strong>si parte da una distribuzione <em>a priori</em> sui parametri, si osservano i dati, si ottiene una distribuzione <em>a posteriori</em></strong>:</p>
<p><span class="math display">\[
    p(\boldsymbol\theta\mid\mathbf{x})=\frac{p(\mathbf{x}\mid\boldsymbol\theta)\,p(\boldsymbol\theta)}{p(\mathbf{x})},
\]</span></p>
<p>dove</p>
<ul>
<li>
<span class="math inline">\(p(\mathbf{x}\mid\boldsymbol\theta)\)</span> è la <strong>verosimiglianza</strong> (il modello generativo dei dati);<br>
</li>
<li>
<span class="math inline">\(p(\boldsymbol\theta)\)</span> è la <strong>prior</strong> (ciò che sapevamo prima);<br>
</li>
<li>
<span class="math inline">\(p(\mathbf{x})\)</span> è la <strong>evidenza</strong> o <strong>marginal likelihood</strong>, costante di normalizzazione.</li>
</ul>
<p>Il risultato è un <strong>meccanismo di apprendimento cumulativo</strong>: ogni nuova evidenza aggiorna coerentemente le nostre credenze. Questo rende l’approccio naturale in psicologia, dove le ricerche successive spesso si accumulano su temi simili (p.e. effetti di un trattamento cognitivo-comportamentale).</p>
</section><section id="un-esempio-intuitivo-la-moneta-sbilanciata" class="level2" data-number="46.4"><h2 data-number="46.4" class="anchored" data-anchor-id="un-esempio-intuitivo-la-moneta-sbilanciata">
<span class="header-section-number">46.4</span> Un esempio intuitivo: la moneta sbilanciata</h2>
<p>Supponiamo di lanciare una moneta <span class="math inline">\(N=10\)</span> volte ottenendo <span class="math inline">\(y=8\)</span> teste. Vogliamo inferire la probabilità <span class="math inline">\(\theta\)</span> di ottenere “testa”.</p>
<ol type="1">
<li><strong>Model specification</strong></li>
</ol>
<p><span class="math display">\[
y\sim\text{Binomiale}(N,\theta).
\]</span></p>
<ol start="2" type="1">
<li><p><strong>Scelta della prior</strong><br><em>Uniforme</em> su <span class="math inline">\([0,1]\)</span> (prior non informativo) oppure <em>Beta(2,2)</em> se riteniamo monete di solito quasi eque.</p></li>
<li><p><strong>Aggiornamento</strong><br>
Con prior Beta e verosimiglianza binomiale otteniamo una posteriore ancora Beta:</p></li>
</ol>
<p><span class="math display">\[
\theta\mid y \sim \text{Beta}(\alpha\!+\!y,\;\beta\!+\!N-y).
\]</span></p>
<ol start="4" type="1">
<li>
<strong>Risultati</strong><br>
</li>
</ol>
<ul>
<li>Stima puntuale: media <span class="math inline">\(\hat\theta=(\alpha+y)/(\alpha+\beta+N)\approx0{,}73\)</span>.<br>
</li>
<li>Incertezza: intervallo di credibilità (p.e. 95 %) dal percentilo 2,5 al 97,5 della posteriore.<br>
</li>
<li>Decisione: la probabilità che <span class="math inline">\(\theta&gt;0{,}5\)</span> è <span class="math inline">\(\approx0{,}97\)</span> → forte evidenza di moneta sbilanciata.</li>
</ul>
<p>L’intero procedimento è automatizzabile in software come <strong>R + brms</strong>, <strong>Stan</strong> o <strong>PyMC</strong>; l’utente indica modello e prior, l’algoritmo MCMC campiona la posteriore.</p>
</section><section id="perché-usare-le-probabilità-come-gradi-di-credenza" class="level2" data-number="46.5"><h2 data-number="46.5" class="anchored" data-anchor-id="perché-usare-le-probabilità-come-gradi-di-credenza">
<span class="header-section-number">46.5</span> Perché usare le probabilità come gradi di credenza?</h2>
<p>L’interpretazione della probabilità come misura quantitativa dei gradi di credenza soggettivi si fonda su tre argomenti teorici fondamentali. Questi dimostrano perché le regole della probabilità siano indispensabili per modellare le credenze in modo coerente, razionale ed efficiente.</p>
<section id="argomento-della-scommessa-olandese-dutch-book" class="level3" data-number="46.5.1"><h3 data-number="46.5.1" class="anchored" data-anchor-id="argomento-della-scommessa-olandese-dutch-book">
<span class="header-section-number">46.5.1</span> 1. Argomento della Scommessa Olandese (Dutch Book)</h3>
<p><em>Credenze incoerenti espongono a perdite certe (Ramsey, 1926; De Finetti, 1972).</em></p>
<p>Se un individuo assegna gradi di credenza che <strong>violano gli assiomi della probabilità</strong> (es.: la somma delle probabilità di eventi mutualmente esclusivi supera 1), è possibile costruire un insieme di scommesse (un “Dutch Book”) che garantisce una <strong>perdita certa</strong>, indipendentemente dall’esito degli eventi.</p>
<p><strong>Esempio intuitivo</strong>:<br>
Immaginate di attribuire una probabilità del 60% a un evento <span class="math inline">\(A\)</span> e del 50% al suo complementare <span class="math inline">\(\neg A\)</span>. Un avversario potrebbe proporvi due scommesse:</p>
<ul>
<li>Pagare €60 per ricevere €100 se <span class="math inline">\(A\)</span> si verifica.<br>
</li>
<li>Pagare €50 per ricevere €100 se <span class="math inline">\(\neg A\)</span> si verifica.</li>
</ul>
<p>In totale, spendete €110, ma vincete solo €100 qualunque sia l’esito. Perdete quindi €10 con certezza. Questo mostra che <strong>credere incoerentemente rende vulnerabili a strategie che sfruttano le incongruenze</strong>.</p>
</section><section id="teoria-della-decisione-razionale" class="level3" data-number="46.5.2"><h3 data-number="46.5.2" class="anchored" data-anchor-id="teoria-della-decisione-razionale">
<span class="header-section-number">46.5.2</span> 2. Teoria della Decisione Razionale</h3>
<p><em>Massimizzare l’utilità attesa richiede probabilità coerenti (Savage, 1954; von Neumann &amp; Morgenstern, 1947).</em></p>
<p>Un agente razionale deve allineare le proprie scelte alla massimizzazione dell’<strong>utilità attesa</strong>, calcolata combinando i gradi di credenza (probabilità) con una funzione di utilità.</p>
<p><strong>Problema delle incoerenze decisionali</strong>:<br>
Se i gradi di credenza non rispettano le regole probabilistiche, l’agente potrebbe:</p>
<ul>
<li>Cadere in <strong>preferenze cicliche</strong> (es.: preferire <span class="math inline">\(A\)</span> a <span class="math inline">\(B\)</span>, <span class="math inline">\(B\)</span> a <span class="math inline">\(C\)</span>, ma <span class="math inline">\(C\)</span> ad <span class="math inline">\(A\)</span>).<br>
</li>
<li>Scegliere opzioni <strong>subottimali</strong> rispetto ai propri obiettivi.</li>
</ul>
<p><strong>Esempio</strong>:<br>
Supponete di valutare tre investimenti con probabilità incoerenti. Potreste sovrastimare i rendimenti di due opzioni contemporaneamente, portandovi a scelte contraddittorie e perdite evitabili.</p>
</section><section id="accuratezza-epistemica" class="level3" data-number="46.5.3"><h3 data-number="46.5.3" class="anchored" data-anchor-id="accuratezza-epistemica">
<span class="header-section-number">46.5.3</span> 3. Accuratezza Epistemica</h3>
<p><em>Solo le funzioni di probabilità minimizzano l’errore medio tra credenza e verità.</em></p>
<p>Le funzioni di probabilità sono ottimali nel ridurre l’<strong>inaccuratezza epistemica</strong>, ovvero la discrepanza media tra le credenze e i valori di verità (1 se un evento accade, 0 altrimenti).</p>
<p><strong>Perché funziona</strong>:<br>
- Studi formali (Cox, 1946; Joyce, 1998; Pettigrew, 2016) dimostrano che solo le probabilità minimizzano l’errore <em>atteso</em> in tutti i possibili scenari.<br>
- <strong>Analogia</strong>: Come un meteorologo migliora le previsioni usando probabilità (es.: 80% pioggia), un agente bayesiano riduce l’errore aderendo alle regole probabilistiche.</p>
<p><strong>Implicazione</strong>:<br>
Credere in modo non probabilistico aumenta sistematicamente il rischio di essere in errore, anche con informazioni incomplete.</p>
<p>In sintesi, questi tre argomenti mostrano che le probabilità non sono solo un formalismo matematico, ma un requisito per:</p>
<ol type="1">
<li>
<strong>evitare conseguenze pratiche dannose</strong> (Dutch Book);<br>
</li>
<li>
<strong>ottimizzare le decisioni</strong> in condizioni di incertezza;</li>
<li>
<strong>avvicinarsi alla verità</strong> in modo efficiente.</li>
</ol>
<p>L’inferenza bayesiana integra questi principi, offrendo un framework coerente per aggiornare le credenze alla luce di nuove evidenze (<em>teorema di Bayes</em>).</p>
</section></section><section id="il-paradigma-dellinferenza-bayesiana" class="level2" data-number="46.6"><h2 data-number="46.6" class="anchored" data-anchor-id="il-paradigma-dellinferenza-bayesiana">
<span class="header-section-number">46.6</span> Il Paradigma dell’Inferenza Bayesiana</h2>
<p>L’inferenza bayesiana si basa sull’idea che la probabilità misuri il grado di certezza soggettiva riguardo a un’ipotesi o alla plausibilità di un valore per un parametro sconosciuto. Il cuore di questo approccio è l’<strong>aggiornamento continuo</strong>: le credenze iniziali (<strong>priori</strong>) vengono riviste alla luce di nuove informazioni provenienti dai dati, producendo credenze aggiornate (<strong>posteriori</strong>).</p>
<p>Per comprendere meglio questo processo, è necessario introdurre due concetti chiave: il <strong>modello generativo dei dati</strong> e i <strong>parametri</strong>.</p>
<section id="modello-generativo-dei-dati" class="level3" data-number="46.6.1"><h3 data-number="46.6.1" class="anchored" data-anchor-id="modello-generativo-dei-dati">
<span class="header-section-number">46.6.1</span> Modello Generativo dei Dati</h3>
<p>Un <strong>modello generativo dei dati</strong> è una rappresentazione matematica che descrive come i dati osservati potrebbero essere generati da un processo sottostante. In altre parole, è un’astrazione che specifica le relazioni tra le variabili osservabili (i dati) e le variabili non osservabili (i parametri). Il modello generativo ci permette di simulare dati ipotetici e di fare previsioni su ciò che potremmo osservare in base a determinate ipotesi.</p>
<p>Ad esempio, nel contesto del lancio di una moneta, il modello generativo potrebbe essere basato sulla distribuzione binomiale, che descrive la probabilità di ottenere un certo numero di “teste” in un dato numero di lanci, assumendo una certa probabilità di successo (in questo caso, la probabilità di ottenere “testa”).</p>
</section><section id="parametri" class="level3" data-number="46.6.2"><h3 data-number="46.6.2" class="anchored" data-anchor-id="parametri">
<span class="header-section-number">46.6.2</span> Parametri</h3>
<p>Un <strong>parametro</strong> è una quantità sconosciuta che caratterizza il modello generativo. Nel caso del lancio della moneta, il parametro di interesse è la probabilità <span class="math inline">\(\theta\)</span> di ottenere “testa”. Questo parametro è ciò che vogliamo stimare o inferire attraverso l’osservazione dei dati. In generale, i parametri possono rappresentare diverse caratteristiche del processo generativo, come medie, varianze, coefficienti di regressione, ecc.</p>
</section><section id="applicazione-allesempio-del-lancio-della-moneta" class="level3" data-number="46.6.3"><h3 data-number="46.6.3" class="anchored" data-anchor-id="applicazione-allesempio-del-lancio-della-moneta">
<span class="header-section-number">46.6.3</span> Applicazione all’Esempio del Lancio della Moneta</h3>
<p>Ora che abbiamo introdotto i concetti di <strong>modello generativo dei dati</strong> e <strong>parametro</strong>, possiamo applicarli all’esempio del lancio della moneta. Immaginiamo di lanciare una moneta 10 volte e osservare 8 teste (<span class="math inline">\(y = 8\)</span>). Vogliamo stabilire se la moneta sia equilibrata (<span class="math inline">\(\theta = 0.5\)</span>) o meno.</p>
<p>Per rispondere a questa domanda, definiamo un <strong>modello generativo dei dati</strong> utilizzando la <strong>distribuzione binomiale</strong>, che è caratterizzata dal parametro <span class="math inline">\(\theta\)</span>, la probabilità di ottenere “testa”. La distribuzione binomiale descrive la probabilità di osservare un certo numero di successi (in questo caso, “teste”) in un numero fisso di prove indipendenti, assumendo un valore specifico per <span class="math inline">\(\theta\)</span>.</p>
<p>In questo contesto, il parametro <span class="math inline">\(\theta\)</span> è l’oggetto della nostra inferenza. Vogliamo aggiornare la nostra credenza iniziale su <span class="math inline">\(\theta\)</span> (ad esempio, che la moneta sia equilibrata, quindi <span class="math inline">\(\theta = 0.5\)</span>) alla luce dei nuovi dati osservati (8 teste su 10 lanci). Questo aggiornamento avviene attraverso l’applicazione del <strong>teorema di Bayes</strong>, che combina la nostra credenza a priori, descritta da una <strong>distribuzione a priori</strong> e indicata come <span class="math inline">\(p(\theta)\)</span>, con la <strong>verosimiglianza</strong> dei dati osservati per produrre una credenza a posteriori su <span class="math inline">\(\theta\)</span>, descritta dalla <strong>distribuzione a posteriori</strong> e denotata come <span class="math inline">\(p(\theta \mid \text{dati})\)</span>.</p>
<p>La distribuzione a priori, <span class="math inline">\(p(\theta)\)</span>, riflette ciò che riteniamo plausibile prima di osservare i dati. Quando raccogliamo nuove informazioni, rivediamo le nostre credenze, ridistribuendo la credibilità su tutto il range di valori possibili del parametro. Questo processo di aggiornamento produce la <strong>distribuzione a posteriori</strong>, <span class="math inline">\(p(\theta \mid \text{dati})\)</span>, che rappresenta la nostra credenza aggiornata <span class="citation" data-cites="gelman1995bayesian">(<a href="#ref-gelman1995bayesian" role="doc-biblioref">Gelman et al., 2013</a>)</span>.</p>
<p>Un aspetto filosofico e matematico distintivo dell’approccio bayesiano è la concezione del parametro d’interesse come una <strong>variabile casuale</strong> che può assumere valori differenti, anziché come un valore fisso (come avviene nel paradigma frequentista). Questa prospettiva permette di trattare il parametro come una distribuzione, fornendo una rappresentazione più flessibile delle incertezze <span class="citation" data-cites="doing_bayesian_data_an">(<a href="#ref-doing_bayesian_data_an" role="doc-biblioref">Kruschke, 2014</a>)</span>. Ad esempio, se tracciassimo la distribuzione a posteriori, l’asse <span class="math inline">\(x\)</span> rappresenterebbe l’intero intervallo di valori possibili per il parametro, mentre l’asse <span class="math inline">\(y\)</span> indicherebbe la densità di probabilità associata a ciascun valore. Il valore più credibile è spesso quello che massimizza la distribuzione (moda), o la sua media o mediana.</p>
</section><section id="approccio-classico-massima-verosimiglianza" class="level3" data-number="46.6.4"><h3 data-number="46.6.4" class="anchored" data-anchor-id="approccio-classico-massima-verosimiglianza">
<span class="header-section-number">46.6.4</span> Approccio Classico: Massima Verosimiglianza</h3>
<p>Nel contesto classico, uno dei metodi più utilizzati per stimare <span class="math inline">\(\theta\)</span> è la <strong>massima verosimiglianza</strong>, che stima <span class="math inline">\(\theta\)</span> come il rapporto tra successi e tentativi: <span class="math inline">\(\hat{\theta} = y/N = 0.8\)</span>. Sebbene semplice, questa stima puntuale non fornisce informazioni sull’incertezza di <span class="math inline">\(\theta\)</span> né sulla plausibilità di valori alternativi. In altre parole, non ci dice quanto sia plausibile che <span class="math inline">\(\theta\)</span> sia, ad esempio, 0.7 o 0.9, né quantifica l’incertezza associata alla stima.</p>
</section><section id="approccio-bayesiano-priori-e-posteriori" class="level3" data-number="46.6.5"><h3 data-number="46.6.5" class="anchored" data-anchor-id="approccio-bayesiano-priori-e-posteriori">
<span class="header-section-number">46.6.5</span> Approccio Bayesiano: Priori e Posteriori</h3>
<p>L’approccio bayesiano supera i limiti dell’approccio classico basato sulla massima verosimiglianza, offrendo un quadro più completo e flessibile per l’aggiornamento delle credenze. Questo risultato è reso possibile dal <strong>teorema di Bayes</strong>, che formalizza il processo di integrazione tra le informazioni iniziali (rappresentate dalla distribuzione a priori) e le nuove evidenze fornite dai dati osservati. Attraverso questo meccanismo, l’approccio bayesiano non solo fornisce stime puntuali, ma quantifica anche l’incertezza associata ai parametri, permettendo una valutazione più robusta e informata delle ipotesi.</p>
</section></section><section id="unintroduzione-ai-priori" class="level2" data-number="46.7"><h2 data-number="46.7" class="anchored" data-anchor-id="unintroduzione-ai-priori">
<span class="header-section-number">46.7</span> Un’introduzione ai Priori</h2>
<p>Ciò che distingue l’approccio bayesiano da quello basato sulla massima verosimiglianza è l’uso esplicito di <strong>credenze iniziali</strong> riguardo al fenomeno di interesse. Nel linguaggio bayesiano, queste credenze sono formalizzate come <strong>distribuzioni di probabilità</strong>, chiamate <strong>distribuzioni a priori</strong>. Le distribuzioni a priori rappresentano la nostra conoscenza o le nostre ipotesi su un parametro o un’ipotesi prima di osservare i dati. Esse forniscono un punto di partenza per l’inferenza, permettendo di incorporare informazioni pregresse nel processo di analisi.</p>
<p>A seconda del grado di conoscenza o incertezza che abbiamo prima di raccogliere i dati, le distribuzioni a priori possono assumere forme diverse. Questa variabilità riflette il livello di fiducia o informazione iniziale e influenza in modo significativo il modo in cui le nuove evidenze vengono integrate nel processo di aggiornamento bayesiano. La scelta della distribuzione a priori è quindi un aspetto cruciale, poiché determina come le credenze iniziali interagiscono con i dati osservati per produrre la distribuzione a posteriori, ovvero la nostra credenza aggiornata.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 35%">
<col style="width: 33%">
<col style="width: 11%">
<col style="width: 19%">
</colgroup>
<thead><tr class="header">
<th>Tipo di prior</th>
<th>Quando usarlo</th>
<th>Pro</th>
<th>Contro</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>
<strong>Non informativo</strong> (p.e. uniforme)</td>
<td>Ignoranza quasi totale</td>
<td>Semplice, “lascia parlare i dati”</td>
<td>Può ricalcare l’MLE, talvolta inappropriato</td>
</tr>
<tr class="even">
<td><strong>Debolmente informativo</strong></td>
<td>Conoscenza generale o vincoli di scala</td>
<td>Stabilizza stime, evita valori implausibili</td>
<td>Richiede riflessione; influenza modesta ma presente</td>
</tr>
<tr class="odd">
<td><strong>Informativo</strong></td>
<td>Meta-analisi, expertise, piccoli campioni</td>
<td>Riduce varianza, incorpora letteratura</td>
<td>Se eccessivo può dominare i dati</td>
</tr>
<tr class="even">
<td><strong>Coniugato</strong></td>
<td>Modelli classici (Binomiale-Beta, Normale-Normale)</td>
<td>Aggiornamento analitico, didattico</td>
<td>Limitato a poche famiglie</td>
</tr>
</tbody>
</table>
<p><strong>Buona pratica</strong>: effettuare un <em>prior predictive check</em> → simulare dati dalla prior, verificare che scenari impossibili (p.e. RT negativi) siano improbabili.</p>
</section><section id="quando-il-calcolo-si-complica-mcmc" class="level2" data-number="46.8"><h2 data-number="46.8" class="anchored" data-anchor-id="quando-il-calcolo-si-complica-mcmc">
<span class="header-section-number">46.8</span> Quando il calcolo si complica: MCMC</h2>
<p>Nell’equazione del teorema di Bayes:</p>
<p><span class="math display">\[
p(\theta \mid \text{dati}) = \frac{p(\theta) \cdot p(\text{dati} \mid \theta)}{p(\text{dati})},
\]</span></p>
<p>la <strong>costante di normalizzazione</strong>, indicata come <span class="math inline">\(p(\text{dati})\)</span>, rappresenta la probabilità complessiva di osservare i dati, indipendentemente dal valore specifico del parametro <span class="math inline">\(\theta\)</span>. Questo termine garantisce che la distribuzione a posteriori sia una distribuzione di probabilità valida, cioè che la somma (o l’integrale) delle probabilità sia uguale a 1. In altre parole, la costante di normalizzazione “aggiusta” la distribuzione risultante affinché sia coerente con le regole della probabilità.</p>
<p>Calcolare <span class="math inline">\(p(\text{dati})\)</span> può essere complesso, poiché per modelli non coniugati o ad alta dimensionalità la posteriore non ha forma chiusa.</p>
<section id="priori-coniugati" class="level3" data-number="46.8.1"><h3 data-number="46.8.1" class="anchored" data-anchor-id="priori-coniugati">
<span class="header-section-number">46.8.1</span> Priori Coniugati</h3>
<p>I <strong>priori coniugati</strong> sono una scelta specifica di distribuzione a priori che, quando combinata con una determinata verosimiglianza, produce una distribuzione a posteriori della stessa famiglia. Questa proprietà semplifica notevolmente i calcoli.</p>
<p><strong>Esempio</strong>: Se la verosimiglianza è binomiale e la distribuzione a priori è una Beta, la distribuzione a posteriori sarà ancora una Beta. Questo caso è particolarmente utile, ad esempio, quando si studia la probabilità di successo in una serie di prove (come il lancio di una moneta).</p>
<p><strong>Vantaggi dei Priori Coniugati</strong>:</p>
<ul>
<li>
<strong>Calcolo diretto</strong>: La distribuzione a posteriori può essere determinata analiticamente senza metodi numerici complessi.</li>
<li>
<strong>Efficienza computazionale</strong>: Ideale per modelli semplici e ben definiti.</li>
</ul>
<p><strong>Limitazioni</strong>:</p>
<ul>
<li>Applicabile solo a modelli specifici e semplici.</li>
<li>Non adatto a situazioni con dati complessi o modelli ad alta dimensionalità.</li>
</ul></section><section id="metodi-approssimativi" class="level3" data-number="46.8.2"><h3 data-number="46.8.2" class="anchored" data-anchor-id="metodi-approssimativi">
<span class="header-section-number">46.8.2</span> Metodi Approssimativi</h3>
<p>Quando i priori coniugati non sono applicabili o il modello è troppo complesso per soluzioni analitiche, si ricorre a metodi numerici approssimativi. Uno dei più utilizzati è il <strong>Markov-Chain Monte Carlo (MCMC)</strong>, una tecnica di campionamento casuale che permette di stimare la distribuzione a posteriori anche in casi complessi.</p>
<p><strong>Vantaggi dei Metodi Approssimativi</strong>:</p>
<ul>
<li>
<strong>Flessibilità</strong>: Possono gestire modelli complessi e dati reali con molte variabili.</li>
<li>
<strong>Precisione</strong>: Forniscono stime accurate della distribuzione a posteriori, anche in assenza di soluzioni analitiche.</li>
</ul>
<p><strong>Svantaggi</strong>:</p>
<ul>
<li>
<strong>Costo computazionale</strong>: Richiedono più tempo e risorse rispetto ai metodi analitici.</li>
<li>
<strong>Complessità implementativa</strong>: Possono richiedere una maggiore attenzione nella scelta dei parametri e nella validazione dei risultati.</li>
</ul>
<p>In sintesi, la scelta tra approccio analitico e numerico dipende dalla complessità del problema e dalle risorse disponibili. Mentre i priori coniugati e i metodi analitici sono ideali per modelli semplici, i metodi numerici come l’MCMC offrono la flessibilità necessaria per affrontare problemi più complessi. In ogni caso, l’obiettivo è sempre lo stesso: aggiornare le nostre credenze in modo rigoroso e sistematico, integrando nuove evidenze con le conoscenze pregresse.</p>
</section><section id="approfondimenti-sullmcmc-e-altri-metodi-numerici" class="level3" data-number="46.8.3"><h3 data-number="46.8.3" class="anchored" data-anchor-id="approfondimenti-sullmcmc-e-altri-metodi-numerici">
<span class="header-section-number">46.8.3</span> Approfondimenti sull’MCMC e Altri Metodi Numerici</h3>
<p>Quando i modelli diventano troppo complessi per essere risolti analiticamente, l’approccio bayesiano si affida a metodi numerici per approssimare la distribuzione a posteriori. Uno dei metodi più potenti e diffusi è il <strong>Markov-Chain Monte Carlo (MCMC)</strong>, che permette di campionare dalla distribuzione a posteriori anche in assenza di soluzioni esatte. Questo metodo è particolarmente utile quando i priori coniugati non sono applicabili o quando il modello coinvolge molte variabili e parametri.</p>
<section id="cosè-lmcmc" class="level4" data-number="46.8.3.1"><h4 data-number="46.8.3.1" class="anchored" data-anchor-id="cosè-lmcmc">
<span class="header-section-number">46.8.3.1</span> Cos’è l’MCMC?</h4>
<p>L’MCMC è una famiglia di algoritmi che generano una sequenza di campioni (una “catena”) dalla distribuzione a posteriori. Ogni campione rappresenta un possibile valore del parametro di interesse, e i campioni successivi dipendono dai precedenti, come i collegamenti di una catena. Con un numero sufficiente di iterazioni, questa catena converge alla distribuzione a posteriori, permettendo di stimarne forma, centro e variabilità.</p>
<p><strong>Come funziona l’MCMC?</strong></p>
<ul>
<li>
<strong>Metropolis-Hastings</strong>: Questo algoritmo è adatto a distribuzioni generiche. Richiede la definizione di una “funzione proposta” che suggerisce nuovi valori per il parametro, che vengono poi accettati o rifiutati in base a una regola probabilistica.</li>
<li>
<strong>Gibbs Sampling</strong>: Questo metodo è particolarmente efficace quando le distribuzioni condizionali dei parametri sono note, anche se la distribuzione congiunta è complessa. In pratica, si campiona iterativamente da ciascuna distribuzione condizionale, aggiornando un parametro alla volta.</li>
</ul>
<p><strong>Pratiche comuni in MCMC</strong>:</p>
<ul>
<li>
<strong>Warm-up (o burn-in)</strong>: All’inizio dell’algoritmo, i campioni vengono scartati per permettere alla catena di stabilizzarsi e raggiungere la distribuzione target. Questa fase è cruciale per evitare che i campioni iniziali, spesso non rappresentativi, influenzino i risultati.</li>
<li>
<strong>Thinning</strong>: Per ridurre l’autocorrelazione tra i campioni, si seleziona solo uno ogni <em>n</em> campioni (ad esempio, ogni 5° campione). Questo migliora l’efficienza e l’indipendenza dei campioni utilizzati per l’analisi.</li>
</ul></section><section id="altri-metodi-numerici" class="level4" data-number="46.8.3.2"><h4 data-number="46.8.3.2" class="anchored" data-anchor-id="altri-metodi-numerici">
<span class="header-section-number">46.8.3.2</span> Altri Metodi Numerici</h4>
<p>Oltre all’MCMC, esistono altri metodi numerici per approssimare la distribuzione a posteriori, ciascuno con i propri vantaggi e svantaggi:</p>
<ul>
<li>
<strong>Variational Bayes</strong>: Questo approccio approssima la distribuzione a posteriori risolvendo un problema di ottimizzazione, minimizzando la divergenza di Kullback-Leibler tra una distribuzione proposta <span class="math inline">\(q(z)\)</span> e la distribuzione reale <span class="math inline">\(p(z \mid x)\)</span>. È più veloce dell’MCMC ma meno preciso, soprattutto per distribuzioni complesse.</li>
<li>
<strong>Approssimazione di Laplace</strong>: Questo metodo semplifica la distribuzione a posteriori approssimandola con una distribuzione normale centrata sul valore MAP (Maximum A Posteriori). È utile per modelli semplici ma meno accurato per distribuzioni non gaussiane.</li>
</ul>
<p><strong>Vantaggi e Svantaggi degli Approcci Numerici</strong>:</p>
<ul>
<li>
<strong>Vantaggi</strong>:
<ul>
<li>Applicabilità a modelli complessi e ad alta dimensionalità.</li>
<li>Flessibilità nell’incorporare informazioni a priori dettagliate.</li>
</ul>
</li>
<li>
<strong>Svantaggi</strong>:
<ul>
<li>Richiedono risorse computazionali elevate.</li>
<li>Necessitano di un tuning accurato degli algoritmi (ad esempio, scelte iniziali in MCMC).</li>
</ul>
</li>
</ul></section></section><section id="linguaggi-di-programmazione-probabilistica-ppl" class="level3" data-number="46.8.4"><h3 data-number="46.8.4" class="anchored" data-anchor-id="linguaggi-di-programmazione-probabilistica-ppl">
<span class="header-section-number">46.8.4</span> Linguaggi di Programmazione Probabilistica (PPL)</h3>
<p>Per semplificare l’implementazione dei metodi numerici, sono stati sviluppati <strong>linguaggi di programmazione probabilistica (PPL)</strong>. Questi strumenti automatizzano il processo di inferenza bayesiana, permettendo ai ricercatori di concentrarsi sulla modellizzazione mentre il PPL gestisce l’inferenza sottostante.</p>
<section id="ppl-più-diffusi" class="level4" data-number="46.8.4.1"><h4 data-number="46.8.4.1" class="anchored" data-anchor-id="ppl-più-diffusi">
<span class="header-section-number">46.8.4.1</span> PPL più Diffusi</h4>
<ul>
<li>
<strong>Stan</strong>: Un linguaggio efficiente e flessibile, ampiamente utilizzato in ambito accademico per la sua capacità di gestire modelli complessi.</li>
<li>
<strong>PyMC</strong>: Una libreria user-friendly per Python, ideale per chi preferisce un approccio più accessibile.</li>
<li>
<strong>TensorFlow Probability</strong>: Combina modellizzazione probabilistica e apprendimento automatico, offrendo strumenti avanzati per l’inferenza bayesiana.</li>
</ul>
<p>I PPL consentono di definire il modello probabilistico in modo intuitivo e delegare l’inferenza agli algoritmi numerici sottostanti, come MCMC o inferenza variazionale. Questo rende l’inferenza bayesiana più accessibile e applicabile a una vasta gamma di problemi, inclusi quelli in psicologia, biologia, economia e scienze sociali.</p>
</section></section><section id="notazione-nei-modelli-bayesiani" class="level3" data-number="46.8.5"><h3 data-number="46.8.5" class="anchored" data-anchor-id="notazione-nei-modelli-bayesiani">
<span class="header-section-number">46.8.5</span> Notazione nei Modelli Bayesiani</h3>
<p>Nella formulazione dei modelli bayesiani, è comune utilizzare una notazione standard per descrivere le relazioni tra dati, parametri e distribuzioni. Ecco un esempio di come viene strutturata un’equazione bayesiana:</p>
<ul>
<li>
<strong><span class="math inline">\(y\)</span></strong>: Dati osservati.</li>
<li>
<strong><span class="math inline">\(\theta\)</span></strong>: Parametri sconosciuti.</li>
<li>
<strong><span class="math inline">\(x\)</span></strong>: Quantità note (ad esempio, predittori o variabili esplicative).</li>
</ul>
<p><strong>Esempio di Modello</strong>: Supponiamo di voler modellare un insieme di dati <span class="math inline">\(y\)</span> come provenienti da una distribuzione normale con media <span class="math inline">\(\mu\)</span> e deviazione standard <span class="math inline">\(\sigma\)</span>. Le distribuzioni a priori per <span class="math inline">\(\mu\)</span> e <span class="math inline">\(\sigma\)</span> potrebbero essere specificate come segue:</p>
<p><span class="math display">\[
\begin{aligned}
y &amp; \sim \mathrm{normal}(\mu, \sigma), \\
\mu &amp; \sim \mathrm{normal}(0, 10), \\
\sigma &amp; \sim \mathrm{normal}^+(\sigma \mid 0, 1),
\end{aligned}
\]</span></p>
<p>dove il simbolo <span class="math inline">\(\sim\)</span> indica <em>“è distribuito come”</em>. La stessa espressione può essere scritta in termini di probabilità:</p>
<p><span class="math display">\[
\begin{aligned}
p(y \mid \mu, \sigma) &amp; = \mathrm{normal}(y \mid \mu, \sigma), \\
p(\mu) &amp; = \mathrm{normal}(\mu \mid 0, 10), \\
p(\sigma) &amp; = \mathrm{normal}^+(\sigma \mid 0, 1).
\end{aligned}
\]</span></p>
<p>Questa notazione chiarisce come i dati e i parametri siano collegati attraverso distribuzioni di probabilità, fornendo un quadro completo per l’inferenza bayesiana.</p>
</section></section><section id="riflessioni-conclusive" class="level2" data-number="46.9"><h2 data-number="46.9" class="anchored" data-anchor-id="riflessioni-conclusive">
<span class="header-section-number">46.9</span> Riflessioni Conclusive</h2>
<p>L’inferenza bayesiana è un approccio potente e versatile per aggiornare le nostre credenze alla luce di nuove evidenze. La sua peculiarità risiede nella capacità di rispondere a una domanda fondamentale per la ricerca scientifica: <strong>qual è la probabilità dei parametri (o delle ipotesi) dati i dati osservati?</strong> Questo concetto, noto come <strong>probabilità inversa</strong>, è il cuore dell’approccio bayesiano e lo distingue dall’inferenza frequentista, che si concentra invece sulla probabilità dei dati condizionata ai parametri.</p>
<p>Il <strong>teorema di Bayes</strong> formalizza questa intuizione, permettendoci di calcolare la distribuzione a posteriori <span class="math inline">\(p(\theta \mid D)\)</span>, che rappresenta la nostra credenza aggiornata sui parametri <span class="math inline">\(\theta\)</span> dopo aver osservato i dati <span class="math inline">\(D\)</span>:</p>
<p><span class="math display">\[
p(\theta \mid D) = \frac{p(D \mid \theta) \cdot p(\theta)}{p(D)}.
\]</span></p>
<p>Questa equazione mostra come, partendo da un <strong>modello generativo</strong> <span class="math inline">\(p(D \mid \theta)\)</span> dei dati osservati e combinando questo con una distribuzione a priori <span class="math inline">\(p(\theta)\)</span>, sia possibile inferire la distribuzione a posteriori <span class="math inline">\(p(\theta \mid D)\)</span>. Questo processo di aggiornamento consente di integrare in modo rigoroso e sistematico nuove evidenze con conoscenze pregresse.</p>
<p>Una stima puntuale comunemente utilizzata nell’inferenza bayesiana è il <strong>Massimo A Posteriori (MAP)</strong>, ovvero il valore di <span class="math inline">\(\theta\)</span> che massimizza la distribuzione a posteriori:</p>
<p><span class="math display">\[
\theta^* = \arg \max_\theta p(\theta \mid D).
\]</span></p>
<p>Nel caso di un <strong>prior non informativo</strong> (una distribuzione a priori piatta), la stima MAP coincide con la stima di <strong>massima verosimiglianza</strong> (MLE), che massimizza la probabilità dei dati osservati. Tuttavia, in presenza di informazioni a priori rilevanti e ben specificate, la stima MAP combina i dati osservati con le credenze iniziali, fornendo una stima più robusta e informata.</p>
<p>La forza dell’approccio bayesiano risiede nella sua capacità di affrontare diverse sfide:</p>
<ul>
<li>
<strong>Incertezza delle ipotesi</strong>: In contesti come la psicologia, la medicina o le scienze sociali, dove le ipotesi sono spesso incerte, l’inferenza bayesiana permette di valutarne la plausibilità.</li>
<li>
<strong>Dati limitati o rumorosi</strong>: Quando i dati sono scarsi o affetti da rumore, l’approccio bayesiano garantisce stime più robuste integrando informazioni a priori.</li>
<li>
<strong>Confronto tra ipotesi complesse</strong>: L’approccio bayesiano consente di confrontare e valutare ipotesi multiple in modo rigoroso.</li>
</ul>
<p>Il teorema di Bayes offre un quadro formale per quantificare l’incertezza e aggiornare le credenze in modo dinamico. Questo è particolarmente utile in situazioni in cui:</p>
<ul>
<li>Le informazioni a priori sono cruciali per guidare l’inferenza.</li>
<li>È necessario un compromesso tra conoscenze pregresse e nuove evidenze.</li>
<li>I problemi analizzati sono complessi e richiedono strumenti avanzati.</li>
</ul>
<p>Per modelli semplici, i <strong>priori coniugati</strong> e i metodi analitici possono essere sufficienti. Tuttavia, per problemi più complessi, l’uso di strumenti numerici come l’<strong>MCMC</strong> (Markov Chain Monte Carlo) e i <strong>linguaggi di programmazione probabilistica</strong> (PPL) è indispensabile. Questi strumenti consentono di applicare l’approccio bayesiano a scenari realistici, superando le limitazioni computazionali e garantendo maggiore flessibilità.</p>
<p>In conclusione, l’inferenza bayesiana non è solo un metodo statistico, ma un paradigma che trasforma il modo di pensare alla scienza e alla conoscenza. Essa permette di formulare domande scientificamente rilevanti, di quantificare l’incertezza e di aggiornare le credenze in modo rigoroso. Attraverso il teorema di Bayes, possiamo passare dalla domanda “qual è la probabilità dei dati dati i parametri?” alla domanda più interessante: <strong>“qual è la probabilità dei parametri dati i dati?”</strong></p>
<p>Questa inversione di prospettiva, unita agli strumenti computazionali moderni, rende l’approccio bayesiano uno strumento indispensabile per la ricerca scientifica contemporanea. In un’epoca caratterizzata da dati complessi e incertezze diffuse, il paradigma bayesiano si pone come una guida affidabile per comprendere meglio il mondo attraverso l’analisi rigorosa e l’aggiornamento continuo delle nostre credenze.</p>
</section><section id="esercizi" class="level2 unnumbered"><h2 class="unnumbered anchored" data-anchor-id="esercizi">Esercizi</h2>
<div class="callout callout-style-simple callout-important no-icon callout-titled" title="Problemi">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Problemi
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li><p>Qual è la differenza principale tra l’approccio bayesiano e l’approccio frequentista all’inferenza statistica?</p></li>
<li><p>Cosa rappresenta la distribuzione <em>a priori</em> in inferenza bayesiana e quale ruolo svolge nel processo inferenziale?</p></li>
<li><p>Come si calcola la distribuzione <em>a posteriori</em> in inferenza bayesiana e quali sono i suoi elementi principali?</p></li>
<li><p>Qual è il significato della funzione di verosimiglianza nel teorema di Bayes?</p></li>
<li><p>Come viene interpretata la probabilità nell’approccio bayesiano rispetto a quello frequentista?</p></li>
<li><p>Quali sono i vantaggi principali dell’inferenza bayesiana rispetto all’inferenza frequentista?</p></li>
<li><p>Cos’è una distribuzione <em>a priori</em> coniugata e quali vantaggi offre nel calcolo della distribuzione <em>a posteriori</em>?</p></li>
<li><p>Quali sono i principali metodi numerici utilizzati per approssimare la distribuzione <em>a posteriori</em> quando i calcoli analitici non sono possibili?</p></li>
<li><p>Cosa sono i modelli generativi dei dati e quale ruolo svolgono nell’inferenza bayesiana?</p></li>
<li><p>Quali sono le tre principali giustificazioni teoriche per l’uso delle probabilità come misura di credenza nell’inferenza bayesiana?</p></li>
</ol>
<p><strong>Consegna:</strong> Rispondi con parole tue e carica il file .qmd, convertito in PDF su Moodle.</p>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-tip no-icon callout-titled" title="Soluzioni">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Soluzioni
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li><p>La differenza principale tra l’approccio bayesiano e quello frequentista riguarda l’interpretazione del parametro <span class="math inline">\(\theta\)</span>. Nell’approccio bayesiano, il parametro è considerato una variabile aleatoria con una distribuzione <em>a priori</em>, mentre nell’approccio frequentista il parametro è una quantità fissa e sconosciuta. Inoltre, l’inferenza bayesiana aggiorna le credenze attraverso il teorema di Bayes, mentre l’inferenza frequentista basa le proprie conclusioni solo sui dati osservati.</p></li>
<li><p>La distribuzione <em>a priori</em> rappresenta le credenze iniziali riguardo al parametro <span class="math inline">\(\theta\)</span> prima di osservare i dati. Essa consente di integrare informazioni pregresse o conoscenze esterne nel processo inferenziale, influenzando la distribuzione <em>a posteriori</em> e permettendo di aggiornare le credenze alla luce di nuove evidenze.</p></li>
<li>
<p>La distribuzione <em>a posteriori</em> si calcola applicando il teorema di Bayes:</p>
<p><span class="math display">\[
f(\theta \mid x) = \frac{f(x \mid \theta) f(\theta)}{f(x)}
\]</span></p>
<p>I suoi elementi principali sono:</p>
<ul>
<li>La <strong>funzione di verosimiglianza</strong> <span class="math inline">\(f(x \mid \theta)\)</span>, che esprime la probabilità di osservare i dati dato un valore del parametro.<br>
</li>
<li>La <strong>distribuzione <em>a priori</em></strong> <span class="math inline">\(f(\theta)\)</span>, che rappresenta le credenze iniziali sul parametro.<br>
</li>
<li>La <strong>costante di normalizzazione</strong> <span class="math inline">\(f(x)\)</span>, che garantisce che la distribuzione <em>a posteriori</em> sia una distribuzione di probabilità valida.</li>
</ul>
</li>
<li><p>La funzione di verosimiglianza, <span class="math inline">\(f(x \mid \theta)\)</span>, rappresenta la probabilità di osservare i dati dati i valori del parametro <span class="math inline">\(\theta\)</span>. Essa è fondamentale nel teorema di Bayes perché determina quanto bene un certo valore di <span class="math inline">\(\theta\)</span> spiega i dati osservati, contribuendo alla determinazione della distribuzione <em>a posteriori</em>.</p></li>
<li><p>Nell’approccio bayesiano, la probabilità è interpretata come un grado di credenza soggettivo su un evento o un parametro incerto. Nell’approccio frequentista, invece, la probabilità è definita come il limite della frequenza relativa di un evento dopo un numero infinito di ripetizioni. Questo porta a differenze metodologiche nel modo in cui vengono effettuate le inferenze.</p></li>
<li>
<p>I principali vantaggi dell’inferenza bayesiana sono:</p>
<ul>
<li>
<strong>Integrazione di informazioni pregresse</strong>: Permette di combinare dati osservati con conoscenze precedenti.<br>
</li>
<li>
<strong>Quantificazione dell’incertezza</strong>: Fornisce una distribuzione completa dei parametri, anziché un singolo valore stimato.<br>
</li>
<li>
<strong>Flessibilità</strong>: Può essere applicata a modelli complessi e a problemi con pochi dati.<br>
</li>
<li>
<strong>Interpretazione intuitiva</strong>: Le probabilità risultanti rappresentano direttamente il grado di credenza sui parametri.</li>
</ul>
</li>
<li><p>Una distribuzione <em>a priori</em> coniugata è una scelta specifica di distribuzione <em>a priori</em> che, quando combinata con una verosimiglianza di una certa famiglia, produce una distribuzione <em>a posteriori</em> della stessa famiglia. Ad esempio, una distribuzione Beta come prior per un parametro binomiale produce una distribuzione Beta come <em>a posteriori</em>. Questo semplifica enormemente i calcoli, poiché la distribuzione <em>a posteriori</em> può essere determinata in modo analitico senza necessità di metodi numerici complessi.</p></li>
<li>
<p>Quando non è possibile calcolare la distribuzione <em>a posteriori</em> in modo analitico, si utilizzano metodi numerici come:</p>
<ul>
<li>
<strong>Markov Chain Monte Carlo (MCMC)</strong>: Un insieme di algoritmi di campionamento (ad esempio, Metropolis-Hastings e Gibbs Sampling) che permette di stimare la distribuzione <em>a posteriori</em> generando campioni iterativi.<br>
</li>
<li>
<strong>Inferenza Variazionale</strong>: Un metodo di approssimazione che ottimizza una distribuzione più semplice per avvicinarsi alla distribuzione <em>a posteriori</em>.<br>
</li>
<li>
<strong>Approssimazione di Laplace</strong>: Un’approssimazione basata sulla normalizzazione locale intorno al massimo <em>a posteriori</em> (MAP).</li>
</ul>
</li>
<li><p>Un modello generativo dei dati è una rappresentazione matematica del processo che ha generato i dati osservati. Esso definisce la relazione tra il parametro sconosciuto <span class="math inline">\(\theta\)</span> e i dati <span class="math inline">\(\mathbf{x}\)</span> attraverso una distribuzione di probabilità. Nell’inferenza bayesiana, il modello generativo aiuta a formulare la funzione di verosimiglianza e a inferire i parametri che meglio spiegano i dati.</p></li>
<li><p>Le tre principali giustificazioni per l’uso delle probabilità come misura di credenza nell’inferenza bayesiana sono:</p></li>
</ol>
<ul>
<li>
<strong>Argomento della scommessa olandese (Dutch Book)</strong>: Se i gradi di credenza non rispettano le regole della probabilità, si possono costruire scommesse che garantiscono una perdita certa, dimostrando che è irrazionale non seguire le leggi della probabilità.<br>
</li>
<li>
<strong>Argomento decisionistico</strong>: Per massimizzare l’utilità attesa nelle scelte razionali, i gradi di credenza devono seguire le regole della probabilità. Se non lo fanno, si possono prendere decisioni incoerenti o subottimali.<br>
</li>
<li>
<strong>Argomento epistemico</strong>: Le funzioni di probabilità minimizzano l’errore epistemico rispetto alla verità oggettiva, rendendole la struttura più razionale per rappresentare le credenze in condizioni di incertezza.</li>
</ul>
</div>
</div>
</div>
</section><section id="informazioni-sullambiente-di-sviluppo" class="level2 unnumbered"><h2 class="unnumbered anchored" data-anchor-id="informazioni-sullambiente-di-sviluppo">Informazioni sull’Ambiente di Sviluppo</h2>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/sessionInfo.html">sessionInfo</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">#&gt; R version 4.5.0 (2025-04-11)</span></span>
<span><span class="co">#&gt; Platform: aarch64-apple-darwin20</span></span>
<span><span class="co">#&gt; Running under: macOS Sequoia 15.5</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Matrix products: default</span></span>
<span><span class="co">#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib </span></span>
<span><span class="co">#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; locale:</span></span>
<span><span class="co">#&gt; [1] C/UTF-8/C/C/C/C</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; time zone: Europe/Rome</span></span>
<span><span class="co">#&gt; tzcode source: internal</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; attached base packages:</span></span>
<span><span class="co">#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; other attached packages:</span></span>
<span><span class="co">#&gt;  [1] thematic_0.1.7   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      </span></span>
<span><span class="co">#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.13.0 psych_2.5.3     </span></span>
<span><span class="co">#&gt;  [9] scales_1.4.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 </span></span>
<span><span class="co">#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     </span></span>
<span><span class="co">#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.3.0     ggplot2_3.5.2   </span></span>
<span><span class="co">#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; loaded via a namespace (and not attached):</span></span>
<span><span class="co">#&gt;  [1] generics_0.1.4     stringi_1.8.7      lattice_0.22-7    </span></span>
<span><span class="co">#&gt;  [4] hms_1.1.3          digest_0.6.37      magrittr_2.0.3    </span></span>
<span><span class="co">#&gt;  [7] evaluate_1.0.4     grid_4.5.0         timechange_0.3.0  </span></span>
<span><span class="co">#&gt; [10] RColorBrewer_1.1-3 fastmap_1.2.0      rprojroot_2.0.4   </span></span>
<span><span class="co">#&gt; [13] jsonlite_2.0.0     mnormt_2.1.1       cli_3.6.5         </span></span>
<span><span class="co">#&gt; [16] rlang_1.1.6        withr_3.0.2        tools_4.5.0       </span></span>
<span><span class="co">#&gt; [19] parallel_4.5.0     tzdb_0.5.0         pacman_0.5.1      </span></span>
<span><span class="co">#&gt; [22] vctrs_0.6.5        R6_2.6.1           lifecycle_1.0.4   </span></span>
<span><span class="co">#&gt; [25] htmlwidgets_1.6.4  pkgconfig_2.0.3    pillar_1.10.2     </span></span>
<span><span class="co">#&gt; [28] gtable_0.3.6       glue_1.8.0         xfun_0.52         </span></span>
<span><span class="co">#&gt; [31] tidyselect_1.2.1   rstudioapi_0.17.1  farver_2.1.2      </span></span>
<span><span class="co">#&gt; [34] htmltools_0.5.8.1  nlme_3.1-168       rmarkdown_2.29    </span></span>
<span><span class="co">#&gt; [37] compiler_4.5.0</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section><section id="bibliografia" class="level2 unnumbered"><h2 class="unnumbered anchored" data-anchor-id="bibliografia">Bibliografia</h2>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2" role="list">
<div id="ref-alter2025navigating" class="csl-entry" role="listitem">
Alter, U., Too, M. A., &amp; Cribbie, R. A. (2025). Navigating the Bayes maze: The psychologist’s guide to Bayesian statistics, a hands-on tutorial with R code. <em>International Journal of Psychology</em>, <em>60</em>(1), e13271.
</div>
<div id="ref-gelman1995bayesian" class="csl-entry" role="listitem">
Gelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., &amp; Rubin, D. B. (2013). <em>Bayesian Data Analysis</em> (3rd ed.). Chapman; Hall/CRC.
</div>
<div id="ref-gimenez2025ten" class="csl-entry" role="listitem">
Gimenez, O., Royle, A., Kéry, M., &amp; Nater, C. R. (2025). Ten quick tips to get you started with Bayesian statistics. <em>PLOS Computational Biology</em>, <em>21</em>(4), e1012898.
</div>
<div id="ref-Johnson2022bayesrules" class="csl-entry" role="listitem">
Johnson, A. A., Ott, M., &amp; Dogucu, M. (2022). <em><span>Bayes Rules! An Introduction to Bayesian Modeling with R</span></em>. CRC Press.
</div>
<div id="ref-doing_bayesian_data_an" class="csl-entry" role="listitem">
Kruschke, J. (2014). <em>Doing Bayesian data analysis: <span>A</span> tutorial with <span>R</span>, JAGS, and <span>Stan</span></em>. Academic Press.
</div>
</div>
</section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copiato!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copiato!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/ccaudek\.github\.io\/psicometria-r\/intro\.html");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
            // default icon
            link.classList.add("external");
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="../../chapters/bayesian_inference/03_statistical_models.html" class="pagination-link" aria-label="Modelli statistici">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">45</span>&nbsp; <span class="chapter-title">Modelli statistici</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../chapters/bayesian_inference/05_subj_prop.html" class="pagination-link" aria-label="Aggiornare le credenze su un parametro: dal prior alla posterior">
        <span class="nav-page-text"><span class="chapter-number">47</span>&nbsp; <span class="chapter-title">Aggiornare le credenze su un parametro: dal prior alla posterior</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer"><div class="nav-footer">
    <div class="nav-footer-left">
<p><strong>Psicometria</strong> è una risorsa didattica creata per il corso di Scienze e Tecniche Psicologiche dell’Università degli Studi di Firenze.</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/ccaudek/psicometria-r/blob/main/chapters/bayesian_inference/04_bayesian_inference.qmd" class="toc-action"><i class="bi bi-github"></i>Mostra il codice</a></li><li><a href="https://github.com/ccaudek/psicometria-r/issues/new" class="toc-action"><i class="bi empty"></i>Segnala un problema</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>Realizzato con <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>


</body></html>