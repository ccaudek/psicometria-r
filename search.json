[
  {
    "objectID": "chapters/eda/02_data_cleaning.html",
    "href": "chapters/eda/02_data_cleaning.html",
    "title": "15¬† Flusso di lavoro per la pulizia dei dati",
    "section": "",
    "text": "15.1 Introduzione\nNonostante la fase pi√π interessante di un progetto di analisi dei dati sia quella in cui si riesce a rispondere alla domanda che ha dato avvio all‚Äôindagine, gran parte del tempo di un analista √® in realt√† dedicata a una fase preliminare: la pulizia e il preprocessing dei dati, operazioni che vengono svolte ancor prima dell‚Äôanalisi esplorativa.\nIn questo capitolo, esamineremo un caso concreto di data cleaning e preprocessing, seguendo il tutorial di Crystal Lewis. Il problema viene presentato come segue:\nCrystal Lewis elenca i seguenti passaggi da seguire nel processo di data cleaning:\nSebbene l‚Äôordine di questi passaggi sia flessibile e possa essere adattato alle esigenze specifiche, c‚Äô√® un passaggio che non dovrebbe mai essere saltato: il primo, ovvero la revisione dei dati. Senza una revisione preliminare, l‚Äôanalista rischia di sprecare ore a pulire i dati per poi scoprire che mancano dei partecipanti, che i dati non sono organizzati come previsto o, peggio ancora, che si sta lavorando con i dati sbagliati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#introduzione",
    "href": "chapters/eda/02_data_cleaning.html#introduzione",
    "title": "15¬† Flusso di lavoro per la pulizia dei dati",
    "section": "",
    "text": "I am managing data for a longitudinal randomized controlled trial (RCT) study. For this RCT, schools are randomized to either a treatment or control group. Students who are in a treatment school receive a program to boost their math self-efficacy. Data is collected on all students in two waves (wave 1 is in the fall of a school year, and wave 2 is collected in the spring). At this point in time, we have collected wave 1 of our student survey on a paper form and we set up a data entry database for staff to enter the information into. Data has been double-entered, checked for entry errors, and has been exported in a csv format (‚Äúw1_mathproj_stu_svy_raw.csv‚Äù) to a folder (called ‚Äúdata‚Äù) where it is waiting to be cleaned.\n\n\n\nRevisione dei dati.\nRegolazione del numero di casi.\nDe-identificazione dei dati.\nEliminazione delle colonne irrilevanti.\nDivisione delle colonne, se necessario.\nRidenominazione delle variabili.\nTrasformazione/normalizzazione delle variabili.\nStandardizzazione delle variabili.\nAggiornamento dei tipi di variabili, se necessario.\nRicodifica delle variabili.\nCreazione di eventuali variabili necessarie.\nGestione dei valori mancanti, se necessario.\nAggiunta di metadati, se necessario.\nValidazione dei dati.\nFusione e/o unione dei dati, se necessario.\nTrasformazione dei dati, se necessario.\nSalvataggio dei dati puliti.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#tutorial",
    "href": "chapters/eda/02_data_cleaning.html#tutorial",
    "title": "15¬† Flusso di lavoro per la pulizia dei dati",
    "section": "15.2 Tutorial",
    "text": "15.2 Tutorial\nQuesto tutorial segue i passaggi descritti da Crystal Lewis per illustrare le buone pratiche nella gestione e pulizia dei dati.\n\n15.2.1 Organizzazione dei Dati\nUn principio fondamentale nella gestione dei dati √® preservare l‚Äôintegrit√† dei dati grezzi. I dati originali non devono mai essere modificati direttamente. √à quindi consigliabile strutturare i dati in una directory denominata data, suddivisa in due sottocartelle:\n\nraw: contiene i dati originali, mantenuti inalterati.\n\nprocessed: destinata ai dati ripuliti e preprocessati.\n\nAd esempio, importiamo i dati da un file denominato w1_mathproj_stu_svy_raw.csv per avviare il processo di pulizia. Tutte le operazioni dovranno essere effettuate utilizzando percorsi relativi alla home directory del progetto, che definiremo come primo passo.\n\n\n15.2.2 Passaggi del Tutorial\n\n15.2.2.1 Importare e Esaminare i Dati\nImportiamo i dati utilizzando la funzione import() della libreria rio e visualizziamo i primi valori di ciascuna colonna per verificarne la corretta importazione:\n\n# Importa i dati\nsvy &lt;- rio::import(here::here(\"data\", \"w1_mathproj_stu_svy_raw.csv\"))\n\n# Esamina la struttura del dataset\nglimpse(svy)\n#&gt; Rows: 6\n#&gt; Columns: 7\n#&gt; $ stu_id      &lt;int&gt; 1347, 1368, 1377, 1387, 1347, 1399\n#&gt; $ svy_date    &lt;IDate&gt; 2023-02-13, 2023-02-13, 2023-02-13, 2023-02-13, 2023-0‚Ä¶\n#&gt; $ grade_level &lt;int&gt; 9, 10, 9, 11, 9, 12\n#&gt; $ math1       &lt;int&gt; 2, 3, 4, 3, 2, 4\n#&gt; $ math2       &lt;chr&gt; \"1\", \"2\", \"\\n4\", \"3\", \"2\", \"1\"\n#&gt; $ math3       &lt;int&gt; 3, 2, 4, NA, 4, 3\n#&gt; $ math4       &lt;int&gt; 3, 2, 4, NA, 2, 1\n\nPer controllare visivamente i dati, possiamo esaminare le prime e le ultime righe del data frame:\n\n# Visualizza le prime righe\nsvy |&gt; \n  head()\n#&gt;   stu_id   svy_date grade_level math1 math2 math3 math4\n#&gt; 1   1347 2023-02-13           9     2     1     3     3\n#&gt; 2   1368 2023-02-13          10     3     2     2     2\n#&gt; 3   1377 2023-02-13           9     4   \\n4     4     4\n#&gt; 4   1387 2023-02-13          11     3     3    NA    NA\n#&gt; 5   1347 2023-02-14           9     2     2     4     2\n#&gt; 6   1399 2023-02-14          12     4     1     3     1\n\n# Visualizza le ultime righe\nsvy |&gt; \n  tail()\n#&gt;   stu_id   svy_date grade_level math1 math2 math3 math4\n#&gt; 1   1347 2023-02-13           9     2     1     3     3\n#&gt; 2   1368 2023-02-13          10     3     2     2     2\n#&gt; 3   1377 2023-02-13           9     4   \\n4     4     4\n#&gt; 4   1387 2023-02-13          11     3     3    NA    NA\n#&gt; 5   1347 2023-02-14           9     2     2     4     2\n#&gt; 6   1399 2023-02-14          12     4     1     3     1\n\n\n\n15.2.2.2 Individuare e Rimuovere i Duplicati\nIn questa fase, eseguiamo alcune modifiche necessarie al data frame, come rimuovere duplicati e ordinare i dati:\n\nVerifica duplicati: controlliamo i record duplicati nel dataset.\nRimuovi duplicati: manteniamo solo la prima occorrenza.\nOrdina per data: organizziamo i record in ordine crescente rispetto alla variabile svy_date.\nEsamina i dati puliti: controlliamo il risultato delle modifiche.\n\n\n# Identifica i duplicati basati su 'stu_id'\nduplicates &lt;- \n  svy[duplicated(svy$stu_id) | duplicated(svy$stu_id, fromLast = TRUE), ]\n\n\n# Visualizza i duplicati trovati\nduplicates\n#&gt;   stu_id   svy_date grade_level math1 math2 math3 math4\n#&gt; 1   1347 2023-02-13           9     2     1     3     3\n#&gt; 5   1347 2023-02-14           9     2     2     4     2\n\n\n# Ordina per 'svy_date' in ordine crescente\nsvy &lt;- svy[order(svy$svy_date), ]\n\n\n# Rimuove i duplicati mantenendo la prima occorrenza\nsvy &lt;- svy[!duplicated(svy$stu_id), ]\n\n\n# Esamina il dataset finale\nprint(svy)\n#&gt;   stu_id   svy_date grade_level math1 math2 math3 math4\n#&gt; 1   1347 2023-02-13           9     2     1     3     3\n#&gt; 2   1368 2023-02-13          10     3     2     2     2\n#&gt; 3   1377 2023-02-13           9     4   \\n4     4     4\n#&gt; 4   1387 2023-02-13          11     3     3    NA    NA\n#&gt; 6   1399 2023-02-14          12     4     1     3     1\n\nVerifichiamo le dimensioni del dataset pulito per assicurarci che le operazioni siano state eseguite correttamente:\n\n# Controlla il numero di righe e colonne\nsvy |&gt; \n  dim()\n#&gt; [1] 5 7\n\n\n\n15.2.2.3 De-identificazione dei Dati\n\n# Rimuovi la colonna 'svy_date'\nsvy &lt;- svy |&gt;\n  dplyr::select(-svy_date)\n\n# Mostra i nomi delle colonne rimaste\nnames(svy)\n#&gt; [1] \"stu_id\"      \"grade_level\" \"math1\"       \"math2\"       \"math3\"      \n#&gt; [6] \"math4\"\n\n\n\n15.2.2.4 Rimuovere le Colonne non Necessarie\nNel caso presente, la rimozione di colonne non √® necessaria. Tuttavia, in molti progetti di analisi dei dati, soprattutto quando i dati vengono raccolti utilizzando software di terze parti o strumenti specifici per esperimenti psicologici, √® comune trovarsi con colonne che non sono pertinenti allo studio in corso.\nQueste colonne possono includere dati come identificatori interni, timestamp generati automaticamente, informazioni di debug, o variabili che non sono rilevanti per l‚Äôanalisi che si intende condurre. Quando tali colonne sono irrilevanti per la ricerca, possono essere rimosse per semplificare il dataset e ridurre il rischio di confusione o errori durante l‚Äôanalisi. Rimuovere le colonne non necessarie non solo rende il dataset pi√π gestibile, ma aiuta anche a focalizzare l‚Äôanalisi sulle variabili che realmente importano per rispondere alle domande di ricerca.\n\n\n15.2.2.5 Dividere le Colonne Secondo Necessit√†\nNel caso presente, questa operazione non √® necessaria. Tuttavia, se si lavora con un dataset che include una colonna chiamata ‚ÄúNomeCompleto‚Äù, contenente sia il nome che il cognome di uno studente, per esempio, √® buona pratica separare questa colonna in due colonne distinte, ‚ÄúNome‚Äù e ‚ÄúCognome‚Äù. Questa suddivisione facilita l‚Äôanalisi e la manipolazione dei dati, rendendoli pi√π organizzati e accessibili.\n\n\n15.2.2.6 Rinominare le Colonne\n√à importante assegnare nomi chiari alle colonne del dataset. Utilizzare nomi di variabili comprensibili aiuta a rendere l‚Äôanalisi dei dati pi√π intuitiva e a ridurre il rischio di errori interpretativi.\nEsempi di buone pratiche:\n\nEvita nomi di colonne come ‚Äúx‚Äù o acronimi incomprensibili. Questi possono creare confusione durante l‚Äôanalisi, specialmente se il dataset viene condiviso con altri ricercatori o se viene ripreso dopo un lungo periodo di tempo.\nInvece, cerca di utilizzare nomi di variabili che descrivano chiaramente il contenuto della colonna. Ad esempio, invece di ‚Äúx1‚Äù o ‚ÄúVAR123‚Äù, un nome come ‚Äúansia_base‚Äù o ‚Äúliv_autoefficacia‚Äù √® molto pi√π comprensibile e immediato.\nPer i nomi composti, utilizza un separatore come il trattino basso _. Ad esempio, se stai lavorando con dati relativi a un test psicologico, potresti avere colonne chiamate ‚Äútest_ansia_pre‚Äù e ‚Äútest_ansia_post‚Äù per indicare i risultati del test di ansia prima e dopo un intervento.\n\nEsempi di nomi di colonne ben scelti:\n\nNome generico: TS, AE\n\nNome migliore: tempo_studio, auto_efficacia\n\nNome generico: S1, S2\n\nNome migliore: stress_situazione1, stress_situazione2\n\nNome generico: Q1, Q2\n\nNome migliore: qualit√†_sonno_sett1, qualit√†_sonno_sett2\n\n\n\n\n15.2.2.7 Trasformare le Variabili\nNel caso presente non si applica, ma √® un passo importante in molte analisi dei dati.\nEsempi di trasformazione delle variabili:\n\nLogaritmo di una variabile: Immaginiamo di avere una variabile che misura i tempi di reazione dei partecipanti a un esperimento. Se i tempi di reazione hanno una distribuzione fortemente asimmetrica (con alcuni valori molto elevati), potrebbe essere utile applicare una trasformazione logaritmica per rendere la distribuzione pi√π simmetrica e migliorare l‚Äôinterpretabilit√† dei risultati.\nCodifica delle variabili categoriche: Se √® presente una variabile categorica come il ‚Äútipo di intervento‚Äù con valori come ‚Äúcognitivo‚Äù, ‚Äúcomportamentale‚Äù e ‚Äúfarmacologico‚Äù, potrebbe essere necessario trasformare questa variabile in variabili dummy (ad esempio, intervento_cognitivo, intervento_comportamentale, intervento_farmacologico), dove ogni variabile assume il valore 0 o 1 a seconda della presenza o meno di quel tipo di intervento. Questo √® utile quando si utilizzano tecniche di regressione.\n\n\n\n15.2.2.8 Standardizzazione delle Variabili\nLa standardizzazione √® utile quando si desidera rendere comparabili variabili misurate su scale diverse, ad esempio per confronti tra gruppi o per inclusione in modelli di regressione.\nEsempio. Supponiamo di avere una variabile che misura il livello di ansia su una scala da 0 a 100. Per standardizzarla:\n\nSottrai la media del campione dalla variabile.\n\nDividi per la deviazione standard.\n\nIl risultato √® una variabile con media pari a 0 e deviazione standard pari a 1.\nVantaggi della standardizzazione:\n\nfacilita l‚Äôinterpretazione dei coefficienti in un modello di regressione;\npermette un confronto diretto tra variabili che hanno unit√† di misura diverse.\n\n\n\n15.2.2.9 Normalizzazione delle Variabili\nLa normalizzazione consiste nel ridimensionare i dati su una scala predefinita, spesso compresa tra 0 e 1. Questo processo √® particolarmente utile in analisi multivariate, dove variabili con scale molto diverse potrebbero influenzare in modo sproporzionato i risultati.\nEsempio. Hai dati su:\n\nOre di sonno (misurate in ore, da 0 a 24).\n\nLivello di stress (misurato su una scala da 1 a 50).\n\nAuto-efficacia (misurata su una scala da 0 a 100).\n\nPer garantire che ogni variabile abbia lo stesso peso nell‚Äôanalisi, puoi normalizzarle usando una formula come:\n\\[\nx_{\\text{norm}} = \\frac{x - \\text{min}(x)}{\\text{max}(x) - \\text{min}(x)} .\n\\]\nPerch√© Standardizzare o Normalizzare?\nTrasformare le variabili √® cruciale per:\n\nGestire scale diverse: Riduce il rischio che variabili con valori numericamente pi√π grandi dominino i risultati.\n\nGarantire validit√† e interpretabilit√†: Facilita il confronto tra dati provenienti da fonti o gruppi diversi.\n\nEvitare problemi numerici nei modelli statistici: Alcuni algoritmi di machine learning o tecniche di ottimizzazione richiedono che i dati siano su scale simili per funzionare correttamente.\n\nIn conclusione, la scelta tra standardizzazione e normalizzazione dipende dal contesto dell‚Äôanalisi e dagli obiettivi specifici. Entrambi i processi sono strumenti indispensabili per garantire che i dati siano trattati in modo adeguato, portando a risultati robusti e facilmente interpretabili.\n\n\n15.2.2.10 Aggiornare i Tipi delle Variabili\nNel caso presente non √® necessario. Supponiamo invece di avere una colonna in un dataset psicologico che contiene punteggi di un questionario, ma i dati sono stati importati come stringhe (testo) invece che come numeri. Per eseguire calcoli statistici, sar√† necessario convertire questa colonna da stringa a numerico.\nIn R, si potrebbe usare il seguente codice:\n\n# Supponiamo di avere un data frame chiamato 'df' con una colonna 'punteggio' importata come carattere\ndf$punteggio &lt;- as.numeric(df$punteggio)\n\n# Ora la colonna 'punteggio' √® stata convertita in un tipo numerico ed √® possibile eseguire calcoli su di essa\n\nIn questo esempio, la funzione as.numeric() viene utilizzata per convertire la colonna punteggio in un formato numerico, permettendo di eseguire analisi quantitative sui dati.\nUn altro caso molto comune si verifica quando si importano dati da file Excel. Spesso capita che, all‚Äôinterno di una cella di una colonna che dovrebbe contenere solo valori numerici, venga inserito erroneamente uno o pi√π caratteri alfanumerici. Di conseguenza, l‚Äôintera colonna viene interpretata come di tipo alfanumerico, anche se i valori dovrebbero essere numerici. In questi casi, √® fondamentale individuare la cella problematica, correggere manualmente il valore errato, e poi riconvertire l‚Äôintera colonna da alfanumerica a numerica.\n\n\n15.2.2.11 Ricodificare le Variabili\nAnche se in questo caso non √® necessario, la ricodifica delle variabili √® una pratica molto comune nelle analisi dei dati psicologici.\nPer esempio, consideriamo una variabile categoriale con modalit√† descritte da stringhe poco comprensibili, che vengono ricodificate con nomi pi√π chiari e comprensibili.\nSupponiamo di avere un DataFrame chiamato df con una colonna tipo_intervento che contiene le modalit√† \"CT\", \"BT\", e \"MT\" per rappresentare rispettivamente ‚ÄúTerapia Cognitiva‚Äù, ‚ÄúTerapia Comportamentale‚Äù e ‚ÄúTerapia Mista‚Äù. Queste abbreviazioni potrebbero non essere immediatamente chiare a chiunque analizzi i dati, quindi decidiamo di ricodificarle con nomi pi√π espliciti. Ecco come farlo in R:\n\n# Tibble chiamato 'df' con una colonna 'tipo_intervento'\ndf &lt;- tibble(tipo_intervento = c(\"CT\", \"BT\", \"MT\", \"CT\", \"BT\"))\ndf\n#&gt; # A tibble: 5 √ó 1\n#&gt;   tipo_intervento\n#&gt;   &lt;chr&gt;          \n#&gt; 1 CT             \n#&gt; 2 BT             \n#&gt; 3 MT             \n#&gt; 4 CT             \n#&gt; 5 BT\n\n\n# Ricodifica delle modalit√† della variabile 'tipo_intervento' in nomi pi√π comprensibili\ndf &lt;- df %&gt;%\n  mutate(tipo_intervento_ricodificato = dplyr::recode(\n    tipo_intervento,\n    \"CT\" = \"Terapia Cognitiva\",\n    \"BT\" = \"Terapia Comportamentale\",\n    \"MT\" = \"Terapia Mista\"\n  ))\n\n# Mostra il tibble con la nuova colonna ricodificata\ndf\n#&gt; # A tibble: 5 √ó 2\n#&gt;   tipo_intervento tipo_intervento_ricodificato\n#&gt;   &lt;chr&gt;           &lt;chr&gt;                       \n#&gt; 1 CT              Terapia Cognitiva           \n#&gt; 2 BT              Terapia Comportamentale     \n#&gt; 3 MT              Terapia Mista               \n#&gt; 4 CT              Terapia Cognitiva           \n#&gt; 5 BT              Terapia Comportamentale\n\n\n\n15.2.2.12 Aggiungere Nuove Variabili nel Data Frame\nNel caso presente non √® richiesto, ma aggiungere nuove variabili a un DataFrame √® un‚Äôoperazione comune durante l‚Äôanalisi dei dati. Un esempio √® il calcolo dell‚Äôindice di massa corporea (BMI).\nSupponiamo di avere un DataFrame chiamato df che contiene le colonne peso_kg (peso in chilogrammi) e altezza_m (altezza in metri) per ciascun partecipante a uno studio psicologico. Per arricchire il dataset, possiamo calcolare il BMI per ogni partecipante e aggiungerlo come una nuova variabile.\nIl BMI si calcola con la formula:\n\\[ \\text{BMI} = \\frac{\\text{peso in kg}}{\\text{altezza in metri}^2} .\\]\nEcco come aggiungere la nuova colonna.\n\n# Supponiamo di avere un tibble chiamato 'df' con le colonne 'peso_kg' e 'altezza_m'\ndf &lt;- tibble(\n  peso_kg = c(70, 85, 60, 95),\n  altezza_m = c(1.75, 1.80, 1.65, 1.90)\n)\ndf\n#&gt; # A tibble: 4 √ó 2\n#&gt;   peso_kg altezza_m\n#&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1      70      1.75\n#&gt; 2      85      1.8 \n#&gt; 3      60      1.65\n#&gt; 4      95      1.9\n\n\n# Calcola il BMI e aggiungilo come una nuova colonna 'BMI'\ndf &lt;- df %&gt;%\n  mutate(BMI = peso_kg / (altezza_m^2))\n\n# Mostra il tibble con la nuova variabile aggiunta\ndf\n#&gt; # A tibble: 4 √ó 3\n#&gt;   peso_kg altezza_m   BMI\n#&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1      70      1.75  22.9\n#&gt; 2      85      1.8   26.2\n#&gt; 3      60      1.65  22.0\n#&gt; 4      95      1.9   26.3\n\n\n\n\n15.2.3 Affrontare il Problema dei Dati Mancanti\nI dati mancanti sono un problema comune nelle ricerche psicologiche e in molte altre discipline. Quando mancano delle informazioni in un dataset, possono verificarsi gravi problemi per l‚Äôanalisi statistica, come risultati distorti, riduzione della precisione delle stime o, in alcuni casi, l‚Äôimpossibilit√† di applicare alcuni algoritmi.\n\n15.2.3.1 Perch√© i Dati Mancanti Sono un Problema?\nImmagina di voler capire il rendimento medio di una classe in un test, ma alcuni studenti hanno lasciato delle risposte in bianco. Se ignoriamo le risposte mancanti o eliminiamo gli studenti con dati incompleti, rischiamo di ottenere una stima che non rappresenta correttamente la realt√†. Questo succede perch√©:\n\nBias dei risultati: Se i dati mancanti non sono casuali (ad esempio, i dati mancanti sono presenti pi√π spesso in studenti con basso rendimento), le conclusioni possono essere errate.\nRiduzione della potenza statistica: Eliminare dati incompleti riduce il numero totale di osservazioni, rendendo pi√π difficile trovare risultati significativi.\nImpossibilit√† di applicare alcuni metodi: Molti algoritmi statistici richiedono dati completi e non funzionano con valori mancanti.\n\n\n\n15.2.3.2 Come Gestire i Dati Mancanti?\nCi sono diversi modi per affrontare i dati mancanti. Vediamo prima i metodi pi√π semplici e poi quelli pi√π avanzati.\nEsaminiamo il data frame iniziale:\n\nsvy |&gt; \n  summary()\n#&gt;      stu_id      grade_level       math1        math2          \n#&gt;  Min.   :1347   Min.   : 9.0   Min.   :2.0   Length:5          \n#&gt;  1st Qu.:1368   1st Qu.: 9.0   1st Qu.:3.0   Class :character  \n#&gt;  Median :1377   Median :10.0   Median :3.0   Mode  :character  \n#&gt;  Mean   :1376   Mean   :10.2   Mean   :3.2                     \n#&gt;  3rd Qu.:1387   3rd Qu.:11.0   3rd Qu.:4.0                     \n#&gt;  Max.   :1399   Max.   :12.0   Max.   :4.0                     \n#&gt;                                                                \n#&gt;      math3          math4     \n#&gt;  Min.   :2.00   Min.   :1.00  \n#&gt;  1st Qu.:2.75   1st Qu.:1.75  \n#&gt;  Median :3.00   Median :2.50  \n#&gt;  Mean   :3.00   Mean   :2.50  \n#&gt;  3rd Qu.:3.25   3rd Qu.:3.25  \n#&gt;  Max.   :4.00   Max.   :4.00  \n#&gt;  NA's   :1      NA's   :1\n\nSi noti la presenza di dati mancanti sulle variabili math3 e math4.\n\ndim(svy)\n#&gt; [1] 5 6\n\n\nEsclusione dei Casi Incompleti (Complete Case Analysis).\nUn approccio comune, ma spesso non ideale, √® quello di analizzare solo i casi completi, eliminando tutte le righe con valori mancanti. In R, questo si pu√≤ fare con il seguente comando:\n\nsvy_comp &lt;- svy |&gt;\n  drop_na()\n\nIn questo modo abbiamo escluso tutte le righe nelle quali sono presenti dei dati mancanti (in questo caso, una sola riga).\n\ndim(svy_comp)\n#&gt; [1] 4 6\n\nLimite: Questo metodo pu√≤ introdurre bias se i dati mancanti non sono casuali e riduce il campione, compromettendo l‚Äôaffidabilit√† delle analisi.\nImputazione Semplice\nSostituire i valori mancanti con stime semplici:\n\nMedia o mediana: Per le variabili numeriche, sostituire i valori mancanti con la media o la mediana. Questo metodo √® facile da implementare, ma pu√≤ ridurre la variabilit√† nei dati.\nModa: Per le variabili categoriche, sostituire i valori mancanti con il valore pi√π frequente. Tuttavia, pu√≤ introdurre distorsioni se i dati sono molto eterogenei.\n\nImputazione Multipla\nUn approccio pi√π avanzato √® l‚Äôimputazione multipla, che utilizza modelli statistici per stimare i valori mancanti in modo iterativo. L‚Äôidea di base √® semplice: ogni valore mancante viene stimato tenendo conto delle relazioni con tutte le altre variabili.\nVantaggi:\n\nMantiene la variabilit√† dei dati.\nPreserva le relazioni tra le variabili.\nRiduce il rischio di bias rispetto ai metodi semplici.\n\n\n\n\n15.2.3.3 Applicazione Pratica: Imputazione Multipla con mice in R\nSupponiamo di avere un dataset con alcune colonne numeriche che contengono valori mancanti. Possiamo utilizzare il pacchetto mice per imputare i dati mancanti.\nSelezioniamo le colonne numeriche da imputare.\n\nnumeric_columns &lt;- c(\"math1\", \"math2\", \"math3\", \"math4\")\nsvy &lt;- svy %&gt;%\n  mutate(across(all_of(numeric_columns), as.numeric))\n\nEseguiamo l‚Äôimputazione multipla.\n\nimputed &lt;- mice(\n  svy[numeric_columns], \n  m = 1, \n  maxit = 10, \n  method = \"norm.predict\", \n  seed = 123\n)\n#&gt; \n#&gt;  iter imp variable\n#&gt;   1   1  math3  math4\n#&gt;   2   1  math3  math4\n#&gt;   3   1  math3  math4\n#&gt;   4   1  math3  math4\n#&gt;   5   1  math3  math4\n#&gt;   6   1  math3  math4\n#&gt;   7   1  math3  math4\n#&gt;   8   1  math3  math4\n#&gt;   9   1  math3  math4\n#&gt;   10   1  math3  math4\n#&gt; Warning: Number of logged events: 2\n\nOttieniamo il dataset con i valori imputati.\n\nsvy_imputed &lt;- complete(imputed)\n\nArrotondiamo i valori imputati (se necessario).\n\nsvy_imputed &lt;- svy_imputed %&gt;%\n  mutate(across(everything(), round))\n\nSostituiamo i valori imputati nel dataset originale.\n\nsvy[numeric_columns] &lt;- svy_imputed\n\nEsaminiamo il risultato ottenuto.\n\nsvy |&gt; \n  summary()\n#&gt;      stu_id      grade_level       math1         math2         math3    \n#&gt;  Min.   :1347   Min.   : 9.0   Min.   :2.0   Min.   :1.0   Min.   :2.0  \n#&gt;  1st Qu.:1368   1st Qu.: 9.0   1st Qu.:3.0   1st Qu.:1.0   1st Qu.:3.0  \n#&gt;  Median :1377   Median :10.0   Median :3.0   Median :2.0   Median :3.0  \n#&gt;  Mean   :1376   Mean   :10.2   Mean   :3.2   Mean   :2.2   Mean   :3.2  \n#&gt;  3rd Qu.:1387   3rd Qu.:11.0   3rd Qu.:4.0   3rd Qu.:3.0   3rd Qu.:4.0  \n#&gt;  Max.   :1399   Max.   :12.0   Max.   :4.0   Max.   :4.0   Max.   :4.0  \n#&gt;      math4    \n#&gt;  Min.   :1.0  \n#&gt;  1st Qu.:2.0  \n#&gt;  Median :3.0  \n#&gt;  Mean   :2.8  \n#&gt;  3rd Qu.:4.0  \n#&gt;  Max.   :4.0\n\n\n\n15.2.3.4 Come Funziona l‚ÄôImputazione Multipla?\n\nOgni variabile con valori mancanti viene modellata come funzione delle altre variabili.\nI valori mancanti vengono stimati iterativamente. In ogni iterazione, si utilizza l‚Äôoutput precedente come input per migliorare le stime.\nDopo un numero sufficiente di iterazioni, le stime si stabilizzano (convergenza).\n\nIn conclusione, l‚Äôimputazione multipla √® una tecnica avanzata che permette di gestire i dati mancanti preservando la qualit√† delle analisi. Rispetto ai metodi semplici, consente di mantenere la variabilit√† e ridurre il rischio di bias, rendendola una scelta ideale per analisi psicologiche e di ricerca.\n\n\n15.2.3.5 Aggiungere i Metadati\nI metadati sono informazioni che descrivono i dati stessi, come etichette di variabili, etichette di valori, informazioni sull‚Äôorigine dei dati, unit√† di misura e altro ancora. Questi metadati sono essenziali per comprendere, documentare e condividere correttamente un dataset.\nIn R, i metadati sono gestiti in modo molto dettagliato e strutturato attraverso pacchetti come haven, labelled, e Hmisc. Questi pacchetti consentono di associare etichette ai dati, come etichette di variabili e di valori, e persino di gestire i valori mancanti con etichette specifiche.\n\nEtichette di variabili: Si possono aggiungere direttamente alle colonne di un DataFrame usando funzioni come labelled::set_variable_labels().\nEtichette di valori: Possono essere aggiunte a variabili categoriali utilizzando labelled::labelled().\nValori mancanti: In R, √® possibile etichettare specifici valori come mancanti usando labelled::na_values&lt;-.\n\nQuesti strumenti rendono molto facile documentare un dataset all‚Äôinterno del processo di analisi, assicurando che tutte le informazioni critiche sui dati siano facilmente accessibili e ben documentate.\nEsaminiamo un esempio pratico. Consideriamo nuovamente il data set svy:\n\nglimpse(svy)\n#&gt; Rows: 5\n#&gt; Columns: 6\n#&gt; $ stu_id      &lt;int&gt; 1347, 1368, 1377, 1387, 1399\n#&gt; $ grade_level &lt;int&gt; 9, 10, 9, 11, 12\n#&gt; $ math1       &lt;dbl&gt; 2, 3, 4, 3, 4\n#&gt; $ math2       &lt;dbl&gt; 1, 2, 4, 3, 1\n#&gt; $ math3       &lt;dbl&gt; 3, 2, 4, 4, 3\n#&gt; $ math4       &lt;dbl&gt; 3, 2, 4, 4, 1\n\nSi noti che la variabile math2 contiene un valore inamissibile, probabilmente un errore di battitura. Questo fa in modo che math2 sia di tipo char mentre dovrebbe essere una variabile numerica. Correggiamo.\n\n# Correzione di `math2`: Rimuovi valori non validi e converti in numerico\nsvy$math2 &lt;- gsub(\"\\\\n\", \"\", svy$math2)  # Rimuovi caratteri non validi come '\\n'\nsvy$math2 &lt;- as.numeric(svy$math2)      # Converte la variabile in numerico\n\n# Visualizzazione del dataset corretto\nprint(svy)\n#&gt;   stu_id grade_level math1 math2 math3 math4\n#&gt; 1   1347           9     2     1     3     3\n#&gt; 2   1368          10     3     2     2     2\n#&gt; 3   1377           9     4     4     4     4\n#&gt; 4   1387          11     3     3     4     4\n#&gt; 6   1399          12     4     1     3     1\n\nDefiniamo le etichette di valore per le variabili math1:math4.\n\nvalue_labels_math &lt;- set_names(\n  as.numeric(names(c(\n    `1` = \"strongly disagree\",\n    `2` = \"disagree\",\n    `3` = \"agree\",\n    `4` = \"strongly agree\"\n  ))),\n  c(\"strongly disagree\", \"disagree\", \"agree\", \"strongly agree\")\n)\n\nAggiungiamo le etichette di valore alle colonne math1:math4.\n\nsvy &lt;- svy %&gt;%\n  mutate(across(starts_with(\"math\"), ~ labelled(., labels = value_labels_math)))\n\nVerifica delle etichette.\n\nval_labels(svy$math1)\n#&gt; strongly disagree          disagree             agree    strongly agree \n#&gt;                 1                 2                 3                 4\n\n\nsvy\n#&gt;   stu_id grade_level math1 math2 math3 math4\n#&gt; 1   1347           9     2     1     3     3\n#&gt; 2   1368          10     3     2     2     2\n#&gt; 3   1377           9     4     4     4     4\n#&gt; 4   1387          11     3     3     4     4\n#&gt; 6   1399          12     4     1     3     1\n\n\n15.2.3.5.1 Utilizzo delle Etichette in R con Variabili Numeriche\nLe etichette dei valori (value labels) vengono utilizzate per rendere pi√π leggibili e interpretabili le variabili numeriche, associando ad ogni valore un‚Äôetichetta descrittiva. Questo approccio √® particolarmente utile in ambiti come la ricerca psicologica, dove le risposte ai questionari sono spesso codificate con numeri (ad esempio, 1 = ‚ÄúStrongly Disagree‚Äù, 2 = ‚ÄúDisagree‚Äù, ecc.) ma rappresentano concetti qualitativi.\nVantaggi dell‚ÄôUso delle Etichette\n\nChiarezza nelle Analisi: Le etichette descrittive rendono i dati pi√π facilmente comprensibili senza dover ricordare il significato numerico di ciascun valore.\n\nDocumentazione Integrata: Permettono di incorporare metadati direttamente nelle variabili, migliorando la trasparenza e riducendo il rischio di interpretazioni errate.\nCompatibilit√† con Software Statistici: Molti strumenti (ad esempio, SPSS o Stata) utilizzano etichette di valori. Il pacchetto haven in R consente di gestire facilmente i dati etichettati esportati/importati da questi software.\n\nManipolazione di Variabili Etichettate\nAnche se una variabile numerica √® etichettata con labelled (ad esempio, tramite il pacchetto haven), essa conserva la sua natura numerica e pu√≤ essere utilizzata in calcoli, modelli statistici, e trasformazioni. Le etichette non alterano il valore sottostante, ma lo arricchiscono con informazioni aggiuntive.\nIn conclusione, le etichette dei valori migliorano l‚Äôinterpretabilit√† dei dati senza comprometterne la manipolabilit√†. Questo approccio √® ideale per mantenere le variabili numeriche pienamente funzionali per analisi statistiche, mentre le etichette descrittive forniscono un contesto chiaro e leggibile.\n\n\n\n15.2.3.6 Validazione dei Dati\nLa validazione dei dati √® un passaggio fondamentale per garantire che il dataset soddisfi i criteri previsti e sia pronto per le analisi successive. Questo processo include il controllo della coerenza e della correttezza dei dati in base a specifiche regole definite dal dizionario dei dati. Alcune verifiche comuni includono:\n\nUnicit√† delle righe: Assicurarsi che ogni riga sia unica, verificando l‚Äôassenza di ID duplicati.\nValidit√† degli ID: Controllare che gli ID rientrino in un intervallo previsto (es. numerico).\nValori accettabili nelle variabili categoriali: Verificare che variabili come grade_level, int e le colonne math contengano esclusivamente valori appartenenti a un set di valori validi.\n\nIl pacchetto pointblank fornisce strumenti flessibili e intuitivi per eseguire verifiche di validazione e generare report dettagliati. Questo pacchetto consente di:\n\nDefinire le regole di validazione: Specificare controlli come unicit√†, intervalli di valori e appartenenza a insiemi predefiniti.\nEseguire i controlli: Applicare le regole di validazione su un dataset per identificare eventuali discrepanze.\nGenerare report interattivi: Creare un riepilogo chiaro e visivo dei controlli, evidenziando eventuali errori o anomalie.\n\nCon pointblank, √® possibile integrare la validazione dei dati come parte di un workflow strutturato, garantendo la qualit√† dei dati in modo sistematico e ripetibile.\n\ncreate_agent(svy) %&gt;%\n  rows_distinct(columns = vars(stu_id)) %&gt;%\n  col_vals_between(columns = c(stu_id), \n                   left = 1300, right = 1400, na_pass = TRUE) %&gt;%\n  col_vals_in_set(columns = c(grade_level), \n                  set = c(9, 10, 11, 12, NA)) %&gt;%\n  col_vals_in_set(columns = c(int),\n                  set = c(0, 1, NA)) %&gt;%\n  col_vals_in_set(columns = c(math1:math4),\n                  set = c(1, 2, 3, 4, NA)) %&gt;%\n  interrogate()\n\n\n\n\n\n\n\nPointblank Validation\n\n\n\n\n[2025-01-13|11:00:27]\n\n\ndata frame svy\n\n\n\n\n\n\nSTEP\nCOLUMNS\nVALUES\nTBL\nEVAL\nUNITS\nPASS\nFAIL\nW\nS\nN\nEXT\n\n\n\n\n\n\n1\n\n\n\n\nrows_distinct\n\n         \n\n\n¬†rows_distinct()\n\n\n‚ñÆstu_id\n\n‚Äî\n\n\n      \n\n\n‚úì\n5\n5\n1\n0\n0\n‚Äî\n‚Äî\n‚Äî\n‚Äî\n\n\n\n\n2\n\n\n\n\ncol_vals_between\n\n     \n\n\n¬†col_vals_between()\n\n\n‚ñÆstu_id\n\n\n[1,300, 1,400]\n\n\n\n      \n\n\n‚úì\n5\n5\n1\n0\n0\n‚Äî\n‚Äî\n‚Äî\n‚Äî\n\n\n\n\n3\n\n\n\n\ncol_vals_in_set\n\n     \n\n\n¬†col_vals_in_set()\n\n\n‚ñÆgrade_level\n\n\n9, 10, 11, 12, NA\n\n\n\n      \n\n\n‚úì\n5\n5\n1\n0\n0\n‚Äî\n‚Äî\n‚Äî\n‚Äî\n\n\n\n\n4\n\n\n\n\ncol_vals_in_set\n\n     \n\n\n¬†col_vals_in_set()\n\n\n‚ñÆint\n\n\n0, 1, NA\n\n\n\n      \n\n\nüí•\n‚Äî\n‚Äî\n‚Äî\n‚Äî\n‚Äî\n‚Äî\n‚Äî\n\n\n\n\n5\n\n\n\n\ncol_vals_in_set\n\n     \n\n\n¬†col_vals_in_set()\n\n\n‚ñÆmath1\n\n\n1, 2, 3, 4, NA\n\n\n\n      \n\n\n‚úì\n5\n5\n1\n0\n0\n‚Äî\n‚Äî\n‚Äî\n‚Äî\n\n\n\n\n6\n\n\n\n\ncol_vals_in_set\n\n     \n\n\n¬†col_vals_in_set()\n\n\n‚ñÆmath2\n\n\n1, 2, 3, 4, NA\n\n\n\n      \n\n\n‚úì\n5\n5\n1\n0\n0\n‚Äî\n‚Äî\n‚Äî\n‚Äî\n\n\n\n\n7\n\n\n\n\ncol_vals_in_set\n\n     \n\n\n¬†col_vals_in_set()\n\n\n‚ñÆmath3\n\n\n1, 2, 3, 4, NA\n\n\n\n      \n\n\n‚úì\n5\n5\n1\n0\n0\n‚Äî\n‚Äî\n‚Äî\n‚Äî\n\n\n\n\n8\n\n\n\n\ncol_vals_in_set\n\n     \n\n\n¬†col_vals_in_set()\n\n\n‚ñÆmath4\n\n\n1, 2, 3, 4, NA\n\n\n\n      \n\n\n‚úì\n5\n5\n1\n0\n0\n‚Äî\n‚Äî\n‚Äî\n‚Äî\n\n\n\n2025-01-13 11:00:27 PST &lt; 1 s 2025-01-13 11:00:27 PST\n\n\n\n\n\n\n\n\nIl dataset ripulito soddisfa tutte le aspettative delineate da Crystal Lewis.\n\nCompleto: Tutti i dati raccolti sono stati inseriti e/o recuperati. Non dovrebbero esserci dati estranei che non appartengono al dataset (come duplicati o partecipanti non autorizzati).\nValido: Le variabili rispettano i vincoli definiti nel tuo dizionario dei dati. Ricorda che il dizionario dei dati specifica i nomi delle variabili, i tipi, i range, le categorie e altre informazioni attese.\nAccurato: Sebbene non sia sempre possibile determinare l‚Äôaccuratezza dei valori durante il processo di pulizia dei dati (ovvero, se un valore √® realmente corretto o meno), in alcuni casi √® possibile valutarla sulla base della conoscenza pregressa riguardante quel partecipante o caso specifico.\nCoerente: I valori sono allineati tra le varie fonti. Ad esempio, la data di nascita raccolta attraverso un sondaggio studentesco dovrebbe avere un formato corrispondere alla data di nascita raccolta dal distretto scolastico.\nUniforme: I dati sono standardizzati attraverso i moduli e nel tempo. Ad esempio, lo stato di partecipazione ai programmi di pranzo gratuito o a prezzo ridotto √® sempre fornito come una variabile numerica con la stessa rappresentazione, oppure il nome della scuola √® sempre scritto in modo coerente in tutto il dataset.\nDe-identificato: Tutte le informazioni personali identificabili (PII) sono state rimosse dal dataset per proteggere la riservatezza dei partecipanti (se richiesto dal comitato etico/consenso informato).\nInterpretabile: I dati hanno nomi di variabili leggibili sia da umani che dal computer, e sono presenti etichette di variabili e valori laddove necessario per facilitare l‚Äôinterpretazione.\nAnalizzabile: Il dataset √® in un formato rettangolare (righe e colonne), leggibile dal computer e conforme alle regole di base della struttura dei dati.\n\nUna volta completati i 14 passaggi precedenti, √® possibile esportare questo dataset ripulito nella cartella processed per le successive analisi statistiche.\n\n\n15.2.3.7 Unire e/o aggiungere dati se necessario\nIn questo passaggio, √® possibile unire o aggiungere colonne o righe presenti in file diversi. √à importante eseguire nuovamente i controlli di validazione dopo l‚Äôunione/aggiunta di nuovi dati.\n\n\n15.2.3.8 Trasformare i dati se necessario\nEsistono vari motivi per cui potrebbe essere utile memorizzare i dati in formato long o wide. In questo passaggio, √® possibile ristrutturare i dati secondo le esigenze.\n\n\n15.2.3.9 Salvare il dataset pulito finale\nL‚Äôultimo passaggio del processo di pulizia consiste nell‚Äôesportare o salvare il dataset pulito. Come accennato in precedenza, pu√≤ essere utile esportare/salvare il dataset in pi√π di un formato di file (ad esempio, un file .csv e un file .parquet).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#organizzazione-dei-file-e-informazioni-aggiuntive",
    "href": "chapters/eda/02_data_cleaning.html#organizzazione-dei-file-e-informazioni-aggiuntive",
    "title": "15¬† Flusso di lavoro per la pulizia dei dati",
    "section": "15.3 Organizzazione dei file e informazioni aggiuntive",
    "text": "15.3 Organizzazione dei file e informazioni aggiuntive\nInfine, √® essenziale includere una documentazione adeguata per garantire che le informazioni siano interpretate correttamente, sia da altri utenti che da te stesso, se dovessi tornare a lavorare su questo progetto in futuro. La documentazione minima da fornire dovrebbe includere:\n\nDocumentazione a livello di progetto: Questa sezione fornisce informazioni contestuali sul perch√© e come i dati sono stati raccolti. √à utile per chiunque voglia comprendere lo scopo e la metodologia del progetto.\nMetadati a livello di progetto: Se condividi i dati in un repository pubblico o privato, √® importante includere metadati a livello di progetto. Questi metadati forniscono informazioni dettagliate che facilitano la ricerca, la comprensione e la consultabilit√† dei dati. I metadati a livello di progetto possono includere descrizioni generali del progetto, parole chiave, e riferimenti bibliografici.\nDizionario dei dati: Un documento che descrive tutte le variabili presenti nel dataset, inclusi i loro nomi, tipi, range di valori, categorie e qualsiasi altra informazione rilevante. Questo strumento √® fondamentale per chiunque voglia comprendere o analizzare i dati.\nREADME: Un file che fornisce una panoramica rapida dei file inclusi nel progetto, spiegando cosa contengono e come sono interconnessi. Il README √® spesso il primo documento consultato e serve a orientare l‚Äôutente tra i vari file e risorse del progetto. Questa documentazione non solo aiuta a mantenere il progetto organizzato, ma √® anche cruciale per facilitare la collaborazione e l‚Äôarchiviazione a lungo termine.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#dizionario-dei-dati",
    "href": "chapters/eda/02_data_cleaning.html#dizionario-dei-dati",
    "title": "15¬† Flusso di lavoro per la pulizia dei dati",
    "section": "15.4 Dizionario dei Dati",
    "text": "15.4 Dizionario dei Dati\nApprofondiamo qui il problema della creazione del Dizionario dei dati.\nUn dizionario dei dati √® un documento che descrive le caratteristiche di ciascuna variabile in un dataset. Include informazioni come il nome della variabile, il tipo di dato, il range di valori, le categorie (per le variabili categoriche), e altre informazioni rilevanti. Questo strumento √® essenziale per comprendere e analizzare correttamente il dataset.\nSi presti particolare attenzione alle guide di stile per la denominazione delle variabili e la codifica dei valori delle risposte.\n\n15.4.1 Esempio in R\nEcco come tradurre i passi per creare un dizionario dei dati in R, utilizzando il pacchetto tibble per creare il dizionario e writexl o readr per esportarlo in formato .xlsx o .csv.\n\nIdentificare le variabili: Elencare tutte le variabili presenti nel dataset.\nDescrivere ogni variabile: Per ciascuna variabile, definire il tipo (ad esempio, integer, numeric, character), il range di valori accettabili o le categorie, e fornire una descrizione chiara.\nSalvare il dizionario dei dati: Il dizionario pu√≤ essere salvato in un file .csv o .xlsx per una facile consultazione.\n\n\nsvy\n#&gt;   stu_id grade_level math1 math2 math3 math4\n#&gt; 1   1347           9     2     1     3     3\n#&gt; 2   1368          10     3     2     2     2\n#&gt; 3   1377           9     4     4     4     4\n#&gt; 4   1387          11     3     3     4     4\n#&gt; 6   1399          12     4     1     3     1\n\nCreeremo un dizionario dei dati per un dataset di esempio e lo salveremo sia in formato CSV che Excel.\n\nlibrary(tibble)\nlibrary(readr)\nlibrary(writexl)\n\n# Creazione del Dizionario dei Dati\ndata_dict &lt;- tibble(\n  `Variable Name` = c(\n    \"stu_id\",\n    \"svy_date\",\n    \"grade_level\",\n    \"math1\",\n    \"math2\",\n    \"math3\",\n    \"math4\"\n  ),\n  `Type` = c(\n    \"integer\",\n    \"datetime\",\n    \"integer\",\n    \"integer\",\n    \"integer\",\n    \"numeric\",\n    \"numeric\"\n  ),\n  `Description` = c(\n    \"Student ID\",\n    \"Survey Date\",\n    \"Grade Level\",\n    \"Math Response 1 (1: Strongly Disagree, 4: Strongly Agree)\",\n    \"Math Response 2 (1: Strongly Disagree, 4: Strongly Agree)\",\n    \"Math Response 3 (1: Strongly Disagree, 4: Strongly Agree)\",\n    \"Math Response 4 (1: Strongly Disagree, 4: Strongly Agree)\"\n  ),\n  `Range/Values` = c(\n    \"1347-1399\",\n    \"2023-02-13 to 2023-02-14\",\n    \"9-12\",\n    \"1-4\",\n    \"1-4\",\n    \"1.0-4.0 (NA allowed)\",\n    \"1.0-4.0 (NA allowed)\"\n  )\n)\n\n# Visualizza il Dizionario dei Dati\nprint(data_dict)\n#&gt; # A tibble: 7 √ó 4\n#&gt;   `Variable Name` Type     Description                       `Range/Values` \n#&gt;   &lt;chr&gt;           &lt;chr&gt;    &lt;chr&gt;                             &lt;chr&gt;          \n#&gt; 1 stu_id          integer  Student ID                        1347-1399      \n#&gt; 2 svy_date        datetime Survey Date                       2023-02-13 to ‚Ä¶\n#&gt; 3 grade_level     integer  Grade Level                       9-12           \n#&gt; 4 math1           integer  Math Response 1 (1: Strongly Dis‚Ä¶ 1-4            \n#&gt; 5 math2           integer  Math Response 2 (1: Strongly Dis‚Ä¶ 1-4            \n#&gt; 6 math3           numeric  Math Response 3 (1: Strongly Dis‚Ä¶ 1.0-4.0 (NA al‚Ä¶\n#&gt; # ‚Ñπ 1 more row\n\n# Salva il Dizionario dei Dati in un file CSV\nwrite_csv(data_dict, here::here(\"data\", \"processed\", \"data_dictionary.csv\"))\n\n# Salva il Dizionario dei Dati in un file Excel\nwrite_xlsx(data_dict, here::here(\"data\", \"processed\", \"data_dictionary.xlsx\"))\n\nOutput Atteso: file CSV (data_dictionary.csv).\n\ndata_dict &lt;- rio::import(\n  here::here(\"data\", \"processed\", \"data_dictionary.csv\")\n)\n\n\nprint(data_dict)\n#&gt;   Variable Name     Type\n#&gt; 1        stu_id  integer\n#&gt; 2      svy_date datetime\n#&gt; 3   grade_level  integer\n#&gt; 4         math1  integer\n#&gt; 5         math2  integer\n#&gt; 6         math3  numeric\n#&gt; 7         math4  numeric\n#&gt;                                                 Description\n#&gt; 1                                                Student ID\n#&gt; 2                                               Survey Date\n#&gt; 3                                               Grade Level\n#&gt; 4 Math Response 1 (1: Strongly Disagree, 4: Strongly Agree)\n#&gt; 5 Math Response 2 (1: Strongly Disagree, 4: Strongly Agree)\n#&gt; 6 Math Response 3 (1: Strongly Disagree, 4: Strongly Agree)\n#&gt; 7 Math Response 4 (1: Strongly Disagree, 4: Strongly Agree)\n#&gt;               Range/Values\n#&gt; 1                1347-1399\n#&gt; 2 2023-02-13 to 2023-02-14\n#&gt; 3                     9-12\n#&gt; 4                      1-4\n#&gt; 5                      1-4\n#&gt; 6     1.0-4.0 (NA allowed)\n#&gt; 7     1.0-4.0 (NA allowed)\n\n\n15.4.1.1 Uso del pacchetto dataMeta\nIl pacchetto dataMeta √® progettato per generare metadati e dizionari dei dati in modo strutturato.\n\nlibrary(dataMeta)\nlibrary(tibble)\n\n# Descrizioni delle variabili\nvariable_descriptions &lt;- c(\n  \"Student ID\",\n  \"Grade Level\",\n  \"Math Response 1 (1: Strongly Disagree, 4: Strongly Agree)\",\n  \"Math Response 2 (1: Strongly Disagree, 4: Strongly Agree)\",\n  \"Math Response 3 (1: Strongly Disagree, 4: Strongly Agree)\",\n  \"Math Response 4 (1: Strongly Disagree, 4: Strongly Agree)\"\n)\n\nvar_type &lt;- c(1, 0, 0, 0, 0, 0)\n\nlinker &lt;- build_linker(\n  svy, \n  variable_description = variable_descriptions, \n  variable_type = var_type\n)\n\ndict &lt;- build_dict(\n  my.data = svy, \n  linker = linker, \n  option_description = NULL, \n  prompt_varopts = FALSE\n)\n\nkable(dict, format = \"html\", caption = \"Data dictionary for original dataset\")\n\n\nData dictionary for original dataset\n\n\nvariable_name\nvariable_description\nvariable_options\n\n\n\n\ngrade_level\nGrade Level\n9 to 12\n\n\nmath1\nMath Response 1 (1: Strongly Disagree, 4: Strongly Agree)\n2 to 4\n\n\nmath2\nMath Response 2 (1: Strongly Disagree, 4: Strongly Agree)\n1 to 4\n\n\nmath3\nMath Response 3 (1: Strongly Disagree, 4: Strongly Agree)\n2 to 4\n\n\nmath4\nMath Response 4 (1: Strongly Disagree, 4: Strongly Agree)\n1 to 4\n\n\nstu_id\nStudent ID\n1347\n\n\n\n\n1368\n\n\n\n\n1377\n\n\n\n\n1387\n\n\n\n\n1399\n\n\n\n\n\n\n\n\n\n15.4.1.2 Uso del pacchetto skimr\nIl pacchetto skimr √® utile per generare riassunti dettagliati delle variabili, che possono essere utilizzati come base per un dizionario.\n\nlibrary(skimr)\n\n# Riassunto del dataset\nskim_dict &lt;- skim(svy)\n\nkable(skim_dict, format = \"html\", caption = \"Data dictionary for original dataset\")\n\n\nData dictionary for original dataset\n\n\nskim_type\nskim_variable\nn_missing\ncomplete_rate\nnumeric.mean\nnumeric.sd\nnumeric.p0\nnumeric.p25\nnumeric.p50\nnumeric.p75\nnumeric.p100\nnumeric.hist\n\n\n\n\nnumeric\nstu_id\n0\n1\n1375.6\n19.718\n1347\n1368\n1377\n1387\n1399\n‚ñÉ‚ñÅ‚ñá‚ñÉ‚ñÉ\n\n\nnumeric\ngrade_level\n0\n1\n10.2\n1.304\n9\n9\n10\n11\n12\n‚ñá‚ñÉ‚ñÅ‚ñÉ‚ñÉ\n\n\nnumeric\nmath1\n0\n1\n3.2\n0.837\n2\n3\n3\n4\n4\n‚ñÉ‚ñÅ‚ñá‚ñÅ‚ñá\n\n\nnumeric\nmath2\n0\n1\n2.2\n1.304\n1\n1\n2\n3\n4\n‚ñá‚ñÉ‚ñÅ‚ñÉ‚ñÉ\n\n\nnumeric\nmath3\n0\n1\n3.2\n0.837\n2\n3\n3\n4\n4\n‚ñÉ‚ñÅ‚ñá‚ñÅ‚ñá\n\n\nnumeric\nmath4\n0\n1\n2.8\n1.304\n1\n2\n3\n4\n4\n‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñá",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#riflessioni-conclusive",
    "href": "chapters/eda/02_data_cleaning.html#riflessioni-conclusive",
    "title": "15¬† Flusso di lavoro per la pulizia dei dati",
    "section": "15.5 Riflessioni Conclusive",
    "text": "15.5 Riflessioni Conclusive\nNel processo di analisi dei dati, la fase di pulizia e pre-elaborazione √® cruciale per garantire la qualit√† e l‚Äôintegrit√† dei risultati finali. Sebbene questa fase possa sembrare meno interessante rispetto all‚Äôanalisi vera e propria, essa costituisce la base su cui si costruiscono tutte le successive elaborazioni e interpretazioni. Attraverso una serie di passaggi strutturati, come quelli illustrati in questo capitolo, √® possibile trasformare dati grezzi e disordinati in un dataset pulito, coerente e pronto per l‚Äôanalisi. La cura nella gestione dei dati, dalla rimozione di duplicati alla creazione di un dizionario dei dati, √® fondamentale per ottenere risultati affidabili e riproducibili.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/02_data_cleaning.html#informazioni-sullambiente-di-sviluppo",
    "title": "15¬† Flusso di lavoro per la pulizia dei dati",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: US/Pacific\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] skimr_2.1.5       dataMeta_0.1.1    writexl_1.5.1     pointblank_0.12.2\n#&gt;  [5] haven_2.5.4       labelled_2.14.0   mice_3.17.0       ggokabeito_0.1.0 \n#&gt;  [9] see_0.9.0         gridExtra_2.3     patchwork_1.3.0   bayesplot_1.11.1 \n#&gt; [13] psych_2.4.12      scales_1.3.0      markdown_1.13     knitr_1.49       \n#&gt; [17] lubridate_1.9.4   forcats_1.0.0     stringr_1.5.1     dplyr_1.1.4      \n#&gt; [21] purrr_1.0.2       readr_2.1.5       tidyr_1.3.1       tibble_3.2.1     \n#&gt; [25] ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1  farver_2.1.2      R.utils_2.12.3    fastmap_1.2.0    \n#&gt;  [5] pacman_0.5.1      digest_0.6.37     rpart_4.1.23      timechange_0.3.0 \n#&gt;  [9] lifecycle_1.0.4   survival_3.7-0    magrittr_2.0.3    compiler_4.4.2   \n#&gt; [13] sass_0.4.9        rlang_1.1.4       tools_4.4.2       gt_0.11.1        \n#&gt; [17] utf8_1.2.4        data.table_1.16.4 htmlwidgets_1.6.4 bit_4.5.0.1      \n#&gt; [21] mnormt_2.1.1      repr_1.1.7        xml2_1.3.6        withr_3.0.2      \n#&gt; [25] R.oo_1.27.0       nnet_7.3-19       grid_4.4.2        jomo_2.7-6       \n#&gt; [29] colorspace_2.1-1  iterators_1.0.14  MASS_7.3-64       cli_3.6.3        \n#&gt; [33] crayon_1.5.3      rmarkdown_2.29    generics_0.1.3    tzdb_0.4.0       \n#&gt; [37] commonmark_1.9.2  minqa_1.2.8       splines_4.4.2     parallel_4.4.2   \n#&gt; [41] base64enc_0.1-3   vctrs_0.6.5       boot_1.3-31       glmnet_4.1-8     \n#&gt; [45] Matrix_1.7-1      jsonlite_1.8.9    hms_1.1.3         bit64_4.5.2      \n#&gt; [49] mitml_0.4-5       foreach_1.5.2     glue_1.8.0        blastula_0.3.5   \n#&gt; [53] nloptr_2.1.1      pan_1.9           codetools_0.2-20  stringi_1.8.4    \n#&gt; [57] shape_1.4.6.1     gtable_0.3.6      lme4_1.1-35.5     munsell_0.5.1    \n#&gt; [61] pillar_1.10.1     htmltools_0.5.8.1 R6_2.5.1          rprojroot_2.0.4  \n#&gt; [65] vroom_1.6.5       evaluate_1.0.1    lattice_0.22-6    R.methodsS3_1.8.2\n#&gt; [69] backports_1.5.0   broom_1.0.7       Rcpp_1.0.13-1     nlme_3.1-166     \n#&gt; [73] xfun_0.50         pkgconfig_2.0.3",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#bibliografia",
    "href": "chapters/eda/02_data_cleaning.html#bibliografia",
    "title": "15¬† Flusso di lavoro per la pulizia dei dati",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBuchanan, E. M., Crain, S. E., Cunningham, A. L., Johnson, H. R., Stash, H., Papadatou-Pastou, M., Isager, P. M., Carlsson, R., & Aczel, B. (2021). Getting started creating data dictionaries: How to create a shareable data set. Advances in Methods and Practices in Psychological Science, 4(1), 2515245920928007.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html",
    "href": "chapters/eda/04_exploring_qualitative_data.html",
    "title": "16¬† Esplorare i dati qualitativi",
    "section": "",
    "text": "16.1 Introduzione\nIn questo capitolo ci concentreremo sull‚Äôanalisi dei dati qualitativi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#il-dataset-penguins",
    "href": "chapters/eda/04_exploring_qualitative_data.html#il-dataset-penguins",
    "title": "16¬† Esplorare i dati qualitativi",
    "section": "16.2 Il dataset penguins",
    "text": "16.2 Il dataset penguins\nPer fornire esempi pratici, in questo capitolo utilizzeremo il dataset palmerpenguins, messo a disposizione da Allison Horst. I dati sono stati raccolti e resi disponibili da Dr.¬†Kristen Gorman e dalla Palmer Station, parte del programma di ricerca ecologica a lungo termine Long Term Ecological Research Network. Il dataset contiene informazioni su 344 pinguini, appartenenti a 3 diverse specie, raccolte su 3 isole dell‚Äôarcipelago di Palmer, in Antartide. Per semplicit√†, i dati sono organizzati nel file penguins.csv.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#importare-i-dati",
    "href": "chapters/eda/04_exploring_qualitative_data.html#importare-i-dati",
    "title": "16¬† Esplorare i dati qualitativi",
    "section": "16.3 Importare i Dati",
    "text": "16.3 Importare i Dati\nPossiamo caricare i dati grezzi dal file penguins.csv in un DataFrame con il seguente comando:\n\nd &lt;- rio::import(here::here(\"data\", \"penguins.csv\"))\n\nEsaminiamo i dati.\n\nglimpse(d)\n#&gt; Rows: 344\n#&gt; Columns: 8\n#&gt; $ species           &lt;chr&gt; \"Adelie\", \"Adelie\", \"Adelie\", \"Adelie\", \"Adelie\"‚Ä¶\n#&gt; $ island            &lt;chr&gt; \"Torgersen\", \"Torgersen\", \"Torgersen\", \"Torgerse‚Ä¶\n#&gt; $ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34‚Ä¶\n#&gt; $ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18‚Ä¶\n#&gt; $ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190,‚Ä¶\n#&gt; $ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 34‚Ä¶\n#&gt; $ sex               &lt;chr&gt; \"male\", \"female\", \"female\", NA, \"female\", \"male\"‚Ä¶\n#&gt; $ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, ‚Ä¶\n\nPer semplicit√†, rimuoviamo le righe con valori mancanti con la seguente istruzione:\n\ndf &lt;- d |&gt;\n  drop_na()",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#tabelle-di-contingenza",
    "href": "chapters/eda/04_exploring_qualitative_data.html#tabelle-di-contingenza",
    "title": "16¬† Esplorare i dati qualitativi",
    "section": "16.4 Tabelle di Contingenza",
    "text": "16.4 Tabelle di Contingenza\nUna tabella di contingenza √® uno strumento utilizzato per riassumere i dati di due variabili categoriali, ovvero variabili qualitative che assumono valori all‚Äôinterno di un insieme finito di categorie. In una tabella di contingenza, ogni cella mostra quante volte si √® verificata una combinazione specifica di categorie per le due variabili considerate.\nPer esempio, se prendiamo in esame due variabili categoriali come ‚Äúisland‚Äù e ‚Äúspecies‚Äù all‚Äôinterno di un DataFrame df, ciascuna delle quali rappresenta rispettivamente l‚Äôisola di provenienza e la specie dei pinguini, possiamo costruire una tabella che mostra quante volte ciascuna combinazione di ‚Äúisland‚Äù e ‚Äúspecies‚Äù appare nel nostro campione. In altre parole, la tabella di contingenza ci permette di vedere quante osservazioni ci sono per ogni combinazione di categorie tra queste due variabili. Usiamo la funzione tably() del pacchetto janitor.\n\ndf |&gt; \n  tabyl(island, species) |&gt; \n  adorn_totals(c(\"row\", \"col\")) \n#&gt;     island Adelie Chinstrap Gentoo Total\n#&gt;     Biscoe     44         0    119   163\n#&gt;      Dream     55        68      0   123\n#&gt;  Torgersen     47         0      0    47\n#&gt;      Total    146        68    119   333\n\nQuesta tabella di contingenza mostra la distribuzione di tre specie di pinguini (Adelie, Chinstrap, Gentoo) rispetto a tre isole (Biscoe, Dream, Torgersen). Ogni cella rappresenta il numero di pinguini di una determinata specie presenti su ciascuna isola. Ecco un‚Äôinterpretazione dettagliata:\n\nIsola Biscoe: Qui troviamo 44 pinguini della specie Adelie e 119 pinguini della specie Gentoo, mentre non sono presenti pinguini Chinstrap.\nIsola Dream: Questa isola ospita 55 pinguini Adelie e 68 pinguini Chinstrap, ma nessun pinguino della specie Gentoo.\nIsola Torgersen: Su quest‚Äôisola sono presenti solo 47 pinguini della specie Adelie, e nessun pinguino delle specie Chinstrap o Gentoo.\n\nPossiamo commentare dicendo:\n\nLa specie Adelie √® distribuita su tutte e tre le isole, con numeri notevoli sia su Biscoe (44), Dream (55), che Torgersen (47).\nLa specie Chinstrap si trova solo sull‚Äôisola Dream (68 esemplari) e non √® presente sulle altre due isole.\nLa specie Gentoo si trova esclusivamente sull‚Äôisola Biscoe (119 esemplari), non essendo presente su Dream e Torgersen.\n\nQuesto suggerisce una distribuzione geografica specifica delle diverse specie di pinguini, con alcune specie limitate a determinate isole e altre distribuite pi√π ampiamente.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#test-del-chi-quadrato",
    "href": "chapters/eda/04_exploring_qualitative_data.html#test-del-chi-quadrato",
    "title": "16¬† Esplorare i dati qualitativi",
    "section": "16.5 Test del Chi-Quadrato",
    "text": "16.5 Test del Chi-Quadrato\nUna tabella di contingenza, che include i totali marginali e i valori delle celle, ci permette di formulare una domanda fondamentale: ‚ÄúCome apparirebbe la tabella di contingenza se non ci fosse alcuna relazione tra le due variabili, ovvero la variabile riga e la variabile colonna?‚Äù.\nCome gi√† visto in precedenza analizzando la distribuzione di probabilit√† congiunta, si ha indipendenza quando le probabilit√† congiunte sono uguali al prodotto delle probabilit√† marginali. Partendo dalle proporzioni marginali, possiamo quindi calcolare i valori teorici attesi in ciascuna cella della tabella di contingenza, assumendo che le due variabili siano indipendenti.\nVa sottolineato che l‚Äôindipendenza √® una propriet√† della popolazione, non del campione. Pertanto, nei dati campionari, ci aspettiamo che i valori osservati nelle celle della tabella differiscano leggermente dai valori teorici attesi, anche se nella popolazione le variabili sono realmente indipendenti. La discrepanza complessiva tra i valori osservati e quelli attesi, calcolati sotto l‚Äôipotesi di indipendenza, pu√≤ essere misurata utilizzando una statistica chiamata Chi-Quadrato (\\(\\chi^2\\)).\nLa formula della statistica Chi-Quadrato √®:\n\\[\n\\chi^2 = \\sum \\frac{(O_i - E_i)^2}{E_i} ,\n\\]\ndove:\n\n\\(O_i\\) rappresenta i valori osservati nelle celle della tabella,\n\n\\(E_i\\) rappresenta i valori attesi nelle celle, calcolati sotto l‚Äôipotesi di indipendenza,\n\nLa somma (\\(\\sum\\)) viene effettuata su tutte le celle della tabella.\n\n\n16.5.1 Interpretazione della Statistica Chi-Quadrato\nLa statistica Chi-Quadrato misura la discrepanza complessiva tra i valori osservati e quelli attesi. Se non ci fosse differenza tra i valori congiunti osservati e quelli teorici, la statistica Chi-Quadrato sarebbe pari a zero. All‚Äôaumentare della discrepanza tra valori osservati e attesi, il valore della statistica Chi-Quadrato aumenta.\nPer valutare l‚Äôimportanza della discrepanza osservata, utilizziamo la distribuzione campionaria della statistica Chi-Quadrato. Questa distribuzione descrive la probabilit√† di ottenere valori della statistica Chi-Quadrato sotto l‚Äôipotesi nulla (indipendenza tra le variabili). La forma della distribuzione dipende dai gradi di libert√† (\\(\\nu\\)), che si calcolano come:\n\\[\n\\nu = (n_{\\text{righe}} - 1)(n_{\\text{colonne}} - 1) ,\n\\]\ndove \\(n_{\\text{righe}}\\) e \\(n_{\\text{colonne}}\\) rappresentano rispettivamente il numero di righe e colonne della tabella di contingenza.\n\n\n16.5.2 Valutazione dell‚ÄôIpotesi di Indipendenza\nLa probabilit√† associata a una data discrepanza (\\(\\chi^2\\)) tra valori osservati e attesi, assumendo che l‚Äôipotesi nulla sia vera, corrisponde all‚Äôarea sotto la coda destra della distribuzione Chi-Quadrato, nell‚Äôintervallo [\\(C\\), \\(+\\infty\\)]. Questa probabilit√† √® indicata come \\(p\\)-value.\nSe il \\(p\\)-value √® molto piccolo (tipicamente inferiore a una soglia predefinita, come 0.05), possiamo rifiutare l‚Äôipotesi nulla e concludere che √® improbabile che le due variabili siano indipendenti nella popolazione.\n\n\n16.5.3 Riepilogo dei Passaggi del Test Chi-Quadrato\n\nCalcolo dei Valori Attesi: Per ogni cella, calcola \\(E_i\\) utilizzando la formula:\n\\[\nE_i = \\frac{\\text{Totale della Riga} \\times \\text{Totale della Colonna}}{\\text{Totale Complessivo}}\n\\]\nCalcolo della Statistica Chi-Quadrato: Usa la formula:\n\\[\n\\chi^2 = \\sum \\frac{(O_i - E_i)^2}{E_i}\n\\]\nDeterminazione dei Gradi di Libert√†: Calcola \\(\\nu\\) come \\((n_{\\text{righe}} - 1)(n_{\\text{colonne}} - 1)\\).\nConfronto con la Distribuzione Chi-Quadrato: Determina il \\(p\\)-value associato al valore di \\(\\chi^2\\) calcolato e valuta l‚Äôipotesi nulla.\n\nIn conclusione, il Test Chi-Quadrato rappresenta uno strumento importante per verificare l‚Äôindipendenza tra due variabili categoriali. Grazie alla sua semplicit√† di applicazione e interpretazione, costituisce un metodo di analisi largamente utilizzato in ambito psicologico, sociale e statistico. Tuttavia, √® importante prestare attenzione ai presupposti del test, come la sufficienza dei dati in ogni cella, per garantire risultati affidabili e interpretabili.\n\n# Creare la tabella di contingenza\nobserved &lt;- matrix(c(44, 0, 119, \n                              55, 68, 0, \n                              47, 0, 0),\n                            nrow = 3, byrow = TRUE)\n\n# Aggiungere i nomi di righe e colonne\nrownames(observed) &lt;- c(\"Biscoe\", \"Dream\", \"Torgersen\")\ncolnames(observed) &lt;- c(\"Adelie\", \"Chinstrap\", \"Gentoo\")\n\n# Visualizzare la tabella\nprint(observed)\n#&gt;           Adelie Chinstrap Gentoo\n#&gt; Biscoe        44         0    119\n#&gt; Dream         55        68      0\n#&gt; Torgersen     47         0      0\n\n\nchi_square_result &lt;- chisq.test(observed)\nchi_square_result\n#&gt; \n#&gt;  Pearson's Chi-squared test\n#&gt; \n#&gt; data:  observed\n#&gt; X-squared = 285, df = 4, p-value &lt;2e-16\n\nSvolgiamo i calcoli ‚Äúa mano‚Äù usando R. Per calcolare la statistica del test del Chi-Quadrato ‚Äúa mano‚Äù in R, segui questi passaggi:\nCalcoliamo i totali per righe e colonne e il totale complessivo.\n\n# Totali marginali\nrow_totals &lt;- rowSums(observed)\ncol_totals &lt;- colSums(observed)\ngrand_total &lt;- sum(observed)\n\n# Visualizzare i totali\nprint(\"Totali marginali per righe:\")\n#&gt; [1] \"Totali marginali per righe:\"\nprint(row_totals)\n#&gt;    Biscoe     Dream Torgersen \n#&gt;       163       123        47\nprint(\"Totali marginali per colonne:\")\n#&gt; [1] \"Totali marginali per colonne:\"\nprint(col_totals)\n#&gt;    Adelie Chinstrap    Gentoo \n#&gt;       146        68       119\nprint(paste(\"Totale complessivo:\", grand_total))\n#&gt; [1] \"Totale complessivo: 333\"\n\nI valori attesi si calcolano come:\n\\[\nE_{ij} = \\frac{\\text{Totale riga} \\times \\text{Totale colonna}}{\\text{Totale complessivo}} .\n\\]\n\n# Calcolo dei valori attesi\nexpected &lt;- outer(row_totals, col_totals) / grand_total\n\n# Visualizzare i valori attesi\nprint(\"Valori attesi:\")\n#&gt; [1] \"Valori attesi:\"\nprint(expected)\n#&gt;           Adelie Chinstrap Gentoo\n#&gt; Biscoe      71.5      33.3   58.2\n#&gt; Dream       53.9      25.1   44.0\n#&gt; Torgersen   20.6       9.6   16.8\n\nLa statistica Chi-Quadrato si calcola con:\n\\[\n\\chi^2 = \\sum \\frac{(O_{ij} - E_{ij})^2}{E_{ij}} .\n\\]\n\n# Calcolo della statistica Chi-Quadrato\nchi_square_stat &lt;- sum((observed - expected)^2 / expected)\n\n# Visualizzare il risultato\nprint(paste(\"Statistica Chi-Quadrato:\", chi_square_stat))\n#&gt; [1] \"Statistica Chi-Quadrato: 284.590012688092\"\n\nI gradi di libert√† si calcolano come:\n\\[\ndof = (\\text{n. righe} - 1) \\times (\\text{n. colonne} - 1) .\n\\]\n\n# Calcolo dei gradi di libert√†\ndof &lt;- (nrow(observed) - 1) * (ncol(observed) - 1)\n\n# Visualizzare i gradi di libert√†\nprint(paste(\"Gradi di libert√†:\", dof))\n#&gt; [1] \"Gradi di libert√†: 4\"\n\nConfrontiamo la statistica Chi-Quadrato con la distribuzione teorica per ottenere il p-value.\n\n# Calcolo del p-value\np_value &lt;- pchisq(chi_square_stat, df = dof, lower.tail = FALSE)\n\n# Visualizzare il p-value\nprint(paste(\"p-value:\", p_value))\n#&gt; [1] \"p-value: 2.28189154098739e-60\"\n\nInterpretazione:\nIl valore-\\(p\\) risulta molto piccolo, indicando che, se le variabili Isola e Specie fossero realmente indipendenti, sarebbe estremamente improbabile osservare una distribuzione delle specie di pinguini sulle tre isole cos√¨ diversa da quella teoricamente attesa. In altre parole, il valore-\\(p\\) rappresenta la probabilit√† di ottenere, per puro caso, una discrepanza tra i valori osservati e quelli attesi pari o superiore a quella riscontrata nei dati.\nPoich√© il valore-\\(p\\) √® estremamente basso, possiamo concludere che l‚Äôipotesi di indipendenza tra le variabili Isola e Specie non √® plausibile. Questo indica che la distribuzione delle specie di pinguini varia in relazione all‚Äôisola, ovvero che conoscendo l‚Äôisola √® possibile prevedere la distribuzione delle specie. In altre parole, le variabili Isola e Specie sono associate.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#grafico-a-barre",
    "href": "chapters/eda/04_exploring_qualitative_data.html#grafico-a-barre",
    "title": "16¬† Esplorare i dati qualitativi",
    "section": "16.6 Grafico a barre",
    "text": "16.6 Grafico a barre\n\n16.6.1 Grafico a Barre con una Singola Variabile\nUn grafico a barre √® uno strumento comunemente utilizzato per rappresentare visivamente una singola variabile categoriale. Questo tipo di grafico mostra le diverse categorie su uno degli assi (solitamente l‚Äôasse orizzontale) e utilizza barre di altezza proporzionale per rappresentare la frequenza o il conteggio di ciascuna categoria sull‚Äôaltro asse (solitamente l‚Äôasse verticale).\nAd esempio, in un dataset che contiene informazioni su diverse specie di pinguini, un grafico a barre potrebbe mostrare il numero di pinguini per ciascuna specie. Le specie vengono visualizzate come etichette lungo l‚Äôasse delle ascisse, mentre l‚Äôaltezza delle barre rappresenta il numero di pinguini osservati per ciascuna specie.\nIl grafico a barre consente di confrontare le dimensioni delle categorie in modo semplice e intuitivo.\nPer i dati in esame, creiamo un grafico a barre che rappresenta il numero totale di pinguini per isola.\n\nggplot(df, aes(x = island)) +\n  geom_bar(fill = palette_okabe_enhanced[1]) +\n  ggtitle(\"Numero totale di pinguini per isola\") +\n  xlab(\"Isola\") +\n  ylab(\"Numero di pinguini\") +\n  scale_fill_okabe_ito(order = c(5,1,3,4,2,6,7,8,9))\n\n\n\n\n\n\n\n\nUn secondo grafico a barre mostra il numero totale di pinguini per specie.\n\nggplot(df, aes(x = species)) +\n  geom_bar(fill = palette_okabe_enhanced[1]) +\n  ggtitle(\"Numero totale di pinguini per specie\") +\n  xlab(\"Specie\") +\n  ylab(\"Numero di pinguini\")\n\n\n\n\n\n\n\n\n\n\n16.6.2 Grafico a Barre con Due Variabili\n√à possibile visualizzare contemporaneamente le distribuzioni di due variabili categoriali utilizzando un grafico a barre. Questo tipo di grafico √® particolarmente utile per esaminare la relazione tra due variabili categoriali.\nIn un grafico a barre con due variabili, una delle variabili viene rappresentata sull‚Äôasse orizzontale come categoria principale, mentre la seconda variabile √® distinta tramite colori diversi o barre impilate. In questo modo, possiamo confrontare facilmente le frequenze o le proporzioni delle categorie della prima variabile, osservando allo stesso tempo come sono distribuite le categorie della seconda variabile all‚Äôinterno di ciascuna categoria principale.\nAd esempio, visualizziamo il numero di pinguini per specie e isola. A qusto fine possiamo creare un grafico a barre dove le isole sono rappresentate sull‚Äôasse delle ascisse e i diversi colori delle barre mostrano la distribuzione delle specie su ciascuna isola. Questo approccio consente di esplorare come le due variabili categoriali (specie e isola) interagiscono visivamente.\n\nggplot(df, aes(x = island, fill = species)) +\n  geom_bar(position = \"stack\") +\n  scale_fill_okabe_ito(order = c(5,1,3,4,2,6,7,8,9)) +\n  ggtitle(\"Numero di pinguini per specie e isola\") +\n  xlab(\"Isola\") +\n  ylab(\"Numero di pinguini\") +\n  labs(fill = \"Specie\")\n\n\n\n\n\n\n\n\nIn alternativa, √® possibile creare un grafico a barre dove le specie sono rappresentate sull‚Äôasse delle ascisse e i diversi colori delle barre mostrano la distribuzione delle isole per ciascuna specie.\n\nggplot(df, aes(x = species, fill = island)) +\n  geom_bar(position = \"stack\") +\n  scale_fill_okabe_ito(order = c(5,1,3,4,2,6,7,8,9)) +\n  ggtitle(\"Numero di pinguini per isola e specie\") +\n  xlab(\"Specie\") +\n  ylab(\"Numero di pinguini\") +\n  labs(fill = \"Isola\")\n\n\n\n\n\n\n\n\nIn alternativa all‚Äôuso delle frequenze assolute, possiamo rappresentare i dati utilizzando le frequenze relative. Questo approccio permette di confrontare meglio le categorie indipendentemente dal numero totale di osservazioni. Nella figura seguente, ad esempio, viene mostrata la proporzione di pinguini di ciascuna specie per ogni isola, evidenziando la distribuzione relativa delle specie su ogni isola, anzich√© il conteggio assoluto. Questa rappresentazione aiuta a visualizzare le differenze nella composizione delle specie, anche se il numero complessivo di pinguini varia tra le isole.\n\nggplot(df, aes(x = island, fill = species)) +\n  geom_bar(position = \"fill\") +\n   scale_fill_okabe_ito(order = c(5,1,3,4,2,6,7,8,9)) +\n  ggtitle(\"Proporzione di pinguini per specie e isola\") +\n  xlab(\"Isola\") +\n  ylab(\"Proporzione\") +\n  labs(fill = \"Specie\")",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#mosaic-plots",
    "href": "chapters/eda/04_exploring_qualitative_data.html#mosaic-plots",
    "title": "16¬† Esplorare i dati qualitativi",
    "section": "16.7 Mosaic plots",
    "text": "16.7 Mosaic plots\nIl Mosaic plot √® una tecnica di visualizzazione particolarmente adatta per rappresentare tabelle di contingenza. Questo tipo di grafico somiglia a un grafico a barre impilate standard, ma con un vantaggio importante: oltre a visualizzare la suddivisione interna delle categorie, permette di vedere anche le dimensioni relative dei gruppi della variabile principale.\nIn altre parole, il Mosaic plot non solo mostra come si distribuiscono le categorie di una variabile secondaria all‚Äôinterno di ogni gruppo della variabile principale, ma fornisce anche un‚Äôidea visiva della grandezza complessiva dei gruppi. Questo lo rende uno strumento utile per analizzare e interpretare le relazioni tra due variabili categoriali, evidenziando sia la proporzione all‚Äôinterno di ciascun gruppo, sia la grandezza relativa tra i gruppi stessi.\n\nmosaic(\n  ~ species + island, \n  data = df, \n  main = \"Mosaic Plot of Species and Island\",\n  shade = TRUE\n)\n\n\n\n\n\n\n\n\n\nisland: Variabile rappresentata come suddivisione orizzontale all‚Äôinterno di ogni gruppo di species (variabile principale).\nspecies: Variabile rappresentata lungo l‚Äôasse verticale (variabile secondaria suddivisa all‚Äôinterno di ogni gruppo di island).\n\n\n16.7.0.1 Interpretazione\n\nDimensione dei Rettangoli:\n\nLa larghezza dei rettangoli corrisponde alla dimensione relativa dei gruppi della variabile island.\nL‚Äôaltezza dei rettangoli rappresenta la proporzione delle categorie di species all‚Äôinterno di ciascun gruppo di island.\n\nColorazione (se shade = TRUE):\n\nI colori indicano deviazioni rispetto all‚Äôindipendenza statistica tra le variabili.\nUn rettangolo scuro rappresenta una frequenza maggiore o minore di quella attesa in caso di indipendenza tra species e island.\n\nOsservazioni Specifiche:\n\nRettangoli alti e larghi: Indicano una categoria di species molto rappresentata su un‚Äôisola specifica.\nRettangoli sottili o stretti: Indicano una rappresentazione meno significativa o assente di una specie su un‚Äôisola.\n\n\nIn conclusione, il Mosaic plot √® uno strumento grafico efficace per analizzare le relazioni tra due variabili categoriali. Ti permette di esplorare:\n\nLa proporzione interna delle categorie.\nLe dimensioni relative dei gruppi della variabile principale.\n\nQuesto grafico √® particolarmente utile per individuare schemi o associazioni, come una specie predominante su un‚Äôisola specifica o una distribuzione equilibrata tra gruppi. La sua rappresentazione intuitiva lo rende ideale per ricerche in psicologia, scienze sociali e biologia.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#proporzioni-di-riga-e-colonna",
    "href": "chapters/eda/04_exploring_qualitative_data.html#proporzioni-di-riga-e-colonna",
    "title": "16¬† Esplorare i dati qualitativi",
    "section": "16.8 Proporzioni di Riga e Colonna",
    "text": "16.8 Proporzioni di Riga e Colonna\nNelle sezioni precedenti abbiamo esaminato la visualizzazione di due variabili categoriali utilizzando grafici a barre e Mosaic plot. Tuttavia, non abbiamo ancora discusso come vengono calcolate le proporzioni mostrate in questi grafici. In questa sezione ci concentreremo sulla suddivisione frazionaria di una variabile rispetto a un‚Äôaltra, esplorando come possiamo modificare la nostra tabella di contingenza per ottenere una visione pi√π dettagliata delle proporzioni.\nQuesto ci permetter√† di comprendere meglio le relazioni tra le due variabili, visualizzando non solo i conteggi assoluti, ma anche le proporzioni relative per riga o per colonna. Le proporzioni di riga mostrano la distribuzione di una variabile all‚Äôinterno delle categorie di un‚Äôaltra, mentre le proporzioni di colonna evidenziano la distribuzione inversa.\nCalcoliamo le proporzioni di specie per isola.\n\ndf %&gt;%\n  tabyl(island, species) %&gt;%  # Crea la tabella di contingenza\n  adorn_percentages(\"row\") %&gt;%  # Calcola le proporzioni per riga\n  adorn_totals(\"col\") %&gt;%  # Aggiunge la colonna dei totali\n  adorn_pct_formatting(digits = 2)  # Formatta le percentuali con 2 decimali\n#&gt;     island  Adelie Chinstrap Gentoo   Total\n#&gt;     Biscoe  26.99%     0.00% 73.01% 100.00%\n#&gt;      Dream  44.72%    55.28%  0.00% 100.00%\n#&gt;  Torgersen 100.00%     0.00%  0.00% 100.00%\n\nCalcoliamo nuovamente le proporzioni, ma questa volta in funzione delle colonne (per isola).\n\ndf |&gt; \n  tabyl(island, species) |&gt; \n  adorn_percentages(\"col\") |&gt; \n  adorn_totals(\"row\") |&gt; \n  adorn_pct_formatting(digits = 2) # Formatta le percentuali con 2 decimali\n#&gt;     island  Adelie Chinstrap  Gentoo\n#&gt;     Biscoe  30.14%     0.00% 100.00%\n#&gt;      Dream  37.67%   100.00%   0.00%\n#&gt;  Torgersen  32.19%     0.00%   0.00%\n#&gt;      Total 100.00%   100.00% 100.00%",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#confronto-tra-gruppi",
    "href": "chapters/eda/04_exploring_qualitative_data.html#confronto-tra-gruppi",
    "title": "16¬† Esplorare i dati qualitativi",
    "section": "16.9 Confronto tra Gruppi",
    "text": "16.9 Confronto tra Gruppi\nAlcune delle analisi pi√π interessanti emergono confrontando i dati numerici tra diversi gruppi. In questa sezione approfondiremo alcune delle tecniche che abbiamo gi√† esplorato per visualizzare i dati numerici di pi√π gruppi su uno stesso grafico e introdurremo nuovi metodi per confrontare i dati numerici tra gruppi. Queste tecniche ci permetteranno di osservare meglio le differenze e le somiglianze tra gruppi, mettendo in evidenza tendenze, variazioni e altre caratteristiche rilevanti.\nQui consideriamo due variabili qualitative. Creiamo un grafico a barre per confrontare la distribuzione del genere per specie.\n\nggplot(df, aes(x = species, fill = sex)) +\n  geom_bar(position = \"dodge\") +\n  scale_fill_okabe_ito(order = c(5,1,3,4,2,6,7,8,9)) +\n  ggtitle(\"Distribuzione del genere per specie\") +\n  xlab(\"Specie\") +\n  ylab(\"Conteggio\")\n\n\n\n\n\n\n\n\nSpesso, i confronti pi√π interessanti riguardano come una variabile numerica varia in base a una o pi√π categorie. Questo tipo di analisi ci aiuta a capire differenze tra gruppi e a individuare modelli o tendenze.\nNel grafico seguente, confrontiamo la distribuzione del peso corporeo (body_mass_g) in base alla specie e al genere. Le aree colorate rappresentano come si distribuisce il peso per maschi e femmine all‚Äôinterno di ciascuna specie. Le linee pi√π strette al centro delle aree colorate aggiungono ulteriori dettagli, mostrando i valori pi√π comuni e come si concentrano i dati per ciascun gruppo.\n\nggplot(df, aes(x = species, y = body_mass_g, fill = sex)) +\n  geom_violin(\n    position = position_dodge(width = 0.9), alpha = 0.5\n  ) +\n  geom_boxplot(\n    position = position_dodge(width = 0.9), width = 0.2, alpha = 0.8\n  ) +\n  scale_fill_okabe_ito(order = c(5,1,3,4,2,6,7,8,9)) +\n  ggtitle(\n    \"Distribuzione della massa corporea\\nin base alla specie e al genere\"\n  ) +\n  xlab(\"Specie\") +\n  ylab(\"Massa corporea (g)\") +\n  labs(fill = \"Genere\")\n\n\n\n\n\n\n\n\n\nAree colorate (grafico a violino):\n\nRappresentano l‚Äôintera distribuzione dei pesi per ogni gruppo (specie e genere). Pi√π l‚Äôarea √® larga in un punto, maggiore √® il numero di pinguini con quel peso.\n\nLinee strette al centro (boxplot):\n\nForniscono un riassunto visivo dei dati, mostrando dove i pesi si concentrano maggiormente e quanto variano all‚Äôinterno di ciascun gruppo.\n\nCosa possiamo osservare:\n\nPossiamo vedere facilmente se i maschi e le femmine di una stessa specie tendono ad avere pesi simili o differenti, e se c‚Äô√® una certa sovrapposizione tra i due gruppi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/04_exploring_qualitative_data.html#informazioni-sullambiente-di-sviluppo",
    "title": "16¬† Esplorare i dati qualitativi",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: US/Pacific\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] grid      stats     graphics  grDevices utils     datasets  methods  \n#&gt; [8] base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] janitor_2.2.1     vcd_1.4-13        viridis_0.6.5     viridisLite_0.4.2\n#&gt;  [5] ggokabeito_0.1.0  see_0.9.0         gridExtra_2.3     patchwork_1.3.0  \n#&gt;  [9] bayesplot_1.11.1  psych_2.4.12      scales_1.3.0      markdown_1.13    \n#&gt; [13] knitr_1.49        lubridate_1.9.4   forcats_1.0.0     stringr_1.5.1    \n#&gt; [17] dplyr_1.1.4       purrr_1.0.2       readr_2.1.5       tidyr_1.3.1      \n#&gt; [21] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [25] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      xfun_0.50         htmlwidgets_1.6.4 lattice_0.22-6   \n#&gt;  [5] tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2       generics_0.1.3   \n#&gt;  [9] parallel_4.4.2    pacman_0.5.1      pkgconfig_2.0.3   R.oo_1.27.0      \n#&gt; [13] data.table_1.16.4 lifecycle_1.0.4   compiler_4.4.2    farver_2.1.2     \n#&gt; [17] munsell_0.5.1     mnormt_2.1.1      snakecase_0.11.1  htmltools_0.5.8.1\n#&gt; [21] pillar_1.10.1     MASS_7.3-64       R.utils_2.12.3    nlme_3.1-166     \n#&gt; [25] tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4     labeling_0.4.3   \n#&gt; [29] rprojroot_2.0.4   fastmap_1.2.0     colorspace_2.1-1  cli_3.6.3        \n#&gt; [33] magrittr_2.0.3    withr_3.0.2       timechange_0.3.0  rmarkdown_2.29   \n#&gt; [37] zoo_1.8-12        R.methodsS3_1.8.2 hms_1.1.3         evaluate_1.0.1   \n#&gt; [41] lmtest_0.9-40     rlang_1.1.4       glue_1.8.0        jsonlite_1.8.9   \n#&gt; [45] R6_2.5.1",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html",
    "href": "chapters/eda/05_exploring_numeric_data.html",
    "title": "17¬† Esplorare i dati numerici",
    "section": "",
    "text": "Introduzione\nIn questo capitolo ci concentreremo sull‚Äôanalisi dei dati numerici. In particolare, esamineremo le distribuzioni di frequenza e i quantili, insieme alle tecniche di visualizzazione pi√π comuni, come l‚Äôistogramma, l‚Äôistogramma smussato e il box-plot. Tratteremo sia gli aspetti computazionali che quelli interpretativi di queste misure, fornendo strumenti utili non solo per una comprensione personale, ma anche per la comunicazione efficace dei risultati, in particolare con chi utilizza questi dati per prendere decisioni pratiche nel mondo reale.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#i-dati-sulle-aspettative-negative-nella-depressione",
    "href": "chapters/eda/05_exploring_numeric_data.html#i-dati-sulle-aspettative-negative-nella-depressione",
    "title": "17¬† Esplorare i dati numerici",
    "section": "17.1 I dati sulle aspettative negative nella depressione",
    "text": "17.1 I dati sulle aspettative negative nella depressione\nConsideriamo i dati relativi alle aspettative negative, individuate come un meccanismo chiave nel mantenimento della depressione (Zetsche et al., 2019). Supponiamo di voler analizzare la distribuzione di una singola variabile quantitativa.\nImportiamo i dati:\n\ndf = rio::import(here::here(\"data\", \"data.mood.csv\"))\n\nPer questo esercizio, ci concentreremo sulle colonne esm_id (il codice del soggetto), group (il gruppo) e bdi (il valore BDI-II).\n\ndf &lt;- df |&gt; \n  dplyr::select(\"esm_id\", \"group\", \"bdi\")\ndf |&gt; \n  head()\n#&gt;   esm_id group bdi\n#&gt; 1     10   mdd  25\n#&gt; 2     10   mdd  25\n#&gt; 3     10   mdd  25\n#&gt; 4     10   mdd  25\n#&gt; 5     10   mdd  25\n#&gt; 6     10   mdd  25\n\nSe elenchiamo le modalit√† presenti in group utilizzando il metodo unique(), scopriamo che corrispondono a mdd (pazienti) e ctl (controlli sani).\n\ndf$group |&gt; \n  unique()\n#&gt; [1] \"mdd\" \"ctl\"\n\nRimuoviamo i duplicati per ottenere un unico valore BDI-II per ogni soggetto:\n\ndf &lt;- df[!duplicated(df), ]\n\nVerifichiamo di avere ottenuto il risultato desiderato.\n\ndim(df)\n#&gt; [1] 67  3\n\n\nhead(df)\n#&gt;    esm_id group bdi\n#&gt; 1      10   mdd  25\n#&gt; 15      9   mdd  30\n#&gt; 30      6   mdd  26\n#&gt; 46      7   mdd  35\n#&gt; 65     12   mdd  44\n#&gt; 83     16   mdd  30\n\nSi noti che il nuovo DataFrame (con 67 righe) conserva il ‚Äúnome‚Äù delle righe (ovvero, l‚Äôindice di riga) del DataFrame originario (con 1188 righe). Per esempio, il secondo soggetto (con codice identificativo 9) si trova sulla seconda riga del DataFrame, ma il suo indice di riga √® 15. Questo non ha nessuna conseguenza perch√© non useremo l‚Äôindice di riga nelle analisi seguenti.\nEliminiamo eventuali valori mancanti:\n\ndf &lt;- df[!is.na(df$bdi), ]\n\nOtteniamo cos√¨ il DataFrame finale per gli scopi presenti (66 righe e 3 colonne):\n\ndim(df)\n#&gt; [1] 66  3\n\nStampiamo i valori BDI-II presentandoli ordinati dal pi√π piccolo al pi√π grande:\n\ndf$bdi |&gt; \n  sort()\n#&gt;  [1]  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  1  1  1  1  1  1\n#&gt; [25]  1  2  2  2  2  3  3  3  5  7  9 12 19 22 22 24 25 25 26 26 26 27 27 28\n#&gt; [49] 28 30 30 30 31 31 33 33 34 35 35 35 36 39 41 43 43 44\n\nNel linguaggio statistico, un‚Äôosservazione rappresenta l‚Äôinformazione raccolta da un singolo individuo o entit√† che partecipa allo studio. Nel caso del dataset utilizzato da Zetsche et al. (2019), l‚Äôunit√† di osservazione √® costituita dai partecipanti allo studio. Ogni riga del DataFrame, denominato df, corrisponde quindi a un individuo distinto incluso nell‚Äôanalisi.\nLe variabili, invece, riflettono le diverse caratteristiche degli individui o delle entit√† considerate. Per i dati in esame, questo concetto si esprime cos√¨:\n\nOgni colonna di df rappresenta una variabile che descrive una specifica propriet√† comune ai partecipanti.\nLe variabili sono identificate da etichette nelle colonne, come esa_id (l‚Äôidentificativo del soggetto), mdd (il gruppo di appartenenza), e bdi (il punteggio del test BDI-II).\n\nIn termini simbolisi, per indicare una singola osservazione della variabile generica \\(X\\), si utilizza la notazione \\(X_i\\), dove \\(i\\) rappresenta l‚Äôindice dell‚Äôosservazione. Questo implica che abbiamo un valore diverso di \\(X\\) per ogni differente \\(i\\). Nel caso presente, con 67 osservazioni, \\(i\\) varia da 1 a 67. Cos√¨, per rappresentare la seconda osservazione (quella con \\(i=2\\)), useremo la notazione \\(X_2\\).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#distribuzioni-di-frequenza",
    "href": "chapters/eda/05_exploring_numeric_data.html#distribuzioni-di-frequenza",
    "title": "17¬† Esplorare i dati numerici",
    "section": "17.2 Distribuzioni di frequenza",
    "text": "17.2 Distribuzioni di frequenza\nCome osservato nell‚Äôoutput della sezione precedente, i dati grezzi non forniscono un‚Äôinterpretazione immediata. Per rendere i dati pi√π comprensibili e sintetici, √® utile costruire una distribuzione di frequenza.\nUna distribuzione di frequenza mostra quante volte i valori di una variabile si verificano all‚Äôinterno di intervalli specifici. Nel caso dei punteggi BDI-II, possiamo raggruppare i punteggi in quattro classi:\n\n0‚Äì13: depressione minima\n14‚Äì19: depressione lieve-moderata\n20‚Äì28: depressione moderata-severa\n29‚Äì63: depressione severa\n\nOgni classe, denotata come \\(\\Delta_i\\), rappresenta un intervallo di valori, definito come \\([a_i, b_i)\\) (aperto a destra) o \\((a_i, b_i]\\) (aperto a sinistra), dove \\(a_i\\) e \\(b_i\\) sono rispettivamente il limite inferiore e superiore della classe. A ciascuna classe si associa un‚Äôampiezza, data da \\(b_i - a_i\\), e un valore centrale, indicato con \\(\\bar{x}_i\\). Poich√© ogni osservazione \\(x_i\\) appartiene a una sola classe \\(\\Delta_i\\), possiamo calcolare le seguenti quantit√†:\n\nFrequenza assoluta \\(n_i\\): il numero di osservazioni che rientrano nella classe \\(\\Delta_i\\).\n\nPropriet√†: \\(n_1 + n_2 + \\dots + n_m = n\\), dove \\(n\\) √® il numero totale di osservazioni.\n\nFrequenza relativa \\(f_i\\): la proporzione di osservazioni in ciascuna classe, calcolata come \\(f_i = n_i/n\\).\n\nPropriet√†: \\(f_1 + f_2 + \\dots + f_m = 1\\).\n\nFrequenza cumulata \\(N_i\\): il numero totale di osservazioni che rientrano nelle classi fino alla \\(i\\)-esima inclusa, calcolata come \\(N_i = \\sum_{j=1}^i n_j\\).\nFrequenza cumulata relativa \\(F_i\\): la somma delle frequenze relative fino alla \\(i\\)-esima classe, data da \\(F_i = \\frac{N_i}{n} = \\sum_{j=1}^i f_j\\).\n\nQueste misure permettono di riassumere in modo efficace la distribuzione dei punteggi e facilitano l‚Äôinterpretazione delle caratteristiche del campione.\n\n17.2.1 Frequenze Assolute e Relative\nPer ottenere la distribuzione di frequenza assoluta e relativa dei valori BDI-II nel dataset di zetsche_2019future, √® necessario aggiungere al DataFrame df una colonna contenente una variabile categoriale che classifichi ciascuna osservazione in una delle quattro classi che descrivono la gravit√† della depressione. Questo risultato si ottiene utilizzando la funzione cut().\nNella funzione cut():\n\nIl primo argomento, x, √® un vettore unidimensionale (ad esempio, un vettore di tipo numeric o una colonna di un DataFrame) che contiene i dati da classificare.\nIl secondo argomento, breaks, definisce gli intervalli delle classi, specificandone i limiti inferiori e superiori.\nL‚Äôargomento include.lowest = TRUE garantisce che il limite inferiore dell‚Äôintervallo pi√π basso sia incluso nella classificazione. Nel nostro caso, questo √® particolarmente utile per assicurare che i valori uguali al limite inferiore siano assegnati correttamente.\n\nDi seguito, il codice per aggiungere la variabile categoriale al DataFrame:\n\n# Creare una variabile categoriale per classi di depressione\ndf &lt;- df %&gt;% \n  mutate(\n    bdi_class = cut(\n      bdi, \n      breaks = c(0, 13.5, 19.5, 28.5, 63),\n      include.lowest = TRUE\n    )\n  )\n\nQuesto codice suddivide i valori della variabile bdi in quattro intervalli corrispondenti ai livelli di gravit√† della depressione:\n\n0‚Äì13: depressione minima\n14‚Äì19: depressione lieve-moderata\n20‚Äì28: depressione moderata-severa\n29‚Äì63: depressione severa\n\nOgni osservazione verr√† assegnata al corrispondente intervallo, creando cos√¨ una nuova colonna bdi_class nel DataFrame df.\n\n17.2.1.1 Frequenze assolute\n\ntable(df$bdi_class)\n#&gt; \n#&gt;    [0,13.5] (13.5,19.5] (19.5,28.5]   (28.5,63] \n#&gt;          36           1          12          17\n\n\n\n17.2.1.2 Frequenze relative\n\nprop.table(table(df$bdi_class))\n#&gt; \n#&gt;    [0,13.5] (13.5,19.5] (19.5,28.5]   (28.5,63] \n#&gt;      0.5455      0.0152      0.1818      0.2576\n\n\n\n\n17.2.2 Distribuzioni congiunte\nLe variabili possono anche essere analizzate insieme tramite le distribuzioni congiunte di frequenze. Queste distribuzioni rappresentano l‚Äôinsieme delle frequenze assolute o relative ad ogni possibile combinazione di valori delle variabili. Ad esempio, se l‚Äôinsieme di variabili \\(V\\) √® composto da due variabili, \\(X\\) e \\(Y\\), ciascuna delle quali pu√≤ assumere due valori, 1 e 2, allora una possibile distribuzione congiunta di frequenze relative per \\(V\\) potrebbe essere espressa come \\(f(X = 1, Y = 1) = 0.2\\), \\(f(X = 1, Y = 2) = 0.1\\), \\(f(X = 2, Y = 1) = 0.5\\), e \\(f(X = 2, Y = 2) = 0.2\\). Come nel caso delle distribuzioni di frequenze relative di una singola variabile, le frequenze relative di una distribuzione congiunta devono sommare a 1.\nPer i dati dell‚Äôesempio precedente, la funzione prop.table() pu√≤ essere utilizzata anche per produrre questo tipo di tabella: basta indicare le serie corrispondenti alle variabili considerate come valori degli argomenti bdi_class e group.\n\nprop.table(table(df$bdi_class, df$group))\n#&gt;              \n#&gt;                  ctl    mdd\n#&gt;   [0,13.5]    0.5455 0.0000\n#&gt;   (13.5,19.5] 0.0000 0.0152\n#&gt;   (19.5,28.5] 0.0000 0.1818\n#&gt;   (28.5,63]   0.0000 0.2576",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#istogramma",
    "href": "chapters/eda/05_exploring_numeric_data.html#istogramma",
    "title": "17¬† Esplorare i dati numerici",
    "section": "17.3 Istogramma",
    "text": "17.3 Istogramma\nUn istogramma rappresenta graficamente una distribuzione di frequenze. Un istogramma mostra sulle ascisse i limiti delle classi \\(\\Delta_i\\) e sulle ordinate la densit√† della frequenza relativa della variabile \\(X\\) nella classe \\(\\Delta_i\\). La densit√† della frequenza relativa √® misurata dalla funzione costante a tratti \\(\\varphi_n(x)= \\frac{f_i}{b_i-a_i}\\), dove \\(f_i\\) √® la frequenza relativa della classe \\(\\Delta_i\\) e \\(b_i - a_i\\) rappresenta l‚Äôampiezza della classe. In questo modo, l‚Äôarea del rettangolo associato alla classe \\(\\Delta_i\\) sull‚Äôistogramma sar√† proporzionale alla frequenza relativa \\(f_i\\). √à importante notare che l‚Äôarea totale dell‚Äôistogramma delle frequenze relative √® uguale a 1.0, poich√© rappresenta la somma delle aree dei singoli rettangoli.\nPer fare un esempio, costruiamo un istogramma per i valori BDI-II di Zetsche et al. (2019). Con i quattro intervalli individuati dai cut-off del BDI-II creo una prima versione dell‚Äôistogramma ‚Äì si notino le frequenze assolute sull‚Äôasse delle ordinate.\n\nggplot(df, aes(x = bdi)) +\n  geom_histogram(\n    breaks = c(0, 13.5, 19.5, 28.5, 63),\n    aes(y = after_stat(density)),\n  ) +\n  labs(\n    title = \"Istogramma delle frequenze relative\", \n    x = \"BDI-II\", \n    y = \"Densit√†\"\n  ) \n\n\n\n\n\n\n\n\nAnche se nel caso presente √® sensato usare ampiezze diverse per gli intervalli delle classi, in generale gli istogrammi si costruiscono utilizzando intervalli riportati sulle ascisse con un‚Äôampiezza uguale.\n\nggplot(df, aes(x = bdi)) +\n  geom_histogram(\n    aes(y = ..density..),\n  ) +\n  labs(\n    title = \"Istogramma delle frequenze relative\", \n    x = \"BDI-II\", \n    y = \"Densit√†\"\n  )\n#&gt; Warning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\n#&gt; ‚Ñπ Please use `after_stat(density)` instead.\n#&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#kernel-density-plot",
    "href": "chapters/eda/05_exploring_numeric_data.html#kernel-density-plot",
    "title": "17¬† Esplorare i dati numerici",
    "section": "17.4 Kernel density plot",
    "text": "17.4 Kernel density plot\nConfrontando le due figure precedenti, emerge chiaramente una limitazione dell‚Äôistogramma: la sua forma dipende dall‚Äôarbitrariet√† con cui vengono scelti il numero e l‚Äôampiezza delle classi, rendendo difficile interpretare correttamente la distribuzione dei dati.\nPer superare questa difficolt√†, possiamo utilizzare una tecnica alternativa chiamata stima della densit√† kernel (KDE) ‚Äì si veda l‚Äô?sec-kde. Mentre l‚Äôistogramma utilizza barre per rappresentare i dati, la KDE crea un profilo smussato che fornisce una visione pi√π continua e meno dipendente dall‚Äôarbitrariet√† delle classi.\nImmaginiamo un istogramma con classi di ampiezza molto piccola, tanto da avere una curva continua invece di barre discrete. Questo √® ci√≤ che fa la KDE: smussa il profilo dell‚Äôistogramma per ottenere una rappresentazione continua dei dati. Invece di utilizzare barre, la KDE posiziona una piccola curva (detta kernel) su ogni osservazione nel dataset. Queste curve possono essere gaussiane (a forma di campana) o di altro tipo. Ogni kernel ha un‚Äôaltezza e una larghezza determinate da parametri di smussamento (o bandwidth), che controllano quanto deve essere larga e alta la curva. Tutte le curve kernel vengono sommate per creare una singola curva complessiva. Questa curva rappresenta la densit√† dei dati, mostrando come i dati sono distribuiti lungo il range dei valori.\nLa curva risultante dal KDE mostra la proporzione di casi per ciascun intervallo di valori. L‚Äôarea sotto la curva in un determinato intervallo rappresenta la proporzione di casi della distribuzione che ricadono in quell‚Äôintervallo. Per esempio, se un intervallo ha un‚Äôarea maggiore sotto la curva rispetto ad altri, significa che in quell‚Äôintervallo c‚Äô√® una maggiore concentrazione di dati.\nLa curva di densit√† ottenuta tramite KDE fornisce dunque un‚Äôidea chiara di come i dati sono distribuiti senza dipendere dall‚Äôarbitrariet√† della scelta delle classi dell‚Äôistogramma.\nCrediamo un kernel density plot per ciascuno dei due gruppi di valori BDI-II riportati da Zetsche et al. (2019).\n\nggplot(df, aes(x = bdi, fill = group)) +\n  geom_density() +\n    scale_fill_okabe_ito(order = c(5, 1, 3, 4, 2, 6, 7, 8, 9)) +\n  labs(\n    title = \"Curva di densit√† KDE\", \n    x = \"BDI-II\", \n    y = \"Densit√†\"\n  )",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#consigli-per-creare-visualizzazioni-di-dati-efficaci",
    "href": "chapters/eda/05_exploring_numeric_data.html#consigli-per-creare-visualizzazioni-di-dati-efficaci",
    "title": "17¬† Esplorare i dati numerici",
    "section": "17.5 Consigli per Creare Visualizzazioni di Dati Efficaci",
    "text": "17.5 Consigli per Creare Visualizzazioni di Dati Efficaci\nEcco alcuni suggerimenti per creare visualizzazioni di dati esplicative, efficaci e di qualit√† adatta alle presentazioni:\n\nMessaggio chiaro: Assicurati che il grafico trasmetta un messaggio chiaro e immediato (ad esempio, ‚ÄúIl livello di benessere psicologico dei partecipanti aumenta nel tempo‚Äù).\nUso del colore:\n\nUtilizza i colori in modo ponderato e con moderazione.\nNon eccedere nell‚Äôuso dei colori solo perch√© √® possibile farlo.\nLimita l‚Äôuso a non pi√π di cinque o sei colori in una singola figura.\nVerifica che le scelte cromatiche non distorcano le conclusioni della figura.\nEvita l‚Äôuso contemporaneo di rosso e verde nello stesso grafico, poich√© queste tonalit√† sono difficili da distinguere per le persone daltoniche.\n\nGuidare l‚Äôattenzione:\n\nUtilizza dimensioni, colori e testo per guidare l‚Äôattenzione del pubblico.\nEvidenzia elementi particolari del grafico per enfatizzare punti chiave.\n\nGestione del sovraccarico visivo:\n\nUtilizza la trasparenza per ridurre il ‚Äúsovrapplotting‚Äù (che si verifica quando ci sono molti elementi sovrapposti nel grafico, come punti o linee, rendendo difficile individuare i pattern).\nQuesta tecnica √® particolarmente utile quando si visualizza una grande quantit√† di dati.\nSe il dataset √® molto ampio e l‚Äôaggiunta di trasparenza non √® sufficiente, considera la visualizzazione di un sottocampione dei dati (un campione casuale di punti dati, scelto senza sostituzione). Questa tecnica √® nota come sottocampionamento.\n\nElementi testuali:\n\nI titoli, le etichette degli assi e il testo delle legende devono essere chiari e facilmente comprensibili.\nGli elementi della legenda dovrebbero essere ordinati in modo logico e coerente.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#forma-di-una-distribuzione",
    "href": "chapters/eda/05_exploring_numeric_data.html#forma-di-una-distribuzione",
    "title": "17¬† Esplorare i dati numerici",
    "section": "17.6 Forma di una Distribuzione",
    "text": "17.6 Forma di una Distribuzione\nIn statistica, la forma di una distribuzione descrive come i dati sono distribuiti intorno ai valori centrali. Si distingue tra distribuzioni simmetriche e asimmetriche, e tra distribuzioni unimodali e multimodali. Un‚Äôillustrazione grafica √® fornita nella figura seguente. Nel pannello 1, la distribuzione √® unimodale con asimmetria negativa; nel pannello 2, la distribuzione √® unimodale con asimmetria positiva; nel pannello 3, la distribuzione √® simmetrica e unimodale; nel pannello 4, la distribuzione √® bimodale.\n\n\n\nDistribuzioni\n\n\nIl grafico della densit√† di kernel (Kernel Density Plot) dei valori BDI-II nel campione di Zetsche et al. (2019) √® bimodale. Questo indica che le osservazioni della distribuzione si raggruppano in due cluster distinti: un gruppo di osservazioni tende ad avere valori BDI-II bassi, mentre l‚Äôaltro gruppo tende ad avere valori BDI-II alti. Questi due cluster di osservazioni corrispondono al gruppo di controllo e al gruppo clinico nel campione di dati esaminato da Zetsche et al. (2019).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#indici-di-posizione",
    "href": "chapters/eda/05_exploring_numeric_data.html#indici-di-posizione",
    "title": "17¬† Esplorare i dati numerici",
    "section": "17.7 Indici di posizione",
    "text": "17.7 Indici di posizione\n\n17.7.1 Quantili\nLa distribuzione dei valori BDI-II di Zetsche et al. (2019) pu√≤ essere sintetizzata attraverso l‚Äôuso dei quantili, che sono valori caratteristici che suddividono i dati in parti ugualmente numerose. I quartili sono tre quantili specifici: il primo quartile, \\(q_1\\), divide i dati in due parti, lasciando a sinistra il 25% del campione; il secondo quartile, \\(q_2\\), corrisponde alla mediana e divide i dati in due parti uguali; il terzo quartile lascia a sinistra il 75% del campione.\nInoltre, ci sono altri indici di posizione chiamati decili e percentili che suddividono i dati in parti di dimensioni uguali a 10% e 1%, rispettivamente.\nPer calcolare i quantili, i dati vengono prima ordinati in modo crescente e poi viene determinato il valore di \\(np\\), dove \\(n\\) √® la dimensione del campione e \\(p\\) √® l‚Äôordine del quantile. Se \\(np\\) non √® un intero, il valore del quantile corrisponde al valore del dato che si trova alla posizione successiva alla parte intera di \\(np\\). Se \\(np\\) √® un intero, il valore del quantile corrisponde alla media dei dati nelle posizioni \\(k\\) e \\(k+1\\), dove \\(k\\) √® la parte intera di \\(np\\).\nGli indici di posizione possono essere utilizzati per creare un box-plot, una rappresentazione grafica della distribuzione dei dati che √® molto popolare e pu√≤ essere utilizzata in alternativa ad un istogramma.\nAd esempio, per calcolare la mediana della distribuzione dei nove soggetti con un unico episodio di depressione maggiore del campione clinico di Zetsche et al. (2019), si determina il valore di \\(np = 9 \\cdot 0.5 = 4.5\\), che non √® un intero. Pertanto, il valore del secondo quartile √® pari al valore del dato che si trova alla posizione successiva alla parte intera di \\(np\\), ovvero \\(q_2 = x_{4 + 1} = 27\\). Per calcolare il quantile di ordine \\(2/3\\), si determina il valore di \\(np = 9 \\cdot 2/3 = 6\\), che √® un intero. Quindi, il valore del quantile corrisponde alla media dei dati nelle posizioni \\(6\\) e \\(7\\), ovvero \\(q_{\\frac{2}{3}} = \\frac{1}{2} (x_{6} + x_{7}) = \\frac{1}{2} (33 + 33) = 33\\).\nUsiamo quantile() per trovare la soluzione dell‚Äôesercizio precedente.\n\nx = c(19, 26, 27, 28, 28, 33, 33, 41, 43)\nquantile(x, 2 / 3)\n#&gt; 66.66667% \n#&gt;        33",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#mostrare-i-dati",
    "href": "chapters/eda/05_exploring_numeric_data.html#mostrare-i-dati",
    "title": "17¬† Esplorare i dati numerici",
    "section": "17.8 Mostrare i dati",
    "text": "17.8 Mostrare i dati\n\n17.8.1 Diagramma a scatola\nIl box plot √® uno strumento grafico che visualizza la dispersione di una distribuzione. Per creare un box plot, si disegna un rettangolo (la ‚Äúscatola‚Äù) di altezza arbitraria, basato sulla distanza interquartile (IQR), che corrisponde alla differenza tra il terzo quartile (\\(q_{0.75}\\)) e il primo quartile (\\(q_{0.25}\\)). La mediana (\\(q_{0.5}\\)) √® rappresentata da una linea all‚Äôinterno del rettangolo.\nAi lati della scatola, vengono tracciati due segmenti di retta, detti ‚Äúbaffi‚Äù, che rappresentano i valori adiacenti inferiore e superiore. Il valore adiacente inferiore √® il valore pi√π basso tra le osservazioni che √® maggiore o uguale al primo quartile meno 1.5 volte la distanza interquartile. Il valore adiacente superiore √® il valore pi√π alto tra le osservazioni che √® minore o uguale al terzo quartile pi√π 1.5 volte la distanza interquartile.\nSe ci sono dei valori che cadono al di fuori dei valori adiacenti, vengono chiamati ‚Äúvalori anomali‚Äù e sono rappresentati individualmente nel box plot per evidenziare la loro presenza e posizione. In questo modo, il box plot fornisce una rappresentazione visiva della distribuzione dei dati, permettendo di individuare facilmente eventuali valori anomali e di comprendere la dispersione dei dati.\n\nUtilizziamo un box-plot per rappresentare graficamente la distribuzione dei punteggi BDI-II nel gruppo dei pazienti e nel gruppo di controllo.\n\nggplot(df, aes(x = group, y = bdi)) +\n  geom_boxplot() +\n  labs(\n    title = \"Box plot per gruppo\", \n    x = \"Gruppo\", \n    y = \"BDI-II\"\n  )\n\n\n\n\n\n\n\n\nUn risultato migliore si ottiene utilizzando un grafico a violino (violin plot) e includendo anche i dati grezzi.\n\n\n17.8.2 Grafico a Violino\nI grafici a violino combinano le caratteristiche dei box plot e dei grafici di densit√† di kernel (KDE plot) per offrire una rappresentazione pi√π dettagliata dei dati. A questi grafici vengono sovrapposti i dati grezzi, fornendo una visione completa della distribuzione e delle caratteristiche dei dati.\n\nggplot(df, aes(x = group, y = bdi, fill = group)) +\n  geom_violin() +\n  geom_dotplot(\n    binaxis = \"y\",\n    stackdir = \"center\",\n    dotsize = 0.5,\n    fill = 1\n  ) +\n    scale_fill_okabe_ito(order = c(5, 1, 3, 4, 2, 6, 7, 8, 9)) +\n  labs(\n    title = \"Violin plot con overlay dei punti grezzi\",\n    x = \"Gruppo\",\n    y = \"BDI-II\"\n  )\n#&gt; Bin width defaults to 1/30 of the range of the data. Pick better value with\n#&gt; `binwidth`.\n\n\n\n\n\n\n\n\n\n\n17.8.3 Grafico Beeswarm\nIl pacchetto {ggbeeswarm} include una funzione chiamata geom_beeswarm, che pu√≤ essere utilizzata per creare un grafico beeswarm in ggplot2.\nUn grafico beeswarm √® una variazione del grafico a punti che disperde i dati in modo che non si sovrappongano, rendendo visibili tutti i singoli punti dati. Questo tipo di visualizzazione √® particolarmente utile quando si desidera esaminare la distribuzione e la densit√† di un set di dati, senza ricorrere all‚Äôuso di barre d‚Äôerrore o di scatole e baffi (boxplot), mantenendo un‚Äôalta leggibilit√† anche quando i set di dati sono densi.\n\nggplot(df, aes(x = group, y = bdi, color = group)) +\n  geom_beeswarm(cex = 3) +\n  labs(\n    title = \"Violin plot con overlay dei punti grezzi\",\n    x = \"Gruppo\",\n    y = \"BDI-II\"\n  )",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#riflessioni-conclusive",
    "href": "chapters/eda/05_exploring_numeric_data.html#riflessioni-conclusive",
    "title": "17¬† Esplorare i dati numerici",
    "section": "17.9 Riflessioni Conclusive",
    "text": "17.9 Riflessioni Conclusive\nAbbiamo esplorato diverse tecniche per sintetizzare e visualizzare i dati, includendo distribuzioni di frequenze, istogrammi e grafici di densit√†. Questi strumenti sono essenziali per comprendere meglio i dati e presentare risultati in modo chiaro e informativo.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/05_exploring_numeric_data.html#informazioni-sullambiente-di-sviluppo",
    "title": "17¬† Esplorare i dati numerici",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: US/Pacific\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] ggbeeswarm_0.7.2 ggokabeito_0.1.0 see_0.9.0        gridExtra_2.3   \n#&gt;  [5] patchwork_1.3.0  bayesplot_1.11.1 psych_2.4.12     scales_1.3.0    \n#&gt;  [9] markdown_1.13    knitr_1.49       lubridate_1.9.4  forcats_1.0.0   \n#&gt; [13] stringr_1.5.1    dplyr_1.1.4      purrr_1.0.2      readr_2.1.5     \n#&gt; [17] tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0 \n#&gt; [21] rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     R.oo_1.27.0       rprojroot_2.0.4  \n#&gt; [13] jsonlite_1.8.9    R.utils_2.12.3    mnormt_2.1.1      cli_3.6.3        \n#&gt; [17] rlang_1.1.4       R.methodsS3_1.8.2 munsell_0.5.1     withr_3.0.2      \n#&gt; [21] yaml_2.3.10       tools_4.4.2       parallel_4.4.2    tzdb_0.4.0       \n#&gt; [25] colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5       R6_2.5.1         \n#&gt; [29] lifecycle_1.0.4   htmlwidgets_1.6.4 vipor_0.4.7       beeswarm_0.4.0   \n#&gt; [33] pkgconfig_2.0.3   pillar_1.10.1     gtable_0.3.6      data.table_1.16.4\n#&gt; [37] glue_1.8.0        xfun_0.50         tidyselect_1.2.1  farver_2.1.2     \n#&gt; [41] htmltools_0.5.8.1 nlme_3.1-166      labeling_0.4.3    rmarkdown_2.29   \n#&gt; [45] compiler_4.4.2",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#bibliografia",
    "href": "chapters/eda/05_exploring_numeric_data.html#bibliografia",
    "title": "17¬† Esplorare i dati numerici",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nZetsche, U., Buerkner, P.-C., & Renneberg, B. (2019). Future expectations in clinical depression: biased or realistic? Journal of Abnormal Psychology, 128(7), 678‚Äì688.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html",
    "href": "chapters/eda/06_data_visualization.html",
    "title": "18¬† Principi della visualizzazione dei dati",
    "section": "",
    "text": "Introduzione\nPrerequisiti\nConcetti e competenze chiave\nIn questo capitolo verranno introdotti i principi fondamentali della visualizzazione dei dati, accompagnati da una descrizione concisa. Per un approfondimento su ciascun principio, si rimanda al capitolo Data Visualization del libro Introduction to Data Science.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#codificare-i-dati-attraverso-segnali-visivi",
    "href": "chapters/eda/06_data_visualization.html#codificare-i-dati-attraverso-segnali-visivi",
    "title": "18¬† Principi della visualizzazione dei dati",
    "section": "18.1 Codificare i dati attraverso segnali visivi",
    "text": "18.1 Codificare i dati attraverso segnali visivi\nIniziamo con una panoramica dei principali segnali visivi utilizzati per codificare i dati: posizione, lunghezza, angoli, area, luminosit√† e tonalit√† del colore. Tra questi, posizione e lunghezza sono i segnali visivi pi√π efficaci e intuitivi, poich√© il cervello umano √® particolarmente abile nel riconoscere variazioni spaziali. Questo rende la posizione e la lunghezza strumenti potenti per la rappresentazione quantitativa. In altre parole, le persone riescono a confrontare con maggiore precisione altezze e lunghezze (come le barre in un barplot) rispetto ad angoli o aree (come in un grafico a torta).\nAngoli e aree, sebbene comunemente usati, sono segnali visivi meno efficaci. Grafici come i pie chart, che si basano su angoli e aree per rappresentare quantit√†, risultano spesso meno precisi e pi√π difficili da interpretare, specialmente quando le differenze sono piccole. Anche l‚Äôuso dell‚Äôarea, ad esempio nei bubble plot, pu√≤ distorcere la percezione delle differenze tra i dati, a meno che non venga gestita correttamente. Anche se l‚Äôarea di una bolla pu√≤ essere proporzionale al valore rappresentato, la percezione umana tende a sovrastimare le differenze tra aree pi√π grandi.\nLuminosit√† e tonalit√† del colore sono utili per rappresentare variabili qualitative o categoriali, ma possono risultare difficili da interpretare quando si tratta di confrontare quantit√† precise. Tuttavia, il colore gioca un ruolo cruciale nelle visualizzazioni multidimensionali, come le heatmap, dove √® necessario rappresentare pi√π di due variabili contemporaneamente. √à importante, per√≤, usare il colore con attenzione, soprattutto per garantire l‚Äôaccessibilit√† a persone con problemi di daltonismo.\nLe tabelle sono utili quando si ha una quantit√† limitata di dati e si richiede una precisione numerica rigorosa. Tuttavia, per set di dati pi√π grandi o per evidenziare tendenze e differenze, i grafici (come i barplot) sono generalmente pi√π efficaci. Le tabelle non offrono lo stesso impatto visivo immediato e rendono pi√π difficile l‚Äôindividuazione di pattern complessi.\n\n18.1.1 Ulteriori considerazioni sulla scelta della visualizzazione\nLa scelta della visualizzazione pi√π appropriata dipende sia dalla natura dei dati che dallo scopo della comunicazione. Per esempio:\n\nBarplot o dot plot sono ideali per confrontare valori quantitativi tra categorie.\nIstogrammi, boxplot e raincloud plots sono pi√π adatti per descrivere la distribuzione di dati continui e fare confronti tra categorie.\nGrafici di dispersione (scatter plot) sono eccellenti per esplorare relazioni tra due variabili continue.\n\nLa chiarezza e la leggibilit√† sono principi fondamentali nella creazione di visualizzazioni efficaci. L‚Äôaggiunta di elementi visivi eccessivi, come decorazioni superflue o troppi colori, pu√≤ distrarre dal messaggio principale. Un buon grafico deve essere semplice, ma allo stesso tempo completo, includendo solo gli elementi visivi necessari per trasmettere il messaggio desiderato.\nIn conclusione, scegliere i segnali visivi adeguati e il tipo di grafico pi√π appropriato non solo migliora l‚Äôaccuratezza della comunicazione, ma rende le informazioni pi√π accessibili e comprensibili per il pubblico.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#quando-includere-lo-zero",
    "href": "chapters/eda/06_data_visualization.html#quando-includere-lo-zero",
    "title": "18¬† Principi della visualizzazione dei dati",
    "section": "18.2 Quando includere lo zero",
    "text": "18.2 Quando includere lo zero\nQuando si usa la lunghezza come segnale visivo, come nei barplot, √® essenziale che l‚Äôasse parta da zero. Non farlo pu√≤ essere fuorviante e far sembrare le differenze pi√π grandi di quanto non siano in realt√†. Questo errore viene spesso sfruttato nei media per esagerare differenze apparentemente significative.\nTuttavia, quando si usa la posizione (ad esempio in un grafico a dispersione), non √® sempre necessario includere lo zero, soprattutto se l‚Äôinteresse principale √® il confronto tra gruppi rispetto alla variabilit√† interna.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#evitare-le-distorsioni",
    "href": "chapters/eda/06_data_visualization.html#evitare-le-distorsioni",
    "title": "18¬† Principi della visualizzazione dei dati",
    "section": "18.3 Evitare le distorsioni",
    "text": "18.3 Evitare le distorsioni\nUna distorsione comune si verifica quando le differenze tra quantit√† sono rappresentate utilizzando aree, come nei bubble plot, dove il raggio dei cerchi √® proporzionale al dato. Il problema √® che, poich√© l‚Äôarea di un cerchio √® proporzionale al quadrato del raggio, le differenze sembrano molto pi√π ampie di quanto siano realmente. Per evitare queste distorsioni, √® meglio utilizzare la posizione o la lunghezza, come in un grafico a barre, per confrontare direttamente le quantit√†.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#ordinare-le-categorie",
    "href": "chapters/eda/06_data_visualization.html#ordinare-le-categorie",
    "title": "18¬† Principi della visualizzazione dei dati",
    "section": "18.4 Ordinare le categorie",
    "text": "18.4 Ordinare le categorie\nQuando si visualizzano categorie, come nei barplot o nei boxplot, √® opportuno ordinarle in base al valore della variabile di interesse, anzich√© in ordine alfabetico. Questo aiuta a evidenziare pattern significativi e facilita il confronto tra categorie.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#evitare-i-dynamite-plots",
    "href": "chapters/eda/06_data_visualization.html#evitare-i-dynamite-plots",
    "title": "18¬† Principi della visualizzazione dei dati",
    "section": "18.5 Evitare i Dynamite Plots",
    "text": "18.5 Evitare i Dynamite Plots\nI dynamite plots, che mostrano la media e l‚Äôerrore standard (o la deviazione standard), sono spesso utilizzati in psicologia ma sono fuorvianti. Questi grafici tendono a esagerare le differenze e possono indurre false interpretazioni. √à preferibile mostrare tutti i dati, ad esempio tramite un dot plot, che fornisce un‚Äôimmagine pi√π chiara della distribuzione dei dati (Butler, 2022).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#facilitare-i-confronti",
    "href": "chapters/eda/06_data_visualization.html#facilitare-i-confronti",
    "title": "18¬† Principi della visualizzazione dei dati",
    "section": "18.6 Facilitare i confronti",
    "text": "18.6 Facilitare i confronti\nQuando si confrontano due distribuzioni, come in un istogramma, √® fondamentale mantenere gli stessi assi per entrambi i grafici. Se le distribuzioni sono presentate su assi con scale diverse, il confronto diventa difficile e potrebbe portare a conclusioni errate. Allineare i grafici verticalmente o orizzontalmente consente di percepire pi√π facilmente le differenze tra i gruppi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#trasformazioni-logaritmiche",
    "href": "chapters/eda/06_data_visualization.html#trasformazioni-logaritmiche",
    "title": "18¬† Principi della visualizzazione dei dati",
    "section": "18.7 Trasformazioni logaritmiche",
    "text": "18.7 Trasformazioni logaritmiche\nLe trasformazioni logaritmiche sono utili quando si lavora con dati distribuiti su pi√π ordini di grandezza o quando le variazioni tra le quantit√† sono moltiplicative (West, 2022). L‚Äôuso della scala logaritmica in un grafico a barre o a dispersione pu√≤ ridurre le distorsioni visive e migliorare l‚Äôinterpretazione dei dati. Questo approccio √® particolarmente utile quando alcuni valori estremi potrebbero dominare il grafico, nascondendo dettagli rilevanti.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#codificare-una-terza-variabile",
    "href": "chapters/eda/06_data_visualization.html#codificare-una-terza-variabile",
    "title": "18¬† Principi della visualizzazione dei dati",
    "section": "18.8 Codificare una terza variabile",
    "text": "18.8 Codificare una terza variabile\nPer rappresentare tre variabili, √® possibile utilizzare un grafico di dispersione con variabili codificate attraverso dimensioni aggiuntive come il colore, la dimensione o la forma dei punti. Ad esempio, in un grafico che confronta aspettativa di vita e reddito, la dimensione dei punti potrebbe rappresentare la popolazione e il colore la regione geografica. Quando si utilizza il colore per rappresentare una variabile, √® importante scegliere palette cromatiche accessibili anche per chi √® affetto da daltonismo, evitando combinazioni problematiche come rosso-verde.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#evitare-pseudo-tre-dimensioni",
    "href": "chapters/eda/06_data_visualization.html#evitare-pseudo-tre-dimensioni",
    "title": "18¬† Principi della visualizzazione dei dati",
    "section": "18.9 Evitare pseudo-tre dimensioni",
    "text": "18.9 Evitare pseudo-tre dimensioni\nGrafici tridimensionali, come barre o pie chart 3D, spesso aggiungono confusione senza fornire informazioni aggiuntive significative. Sebbene visivamente accattivanti, questi grafici distorcono la percezione e rendono difficile l‚Äôinterpretazione accurata dei dati. √à preferibile mantenere le visualizzazioni bidimensionali, a meno che la terza dimensione non rappresenti effettivamente una variabile aggiuntiva.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#scegliere-il-numero-giusto-di-cifre-significative",
    "href": "chapters/eda/06_data_visualization.html#scegliere-il-numero-giusto-di-cifre-significative",
    "title": "18¬† Principi della visualizzazione dei dati",
    "section": "18.10 Scegliere il numero giusto di cifre significative",
    "text": "18.10 Scegliere il numero giusto di cifre significative\n√à importante evitare l‚Äôuso di troppe cifre decimali nelle tabelle e nei grafici. Spesso, una o due cifre significative sono sufficienti per rappresentare accuratamente i dati, mentre l‚Äôaggiunta di cifre inutili pu√≤ confondere il lettore e dare un falso senso di precisione. Limitiamoci a mostrare solo le cifre necessarie per trasmettere il messaggio in modo chiaro.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#conoscere-il-pubblico",
    "href": "chapters/eda/06_data_visualization.html#conoscere-il-pubblico",
    "title": "18¬† Principi della visualizzazione dei dati",
    "section": "18.11 Conoscere il pubblico",
    "text": "18.11 Conoscere il pubblico\nInfine, √® fondamentale adattare la visualizzazione dei dati al pubblico di riferimento. Grafici progettati per l‚Äôanalisi esplorativa interna possono contenere dettagli tecnici complessi, ma quando si comunica a un pubblico pi√π ampio o non specializzato, √® necessario semplificare. Ad esempio, utilizzare una scala logaritmica pu√≤ essere utile per un pubblico esperto, ma confondere un pubblico generale. In questi casi, mantenere la scala lineare e spiegare chiaramente i dati aiuta a evitare malintesi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#riflessioni-conclusive",
    "href": "chapters/eda/06_data_visualization.html#riflessioni-conclusive",
    "title": "18¬† Principi della visualizzazione dei dati",
    "section": "18.12 Riflessioni Conclusive",
    "text": "18.12 Riflessioni Conclusive\nI principi di visualizzazione dei dati trattati in questo capitolo sono strumenti fondamentali per garantire chiarezza e accuratezza nella rappresentazione delle informazioni. Scelte appropriate di grafici, segnali visivi e trasformazioni facilitano la comprensione, riducendo la possibilit√† di distorsioni o interpretazioni errate.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#bibliografia",
    "href": "chapters/eda/06_data_visualization.html#bibliografia",
    "title": "18¬† Principi della visualizzazione dei dati",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nButler, R. C. (2022). Popularity leads to bad habits: Alternatives to ¬´the statistics¬ª routine of significance,¬´alphabet soup¬ª and dynamite plots. In Annals of Applied Biology (Fasc. 2; Vol. 180, pp. 182‚Äì195). Wiley Online Library.\n\n\nHealy, K. (2018). Data visualization: a practical introduction. Princeton University Press.\n\n\nWest, R. M. (2022). Best practice in statistics: The use of log transformation. Annals of Clinical Biochemistry, 59(3), 162‚Äì165.\n\n\nWickham, H., √áetinkaya-Rundel, M., & Grolemund, G. (2023). R for data science. \" O‚ÄôReilly Media, Inc.\".\n\n\nWilke, C. O. (2019). Fundamentals of data visualization: a primer on making informative and compelling figures. O‚ÄôReilly Media.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html",
    "href": "chapters/eda/07_loc_scale.html",
    "title": "19¬† Indicatori di tendenza centrale e variabilit√†",
    "section": "",
    "text": "19.1 Introduzione\nLa visualizzazione grafica dei dati rappresenta il pilastro fondamentale di ogni analisi quantitativa. Grazie alle rappresentazioni grafiche adeguate, √® possibile individuare importanti caratteristiche di una distribuzione, quali la simmetria o l‚Äôasimmetria, nonch√© la presenza di una o pi√π mode. Successivamente, al fine di descrivere sinteticamente le principali caratteristiche dei dati, si rende necessario l‚Äôutilizzo di specifici indici numerici. In questo capitolo, verranno presentati i principali indicatori della statistica descrittiva.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Indicatori di tendenza centrale e variabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#indici-di-tendenza-centrale",
    "href": "chapters/eda/07_loc_scale.html#indici-di-tendenza-centrale",
    "title": "19¬† Indicatori di tendenza centrale e variabilit√†",
    "section": "19.2 Indici di Tendenza Centrale",
    "text": "19.2 Indici di Tendenza Centrale\nGli indici di tendenza centrale sono misure statistiche che cercano di rappresentare un valore tipico o centrale all‚Äôinterno di un insieme di dati. Sono utilizzati per ottenere una comprensione immediata della distribuzione dei dati senza dover analizzare l‚Äôintero insieme. Gli indici di tendenza centrale sono fondamentali nell‚Äôanalisi statistica, in quanto forniscono una sintesi semplice e comprensibile delle caratteristiche principali di un insieme di dati. I principali indici di tendenza centrale sono:\n\nMedia: La media √® la somma di tutti i valori divisa per il numero totale di valori. √à spesso utilizzata come misura generale di tendenza centrale, ma √® sensibile agli estremi (valori molto alti o molto bassi).\nMediana: La mediana √® il valore che divide l‚Äôinsieme di dati in due parti uguali. A differenza della media, non √® influenzata da valori estremi ed √® quindi pi√π robusta in presenza di outlier.\nModa: La moda √® il valore che appare pi√π frequentemente in un insieme di dati. In alcuni casi, pu√≤ non essere presente o esserci pi√π di una moda.\n\nLa scelta dell‚Äôindice di tendenza centrale appropriato dipende dalla natura dei dati e dall‚Äôobiettivo dell‚Äôanalisi. Ad esempio, la mediana potrebbe essere preferita alla media se l‚Äôinsieme di dati contiene valori anomali che potrebbero distorcere la rappresentazione centrale. La conoscenza e l‚Äôapplicazione corretta di questi indici possono fornire una preziosa intuizione sulle caratteristiche centrali di una distribuzione di dati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Indicatori di tendenza centrale e variabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#moda",
    "href": "chapters/eda/07_loc_scale.html#moda",
    "title": "19¬† Indicatori di tendenza centrale e variabilit√†",
    "section": "19.3 Moda",
    "text": "19.3 Moda\nLa moda (\\(\\text{Mo}\\)) rappresenta il valore della variabile che compare con maggiore frequenza in una distribuzione. In altre parole, √® il valore pi√π ricorrente nei dati.\n\nNelle distribuzioni unimodali, esiste una sola moda, che coincide con il valore centrale della distribuzione pi√π frequente.\n\nTuttavia, in alcune distribuzioni, possono emergere pi√π di una moda, rendendole multimodali. In questi casi, la moda perde il suo significato di indicatore unico di tendenza centrale, poich√© la presenza di pi√π valori con frequenze elevate rende difficile individuare un singolo punto di riferimento.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Indicatori di tendenza centrale e variabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#mediana",
    "href": "chapters/eda/07_loc_scale.html#mediana",
    "title": "19¬† Indicatori di tendenza centrale e variabilit√†",
    "section": "19.4 Mediana",
    "text": "19.4 Mediana\nLa mediana (\\(\\tilde{x}\\)) corrisponde al valore che divide il campione in due met√†: il 50% dei dati √® inferiore o uguale alla mediana e il restante 50% √® superiore o uguale. A differenza della media, la mediana √® meno influenzata dai valori estremi, rendendola una misura particolarmente robusta in presenza di dati asimmetrici o outlier.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Indicatori di tendenza centrale e variabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#media",
    "href": "chapters/eda/07_loc_scale.html#media",
    "title": "19¬† Indicatori di tendenza centrale e variabilit√†",
    "section": "19.5 Media",
    "text": "19.5 Media\nLa media aritmetica di un insieme di valori rappresenta il punto centrale o il baricentro della distribuzione dei dati. √à calcolata come la somma di tutti i valori divisa per il numero totale di valori, ed √® espressa dalla formula:\n\\[\n\\bar{x}=\\frac{1}{n}\\sum_{i=1}^n x_i,\n\\tag{19.1}\\]\ndove \\(x_i\\) rappresenta i valori nell‚Äôinsieme, \\(n\\) √® il numero totale di valori, e \\(\\sum\\) indica la sommatoria.\n\n19.5.1 Propriet√† della Media\nUna propriet√† fondamentale della media √® che la somma degli scarti di ciascun valore dalla media √® zero:\n\\[\n\\sum_{i=1}^n (x_i - \\bar{x}) = 0.\\notag\n\\tag{19.2}\\]\nInfatti,\n\\[\n\\begin{aligned}\n\\sum_{i=1}^n (x_i - \\bar{x}) &= \\sum_i x_i - \\sum_i \\bar{x}\\notag\\\\\n&= \\sum_i x_i - n \\bar{x}\\notag\\\\\n&= \\sum_i x_i - \\sum_i x_i = 0.\\notag\n\\end{aligned}\n\\]\nQuesta propriet√† implica che i dati sono equamente distribuiti intorno alla media.\n\n\n19.5.2 La media come Centro di Gravit√† dell‚ÄôIstogramma\nLa media aritmetica pu√≤ essere interpretata come il centro di gravit√† o il punto di equilibrio della distribuzione dei dati. In termini fisici, il centro di gravit√† √® il punto in cui la massa di un sistema √® equilibrata o concentrata.\nIn termini statistici, possiamo considerare la media come il punto in cui la distribuzione dei dati √® in equilibrio. Ogni valore dell‚Äôinsieme di dati pu√≤ essere visto come un punto materiale con una massa proporzionale al suo valore. Se immaginiamo questi punti disposti su una linea, con valori pi√π grandi a destra e pi√π piccoli a sinistra, la media corrisponder√† esattamente al punto in cui la distribuzione sarebbe in equilibrio.\n\n\n19.5.3 Principio dei Minimi Quadrati\nLa posizione della media minimizza la somma delle distanze quadrate dai dati, un principio noto come ‚Äúmetodo dei minimi quadrati‚Äù. Matematicamente, questo si traduce nel fatto che la somma dei quadrati degli scarti tra ciascun valore e la media √® minima. Questo principio √® alla base dell‚Äôanalisi statistica dei modelli di regressione e conferma l‚Äôinterpretazione della media come centro di gravit√† dell‚Äôistogramma.\n\n\n19.5.4 Calcolo della Media con R\nPer calcolare la media di un piccolo numero di valori in R, possiamo utilizzare la somma di questi valori e dividerla per il numero totale di elementi. Consideriamo ad esempio i valori 12, 44, 21, 62, 24:\n\n(12 + 44 + 21 + 62 + 24) / 5\n#&gt; [1] 32.6\n\novvero\n\nx &lt;- c(12, 44, 21, 62, 24)\nmean(x)\n#&gt; [1] 32.6\n\n\n\n19.5.5 Le Proporzioni Sono Medie\nSe una collezione consiste solo di uni e zeri, allora la somma della collezione √® il numero di uni in essa, e la media della collezione √® la proporzione di uni.\n\nzero_one &lt;- c(1, 1, 1, 0)\nresult &lt;- mean(zero_one)\nresult\n#&gt; [1] 0.75\n\n√à possibile sostituire 1 con il valore booleano True e 0 con False:\n\nmean(c(TRUE, TRUE, TRUE, FALSE))\n#&gt; [1] 0.75\n\n\n\n19.5.6 Limiti della Media Aritmetica\nLa media aritmetica, tuttavia, ha alcune limitazioni: non sempre √® l‚Äôindice pi√π adeguato per descrivere accuratamente la tendenza centrale della distribuzione, specialmente quando si verificano asimmetrie o valori anomali (outlier). In queste situazioni, √® pi√π indicato utilizzare la mediana o la media spuntata (come spiegheremo successivamente).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Indicatori di tendenza centrale e variabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#come-descrivere-la-tendenza-centrale-in-distribuzioni-asimmetriche",
    "href": "chapters/eda/07_loc_scale.html#come-descrivere-la-tendenza-centrale-in-distribuzioni-asimmetriche",
    "title": "19¬† Indicatori di tendenza centrale e variabilit√†",
    "section": "19.6 Come Descrivere la Tendenza Centrale in Distribuzioni Asimmetriche",
    "text": "19.6 Come Descrivere la Tendenza Centrale in Distribuzioni Asimmetriche\nIl diverso significato degli indici di tendenza centrale ‚Äì moda, media e mediana ‚Äì diventa evidente quando si analizzano distribuzioni asimmetriche. Per illustrare questo concetto, utilizzeremo i dati del Progetto Natsal, contenuti nel file sexual-partners.csv.\nNegli anni ‚Äô80, con la crescente preoccupazione per l‚ÄôAIDS, le autorit√† sanitarie del Regno Unito si resero conto della mancanza di dati affidabili sui comportamenti sessuali della popolazione. In particolare, vi erano dubbi sulla frequenza con cui le persone cambiavano partner, sul numero di partner simultanei e sulle pratiche sessuali adottate. Questa conoscenza era essenziale per prevedere la diffusione delle malattie sessualmente trasmissibili nella societ√† e per pianificare adeguatamente i servizi sanitari. Tuttavia, si faceva ancora riferimento ai dati raccolti da Alfred Kinsey negli Stati Uniti negli anni ‚Äô40, che non tenevano conto della rappresentativit√† del campione.\nA partire dalla fine degli anni ‚Äô80, vennero dunque avviati nel Regno Unito e negli Stati Uniti ampi e rigorosi studi sui comportamenti sessuali, nonostante una forte opposizione in alcuni ambienti. Nel Regno Unito, il governo guidato da Margaret Thatcher ritir√≤ il proprio sostegno a un‚Äôimportante indagine sui comportamenti sessuali all‚Äôultimo momento. Fortunatamente, i ricercatori riuscirono a ottenere finanziamenti da enti benefici, dando vita al National Sexual Attitudes and Lifestyles Survey (Natsal). Da allora, questa indagine viene condotta ogni dieci anni, a partire dal 1990. La terza rilevazione, denominata Natsal-3, √® stata effettuata intorno al 2010.\n\nPoniamoci il problema di descrivere la tendenza centrale per i dati contenuti nel file sexual-partners.csv, separatamente per maschi e femmine. Il dataset fornisce la distribuzione del numero totale dichiarato di partner sessuali di sesso opposto nella vita per uomini e donne di et√† compresa tra 35 e 44 anni. I dati provengono dal sondaggio Natsal-3 e corrispondono a un totale di 796 uomini e 1193 donne.\nProcediamo all‚Äôimportazione dei dati per iniziare l‚Äôanalisi.\n\ndf &lt;- rio::import(here::here(\"data\", \"sexual-partners.csv\"))\n\nEsaminiamo alcune righe prese a caso dal data frame df:\n\ndf[sample(1:nrow(df), size = 10, replace = FALSE), ]\n#&gt;      Gender NumPartners\n#&gt; 561     Man          15\n#&gt; 321     Man           6\n#&gt; 1177  Woman           3\n#&gt; 1098  Woman           2\n#&gt; 1252  Woman           4\n#&gt; 1170  Woman           3\n#&gt; 634     Man          21\n#&gt; 49      Man           1\n#&gt; 1152  Woman           3\n#&gt; 1327  Woman           5\n\nLa colonna Gender riporta il genere del rispondente e la colonna NumPartners il numero di partner sessuali di sesso opposto dichiarati.\nEsaminiamo la numerosit√† di ciascun gruppo.\n\ndf |&gt; \n  group_by(Gender) |&gt; \n  summarize(count = n())\n#&gt; # A tibble: 2 √ó 2\n#&gt;   Gender count\n#&gt;   &lt;chr&gt;  &lt;int&gt;\n#&gt; 1 Man      796\n#&gt; 2 Woman   1193\n\nPoniamoci innnanzitutto il problema di visualizzare i dati con un istogramma, separatamente per maschi e femmine. Per ragioni di spazio ci limiteremo ad un numero massimo di partner sessuali di 50 (ma in questo campione il numero massimo arriva a 501 per gli uomini e 550 per le donne):\n\ndf |&gt; \n  group_by(Gender) |&gt; \n  summarize(maximum = max(NumPartners))\n#&gt; # A tibble: 2 √ó 2\n#&gt;   Gender maximum\n#&gt;   &lt;chr&gt;    &lt;int&gt;\n#&gt; 1 Man        501\n#&gt; 2 Woman      550\n\nIniziamo calcolando la percentuale di intervistati per ciascun valore possibile della variabile ‚Äúnumero di partner sessuali‚Äù, compreso tra 0 e 50. Il calcolo verr√† svolto in due passaggi:\n\nConteggio delle frequenze assolute: Per ogni valore della variabile ‚Äúnumero di partner sessuali‚Äù e per ciascun gruppo di genere (uomini e donne), contiamo quante volte quel valore compare nei dati.\nCalcolo delle percentuali relative: Per ciascun gruppo di genere, dividiamo il conteggio di ogni valore per il totale delle osservazioni nel gruppo e moltiplichiamo per 100 per ottenere la percentuale.\n\n\n# Filtra i dati troncando il numero di partner a 50\ndf_truncated &lt;- df[df$NumPartners &lt;= 50, ]\n\n# Calcola il conteggio per ciascun genere e numero di partner\ncounts_data &lt;- df_truncated %&gt;%\n  group_by(Gender, NumPartners) %&gt;%  # Raggruppa per genere e numero di partner\n  summarise(Count = n(), .groups = \"drop\")  # Conta le occorrenze\n\n# Aggiunge la percentuale relativa per ciascun genere\npercentage_data &lt;- counts_data %&gt;%\n  group_by(Gender) %&gt;%  # Raggruppa nuovamente per genere\n  mutate(Percentage = Count / sum(Count) * 100)  # Calcola la percentuale\n\nhead(percentage_data)\n#&gt; # A tibble: 6 √ó 4\n#&gt; # Groups:   Gender [1]\n#&gt;   Gender NumPartners Count Percentage\n#&gt;   &lt;chr&gt;        &lt;int&gt; &lt;int&gt;      &lt;dbl&gt;\n#&gt; 1 Man              0     6      0.789\n#&gt; 2 Man              1   100     13.2  \n#&gt; 3 Man              2    44      5.79 \n#&gt; 4 Man              3    39      5.13 \n#&gt; 5 Man              4    58      7.63 \n#&gt; 6 Man              5    51      6.71\n\nPossiamo ora creare gli istogrammi per maschi e femmine:\n\n# Crea l'istogramma separato per maschi e femmine\ngender_labels &lt;- c(\"Man\" = \"Uomini 35-44\", \"Woman\" = \"Donne 35-44\")\n\n# Trova il massimo valore di Percentage per impostare lo stesso limite\ny_max &lt;- max(percentage_data$Percentage)\n\n# Grafico con limiti dell'asse y uguali nei due pannelli\npercentage_data |&gt;\n  ggplot(aes(NumPartners, Percentage, fill = Gender)) +\n  geom_col(position = \"dodge\", color = \"black\") +\n  facet_wrap(~Gender, labeller = labeller(Gender = gender_labels)) +\n  scale_y_continuous(limits = c(0, y_max)) +  # Imposta i limiti dell'asse y\n  labs(\n    x = \"Numero di partner sessuali opposti dichiarati nella vita\",\n    y = \"Percentuale\"\n  ) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nNotiamo che la distribuzione √® altamente asimmetrica positiva. Come possiamo descrivere la tendenza centrale di questi dati?\nCalcoliamo gli indici di tendenza centrale all‚Äôinterno dei due gruppi. Per la moda utilizziamo una funzione personalizzata:\n\n# Funzione personalizzata per calcolare la moda\nget_mode &lt;- function(x) {\n  # Calcola la tabella di frequenza e restituisce il valore con frequenza massima\n  tbl &lt;- table(x)\n  as.numeric(names(tbl)[which.max(tbl)])\n}\n\n# Calcolo delle statistiche per Gender\ndf |&gt; \n  group_by(Gender) |&gt; \n  summarise(\n    mean_sex_partner = mean(NumPartners, na.rm = TRUE),\n    median_sex_partner = median(NumPartners, na.rm = TRUE),\n    mode_sex_partner = get_mode(NumPartners)  # Usa la funzione personalizzata per la moda\n  )\n#&gt; # A tibble: 2 √ó 4\n#&gt;   Gender mean_sex_partner median_sex_partner mode_sex_partner\n#&gt;   &lt;chr&gt;             &lt;dbl&gt;              &lt;dbl&gt;            &lt;dbl&gt;\n#&gt; 1 Man               17.0                   8                1\n#&gt; 2 Woman              8.23                  5                1\n\n√à evidente che, quando la distribuzione dei dati √® altamente asimmetrica, come nel caso attuale, gli indici di tendenza centrale ‚Äì media, mediana e moda ‚Äì possono fornire risultati molto diversi, rendendo difficile individuare una misura rappresentativa della tendenza centrale.\n\nLa media risulta pi√π elevata rispetto alla mediana e alla moda. Questo √® tipico di una distribuzione asimmetrica positiva, caratterizzata da una lunga coda destra: pochi individui con valori estremamente alti influenzano la media, spostandola verso destra.\n\nLa mediana, invece, rappresenta il valore centrale della distribuzione e risulta meno influenzata dai valori estremi. Per questo motivo, √® spesso pi√π vicina alla ‚Äúrealt√†‚Äù dei dati, offrendo una stima pi√π robusta della tendenza centrale per la maggior parte degli individui.\n\nLa moda, infine, corrisponde al valore pi√π frequente nella distribuzione (in questo caso, 1 partner). Tuttavia, in presenza di un‚Äôelevata dispersione dei dati, la moda pu√≤ risultare poco rappresentativa della distribuzione complessiva.\n\nIn conclusione, quando la distribuzione √® fortemente asimmetrica, la mediana √® generalmente l‚Äôindice di tendenza centrale pi√π appropriato. Essendo insensibile ai valori estremi, fornisce una rappresentazione pi√π robusta della ‚Äúposizione centrale‚Äù dei dati. Tuttavia, √® utile integrare la mediana con la media e la moda per offrire un quadro pi√π completo della distribuzione.\nPer una descrizione efficace della tendenza centrale in distribuzioni asimmetriche, si consiglia dunque di seguire questa procedura:\n\nutilizzare la mediana come misura principale della tendenza centrale;\n\nriportare media e moda come complemento per confrontare i risultati e interpretare eventuali differenze.\n\n√à comunque fondamentale visualizzare la distribuzione dei dati attraverso grafici appropriati, come istogrammi o boxplot. Questi strumenti consentono di evidenziare chiaramente l‚Äôasimmetria, identificare valori estremi e comprendere meglio la struttura dei dati.\nInoltre, per arricchire i sommari numerici, √® importante associare indici di dispersione che tratteremo in seguito.\n\n19.6.1 Media Spuntata\nLa media spuntata, indicata come \\(\\bar{x}_t\\) o trimmed mean, √® un metodo di calcolo della media che prevede l‚Äôeliminazione di una determinata percentuale di dati estremi prima di effettuare la media aritmetica. Solitamente, viene eliminato il 10% dei dati, ovvero il 5% all‚Äôinizio e alla fine della distribuzione. Per ottenere la media spuntata, i dati vengono ordinati in modo crescente, \\(x_1 \\leq x_2 \\leq x_3 \\leq \\dots \\leq x_n\\), e quindi viene eliminato il primo 5% e l‚Äôultimo 5% dei dati nella sequenza ordinata. Infine, la media spuntata √® calcolata come la media aritmetica dei dati rimanenti. Questo approccio √® utile quando ci sono valori anomali o quando la distribuzione √® asimmetrica e la media aritmetica non rappresenta adeguatamente la tendenza centrale dei dati.\n\nEsempio 19.1 A titolo di esempio, procediamo al calcolo della media spuntata dei valori NumPartners per i due gruppi definiti dalla variabile Gender, escludendo il 10% dei valori pi√π estremi.\n\nglimpse(df)\n#&gt; Rows: 1,989\n#&gt; Columns: 2\n#&gt; $ Gender      &lt;chr&gt; \"Man\", \"Man\", \"Man\", \"Man\", \"Man\", \"Man\", \"Man\", \"Man\"‚Ä¶\n#&gt; $ NumPartners &lt;int&gt; 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ‚Ä¶\n\nUomini:\n\nsex_partners_men &lt;- df[df$Gender == \"Man\", \"NumPartners\"]\nmean(sex_partners_men, trim = 0.10, na.rm = TRUE)\n#&gt; [1] 10.6\n\nDonne:\n\nsex_partners_women &lt;- df[df$Gender == \"Woman\", \"NumPartners\"]\nmean(sex_partners_women, trim = 0.10, na.rm = TRUE)\n#&gt; [1] 6.01\n\n\n\n\n19.6.2 Quando Usare Media, Media Spuntata, Moda e Mediana\nLa scelta della misura di tendenza centrale pi√π appropriata dipende dal tipo di dati, dalla distribuzione e dalla presenza di valori anomali o asimmetrie.\n\n19.6.2.1 Moda\nLa moda √® il valore che compare con maggiore frequenza nei dati ed √® l‚Äôunica misura di tendenza centrale utilizzabile per dati a livello nominale (categorie senza ordine) o ordinale (categorie ordinate ma senza distanza definita). Tuttavia:\n- In una distribuzione unimodale, la moda pu√≤ rappresentare un indicatore significativo della tendenza centrale.\n- In distribuzioni multimodali (con pi√π valori ricorrenti), la moda diventa meno interpretabile, poich√© l‚Äôesistenza di pi√π ‚Äúpicchi‚Äù rende difficile individuare un singolo valore rappresentativo.\n- Nei dati continui, la moda pu√≤ non essere definita o risultare meno informativa, soprattutto in presenza di valori unici.\n\n\n19.6.2.2 Media\nLa media aritmetica √® una misura efficace di tendenza centrale se la distribuzione √® simmetrica e priva di valori anomali. In tali condizioni, la media rappresenta il ‚Äúbaricentro‚Äù della distribuzione, equilibrando i valori a sinistra e a destra. Tuttavia:\n\nIn distribuzioni asimmetriche o con outlier, la media √® fortemente influenzata dai valori estremi e tende a spostarsi nella direzione della coda pi√π lunga (asimmetria positiva o negativa).\n\nIn questi casi, la media potrebbe non essere rappresentativa della tendenza centrale reale.\n\n\n\n19.6.2.3 Media Spuntata\nLa media spuntata √® una versione modificata della media, calcolata dopo aver rimosso una certa percentuale di valori estremi (generalmente il 5% o il 10%) sia dalla coda inferiore che da quella superiore della distribuzione. Questa misura √® particolarmente utile quando:\n- La distribuzione √® asimmetrica o contiene outlier, ma si desidera comunque una stima della tendenza centrale che consideri gran parte dei dati.\n- La media spuntata √® meno sensibile ai valori anomali rispetto alla media tradizionale, pur mantenendo il vantaggio di considerare un‚Äôampia porzione dei dati.\n\n\n19.6.2.4 Mediana\nLa mediana √® il valore centrale che divide il campione in due met√†: il 50% dei dati √® inferiore e il restante 50% √® superiore. √à una misura robusta della tendenza centrale, particolarmente adatta quando:\n- La distribuzione √® asimmetrica o contiene valori anomali. Poich√© si basa sulla posizione dei dati e non sulle loro dimensioni, la mediana non √® influenzata da valori estremi.\n- Nei dati ordinali, la mediana √® spesso pi√π appropriata della media, poich√© non richiede una scala numerica con distanze precise.\n\n\n19.6.2.5 Quale Misura Scegliere?\n\nDistribuzioni Simmetriche:\nLa media √® la scelta pi√π appropriata, poich√© riflette bene la tendenza centrale.\nDistribuzioni Asimmetriche o con Outlier:\nLa mediana √® preferibile perch√© √® robusta e meno influenzata dai valori estremi. In alternativa, si pu√≤ utilizzare la media spuntata per ottenere un compromesso tra media e mediana.\nDati Categoriali:\nLa moda √® l‚Äôunica misura applicabile, ma √® interpretabile solo in distribuzioni unimodali.\nDistribuzioni Multimodali:\nIn questo caso, √® importante visualizzare i dati (ad esempio con un istogramma) e descrivere ciascun ‚Äúpicco‚Äù separatamente, poich√© nessuna delle misure tradizionali (media, mediana, moda) sar√† sufficiente da sola per rappresentare la tendenza centrale.\n\nIn conclusione\n\nLa media √® ideale per distribuzioni simmetriche senza valori estremi.\n\nLa mediana √® pi√π robusta e appropriata in caso di asimmetria o outlier.\n\nLa media spuntata rappresenta una soluzione intermedia utile nei casi con pochi valori anomali.\n\nLa moda √® rilevante solo per dati nominali o ordinale, ma perde significato in distribuzioni multimodali.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Indicatori di tendenza centrale e variabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#la-variabilit√†-nei-dati-psicologici",
    "href": "chapters/eda/07_loc_scale.html#la-variabilit√†-nei-dati-psicologici",
    "title": "19¬† Indicatori di tendenza centrale e variabilit√†",
    "section": "19.7 La Variabilit√† nei Dati Psicologici",
    "text": "19.7 La Variabilit√† nei Dati Psicologici\nSe misuriamo il livello di stress percepito da una persona dieci volte in un solo giorno, √® improbabile ottenere esattamente lo stesso valore ogni volta, anche utilizzando la stessa scala. Se valutiamo il punteggio di autostima in un campione di studenti universitari utilizzando un questionario standardizzato, otterremo valori differenti per ciascun partecipante. Allo stesso modo, se registriamo il tempo di reazione in un compito cognitivo somministrato a un gruppo di persone, noteremo una variabilit√† nei tempi di risposta anche tra prove dello stesso individuo. La variazione √® una caratteristica intrinseca dei fenomeni psicologici e comportamentali, e comprenderne a fondo la natura, le cause e i modi per descriverla √® essenziale. In effetti, attribuire la variazione a determinati fattori causali ‚Äì come differenze individuali, influenze ambientali o variabilit√† di misurazione ‚Äì √® uno degli obiettivi principali dell‚Äôanalisi statistica. In questa sezione, esamineremo come la variazione pu√≤ essere suddivisa, i due tipi principali di variazione (spiegata e non spiegata) e i metodi per descriverla sia visivamente sia numericamente.\nIn questa sezione, esamineremo come la variazione pu√≤ essere suddivisa, i due tipi principali di variazione (spiegata e non spiegata) e i metodi per descriverla sia visivamente sia numericamente. Comprendere la variabilit√† √® cruciale in psicologia, poich√© molti fenomeni, come le differenze individuali o le fluttuazioni dell‚Äôumore, dipendono proprio dall‚Äôanalisi della dispersione dei dati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Indicatori di tendenza centrale e variabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#quantili",
    "href": "chapters/eda/07_loc_scale.html#quantili",
    "title": "19¬† Indicatori di tendenza centrale e variabilit√†",
    "section": "19.8 Quantili",
    "text": "19.8 Quantili\nI quantili sono valori che dividono la distribuzione dei dati in intervalli proporzionali, fornendo informazioni sulla loro variabilit√† e sui punti critici della distribuzione. Il quantile non interpolato di ordine \\(p\\) (\\(0 &lt; p &lt; 1\\)) √® definito come il valore al di sotto del quale si trova una frazione \\(p\\) dei dati.\nLa formula per calcolare il quantile non interpolato √®:\n\\[\nq_p = x_{(k)},\n\\]\ndove \\(x_{(k)}\\) √® il valore \\(k\\)-esimo dell‚Äôinsieme di dati ordinati in modo crescente. L‚Äôindice \\(k\\) √® determinato come:\n\\[\nk = \\lceil p \\cdot n \\rceil,\n\\]\ndove \\(n\\) √® il numero totale di osservazioni e \\(\\lceil \\cdot \\rceil\\) rappresenta la funzione di arrotondamento all‚Äôintero successivo.\n\nEsempio 19.2 Consideriamo il seguente insieme di dati:\n\\[\n\\{ 15, 20, 23, 25, 28, 30, 35, 40, 45, 50 \\}.\n\\]\nSupponiamo di voler calcolare il quantile di ordine 0.3 (30¬∞ percentile):\n1. I dati sono gi√† ordinati in ordine crescente.\n2. Calcoliamo \\(k\\) come:\n\\[\n   k = \\lceil 0.3 \\cdot 10 \\rceil = \\lceil 3 \\rceil = 3.\n   \\]\n\nIl quantile corrisponde al terzo valore nell‚Äôinsieme ordinato:\n\\[\nq_{0.3} = x_{(3)} = 23.\n\\]\n\n\n\n\n19.8.1 Quantile Interpolato\nPer valori di \\(p\\) che non corrispondono esattamente a una posizione nell‚Äôinsieme di dati ordinati, si utilizza il quantile interpolato. Questo metodo stima il valore attraverso un‚Äôinterpolazione lineare tra i dati adiacenti. √à particolarmente utile per set di dati numerosi e viene calcolato automaticamente tramite software statistici come R o Python.\n\n\n19.8.2 Interpretazione dei Quantili\nI quantili completano le misure di tendenza centrale (media, mediana, moda), permettendo di esplorare la distribuzione dei dati e identificare i valori critici. In particolare:\n\nI quantili bassi (ad esempio il 10¬∞ percentile) forniscono informazioni sui valori minimi o nella parte inferiore della distribuzione.\n\nI quantili alti (ad esempio il 90¬∞ percentile) aiutano a esplorare i valori massimi o nella parte superiore della distribuzione.\n\nLa mediana √® un caso particolare di quantile, corrispondente al quantile di ordine 0.5: divide la distribuzione in due parti uguali.\n\n\n\n19.8.3 Importanza dei Quantili\nL‚Äôuso congiunto di quantili e misure di tendenza centrale √® fondamentale per ottenere una descrizione completa e robusta di una distribuzione, soprattutto in presenza di asimmetrie o valori anomali. Mentre la media e la mediana descrivono il comportamento ‚Äúcentrale‚Äù dei dati, i quantili permettono di analizzare la dispersione e identificare aree di particolare interesse nella distribuzione.\n\nEsempio 19.3 Consideriamo ora la variabile NumPartners per due gruppi definiti dalla variabile Gender (‚ÄúMan‚Äù e ‚ÄúWoman‚Äù). Calcoleremo i quantili di ordine 0.1 e 0.9 per ciascun gruppo:\n\nIl quantile di ordine 0.1 rappresenta il valore al di sotto del quale si trova il 10% dei dati.\n\nIl quantile di ordine 0.9 rappresenta il valore al di sotto del quale si trova il 90% dei dati.\n\nCalcolo per il Gruppo ‚ÄúMan‚Äù:\n\n# Quantili di ordine 0.1 e 0.9 per i maschi\nquantile(df[df$Gender == \"Man\", \"NumPartners\"], probs = c(0.1, 0.9))\n#&gt;  10%  90% \n#&gt;  1.0 34.5\n\n\n10¬∞ percentile (0.1): \\(1.0\\) ‚Üí Il 10% degli uomini ha dichiarato al massimo 1 partner sessuale.\n\n90¬∞ percentile (0.9): \\(34.5\\) ‚Üí Il 10% degli uomini con i valori pi√π alti ha dichiarato pi√π di 34 partner sessuali.\n\nCalcolo per il Gruppo ‚ÄúWoman‚Äù:\n\n# Quantili di ordine 0.1 e 0.9 per le femmine\nquantile(df[df$Gender == \"Woman\", \"NumPartners\"], probs = c(0.1, 0.9))\n#&gt; 10% 90% \n#&gt;   1  18\n\n\n10¬∞ percentile (0.1): \\(1.0\\) ‚Üí Anche per le donne, il 10% dei valori pi√π bassi corrisponde a 1 partner sessuale.\n\n90¬∞ percentile (0.9): \\(18.0\\) ‚Üí Il 10% delle donne con i valori pi√π alti ha dichiarato pi√π di 18 partner sessuali.\n\nI quantili calcolati forniscono una descrizione chiara della dispersione e della variabilit√† dei dati nei due gruppi:\n\nIl fatto che il 10¬∞ percentile sia identico per entrambi i gruppi suggerisce che una porzione simile di intervistati dichiara un numero molto basso di partner sessuali.\n\nLa differenza nel 90¬∞ percentile tra uomini e donne √® significativa:\n\nPer gli uomini, il valore √® pi√π alto (\\(34.5\\)), indicando una maggiore presenza di valori estremi nella coda superiore della distribuzione.\n\nPer le donne, il valore (\\(18.0\\)) √® inferiore, suggerendo una minore dispersione nella parte alta della distribuzione.\n\n\nQuesta differenza evidenzia una asimmetria positiva pi√π pronunciata nel gruppo degli uomini, dove pochi individui con valori elevati ‚Äútirano‚Äù la coda della distribuzione verso destra.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Indicatori di tendenza centrale e variabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#intervallo-di-variazione",
    "href": "chapters/eda/07_loc_scale.html#intervallo-di-variazione",
    "title": "19¬† Indicatori di tendenza centrale e variabilit√†",
    "section": "19.9 Intervallo di variazione",
    "text": "19.9 Intervallo di variazione\nL‚Äôintervallo di variazione √® il pi√π semplice tra gli indici di dispersione. Si calcola come la differenza tra il valore massimo e il valore minimo di una distribuzione:\n\\[\n\\text{Intervallo di variazione} = \\text{valore massimo} - \\text{valore minimo}.\n\\]\nTuttavia, l‚Äôintervallo di variazione presenta due limiti principali:\n\nSi basa esclusivamente su due valori della distribuzione, ignorando tutte le altre osservazioni.\n√à altamente sensibile ai valori anomali (ad esempio, un adolescente con un punteggio di autostima molto pi√π basso o pi√π alto rispetto alla maggior parte del campione).\n\n\nEsempio 19.4 Supponiamo di misurare il punteggio di autostima in un campione di adolescenti. Se il punteggio massimo √® 35 e il minimo √® 12, l‚Äôintervallo di variazione sar√†:\n\\[\n\\text{Intervallo di variazione} = 35 - 12 = 23.\n\\]",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Indicatori di tendenza centrale e variabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#differenza-interquartile",
    "href": "chapters/eda/07_loc_scale.html#differenza-interquartile",
    "title": "19¬† Indicatori di tendenza centrale e variabilit√†",
    "section": "19.10 Differenza interquartile",
    "text": "19.10 Differenza interquartile\nUn‚Äôaltra misura basata sull‚Äôordinamento √® la differenza interquartile (IQR), calcolata come la differenza tra il terzo quartile (\\(Q_3\\)) e il primo quartile (\\(Q_1\\)):\n\\[\n\\text{IQR} = Q_3 - Q_1.\n\\]\nL‚ÄôIQR considera solo il 50% centrale dei dati, ignorando gli estremi, rendendolo meno sensibile ai valori anomali rispetto all‚Äôintervallo di variazione.\n\nEsempio 19.5 Supponiamo di analizzare il livello di ansia percepita in un gruppo di studenti universitari. Se il primo quartile (\\(Q_1\\)) √® 25 (25% degli studenti ha un livello di ansia pari o inferiore a 25) e il terzo quartile (\\(Q_3\\)) √® 40 (75% degli studenti ha un livello di ansia pari o inferiore a 40), allora:\n\\[\n\\text{IQR} = 40 - 25 = 15.\n\\]",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Indicatori di tendenza centrale e variabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#la-varianza",
    "href": "chapters/eda/07_loc_scale.html#la-varianza",
    "title": "19¬† Indicatori di tendenza centrale e variabilit√†",
    "section": "19.11 La Varianza",
    "text": "19.11 La Varianza\nPer ottenere una misura di dispersione che consideri tutte le osservazioni, l‚Äôindice pi√π utilizzato √® la varianza. Questa misura valuta la dispersione dei dati rispetto alla media e si calcola come la media dei quadrati degli scarti di ciascun valore (\\(x_i\\)) dalla media (\\(\\bar{x}\\)):\n\\[\nS^2 = \\frac{1}{n} \\sum_{i=1}^n (x_i - \\bar{x})^2.\n\\tag{19.3}\\]\n\nEsempio 19.6 Supponiamo di calcolare il numero di ore dedicate allo studio quotidiano da un gruppo di partecipanti a un esperimento di psicologia. Se la media delle ore studiate √® 4 (\\(\\bar{x} = 4\\)), la varianza misura quanto i dati si discostano da questa media. I dati con una varianza maggiore indicano una maggiore diversit√† nei comportamenti di studio, mentre una varianza minore suggerisce un gruppo pi√π omogeneo.\n\n\n19.11.1 Propriet√† della varianza\n\nUnit√† di misura: La varianza √® espressa nell‚Äôunit√† di misura al quadrato dei dati originali (es. ore quadrate nel caso precedente), rendendola meno intuitiva da interpretare.\nSensibilit√† agli outlier: Poich√© ogni scarto viene elevato al quadrato, i valori estremi influenzano significativamente la varianza.\n\n\n\n19.11.2 Variazione Sistematica e Non Sistematica\nNell‚Äôanalisi dei dati psicologici, la variabilit√† pu√≤ essere suddivisa in due componenti principali:\n\nVariazione non sistematica (rumore):\n√à la variabilit√† casuale, non attribuibile a una causa specifica. Si manifesta come errori di misurazione o fluttuazioni imprevedibili che non seguono uno schema chiaro. Esempi includono:\n\nErrori casuali nel completare un test (ad esempio, distrazione momentanea).\n\nFluttuazioni dell‚Äôumore durante la giornata.\n\nVariazione sistematica (segnale):\n√à la variabilit√† attribuibile a fattori specifici che influiscono in modo prevedibile sui dati. Questa componente rappresenta il ‚Äúsegnale‚Äù utile nell‚Äôanalisi statistica. Esempi includono:\n\nIl miglioramento nei punteggi di un test di attenzione dopo una sessione di meditazione.\n\nLe differenze individuali nei livelli di self-compassion misurati da una scala psicologica.\n\n\nPer esempio, supponiamo di misurare il livello di stress prima e dopo una sessione di rilassamento:\n\nLa variazione sistematica rappresenta la riduzione del livello di stress dovuta all‚Äôeffetto del rilassamento.\n\nLa variazione non sistematica comprende fattori casuali, come distrazioni, stanchezza momentanea o condizioni personali dei partecipanti.\n\n\n\n19.11.3 Calcolo della Varianza in R\nPer illustrare come quantificare la variabilit√†, utilizziamo i punteggi totali della Self-Compassion Scale su un campione di studenti universitari, forniti nel file scs_scores.csv.\nPassaggio 1: Importazione dei dati\n\nscs_df &lt;- rio::import(here::here(\"data\", \"scs_scores.csv\")) |&gt; \n  dplyr::rename(ts = scs_total_score)\nglimpse(scs_df)\n#&gt; Rows: 121\n#&gt; Columns: 7\n#&gt; $ self_kindness       &lt;int&gt; 14, 15, 19, 10, 11, 9, 19, 13, 23, 5, 14, 22, ‚Ä¶\n#&gt; $ common_humanity     &lt;int&gt; 11, 9, 16, 11, 10, 8, 12, 12, 19, 4, 13, 18, 6‚Ä¶\n#&gt; $ mindfulness         &lt;int&gt; 10, 10, 16, 9, 9, 10, 8, 12, 20, 8, 15, 15, 6,‚Ä¶\n#&gt; $ self_judgment       &lt;int&gt; 15, 16, 13, 15, 18, 19, 11, 15, 9, 25, 17, 11,‚Ä¶\n#&gt; $ isolation           &lt;int&gt; 16, 11, 12, 14, 13, 16, 11, 11, 5, 20, 14, 11,‚Ä¶\n#&gt; $ over_identification &lt;int&gt; 14, 11, 8, 11, 14, 17, 20, 15, 7, 20, 15, 16, ‚Ä¶\n#&gt; $ ts                  &lt;int&gt; 68, 74, 96, 68, 63, 53, 75, 74, 119, 30, 74, 9‚Ä¶\n\nLa colonna ts contiene i punteggi totali della scala.\nPassaggio 2: Calcolo della varianza\nUtilizzando la formula della varianza:\n\nsum((scs_df$ts - mean(scs_df$ts))^2) / length(scs_df$ts)\n#&gt; [1] 405\n\nCon la funzione var() corretta per il campione:\n\nvar(scs_df$ts) * (length(scs_df$ts) - 1) / length(scs_df$ts)\n#&gt; [1] 405\n\n\n\n19.11.4 Interpretazione della Varianza\nLa varianza misura la dispersione totale dei dati, che pu√≤ essere scomposta in:\n\nVariazione sistematica:\nNel caso della Self-Compassion Scale, la varianza sistematica riflette le differenze tra individui nei livelli di self-compassion. Alcuni individui mostrano livelli elevati (fattore protettivo contro il disagio psicologico), mentre altri livelli pi√π bassi.\nVariazione non sistematica:\nQuesta componente √® dovuta a errori di misurazione e altre cause casuali. La psicometria presuppone che il punteggio osservato sia la somma di:\n\\[\n\\text{Punteggio osservato} = \\text{Punteggio vero} + \\text{Errore di misurazione}.\n\\] Esempi di errori includono distrazioni o stanchezza dei partecipanti; limitazioni della scala psicologica nella misurazione accurata del costrutto.\n\n\n\n\n19.11.5 Affidabilit√† e Rapporto Segnale-Rumore\nPerch√© uno strumento psicometrico sia considerato affidabile, almeno l‚Äô80% della varianza osservata deve essere attribuibile alla componente vera del costrutto. Questo requisito si traduce in un coefficiente di affidabilit√† di almeno 0.8.\n\nUn alto rapporto segnale-rumore indica che la maggior parte della variabilit√† osservata √® dovuta a fattori sistematici (segnale) e non a errori casuali (rumore).\n\nUn basso rapporto segnale-rumore suggerisce che la variabilit√† casuale (rumore) √® predominante e lo strumento potrebbe non essere sufficientemente preciso.\n\nLa disciplina della psicometria fornisce strumenti per:\n\nValutare l‚Äôaffidabilit√† delle scale psicologiche (es. Alpha di Cronbach).\n\nProgettare strumenti pi√π accurati per minimizzare la variabilit√† non sistematica (rumore).\n\nUno strumento affidabile assicura che i risultati riflettano con precisione le differenze reali tra gli individui e non siano influenzati da errori casuali.\n\nSupponiamo di valutare l‚Äôefficacia di un nuovo metodo di studio misurando il miglioramento in un test di comprensione:\n\nUn alto rapporto segnale-rumore (ovvero, un‚Äôalta affidabilit√†) indica che il miglioramento osservato √® chiaramente attribuibile al metodo.\n\nUn basso rapporto segnale-rumore (bassa affidabilit√†) implica che la variabilit√† √® prevalentemente casuale e l‚Äôeffetto del metodo non √® distinguibile dal rumore.\n\nIn conclusione, la distinzione tra variazione sistematica e non sistematica √® fondamentale per l‚Äôanalisi dei dati psicologici:\n\nLa variazione sistematica rappresenta il ‚Äúsegnale‚Äù, ossia l‚Äôeffetto reale o il fattore di interesse.\n\nLa variazione non sistematica rappresenta il ‚Äúrumore‚Äù, ossia la variabilit√† casuale o l‚Äôerrore di misurazione.\n\nL‚Äôobiettivo √® massimizzare il segnale e minimizzare il rumore, garantendo strumenti affidabili che consentano di ottenere risultati precisi e interpretabili.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Indicatori di tendenza centrale e variabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#stima-della-varianza-della-popolazione",
    "href": "chapters/eda/07_loc_scale.html#stima-della-varianza-della-popolazione",
    "title": "19¬† Indicatori di tendenza centrale e variabilit√†",
    "section": "19.12 Stima della Varianza della Popolazione",
    "text": "19.12 Stima della Varianza della Popolazione\nSi noti il denominatore della formula della varianza. Nell‚ÄôEquazione¬†19.3, ho utilizzato \\(n\\) come denominatore (l‚Äôampiezza campionaria, ovvero il numero di osservazioni nel campione). In questo modo, otteniamo la varianza come statistica descrittiva del campione. Tuttavia, √® possibile utilizzare \\(n-1\\) come denominatore alternativo:\n\\[\n\\begin{equation}\ns^2 = \\frac{1}{n-1} \\sum_{i=1}^n (x_i - \\bar{x})^2\n\\end{equation}\n\\tag{19.4}\\]\nIn questo secondo caso, otteniamo la varianza come stimatore della varianza della popolazione. Si pu√≤ dimostrare che l‚ÄôEquazione¬†19.4 fornisce una stima corretta (ovvero, non distorta) della varianza della popolazione da cui abbiamo ottenuto il campione, mentre l‚ÄôEquazione¬†19.3 fornisce (in media) una stima troppo piccola della varianza della popolazione. Si presti attenzione alla notazione: \\(S^2\\) rappresenta la varianza come statistica descrittiva, mentre \\(s^2\\) rappresenta la varianza come stimatore.\nPer illustrare questo punto, svolgiamo una simulazione. Consideriamo la distribuzione dei punteggi del quoziente di intelligenza (QI). I valori del QI seguono una particolare distribuzione chiamata distribuzione normale, con media 100 e deviazione standard 15. La forma di questa distribuzione √® illustrata nella figura seguente.\n\n# Define parameters\nx &lt;- seq(100 - 4 * 15, 100 + 4 * 15, by = 0.001)\nmu &lt;- 100\nsigma &lt;- 15\n\n# Compute the PDF\npdf &lt;- dnorm(x, mean = mu, sd = sigma)\n\n# Plot using ggplot2\ndata &lt;- tibble(x = x, pdf = pdf)\nggplot(data, aes(x = x, y = pdf)) +\n  geom_line() +\n  labs(\n    x = \"QI\", \n    y = \"Densit√†\", \n    title = \"Distribuzione del QI nella popolazione\"\n  ) \n\n\n\n\n\n\n\n\nSupponiamo di estrarre un campione casuale di 4 osservazioni dalla popolazione del quoziente di intelligenza ‚Äì in altre parole, supponiamo di misurare il quoziente di intelligenza di 4 persone prese a caso dalla popolazione.\n\nset.seed(123) \nx &lt;- rnorm(4, mean = 100, sd = 15)\nprint(x)\n#&gt; [1]  91.6  96.5 123.4 101.1\n\nCalcoliamo la varianza usando \\(n\\) al denominatore. Si noti che la vera varianza del quoziente di intelligenza √® \\(15^2\\) = 225.\n\nvar(x)\n#&gt; [1] 197\n\nConsideriamo ora 10 campioni casuali del QI, ciascuno di ampiezza 4.\n\nmu &lt;- 100\nsigma &lt;- 15\nsize &lt;- 4\nniter &lt;- 10\nrandom_samples &lt;- list()\n\nset.seed(123) \n\nfor (i in 1:niter) {\n  one_sample &lt;- rnorm(size, mean = mu, sd = sigma)\n  random_samples[[i]] &lt;- one_sample\n}\n\nIl primo campione √®\n\nrandom_samples[1]\n#&gt; [[1]]\n#&gt; [1]  91.6  96.5 123.4 101.1\n\nIl decimo campione √®\n\nrandom_samples[10]\n#&gt; [[1]]\n#&gt; [1] 108.3  99.1  95.4  94.3\n\nStampiamo i valori di tutti i 10 campioni.\n\nrs &lt;- do.call(rbind, random_samples)\nrs\n#&gt;        [,1]  [,2]  [,3]  [,4]\n#&gt;  [1,]  91.6  96.5 123.4 101.1\n#&gt;  [2,] 101.9 125.7 106.9  81.0\n#&gt;  [3,]  89.7  93.3 118.4 105.4\n#&gt;  [4,] 106.0 101.7  91.7 126.8\n#&gt;  [5,] 107.5  70.5 110.5  92.9\n#&gt;  [6,]  84.0  96.7  84.6  89.1\n#&gt;  [7,]  90.6  74.7 112.6 102.3\n#&gt;  [8,]  82.9 118.8 106.4  95.6\n#&gt;  [9,] 113.4 113.2 112.3 110.3\n#&gt; [10,] 108.3  99.1  95.4  94.3\n\nPer ciascun campione (ovvero, per ciascuna riga della matrice precedente), calcoliamo la varianza usando la formula con \\(n\\) al denominatore. Otteniamo cos√¨ 10 stime della varianza della popolazione del QI.\n\nx_var &lt;- apply(rs, 1, var)  # Applica la funzione var su ciascuna riga\nprint(x_var)\n#&gt;  [1] 196.94 337.54 168.55 218.68 333.48  34.52 264.38 234.08   1.97  40.47\n\nNotiamo due cose:\n\nle stime sono molto diverse tra loro; questo fenomeno √® noto con il nome di variabilit√† campionaria;\nin media le stime sono troppo piccole.\n\nPer aumentare la sicurezza riguardo al secondo punto menzionato in precedenza, ripeteremo la simulazione utilizzando un numero di iterazioni maggiore.\n\nmu &lt;- 100\nsigma &lt;- 15\nsize &lt;- 4\nniter &lt;- 10000\nrandom_samples &lt;- list()\n\nset.seed(123) # Replace 123 with your desired seed for reproducibility\n\nfor (i in 1:niter) {\n  one_sample &lt;- rnorm(size, mean = mu, sd = sigma)\n  random_samples[[i]] &lt;- one_sample\n}\n\nrs &lt;- do.call(rbind, random_samples)\nx_var &lt;- apply(rs, 1, var) * (size - 1) / size  # Adjust for population variance (ddof = 0)\n\nEsaminiamo la distribuzione dei valori ottenuti.\n\n# Create a data frame for plotting\ndata &lt;- data.frame(x_var = x_var)\n\n# Plot the histogram using ggplot2\nggplot(data, aes(x = x_var)) +\n  geom_histogram(alpha = 0.5, fill = \"blue\") +\n  labs(\n    x = \"Varianza\", \n    y = \"Frequenza\", \n    title = \"Varianza del QI in campioni di n = 4\"\n  )\n#&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nLa stima pi√π verosimile della varianza del QI √® dato dalla media di questa distribuzione.\n\nmean(x_var)\n#&gt; [1] 169\n\nSi noti che il nostro spospetto √® stato confermato: il valore medio della stima della varianza ottenuta con l‚ÄôEquazione¬†19.3 √® troppo piccolo rispetto al valore corretto di \\(15^2 = 225\\).\nRipetiamo ora la simulazione usando la formula della varianza con \\(n-1\\) al denominatore.\n\nset.seed(123) \n\nmu &lt;- 100\nsigma &lt;- 15\nsize &lt;- 4\nniter &lt;- 10000\nrandom_samples &lt;- list()\n\nfor (i in 1:niter) {\n  one_sample &lt;- rnorm(size, mean = mu, sd = sigma)\n  random_samples[[i]] &lt;- one_sample\n}\n\nrs &lt;- do.call(rbind, random_samples)\nx_var &lt;- apply(rs, 1, var)  # ddof = 1 is default for var in R\n\nmean(x_var)\n#&gt; [1] 225\n\nNel secondo caso, se utilizziamo \\(n-1\\) come denominatore per calcolare la stima della varianza, il valore atteso di questa stima √® molto vicino al valore corretto di 225. Se il numero di campioni fosse infinito, i due valori sarebbero identici.\nIn conclusione, le due formule della varianza hanno scopi diversi. La formula della varianza con \\(n\\) al denominatore viene utilizzata come statistica descrittiva per descrivere la variabilit√† di un particolare campione di osservazioni. D‚Äôaltro canto, la formula della varianza con \\(n-1\\) al denominatore viene utilizzata come stimatore per ottenere la migliore stima della varianza della popolazione da cui quel campione √® stato estratto.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Indicatori di tendenza centrale e variabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#deviazione-standard",
    "href": "chapters/eda/07_loc_scale.html#deviazione-standard",
    "title": "19¬† Indicatori di tendenza centrale e variabilit√†",
    "section": "19.13 Deviazione Standard",
    "text": "19.13 Deviazione Standard\nPer interpretare la varianza in modo pi√π intuitivo, si pu√≤ calcolare la deviazione standard (o scarto quadratico medio o scarto tipo) prendendo la radice quadrata della varianza. La deviazione standard √® espressa nell‚Äôunit√† di misura originaria dei dati, a differenza della varianza che √® espressa nel quadrato dell‚Äôunit√† di misura dei dati. La deviazione standard fornisce una misura della dispersione dei dati attorno alla media, rendendo pi√π facile la comprensione della variabilit√† dei dati.\nLa deviazione standard (o scarto quadratico medio, o scarto tipo) √® definita come:\n\\[\ns^2 = \\sqrt{(n-1)^{-1} \\sum_{i=1}^n (x_i - \\bar{x})^2}.\n\\tag{19.5}\\]\nQuando tutte le osservazioni sono uguali, \\(s = 0\\), altrimenti \\(s &gt; 0\\).\n\n\n\n\n\n\nIl termine standard deviation √® stato introdotto in statistica da Pearson nel 1894 assieme alla lettera greca \\(\\sigma\\) che lo rappresenta. Il termine italiano ‚Äúdeviazione standard‚Äù ne √® la traduzione pi√π utilizzata nel linguaggio comune; il termine dell‚ÄôEnte Nazionale Italiano di Unificazione √® tuttavia ‚Äúscarto tipo‚Äù, definito come la radice quadrata positiva della varianza.\n\n\n\nLa deviazione standard \\(s\\) dovrebbe essere utilizzata solo quando la media √® una misura appropriata per descrivere il centro della distribuzione, ad esempio nel caso di distribuzioni simmetriche. Tuttavia, √® importante tener conto che, come la media \\(\\bar{x}\\), anche la deviazione standard √® fortemente influenzata dalla presenza di dati anomali, ovvero pochi valori che si discostano notevolmente dalla media rispetto agli altri dati della distribuzione. In presenza di dati anomali, la deviazione standard pu√≤ risultare ingannevole e non rappresentare accuratamente la variabilit√† complessiva della distribuzione. Pertanto, √® fondamentale considerare attentamente il contesto e le caratteristiche dei dati prima di utilizzare la deviazione standard come misura di dispersione. In alcune situazioni, potrebbe essere pi√π appropriato ricorrere a misure di dispersione robuste o ad altre statistiche descrittive per caratterizzare la variabilit√† dei dati in modo pi√π accurato e affidabile.\n\nEsempio 19.7 Calcoliamo la deviazione standard per i valori di self-compassion del campione di dati esaminato in precedenza. Applicando l‚ÄôEquazione¬†19.5, per tutto il campione abbiamo\n\nsd(scs_df$ts)\n#&gt; [1] 20.2\n\n\n\n19.13.1 Interpretazione\nLa deviazione standard misura la dispersione dei dati rispetto alla media aritmetica. In termini semplici, indica quanto, in media, ciascun valore osservato si discosta dalla media del campione. Anche se √® simile allo scarto semplice medio campionario (la media dei valori assoluti degli scarti rispetto alla media), la deviazione standard utilizza lo scarto quadratico medio e produce un valore leggermente diverso.\nPer esempio, consideriamo i punteggi di self-compassione di un campione di individui:\n\nEsempio 19.8 Per verificare l‚Äôinterpretazione della deviazione standard, utilizziamo i valori della self-compassione.\n\nsd(scs_df$ts)\n#&gt; [1] 20.2\n\nLa deviazione standard calcolata √® 20.2. Questo valore ci dice che, in media, ciascun punteggio si discosta di circa 20.2 punti dalla media aritmetica dei punteggi.\n\nValore pi√π alto: indica maggiore dispersione dei dati intorno alla media.\nValore pi√π basso: i dati sono pi√π concentrati vicino alla media.\n\nSe calcoliamo anche lo scarto semplice medio campionario per confronto, otteniamo:\n\nmean(abs(scs_df$ts - mean(scs_df$ts, na.rm = TRUE)), na.rm = TRUE)\n#&gt; [1] 16.2\n\nI due valori (deviazione standard e scarto semplice medio) sono simili ma non identici, a causa delle diverse definizioni matematiche.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Indicatori di tendenza centrale e variabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#deviazione-mediana-assoluta",
    "href": "chapters/eda/07_loc_scale.html#deviazione-mediana-assoluta",
    "title": "19¬† Indicatori di tendenza centrale e variabilit√†",
    "section": "19.14 Deviazione Mediana Assoluta",
    "text": "19.14 Deviazione Mediana Assoluta\nLa deviazione mediana assoluta (MAD) √® una misura robusta di dispersione basata sulla mediana. √à definita come la mediana dei valori assoluti delle deviazioni dei dati rispetto alla mediana:\n\\[\n\\text{MAD} = \\text{median} \\left( |X_i - \\text{median}(X)| \\right)\n\\tag{19.6}\\]\nLa MAD √® particolarmente utile per analizzare dati contenenti outlier o distribuzioni asimmetriche, poich√© √® meno influenzata dai valori estremi rispetto alla deviazione standard.\n\n19.14.1 Relazione tra MAD e Deviazione Standard in una Distribuzione Normale\nQuando i dati seguono una distribuzione normale (gaussiana), esiste una relazione approssimativa tra MAD e deviazione standard. La MAD pu√≤ essere convertita in una stima della deviazione standard moltiplicandola per una costante di 1.4826:\n\\[\n\\sigma \\approx k \\times \\text{MAD},\n\\]\ndove:\n\n\\(\\sigma\\) √® la deviazione standard.\nMAD √® la Mediana della Deviazione Assoluta.\n\\(k\\) √® una costante che, per una distribuzione normale, √® tipicamente presa come circa 1.4826.\n\nQuesta costante deriva dalla propriet√† della distribuzione normale, in cui circa il 50% dei valori si trova entro 0.6745 deviazioni standard dalla media.\nLa formula completa per convertire la MAD in una stima della deviazione standard in una distribuzione normale √®:\n\\[\n\\sigma \\approx 1.4826 \\times \\text{MAD}\n\\]\nQuesta relazione √® utile per stimare la deviazione standard in modo pi√π robusto, specialmente quando si sospetta la presenza di outlier o si ha a che fare con campioni piccoli. Di conseguenza, molti software restituiscono il valore MAD moltiplicato per questa costante per fornire un‚Äôindicazione pi√π intuitiva della variabilit√† dei dati. Tuttavia, √® importante notare che questa relazione si mantiene accurata solo per le distribuzioni che sono effettivamente normali. In presenza di distribuzioni fortemente asimmetriche o con elevati outlier, la deviazione standard e la MAD possono fornire indicazioni molto diverse sulla variabilit√† dei dati.\n\nEsempio 19.9 Per verificare questo principio, calcoliamo la deviazione mediana assoluta dei valori di self-compassion del campione esaminato:\n\n1.4826 * median(abs(scs_df$ts - median(scs_df$ts, na.rm = TRUE)), na.rm = TRUE)\n#&gt; [1] 22.2\n\nOtteniamo un valore che √® simile alla deviazione standard calcolata con:\n\nsd(scs_df$ts)\n#&gt; [1] 20.2\n\nSe verifichiamo la distribuzione dei dati con un grafico della densit√†, possiamo osservare che i punteggi sono approssimativamente normali:\n\nggplot(scs_df, aes(x = ts)) +\n  geom_density(alpha = 0.5) +\n  labs(\n    x = \"math\", \n    y = \"Frequenza\", \n    title = \"Distribuzione dei punteggi di self-compassion\"\n  )\n\n\n\n\n\n\n\n\nPer ulteriori verifiche, possiamo estrarre un campione di dati da una distribuzione normale con media 100 e deviazione standard 15:\n\nset.seed(123) \nx &lt;- rnorm(10000, mean = 100, sd = 15)\n1.4826 * median(abs(x - median(x)))\n#&gt; [1] 14.9\n\nAnche in questo caso, il valore ottenuto √® molto vicino alla deviazione standard reale (15), confermando la relazione tra MAD e deviazione standard in distribuzioni gaussiane.\n\n\n\n19.14.2 Quando Usare Deviazione Standard e MAD\n\nDeviazione standard: √à la misura pi√π appropriata per dati normalmente distribuiti e situazioni in cui l‚Äôobiettivo √® descrivere la dispersione dei dati rispetto alla media. Tuttavia, √® sensibile ai valori anomali (outlier).\nDeviazione mediana assoluta (MAD): √à ideale quando i dati sono non normali, asimmetrici o contengono outlier. La MAD √® pi√π robusta poich√© utilizza la mediana anzich√© la media e non √® influenzata da valori estremi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Indicatori di tendenza centrale e variabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#indici-di-variabilit√†-relativi",
    "href": "chapters/eda/07_loc_scale.html#indici-di-variabilit√†-relativi",
    "title": "19¬† Indicatori di tendenza centrale e variabilit√†",
    "section": "19.15 Indici di Variabilit√† Relativi",
    "text": "19.15 Indici di Variabilit√† Relativi\nA volte pu√≤ essere necessario confrontare la variabilit√† di grandezze incommensurabili, ovvero di caratteri misurati con differenti unit√† di misura. In queste situazioni, le misure di variabilit√† descritte in precedenza diventano inadeguate poich√© dipendono dall‚Äôunit√† di misura utilizzata. Per superare questo problema, si ricorre a specifici numeri adimensionali chiamati indici relativi di variabilit√†.\nIl pi√π importante di questi indici √® il coefficiente di variazione (\\(C_v\\)), definito come il rapporto tra la deviazione standard (\\(\\sigma\\)) e la media dei dati (\\(\\bar{x}\\)):\n\\[\nC_v = \\frac{\\sigma}{\\bar{x}}.\n\\tag{19.7}\\]\nIl coefficiente di variazione √® un numero puro e permette di confrontare la variabilit√† di distribuzioni con unit√† di misura diverse.\nUn altro indice relativo di variabilit√† √® la differenza interquartile rapportata a uno dei tre quartili (primo quartile, terzo quartile o mediana). Questo indice √® definito come:\n\\[\n\\frac{x_{0.75} - x_{0.25}}{x_{0.25}}, \\qquad \\frac{x_{0.75} - x_{0.25}}{x_{0.75}}, \\qquad \\frac{x_{0.75} - x_{0.25}}{x_{0.50}}.\n\\]\nQuesti indici relativi di variabilit√† forniscono una misura adimensionale della dispersione dei dati, rendendo possibile il confronto tra grandezze con diverse unit√† di misura e facilitando l‚Äôanalisi delle differenze di variabilit√† tra i dati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Indicatori di tendenza centrale e variabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#la-fallacia-ergodica",
    "href": "chapters/eda/07_loc_scale.html#la-fallacia-ergodica",
    "title": "19¬† Indicatori di tendenza centrale e variabilit√†",
    "section": "19.16 La Fallacia Ergodica",
    "text": "19.16 La Fallacia Ergodica\nSebbene il concetto di ‚Äúmedia‚Äù possa sembrare chiaro, ci√≤ non implica che il suo utilizzo non presenti delle problematiche nell‚Äôambito della pratica psicologica. Un aspetto su cui vale la pena soffermarsi √® ci√≤ che viene definito ‚Äúfallacia ergodica‚Äù.\nIl concetto di ‚Äúfallacia ergodica‚Äù (Speelman et al., 2024) si riferisce all‚Äôerrore compiuto dai ricercatori quando assumono che le caratteristiche medie di un gruppo di individui possano essere applicate a ciascun individuo all‚Äôinterno di quel gruppo, senza considerare le differenze individuali o le variazioni nel tempo. Questa fallacia emerge dalla pratica comune nella ricerca psicologica di raccogliere dati aggregati da gruppi di persone per stimare parametri della popolazione, al fine di confrontare comportamenti in condizioni diverse o esplorare associazioni tra diverse misurazioni della stessa persona.\nIl problema di questo approccio √® che l‚Äôuso dei risultati basati sul gruppo per caratterizzare le caratteristiche degli individui o per estrapolare a persone simili a quelle del gruppo √® ingiustificato, poich√© le medie di gruppo possono fornire informazioni solo sui risultati collettivi, come la performance media del gruppo, e non consentono di fare affermazioni accurate sugli individui che compongono quel gruppo. La fallacia ergodica si basa sull‚Äôassunzione che per utilizzare legittimamente una statistica aggregata (ad esempio, la media) derivata da un gruppo per descrivere un individuo di quel gruppo, due condizioni devono essere soddisfatte: gli individui devono essere cos√¨ simili da essere praticamente interscambiabili, e le caratteristiche degli individui devono essere temporalmente stabili.\nTuttavia, i fenomeni e i processi psicologici di interesse per i ricercatori sono per natura non uniformi tra gli individui e variabili nel tempo, sia all‚Äôinterno degli individui che tra di loro. Di conseguenza, i risultati ottenuti dalla media di misure di comportamenti, cognizioni o stati emotivi di pi√π individui non descrivono accuratamente nessuno di quegli individui in un dato momento, n√© possono tenere conto dei cambiamenti in quelle variabili per un individuo nel tempo.\nSpeelman et al. (2024) osservano che la stragrande maggioranza degli articoli che hanno analizzato include conclusioni nelle sezioni degli Abstract e/o delle Discussioni che implicano che i risultati trovati con dati aggregati di gruppo si applichino anche agli individui in quei gruppi e/o si applichino agli individui nella popolazione. Questa pratica riflette la fallacia ergodica, che consiste nell‚Äôassumere che i campioni siano sistemi ergodici quando non lo sono.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Indicatori di tendenza centrale e variabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#riflessioni-conclusive",
    "href": "chapters/eda/07_loc_scale.html#riflessioni-conclusive",
    "title": "19¬† Indicatori di tendenza centrale e variabilit√†",
    "section": "19.17 Riflessioni Conclusive",
    "text": "19.17 Riflessioni Conclusive\nLe statistiche descrittive ci permettono di ottenere indicatori sintetici che riassumono i dati di una popolazione o di un campione estratto da essa. Questi indicatori includono misure di tendenza centrale, come la media, la mediana e la moda, che ci forniscono informazioni sulla posizione centrale dei dati rispetto alla distribuzione. Inoltre, ci sono gli indici di dispersione, come la deviazione standard e la varianza, che ci indicano quanto i dati si disperdono attorno alla tendenza centrale. Questi indici ci aiutano a comprendere quanto i valori si discostano dalla media, e quindi ci forniscono un‚Äôidea della variabilit√† dei dati. In conclusione, le statistiche descrittive ci offrono un quadro sintetico delle caratteristiche principali dei dati, consentendoci di comprendere meglio la loro distribuzione e variabilit√†.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Indicatori di tendenza centrale e variabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/07_loc_scale.html#informazioni-sullambiente-di-sviluppo",
    "title": "19¬† Indicatori di tendenza centrale e variabilit√†",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: US/Pacific\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] grid      stats     graphics  grDevices utils     datasets  methods  \n#&gt; [8] base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] vcd_1.4-13        viridis_0.6.5     viridisLite_0.4.2 ggokabeito_0.1.0 \n#&gt;  [5] see_0.9.0         gridExtra_2.3     patchwork_1.3.0   bayesplot_1.11.1 \n#&gt;  [9] psych_2.4.12      scales_1.3.0      markdown_1.13     knitr_1.49       \n#&gt; [13] lubridate_1.9.4   forcats_1.0.0     stringr_1.5.1     dplyr_1.1.4      \n#&gt; [17] purrr_1.0.2       readr_2.1.5       tidyr_1.3.1       tibble_3.2.1     \n#&gt; [21] ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] utf8_1.2.4        generics_0.1.3    stringi_1.8.4     lattice_0.22-6   \n#&gt;  [5] hms_1.1.3         digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1   \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     R.oo_1.27.0       rprojroot_2.0.4  \n#&gt; [13] jsonlite_1.8.9    R.utils_2.12.3    mnormt_2.1.1      cli_3.6.3        \n#&gt; [17] rlang_1.1.4       R.methodsS3_1.8.2 munsell_0.5.1     withr_3.0.2      \n#&gt; [21] tools_4.4.2       parallel_4.4.2    tzdb_0.4.0        colorspace_2.1-1 \n#&gt; [25] pacman_0.5.1      vctrs_0.6.5       R6_2.5.1          zoo_1.8-12       \n#&gt; [29] lifecycle_1.0.4   htmlwidgets_1.6.4 MASS_7.3-64       pkgconfig_2.0.3  \n#&gt; [33] pillar_1.10.1     gtable_0.3.6      data.table_1.16.4 glue_1.8.0       \n#&gt; [37] lmtest_0.9-40     xfun_0.50         tidyselect_1.2.1  farver_2.1.2     \n#&gt; [41] htmltools_0.5.8.1 nlme_3.1-166      labeling_0.4.3    rmarkdown_2.29   \n#&gt; [45] compiler_4.4.2",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Indicatori di tendenza centrale e variabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#bibliografia",
    "href": "chapters/eda/07_loc_scale.html#bibliografia",
    "title": "19¬† Indicatori di tendenza centrale e variabilit√†",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nSpeelman, C. P., Parker, L., Rapley, B. J., & McGann, M. (2024). Most Psychological Researchers Assume Their Samples Are Ergodic: Evidence From a Year of Articles in Three Major Journals. Collabra: Psychology, 10(1).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Indicatori di tendenza centrale e variabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html",
    "href": "chapters/eda/08_correlation.html",
    "title": "20¬† Relazioni tra variabili",
    "section": "",
    "text": "20.1 Introduzione\nNonostante sia un‚Äôoperazione di base, l‚Äôanalisi delle associazioni tra variabili rappresenta uno degli aspetti pi√π controversi nell‚Äôambito dell‚Äôanalisi dei dati psicologici. Sebbene possa sembrare un passaggio naturale dopo l‚Äôanalisi univariata, questo processo solleva numerose questioni metodologiche e concettuali.\nTradizionalmente, in psicologia, l‚Äôanalisi delle associazioni tra variabili √® stata considerata come l‚Äôobiettivo finale del processo di ricerca. Questa visione si basa sull‚Äôidea che la descrizione delle relazioni tra variabili fornisca una spiegazione esaustiva dei fenomeni psicologici. Tale approccio trova le sue radici storiche nel pensiero di Karl Pearson (1911), il quale sosteneva che la spiegazione scientifica si esaurisse una volta delineate le associazioni tra le variabili osservate:\nSebbene sia indubbio che rispondere alla seconda domanda posta da Pearson sia relativamente semplice, √® altres√¨ evidente che la nostra comprensione di un fenomeno non pu√≤ dipendere unicamente dalle informazioni fornite dalle correlazioni.\nIn contrasto con questa visione tradizionale, la ‚ÄúCausal Revolution‚Äù propone un paradigma radicalmente diverso secondo il quale le associazioni tra variabili sono considerate come epifenomeni, mentre l‚Äôobiettivo principale della ricerca √® l‚Äôidentificazione e la comprensione delle relazioni causali: per comprendere veramente i fenomeni psicologici √® essenziale indagare le cause sottostanti, andando oltre la mera descrizione delle associazioni.\nLa discussione dei metodi utilizzati per individuare le relazioni causali sar√† trattata successivamente. In questo capitolo, ci concentreremo sui concetti statistici fondamentali necessari per descrivere le associazioni lineari tra variabili. √à importante sottolineare che, sebbene esistano indici statistici per quantificare associazioni non lineari, la maggior parte degli psicologi si limita all‚Äôutilizzo di indici lineari.\nNel linguaggio comune, termini come ‚Äúdipendenza‚Äù, ‚Äúassociazione‚Äù e ‚Äúcorrelazione‚Äù vengono spesso usati in modo intercambiabile. Tuttavia, da un punto di vista tecnico, √® importante distinguere questi concetti:\n√à cruciale comprendere che non tutte le associazioni sono correlazioni e, soprattutto, che la correlazione non implica necessariamente causalit√†. Questa distinzione √® fondamentale per interpretare correttamente i dati e evitare conclusioni errate sulle relazioni tra variabili.\nIn questo capitolo, esamineremo due misure statistiche fondamentali per valutare la relazione lineare tra due variabili: la covarianza e la correlazione. Questi indici ci permettono di descrivere il grado e la direzione dell‚Äôassociazione lineare tra variabili, quantificando come queste variano congiuntamente.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#introduzione",
    "href": "chapters/eda/08_correlation.html#introduzione",
    "title": "20¬† Relazioni tra variabili",
    "section": "",
    "text": "Quanto spesso, quando √® stato osservato un nuovo fenomeno, sentiamo che viene posta la domanda: ‚Äòqual √® la sua causa?‚Äô. Questa √® una domanda a cui potrebbe essere assolutamente impossibile rispondere. Invece, pu√≤ essere pi√π facile rispondere alla domanda: ‚Äòin che misura altri fenomeni sono associati con esso?‚Äô. Dalla risposta a questa seconda domanda possono risultare molte preziose conoscenze.\n\n\n\n\n\n\nAssociazione: questo termine indica una relazione generale tra variabili, dove la conoscenza del valore di una variabile fornisce informazioni su un‚Äôaltra.\nCorrelazione: descrive una relazione specifica e quantificabile, indicando se due variabili tendono a variare insieme in modo sistematico. Ad esempio, in una correlazione positiva, se \\(X &gt; \\mu_X\\), √® probabile che anche \\(Y &gt; \\mu_Y\\). La correlazione specifica il segno e l‚Äôintensit√† di una relazione lineare.\nDipendenza: indica una relazione causale tra le variabili, dove la variazione della variabile causale porta probabilisticamente alla variazione della variabile dipendente.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#i-dati-grezzi",
    "href": "chapters/eda/08_correlation.html#i-dati-grezzi",
    "title": "20¬† Relazioni tra variabili",
    "section": "20.2 I dati grezzi",
    "text": "20.2 I dati grezzi\nPer illustrare la correlazione e la covarianza, analizzeremo i dati raccolti da Zetsche et al. (2019) in uno studio che indaga le aspettative negative come meccanismo chiave nel mantenimento e nella reiterazione della depressione. Nello specifico, i ricercatori si sono proposti di determinare se gli individui depressi sviluppano aspettative accurate riguardo al loro umore futuro o se tali aspettative sono distortamente negative.\nUno dei loro studi ha coinvolto un campione di 30 soggetti con almeno un episodio depressivo maggiore, confrontati con un gruppo di controllo composto da 37 individui sani. La misurazione del livello di depressione √® stata effettuata tramite il Beck Depression Inventory (BDI-II).\nIl BDI-II √® uno strumento di autovalutazione utilizzato per valutare la gravit√† della depressione in adulti e adolescenti. Il test √® stato sviluppato per identificare e misurare l‚Äôintensit√† dei sintomi depressivi sperimentati nelle ultime due settimane. I 21 item del test sono valutati su una scala a 4 punti, dove 0 rappresenta il grado pi√π basso e 3 il grado pi√π elevato di sintomatologia depressiva.\nNell‚Äôesercizio successivo, ci proponiamo di analizzare i punteggi di depressione BDI-II nel campione di dati fornito da Zetsche et al. (2019).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#definizione-delle-relazioni-tra-variabili",
    "href": "chapters/eda/08_correlation.html#definizione-delle-relazioni-tra-variabili",
    "title": "20¬† Relazioni tra variabili",
    "section": "20.3 Definizione delle relazioni tra variabili",
    "text": "20.3 Definizione delle relazioni tra variabili\nNel contesto delle indagini statistiche, spesso non ci limitiamo a esaminare la distribuzione di una singola variabile. Invece, il nostro interesse si concentra sulla relazione che emerge nei dati tra due o pi√π variabili. Ma cosa significa esattamente quando diciamo che due variabili hanno una relazione?\nPer comprendere ci√≤, prendiamo ad esempio l‚Äôaltezza e l‚Äôet√† tra un gruppo di bambini. In generale, √® possibile notare che all‚Äôaumentare dell‚Äôet√† di un bambino, aumenta anche la sua altezza. Pertanto, conoscere l‚Äôet√† di un bambino, ad esempio tredici anni, e l‚Äôet√† di un altro, sei anni, ci fornisce un‚Äôindicazione su quale dei due bambini sia pi√π alto.\nNel linguaggio statistico, definiamo questa relazione tra altezza e et√† come positiva, il che significa che all‚Äôaumentare dei valori di una delle variabili (in questo caso, l‚Äôet√†), ci aspettiamo di vedere valori pi√π elevati anche nell‚Äôaltra variabile (l‚Äôaltezza). Tuttavia, esistono anche relazioni negative, in cui l‚Äôaumento di una variabile √® associato a un diminuzione dell‚Äôaltra (ad esempio, pi√π et√† √® correlata a meno pianto).\nNon si tratta solo di relazioni positive o negative; ci sono anche situazioni in cui le variabili non hanno alcuna relazione tra loro, definendo cos√¨ una relazione nulla. Inoltre, le relazioni possono variare nel tempo, passando da positive a negative o da fortemente positive a appena positiva. In alcuni casi, una delle variabili pu√≤ essere categorica, rendendo difficile parlare di ‚Äúmaggioranza‚Äù o ‚Äúminoranza‚Äù ma piuttosto di ‚Äúdifferente‚Äù (ad esempio, i bambini pi√π grandi potrebbero semplicemente avere diverse preferenze rispetto ai bambini pi√π piccoli, senza necessariamente essere ‚Äúmigliori‚Äù o ‚Äúpeggiori‚Äù).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#sec-scatter-plot",
    "href": "chapters/eda/08_correlation.html#sec-scatter-plot",
    "title": "20¬† Relazioni tra variabili",
    "section": "20.4 Grafico a dispersione",
    "text": "20.4 Grafico a dispersione\nIl metodo pi√π diretto per visualizzare la relazione tra due variabili continue √® tramite un grafico a dispersione, comunemente noto come ‚Äúscatterplot‚Äù. Questo tipo di diagramma rappresenta le coppie di dati ottenute da due variabili, posizionandole sull‚Äôasse delle ascisse (orizzontale) e delle ordinate (verticale).\nPer rendere l‚Äôidea pi√π chiara, consideriamo i dati dello studio condotto da Zetsche et al. (2019), in cui i ricercatori hanno utilizzato due scale psicometriche, il Beck Depression Inventory II (BDI-II) e la Center for Epidemiologic Studies Depression Scale (CES-D), per misurare il livello di depressione nei partecipanti. Il BDI-II √® uno strumento di autovalutazione che valuta la presenza e l‚Äôintensit√† dei sintomi depressivi in pazienti adulti e adolescenti con diagnosi psichiatrica, mentre la CES-D √® una scala di autovalutazione progettata per misurare i sintomi depressivi sperimentati nella settimana precedente nella popolazione generale, in particolare negli adolescenti e nei giovani adulti. Poich√© entrambe le scale misurano lo stesso costrutto, ovvero la depressione, ci aspettiamo una relazione tra i punteggi ottenuti dal BDI-II e dalla CES-D. Un diagramma a dispersione ci consente di esaminare questa relazione in modo visuale e intuitivo.\n\n# Leggi i dati dal file CSV\ndf &lt;- rio::import(here::here(\"data\", \"data.mood.csv\"))\n\n# Seleziona le colonne di interesse\ndf &lt;- df |&gt;\n  dplyr::select(\"esm_id\", \"group\", \"bdi\", \"cesd_sum\")\n\n# Rimuovi le righe duplicate\ndf &lt;- df[!duplicated(df), ]\n\n# Rimuovi le righe con valori mancanti nella colonna \"bdi\"\ndf &lt;- df[!is.na(df$bdi), ]\n\nPosizionando i valori del BDI-II sull‚Äôasse delle ascisse e quelli del CES-D sull‚Äôasse delle ordinate, ogni punto sul grafico rappresenta un individuo, di cui conosciamo il livello di depressione misurato dalle due scale. √à evidente che i valori delle scale BDI-II e CES-D non possono coincidere per due motivi principali: (1) la presenza di errori di misurazione e (2) l‚Äôutilizzo di unit√† di misura arbitrarie per le due variabili. L‚Äôerrore di misurazione √® una componente inevitabile che influisce in parte su qualsiasi misurazione, ed √® particolarmente rilevante in psicologia, dove la precisione degli strumenti di misurazione √® generalmente inferiore rispetto ad altre discipline, come la fisica. Il secondo motivo per cui i valori delle scale BDI-II e CES-D non possono essere identici √® che l‚Äôunit√† di misura della depressione √® una questione arbitraria e non standardizzata. Tuttavia, nonostante le differenze dovute agli errori di misurazione e all‚Äôuso di unit√† di misura diverse, ci aspettiamo che, se le due scale misurano lo stesso costrutto (la depressione), i valori prodotti dalle due scale dovrebbero essere associati linearmente tra di loro. Per comprendere meglio il concetto di ‚Äúassociazione lineare‚Äù, √® possibile esaminare i dati attraverso l‚Äôutilizzo di un diagramma a dispersione.\n\n\n\n\n\n\n\n\n\nOsservando il grafico a dispersione, √® evidente che i dati mostrano una tendenza a distribuirsi in modo approssimativamente lineare. In termini statistici, ci√≤ suggerisce una relazione di associazione lineare tra i punteggi CES-D e BDI-II.\nTuttavia, √® importante notare che la relazione lineare tra le due variabili √® lontana dall‚Äôessere perfetta. In una relazione lineare perfetta, tutti i punti nel grafico sarebbero allineati in modo preciso lungo una retta. Nella realt√†, la dispersione dei punti dal comportamento lineare ideale √® evidente.\nDi conseguenza, sorge la necessit√† di quantificare numericamente la forza e la direzione della relazione lineare tra le due variabili e di misurare quanto i punti si discostino da una relazione lineare ideale. Esistono vari indici statistici a disposizione per raggiungere questo obiettivo.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#covarianza",
    "href": "chapters/eda/08_correlation.html#covarianza",
    "title": "20¬† Relazioni tra variabili",
    "section": "20.5 Covarianza",
    "text": "20.5 Covarianza\nIniziamo a considerare il pi√π importante di tali indici, chiamato covarianza. In realt√† la definizione di questo indice non ci sorprender√† pi√π di tanto in quanto, in una forma solo apparentemente diversa, l‚Äôabbiamo gi√† incontrata in precedenza. Ci ricordiamo infatti che la varianza di una generica variabile \\(X\\) √® definita come la media degli scarti quadratici di ciascuna osservazione dalla media:\n\\[\nS_{XX} = \\frac{1}{n} \\sum_{i=1}^n(X_i - \\bar{X}) (X_i - \\bar{X}).\n\\]\nLa varianza viene talvolta descritta come la ‚Äúcovarianza di una variabile con s√© stessa‚Äù. Adesso facciamo un passo ulteriore. Invece di valutare la dispersione di una sola variabile, ci chiediamo come due variabili \\(X\\) e \\(Y\\) ‚Äúvariano insieme‚Äù (co-variano). √à facile capire come una risposta a tale domanda possa essere fornita da una semplice trasformazione della formula precedente che diventa:\n\\[\nS_{XY} = \\frac{1}{n} \\sum_{i=1}^n(X_i - \\bar{X}) (Y_i - \\bar{Y}).\n\\tag{20.1}\\]\nL‚ÄôEquazione¬†20.1 ci fornisce la definizione della covarianza.\n\n20.5.1 Interpretazione\nPer capire il significato dell‚ÄôEquazione¬†20.1, supponiamo di dividere il grafico riportato nella Sezione 20.4 in quattro quadranti definiti da una retta verticale passante per la media dei valori BDI-II e da una retta orizzontale passante per la media dei valori CES-D. Numeriamo i quadranti partendo da quello in basso a sinistra e muovendoci in senso antiorario.\nSe prevalgono punti nel I e III quadrante, allora la nuvola di punti avr√† un andamento crescente (per cui a valori bassi di \\(X\\) tendono ad associarsi valori bassi di \\(Y\\) e a valori elevati di \\(X\\) tendono ad associarsi valori elevati di \\(Y\\)) e la covarianza avr√† segno positivo. Mentre se prevalgono punti nel II e IV quadrante la nuvola di punti avr√† un andamento decrescente (per cui a valori bassi di \\(X\\) tendono ad associarsi valori elevati di \\(Y\\) e a valori elevati di \\(X\\) tendono ad associarsi valori bassi di \\(Y\\)) e la covarianza avr√† segno negativo. Dunque, il segno della covarianza ci informa sulla direzione della relazione lineare tra due variabili: l‚Äôassociazione lineare si dice positiva se la covarianza √® positiva, negativa se la covarianza √® negativa.\nEsercizio. Implemento l‚ÄôEquazione¬†20.1 in R.\n\ncov_value &lt;- function(x, y) {\n  mean_x &lt;- sum(x) / length(x)\n  mean_y &lt;- sum(y) / length(y)\n\n  sub_x &lt;- x - mean_x\n  sub_y &lt;- y - mean_y\n\n  sum_value &lt;- sum(sub_y * sub_x)\n  denom &lt;- length(x)\n\n  cov &lt;- sum_value / denom\n  return(cov)\n}\n\nPer i dati mostrati nel diagramma, la covarianza tra BDI-II e CESD √® 207.4\n\nx &lt;- df$bdi\ny &lt;- df$cesd_sum\n\ncov_value(x, y)\n#&gt; [1] 207\n\nOppure, in maniera pi√π semplice:\n\nmean((x - mean(x)) * (y - mean(y)))\n#&gt; [1] 207\n\nLo stesso risultato si ottiene con la funzione cov:\n\ncov(x, y) * (length(x) - 1) / length(x)\n#&gt; [1] 207\n\nLa funzione cov(x, y) calcola la covarianza tra due array, x e y utilizzando \\(n-1\\) al denominatore.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#correlazione",
    "href": "chapters/eda/08_correlation.html#correlazione",
    "title": "20¬† Relazioni tra variabili",
    "section": "20.6 Correlazione",
    "text": "20.6 Correlazione\nLa direzione della relazione tra le variabili √® indicata dal segno della covarianza, ma il valore assoluto di questo indice non fornisce informazioni utili poich√© dipende dall‚Äôunit√† di misura delle variabili. Ad esempio, considerando l‚Äôaltezza e il peso delle persone, la covarianza sar√† pi√π grande se l‚Äôaltezza √® misurata in millimetri e il peso in grammi, rispetto al caso in cui l‚Äôaltezza √® in metri e il peso in chilogrammi. Pertanto, per descrivere la forza e la direzione della relazione lineare tra due variabili in modo adimensionale, si utilizza l‚Äôindice di correlazione.\nLa correlazione √® ottenuta standardizzando la covarianza tramite la divisione delle deviazioni standard (\\(s_X\\), \\(s_Y\\)) delle due variabili:\n\\[\nr = \\frac{S_{XY}}{S_X S_Y}.\n\\tag{20.2}\\]\nLa quantit√† che si ottiene dall‚ÄôEquazione¬†20.2 viene chiamata correlazione di Bravais-Pearson (dal nome degli autori che, indipendentemente l‚Äôuno dall‚Äôaltro, l‚Äôhanno introdotta).\nIn maniera equivalente, per una lista di coppie di valori \\((x_1, y_1), \\dots, (x_n, y_n)\\), il coefficiente di correlazione √® definito come la media del prodotto dei valori standardizzati:\n\\[\nr = \\frac{1}{n} \\sum_{i=1}^{n} \\left( \\frac{x_i - \\bar{x}}{\\sigma_x} \\right) \\left( \\frac{y_i - \\bar{y}}{\\sigma_y} \\right),\n\\tag{20.3}\\]\ndove \\(\\bar{x}\\) e \\(\\bar{y}\\) rappresentano, rispettivamente, le medie dei valori \\(x\\) e \\(y\\), e \\(\\sigma_x\\) e \\(\\sigma_y\\) sono le rispettive deviazioni standard.\nNell‚ÄôEquazione¬†20.3, i valori \\(x_i\\) e \\(y_i\\) vengono prima standardizzati sottraendo la media e dividendo per la deviazione standard, e poi si calcola la media del prodotto di questi valori standardizzati.\n\n20.6.1 Propriet√†\nIl coefficiente di correlazione ha le seguenti propriet√†:\n\nha lo stesso segno della covarianza, dato che si ottiene dividendo la covarianza per due numeri positivi;\n√® un numero puro, cio√® non dipende dall‚Äôunit√† di misura delle variabili;\nassume valori compresi tra -1 e +1.\n\n\n\n20.6.2 Interpretazione\nAll‚Äôindice di correlazione possiamo assegnare la seguente interpretazione:\n\n\\(r_{XY} = -1\\) \\(\\rightarrow\\) perfetta relazione negativa: tutti i punti si trovano esattamente su una retta con pendenza negativa (dal quadrante in alto a sinistra al quadrante in basso a destra);\n\\(r_{XY} = +1\\) \\(\\rightarrow\\) perfetta relazione positiva: tutti i punti si trovano esattamente su una retta con pendenza positiva (dal quadrante in basso a sinistra al quadrante in alto a destra);\n\\(-1 &lt; r_{XY} &lt; +1\\) \\(\\rightarrow\\) presenza di una relazione lineare di intensit√† diversa;\n\\(r_{XY} = 0\\) \\(\\rightarrow\\) assenza di relazione lineare tra \\(X\\) e \\(Y\\).\n\nEsercizio. Per i dati riportati nel diagramma della sezione {ref}sec-zetsche-scatter, la covarianza √® 207.4. Il segno positivo della covarianza ci dice che tra le due variabili c‚Äô√® un‚Äôassociazione lineare positiva. Per capire quale sia l‚Äôintensit√† della relazione lineare calcoliamo la correlazione. Essendo le deviazioni standard del BDI-II e del CES-D rispettavamente uguali a 15.37 e 14.93, la correlazione diventa uguale a \\(\\frac{207.426}{15.38 \\cdot 14.93} = 0.904.\\) Tale valore √® prossimo a 1.0, il che vuol dire che i punti del diagramma a dispersione non si discostano troppo da una retta con una pendenza positiva.\nTroviamo la correlazione con la funzione corrcoef():\n\ncor(x, y)\n#&gt; [1] 0.904\n\nReplichiamo il risultato implementando l‚Äôeq. {eq}eq-cor-def:\n\ns_xy &lt;- mean((x - mean(x)) * (y - mean(y)))\ns_x &lt;- sqrt(mean((x - mean(x))^2)) # Deviazione standard popolazione\ns_y &lt;- sqrt(mean((y - mean(y))^2)) # Deviazione standard popolazione\nr_xy &lt;- s_xy / (s_x * s_y)\nprint(r_xy)\n#&gt; [1] 0.904\n\nUn altro modo ancora per trovare la correlazione tra i punteggi BDI-II e CESD √® quello di applicare l‚ÄôEquazione¬†20.3:\n\nz_x &lt;- (x - mean(x)) / sqrt(mean((x - mean(x))^2)) \n# Standardizzazione con deviazione standard popolazione\nz_y &lt;- (y - mean(y)) / sqrt(mean((y - mean(y))^2)) \n# Standardizzazione con deviazione standard popolazione\nmean(z_x * z_y)\n#&gt; [1] 0.904\n\nEsempio. Un uso interessante delle correlazioni viene fatto in un recente articolo di Guilbeault et al.¬†(2024). Il concetto di ‚Äúgender bias‚Äù si riferisce alla tendenza sistematica di favorire un sesso rispetto all‚Äôaltro, spesso a scapito delle donne. Lo studio di Guilbeault et al.¬†(2024) analizza come le immagini online influenzino la diffusione su vasta scala di questo preconcetto di genere.\nAttraverso un vasto insieme di immagini e testi raccolti online, gli autori dimostrano che sia le misurazioni basate sulle immagini che quelle basate sui testi catturano la frequenza con cui varie categorie sociali sono associate a rappresentazioni di genere, valutate su una scala da -1 (femminile) a 1 (maschile), con 0 che indica una neutralit√† di genere. Questo consente di quantificare il preconcetto di genere come una forma di bias statistico lungo tre dimensioni: la tendenza delle categorie sociali ad associarsi a un genere specifico nelle immagini e nei testi, la rappresentazione relativa delle donne rispetto agli uomini in tutte le categorie sociali nelle immagini e nei testi, e il confronto tra le associazioni di genere nei dati delle immagini e dei testi con la distribuzione empirica delle donne e degli uomini nella societ√†. Il lavoro di Guilbeault et al.¬†(2024) evidenzia che il preconcetto di genere √® molto pi√π evidente nelle immagini rispetto ai testi, come mostrato nella {numref}gender-bias-1-fig C.\nSi noti che, nel grafico della {numref}gender-bias-1-fig C, ogni punto pu√≤ essere interpretato come una misura di correlazione. La misura utilizzata da Guilbeault et al.¬†(2024) riflette il grado di associazione tra le categorie sociali e le rappresentazioni di genere presenti nelle immagini e nei testi analizzati. Quando la misura √® vicina a +1, indica una forte associazione positiva tra una categoria sociale specifica e una rappresentazione di genere maschile, mentre un valore vicino a -1 indica una forte associazione negativa con una rappresentazione di genere femminile. Un valore di 0, invece, suggerisce che non vi √® alcuna associazione tra la categoria sociale considerata e un genere specifico, indicando una sorta di neutralit√† di genere. In sostanza, questa misura di frequenza pu√≤ essere interpretata come una correlazione che riflette la tendenza delle categorie sociali a essere rappresentate in un modo o nell‚Äôaltro nelle immagini e nei testi analizzati, rispetto ai concetti di genere femminile e maschile.\n\n\n\nIl preconcetto di genere √® pi√π prevalente nelle immagini online (da Google Immagini) e nei testi online (da Google News). A. La correlazione tra le associazioni di genere nelle immagini da Google Immagini e nei testi da Google News per tutte le categorie sociali (n = 2.986), organizzate per decili. B. La forza dell‚Äôassociazione di genere in queste immagini e testi online per tutte le categorie (n = 2.986), suddivisa in base al fatto che queste categorie siano inclinate verso il femminile o il maschile. C. Le associazioni di genere per un campione di occupazioni secondo queste immagini e testi online; questo campione √® stato selezionato manualmente per evidenziare i tipi di categorie sociali e preconcetti di genere esaminati. (Figura tratta da Guilbeault et al.¬†(2024)).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#correlazione-di-spearman",
    "href": "chapters/eda/08_correlation.html#correlazione-di-spearman",
    "title": "20¬† Relazioni tra variabili",
    "section": "20.7 Correlazione di Spearman",
    "text": "20.7 Correlazione di Spearman\nUn‚Äôalternativa per valutare la relazione lineare tra due variabili √® il coefficiente di correlazione di Spearman, che si basa esclusivamente sull‚Äôordine dei dati e non sugli specifici valori. Questo indice di associazione √® particolarmente adatto quando gli psicologi sono in grado di misurare solo le relazioni di ordine tra diverse modalit√† di risposta dei soggetti, ma non l‚Äôintensit√† della risposta stessa. Tali variabili psicologiche che presentano questa caratteristica sono definite come ‚Äúordinali‚Äù.\n\n\n\n\n\n\n√à importante ricordare che, nel caso di una variabile ordinale, non √® possibile utilizzare le statistiche descrittive convenzionali come la media e la varianza per sintetizzare le osservazioni. Tuttavia, √® possibile riassumere le osservazioni attraverso una distribuzione di frequenze delle diverse modalit√† di risposta. Come abbiamo appena visto, la direzione e l‚Äôintensit√† dell‚Äôassociazione tra due variabili ordinali possono essere descritte utilizzando il coefficiente di correlazione di Spearman.\n\n\n\nPer fornire un esempio, consideriamo due variabili di scala ordinale e calcoliamo la correlazione di Spearman tra di esse.\n\ncor.test(c(1, 2, 3, 4, 5), c(5, 6, 7, 8, 7), method = \"spearman\")\n#&gt; Warning in cor.test.default(c(1, 2, 3, 4, 5), c(5, 6, 7, 8, 7), method =\n#&gt; \"spearman\"): Impossibile calcolare p-value esatti in presenza di ties\n#&gt; \n#&gt;  Spearman's rank correlation rho\n#&gt; \n#&gt; data:  c(1, 2, 3, 4, 5) and c(5, 6, 7, 8, 7)\n#&gt; S = 4, p-value = 0.09\n#&gt; alternative hypothesis: true rho is not equal to 0\n#&gt; sample estimates:\n#&gt;   rho \n#&gt; 0.821",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#oltre-la-correlazione-e-la-covarianza-quando-lassociazione-tra-variabili-√®-pi√π-complessa",
    "href": "chapters/eda/08_correlation.html#oltre-la-correlazione-e-la-covarianza-quando-lassociazione-tra-variabili-√®-pi√π-complessa",
    "title": "20¬† Relazioni tra variabili",
    "section": "20.8 Oltre la correlazione e la covarianza: quando l‚Äôassociazione tra variabili √® pi√π complessa",
    "text": "20.8 Oltre la correlazione e la covarianza: quando l‚Äôassociazione tra variabili √® pi√π complessa\nIn questo capitolo abbiamo introdotto due misure fondamentali per descrivere la relazione tra due variabili: covarianza e correlazione. La covarianza fornisce un‚Äôindicazione del modo in cui due variabili si discostano congiuntamente dalle proprie medie, mentre la correlazione ne standardizza i valori, permettendo un confronto pi√π immediato tra diverse coppie di variabili e garantendo un indice compreso tra -1 e +1. Una correlazione vicina a +1 indica una forte relazione lineare positiva, vicina a -1 una forte relazione lineare negativa, mentre un valore vicino a 0 segnala l‚Äôassenza di una chiara relazione lineare.\nTuttavia, √® cruciale comprendere che la correlazione descrive esclusivamente la dimensione lineare della relazione tra due variabili. Questo significa che una correlazione nulla (pari a zero) non implica affatto che non vi sia alcuna relazione tra le variabili, ma semplicemente che non esiste una relazione lineare. Possono esistere relazioni non lineari anche molto forti, non catturate da questo indice. Inoltre, altre situazioni possono trarre in inganno, come nei casi in cui i dati siano raggruppati in sottogruppi con propriet√† differenti o siano frutto di particolari processi di selezione.\n\n20.8.1 Correlazione nulla e relazioni non lineari\nUna correlazione pari a zero pu√≤ nascondere relazioni non lineari anche molto marcate. Per esempio, se una variabile Y aumenta solo quando X √® molto alta o molto bassa, ma rimane costante per valori intermedi di X, questa curva a ‚ÄúU‚Äù pu√≤ generare una correlazione vicina allo zero, pur esistendo un forte legame non lineare.\nUn esempio illustrativo √® fornito dal cosiddetto Datasaurus Dozen, un insieme di tredici dataset con la stessa media, deviazione standard e correlazione tra le variabili, ma con distribuzioni visivamente e strutturalmente molto diverse. In ognuno di questi dataset la correlazione di Pearson √® pari a zero, ma l‚Äôispezione grafica rivela pattern e forme ben definite. Questo ci ricorda che √® sempre bene accompagnare le misure numeriche con una visualizzazione grafica dei dati.\n\ndatasaurus_data &lt;- read.csv(\"../../data/datasaurus.csv\")\n\ndatasaurus_summary &lt;- datasaurus_data %&gt;%\n  group_by(dataset) %&gt;%\n  summarise(\n    x_count = n(),\n    x_mean = mean(x, na.rm = TRUE),\n    x_std = sd(x, na.rm = TRUE),\n    y_count = n(),\n    y_mean = mean(y, na.rm = TRUE),\n    y_std = sd(y, na.rm = TRUE)\n  )\n\ndatasaurus_summary\n#&gt; # A tibble: 13 √ó 7\n#&gt;   dataset  x_count x_mean x_std y_count y_mean y_std\n#&gt;   &lt;chr&gt;      &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 away         142   54.3  16.8     142   47.8  26.9\n#&gt; 2 bullseye     142   54.3  16.8     142   47.8  26.9\n#&gt; 3 circle       142   54.3  16.8     142   47.8  26.9\n#&gt; 4 dino         142   54.3  16.8     142   47.8  26.9\n#&gt; 5 dots         142   54.3  16.8     142   47.8  26.9\n#&gt; 6 h_lines      142   54.3  16.8     142   47.8  26.9\n#&gt; # ‚Ñπ 7 more rows\n\n\ndatasaurus_data |&gt;\n  ggplot(aes(x = x, y = y)) +\n  geom_point(alpha = 0.7) +\n  facet_wrap(~dataset, nrow = 4, ncol = 4) +\n  labs(x = NULL, y = NULL)\n\n\n\n\n\n\n\n\nTutti questi esempi rafforzano l‚Äôidea che l‚Äôassenza di correlazione lineare non significa assenza di relazione: potremmo avere strutture curve, pattern complessi o punti anomali (outlier) capaci di modificare radicalmente la forma della relazione tra le variabili.\nOltre alle relazioni non lineari, esistono situazioni in cui la correlazione, da sola, pu√≤ fornire un‚Äôimmagine distorta dei dati. Tra queste ricordiamo due fenomeni noti come il paradosso di Simpson e il paradosso di Berkson.\n\n\n20.8.2 Paradosso di Simpson\nIl paradosso di Simpson si verifica quando, guardando i dati raggruppati per sottogruppi, si osserva una certa relazione tra due variabili, ma aggregando i dati di tutti i sottogruppi insieme emerge una relazione opposta. In altre parole, la tendenza che appare quando si considerano i dati divisi per gruppi scompare o si inverte quando si esamina l‚Äôintero campione senza tenere conto della suddivisione in sottogruppi.\nImmaginiamo di avere due dipartimenti universitari, A e B. All‚Äôinterno di ciascun dipartimento, la relazione tra il voto di laurea (X) e la performance in un successivo programma di specializzazione (Y) √® positiva: all‚Äôaumentare del voto di laurea aumenta, in media, la performance nella scuola di specializzazione.\nTuttavia, supponiamo che il Dipartimento A abbia in generale voti di laurea mediamente pi√π bassi, ma ottime performance nella specializzazione; mentre il Dipartimento B abbia voti di laurea mediamente pi√π alti, ma performance alla specializzazione un po‚Äô pi√π basse. Se uniamo tutti gli studenti dei due dipartimenti senza considerarne l‚Äôappartenenza, potremmo osservare una relazione negativa tra voto di laurea e performance, sovvertendo le conclusioni tratte guardando ai singoli sottogruppi.\nEcco come possiamo simulare questi dati in R:\n\nset.seed(123)\n\n# Numero di osservazioni per dipartimento\nn &lt;- 100\n\n# Dipartimento A:\n# Voti di laurea (X) pi√π bassi, ma performance (Y) pi√π alta.\n# Creiamo un legame positivo tra X e Y all'interno di A.\nX_A &lt;- rnorm(n, mean = 50, sd = 5)    # Voti laurea mediamente pi√π bassi\nY_A &lt;- X_A + rnorm(n, mean = 20, sd = 5) # Performance alta e correlata positivamente con X\n\n# Dipartimento B:\n# Voti di laurea (X) pi√π alti, ma performance (Y) pi√π bassa.\n# Anche qui creiamo un legame positivo tra X e Y all'interno di B, \n# ma con un offset tale che globalmente i voti alti coincidano con performance minori.\nX_B &lt;- rnorm(n, mean = 60, sd = 5)    # Voti laurea mediamente pi√π alti\nY_B &lt;- X_B - rnorm(n, mean = 10, sd = 5) # Performance pi√π bassa ma comunque correlata positivamente con X all‚Äôinterno di B\n\n# Creiamo un dataframe con tutti i dati\ndipartimento &lt;- c(rep(\"A\", n), rep(\"B\", n))\nX &lt;- c(X_A, X_B)\nY &lt;- c(Y_A, Y_B)\ndati &lt;- data.frame(dipartimento, X, Y)\n\n# Correlazioni all'interno dei dipartimenti\ncat(\"Correlazione nel Dipartimento A:\", cor(X_A, Y_A), \"\\n\")\n#&gt; Correlazione nel Dipartimento A: 0.667\ncat(\"Correlazione nel Dipartimento B:\", cor(X_B, Y_B), \"\\n\")\n#&gt; Correlazione nel Dipartimento B: 0.693\n\n# Correlazione sull'intero dataset (senza distinguere i dipartimenti)\ncat(\"Correlazione globale:\", cor(X, Y), \"\\n\")\n#&gt; Correlazione globale: -0.335\n\n\n# Visualizziamo i dati\nggplot(dati, aes(x = X, y = Y, color = dipartimento)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  scale_fill_okabeito() + \n  labs(\n    title = \"Paradosso di Simpson\",\n    x = \"Voto di laurea\", \n    y = \"Performance nella specializzazione\",\n    color = \"Dipartimento\"\n  )\n#&gt; `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nAll‚Äôinterno del Dipartimento A: la correlazione tra voto di laurea (X) e performance (Y) √® positiva. Ci√≤ significa che, per gli studenti di A, avere un voto di laurea pi√π alto √® associato a una performance maggiore nella specializzazione.\nAll‚Äôinterno del Dipartimento B: la correlazione tra X e Y √® anch‚Äôessa positiva, indicando che anche nel secondo dipartimento voti pi√π alti tendono ad accompagnarsi a performance pi√π alte.\nConsiderando entrambi i dipartimenti insieme: a causa delle differenze nei livelli medi di X e Y tra i dipartimenti, unendo i dati senza distinguere il gruppo di appartenenza otteniamo una correlazione globale negativa. Questo significa che, ignorando la suddivisione in dipartimenti, sembra che aumentare il voto di laurea sia associato a una diminuzione della performance nella specializzazione ‚Äî una conclusione opposta a quella tratta dall‚Äôanalisi separata dei due sottogruppi.\n\nQuesto √® un esempio concreto del paradosso di Simpson: la relazione osservata in sottogruppi omogenei si inverte quando si aggregano i dati, mettendo in guardia sulla necessit√† di considerare con attenzione la struttura dei dati e i fattori confondenti prima di trarre conclusioni.\n\n\n20.8.3 Paradosso di Berkson\nIl paradosso di Berkson √® un fenomeno legato alla selezione del campione. Se il dataset non √® rappresentativo della popolazione generale, la relazione osservata pu√≤ risultare artificiale o opposta a quella esistente su un campione pi√π ampio. Per esempio, analizzando solo ciclisti professionisti, potremmo non vedere alcuna relazione tra VO2 max e probabilit√† di vincere una gara, poich√© tutti hanno gi√† superato una certa soglia di VO2 max. Considerando la popolazione generale, invece, potrebbe emergere chiaramente una relazione positiva tra questi due fattori. Questo paradosso evidenzia l‚Äôimportanza di considerare il processo di selezione dei dati e di chiedersi se il campione analizzato sia adeguato a rispondere alla domanda di ricerca.\n\n\n20.8.4 Limiti delle statistiche riassuntive semplici\nUn esempio particolarmente famoso che dimostra i limiti delle semplici statistiche descrittive ‚Äî come media, deviazione standard e correlazione ‚Äî √® il quartetto di Anscombe. Questo insieme di quattro piccoli dataset possiede identiche medie, varianze e correlazioni tra variabili, ma rappresenta relazioni estremamente differenti tra X e Y (Anscombe, 1973).\nImportiamo il dataset anscombe gi√† disponibile nel pacchetto datasets di R:\n\ndata(\"anscombe\")\n\nanscombe |&gt; \n  head()\n#&gt;   x1 x2 x3 x4   y1   y2    y3   y4\n#&gt; 1 10 10 10  8 8.04 9.14  7.46 6.58\n#&gt; 2  8  8  8  8 6.95 8.14  6.77 5.76\n#&gt; 3 13 13 13  8 7.58 8.74 12.74 7.71\n#&gt; 4  9  9  9  8 8.81 8.77  7.11 8.84\n#&gt; 5 11 11 11  8 8.33 9.26  7.81 8.47\n#&gt; 6 14 14 14  8 9.96 8.10  8.84 7.04\n\nIl dataset anscombe contiene quattro serie di dati (x1, y1), (x2, y2), (x3, y3) e (x4, y4), ognuna costituita da 11 coppie di valori (x, y). Per comprendere meglio le loro caratteristiche, iniziamo calcolando alcune statistiche descrittive. La funzione apply() consente di applicare una funzione (ad esempio, mean) a tutte le colonne di un data frame. Usandola sulle colonne di anscombe, otteniamo le medie di ciascuna delle otto variabili (le quattro x e le quattro y):\n\napply(anscombe, MARGIN = 2, mean)\n#&gt;  x1  x2  x3  x4  y1  y2  y3  y4 \n#&gt; 9.0 9.0 9.0 9.0 7.5 7.5 7.5 7.5\n\nOsserviamo che le medie delle quattro variabili x sono identiche fino a sei cifre decimali, e le medie delle quattro variabili y differiscono solo in modo trascurabile (circa lo 0.01%). Analogamente, se calcoliamo le deviazioni standard per ciascuna variabile, notiamo una notevole somiglianza:\n\napply(anscombe, MARGIN = 2, sd)\n#&gt;   x1   x2   x3   x4   y1   y2   y3   y4 \n#&gt; 3.32 3.32 3.32 3.32 2.03 2.03 2.03 2.03\n\nAnche in questo caso, le deviazioni standard per le x coincidono fino alla sesta cifra decimale, mentre quelle delle y differiscono di meno dello 0.06%. Inoltre, se calcoliamo i coefficienti di correlazione tra x e y in ognuno dei quattro dataset, scopriamo che sono quasi identici:\n\n# Calcoliamo la correlazione per ciascuna coppia (x1,y1), (x2,y2), (x3,y3), (x4,y4)\nfor (i in 1:4) {\n  x_var &lt;- anscombe[[paste0(\"x\", i)]]\n  y_var &lt;- anscombe[[paste0(\"y\", i)]]\n  \n  corr_value &lt;- cor(x_var, y_var)\n  cat(\"Correlazione tra x\", i, \"e y\", i, \":\", corr_value, \"\\n\")\n}\n#&gt; Correlazione tra x 1 e y 1 : 0.816 \n#&gt; Correlazione tra x 2 e y 2 : 0.816 \n#&gt; Correlazione tra x 3 e y 3 : 0.816 \n#&gt; Correlazione tra x 4 e y 4 : 0.817\n\nSe ci limitassimo a guardare queste statistiche (media, deviazione standard, correlazione), potremmo facilmente essere indotti a concludere che i quattro dataset sono tra loro sostanzialmente indistinguibili. Tuttavia, la realt√† √® molto diversa. Le statistiche descrittive, prese da sole, non offrono una visione completa e possono nascondere importanti differenze nella struttura dei dati.\nQuesta differenza diventa evidente non appena decidiamo di visualizzare i dati. La rappresentazione grafica fornisce informazioni che non emergono dalle sole statistiche riassuntive:\n\nanscombe_m &lt;- tibble()\n\nfor (i in 1:4) {\n  anscombe_m &lt;- rbind(\n    anscombe_m, tibble(set = i, x = anscombe[, i], y = anscombe[, i + 4])\n  )\n}\n\nggplot(anscombe_m, aes(x, y)) +\n  geom_point(size = 3, color = \"red\", fill = \"orange\", shape = 21) +\n  geom_smooth(method = \"lm\", fill = NA, fullrange = TRUE) +\n  facet_wrap(~set, ncol = 2)\n#&gt; `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nOsservando i grafici, notiamo subito che i quattro dataset sono profondamente diversi:\n\nDataset 1: Qui la relazione tra x e y √® approssimativamente lineare, e la correlazione riflette in modo appropriato il legame tra le due variabili.\nDataset 2: Sebbene la correlazione sia simile a quella del Dataset 1, i dati mostrano una relazione curvilinea e non lineare. La semplice correlazione lineare non ne cattura la forma.\nDataset 3: La presenza di un singolo outlier distorce la percezione della relazione tra le variabili, altrimenti lineare. La correlazione alta √® influenzata in modo sproporzionato da questo punto anomalo.\nDataset 4: Qui i dati non mostrano alcuna relazione lineare. La correlazione elevata √® il frutto di un pattern fortemente atipico (ad esempio, una sola coppia di punti allineata).\n\nIl quartetto di Anscombe mette in luce un principio fondamentale: statistiche descrittive come media, deviazione standard e correlazione non sono sempre sufficienti per comprendere la natura dei dati. La visualizzazione grafica √® essenziale per cogliere relazioni, pattern non lineari, outlier e altre caratteristiche che le semplici statistiche non riescono a rivelare. In definitiva, questo esempio dimostra che analizzare i dati soltanto attraverso poche statistiche di sintesi pu√≤ portare a conclusioni fuorvianti, mentre l‚Äôintegrazione con la rappresentazione grafica fornisce una visione pi√π completa e accurata.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#riflessioni-conclusive",
    "href": "chapters/eda/08_correlation.html#riflessioni-conclusive",
    "title": "20¬† Relazioni tra variabili",
    "section": "20.9 Riflessioni Conclusive",
    "text": "20.9 Riflessioni Conclusive\nLa covarianza e la correlazione sono strumenti preziosi per capire l‚Äôintensit√† e la direzione lineare di una relazione tra due variabili. Tuttavia, non dobbiamo confondere la loro semplicit√† con completezza d‚Äôinformazione. Una correlazione nulla non implica assenza di relazione, ma solo assenza di una relazione lineare. Inoltre, il paradosso di Simpson e il paradosso di Berkson dimostrano che la semplice osservazione di correlazioni pu√≤ essere fuorviante se non si tiene conto della struttura dei dati o del processo di selezione del campione.\nInfine, esempi come il quartetto di Anscombe sottolineano quanto sia fondamentale accompagnare le statistiche riassuntive con analisi grafiche e un‚Äôattenzione costante ai possibili pattern non lineari, agli outlier e alle caratteristiche peculiari del dataset. Nel prossimo capitolo esamineremo approcci che consentono di avvicinarsi alla comprensione causale dei fenomeni, andando oltre la semplice osservazione dell‚Äôassociazione tra variabili.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/08_correlation.html#informazioni-sullambiente-di-sviluppo",
    "title": "20¬† Relazioni tra variabili",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: US/Pacific\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] ggokabeito_0.1.0 see_0.9.0        gridExtra_2.3    patchwork_1.3.0 \n#&gt;  [5] bayesplot_1.11.1 psych_2.4.12     scales_1.3.0     markdown_1.13   \n#&gt;  [9] knitr_1.49       lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1   \n#&gt; [13] dplyr_1.1.4      purrr_1.0.2      readr_2.1.5      tidyr_1.3.1     \n#&gt; [17] tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3       \n#&gt; [21] here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] utf8_1.2.4        generics_0.1.3    stringi_1.8.4     lattice_0.22-6   \n#&gt;  [5] hms_1.1.3         digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1   \n#&gt;  [9] grid_4.4.2        timechange_0.3.0  fastmap_1.2.0     Matrix_1.7-1     \n#&gt; [13] R.oo_1.27.0       rprojroot_2.0.4   jsonlite_1.8.9    R.utils_2.12.3   \n#&gt; [17] mgcv_1.9-1        mnormt_2.1.1      cli_3.6.3         rlang_1.1.4      \n#&gt; [21] R.methodsS3_1.8.2 splines_4.4.2     munsell_0.5.1     withr_3.0.2      \n#&gt; [25] yaml_2.3.10       tools_4.4.2       parallel_4.4.2    tzdb_0.4.0       \n#&gt; [29] colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5       R6_2.5.1         \n#&gt; [33] lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.1    \n#&gt; [37] gtable_0.3.6      data.table_1.16.4 glue_1.8.0        xfun_0.50        \n#&gt; [41] tidyselect_1.2.1  farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-166     \n#&gt; [45] labeling_0.4.3    rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#bibliografia",
    "href": "chapters/eda/08_correlation.html#bibliografia",
    "title": "20¬† Relazioni tra variabili",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAnscombe, F. J. (1973). Graphs in statistical analysis. The American Statistician, 27(1), 17‚Äì21.\n\n\nHamaker, E. (2024). The curious case of the cross-sectional correlation. Multivariate Behavioral Research, 59(6), 1111‚Äì1122.\n\n\nZetsche, U., Buerkner, P.-C., & Renneberg, B. (2019). Future expectations in clinical depression: biased or realistic? Journal of Abnormal Psychology, 128(7), 678‚Äì688.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html",
    "href": "chapters/eda/09_causality.html",
    "title": "21¬† Causalit√† dai dati osservazionali üî∏",
    "section": "",
    "text": "21.1 Introduzione\nLa pura osservazione dei dati pu√≤ rivelare correlazioni e pattern nei dati, ma senza un‚Äôindagine sulle cause che stanno alla base di tali correlazioni, le conclusioni tratte possono essere fuorvianti o incomplete.\nRichard McElreath, nel suo libro ‚ÄúStatistical Rethinking‚Äù (McElreath, 2020), utilizza l‚Äôanalogia dei Golem - creature potenti ma prive di saggezza - per descrivere un approccio metodologico che √® stato a lungo predominante in psicologia. Questo approccio si basa esclusivamente sull‚Äôanalisi delle associazioni statistiche tra variabili, trascurando considerazioni pi√π profonde sulla causalit√†.\nIl metodo in questione si concentra principalmente sul test delle ipotesi nulle, senza stabilire una chiara connessione tra le domande di ricerca riguardanti relazioni causali e i test statistici impiegati. Questa disconnessione √® evidente nella figura successiva, tratta da un manuale di analisi dati di impostazione frequentista, che illustra la procedura raccomandata dai sostenitori di questo approccio per descrivere le associazioni tra variabili.\n√à importante notare come tale procedura non fornisca strumenti utili per identificare le effettive cause sottostanti ai fenomeni osservati. Questa limitazione metodologica √® stata identificata come uno dei fattori principali che hanno contribuito alla crisi di replicabilit√† nella ricerca psicologica, come approfondito nel ?sec-crisis. L‚Äôapproccio descritto, pur essendo potente nell‚Äôindividuare correlazioni, manca della ‚Äúsaggezza‚Äù necessaria per distinguere tra semplici associazioni e vere relazioni causali, analogamente ai Golem della metafora di McElreath.\nUn problema evidenziato da McElreath (2020) √® che processi causali completamente distinti possono generare la stessa distribuzione di risultati osservati. Pertanto, un approccio focalizzato esclusivamente sull‚Äôanalisi delle associazioni mediante il test dell‚Äôipotesi nulla non √® in grado di distinguere tra questi diversi scenari, come spiegato nel ?sec-causal-inference-regr.\nL‚Äôapproccio frequentista, che si limita a descrivere le associazioni tra le variabili, ha una scarsa capacit√† di rilevare le caratteristiche cruciali dei fenomeni studiati e tende a produrre un alto tasso di falsi positivi (Zwet et al., 2023). √à invece necessario utilizzare una metodologia che non si limiti a confutare ipotesi nulle, ma sia in grado di sviluppare modelli causali che rispondano direttamente alle domande di ricerca. In questo capitolo, ci concentreremo sull‚Äôintroduzione dei concetti fondamentali dell‚Äôanalisi causale.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali üî∏</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#introduzione",
    "href": "chapters/eda/09_causality.html#introduzione",
    "title": "21¬† Causalit√† dai dati osservazionali üî∏",
    "section": "",
    "text": "Esempio di albero decisionale per la selezione di una procedura statistica appropriata. Iniziando dall‚Äôalto, l‚Äôutente risponde a una serie di domande riguardanti la misurazione e l‚Äôintento, arrivando infine al nome di una procedura. Sono possibili molti alberi decisionali simili. (Figura tratta da McElreath (2020)).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali üî∏</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#cos√®-la-causalit√†",
    "href": "chapters/eda/09_causality.html#cos√®-la-causalit√†",
    "title": "21¬† Causalit√† dai dati osservazionali üî∏",
    "section": "21.2 Cos‚Äô√® la causalit√†?",
    "text": "21.2 Cos‚Äô√® la causalit√†?\nHardt & Recht (2022) introducono il concetto di causalit√† distinguendo tra osservazione e azione. Ci√≤ che vediamo nell‚Äôosservazione passiva √® il modo in cui le persone seguono i loro comportamenti abituali, le loro inclinazioni naturali, proiettando lo stato del mondo su un insieme di caratteristiche che abbiamo scelto di evidenziare. Tuttavia, le domande pi√π importanti spesso non riguardano semplici osservazioni.\n\nNon ci basta sapere che le persone che praticano regolarmente attivit√† fisica soffrono meno d‚Äôansia; vogliamo capire se l‚Äôattivit√† fisica riduce effettivamente i livelli d‚Äôansia.\nNon ci accontentiamo di osservare che chi segue una terapia cognitivo-comportamentale (CBT) presenta meno sintomi depressivi; desideriamo verificare se la CBT riduce realmente questi sintomi.\nNon ci limitiamo a constatare che l‚Äôuso frequente dei social media √® associato a un calo del benessere mentale; vogliamo determinare se l‚Äôuso intensivo dei social media causa effettivamente una diminuzione del benessere mentale.\n\nAlla base, il ragionamento causale √® un quadro concettuale per affrontare domande sugli effetti di azioni o interventi ipotetici. Una volta compreso quale sia l‚Äôeffetto di un‚Äôazione, possiamo invertire la domanda e chiederci quale azione plausibile abbia causato un determinato evento.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali üî∏</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#effetto-causale",
    "href": "chapters/eda/09_causality.html#effetto-causale",
    "title": "21¬† Causalit√† dai dati osservazionali üî∏",
    "section": "21.3 Effetto Causale",
    "text": "21.3 Effetto Causale\nSebbene non esista una definizione univoca di causalit√†, possiamo concettualizzarla in modo pratico: diciamo che X causa Y se, intervenendo e modificando il valore di X (il trattamento), la distribuzione di Y cambia di conseguenza. Questa definizione sottolinea l‚Äôimportanza cruciale dell‚Äôazione o dell‚Äôintervento nel determinare una relazione causale.\nQuando X √® una variabile binaria, rappresentante la presenza o l‚Äôassenza del trattamento, la conseguenza dell‚Äôintervento su X √® denominata effetto medio del trattamento. Questo ci indica quanto il trattamento (azione X = 1) aumenta l‚Äôaspettativa di Y rispetto all‚Äôassenza di trattamento (azione X = 0).\n√à importante notare che gli effetti causali sono quantit√† relative alla popolazione. Si riferiscono a effetti mediati sull‚Äôintera popolazione in esame. Tuttavia, spesso l‚Äôeffetto del trattamento pu√≤ variare significativamente da un individuo all‚Äôaltro o tra gruppi di individui. In questi casi, parliamo di effetti di trattamento eterogenei.\nPer chiarire questo concetto, consideriamo un esempio concreto: supponiamo che la terapia cognitivo-comportamentale (CBT) riduca l‚Äôansia. Se un gruppo di persone ansiose non riceve alcun trattamento, i loro livelli d‚Äôansia rimarranno presumibilmente invariati. Se invece interveniamo introducendo la CBT (modificando cos√¨ il valore di X), i livelli d‚Äôansia nel gruppo tenderanno a diminuire (cambiando quindi il valore di Y). Questo esempio illustra la distinzione tra semplice correlazione, basata sull‚Äôosservazione passiva, e causalit√†, che implica un‚Äôazione o un intervento.\nLa definizione di causalit√† pu√≤ essere applicata anche per collegare variabili apparentemente distanti. Ad esempio, l‚Äôautoefficacia potrebbe non avere un effetto causale diretto sulle prestazioni accademiche. Tuttavia, se aumentiamo l‚Äôautoefficacia attraverso interventi mirati, √® probabile che osserviamo un miglioramento nell‚Äôimpegno allo studio. Questo aumento dell‚Äôimpegno, a sua volta, tende a migliorare le prestazioni accademiche. Di conseguenza, possiamo affermare che l‚Äôautoefficacia influisce indirettamente sulle prestazioni accademiche attraverso una catena causale.\n√à importante precisare che affermiamo l‚Äôesistenza di una relazione causale tra X e Y anche quando modificare X non porta necessariamente a un cambiamento immediato o deterministico in Y, ma altera la probabilit√† che Y si verifichi in un certo modo, modificando quindi la distribuzione di Y. Questa prospettiva probabilistica della causalit√† √® particolarmente rilevante in campi come la psicologia, dove le relazioni tra variabili sono spesso complesse e influenzate da molteplici fattori.\n\n21.3.1 I Limiti dell‚ÄôOsservazione\nPer comprendere i limiti dell‚Äôosservazione passiva, e quindi la necessit√† di comprendere le relazioni causali sottostanti, Hardt & Recht (2022) si riferiscono all‚Äôesempio storico delle ammissioni ai corsi di laurea dell‚ÄôUniversit√† della California, Berkeley, nel 1973. In quell‚Äôanno, 12,763 candidati furono considerati per l‚Äôammissione in uno dei 101 dipartimenti o major interdipartimentali. Di questi, 4,321 erano donne e 8,442 erano uomini. I dati mostrano che circa il 35% delle donne fu ammesso, rispetto al 44% degli uomini. Test di significativit√† statistica indicano che questa differenza non √® attribuibile al caso, suggerendo una disparit√† nei tassi di ammissione tra i generi.\nUna tendenza simile si osserva quando si analizzano le decisioni aggregate di ammissione nei sei maggiori dipartimenti. Il tasso di ammissione complessivo per gli uomini era di circa il 44%, mentre per le donne era solo il 30%, un‚Äôaltra differenza significativa. Tuttavia, poich√© i dipartimenti hanno autonomia nelle loro decisioni di ammissione, √® utile esaminare il possibile bias di genere a livello di singolo dipartimento.\nUomini\n\n\n\nDipartimento\nCandidati\nAmmessi (%)\n\n\n\n\nA\n825\n62\n\n\nB\n520\n60\n\n\nC\n325\n37\n\n\nD\n417\n33\n\n\nE\n191\n28\n\n\nF\n373\n6\n\n\n\nDonne\n\n\n\nDipartimento\nCandidati\nAmmessi (%)\n\n\n\n\nA\n108\n82\n\n\nB\n25\n68\n\n\nC\n593\n34\n\n\nD\n375\n35\n\n\nE\n393\n24\n\n\nF\n341\n7\n\n\n\nDall‚Äôosservazione di questi dati, emerge che quattro dei sei maggiori dipartimenti mostrano un tasso di ammissione pi√π elevato per le donne, mentre due mostrano un tasso pi√π elevato per gli uomini. Tuttavia, questi due dipartimenti non possono giustificare la sostanziale differenza nei tassi di ammissione osservata nei dati aggregati. Questo suggerisce che la tendenza generale di un tasso di ammissione pi√π alto per gli uomini sembra invertita quando i dati sono disaggregati per dipartimento.\nQuesto fenomeno √® noto come paradosso di Simpson, un paradosso statistico in cui una tendenza che appare in sottopopolazioni si inverte o scompare quando i dati vengono aggregati. Nel contesto attuale, il paradosso di Simpson si manifesta nel fatto che, mentre i dati aggregati sembrano indicare una discriminazione di genere contro le donne, l‚Äôanalisi dei dati disaggregati per dipartimento rivela che in alcuni casi le donne sono favorite in termini di ammissioni.\nLa domanda fondamentale √® se questi dati indicano effettivamente un problema di discriminazione di genere o se, come suggerito dallo studio originale, il bias di genere nelle ammissioni fosse principalmente dovuto al fatto che ‚Äúle donne sono indirizzate dalla loro socializzazione e istruzione verso campi di studio generalmente pi√π affollati, meno produttivi in termini di completamento dei diplomi, meno finanziati e che spesso offrono prospettive professionali peggiori.‚Äù In altre parole, il problema risiederebbe in differenze sistemiche e strutturali tra i campi di studio scelti dalle donne e quelli scelti dagli uomini.\nIl paradosso di Simpson crea disagio proprio perch√© l‚Äôintuizione suggerisce che una tendenza valida per tutte le sottopopolazioni dovrebbe esserlo anche a livello aggregato. Tuttavia, questo paradosso evidenzia un errore comune nell‚Äôinterpretazione delle probabilit√† condizionate: confondere l‚Äôosservazione passiva con l‚Äôanalisi causale. I dati che abbiamo rappresentano solo un‚Äôistantanea del comportamento normale di uomini e donne che si candidavano per l‚Äôammissione a UC Berkeley nel 1973.\nNon possiamo trarre conclusioni definitive da questi dati. Possiamo solo riconoscere che l‚Äôanalisi iniziale solleva ulteriori domande, come ad esempio la necessit√† di progettare nuovi studi per raccogliere dati pi√π completi, che potrebbero portare a conclusioni pi√π definitive. In alternativa, potremmo discutere su quale scenario sia pi√π verosimile in base alle nostre convinzioni e alle notre ipotesi sul mondo.\nL‚Äôinferenza causale pu√≤ essere utile in entrambi i casi. Da un lato, pu√≤ guidare la progettazione di nuovi studi, aiutandoci a scegliere quali variabili includere, quali escludere e quali mantenere costanti. Dall‚Äôaltro, i modelli causali possono fungere da meccanismo per incorporare le conoscenze scientifiche del dominio e passare da ipotesi plausibili a conclusioni plausibili.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali üî∏</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#variabili-confondenti",
    "href": "chapters/eda/09_causality.html#variabili-confondenti",
    "title": "21¬† Causalit√† dai dati osservazionali üî∏",
    "section": "21.4 Variabili confondenti",
    "text": "21.4 Variabili confondenti\nSebbene gli esperimenti controllati offrano un elevato grado di certezza nell‚Äôidentificazione di queste relazioni, molte domande di ricerca non possono essere affrontate sperimentalmente a causa di limitazioni etiche o pratiche. In questi casi, i ricercatori ricorrono a disegni osservazionali, che offrono maggiore flessibilit√† e applicabilit√†. Tuttavia, l‚Äôuso di dati osservazionali comporta una sfida significativa: la difficolt√† di trarre conclusioni causali affidabili.\nAl centro di questa complessit√† si trovano le variabili confondenti. Possiamo dire che una variabile confondente √® presente quando l‚Äôassociazione osservata tra due variabili X e Y non riflette accuratamente la vera relazione causale tra di esse. In altre parole, la variabile confondente influenza sia X che Y, creando l‚Äôapparenza di una relazione diretta tra le due che potrebbe essere fuorviante o inesatta.\nNegli studi osservazionali, se le variabili confondenti non vengono misurate e controllate adeguatamente, possono distorcere le stime degli effetti causali, introducendo bias nei risultati e impedendo di riflettere il vero valore dell‚Äôeffetto. In pratica, la presenza di variabili confondenti pu√≤ portare a conclusioni errate quando si confrontano semplicemente i risultati osservati in diversi gruppi. Ci√≤ che si osserva nei dati potrebbe non corrispondere a ci√≤ che accadrebbe se si potesse manipolare direttamente la variabile di interesse in un esperimento controllato.\nUn approccio apparentemente semplice per affrontare questo problema potrebbe essere quello di controllare statisticamente tutte le variabili confondenti. In questo metodo, si stima l‚Äôeffetto di X su Y separatamente in ogni segmento della popolazione definito da una condizione Z = z per ogni possibile valore di z. Successivamente, si calcola la media di questi effetti stimati nelle sottopopolazioni, ponderandoli per la probabilit√† di Z = z nella popolazione. Tuttavia, questo metodo presenta due difficolt√† fondamentali: richiede la conoscenza di tutte le possibili variabili confondenti e la capacit√† di misurare ciascuna di esse, cosa che spesso non √® praticabile.\nIl controllo delle variabili confondenti √® cruciale per stabilire relazioni causali, poich√© permette di isolare gli effetti delle variabili indipendenti da quelli delle variabili confondenti che potrebbero influenzare le variabili dipendenti. Esistono due principali metodologie di controllo:\n\nIl controllo sperimentale, implementato attraverso il disegno sperimentale e basato principalmente sulla randomizzazione.\nIl controllo statistico, applicato durante l‚Äôanalisi dei dati, con l‚Äôobiettivo di neutralizzare o quantificare l‚Äôinfluenza delle variabili estranee.\n\nA causa di queste difficolt√†, l‚Äôinferenza causale basata su dati osservazionali √® spesso considerata problematica, dando origine al famoso detto ‚Äúla correlazione non implica causalit√†‚Äù. Tuttavia, √® importante notare che in alcune circostanze, √® possibile fare inferenze causali anche a partire da dati osservazionali.\nL‚Äôobiettivo dell‚Äôanalisi causale moderna √® proprio quello di fornire gli strumenti concettuali e metodologici per affrontare queste sfide. Attraverso l‚Äôuso di tecniche avanzate come i modelli causali strutturali, i grafi aciclici diretti (DAG) e i metodi di identificazione degli effetti causali, i ricercatori possono spesso superare le limitazioni dei dati osservazionali e trarre conclusioni causali pi√π robuste.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali üî∏</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#modelli-causali-strutturali",
    "href": "chapters/eda/09_causality.html#modelli-causali-strutturali",
    "title": "21¬† Causalit√† dai dati osservazionali üî∏",
    "section": "21.5 Modelli Causali Strutturali",
    "text": "21.5 Modelli Causali Strutturali\nI modelli causali sono strumenti essenziali per l‚Äôanalisi dei dati osservazionali, poich√© consentono di rappresentare il processo sottostante a un fenomeno e di prevedere gli effetti di un intervento. Questi modelli non solo permettono di anticipare le conseguenze di una causa, ma offrono anche la possibilit√† di esplorare scenari controfattuali, immaginando esiti alternativi che si sarebbero potuti verificare in presenza di decisioni diverse.\nUn modello causale strutturale (Structural Causal Model, SCM) √® un approccio che rappresenta le relazioni causali tra variabili. Esso si basa su una serie di assegnazioni che, partendo da variabili di rumore indipendenti (note anche come variabili esogene), generano una distribuzione di probabilit√† congiunta.\nLe variabili di rumore indipendenti svolgono un ruolo cruciale negli SCM. Esse rappresentano fonti di incertezza o variabilit√† all‚Äôinterno del sistema e non sono influenzate da altre variabili del modello. Queste variabili sono mutuamente indipendenti, il che significa che il loro valore non fornisce informazioni sul valore delle altre.\nLa costruzione di un SCM segue una sequenza specifica: si parte dalle variabili di rumore indipendenti, si applicano una serie di assegnazioni che descrivono gli effetti causali delle variabili esogene su altre variabili, e si genera progressivamente un insieme di variabili casuali che d√† origine a una distribuzione congiunta.\nIl principale vantaggio di un SCM risiede nella sua duplice natura: da un lato, fornisce una distribuzione di probabilit√† congiunta delle variabili, e dall‚Äôaltro, descrive il processo generativo che porta alla formazione di tale distribuzione, partendo dalle variabili di rumore elementari.\nQuesta struttura consente non solo di modellare le relazioni probabilistiche tra le variabili, ma anche di rappresentare in modo esplicito i meccanismi causali che le governano.\nI SCM possono essere rappresentati graficamente attraverso Grafi Aciclici Direzionati (Directed Acyclic Graphs, DAG). Questi DAG visualizzano le relazioni causali tra le variabili all‚Äôinterno di un SCM, facilitando l‚Äôidentificazione delle variabili confondenti e il loro impatto sull‚Äôanalisi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali üî∏</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#bias-da-variabile-omessa",
    "href": "chapters/eda/09_causality.html#bias-da-variabile-omessa",
    "title": "21¬† Causalit√† dai dati osservazionali üî∏",
    "section": "21.6 Bias da Variabile Omessa",
    "text": "21.6 Bias da Variabile Omessa\nPossiamo introdurre i DAG facendo riferiento al bias da variabile omessa (Omitted Variable Bias, o OVB; Wilms et al. (2021)). Come discusso da Byrnes & Dee (2024), l‚Äôomissione dall‚Äôanalisi statistica di variabili confondenti note ma non misurate, o sconosciute e non misurate, pu√≤ portare a stime errate della magnitudine degli effetti, errori nel segno delle stime (stimatori distorti), correlazioni spurie, e al mascheramento delle vere relazioni causali.\nUn illustrazione di questa situazione √® fornita nella Figura¬†21.1. La figura mostra tre DAG che illustrano diversi scenari in cui le variabili non osservate non influenzano i risultati del modello o potrebbero creare problemi a causa della confusione. Una variabile di risposta di interesse (Y) √® causata sia da una variabile misurata (X) che da una variabile non misurata (U). Nel pannello di sinistra, la variabile non osservata (U) non √® una variabile confondente. Nel pannello centrale, la variabile non osservata (U) √® una variabile confondente e causa il bias da variabile omessa. Nel pannello di destra la variabile non osservata (U) causa il bias da variabile omessa in maniera indiretta.\n\n\n\n\n\n\nFigura¬†21.1: Nel pannello di sinistra, X e U sono non correlate, quindi la mancata inclusione di U in un modello statistico aumenterebbe l‚Äôerrore standard della stima (riducendo la precisione del modello) ma non porterebbe a bias nella stima dell‚Äôeffetto di X su Y. Tuttavia, se U influenza anche X come nel pannello centrale, o se U e X sono influenzati da un fattore comune Z come nel pannello di destra, allora omettere U da un modello statistico causa il bias da variabile omessa nella stima dell‚Äôeffetto di X su Y. I casi illustrati dal pannello centrale e dal pannello di destra sono esempi di sistemi in cui le cause comuni di confusione (U e Z rispettivamente) devono essere controllate per effettuare inferenze causali non distorte (la figura √® ispirata da Byrnes & Dee (2024)).\n\n\n\nAffrontare i problemi creati dalle variabili confondenti non misurate rappresenta una sfida primaria nell‚Äôinferenza causale dai dati osservazionali. A differenza dell‚Äôerrore di misurazione nelle variabili predittive, che produce un bias costante verso lo zero e pu√≤ essere corretto o modellato (McElreath, 2020; Schennach, 2016), con l‚ÄôOVB non possiamo conoscere la grandezza o la direzione del bias senza conoscere tutte le possibili variabili confondenti e le loro relazioni nel sistema.\nNonostante queste sfide, non √® necessario abbandonare l‚Äôuso dei dati osservazionali per l‚Äôinferenza causale in psicologia. √à invece necessario ricorrere all‚Äôadozione delle tecniche dei SCM per potere comunque svolgere l‚Äôinferenza causale.\n√à evidente che questo approccio porter√† a conclusioni inevitabilmente parziali, destinate ad essere perfezionate da studi successivi. Tuttavia, tale metodologia offre il vantaggio di esplicitare il ‚Äúmodello generativo dei dati‚Äù, ovvero la struttura causale sottostante ai fenomeni psicologici oggetto di studio.\nI progressi nella ricerca empirica conducono a una maggiore comprensione e, di conseguenza, a modifiche nelle ipotesi sui meccanismi causali. Questo processo rappresenta un‚Äôevoluzione della conoscenza scientifica. Tale sviluppo √® reso possibile proprio perch√© le ipotesi causali sono formulate in termini di modelli formali, che descrivono in modo preciso i meccanismi ipotizzati.\nAl contrario, limitarsi alla mera descrizione delle associazioni tra variabili non consente questo tipo di avanzamento conoscitivo. La formulazione di modelli causali espliciti permette infatti di testare, raffinare e, se necessario, rivedere le ipotesi sui meccanismi sottostanti ai fenomeni osservati, portando a una comprensione pi√π profonda e dinamica dei processi psicologici.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali üî∏</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#grafi-aciclici-diretti",
    "href": "chapters/eda/09_causality.html#grafi-aciclici-diretti",
    "title": "21¬† Causalit√† dai dati osservazionali üî∏",
    "section": "21.7 Grafi Aciclici Diretti",
    "text": "21.7 Grafi Aciclici Diretti\nI DAG sono uno strumento fondamentale per l‚Äôinferenza causale, offrendo una rappresentazione visiva delle relazioni causali ipotizzate tra variabili. Questi grafi sono definiti ‚Äúdiretti‚Äù perch√© le variabili, rappresentate da nodi, sono collegate da frecce orientate anzich√© da semplici linee. Sono inoltre chiamati ‚Äúaciclici‚Äù poich√© non √® possibile tornare a un nodo di partenza seguendo il percorso delle frecce.\nIn un DAG, una freccia che va da X a Y indica un‚Äôinfluenza probabilistica di X su Y. La terminologia delle relazioni all‚Äôinterno del grafo √® importante: il nodo di origine di una freccia √® chiamato ‚Äúgenitore‚Äù, mentre il nodo di destinazione √® detto ‚Äúfiglio‚Äù. Quando √® possibile raggiungere un nodo B partendo da un nodo A seguendo una successione di frecce, A √® definito ‚Äúantenato‚Äù di B, e B √® considerato ‚Äúdiscendente‚Äù di A.\nI DAG consentono di distinguere chiaramente tra cause dirette e indirette. Una causa diretta √® rappresentata da un nodo genitore, mentre una causa indiretta pu√≤ essere qualsiasi antenato di un nodo nel grafo causale. Questa struttura permette di differenziare efficacemente causa ed effetto basandosi sulla posizione relativa dei nodi all‚Äôinterno del grafo, ovvero se un nodo √® antenato o discendente di un altro.\nQuesti grafi sono particolarmente utili per identificare variabili confondenti, basandosi sulla teoria sviluppata da Judea Pearl (Pearl, 2009). √à cruciale rappresentare in un DAG tutte le possibili relazioni causali, poich√© l‚Äôassenza di una freccia tra due nodi implica la certezza dell‚Äôassenza di una relazione causale diretta tra le variabili corrispondenti.\nNella teoria dei DAG, due concetti fondamentali sono la d-separazione e il criterio del back-door.\n\n21.7.1 La d-separazione\nLa d-separazione ci aiuta a determinare quando due variabili in un grafo causale sono indipendenti condizionatamente a un insieme di altre variabili. Questo concetto √® cruciale per comprendere come l‚Äôinformazione o l‚Äôinfluenza si propaga tra le variabili in un modello causale.\nIn termini pi√π semplici, la d-separazione ci permette di identificare se esiste un ‚Äúblocco‚Äù nel flusso di informazioni tra due variabili, dato un certo insieme di altre variabili (che chiameremo Œõ). Quando due variabili sono d-separate da Œõ, significa che non c‚Äô√® flusso di informazioni tra di loro, condizionatamente a Œõ.\nPer comprendere meglio la d-separazione, consideriamo tre situazioni principali che possono verificarsi in un DAG:\n\nCatena (X ‚Üí Z ‚Üí Y): In questo caso, Z √® un mediatore tra X e Y. Se Z appartiene all‚Äôinsieme Œõ (cio√®, se controlliamo o condizioniamo su Z), blocchiamo il flusso di informazioni da X a Y attraverso questo percorso. Per esempio, se X √® ‚Äúesercizio fisico‚Äù, Z √® ‚Äúpressione sanguigna‚Äù e Y √® ‚Äúrischio di malattie cardiache‚Äù, controllando per la pressione sanguigna (Z) blocchiamo il percorso attraverso il quale l‚Äôesercizio fisico influenza il rischio di malattie cardiache.\nFork (X ‚Üê Z ‚Üí Y): Qui, Z √® una causa comune sia di X che di Y. Se Z appartiene a Œõ, blocchiamo la correlazione spuria tra X e Y che deriva dalla loro causa comune. Per esempio, se Z √® ‚Äústatus socioeconomico‚Äù, X √® ‚Äúlivello di istruzione‚Äù e Y √® ‚Äústato di salute‚Äù, controllando per lo status socioeconomico (Z) eliminiamo la correlazione apparente tra istruzione e salute che potrebbe derivare dal fatto che entrambe sono influenzate dallo status socioeconomico.\nCollider (X ‚Üí Z ‚Üê Y): In questa situazione, Z √® un effetto comune di X e Y. Sorprendentemente, se n√© Z n√© i suoi discendenti appartengono a Œõ, il percorso √® gi√† bloccato. Controllare per Z (o i suoi discendenti) in realt√† aprirebbe un percorso tra X e Y, creando una correlazione spuria. Per esempio, se X √® ‚Äúintelligenza‚Äù, Y √® ‚Äúbellezza‚Äù e Z √® ‚Äúsuccesso in una carriera di attore‚Äù, controllare per il successo nella carriera di attore (Z) creerebbe una correlazione apparente tra intelligenza e bellezza, anche se queste potrebbero essere indipendenti nella popolazione generale.\n\nIn sintesi, la d-separazione ci permette di determinare, dato un certo insieme di variabili Œõ, se due variabili X e Y sono indipendenti condizionatamente a Œõ. Questo ci aiuta a identificare quali variabili dobbiamo controllare (e quali non dobbiamo controllare) per ottenere stime causali non distorte, facilitando cos√¨ l‚Äôinferenza causale corretta. La d-separazione √® quindi uno strumento potente che ci permette di leggere le indipendenze condizionali direttamente dal grafo, senza dover fare calcoli probabilistici complessi.\n\n\n21.7.2 Il criterio del back-door\nIl criterio del back-door consente di identificare un insieme di variabili che, se controllate adeguatamente, permettono di stimare gli effetti causali in modo non distorto. L‚Äôobiettivo principale di questo criterio √® eliminare l‚Äôinfluenza di percorsi non causali tra la variabile di esposizione (causa potenziale) e l‚Äôoutcome (effetto), mantenendo aperto solo il percorso causale diretto di interesse.\nIn questo contesto, due variabili sono considerate ‚Äúconfuse‚Äù se esiste tra di esse un percorso di tipo back-door. Un back-door path da X a Y √® definito come qualsiasi percorso che inizia da X con una freccia entrante in X. Per esempio, consideriamo il seguente percorso:\nX ‚Üê A ‚Üí B ‚Üê C ‚Üí Y\nIn questo caso, il percorso rappresenta un flusso di informazioni da X a Y che non √® causale, ma potrebbe creare l‚Äôapparenza di una relazione causale.\nPer ‚Äúdeconfondere‚Äù una coppia di variabili, √® necessario selezionare un insieme di variabili (chiamato back-door set) che ‚Äúblocchi‚Äù tutti i back-door paths tra i due nodi di interesse. Il blocco di questi percorsi avviene in modi diversi a seconda della struttura del percorso:\n\nUn back-door path che coinvolge una catena di variabili (ad esempio, A ‚Üí B ‚Üí C) pu√≤ essere bloccato controllando per la variabile intermedia (in questo caso, B).\nUn percorso che coinvolge un ‚Äúcollider‚Äù (una variabile che riceve frecce da entrambe le direzioni, come in A ‚Üí B ‚Üê C) √® naturalmente bloccato e non permette il flusso di informazioni.\n\n√à importante notare che bisogna prestare attenzione a non aprire involontariamente un flusso di informazioni attraverso un collider. Questo pu√≤ accadere se si condiziona l‚Äôanalisi sul collider stesso o su un suo discendente, il che potrebbe erroneamente aprire il percorso e introdurre bias nell‚Äôanalisi.\n\n\n\n\n\n\nPunti chiave\n\n\n\n\nIl criterio del back-door aiuta a identificare il set minimale di variabili da controllare.\nNon tutte le variabili associate sia all‚Äôesposizione che all‚Äôoutcome devono essere controllate; solo quelle che creano percorsi back-door.\nIn alcuni casi, potrebbe non essere necessario controllare alcuna variabile (se non ci sono percorsi back-door aperti).\nIn altri casi, potrebbe essere impossibile bloccare tutti i percorsi back-door con le variabili disponibili, indicando che l‚Äôeffetto causale non pu√≤ essere identificato con i dati a disposizione.\n\nUtilizzando il criterio del back-door in combinazione con i DAG, i ricercatori possono fare scelte pi√π informate su quali variabili includere nelle loro analisi, migliorando cos√¨ la validit√† delle loro inferenze causali.\n\n\n\n\n21.7.3 Applicazioni\nConsideriamo nuovamente la struttura causale illustrata nella Figura¬†21.1, pannello centrale. Dopo aver costruito un DAG come descritto nella sezione precedente, √® possibile identificare le potenziali fonti di bias da variabili omesse, inclusi i confondenti non misurati (ad esempio, U). Non controllare per le variabili confondenti apre una ‚Äúback-door‚Äù permettendo alla variazione confondente di influenzare la relazione tra la variabile causale e la variabile di risposta di interesse attraverso un percorso non valutato (Pearl, 2009). In altre parole, omettere una variabile confondente come U nella Figura¬†21.1 (pannello centrale) in un‚Äôanalisi statistica significa che questa viene incorporata nel termine di errore del modello statistico, insieme alle fonti di errore casuali. La Figura¬†21.2 illustra le conseguenze di un confondente U che ha un effetto positivo su X ma un effetto negativo su Y. Se adattiamo un modello come mostrato nella Figura¬†21.2 bi, l‚Äôeffetto stimato di X su Y √® positivo quando si controlla per U. Tuttavia, se non si controlla per U, come mostrato nella Figura¬†21.2 bii, U viene incorporato nel termine di errore, inducendo una correlazione tra l‚Äôerrore e X, come illustrato nella Figura¬†21.2 biii, portando a una stima errata. Pertanto, il termine di errore del modello e X risultano correlati, il che viola un‚Äôassunzione fondamentale dei modelli lineari (ovvero, il teorema di Gauss-Markov; Abdallah et al., 2015; Antonakis et al., 2010). Questo produce una stima errata, evidenziata in blu.\n\n\n\n\n\n\nFigura¬†21.2: Una visualizzazione del bias da variabile omessa e delle conseguenze per l‚Äôinferenza causale. (A) mostra un DAG di un sistema in cui X ha un effetto positivo su Y, e una variabile confondente U ha un effetto positivo su Y ma un effetto negativo su X. Le variabili non osservate (cio√® non misurate) sono rappresentate in ellissi, come la variabile U e il termine di errore e nel pannello B. (B) illustra diverse stime del DAG in (A) utilizzando un‚Äôanalisi del percorso. Vedi Box 1 per una breve spiegazione delle principali differenze tra DAG e diagrammi dei percorsi. Presumiamo che U non sia misurata. In (Bi), presumiamo di poter misurare e controllare U, rappresentata dalla freccia a doppia testa tra U e X, che rappresenta la correlazione tra le due variabili considerata dal modello. La variabile non misurata e √® la fonte residua di variazione che si presume non sia correlata con nessun predittore. La freccia rossa rappresenta il percorso stimato. Al contrario, (Bii) e (Biii) rappresentano la realt√†, dove non abbiamo una misurazione di U e non la controlliamo nel modello dei percorsi. Il ricercatore pensa di adattare il modello in (Bii) ma in realt√† sta adattando il modello in (Biii), dove il termine di errore non √® solo e, ma la somma di e e la variazione dovuta alla variabile omessa U. A causa di ci√≤, c‚Äô√® un percorso diretto dal termine di errore del modello a X (e quindi X √® endogeno). (C) mostra le relazioni stimate risultanti dai modelli in (Bi) rispetto a (Bii). Le linee rappresentano la relazione stimata tra X e Y dai rispettivi modelli. La linea rossa √® la vera relazione causale, stimata da (Bi), mentre la linea blu contiene il bias da variabile omessa, poich√© non si tiene conto della variabile confondente U, come stimato dal modello in Bii/Biii (Figura tratta da Byrnes & Dee (2024)).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali üî∏</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#commenti-e-considerazioni-finali",
    "href": "chapters/eda/09_causality.html#commenti-e-considerazioni-finali",
    "title": "21¬† Causalit√† dai dati osservazionali üî∏",
    "section": "21.8 Commenti e Considerazioni Finali",
    "text": "21.8 Commenti e Considerazioni Finali\nI diagrammi causali sono uno dei primi strumenti per identificare il bias da variabili omesse (Pearl, 1995; Pearl et al., 2016). I diagrammi causali, sotto forma di DAG, visualizzano la nostra comprensione delle relazioni causali e delle variabili confondenti all‚Äôinterno di un sistema. In questo modo, i DAG chiariscono in modo trasparente le assunzioni dietro le affermazioni causali derivate dai dati e mostrano le potenziali fonti di bias derivanti da variabili confondenti.\n√à fondamentale che i DAG includano tutte le cause comuni di un predittore e della risposta di interesse, comprendendo tutte le variabili confondenti misurate e non misurate. Questo significa che l‚Äôinferenza causale √® possibile solo quando il ricercatore dispone di adeguate conoscenze del dominio.\nDopo aver costruito un DAG, √® possibile determinare le potenziali fonti di bias da variabili omesse, incluse quelle derivanti da variabili confondenti non misurate (es., U nella figura fig-byrnes-dee-1, pannello centrale). Non controllare le variabili confondenti apre una ‚Äúback-door‚Äù per la variazione confondente, permettendo a quest‚Äôultima di fluire tra la variabile causale e la variabile di risposta di interesse attraverso un percorso non valutato (Pearl, 2009).\nPertanto, un diagramma causale √® un primo passo fondamentale per identificare potenziali bias da variabili omesse. I DAG giustificano anche la scelta delle variabili di controllo, rendendo trasparenti le assunzioni che un ricercatore fa su come funziona il sistema oggetto di studio.\n√à importante notare che i DAG possono essere incorretti o non includere variabili confondenti sconosciute. Infatti, un DAG rappresenta solo la comprensione attuale e le assunzioni del ricercatore riguardo alle relazioni causali all‚Äôinterno di un sistema.\nUn sommario ironico di questi concetti √® fornito nella vignetta di xkcd.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali üî∏</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#bibliografia",
    "href": "chapters/eda/09_causality.html#bibliografia",
    "title": "21¬† Causalit√† dai dati osservazionali üî∏",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAlexander, R. (2023). Telling Stories with Data: With Applications in R. Chapman; Hall/CRC.\n\n\nByrnes, J. E., & Dee, L. E. (2024). Causal inference with observational data and unobserved confounding variables. bioRxiv, 2024‚Äì2002.\n\n\nHardt, M., & Recht, B. (2022). Patterns, Predictions, and Actions: Foundations of Machine Learning. Princeton University Press.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nPearl, J. (1995). Causal diagrams for empirical research. Biometrika, 82(4), 669‚Äì688.\n\n\nPearl, J. (2009). Causality. Cambridge University Press.\n\n\nPearl, J., Glymour, M., & Jewell, N. P. (2016). Causal inference in statistics: A primer. John Wiley & Sons.\n\n\nRiederer, E. (2021). Causal design patterns for data analysts. https://emilyriederer.netlify.app/post/causal-design-patterns/\n\n\nSchennach, S. M. (2016). Recent advances in the measurement error literature. Annual Review of Economics, 8(1), 341‚Äì377.\n\n\nWilms, R., M√§thner, E., Winnen, L., & Lanwehr, R. (2021). Omitted variable bias: A threat to estimating causal relationships. Methods in Psychology, 5, 100075.\n\n\nZwet, E. van, Gelman, A., Greenland, S., Imbens, G., Schwab, S., & Goodman, S. N. (2023). A New Look at P Values for Randomized Clinical Trials. NEJM Evidence, 3(1), EVIDoa2300003.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali üî∏</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html",
    "href": "chapters/eda/10_estimand.html",
    "title": "22¬† Estimandi teorici e estimandi empirici üî∏",
    "section": "",
    "text": "22.1 Introduzione\nNei capitoli precedenti abbiamo illustrato diverse tecniche di analisi esplorativa dei dati, utili per sintetizzare ampie quantit√† di informazioni, rappresentare le distribuzioni delle variabili e descriverne le relazioni. In tali esempi, abbiamo dato per scontato che le variabili fossero state misurate correttamente con lo scopo di rispondere a una determinata domanda teorica. √à per√≤ fondamentale interrogarsi sul legame tra le quantit√† che vogliamo stimare (estimandi) e la teoria che guida lo studio. Per approfondire questo aspetto, esamineremo l‚Äôarticolo di Lundberg et al. (2021), ‚ÄúWhat Is Your Estimand? Defining the Target Quantity Connects Statistical Evidence to Theory‚Äù, che mette in luce quanto sia importante definire con precisione l‚Äôestimando chiave di una ricerca.\nL‚Äôestimando √® la quantit√† che uno studio intende stimare e rappresenta il ponte tra la teoria e l‚Äôevidenza statistica. Gli autori suggeriscono un approccio metodologico in tre fasi:\nQuesto approccio consente di chiarire come le informazioni ottenute dai dati rispondano a una ben precisa domanda teorica. In breve, Lundberg et al. (2021) invitano i ricercatori a definire l‚Äôestimando teorico in modo indipendente dai modelli statistici impiegati, cos√¨ da evidenziare il nesso logico fra teoria ed evidenza empirica.\nIn altre parole, non basta limitarsi a verificare se un coefficiente di regressione √® ‚Äúsignificativamente diverso da zero‚Äù basandosi solo sul modello statistico. √à necessario distinguere l‚Äôobiettivo teorico della ricerca (ad esempio, studiare l‚Äôapprendimento associativo) dal modo in cui questo obiettivo viene tradotto in una misura osservabile. Un esempio concreto √® fornito dal modello di Rescorla-Wagner, applicato a compiti di Probabilistic Reversal Learning (PRL): l‚Äôestimando empirico potrebbe corrispondere a parametri come il tasso di apprendimento \\(\\alpha\\) o la temperatura inversa \\(\\beta\\). Questi parametri riflettono quanto i partecipanti modifichino i valori associati agli stimoli o regolino la strategia di scelta (esplorazione rispetto a sfruttamento), come descritto nella sezione ?sec-rescorla-wagner.\n√à importante notare che l‚Äôestimando empirico pu√≤ essere stimato in modi diversi, utilizzando modelli, metodi di stima e disegni sperimentali vari. Il modello di Rescorla-Wagner √® solo una possibile rappresentazione dell‚Äôapprendimento associativo, e i suoi parametri possono essere ricavati con procedure differenti. Di conseguenza, il valore numerico che descrive la capacit√† di apprendimento associativo dipende dal modello, dalla tecnica di stima e dal contesto sperimentale.\nIn conclusione, Lundberg et al. (2021) sottolineano l‚Äôimportanza di definire l‚Äôestimando teorico prima di qualsiasi analisi, e di giustificare in modo chiaro la scelta dello specifico estimando empirico e della strategia di stima adottata. Cos√¨ facendo, si evidenzia il legame tra teoria e dati, rendendo pi√π trasparenti, coerenti e riproducibili i processi di inferenza statistica.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Estimandi teorici e estimandi empirici üî∏</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#introduzione",
    "href": "chapters/eda/10_estimand.html#introduzione",
    "title": "22¬† Estimandi teorici e estimandi empirici üî∏",
    "section": "",
    "text": "Definire un estimando teorico, collegato esplicitamente alla teoria che guida la ricerca.\nTradurre l‚Äôestimando teorico in un estimando empirico, cio√® una misura concreta, ottenuta dai dati osservabili, che richiede l‚Äôadozione di specifiche assunzioni di identificazione.\nStimare l‚Äôestimando empirico utilizzando procedure statistiche appropriate, in modo da ricavare inferenze solide a partire dai dati.\n\n\n\n\n\n\n\n\n\n\n\nIn italiano, la traduzione comunemente usata di ‚Äúestimand‚Äù nella letteratura scientifica √® estimando. Questo termine viene utilizzato per riferirsi alla quantit√† o al parametro che si desidera stimare in un‚Äôanalisi statistica.\nStimatore, invece, √® la traduzione di ‚Äúestimator‚Äù e si riferisce alla regola o alla funzione utilizzata per calcolare una stima basata sui dati osservati. Quindi, ‚Äúestimando‚Äù e ‚Äústimatore‚Äù sono termini distinti: l‚Äô‚Äúestimando‚Äù √® l‚Äôoggetto dell‚Äôinferenza statistica, mentre lo ‚Äústimatore‚Äù √® il metodo o la formula usata per ottenere l‚Äôinferenza.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Estimandi teorici e estimandi empirici üî∏</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#limiti-dellapproccio-attuale",
    "href": "chapters/eda/10_estimand.html#limiti-dellapproccio-attuale",
    "title": "22¬† Estimandi teorici e estimandi empirici üî∏",
    "section": "22.2 Limiti dell‚ÄôApproccio Attuale",
    "text": "22.2 Limiti dell‚ÄôApproccio Attuale\nLundberg et al. (2021) osservano che spesso i ricercatori sociali omettono il passaggio cruciale della definizione dell‚Äôestimando, concentrandosi direttamente sui dati e sulle procedure statistiche. Questo approccio pu√≤ causare una mancanza di chiarezza riguardo a ci√≤ che si intende effettivamente stimare, limitando anche l‚Äôuso di modelli statistici alternativi che potrebbero essere pi√π adatti a rispondere alla domanda di ricerca. Sebbene Lundberg et al. (2021) facciano riferimento alla letteratura sociologica, questi stessi argomenti sono applicabili anche alla psicologia.\nIl problema del collegamento tra estimandi teorici ed empirici (si veda la figura seguente) pu√≤ essere illustrato con un esempio in psicologia riguardante l‚Äôintelligenza. La distinzione tra estimandi teorici ed empirici √® cruciale: gli estimandi teorici possono includere quantit√† non osservabili, come i costrutti latenti, ad esempio l‚Äôintelligenza come concetto astratto. Gli estimandi empirici, invece, riguardano esclusivamente dati osservabili, come i punteggi ottenuti in un test di intelligenza.\nNel caso dell‚Äôintelligenza, la scelta dell‚Äôestimando teorico richiede un‚Äôargomentazione sostanziale riguardo alla teoria dell‚Äôintelligenza adottata e agli obiettivi della ricerca. Ad esempio, se si vuole studiare l‚Äôintelligenza generale (fattore g), bisogna chiarire come questo costrutto viene teoricamente definito e perch√© √® rilevante per lo studio.\nD‚Äôaltra parte, la scelta dell‚Äôestimando empirico richiede un‚Äôargomentazione concettuale su come i dati osservabili, come i risultati dei test di intelligenza, possano rappresentare il costrutto latente di interesse. √à necessario spiegare quali dati vengono utilizzati per inferire il costrutto teorico e quali assunzioni si fanno riguardo al rapporto tra le misure osservate e il costrutto latente.\nInfine, la scelta delle strategie di stima, come l‚Äôuso di modelli di equazioni strutturali per stimare l‚Äôintelligenza generale da diversi test, √® una decisione separata, che pu√≤ essere in parte guidata dai dati disponibili e dalle caratteristiche della misurazione. Separare chiaramente questi passaggi aiuta i ricercatori a fare scelte informate e fondate, consente ai lettori di valutare in modo critico le affermazioni fatte e permette alla comunit√† scientifica di costruire su basi solide per futuri sviluppi della ricerca.\n\n\n\nTre Scelte Critiche nelle Argomentazioni delle Scienze Sociali Quantitative. La prima scelta riguarda gli estimandi teorici, che definiscono gli obiettivi dell‚Äôinferenza. √à necessario un argomento che colleghi gli estimandi teorici alla teoria pi√π ampia. La seconda scelta riguarda gli estimandi empirici, che collegano questi obiettivi ai dati osservabili. Questo collegamento richiede delle assunzioni sostanziali, che possono essere formalizzate attraverso grafici aciclici diretti. La terza scelta riguarda le strategie di stima, che determinano come verranno effettivamente utilizzati i dati. La selezione delle strategie di stima si basa sui dati disponibili (figura tratta da Lundberg et al. (2021)).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Estimandi teorici e estimandi empirici üî∏</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#definizione-dellestimando-teorico",
    "href": "chapters/eda/10_estimand.html#definizione-dellestimando-teorico",
    "title": "22¬† Estimandi teorici e estimandi empirici üî∏",
    "section": "22.3 Definizione dell‚ÄôEstimando Teorico",
    "text": "22.3 Definizione dell‚ÄôEstimando Teorico\nLa definizione dell‚Äôestimando teorico √® cruciale per determinare la natura dello studio perch√© specifica chiaramente quale tipo di relazione tra le variabili stiamo cercando di indagare. In altre parole, l‚Äôestimando teorico indica se lo studio mira a descrivere, prevedere o stabilire una relazione causale. Vediamo come questo funziona in pratica con esempi legati all‚Äôintelligenza e all‚Äôallenamento cognitivo.\n\n22.3.1 Estimando Teorico in uno Studio Descrittivo\nUno studio descrittivo ha come obiettivo semplicemente quello di caratterizzare o descrivere una certa realt√† o fenomeno senza inferire relazioni di causa-effetto. In questo caso, l‚Äôestimando teorico potrebbe essere una misura che riassume una caratteristica della popolazione.\nEsempio: Qual √® il punteggio medio di intelligenza tra le persone che hanno partecipato a un programma di allenamento cognitivo rispetto a quelle che non l‚Äôhanno fatto?\nEstimando Teorico: La differenza media nei punteggi di intelligenza tra i due gruppi. Questo tipo di estimando descrive la distribuzione dei punteggi di intelligenza nei gruppi, ma non implica che l‚Äôallenamento abbia causato le differenze osservate.\n\n\n22.3.2 Estimando Teorico in uno Studio Predittivo\nUno studio predittivo si concentra sulla capacit√† di prevedere un risultato basato su dati osservabili. Qui, l‚Äôestimando teorico riguarda la capacit√† del modello di predire correttamente i risultati futuri, ma senza implicazioni causali.\nEsempio: In che misura la partecipazione a un programma di allenamento cognitivo pu√≤ prevedere il punteggio di intelligenza futuro di una persona?\nEstimando Teorico: La previsione del punteggio di intelligenza basata sulla partecipazione all‚Äôallenamento cognitivo. Questo estimando si basa su modelli statistici che utilizzano variabili osservabili per fare previsioni, ma non determinano la causalit√† tra allenamento e punteggi di intelligenza.\n\n\n22.3.3 Estimando Teorico in uno Studio Causale\nUno studio causale cerca di stabilire un nesso diretto di causa-effetto tra variabili. L‚Äôestimando teorico in questo caso riguarda l‚Äôeffetto diretto di una variabile indipendente su una variabile dipendente, tenendo conto di altre variabili confondenti.\nEsempio: L‚Äôallenamento cognitivo causa un aumento nei punteggi di intelligenza?\nEstimando Teorico: La differenza media nei punteggi di intelligenza che si attribuisce direttamente all‚Äôeffetto dell‚Äôallenamento cognitivo, controllando per tutte le altre variabili confondenti. Questo estimando implica l‚Äôuso di un disegno di ricerca che isola l‚Äôeffetto dell‚Äôallenamento, come un esperimento con assegnazione casuale.\n\n\n22.3.4 L‚ÄôEstimando Teorico Chiarisce la Natura dello Studio\nDefinire l‚Äôestimando teorico in modo preciso aiuta a chiarire la natura dello studio perch√© specifica esattamente quale relazione tra le variabili viene studiata:\n\nStudi Descrittivi: L‚Äôestimando teorico √® una semplice descrizione di dati, come una media o una differenza, senza inferire causalit√†.\nStudi Predittivi: L‚Äôestimando teorico si concentra sulla capacit√† di un modello di fare previsioni basate sui dati, senza implicazioni causali.\nStudi Causali: L‚Äôestimando teorico cerca di determinare l‚Äôeffetto diretto di una variabile su un‚Äôaltra, richiedendo un disegno di studio che possa controllare variabili confondenti per isolare la causalit√†.\n\nIn sintesi, l‚Äôestimando teorico orienta il ricercatore nel definire chiaramente se lo scopo dello studio √® descrittivo, predittivo o causale, e guida il disegno dello studio e l‚Äôanalisi dei dati di conseguenza.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Estimandi teorici e estimandi empirici üî∏</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#importanza-dei-dag-nel-contesto-degli-estimandi-teorici",
    "href": "chapters/eda/10_estimand.html#importanza-dei-dag-nel-contesto-degli-estimandi-teorici",
    "title": "22¬† Estimandi teorici e estimandi empirici üî∏",
    "section": "22.4 Importanza dei DAG nel Contesto degli Estimandi Teorici",
    "text": "22.4 Importanza dei DAG nel Contesto degli Estimandi Teorici\nNella figura 2 dell‚Äôarticolo di Lundberg et al. (2021), i Grafici Aciclici Diretti (DAG) vengono utilizzati per illustrare le relazioni causali tra variabili all‚Äôinterno di uno studio. I DAG sono strumenti visivi che aiutano i ricercatori a rappresentare e comprendere le assunzioni causali sottostanti ai loro studi, fornendo una chiara rappresentazione grafica di come le variabili si influenzano a vicenda. Questo √® particolarmente importante quando si definiscono estimandi teorici, perch√© i DAG consentono di identificare chiaramente le variabili confondenti e di stabilire le relazioni di causalit√†.\nI DAG possono contribuire alla definizione degli estimandi teorici in molti modi.\n\nChiarificazione delle Relazioni Causali: I DAG aiutano a chiarire quali variabili sono considerate come cause potenziali e quali come effetti. Questo √® fondamentale per definire l‚Äôestimando teorico, soprattutto in uno studio causale, dove √® importante distinguere tra correlazione e causalit√†. Ad esempio, se si studia l‚Äôeffetto dell‚Äôallenamento cognitivo sull‚Äôintelligenza, un DAG pu√≤ mostrare come l‚Äôallenamento influisce direttamente sull‚Äôintelligenza, identificando al contempo variabili confondenti come il background educativo o la motivazione.\nIdentificazione delle Variabili Confondenti: Uno dei principali vantaggi dell‚Äôutilizzo dei DAG √® la loro capacit√† di identificare le variabili confondenti che possono influenzare entrambe le variabili di interesse. Nel contesto degli estimandi teorici, riconoscere e controllare queste variabili confondenti √® cruciale per stabilire una relazione causale valida. Ad esempio, un DAG potrebbe rivelare che la motivazione personale influisce sia sulla partecipazione all‚Äôallenamento cognitivo che sui punteggi di intelligenza, indicando che questa variabile deve essere controllata per ottenere un estimando causale corretto.\nGuida nella Costruzione del Disegno di Ricerca: I DAG sono strumenti utili nella pianificazione del disegno di ricerca perch√© aiutano a determinare quali variabili devono essere misurate e controllate. Definendo chiaramente le relazioni tra le variabili, i ricercatori possono progettare esperimenti o studi osservazionali che minimizzano i bias e migliorano la validit√† interna dello studio. Ad esempio, un DAG pu√≤ suggerire la necessit√† di randomizzare l‚Äôassegnazione all‚Äôallenamento cognitivo per garantire che l‚Äôeffetto osservato sui punteggi di intelligenza sia realmente causato dall‚Äôallenamento e non da un‚Äôaltra variabile.\nSupporto nella Selezione delle Strategie di Stima: Una volta definite le relazioni tra le variabili attraverso un DAG, i ricercatori possono scegliere strategie di stima appropriate per gli estimandi teorici ed empirici. Per esempio, se un DAG indica che non ci sono percorsi diretti tra alcune variabili, si possono utilizzare metodi statistici che presuppongono l‚Äôindipendenza condizionale, come la regressione lineare o i modelli di equazioni strutturali.\n\nIn sintesi, nel contesto della definizione degli estimandi teorici, i DAG sono strumenti essenziali che consentono ai ricercatori di visualizzare e comprendere le relazioni causali e le variabili confondenti all‚Äôinterno di uno studio. Essi facilitano la costruzione di disegni di ricerca solidi, la selezione di strategie di stima appropriate e la comunicazione chiara delle assunzioni causali sottostanti. Utilizzando i DAG, i ricercatori possono garantire che gli estimandi teorici siano ben definiti e che le inferenze tratte dai dati siano valide e affidabili.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Estimandi teorici e estimandi empirici üî∏</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#collegamento-tra-estimando-teorico-ed-empirico",
    "href": "chapters/eda/10_estimand.html#collegamento-tra-estimando-teorico-ed-empirico",
    "title": "22¬† Estimandi teorici e estimandi empirici üî∏",
    "section": "22.5 Collegamento tra Estimando Teorico ed Empirico",
    "text": "22.5 Collegamento tra Estimando Teorico ed Empirico\nLundberg et al. (2021) sottolineano l‚Äôimportanza di collegare chiaramente l‚Äôestimando teorico all‚Äôestimando empirico, utilizzando assunzioni sostanziali e metodi appropriati per garantire che le conclusioni tratte dai dati siano valide.\nEstimando Empirico: L‚Äôestimando empirico √® la quantit√† che viene effettivamente calcolata dai dati osservati. Mentre l‚Äôestimando teorico rappresenta l‚Äôobiettivo concettuale dello studio (come l‚Äôeffetto dell‚Äôallenamento cognitivo sull‚Äôintelligenza), l‚Äôestimando empirico √® ci√≤ che viene effettivamente misurato nel contesto dei dati disponibili.\nPer tradurre un estimando teorico in uno empirico, √® essenziale formulare assunzioni che rendano possibile l‚Äôinferenza causale. Queste assunzioni possono essere formalizzate attraverso l‚Äôuso dei Grafici Aciclici Diretti (DAG) per garantire che le variabili confondenti siano adeguatamente controllate. L‚Äôidentificazione corretta assicura che le conclusioni derivate dai dati osservati siano valide rispetto all‚Äôeffetto causale che si sta cercando di stimare.\nConsideriamo uno studio psicologico sull‚Äôeffetto dell‚Äôallenamento cognitivo sui punteggi di intelligenza:\n\nEstimando Teorico: Il nostro obiettivo teorico potrebbe essere stimare l‚Äôeffetto causale dell‚Äôallenamento cognitivo sull‚Äôaumento del punteggio di intelligenza in una popolazione adulta. L‚Äôestimando teorico qui sarebbe la differenza media nei punteggi di intelligenza tra gli individui che hanno partecipato all‚Äôallenamento e quelli che non lo hanno fatto, supponendo che l‚Äôunica differenza tra i gruppi sia l‚Äôallenamento stesso.\nEstimando Empirico: Per passare all‚Äôestimando empirico, dobbiamo considerare cosa possiamo effettivamente misurare. Supponiamo di avere dati da un campione di adulti, alcuni dei quali hanno partecipato all‚Äôallenamento cognitivo e altri no. L‚Äôestimando empirico potrebbe essere la differenza osservata nei punteggi di intelligenza tra questi due gruppi nel campione disponibile.\nAssunzioni per l‚ÄôIdentificazione:\n\nAssunzione di Nessuna Confusione (No Confounding): Dobbiamo assumere che non vi siano variabili non misurate che influenzano sia la partecipazione all‚Äôallenamento che i punteggi di intelligenza. Per esempio, la motivazione personale potrebbe influenzare sia la decisione di partecipare all‚Äôallenamento che il punteggio di intelligenza. Se questa variabile non √® controllata, l‚Äôestimando empirico potrebbe sovrastimare o sottostimare l‚Äôeffetto dell‚Äôallenamento.\nAssunzione di Non-Interferenza (Stable Unit Treatment Value Assumption, SUTVA): Dobbiamo assumere che la partecipazione di un individuo all‚Äôallenamento non influisca sui punteggi di intelligenza di altri individui. Questa assunzione potrebbe essere violata, ad esempio, se i partecipanti condividono tecniche apprese con amici che non hanno partecipato.\n\nUtilizzo dei DAG per la Chiarificazione:\n\nUn DAG pu√≤ aiutare a visualizzare queste assunzioni mostrando le relazioni tra le variabili. In un DAG ben costruito, l‚Äôallenamento cognitivo influenzerebbe direttamente il punteggio di intelligenza, mentre altre variabili come l‚Äôeducazione o la motivazione sarebbero rappresentate come confondenti da controllare. Se il DAG indica che ci sono variabili confondenti che non possiamo osservare o misurare, dovremo usare metodi statistici specifici, come i modelli di equazioni strutturali o l‚Äôuso di variabili strumentali, per isolare l‚Äôeffetto dell‚Äôallenamento cognitivo.\n\n\nIn sintesi, collegare correttamente l‚Äôestimando teorico a uno empirico √® un passo cruciale per garantire la validit√† delle inferenze causali in uno studio. Utilizzando l‚Äôesempio relativo all‚Äôeffetto dell‚Äôallenamento cognitivo sull‚Äôintelligenza, possiamo vedere come le assunzioni sostanziali e gli strumenti come i DAG siano essenziali per identificare correttamente le relazioni causali e assicurare che i risultati siano interpretabili in modo affidabile.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Estimandi teorici e estimandi empirici üî∏</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#dedurre-lestimando-empirico-dai-dati-osservati",
    "href": "chapters/eda/10_estimand.html#dedurre-lestimando-empirico-dai-dati-osservati",
    "title": "22¬† Estimandi teorici e estimandi empirici üî∏",
    "section": "22.6 Dedurre l‚ÄôEstimando Empirico dai Dati Osservati",
    "text": "22.6 Dedurre l‚ÄôEstimando Empirico dai Dati Osservati\nDopo aver chiaramente definito l‚Äôestimando teorico e stabilito il collegamento con l‚Äôestimando empirico attraverso l‚Äôidentificazione, il passo successivo √® utilizzare tecniche statistiche per ottenere stime valide dai dati raccolti.\nRiprendiamo l‚Äôesempio psicologico sull‚Äôeffetto dell‚Äôallenamento cognitivo sui punteggi di intelligenza per illustrare come l‚Äôapproccio bayesiano pu√≤ essere utilizzato per stimare l‚Äôestimando empirico:\n\nDefinizione dell‚ÄôEstimando Empirico:\n\nL‚Äôestimando empirico in questo contesto √® la differenza media nei punteggi di intelligenza tra il gruppo di individui che ha partecipato all‚Äôallenamento cognitivo e il gruppo che non ha partecipato.\n\nStrategie di Stima Appropriate:\n\nRegressione Lineare: Se ipotizziamo che i punteggi di intelligenza dipendano linearmente dalla partecipazione all‚Äôallenamento cognitivo e da altre variabili confondenti controllate, potremmo utilizzare una regressione lineare per stimare l‚Äôeffetto dell‚Äôallenamento. In questa regressione, la partecipazione all‚Äôallenamento sarebbe una variabile indipendente, e i punteggi di intelligenza la variabile dipendente.\nMatching: Se i dati disponibili includono molte variabili confondenti misurate, potremmo utilizzare una tecnica di matching per creare coppie di individui simili (matchati) tra i gruppi di trattamento e controllo, basati su queste variabili. Questo metodo aiuta a bilanciare le differenze tra i gruppi che potrebbero influenzare i risultati, cercando di rendere le stime dell‚Äôeffetto pi√π affidabili.\nPropensity Score Matching: Invece di confrontare direttamente individui basandosi su caratteristiche osservabili, possiamo calcolare un punteggio di propensione per ciascun individuo, che rappresenta la probabilit√† di partecipare all‚Äôallenamento in base alle covariate osservate. Gli individui con punteggi di propensione simili vengono quindi confrontati, aiutando a controllare per le variabili confondenti.\nModelli di Equazioni Strutturali (SEM): Se ci sono molteplici relazioni tra variabili latenti e osservate, un modello di equazioni strutturali pu√≤ essere utilizzato per stimare simultaneamente questi effetti complessi e isolare l‚Äôeffetto diretto dell‚Äôallenamento cognitivo sui punteggi di intelligenza.\nRandomizzazione: In un disegno sperimentale ideale, l‚Äôassegnazione casuale dell‚Äôallenamento cognitivo elimina l‚Äôinfluenza delle variabili confondenti, permettendo una stima non distorta dell‚Äôeffetto causale. Se i dati derivano da un esperimento randomizzato, potremmo semplicemente confrontare le medie dei due gruppi.\n\nInterpreting the Results:\n\nStime Non Distorte: Utilizzando la strategia di stima appropriata, possiamo ottenere una stima non distorta dell‚Äôeffetto dell‚Äôallenamento cognitivo sui punteggi di intelligenza. Ad esempio, se utilizziamo una regressione lineare e controlliamo correttamente per tutte le variabili confondenti, l‚Äôeffetto stimato rappresenter√† l‚Äôeffetto causale dell‚Äôallenamento.\n\n\nLa fase di stima √® cruciale per trasformare i dati osservati in stime valide dell‚Äôestimando empirico. Nel contesto psicologico dell‚Äôallenamento cognitivo e dell‚Äôintelligenza, la scelta della strategia di stima appropriata dipende dalle assunzioni fatte sulla causalit√† e dalla natura dei dati disponibili. Utilizzando tecniche come la regressione, il matching, o i modelli di equazioni strutturali, i ricercatori possono ottenere stime precise e affidabili, garantendo che le conclusioni tratte siano valide e scientificamente robuste.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Estimandi teorici e estimandi empirici üî∏</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#implicazioni-per-la-ricerca",
    "href": "chapters/eda/10_estimand.html#implicazioni-per-la-ricerca",
    "title": "22¬† Estimandi teorici e estimandi empirici üî∏",
    "section": "22.7 Implicazioni per la Ricerca",
    "text": "22.7 Implicazioni per la Ricerca\nLundberg et al. (2021) sottolineano l‚Äôimportanza di una chiara comunicazione e dell‚Äôuso del framework presentato per migliorare la pratica della ricerca quantitativa.\n\n22.7.1 Importanza della Trasparenza e della Chiarezza nella Ricerca\nGli autori sottolineano che per garantire la validit√† e la replicabilit√† dei risultati di ricerca, √® fondamentale che i ricercatori siano trasparenti e chiari su tutte le fasi del loro lavoro. Questo significa esplicitare le assunzioni fatte, il modo in cui l‚Äôestimando teorico √® stato tradotto in un estimando empirico, e come i dati sono stati analizzati.\nPer esempio, in uno studio sull‚Äôeffetto di una terapia cognitivo-comportamentale (CBT) sui livelli di ansia, √® essenziale che i ricercatori definiscano chiaramente l‚Äôestimando teorico, ad esempio, ‚Äúl‚Äôeffetto medio della CBT sulla riduzione dell‚Äôansia nella popolazione target di adulti con disturbo d‚Äôansia generalizzato‚Äù. Devono poi descrivere come questo estimando √® stato misurato empiricamente, ad esempio, utilizzando questionari standardizzati per l‚Äôansia prima e dopo l‚Äôintervento. Infine, devono spiegare le assunzioni fatte e le tecniche utilizzate per l‚Äôanalisi dei dati, come un modello bayesiano per gestire la variabilit√† individuale nella risposta alla terapia.\n\n\n22.7.2 Benefici dell‚ÄôUtilizzo di Estimandi Chiaramente Definiti\nL‚Äôarticolo discute come l‚Äôuso di estimandi chiaramente definiti pu√≤ migliorare la comprensione dei risultati e facilitare il confronto tra studi diversi. Quando i ricercatori definiscono in modo preciso ci√≤ che stanno stimando, diventa pi√π facile per altri replicare lo studio, confrontare risultati e costruire un corpus di conoscenza cumulativo.\nPer esempio, consideriamo due studi sull‚Äôefficacia di diversi tipi di training di memoria per migliorare le funzioni cognitive negli anziani. Se entrambi gli studi definiscono chiaramente il loro estimando teorico (ad esempio, ‚Äúl‚Äôeffetto del training di memoria verbale sul punteggio del test di memoria a lungo termine‚Äù) e empirico (ad esempio, ‚Äúla differenza media nei punteggi del test di memoria tra il gruppo che ha ricevuto il training e un gruppo di controllo‚Äù), sar√† pi√π semplice confrontare i risultati e capire quale tipo di training √® pi√π efficace.\n\n\n22.7.3 Adattabilit√† e Flessibilit√† del Framework\nIl framework proposto dagli autori √® adattabile a diversi contesti di ricerca, permettendo ai ricercatori di applicare questi principi in una variet√† di studi quantitativi, indipendentemente dal dominio specifico.\nPer esempio, in uno studio che esplora l‚Äôeffetto della privazione del sonno sulla capacit√† di attenzione nei bambini, il framework potrebbe essere utilizzato per definire l‚Äôestimando teorico come ‚Äúl‚Äôeffetto della privazione di 8 ore di sonno sulla capacit√† di mantenere l‚Äôattenzione in attivit√† ripetitive‚Äù, e l‚Äôestimando empirico potrebbe essere ‚Äúla differenza media nei punteggi di attenzione tra bambini che hanno dormito 8 ore e quelli che non hanno dormito‚Äù. Questo approccio garantisce che le conclusioni siano fondate su basi metodologiche solide e che altri ricercatori possano replicare lo studio per verificare i risultati.\n\n\n22.7.4 Implicazioni per la Ricerca Futura\nL‚Äôadozione del framework proposto da Lundberg et al. (2021) per la definizione degli estimandi teorici ed empirici, la chiara identificazione delle assunzioni e l‚Äôutilizzo di metodi di stima appropriati pu√≤ migliorare la qualit√† e l‚Äôaffidabilit√† della ricerca quantitativa nella psicologia e nelle scienze sociali. Questo approccio promuove una pratica di ricerca pi√π rigorosa e trasparente.\nSe la comunit√† psicologica integrasse questo framework, studi sugli interventi psicologici, come quelli sulla terapia cognitivo-comportamentale (CBT) discusso nell‚Äôesempio sopra, potrebbero diventare pi√π comparabili e replicabili. Ci√≤ migliorerebbe la nostra comprensione dell‚Äôefficacia e dei limiti di tali interventi. Ad esempio, definendo chiaramente cosa si intende per ‚Äúefficacia‚Äù della CBT (come la riduzione del punteggio su una scala di ansia standardizzata) e utilizzando metodi bayesiani per incorporare dati preesistenti e nuove osservazioni, √® possibile ottenere stime pi√π robuste e interpretabili. Queste stime rifletterebbero meglio l‚Äôefficacia reale della terapia nella pratica clinica.\nLe proposte di Lundberg et al. (2021) sono in linea con le raccomandazioni di altri studiosi. Andrew Gelman, ad esempio, sottolinea spesso l‚Äôimportanza di definire con precisione cosa si sta cercando di stimare in un‚Äôanalisi statistica. Gelman sostiene che una definizione vaga o mal definita dell‚Äôestimando teorico pu√≤ portare a interpretazioni errate e conclusioni fuorvianti. La chiara definizione dell‚Äôestimando teorico, come evidenziato nell‚Äôarticolo di Lundberg et al., √® cruciale per determinare se uno studio √® descrittivo, predittivo o causale, e per comprendere la natura dell‚Äôinferenza da trarre dai dati (Gelman & Imbens, 2013).\nSia McElreath (2020), nel suo testo ‚ÄúStatistical Rethinking,‚Äù sia Andrew Gelman, enfatizzano l‚Äôimportanza dell‚Äôutilizzo dei Grafici Aciclici Diretti (DAG) per rappresentare visivamente le assunzioni causali e le relazioni tra variabili in un modello statistico. Questo tipo di approccio aiuta i ricercatori a identificare variabili confondenti e a chiarire le relazioni causali, migliorando cos√¨ la validit√† delle inferenze.\nGelman discute anche frequentemente l‚Äôimportanza della trasparenza nella comunicazione dei risultati di ricerca, un principio centrale anche nell‚Äôarticolo di Lundberg et al.¬†Egli insiste sul fatto che i ricercatori dovrebbero essere espliciti riguardo alle assunzioni fatte, ai metodi utilizzati e alle limitazioni dei loro studi (Gelman et al., 1995).\nIn sintesi, sia Lundberg et al.¬†che altri ricercatori evidenziano l‚Äôimportanza di una chiara definizione degli estimandi, dell‚Äôuso dei DAG per rappresentare le assunzioni causali e della scelta di strategie di stima appropriate. L‚Äôapproccio bayesiano, in particolare, offre un metodo potente e flessibile per gestire l‚Äôincertezza e aggiornare le inferenze alla luce di nuove evidenze. Adottando queste pratiche, i ricercatori nelle scienze sociali e nella psicologia possono migliorare la validit√†, la replicabilit√† e la trasparenza delle loro ricerche, contribuendo a una conoscenza scientifica pi√π solida e affidabile.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Estimandi teorici e estimandi empirici üî∏</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#riflessioni-conclusive",
    "href": "chapters/eda/10_estimand.html#riflessioni-conclusive",
    "title": "22¬† Estimandi teorici e estimandi empirici üî∏",
    "section": "22.8 Riflessioni Conclusive",
    "text": "22.8 Riflessioni Conclusive\nIn questo capitolo abbiamo esaminato l‚Äôimportanza della definizione dell‚Äôestimando in uno studio quantitativo, come evidenziato nell‚Äôarticolo di Lundberg et al. (2021). Il concetto centrale √® la distinzione tra estimando teorico ed estimando empirico e il loro collegamento, che facilita l‚Äôinterpretazione dei risultati e rende l‚Äôinferenza statistica pi√π rigorosa.\nL‚Äôarticolo propone un framework strutturato in tre fasi principali:\n\nDefinire un estimando teorico collegato alla teoria sottostante.\nTradurre questo estimando in un estimando empirico, basato su dati osservabili e assunzioni di identificazione.\nScegliere le strategie di stima adeguate per ottenere stime affidabili.\n\nL‚Äôadozione di questo approccio consente di migliorare la chiarezza e la trasparenza nella ricerca, rendendo pi√π facili il confronto tra studi diversi e la replicabilit√† dei risultati. La corretta definizione dell‚Äôestimando guida l‚Äôintero processo di ricerca, dalla progettazione dello studio alla scelta delle tecniche di stima e all‚Äôinterpretazione dei risultati, garantendo che la teoria e le evidenze empiriche siano strettamente collegate.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Estimandi teorici e estimandi empirici üî∏</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#bibliografia",
    "href": "chapters/eda/10_estimand.html#bibliografia",
    "title": "22¬† Estimandi teorici e estimandi empirici üî∏",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., Carlin, J. B., Stern, H. S., & Rubin, D. B. (1995). Bayesian data analysis. Chapman; Hall/CRC.\n\n\nGelman, A., & Imbens, G. (2013). Why ask why? Forward causal inference and reverse causal questions. National Bureau of Economic Research.\n\n\nLundberg, I., Johnson, R., & Stewart, B. M. (2021). What is your estimand? Defining the target quantity connects statistical evidence to theory. American Sociological Review, 86(3), 532‚Äì565.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Estimandi teorici e estimandi empirici üî∏</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_outlier.html",
    "href": "chapters/eda/11_outlier.html",
    "title": "23¬† Outlier",
    "section": "",
    "text": "23.1 Introduzione\nI dati raccolti nella vita reale spesso contengono osservazioni che, se confrontate con la maggior parte della popolazione, risultano ‚Äúanomale‚Äù o ‚Äúestreme‚Äù. Queste osservazioni, comunemente note come outlier, possono avere cause diverse: ad esempio, potrebbero provenire da un processo generativo differente, oppure essere semplicemente casi estremi ma comunque possibili. Definire i confini tra ci√≤ che √® ‚Äúnormale‚Äù e ci√≤ che √® ‚Äúanormale‚Äù non √® semplice.\nUna gestione non adeguata degli outlier pu√≤ influenzare considerevolmente le stime statistiche, introducendo bias negli effetti misurati e riducendo la capacit√† predittiva dei modelli. √à quindi importante affrontare il problema degli outlier con criteri chiari e strategie riproducibili. Tuttavia, nonostante siano disponibili linee guida consolidate, molti ricercatori non trattano gli outlier in modo coerente, o utilizzano approcci non appropriati (Simmons et al., 2011).\nUno dei motivi potrebbe essere la scarsa consapevolezza delle raccomandazioni esistenti o la difficolt√† ad implementarle con il proprio software di analisi. In questo capitolo mostreremo come seguire le buone pratiche correnti per la rilevazione automatica e riproducibile degli outlier (Statistical Outlier Detection, SOD) in R utilizzando il pacchetto {performance} (L√ºdecke et al.¬†2021).\nIl materiale di questo capitolo riassume l‚Äôarticolo di Th√©riault et al. (2024).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_outlier.html#identificare-gli-outlier",
    "href": "chapters/eda/11_outlier.html#identificare-gli-outlier",
    "title": "23¬† Outlier",
    "section": "23.2 Identificare gli Outlier",
    "text": "23.2 Identificare gli Outlier\nMolti ricercatori cercano di identificare gli outlier utilizzando metodi basati sulla media (ad esempio, z-score tradizionali). Tuttavia, questi metodi non sono robusti, poich√© sia la media sia la deviazione standard sono sensibili agli stessi outlier e presuppongono una distribuzione normale. Le linee guida attuali raccomandano invece metodi robusti, come quelli che si basano sulla mediana anzich√© sulla media (Leys et al., 2019).\nLa scelta del metodo di rilevazione outlier dipende per√≤ da vari fattori. In alcuni casi potrebbe bastare un‚Äôispezione visiva, ma spesso si preferiscono soluzioni algoritmiche. Inoltre, il metodo da utilizzare pu√≤ variare in base al tipo di test statistico o al modello di interesse. Ad esempio, nei modelli di regressione ha senso ricercare outlier che non si adattano bene al modello (outlier ‚Äúmodel-based‚Äù), mentre altre volte si considera la distanza di una singola osservazione dal ‚Äúcentro‚Äù della distribuzione (outlier ‚Äúdistribution-based‚Äù). Queste strategie possono essere univariate (un‚Äôunica variabile) o multivariate (pi√π variabili contemporaneamente).\nIn assenza di metodi ad hoc per modelli complessi (ad es. SEM), pu√≤ essere utile cercare outlier multivariati. Per test semplici (inferenze su una media, o sul confronto tra medie, o sulle correlazioni), possono essere sufficienti metodi univariati, pur essendo meno flessibili e talvolta pi√π inclini a falsi positivi.\n√à importante ricordare che qualsiasi scelta resta soggettiva e dev‚Äôessere documentata in modo trasparente e riproducibile (Leys et al., 2019). Idealmente, le decisioni andrebbero prese prima della raccolta dei dati (ad esempio in una preregistrazione) e poi riportate chiaramente nell‚Äôarticolo, menzionando ogni eventuale deviazione dal piano originale.\nNelle sezioni successive illustreremo vari metodi e forniremo esempi di codice R per implementarli.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_outlier.html#outlier-univariati",
    "href": "chapters/eda/11_outlier.html#outlier-univariati",
    "title": "23¬† Outlier",
    "section": "23.3 Outlier Univariati",
    "text": "23.3 Outlier Univariati\nUn approccio comune √® individuare outlier in base alla distanza dal ‚Äúcentro‚Äù della distribuzione di una singola variabile. Il metodo dei z-score tradizionali, basati sulla media, non √® robusto. Si raccomanda invece di usare la mediana e la Median Absolute Deviation (MAD) (Leys et al., 2019).\nLa funzione check_outliers() del pacchetto {performance}, con method = \"zscore_robust\", consente di individuare outlier secondo questo criterio. Ad esempio, il threshold predefinito √® pari a ¬±3.29 MAD, ma pu√≤ essere modificato.\nDi seguito un esempio con il dataset mtcars, disponibile in R. Prima creiamo degli outlier artificiali, poi utilizziamo check_outliers().\n\nhead(mtcars)\n#&gt;                    mpg cyl disp  hp drat   wt qsec vs am gear carb\n#&gt; Mazda RX4         21.0   6  160 110 3.90 2.62 16.5  0  1    4    4\n#&gt; Mazda RX4 Wag     21.0   6  160 110 3.90 2.88 17.0  0  1    4    4\n#&gt; Datsun 710        22.8   4  108  93 3.85 2.32 18.6  1  1    4    1\n#&gt; Hornet 4 Drive    21.4   6  258 110 3.08 3.21 19.4  1  0    3    1\n#&gt; Hornet Sportabout 18.7   8  360 175 3.15 3.44 17.0  0  0    3    2\n#&gt; Valiant           18.1   6  225 105 2.76 3.46 20.2  1  0    3    1\n\n\n# Create some artificial outliers and an ID column\ndata &lt;- rbind(mtcars[1:4], 42, 55)\ndata &lt;- cbind(car = row.names(data), data)\n\noutliers &lt;- check_outliers(data, method = \"zscore_robust\", ID = \"car\")\noutliers\n#&gt; 2 outliers detected: cases 33, 34.\n#&gt; - Based on the following method and threshold: zscore_robust\n#&gt;   (3.291).\n#&gt; - For variables: mpg, cyl, disp, hp.\n#&gt; \n#&gt; -----------------------------------------------------------------------------\n#&gt;  \n#&gt; The following observations were considered outliers for two or more\n#&gt;   variables by at least one of the selected methods:\n#&gt; \n#&gt;   Row car n_Zscore_robust\n#&gt; 1  33  33               2\n#&gt; 2  34  34               2\n#&gt; \n#&gt; -----------------------------------------------------------------------------\n#&gt; Outliers per variable (zscore_robust): \n#&gt; \n#&gt; $mpg\n#&gt;    Row car Distance_Zscore_robust\n#&gt; 33  33  33                   3.71\n#&gt; 34  34  34                   5.85\n#&gt; \n#&gt; $cyl\n#&gt;    Row car Distance_Zscore_robust\n#&gt; 33  33  33                   12.1\n#&gt; 34  34  34                   16.5\n\nQuesti due outlier aggiunti artificialmente vengono rilevati correttamente. Per escluderli dal dataset principale:\n\nwhich(outliers) \n#&gt; [1] 33 34\n# Restituisce i numeri di riga degli outlier\n\n\ndata_clean &lt;- data[-which(outliers), ]\n\n√à anche possibile visualizzare gli outlier graficamente:\n\nplot(outliers)\n\n\n\n\n\n\n\n\nOltre al metodo MAD, check_outliers() supporta anche altri approcci univariati (basati su IQR, intervalli a densit√† pi√π alta, ecc.).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_outlier.html#outlier-multivariati",
    "href": "chapters/eda/11_outlier.html#outlier-multivariati",
    "title": "23¬† Outlier",
    "section": "23.4 Outlier Multivariati",
    "text": "23.4 Outlier Multivariati\nQuando si analizzano pi√π variabili contemporaneamente (ad esempio altezza e peso di un gruppo di persone), pu√≤ risultare complesso stabilire quali osservazioni siano davvero ‚Äúfuori dal comune‚Äù rispetto alla maggioranza. In questo contesto, la distanza di Mahalanobis offre un modo per individuare outlier multivariati, cio√® osservazioni che si discostano notevolmente dal ‚Äúcentro‚Äù dei dati considerati nel loro insieme, anzich√© analizzare ogni variabile separatamente.\nPer comprendere intuitivamente la distanza di Mahalanobis, immaginate di avere una nube di punti che rappresentano individui, ciascuno con i propri valori di altezza e peso. Il ‚Äúcentro‚Äù di questa nube √® un punto ideale che rappresenta una sorta di media multivariata (tenendo conto sia dell‚Äôaltezza sia del peso). La distanza di Mahalanobis misura quanto ogni singolo individuo si allontana da questo centro, considerando la variabilit√† congiunta delle variabili (ad esempio, la correlazione tra altezza e peso). Se un individuo presenta caratteristiche molto diverse rispetto alla maggioranza, la sua distanza di Mahalanobis sar√† elevata, segnalando un potenziale outlier.\n\n\n\n\n\n\nFigura¬†23.1\n\n\n\nTuttavia, la versione classica di questa misura non √® particolarmente robusta: la presenza stessa di outlier pu√≤ distorcere il calcolo del ‚Äúcentro‚Äù e della variabilit√† complessiva, rendendo meno affidabile l‚Äôindividuazione di altri valori anomali. Per questo motivo, si preferisce utilizzare una variante pi√π resistente, la Minimum Covariance Determinant (MCD), che diminuisce l‚Äôinfluenza degli outlier stessi nel processo di identificazione.\nAll‚Äôinterno del pacchetto {performance} in R, √® possibile applicare questa variante robusta utilizzando la funzione check_outliers() con l‚Äôargomento method = \"mcd\". In questo modo, √® possibile individuare gli outlier multivariati in maniera pi√π solida e coerente, anche quando si lavora con dati fortemente influenzati da valori estremi.\n\noutliers &lt;- performance::check_outliers(data, method = \"mcd\", verbose = FALSE)\noutliers\n#&gt; 2 outliers detected: cases 33, 34.\n#&gt; - Based on the following method and threshold: mcd (20).\n#&gt; - For variables: mpg, cyl, disp, hp.\n\nSi possono poi visualizzare questi outlier:\n\nplot(outliers)\n\n\n\n\n\n\n\n\nSono disponibili anche altre varianti multivariate documentate nella help page della funzione.\n\n23.4.1 Outlier Basati sul Modello (Model-Based)\nQuando si impiega un modello di regressione, lo scopo principale √® capire la relazione tra una o pi√π variabili predittive (ad esempio, il numero di ore di studio) e una variabile di esito (ad esempio, il punteggio a un test). In questi contesti, pu√≤ capitare che alcuni punti dati, pur essendo veri e propri dati raccolti, esercitino un‚Äôinfluenza eccessiva sulle stime dei parametri del modello, alterando in modo significativo i risultati dell‚Äôanalisi. Queste osservazioni vengono definite outlier ‚Äúmodel-based‚Äù proprio perch√© il criterio per individuarle non √® un semplice confronto con la media o la mediana, bens√¨ con le previsioni del modello stesso.\nIn pratica, per ciascuna osservazione si verifica quanto i risultati previsti dal modello (le stime dei valori di esito) cambierebbero se quella specifica osservazione venisse rimossa. Se togliendo uno specifico caso il modello cambia notevolmente, allora quell‚Äôosservazione √® considerata un outlier model-based. L‚Äôidea √® che non ci limitiamo a guardare quanto un singolo valore sia ‚Äúlontano‚Äù dagli altri in termini di distribuzione, ma verifichiamo quanto quel valore ‚Äútira‚Äù i risultati del modello nella sua direzione.\nIl pacchetto {performance} in R fornisce due metodi per individuare questo tipo di outlier. Per i modelli di regressione classici (ad esempio quelli stimati con la funzione lm() in R), √® possibile utilizzare Cook‚Äôs distance (method = \"cook\"). Cook‚Äôs distance misura quanto i risultati del modello si modificherebbero rimuovendo singolarmente ogni osservazione, identificando cos√¨ i casi che hanno un effetto sproporzionato sulle stime.\nPer i modelli bayesiani, che utilizzano un approccio probabilistico diverso dal classico, √® disponibile invece una metrica chiamata Pareto (method = \"pareto\"). Questo indicatore √® ottimizzato per valutare la sensibilit√† dei modelli bayesiani ad alcune osservazioni estreme, segnalando quelle che hanno un impatto potenzialmente troppo forte sulle inferenze.\nIn sintesi, utilizzare un approccio model-based significa considerare gli outlier non soltanto come valori numerici insoliti, ma come casi che, modificando eccessivamente la forma o le conclusioni del modello, ne compromettono la stabilit√† e l‚Äôaffidabilit√†. L‚Äôapproccio offerto da {performance} permette cos√¨ di individuare queste osservazioni ‚Äúcritiche‚Äù in modo pi√π mirato e consapevole.\n\nmodel &lt;- lm(disp ~ mpg * hp, data = data)\noutliers &lt;- check_outliers(model, method = \"cook\")\noutliers\n#&gt; 2 outliers detected: cases 31, 34.\n#&gt; - Based on the following method and threshold: cook (0.806).\n#&gt; - For variable: (Whole model).\n\nIn questo modo si individuano outlier che hanno un‚Äôelevata influenza sul modello.\n\n\n\n\n\n\nTabella di Riferimento\n\n\n\n\n\n\n\n\n\n\n\n\nTipo di Analisi\nMetodo Outlier\nThreshold Suggerito\nCodice\n\n\n\n\nRegressione supportata (lm)\nModel-based (Cook)\nCook: qf(0.5, ...)\ncheck_outliers(model, method=\"cook\")\n\n\nSEM o modello non supportato\nMultivariato (MCD)\nMCD: qchisq(1-0.001, df)\ncheck_outliers(data, method=\"mcd\")\n\n\nTest semplici (t, correlazioni)\nUnivariato (robust z)\n¬±~3.29 (MAD)\ncheck_outliers(data, method=\"zscore_robust\")\n\n\n\n\n\n\n\n23.4.2 Cook‚Äôs Distance vs.¬†MCD\nLeys et al. (2018) suggeriscono di preferire la MCD alla Cook‚Äôs distance in presenza di molti outlier, poich√© quest‚Äôultima valuta l‚Äôimpatto della rimozione di un‚Äôosservazione alla volta, rischiando cos√¨ di lasciare il modello ancora ‚Äúcontaminato‚Äù da altre osservazioni anomale. D‚Äôaltro canto, i metodi basati sulla distribuzione possono risultare eccessivamente rigorosi, segnalando come outlier anche casi estremi ma perfettamente in linea con il modello teorico. Quando disponibili, i metodi model-based forniscono dunque una prospettiva pi√π informativa.\n\n\n23.4.3 Approccio Composito (Composite Outlier Score)\nIl pacchetto {performance} permette di combinare diversi metodi per ottenere un punteggio composito, aumentando l‚Äôaffidabilit√† della classificazione degli outlier. Ad esempio:\n\noutliers &lt;- check_outliers(\n  model, \n  method = c(\"zscore_robust\", \"mcd\", \"cook\"), \n  verbose = FALSE\n)\nwhich(outliers)\n#&gt; [1] 31 33 34\n\nSi ottengono cos√¨ osservazioni ritenute outlier da almeno la met√† dei metodi utilizzati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_outlier.html#gestione-degli-outlier",
    "href": "chapters/eda/11_outlier.html#gestione-degli-outlier",
    "title": "23¬† Outlier",
    "section": "23.5 Gestione degli Outlier",
    "text": "23.5 Gestione degli Outlier\nDopo l‚Äôidentificazione, come gestire gli outlier? Leys et al. (2019) distinguono tra outlier dovuti a errori (da correggere o rimuovere), outlier interessanti (potenzialmente rilevanti dal punto di vista teorico) e outlier casuali (da mantenere se compatibili con la distribuzione di interesse).\nSe gli outlier appartengono realmente alla distribuzione di interesse, vanno mantenuti. Se per√≤ provengono da un‚Äôaltra distribuzione o compromettono la robustezza dei risultati, potrebbe essere giustificata la loro rimozione. In alcuni casi, si pu√≤ utilizzare la ‚Äúwinsorizzazione‚Äù, cio√® ridurre i valori estremi entro soglie stabilite, per conservare potenza statistica.\nNel pacchetto easystats, la funzione winsorize() di {datawizard} semplifica questo compito:\n\nwinsorized_data &lt;- winsorize(\n  data, \n  method = \"zscore\", \n  robust = TRUE, \n  threshold = 3\n)",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_outlier.html#importanza-della-trasparenza",
    "href": "chapters/eda/11_outlier.html#importanza-della-trasparenza",
    "title": "23¬† Outlier",
    "section": "23.6 Importanza della Trasparenza",
    "text": "23.6 Importanza della Trasparenza\nQualunque decisione va documentata chiaramente: quanti outlier sono stati individuati, con quale metodo, a quale threshold, come sono stati gestiti, e preferibilmente con il codice R utilizzato. La preregistrazione e la condivisione dei dati e del codice (ad es. su OSF) sono pratiche consigliate per garantire riproducibilit√† e trasparenza.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_outlier.html#riflessioni-conclusive",
    "href": "chapters/eda/11_outlier.html#riflessioni-conclusive",
    "title": "23¬† Outlier",
    "section": "23.7 Riflessioni Conclusive",
    "text": "23.7 Riflessioni Conclusive\nAbbiamo mostrato come identificare gli outlier in modo coerente e trasparente utilizzando la funzione check_outliers() del pacchetto {performance}, allineandoci alle buone pratiche correnti. Tuttavia, la buona pratica non si limita alla scelta degli algoritmi: √® fondamentale anche preregistrare le decisioni, essere coerenti, trasparenti e fornire giustificazioni. Speriamo che queste linee guida e gli esempi di codice facilitino l‚Äôimplementazione di procedure corrette e riproducibili per il trattamento degli outlier.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_outlier.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/11_outlier.html#informazioni-sullambiente-di-sviluppo",
    "title": "23¬† Outlier",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: US/Pacific\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] datawizard_1.0.0   performance_0.12.4 ggokabeito_0.1.0  \n#&gt;  [4] see_0.9.0          gridExtra_2.3      patchwork_1.3.0   \n#&gt;  [7] bayesplot_1.11.1   psych_2.4.12       scales_1.3.0      \n#&gt; [10] markdown_1.13      knitr_1.49         lubridate_1.9.4   \n#&gt; [13] forcats_1.0.0      stringr_1.5.1      dplyr_1.1.4       \n#&gt; [16] purrr_1.0.2        readr_2.1.5        tidyr_1.3.1       \n#&gt; [19] tibble_3.2.1       ggplot2_3.5.1      tidyverse_2.0.0   \n#&gt; [22] rio_1.2.3          here_1.0.1        \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] viridisLite_0.4.2 mnormt_2.1.1      cli_3.6.3         rlang_1.1.4      \n#&gt; [17] munsell_0.5.1     withr_3.0.2       tools_4.4.2       parallel_4.4.2   \n#&gt; [21] tzdb_0.4.0        colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5      \n#&gt; [25] R6_2.5.1          lifecycle_1.0.4   htmlwidgets_1.6.4 MASS_7.3-64      \n#&gt; [29] insight_1.0.1     pkgconfig_2.0.3   pillar_1.10.1     gtable_0.3.6     \n#&gt; [33] glue_1.8.0        xfun_0.50         tidyselect_1.2.1  farver_2.1.2     \n#&gt; [37] htmltools_0.5.8.1 nlme_3.1-166      labeling_0.4.3    rmarkdown_2.29   \n#&gt; [41] compiler_4.4.2",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_outlier.html#bibliografia",
    "href": "chapters/eda/11_outlier.html#bibliografia",
    "title": "23¬† Outlier",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nLeys, C., Delacre, M., Mora, Y. L., Lakens, D., & Ley, C. (2019). How to classify, detect, and manage univariate and multivariate outliers, with emphasis on pre-registration. International Review of Social Psychology, 32(1).\n\n\nLeys, C., Klein, O., Dominicy, Y., & Ley, C. (2018). Detecting multivariate outliers: Use a robust variant of the Mahalanobis distance. Journal of Experimental Social Psychology, 74, 150‚Äì156.\n\n\nSimmons, J. P., Nelson, L. D., & Simonsohn, U. (2011). False-positive psychology: Undisclosed flexibility in data collection and analysis allows presenting anything as significant. Psychological science, 22(11), 1359‚Äì1366.\n\n\nTh√©riault, R., Ben-Shachar, M. S., Patil, I., L√ºdecke, D., Wiernik, B. M., & Makowski, D. (2024). Check your outliers! An introduction to identifying statistical outliers in R with easystats. Behavior Research Methods, 56(4), 4162‚Äì4172.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/probability/introduction_probability.html",
    "href": "chapters/probability/introduction_probability.html",
    "title": "Probabilit√†",
    "section": "",
    "text": "Questa sezione della dispensa introduce la teoria della probabilit√†, una componente essenziale per la ricerca scientifica. Nell‚Äôambito della scienza, l‚Äôinferenza induttiva √® di fondamentale importanza, e la probabilit√† svolge un ruolo cruciale in questo processo. Sebbene non possiamo ottenere una certezza assoluta riguardo alla veridicit√† di un‚Äôipotesi o teoria, possiamo assegnare loro un grado di certezza probabilistica. L‚Äôapproccio bayesiano utilizza la probabilit√† per quantificare il grado di fiducia che possiamo attribuire a una determinata proposizione.\nL‚Äôinferenza statistica bayesiana mira a quantificare la fiducia nell‚Äôipotesi \\(H\\) dopo aver osservato un dato di evidenza \\(O\\). Per affrontare adeguatamente l‚Äôinferenza statistica bayesiana, √® quindi essenziale avere una solida comprensione della teoria delle probabilit√†, almeno nei suoi concetti fondamentali.\nIn questa sezione esamineremo le definizioni di probabilit√†, la probabilit√† condizionale e il teorema di Bayes. Approfondiremo inoltre le propriet√† delle variabili casuali e le principali distribuzioni di massa e densit√† di probabilit√†. Concluderemo presentando la funzione di verosimiglianza, un concetto fondamentale sia nell‚Äôinferenza bayesiana sia nell‚Äôinferenza frequentista.",
    "crumbs": [
      "Probabilit√†"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html",
    "href": "chapters/probability/01_intro_prob.html",
    "title": "24¬† Interpretazione della probabilit√†",
    "section": "",
    "text": "24.1 Introduzione\nNel corso di questo capitolo, esploreremo varie concezioni della probabilit√†, tra cui la visione classica, frequentista e bayesiana. Inoltre, introdurremo la simulazione con R per una migliore comprensione della legge dei grandi numeri, un concetto fondamentale nell‚Äôambito della probabilit√†. Iniziamo introducendo il concetto di causalit√†.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Interpretazione della probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#il-concetto-di-casualit√†-e-la-teoria-della-probabilit√†",
    "href": "chapters/probability/01_intro_prob.html#il-concetto-di-casualit√†-e-la-teoria-della-probabilit√†",
    "title": "24¬† Interpretazione della probabilit√†",
    "section": "24.2 Il Concetto di Casualit√† e la Teoria della Probabilit√†",
    "text": "24.2 Il Concetto di Casualit√† e la Teoria della Probabilit√†\nDavid Spiegelhalter, in un recente articolo pubblicato su Nature, descrive il concetto di probabilit√† partendo dall‚Äôidea di incertezza:\n\nLife is uncertain. None of us know what is going to happen. We know little of what has happened in the past, or is happening now outside our immediate experience. Uncertainty has been called the ‚Äòconscious awareness of ignorance‚Äô ‚Äî be it of the weather tomorrow, the next Premier League champions, the climate in 2100 or the identity of our ancient ancestors (Spiegelhalter, 2024).\n\nL‚Äôincertezza pu√≤ essere vista come una manifestazione della casualit√†, che rappresenta non solo un fenomeno, ma anche un modello concettuale per affrontare l‚Äôimprevedibilit√† della realt√†. Attraverso il concetto di casualit√†, possiamo gestire e quantificare eventi che, pur essendo imprevedibili singolarmente, seguono schemi regolari e osservabili. Questo rende la casualit√† uno strumento fondamentale per comprendere il mondo e prendere decisioni.\n\nAttempts to put numbers on chance and uncertainty take us into the mathematical realm of probability, which today is used confidently in any number of fields (Spiegelhalter, 2024).\n\nLa teoria della probabilit√† fornisce una risposta matematica all‚Äôincertezza, permettendo di esprimere in termini numerici il grado di possibilit√† associato a un evento. Grazie a questa formalizzazione, possiamo modellare fenomeni complessi e applicare il concetto di probabilit√† in contesti che spaziano dalla ricerca scientifica alla vita quotidiana.\n\n24.2.1 L‚ÄôUrna come Modello della Casualit√†\nUn classico esempio utilizzato per rappresentare la casualit√† √® il modello dell‚Äôurna. Immaginiamo un‚Äôurna contenente palline identiche, ognuna numerata in modo univoco. Se ogni pallina ha la stessa probabilit√† di essere estratta, l‚Äôestrazione √® considerata casuale. Anche se non possiamo prevedere quale pallina verr√† estratta, sappiamo che ogni pallina ha uguali possibilit√† di essere selezionata.\nQuesto modello, per quanto semplice, incarna l‚Äôessenza della casualit√†. La sua semplicit√† consente di estenderne i principi a situazioni pi√π complesse. Ad esempio, il modello dell‚Äôurna pu√≤ essere utilizzato come base concettuale per comprendere processi che vanno ben oltre l‚Äôestrazione di palline, trovando applicazioni in ambiti come la statistica, la scienza e la psicologia.\n\n24.2.1.1 Applicazioni del Modello della Casualit√†\nIndagini statistiche\nIl campionamento casuale nelle ricerche statistiche garantisce un campione rappresentativo di una popolazione pi√π ampia, riducendo il rischio di bias di selezione e migliorando la generalizzabilit√† delle conclusioni.\nSperimentazione scientifica\nLa randomizzazione √® essenziale per controllare le variabili confondenti nelle sperimentazioni. Permette di attribuire le differenze osservate tra i gruppi al trattamento, riducendo l‚Äôeffetto di fattori esterni.\n\nOpen any science journal, for example, and you‚Äôll find papers liberally sprinkled with P values, confidence intervals and possibly Bayesian posterior distributions, all of which are dependent on probability (Spiegelhalter, 2024).\n\nSimulazioni\nIn discipline come fisica e psicologia, i modelli di simulazione basati sulla casualit√† permettono di analizzare sistemi complessi e formulare previsioni, offrendo strumenti indispensabili per la ricerca scientifica.\nNonostante la semplicit√†, il modello dell‚Äôurna costituisce un pilastro per comprendere e applicare il concetto di casualit√† in un‚Äôampia variet√† di contesti.\n\n\n\n24.2.2 Dalla Casualit√† alla Teoria della Probabilit√†\nLa teoria della probabilit√† si sviluppa a partire dal concetto di casualit√†, fornendo strumenti matematici per analizzare e quantificare rigorosamente l‚Äôincertezza. Questo approccio consente di tradurre l‚Äôintuizione in un linguaggio formale, attraverso il quale possiamo:\n\nQuantificare l‚Äôincertezza\nAssegnare un valore numerico agli esiti possibili permette di esprimere in modo preciso la probabilit√† di ciascun evento.\nCombinare informazioni\nCon regole come la somma e il prodotto delle probabilit√†, possiamo calcolare la probabilit√† di eventi complessi derivati da eventi pi√π semplici.\nAggiornare le credenze\nLa teoria della probabilit√†, in particolare nella sua formulazione bayesiana, fornisce metodi per aggiornare razionalmente le stime di probabilit√† alla luce di nuove informazioni.\nPrendere decisioni informate\nValutando rischi e benefici attesi, la probabilit√† guida decisioni ottimali in condizioni di incertezza.\n\nIn sintesi, la casualit√† e la probabilit√† rappresentano strumenti fondamentali per navigare un mondo incerto, fornendo un linguaggio preciso per descriverlo e una struttura rigorosa per ragionare su di esso. Comprendere questi concetti √® essenziale non solo per matematici o statistici, ma per chiunque voglia prendere decisioni consapevoli, sia nella ricerca che nella vita quotidiana.\nNei capitoli seguenti, esploreremo come questi principi si applichino all‚Äôanalisi dei dati, con un focus sull‚Äôapproccio bayesiano. Questo metodo, attraverso un processo iterativo di aggiornamento delle conoscenze, rappresenta una modalit√† intuitiva e potente per affrontare l‚Äôincertezza e migliorare le nostre inferenze alla luce di nuove evidenze.\n\n\n24.2.3 Storia e Definizioni della Probabilit√†\nLa probabilit√† √® un concetto cardine nella matematica e nelle scienze, utilizzato per misurare l‚Äôincertezza e studiare fenomeni aleatori. Nel corso del tempo, la sua definizione si √® evoluta, passando da intuizioni di tipo qualitativo a formulazioni formali e rigorose.\nLa probabilit√† nasce dal bisogno di distinguere gli eventi deterministici, il cui esito √® prevedibile, da quelli casuali, caratterizzati dall‚Äôimprevedibilit√†. Un evento deterministico, almeno in teoria, produce sempre lo stesso risultato nelle stesse condizioni, mentre un evento casuale ha esiti che non possiamo prevedere con certezza. Questa distinzione ha portato alla necessit√† di quantificare l‚Äôincertezza associata agli eventi casuali, utilizzando il concetto di probabilit√†.\n\n\n24.2.4 Fonti dell‚ÄôIncertezza\nL‚Äôincertezza nei fenomeni casuali pu√≤ derivare da due fonti principali:\n\nIncertezza epistemica: Questa forma di incertezza √® legata alla nostra conoscenza limitata. Ad esempio, in un esperimento scientifico complesso, la nostra impossibilit√† di controllare tutte le variabili pu√≤ introdurre incertezza nei risultati.\nIncertezza ontologica: Si riferisce alla casualit√† intrinseca di alcuni fenomeni, come in fisica quantistica, dove l‚Äôindeterminazione sembra essere una caratteristica fondamentale della realt√† stessa. Un esempio intuitivo √® il lancio di un dado: indipendentemente da quanto conosciamo le condizioni, non possiamo prevedere con assoluta precisione il risultato.\n\nIl fisico danese Niels Bohr ha offerto un‚Äôinterpretazione illuminante su questo tema: la fisica, secondo Bohr, non mira a rivelare una verit√† assoluta sulla natura, ma a capire cosa possiamo dire su di essa. Questa visione riconosce che l‚Äôincertezza ‚Äì sia epistemica che ontologica ‚Äì riflette i limiti del nostro linguaggio e delle nostre conoscenze. Questo approccio si allinea bene con l‚Äôinterpretazione soggettiva della probabilit√†, secondo la quale la probabilit√† rappresenta il grado di fiducia che un individuo ha riguardo al verificarsi di un evento, basata sulle informazioni di cui dispone.\n\n\n24.2.5 Assiomatizzazione della Probabilit√†\nNel 1933, il matematico Andrey Kolmogorov forn√¨ una definizione formale della probabilit√†, introducendo un sistema assiomatico che costitu√¨ la base della moderna teoria della probabilit√†. Questa formulazione ha trasformato la probabilit√† in una disciplina matematica rigorosa, offrendo uno strumento essenziale per quantificare l‚Äôincertezza in contesti scientifici. Da semplice metodo per analizzare i giochi d‚Äôazzardo nel XVII secolo, la probabilit√† √® diventata una pietra miliare del ragionamento scientifico, fornendo un linguaggio universale per descrivere e analizzare l‚Äôincertezza in numerosi campi del sapere.\n\n\n24.2.6 La Storia della Probabilit√†\nLa probabilit√† moderna nacque da una domanda posta da Antoine Gombaud (Chevalier de M√©r√©) a Blaise Pascal nel XVII secolo su come dividere equamente le puntate di un gioco d‚Äôazzardo interrotto.\n\n24.2.6.1 Il Problema dei Punti\nIl problema pu√≤ essere riassunto come segue:\n\nImmaginiamo due persone, A e B, che partecipano a un gioco in cui il primo che vince sei round consecutivi ottiene un premio. Dopo sei round, A ha vinto cinque round e B uno. Poich√© il gioco si interrompe prima di assegnare il premio, come dovrebbero dividere il premio in modo equo?\n\nQuesta domanda diede origine a una corrispondenza tra Pascal e Fermat, che svilupparono una soluzione matematica basata sulle probabilit√† di vittoria per ciascun giocatore. Se, per esempio, A aveva una probabilit√† del 97% di vincere, mentre B una del 3%, sembrava equo assegnare il 97% del premio ad A. La loro corrispondenza ispir√≤ l‚Äôopera di Christian Huygens, ‚ÄúDe Ratiociniis in Ludo Aleae‚Äù (1657), che rimase un riferimento in probabilit√† per mezzo secolo.\n\n\n\n24.2.7 Sviluppi Successivi\nNel 1713, Jacob Bernoulli pubblic√≤ postumo ‚ÄúL‚ÄôArte della Congettura‚Äù, introducendo la legge dei grandi numeri e ponendo le basi per l‚Äôapplicazione della probabilit√† al di fuori dei giochi d‚Äôazzardo, ad esempio nello studio della mortalit√† e della giustizia penale.\n\n\n24.2.8 Interpretazione Classica\nLa definizione classica di probabilit√† fu proposta da Pierre-Simon Laplace (1749-1827), che bas√≤ il concetto sul calcolo combinatorio. Secondo Laplace, la probabilit√† di un evento √® data dal rapporto tra i casi favorevoli e il numero totale di casi possibili, assumendo che tutti siano equiprobabili. Ad esempio, la probabilit√† di ottenere un ‚Äú3‚Äù lanciando un dado √® \\(\\frac{1}{6}\\), poich√© solo uno dei sei risultati √® favorevole.\nTuttavia, questa definizione √® limitata, poich√© si basa sull‚Äôassunzione che ogni evento sia equiprobabile, il che non √® sempre vero. Inoltre, √® parzialmente circolare, poich√© presuppone una conoscenza implicita del concetto di probabilit√†.\n\n\n24.2.9 Interpretazione Frequentista\nL‚Äôapproccio frequentista, nato dalla necessit√† di evitare le limitazioni dell‚Äôinterpretazione classica, definisce la probabilit√† come il limite della frequenza relativa con cui un evento si verifica in una serie infinita di prove. Per esempio, la probabilit√† di ottenere ‚Äútesta‚Äù in un lancio di moneta pu√≤ essere stimata come la frequenza relativa di ‚Äútesta‚Äù sul totale dei lanci, quando il numero di lanci tende all‚Äôinfinito. Questa definizione √® utile, ma impraticabile in molte situazioni, poich√© richiede un numero infinito di ripetizioni e assume che gli eventi futuri siano identici a quelli passati.\nLa figura seguente illustra la proporzione di risultati ‚Äútesta‚Äù in una sequenza di lanci di una moneta equa. Si pu√≤ osservare come la frequenza relativa dei risultati ‚Äútesta‚Äù converga progressivamente verso il valore della probabilit√† teorica.\n\n\n\n\n\n\n\n\n\n\n\n24.2.10 La Legge dei Grandi Numeri\nLa simulazione precedente offre una chiara illustrazione della Legge dei Grandi Numeri, un principio fondamentale della probabilit√†. Questo teorema afferma che, con l‚Äôaumentare del numero di esperimenti casuali ripetuti, la stima empirica della probabilit√† di un evento \\(P(Y = y)\\) tende a convergere al valore teorico.\nIn termini semplici, la Legge dei Grandi Numeri garantisce che, al crescere del numero di prove, la media dei risultati osservati si avvicina progressivamente al valore atteso della variabile casuale. Questo significa che, anche se i risultati individuali possono variare in modo casuale, la media dei risultati su un gran numero di esperimenti rifletter√† con sempre maggiore precisione la probabilit√† teorica.\nQuesto principio √® fondamentale perch√© assicura che:\n\nCon un numero sufficiente di prove, le stime empiriche delle probabilit√† siano affidabili.\nI modelli probabilistici possano essere utilizzati per descrivere e prevedere fenomeni reali, nonostante la variabilit√† intrinseca delle osservazioni singole.\n\nFormalmente, se consideriamo una serie di variabili casuali indipendenti \\(X_1, X_2, \\ldots, X_n\\), tutte con la stessa media teorica \\(\\mu\\), la Legge dei Grandi Numeri si esprime come:\n\\[\n\\lim_{{n \\to \\infty}} P\\left(\\left|\\frac{1}{n} \\sum_{i=1}^n X_i - \\mu\\right| &lt; \\epsilon\\right) = 1,\n\\]\ndove \\(\\epsilon\\) √® un numero positivo arbitrariamente piccolo e \\(P(\\cdot)\\) rappresenta la probabilit√†. In altre parole:\n\nMan mano che \\(n\\) (il numero di prove) diventa molto grande, la media campionaria \\(\\frac{1}{n} \\sum_{i=1}^n X_i\\) sar√† sempre pi√π vicina alla media teorica \\(\\mu\\), con una probabilit√† che si avvicina a 1.\n\nQuesto teorema ha implicazioni importanti nella pratica:\n\nPermette di stimare probabilit√† con crescente precisione al crescere delle osservazioni.\nOffre un fondamento teorico per l‚Äôutilizzo di medie campionarie in statistica e in molte applicazioni scientifiche.\n\nIn conclusione, la Legge dei Grandi Numeri √® essenziale per comprendere come, nonostante la variabilit√† casuale nei risultati individuali, la regolarit√† emerge quando si considera un numero sufficientemente grande di osservazioni. Questo principio stabilisce il legame tra la teoria della probabilit√† e le applicazioni pratiche, garantendo che le stime empiriche, nel lungo periodo, riflettano i valori teorici con elevata precisione.\n\n\n24.2.11 Il Problema del Caso Singolo\nNell‚Äôapproccio frequentista alla probabilit√†, basato sull‚Äôidea che la probabilit√† sia definita come la frequenza relativa di un evento osservato su un grande numero di ripetizioni, emerge una limitazione concettuale nel trattare la probabilit√† di eventi singolari e non ripetibili. Secondo questa prospettiva, non √® rigorosamente corretto parlare di probabilit√† associate a eventi unici e irripetibili.\nEsempi di tali eventi includono:\n\nLa probabilit√† che Alcaraz vinca contro Djokovic nella finale di Wimbledon del 2023.\nLa probabilit√† che piova a Firenze il giorno di Ferragosto del 2025.\n\nQuesti scenari, legati a un preciso momento storico e privi di una struttura ripetitiva, non rientrano nella logica frequentista, che richiede la possibilit√† di osservare ripetutamente un evento per determinarne la probabilit√†. Infatti, nel contesto frequentista, una definizione operativa della probabilit√† implica un esperimento ripetibile un numero indefinito di volte in condizioni simili, una situazione non applicabile ai casi singoli.\nTuttavia, nel linguaggio comune, √® frequente usare il termine ‚Äúprobabilit√†‚Äù per riferirsi anche a eventi singolari e irripetibili, come se la probabilit√† fosse una misura intuitiva del nostro grado di fiducia nel verificarsi di un evento. Questo uso non tecnico evidenzia una discrepanza tra il significato formale della probabilit√† nella teoria frequentista e l‚Äôinterpretazione colloquiale del termine.\nIn conclusione, il problema del caso singolo mette in luce i limiti dell‚Äôapproccio frequentista nella descrizione di eventi unici e irripetibili. Sebbene il concetto di probabilit√† sia ampiamente utilizzato per descrivere tali eventi nel linguaggio comune, una trattazione rigorosa richiede approcci alternativi, come l‚Äôapproccio bayesiano, che permette di esprimere la probabilit√† come una misura soggettiva del grado di credenza, superando cos√¨ la necessit√† di ripetizioni sperimentali.\n\n\n24.2.12 Collegamento tra probabilit√† e statistica\nDurante gli anni ‚Äô20 del Novecento, Ronald A. Fisher propose un nuovo framework teorico per l‚Äôinferenza statistica, basato sulla concettualizzazione della frequenza. Fisher introdusse concetti chiave come la massima verosimiglianza, i test di significativit√†, i metodi di campionamento, l‚Äôanalisi della varianza e il disegno sperimentale.\nNegli anni ‚Äô30, Jerzy Neyman ed Egon Pearson fecero ulteriori progressi nel campo con lo sviluppo di una teoria della decisione statistica, basata sul principio della verosimiglianza e sull‚Äôinterpretazione frequentista della probabilit√†. Definirono due tipologie di errori decisionali e utilizzarono il test di significativit√† di Fisher, interpretando i valori-\\(p\\) come indicatori dei tassi di errore a lungo termine.\n\n\n24.2.13 La riscoperta dei metodi Monte Carlo Markov chain\nFisher assunse una prospettiva critica nei confronti della ‚Äúprobabilit√† inversa‚Äù (ossia, i metodi bayesiani), nonostante questa fosse stata la metodologia predominante per l‚Äôinferenza statistica per quasi un secolo e mezzo. Il suo approccio frequentista ebbe un profondo impatto sullo sviluppo della statistica sia teorica che sperimentale, contribuendo a un decremento nell‚Äôutilizzo dell‚Äôinferenza basata sul metodo della probabilit√† inversa, originariamente proposto da Laplace.\nNel 1939, il libro di Harold Jeffreys intitolato ‚ÄúTheory of Probability‚Äù rappresent√≤ una delle prime esposizioni moderne dei metodi bayesiani. Tuttavia, la rinascita del framework bayesiano fu rinviata fino alla scoperta dei metodi Monte Carlo Markov chain alla fine degli anni ‚Äô80. Questi metodi hanno reso fattibile il calcolo di risultati precedentemente non ottenibili, consentendo un rinnovato interesse e sviluppo nei metodi bayesiani. Per una storia dell‚Äôapproccio bayesiano, si veda Bayesian Methods: General Background oppure Philosophy of Statistics.\n\n\n24.2.14 Interpretazione Soggettivista della Probabilit√†\nL‚Äôinterpretazione soggettivista considera la probabilit√† non come una propriet√† intrinseca degli eventi, ma come una misura del grado di credenza personale di un individuo. In questa visione, la probabilit√† riflette il livello di fiducia che una persona attribuisce a un evento, sulla base delle informazioni disponibili.\nUn‚Äôaffermazione provocatoria in questo senso proviene da Bruno de Finetti, uno dei principali fautori di questa prospettiva:\n\n‚ÄúLa probabilit√† non esiste.‚Äù\n\nDe Finetti paragonava l‚Äôidea di una probabilit√† oggettiva a credenze superate come l‚Äô‚ÄúEtere cosmico‚Äù o le ‚ÄúFate e Streghe.‚Äù Per lui, le probabilit√† sono esclusivamente soggettive, rappresentando convinzioni personali che variano in base al contesto informativo. Questa visione, radicale ma influente, ha gettato le basi per lo sviluppo del pensiero probabilistico bayesiano.\nLa rilevanza contemporanea di questa prospettiva √® evidente in un recente articolo pubblicato su Nature, che ribadisce l‚Äôessenza soggettiva della probabilit√†:\n\n[‚Ä¶] any numerical probability, I will argue ‚Äî whether in a scientific paper, as part of weather forecasts, predicting the outcome of a sports competition or quantifying a health risk ‚Äî is not an objective property of the world, but a construction based on personal or collective judgements and (often doubtful) assumptions. Furthermore, in most circumstances, it is not even estimating some underlying ‚Äòtrue‚Äô quantity. Probability, indeed, can only rarely be said to ‚Äòexist‚Äô at all (Spiegelhalter, 2024).\n\nLe basi dell‚Äôinterpretazione soggettivista furono poste da Frank P. Ramsey nel 1926, quando defin√¨ la probabilit√† come grado di credenza individuale (Ramsey, 1926). Sebbene inizialmente marginale, questa concezione ha acquisito un ruolo centrale nel pensiero bayesiano.\nUna rigorosa formalizzazione matematica degli assiomi della probabilit√† soggettiva √® stata proposta da Fishburn (Fishburn, 1986), mentre approfondimenti metodologici e applicativi si trovano nei lavori successivi di Press (Press, 2009).\nQuesta interpretazione sottolinea come la probabilit√† sia una costruzione umana, influenzata da giudizi, ipotesi e informazioni, pi√π che una propriet√† intrinseca della realt√†.\n\n24.2.14.1 Terminologia\nIl termine ‚Äúprobabilit√† soggettiva‚Äù pu√≤ talvolta suggerire una connotazione di imprecisione o mancanza di rigore scientifico. Per evitare tali fraintendimenti:\n\nLindley (2013) ha proposto il termine ‚Äúprobabilit√† personale,‚Äù sottolineando l‚Äôaspetto individuale ma razionale di questa concezione.\nHowson & Urbach (2006) preferiscono ‚Äúprobabilit√† epistemica,‚Äù evidenziando il legame con la conoscenza e l‚Äôincertezza di fronte a informazioni incomplete.\n\nQueste alternative linguistiche, adottate ad esempio da Kaplan (2023), offrono una descrizione pi√π neutra e accessibile per discutere la probabilit√† soggettiva in contesti scientifici.\n\n\n24.2.14.2 Applicazioni\nL‚Äôinterpretazione soggettivista si adatta particolarmente bene a situazioni che sfuggono all‚Äôapproccio frequentista, come l‚Äôanalisi di eventi singoli. Questi eventi non possono essere analizzati in termini di frequenze relative, poich√© sono unici e irripetibili. L‚Äôapproccio soggettivista consente invece di quantificare il grado di fiducia in base alle informazioni disponibili.\n\n\n\n24.2.15 Fondamenti Bayesiani\nL‚Äôinterpretazione soggettivista bayesiana propone che:\n\nLa probabilit√† sia una misura del grado di fiducia che un soggetto razionale attribuisce alla validit√† di un‚Äôaffermazione, basandosi su informazioni disponibili, generalmente insufficienti per determinare con certezza la verit√† o la falsit√† dell‚Äôaffermazione stessa.\n\nQuesta definizione non si riferisce a un individuo specifico, bens√¨ a una idealizzazione di un soggetto razionale, privo di emozioni o istinti, il cui giudizio √® basato esclusivamente sulla logica e sulle evidenze disponibili.\nCome descritto da E.T. Jaynes in Probability Theory: The Logic of Science, il problema della probabilit√† pu√≤ essere immaginato come segue:\n\nSi fornisca a un robot razionale un‚Äôinformazione \\(I\\), considerata vera e completa dal robot.\nSi presenti un‚Äôaffermazione \\(A\\), che nella realt√† √® esclusivamente vera o falsa.\nIl robot deve quantificare, nel modo pi√π razionale possibile, il grado di incertezza riguardante la validit√† di \\(A\\), basandosi esclusivamente sull‚Äôinformazione \\(I\\).\n\nLa probabilit√† di \\(A\\) dato \\(I\\) viene espressa come \\(P(A \\mid I)\\), dove:\n\n\\(P(A \\mid I)\\) √® un numero reale compreso tra 0 e 1.\nDeve rispettare i principi della coerenza logica, ossia i postulati della teoria della probabilit√†.\n\nIn conclusione, l‚Äôinterpretazione soggettivista trasforma la probabilit√† in uno strumento flessibile per affrontare situazioni di incertezza, adattandosi sia a eventi singoli che a contesti complessi. Essa consente di esprimere razionalmente le credenze personali, fornendo un quadro coerente e rigoroso per il ragionamento probabilistico.\n\n\n\n\n\n\nPer chi desidera approfondire, il primo capitolo del testo Bernoulli‚Äôs Fallacy (Clayton, 2021) offre un‚Äôintroduzione molto leggibile alle tematiche della definizione della probabilit√† nella storia della scienza.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Interpretazione della probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#riflessioni-conclusive",
    "href": "chapters/probability/01_intro_prob.html#riflessioni-conclusive",
    "title": "24¬† Interpretazione della probabilit√†",
    "section": "24.3 Riflessioni Conclusive",
    "text": "24.3 Riflessioni Conclusive\nNel presente capitolo, si √® proceduto a un‚Äôanalisi filosofica della nozione di probabilit√†, esplorando le sue interpretazioni sia come propriet√† intrinseca degli eventi sia come espressione di convinzioni soggettive in condizioni di incertezza.\n√à stato, inoltre, introdotto il ruolo della simulazione come strumento metodologico fondamentale per l‚Äôapprossimazione delle probabilit√† empiriche in contesti nei quali le soluzioni analitiche risultano impraticabili. Questa tecnica si rivela di estrema rilevanza in ambiti di recente sviluppo, dove la complessit√† dei modelli matematici richiede l‚Äôimpiego di algoritmi numerici avanzati per la loro elaborazione e comprensione.\nCon le premesse sopra esposte, il capitolo successivo sar√† dedicato all‚Äôanalisi matematica della probabilit√†. Si esaminer√† il modo in cui gli statistici formulano e applicano teoremi e leggi probabilistici, estendendo l‚Äôapplicabilit√† del concetto di probabilit√† al di l√† delle teorizzazioni puramente teoriche, verso implementazioni pratiche. Questo approccio quantitativo permetter√† di quantificare e gestire l‚Äôincertezza con maggiore precisione e affidabilit√†.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Interpretazione della probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/01_intro_prob.html#informazioni-sullambiente-di-sviluppo",
    "title": "24¬† Interpretazione della probabilit√†",
    "section": "24.4 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "24.4 Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: US/Pacific\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] ggokabeito_0.1.0 see_0.9.0        gridExtra_2.3    patchwork_1.3.0 \n#&gt;  [5] bayesplot_1.11.1 psych_2.4.12     scales_1.3.0     markdown_1.13   \n#&gt;  [9] knitr_1.49       lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1   \n#&gt; [13] dplyr_1.1.4      purrr_1.0.2      readr_2.1.5      tidyr_1.3.1     \n#&gt; [17] tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3       \n#&gt; [21] here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.3         rlang_1.1.4       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       yaml_2.3.10       tools_4.4.2       parallel_4.4.2   \n#&gt; [21] tzdb_0.4.0        colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5      \n#&gt; [25] R6_2.5.1          lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3  \n#&gt; [29] pillar_1.10.1     gtable_0.3.6      glue_1.8.0        xfun_0.50        \n#&gt; [33] tidyselect_1.2.1  farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-166     \n#&gt; [37] labeling_0.4.3    rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Interpretazione della probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#bibliografia",
    "href": "chapters/probability/01_intro_prob.html#bibliografia",
    "title": "24¬† Interpretazione della probabilit√†",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nClayton, A. (2021). Bernoulli‚Äôs Fallacy: Statistical Illogic and the Crisis of Modern Science. Columbia University Press.\n\n\nFishburn, P. C. (1986). The axioms of subjective probability. Statistical Science, 1(3), 335‚Äì345.\n\n\nHowson, C., & Urbach, P. (2006). Scientific reasoning: the Bayesian approach. Open Court Publishing.\n\n\nKaplan, D. (2023). Bayesian statistics for the social sciences. Guilford Publications.\n\n\nLindley, D. V. (2013). Understanding uncertainty. John Wiley & Sons.\n\n\nPress, S. J. (2009). Subjective and objective Bayesian statistics: Principles, models, and applications. John Wiley & Sons.\n\n\nRamsey, F. P. (1926). Truth and probability. In Readings in Formal Epistemology: Sourcebook (pp. 21‚Äì45). Springer.\n\n\nSpiegelhalter, D. (2024). Why probability probably doesn‚Äôt exist (but it is useful to act like it does). Nature, 636(8043), 560‚Äì563.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Interpretazione della probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_prob_spaces.html",
    "href": "chapters/probability/02_prob_spaces.html",
    "title": "25¬† Misura di Probabilit√†",
    "section": "",
    "text": "25.1 Introduzione\nPrerequisiti\nConcetti e Competenze Chiave\nDa dove derivano matematicamente i numeri che chiamiamo ‚Äúprobabilit√†‚Äù? Per rispondere a questa domanda, in questo capitolo faremo riferimento alla trattazione di Michael Betancourt. Questo capitolo offre una versione semplificata del suo lavoro, mantenendo la notazione e le figure originali.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Misura di Probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_prob_spaces.html#insiemi-finiti",
    "href": "chapters/probability/02_prob_spaces.html#insiemi-finiti",
    "title": "25¬† Misura di Probabilit√†",
    "section": "25.2 Insiemi Finiti",
    "text": "25.2 Insiemi Finiti\nPer semplificare, Betancourt introduce i fondamenti della teoria della probabilit√† utilizzando uno spazio campionario composto da un numero finito di elementi.\nUn insieme finito √® costituito da un numero finito di elementi distinti,\n\\[\nX = \\{x_1, ..., x_N\\}.\n\\]\nQui, l‚Äôindice numerico serve a distinguere gli \\(N\\) elementi individuali, senza implicare necessariamente un ordine particolare tra di essi. Per evitare qualsiasi presunzione di ordine, Betancourt utilizza il seguente insieme arbitrario di cinque elementi quale esempio:\n\\[\nX = \\{\\Box, \\clubsuit, \\diamondsuit, \\heartsuit, \\spadesuit\\}.\n\\]\n\n\n\n\n\n\nFigura¬†25.1: Un insieme finito contiene un numero finito di elementi. Questo particolare insieme ne contiene cinque.\n\n\n\nNelle applicazioni pratiche della teoria della probabilit√†, gli elementi astratti \\(x_{n}\\) rappresentano oggetti concreti. Tuttavia, in questo capitolo, ci si concentrer√† esclusivamente sui concetti matematici, evitando qualsiasi interpretazione particolare. Quando l‚Äôinsieme \\(X\\) rappresenta tutti gli oggetti di interesse in una data applicazione, viene denominato spazio campionario. Una volta definito lo spazio campionario, possiamo organizzare e manipolare i suoi elementi in vari modi.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Misura di Probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_prob_spaces.html#sottoinsiemi",
    "href": "chapters/probability/02_prob_spaces.html#sottoinsiemi",
    "title": "25¬† Misura di Probabilit√†",
    "section": "25.3 Sottoinsiemi",
    "text": "25.3 Sottoinsiemi\nUn sottoinsieme di \\(X\\) √® qualsiasi collezione di elementi in \\(X\\). Per evitare ambiguit√†, Betancourt usa le lettere romane minuscole \\(x\\) per indicare un elemento variabile nello spazio campionario \\(X\\) e le lettere minuscole sans serif \\(\\mathsf{x}\\) per indicare un sottoinsieme variabile.\nAd esempio, \\(\\mathsf{x} = \\{\\Box, \\diamondsuit, \\heartsuit\\}\\) √® un sottoinsieme di \\(X = \\{\\Box, \\clubsuit, \\diamondsuit, \\heartsuit, \\spadesuit\\}\\). Importante notare che nel concetto di sottoinsieme non esiste la nozione di molteplicit√†, solo di appartenenza: un sottoinsieme pu√≤ includere un elemento \\(x_{n}\\) ma non pu√≤ includerlo pi√π volte.\n\n\n\n\n\n\nFigura¬†25.2: Un sottoinsieme \\(\\mathsf{x} \\subset X\\) √® qualsiasi collezione di elementi dallo spazio campionario \\(X\\). Qui \\(\\mathsf{x} = \\{\\Box, \\diamondsuit, \\heartsuit\\}\\) contiene solo tre dei cinque elementi in $X = {, , , , }.\n\n\n\nSe \\(\\mathsf{x}\\) √® un sottoinsieme dello spazio campionario \\(X\\) allora scriviamo \\(\\mathsf{x} \\subset X\\). Quando \\(\\mathsf{x}\\) contiene tutti gli elementi di \\(X\\), ovvero \\(\\mathsf{x} = X\\), allora scriviamo \\(\\mathsf{x} \\subseteq X\\).\nIndipendentemente da quanti elementi un insieme finito \\(X\\) contiene, possiamo sempre costruire tre tipi speciali di sottoinsiemi. L‚Äôinsieme vuoto \\(\\emptyset = \\{\\}\\) non contiene alcun elemento. D‚Äôaltra parte, l‚Äôintero insieme stesso pu√≤ essere considerato un sottoinsieme contenente tutti gli elementi. Un sottoinsieme contenente un singolo elemento √® denotato \\(\\{ x_{n} \\}\\) ed √® chiamato insieme atomico.\nCi sono\n\\[\n{N \\choose n} = \\frac{ N! }{ n! (N - n)!}\n\\]\nmodi per selezionare \\(n\\) elementi da un insieme finito di \\(N\\) elementi totali, e quindi \\({N \\choose n}\\) sottoinsiemi totali di dimensione \\(n\\). Ad esempio, esiste un solo sottoinsieme che non contiene alcun elemento,\n\\[\n{N \\choose 0} = \\frac{ N! }{ 0! (N - 0)!} = \\frac{ N! }{ N! } = 1,\n\\]\ned √® l‚Äôinsieme vuoto. Allo stesso modo, esiste un solo sottoinsieme che contiene tutti gli elementi,\n\\[\n{N \\choose N} = \\frac{ N! }{ N! (N - N)!} = \\frac{ N! }{ N! } = 1,\n\\]\ned √® l‚Äôinsieme completo stesso. D‚Äôaltra parte, ci sono\n\\[\n{N \\choose 1} = \\frac{ N! }{ 1! (N - 1)!} = N\n\\]\ninsiemi atomici distinti che contengono un solo elemento, uno per ciascun elemento in \\(X\\).\nContando tutti i sottoinsiemi di tutte le dimensioni possibili si ottiene\n\\[\n\\sum_{n = 0}^{N} {N \\choose n} = 2^{N}\n\\]\nsottoinsiemi possibili che possiamo costruire da un insieme finito con \\(N\\) elementi.\nLa collezione di tutti i sottoinsiemi √® essa stessa un insieme finito con \\(2^{N}\\) elementi. Chiamiamo questo insieme insieme potenza di \\(X\\) e lo denotiamo \\(2^{X}\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Misura di Probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_prob_spaces.html#operazioni-sui-sottoinsiemi",
    "href": "chapters/probability/02_prob_spaces.html#operazioni-sui-sottoinsiemi",
    "title": "25¬† Misura di Probabilit√†",
    "section": "25.4 Operazioni sui Sottoinsiemi",
    "text": "25.4 Operazioni sui Sottoinsiemi\nPossiamo sempre costruire sottoinsiemi elemento per elemento, ma possiamo anche costruirli manipolando sottoinsiemi esistenti.\nAd esempio, dato un sottoinsieme \\(\\mathsf{x} \\subset X\\) possiamo costruire il suo complemento raccogliendo tutti gli elementi in \\(X\\) che non sono gi√† in \\(\\mathsf{x}\\). L‚Äôinsieme atomico \\(\\mathsf{x} = \\{ \\diamondsuit \\}\\) contiene l‚Äôunico elemento \\(\\diamondsuit\\) e il suo complemento contiene i rimanenti elementi \\[\n\\mathsf{x}^{c} = \\{ \\Box, \\clubsuit, \\heartsuit, \\spadesuit \\}.\n\\] Per costruzione, il complemento dell‚Äôinsieme vuoto √® l‚Äôintero insieme, \\(\\emptyset^{c} = X\\), e il complemento dell‚Äôinsieme completo √® l‚Äôinsieme vuoto, \\(X^{c} = \\emptyset\\).\n\n\n\n\n\n\nFigura¬†25.3: Il complemento di un sottoinsieme \\(\\mathsf{x}\\) √® il sottoinsieme \\(\\mathsf{x}^{c}\\) costituito da tutti gli elementi nello spazio campionario che non sono in \\(\\mathsf{x}\\).\n\n\n\nAd esempio, applicando l‚Äôoperatore di complemento al sottoinsieme \\(\\mathsf{x} = \\{ \\clubsuit, \\spadesuit \\}\\) otteniamo \\[\n\\mathsf{x}^{c}\n= \\{ \\clubsuit, \\spadesuit \\}^{c}\n= \\{ \\Box, \\diamondsuit, \\heartsuit \\}.\n\\]\nPossiamo anche costruire sottoinsiemi da pi√π di un sottoinsieme. Consideriamo, ad esempio, due sottoinsiemi \\(\\mathsf{x}_1 = \\{ \\Box, \\heartsuit \\}\\) e \\(\\mathsf{x}_2 = \\{ \\Box, \\spadesuit \\}\\). La collezione di tutti gli elementi che sono contenuti in uno qualsiasi dei due sottoinsiemi √® essa stessa un sottoinsieme, \\[\n\\{ \\Box, \\heartsuit, \\spadesuit \\} \\subset X,\n\\] cos√¨ come la collezione di tutti gli elementi che sono contenuti in entrambi i sottoinsiemi, \\[\n\\{ \\Box \\} \\subset X.\n\\] Questi sottoinsiemi derivati sono chiamati rispettivamente unione, \\[\n\\mathsf{x}_1 \\cup \\mathsf{x}_2\n= \\{ \\Box, \\heartsuit \\} \\cup \\{ \\Box, \\spadesuit \\}\n= \\{ \\Box, \\heartsuit, \\spadesuit \\},\n\\] e intersezione, \\[\n\\mathsf{x}_1 \\cap \\mathsf{x}_2\n= \\{ \\Box, \\heartsuit \\} \\cap \\{ \\Box, \\spadesuit \\}\n= \\{ \\Box \\}.\n\\]\n\n\n\n\n\n\nFigura¬†25.4: Possiamo manipolare due sottoinsiemi in vari modi per ottenere un nuovo sottoinsieme.\n\n\n\n\n\n\n\n\n\nFigura¬†25.5: L‚Äôunione di due sottoinsiemi, \\(\\mathsf{x}_1 \\cup \\mathsf{x}_2\\), √® un sottoinsieme contenente tutti gli elementi di entrambi i sottoinsiemi in input. D‚Äôaltra parte, l‚Äôintersezione di due sottoinsiemi, \\(\\mathsf{x}_1 \\cap \\mathsf{x}_2\\), √® un sottoinsieme contenente solo gli elementi che compaiono in entrambi i sottoinsiemi in input.\n\n\n\nDue sottoinsiemi sono disgiunti se non condividono alcun elemento; in questo caso la loro intersezione √® l‚Äôinsieme vuoto, \\[\n\\mathsf{x}_{1} \\cap \\mathsf{x}_{2} = \\emptyset.\n\\] L‚Äôunione e l‚Äôintersezione di un sottoinsieme con se stesso restituiscono quel sottoinsieme, \\[\n\\mathsf{x} \\cup \\mathsf{x} = \\mathsf{x} \\cap \\mathsf{x} = \\mathsf{x}.\n\\] Poich√© l‚Äôinsieme vuoto non contiene alcun elemento, la sua unione con qualsiasi sottoinsieme restituisce quel sottoinsieme, \\[\n\\mathsf{x} \\cup \\emptyset = \\emptyset \\cup \\mathsf{x} = \\mathsf{x},\n\\] e la sua intersezione con qualsiasi sottoinsieme restituisce l‚Äôinsieme vuoto, \\[\n\\mathsf{x} \\cap \\emptyset = \\emptyset \\cap \\mathsf{x} = \\emptyset.\n\\] Allo stesso modo, l‚Äôunione di un sottoinsieme con l‚Äôinsieme completo restituisce l‚Äôinsieme completo, \\[\n\\mathsf{x} \\cup X = X \\cup \\mathsf{x} = X,\n\\] e l‚Äôintersezione di un sottoinsieme con l‚Äôinsieme completo restituisce quel sottoinsieme, \\[\n\\mathsf{x} \\cap X = X \\cap \\mathsf{x} = \\mathsf{x}.\n\\]",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Misura di Probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_prob_spaces.html#misura-e-probabilit√†-sugli-elementi",
    "href": "chapters/probability/02_prob_spaces.html#misura-e-probabilit√†-sugli-elementi",
    "title": "25¬† Misura di Probabilit√†",
    "section": "25.5 Misura e Probabilit√† sugli Elementi",
    "text": "25.5 Misura e Probabilit√† sugli Elementi\nDa un punto di vista matematico, la teoria della misura riguarda l‚Äôallocazione coerente di una qualche quantit√† astratta attraverso lo spazio campionario. Consideriamo un serbatoio (il termine standard in questo contesto sarebbe ‚Äúmisura totale‚Äù o ‚Äúmassa totale‚Äù) di una qualche quantit√† positiva, continua e conservata, \\(M \\in [0, \\infty]\\). Poich√© \\(M\\) √® conservato, qualsiasi quantit√† \\(m_{n}\\) che viene allocata all‚Äôelemento \\(x_{n} \\in X\\) deve essere detratta dal serbatoio, lasciando meno da allocare agli altri elementi.\nUn caso particolare si verifica quando il contenuto totale del serbatoio \\(M\\) √® infinito. In questo scenario, possiamo allocare una quantit√† infinita dal serbatoio pur avendo ancora una quantit√† infinita rimanente. Allo stesso tempo, allocare una quantit√† infinita pu√≤ esaurire completamente il serbatoio o lasciare qualsiasi quantit√† finita residua. L‚Äôinfinito √® un concetto matematicamente complesso da trattare.\n\n\n\n\n\n\nFigura¬†25.6: La teoria della misura riguarda l‚Äôallocazione di una qualche quantit√† continua e positiva \\(M\\) sugli elementi individuali dello spazio campionario.\n\n\n\nUn‚Äôallocazione esaustiva di \\(M\\) su tutto lo spazio campionario assicura che il serbatoio sia completamente svuotato. In altre parole, l‚Äôintero valore di \\(M\\) deve essere distribuito tra gli elementi \\(x_{n} \\in X\\).\nPer illustrare questo concetto, consideriamo il nostro spazio campionario dimostrativo \\(X = \\{\\Box, \\clubsuit, \\diamondsuit, \\heartsuit, \\spadesuit \\}\\). Il processo di allocazione pu√≤ essere descritto come segue:\n\nAllocchiamo \\(m_\\Box\\) a \\(\\Box\\), lasciando \\(M - m_\\Box\\) nel serbatoio.\nAssegniamo \\(m_\\clubsuit\\) a \\(\\clubsuit\\), riducendo ulteriormente il contenuto del serbatoio a \\(M - m_\\Box - m_\\clubsuit\\).\nContinuiamo questo processo per \\(\\diamondsuit\\) e \\(\\heartsuit\\).\nInfine, per svuotare completamente il serbatoio, dobbiamo allocare tutto ci√≤ che rimane a \\(\\spadesuit\\).\n\nMatematicamente, l‚Äôammontare finale allocato a \\(\\spadesuit\\) sar√†:\n\\[\nM - m_{\\Box} - m_{\\clubsuit} - m_{\\diamondsuit} - m_{\\heartsuit}.\n\\]\nQuesta allocazione finale assicura che la somma di tutte le quantit√† distribuite sia esattamente uguale a \\(M\\), svuotando cos√¨ completamente il serbatoio.\n\n\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c)\n\n\n\n\n\n\n\n\n\n\n\n(d)\n\n\n\n\n\n\n\n¬†\n\n\n\n\n\n\n\n\n(e)\n\n\n\n\n\n¬†\n\n\n\n\nFigura¬†25.7: Poich√© la quantit√† totale \\(M\\) √® conservata, ogni allocazione \\(m_{n}\\) a un elemento \\(x_{n} \\in X\\) riduce la quantit√† disponibile per l‚Äôallocazione agli altri elementi. Un‚Äôallocazione esaustiva non lascia nulla nel serbatoio iniziale dopo che ciascun elemento ha ricevuto la sua allocazione.\n\n\n\nUna misura √® qualsiasi allocazione coerente della quantit√† \\(M\\) agli elementi di uno spazio campionario. Matematicamente, qualsiasi misura su un insieme finito pu√≤ essere caratterizzata da \\(N\\) numeri \\[\n\\mu = \\{ m_{1}, \\ldots, m_{N} \\}\n\\] che soddisfano \\[\n0 \\le m_{n}\n\\] e \\[\n\\sum_{n = 1}^{N} m_{n} = M.\n\\] Ad esempio, qualsiasi misura sui cinque elementi dell‚Äôinsieme \\(X = \\{\\Box, \\clubsuit, \\diamondsuit, \\heartsuit, \\spadesuit\\}\\) √® specificata da cinque numeri positivi \\(\\{ m_\\Box, m_\\clubsuit, m_\\diamondsuit, m_\\heartsuit, m_\\spadesuit \\}\\) che soddisfano \\[\nm_\\Box + m_\\clubsuit + m_\\diamondsuit + m_\\heartsuit + m_\\spadesuit = M.\n\\]\n\n\n\n\n\n\nFigura¬†25.8: Una misura \\(\\mu\\) su un insieme finito \\(X\\) √® qualsiasi allocazione coerente di \\(M\\) agli elementi $x_{n} X. Ogni misura pu√≤ essere caratterizzata da \\(N\\) numeri \\(m_{n}\\) che sommano a \\(M\\), o equivalentemente una funzione che mappa ogni elemento \\(x_{n}\\) alla sua misura allocata \\(m_{n}\\).\n\n\n\nPi√π grande √® \\(m_{n}\\), pi√π di \\(M\\) viene allocato all‚Äôelemento \\(x_{n}\\). Seguendo questa terminologia, chiameremo anche \\(M\\) come la misura totale e \\(m_{n}\\) come la misura allocata a \\(x_{n}\\).\nIn questa discussione, ci occuperemo solo di misure finite, dove la misura totale \\(M\\) √® un numero positivo e finito (\\(0 \\leq M \\leq \\infty\\)). Non tratteremo il caso di misure infinite (\\(M = \\infty\\)), poich√© richiede considerazioni pi√π complesse che vanno oltre lo scopo di questa trattazione.\nUna misura \\(\\mu\\) su uno spazio campionario \\(X\\) pu√≤ essere vista come una funzione che assegna un valore numerico non negativo (la misura) a ogni elemento dello spazio:\n\\[\n\\begin{alignat*}{6}\n\\mu :\\; & X & &\\rightarrow& \\; & [0, \\infty] &\n\\\\\n& x_{n} & &\\mapsto& & m_{n} = \\mu(x_{n}) &,\n\\end{alignat*}\n\\] dove:\n\n\\(X\\) √® lo spazio campionario,\n\\(x_n\\) √® un elemento di \\(X\\),\n\\(m_n\\) √® la misura assegnata a \\(x_n\\).\n\nQuesto approccio funzionale ci permette di considerare ogni elemento dello spazio campionario separatamente, valutando \\(\\mu(x_{n})\\) per ciascun \\(x_{n}\\), invece di dover gestire tutte le allocazioni contemporaneamente.\n√à importante notare che esistono molti modi diversi per distribuire una misura totale \\(M\\) tra gli elementi di un insieme finito. L‚Äôinsieme di tutte le possibili misure su \\(X\\) si indica con \\(\\mathcal{M}(X)\\).\nAll‚Äôinterno di questa collezione ci sono alcuni esempi notevoli. Ad esempio, una misura singolare alloca la misura totale \\(M\\) a un singolo elemento, lasciando il resto con niente. D‚Äôaltra parte, una misura uniforme alloca la stessa misura \\(M / N\\) a ciascun elemento. Su insiemi finiti ci sono \\(N\\) misure singolari distinte, una per ciascun elemento distinto, e una misura uniforme unica.\n\n\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\n\nFigura¬†25.9: Una misura singolare (a) alloca la misura totale a un singolo elemento, mentre la misura uniforme (b) distribuisce la misura totale uniformemente a ciascun elemento.\n\n\n\nLe misure finite sono una categoria particolarmente importante nel campo della teoria della misura. Una misura si definisce finita quando la sua misura totale \\(M\\) √® un numero positivo e limitato, ovvero \\(0 &lt; M &lt; \\infty\\).\nL‚Äôimportanza delle misure finite risiede nella possibilit√† di esprimere le allocazioni in termini relativi anzich√© assoluti. Questo significa che possiamo rappresentare la misura di ciascun elemento come una frazione o una percentuale della misura totale, invece di usare il valore assoluto. Invece di considerare la misura assoluta allocata a ciascun elemento \\(m_{n}\\), possiamo considerare la proporzione della misura totale allocata a ciascun elemento \\[\np_{n} = m_{n} / M.\n\\] Per costruzione, le proporzioni sono confinate all‚Äôintervallo unitario \\([0, 1]\\). Come per qualsiasi quantit√† che assume valori in \\([0, 1]\\), possiamo rappresentare le proporzioni altrettanto bene con decimali, ad esempio \\(p_{n} = 0.2\\), e percentuali, \\(p_{n} = 20\\%\\).\nQuesto approccio relativo offre diversi vantaggi: permette di confrontare facilmente l‚Äôimportanza relativa di diversi elementi, facilita la comprensione della distribuzione della misura sull‚Äôintero spazio campionario e consente di normalizzare misure diverse, rendendo pi√π semplice il confronto tra sistemi diversi. In sintesi, le misure finite ci permettono di passare da una visione ‚Äúassoluta‚Äù a una ‚Äúrelativa‚Äù della distribuzione della misura, offrendo una prospettiva pi√π intuitiva e utile per l‚Äôanalisi.\n\n\n\n\n\n\nFigura¬†25.10: Ogni misura finita pu√≤ essere caratterizzata da un‚Äôallocazione proporzionale.\n\n\n\nIn altre parole, una misura proporzionale definisce la funzione \\[\n\\begin{alignat*}{6}\n\\pi :\\; & X & &\\rightarrow& \\; & [0, 1] &\n\\\\\n& x_{n} & &\\mapsto& & p_{n} = \\pi(x_{n}) &\n\\end{alignat*}\n\\] con \\[\n0 \\le p_{n} \\le 1\n\\] e \\[\n\\sum_{n = 1}^{N} p_{n} = 1.\n\\] Una collezione di variabili \\(\\{ p_{1}, \\ldots, p_{N} \\}\\) che soddisfano queste propriet√† √® chiamata simplex.\n\n\n\n\n\n\nFigura¬†25.11: Un‚Äôallocazione proporzionale √® anche conosciuta come distribuzione di probabilit√†.\n\n\n\nPi√π importante, una misura proporzionale \\(\\pi\\) √® anche conosciuta come distribuzione di probabilit√†, e le allocazioni proporzionali \\(p_{n}\\) sono chiamate probabilit√†. Sebbene il termine ‚Äúprobabilit√†‚Äù sia spesso carico di significati interpretativi e filosofici, la sua struttura matematica √® piuttosto semplice: su un insieme finito, una probabilit√† rappresenta semplicemente la proporzione di una quantit√† finita assegnata a ciascun elemento individuale.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Misura di Probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_prob_spaces.html#misura-e-probabilit√†-sui-sottoinsiemi",
    "href": "chapters/probability/02_prob_spaces.html#misura-e-probabilit√†-sui-sottoinsiemi",
    "title": "25¬† Misura di Probabilit√†",
    "section": "25.6 Misura e Probabilit√† sui Sottoinsiemi",
    "text": "25.6 Misura e Probabilit√† sui Sottoinsiemi\nSugli insiemi finiti, qualsiasi allocazione, sia assoluta che proporzionale, agli elementi individuali \\(x \\in X\\) determina anche un‚Äôallocazione per i sottoinsiemi \\(\\mathsf{x} \\in 2^{X}\\). La misura assegnata a un sottoinsieme √® semplicemente la somma delle misure assegnate agli elementi che lo compongono. Ad esempio, la misura assegnata al sottoinsieme \\(\\mathsf{x} = \\{ \\Box, \\clubsuit, \\heartsuit \\}\\) √® \\(m_{\\Box} + m_{\\clubsuit} + m_{\\heartsuit}\\).\n\n\n\n\n\n\nFigura¬†25.12: Su un insieme finito, un‚Äôallocazione sugli elementi individuali definisce anche un‚Äôallocazione su qualsiasi sottoinsieme.\n\n\n\nPer costruzione, qualsiasi misura sui sottoinsiemi e distribuzione di probabilit√† soddisfano una serie di propriet√† utili. Ad esempio, per qualsiasi misura \\[\n\\mu( \\emptyset ) = 0\n\\] e \\[\n\\mu( X ) = \\sum_{n = 1}^{N} \\mu(x_{n}) = M,\n\\] mentre per qualsiasi distribuzione di probabilit√† abbiamo \\(\\pi( \\emptyset ) = 0\\) e \\(\\pi( X ) = 1\\).\nLe allocazioni sui sottoinsiemi si combinano in modo naturale con le operazioni sui sottoinsiemi. Consideriamo, ad esempio, i due sottoinsiemi disgiunti \\(\\mathsf{x}_{1} = \\{ \\Box, \\diamondsuit \\}\\) e \\(\\mathsf{x}_{2} = \\{ \\clubsuit, \\spadesuit \\}\\). Poich√© i due sottoinsiemi sono disgiunti, la loro unione include semplicemente tutti i loro elementi:\n\\[\n\\mathsf{x}_{1} \\cup \\mathsf{x}_{2}\n=\n\\{ \\Box, \\diamondsuit \\} \\cup \\{ \\clubsuit, \\spadesuit \\}\n=\n\\{ \\Box, \\clubsuit, \\diamondsuit, \\spadesuit \\},\n\\]\ne la misura di questa unione √® solo la somma delle misure dei due sottoinsiemi:\n\\[\n\\begin{align*}\n\\mu ( \\mathsf{x}_{1} \\cup \\mathsf{x}_{2} )\n&=\n\\mu ( \\{ \\Box, \\clubsuit, \\diamondsuit, \\spadesuit \\} )\n\\\\\n&=\nm_{\\Box} + m_{\\clubsuit} + m_{\\diamondsuit} + m_{\\spadesuit}\n\\\\\n&=\n( m_{\\Box} + m_{\\diamondsuit} ) + ( m_{\\clubsuit} + m_{\\spadesuit} )\n\\\\\n&=\n\\mu( \\mathsf{x}_{1} ) + \\mu( \\mathsf{x}_{2} ).\n\\end{align*}\n\\]\nPi√π in generale, per qualsiasi collezione di sottoinsiemi\n\\[\n\\mathsf{x}_{1}, \\ldots, \\mathsf{x}_{K}\n\\]\nche sono reciprocamente disgiunti,\n\\[\n\\mathsf{x}_{k} \\cap \\mathsf{x}_{k'} = \\emptyset \\quad \\text{per} \\quad k \\ne k',\n\\]\nabbiamo\n\\[\n\\mu ( \\cup_{k = 1}^{K} \\mathsf{x}_{k} )\n=\n\\sum_{k = 1}^{K} \\mu ( \\mathsf{x}_{k} ).\n\\]\nIn altre parole, se possiamo scomporre un sottoinsieme in una collezione di sottoinsiemi pi√π piccoli e disgiunti, possiamo anche scomporre la misura allocata a quel sottoinsieme iniziale nelle misure allocate ai sottoinsiemi componenti. Questa propriet√† di coerenza √® chiamata additivit√†.\nUn sottoinsieme \\(\\mathsf{x}\\) e il suo complemento \\(\\mathsf{x}^{c}\\) sono sempre disgiunti, ovvero \\(\\mathsf{x} \\cap \\mathsf{x}^{c} = \\emptyset\\). Allo stesso tempo, la loro unione copre l‚Äôintero insieme: \\(\\mathsf{x} \\cup \\mathsf{x}^{c} = X\\). Di conseguenza, l‚Äôadditivit√† implica che:\n\\[\n\\begin{align*}\nM &= \\mu (X) \\\\\n  &= \\mu ( \\mathsf{x} \\cup \\mathsf{x}^{c} ) \\\\\n  &= \\mu ( \\mathsf{x} ) + \\mu ( \\mathsf{x}^{c} ),\n\\end{align*}\n\\]\nda cui segue che:\n\\[\n\\mu ( \\mathsf{x}^{c} ) = M - \\mu ( \\mathsf{x} ).\n\\]\nIn altre parole, la misura assegnata al complemento di un sottoinsieme √® la misura totale meno la misura assegnata a quel sottoinsieme. Per le distribuzioni di probabilit√†, questo concetto √® ancora pi√π evidente:\n\\[\n\\pi ( \\mathsf{x}^{c} ) = 1 - \\pi ( \\mathsf{x} ).\n\\]\nQuando due sottoinsiemi si sovrappongono, dobbiamo considerare che la somma delle loro misure \\(\\mu (\\mathsf{x}_{1} ) + \\mu ( \\mathsf{x}_{2} )\\) conta due volte la misura degli elementi condivisi tra di essi. Ad esempio, se \\(\\mathsf{x}_{1} = \\{ \\Box, \\heartsuit \\}\\) e \\(\\mathsf{x}_{2} = \\{ \\Box, \\spadesuit \\}\\), allora l‚Äôunione include l‚Äôelemento sovrapposto \\(\\Box\\) solo una volta:\n\\[\n\\mathsf{x}_{1} \\cup \\mathsf{x}_{2} = \\{ \\Box, \\heartsuit \\} \\cup \\{ \\Box, \\spadesuit \\} = \\{ \\Box, \\heartsuit, \\spadesuit \\}.\n\\]\nDi conseguenza:\n\\[\n\\begin{align*}\n\\mu( \\mathsf{x}_{1} \\cup \\mathsf{x}_{2} ) &= \\mu( \\{ \\Box, \\heartsuit, \\spadesuit \\} ) \\\\\n&= m_{\\Box} + m_{\\heartsuit} + m_{\\spadesuit}.\n\\end{align*}\n\\]\nSommando le misure allocate ai due sottoinsiemi individualmente, tuttavia, otteniamo:\n\\[\n\\begin{align*}\n\\mu( \\mathsf{x}_{1} ) + \\mu ( \\mathsf{x}_{2} ) &= (m_{\\Box} + m_{\\heartsuit} ) + ( m_{\\Box} + m_{\\spadesuit} ) \\\\\n&= m_{\\Box} + m_{\\Box} + m_{\\heartsuit} + m_{\\spadesuit} \\\\\n&= m_{\\Box} + \\mu( \\mathsf{x}_{1} \\cup \\mathsf{x}_{2} ).\n\\end{align*}\n\\]\nL‚Äôelemento che viene contato due volte √® esattamente l‚Äôunico elemento nell‚Äôintersezione dei due sottoinsiemi:\n\\[\nm_{\\Box} = \\mu( \\{ \\Box \\} ) = \\mu( \\mathsf{x}_{1} \\cap \\mathsf{x}_{2} ).\n\\]\nIn altre parole, possiamo scrivere:\n\\[\n\\mu( \\mathsf{x}_{1} ) + \\mu ( \\mathsf{x}_{2} ) = \\mu( \\mathsf{x}_{1} \\cup \\mathsf{x}_{2} ) + \\mu( \\mathsf{x}_{1} \\cap \\mathsf{x}_{2} ).\n\\]\nQuesta relazione vale per qualsiasi due sottoinsiemi, indipendentemente dalla loro sovrapposizione.\n\n\n\n\n\n\nFigura¬†25.13: Quando due sottoinsiemi si sovrappongono, la misura allocata a ciascuno conta doppio la misura allocata a qualsiasi elemento sovrapposto, qui \\(\\Box\\), ma la misura allocata alla loro unione no. Questo risulta in una relazione importante tra le misure allocate ai due sottoinsiemi, la misura allocata alla loro unione e la misura allocata alla loro intersezione.\n\n\n\nQueste propriet√† dei sottoinsiemi ci permettono di costruire una misura in molti modi diversi, ciascuno dei quali pu√≤ essere utile in circostanze diverse. Questa flessibilit√† √® molto comoda quando si applica la teoria della misura e la teoria della probabilit√† nella pratica.\nAd esempio, possiamo specificare una misura in due modi principali:\n\nAllocazione globale: possiamo assegnare le misure a tutti gli elementi individuali contemporaneamente. Questo metodo considera l‚Äôintero insieme fin dall‚Äôinizio e assegna una misura a ciascun elemento.\n\n\n\n\n\n\n\nFigura¬†25.14: Le misure possono essere costruite specificando le allocazioni degli elementi individuali tutte insieme.\n\n\n\n\nAllocazione locale: possiamo assegnare la misura a ciascun elemento uno alla volta. Questo metodo permette di concentrarsi su un elemento alla volta, aggiungendo gradualmente le misure agli altri elementi.\n\n\n\n\n\n\n\nFigura¬†25.15: Allo stesso tempo, le misure possono essere costruite specificando le allocazioni degli elementi individuali uno alla volta.\n\n\n\nInoltre, non √® sempre necessario partire dalle allocazioni individuali. Un altro metodo consiste nel:\n\nAllocazione iterativa: possiamo iniziare allocando la misura totale a sottoinsiemi disgiunti e poi affinare iterativamente questa allocazione suddividendo i sottoinsiemi in parti sempre pi√π piccole fino a raggiungere gli elementi individuali.\n\n\n\n\n\n\n\nFigura¬†25.16: Le misure possono anche essere costruite allocando la misura totale a sottoinsiemi disgiunti e poi raffinando iterativamente tale allocazione a sottoinsiemi sempre pi√π piccoli.\n\n\n\nQuesta flessibilit√† nelle modalit√† di costruzione delle misure √® particolarmente utile perch√© permette di adattare l‚Äôapproccio alle specifiche necessit√† del problema in questione. Ad esempio, nella pratica, potremmo trovare pi√π semplice allocare inizialmente misure a grandi gruppi di elementi e poi suddividere questi gruppi, oppure potremmo voler assegnare le misure a ciascun elemento uno per uno a seconda delle esigenze del contesto.\nInfine, la definizione di misura sui sottoinsiemi \\(\\mu : 2^{X} \\rightarrow [0, \\infty]\\) √® cruciale per estendere la teoria della misura oltre gli insiemi finiti. Questa estensione √® necessaria per definire misure in modo coerente su insiemi matematicamente pi√π complessi, come la retta reale.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Misura di Probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_prob_spaces.html#riflessioni-conclusive",
    "href": "chapters/probability/02_prob_spaces.html#riflessioni-conclusive",
    "title": "25¬† Misura di Probabilit√†",
    "section": "25.7 Riflessioni Conclusive",
    "text": "25.7 Riflessioni Conclusive\nIl significato applicativo delle nozioni di misura e distribuzione di probabilit√† √® centrale per comprendere come utilizzare questi concetti nella pratica, in particolare nella statistica bayesiana. Il punto cruciale √® capire cosa rappresenta \\(M\\), la ‚Äúmisura totale‚Äù. Nelle applicazioni bayesiane, \\(M\\) rappresenta la nostra certezza complessiva.\nQuando si lavora con distribuzioni di probabilit√†, stiamo effettivamente allocando questa certezza complessiva tra diversi eventi possibili. Una distribuzione (di massa) di probabilit√† √® quindi l‚Äôallocazione relativa della nostra certezza tra un insieme di eventi disgiunti. Ogni probabilit√† individuale, \\(p_n\\), rappresenta la proporzione della nostra certezza totale che assegniamo a un particolare evento.\nNella teoria bayesiana, la ‚Äúmisura totale‚Äù \\(M\\) √® interpretata come la somma totale delle probabilit√†, che √® sempre uguale a 1. Questo riflette il fatto che la somma delle nostre certezze relative per tutti gli eventi possibili deve essere completa: siamo completamente certi che uno degli eventi nel nostro spazio campionario si verificher√†.\nQuando creiamo una distribuzione di probabilit√†, stiamo dividendo questa certezza totale tra i vari eventi possibili nel nostro spazio campionario. Ad esempio, se stiamo analizzando un problema con cinque possibili esiti distinti, dobbiamo allocare l‚Äôintera certezza (pari a 1) tra questi esiti. Ogni valore di probabilit√† \\(p_n\\) rappresenta la frazione della nostra certezza totale che attribuiamo a un particolare esito.\nIn conclusione, le nozioni di misura e distribuzione di probabilit√† sono strumenti potenti per allocare e manipolare la nostra certezza tra diversi eventi possibili. Comprendere questi concetti √® fondamentale per comprendere le applicazioni della teoria della probabilit√† e della statistica. La ‚Äúmisura totale‚Äù \\(M\\) rappresenta la nostra certezza complessiva, e le distribuzioni di probabilit√† ci permettono di distribuire questa certezza in modo coerente e informato tra gli eventi possibili.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Misura di Probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_prob_spaces.html#esercizi",
    "href": "chapters/probability/02_prob_spaces.html#esercizi",
    "title": "25¬† Misura di Probabilit√†",
    "section": "Esercizi",
    "text": "Esercizi\nDal testo di Blitzstein & Hwang (2019), svolgere i seguenti esercizi: 1.4.3, 1.4.4, 1.4.5, 1.4.6, 1.4.9, 1.4.12, 1.4.13.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Misura di Probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_prob_spaces.html#bibliografia",
    "href": "chapters/probability/02_prob_spaces.html#bibliografia",
    "title": "25¬† Misura di Probabilit√†",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlitzstein, J. K., & Hwang, J. (2019). Introduction to probability. CRC Press.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Misura di Probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html",
    "href": "chapters/probability/03_prob_on_general_spaces.html",
    "title": "26¬† Fondamenti della probabilit√†",
    "section": "",
    "text": "26.1 Introduzione\nNel Capitolo 25 abbiamo introdotto la teoria della misura e della probabilit√† su insiemi con un numero finito di elementi. Tuttavia, molti degli spazi matematici che incontriamo nelle applicazioni pratiche, come gli interi e la retta reale, non hanno un numero finito di elementi, ma piuttosto un numero numerabile infinito o addirittura non numerabile infinito di elementi. Sfortunatamente, estendere la teoria della misura e della probabilit√† a spazi pi√π generali come questi non √® sempre semplice.\nSenza entrare nei dettagli, √® stato dimostrato che la forma pi√π generale della teoria della misura e della probabilit√† applicabile a qualsiasi spazio matematico √® chiamata \\(\\sigma\\)-algebra. In questo capitolo, forniremo un‚Äôintroduzione intuitiva ai vincoli delle \\(\\sigma\\)-algebre ed esamineremo alcune notevoli applicazioni. In particolare, introdurremo i concetti di variabile casuale, funzioni di massa di probabilit√† e funzioni di ripartizione.\nQuesti concetti sono fondamentali per comprendere come la probabilit√† e la misura possono essere utilizzate in contesti pi√π complessi, permettendo di estendere le nostre analisi a insiemi infiniti e spazi continui, che sono comuni nelle applicazioni psicologiche.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Fondamenti della probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#sigma-algebra",
    "href": "chapters/probability/03_prob_on_general_spaces.html#sigma-algebra",
    "title": "26¬† Fondamenti della probabilit√†",
    "section": "26.2 \\(\\sigma\\)-Algebra",
    "text": "26.2 \\(\\sigma\\)-Algebra\nUna \\(\\sigma\\)-algebra √® una struttura matematica che permette di definire in modo coerente quali sottoinsiemi di un insieme sono ‚Äúmisurabili‚Äù.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Fondamenti della probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#definizione-di-sigma-algebra",
    "href": "chapters/probability/03_prob_on_general_spaces.html#definizione-di-sigma-algebra",
    "title": "26¬† Fondamenti della probabilit√†",
    "section": "26.3 Definizione di \\(\\sigma\\)-Algebra",
    "text": "26.3 Definizione di \\(\\sigma\\)-Algebra\nUna \\(\\sigma\\)-algebra √® una collezione di sottoinsiemi di uno spazio \\(X\\) che soddisfa le seguenti propriet√†:\n\nChiusura rispetto al complemento: Se un sottoinsieme \\(A\\) appartiene alla \\(\\sigma\\)-algebra \\(\\mathcal{F}\\), allora anche il suo complemento \\(A^c\\) appartiene a \\(\\mathcal{F}\\). Questo significa che se \\(\\mathcal{F}\\) contiene un certo sottoinsieme, deve contenere anche tutti gli elementi che non sono in quel sottoinsieme.\nChiusura rispetto alle unioni numerabili: Se una sequenza numerabile di sottoinsiemi \\(A_1, A_2, A_3, \\ldots\\) appartiene alla \\(\\sigma\\)-algebra \\(\\mathcal{F}\\), allora anche l‚Äôunione di tutti questi sottoinsiemi appartiene a \\(\\mathcal{F}\\). Questo implica che se \\(\\mathcal{F}\\) contiene una serie di sottoinsiemi, deve contenere anche il loro insieme unito.\nInclusione dello spazio campionario: Lo spazio campionario \\(X\\) stesso deve appartenere alla \\(\\sigma\\)-algebra \\(\\mathcal{F}\\). In altre parole, l‚Äôintero insieme \\(X\\) √® considerato un sottoinsieme misurabile.\n\nLa chiusura in questo contesto significa che la collezione \\(\\mathcal{F}\\) √® stabile rispetto a determinate operazioni insiemistiche. In particolare, se si applicano le operazioni di complemento o di unione numerabile a elementi della \\(\\sigma\\)-algebra, i risultati di queste operazioni rimarranno all‚Äôinterno della stessa \\(\\sigma\\)-algebra. Questo garantisce che la \\(\\sigma\\)-algebra non ‚Äúperda‚Äù elementi a causa di queste operazioni, mantenendo cos√¨ la coerenza e la completezza della collezione di sottoinsiemi.\n\n26.3.1 Spazio Misurabile\nUn insieme dotato di una \\(\\sigma\\)-algebra, \\((X, \\mathcal{X})\\), √® detto spazio misurabile. Gli elementi di una \\(\\sigma\\)-algebra sono noti come sottoinsiemi misurabili, mentre i sottoinsiemi non appartenenti alla \\(\\sigma\\)-algebra sono detti non misurabili. La distinzione tra sottoinsiemi misurabili e non misurabili √® cruciale per evitare comportamenti anomali e controintuitivi nella teoria della misura e della probabilit√†.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Fondamenti della probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#gli-assiomi-di-kolmogorov",
    "href": "chapters/probability/03_prob_on_general_spaces.html#gli-assiomi-di-kolmogorov",
    "title": "26¬† Fondamenti della probabilit√†",
    "section": "26.4 Gli Assiomi di Kolmogorov",
    "text": "26.4 Gli Assiomi di Kolmogorov\nUna volta definita una \\(\\sigma\\)-algebra, √® possibile introdurre la probabilit√† come una misura definita su questa collezione di sottoinsiemi. Gli assiomi di Kolmogorov stabiliscono le propriet√† fondamentali che ogni funzione di probabilit√† deve soddisfare:\n\nNon negativit√†: Per qualsiasi evento \\(A\\) nello spazio campionario \\(\\Omega\\), la probabilit√† di \\(A\\) √® non negativa.\n\\[\nP(A) \\geq 0.\n\\]\nNormalizzazione: La probabilit√† dell‚Äôintero spazio campionario \\(\\Omega\\) √® 1.\n\\[\nP(\\Omega) = 1.\n\\]\nAdditivit√† numerabile: Per qualsiasi sequenza di eventi mutuamente esclusivi \\({A_i}_{i=1}^\\infty \\subset \\mathcal{F}\\) (cio√® \\(A_i \\cap A_j = \\varnothing\\) per \\(i \\neq j\\)), la probabilit√† della loro unione √® la somma delle loro probabilit√†.\n\\[\nP\\left(\\bigcup_{i=1}^{\\infty} A_i\\right) = \\sum_{i=1}^{\\infty} P(A_i).\n\\]\n\n\n26.4.1 Connessione tra \\(\\sigma\\)-Algebra e Probabilit√†\nGli assiomi di Kolmogorov richiedono una \\(\\sigma\\)-algebra \\(\\mathcal{F}\\) come base per definire una misura di probabilit√† \\(P\\). La \\(\\sigma\\)-algebra delimita l‚Äôinsieme di sottoinsiemi dello spazio \\(X\\) per i quali la probabilit√† √® ben definita.\n\nNon negativit√† La misura di probabilit√† assegna un valore non negativo a ogni evento in \\(\\mathcal{F}\\).\nNormalizzazione garantisce che \\(P(\\Omega) = 1\\), garantendo coerenza nella distribuzione della probabilit√†.\nAdditivit√† numerabile: La chiusura della \\(\\sigma\\)-algebra rispetto alle unioni numerabili consente di applicare l‚Äôadditivit√† anche a collezioni infinite di eventi.\n\nIn sintesi, gli assiomi di Kolmogorov richiedono una \\(\\sigma\\)-algebra come struttura all‚Äôinterno della quale queste propriet√† valgono. La \\(\\sigma\\)-algebra √® quindi la collezione di eventi per i quali la misura di probabilit√† √® ben definita e coerente con gli assiomi di Kolmogorov.\n\n26.4.1.1 Esempio di \\(\\sigma\\)-Algebra\nConsideriamo lo spazio campionario \\(\\Omega = {1, 2, 3}\\). Una possibile \\(\\sigma\\)-algebra su \\(\\Omega\\) √®:\n\\(\\mathcal{F}\\) = {\\(\\varnothing\\),{1},{2,3}, {1, 2, 3}}.\nQuesta \\(\\sigma\\)-algebra soddisfa tutte le propriet√† richieste:\n\nLo spazio campionario \\(\\Omega\\) e l‚Äôinsieme vuoto \\(\\varnothing\\) appartengono a \\(\\mathcal{F}\\).\nIl complemento di ogni sottoinsieme in \\(\\mathcal{F}\\) appartiene ancora a \\(\\mathcal{F}\\).\nL‚Äôunione di qualsiasi collezione di sottoinsiemi in \\(\\mathcal{F}\\) appartiene a \\(\\mathcal{F}\\).\n\nIn conclusione, la \\(\\sigma\\)-algebra √® un concetto essenziale nella teoria della probabilit√†, poich√© delimita quali eventi possono essere misurati e assegnati una probabilit√†. Attraverso gli assiomi di Kolmogorov, questa struttura consente di costruire un sistema probabilistico coerente, garantendo che la probabilit√† sia definita in modo rigoroso e che operazioni come complemento, unione e intersezione numerabili siano sempre ben poste.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Fondamenti della probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#probabilit√†",
    "href": "chapters/probability/03_prob_on_general_spaces.html#probabilit√†",
    "title": "26¬† Fondamenti della probabilit√†",
    "section": "26.5 Probabilit√†",
    "text": "26.5 Probabilit√†\nUna volta definiti gli assiomi di Kolmogorov, √® possibile introdurre formalmente il concetto di probabilit√†.\nLa probabilit√† di un evento √® una misura numerica che quantifica il grado di fiducia nel verificarsi di tale evento, in accordo con gli assiomi di Kolmogorov. Pi√π precisamente:\n\nSe \\(P(A) = 0\\), l‚Äôevento \\(A\\) √® impossibile.\nSe \\(P(A) = 1\\), l‚Äôevento \\(A\\) √® certo.\n\nPer indicare la probabilit√† che un evento \\(A\\) non si verifichi, si usa la notazione \\(P(A^c)\\), dove:\n\\[\nP(A^c) = 1 - P(A).\n\\]\n\n26.5.1 Propriet√† Derivate dagli Assiomi di Kolmogorov\nGli assiomi di Kolmogorov implicano alcune propriet√† fondamentali, tra cui:\n\n\\(P(\\varnothing) = 0\\) (la probabilit√† dell‚Äôevento impossibile √® nulla),\n\\(0 \\leq P(A) \\leq 1\\) (la probabilit√† √® sempre compresa tra 0 e 1),\n\\(P(A^c) = 1 - P(A)\\) (probabilit√† del complemento),\nSe \\(A \\subset B\\), allora \\(P(A) \\leq P(B)\\) (monotonia),\nSe \\(A \\cap B = \\varnothing\\), allora \\(P(A \\cup B) = P(A) + P(B)\\) (additivit√† per eventi incompatibili).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Fondamenti della probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#regola-della-somma",
    "href": "chapters/probability/03_prob_on_general_spaces.html#regola-della-somma",
    "title": "26¬† Fondamenti della probabilit√†",
    "section": "26.6 Regola della Somma",
    "text": "26.6 Regola della Somma\nLa regola della somma permette di calcolare la probabilit√† dell‚Äôunione di due eventi \\(A\\) e \\(B\\), cio√® la probabilit√† che si verifichi \\(A\\) oppure \\(B\\). La formula dipende dal fatto che i due eventi siano incompatibili (mutuamente esclusivi) o meno.\n\n26.6.1 Caso 1: Eventi incompatibili\nDue eventi \\(A\\) e \\(B\\) sono detti incompatibili o mutuamente esclusivi se non possono verificarsi contemporaneamente. In altre parole, la probabilit√† della loro intersezione √® nulla:\n\\[\nP(A \\cap B) = 0.\n\\]\nIn questo caso, la probabilit√† dell‚Äôunione di \\(A\\) e \\(B\\) si calcola semplicemente sommando le probabilit√† individuali:\n\\[\nP(A \\text{ oppure } B) = P(A) + P(B).\n\\]\n\n26.6.1.1 Rappresentazione grafica\nNei diagrammi, gli eventi incompatibili sono rappresentati come aree che non si sovrappongono. La probabilit√† dell‚Äôunione corrisponde alla somma delle aree associate ai due eventi.\n\n\n26.6.1.2 Esempio: Negazione di un evento\nUn esempio classico di eventi incompatibili si ha quando \\(B\\) √® il complemento di \\(A\\), ovvero \\(B = A^c\\). Poich√© \\(A\\) oppure \\(A^c\\) rappresenta l‚Äôintero spazio campionario, la loro somma deve essere uguale a 1:\n\\[\nP(A) + P(A^c) = 1.\n\\]\nDa questa relazione segue che:\n\\[\nP(A^c) = 1 - P(A).\n\\]\n\n\n\n26.6.2 Caso 2: Eventi non incompatibili\nQuando i due eventi \\(A\\) e \\(B\\) possono verificarsi contemporaneamente, si deve tener conto della probabilit√† della loro intersezione \\(P(A \\cap B)\\). In questo caso, la regola della somma diventa:\n\\[\nP(A \\text{ oppure } B) = P(A) + P(B) - P(A \\cap B).\n\\]\n\n26.6.2.1 Perch√© sottrarre \\(P(A \\cap B)\\)?\nIl termine \\(P(A \\cap B)\\) rappresenta la probabilit√† che entrambi gli eventi si verifichino. Poich√© questa probabilit√† √® gi√† inclusa in \\(P(A)\\) e in \\(P(B)\\), sottrarla evita di conteggiarla due volte.\n\n\n26.6.2.2 Rappresentazione grafica\nIn un diagramma, gli eventi non incompatibili sono rappresentati da aree che si sovrappongono. La probabilit√† dell‚Äôunione corrisponde alla somma delle aree associate ai due eventi, meno l‚Äôarea della sovrapposizione.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Fondamenti della probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#legge-della-probabilit√†-totale",
    "href": "chapters/probability/03_prob_on_general_spaces.html#legge-della-probabilit√†-totale",
    "title": "26¬† Fondamenti della probabilit√†",
    "section": "26.7 Legge della Probabilit√† Totale",
    "text": "26.7 Legge della Probabilit√† Totale\nLa legge della probabilit√† totale consente di calcolare la probabilit√† di un evento \\(A\\) suddividendo lo spazio campionario in sottoinsiemi mutuamente esclusivi e completi, detti partizioni. Questo metodo √® utile per decomporre un problema complesso in elementi pi√π semplici.\n\n26.7.1 Caso base: Partizione con due eventi\nSe gli eventi \\(B\\) e \\(B^c\\) formano una partizione dello spazio campionario (ossia sono mutuamente esclusivi e la loro unione copre l‚Äôintero spazio), allora si pu√≤ scrivere:\n\\[\nP(A) = P(A \\cap B) + P(A \\cap B^c).\n\\]\nIn altre parole, la probabilit√† di \\(A\\) √® data dalla somma delle probabilit√† delle sue intersezioni con \\(B\\) e con il complemento di \\(B\\).\n\n\n26.7.2 Estensione a pi√π eventi\nSe lo spazio campionario √® suddiviso in \\(n\\) sottoinsiemi \\(B_1, B_2, \\dots, B_n\\), tali che:\n\nGli eventi \\(B_1, B_2, \\dots, B_n\\) sono mutuamente esclusivi (\\(B_i \\cap B_j = \\varnothing\\) per \\(i \\neq j\\)).\nLa loro unione copre l‚Äôintero spazio campionario (\\(\\bigcup_{i=1}^n B_i = \\Omega\\)),\n\nallora la probabilit√† di \\(A\\) si calcola come:\n\\[\nP(A) = P(A \\cap B_1) + P(A \\cap B_2) + \\dots + P(A \\cap B_n).\n\\]\n\n\n26.7.3 Applicazioni\nQuesta legge √® utile nei casi in cui un problema complesso pu√≤ essere scomposto in diversi scenari o categorie (\\(B_1, B_2, \\dots, B_n\\)). In pratica, permette di calcolare \\(P(A)\\) sommando le probabilit√† di \\(A\\) all‚Äôinterno di ciascuna categoria, tenendo conto delle rispettive probabilit√†.\n\n\n26.7.4 Esempio\nImmagina che una scuola abbia due corsi, \\(B\\) e \\(B^c\\), e che un certo evento \\(A\\) (ad esempio, un esame superato) possa avvenire sia tra gli studenti del corso \\(B\\) che tra quelli di \\(B^c\\). Per calcolare la probabilit√† totale che \\(A\\) si verifichi, possiamo considerare separatamente i due gruppi:\n\\[\nP(A) = P(A \\cap B) + P(A \\cap B^c).\n\\]\nIn generale, la legge della probabilit√† totale aiuta a gestire problemi complessi e ad assicurare che ogni contributo venga considerato una sola volta, evitando duplicazioni o omissioni.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Fondamenti della probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#probabilit√†-calcolo-combinatorio-e-simulazioni",
    "href": "chapters/probability/03_prob_on_general_spaces.html#probabilit√†-calcolo-combinatorio-e-simulazioni",
    "title": "26¬† Fondamenti della probabilit√†",
    "section": "26.8 Probabilit√†, Calcolo Combinatorio e Simulazioni",
    "text": "26.8 Probabilit√†, Calcolo Combinatorio e Simulazioni\nMolti problemi di probabilit√† scolastici si basano sul calcolo combinatorio per determinare la probabilit√† di un evento. La struttura generale di questi problemi consiste nel:\n\nDefinire gli eventi di successo: identificare tutte le configurazioni compatibili con l‚Äôevento di interesse.\nContare le possibilit√†: calcolare il numero di eventi di successo e rapportarlo al numero totale di eventi nello spazio campionario.\n\nAd esempio, supponiamo di avere una scatola con 10 palline numerate da 1 a 10 e di voler calcolare la probabilit√† di estrarre una pallina con un numero pari:\n\nEventi di successo: {2, 4, 6, 8, 10} (5 casi).\nEventi totali: {1, 2, 3, 4, 5, 6, 7, 8, 9, 10} (10 casi).\n\nLa probabilit√† √® quindi:\n\\[\nP(\\text{numero pari}) = \\frac{\\text{numero di eventi di successo}}{\\text{numero totale di eventi}} = \\frac{5}{10} = 0.5.\n\\]\nPer problemi pi√π complessi, come il calcolo della probabilit√† di ottenere una determinata combinazione di carte o di formare gruppi specifici da una popolazione, utilizziamo tecniche combinatorie pi√π avanzate, come permutazioni e combinazioni.\n\n26.8.1 Gli Errori dei Grandi Matematici\nLa storia della teoria della probabilit√† √® ricca di esempi che mostrano quanto questi problemi possano essere controintuitivi, persino per i grandi matematici. Uno di questi riguarda Jakob Bernoulli, pioniere della probabilit√†, nel suo libro Ars Conjectandi (1713). Un problema che affront√≤ riguardava il calcolo della probabilit√† di ottenere almeno una testa in 8 lanci di una moneta equa.\nPer risolvere il problema, √® utile considerare la probabilit√† complementare, ovvero quella di non ottenere alcuna testa (solo croci), e poi sottrarla da 1:\n\nCalcolo della probabilit√† complementare: La probabilit√† di ottenere solo croci in un lancio √® \\(\\frac{1}{2}\\). In 8 lanci consecutivi, questa diventa:\n\\[\nP(\\text{solo croci}) = \\left(\\frac{1}{2}\\right)^8 = \\frac{1}{256}.\n\\]\nCalcolo della probabilit√† di almeno una testa: \\[\nP(\\text{almeno una testa}) = 1 - P(\\text{solo croci}) = 1 - \\frac{1}{256} = \\frac{255}{256}.\n\\]\n\nTuttavia, Bernoulli commise un errore nel conteggio combinatorio, sottostimando la probabilit√† corretta. Questo errore fu poi corretto da altri matematici, come suo nipote Daniel Bernoulli, che affin√≤ l‚Äôuso del calcolo combinatorio.\n\n\n26.8.2 Simulazioni Monte Carlo e Problemi Probabilistici\nUno degli aspetti pi√π impegnativi della probabilit√† √® che molti problemi non si prestano a soluzioni immediate o intuitive. Per affrontarli, si possono adottare due approcci principali. Il primo consiste nell‚Äôapplicare i teoremi della teoria della probabilit√†, un metodo rigoroso ma spesso controintuitivo. Il secondo approccio √® quello della simulazione Monte Carlo, che permette di ottenere una soluzione approssimata, ma molto vicina al valore reale, seguendo una procedura pi√π accessibile e intuitiva. Questo metodo prende il nome dal famoso Casin√≤ di Monte Carlo a Monaco, anche se pu√≤ essere semplicemente definito come ‚Äúmetodo di simulazione.‚Äù\nLa simulazione Monte Carlo appartiene a una classe generale di metodi stocastici, che si contrappongono ai metodi deterministici. Questi metodi consentono di risolvere approssimativamente problemi analitici attraverso la generazione casuale delle quantit√† di interesse. Tra le tecniche comunemente utilizzate troviamo il campionamento con reinserimento, in cui la stessa unit√† pu√≤ essere selezionata pi√π volte, e il campionamento senza reinserimento, dove ogni unit√† pu√≤ essere selezionata una sola volta. Questi strumenti rappresentano un mezzo potente e pratico per affrontare problemi complessi.\n\n26.8.2.1 Il Problema dei Complenni\nUn esempio classico di applicazione del metodo Monte Carlo √® il calcolo delle probabilit√† relative a vari eventi definiti attraverso il modello dell‚Äôurna. Tra questi, abbiamo il celebre problema dei compleanni.\nIl problema dei compleanni esplora la probabilit√† che, in un gruppo di \\(n\\) persone, almeno due persone condividano la stessa data di nascita. Supponendo che i compleanni siano distribuiti uniformemente su 365 giorni (ignorando anni bisestili), il problema sorprende molte persone per il fatto che gi√† con 23 persone la probabilit√† di una coincidenza √® superiore al 50%.\n\n26.8.2.1.1 Soluzione analitica\n\nProbabilit√† complementari\n\nIl problema pu√≤ essere visto in due modi complementari:\n\nCaso 1: Tutti i compleanni sono diversi (cio√® nessuna persona condivide il compleanno con un‚Äôaltra).\nCaso 2: Almeno due persone condividono lo stesso compleanno.\n\nPoich√© questi due casi sono mutuamente esclusivi e coprono tutte le possibilit√†, la somma delle loro probabilit√† deve essere 1:\n\\[\nP(\\text{almeno un compleanno in comune}) = 1 - P(\\text{nessun compleanno in comune}).\n\\]\nQuindi, per calcolare la probabilit√† che almeno due persone abbiano lo stesso compleanno, calcoliamo prima la probabilit√† del caso opposto (nessun compleanno in comune) e poi sottraiamo questo valore da 1.\n\nProbabilit√† che tutti i compleanni siano diversi\n\nPer calcolare \\(P(\\text{nessun compleanno in comune})\\), seguiamo questo ragionamento:\n\nLa prima persona pu√≤ scegliere liberamente un giorno del calendario: ci sono 365 possibilit√†.\nLa seconda persona deve avere un compleanno diverso dalla prima: ci sono 364 giorni disponibili.\nLa terza persona deve avere un compleanno diverso dai primi due: ci sono 363 giorni disponibili.\n\nQuesto continua fino alla \\(n\\)-esima persona, che ha \\(365 - n + 1\\) giorni disponibili.\nLa probabilit√† che tutti i compleanni siano diversi si ottiene moltiplicando queste probabilit√† individuali, e poi normalizzando rispetto a tutte le possibili scelte di compleanno (\\(365^n\\)):\n\\[\nP(\\text{nessun compleanno in comune}) = \\frac{365}{365} \\cdot \\frac{364}{365} \\cdot \\frac{363}{365} \\cdot \\ldots \\cdot \\frac{365-n+1}{365}.\n\\]\nQuesto prodotto pu√≤ essere scritto in forma compatta usando il fattoriale:\n\\[\nP(\\text{nessun compleanno in comune}) = \\frac{365!}{(365-n)! \\cdot 365^n}.\n\\]\n\nProbabilit√† di almeno un compleanno in comune\n\nOra possiamo calcolare la probabilit√† che almeno due persone abbiano lo stesso compleanno come il complemento:\n\\[\nP(\\text{almeno un compleanno in comune}) = 1 - P(\\text{nessun compleanno in comune}).\n\\]\n\n\n26.8.2.1.2 Soluzione con simulazione in R\nPer risolvere il problema tramite simulazione, possiamo generare gruppi casuali di \\(n\\) persone, assegnando loro un compleanno casuale tra 1 e 365. Per ogni gruppo, verifichiamo se almeno due persone condividono lo stesso compleanno.\nEcco il codice R:\n\n# Numero di simulazioni\nnum_simulazioni &lt;- 10000\n\n# Funzione per simulare il problema del compleanno\nsimula_compleanno &lt;- function(n) {\n  # Conta il numero di successi (almeno un compleanno in comune)\n  successi &lt;- 0\n  \n  # Loop per il numero di simulazioni\n  for (i in 1:num_simulazioni) {\n    # Genera n compleanni casuali\n    compleanni &lt;- sample(1:365, n, replace = TRUE)\n    \n    # Verifica se ci sono duplicati\n    if (any(duplicated(compleanni))) {\n      successi &lt;- successi + 1\n    }\n  }\n  \n  # Calcola la probabilit√† stimata\n  return(successi / num_simulazioni)\n}\n\n\n# Proviamo con diversi valori di n\nset.seed(123)  # Fissiamo il seme per riproducibilit√†\nrisultati &lt;- sapply(1:50, simula_compleanno)\n\n# Plot dei risultati\nplot(\n  1:50, risultati, type = \"b\", col = \"blue\", \n  xlab = \"Numero di persone (n)\", \n  ylab = \"Probabilit√† stimata\", \n  main = \"Problema del Compleanno (Simulazione)\"\n)\nabline(h = 0.5, col = \"red\", lty = 2)  # Linea di riferimento al 50%\n\n\n\n\n\n\n\n\n\nSimulazioni: Per ogni gruppo di \\(n\\), si eseguono 10.000 simulazioni, in cui si generano \\(n\\) compleanni casuali tra 1 e 365.\nDuplicati: La funzione duplicated() verifica se ci sono compleanni ripetuti.\nCalcolo della probabilit√†: La proporzione di simulazioni in cui si verifica almeno un compleanno condiviso rappresenta la probabilit√† stimata.\nVisualizzazione: Si tracciano le probabilit√† per diversi valori di \\(n\\), evidenziando il punto in cui la probabilit√† supera il 50%.\n\n\n\n26.8.2.1.3 Risultati attesi\n\nCon circa 23 persone, la probabilit√† stimata sar√† superiore a 0.5.\nIl grafico mostra una curva crescente con un rapido aumento della probabilit√† per \\(n\\) piccoli e un asintoto vicino a 1 per \\(n\\) grandi.\n\nQuesto approccio permette di comprendere intuitivamente il problema e di verificare i risultati teorici con la simulazione.\n\n\n26.8.2.1.4 Assunzioni\nIl problema dei compleanni evidenzia non solo l‚Äôefficacia dell‚Äôapproccio simulativo nel semplificare la soluzione rispetto all‚Äôanalisi formale, ma anche l‚Äôimportanza delle assunzioni che entrambi i metodi condividono. In questo caso, l‚Äôassunzione √® che la probabilit√† di nascita sia uniformemente distribuita nei 365 giorni dell‚Äôanno ‚Äî un‚Äôipotesi semplificativa che non rispecchia la realt√†.\nQuesto esempio sottolinea un principio fondamentale dei modelli probabilistici (e scientifici in generale): ogni modello si basa su un insieme di ipotesi che ne delimitano la validit√† e l‚Äôapplicabilit√†. Valutare criticamente la plausibilit√† di tali ipotesi √® dunque essenziale per garantire che il modello fornisca una rappresentazione coerente e utile del fenomeno in studio.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Fondamenti della probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#riflessioni-conlusive",
    "href": "chapters/probability/03_prob_on_general_spaces.html#riflessioni-conlusive",
    "title": "26¬† Fondamenti della probabilit√†",
    "section": "26.9 Riflessioni Conlusive",
    "text": "26.9 Riflessioni Conlusive\nDalla rigorosa applicazione del calcolo combinatorio agli approcci pi√π intuitivi delle simulazioni Monte Carlo, la probabilit√† fornisce strumenti fondamentali per risolvere problemi complessi. Comprendere le probabilit√† ci consente di prendere decisioni informate in situazioni di incertezza e di formulare previsioni affidabili. Una solida conoscenza delle basi della probabilit√† ci permette di affrontare una vasta gamma di problemi e di fare scelte ponderate basate sulla probabilit√† dei vari esiti possibili. Tuttavia, √® importante ricordare che i modelli probabilistici sono solo approssimazioni della realt√† e possono essere influenzati da semplificazioni o dalle limitazioni dei dati disponibili. Pertanto, √® fondamentale interpretare i risultati con cautela e avere piena consapevolezza delle assunzioni che sottendono le analisi.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Fondamenti della probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/03_prob_on_general_spaces.html#informazioni-sullambiente-di-sviluppo",
    "title": "26¬† Fondamenti della probabilit√†",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: US/Pacific\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] reshape2_1.4.4   ggokabeito_0.1.0 see_0.9.0        gridExtra_2.3   \n#&gt;  [5] patchwork_1.3.0  bayesplot_1.11.1 psych_2.4.12     scales_1.3.0    \n#&gt;  [9] markdown_1.13    knitr_1.49       lubridate_1.9.4  forcats_1.0.0   \n#&gt; [13] stringr_1.5.1    dplyr_1.1.4      purrr_1.0.2      readr_2.1.5     \n#&gt; [17] tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0 \n#&gt; [21] rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     plyr_1.8.9        rprojroot_2.0.4  \n#&gt; [13] jsonlite_1.8.9    mnormt_2.1.1      cli_3.6.3         rlang_1.1.4      \n#&gt; [17] munsell_0.5.1     withr_3.0.2       yaml_2.3.10       tools_4.4.2      \n#&gt; [21] parallel_4.4.2    tzdb_0.4.0        colorspace_2.1-1  pacman_0.5.1     \n#&gt; [25] vctrs_0.6.5       R6_2.5.1          lifecycle_1.0.4   htmlwidgets_1.6.4\n#&gt; [29] pkgconfig_2.0.3   pillar_1.10.1     gtable_0.3.6      Rcpp_1.0.13-1    \n#&gt; [33] glue_1.8.0        xfun_0.50         tidyselect_1.2.1  farver_2.1.2     \n#&gt; [37] htmltools_0.5.8.1 nlme_3.1-166      rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Fondamenti della probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#bibliografia",
    "href": "chapters/probability/03_prob_on_general_spaces.html#bibliografia",
    "title": "26¬† Fondamenti della probabilit√†",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlitzstein, J. K., & Hwang, J. (2019). Introduction to probability. CRC Press.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Fondamenti della probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html",
    "href": "chapters/probability/04_conditional_prob.html",
    "title": "27¬† Probabilit√† condizionata",
    "section": "",
    "text": "27.1 Introduzione\nLa probabilit√† condizionata si riferisce al calcolo della probabilit√† di un evento, tenendo conto che un altro evento si √® gi√† verificato. Questo concetto √® cruciale perch√© riflette come aggiorniamo le nostre credenze alla luce di nuove evidenze o informazioni. Per esempio, immaginiamo di voler stimare la probabilit√† di pioggia per domani. La nostra stima iniziale cambia se oggi osserviamo un cielo nuvoloso. Il fatto che oggi sia nuvoloso ‚Äúcondiziona‚Äù la nostra valutazione della probabilit√† di pioggia per domani.\nQuesto processo di aggiornamento delle nostre credenze in base a nuove osservazioni √® continuo. Una nuova evidenza coerente con una credenza esistente potrebbe rafforzarla, mentre un‚Äôosservazione inaspettata potrebbe metterla in discussione. La probabilit√† condizionata non √® solo un concetto teorico, ma ha applicazioni pratiche sia nella vita quotidiana che in ambito scientifico. In realt√†, si potrebbe argomentare che tutte le probabilit√† sono in qualche modo condizionate da un certo contesto o da informazioni preesistenti, anche se non sempre lo specifichiamo esplicitamente.\nIn sintesi, la probabilit√† condizionata ci fornisce un framework per comprendere e quantificare come le nostre credenze dovrebbero evolversi man mano che acquisiamo nuove informazioni, rendendo il concetto di probabilit√† uno strumento dinamico e potente per gestire l‚Äôincertezza.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>Probabilit√† condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#indipendenza-stocastica",
    "href": "chapters/probability/04_conditional_prob.html#indipendenza-stocastica",
    "title": "27¬† Probabilit√† condizionata",
    "section": "27.2 Indipendenza Stocastica",
    "text": "27.2 Indipendenza Stocastica\nIl concetto di indipendenza √® cruciale nel contesto della probabilit√† condizionata, facilitando notevolmente i calcoli in numerosi problemi e indicando come la presenza di un evento non influenzi l‚Äôoccorrenza di un altro.\n\n27.2.1 Indipendenza di Due Eventi\nDue eventi, \\(A\\) e \\(B\\), sono considerati indipendenti se la realizzazione di uno non altera la probabilit√† di occorrenza dell‚Äôaltro. Formalmente, questa relazione √® espressa come:\n\\[P(A \\cap B) = P(A) P(B),\\]\ndove \\(P(A \\cap B)\\) √® la probabilit√† che \\(A\\) e \\(B\\) si verifichino contemporaneamente. Se questa condizione √® verificata, denotiamo \\(A \\text{ ‚´´ } B\\), indicando che \\(A\\) √® indipendente da \\(B\\).\n\n\n27.2.2 Indipendenza di un Insieme di Eventi\nL‚Äôindipendenza stocastica √® un principio fondamentale nell‚Äôapplicazione statistica della probabilit√†. Un insieme di eventi \\(\\{ A_i : i \\in I \\}\\) √® definito indipendente se per ogni sottoinsieme finito \\(J\\) di \\(I\\), la probabilit√† dell‚Äôintersezione degli eventi in \\(J\\) equivale al prodotto delle loro probabilit√† individuali:\n\\[P \\left( \\bigcap_{i \\in J} A_i \\right) = \\prod_{i \\in J} P(A_i).\\]\nQuesto implica che ogni combinazione finita di eventi nell‚Äôinsieme agisce in maniera indipendente.\nL‚Äôindipendenza pu√≤ essere assunta o derivata, a seconda del contesto. In alcuni modelli o situazioni, assumiamo l‚Äôindipendenza per semplificare i calcoli o per riflettere una conoscenza preesistente. In altri contesti, l‚Äôindipendenza pu√≤ emergere dai dati o da altre propriet√† del modello.\n\n\n27.2.3 Eventi Disgiunti e Indipendenza\nEventi disgiunti, o mutuamente esclusivi, sono quelli che non possono verificarsi contemporaneamente, ossia \\(\\mathbb{P}(A \\cap B) = 0\\). Se due eventi disgiunti hanno probabilit√† positive, essi non possono essere indipendenti, poich√© l‚Äôequazione \\(P(A \\cap B) = P(A) P(B)\\) non pu√≤ essere soddisfatta; \\(P(A \\cap B) = 0\\) non uguaglia \\(P(A) P(B) &gt; 0\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>Probabilit√† condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#probabilit√†-condizionata",
    "href": "chapters/probability/04_conditional_prob.html#probabilit√†-condizionata",
    "title": "27¬† Probabilit√† condizionata",
    "section": "27.3 Probabilit√† Condizionata",
    "text": "27.3 Probabilit√† Condizionata\nLa probabilit√† di un evento √® sempre contestualizzata e varia a seconda del nostro stato di informazione. Con un insieme di informazioni disponibile, attribuiamo una probabilit√† specifica a un evento. Se lo stato informativo cambia, anche la probabilit√† associata deve essere aggiornata. In sostanza, tutte le probabilit√† possono essere considerate condizionate, anche se l‚Äôevento condizionante non √® esplicitato.\nLa probabilit√† condizionata di un evento \\(A\\) dato un altro evento \\(B\\), con \\(P(B) &gt; 0\\), √® definita come:\n\\[\nP(A \\mid B) = \\frac{P(A \\cap B)}{P(B)},\n\\]\ndove \\(P(A \\cap B)\\) √® la probabilit√† congiunta di \\(A\\) e \\(B\\). Questa relazione permette di derivare la regola della moltiplicazione:\n\\[\nP(A \\cap B) = P(A \\mid B)P(B) = P(B \\mid A)P(A),\n\\]\ne una forma alternativa della legge della probabilit√† totale:\n\\[\nP(A) = P(A \\mid B)P(B) + P(A \\mid B^c)P(B^c),\n\\]\ndove \\(B^c\\) rappresenta il complemento di \\(B\\).\nPer spazi campionari discreti, possiamo esprimere la probabilit√† condizionata come:\n\\[\nP(A \\mid B) = \\frac{| A \\cap B |}{| B |}.\n\\]\nLa probabilit√† condizionata ricalibra lo spazio campionario, riducendolo da \\(S\\) a \\(B\\), e non √® definita se \\(P(B) = 0\\).\n\nEsempio 27.1 Lanciamo due dadi equilibrati e vogliamo calcolare la probabilit√† che la somma dei punteggi ottenuti sia minore di 8.\nInizialmente, quando non abbiamo ulteriori informazioni, possiamo calcolare la probabilit√† in modo tradizionale. Ci sono 21 risultati possibili con somma minore di 8. Poich√© ci sono 36 possibili combinazioni di lancio dei due dadi, la probabilit√† di ottenere una somma minore di 8 √® 21/36, che equivale a circa 0.58.\nSupponiamo ora di sapere che la somma del lancio di due dadi ha prodotto un risultato dispari. In questo caso, ci sono solo 18 possibili combinazioni di lancio dei due dadi (dato che abbiamo escluso i risultati pari). Tra essi, vi sono 12 risultati che soddisfano la condizione per cui la somma √® minore di 8. Quindi, la probabilit√† di ottenere una somma minore di 8 cambia da circa 0.58 a 12/18, ovvero 0.67 quando consideriamo l‚Äôinformazione aggiuntiva del risultato dispari.\nSvolgiamo il problema in R:\n\nr &lt;- 1:6\nsample &lt;- expand.grid(i = r, j = r)\nsample\n#&gt;    i j\n#&gt; 1  1 1\n#&gt; 2  2 1\n#&gt; 3  3 1\n#&gt; 4  4 1\n#&gt; 5  5 1\n#&gt; 6  6 1\n#&gt; 7  1 2\n#&gt; 8  2 2\n#&gt; 9  3 2\n#&gt; 10 4 2\n#&gt; 11 5 2\n#&gt; 12 6 2\n#&gt; 13 1 3\n#&gt; 14 2 3\n#&gt; 15 3 3\n#&gt; 16 4 3\n#&gt; 17 5 3\n#&gt; 18 6 3\n#&gt; 19 1 4\n#&gt; 20 2 4\n#&gt; 21 3 4\n#&gt; 22 4 4\n#&gt; 23 5 4\n#&gt; 24 6 4\n#&gt; 25 1 5\n#&gt; 26 2 5\n#&gt; 27 3 5\n#&gt; 28 4 5\n#&gt; 29 5 5\n#&gt; 30 6 5\n#&gt; 31 1 6\n#&gt; 32 2 6\n#&gt; 33 3 6\n#&gt; 34 4 6\n#&gt; 35 5 6\n#&gt; 36 6 6\n\n\nevent &lt;- subset(sample, i + j &lt; 8)\ncat(nrow(event), \"/\", nrow(sample), \"\\n\")\n#&gt; 21 / 36\n\n\nsample_odd &lt;- subset(sample, (i + j) %% 2 != 0)\nsample_odd\n#&gt;    i j\n#&gt; 2  2 1\n#&gt; 4  4 1\n#&gt; 6  6 1\n#&gt; 7  1 2\n#&gt; 9  3 2\n#&gt; 11 5 2\n#&gt; 14 2 3\n#&gt; 16 4 3\n#&gt; 18 6 3\n#&gt; 19 1 4\n#&gt; 21 3 4\n#&gt; 23 5 4\n#&gt; 26 2 5\n#&gt; 28 4 5\n#&gt; 30 6 5\n#&gt; 31 1 6\n#&gt; 33 3 6\n#&gt; 35 5 6\n\n\nevent &lt;- subset(sample_odd, i + j &lt; 8)\ncat(nrow(event), \"/\", nrow(sample_odd), \"\\n\")\n#&gt; 12 / 18\n\nSe applichiamo l‚Äô?eq-prob-cond-def, abbiamo: \\(P(A \\cap B)\\) = 12/36, \\(P(B)\\) = 18/36 e\n\\[\nP(A \\mid B) = \\frac{12}{18}.\n\\]\nQuesto esempio illustra come la probabilit√† di un evento possa variare in base alle informazioni aggiuntive di cui disponiamo. Nel secondo caso, avendo l‚Äôinformazione che la somma √® dispari, la probabilit√† di ottenere una somma minore di 8 aumenta notevolmente rispetto al caso iniziale in cui non avevamo questa informazione.\n\n\nEsempio 27.2 Consideriamo uno screening per la diagnosi precoce del tumore mammario utilizzando un test con determinate caratteristiche:\n\nSensibilit√† del test: 90%. Questo significa che il test classifica correttamente come positivo il 90% delle donne colpite dal cancro al seno.\nSpecificit√† del test: 90%. Ci√≤ indica che il test classifica correttamente come negativo il 90% delle donne che non hanno il cancro al seno.\nPrevalenza del cancro al seno nella popolazione sottoposta allo screening: 1% (0.01). Questo √® il 1% delle donne che ha effettivamente il cancro al seno, mentre il restante 99% (0.99) non ne √® affetto.\n\nOra cerchiamo di rispondere alle seguenti domande:\n\nQual √® la probabilit√† che una donna scelta a caso ottenga una mammografia positiva? Poich√© il 1% delle donne ha il cancro al seno, la probabilit√† di ottenere una mammografia positiva (test positivo) √® pari alla sensibilit√† del test, ovvero 0.90 (cio√® 90%).\nSe la mammografia √® positiva, qual √® la probabilit√† che vi sia effettivamente un tumore al seno?\n\nPer risolvere questo problema, consideriamo un campione di 1000 donne sottoposte al test di screening per il tumore al seno. Di queste 1000 donne:\n\n10 donne (1% del campione) hanno effettivamente il cancro al seno. Per queste 10 donne con il cancro, il test dar√† un risultato positivo (vera positivit√†) in 9 casi (90%).\nPer le restanti 990 donne (99% del campione) che non hanno il cancro al seno, il test dar√† un risultato positivo (falsa positivit√†) in 99 casi (10%).\n\nQuesta situazione pu√≤ essere rappresentata graficamente nel seguente modo:\n\n\n\n\n\n\nFigura¬†27.1: Esiti della mammografia per 1000 donne.\n\n\n\nCombinando i due risultati precedenti, vediamo che il test d√† un risultato positivo per 9 donne che hanno effettivamente il cancro al seno e per 99 donne che non lo hanno, per un totale di 108 risultati positivi su 1000. Pertanto, la probabilit√† di ottenere un risultato positivo al test √® \\(\\frac{108}{1000}\\) = 0.108.\nTuttavia, tra le 108 donne che hanno ottenuto un risultato positivo al test, solo 9 hanno effettivamente il cancro al seno. Quindi, la probabilit√† di avere il cancro al seno, dato un risultato positivo al test, √® pari a \\(\\frac{9}{108}\\) = 0.083, corrispondente all‚Äô8.3%.\nIn questo esempio, la probabilit√† dell‚Äôevento ‚Äúottenere un risultato positivo al test‚Äù √® una probabilit√† non condizionata, poich√© calcoliamo semplicemente la proporzione di risultati positivi nel campione totale. D‚Äôaltra parte, la probabilit√† dell‚Äôevento ‚Äúavere il cancro al seno, dato che il test ha prodotto un risultato positivo‚Äù √® una probabilit√† condizionata, poich√© calcoliamo la proporzione delle donne con il cancro al seno tra quelle che hanno ottenuto un risultato positivo al test.\nQuesto esempio illustra come la conoscenza di ulteriori informazioni (il risultato positivo al test) pu√≤ influenzare la probabilit√† di un evento (avere il cancro al seno), mostrando chiaramente la differenza tra probabilit√† condizionate e non condizionate.\n\n\nEsempio 27.3 Il problema di Monty Hall √® diventato famoso grazie alla rubrica tenuta da Marilyn vos Savant nella rivista Parade, che rispose alla seguente lettera, pubblicata il 9 settembre 1990:\n\n‚ÄúSupponiamo che tu sia in un quiz televisivo, e ti venga data la scelta tra tre porte. Dietro una delle porte c‚Äô√® un‚Äôauto, dietro le altre due ci sono delle capre. Tu scegli una porta, diciamo la numero 1, e il conduttore, che sa cosa c‚Äô√® dietro ogni porta, apre un‚Äôaltra porta, diciamo la numero 3, che contiene una capra. Il conduttore ti chiede quindi se vuoi cambiare la tua scelta e passare alla porta numero 2. √à vantaggioso cambiare la scelta?‚Äù Craig. F. Whitaker, Columbia, MD\n\nLa situazione descritta nella lettera √® simile a quella che i concorrenti affrontavano nel quiz televisivo degli anni ‚Äô70 Let‚Äôs Make a Deal, condotto da Monty Hall e Carol Merrill. Marilyn rispose che il concorrente dovrebbe cambiare la scelta, poich√© se l‚Äôauto √® dietro una delle due porte non scelte (il che √® due volte pi√π probabile rispetto alla porta inizialmente scelta), il concorrente vince cambiando porta. Tuttavia, la sua risposta suscit√≤ una reazione a catena, con molte lettere, persino da parte di matematici, che affermavano che avesse torto. Questo episodio diede origine al problema di Monty Hall e innesc√≤ migliaia di ore di dibattiti.\nQuesto incidente sottolinea un aspetto fondamentale della probabilit√†: spesso, l‚Äôintuizione porta a conclusioni completamente errate. Fino a quando non si affinano le capacit√† nel trattare problemi di probabilit√†, un approccio rigoroso e sistematico √® utile per evitare errori.\nChiarire il Problema\nLa lettera originale di Craig Whitaker √® un po‚Äô vaga, quindi dobbiamo fare delle ipotesi per poter modellare formalmente il gioco. Supponiamo che:\n\nL‚Äôauto sia nascosta in modo casuale ed equiprobabile dietro una delle tre porte.\nIl giocatore scelga una delle tre porte in modo casuale, indipendentemente dalla posizione dell‚Äôauto.\nDopo che il giocatore ha scelto una porta, il conduttore apre un‚Äôaltra porta, che contiene una capra, e offre al giocatore la possibilit√† di mantenere la scelta o cambiarla.\nSe il conduttore ha la possibilit√† di scegliere quale porta aprire (ossia, se ci sono due capre disponibili), sceglie casualmente quale porta aprire.\n\nCon queste assunzioni, possiamo affrontare la domanda: ‚ÄúQual √® la probabilit√† che un giocatore che cambia porta vinca l‚Äôauto?‚Äù\nIl Metodo in Quattro Passi\nOgni problema di probabilit√† riguarda un esperimento o un processo casuale. In questi casi, il problema pu√≤ essere suddiviso in quattro fasi distinte.\nPasso 1: Trovare lo Spazio Campionario\nIl primo passo √® identificare tutti i possibili esiti dell‚Äôesperimento. Nel problema di Monty Hall, ci sono tre quantit√† determinate casualmente:\n\nLa porta che nasconde l‚Äôauto.\nLa porta scelta inizialmente dal giocatore.\nLa porta che il conduttore apre per rivelare una capra.\n\nUn diagramma ad albero pu√≤ aiutarci a visualizzare il problema, dato che il numero di esiti non √® troppo grande e la struttura √® semplice. Il primo evento casuale √® la posizione dell‚Äôauto, che rappresentiamo con tre rami in un albero. Ogni ramo corrisponde a una delle porte. La seconda quantit√† casuale √® la porta scelta dal giocatore, rappresentata nel secondo livello dell‚Äôalbero, e la terza quantit√† casuale √® la porta che il conduttore apre, mostrata nel terzo livello.\nEcco un esempio di diagramma ad albero che rappresenta questa situazione:\n\n\n\n\n\n\nFigura¬†27.2: Il diagramma ad albero per il Problema di Monty Hall mostra le probabilit√† associate a ogni possibile esito. I pesi sugli archi rappresentano la probabilit√† di seguire quel particolare percorso, dato che ci troviamo nel nodo padre. Ad esempio, se l‚Äôauto si trova dietro la porta A, la probabilit√† che il giocatore scelga inizialmente la porta B √® pari a 1/3. La colonna pi√π a destra del diagramma mostra la probabilit√† di ciascun esito finale. Ogni probabilit√† di esito √® calcolata moltiplicando le probabilit√† lungo il percorso che parte dalla radice (auto dietro una certa porta) e termina alla foglia (esito finale) (Figura tratta da Lehman, Leighton e Meyer, 2018).\n\n\n\nNel diagramma ad albero, i rami rappresentano le possibili combinazioni delle porte, e le foglie rappresentano gli esiti dell‚Äôesperimento. Ogni foglia dell‚Äôalbero rappresenta un esito dello spazio campionario, che nel nostro caso √® composto da 12 esiti. Per esempio, (Car A, Pick B, Reveal C).\nPasso 2: Definire gli Eventi di Interesse\nL‚Äôevento di interesse √® ‚Äúil giocatore vince cambiando porta‚Äù. Questo significa che, se la porta scelta dal giocatore inizialmente non contiene l‚Äôauto, e il giocatore decide di cambiare porta, allora vincer√†. Gli esiti favorevoli sono quelli in cui la porta inizialmente scelta dal giocatore non nasconde l‚Äôauto, e cambiando porta il giocatore sceglie correttamente la porta che nasconde l‚Äôauto.\nGli esiti che soddisfano questa condizione sono:\n\n(Car A, Pick B, Reveal C)\n(Car A, Pick C, Reveal B)\n(Car B, Pick A, Reveal C)\n(Car B, Pick C, Reveal A)\n(Car C, Pick A, Reveal B)\n(Car C, Pick B, Reveal A)\n\nQuesti esiti sono 6 in totale.\nPasso 3: Calcolare le Probabilit√† degli Esiti\nOgni esito ha una certa probabilit√† di verificarsi. Il modo per determinare la probabilit√† di ciascun esito √® moltiplicare le probabilit√† lungo il percorso nell‚Äôalbero.\nEsempio di calcolo per l‚Äôesito (Car A, Pick B, Reveal C):\n\nLa probabilit√† che l‚Äôauto sia dietro la porta A √® \\(\\frac{1}{3}\\).\nLa probabilit√† che il giocatore scelga la porta B √® \\(\\frac{1}{3}\\).\nLa probabilit√† che il conduttore apra la porta C (che contiene una capra) √® \\(1\\) (poich√© il conduttore deve aprire una porta con una capra, e la porta C √® l‚Äôunica possibile).\n\nLa probabilit√† totale per questo esito √®:\n\\[\nP(\\text{Car A, Pick B, Reveal C}) = \\frac{1}{3} \\times \\frac{1}{3} \\times 1 = \\frac{1}{9}.\n\\]\nProcedendo in modo simile per tutti gli altri esiti, otteniamo le probabilit√† per tutti i 12 esiti.\nPasso 4: Calcolare le Probabilit√† degli Eventi\nLa probabilit√† di vincere cambiando porta √® data dalla somma delle probabilit√† degli esiti favorevoli elencati sopra.\n\\[\n\\begin{aligned}\nP&(\\text{vincere cambiando porta}) = \\notag \\\\\n&\\quad P(\\text{Car A, Pick B, Reveal C}) + P(\\text{Car A, Pick C, Reveal B}) + \\notag\\\\  \n&\\quad P(\\text{Car B, Pick A, Reveal C}) + \\dots \\notag\n\\end{aligned}\n\\]\n\\[\n= \\frac{1}{9} + \\frac{1}{9} + \\frac{1}{9} + \\frac{1}{9} + \\frac{1}{9} + \\frac{1}{9} = \\frac{6}{9} = \\frac{2}{3}.\n\\]\nLa probabilit√† di vincere mantenendo la scelta originale √® semplicemente il complemento:\n\\[\nP(\\text{vincere mantenendo la scelta}) = 1 - P(\\text{vincere cambiando porta}) = 1 - \\frac{2}{3} = \\frac{1}{3}.\n\\]\nLa conclusione √® che il giocatore ha una probabilit√† di vincere pari a \\(\\frac{2}{3}\\) se cambia porta, contro una probabilit√† di \\(\\frac{1}{3}\\) se mantiene la sua scelta iniziale. Cambiare porta √® quindi la strategia vincente. Questo risultato controintuitivo √® il motivo per cui il problema di Monty Hall ha causato tanta confusione inizialmente.\nIl problema di Monty Hall √® un classico esempio di probabilit√† condizionata perch√© la probabilit√† di vincere l‚Äôauto dipende da informazioni aggiuntive ottenute durante il gioco, cio√® la porta che il conduttore apre. Inizialmente, la probabilit√† di trovare l‚Äôauto dietro la porta scelta dal giocatore √® \\(\\frac{1}{3}\\), mentre la probabilit√† che l‚Äôauto sia dietro una delle altre due porte √® \\(\\frac{2}{3}\\).\nQuando il conduttore apre una porta mostrando una capra, fornisce nuove informazioni che cambiano le probabilit√†. Questa nuova informazione condiziona la probabilit√† che l‚Äôauto sia dietro la porta non scelta dal giocatore, facendo s√¨ che la probabilit√† di vincere cambiando porta diventi \\(\\frac{2}{3}\\). Quindi, il problema di Monty Hall √® un esempio di probabilit√† condizionata perch√© l‚Äôaggiornamento delle probabilit√† dipende da un evento intermedio (la scelta della porta aperta dal conduttore).\n\n\nEsempio 27.4 Per confermare il risultato inaspettato del Problema di Monty Hall, √® possibile eseguire una simulazione. In questa simulazione, consideriamo due scenari: uno in cui il concorrente mantiene la sua scelta iniziale e un altro in cui cambia la sua scelta dopo che Monty Hall ha svelato una capra. Ripetendo questa simulazione migliaia di volte, possiamo confrontare i risultati empirici e confermare come effettivamente il cambiamento di scelta aumenti le probabilit√† del concorrente di vincere l‚Äôautomobile.\nDi seguito √® riportato lo script di una simulazione progettata per illustrare il paradosso di Monty Hall.\n\nset.seed(123)  # For reproducibility\n\nporte &lt;- c(\"capra1\", \"capra2\", \"macchina\")  # Define the game\ncounter &lt;- 0\ncontatore_cambio &lt;- 0\nn &lt;- 10000\nporta_vincente &lt;- \"macchina\"\n\nfor (i in 1:n) {\n  scelta_casuale &lt;- sample(porte, 1)\n  porte_rimaste &lt;- porte[porte != scelta_casuale]\n  porta_rivelata &lt;- sample(porte_rimaste[porte_rimaste != porta_vincente], 1)\n  porta_alternativa &lt;- porte[porte != scelta_casuale & porte != porta_rivelata]\n  \n  if (\"macchina\" %in% porta_alternativa) {\n    contatore_cambio &lt;- contatore_cambio + 1\n  }\n  \n  if (scelta_casuale == \"macchina\") {\n    counter &lt;- counter + 1\n  }\n}\n\ncat(counter / n, \"\\n\")  # Proportion of wins without changing the door\n#&gt; 0.334\ncat(contatore_cambio / n, \"\\n\")  # Proportion of wins by changing the door\n#&gt; 0.666\n\nLa simulazione mostra che, effettivamente, la probabilit√† di vincere la macchina aumenta quando il concorrente sceglie di cambiare porta.\n\n\n27.3.1 Il paradosso di Simpson\nNel campo della probabilit√† condizionata, uno dei fenomeni pi√π interessanti e, nel contempo, pi√π controintuitivi, √® rappresentato dal paradosso di Simpson. Il paradosso di Simpson √® un fenomeno statistico in cui una tendenza che appare in diversi gruppi separati di dati scompare o si inverte quando i dati vengono combinati. Questo paradosso mette in luce l‚Äôimportanza di considerare le variabili confondenti e di analizzare i dati con attenzione per evitare conclusioni errate.\n\nEsempio 27.5 Due psicoterapeuti, Rossi e Bianchi, praticano due tipi di terapie: terapia per disturbi d‚Äôansia e coaching per migliorare le prestazioni lavorative. Ogni terapia pu√≤ avere un esito positivo o negativo.\nI rispettivi bilanci dei due terapeuti sono riportati nelle seguenti tabelle.\nRossi\n\n\n\nTipo di terapia\nSuccesso\nFallimento\n\n\n\n\nDisturbi d‚Äôansia\n70\n20\n\n\nCoaching lavorativo\n10\n0\n\n\nTotale\n80\n20\n\n\n\nBianchi\n\n\n\nTipo di terapia\nSuccesso\nFallimento\n\n\n\n\nDisturbi d‚Äôansia\n2\n8\n\n\nCoaching lavorativo\n81\n9\n\n\nTotale\n83\n17\n\n\n\nRossi ha un tasso di successo superiore a Bianchi nella terapia per i disturbi d‚Äôansia: 70 su 90 rispetto a 2 su 10. Anche nel coaching lavorativo, Rossi ha un tasso di successo superiore: 10 su 10 rispetto a 81 su 90. Tuttavia, se aggregiamo i dati dei due tipi di terapia per confrontare i tassi di successo globali, Rossi √® efficace in 80 su 100 terapie, mentre Bianchi in 83 su 100: il tasso di successo globale di Bianchi risulta superiore!\nQuesto fenomeno √® un esempio del paradosso di Simpson, dove una tendenza osservata in diversi gruppi si inverte quando i gruppi sono combinati.\nPer essere pi√π precisi, possiamo calcolare i tassi di successo per ciascun terapeuta e per ciascun tipo di terapia, oltre al tasso di successo globale.\n\nRossi\n\nTasso di successo in terapia per disturbi d‚Äôansia: \\(\\frac{70}{70+20} = \\frac{70}{90} \\approx 0.778\\)\nTasso di successo in coaching lavorativo: \\(\\frac{10}{10+0} = \\frac{10}{10} = 1\\)\nTasso di successo globale: \\(\\frac{70+10}{70+20+10+0} = \\frac{80}{100} = 0.8\\)\n\nBianchi\n\nTasso di successo in terapia per disturbi d‚Äôansia: \\(\\frac{2}{2+8} = \\frac{2}{10} = 0.2\\)\nTasso di successo in coaching lavorativo: \\(\\frac{81}{81+9} = \\frac{81}{90} \\approx 0.9\\)\nTasso di successo globale: \\(\\frac{2+81}{2+8+81+9} = \\frac{83}{100} = 0.83\\)\n\n\nQuello che sta succedendo √® che Rossi, presumibilmente a causa della sua reputazione come terapeuta pi√π esperto, sta effettuando un numero maggiore di terapie per disturbi d‚Äôansia, che sono intrinsecamente pi√π complesse e con una probabilit√† di successo variabile rispetto al coaching lavorativo. Il suo tasso di successo globale √® inferiore non a causa di una minore abilit√† in un particolare tipo di terapia, ma perch√© una frazione maggiore delle sue terapie riguarda casi pi√π complessi.\nL‚Äôaggregazione dei dati tra diversi tipi di terapia presenta un quadro fuorviante delle abilit√† dei terapeuti perch√© perdiamo l‚Äôinformazione su quale terapeuta tende a effettuare quale tipo di terapia. Quando sospettiamo la presenza di variabili di confondimento, come ad esempio il tipo di terapia in questo contesto, √® fondamentale analizzare i dati in modo disaggregato per comprendere con precisione la dinamica in atto.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>Probabilit√† condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#teorema-della-probabilit√†-composta",
    "href": "chapters/probability/04_conditional_prob.html#teorema-della-probabilit√†-composta",
    "title": "27¬† Probabilit√† condizionata",
    "section": "27.4 Teorema della Probabilit√† Composta",
    "text": "27.4 Teorema della Probabilit√† Composta\nIl Teorema della Probabilit√† Composta, noto anche come regola moltiplicativa o regola della catena, permette di calcolare la probabilit√† congiunta di due o pi√π eventi in termini delle loro probabilit√† individuali e condizionate. Questo teorema deriva direttamente dalla definizione di probabilit√† condizionata.\nPer due eventi \\(A\\) e \\(B\\), possiamo esprimere la probabilit√† congiunta \\(P(A \\cap B)\\) utilizzando la relazione:\n\\[\nP(A \\cap B) = P(B)P(A \\mid B) = P(A)P(B \\mid A).\n\\tag{27.1}\\]\nQuesta formula ci dice che la probabilit√† che entrambi gli eventi si verifichino √® data dalla probabilit√† che uno dei due eventi accada, moltiplicata per la probabilit√† che l‚Äôaltro evento si verifichi dato il primo.\nIl teorema della probabilit√† composta si estende facilmente al caso di \\(n\\) eventi \\(A_1, A_2, \\dots, A_n\\). In questo caso, la probabilit√† che tutti gli eventi si verifichino pu√≤ essere scritta come:\n\\[\nP\\left( \\bigcap_{k=1}^n A_k \\right) = \\prod_{k=1}^n P\\left( A_k \\ \\Bigg\\lvert \\ \\bigcap_{j=1}^{k-1} A_j \\right).\n\\tag{27.2}\\]\nQuesto significa che per calcolare la probabilit√† congiunta di tutti gli eventi, dobbiamo moltiplicare:\n\nLa probabilit√† del primo evento.\nLa probabilit√† del secondo evento, condizionata al primo.\nLa probabilit√† del terzo evento, condizionata ai primi due.\nE cos√¨ via, fino all‚Äô\\(n\\)-esimo evento, condizionato a tutti quelli precedenti.\n\nPer fare un esempio, consideriamo il caso di quattro eventi \\(A_1, A_2, A_3, A_4\\). La probabilit√† congiunta √®:\n\\[\nP(A_1 \\cap A_2 \\cap A_3 \\cap A_4) = P(A_1) \\cdot P(A_2 \\mid A_1) \\cdot P(A_3 \\mid A_1 \\cap A_2) \\cdot P(A_4 \\mid A_1 \\cap A_2 \\cap A_3).\n\\]\nIn questa espressione:\n\nLa probabilit√† di \\(A_1\\) √® considerata incondizionata.\nLa probabilit√† di \\(A_2\\) dipende da \\(A_1\\).\nLa probabilit√† di \\(A_3\\) dipende sia da \\(A_1\\) che da \\(A_2\\).\nLa probabilit√† di \\(A_4\\) dipende da tutti gli eventi precedenti.\n\nIl Teorema della Probabilit√† Composta √® una delle basi teoriche pi√π importanti della probabilit√† e viene utilizzato frequentemente in contesti come:\n\nLa modellazione di processi sequenziali o temporali.\nLa decomposizione di probabilit√† complesse in calcoli pi√π semplici.\nLa teoria delle reti bayesiane e la probabilit√† condizionata.\n\nGrazie a questo teorema, possiamo affrontare problemi complessi frammentandoli in parti pi√π gestibili, utilizzando le probabilit√† condizionate per costruire una soluzione graduale e sistematica.\n\nEsempio 27.6 Da un‚Äôurna contenente 6 palline bianche e 4 nere si estrae una pallina per volta, senza reintrodurla nell‚Äôurna. Indichiamo con \\(B_i\\) l‚Äôevento: ‚Äúesce una pallina bianca alla \\(i\\)-esima estrazione‚Äù e con \\(N_i\\) l‚Äôestrazione di una pallina nera. L‚Äôevento: ‚Äúescono due palline bianche nelle prime due estrazioni‚Äù √® rappresentato dalla intersezione \\(\\{B_1 \\cap B_2\\}\\) e, per l‚ÄôEquazione¬†27.1, la sua probabilit√† vale\n\\[\nP(B_1 \\cap B_2) = P(B_1)P(B_2 \\mid B_1).\n\\]\n\\(P(B_1)\\) vale 6/10, perch√© nella prima estrazione \\(\\Omega\\) √® costituito da 10 elementi: 6 palline bianche e 4 nere. La probabilit√† condizionata \\(P(B_2 \\mid B_1)\\) vale 5/9, perch√© nella seconda estrazione, se √® verificato l‚Äôevento \\(B_1\\), lo spazio campionario consiste di 5 palline bianche e 4 nere. Si ricava pertanto:\n\\[\nP(B_1 \\cap B_2) = \\frac{6}{10} \\cdot \\frac{5}{9} = \\frac{1}{3}.\n\\]\nIn modo analogo si ha che\n\\[\nP(N_1 \\cap N_2) = P(N_1)P(N_2 \\mid N_1) = \\frac{4}{10} \\cdot \\frac{3}{9} = \\frac{4}{30}.\n\\]\nSe l‚Äôesperimento consiste nell‚Äôestrazione successiva di 3 palline, la probabilit√† che queste siano tutte bianche, per l‚ÄôEquazione¬†27.2, vale\n\\[\n\\begin{aligned}\nP(B_1 \\cap B_2 \\cap B_3) &=P(B_1)P(B_2 \\mid B_1)P(B_3 \\mid B_1 \\cap B_2) \\notag\\\\\n&=\\frac{6}{10}\\cdot\\frac{5}{9} \\cdot\\frac{4}{8} \\notag\\\\\n&= \\frac{1}{6}.\n\\end{aligned}\n\\]\nLa probabilit√† dell‚Äôestrazione di tre palline nere √® invece:\n\\[\n\\begin{aligned}\nP(N_1 \\cap N_2 \\cap N_3) &= P(N_1)P(N_2 \\mid N_1)P(N_3 \\mid N_1 \\cap N_2)\\notag\\\\\n&= \\frac{4}{10} \\cdot \\frac{3}{9} \\cdot \\frac{2}{8} \\notag\\\\\n&= \\frac{1}{30}.\\notag\n\\end{aligned}\n\\]",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>Probabilit√† condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#il-teorema-della-probabilit√†-totale",
    "href": "chapters/probability/04_conditional_prob.html#il-teorema-della-probabilit√†-totale",
    "title": "27¬† Probabilit√† condizionata",
    "section": "27.5 Il Teorema della Probabilit√† Totale",
    "text": "27.5 Il Teorema della Probabilit√† Totale\nIl teorema della probabilit√† totale (o teorema delle partizioni), che abbiamo gi√† discusso nel capitolo precedente, pu√≤ essere riformulato nei termini della probabilit√† condizionata. Il teorema afferma che, dato uno spazio campionario \\(\\Omega\\) suddiviso in una partizione di \\(n\\) eventi mutualmente esclusivi (cio√® non sovrapposti) e tali che la loro unione formi \\(\\Omega\\), √® possibile calcolare la probabilit√† di un qualsiasi evento \\(E \\subseteq \\Omega\\) sommando la probabilit√† di \\(E\\) su ciascun sottoinsieme della partizione, pesata per la probabilit√† del sottoinsieme.\n\n27.5.1 Definizione Formale\nSiano \\(H_1, H_2, \\dots, H_n\\) eventi che costituiscono una partizione dello spazio campionario \\(\\Omega\\), ossia:\n\n\\(H_i \\cap H_j = \\varnothing\\) per \\(i \\neq j\\) (mutualmente esclusivi),\n\\(\\bigcup_{i=1}^n H_i = \\Omega\\) (copertura completa dello spazio campionario).\n\nAllora, per ogni evento \\(E \\subseteq \\Omega\\), la probabilit√† di \\(E\\) √® data da:\n\\[\nP(E) = \\sum_{i=1}^n P(E \\mid H_i)P(H_i),\n\\tag{27.3}\\]\ndove:\n\n\\(P(E \\mid H_i)\\) √® la probabilit√† condizionata di \\(E\\) dato che si √® verificato l‚Äôevento \\(H_i\\),\n\\(P(H_i)\\) √® la probabilit√† dell‚Äôevento \\(H_i\\).\n\nIl teorema afferma dunque che la probabilit√† di un evento \\(E\\) pu√≤ essere calcolata considerando il contributo di ciascun sottoinsieme della partizione. Ogni termine nella somma rappresenta la probabilit√† di \\(E\\) ‚Äúpassando‚Äù attraverso un sottoinsieme \\(H_i\\), pesata per la probabilit√† che \\(H_i\\) si verifichi.\nIl teorema della probabilit√† totale √® cruciale in molte applicazioni della probabilit√†, in particolare:\n\nTeorema di Bayes: Fornisce il denominatore necessario per normalizzare la probabilit√† condizionata e garantire che la distribuzione a posteriori sia valida.\nProblemi con partizioni: √à utile per calcolare la probabilit√† di un evento \\(E\\) quando si conoscono le probabilit√† condizionate \\(P(E \\mid H_i)\\) e le probabilit√† dei sottoinsiemi \\(P(H_i)\\).\n\nNella sua forma pi√π semplice, l‚Äôapplicazione del teorema si basa su una partizione dello spazio campionario \\(\\Omega\\) in due sottoinsiemi disgiunti, \\(H_1\\) e \\(H_2\\).\n\n\n\n\n\n\nFigura¬†27.3: Partizione dello spazio campionario in due sottoinsiemi.\n\n\n\nLa probabilit√† di un evento \\(E\\) pu√≤ essere calcolata come\n\\[\nP(E) = P(E \\cap H_1) + P(E \\cap H_2),\n\\]\novvero\n\\[\nP(E) = P(E \\mid H_1) P(H_1) + P(E \\mid H_2) P(H_2).\n\\]\nIn sintesi, l‚ÄôEquazione¬†27.3 ci consente di calcolare probabilit√† complesse sfruttando partizioni dello spazio campionario. √à particolarmente utile quando \\(P(E \\mid H_i)\\) e \\(P(H_i)\\) sono disponibili, consentendo una valutazione della probabilit√† di \\(E\\).\n\nEsempio 27.7 Abbiamo tre urne, ciascuna delle quali contiene 100 palline:\n\nUrna 1: 75 palline rosse e 25 palline blu,\nUrna 2: 60 palline rosse e 40 palline blu,\nUrna 3: 45 palline rosse e 55 palline blu.\n\nUna pallina viene estratta a caso da un‚Äôurna anch‚Äôessa scelta a caso. Qual √® la probabilit√† che la pallina estratta sia di colore rosso?\nSia \\(R\\) l‚Äôevento ‚Äúla pallina estratta √® rossa‚Äù e sia \\(U_i\\) l‚Äôevento che corrisponde alla scelta dell‚Äô\\(i\\)-esima urna. Sappiamo che\n\\[\nP(R \\mid U_1) = 0.75, \\quad P(R \\mid U_2) = 0.60, \\quad P(R \\mid U_3) = 0.45.\n\\]\nGli eventi \\(U_1\\), \\(U_2\\) e \\(U_3\\) costituiscono una partizione dello spazio campione in quanto \\(U_1\\), \\(U_2\\) e \\(U_3\\) sono eventi mutualmente esclusivi ed esaustivi, ovvero \\(P(U_1 \\cup U_2 \\cup U_3) = 1.0\\). In base al teorema della probabilit√† totale, la probabilit√† di estrarre una pallina rossa √® dunque\n\\[\n\\begin{split}\nP(R) &= P(R \\mid U_1)P(U_1) + P(R \\mid U_2)P(U_2) + P(R \\mid U_3)P(U_3) \\\\\n&= 0.75 \\cdot \\frac{1}{3}+0.60 \\cdot \\frac{1}{3}+0.45 \\cdot \\frac{1}{3} \\\\\n&=0.60.\n\\end{split}\n\\]",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>Probabilit√† condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#indipendenza-e-probabilit√†-condizionata",
    "href": "chapters/probability/04_conditional_prob.html#indipendenza-e-probabilit√†-condizionata",
    "title": "27¬† Probabilit√† condizionata",
    "section": "27.6 Indipendenza e Probabilit√† Condizionata",
    "text": "27.6 Indipendenza e Probabilit√† Condizionata\nL‚Äôindipendenza tra due eventi \\(A\\) e \\(B\\) pu√≤ essere interpretata intuitivamente attraverso la probabilit√† condizionata. Due eventi sono indipendenti se il verificarsi di uno non influenza la probabilit√† di verificarsi dell‚Äôaltro. In altre parole, conoscere che \\(B\\) √® accaduto non modifica la probabilit√† di \\(A\\), e viceversa.\nQuesta relazione pu√≤ essere formalizzata con le seguenti equazioni:\n\\[\nP(A \\mid B) = \\frac{P(A \\cap B)}{P(B)} = P(A),\n\\]\n\\[\nP(B \\mid A) = \\frac{P(A \\cap B)}{P(A)} = P(B).\n\\]\nPertanto, \\(A\\) e \\(B\\) sono indipendenti se e solo se:\n\\[\nP(A \\mid B) = P(A),\n\\]\n\\[\nP(B \\mid A) = P(B).\n\\]\nQueste condizioni significano che la probabilit√† di \\(A\\) non cambia, indipendentemente dal fatto che \\(B\\) sia accaduto, e lo stesso vale per \\(B\\).\n\n\n\n\n\n\n\n27.6.1 Indipendenza di Tre Eventi\nLa definizione di indipendenza si estende naturalmente a tre eventi \\(A\\), \\(B\\), e \\(C\\), ma con condizioni aggiuntive. Tre eventi sono indipendenti se:\n\nOgni coppia di eventi √® indipendente:\n\\[\n\\begin{align}\nP(A \\cap B) &= P(A) P(B), \\\\\nP(A \\cap C) &= P(A) P(C), \\\\\nP(B \\cap C) &= P(B) P(C).\n\\end{align}\n\\]\nLa probabilit√† congiunta di tutti e tre gli eventi √® uguale al prodotto delle loro probabilit√† individuali:\n\\[\nP(A \\cap B \\cap C) = P(A) P(B) P(C).\n\\]\n\nLe prime tre condizioni verificano l‚Äôindipendenza a coppie (indipendenza a due a due), mentre l‚Äôultima condizione garantisce che i tre eventi siano completamente indipendenti. √à importante notare che l‚Äôindipendenza a due a due non implica necessariamente l‚Äôindipendenza completa: per essere indipendenti nel senso completo, tutte e quattro le condizioni devono essere soddisfatte.\nIn sintesi, l‚Äôindipendenza tra eventi implica che il verificarsi di uno di essi non fornisce alcuna informazione sulla probabilit√† del verificarsi degli altri. Nel caso di due eventi, questa propriet√† si traduce nell‚Äôinvarianza della probabilit√† condizionata. Per tre o pi√π eventi, l‚Äôindipendenza richiede sia l‚Äôindipendenza a coppie sia la condizione pi√π forte sull‚Äôintersezione di tutti gli eventi.\nQuesti concetti sono fondamentali nella probabilit√† e nella statistica, poich√© semplificano molti calcoli e forniscono una base per modelli pi√π complessi.\n\nEsempio 27.8 Consideriamo un esempio utilizzando un mazzo di 52 carte. Ogni seme contiene 13 carte e ci sono 4 regine in totale. Definiamo i seguenti eventi:\n\nEvento A: pescare una carta di picche,\nEvento B: pescare una regina.\n\nProbabilit√† con un mazzo completo\nIn un mazzo completo, la probabilit√† di pescare una carta di picche (\\(P(A)\\)) √® \\(\\frac{13}{52} = \\frac{1}{4}\\), poich√© ci sono 13 picche su 52 carte totali. La probabilit√† di pescare una regina (\\(P(B)\\)) √® \\(\\frac{4}{52} = \\frac{1}{13}\\), poich√© ci sono 4 regine su 52 carte.\nOra consideriamo la probabilit√† congiunta di pescare la regina di picche (\\(P(AB)\\)). Poich√© esiste solo una regina di picche nel mazzo, la probabilit√† di pescare questa specifica carta √® \\(\\frac{1}{52}\\).\nSecondo la definizione di indipendenza, se gli eventi \\(A\\) e \\(B\\) sono indipendenti, allora:\n\\[ P(AB) = P(A)P(B) \\]\nCalcoliamo \\(P(A)P(B)\\):\n\\[ P(A)P(B) = \\left( \\frac{1}{4} \\right) \\left( \\frac{1}{13} \\right) = \\frac{1}{52} \\]\nPoich√© \\(P(AB) = \\frac{1}{52}\\) √® uguale a \\(P(A)P(B)\\), possiamo affermare che gli eventi \\(A\\) e \\(B\\) sono indipendenti con un mazzo completo di 52 carte.\nProbabilit√† dopo la rimozione di una carta\nConsideriamo ora un mazzo con una carta in meno, ad esempio il due di quadri, riducendo il numero totale di carte a 51. Ricalcoliamo le probabilit√† con questo mazzo ridotto:\nLa probabilit√† di pescare la regina di picche (\\(P(AB)\\)) √® ora \\(\\frac{1}{51}\\), poich√© ci sono 51 carte nel mazzo.\nRicalcoliamo anche \\(P(A)\\) e \\(P(B)\\):\n\n\\(P(A)\\) diventa \\(\\frac{13}{51}\\), poich√© ci sono ancora 13 picche, ma su 51 carte.\n\\(P(B)\\) diventa \\(\\frac{4}{51}\\), poich√© ci sono ancora 4 regine, ma su 51 carte.\n\nOra calcoliamo il prodotto \\(P(A)P(B)\\) con queste nuove probabilit√†:\n\\[ P(A)P(B) = \\left( \\frac{13}{51} \\right) \\left( \\frac{4}{51} \\right) = \\frac{52}{2601} \\]\nConfrontiamo \\(P(AB)\\) e \\(P(A)P(B)\\):\n\\[ \\frac{1}{51} \\neq \\frac{52}{2601} \\]\nPoich√© \\(\\frac{1}{51} \\neq \\frac{52}{2601}\\), gli eventi \\(A\\) e \\(B\\) non sono pi√π indipendenti dopo la rimozione del due di quadri.\nQuesto esempio mostra come l‚Äôindipendenza tra due eventi dipenda dal contesto. Con un mazzo completo, i due eventi sono indipendenti. Tuttavia, rimuovendo una carta dal mazzo, le probabilit√† cambiano e gli eventi non sono pi√π indipendenti. Questo evidenzia l‚Äôimportanza di considerare la composizione e le condizioni iniziali quando si analizzano probabilit√† e indipendenza. Modifiche nella composizione del mazzo possono alterare le probabilit√†, influenzando le relazioni di indipendenza tra eventi specifici.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>Probabilit√† condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#riflessioni-conclusive",
    "href": "chapters/probability/04_conditional_prob.html#riflessioni-conclusive",
    "title": "27¬† Probabilit√† condizionata",
    "section": "27.7 Riflessioni Conclusive",
    "text": "27.7 Riflessioni Conclusive\nLa probabilit√† condizionata √® uno dei concetti fondamentali della statistica, poich√© fornisce il quadro teorico necessario per comprendere l‚Äôindipendenza statistica e molte altre relazioni tra eventi e variabili.\nUn punto chiave √® che l‚Äôindipendenza implica l‚Äôassenza di una associazione tra due variabili. Nei capitoli successivi esploreremo strumenti per misurare la correlazione correlazione, ovvero la presenza e l‚Äôintensit√† di una relazione lineare tra di esse.\nLa probabilit√† condizionata ha inoltre permesso di riformulare la legge della probabilit√† totale, che consente di scomporre probabilit√† complesse utilizzando partizioni dello spazio campionario. Questa legge si rivela cruciale per il teorema di Bayes, uno degli strumenti cardine dell‚Äôinferenza statistica.\nIn particolare, nel contesto dell‚Äôinferenza bayesiana, il condizionamento assume un ruolo fondamentale. Grazie a questo principio, √® possibile aggiornare continuamente le credenze o le incertezze riguardo a ipotesi, integrando nuove informazioni man mano che diventano disponibili. Questa capacit√† di adattamento rende l‚Äôinferenza bayesiana uno strumento estremamente flessibile e potente, capace di modellare situazioni complesse e dinamiche.\nIn sintesi, la probabilit√† condizionata non solo √® essenziale per comprendere l‚Äôindipendenza statistica, ma costituisce anche la base di metodi inferenziali avanzati, come l‚Äôinferenza bayesiana. Attraverso di essa, possiamo costruire modelli che evolvono e migliorano con l‚Äôaggiunta di nuove informazioni, rendendo l‚Äôanalisi statistica uno strumento dinamico e versatile per interpretare il mondo reale.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>Probabilit√† condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/04_conditional_prob.html#informazioni-sullambiente-di-sviluppo",
    "title": "27¬† Probabilit√† condizionata",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: US/Pacific\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] ggokabeito_0.1.0 see_0.9.0        gridExtra_2.3    patchwork_1.3.0 \n#&gt;  [5] bayesplot_1.11.1 psych_2.4.12     scales_1.3.0     markdown_1.13   \n#&gt;  [9] knitr_1.49       lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1   \n#&gt; [13] dplyr_1.1.4      purrr_1.0.2      readr_2.1.5      tidyr_1.3.1     \n#&gt; [17] tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3       \n#&gt; [21] here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.3         rlang_1.1.4       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       yaml_2.3.10       tools_4.4.2       parallel_4.4.2   \n#&gt; [21] tzdb_0.4.0        colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5      \n#&gt; [25] R6_2.5.1          lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3  \n#&gt; [29] pillar_1.10.1     gtable_0.3.6      glue_1.8.0        xfun_0.50        \n#&gt; [33] tidyselect_1.2.1  farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-166     \n#&gt; [37] rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>Probabilit√† condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#bibliografia",
    "href": "chapters/probability/04_conditional_prob.html#bibliografia",
    "title": "27¬† Probabilit√† condizionata",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlitzstein, J. K., & Hwang, J. (2019). Introduction to probability. CRC Press.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>Probabilit√† condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_random_var.html",
    "href": "chapters/probability/05_random_var.html",
    "title": "28¬† Variabili casuali",
    "section": "",
    "text": "28.1 Introduzione\nFinora, ci siamo concentrati sulle probabilit√† degli eventi. Ad esempio, abbiamo calcolato la probabilit√† di vincere il gioco di Monty Hall o di avere una rara condizione medica dato che il test √® risultato positivo. Ma, in molti casi, vorremmo sapere di pi√π. Ad esempio, quanti concorrenti devono giocare al gioco di Monty Hall fino a quando uno di loro finalmente vince? Quanto durer√† questa condizione? Quanto perder√≤ giocando d‚Äôazzardo con un dado sbilanciato tutta la notte? Per rispondere a queste domande, dobbiamo lavorare con le variabili casuali. In questo capitolo, introduciamo le variabili casuali e le loro propriet√†.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_random_var.html#definizione",
    "href": "chapters/probability/05_random_var.html#definizione",
    "title": "28¬† Variabili casuali",
    "section": "28.2 Definizione",
    "text": "28.2 Definizione\nLe variabili casuali sono risultati numerici derivanti da processi aleatori. Esse ci consentono di trasformare risultati qualitativi (ad esempio \\(X = \\{\\Box, \\clubsuit, \\diamondsuit, \\heartsuit, \\spadesuit\\}\\)) in valori numerici, semplificando cos√¨ l‚Äôanalisi matematica.\nFormalmente, una variabile casuale √® definita come una funzione che associa ogni elemento di uno spazio campionario \\(S\\) a un valore in un sottoinsieme dei numeri reali \\(\\mathbb{R}\\). Questa definizione consente di esprimere numericamente gli esiti di un fenomeno aleatorio, associando un valore specifico a ciascun possibile risultato dell‚Äôesperimento.\n\nEsempio 28.1 Un esempio √® la variabile casuale \\(X\\), che rappresenta il risultato del lancio di un dado. Se definiamo \\(X = 1\\) per indicare che il risultato del lancio √® un numero dispari (1, 3 o 5) e \\(X = 0\\) per indicare che il risultato √® un numero pari (2, 4 o 6), abbiamo trasformato un‚Äôosservazione fisica (il lancio del dado) in un valore numerico che rappresenta una determinata categoria di eventi.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_random_var.html#tipologie-di-variabili-casuali",
    "href": "chapters/probability/05_random_var.html#tipologie-di-variabili-casuali",
    "title": "28¬† Variabili casuali",
    "section": "28.3 Tipologie di Variabili Casuali",
    "text": "28.3 Tipologie di Variabili Casuali\nLe variabili casuali possono essere suddivise in due categorie principali: discrete e continue. Una variabile casuale discreta assume valori all‚Äôinterno di un insieme finito o al massimo numerabile, il che significa che i suoi possibili esiti possono essere contati, anche se l‚Äôinsieme √® infinito. Al contrario, una variabile casuale continua pu√≤ assumere un‚Äôinfinit√† di valori all‚Äôinterno di un intervallo, essendo in grado di coprire ogni punto di quell‚Äôintervallo senza interruzioni.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_random_var.html#convenzioni-notazionali",
    "href": "chapters/probability/05_random_var.html#convenzioni-notazionali",
    "title": "28¬† Variabili casuali",
    "section": "28.4 Convenzioni Notazionali",
    "text": "28.4 Convenzioni Notazionali\nNella teoria della probabilit√†, √® usuale adottare una specifica convenzione di notazione per le variabili casuali e i loro esiti. Comunemente, si utilizzano le lettere maiuscole, come \\(X\\), per indicare una variabile casuale, ovvero un concetto che rappresenta una serie di possibili esiti di un fenomeno aleatorio. D‚Äôaltro canto, la corrispondente lettera minuscola, \\(x\\) nel nostro esempio, √® impiegata per denotare una specifica realizzazione o un esito particolare che la variabile casuale pu√≤ assumere. Questa distinzione aiuta a chiarire se si sta parlando della variabile casuale nel suo insieme (\\(X\\)) o di un suo specifico valore (\\(x\\)).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_random_var.html#variabili-casuali-multiple",
    "href": "chapters/probability/05_random_var.html#variabili-casuali-multiple",
    "title": "28¬† Variabili casuali",
    "section": "28.5 Variabili casuali multiple",
    "text": "28.5 Variabili casuali multiple\nNella teoria della probabilit√†, le variabili casuali spesso interagiscono o si combinano tra loro. Consideriamo l‚Äôesempio di tre lanci di una moneta bilanciata, rappresentati da variabili casuali indipendenti \\(X_1\\), \\(X_2\\), e \\(X_3\\). Per ogni lancio:\n\n\\(P(X_n = 1)\\) (testa) = 0.5,\n\\(P(X_n = 0)\\) (croce) = 0.5,\n\ndove \\(n = 1, 2, 3\\).\nCombinando queste variabili, possiamo creare nuove variabili casuali. Ad esempio, definiamo \\(Z\\) come la somma dei risultati:\n\\[\nZ = X_1 + X_2 + X_3.\n\\]\n\\(Z\\) √® una variabile casuale discreta che rappresenta il numero totale di teste ottenute nei tre lanci. I suoi possibili valori sono 0, 1, 2, e 3.\nQuesto esempio illustra come variabili casuali indipendenti possano essere combinate per creare nuove variabili casuali.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_random_var.html#distribuzione-di-probabilit√†",
    "href": "chapters/probability/05_random_var.html#distribuzione-di-probabilit√†",
    "title": "28¬† Variabili casuali",
    "section": "28.6 Distribuzione di Probabilit√†",
    "text": "28.6 Distribuzione di Probabilit√†\nLa distribuzione di probabilit√† descrive come le probabilit√† si distribuiscono tra i possibili esiti associati a una variabile casuale. In precedenza, abbiamo introdotto il concetto di distribuzione di probabilit√† applicato agli elementi e ai sottoinsiemi dello spazio campionario di un esperimento casuale. Ora estendiamo questo concetto alle variabili casuali, con una differenza fondamentale: nel caso delle variabili casuali, gli elementi dello spazio campionario vengono mappati su numeri, mentre in precedenza potevano rappresentare altre categorie, come colori, oggetti o nomi.\n\n28.6.1 Parallelo tra Spazio Campionario e Variabili Casuali\n\nDistribuzione di probabilit√† nello spazio campionario: Ogni esperimento casuale ha uno spazio campionario, cio√® l‚Äôinsieme degli esiti possibili. Ad esempio, consideriamo un‚Äôurna contenente tre palline di colori diversi: \\(\\{\\text{rosso}, \\text{blu}, \\text{verde}\\}\\). Se estraiamo una pallina a caso, ogni colore pu√≤ essere associato a una probabilit√†, ad esempio: \\[\nP(\\text{rosso}) = 0.4, \\quad P(\\text{blu}) = 0.3, \\quad P(\\text{verde}) = 0.3.\n\\]\nDistribuzione di probabilit√† di una variabile casuale: Una variabile casuale trasforma questi esiti in numeri. Ad esempio, definiamo una variabile casuale \\(X\\) che assegna un valore numerico ai colori estratti:\n\\[\nX(\\text{rosso}) = 1, \\quad X(\\text{blu}) = 2, \\quad X(\\text{verde}) = 3.\n\\]\nLa distribuzione di probabilit√† di \\(X\\) descrive come le probabilit√† sono distribuite tra i numeri \\(\\{1, 2, 3\\}\\):\n\\[\nP(X = 1) = 0.4, \\quad P(X = 2) = 0.3, \\quad P(X = 3) = 0.3.\n\\]\n\n\n\n28.6.2 Distribuzioni di Probabilit√†: Discrete e Continue\nCome per lo spazio campionario, anche per le variabili casuali distinguiamo tra distribuzioni discrete e distribuzioni continue, a seconda della natura della variabile casuale:\n\nDistribuzioni discrete: Si applicano a variabili casuali discrete, che possono assumere un insieme finito o numerabile di valori. L‚Äôesempio sopra, con i colori delle palline trasformati in numeri, √® una distribuzione discreta. La funzione di massa di probabilit√† (PMF) assegna una probabilit√† a ciascun valore possibile.\nDistribuzioni continue: Si applicano a variabili casuali continue, che possono assumere un numero infinito di valori in un intervallo. Ad esempio, consideriamo l‚Äôaltezza delle persone in una popolazione. Definiamo una variabile casuale \\(X\\) che rappresenta l‚Äôaltezza in centimetri. In questo caso, la distribuzione di \\(X\\) √® descritta da una funzione di densit√† di probabilit√† (PDF), che non assegna probabilit√† a valori specifici ma descrive la probabilit√† per intervalli, ad esempio:\n\\[\nP(170 \\leq X \\leq 180).\n\\]\n\n\nIn sintesi, la distribuzione di probabilit√† delle variabili casuali estende il concetto di distribuzione nello spazio campionario a un contesto numerico. Questo permette di analizzare e modellare fenomeni reali in cui gli esiti possono essere rappresentati quantitativamente, sia per variabili discrete che continue, offrendo un quadro unificato per descrivere la probabilit√†.\n\n\n28.6.3 Supporto della Variabile Casuale\nIl supporto di una variabile casuale √® l‚Äôinsieme di tutti i valori che la variabile pu√≤ effettivamente assumere. Ad esempio:\n\nper un dado a sei facce: {1, 2, 3, 4, 5, 6};\nper una distribuzione gaussiana: l‚Äôintero insieme dei numeri reali.\n\n\n\n28.6.4 Assegnazione di Probabilit√†\n\nPer variabili discrete: si specifica la probabilit√† di ogni possibile valore.\nPer variabili continue: si utilizza la densit√† di probabilit√† per calcolare la probabilit√† di intervalli di valori.\n\n\nEsempio 28.2 Consideriamo l‚Äôesperimento casuale costituito dal lancio di due dadi equilibrati. Definiamo la variabile casuale \\(X\\) come la somma dei punti ottenuti dai due dadi.\nLo spazio campionario \\(S\\) √® l‚Äôinsieme di tutte le possibili coppie ordinate \\((a,b)\\), dove \\(a\\) e \\(b\\) rappresentano i risultati del primo e del secondo dado rispettivamente:\n\\[\nS = {(1,1), (1,2), ..., (1,6), (2,1), (2,2), ..., (2,6), ..., (6,1), (6,2), ..., (6,6)}.\n\\]\nIn totale, ci sono 6 √ó 6 = 36 possibili esiti.\nLa variabile casuale \\(X\\) √® definita come la somma dei punti dei due dadi. Quindi:\n\\[\nX = a + b, \\quad \\text{dove } (a,b) \\in S.\n\\]\n\\(X\\) pu√≤ assumere valori interi da 2 (1+1) a 12 (6+6).\nLa distribuzione della variabile casuale \\(X\\) √® una funzione che associa a ogni possibile valore di \\(X\\) la sua probabilit√†. In questo caso, poich√© \\(X\\) √® discreta, usiamo una funzione di massa di probabilit√†.\nPer calcolare la probabilit√† di ogni valore di \\(X\\), contiamo il numero di casi favorevoli e lo dividiamo per il numero totale di casi possibili (36).\n\n\n\n\n\n\n\n\n\nX\nCasi favorevoli\nNumero di casi\nProbabilit√† P(X = x)\n\n\n\n\n2\n(1,1)\n1\n1/36\n\n\n3\n(1,2), (2,1)\n2\n2/36 = 1/18\n\n\n4\n(1,3), (2,2), (3,1)\n3\n3/36 = 1/12\n\n\n5\n(1,4), (2,3), (3,2), (4,1)\n4\n4/36 = 1/9\n\n\n6\n(1,5), (2,4), (3,3), (4,2), (5,1)\n5\n5/36\n\n\n7\n(1,6), (2,5), (3,4), (4,3), (5,2), (6,1)\n6\n6/36 = 1/6\n\n\n8\n(2,6), (3,5), (4,4), (5,3), (6,2)\n5\n5/36\n\n\n9\n(3,6), (4,5), (5,4), (6,3)\n4\n4/36 = 1/9\n\n\n10\n(4,6), (5,5), (6,4)\n3\n3/36 = 1/12\n\n\n11\n(5,6), (6,5)\n2\n2/36 = 1/18\n\n\n12\n(6,6)\n1\n1/36\n\n\n\nQuesta tabella rappresenta la distribuzione completa della variabile casuale \\(X\\).\nIn conclusione, la distribuzione di una variabile casuale discreta, come nell‚Äôesempio della somma dei punti di due dadi, fornisce una descrizione completa delle propriet√† probabilistiche della variabile. Essa associa a ogni possibile valore della variabile la sua probabilit√† di verificarsi.\nIn questo caso, la distribuzione ci dice, per esempio, che la probabilit√† di ottenere una somma di 7 √® 1/6, la pi√π alta tra tutti i possibili risultati. Questo √® dovuto al fatto che ci sono pi√π combinazioni che producono una somma di 7 rispetto a qualsiasi altro risultato.\nLa distribuzione ci permette di rispondere a domande come:\n\nQual √® la probabilit√† di ottenere una somma pari? (Sommando le probabilit√† di 2, 4, 6, 8, 10, 12).\nQual √® la probabilit√† di ottenere una somma maggiore o uguale a 10? (Sommando le probabilit√† di 10, 11, 12).\n\nLa distribuzione di massa di probabilit√† della variabile casuale \\(X\\) pu√≤ essere rappresentata visivamente utilizzando un istogramma. Un istogramma permette di vedere immediatamente la probabilit√† associata a ciascun valore di \\(X\\), rendendo chiaro quali risultati sono pi√π probabili e quali lo sono meno.\nLe istruzioni R necessarie per generare questo istogramma sono fornite di seguito.\n\n\n# Valori possibili della variabile casuale X\nvalori_X &lt;- c(2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12)\n\n# Probabilit√† associate a ciascun valore di X\nprobabilita_X &lt;- c(\n  1 / 36,\n  2 / 36,\n  3 / 36,\n  4 / 36,\n  5 / 36,\n  6 / 36,\n  5 / 36,\n  4 / 36,\n  3 / 36,\n  2 / 36,\n  1 / 36\n)\n\ndat &lt;- data.frame(\n  Valore = valori_X,\n  Probabilit√† = probabilita_X\n)\n\nggplot(dat, aes(x = Valore, y = Probabilit√†)) +\n  geom_bar(\n    stat = \"identity\"\n    ) +\n  labs(\n    x = \"Valore della variabile casuale X\",\n    y = \"Probabilit√† P(X = x)\",\n    title = \"Distribuzione di Massa di Probabilit√†\\ndella Variabile Casuale X\"\n  )",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_random_var.html#funzione-di-distribuzione-cumulativa-cdf",
    "href": "chapters/probability/05_random_var.html#funzione-di-distribuzione-cumulativa-cdf",
    "title": "28¬† Variabili casuali",
    "section": "28.7 Funzione di Distribuzione Cumulativa (CDF)",
    "text": "28.7 Funzione di Distribuzione Cumulativa (CDF)\nLa Funzione di Distribuzione Cumulativa (CDF) √® uno strumento fondamentale nella teoria della probabilit√† per descrivere la distribuzione di una variabile casuale.\n\n28.7.1 Definizione\nPer una variabile casuale \\(X\\), la funzione di distribuzione cumulativa \\(F(x)\\) √® definita come:\n\\[\nF(x) = P(X \\leq x),\n\\]\ndove:\n\n\\(X\\) √® la variabile casuale.\n\\(P(X \\leq x)\\) rappresenta la probabilit√† che \\(X\\) assuma un valore minore o uguale a \\(x\\).\n\nIn altre parole, \\(F(x)\\) quantifica la probabilit√† cumulativa dall‚Äôestremo inferiore dello spazio di probabilit√† fino al punto \\(x\\).\n\n\n28.7.2 Propriet√† della CDF\n\nMonotonia non decrescente:\n\nPer \\(x_1 &lt; x_2\\), \\(F(x_1) \\leq F(x_2)\\).\nLa CDF non diminuisce mai quando ci si sposta da sinistra a destra lungo l‚Äôasse \\(x\\).\n\nNormalizzazione:\n\n\\(\\lim_{{x \\to -\\infty}} F(x) = 0 \\quad \\text{e} \\quad \\lim_{{x \\to +\\infty}} F(x) = 1\\).\nLa CDF parte da 0 quando \\(x\\) tende a \\(-\\infty\\) e raggiunge 1 quando \\(x\\) tende a \\(+\\infty\\).\n\nContinuit√† a destra:\n\n\\(F(x) = \\lim_{{y \\to x^+}} F(y)\\).\nLa CDF √® continua da destra, il che significa che non presenta salti improvvisi quando ci si avvicina a un punto da destra.\n\n\n\n\n28.7.3 CDF per Variabili Casuali Discrete\nPer una variabile casuale discreta \\(X\\), la CDF (anche chiamata funzione di ripartizione cumulativa) √® definita come:\n\\[\nF(x) = P(X \\leq x) = \\sum_{x_i \\leq x} P(X = x_i),\n\\]\ndove la somma √® calcolata su tutti i valori \\(x_i\\) minori o uguali a \\(x\\).\n\n\n28.7.4 Importanza e Applicazioni\n\nLa CDF offre una rappresentazione visiva di come le probabilit√† si accumulano lungo l‚Äôintero intervallo dei possibili valori della variabile casuale.\nLa CDF permette di calcolare facilmente la probabilit√† che \\(X\\) cada in un intervallo specifico:\n\n\\[\nP(a &lt; X \\leq b) = F(b) - F(a).\n\\]\n\nLa CDF √® utilizzata in vari metodi di generazione di variabili casuali, come il metodo della trasformazione inversa.\nLe CDF facilitano il confronto tra diverse distribuzioni di probabilit√†, consentendo di valutare differenze nelle loro caratteristiche cumulative.\n\nIn conclusione, la CDF √® uno strumento versatile e potente che fornisce una descrizione completa della distribuzione di probabilit√† di una variabile casuale, sia essa discreta o continua.\n\nEsempio 28.3 Nel caso del lancio di due dadi, con la variabile casuale \\(Z\\) definita come la somma dei loro valori, la funzione di distribuzione cumulativa \\(F(z)\\) pu√≤ essere illustrata come segue:\n\n\n\n\\(z\\)\n\\(P(Z = z)\\)\n\\(F(z)\\)\n\n\n\n\n2\n\\(\\frac{1}{36}\\)\n\\(\\frac{1}{36}\\)\n\n\n3\n\\(\\frac{2}{36}\\)\n\\(\\frac{3}{36}\\)\n\n\n4\n\\(\\frac{3}{36}\\)\n\\(\\frac{6}{36}\\)\n\n\n5\n\\(\\frac{4}{36}\\)\n\\(\\frac{10}{36}\\)\n\n\n6\n\\(\\frac{5}{36}\\)\n\\(\\frac{15}{36}\\)\n\n\n7\n\\(\\frac{6}{36}\\)\n\\(\\frac{21}{36}\\)\n\n\n8\n\\(\\frac{5}{36}\\)\n\\(\\frac{26}{36}\\)\n\n\n9\n\\(\\frac{4}{36}\\)\n\\(\\frac{30}{36}\\)\n\n\n10\n\\(\\frac{3}{36}\\)\n\\(\\frac{33}{36}\\)\n\n\n11\n\\(\\frac{2}{36}\\)\n\\(\\frac{35}{36}\\)\n\n\n12\n\\(\\frac{1}{36}\\)\n\\(\\frac{36}{36}\\)\n\n\n\nIn questa tabella:\n\n\\(P(Z = z)\\) rappresenta la probabilit√† che la somma dei due dadi sia esattamente \\(z\\).\n\\(F(z)\\) √® la funzione di distribuzione cumulativa, che fornisce la probabilit√† che la somma \\(Z\\) sia minore o uguale a \\(z\\).\n\nQuesta tabella mostra come le probabilit√† cumulative si accumulano per la variabile casuale \\(Z\\), evidenziando la distribuzione delle somme possibili quando si lanciano due dadi. Ad esempio, \\(F(7) = \\frac{21}{36}\\) indica che la probabilit√† che la somma sia 7 o inferiore √® \\(\\frac{21}{36}\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_random_var.html#trovare-la-distribuzione-di-probabilit√†-attraverso-una-simulazione",
    "href": "chapters/probability/05_random_var.html#trovare-la-distribuzione-di-probabilit√†-attraverso-una-simulazione",
    "title": "28¬† Variabili casuali",
    "section": "28.8 Trovare la Distribuzione di Probabilit√† attraverso una Simulazione",
    "text": "28.8 Trovare la Distribuzione di Probabilit√† attraverso una Simulazione\nLa distribuzione di probabilit√† teorica per il lancio di due dadi pu√≤ essere calcolata analiticamente, ma un‚Äôalternativa altrettanto valida √® ottenere una stima empirica tramite simulazione. Questo approccio consiste nel ripetere l‚Äôesperimento casuale un numero elevato di volte e analizzare le frequenze relative dei risultati ottenuti. Aumentando il numero di simulazioni, la distribuzione empirica tende a convergere verso quella teorica.\nDi seguito vedremo come implementare una simulazione in R per calcolare la distribuzione empirica di probabilit√† dei risultati ottenuti sommando i punteggi di due dadi.\n\nEsempio 28.4 Iniziamo definendo una funzione che simula il lancio di un dado a sei facce, restituendo un valore casuale tra 1 e 6.\n\n# Funzione per simulare il lancio di un dado\nroll_die &lt;- function() {\n  sample(1:6, size = 1)\n}\n\nPossiamo ora definire una funzione che calcola la somma dei valori di due dadi lanciati simultaneamente. La funzione accetta come argomento il numero di ripetizioni da effettuare e restituisce un vettore contenente i risultati.\n\n# Funzione per simulare il lancio di due dadi per n volte\nroll_two_dice &lt;- function(n) {\n  map_dbl(1:n, ~ roll_die() + roll_die())\n}\n\nUtilizziamo la funzione appena definita per simulare 100.000 lanci di due dadi. Memorizziamo i risultati in un oggetto res e visualizziamo i primi 20 valori.\n\n# Numero di simulazioni\nnrolls &lt;- 100000\n\n# Simula i risultati del lancio di due dadi\nres &lt;- roll_two_dice(nrolls)\n\n# Visualizza i primi 20 risultati\ncat(res[1:20], \"\\n\")\n#&gt; 6 2 6 4 5 6 10 4 4 4 9 10 6 7 3 8 9 6 10 7\n\nUtilizzando il tidyverse, possiamo creare un DataFrame contenente i risultati della simulazione e calcolare la distribuzione empirica delle probabilit√†. Per fare ci√≤, calcoliamo le frequenze assolute dei risultati, le normalizziamo dividendo per il numero totale di simulazioni e assicuriamo che siano rappresentati tutti i possibili valori (da 2 a 12).\n\n# Converti i risultati in un DataFrame (tibble)\ndf &lt;- tibble(y = res)\n\n# Calcola la distribuzione empirica delle probabilit√†\nempirical_probs &lt;- df %&gt;%\n  count(y) %&gt;%                             # Calcola le frequenze assolute\n  complete(y = 2:12, fill = list(n = 0)) %&gt;% # Assicura che tutti i valori siano inclusi\n  mutate(prob = n / nrolls)                # Calcola le probabilit√† relative\n\n# Visualizza la distribuzione empirica\nempirical_probs %&gt;%\n  dplyr::select(y, prob)\n#&gt; # A tibble: 11 √ó 2\n#&gt;       y   prob\n#&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1     2 0.0282\n#&gt; 2     3 0.0566\n#&gt; 3     4 0.0849\n#&gt; 4     5 0.111 \n#&gt; 5     6 0.139 \n#&gt; 6     7 0.165 \n#&gt; # ‚Ñπ 5 more rows\n\nIl risultato finale √® una tabella che mostra i valori possibili (da 2 a 12) e la loro probabilit√† empirica stimata. Questa distribuzione empirica dovrebbe essere molto simile alla distribuzione teorica, specialmente considerando un numero elevato di simulazioni.\nQuesto approccio dimostra come sia possibile utilizzare la simulazione per approssimare distribuzioni di probabilit√†, una tecnica particolarmente utile quando la soluzione analitica non √® immediatamente disponibile.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_random_var.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/05_random_var.html#informazioni-sullambiente-di-sviluppo",
    "title": "28¬† Variabili casuali",
    "section": "28.9 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "28.9 Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: US/Pacific\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] ggokabeito_0.1.0 see_0.9.0        gridExtra_2.3    patchwork_1.3.0 \n#&gt;  [5] bayesplot_1.11.1 psych_2.4.12     scales_1.3.0     markdown_1.13   \n#&gt;  [9] knitr_1.49       lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1   \n#&gt; [13] dplyr_1.1.4      purrr_1.0.2      readr_2.1.5      tidyr_1.3.1     \n#&gt; [17] tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3       \n#&gt; [21] here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.3         rlang_1.1.4       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       yaml_2.3.10       tools_4.4.2       parallel_4.4.2   \n#&gt; [21] tzdb_0.4.0        colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5      \n#&gt; [25] R6_2.5.1          lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3  \n#&gt; [29] pillar_1.10.1     gtable_0.3.6      glue_1.8.0        xfun_0.50        \n#&gt; [33] tidyselect_1.2.1  farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-166     \n#&gt; [37] labeling_0.4.3    rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_random_var.html#bibliografia",
    "href": "chapters/probability/05_random_var.html#bibliografia",
    "title": "28¬† Variabili casuali",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlitzstein, J. K., & Hwang, J. (2019). Introduction to probability. CRC Press.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_expval_var.html",
    "href": "chapters/probability/06_expval_var.html",
    "title": "29¬† Propriet√† delle variabili casuali",
    "section": "",
    "text": "29.1 Introduzione\nPrerequisiti\nPrima di affrontare il presente capitolo, √® essenziale leggere la sezione ?sec-calculus.\nConcetti e Competenze Chiave\nPreparazione del Notebook\nSintetizzare la distribuzione di una variabile casuale attraverso indicatori caratteristici √® spesso molto utile. Questi indicatori consentono di cogliere le principali propriet√† della distribuzione, come la posizione centrale (ovvero il ‚Äúbaricentro‚Äù) e la variabilit√† (ossia la dispersione attorno al centro). In questo modo, √® possibile ottenere una descrizione sintetica e significativa della distribuzione di probabilit√† della variabile casuale.\nIn questo capitolo, introdurremo i concetti fondamentali di valore atteso e varianza di una variabile casuale, che sono strumenti essenziali per comprendere e riassumere le propriet√† di una distribuzione probabilistica.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_expval_var.html#valore-atteso",
    "href": "chapters/probability/06_expval_var.html#valore-atteso",
    "title": "29¬† Propriet√† delle variabili casuali",
    "section": "29.2 Valore Atteso",
    "text": "29.2 Valore Atteso\nQuando vogliamo comprendere il comportamento tipico di una variabile casuale, ci interessa spesso determinare il suo ‚Äúvalore tipico‚Äù. Tuttavia, questa nozione pu√≤ essere interpretata in diversi modi:\n\nMedia: La somma dei valori divisa per il numero dei valori.\nMediana: Il valore centrale della distribuzione, quando i dati sono ordinati in senso crescente o decrescente.\nModa: Il valore che si verifica con maggiore frequenza.\n\nAd esempio, per il set di valori \\(\\{3, 1, 4, 1, 5\\}\\), la media √® \\(\\frac{3+1+4+1+5}{5} = 2.8\\), la mediana √® 3, e la moda √® 1. Tuttavia, quando ci occupiamo di variabili casuali, anzich√© di semplici sequenze di numeri, diventa necessario chiarire cosa intendiamo per ‚Äúvalore tipico‚Äù in questo contesto. Questo ci porta alla definizione formale del valore atteso.\n\nDefinizione 29.1 Sia \\(X\\) una variabile casuale discreta che assume i valori \\(x_1, \\dots, x_n\\) con probabilit√† \\(P(X = x_i) = p(x_i)\\). Il valore atteso di \\(X\\), denotato con \\(\\mathbb{E}(X)\\), √® definito come:\n\\[\n\\mathbb{E}(X) = \\sum_{i=1}^n x_i \\cdot p(x_i).\n\\]\n\nIn altre parole, il valore atteso (noto anche come speranza matematica o aspettazione) di una variabile casuale √® la somma di tutti i valori che la variabile pu√≤ assumere, ciascuno ponderato dalla probabilit√† con cui esso si verifica.\n\nEsempio 29.1 Calcoliamo il valore atteso della variabile casuale \\(X\\) corrispondente al lancio di una moneta equilibrata, dove testa corrisponde a \\(X = 1\\) e croce corrisponde a \\(X = 0\\):\n\\[\n\\mathbb{E}(X) = \\sum_{i=1}^{2} x_i \\cdot P(x_i) = 0 \\cdot \\frac{1}{2} + 1 \\cdot \\frac{1}{2} = 0.5.\n\\]\n\n\nEsempio 29.2 Calcoliamo il valore atteso della variabile casuale \\(X\\) che rappresenta la somma dei punti ottenuti dal lancio di due dadi equilibrati a sei facce.\nLa variabile casuale \\(X\\) pu√≤ assumere i seguenti valori:\n\\[\n\\{2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12\\}.\n\\]\nLa probabilit√† associata a ciascun valore √® data dalla distribuzione di massa di probabilit√†. Ad esempio, il valore \\(X = 2\\) si ottiene solo se entrambi i dadi mostrano 1, quindi ha probabilit√†:\n\\[\nP(X = 2) = \\frac{1}{36}.\n\\]\nAnalogamente, \\(X = 7\\) pu√≤ essere ottenuto con sei combinazioni diverse: (1,6), (2,5), (3,4), (4,3), (5,2), (6,1), quindi:\n\\[\nP(X = 7) = \\frac{6}{36}.\n\\]\nLa distribuzione di massa di probabilit√† completa √®: $$\nP(X) = {, , , , , , , , , , }. $$\nIl valore atteso \\(\\mathbb{E}[X]\\) √® definito come:\n\\[\n\\mathbb{E}[X] = \\sum_{x} x \\cdot P(X = x).\n\\]\nApplicando questa formula:\n\\[\n\\mathbb{E}[X] = 2 \\cdot \\frac{1}{36} + 3 \\cdot \\frac{2}{36} + 4 \\cdot \\frac{3}{36} + \\cdots + 12 \\cdot \\frac{1}{36} = 7.\n\\]\nEcco come calcolarlo utilizzando R:\n\n# Valori di X e le loro probabilit√†\nvalori &lt;- 2:12\nprob &lt;- c(1, 2, 3, 4, 5, 6, 5, 4, 3, 2, 1) / 36\n\n# Calcolo del valore atteso\nvalore_atteso &lt;- sum(valori * prob)\nvalore_atteso\n#&gt; [1] 7\n\nIl risultato sar√†: \\[\n\\mathbb{E}[X] = 7.\n\\]\nPer rappresentare graficamente la distribuzione di massa di probabilit√†:\n\n# Creazione di un data frame\ndati &lt;- data.frame(Valore = valori, Probabilit√† = prob)\n\n# Plot\nggplot(dati, aes(x = Valore, y = Probabilit√†)) +\n  geom_col() +\n  labs(\n    title = \"Distribuzione di Massa di Probabilit√† per X\",\n    x = \"Valore della Somma (X)\",\n    y = \"Probabilit√†\"\n  ) \n\n\n\n\n\n\n\n\n\n\n29.2.1 Interpretazione\nIl valore atteso di una variabile casuale corrisponde alla media aritmetica di un ampio numero di realizzazioni indipendenti della variabile stessa.\nPer chiarire questo concetto, consideriamo nuovamente l‚Äôesempio del lancio di due dadi bilanciati a sei facce, dove la variabile casuale \\(X\\) rappresenta la ‚Äúsomma dei due dadi‚Äù. Simuliamo un grande numero di realizzazioni indipendenti di \\(X\\).\n\nset.seed(123)  \nx_samples &lt;- sample(valori, size = 1e6, replace = TRUE, prob = prob)\n\nL‚Äôistruzione sample(x, size = 1e6, replace = TRUE, prob = px)) utilizza R per generare un array di 1.000.000 di elementi (specificato dal parametro size), selezionati casualmente dall‚Äôarray x secondo le probabilit√† specificate nell‚Äôarray px.\nQuando il numero di realizzazioni indipendenti √® sufficientemente grande, la media aritmetica dei campioni generati si avvicina al valore atteso della variabile casuale:\n\nmean(x_samples)\n#&gt; [1] 7\n\nQuesto risultato conferma che il valore atteso \\(\\mathbb{E}[X] = 7\\) rappresenta la somma media dei punti ottenuti nel lancio di due dadi equilibrati su un numero elevato di prove. Anche se ogni singola somma pu√≤ variare tra 2 e 12, in media ci aspettiamo una somma di 7.\n\n\n29.2.2 Propriet√† del Valore Atteso\nUna delle propriet√† pi√π importanti del valore atteso √® la sua linearit√†: il valore atteso della somma di due variabili casuali √® uguale alla somma dei loro rispettivi valori attesi:\n\\[\n\\mathbb{E}(X + Y) = \\mathbb{E}(X) + \\mathbb{E}(Y).\n\\tag{29.1}\\]\nQuesta propriet√†, espressa dalla formula sopra, √® intuitiva quando \\(X\\) e \\(Y\\) sono variabili casuali indipendenti, ma √® valida anche nel caso in cui \\(X\\) e \\(Y\\) siano correlate.\nInoltre, se moltiplichiamo una variabile casuale per una costante \\(c\\), il valore atteso del prodotto √® uguale alla costante moltiplicata per il valore atteso della variabile casuale:\n\\[\n\\mathbb{E}(cY) = c \\mathbb{E}(Y).\n\\tag{29.2}\\]\nQuesta propriet√† ci dice che una costante pu√≤ essere ‚Äúestratta‚Äù dall‚Äôoperatore di valore atteso, e si applica a qualunque numero di variabili casuali.\nUn‚Äôaltra propriet√† significativa riguarda il prodotto di variabili casuali indipendenti. Se \\(X\\) e \\(Y\\) sono indipendenti, allora il valore atteso del loro prodotto √® uguale al prodotto dei loro valori attesi:\n\\[\n\\mathbb{E}(XY) = \\mathbb{E}(X) \\mathbb{E}(Y).\n\\tag{29.3}\\]\nInfine, consideriamo la media aritmetica \\(\\bar{X} = \\frac{X_1 + \\ldots + X_n}{n}\\) di \\(n\\) variabili casuali indipendenti con la stessa distribuzione e con valore atteso \\(\\mu\\). Il valore atteso della media aritmetica √®:\n\\[\n\\mathbb{E}(\\bar{X}) = \\frac{1}{n} \\left(\\mathbb{E}(X_1) + \\dots + \\mathbb{E}(X_n)\\right) = \\frac{1}{n} \\cdot n \\cdot \\mathbb{E}(X) = \\mu.\n\\]\nQuesto risultato conferma che la media aritmetica di un campione di variabili casuali indipendenti ha lo stesso valore atteso della distribuzione originaria, rendendo il valore atteso uno strumento cruciale per l‚Äôanalisi statistica e probabilistica.\n\nEsempio 29.3 Consideriamo il seguente esperimento casuale. Sia \\(Y\\) il numero che si ottiene dal lancio di un dado equilibrato a sei facce e \\(Y\\) il numero di teste prodotto dal lancio di una moneta equilibrata (0 oppure 1). Troviamo il valore atteso di \\(X+Y\\).\nPer risolvere il problema iniziamo a costruire lo spazio campione dell‚Äôesperimento casuale.\n\n\n\n\n\n\n\n\n\n\n\n\n\\(x /\\ y\\)\n1\n2\n3\n4\n5\n6\n\n\n\n\n0\n(0, 1)\n(0, 2)\n(0, 3)\n(0, 4)\n(0, 5)\n(0, 6)\n\n\n1\n(1, 1)\n(1, 2)\n(1, 3)\n(1, 4)\n(1, 5)\n(1, 6)\n\n\n\novvero\n\n\n\n\\(x /\\ y\\)\n1\n2\n3\n4\n5\n6\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\nIl risultato del lancio del dado √® indipendente dal risultato del lancio della moneta. Pertanto, ciascun evento elementare dello spazio campione avr√† la stessa probabilit√† di verificarsi, ovvero \\(P(\\omega) = \\frac{1}{12}\\). Il valore atteso di \\(X+Y\\) √® dunque uguale a:\n\\[\n\\mathbb{E}(X+Y) = 1 \\cdot \\frac{1}{12} + 2 \\cdot \\frac{1}{12} + \\dots + 7 \\cdot \\frac{1}{12} = 4.0.\n\\]\nSi ottiene lo stesso risultato usando l‚ÄôEquazione¬†29.1:\n\\[\n\\mathbb{E}(X+Y) = \\mathbb{E}(X) + E(Y) = 3.5 + 0.5 = 4.0.\n\\]\n\n\nEsempio 29.4 Svolgiamo ora l‚Äôesercizio in R\n\ncoin &lt;- 0:1  # Valori della moneta: testa (0) e croce (1)\ndie &lt;- 1:6   # Valori del dado: da 1 a 6\n\n# Creazione del campione come combinazione di valori (moneta, dado)\nsample &lt;- expand.grid(coin = coin, die = die)\nprint(sample)\n#&gt;    coin die\n#&gt; 1     0   1\n#&gt; 2     1   1\n#&gt; 3     0   2\n#&gt; 4     1   2\n#&gt; 5     0   3\n#&gt; 6     1   3\n#&gt; 7     0   4\n#&gt; 8     1   4\n#&gt; 9     0   5\n#&gt; 10    1   5\n#&gt; 11    0   6\n#&gt; 12    1   6\n\n\npx &lt;- numeric()  # Vettore per memorizzare le probabilit√†\n\nfor (i in 1:7) {\n  # Filtrare le combinazioni in cui la somma √® uguale a 'i'\n  event &lt;- subset(sample, coin + die == i)\n  # Calcolare la probabilit√†\n  prob &lt;- nrow(event) / nrow(sample)\n  px &lt;- c(px, prob)\n  \n  # Stampare la probabilit√†\n  cat(sprintf(\"P(X + Y = %d) = %d / %d\\n\", i, nrow(event), nrow(sample)))\n}\n#&gt; P(X + Y = 1) = 1 / 12\n#&gt; P(X + Y = 2) = 2 / 12\n#&gt; P(X + Y = 3) = 2 / 12\n#&gt; P(X + Y = 4) = 2 / 12\n#&gt; P(X + Y = 5) = 2 / 12\n#&gt; P(X + Y = 6) = 2 / 12\n#&gt; P(X + Y = 7) = 1 / 12\n\n\nx &lt;- 1:7  # Valori della variabile casuale (somma di moneta e dado)\nexpected_value &lt;- sum(x * px)\nexpected_value\n#&gt; [1] 4\n\n\n\nEsempio 29.5 Consideriamo le variabili casuali \\(X\\) e \\(Y\\) definite nel caso del lancio di tre monete equilibrate, dove \\(X\\) conta il numero delle teste nei tre lanci e \\(Y\\) conta il numero delle teste al primo lancio. Si calcoli il valore atteso di \\(Z = X \\cdot Y\\).\nLa distribuzione di probabilit√† congiunta \\(P(X, Y)\\) √® fornita nella tabella seguente.\n\n\n\n\\(x /\\ y\\)\n0\n1\n\\(p(Y)\\)\n\n\n\n\n0\n1/8\n0\n1/8\n\n\n1\n2/8\n1/8\n3/8\n\n\n2\n1/8\n2/8\n3/8\n\n\n3\n0\n1/8\n1/8\n\n\n\\(p(y)\\)\n4/8\n4/8\n1.0\n\n\n\nIl calcolo del valore atteso di \\(XY\\) si riduce a\n\\[\n\\mathbb{E}(Z) = 1 \\cdot \\frac{1}{8} + 2 \\cdot \\frac{2}{8} + 3 \\cdot \\frac{1}{8} = 1.0.\n\\]\nSi noti che le variabili casuali \\(Y\\) e \\(Y\\) non sono indipendenti. Dunque non possiamo usare l‚ÄôEquazione¬†29.3. Infatti, il valore atteso di \\(X\\) √®\n\\[\n\\mathbb{E}(X) = 1 \\cdot \\frac{3}{8} + 2 \\cdot \\frac{3}{8} + 3 \\cdot \\frac{1}{8} = 1.5\n\\]\ne il valore atteso di \\(Y\\) √®\n\\[\n\\mathbb{E}(Y) = 0 \\cdot \\frac{4}{8} + 1 \\cdot \\frac{4}{8} = 0.5.\n\\]\nPerci√≤\n\\[\n1.5 \\cdot 0.5 \\neq 1.0.\n\\]\n\n\n\n29.2.3 Variabili casuali continue\nNel caso di una variabile casuale continua \\(X\\), il valore atteso √® definito come:\n\\[\n\\mathbb{E}(X) = \\int_{-\\infty}^{+\\infty} x \\cdot p(x) \\, \\mathrm{d}x.\n\\]\nAnche in questo contesto, il valore atteso rappresenta una media ponderata dei valori di \\(x\\), dove ogni possibile valore di \\(x\\) √® ponderato in base alla densit√† di probabilit√† \\(p(x)\\).\nL‚Äôintegrale pu√≤ essere interpretato analogamente a una somma continua, in cui \\(x\\) rappresenta la posizione delle barre infinitamente strette di un istogramma, e \\(p(x)\\) rappresenta l‚Äôaltezza di tali barre. La notazione \\(\\int_{-\\infty}^{+\\infty}\\) indica che si sta sommando il contributo di ogni valore possibile di \\(x\\) lungo l‚Äôintero asse reale.\nQuesta interpretazione rende chiaro come l‚Äôintegrale calcoli una somma ponderata che si estende su tutti i possibili valori di \\(x\\), fornendo una misura centrale della distribuzione della variabile casuale continua. Per ulteriori dettagli sulla notazione dell‚Äôintegrale, si veda l‚Äô?sec-calculus.\n\n29.2.3.1 Moda\nUn‚Äôaltra misura di tendenza centrale delle variabili casuali continue √® la moda. La moda di \\(Y\\) individua il valore \\(y\\) pi√π plausibile, ovvero il valore \\(y\\) che massimizza la funzione di densit√† \\(p(y)\\):\n\\[\nMo(Y) = \\text{argmax}_y p(y).\n\\tag{29.4}\\]\n\n\n\n\n\n\nLa notazione \\(\\text{argmax}_y p(y)\\) significa: il valore \\(y\\) tale per cui la funzione \\(p(y)\\) assume il suo valore massimo.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_expval_var.html#varianza",
    "href": "chapters/probability/06_expval_var.html#varianza",
    "title": "29¬† Propriet√† delle variabili casuali",
    "section": "29.3 Varianza",
    "text": "29.3 Varianza\nDopo il valore atteso, la seconda propriet√† pi√π importante di una variabile casuale √® la varianza.\n\nDefinizione 29.2 Se \\(X\\) √® una variabile casuale discreta con distribuzione \\(p(x)\\), la varianza di \\(X\\), denotata con \\(\\mathbb{V}(X)\\), √® definita come:\n\\[\n\\mathbb{V}(X) = \\mathbb{E}\\Big[\\big(X - \\mathbb{E}(X)\\big)^2\\Big].\n\\tag{29.5}\\]\n\nIn altre parole, la varianza misura la deviazione media quadratica dei valori della variabile rispetto alla sua media. Se denotiamo il valore atteso di \\(X\\) con \\(\\mu = \\mathbb{E}(X)\\), la varianza \\(\\mathbb{V}(X)\\) diventa il valore atteso di \\((X - \\mu)^2\\).\n\n29.3.1 Interpretazione della Varianza\nLa varianza rappresenta una misura della ‚Äúdispersione‚Äù dei valori di \\(X\\) intorno al suo valore atteso. Quando calcoliamo la varianza, stiamo effettivamente misurando quanto i valori di \\(X\\) tendono a differire dalla media \\(\\mu\\).\nPer capire meglio, consideriamo la variabile casuale \\(X - \\mathbb{E}(X)\\), detta scarto o deviazione dalla media. Questa variabile rappresenta le ‚Äúdistanze‚Äù tra i valori di \\(X\\) e il valore atteso \\(\\mathbb{E}(X)\\). Tuttavia, poich√© lo scarto pu√≤ essere positivo o negativo, la media dello scarto √® sempre zero, il che lo rende inadatto a quantificare la dispersione.\nPer risolvere questo problema, eleviamo al quadrato gli scarti, ottenendo \\((X - \\mathbb{E}(X))^2\\), che rende tutte le deviazioni positive. La varianza √® quindi la media di questi scarti al quadrato, fornendo una misura efficace della dispersione complessiva dei valori di \\(X\\) rispetto alla sua media.\nQuesto concetto √® fondamentale per comprendere la variabilit√† di una distribuzione e per applicare strumenti statistici che richiedono una conoscenza approfondita della distribuzione dei dati.\n\nEsempio 29.6 Posta \\(S\\) uguale alla somma dei punti ottenuti nel lancio di due dadi equilibrati, si calcoli la varianza di \\(S\\).\nLa variabile casuale \\(S\\) ha la seguente distribuzione di probabilit√†:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(s\\)\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\n\n\\(P(S = s)\\)\n\\(\\frac{1}{36}\\)\n\\(\\frac{2}{36}\\)\n\\(\\frac{3}{36}\\)\n\\(\\frac{4}{36}\\)\n\\(\\frac{5}{36}\\)\n\\(\\frac{6}{36}\\)\n\\(\\frac{5}{36}\\)\n\\(\\frac{4}{36}\\)\n\\(\\frac{3}{36}\\)\n\\(\\frac{2}{36}\\)\n\\(\\frac{1}{36}\\)\n\n\n\nEssendo \\(\\mathbb{E}(S) = 7\\), la varianza diventa\n\\[\n\\begin{align}\n\\mathbb{V}(S) &= \\sum \\left(s - \\mathbb{E}(S)\\right)^2 \\cdot P(s) \\notag\\\\\n&= (2 - 7)^2 \\cdot \\frac{1}{36} + (3-7)^2 \\cdot \\frac{3}{36} + \\dots + (12 - 7)^2 \\cdot \\frac{1}{36} \\notag\\\\\n&= 5.8333.\\notag\n\\end{align}\n\\]\n\n\nEsempio 29.7 Svolgiamo l‚Äôesercizio in R\n\n# Definire i valori di x e le loro probabilit√† px\nx &lt;- 2:12\npx &lt;- c(\n  1 / 36, 2 / 36, 3 / 36, 4 / 36, 5 / 36, 6 / 36,\n  5 / 36, 4 / 36, 3 / 36, 2 / 36, 1 / 36\n)\n\n# Calcolare il valore atteso\nex &lt;- sum(x * px)\nex\n#&gt; [1] 7\n\nApplichiamo l‚ÄôEquazione¬†29.5:\n\n# Calcolo della varianza utilizzando la definizione\nvariance &lt;- sum((x - ex)^2 * px)\nvariance\n#&gt; [1] 5.83\n\nUsiamo la funzione var() di rv_discrete:\n\n# Calcolo della varianza con pesi\nvariance_check &lt;- weighted.mean((x - ex)^2, w = px)\nvariance_check\n#&gt; [1] 5.83\n\n\n\n\n29.3.2 Formula Alternativa per la Varianza\nEsiste un metodo pi√π semplice e diretto per calcolare la varianza di una variabile casuale \\(X\\):\n\\[\n\\begin{align}\n\\mathbb{E}\\Big[\\big(X - \\mathbb{E}(X)\\big)^2\\Big] &= \\mathbb{E}\\big(X^2 - 2Y\\mathbb{E}(X) + \\mathbb{E}(X)^2\\big) \\notag\\\\\n&= \\mathbb{E}(X^2) - 2\\mathbb{E}(Y)\\mathbb{E}(X) + \\mathbb{E}(X)^2,\n\\end{align}\n\\]\ndove \\(\\mathbb{E}(X)\\) √® una costante. Semplificando ulteriormente, otteniamo:\n\\[\n\\mathbb{V}(X) = \\mathbb{E}(X^2) - \\big(\\mathbb{E}(X)\\big)^2.\n\\tag{29.6}\\]\nIn altre parole, la varianza √® data dalla differenza tra la media dei quadrati dei valori di \\(X\\) e il quadrato della media di \\(X\\).\nQuesta formula √® utile perch√© permette di calcolare la varianza senza dover prima determinare lo scarto quadratico medio per ciascun valore di \\(X\\). Invece, si pu√≤ calcolare direttamente la media dei quadrati e sottrarre il quadrato della media, il che spesso semplifica i calcoli e riduce il rischio di errori.\n\nEsempio 29.8 Consideriamo la variabile casuale \\(X\\) che corrisponde al numero di teste che si osservano nel lancio di una moneta truccata con probabilit√† di testa uguale a 0.8. Si trovi la varianza di \\(Y\\).\nIl valore atteso di \\(X\\) √®\n\\[\n\\mathbb{E}(X) = 0 \\cdot 0.2 + 1 \\cdot 0.8 = 0.8.\n\\]\nUsando la formula tradizionale della varianza otteniamo:\n\\[\n\\mathbb{V}(X) = (0 - 0.8)^2 \\cdot 0.2 + (1 - 0.8)^2 \\cdot 0.8 = 0.16.\n\\]\nLo stesso risultato si trova con la formula alternativa della varianza. Il valore atteso di \\(X^2\\) √®\n\\[\n\\mathbb{E}(X^2) = 0^2 \\cdot 0.2 + 1^2 \\cdot 0.8 = 0.8.\n\\]\ne la varianza diventa\n\\[\n\\mathbb{V}(X) = \\mathbb{E}(X^2) - \\big(\\mathbb{E}(Y) \\big)^2 = 0.8 - 0.8^2 = 0.16.\n\\]\n\n\nEsempio 29.9 Svolgiamo l‚Äôesercizio in R:\n\n# Definire i valori di x e le probabilit√† px\nx &lt;- c(0, 1)\npx &lt;- c(0.2, 0.8)\n\n# Calcolare il risultato\nresult &lt;- sum(x^2 * px) - (sum(x * px))^2\nresult\n#&gt; [1] 0.16\n\n\n\n\n29.3.3 Propriet√†\nSegno della varianza. La varianza di una variabile aleatoria non √® mai negativa, ed √® zero solamente quando la variabile assume un solo valore.\nInvarianza per traslazione. La varianza √® invariante per traslazione, che lascia fisse le distanze dalla media, e cambia quadraticamente per riscalamento:\n\\[\n\\mathbb{V}(a + bX) = b^2\\mathbb{V}(X).\n\\]\nDimostrazione. Iniziamo a scrivere\n\\[\n(aX+b)-{\\mathbb{E}}[aX+b]=aX+b-a{\\mathbb{E}}[X]-b=a(X-{\\mathbb  {E}}[X]).\n\\]\nQuindi\n\\[\n\\sigma _{{aX+b}}^{2}={\\mathbb{E}}[a^{2}(X-{\\mathbb  {E}}[X])^{2}]=a^{2}\\sigma _{X}^{2}.\n\\]\nEsaminiamo una dimostrazione numerica.\n\n# Definire i valori di x\nx &lt;- c(2, 1, 4, 7)\n\n# Calcolare y\ny &lt;- 100 + 2 * x\n\n# Verificare la relazione tra le varianze\nresult &lt;- var(y) == 2^2 * var(x)\nresult\n#&gt; [1] TRUE\n\nVarianza della somma di due variabili indipendenti. La varianza della somma di due variabili indipendenti o anche solo incorrelate √® pari alla somma delle loro varianze:\n\\[\n\\mathbb{V}(X+Y) = \\mathbb{V}(X) + \\mathbb{V}(Y).\n\\]\nDimostrazione. Se \\(\\mathbb{E}(X) = \\mathbb{E}(Y) = 0\\), allora \\(\\mathbb{E}(X+Y) = 0\\) e\n\\[\\mathbb{V}(X+Y) = \\mathbb{E}((X+Y)^2) = \\mathbb{E}(X^2) + 2 \\mathbb{E}(XY) + \\mathbb{E}(Y^2).\\]\nSiccome le variabili sono indipendenti risulta \\(\\mathbb{E}(XY) = \\mathbb{E}(X)\\mathbb{E}(Y) = 0\\).\nVarianza della differenza di due variabili indipendenti. La varianza della differenza di due variabili indipendenti √® pari alla somma delle loro varianze:\n\\[\n\\mathbb{V}(X-Y) = \\mathbb{V}(X) + \\mathbb{V}(Y).\n\\]\nDimostrazione.\n\\[\n\\mathbb{V}(X-Y) = \\mathbb{V}(X +(-Y)) = \\mathbb{V}(X) + \\mathbb{V}(-Y) = \\mathbb{V}(X) + \\mathbb{V}(Y).\n\\]\nVarianza della somma di due variabili non indipendenti. Se \\(X\\) e \\(Y\\) non sono indipendenti, la formula viene corretta dalla loro covarianza:\n\\[\n\\mathbb{V}(X+Y) = \\mathbb{V}(X) + \\mathbb{V}(Y) + 2 Cov(X,Y),\n\\]\ndove \\(Cov(X,Y) = \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y)\\).\nUna dimostrazione numerica di questo principio √® fornita sotto.\n\n# Definire i valori di x e y\nx &lt;- c(2, 1, 4, 7)\ny &lt;- c(1, 3, 5, 11)\n\n# Calcolare la varianza di x + y con ddof = 0\nvar_x_y &lt;- mean((x + y - mean(x + y))^2)\nvar_x_y\n#&gt; [1] 35.2\n\n\n# Definire i valori di x e y\nx &lt;- c(2, 1, 4, 7)\ny &lt;- c(1, 3, 5, 11)\n\n# Calcolo della varianza combinata\nresult &lt;- mean((x - mean(x))^2) + \n          mean((y - mean(y))^2) + \n          2 * cov(x, y) * (length(x) - 1) / length(x)\nresult\n#&gt; [1] 35.2\n\nVarianza della media di variabili indipendenti. La media aritmetica \\(\\textstyle {\\bar  {X}}={\\frac  {X_{1}+\\ldots +X_{n}}{n}}\\) di \\(n\\) variabili casuali indipendenti aventi la medesima distribuzione, ha varianza\n\\[\n\\mathbb{V}(\\bar{X}) = \\frac{1}{n^2} \\mathbb{V}(X_1)+ \\dots \\mathbb{V}(X_n) = \\frac{1}{n^2} n \\mathbb{V}(X) = \\frac{1}{n} \\mathbb{V}(X).\n\\]\nIl principio precedente √® illustrato dalla seguente simulazione.\n\n# Creare la popolazione\nset.seed(123)  # Per riproducibilit√†\npopulation &lt;- rnorm(10000, mean = 50, sd = 10)\n\n# Definire dimensione del campione e numero di campioni\nsample_size &lt;- 30\nnum_samples &lt;- 100000\n\n# Creare un vettore per memorizzare le medie campionarie\nsample_means &lt;- numeric(num_samples)\n\n# Generare i campioni e calcolare le medie\nfor (i in 1:num_samples) {\n  sample &lt;- sample(population, size = sample_size, replace = TRUE)\n  sample_means[i] &lt;- mean(sample)\n}\n\n# Calcolare la varianza delle medie campionarie\nsampling_dist_mean_var &lt;- var(sample_means) * ((num_samples - 1) / num_samples)  # ddof = 0\nsampling_dist_mean_var\n#&gt; [1] 3.33\n\nIl valore teorico della varianza della distribuzione campionaria della media √®\n\n10^2 / 30\n#&gt; [1] 3.33\n\n\n\n29.3.4 Variabili casuali continue\nPer una variabile casuale continua \\(X\\), la varianza √® definita come:\n\\[\n\\mathbb{V}(X) = \\int_{-\\infty}^{+\\infty} \\large[x - \\mathbb{E}(X)\\large]^2 p(x) \\,\\operatorname {d}\\!x.\n\\tag{29.7}\\]\nAnalogamente al caso discreto, la varianza di una variabile casuale continua \\(X\\) una misura della dispersione, ovvero la ‚Äúdistanza‚Äù media quadratica attesa dei valori \\(x\\) rispetto alla loro media \\(\\mathbb{E}(X)\\). In altre parole, la varianza quantifica quanto i valori della variabile casuale si discostano tipicamente dal loro valore medio.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_expval_var.html#deviazione-standard",
    "href": "chapters/probability/06_expval_var.html#deviazione-standard",
    "title": "29¬† Propriet√† delle variabili casuali",
    "section": "29.4 Deviazione Standard",
    "text": "29.4 Deviazione Standard\nQuando si lavora con le varianze, i valori sono elevati al quadrato, il che pu√≤ rendere i numeri significativamente pi√π grandi (o pi√π piccoli) rispetto ai dati originali. Per riportare questi valori all‚Äôunit√† di misura della scala originale, si prende la radice quadrata della varianza. Il risultato ottenuto √® chiamato deviazione standard ed √® comunemente indicato con la lettera greca \\(\\sigma\\).\n\nDefinizione 29.3 La deviazione standard, o scarto quadratico medio, √® definita come la radice quadrata della varianza:\n\\[\n\\sigma_X = \\sqrt{\\mathbb{V}(X)}.\n\\]\n\nCome nella statistica descrittiva, la deviazione standard di una variabile casuale fornisce una misura della dispersione, ossia la ‚Äúdistanza‚Äù tipica o prevista dei valori \\(x\\) rispetto alla loro media.\n\nEsempio 29.10 Per i dadi equilibrati dell‚Äôesempio precedente, la deviazione standard della variabile casuale \\(S\\) √® pari a \\(\\sqrt{5.833} = 2.415\\). Questo valore indica quanto i risultati della somma dei due dadi tendono a variare attorno alla loro media.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_expval_var.html#standardizzazione",
    "href": "chapters/probability/06_expval_var.html#standardizzazione",
    "title": "29¬† Propriet√† delle variabili casuali",
    "section": "29.5 Standardizzazione",
    "text": "29.5 Standardizzazione\n\nDefinizione 29.4 Data una variabile casuale \\(X\\), si dice variabile standardizzata di \\(X\\) l‚Äôespressione\n\\[\nZ = \\frac{X - \\mathbb{E}(X)}{\\sigma_X}.\n\\tag{29.8}\\]\n\nSolitamente, una variabile standardizzata viene denotata con la lettera \\(Z\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_expval_var.html#il-teorema-di-chebyshev",
    "href": "chapters/probability/06_expval_var.html#il-teorema-di-chebyshev",
    "title": "29¬† Propriet√† delle variabili casuali",
    "section": "29.6 Il Teorema di Chebyshev",
    "text": "29.6 Il Teorema di Chebyshev\nIl Teorema di Chebyshev ci permette di stimare la probabilit√† che una variabile aleatoria si discosti dal suo valore atteso (media) di una certa quantit√†. In altre parole, ci fornisce un limite superiore alla probabilit√† che una variabile aleatoria assuma valori ‚Äúestremi‚Äù.\nIl teorema di Chebyshev afferma che, per qualsiasi variabile aleatoria X con media E(X) e varianza Var(X), e per qualsiasi numero reale k &gt; 0, si ha:\n\\[\nP(|X - E(X)| ‚â• kœÉ) ‚â§ 1/k^2,\n\\]\ndove:\n\nP(|X - E(X)| ‚â• kœÉ) √® la probabilit√† che lo scarto assoluto tra X e la sua media sia maggiore o uguale a k volte la deviazione standard (œÉ).\nœÉ √® la radice quadrata della varianza, ovvero la deviazione standard.\n\nCosa ci dice questo teorema?\n\nLimite superiore: Il teorema ci fornisce un limite superiore alla probabilit√† che una variabile aleatoria si discosti dalla sua media di pi√π di k deviazioni standard.\nQualsiasi distribuzione: La bellezza di questo teorema √® che vale per qualsiasi distribuzione di probabilit√†, a patto che la media e la varianza esistano.\nUtilizzo: Il teorema di Chebyshev √® molto utile quando non conosciamo la distribuzione esatta di una variabile aleatoria, ma conosciamo la sua media e la sua varianza.\n\nIn sintesi, il teorema di Chebyshev ci fornisce un limite superiore alla probabilit√† che una variabile aleatoria si discosti dalla sua media di una certa quantit√†, in base alla sua varianza. Il teorema di Chebyshev ci permette quindi di fare inferenze sulla distribuzione di una variabile aleatoria anche quando abbiamo informazioni limitate.\n\nEsempio 29.11 Supponiamo di avere una variabile aleatoria X con media 100 e varianza 25. Vogliamo stimare la probabilit√† che X assuma valori al di fuori dell‚Äôintervallo [90, 110]. In questo caso, k = 2 (poich√© 10 √® uguale a 2 volte la deviazione standard, che √® 5). Applicando il teorema di Chebyshev, otteniamo:\nP(|X - 100| ‚â• 10) ‚â§ 1/2^2 = 0.25\nQuindi, possiamo affermare con certezza che al massimo il 25% dei valori di X saranno al di fuori dell‚Äôintervallo [90, 110].",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_expval_var.html#momenti-di-variabili-casuali",
    "href": "chapters/probability/06_expval_var.html#momenti-di-variabili-casuali",
    "title": "29¬† Propriet√† delle variabili casuali",
    "section": "29.7 Momenti di variabili casuali",
    "text": "29.7 Momenti di variabili casuali\n\nDefinizione 29.5 Si chiama momento di ordine \\(q\\) di una v.c. \\(X\\), dotata di densit√† \\(p(x)\\), la quantit√†\n\\[\n\\mathbb{E}(X^q) = \\int_{-\\infty}^{+\\infty} x^q p(x) \\; dx.\n\\tag{29.9}\\]\nSe \\(X\\) √® una v.c. discreta, i suoi momenti valgono:\n\\[\n\\mathbb{E}(X^q) = \\sum_i x_i^q P(x_i),\n\\tag{29.10}\\]\ndove:\n\n\\(E(X^q)\\) rappresenta il valore atteso di \\(X\\) elevato alla \\(q\\)-esima potenza.\n\\(x_i\\) sono i possibili valori della variabile discreta.\n\\(P(x_i)\\) √® la probabilit√† associata a ciascun valore discreto.\n\n\nI momenti sono parametri statistici che forniscono informazioni importanti sulle caratteristiche di una variabile casuale. Tra questi, i pi√π noti e utilizzati sono:\n\nIl momento del primo ordine (\\(q\\) = 1): corrisponde al valore atteso (o media) della variabile casuale \\(X\\).\nIl momento del secondo ordine (\\(q\\) = 2): quando calcolato rispetto alla media, corrisponde alla varianza.\n\nPer i momenti di ordine superiore al primo, √® comune calcolarli rispetto al valore medio di \\(X\\). Questo si ottiene applicando una traslazione: \\(x_0 = x ‚àí \\mathbb{E}(X)\\), dove \\(x_0\\) rappresenta lo scarto dalla media. In particolare, il momento centrale del secondo ordine, calcolato con questa traslazione, corrisponde alla definizione di varianza.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_expval_var.html#alcuni-esempi-in-r",
    "href": "chapters/probability/06_expval_var.html#alcuni-esempi-in-r",
    "title": "29¬† Propriet√† delle variabili casuali",
    "section": "29.8 Alcuni esempi in R",
    "text": "29.8 Alcuni esempi in R\nIn R, possiamo calcolare il valore atteso e la varianza di variabili casuali discrete utilizzando vettori di valori e probabilit√†.\nConsideriamo una variabile casuale \\(X\\) che rappresenta i valori ottenuti dal lancio di un dado non equilibrato, con valori possibili da 0 a 6, e con la seguente distribuzione di massa di probabilit√†: 0.1, 0.2, 0.3, 0.1, 0.1, 0.0, 0.2.\nIniziamo a definire un vettore che contiene i valori della v.c.:\n\nx &lt;- 0:6\nprint(x)\n#&gt; [1] 0 1 2 3 4 5 6\n\nIl vettore px conterr√† le probabilit√† associate ai valori x:\n\npx &lt;- c(0.1, 0.2, 0.3, 0.1, 0.1, 0.0, 0.2)\nprint(px)\n#&gt; [1] 0.1 0.2 0.3 0.1 0.1 0.0 0.2\n\nControlliamo che la somma sia 1:\n\nsum(px)\n#&gt; [1] 1\n\nCalcoliamo il valore atteso di \\(X\\) implementando la formula del valore atteso utilizzando i vettori x e px:\n\nx_ev &lt;- sum(x * px)\nx_ev\n#&gt; [1] 2.7\n\nCalcoliamo la varianza di \\(X\\) usando i vettori x e px:\n\nx_var &lt;- sum((x - x_ev)^2 * px)\nx_var\n#&gt; [1] 3.81\n\nCalcoliamo la deviazione standard di \\(X\\) prendendo la radice quadrata della varianza:\n\nx_sd &lt;- sqrt(x_var)\nx_sd\n#&gt; [1] 1.95\n\nPer rappresentare graficamente la distribuzione di massa, possiamo usare ggplot2:\n\ndf &lt;- data.frame(x = x, pmf = px)\nggplot(df, aes(x = x, y = pmf)) +\n  geom_point(color = \"#832F2B\", size = 3) +\n  geom_segment(aes(xend = x, yend = 0), linewidth = 1) +\n  labs(title = \"Distribuzione di massa di probabilit√†\", \n       x = \"Valori\", y = \"Probabilit√†\")\n\n\n\n\n\n\n\n\nQuesto codice calcola il valore atteso, la varianza e la deviazione standard di una variabile casuale discreta e rappresenta graficamente la distribuzione di massa, tutto in R.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_expval_var.html#riflessioni-conclusive",
    "href": "chapters/probability/06_expval_var.html#riflessioni-conclusive",
    "title": "29¬† Propriet√† delle variabili casuali",
    "section": "29.9 Riflessioni Conclusive",
    "text": "29.9 Riflessioni Conclusive\nIn conclusione, i concetti di valore atteso e varianza sono fondamentali per comprendere il comportamento delle variabili casuali. Il valore atteso fornisce una misura centrale, rappresentando il ‚Äúvalore tipico‚Äù che ci si aspetta di osservare, mentre la varianza quantifica la dispersione dei valori attorno a questa media, offrendo una visione pi√π completa della distribuzione. Questi strumenti sono essenziali per l‚Äôanalisi e la modellizzazione statistica, fornendo le basi per valutare e interpretare la variabilit√† nei fenomeni aleatori.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_expval_var.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/06_expval_var.html#informazioni-sullambiente-di-sviluppo",
    "title": "29¬† Propriet√† delle variabili casuali",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: US/Pacific\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.17.0      ggokabeito_0.1.0 see_0.9.0        gridExtra_2.3   \n#&gt;  [5] patchwork_1.3.0  bayesplot_1.11.1 psych_2.4.12     scales_1.3.0    \n#&gt;  [9] markdown_1.13    knitr_1.49       lubridate_1.9.4  forcats_1.0.0   \n#&gt; [13] stringr_1.5.1    dplyr_1.1.4      purrr_1.0.2      readr_2.1.5     \n#&gt; [17] tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0 \n#&gt; [21] rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      shape_1.4.6.1     xfun_0.50         htmlwidgets_1.6.4\n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2      \n#&gt;  [9] generics_0.1.3    parallel_4.4.2    pan_1.9           pacman_0.5.1     \n#&gt; [13] jomo_2.7-6        pkgconfig_2.0.3   Matrix_1.7-1      lifecycle_1.0.4  \n#&gt; [17] compiler_4.4.2    farver_2.1.2      munsell_0.5.1     mnormt_2.1.1     \n#&gt; [21] codetools_0.2-20  htmltools_0.5.8.1 yaml_2.3.10       glmnet_4.1-8     \n#&gt; [25] nloptr_2.1.1      pillar_1.10.1     MASS_7.3-64       iterators_1.0.14 \n#&gt; [29] rpart_4.1.23      boot_1.3-31       foreach_1.5.2     mitml_0.4-5      \n#&gt; [33] nlme_3.1-166      tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4    \n#&gt; [37] labeling_0.4.3    splines_4.4.2     rprojroot_2.0.4   fastmap_1.2.0    \n#&gt; [41] grid_4.4.2        colorspace_2.1-1  cli_3.6.3         magrittr_2.0.3   \n#&gt; [45] survival_3.7-0    broom_1.0.7       withr_3.0.2       backports_1.5.0  \n#&gt; [49] timechange_0.3.0  rmarkdown_2.29    nnet_7.3-19       lme4_1.1-35.5    \n#&gt; [53] hms_1.1.3         evaluate_1.0.1    rlang_1.1.4       Rcpp_1.0.13-1    \n#&gt; [57] glue_1.8.0        minqa_1.2.8       jsonlite_1.8.9    R6_2.5.1",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_bayes_theorem.html",
    "href": "chapters/probability/07_bayes_theorem.html",
    "title": "30¬† Il teorema di Bayes",
    "section": "",
    "text": "30.1 Introduzione\nIl teorema di Bayes offre una soluzione ottimale ai problemi induttivi, che spaziano dall‚Äôidentificazione della struttura tridimensionale del mondo basata su dati sensoriali limitati, all‚Äôinferenza dei pensieri altrui a partire dal loro comportamento. Questa regola si rivela particolarmente utile in situazioni in cui i dati osservati sono insufficienti per distinguere in modo definitivo tra diverse ipotesi.\nNonostante ci√≤, tutte le previsioni basate su questo metodo mantengono un certo grado di incertezza. Anche se l‚Äôuniverso fosse completamente deterministico, la nostra conoscenza di esso rimarrebbe imperfetta: non possiamo conoscere la posizione e lo stato di ogni singola particella che lo compone. Le informazioni a nostra disposizione sono inevitabilmente parziali e imprecise, ottenute attraverso i nostri sensi limitati.\nLa vita reale non √® paragonabile a una partita di scacchi, un gioco con informazioni perfette che pu√≤ essere ‚Äúrisolto‚Äù in linea di principio. Assomiglia piuttosto al poker, dove le decisioni vengono prese utilizzando le informazioni limitate a disposizione dei giocatori. Questo capitolo si concentra sull‚Äôequazione che ci permette di fare proprio questo: il teorema di Bayes. Esso descrive come modifichiamo le nostre convinzioni riguardo a un‚Äôipotesi in una situazione in cui i dati disponibili non consentono una decisione certa.\nQuesto processo √® noto come inferenza induttiva, che ci permette di trarre conclusioni generali da dati specifici e limitati. Il teorema di Bayes fornisce quindi un framework matematico per aggiornare le nostre credenze alla luce di nuove evidenze, permettendoci di prendere decisioni informate in un mondo caratterizzato dall‚Äôincertezza.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_bayes_theorem.html#una-rivoluzione-nel-pensiero-probabilistico",
    "href": "chapters/probability/07_bayes_theorem.html#una-rivoluzione-nel-pensiero-probabilistico",
    "title": "30¬† Il teorema di Bayes",
    "section": "30.2 Una Rivoluzione nel Pensiero Probabilistico",
    "text": "30.2 Una Rivoluzione nel Pensiero Probabilistico\nNel cuore del XVIII secolo, un ecclesiastico presbiteriano di nome Thomas Bayes gett√≤ le basi per una delle pi√π importanti rivoluzioni nel campo della statistica e del calcolo delle probabilit√†. Il suo contributo, noto oggi come teorema di Bayes, non solo ha trasformato il modo in cui comprendiamo e applichiamo la probabilit√†, ma continua a influenzare profondamente la scienza moderna e la tecnologia, inclusa l‚Äôintelligenza artificiale (Chivers, 2024).\nThomas Bayes nacque in una famiglia benestante e ricevette un‚Äôeducazione di alto livello, studiando teologia a Edimburgo per prepararsi alla vita da ecclesiastico. Come nota il suo biografo Bellhouse, Bayes ‚Äúnon sembrava un accademico moderno. Era pi√π un dilettante, un virtuoso. Lo faceva per il proprio piacere piuttosto che avere un‚Äôagenda di ricerca.‚Äù\nBayes pubblic√≤ due opere principali durante la sua vita:\n\nUna di teologia, ‚ÄúDivine benevolence: Or, an attempt to prove that the principal end of the divine providence and government is the happiness of his creatures‚Äù, nel 1731.\nUna difesa del calcolo newtoniano, ‚ÄúAn Introduction to the Doctrine of Fluxions‚Äù, in risposta a una critica del filosofo George Berkeley.\n\nTuttavia, fu il suo lavoro postumo, ‚ÄúAn Essay towards Solving a Problem in the Doctrine of Chances‚Äù, pubblicato nel 1763 nella rivista Philosophical Transactions, a cambiare per sempre il corso della teoria della probabilit√†.\nBellhouse nota che l‚Äôinteresse di Bayes per la matematica era tipico del suo tempo: ‚ÄúNel XVIII secolo, i ricchi si dedicavano alla scienza. √à un po‚Äô come i ricchi di oggi che si dedicano agli sport.‚Äù Ma forse Bellhouse si riferiva solo al suo tempo: oggi i ricchi sembrano interessarsi solo ai social media.\nIl contributo di Bayes non fu tanto matematico quanto filosofico. David Spiegelhalter, ex presidente della Royal Statistical Society, spiega che per Bayes ‚Äúla probabilit√† √® un‚Äôespressione della nostra mancanza di conoscenza sul mondo.‚Äù Questa visione introduce l‚Äôidea rivoluzionaria che la probabilit√† sia soggettiva, un‚Äôespressione della nostra conoscenza limitata e delle nostre supposizioni sulla verit√†, piuttosto che una propriet√† oggettiva della realt√†.\nPer illustrare questo concetto, Bayes utilizz√≤ l‚Äôesempio di un tavolo nascosto alla vista su cui vengono lanciate delle palle. Una palla bianca viene lanciata in modo tale che la sua posizione finale sia completamente casuale. Quando la palla bianca si ferma, viene rimossa e si traccia una linea sul tavolo nel punto in cui si trovava. La posizione della linea non √® nota. Successivamente, un certo numero di palle rosse viene lanciato sul tavolo. Viene comunicato solo quante palle si trovano a sinistra della linea e quante a destra. Il compito √® stimare la posizione della linea. La soluzione proposta da Bayes utilizza non solo i dati osservati (il numero di palle rosse a sinistra e a destra della linea), ma anche le convinzioni iniziali (il ‚Äúprior‚Äù).\nRichard Price (1723-1791), un altro ecclesiastico nonconformista, ebbe un ruolo cruciale nella diffusione del lavoro di Thomas Bayes. Molto pi√π noto del suo amico, Price era ben inserito nei circoli intellettuali dell‚Äôepoca. Era in contatto con diversi Padri Fondatori della Rivoluzione Americana, tra cui Thomas Jefferson e Benjamin Franklin, cos√¨ come John Adams, il secondo presidente degli Stati Uniti. Supportava attivamente la rivoluzione americana, pubblicando un influente opuscolo Observations on the Nature of Civil Liberty, the Principles of Government, and the Justice and Policy of the War with America nel 1776. Era amico di filosofi come David Hume e Adam Smith.\nPrice √® importante in questa storia come colui che port√≤ all‚Äôattenzione pubblica il lavoro di Bayes: mostr√≤ il saggio al fisico John Canton nel 1761, dopo la morte di Bayes, e lo fece pubblicare nelle Philosophical Transactions della Royal Society due anni dopo. Parte del motivo per cui ci volle tanto tempo per pubblicarlo era che Price non si limit√≤ a correggere refusi e virgole fuori posto. Price aveva una visione propria del lavoro: mentre Bayes scrisse la prima met√† del saggio, la seconda met√†, contenente tutte le possibili applicazioni pratiche del teorema, fu tutta opera di Price. Bayes non aveva interesse per le statistiche applicate: il suo lavoro, in questo e in tutti gli altri articoli, era ‚Äútutta teoria senza alcun accenno di applicazione.‚Äù Ma Price fu ‚Äì come dice lo storico della statistica Stephen Stigler ‚Äì ‚Äúil primo bayesiano.‚Äù\nSebbene il lavoro di Bayes sia rimasto nell‚Äôombra per decenni, con Pierre-Simon Laplace che giunse indipendentemente a conclusioni simili nel 1774 e le espanse nella sua ‚ÄúTh√©orie analytique des probabilit√©s‚Äù del 1812, l‚Äôimportanza del teorema di Bayes √® oggi indiscutibile. Esso fornisce un meccanismo matematico per aggiornare le probabilit√† di un‚Äôipotesi in base a nuove evidenze, riflettendo un approccio dinamico e iterativo alla conoscenza.\nNel panorama contemporaneo, il teorema di Bayes trova applicazioni in ogni campo della scienza e della tecnologia. √à particolarmente rilevante nel campo dell‚Äôintelligenza artificiale, dove modelli linguistici avanzati come ChatGPT e Claude utilizzano principi bayesiani per fare previsioni e prendere decisioni.\nIn conclusione, il teorema di Bayes, nato dalle riflessioni di un ministro presbiteriano del XVIII secolo, ha trasformato il nostro modo di comprendere la probabilit√† e di aggiornare le nostre conoscenze. La sua rilevanza universale nella comprensione e previsione dei fenomeni √® tale che, come afferma Brian Clegg nel suo libro ‚ÄúEverything is predictable: how bayesian statistics explain our world‚Äù, la statistica bayesiana √® diventata uno strumento fondamentale per spiegare il nostro mondo (Chivers, 2024).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_bayes_theorem.html#la-regola-di-bayes",
    "href": "chapters/probability/07_bayes_theorem.html#la-regola-di-bayes",
    "title": "30¬† Il teorema di Bayes",
    "section": "30.3 La Regola di Bayes",
    "text": "30.3 La Regola di Bayes\nL‚Äôinferenza bayesiana si basa su una formula fondamentale nota come regola di Bayes. Sebbene sia un semplice risultato della teoria delle probabilit√†, la sua applicazione ha implicazioni profonde in molti campi, inclusi la scienza cognitiva e l‚Äôapprendimento automatico. Supponiamo di avere due variabili casuali, \\(A\\) e \\(B\\). Un principio della probabilit√†, chiamato regola della catena, ci consente di esprimere la probabilit√† congiunta di queste due variabili \\(P(A, B)\\) come il prodotto della probabilit√† condizionale di \\(A\\) dato \\(B\\) e della probabilit√† marginale di \\(B\\). In termini formali:\n\\[\nP(A, B) = P(A \\mid B) P(B).\n\\tag{30.1}\\]\nNon vi √® nulla di speciale nel trattare \\(A\\) prima di \\(B\\); possiamo infatti scrivere anche:\n\\[\nP(A, B) = P(B \\mid A) P(A).\n\\tag{30.2}\\]\nDalle due equazioni precedenti possiamo derivare la regola di Bayes riorganizzando i termini:\n\\[\nP(B \\mid A) = \\frac{P(A \\mid B) P(B)}{P(A)}.\n\\tag{30.3}\\]\nQuesta espressione, nota come regola di Bayes, ci permette di calcolare la probabilit√† condizionale di \\(B\\) dato \\(A\\), usando la probabilit√† condizionale opposta \\(P(A \\mid B)\\), la probabilit√† a priori \\(P(B)\\) e la probabilit√† marginale \\(P(A)\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_bayes_theorem.html#applicazioni-della-regola-di-bayes",
    "href": "chapters/probability/07_bayes_theorem.html#applicazioni-della-regola-di-bayes",
    "title": "30¬† Il teorema di Bayes",
    "section": "30.4 Applicazioni della Regola di Bayes",
    "text": "30.4 Applicazioni della Regola di Bayes\nLa forza della regola di Bayes si manifesta pienamente quando viene applicata al contesto dell‚Äôinferenza. Supponiamo di avere un agente che cerca di inferire quale processo ha generato alcuni dati \\(D\\). Indichiamo con \\(H\\) un‚Äôipotesi su tale processo. L‚Äôagente usa le probabilit√† per rappresentare il grado di credenza in \\(H\\) e nelle ipotesi alternative \\(H'\\). La probabilit√† a priori \\(P(H)\\) rappresenta la credenza che l‚Äôagente attribuisce a \\(H\\) prima di osservare i dati.\nQuando l‚Äôagente osserva i nuovi dati \\(D\\), aggiorna la credenza ottenendo la probabilit√† a posteriori \\(P(H \\mid D)\\). La regola di Bayes permette di calcolare questa probabilit√† come segue:\n\\[\nP(H \\mid D) = \\frac{P(D \\mid H) P(H)}{P(D)}.\n\\tag{30.4}\\]\nIn questa equazione:\n\n\\(P(D \\mid H)\\): la verosimiglianza, ovvero la probabilit√† di osservare i dati \\(D\\) assumendo che l‚Äôipotesi \\(H\\) sia vera. Questa componente valuta quanto l‚Äôipotesi predice i dati osservati.\n\\(P(H)\\): la probabilit√† a priori di \\(H\\).\n\\(P(D)\\): la probabilit√† marginale dei dati, calcolata sommando (o integrando) le probabilit√† congiunte per tutte le ipotesi \\(H'\\).\n\n\n\n30.4.1 La Marginalizzazione\nLa probabilit√† marginale di \\(D\\), necessaria per normalizzare la distribuzione a posteriori, si ottiene considerando tutte le ipotesi possibili \\(H'\\). Per ipotesi discrete, la somma √®:\n\\[\nP(D) = \\sum_{H' \\in H} P(D \\mid H') P(H').\n\\]\nSostituendo questa espressione nella regola di Bayes otteniamo:\n\\[\nP(H \\mid D) = \\frac{P(D \\mid H) P(H)}{\\sum_{H' \\in H} P(D \\mid H') P(H')}.\n\\tag{30.5}\\]\nNel caso continuo, la somma √® sostituita da un integrale:\n\\[\nP(H \\mid D) = \\frac{P(D \\mid H) P(H)}{\\int P(D \\mid H') P(H') \\, dH'}.\n\\tag{30.6}\\]\n\n\n\n30.4.2 Componenti Chiave della Formula di Bayes\nLa regola di Bayes si basa su tre componenti principali:\n\nProbabilit√† a Priori \\(P(H)\\): La credenza iniziale sull‚Äôipotesi \\(H\\), basata su informazioni preesistenti.\nVerosimiglianza \\(P(D \\mid H)\\): La probabilit√† dei dati osservati \\(D\\), dato che \\(H\\) sia vera. Misura quanto \\(H\\) spiega \\(D\\).\nProbabilit√† a Posteriori \\(P(H \\mid D)\\): La credenza aggiornata in \\(H\\) dopo aver osservato \\(D\\).\n\nGrazie alla regola di Bayes, possiamo aggiornare costantemente le nostre credenze man mano che nuove informazioni diventano disponibili. Questo processo dinamico di aggiornamento ci permette di affinare le nostre convinzioni e le nostre previsioni, rendendo il modello bayesiano particolarmente utile nelle situazioni in cui le informazioni sono incomplete o incerte. Questo approccio non solo ci consente di prendere decisioni pi√π informate, ma ci permette anche di sviluppare modelli pi√π accurati della realt√† basati sulle evidenze.\n\n\n30.4.3 Applicazioni dei modelli bayesiani\nCome discusso da Griffiths et al. (2024), negli ultimi anni, i modelli bayesiani hanno acquisito un‚Äôimportanza crescente in vari campi delle scienze cognitive. Questi modelli sono stati applicati allo studio dell‚Äôapprendimento animale (Courville, Daw, & Touretzky, 2006), dell‚Äôapprendimento induttivo umano e della generalizzazione (Tenenbaum, Griffiths, & Kemp, 2006), della percezione visiva (Yuille & Kersten, 2006), del controllo motorio (Kording & Wolpert, 2006), della memoria semantica (Steyvers, Griffiths, & Dennis, 2006), dell‚Äôacquisizione e del processamento del linguaggio (Chater & Manning, 2006; Xu & Tenenbaum, in press), del ragionamento simbolico (Oaksford & Chater, 2001), dell‚Äôapprendimento causale (Steyvers, Tenenbaum, Wagenmakers, & Blum, 2003; Griffiths & Tenenbaum, 2005, 2007a), e della cognizione sociale (Baker, Tenenbaum, & Saxe, 2007), tra molti altri argomenti.\nDietro questi diversi programmi di ricerca emerge una domanda centrale: come fa la mente umana ad andare oltre i dati dell‚Äôesperienza? In altre parole, come riesce la mente a costruire modelli complessi e astratti del mondo, partendo solo da dati sparsi e rumorosi, osservati attraverso i nostri sensi? La risposta proposta dall‚Äôapproccio bayesiano √® che la mente umana utilizza un processo di inferenza probabilistica per aggiornare le proprie credenze sulla base delle nuove evidenze, creando cos√¨ modelli del mondo sempre pi√π accurati e raffinati.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_bayes_theorem.html#test-medici",
    "href": "chapters/probability/07_bayes_theorem.html#test-medici",
    "title": "30¬† Il teorema di Bayes",
    "section": "30.5 Test medici",
    "text": "30.5 Test medici\nIl modo pi√π comune per spiegare il teorema di Bayes √® attraverso i test medici.\n\nEsempio 30.1 Prendiamo come esempio il caso della mammografia e la diagnosi del cancro al seno che abbiamo gi√† discusso in precedenza. Supponiamo di avere un test di mammografia con una sensibilit√† del 90% e una specificit√† del 90%. Questo significa che:\n\nIn presenza di cancro al seno, la probabilit√† che il test lo rilevi correttamente √® del 90%.\nIn assenza di cancro al seno, la probabilit√† che il test confermi correttamente l‚Äôassenza della malattia √® del 90%.\n\nIn altri termini, il test ha un tasso di falsi negativi del 10% e un tasso di falsi positivi anch‚Äôesso del 10%.\nDefiniamo due ipotesi:\n\n\\(M^+\\): presenza della malattia\n\\(M^-\\): assenza della malattia\n\nL‚Äôevidenza √® rappresentata dal risultato positivo di un test di mammografia, che indichiamo con \\(T^+\\).\nApplicando il teorema di Bayes, possiamo calcolare la probabilit√† di avere il cancro al seno dato un risultato positivo al test, come segue:\n\\[\nP(M^+ \\mid T^+) = \\frac{P(T^+ \\mid M^+) \\cdot P(M^+)}{P(T^+ \\mid M^+) \\cdot P(M^+) + P(T^+ \\mid M^-) \\cdot P(M^-)},\n\\]\ndove:\n\n\\(P(M^+ \\mid T^+)\\) √® la probabilit√† di avere il cancro (\\(M^+\\)) dato un risultato positivo al test (\\(T^+\\)).\n\\(P(T^+ \\mid M^+)\\) rappresenta la sensibilit√† del test, ovvero la probabilit√† che il test risulti positivo in presenza effettiva del cancro. In questo caso, √® pari a 0.90.\n\\(P(M^+)\\) √® la probabilit√† a priori che una persona abbia il cancro, ovvero la prevalenza della malattia nella popolazione.\n\\(P(T^+ \\mid M^-)\\) indica la probabilit√† di un falso positivo, cio√® la probabilit√† che il test risulti positivo in assenza di cancro. Con una specificit√† del 90%, questa probabilit√† si calcola come:\n\\[\nP(T^+ \\mid M^-) = 1 - \\text{Specificit√†} = 1 - 0.90 = 0.10\n\\]\nQuesto significa che c‚Äô√® una probabilit√† del 10% che il test diagnostichi erroneamente la presenza del cancro in una persona sana.\n\\(P(M^-)\\) √® la probabilit√† a priori che una persona non sia affetta da cancro prima di effettuare il test.\n\nQuesta formulazione del teorema di Bayes ci permette di calcolare la probabilit√† effettiva di avere il cancro al seno, dato un risultato positivo al test di mammografia, tenendo conto sia della sensibilit√† e specificit√† del test, sia della prevalenza della malattia nella popolazione.\nInserendo nella formula i del problema, otteniamo:\n\\[\n\\begin{align}\nP(M^+ \\mid T^+) &= \\frac{0.9 \\cdot 0.01}{0.9 \\cdot 0.01 + 0.1 \\cdot 0.99} \\notag\\\\\n&= \\frac{9}{108} \\notag\\\\\n&\\approx 0.083.\\notag\n\\end{align}\n\\]\nI calcoli effettuati evidenziano come, in presenza di una mammografia positiva ottenuta con un test avente sensibilit√† e specificit√† pari al 90%, la probabilit√† di effettiva positivit√† al tumore al seno si attesta intorno all‚Äô8.3%. Tale risultato conferma quanto precedentemente ottenuto nel ?sec-cond-prob, attraverso un metodo di calcolo alternativo.\n\n\n30.5.1 Il Valore Predittivo di un Test di Laboratorio\nPer semplicit√†, possiamo riscrivere il teorema di Bayes in due modi distinti per calcolare ci√≤ che viene chiamato valore predittivo del test positivo e valore predittivo del test negativo.\nLa comprensione di tre elementi √® fondamentale per questo calcolo: la prevalenza della malattia, la sensibilit√† e la specificit√† del test.\n\nPrevalenza: Si riferisce alla percentuale di individui in una popolazione affetti da una certa malattia in un determinato momento. Viene espressa come percentuale o frazione della popolazione. Per esempio, una prevalenza dello 0,5% indica che su mille persone, cinque sono affette dalla malattia.\nSensibilit√†: Indica la capacit√† del test di identificare correttamente la malattia negli individui malati. Viene calcolata come la frazione di veri positivi (individui malati correttamente identificati) sul totale degli individui malati. La formula della sensibilit√† (\\(Sens\\)) √® la seguente:\n\\[ \\text{Sensibilit√†} = \\frac{TP}{TP + FN}, \\]\ndove \\(TP\\) rappresenta i veri positivi e \\(FN\\) i falsi negativi. Pertanto, la sensibilit√† misura la probabilit√† che il test risulti positivo se la malattia √® effettivamente presente.\nSpecificit√†: Misura la capacit√† del test di riconoscere gli individui sani, producendo un risultato negativo per chi non √® affetto dalla malattia. Si calcola come la frazione di veri negativi (individui sani correttamente identificati) sul totale degli individui sani. La specificit√† (\\(Spec\\)) si definisce come:\n\\[ \\text{Specificit√†} = \\frac{TN}{TN + FP}, \\]\ndove \\(TN\\) sono i veri negativi e \\(FP\\) i falsi positivi. Cos√¨, la specificit√† rappresenta la probabilit√† che il test risulti negativo in assenza della malattia.\n\nQuesta tabella riassume la terminologia:\n\n\n\n\n\n\n\n\n\n\n\\(T^+\\)\n\\(T^-\\)\nTotale\n\n\n\n\n\\(M^+\\)\n\\(P(T^+ \\cap M^+)\\)  (Sensibilit√†)\n\\(P(T^- \\cap M^+)\\)  (1 - Sensibilit√†)\n\\(P(M^+)\\)\n\n\n\\(M^-\\)\n\\(P(T^+ \\cap M^-)\\)  (1 - Specificit√†)\n\\(P(T^- \\cap M^-)\\)  (Specificit√†)\n\\(P(M^-)\\)\n\n\nTotale\n\\(P(T^+)\\)\n\\(P(T^-)\\)\n1\n\n\n\ndove \\(T^+\\) e \\(T^-\\) indicano rispettivamente un risultato positivo o negativo del test, mentre \\(M^+\\) e \\(M^-\\) la presenza o assenza effettiva della malattia. In questa tabella, i totali marginali rappresentano:\n\nTotale per \\(M^+\\) e \\(M^-\\) (ultima colonna): La probabilit√† totale di avere la malattia (\\(P(M^+)\\)) e la probabilit√† totale di non avere la malattia (\\(P(M^-)\\)), rispettivamente. Questi valori sono calcolati sommando le probabilit√† all‚Äôinterno di ciascuna riga.\nTotale per \\(T^+\\) e \\(T^-\\) (ultima riga): La probabilit√† totale di un risultato positivo al test (\\(P(T^+)\\)) e la probabilit√† totale di un risultato negativo al test (\\(P(T^-)\\)), rispettivamente. Questi valori sono calcolati sommando le probabilit√† all‚Äôinterno di ciascuna colonna.\nTotale generale (angolo in basso a destra): La somma di tutte le probabilit√†, che per definizione √® 1, rappresentando l‚Äôintera popolazione o il set di casi considerati.\n\nMediante il teorema di Bayes, possiamo usare queste informazioni per stimare la probabilit√† post-test di avere o non avere la malattia basandoci sul risultato del test.\nIl valore predittivo positivo (VPP) del test, cio√® la probabilit√† post-test che un individuo sia malato dato un risultato positivo del test, √® calcolato come:\n\\[\nP(M^+ \\mid T^+) = \\frac{P(T^+ \\mid M^+) \\cdot P(M^+)}{P(T^+ \\mid M^+) \\cdot P(M^+) + P(T^+ \\mid M^-) \\cdot P(M^-)}.\n\\]\novvero,\n\\[ VPP = \\frac{(\\text{Sensibilit√†} \\times \\text{Prevalenza})}{(\\text{Sensibilit√†} \\times \\text{Prevalenza}) + (1 - \\text{Specificit√†}) \\times (1 - \\text{Prevalenza})} \\]\nAnalogamente, il valore predittivo negativo (VPN), che √® la probabilit√† che un individuo non sia malato dato un risultato negativo del test, si calcola come:\n\\[\nP(M^- \\mid T^-) = \\frac{P(T^- \\mid M^-) \\cdot (1 - P(M^+))}{P(T^- \\mid M^-) \\cdot (1 - P(M^+)) + P(T^- \\mid M^+) \\cdot P(M^+)}.\n\\]\novvero,\n\\[ NPV = \\frac{\\text{Specificit√†} \\cdot (1 - \\text{Prevalenza})}{\\text{Specificit√†} \\cdot (1 - \\text{Prevalenza}) + (1 - \\text{Sensibilit√†}) \\cdot \\text{Prevalenza}}. \\]\n\nEsempio 30.2 Implementiamo le formule del valore predittivo positivo e del valore predittivo negativo del test in R e usiamo gli stessi dati dell‚Äôesercizio precedente.\n\npositive_predictive_value_of_diagnostic_test &lt;- function(sens, spec, prev) {\n  (sens * prev) / (sens * prev + (1 - spec) * (1 - prev))\n}\n\nnegative_predictive_value_of_diagnostic_test &lt;- function(sens, spec, prev) {\n  (spec * (1 - prev)) / (spec * (1 - prev) + (1 - sens) * prev)\n}\n\nInseriamo i dati del problema.\n\nsens = 0.9  # sensibilit√†\nspec = 0.9  # specificit√†\nprev = 0.01  # prevalenza\n\nIl valore predittivo del test positivo √®:\n\nres_pos &lt;- positive_predictive_value_of_diagnostic_test(sens, spec, prev)\ncat(sprintf(\"P(M+ | T+) = %.3f\\n\", res_pos))\n#&gt; P(M+ | T+) = 0.083\n\nIl valore predittivo del test negativo √®:\n\nres_neg &lt;- negative_predictive_value_of_diagnostic_test(sens, spec, prev)\ncat(sprintf(\"P(M- | T-) = %.3f\\n\", res_neg))\n#&gt; P(M- | T-) = 0.999\n\n\n\nEsempio 30.3 La simulazione seguente ha lo scopo di aiutare a visualizzare il teorema di Bayes, utilizzando come esempio gli stessi dati della mammografia che abbiamo analizzato in precedenza.\n\n# Parametri\nsensitivity &lt;- 0.90  # Sensibilit√† del test (P(T+ | M+))\nspecificity &lt;- 0.90  # Specificit√† del test (P(T- | M-))\nprev_cancer &lt;- 0.01  # Prevalenza (P(M+))\n\n# Simulazione per una popolazione di 100.000 persone\nN_mammography &lt;- 100000\n\n# Generazione del campione casuale\nset.seed(123)\noutcome_mammography &lt;- sample(\n  c(\"Cancer\", \"Healthy\"), \n  N_mammography, \n  replace = TRUE, \n  prob = c(prev_cancer, 1 - prev_cancer)\n)\n\n# Conteggio delle persone con e senza cancro\nN_C &lt;- sum(outcome_mammography == \"Cancer\")\nN_H &lt;- sum(outcome_mammography == \"Healthy\")\n\n# Simulazione dei risultati del test\ntest_mammography &lt;- character(N_mammography)\ntest_mammography[outcome_mammography == \"Cancer\"] &lt;- sample(\n  c(\"+\", \"-\"), \n  N_C, \n  replace = TRUE, \n  prob = c(sensitivity, 1 - sensitivity)\n)\ntest_mammography[outcome_mammography == \"Healthy\"] &lt;- sample(\n  c(\"-\", \"+\"), \n  N_H, \n  replace = TRUE, \n  prob = c(specificity, 1 - specificity)\n)\n\n# Creazione di un data frame per memorizzare i risultati\ndf_mammography &lt;- tibble(\n  outcome = outcome_mammography,\n  test = test_mammography\n)\n\n# Creazione di una tabella di contingenza\ncontingency_table_mammography &lt;- df_mammography %&gt;%\n  count(outcome, test) %&gt;%\n  pivot_wider(names_from = test, values_from = n, values_fill = 0)\n\ncontingency_table_mammography\n#&gt; # A tibble: 2 √ó 3\n#&gt;   outcome   `+`   `-`\n#&gt;   &lt;chr&gt;   &lt;int&gt; &lt;int&gt;\n#&gt; 1 Cancer    911   114\n#&gt; 2 Healthy  9897 89078\n\n\n# Calcolo delle probabilit√† basate sulla tabella di contingenza\n\n# Veri positivi (cancro e risultato positivo al test)\ntrue_positives &lt;- contingency_table_mammography %&gt;%\n  filter(outcome == \"Cancer\") %&gt;%\n  pull(`+`)\n\n# Falsi positivi (sani e risultato positivo al test)\nfalse_positives &lt;- contingency_table_mammography %&gt;%\n  filter(outcome == \"Healthy\") %&gt;%\n  pull(`+`)\n\n# Frequenza totale dei risultati positivi\ntotal_positives &lt;- true_positives + false_positives\n\n# Applicazione del teorema di Bayes sui dati simulati\nP_M_given_T &lt;- true_positives / total_positives\nP_M_given_T\n#&gt; [1] 0.0843\n\nUtilizzando i dati della simulazione, la probabilit√† che una persona abbia il cancro al seno dato un risultato positivo al test √® molto vicina al valore teorico calcolato in precedenza (circa 8.3%). Se eseguissimo la simulazione nuovamente, il valore ottenuto potrebbe variare leggermente a causa della casualit√† intrinseca nel campionamento. Tuttavia, ripetendo la simulazione molte volte, i risultati tenderanno a convergere verso il valore teorico, grazie alla legge dei grandi numeri. Questo conferma che il modello teorico √® coerente con i risultati simulati.\n\n\nEsempio 30.4 Poniamoci il problema di capire quanto sia affidabile un test per l‚ÄôHIV. Per fare questo, utilizzeremo le seguenti informazioni (Petersen, 2024):\n\nTasso di base dell‚ÄôHIV (P(HIV)): 0.3% (0.003). Questa √® la probabilit√† che una persona nella popolazione generale abbia l‚ÄôHIV.\nSensibilit√† del test (P(Test+ HIV)): 95% (0.95). Questa √® la probabilit√† che il test risulti positivo se la persona ha effettivamente l‚ÄôHIV.\nSpecificit√† del test (P(Test- ¬¨HIV)): 99.28% (0.9928). Questa √® la probabilit√† che il test risulti negativo se la persona non ha l‚ÄôHIV.\n\nCalcolo della probabilit√† di HIV dato un test positivo.\nPer calcolare la probabilit√† di avere l‚ÄôHIV dato un test positivo (P(HIV Test+)), utilizziamo il teorema di Bayes:\n\\[\nP(HIV \\mid Test+) = \\frac{P(Test+ \\mid HIV) \\times P(HIV)}{P(Test+)}.\n\\]\nAbbiamo bisogno di calcolare il denominatore, ovvero la probabilit√† complessiva di ottenere un test positivo (P(Test+)). Questo valore include sia i veri positivi che i falsi positivi:\n\\[\nP(Test+) = P(Test+ \\mid HIV) \\times P(HIV) + P(Test+ \\mid \\neg HIV) \\times P(\\neg HIV),\n\\]\ndove:\n\n\\(P(Test+ \\mid \\neg HIV) = 1 - P(Test- \\mid \\neg HIV) = 1 - 0.9928 = 0.0072\\) (tasso di falsi positivi),\n\\(P(\\neg HIV) = 1 - P(HIV) = 1 - 0.003 = 0.997\\).\n\nCalcoliamo \\(P(Test+)\\):\n\\[\nP(Test+) = (0.95 \\times 0.003) + (0.0072 \\times 0.997) \\approx 0.010027.\n\\]\nOra possiamo calcolare \\(P(HIV \\mid Test+)\\):\n\\[\nP(HIV \\mid Test+) = \\frac{0.95 \\times 0.003}{0.010027} \\approx 0.2844 \\text{ o 28.44\\%}.\n\\]\nQuindi, se il test risulta positivo, la probabilit√† di avere l‚ÄôHIV √® circa il 28.44%.\nCalcolo della probabilit√† di un secondo test positivo.\nDopo un primo test positivo, la probabilit√† di avere l‚ÄôHIV √® aumentata al 28.44%. Ora calcoleremo la probabilit√† che un secondo test risulti positivo e la conseguente probabilit√† di avere l‚ÄôHIV dopo due test positivi consecutivi.\nPer calcolare \\(P(\\text{Secondo Test+})\\), consideriamo due scenari:\n\nLa persona ha effettivamente l‚ÄôHIV:\n\nProbabilit√†: \\(P(HIV \\mid Test+) = 0.2844\\).\nProbabilit√† di un test positivo: \\(P(\\text{Test+} \\mid HIV) = 0.95\\) (sensibilit√† del test).\n\nLa persona non ha l‚ÄôHIV:\n\nProbabilit√†: \\(P(\\neg HIV \\mid Test+) = 1 - P(HIV \\mid Test+) = 0.7156\\).\nProbabilit√† di un test positivo: \\(P(\\text{Test+} \\mid \\neg HIV) = 0.0072\\) (tasso di falsi positivi).\n\n\nUtilizziamo la formula della probabilit√† totale:\n\\[\n\\begin{aligned}\nP(\\text{Secondo Test+}) &= P(\\text{Test+} \\mid HIV) \\times P(HIV \\mid Test+) + \\\\\n&\\quad P(\\text{Test+} \\mid \\neg HIV) \\times P(\\neg HIV \\mid Test+).\n\\end{aligned}\n\\]\nSostituendo i valori:\n\\[\nP(\\text{Secondo Test+}) = (0.95 \\times 0.2844) + (0.0072 \\times 0.7156) \\approx 0.2753.\n\\]\nApplichiamo nuovamente il teorema di Bayes per calcolare la probabilit√† di avere l‚ÄôHIV dopo un secondo test positivo:\n\\[\nP(HIV \\mid \\text{Secondo Test+}) = \\frac{P(\\text{Secondo Test+} \\mid HIV) \\times P(HIV \\mid Test+)}{P(\\text{Secondo Test+})}.\n\\]\nSostituendo i valori:\n\\[\nP(HIV \\mid \\text{Secondo Test+}) = \\frac{0.95 \\times 0.2844}{0.2753} \\approx 0.981.\n\\]\nDopo un secondo test positivo, la probabilit√† di avere l‚ÄôHIV aumenta significativamente, passando dal 28.44% al 98.1%. Questo aumento drastico dimostra l‚Äôimportanza di:\n\nConsiderare il tasso di base (prevalenza) nella popolazione.\nAggiornare progressivamente le probabilit√† con nuove evidenze.\nInterpretare i risultati di test diagnostici multipli in modo bayesiano.\n\nL‚Äôanalisi evidenzia come l‚Äôaccumulo di evidenze attraverso test ripetuti, in linea con i principi del teorema di Bayes, possa portare a una stima molto pi√π accurata della probabilit√† di avere una condizione medica, riducendo significativamente l‚Äôincertezza iniziale.\n\n\nEsempio 30.5 Consideriamo ora un altro esempio relativo ai test medici e analizziamo i risultati del test antigenico rapido per il virus SARS-CoV-2 alla luce del teorema di Bayes. Questo test pu√≤ essere eseguito mediante tampone nasale, tampone naso-orofaringeo o campione di saliva. L‚ÄôIstituto Superiore di Sanit√†, nel documento pubblicato il 5 novembre 2020, sottolinea che, fino a quel momento, i dati disponibili sui vari test erano quelli forniti dai produttori: la sensibilit√† varia tra il 70% e l‚Äô86%, mentre la specificit√† si attesta tra il 95% e il 97%.\nPrendiamo un esempio specifico: nella settimana tra il 17 e il 23 marzo 2023, in Italia, il numero di individui positivi al virus √® stato stimato essere di 138.599 (fonte: Il Sole 24 Ore). Questo dato corrisponde a una prevalenza di circa lo 0,2% su una popolazione totale di circa 59 milioni di persone.\n\n prev = 138599 / 59000000\n prev\n#&gt; [1] 0.00235\n\nL‚Äôobiettivo √® determinare la probabilit√† di essere effettivamente affetti da Covid-19, dato un risultato positivo al test antigenico rapido, ossia \\(P(M^+ \\mid T^+)\\). Per raggiungere questo scopo, useremo la formula relativa al valore predittivo positivo del test.\n\n# Calcolo della sensibilit√† e specificit√† medie\nsens &lt;- (0.7 + 0.86) / 2  # sensibilit√†\nspec &lt;- (0.95 + 0.97) / 2 # specificit√†\n\n# Calcolo del valore predittivo positivo\nres_pos &lt;- positive_predictive_value_of_diagnostic_test(sens, spec, prev)\ncat(sprintf(\"P(M+ | T+) = %.3f\\n\", res_pos))\n#&gt; P(M+ | T+) = 0.044\n\nPertanto, se il risultato del tampone √® positivo, la probabilit√† di essere effettivamente affetti da Covid-19 √® solo del 4.4%.\nSe la prevalenza fosse 100 volte superiore (cio√®, pari al 23.5%), la probabilit√† di avere il Covid-19, dato un risultato positivo del tampone, aumenterebbe notevolmente e sarebbe pari a circa l‚Äô86%.\n\n# Calcolo della prevalenza aumentata di 100 volte\nprev &lt;- 138599 / 59000000 * 100\n\n# Calcolo del valore predittivo positivo\nres_pos &lt;- positive_predictive_value_of_diagnostic_test(sens, spec, prev)\ncat(sprintf(\"P(M+ | T+) = %.3f\\n\", res_pos))\n#&gt; P(M+ | T+) = 0.857\n\nSe il risultato del test fosse negativo, considerando la prevalenza stimata del Covid-19 nella settimana dal 17 al 23 marzo 2023, la probabilit√† di non essere infetto sarebbe del 99.9%.\n\n# Calcolo della sensibilit√†, specificit√† e prevalenza\nsens &lt;- (0.7 + 0.86) / 2  # sensibilit√†\nspec &lt;- (0.95 + 0.97) / 2  # specificit√†\nprev &lt;- 138599 / 59000000  # prevalenza\n\n# Calcolo del valore predittivo negativo\nres_neg &lt;- negative_predictive_value_of_diagnostic_test(sens, spec, prev)\ncat(sprintf(\"P(M- | T-) = %.3f\\n\", res_neg))\n#&gt; P(M- | T-) = 0.999\n\nTuttavia, un‚Äôesito del genere non dovrebbe sorprenderci, considerando che la prevalenza della malattia √® molto bassa; in altre parole, il risultato negativo conferma una situazione gi√† presunta prima di sottoporsi al test. Il vero ostacolo, specialmente nel caso di malattie rare come il Covid-19 in quel periodo specifico, non risiede tanto nell‚Äôasserire l‚Äôassenza della malattia quanto piuttosto nel confermarne la presenza.\n\n\nEsempio 30.6 Consideriamo le persone in attesa di un figlio. Il teorema di Bayes gioca un ruolo cruciale nell‚Äôinterpretazione dei test prenatali non invasivi (NIPT), un esame del sangue materno usato per rilevare anomalie cromosomiche fetali. Sebbene il NIPT sia spesso pubblicizzato con un‚Äôaccuratezza del 99%, la sua affidabilit√† varia significativamente a seconda della condizione testata e della popolazione esaminata.\nParametri chiave del NIPT:\n\nSensibilit√†:\n\nSindrome di Down: 99%\nSindrome di Edwards: 97%\nSindrome di Patau: 91%\n\nSpecificit√†: circa 99.9% per tutte le condizioni citate\nPrevalenza nelle nascite:\n\nSindrome di Down: 1 su 700 (0.14%)\nSindrome di Edwards: 1 su 5,000 (0.02%)\nSindrome di Patau: 1 su 10,000 (0.01%)\n\n\nNonostante l‚Äôalta sensibilit√† e specificit√†, il VPP pu√≤ essere sorprendentemente basso, soprattutto nella popolazione generale. Questo implica che molti risultati positivi potrebbero essere falsi positivi, in particolare per le condizioni pi√π rare.\nPer calcolare il VPP, utilizziamo il teorema di Bayes:\n\\[ VPP = \\frac{(\\text{Sensibilit√†} \\times \\text{Prevalenza})}{(\\text{Sensibilit√†} \\times \\text{Prevalenza}) + (1 - \\text{Specificit√†}) \\times (1 - \\text{Prevalenza})} \\]\nApplicando questa formula alla popolazione generale:\n\nSindrome di Down: \\[ VPP = \\frac{(0.99 \\times 0.0014)}{(0.99 \\times 0.0014) + (1 - 0.999) \\times (1 - 0.0014)} \\approx 58\\% \\]\nSindrome di Edwards: \\[ VPP = \\frac{(0.97 \\times 0.0002)}{(0.97 \\times 0.0002) + (1 - 0.999) \\times (1 - 0.0002)} \\approx 16.2\\% \\]\nSindrome di Patau: \\[ VPP = \\frac{(0.91 \\times 0.0001)}{(0.91 \\times 0.0001) + (1 - 0.999) \\times (1 - 0.0001)} \\approx 8.3\\% \\]\n\nQuesti calcoli rivelano VPP molto bassi, specialmente per condizioni molto rare come la sindrome di Patau. Anche in questo caso, dunque, il teorema di Bayes ci mostra che la probabilit√† che un risultato positivo sia effettivamente corretto dipende non solo dall‚Äôaccuratezza del test, ma anche dalla prevalenza della condizione nella popolazione testata. Per questo motivo, il NIPT risulta pi√π affidabile nelle categorie ad alto rischio.\nIn conclusione, mentre il NIPT √® uno strumento prezioso per lo screening prenatale, √® fondamentale interpretare i risultati con cautela, considerando il contesto specifico di ogni paziente e la prevalenza della condizione nella popolazione di riferimento.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_bayes_theorem.html#la-fallacia-del-procuratore",
    "href": "chapters/probability/07_bayes_theorem.html#la-fallacia-del-procuratore",
    "title": "30¬† Il teorema di Bayes",
    "section": "30.6 La Fallacia del Procuratore",
    "text": "30.6 La Fallacia del Procuratore\nIl teorema di Bayes non √® rilevante solo in ambito medico; √® altrettanto cruciale nel contesto legale, dove un errore logico noto come fallacia del procuratore pu√≤ avere conseguenze significative. Questa fallacia si verifica quando si confonde la probabilit√† di un risultato dato un evento con la probabilit√† dell‚Äôevento dato il risultato. In ambito giudiziario, ci√≤ accade spesso quando si scambia la probabilit√† di ottenere una corrispondenza del DNA se una persona √® innocente con la probabilit√† che una persona sia innocente dato che il test del DNA ha prodotto una corrispondenza.\n\nEsempio 30.7 Supponiamo che un test del DNA venga utilizzato per identificare un sospetto in una popolazione di 65 milioni di persone. Consideriamo i seguenti parametri:\n\nSensibilit√†: \\(P(T^+ \\mid C) = 99\\%\\), ovvero la probabilit√† che il test identifichi correttamente il colpevole.\nSpecificit√†: \\(P(T^- \\mid I) = 99.99997\\%\\), ovvero la probabilit√† che il test identifichi correttamente un innocente.\nPrevalenza: \\(P(C) = \\frac{1}{65.000.000}\\), ovvero la probabilit√† a priori che una persona qualsiasi sia il colpevole.\n\nUn campione di DNA √® stato trovato sulla scena del crimine e confrontato con quello di una persona nel database. Determiniamo la probabilit√† che questa persona sia effettivamente il colpevole, dato che il test √® positivo (\\(T^+\\)).\nPasso 1: Calcolo della Probabilit√† del Test Positivo \\(P(T^+)\\).\nLa probabilit√† di ottenere un test positivo (\\(T^+\\)) √® data dalla somma delle probabilit√† di un risultato positivo per un colpevole e per un innocente:\n\\[\nP(T^+) = P(T^+ \\mid C) \\cdot P(C) + P(T^+ \\mid I) \\cdot P(I),\n\\]\ndove \\(P(I) = 1 - P(C)\\) √® la probabilit√† che una persona sia innocente e \\(P(T^+ \\mid I) = 1 - \\text{Specificit√†}\\).\nSostituiamo i valori noti:\n\\[\nP(T^+) = 0.99 \\cdot \\frac{1}{65.000.000} + (1 - 0.9999997) \\cdot \\frac{64.999.999}{65.000.000}.\n\\]\nEseguiamo i calcoli:\n\\[\nP(T^+) \\approx 0.99 \\cdot 1.5385 \\times 10^{-8} + 0.0000003 \\cdot 0.9999999,\n\\]\n\\[\nP(T^+) \\approx 1.5231 \\times 10^{-8} + 2.9999997 \\times 10^{-7},\n\\]\n\\[\nP(T^+) \\approx 3.1523 \\times 10^{-7}.\n\\]\nPasso 2: Probabilit√† Condizionale che il Sospetto sia Colpevole Dato un Test Positivo.\nUtilizzando il teorema di Bayes, la probabilit√† a posteriori che il sospetto sia colpevole, dato un test positivo, √®:\n\\[\nP(C \\mid T^+) = \\frac{P(T^+ \\mid C) \\cdot P(C)}{P(T^+)}.\n\\]\nSostituiamo i valori calcolati:\n\\[\nP(C \\mid T^+) = \\frac{0.99 \\cdot \\frac{1}{65.000.000}}{3.1523 \\times 10^{-7}},\n\\]\n\\[\nP(C \\mid T^+) = \\frac{0.99 \\cdot 1.5385 \\times 10^{-8}}{3.1523 \\times 10^{-7}},\n\\]\n\\[\nP(C \\mid T^+) \\approx 0.0483.\n\\]\nLa probabilit√† che il sospetto sia effettivamente il colpevole, dato che il test del DNA √® positivo, √® quindi circa 4.83%, nonostante la specificit√† estremamente elevata del test.\nQuesto risultato dimostra quanto sia importante considerare la bassa prevalenza del colpevole nella popolazione. Affermare, ad esempio, che ‚Äúc‚Äô√® solo una probabilit√† su 3 milioni che il sospetto sia innocente‚Äù confonde la specificit√† del test (\\(P(T^- \\mid I)\\)) con la probabilit√† condizionale di colpevolezza (\\(P(C \\mid T^+)\\)).\nIn realt√†, la probabilit√† che il sospetto sia colpevole dato un test positivo √® molto pi√π bassa, a causa della prevalenza estremamente ridotta. Questo errore logico pu√≤ portare a gravi ingiustizie, poich√© non si considera che i falsi positivi diventano statisticamente pi√π rilevanti quando il numero di innocenti testati √® molto alto.\nPer chiarire, confondere \\(P(T^+ \\mid I)\\) con \\(P(I \\mid T^+)\\) √® analogo a confondere ‚ÄúQuanto √® probabile che il DNA di una persona corrisponda al campione, se √® innocente?‚Äù con ‚ÄúQuanto √® probabile che una persona sia innocente, dato che il suo DNA corrisponde al campione?‚Äù.\nIn conclusione, la fallacia del procuratore mette in evidenza l‚Äôimportanza di interpretare correttamente i risultati dei test probabilistici in contesti legali. L‚Äôuso del teorema di Bayes √® essenziale per evitare errori logici e per garantire che le decisioni siano basate su una comprensione accurata delle probabilit√† condizionali.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_bayes_theorem.html#probabilit√†-inversa",
    "href": "chapters/probability/07_bayes_theorem.html#probabilit√†-inversa",
    "title": "30¬† Il teorema di Bayes",
    "section": "30.7 Probabilit√† Inversa",
    "text": "30.7 Probabilit√† Inversa\nGli esempi precedenti evidenziano la differenza tra due domande fondamentali. La prima √®: ‚ÄúQual √® la probabilit√† di osservare un determinato risultato, supponendo che una certa ipotesi sia vera?‚Äù La seconda, invece, √®: ‚ÄúQual √® la probabilit√† che un‚Äôipotesi sia vera, dato il risultato osservato?‚Äù\nUn esempio che risponde alla prima domanda potrebbe essere questo: supponiamo che la probabilit√† di ottenere testa nel lancio di una moneta sia 0.5 (ipotesi). Qual √® la probabilit√† di ottenere 0 teste in cinque lanci?\nPer la seconda domanda, un esempio potrebbe essere: supponiamo di aver ottenuto 0 teste in 5 lanci di una moneta (evidenza). Qual √® la probabilit√† che la moneta sia effettivamente bilanciata, alla luce di questa osservazione?\nPer molto tempo, lo studio della probabilit√† si √® concentrato principalmente sulla prima domanda. Tuttavia, nel XVIII secolo, il reverendo Thomas Bayes inizi√≤ a riflettere sulla seconda domanda, dando origine a quello che oggi chiamiamo probabilit√† inversa.\nQuesto approccio ha generato numerose controversie nella storia della statistica, in gran parte perch√© influenza molti ambiti. Ad esempio, possiamo chiederci: quanto √® probabile che un‚Äôipotesi scientifica sia vera, dato il risultato di un esperimento? Per stimare questa probabilit√† ‚Äî un compito che molti scienziati ritengono essenziale per la statistica moderna ‚Äî √® necessario fare uso del teorema di Bayes e delle probabilit√† a priori.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_bayes_theorem.html#riflessioni-conclusive",
    "href": "chapters/probability/07_bayes_theorem.html#riflessioni-conclusive",
    "title": "30¬† Il teorema di Bayes",
    "section": "30.8 Riflessioni Conclusive",
    "text": "30.8 Riflessioni Conclusive\nIn questo capitolo abbiamo esplorato vari esempi, principalmente nel campo medico e forense, per illustrare come il teorema di Bayes permetta di combinare le informazioni derivate dalle osservazioni con le conoscenze precedenti (priori), aggiornando cos√¨ il nostro grado di convinzione rispetto a un‚Äôipotesi. Il teorema di Bayes fornisce un meccanismo razionale, noto come ‚Äúaggiornamento bayesiano‚Äù, che ci consente di ricalibrare le nostre convinzioni iniziali alla luce di nuove evidenze.\nUna lezione fondamentale che il teorema di Bayes ci insegna, sia nella ricerca scientifica che nella vita quotidiana, √® che spesso non ci interessa tanto conoscere la probabilit√† che qualcosa accada assumendo vera un‚Äôipotesi, quanto piuttosto la probabilit√† che un‚Äôipotesi sia vera, dato che abbiamo osservato una certa evidenza. In altre parole, la forza del teorema di Bayes sta nella sua capacit√† di affrontare direttamente il problema inverso, cio√® come dedurre la verit√† di un‚Äôipotesi a partire dalle osservazioni.\nIl framework bayesiano per l‚Äôinferenza probabilistica offre un approccio generale per comprendere come i problemi di induzione possano essere risolti in linea di principio e, forse, anche come possano essere affrontati dalla mente umana.\nIn questo capitolo ci siamo concentrati sull‚Äôapplicazione del teorema di Bayes utilizzando probabilit√† puntuali. Tuttavia, il teorema esprime pienamente il suo potenziale quando sia l‚Äôevidenza che i gradi di certezza a priori delle ipotesi sono rappresentati attraverso distribuzioni di probabilit√† continue. Questo sar√† l‚Äôargomento centrale nella prossima sezione della dispensa, dove approfondiremo il flusso di lavoro bayesiano e l‚Äôuso di distribuzioni continue nell‚Äôaggiornamento bayesiano.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_bayes_theorem.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/07_bayes_theorem.html#informazioni-sullambiente-di-sviluppo",
    "title": "30¬† Il teorema di Bayes",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: US/Pacific\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] ggokabeito_0.1.0 see_0.9.0        gridExtra_2.3    patchwork_1.3.0 \n#&gt;  [5] bayesplot_1.11.1 psych_2.4.12     scales_1.3.0     markdown_1.13   \n#&gt;  [9] knitr_1.49       lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1   \n#&gt; [13] dplyr_1.1.4      purrr_1.0.2      readr_2.1.5      tidyr_1.3.1     \n#&gt; [17] tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3       \n#&gt; [21] here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] utf8_1.2.4        generics_0.1.3    stringi_1.8.4     lattice_0.22-6   \n#&gt;  [5] hms_1.1.3         digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1   \n#&gt;  [9] grid_4.4.2        timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4  \n#&gt; [13] jsonlite_1.8.9    mnormt_2.1.1      cli_3.6.3         rlang_1.1.4      \n#&gt; [17] munsell_0.5.1     withr_3.0.2       yaml_2.3.10       tools_4.4.2      \n#&gt; [21] parallel_4.4.2    tzdb_0.4.0        colorspace_2.1-1  pacman_0.5.1     \n#&gt; [25] vctrs_0.6.5       R6_2.5.1          lifecycle_1.0.4   htmlwidgets_1.6.4\n#&gt; [29] pkgconfig_2.0.3   pillar_1.10.1     gtable_0.3.6      glue_1.8.0       \n#&gt; [33] xfun_0.50         tidyselect_1.2.1  farver_2.1.2      htmltools_0.5.8.1\n#&gt; [37] nlme_3.1-166      rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_bayes_theorem.html#bibliografia",
    "href": "chapters/probability/07_bayes_theorem.html#bibliografia",
    "title": "30¬† Il teorema di Bayes",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nChivers, T. (2024). Everything is Predictable: How Bayesian Statistics Explain Our World. Simon; Schuster.\n\n\nGriffiths, T. L., Chater, N., & Tenenbaum, J. B. (2024). Bayesian models of cognition: reverse engineering the mind. MIT Press.\n\n\nPetersen, I. T. (2024). Principles of psychological assessment: With applied examples in R. CRC Press.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html",
    "href": "chapters/probability/08_sampling_distr.html",
    "title": "31¬† Stime, stimatori e parametri",
    "section": "",
    "text": "31.1 Introduzione\nIn questo capitolo, approfondiremo il concetto di distribuzione campionaria che costituisce uno dei pilastri dell‚Äôinferenza statistica frequentista. La distribuzione campionaria ci permette di comprendere come le stime dei parametri della popolazione, come la media o la varianza, cambiano da campione a campione. In particolare, la distribuzione campionaria ci consente di stabilire delle propriet√† probabilistiche delle stime campionarie, come ad esempio la loro media e la loro varianza. Queste propriet√† verranno utilizzate per costruire gli strumenti fondamentali dell‚Äôinferenza frequentista: gli intervalli di fiducia e i test di ipotesi.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#popolazione-e-campioni",
    "href": "chapters/probability/08_sampling_distr.html#popolazione-e-campioni",
    "title": "31¬† Stime, stimatori e parametri",
    "section": "31.2 Popolazione e campioni",
    "text": "31.2 Popolazione e campioni\nNell‚Äôanalisi dei dati, l‚Äôobiettivo spesso √® comprendere una quantit√† specifica a livello di popolazione, ma in genere abbiamo accesso solo a un campione di osservazioni. La quantit√† sconosciuta che vogliamo determinare viene chiamata parametro. Quando usiamo i dati del campione per calcolare una misura di questo parametro, la misura ottenuta √® chiamata stima, e la formula che utilizziamo per ottenerla √® conosciuta come stimatore. In termini formali, uno stimatore √® una funzione dei dati osservati, utilizzata per fornire un‚Äôapprossimazione del parametro di interesse.\nIn pratica, quando analizziamo un campione di dati, il nostro obiettivo √® inferire determinate propriet√† della popolazione intera dalla quale il campione √® stato tratto. Il parametro √® l‚Äôindicatore numerico di queste propriet√†, ma poich√© spesso non possiamo calcolarlo direttamente sulla popolazione, ricorriamo alle osservazioni del campione per stimarlo. La stima, quindi, rappresenta il valore approssimato del parametro ottenuto dal campione, mentre lo stimatore √® la regola o la formula matematica che usiamo per arrivare a questa approssimazione.\n√à importante riconoscere che le stime non corrispondono mai esattamente ai parametri che vogliamo comprendere. In altre parole, le stime sono solo approssimazioni del parametro a causa della natura aleatoria del campionamento.\n\n31.2.1 La relazione tra stime e parametri\nIn questo capitolo, ci concentreremo sulla relazione tra le stime ottenute dai campioni e i parametri della popolazione, esplorando in particolare la connessione tra la media di un campione e la media della popolazione, denotata con \\(\\mu\\). Il nostro obiettivo √® capire e caratterizzare l‚Äôincertezza che deriva dalla natura aleatoria delle stime, e per farlo, adotteremo l‚Äôapproccio frequentista, facendo uso dello strumento statistico chiamato distribuzione campionaria.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#la-distribuzione-campionaria",
    "href": "chapters/probability/08_sampling_distr.html#la-distribuzione-campionaria",
    "title": "31¬† Stime, stimatori e parametri",
    "section": "31.3 La Distribuzione Campionaria",
    "text": "31.3 La Distribuzione Campionaria\nPer illustrare il concetto di distribuzione campionaria, possiamo iniziare considerando un caso semplice e specifico: una popolazione finita di dimensioni ridotte. Sebbene stiamo esaminando un caso particolare, √® fondamentale notare che le propriet√† e i principi che analizzeremo in questo contesto sono perfettamente applicabili a popolazioni di qualsiasi dimensione.\nLa distribuzione campionaria ci d√† una visione della variazione che potremmo aspettarci nelle stime derivate da diversi campioni estratti dalla stessa popolazione. Ogni volta che preleviamo un campione, otteniamo una stima diversa per il parametro di interesse (come la media). La distribuzione campionaria ci mostra come queste stime sono distribuite e ci aiuta a comprendere quanto siano affidabili.\nIn termini pratici, se vogliamo calcolare la media della popolazione, non possiamo farlo direttamente (a meno di non avere accesso all‚Äôintera popolazione). Invece, possiamo estrarre un campione casuale e calcolare la media del campione come stima di \\(\\mu\\). Tuttavia, un altro campione fornir√† una stima leggermente diversa. La distribuzione campionaria ci aiuta a capire quanto queste stime varino da campione a campione e ci fornisce un quadro completo dell‚Äôincertezza legata al processo di stima.\nNella simulazione seguente, ipotizziamo la seguente popolazione:\n\nx &lt;- c(2, 4.5, 5, 5.5)\nx\n#&gt; [1] 2.0 4.5 5.0 5.5\n\nL‚Äôistogramma seguente descrive la distribuzione della popolazione.\n\nggplot(data.frame(x = x), aes(x)) +\n  geom_histogram(\n    bins = 5,\n    aes(y = after_stat(density))\n  )\n\n\n\n\n\n\n\n\nStampiamo gli intervalli utilizzati per l‚Äôistogramma.\n\n# Calcolo degli intervalli e delle frequenze per l'istogramma\nhist_data &lt;- hist(x, breaks = 5, plot = FALSE)\n\n# Stampa degli intervalli e delle frequenze relative\ncat(\"Intervalli utilizzati per l'istogramma:\", hist_data$breaks, \"\\n\")\n#&gt; Intervalli utilizzati per l'istogramma: 2 2.5 3 3.5 4 4.5 5 5.5\ncat(\"Frequenze relative utilizzate per l'istogramma:\", hist_data$density, \"\\n\")\n#&gt; Frequenze relative utilizzate per l'istogramma: 0.5 0 0 0 0.5 0.5 0.5\n\n\n# Calcolo delle frequenze assolute\nhist_data_abs &lt;- hist(x, breaks = 5, plot = FALSE)\n\n# Stampa delle frequenze assolute\ncat(\"Frequenze assolute utilizzate per l'istogramma:\", hist_data_abs$counts, \"\\n\")\n#&gt; Frequenze assolute utilizzate per l'istogramma: 1 0 0 0 1 1 1\n\nCalcoliamo la media e la varianza della popolazione. Media:\n\nmean_x &lt;- mean(x) # Media della popolazione\nmean_x\n#&gt; [1] 4.25\n\nVarianza:\n\nvar_x &lt;- var(x) * ((length(x) - 1) / length(x)) # Varianza popolazione\nvar_x\n#&gt; [1] 1.81\n\nConsideriamo tutti i possibili campioni di dimensione \\(n = 2\\) che possono essere estratti dalla popolazione rappresentata dal vettore x. Per generare questi campioni, utilizziamo la funzione expand.grid in R, che consente di creare tutte le combinazioni possibili di valori, includendo le ripetizioni.\nIl risultato sar√† un data frame con 16 righe e 2 colonne, dove ogni riga rappresenta una coppia possibile di valori estratti dal vettore x. Questo risultato √® in linea con il principio del calcolo combinatorio: quando selezioniamo \\(n\\) elementi da un insieme di \\(k\\) elementi e permettiamo ripetizioni, il numero totale di combinazioni √® dato da \\(k^n\\). Nel nostro caso, con \\(k = 4\\) e \\(n = 2\\), otteniamo:\n\\[\n4^2 = 16 \\text{ combinazioni}.\n\\]\nUtilizzando expand.grid, possiamo verificare questo risultato in R:\n\n# Generazione delle combinazioni con ripetizione\nsamples &lt;- expand.grid(x, x)\n\n# Visualizzazione del risultato\nprint(samples)\n#&gt;    Var1 Var2\n#&gt; 1   2.0  2.0\n#&gt; 2   4.5  2.0\n#&gt; 3   5.0  2.0\n#&gt; 4   5.5  2.0\n#&gt; 5   2.0  4.5\n#&gt; 6   4.5  4.5\n#&gt; 7   5.0  4.5\n#&gt; 8   5.5  4.5\n#&gt; 9   2.0  5.0\n#&gt; 10  4.5  5.0\n#&gt; 11  5.0  5.0\n#&gt; 12  5.5  5.0\n#&gt; 13  2.0  5.5\n#&gt; 14  4.5  5.5\n#&gt; 15  5.0  5.5\n#&gt; 16  5.5  5.5\n\nIl data frame risultante mostrer√† tutte le possibili coppie \\((x_1, x_2)\\), dove \\(x_1\\) e \\(x_2\\) possono essere scelti indipendentemente dalla popolazione \\(x = \\{2, 4.5, 5, 5.5\\}\\).\nPer calcolare la media di ogni campione di ampiezza \\(n = 2\\), possiamo utilizzare la funzione rowMeans, che calcola la media per ogni riga di una matrice. In questo modo, otteniamo un vettore contenente la media di ciascuna coppia di valori. Questo insieme di valori costituisce la distribuzione campionaria delle medie dei campioni di ampiezza \\(n = 2\\) che possono essere estratti dalla popolazione x.\n\n# Calcolare la media di ciascun campione\nsample_means &lt;- rowMeans(samples)\nprint(sample_means)\n#&gt;  [1] 2.00 3.25 3.50 3.75 3.25 4.50 4.75 5.00 3.50 4.75 5.00 5.25 3.75 5.00\n#&gt; [15] 5.25 5.50\n\nUna rappresentazione grafica della distribuzione campionaria delle medie dei campioni di ampiezza \\(n = 2\\) che possono essere estratti dalla popolazione x √® fornita qui sotto.\n\n# Istogramma delle medie campionarie\nggplot(data.frame(sample_means), aes(x = sample_means)) +\n  geom_histogram(\n    bins = 5,\n    aes(y = after_stat(density))\n)\n\n\n\n\n\n\n\n\nMostriamo qui nuovamente la lista di tutti i possibili campioni di ampiezza 2 insieme alla media di ciascun campione.\n\n# Creare un data frame con i campioni e le loro medie\ndf &lt;- data.frame(\n  Samples = apply(samples, 1, paste, collapse = \", \"),\n  x_bar = rowMeans(samples)\n)\nprint(df)\n#&gt;     Samples x_bar\n#&gt; 1      2, 2  2.00\n#&gt; 2    4.5, 2  3.25\n#&gt; 3      5, 2  3.50\n#&gt; 4    5.5, 2  3.75\n#&gt; 5    2, 4.5  3.25\n#&gt; 6  4.5, 4.5  4.50\n#&gt; 7    5, 4.5  4.75\n#&gt; 8  5.5, 4.5  5.00\n#&gt; 9      2, 5  3.50\n#&gt; 10   4.5, 5  4.75\n#&gt; 11     5, 5  5.00\n#&gt; 12   5.5, 5  5.25\n#&gt; 13   2, 5.5  3.75\n#&gt; 14 4.5, 5.5  5.00\n#&gt; 15   5, 5.5  5.25\n#&gt; 16 5.5, 5.5  5.50\n\nProcediamo ora al calcolo della media della distribuzione campionaria delle medie di campioni di ampiezza \\(n = 2\\) che possono essere estratti dalla popolazione x.\n\n# Calcolare la media delle medie campionarie\nmean(sample_means)\n#&gt; [1] 4.25\n\nSi noti che questo valore coincide con la media della popolazione. In generale, infatti, possiamo dire quanto segue.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#valore-atteso-della-media-campionaria",
    "href": "chapters/probability/08_sampling_distr.html#valore-atteso-della-media-campionaria",
    "title": "31¬† Stime, stimatori e parametri",
    "section": "31.4 Valore Atteso della Media Campionaria",
    "text": "31.4 Valore Atteso della Media Campionaria\nIl valore atteso della media campionaria √® una propriet√† fondamentale in statistica. Supponiamo che \\(X_1, X_2, \\ldots, X_n\\) siano variabili aleatorie indipendenti e identicamente distribuite (iid), con valore atteso \\(\\mu\\) e varianza \\(\\sigma^2\\). La media campionaria √® definita come:\n\\[\n\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i.\n\\]\nVogliamo dimostrare che il valore atteso della media campionaria \\(\\mathbb{E}(\\bar{X})\\) coincide con il valore atteso delle singole variabili, cio√® \\(\\mu\\).\n\n\n31.4.1 Dimostrazione\nApplichiamo le propriet√† della speranza matematica per calcolare \\(\\mathbb{E}(\\bar{X})\\):\n\\[\n\\begin{align*}\n\\mathbb{E}(\\bar{X}) & = \\mathbb{E}\\left(\\frac{1}{n} \\sum_{i=1}^n X_i\\right) & \\text{(definizione di media campionaria)} \\\\\n& = \\frac{1}{n} \\mathbb{E}\\left(\\sum_{i=1}^n X_i\\right) & \\text{(linearit√† della speranza)} \\\\\n& = \\frac{1}{n} \\sum_{i=1}^n \\mathbb{E}(X_i) & \\text{(speranza della somma)} \\\\\n& = \\frac{1}{n} \\sum_{i=1}^n \\mu & \\text{(tutte le $X_i$ hanno valore atteso $\\mu$)} \\\\\n& = \\frac{1}{n} \\cdot n \\cdot \\mu & \\text{(semplificazione della somma)} \\\\\n& = \\mu.\n\\end{align*}\n\\]\n\n\n\n31.4.2 Interpretazione\nAbbiamo dimostrato che il valore atteso della media campionaria √® uguale al valore atteso delle singole variabili. In termini pratici, ci√≤ implica che la media campionaria √® un stimatore non distorto del valore atteso della popolazione: anche se la media campionaria pu√≤ variare a seconda del campione, in media si avvicina sempre al valore atteso della popolazione, \\(\\mu\\).\nQuesta propriet√† √® una delle basi della statistica inferenziale. La media campionaria √® uno degli stimatori pi√π utilizzati in pratica proprio perch√©, oltre a essere non distorta, presenta altre propriet√† utili, come l‚Äôefficienza (soprattutto per \\(n\\) grande).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#varianza-della-media-campionaria",
    "href": "chapters/probability/08_sampling_distr.html#varianza-della-media-campionaria",
    "title": "31¬† Stime, stimatori e parametri",
    "section": "31.5 Varianza della media campionaria",
    "text": "31.5 Varianza della media campionaria\nDato che le variabili \\(X_1, X_2, \\ldots, X_n\\) sono indipendenti ed identicamente distribuite (iid) con valore atteso \\(\\mu\\) e varianza \\(\\sigma^2\\), possiamo calcolare la varianza della media campionaria \\(\\bar{X}\\) come segue:\n\\[\n\\begin{align*}\n\\text{Var}(\\bar{X}) & = \\text{Var}\\left(\\frac{1}{n} \\sum_{i=1}^n X_i\\right) \\\\\n& = \\frac{1}{n^2} \\text{Var}\\left(\\sum_{i=1}^n X_i\\right) \\\\\n& = \\frac{1}{n^2} \\sum_{i=1}^n \\text{Var}(X_i) \\quad \\text{(dato che le $X_i$ sono indipendenti, i termini incrociati si annullano)} \\\\\n& = \\frac{1}{n^2} \\sum_{i=1}^n \\sigma^2 \\\\\n& = \\frac{1}{n^2} \\cdot n \\cdot \\sigma^2 \\\\\n& = \\frac{\\sigma^2}{n}\n\\end{align*}\n\\]\nQuindi, la varianza della media campionaria di \\(n\\) variabili iid √® uguale alla varianza di ciascuna variabile singola divisa per \\(n\\), che in questo caso √® \\(\\sigma^2/n\\).\nQuesto risultato riflette un‚Äôimportante propriet√† statistica:\n\nall‚Äôaumentare di \\(n\\), la varianza della media campionaria diminuisce, rendendo la media campionaria una stima pi√π precisa del valore atteso \\(\\mu\\). La riduzione della varianza √® proporzionale a \\(1/n\\), quindi raddoppiare il campione riduce la varianza della media campionaria di un fattore 2.\n\nIn conclusione, la formula \\(\\text{Var}(\\bar{X}) = \\frac{\\sigma^2}{n}\\) mostra che la precisione della media campionaria aumenta con la dimensione del campione, poich√© la varianza diminuisce. Questo principio √® alla base dell‚Äôimportanza di campioni pi√π grandi nella stima statistica.\n\n31.5.1 Applicazione\nAnalizziamo l‚Äôesempio in dettaglio per comprendere meglio i concetti relativi alle medie campionarie e al loro rapporto con la popolazione.\n\n\n31.5.1.1 Varianza delle Medie Campionarie\nLa varianza delle medie campionarie, calcolata empiricamente, pu√≤ essere ottenuta direttamente dai dati:\n\nvar(x) * ((length(x) - 1) / length(x)) / 2\n#&gt; [1] 0.906\n\nQuesto calcolo riflette la formula per la varianza della media campionaria, dove il fattore (((x) - 1) / (x)) corregge per il fatto che stiamo lavorando con una popolazione finita. In alternativa, possiamo calcolare lo stesso valore prendendo la varianza delle medie di tutti i campioni (16 in questo caso):\n\nvar(sample_means) * ((length(sample_means) - 1) / length(sample_means))\n#&gt; [1] 0.906\n\nEntrambi i calcoli forniscono risultati coerenti con la teoria, dimostrando che la varianza delle medie campionarie √® inferiore a quella della popolazione.\n\n\n\n31.5.1.2 Analisi di un Campione Specifico\nPrendiamo ora un campione particolare dalla popolazione:\n\nobserved_sample &lt;- c(5, 5.5)\nprint(observed_sample)\n#&gt; [1] 5.0 5.5\n\n\nMedia del Campione\nLa media del campione viene calcolata come segue:\n\n\nsample_mean &lt;- mean(observed_sample)\nprint(sample_mean)\n#&gt; [1] 5.25\n\nLa media campionaria (\\(\\bar{x} = 5.25\\)) √® diversa dalla media della popolazione (\\(\\mu = 4.25\\)), come √® atteso per un singolo campione.\n\nDeviazione Standard del Campione\nLa deviazione standard del campione √® calcolata utilizzando la formula corretta per la varianza campionaria:\n\n\nsample_sd &lt;- sqrt(var(observed_sample) / 2)\nprint(sample_sd)\n#&gt; [1] 0.25\n\nAnche la deviazione standard del campione √® diversa dalla deviazione standard della popolazione:\n\nsqrt(var(x) * (length(x) - 1) / length(x))\n#&gt; [1] 1.35\n\nQuesto risultato riflette il fatto che un singolo campione non riproduce perfettamente le propriet√† della popolazione, ma le medie campionarie aggregate tendono a rifletterle meglio.\n\n\n\n\n31.5.2 Risultati Centrali\nDall‚Äôanalisi delle medie campionarie emergono due risultati fondamentali:\n\nMedia delle Medie Campionarie e Media della Popolazione\nLa media della distribuzione delle medie campionarie coincide con la media della popolazione:\n\\[\n\\mathbb{E}(\\bar{X}_n) = \\mu.\n\\]\nVarianza delle Medie Campionarie\nLa varianza delle medie campionarie √® inferiore alla varianza della popolazione ed √® pari a:\n\\[\n\\mathbb{V}(\\bar{X}_n) = \\frac{\\sigma^2}{n}.\n\\]\n\nQuesti risultati dimostrano empiricamente come le medie campionarie rappresentino una stima non distorta della media della popolazione e diventino pi√π precise all‚Äôaumentare della dimensione del campione \\(n\\).\n\n\n\n31.5.3 Forma della Distribuzione delle Medie Campionarie\nIl comportamento della distribuzione delle medie campionarie dipende dalla distribuzione della popolazione:\n\nDistribuzione Normale: Se la popolazione segue una distribuzione normale, le medie campionarie seguiranno anch‚Äôesse una distribuzione normale, indipendentemente dalla dimensione del campione.\nDistribuzione Non Normale: Se la popolazione non segue una distribuzione normale, il Teorema del Limite Centrale garantisce che, per dimensioni del campione sufficientemente grandi, la distribuzione delle medie campionarie tender√† a una distribuzione normale.\n\n\nIn conclusione, l‚Äôanalisi delle medie campionarie ci fornisce una comprensione fondamentale dei principi statistici alla base dell‚Äôinferenza. La convergenza delle medie campionarie alla media della popolazione e la riduzione della loro varianza con l‚Äôaumentare di \\(n\\) sono concetti chiave che supportano molte tecniche di stima e test statistici. Inoltre, il ruolo del Teorema del Limite Centrale evidenzia la robustezza di questi principi, indipendentemente dalla forma della distribuzione di partenza.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#errore-standard-e-rappresentazione-dellincertezza-inferenziale",
    "href": "chapters/probability/08_sampling_distr.html#errore-standard-e-rappresentazione-dellincertezza-inferenziale",
    "title": "31¬† Stime, stimatori e parametri",
    "section": "31.6 Errore standard e rappresentazione dell‚Äôincertezza inferenziale",
    "text": "31.6 Errore standard e rappresentazione dell‚Äôincertezza inferenziale\nNella statistica inferenziale, l‚Äôerrore standard √® una misura frequentemente utilizzata per rappresentare l‚Äôincertezza legata a un parametro stimato, conosciuta anche come incertezza inferenziale. L‚Äôerrore standard quantifica quanto possa variare la stima di una statistica da un campione all‚Äôaltro; un errore standard minore indica una stima pi√π precisa, mentre uno maggiore implica maggiore incertezza. Spesso, le rappresentazioni grafiche includono gli errori standard nella forma di ‚Äúmedia pi√π o meno uno (o due) errori standard.‚Äù Questa espressione fornisce una gamma di valori entro cui √® plausibile che ricada il valore vero del parametro della popolazione.\nL‚Äôuso dell‚Äôerrore standard nei grafici non √® soltanto una convenzione; esso √® uno strumento per quantificare e visualizzare l‚Äôincertezza inferenziale. Contribuisce alla comprensione dell‚Äôaffidabilit√† delle stime ottenute dai dati campionari, permettendo di valutare quanto le stime possano variare se si prendesse un altro campione dalla stessa popolazione. Tuttavia, √® importante notare che questo utilizzo dell‚Äôerrore standard pu√≤ essere problematico (Ward & Mann, 2022).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#legge-dei-grandi-numeri",
    "href": "chapters/probability/08_sampling_distr.html#legge-dei-grandi-numeri",
    "title": "31¬† Stime, stimatori e parametri",
    "section": "31.7 Legge dei Grandi Numeri",
    "text": "31.7 Legge dei Grandi Numeri\nLa Legge dei Grandi Numeri (LLN) √® un principio fondamentale della teoria delle probabilit√† che stabilisce come, incrementando il numero \\(n\\) di osservazioni, la media campionaria \\(\\bar{X}_n\\) tenda asintoticamente alla media teorica \\(\\mu\\). La LLN si articola in due varianti: la versione ‚Äúforte‚Äù e quella ‚Äúdebole‚Äù, le quali differiscono per il tipo di convergenza verso la media attesa.\n\n31.7.1 Versione Forte della Legge dei Grandi Numeri (SLLN)\nLa SLLN afferma che la media campionaria $ {X}_n $ converge quasi certamente alla media teorica \\(\\mu\\), ovvero la convergenza avviene con probabilit√† 1. Questo implica che, per quasi ogni possibile sequenza di eventi nell‚Äôinsieme campionario \\(S\\), \\(\\bar{X}_n(s)\\) tende a \\(\\mu\\), ad eccezione di un insieme di eventi \\(B_0\\) la cui probabilit√† √® zero. In termini tecnici, si dice che \\(\\bar{X}_n\\) converge a \\(\\mu\\) ‚Äúquasi certamente‚Äù.\n\n\n31.7.2 Versione Debole della Legge dei Grandi Numeri (WLLN)\nLa WLLN afferma che, per ogni \\(\\epsilon &gt; 0\\), la probabilit√† che la media campionaria \\(\\bar{X}_n\\) si discosti da \\(\\mu\\) di una quantit√† maggiore di \\(\\epsilon\\) tende a zero all‚Äôaumentare di \\(n\\). Questo fenomeno √® definito come convergenza in probabilit√† verso la media teorica \\(\\mu\\).\n\n\n31.7.3 Implicazioni e Applicazioni\nLa Legge dei Grandi Numeri riveste un ruolo cruciale nel campo delle simulazioni, della statistica e, pi√π in generale, nelle discipline scientifiche. La generazione di dati attraverso numerose repliche indipendenti di un esperimento, sia in ambito simulativo che empirico, implica l‚Äôutilizzo della media campionaria come stima affidabile della media teorica della variabile di interesse. In pratica, la LLN fornisce una base teorica per l‚Äôaffidabilit√† delle stime medie ottenute da grandi campioni di dati, sottolineando come, a fronte di un numero elevato di osservazioni, le fluttuazioni casuali tendano ad annullarsi, convergendo verso un valore stabile e prevedibile.\n\nEsempio 31.1 Siano \\(X_1, X_2, \\ldots\\) variabili aleatorie indipendenti e identicamente distribuite secondo una distribuzione di Bernoulli con parametro \\(1/2\\). Interpretando gli \\(X_j\\) come indicatori di ‚ÄúTesta‚Äù in una sequenza di lanci di una moneta equa, \\(\\bar{X}_n\\) rappresenta la proporzione di ‚ÄúTesta‚Äù dopo \\(n\\) lanci. La Legge Forte dei Grandi Numeri (SLLN) afferma che, con probabilit√† 1, la sequenza di variabili aleatorie \\(\\bar{X}_1, \\bar{X}_2, \\bar{X}_3, \\ldots\\) converger√† a \\(1/2\\) quando si cristallizza in una sequenza di numeri reali. Matematicamente parlando, esistono scenari improbabili come una sequenza infinita di ‚ÄúTesta‚Äù (HHHHHH‚Ä¶) o sequenze irregolari come HHTHHTHHTHHT‚Ä¶, ma queste hanno una probabilit√† collettiva di zero di verificarsi. La Legge Debole dei Grandi Numeri (WLLN) stabilisce che, per ogni \\(\\epsilon &gt; 0\\), la probabilit√† che \\(\\bar{X}_n\\) sia distante pi√π di \\(\\epsilon\\) da \\(1/2\\) pu√≤ essere resa arbitrariamente piccola aumentando \\(n\\).\nCome illustrazione, abbiamo simulato sei sequenze di lanci di una moneta equa e, per ciascuna sequenza, abbiamo calcolato \\(\\bar{X}_n\\) in funzione di \\(n\\). Ovviamente, nella realt√† non possiamo effettuare un numero infinito di lanci, quindi ci siamo fermati dopo 300 lanci. Il grafico seguente mostra \\(\\bar{X}_n\\) in funzione di $ n $ per ciascuna delle sei sequenze. All‚Äôinizio, notiamo una certa variazione nella proporzione cumulativa di ‚ÄúTesta‚Äù. Tuttavia, con l‚Äôaumentare del numero di lanci, la varianza $ ({X}_n) $ diminuisce progressivamente e \\(\\bar{X}_n\\) tende a \\(1/2\\).\n\n# Numero di sequenze\nnum_sequences &lt;- 6\n# Numero di lanci\nnum_tosses &lt;- 300\n\n# Creare un data frame per contenere i risultati\nresults &lt;- data.frame(Toss = numeric(), Proportion = numeric(), Sequence = character())\n\n# Loop attraverso ciascuna sequenza\nfor (i in 1:num_sequences) {\n  # Generare una sequenza di lanci di moneta equa (Testa=1, Croce=0)\n  coin_tosses &lt;- sample(c(0, 1), num_tosses, replace = TRUE)\n  \n  # Calcolare la proporzione cumulativa di Teste\n  running_proportion &lt;- cumsum(coin_tosses) / seq_along(coin_tosses)\n  \n  # Aggiungere i risultati al data frame\n  results &lt;- rbind(\n    results,\n    data.frame(\n      Toss = seq_along(coin_tosses),\n      Proportion = running_proportion,\n      Sequence = paste(\"Sequence\", i)\n    )\n  )\n}\n\n# Creare il grafico con ggplot2\nggplot(results, aes(x = Toss, y = Proportion, color = Sequence)) +\n  geom_line() +\n  geom_hline(yintercept = 0.5, color = \"red\", linetype = \"dashed\") +\n  labs(\n    x = \"Number of Tosses\",\n    y = \"Running Proportion of Heads\",\n    title = \"Running Proportion of Heads in Six Sequences of Fair Coin Tosses\",\n    color = \"Sequence\"\n  )",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#teorema-del-limite-centrale",
    "href": "chapters/probability/08_sampling_distr.html#teorema-del-limite-centrale",
    "title": "31¬† Stime, stimatori e parametri",
    "section": "31.8 Teorema del Limite Centrale",
    "text": "31.8 Teorema del Limite Centrale\nIl teorema del limite centrale √® un risultato fondamentale in statistica che √® stato dimostrato per la prima volta da Laplace nel 1812. Esso fornisce una spiegazione matematica per il motivo per cui la distribuzione normale appare cos√¨ frequentemente nei fenomeni naturali. Ecco la formulazione essenziale.\nSupponiamo di avere una sequenza di variabili aleatorie indipendenti ed identicamente distribuite (i.i.d.), \\(Y = Y_1, \\dots, Y_i, \\ldots, Y_n\\), ciascuna con valore atteso \\(\\mathbb{E}(Y_i) = \\mu\\) e deviazione standard \\(SD(Y_i) = \\sigma\\). Definiamo una nuova variabile casuale come la media aritmetica di queste variabili:\n\\[\nZ = \\frac{1}{n} \\sum_{i=1}^n Y_i.\n\\]\nAllora, quando \\(n\\) tende all‚Äôinfinito, la distribuzione di \\(Z\\) converger√† a una distribuzione normale con media \\(\\mu\\) e deviazione standard ridotta di un fattore \\(\\frac{1}{\\sqrt{n}}\\):\n\\[\np_Z(z) \\rightarrow \\mathcal{N}\\left(z \\ \\Bigg| \\ \\mu, \\, \\frac{\\sigma}{\\sqrt{n}}\\right).\n\\]\n\n31.8.1 Significato e generalizzazione\nIl TLC non si applica solo alle variabili casuali con la stessa distribuzione, ma pu√≤ essere esteso a variabili casuali indipendenti con aspettative e varianze finite. La potenza del teorema sta nella sua capacit√† di descrivere fenomeni che sono il risultato di molteplici effetti additivi indipendenti. Anche se questi effetti possono avere distribuzioni diverse, la loro somma tende a una distribuzione normale.\nAd esempio, l‚Äôaltezza degli esseri umani adulti pu√≤ essere vista come la somma di molti fattori genetici e ambientali indipendenti. Indipendentemente dalla distribuzione individuale di questi fattori, la loro combinazione tende a formare una distribuzione normale. Questa universalit√† rende la distribuzione normale una buona approssimazione per molti fenomeni naturali.\n\nEsempio 31.2 Per visualizzare il TLC in azione, si pu√≤ condurre una simulazione. Immaginiamo una popolazione distribuita in maniera uniforme. Estraiamo 300 campioni di dimensione \\(n\\) = 30 da questa popolazione e osserviamo come la distribuzione campionaria di tali medie converga a una distribuzione normale. Questa simulazione fornir√† un‚Äôillustrazione concreta dell‚Äôefficacia del TLC nell‚Äôapprossimare distribuzioni reali.\n\n# Set the random seed for reproducibility\nset.seed(42)\n\n# Generate a non-normally distributed population\npopulation &lt;- runif(5000, min = 0, max = 1)\n\n# Create a histogram of the population\npar(mfrow = c(1, 2))  # Set up a 1x2 grid for plotting\n\n# Plot the histogram of the population\nhist(population, breaks = 30, prob = TRUE, main = \"Population Distribution\",\n     xlab = \"Value\", col = \"lightblue\")\n\n# Step 2 and 3: Draw random samples and calculate sample means\nsample_size &lt;- 30\nnum_samples &lt;- 300\n\n# Empty vector to store sample means\nsample_means &lt;- c()\n\nfor (i in 1:num_samples) {\n  # Take a random sample\n  sample &lt;- sample(population, size = sample_size, replace = TRUE)\n  \n  # Calculate the mean of the sample\n  sample_means[i] &lt;- mean(sample)\n}\n\n# For sample\nx_bar &lt;- mean(sample_means)\nstd &lt;- sd(sample_means)\n\nprint('Sample Mean and Variance')\n#&gt; [1] \"Sample Mean and Variance\"\nprint(x_bar)\n#&gt; [1] 0.501\nprint(std**2)\n#&gt; [1] 0.00275\n\n# For Population\nmu &lt;- mean(population)\nsigma &lt;- sd(population)\n\nprint('Population Mean and Variance')\n#&gt; [1] \"Population Mean and Variance\"\nprint(mu)\n#&gt; [1] 0.503\nprint((sigma**2)/sample_size)\n#&gt; [1] 0.00282\n\n# Plot the histogram of sample means\nhist(sample_means, breaks = 30, prob = TRUE, main = \"Distribution of Sample Means\",\n     xlab = \"Sample Mean\", col = \"lightgreen\")\n\n# Overlay density curves\ncurve(dnorm(x, mean = x_bar, sd = std), col = \"black\", lwd = 2, add = TRUE)\n\n# Add labels and legends\nlegend(\"topright\", legend = c(\"Distribution Curve\"),\n       col = c(\"black\"), lwd = 2)\n\n# Reset the plot layout\npar(mfrow = c(1, 1))\n\n\n\n\n\n\n\n\n\nIn conclusione, il teorema del limite centrale (TLC) stabilisce che, a meno che non si stia lavorando con campioni estremamente piccoli, √® possibile approssimare con buona precisione la distribuzione campionaria della media dei campioni utilizzando la distribuzione Normale. Questo vale indipendentemente dalla forma specifica della distribuzione della popolazione da cui sono tratti i campioni. In altre parole, quando si lavora con campioni di dimensioni sufficienti, il TLC offre una formula concreta per descrivere la forma della distribuzione campionaria della media dei campioni. Ci√≤ avviene anche se non si hanno informazioni dettagliate sulla popolazione, come la media \\(\\mu\\) e la deviazione standard \\(\\sigma\\), ed √® espresso dalla relazione \\(\\bar{X} \\sim \\mathcal{N}(\\mu, \\sigma/\\sqrt{n})\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#distribuzioni-campionarie-di-altre-statistiche",
    "href": "chapters/probability/08_sampling_distr.html#distribuzioni-campionarie-di-altre-statistiche",
    "title": "31¬† Stime, stimatori e parametri",
    "section": "31.9 Distribuzioni campionarie di altre statistiche",
    "text": "31.9 Distribuzioni campionarie di altre statistiche\nIn precedenza abbiamo descritto la distribuzione campionaria della media dei campioni. Ma ovviamente √® possibile costruire la distribuzione campionaria di altre statistiche campionarie. Ad esempio, la figura seguente mostra l‚Äôapprossimazione empirica della distribuzione campionaria del valore massimo del campione. √à chiaro che, se da ciascun campione estraiamo il valore massimo, il valore atteso della distribuzione campionaria di questa statistica sar√† maggiore della media della popolazione.\n\n# Definire una distribuzione normale con media 100 e deviazione standard 15\nmu &lt;- 100\nsigma &lt;- 15\nx &lt;- seq(mu - 3 * sigma, mu + 3 * sigma, length.out = 100)\ny &lt;- dnorm(x, mean = mu, sd = sigma)\n\n# Simulare 10.000 esperimenti con 5 soggetti ciascuno e trovare il massimo punteggio per ciascun esperimento\nset.seed(123)  # Per riproducibilit√†\nsample_maxes &lt;- replicate(10000, max(rnorm(5, mean = mu, sd = sigma)))\n\n# Creare un istogramma della distribuzione dei massimi campionari insieme alla distribuzione della popolazione\n\n# Creare il data frame per il grafico\ndata &lt;- data.frame(SampleMaxes = sample_maxes)\ndensity_data &lt;- data.frame(x = x, y = y)\n\nggplot(data, aes(x = SampleMaxes)) +\n  geom_histogram(\n    aes(y = ..density..),\n    bins = 30,\n    alpha = 0.7\n  ) +\n  geom_line(data = density_data, aes(x = x, y = y), size = 1) +\n  labs(\n    title = \"Distribuzione dei massimi campionari\",\n    x = \"Massimo campionario\",\n    y = \"Densit√†\"\n  ) \n#&gt; Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#&gt; ‚Ñπ Please use `linewidth` instead.\n#&gt; Warning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\n#&gt; ‚Ñπ Please use `after_stat(density)` instead.\n\n\n\n\n\n\n\n\nLa distribuzione campionaria della varianza dei campioni √® particolarmente interessante. Usiamo la formula della statistica descrittiva, ovvero\n\\[\nS^2 = \\frac{\\sum_{i=1}^n (Y_i - \\bar{Y})^2}{n}.\n\\]\nUna volta compresa la procedura, possiamo creare un grafico che rappresenta l‚Äôapprossimazione empirica della distribuzione campionaria della varianza dei punteggi del quoziente di intelligenza. Sapendo che la varianza della popolazione √® uguale a \\(15^2\\), abbiamo utilizzato la simulazione per stimare la varianza della popolazione. Tuttavia, il risultato ottenuto √® stato interessante: in media, l‚Äôutilizzo della formula precedente ha portato a una stima della varianza della popolazione troppo piccola. Gli statistici chiamano questa discrepanza distorsione, ovvero quando il valore atteso di uno stimatore non coincide con il parametro.\n\n# Definire una distribuzione normale con media 100 e deviazione standard 15\nmu &lt;- 100\nsigma &lt;- 15\nx &lt;- seq(0, 30, length.out = 100)\ny &lt;- dnorm(x, mean = mu, sd = sigma)\n\n# Simulare 10.000 esperimenti con 5 soggetti ciascuno e calcolare la varianza per ciascun esperimento\nset.seed(123)  # Per riproducibilit√†\nsample_vars &lt;- replicate(10000, var(rnorm(5, mean = mu, sd = sigma)))\n\n# Creare un istogramma della distribuzione delle varianze campionarie\n\ndata &lt;- data.frame(SampleVars = sample_vars)\n\nggplot(data, aes(x = SampleVars)) +\n  geom_histogram(\n    aes(y = ..density..),\n    bins = 30,\n    alpha = 0.7\n  ) +\n  labs(\n    title = \"Distribuzione delle varianze campionarie\",\n    x = \"Varianza campionaria\",\n    y = \"Densit√†\"\n  ) \n\n\n\n\n\n\n\n\n\n# Calcolare la media delle varianze campionarie\nmean(sample_vars)\n#&gt; [1] 226\n\nAbbiamo gi√† visto come questo problema trova una semplice soluzione nel momento in cui usiamo \\(n-1\\) al denominatore.\n\n# Definire una distribuzione normale con media 100 e deviazione standard 15\nmu &lt;- 100\nsigma &lt;- 15\nx &lt;- seq(0, 30, length.out = 100)\ny &lt;- dnorm(x, mean = mu, sd = sigma)\n\n# Simulare 10.000 esperimenti con 5 soggetti ciascuno e calcolare la varianza corretta per ciascun esperimento\nset.seed(123)  # Per riproducibilit√†\nsample_vars &lt;- replicate(10000, var(rnorm(5, mean = mu, sd = sigma)))\n\n# Creare un istogramma della distribuzione delle varianze campionarie\ndata &lt;- data.frame(SampleVars = sample_vars)\n\nggplot(data, aes(x = SampleVars)) +\n  geom_histogram(\n    aes(y = ..density..),\n    bins = 30,\n    alpha = 0.7\n  ) +\n  labs(\n    title = \"Distribuzione delle varianze campionarie\",\n    x = \"Varianza campionaria\",\n    y = \"Densit√†\"\n  ) \n\n\n\n\n\n\n\n\n\n# Calcolare la media delle varianze campionarie\nmean(sample_vars)\n#&gt; [1] 226\n\nLa differenza tra la stima di un parametro e il valore vero del parametro √® chiamata errore della stima. Uno stimatore si dice non distorto (unbiased) se la media delle sue stime su molteplici campioni ipotetici √® uguale al valore del parametro che si vuole stimare. In altre parole, l‚Äôerrore medio di stima √® zero.\nIn questo capitolo abbiamo visto che \\(\\frac{\\sum_{i=1}^n{X_i}}{n}\\) √® uno stimatore non distorto di \\(\\mu\\) e che \\(\\frac{\\sum_{i=1}^n{(^2)}}{n-1}\\) √® uno stimatore non distorto di \\(\\sigma^2\\). Questo significa che tali stimatori hanno una distribuzione campionaria centrata sul vero valore del parametro.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#riflessioni-conclusive",
    "href": "chapters/probability/08_sampling_distr.html#riflessioni-conclusive",
    "title": "31¬† Stime, stimatori e parametri",
    "section": "31.10 Riflessioni Conclusive",
    "text": "31.10 Riflessioni Conclusive\nIn generale, i parametri della popolazione sono sconosciuti, ma possiamo stimarli utilizzando le informazioni del campione. Di seguito viene presentata una tabella che riassume i simboli comuni utilizzati per indicare le quantit√† note e sconosciute nel contesto dell‚Äôinferenza statistica. Questo ci aiuter√† a tenere traccia di ci√≤ che sappiamo e ci√≤ che non sappiamo.\n\n\n\n\n\n\n\n\nSimbolo\nNome\n√à qualcosa che conosciamo?\n\n\n\n\n\\(s\\)\nDeviazione standard del campione\nS√¨, la calcoliamo dai dati grezzi\n\n\n\\(\\sigma\\)\nDeviazione standard della popolazione\nNo, tranne in casi particolari o nelle simulazioni\n\n\n\\(\\hat{\\sigma}\\)\nStima della deviazione standard della popolazione\nS√¨, ma non √® uguale a \\(\\sigma\\)\n\n\n\\(s^2\\)\nVarianza del campione\nS√¨, la calcoliamo dai dati grezzi\n\n\n\\(\\sigma^2\\)\nVarianza della popolazione\nNo, tranne in casi particolari o nelle simulazioni\n\n\n\\(\\hat{\\sigma}^2\\)\nStima della varianza della popolazione\nS√¨, ma non √® uguale a \\(\\sigma^2\\)\n\n\n\nUtilizzando le informazioni di un campione casuale di ampiezza \\(n\\):\n\nLa stima migliore che possiamo ottenere per la media \\(\\mu\\) della popolazione √® la media del campione \\(\\bar{Y}\\).\nLa stima migliore che possiamo ottenere per la varianza \\(\\sigma^2\\) della popolazione √®:\n\n\\[\n\\hat{\\sigma}^2 = \\frac{1}{n-1} \\sum_{i=1}^n (Y_i - \\bar{Y})^2.\n\\]",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/08_sampling_distr.html#informazioni-sullambiente-di-sviluppo",
    "title": "31¬† Stime, stimatori e parametri",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: US/Pacific\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] ggokabeito_0.1.0 see_0.9.0        gridExtra_2.3    patchwork_1.3.0 \n#&gt;  [5] bayesplot_1.11.1 psych_2.4.12     scales_1.3.0     markdown_1.13   \n#&gt;  [9] knitr_1.49       lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1   \n#&gt; [13] dplyr_1.1.4      purrr_1.0.2      readr_2.1.5      tidyr_1.3.1     \n#&gt; [17] tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3       \n#&gt; [21] here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.3         rlang_1.1.4       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       yaml_2.3.10       tools_4.4.2       parallel_4.4.2   \n#&gt; [21] tzdb_0.4.0        colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5      \n#&gt; [25] R6_2.5.1          lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3  \n#&gt; [29] pillar_1.10.1     gtable_0.3.6      glue_1.8.0        xfun_0.50        \n#&gt; [33] tidyselect_1.2.1  farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-166     \n#&gt; [37] labeling_0.4.3    rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#bibliografia",
    "href": "chapters/probability/08_sampling_distr.html#bibliografia",
    "title": "31¬† Stime, stimatori e parametri",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nWard, A., & Mann, T. (2022). Control yourself: Broad implications of narrowed attention. Perspectives on Psychological Science, 17(6), 1692‚Äì1703.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html",
    "href": "chapters/probability/09_joint_prob.html",
    "title": "32¬† Probabilit√† congiunta",
    "section": "",
    "text": "32.1 Introduzione\nPrerequisiti\nConcetti e Competenze Chiave\nPreparazione del Notebook\nIn questo capitolo ci proponiamo di analizzare in dettaglio il concetto di probabilit√† congiunta, focalizzando l‚Äôattenzione sul caso di variabili aleatorie discrete. La probabilit√† congiunta rappresenta la misura della probabilit√† che due o pi√π eventi si verifichino simultaneamente.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#funzione-di-probabilit√†-congiunta",
    "href": "chapters/probability/09_joint_prob.html#funzione-di-probabilit√†-congiunta",
    "title": "32¬† Probabilit√† congiunta",
    "section": "32.2 Funzione di Probabilit√† Congiunta",
    "text": "32.2 Funzione di Probabilit√† Congiunta\nFinora abbiamo analizzato la probabilit√† associata a un singolo evento, o pi√π precisamente, a un singolo valore assunto da una variabile aleatoria. Tuttavia, spesso siamo interessati a studiare la relazione tra due o pi√π eventi. La funzione di probabilit√† congiunta ci permette di estendere il concetto di probabilit√† al caso di pi√π variabili aleatorie, descrivendo la probabilit√† che queste assumano specifici valori contemporaneamente.\n\n32.2.1 Esempio: Lancio di Tre Monete Equilibrate\nPer comprendere meglio il concetto di probabilit√† congiunta, immaginiamo di lanciare tre monete. Tutti i possibili risultati di questo esperimento (ad esempio, tre teste, due teste e una croce, ecc.) costituiscono quello che chiamiamo spazio campionario. In questo caso, lo spazio campionario \\(\\Omega\\) √® dato da:\n\\[\n\\Omega = \\{TTT, TTC, TCT, CTT, CCT, CTC, TCC, CCC\\},\n\\]\ndove \\(T\\) indica ‚Äútesta‚Äù e \\(C\\) indica ‚Äúcroce‚Äù. Assumendo che ogni lancio sia indipendente dagli altri, ogni risultato nello spazio campionario \\(\\Omega\\) ha la stessa probabilit√† di verificarsi, ovvero \\(1/8\\).\nDefiniamo ora le seguenti variabili casuali sullo spazio campionario \\(\\Omega\\):\n\n\\(X \\in \\{0, 1, 2, 3\\}\\) rappresenta il numero totale di teste ottenute nei tre lanci.\n\\(Y \\in \\{0, 1\\}\\) indica se il primo lancio ha dato testa (\\(1\\)) oppure croce (\\(0\\)).\n\nLa tabella seguente mostra lo spazio campionario con i valori di \\(X\\) e \\(Y\\) associati a ciascun esito, insieme alla probabilit√† di ciascun evento \\(\\omega\\):\n\n\n\n\\(\\omega\\)\n\\(X\\)\n\\(Y\\)\n\\(P(\\omega)\\)\n\n\n\n\n\\(\\omega_1\\) = TTT\n3\n1\n1/8\n\n\n\\(\\omega_2\\) = TTC\n2\n1\n1/8\n\n\n\\(\\omega_3\\) = TCT\n2\n1\n1/8\n\n\n\\(\\omega_4\\) = CTT\n2\n0\n1/8\n\n\n\\(\\omega_5\\) = CCT\n1\n0\n1/8\n\n\n\\(\\omega_6\\) = CTC\n1\n0\n1/8\n\n\n\\(\\omega_7\\) = TCC\n1\n1\n1/8\n\n\n\\(\\omega_8\\) = CCC\n0\n0\n1/8\n\n\n\nOra possiamo determinare la probabilit√† congiunta per ogni coppia \\((X, Y)\\), che rappresenta la probabilit√† di ottenere un determinato numero di teste \\(X\\) e un determinato risultato per il primo lancio \\(Y\\). Ad esempio:\n\\[P(X=0, Y=0) = P(\\text{CCC}) = 1/8,\\]\ne cos√¨ via per le altre coppie.\nLe probabilit√† congiunte per tutte le possibili combinazioni \\((X, Y)\\) sono calcolate come segue:\n\\[\n\\begin{aligned}\nP(X = 0, Y = 0) &= 1/8, \\\\\nP(X = 1, Y = 0) &= P(\\text{CCT}) + P(\\text{CTC}) = 1/4, \\\\\nP(X = 1, Y = 1) &= P(\\text{TCC}) = 1/8, \\\\\nP(X = 2, Y = 0) &= P(\\text{CTT}) = 1/8, \\\\\nP(X = 2, Y = 1) &= P(\\text{TTC}) + P(\\text{TCT}) = 1/4, \\\\\nP(X = 3, Y = 1) &= P(\\text{TTT}) = 1/8.\n\\end{aligned}\n\\]\nQueste probabilit√† costituiscono la distribuzione di probabilit√† congiunta delle variabili casuali \\(X\\) (numero di teste) e \\(Y\\) (testa al primo lancio). Questa distribuzione fornisce un quadro completo delle probabilit√† per tutte le combinazioni di risultati di queste due variabili.\n\n\n32.2.2 Definizione: Funzione di Probabilit√† Congiunta\nLa funzione di probabilit√† congiunta di due variabili casuali \\(X\\) e \\(Y\\) associa a ogni coppia \\((x, y)\\) una probabilit√† \\(P(X = x, Y = y)\\).\n\n\n32.2.3 Propriet√†\nUna distribuzione di probabilit√† congiunta deve soddisfare:\n\n\\(0 \\leq P(x_i, y_j) \\leq 1\\) per ogni coppia \\((x_i, y_j)\\),\n\\(\\sum_{i} \\sum_{j} P(x_i, y_j) = 1\\), ovvero la somma delle probabilit√† su tutte le coppie deve essere 1.\n\n\n\n32.2.4 Calcolo della Probabilit√† di Eventi Specifici\nData la distribuzione di probabilit√† congiunta, possiamo determinare la probabilit√† di eventi definiti in termini delle variabili aleatorie \\(X\\) e \\(Y\\). Ad esempio, per trovare la probabilit√† che \\(X + Y \\leq 1\\), sommiamo le probabilit√† di tutte le coppie \\((x, y)\\) che soddisfano questa condizione, ottenendo \\(P(X+Y \\leq 1) = 3/8\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#marginalizzazione",
    "href": "chapters/probability/09_joint_prob.html#marginalizzazione",
    "title": "32¬† Probabilit√† congiunta",
    "section": "32.3 Marginalizzazione",
    "text": "32.3 Marginalizzazione\nImmagina di condurre uno studio sul livello di stress tra studenti universitari, raccogliendo dati su variabili come l‚Äôanno di corso, il genere, il supporto sociale e il livello di stress. Se desideri comprendere come il livello di stress varia in funzione dell‚Äôanno di corso, indipendentemente dal genere e dal supporto sociale, puoi utilizzare la marginalizzazione.\nLa marginalizzazione consente di ottenere una distribuzione di probabilit√† focalizzata su una o pi√π variabili di interesse, ‚Äúeliminando‚Äù dal calcolo le variabili non rilevanti. Nel nostro esempio, per ottenere la distribuzione marginale del livello di stress rispetto all‚Äôanno di corso, occorre sommare (o integrare, nel caso di variabili continue) le probabilit√† associate a tutte le combinazioni di genere e supporto sociale, mantenendo fisso l‚Äôanno di corso. In questo modo, otteniamo una distribuzione che descrive come il livello di stress varia solo in relazione all‚Äôanno di corso.\nIl termine ‚Äúmarginalizzazione‚Äù deriva dalle tabelle di contingenza: quando rappresentiamo una distribuzione di probabilit√† congiunta in una tabella, le probabilit√† marginali‚Äîche descrivono la distribuzione di una variabile indipendentemente dalle altre‚Äîsi trovano nei margini della tabella (ovvero nelle righe e colonne finali).\n\n32.3.1 Formalizzazione della Marginalizzazione\nData una distribuzione di probabilit√† congiunta \\(P(X, Y)\\) di due variabili casuali \\(X\\) e \\(Y\\), possiamo ottenere la distribuzione marginale di \\(X\\) sommando tutte le probabilit√† associate a \\(Y\\). Formalmente:\n\\[\nP(X = x) = \\sum_y P(X = x, Y = y),\n\\]\ndove \\(P(X = x, Y = y)\\) rappresenta la probabilit√† congiunta di \\(X\\) e \\(Y\\). La marginalizzazione garantisce inoltre che le distribuzioni siano normalizzate, cio√® che le somme delle probabilit√† marginali per ciascuna variabile siano uguali a 1:\n\\[\n\\sum_x P(X = x) = 1 \\quad \\text{e} \\quad \\sum_y P(Y = y) = 1.\n\\]\nNel caso di variabili continue, questa operazione di somma viene sostituita dall‚Äôintegrazione.\nPer chiarire, consideriamo il seguente esempio. Supponiamo di studiare l‚Äôefficacia di una terapia cognitivo-comportamentale per l‚Äôansia, includendo variabili come l‚Äôet√† dei partecipanti e il livello iniziale di ansia. Se vogliamo valutare l‚Äôefficacia della terapia a prescindere dall‚Äôet√† e dal livello di ansia iniziale, marginalizziamo rispetto a queste due variabili, ottenendo cos√¨ una distribuzione che riflette solo l‚Äôassociazione tra terapia e riduzione dell‚Äôansia.\nIn sintesi, la marginalizzazione:\n\npermette di estrarre distribuzioni di probabilit√† per variabili specifiche, ‚Äúdimenticando‚Äù quelle non rilevanti;\nconsiste nel sommare o integrare le probabilit√† attraverso tutte le possibili combinazioni delle variabili non rilevanti, concentrandosi su quelle di interesse.\n\nIn conclusione, la marginalizzazione √® uno strumento essenziale per l‚Äôanalisi statistica, facilitando lo studio delle relazioni tra variabili complesse e aiutandoci a isolare gli effetti delle variabili di interesse in modo rigoroso.\n\nEsempio 32.1 Per fare un esempio, prendiamo come riferimento l‚Äôesperimento del lancio di tre monete equilibrate descritto precedentemente. Per calcolare le probabilit√† marginali di \\(X\\) e \\(Y\\), sommiamo le probabilit√† congiunte su una dimensione. La probabilit√† marginale di \\(X\\), \\(P_X\\), si ottiene sommando le probabilit√† lungo le colonne per ciascun valore fisso di \\(X\\); analogamente, la probabilit√† marginale di \\(Y\\), \\(P_Y\\), si calcola sommando le probabilit√† lungo le righe per ciascun valore fisso di \\(Y\\).\nLa tabella seguente mostra la distribuzione di probabilit√† congiunta \\(P(X, Y)\\) e le probabilit√† marginali \\(P(X)\\) e \\(P(Y)\\):\n\n\n\n\\(x \\setminus y\\)\n0\n1\n\\(P(x)\\)\n\n\n\n\n0\n1/8\n0\n1/8\n\n\n1\n2/8\n1/8\n3/8\n\n\n2\n1/8\n2/8\n3/8\n\n\n3\n0\n1/8\n1/8\n\n\n\\(P(y)\\)\n4/8\n4/8\n1.0\n\n\n\n\n\n\n32.3.2 Marginalizzazione per Variabili Casuali Continue\nNell‚Äôambito della statistica bayesiana, il concetto di marginalizzazione gioca un ruolo cruciale. Un esempio di equazione che emerge da questo processo √®:\n\\[\np(y) = \\int_{\\theta} p(y, \\theta) \\, d\\theta = \\int_{\\theta} p(y \\mid \\theta) p(\\theta) \\, d\\theta,\n\\]\ndove \\(y\\) e \\(\\theta\\) sono variabili casuali continue, con \\(y\\) che rappresenta i dati osservati e \\(\\theta\\) i parametri di un modello statistico. Questa equazione illustra come, in un contesto continuo, la marginalizzazione possa essere vista come l‚Äôestensione dell‚Äôapproccio discreto a un continuum di valori per le variabili in esame.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#indipendenza-tra-variabili-casuali",
    "href": "chapters/probability/09_joint_prob.html#indipendenza-tra-variabili-casuali",
    "title": "32¬† Probabilit√† congiunta",
    "section": "32.4 Indipendenza tra Variabili Casuali",
    "text": "32.4 Indipendenza tra Variabili Casuali\nL‚Äôindipendenza tra variabili casuali √® un concetto fondamentale in statistica e probabilit√†, parallelo all‚Äôidea di indipendenza tra eventi. Due variabili casuali si considerano indipendenti quando l‚Äôinformazione su una non altera in alcun modo la distribuzione di probabilit√† dell‚Äôaltra. Questa sezione offre una formalizzazione dell‚Äôindipendenza tra due variabili casuali discrete, basata sulla loro distribuzione di probabilit√† congiunta.\n\n32.4.1 Definizione di Indipendenza\nDue variabili casuali \\(X\\) e \\(Y\\), con una distribuzione congiunta, sono definite indipendenti se, e solo se, per ogni coppia di valori \\((x, y)\\) si verifica che:\n\\[\nP_{X, Y}(x, y) = P_X(x) \\cdot P_Y(y).\n\\]\nIn termini pratici, ci√≤ significa che se \\(X\\) e \\(Y\\) sono variabili casuali discrete indipendenti, la loro distribuzione di probabilit√† congiunta √® il prodotto delle rispettive distribuzioni di probabilit√† marginali. Se invece \\(P_{X, Y}(x, y) \\neq P_X(x) \\cdot P_Y(y)\\), le variabili non sono indipendenti e si dicono associate o dipendenti.\nQuesto concetto si applica anche alle variabili casuali continue, mantenendo la stessa logica: l‚Äôindipendenza si verifica quando la funzione di densit√† congiunta √® il prodotto delle funzioni di densit√† marginali.\n\n\n32.4.2 Associazione tra Variabili Casuali\nQuando due variabili casuali non sono indipendenti, si descrivono come associate o dipendenti. In questo contesto, √® utile introdurre il concetto di covarianza (e correlazione) come misura del grado di associazione lineare tra due variabili casuali. La covarianza e la correlazione quantificano in che modo la variazione di una variabile √® associata alla variazione dell‚Äôaltra, fornendo un indice della loro interdipendenza lineare.\nRiepilogando, l‚Äôindipendenza tra variabili casuali √® un concetto chiave per comprendere le relazioni tra fenomeni aleatori. Riconoscere se due variabili sono indipendenti o associate √® fondamentale per l‚Äôanalisi statistica e per la modellazione di relazioni causali o di correlazione tra variabili.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#covarianza",
    "href": "chapters/probability/09_joint_prob.html#covarianza",
    "title": "32¬† Probabilit√† congiunta",
    "section": "32.5 Covarianza",
    "text": "32.5 Covarianza\nLa covarianza √® un parametro statistico che quantifica il grado e la direzione della relazione lineare tra due variabili casuali, \\(X\\) e \\(Y\\). In termini semplici, misura come le variazioni di una variabile si accompagnano a quelle dell‚Äôaltra. Per esempio, considerando l‚Äôaltezza e il peso di giraffe, scopriremmo che queste due misure tendono ad aumentare insieme, evidenziando cos√¨ una covarianza positiva. La covarianza √® denotata come \\(Cov(X, Y) = \\sigma_{xy}\\).\n\n32.5.1 Definizione di Covarianza\nLa covarianza tra due variabili casuali \\(X\\) e \\(Y\\) √® definita come:\n\\[\nCov(X, Y) = \\mathbb{E}\\left[\\left(X - \\mathbb{E}[X]\\right) \\left(Y - \\mathbb{E}[Y]\\right)\\right],\n\\]\ndove \\(\\mathbb{E}[X]\\) e \\(\\mathbb{E}[Y]\\) rappresentano i valori attesi (o medie) di \\(X\\) ed \\(Y\\), rispettivamente.\nIn termini pi√π espliciti, la covarianza pu√≤ essere espressa come:\n\\[\nCov(X, Y) = \\sum_{(x, y) \\in \\Omega} (x - \\mu_X) (y - \\mu_Y) f(x, y),\n\\]\ndove \\(\\mu_X\\) e \\(\\mu_Y\\) sono le medie di \\(X\\) ed \\(Y\\), e \\(f(x, y)\\) √® la funzione di probabilit√† congiunta delle variabili.\nQuesta definizione mostra una stretta analogia con la varianza, che √® la covarianza di una variabile con se stessa:\n\\[\n\\mathbb{V}(X) = Cov(X, X).\n\\]\nInoltre, la covarianza pu√≤ essere calcolata attraverso la relazione:\n\\[\nCov(X, Y) = \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y).\n\\]\n\n\n32.5.2 Dimostrazione\nLa formula alternativa per la covarianza si dimostra come segue:\n\\[\n\\begin{align}\nCov(X, Y) &= \\mathbb{E}\\left[\\left(X - \\mathbb{E}[X]\\right) \\left(Y - \\mathbb{E}[Y]\\right)\\right]\\\\\n&= \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y).\n\\end{align}\n\\]\n\n\n32.5.3 Esempio di Calcolo della Covarianza\nConsideriamo le variabili casuali \\(X\\) e \\(Y\\) con medie \\(\\mu_X = 1.5\\) e \\(\\mu_Y = 0.5\\). La covarianza di \\(X\\) e \\(Y\\) si calcola come:\n\\[\nCov(X, Y) = \\sum_{(x, y) \\in \\Omega} (x - \\mu_X) (y - \\mu_Y) f(x, y) = \\frac{1}{4}.\n\\]\nQuesto risultato si pu√≤ ottenere anche dalla formula alternativa, calcolando prima \\(\\mathbb{E}(XY)\\):\n\\[\n\\mathbb{E}(XY) = 1.0.\n\\]\nAllora, la covarianza tra \\(X\\) e \\(Y\\) √®:\n\\[\nCov(X, Y) = 1 - 1.5 \\cdot 0.5 = 0.25.\n\\]\n\nEsempio 32.2 Per calcolare la covarianza \\(Cov(X, Y)\\) in R, consideriamo l‚Äôesempio in cui \\(X\\) √® il numero totale di teste che si ottiene dal lancio di tre monete equilibrate e \\(Y\\) √® il risultato del primo lancio (testa = 1, croce = 0). Procediamo creando il prodotto cartesiano di tutti i possibili valori di \\(X\\) e \\(Y\\).\n\n# Creare il prodotto cartesiano di X (c3) e Y (c1)\nc3 &lt;- 0:3  # Numero totale di teste possibili\nc1 &lt;- 0:1  # Risultato del primo lancio (0 = croce, 1 = testa)\nsample &lt;- expand.grid(c1 = c1, c3 = c3)\nsample\n#&gt;   c1 c3\n#&gt; 1  0  0\n#&gt; 2  1  0\n#&gt; 3  0  1\n#&gt; 4  1  1\n#&gt; 5  0  2\n#&gt; 6  1  2\n#&gt; 7  0  3\n#&gt; 8  1  3\n\nIl primo numero di ogni coppia rappresenta il valore di \\(Y\\), mentre il secondo rappresenta il valore di \\(X\\). Tuttavia, queste coppie \\((X, Y)\\) non hanno tutte la stessa probabilit√† di verificarsi. La probabilit√† associata a ciascuna coppia √® data dai seguenti valori: \\(1/8, 2/8, 1/8, 0, 0, 1/8, 2/8, 1/8\\). Questa √® la distribuzione di massa di probabilit√† congiunta delle variabili casuali \\(X\\) e \\(Y\\). Applicando la formula per la covarianza:\n[ Cov(X, Y) = _{i=1}^n (X_i - E[X])(Y_i - E[Y]) P(X_i, Y_i) ]\nCalcoliamo la covarianza in R:\n\n# Probabilit√† di ogni coppia (X, Y)\npmf &lt;- c(1 / 8, 2 / 8, 1 / 8, 0, 0, 1 / 8, 2 / 8, 1 / 8)\n\n# Calcolo della covarianza\nres &lt;- c()\nfor (i in 1:nrow(sample)) {\n  res &lt;- c(res, (sample$c1[i] - 0.5) * (sample$c3[i] - 1.5) * pmf[i])\n}\n\n# Somma dei prodotti ponderati\ncovariance &lt;- sum(res)\ncovariance\n#&gt; [1] -0.125\n\nLa covarianza tra \\(X\\) e \\(Y\\) √® dunque uguale a \\(-0.125\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#correlazione",
    "href": "chapters/probability/09_joint_prob.html#correlazione",
    "title": "32¬† Probabilit√† congiunta",
    "section": "32.6 Correlazione",
    "text": "32.6 Correlazione\nMentre la covarianza fornisce un‚Äôindicazione della tendenza di due variabili casuali a variare insieme, essa √® influenzata dalle unit√† di misura delle variabili, rendendo difficile valutare l‚Äôintensit√† della loro relazione lineare. Per ovviare a questo, si utilizza la correlazione, che normalizza la covarianza attraverso le deviazioni standard delle variabili, offrendo cos√¨ una misura standardizzata dell‚Äôassociazione lineare tra di esse.\n\nDefinizione 32.1 Il coefficiente di correlazione tra due variabili casuali \\(X\\) e \\(Y\\), denotato come \\(\\rho(X,Y)\\) o \\(\\rho_{X,Y}\\), √® definito come:\n\\[\n\\rho(X,Y) = \\frac{Cov(X,Y)}{\\sqrt{\\mathbb{V}(X)\\mathbb{V}(Y)}},\n\\]\ndove \\(\\mathbb{V}(X)\\) e \\(\\mathbb{V}(Y)\\) rappresentano le varianze di \\(X\\) e \\(Y\\), rispettivamente.\n\nIl coefficiente di correlazione \\(\\rho_{xy}\\) √® un valore adimensionale, ovvero non dipende dalle unit√† di misura delle variabili, e varia nell‚Äôintervallo \\(-1 \\leq \\rho \\leq 1\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#propriet√†-1",
    "href": "chapters/probability/09_joint_prob.html#propriet√†-1",
    "title": "32¬† Probabilit√† congiunta",
    "section": "32.7 Propriet√†",
    "text": "32.7 Propriet√†\n\nCovarianza con una Costante: La covarianza tra una variabile aleatoria \\(X\\) e una costante \\(c\\) √® sempre nulla: \\(Cov(c, X) = 0\\).\nSimmetria: La covarianza √® simmetrica: \\(Cov(X,Y) = Cov(Y,X)\\).\nIntervallo di Correlazione: Il coefficiente di correlazione \\(\\rho\\) varia tra -1 e 1: \\(-1 \\leq \\rho(X,Y) \\leq 1\\).\nIndipendenza dalle Unit√† di Misura: La correlazione √® indipendente dalle unit√† di misura: \\(\\rho(aX, bY) = \\rho(X,Y)\\) per ogni \\(a, b &gt; 0\\).\nRelazione Lineare Perfetta: Se \\(Y = a + bX\\) √® una funzione lineare di \\(X\\), allora \\(\\rho(X,Y) = \\pm 1\\), a seconda del segno di \\(b\\).\nCovarianza e Costanti: La covarianza tra \\(X\\) e \\(Y\\), ciascuna moltiplicata per una costante, √® \\(Cov(aX, bY) = ab \\, Cov(X,Y)\\).\nVarianza della Somma/Differenza: \\(\\mathbb{V}(X \\pm Y) = \\mathbb{V}(X) + \\mathbb{V}(Y) \\pm 2Cov(X,Y)\\).\nCovarianza e Somma di Variabili: \\(Cov(X + Y, Z) = Cov(X,Z) + Cov(Y,Z)\\).\nVarianza di una Somma di Variabili Aleatorie: Per variabili aleatorie \\(X_1, \\dots, X_n\\), si ha \\(\\mathbb{V}(\\sum_{i=1}^n X_i) = \\sum_{i=1}^n \\mathbb{V}(X_i) + 2\\sum_{i&lt;j} Cov(X_i, X_j)\\).\nCovarianza e Somme di Prodotti: \\(Cov(\\sum_{i=1}^n a_i X_i, \\sum_{j=1}^m b_j Y_j) = \\sum_{i=1}^n \\sum_{j=1}^m a_i b_j Cov(X_i, Y_j)\\).\nIndipendenza e Covarianza di Somme: Se \\(X_1, X_2, \\dots, X_n\\) sono indipendenti, allora \\(Cov(\\sum_{i=1}^n a_i X_i, \\sum_{j=1}^n b_j X_j) = \\sum_{i=1}^n a_i b_i \\mathbb{V}(X_i)\\).\n\n\n32.7.1 Incorrelazione\nDue variabili casuali \\(X\\) ed \\(Y\\) si dicono incorrelate, o linearmente indipendenti, se la loro covarianza √® nulla:\n\\[\nCov(X,Y) = \\mathbb{E}[(X - \\mu_X)(Y - \\mu_Y)] = 0,\n\\]\nequivalente a dire che \\(\\rho_{XY} = 0\\) e \\(\\mathbb{E}(XY) = \\mathbb{E}(X)\\mathbb{E}(Y)\\).\nQuesta condizione indica una forma di indipendenza pi√π debole rispetto all‚Äôindipendenza stocastica. Tuttavia, \\(Cov(X, Y) = 0\\) non implica necessariamente che \\(X\\) ed \\(Y\\) siano stocasticamente indipendenti.\n\nEsempio 32.3 Consideriamo una distribuzione di probabilit√† congiunta di due variabili aleatorie, \\(X\\) e \\(Y\\), definita come:\n\\[\nf_{XY}(x,y) = \\left\\{\n\\begin{array}{ll}\n\\frac{1}{4} & \\text{per } (x,y) \\in \\{(0,0), (1,1), (1, -1), (2,0) \\}, \\\\\n0 & \\text{altrimenti.}\n\\end{array}\n\\right.\n\\]\nQuesto implica che le variabili aleatorie \\(X\\) e \\(Y\\) assumono valori specifici con probabilit√† uniforme solo per determinate coppie \\((x, y)\\) e zero in tutti gli altri casi.\nDistribuzioni Marginali\nLa distribuzione marginale di \\(X\\) si ottiene sommando le probabilit√† congiunte su tutti i possibili valori di \\(Y\\), e viceversa per \\(Y\\). Le distribuzioni marginali risultano essere:\n\nPer \\(X\\):\n\\[\nf_X(x) = \\left\\{\n\\begin{array}{ll}\n\\frac{1}{4} & \\text{per } x=0, \\\\\n\\frac{1}{2} & \\text{per } x=1, \\\\\n\\frac{1}{4} & \\text{per } x=2.\n\\end{array}\n\\right.\n\\]\nPer \\(Y\\):\n\\[\nf_Y(y) = \\left\\{\n\\begin{array}{ll}\n\\frac{1}{4} & \\text{per } y=-1, \\\\\n\\frac{1}{2} & \\text{per } y=0, \\\\\n\\frac{1}{4} & \\text{per } y=1.\n\\end{array}\n\\right.\n\\]\n\nMedie e Varianze\nCalcoliamo ora le medie e le varianze di \\(X\\) e \\(Y\\):\n\nMedia di \\(X\\):\n\\[\n\\mathbb{E}(X) = 0 \\cdot \\frac{1}{4} + 1 \\cdot \\frac{1}{2} + 2 \\cdot \\frac{1}{4} = 1.\n\\]\nVarianza di \\(X\\):\n\\[\n\\mathbb{V}(X) = \\left(0^2 \\cdot \\frac{1}{4} + 1^2 \\cdot \\frac{1}{2} + 2^2 \\cdot \\frac{1}{4}\\right) - \\mathbb{E}(X)^2 = \\frac{3}{2} - 1 = \\frac{1}{2}.\n\\]\nMedia di \\(Y\\):\n\\[\n\\mathbb{E}(Y) = (-1) \\cdot \\frac{1}{4} + 0 \\cdot \\frac{1}{2} + 1 \\cdot \\frac{1}{4} = 0.\n\\]\nVarianza di \\(Y\\):\n\\[\n\\mathbb{V}(Y) = \\left((-1)^2 \\cdot \\frac{1}{4} + 0^2 \\cdot \\frac{1}{2} + 1^2 \\cdot \\frac{1}{4}\\right) - \\mathbb{E}(Y)^2 = \\frac{1}{2}.\n\\]\n\nCovarianza tra X e Y\nLa covarianza si calcola come:\n\\[\nCov(X,Y) = \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y),\n\\]\ndove \\(\\mathbb{E}(XY)\\) si trova sommando il prodotto delle coppie di valori \\((x, y)\\) per la loro probabilit√† congiunta:\n\\[\n\\mathbb{E}(XY) = 0.\n\\]\nDi conseguenza, la covarianza tra \\(X\\) e \\(Y\\) √® zero:\n\\[\nCov(X,Y) = 0 - 1 \\cdot 0 = 0.\n\\]\nConclusioni\nSebbene \\(X\\) e \\(Y\\) siano incorrelate (covarianza nulla), ci√≤ non implica la loro indipendenza. L‚Äôindipendenza richiede che la funzione di probabilit√† congiunta si possa esprimere come il prodotto delle funzioni di probabilit√† marginali per ogni \\(x\\) e \\(y\\), condizione che non si verifica in questo caso. Quindi, nonostante l‚Äôassenza di correlazione, \\(X\\) e \\(Y\\) non sono indipendenti, dimostrando che l‚Äôincorrelazione non garantisce l‚Äôindipendenza.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#variabili-continue",
    "href": "chapters/probability/09_joint_prob.html#variabili-continue",
    "title": "32¬† Probabilit√† congiunta",
    "section": "32.8 Variabili continue",
    "text": "32.8 Variabili continue\nConsideriamo ora le distribuzioni di densit√†. Nella figura successiva, tratta da Martin (2024), vediamo una rappresentazione della relazione tra la probabilit√† congiunta \\(p(A,B)\\), le probabilit√† marginali \\(p(A)\\) e \\(p(B)\\), e le probabilit√† condizionali \\(p(A \\mid B)\\).\n\n\n\nDistribuzioni di densit√† (figura tratta da Martin (2024)).\n\n\n\nProbabilit√† congiunta \\(p(A,B)\\): rappresenta la probabilit√† che A e B assumano certi valori contemporaneamente. Per le variabili continue, questa √® data dall‚Äôintegrazione della funzione di densit√† congiunta su un‚Äôarea o volume di interesse.\nProbabilit√† marginale \\(p(A)\\) e \\(p(B)\\): √® la probabilit√† di osservare un particolare valore di A (o B) indipendentemente dal valore di B (o A). Si ottiene integrando la funzione di densit√† congiunta sull‚Äôintero intervallo di valori dell‚Äôaltra variabile.\nProbabilit√† condizionale \\(p(A \\mid B)\\): esprime la probabilit√† di A dato B. Si calcola dividendo la probabilit√† congiunta per la probabilit√† marginale di B, applicando la definizione di probabilit√† condizionale anche nel contesto continuo.\n\nLa transizione dal trattamento delle variabili discrete a quello delle variabili continue richiede un cambiamento di strumenti matematici da somme ad integrali, ma i concetti fondamentali di probabilit√† congiunta, marginale e condizionale rimangono applicabili.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#riflessioni-conclusive",
    "href": "chapters/probability/09_joint_prob.html#riflessioni-conclusive",
    "title": "32¬† Probabilit√† congiunta",
    "section": "32.9 Riflessioni Conclusive",
    "text": "32.9 Riflessioni Conclusive\nIn alcune situazioni, ogni singolo elemento di una popolazione pu√≤ essere associato a diverse variabili casuali. Ad esempio, consideriamo l‚Äôelenco di tutti gli studenti iscritti a un‚Äôuniversit√† e immaginiamo di selezionare uno studente a caso per misurare la sua altezza e il suo peso. In questo caso, ogni individuo della popolazione √® associato a due variabili casuali, l‚Äôaltezza e il peso. Quando si hanno due o pi√π variabili casuali associate ad ogni elemento di una popolazione, √® possibile studiare la distribuzione congiunta di tali variabili casuali. In questo capitolo abbiamo esaminato come rappresentare la distribuzione di massa di probabilit√† congiunta di due variabili casuali discrete e come ottenere le distribuzioni marginali delle due variabili. Inoltre, abbiamo discusso i concetti di incorrelazione e indipendenza.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/09_joint_prob.html#informazioni-sullambiente-di-sviluppo",
    "title": "32¬† Probabilit√† congiunta",
    "section": "32.10 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "32.10 Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: US/Pacific\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.17.0      ggokabeito_0.1.0 see_0.9.0        gridExtra_2.3   \n#&gt;  [5] patchwork_1.3.0  bayesplot_1.11.1 psych_2.4.12     scales_1.3.0    \n#&gt;  [9] markdown_1.13    knitr_1.49       lubridate_1.9.4  forcats_1.0.0   \n#&gt; [13] stringr_1.5.1    dplyr_1.1.4      purrr_1.0.2      readr_2.1.5     \n#&gt; [17] tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0 \n#&gt; [21] rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      shape_1.4.6.1     xfun_0.50         htmlwidgets_1.6.4\n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2      \n#&gt;  [9] generics_0.1.3    parallel_4.4.2    pan_1.9           pacman_0.5.1     \n#&gt; [13] jomo_2.7-6        pkgconfig_2.0.3   Matrix_1.7-1      lifecycle_1.0.4  \n#&gt; [17] compiler_4.4.2    farver_2.1.2      munsell_0.5.1     mnormt_2.1.1     \n#&gt; [21] codetools_0.2-20  htmltools_0.5.8.1 yaml_2.3.10       glmnet_4.1-8     \n#&gt; [25] nloptr_2.1.1      pillar_1.10.1     MASS_7.3-64       iterators_1.0.14 \n#&gt; [29] rpart_4.1.23      boot_1.3-31       foreach_1.5.2     mitml_0.4-5      \n#&gt; [33] nlme_3.1-166      tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4    \n#&gt; [37] splines_4.4.2     rprojroot_2.0.4   fastmap_1.2.0     grid_4.4.2       \n#&gt; [41] colorspace_2.1-1  cli_3.6.3         magrittr_2.0.3    survival_3.7-0   \n#&gt; [45] broom_1.0.7       withr_3.0.2       backports_1.5.0   timechange_0.3.0 \n#&gt; [49] rmarkdown_2.29    nnet_7.3-19       lme4_1.1-35.5     hms_1.1.3        \n#&gt; [53] evaluate_1.0.1    rlang_1.1.4       Rcpp_1.0.13-1     glue_1.8.0       \n#&gt; [57] minqa_1.2.8       jsonlite_1.8.9    R6_2.5.1",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#bibliografia",
    "href": "chapters/probability/09_joint_prob.html#bibliografia",
    "title": "32¬† Probabilit√† congiunta",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nMartin, O. (2024). Bayesian analysis with python. Packt Publishing Ltd.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_prob_distributions.html",
    "href": "chapters/probability/10_prob_distributions.html",
    "title": "33¬† Distribuzioni di massa e di densit√†",
    "section": "",
    "text": "33.1 Introduzione\nLa data science mira a comprendere e prevedere fenomeni, compresi quelli futuri, mediante l‚Äôimpiego di modelli probabilistici e dati empirici. Tale capacit√† predittiva si fonda sulla conoscenza approfondita della popolazione di riferimento, senza la necessit√† di esaminare ogni singolo risultato possibile. In statistica, questa conoscenza viene formalizzata attraverso le distribuzioni di probabilit√†, uno strumento essenziale per analizzare e modellare i dati.\nUna distribuzione di probabilit√†, indicata formalmente come \\(p(x)\\), √® associata a una variabile casuale \\(X\\) e descrive la variabilit√† osservabile in una popolazione. Essa fornisce un modello teorico per quantificare la probabilit√† di osservare ciascun valore possibile di \\(X\\), permettendo di caratterizzare l‚Äôincertezza legata al fenomeno in analisi.\nAd esempio, se si seleziona casualmente un‚Äôosservazione dalla popolazione, la distribuzione \\(p(x)\\) indica la probabilit√† che la variabile casuale \\(X\\) assuma un determinato valore. In tal modo, la distribuzione riassume matematicamente le informazioni sulle frequenze o probabilit√† associate ai possibili esiti, offrendo un quadro generalizzabile del fenomeno studiato.\nTuttavia, √® fondamentale sottolineare che \\(p(x)\\) non rappresenta la popolazione reale nella sua interezza, ma costituisce un modello statistico, ovvero una rappresentazione semplificata della realt√†. Questo modello consente di generalizzare le osservazioni disponibili e di formulare previsioni su eventi futuri con un approccio rigoroso. La distribuzione di probabilit√† non mira a catturare ogni dettaglio, ma piuttosto a fornire una descrizione essenziale e funzionale del fenomeno.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Distribuzioni di massa e di densit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_prob_distributions.html#variabili-casuali-discrete-e-continue",
    "href": "chapters/probability/10_prob_distributions.html#variabili-casuali-discrete-e-continue",
    "title": "33¬† Distribuzioni di massa e di densit√†",
    "section": "33.2 Variabili Casuali Discrete e Continue",
    "text": "33.2 Variabili Casuali Discrete e Continue\nUn elemento fondamentale nella comprensione delle distribuzioni di probabilit√† √® la distinzione tra variabili casuali discrete e continue, poich√© le distribuzioni associate differiscono significativamente.\n\n33.2.1 Distribuzioni di Massa di Probabilit√† (Discrete)\nLe distribuzioni di probabilit√† discrete descrivono fenomeni aleatori che generano un numero finito o numerabile di esiti possibili. Queste distribuzioni sono particolarmente utili per modellare eventi che si verificano in contesti discreti, come il numero di successi in un esperimento o la selezione casuale da un insieme di opzioni finite.\nIn una distribuzione di massa di probabilit√†, a ciascun valore di una variabile casuale discreta \\(X\\) √® associata una probabilit√† ben definita. Ad esempio, consideriamo un dado sbilanciato con la seguente distribuzione di probabilit√†:\n\n\n\nValore di \\(X\\)\nProbabilit√† \\(p(x)\\)\n\n\n\n\n1\n0.10\n\n\n2\n0.15\n\n\n3\n0.20\n\n\n4\n0.25\n\n\n5\n0.20\n\n\n6\n0.10\n\n\n\nPossiamo rappresentare questa distribuzione empiricamente generando 1000 lanci del dado e creando un diagramma a barre, in cui l‚Äôaltezza di ciascuna barra rappresenta la frequenza relativa osservata. In R:\n\n# Dati\nset.seed(123)\nprob &lt;- c(0.10, 0.15, 0.20, 0.25, 0.20, 0.10)\nlanci &lt;- sample(1:6, size = 1000, replace = TRUE, prob = prob)\n\n# Creazione di un data frame\ndf &lt;- data.frame(Valore = factor(lanci))\n\n# Creazione del diagramma a barre\nggplot(df, aes(x = Valore)) +\n  geom_bar(aes(y = after_stat(count) / sum(after_stat(count))), fill = \"skyblue\") +\n  labs(\n    title = \"Distribuzione empirica dei lanci\",\n    x = \"Valore\",\n    y = \"Frequenza relativa\"\n  )\n\n\n\n\n\n\n\n\nCon un numero infinito di osservazioni, la distribuzione empirica si avvicinerebbe alla distribuzione di massa di probabilit√† teorica.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Distribuzioni di massa e di densit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_prob_distributions.html#distribuzioni-di-densit√†-di-probabilit√†-continue",
    "href": "chapters/probability/10_prob_distributions.html#distribuzioni-di-densit√†-di-probabilit√†-continue",
    "title": "33¬† Distribuzioni di massa e di densit√†",
    "section": "33.3 Distribuzioni di Densit√† di Probabilit√† (Continue)",
    "text": "33.3 Distribuzioni di Densit√† di Probabilit√† (Continue)\nLe densit√† di probabilit√† descrivono variabili casuali continue, cio√® variabili che possono assumere un numero infinito di valori all‚Äôinterno di un intervallo. A differenza delle distribuzioni discrete, dove una funzione di massa di probabilit√† fornisce la probabilit√† esatta di ogni valore discreto, una densit√† di probabilit√† \\(f(x)\\) rappresenta la probabilit√† che la variabile casuale assuma valori in un dato intervallo. La probabilit√† per un intervallo \\([a, b]\\) √® data dall‚Äôarea sotto la curva di densit√† tra \\(a\\) e \\(b\\):\n\\[\nP(a \\leq X \\leq b) = \\int_a^b f(x) \\, dx.\n\\]\n\n33.3.1 Esempio pratico: quoziente intellettivo (QI)\nConsideriamo una variabile casuale che rappresenta il quoziente intellettivo (QI) in una popolazione. I valori di QI sono tipicamente distribuiti secondo una distribuzione normale, con una media di \\(100\\) e una deviazione standard di \\(15\\). Possiamo approssimare la densit√† teorica attraverso un istogramma dei dati simulati.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Distribuzioni di massa e di densit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_prob_distributions.html#dagli-istogrammi-alle-densit√†",
    "href": "chapters/probability/10_prob_distributions.html#dagli-istogrammi-alle-densit√†",
    "title": "33¬† Distribuzioni di massa e di densit√†",
    "section": "33.4 Dagli istogrammi alle densit√†",
    "text": "33.4 Dagli istogrammi alle densit√†\nUn istogramma divide i dati in intervalli (o ‚Äúclassi‚Äù) di ampiezza \\(\\Delta\\) e rappresenta graficamente le frequenze relative dei valori in ciascun intervallo. L‚Äôarea di ogni barra √® proporzionale alla frequenza relativa, mentre la sua altezza √® proporzionale alla densit√† relativa. Con un numero crescente di osservazioni \\(M\\) e una larghezza degli intervalli \\(\\Delta \\to 0\\), il profilo dell‚Äôistogramma tende a una curva continua, detta funzione di densit√† di probabilit√† \\(f(x)\\).\nAd esempio, nella statistica descrittiva, abbiamo gi√† incontrato rappresentazioni simili alla densit√† di probabilit√†, come il kernel density plot (KDE). Questo metodo non parametrico stima la funzione di densit√† a partire dai dati osservati.\n\n\n33.4.1 Simulazione: distribuzione del QI\n\n33.4.1.1 Caso 1: campione piccolo\nIniziamo simulando un campione di 50 individui. Creiamo un istogramma e lo confrontiamo con la densit√† teorica stimata.\n\n# Parametri della distribuzione normale\nmu &lt;- 100\nsigma &lt;- 15\nsize &lt;- 50\n\n# Generare i dati\nset.seed(123)\nx &lt;- rnorm(size, mean = mu, sd = sigma)\n\n# Istogramma e densit√†\ndata_frame &lt;- data.frame(X = x)\nxmin &lt;- min(x)\nxmax &lt;- max(x)\ndensity_data &lt;- data.frame(\n  X = seq(xmin, xmax, length.out = 100),\n  Density = dnorm(seq(xmin, xmax, length.out = 100), mean = mu, sd = sigma)\n)\n\nggplot(data_frame, aes(x = X)) +\n  geom_histogram(\n    aes(y = after_stat(density)), # Uso di after_stat() al posto di ..density..\n    bins = 25,\n    fill = \"blue\",\n    alpha = 0.6\n  ) +\n  geom_line(\n    data = density_data,\n    aes(x = X, y = Density),\n    color = \"black\",\n    size = 1\n  ) +\n  labs(\n    title = \"Distribuzione del QI (50 osservazioni)\",\n    x = \"Valori del QI\",\n    y = \"Densit√†\"\n  ) \n#&gt; Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#&gt; ‚Ñπ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\nCon un campione di piccole dimensioni, l‚Äôistogramma non corrisponde perfettamente alla densit√† teorica. L‚Äôapprossimazione migliora aumentando il numero di osservazioni.\n\n\n\n33.4.1.2 Caso 2: campione grande\nRipetiamo la simulazione con 20.000 individui per osservare una maggiore corrispondenza tra istogramma e densit√† teorica.\n\n# Generare un campione pi√π grande\nsize &lt;- 20000\nset.seed(123)\nx &lt;- rnorm(size, mean = mu, sd = sigma)\n\n# Aggiornare media e deviazione standard\nmu &lt;- mean(x)\nsigma &lt;- sd(x)\n\n# Creare il grafico\ndata_frame &lt;- data.frame(X = x)\nxmin &lt;- min(x)\nxmax &lt;- max(x)\ndensity_data &lt;- data.frame(\n  X = seq(xmin, xmax, length.out = 100),\n  Density = dnorm(seq(xmin, xmax, length.out = 100), mean = mu, sd = sigma)\n)\n\nggplot(data_frame, aes(x = X)) +\n  geom_histogram(\n    aes(y = after_stat(density)), # Uso di after_stat() al posto di ..density..\n    bins = 25,\n    fill = \"blue\",\n    alpha = 0.6\n  ) +\n  geom_line(\n    data = density_data,\n    aes(x = X, y = Density),\n    color = \"black\",\n    size = 1\n  ) +\n  labs(\n    title = sprintf(\"Distribuzione del QI (%d osservazioni)\", size),\n    x = \"Valori del QI\",\n    y = \"Densit√†\"\n  )\n\n\n\n\n\n\n\n\nCon un campione di grandi dimensioni, l‚Äôistogramma riflette molto meglio la densit√† teorica. La funzione di densit√† rappresenta quindi un‚Äôastrazione continua dell‚Äôistogramma.\n\n\n\n\n33.4.2 Interpretazione della funzione di densit√†\nLa funzione di densit√† √® una curva che approssima il profilo di un istogramma quando:\n\nIl numero di osservazioni tende a infinito: le frequenze relative si avvicinano alle probabilit√† teoriche.\nGli intervalli sono infinitamente piccoli: il profilo dell‚Äôistogramma diventa continuo.\n\nIn un istogramma, l‚Äôarea di ciascuna barra rappresenta la probabilit√† stimata che la variabile casuale assuma un valore compreso in quell‚Äôintervallo. Analogamente, nella densit√† di probabilit√†, l‚Äôarea sotto la curva per un intervallo \\([a, b]\\) rappresenta la probabilit√† di osservare un valore in quell‚Äôintervallo.\nIn conclusione, la funzione di densit√† di probabilit√† √® uno strumento fondamentale per modellare fenomeni reali. Consente di passare da una rappresentazione discreta (istogramma) a una continua, rendendo possibile l‚Äôanalisi di variabili casuali continue con maggiore precisione e flessibilit√†.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Distribuzioni di massa e di densit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_prob_distributions.html#parametri",
    "href": "chapters/probability/10_prob_distributions.html#parametri",
    "title": "33¬† Distribuzioni di massa e di densit√†",
    "section": "33.5 Parametri",
    "text": "33.5 Parametri\nLe distribuzioni di probabilit√†, siano esse discrete o continue, sono definite da uno o pi√π parametri, che ne determinano le propriet√† fondamentali e permettono di modellare in modo preciso fenomeni reali. I parametri rappresentano valori numerici che influenzano il comportamento della distribuzione, come la posizione, la dispersione, la forma e altre caratteristiche specifiche.\nI parametri delle distribuzioni sono utilizzati per descrivere propriet√† essenziali della variabile casuale, consentendo di adattare il modello probabilistico al fenomeno in analisi. Ecco alcune delle propriet√† principali influenzate dai parametri:\n\nPosizione (o tendenza centrale): Indica il valore attorno al quale si concentra la distribuzione. Ad esempio, nella distribuzione normale, la media (\\(\\mu\\)) rappresenta il centro della distribuzione.\nDispersione: Misura quanto i valori della distribuzione si allontanano dalla posizione centrale. Ad esempio, nella distribuzione normale, la deviazione standard (\\(\\sigma\\)) controlla la larghezza della curva.\nForma: Determina l‚Äôasimmetria o la curtosi della distribuzione. Alcune distribuzioni, come quella gamma o beta, hanno parametri specifici per regolare la forma.\nProbabilit√† specifiche: Nelle distribuzioni discrete, i parametri possono determinare la probabilit√† di specifici eventi. Ad esempio, nella distribuzione binomiale, il parametro \\(p\\) rappresenta la probabilit√† di successo in ciascun tentativo.\n\nLa capacit√† di manipolare i parametri consente di adattare la distribuzione a diversi contesti e di catturare meglio le caratteristiche dei dati reali. Nella pratica, stimare accuratamente i parametri di una distribuzione √® essenziale per comprendere e modellare i fenomeni studiati, nonch√© per formulare previsioni affidabili. Questi parametri sono spesso stimati a partire dai dati osservati mediante metodi statistici come la massima verosimiglianza o i metodi bayesiani.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Distribuzioni di massa e di densit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_prob_distributions.html#il-paradosso-delle-variabili-casuali-continue",
    "href": "chapters/probability/10_prob_distributions.html#il-paradosso-delle-variabili-casuali-continue",
    "title": "33¬† Distribuzioni di massa e di densit√†",
    "section": "33.6 Il Paradosso delle Variabili Casuali Continue",
    "text": "33.6 Il Paradosso delle Variabili Casuali Continue\nConsideriamo la probabilit√† che una variabile casuale continua assuma un valore specifico, come ad esempio un QI esattamente uguale a 100. Intuitivamente, potremmo pensare che sia possibile calcolare questa probabilit√†. Tuttavia, sorprendentemente, la risposta √®:\n\\[\nP(X = 100) = 0.\n\\]\nQuesto risultato deriva dal fatto che, per una variabile casuale continua, la probabilit√† di un singolo valore √® sempre pari a zero. Se cos√¨ non fosse, ogni possibile valore all‚Äôinterno del dominio della variabile dovrebbe avere una probabilit√† positiva. Ma se sommiamo tutte queste probabilit√†, il totale sarebbe maggiore di uno, il che √® impossibile, dato che la somma delle probabilit√† per una variabile casuale deve essere esattamente uno.\n\n\n33.6.1 L‚ÄôInterpretazione delle Probabilit√† per Variabili Continue\nNel caso delle variabili casuali continue, rinunciamo al concetto di probabilit√† associata a un singolo valore. Invece, consideriamo la probabilit√† di osservare un valore all‚Äôinterno di un intervallo. Ad esempio, la probabilit√† che il QI sia compreso tra 95 e 105 si calcola come:\n\\[\nP(95 \\leq X \\leq 105) = \\int_{95}^{105} f(x) \\, dx,\n\\]\ndove \\(f(x)\\) √® la funzione di densit√† di probabilit√† (PDF). La probabilit√† per un valore esatto, come \\(P(X = 100)\\), corrisponde all‚Äôarea sotto la curva di densit√† in un singolo punto, che √® sempre zero.\nQuesta caratteristica introduce due conseguenze fondamentali:\n\nLe probabilit√† si calcolano solo per intervalli di valori, non per punti specifici.\nEventi con probabilit√† zero non sono impossibili: il fatto che un evento abbia probabilit√† zero non implica che non possa verificarsi.\n\n\n\n33.6.2 Il Paradosso della Probabilit√† Zero\nDa questa concezione emerge un apparente paradosso: se la probabilit√† che il QI sia esattamente 100 √® zero, come possiamo osservare un valore specifico nella realt√†? Questo problema ci conduce a due domande cruciali:\n\n√à possibile confrontare le ‚Äúpossibilit√†‚Äù di eventi diversi che hanno tutti probabilit√† zero?\nCome pu√≤ l‚Äôunione di infiniti eventi con probabilit√† zero (ogni valore specifico in un intervallo) risultare in un evento con probabilit√† certa (qualsiasi valore nell‚Äôintervallo)?\n\n\n\n33.6.3 Un‚ÄôAnalogia: Il Paradosso di Zenone\nQuesto paradosso richiama il celebre paradosso di Zenone sulla freccia: se in ogni istante la freccia √® ferma, come pu√≤ essa muoversi? In entrambi i casi, affrontiamo un‚Äôapparente contraddizione: come pu√≤ la somma di infiniti ‚Äúnulla‚Äù (probabilit√† zero o stati di immobilit√†) dare origine a ‚Äúqualcosa‚Äù (probabilit√† certa o movimento)?\nLa soluzione risiede nella teoria dell‚Äôintegrazione. La somma degli infiniti contributi infinitesimali di probabilit√† lungo un intervallo non √® ‚Äúnulla‚Äù, ma costituisce l‚Äôarea totale sotto la curva di densit√†, che rappresenta una probabilit√† positiva.\n\n\n33.6.4 La Prospettiva degli Infinitesimi\nNegli anni ‚Äô60, il matematico Abraham Robinson introdusse una teoria rigorosa degli infinitesimi, numeri infinitamente piccoli ma non nulli. Applicando questa idea alle variabili casuali continue, possiamo reinterpretare il concetto di probabilit√† zero:\n\nLa probabilit√† di un singolo valore non √® realmente zero, ma infinitesimale.\nL‚Äôunione di infiniti eventi con probabilit√† infinitesimale risulta in una probabilit√† finita e positiva, come accade per un intervallo.\n\nQuesta prospettiva consente di confrontare eventi che la teoria classica assegna a probabilit√† zero, distinguendoli in base alla loro ‚Äúgrandezza infinitesimale‚Äù.\nIn conclusione, il ‚Äúparadosso della probabilit√† zero‚Äù non √® un vero paradosso, ma piuttosto un limite delle nostre intuizioni quando affrontiamo concetti continui. La teoria moderna degli infinitesimi e l‚Äôanalisi matematica ci forniscono strumenti potenti per risolvere queste apparenti contraddizioni. Comprendendo che la probabilit√† √® distribuita in modo continuo lungo un intervallo, possiamo superare la difficolt√† concettuale di assegnare probabilit√† a eventi infinitamente piccoli, pur mantenendo coerenza con i principi fondamentali della teoria della probabilit√†.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Distribuzioni di massa e di densit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_prob_distributions.html#la-funzione-di-ripartizione-per-una-variabile-casuale-continua",
    "href": "chapters/probability/10_prob_distributions.html#la-funzione-di-ripartizione-per-una-variabile-casuale-continua",
    "title": "33¬† Distribuzioni di massa e di densit√†",
    "section": "33.7 La funzione di ripartizione per una variabile casuale continua",
    "text": "33.7 La funzione di ripartizione per una variabile casuale continua\nPer le variabili casuali continue, la funzione di ripartizione (ovvero, la distribuzione cumulativa) √® definita esattamente come nel caso delle variabili casuali discrete:\n\\[\nF_{\\Theta}(\\theta) = P(\\Theta \\leq \\theta).\n\\]\nCio√®, √® la probabilit√† che la variabile casuale \\(\\Theta\\) assuma un valore minore di o uguale a \\(\\theta\\).\nCome nel caso discreto, la funzione di ripartizione di una v.c. continua pu√≤ essere utilizzata per calcolare la probabilit√† che la v.c. assuma valori in un certo intervallo.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Distribuzioni di massa e di densit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_prob_distributions.html#interpretazioni-bayesiana-e-frequentista-della-funzione-di-densit√†-di-probabilit√†-pdf",
    "href": "chapters/probability/10_prob_distributions.html#interpretazioni-bayesiana-e-frequentista-della-funzione-di-densit√†-di-probabilit√†-pdf",
    "title": "33¬† Distribuzioni di massa e di densit√†",
    "section": "33.8 Interpretazioni Bayesiana e Frequentista della Funzione di Densit√† di Probabilit√† (PDF)",
    "text": "33.8 Interpretazioni Bayesiana e Frequentista della Funzione di Densit√† di Probabilit√† (PDF)\nIn questo capitolo, abbiamo introdotto la funzione di densit√† di probabilit√† come limite del profilo di un istogramma, una descrizione intuitiva e utile per comprendere il concetto di densit√†. Questa interpretazione corrisponde, tuttavia, alla visione frequentista della densit√† di probabilit√†. Nella statistica Bayesiana, l‚Äôinterpretazione √® diversa e merita una spiegazione separata.\nNell‚Äôapproccio Bayesiano, un parametro √® considerato una ‚Äúvariabile casuale‚Äù che segue una distribuzione di valori, anzich√© un valore fisso. La Figura¬†33.1, vedi¬†33.1 illustra le diverse interpretazioni di una PDF per una quantit√† reale \\(x\\). Queste interpretazioni valgono sia che \\(x\\) rappresenti un parametro incognito sia che si tratti di un dato osservato.\nNel pannello di sinistra, vediamo l‚Äôinterpretazione frequentista di \\(p(x)\\): la PDF rappresenta una collezione ipotetica di ripetizioni di esperimenti, in cui \\(x\\) pu√≤ assumere diversi valori. La PDF corrisponde quindi a un istogramma limite di questi valori, distribuiti secondo \\(p(x)\\).\nIl pannello di destra, invece, raffigura l‚Äôinterpretazione Bayesiana, in cui la PDF rappresenta l‚Äôincertezza sul valore di \\(x\\) per un singolo caso specifico. In questo caso, la probabilit√† si distribuisce lungo i possibili valori che \\(x\\) potrebbe assumere, visualizzata dalla sfumatura lungo l‚Äôasse \\(x\\).\nIn altre parole, nell‚Äôinterpretazione frequentista, √® il valore di \\(x\\) a essere distribuito in \\(p(x)\\) (attraverso ripetizioni dell‚Äôesperimento), mentre nell‚Äôinterpretazione Bayesiana √® la probabilit√† stessa a distribuirsi sui possibili valori di \\(x\\) nel caso analizzato. Una PDF Bayesiana pu√≤ essere vista come analoga a una densit√† di materia \\(\\rho(x)\\) in meccanica classica: √® la probabilit√† che si distribuisce lungo i possibili valori, e non i valori stessi di \\(x\\).\n\n\n\n\n\n\nFigura¬†33.1: Interpretazioni frequentista e bayesiana di una PDF (curva blu) per una quantit√† reale \\(x\\). A sinistra: interpretazione frequentista come istogramma limite dei valori di \\(x\\) nelle ripetizioni; i valori di \\(x\\) sono distribuiti secondo la PDF. A destra: interpretazione bayesiana, con \\(x\\) che assume un valore fisso ma incerto per il caso specifico (rappresentato dal punto sull‚Äôasse \\(x\\)), con la probabilit√† distribuita sui valori possibili (raffigurata con una sfumatura lungo l‚Äôasse \\(x\\)). (Figura tratta da Loredo & Wolpert, 2024)",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Distribuzioni di massa e di densit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_prob_distributions.html#riflessioni-conclusive",
    "href": "chapters/probability/10_prob_distributions.html#riflessioni-conclusive",
    "title": "33¬† Distribuzioni di massa e di densit√†",
    "section": "33.9 Riflessioni Conclusive",
    "text": "33.9 Riflessioni Conclusive\nLa funzione di densit√† di probabilit√† (PDF) √® un concetto centrale nella descrizione di variabili casuali continue, permettendo di calcolare le probabilit√† come aree sotto una curva in intervalli specifici. Questo approccio sostituisce l‚Äôidea di assegnare probabilit√† a singoli valori, un‚Äôoperazione impossibile nel contesto continuo.\nUn risultato fondamentale della PDF √® che la probabilit√† di osservare un valore esatto √® pari a zero. Questo non implica l‚Äôimpossibilit√† dell‚Äôevento, ma riflette la struttura continua della distribuzione: l‚Äôintervallo, per quanto piccolo, √® sempre necessario per assegnare una probabilit√† positiva. Ad esempio, possiamo calcolare la probabilit√† che una variabile sia compresa tra 95 e 105, ma non esattamente uguale a 100.\n\n33.9.1 Implicazioni e Interpretazioni\n\nProbabilit√† per intervalli: La PDF permette di quantificare la probabilit√† in termini di intervalli, superando i limiti del calcolo sui singoli valori.\nApparenti paradossi: L‚Äôapparente paradosso della probabilit√† zero ‚Äì come l‚Äôunione di infiniti punti con probabilit√† zero possa generare un evento certo ‚Äì viene risolto comprendendo che tali probabilit√† si riferiscono alla somma delle aree infinitesimali sotto la curva.\n\n\n\n33.9.2 Riflessione Filosofica: Dal ‚ÄúNulla‚Äù al ‚ÄúQualcosa‚Äù\nIl problema della probabilit√† zero ricorda il paradosso di Zenone sulla freccia: se la freccia √® ferma in ogni istante, come pu√≤ muoversi? Allo stesso modo, la somma di infiniti punti con probabilit√† zero pu√≤ produrre una probabilit√† totale positiva. La soluzione risiede nella teoria dell‚Äôintegrazione: la somma di contributi infinitesimali lungo un intervallo costruisce la probabilit√† complessiva.\n\n\n33.9.3 Nuove Prospettive: Gli Infinitesimi\nUna visione alternativa √® offerta dalla teoria degli infinitesimi di Abraham Robinson, che reinterpreta gli eventi con probabilit√† zero come aventi una probabilit√† infinitesimale, non nulla. Questa teoria distingue tra eventi con diversa ‚Äúgrandezza infinitesimale‚Äù e chiarisce come l‚Äôunione di infiniti eventi infinitesimali possa produrre una probabilit√† totale unitaria.\n\n\n33.9.4 Conclusione\nLa PDF non √® solo uno strumento matematico, ma anche un ponte concettuale che collega il finito all‚Äôinfinito e il discreto al continuo. Comprendere questi concetti aiuta non solo a risolvere problemi tecnici, ma anche a sviluppare un‚Äôintuizione pi√π profonda sulle strutture sottostanti alla probabilit√† e alla matematica continua.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Distribuzioni di massa e di densit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_prob_distributions.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/10_prob_distributions.html#informazioni-sullambiente-di-sviluppo",
    "title": "33¬† Distribuzioni di massa e di densit√†",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: US/Pacific\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] ggokabeito_0.1.0 see_0.9.0        gridExtra_2.3    patchwork_1.3.0 \n#&gt;  [5] bayesplot_1.11.1 psych_2.4.12     scales_1.3.0     markdown_1.13   \n#&gt;  [9] knitr_1.49       lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1   \n#&gt; [13] dplyr_1.1.4      purrr_1.0.2      readr_2.1.5      tidyr_1.3.1     \n#&gt; [17] tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3       \n#&gt; [21] here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.3         rlang_1.1.4       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       yaml_2.3.10       tools_4.4.2       parallel_4.4.2   \n#&gt; [21] tzdb_0.4.0        colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5      \n#&gt; [25] R6_2.5.1          lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3  \n#&gt; [29] pillar_1.10.1     gtable_0.3.6      glue_1.8.0        xfun_0.50        \n#&gt; [33] tidyselect_1.2.1  farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-166     \n#&gt; [37] labeling_0.4.3    rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Distribuzioni di massa e di densit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_prob_distributions.html#bibliografia",
    "href": "chapters/probability/10_prob_distributions.html#bibliografia",
    "title": "33¬† Distribuzioni di massa e di densit√†",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlitzstein, J. K., & Hwang, J. (2019). Introduction to probability. CRC Press.\n\n\nLoredo, T. J., & Wolpert, R. L. (2024). Bayesian inference: more than Bayes‚Äôs theorem. Frontiers in Astronomy and Space Sciences, 11, 1326926.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Distribuzioni di massa e di densit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html",
    "href": "chapters/probability/11_discr_rv_distr.html",
    "title": "34¬† Distribuzioni di v.c. discrete",
    "section": "",
    "text": "34.1 Introduzione\n√à importante distinguere tra variabili casuali discrete e continue, perch√© le distribuzioni di probabilit√† associate sono molto diverse nei due casi.\nIn questo capitolo ci focalizzeremo sulle distribuzioni di probabilit√† discrete, strumenti fondamentali per modellare fenomeni aleatori che generano un numero finito o numerabile di possibili esiti. Queste distribuzioni risultano particolarmente efficaci per descrivere eventi che si verificano in contesti discreti, come il numero di successi in un esperimento, l‚Äôoccorrenza di un evento, o la selezione casuale da un insieme di opzioni finite. Di seguito, presentiamo una panoramica delle distribuzioni che verranno trattate.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#introduzione",
    "href": "chapters/probability/11_discr_rv_distr.html#introduzione",
    "title": "34¬† Distribuzioni di v.c. discrete",
    "section": "",
    "text": "Distribuzione di Bernoulli\n\n\nDescrizione: Modella esperimenti con due soli possibili esiti, spesso denominati ‚Äúsuccesso‚Äù e ‚Äúfallimento‚Äù.\nApplicazioni: Processi che coinvolgono eventi binari, come l‚Äôesito di una moneta lanciata o la risposta a una domanda dicotomica.\nParametro: La probabilit√† di successo (\\(p\\)).\nImportanza: Costituisce la base teorica per molte altre distribuzioni discrete.\n\n\n\nDistribuzione Binomiale\n\n\nDescrizione: Descrive il numero totale di successi in un numero fisso di prove Bernoulliane indipendenti.\nApplicazioni: Esperimenti che coinvolgono ripetizioni di un processo binario, come il numero di voti favorevoli in un gruppo o il numero di sintomi in un campione di pazienti.\nParametri: Probabilit√† di successo (\\(p\\)) e numero di prove (\\(n\\)).\nImportanza: Modella fenomeni ripetuti in condizioni identiche, fornendo una struttura per analisi probabilistiche pi√π complesse.\n\n\n\nDistribuzione di Poisson\n\n\nDescrizione: Modella il numero di eventi che si verificano in un intervallo fisso di tempo o spazio, quando tali eventi sono rari e indipendenti.\nApplicazioni: Il numero di episodi di ansia acuta riportati da un individuo in un periodo di una settimana; il numero di interazioni sociali spontanee di un bambino con un disturbo dello spettro autistico durante una sessione di osservazione; la frequenza di lapsus verbali durante una presentazione pubblica; il numero di sogni vividi riportati durante una serie di notti consecutive in uno studio sul sonno.\nParametro: Il tasso medio di eventi per unit√† di tempo o spazio (\\(\\lambda\\)).\nImportanza: √à cruciale per analizzare processi psicologici o comportamentali rari ma importanti, permettendo di comprendere i meccanismi sottostanti e di modellare la variabilit√† osservata in contesti clinici, sperimentali o quotidiani.\n\n\n\nDistribuzione Uniforme Discreta\n\n\nDescrizione: Ogni evento ha la stessa probabilit√† di verificarsi, all‚Äôinterno di un intervallo discreto finito.\nApplicazioni: La scelta casuale di uno stimolo da una lista di parole equiprobabili in un esperimento di memoria; l‚Äôassegnazione casuale di partecipanti a gruppi sperimentali in uno studio di psicologia sociale. La selezione casuale di un‚Äôimmagine tra un insieme di stimoli visivi utilizzati in una ricerca sull‚Äôattenzione; la probabilit√† uniforme che un partecipante scelga una delle opzioni in un questionario a risposte multiple quando non ha preferenze o conoscenze specifiche.\nParametri: L‚Äôintervallo di supporto della distribuzione, ad esempio il numero totale di opzioni disponibili o di stimoli tra cui scegliere.\nImportanza: √à utile come modello di riferimento in situazioni in cui si assume che i partecipanti non abbiano preferenze o che l‚Äôincertezza sia massima. Questo tipo di distribuzione aiuta a comprendere il comportamento casuale e a definire un punto di partenza per analisi pi√π complesse.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#distribuzioni-in-r",
    "href": "chapters/probability/11_discr_rv_distr.html#distribuzioni-in-r",
    "title": "34¬† Distribuzioni di v.c. discrete",
    "section": "34.2 Distribuzioni in R",
    "text": "34.2 Distribuzioni in R\nIn R, per ogni distribuzione sono disponibili quattro funzioni principali, i cui nomi iniziano con le lettere:\n\nd (density): per calcolare i valori teorici relativi alla distribuzione,\n\np (probability): per ottenere la probabilit√† cumulativa,\n\nq (quantile): per determinare i quantili,\n\nr (random): per generare campioni casuali.\n\nIl pacchetto di base stats include numerose funzioni dedicate alle principali distribuzioni statistiche, permettendo di calcolare valori teorici e simulare dati in modo semplice e flessibile. Per ulteriori dettagli sulle distribuzioni disponibili e sull‚Äôuso delle relative funzioni, √® possibile consultare la documentazione con il comando ?Distributions.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#distribuzione-di-bernoulli",
    "href": "chapters/probability/11_discr_rv_distr.html#distribuzione-di-bernoulli",
    "title": "34¬† Distribuzioni di v.c. discrete",
    "section": "34.3 Distribuzione di Bernoulli",
    "text": "34.3 Distribuzione di Bernoulli\nIn statistica, un esperimento che ammette solo due esiti possibili √® modellato attraverso quella che viene chiamata ‚Äúprova Bernoulliana‚Äù. Un esempio tipico √® il lancio di una moneta, che pu√≤ dare come risultato testa o croce.\n\nDefinizione 34.1 Una variabile casuale \\(X\\) che assume valori in \\(\\{0, 1\\}\\) √® detta variabile di Bernoulli. La sua distribuzione di probabilit√† √® definita come:\n\\[\nP(X \\mid \\theta) =\n  \\begin{cases}\n    p     & \\text{se $X = 1$ (successo)}, \\\\\n    1 - p & \\text{se $X = 0$ (insuccesso)},\n  \\end{cases}\n\\]\ndove \\(0 \\leq p \\leq 1\\). Il parametro \\(p\\) rappresenta la probabilit√† del ‚Äúsuccesso‚Äù (\\(X = 1\\)), mentre \\(1 - p\\) √® la probabilit√† dell‚Äô‚Äúinsuccesso‚Äù (\\(X = 0\\)).\n\nLa distribuzione di Bernoulli descrive quindi un contesto in cui la probabilit√† di osservare l‚Äôesito 1 √® \\(p\\) e quella di osservare l‚Äôesito 0 √® \\(1 - p\\). Viene utilizzata per modellare situazioni binarie, come una risposta ‚Äús√¨‚Äù o ‚Äúno‚Äù, oppure un ‚Äúsuccesso‚Äù o ‚Äúinsuccesso‚Äù.\nCalcolando il valore atteso e la varianza, otteniamo:\n\\[\n\\begin{align}\n\\mathbb{E}(X) &= 0 \\cdot P(X=0) + 1 \\cdot P(X=1) = p, \\\\\n\\mathbb{V}(X) &= (0 - p)^2 \\cdot P(X=0) + (1 - p)^2 \\cdot P(X=1) = p(1-p).\n\\end{align}\n\\tag{34.1}\\]\n\n\n\n\n\n\nDimostrazione\n\n\n\nEsaminiamo la dimostrazione algebrica del calcolo della varianza.\nEspandiamo il calcolo della somma, considerando i due possibili valori di \\(X\\) (0 e 1).\n\nPrimo termine (\\(X = 0\\)):\n\\[\n(0 - \\mathbb{E}(X))^2 \\cdot P(X = 0) = (0 - p)^2 \\cdot (1 - p).\n\\]\nSemplificando \\((0 - p)^2 = p^2\\), quindi:\n\\[\n(0 - \\mathbb{E}(X))^2 \\cdot P(X = 0) = p^2 \\cdot (1 - p).\n\\]\nSecondo termine (\\(X = 1\\)):\n\\[\n(1 - \\mathbb{E}(X))^2 \\cdot P(X = 1) = (1 - p)^2 \\cdot p.\n\\]\nSemplificando \\((1 - p)^2 = 1 - 2p + p^2\\), quindi:\n\\[\n(1 - \\mathbb{E}(X))^2 \\cdot P(X = 1) = (1 - 2p + p^2) \\cdot p = p - 2p^2 + p^3.\n\\]\nSomma dei termini\nOra sommiamo i due contributi:\n\\[\n\\mathbb{V}(X) = p^2 \\cdot (1 - p) + (p - 2p^2 + p^3).\n\\]\nEspandendo il primo termine:\n\\[\np^2 \\cdot (1 - p) = p^2 - p^3.\n\\]\nSomma completa:\n\\[\n\\mathbb{V}(X) = (p^2 - p^3) + (p - 2p^2 + p^3).\n\\]\nRaggruppiamo i termini\n\\[\n\\mathbb{V}(X) = p - p^2.\n\\]\nRisultato finale:\n\\[\n\\mathbb{V}(X) = p(1 - p).\n\\]\n\nIn sintesi, la varianza di una variabile aleatoria binaria \\(X\\), distribuita secondo Bernoulli con parametro \\(p\\), √® data da \\(p(1-p)\\).\n\n\nTale risultato mostra come la varianza massima si ottenga per \\(p = 0.5\\), condizione che corrisponde alla massima incertezza intrinseca nel processo, ossia quando la probabilit√† di successo eguaglia quella di insuccesso.\n\n# Valori di p tra 0 e 1\np &lt;- seq(0, 1, length.out = 100)\nvariance &lt;- p * (1 - p)\ndata &lt;- data.frame(p = p, Variance = variance)\n\n# Creazione del grafico\nggplot(data, aes(x = p, y = Variance)) +\n  geom_line(color = \"blue\", linewidth = 1.2) +\n  labs(\n    x = expression(p),\n    y = \"Varianza\",\n    title = \"Varianza di una Variabile Bernoulliana in funzione di p\"\n  )\n\n\n\n\n\n\n\n\n\n34.3.1 Notazione\nPer indicare che la variabile casuale \\(X\\) segue una distribuzione Bernoulliana di parametro \\(p\\) Utilizziamo la notazione \\(X \\sim \\mathcal{Bern}(p)\\), o in maniera equivalente \\(\\mathcal{Bern}(X \\mid p)\\).\n\nEsempio 34.1 Nel caso del lancio di una moneta equilibrata, la variabile di Bernoulli assume i valori \\(0\\) e \\(1\\) con uguale probabilit√† di \\(\\frac{1}{2}\\). Pertanto, la funzione di massa di probabilit√† assegna una probabilit√† di \\(\\frac{1}{2}\\) sia per \\(X = 0\\) che per \\(X = 1\\), mentre la funzione di distribuzione cumulativa risulta essere \\(\\frac{1}{2}\\) per \\(X = 0\\) e \\(1\\) per \\(X = 1\\).\nGeneriamo dei valori casuali dalla distribuzione di Bernoulli. Iniziamo con un singolo valore:\n\n# Probabilit√† di successo\np &lt;- 0.5\n\n# Genera un singolo valore\nbernoulli_sample &lt;- rbinom(n = 1, size = 1, prob = p)\nprint(bernoulli_sample)\n#&gt; [1] 1\n\n# Genera un campione di 10 valori\nbernoulli_sample &lt;- rbinom(n = 10, size = 1, prob = p)\nprint(bernoulli_sample)\n#&gt;  [1] 1 0 1 1 1 1 0 1 1 0",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#distribuzione-binomiale",
    "href": "chapters/probability/11_discr_rv_distr.html#distribuzione-binomiale",
    "title": "34¬† Distribuzioni di v.c. discrete",
    "section": "34.4 Distribuzione Binomiale",
    "text": "34.4 Distribuzione Binomiale\nLa distribuzione binomiale √® una distribuzione di probabilit√† discreta che modella il numero di successi \\(y\\) in un numero fissato \\(n\\) di prove di Bernoulli indipendenti e identiche, dove ciascuna prova ha solo due esiti possibili: ‚Äúsuccesso‚Äù (rappresentato da ‚Äú1‚Äù) con probabilit√† \\(p\\) o ‚Äúinsuccesso‚Äù (rappresentato da ‚Äú0‚Äù) con probabilit√† \\(1 - p\\). La notazione utilizzata √® la seguente:\n\\[\nY \\sim \\mathcal{Binom}(n, p).\n\\]\n\nDefinizione 34.2 La distribuzione binomiale descrive la probabilit√† di osservare esattamente \\(y\\) successi in \\(n\\) prove di Bernoulli indipendenti:\n\\[\nP(Y = y) = \\binom{n}{y} p^{y} (1 - p)^{n - y} = \\frac{n!}{y!(n - y)!} p^{y} (1 - p)^{n - y},\n\\tag{34.2}\\]\ndove \\(\\binom{n}{y}\\), noto come coefficiente binomiale, rappresenta il numero di modi possibili per ottenere \\(y\\) successi in \\(n\\) prove, e \\(p\\) √® la probabilit√† di successo in ciascuna prova.\n\nLa distribuzione binomiale si presta bene a esempi classici come il lancio ripetuto di una moneta o l‚Äôestrazione di biglie da un‚Äôurna. Ad esempio, nel caso del lancio di una moneta, questa distribuzione descrive la probabilit√† di ottenere un determinato numero di ‚Äúteste‚Äù in un certo numero di lanci, con ogni lancio che segue una distribuzione di Bernoulli con probabilit√† di successo \\(p\\).\nUna caratteristica interessante della distribuzione binomiale √® la sua propriet√† di riproducibilit√†: se due variabili casuali indipendenti, \\(y_1\\) e \\(y_2\\), seguono entrambe distribuzioni binomiali con lo stesso parametro \\(p\\), ma con un diverso numero di prove (\\(n_1\\) e \\(n_2\\)), la loro somma, \\(y = y_1 + y_2\\), sar√† ancora distribuita binomialmente, con parametri \\(n_1 + n_2\\) e \\(p\\).\n\n34.4.1 Calcolo delle Probabilit√†\nPer chiarire il calcolo delle probabilit√† nella distribuzione binomiale, consideriamo una serie di prove di Bernoulli. Supponiamo di avere \\(n\\) prove, con \\(y\\) successi. La configurazione di questi risultati pu√≤ essere rappresentata come:\n\\[\n\\overbrace{SS\\dots S}^\\text{$y$ successi} \\overbrace{II\\dots I}^\\text{$n - y$ insuccessi}\n\\]\nLa probabilit√† di ottenere esattamente \\(y\\) successi in una sequenza specifica di prove √® pari a:\n\\[\np^y \\cdot (1 - p)^{n - y},\n\\]\ndove \\(p^y\\) √® la probabilit√† di ottenere \\(y\\) successi, e \\((1 - p)^{n - y}\\) √® la probabilit√† di ottenere \\(n - y\\) insuccessi.\nTuttavia, siamo interessati alla probabilit√† complessiva di ottenere esattamente \\(y\\) successi in qualsiasi ordine. Il numero di modi in cui ci√≤ pu√≤ avvenire √® dato dal coefficiente binomiale \\(\\binom{n}{y}\\), che rappresenta tutte le possibili disposizioni dei successi e degli insuccessi nelle \\(n\\) prove.\nQuindi, moltiplicando la probabilit√† di una singola sequenza per il numero di sequenze possibili, otteniamo la probabilit√† di osservare esattamente \\(y\\) successi:\n\\[\nP(Y = y) = \\binom{n}{y} p^y (1 - p)^{n - y}.\n\\]\nQuesto risultato corrisponde alla formula della distribuzione binomiale.\n\n\n34.4.2 Caso particolare \\(n = 1\\)\nOra consideriamo il caso particolare in cui \\(n = 1\\). Quando \\(n = 1\\), il coefficiente binomiale diventa:\n\\[\n\\binom{1}{k} = \\frac{1!}{k! (1-k)!}.\n\\]\nEspandiamo i fattoriali per i due possibili valori di \\(k\\), che pu√≤ assumere solo 0 o 1 (poich√© \\(k \\in \\{0, 1, \\dots, n\\}\\)).\nCaso 1: \\(k = 0\\)\n\\[\n\\binom{1}{0} = \\frac{1!}{0! (1-0)!} = \\frac{1}{1 \\cdot 1} = 1.\n\\]\nQuindi, per \\(k = 0\\): \\[\nP(X = 0) = \\binom{1}{0} p^0 (1-p)^{1-0} = 1 \\cdot 1 \\cdot (1-p) = 1-p.\n\\]\nCaso 2: \\(k = 1\\)\n\\[\n\\binom{1}{1} = \\frac{1!}{1! (1-1)!} = \\frac{1}{1 \\cdot 1} = 1.\n\\]\nQuindi, per \\(k = 1\\): \\[\nP(X = 1) = \\binom{1}{1} p^1 (1-p)^{1-1} = 1 \\cdot p \\cdot 1 = p.\n\\]\nIn conclusione, la PMF per la distribuzione binomiale con \\(n = 1\\) diventa:\n\\[\nP(X = k) =\n\\begin{cases}\n1-p, & \\text{se } k = 0, \\\\\np, & \\text{se } k = 1.\n\\end{cases}\n\\]\nQuesta √® esattamente la PMF della distribuzione di Bernoulli con parametro \\(p\\):\n\\[\nP(X = x) = p^x (1-p)^{1-x}, \\quad x \\in \\{0, 1\\}.\n\\]\nPertanto, la distribuzione binomiale con \\(n = 1\\) √® equivalente alla distribuzione di Bernoulli con parametro \\(p\\).\n\n\n34.4.3 Applicazioni Pratiche della Distribuzione Binomiale\nConsideriamo un esempio pratico per illustrare l‚Äôapplicazione della distribuzione binomiale. Supponiamo di osservare 2 successi in 4 prove Bernoulliane, dove la probabilit√† di successo in ogni prova √® \\(p = 0.2\\). La probabilit√† di ottenere questo risultato specifico √® calcolata utilizzando l‚Äôeq. {eq}eq-binom-distr:\n\\[\nP(Y=2) = \\frac{4!}{2!(4-2)!} \\cdot 0.2^{2} \\cdot (1-0.2)^{4-2} = 0.1536.\n\\]\nQuesto calcolo pu√≤ essere replicato in Python. Utilizzando il modulo math, possiamo calcolare direttamente:\n\n# Parametri\nn &lt;- 4\np &lt;- 0.2\ny &lt;- 2\n\n# Probabilit√† di ottenere esattamente y successi\nprob &lt;- choose(n, y) * p^y * (1 - p)^(n - y)\nprint(prob)\n#&gt; [1] 0.154\n\nIn alternativa, possiamo sfruttare la libreria SciPy per eseguire calcoli analoghi. SciPy offre una vasta gamma di funzioni per la gestione delle distribuzioni statistiche, tra cui la distribuzione binomiale.\n\n# Probabilit√† di ottenere esattamente y successi\nprob &lt;- choose(n, y) * p^y * (1 - p)^(n - y)\nprint(prob)\n#&gt; [1] 0.154\n\nUtilizzando dbinom(y, n, p), possiamo trovare le probabilit√† per ogni possibile valore \\(y\\) in una distribuzione binomiale di parametri \\(n = 4\\) e \\(\\theta = 0.2\\):\n\n# Usando la funzione dbinom\nprob &lt;- dbinom(x = y, size = n, prob = p)\nprint(prob)\n#&gt; [1] 0.154\n\nVisualizziamo la distribuzione di massa di probabilit√†:\n\ny &lt;- 0:n  # Numero di successi\nprobabilities &lt;- dbinom(y, size = n, prob = p)  # Probabilit√† associate\n\n# Preparare i dati in un data frame\ndf &lt;- data.frame(Successi = y, Probabilit√† = probabilities)\n\ndf |&gt; \n  ggplot(aes(x = Successi, y = Probabilit√†)) +\n    geom_segment(aes(xend = Successi, yend = 0), lwd = 1.2, color = \"blue\") +\n    geom_point(size = 3, color = \"blue\") +\n    labs(\n      x = \"Numero di Successi y\",\n      y = \"Probabilit√†\",\n      title = paste(\"Distribuzione Binomiale: n =\", n, \", p =\", p)\n  )\n\n\n\n\n\n\n\n\nUn campione casuale si ottiene con rbinom():\n\nset.seed(42)\nsamples &lt;- rbinom(n = 30, size = 5, prob = 0.5)\nprint(samples)\n#&gt;  [1] 4 4 2 4 3 3 3 1 3 3 2 3 4 2 2 4 5 1 2 3 4 1 5 4 1 3 2 4 2 4\n\nPer esplorare ulteriormente, consideriamo la distribuzione di probabilit√† di diverse distribuzioni binomiali per due valori di \\(n\\) e \\(\\theta\\). La seguente visualizzazione mostra come cambia la distribuzione al variare di \\(\\theta\\):\n\n# Parametri\nn &lt;- 20\np_values &lt;- seq(0.3, 0.9, by = 0.3) # Valori di probabilit√†\ny &lt;- 0:25 # Numero di successi\n\n# Creazione di un data frame per tutte le distribuzioni\ndf &lt;- data.frame()\n\nfor (p in p_values) {\n  binom_dist &lt;- dbinom(y, size = n, prob = p)\n  df &lt;- rbind(df, data.frame(y = y, Prob = binom_dist, p = factor(p)))\n}\n\n# Grafico con ggplot2\ndf |&gt; \n  ggplot(aes(x = y, y = Prob, color = p)) +\n    geom_point() +\n    geom_line() +\n    labs(\n      x = \"Numero di successi y\", \n      y = \"Probabilit√†\",\n      title = \"Distribuzione binomiale al variare di p\",\n      color = expression(theta)\n  )\n\n\n\n\n\n\n\n\nConsideriamo un altro esempio. Lanciando \\(5\\) volte una moneta onesta, qual √® la probabilit√† che esca testa almeno due volte? Troviamo la soluzione usando stats.binom.pmf().\n\n# Calcolo della somma delle probabilit√†\nresult &lt;- dbinom(2, size = 5, prob = 0.5) +\n          dbinom(3, size = 5, prob = 0.5) +\n          dbinom(4, size = 5, prob = 0.5) +\n          dbinom(5, size = 5, prob = 0.5)\n\nprint(result)\n#&gt; [1] 0.812\n\nOppure, in modo pi√π compatto:\n\n# Valori di interesse\nresult &lt;- sum(dbinom(2:5, size = 5, prob = 0.5))\nprint(result)\n#&gt; [1] 0.812\n\nRappresentiamo graficamente la funzione di ripartizione per una Binomiale di ordine \\(n\\) = 5 e \\(\\theta\\) = 0.5.\n\n# Parametri\nn &lt;- 5\np &lt;- 0.5\ny &lt;- 0:n\n\n# Calcolo della funzione di ripartizione cumulativa\ncdf_values &lt;- pbinom(y, size = n, prob = p)\n\n# Creazione del data frame per ggplot2\ndf &lt;- data.frame(y = y, cdf = cdf_values)\n\n# Grafico\ndf |&gt; \n  ggplot(aes(x = y, y = cdf)) +\n    geom_line() +\n    geom_point() +\n    geom_hline(yintercept = 1, color = \"black\", alpha = 0.7, linetype = \"dashed\") +\n    labs(\n      title = paste(\"Funzione di ripartizione binomiale: n =\", n, \", p =\", p),\n      x = \"y\",\n      y = \"Probabilit√†\"\n    )\n\n\n\n\n\n\n\n\nUn‚Äôaltra funzione utile √® quella che permette di trovare il numero di successi associato a una data probabilit√† cumulativa nella coda sinistra di una distribuzione binomiale. Questo si ottiene utilizzando la funzione qbinom, che rappresenta l‚Äôinversa della funzione di distribuzione cumulativa (CDF).\nAd esempio, consideriamo una distribuzione binomiale con \\(n = 5\\) prove e probabilit√† di successo \\(p = 0.5\\). Supponiamo di voler calcolare il numero minimo di successi per cui la probabilit√† cumulativa √® almeno \\(1 - 0.8125 = 0.1875\\). Possiamo farlo nel seguente modo:\n\n# Probabilit√† target\ntarget_probability &lt;- 1 - 0.8125\n\n# Numero di successi corrispondente alla probabilit√† target\nresult &lt;- qbinom(target_probability, size = 5, prob = 0.5)\n\nprint(result)\n#&gt; [1] 1\n\nIn questo esempio, il valore restituito √® \\(1\\), che indica che almeno 1 successo soddisfa la condizione di una probabilit√† cumulativa di \\(0.1875\\).\n\n\n34.4.4 Altro esempio\nConsideriamo ora una distribuzione binomiale con \\(n = 10\\) prove e probabilit√† di successo \\(p = 0.2\\). Per calcolare la probabilit√† cumulativa \\(P(Y \\leq 4)\\), ovvero la probabilit√† di ottenere al massimo 4 successi su 10 tentativi, possiamo utilizzare la funzione pbinom:\n\n# Calcolo della probabilit√† cumulativa\ntarget_probability &lt;- pbinom(4, size = 10, prob = 0.2)\nprint(target_probability)\n#&gt; [1] 0.967\n\nIl risultato rappresenta la probabilit√† cumulativa associata a 4 o meno successi.\nSe invece vogliamo determinare il numero di successi corrispondente a questa probabilit√† cumulativa, possiamo utilizzare la funzione inversa qbinom:\n\n# Calcolo del numero di successi associato alla probabilit√† cumulativa\nresult &lt;- qbinom(target_probability, size = 10, prob = 0.2)\nprint(result)\n#&gt; [1] 4\n\nIn questo caso, il valore restituito rappresenta il numero massimo di successi \\(Y\\) per cui la probabilit√† cumulativa √® uguale o inferiore a \\(target\\_probability\\). Questo √® particolarmente utile per interpretare i risultati di una distribuzione binomiale in termini di successi associati a determinate probabilit√† cumulative.\n\n\n34.4.5 Valore atteso e deviazione standard\nLa media (numero atteso di successi in \\(n\\) prove) e la deviazione standard di una distribuzione binomiale si calcolano nel seguente modo:\n\\[\n\\begin{align}\n\\mu    &= np,  \\notag \\\\\n\\sigma &= \\sqrt{np(1-p)}.\n\\end{align}\n\\tag{34.3}\\]\nDimostrazione. Dato che \\(Y\\) rappresenta la somma di \\(n\\) prove di Bernoulli indipendenti \\(Y_i\\), possiamo scrivere:\n\\[\n\\begin{align}\n\\mathbb{E}(Y) &= \\mathbb{E}\\left( \\sum_{i=1}^n Y_i \\right) = \\sum_{i=1}^n \\mathbb{E}(Y_i) = np, \\\\\n\\mathbb{V}(Y) &= \\mathbb{V} \\left( \\sum_{i=1}^n Y_i \\right) = \\sum_{i=1}^n \\mathbb{V}(Y_i) = np(1-p).\n\\end{align}\n\\]\nPertanto, la deviazione standard √® data da \\(\\sigma = \\sqrt{np(1-p)}\\).\nPer esempio, prendiamo in considerazione il caso di un esperimento in cui vengono lanciate quattro monete, ciascuna con una probabilit√† di ottenere testa (successo) pari a \\(p = 0.2\\). Calcoliamo il valore atteso e la varianza per questo esperimento.\nIl valore atteso, \\(\\mu\\), rappresenta il numero medio di teste che ci aspettiamo di ottenere in ciascun lancio. Per la distribuzione binomiale, questo √® dato da \\(\\mu = n p\\), dove \\(n\\) √® il numero di prove (lanci di monete). Nel nostro caso, con \\(n = 4\\) e \\(p = 0.2\\), abbiamo:\n\\[\n\\mu = n p = 4 \\times 0.2 = 0.8.\n\\]\nQuesto significa che, in media, ci aspettiamo di ottenere circa 0.8 teste per ogni serie di quattro lanci.\nPer quanto riguarda la varianza, che misura quanto i risultati individuali tendono a differire dalla media, nella distribuzione binomiale √® calcolata come \\(n p (1-p)\\). Pertanto, per il nostro esperimento:\n\\[\n\\text{Varianza} = n p (1-p) = 4 \\times 0.2 \\times (1 - 0.2) = 0.64.\n\\]\nLa varianza di 0.64 suggerisce una certa dispersione intorno al valore medio di 0.8 teste.\nPer confermare queste aspettative teoriche, possiamo eseguire una simulazione. Creiamo una serie di esperimenti simulati in cui lanciamo quattro monete per un gran numero di volte, registrando il numero di teste ottenute in ogni serie. Calcoliamo poi la media e la varianza dei risultati ottenuti per vedere quanto si avvicinano ai valori teorici calcolati.\n\nset.seed(42)\n\n# Genera un campione di 1.000.000 di valori dalla distribuzione binomiale\nx &lt;- rbinom(n = 1000000, size = 4, prob = 0.2)\n\n\nmean(x)\n#&gt; [1] 0.8\n\n\nvar(x)\n#&gt; [1] 0.639\n\n\n\n34.4.6 Funzioni R associate alle distribuzioni di probabilit√†\nLa seguente tabella riassume le funzioni di R utilizzate per manipolare le distribuzioni di probabilit√†, illustrando i casi della distribuzione Binomiale e della Normale.\n\n\n\n\n\n\n\n\nTipo\nEsempio: Binomiale (\\(y \\mid n, p\\))\nEsempio: Normale (\\(y \\mid \\mu, \\sigma\\))\n\n\n\n\nFunzione di verosimiglianza\ndbinom(y, size = n, prob = p)\ndnorm(y, mean = Œº, sd = œÉ)\n\n\nProb \\(Y = y\\)\ndbinom(y, size = n, prob = p)\nNon definita (variabili continue hanno pdf, non pmf)\n\n\nProb \\(Y \\geq y, Y \\leq y, y_1 &lt; Y &lt; y_2\\)\npbinom(y, size = n, prob = p) o 1 - pbinom(y - 1, ...)\npnorm(y, mean = Œº, sd = œÉ) o 1 - pnorm(y, ...)\n\n\nInversa della CDF\nqbinom(q, size = n, prob = p)\nqnorm(q, mean = Œº, sd = œÉ)\n\n\nGenerazione di dati simulati\nrbinom(n, size = trials, prob = p)\nrnorm(n, mean = Œº, sd = œÉ)\n\n\n\nIn seguito, useremo altre distribuzioni come Uniforme, Beta, ecc., ognuna delle quali ha un proprio insieme di funzioni disponibili in R. La sintassi segue uno schema generale comune:\n\nd*: Calcola la funzione di densit√† di probabilit√† (per distribuzioni continue) o di massa (per distribuzioni discrete). Esempi: dbinom, dnorm.\np*: Calcola la funzione di ripartizione cumulativa (CDF). Esempi: pbinom, pnorm.\nq*: Calcola l‚Äôinversa della funzione di ripartizione cumulativa (quantile function). Esempi: qbinom, qnorm.\nr*: Genera campioni casuali secondo una determinata distribuzione. Esempi: rbinom, rnorm.\n\n\nEsercizio 34.1 ¬†\n\nCalcolare la probabilit√† di esattamente \\(y = 3\\) successi su \\(n = 5\\) prove con \\(p = 0.5\\):\n\n\ndbinom(3, size = 5, prob = 0.5)\n#&gt; [1] 0.312\n\n\nCalcolare la probabilit√† cumulativa \\(P(Y \\leq 3)\\):\n\n\npbinom(3, size = 5, prob = 0.5)\n#&gt; [1] 0.812\n\n\nCalcolare il valore minimo \\(y\\) tale che \\(P(Y \\leq y) \\geq 0.9\\):\n\n\nqbinom(0.9, size = 5, prob = 0.5)\n#&gt; [1] 4\n\n\nGenerare un campione di 100 numeri casuali da una distribuzione binomiale:\n\n\nrbinom(100, size = 5, prob = 0.5)\n#&gt;   [1] 2 2 4 1 3 2 3 2 2 2 3 3 3 3 1 4 1 1 0 2 2 2 4 1 2 3 3 1 5 2 3 3 0 3 2\n#&gt;  [36] 3 4 2 3 3 3 3 1 5 3 3 2 3 1 2 1 3 3 2 2 4 1 4 2 3 1 4 2 2 3 4 1 1 4 2\n#&gt;  [71] 3 2 3 3 3 1 4 4 3 3 4 3 3 3 2 2 3 3 2 4 4 3 2 2 0 3 1 3 1 2",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#distribuzione-discreta-uniforme",
    "href": "chapters/probability/11_discr_rv_distr.html#distribuzione-discreta-uniforme",
    "title": "34¬† Distribuzioni di v.c. discrete",
    "section": "34.5 Distribuzione Discreta Uniforme",
    "text": "34.5 Distribuzione Discreta Uniforme\nLa distribuzione discreta uniforme √® un tipo particolare di distribuzione di probabilit√†, dove ogni risultato in un insieme finito e discreto \\(S\\) ha la stessa probabilit√† \\(p\\) di verificarsi. Questa distribuzione √® caratterizzata dalla sua semplicit√† e dalla sua propriet√† fondamentale di equiprobabilit√†.\nConsideriamo un esempio pratico con una variabile casuale discreta \\(X\\), che pu√≤ assumere valori nell‚Äôinsieme \\(\\{1, 2, \\dots, N\\}\\). Un‚Äôistanza classica di questa distribuzione si verifica quando si sceglie casualmente un numero intero tra 1 e \\(N\\), inclusi. Se \\(X\\) rappresenta il numero selezionato, allora la somma delle probabilit√† di tutti i possibili valori di \\(X\\) deve totalizzare 1, come indicato dalla formula di normalizzazione:\n\\[\n\\sum_{i=1}^N P(X_i) = Np = 1.\n\\]\nDi conseguenza, la probabilit√† che \\(X\\) assuma un valore specifico \\(x\\) √® uniformemente distribuita:\n\\[\nP(X = x) = \\frac{1}{N},\n\\]\nindicando che ogni evento ha la stessa probabilit√† di verificarsi.\nIl valore atteso, o la media, di \\(X\\) ci d√† un‚Äôidea del risultato medio atteso e si calcola come:\n\\[\n\\mathbb{E}(X) = \\sum_{x=1}^N x \\cdot \\frac{1}{N} = \\frac{1}{N} \\cdot \\sum_{x=1}^N x.\n\\]\nA questo punto, dobbiamo calcolare la somma \\(\\sum_{x=1}^{N} x\\), che √® la somma dei primi \\(N\\) numeri naturali. Questa somma √® data dalla formula:\n\\[\n\\sum_{x=1}^{N} x = \\frac{N(N + 1)}{2}.\n\\]\nSostituendo questa formula nel nostro calcolo del valore atteso, otteniamo:\n\\[\n\\mathbb{E}(X) = \\frac{1}{N} \\cdot \\frac{N(N + 1)}{2} = \\frac{N + 1}{2}.\n\\]\nQuindi, abbiamo dimostrato che il valore atteso $ (X) $ per una variabile casuale \\(X\\) che assume valori interi uniformemente distribuiti da 1 a \\(N\\) √® \\(\\frac{N + 1}{2}\\).\nPer determinare quanto i valori di \\(X\\) si disperdono attorno al valore medio, calcoliamo la varianza. Il primo passo √® calcolare \\(\\mathbb{E}(X^2)\\), il valore atteso del quadrato di \\(X\\). Per una variabile casuale discreta uniforme, questo si ottiene moltiplicando ogni valore al quadrato per la sua probabilit√† (che √® \\(1/N\\) per tutti i valori) e sommando i risultati:\n\\[\n\\mathbb{E}(X^2) = \\frac{1}{N} \\cdot \\sum_{x=1}^N x^2\n\\]\nUsando l‚Äôidentit√† per la somma dei quadrati dei primi \\(N\\) numeri naturali:\n\\[\n1^2 + 2^2 + \\dots + N^2 = \\frac{N(N + 1)(2N + 1)}{6}\n\\]\npossiamo sostituirla per trovare \\(\\mathbb{E}(X^2)\\):\n\\[\n\\mathbb{E}(X^2) = \\frac{1}{N} \\cdot \\frac{N(N + 1)(2N + 1)}{6} = \\frac{(N + 1)(2N + 1)}{6}\n\\]\nLa varianza di \\(X\\), denotata con \\(\\mathbb{V}(X)\\), si calcola usando la formula:\n\\[\n\\mathbb{V}(X) = \\mathbb{E}(X^2) - [\\mathbb{E}(X)]^2\n\\]\nAbbiamo gi√† stabilito che \\(\\mathbb{E}(X) = \\frac{N + 1}{2}\\) e \\(\\mathbb{E}(X^2) = \\frac{(N + 1)(2N + 1)}{6}\\). Sostituendo questi valori nella formula della varianza, otteniamo:\n\\[\n\\mathbb{V}(X) = \\frac{(N + 1)(2N + 1)}{6} - \\left(\\frac{N + 1}{2}\\right)^2\n\\]\nPer semplicare l‚Äôespressione della varianza, dobbiamo sottrarre il quadrato di \\(\\mathbb{E}(X)\\) da \\(\\mathbb{E}(X^2)\\):\n\\[\n\\begin{align*}\n\\mathbb{V}(X) &= \\frac{(N + 1)(2N + 1)}{6} - \\left(\\frac{N + 1}{2}\\right)^2 \\\\\n&= \\frac{(N + 1)(2N + 1)}{6} - \\frac{(N + 1)^2}{4} \\\\\n&= \\frac{2(N + 1)(2N + 1)}{12} - \\frac{3(N + 1)^2}{12} \\\\\n&= \\frac{(N + 1)(2(2N + 1) - 3(N + 1))}{12} \\\\\n&= \\frac{(N + 1)(4N + 2 - 3N - 3)}{12} \\\\\n&= \\frac{(N + 1)(N - 1)}{12}\n\\end{align*}\n\\]\nQuindi, la varianza \\(\\mathbb{V}(X)\\) di una variabile casuale uniforme discreta \\(X\\) che assume valori da 1 a \\(N\\) √® \\(\\frac{(N + 1)(N - 1)}{12}\\), il che mostra come la dispersione dei valori attorno al loro valore medio dipenda dalla grandezza di \\(N\\). Questa formula fornisce la varianza di una variabile casuale in una distribuzione discreta uniforme, offrendo una misura quantitativa della dispersione dei valori attorno al loro valore medio.\n\n34.5.1 Distribuzione di Poisson\nLa distribuzione di Poisson √® utilizzata per modellare il numero di eventi che si verificano in un determinato intervallo di tempo o spazio, con eventi indipendenti e un tasso costante di occorrenza.\nLa funzione di massa di probabilit√† (PMF) √® data da:\n\\[\nP(Y = y \\mid \\lambda) = \\frac{\\lambda^y \\cdot e^{-\\lambda}}{y!}, \\quad y = 0, 1, 2, \\ldots\n\\]\ndove \\(\\lambda\\) rappresenta il tasso medio di eventi e \\(y\\) √® il numero di eventi.\n\n34.5.1.1 Propriet√† principali\n\nMedia: \\(\\mathbb{E}[Y] = \\lambda\\)\nVarianza: \\(\\text{Var}(Y) = \\lambda\\)\n\nDi seguito, presentiamo esempi di calcolo e simulazione con R.\n\n\n34.5.1.2 Grafico della distribuzione di Poisson con \\(\\lambda = 2\\)\n\n# Parametro lambda\nlambda &lt;- 2\n\n# Valori di y (numero di eventi)\ny &lt;- 0:10\n\n# Calcolo delle probabilit√†\nprobabilities &lt;- dpois(y, lambda = lambda)\n\n# Grafico della funzione di massa di probabilit√†\nbarplot(probabilities, names.arg = y, col = \"blue\", \n        xlab = \"Numero di eventi (k)\", ylab = \"Probabilit√†\", \n        main = \"Distribuzione di Massa di Probabilit√† di Poisson\")\n\n\n\n\n\n\n\n\n\n\n34.5.1.3 Calcolo della probabilit√† per un numero specifico di eventi\nPer calcolare la probabilit√† di osservare esattamente 3 eventi con \\(\\lambda = 2\\):\n\nprob &lt;- dpois(3, lambda = 2)\nprint(prob)\n#&gt; [1] 0.18\n\n\n\n34.5.1.4 Calcolo della probabilit√† cumulativa \\(P(Y \\leq 3)\\)\nPer calcolare \\(P(Y \\leq 3)\\), la probabilit√† cumulativa:\n\ncum_prob &lt;- ppois(3, lambda = 2)\nprint(cum_prob)\n#&gt; [1] 0.857\n\n\n\n34.5.1.5 Trovare il quantile corrispondente a una probabilit√† data\nPer trovare il numero massimo di eventi per cui la probabilit√† cumulativa √® al massimo \\(0.8125\\):\n\nquantile &lt;- qpois(0.8125, lambda = 2)\nprint(quantile)\n#&gt; [1] 3\n\n\n\n34.5.1.6 Generazione di numeri casuali\nPer generare un campione di 1.000.000 di osservazioni da una distribuzione di Poisson con \\(\\lambda = 2\\):\n\nset.seed(42)\nsample &lt;- rpois(1000000, lambda = 2)\n\n# Calcolo di media e varianza del campione\nmean_sample &lt;- mean(sample)\nvar_sample &lt;- var(sample)\n\nprint(mean_sample)\n#&gt; [1] 2\nprint(var_sample)\n#&gt; [1] 2\n\n\nEsercizio 34.2 Consideriamo un ospedale con una media storica di 4,5 nascite al giorno. Qual √® la probabilit√† che nascano esattamente 6 bambini in un giorno?\n\n# Calcolo della probabilit√†\nlambda &lt;- 4.5\nprob &lt;- dpois(6, lambda = lambda)\nprint(prob)\n#&gt; [1] 0.128\n\nSimuliamo 365 giorni di nascite e confrontiamo la proporzione di giorni con esattamente 6 nascite:\n\nset.seed(42)\nn_days &lt;- 365\nsimulated_births &lt;- rpois(n_days, lambda = lambda)\n\n# Proporzione di giorni con esattamente 6 nascite\nproportion_six_births &lt;- mean(simulated_births == 6)\nprint(proportion_six_births)\n#&gt; [1] 0.14\n\nIstogramma delle nascite simulate:\n\nhist(simulated_births, breaks = seq(-0.5, max(simulated_births) + 0.5, by = 1), \n     col = \"blue\", xlab = \"Numero di nascite per giorno\", \n     ylab = \"Frequenza\", main = \"365 nascite simulate (Poisson)\")\n\n\n\n\n\n\n\n\nProbabilit√† di pi√π di 6 nascite in un giorno. Per calcolare la probabilit√† teorica \\(P(Y &gt; 6)\\):\n\nprob_more_than_six &lt;- 1 - ppois(6, lambda = lambda)\nprint(prob_more_than_six)\n#&gt; [1] 0.169\n\nProporzione simulata di pi√π di 6 nascite:\n\nproportion_more_than_six &lt;- mean(simulated_births &gt; 6)\nprint(proportion_more_than_six)\n#&gt; [1] 0.17",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#distribuzione-beta-binomiale",
    "href": "chapters/probability/11_discr_rv_distr.html#distribuzione-beta-binomiale",
    "title": "34¬† Distribuzioni di v.c. discrete",
    "section": "34.6 Distribuzione Beta-Binomiale",
    "text": "34.6 Distribuzione Beta-Binomiale\nLa distribuzione beta-binomiale rappresenta una estensione della distribuzione binomiale che tiene conto della variabilit√† nella probabilit√† di successo tra i vari tentativi. Viene descritta da tre parametri principali: \\(N\\), \\(\\alpha\\) e \\(\\beta\\).\nNel dettaglio, la funzione di massa di probabilit√† per la distribuzione beta-binomiale √® data da:\n\\[\n\\text{BetaBinomiale}(y | N, \\alpha, \\beta) = \\binom{N}{y} \\cdot \\frac{B(y + \\alpha, N - y + \\beta)}{B(\\alpha, \\beta)},\n\\tag{34.4}\\]\ndove:\n\n\\(y\\) indica il numero di successi osservati.\n\\(N\\) rappresenta il numero totale di tentativi.\n\\(\\alpha\\) e \\(\\beta\\) sono i parametri della distribuzione beta, che modellano la variabilit√† nella probabilit√† di successo tra i tentativi.\n\nLa funzione \\(B(u, v)\\), nota come funzione beta, √® definita tramite l‚Äôuso della funzione gamma \\(\\Gamma\\), secondo la formula:\n\\[\nB(u, v) = \\frac{\\Gamma(u) \\Gamma(v)}{\\Gamma(u + v)},\n\\]\ndove la funzione gamma \\(\\Gamma\\) generalizza il concetto di fattoriale a numeri reali e complessi.\nL‚Äôimportanza della distribuzione beta-binomiale deriva dalla sua capacit√† di modellare situazioni in cui la probabilit√† di successo non √® fissa, ma segue una distribuzione di probabilit√†, specificatamente una distribuzione beta. Ci√≤ la rende particolarmente adatta per applicazioni in cui le probabilit√† di successo cambiano in maniera incerta da un tentativo all‚Äôaltro, come pu√≤ avvenire in contesti di ricerca clinica o in studi comportamentali. Rispetto alla distribuzione binomiale, che assume una probabilit√† di successo costante per tutti i tentativi, la beta-binomiale offre una rappresentazione pi√π realistica e flessibile per dati empirici che presentano variabilit√† nelle probabilit√† di successo.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#la-distribuzione-categorica",
    "href": "chapters/probability/11_discr_rv_distr.html#la-distribuzione-categorica",
    "title": "34¬† Distribuzioni di v.c. discrete",
    "section": "34.7 La Distribuzione Categorica",
    "text": "34.7 La Distribuzione Categorica\nLa distribuzione categorica √® una distribuzione di probabilit√† discreta utilizzata per modellare eventi con pi√π esiti distinti e non ordinati. √à una generalizzazione della distribuzione Bernoulliana, che si limita a due esiti (successo e fallimento), ed √® utile in situazioni in cui un evento pu√≤ produrre uno tra molti esiti, ciascuno con una probabilit√† associata.\n\n34.7.1 Definizione e Funzione di Massa di Probabilit√†\nLa distribuzione categorica pu√≤ essere caratterizzata dalla sua funzione di massa di probabilit√† (PMF):\n\\[\np(X = x) = \\mathcal{Categorical}(X \\mid p) = \\prod_{k=1}^K p_k^{I_{x=k}},\n\\]\ndove:\n\n\\(K\\) √® il numero di esiti possibili,\n\\(p_k\\) √® la probabilit√† associata al \\(k\\)-esimo esito,\n\\(I_{x=k}\\) √® una funzione indicatrice che vale 1 se \\(x = k\\) e 0 altrimenti.\n\nLe probabilit√† \\(p_k\\) formano un vettore:\n\\[\np =\n\\begin{pmatrix}\np_1\\\\\np_2\\\\\n\\dots \\\\\np_K\n\\end{pmatrix},\n\\]\nche soddisfa la condizione:\n\\[\n\\sum_{k=1}^K p_k = 1.\n\\]\nIn altre parole, la somma delle probabilit√† di tutti i possibili esiti √® pari a 1, come richiesto da qualsiasi distribuzione di probabilit√†.\n\n\n34.7.2 Propriet√† Principali\n\nEsiti Multipli: La distribuzione categorica √® adatta per modellare eventi con pi√π di due esiti distinti. Un esempio classico √® il lancio di un dado a sei facce, dove ciascun esito ha una probabilit√† di \\(\\frac{1}{6}\\) nel caso di un dado equo.\nGeneralizzazione della Distribuzione Bernoulliana: La distribuzione categorica √® una generalizzazione della distribuzione Bernoulliana. In particolare, la distribuzione Bernoulliana rappresenta un caso speciale della distribuzione categorica con due sole categorie (\\(K = 2\\)), come il risultato di un lancio di una moneta (testa o croce).\nProbabilit√† in Forma di Simplex: Le probabilit√† degli esiti nella distribuzione categorica sono rappresentate da un vettore simplex. Un simplex √® un vettore di probabilit√† non negative che sommano a 1, rispettando la condizione fondamentale delle distribuzioni di probabilit√†.\n\n\n\n34.7.3 Utilizzo della Distribuzione Categorica in Stan\nIn Stan, la distribuzione categorica √® impiegata per modellare la probabilit√† di un singolo esito tra diversi possibili risultati. Questo √® particolarmente utile in contesti come le catene di Markov, dove ogni stato pu√≤ evolvere verso uno tra molti altri stati con una certa probabilit√†.\nAd esempio, supponiamo di avere una matrice di transizione \\(P\\) che descrive le probabilit√† di passaggio tra stati in una catena di Markov. Ogni riga della matrice \\(P\\) rappresenta una distribuzione categorica, in cui le voci corrispondono alle probabilit√† di transizione dallo stato corrente agli stati successivi. La distribuzione categorical pu√≤ essere utilizzata per modellare la probabilit√† di osservare una specifica transizione.\nConsideriamo un esempio pratico: se uno studente si trova nello stato \\(A\\) al tempo \\(t\\), e le probabilit√† di transizione agli stati \\(A\\), \\(B\\) e \\(C\\) sono rispettivamente \\(0.7\\), \\(0.2\\) e \\(0.1\\), possiamo modellare la probabilit√† che l‚Äôevento successivo sia una transizione verso uno di questi stati usando la distribuzione categorica:\n\\[\nX \\sim \\text{categorical}(0.7, 0.2, 0.1)\n\\]\nQui, la variabile aleatoria \\(X\\) segue una distribuzione categorical con le probabilit√† assegnate ai tre possibili esiti (stati \\(A\\), \\(B\\), e \\(C\\)). Questo consente di simulare il prossimo stato in base alle probabilit√† specificate.\n\n34.7.3.1 Applicazione nelle Catene di Markov\nLa distribuzione categorical √® particolarmente efficace nei modelli di catene di Markov, dove descrive le transizioni tra stati in un sistema dinamico. Ogni transizione tra stati √® trattata come un evento discreto con pi√π esiti possibili, ciascuno con la propria probabilit√†. Questo approccio √® utile per modellare sistemi con molteplici stati e transizioni complesse, garantendo flessibilit√† e precisione nella simulazione delle dinamiche del sistema.\nIn sintesi, la distribuzione categorica in Stan permette di modellare eventi con molteplici esiti in modo semplice ed efficace, rendendola uno strumento prezioso per descrivere fenomeni dinamici, come le catene di Markov o qualsiasi altro processo con transizioni probabilistiche tra stati.\nDi seguito, esaminiamo come simulare una distribuzione categorica utilizzando numpy e come creare un istogramma per visualizzare la distribuzione di massa:\n\n# Definire le probabilit√† della distribuzione categorica\nprobabilities &lt;- c(0.6, 0.3, 0.1)  # Le probabilit√† per ciascun esito\n\n# Definire le categorie\ncategories &lt;- c(\"A\", \"B\", \"C\")\n\n# Numero di campioni da generare\nn_samples &lt;- 1000\n\n# Simulare la distribuzione categorica\nset.seed(123)  # Per riproducibilit√†\nsamples &lt;- sample(categories, size = n_samples, replace = TRUE, prob = probabilities)\n\nggplot(data.frame(samples = samples), aes(x = samples)) +\n  geom_bar(fill = \"skyblue\", color = \"black\") +\n  scale_x_discrete(labels = categories) +\n  labs(\n    x = \"Categorie\", \n    y = \"Frequenza\", \n    title = \"Istogramma della Distribuzione Categorica Simulata\"\n) \n\n\n\n\n\n\n\n\nConcludiamo chiarendo la relazione tra la distribuzione categorica e quella multinomiale.\nLa distribuzione categorica descrive l‚Äôesito di una singola prova con \\(K\\) categorie, ciascuna con una probabilit√† associata. √à una generalizzazione della distribuzione Bernoulliana, che prevede solo due esiti (successo o fallimento).\n\n\n\n34.7.4 Implementazioni in R\n\nsample: Permette di campionare da una distribuzione categorica, restituendo uno o pi√π esiti in base alle probabilit√† specificate. Ad esempio:\nsample(categories, size = n, replace = TRUE, prob = probabilities)\nDove categories √® un vettore di esiti, n √® il numero di campioni, e probabilities definisce le probabilit√† associate a ciascun esito.\nrmultinom: Funzione per la distribuzione multinomiale. Pu√≤ essere utilizzata per simulare una distribuzione categorica impostando il numero di prove \\(n = 1\\). Ad esempio:\nrmultinom(1, size = 1, prob = probabilities)\nQui, probabilities specifica le probabilit√† per ciascun esito. Restituisce il numero di successi per ciascuna categoria in una matrice.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#la-distribuzione-geometrica",
    "href": "chapters/probability/11_discr_rv_distr.html#la-distribuzione-geometrica",
    "title": "34¬† Distribuzioni di v.c. discrete",
    "section": "34.8 La Distribuzione Geometrica",
    "text": "34.8 La Distribuzione Geometrica\nLa distribuzione geometrica √® una distribuzione discreta che modella il numero di tentativi necessari per ottenere il primo successo in una sequenza di prove Bernoulliane indipendenti. Ogni prova ha due possibili esiti: successo (con probabilit√† \\(p\\)) o fallimento (con probabilit√† \\(1 - p\\)).\nIn termini pratici, la distribuzione geometrica pu√≤ essere utilizzata per rispondere alla domanda: ‚ÄúQuante prove falliscono prima di ottenere il primo successo?‚Äù.\n\n34.8.1 Funzione di Massa di Probabilit√†\nLa funzione di massa di probabilit√† (PMF) della distribuzione geometrica √® definita come:\n\\[\nP(X = k) = (1 - p)^{k-1} \\cdot p\n\\]\ndove:\n\n\\(X\\) √® il numero di tentativi fino al primo successo (incluso il tentativo in cui si ottiene il successo).\n\\(p\\) √® la probabilit√† di successo in ogni prova.\n\\(k\\) √® il numero di prove necessarie per ottenere il primo successo (un numero intero positivo, \\(k \\geq 1\\)).\n\n\n\n34.8.2 Propriet√† della Distribuzione Geometrica\n\nValore Atteso (Media): La media del numero di prove fino al primo successo √® data da:\n\n\\[\n\\mathbb{E}[X] = \\frac{1}{p}.\n\\]\nQuesto significa che, in media, ci si aspetta di avere \\(\\frac{1}{p}\\) prove prima di ottenere un successo.\n\nVarianza: La varianza della distribuzione geometrica √®:\n\n\\[\n\\text{Var}(X) = \\frac{1 - p}{p^2}.\n\\]\n\nMemoria Assente: La distribuzione geometrica ha una propriet√† interessante chiamata ‚Äúassenza di memoria‚Äù. Ci√≤ significa che, dato che non si √® verificato alcun successo fino a un certo punto, la probabilit√† di successo nelle prove future √® indipendente dal passato e rimane sempre \\(p\\).\n\n\n\n34.8.3 Applicazione nel Modello\nAd esempio, supponiamo di voler modellare quanti giorni passano prima che un animale venga adottato in un rifugio. Se la probabilit√† giornaliera di essere adottato √® \\(p\\), la distribuzione geometrica pu√≤ dirci quanto tempo ci aspettiamo prima che l‚Äôadozione avvenga. Se, ad esempio, \\(p = 0.2\\), significa che c‚Äô√® il 20% di probabilit√† di adozione ogni giorno, e possiamo modellare il numero di giorni fino all‚Äôadozione usando una distribuzione geometrica.\nNel nostro modello di adozione, stiamo utilizzando la distribuzione geometrica per modellare i giorni fino all‚Äôadozione. La probabilit√† \\(p\\) rappresenta la probabilit√† giornaliera che un animale venga adottato, e la distribuzione geometrica ci permette di modellare il numero di giorni fino a quando avviene il successo (adozione).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#riflessioni-conclusive",
    "href": "chapters/probability/11_discr_rv_distr.html#riflessioni-conclusive",
    "title": "34¬† Distribuzioni di v.c. discrete",
    "section": "34.9 Riflessioni Conclusive",
    "text": "34.9 Riflessioni Conclusive\nIn questo capitolo, abbiamo esplorato diverse distribuzioni discrete fondamentali, ciascuna con le sue specifiche applicazioni e peculiarit√†. Abbiamo iniziato con la distribuzione Bernoulliana, che modella esperimenti con due possibili esiti, come il lancio di una moneta. Abbiamo poi approfondito la distribuzione Binomiale, una generalizzazione della Bernoulliana, che si focalizza sul conteggio del numero di successi in un dato numero di prove indipendenti.\nAbbiamo anche esaminato la distribuzione Beta-Binomiale, che estende ulteriormente il modello Binomiale incorporando la variabilit√† nella probabilit√† di successo, e la distribuzione di Poisson, utilizzata per modellare il numero di eventi che si verificano in un intervallo di tempo o spazio, quando questi eventi sono rari e indipendenti.\nInfine, abbiamo discusso la distribuzione Discreta Uniforme, che attribuisce la stessa probabilit√† a ogni evento in un insieme finito e discreto. Questa distribuzione √® particolarmente utile quando non abbiamo ragioni per assegnare probabilit√† diverse ai diversi esiti.\nQueste distribuzioni formano il cuore dell‚Äôanalisi statistica discreta e trovano applicazione in un‚Äôampia gamma di settori. In particolare, nel contesto dell‚Äôanalisi bayesiana, la comprensione della distribuzione Binomiale e Beta-Binomiale √® cruciale, poich√© queste distribuzioni forniscono le basi per l‚Äôaggiornamento bayesiano, un concetto chiave che sar√† esplorato nei capitoli successivi.\nPer coloro interessati a tecniche pi√π avanzate, la generazione di valori casuali a partire da queste distribuzioni √® trattata nell‚Äôappendice {ref}rng-appendix. Questa sezione fornisce strumenti e approfondimenti utili per l‚Äôapplicazione pratica di questi modelli probabilistici.\nIn conclusione, le distribuzioni discrete forniscono strumenti essenziali e versatili per modellare e analizzare fenomeni caratterizzati da eventi distinti e quantificabili. La comprensione approfondita di queste distribuzioni √® cruciale per chiunque desideri esplorare il vasto campo della probabilit√† e della statistica.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#esercizi",
    "href": "chapters/probability/11_discr_rv_distr.html#esercizi",
    "title": "34¬† Distribuzioni di v.c. discrete",
    "section": "34.10 Esercizi",
    "text": "34.10 Esercizi\n\nEsercizio 34.3 Per ciascuna delle distribuzioni di massa di probabilit√† discusse, utilizzare R per:\n\ncreare un grafico della funzione, scegliendo opportunamente i parametri;\nestrarre un campione di 1000 valori casuali dalla distribuzione e visualizzarlo con un istogramma;\ncalcolare la media e la deviazione standard dei campioni e confrontarle con i valori teorici attesi;\nstimare l‚Äôintervallo centrale del 94% utilizzando i campioni simulati;\ndeterminare i quantili della distribuzione per gli ordini 0.05, 0.25, 0.75 e 0.95;\nscegliendo un valore della distribuzione pari alla media pi√π una deviazione standard, calcolare la probabilit√† che la variabile aleatoria assuma un valore minore o uguale a questo valore.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/11_discr_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "title": "34¬† Distribuzioni di v.c. discrete",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: US/Pacific\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] ggokabeito_0.1.0 see_0.9.0        gridExtra_2.3    patchwork_1.3.0 \n#&gt;  [5] bayesplot_1.11.1 psych_2.4.12     scales_1.3.0     markdown_1.13   \n#&gt;  [9] knitr_1.49       lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1   \n#&gt; [13] dplyr_1.1.4      purrr_1.0.2      readr_2.1.5      tidyr_1.3.1     \n#&gt; [17] tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3       \n#&gt; [21] here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.3         rlang_1.1.4       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       yaml_2.3.10       tools_4.4.2       parallel_4.4.2   \n#&gt; [21] tzdb_0.4.0        colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5      \n#&gt; [25] R6_2.5.1          lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3  \n#&gt; [29] pillar_1.10.1     gtable_0.3.6      glue_1.8.0        xfun_0.50        \n#&gt; [33] tidyselect_1.2.1  farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-166     \n#&gt; [37] labeling_0.4.3    rmarkdown_2.29    compiler_4.4.2\n\n\n\n\n\nBlitzstein, J. K., & Hwang, J. (2019). Introduction to probability. CRC Press.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html",
    "href": "chapters/probability/12_cont_rv_distr.html",
    "title": "35¬† Distribuzioni di v.c. continue",
    "section": "",
    "text": "35.1 Introduzione\nAnalogamente a quanto avviene per le variabili casuali discrete, anche per le variabili casuali continue possiamo rappresentare la variabilit√† all‚Äôinterno di una popolazione attraverso un modello statistico, ma in questo caso utilizziamo le densit√† di probabilit√† ‚Äì si veda il Capitolo 33. Mentre le distribuzioni di probabilit√† discrete si applicano a fenomeni con un numero finito o numerabile di esiti, le densit√† di probabilit√† descrivono variabili casuali che possono assumere un continuum di valori.\nLa funzione di densit√† di probabilit√† \\(f(x)\\) associata a una variabile casuale continua \\(X\\) rappresenta la distribuzione della probabilit√† all‚Äôinterno della popolazione. Questa funzione non fornisce la probabilit√† esatta di un singolo valore, ma piuttosto la probabilit√† di osservare valori di \\(X\\) all‚Äôinterno di un intervallo specifico. Cos√¨ come per le distribuzioni discrete, anche le densit√† di probabilit√† costituiscono un modello della popolazione, una rappresentazione matematica che ci consente di fare previsioni e di comprendere meglio i fenomeni aleatori continui.\nIniziamo con la distribuzione continua uniforme.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#introduzione",
    "href": "chapters/probability/12_cont_rv_distr.html#introduzione",
    "title": "35¬† Distribuzioni di v.c. continue",
    "section": "",
    "text": "35.1.1 Distribuzione Uniforme\nLa distribuzione uniforme √® una delle pi√π semplici funzioni di densit√† di probabilit√†. Consideriamo di nuovo l‚Äôesperimento dello spinner introdotto in precedenza. Simuliamo 20 valori che potrebbero essere ottenuti facendo ruotare lo spinner e li rappresentiamo con un istogramma.\n\n35.1.1.1 Simulazione di 20 valori\n\n# Simulazione di 20 valori\nset.seed(123)\nspinner_results &lt;- runif(20, min = 0, max = 360)\nprint(spinner_results)\n#&gt;  [1] 103.5 283.8 147.2 317.9 338.6  16.4 190.1 321.3 198.5 164.4 344.5 163.2\n#&gt; [13] 243.9 206.1  37.1 323.9  88.6  15.1 118.1 343.6\n\nggplot(data.frame(Valori = spinner_results), aes(x = Valori)) +\n  geom_histogram(binwidth = 10, fill = \"skyblue\", color = \"black\", alpha = 0.5) +\n  labs(x = \"Risultato dello spinner\", y = \"Frequenza relativa\",\n       title = \"Istogramma dei risultati (20 simulazioni)\") \n\n\n\n\n\n\n\n\nNonostante possiamo pensare che ogni risultato tra 0 e 360 sia ugualmente probabile, l‚Äôistogramma non lo suggerisce chiaramente con solo 20 osservazioni. Simuliamo ora 100.000 ripetizioni.\n\n\n35.1.1.2 Simulazione di 100.000 valori\n\n# Simulazione di 100.000 valori\nspinner_results_large &lt;- runif(100000, min = 0, max = 360)\n\n# Istogramma\nggplot(data.frame(Valori = spinner_results_large), aes(x = Valori)) +\n  geom_histogram(binwidth = 10, fill = \"skyblue\", color = \"black\", alpha = 0.5) +\n  labs(x = \"Risultato dello spinner\", y = \"Frequenza relativa\",\n       title = \"Istogramma dei risultati (100.000 simulazioni)\") \n\n\n\n\n\n\n\n\nIn questo caso, anche se ci sono variazioni nelle altezze delle barre (bin di ampiezza pari a 10), la forma generale dell‚Äôistogramma appare piuttosto uniforme su tutto l‚Äôintervallo \\([0, 360]\\). Con un numero enorme di risultati, l‚Äôistogramma si avvicinerebbe alla funzione di densit√† uniforme mostrata di seguito.\n\n\n35.1.1.3 Funzione di densit√† uniforme\n\n# Curva della funzione di densit√† uniforme\nx &lt;- seq(0, 360, length.out = 100)\ndensity_uniform &lt;- dunif(x, min = 0, max = 360)\n\nggplot(data.frame(x = x, y = density_uniform), aes(x = x, y = y)) +\n  geom_line(size = 1, color = \"blue\") +\n  labs(x = \"x\", y = \"p(x)\", title = \"Funzione di densit√† uniforme\") \n#&gt; Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#&gt; ‚Ñπ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\nQuando la variabile casuale \\(X\\) √® continua, come nel caso dello spinner, la probabilit√† √® rappresentata da una curva, la funzione di densit√† di probabilit√†. Poich√© lo spinner copre l‚Äôintervallo \\([0, 360]\\), la probabilit√† che \\(X\\) sia compreso in questo intervallo √® pari a 1. La densit√† costante √® quindi:\n\n1 / 360\n#&gt; [1] 0.00278\n\n\n\n35.1.1.4 Probabilit√† in un intervallo specifico\nLa probabilit√† di ottenere un valore tra 150 e 250, \\(P(150 &lt; X &lt; 250)\\), √® data dall‚Äôarea sottesa alla curva in quell‚Äôintervallo. L‚Äôaltezza della curva √® \\(1/360\\), mentre la base √® \\(250 - 150 = 100\\). Quindi:\n\n100 * (1 / 360)\n#&gt; [1] 0.278\n\nPer calcolare la probabilit√†, si possono utilizzare le funzioni di distribuzione cumulative:\n\npunif(250, min = 0, max = 360) - punif(150, min = 0, max = 360)\n#&gt; [1] 0.278\n\n\n\n35.1.1.5 Visualizzazione dell‚Äôintervallo di probabilit√†\n\n# Visualizzazione della probabilit√† nell'intervallo [150, 250]\nx &lt;- seq(0, 360, length.out = 1000)\nfx &lt;- dunif(x, min = 0, max = 360)\n\nggplot(data.frame(x = x, fx = fx), aes(x = x, y = fx)) +\n  geom_line(size = 1, color = \"blue\") +\n  geom_area(data = subset(data.frame(x = x, fx = fx), x &gt;= 150 & x &lt;= 250),\n            aes(x = x, y = fx), fill = \"gray\", alpha = 0.5) +\n  labs(x = \"x\", y = \"p(x)\", title = \"Probabilit√† per l'intervallo [150, 250]\")\n\n\n\n\n\n\n\n\nIn maniera pi√π formale possiamo dire che la distribuzione continua uniforme √® una distribuzione di probabilit√† continua che assegna lo stesso grado di fiducia a tutti i possibili valori di una variabile definita in un certo intervallo \\(S=[a,b]\\subset {\\mathbb  {R}}\\). La distribuzione continua uniforme viene indicata con \\({\\mathcal  {U}}(a,b)={\\mathcal  {U}}([a,b])\\). Come intervallo \\([a,b]\\) viene spesso preso l‚Äôintervallo unitario \\(I=[0,1]\\).\nLa densit√† di probabilit√† di una variabile casuale continua uniforme \\({\\mathcal  {U}}(a,b)\\) √®\n\\[\nf(x)={\\frac  {1}{b-a}} \\quad \\text{su}\\; [a, b].\n\\]\nIl suo valore attesto √®\n\\[\n\\displaystyle E(X)={\\frac {1}{2}}(b+a).\n\\]\nLa sua varianza √®\n\\[\nV(X)={\\frac {1}{12}}(b-a)^{2}.\n\\]\nIn R, √® possibile manipolare la distribuzione uniforme utilizzando le funzioni della famiglia runif, dunif, punif e qunif. Di default, queste funzioni lavorano con la distribuzione uniforme standard \\(\\mathcal{U}(0,1)\\).\n\n\n\n35.1.2 Funzione di densit√† di probabilit√† (PDF)\nLa funzione dunif() calcola l‚Äôordinata della funzione di densit√† per i valori di input specificati. Per esempio, esaminiamo la densit√† di \\(\\mathcal{U}(0,1)\\) per i valori 0.5, 0.8 e 1.2. Ci aspettiamo di ottenere 1 per i primi due valori e 0 per 1.2, che √® fuori dall‚Äôintervallo \\([0, 1]\\).\n\ndunif(c(0.5, 0.8, 1.2), min = 0, max = 1)\n#&gt; [1] 1 1 0\n\n\n\n35.1.3 Funzione di ripartizione (CDF)\nLa funzione punif() restituisce il valore della funzione di ripartizione. Per esempio, per \\(\\mathcal{U}(0,1)\\) nei punti 0.5 e 0.8:\n\npunif(c(0.5, 0.8), min = 0, max = 1)\n#&gt; [1] 0.5 0.8\n\n\n\n35.1.4 Calcolo della probabilit√† in un intervallo\nUtilizzando la funzione di ripartizione, possiamo calcolare la probabilit√† che la variabile casuale continua assuma un valore in un intervallo specificato. Per esempio, per \\(\\mathcal{U}(0,1)\\) troviamo \\(P(0.5 &lt; X &lt; 0.8)\\):\n\npunif(0.8, min = 0, max = 1) - punif(0.5, min = 0, max = 1)\n#&gt; [1] 0.3\n\n\n\n35.1.5 Calcolo dei quantili\nLa funzione qunif() restituisce i quantili della distribuzione uniforme, ovvero il valore della variabile casuale \\(X\\) in corrispondenza del valore della funzione di ripartizione fornito in input. Per esempio, troviamo i quantili di ordine 0.5 e 0.8 di \\(\\mathcal{U}(0,1)\\):\n\nqunif(c(0.5, 0.8), min = 0, max = 1)\n#&gt; [1] 0.5 0.8\n\n\n\n35.1.6 Simulazione di valori casuali\nLa funzione runif() consente di generare numeri casuali dalla distribuzione uniforme. Per esempio, simuliamo 5 valori casuali da \\(\\mathcal{U}(0,1)\\):\n\nset.seed(123)  # Per la riproducibilit√†\nrunif(5, min = 0, max = 1)\n#&gt; [1] 0.288 0.788 0.409 0.883 0.940\n\n\n\n35.1.7 Valore atteso\nPer verificare il valore atteso di 100,000 realizzazioni di \\(\\mathcal{U}(0,1)\\):\n\nmean(runif(100000, min = 0, max = 1))\n#&gt; [1] 0.499\n\n\n\n35.1.8 Varianza\nPer calcolare la varianza di 100,000 realizzazioni di \\(\\mathcal{U}(0,1)\\):\n\nvar(runif(100000, min = 0, max = 1))\n#&gt; [1] 0.0834\n\nConfrontiamo il valore teorico della varianza per \\(\\mathcal{U}(0,1)\\), che √® \\(1/12\\):\n\n1 / 12\n#&gt; [1] 0.0833\n\nIn conclusione, le funzioni della famiglia runif, dunif, punif e qunif in R consentono di manipolare e analizzare la distribuzione uniforme.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-esponenziale",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-esponenziale",
    "title": "35¬† Distribuzioni di v.c. continue",
    "section": "35.2 Distribuzione esponenziale",
    "text": "35.2 Distribuzione esponenziale\nUn‚Äôaltra distribuzione di densit√† molto semplice √® la distribuzione esponenziale. La distribuzione esponenziale viene spesso utilizzata per modellare il tempo trascorso prima che un evento si verifichi (tempo di attesa).\nLa distribuzione esponenziale √® l‚Äôunica distribuzione di probabilit√† continua che possiede la propriet√† di assenza di memoria. Ad esempio, ipotizziamo che il tempo necessario affinch√© un bicchiere da vino si rompa dopo il primo utilizzo segua una distribuzione esponenziale. Supponiamo inoltre che ci sia un bicchiere da vino che non si √® rotto dopo 3 anni dal primo utilizzo. L‚Äôassenza di memoria significa che la probabilit√† che questo bicchiere da vino non si rompa nel prossimo anno √® la stessa della probabilit√† che un altro bicchiere da vino nuovo non si rompa nel primo anno di utilizzo.\nChiamiamo \\(X\\) il tempo di attesa. Sia \\(\\mu = \\mathbb{E}(X)\\) il tempo di attesa medio. La funzione di densit√† esponenziale √®\n\\[\nf(x) = \\lambda {\\rm e}^{-\\lambda x}, \\quad \\text{con} \\; \\lambda = 1/\\mu,\\, \\lambda &gt; 0,\\, x &gt; 0,\n\\tag{35.1}\\]\novvero\n\\[\nf(x) = \\frac{1}{\\mu} {\\rm e}^{-x/\\mu}.\n\\]\nLa media di una distribuzione esponenziale √®\n\\[\nE(X) = \\frac{1}{\\lambda}.\n\\]\nLa varianza di una distribuzione esponenziale √®\n\\[\nV(X) = \\mu = \\frac{1}{\\lambda^2}.\n\\]\nLa deviazione standard √® dunque uguale alla media:\n\\[\n\\sigma_X = \\frac{1}{\\lambda} = \\mu.\n\\]\nAd esempio, il tempo di attesa della pubblicazione del voto di un esame scritto segue una distribuzione esponenziale. Supponiamo che, in questo Corso di Laurea, il tempo di attesa medio per conoscere il risultato di un esame scritto sia di 4 giorni. La funzione esponenziale diventa\n\\[\nf(x) = \\frac{1}{4} \\exp^{-x/4}.\n\\]\n\n35.2.1 Grafico della funzione di densit√† esponenziale\nLa densit√† esponenziale √® definita da \\(f(x) = \\lambda e^{-\\lambda x}\\). In R, possiamo disegnarla con:\n\n# Parametri della distribuzione\nmu &lt;- 4  # Media\nlambda &lt;- 1 / mu  # Tasso (1 / media)\nstdev &lt;- 1 / lambda  # Deviazione standard\n\n# Generare valori per x\nx &lt;- seq(0, 20, by = 0.01)\n\n# Calcolare la densit√†\npdf &lt;- dexp(x, rate = lambda)\n\n# Grafico della densit√†\nggplot(data.frame(x, pdf), aes(x = x, y = pdf)) +\n  geom_line(size = 1, color = \"blue\") +\n  labs(x = \"x\", y = \"f(x)\", title = \"Funzione di densit√† della distribuzione esponenziale\") \n\n\n\n\n\n\n\n\n\n\n35.2.2 Probabilit√† che \\(X \\leq 1.5\\)\nLa probabilit√† \\(P(X \\leq 1.5)\\) √® calcolata con la funzione di ripartizione pexp():\n\n# Probabilit√† che X &lt;= 1.5\npexp(1.5, rate = lambda)\n#&gt; [1] 0.313\n\nVisualizzazione dell‚Äôarea sottesa:\n\nggplot(data.frame(x, pdf), aes(x = x, y = pdf)) +\n  geom_line(size = 1, color = \"blue\") +\n  geom_area(data = subset(data.frame(x, pdf), x &lt;= 1.5), aes(x = x, y = pdf), fill = \"gray\", alpha = 0.5) +\n  labs(x = \"x\", y = \"f(x)\", title = \"Probabilit√† P(X &lt;= 1.5)\") \n\n\n\n\n\n\n\n\n\n\n35.2.3 Probabilit√† che \\(1 \\leq X \\leq 6\\)\nLa probabilit√† \\(P(1 \\leq X \\leq 6)\\) si calcola come differenza di funzioni di ripartizione:\n\n# Probabilit√† che 1 &lt;= X &lt;= 6\npexp(6, rate = lambda) - pexp(1, rate = lambda)\n#&gt; [1] 0.556\n\nVisualizzazione dell‚Äôarea sottesa:\n\nggplot(data.frame(x, pdf), aes(x = x, y = pdf)) +\n  geom_line(size = 1, color = \"blue\") +\n  geom_area(data = subset(data.frame(x, pdf), x &gt;= 1 & x &lt;= 6), aes(x = x, y = pdf), fill = \"gray\", alpha = 0.5) +\n  labs(x = \"x\", y = \"f(x)\", title = \"Probabilit√† P(1 &lt;= X &lt;= 6)\")\n\n\n\n\n\n\n\n\n\n\n35.2.4 Probabilit√† che \\(X \\geq 5.5\\)\nLa probabilit√† \\(P(X \\geq 5.5)\\) si ottiene con l‚Äôevento complementare \\(1 - P(X \\leq 5.5)\\) oppure con 1 - pexp():\n\n# Complemento\n1 - pexp(5.5, rate = lambda)\n#&gt; [1] 0.253\n\n# Alternativa con funzione di sopravvivenza\npexp(5.5, rate = lambda, lower.tail = FALSE)\n#&gt; [1] 0.253\n\nVisualizzazione dell‚Äôarea sottesa:\n\nggplot(data.frame(x, pdf), aes(x = x, y = pdf)) +\n  geom_line(size = 1, color = \"blue\") +\n  geom_area(data = subset(data.frame(x, pdf), x &gt;= 5.5), aes(x = x, y = pdf), fill = \"gray\", alpha = 0.5) +\n  labs(x = \"x\", y = \"f(x)\", title = \"Probabilit√† P(X &gt;= 5.5)\") \n\n\n\n\n\n\n\n\n\n\n35.2.5 Istogramma di valori simulati\nSimuliamo 1.000.000 di valori casuali da una distribuzione esponenziale con parametro \\(\\lambda = 1/4\\), quindi costruiamo l‚Äôistogramma sovrapponendo la densit√† teorica.\n\n# Simulazione di valori casuali\nset.seed(123)\nsamples &lt;- rexp(1000000, rate = lambda)\n\n# Istogramma con densit√† sovrapposta\nggplot(data.frame(samples), aes(x = samples)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 100, fill = \"skyblue\", color = \"black\", alpha = 0.5) +\n  geom_line(data = data.frame(x, pdf), aes(x = x, y = pdf), color = \"red\", size = 1) +\n  xlim(0, 20) +\n  labs(x = \"Tempo di attesa\", y = \"Frequenza relativa\",\n       title = \"Istogramma dei valori simulati con densit√† teorica\")\n#&gt; Warning: Removed 6631 rows containing non-finite outside the scale range\n#&gt; (`stat_bin()`).\n#&gt; Warning: Removed 2 rows containing missing values or values outside the scale range\n#&gt; (`geom_bar()`).\n\n\n\n\n\n\n\n\nQuesti esempi replicano tutte le funzionalit√† dell‚Äôimplementazione Python utilizzando R e producono grafici chiari e ben definiti.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-gaussiana",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-gaussiana",
    "title": "35¬† Distribuzioni di v.c. continue",
    "section": "35.3 Distribuzione Gaussiana",
    "text": "35.3 Distribuzione Gaussiana\nLa pi√π importante distribuzione di densit√† √® la Gaussiana. Non c‚Äô√® un‚Äôunica distribuzione gaussiana (o Normale): la distribuzione gaussiana √® una famiglia di distribuzioni. Tali distribuzioni sono dette ‚Äúgaussiane‚Äù in onore di Carl Friedrich Gauss (uno dei pi√π grandi matematici della storia il quale, tra le altre cose, scopr√¨ l‚Äôutilit√† di tale funzione di densit√† per descrivere gli errori di misurazione). Adolphe Quetelet, il padre delle scienze sociali quantitative, fu il primo ad applicare tale funzione di densit√† alle misurazioni dell‚Äôuomo. Karl Pearson us√≤ per primo il termine ‚Äúdistribuzione normale‚Äù anche se ammise che questa espressione ‚Äúha lo svantaggio di indurre le persone a credere che le altre distribuzioni, in un senso o nell‚Äôaltro, non siano normali.‚Äù\n\n35.3.1 Limite delle distribuzioni binomiali\nIniziamo con un un breve excursus storico. Nel 1733, Abraham de Moivre not√≤ che, aumentando il numero di prove di una distribuzione binomiale, la distribuzione risultante diventava quasi simmetrica e a forma campanulare. Per esempio, con 10 prove e una probabilit√† di successo di 0.9, la distribuzione √® chiaramente asimmetrica.\n\n# Parametri\nn &lt;- 10\np &lt;- 0.9\n\n# Calcolare la distribuzione binomiale\nr_values &lt;- 0:n\ndist &lt;- dbinom(r_values, size = n, prob = p)\n\n# Grafico\nggplot(data.frame(Successi = r_values, Probabilit√† = dist), aes(x = Successi, y = Probabilit√†)) +\n  geom_bar(stat = \"identity\", fill = \"skyblue\", color = \"black\") +\n  labs(title = \"Distribuzione Binomiale: n = 10, p = 0.9\", x = \"Numero di Successi\", y = \"Probabilit√†\") \n\n\n\n\n\n\n\n\nQuando il numero di prove N viene aumentato di un fattore di 100 a N = 1000, mantenendo costante la probabilit√† di successo del 90%, si osserva che la distribuzione assume una forma campanulare quasi simmetrica. Questa osservazione porta a una scoperta di de Moivre: quando N diventa grande, la funzione gaussiana, nonostante rappresenti la densit√† di variabili casuali continue, offre una buona approssimazione alla funzione di massa di probabilit√† binomiale.\n\n# Parametri aggiornati\nn &lt;- 1000\n\n# Calcolare la distribuzione\nr_values &lt;- 850:950  # Intervallo per una migliore visualizzazione\ndist &lt;- dbinom(r_values, size = n, prob = p)\n\n# Grafico\nggplot(data.frame(Successi = r_values, Probabilit√† = dist), aes(x = Successi, y = Probabilit√†)) +\n  geom_bar(stat = \"identity\", fill = \"skyblue\", color = \"black\") +\n  labs(\n    title = \"Distribuzione Binomiale: n = 1000, p = 0.9\", \n    x = \"Numero di Successi\", \n    y = \"Probabilit√†\"\n  ) \n\n\n\n\n\n\n\n\nLa distribuzione Normale fu scoperta da Gauss nel 1809. Il Paragrafo successivo illustra come si possa giungere alla Normale mediante una simulazione.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#la-normale-prodotta-con-una-simulazione",
    "href": "chapters/probability/12_cont_rv_distr.html#la-normale-prodotta-con-una-simulazione",
    "title": "35¬† Distribuzioni di v.c. continue",
    "section": "35.4 La Normale prodotta con una simulazione",
    "text": "35.4 La Normale prodotta con una simulazione\nIl libro ‚ÄúRethinking Statistics‚Äù di McElreath (2020) spiega come sia possibile ottenere la distribuzione normale attraverso una simulazione. Immaginiamo di avere duemila persone che si trovano allineate su una linea di partenza. Quando viene dato il segnale di partenza, ogni persona lancia una moneta e compie un passo avanti o indietro a seconda del risultato del lancio. La lunghezza di ogni passo pu√≤ variare da 0 a 1 metro. Ogni persona lancia la moneta 16 volte e quindi compie 16 passi.\nI risultati ottenuti da una serie di passeggiate casuali si traducono in varie distanze dall‚Äôorigine, che √® il punto da cui si parte, contrassegnato come zero, dopo un numero specificato di passi. Queste distanze sono rappresentate numericamente. Al termine di queste passeggiate, non √® possibile determinare la posizione esatta di ogni individuo, ma √® possibile descrivere accuratamente le caratteristiche della distribuzione delle 1000 distanze dall‚Äôorigine.\nAd esempio, √® possibile prevedere con precisione la frazione di individui che si sono mossi verso in avanti o indietro, o la proporzione di persone che si troveranno a una distanza specifica dal punto di partenza, come a 1.5 metri dall‚Äôorigine. Queste previsioni sono fattibili perch√© la distribuzione delle distanze segue una distribuzione Normale.\nIl codice presentato di seguito genera passeggiate casuali utilizzando un generatore di numeri casuali e ne traccia i percorsi risultanti. Il codice inizia inizializzando un oggetto generatore di numeri casuali con la funzione np.random.default_rng() della libreria numpy. Questo generatore sar√† usato per produrre numeri casuali uniformemente distribuiti tra -1 e 1, simulando cos√¨ il lancio di una moneta.\nLa variabile steps specifica il numero di passi per ogni passeggiata casuale, mentre repetitions indica il numero di passeggiate da generare. La variabile show_steps √® un elenco di numeri di passi in cui il codice traccer√† linee verticali sul grafico.\nSuccessivamente, il codice crea un array bidimensionale di NumPy chiamato x con righe pari a steps + 1 e colonne pari a repetitions. La prima colonna di questo array √® riempita di zeri, e le colonne rimanenti sono riempite con la somma cumulativa dei passi, ottenuti da numeri casuali uniformemente distribuiti generati dal generatore di numeri casuali. Questo array verr√† utilizzato per memorizzare le posizioni della passeggiata casuale ad ogni passo.\nIl codice poi prepara una figura per tracciare tutte le passeggiate casuali. Il codice traccia anche la prima passeggiata casuale in nero.\n\n# Parametri\nnumero_passi &lt;- 16\nripetizioni &lt;- 1000\npunti_da_evidenziare &lt;- c(4, 8, 16)\n\n# Generare passeggiate casuali\nset.seed(123)\nx &lt;- matrix(0, nrow = numero_passi + 1, ncol = ripetizioni)\n\nfor (i in 1:ripetizioni) {\n  passi &lt;- runif(numero_passi, min = -1, max = 1)\n  x[-1, i] &lt;- cumsum(passi)\n}\n\n# Grafico delle passeggiate casuali\ndf &lt;- data.frame(\n  Passo = rep(0:numero_passi, times = ripetizioni), \n  Distanza = as.vector(x)\n)\n\n# Grafico delle passeggiate casuali\nggplot(\n  df, \n  aes(\n    x = Passo, \n    y = Distanza, \n    group = rep(1:ripetizioni, each = numero_passi + 1))\n  ) +\n  geom_line(color = \"blue\", alpha = 0.05) +\n  geom_line(\n    data = data.frame(Passo = 0:numero_passi, Distanza = x[, 1], group = 1), \n    aes(x = Passo, y = Distanza, group = group), color = \"black\") +\n  geom_vline(\n    xintercept = punti_da_evidenziare, \n    linetype = \"dashed\", \n    color = \"black\", \n    alpha = 0.5) +\n  labs(\n    title = \"Passeggiate Casuali\", \n    x = \"Numero di Passi\", \n    y = \"Distanza dall'Origine\"\n  ) \n\n\n\n\n\n\n\n\nIl grafico riportato qui sotto visualizza la distribuzione dei passi a partire dalla linea mediana dopo 4, 8 e 16 lanci di moneta/passi. Quello che si nota √® che, man mano che procediamo nel numero di passi, le densit√† iniziano a somigliare alla curva a campana associata alle distribuzioni Gaussiane.\n\ndensities &lt;- lapply(punti_da_evidenziare, function(step) {\n  data.frame(Posizione = x[step + 1, ], Passo = step)\n})\n\ndensities &lt;- bind_rows(densities)\n\nggplot(densities, aes(x = Posizione, fill = as.factor(Passo))) +\n  geom_density(alpha = 0.6) +\n  facet_wrap(~ Passo, scales = \"free\") +\n  labs(\n    title = \"Densit√† delle Posizioni\",\n    x = \"Posizione\",\n    y = \"Densit√†\",\n    fill = \"Passo\"  # Etichetta per la legenda\n  ) +\n  theme(\n    legend.position = \"bottom\"  # Sposta la legenda in basso\n  )\n\n\n\n\n\n\n\n\nLa chiarezza dell‚Äôinformazione presentata nei grafici precedenti pu√≤ essere migliorata utilizzando un KDE plot.\n\n# Generare i dati\nposizioni &lt;- apply(matrix(runif(numero_passi * ripetizioni, min = -1, max = 1), nrow = numero_passi), 2, sum)\n\n# Calcolare media e deviazione standard\nmedia &lt;- mean(posizioni)\ndev_std &lt;- sd(posizioni)\n\n# Generare la curva normale\nvalori &lt;- seq(min(posizioni), max(posizioni), length.out = 1000)\ndensit√†_normale &lt;- dnorm(valori, mean = media, sd = dev_std)\n\n# Grafico\nggplot(data.frame(Posizione = posizioni), aes(x = Posizione)) +\n  geom_density(fill = \"skyblue\", alpha = 0.5) +\n  geom_line(data = data.frame(Posizione = valori, Densit√† = densit√†_normale), aes(x = Posizione, y = Densit√†), color = \"red\", linetype = \"dashed\") +\n  labs(title = \"Confronto tra Passeggiate Casuali e Normale\", x = \"Posizione\", y = \"Densit√†\") \n\n\n\n\n\n\n\n\nQuesta simulazione in luce un principio fondamentale della teoria delle probabilit√†: ogni processo che coinvolge la somma di una sequenza di valori casuali, tutti estratti dalla stessa distribuzione, inevitabilmente tende verso una distribuzione normale, comunemente conosciuta come curva gaussiana. Questa tendenza si verifica indipendentemente dalla configurazione iniziale della distribuzione di partenza, che pu√≤ essere uniforme, come nell‚Äôesempio menzionato, o di qualsiasi altro tipo. La forma specifica della distribuzione iniziale influisce sulla velocit√† con cui si verifica questa convergenza verso il comportamento gaussiano, con variazioni significative nella velocit√† di convergenza: alcuni processi possono manifestare una convergenza lenta, mentre altri possono convergere estremamente rapidamente. Un esempio emblematico di questo fenomeno √® rappresentato dal dispositivo conosciuto come Galton box, il quale offre una rappresentazione visiva e fisica di come la somma di valori casuali generi una distribuzione normale.\nUn modo per razionalizzare la distribuzione Gaussiana √® quello di pensare alle medie. Qualunque sia il valore medio della distribuzione di origine, ogni campione da essa pu√≤ essere considerato una fluttuazione rispetto a quel valore medio. Tuttavia, quando sommiamo queste fluttuazioni insieme, esse si annullano a vicenda. E, facendo ci√≤, queste fluttuazioni convergono eventualmente alla media delle osservazioni collettive. Non importa quale sia la forma della distribuzione sottostante. A seconda della forma, le somme cumulative convergeranno inevitabilmente sulla media, alcune distribuzioni pi√π lentamente di altre.\nDal punto di vista formale, possiamo definire una variabile casuale continua \\(Y\\) come avente una distribuzione normale se la sua densit√† di probabilit√† √® distribuita secondo la seguente equazione\n\\[\nf(y; \\mu, \\sigma) = {1 \\over {\\sigma\\sqrt{2\\pi} }} \\exp \\left\\{-\\frac{(y -  \\mu)^2}{2 \\sigma^2} \\right\\},\n\\tag{35.2}\\]\ndove \\(\\mu \\in \\mathbb{R}\\) e \\(\\sigma &gt; 0\\) sono i parametri della distribuzione.\nLa densit√† normale √® unimodale e simmetrica con una caratteristica forma a campana e con il punto di massima densit√† in corrispondenza di \\(\\mu\\).\nIl significato dei parametri \\(\\mu\\) e \\(\\sigma\\) che appaiono nell‚Äôeq. {eq}eq-normal-formula viene chiarito dalla dimostrazione che\n\\[\n\\mathbb{E}(Y) = \\mu, \\qquad \\mathbb{V}(Y) = \\sigma^2.\n\\]\nLa rappresentazione grafica di quattro densit√† Normali con medie -1, -0.5, 0, 1 e con deviazioni standard 0.25, 0.5, 1 e 2 √® fornita nella figura seguente.\n\n# Definire l'intervallo di x\nx &lt;- seq(-5, 6, by = 0.001)\n\n# Parametri della distribuzione normale\nmus &lt;- c(-1.0, -0.5, 0.0, 1.0)\nsigmas &lt;- c(0.25, 0.5, 1, 2)\n\n# Creare un data frame per tutte le combinazioni di mu e sigma\ndata &lt;- do.call(rbind, lapply(1:length(mus), function(i) {\n  data.frame(\n    x = x,\n    f_x = dnorm(x, mean = mus[i], sd = sigmas[i]),\n    mu = mus[i],\n    sigma = sigmas[i]\n  )\n}))\n\n# Grafico\nggplot(data, aes(x = x, y = f_x, color = factor(mu), linetype = factor(sigma))) +\n  geom_line(size = 1) +\n  labs(\n    x = \"x\",\n    y = \"f(x)\",\n    color = expression(mu),\n    linetype = expression(sigma),\n    title = \"Distribuzioni Normali con Diversi Parametri\"\n  ) +\n  theme(legend.position = \"top\")\n\n\n\n\n\n\n\n\n\n35.4.1 Concentrazione\n√à istruttivo osservare il grado di concentrazione della distribuzione Normale attorno alla media:\n\\[\n\\begin{align}\nP(\\mu - \\sigma &lt; Y &lt; \\mu + \\sigma) &= P (-1 &lt; Z &lt; 1) \\simeq 0.683, \\notag\\\\\nP(\\mu - 2\\sigma &lt; Y &lt; \\mu + 2\\sigma) &= P (-2 &lt; Z &lt; 2) \\simeq 0.956, \\notag\\\\\nP(\\mu - 3\\sigma &lt; Y &lt; \\mu + 3\\sigma) &= P (-3 &lt; Z &lt; 3) \\simeq 0.997. \\notag\n\\end{align}\n\\]\nSi noti come un dato la cui distanza dalla media √® superiore a 3 volte la deviazione standard presenti un carattere di eccezionalit√† perch√© meno del 0.3% dei dati della distribuzione Normale presentano questa caratteristica.\nPer indicare la distribuzione Normale si usa la notazione \\(\\mathcal{N}(\\mu, \\sigma)\\).\n\n\n35.4.2 Funzione di ripartizione\nIl valore della funzione di ripartizione di \\(Y\\) nel punto \\(y\\) √® l‚Äôarea sottesa alla curva di densit√† \\(f(y)\\) nella semiretta \\((-\\infty, y]\\). Non esiste alcuna funzione elementare per la funzione di ripartizione\n\\[\nF(y) = \\int_{-\\infty}^y {1 \\over {\\sigma\\sqrt{2\\pi} }} \\exp \\left\\{-\\frac{(y - \\mu)^2}{2\\sigma^2} \\right\\} dy,\n\\] (eq-gaussian-rip-formula)\npertanto le probabilit√† \\(P(Y &lt; y)\\) vengono calcolate mediante integrazione numerica approssimata. I valori della funzione di ripartizione di una variabile casuale Normale sono dunque forniti da un software.\nEcco l‚Äôequivalente in R utilizzando le funzioni per la distribuzione normale e il pacchetto ggplot2 per i grafici.\n\n\n35.4.3 Generazione di Valori Casuali\nIn R, la funzione rnorm() genera valori casuali dalla distribuzione normale. Ad esempio, per ottenere un singolo valore casuale dalla \\(\\mathcal{N}(100, 15)\\):\n\n# Generare un singolo valore casuale\nset.seed(123)  # Per la riproducibilit√†\nrnorm(1, mean = 100, sd = 15)\n#&gt; [1] 91.6\n\nPer estrarre 10 valori casuali dalla stessa distribuzione:\n\n# Generare 10 valori casuali\nset.seed(123)\nqi &lt;- rnorm(10, mean = 100, sd = 15)\nprint(qi)\n#&gt;  [1]  91.6  96.5 123.4 101.1 101.9 125.7 106.9  81.0  89.7  93.3\n\n\n\n35.4.4 Funzione di Ripartizione (CDF)\nPer calcolare la probabilit√† che un‚Äôosservazione casuale abbia un valore minore o uguale a 115, utilizziamo pnorm():\n\n# Probabilit√† che X &lt;= 115\npnorm(115, mean = 100, sd = 15)\n#&gt; [1] 0.841\n\n\n\n35.4.5 Visualizzazione dell‚ÄôArea Sottesa alla Funzione di Densit√†\nPossiamo visualizzare l‚Äôarea sottesa utilizzando ggplot2:\n\n# Parametri\nmu &lt;- 100\nsigma &lt;- 15\n\n# Intervallo di x\nx &lt;- seq(mu - 3 * sigma, mu + 3 * sigma, length.out = 1000)\n\n# Densit√†\nfx &lt;- dnorm(x, mean = mu, sd = sigma)\n\n# Grafico\nggplot(data.frame(x, fx), aes(x = x, y = fx)) +\n  geom_line(color = \"blue\") +\n  geom_area(\n    data = subset(data.frame(x, fx), x &lt;= 115), \n    aes(x = x, y = fx), fill = \"gray\", alpha = 0.5\n  ) +\n  labs(title = \"Funzione di Densit√† Normale\", x = \"x\", y = \"f(x)\") \n\n\n\n\n\n\n\n\n\n\n35.4.6 Calcolo dell‚ÄôIntegrale con integrate\nPossiamo calcolare l‚Äôarea sotto la curva manualmente utilizzando la funzione integrate:\n\n# Definizione della funzione gaussiana\ngaussian &lt;- function(x, mu, sigma) {\n  (1 / (sqrt(2 * pi) * sigma)) * exp(-((x - mu)^2) / (2 * sigma^2))\n}\n\n# Calcolo dell'area\nresult &lt;- integrate(gaussian, lower = -Inf, upper = 115, mu = 100, sigma = 15)\nprint(paste(\"Il risultato √®\", result$value, \"con errore\", result$abs.error))\n#&gt; [1] \"Il risultato √® 0.84134474610298 con errore 3.76616994661114e-06\"\n\n\n\n35.4.7 Proporzione di Valori Maggiori di 130\nCalcoliamo \\(P(X &gt; 130)\\) utilizzando il complementare della funzione di ripartizione:\n\n# Probabilit√† che X &gt; 130\n1 - pnorm(130, mean = 100, sd = 15)\n#&gt; [1] 0.0228\n\nPossiamo anche utilizzare la funzione di sopravvivenza 1 - pnorm():\n\n# Funzione di sopravvivenza\npnorm(130, mean = 100, sd = 15, lower.tail = FALSE)\n#&gt; [1] 0.0228\n\nVisualizzazione:\n\nggplot(data.frame(x, fx), aes(x = x, y = fx)) +\n  geom_line(color = \"blue\") +\n  geom_area(\n    data = subset(data.frame(x, fx), x &gt;= 130), \n    aes(x = x, y = fx), fill = \"gray\", alpha = 0.5\n  ) +\n  labs(title = \"Area Sottesa per X &gt;= 130\", x = \"x\", y = \"f(x)\") \n\n\n\n\n\n\n\n\n\n\n35.4.8 Funzione di Quantile (PPF)\nLa funzione qnorm() restituisce il quantile della distribuzione normale. Ad esempio:\n\n# Quantile corrispondente al 97.725%\nqnorm(1 - 0.022750131948179195, mean = 100, sd = 15)\n#&gt; [1] 130\n\nIn conclusione, le funzioni rnorm, dnorm, pnorm, e qnorm in R forniscono gli strumenti necessari per manipolare la distribuzione normale.\n\n\n35.4.9 Distribuzione Normale standard\nLa distribuzione Normale di parametri \\(\\mu = 0\\) e \\(\\sigma = 1\\) viene detta distribuzione Normale standard. La famiglia Normale √® l‚Äôinsieme avente come elementi tutte le distribuzioni Normali con parametri \\(\\mu\\) e \\(\\sigma\\) diversi. Tutte le distribuzioni Normali si ottengono dalla Normale standard mediante una trasformazione lineare: se \\(Y \\sim \\mathcal{N}(\\mu_Y, \\sigma_Y)\\) allora\n\\[\nX = a + b Y \\sim \\mathcal{N}(\\mu_X = a+b \\mu_Y, \\sigma_X = \\left|b\\right|\\sigma_Y).\n\\]\nL‚Äôarea sottesa alla curva di densit√† di \\(\\mathcal{N}(\\mu, \\sigma)\\) nella semiretta \\((-\\infty, y]\\) √® uguale all‚Äôarea sottesa alla densit√† Normale standard nella semiretta \\((-\\infty, z]\\), in cui \\(z = (y -\\mu_Y )/\\sigma_Y\\) √® il punteggio standard di \\(Y\\). Per la simmetria della distribuzione, l‚Äôarea sottesa nella semiretta \\([1, \\infty)\\) √® uguale all‚Äôarea sottesa nella semiretta \\((-\\infty, 1]\\) e quest‚Äôultima coincide con \\(F(-1)\\). Analogamente, l‚Äôarea sottesa nell‚Äôintervallo \\([y_a, y_b]\\), con \\(y_a &lt; y_b\\), √® pari a \\(F(z_b) - F(z_a)\\), dove \\(z_a\\) e \\(z_b\\) sono i punteggi standard di \\(y_a\\) e \\(y_b\\).\nSi ha anche il problema inverso rispetto a quello del calcolo delle aree: dato un numero \\(0 \\leq p \\leq 1\\), il problema √® quello di determinare un numero \\(z \\in \\mathbb{R}\\) tale che \\(P(Z &lt; z) = p\\). Il valore \\(z\\) cercato √® detto quantile di ordine \\(p\\) della Normale standard e pu√≤ essere trovato mediante un software.\nSupponiamo che l‚Äôaltezza degli individui adulti segua la distribuzione Normale di media \\(\\mu = 1.7\\) m e deviazione standard \\(\\sigma = 0.1\\) m. Vogliamo sapere la proporzione di individui adulti con un‚Äôaltezza compresa tra \\(1.7\\) e \\(1.8\\) m.\nIl problema ci chiede di trovare l‚Äôarea sottesa alla distribuzione \\(\\mathcal{N}(\\mu = 1.7, \\sigma = 0.1)\\) nell‚Äôintervallo \\([1.7, 1.8]\\):\n\n# Parametri della distribuzione\nmu &lt;- 1.7\nsigma &lt;- 0.1\n\n# Calcolare la probabilit√† cumulativa\nprob &lt;- pnorm(1.8, mean = mu, sd = sigma) - pnorm(1.7, mean = mu, sd = sigma)\nprint(prob)\n#&gt; [1] 0.341\n\n\n# Generare dati\nx &lt;- seq(mu - 3 * sigma, mu + 3 * sigma, length.out = 1000)\nfx &lt;- dnorm(x, mean = mu, sd = sigma)\n\n# Creare il grafico\nggplot(data.frame(x, fx), aes(x = x, y = fx)) +\n  geom_line(color = \"blue\") +\n  geom_area(data = subset(data.frame(x, fx), x &gt;= 1.7 & x &lt;= 1.8), \n            aes(x = x, y = fx), fill = \"gray\", alpha = 0.5) +\n  labs(title = \"Funzione di Densit√† Normale\", \n       x = \"Altezza (m)\", \n       y = \"Densit√†\")\n\n\n\n\n\n\n\n\nIn maniera equivalente, possiamo standardizzare i valori che delimitano l‚Äôintervallo considerato e utilizzare la funzione di ripartizione della normale standardizzata. I limiti inferiore e superiore dell‚Äôintervallo sono\n\\[\nz_{\\text{inf}} = \\frac{1.7 - 1.7}{0.1} = 0, \\quad z_{\\text{sup}} = \\frac{1.8 - 1.7}{0.1} = 1.0,\n\\]\nquindi otteniamo\n\n# Standardizzazione\nz_inf &lt;- (1.7 - mu) / sigma\nz_sup &lt;- (1.8 - mu) / sigma\n\n# Calcolo con la normale standardizzata\nprob_standard &lt;- pnorm(z_sup, mean = 0, sd = 1) - pnorm(z_inf, mean = 0, sd = 1)\nprint(prob_standard)\n#&gt; [1] 0.341\n\nIl modo pi√π semplice per risolvere questo problema resta comunque quello di rendersi conto che la probabilit√† richiesta non √® altro che la met√† dell‚Äôarea sottesa dalle distribuzioni Normali nell‚Äôintervallo \\([\\mu - \\sigma, \\mu + \\sigma]\\), ovvero \\(0.683/2\\).\nConsideriamo ora la visualizzazione della PDF, la CDF e l‚Äôinverso della CDF della distribuzione normale.\n\n# Parametri della distribuzione\nmu &lt;- 100\nsigma &lt;- 15\n\n# Generare intervalli di valori\nx &lt;- seq(mu - 3 * sigma, mu + 3 * sigma, length.out = 1000)\nprobabilities &lt;- seq(0.01, 0.99, length.out = 100)\n\n# Calcolo delle funzioni\npdf &lt;- dnorm(x, mean = mu, sd = sigma)\ncdf &lt;- pnorm(x, mean = mu, sd = sigma)\nppf &lt;- qnorm(probabilities, mean = mu, sd = sigma)\n\n# Creare i grafici con ggplot2\nlibrary(gridExtra)\n\n# Grafico della PDF\npdf_plot &lt;- ggplot(data.frame(x, pdf), aes(x = x, y = pdf)) +\n  geom_line(color = \"blue\") +\n  labs(title = \"PDF\", x = \"Valori\", y = \"Probabilit√†\")\n\n# Grafico della CDF\ncdf_plot &lt;- ggplot(data.frame(x, cdf), aes(x = x, y = cdf)) +\n  geom_line(color = \"orange\") +\n  labs(title = \"CDF\", x = \"Valori\", y = \"Cumulativa\")\n\n# Grafico dell'inversa della CDF\nppf_plot &lt;- ggplot(data.frame(Probabilit√† = probabilities, Valori = ppf), aes(x = Probabilit√†, y = Valori)) +\n  geom_line(color = \"green\") +\n  labs(title = \"Inverse CDF\", x = \"Probabilit√†\", y = \"Valori\") \n\n# Mostrare i grafici\ngrid.arrange(pdf_plot, cdf_plot, ppf_plot, ncol = 3)\n\n\n\n\n\n\n\n\nDovrebbe essere chiaro dalla figura che queste sono tre diverse modalit√† di osservare la stessa informazione.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-chi-quadrato",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-chi-quadrato",
    "title": "35¬† Distribuzioni di v.c. continue",
    "section": "35.5 Distribuzione Chi-quadrato",
    "text": "35.5 Distribuzione Chi-quadrato\nDalla Normale deriva la distribuzione \\(\\chi^2\\). La distribuzione \\(\\chi^2_{~k}\\) con \\(k\\) gradi di libert√† descrive la variabile casuale\n\\[\nZ_1^2 + Z_2^2 + \\dots + Z_k^2,\n\\]\ndove \\(Z_1, Z_2, \\dots, Z_k\\) sono variabili casuali i.i.d. che seguono la distribuzione Normale standard \\(\\mathcal{N}(0, 1)\\). La variabile casuale chi-quadrato dipende dal parametro intero positivo \\(\\nu = k\\) che ne identifica il numero di gradi di libert√†. La densit√† di probabilit√† di \\(\\chi^2_{~\\nu}\\) √®\n\\[\nf(x) = C_{\\nu} x^{\\nu/2-1} \\exp (-x/2), \\qquad \\text{se } x &gt; 0,\n\\]\ndove \\(C_{\\nu}\\) √® una costante positiva.\nUsiamo la definizione precedente per definire empiricamente la distribuzione della variabile chi-quadrato con 3 gradi di libert√†.\n\n# Impostare il seed per la riproducibilit√†\nset.seed(1234)\n\n# Generare 1000 valori casuali per 3 variabili gaussiane standardizzate\nn &lt;- 1000\nvar1 &lt;- rnorm(n, mean = 0, sd = 1)\nvar2 &lt;- rnorm(n, mean = 0, sd = 1)\nvar3 &lt;- rnorm(n, mean = 0, sd = 1)\n\n# Calcolare la somma dei quadrati delle 3 variabili\nchi_sq_values &lt;- var1^2 + var2^2 + var3^2\n\n# Creare un dataframe per ggplot\ndata &lt;- data.frame(chi_sq_values = chi_sq_values)\n\n# Creare l'istogramma con ggplot\nggplot(data, aes(x = chi_sq_values)) +\n  geom_histogram(\n    aes(y = after_stat(density)), \n    bins = 30, fill = \"lightblue\", color = \"black\", alpha = 0.7\n    ) +\n  stat_function(fun = dchisq, args = list(df = 3), color = \"red\", size = 1) +\n  labs(\n    title = \"Distribuzione Chi-Quadrato (df = 3)\",\n    x = \"Valore\",\n    y = \"Densit√†\"\n  )\n\n\n\n\n\n\n\n\nL‚Äôistogramma descrive i valori empirici; la curva continua rossa √® la distribuzione teorica.\nLa media dei valori empirici √®:\n\nmean(chi_sq_values)\n#&gt; [1] 2.98\n\nLa varianza empirica √®\n\nvar(chi_sq_values)\n#&gt; [1] 5.97\n\n\n35.5.1 Grafico delle Distribuzioni Chi-Quadrato per Vari Valori di \\(\\nu\\)\nIn R, utilizziamo dchisq() per calcolare la funzione di densit√† della distribuzione chi-quadrato e ggplot2 per creare il grafico.\n\n# Intervallo di x\nx &lt;- seq(0, 40, by = 0.1)\n\n# Valori di gradi di libert√†\nnus &lt;- c(2, 4, 8, 16)\n\n# Creazione del data frame per il grafico\ndata &lt;- do.call(rbind, lapply(nus, function(nu) {\n  data.frame(x = x, f_x = dchisq(x, df = nu), nu = as.factor(nu))\n}))\n\n# Grafico\nggplot(data, aes(x = x, y = f_x, color = nu)) +\n  geom_line(size = 1) +\n  labs(\n    title = \"Distribuzioni Chi-Quadrato per Diversi Valori di \\u03bd\",\n    x = \"x\",\n    y = \"f(x)\",\n    color = expression(nu)\n  ) \n\n\n\n\n\n\n\n\n\n\n35.5.2 Propriet√† della Distribuzione Chi-Quadrato\n\nAsimmetria: La distribuzione \\(\\chi^2_{\\nu}\\) √® asimmetrica.\nMedia: Il valore atteso di una variabile \\(\\chi^2_{\\nu}\\) √® uguale a \\(\\nu\\).\nVarianza: La varianza √® pari a \\(2\\nu\\).\nConvergenza: Per \\(k \\to \\infty\\), \\(\\chi^2_{\\nu} \\to \\mathcal{N}(\\nu, 2\\nu)\\).\nSomma di variabili: La somma di variabili \\(\\chi^2_{\\nu}\\) indipendenti con gradi di libert√† diversi segue una distribuzione \\(\\chi^2_{m}\\), dove \\(m\\) √® la somma dei gradi di libert√†.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-t-di-student",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-t-di-student",
    "title": "35¬† Distribuzioni di v.c. continue",
    "section": "35.6 Distribuzione \\(t\\) di Student",
    "text": "35.6 Distribuzione \\(t\\) di Student\nLa distribuzione \\(t\\) di Student deriva dalle distribuzioni Normale e Chi-quadrato, ed √® una delle distribuzioni fondamentali in statistica inferenziale, specialmente per problemi che coinvolgono campioni di dimensioni limitate.\n\n35.6.1 Definizione Formale\nSe \\(Z \\sim \\mathcal{N}(0, 1)\\) (distribuzione Normale standard) e \\(W \\sim \\chi^2_{\\nu}\\) (distribuzione Chi-quadrato con \\(\\nu\\) gradi di libert√†) sono due variabili casuali indipendenti, allora la variabile casuale\n\\[\nT = \\frac{Z}{\\sqrt{\\frac{W}{\\nu}}} ,\n\\]\nsegue una distribuzione \\(t\\) di Student con \\(\\nu\\) gradi di libert√†. Si indica come \\(T \\sim t_{\\nu}\\).\n\n\n35.6.2 Propriet√† della Distribuzione \\(t\\) di Student\n\nForma della distribuzione:\n\nLa distribuzione \\(t\\) √® simile alla distribuzione Normale standard (\\(\\mathcal{N}(0, 1)\\)), ma presenta code pi√π pesanti, che diventano pi√π leggere all‚Äôaumentare di \\(\\nu\\).\nPer \\(\\nu \\to \\infty\\), la distribuzione \\(t\\) converge alla distribuzione Normale standard.\n\nCode pi√π pesanti:\n\nA causa della presenza della variabile Chi-quadrato nel denominatore, la distribuzione \\(t\\) di Student ha una maggiore dispersione rispetto alla Normale.\nLe code pesanti riflettono una maggiore probabilit√† di valori estremi rispetto alla Normale.\n\nMedia e varianza:\n\nLa media √® \\(0\\), come nella Normale.\nLa varianza √® maggiore di \\(1\\) per \\(\\nu &gt; 1\\) ed √® definita come \\(\\frac{\\nu}{\\nu - 2}\\) per \\(\\nu &gt; 2\\). Non √® definita per \\(\\nu \\leq 2\\).\n\nApplicazioni:\n\nLa distribuzione \\(t\\) √® utilizzata per costruire intervalli di confidenza e testare ipotesi quando la varianza della popolazione √® sconosciuta e deve essere stimata dal campione.\n\n\n\n\n\n35.6.3 Differenze tra la Distribuzione \\(t\\) e la Normale\n\n\n\n\n\n\n\n\nCaratteristica\nDistribuzione Normale\nDistribuzione \\(t\\) di Student\n\n\n\n\nForma\nSimmetrica, campana\nSimmetrica, campana\n\n\nCode\nSottili\nPesanti\n\n\nDipendenza dai gradi di libert√†\nNo\nS√¨\n\n\nConvergenza\nNon cambia\nCon \\(\\nu \\to \\infty\\), converge alla Normale\n\n\n\n\n\n\n35.6.4 Visualizzazione della Distribuzione \\(t\\)\nEcco un esempio in R per confrontare graficamente la distribuzione \\(t\\) di Student con diversi gradi di libert√† con la distribuzione Normale standard:\n\n# Creazione dei dati\nx &lt;- seq(-4, 4, length.out = 1000)\ndf &lt;- c(1, 2, 5, 10) # Gradi di libert√†\n\n# Dataframe con curve di densit√†\ndata &lt;- data.frame(\n  x = rep(x, length(df) + 1),\n  density = c(\n    dnorm(x),\n    dt(x, df[1]),\n    dt(x, df[2]),\n    dt(x, df[3]),\n    dt(x, df[4])\n  ),\n  distribution = rep(c(\"Normale\", paste(\"t (df =\", df, \")\")), each = length(x))\n)\n\n# Plot\nggplot(data, aes(x = x, y = density, color = distribution)) +\n  geom_line(size = 1) +\n  labs(\n    title = \"Distribuzione Normale e distribuzioni t di Student\",\n    x = \"Valore\",\n    y = \"Densit√†\",\n    color = \"Distribuzione\"\n  ) \n\n\n\n\n\n\n\n\nIn conclusione, la distribuzione \\(t\\) di Student √® essenziale per le analisi statistiche su piccoli campioni, grazie alla sua capacit√† di gestire l‚Äôincertezza legata alla stima della varianza. Sebbene assomigli alla distribuzione Normale, le sue code pi√π pesanti rendono i test statistici pi√π robusti in condizioni di varianza incerta.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#funzione-beta-di-eulero",
    "href": "chapters/probability/12_cont_rv_distr.html#funzione-beta-di-eulero",
    "title": "35¬† Distribuzioni di v.c. continue",
    "section": "35.7 Funzione Beta di Eulero",
    "text": "35.7 Funzione Beta di Eulero\nLa funzione Beta di Eulero √® una funzione matematica, non una densit√† di probabilit√†. La menzioniamo qui perch√© viene utilizzata nella densit√† di probabilit√† Beta. La funzione Beta di Eulero, comunemente indicata con il simbolo \\(B(\\alpha, \\beta)\\), si pu√≤ scrivere in molti modi diversi; per i nostri scopi la presentiamo cos√¨:\n\\[\n\\mathcal{B}(\\alpha, \\beta) = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)}\\,,\n\\]\ndove \\(\\Gamma(x)\\) √® la funzione Gamma, ovvero il fattoriale discendente, cio√®\n\\[\n(x-1)(x-2)\\ldots (x-n+1)\\notag\\,.\n\\]\nPer esempio, posti \\(\\alpha = 3\\) e \\(\\beta = 9\\), la funzione Beta di Eulero assume il valore:\n\nalpha &lt;- 3\nbeta &lt;- 9\n\nbeta_function &lt;- gamma(alpha) * gamma(beta) / gamma(alpha + beta)\nbeta_function\n#&gt; [1] 0.00202\n\nLo stesso risultato si ottiene usando direttamente la funzione beta in R:\n\nbeta(alpha, beta)\n#&gt; [1] 0.00202\n\nOppure calcolandolo manualmente:\n\n(factorial(alpha - 1) * factorial(beta - 1)) / factorial(alpha + beta - 1)\n#&gt; [1] 0.00202",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-beta",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-beta",
    "title": "35¬† Distribuzioni di v.c. continue",
    "section": "35.8 Distribuzione Beta",
    "text": "35.8 Distribuzione Beta\nLa distribuzione di probabilit√† Beta, denotata comunemente come \\(\\mathcal{Beta}(\\alpha, \\beta)\\), √® utilizzata per modellare fenomeni che sono espressi in percentuali o proporzioni. Un aspetto cruciale di questa distribuzione √® la sua definizione esclusiva nell‚Äôintervallo \\((0, 1)\\). In pratica, ci√≤ significa che essa considera valori compresi strettamente tra 0 e 1, escludendo sia lo 0 che l‚Äô1 come estremi.\n\n35.8.1 Definizione Formale\nConsideriamo una variabile casuale \\(\\theta\\), la quale pu√≤ assumere qualunque valore nell‚Äôintervallo aperto \\((0, 1)\\). Se diciamo che \\(\\theta\\) segue una distribuzione Beta con parametri \\(\\alpha\\) e \\(\\beta\\) (indicato come \\(\\theta \\sim \\mathcal{Beta}(\\alpha, \\beta)\\)), intendiamo che la sua funzione di densit√† √® descritta dalla seguente formula:\n\\[\n\\mathcal{Beta}(\\theta \\mid \\alpha, \\beta) = \\frac{1}{B(\\alpha, \\beta)}\\theta^{\\alpha-1} (1-\\theta)^{\\beta-1} =  \\frac{\\Gamma(\\alpha+ \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}\\theta^{\\alpha-1} (1-\\theta)^{\\beta-1} \\quad \\text{per } \\theta \\in (0, 1)\\,,\n\\]\ndove \\(B(\\alpha, \\beta)\\) √® la funzione beta di Eulero, definita come \\(\\frac{\\Gamma(\\alpha) \\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)}\\).\n\n\n35.8.2 I Parametri \\(\\alpha\\) e \\(\\beta\\)\nI parametri \\(\\alpha\\) e \\(\\beta\\) giocano un ruolo cruciale nella distribuzione Beta, influenzando direttamente la sua forma e il suo comportamento. √à essenziale che entrambi questi parametri siano positivi.\n\n\n35.8.3 Intuizione e Collegamento con la Distribuzione Binomiale\nLa distribuzione Beta pu√≤ essere meglio compresa quando la si osserva in relazione con la distribuzione binomiale. Mentre la distribuzione binomiale modella il numero di successi in una serie di prove, la distribuzione Beta si focalizza sulla probabilit√† di successo in queste prove.\nNel contesto della distribuzione binomiale, la probabilit√† di successo √® un parametro fisso; nella distribuzione Beta, questa probabilit√† diventa una variabile aleatoria.\n\n\n35.8.4 Interpretazione dei Parametri \\(\\alpha\\) e \\(\\beta\\)\nI parametri \\(\\alpha\\) e \\(\\beta\\) possono essere interpretati come rappresentanti il numero di successi e insuccessi, rispettivamente. Questa interpretazione √® analoga ai termini \\(n\\) e \\(n-x\\) nella distribuzione binomiale.\nLa scelta di \\(\\alpha\\) e \\(\\beta\\) dipende dall‚Äôaspettativa iniziale della probabilit√† di successo: - Se si presume un‚Äôalta probabilit√† di successo (ad esempio, 90%), si potrebbe scegliere \\(\\alpha = 90\\) e \\(\\beta = 10\\). - Al contrario, per una bassa aspettativa di successo, si potrebbe impostare \\(\\alpha = 10\\) e \\(\\beta = 90\\).\nUn aumento di \\(\\alpha\\) (successi) sposta la distribuzione verso destra, mentre un aumento di \\(\\beta\\) (insuccessi) la sposta verso sinistra. Inoltre, se sia \\(\\alpha\\) sia \\(\\beta\\) aumentano, la distribuzione diventa pi√π stretta, indicando una maggiore certezza.\nQuesta interpretazione consente di utilizzare la distribuzione Beta per esprimere le nostre credenze a priori riguardo a una sequenza di prove di Bernoulli, dove il rapporto tra successi e tentativi totali √® dato da:\n\\[\n\\frac{\\text{Numero di successi}}{\\text{Numero di successi} + \\text{Numero di insuccessi}} = \\frac{\\alpha}{\\alpha + \\beta}\\notag\\,.\n\\]\nAl variare di \\(\\alpha\\) e \\(\\beta\\) si ottengono molte distribuzioni di forma diversa; un‚Äôillustrazione √® fornita dalla seguente GIF animata.\nLa figura seguente mostra la distribuzione \\(Beta(x \\mid \\alpha, \\beta)\\) per \\(\\alpha\\) = 0.5, 5.0, 1.0, 2.0, 2.0 e \\(\\beta\\) = 5, 1.0, 3.0, 2.0, 5.0.\n\n# Define the parameters\nx &lt;- seq(0, 1, length.out = 200)\nalphas &lt;- c(0.5, 5.0, 1.0, 2.0, 2.0)\nbetas &lt;- c(0.5, 1.0, 3.0, 2.0, 5.0)\n\n# Create a data frame for plotting\ndf &lt;- do.call(rbind, lapply(1:length(alphas), function(i) {\n  data.frame(\n    x = x,\n    density = dbeta(x, alphas[i], betas[i]),\n    label = paste0(\"Œ± = \", alphas[i], \", Œ≤ = \", betas[i])\n  )\n}))\n\nggplot(df, aes(x = x, y = density, color = label)) +\n  geom_line(size = 1) +\n  labs(\n    x = \"x\",\n    y = \"f(x)\",\n    title = \"Distribuzioni Beta\"\n  ) +\n  ylim(0, 4.5) +\n  theme(\n    legend.title = element_blank(),\n    legend.position = \"top\"\n  )\n#&gt; Warning: Removed 6 rows containing missing values or values outside the scale range\n#&gt; (`geom_line()`).\n\n\n\n\n\n\n\n\n\n\n35.8.5 Costante di normalizzazione\nLa relazione \\(\\frac{1}{B(\\alpha, \\beta)} = \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}\\) definisce il reciproco della funzione Beta di Eulero, \\(B(\\alpha, \\beta)\\), come una costante di normalizzazione. Qui, \\(\\Gamma(\\cdot)\\) denota la funzione Gamma di Eulero. Questa costante di normalizzazione garantisce che\n\\[\n\\int_0^1 \\theta^{\\alpha-1} (1-\\theta)^{\\beta-1} d\\theta = 1\\,,\n\\]\nper \\(\\alpha, \\beta &gt; 0\\). Questa integrazione conferma che \\(\\theta^{\\alpha-1} (1-\\theta)^{\\beta-1}\\), quando moltiplicata per la costante di normalizzazione, forma una densit√† di probabilit√† che si estende sull‚Äôintervallo \\([0,1]\\), con l‚Äôarea sottesa dalla curva (l‚Äôintegrale) uguale a 1.\nAd esempio, con \\(\\alpha = 3\\) e \\(\\beta = 9\\), possiamo calcolare il risultato integrando la funzione \\((p^{\\alpha - 1} \\cdot (1 - p)^{\\beta - 1})\\) su \\([0, 1]\\), usando la funzione integrate in R:\n\n# Definizione della funzione da integrare\nintegrand &lt;- function(p, a, b) {\n  p^(a - 1) * (1 - p)^(b - 1)\n}\n\n# Parametri\na &lt;- 3\nb &lt;- 9\n\n# Calcolo dell'integrale\nresult &lt;- integrate(integrand, lower = 0, upper = 1, a = a, b = b)\nresult$value  # Valore dell'integrale\n#&gt; [1] 0.00202\n\nOtteniamo lo stesso risultato calcolando esplicitamente la funzione Beta di Eulero:\n\n# Calcolo usando la funzione Gamma\nresult_gamma &lt;- gamma(a) * gamma(b) / gamma(a + b)\nresult_gamma\n#&gt; [1] 0.00202\n\nOppure utilizzando la funzione beta gi√† disponibile in R:\n\n# Calcolo con la funzione beta\nresult_beta &lt;- beta(a, b)\nresult_beta\n#&gt; [1] 0.00202\n\nQuesti approcci mostrano che i diversi metodi producono lo stesso valore per la funzione Beta di Eulero.\n\n\n35.8.6 Propriet√†\nIl valore atteso, la moda e la varianza di una densit√† di probabilit√† Beta sono dati dalle seguenti equazioni:\n\\[\n\\mathbb{E}(\\theta) = \\frac{\\alpha}{\\alpha+\\beta}\\,,\n\\] (eq-beta-mean)\n\\[\nMo(\\theta) = \\frac{\\alpha-1}{\\alpha+\\beta-2}\\,,\n\\] (eq-beta-mode)\n\\[\n\\mathbb{V}(\\theta) = \\frac{\\alpha \\beta}{(\\alpha+\\beta)^2 (\\alpha+\\beta+1)}\\,.\n\\] (eq-beta-var)\nUsando le formule precedenti, possiamo definire una funzione beta_mean_mode_variance() in R per calcolare la media, la moda e la varianza di una distribuzione di probabilit√† Beta:\n\n# Funzione per calcolare media, moda e varianza della distribuzione Beta\nbeta_mean_mode_variance &lt;- function(alpha, beta) {\n  mean &lt;- alpha / (alpha + beta)\n  mode &lt;- ifelse(alpha &gt; 1 & beta &gt; 1, (alpha - 1) / (alpha + beta - 2), NA) # Moda definita solo per alpha, beta &gt; 1\n  variance &lt;- (alpha * beta) / ((alpha + beta)^2 * (alpha + beta + 1))\n  list(mean = mean, mode = mode, variance = variance)\n}\n\n# Esempio di utilizzo\nalpha &lt;- 7\nbeta &lt;- 3\nresult &lt;- beta_mean_mode_variance(alpha, beta)\n\n# Stampa dei risultati\ncat(sprintf(\"Mean: %.2f, Mode: %.2f, Variance: %.4f\\n\", result$mean, result$mode, result$variance))\n#&gt; Mean: 0.70, Mode: 0.75, Variance: 0.0191\n\n\n\n35.8.7 Risultati\nLa funzione calcola: - Media: \\(\\mu = \\frac{\\alpha}{\\alpha + \\beta}\\), - Moda: \\(\\frac{\\alpha - 1}{\\alpha + \\beta - 2}\\) (definita solo per \\(\\alpha &gt; 1\\) e \\(\\beta &gt; 1\\)), - Varianza: \\(\\frac{\\alpha \\cdot \\beta}{(\\alpha + \\beta)^2 \\cdot (\\alpha + \\beta + 1)}\\).\nSe \\(\\alpha\\) o \\(\\beta\\) sono inferiori o uguali a 1, la moda non √® definita.\n\n\n35.8.8 Distribuzione a priori coniugata\nLa distribuzione Beta rappresenta una prior coniugata ottimale per una gamma di distribuzioni legate a eventi di successo e fallimento, quali le distribuzioni Bernoulli, Binomiale, Binomiale Negativa e Geometrica, nell‚Äôambito dell‚Äôinferenza Bayesiana. Questa caratteristica di prior coniugata rende il calcolo della distribuzione a posteriori particolarmente efficiente, poich√© permette di bypassare onerose computazioni numeriche tipicamente associate all‚Äôinferenza Bayesiana.\nPrendiamo, ad esempio, il caso in cui la distribuzione Beta, espressa come Beta(Œ±, Œ≤), venga adottata come prior nel contesto di una distribuzione Binomiale. Questa scelta metodologica ci assicura che la distribuzione a posteriori manterr√† la forma funzionale della distribuzione Beta. Ci√≤ significa che, una volta raccolti i dati, l‚Äôaggiornamento a posteriori pu√≤ essere eseguito semplicemente aggiungendo il numero di successi osservati (x) e il numero di fallimenti (n-x) ai parametri Œ± e Œ≤ del prior, rispettivamente. In tal modo, si ottiene una distribuzione a posteriori Beta con parametri aggiornati (Œ±+x, Œ≤+n-x), senza la necessit√† di compiere la moltiplicazione tra la funzione di verosimiglianza e il prior.\n\n\n\n\n\n\n√à importante prestare attenzione all‚Äôuso del termine ‚ÄúBeta‚Äù in questo contesto, poich√© assume significati differenti a seconda del riferimento: - La distribuzione Beta, che descrive una distribuzione di probabilit√† continua. - La funzione Beta, una funzione matematica speciale. - Il parametro Œ≤, che insieme ad Œ±, definisce i parametri specifici della distribuzione Beta.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-di-cauchy",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-di-cauchy",
    "title": "35¬† Distribuzioni di v.c. continue",
    "section": "35.9 Distribuzione di Cauchy",
    "text": "35.9 Distribuzione di Cauchy\nLa distribuzione di Cauchy √® un caso speciale della distribuzione di \\(t\\) di Student con 1 grado di libert√†. √à definita da una densit√† di probabilit√† che corrisponde alla seguente funzione, dipendente da due parametri \\(\\alpha\\) e \\(\\beta\\),\n\\[\nf(x \\mid \\alpha, \\beta) = \\frac{1}{\\pi \\beta \\left[1 + \\left( \\frac{x - \\alpha}{\\beta} \\right)^2\\right]}.\n\\tag{35.3}\\]\nIl grafico mostra alcune distribuzioni di Cauchy con \\(\\alpha\\) = 0., 0., 0., -2.0 e \\(\\beta\\) = .5, 1., 2., 1.0.\n\n# Definire i parametri\nx &lt;- seq(-5, 5, length.out = 500)\nalphas &lt;- c(0.0, 0.0, 0.0, -2.0)\nbetas &lt;- c(0.5, 1.0, 2.0, 1.0)\n\n# Creare un data frame per i risultati\ndf &lt;- do.call(rbind, lapply(1:length(alphas), function(i) {\n  data.frame(\n    x = x,\n    density = dcauchy(x, location = alphas[i], scale = betas[i]),\n    label = paste0(\"Œ± = \", alphas[i], \", Œ≤ = \", betas[i])\n  )\n}))\n\nggplot(df, aes(x = x, y = density, color = label)) +\n  geom_line(size = 1) +\n  labs(\n    x = \"x\",\n    y = \"f(x)\",\n    title = \"Distribuzioni di Cauchy con diversi parametri\"\n  ) +\n  theme(\n    legend.title = element_blank(),\n    legend.position = \"top\"\n  )",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-gamma",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-gamma",
    "title": "35¬† Distribuzioni di v.c. continue",
    "section": "35.10 Distribuzione Gamma",
    "text": "35.10 Distribuzione Gamma\nLa distribuzione Gamma √® ampiamente utilizzata nella statistica bayesiana come distribuzione a priori per parametri che sono strettamente positivi, come tassi o varianze. √à particolarmente utile nella modellazione di variabili che rappresentano tempi di attesa o qualsiasi altra quantit√† che pu√≤ assumere solo valori positivi. La densit√† di probabilit√† Gamma gioca un ruolo fondamentale nella modellazione del tempo di attesa per l‚Äôoccorrenza di un certo numero di eventi indipendenti e rari, rendendola adatta per processi di Poisson generalizzati.\nLa distribuzione Gamma pu√≤ essere vista come una generalizzazione della distribuzione esponenziale. Pi√π precisamente, la distribuzione esponenziale √® un caso speciale della distribuzione Gamma. Se sommiamo \\(n\\) variabili casuali indipendenti, ciascuna delle quali segue una distribuzione esponenziale con parametro \\(\\lambda\\), il risultato segue una distribuzione Gamma con parametri \\(n\\) (numero di variabili sommate) e \\(\\lambda\\) (tasso esponenziale). Questo si formalizza come:\n\\[\n\\text{Gamma}(n, \\lambda) = \\sum_{i=1}^n \\text{Esponenziale}(\\lambda).\n\\]\nIn particolare, la distribuzione Gamma con parametro di forma 1, ovvero \\(\\text{Gamma}(1, \\lambda)\\), corrisponde esattamente a una distribuzione esponenziale con parametro \\(\\lambda\\), cio√®:\n\\[\n\\text{Gamma}(1, \\lambda) = \\text{Esponenziale}(\\lambda).\n\\]\nLa distribuzione Gamma √® anche legata alla distribuzione normale in alcuni contesti. Sebbene non vi sia una relazione diretta e semplice tra una distribuzione Gamma e una normale, un caso specifico √® quando il parametro di forma \\(n\\) √® molto grande (cio√® \\(n \\to \\infty\\)). In questo caso, la distribuzione Gamma pu√≤ essere approssimata da una distribuzione normale tramite il teorema del limite centrale. Pi√π precisamente, quando \\(n\\) √® grande, una Gamma di parametri \\(n\\) e \\(\\lambda\\) converge approssimativamente a una normale con media \\(n/\\lambda\\) e varianza \\(n/\\lambda^2\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#parametrizzazione",
    "href": "chapters/probability/12_cont_rv_distr.html#parametrizzazione",
    "title": "35¬† Distribuzioni di v.c. continue",
    "section": "35.11 Parametrizzazione",
    "text": "35.11 Parametrizzazione\nLa distribuzione Gamma √® caratterizzata da due parametri principali: \\(\\alpha\\) e \\(\\beta\\), noti rispettivamente come parametro di forma e parametro di tasso (o, alternativamente, si pu√≤ usare \\(\\theta = \\frac{1}{\\beta}\\), il parametro di scala).\n\n35.11.1 Parametro di forma (\\(\\alpha\\))\nIl parametro di forma, \\(\\alpha\\), determina la forma generale della curva della distribuzione:\n\nSe \\(\\alpha = 1\\), la distribuzione Gamma si riduce a una distribuzione esponenziale, con la funzione di densit√† \\(f(x) = \\beta e^{-\\beta x}\\).\nSe \\(\\alpha &gt; 1\\), la distribuzione presenta un picco (modalit√†) attorno a \\((\\alpha - 1) \\cdot \\theta\\), indicando una distribuzione pi√π concentrata attorno a un valore medio.\nSe \\(\\alpha &lt; 1\\), la distribuzione √® inclinata verso destra, con una coda lunga che si estende verso valori pi√π bassi, mostrando una maggiore probabilit√† di valori piccoli di \\(x\\).\n\nIl parametro \\(\\alpha\\) pu√≤ essere interpretato come il numero di ‚Äúeventi‚Äù che ci si aspetta si verifichino prima di raggiungere un certo tempo di attesa, in contesti di modelli di Poisson generalizzati. Ad esempio, se la distribuzione Gamma modella il tempo di attesa per l‚Äôarrivo di un certo numero di eventi, \\(\\alpha\\) indica il numero di eventi attesi.\nMan mano che \\(\\alpha\\) aumenta, la distribuzione si sposta verso destra e diventa pi√π simmetrica. Per valori alti di \\(\\alpha\\), la distribuzione Gamma si avvicina a una distribuzione normale.\n\n\n35.11.2 Parametro di scala (\\(\\theta\\)) o tasso (\\(\\beta\\))\nIl parametro \\(\\theta\\) (o, alternativamente, \\(\\beta\\)) controlla la scala temporale o la larghezza della distribuzione:\n\nIl parametro di scala \\(\\theta\\) √® inversamente proporzionale al parametro di tasso \\(\\beta\\). Un valore pi√π grande di \\(\\theta\\) (o un valore pi√π piccolo di \\(\\beta\\)) produce una curva pi√π piatta, indicando una maggiore variabilit√† (dispersione) nel tempo di attesa.\nUn valore pi√π piccolo di \\(\\theta\\) (o pi√π grande di \\(\\beta\\)) rende la curva pi√π appuntita, indicando una minore variabilit√†.\n\nNel contesto del tempo di attesa, \\(\\theta\\) agisce come un fattore di scala: un valore grande di \\(\\theta\\) indica un periodo di tempo pi√π lungo tra gli eventi, mentre un valore piccolo di \\(\\theta\\) indica un periodo di tempo pi√π breve.\n\n\n35.11.3 Formula della funzione di densit√† di probabilit√†\nLa funzione di densit√† di probabilit√† (PDF) della distribuzione Gamma √® data da:\n\\[\nf(x \\mid \\alpha, \\theta) = \\frac{x^{\\alpha-1} e^{-\\frac{x}{\\theta}}}{\\theta^\\alpha \\Gamma(\\alpha)},\n\\]\ndove:\n\n\\(x\\) √® la variabile casuale continua, con \\(x &gt; 0\\),\n\\(\\alpha\\) √® il parametro di forma,\n\\(\\theta\\) √® il parametro di scala (alternativamente si pu√≤ usare \\(\\beta = \\frac{1}{\\theta}\\), il parametro di tasso),\n\\(\\Gamma(\\alpha)\\) √® la funzione Gamma di Eulero, che generalizza il fattoriale per numeri reali e complessi. Per numeri interi \\(n\\), si ha \\(\\Gamma(n) = (n-1)!\\), ma per argomenti generali \\(\\alpha\\), la funzione Gamma √® definita come:\n\n\\[\n\\Gamma(\\alpha) = \\int_0^\\infty x^{\\alpha-1} e^{-x} dx.\n\\]\n\n\n35.11.4 Media e varianza della distribuzione Gamma\nLe espressioni per la media e la varianza della distribuzione Gamma in funzione di \\(\\alpha\\) e \\(\\theta\\) (o \\(\\beta\\)) sono:\n\nMedia (\\(\\mu\\)):\n\n\\[\n\\mu = \\alpha \\cdot \\theta = \\frac{\\alpha}{\\beta}.\n\\]\n\nVarianza (\\(\\sigma^2\\)): \\[\n\\sigma^2 = \\alpha \\cdot \\theta^2 = \\frac{\\alpha}{\\beta^2}.\n\\]\n\nIn sintesi, il parametro di forma \\(\\alpha\\) controlla la forma generale della distribuzione, mentre il parametro di scala \\(\\theta\\) (o tasso \\(\\beta\\)) regola la dispersione o variabilit√†. Questa parametrizzazione √® largamente utilizzata, in particolare nella statistica bayesiana, dove la distribuzione Gamma pu√≤ servire da distribuzione a priori per parametri positivi, come varianze o tassi di processi stocastici.\nPer esempio, qui √® riportata la distribuzione Gamma di parametri \\(\\alpha\\) = 3 e \\(\\beta\\) = 5/3.\n\n\n35.11.5 Calcolo della Media e della Deviazione Standard per la Distribuzione Gamma\nLa distribuzione Gamma √® definita dai parametri \\(\\alpha\\) (shape) e \\(\\beta\\) (rate). La media e la deviazione standard della distribuzione possono essere calcolate come segue:\n\nMedia: \\(\\mu = \\frac{\\alpha}{\\beta}\\)\nDeviazione Standard: \\(\\sigma = \\sqrt{\\frac{\\alpha}{\\beta^2}}\\)\n\n\n35.11.5.1 Calcolo in R\n\n# Parametri della distribuzione Gamma\nalpha &lt;- 3\nbeta &lt;- 5 / 3\n\n# Calcolo della media\nmean &lt;- alpha / beta\ncat(\"Mean:\", mean, \"\\n\")\n#&gt; Mean: 1.8\n\n# Calcolo della deviazione standard\nsigma &lt;- sqrt(alpha / beta^2)\ncat(\"Standard Deviation:\", sigma, \"\\n\")\n#&gt; Standard Deviation: 1.04\n\n\n\n\n35.11.6 Generazione di Dati dalla Distribuzione Gamma e Visualizzazione\n\n35.11.6.1 Generazione di dati\nIn R, possiamo utilizzare la funzione rgamma() per generare dati da una distribuzione Gamma specificando i parametri shape (\\(\\alpha\\)) e rate (\\(\\beta\\)).\n\n\n35.11.6.2 Plot della Distribuzione\n\n# Generazione di dati\nset.seed(123)  # Per riproducibilit√†\ndata &lt;- rgamma(100000, shape = alpha, rate = beta)\n\n# Creazione di un data frame per ggplot\ndf &lt;- data.frame(values = data)\n\n# Istogramma dei dati generati\nggplot(df, aes(x = values)) +\n  geom_histogram(aes(y = ..density..), bins = 30, fill = \"green\", alpha = 0.6) +\n  stat_function(fun = function(x) dgamma(x, shape = alpha, rate = beta),\n                color = \"red\", size = 1, linetype = \"solid\") +\n  labs(\n    x = \"Valore\",\n    y = \"Densit√† di probabilit√†\",\n    title = \"Distribuzione Gamma con Œ±=3 e Œ≤=5/3\"\n  ) \n#&gt; Warning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\n#&gt; ‚Ñπ Please use `after_stat(density)` instead.\n\n\n\n\n\n\n\n\nSpiegazione del Codice.\n\nCalcolo della media e della deviazione standard:\n\nLa media √® calcolata come il rapporto tra i parametri \\(\\alpha\\) e \\(\\beta\\).\nLa deviazione standard √® la radice quadrata del rapporto tra \\(\\alpha\\) e \\(\\beta^2\\).\n\nGenerazione dei dati:\n\nrgamma(n, shape, rate) genera \\(n\\) osservazioni dalla distribuzione Gamma specificata.\n\nVisualizzazione:\n\nL‚Äôistogramma rappresenta i dati generati.\nLa funzione dgamma(x, shape, rate) calcola la densit√† teorica, che viene tracciata sopra l‚Äôistogramma per confrontare i dati simulati con la distribuzione teorica.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-esponenziale-1",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-esponenziale-1",
    "title": "35¬† Distribuzioni di v.c. continue",
    "section": "35.12 Distribuzione Esponenziale",
    "text": "35.12 Distribuzione Esponenziale\nLa distribuzione esponenziale √® una distribuzione di probabilit√† continua che descrive la ‚Äúdurata di vita‚Äù di un fenomeno che non invecchia (ossia la distribuzione esponenziale √® priva di memoria).\nLa distribuzione esponenziale (o di Laplace) pu√≤ anche essere ricavata come la distribuzione di probabilit√† di una variabile aleatoria definita come somma dei quadrati di due variabili aleatorie normali standardizzate (ossia con valore atteso zero e varianza unitaria); dunque √® riconducibile a un caso particolare di distribuzione del chi-quadro, essendo, quest‚Äôultima, la distribuzione di probabilit√† della variabile aleatoria costruita come la somma dei quadrati di \\(n\\) variabili aleatorie indipendenti normali e standardizzate.\nLa distribuzione esponenziale con parametro \\({\\displaystyle \\lambda &gt;0}\\), ha funzione di densit√† di probabilit√†:\n\\[\n{\\displaystyle f(x;\\lambda )={\\begin{cases}\\lambda e^{-\\lambda x}&x&gt;0,\\\\0&x\\leq 0.\\end{cases}}}.\n\\]\nUna variabile aleatoria con distribuzione esponenziale di parametro \\({\\displaystyle \\lambda }\\) ha\n\nvalore atteso \\({\\displaystyle E[X]=1/\\lambda }\\),\nvarianza \\({\\displaystyle {\\text{Var}}(X)=1/\\lambda ^{2}}.\\)\n\nPer fare un esempio, consideriamo il punteggio totale della scala psicologica di Kessler (K6), una misura standardizzata utilizzata dal NHIS per lo screening del disagio psicologico. La K6 include sei item relativi alla sintomatologia depressiva e ansiosa e valuta il disagio psicologico aspecifico degli ultimi 30 giorni. Gli item sono valutati su una scala Likert a 5 punti, che va da ‚Äúmai‚Äù (=0) a ‚Äúsempre‚Äù (=4). I punteggi totali variano da 0 a 24. Secondo Tomitaka et al. (2019), il punteggio totale della K6 segue una distribuzione esponenziale, con punteggi di cut-off per disagio psicologico moderato e grave corrispondenti a punteggi di 5 e 13, rispettivamente. Dallo studio emerge che il punteggio medio del totale della K6 nella popolazione americana √® di 2.5. La corrispondente distribuzione esponenziale √® rappresentata di seguito.\n\n# Parametri della distribuzione Esponenziale\nmean &lt;- 2.5\nlambda &lt;- 1 / mean  # Lambda √® l'inverso della media\n\n# Creazione del vettore x\nx &lt;- seq(0.001, 22, length.out = 100)\n\n# Calcolo della densit√†\npdf &lt;- dexp(x, rate = lambda)\n\n# Creazione del data frame per ggplot\ndf &lt;- data.frame(x = x, pdf = pdf)\n\n# Tracciamento del grafico\nlibrary(ggplot2)\nggplot(df, aes(x = x, y = pdf)) +\n  geom_line(color = \"blue\", size = 1) +\n  labs(\n    x = \"x\",\n    y = \"f(x)\",\n    title = \"Distribuzione Esponenziale\"\n  ) +\n  annotate(\"text\", x = 10, y = max(pdf)/2, label = paste0(\"Œª = \", round(lambda, 2)), size = 5, color = \"blue\")",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#riflessioni-conclusive-in-r",
    "href": "chapters/probability/12_cont_rv_distr.html#riflessioni-conclusive-in-r",
    "title": "35¬† Distribuzioni di v.c. continue",
    "section": "35.13 Riflessioni Conclusive in R",
    "text": "35.13 Riflessioni Conclusive in R\nLa statistica bayesiana utilizza le distribuzioni di probabilit√† per la stima dei parametri e dell‚Äôincertezza. Possiamo considerare le distribuzioni di probabilit√† come ‚Äúmattoncini‚Äù con cui costruire modelli statistici, dai pi√π semplici ai pi√π complessi. R offre strumenti per generare campioni casuali e calcolare densit√†, probabilit√† cumulate, e quantili per molte distribuzioni di probabilit√†.\n\n35.13.1 Generazione di Campioni\nIn R, possiamo generare campioni da diverse distribuzioni utilizzando le funzioni rnorm, runif, rt, rbeta, e rgamma. Ad esempio:\nDistribuzione Normale:\nset.seed(42)  # Per garantire la riproducibilit√†\nmedia &lt;- 0\ndeviazione_standard &lt;- 1\ncampione_normale &lt;- rnorm(100, mean = media, sd = deviazione_standard)\nDistribuzione Uniforme:\na &lt;- 0\nb &lt;- 10\ncampione_uniforme &lt;- runif(100, min = a, max = b)\nDistribuzione t di Student:\ngradi_libert√† &lt;- 10\ncampione_t &lt;- rt(100, df = gradi_libert√†)\nDistribuzione Beta:\nalpha &lt;- 2\nbeta_param &lt;- 5\ncampione_beta &lt;- rbeta(100, shape1 = alpha, shape2 = beta_param)\nDistribuzione Gamma:\nforma &lt;- 2\nscala &lt;- 1\ncampione_gamma &lt;- rgamma(100, shape = forma, rate = 1 / scala)\n\n\n35.13.1.1 Calcolo della Densit√†\nPossiamo calcolare la densit√† utilizzando le funzioni dnorm, dunif, dt, dbeta, e dgamma. Ad esempio:\nDistribuzione Normale:\nx &lt;- seq(media - 4 * deviazione_standard, media + 4 * deviazione_standard, length.out = 100)\npdf_normale &lt;- dnorm(x, mean = media, sd = deviazione_standard)\nDistribuzione Uniforme:\nx &lt;- seq(a, b, length.out = 100)\npdf_uniforme &lt;- dunif(x, min = a, max = b)\nDistribuzione t di Student:\nx &lt;- seq(-5, 5, length.out = 100)\npdf_t &lt;- dt(x, df = gradi_libert√†)\nDistribuzione Beta:\nx &lt;- seq(0, 1, length.out = 100)\npdf_beta &lt;- dbeta(x, shape1 = alpha, shape2 = beta_param)\nDistribuzione Gamma:\nx &lt;- seq(0, 10, length.out = 100)\npdf_gamma &lt;- dgamma(x, shape = forma, rate = 1 / scala)\n\n\n\n35.13.1.2 Calcolo dei Quantili\nI quantili si calcolano con le funzioni qnorm, qunif, qt, qbeta, e qgamma. Ad esempio:\nDistribuzione Normale:\nprobabilit√† &lt;- 0.5\nquantile_normale &lt;- qnorm(probabilit√†, mean = media, sd = deviazione_standard)\nDistribuzione Uniforme:\nquantile_uniforme &lt;- qunif(probabilit√†, min = a, max = b)\nDistribuzione t di Student:\nquantile_t &lt;- qt(probabilit√†, df = gradi_libert√†)\nDistribuzione Beta:\nquantile_beta &lt;- qbeta(probabilit√†, shape1 = alpha, shape2 = beta_param)\nDistribuzione Gamma:\nquantile_gamma &lt;- qgamma(probabilit√†, shape = forma, rate = 1 / scala)\n\n\n\n35.13.1.3 Calcolo delle Probabilit√† Cumulate\nLe probabilit√† cumulate si calcolano con le funzioni pnorm, punif, pt, pbeta, e pgamma. Ad esempio:\nDistribuzione Normale:\nquantile &lt;- 0\nprobabilit√†_normale &lt;- pnorm(quantile, mean = media, sd = deviazione_standard)\nDistribuzione Uniforme:\nprobabilit√†_uniforme &lt;- punif(quantile, min = a, max = b)\nDistribuzione t di Student:\nprobabilit√†_t &lt;- pt(quantile, df = gradi_libert√†)\nDistribuzione Beta:\nprobabilit√†_beta &lt;- pbeta(quantile, shape1 = alpha, shape2 = beta_param)\nDistribuzione Gamma:\nprobabilit√†_gamma &lt;- pgamma(quantile, shape = forma, rate = 1 / scala)\n\nCon questi strumenti, R consente di generare, visualizzare e analizzare campioni da una vasta gamma di distribuzioni di probabilit√†, fornendo un potente supporto all‚Äôinferenza bayesiana e alla modellazione statistica.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#esercizi",
    "href": "chapters/probability/12_cont_rv_distr.html#esercizi",
    "title": "35¬† Distribuzioni di v.c. continue",
    "section": "35.14 Esercizi",
    "text": "35.14 Esercizi\n\nEsercizio 35.1 Per ciascuna delle distribuzioni di massa di probabilit√† discusse, utilizza R per:\n\ncreare un grafico della funzione, scegliendo opportunamente i parametri;\nestrarre un campione di 1000 valori casuali dalla distribuzione e visualizzarlo con un istogramma;\ncalcolare la media e la deviazione standard dei campioni e confrontarle con i valori teorici attesi;\nstimare l‚Äôintervallo centrale del 94% utilizzando i campioni simulati;\ndeterminare i quantili della distribuzione per gli ordini 0.05, 0.25, 0.75 e 0.95;\nscegliendo un valore della distribuzione pari alla media pi√π una deviazione standard, calcolare la probabilit√† che la variabile aleatoria assuma un valore minore o uguale a questo valore.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/12_cont_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "title": "35¬† Distribuzioni di v.c. continue",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: US/Pacific\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] ggokabeito_0.1.0 see_0.9.0        gridExtra_2.3    patchwork_1.3.0 \n#&gt;  [5] bayesplot_1.11.1 psych_2.4.12     scales_1.3.0     markdown_1.13   \n#&gt;  [9] knitr_1.49       lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1   \n#&gt; [13] dplyr_1.1.4      purrr_1.0.2      readr_2.1.5      tidyr_1.3.1     \n#&gt; [17] tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3       \n#&gt; [21] here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.3         rlang_1.1.4       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       yaml_2.3.10       tools_4.4.2       parallel_4.4.2   \n#&gt; [21] tzdb_0.4.0        colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5      \n#&gt; [25] R6_2.5.1          lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3  \n#&gt; [29] pillar_1.10.1     gtable_0.3.6      glue_1.8.0        xfun_0.50        \n#&gt; [33] tidyselect_1.2.1  farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-166     \n#&gt; [37] labeling_0.4.3    rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#bibliografia",
    "href": "chapters/probability/12_cont_rv_distr.html#bibliografia",
    "title": "35¬† Distribuzioni di v.c. continue",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlitzstein, J. K., & Hwang, J. (2019). Introduction to probability. CRC Press.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nTomitaka, S., Kawasaki, Y., Ide, K., Akutagawa, M., Ono, Y., & Furukawa, T. A. (2019). Distribution of psychological distress is stable in recent decades and follows an exponential pattern in the US population. Scientific reports, 9(1), 11982.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_gauss.html",
    "href": "chapters/probability/13_gauss.html",
    "title": "36¬† Assunzione di gaussianit√† e trasformazioni dei dati",
    "section": "",
    "text": "36.1 Introduzione\nNell‚Äôanalisi dei dati numerici, un aspetto cruciale da affrontare √® l‚Äôimprecisione delle misurazioni, una caratteristica intrinseca dei dati reali. Anche in condizioni ottimali, le misure sono soggette a incertezze: i dati rappresentano sempre una stima approssimativa della realt√†, accurata solo entro un certo margine (ad esempio, pochi punti percentuali). Inoltre, in molti contesti, come quelli demografici, commerciali o sociali, i dati possono essere arrotondati intenzionalmente o risultare imprecisi a causa di stime indirette, incompletezza delle informazioni o altri fattori.\nRiconoscere e gestire questa incertezza √® una componente essenziale del processo analitico. Gli strumenti statistici forniscono un framework formale per descrivere e quantificare l‚Äôincertezza, consentendo di trarre inferenze robuste dai dati. Tra le distribuzioni di probabilit√†, la distribuzione normale (o gaussiana) occupa un posto centrale per la sua ubiquit√† e versatilit√†. Spesso rappresentata dalla caratteristica ‚Äúcurva a campana,‚Äù questa distribuzione √® utilizzata per descrivere molte variabili naturali. Quando i dati approssimano una distribuzione normale, gran parte dei valori si concentra intorno alla media, con una diminuzione progressiva della probabilit√† di valori estremi.\nUna delle propriet√† pi√π utili della distribuzione normale √® la possibilit√† di esprimere affermazioni quantitative rigorose. Ad esempio, si pu√≤ calcolare la probabilit√† che un valore cada entro un determinato intervallo dalla media utilizzando parametri semplici come media (\\(\\mu\\)) e deviazione standard (\\(\\sigma\\)):\npnorm(1) - pnorm(-1)\n#&gt; [1] 0.683\npnorm(3) - pnorm(-3)\n#&gt; [1] 0.997\nQuesti calcoli costituiscono la base della ‚Äúregola delle tre sigma,‚Äù una strategia utilizzata per identificare valori anomali (outlier), come discusso nel Capitolo 23. Tuttavia, tale regola pu√≤ risultare fuorviante se i dati non seguono effettivamente una distribuzione normale.\nLa densit√† della distribuzione normale √® definita dalla formula:\n\\[\np(x) = \\frac{1}{\\sqrt{2\\pi}\\,\\sigma} \\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right),\n\\]\ndove \\(\\mu\\) rappresenta la media e \\(\\sigma\\) la deviazione standard. Conoscere questi due parametri permette di calcolare propriet√† fondamentali della distribuzione e di stimare probabilit√† associate a intervalli specifici.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>36</span>¬† <span class='chapter-title'>Assunzione di gaussianit√† e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_gauss.html#introduzione",
    "href": "chapters/probability/13_gauss.html#introduzione",
    "title": "36¬† Assunzione di gaussianit√† e trasformazioni dei dati",
    "section": "",
    "text": "Circa il 68.3% dei valori cade entro una deviazione standard dalla media:\n\n\n\nCirca il 99.7% cade entro tre deviazioni standard:\n\n\n\n\n\n\n\n36.1.1 Gaussianit√† e Inferenza Statistica\nLa distribuzione normale √® particolarmente rilevante per molti metodi statistici, in particolare nell‚Äôapproccio frequentista. Gran parte dei test di ipotesi e delle procedure inferenziali assume che i dati siano distribuiti normalmente, una condizione necessaria per derivare formalmente i risultati di molti test. Ad esempio, i test t di Student e l‚ÄôANOVA richiedono la normalit√† delle variabili o dei residui. Quando questa assunzione √® soddisfatta, tali strumenti offrono inferenze precise e affidabili.\nTuttavia, se i dati non sono gaussiani, molti test perdono validit√†. Sebbene si siano proposti approcci che dimostrano la robustezza di alcuni test a deviazioni moderate dalla normalit√† (Shatz, 2024), tale robustezza non √® garantita in tutte le situazioni. Inoltre, l‚Äôenfasi sui valori-p complica la questione, poich√© violazioni dell‚Äôassunzione di normalit√† possono compromettere l‚Äôinterpretazione di questi indicatori.\nUna strategia comune per affrontare la non-gaussianit√† √® l‚Äôapplicazione di trasformazioni dei dati, come la trasformazione logaritmica o quella della radice quadrata, per avvicinare i dati alla distribuzione normale (Osborne, 2002). Ad esempio, distribuzioni asimmetriche come quelle dei tempi di reazione possono essere rese pi√π gaussiane attraverso trasformazioni adeguate, rendendo applicabili i test frequentisti standard. Tuttavia, l‚Äôuso delle trasformazioni ha un costo: la perdita di interpretabilit√†. Se i dati originali avevano un significato chiaro e intuitivo, la trasformazione pu√≤ rendere i risultati pi√π difficili da collegare al fenomeno studiato.\nIn questo capitolo, esploreremo come verificare se i dati seguono una distribuzione normale, discuteremo l‚Äôimpatto di questa assunzione sui metodi frequentisti e valuteremo il ruolo delle trasformazioni. Il nostro obiettivo √® fornire al data analyst una guida pratica per decidere come trattare i dati non gaussiani, considerando sia i vantaggi che i limiti di ciascun approccio.\n\n\n36.1.2 L‚Äôassunzione di Gaussianit√†: Quando √® valida?\nSebbene la distribuzione normale sia spesso un buon modello per i dati numerici, non √® sempre una rappresentazione adeguata. Questo pu√≤ dipendere da caratteristiche intrinseche dei dati, come asimmetrie, code lunghe o la presenza di valori anomali. Valutare l‚Äôappropriatezza dell‚Äôassunzione di normalit√† √® un passaggio critico in qualsiasi analisi statistica.\nPer diagnosticare la normalit√†, presenteremo tre strumenti grafici:\n\nIstogrammi, una visualizzazione semplice ma spesso limitata.\nGrafici di densit√†, che forniscono un confronto pi√π fluido rispetto agli istogrammi.\nQQ-plot (Quantile-Quantile plot), uno strumento visivo particolarmente efficace per rilevare deviazioni dalla normalit√†.\n\nQuesti strumenti possono anche essere affiancati da test formali per consentire una diagnosi robusta e guidare le decisioni sul trattamento dei dati.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>36</span>¬† <span class='chapter-title'>Assunzione di gaussianit√† e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_gauss.html#istogramma",
    "href": "chapters/probability/13_gauss.html#istogramma",
    "title": "36¬† Assunzione di gaussianit√† e trasformazioni dei dati",
    "section": "36.2 Istogramma",
    "text": "36.2 Istogramma\nPer illustrare il concetto, utilizziamo un set di dati simulati che hanno propriet√† simili a quelle dei tempi di reazione. Creeremo un istogramma e vi sovrapporremo la curva di densit√† normale calcolata in base ai dati.\n\n# Dati simulati di tempi di reazione\nset.seed(123)\nrt &lt;- c(rexp(100, rate = 0.2), 50, 60) # Aggiunti valori estremi\n\n# Calcolare la media e la deviazione standard per sovrapporre la densit√† normale\nmean_rt &lt;- mean(rt, na.rm = TRUE)\nsd_rt &lt;- sd(rt, na.rm = TRUE)\n\n# Creare l'istogramma e sovrapporre la densit√† normale\nggplot(tibble(rt=rt), aes(x = rt)) +\n  geom_histogram(\n    aes(y = ..density..),\n    bins = 30, color = \"black\"\n  ) +\n  stat_function(\n    fun = dnorm,\n    args = list(mean = mean_rt, sd = sd_rt),\n    size = 1\n  ) +\n  labs(\n    title = \"Istogramma dei Tempi di Reazione\\ne Densit√† Normale\",\n    x = \"Tempi di Reazione\",\n    y = \"Densit√†\"\n  )\n#&gt; Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#&gt; ‚Ñπ Please use `linewidth` instead.\n#&gt; Warning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\n#&gt; ‚Ñπ Please use `after_stat(density)` instead.\n\n\n\n\n\n\n\n\nL‚Äôistogramma mostra la distribuzione empirica dei dati, mentre la curva rossa rappresenta la densit√† normale con la stessa media e deviazione standard. Nel nostro caso, √® evidente una discrepanza tra la distribuzione empirica e la densit√† normale, indicando che l‚Äôassunzione di normalit√† non √® appropriata.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>36</span>¬† <span class='chapter-title'>Assunzione di gaussianit√† e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_gauss.html#grafico-di-densit√†",
    "href": "chapters/probability/13_gauss.html#grafico-di-densit√†",
    "title": "36¬† Assunzione di gaussianit√† e trasformazioni dei dati",
    "section": "36.3 Grafico di densit√†",
    "text": "36.3 Grafico di densit√†\nUn grafico di densit√† √® una versione lisciata dell‚Äôistogramma che facilita il confronto con la distribuzione normale. Utilizzando il dataset precedente, possiamo creare un grafico di densit√† sovrapposto alla curva gaussiana.\n\nggplot(tibble(rt=rt), aes(x = rt)) +\n  geom_density(alpha = 0.5) +\n  stat_function(\n    fun = dnorm,\n    args = list(mean = mean_rt, sd = sd_rt),\n    size = 1\n  ) +\n  labs(\n    title = \"Grafico di Densit√† del Peso dei Pulcini e\\nDensit√† Normale\",\n    x = \"Peso\",\n    y = \"Densit√†\"\n  )\n\n\n\n\n\n\n\n\nAnche questa rappresentazione rende chiaro come l‚Äôassunzione di normalit√† non sia appropriata.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>36</span>¬† <span class='chapter-title'>Assunzione di gaussianit√† e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_gauss.html#diagramma-quantile-quantile",
    "href": "chapters/probability/13_gauss.html#diagramma-quantile-quantile",
    "title": "36¬† Assunzione di gaussianit√† e trasformazioni dei dati",
    "section": "36.4 Diagramma quantile-quantile",
    "text": "36.4 Diagramma quantile-quantile\nIl diagramma quantile-quantile (QQ-plot) √® lo strumento pi√π utile per analizzare visivamente la conformit√† di un dataset a una distribuzione teorica, in particolare alla distribuzione normale. Il QQ-plot √® una tecnica essenziale per chi lavora con dati che si presume seguano una distribuzione specifica, e rappresenta un passaggio cruciale in molte analisi statistiche, soprattutto per verificare l‚Äôassunto di normalit√†.\nUn QQ-plot permette di:\n\nValutare graficamente la normalit√† dei dati: Se i punti nel diagramma seguono approssimativamente una linea retta, i dati possono essere considerati normalmente distribuiti. In caso contrario, il QQ-plot rivela deviazioni dalla normalit√†, come code pesanti o asimmetrie.\nConfrontare distribuzioni: Il QQ-plot non si limita solo alla distribuzione normale, ma pu√≤ essere utilizzato per confrontare la distribuzione del campione con qualsiasi distribuzione teorica, facilitando l‚Äôanalisi di dati con forme di distribuzione complesse.\nIdentificare outlier: Gli outlier nei dati saranno visibili come punti che si discostano significativamente dalla linea retta del QQ-plot.\n\nIl QQ-plot √® costruito tracciando i quantili del campione contro i quantili teorici di una distribuzione di riferimento. L‚Äôinterpretazione √® piuttosto semplice:\n\nSe il campione segue la distribuzione teorica, i punti nel QQ-plot si allineano lungo una linea retta di pendenza 1 (e intercetta 0 nel caso di distribuzione normale standardizzata).\nLa deviazione dalla linea retta indica differenze nella distribuzione del campione rispetto alla distribuzione teorica:\n\nIntercetta diversa da 0: indica che la media del campione differisce dalla media della distribuzione teorica.\nPendenza diversa da 1: indica una differenza nella varianza tra il campione e la distribuzione teorica.\nCurve: indicano deviazioni sistematiche, come code pesanti o distribuzioni asimmetriche.\n\n\nNella discussione seguente, costruiremo e analizzeremo QQ-plot per tre casi tipici:\n\nCampione con stessa media e varianza della distribuzione teorica.\nCampione con media diversa ma stessa varianza.\nCampione con media e varianza diverse.\n\nSimuleremo i dati, li ordineremo, calcoleremo manualmente i quantili teorici e infine utilizzeremo librerie specializzate per replicare e confrontare i risultati. Questo approccio pratico ci permetter√† di comprendere a fondo l‚Äôutilit√† e il funzionamento del QQ-plot.\n\n36.4.1 Comprendere e Costruire un QQ-Plot (Distribuzione Normale)\nUn QQ-plot (Quantile-Quantile plot) √® uno strumento grafico utilizzato per confrontare la distribuzione di un campione con una distribuzione teorica, spesso la distribuzione normale. Il QQ-plot aiuta a visualizzare se un dataset segue una distribuzione specifica, tracciando i quantili del campione contro i quantili della distribuzione teorica.\n\n\n36.4.2 Passi per Costruire un QQ-Plot\n\nOrdinare i Dati: Disporre i dati del campione in ordine crescente.\nDeterminare i Quantili Teorici: Per una distribuzione normale, i quantili corrispondono all‚Äôinverso della funzione di distribuzione cumulativa (CDF) della distribuzione normale.\nConfrontare i Quantili: Tracciare i quantili del campione rispetto ai quantili della distribuzione teorica. Se il campione proviene dalla distribuzione teorica, i punti dovrebbero trovarsi approssimativamente su una linea retta.\n\n\n\n36.4.3 Caso 1: Campione con Stessa Media e Varianza della Distribuzione Normale\nSupponiamo che il campione provenga da una distribuzione normale \\(N(\\mu = 0, \\sigma^2 = 1)\\), esattamente come la distribuzione teorica.\n\n36.4.3.1 Simulazione dei Dati\nIniziamo simulando un piccolo dataset da \\(N(0, 1)\\):\n\n# Generiamo 20 punti dati da N(0, 1)\nset.seed(42)  # Per garantire la riproducibilit√†\ndati_campione &lt;- rnorm(20, mean = 0, sd = 1)\n\n# Ordiniamo i dati del campione\ncampione_ordinato &lt;- sort(dati_campione)\n\n# Calcoliamo i quantili teorici da N(0, 1)\nquantili_teorici &lt;- qnorm((seq(1, 20) - 0.5) / 20)\n\n# Tracciamo il QQ-plot\nplot(quantili_teorici, campione_ordinato,\n     xlab = \"Quantili Teorici\", ylab = \"Quantili del Campione\",\n     main = \"QQ-Plot: Stessa Media e Varianza\", pch = 16)\nabline(0, 1, lwd = 2)  # Linea y = x\n\n\n\n\n\n\n\n\nIn questo caso, i punti del QQ-plot dovrebbero allinearsi alla linea rossa, indicando che la distribuzione del campione corrisponde a quella teorica.\n\n\n\n\n36.4.4 Caso 2: Campione con Media Diversa (Intercetta ‚â† 0)\nSimuliamo un campione da \\(N(2, 1)\\), con una media diversa ma la stessa varianza:\n\n# Generiamo 20 punti dati da N(2, 1)\ndati_campione_media_spostata &lt;- rnorm(20, mean = 2, sd = 1)\n\n# Ordiniamo i dati del campione\ncampione_ordinato_media_spostata &lt;- sort(dati_campione_media_spostata)\n\n# Tracciamo il QQ-plot\nplot(quantili_teorici, campione_ordinato_media_spostata,\n     xlab = \"Quantili Teorici\", ylab = \"Quantili del Campione\",\n     main = \"QQ-Plot: Media Diversa (Intercetta ‚â† 0)\", pch = 16)\nabline(0, 1, lwd = 2)  # Linea y = x\n\n\n\n\n\n\n\n\nIn questo caso, i punti dovrebbero seguire una linea retta ma essere spostati verticalmente, indicando una media diversa (intercetta ‚â† 0).\n\n\n\n36.4.5 Caso 3: Campione con Media e Varianza Diverse (Pendenza ‚â† 1)\nSimuliamo un campione da \\(N(2, 2^2)\\), con una media e una varianza diverse:\n\n# Generiamo 20 punti dati da N(2, 2^2)\ndati_campione_varianza_spostata &lt;- rnorm(20, mean = 2, sd = 2)\n\n# Ordiniamo i dati del campione\ncampione_ordinato_varianza_spostata &lt;- sort(dati_campione_varianza_spostata)\n\n# Tracciamo il QQ-plot\nplot(quantili_teorici, campione_ordinato_varianza_spostata,\n     xlab = \"Quantili Teorici\", ylab = \"Quantili del Campione\",\n     main = \"QQ-Plot: Media e Varianza Diverse (Pendenza ‚â† 1)\", pch = 16)\nabline(0, 1, lwd = 2)  # Linea y = x\n\n\n\n\n\n\n\n\nIn questo caso, i punti si discosteranno sia verticalmente (per la media diversa) sia rispetto alla pendenza della linea (per la varianza diversa).\n\n\n\n36.4.6 Calcolo Manuale del QQ-Plot\nPer ciascun caso sopra, i passaggi sono i seguenti:\n\nOrdinamento dei dati del campione: Questo fornisce i quantili del campione.\nCalcolo dei quantili teorici: Utilizzando la funzione inversa della CDF per la distribuzione normale.\n\nEsempio in R:\n\n# Calcolo manuale dei quantili teorici\nquantili_teorici_manuali &lt;- function(n) {\n  sapply(1:n, function(i) qnorm((i - 0.5) / n))\n}\n\nn &lt;- length(dati_campione)\nquantili_teorici_calcolati &lt;- quantili_teorici_manuali(n)\nquantili_teorici_calcolati\n#&gt;  [1] -1.9600 -1.4395 -1.1503 -0.9346 -0.7554 -0.5978 -0.4538 -0.3186 -0.1891\n#&gt; [10] -0.0627  0.0627  0.1891  0.3186  0.4538  0.5978  0.7554  0.9346  1.1503\n#&gt; [19]  1.4395  1.9600\n\n\n\n\n36.4.7 Utilizzo di Funzioni Specializzate\nIn R, il pacchetto base offre la funzione qqnorm() per generare QQ-plot. Ad esempio:\n\n# Generazione del QQ-plot con qqnorm\nqqnorm(dati_campione, main = \"QQ-Plot: Stessa Media e Varianza\")\nqqline(dati_campione, lwd = 2)  # Linea di riferimento\n\n\n\n\n\n\n\n\nPossiamo ripetere lo stesso per i campioni con media e varianza spostate.\n\nQuesto approccio fornisce un‚Äôanalisi completa della corrispondenza tra distribuzioni teoriche e campioni simulati utilizzando QQ-plot.\nPer concludere, esaminiamo la distribuzione dei tempi di reazione simulati con il qq-plot.\n\nqqnorm(rt, main = \"Tempi di Reazione\")\n\n\n\n\n\n\n\n\nIl diagramma quantile-quantile rende molto chiaro che la distribuzione del peso dei pulcini non √® gaussiana.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>36</span>¬† <span class='chapter-title'>Assunzione di gaussianit√† e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_gauss.html#valutare-la-normalit√†-test-statistici",
    "href": "chapters/probability/13_gauss.html#valutare-la-normalit√†-test-statistici",
    "title": "36¬† Assunzione di gaussianit√† e trasformazioni dei dati",
    "section": "36.5 Valutare la Normalit√†: Test Statistici",
    "text": "36.5 Valutare la Normalit√†: Test Statistici\nSebbene esistano numerosi test statistici formali per valutare la conformit√† dei dati alla distribuzione normale, questi sono spesso troppo conservativi o sensibili a lievi deviazioni, e nella pratica sono frequentemente sostituiti da metodi visivi pi√π flessibili ed efficaci.\nIn R sono disponibili diversi test per verificare la normalit√† dei dati. Di seguito presentiamo i pi√π comuni, insieme a un esempio pratico basato sul dataset ChickWeight.\n\n36.5.1 Test di Shapiro-Wilk\nIl test di Shapiro-Wilk √® uno dei test pi√π utilizzati per verificare la normalit√†. Valuta l‚Äôipotesi nulla che i dati seguano una distribuzione normale.\n\nshapiro_test &lt;- shapiro.test(rt)\nshapiro_test\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  rt\n#&gt; W = 0.6, p-value = 5e-16\n\n\nIl p-value √® inferiore a 0.05 ‚Üí Rifiutiamo l‚Äôipotesi nulla, i dati non sono normali.\nIl p-value √® maggiore di 0.05 ‚Üí Non rifiutiamo l‚Äôipotesi nulla, i dati possono essere considerati normali.\n\n\n\n36.5.2 Test di Kolmogorov-Smirnov\nQuesto test confronta la distribuzione cumulativa dei dati con una distribuzione teorica, come la normale. Tuttavia, √® meno sensibile rispetto al test di Shapiro-Wilk.\n\nks_test &lt;- ks.test(\n  rt, \n  \"pnorm\", \n  mean = mean(rt), \n  sd = sd(rt)\n)\nks_test\n#&gt; \n#&gt;  Asymptotic one-sample Kolmogorov-Smirnov test\n#&gt; \n#&gt; data:  rt\n#&gt; D = 0.3, p-value = 5e-06\n#&gt; alternative hypothesis: two-sided\n\nIl test di Kolmogorov-Smirnov √® pi√π adatto per grandi dataset, ma √® noto per essere eccessivamente conservativo.\n\n\n36.5.3 Limitazioni dei test statistici\nNonostante la loro precisione formale, i test statistici per la normalit√† notevoli limitazioni:\n\nEccessiva sensibilit√† ai grandi campioni: Quando il campione √® ampio, anche lievi deviazioni dalla normalit√†, non rilevanti per l‚Äôanalisi, possono portare a un risultato di non-normalit√†.\nMancanza di sensibilit√† nei piccoli campioni: Con campioni ridotti, i test possono mancare di potere statistico, portando a falsi negativi (ovvero, non rilevare deviazioni significative dalla normalit√†).\n\n\nset.seed(123)\nshapiro.test(rchisq(20, 4))\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  rchisq(20, 4)\n#&gt; W = 0.9, p-value = 0.3\n\nIn questo esempio, vediamo come, con un campione di 20 osservazioni da una distribuzione \\(\\chi^2_4\\) si produca un falso negativo.\n\nDifficolt√† interpretative: Un p-value elevato non implica che i dati siano esattamente normali; semplicemente, non c‚Äô√® evidenza sufficiente per rifiutare l‚Äôipotesi di normalit√†.\n\nI metodi visivi, sebbene meno formali, sono spesso pi√π pratici ed efficaci per diagnosticare deviazioni dalla normalit√†.I metodi visivi sono preferibili sono preferibili perch√©\n\nforniscono una diagnosi immediata, che consente di identificare deviazioni rilevanti senza dipendere da un p-value.\nrivelano non solo se i dati non sono normali, ma anche come e dove differiscono dalla normalit√† (ad esempio, asimmetria o code pesanti).\noffrono indicazioni utili anche in presenza di grandi campioni, dove i test statistici possono risultare eccessivamente conservativi.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>36</span>¬† <span class='chapter-title'>Assunzione di gaussianit√† e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_gauss.html#trasformazione-dei-dati-affrontare-la-non-normalit√†",
    "href": "chapters/probability/13_gauss.html#trasformazione-dei-dati-affrontare-la-non-normalit√†",
    "title": "36¬† Assunzione di gaussianit√† e trasformazioni dei dati",
    "section": "36.6 Trasformazione dei dati: affrontare la non-normalit√†",
    "text": "36.6 Trasformazione dei dati: affrontare la non-normalit√†\nQuando i dati non rispettano l‚Äôassunzione di normalit√†, √® possibile utilizzare diverse strategie per affrontare questa violazione. Una delle pi√π comuni √® l‚Äôuso di trasformazioni dei dati, che permettono di adattare la distribuzione dei dati a una forma pi√π vicina a quella normale, mantenendo comunque la validit√† dell‚Äôanalisi che richiede l‚Äôassunzione di normalit√†. Due approcci comuni sono Winsorizing e trimming.\n\n36.6.1 Winsorizing e Trimming\nQuesti metodi si concentrano sulla gestione degli outlier, ossia valori estremi che possono distorcere la distribuzione dei dati. Entrambi gli approcci presumono che la non-normalit√† sia dovuta a dati contaminanti e agiscono in modo differente:\n\nWinsorizing: Sostituisce i valori estremi con valori meno estremi, come i percentili limite della distribuzione.\nTrimming: Rimuove completamente i valori estremi dalla distribuzione.\n\nConsideriamo i seguenti dati di esempio:\n\ndati &lt;- c(\n  1.0, 2.2, 3.0, 3.1, 4.0, 4.0, 4.1, 5.3, 6.5, 8.3,\n  10.9, 20.4, 21.4, 34.\n)\n\n# Winsorizing al 20%\ndati_winsorized &lt;- winsorize(\n  dati,\n  method = \"percentile\", percentile = 20\n)\nprint(dati_winsorized)\n#&gt;  [1]  3.0  3.0  3.0  3.1  4.0  4.0  4.1  5.3  6.5  8.3 10.9 20.4 20.4 20.4\n\n\n# Trimming al 20%\ndati_trimmed &lt;- dati[\n  dati &gt;= quantile(dati, 0.2) & dati &lt;= quantile(dati, 0.8)\n]\nprint(dati_trimmed)\n#&gt; [1]  3.1  4.0  4.0  4.1  5.3  6.5  8.3 10.9\n\n\nDati Winsorized: I valori estremi (inferiori e superiori ai percentili 20¬∞ e 80¬∞) sono sostituiti dai valori limite.\nDati Trimmed: I valori fuori dai percentili 20¬∞ e 80¬∞ sono completamente rimossi.\n\nQuesti metodi riducono l‚Äôimpatto degli outlier, ma possono introdurre bias se i valori estremi sono effettivamente parte della popolazione target.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>36</span>¬† <span class='chapter-title'>Assunzione di gaussianit√† e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_gauss.html#trasformazioni-comuni",
    "href": "chapters/probability/13_gauss.html#trasformazioni-comuni",
    "title": "36¬† Assunzione di gaussianit√† e trasformazioni dei dati",
    "section": "36.7 Trasformazioni comuni",
    "text": "36.7 Trasformazioni comuni\nQuando i dati non rispettano l‚Äôassunzione di normalit√†, √® possibile applicare trasformazioni matematiche per modificarne la forma e migliorare l‚Äôadattamento a una distribuzione normale. Di seguito, presentiamo le trasformazioni pi√π utilizzate.\nTrasformazione logaritmica.\nLa trasformazione logaritmica √® particolarmente utile per variabili con asimmetria positiva (code lunghe a destra), come i tempi di reazione.\n\n# Trasformazione logaritmica\ndati_log &lt;- log(rt)\nplot(density(dati_log), main = \"Densit√† dei dati log-transformati\")\n\n\n\n\n\n\n\n\nTrasformazione radice quadrata.\nAdatta per variabili di conteggio o proporzioni con valori vicini a zero.\n\ndati_sqrt &lt;- sqrt(rt)\nplot(density(dati_sqrt), main = \"Densit√† dei dati trasformati con radice quadrata\")\n\n\n\n\n\n\n\n\nTrasformazione inversa.\nEfficace per dati con forte asimmetria positiva, ma pu√≤ complicare l‚Äôinterpretazione.\n\ndati_inv &lt;- 1 / rt\nplot(density(dati_inv), main = \"Densit√† dei dati trasformati inversamente\")\n\n\n\n\n\n\n\n\nTrasformazione Box-Cox.\nLa trasformazione Box-Cox √® una tecnica parametrica che generalizza le precedenti. Utilizza il massimo della verosimiglianza per determinare la trasformazione ottimale per normalizzare i dati. La funzione di trasformazione dipende da un parametro \\(\\lambda\\):\n\\[\ny(\\lambda) =\n\\begin{cases}\n\\frac{y^\\lambda - 1}{\\lambda} & \\text{se } \\lambda \\neq 0, \\\\\n\\log(y) & \\text{se } \\lambda = 0.\n\\end{cases}\n\\]\n\nb &lt;- boxcox(lm(rt ~ 1))\n\n\n\n\n\n\n\n\n\n# Exact lambda\nlambda &lt;- b$x[which.max(b$y)]\nlambda\n#&gt; [1] 0.182\n\nTrasformiamo i dati utilizzando lambda.\n\nrt_boxcox &lt;- (rt^lambda - 1) / lambda\nrt_boxcox |&gt; head()\n#&gt; [1]  1.645  1.168  2.261 -1.568 -1.133  0.479\n\n\nplot(\n  density(rt_boxcox), \n  main = \"Densit√† dei dati trasformati con Box-Cox\"\n)\n\n\n\n\n\n\n\n\n\n# Generazione del QQ-plot con qqnorm\nqqnorm(rt_boxcox, main = \"QQ-Plot\")\nqqline(rt_boxcox, lwd = 2) \n\n\n\n\n\n\n\n\n\n\n36.7.1 Pro e contro delle trasformazioni\nVantaggi:\nLe trasformazioni dei dati offrono molteplici benefici nell‚Äôanalisi statistica. In primo luogo, possono migliorare l‚Äôaderenza alla normalit√†, un requisito fondamentale per l‚Äôapplicazione di molti test statistici. Inoltre, contribuiscono a stabilizzare la varianza e a mitigare l‚Äôimpatto dei valori estremi, riducendo il rischio che questi ultimi influenzino eccessivamente i risultati. Tali vantaggi migliorano la robustezza e l‚Äôaccuratezza delle analisi.\nSvantaggi:\nNonostante i benefici, le trasformazioni presentano limitazioni rilevanti. La perdita di interpretabilit√† √® uno degli aspetti pi√π critici: i risultati su dati trasformati possono risultare meno intuitivi. Ad esempio, in un modello di regressione applicato a dati trasformati con il logaritmo, il coefficiente rappresenta un cambiamento percentuale anzich√© assoluto, rendendo l‚Äôinterpretazione meno diretta per i non esperti.\nInoltre, l‚Äôapplicazione di una trasformazione deve essere attentamente motivata in base alla natura dei dati e agli obiettivi dell‚Äôanalisi. Una trasformazione inappropriata pu√≤ introdurre distorsioni indesiderate, compromettendo la validit√† dei risultati e portando a conclusioni fuorvianti. Per questo motivo, √® essenziale valutare attentamente i costi e i benefici della trasformazione nel contesto specifico della ricerca.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>36</span>¬† <span class='chapter-title'>Assunzione di gaussianit√† e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_gauss.html#riflessioni-conclusive",
    "href": "chapters/probability/13_gauss.html#riflessioni-conclusive",
    "title": "36¬† Assunzione di gaussianit√† e trasformazioni dei dati",
    "section": "36.8 Riflessioni Conclusive",
    "text": "36.8 Riflessioni Conclusive\nLa verifica della normalit√† dei dati e l‚Äôeventuale utilizzo di trasformazioni matematiche costituiscono fasi fondamentali nell‚Äôanalisi statistica. Sebbene i test formali (come Shapiro-Wilk o Kolmogorov-Smirnov) offrano una valutazione strutturata, essi possono risultare troppo sensibili, portando a rigettare l‚Äôassunto di normalit√† anche in presenza di lievi deviazioni non rilevanti dal punto di vista pratico. In questi casi, l‚Äôimpiego di strumenti visivi‚Äîcome istogrammi, grafici di densit√† o QQ-plot‚Äîsi rivela spesso pi√π informativo e flessibile, consentendo di individuare la natura e l‚Äôentit√† delle deviazioni.\nLe trasformazioni dei dati rappresentano una strategia utile per normalizzare la distribuzione, ma richiedono una scelta oculata. √à essenziale verificare che la trasformazione adottata non comprometta il significato teorico della variabile in esame. Quando l‚Äôinterpretabilit√† risulta compromessa, potrebbe essere preferibile ricorrere a metodi robusti o modelli alternativi (ad esempio, approcci bayesiani) che non presuppongono la normalit√†. In definitiva, la decisione finale dipender√† dal contesto di ricerca, dalla natura dei dati e dagli obiettivi analitici, privilegiando sempre un equilibrio tra rigore statistico e interpretabilit√† dei risultati.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>36</span>¬† <span class='chapter-title'>Assunzione di gaussianit√† e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_gauss.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/13_gauss.html#informazioni-sullambiente-di-sviluppo",
    "title": "36¬† Assunzione di gaussianit√† e trasformazioni dei dati",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: US/Pacific\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] MASS_7.3-64      datawizard_1.0.0 ggokabeito_0.1.0 see_0.9.0       \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.4.12    \n#&gt;  [9] scales_1.3.0     markdown_1.13    knitr_1.49       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.2     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.3         rlang_1.1.4       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       yaml_2.3.10       tools_4.4.2       parallel_4.4.2   \n#&gt; [21] tzdb_0.4.0        colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5      \n#&gt; [25] R6_2.5.1          lifecycle_1.0.4   htmlwidgets_1.6.4 insight_1.0.1    \n#&gt; [29] pkgconfig_2.0.3   pillar_1.10.1     gtable_0.3.6      glue_1.8.0       \n#&gt; [33] xfun_0.50         tidyselect_1.2.1  farver_2.1.2      htmltools_0.5.8.1\n#&gt; [37] nlme_3.1-166      labeling_0.4.3    rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>36</span>¬† <span class='chapter-title'>Assunzione di gaussianit√† e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_gauss.html#bibliografia",
    "href": "chapters/probability/13_gauss.html#bibliografia",
    "title": "36¬† Assunzione di gaussianit√† e trasformazioni dei dati",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nOsborne, J. (2002). Notes on the use of data transformations. Practical Assessment, Research, and Evaluation, 8(1).\n\n\nShatz, I. (2024). Assumption-checking rather than (just) testing: The importance of visualization and effect size in statistical diagnostics. Behavior Research Methods, 56(2), 826‚Äì845.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>36</span>¬† <span class='chapter-title'>Assunzione di gaussianit√† e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_likelihood.html",
    "href": "chapters/probability/14_likelihood.html",
    "title": "37¬† La verosimiglianza",
    "section": "",
    "text": "37.1 Introduzione\nPrerequisiti\nConcetti e Competenze Chiave\nPreparazione del Notebook\nI ricercatori utilizzano modelli con diverse strutture funzionali per descrivere e prevedere il comportamento dei dati. La scelta del modello pi√π adatto si basa sul confronto tra le previsioni teoriche e i dati osservati: il modello che produce previsioni pi√π vicine ai dati osservati viene considerato il migliore per rappresentare il fenomeno studiato. In questo processo, la funzione di verosimiglianza svolge un ruolo centrale, quantificando la probabilit√† che i dati osservati siano compatibili con un modello specifico e i suoi parametri.\nLa funzione di verosimiglianza rappresenta il meccanismo generativo dei dati, collegando i parametri del modello alle osservazioni empiriche. Tuttavia, essa non costituisce da sola un modello scientifico completo. Un modello scientifico include infatti altri elementi, come i priori (in un approccio bayesiano), che rappresentano le ipotesi iniziali sui parametri prima dell‚Äôosservazione dei dati, e la modellazione dell‚Äôerrore di misurazione, che tiene conto delle imperfezioni nei dati raccolti.\nIn un approccio bayesiano, i priori si combinano con la verosimiglianza per generare la distribuzione a posteriori, che aggiorna le conoscenze sui parametri alla luce dei dati osservati. Questo passaggio √® cruciale per il confronto tra modelli, poich√© i priori possono influenzare significativamente le conclusioni.\nUn modello scientifico pu√≤ anche includere la modellazione dell‚Äôerrore di misurazione per spiegare le discrepanze tra i dati osservati e il processo reale. Questo aspetto √® fondamentale per garantire che il modello sia in grado di catturare sia le osservazioni che le loro imprecisioni.\nIn sintesi, la funzione di verosimiglianza descrive come i dati potrebbero essere generati da un modello dato un insieme di parametri, ma un modello scientifico completo include ulteriori componenti, come i priori e la modellazione dell‚Äôerrore, per rendere la rappresentazione del fenomeno pi√π accurata. Questo capitolo si propone di approfondire il concetto di verosimiglianza e il suo ruolo nell‚Äôinferenza statistica.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>37</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_likelihood.html#il-principio-della-verosimiglianza-e-la-sua-formalizzazione",
    "href": "chapters/probability/14_likelihood.html#il-principio-della-verosimiglianza-e-la-sua-formalizzazione",
    "title": "37¬† La verosimiglianza",
    "section": "37.2 Il Principio della Verosimiglianza e la sua Formalizzazione",
    "text": "37.2 Il Principio della Verosimiglianza e la sua Formalizzazione\nLa funzione di verosimiglianza √® strettamente collegata alla funzione di densit√† (o massa) di probabilit√†, ma i due concetti hanno interpretazioni distinte:\n\nLa funzione di densit√† di probabilit√† descrive la probabilit√† di osservare un determinato insieme di dati, assumendo che i parametri siano noti e fissi.\nLa funzione di verosimiglianza considera i dati osservati come fissi e varia i parametri, valutando quanto ciascun valore dei parametri spieghi i dati.\n\nLa relazione tra queste due funzioni pu√≤ essere formalizzata come segue:\n\\[\nL(\\theta \\mid y) \\propto p(y \\mid \\theta),\n\\]\ndove \\(L(\\theta \\mid y)\\) √® la verosimiglianza dei parametri \\(\\theta\\) dati i dati \\(y\\), e \\(p(y \\mid \\theta)\\) rappresenta la probabilit√† di osservare i dati \\(y\\) dato un certo \\(\\theta\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>37</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_likelihood.html#verosimiglianza-binomiale",
    "href": "chapters/probability/14_likelihood.html#verosimiglianza-binomiale",
    "title": "37¬† La verosimiglianza",
    "section": "37.3 Verosimiglianza Binomiale",
    "text": "37.3 Verosimiglianza Binomiale\nConsideriamo un esempio pratico: il lancio di una moneta. Supponiamo di osservare 23 teste su 30 lanci. La probabilit√† di osservare esattamente questo risultato, data una probabilit√† di successo \\(\\theta\\), pu√≤ essere calcolata utilizzando la funzione di massa della distribuzione binomiale:\n\\[\nP(Y = y) = \\binom{n}{y} \\theta^y (1 - \\theta)^{n - y},\n\\]\ndove:\n\n\\(n\\) √® il numero totale di lanci,\n\\(y\\) √® il numero di successi osservati,\n\\(\\theta\\) √® la probabilit√† di successo per ogni lancio.\n\nLa funzione di verosimiglianza, invece, si concentra sull‚Äôidentificazione dei valori di \\(\\theta\\) che meglio spiegano i dati osservati. Per la distribuzione binomiale, la funzione di verosimiglianza si scrive come:\n\\[\n\\mathcal{L}(\\theta \\mid y) = \\theta^y (1 - \\theta)^{n - y}.\n\\]\nQui, il coefficiente binomiale \\(\\binom{n}{y}\\) pu√≤ essere omesso perch√© non dipende da \\(\\theta\\) e quindi non influisce sulla stima del parametro.\n\n37.3.1 Verosimiglianza per il Lancio di una Moneta\nSupponiamo che:\n\n\\(n = 30\\) (numero di lanci),\n\\(y = 23\\) (numero di teste osservate).\n\nLa funzione di verosimiglianza diventa:\n\\[\n\\mathcal{L}(\\theta \\mid y) = \\theta^{23} (1 - \\theta)^7.\n\\]\nQuesto ci permette di calcolare la verosimiglianza per diversi valori di \\(\\theta\\), determinando quale valore rende i dati osservati pi√π plausibili. Ad esempio, possiamo simulare 100 valori equidistanti di \\(\\theta\\) nell‚Äôintervallo ([0, 1]) e calcolare la funzione di verosimiglianza per ciascun valore.\nIn R, possiamo calcolare la funzione di verosimiglianza per \\(n = 30\\), \\(y = 23\\), e una griglia di valori di \\(\\theta\\) come segue:\n\n# Parametri\nn &lt;- 30\ny &lt;- 23\n\n# Definizione dei valori di theta\ntheta &lt;- seq(0, 1, length.out = 100)\n\n# Calcolo della verosimiglianza\nlikelihood &lt;- theta^y * (1 - theta)^(n - y)\n\n# Visualizzazione della funzione di verosimiglianza\nggplot(\n  data.frame(theta, likelihood), \n  aes(x = theta, y = likelihood)) +\n  geom_line(color = \"blue\") +\n  labs(\n    title = \"Funzione di Verosimiglianza\",\n    x = \"Valore di Œ∏\",\n    y = \"Verosimiglianza\"\n  ) \n\n\n\n\n\n\n\n\n\n\n37.3.2 Interpretazione della Verosimiglianza\n\nValore di \\(\\theta\\): La funzione di verosimiglianza indica quali valori di \\(\\theta\\) sono pi√π plausibili dati i dati osservati.\nStima di Massima Verosimiglianza (MLE): Il valore di \\(\\theta\\) che massimizza la funzione di verosimiglianza √® detto stima di massima verosimiglianza. Nel nostro esempio, possiamo individuare questo valore esplorando numericamente i punti di massimo della curva.\n\nIn pratica, per identificare numericamente il valore ottimale di \\(\\theta\\), si pu√≤ utilizzare un approccio computazionale che identifica il massimo della verosimiglianza.\n\n# Calcolo delle probabilit√† binomiali\nl &lt;- dbinom(y, size = n, prob = theta)\n\n# Individuazione dell'indice massimo\nmax_index &lt;- which.max(l)\n\n# Recupero del valore corrispondente di theta\ntheta[max_index]\n#&gt; [1] 0.768\n\nSpiegazione:\n\ndbinom(y, size = n, prob = theta) calcola la probabilit√† binomiale per ogni valore di theta.\nwhich.max(l) restituisce l‚Äôindice del valore massimo nella distribuzione di probabilit√† calcolata.\ntheta[max_index] seleziona il valore di theta corrispondente all‚Äôindice massimo.\n\nQuesto approccio illustra come la funzione di verosimiglianza aiuti a stimare parametri incogniti e a valutare la plausibilit√† relativa di diversi modelli statistici, basandosi esclusivamente sui dati osservati.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>37</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_likelihood.html#la-funzione-di-log-verosimiglianza",
    "href": "chapters/probability/14_likelihood.html#la-funzione-di-log-verosimiglianza",
    "title": "37¬† La verosimiglianza",
    "section": "37.4 La Funzione di Log-Verosimiglianza",
    "text": "37.4 La Funzione di Log-Verosimiglianza\nLa log-verosimiglianza √® il logaritmo naturale della funzione di verosimiglianza:\n\\[\n\\ell(\\theta) = \\log \\mathcal{L}(\\theta \\mid y).\n\\]\nQuesta trasformazione √® utile per semplificare i calcoli e migliorare la stabilit√† numerica, specialmente con dataset di grandi dimensioni.\nEsempio grafico per i valori di log-verosimiglianza:\n\n# Parametri\nn &lt;- 30\nr &lt;- 23\n\n# Genera la sequenza per theta\ntheta &lt;- seq(0, 1, length.out = 100)\n\n# Calcolo della log-verosimiglianza\nlog_likelihood &lt;- dbinom(r, size = n, prob = theta, log = TRUE)\n\n# Creazione del grafico\nplot(\n  theta, log_likelihood, type = \"l\",\n  main = \"Funzione di log-verosimiglianza\",\n  xlab = \"Valore della variabile casuale theta [0, 1]\",\n  ylab = \"Log-verosimiglianza\"\n)\n\n\n\n\n\n\n\n\nIl massimo della log-verosimiglianza replica il risultato trovato in precedenza con la funzione di verosimiglianza.\n\n# Calcolo della log-verosimiglianza per ogni valore di theta\nlog_likelihood &lt;- dbinom(r, size = n, prob = theta, log = TRUE)\n\n# Trova l'indice del valore massimo\nmax_index &lt;- which.max(log_likelihood)\n\n# Valore di theta corrispondente al massimo\ntheta[max_index]\n#&gt; [1] 0.768",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>37</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_likelihood.html#verosimiglianza-congiunta",
    "href": "chapters/probability/14_likelihood.html#verosimiglianza-congiunta",
    "title": "37¬† La verosimiglianza",
    "section": "37.5 Verosimiglianza Congiunta",
    "text": "37.5 Verosimiglianza Congiunta\nNell‚Äôinferenza statistica basata sulla verosimiglianza, √® comune incontrare situazioni in cui si dispone di pi√π osservazioni indipendenti, tutte generate dallo stesso processo probabilistico. Ad esempio, raccogliamo un insieme di dati $ Y = [y_1, y_2, , y_n] $, dove ciascun valore √® osservato indipendentemente e segue la stessa distribuzione binomiale. Questo scenario, noto come condizione di indipendenza e identica distribuzione (IID), √® frequente nelle applicazioni pratiche.\n\n37.5.1 Calcolo della Verosimiglianza Congiunta\nPer considerare congiuntamente tutte le osservazioni, calcoliamo la probabilit√† congiunta di osservare $ y_1, y_2, , y_n $, data una comune probabilit√† di successo \\(\\theta\\). Grazie all‚Äôindipendenza delle osservazioni, questa probabilit√† si esprime come il prodotto delle probabilit√† individuali:\n\\[\np(y_1, y_2, \\ldots, y_n \\mid \\theta) = \\prod_{i=1}^{n} p(y_i \\mid \\theta) = \\prod_{i=1}^{n} \\text{Binomiale}(y_i \\mid \\theta).\n\\]\nLa verosimiglianza congiunta √® quindi:\n\\[\n\\mathcal{L}(\\theta \\mid Y) = \\prod_{i=1}^{n} \\mathcal{L}(\\theta \\mid y_i) = \\prod_{i=1}^{n} p(y_i \\mid \\theta).\n\\]\nQuesta funzione misura la plausibilit√† complessiva del parametro \\(\\theta\\) rispetto all‚Äôintero insieme di dati \\(Y\\). Il valore di \\(\\theta\\) che massimizza la verosimiglianza congiunta √® noto come stimatore di massima verosimiglianza (MLE) e rappresenta il parametro che rende i dati osservati pi√π plausibili.\n\n\n37.5.2 Log-Verosimiglianza Congiunta\nPoich√© il prodotto delle probabilit√† pu√≤ diventare numericamente instabile, lavoriamo spesso con la log-verosimiglianza, che trasforma il prodotto in una somma:\n\\[\n\\log \\mathcal{L}(\\theta \\mid Y) = \\sum_{i=1}^{n} \\log p(y_i \\mid \\theta).\n\\]\nIn un esempio pratico con dati raggruppati, consideriamo quattro gruppi di osservazioni binomiali indipendenti:\n\nGruppo 1: 30 prove con 23 successi\nGruppo 2: 28 prove con 20 successi\nGruppo 3: 40 prove con 29 successi\nGruppo 4: 36 prove con 29 successi\n\nLa log-verosimiglianza congiunta √®:\n\\[\n\\log \\mathcal{L}(\\theta) = \\sum_{i=1}^{4} \\left[ y_i \\log(\\theta) + (n_i - y_i) \\log(1 - \\theta) \\right],\n\\]\ndove $ n_i $ e $ y_i $ rappresentano rispettivamente il numero di prove e di successi nel gruppo \\(i\\)-esimo.\n\n\n37.5.3 Implementazione in R\nPer calcolare la log-verosimiglianza congiunta, definiamo una funzione che accetta \\(\\theta\\) e i dati dei gruppi:\n\nlog_verosimiglianza_congiunta &lt;- function(theta, dati) {\n  # Evita valori problematici per log(0)\n  theta &lt;- pmax(pmin(theta, 1 - 1e-10), 1e-10)\n  \n  # Calcolo della log-verosimiglianza\n  log_likelihood &lt;- 0\n  for (gruppo in dati) {\n    n &lt;- gruppo[1]\n    y &lt;- gruppo[2]\n    log_likelihood &lt;- log_likelihood + y * log(theta) + (n - y) * log(1 - theta)\n  }\n  \n  return(-log_likelihood) # Negativo per ottimizzazione\n}\n\nI dati dei gruppi sono rappresentati come segue:\n\ndati_gruppi &lt;- list(c(30, 23), c(28, 20), c(40, 29), c(36, 29))\n\n\n\n37.5.4 Ottimizzazione per trovare \\(\\theta\\)\nUtilizziamo l‚Äôalgoritmo di ottimizzazione optim per stimare il valore di \\(\\theta\\) che massimizza la log-verosimiglianza:\n\nresult &lt;- optim(\n  par = 0.5,                        # Valore iniziale\n  fn = log_verosimiglianza_congiunta, \n  dati = dati_gruppi,               # Dati\n  method = \"L-BFGS-B\",              # Metodo con vincoli\n  lower = 0,                        # Limite inferiore\n  upper = 1                         # Limite superiore\n)\n\n# Valore ottimale di theta\nresult$par\n#&gt; [1] 0.754\n\n\n\n37.5.5 Visualizzazione della log-verosimiglianza\nCalcoliamo e tracciamo la log-verosimiglianza negativa per un intervallo di valori di \\(\\theta\\):\n\ntheta_values &lt;- seq(0.01, 0.99, length.out = 100)\n\nlog_likelihood_values &lt;- sapply(theta_values, function(theta) {\n  log_verosimiglianza_congiunta(theta, dati_gruppi)\n})\n\nggplot(\n  data.frame(theta = theta_values, log_likelihood = log_likelihood_values), \n  aes(x = theta, y = log_likelihood)) +\n  geom_line(color = \"blue\") +\n  labs(\n    title = \"Funzione di Log-verosimiglianza Congiunta\",\n    x = \"Theta\",\n    y = \"Log-verosimiglianza Negativa\"\n  ) \n\n\n\n\n\n\n\n\nIn conclusione, l‚Äôanalisi della verosimiglianza congiunta consente di stimare con precisione il parametro \\(\\theta\\) considerando tutte le osservazioni contemporaneamente. La log-verosimiglianza, grazie alla sua stabilit√† numerica e alla semplicit√† di calcolo, √® uno strumento potente per l‚Äôinferenza statistica. Utilizzando tecniche di ottimizzazione, possiamo identificare il valore di \\(\\theta\\) che meglio spiega i dati osservati, ottenendo stime affidabili anche in contesti complessi.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>37</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_likelihood.html#la-verosimiglianza-marginale",
    "href": "chapters/probability/14_likelihood.html#la-verosimiglianza-marginale",
    "title": "37¬† La verosimiglianza",
    "section": "37.6 La Verosimiglianza Marginale",
    "text": "37.6 La Verosimiglianza Marginale\nLa verosimiglianza marginale √® un concetto fondamentale nell‚Äôinferenza bayesiana. Essa permette di calcolare la probabilit√† complessiva di osservare un determinato risultato, tenendo conto di tutte le possibili incertezze sui parametri del modello. Questo √® particolarmente rilevante quando il parametro di interesse, \\(\\theta\\), non √® considerato un valore fisso, ma √® descritto da una distribuzione di probabilit√†.\nIn pratica, la verosimiglianza marginale valuta la compatibilit√† dei dati con il modello, integrando su tutti i possibili valori di \\(\\theta\\), ciascuno pesato dalla sua probabilit√† a priori.\n\n37.6.1 Caso con Parametri Discreti\nConsideriamo un esempio semplice in cui \\(\\theta\\) pu√≤ assumere un insieme discreto di valori. Ad esempio, in una sequenza di prove binomiali con \\(k = 7\\) successi su \\(n = 10\\) prove, e con \\(\\theta \\in \\{0.1, 0.5, 0.9\\}\\), la verosimiglianza marginale √® calcolata come:\n\\[\np(k = 7 \\mid n = 10) = \\sum_{\\theta \\in \\{0.1, 0.5, 0.9\\}} \\binom{10}{7} \\theta^7 (1 - \\theta)^3 p(\\theta),\n\\]\ndove \\(p(\\theta)\\) rappresenta la probabilit√† a priori associata a ciascun valore discreto di \\(\\theta\\). In questo caso, la verosimiglianza marginale √® la somma delle probabilit√† di osservare i dati, pesata dalla probabilit√† a priori di ciascun valore di \\(\\theta\\).\n\n\n37.6.2 Caso con Parametri Continui\nNella maggior parte delle applicazioni, \\(\\theta\\) varia continuamente all‚Äôinterno di un intervallo, ad esempio \\([0, 1]\\) per un parametro binomiale. In tal caso, la verosimiglianza marginale √® calcolata mediante un‚Äôintegrazione:\n\\[\np(k = 7 \\mid n = 10) = \\int_{0}^{1} \\binom{10}{7} \\theta^7 (1 - \\theta)^3 p(\\theta) \\, d\\theta,\n\\]\ndove \\(p(\\theta)\\) √® la densit√† a priori di \\(\\theta\\). Questa formula combina le probabilit√† condizionali dei dati dati \\(\\theta\\) con le probabilit√† a priori, integrando su tutti i possibili valori di \\(\\theta\\).\n\n\n37.6.3 Calcolo Numerico della Verosimiglianza Marginale\nPer calcolare la verosimiglianza marginale con \\(\\theta\\) continuo, possiamo utilizzare l‚Äôintegrazione numerica. In R, il pacchetto stats offre strumenti utili come la funzione integrate. Ecco un esempio concreto:\n\n# Definizione della funzione di verosimiglianza\nlikelihood &lt;- function(theta) {\n  dbinom(x = 7, size = 10, prob = theta)\n}\n\n# Calcolo della verosimiglianza marginale con integrazione numerica\nmarginal_likelihood &lt;- integrate(likelihood, lower = 0, upper = 1)$value\n\n# Stampa del risultato\ncat(\"La verosimiglianza marginale √®:\", marginal_likelihood, \"\\n\")\n#&gt; La verosimiglianza marginale √®: 0.0909\n\n\n\n37.6.4 Interpretazione della Verosimiglianza Marginale\nLa verosimiglianza marginale rappresenta la capacit√† complessiva del modello di spiegare i dati, tenendo conto dell‚Äôincertezza sui parametri. Dal punto di vista geometrico, pu√≤ essere interpretata come l‚Äôarea sottesa alla funzione di verosimiglianza ponderata dalla distribuzione a priori di \\(\\theta\\).\nTuttavia, √® importante chiarire che la verosimiglianza marginale non √® una probabilit√† dei dati dato un valore specifico di \\(\\theta\\). Piuttosto, essa considera tutte le possibili incertezze sui parametri, fornendo una misura complessiva della compatibilit√† del modello con i dati.\n\n\n37.6.5 Ruolo nell‚ÄôInferenza Bayesiana\nLa verosimiglianza marginale assume un ruolo chiave nell‚Äôinferenza bayesiana come fattore di normalizzazione nella formula di Bayes:\n\\[\np(\\theta \\mid D) = \\frac{p(D \\mid \\theta) p(\\theta)}{p(D)},\n\\]\ndove \\(p(D)\\), ossia la verosimiglianza marginale, garantisce che la distribuzione posteriore \\(p(\\theta \\mid D)\\) sia una distribuzione di probabilit√† valida, con un‚Äôarea totale pari a 1.\nIn conclusione, la verosimiglianza marginale √® uno strumento fondamentale per valutare il modello nel suo complesso, integrando informazioni sui parametri e sulla loro incertezza. In particolare:\n\nPer parametri discreti, si calcola sommando le probabilit√† di ciascun valore di \\(\\theta\\), ponderate dalla loro probabilit√† a priori.\nPer parametri continui, si utilizza l‚Äôintegrazione per ottenere una misura globale della compatibilit√† del modello con i dati.\n\nQuesta misura non solo consente di confrontare modelli diversi, ma garantisce anche la validit√† della distribuzione a posteriori nell‚Äôinferenza bayesiana. Grazie a strumenti computazionali, possiamo calcolare la verosimiglianza marginale anche in situazioni complesse, fornendo una base solida per analisi statistiche rigorose e flessibili.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>37</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_likelihood.html#modello-gaussiano-e-verosimiglianza",
    "href": "chapters/probability/14_likelihood.html#modello-gaussiano-e-verosimiglianza",
    "title": "37¬† La verosimiglianza",
    "section": "37.7 Modello Gaussiano e Verosimiglianza",
    "text": "37.7 Modello Gaussiano e Verosimiglianza\nIn questa sezione analizziamo il caso di una distribuzione gaussiana per calcolare la funzione di verosimiglianza. Inizieremo con una singola osservazione e successivamente estenderemo l‚Äôanalisi a un insieme di osservazioni indipendenti e identicamente distribuite (IID).\n\n37.7.1 Caso di una Singola Osservazione\nConsideriamo una singola osservazione $ y $, ad esempio il Quoziente Intellettivo (QI) di un individuo, che supponiamo seguire una distribuzione normale. La funzione di verosimiglianza per $ y $ esprime la plausibilit√† di diversi valori del parametro \\(\\mu\\) (media), dato il valore osservato, assumendo che la deviazione standard \\(\\sigma\\) sia nota.\n\n37.7.1.1 Definizione della Verosimiglianza\nLa funzione di densit√† di probabilit√† gaussiana √® definita come:\n\\[\nf(y \\mid \\mu, \\sigma) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left(-\\frac{(y-\\mu)^2}{2\\sigma^2}\\right),\n\\]\ndove \\(y\\) √® il valore osservato, \\(\\mu\\) √® la media e \\(\\sigma\\) √® la deviazione standard.\n\n\n37.7.1.2 Esempio con R\nSupponiamo di osservare un valore $ y = 114 $ e di assumere che \\(\\sigma = 15\\). Esploriamo i valori di \\(\\mu\\) in un intervallo compreso tra 70 e 160 per determinare quale valore massimizza la verosimiglianza.\n\n# Parametri iniziali\ny_obs &lt;- 114\nsigma &lt;- 15\nmu_values &lt;- seq(70, 160, length.out = 1000)\n\n# Calcolo della funzione di verosimiglianza\nlikelihood &lt;- dnorm(y_obs, mean = mu_values, sd = sigma)\n\n# Visualizzazione della funzione di verosimiglianza\nlibrary(ggplot2)\nggplot(data.frame(mu = mu_values, likelihood = likelihood), aes(x = mu, y = likelihood)) +\n  geom_line(color = \"blue\") +\n  labs(\n    title = \"Funzione di Verosimiglianza per QI = 114\",\n    x = \"Valore di Œº (media)\",\n    y = \"Verosimiglianza\"\n  )\n\n\n\n\n\n\n\n\n\n\n37.7.1.3 Calcolo del Valore Ottimale\nPer determinare il valore di \\(\\mu\\) che massimizza la verosimiglianza, individuiamo il massimo della curva.\n\n# Identificazione del massimo\nmu_optimal &lt;- mu_values[which.max(likelihood)]\ncat(\"Il valore ottimale di Œº √®:\", mu_optimal, \"\\n\")\n#&gt; Il valore ottimale di Œº √®: 114\n\nIl valore di \\(\\mu\\) che massimizza la verosimiglianza √® $ = 114 $, coincidente con il valore osservato.\n\n\n\n37.7.2 Log-Verosimiglianza\nIn alternativa, possiamo lavorare con la log-verosimiglianza, una trasformazione utile per semplificare i calcoli numerici e migliorare la stabilit√† computazionale:\n\\[\n\\log L(\\mu \\mid y, \\sigma) = -\\frac{1}{2} \\log(2\\pi) - \\log(\\sigma) - \\frac{(y - \\mu)^2}{2\\sigma^2}.\n\\]\nQuesta funzione √® equivalente alla funzione di verosimiglianza per determinare il valore di \\(\\mu\\) che meglio si adatta ai dati.\n\n37.7.2.1 Calcolo della Log-Verosimiglianza con R\n\n# Funzione di log-verosimiglianza negativa\nnegative_log_likelihood &lt;- function(mu, y, sigma) {\n  0.5 * log(2 * pi) + log(sigma) + ((y - mu)^2) / (2 * sigma^2)\n}\n\n# Ottimizzazione per trovare il massimo della log-verosimiglianza\nresult &lt;- optim(\n  par = 100,  # Valore iniziale per Œº\n  fn = negative_log_likelihood,\n  y = y_obs,\n  sigma = sigma,\n  method = \"L-BFGS-B\",\n  lower = 70,\n  upper = 160\n)\n\n# Risultato dell'ottimizzazione\nmu_max_loglik &lt;- result$par\ncat(\"Il valore ottimale di Œº basato sulla log-verosimiglianza √®:\", mu_max_loglik, \"\\n\")\n#&gt; Il valore ottimale di Œº basato sulla log-verosimiglianza √®: 114\n\nIl valore di \\(\\mu\\) che massimizza la log-verosimiglianza √® $ = 114 $, confermando che, in presenza di una singola osservazione, il valore ottimale coincide con l‚Äôosservazione stessa.\nIn conclusione, l‚Äôanalisi della funzione di verosimiglianza nel caso gaussiano mostra che:\n\nLa funzione di verosimiglianza rappresenta la plausibilit√† dei parametri del modello dato il valore osservato.\nLa log-verosimiglianza √® una trasformazione utile per calcoli pi√π stabili e semplificati.\nNel caso di una singola osservazione e deviazione standard nota, il valore di \\(\\mu\\) che massimizza la verosimiglianza coincide con il valore osservato \\(y\\).\n\n\n\n\n37.7.3 Campione Indipendente di Osservazioni da una Distribuzione Normale\nConsideriamo un campione composto da \\(n\\) osservazioni indipendenti e identicamente distribuite (IID), ognuna derivante da una distribuzione normale con media \\(\\mu\\) e deviazione standard \\(\\sigma\\). La distribuzione √® rappresentata da:\n\\[\nX \\sim N(\\mu, \\sigma^2),\n\\]\ndove \\(y_i\\) indica ogni osservazione del campione.\nLa densit√† di probabilit√† congiunta per il campione √® il prodotto delle densit√† delle singole osservazioni:\n\\[\np(y_1, y_2, \\ldots, y_n \\mid \\mu, \\sigma) = \\prod_{i=1}^n p(y_i \\mid \\mu, \\sigma).\n\\]\nDi conseguenza, la funzione di verosimiglianza √®:\n\\[\n\\mathcal{L}(\\mu, \\sigma \\mid y) = \\prod_{i=1}^n \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp \\left( -\\frac{(y_i - \\mu)^2}{2\\sigma^2} \\right).\n\\]\nPer semplificare i calcoli, si considera il logaritmo della funzione di verosimiglianza:\n\\[\n\\log \\mathcal{L}(\\mu, \\sigma \\mid y) = -\\frac{n}{2} \\log(2\\pi) - n \\log(\\sigma) - \\frac{1}{2\\sigma^2} \\sum_{i=1}^n (y_i - \\mu)^2.\n\\]\n\n37.7.3.1 Esempio Pratico\nSupponiamo di misurare i punteggi del BDI-II su un campione di 30 partecipanti. I dati sono i seguenti:\n\n# Dati osservati\ny &lt;- c(\n  26, 35, 30, 25, 44, 30, 33, 43, 22, 43, \n  24, 19, 39, 31, 25, 28, 35, 30, 26, 31, \n  41, 36, 26, 35, 33, 28, 27, 34, 27, 22\n)\n\nAssumiamo che la deviazione standard \\(\\sigma\\) sia nota e pari alla deviazione standard campionaria (\\(\\sigma = 6.50\\)).\nDefiniamo una funzione per calcolare la log-verosimiglianza dato un valore di \\(\\mu\\):\n\nlog_likelihood &lt;- function(mu, y, sigma) {\n  n &lt;- length(y)\n  term1 &lt;- -n * log(sigma) - n * log(sqrt(2 * pi))\n  term2 &lt;- -sum((y - mu)^2) / (2 * sigma^2)\n  return(term1 + term2)\n}\n\nDefiniamo un intervallo per \\(\\mu\\), centrato sulla media campionaria:\n\n# Parametri\nsigma &lt;- 6.50\nmu_range &lt;- seq(mean(y) - 2 * sigma, mean(y) + 2 * sigma, length.out = 1000)\n\n# Calcolo della log-verosimiglianza per ogni valore di mu\nlog_lik_values &lt;- sapply(mu_range, log_likelihood, y = y, sigma = sigma)\n\nTracciamo la funzione di log-verosimiglianza per i diversi valori di \\(\\mu\\):\n\nggplot(\n  data.frame(mu = mu_range, log_likelihood = log_lik_values), \n  aes(x = mu, y = log_likelihood)) +\n  geom_line(color = \"blue\") +\n  labs(\n    title = \"Funzione di Log-Verosimiglianza\",\n    x = \"Valore di Œº\",\n    y = \"Log-Verosimiglianza\"\n  ) +\n  geom_vline(xintercept = mean(y), linetype = \"dashed\", color = \"red\", alpha = 0.7) \n\n\n\n\n\n\n\n\nUtilizziamo l‚Äôottimizzazione numerica per trovare il valore di \\(\\mu\\) che massimizza la log-verosimiglianza:\n\n# Definizione della funzione negativa per l'ottimizzazione\nnegative_log_likelihood &lt;- function(mu, y, sigma) {\n  -log_likelihood(mu, y, sigma)\n}\n\n# Ottimizzazione\nresult &lt;- optim(\n  par = mean(y),  # Punto di partenza\n  fn = negative_log_likelihood,\n  y = y,\n  sigma = sigma,\n  method = \"L-BFGS-B\",\n  lower = min(mu_range),\n  upper = max(mu_range)\n)\n\n# Risultato\nmu_optimal &lt;- result$par\ncat(\"Il valore ottimale di Œº √®:\", mu_optimal, \"\\n\")\n#&gt; Il valore ottimale di Œº √®: 30.9\n\nInterpretazione dei risultati:\n\nStima di Massima Verosimiglianza (MLE): La media campionaria \\(\\bar{y}\\) rappresenta la stima di massima verosimiglianza (MLE) per \\(\\mu\\). Questo risultato √® coerente con la propriet√† della distribuzione normale.\nCurva della Log-Verosimiglianza: La curva mostra la ‚Äúplausibilit√† relativa‚Äù dei diversi valori di \\(\\mu\\) alla luce dei dati osservati.\nOttimizzazione Numerica: Il valore di \\(\\mu\\) che massimizza la funzione di log-verosimiglianza √® il valore che meglio spiega i dati osservati.\n\nIn conclusione, la log-verosimiglianza √® uno strumento essenziale per stimare i parametri di una distribuzione normale:\n\nLa stima di massima verosimiglianza per \\(\\mu\\) coincide con la media campionaria.\nVisualizzare la log-verosimiglianza aiuta a comprendere la plausibilit√† dei parametri.\nL‚Äôottimizzazione numerica fornisce una soluzione precisa ed efficiente per trovare il massimo della log-verosimiglianza.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>37</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_likelihood.html#riflessioni-conclusive",
    "href": "chapters/probability/14_likelihood.html#riflessioni-conclusive",
    "title": "37¬† La verosimiglianza",
    "section": "37.8 Riflessioni Conclusive",
    "text": "37.8 Riflessioni Conclusive\nLa funzione di verosimiglianza rappresenta un elemento cruciale che collega i dati osservati ai parametri di un modello statistico. Essa fornisce una misura della plausibilit√† dei dati in relazione a diversi valori possibili dei parametri del modello. La strutturazione di una funzione di verosimiglianza richiede la considerazione di tre componenti fondamentali: il modello statistico che si presume abbia generato i dati, l‚Äôinsieme di valori possibili per i parametri di tale modello e le osservazioni empiriche che effettivamente abbiamo a disposizione.\nLa funzione di verosimiglianza √® centrale nella pratica dell‚Äôinferenza statistica. Essa ci permette di quantificare quanto bene differenti set di parametri potrebbero aver generato i dati osservati. Questo √® fondamentale sia per la selezione del modello che per la stima dei parametri, e pertanto √® indispensabile per un‚Äôanalisi dati rigorosa e per un‚Äôinterpretazione accurata dei risultati.\nUn‚Äôapplicazione pratica e illustrativa dei principi esposti in questo capitolo √® fornita nella sezione sul modello Rescorla-Wagner, che √® un esempio di come la teoria della verosimiglianza possa essere applicata per affrontare questioni empiriche in psicologia.\nIn sintesi, la comprensione e l‚Äôapplicazione appropriata della funzione di verosimiglianza sono passaggi essenziali nel processo di analisi dati. Essa costituisce uno strumento indispensabile per chi √® impegnato nella ricerca empirica e nell‚Äôinterpretazione di dati complessi.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>37</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_likelihood.html#esercizi",
    "href": "chapters/probability/14_likelihood.html#esercizi",
    "title": "37¬† La verosimiglianza",
    "section": "37.9 Esercizi",
    "text": "37.9 Esercizi\n\nEsercizio 37.1 Spiega ciascuno dei concetti seguenti con una frase:\n\nprobabilit√†.\nfunzione di massa di probabilit√†.\nfunzione di densit√† di probabilit√†.\ndistribuzione di probabilit√†.\ndistribuzione di probabilit√† discreta.\ndistribuzione di probabilit√† continua.\nfunzione di distribuzione cumulativa (cdf).\nverosimiglianza\n\n\n\n\n\n\n\n\nAll‚Äôesame ti verr√† chiesto di:\n\nCalcolare la funzione di verosimiglianza binomiale e riportare il valore della funzione in corrispondenza di specifici valori \\(\\theta\\).\nCalcolare la funzione di verosimiglianza del modello gaussiano, per \\(\\sigma\\) noto, e riportare il valore della funzione in corrispondenza di specifici valori \\(\\mu\\).\nCalcolare la stima di massima verosimiglianza.\nRispondere a domande che implicano una adeguata comprensione del concetto di funzione di verosimiglianza.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>37</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_likelihood.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/14_likelihood.html#informazioni-sullambiente-di-sviluppo",
    "title": "37¬† La verosimiglianza",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: US/Pacific\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pointblank_0.12.2 haven_2.5.4       labelled_2.14.0   mice_3.17.0      \n#&gt;  [5] ggokabeito_0.1.0  see_0.9.0         gridExtra_2.3     patchwork_1.3.0  \n#&gt;  [9] bayesplot_1.11.1  psych_2.4.12      scales_1.3.0      markdown_1.13    \n#&gt; [13] knitr_1.49        lubridate_1.9.4   forcats_1.0.0     stringr_1.5.1    \n#&gt; [17] dplyr_1.1.4       purrr_1.0.2       readr_2.1.5       tidyr_1.3.1      \n#&gt; [21] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [25] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      shape_1.4.6.1     xfun_0.50         htmlwidgets_1.6.4\n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2      \n#&gt;  [9] generics_0.1.3    parallel_4.4.2    pan_1.9           pacman_0.5.1     \n#&gt; [13] jomo_2.7-6        pkgconfig_2.0.3   Matrix_1.7-1      lifecycle_1.0.4  \n#&gt; [17] compiler_4.4.2    farver_2.1.2      munsell_0.5.1     mnormt_2.1.1     \n#&gt; [21] codetools_0.2-20  htmltools_0.5.8.1 yaml_2.3.10       glmnet_4.1-8     \n#&gt; [25] nloptr_2.1.1      pillar_1.10.1     MASS_7.3-64       iterators_1.0.14 \n#&gt; [29] rpart_4.1.23      boot_1.3-31       foreach_1.5.2     mitml_0.4-5      \n#&gt; [33] nlme_3.1-166      tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4    \n#&gt; [37] labeling_0.4.3    splines_4.4.2     rprojroot_2.0.4   fastmap_1.2.0    \n#&gt; [41] grid_4.4.2        blastula_0.3.5    colorspace_2.1-1  cli_3.6.3        \n#&gt; [45] magrittr_2.0.3    survival_3.7-0    broom_1.0.7       withr_3.0.2      \n#&gt; [49] backports_1.5.0   timechange_0.3.0  rmarkdown_2.29    nnet_7.3-19      \n#&gt; [53] lme4_1.1-35.5     hms_1.1.3         evaluate_1.0.1    rlang_1.1.4      \n#&gt; [57] Rcpp_1.0.13-1     glue_1.8.0        minqa_1.2.8       jsonlite_1.8.9   \n#&gt; [61] R6_2.5.1",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>37</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_simulation.html",
    "href": "chapters/probability/15_simulation.html",
    "title": "38¬† Simulazioni",
    "section": "",
    "text": "38.1 Introduzione\nPrerequisiti\nConcetti e Competenze Chiave\nPreparazione del Notebook\nIn questo capitolo, discuteremo alcuni esercizi di simulazione presentati da Gelman et al. (2021) nel quinto capitolo del loro libro. Gli autori sottolineano che simulare variabili casuali √® essenziale nelle statistiche applicate per diversi motivi:",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>38</span>¬† <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_simulation.html#introduzione",
    "href": "chapters/probability/15_simulation.html#introduzione",
    "title": "38¬† Simulazioni",
    "section": "",
    "text": "Comprensione della variazione casuale: I modelli di probabilit√† imitano la variabilit√† del mondo reale. La simulazione aiuta a sviluppare intuizioni sulle oscillazioni casuali nel breve termine e sui loro effetti nel lungo termine.\nDistribuzione campionaria: Simulare dati consente di approssimare la distribuzione campionaria, trasferendo questa approssimazione alle stime e alle procedure statistiche.\nPrevisioni probabilistiche: I modelli di regressione producono previsioni probabilistiche. La simulazione √® il metodo pi√π generale per rappresentare l‚Äôincertezza nelle previsioni.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>38</span>¬† <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_simulation.html#esempio-1-quante-bambine-su-400-nascite",
    "href": "chapters/probability/15_simulation.html#esempio-1-quante-bambine-su-400-nascite",
    "title": "38¬† Simulazioni",
    "section": "38.2 Esempio 1: Quante bambine su 400 nascite?",
    "text": "38.2 Esempio 1: Quante bambine su 400 nascite?\nSupponiamo che la probabilit√† di nascita di una bambina sia \\(p\\) = 0.488. Se in un ospedale nascono 400 bambini in un anno, quante saranno bambine? Possiamo simulare questo processo usando una distribuzione binomiale, ripetendo la simulazione 10,000 volte.\n\n# Numero di simulazioni\nn_sims &lt;- 10000\n\n# Probabilit√† di nascita di una bambina\np_girl &lt;- 0.488\n\n# Simulazione del numero di bambine\nset.seed(123)\nn_girls &lt;- rbinom(n_sims, size = 400, prob = p_girl)\n\n# Visualizzazione dell'istogramma\nggplot(data.frame(n_girls), aes(x = n_girls)) +\n  geom_histogram(binwidth = 5, fill = \"blue\", color = \"black\", alpha = 0.6) +\n  labs(\n    title = \"Distribuzione del Numero di Bambine su 400 Nascite\",\n    x = \"Numero di Bambine\",\n    y = \"Frequenza\"\n  )",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>38</span>¬† <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_simulation.html#simulazione-di-probabilit√†-continue",
    "href": "chapters/probability/15_simulation.html#simulazione-di-probabilit√†-continue",
    "title": "38¬† Simulazioni",
    "section": "38.3 Simulazione di probabilit√† continue",
    "text": "38.3 Simulazione di probabilit√† continue\nGelman et al. (2021) dimostrano come sia possibile incorporare anche distribuzioni di probabilit√† continue nei tipi di simulazioni discusse nella sezione precedente. Forniscono il seguente esempio di un modello misto discreto/continuo: il 52% degli adulti negli Stati Uniti sono donne e il 48% sono uomini. L‚Äôaltezza degli uomini segue approssimativamente una distribuzione normale con una media di 69.1 pollici e una deviazione standard di 2.9 pollici; per le donne, la media √® 63.7 pollici e la deviazione standard √® 2.7 pollici. Ecco il codice per generare l‚Äôaltezza di un adulto scelto casualmente:\n\nsimulate_height &lt;- function(N) {\n  gender &lt;- rbinom(N, size = 1, prob = 0.48) # 1 = uomo, 0 = donna\n  height &lt;- ifelse(\n    gender == 1,\n    rnorm(N, mean = 69.1, sd = 2.9),\n    rnorm(N, mean = 63.7, sd = 2.7)\n  )\n  return(mean(height))\n}\n\nSupponiamo di selezionare 10 adulti a caso. Cosa possiamo dire della loro altezza media?\n\nset.seed(123)\nn_sims &lt;- 10000\navg_heights &lt;- replicate(n_sims, simulate_height(10))\n\n# Visualizzazione dell'istogramma\nggplot(data.frame(avg_heights), aes(x = avg_heights)) +\n  geom_histogram(binwidth = 0.2, fill = \"blue\", color = \"black\", alpha = 0.6) +\n  labs(\n    title = \"Distribuzione dell'Altezza Media di 10 Adulti\",\n    x = \"Altezza Media\",\n    y = \"Frequenza\"\n  )",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>38</span>¬† <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_simulation.html#sommario-di-una-simulazione-con-media-e-mediana",
    "href": "chapters/probability/15_simulation.html#sommario-di-una-simulazione-con-media-e-mediana",
    "title": "38¬† Simulazioni",
    "section": "38.4 Sommario di una simulazione con media e mediana",
    "text": "38.4 Sommario di una simulazione con media e mediana\nQuando le nostre distribuzioni sono costruite come simulazioni al computer, pu√≤ essere conveniente riassumerle in qualche modo. Tipicamente, riassumiamo la posizione di una distribuzione con la sua media o mediana.\nLa variazione nella distribuzione √® tipicamente riassunta dalla deviazione standard, ma spesso preferiamo usare la deviazione mediana assoluta. Se la mediana di un insieme di simulazioni \\(z_1, \\ldots, z_n\\) √® \\(M\\), allora la deviazione mediana assoluta √®:\n\\[ \\text{mad} = \\text{mediana}_{n} |z_i - M| \\]\nTuttavia, poich√© siamo abituati a lavorare con le deviazioni standard, quando calcoliamo la deviazione mediana assoluta, la riscaliamo moltiplicandola per 1.483, il che riproduce la deviazione standard nel caso speciale della distribuzione normale:\n\\[ 1.483 * \\text{median}(|y - \\text{median}(z)|) \\]\nPreferiamo tipicamente i riassunti basati sulla mediana perch√© sono pi√π stabili computazionalmente, e riscaliamo il riassunto basato sulla mediana della variazione come descritto sopra in modo da essere comparabile alla deviazione standard, che sappiamo gi√† interpretare nella pratica statistica usuale.\nEcco come implementare quanto sopra in R per i dati relativi all‚Äôaltezza media di 10 adulti.\n\n# Calcolo della media e mediana\nmean_avg_height &lt;- mean(avg_heights)\nmedian_avg_height &lt;- median(avg_heights)\n\n# Calcolo della deviazione standard\nsd_avg_height &lt;- sd(avg_heights)\n\n# Calcolo della MAD (Deviazione Mediana Assoluta)\nmad_avg_height &lt;- median(abs(avg_heights - median_avg_height)) * 1.483\n\n# Risultati\ncat(\"Mean:\", mean_avg_height, \"\\n\")\n#&gt; Mean: 66.3\ncat(\"Median:\", median_avg_height, \"\\n\")\n#&gt; Median: 66.3\ncat(\"Standard Deviation:\", sd_avg_height, \"\\n\")\n#&gt; Standard Deviation: 1.23\ncat(\"MAD (scaled):\", mad_avg_height, \"\\n\")\n#&gt; MAD (scaled): 1.23\n\n\n38.4.1 Intervalli di Incertezza\nPer rappresentare l‚Äôincertezza, possiamo calcolare intervalli centrali al 50% e al 95%.\n\n# Intervalli di incertezza\nlower_50 &lt;- quantile(avg_heights, 0.25)\nupper_50 &lt;- quantile(avg_heights, 0.75)\n\nlower_95 &lt;- quantile(avg_heights, 0.025)\nupper_95 &lt;- quantile(avg_heights, 0.975)\n\ncat(\"50% Interval:\", lower_50, \"-\", upper_50, \"\\n\")\n#&gt; 50% Interval: 65.5 - 67.1\ncat(\"95% Interval:\", lower_95, \"-\", upper_95, \"\\n\")\n#&gt; 95% Interval: 63.9 - 68.8\n\nEcco come interpretarli.\nIntervallo centrale al 50%.\n\nContiene i valori centrali che coprono il 50% della distribuzione. Questo intervallo si estende dal primo quartile (25¬∞ percentile) al terzo quartile (75¬∞ percentile).\nIndica la fascia di valori in cui si trovano i risultati ‚Äúpi√π comuni‚Äù o tipici. √à una misura di variabilit√† concentrata nella parte centrale della distribuzione, meno sensibile a valori estremi.\n\nPer le altezze medie simulate di 10 adulti, un intervallo centrale al 50% che va da 65 a 67 pollici indica che met√† delle medie osservate si trova in questo intervallo.\n\n\nIntervallo centrale al 95%.\n\nContiene il 95% della distribuzione simulata, lasciando solo il 2.5% dei valori al di sotto e il 2.5% al di sopra dell‚Äôintervallo. Questo intervallo si calcola tra il 2.5¬∞ percentile e il 97.5¬∞ percentile.\nIndica una fascia pi√π ampia che cattura quasi tutti i valori plausibili, inclusi quelli meno probabili ma comunque possibili.\n\nPer le altezze medie simulate, un intervallo al 95% che va da 64 a 68 pollici significa che, in quasi tutte le simulazioni, l‚Äôaltezza media si trova in questo intervallo, con poche eccezioni.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>38</span>¬† <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_simulation.html#commenti-e-considerazioni-finali",
    "href": "chapters/probability/15_simulation.html#commenti-e-considerazioni-finali",
    "title": "38¬† Simulazioni",
    "section": "38.5 Commenti e Considerazioni Finali",
    "text": "38.5 Commenti e Considerazioni Finali\nLo scopo della simulazione di dati fittizi non √® fornire intuizioni sui dati o sul problema reale in esame, ma piuttosto valutare le propriet√† dei metodi statistici utilizzati, partendo da un modello generativo ipotizzato. Le simulazioni sono cruciali nella pratica della ricerca. Molti autori suggeriscono che dovrebbero essere eseguite prima di raccogliere i dati di uno studio, per valutare, tra le altre cose, se la dimensione campionaria prevista fornisce un potere statistico sufficiente per rispondere alla domanda della ricerca (Gelman & Brown, 2024).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>38</span>¬† <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_simulation.html#esercizi",
    "href": "chapters/probability/15_simulation.html#esercizi",
    "title": "38¬† Simulazioni",
    "section": "38.6 Esercizi",
    "text": "38.6 Esercizi\n\nEsercizio 38.1 Immagina il caso di 220 studenti che devono sostenere tre prove in itinere in un corso. Il voto finale √® la media dei voti ottenuti in queste tre prove. Le distribuzioni dei voti per le prove sono descritte come segue:\n\nPrima prova: I voti sono distribuiti secondo una gaussiana con media 24. Il 15% degli studenti ottiene un voto inferiore a 18.\nSeconda prova: I voti sono distribuiti secondo una gaussiana con media 25. Il 10% degli studenti ottiene un voto inferiore a 18.\nTerza prova: I voti sono distribuiti secondo una gaussiana con media 26. Solo il 5% degli studenti ottiene un voto inferiore a 18.\n\nDei 220 studenti iniziali:\n\nIl 10% non partecipa alla prima prova.\nUn ulteriore 5% non partecipa alla seconda prova.\n\nPer ottenere il voto finale, uno studente deve partecipare a tutte e tre le prove.\nUtilizzando una simulazione, trova la media finale dei voti e calcola l‚Äôintervallo di incertezza al 90% per la stima della media.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>38</span>¬† <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_simulation.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/15_simulation.html#informazioni-sullambiente-di-sviluppo",
    "title": "38¬† Simulazioni",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: US/Pacific\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] ggokabeito_0.1.0 see_0.9.0        gridExtra_2.3    patchwork_1.3.0 \n#&gt;  [5] bayesplot_1.11.1 psych_2.4.12     scales_1.3.0     markdown_1.13   \n#&gt;  [9] knitr_1.49       lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1   \n#&gt; [13] dplyr_1.1.4      purrr_1.0.2      readr_2.1.5      tidyr_1.3.1     \n#&gt; [17] tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3       \n#&gt; [21] here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.3         rlang_1.1.4       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       yaml_2.3.10       tools_4.4.2       parallel_4.4.2   \n#&gt; [21] tzdb_0.4.0        colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5      \n#&gt; [25] R6_2.5.1          lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3  \n#&gt; [29] pillar_1.10.1     gtable_0.3.6      glue_1.8.0        xfun_0.50        \n#&gt; [33] tidyselect_1.2.1  farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-166     \n#&gt; [37] labeling_0.4.3    rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>38</span>¬† <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_simulation.html#bibliografia",
    "href": "chapters/probability/15_simulation.html#bibliografia",
    "title": "38¬† Simulazioni",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., & Brown, N. J. (2024). How statistical challenges and misreadings of the literature combine to produce unreplicable science: An example from psychology.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other stories. Cambridge University Press.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>38</span>¬† <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/introduction_bayes_inference.html",
    "href": "chapters/bayesian_inference/introduction_bayes_inference.html",
    "title": "Introduzione",
    "section": "",
    "text": "In questa sezione della dispensa, esamineremo l‚Äôinferenza bayesiana applicata a modelli statistici in cui si stima un unico parametro scalare, cio√® quando l‚Äôestimando \\(\\theta\\) √® unidimensionale. In questo capitolo, consideriamo quattro modelli unidimensionali fondamentali e ampiamente utilizzati: il modello binomiale, il modello normale, il modello di Poisson e il modello esponenziale. Approfondiremo il processo di aggiornamento bayesiano, analizzando due metodi principali per derivare la distribuzione a posteriori: l‚Äôapprossimazione numerica attraverso il metodo basato su griglia e l‚Äôutilizzo delle distribuzioni coniugate, in cui una specifica combinazione di distribuzione a priori e verosimiglianza consente una derivazione analitica della distribuzione a posteriori. Inoltre, considereremo l‚Äôinfluenza della scelta della distribuzione a priori sulla distribuzione a posteriori e discuteremo le tecniche utili per sintetizzare e interpretare quest‚Äôultima in modo efficace.",
    "crumbs": [
      "Inferenza",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html",
    "href": "chapters/bayesian_inference/01_intro_bayes.html",
    "title": "39¬† La quantificazione dell‚Äôincertezza",
    "section": "",
    "text": "39.1 Introduzione\nL‚Äôapproccio bayesiano non si limita all‚Äôapplicazione del Teorema di Bayes, ma si distingue per una gestione esplicita dell‚Äôincertezza e per l‚Äôuso delle distribuzioni di probabilit√† per rappresentare stime e soluzioni. Il processo di modellazione bayesiana, noto come workflow bayesiano (Baribault & Collins, 2023), comprende pi√π fasi iterative: dalla costruzione del modello, all‚Äôapplicazione del Teorema di Bayes, fino all‚Äôanalisi critica dei risultati. Questo approccio permette un continuo affinamento delle stime, adattandole alle nuove evidenze.\nL‚Äôobiettivo dell‚Äôapproccio bayesiano non √® scoprire una ‚Äúverit√† assoluta‚Äù, ma aggiornare razionalmente le credenze riguardo a un‚Äôipotesi integrando nuove informazioni. In psicologia, dove le misurazioni sono soggette a incertezza e i fenomeni complessi, questa capacit√† √® cruciale.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>39</span>¬† <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#introduzione",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#introduzione",
    "title": "39¬† La quantificazione dell‚Äôincertezza",
    "section": "",
    "text": "‚ÄúQuindi non avete una sola risposta alle vostre domande?‚Äù\n‚ÄúAdson, se l‚Äôavessi insegnerei teologia a Parigi.‚Äù\n‚ÄúA Parigi hanno sempre la risposta vera?‚Äù\n‚ÄúMai,‚Äù disse Guglielmo, ‚Äúma sono molto sicuri dei loro errori.‚Äù\n(Umberto Eco: Il Nome della Rosa)",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>39</span>¬† <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#il-valore-dellincertezza",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#il-valore-dellincertezza",
    "title": "39¬† La quantificazione dell‚Äôincertezza",
    "section": "39.2 Il Valore dell‚ÄôIncertezza",
    "text": "39.2 Il Valore dell‚ÄôIncertezza\nIn psicologia e in altre scienze sociali, l‚Äôinformazione √® spesso incompleta, e le variabili di interesse sono latenti o difficili da osservare direttamente. L‚Äôinferenza bayesiana offre un quadro metodologico per rappresentare e affrontare questa incertezza, permettendo di modellare ci√≤ che non si conosce come una variabile aleatoria che pu√≤ essere aggiornata man mano che si acquisiscono nuovi dati (Jaynes, 2003).\nDiversamente dai modelli deterministici, che assumono la possibilit√† di prevedere i risultati con certezza date tutte le informazioni, i modelli bayesiani accolgono e gestiscono l‚Äôincertezza, caratteristica fondamentale in psicologia. Molti fenomeni psicologici coinvolgono variabili latenti ‚Äì come l‚Äôansia, la motivazione o l‚Äôautostima ‚Äì che non possono essere osservate direttamente. L‚Äôapproccio bayesiano consente di rappresentare tali variabili in modo flessibile, integrando evidenze precedenti con i dati attuali.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>39</span>¬† <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#interpretazione-frequentista-vs.-bayesiana-dellincertezza",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#interpretazione-frequentista-vs.-bayesiana-dellincertezza",
    "title": "39¬† La quantificazione dell‚Äôincertezza",
    "section": "39.3 Interpretazione Frequentista vs.¬†Bayesiana dell‚ÄôIncertezza",
    "text": "39.3 Interpretazione Frequentista vs.¬†Bayesiana dell‚ÄôIncertezza\n\nInterpretazione Frequentista: Immaginiamo di misurare la frequenza di un evento psicologico, come un livello di ansia oltre una certa soglia, in un grande campione di individui simili. Secondo i frequentisti, si potrebbe interpretare l‚Äôincertezza come la frequenza relativa dell‚Äôevento in situazioni simili nel lungo periodo. Tuttavia, questa interpretazione presenta due problemi principali: non √® possibile osservare un evento infinite volte in condizioni identiche, e il ‚Äúgruppo di riferimento‚Äù (o reference class) ‚Äì cio√®, le condizioni simili rilevanti ‚Äì pu√≤ essere difficile da definire precisamente.\nInterpretazione Bayesiana: Un‚Äôinterpretazione bayesiana dell‚Äôincertezza riguarda invece il grado di credenza soggettiva. Supponiamo che uno psicologo creda con il 10% di fiducia che un individuo avr√† un punteggio d‚Äôansia superiore a una certa soglia. Questo grado di fiducia pu√≤ essere aggiornato man mano che si raccolgono nuove informazioni, utilizzando il Teorema di Bayes per calcolare probabilit√† a posteriori. A differenza dell‚Äôapproccio frequentista, l‚Äôincertezza bayesiana descrive una credenza soggettiva che pu√≤ essere costantemente aggiornata.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>39</span>¬† <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#esempi-psicologici-dellinferenza-bayesiana",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#esempi-psicologici-dellinferenza-bayesiana",
    "title": "39¬† La quantificazione dell‚Äôincertezza",
    "section": "39.4 Esempi Psicologici dell‚ÄôInferenza Bayesiana",
    "text": "39.4 Esempi Psicologici dell‚ÄôInferenza Bayesiana\nEsempio 1: Misurare l‚ÄôAnsia con Questionari\nQuando si misura l‚Äôansia tramite un questionario, la stima √® soggetta a incertezza per vari motivi:\n\nRisposte Soggettive: L‚Äôinterpretazione delle domande pu√≤ variare tra individui e pu√≤ essere influenzata dallo stato d‚Äôanimo.\nMisurazioni Incomplete: Un questionario pu√≤ non cogliere tutte le sfumature dell‚Äôansia.\nRumore nei Dati: Errori minori, come distrazioni durante la compilazione, possono influire sulla precisione dei risultati.\n\nCon l‚Äôapproccio bayesiano, √® possibile combinare credenze a priori basate su ricerche precedenti con i dati raccolti per ottenere una stima aggiornata. Ad esempio, se si dispone di una distribuzione di probabilit√† iniziale sull‚Äôansia, questa distribuzione pu√≤ essere aggiornata man mano che si raccolgono pi√π dati, permettendo una stima pi√π accurata del livello di ansia effettivo.\nEsempio 2: Effetto del Rinforzo Negativo sulla Motivazione\nConsideriamo uno studio sull‚Äôeffetto del rinforzo negativo sulla motivazione in un compito. La ‚Äúmotivazione interna‚Äù √® una variabile latente, non osservabile direttamente. Possiamo inferirla, per√≤, tramite misure indirette, come il tempo trascorso sul compito o la velocit√† di risposta. Un modello bayesiano consente di collegare queste variabili osservabili alla motivazione latente, rappresentando l‚Äôincertezza sia nella variabilit√† individuale sia nell‚Äôeffetto del rinforzo negativo. Man mano che vengono raccolti nuovi dati, il modello bayesiano aggiorna le stime di motivazione e permette di esprimere in modo rigoroso la probabilit√† che un cambiamento osservato sia effettivamente dovuto al rinforzo negativo.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>39</span>¬† <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#inferenza-bayesiana-e-incertezza-nelle-stime",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#inferenza-bayesiana-e-incertezza-nelle-stime",
    "title": "39¬† La quantificazione dell‚Äôincertezza",
    "section": "39.5 Inferenza Bayesiana e Incertezza nelle Stime",
    "text": "39.5 Inferenza Bayesiana e Incertezza nelle Stime\nL‚Äôinferenza bayesiana utilizza le probabilit√† per aggiornare le credenze sui parametri di un modello basandosi sui dati osservati. Queste credenze sono rappresentate da distribuzioni di probabilit√†, e l‚Äôampiezza di queste distribuzioni riflette l‚Äôincertezza associata alle stime. In psicologia, dove spesso si lavora con campioni limitati e misurazioni indirette di variabili latenti, questa gestione dell‚Äôincertezza √® fondamentale per interpretare i risultati in modo robusto e realistico.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>39</span>¬† <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#il-modello-bayesiano",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#il-modello-bayesiano",
    "title": "39¬† La quantificazione dell‚Äôincertezza",
    "section": "39.6 Il Modello Bayesiano",
    "text": "39.6 Il Modello Bayesiano\nUn modello statistico combina una distribuzione probabilistica con ipotesi sui parametri per descrivere un fenomeno osservato. Ad esempio, possiamo modellare il lancio di una moneta equa con un modello binomiale, in cui la probabilit√† \\(\\theta\\) √® fissata a 0.5, oppure modellare l‚Äôaltezza degli uomini italiani con un modello normale, in cui \\(\\mu\\) √® 183 cm e \\(\\sigma\\) √® 5 cm. In termini bayesiani, il modello statistico include tre componenti principali:\n\nDistribuzione a Priori (Prior): Rappresenta le credenze iniziali sui valori dei parametri del modello, informate da ricerche precedenti o da assunzioni neutre.\nVerosimiglianza (Likelihood): Descrive la probabilit√† di osservare i dati dati i parametri del modello, riflettendo il processo che genera i dati.\nDistribuzione a Posteriori (Posterior): √à la distribuzione aggiornata dei parametri dopo aver osservato i dati, ottenuta combinando la prior e la verosimiglianza mediante il teorema di Bayes. La posterior rappresenta la conoscenza aggiornata dopo aver integrato le informazioni fornite dai dati.\n\nLa modellazione bayesiana descrive il processo generativo che ha prodotto i dati osservati, incorporando l‚Äôincertezza nei parametri e aggiornando continuamente le stime man mano che emergono nuovi dati. Questo approccio √® particolarmente utile in contesti come la psicologia, dove i fenomeni complessi e le variabili latenti rendono necessario modellare l‚Äôincertezza in modo esplicito.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>39</span>¬† <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#componenti-chiave-della-modellazione-probabilistica",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#componenti-chiave-della-modellazione-probabilistica",
    "title": "39¬† La quantificazione dell‚Äôincertezza",
    "section": "39.7 Componenti Chiave della Modellazione Probabilistica",
    "text": "39.7 Componenti Chiave della Modellazione Probabilistica\n\nVariabili Aleatorie: Quantit√† incerte che assumono diversi valori secondo una distribuzione di probabilit√†. Ad esempio, il livello di depressione di un paziente pu√≤ essere trattato come una variabile aleatoria.\nDistribuzioni di Probabilit√†: Descrivono come i valori di una variabile aleatoria sono distribuiti. Ad esempio, una distribuzione normale pu√≤ essere utilizzata per modellare la variabilit√† dell‚Äôansia in una popolazione.\nInferenza Bayesiana: Aggiorna la distribuzione di probabilit√† delle variabili di interesse sulla base dei nuovi dati, migliorando progressivamente le stime.\n\nEsempio: Inferenza sul Livello di Depressione\nIn uno studio clinico sulla depressione, possiamo utilizzare l‚Äôinferenza bayesiana per stimare il livello di depressione di un paziente partendo da una distribuzione a priori informata da studi precedenti. Ogni nuovo dato raccolto (come punteggi a questionari o osservazioni) permette di aggiornare questa stima, affinando progressivamente la comprensione del fenomeno.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>39</span>¬† <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#il-potere-dellaggiornamento-bayesiano",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#il-potere-dellaggiornamento-bayesiano",
    "title": "39¬† La quantificazione dell‚Äôincertezza",
    "section": "39.8 Il Potere dell‚ÄôAggiornamento Bayesiano",
    "text": "39.8 Il Potere dell‚ÄôAggiornamento Bayesiano\nIl vero punto di forza della modellazione bayesiana risiede nella sua capacit√† di aggiornare continuamente le credenze sui parametri del modello man mano che si raccolgono nuovi dati. Questo processo iterativo, basato sul teorema di Bayes, consente di integrare sia le credenze iniziali (a priori) sia le evidenze empiriche (verosimiglianza) per ottenere stime sempre pi√π precise.\nEsempio Intuitivo: Il Globo Terrestre\nUn esempio intuitivo per spiegare l‚Äôaggiornamento bayesiano √® quello proposto da McElreath (2020). Supponiamo di voler stimare la proporzione della superficie terrestre coperta d‚Äôacqua. L‚Äôesperimento consiste nel lanciare un globo terrestre in aria, afferrarlo e osservare se la superficie sotto il dito √® acqua o terra. Dopo ogni osservazione, possiamo aggiornare le nostre credenze sulla proporzione d‚Äôacqua (p).\nIniziamo con una distribuzione a priori che assegna la stessa probabilit√† a tutti i valori possibili di \\(p\\) (proporzione d‚Äôacqua). Dopo il primo lancio, in cui osserviamo acqua (‚ÄúW‚Äù), la probabilit√† che \\(p\\) sia zero diminuisce, mentre quella che \\(p\\) sia maggiore aumenta. Man mano che raccogliamo pi√π dati, la distribuzione si aggiorna, riducendo l‚Äôincertezza e convergendo verso una stima pi√π precisa di \\(p\\).\nCon l‚Äôaumento dei dati osservati, la distribuzione a posteriori si concentra sempre di pi√π attorno ai valori di \\(p\\) che meglio spiegano i dati. Questo processo rappresenta il continuo affinamento delle stime bayesiane, che diventano pi√π accurate man mano che le evidenze si accumulano.\nIn sintesi, l‚Äôaggiornamento bayesiano fornisce un quadro flessibile e sistematico per trattare l‚Äôincertezza e integrare nuove informazioni. √à particolarmente utile nelle scienze psicologiche e sociali, dove la complessit√† e la variabilit√† dei fenomeni rendono difficile ottenere stime precise. Questo approccio consente di migliorare costantemente la comprensione dei fenomeni, adattando le credenze man mano che emergono nuovi dati.\n\n\n\n\n\n\n\n\n\nIl grafico precedente illustra un processo di aggiornamento bayesiano, in cui vengono progressivamente aggiornate le credenze sulla proporzione di superficie coperta d‚Äôacqua (\\(p\\)) del globo terrestre, man mano che vengono raccolti nuovi dati.\nL‚Äôesperimento prevede il lancio di un globo terrestre per osservare se la superficie sotto il dito √® acqua (‚ÄúW‚Äù) o terra (‚ÄúL‚Äù). Dopo ogni lancio, le probabilit√† sui possibili valori di \\(p\\) vengono aggiornate sulla base delle osservazioni, utilizzando il teorema di Bayes. Il processo √® visualizzato attraverso una serie di grafici, organizzati in una griglia 3x3, con ogni pannello che rappresenta un‚Äôosservazione aggiuntiva.\n\nLinee tratteggiate: Ogni curva tratteggiata in un pannello rappresenta la distribuzione di probabilit√† a posteriori (posterior) derivata dal pannello precedente. In altre parole, questa √® la distribuzione che incorpora tutte le osservazioni fino a quel momento.\nLinee continue: Ogni curva continua rappresenta la nuova distribuzione a posteriori, aggiornata dopo aver aggiunto una nuova osservazione. Questa curva combina la distribuzione a priori (che coincide con la curva tratteggiata dal pannello precedente) e la nuova evidenza.\n\n\nPrimo Pannello (Osservazione: W)\n\nLa prima osservazione √® ‚Äúacqua‚Äù (W). La distribuzione a priori √® uniforme, poich√© non ci sono informazioni iniziali. Dopo aver osservato acqua, la distribuzione a posteriori si aggiorna: la probabilit√† che \\(p = 0\\) (nessuna acqua) √® ora zero, e la curva si sposta verso destra, indicando che √® pi√π probabile che \\(p\\) sia maggiore di 0.\n\nSecondo Pannello (Osservazione: L)\n\nLa seconda osservazione √® ‚Äúterra‚Äù (L). La curva si sposta leggermente verso sinistra, poich√© √® ora meno probabile che \\(p\\) sia molto alto (vicino a 1). La probabilit√† che \\(p\\) sia 0.5 diventa massima, in quanto abbiamo osservato una volta acqua e una volta terra.\n\nTerzo Pannello (Osservazione: W)\n\nIl terzo lancio produce di nuovo acqua. La curva si sposta nuovamente verso destra, con un picco vicino a \\(p = 0.75\\), riflettendo che abbiamo osservato acqua due volte su tre. La distribuzione si aggiorna in base alla nuova evidenza.\n\nPannelli Successivi\n\nOgni nuovo pannello segue lo stesso schema: la distribuzione a priori (linea tratteggiata) viene aggiornata con la nuova osservazione (linea continua). Se viene osservata acqua (W), il picco della distribuzione si sposta a destra; se viene osservata terra (L), il picco si sposta a sinistra. In ogni caso, la curva diventa progressivamente pi√π ‚Äúappuntita‚Äù, indicando che l‚Äôincertezza sulla vera proporzione di acqua diminuisce con l‚Äôaumentare del numero di osservazioni.\n\n\nL‚Äôaspetto fondamentale dell‚Äôapproccio bayesiano √® che ogni distribuzione a posteriori aggiornata (linea continua) diventa la nuova distribuzione a priori per la successiva osservazione. Questo processo iterativo permette di apprendere progressivamente dai dati, integrando ogni nuova informazione per affinare la stima di \\(p\\). Alla fine, la distribuzione diventa sempre pi√π concentrata intorno al valore pi√π probabile di \\(p\\), man mano che raccogliamo pi√π dati.\nIn conclusione, l‚Äôesempio illustra come l‚Äôaggiornamento bayesiano modifichi le nostre credenze sulla proporzione d‚Äôacqua (\\(p\\)) sulla superficie del globo, basandosi sulle osservazioni raccolte. Ogni curva rappresenta la sintesi delle conoscenze attuali, combinando le osservazioni precedenti con l‚Äôultima evidenza raccolta. Il grafico dimostra visivamente come l‚Äôapproccio bayesiano consenta di trattare l‚Äôincertezza e aggiornare le stime in modo coerente e progressivo.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>39</span>¬† <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#il-processo-generatore-dei-dati",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#il-processo-generatore-dei-dati",
    "title": "39¬† La quantificazione dell‚Äôincertezza",
    "section": "39.9 Il Processo Generatore dei Dati",
    "text": "39.9 Il Processo Generatore dei Dati\nNel contesto dell‚Äôaggiornamento bayesiano, √® fondamentale fare un‚Äôassunzione su quale modello statistico descriva il processo generatore dei dati, ossia il meccanismo che collega i parametri sconosciuti ai dati osservati. Questo modello √® rappresentato dalla funzione di verosimiglianza, che descrive la probabilit√† di osservare i dati per ogni possibile valore del parametro incognito. Ad esempio, nel caso di esperimenti bernoulliani come quello dei lanci del globo, ogni prova pu√≤ risultare in un successo (acqua) o in un fallimento (terra), e l‚Äôobiettivo √® stimare la probabilit√† di successo, \\(\\theta\\).\nIl processo generatore dei dati per questo tipo di esperimento √® ben descritto da una distribuzione binomiale, che modella il numero di successi osservati in una serie di prove indipendenti, ciascuna caratterizzata dalla stessa probabilit√† \\(\\theta\\). In questo contesto, \\(\\theta\\) rappresenta la proporzione di superficie coperta d‚Äôacqua sul globo, e l‚Äôassunzione chiave √® che essa rimanga costante durante l‚Äôintero esperimento.\n\n\n\n\n\n\nFigura¬†39.1: Gli stessi dati possono essere coerenti con diverse ipotesi riguardanti il processo che li ha generati(Figura tratta da Freiesleben & Molnar, 2024).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>39</span>¬† <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#aggiornamento-bayesiano-e-processo-generatore",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#aggiornamento-bayesiano-e-processo-generatore",
    "title": "39¬† La quantificazione dell‚Äôincertezza",
    "section": "39.10 Aggiornamento Bayesiano e Processo Generatore",
    "text": "39.10 Aggiornamento Bayesiano e Processo Generatore\nL‚Äôaggiornamento bayesiano permette di modificare le nostre credenze riguardo al valore del parametro \\(\\theta\\) man mano che osserviamo nuovi dati. Il punto di partenza √® una distribuzione a priori su \\(\\theta\\), che pu√≤ riflettere la nostra ignoranza (ad esempio, una distribuzione uniforme, che assegna uguale probabilit√† a tutti i valori di \\(\\theta\\) tra 0 e 1) o conoscenze preesistenti. Nel nostro esempio con il globo, possiamo iniziare con una distribuzione a priori uniforme, che indica che ogni proporzione di acqua √® inizialmente considerata ugualmente probabile.\nMan mano che raccogliamo dati (ad esempio, 6 successi su 9 lanci), applichiamo il Teorema di Bayes per combinare la distribuzione a priori con la verosimiglianza dei dati osservati, ottenendo una distribuzione a posteriori che rappresenta le nostre credenze aggiornate su \\(\\theta\\). La distribuzione a posteriori riflette le informazioni aggiunte dai dati e fornisce una stima aggiornata e pi√π precisa di \\(\\theta\\).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>39</span>¬† <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#interpretazione-della-distribuzione-a-posteriori",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#interpretazione-della-distribuzione-a-posteriori",
    "title": "39¬† La quantificazione dell‚Äôincertezza",
    "section": "39.11 Interpretazione della Distribuzione a Posteriori",
    "text": "39.11 Interpretazione della Distribuzione a Posteriori\nLa distribuzione a posteriori ci permette di fare inferenze pi√π solide su \\(\\theta\\). In particolare, possiamo calcolare:\n\nModa: Il valore di \\(\\theta\\) con la massima probabilit√†, che indica la stima pi√π plausibile.\nMedia o Mediana: Altre misure riassuntive della distribuzione a posteriori, che possono fornire ulteriori informazioni sull‚Äôintervallo di valori probabili per \\(\\theta\\).\n\nL‚Äôincertezza sulla stima √® rappresentata dall‚Äôampiezza della distribuzione a posteriori. Se la distribuzione √® stretta, significa che l‚Äôincertezza √® bassa, mentre una distribuzione pi√π ampia indica una maggiore incertezza. Con l‚Äôaumento dei dati osservati, la distribuzione tende a concentrarsi intorno a un intervallo ristretto, riducendo l‚Äôincertezza e migliorando la precisione della stima.\nNel caso del globo, ad esempio, se osserviamo che la distribuzione a posteriori ha un picco vicino a \\(\\theta = 0.67\\), possiamo concludere che la probabilit√† pi√π plausibile per la proporzione di acqua sul globo √® circa 67%. Inoltre, se la distribuzione a posteriori √® stretta, possiamo essere pi√π sicuri di questa stima, mentre se √® pi√π ampia, la nostra incertezza sar√† maggiore.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>39</span>¬† <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#influenza-delle-distribuzioni-a-priori",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#influenza-delle-distribuzioni-a-priori",
    "title": "39¬† La quantificazione dell‚Äôincertezza",
    "section": "39.12 Influenza delle Distribuzioni a Priori",
    "text": "39.12 Influenza delle Distribuzioni a Priori\nIn questo esempio, abbiamo utilizzato una distribuzione a priori uniforme, che esprime una totale mancanza di conoscenza iniziale su \\(\\theta\\). Tuttavia, in contesti in cui abbiamo informazioni preesistenti, √® possibile utilizzare distribuzioni a priori pi√π informative. Ad esempio, se sappiamo da studi precedenti che circa il 70% della superficie terrestre √® coperta d‚Äôacqua, possiamo utilizzare una distribuzione a priori che rifletta questa conoscenza. Questo tipo di distribuzione a priori informativa pu√≤ rendere l‚Äôaggiornamento bayesiano pi√π efficiente, portando a stime pi√π precise con meno dati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>39</span>¬† <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#vantaggi-dellaggiornamento-bayesiano",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#vantaggi-dellaggiornamento-bayesiano",
    "title": "39¬† La quantificazione dell‚Äôincertezza",
    "section": "39.13 Vantaggi dell‚ÄôAggiornamento Bayesiano",
    "text": "39.13 Vantaggi dell‚ÄôAggiornamento Bayesiano\nUno dei principali vantaggi dell‚Äôapproccio bayesiano √® che ogni nuova osservazione aggiorna automaticamente le credenze preesistenti, integrando le informazioni precedenti con i nuovi dati. Questo processo consente un apprendimento iterativo e progressivo, che diventa pi√π efficiente man mano che si accumulano dati. Inoltre, la flessibilit√† nella scelta della distribuzione a priori consente al ricercatore di adattare l‚Äôinferenza bayesiana al contesto specifico, migliorando ulteriormente la precisione delle stime.\nIn sintesi, il processo generatore dei dati, modellato tramite la verosimiglianza, gioca un ruolo centrale nell‚Äôaggiornamento bayesiano. Nel caso del globo, abbiamo modellato il fenomeno utilizzando una distribuzione binomiale e, attraverso l‚Äôapplicazione del Teorema di Bayes, abbiamo aggiornato progressivamente le nostre credenze sulla proporzione di acqua osservata. Il risultato √® una stima sempre pi√π precisa di \\(\\theta\\), con una distribuzione a posteriori che riflette sia le osservazioni passate sia le nuove evidenze, riducendo progressivamente l‚Äôincertezza.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>39</span>¬† <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#riflessioni-conclusive",
    "title": "39¬† La quantificazione dell‚Äôincertezza",
    "section": "39.14 Riflessioni Conclusive",
    "text": "39.14 Riflessioni Conclusive\nNegli ultimi anni, i metodi bayesiani stanno acquisendo sempre pi√π importanza nel campo dell‚Äôinferenza statistica, anche in discipline come la psicologia. Questa diffusione √® favorita dall‚Äôaccesso a risorse educative e a testi fondamentali, come quelli di Albert & Hu (2019), Johnson et al. (2022), McElreath (2020) e Kruschke (2014), che hanno reso la modellizzazione bayesiana pi√π accessibile, chiarendo i concetti centrali in modo pratico e comprensibile.\nL‚Äôapproccio bayesiano si distingue dalla metodologia frequentista tradizionale per la sua capacit√† di trattare i parametri di interesse come quantit√† probabilistiche. Invece di considerare i parametri come valori fissi e sconosciuti (come avviene nel paradigma frequentista), il bayesianesimo assegna ai parametri una distribuzione a priori, che rappresenta le credenze iniziali del ricercatore. Man mano che nuovi dati vengono raccolti, queste credenze vengono aggiornate tramite il teorema di Bayes, portando a una distribuzione a posteriori che riflette sia le informazioni pregresse sia l‚Äôevidenza empirica. Questa distribuzione aggiornata consente di esprimere l‚Äôincertezza sui parametri in modo pi√π completo e informato.\nUno dei principali vantaggi dell‚Äôapproccio bayesiano √® la sua capacit√† di combinare conoscenze pregresse con nuove osservazioni in modo fluido e sistematico. Ogni nuova informazione arricchisce e raffina le stime, rendendole pi√π accurate e interpretabili nel contesto del problema specifico. Questo non solo migliora la precisione delle inferenze, ma permette anche una migliore comprensione dell‚Äôincertezza che circonda i parametri studiati.\nIn definitiva, l‚Äôinferenza bayesiana non √® solo uno strumento analitico, ma un approccio dinamico che incoraggia un‚Äôinterazione continua tra teoria ed evidenza. Offrendo una flessibilit√† unica e una gestione esplicita dell‚Äôincertezza, il bayesianesimo si rivela un metodo potente per supportare il processo decisionale in contesti complessi, rendendo le sue applicazioni particolarmente rilevanti in campi come la psicologia, dove l‚Äôincertezza √® una componente inevitabile dell‚Äôanalisi dei dati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>39</span>¬† <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#informazioni-sullambiente-di-sviluppo",
    "title": "39¬† La quantificazione dell‚Äôincertezza",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: US/Pacific\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] ggokabeito_0.1.0 see_0.9.0        gridExtra_2.3    patchwork_1.3.0 \n#&gt;  [5] bayesplot_1.11.1 psych_2.4.12     scales_1.3.0     markdown_1.13   \n#&gt;  [9] knitr_1.49       lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1   \n#&gt; [13] dplyr_1.1.4      purrr_1.0.2      readr_2.1.5      tidyr_1.3.1     \n#&gt; [17] tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3       \n#&gt; [21] here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.3         rlang_1.1.4       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       yaml_2.3.10       tools_4.4.2       parallel_4.4.2   \n#&gt; [21] tzdb_0.4.0        colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5      \n#&gt; [25] R6_2.5.1          lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3  \n#&gt; [29] pillar_1.10.1     gtable_0.3.6      glue_1.8.0        xfun_0.50        \n#&gt; [33] tidyselect_1.2.1  farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-166     \n#&gt; [37] rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>39</span>¬† <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#bibliografia",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#bibliografia",
    "title": "39¬† La quantificazione dell‚Äôincertezza",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAlbert, J., & Hu, J. (2019). Probability and Bayesian Modeling. CRC Press.\n\n\nBaribault, B., & Collins, A. G. (2023). Troubleshooting Bayesian cognitive models. Psychological Methods.\n\n\nFreiesleben, T., & Molnar, C. (2024). Supervised Machine Learning for Science: How to stop worrying and love your black box. https://ml-science-book.com/\n\n\nGoligher, E. C., Heath, A., & Harhay, M. O. (2024). Bayesian statistics for clinical research. The Lancet, 404(10457), 1067‚Äì1076. https://doi.org/10.1016/S0140-6736(24)00055-9\n\n\nJaynes, E. T. (2003). Probability theory: The logic of science. Cambridge University Press.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nKruschke, J. (2014). Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan. Academic Press.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>39</span>¬† <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_bayesian_inference.html",
    "href": "chapters/bayesian_inference/02_bayesian_inference.html",
    "title": "40¬† Inferenza bayesiana",
    "section": "",
    "text": "40.1 Introduzione\nQuesto capitolo approfondisce i concetti introdotti nel precedente, presentando l‚Äôaggiornamento bayesiano in modo formale e dettagliato.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>¬† <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_bayesian_inference.html#introduzione",
    "href": "chapters/bayesian_inference/02_bayesian_inference.html#introduzione",
    "title": "40¬† Inferenza bayesiana",
    "section": "",
    "text": "40.1.1 Il Paradigma dell‚ÄôInferenza Bayesiana\nAl centro dell‚Äôinferenza bayesiana vi √® l‚Äôidea che la probabilit√† misuri il grado di certezza soggettiva riguardo a un‚Äôipotesi o alla plausibilit√† di un valore per un parametro sconosciuto. L‚Äôinferenza bayesiana si basa sul concetto di aggiornamento continuo: partendo da credenze iniziali (priori), queste vengono riviste alla luce di nuove informazioni fornite dai dati, producendo credenze aggiornate (posteriori).\nPer esempio, consideriamo il caso di una moneta. Dopo averla lanciata 10 volte osserviamo 8 testa (\\(y = 8\\)) e ci chiediamo se la moneta sia equilibrata (\\(p = 0.5\\)). Per rispondere, definiamo un modello generativo dei dati, il pi√π semplice dei quali √® il modello binomiale, caratterizzato dal parametro \\(p\\), la probabilit√† di ottenere testa. Questo parametro √® l‚Äôoggetto della nostra inferenza.\n\n\n40.1.2 Approccio Classico: Massima Verosimiglianza\nUn metodo classico √® la massima verosimiglianza, che stima \\(p\\) come rapporto tra successi e tentativi: \\(\\hat{p} = y/N = 0.8\\). Tuttavia, questa stima puntuale non fornisce informazioni sull‚Äôincertezza associata a \\(p\\) o sulla plausibilit√† di altri valori vicini.\n\n\n40.1.3 Approccio Bayesiano: Prior e Posteriori\nL‚Äôapproccio bayesiano supera questa limitazione introducendo una distribuzione a priori per \\(p\\), che riflette le credenze iniziali. Una distribuzione uniforme su \\([0, 1]\\) considera tutti i valori di \\(p\\) ugualmente plausibili, mentre una distribuzione centrata su \\(0.5\\) indica una convinzione iniziale che la moneta sia equilibrata.\nDopo aver osservato i dati (\\(y = 8\\), \\(N = 10\\)), combiniamo il prior con la funzione di verosimiglianza (che esprime la probabilit√† dei dati per ciascun valore ipotizzato di \\(p\\)) tramite il teorema di Bayes:\n\\[\np(\\theta \\mid y) \\propto p(y \\mid \\theta)p(\\theta),\n\\]\ndove:\n\n\\(p(\\theta)\\) √® la distribuzione a priori.\n\\(p(y \\mid \\theta)\\) √® la verosimiglianza.\n\\(p(\\theta \\mid y)\\) √® la distribuzione a posteriori.\n\nIl teorema di Bayes produce una distribuzione a posteriori, che integra le informazioni iniziali con quelle dei dati osservati, fornendo:\n\nUna stima plausibile di \\(p\\) (ad esempio, mediana o moda della distribuzione a posteriori).\nUna misura dell‚Äôincertezza associata a \\(p\\) (ad esempio, varianza o intervalli di credibilit√†).\n\n\n\n40.1.4 Vantaggi dell‚ÄôInferenza Bayesiana\nL‚Äôinferenza bayesiana non si limita a stime puntuali ma descrive lo stato attuale di conoscenza attraverso una distribuzione completa. Questo approccio √® particolarmente utile in contesti con dati scarsi o elevata incertezza, frequenti in psicologia.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>¬† <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_bayesian_inference.html#implementazione-e-calcolo",
    "href": "chapters/bayesian_inference/02_bayesian_inference.html#implementazione-e-calcolo",
    "title": "40¬† Inferenza bayesiana",
    "section": "40.2 Implementazione e Calcolo",
    "text": "40.2 Implementazione e Calcolo\nPer calcolare la distribuzione a posteriori in un contesto di inferenza bayesiana, si possono adottare due approcci principali.\n\n40.2.1 Approccio Analitico (o Coniugato)\nQuesto metodo √® applicabile quando la distribuzione a priori appartiene alla stessa famiglia di distribuzioni della funzione di verosimiglianza, definendo una relazione coniugata. In questi casi:\n\nLa distribuzione a posteriori pu√≤ essere calcolata esattamente attraverso formule matematiche, senza necessit√† di approssimazioni.\n\nL‚Äôapproccio √® computazionalmente efficiente, poich√© evita algoritmi iterativi complessi.\n\nLimitazioni:\n\nLa coniugazione √® possibile solo per modelli semplici e specifici, limitando l‚Äôuso di questo approccio ai casi in cui le assunzioni sono realistiche.\n\nNei dati reali, la necessit√† di flessibilit√† spesso rende queste assunzioni troppo restrittive.\n\n\n\n40.2.2 Approccio Numerico\nQuando il calcolo analitico non √® possibile, ad esempio per modelli complessi o distribuzioni non coniugate, si ricorre a metodi numerici per stimare la distribuzione a posteriori in modo approssimato ma accurato.\n\n40.2.2.1 Metodi Basati su Catene di Markov Monte Carlo\nGli algoritmi MCMC campionano iterativamente dalla distribuzione a posteriori, garantendo la convergenza a quest‚Äôultima con un numero sufficiente di iterazioni. Tra i metodi pi√π diffusi:\n\nMetropolis-Hastings: Un algoritmo generale adatto a una vasta gamma di distribuzioni.\n\nGibbs Sampling: Una variante particolarmente efficiente quando le distribuzioni condizionali sono note, anche se la distribuzione congiunta √® difficile da campionare direttamente.\n\n\n\n40.2.2.2 Altri Metodi Numerici\nOltre alle MCMC, si utilizzano anche approcci alternativi:\n\nVariational Bayes:\n\nCerca una distribuzione \\(q(z)\\) che approssima \\(p(z \\mid x)\\) minimizzando una misura di divergenza, come la divergenza di Kullback-Leibler.\n\nQuesto metodo trasforma il problema di inferenza in un problema di ottimizzazione, risultando spesso pi√π veloce delle MCMC, ma talvolta meno accurato.\n\n\nApprossimazione di Laplace:\n\nApprossima la distribuzione a posteriori con una normale centrata sul valore MAP (massimo a posteriori) e con una matrice di covarianza basata sull‚Äôinverso dell‚ÄôHessiano negativo al MAP.\n\n√à efficiente, ma l‚Äôaccuratezza √® limitata nelle regioni lontane dal MAP o per distribuzioni non gaussiane.\n\n\n\n\n\n40.2.3 Vantaggi e Svantaggi degli Approcci Numerici\nVantaggi:\n\nVersatilit√†: Applicabili a una vasta gamma di modelli e distribuzioni, anche molto complessi.\n\nFlessibilit√†: Consentono di incorporare informazioni a priori articolate.\n\nSvantaggi:\n\nCosto Computazionale: Modelli complessi o grandi dataset richiedono risorse computazionali elevate.\n\nTuning degli Algoritmi: Parametri come la proposta iniziale nelle MCMC devono essere scelti attentamente per garantire efficienza e convergenza.\n\nIn sintesi\n\nl‚Äôapproccio analitico √® ideale per semplicit√† ed efficienza ma limitato a casi specifici;\nl‚Äôapproccio numerico, pur richiedendo maggiore attenzione e risorse, offre una soluzione generale e flessibile per affrontare modelli realistici.\n\nLa scelta dell‚Äôapproccio dipende dalla complessit√† del modello e dalla natura dei dati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>¬† <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_bayesian_inference.html#programmazione-probabilistica",
    "href": "chapters/bayesian_inference/02_bayesian_inference.html#programmazione-probabilistica",
    "title": "40¬† Inferenza bayesiana",
    "section": "40.3 Programmazione Probabilistica",
    "text": "40.3 Programmazione Probabilistica\nI linguaggi di programmazione probabilistica (PPL) facilitando l‚Äôuso di tecniche di approssimazione numerica per stimare le distribuzioni posteriori. Grazie ai PPL, la modellizzazione probabilistica diventa pi√π accessibile, riducendo le barriere tecniche e computazionali. Questi strumenti consentono di definire modelli in modo dichiarativo, descrivendo le relazioni tra le variabili in termini probabilistici senza doversi occupare dei dettagli algoritmici sottostanti. In altre parole, i PPL permettono ai ricercatori di concentrarsi sull‚Äôespressione del modello, lasciando ai linguaggi il compito di gestire l‚Äôimplementazione computazionale.\nTra i PPL pi√π utilizzati troviamo:\n\nStan: Uno dei linguaggi pi√π popolari, noto per la sua efficienza e flessibilit√†.\nPyMC: Molto utilizzato nell‚Äôecosistema Python, offre un‚Äôinterfaccia user-friendly per la modellazione bayesiana.\nTensorFlow: Un framework che combina un approccio probabilistico con le reti neurali.\n\n\n40.3.1 Come Funzionano i PPL?\nI linguaggi di programmazione probabilistica richiedono semplicemente la descrizione del modello probabilistico. Successivamente, utilizzano algoritmi di inferenza, come le catene di Markov Monte Carlo (MCMC) o l‚Äôinferenza variazionale, per stimare la distribuzione posteriore delle variabili di interesse. Ci√≤ consente ai ricercatori di ottenere stime delle variabili sconosciute e di valutare l‚Äôincertezza associata.\nIn conclusione, i linguaggi di programmazione probabilistica hanno trasformato il modo in cui affrontiamo l‚Äôinferenza bayesiana, rendendola pi√π accessibile e potente. Grazie alla loro semplicit√† d‚Äôuso e alla potenza computazionale, i PPL hanno reso l‚Äôinferenza bayesiana uno strumento sempre pi√π diffuso in molte discipline, inclusa la psicologia. Questo approccio facilita la modellazione di fenomeni complessi e l‚Äôanalisi rigorosa di dati, offrendo un metodo efficace per rispondere a domande di ricerca psicologica in modo trasparente e accurato.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>¬† <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_bayesian_inference.html#notazione",
    "href": "chapters/bayesian_inference/02_bayesian_inference.html#notazione",
    "title": "40¬† Inferenza bayesiana",
    "section": "40.4 Notazione",
    "text": "40.4 Notazione\nIn seguito, utilizzeremo \\(y\\) per rappresentare i dati osservati e \\(\\theta\\) per indicare i parametri sconosciuti di un modello statistico. Entrambi, \\(y\\) e \\(\\theta\\), saranno trattati come variabili casuali. Utilizzeremo \\(x\\) per denotare le quantit√† note, come i predittori di un modello lineare.\n√à comune scrivere modelli statistici utilizzando la seguente notazione:\n\\[\n\\begin{aligned}\ny & \\sim \\mathrm{normal}(\\mu, \\sigma) \\\\\n\\mu & \\sim \\mathrm{normal}(0, 10) \\\\\n\\sigma & \\sim \\mathrm{normal}^+(\\sigma \\mid  0, 1),\n\\end{aligned}\n\\]\ndove il simbolo \\(\\sim\\) √® chiamato tilde (\\sim in LaTeX).\nIn generale, possiamo leggere \\(\\sim\\) come ‚Äú√® distribuito come‚Äù, e questa notazione √® usata come una scorciatoia per definire distribuzioni. L‚Äôesempio sopra pu√≤ essere scritto anche come:\n\\[\n\\begin{aligned}\n   p(y \\mid \\mu, \\sigma) & = \\mathrm{normal}(y \\mid  \\mu, \\sigma)\\\\\n   p(\\mu) & = \\mathrm{normal}(\\mu \\mid 0, 10)\\\\\n   p(\\sigma) & = \\mathrm{normal}^+(\\sigma \\mid  0, 1).\n\\end{aligned}\n\\]",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>¬† <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_bayesian_inference.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/02_bayesian_inference.html#riflessioni-conclusive",
    "title": "40¬† Inferenza bayesiana",
    "section": "40.5 Riflessioni Conclusive",
    "text": "40.5 Riflessioni Conclusive\nAl cuore della ricerca scientifica c‚Äô√® una domanda del tipo: ‚Äúdimmi qualcosa sulla variabile \\(\\theta\\) dato che ho osservato i dati \\(D\\) e ho una certa conoscenza del meccanismo sottostante che genera i dati‚Äù. La regola di Bayes fornisce la seguente risposta:\n\\[\np(\\theta \\mid D) = \\frac{p(D \\mid\\theta) p(\\theta)}{p(D)} = \\frac{p(D \\mid \\theta) p(\\theta)}{\\int_\\theta p(D \\mid\\theta) p(\\theta) d\\theta}.\n\\]\nQuesta equazione mostra come, partendo da un modello generativo \\(p(D \\mid\\theta)\\) dei dati osservati e abbinato a una credenza a priori \\(p(\\theta)\\) su quali valori della variabile \\(\\theta\\) siano plausibili, possiamo inferire la distribuzione a posteriori \\(p(\\theta \\mid D)\\) della variabile alla luce dei dati osservati.\nLa stima MAP (Massimo A Posteriori), che corrisponde al valore di \\(\\theta\\) che massimizza la distribuzione a posteriori, rappresenta una stima puntuale del parametro:\n\\[\n\\theta^* = \\arg \\max_\\theta p(\\theta \\mid D).\n\\]\nNel caso di un prior non informativo (piatto), la stima MAP coincide con la stima di massima verosimiglianza, ovvero il valore di \\(\\theta\\) che massimizza la probabilit√† che il modello generi i dati osservati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>¬† <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_bayesian_inference.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/02_bayesian_inference.html#informazioni-sullambiente-di-sviluppo",
    "title": "40¬† Inferenza bayesiana",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: US/Pacific\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] ggokabeito_0.1.0 see_0.9.0        gridExtra_2.3    patchwork_1.3.0 \n#&gt;  [5] bayesplot_1.11.1 psych_2.4.12     scales_1.3.0     markdown_1.13   \n#&gt;  [9] knitr_1.49       lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1   \n#&gt; [13] dplyr_1.1.4      purrr_1.0.2      readr_2.1.5      tidyr_1.3.1     \n#&gt; [17] tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3       \n#&gt; [21] here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.3         rlang_1.1.4       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       yaml_2.3.10       tools_4.4.2       parallel_4.4.2   \n#&gt; [21] tzdb_0.4.0        colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5      \n#&gt; [25] R6_2.5.1          lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3  \n#&gt; [29] pillar_1.10.1     gtable_0.3.6      glue_1.8.0        xfun_0.50        \n#&gt; [33] tidyselect_1.2.1  farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-166     \n#&gt; [37] rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>¬† <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_bayesian_inference.html#bibliografia",
    "href": "chapters/bayesian_inference/02_bayesian_inference.html#bibliografia",
    "title": "40¬† Inferenza bayesiana",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>¬† <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html",
    "href": "chapters/bayesian_inference/03_subj_prop.html",
    "title": "41¬† Pensare ad una proporzione in termini soggettivi",
    "section": "",
    "text": "41.1 Introduzione\nL‚Äôinferenza bayesiana √® un metodo di inferenza statistica che utilizza la probabilit√† per aggiornare le credenze sui parametri di un modello, sulla base di nuove evidenze o dati osservati. Essa fornisce un quadro concettuale per stimare variabili sconosciute, tenendo conto dell‚Äôincertezza. Attraverso un modello che descrive le dipendenze tra variabili aleatorie, la teoria della probabilit√† pu√≤ essere impiegata per inferire tutte le quantit√† sconosciute. In questo approccio, tutte le incertezze, sia nelle osservazioni che nei parametri del modello, sono trattate come distribuzioni di probabilit√†.\nIn sintesi, l‚Äôinferenza bayesiana √® il processo di deduzione delle propriet√† di una distribuzione di probabilit√† a partire dai dati, utilizzando il teorema di Bayes. Questo processo incorpora l‚Äôidea che la probabilit√† rappresenti una misura della fiducia su una previsione o un risultato.\nQuesto capitolo ha lo scopo di esplorare in dettaglio il concetto di aggiornamento bayesiano, illustrandolo con un esempio concreto in un contesto semplificato. L‚Äôobiettivo √® dimostrare come le credenze preesistenti sulla probabilit√† di un parametro \\(\\theta\\) possano essere aggiornate attraverso l‚Äôosservazione di nuovi dati.\nIl primo passo nell‚Äôinferenza bayesiana consiste nel rappresentare le credenze iniziali, formulate prima di raccogliere i dati, tramite una distribuzione a priori. La distribuzione a priori riflette le nostre conoscenze o ipotesi preesistenti su \\(\\theta\\) e pu√≤ variare in base al contesto o alle informazioni pregresse disponibili.\nUna volta ottenuti nuovi dati, il passaggio successivo √® l‚Äôaggiornamento delle credenze tramite la distribuzione a posteriori. Questo aggiornamento si ottiene moltiplicando la distribuzione a priori per la verosimiglianza dei dati osservati, il che riflette quanto i dati supportino un determinato valore di \\(\\theta\\). Il prodotto di questi due termini fornisce una misura delle credenze aggiornate, che viene successivamente normalizzata per garantire che il risultato sia una distribuzione di probabilit√† valida (ovvero, che l‚Äôarea sotto la curva sia pari a 1).\nIl capitolo si concentra sul modello binomiale. Questo modello √® utilizzato per stimare una proporzione sconosciuta basata su una serie di dati binari \\(y_1, \\ldots, y_n\\), ciascuno dei quali pu√≤ assumere valore 0 o 1.\nInizieremo esplorando un esempio in cui la distribuzione a priori di \\(\\theta\\) √® discreta, un caso in cui i valori possibili di \\(\\theta\\) sono limitati a un insieme finito di opzioni. Successivamente, discuteremo scenari in cui la distribuzione a priori √® continua, ampliando il modello per affrontare casi pi√π complessi e realistici. Questo approccio progressivo consente di acquisire una comprensione graduale dei concetti centrali dell‚Äôinferenza bayesiana e del loro utilizzo pratico nel contesto di problemi statistici reali.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#introduzione",
    "href": "chapters/bayesian_inference/03_subj_prop.html#introduzione",
    "title": "41¬† Pensare ad una proporzione in termini soggettivi",
    "section": "",
    "text": "L‚Äôunica cosa rilevante √® l‚Äôincertezza ‚Äì il grado della nostra conoscenza e ignoranza. Il fatto che gli eventi considerati siano in qualche modo determinati, o conosciuti da altre persone, non ha alcuna importanza.\n(Bruno deFinetti)",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#verosimiglianza-binomiale",
    "href": "chapters/bayesian_inference/03_subj_prop.html#verosimiglianza-binomiale",
    "title": "41¬† Pensare ad una proporzione in termini soggettivi",
    "section": "41.2 Verosimiglianza Binomiale",
    "text": "41.2 Verosimiglianza Binomiale\nLa distribuzione binomiale offre un modello naturale per dati che derivano da una sequenza di \\(n\\) prove indipendenti e identicamente distribuite, dove ciascuna prova d√† origine a uno dei due possibili esiti, convenzionalmente etichettati come ‚Äòsuccesso‚Äô e ‚Äòfallimento‚Äô. Grazie al fatto che le prove sono iid, i dati possono essere riassunti dal numero totale di successi nelle \\(n\\) prove, che denotiamo con \\(y\\). Il parametro \\(\\theta\\) rappresenta la proporzione di successi nella popolazione o, equivalentemente, la probabilit√† di successo in ciascuna prova. Il modello di campionamento binomiale √®:\n\\[\np(y \\mid \\theta) = \\text{Bin}(y \\mid n, \\theta) = \\binom{n}{y} \\theta^y (1 - \\theta)^{n-y},\n\\]\ndove nella parte sinistra dell‚Äôequazione non si indica la dipendenza da \\(n\\) perch√© viene considerato parte del disegno sperimentale e fissato; tutte le probabilit√† discusse per questo problema sono considerate condizionate su \\(n\\), cio√® assumono che il numero totale di prove sia fissato e noto.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#applicazione-specifica-del-modello-binomiale",
    "href": "chapters/bayesian_inference/03_subj_prop.html#applicazione-specifica-del-modello-binomiale",
    "title": "41¬† Pensare ad una proporzione in termini soggettivi",
    "section": "41.3 Applicazione Specifica del Modello Binomiale",
    "text": "41.3 Applicazione Specifica del Modello Binomiale\nIn questo capitolo, esaminiamo un‚Äôapplicazione specifica del modello binomiale per valutare la prestazione di un partecipante in un classico esperimento di psicologia, noto come Go/No-Go task (Shiffrin & Schneider, 1977). In questo tipo di compito, ai partecipanti viene richiesto di rispondere a determinati stimoli (prove Go) e di trattenere la risposta ad altri stimoli (prove No-Go). Ad esempio, i partecipanti possono vedere una serie di lettere presentate su uno schermo e devono premere un pulsante quando vedono qualsiasi lettera tranne una specifica lettera bersaglio (ad esempio, la lettera ‚ÄúX‚Äù). In questo esperimento, ogni prova rappresenta un evento di tipo bernoulliano con due possibili esiti: o il partecipante risponde correttamente o commette un errore. I ricercatori analizzano la percentuale di risposte corrette e di inibizioni, concentrandosi in particolare sulla capacit√† del partecipante di controllare l‚Äôimpulso di rispondere durante le prove No-Go.\nConsideriamo un piccolo numero di prove No-Go di un partecipante, dove i risultati sono: 1, 0, 1, 1, 1, 0, 1, 0, 1. Qui, il valore ‚Äú1‚Äù indica che il partecipante √® stato in grado di inibire la risposta, mentre ‚Äú0‚Äù indica che non √® riuscito a farlo. L‚Äôobiettivo dell‚Äôanalisi √® quantificare l‚Äôincertezza nella stima di \\(\\theta\\), che rappresenta la proporzione di risposte corrette nel compito No-Go, ovvero la capacit√† inibitoria del partecipante.\nConsideriamo questi dati come una sequenza di 9 prove bernoulliane indipendenti. Utilizzando il modello binomiale, stimiamo la probabilit√† \\(\\theta\\) che il partecipante riesca a controllare il proprio impulso di rispondere durante le prove No-Go e quantifichiamo l‚Äôincertezza associata a questa stima.\n\n41.3.1 Flusso di Lavoro Bayesiano\nMcElreath (2020) descrive il flusso di lavoro bayesiano attraverso una serie di passaggi chiari e ben definiti. Ecco una spiegazione semplificata ma formale, adatta per studenti universitari senza esperienza precedente nell‚Äôambito.\n\nDefinizione di un Modello Generativo per i Dati\nUn modello generativo rappresenta il processo attraverso cui i dati vengono prodotti. Per esempio, nel caso di un compito No-Go, ogni prova pu√≤ essere considerata come un esperimento di tipo Bernoulli, che pu√≤ produrre due possibili risultati:\n\nSuccesso: inibizione della risposta corretta (rappresentata da 1).\n\nErrore: mancata inibizione della risposta (rappresentata da 0).\n\nDenotiamo con \\(\\theta\\) la probabilit√† di inibire correttamente la risposta. Il modello generativo √® quindi formalizzato come:\n\\[\nX_i \\sim \\text{Bernoulli}(\\theta),\n\\]\ndove \\(i = 1, 2, \\dots, 9\\) indica le prove eseguite, e \\(X_i\\) rappresenta l‚Äôesito di ciascuna prova.\nDefinizione di uno Stimatore per il Parametro di Interesse\nLo stimatore √® uno strumento che ci permette di calcolare una stima del parametro di interesse (in questo caso \\(\\theta\\)) basandoci sui dati raccolti.\n\n\\(\\theta\\) rappresenta la probabilit√† di successo, ovvero di inibire correttamente la risposta.\n\nOltre a stimare \\(\\theta\\), √® importante quantificare l‚Äôincertezza della stima utilizzando i dati a disposizione.\n\nSviluppo di un Metodo Statistico per la Stima di \\(\\theta\\)\nUtilizziamo un approccio bayesiano per stimare \\(\\theta\\). Questo approccio combina:\n\nUna distribuzione a priori: rappresenta le convinzioni iniziali su \\(\\theta\\). Scegliamo una distribuzione Beta \\(\\text{Beta}(1, 1)\\), che corrisponde a una distribuzione uniforme, per indicare che non abbiamo informazioni iniziali preferenziali.\n\nLa verosimiglianza: rappresenta quanto i dati osservati siano compatibili con diversi valori di \\(\\theta\\). Per 6 successi e 3 errori, la verosimiglianza √® data da una distribuzione binomiale:\n\\[\nL(\\theta) = {9 \\choose 6} \\theta^{6} (1-\\theta)^{3}.\n\\]\nLa distribuzione a posteriori: si ottiene aggiornando la distribuzione a priori con i dati osservati, tramite il teorema di Bayes:\n\\[\n\\text{Posteriore} \\propto \\text{Verosimiglianza} \\times \\text{Priori}.\n\\]\n\nValidazione del Modello Tramite Simulazioni\nPrima di applicare il modello ai dati reali, verifichiamo che il modello sia realistico attraverso:\n\nSimulazioni predittive a priori: servono per controllare se il modello √® in grado di generare dati plausibili.\n\nSimulazioni predittive a posteriori: valutano se il modello, una volta adattato ai dati osservati, pu√≤ riprodurre risultati simili a quelli effettivamente ottenuti.\n\nAnalisi e Sintesi dei Risultati\nUna volta adattato il modello ai dati reali:\n\nUtilizziamo metodi computazionali come il Monte Carlo a catene di Markov (MCMC) per calcolare la distribuzione a posteriori.\n\nRiassumiamo i risultati tramite statistiche descrittive, come media, mediana e intervalli di credibilit√†, per fare inferenze su \\(\\theta\\).\n\n\nIn questo capitolo, mostreremo come calcolare numericamente la distribuzione a posteriori di \\(\\theta\\). Nei capitoli successivi esploreremo in dettaglio ogni fase del flusso di lavoro bayesiano descritto da McElreath (2020).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#metodo-basato-su-griglia-nellaggiornamento-bayesiano",
    "href": "chapters/bayesian_inference/03_subj_prop.html#metodo-basato-su-griglia-nellaggiornamento-bayesiano",
    "title": "41¬† Pensare ad una proporzione in termini soggettivi",
    "section": "41.4 Metodo Basato su Griglia nell‚ÄôAggiornamento Bayesiano",
    "text": "41.4 Metodo Basato su Griglia nell‚ÄôAggiornamento Bayesiano\nDopo aver discusso l‚Äôaggiornamento bayesiano e come permette di raffinare le nostre convinzioni preesistenti alla luce di nuove evidenze, esploreremo ora una tecnica specifica per realizzare questo aggiornamento: il metodo basato su griglia.\nIl metodo basato su griglia √® un approccio semplice e intuitivo per stimare la distribuzione a posteriori, particolarmente utile quando non sono disponibili soluzioni analitiche esatte o si desidera evitare l‚Äôuso di algoritmi computazionali complessi. La procedura si articola nei seguenti passi:\n\nSelezione di un intervallo per il parametro: Basandosi sulle convinzioni a priori, si definisce un intervallo ragionevole per il parametro di interesse.\nCreazione di una griglia di punti: Su questo intervallo, si distribuiscono una serie di punti, di solito equidistanti tra loro.\nCalcolo della posteriori per ogni punto: Per ogni punto della griglia, si moltiplica la verosimiglianza per il prior corrispondente.\nNormalizzazione dei risultati: Per garantire che la somma delle probabilit√† sia pari a 1, si normalizzano i valori ottenuti dividendo ciascun punto per l‚Äôarea totale sottesa dalla curva della distribuzione a posteriori.\n\nAttraverso questo metodo, si ottiene una rappresentazione approssimativa ma illustrativa della distribuzione a posteriori. Questo approccio offre un modo accessibile per visualizzare e comprendere il processo di aggiornamento bayesiano.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-discreta",
    "href": "chapters/bayesian_inference/03_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-discreta",
    "title": "41¬† Pensare ad una proporzione in termini soggettivi",
    "section": "41.5 Aggiornamento Bayesiano con una Distribuzione a Priori Discreta",
    "text": "41.5 Aggiornamento Bayesiano con una Distribuzione a Priori Discreta\n\n41.5.1 Distribuzione a priori\nQuando non disponiamo di informazioni specifiche preliminari su \\(\\theta\\), potremmo inizialmente assegnare un valore di 0.5, suggerendo una probabilit√† a priori uniforme tra le due alternative (la capacit√† di inibire la risposta e la mancanza di questa capacit√† in una prova del compito Go/No-Go). Tuttavia, questo valore non rappresenta adeguatamente l‚Äôintero spettro della nostra incertezza iniziale.\nPer riflettere meglio questa incertezza, utilizziamo una distribuzione a priori discreta, che assegna una probabilit√† distinta a ciascun valore plausibile di \\(\\theta\\). Questo approccio ci permette di quantificare le nostre convinzioni preliminari sulla distribuzione di questi valori.\nSupponiamo di considerare undici possibili valori per \\(\\theta\\), che variano da 0 a 1 con incrementi di 0.1. Possiamo attribuire a ciascun valore una probabilit√† a priori uguale, creando cos√¨ una distribuzione uniforme, oppure scegliere una distribuzione non uniforme che meglio rifletta le nostre aspettative sui valori di \\(\\theta\\) pi√π probabili.\nDopo aver osservato i dati ‚Äî nel nostro caso, 6 successi in 9 prove ‚Äî applichiamo il teorema di Bayes per trasformare la distribuzione a priori in una distribuzione a posteriori. Questo processo consiste nel combinare la probabilit√† a priori di \\(\\theta\\) con la verosimiglianza dei dati per produrre una probabilit√† a posteriori aggiornata per \\(\\theta\\).\n\n\n41.5.2 Distribuzione a Posteriori\nLa distribuzione a posteriori combina le informazioni a priori con i dati osservati, aggiornando le nostre credenze riguardo al parametro \\(\\theta\\). Vediamo passo passo come implementare il calcolo della distribuzione a posteriori e delle relative quantit√† in R, partendo dalla rappresentazione discreta di \\(\\theta\\).\n\n41.5.2.1 1. Definizione di \\(\\theta\\)\nIniziamo definendo un insieme discreto di valori per \\(\\theta\\).\n\ntheta &lt;- seq(0, 1, by = 0.1)\ntheta\n#&gt;  [1] 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0\n\n\n\n41.5.2.2 2. Distribuzione a Priori Uniforme\nSe non abbiamo motivi per preferire alcuni valori di \\(\\theta\\), assegniamo probabilit√† uguali a tutti i valori. Standardizziamo la distribuzione affinch√© le probabilit√† si sommino a 1.\n\nunif_prior &lt;- rep(1 / length(theta), length(theta))\nprint(unif_prior)\n#&gt;  [1] 0.0909 0.0909 0.0909 0.0909 0.0909 0.0909 0.0909 0.0909 0.0909 0.0909\n#&gt; [11] 0.0909\n\n\nsum(unif_prior) # Verifica che le probabilit√† sommino a 1\n#&gt; [1] 1\n\nVisualizziamo questa distribuzione a priori uniforme:\n\nggplot(data.frame(theta, unif_prior), aes(x = theta, y = unif_prior)) +\n  geom_segment(aes(xend = theta, yend = 0), linetype = \"solid\", size = 1.2) +\n  labs(\n    title = \"Distribuzione a Priori (Uniforme)\",\n    x = expression(theta),\n    y = \"Probabilit√†\"\n  )\n#&gt; Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#&gt; ‚Ñπ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\n\n41.5.2.3 3. Distribuzione a Priori Non Uniforme\nSe riteniamo pi√π probabili i valori centrali di \\(\\theta\\), definiamo una distribuzione a priori discreta non uniforme:\n\n# Dati per il grafico\ntheta &lt;- seq(0, 1, length.out = 11)  # Valori di theta\nnot_unif_prior &lt;- \n  c(0, 0.05, 0.05, 0.05, 0.175, 0.175, 0.175, 0.175, 0.05, 0.05, 0.05)  \n# Probabilit√†\n\n# Creazione del grafico\nggplot(\n  data.frame(theta, not_unif_prior), \n  aes(x = theta, y = not_unif_prior)) +\n  geom_segment(\n    aes(xend = theta, yend = 0), linetype = \"solid\", size = 1.2) +\n  labs(\n    title = \"Distribuzione a Priori (Non Uniforme)\",\n    x = expression(theta),\n    y = \"Probabilit√†\"\n  )\n\n\n\n\n\n\n\n\n\n\n41.5.2.4 4. Calcolo della Verosimiglianza\nLa funzione di verosimiglianza per il modello binomiale √® definita come segue:\n\nlikelihood &lt;- dbinom(6, size = 9, prob = theta)\n\n\nlikelihood &lt;- likelihood / sum(likelihood) # Normalizzazione\n\n\nggplot(\n  data.frame(theta, likelihood), \n  aes(x = theta, y = likelihood)) +\n  geom_segment(\n    aes(xend = theta, yend = 0), linetype = \"solid\", size = 1.2) +\n  labs(\n    title = \"Funzione di Verosimiglianza\",\n    x = expression(theta),\n    y = expression(L(theta))\n  )\n\n\n\n\n\n\n\n\n\n\n41.5.2.5 5. Distribuzione a Posteriori\nLa distribuzione a posteriori si calcola moltiplicando elemento per elemento la distribuzione a priori e la verosimiglianza, quindi dividendo per la probabilit√† marginale dei dati (normalizzazione).\n\npost &lt;- (not_unif_prior * likelihood) / sum(not_unif_prior * likelihood)\nprint(post)\n#&gt;  [1] 0.00e+00 2.12e-05 9.52e-04 7.27e-03 9.00e-02 1.99e-01 3.04e-01 3.23e-01\n#&gt;  [9] 6.09e-02 1.54e-02 0.00e+00\n\n\nsum(post) # Verifica che sommi a 1\n#&gt; [1] 1\n\nVisualizziamo la distribuzione a posteriori:\n\nggplot(\n  data.frame(theta, post), \n  aes(x = theta, y = post)) +\n  geom_segment(\n    aes(xend = theta, yend = 0), linetype = \"solid\", size = 1.2) +\n  labs(\n    title = \"Distribuzione a Posteriori\",\n    x = expression(theta),\n    y = expression(f(theta))\n  )\n\n\n\n\n\n\n\n\n\n\n41.5.2.6 6. Quantit√† a Posteriori\n\nMedia a Posteriori: Calcolata come il valore atteso di \\(\\theta\\) sotto la distribuzione a posteriori.\n\n\nposterior_mean &lt;- sum(theta * post)\nposterior_mean\n#&gt; [1] 0.609\n\n\nVarianza a Posteriori: Calcolata come la varianza della distribuzione a posteriori.\n\n\nposterior_variance &lt;- sum((theta^2) * post) - posterior_mean^2\nposterior_variance\n#&gt; [1] 0.0134\n\n\nModa a Posteriori: Il valore di \\(\\theta\\) con la probabilit√† pi√π alta.\n\n\nposterior_mode &lt;- theta[which.max(post)]\nposterior_mode\n#&gt; [1] 0.7\n\nIn sintesi, abbiamo calcolato la distribuzione a posteriori di \\(\\theta\\) utilizzando una distribuzione a priori discreta non uniforme e osservando 6 successi su 9 prove. Abbiamo derivato quantit√† statistiche come media, varianza e moda a posteriori. Questo processo dimostra come l‚Äôinferenza bayesiana aggiorni le credenze a priori in base ai dati osservati, offrendo una visione quantitativamente informata del parametro \\(\\theta\\).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-continua",
    "href": "chapters/bayesian_inference/03_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-continua",
    "title": "41¬† Pensare ad una proporzione in termini soggettivi",
    "section": "41.6 Aggiornamento Bayesiano con una Distribuzione a Priori Continua",
    "text": "41.6 Aggiornamento Bayesiano con una Distribuzione a Priori Continua\nPassiamo ora all‚Äôaggiornamento bayesiano utilizzando una distribuzione a priori continua, in particolare la distribuzione Beta. Questo approccio √® particolarmente utile poich√© consente di rappresentare \\(\\theta\\) come una variabile continua definita nell‚Äôintervallo [0, 1].\n\n41.6.1 Definizione della Distribuzione Beta\nIniziamo con una distribuzione Beta simmetrica, Beta(2, 2), e calcoliamo la sua densit√† di probabilit√† su un intervallo continuo di valori \\(\\theta\\).\n\n# Parametri della distribuzione Beta\nalpha &lt;- 2\nbeta &lt;- 2\n\n# Valori di theta\ntheta &lt;- seq(0, 1, length.out = 1000)\n\n# Densit√† di probabilit√† della distribuzione Beta\npdf &lt;- dbeta(theta, alpha, beta)\n\n# Grafico della distribuzione Beta\nggplot(\n  data.frame(theta, pdf), \n  aes(x = theta, y = pdf)) +\n  geom_line(size = 1.2) +\n  labs(\n    title = \"Funzione di Densit√† di Probabilit√† Beta(2, 2)\",\n    x = expression(theta),\n    y = \"Densit√†\"\n  )\n\n\n\n\n\n\n\n\n\n\n41.6.2 Distribuzione a Priori Non Simmetrica\nConsideriamo una distribuzione a priori non simmetrica, Beta(2, 5), per rappresentare credenze che privilegiano valori bassi di \\(\\theta\\).\n\n# Parametri della distribuzione Beta non simmetrica\nalpha &lt;- 2\nbeta &lt;- 5\n\n# Valori di theta e densit√† di probabilit√†\ntheta &lt;- seq(0, 1, length.out = 100)  # Valori di theta\npdf &lt;- dbeta(theta, alpha, beta)  # Densit√† di probabilit√† Beta(2, 5)\n\n# Creazione del grafico\nggplot(data.frame(theta, pdf), aes(x = theta, y = pdf)) +\n  geom_line(size = 1.2) +\n  labs(\n    title = \"Funzione di Densit√† di Probabilit√† Beta(2, 5)\",\n    x = expression(theta),\n    y = \"Densit√†\"\n  )\n\n\n\n\n\n\n\n\n\n\n41.6.3 Verosimiglianza\nConsideriamo un esperimento con 9 prove e 6 successi, modellato con una distribuzione binomiale. Calcoliamo la funzione di verosimiglianza normalizzata.\n\n# Parametri dell'esperimento\nn &lt;- 9\nk &lt;- 6\n\n# Calcolo della verosimiglianza\nlikelihood &lt;- dbinom(k, size = n, prob = theta)\nlikelihood &lt;- likelihood / sum(likelihood) # Normalizzazione\n\n# Grafico della verosimiglianza\nggplot(\n  data.frame(theta, likelihood), \n  aes(x = theta, y = likelihood)) +\n  geom_line(size = 1.2) +\n  labs(\n    title = \"Funzione di Verosimiglianza\",\n    x = expression(theta),\n    y = \"Densit√†\"\n  )\n\n\n\n\n\n\n\n\n\n\n41.6.4 Distribuzione a Posteriori\nLa distribuzione a posteriori si ottiene moltiplicando la distribuzione a priori per la verosimiglianza e normalizzando il risultato.\n\n# Calcolo della distribuzione a priori Beta(2, 5)\nprior &lt;- dbeta(theta, shape1 = 2, shape2 = 5)\nprior &lt;- prior / sum(prior)\n\n# Calcolo della distribuzione a posteriori\nposterior &lt;- (prior * likelihood) / sum(prior * likelihood)\n\n\n# Uniamo tutti i dati in un dataframe per ggplot2\ndat &lt;- tibble(\n  theta, \n  prior, \n  likelihood, \n  posterior\n)\n\n# Preparazione dei dati per il plot\nlong_data &lt;- dat |&gt; \n  pivot_longer(\n    cols = c(prior, likelihood, posterior),\n    names_to = \"distribution\",\n    values_to = \"density\"\n  )\n\n# Grafico\nggplot(long_data, aes(x = theta, y = density, color = distribution)) +\n  geom_line(size = 1.2) +\n  scale_color_manual(\n    values = c(\"prior\" = \"blue\", \"likelihood\" = \"red\", \"posterior\" = \"green\"),\n    labels = c(\"Prior\", \"Likelihood\", \"Posterior\"),\n    breaks = c(\"prior\", \"likelihood\", \"posterior\")\n  ) +\n  labs(\n    title = \"Distribuzioni Bayesiane\",\n    x = expression(theta),\n    y = \"Densit√†\"\n  ) +\n  theme(legend.position = \"bottom\") \n\n\n\n\n\n\n\n\n\n\n41.6.5 Quantit√† a Posteriori\nCalcoliamo alcune quantit√† riassuntive dalla distribuzione a posteriori.\n\nMedia a Posteriori\n\n\nposterior_mean &lt;- sum(theta * posterior)\nposterior_mean\n#&gt; [1] 0.5\n\n\nDeviazione Standard a Posteriori\n\n\nposterior_sd &lt;- sqrt(sum((theta^2) * posterior) - posterior_mean^2)\nposterior_sd\n#&gt; [1] 0.121\n\n\nModa a Posteriori\n\n\nposterior_mode &lt;- theta[which.max(posterior)]\nposterior_mode\n#&gt; [1] 0.495\n\n\n\n41.6.6 Campionamento dalla Distribuzione a Posteriori\nPossiamo generare campioni casuali dalla distribuzione a posteriori per effettuare inferenze.\n\n# Campionamento casuale basato sul posterior\nset.seed(123)\nsamples &lt;- sample(theta, size = 10000, prob = posterior, replace = TRUE)\n\n# Creazione dell'istogramma e della curva di densit√†\ndata_frame_samples &lt;- data.frame(samples)\n\n# Grafico con ggplot\nggplot(data_frame_samples, aes(x = samples)) +\n  geom_histogram(\n    aes(y = ..density..), bins = 20, \n    fill = \"gray\", color = \"black\") +\n  geom_density(color = \"black\", size = 1.2) +\n  labs(\n    title = \"Distribuzione dei Campioni dalla Posteriori\",\n    x = expression(theta),\n    y = \"Densit√†\"\n  )\n#&gt; Warning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\n#&gt; ‚Ñπ Please use `after_stat(density)` instead.\n\n\n\n\n\n\n\n\n\n41.6.6.1 Intervalli di Credibilit√†\nCalcoliamo l‚Äôintervallo di credibilit√† al 94%.\n\ncredible_interval &lt;- quantile(samples, probs = c(0.03, 0.97))\ncredible_interval\n#&gt;    3%   97% \n#&gt; 0.273 0.727\n\nSe desideriamo calcolare l‚Äôintervallo di densit√† pi√π alta (HPDI), possiamo utilizzare pacchetti aggiuntivi come HDInterval.\n\n# Calcolo HPDI (richiede il pacchetto HDInterval)\nhdi(samples, credMass = 0.94)\n#&gt; lower upper \n#&gt; 0.283 0.727 \n#&gt; attr(,\"credMass\")\n#&gt; [1] 0.94\n\nIn sintesi, questo approccio dimostra l‚Äôapplicazione del metodo bayesiano con distribuzioni a priori continue, utilizzando sia formule analitiche che campionamento. I risultati mostrano come possiamo ottenere credenze aggiornate su \\(\\theta\\) e riassumerle con quantit√† come media, moda e intervalli di credibilit√†.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#metodo-basato-su-griglia",
    "href": "chapters/bayesian_inference/03_subj_prop.html#metodo-basato-su-griglia",
    "title": "41¬† Pensare ad una proporzione in termini soggettivi",
    "section": "41.7 Metodo basato su griglia",
    "text": "41.7 Metodo basato su griglia\nIl metodo utilizzato in questo capitolo per generare la distribuzione a posteriori √® noto come metodo basato su griglia. Questo metodo numerico esatto si basa sul calcolo della distribuzione a posteriori mediante una griglia di punti uniformemente spaziati. Nonostante la maggior parte dei parametri sia continua, l‚Äôapprossimazione della distribuzione a posteriori pu√≤ essere ottenuta considerando soltanto una griglia finita di valori dei parametri. Il metodo segue quattro fasi:\n\nFissare una griglia discreta di possibili valori dei parametri.\nValutare la distribuzione a priori e la funzione di verosimiglianza per ciascun valore della griglia.\nCalcolare l‚Äôapprossimazione della densit√† a posteriori, ottenuta moltiplicando la distribuzione a priori per la funzione di verosimiglianza per ciascun valore della griglia e normalizzando i prodotti in modo che la loro somma sia uguale a 1.\nSelezionare \\(n\\) valori casuali dalla griglia per ottenere un campione casuale della densit√† a posteriori normalizzata.\n\nQuesto metodo pu√≤ essere potenziato aumentando il numero di punti nella griglia, ma il limite principale risiede nel fatto che all‚Äôaumentare della dimensionalit√† dello spazio dei parametri, il numero di punti necessari per una stima accurata cresce in modo esponenziale, rendendo il metodo impraticabile per problemi complessi.\nIn sintesi, l‚Äôapproccio basato sulla griglia √® intuitivo e non richiede competenze di programmazione avanzate per l‚Äôimplementazione. Inoltre, fornisce un risultato che pu√≤ essere considerato, per tutti gli scopi pratici, come un campione casuale estratto dalla distribuzione di probabilit√† a posteriori condizionata ai dati. Tuttavia, questo metodo √® limitato a causa della maledizione della dimensionalit√†1, il che significa che pu√≤ essere applicato soltanto a modelli statistici semplici con non pi√π di due parametri. Di conseguenza, in pratica, √® spesso sostituito da altre tecniche pi√π efficienti, poich√© i modelli impiegati in psicologia richiedono frequentemente la stima di centinaia o anche migliaia di parametri.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/03_subj_prop.html#riflessioni-conclusive",
    "title": "41¬† Pensare ad una proporzione in termini soggettivi",
    "section": "41.8 Riflessioni Conclusive",
    "text": "41.8 Riflessioni Conclusive\nIn questo capitolo, abbiamo esplorato l‚Äôaggiornamento bayesiano utilizzando una distribuzione a priori discreta, accennando brevemente al caso delle distribuzioni a priori continue. Quando si affrontano scenari con distribuzioni a priori continue, l‚Äôelaborazione della distribuzione a posteriori generalmente richiede la risoluzione di un integrale che, nella maggior parte dei casi, non ammette una soluzione analitica. Tuttavia, ci sono eccezioni notevoli, come nell‚Äôinferenza relativa alle proporzioni, dove la distribuzione a priori √® modellata come una distribuzione Beta e la funzione di verosimiglianza segue una distribuzione binomiale. In queste circostanze particolari, √® possibile derivare analiticamente la distribuzione a posteriori. L‚Äôanalisi dettagliata di questo caso sar√† trattata nel capitolo successivo.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#esercizi",
    "href": "chapters/bayesian_inference/03_subj_prop.html#esercizi",
    "title": "41¬† Pensare ad una proporzione in termini soggettivi",
    "section": "41.9 Esercizi",
    "text": "41.9 Esercizi\n\nEsercizio 41.1 Viene chieso di calcolare la distribuzione a posteriori della probabilit√† che uno studio condivida i materiali di ricerca utilizzando il metodo basato su griglia. Si utilizzeranno dati reali per motivare e costruire una distribuzione a priori discretizzata.\nIn uno studio sull‚Äôanalisi delle pratiche di trasparenza e riproducibilit√† nella ricerca in psicologia, Hardwicke et al. (2022) hanno riportato che la condivisione dei materiali di ricerca √® stata rilevata nel 14% dei casi (26 su 183 studi), con un intervallo di confidenza al 95% pari a [10%, 19%]. Questo suggerisce che la condivisione di materiali √® rara.\nIspirandoti ai risultati di questo studio, costruisci una distribuzione a priori per la probabilit√† \\(\\theta\\) che uno studio condivida i materiali di ricerca. Per semplicit√†, discretizza \\(\\theta\\) in 10 livelli equispaziati: \\(0.05, 0.15, 0.25, 0.35, 0.45, 0.55, 0.65, 0.75, 0.85, 0.95\\).\nAttribuisci le seguenti probabilit√† a priori ai 10 livelli, basandoti sull‚Äôinformazione che la condivisione dei materiali √® un evento raro ma non trascurabile: \\(0.05, 0.20, 0.30, 0.15, 0.10, 0.08, 0.05, 0.03, 0.02, 0.02\\).\nSupponiamo che siano stati osservati 20 studi su 100 che hanno condiviso i materiali di ricerca. Calcola la distribuzione a posteriori utilizzando il metodo basato su griglia. Calcola la media della distribuzione a posteriori e l‚Äôintervallo di credibilit√† al 89%.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/03_subj_prop.html#informazioni-sullambiente-di-sviluppo",
    "title": "41¬† Pensare ad una proporzione in termini soggettivi",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: US/Pacific\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] HDInterval_0.2.4 ggokabeito_0.1.0 see_0.9.0        gridExtra_2.3   \n#&gt;  [5] patchwork_1.3.0  bayesplot_1.11.1 psych_2.4.12     scales_1.3.0    \n#&gt;  [9] markdown_1.13    knitr_1.49       lubridate_1.9.4  forcats_1.0.0   \n#&gt; [13] stringr_1.5.1    dplyr_1.1.4      purrr_1.0.2      readr_2.1.5     \n#&gt; [17] tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0 \n#&gt; [21] rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.3         rlang_1.1.4       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       tools_4.4.2       parallel_4.4.2    tzdb_0.4.0       \n#&gt; [21] colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5       R6_2.5.1         \n#&gt; [25] lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.1    \n#&gt; [29] gtable_0.3.6      glue_1.8.0        xfun_0.50         tidyselect_1.2.1 \n#&gt; [33] farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-166      labeling_0.4.3   \n#&gt; [37] rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#bibliografia",
    "href": "chapters/bayesian_inference/03_subj_prop.html#bibliografia",
    "title": "41¬† Pensare ad una proporzione in termini soggettivi",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAlbert, J., & Hu, J. (2019). Probability and Bayesian Modeling. CRC Press.\n\n\nHardwicke, T. E., Thibault, R. T., Kosie, J. E., Wallach, J. D., Kidwell, M. C., & Ioannidis, J. P. (2022). Estimating the prevalence of transparency and reproducibility-related research practices in psychology (2014‚Äì2017). Perspectives on Psychological Science, 17(1), 239‚Äì251.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nShiffrin, R. M., & Schneider, W. (1977). Controlled and automatic human information processing: II. Perceptual learning, automatic attending and a general theory. Psychological Review, 84(2), 127‚Äì190.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#footnotes",
    "href": "chapters/bayesian_inference/03_subj_prop.html#footnotes",
    "title": "41¬† Pensare ad una proporzione in termini soggettivi",
    "section": "",
    "text": "Per comprendere la maledizione della dimensionalit√†, possiamo considerare l‚Äôesempio di una griglia di 100 punti equispaziati. Nel caso di un solo parametro, sarebbe necessario calcolare solo 100 valori. Tuttavia, se abbiamo due parametri, il numero di valori da calcolare diventa \\(100^2\\). Se invece abbiamo 10 parametri, il numero di valori da calcolare sarebbe di \\(10^{10}\\). √à evidente che la quantit√† di calcoli richiesta diventa troppo grande persino per un computer molto potente. Pertanto, per modelli che richiedono la stima di un numero significativo di parametri, √® necessario utilizzare un approccio diverso.‚Ü©Ô∏é",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_grid_gauss.html",
    "href": "chapters/bayesian_inference/04_grid_gauss.html",
    "title": "42¬† Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "",
    "text": "42.1 Introduzione\nIn questo capitolo, estenderemo la discussione precedente sul calcolo della distribuzione a posteriori utilizzando il metodo basato su griglia, applicandolo questa volta a un caso con verosimiglianza gaussiana. In particolare, ci concentreremo su come costruire un modello gaussiano per descrivere l‚Äôintelligenza.\nImmaginiamo di condurre uno studio sulla plusdotazione, considerando l‚Äôapproccio psicometrico. Secondo questo approccio, una persona √® considerata plusdotata se ha un QI (Quoziente Intellettivo) di 130 o superiore (Robinson, Zigler, & Gallagher, 2000). Anche se l‚Äôuso di un QI di 130 come soglia √® il criterio pi√π comune, non √® universalmente accettato. L‚Äôintelligenza nei bambini plusdotati non √® solo superiore rispetto a quella dei loro pari, ma √® qualitativamente diversa (Lubart & Zenasni, 2010). I bambini plusdotati tendono a mostrare caratteristiche come un vocabolario ampio, un linguaggio molto sviluppato, processi di ragionamento avanzati, eccellente memoria, vasti interessi, forte curiosit√†, empatia, capacit√† di leadership, abilit√† visive elevate, impegno in situazioni sfidanti e un forte senso di giustizia (Song & Porath, 2005).\nNella simulazione che seguir√†, assumeremo che i dati provengano da una distribuzione normale. Per semplicit√†, considereremo che la deviazione standard sia nota e pari a 5. Il parametro della media sar√† l‚Äôoggetto della nostra inferenza.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>¬† <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_grid_gauss.html#dati",
    "href": "chapters/bayesian_inference/04_grid_gauss.html#dati",
    "title": "42¬† Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "42.2 Dati",
    "text": "42.2 Dati\nSupponiamo di avere un campione di 10 osservazioni. I dati saranno generati casualmente da una distribuzione normale con media 130 e deviazione standard 5.\n\nset.seed(123) # Per la riproducibilit√†\nvera_media &lt;- 130 # Media vera\nsigma_conosciuta &lt;- 5 # Deviazione standard conosciuta\ndimensione_campione &lt;- 10 # Dimensione del campione\n\n# Generare un campione\ncampione &lt;- round(rnorm(n = dimensione_campione, mean = vera_media, sd = sigma_conosciuta))\ncampione\n#&gt;  [1] 127 129 138 130 131 139 132 124 127 128",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>¬† <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_grid_gauss.html#griglia",
    "href": "chapters/bayesian_inference/04_grid_gauss.html#griglia",
    "title": "42¬† Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "42.3 Griglia",
    "text": "42.3 Griglia\nCreiamo ora una griglia di 100 valori compresi tra 110 e 150.\n\nmu_griglia &lt;- seq(110, 150, length.out = 100)\nmu_griglia\n#&gt;   [1] 110 110 111 111 112 112 112 113 113 114 114 114 115 115 116 116 116\n#&gt;  [18] 117 117 118 118 118 119 119 120 120 121 121 121 122 122 123 123 123\n#&gt;  [35] 124 124 125 125 125 126 126 127 127 127 128 128 129 129 129 130 130\n#&gt;  [52] 131 131 131 132 132 133 133 133 134 134 135 135 135 136 136 137 137\n#&gt;  [69] 137 138 138 139 139 139 140 140 141 141 142 142 142 143 143 144 144\n#&gt;  [86] 144 145 145 146 146 146 147 147 148 148 148 149 149 150 150",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>¬† <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_grid_gauss.html#calcolo-della-verosimiglianza",
    "href": "chapters/bayesian_inference/04_grid_gauss.html#calcolo-della-verosimiglianza",
    "title": "42¬† Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "42.4 Calcolo della Verosimiglianza",
    "text": "42.4 Calcolo della Verosimiglianza\nPer ogni valore della griglia, calcoliamo la verosimiglianza complessiva come prodotto delle densit√† di probabilit√†.\n\nlikelihood &lt;- sapply(mu_griglia, function(mu) {\n    prod(dnorm(campione, mean = mu, sd = sigma_conosciuta))\n})\nlikelihood\n#&gt;   [1] 5.29e-50 1.41e-48 3.50e-47 8.17e-46 1.79e-44 3.66e-43 7.02e-42\n#&gt;   [8] 1.26e-40 2.12e-39 3.35e-38 4.94e-37 6.84e-36 8.87e-35 1.08e-33\n#&gt;  [15] 1.23e-32 1.31e-31 1.30e-30 1.22e-29 1.07e-28 8.77e-28 6.74e-27\n#&gt;  [22] 4.86e-26 3.28e-25 2.07e-24 1.23e-23 6.81e-23 3.54e-22 1.72e-21\n#&gt;  [29] 7.85e-21 3.35e-20 1.34e-19 5.03e-19 1.77e-18 5.82e-18 1.79e-17\n#&gt;  [36] 5.18e-17 1.40e-16 3.55e-16 8.42e-16 1.87e-15 3.90e-15 7.61e-15\n#&gt;  [43] 1.39e-14 2.38e-14 3.82e-14 5.74e-14 8.08e-14 1.07e-13 1.32e-13\n#&gt;  [50] 1.52e-13 1.65e-13 1.68e-13 1.60e-13 1.42e-13 1.19e-13 9.29e-14\n#&gt;  [57] 6.81e-14 4.67e-14 3.01e-14 1.81e-14 1.02e-14 5.40e-15 2.67e-15\n#&gt;  [64] 1.24e-15 5.39e-16 2.19e-16 8.37e-17 2.99e-17 1.00e-17 3.14e-18\n#&gt;  [71] 9.22e-19 2.54e-19 6.54e-20 1.58e-20 3.57e-21 7.56e-22 1.50e-22\n#&gt;  [78] 2.79e-23 4.86e-24 7.93e-25 1.21e-25 1.74e-26 2.33e-27 2.93e-28\n#&gt;  [85] 3.45e-29 3.80e-30 3.93e-31 3.80e-32 3.45e-33 2.93e-34 2.33e-35\n#&gt;  [92] 1.74e-36 1.21e-37 7.93e-39 4.86e-40 2.79e-41 1.50e-42 7.56e-44\n#&gt;  [99] 3.57e-45 1.58e-46",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>¬† <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_grid_gauss.html#calcolo-della-distribuzione-a-posteriori",
    "href": "chapters/bayesian_inference/04_grid_gauss.html#calcolo-della-distribuzione-a-posteriori",
    "title": "42¬† Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "42.5 Calcolo della Distribuzione a Posteriori",
    "text": "42.5 Calcolo della Distribuzione a Posteriori\nImpostiamo una prior uniforme e calcoliamo la distribuzione a posteriori normalizzata.\n\nprior &lt;- rep(1, length(mu_griglia)) # Prior uniforme\nposterior_non_norm &lt;- likelihood * prior\nposterior &lt;- posterior_non_norm / sum(posterior_non_norm) # Normalizzazione\n\nVisualizzazione:\n\nplot(mu_griglia, posterior,\n    type = \"l\", main = \"Distribuzione a Posteriori della Media\",\n    xlab = \"Media\", ylab = \"Probabilit√†\"\n)\n\n\n\n\n\n\n\n\n\n42.5.1 Aggiunta di una Prior Informativa\nUsiamo una prior gaussiana con media 140 e deviazione standard 3.\n\nprior &lt;- dnorm(mu_griglia, mean = 140, sd = 3)\n\nposterior_non_norm &lt;- likelihood * prior\nposterior &lt;- posterior_non_norm / sum(posterior_non_norm)\n\n# Grafico\nplot(mu_griglia, posterior,\n    type = \"l\", col = \"blue\", lwd = 2,\n    main = \"Distribuzione a Posteriori e Prior della Media\",\n    xlab = \"Media\", ylab = \"Densit√†\"\n)\nlines(mu_griglia, prior / sum(prior), col = \"red\", lty = 2)\nlegend(\"topright\", legend = c(\"Posterior\", \"Prior\"), col = c(\"blue\", \"red\"), lty = c(1, 2))",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>¬† <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_grid_gauss.html#campionamento-dalla-posterior",
    "href": "chapters/bayesian_inference/04_grid_gauss.html#campionamento-dalla-posterior",
    "title": "42¬† Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "42.6 Campionamento dalla Posterior",
    "text": "42.6 Campionamento dalla Posterior\nGeneriamo un campione dalla distribuzione a posteriori.\n\nset.seed(123)\nindice_campionato &lt;- sample(1:length(mu_griglia), size = 1000, replace = TRUE, prob = posterior)\nmedia_campionata &lt;- mu_griglia[indice_campionato]\n\n# Istogramma dei campioni\nhist(media_campionata,\n    main = \"Campionamento dalla Posterior\", xlab = \"Media\",\n    breaks = 20, col = \"lightblue\", border = \"white\"\n)\n\n# Media e intervallo di credibilit√†\nmean(media_campionata)\n#&gt; [1] 133\nquantile(media_campionata, c(0.03, 0.97))\n#&gt;  3% 97% \n#&gt; 130 135",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>¬† <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_grid_gauss.html#calcolo-della-log-verosimiglianza",
    "href": "chapters/bayesian_inference/04_grid_gauss.html#calcolo-della-log-verosimiglianza",
    "title": "42¬† Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "42.7 Calcolo della Log-Verosimiglianza",
    "text": "42.7 Calcolo della Log-Verosimiglianza\nUtilizziamo i logaritmi per migliorare la stabilit√† numerica.\n\nlog_likelihood &lt;- sapply(mu_griglia, function(mu) {\n    sum(dnorm(campione, mean = mu, sd = sigma_conosciuta, log = TRUE))\n})\n\nlog_prior &lt;- dnorm(mu_griglia, mean = 140, sd = 3, log = TRUE)\n\nlog_posterior_non_norm &lt;- log_likelihood + log_prior\nlog_posterior &lt;- log_posterior_non_norm - max(log_posterior_non_norm) # Stabilizzazione\nposterior &lt;- exp(log_posterior) / sum(exp(log_posterior))\n\n# Grafico\nplot(mu_griglia, posterior,\n    type = \"l\", col = \"darkgreen\", lwd = 2,\n    main = \"Distribuzione a Posteriori con Log-Verosimiglianza\",\n    xlab = \"Media\", ylab = \"Probabilit√†\"\n)",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>¬† <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_grid_gauss.html#estensione-alla-deviazione-standard-ignota",
    "href": "chapters/bayesian_inference/04_grid_gauss.html#estensione-alla-deviazione-standard-ignota",
    "title": "42¬† Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "42.8 Estensione alla Deviazione Standard Ignota",
    "text": "42.8 Estensione alla Deviazione Standard Ignota\nPer una griglia bidimensionale di valori di \\(\\mu\\) e \\(\\sigma\\):\n\n# Define the grid for mu and sigma\nmu_griglia &lt;- seq(110, 150, length.out = 100)\nsigma_griglia &lt;- seq(1, 10, length.out = 50)\n\n# Create combinations of mu and sigma using expand.grid\ngrid &lt;- expand.grid(mu = mu_griglia, sigma = sigma_griglia)\n\n# Compute the log-likelihood for each combination of mu and sigma\nlog_likelihood &lt;- apply(grid, 1, function(params) {\n    mu &lt;- params[1]\n    sigma &lt;- params[2]\n    sum(dnorm(campione, mean = mu, sd = sigma, log = TRUE))\n})\n\n# Reshape log-likelihood into a matrix\nlog_likelihood_2d &lt;- matrix(log_likelihood, nrow = length(mu_griglia), ncol = length(sigma_griglia))\n\n# Compute priors for mu and sigma\nlog_prior_mu &lt;- dnorm(mu_griglia, mean = 140, sd = 5, log = TRUE)\nlog_prior_sigma &lt;- dnorm(sigma_griglia, mean = 5, sd = 2, log = TRUE)\n\n# Combine priors into a grid\nlog_prior_2d &lt;- outer(log_prior_mu, log_prior_sigma, \"+\")\n\n# Compute log-posterior\nlog_posterior_2d &lt;- log_likelihood_2d + log_prior_2d\nlog_posterior_2d &lt;- log_posterior_2d - max(log_posterior_2d) # Stabilize\nposterior_2d &lt;- exp(log_posterior_2d)\nposterior_2d &lt;- posterior_2d / sum(posterior_2d) # Normalize\n\n# Convert posterior_2d to a data frame for visualization\nlibrary(reshape2)\nposterior_df &lt;- melt(posterior_2d)\nnames(posterior_df) &lt;- c(\"mu_idx\", \"sigma_idx\", \"posterior\")\nposterior_df$mu &lt;- mu_griglia[posterior_df$mu_idx]\nposterior_df$sigma &lt;- sigma_griglia[posterior_df$sigma_idx]\n\n# Plot the posterior distribution\nlibrary(ggplot2)\nggplot(posterior_df, aes(x = mu, y = sigma, fill = posterior)) +\n    geom_tile() +\n    scale_fill_viridis_c() +\n    labs(\n        title = \"Distribuzione a Posteriori Bidimensionale\",\n        x = \"Media ($\\\\mu$)\", y = \"Deviazione Standard ($\\\\sigma$)\"\n    )",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>¬† <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_grid_gauss.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/04_grid_gauss.html#riflessioni-conclusive",
    "title": "42¬† Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "42.9 Riflessioni Conclusive",
    "text": "42.9 Riflessioni Conclusive\nQuando si passa alla stima simultanea di pi√π parametri, come la media (\\(\\mu\\)) e la deviazione standard (\\(\\sigma\\)), l‚Äôanalisi diventa notevolmente pi√π complessa. Questo perch√© occorre considerare un numero molto maggiore di combinazioni di parametri rispetto alla stima di un solo parametro, aumentando cos√¨ il carico computazionale. Inoltre, la scelta delle priors per ciascun parametro richiede particolare attenzione, poich√© queste influenzeranno in modo diretto le stime a posteriori.\nIn scenari dove lo spazio dei parametri √® multidimensionale o quando l‚Äôesplorazione della griglia diventa impraticabile, l‚Äôuso di metodi avanzati come il campionamento di Markov Chain Monte Carlo (MCMC) diventa indispensabile. Questi metodi permettono di campionare in modo efficiente dalla distribuzione a posteriori, senza la necessit√† di esplorare esplicitamente ogni combinazione possibile di parametri, rendendo l‚Äôanalisi pi√π gestibile anche in contesti complessi.\nIn conclusione, l‚Äôestensione dell‚Äôapproccio bayesiano a problemi con pi√π parametri sconosciuti richiede un‚Äôattenzione ancora maggiore nella definizione dello spazio dei parametri, nella selezione delle priors appropriate e nel calcolo delle distribuzioni a posteriori. L‚Äôadozione di tecniche come l‚ÄôMCMC pu√≤ facilitare questo processo, permettendo di affrontare in modo efficiente problemi che altrimenti sarebbero proibitivi dal punto di vista computazionale.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>¬† <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_grid_gauss.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/04_grid_gauss.html#informazioni-sullambiente-di-sviluppo",
    "title": "42¬† Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: US/Pacific\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] reshape2_1.4.4   ggokabeito_0.1.0 see_0.9.0        gridExtra_2.3   \n#&gt;  [5] patchwork_1.3.0  bayesplot_1.11.1 psych_2.4.12     scales_1.3.0    \n#&gt;  [9] markdown_1.13    knitr_1.49       lubridate_1.9.4  forcats_1.0.0   \n#&gt; [13] stringr_1.5.1    dplyr_1.1.4      purrr_1.0.2      readr_2.1.5     \n#&gt; [17] tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0 \n#&gt; [21] rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     plyr_1.8.9        rprojroot_2.0.4  \n#&gt; [13] jsonlite_1.8.9    viridisLite_0.4.2 mnormt_2.1.1      cli_3.6.3        \n#&gt; [17] rlang_1.1.4       munsell_0.5.1     withr_3.0.2       yaml_2.3.10      \n#&gt; [21] tools_4.4.2       parallel_4.4.2    tzdb_0.4.0        colorspace_2.1-1 \n#&gt; [25] pacman_0.5.1      vctrs_0.6.5       R6_2.5.1          lifecycle_1.0.4  \n#&gt; [29] htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.1     gtable_0.3.6     \n#&gt; [33] Rcpp_1.0.13-1     glue_1.8.0        xfun_0.50         tidyselect_1.2.1 \n#&gt; [37] farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-166      labeling_0.4.3   \n#&gt; [41] rmarkdown_2.29    compiler_4.4.2\n\n\n\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>¬† <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_conjugate_families_1.html",
    "href": "chapters/bayesian_inference/05_conjugate_families_1.html",
    "title": "43¬† Distribuzioni coniugate (1)",
    "section": "",
    "text": "43.1 Introduzione\nIn questo capitolo, esploriamo il concetto di distribuzioni a priori coniugate e il loro ruolo nell‚Äôinferenza bayesiana. Utilizzando il modello beta-binomiale come esempio paradigmatico, dimostreremo come queste distribuzioni semplifichino l‚Äôanalisi attraverso calcoli analitici diretti. L‚Äôuso di una distribuzione a priori coniugata non solo rende l‚Äôinferenza pi√π agevole, ma fornisce anche una chiara visione del modo in cui le credenze a priori influenzano le conclusioni.\nPer favorire la comprensione, procederemo in tre fasi principali:",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>¬† <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_conjugate_families_1.html#introduzione",
    "href": "chapters/bayesian_inference/05_conjugate_families_1.html#introduzione",
    "title": "43¬† Distribuzioni coniugate (1)",
    "section": "",
    "text": "Introduzione del modello beta-binomiale.\nAnalisi della distribuzione Beta e del suo ruolo come distribuzione a priori.\nDescrizione del processo di aggiornamento bayesiano e dei vantaggi derivanti dall‚Äôuso di distribuzioni coniugate.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>¬† <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_conjugate_families_1.html#il-modello-beta-binomiale",
    "href": "chapters/bayesian_inference/05_conjugate_families_1.html#il-modello-beta-binomiale",
    "title": "43¬† Distribuzioni coniugate (1)",
    "section": "43.2 Il Modello Beta-Binomiale",
    "text": "43.2 Il Modello Beta-Binomiale\nIl modello beta-binomiale √® un esempio classico per analizzare una proporzione \\(\\theta\\), ossia la probabilit√† di successo in una sequenza di prove binarie (ad esempio, successo/fallimento). Supponiamo di osservare \\(y\\) successi su \\(n\\) prove, dove ogni prova √® indipendente e con la stessa probabilit√† di successo \\(\\theta\\), che appartiene all‚Äôintervallo \\([0,1]\\).\nLa funzione di verosimiglianza, basata sulla distribuzione binomiale, √® espressa come:\n\\[\n\\text{Bin}(y \\mid n, \\theta) = \\binom{n}{y} \\theta^y (1 - \\theta)^{n - y},\n\\]\ndove \\(\\binom{n}{y}\\) √® il coefficiente binomiale che conta il numero di modi in cui \\(y\\) successi possono verificarsi in \\(n\\) prove.\nPer modellare la nostra conoscenza preliminare su \\(\\theta\\), scegliamo una distribuzione a priori Beta, che rappresenta un‚Äôampia gamma di credenze iniziali con parametri flessibili.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>¬† <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_conjugate_families_1.html#la-distribuzione-beta-un-prior-flessibile",
    "href": "chapters/bayesian_inference/05_conjugate_families_1.html#la-distribuzione-beta-un-prior-flessibile",
    "title": "43¬† Distribuzioni coniugate (1)",
    "section": "43.3 La Distribuzione Beta: Un Prior Flessibile",
    "text": "43.3 La Distribuzione Beta: Un Prior Flessibile\nLa distribuzione Beta √® definita come:\n\\[\n\\text{Beta}(\\theta \\mid \\alpha, \\beta) = \\frac{1}{B(\\alpha, \\beta)} \\theta^{\\alpha - 1} (1 - \\theta)^{\\beta - 1}, \\quad \\text{con } \\theta \\in (0, 1),\n\\]\ndove:\n\n\\(\\alpha &gt; 0\\) e \\(\\beta &gt; 0\\) sono i iperparametri, che determinano la forma della distribuzione.\n\\(B(\\alpha, \\beta)\\) √® la funzione Beta di Eulero, calcolata come:\n\\[\n  B(\\alpha, \\beta) = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)},\n  \\]\ndove \\(\\Gamma(x)\\) √® la funzione Gamma, una generalizzazione del fattoriale.\n\n\n43.3.1 Interpretazione Intuitiva di \\(\\alpha\\) e \\(\\beta\\)\nNel contesto bayesiano:\n\n\\(\\alpha -1\\) rappresenta il numero ipotetico di ‚Äúsuccessi‚Äù a priori.\n\\(\\beta -1\\) rappresenta il numero ipotetico di ‚Äúfallimenti‚Äù a priori.\n\nAd esempio:\n\nUna distribuzione Beta(1, 1) √® uniforme (0 successi a priori e 0 fallimenti), indicando totale incertezza iniziale (assenza di credenze informate).\nUna distribuzione Beta(10, 20) rappresenta una conoscenza a priori basata su 9 successi e 19 fallimenti ipotizzati, indicando una convinzione iniziale relativamente solida, poich√© deriva da un totale di 28 osservazioni virtuali che riflettono le credenze precedenti.\n\nQuesta interpretazione consente di calibrare le credenze a priori in base all‚Äôevidenza disponibile o alla fiducia nella stima.\n\n\n43.3.2 Flessibilit√† della Distribuzione Beta\nLa distribuzione Beta √® estremamente versatile:\n\nForma: Valori diversi di \\(\\alpha\\) e \\(\\beta\\) producono distribuzioni simmetriche, asimmetriche o uniformi.\nForza del prior: Valori elevati di \\(\\alpha\\) e \\(\\beta\\) riducono la varianza, riflettendo credenze pi√π forti.\n\nQuesta flessibilit√† rende la distribuzione Beta una scelta ideale per rappresentare credenze iniziali su proporzioni.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>¬† <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_conjugate_families_1.html#aggiornamento-bayesiano",
    "href": "chapters/bayesian_inference/05_conjugate_families_1.html#aggiornamento-bayesiano",
    "title": "43¬† Distribuzioni coniugate (1)",
    "section": "43.4 Aggiornamento Bayesiano",
    "text": "43.4 Aggiornamento Bayesiano\nL‚Äôaggiornamento bayesiano combina le informazioni iniziali (priori) con i dati osservati (verosimiglianza) per produrre una nuova distribuzione delle credenze (posteriori). Nel caso del modello beta-binomiale, questo processo √® particolarmente semplice grazie alla ‚Äúconiugazione‚Äù: il prior Beta e la verosimiglianza Binomiale producono una distribuzione a posteriori che appartiene ancora alla famiglia Beta.\n\n43.4.1 Problema\nSe osserviamo \\(y\\) successi su \\(n\\) prove, vogliamo aggiornare il nostro prior Beta con i dati osservati per ottenere una distribuzione a posteriori Beta. I parametri aggiornati della distribuzione a posteriori sono:\n\\[\n\\alpha' = \\alpha + y, \\quad \\beta' = \\beta + n - y.\n\\]\nVediamo in dettaglio come si arriva a questo risultato.\n\n\n43.4.2 Passaggi dell‚ÄôAggiornamento Bayesiano\n1. Formula di Bayes\nLa regola di Bayes afferma che:\n\\[\n\\text{Posterior} \\propto \\text{Prior} \\times \\text{Verosimiglianza},\n\\]\ndove \\(\\propto\\) indica ‚Äúproporzionale a‚Äù. Qui ci concentriamo sui termini che dipendono dal parametro di interesse, \\(\\theta\\), la probabilit√† di successo.\n2. Espressione del Prior\nIl prior √® una distribuzione Beta, definita come:\n\\[\n\\text{Prior} = \\theta^{\\alpha-1} (1-\\theta)^{\\beta-1},\n\\]\ndove:\n\n\\(\\theta\\) rappresenta la probabilit√† di successo,\n\\(\\alpha\\) e \\(\\beta\\) sono parametri che descrivono le nostre convinzioni iniziali:\n\n\\(\\alpha\\): il numero di successi attesi prima di osservare i dati,\n\\(\\beta\\): il numero di insuccessi attesi prima di osservare i dati.\n\n\n3. Espressione della Verosimiglianza\nLa verosimiglianza √® data dalla distribuzione Binomiale, che rappresenta la probabilit√† di osservare \\(y\\) successi su \\(n\\) prove:\n\\[\n\\text{Verosimiglianza} = \\theta^y (1-\\theta)^{n-y},\n\\]\ndove:\n\n\\(y\\) √® il numero di successi osservati,\n\\(n\\) √® il numero totale di prove,\n\\(\\theta\\) √® la probabilit√† di successo (il parametro che stiamo aggiornando).\n\n4. Moltiplicazione di Prior e Verosimiglianza\nCombinando prior e verosimiglianza, otteniamo:\n\\[\n\\text{Posterior} \\propto \\underbrace{\\theta^{\\alpha-1} (1-\\theta)^{\\beta-1}}_{\\text{Prior}} \\times \\underbrace{\\theta^y (1-\\theta)^{n-y}}_{\\text{Verosimiglianza}}.\n\\]\n5. Raggruppamento dei termini\nMoltiplicando i termini simili, raggruppiamo gli esponenti di \\(\\theta\\) e \\(1-\\theta\\):\n\\[\n\\text{Posterior} \\propto \\theta^{(\\alpha-1) + y} (1-\\theta)^{(\\beta-1) + (n-y)}.\n\\]\n6. Forma finale\nSemplificando gli esponenti:\n\\[\n\\text{Posterior} \\propto \\theta^{\\alpha + y - 1} (1-\\theta)^{\\beta + n - y - 1}.\n\\]\nQuesta √® la forma di una distribuzione Beta con nuovi parametri:\n\\[\n\\alpha' = \\alpha + y, \\quad \\beta' = \\beta + n - y.\n\\]\n7. Normalizzazione\nPer trasformare questa espressione in una distribuzione di probabilit√† vera e propria, dobbiamo dividere per una costante di normalizzazione. La funzione Beta, \\(B(\\alpha', \\beta')\\), normalizza la distribuzione:\n\\[\np(\\theta | y, n) = \\frac{\\theta^{\\alpha' - 1} (1-\\theta)^{\\beta' - 1}}{B(\\alpha', \\beta')},\n\\]\ndove \\(B(\\alpha', \\beta')\\) √® definita come:\n\\[\nB(\\alpha', \\beta') = \\int_0^1 \\theta^{\\alpha' - 1} (1-\\theta)^{\\beta' - 1} \\, d\\theta.\n\\]\nTuttavia, non dobbiamo calcolarla esplicitamente poich√© sappiamo gi√† che il risultato √® una distribuzione Beta.\n8. Parametri aggiornati\nIn conclusione, i parametri aggiornati sono:\n\nNuovo \\(\\alpha'\\): \\(\\alpha + y\\), che somma al vecchio \\(\\alpha\\) il numero di successi osservati (\\(y\\)).\nNuovo \\(\\beta'\\): \\(\\beta + n - y\\), che somma al vecchio \\(\\beta\\) il numero di insuccessi osservati (\\(n-y\\)).\n\n\n\n43.4.3 Vantaggi del Modello Beta-Binomiale\nIl modello beta-binomiale presenta diversi vantaggi:\n\nSemplicit√† analitica: La distribuzione a posteriori appartiene alla stessa famiglia della distribuzione a priori, evitando calcoli complessi.\nInterpretazione trasparente: L‚Äôaggiornamento dei parametri \\(\\alpha\\) e \\(\\beta\\) mostra chiaramente come i dati influenzino le credenze.\n\nNonostante la semplicit√†, le distribuzioni a priori coniugate non sempre rappresentano credenze realistiche. Tecniche moderne come il campionamento Monte Carlo consentono di usare distribuzioni a priori pi√π complesse, ma il modello beta-binomiale rimane un esempio didattico fondamentale per comprendere l‚Äôinferenza bayesiana.\nIn conclusione, il modello beta-binomiale illustra chiaramente come le distribuzioni a priori coniugate possano semplificare l‚Äôinferenza bayesiana e fornire una comprensione intuitiva dell‚Äôinterazione tra prior e dati. Questo modello rappresenta un punto di partenza ideale per approfondire l‚Äôapproccio bayesiano e prepararsi a concetti pi√π avanzati.\n\nEsempio 43.1 In un esempio ispirato da McElreath (2020) nel suo libro ‚ÄúStatistical Rethinking‚Äù, consideriamo un esperimento dove otteniamo 6 successi (indicati come ‚Äúacqua‚Äù) su un totale di 9 prove (immaginate come lanci di un mappamondo). La verosimiglianza binomiale per questo esperimento √® data da:\n\\[\n\\theta^y (1-\\theta)^{n-y},\n\\]\ndove \\(y = 6\\) √® il numero di successi e \\(n = 9\\) √® il numero totale di prove.\nSe scegliamo una distribuzione a priori Beta con parametri \\(\\alpha = 2\\) e \\(\\beta = 2\\), possiamo utilizzare l‚Äôaggiornamento bayesiano per calcolare i parametri della distribuzione a posteriori, dato l‚Äôesito delle nostre prove. L‚Äôapplicazione del teorema di Bayes porta a una distribuzione a posteriori Beta con i parametri aggiornati \\(\\alpha' = \\alpha + y = 8\\) e \\(\\beta' = \\beta + n - y = 5\\).\nOra, vediamo come visualizzare le tre distribuzioni di interesse: la distribuzione a priori Beta(\\(2, 2\\)), la verosimiglianza binomiale per \\(y=6\\) e \\(n=9\\), e la distribuzione a posteriori Beta(\\(8, 5\\)).\n\n# Definizione dei parametri\nalpha_prior &lt;- 2\nbeta_prior &lt;- 2\ny &lt;- 6\nn &lt;- 9\n\n# Parametri della distribuzione a posteriori\nalpha_post &lt;- alpha_prior + y\nbeta_post &lt;- beta_prior + n - y\n\n# Creiamo una sequenza di valori di theta\ntheta &lt;- seq(0, 1, length.out = 1000) # Maggiore risoluzione\n\n# Calcoliamo le PDF\nprior_pdf &lt;- dbeta(theta, shape1 = alpha_prior, shape2 = beta_prior)\nlikelihood &lt;- theta^y * (1 - theta)^(n - y)\n\n# Normalizziamo la verosimiglianza usando il metodo trapezoidale\nlikelihood_integral &lt;- sum(likelihood) * (theta[2] - theta[1]) # Approssimazione numerica dell'integrale\nnormalized_likelihood &lt;- likelihood / likelihood_integral\n\nposterior_pdf &lt;- dbeta(theta, shape1 = alpha_post, shape2 = beta_post)\n\n# Disegniamo le distribuzioni\nplot(theta, prior_pdf,\n    type = \"l\", col = \"blue\", lwd = 2,\n    ylim = c(0, max(c(prior_pdf, normalized_likelihood, posterior_pdf))),\n    xlab = expression(theta), ylab = \"Densit√†\",\n    main = \"Distribuzioni Prior, Likelihood e Posterior\"\n)\nlines(theta, normalized_likelihood, col = \"green\", lwd = 2, lty = 2)\nlines(theta, posterior_pdf, col = \"red\", lwd = 2)\nlegend(\"topleft\",\n    legend = c(\n        sprintf(\"Prior Beta(%d, %d)\", alpha_prior, beta_prior),\n        \"Likelihood (normalizzata)\",\n        sprintf(\"Posterior Beta(%d, %d)\", alpha_post, beta_post)\n    ),\n    col = c(\"blue\", \"green\", \"red\"),\n    lty = c(1, 2, 1), lwd = 2\n)\n\n\n\n\n\n\n\n\nIn questo codice, la funzione trapezoid viene usata per calcolare l‚Äôintegrale della funzione di verosimiglianza non normalizzata su Œ∏, fornendo il fattore di normalizzazione. Dividendo la funzione di verosimiglianza per questo fattore, otteniamo una funzione di verosimiglianza normalizzata, il cui integrale su [0, 1] √® uguale a 1. La normalizzazione della verosimiglianza √® eseguita solo a scopo di visualizzazione, per facilitare il confronto tra le curve.\n\n\nEsempio 43.2 Esaminiamo ora un esempio discuso da Johnson et al. (2022). In uno studio molto famoso, Stanley Milgram ha studiato la propensione delle persone a obbedire agli ordini delle figure di autorit√†, anche quando tali ordini potrebbero danneggiare altre persone (Milgram 1963). Nell‚Äôarticolo, Milgram descrive lo studio come\n\nconsistente nell‚Äôordinare a un soggetto ingenuo di somministrare una scossa elettrica a una vittima. Viene utilizzato un generatore di scosse simulato, con 30 livelli di tensione chiaramente contrassegnati che vanno da IS a 450 volt. Lo strumento porta delle designazioni verbali che vanno da Scossa Lieve a Pericolo: Scossa Grave. Le risposte della vittima, che √® un complice addestrato dell‚Äôesperimentatore, sono standardizzate. Gli ordini di somministrare scosse vengono dati al soggetto ingenuo nel contesto di un ‚Äòesperimento di apprendimento‚Äô apparentemente organizzato per studiare gli effetti della punizione sulla memoria. Man mano che l‚Äôesperimento procede, al soggetto ingenuo viene ordinato di somministrare scosse sempre pi√π intense alla vittima, fino al punto di raggiungere il livello contrassegnato Pericolo: Scossa Grave.\n\nIn altre parole, ai partecipanti allo studio veniva dato il compito di testare un altro partecipante (che in realt√† era un attore addestrato) sulla loro capacit√† di memorizzare una serie di item. Se l‚Äôattore non ricordava un item, al partecipante veniva ordinato di somministrare una scossa all‚Äôattore e di aumentare il livello della scossa con ogni fallimento successivo. I partecipanti non erano consapevoli del fatto che le scosse fossero finte e che l‚Äôattore stesse solo fingendo di provare dolore dalla scossa.\nNello studio di Milgram, 26 partecipanti su 40 hanno somministrato scosse al livello ‚ÄúPericolo: Scossa Grave‚Äù. Il problema richiede di costruire la distribuzione a posteriori della probabilit√† \\(\\theta\\) di infliggere una scossa a l livello ‚ÄúPericolo: Scossa Grave‚Äù, ipotizzando che uno studio precedente aveva stabilito che \\(\\theta\\) segue una distribuzione Beta(1, 10).\nIniziamo a fornire una rappresentazione grafica della distribuzione a priori.\n\n# Impostazione dei parametri della distribuzione Beta\nalpha &lt;- 1\nbeta_val &lt;- 10\n\n# Creazione di valori x per il plot\nx_values &lt;- seq(0, 1, length.out = 1000)\n\n# Calcolo della densit√† di probabilit√† per ogni valore di x\nbeta_pdf &lt;- dbeta(x_values, shape1 = alpha, shape2 = beta_val)\n\n# Plot della densit√† di probabilit√†\ncolor_fill &lt;- \"#b97c7c\"\nplot(x_values, beta_pdf,\n    type = \"l\", col = color_fill, lwd = 2,\n    main = \"Distribuzione Beta(1, 10)\",\n    xlab = \"x\", ylab = \"Densit√† di probabilit√†\"\n)\nlegend(\"topright\", legend = \"Beta(1, 10)\", col = color_fill, lwd = 2)\n\n\n\n\n\n\n\n\nLa distribuzione a posteriori segue una distribuzione Beta con parametri aggiornati:\n\ny &lt;- 26\nn &lt;- 40\n\nalpha_prior &lt;- 1\nbeta_prior &lt;- 10\n\nalpha_post &lt;- alpha_prior + y\nbeta_post &lt;- beta_prior + n - y\n\nalpha_post\n#&gt; [1] 27\nbeta_post\n#&gt; [1] 24\n\nCreazione di un grafico per la distribuzione a posteriori:\n\n# Creazione di valori x per il plot\nx_values &lt;- seq(0, 1, length.out = 1000)\n\n# Calcolo della densit√† di probabilit√† per ogni valore di x\nbeta_pdf &lt;- dbeta(x_values, alpha_post, beta_post)\n\n# Plot della densit√† di probabilit√†\nplot(x_values, beta_pdf,\n    type = \"l\", col = \"blue\", lwd = 2,\n    main = \"Distribuzione Beta(27, 24)\", xlab = expression(theta), ylab = \"Densit√† di probabilit√†\"\n)\nlegend(\"topright\", legend = \"Beta(27, 24)\", col = \"blue\", lwd = 2)\n\n\n\n\n\n\n\n\nCalcolo della media a posteriori di \\(\\theta\\):\n\nalpha_post / (alpha_post + beta_post)\n#&gt; [1] 0.529\n\nCalcolo della moda a posteriori:\n\n(alpha_post - 1) / (alpha_post + beta_post - 2)\n#&gt; [1] 0.531\n\nCalcolo della probabilit√† che \\(\\theta &gt; 0.6\\):\n\npbeta(0.6, alpha_post, beta_post, lower.tail = FALSE)\n#&gt; [1] 0.156\n\nOvvero:\n\n1 - pbeta(0.6, alpha_post, beta_post)\n#&gt; [1] 0.156\n\nEseguiamo il problema utilizzando il metodo basato su griglia. Definiamo la griglia di interesse:\n\ntheta &lt;- seq(0, 1, length.out = 100)\n\nCreiamo la distribuzione a priori:\n\nprior &lt;- dbeta(theta, alpha_prior, beta_prior)\n\nplot(theta, prior / sum(prior),\n    type = \"h\", col = \"blue\", lwd = 2,\n    main = \"Distribuzione a priori\", xlab = expression(theta), ylab = \"Probabilit√†\"\n)\n\n\n\n\n\n\n\n\nCreiamo la verosimiglianza:\n\nlk &lt;- dbinom(y, n, theta)\n\nplot(theta, lk / sum(lk),\n    type = \"h\", col = \"red\", lwd = 2,\n    main = \"Verosimiglianza\", xlab = expression(theta), ylab = \"Probabilit√†\"\n)\n\n\n\n\n\n\n\n\nCalcoliamo la distribuzione a posteriori:\n\npost &lt;- (prior * lk) / sum(prior * lk)\n\nplot(theta, post,\n    type = \"h\", col = \"green\", lwd = 2,\n    main = \"Distribuzione a posteriori\", xlab = expression(theta), ylab = \"Probabilit√†\"\n)\n\n\n\n\n\n\n\n\nEstrazione di un campione dalla distribuzione a posteriori:\n\nsamples &lt;- sample(theta, size = 1e6, replace = TRUE, prob = post)\n\nTroviamo la media a posteriori:\n\nmean(samples)\n#&gt; [1] 0.529\n\nCalcoliamo la probabilit√† che \\(\\theta &gt; 0.6\\):\n\nmean(samples &gt; 0.6)\n#&gt; [1] 0.153\n\nQuesto codice mantiene la struttura logica del problema e produce risultati equivalenti utilizzando R.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>¬† <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_conjugate_families_1.html#principali-distribuzioni-coniugate",
    "href": "chapters/bayesian_inference/05_conjugate_families_1.html#principali-distribuzioni-coniugate",
    "title": "43¬† Distribuzioni coniugate (1)",
    "section": "43.5 Principali distribuzioni coniugate",
    "text": "43.5 Principali distribuzioni coniugate\nEsistono altre combinazioni di verosimiglianza e distribuzione a priori che producono una distribuzione a posteriori con la stessa forma della distribuzione a priori. Ecco alcune delle pi√π note coniugazioni tra modelli statistici e distribuzioni a priori:\n\nNel modello Normale-Normale \\(\\mathcal{N}(\\mu, \\sigma^2_0)\\), la distribuzione a priori √® \\(\\mathcal{N}(\\mu_0, \\tau^2)\\) e la distribuzione a posteriori √® \\(\\mathcal{N}\\left(\\frac{\\mu_0\\sigma^2 + \\bar{y}n\\tau^2}{\\sigma^2 + n\\tau^2}, \\frac{\\sigma^2\\tau^2}{\\sigma^2 + n\\tau^2} \\right)\\).\nNel modello Poisson-gamma \\(\\text{Po}(\\theta)\\), la distribuzione a priori √® \\(\\Gamma(\\lambda, \\delta)\\) e la distribuzione a posteriori √® \\(\\Gamma(\\lambda + n \\bar{y}, \\delta +n)\\).\nNel modello esponenziale \\(\\text{Exp}(\\theta)\\), la distribuzione a priori √® \\(\\Gamma(\\lambda, \\delta)\\) e la distribuzione a posteriori √® \\(\\Gamma(\\lambda + n, \\delta +n\\bar{y})\\).\nNel modello uniforme-Pareto \\(\\text{U}(0, \\theta)\\), la distribuzione a priori √® \\(\\text{Pa}(\\alpha, \\varepsilon)\\) e la distribuzione a posteriori √® \\(\\text{Pa}(\\alpha + n, \\max(y_{(n)}, \\varepsilon))\\).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>¬† <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_conjugate_families_1.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/05_conjugate_families_1.html#riflessioni-conclusive",
    "title": "43¬† Distribuzioni coniugate (1)",
    "section": "43.6 Riflessioni Conclusive",
    "text": "43.6 Riflessioni Conclusive\nIn conclusione, l‚Äôutilizzo di priori coniugati presenta vantaggi e svantaggi. Cominciamo con i vantaggi principali. Il principale vantaggio dell‚Äôadozione di distribuzioni a priori coniugate risiede nella loro capacit√† di rendere l‚Äôanalisi della distribuzione a posteriori trattabile da un punto di vista analitico. Ad esempio, nel corso di questo capitolo abbiamo esaminato come sia possibile formulare la distribuzione a posteriori in seguito a un esperimento composto da una serie di prove di Bernoulli (con una verosimiglianza binomiale), utilizzando una distribuzione Beta sia per la prior che per il posteriore.\nTuttavia, √® cruciale riconoscere che i modelli basati sul concetto di famiglie coniugate presentano delle limitazioni intrinseche. Le distribuzioni coniugate a priori sono disponibili solamente per distribuzioni di verosimiglianza di base e relativamente semplici. Per modelli complessi e pi√π realistici, la ricerca di priori coniugati diventa spesso un compito estremamente arduo, limitando quindi la loro utilit√†. Inoltre, anche quando le distribuzioni a priori coniugate sono disponibili, un modello che ne fa uso potrebbe non essere sufficientemente flessibile per adattarsi alle nostre credenze iniziali. Ad esempio, un modello basato su una distribuzione normale √® sempre unimodale e simmetrico rispetto alla media \\(\\mu\\). Tuttavia, se le nostre conoscenze iniziali non sono simmetriche o non seguono una distribuzione unimodale, la scelta di una distribuzione a priori normale potrebbe non risultare la pi√π adeguata (Johnson et al., 2022).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>¬† <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_conjugate_families_1.html#esercizi",
    "href": "chapters/bayesian_inference/05_conjugate_families_1.html#esercizi",
    "title": "43¬† Distribuzioni coniugate (1)",
    "section": "43.7 Esercizi",
    "text": "43.7 Esercizi\n\nEsercizio 43.1 Si consideri lo studio ‚ÄúAn excess of positive results: Comparing the standard psychology literature with registered reports‚Äù di Scheel et al. (2021). In questo lavoro, gli autori confrontano il tasso di risultati positivi \\(\\theta\\) ottenuti in studi psicologici pubblicati senza preregistrazione con quelli pubblicati con preregistrazione. Si utilizzi il tasso di successo riportato negli studi preregistrati per costruire una distribuzione a priori per il parametro \\(\\theta\\).\nSecondo i risultati degli studi preregistrati, gli autori riscontrano un tasso di successo del 43.66%, con un intervallo di confidenza al 95% [CI] = [31.91, 55.95]. Sulla base di questi dati, si costruisca una distribuzione beta come distribuzione a priori per \\(\\theta\\), seguendo il metodo illustrato da Johnson et al. (2022).\nSuccessivamente, utilizzando questa distribuzione beta come distribuzione a priori, si determini la distribuzione a posteriori utilizzando il metodo delle famiglie coniugate per due scenari distinti, basati su 152 studi osservati: (a) Un tasso di successo del 60% (b) Un tasso di successo del 96% (come riportato per gli studi non preregistrati da Scheel et al. (2021)).\nInfine, si commentino i risultati derivanti dall‚Äôanalisi delle distribuzioni a posteriori ottenute per entrambi gli scenari.\n\n\nEsercizio 43.2 Tra i fattori che possono influenzare il rapporto tra i sessi alla nascita c‚Äô√® la condizione materna di placenta previa, una condizione insolita della gravidanza in cui la placenta √® impiantata in basso nell‚Äôutero, impedendo un normale parto vaginale del feto. Uno studio condotto in Germania ha esaminato il sesso dei neonati in casi di placenta previa e ha riscontrato che, su un totale di 980 nascite, 437 erano femmine.\nQuanta evidenza fornisce questo studio a supporto dell‚Äôipotesi che la proporzione di nascite femminili nella popolazione di placenta previa sia inferiore a 0.485, che rappresenta la proporzione di nascite femminili nella popolazione generale? (Esercizio tratto da Gelman et al. (1995))\n\n\nEsercizio 43.3 Per valutare la sensibilit√† della soluzione precedente alla scelta della distribuzione a priori, ripetere l‚Äôesercizio utilizzando come distribuzione a priori per la proporzione di nascite femminili una distribuzione Beta(48.5, 51.5). Questa distribuzione √® centrata su 0.485 e concentra la maggior parte della sua massa nell‚Äôintervallo [0.385, 0.585]. Interpretare i risultati ottenuti.\n\n\nEsercizio 43.4 In uno studio recente, Gori et al. (2024) hanno esaminato un campione di 202 adulti italiani e hanno riscontrato una prevalenza di mancini del 6.4%. Una meta-analisi di Papadatou-Pastou et al. (2020), condotta su un totale di 2,396,170 soggetti, riporta che la proporzione di mancini varia tra il 9.3% e il 18.1%, a seconda di come viene misurata la lateralit√† manuale. Inoltre, Papadatou-Pastou et al. (2020) mostrano che la prevalenza della lateralit√† manuale varia tra i paesi e nel tempo. Considerata questa incertezza, si determini la distribuzione a posteriori che combina i dati dello studio di Gori et al. (2024) con le informazioni pregresse fornite da Papadatou-Pastou et al.¬†(2020). Le informazioni di Papadatou-Pastou et al. (2020) possono essere espresse in termini di una distribuzione Beta(8, 60).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>¬† <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_conjugate_families_1.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/05_conjugate_families_1.html#informazioni-sullambiente-di-sviluppo",
    "title": "43¬† Distribuzioni coniugate (1)",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: US/Pacific\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.17.0      ggokabeito_0.1.0 see_0.9.0        gridExtra_2.3   \n#&gt;  [5] patchwork_1.3.0  bayesplot_1.11.1 psych_2.4.12     scales_1.3.0    \n#&gt;  [9] markdown_1.13    knitr_1.49       lubridate_1.9.4  forcats_1.0.0   \n#&gt; [13] stringr_1.5.1    dplyr_1.1.4      purrr_1.0.2      readr_2.1.5     \n#&gt; [17] tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0 \n#&gt; [21] rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      shape_1.4.6.1     xfun_0.50         htmlwidgets_1.6.4\n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2      \n#&gt;  [9] generics_0.1.3    parallel_4.4.2    pan_1.9           pacman_0.5.1     \n#&gt; [13] jomo_2.7-6        pkgconfig_2.0.3   Matrix_1.7-1      lifecycle_1.0.4  \n#&gt; [17] compiler_4.4.2    farver_2.1.2      munsell_0.5.1     mnormt_2.1.1     \n#&gt; [21] codetools_0.2-20  htmltools_0.5.8.1 yaml_2.3.10       glmnet_4.1-8     \n#&gt; [25] nloptr_2.1.1      pillar_1.10.1     MASS_7.3-64       iterators_1.0.14 \n#&gt; [29] rpart_4.1.23      boot_1.3-31       foreach_1.5.2     mitml_0.4-5      \n#&gt; [33] nlme_3.1-166      tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4    \n#&gt; [37] splines_4.4.2     rprojroot_2.0.4   fastmap_1.2.0     grid_4.4.2       \n#&gt; [41] colorspace_2.1-1  cli_3.6.3         magrittr_2.0.3    survival_3.7-0   \n#&gt; [45] broom_1.0.7       withr_3.0.2       backports_1.5.0   timechange_0.3.0 \n#&gt; [49] rmarkdown_2.29    nnet_7.3-19       lme4_1.1-35.5     hms_1.1.3        \n#&gt; [53] evaluate_1.0.1    rlang_1.1.4       Rcpp_1.0.13-1     glue_1.8.0       \n#&gt; [57] minqa_1.2.8       jsonlite_1.8.9    R6_2.5.1",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>¬† <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_conjugate_families_1.html#bibliografia",
    "href": "chapters/bayesian_inference/05_conjugate_families_1.html#bibliografia",
    "title": "43¬† Distribuzioni coniugate (1)",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., Carlin, J. B., Stern, H. S., & Rubin, D. B. (1995). Bayesian data analysis. Chapman; Hall/CRC.\n\n\nGori, B., Grippo, A., Focardi, M., & Lolli, F. (2024). The Italian version of Edinburgh Handedness Inventory: Translation, transcultural adaptation, and validation in healthy subjects. Laterality, 29(2), 151‚Äì168.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nPapadatou-Pastou, M., Ntolka, E., Schmitz, J., Martin, M., Munaf√≤, M. R., Ocklenburg, S., & Paracchini, S. (2020). Human handedness: A meta-analysis. Psychological bulletin, 146(6), 481‚Äì524.\n\n\nScheel, A. M., Schijen, M. R., & Lakens, D. (2021). An excess of positive results: Comparing the standard psychology literature with registered reports. Advances in Methods and Practices in Psychological Science, 4(2), 25152459211007467.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>¬† <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_conjugate_families_2.html",
    "href": "chapters/bayesian_inference/06_conjugate_families_2.html",
    "title": "44¬† Distribuzioni coniugate (2)",
    "section": "",
    "text": "44.1 Introduzione\nLa statistica bayesiana ci permette di aggiornare le nostre credenze iniziali o conoscenze a priori sulla distribuzione di un parametro (in questo caso, la media della popolazione) in base ai dati osservati. Questo processo di aggiornamento ci porta a ottenere una distribuzione a posteriori che riflette una nuova comprensione del parametro, integrata con le informazioni fornite dal campione.\nIl concetto fondamentale √® che, attraverso l‚Äôaggiornamento bayesiano, l‚Äôincertezza sulla stima del parametro si riduce. Questo √® dovuto al fatto che l‚Äôinformazione aggiuntiva fornita dai dati osservati consente di ‚Äúrestringere‚Äù la distribuzione a posteriori rispetto alla distribuzione a priori, riducendo cos√¨ la varianza (o deviazione standard) della distribuzione del parametro di interesse.\nIn questo capitolo, approfondiremo il tema delle famiglie coniugate (Capitolo 43), focalizzandoci sul modello normale-normale. Una caratteristica distintiva di questo modello √® la sua capacit√† di auto-coniugazione rispetto a una funzione di verosimiglianza gaussiana. In termini pi√π semplici, se la funzione di verosimiglianza segue una distribuzione gaussiana, l‚Äôadozione di una distribuzione a priori gaussiana per la media garantisce che anche la distribuzione a posteriori mantenga la sua forma gaussiana.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>¬† <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_conjugate_families_2.html#perch√©-usare-la-distribuzione-normale",
    "href": "chapters/bayesian_inference/06_conjugate_families_2.html#perch√©-usare-la-distribuzione-normale",
    "title": "44¬† Distribuzioni coniugate (2)",
    "section": "44.2 Perch√© Usare la Distribuzione Normale?",
    "text": "44.2 Perch√© Usare la Distribuzione Normale?\nSpesso, quando la distribuzione a posteriori √® nota per essere unimodale e simmetrica, possiamo modellarla efficacemente con una distribuzione normale, anche se sappiamo che la sua forma √® solo approssimativamente normale. Nei casi in cui il ricercatore abbia un‚Äôidea approssimativa di dove sia centrato un parametro sconosciuto, la distribuzione normale fornisce un metodo utile per modellare questa stima, permettendo di descrivere il livello di incertezza tramite il termine di varianza della distribuzione normale. Questa convenienza pu√≤ offrire buone approssimazioni alla densit√† a posteriori desiderata, con la consapevolezza che, con l‚Äôaumentare dei dati osservati, tali assunzioni perdono di importanza.\nCome dimostrato di seguito, il modello normale bayesiano possiede propriet√† frequentiste desiderabili. Sebbene l‚Äôenfasi nell‚Äôanalisi bayesiana non sia sulle stime puntuali, si pu√≤ dimostrare che, con campioni sempre pi√π grandi, la media della distribuzione a posteriori bayesiana si avvicina alla stima di massima verosimiglianza. Questa propriet√† esiste perch√© la distribuzione a posteriori √® un compromesso ponderato tra la distribuzione a priori specificata dall‚Äôutente, che in questo capitolo √® normale, e la funzione di verosimiglianza derivata dai dati, anch‚Äôessa normale in questo capitolo. Con l‚Äôaumentare delle dimensioni del campione, la verosimiglianza diventa sempre pi√π dominante in questa ponderazione.\nNel caso di una media normale, illustrato qui, la varianza della distribuzione di campionamento frequentista diminuisce con l‚Äôaumento della dimensione del campione. Nel contesto bayesiano, la riduzione della varianza media dalla funzione di verosimiglianza alla fine prevale anche su una varianza a priori deliberatamente grande. Pertanto, se si prevede che la dimensione del dataset sia grande, i ricercatori possono permettersi di essere liberali nella specificazione della varianza a priori.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>¬† <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_conjugate_families_2.html#distribuzione-a-posteriori-in-un-contesto-normale-con-varianza-nota",
    "href": "chapters/bayesian_inference/06_conjugate_families_2.html#distribuzione-a-posteriori-in-un-contesto-normale-con-varianza-nota",
    "title": "44¬† Distribuzioni coniugate (2)",
    "section": "44.3 Distribuzione a Posteriori in un Contesto Normale con Varianza Nota",
    "text": "44.3 Distribuzione a Posteriori in un Contesto Normale con Varianza Nota\nConsideriamo un insieme di dati \\(y = [y_1, y_2, \\ldots, y_n]\\), composto da \\(n\\) osservazioni indipendenti e identicamente distribuite (i.i.d.) secondo una distribuzione normale \\(\\mathcal{N}(\\mu, \\sigma^2)\\). In questo scenario, il nostro obiettivo √® stimare il valore del parametro \\(\\mu\\), che rappresenta la media della popolazione da cui provengono i dati.\n\n44.3.1 Distribuzione a Priori\nNell‚Äôapproccio bayesiano, assumiamo una conoscenza iniziale sul parametro \\(\\mu\\) mediante una distribuzione a priori. In questo caso, utilizziamo una distribuzione normale coniugata, ovvero una distribuzione normale con media \\(\\mu_0\\) e varianza \\(\\sigma_0^2\\). Questa scelta riflette la nostra incertezza iniziale su \\(\\mu\\).\n\n\n44.3.2 Funzione di Verosimiglianza\nLa funzione di verosimiglianza, denotata da \\(p(y | \\mu, \\sigma)\\), rappresenta la probabilit√† di osservare i dati \\(y\\) dato il valore del parametro \\(\\mu\\) e la varianza nota \\(\\sigma^2\\). Per una distribuzione normale i.i.d., la funzione di verosimiglianza √® data da:\n\\[\np(y | \\mu, \\sigma) = \\prod_{i=1}^n \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp\\left(-\\frac{(y_i - \\mu)^2}{2\\sigma^2}\\right).\n\\]\n\n\n44.3.3 Teorema di Bayes e Distribuzione a Posteriori\nIl teorema di Bayes combina la distribuzione a priori con la funzione di verosimiglianza per ottenere la distribuzione a posteriori del parametro \\(\\mu\\), data l‚Äôevidenza osservata \\(y\\):\n\\[\np(\\mu | y) = \\frac{ p(y | \\mu) p(\\mu) }{ p(y) }.\n\\]\nPoich√© la distribuzione a priori e la funzione di verosimiglianza sono entrambe distribuzioni normali, la distribuzione a posteriori risulter√† anch‚Äôessa una distribuzione normale con media a posteriori \\(\\mu_p\\) e varianza a posteriori \\(\\sigma_p^2\\).\n\n\n44.3.4 Formula per la Media a Posteriori (\\(\\mu_p\\))\nLa media a posteriori \\(\\mu_p\\) rappresenta la stima aggiornata del parametro \\(\\mu\\) alla luce delle informazioni contenute nei dati osservati. La sua formula √®:\n\\[\n\\mu_p = \\frac{\\frac{1}{\\sigma_0^2} \\mu_0 + \\frac{n}{\\sigma^2} \\bar{y}}{\\frac{1}{\\sigma_0^2} + \\frac{n}{\\sigma^2}},\n\\]\ndove \\(\\bar{y}\\) rappresenta la media campionaria:\n\\[\n\\bar{y} = \\frac{\\sum_{i=1}^n y_i}{n}.\n\\]\nOsserviamo che \\(\\mu_p\\) √® una combinazione ponderata tra la media a priori \\(\\mu_0\\) e la media campionaria \\(\\bar{y}\\). Il peso di \\(\\bar{y}\\) aumenta con il numero di osservazioni \\(n\\), mentre il peso di \\(\\mu_0\\) diminuisce. Questo riflette il fatto che con pi√π dati, la nostra fiducia nella media campionaria cresce, mentre l‚Äôincertezza a priori diminuisce.\n\n\n44.3.5 Formula per la Varianza a Posteriori (\\(\\sigma_p^2\\))\nLa varianza a posteriori \\(\\sigma_p^2\\) rappresenta l‚Äôincertezza residua sulla stima del parametro \\(\\mu\\) dopo aver incorporato le informazioni dai dati. La sua formula √®:\n\\[\n\\sigma_p^2 = \\frac{1}{\\frac{1}{\\sigma_0^2} + \\frac{n}{\\sigma^2}}.\n\\]\nRispetto alla varianza a priori \\(\\sigma_0^2\\), la varianza a posteriori \\(\\sigma_p^2\\) √® sempre inferiore o uguale. In altre parole, l‚Äôincertezza sulla stima di \\(\\mu\\) si riduce con l‚Äôaumentare del numero di osservazioni. La varianza a posteriori rappresenta un bilanciamento tra l‚Äôincertezza a priori (\\(\\sigma_0^2\\)) e l‚Äôinformazione derivata dai dati (\\(\\sigma^2/n\\)).\nIn sintesi, nel caso normale-normale con varianza nota, la distribuzione a posteriori risulta essere una distribuzione normale con una media e una varianza che riflettono un‚Äôintegrazione bilanciata tra l‚Äôinformazione a priori e quella ottenuta dai dati osservati. Questo approccio garantisce una stima aggiornata e affinata del parametro \\(\\mu\\) che migliora con l‚Äôaumento del numero di osservazioni.\n\nEsempio 44.1 I test standard di QI sono progettati per misurare l‚Äôintelligenza con una media di 100 e una deviazione standard di 15. Tuttavia, si dice anche che questi test presentino bias culturali che favoriscono alcuni gruppi rispetto ad altri. Un‚Äôulteriore complicazione si verifica quando i punteggi di QI vengono aggregati a livello nazionale, poich√© le caratteristiche interne ai paesi vengono mascherate. Questo esempio analizza i dati di QI raccolti a livello internazionale (Lynn e Vanhanen, 2001) per 80 paesi da fonti nazionali pubblicate e discussi da Gill (2015). L‚Äôidea chiave nella descrizione della distribuzione a posteriori √® se le differenze tra le nazioni alterano la parametrizzazione prevista.\nI dati di Lynn e Vanhanen (2001) sono forniti di seguito:\n\n\n\n\n\n\n\n\n\n\n\n\n\nPaese\nIQ\nPaese\nIQ\nPaese\nIQ\nPaese\nIQ\n\n\n\n\nArgentina\n96\nAustralia\n98\nAustria\n102\nBarbados\n78\n\n\nBelgium\n100\nBrazil\n87\nBulgaria\n93\nCanada\n97\n\n\nChina\n100\nCongo (Br.)\n73\nCongo (Zr.)\n65\nCroatia\n90\n\n\nCuba\n85\nCzech Repub.\n97\nDenmark\n98\nEcuador\n80\n\n\nEgypt\n83\nEq. Guinea\n59\nEthiopia\n63\nFiji\n84\n\n\nFinland\n97\nFrance\n98\nGermany\n102\nGhana\n71\n\n\nGreece\n92\nGuatemala\n79\nGuinea\n66\nHong Kong\n107\n\n\nHungary\n99\nIndia\n81\nIndonesia\n89\nIran\n84\n\n\nIraq\n87\nIreland\n93\nIsrael\n94\nItaly\n102\n\n\nJamaica\n72\nJapan\n105\nKenya\n72\nKorea (S.)\n106\n\n\nLebanon\n86\nMalaysia\n92\nMarshall I.\n84\nMexico\n87\n\n\nMorocco\n85\nNepal\n78\nNetherlands\n102\nNew Zealand\n100\n\n\nNigeria\n67\nNorway\n98\nPeru\n90\nPhilippines\n86\n\n\nPoland\n99\nPortugal\n95\nPuerto Rico\n84\nQatar\n78\n\n\nRomania\n94\nRussia\n96\nSamoa\n87\nSierra Leone\n64\n\n\nSingapore\n103\nSlovakia\n96\nSlovenia\n95\nSouth Africa\n72\n\n\nSpain\n97\nSudan\n72\nSuriname\n89\nSweden\n101\n\n\nSwitzerland\n101\nTaiwan\n104\nTanzania\n72\nThailand\n91\n\n\nTonga\n87\nTurkey\n90\nUganda\n73\nU.K.\n100\n\n\nU.S.\n98\nUruguay\n96\nZambia\n77\nZimbabwe\n66\n\n\n\nImplementiamo le informazioni necessarie in Python.\n\n# Dati IQ delle 80 nazioni\niq &lt;- c(\n  96, 100, 100, 85, 83, 97, 92, 99, 87, 72, 86, 85, 67, 99, 94, 103, 97, 101, 87, 98,\n  87, 73, 97, 59, 98, 79, 81, 93, 105, 92, 78, 98, 95, 96, 72, 104, 90, 96, 98, 102,\n  78, 90, 63, 84, 84, 107, 86, 102, 106, 94, 102, 72, 101, 89, 72, 101, 91, 100, 100,\n  66, 107, 86, 78, 84, 78, 64, 72, 101, 91, 100, 67, 86\n)\n\n\n# Numero di osservazioni\nn &lt;- length(iq)\n\n# Media campionaria\ny_bar &lt;- mean(iq)\n\n# Deviazione standard nota\nsigma &lt;- 15\n\n# Parametri a priori\nmu_0 &lt;- 100\nsigma_0 &lt;- 15\n\nCalcoliamo la media a posteriori con la formula discussa in precedenza\n\\[\n\\mu_p = \\frac{\\frac{1}{\\sigma_0^2}\\mu_0 + \\frac{n}{\\sigma^2}\\bar{y}}{\\frac {1}{\\sigma_0^2} + \\frac{n}{\\sigma^2}}\n\\]\ndove:\n\n\\(\\mu_0\\) √® la media a priori\n\\(\\sigma_0\\) √® la deviazione standard a priori\n\\(n\\) √® il numero di osservazioni\n\\(\\sigma\\) √® la deviazione standard delle osservazioni (nota)\n\\(\\bar{y}\\) √® la media campionaria\n\n\nmu_p &lt;- ((1 / sigma_0^2) * mu_0 + (n / sigma^2) * y_bar) /\n  ((1 / sigma_0^2) + (n / sigma^2))\nprint(paste(\"Media a posteriori (mu_p):\", round(mu_p, 2)))\n#&gt; [1] \"Media a posteriori (mu_p): 89.36\"\n\nCalcoliamo la varianza a posteriori\n\\[\n\\sigma_p^2 = \\frac{1}{\\frac {1}{\\sigma_0^2}+ \\frac{n}{\\sigma^2}}\n\\]\n\nsigma_p_sq &lt;- 1 / ((1 / sigma_0^2) + (n / sigma^2))\nsigma_p &lt;- sqrt(sigma_p_sq)\nprint(paste(\"Varianza a posteriori (sigma_p_sq):\", round(sigma_p_sq, 2)))\n#&gt; [1] \"Varianza a posteriori (sigma_p_sq): 3.08\"\n\nGeneriamo una rappresentazione grafica della distribuzione a posteriori della media del IQ sulla base dei dati osservati, avendo assunto mu_0 = 100 e sigma_0 = 15 per la distribuzione a priori.\n\n# Definizione dei valori sull'asse x\nx &lt;- seq(mu_p - 4 * sigma_p, mu_p + 4 * sigma_p, length.out = 1000)\n\n# Calcolo della densit√† di probabilit√†\npdf &lt;- dnorm(x, mean = mu_p, sd = sigma_p)\n\n# Creazione del grafico\nggplot(data.frame(x = x, pdf = pdf), aes(x = x, y = pdf)) +\n  geom_line(color = \"blue\", size = 1) +\n  geom_area(aes(fill = \"Posterior\"), alpha = 0.2) +\n  scale_fill_manual(values = c(\"blue\")) +\n  labs(\n    title = \"Distribuzione a Posteriori\",\n    x = \"Media del Quoziente di Intelligenza\",\n    y = \"Densit√† di probabilit√†\"\n  )\n#&gt; Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#&gt; ‚Ñπ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\nL‚Äôanalisi condotta mediante un modello bayesiano basato sulla distribuzione normale ha prodotto un risultato interessante: la media stimata della distribuzione a posteriori del QI si attesta a 89.36, un valore sensibilmente inferiore ai 100 punti previsti come media standard.\nTuttavia, per un‚Äôinterpretazione completa di questo dato, √® fondamentale adottare un approccio critico che consideri alcuni aspetti cruciali:\n\nLa media a posteriori √® ottenuta aggregando i dati QI di 80 nazioni diverse. Questo processo pu√≤ innescare un effetto di aggregazione, dove la media ‚Äúsmussata‚Äù risultante non rispecchia accuratamente la distribuzione del QI a livello individuale in ogni singola nazione. Di conseguenza, le differenze tra le nazioni in termini di QI medio e variabilit√† potrebbero essere mascherate da questa media aggregata.\n√à importante sottolineare che la media a posteriori viene calcolata utilizzando dati non ponderati per ogni nazione. Ci√≤ significa che nazioni con popolazioni pi√π piccole, anche se con punteggi QI mediamente pi√π alti o pi√π bassi, hanno lo stesso impatto sulla media aggregata rispetto a nazioni con popolazioni pi√π grandi. Questo aspetto potrebbe ulteriormente distorcere la rappresentazione della vera distribuzione globale del QI.\nLa deviazione osservata dalla media standard di 100 potrebbe non riflettere esclusivamente differenze nell‚Äôintelligenza media tra le nazioni, ma anche differenze nei contesti sanitari, sociologici e politici in cui i test sono stati somministrati. Fattori quali l‚Äôaccesso all‚Äôistruzione, la qualit√† della nutrizione e l‚Äôesposizione a stimoli cognitivi possono influenzare i punteggi QI ottenuti e contribuire alla variabilit√† osservata tra le nazioni.\nInoltre, √® fondamentale considerare la possibilit√† di un bias culturale intrinseco allo strumento stesso. I test del QI sono stati originariamente progettati per un contesto specifico (paese industrializzato di lingua inglese) e potrebbero non essere adatti o culturalmente sensibili a contesti differenti. Questo potrebbe portare a una sottostima dei punteggi QI in alcune nazioni e influenzare la media a posteriori aggregata.\n\nQuesti risultati evidenziano l‚Äôimportanza di un‚Äôattenta considerazione dei fattori metodologici quando si interpretano dati di test del QI a livello trans-culturale. L‚Äôeffetto di aggregazione, l‚Äôutilizzo di medie non ponderate, le differenze nei contesti e il potenziale bias culturale richiedono un‚Äôanalisi pi√π approfondita che consideri questi fattori e utilizzi metodi statistici pi√π sofisticati per ottenere una comprensione pi√π completa delle differenze nel QI tra le nazioni.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>¬† <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_conjugate_families_2.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/06_conjugate_families_2.html#riflessioni-conclusive",
    "title": "44¬† Distribuzioni coniugate (2)",
    "section": "44.4 Riflessioni Conclusive",
    "text": "44.4 Riflessioni Conclusive\nIn questo capitolo, abbiamo approfondito il meccanismo dell‚Äôaggiornamento bayesiano attraverso l‚Äôimplementazione del modello normale-normale. Il processo inizia definendo una distribuzione a priori per \\(\\mu\\), specificata da una media \\(\\mu_0\\) e una varianza \\(\\sigma_0^2\\). Dopo l‚Äôacquisizione di nuovi dati, ipotizzando che seguano una distribuzione Normale con media campionaria \\(\\bar{y}\\) e varianza nota \\(\\sigma^2\\), implementiamo il teorema normale-normale per derivare la distribuzione a posteriori del parametro.\nLa media della distribuzione a posteriori, denotata come \\(\\mu_{\\text{post}}\\), si configura come una media ponderata tra la media a priori \\(\\mu_0\\) e la media campionaria \\(\\bar{y}\\), dove il peso assegnato a ciascuna media √® determinato dalle rispettive varianze \\(\\sigma_0^2\\) e \\(\\sigma^2\\) della distribuzione a priori e dei dati osservati. Analogamente, la varianza a posteriori \\(\\sigma_{\\text{post}}^2\\) √® determinata utilizzando un‚Äôespressione che incorpora entrambe le varianze.\nIn sintesi, l‚Äôadozione del modello normale-normale in un contesto bayesiano facilita il calcolo delle distribuzioni a posteriori, grazie alla scelta di una distribuzione a priori Normale che mantiene la propriet√† di coniugatezza, semplificando cos√¨ l‚Äôintero processo analitico.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>¬† <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_conjugate_families_2.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/06_conjugate_families_2.html#informazioni-sullambiente-di-sviluppo",
    "title": "44¬† Distribuzioni coniugate (2)",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: US/Pacific\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.17.0      ggokabeito_0.1.0 see_0.9.0        gridExtra_2.3   \n#&gt;  [5] patchwork_1.3.0  bayesplot_1.11.1 psych_2.4.12     scales_1.3.0    \n#&gt;  [9] markdown_1.13    knitr_1.49       lubridate_1.9.4  forcats_1.0.0   \n#&gt; [13] stringr_1.5.1    dplyr_1.1.4      purrr_1.0.2      readr_2.1.5     \n#&gt; [17] tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0 \n#&gt; [21] rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      shape_1.4.6.1     xfun_0.50         htmlwidgets_1.6.4\n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2      \n#&gt;  [9] generics_0.1.3    parallel_4.4.2    pan_1.9           pacman_0.5.1     \n#&gt; [13] jomo_2.7-6        pkgconfig_2.0.3   Matrix_1.7-1      lifecycle_1.0.4  \n#&gt; [17] compiler_4.4.2    farver_2.1.2      munsell_0.5.1     mnormt_2.1.1     \n#&gt; [21] codetools_0.2-20  htmltools_0.5.8.1 yaml_2.3.10       glmnet_4.1-8     \n#&gt; [25] nloptr_2.1.1      pillar_1.10.1     MASS_7.3-64       iterators_1.0.14 \n#&gt; [29] rpart_4.1.23      boot_1.3-31       foreach_1.5.2     mitml_0.4-5      \n#&gt; [33] nlme_3.1-166      tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4    \n#&gt; [37] labeling_0.4.3    splines_4.4.2     rprojroot_2.0.4   fastmap_1.2.0    \n#&gt; [41] grid_4.4.2        colorspace_2.1-1  cli_3.6.3         magrittr_2.0.3   \n#&gt; [45] survival_3.7-0    broom_1.0.7       withr_3.0.2       backports_1.5.0  \n#&gt; [49] timechange_0.3.0  rmarkdown_2.29    nnet_7.3-19       lme4_1.1-35.5    \n#&gt; [53] hms_1.1.3         evaluate_1.0.1    rlang_1.1.4       Rcpp_1.0.13-1    \n#&gt; [57] glue_1.8.0        minqa_1.2.8       jsonlite_1.8.9    R6_2.5.1",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>¬† <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_conjugate_families_2.html#bibliografia",
    "href": "chapters/bayesian_inference/06_conjugate_families_2.html#bibliografia",
    "title": "44¬† Distribuzioni coniugate (2)",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGill, J. (2015). Bayesian methods: A social and behavioral sciences approach (3rd Edition). Chapman; Hall/CRC.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>¬† <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_summary_posterior.html",
    "href": "chapters/bayesian_inference/07_summary_posterior.html",
    "title": "45¬† Sintesi a posteriori",
    "section": "",
    "text": "45.1 Introduzione\nIn questo capitolo, concentriamo la nostra attenzione sulla sintesi dell‚Äôinformazione racchiusa nella distribuzione a posteriori, la quale rappresenta il nostro livello di incertezza riguardo al parametro o ai parametri incogniti oggetto dell‚Äôinferenza.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>¬† <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_summary_posterior.html#riepilogo-numerico",
    "href": "chapters/bayesian_inference/07_summary_posterior.html#riepilogo-numerico",
    "title": "45¬† Sintesi a posteriori",
    "section": "45.2 Riepilogo numerico",
    "text": "45.2 Riepilogo numerico\nLa distribuzione a posteriori contiene in s√© tutte le informazioni disponibili sui potenziali valori del parametro. Nel caso di un parametro unidimensionale o bidimensionale, possiamo rappresentare la distribuzione a posteriori mediante un grafico \\(p(\\theta \\mid y)\\).\nTuttavia, quando ci troviamo di fronte a vettori di parametri con pi√π di due dimensioni, risulta vantaggioso eseguire una sintesi numerica della distribuzione a posteriori. Possiamo distinguere due forme di sintesi numerica della distribuzione a posteriori:\n\nStima puntuale;\nIntervallo di credibilit√†.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>¬† <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_summary_posterior.html#stima-puntuale",
    "href": "chapters/bayesian_inference/07_summary_posterior.html#stima-puntuale",
    "title": "45¬† Sintesi a posteriori",
    "section": "45.3 Stima puntuale",
    "text": "45.3 Stima puntuale\nNel contesto dell‚Äôinferenza bayesiana, il processo di stima del valore pi√π credibile del parametro \\(\\theta\\) tramite la distribuzione a posteriori si avvale di tre statistiche: la moda, la mediana e la media, la cui scelta √® guidata dalla forma della distribuzione a posteriori. Queste statistiche sono utilizzate per ottenere una stima puntuale della tendenza centrale della distribuzione a posteriori, che a sua volta fornisce il ‚Äúvalore pi√π credibile‚Äù del parametro. Questo valore rappresenta la stima a cui attribuiamo il massimo grado di fiducia soggettiva, basandoci sui dati osservati e sulle nostre credenze a priori.\n\nModa (Massimo a posteriori, MAP):\nLa moda rappresenta il valore pi√π probabile di un parametro, ovvero quello che massimizza la distribuzione a posteriori. Questo valore √® noto come ‚Äúmassimo a posteriori‚Äù (MAP). La stima MAP prende origine dalla stima di massima verosimiglianza (MLE), che cerca il valore di \\(\\theta\\), denotato come \\(\\hat{\\theta}_{ML}\\), che massimizza la funzione di verosimiglianza \\(L(\\theta \\mid y)\\):\n\n\\[\n\\hat{\\theta}_{ML} = \\arg \\max_\\theta L(\\theta \\mid y).\n\\]\nNell‚Äôinferenza bayesiana, \\(\\theta\\) √® considerato una variabile casuale, e si specifica una distribuzione a priori su \\(\\theta\\) per riflettere l‚Äôincertezza sul suo valore. Integrando l‚Äôinformazione a priori nella funzione di verosimiglianza, si ottiene la formula per la stima MAP:\n\\[\n\\hat{\\theta}_{MAP} = \\arg \\max_\\theta L(\\theta \\mid y)p(\\theta).\n\\]\nQuesta formula evidenzia che la stima MAP corrisponde al valore che massimizza la densit√† a posteriori di \\(\\theta\\) dati i dati osservati \\(y\\), ovvero il valore che rappresenta la moda della distribuzione a posteriori.\nSebbene il concetto di MAP sia intuitivo, presenta diversi problemi che ne limitano l‚Äôuso nella pratica.\nLa prima difficolt√† √® di tipo computazionale: con i metodi MCMC comunemente utilizzati per stimare le distribuzioni a posteriori, √® molto difficile individuare con precisione la posizione esatta del MAP nello spazio delle distribuzioni posteriori.\nIl secondo problema √® legato all‚Äôuso dell‚Äôinferenza bayesiana in modelli complessi e in situazioni non asintotiche. In questi casi, la verosimiglianza o la distribuzione a posteriori possono avere forme irregolari o non normali. Se la distribuzione a posteriori √® molto asimmetrica, il MAP potrebbe non rappresentare adeguatamente dove si concentra la maggior parte della probabilit√†. Di conseguenza, il MAP non sempre fornisce un‚Äôidea accurata del comportamento complessivo della distribuzione a posteriori.\n\nMedia a posteriori:\n\nLa media a posteriori √® il valore atteso del parametro \\(\\theta\\), calcolato sulla base della distribuzione a posteriori. In termini matematici, nel caso continuo, √® espressa dalla formula:\n\\[\nE(\\theta \\mid y) = \\int_{-\\infty}^{\\infty} \\theta \\, p(\\theta \\mid y) \\, d\\theta.\n\\]\n\nMediana:\n\nLa mediana √® il valore del parametro per cui il 50% della massa di probabilit√† a posteriori si distribuisce equamente a sinistra e a destra. √à una misura robusta della tendenza centrale, particolarmente utile in presenza di distribuzioni asimmetriche o multimodali, dove la moda potrebbe non fornire una stima accurata del valore pi√π probabile del parametro.\nPer valutare l‚Äôincertezza associata al parametro \\(\\theta\\), √® utile calcolare la varianza a posteriori. Questa varianza √® basata sulla tendenza centrale definita dalla media a posteriori, e la sua radice quadrata fornisce la deviazione standard a posteriori, che misura l‚Äôincertezza a posteriori relativa a \\(\\theta\\), espressa nelle stesse unit√† di misura dei dati. La formula per la varianza a posteriori √® data da:\n\\[\nV(\\theta|y) = E[((\\theta - E[(\\theta|y)])^2 |y) = \\int_{-\\infty}^{\\infty} (\\theta - E[\\theta | y])^2 p(\\theta | y) d\\theta = E[\\theta^2 |y] - E[\\theta|y]^2.\n\\]\nIn sintesi, la media, la moda e la mediana a posteriori, insieme alla varianza a posteriori, forniscono una descrizione comprensiva del comportamento della distribuzione a posteriori di \\(\\theta\\), permettendoci di derivare stime puntuali e misurare l‚Äôincertezza associata a \\(\\theta\\) in modo informativo.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>¬† <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_summary_posterior.html#intervallo-di-credibilit√†",
    "href": "chapters/bayesian_inference/07_summary_posterior.html#intervallo-di-credibilit√†",
    "title": "45¬† Sintesi a posteriori",
    "section": "45.4 Intervallo di credibilit√†",
    "text": "45.4 Intervallo di credibilit√†\nNell‚Äôinferenza bayesiana, l‚Äôintervallo di credibilit√† √® uno strumento utilizzato per definire un intervallo che contiene una determinata percentuale della massa della distribuzione a posteriori del parametro \\(\\theta\\). Questo intervallo riflette l‚Äôincertezza associata alla stima del parametro: un intervallo pi√π ampio suggerisce una maggiore incertezza. Lo scopo principale dell‚Äôintervallo di credibilit√† √® fornire una misura quantitativa dell‚Äôincertezza riguardante \\(\\theta\\).\nA differenza degli intervalli di confidenza frequentisti, non esiste un unico intervallo di credibilit√† per un dato livello di confidenza \\((1 - \\alpha) \\cdot 100\\%\\). In effetti, √® possibile costruire un numero infinito di tali intervalli. Per questo motivo, √® necessario stabilire criteri aggiuntivi per selezionare l‚Äôintervallo di credibilit√† pi√π appropriato. Tra le opzioni pi√π comuni ci sono l‚Äôintervallo di credibilit√† simmetrico e l‚Äôintervallo di massima densit√† posteriore (HPD).\n\nIntervallo di Credibilit√† Simmetrico:\n\nQuesto tipo di intervallo √® centrato rispetto al punto di stima puntuale. Se \\(\\hat{\\theta}\\) rappresenta la stima del parametro, l‚Äôintervallo simmetrico avr√† la forma \\((\\hat{\\theta} - a, \\hat{\\theta} + a)\\), dove \\(a\\) √® un valore positivo scelto in modo tale che la massa totale inclusa sia pari a \\((1 - \\alpha)\\). Pi√π formalmente, un intervallo di credibilit√† simmetrico al livello \\(\\alpha\\) pu√≤ essere espresso come:\n\\[\nI_{\\alpha} = [q_{\\alpha/2}, q_{1 - \\alpha/2}],\n\\]\ndove \\(q_z\\) rappresenta il quantile \\(z\\) della distribuzione a posteriori. Ad esempio, un intervallo di credibilit√† simmetrico al 94% sar√†:\n\\[\nI_{0.06} = [q_{0.03}, q_{0.97}],\n\\]\ndove il 3% della massa a posteriori si trova in ciascuna delle due code della distribuzione.\n\nIntervallo di Credibilit√† Pi√π Stretto (Intervallo di Massima Densit√† Posteriore, HPD):\n\nL‚Äôintervallo di massima densit√† posteriore (HPD) √® l‚Äôintervallo pi√π stretto possibile che contiene il \\((1 - \\alpha) \\cdot 100\\%\\) della massa a posteriori. A differenza dell‚Äôintervallo simmetrico, l‚ÄôHPD include tutti i valori di \\(\\theta\\) che hanno la maggiore densit√† a posteriori. Per costruirlo, si disegna una linea orizzontale sulla distribuzione a posteriori e si regola l‚Äôaltezza della linea in modo che l‚Äôarea sotto la curva corrisponda a \\((1 - \\alpha)\\). L‚ÄôHPD risulta essere il pi√π stretto tra tutti gli intervalli possibili per lo stesso livello di confidenza. Nel caso di una distribuzione a posteriori unimodale e simmetrica, l‚ÄôHPD coincide con l‚Äôintervallo di credibilit√† simmetrico.\n\n45.4.1 Interpretazione\nIl calcolo degli intervalli di credibilit√†, in particolare dell‚Äôintervallo di massima densit√† posteriore (HPD), richiede spesso l‚Äôuso di software statistici avanzati. Questo perch√© determinare manualmente tali intervalli pu√≤ essere complicato, soprattutto nei modelli bayesiani con distribuzioni posteriori complesse o quando sono necessarie simulazioni numeriche per stimare la distribuzione a posteriori.\nUn aspetto cruciale dell‚Äôinferenza bayesiana riguarda l‚Äôinterpretazione dell‚Äôincertezza. Nel contesto frequentista, si considera il parametro, come ad esempio la media della popolazione \\(\\mu\\), come un valore fisso ma sconosciuto. L‚Äôinferenza frequentista si basa sull‚Äôimmaginare un numero infinito di campioni ripetuti dalla popolazione. Per ogni campione, si pu√≤ calcolare una media campionaria \\(\\bar{x}\\) e formare un intervallo di confidenza al \\(100(1-\\alpha)\\%\\). L‚Äôinterpretazione corretta in termini frequentisti √® che, nel lungo periodo, il \\(100(1-\\alpha)\\%\\) degli intervalli di confidenza costruiti con questo metodo conterr√† il vero valore del parametro \\(\\mu\\). Tuttavia, per un singolo intervallo calcolato, la probabilit√† che contenga effettivamente \\(\\mu\\) √® o 0 o 1, poich√© \\(\\mu\\) √® considerato un valore fisso.\nNel framework bayesiano, invece, il parametro √® trattato come una variabile aleatoria con una distribuzione di probabilit√†. Campionando dalla distribuzione a posteriori dei parametri, possiamo ottenere quantili che ci permettono di calcolare direttamente la probabilit√† che un parametro rientri in un determinato intervallo. Ad esempio, un intervallo di credibilit√† al 95% indica che c‚Äô√® una probabilit√† del 95% che il parametro sia contenuto all‚Äôinterno di quell‚Äôintervallo, data l‚Äôevidenza osservata. Questa interpretazione differisce profondamente da quella frequentista e risulta pi√π intuitiva, poich√© riflette direttamente il grado di incertezza che abbiamo riguardo al parametro.\nIn sintesi, mentre l‚Äôintervallo di confidenza frequentista riguarda la ripetizione ipotetica del campionamento, l‚Äôintervallo di credibilit√† bayesiano fornisce una misura diretta dell‚Äôincertezza attuale sul valore di un parametro, basata sui dati osservati e sulle informazioni a priori. Questo approccio √® spesso considerato pi√π vicino al senso comune quando si tratta di interpretare la probabilit√† associata ai parametri.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>¬† <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_summary_posterior.html#verifica-di-ipotesi-bayesiana",
    "href": "chapters/bayesian_inference/07_summary_posterior.html#verifica-di-ipotesi-bayesiana",
    "title": "45¬† Sintesi a posteriori",
    "section": "45.5 Verifica di ipotesi bayesiana",
    "text": "45.5 Verifica di ipotesi bayesiana\nL‚Äôinferenza bayesiana pu√≤ essere applicata anche nel contesto della verifica di ipotesi, in un approccio noto come verifica di ipotesi bayesiana. In questo tipo di inferenza, l‚Äôobiettivo √® valutare la plausibilit√† che un parametro \\(\\theta\\) assuma valori all‚Äôinterno di un determinato intervallo. Ad esempio, possiamo voler sapere quanto √® probabile che \\(\\theta\\) sia maggiore di 0.5 o che rientri in un intervallo specifico, come [0.5, 1.0].\nIn questo approccio, si calcola la probabilit√† a posteriori che \\(\\theta\\) si trovi all‚Äôinterno dell‚Äôintervallo di interesse. Questa probabilit√† viene ottenuta integrando la distribuzione a posteriori su tale intervallo. Quindi, invece di rifiutare o accettare un‚Äôipotesi come nel test di ipotesi frequentista, la verifica di ipotesi bayesiana fornisce una misura diretta della probabilit√† che un parametro rientri in un intervallo specifico, dato l‚Äôevidenza osservata e le informazioni a priori.\nIn altre parole, questo approccio consente di quantificare la nostra incertezza rispetto all‚Äôaffermazione che \\(\\theta\\) rientri in un certo intervallo, fornendo una probabilit√† che rappresenta direttamente la plausibilit√† di quell‚Äôipotesi.\n\nEsempio 45.1 Per illustrare l‚Äôapproccio bayesiano, consideriamo i dati relativi ai punteggi del BDI-II (Beck Depression Inventory - Second Edition) di 30 soggetti clinici, come riportato nello studio condotto da Zetsche et al. (2019). Il BDI-II √® uno strumento per valutare la gravit√† dei sintomi depressivi.\nI punteggi del BDI-II per i 30 soggetti sono:\n\n# Dati del BDI-II\nbdi &lt;- c(\n  26, 35, 30, 25, 44, 30, 33, 43, 22, 43, \n  24, 19, 39, 31, 25, 28, 35, 30, 26, 31, \n  41, 36, 26, 35, 33, 28, 27, 34, 27, 22\n)\nbdi\n#&gt;  [1] 26 35 30 25 44 30 33 43 22 43 24 19 39 31 25 28 35 30 26 31 41 36 26 35\n#&gt; [25] 33 28 27 34 27 22\n\nUn punteggio BDI-II \\(\\geq 30\\) indica un livello grave di depressione. Nel nostro campione, 17 pazienti su 30 manifestano un livello grave:\n\n# Conteggio di depressione grave\nsum(bdi &gt;= 30)\n#&gt; [1] 17\n\n\n45.5.1 Stima della Distribuzione a Posteriori\nSupponiamo di voler stimare la probabilit√† \\(\\theta\\) di depressione grave nei pazienti clinici utilizzando una distribuzione a priori \\(Beta(8, 2)\\). I dati possono essere visti come una sequenza di prove Bernoulliane indipendenti, dove la presenza di depressione grave √® un ‚Äúsuccesso‚Äù. La verosimiglianza √® quindi binomiale con parametri \\(n = 30\\) e \\(y = 17\\).\nCon una distribuzione a priori \\(Beta(8, 2)\\), la distribuzione a posteriori di \\(\\theta\\) sar√†:\n\\[\n\\text{Beta}(\\alpha = 8 + 17, \\beta = 2 + 30 - 17) = \\text{Beta}(25, 15).\n\\]\n\n45.5.1.1 Tracciamo la Distribuzione a Posteriori\n\n# Parametri della distribuzione Beta\nalpha &lt;- 25\nbeta &lt;- 15\n\n# Calcolo della densit√† per valori di theta\ntheta &lt;- seq(0, 1, length.out = 200)\nposterior_density &lt;- dbeta(theta, alpha, beta)\n\n# Grafico della distribuzione a posteriori\nggplot(data = data.frame(theta, posterior_density), aes(x = theta, y = posterior_density)) +\n  geom_line(color = \"blue\") +\n  labs(\n    title = \"Distribuzione a Posteriori Beta(25, 15)\",\n    x = expression(theta),\n    y = \"Densit√† di probabilit√†\"\n  ) \n\n\n\n\n\n\n\n\n\n\n\n\n45.5.2 Stime Puntuali\n\nMedia a Posteriori\nLa media della distribuzione a posteriori √® calcolata come:\n\n\\[\n\\mathbb{E}(\\theta | y = 17) = \\frac{\\alpha}{\\alpha + \\beta} = \\frac{25}{25 + 15} = 0.625.\n\\]\nIn R:\n\n# Calcolo della media a posteriori\nposterior_mean &lt;- alpha / (alpha + beta)\nposterior_mean\n#&gt; [1] 0.625\n\n\nModa a Posteriori (MAP)\nLa moda della distribuzione a posteriori √®:\n\n\\[\nMo(\\theta | y = 17) = \\frac{\\alpha - 1}{\\alpha + \\beta - 2} = \\frac{25 - 1}{25 + 15 - 2} = 0.6316.\n\\]\nIn R:\n\n# Calcolo della moda a posteriori\nposterior_mode &lt;- (alpha - 1) / (alpha + beta - 2)\nposterior_mode\n#&gt; [1] 0.632\n\n\nMediana a Posteriori\nLa mediana si ottiene utilizzando la funzione di distribuzione cumulativa inversa:\n\n\n# Calcolo della mediana a posteriori\nposterior_median &lt;- qbeta(0.5, alpha, beta)\nposterior_median\n#&gt; [1] 0.627\n\n\n\n\n45.5.3 Intervallo di Credibilit√†\nL‚Äôintervallo di credibilit√† simmetrico al 94% √® dato dai percentili 3% e 97%:\n\n# Intervallo di credibilit√† simmetrico al 94%\ncred_interval &lt;- qbeta(c(0.03, 0.97), alpha, beta)\ncred_interval\n#&gt; [1] 0.478 0.761\n\nPossiamo interpretare questo intervallo come segue: c‚Äô√® una certezza soggettiva del 94% che \\(\\theta\\) sia compreso tra 0.478 e 0.761.\n\n\n\n45.5.4 Verifica di Ipotesi Bayesiana\nInfine, calcoliamo la probabilit√† che \\(\\theta &gt; 0.5\\):\n\\[\nP(\\theta &gt; 0.5 | y = 17) = \\int_{0.5}^1 f(\\theta | y = 17) d\\theta.\n\\]\nIn R:\n\n# Probabilit√† P(theta &gt; 0.5)\nprob_theta_greater_0_5 &lt;- pbeta(0.5, alpha, beta, lower.tail = FALSE)\nprob_theta_greater_0_5\n#&gt; [1] 0.946\n\nIn conclusione, utilizzando un approccio bayesiano, abbiamo stimato la distribuzione a posteriori di \\(\\theta\\), ottenuto stime puntuali e costruito intervalli di credibilit√†. Abbiamo inoltre calcolato la probabilit√† che \\(\\theta\\) superi una soglia specifica, mostrando la flessibilit√† e l‚Äôinterpretabilit√† delle analisi bayesiane.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>¬† <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_summary_posterior.html#sintesi-della-distribuzione-a-posteriori-questioni-multivariate",
    "href": "chapters/bayesian_inference/07_summary_posterior.html#sintesi-della-distribuzione-a-posteriori-questioni-multivariate",
    "title": "45¬† Sintesi a posteriori",
    "section": "45.6 Sintesi della distribuzione a posteriori: questioni multivariate",
    "text": "45.6 Sintesi della distribuzione a posteriori: questioni multivariate\nQuando si affronta un‚Äôanalisi bayesiana con pi√π parametri, la complessit√† aumenta. Le principali difficolt√† riguardano le interazioni tra i parametri e il modo in cui queste influenzano le distribuzioni marginali. Questi fattori possono complicare notevolmente la sintesi della distribuzione a posteriori e, se non considerati attentamente, possono portare a interpretazioni errate.\n\n45.6.1 Correlazioni nascoste e distribuzioni marginali\nUn problema comune nelle analisi con pi√π parametri √® rappresentato dalle correlazioni tra i parametri. Le distribuzioni marginali a posteriori, spesso riportate nei riassunti statistici, possono essere molto fuorvianti se considerate isolatamente. Quando i parametri sono fortemente correlati, le distribuzioni marginali possono apparire piatte o poco informative, inducendo a pensare che non ci sia molta informazione nella verosimiglianza.\nTuttavia, le correlazioni tra parametri possono restringere notevolmente lo spazio delle combinazioni plausibili, escludendo vaste aree dello spazio dei parametri. Questo significa che, nonostante le marginali possano sembrare non informative, l‚Äôanalisi congiunta dei parametri pu√≤ rivelare una struttura sottostante che riduce l‚Äôincertezza su specifiche combinazioni. Pertanto, √® essenziale esaminare le correlazioni congiunte tra i parametri per ottenere una visione pi√π completa dell‚Äôincertezza.\nCon un numero maggiore di parametri, anche i grafici di correlazione bidimensionali possono diventare limitati, poich√© potrebbero esistere correlazioni di ordine superiore che non emergono in rappresentazioni a due dimensioni.\n\n\n45.6.2 Correlazioni non lineari\nUn‚Äôaltra difficolt√† significativa riguarda le correlazioni non lineari tra i parametri. Quando queste correlazioni sono presenti, il massimo delle distribuzioni marginali non coincide necessariamente con il massimo della distribuzione congiunta. Per esempio, se due parametri presentano una correlazione complessa, come una forma a ‚Äúbanana‚Äù, il massimo delle distribuzioni marginali potrebbe trovarsi in una posizione diversa rispetto al massimo globale della distribuzione congiunta.\nQuesto fenomeno rende pi√π difficile sintetizzare correttamente la distribuzione a posteriori. In tali casi, la stima del massimo a posteriori (MAP) o altri riassunti, come gli intervalli di credibilit√† (CI) o gli intervalli di massima densit√† a posteriori (HPD), calcolati sulle marginali, potrebbero essere fuorvianti. Quando la distribuzione a posteriori √® asimmetrica nello spazio multivariato, le distribuzioni marginali non catturano adeguatamente le relazioni tra i parametri. Questa √® una fonte comune di confusione, poich√© si tende a sottovalutare l‚Äôimportanza della struttura multivariata nella distribuzione a posteriori.\n\n\n45.6.3 Strategie per affrontare queste sfide\n\nConfronto tra distribuzioni predittive:\n\nConfrontare la distribuzione predittiva a priori con quella a posteriori offre una visione pi√π completa della riduzione dell‚Äôincertezza.\nQuesto approccio √® particolarmente utile in presenza di parametri multipli e correlazioni complesse, poich√© la distribuzione predittiva a posteriori incorpora le interazioni tra i parametri, fornendo una rappresentazione pi√π accurata della plausibilit√† dei diversi valori parametrici.\n\nAnalisi congiunta:\n\nEsaminare le distribuzioni congiunte dei parametri, oltre alle distribuzioni marginali.\nUtilizzare grafici di dispersione bivariati o multivariati per visualizzare le relazioni tra i parametri.\nTecniche avanzate di visualizzazione, come i pair plots o le heatmap, possono essere utili per esplorare relazioni in spazi ad alta dimensionalit√†.\n\nMisure di dipendenza:\n\nUtilizzare misure di dipendenza non lineare, come la correlazione di Spearman o l‚Äôinformazione mutua, che possono catturare relazioni complesse che le misure lineari tradizionali potrebbero non rilevare.\n\nAnalisi di sensibilit√†:\n\nCondurre un‚Äôanalisi di sensibilit√† per valutare come i cambiamenti in un parametro influenzano gli altri parametri e le previsioni del modello. Questo permette di capire meglio le relazioni tra i parametri e il loro impatto sulle inferenze.\n\nTecniche di riduzione della dimensionalit√†:\n\nQuando ci sono molti parametri, l‚Äôuso di metodi come l‚Äôanalisi delle componenti principali (PCA) pu√≤ aiutare a identificare strutture latenti e ridurre la complessit√† del problema, facilitando l‚Äôinterpretazione dei risultati.\n\n\nIn sintesi, l‚Äôanalisi multivariata in un contesto bayesiano richiede particolare attenzione nella sintesi delle distribuzioni a posteriori. Le distribuzioni marginali possono fornire informazioni utili, ma spesso nascondono importanti correlazioni e strutture di dipendenza tra i parametri. Un‚Äôanalisi completa dovrebbe combinare l‚Äôesame delle marginali con una valutazione attenta delle relazioni congiunte tra i parametri, utilizzando tecniche di visualizzazione e misure di dipendenza adeguate. Questo approccio integrato permette di comprendere pi√π a fondo la distribuzione a posteriori e di trarre inferenze pi√π robuste e accurate.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>¬† <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_summary_posterior.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/07_summary_posterior.html#riflessioni-conclusive",
    "title": "45¬† Sintesi a posteriori",
    "section": "45.7 Riflessioni Conclusive",
    "text": "45.7 Riflessioni Conclusive\nIn conclusione, la distribuzione a posteriori rappresenta la nostra conoscenza aggiornata sui parametri sconosciuti. L‚Äôimpiego delle statistiche descrittive e l‚Äôanalisi degli intervalli di credibilit√† contribuiscono a tracciare un quadro completo della distribuzione a posteriori e delle nostre inferenze riguardo al parametro di interesse.\nLe stime puntuali, ottenute attraverso statistiche descrittive come media, mediana o moda a posteriori, offrono una singola valutazione numerica del parametro ignoto. Gli intervalli di credibilit√† forniscono un intervallo di valori all‚Äôinterno del quale si ritiene, con un certo grado di probabilit√† soggettiva, che il parametro incognito possa rientrare. Questi intervalli quantificano l‚Äôincertezza associata al parametro e consentono di esprimere il livello di fiducia soggettiva riguardo ai possibili valori del parametro dopo l‚Äôanalisi dei dati. Abbiamo inoltre esaminato il concetto di test di ipotesi bayesiano, il quale pu√≤ essere condotto agevolmente calcolando l‚Äôarea appropriata sotto la distribuzione a posteriori, in accordo con l‚Äôipotesi in questione.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>¬† <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_summary_posterior.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/07_summary_posterior.html#informazioni-sullambiente-di-sviluppo",
    "title": "45¬† Sintesi a posteriori",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: US/Pacific\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.17.0      ggokabeito_0.1.0 see_0.9.0        gridExtra_2.3   \n#&gt;  [5] patchwork_1.3.0  bayesplot_1.11.1 psych_2.4.12     scales_1.3.0    \n#&gt;  [9] markdown_1.13    knitr_1.49       lubridate_1.9.4  forcats_1.0.0   \n#&gt; [13] stringr_1.5.1    dplyr_1.1.4      purrr_1.0.2      readr_2.1.5     \n#&gt; [17] tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0 \n#&gt; [21] rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      shape_1.4.6.1     xfun_0.50         htmlwidgets_1.6.4\n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2      \n#&gt;  [9] generics_0.1.3    parallel_4.4.2    pan_1.9           pacman_0.5.1     \n#&gt; [13] jomo_2.7-6        pkgconfig_2.0.3   Matrix_1.7-1      lifecycle_1.0.4  \n#&gt; [17] compiler_4.4.2    farver_2.1.2      munsell_0.5.1     mnormt_2.1.1     \n#&gt; [21] codetools_0.2-20  htmltools_0.5.8.1 yaml_2.3.10       glmnet_4.1-8     \n#&gt; [25] nloptr_2.1.1      pillar_1.10.1     MASS_7.3-64       iterators_1.0.14 \n#&gt; [29] rpart_4.1.23      boot_1.3-31       foreach_1.5.2     mitml_0.4-5      \n#&gt; [33] nlme_3.1-166      tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4    \n#&gt; [37] labeling_0.4.3    splines_4.4.2     rprojroot_2.0.4   fastmap_1.2.0    \n#&gt; [41] grid_4.4.2        colorspace_2.1-1  cli_3.6.3         magrittr_2.0.3   \n#&gt; [45] survival_3.7-0    broom_1.0.7       withr_3.0.2       backports_1.5.0  \n#&gt; [49] timechange_0.3.0  rmarkdown_2.29    nnet_7.3-19       lme4_1.1-35.5    \n#&gt; [53] hms_1.1.3         evaluate_1.0.1    rlang_1.1.4       Rcpp_1.0.13-1    \n#&gt; [57] glue_1.8.0        minqa_1.2.8       jsonlite_1.8.9    R6_2.5.1",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>¬† <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_summary_posterior.html#bibliografia",
    "href": "chapters/bayesian_inference/07_summary_posterior.html#bibliografia",
    "title": "45¬† Sintesi a posteriori",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nZetsche, U., Buerkner, P.-C., & Renneberg, B. (2019). Future expectations in clinical depression: biased or realistic? Journal of Abnormal Psychology, 128(7), 678‚Äì688.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>¬† <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html",
    "title": "46¬† L‚Äôinfluenza della distribuzione a priori",
    "section": "",
    "text": "46.1 Introduzione\nConsideriamo un semplice scenario medico: un paziente si presenta dal dottore con un mal di testa. Il medico, per formulare una diagnosi accurata, dovr√† considerare diversi fattori. Possiamo immaginare due medici con approcci leggermente differenti:\nQuale dei due medici √® in grado di fornire una diagnosi pi√π precisa? La risposta risiede nel concetto di probabilit√† a priori (o semplicemente prior), ovvero le credenze che un individuo ha su un evento prima di osservare nuovi dati.\nNel contesto medico, la storia clinica del paziente rappresenta una preziosa fonte di informazioni a priori. Conoscere gli antecedenti sanitari di un individuo permette al medico di formulare ipotesi pi√π plausibili sulla causa del mal di testa. In termini bayesiani, i priori agiscono come una sorta di ‚Äúlente‚Äù attraverso cui vengono interpretati i nuovi dati (in questo caso, i risultati dei test).\nQuando prendiamo decisioni nella vita quotidiana, utilizziamo costantemente le nostre conoscenze pregresse per interpretare nuove informazioni. Ad esempio, se vediamo una persona che indossa un camice bianco in un ospedale, inferiamo che si tratti di un medico, basandoci sulla nostra esperienza e sulle associazioni mentali che abbiamo costruito nel tempo. Questo processo di inferenza √® molto simile a quello che avviene nell‚Äôaggiornamento bayesiano.\nLa scelta dei priori ha un impatto fondamentale sulla qualit√† delle inferenze che possiamo trarre dai dati. Questo capitolo si focalizza sull‚Äôimportanza e sulle implicazioni che derivano dalla scelta dei priori sul processo di aggiornamento bayesiano. Per illustrare questi concetti, esamineremo alcuni esempi discussi da Johnson et al. (2022).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>¬† <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#introduzione",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#introduzione",
    "title": "46¬† L‚Äôinfluenza della distribuzione a priori",
    "section": "",
    "text": "Medico 1: Si basa principalmente sui risultati di test specifici, senza considerare una storia clinica pregressa del paziente.\nMedico 2: Oltre ai test, tiene conto della storia clinica del paziente, cercando di individuare eventuali fattori di rischio o condizioni preesistenti che potrebbero essere correlate al mal di testa.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>¬† <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#la-distribuzione-a-priori",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#la-distribuzione-a-priori",
    "title": "46¬† L‚Äôinfluenza della distribuzione a priori",
    "section": "46.2 La Distribuzione a Priori",
    "text": "46.2 La Distribuzione a Priori\nLa distribuzione a priori gioca un ruolo centrale nell‚Äôapproccio bayesiano, poich√© rappresenta le nostre conoscenze pregresse o le ipotesi sui parametri del modello prima di osservare i dati. Questo concetto √® fondamentale perch√© permette di integrare le informazioni disponibili in precedenza con i dati osservati, fornendo cos√¨ una stima pi√π precisa e robusta dei parametri. Le distribuzioni a priori possono variare a seconda del grado di certezza che si attribuisce ai valori dei parametri.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>¬† <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#tipologie-di-distribuzioni-a-priori",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#tipologie-di-distribuzioni-a-priori",
    "title": "46¬† L‚Äôinfluenza della distribuzione a priori",
    "section": "46.3 Tipologie di Distribuzioni a Priori",
    "text": "46.3 Tipologie di Distribuzioni a Priori\nLa scelta della distribuzione a priori (nota come elicitazione della prior) √® uno dei passaggi cruciali nell‚Äôanalisi bayesiana ed √® spesso vista come la fase pi√π controversa, poich√© √® considerata ‚Äúsoggettiva‚Äù. Tuttavia, √® importante sottolineare che la scelta della prior non √® necessariamente soggettiva. A differenza dell‚Äôapproccio frequentista, l‚Äôapproccio bayesiano incoraggia la raccolta e l‚Äôintegrazione di tutte le informazioni conosciute sul parametro in anticipo. Questo pu√≤ essere fatto in modo oggettivo, basandosi su evidenze pregresse o raccomandazioni consolidate.\nEsistono tre principali categorie di distribuzioni a priori.\n\nDistribuzioni a Priori Non Informative. Le distribuzioni a priori non informative sono caratterizzate da una totale mancanza di conoscenza pregressa e assegnano la stessa credibilit√† a tutti i valori dei parametri. Un esempio comune di distribuzione a priori non informativa √® la distribuzione uniforme, basata sul ‚ÄúPrincipio della Ragione Insufficiente‚Äù formulato da Laplace. Secondo questo principio, in assenza di evidenze rilevanti pregresse, tutte le possibili configurazioni dei parametri sono considerate equiprobabili.\nDistribuzioni a Priori Debolmente Informative. Le distribuzioni a priori debolmente informative consentendo di integrare una quantit√† limitata di informazioni pregresse nei modelli statistici. Queste distribuzioni sono progettate per riflettere le nostre assunzioni su quali possono essere i valori ‚Äúragionevoli‚Äù dei parametri del modello, tenendo conto delle incertezze presenti nell‚Äôanalisi. L‚Äôuso di informazioni a priori debolmente informative pu√≤ contribuire a migliorare la stabilit√† dell‚Äôanalisi senza influenzare in modo significativo le conclusioni derivate da essa.\nLe distribuzioni a priori debolmente informative hanno la caratteristica di non ‚Äúspostare‚Äù in modo significativo la distribuzione a posteriori in una direzione specifica. In altre parole, sono centrate su valori ‚Äúneutri‚Äù dei parametri. Ad esempio, quando si trattano parametri che possono assumere valori positivi o negativi, la distribuzione a priori debolmente informativa potrebbe essere centrata sullo zero. Nel caso di parametri che rappresentano proporzioni, essa potrebbe essere centrata su 0.5.\nTuttavia, ci√≤ che rende queste distribuzioni debolmente informative √® la specifica definizione di un intervallo ‚Äúplausibile‚Äù di valori dei parametri. Questo intervallo indica quali valori dei parametri sono considerati plausibili e quali sono invece considerati implausibili. Ad esempio, una distribuzione a priori debolmente informativa potrebbe suggerire che valori estremamente grandi o estremamente bassi dei parametri sono poco plausibili, concentrandosi su un intervallo pi√π stretto di valori considerati ragionevoli.\nIn sintesi, le distribuzioni a priori debolmente informative sono utilizzate per incorporare informazioni pregresse limitate nei modelli bayesiani, contribuendo a stabilizzare le stime dei parametri senza influenzare in modo significativo le conclusioni derivate dai dati. Queste distribuzioni definiscono un intervallo plausibile di valori dei parametri, aiutando a guidare l‚Äôanalisi verso soluzioni pi√π verosimili senza imporre vincoli eccessivi sui risultati.\nDistribuzioni a Priori Informativa. Le conoscenze pregresse, acquisite attraverso ricerche precedenti, pareri esperti o una combinazione di entrambi, possono essere meticolosamente integrate nel processo di analisi mediante l‚Äôincorporazione nelle distribuzioni a priori. Queste distribuzioni sono comunemente conosciute come distribuzioni a priori informative. Esse rappresentano un mezzo per codificare in modo sistematico informazioni concrete e rilevanti che possono avere un notevole impatto sull‚Äôanalisi statistica, fornendo una solida base di conoscenza su cui fondare l‚Äôinferenza bayesiana.\nLe distribuzioni a priori informative possono derivare da una vasta gamma di fonti, comprese ricerche pregresse, pareri di esperti nel campo e altre fonti affidabili. Questo approccio offre un metodo strutturato per integrare in modo coerente le conoscenze pregresse nel processo di analisi statistica. L‚Äôincorporazione di queste informazioni aggiuntive contribuisce notevolmente a migliorare la robustezza e l‚Äôaccuratezza delle conclusioni derivate dai dati, fornendo una solida base empirica su cui basare le stime dei parametri del modello e le decisioni basate sull‚Äôanalisi bayesiana.\nNell‚Äôambito della ricerca psicologica, l‚Äôutilizzo di distribuzioni a priori informative √® attualmente poco diffuso, tuttavia emergono segnali che all‚Äôinterno della comunit√† statistica sta crescendo l‚Äôinteresse per questa pratica, considerandola come un avanzamento promettente nel campo della data science.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>¬† <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#limportanza-della-prior-in-base-ai-dati",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#limportanza-della-prior-in-base-ai-dati",
    "title": "46¬† L‚Äôinfluenza della distribuzione a priori",
    "section": "46.4 L‚Äôimportanza della Prior in base ai Dati",
    "text": "46.4 L‚Äôimportanza della Prior in base ai Dati\nUn aspetto cruciale da considerare √® che l‚Äôinfluenza della prior diminuisce all‚Äôaumentare del numero di dati osservati. In altre parole, con un numero infinito di dati, la verosimiglianza diventa estremamente precisa (o ‚Äúaffilata‚Äù), rendendo la scelta della prior irrilevante, a patto che la prior non assegni probabilit√† zero a regioni dello spazio parametri dove la verosimiglianza √® positiva.\nTuttavia, la prior assume un‚Äôimportanza fondamentale quando si lavora con dataset di piccole dimensioni. In questi casi, la distribuzione a priori pu√≤ avere un‚Äôinfluenza significativa sulle stime, poich√© i dati da soli non sono sufficienti per ottenere stime precise.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>¬† <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#effetti-del-cambiamento-di-scala-dei-parametri",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#effetti-del-cambiamento-di-scala-dei-parametri",
    "title": "46¬† L‚Äôinfluenza della distribuzione a priori",
    "section": "46.5 Effetti del Cambiamento di Scala dei Parametri",
    "text": "46.5 Effetti del Cambiamento di Scala dei Parametri\nUn altro aspetto da tenere a mente √® che le priors possono cambiare quando si modificano le scale dei parametri. Se un parametro viene riscalato, ad esempio passando da metri a chilometri, anche la prior deve essere riscalata di conseguenza per mantenere la coerenza dell‚Äôinferenza.\n\n46.5.1 Scala e invariabilit√† della scelta delle distribuzioni a priori\nLa scelta delle distribuzioni a priori non informative non √® sempre banale e non pu√≤ sempre essere rappresentata da una prior piatta. Per capire questo concetto, √® fondamentale comprendere il ruolo della scala. Vediamo un esempio per chiarire meglio questo aspetto.\nImmaginiamo di avere un dataset che contiene la media dei diametri di alcuni alberi, e vogliamo stimare la media di questi diametri utilizzando un metodo bayesiano. Prima di osservare i dati, dobbiamo specificare la nostra distribuzione a priori, poich√© non vogliamo che i dati influenzino la nostra scelta. Supponiamo di scegliere una distribuzione a priori piatta tra 1 cm e 10 cm, per evitare di introdurre bias:\n\n# Creazione di un vettore da 1 a 5\nvalori &lt;- 1:5\n# Creazione di un vettore di 5 elementi, tutti uguali a 1/5\npesoPrior &lt;- rep(1/5, 5)\n# Mostra i risultati\npesoPrior\n#&gt; [1] 0.2 0.2 0.2 0.2 0.2\n\nIn questo caso, stiamo assegnando la stessa probabilit√† a ciascun diametro compreso tra 1 e 10 cm, senza dare pi√π peso a un valore rispetto a un altro. Questa sembra una scelta ragionevole e ‚Äúnon informativa‚Äù, poich√© non stiamo preferendo nessun diametro in particolare.\nOra, supponiamo di voler modificare leggermente la nostra analisi e di misurare la grandezza degli alberi in termini di area basale (cio√® la sezione trasversale dell‚Äôalbero alla base), che √® proporzionale al quadrato del diametro (cio√® \\(x^2\\)). Poich√© abbiamo gi√† specificato la nostra distribuzione a priori in termini di diametro, dovremmo trasformare questa distribuzione in modo coerente con la nuova scala (area basale).\nIl problema che emerge √® il seguente: quando riscaliamo l‚Äôasse \\(x\\) per riflettere l‚Äôarea basale (cio√®, passiamo da cm a cm\\(^2\\)), i valori pi√π grandi diventano pi√π ampi (poich√© l‚Äôarea cresce con il quadrato del diametro), mentre i valori pi√π piccoli diventano pi√π stretti. Se vogliamo mantenere la stessa distribuzione a priori in termini di probabilit√†, dobbiamo modificare il peso di ciascun valore.\nDi conseguenza, una distribuzione a priori che inizialmente era piatta (uguale per tutti i valori di diametro) non rimane piatta dopo la trasformazione in area basale. I valori pi√π grandi ora hanno un peso minore, mentre i valori pi√π piccoli hanno un peso maggiore. Questo dimostra che una distribuzione a priori non pu√≤ essere piatta per tutte le possibili trasformazioni dei parametri.\n\n\n46.5.2 Il concetto di invariabilit√† della scala\nUna delle chiavi per definire correttamente le distribuzioni a priori non informative √® l‚Äôinvariabilit√† rispetto alle trasformazioni dei parametri. Se possiamo scegliere liberamente come rappresentare i parametri (ad esempio, in termini di diametro o area basale), la nostra distribuzione a priori dovrebbe essere definita in modo che sia coerente indipendentemente dalla scala scelta.\n\n\n46.5.3 Attenzione alle trasformazioni dei parametri\nUn secondo messaggio importante riguarda la cautela nelle trasformazioni dei parametri nell‚Äôanalisi bayesiana. Quando cambiamo i parametri del nostro modello, non stiamo semplicemente osservando un singolo valore, ma una distribuzione intera. La forma di questa distribuzione pu√≤ cambiare notevolmente con la trasformazione dei parametri.\nAd esempio, se si sta conducendo uno studio psicologico e si vuole misurare un parametro legato alla gravit√† di un disturbo (ad esempio, la gravit√† della depressione su una scala numerica), e poi si decide di trasformare la scala in un‚Äôunit√† diversa (ad esempio, un punteggio quadratico per evidenziare differenze estreme), la distribuzione a priori che sembrava ragionevole prima della trasformazione potrebbe non esserlo pi√π dopo. Questo significa che bisogna prestare attenzione a come si scelgono le priors e come queste si comportano sotto diverse rappresentazioni del problema.\nIn conclusione, la scelta delle distribuzioni a priori non pu√≤ essere fatta superficialmente. Deve essere considerata con attenzione, tenendo conto delle possibili trasformazioni dei parametri e assicurandosi che le priors siano coerenti rispetto alla scala scelta. Questo rende evidente che le priors non informative non sono sempre piatte, e la loro scelta deve tenere conto della struttura del problema e delle variabili coinvolte.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>¬† <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#scelte-predefinite-per-le-distribuzioni-a-priori-non-informative",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#scelte-predefinite-per-le-distribuzioni-a-priori-non-informative",
    "title": "46¬† L‚Äôinfluenza della distribuzione a priori",
    "section": "46.6 Scelte predefinite per le distribuzioni a priori non informative",
    "text": "46.6 Scelte predefinite per le distribuzioni a priori non informative\nUna delle domande pi√π ricorrenti nell‚Äôinferenza bayesiana riguarda la scelta delle distribuzioni a priori non informative. La risposta, per√≤, √® piuttosto complessa: non esiste una soluzione generalmente accettata. Questo √® particolarmente importante perch√©, mentre le priors informative possono essere basate su conoscenze pregresse, una prior non informativa deve essere scelta con cura per evitare di influenzare eccessivamente i risultati.\nUna delle proposte pi√π famose, che soddisfa molte delle propriet√† desiderabili, √® la prior di Jeffreys, definita come:\n\\[\np(\\phi) \\propto \\sqrt{ \\det (F(\\phi)) },\n\\]\ndove \\(F(\\phi)\\) √® la matrice di informazione di Fisher, che misura quanto la verosimiglianza cambia quando variano i parametri. La prior di Jeffreys ha due caratteristiche fondamentali:\n\nInvarianza rispetto alla riscalatura dei parametri: Ci√≤ significa che se trasformiamo la scala del parametro, la prior si adatta automaticamente, rimanendo coerente con il problema.\nProporzionalit√† all‚Äôinfluenza dei parametri sulla verosimiglianza: Parametri che influenzano maggiormente la verosimiglianza hanno una prior pi√π informativa.\n\nQuesti aspetti sembrano coprire molti dei criteri comunemente accettati per la scelta delle distribuzioni a priori non informative. Tuttavia, la prior di Jeffreys presenta alcuni problemi nei modelli multivariati e gerarchici, il che limita la sua applicabilit√† come soluzione universale.\n\n46.6.1 Scelte predefinite comuni per le priors non informative\nNonostante le difficolt√† legate alla prior di Jeffreys, sono emerse alcune scelte predefinite comuni per le priors non informative, basate su intuizioni derivanti proprio da questa distribuzione. Di seguito sono elencate alcune di queste scelte:\n\nParametri di scala (es. coefficiente angolare o intercetta in una regressione):\n\nPer i parametri di scala, che influenzano l‚Äôoutput in modo lineare, si utilizzano comunemente priors piatte o quasi piatte. Queste possono essere distribuzioni uniformi con limiti fissati o, pi√π comunemente, una distribuzione normale ampia.\nUn esempio di prior modificata √® l‚Äôuso di una normalit√† centrata su un valore neutro, come 0, per ottenere l‚Äôanalogo bayesiano della regressione Lasso o Ridge, che introduce una penalizzazione sui parametri (Park & Casella, 2008; Kyung et al., 2010).\n\nSe questa penalizzazione √® lieve, si parla di priors debolmente regolarizzanti.\nSe √® forte, si parla di priors di riduzione (shrinkage), che possono essere fisse o adattative:\n\nShrinkage fisso: la forza della riduzione (ad es. controllata dalla deviazione standard nella prior normale) rimane costante.\nShrinkage adattativo: la prior di riduzione si adatta tramite un iperparametro (hyperprior), il che consente al modello di decidere autonomamente la forza della riduzione.\n\n\n\nParametri di varianza (es. la deviazione standard in una regressione lineare):\n\nPer i parametri di varianza, si utilizzano spesso priors che decrescono all‚Äôaumentare del valore. Un esempio classico √® la prior di Jeffrey‚Äôs, che per la varianza assume la forma \\(1/x\\), oppure la distribuzione inversa-gamma, molto comune per via della sua propriet√† di coniugazione, che semplifica il calcolo bayesiano.\n\nIperparametri di varianza nei modelli gerarchici:\n\nNei modelli gerarchici, gli iperparametri di varianza vengono trattati con priors decrescenti come l‚Äôinversa-gamma o la distribuzione half-t (Gelman, 2006). Queste priors sono progettate per gestire la varianza tra gruppi in modo efficace.\n\nDistribuzioni binomiali:\n\nPer una distribuzione binomiale, la prior di Jeffreys corrisponde a una distribuzione Beta(1/2, 1/2), che √® considerata una buona scelta predefinita non informativa. Questo tipo di prior assegna un peso equo alle possibili probabilit√† di successo, riflettendo una distribuzione equilibrata senza favorire un particolare risultato.\n\n\n\n\n46.6.2 Attenzione alle trasformazioni dei parametri\nUn aspetto importante da considerare nell‚Äôuso delle priors non informative √® che la loro forma pu√≤ cambiare significativamente in seguito a trasformazioni dei parametri. Per esempio, passando dalla scala lineare alla scala quadratica di un parametro, la prior pu√≤ assumere una forma diversa e introdurre involontariamente un bias. Pertanto, √® essenziale prestare attenzione a come i parametri sono scalati e trasformati nel modello.\n\n\n46.6.3 Analisi di sensibilit√†\nInfine, quando si √® incerti sulla scelta della prior, un buon approccio consiste nel condurre un‚Äôanalisi di sensibilit√†. Questa tecnica prevede di variare la prior e osservare come ci√≤ influenzi i risultati. Se i risultati sono robusti rispetto a diverse scelte di prior, ci√≤ suggerisce che la prior scelta non sta influenzando in modo eccessivo l‚Äôinferenza finale. Questo √® particolarmente utile nei casi in cui si dispone di pochi dati, situazione in cui la prior pu√≤ avere un impatto maggiore.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>¬† <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#priori-coniugate",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#priori-coniugate",
    "title": "46¬† L‚Äôinfluenza della distribuzione a priori",
    "section": "46.7 Priori coniugate",
    "text": "46.7 Priori coniugate\nUna distribuzione a priori √® detta coniugata rispetto a una funzione di verosimiglianza se la distribuzione a posteriori risultante ha la stessa forma funzionale della distribuzione a priori. In altre parole, la distribuzione a priori e quella a posteriori appartengono alla stessa famiglia di distribuzioni. Questo √® particolarmente utile perch√©, quando si usano priori coniugate, si ottiene una distribuzione a posteriori che pu√≤ essere espressa in forma chiusa, rendendo possibile risolverla analiticamente.\nUn esempio tipico √® quello delle funzioni di verosimiglianza appartenenti alla famiglia esponenziale, per le quali esiste sempre una distribuzione a priori coniugata. Questo √® uno dei motivi per cui le distribuzioni della famiglia esponenziale sono cos√¨ rilevanti: in modelli semplici, l‚Äôuso di una prior coniugata consente di ottenere una soluzione analitica per la distribuzione a posteriori, noto come modello coniugato-esponenziale.\nTradizionalmente, si preferiva specificare priori coniugate quando possibile, proprio per la semplicit√† analitica che garantivano. Tuttavia, l‚Äôimportanza delle priors coniugate √® diminuita con l‚Äôevoluzione dei metodi di campionamento. Oggi, la maggior parte dei campionatori moderni (come i metodi MCMC) non richiede pi√π la coniugazione per funzionare in modo efficiente, e l‚Äôuso di priors non coniugate √® diventato comune senza compromettere la qualit√† delle stime.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>¬† <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#simulazioni",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#simulazioni",
    "title": "46¬† L‚Äôinfluenza della distribuzione a priori",
    "section": "46.8 Simulazioni",
    "text": "46.8 Simulazioni\nIn questa sezione, esploriamo come le distribuzioni a priori influenzano la distribuzione a posteriori attraverso una serie di simulazioni. La formula di Bayes, \\(p(\\theta \\mid y) \\propto p(\\theta) \\times p(y \\mid \\theta)\\), evidenzia come la distribuzione a posteriori sia il risultato della combinazione tra la distribuzione a priori e la funzione di verosimiglianza basata sui dati osservati. Se abbiamo le valutazioni puntuali della verosimiglianza e della distribuzione a priori, possiamo moltiplicarle punto per punto per ottenere la distribuzione a posteriori.\n\n46.8.1 Verosimiglianza Binomiale con Distribuzioni a Priori Arbitrari\nConsideriamo un caso in cui la verosimiglianza √® binomiale, ma utilizziamo distribuzioni a priori non coniugate. Supponiamo che i dati consistano in 6 successi su 9 prove di tipo bernoulliano. Confronteremo l‚Äôeffetto di tre distribuzioni a priori diverse sulla distribuzione a posteriori e analizzeremo come ciascuna influisce sull‚Äôinferenza finale.\n\n46.8.1.1 Creazione della Griglia e Calcolo della Verosimiglianza\nIniziamo definendo una griglia di valori per \\(\\theta\\) e calcolando la verosimiglianza a ciascun punto della griglia.\n\n# Dati\nsuccess &lt;- 6\ntosses &lt;- 9\n\n# Griglia di valori per theta\ngrid_points &lt;- 100\np_grid &lt;- seq(0, 1, length.out = grid_points)\n\n# Verosimiglianza binomiale\nlikelihood &lt;- dbinom(success, tosses, p_grid)\n\n\n\n46.8.1.2 Funzione per Calcolare e Visualizzare la Posteriori\nDefiniamo una funzione che calcola la distribuzione a posteriori in base alla verosimiglianza e al priore fornito. La funzione visualizza anche il priore, la verosimiglianza e la distribuzione a posteriori.\n\ncomputePosterior &lt;- function(likelihood, prior, p_grid) {\n  # Calcolo della distribuzione a posteriori non normalizzata\n  unstd_posterior &lt;- likelihood * prior\n  \n  # Normalizzazione\n  posterior &lt;- unstd_posterior / sum(unstd_posterior)\n  \n  # Visualizzazione\n  par(mfrow = c(1, 3))\n  plot(\n    p_grid, \n    prior, \n    type = \"l\", \n    main = \"Prior\", \n    xlab = expression(theta), \n    ylab = \"Densit√†\"\n  )\n  plot(\n    p_grid, \n    likelihood, \n    type = \"l\", \n    main = \"Likelihood\", \n    xlab = expression(theta), \n    ylab = \"Densit√†\"\n  )\n  plot(\n    p_grid, \n    posterior, \n    type = \"l\", \n    main = \"Posterior\", \n    xlab = expression(theta), \n    ylab = \"Densit√†\"\n  )\n  \n  return(posterior)\n}\n\n\n\n\n\n46.8.2 Esempio 1: Priore Uniforme\nIl nostro primo priore √® una distribuzione uniforme: \\(p(\\theta) = 1\\). Questo riflette una completa mancanza di informazioni a priori sulla probabilit√† di successo \\(\\theta\\).\n\n# Priore uniforme\nprior1 &lt;- rep(1, grid_points)\n\n# Calcolo e visualizzazione della distribuzione a posteriori\nposterior1 &lt;- computePosterior(likelihood, prior1, p_grid)\n\n\n\n\n\n\n\n\nCome previsto, la distribuzione a posteriori coincide con la verosimiglianza (a parte un fattore di scala), poich√© non abbiamo aggiunto informazioni.\n\n\n\n46.8.3 Esempio 2: Priore a Gradino\nIl secondo priore √® una funzione a gradino che riflette la convinzione che \\(\\theta\\) sia almeno \\(0.5\\). Questo priore esprime la credenza che il successo (‚Äútesta‚Äù) sia pi√π probabile, ma non specifica di quanto.\n\n# Priore a gradino\nprior2 &lt;- ifelse(p_grid &gt;= 0.5, 1, 0)\n\n# Calcolo e visualizzazione della distribuzione a posteriori\nposterior2 &lt;- computePosterior(likelihood, prior2, p_grid)\n\n\n\n\n\n\n\n\nLa distribuzione a posteriori risultante esclude completamente i valori di \\(\\theta\\) inferiori a 0.5, coerentemente con le ipotesi del priore.\n\n\n\n46.8.4 Esempio 3: Priore Esponenziale\nIl terzo priore √® una distribuzione centrata su 0.5, con un rapido decadimento esponenziale su entrambi i lati. Questo priore riflette la convinzione che \\(\\theta\\) sia vicina a 0.5.\n\n# Priore esponenziale\nprior3 &lt;- exp(-5 * abs(p_grid - 0.5))\n\n# Calcolo e visualizzazione della distribuzione a posteriori\nposterior3 &lt;- computePosterior(likelihood, prior3, p_grid)\n\n\n\n\n\n\n\n\nQuesto priore ‚Äúattrare‚Äù la distribuzione a posteriori verso 0.5, a meno che i dati non forniscano evidenze contrarie molto forti.\n\n\n\n46.8.5 Analisi del Modello Beta-Binomiale\nConsideriamo ora il caso coniugato, in cui il priore √® una distribuzione Beta e i dati seguono una distribuzione Binomiale.\nDefiniamo una funzione per visualizzare le distribuzioni del modello Beta-Binomiale: priore, verosimiglianza e posteriore.\n\nplot_beta_binomial &lt;- function(alpha, beta, y = NULL, n = NULL) {\n  # Griglia di valori per theta\n  theta &lt;- seq(0, 1, length.out = 100)\n  \n  # Priore\n  prior_density &lt;- dbeta(theta, alpha, beta)\n  \n  # Verosimiglianza scalata\n  if (!is.null(y) && !is.null(n)) {\n    likelihood &lt;- dbinom(y, n, theta)\n    scaled_likelihood &lt;- likelihood / max(likelihood)\n    posterior_alpha &lt;- alpha + y\n    posterior_beta &lt;- beta + n - y\n    posterior_density &lt;- dbeta(theta, posterior_alpha, posterior_beta)\n  }\n  \n  # Grafico\n  plot(\n    theta, \n    prior_density, \n    type = \"l\", \n    col = \"blue\", \n    ylim = c(0, max(prior_density, posterior_density)), \n    main = \"Beta-Binomial Model\", \n    xlab = expression(theta), \n    ylab = \"Density\"\n  )\n  if (!is.null(y) && !is.null(n)) {\n    lines(theta, scaled_likelihood, col = \"orange\", lwd = 2)\n    lines(theta, posterior_density, col = \"green\", lwd = 2)\n    legend(\n      \"topright\", \n      legend = c(\"Prior\", \"Likelihood (scaled)\", \"Posterior\"), \n      col = c(\"blue\", \"orange\", \"green\"), \n      lty = 1, \n      bty = \"n\")\n  }\n}\n\n\n46.8.5.1 Priore Uniforme\n\nplot_beta_binomial(alpha = 1, beta = 1, y = 15, n = 20)\n\n\n\n\n\n\n\n\n\n\n46.8.5.2 Priore Informativo (Beta(2, 2))\n\nplot_beta_binomial(alpha = 2, beta = 2, y = 15, n = 20)\n\n\n\n\n\n\n\n\n\n\n46.8.5.3 Priore Fortemente Informativo (Beta(2, 5))\n\nplot_beta_binomial(alpha = 2, beta = 5, y = 15, n = 20)\n\n\n\n\n\n\n\n\nIn conclusione, abbiamo esplorato come i priori influenzano la distribuzione a posteriori in contesti binomiali, dimostrando che l‚Äôinfluenza del priore √® maggiore nei campioni piccoli e diminuisce con campioni di grandi dimensioni. L‚Äôanalisi bayesiana consente un‚Äôintegrazione flessibile delle conoscenze pregresse con i dati osservati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>¬† <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#connessione-tra-intuizioni-e-teoria",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#connessione-tra-intuizioni-e-teoria",
    "title": "46¬† L‚Äôinfluenza della distribuzione a priori",
    "section": "46.9 Connessione tra Intuizioni e Teoria",
    "text": "46.9 Connessione tra Intuizioni e Teoria\nL‚Äôequilibrio tra la distribuzione a priori e le evidenze provenienti dai dati, come dimostrato negli esempi precedenti, non solo rispecchia le nostre intuizioni, ma rappresenta anche una necessit√† matematica. Questo concetto diventa chiaro esaminando la formula del valore atteso della distribuzione a posteriori nel contesto del caso beta-binomiale, che pu√≤ essere riscritta come segue:\n\\[\n\\begin{align}\n\\mathbb{E}_{\\text{post}} &[\\text{Beta}(\\alpha + y, \\beta + n - y)] = \\frac{\\alpha + y}{\\alpha + \\beta + n} \\\\\n&= \\frac{a+b}{a+b+n} \\cdot \\frac{a}{a+b} + \\frac{n}{a+b+n} \\cdot \\frac{y}{n}.\n\\end{align}\n\\]\nL‚Äôequazione precedente rivela che il valore atteso a posteriori si ottiene come una media ponderata tra il valore atteso a priori \\(\\left( \\frac{\\alpha}{\\alpha+\\beta}\\right)\\) e la proporzione osservata dei successi \\(\\left(\\frac{y}{n}\\right)\\). I pesi sono dati da \\(\\left( \\frac{\\alpha+\\beta}{\\alpha+\\beta+n}\\right)\\) e \\(\\left( \\frac{n}{\\alpha+\\beta+n}\\right)\\). Pertanto, quando il numero di osservazioni \\(n\\) √® significativo rispetto alla somma dei parametri \\(\\alpha + \\beta\\), la distribuzione a posteriori sar√† principalmente influenzata dai dati osservati e in minor misura dalle credenze a priori. Al contrario, se \\(n\\) √® piccolo rispetto a \\(\\alpha + \\beta\\), i dati avranno un peso inferiore rispetto alle credenze a priori.\nQueste considerazioni indicano come scegliere i parametri \\(\\alpha\\) e \\(\\beta\\): se desideriamo rappresentare una totale ignoranza sul fenomeno, una scelta coerente √® \\(\\alpha = \\beta = 1\\) (attribuiamo uguale credibilit√† a ogni valore di \\(\\theta\\)). Se, invece, possediamo forti credenze a priori, possiamo selezionare \\(\\alpha\\) in modo da eguagliare il valore atteso a priori, mentre \\(\\alpha + \\beta\\) rifletter√† l‚Äôimportanza attribuita all‚Äôinformazione a priori: maggiore √® il valore di \\(\\alpha + \\beta\\), maggiore sar√† il numero di dati necessari per influenzare significativamente la distribuzione a posteriori rispetto a quella a priori. In situazioni in cui \\(n\\) √® considerevolmente grande, la distribuzione a posteriori avr√† un impatto ridotto sulla distribuzione a priori, a meno che non si facciano scelte estreme per i parametri a priori.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>¬† <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#conflitto-tra-prior-e-verosimiglianza",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#conflitto-tra-prior-e-verosimiglianza",
    "title": "46¬† L‚Äôinfluenza della distribuzione a priori",
    "section": "46.10 Conflitto tra Prior e Verosimiglianza",
    "text": "46.10 Conflitto tra Prior e Verosimiglianza\nEsaminiamo ora un altro esempio proposto da McElreath:\n\nLesson: Don‚Äôt trust intuition, for even simple prior+likelihood scenarios defy it. Four examples below, each producing radically different posteriors. Can you guess what each does?\n\n\nNella figura successiva vediamo la risposta alla domanda precedente.\n\nMcElreath descrive le caratteristiche di quattro diversi modelli in cui si combinano distribuzioni normali (Gaussiane) e Student-t (con 2 gradi di libert√†) per il prior e la likelihood. La distribuzione gaussiana ha code molto sottili, mentre quella di Student-t ha code pi√π spesse.\n\nIn Alto a Sinistra: Prior Normale, Likelihood Normale\n\ny ~ Normal(mu,1)\nmu ~ Normal(10,1)\n\nIn questo scenario classico di aggiornamento bayesiano, il posterior risulta essere un compromesso tra il prior e la likelihood. La distribuzione normale, con le sue code sottili, contribuisce a un aggiornamento pi√π ‚Äúprevedibile‚Äù e concentrato attorno al valore medio.\nIn Alto a Destra: Prior Student, Likelihood Student (df=2)\n\ny ~ Student(2,mu,1)\nmu ~ Student(2,10,1)\n\nIn questo caso, entrambe le distribuzioni hanno code pi√π spesse. La presenza di ‚Äúextra massa‚Äù nelle code significa che ciascuna distribuzione trova il modo dell‚Äôaltra pi√π plausibile, portando a una media che non rappresenta il miglior ‚Äúcompromesso‚Äù. Questo scenario risulta in una maggiore incertezza e un posterior meno definito.\nIn Basso a Sinistra: Prior Student, Likelihood Normale\n\ny ~ Normal(mu,1)\nmu ~ Student(2,10,1)\n\nQui, la likelihood normale, con le sue code sottili, tende a dominare. Essa √® molto scettica nei confronti del prior con code spesse, ma il prior di Student-t non √® sorpreso dalla likelihood. Questo porta a un posterior che √® pi√π influenzato dalla likelihood normale.\nIn Basso a Destra: Prior Normale, Likelihood Student\n\ny ~ Student(2,mu,1)\nmu ~ Normal(10,1)\n\nIn questo ultimo scenario, √® il prior normale a dominare. Il ragionamento √® simile a quello del caso precedente, ma in senso inverso. Il prior normale, con le sue code sottili, impone una maggiore influenza sul posterior, rendendolo meno influenzato dalle code pi√π spesse della likelihood di Student-t.\n\nIn sintesi, la combinazione di queste due distribuzioni in diversi modi porta a risultati di aggiornamento bayesiano molto differenti, a seconda di quale tra prior e likelihood abbia le code pi√π spesse e quindi eserciti una maggiore influenza sul posterior.\nIn conclusione, questo esercizio mostra come, ad eccezione del caso gaussiano, i risultati non sono affatto intuitivi. Pertanto, in contesti come questi, affidarsi esclusivamente alle proprie intuizioni non √® una scelta consigliabile. √à invece fondamentale procedere con l‚Äôesecuzione dei calcoli.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>¬† <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#riflessioni-conclusive",
    "title": "46¬† L‚Äôinfluenza della distribuzione a priori",
    "section": "46.11 Riflessioni Conclusive",
    "text": "46.11 Riflessioni Conclusive\nLa scelta della distribuzione a priori √® uno degli aspetti pi√π cruciali nell‚Äôinferenza bayesiana. Da un lato, le priors non informative possono essere utilizzate per minimizzare l‚Äôinfluenza delle conoscenze pregresse, permettendo ai dati osservati di guidare l‚Äôinferenza. Dall‚Äôaltro, le priors informative sono estremamente utili quando si dispone di informazioni affidabili sui parametri, consentendo una stima pi√π precisa. √à importante ricordare che, con un gran numero di dati, l‚Äôinfluenza della prior tende a ridursi, mentre nei contesti con pochi dati la scelta della prior pu√≤ avere un impatto significativo.\nUn aspetto essenziale dell‚Äôapproccio bayesiano, come evidenziato nell‚Äôesempio di Johnson (2022), √® che il processo di aggiornamento bayesiano riflette il modo in cui le persone ragionano intuitivamente: di fronte a evidenze deboli, le credenze rimangono stabili, mentre nuove informazioni robuste portano a un aggiornamento significativo delle credenze. Questo meccanismo formalizza in modo quantitativo e rigoroso le intuizioni che utilizziamo quotidianamente. Al contrario, l‚Äôapproccio frequentista ignora le conoscenze pregresse, il che pu√≤ portare a cambiamenti nelle inferenze senza tener conto delle credenze gi√† esistenti.\nTuttavia, come evidenziato dagli esempi di McElreath, la situazione pu√≤ essere pi√π complessa nei modelli non coniugati, dove l‚Äôintuizione pu√≤ fallire nel prevedere correttamente la distribuzione a posteriori. Questo ci ricorda che il contesto e la struttura del modello giocano un ruolo determinante nell‚Äôinferenza bayesiana.\n\n46.11.1 Il Ruolo della Prior nella Regolarizzazione\nNel contesto bayesiano, le distribuzioni a priori debolmente informative fungono da meccanismo di regolarizzazione, limitando l‚Äôinfluenza delle osservazioni estreme e garantendo inferenze pi√π stabili. Questo approccio √® ormai ampiamente accettato nella comunit√† statistica, poich√© permette di ottenere risultati pi√π prudenti senza introdurre un forte bias.\n\n\n46.11.2 L‚ÄôImportanza dei Prior Informativi\nNegli ultimi anni, l‚Äôuso di priori informativi ha guadagnato maggiore attenzione, soprattutto grazie all‚Äôintegrazione delle conoscenze esperte nel processo inferenziale. Questa pratica, nota come elicitazione della conoscenza esperta, richiede un rigoroso approccio metodologico per evitare bias cognitivi e assicurare che le informazioni pregresse siano incorporate in modo accurato. Questo √® particolarmente rilevante in campi come la psicologia, dove spesso la base teorica √® incerta, e l‚Äôelicitazione esperta pu√≤ contribuire a migliorare la solidit√† delle analisi bayesiane (O‚ÄôHagan, 2019).\n\n\n46.11.3 Conclusioni Finali\nIn conclusione, la scelta delle prior deve essere ponderata attentamente in base alla disponibilit√† di dati e al contesto dell‚Äôanalisi. Sebbene l‚Äôuso di priors non informative possa sembrare una scelta ‚Äúneutra‚Äù, √® spesso sub-ottimale. Le priors debolmente informative rappresentano lo standard attuale, poich√© favoriscono un‚Äôinferenza pi√π robusta grazie alla loro capacit√† di regolarizzare l‚Äôinfluenza dei dati. Infine, l‚Äôuso di priori informativi, sviluppati attraverso protocolli rigorosi di elicitazione esperta, √® una frontiera in crescita nell‚Äôanalisi bayesiana, poich√© consente di sfruttare al meglio le conoscenze pregresse per migliorare la qualit√† delle inferenze e ridurre l‚Äôincertezza.\nQuesto approccio, che bilancia conoscenza pregressa e nuovi dati, permette di sviluppare modelli bayesiani pi√π solidi e informati, riflettendo accuratamente sia l‚Äôincertezza sia la competenza specifica del dominio di studio.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>¬† <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#informazioni-sullambiente-di-sviluppo",
    "title": "46¬† L‚Äôinfluenza della distribuzione a priori",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: US/Pacific\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.17.0      ggokabeito_0.1.0 see_0.9.0        gridExtra_2.3   \n#&gt;  [5] patchwork_1.3.0  bayesplot_1.11.1 psych_2.4.12     scales_1.3.0    \n#&gt;  [9] markdown_1.13    knitr_1.49       lubridate_1.9.4  forcats_1.0.0   \n#&gt; [13] stringr_1.5.1    dplyr_1.1.4      purrr_1.0.2      readr_2.1.5     \n#&gt; [17] tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0 \n#&gt; [21] rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      shape_1.4.6.1     xfun_0.50         htmlwidgets_1.6.4\n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2      \n#&gt;  [9] generics_0.1.3    parallel_4.4.2    pan_1.9           pacman_0.5.1     \n#&gt; [13] jomo_2.7-6        pkgconfig_2.0.3   Matrix_1.7-1      lifecycle_1.0.4  \n#&gt; [17] compiler_4.4.2    farver_2.1.2      munsell_0.5.1     mnormt_2.1.1     \n#&gt; [21] codetools_0.2-20  htmltools_0.5.8.1 yaml_2.3.10       glmnet_4.1-8     \n#&gt; [25] nloptr_2.1.1      pillar_1.10.1     MASS_7.3-64       iterators_1.0.14 \n#&gt; [29] rpart_4.1.23      boot_1.3-31       foreach_1.5.2     mitml_0.4-5      \n#&gt; [33] nlme_3.1-166      tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4    \n#&gt; [37] splines_4.4.2     rprojroot_2.0.4   fastmap_1.2.0     grid_4.4.2       \n#&gt; [41] colorspace_2.1-1  cli_3.6.3         magrittr_2.0.3    survival_3.7-0   \n#&gt; [45] broom_1.0.7       withr_3.0.2       backports_1.5.0   timechange_0.3.0 \n#&gt; [49] rmarkdown_2.29    nnet_7.3-19       lme4_1.1-35.5     hms_1.1.3        \n#&gt; [53] evaluate_1.0.1    rlang_1.1.4       Rcpp_1.0.13-1     glue_1.8.0       \n#&gt; [57] minqa_1.2.8       jsonlite_1.8.9    R6_2.5.1",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>¬† <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#bibliografia",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#bibliografia",
    "title": "46¬† L‚Äôinfluenza della distribuzione a priori",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A. (2006). Prior distributions for variance parameters in hierarchical models (comment on article by Browne and Draper). Bayesian Analysis, 1(3), 515‚Äì534. https://doi.org/10.1214/06-BA117A\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nO‚ÄôHagan, A. (2019). Expert knowledge elicitation: subjective but scientific. The American Statistician, 73(sup1), 69‚Äì81.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>¬† <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_gamma_poisson_model.html",
    "href": "chapters/bayesian_inference/09_gamma_poisson_model.html",
    "title": "47¬† Modello coniugato Gamma-Poisson üî∏",
    "section": "",
    "text": "47.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nPreparazione del Notebook\nIn psicologia, le variabili di conteggio (\\(y\\)), che indicano il numero di occorrenze di un evento, trovano ampio impiego in diversi ambiti. Ad esempio, sono usate per quantificare la frequenza dei sintomi di un disturbo o per analizzare le frequenze delle parole negli studi di psicolinguistica. Queste variabili, assumendo valori discreti, richiedono modelli statistici specifici.\nQuesto capitolo si focalizza sulla stima del tasso medio di incidenza (\\(\\lambda_i\\)) di tali eventi, ovvero sul numero medio di occorrenze per unit√† di misura. Adotteremo un approccio bayesiano, utilizzando il modello di Poisson per descrivere la distribuzione di probabilit√† delle variabili di conteggio. In particolare, esploreremo la derivazione analitica della distribuzione a posteriori del parametro \\(\\lambda_i\\), considerando una distribuzione a priori Gamma. Successivamente, verificheremo la validit√† dei risultati analitici mediante simulazioni Monte Carlo.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>¬† <span class='chapter-title'>Modello coniugato Gamma-Poisson üî∏</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_gamma_poisson_model.html#distribuzione-di-poisson",
    "href": "chapters/bayesian_inference/09_gamma_poisson_model.html#distribuzione-di-poisson",
    "title": "47¬† Modello coniugato Gamma-Poisson üî∏",
    "section": "47.2 Distribuzione di Poisson",
    "text": "47.2 Distribuzione di Poisson\nLa distribuzione di Poisson √® un modello probabilistico utilizzato per descrivere il numero di eventi che si verificano in un intervallo di tempo o spazio fisso, partendo dall‚Äôassunto che tali eventi si verifichino con una frequenza media costante e in modo indipendente rispetto al tempo trascorso dall‚Äôultimo evento. Se un dato \\(y\\) segue una distribuzione di Poisson con parametro \\(\\lambda\\), allora la probabilit√† di osservare un singolo valore \\(y_i\\) √® data da:\n\\[\nf(y_i \\mid \\lambda) = \\frac{e^{-\\lambda} \\lambda^{y_i}}{y_i!},\n\\]\ndove \\(\\lambda &gt; 0\\) rappresenta la frequenza media di occorrenza degli eventi e \\(y_i\\) √® il numero di eventi osservati. La distribuzione di Poisson ha la caratteristica che sia il valore atteso che la varianza di una variabile casuale \\(Y\\) che segue questa distribuzione sono pari a \\(\\lambda\\), cio√® \\(E(Y) = \\lambda\\) e \\(\\text{Var}(Y) = \\lambda\\).\n\n47.2.1 Simulazione\nPer capire meglio come funziona la distribuzione di Poisson, immaginiamo un paziente con un disturbo ossessivo-compulsivo. Supponiamo che in media questo paziente ripeta un‚Äôazione compulsiva 2 volte ogni ora. In questo caso, il parametro della distribuzione di Poisson √® Œª = 2.\nLa probabilit√† di osservare esattamente \\(k\\) eventi in un‚Äôora √® calcolata dalla formula:\n\\[\nf(k | \\lambda) = \\frac{e^{-\\lambda} \\lambda^k}{k!}.\n\\]\nNel caso specifico con \\(\\lambda = 2\\), le probabilit√† per i primi valori di \\(k\\) sono:\n\nLa probabilit√† di osservare 0 eventi in un‚Äôora √® \\(\\frac{e^{-2} \\cdot 2^0}{0!} = e^{-2} \\approx 0{.}1353\\).\nLa probabilit√† di osservare 1 evento in un‚Äôora √® \\(\\frac{e^{-2} \\cdot 2^1}{1!} = 2e^{-2} \\approx 0{.}2707\\).\nLa probabilit√† di osservare 2 eventi in un‚Äôora √® \\(\\frac{e^{-2} \\cdot 2^2}{2!} = 2e^{-2} \\approx 0{.}2707\\).\nE cos√¨ via per \\(k = 3\\), \\(k = 4\\), \\(\\dots\\)\n\nQuesto esempio illustra come la distribuzione di Poisson possa essere utilizzata per modellare il numero di eventi rari che si verificano in un intervallo temporale fisso, con una frequenza media nota.\nSvolgiamo ora i calcoli utilizzando la funzione dpois in R:\n\nlam_true &lt;- 2\n# Creazione di un vettore di valori da 0 a 9\nk_values &lt;- 0:9\n\n# Calcolo delle probabilit√† per ogni valore in k_values\nprobabilities &lt;- dpois(k_values, lambda = lam_true)\n\n# Stampa delle probabilit√†\nfor (i in seq_along(k_values)) {\n  cat(sprintf(\"Probabilit√† di %d eventi: %.4f\\n\", k_values[i], probabilities[i]))\n}\n#&gt; Probabilit√† di 0 eventi: 0.1353\n#&gt; Probabilit√† di 1 eventi: 0.2707\n#&gt; Probabilit√† di 2 eventi: 0.2707\n#&gt; Probabilit√† di 3 eventi: 0.1804\n#&gt; Probabilit√† di 4 eventi: 0.0902\n#&gt; Probabilit√† di 5 eventi: 0.0361\n#&gt; Probabilit√† di 6 eventi: 0.0120\n#&gt; Probabilit√† di 7 eventi: 0.0034\n#&gt; Probabilit√† di 8 eventi: 0.0009\n#&gt; Probabilit√† di 9 eventi: 0.0002\n\n\n\n47.2.2 Creazione del grafico della funzione di massa di probabilit√†\nIl seguente codice R genera il grafico della funzione di massa di probabilit√† (PMF) di una distribuzione di Poisson con parametro \\(\\lambda = 2\\):\n\n# Definiamo il parametro lambda\nlambd &lt;- 2\n\n# Generiamo i valori sull'asse x (numero di eventi)\nx &lt;- 0:9  # Possiamo aumentare o diminuire il range a seconda delle esigenze\n\n# Calcoliamo le probabilit√† corrispondenti utilizzando la funzione dpois\ny &lt;- dpois(x, lambda = lambd)\n\n# Creiamo il grafico a barre\nbarplot(\n  height = y,\n  names.arg = x,\n  col = \"lightblue\",\n  xlab = \"Numero di eventi\",\n  ylab = \"Probabilit√†\",\n  main = \"Distribuzione di Poisson (Œª = 2)\"\n)",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>¬† <span class='chapter-title'>Modello coniugato Gamma-Poisson üî∏</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_gamma_poisson_model.html#verosimiglianza-per-un-campione-di-osservazioni",
    "href": "chapters/bayesian_inference/09_gamma_poisson_model.html#verosimiglianza-per-un-campione-di-osservazioni",
    "title": "47¬† Modello coniugato Gamma-Poisson üî∏",
    "section": "47.3 Verosimiglianza per un Campione di Osservazioni",
    "text": "47.3 Verosimiglianza per un Campione di Osservazioni\nConsideriamo un campione di \\(n\\) osservazioni indipendenti e identicamente distribuite, \\(y_1, y_2, \\dots, y_n\\), tratto da una distribuzione di Poisson con parametro \\(\\lambda\\). La funzione di verosimiglianza \\(f(y \\mid \\lambda)\\) rappresenta la probabilit√† congiunta di osservare esattamente questi valori dato un particolare valore di \\(\\lambda\\).\nMatematicamente, la verosimiglianza si esprime come:\n\\[\nf(y \\mid \\lambda) = \\prod_{i=1}^{n} \\frac{e^{-\\lambda} \\lambda^{y_i}}{y_i!}\n= \\frac{e^{-n\\lambda} \\lambda^{\\sum_{i=1}^n y_i}}{\\prod_{i=1}^{n} y_i!}.\n\\]\nQuesta funzione misura la compatibilit√† tra i dati osservati e un dato valore di \\(\\lambda\\). Valori di \\(\\lambda\\) che rendono pi√π alta la verosimiglianza sono quelli che meglio spiegano i dati osservati.\nLa funzione di verosimiglianza descrive quanto sia plausibile un valore specifico di \\(\\lambda\\) dato il campione di dati osservati \\(y_1, y_2, \\dots, y_n\\). Per ogni possibile valore di \\(\\lambda\\), la funzione fornisce una misura della compatibilit√† tra il valore ipotizzato e i dati. In altre parole, essa risponde alla domanda: quanto bene questo valore di \\(\\lambda\\) spiega i dati osservati?\nPer semplificare i calcoli ed evitare problemi di overflow numerico, √® comune utilizzare il logaritmo naturale della funzione di verosimiglianza, chiamato log-verosimiglianza. La log-verosimiglianza per il modello di Poisson si ottiene come:\n\\[\n\\log f(y \\mid \\lambda) = -n\\lambda + \\left(\\sum_{i=1}^n y_i \\right) \\log \\lambda - \\sum_{i=1}^n \\log(y_i!).\n\\]\nL‚Äôuso del logaritmo trasforma il prodotto nella somma, facilitando le analisi e la stima dei parametri.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>¬† <span class='chapter-title'>Modello coniugato Gamma-Poisson üî∏</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_gamma_poisson_model.html#distribuzione-gamma",
    "href": "chapters/bayesian_inference/09_gamma_poisson_model.html#distribuzione-gamma",
    "title": "47¬† Modello coniugato Gamma-Poisson üî∏",
    "section": "47.4 Distribuzione Gamma",
    "text": "47.4 Distribuzione Gamma\nLa distribuzione Gamma riveste un ruolo centrale nel modello coniugato Gamma-Poisson, poich√© funge da distribuzione a priori per il parametro di tasso \\(\\lambda\\) della distribuzione di Poisson. La sua scelta √® motivata dalla propriet√† di coniugatezza, che consente di ottenere una distribuzione a posteriori appartenente alla stessa famiglia della prior, semplificando significativamente i calcoli inferenziali e aggiornando in modo diretto le credenze alla luce dei dati osservati.\nLa funzione di densit√† della distribuzione Gamma √® definita come:\n\\[\nf(x \\mid \\alpha, \\beta) = \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)} x^{\\alpha - 1} e^{-\\beta x},\n\\]\ndove:\n\n\\(\\alpha\\) (detto parametro di forma) determina la forma della distribuzione: valori pi√π elevati di \\(\\alpha\\) tendono a rendere la distribuzione pi√π simmetrica;\n\\(\\beta\\) (detto parametro di tasso o scala inversa) controlla la scala: valori pi√π elevati di \\(\\beta\\) concentrano maggiormente la massa di probabilit√† vicino all‚Äôorigine.\n\nAd esempio:\n\nUna distribuzione Gamma con \\(\\alpha = 2\\) e \\(\\beta = 3\\) rappresenta un processo in cui eventi relativamente rari si verificano occasionalmente.\nUna distribuzione Gamma con \\(\\alpha = 10\\) e \\(\\beta = 1\\) descrive un processo pi√π regolare, con eventi che si verificano con maggiore frequenza e prevedibilit√†.\n\n\n\n\n\n\n\nIn R, la parametrizzazione della distribuzione Gamma utilizza direttamente il parametro \\(\\beta\\) come tasso (\\(rate\\)), che √® l‚Äôinverso del parametro di scala (\\(scale = 1 / \\beta\\)) utilizzato in Scipy.\n\n\n\nPer calcolare la densit√† di probabilit√† in R, si utilizza:\ndgamma(x, shape = alpha, rate = beta)\n\n# Definizione dei parametri\nalpha &lt;- 2\nbeta &lt;- 3\n\n# Generazione dei valori di x\nx &lt;- seq(0, 3, length.out = 500)\n\n# Calcolo della densit√† di probabilit√†\npdf &lt;- dgamma(x, shape = alpha, rate = beta)\n\n# Creazione del grafico\nplot(\n  x, pdf,\n  type = \"l\",\n  col = \"blue\",\n  lwd = 2,\n  xlab = \"x\",\n  ylab = \"Densit√† di probabilit√†\",\n  main = expression(\"Distribuzione Gamma (\" ~ alpha == 2 ~ \",\" ~ beta == 3 ~ \")\")\n)\ngrid()\n\n\n\n\n\n\n\n\nQuesto grafico mostra la densit√† di una distribuzione Gamma con \\(\\alpha = 2\\) e \\(\\beta = 3\\), calcolata su un intervallo \\([0, 3]\\).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>¬† <span class='chapter-title'>Modello coniugato Gamma-Poisson üî∏</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_gamma_poisson_model.html#metodo-basato-su-griglia",
    "href": "chapters/bayesian_inference/09_gamma_poisson_model.html#metodo-basato-su-griglia",
    "title": "47¬† Modello coniugato Gamma-Poisson üî∏",
    "section": "47.5 Metodo Basato su Griglia",
    "text": "47.5 Metodo Basato su Griglia\nSupponiamo di voler calcolare la distribuzione a posteriori del parametro \\(\\lambda\\) di un modello di Poisson, con una distribuzione a priori Gamma. Utilizziamo un approccio numerico basato sulla discretizzazione dello spazio dei parametri.\nConsideriamo i seguenti dati osservati:\n\n# Dati osservati\ny &lt;- c(2, 1, 3, 2, 2, 1, 1, 1)\n\nAdotteremo questa distribuzione a priori:\n\n# Parametri della distribuzione a priori Gamma\nalpha_prior &lt;- 9\nbeta_prior &lt;- 2\n\n# Griglia dei valori di lambda\nlambda_grid &lt;- seq(0.01, 10, length.out = 1000)\n\n# Calcolo della densit√† della distribuzione a priori\nprior &lt;- dgamma(lambda_grid, shape = alpha_prior, rate = beta_prior)\n\n# Plot della distribuzione a priori\nplot(\n  lambda_grid, prior, type = \"l\", col = \"blue\",\n  xlab = expression(lambda),\n  ylab = \"Densit√† di probabilit√†\",\n  main = \"Distribuzione Gamma a Priori\"\n)\nabline(v = alpha_prior / beta_prior, col = \"red\", lty = 2, lwd = 2)\nabline(v = mean(y), col = \"green\", lty = 2, lwd = 2)\nlegend(\"topright\", legend = c(\"Media Gamma\", \"Media Campionaria\"),\n       col = c(\"red\", \"green\"), lty = 2, lwd = 2)\ngrid()\n\n\n\n\n\n\n\n\nCalcoliamo la verosimiglianza:\n\n# Inizializzazione della verosimiglianza\nlikelihood &lt;- rep(1, length(lambda_grid))\n\n# Calcolo iterativo della verosimiglianza\nfor (yi in y) {\n  likelihood &lt;- likelihood * dpois(yi, lambda = lambda_grid)\n}\n\nCalcoliamo la distribuzione a posteriori non normalizzata:\n\nposterior_unnormalized &lt;- likelihood * prior\n\nNormalizzazione della distribuzione a posteriori:\n\n# Fattore di normalizzazione\nnormalization_factor &lt;- sum(posterior_unnormalized * diff(lambda_grid)[1])\n\n# Distribuzione a posteriori normalizzata\nposterior &lt;- posterior_unnormalized / normalization_factor\n\nCreiamo un grafico delle distribuzioni a priori e a posteriori:\n\nplot(\n  lambda_grid, posterior, type = \"l\", col = \"blue\",\n  xlab = expression(lambda),\n  ylab = \"Densit√† di probabilit√†\",\n  main = \"Distribuzione a Posteriori di Lambda\"\n)\nlines(lambda_grid, prior, col = \"red\", lty = 2, lwd = 2)\nlegend(\"topright\", legend = c(\"Posteriori\", \"A Priori\"),\n       col = c(\"blue\", \"red\"), lty = c(1, 2), lwd = 2)\ngrid()\n\n\n\n\n\n\n\n\nIn conclusione,\n\nla distribuzione a posteriori √® spostata a sinistra rispetto a quella a priori, indicando che i dati suggeriscono un valore pi√π basso per \\(\\lambda\\).\nla distribuzione a posteriori √® pi√π stretta rispetto a quella a priori, indicando una riduzione dell‚Äôincertezza.\n\nQuesto approccio numerico consente di esplorare come le osservazioni aggiornano la nostra credenza sul parametro \\(\\lambda\\), evidenziando la potenza del metodo bayesiano.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>¬† <span class='chapter-title'>Modello coniugato Gamma-Poisson üî∏</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_gamma_poisson_model.html#modello-coniugato-gamma-poission",
    "href": "chapters/bayesian_inference/09_gamma_poisson_model.html#modello-coniugato-gamma-poission",
    "title": "47¬† Modello coniugato Gamma-Poisson üî∏",
    "section": "47.6 Modello Coniugato Gamma-Poission",
    "text": "47.6 Modello Coniugato Gamma-Poission\nPer calcolare analiticamente la distribuzione a posteriori nel contesto di un modello gamma-Poisson possiamo seguire un processo diretto. Il modello Gamma-Poisson √® coniugato, il che significa che la distribuzione a posteriori sar√† ancora una distribuzione Gamma.\nSeguendo il teorema di Bayes, possiamo scrivere la distribuzione a posteriori come:\n\\(f(\\lambda \\mid y) \\propto f(y \\mid \\lambda) \\cdot f(\\lambda) ,\\)\ndove \\(f(\\lambda \\mid y)\\) √® la distribuzione a posteriori, \\(f(y \\mid \\lambda)\\) √® la verosimiglianza e \\(f(\\lambda)\\) √® la distribuzione a priori.\nDefiniamo la verosimiglianza (distribuzione di Poisson):\n\\(f(y \\mid \\lambda) = \\prod_{i=1}^n \\frac{e^{-\\lambda}\\lambda^{y_i}}{y_i!} = \\frac{e^{-n\\lambda}\\lambda^{\\sum_{i=1}^n y_i}}{\\prod_{i=1}^n y_i!}.\\)\nDefiniamo la distribuzione a priori (distribuzione Gamma):\n\\(f(\\lambda) = \\frac{b^a}{\\Gamma(a)}\\lambda^{a-1}e^{-b\\lambda}.\\)\nOra, moltiplichiamo la verosimiglianza per la distribuzione a priori:\n\\(f(\\lambda|y) \\propto \\frac{e^{-n\\lambda}\\lambda^{\\sum_{i=1}^n y_i}}{\\prod_{i=1}^n y_i!} \\cdot \\frac{b^a}{\\Gamma(a)}\\lambda^{a-1}e^{-b\\lambda}.\\)\nSemplifichiamo, eliminando i termini costanti (che non dipendono da \\(\\lambda\\)):\n\\(f(\\lambda \\mid y) \\propto e^{-n\\lambda}\\lambda^{\\sum_{i=1}^n y_i} \\cdot \\lambda^{a-1}e^{-b\\lambda}.\\)\nRaggruppiamo i termini:\n\\(f(\\lambda|y) \\propto \\lambda^{\\sum_{i=1}^n y_i} \\cdot \\lambda^{a-1} \\cdot e^{-n\\lambda} \\cdot e^{-b\\lambda}.\\)\nSemplifichiamo ulteriormente:\n\\(f(\\lambda \\mid y) \\propto \\lambda^{\\sum_{i=1}^n y_i + a - 1} \\cdot e^{-(n+b)\\lambda}.\\)\nRiconosciamo che questa √® la forma di una distribuzione Gamma con nuovi parametri:\n\\(f(\\lambda \\mid y) \\propto \\lambda^{(\\sum_{i=1}^n y_i + a) - 1} \\cdot e^{-(n+b)\\lambda}.\\)\nQuindi, la distribuzione a posteriori √® una Gamma con parametri:\n\n\\(\\alpha_{post} = a + \\sum_{i=1}^n y_i\\),\n\\(\\beta_{post} = b + n\\),\n\ndove:\n\n\\(a\\) e \\(b\\) sono i parametri della distribuzione Gamma a priori,\n\\(\\sum_{i=1}^n y_i\\) √® la somma di tutte le osservazioni,\n\\(n\\) √® il numero di osservazioni.\n\nQuesta derivazione mostra come la distribuzione a posteriori mantiene la forma di una Gamma, ma con parametri aggiornati che incorporano l‚Äôinformazione dai dati osservati.\nConsideriamo nuovamente l‚Äôesempio precedente. Utilizzando i parametri aggiornati, rappresentiamo graficamente la distribuzione a posteriori:\n\n# Parametri aggiornati della distribuzione a posteriori Gamma\nalpha_post &lt;- alpha_prior + sum(y)\nbeta_post &lt;- beta_prior + length(y)\n\n# Distribuzione a posteriori analitica\nposterior_analytic &lt;- dgamma(lambda_grid, shape = alpha_post, rate = beta_post)\n\n# Plot della distribuzione a posteriori analitica\nplot(\n  lambda_grid, posterior_analytic, type = \"l\", col = \"blue\",\n  xlab = expression(lambda),\n  ylab = \"Densit√† di probabilit√†\",\n  main = \"Distribuzione a Posteriori Analitica Gamma-Poisson\"\n)\nabline(v = alpha_post / beta_post, col = \"red\", lty = 2) # Media a posteriori\nlegend(\n  \"topright\",\n  legend = c(\"Distribuzione a Posteriori\", \"Media a Posteriori\"),\n  col = c(\"blue\", \"red\"),\n  lty = c(1, 2)\n)\n\n\n\n\n\n\n\n\nIl grafico mostra la distribuzione a posteriori analitica del parametro di tasso \\(\\lambda\\) di un modello di Poisson, ottenuta utilizzando una distribuzione a priori Gamma e aggiornando i parametri alla luce dei dati osservati. La distribuzione a posteriori √® calcolata come una Gamma aggiornata con i parametri \\(\\alpha_{\\text{post}}\\) e \\(\\beta_{\\text{post}}\\), e rappresenta la nostra conoscenza aggiornata dopo aver visto i dati. I risultati analitici concordano con quelli ottenuti tramite simulazione.\nProcediamo ora con il calcolo della soluzione analitica per la media della distribuzione a posteriori del parametro \\(\\lambda\\):\n\n# Media della distribuzione a posteriori\nposterior_mean &lt;- alpha_post / beta_post\ncat(sprintf(\"Media a Posteriori = %.3f\\n\", posterior_mean))\n#&gt; Media a Posteriori = 2.200\n\n# Parametri della distribuzione a posteriori\ncat(sprintf(\"Shape (Œ±) = %.1f\\n\", alpha_post))\n#&gt; Shape (Œ±) = 22.0\ncat(sprintf(\"Rate (Œ≤) = %.1f\\n\", beta_post))\n#&gt; Rate (Œ≤) = 10.0\n\nPossiamo calcolare la probabilit√† di qualsiasi evento di interesse. Per esempio, ci possiamo chiedere quale sia la probabilit√† di osservare pi√π di 3 compulsioni per ora:\n\n# Probabilit√† di osservare pi√π di 3 eventi\nprob_y_greater_than_3 &lt;- 1 - pgamma(3, shape = alpha_post, rate = beta_post)\ncat(sprintf(\"Probabilit√† di osservare pi√π di 3 eventi = %.3f\\n\", prob_y_greater_than_3))\n#&gt; Probabilit√† di osservare pi√π di 3 eventi = 0.054",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>¬† <span class='chapter-title'>Modello coniugato Gamma-Poisson üî∏</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_gamma_poisson_model.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/09_gamma_poisson_model.html#riflessioni-conclusive",
    "title": "47¬† Modello coniugato Gamma-Poisson üî∏",
    "section": "47.7 Riflessioni Conclusive",
    "text": "47.7 Riflessioni Conclusive\nIl modello Gamma-Poisson offre un framework robusto per l‚Äôinferenza bayesiana su dati di conteggio in psicologia. Partendo da una distribuzione a priori Gamma, che rappresenta la nostra conoscenza iniziale sul tasso medio, siamo in grado di aggiornare questa conoscenza alla luce dei dati osservati, ottenendo una distribuzione a posteriori che riflette in modo pi√π preciso la realt√† sottostante. Questo approccio permette di quantificare l‚Äôincertezza associata alle nostre stime e di prendere decisioni informate sulla base dei dati disponibili.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>¬† <span class='chapter-title'>Modello coniugato Gamma-Poisson üî∏</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_gamma_poisson_model.html#esercizi",
    "href": "chapters/bayesian_inference/09_gamma_poisson_model.html#esercizi",
    "title": "47¬† Modello coniugato Gamma-Poisson üî∏",
    "section": "47.8 Esercizi",
    "text": "47.8 Esercizi\n\nEsercizio 47.1 Consideriamo uno studio longitudinale su coppie, dove i partecipanti registrano quotidianamente la frequenza con cui nascondono il loro comportamento di fumo al partner. Basandoci sui dati di Scholz et al. (2021), assumiamo che il tasso medio di nascondere il fumo sia di 1.52 volte al giorno. Supponiamo di avere i seguenti dati giornalieri per un partecipante:\n\nGiorno 1: 2 volte.\nGiorno 2: 0 volte.\nGiorno 3: 1 volta.\nGiorno 4: 3 volte.\n\nUtilizzare un modello Gamma-Poisson per stimare la distribuzione a posteriori del tasso individuale di nascondere il fumo per un partecipante specifico, dato il suo insieme di osservazioni giornaliere.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>¬† <span class='chapter-title'>Modello coniugato Gamma-Poisson üî∏</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_gamma_poisson_model.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/09_gamma_poisson_model.html#informazioni-sullambiente-di-sviluppo",
    "title": "47¬† Modello coniugato Gamma-Poisson üî∏",
    "section": "47.9 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "47.9 Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: US/Pacific\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.17.0      ggokabeito_0.1.0 see_0.9.0        gridExtra_2.3   \n#&gt;  [5] patchwork_1.3.0  bayesplot_1.11.1 psych_2.4.12     scales_1.3.0    \n#&gt;  [9] markdown_1.13    knitr_1.49       lubridate_1.9.4  forcats_1.0.0   \n#&gt; [13] stringr_1.5.1    dplyr_1.1.4      purrr_1.0.2      readr_2.1.5     \n#&gt; [17] tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0 \n#&gt; [21] rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      shape_1.4.6.1     xfun_0.50         htmlwidgets_1.6.4\n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2      \n#&gt;  [9] generics_0.1.3    parallel_4.4.2    pan_1.9           pacman_0.5.1     \n#&gt; [13] jomo_2.7-6        pkgconfig_2.0.3   Matrix_1.7-1      lifecycle_1.0.4  \n#&gt; [17] compiler_4.4.2    farver_2.1.2      munsell_0.5.1     mnormt_2.1.1     \n#&gt; [21] codetools_0.2-20  htmltools_0.5.8.1 yaml_2.3.10       glmnet_4.1-8     \n#&gt; [25] nloptr_2.1.1      pillar_1.10.1     MASS_7.3-64       iterators_1.0.14 \n#&gt; [29] rpart_4.1.23      boot_1.3-31       foreach_1.5.2     mitml_0.4-5      \n#&gt; [33] nlme_3.1-166      tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4    \n#&gt; [37] splines_4.4.2     rprojroot_2.0.4   fastmap_1.2.0     grid_4.4.2       \n#&gt; [41] colorspace_2.1-1  cli_3.6.3         magrittr_2.0.3    survival_3.7-0   \n#&gt; [45] broom_1.0.7       withr_3.0.2       backports_1.5.0   timechange_0.3.0 \n#&gt; [49] rmarkdown_2.29    nnet_7.3-19       lme4_1.1-35.5     hms_1.1.3        \n#&gt; [53] evaluate_1.0.1    rlang_1.1.4       Rcpp_1.0.13-1     glue_1.8.0       \n#&gt; [57] minqa_1.2.8       jsonlite_1.8.9    R6_2.5.1",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>¬† <span class='chapter-title'>Modello coniugato Gamma-Poisson üî∏</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_gamma_poisson_model.html#bibliografia",
    "href": "chapters/bayesian_inference/09_gamma_poisson_model.html#bibliografia",
    "title": "47¬† Modello coniugato Gamma-Poisson üî∏",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nScholz, U., Stadler, G., Berli, C., L√ºscher, J., & Knoll, N. (2021). How do people experience and respond to social control from their partner? Three daily diary studies. Frontiers in Psychology, 11, 613546.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>¬† <span class='chapter-title'>Modello coniugato Gamma-Poisson üî∏</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_gamma_exponential_model.html",
    "href": "chapters/bayesian_inference/10_gamma_exponential_model.html",
    "title": "48¬† Modello gamma-esponenziale üî∏",
    "section": "",
    "text": "48.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nPreparazione del Notebook\nNell‚Äôinferenza bayesiana, il modello coniugato Gamma-Esponenziale rappresenta un approccio analitico efficace per l‚Äôanalisi di dati che seguono una distribuzione esponenziale. Questa distribuzione √® comunemente utilizzata per modellare i tempi di attesa tra eventi in processi di Poisson, come ad esempio gli intervalli tra arrivi in un sistema a coda o la durata di eventi psicologici.\nConsideriamo, ad esempio, un esperimento in psicologia in cui si misurano i tempi di insorgenza di episodi di ansia in seguito a un evento stressante. In questo caso, si pu√≤ ipotizzare che i tempi di insorgenza siano distribuiti esponenzialmente. Il parametro \\(\\lambda\\) della distribuzione esponenziale rappresenta il tasso medio con cui si verificano gli episodi di ansia.\nIl modello coniugato Gamma-Esponenziale consente di stimare il parametro \\(\\lambda\\) utilizzando i dati osservati. La distribuzione a priori Gamma viene utilizzata per rappresentare l‚Äôincertezza iniziale su \\(\\lambda\\), mentre la distribuzione esponenziale modella i dati osservati. Grazie a questa coniugazione, l‚Äôaggiornamento delle credenze sul parametro \\(\\lambda\\) avviene in modo semplice e analitico, permettendo di ottenere una stima bayesiana del tasso medio di occorrenza degli episodi di ansia, fornendo cos√¨ una descrizione probabilistica accurata del fenomeno in esame.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>¬† <span class='chapter-title'>Modello gamma-esponenziale üî∏</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_gamma_exponential_model.html#introduzione",
    "href": "chapters/bayesian_inference/10_gamma_exponential_model.html#introduzione",
    "title": "48¬† Modello gamma-esponenziale üî∏",
    "section": "",
    "text": "48.1.1 Il Modello Matematico\nCaso singolo. Supponiamo di osservare un singolo tempo di attesa \\(y_1\\) prima che si verifichi un evento, come un episodio di disagio psicologico. Assumiamo che questo tempo di attesa segua una distribuzione esponenziale con parametro \\(\\lambda\\). La funzione di densit√† di probabilit√† (pdf) della distribuzione esponenziale √® data da:\n\\[\nf(y_1 \\mid \\lambda) = \\lambda e^{-\\lambda y_1},\n\\]\ndove:\n\n\\(y_1\\) rappresenta il tempo di attesa,\n\\(\\lambda\\) √® il parametro della distribuzione, che rappresenta il tasso medio con cui gli eventi si verificano per unit√† di tempo.\n\nIn questa distribuzione, \\(\\lambda\\) √® il tasso di occorrenza o tasso di decadimento, ed √® l‚Äôinverso del tempo medio di attesa. Pi√π precisamente:\n\nIl tempo medio di attesa √® il valore medio del tempo che trascorre prima che l‚Äôevento si verifichi (ad esempio, quanto tempo ci si aspetta in media prima che arrivi un autobus).\nIl parametro \\(\\lambda\\) rappresenta la frequenza con cui l‚Äôevento si verifica per unit√† di tempo, e quindi \\(\\lambda = \\frac{1}{\\text{tempo medio}}\\).\n\nPertanto, nella funzione esponenziale \\(f(y_1 \\mid \\lambda) = \\lambda e^{-\\lambda y_1}\\), il parametro \\(\\lambda\\) √® inversamente proporzionale al tempo medio di attesa: pi√π grande √® \\(\\lambda\\), pi√π breve √® il tempo medio di attesa tra gli eventi.\nQuesta funzione descrive la probabilit√† di osservare un tempo di attesa esattamente uguale a \\(y_1\\), dato un valore specifico di \\(\\lambda\\). Per la distribuzione esponenziale, la media √® \\(\\frac{1}{\\lambda}\\) e la varianza √® \\(\\frac{1}{\\lambda^2}\\), il che riflette l‚Äôinfluenza del tasso \\(\\lambda\\) sulla dispersione dei tempi di attesa.\nPer fare un esempio, supponiamo che il tempo medio di attesa sia 2 ore. In questo caso, il parametro \\(\\lambda\\) (l‚Äôinverso del tempo medio di attesa) √® \\(\\frac{1}{2}\\).\n\n# Parametro lambda (l'inverso del tempo medio di attesa)\nlambda_value &lt;- 1 / 2\n\nDisegniamo la funzione di densit√† esponenziale per tempi di attesa compresi tra 0 e 10 ore.\n\n# Creazione dei valori di y1 su cui valutare la funzione\ny1_values &lt;- seq(0, 10, length.out = 500) # Intervallo da 0 a 10 ore\n\n# Definizione della funzione di densit√† esponenziale\nexponential_density &lt;- function(y1, lambda_value) {\n  lambda_value * exp(-lambda_value * y1)\n}\n\n# Calcolo dei valori di f(y1 | lambda)\nf_values &lt;- exponential_density(y1_values, lambda_value)\n\n# Creazione del grafico\nplot(\n  y1_values, f_values,\n  type = \"l\", lwd = 2,\n  main = expression(paste(\n    \"Funzione di Densit√† Esponenziale con \",\n    lambda, \" = 1/2\"\n  )),\n  xlab = \"Tempo di attesa (ore)\", ylab = \"Densit√†\"\n)\nlegend(\"topright\",\n  legend = expression(f(y[1] ~ \"|\" ~ lambda) == lambda ~ e^(-lambda * y[1])),\n  lty = 1, bty = \"n\"\n)\n\n\n\n\n\n\n\n\nQuesto codice crea un grafico della funzione di densit√† esponenziale per \\(\\lambda = 1/2\\) e tempi di attesa compresi tra 0 e 10 ore.\nIl caso di \\(n\\) osservazioni indipendenti. Consideriamo ora un campione di \\(n\\) osservazioni indipendenti \\(y_1, y_2, \\dots, y_n\\). L‚Äôindipendenza tra le osservazioni implica che il tempo di attesa osservato per un evento non influisce sulla probabilit√† di osservare altri tempi di attesa.\nPoich√© le osservazioni sono indipendenti, la probabilit√† congiunta di osservare tutti i tempi di attesa nel campione √® il prodotto delle probabilit√† individuali. Di conseguenza, la funzione di verosimiglianza per l‚Äôintero campione √® data da:\n\\[\nf(y_1, y_2, \\dots, y_n \\mid \\lambda) = f(y_1 \\mid \\lambda) \\cdot f(y_2 \\mid \\lambda) \\cdot \\dots \\cdot f(y_n \\mid \\lambda).\n\\]\nSostituendo la funzione di densit√† della distribuzione esponenziale per ciascuna osservazione, otteniamo:\n\\[\nf(y \\mid \\lambda) = \\lambda e^{-\\lambda y_1} \\cdot \\lambda e^{-\\lambda y_2} \\cdot \\dots \\cdot \\lambda e^{-\\lambda y_n}.\n\\]\nRaccogliendo i termini comuni, possiamo riscrivere la funzione di verosimiglianza come:\n\\[\nf(y \\mid \\lambda) = \\lambda^n e^{-\\lambda (y_1 + y_2 + \\dots + y_n)}.\n\\]\nUtilizzando la notazione di sommatoria, possiamo esprimere la funzione di verosimiglianza in modo compatto come:\n\\[\nf(y \\mid \\lambda) = \\lambda^n e^{-\\lambda \\sum_{i=1}^{n} y_i}.\n\\]\nLa funzione di verosimiglianza \\(f(y \\mid \\lambda)\\) rappresenta la probabilit√† di osservare il campione \\(y_1, y_2, \\dots, y_n\\) dato un particolare valore del parametro \\(\\lambda\\). Un valore pi√π alto della verosimiglianza indica una maggiore plausibilit√† del valore di \\(\\lambda\\), dato il campione osservato.\nSpesso √® pi√π conveniente lavorare con il logaritmo della funzione di verosimiglianza, poich√© il logaritmo trasforma i prodotti in somme, semplificando i calcoli. Il logaritmo della funzione di verosimiglianza √®:\n\\[\n\\log L(\\lambda \\mid y_1, y_2, \\dots, y_n) = n \\log \\lambda - \\lambda \\sum_{i=1}^{n} y_i.\n\\]\nQuesta forma semplificata della log-verosimiglianza √® utile per stimare il parametro \\(\\lambda\\) tramite tecniche come la massimizzazione della verosimiglianza.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>¬† <span class='chapter-title'>Modello gamma-esponenziale üî∏</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_gamma_exponential_model.html#aggiornare-le-nostre-credenze-con-linferenza-bayesiana",
    "href": "chapters/bayesian_inference/10_gamma_exponential_model.html#aggiornare-le-nostre-credenze-con-linferenza-bayesiana",
    "title": "48¬† Modello gamma-esponenziale üî∏",
    "section": "48.2 Aggiornare le Nostre Credenze con l‚ÄôInferenza Bayesiana",
    "text": "48.2 Aggiornare le Nostre Credenze con l‚ÄôInferenza Bayesiana\nNell‚Äôapproccio bayesiano, non consideriamo solo i dati, ma anche le nostre conoscenze a priori sul parametro \\(\\lambda\\). Assegniamo a \\(\\lambda\\) una distribuzione a priori, tipicamente una distribuzione Gamma. Combinando la verosimiglianza con la distribuzione a priori, otteniamo la distribuzione a posteriori di \\(\\lambda\\), che rappresenta la nostra conoscenza aggiornata alla luce dei dati. La propriet√† della coniugazione assicura che la distribuzione a posteriori sia anch‚Äôessa una Gamma, facilitando i calcoli.\nPer fare un esempio concreto, simuleremo un campione di dati. Immaginiamo di raccogliere dati che rappresentano il tempo, misurato in ore, che intercorre tra episodi di ansia in individui con disturbi d‚Äôansia. La distribuzione esponenziale pu√≤ essere utilizzata per modellare questo tempo di attesa tra un episodio di ansia e il successivo. Ad esempio, possiamo ipotizzare che, una volta concluso un episodio, l‚Äôinsorgenza del prossimo segua un processo stocastico con un tasso costante, indipendentemente dal tempo trascorso dall‚Äôepisodio precedente. In questo contesto, il parametro \\(\\lambda\\) della distribuzione esponenziale rappresenta il tasso medio di occorrenza degli episodi di ansia, ossia quanti episodi ci si aspetta in media in una certa unit√† di tempo (ad esempio, in un giorno).\nSe \\(\\lambda\\) √® elevato, ci√≤ indica che gli episodi di ansia sono pi√π frequenti, con tempi di attesa pi√π brevi tra un episodio e l‚Äôaltro.\n\n# Impostiamo il seed per rendere i risultati riproducibili\nset.seed(42)\n\n# Parametro medio (tempo medio di attesa in ore)\nmean_time &lt;- 3.0\nlambda_param &lt;- 1 / mean_time # Parametro lambda per la distribuzione esponenziale\n\n# Numero di osservazioni nel campione\nn &lt;- 15\n\n# Generazione del campione casuale\ny &lt;- round(rexp(n, rate = lambda_param))\ny\n#&gt;  [1] 1 2 1 0 1 4 1 1 4 2 4 7 0 0 4\n\nImmaginiamo che questi dati rappresentino il tempo di attesa in ore tra episodi di ansia in 15 individui con disturbi d‚Äôansia. Il tempo di attesa medio √®:\n\nmean_time_observed &lt;- mean(y)\nmean_time_observed\n#&gt; [1] 2.13\n\nIl tasso di occorrenza, \\(\\lambda\\), calcolato sulla base dei dati osservati √®:\n\nlambda_estimated &lt;- 1 / mean_time_observed\nlambda_estimated\n#&gt; [1] 0.469\n\nOra possiamo procedere a trovare la distribuzione a posteriori per il tasso di occorrenza \\(\\lambda\\).\n\n48.2.1 Passi per definire un prior debolmente informativo\nIl primo passo consiste nel definire una distribuzione a priori per \\(\\lambda\\), il tasso di occorrenza degli episodi di ansia in individui con disturbi d‚Äôansia. Se disponiamo di poche informazioni a priori riguardo al valore di \\(\\lambda\\), possiamo adottare una distribuzione a priori debolmente informativa. Un prior debolmente informativo ha lo scopo di esercitare una minima influenza sull‚Äôinferenza, consentendo ai dati osservati di guidare principalmente la stima del parametro.\nLa distribuzione a priori coniugata per la distribuzione esponenziale √® la distribuzione Gamma. Un prior debolmente informativo per \\(\\lambda\\) potrebbe essere impostato in modo tale da riflettere una conoscenza vaga, con una media che rappresenta un tempo di attesa ragionevole (basato su qualche informazione preliminare o ipotesi generale), ma con una varianza ampia, in modo da non vincolare eccessivamente l‚Äôinferenza.\nSupponiamo di voler impostare una distribuzione a priori per il tasso di occorrenza \\(\\lambda\\), in modo tale che il tempo medio di attesa sia 3.33 ore, con una deviazione standard ampia, ad esempio 5 ore. Poich√© \\(\\lambda\\) rappresenta il tasso di occorrenza (ovvero l‚Äôinverso del tempo medio di attesa), dobbiamo applicare la distribuzione Gamma ai valori di \\(\\lambda\\), non direttamente ai tempi di attesa.\nI parametri della distribuzione Gamma, \\(\\alpha\\) (forma) e \\(\\beta\\) (tasso), sono dati da:\n\n\\(\\alpha_{\\text{prior}} = 0.45\\)\n\\(\\beta_{\\text{prior}} = 1.5\\)\n\nVerifichiamo che questi parametri corrispondano alla media e alla varianza desiderate.\n\n# Parametri della distribuzione Gamma\nalpha_prior &lt;- 0.45 # Forma\nbeta_prior &lt;- 1.5 # Tasso (inverso della scala)\n\n# Calcolo della media e della varianza della distribuzione Gamma per Œª\nmean_lambda &lt;- alpha_prior / beta_prior\nvariance_lambda &lt;- alpha_prior / (beta_prior^2)\n\n# Calcolo della media del tempo di attesa (E[Y] = 1 / E[Œª])\nmean_waiting_time &lt;- 1 / mean_lambda\n\n# Stampiamo la media e la varianza di Œª e del tempo di attesa\ncat(\"Media di Œª:\", mean_lambda, \"\\n\")\n#&gt; Media di Œª: 0.3\ncat(\"Varianza di Œª:\", variance_lambda, \"\\n\")\n#&gt; Varianza di Œª: 0.2\ncat(\"Media del tempo di attesa:\", mean_waiting_time, \"ore\\n\")\n#&gt; Media del tempo di attesa: 3.33 ore\n\nLa media del tempo di attesa √® 3.33 ore, come desiderato. La varianza del tempo di attesa richiede un calcolo pi√π complesso e non √® semplicemente l‚Äôinverso della varianza di \\(\\lambda\\).\n\n\n48.2.2 Visualizzazione della Distribuzione a Priori\nDisegniamo la funzione di densit√† della distribuzione Gamma per \\(\\lambda\\), utilizzando i parametri specificati.\n\n# Creazione dei valori x per il grafico\nx &lt;- seq(0, 2, length.out = 500)\n\n# Funzione di densit√† della distribuzione Gamma con i parametri dati\ngamma_pdf &lt;- dgamma(x, shape = alpha_prior, rate = beta_prior)\n\n# Creazione del grafico\nplot(x, gamma_pdf,\n  type = \"l\", lwd = 2,\n  main = bquote(\"Funzione di Densit√† Gamma con \" ~ alpha == .(alpha_prior) ~ \",\" ~ beta == .(beta_prior)),\n  xlab = expression(lambda),\n  ylab = \"Densit√† di probabilit√†\"\n)\nlegend(\n  \"topright\",\n  legend = \"Distribuzione a Priori\",\n  lty = 1,\n  lwd = 2,\n  bty = \"n\"\n)",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>¬† <span class='chapter-title'>Modello gamma-esponenziale üî∏</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_gamma_exponential_model.html#metodo-basato-su-griglia",
    "href": "chapters/bayesian_inference/10_gamma_exponential_model.html#metodo-basato-su-griglia",
    "title": "48¬† Modello gamma-esponenziale üî∏",
    "section": "48.3 Metodo Basato su Griglia",
    "text": "48.3 Metodo Basato su Griglia\nPoniamoci l‚Äôobiettivo di utilizzare il metodo basato su griglia per derivare la distribuzione a posteriori del parametro \\(\\lambda\\) della distribuzione esponenziale. Iniziamo creando una griglia per \\(\\lambda\\) nell‚Äôintervallo [0.01, 2].\n\n# Evitiamo zero per evitare divisione per zero\nlambda_grid &lt;- seq(0.01, 2, length.out = 1000)\n\n\n48.3.1 Calcolo della Distribuzione a Priori\n\n# Calcolo della distribuzione a priori\nprior &lt;- dgamma(lambda_grid, shape = alpha_prior, rate = beta_prior)\n\n\n\n48.3.2 Calcolo della Verosimiglianza\nImmaginiamo di avere i seguenti dati, che rappresentano i tempi di attesa (in ore) tra episodi di ansia per 15 individui:\n\n# Impostiamo il seed per rendere i risultati riproducibili\nset.seed(42)\n\n# Parametro medio (tempo medio di attesa in ore)\nmean_time &lt;- 3.0\nlambda_param &lt;- 1 / mean_time # Parametro Œª per la distribuzione esponenziale\n\n# Numero di osservazioni nel campione\nn &lt;- 15\n\n# Generazione del campione casuale\ny &lt;- round(rexp(n, rate = lambda_param))\ny\n#&gt;  [1] 1 2 1 0 1 4 1 1 4 2 4 7 0 0 4\n\nCalcoliamo la log-verosimiglianza per ciascun valore di \\(\\lambda\\) nella griglia:\n\n# Calcolo della log-verosimiglianza per ciascun valore di lambda\nlog_likelihood &lt;- sapply(\n  lambda_grid,\n  function(lam) sum(dexp(y, rate = lam, log = TRUE))\n)\n\n\n\n48.3.3 Calcolo della Distribuzione a Posteriori\nCalcoliamo la distribuzione a posteriori non normalizzata in logaritmo per evitare problemi di underflow numerico:\n\n# Calcolo del log-posteriori non normalizzato\nlog_posterior_unnormalized &lt;- log_likelihood + log(prior)\n\n# Normalizzazione per stabilit√† numerica\nlog_posterior_unnormalized &lt;- log_posterior_unnormalized - max(log_posterior_unnormalized)\n\n# Convertiamo in scala normale\nposterior_unnormalized &lt;- exp(log_posterior_unnormalized)\n\nNormalizziamo la distribuzione a posteriori:\n\n# Calcolo del passo nella griglia\ndelta_lambda &lt;- diff(lambda_grid)[1] # Assumendo che la griglia sia equispaziata\n\n# Normalizzazione della distribuzione a posteriori\nposterior &lt;-\n  posterior_unnormalized / sum(posterior_unnormalized * delta_lambda)\n\n\n\n48.3.4 Visualizzazione dei Risultati\n\n# Grafico della distribuzione a posteriori e a priori\nplot(lambda_grid, posterior,\n  type = \"l\",\n  lwd = 2,\n  xlab = expression(lambda),\n  ylab = \"Densit√† di probabilit√†\",\n  main = \"Distribuzione a Posteriori di Œª\"\n)\nlines(lambda_grid, prior, lwd = 2, lty = 2)\nlegend(\"topright\",\n  legend = c(\"Posteriori\", \"Priori\"),\n  lty = c(1, 2), \n  lwd = 2, \n  bty = \"n\"\n)\n\n\n\n\n\n\n\n\nDal grafico, possiamo osservare come la distribuzione a posteriori di \\(\\lambda\\) sia aggiornata rispetto alla distribuzione a priori in base ai dati osservati. La distribuzione a posteriori riflette sia le informazioni a priori sia l‚Äôevidenza fornita dai dati, fornendo una stima aggiornata del tasso di occorrenza degli episodi di ansia.\n\n\n48.3.5 Calcolo della Media e Varianza Posteriori\nPossiamo calcolare la media e la varianza a posteriori di \\(\\lambda\\) utilizzando la distribuzione a posteriori calcolata sulla griglia.\n\n# Calcolo della media a posteriori di Œª\nposterior_mean_lambda &lt;- sum(lambda_grid * posterior * delta_lambda)\n\n# Calcolo della varianza a posteriori di Œª\nposterior_variance_lambda &lt;-\n  sum((lambda_grid - posterior_mean_lambda)^2 * posterior * delta_lambda)\n\n# Stampiamo i risultati\ncat(\"Media a posteriori di Œª:\", posterior_mean_lambda, \"\\n\")\n#&gt; Media a posteriori di Œª: 0.461\ncat(\"Varianza a posteriori di Œª:\", posterior_variance_lambda, \"\\n\")\n#&gt; Varianza a posteriori di Œª: 0.0138\n\n\n\n48.3.6 Stima del Tempo di Attesa Medio a Posteriori\nUtilizzando la media a posteriori di \\(\\lambda\\), possiamo stimare il tempo di attesa medio a posteriori:\n\n# Stima del tempo di attesa medio a posteriori\nposterior_mean_waiting_time &lt;- 1 / posterior_mean_lambda\ncat(\"Tempo di attesa medio a posteriori:\", posterior_mean_waiting_time, \"ore\\n\")\n#&gt; Tempo di attesa medio a posteriori: 2.17 ore\n\nIn conclusione, attraverso il metodo basato su griglia, abbiamo derivato la distribuzione a posteriori del tasso di occorrenza \\(\\lambda\\), tenendo conto della nostra conoscenza a priori e dei dati osservati. Questo approccio ci permette di aggiornare le nostre credenze su \\(\\lambda\\) in modo coerente con l‚Äôevidenza empirica, fornendo stime pi√π accurate e affidabili.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>¬† <span class='chapter-title'>Modello gamma-esponenziale üî∏</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_gamma_exponential_model.html#modello-coniugato-gamma-esponenziale",
    "href": "chapters/bayesian_inference/10_gamma_exponential_model.html#modello-coniugato-gamma-esponenziale",
    "title": "48¬† Modello gamma-esponenziale üî∏",
    "section": "48.4 Modello Coniugato Gamma-Esponenziale",
    "text": "48.4 Modello Coniugato Gamma-Esponenziale\nQuando utilizziamo una distribuzione \\(\\text{Gamma}(\\alpha, \\beta)\\) come distribuzione coniugata a priori, la distribuzione a posteriori risulta anch‚Äôessa essere una distribuzione Gamma, con parametri aggiornati \\(\\alpha + n\\) e \\(\\beta + \\sum_{i=1}^{n} x_{i}\\).\nIn altre parole, se il parametro \\(\\lambda\\) della distribuzione esponenziale segue una distribuzione a priori Gamma con parametri \\(\\alpha\\) e \\(\\beta\\), allora, dopo aver osservato un campione di \\(n\\) osservazioni \\(x_1, x_2, \\dots, x_n\\), la distribuzione a posteriori di \\(\\lambda\\) sar√† ancora una distribuzione Gamma, ma con i parametri aggiornati:\n\\[\n\\lambda \\mid x \\sim \\text{Gamma}(\\alpha + n, \\beta + \\sum_{i=1}^{n} x_{i}).\n\\]\nQuesto aggiornamento dei parametri √® una conseguenza della propriet√† coniugata della distribuzione Gamma rispetto alla distribuzione esponenziale.\n\n48.4.1 Dimostrazione del Modello Coniugato Gamma-Esponenziale\nPer dimostrare questo risultato, partiamo dal teorema di Bayes:\n\\[\nf(\\lambda \\mid x) \\propto f(x \\mid \\lambda) \\cdot f(\\lambda),\n\\]\ndove \\(f(\\lambda \\mid x)\\) √® la distribuzione a posteriori di \\(\\lambda\\) dato il campione \\(x\\), \\(f(x \\mid \\lambda)\\) √® la verosimiglianza basata sul campione \\(x\\), e \\(f(\\lambda)\\) √® la distribuzione a priori di \\(\\lambda\\).\nLa funzione di verosimiglianza per un campione di \\(n\\) osservazioni indipendenti \\(x_1, x_2, \\dots, x_n\\), che seguono una distribuzione esponenziale con parametro \\(\\lambda\\), √® data da:\n\\[\nf(x \\mid \\lambda) = \\prod_{i=1}^{n} \\lambda e^{-\\lambda x_i} = \\lambda^n e^{-\\lambda \\sum_{i=1}^{n} x_i}.\n\\]\nSupponiamo che il parametro \\(\\lambda\\) segua una distribuzione a priori Gamma con parametri \\(\\alpha\\) e \\(\\beta\\):\n\\[\nf(\\lambda) = \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)} \\lambda^{\\alpha - 1} e^{-\\beta \\lambda}.\n\\]\nMoltiplicando la verosimiglianza per la distribuzione a priori, otteniamo la distribuzione a posteriori:\n\\[\nf(\\lambda \\mid x) \\propto \\lambda^n e^{-\\lambda \\sum_{i=1}^{n} x_i} \\cdot \\lambda^{\\alpha - 1} e^{-\\beta \\lambda}.\n\\]\nSemplificando, si ottiene:\n\\[\nf(\\lambda \\mid x) \\propto \\lambda^{n + \\alpha - 1} e^{-\\lambda \\left(\\beta + \\sum_{i=1}^{n} x_i\\right)}.\n\\]\nQuesta espressione corrisponde alla forma di una distribuzione Gamma con parametri aggiornati:\n\nparametro della forma (alpha): \\(\\alpha_{\\text{post}} = \\alpha + n\\);\nparametro della scala (beta): \\(\\beta_{\\text{post}} = \\beta + \\sum_{i=1}^{n} x_i\\).\n\nQuindi, la distribuzione a posteriori di \\(\\lambda\\) dato il campione \\(x\\) segue una distribuzione Gamma con parametri aggiornati:\n\\[\n\\lambda \\mid x \\sim \\text{Gamma}(\\alpha + n, \\beta + \\sum_{i=1}^{n} x_i).\n\\]\nQuesta derivazione mostra come l‚Äôinformazione contenuta nei dati osservati venga incorporata nei parametri della distribuzione a posteriori, mantenendo la forma della distribuzione a priori grazie alla propriet√† coniugata.\n\n\n48.4.2 Calcolo dei Parametri Aggiornati\nPer il caso dell‚Äôesempio in discussione:\n\nIl numero di osservazioni nel campione \\(n\\) √® 15;\nLa somma delle osservazioni nel campione √®:\n\n\\[\n\\sum_{i=1}^{n} y_i =\n1 + 9 + 4 + 3 + 1 + 1 + 0 + 6 + 3 + 4 + 0 + 11 + 5 + 1 + 1 = 50.\n\\]\nLa distribuzione a posteriori per \\(\\lambda\\) segue una distribuzione Gamma aggiornata con i seguenti parametri:\n\\[\n\\alpha_{\\text{post}} = \\alpha_{\\text{prior}} + n,\n\\]\n\\[\n\\beta_{\\text{post}} = \\beta_{\\text{prior}} + \\sum_{i=1}^{n} y_i.\n\\]\nUsando i valori \\(\\alpha_{\\text{prior}} = 0.009\\) e \\(\\beta_{\\text{prior}} = 0.03\\), otteniamo:\n\\[\n\\alpha_{\\text{post}} = 0.009 + 15 = 15.009,\n\\]\n\\[\n\\beta_{\\text{post}} = 0.03 + 50 = 50.03.\n\\]\n\n# Dati iniziali\nalpha_prior &lt;- 0.009\nbeta_prior &lt;- 0.03\nn &lt;- 15\ny &lt;- c(1, 9, 4, 3, 1, 1, 0, 6, 3, 4, 0, 11, 5, 1, 1)\nsum_y &lt;- sum(y)\n\n# Parametri aggiornati\nalpha_post &lt;- alpha_prior + n\nbeta_post &lt;- beta_prior + sum_y\n\n# Stampa dei parametri aggiornati\ncat(sprintf(\"alpha_post = %.3f; beta_post = %.3f\\n\", alpha_post, beta_post))\n#&gt; alpha_post = 15.009; beta_post = 50.030\n\nGeneriamo il grafico della distribuzione a posteriori.\n\n# Griglia di valori di lambda per il grafico\nlambda_grid &lt;- seq(0, 2, length.out = 1000)\n\n# Calcolo della densit√† della distribuzione Gamma a posteriori\nposterior_pdf &lt;- dgamma(lambda_grid, shape = alpha_post, rate = beta_post)\n\n# Creazione del grafico\nplot(\n  lambda_grid, posterior_pdf,\n  type = \"l\", lwd = 2,\n  main = bquote(\n    \"Distribuzione Gamma a Posteriori con \" ~ alpha[post] ==\n      .(alpha_post) ~ \",\" ~ beta[post] == .(beta_post)\n  ),\n  xlab = expression(lambda), ylab = \"Densit√† di probabilit√†\"\n)\nlegend(\n  \"topright\",\n  legend = bquote(\n    Gamma(alpha[post] == .(alpha_post) ~ \",\" ~ beta[post] == .(beta_post))\n  ),\n  lty = 1,\n  lwd = 2,\n  bty = \"n\"\n)\n\n\n\n\n\n\n\n\n\n\n48.4.3 Calcolo della Media e della Varianza a Posteriori\nLa media e la varianza della distribuzione a posteriori sono calcolate come:\n\\[\n\\text{E}[\\lambda \\mid y] = \\frac{\\alpha_{\\text{post}}}{\\beta_{\\text{post}}},\n\\]\n\\[\n\\text{Var}[\\lambda \\mid y] = \\frac{\\alpha_{\\text{post}}}{\\beta_{\\text{post}}^2}.\n\\]\nIn R:\n\n# Calcolo della media e della varianza a posteriori\nposterior_mean &lt;- alpha_post / beta_post\nposterior_variance &lt;- alpha_post / (beta_post^2)\n\n# Stampa dei risultati\ncat(sprintf(\"Media a posteriori di Œª: %.3f\\n\", posterior_mean))\n#&gt; Media a posteriori di Œª: 0.300\ncat(sprintf(\"Varianza a posteriori di Œª: %.6f\\n\", posterior_variance))\n#&gt; Varianza a posteriori di Œª: 0.005996\n\nLa distribuzione a posteriori di \\(\\lambda\\) √® aggiornata in base ai dati osservati e al prior. La media a posteriori rappresenta la stima del tasso di occorrenza degli episodi di ansia, mentre la varianza riflette l‚Äôincertezza nella stima.\n\nMedia a Posteriori: La media a posteriori di \\(\\lambda\\) √® circa 0.3, indicando un tasso di occorrenza medio di 0.3 episodi per ora.\nVarianza a Posteriori: La varianza di 0.006 riflette una moderata incertezza nella stima di \\(\\lambda\\).\n\nQuesti risultati evidenziano come la distribuzione Gamma aggiornata combini informazioni a priori e dati osservati per ottenere stime robuste del tasso di occorrenza \\(\\lambda\\).\n\n\n48.4.4 Trasformazione della media e della varianza\nPer interpretare questi risultati in termini di tempi di attesa, dobbiamo trasformare i valori sulla scala inversa, cio√® passare dal tasso \\(\\lambda\\) ai tempi di attesa \\(T = \\frac{1}{\\lambda}\\).\nLa media del tempo di attesa \\(T\\) √® l‚Äôinverso della media del tasso di occorrenza \\(\\lambda\\). Pertanto, la media dei tempi di attesa sar√†:\n\\[\n\\text{E}[T \\mid y] = \\frac{1}{\\text{E}[\\lambda \\mid y]} = \\frac{1}{0.3} \\approx 3.33 \\, \\text{ore}.\n\\]\nPer la varianza del tempo di attesa, dobbiamo applicare una trasformazione pi√π complessa. La varianza del tempo di attesa \\(T\\) √® legata alla varianza di \\(\\lambda\\) da:\n\\[\n\\text{Var}(T) = \\frac{\\text{Var}[\\lambda \\mid y]}{(\\text{E}[\\lambda \\mid y])^4}.\n\\]\nSostituendo i valori calcolati per la varianza e la media di \\(\\lambda\\), otteniamo:\n\\[\n\\text{Var}(T) \\approx \\frac{0.006}{(0.3)^4} \\approx 24.59 \\, \\text{ore}.\n\\]\nIn conclusione,\n\nla media del tempo di attesa a posteriori √® di circa 3.33 ore;\nla varianza del tempo di attesa a posteriori √® di circa 24.59 ore, che indica una certa dispersione dei tempi di attesa, con alcuni episodi che possono verificarsi molto pi√π rapidamente o pi√π lentamente rispetto alla media. Si noti che la distribuzione a posteriori √® pi√π concentrata rispetto al prior, poich√© incorpora l‚Äôinformazione aggiuntiva proveniente dai dati osservati.\n\nQuesta trasformazione ci permette di interpretare i risultati sulla scala dei tempi di attesa, che √® pi√π intuitiva per descrivere fenomeni psicologici come l‚Äôinsorgenza di episodi di ansia.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>¬† <span class='chapter-title'>Modello gamma-esponenziale üî∏</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_gamma_exponential_model.html#applicazioni",
    "href": "chapters/bayesian_inference/10_gamma_exponential_model.html#applicazioni",
    "title": "48¬† Modello gamma-esponenziale üî∏",
    "section": "48.5 Applicazioni",
    "text": "48.5 Applicazioni\nUna volta ottenuta la distribuzione a posteriori per Œª, possiamo utilizzarla per rispondere a domande probabilistiche relative ai tempi di attesa tra episodi di ansia. Questo approccio ci consente di calcolare probabilit√† aggiornate alla luce dei dati osservati, rispecchiando meglio l‚Äôincertezza e le informazioni disponibili. Ad esempio, possiamo stimare la probabilit√† di osservare tempi di attesa compresi tra 2 e 5 ore.\nPer risolvere questo problema possiamo usare il metodo Monte Carlo:\n\nGeneriamo un gran numero di campioni dalla distribuzione Gamma a posteriori di \\(\\lambda\\), usando i parametri \\(\\alpha_{\\text{posteriori}}\\) e \\(\\beta_{\\text{posteriori}}\\).\nConvertiamo ciascun \\(\\lambda\\) campionato in un tempo di attesa \\(T = \\frac{1}{\\lambda}\\).\nCalcoliamo le probabilit√† richieste (ad esempio, \\(P(T &gt; 2)\\) e \\(P(T &lt; 5)\\)) semplicemente contando le proporzioni di campioni che soddisfano tali condizioni.\n\n\n48.5.1 Simulazione con Monte Carlo\nUtilizziamo i parametri posteriori della distribuzione Gamma per simulare campioni di \\(\\lambda\\) e calcolare la probabilit√† che il tempo di attesa tra due episodi di ansia sia compreso tra 2 e 5 ore.\n\n# Parametri posteriori per la distribuzione Gamma\nalpha_post &lt;- 15.009\nbeta_post &lt;- 50.03\n\n# Numero di campioni da generare\nn_samples &lt;- 100000\n\n# Simulazione di campioni dalla distribuzione Gamma per Œª\nlambda_samples &lt;- rgamma(n_samples, shape = alpha_post, rate = beta_post)\n\n# Conversione dei campioni di Œª in tempi di attesa T = 1/Œª\nwaiting_time_samples &lt;- 1 / lambda_samples\n\n# Calcolo della probabilit√† che il tempo di attesa sia compreso tra 2 e 5 ore\nprob_between_2_and_5_mc &lt;-\n  mean(waiting_time_samples &gt;= 2 & waiting_time_samples &lt;= 5)\n\n# Stampa del risultato\ncat(sprintf(\"Probabilit√† che il tempo di attesa sia tra 2 e 5 ore: %.4f\\n\", prob_between_2_and_5_mc))\n#&gt; Probabilit√† che il tempo di attesa sia tra 2 e 5 ore: 0.9027\n\nLa probabilit√† che il tempo di attesa tra due episodi di ansia sia compreso tra 2 e 5 ore √® di circa 0.9029, ovvero il 90.3%. Questa stima si basa su campioni simulati dalla distribuzione a posteriori di \\(\\lambda\\), trasformati nei corrispondenti tempi di attesa. L‚Äôapproccio Monte Carlo √® utile per calcolare probabilit√† che coinvolgono trasformazioni non lineari, come nel caso del tempo di attesa.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>¬† <span class='chapter-title'>Modello gamma-esponenziale üî∏</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_gamma_exponential_model.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/10_gamma_exponential_model.html#riflessioni-conclusive",
    "title": "48¬† Modello gamma-esponenziale üî∏",
    "section": "48.6 Riflessioni Conclusive",
    "text": "48.6 Riflessioni Conclusive\nIl modello esponenziale si rivela uno strumento utile e versatile nella ricerca psicologica, in particolare per la modellazione di fenomeni caratterizzati da tempi di attesa o durate di eventi. √à applicabile in vari contesti, tra cui l‚Äôanalisi dei tempi di reazione, lo studio degli intervalli tra episodi di ansia o depressione e, pi√π in generale, in tutti quei processi psicologici che possono essere descritti come il tempo trascorso fino al verificarsi di un evento.\nUn aspetto particolarmente vantaggioso dell‚Äôuso di modelli basati sulla distribuzione esponenziale nell‚Äôinferenza bayesiana √® la possibilit√† di utilizzare le famiglie coniugate. Nella famiglia coniugata Gamma-Esponenziale, la distribuzione a priori Gamma per il tasso \\(\\lambda\\) si aggiorna in modo analitico quando si osservano nuovi dati esponenziali. Questo rende i calcoli bayesiani particolarmente efficienti e semplici da implementare, poich√© la distribuzione a posteriori rimane della stessa forma della distribuzione a priori (ossia, una Gamma). Tale propriet√† coniugata consente di ottenere una stima aggiornata del tasso \\(\\lambda\\) e di fare inferenze accurate sui tempi di attesa futuri.\nLa combinazione tra la distribuzione esponenziale e il prior Gamma non solo semplifica l‚Äôinferenza, ma fornisce anche una struttura interpretativa chiara. Ad esempio, il parametro \\(\\lambda\\), che rappresenta il tasso di occorrenza di un fenomeno, viene aggiornato sulla base dell‚Äôevidenza osservata, consentendo una stima dinamica della frequenza con cui gli episodi si verificano. Questo approccio bayesiano offre un‚Äôinterpretazione probabilistica naturale dei tempi di attesa futuri, rispecchiando l‚Äôincertezza presente nei dati.\nInoltre, grazie alla flessibilit√† del metodo Monte Carlo, √® possibile simulare campioni dalla distribuzione a posteriori di \\(\\lambda\\) e ottenere stime precise per una vasta gamma di probabilit√†, come la probabilit√† che il tempo di attesa sia compreso tra intervalli specifici. Questo approccio simulativo permette di rispondere a domande specifiche relative ai processi psicologici, ad esempio la probabilit√† che un episodio di ansia duri pi√π di un certo numero di ore.\nIn conclusione, il modello esponenziale, integrato in un framework bayesiano con famiglie coniugate, rappresenta un utile strumento per la ricerca psicologica. Offre un modo rigoroso per modellare e analizzare dati su tempi di attesa e durate, fornendo al contempo una base solida per l‚Äôinferenza e la previsione dei processi psicologici.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>¬† <span class='chapter-title'>Modello gamma-esponenziale üî∏</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_gamma_exponential_model.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/10_gamma_exponential_model.html#informazioni-sullambiente-di-sviluppo",
    "title": "48¬† Modello gamma-esponenziale üî∏",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: US/Pacific\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] ggokabeito_0.1.0 see_0.9.0        gridExtra_2.3    patchwork_1.3.0 \n#&gt;  [5] bayesplot_1.11.1 psych_2.4.12     scales_1.3.0     markdown_1.13   \n#&gt;  [9] knitr_1.49       lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1   \n#&gt; [13] dplyr_1.1.4      purrr_1.0.2      readr_2.1.5      tidyr_1.3.1     \n#&gt; [17] tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3       \n#&gt; [21] here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.3         rlang_1.1.4       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       tools_4.4.2       parallel_4.4.2    tzdb_0.4.0       \n#&gt; [21] colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5       R6_2.5.1         \n#&gt; [25] lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.1    \n#&gt; [29] gtable_0.3.6      glue_1.8.0        xfun_0.50         tidyselect_1.2.1 \n#&gt; [33] farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-166      rmarkdown_2.29   \n#&gt; [37] compiler_4.4.2",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>¬† <span class='chapter-title'>Modello gamma-esponenziale üî∏</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_post_pred_distr.html",
    "href": "chapters/bayesian_inference/11_post_pred_distr.html",
    "title": "49¬† Distribuzione predittiva a posteriori",
    "section": "",
    "text": "49.1 Introduzione\nNel contesto dell‚Äôinferenza bayesiana, uno degli obiettivi principali √® non solo stimare i parametri di un modello (ad esempio, la probabilit√† \\(p\\) di successo in un esperimento binomiale) ma anche fare previsioni su dati futuri basandosi su ci√≤ che abbiamo osservato. La distribuzione predittiva a posteriori risponde proprio a questa esigenza, combinando:\nIn termini semplici, la distribuzione predittiva a posteriori ci dice quali risultati futuri sono plausibili, dato ci√≤ che sappiamo dai dati osservati e dal modello.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>¬† <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_post_pred_distr.html#introduzione",
    "href": "chapters/bayesian_inference/11_post_pred_distr.html#introduzione",
    "title": "49¬† Distribuzione predittiva a posteriori",
    "section": "",
    "text": "La nostra incertezza sui parametri descritta dalla distribuzione a posteriori.\nLa variabilit√† intrinseca del processo che genera i dati futuri.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>¬† <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_post_pred_distr.html#definizione-formale",
    "href": "chapters/bayesian_inference/11_post_pred_distr.html#definizione-formale",
    "title": "49¬† Distribuzione predittiva a posteriori",
    "section": "49.2 Definizione Formale",
    "text": "49.2 Definizione Formale\nSupponiamo di avere un insieme di dati osservati \\(y = \\{y_1, y_2, \\ldots, y_n\\}\\), generati da un modello che dipende da un parametro sconosciuto \\(\\theta\\). Il parametro \\(\\theta\\) pu√≤ rappresentare qualsiasi caratteristica del modello, come una probabilit√† di successo, una media, o un coefficiente in un modello di regressione. Inizialmente, la nostra conoscenza su \\(\\theta\\) √® rappresentata dalla distribuzione a priori \\(p(\\theta)\\), che riflette ci√≤ che sappiamo (o non sappiamo) su \\(\\theta\\) prima di osservare i dati.\nDopo aver osservato i dati \\(y\\), possiamo aggiornare la nostra conoscenza su \\(\\theta\\) utilizzando la formula di Bayes per calcolare la distribuzione a posteriori \\(p(\\theta \\mid y)\\):\n\\[\np(\\theta \\mid y) = \\frac{p(y \\mid \\theta) p(\\theta)}{p(y)},\n\\]\ndove:\n\n\\(p(\\theta \\mid y)\\): la distribuzione a posteriori rappresenta la nostra conoscenza aggiornata su \\(\\theta\\) dopo aver osservato i dati.\n\\(p(y \\mid \\theta)\\): la verosimiglianza √® la probabilit√† di osservare i dati dati i parametri del modello.\n\\(p(\\theta)\\): la distribuzione a priori rappresenta la conoscenza iniziale su \\(\\theta\\).\n\\(p(y)\\): l‚Äôevidenza √® la probabilit√† totale dei dati osservati, calcolata come:\n\\[\np(y) = \\int p(y \\mid \\theta) p(\\theta) \\, d\\theta.\n\\]\n\n\n\n49.2.1 Previsione di Nuovi Dati\nQuando vogliamo prevedere un nuovo dato, indicato con \\(\\tilde{y}\\), la nostra attenzione si sposta sulla distribuzione predittiva a posteriori, \\(p(\\tilde{y} \\mid y)\\).\n\n49.2.1.1 Cosa rappresenta \\(\\tilde{y}\\)?\n\n\\(\\tilde{y}\\) rappresenta un dato futuro o non osservato. Ad esempio, se i dati \\(y\\) rappresentano il numero di successi osservati in una serie di lanci di una moneta, \\(\\tilde{y}\\) potrebbe rappresentare il numero di successi in una nuova serie di lanci.\nL‚Äôobiettivo √® stimare \\(p(\\tilde{y} \\mid y)\\), cio√® la probabilit√† del nuovo dato \\(\\tilde{y}\\) dato ci√≤ che abbiamo osservato in \\(y\\).\n\n\n\n49.2.1.2 Cosa rappresenta \\(p(\\tilde{y} \\mid \\theta)\\)?\n\n\\(p(\\tilde{y} \\mid \\theta)\\) √® la probabilit√† del nuovo dato \\(\\tilde{y}\\) dato un particolare valore del parametro \\(\\theta\\).\nAd esempio, in un modello binomiale, \\(p(\\tilde{y} \\mid \\theta)\\) corrisponde alla probabilit√† di ottenere \\(\\tilde{y}\\) successi su \\(n_{\\text{new}}\\) prove, data la probabilit√† di successo \\(\\theta\\).\n\n\n\n49.2.1.3 Combinazione di \\(p(\\tilde{y} \\mid \\theta)\\) con \\(p(\\theta \\mid y)\\)\nPoich√© non conosciamo esattamente \\(\\theta\\), dobbiamo considerare tutte le possibili ipotesi su \\(\\theta\\), pesandole in base alla loro probabilit√† a posteriori \\(p(\\theta \\mid y)\\). Questo porta alla formula per la distribuzione predittiva a posteriori:\n\\[\np(\\tilde{y} \\mid y) = \\int p(\\tilde{y} \\mid \\theta) p(\\theta \\mid y) \\, d\\theta.\n\\]\n\n\n49.2.1.4 Interpretazione\n\nLa distribuzione predittiva a posteriori, \\(p(\\tilde{y} \\mid y)\\), rappresenta la nostra miglior stima della probabilit√† del nuovo dato \\(\\tilde{y}\\), tenendo conto sia dei dati osservati \\(y\\) sia dell‚Äôincertezza su \\(\\theta\\).\n\n\n\n\n49.2.2 Caso Discreto\nSe il parametro \\(\\theta\\) assume un numero finito di valori, l‚Äôintegrale si semplifica in una somma:\n\\[\np(\\tilde{y} \\mid y) = \\sum_{\\theta} p(\\tilde{y} \\mid \\theta) p(\\theta \\mid y).\n\\]\nQuesto approccio √® utile nei modelli discreti o quando si approssimano i parametri con un numero finito di valori campionati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>¬† <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_post_pred_distr.html#il-caso-beta-binomiale",
    "href": "chapters/bayesian_inference/11_post_pred_distr.html#il-caso-beta-binomiale",
    "title": "49¬† Distribuzione predittiva a posteriori",
    "section": "49.3 Il Caso Beta-Binomiale",
    "text": "49.3 Il Caso Beta-Binomiale\nConsideriamo un classico esperimento binomiale: lanciare una moneta \\(n\\) volte e osservare il numero di successi \\(y\\) (ad esempio, il numero di ‚Äúteste‚Äù). In un contesto bayesiano, il processo di analisi si articola in tre fasi:\n\nDistribuzione a Priori: Prima di osservare i dati, formuliamo una distribuzione a priori sulla probabilit√† \\(p\\) di successo, che riflette le nostre conoscenze iniziali (o la loro assenza). Una scelta comune √® la distribuzione Beta(\\(\\alpha, \\beta\\)), perch√© √® flessibile e ben definita per probabilit√†. Per esempio:\n\n\\(\\alpha\\) rappresenta il numero ‚Äúfittizio‚Äù di successi osservati.\n\\(\\beta\\) rappresenta il numero ‚Äúfittizio‚Äù di insuccessi osservati.\n\nDistribuzione a Posteriori: Dopo aver osservato \\(y\\) successi su \\(n\\) prove, aggiorniamo la distribuzione a priori combinandola con i dati osservati, ottenendo la distribuzione a posteriori di \\(p\\):\n\\[\n\\alpha_{\\text{post}} = \\alpha_{\\text{prior}} + y, \\quad \\beta_{\\text{post}} = \\beta_{\\text{prior}} + (n - y).\n\\]\nQuesta distribuzione rappresenta ci√≤ che sappiamo di \\(p\\) dopo aver osservato i dati.\nDistribuzione Predittiva a Posteriori: Per prevedere il numero di successi futuri \\(y_{\\text{new}}\\) in un nuovo esperimento con \\(n_{\\text{new}}\\) prove, combiniamo la distribuzione a posteriori di \\(p\\) con la variabilit√† intrinseca del processo binomiale. In pratica:\n\nCampioniamo \\(p\\) dalla distribuzione a posteriori (\\(p \\sim \\text{Beta}(\\alpha_{\\text{post}}, \\beta_{\\text{post}})\\)).\nUsiamo ciascun campione di \\(p\\) per simulare nuovi dati (\\(y_{\\text{new}} \\sim \\text{Binomiale}(n_{\\text{new}}, p)\\)).\n\n\nQuesto processo tiene conto sia dell‚Äôincertezza sui parametri (\\(p\\)) sia della variabilit√† intrinseca nei dati futuri.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>¬† <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_post_pred_distr.html#simulazione-della-distribuzione-predittiva-a-posteriori",
    "href": "chapters/bayesian_inference/11_post_pred_distr.html#simulazione-della-distribuzione-predittiva-a-posteriori",
    "title": "49¬† Distribuzione predittiva a posteriori",
    "section": "49.4 Simulazione della Distribuzione Predittiva a Posteriori",
    "text": "49.4 Simulazione della Distribuzione Predittiva a Posteriori\n\n49.4.1 Impostazione dei Parametri\n\nSupponiamo di aver osservato \\(y = 70\\) successi su \\(n = 100\\) prove.\nUtilizziamo una distribuzione a priori Beta(\\(2, 2\\)), che rappresenta una conoscenza iniziale debolmente informativa, con una leggera preferenza per \\(p \\approx 0.5\\).\n\n\n\n49.4.2 Calcolo della Distribuzione a Posteriori\n\nAggiorniamo la distribuzione a priori con i dati osservati. I parametri aggiornati sono:\n\\[\n\\alpha_{\\text{post}} = \\alpha_{\\text{prior}} + y = 2 + 70 = 72, \\quad \\beta_{\\text{post}} = \\beta_{\\text{prior}} + (n - y) = 2 + 30 = 32.\n\\]\nLa distribuzione a posteriori √® quindi \\(p \\sim \\text{Beta}(72, 32)\\), che descrive la probabilit√† aggiornata di successo basata sui dati.\n\n\n\n49.4.3 Simulazione dei Dati Futuri\n\nGeneriamo \\(n_{\\text{sim}} = 1000\\) campioni di \\(p\\) dalla distribuzione a posteriori Beta(72, 32).\nPer ogni campione di \\(p\\), simuliamo \\(y_{\\text{new}}\\), il numero di successi futuri su \\(n_{\\text{new}} = 10\\) prove, utilizzando la distribuzione binomiale:\n\\[\ny_{\\text{new}} \\sim \\text{Binomiale}(n_{\\text{new}} = 10, p).\n\\]\nInfine, convertiamo \\(y_{\\text{new}}\\) in proporzioni predette:\n\\[\n\\text{Proporzione predetta} = \\frac{y_{\\text{new}}}{n_{\\text{new}}}.\n\\]\n\n\n# Impostazione del seed per riproducibilit√†\nset.seed(123)\n\n# Parametri osservati\ny &lt;- 70\nn &lt;- 100\n\n# Parametri a priori\nalpha_prior &lt;- 2\nbeta_prior &lt;- 2\n\n# Calcolo dei parametri a posteriori\nalpha_post &lt;- alpha_prior + y\nbeta_post &lt;- beta_prior + (n - y)\n\n# Simulazione della distribuzione a posteriori\np_samples &lt;- rbeta(1000, alpha_post, beta_post)\n\n# Simulazione di nuovi dati per n_new = 10\ny_preds &lt;- sapply(p_samples, function(p) {\n  rbinom(1, 10, p)\n})\n\n# Calcolo delle proporzioni predette\nprop_preds &lt;- y_preds / 10\n\n\n\n49.4.4 Risultati Attesi\n\nDistribuzione a Posteriori di \\(p\\):\n\nCentrata attorno a \\(0.7\\), con una varianza ridotta grazie alla dimensione del campione \\(n = 100\\).\n\nDistribuzione Predittiva per \\(n_{\\text{new}} = 10\\):\n\nVariabilit√† pi√π ampia rispetto a \\(p\\), dovuta al numero ridotto di prove (\\(n_{\\text{new}} = 10\\)).\nRiflette sia l‚Äôincertezza su \\(p\\) sia la variabilit√† intrinseca dei dati futuri.\n\n\n\n# Visualizzazione\npar(mfrow = c(1, 2))\ncurve(dbeta(x, alpha_prior, beta_prior), from = 0, to = 1, \n      main = \"Distribuzione a Priori\", col = \"blue\", lwd = 2)\ncurve(dbeta(x, alpha_post, beta_post), from = 0, to = 1, \n      main = \"Distribuzione a Posteriori\", col = \"red\", lwd = 2)\n\n\n\n\n\n\n\n\n\nhist(prop_preds, breaks = 20, col = \"lightblue\", freq = FALSE,\n     main = \"Distribuzione Predittiva (n_new = 10)\",\n     xlab = \"Proporzione di Successi\")\nabline(v = y / n, col = \"blue\", lwd = 3, lty = 2)\n\n\n\n\n\n\n\n\n\n\n49.4.5 Spiegazione del Codice\nSimulazione di nuovi dati per \\(n_{\\text{new}} = 10\\):\ny_preds &lt;- sapply(p_samples, function(p) {\n  rbinom(1, 10, p)\n})\n\np_samples contiene \\(1000\\) valori di \\(p\\) simulati dalla distribuzione Beta(72, 32).\nPer ciascun \\(p\\), rbinom(1, 10, p) genera un valore di \\(y_{\\text{new}}\\), simulando il numero di successi futuri su \\(n_{\\text{new}} = 10\\) prove.\n\nRisultato: un vettore di 1000 valori di \\(y_{\\text{new}}\\), uno per ciascun campione di \\(p\\).\nCalcolo delle proporzioni predette:\nprop_preds &lt;- y_preds / 10\n\nDivide ciascun valore di \\(y_{\\text{new}}\\) per \\(n_{\\text{new}} = 10\\), ottenendo le proporzioni di successi predette.\n\nRisultato: un vettore di 1000 proporzioni predette (\\(y_{\\text{new}} / n_{\\text{new}}\\)).\n\n\n49.4.6 Interpretazione\n\nLa distribuzione a posteriori di \\(p\\), Beta(72, 32), √® centrata attorno a \\(p \\approx 0.7\\), coerente con i dati osservati (\\(y / n = 0.7\\)).\nLe proporzioni predette mostrano la variabilit√† combinata dell‚Äôincertezza su \\(p\\) (dalla distribuzione a posteriori) e della variabilit√† binomiale per un campione futuro di 10 prove.\nL‚Äôistogramma delle proporzioni predette √® pi√π ampio rispetto alla distribuzione a posteriori di \\(p\\), riflettendo l‚Äôincertezza aggiuntiva derivante dal numero ridotto di prove (\\(n_{\\text{new}} = 10\\)).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>¬† <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_post_pred_distr.html#posterior-predictive-check-pp-check",
    "href": "chapters/bayesian_inference/11_post_pred_distr.html#posterior-predictive-check-pp-check",
    "title": "49¬† Distribuzione predittiva a posteriori",
    "section": "49.5 Posterior Predictive Check (PP-Check)",
    "text": "49.5 Posterior Predictive Check (PP-Check)\nLa distribuzione predittiva a posteriori ottenuta dalla simulazione (\\(n_{\\text{new}} = 10\\)) pu√≤ essere utilizzata per effettuare un Posterior Predictive Check (PP-Check). Questo controllo confronta i dati osservati con i dati simulati dal modello per verificare se il modello √® in grado di riprodurre caratteristiche rilevanti dei dati osservati.\nIn questa simulazione, il Posterior Predictive-Check suggerisce che il modello √® ben specificato per i dati osservati (\\(y = 70\\), \\(n = 100\\)): la proporzione osservata (\\(0.7\\)) √® vicina al centro della distribuzione predittiva. Questo significa che il modello pu√≤ essere considerato valido per fare previsioni sui dati futuri, almeno nel contesto specificato.\n\n\n\n\n\n\nIl fatto che la distribuzione predittiva a posteriori rappresenti accuratamente la proporzione osservata pu√≤ sembrare ovvio nel caso presente. Questo avviene perch√© stiamo lavorando con un modello semplice e ben specificato, utilizzato qui con l‚Äôintento di chiarire la logica del concetto di distribuzione predittiva a posteriori. Tuttavia, nei modelli pi√π complessi, tipici delle indagini psicologiche, la corrispondenza tra i dati osservati e quelli predetti dal modello non pu√≤ mai essere data per scontata. √à essenziale verificarla attraverso la distribuzione predittiva a posteriori.\nSe i dati osservati non sono ben rappresentati dalla distribuzione predittiva a posteriori, ci√≤ indica che il modello non √® adeguato a spiegare i dati e necessita di revisione. Questo processo di verifica non solo garantisce la coerenza del modello con i dati disponibili, ma consente anche di identificare eventuali aree problematiche nella specificazione del modello, come prior inappropriati o assunzioni non realistiche. In definitiva, il confronto tra i dati osservati e quelli predetti √® un passo fondamentale per la validazione di modelli complessi in contesti psicologici e scientifici.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>¬† <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_post_pred_distr.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/11_post_pred_distr.html#riflessioni-conclusive",
    "title": "49¬† Distribuzione predittiva a posteriori",
    "section": "49.6 Riflessioni Conclusive",
    "text": "49.6 Riflessioni Conclusive\nLa distribuzione predittiva a posteriori √® uno strumento centrale nell‚Äôinferenza bayesiana, poich√© consente di fare previsioni sui dati futuri integrando l‚Äôincertezza sui parametri del modello con la variabilit√† intrinseca del processo generativo. Questa capacit√† va oltre la semplice stima dei parametri, permettendo di confrontare le previsioni del modello con i dati reali, un passaggio fondamentale per verificare la coerenza e l‚Äôutilit√† del modello stesso.\nNel flusso di lavoro bayesiano, la distribuzione predittiva a posteriori svolge un ruolo chiave nella valutazione del modello. Ad esempio, consente di effettuare controlli predittivi a posteriori per identificare discrepanze tra i dati osservati e quelli previsti. Tali controlli aiutano a diagnosticare problemi di specificazione del modello, a valutare l‚Äôadeguatezza delle scelte a priori e a guidare eventuali revisioni del modello.\nInoltre, il caso beta-binomiale utilizzato in questo capitolo rappresenta un esempio intuitivo e potente: evidenzia come l‚Äôincertezza sui parametri possa essere tradotta in previsioni probabilistiche robuste, senza la necessit√† di fare assunzioni rigide o non realistiche. Questo approccio non solo formalizza l‚Äôincertezza in modo rigoroso, ma permette anche di comunicare le previsioni in modo trasparente e interpretabile, caratteristiche essenziali in ambito decisionale e scientifico.\nIn sintesi, la distribuzione predittiva a posteriori √® un elemento fondamentale della modellazione bayesiana, che lega l‚Äôinferenza paramatrica alla previsione empirica, contribuendo a rendere l‚Äôintero processo inferenziale pi√π affidabile, interpretabile e applicabile a scenari complessi.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>¬† <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_post_pred_distr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/11_post_pred_distr.html#informazioni-sullambiente-di-sviluppo",
    "title": "49¬† Distribuzione predittiva a posteriori",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: US/Pacific\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] ggokabeito_0.1.0 see_0.9.0        gridExtra_2.3    patchwork_1.3.0 \n#&gt;  [5] bayesplot_1.11.1 psych_2.4.12     scales_1.3.0     markdown_1.13   \n#&gt;  [9] knitr_1.49       lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1   \n#&gt; [13] dplyr_1.1.4      purrr_1.0.2      readr_2.1.5      tidyr_1.3.1     \n#&gt; [17] tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3       \n#&gt; [21] here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.3         rlang_1.1.4       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       yaml_2.3.10       tools_4.4.2       parallel_4.4.2   \n#&gt; [21] tzdb_0.4.0        colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5      \n#&gt; [25] R6_2.5.1          lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3  \n#&gt; [29] pillar_1.10.1     gtable_0.3.6      glue_1.8.0        xfun_0.50        \n#&gt; [33] tidyselect_1.2.1  farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-166     \n#&gt; [37] rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>¬† <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_post_pred_distr.html#bibliografia",
    "href": "chapters/bayesian_inference/11_post_pred_distr.html#bibliografia",
    "title": "49¬† Distribuzione predittiva a posteriori",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nSchoot, R. van de, Depaoli, S., King, R., Kramer, B., M√§rtens, K., Tadesse, M. G., Vannucci, M., Gelman, A., Veen, D., Willemsen, J., et al. (2021). Bayesian statistics and modelling. Nature Reviews Methods Primers, 1(1), 1.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>¬† <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/introduction_mcmc.html",
    "href": "chapters/mcmc/introduction_mcmc.html",
    "title": "Introduzione",
    "section": "",
    "text": "In questa sezione della dispensa, ci concentreremo sulle procedure Monte Carlo a catena di Markov, con particolare attenzione all‚Äôalgoritmo di Metropolis, che consente di approssimare la distribuzione a posteriori quando non √® possibile ottenere una soluzione analitica. Esploreremo il concetto di predizione bayesiana, fondamentale per la costruzione della distribuzione predittiva a posteriori, e discuteremo anche la distribuzione predittiva a priori. Applicheremo l‚Äôinferenza bayesiana a diversi contesti, tra cui la stima di una proporzione, il confronto tra due proporzioni, la stima di una media da una distribuzione normale e il confronto tra due medie. Esamineremo inoltre il modello bayesiano di Poisson per l‚Äôanalisi delle frequenze. Infine, introdurremo il modello gerarchico bayesiano, uno strumento potente per affrontare situazioni in cui le osservazioni sono strutturate su diversi livelli di incertezza.",
    "crumbs": [
      "MCMC",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html",
    "href": "chapters/mcmc/01_metropolis.html",
    "title": "50¬† L‚Äôalgoritmo di Metropolis-Hastings",
    "section": "",
    "text": "50.1 Introduzione\nIn precedenza, abbiamo esplorato diversi esempi di inferenza bayesiana riguardanti la distribuzione a posteriori di un singolo parametro, come nel caso del modello bernoulliano. Abbiamo anche trattato metodi come l‚Äôapprossimazione tramite griglia e l‚Äôutilizzo dei priori coniugati per ottenere o approssimare la distribuzione a posteriori. In questo capitolo, ci concentreremo sul metodo di simulazione Monte Carlo a Catena di Markov (MCMC).\nIl metodo MCMC √® una tecnica computazionale utilizzata per approssimare distribuzioni di probabilit√† complesse, generando una sequenza di campioni (correlati) attraverso una catena di Markov, in cui ogni campione viene ottenuto tramite una transizione iterativa con probabilit√† attentamente progettate.\nIl metodo MCMC rappresenta l‚Äôapproccio moderno per approssimare distribuzioni a posteriori complesse. L‚Äôidea di base √® simile al concetto di considerare la distribuzione a posteriori come una popolazione da cui estraiamo campioni ripetutamente. Con un numero sufficientemente grande di campioni (ad esempio 1000), la distribuzione del campione si avvicina molto alla distribuzione della popolazione, consentendo stime affidabili dei parametri incogniti.\nUna differenza rispetto all‚Äôanalogia precedente √® che i campioni generati con MCMC sono correlati: se il primo campione ha un valore alto, anche il successivo ha maggiori probabilit√† di essere alto. Questo accade perch√© non abbiamo un modo diretto per estrarre campioni dalla distribuzione a posteriori, che spesso ha una forma molto complessa; utilizziamo invece algoritmi che ci permettono di arrivarci indirettamente. La correlazione tra i campioni non rappresenta un problema rilevante, ma rende necessario estrarre un numero maggiore di campioni per compensare questa correlazione e ottenere stime accurate.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>50</span>¬† <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#il-denominatore-bayesiano",
    "href": "chapters/mcmc/01_metropolis.html#il-denominatore-bayesiano",
    "title": "50¬† L‚Äôalgoritmo di Metropolis-Hastings",
    "section": "50.2 Il denominatore bayesiano",
    "text": "50.2 Il denominatore bayesiano\nNell‚Äôapproccio bayesiano, l‚Äôobiettivo principale √® determinare la distribuzione a posteriori \\(p(\\theta \\mid y)\\) di un parametro \\(\\theta\\), utilizzando i dati osservati \\(y\\) e la distribuzione a priori \\(p(\\theta)\\). Questo si ottiene attraverso il teorema di Bayes:\n\\[\np(\\theta \\mid y) = \\frac{p(y \\mid \\theta) p(\\theta)}{\\int p(y \\mid \\theta) p(\\theta) d\\theta}.\n\\]\nIl denominatore \\(\\int p(y \\mid \\theta) p(\\theta) d\\theta\\) rappresenta la probabilit√† marginale di \\(y\\), chiamata evidenza. Tale integrale garantisce che \\(p(\\theta \\mid y)\\) sia una distribuzione di probabilit√† valida. Tuttavia, il calcolo di questo integrale √® spesso complesso, soprattutto in modelli articolati o ad alta dimensionalit√†, rendendo difficile ottenere una rappresentazione esplicita della distribuzione a posteriori.\nUna possibile semplificazione analitica √® l‚Äôuso di distribuzioni a priori coniugate, che offrono una soluzione esatta per la distribuzione a posteriori. Tuttavia, questo approccio √® limitato a casi specifici e impone forti vincoli sulla scelta delle distribuzioni a priori e delle verosimiglianze.\nUn approccio pi√π generale √® ricorrere a soluzioni numeriche. In precedenza abbiamo discusso il metodo di campionamento a griglia. Tuttavia, i metodi di campionamento a griglia, sebbene efficaci per modelli con pochi parametri, diventano impraticabili man mano che il numero di parametri aumenta, poich√© richiedono una copertura densa dell‚Äôintero spazio parametrico. Di conseguenza, per modelli pi√π complessi e con pi√π parametri, si rende necessario un metodo che possa esplorare lo spazio dei parametri in maniera pi√π efficiente.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>50</span>¬† <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#il-metodo-monte-carlo-e-le-sue-limitazioni",
    "href": "chapters/mcmc/01_metropolis.html#il-metodo-monte-carlo-e-le-sue-limitazioni",
    "title": "50¬† L‚Äôalgoritmo di Metropolis-Hastings",
    "section": "50.3 Il metodo Monte Carlo e le sue limitazioni",
    "text": "50.3 Il metodo Monte Carlo e le sue limitazioni\nIl metodo Monte Carlo fornisce una soluzione a questo problema generando campioni casuali dalla distribuzione a posteriori \\(p(\\theta \\mid y)\\). L‚Äôidea centrale √® semplice: se possiamo generare un numero sufficiente di campioni casuali dalla distribuzione a posteriori, possiamo usare questi campioni per stimare le propriet√† d‚Äôinteresse, come la media o la varianza del parametro \\(\\theta\\). Questa procedura ci permette di evitare il calcolo diretto dell‚Äôintegrale complicato nel denominatore del teorema di Bayes.\nPer esempio, se fossimo in grado di generare una serie di campioni \\(\\theta^{(1)}, \\theta^{(2)}, \\dots, \\theta^{(T)}\\) dalla distribuzione a posteriori, potremmo approssimare il valore atteso di \\(\\theta\\) con la media campionaria:\n\\[\n\\mathbb{E}[\\theta] \\approx \\frac{1}{T} \\sum_{t=1}^T \\theta^{(t)}.\n\\]\nTuttavia, un problema significativo nei metodi Monte Carlo tradizionali √® che generare campioni indipendenti dalla distribuzione a posteriori non √® semplice, soprattutto quando questa distribuzione ha una forma complessa, √® multimodale o definita su spazi di alta dimensionalit√†. Le regioni di alta densit√†, che contribuiscono maggiormente al valore dell‚Äôintegrale, possono essere difficili da individuare e campionare adeguatamente. Per ottenere una buona copertura dello spazio dei parametri, sarebbe necessario generare un numero enorme di campioni, rendendo il metodo Monte Carlo inefficiente e computazionalmente oneroso.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>50</span>¬† <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#perch√©-i-metodi-mcmc-sono-necessari",
    "href": "chapters/mcmc/01_metropolis.html#perch√©-i-metodi-mcmc-sono-necessari",
    "title": "50¬† L‚Äôalgoritmo di Metropolis-Hastings",
    "section": "50.4 Perch√© i metodi MCMC sono necessari",
    "text": "50.4 Perch√© i metodi MCMC sono necessari\n√à qui che entrano in gioco i Metodi Monte Carlo a Catena di Markov (MCMC). Questi metodi risolvono il problema generando campioni dipendenti dalla distribuzione a posteriori, sfruttando la struttura di una catena di Markov. A differenza dei campioni indipendenti utilizzati nei metodi Monte Carlo tradizionali, i metodi MCMC costruiscono una sequenza di campioni, in cui ciascun campione dipende dal precedente. Questa dipendenza permette di esplorare in modo pi√π efficiente le regioni di alta densit√† della distribuzione a posteriori, riducendo il numero di campioni necessari per ottenere stime accurate.\nIn pratica, MCMC consente di evitare di campionare inutilmente da regioni di bassa densit√†, concentrandosi invece sulle aree pi√π rilevanti della distribuzione. Questo approccio √® particolarmente potente nei contesti ad alta dimensionalit√† o in presenza di distribuzioni multimodali, dove i metodi Monte Carlo tradizionali risulterebbero inefficaci o richiederebbero un numero sproporzionato di campioni.\nIn sintesi, i metodi Monte Carlo classici sono limitati quando si tratta di campionare da distribuzioni complesse e multidimensionali. I metodi MCMC, invece, offrono una soluzione efficiente e flessibile, permettendo di esplorare le distribuzioni a posteriori anche in contesti complessi, senza la necessit√† di campionare indipendentemente ogni punto. Nel prossimo paragrafo introdurremo i concetti fondamentali delle catene di Markov e vedremo come queste vengono utilizzate nei metodi MCMC per campionare efficacemente da distribuzioni a posteriori difficili da trattare analiticamente.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>50</span>¬† <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#le-catene-di-markov",
    "href": "chapters/mcmc/01_metropolis.html#le-catene-di-markov",
    "title": "50¬† L‚Äôalgoritmo di Metropolis-Hastings",
    "section": "50.5 Le Catene di Markov",
    "text": "50.5 Le Catene di Markov\nLe catene di Markov, introdotte da Andrey Markov nel 1906, rappresentano un‚Äôestensione della legge dei grandi numeri per descrivere sequenze di variabili casuali non indipendenti (per maggiori dettagli, si veda l‚Äô?sec-appendix-markov-first-order). Nella statistica tradizionale, si lavora spesso con sequenze di variabili casuali indipendenti e identicamente distribuite (i.i.d.), come \\(X_0, X_1, \\ldots, X_n, \\ldots\\), dove ogni variabile √® indipendente dalle altre e segue la stessa distribuzione. Tuttavia, nei modelli pi√π realistici che descrivono fenomeni complessi, l‚Äôindipendenza tra variabili √® un‚Äôassunzione troppo rigida e spesso irrealistica.\nLe catene di Markov superano questo limite introducendo una dipendenza locale, detta dipendenza a un passo, formalizzata nella cosiddetta propriet√† di Markov. Secondo questa propriet√†, il valore futuro di una variabile casuale \\(X_{n+1}\\) dipende unicamente dal valore attuale \\(X_n\\), ignorando tutta la storia precedente della catena. Questo permette di semplificare notevolmente i calcoli relativi alle probabilit√† condizionali. La propriet√† di Markov √® formalmente espressa come:\n\\[\nP(X_{n+1} = j | X_n = i, X_{n-1} = i_{n-1}, \\ldots, X_0 = i_0) = P(X_{n+1} = j | X_n = i).\n\\]\nIn altre parole, la previsione di un evento futuro dipende soltanto dallo stato attuale e non da tutti gli eventi precedenti, semplificando cos√¨ il processo di modellazione. Questa caratteristica rende le catene di Markov particolarmente utili per descrivere sistemi dinamici in cui gli eventi successivi sono influenzati solo dallo stato immediatamente precedente.\n\n50.5.1 Catene di Markov e Metodi MCMC\nLe catene di Markov sono fondamentali nei metodi Monte Carlo a Catena di Markov (MCMC) perch√© forniscono un modo efficiente per generare sequenze di campioni che approssimano distribuzioni di probabilit√† complesse. Mentre i metodi Monte Carlo classici generano campioni indipendenti, i metodi MCMC costruiscono una sequenza di campioni dipendenti attraverso una catena di Markov, in cui ciascun campione √® ottenuto in base al campione precedente. Questo approccio consente di concentrarsi sulle regioni di alta probabilit√† della distribuzione, migliorando l‚Äôefficienza del campionamento.\nPer esempio, consideriamo una distribuzione di probabilit√† \\(P(x_1, x_2, ..., x_n)\\) definita su un insieme di variabili \\(x_1, x_2, ..., x_n\\). Nei metodi MCMC, si genera una sequenza di configurazioni \\(\\{x(0)\\}, \\{x(1)\\}, \\{x(2)\\}, \\dots\\), tale che la frequenza con cui ogni configurazione \\(\\{x\\}\\) viene visitata √® proporzionale alla sua probabilit√† \\(P(x)\\). In questo modo, le configurazioni pi√π probabili vengono visitate pi√π spesso, garantendo che l‚Äôalgoritmo converga alla distribuzione di interesse.\n\n\n50.5.2 Condizioni fondamentali per le Catene di Markov\nAffinch√© un algoritmo MCMC funzioni correttamente e converga alla distribuzione desiderata, la catena di Markov deve soddisfare alcune condizioni fondamentali:\n\nPropriet√† di Markov: La prossima configurazione dipende solo dalla configurazione attuale, non dalla storia passata. Questo garantisce che l‚Äôevoluzione della catena sia ‚Äúlocale‚Äù e non influenzata dagli stati remoti.\nIrriducibilit√†: Ogni configurazione della catena pu√≤ essere raggiunta da qualsiasi altra in un numero finito di passi. Ci√≤ assicura che l‚Äôintero spazio dei parametri possa essere esplorato.\nAperiodicit√†: La catena non segue cicli fissi e non ritorna sistematicamente allo stesso stato dopo un certo numero di passi. Questo garantisce che la catena possa esplorare lo spazio dei parametri in modo casuale.\nCondizione di bilanciamento dettagliato: La probabilit√† di passare da uno stato a un altro deve essere bilanciata dalla probabilit√† di tornare allo stato iniziale, assicurando cos√¨ che la distribuzione di equilibrio della catena sia proprio la distribuzione a posteriori desiderata.\n\n\n\n50.5.3 Algoritmi MCMC\nEsistono diversi algoritmi basati su MCMC, ognuno con caratteristiche specifiche:\n\nMetropolis-Hastings: Questo √® uno degli algoritmi pi√π noti. Si basa sulla generazione di una configurazione proposta che viene accettata o rifiutata in base a un criterio di probabilit√†. Se la configurazione proposta ha una probabilit√† pi√π alta, viene accettata; se ha una probabilit√† pi√π bassa, pu√≤ essere accettata con una certa probabilit√†, che dipende dal rapporto tra le probabilit√† delle due configurazioni.\nGibbs Sampling: In questo algoritmo, le variabili vengono aggiornate una alla volta, campionando ogni variabile dalla sua distribuzione condizionale data la configurazione corrente delle altre variabili. √à particolarmente utile quando le distribuzioni condizionali sono note o facili da campionare.\nHamiltonian Monte Carlo (HMC): Utilizza principi della meccanica hamiltoniana per esplorare lo spazio dei parametri in modo pi√π efficiente, considerando non solo le probabilit√†, ma anche le ‚Äúforze‚Äù che muovono i campioni attraverso lo spazio dei parametri. Questo approccio √® particolarmente vantaggioso per modelli complessi e ad alta dimensionalit√†, poich√© consente di generare campioni lontani dallo stato corrente senza ricorrere a piccoli passi.\n\nIn sintesi, le catene di Markov forniscono il fondamento teorico e pratico per i metodi MCMC, offrendo un modo efficiente per esplorare lo spazio dei parametri nei modelli complessi. Grazie alle propriet√† specifiche delle catene di Markov, i metodi MCMC permettono di affrontare problemi di inferenza bayesiana che sarebbero intrattabili con approcci analitici o con i metodi Monte Carlo classici. Essendo flessibili e potenti, le catene di Markov continueranno a essere uno strumento fondamentale nella statistica e nella scienza dei dati.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>50</span>¬† <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#estrazione-di-campioni-dalla-distribuzione-a-posteriori",
    "href": "chapters/mcmc/01_metropolis.html#estrazione-di-campioni-dalla-distribuzione-a-posteriori",
    "title": "50¬† L‚Äôalgoritmo di Metropolis-Hastings",
    "section": "50.6 Estrazione di campioni dalla distribuzione a posteriori",
    "text": "50.6 Estrazione di campioni dalla distribuzione a posteriori\nIn questo capitolo presenteremo l‚Äôalgoritmo di Metropolis, che √® uno dei pi√π semplici e potenti metodi MCMC. Sfruttando la struttura delle catene di Markov, esplora in modo efficiente lo spazio dei parametri, permettendo di ottenere campioni dalla distribuzione a posteriori anche in casi complessi, dove i metodi analitici falliscono. In sostanza, il MCMC genera un gran numero di valori per il parametro \\(\\theta\\) che, nel loro insieme, approssimano la distribuzione di interesse \\(p(\\theta \\mid y)\\). A questo fine, il capitolo √® strutturato in varie sezioni che facilitano la comprensione progressiva del tema.\n\nInizieremo discutendo di come la distribuzione a posteriori possa essere approssimata mediante tecniche di simulazione convenzionali. Questa prima parte presuppone che la distribuzione target, o ‚Äúa posteriori,‚Äù sia gi√† conosciuta o disponibile per l‚Äôanalisi.\nIn seguito, passeremo a illustrare come l‚Äôalgoritmo di Metropolis possa essere utilizzato per affrontare situazioni in cui la distribuzione a posteriori non √® direttamente nota. In questi casi, spesso abbiamo a disposizione informazioni riguardanti la distribuzione a priori e la funzione di verosimiglianza, che possono essere utilizzate per ottenere un‚Äôapprossimazione efficace della distribuzione a posteriori.\n\nA titolo esemplificativo, utilizzeremo il dataset moma_sample.csv, il quale costituisce un campione casuale di 100 artisti provenienti dal Museo di Arte Moderna di New York (MoMA) e contiene diverse informazioni relative a ciascun artista.\nIl nostro interesse √® focalizzato sulla determinazione della probabilit√† che un artista presente nel MoMA appartenga alla generazione X o a una generazione successiva (nati dopo il 1965). Questa probabilit√† sar√† indicata come \\(\\pi\\).\nImportiamo i dati.\n\nmoma_sample &lt;- rio::import(here::here(\"data\", \"moma_sample.csv\"))\n\nEsaminiamo le prime cinque righe del DataFrame.\n\nmoma_sample |&gt; \n  head()\n#&gt;                artist  country birth death alive  genx gender count\n#&gt; 1        Ad Gerritsen    dutch  1940  2015 FALSE FALSE   male     1\n#&gt; 2 Kirstine Roepstorff   danish  1972    NA  TRUE  TRUE female     3\n#&gt; 3    Lisa Baumgardner american  1958  2015 FALSE FALSE female     2\n#&gt; 4         David Bates american  1952    NA  TRUE FALSE   male     1\n#&gt; 5          Simon Levy american  1946    NA  TRUE FALSE   male     1\n#&gt; 6      Pierre Mercure canadian  1927  1966 FALSE FALSE   male     8\n#&gt;   year_acquired_min year_acquired_max\n#&gt; 1              1981              1981\n#&gt; 2              2005              2005\n#&gt; 3              2016              2016\n#&gt; 4              2001              2001\n#&gt; 5              2012              2012\n#&gt; 6              2008              2008\n\nDai dati osserviamo che solo 14 artisti su 100 appartengono alla generazione X o a una generazione successiva.\n\n# Calcoliamo la distribuzione delle generazioni\nresult &lt;- table(moma_sample$genx)\nresult\n#&gt; \n#&gt; FALSE  TRUE \n#&gt;    86    14\n\nIl valore campionato \\(y = 14\\) riflette le caratteristiche del campione che √® stato osservato. Tuttavia, poich√© il MOMA contiene opere di migliaia di artisti, sorge una domanda riguardante il vero valore di \\(\\theta\\) (la probabilit√† di appartenere alla generazione X o a una generazione successiva) all‚Äôinterno di questa popolazione.\nPossiamo interpretare i dati \\(y = 14\\) come l‚Äôesito di una variabile casuale Binomiale con parametri \\(N = 100\\) e \\(\\theta\\) sconosciuto.\nSupponiamo che le nostre credenze pregresse riguardo a \\(\\theta\\) possano essere modellate attraverso una distribuzione Beta(4, 6).\nSfruttando le propriet√† delle distribuzioni coniugate, possiamo calcolare esattamente la distribuzione a posteriori:\n# Y ~ Binomiale(100, œÄ)\n# Œ∏ ~ Beta(4, 6)\n# Posteriori: Œ∏ | (Y = 14) ~ Beta(4 + 14, 6 + 100 - 14) ‚Üí Beta(18, 92)\nNella figura seguente, √® rappresentata la distribuzione a posteriori del parametro \\(\\theta\\), insieme alla distribuzione a priori specificata.\n\n# Generiamo la sequenza dei valori per Œ∏\nx &lt;- seq(0, 1, length.out = 1000)\n\n# Calcoliamo le densit√† della prior e della posterior\nprior_density &lt;- dbeta(x, 4, 6)\nposterior_density &lt;- dbeta(x, 18, 92)\n\n# Creiamo il grafico\nplot(\n  x, prior_density,\n  type = \"l\", col = \"blue\", lwd = 2,\n  ylim = c(0, max(c(prior_density, posterior_density))),\n  xlab = \"Valore del Parametro\",\n  ylab = \"Densit√†\",\n  main = \"Densit√† a Priori e a Posteriori\"\n)\nlines(x, posterior_density, col = \"red\", lwd = 2)\npolygon(\n  c(x, rev(x)), c(prior_density, rep(0, length(x))),\n  col = adjustcolor(\"blue\", alpha.f = 0.5), border = NA\n)\npolygon(\n  c(x, rev(x)), c(posterior_density, rep(0, length(x))),\n  col = adjustcolor(\"red\", alpha.f = 0.5), border = NA\n)\nlegend(\"topright\",\n  legend = c(\"Prior: Beta(4, 6)\", \"Posterior: Beta(18, 92)\"),\n  fill = c(\n    adjustcolor(\"blue\", alpha.f = 0.5),\n    adjustcolor(\"red\", alpha.f = 0.5)\n  ), border = NA\n)\n\n\n\n\n\n\n\n\nIn questo grafico, la curva blu rappresenta la distribuzione a priori \\(\\text{Beta}(4, 6)\\), mentre la curva rossa mostra la distribuzione a posteriori \\(\\text{Beta}(18, 92)\\). La sovrapposizione delle aree evidenzia come l‚Äôevidenza fornita dai dati modifichi la conoscenza iniziale sul parametro \\(\\theta\\).\nSe vogliamo conoscere il valore della media a posteriori di \\(\\theta\\), il risultato esatto √®\n\\[\n\\bar{\\theta}_{post} = \\frac{\\alpha}{\\alpha + \\beta} = \\frac{18}{18 + 92} \\approx 0.1636.\n\\]\n\n50.6.1 Simulazione con distribuzione target nota\nUsiamo ora una simulazione numerica per stimare la media a posteriori di \\(\\theta\\). Conoscendo la forma della distribuzione a posteriori \\(Beta(18, 92)\\), possiamo generare un campione di osservazioni casuali da questa distribuzione. Successivamente, calcoliamo la media delle osservazioni ottenute per ottenere un‚Äôapprossimazione della media a posteriori.\nSe vogliamo ottenere un risultato approssimato con un numero limitato di campioni (ad esempio, 10), possiamo utilizzare la seguente simulazione:\n\n# Generiamo 10 campioni dalla distribuzione Beta(18, 92)\nset.seed(1)  # Per riproducibilit√†\ny &lt;- rbeta(10, shape1 = 18, shape2 = 92)\ny\n#&gt;  [1] 0.140 0.171 0.132 0.177 0.132 0.184 0.196 0.152 0.242 0.180\n\n\n# Calcoliamo la media dei campioni\nmean(y)\n#&gt; [1] 0.171\n\nTuttavia, con soli 10 campioni, l‚Äôapprossimazione potrebbe non essere molto accurata. Aumentando il numero di campioni, ad esempio a 10.000, possiamo ottenere una stima molto pi√π precisa:\n\n# Generiamo 10.000 campioni e calcoliamo la media\nset.seed(123)  # Per riproducibilit√†\nmean(rbeta(10000, shape1 = 18, shape2 = 92))\n#&gt; [1] 0.164\n\nQuando il numero di campioni dalla distribuzione a posteriori diventa molto grande, la media campionaria converge al valore atteso della distribuzione della popolazione. Questo principio non si applica solo alla media, ma anche ad altre statistiche descrittive come la moda e la varianza.\n√à importante sottolineare che l‚Äôapplicazione della simulazione di Monte Carlo √® efficace per calcolare distribuzioni a posteriori solo quando conosciamo la distribuzione stessa e possiamo utilizzare funzioni Python per estrarre campioni casuali da tale distribuzione. Ci√≤ √® stato possibile nel caso della distribuzione a posteriori \\(Beta(18, 92)\\).\nTuttavia, questa situazione ideale non si verifica sempre nella pratica, poich√© le distribuzioni a priori coniugate alla verosimiglianza sono spesso rare. Per esempio, nel caso di una verosimiglianza binomiale e una distribuzione a priori gaussiana, l‚Äôespressione\n\\[\np(\\theta \\mid y) = \\frac{\\mathrm{e}^{-(\\theta - 1 / 2)^2} \\theta^y (1 - \\theta)^{n - y}} {\\int_0^1 \\mathrm{e}^{-(t - 1 / 2)^2} t^y (1 - t)^{n - y} dt}\n\\]\nrende impossibile calcolare analiticamente la distribuzione a posteriori di \\(\\theta\\), precludendo quindi l‚Äôutilizzo diretto di Python per generare campioni casuali.\nIn queste circostanze, per√≤, √® possibile ottenere campioni casuali dalla distribuzione a posteriori mediante l‚Äôuso di metodi Monte Carlo basati su Catena di Markov (MCMC). Gli algoritmi MCMC, come ad esempio l‚Äôalgoritmo Metropolis, costituiscono una classe di metodi che consentono di estrarre campioni casuali dalla distribuzione a posteriori senza richiedere la conoscenza della sua rappresentazione analitica. Le tecniche MCMC sono ampiamente adottate per risolvere problemi di inferenza bayesiana e rappresentano il principale strumento computazionale per ottenere stime approssimate di distribuzioni a posteriori in situazioni complesse e non analiticamente trattabili.\n\n\n50.6.2 Algoritmo di Metropolis\nL‚Äôalgoritmo di Metropolis appartiene alla famiglia dei metodi Monte Carlo basati su catene di Markov (MCMC), sfruttando le propriet√† di queste catene per generare campioni da una distribuzione target. Il suo obiettivo principale √® di esplorare lo spazio dei parametri in modo efficiente, producendo campioni che approssimano la distribuzione a posteriori di interesse.\n\n\n50.6.3 Principio di Funzionamento\nL‚Äôalgoritmo inizia da un valore iniziale per i parametri e, in ogni iterazione, genera un nuovo campione tramite una distribuzione di proposta (solitamente una distribuzione normale centrata sul valore corrente). Successivamente, decide se accettare il nuovo campione in base al confronto tra le densit√† posteriori del nuovo campione e di quello precedente. Questa accettazione avviene in modo probabilistico, favorendo campioni con una densit√† pi√π alta ma consentendo anche l‚Äôaccettazione di campioni peggiori per evitare che la catena rimanga bloccata in minimi locali.\n\n\n50.6.4 Burn-in e Convergenza\nPoich√© i primi campioni potrebbero non rappresentare bene la distribuzione target, si esclude spesso una porzione iniziale della catena (fase di burn-in). Con il progredire delle iterazioni, i campioni si distribuiscono in accordo con la distribuzione stazionaria desiderata, indipendentemente dallo stato iniziale scelto. Questo processo permette di esplorare lo spazio dei parametri in modo efficiente.\n\n\n50.6.5 Meccanismo di Accettazione e Rifiuto\nL‚Äôalgoritmo di Metropolis bilancia due esigenze opposte:\n\nEsplorazione di nuove aree dello spazio dei parametri.\nSfruttamento delle informazioni gi√† acquisite dai campioni precedenti.\n\nUtilizzando una regola probabilistica per accettare campioni peggiori (con minore densit√† a posteriori), l‚Äôalgoritmo evita di restare intrappolato in minimi locali, esplorando cos√¨ in modo pi√π completo l‚Äôintera distribuzione.\n\n\n50.6.6 Passaggi Fondamentali dell‚ÄôAlgoritmo di Metropolis\n\nScelta di uno stato iniziale \\(\\theta_1\\) e impostazione del contatore \\(t = 1\\).\n\nQuesto √® il punto di partenza della catena, dove \\(\\theta_1\\) rappresenta il primo campione.\n\nProposta di un nuovo campione \\(\\theta_p\\).\n\nUn nuovo valore \\(\\theta_p\\) viene generato da una distribuzione di proposta \\(g(\\theta_p \\mid \\theta_t)\\), solitamente una distribuzione normale centrata sul campione corrente \\(\\theta_t\\) con una deviazione standard \\(\\tau\\) che controlla l‚Äôampiezza dei passi.\n\nVerifica dei vincoli del campione proposto.\n\nSe il nuovo campione deve rispettare dei vincoli (ad esempio, essere compreso tra 0 e 1 per probabilit√†), campioni non validi vengono automaticamente rifiutati.\n\nCalcolo del rapporto di accettazione \\(\\alpha\\).\n\nSi calcola \\(\\alpha = \\frac{p(\\theta_p \\mid y)}{p(\\theta_t \\mid y)}\\), che rappresenta il rapporto tra le densit√† a posteriori del nuovo campione \\(\\theta_p\\) e del campione corrente \\(\\theta_t\\). Questo valore guida la decisione di accettazione.\n\nDecisione di accettazione.\n\nSe \\(\\alpha \\geq 1\\), il nuovo campione \\(\\theta_p\\) viene accettato incondizionatamente.\nSe \\(\\alpha &lt; 1\\), il campione \\(\\theta_p\\) viene accettato con probabilit√† \\(\\alpha\\). In caso di rifiuto, si mantiene il campione corrente \\(\\theta_t\\) per la prossima iterazione.\n\nRipetizione del processo.\n\nSi ripetono i passaggi dal 2 al 5 fino a ottenere il numero desiderato di campioni.\n\n\n\n\n50.6.7 Dettagli Aggiuntivi\n\nDistribuzione di proposta: La distribuzione di proposta \\(g(\\theta_p \\mid \\theta_t)\\) genera nuovi campioni attorno a \\(\\theta_t\\). Tipicamente si usa una normale \\(N(\\theta_t, \\tau)\\), dove \\(\\tau\\) controlla quanto il nuovo campione si discosta da quello corrente. Scegliere un \\(\\tau\\) troppo piccolo pu√≤ rendere l‚Äôesplorazione lenta, mentre un \\(\\tau\\) troppo grande pu√≤ far rifiutare troppi campioni, riducendo l‚Äôefficienza.\nRapporto di accettazione \\(\\alpha\\): Se il nuovo campione ha una densit√† a posteriori maggiore del campione corrente, viene sempre accettato. Se ha una densit√† inferiore, viene accettato con probabilit√† \\(\\alpha\\), il che consente di esplorare anche regioni meno probabili della distribuzione.\nAccettazione probabilistica: Accettare campioni peggiori occasionalmente aiuta l‚Äôalgoritmo a evitare di bloccarsi in minimi locali. Questo √® uno dei punti di forza dell‚Äôalgoritmo di Metropolis, che garantisce una buona esplorazione dello spazio dei parametri.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>50</span>¬† <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#esempio-di-implementazione",
    "href": "chapters/mcmc/01_metropolis.html#esempio-di-implementazione",
    "title": "50¬† L‚Äôalgoritmo di Metropolis-Hastings",
    "section": "50.7 Esempio di Implementazione",
    "text": "50.7 Esempio di Implementazione\nPer questa simulazione, adattiamo l‚Äôapproccio proposto da Elizaveta Semenova, implementando l‚Äôalgoritmo di Metropolis-Hastings in R. Cominciamo definendo alcune funzioni fondamentali.\nDefiniamo una funzione prior che calcola la densit√† della distribuzione Beta(4, 6) per un dato valore di \\(\\theta\\):\n\n# Definizione della distribuzione a priori (Beta(4, 6))\nprior &lt;- function(p) {\n  dbeta(p, shape1 = 4, shape2 = 6)\n}\n\nDefiniamo la funzione likelihood, che calcola la densit√† della verosimiglianza binomiale per 14 successi su 100 prove:\n\n# Definizione della funzione di verosimiglianza (Binomiale \n# con y = 14 su n = 100)\nlikelihood &lt;- function(p) {\n  y &lt;- 14\n  n &lt;- 100\n  dbinom(y, size = n, prob = p)\n}\n\nDefiniamo la funzione posterior, che calcola la densit√† della distribuzione a posteriori non normalizzata come prodotto tra la distribuzione a priori e la verosimiglianza:\n\n# Definizione della distribuzione a posteriori (non normalizzata)\nposterior &lt;- function(p) {\n  likelihood(p) * prior(p)\n}\n\nLa distribuzione proposta sar√† una distribuzione normale centrata sullo stato corrente con una deviazione standard specificata:\n\n# Distribuzione proposta (normale centrata sullo stato corrente)\nproposal_distribution &lt;- function(current_state, proposal_sigma) {\n  rnorm(1, mean = current_state, sd = proposal_sigma)\n}\n\nDefiniamo infine la distribuzione target, che corrisponde alla distribuzione a posteriori:\n\n# Distribuzione target, equivalente alla distribuzione a posteriori\ntarget_distribution &lt;- function(p) {\n  posterior(p)\n}\n\nProcediamo ora con l‚Äôimplementazione dell‚Äôalgoritmo di Metropolis-Hastings, considerando i dati relativi agli artisti della Generazione X presenti al MoMA. La distribuzione a priori per \\(\\theta\\) √® modellata come una Beta(4, 6).\n\n# Algoritmo di Metropolis-Hastings\nmetropolis_hastings &lt;- function(num_samples, initial_state, proposal_sigma) {\n  # Inizializza lo stato corrente e la lista dei campioni\n  samples &lt;- numeric(num_samples)\n  current_state &lt;- initial_state\n\n  for (i in seq_len(num_samples)) {\n    # Proponi un nuovo stato dalla distribuzione proposta\n    proposed_state &lt;- proposal_distribution(current_state, proposal_sigma)\n\n    # Verifica che il valore proposto sia tra 0 e 1\n    if (proposed_state &gt;= 0 && proposed_state &lt;= 1) {\n      # Calcola il rapporto di accettazione\n      acceptance_ratio &lt;- min(\n        1,\n        target_distribution(proposed_state) / target_distribution(current_state)\n      )\n\n      # Accetta o rifiuta lo stato proposto\n      if (runif(1) &lt; acceptance_ratio) {\n        current_state &lt;- proposed_state\n      }\n    }\n\n    # Registra lo stato corrente (accettato o rifiutato)\n    samples[i] &lt;- current_state\n  }\n\n  return(samples)\n}\n\n\n\n\n\n\n\nPunti Chiave dell‚ÄôAlgoritmo\n\n\n\n\nGenerazione dei nuovi stati: Ogni nuovo stato viene proposto campionando da una distribuzione normale centrata sullo stato corrente. Questo approccio consente un‚Äôesplorazione sistematica dello spazio dei parametri.\n\nControllo dei limiti: Gli stati proposti devono rientrare nell‚Äôintervallo [0, 1], poich√© rappresentano probabilit√†. Questo assicura che i valori generati siano validi nel contesto dell‚Äôanalisi.\n\nRapporto di accettazione: La decisione di accettare o rifiutare un nuovo stato √® basata sul confronto tra la densit√† a posteriori del nuovo stato e quella dello stato corrente. Stati pi√π probabili vengono sempre accettati, mentre quelli meno probabili sono accettati con una probabilit√† proporzionale.\n\nMemorizzazione degli stati: Ogni iterazione salva lo stato corrente, sia che il nuovo stato venga accettato sia che venga rifiutato, garantendo una catena continua di valori.\n\n\n\nQuesta implementazione fornisce una stima robusta della distribuzione a posteriori utilizzando una combinazione di una distribuzione a priori e dei dati osservati.\nLa distribuzione normale utilizzata per la proposta √® simmetrica, soddisfacendo i requisiti dell‚Äôalgoritmo di Metropolis. Questa simmetria garantisce che la probabilit√† di proporre uno stato \\(\\theta_p\\) partendo da \\(\\theta_t\\) sia uguale alla probabilit√† inversa, assicurando l‚Äôequilibrio dettagliato necessario per la corretta convergenza della catena Markoviana.\n\n50.7.1 Esecuzione dell‚ÄôAlgoritmo\n\n# Parametri dell'algoritmo\nnum_samples &lt;- 10000\ninitial_state &lt;- 0.5\nproposal_sigma &lt;- 0.1\n\n# Esecuzione del campionamento\nset.seed(123)  # Per riproducibilit√†\nsamples &lt;- metropolis_hastings(num_samples, initial_state, proposal_sigma)\n\n\n\n50.7.2 Analisi dei Risultati\nScartiamo i primi 5000 campioni per considerare solo quelli generati dopo il burn-in:\n\nburnin &lt;- floor(num_samples * 0.5)\npost_burnin_samples &lt;- samples[-seq_len(burnin)]\n\nCalcoliamo la media e la deviazione standard dei campioni:\n\n# Media a posteriori\nmean(post_burnin_samples)\n#&gt; [1] 0.163\n\n# Deviazione standard a posteriori\nsd(post_burnin_samples)\n#&gt; [1] 0.0354\n\nVisualizziamo l‚Äôevoluzione della catena per i primi 200 campioni e per quelli post-burn-in:\n\n# Trace plot dei primi 200 campioni\nplot(\n  samples[1:200], \n  type = \"l\", \n  main = \"Trace Plot (Primi 200 Campioni)\",\n  xlab = \"Iterazioni\", \n  ylab = expression(theta)\n)\n\n\n\n\n\n\n\n\n\n# Trace plot dopo il burn-in\nplot(\n  post_burnin_samples, \n  type = \"l\", \n  main = \"Trace Plot (Post Burn-in)\",\n  xlab = \"Iterazioni\", \n  ylab = expression(theta)\n)\n\n\n\n\n\n\n\n\nSovrapponiamo la distribuzione analitica \\(\\text{Beta}(18, 92)\\) all‚Äôistogramma dei campioni post-burn-in:\n\n# Istogramma e distribuzione analitica\nhist(\n  post_burnin_samples, \n  breaks = 20, \n  probability = TRUE, \n  col = \"lightblue\",\n  main = \"Istogramma e Distribuzione Posteriori\", \n  xlab = expression(theta)\n)\ncurve(\n  dbeta(x, 18, 92), \n  add = TRUE, \n  col = \"red\", \n  lwd = 2\n)\nlegend(\n  \"topright\", \n  legend = c(\"Istogramma MCMC\", \"Beta(18, 92)\"),\n  col = c(\"lightblue\", \"red\"), lwd = 2, fill = c(\"lightblue\", NA)\n)\n\n\n\n\n\n\n\n\nCalcoliamo l‚Äôintervallo di credibilit√† al 94%:\n\nquantile(post_burnin_samples, probs = c(0.03, 0.97))\n#&gt;    3%   97% \n#&gt; 0.102 0.235\n\nQuesta implementazione in R dimostra come utilizzare l‚Äôalgoritmo di Metropolis per stimare una distribuzione a posteriori e analizzare i risultati in modo dettagliato e riproducibile.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>50</span>¬† <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#catene-di-markov-e-convergenza",
    "href": "chapters/mcmc/01_metropolis.html#catene-di-markov-e-convergenza",
    "title": "50¬† L‚Äôalgoritmo di Metropolis-Hastings",
    "section": "50.8 Catene di Markov e Convergenza",
    "text": "50.8 Catene di Markov e Convergenza\nNell‚Äôambito delle simulazioni Monte Carlo, una catena rappresenta una sequenza di valori campionati dall‚Äôalgoritmo durante le sue iterazioni. Ogni valore nella catena corrisponde a un possibile stato del sistema che stiamo modellando. In altre parole, una catena traccia il percorso che l‚Äôalgoritmo segue nello spazio dei parametri, esplorando le diverse configurazioni possibili.\nPer verificare se l‚Äôalgoritmo ha raggiunto la convergenza e se i campioni generati rappresentano effettivamente la distribuzione di interesse, √® utile eseguire multiple catene. Ogni catena parte da un punto iniziale diverso nello spazio dei parametri.\nI vantaggi delle multiple catene:\n\nDiagnostica della convergenza: Confrontando le diverse catene, possiamo valutare se si stabilizzano verso la stessa distribuzione. Se le catene si mescolano bene, ovvero si intersecano frequentemente nel grafico dei valori campionati (trace plot), √® un forte indicatore di convergenza.\nRobustezza: L‚Äôutilizzo di multiple catene rende l‚Äôanalisi meno sensibile alla scelta del punto di partenza. Se una singola catena potesse rimanere ‚Äúintrappolata‚Äù in una regione dello spazio dei parametri, multiple catene aumentano la probabilit√† di esplorare lo spazio in modo pi√π completo.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>50</span>¬† <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#diagnostiche-della-soluzione-mcmc",
    "href": "chapters/mcmc/01_metropolis.html#diagnostiche-della-soluzione-mcmc",
    "title": "50¬† L‚Äôalgoritmo di Metropolis-Hastings",
    "section": "50.9 Diagnostiche della soluzione MCMC",
    "text": "50.9 Diagnostiche della soluzione MCMC\n\n50.9.1 Stazionariet√† e Convergenza\nUn aspetto cruciale nell‚Äôanalisi delle catene di Markov MCMC √® la convergenza alla distribuzione stazionaria. Intuitivamente, la catena converge quando i campioni generati rappresentano fedelmente la distribuzione di interesse, indipendentemente dal punto di partenza. Questo fenomeno √® spesso indicato come ‚Äúmixing‚Äù.\n\n50.9.1.1 Valutazione Visuale: Trace Plots e Grafici di Densit√†\n\nTrace Plots: Questi grafici visualizzano l‚Äôevoluzione dei parametri nel tempo. Una catena convergente mostra tracce stabili e senza trend evidenti. Tracce irregolari o con andamenti sistematici suggeriscono problemi di convergenza.\nGrafici di Densit√†: Confrontando i grafici di densit√† dei campioni con la distribuzione teorica, √® possibile valutare visivamente se la catena sta esplorando adeguatamente lo spazio dei parametri. Una buona convergenza si manifesta con una sovrapposizione significativa tra i due grafici.\n\nSegni di Convergenza:\n\nStabilit√†: I valori campionati oscillano attorno a un valore medio costante, senza trend marcati.\nOmogeneit√†: La variabilit√† dei campioni rimane relativamente uniforme nel tempo.\nAssenza di Periodicit√†: Non si osservano pattern ciclici o ripetitivi.\n\nIn sintesi, i trace plots e i grafici di densit√† offrono strumenti visivi rapidi per valutare la convergenza di una catena di Markov MCMC. Una convergenza soddisfacente √® fondamentale per garantire la validit√† delle inferenze statistiche basate sui campioni generati.\n\n\n\n50.9.2 Autocorrelazione nelle catene di Markov MCMC\nA differenza dei generatori di numeri casuali indipendenti, gli algoritmi MCMC producono una sequenza di campioni correlati. Ogni valore campionato dipende da quello precedente, formando una catena di Markov. Questa interdipendenza √® un aspetto fondamentale dell‚ÄôMCMC.\nL‚Äôautocorrelazione quantifica il grado di dipendenza tra valori distanti di una certa quantit√† (detta lag) nella catena. Un‚Äôalta autocorrelazione a lag bassi indica una forte dipendenza tra campioni successivi. Al contrario, una rapida diminuzione dell‚Äôautocorrelazione al crescere del lag suggerisce che la catena ‚Äúmiscela‚Äù bene, ovvero esplora lo spazio dei parametri in modo efficiente.\n\nLag 1: Misura la correlazione tra valori consecutivi nella catena.\nLag 2: Misura la correlazione tra valori separati da un passo intermedio.\nLag k: Generalizza il concetto ai valori separati da k passi.\n\nUn correlogramma √® un grafico che mostra l‚Äôautocorrelazione in funzione del lag. Un decadimento rapido dell‚Äôautocorrelazione verso zero indica una buona convergenza della catena.\nL‚Äôautocorrelazione di ordine \\(k\\) √® data da \\(\\rho_k\\) e pu√≤ essere stimata come:\n\\[\n\\begin{align}\n\\rho_k &= \\frac{Cov(\\theta_m, \\theta_{m+k})}{Var(\\theta_m)}\\notag\\\\\n&= \\frac{\\sum_{m=1}^{n-k}(\\theta_m - \\bar{\\theta})(\\theta_{m-k} - \\bar{\\theta})}{\\sum_{m=1}^{n-k}(\\theta_m - \\bar{\\theta})^2} \\qquad\\text{con }\\quad \\bar{\\theta} = \\frac{1}{n}\\sum_{m=1}^{n}\\theta_m.\n\\end{align}\n\\tag{50.1}\\]\n\n\n50.9.3 Esempio di Simulazione di Dati Autocorrelati\nPer fare un esempio pratico, creiamo un vettore di dati autocorrelati:\n\n# Creiamo un vettore di dati\nx &lt;- c(22, 24, 25, 25, 28, 29, 34, 37, 40, 44, 51, 48, 47, 50, 51)\nx\n#&gt;  [1] 22 24 25 25 28 29 34 37 40 44 51 48 47 50 51\n\n\n50.9.3.1 Calcolo dell‚ÄôAutocorrelazione\nL‚Äôautocorrelazione di ordine 1 √® la correlazione tra ciascun elemento e il successivo nella sequenza. In R possiamo utilizzare la funzione acf() per calcolare l‚Äôautocorrelazione.\n\n# Calcolo dell'autocorrelazione\nacf_values &lt;- acf(x, plot = FALSE)\nacf_values\n#&gt; \n#&gt; Autocorrelations of series 'x', by lag\n#&gt; \n#&gt;      0      1      2      3      4      5      6      7      8      9 \n#&gt;  1.000  0.832  0.656  0.491  0.279  0.031 -0.165 -0.304 -0.401 -0.458 \n#&gt;     10     11 \n#&gt; -0.450 -0.369\n\nNell‚Äôesempio, il vettore x rappresenta una serie temporale di 15 elementi. Il calcolo dell‚Äôautocorrelazione restituisce i seguenti valori per i primi ritardi (lag):\n\n0.8317: autocorrelazione di ordine 1 (lag = 1),\n0.6563: autocorrelazione di ordine 2 (lag = 2),\n0.4910: autocorrelazione di ordine 3 (lag = 3),\necc.\n\n\n\n50.9.3.2 Specifica del Numero di Ritardi (Lag)\nPossiamo limitare il numero di ritardi calcolati utilizzando l‚Äôargomento lag.max nella funzione acf():\n\n# Calcolo dell'autocorrelazione per i primi 4 lag\nacf(x, lag.max = 4, plot = FALSE)\n#&gt; \n#&gt; Autocorrelations of series 'x', by lag\n#&gt; \n#&gt;     0     1     2     3     4 \n#&gt; 1.000 0.832 0.656 0.491 0.279\n\n\n\n50.9.3.3 Grafico della Funzione di Autocorrelazione (Correlogramma)\nIn R possiamo creare un correlogramma con la funzione acf():\n\n# Correlogramma per la serie temporale\nacf(x, main = \"Correlogramma della Serie Temporale\", lag.max = 9)\n\n\n\n\n\n\n\n\n\n\n\n50.9.4 Analisi della Catena di Markov\nApplichiamo lo stesso approccio alla catena di Markov ottenuta precedentemente, considerando i campioni post burn-in:\n\n# Definizione dei campioni post burn-in\npost_burnin_samples &lt;- samples[-seq_len(burnin)]\n\n# Correlogramma per i campioni post burn-in\nacf(\n  post_burnin_samples, \n  main = \"Correlogramma della Catena Post Burn-in\", \n  lag.max = 9\n)\n\n\n\n\n\n\n\n\nIn situazioni ideali, l‚Äôautocorrelazione diminuisce rapidamente, diventando insignificante per piccoli lag. Questo comportamento √® un‚Äôindicazione del ‚Äúmixing‚Äù efficace della catena, ossia della sua convergenza alla distribuzione stazionaria.\n\n\n50.9.5 Sottocampionamento (Thinning)\nPer ridurre l‚Äôautocorrelazione, possiamo applicare una strategia di sottocampionamento (thinning), memorizzando solo ogni \\(m\\)-esimo campione.\n\n# Sottocampionamento con un fattore di 5\nthin &lt;- 5\nsampsthin &lt;- \n  post_burnin_samples[seq(1, length(post_burnin_samples), by = thin)]\n\n# Correlogramma per i campioni sottocampionati\nacf(\n  sampsthin, \n  main = \"Correlogramma con Sottocampionamento (Thinning)\", \n  lag.max = 9\n)\n\n\n\n\n\n\n\n\nIn conclusione, il correlogramma con thinning mostra che l‚Äôautocorrelazione diminuisce pi√π rapidamente rispetto ai campioni originali, suggerendo che la strategia di sottocampionamento √® efficace nel migliorare l‚Äôindipendenza tra i campioni successivi. Questo migliora la qualit√† delle inferenze basate sulla catena di Markov.\n\n50.9.5.1 Tasso di accettazione\nQuando si utilizza l‚Äôalgoritmo Metropolis, √® importante monitorare il tasso di accettazione e assicurarsi che sia nell‚Äôintervallo ottimale. Se si accetta quasi sempre il candidato proposto, probabilmente significa che, in ogni iterazione, la catena salta solo di un piccolo passo (in modo che il rapporto di accettazione sia vicino a 1 ogni volta). Di conseguenza, la catena impiegher√† molte iterazioni per raggiungere altre regioni della distribuzione stazionaria e i campioni consecutivi saranno molto fortemente correlati. D‚Äôaltra parte, se il tasso di accettazione √® molto basso, la catena rimarr√† bloccata nella stessa posizione per molte iterazioni prima di spostarsi verso uno stato diverso. Per l‚Äôalgoritmo Metropolis base con un singolo parametro con una distribuzione proposta Gaussiana normale, un tasso di accettazione ottimale √® compreso tra il 40% e il 50%.\n\n\n\n50.9.6 Test Statistici per la Convergenza\nOltre agli approcci grafici, esistono test statistici specifici che possono aiutare a determinare se la catena ha raggiunto uno stato stazionario.\n\n50.9.6.1 Test di Geweke\nIl test di Geweke √® una procedura che confronta le medie di due segmenti della catena di campionamento, tipicamente il primo 10% e l‚Äôultimo 50% dei campioni, dopo aver escluso un iniziale periodo di ‚Äúburn-in‚Äù (una fase iniziale durante la quale la catena potrebbe non essere ancora convergente). La premessa di base √® che, se la catena √® in uno stato stazionario, le medie di questi due segmenti dovrebbero essere sostanzialmente uguali. Differenze significative tra queste medie possono indicare che la catena non ha ancora raggiunto la convergenza.\n\n\n50.9.6.2 Geweke Z-score\nUna variante del test di Geweke √® lo z-score di Geweke, che offre un modo quantitativo per valutare le differenze tra i segmenti della catena. Questo test calcola uno z-score che confronta le medie dei due segmenti tenendo conto della varianza. Un valore di z-score:\n\nAl di sotto di 2 (in valore assoluto) suggerisce che non ci sono differenze significative tra i segmenti, indicando che la catena potrebbe essere in stato stazionario.\nSuperiore a 2 (in valore assoluto) indica che esiste una differenza significativa tra i segmenti, suggerendo che la catena non ha raggiunto la convergenza e potrebbe essere necessario un periodo di burn-in pi√π esteso.\n\nEntrambi i metodi forniscono strumenti utili per valutare la convergenza delle catene MCMC. √à importante notare che nessun test pu√≤ garantire con certezza la convergenza, ma l‚Äôutilizzo congiunto di approcci grafici e test statistici pu√≤ offrire una buona indicazione dello stato della catena.\n\n\n\n50.9.7 Dimensione del campione effettiva (ESS)\nLa correlazione tra campioni consecutivi in una catena MCMC riduce l‚Äôinformazione effettiva contenuta in ogni iterazione. La dimensione del campione effettiva (ESS) quantifica questa perdita di informazione dovuta alla dipendenza tra i campioni, stimando il numero equivalente di campioni indipendenti. Un valore basso di ESS indica una forte correlazione tra i campioni e una convergenza pi√π lenta della catena.\nL‚ÄôESS descrive l‚Äôefficacia del campionamento dipendente in termini di campioni indipendenti estratti dalla stessa distribuzione. Rappresenta un indicatore dell‚Äôefficienza del campionamento e dell‚Äôautocorrelazione della catena.\nLa formula per stimare la dimensione del campione effettiva (ESS) di una catena di Markov √®:\n\\[\n\\text{ESS} = \\frac{N}{1 + 2 \\sum_{t=1}^{T} \\rho_t},\n\\]\ndove:\n\n\\(N\\) √® il numero totale di campioni nella catena,\n\\(T\\) √® il lag, ovvero il numero massimo di termini di autocorrelazione considerati,\n\\(\\rho_t\\) √® l‚Äôautocorrelazione al lag \\(t\\), ossia la correlazione tra due campioni consecutivi separati da \\(t\\) iterazioni.\n\nIn pratica, \\(T\\) viene scelto in modo tale che \\(\\rho_T\\) sia sufficientemente piccolo, indicando che l‚Äôautocorrelazione √® quasi svanita. La somma \\(\\sum_{t=1}^T \\rho_t\\) viene quindi troncata approssimativamente a \\(T\\), poich√© i contributi delle autocorrelazioni successive diventano trascurabili.\n\n\n50.9.8 Calcolo della Statistica di Gelman-Rubin (\\(\\hat{R}\\))\nPer calcolare la statistica di Gelman-Rubin (spesso indicata come \\(\\hat{R}\\)), √® necessario eseguire pi√π catene e confrontare la variabilit√† all‚Äôinterno di ciascuna catena con la variabilit√† tra le catene. Ecco i passaggi per calcolare \\(\\hat{R}\\):\n\nEsegui \\(m\\) catene di Markov di lunghezza \\(n\\), dove \\(m\\) √® solitamente maggiore di 1.\nPer ciascun parametro scalare \\(\\theta\\), calcola la varianza all‚Äôinterno delle catene (\\(W\\)) e la varianza tra le catene (\\(B\\)).\nCalcola la varianza combinata \\(\\hat{V}\\) come media ponderata delle varianze all‚Äôinterno delle catene.\nCalcola il fattore di riduzione della scala potenziale \\(\\hat{R}\\) come la radice quadrata del rapporto tra la varianza combinata \\(\\hat{V}\\) e la varianza all‚Äôinterno delle catene \\(W\\):\n\n\\[\n\\hat{R} = \\sqrt{\\frac{\\hat{V}}{W}}.\n\\]\n\nSe \\(\\hat{R}\\) √® vicino a 1, ci√≤ indica che le catene sono in convergenza.\n\nLa statistica di Gelman-Rubin \\(\\hat{R}\\) √® una misura di convergenza per le catene di Markov. Essa quantifica il grado di accordo tra pi√π catene, fornendo uno strumento diagnostico per valutare la convergenza nelle simulazioni MCMC.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>50</span>¬† <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#vantaggi-del-campionamento-mcmc-rispetto-alle-soluzioni-analitiche",
    "href": "chapters/mcmc/01_metropolis.html#vantaggi-del-campionamento-mcmc-rispetto-alle-soluzioni-analitiche",
    "title": "50¬† L‚Äôalgoritmo di Metropolis-Hastings",
    "section": "50.10 Vantaggi del Campionamento MCMC rispetto alle Soluzioni Analitiche",
    "text": "50.10 Vantaggi del Campionamento MCMC rispetto alle Soluzioni Analitiche\nIl campionamento MCMC offre notevoli vantaggi pratici rispetto alle soluzioni analitiche nella statistica bayesiana, in particolare quando si tratta di manipolare distribuzioni a posteriori. Sebbene l‚Äôimpossibilit√† di calcolare analiticamente la distribuzione a posteriori sia spesso la motivazione principale per l‚Äôuso di MCMC, i benefici di questo approccio si estendono ben oltre questa necessit√† (B√ºrkner, 2024).\n\n50.10.1 Facilit√† di Manipolazione e Flessibilit√†\nIl vantaggio chiave del campionamento MCMC risiede nella semplicit√† con cui si possono manipolare i campioni ottenuti. Mentre le densit√† calcolate analiticamente possono richiedere trasformazioni matematiche complesse, i campioni MCMC possono essere facilmente trasformati con operazioni dirette. Questa flessibilit√† si manifesta in diversi aspetti:\n\nTrasformazioni di Variabili: Consideriamo un caso in cui siamo interessati alla varianza residua (\\(\\sigma^2\\)) in un modello, ma abbiamo campioni solo della deviazione standard residua (\\(\\sigma\\)). Con il campionamento MCMC, la trasformazione √® immediata:\n\n\\[\n(\\sigma^{(s)})^2 = \\sigma^{2(s)},\n\\]\ndove \\(s\\) indica il singolo campione. Questa operazione si traduce semplicemente nell‚Äôelevare al quadrato ogni campione di \\(\\sigma\\), ottenendo direttamente campioni validi di \\(\\sigma^2\\). In contrasto, con una densit√† analitica di \\(\\sigma\\), la trasformazione richiederebbe l‚Äôapplicazione dell‚Äôaggiustamento del Jacobiano, un processo matematicamente pi√π complesso.\n\nCombinazione di Parametri: Il MCMC semplifica notevolmente la combinazione di parametri in modelli statistici. Per una quantit√† \\(\\theta\\) che dipende da parametri \\(\\beta_1\\) e \\(\\beta_2\\) attraverso una funzione \\(f\\), possiamo calcolare:\n\n\\[\n\\theta^{(s)} = f(\\beta_1^{(s)}, \\beta_2^{(s)}).\n\\]\nQuesta operazione si estende facilmente a combinazioni complesse e funzioni non lineari, contrastando nettamente con la complessit√† di derivare analiticamente la distribuzione di \\(\\theta\\).\nIn conclusione, il campionamento MCMC non √® solo una necessit√† quando le soluzioni analitiche sono introvabili, ma offre vantaggi in termini di facilit√† di manipolazione, flessibilit√† computazionale e applicabilit√† pratica.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>50</span>¬† <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#caso-normale-normale-con-soluzione-analitica",
    "href": "chapters/mcmc/01_metropolis.html#caso-normale-normale-con-soluzione-analitica",
    "title": "50¬† L‚Äôalgoritmo di Metropolis-Hastings",
    "section": "50.11 Caso Normale-Normale con Soluzione Analitica",
    "text": "50.11 Caso Normale-Normale con Soluzione Analitica\nConsideriamo un caso normale-normale per cui possiamo derivare una soluzione analitica. Supponiamo che il prior sia distribuito secondo \\(\\mathcal{N}(30, 5^2)\\).\nDefiniamo le funzioni per il prior, la verosimiglianza e il posterior non normalizzato.\n\n# Prior: Normal(30, 5^2)\nprior &lt;- function(mu) {\n  dnorm(mu, mean = 30, sd = 5)\n}\n\n# Likelihood: Normal(mu, sigma^2) con sigma calcolata dai dati\nlikelihood &lt;- function(mu, data) {\n  sigma &lt;- sd(data)  # Deviazione standard dei dati\n  prod(dnorm(data, mean = mu, sd = sigma))\n}\n\n# Posterior non normalizzato\nposterior &lt;- function(mu, data) {\n  likelihood(mu, data) * prior(mu)\n}\n\nImplementiamo l‚Äôalgoritmo di Metropolis per il caso normale-normale:\n\n# Algoritmo di Metropolis\nmetropolis_for_normal &lt;- function(nsamp, xinit, data) {\n  samples &lt;- numeric(nsamp)\n  x_prev &lt;- xinit\n  \n  for (i in seq_len(nsamp)) {\n    x_star &lt;- rnorm(1, mean = x_prev, sd = 0.5)  # Proposta\n    if (runif(1) &lt; min(1, posterior(x_star, data) / posterior(x_prev, data))) {\n      x_prev &lt;- x_star\n    }\n    samples[i] &lt;- x_prev\n  }\n  \n  samples\n}\n\nUtilizziamo un campione di 30 valori BDI-II forniti da Zetsche et al. (2019):\n\n# Dati osservati\ny &lt;- c(\n  26, 35, 30, 25, 44, 30, 33, 43, 22, 43, 24, 19, 39, 31, 25, \n  28, 35, 30, 26, 31, 41, 36, 26, 35, 33, 28, 27, 34, 27, 22\n)\n\nEsecuzione dell‚Äôalgoritmo:\n\nsamples &lt;- metropolis_for_normal(100000, mean(y), y)\n\nNel caso normale-normale, il posterior pu√≤ essere calcolato analiticamente come segue:\n\n# Parametri del prior\nmu_prior &lt;- 30\nstd_prior &lt;- 5\nvar_prior &lt;- std_prior^2\n\n# Calcolo dei parametri posterior\nn &lt;- length(y)\nsum_y &lt;- sum(y)\nvar_data &lt;- var(y)\n\nmu_post &lt;- (mu_prior / var_prior + sum_y / var_data) / (1 / var_prior + n / var_data)\nvar_post &lt;- 1 / (1 / var_prior + n / var_data)\nstd_post &lt;- sqrt(var_post)\n\nmu_post\n#&gt; [1] 30.9\nstd_post\n#&gt; [1] 1.17\n\nVisualizziamo i risultati con un istogramma dei campioni MCMC e la curva della distribuzione analitica:\n\n# Campioni post burn-in\nburnin &lt;- floor(length(samples) * 0.5)\npost_samples &lt;- samples[-seq_len(burnin)]\n\n# Dati per la curva analitica\nx &lt;- seq(mu_post - 4 * std_post, mu_post + 4 * std_post, length.out = 1000)\nanalytical_posterior &lt;- dnorm(x, mean = mu_post, sd = std_post)\n\n# Creazione del grafico\nggplot() +\n  geom_histogram(aes(x = post_samples, y = ..density..), bins = 30, fill = \"blue\", alpha = 0.4) +\n  geom_line(aes(x = x, y = analytical_posterior), color = \"red\", size = 1) +\n  labs(title = \"Distribuzione Posterior: MCMC vs Analitico\",\n       x = expression(mu), y = \"Densit√†\") \n#&gt; Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#&gt; ‚Ñπ Please use `linewidth` instead.\n#&gt; Warning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\n#&gt; ‚Ñπ Please use `after_stat(density)` instead.\n\n\n\n\n\n\n\n\nTroviamo le propriet√† del Posterior derivato con MCMC:\n\nmean(samples)\n#&gt; [1] 30.9\n\n\nsd(samples)\n#&gt; [1] 1.18\n\nIn conclusione, questo esempio mostra come applicare l‚Äôalgoritmo di Metropolis per stimare una distribuzione a posteriori e come confrontare i risultati del sampling con la soluzione analitica, confermando la coerenza tra le due tecniche.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>50</span>¬† <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#riflessioni-conclusive",
    "href": "chapters/mcmc/01_metropolis.html#riflessioni-conclusive",
    "title": "50¬† L‚Äôalgoritmo di Metropolis-Hastings",
    "section": "50.12 Riflessioni Conclusive",
    "text": "50.12 Riflessioni Conclusive\nIn molti casi, la distribuzione a posteriori dei parametri di un modello statistico non ha una forma analitica risolvibile. Per affrontare questa limitazione, si utilizzano metodi Monte Carlo basati su catene di Markov (MCMC). Questi algoritmi permettono di campionare efficacemente dalla distribuzione a posteriori, anche per modelli complessi, generando una sequenza di valori che approssima la distribuzione desiderata. L‚Äôalgoritmo di Metropolis-Hastings (Hastings, 1970), un‚Äôestensione dell‚Äôalgoritmo di Metropolis originale (Metropolis et al., 1953), √® uno dei metodi MCMC pi√π ampiamente utilizzati.\nIn sintesi, l‚Äôalgoritmo segue questi passaggi principali:\n\nGenerazione del nuovo stato proposto: Si crea un nuovo stato vicino a quello corrente utilizzando una distribuzione di proposta.\nConfronto tra densit√† posteriori: Si confrontano le densit√† a posteriori del nuovo stato proposto e dello stato corrente.\nAccettazione probabilistica: Il nuovo stato viene sempre accettato se ha una densit√† posteriore maggiore, oppure accettato con una certa probabilit√† se ha una densit√† minore.\nBurn-in e tasso di accettazione: I primi campioni vengono scartati (fase di burn-in) per garantire che la catena abbia raggiunto la distribuzione stazionaria, e si monitora il tasso di accettazione per ottimizzare l‚Äôefficienza del campionamento.\n\nQuesto approccio consente di ottenere campioni che approssimano la distribuzione a posteriori, ma l‚Äôalgoritmo di Metropolis pu√≤ presentare limiti di efficienza, soprattutto per problemi ad alta dimensionalit√† o distribuzioni con geometrie complesse. Un aspetto cruciale √® il tasso di accettazione, che rappresenta il rapporto tra il numero di proposte accettate e il numero totale di proposte. Un tasso troppo basso pu√≤ indicare che la catena esplora lo spazio dei parametri in modo inefficiente, mentre un tasso troppo alto pu√≤ segnalare che i passi effettuati sono troppo piccoli per consentire una buona esplorazione.\nRispetto alle varianti pi√π moderne, l‚Äôalgoritmo di Metropolis tende a essere meno efficiente. Metodi come il No-U-Turn Sampler (NUTS) e l‚ÄôHamiltonian Monte Carlo (HMC) offrono miglioramenti significativi, specialmente in spazi di parametri di grandi dimensioni. NUTS, ad esempio, viene utilizzato in strumenti avanzati come Stan e PyMC (Hoffman et al., 2014), permettendo un‚Äôesplorazione pi√π rapida e accurata della distribuzione a posteriori.\nTra gli altri algoritmi MCMC degni di nota troviamo il campionatore di Gibbs (Geman & Geman, 1984) e l‚ÄôHamiltonian Monte Carlo (Duane et al., 1987). Questi metodi, insieme a Metropolis-Hastings, formano la base di numerose tecniche moderne per il campionamento da distribuzioni complesse. Per un approfondimento dettagliato sulle tecniche MCMC, si consiglia di consultare Hanada & Matsuura (2022).",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>50</span>¬† <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/01_metropolis.html#informazioni-sullambiente-di-sviluppo",
    "title": "50¬† L‚Äôalgoritmo di Metropolis-Hastings",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: US/Pacific\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] cmdstanr_0.8.1   ggokabeito_0.1.0 see_0.9.0        gridExtra_2.3   \n#&gt;  [5] patchwork_1.3.0  bayesplot_1.11.1 psych_2.4.12     scales_1.3.0    \n#&gt;  [9] markdown_1.13    knitr_1.49       lubridate_1.9.4  forcats_1.0.0   \n#&gt; [13] stringr_1.5.1    dplyr_1.1.4      purrr_1.0.2      readr_2.1.5     \n#&gt; [17] tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0 \n#&gt; [21] rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6         tensorA_0.36.2.1     xfun_0.50           \n#&gt;  [4] htmlwidgets_1.6.4    processx_3.8.5       lattice_0.22-6      \n#&gt;  [7] tzdb_0.4.0           vctrs_0.6.5          tools_4.4.2         \n#&gt; [10] ps_1.8.1             generics_0.1.3       parallel_4.4.2      \n#&gt; [13] pacman_0.5.1         pkgconfig_2.0.3      R.oo_1.27.0         \n#&gt; [16] data.table_1.16.4    checkmate_2.3.2      distributional_0.5.0\n#&gt; [19] lifecycle_1.0.4      compiler_4.4.2       farver_2.1.2        \n#&gt; [22] munsell_0.5.1        mnormt_2.1.1         htmltools_0.5.8.1   \n#&gt; [25] pillar_1.10.1        R.utils_2.12.3       abind_1.4-8         \n#&gt; [28] nlme_3.1-166         posterior_1.6.0.9000 tidyselect_1.2.1    \n#&gt; [31] digest_0.6.37        stringi_1.8.4        labeling_0.4.3      \n#&gt; [34] rprojroot_2.0.4      fastmap_1.2.0        grid_4.4.2          \n#&gt; [37] colorspace_2.1-1     cli_3.6.3            magrittr_2.0.3      \n#&gt; [40] withr_3.0.2          backports_1.5.0      timechange_0.3.0    \n#&gt; [43] rmarkdown_2.29       R.methodsS3_1.8.2    hms_1.1.3           \n#&gt; [46] evaluate_1.0.1       rlang_1.1.4          glue_1.8.0          \n#&gt; [49] jsonlite_1.8.9       R6_2.5.1",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>50</span>¬† <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#bibliografia",
    "href": "chapters/mcmc/01_metropolis.html#bibliografia",
    "title": "50¬† L‚Äôalgoritmo di Metropolis-Hastings",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nB√ºrkner, P.-C. (2024). The brms Book: Applied Bayesian Regression Modelling Using R and Stan (Early Draft). https://paulbuerkner.com/software/brms-book\n\n\nDuane, S., Kennedy, A. D., Pendleton, B. J., & Roweth, D. (1987). Hybrid monte carlo. Physics letters B, 195(2), 216‚Äì222.\n\n\nGeman, S., & Geman, D. (1984). Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images. IEEE Transactions on pattern analysis and machine intelligence, 6, 721‚Äì741.\n\n\nHanada, M., & Matsuura, S. (2022). MCMC from Scratch. Springer.\n\n\nHastings, W. K. (1970). Monte Carlo sampling methods using Markov chains and their applications. Biometrika, 57(1), 97‚Äì109.\n\n\nHoffman, M. D., Gelman, A., et al. (2014). The No-U-Turn sampler: adaptively setting path lengths in Hamiltonian Monte Carlo. Journal of Machine Learning Research, 15(1), 1593‚Äì1623.\n\n\nMetropolis, N., Rosenbluth, A. W., Rosenbluth, M. N., Teller, A. H., & Teller, E. (1953). Equation of state calculations by fast computing machines. The Journal of Chemical Physics, 21(6), 1087‚Äì1092.\n\n\nZetsche, U., Buerkner, P.-C., & Renneberg, B. (2019). Future expectations in clinical depression: biased or realistic? Journal of Abnormal Psychology, 128(7), 678‚Äì688.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>50</span>¬† <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_ppl.html",
    "href": "chapters/mcmc/02_ppl.html",
    "title": "51¬† Linguaggi di programmazione probabilistici",
    "section": "",
    "text": "51.1 Cos‚Äô√® la programmazione probabilistica\nLa programmazione probabilistica √® un paradigma della programmazione informatica che consente di creare modelli e algoritmi capaci di gestire l‚Äôincertezza e la casualit√†. Combina i principi della teoria delle probabilit√† con la programmazione, permettendo di costruire sistemi in grado di ragionare su dati incerti e di prendere decisioni informate. Questo approccio consente di esprimere modelli complessi in modo naturale e intuitivo, facilitando il processo di inferenza bayesiana.\nLa programmazione probabilistica si colloca all‚Äôintersezione tra algoritmi di machine learning, statistica e linguaggi di programmazione. I suoi obiettivi principali sono semplificare il processo di inferenza e automatizzarlo.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>51</span>¬† <span class='chapter-title'>Linguaggi di programmazione probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_ppl.html#perch√©-abbiamo-bisogno-della-programmazione-probabilistica",
    "href": "chapters/mcmc/02_ppl.html#perch√©-abbiamo-bisogno-della-programmazione-probabilistica",
    "title": "51¬† Linguaggi di programmazione probabilistici",
    "section": "51.2 Perch√© abbiamo bisogno della programmazione probabilistica?",
    "text": "51.2 Perch√© abbiamo bisogno della programmazione probabilistica?\nScrivere un proprio campionatore per l‚Äôinferenza bayesiana √® un compito estremamente difficile. Richiede competenze matematiche avanzate e una profonda conoscenza degli algoritmi di campionamento (sia MCMC che approssimati). Inoltre, ci sono numerosi problemi potenziali legati alla stabilit√† numerica e ai costi computazionali. Questo significa che per riuscirci bisogna essere allo stesso tempo degli ottimi sviluppatori e degli esperti statistici.\n√à per√≤ possibile delegare tutti questi compiti a un sistema che li automatizzi, permettendoci di concentrarci sulla risoluzione dei problemi scientifici.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>51</span>¬† <span class='chapter-title'>Linguaggi di programmazione probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_ppl.html#linguaggi-di-programmazione-probabilistica-ppls",
    "href": "chapters/mcmc/02_ppl.html#linguaggi-di-programmazione-probabilistica-ppls",
    "title": "51¬† Linguaggi di programmazione probabilistici",
    "section": "51.3 Linguaggi di programmazione probabilistica (PPLs)",
    "text": "51.3 Linguaggi di programmazione probabilistica (PPLs)\nIn questa sezione esamineremo il panorama moderno dei linguaggi di programmazione probabilistica (PPLs) e, nella sezione successiva, esploreremo le funzionalit√† di uno di questi, Stan.\n\n51.3.1 Linguaggi di Programmazione Probabilistica (PPL)\nUn linguaggio di programmazione probabilistica (PPL) consente di formalizzare modelli bayesiani e di eseguire inferenze utilizzando algoritmi avanzati. L‚Äôutente deve semplicemente definire il modello, selezionare un campionatore e avviare il processo di inferenza.\nIn generale, le funzionalit√† fondamentali richieste a un PPL sono:\n\ngenerare valori casuali da distribuzioni probabilistiche;\ncondizionare variabili su dati osservati.\n\nI primi linguaggi di programmazione probabilistica, come BUGS e WinBUGS, hanno gettato le basi offrendo tre capacit√† essenziali:\n\nrandom: per definire variabili casuali.\nconstraint: per vincolare variabili ai dati osservati.\ninfer: per calcolare e restituire la distribuzione delle variabili di interesse.\n\nNel corso del tempo, l‚Äôelenco dei PPL disponibili si √® notevolmente ampliato, comprendendo una vasta gamma di strumenti in continua evoluzione. Ecco alcuni esempi rappresentativi:\n\nBUGS, WinBUGS, JAGS\nStan\nPyMC3, PyMC4, PyMC\nNimble\nPyro, NumPyro\nEdward, TensorFlow Probability, Edward 2\nGen\nTuring\nStheno\nSOSS\nOmega\nInfer.NET",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>51</span>¬† <span class='chapter-title'>Linguaggi di programmazione probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_ppl.html#come-scegliere-un-ppl",
    "href": "chapters/mcmc/02_ppl.html#come-scegliere-un-ppl",
    "title": "51¬† Linguaggi di programmazione probabilistici",
    "section": "51.4 Come scegliere un PPL?",
    "text": "51.4 Come scegliere un PPL?\nDal punto di vista pratico, come si pu√≤ decidere quale linguaggio di programmazione probabilistica utilizzare? Ecco alcuni fattori chiave da considerare:\n\nDocumentazione: La presenza di risorse ben strutturate, come guide, tutorial e documentazione ufficiale, √® essenziale per facilitare l‚Äôapprendimento e migliorare la produttivit√†. Un PPL con documentazione chiara e completa √® sempre preferibile, specialmente per chi √® alle prime armi.\nPerformance: Alcuni PPL sono ottimizzati per offrire prestazioni superiori, ad esempio mediante l‚Äôelaborazione parallela o l‚Äôuso di acceleratori hardware come le GPU. Valuta le prestazioni in relazione alla complessit√† e alla scala dei modelli che desideri costruire.\nFunzionalit√†: √à importante verificare se il PPL offre un‚Äôampia gamma di distribuzioni probabilistiche e campionatori, oltre a strumenti avanzati per personalizzare i modelli e implementare inferenze specifiche.\nSupporto della comunit√†: Una comunit√† attiva pu√≤ fare la differenza quando incontri difficolt√†. Forum, gruppi di discussione e risorse condivise dagli utenti (come esempi pratici o risposte a domande frequenti) sono fondamentali per risolvere problemi in modo rapido e imparare dalle esperienze di altri.\nIntegrazione: Considera quanto bene il PPL si integra con gli strumenti e i framework gi√† in uso. Per esempio, se utilizzi librerie per la manipolazione dei dati, la visualizzazione o il machine learning, come pandas, ggplot o TensorFlow, verifica che il PPL scelto supporti queste interazioni senza complicazioni.\n\n\n51.4.1 API\nI linguaggi di programmazione probabilistica (PPL) permettono agli utenti di definire con precisione le caratteristiche dei priori, della verosimiglianza e dell‚Äôintero modello bayesiano. Inoltre, offrono strumenti per effettuare le necessarie trasformazioni sui dati, garantendo la flessibilit√† richiesta per affrontare una vasta gamma di problemi statistici. Tuttavia, anche se i PPL cercano di semplificare queste operazioni, l‚Äôutente deve comunque scrivere codice che rispetti i vincoli sintattici e logici specifici del linguaggio. Questo richiede non solo competenze di programmazione, ma anche una buona conoscenza dei principi statistici e bayesiani.\nPer venire incontro a utenti che desiderano utilizzare l‚Äôinferenza bayesiana senza doversi addentrare nella programmazione, sono state sviluppate interfacce di alto livello. Queste interfacce permettono di specificare modelli statistici comuni in modo intuitivo, utilizzando una sintassi semplificata. Sebbene offrano meno controllo sui dettagli tecnici del modello, garantiscono comunque la possibilit√† di personalizzare elementi cruciali, come i priori e la verosimiglianza, rendendo l‚Äôinferenza bayesiana accessibile anche a chi non ha competenze di programmazione.\n\n\n51.4.2 Principali Interfacce di Alto Livello\nTra le interfacce pi√π popolari troviamo:\n\nbrms: utilizza Stan come motore sottostante per eseguire l‚Äôinferenza.\nBambi: si basa su PyMC per eseguire l‚Äôinferenza bayesiana.\n\nEntrambe queste librerie adottano una sintassi semplificata, nota come sintassi di Wilkinson (Wilkinson & Rogers, 1973). Questo approccio consente di specificare modelli in modo dichiarativo, usando una struttura simile a quella adottata da pacchetti R come lm (per modelli di regressione lineare) o lme4 (per modelli multilivello con lmer).\nAd esempio, in brms √® possibile specificare un modello di regressione lineare con una sintassi simile a questa:\nfit &lt;- brm(y ~ x1 + x2, data = dataset)\nIn questo esempio y ~ x1 + x2 definisce la relazione tra la variabile dipendente (y) e le variabili indipendenti (x1 e x2).\n\n\n51.4.3 Vantaggi delle Interfacce di Alto Livello\n\nAccessibilit√†: Riduzione della complessit√† sintattica, rendendo l‚Äôinferenza bayesiana pi√π accessibile a un pubblico pi√π ampio, inclusi studenti e ricercatori con competenze di programmazione limitate.\nFlessibilit√†: Sebbene pi√π semplici, le interfacce consentono di specificare prior distribuiti in modo personalizzato e di modificare molteplici aspetti del modello.\nEfficienza: Automatizzano molti passaggi tecnici, permettendo di concentrarsi sulla definizione del modello e sull‚Äôinterpretazione dei risultati.\nCompatibilit√†: Integrazione con strumenti statistici familiari, come il framework di modelli lineari in R.\n\nIn questo corso, utilizzeremo principalmente brms per specificare e stimare modelli di regressione lineare e multilivello, sfruttandone la sintassi intuitiva e l‚Äôintegrazione con R. Negli approfondimenti, invece, esploreremo come scrivere direttamente modelli in Stan, per comprendere meglio le basi dei PPL e avere maggiore controllo sui dettagli tecnici.\nQuesta combinazione ci permetter√† di bilanciare semplicit√† e potenza, rendendo l‚Äôinferenza bayesiana sia accessibile che personalizzabile, a seconda delle esigenze specifiche del progetto o dell‚Äôanalisi.\n\n\n51.4.4 Introduzione alla sintassi di Wilkinson\nLa sintassi di Wilkinson in R fornisce un modo semplice ed efficace per specificare modelli di regressione lineare, consentendo di descrivere relazioni tra una variabile dipendente (risposta) e una o pi√π variabili indipendenti (predittori) utilizzando una notazione simbolica. Questa sintassi si allinea direttamente al modello matematico, rendendo immediata la corrispondenza tra i termini simbolici e il codice.\n\n51.4.4.1 Modello simbolico e modello Wilkinson\nSupponiamo di voler specificare un modello di regressione lineare multipla con la seguente formula:\n\\[\ny_i = \\alpha + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\varepsilon_i ,\n\\]\ndove:\n\n\\(y_i\\) √® la variabile dipendente per l‚Äôosservazione \\(i\\),\n\\(\\alpha\\) √® l‚Äôintercetta,\n\\(\\beta_1\\) e \\(\\beta_2\\) sono i coefficienti di regressione per i predittori \\(x_1\\) e \\(x_2\\),\n\\(\\varepsilon_i\\) rappresenta l‚Äôerrore residuo, normalmente distribuito (\\(\\varepsilon_i \\sim \\mathcal{N}(0, \\sigma^2)\\)).\n\nIn R, questo modello pu√≤ essere specificato con la sintassi Wilkinson:\ny ~ x1 + x2\n\n\n51.4.4.2 Dettaglio dei componenti\n\nIntercetta implicita:\nLa sintassi R include automaticamente l‚Äôintercetta (\\(\\alpha\\)) quando si utilizza il simbolo +. Ad esempio:\ny ~ x1 + x2\nequivale al modello: \\[\ny_i = \\alpha + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\varepsilon_i\n\\]\nEsclusione dell‚Äôintercetta:\nSe si desidera escludere l‚Äôintercetta (\\(\\alpha\\)), si utilizza - 1 nella specifica:\ny ~ x1 + x2 - 1\nQuesto produce un modello senza intercetta: \\[\ny_i = \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\varepsilon_i\n\\]\nInclusione esplicita dell‚Äôintercetta:\nAnche se √® implicita, l‚Äôintercetta pu√≤ essere specificata esplicitamente con 1 +:\ny ~ 1 + x1 + x2\nQuesto √® equivalente al modello con intercetta implicita.\nInterazione tra predittori:\nLa sintassi Wilkinson consente anche di specificare interazioni. Ad esempio, un‚Äôinterazione tra \\(x_1\\) e \\(x_2\\):\ny ~ x1 * x2\nEspande automaticamente il modello per includere: \\[\ny_i = \\alpha + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\beta_3 (x_{1i} \\cdot x_{2i}) + \\varepsilon_i\n\\]\n\n\n\n51.4.4.3 Esempio pratico\nSupponiamo di avere un dataset con una variabile dipendente y e due predittori x1 e x2. Ecco come specificare e adattare un modello di regressione lineare multipla in R:\n# Specifica del modello\nmodello &lt;- lm(y ~ x1 + x2, data = dataset)\n\n# Sommario del modello\nsummary(modello)\nQuesto codice:\n\nSpecifica un modello con intercetta e due predittori.\nAdatta il modello ai dati contenuti in dataset.\nCalcola i coefficienti (\\(\\alpha, \\beta_1, \\beta_2\\)), i valori di errore standard, i p-value (frequentisti) e altre statistiche di sintesi.\n\nIn sintesi, la sintassi di Wilkinson in R permette di esprimere modelli di regressione lineare in modo conciso e leggibile, rendendo il passaggio dal modello matematico al codice intuitivo e diretto.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>51</span>¬† <span class='chapter-title'>Linguaggi di programmazione probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_ppl.html#riflessioni-conclusive",
    "href": "chapters/mcmc/02_ppl.html#riflessioni-conclusive",
    "title": "51¬† Linguaggi di programmazione probabilistici",
    "section": "51.5 Riflessioni Conclusive",
    "text": "51.5 Riflessioni Conclusive\nI linguaggi di programmazione probabilistica (PPL) rappresentano strumenti potenti per la specificazione completa e flessibile di modelli bayesiani, consentendo agli utenti di definire ogni aspetto del modello, dai priori alla verosimiglianza, fino agli algoritmi di inferenza. Strumenti come Stan e PyMC permettono un controllo dettagliato sui modelli, rendendoli ideali per analisi avanzate e progetti personalizzati.\nTuttavia, questo livello di controllo richiede competenze di programmazione e una comprensione approfondita della statistica bayesiana. Per superare queste barriere e rendere l‚Äôinferenza bayesiana accessibile a un pubblico pi√π ampio, sono state sviluppate interfacce di alto livello come brms (basata su Stan) e Bambi (basata su PyMC). Questi strumenti semplificano enormemente il processo, consentendo agli utenti di specificare modelli statistici complessi senza la necessit√† di scrivere codice dettagliato, grazie a una sintassi intuitiva come quella di Wilkinson.\nIn sintesi:\n\nI PPL offrono flessibilit√† massima e un controllo completo, ma richiedono esperienza nella programmazione.\nLe interfacce di alto livello rendono possibile l‚Äôinferenza bayesiana anche a chi preferisce evitare la programmazione, garantendo un compromesso tra semplicit√† e capacit√† di personalizzazione.\n\nLa scelta tra un PPL e un‚Äôinterfaccia di alto livello dipende quindi dalle esigenze specifiche: chi necessita di modelli estremamente personalizzati e complessi opter√† per un PPL come Stan o PyMC, mentre chi desidera facilit√† d‚Äôuso senza rinunciare alla potenza dell‚Äôinferenza bayesiana trover√† in brms o Bambi strumenti ideali. In ogni caso, la crescente disponibilit√† di strumenti e risorse rende oggi l‚Äôinferenza bayesiana pi√π accessibile che mai, anche per chi non ha un background tecnico avanzato.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>51</span>¬† <span class='chapter-title'>Linguaggi di programmazione probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_ppl.html#bibliografia",
    "href": "chapters/mcmc/02_ppl.html#bibliografia",
    "title": "51¬† Linguaggi di programmazione probabilistici",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nWilkinson, G., & Rogers, C. (1973). Symbolic description of factorial models for analysis of variance. Journal of the Royal Statistical Society Series C: Applied Statistics, 22(3), 392‚Äì399.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>51</span>¬† <span class='chapter-title'>Linguaggi di programmazione probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html",
    "href": "chapters/mcmc/07_bayesian_workflow.html",
    "title": "52¬† Flusso di lavoro bayesiano",
    "section": "",
    "text": "52.1 Introduzione\nL‚Äôapplicazione dell‚Äôinferenza bayesiana nella risoluzione di problemi reali richiede un approccio strutturato e multidisciplinare, noto come workflow bayesiano. Questo processo iterativo e complesso va ben oltre la semplice applicazione della regola di Bayes, che pur costituendo il fondamento teorico dell‚Äôinferenza bayesiana, rappresenta solo il punto di partenza di un percorso analitico pi√π articolato.\nIl workflow bayesiano include molteplici fasi interconnesse, tra cui:\nPer esempio, immaginiamo di voler valutare l‚Äôefficacia di un intervento psicologico. Il ricercatore deve affrontare diverse decisioni: quali variabili includere (covariate), come modellare i dati gerarchici (ad esempio, individui e gruppi), e quali distribuzioni utilizzare per rappresentare incertezze (priori). Queste decisioni, lungi dall‚Äôessere definitive, richiedono continui aggiustamenti basati sui risultati intermedi.\nUn ulteriore aspetto critico √® la gestione di possibili problemi computazionali. Ad esempio, il campionamento MCMC (Markov Chain Monte Carlo) potrebbe non convergere correttamente, richiedendo modifiche al modello o all‚Äôapproccio algoritmico. Inoltre, il workflow bayesiano non si limita alla stima dei parametri: include la valutazione della capacit√† del modello di fare previsioni attendibili e il confronto tra modelli alternativi.\nInfine, √® fondamentale bilanciare la complessit√† del modello con la rilevanza pratica dei risultati. Modelli troppo semplici possono portare a conclusioni distorte, mentre modelli troppo complessi possono diventare difficili da interpretare. Il workflow bayesiano aiuta i ricercatori a navigare queste sfide, fornendo un quadro metodologico flessibile e iterativo.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>¬† <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html#introduzione",
    "href": "chapters/mcmc/07_bayesian_workflow.html#introduzione",
    "title": "52¬† Flusso di lavoro bayesiano",
    "section": "",
    "text": "Costruzione iterativa del modello: Definizione e revisione di modelli probabilistici che rappresentano i processi generativi dei dati.\nVerifica e validazione: Controllo della qualit√† delle stime e valutazione delle capacit√† predittive del modello.\nRisultati e interpretazione: Confronto tra modelli alternativi per trarre conclusioni solide.\nGestione di problemi computazionali: Identificazione e soluzione di eventuali difficolt√† nell‚Äôadattamento del modello.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>¬† <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html#principi-del-workflow-bayesiano",
    "href": "chapters/mcmc/07_bayesian_workflow.html#principi-del-workflow-bayesiano",
    "title": "52¬† Flusso di lavoro bayesiano",
    "section": "52.2 Principi del workflow bayesiano",
    "text": "52.2 Principi del workflow bayesiano\nUn workflow √® una sequenza strutturata di passi che definisce cosa costituisce una ‚Äúbuona pratica‚Äù in un determinato ambito. Nel contesto dell‚Äôinferenza bayesiana, il workflow si ispira a concetti come il Ciclo di Box e le pi√π recenti estensioni proposte da studiosi come Gelman e Riha.\n\n52.2.1 Il Ciclo di Box\nGeorge Box, uno dei pionieri della statistica moderna, ha sviluppato negli anni ‚Äô60 un approccio ciclico alla modellizzazione statistica, noto come Ciclo di Box. Questo paradigma sottolinea che la modellizzazione non √® un processo lineare, ma un ciclo continuo di miglioramento.\n\n\n\nFigura tratta da Blei (2014).\n\n\nIl Ciclo di Box si articola in una serie di fasi iterative:\n\nFormulazione del modello: Si costruisce un modello basato sulle conoscenze disponibili e sui dati osservati.\nInferenza: Si stimano i parametri del modello e si valutano le incertezze associate.\nValutazione del modello: Si verifica quanto il modello si adatta ai dati.\nRevisione del modello: Si corregge il modello in base alle discrepanze identificate.\n\nQuesto approccio iterativo √® il cuore del workflow bayesiano. La capacit√† dell‚Äôinferenza bayesiana di aggiornare le credenze a priori alla luce di nuovi dati lo rende particolarmente adatto a essere integrato nel Ciclo di Box. Pi√π recentemente, Gelman et al. (2020) hanno proposto una versione estesa del Ciclo di Box, fornendo una guida dettagliata per implementare un workflow bayesiano completo.\n\n\n\nFigura tratta da Gelman et al. (2020).",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>¬† <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html#costruzione-iterativa-del-modello",
    "href": "chapters/mcmc/07_bayesian_workflow.html#costruzione-iterativa-del-modello",
    "title": "52¬† Flusso di lavoro bayesiano",
    "section": "52.3 Costruzione iterativa del modello",
    "text": "52.3 Costruzione iterativa del modello\nIl processo di costruzione di un modello bayesiano pu√≤ essere descritto attraverso i seguenti passaggi:\n\nComprensione del fenomeno e formulazione del problema: Il punto di partenza √® definire chiaramente la domanda di ricerca. L‚Äôobiettivo non √® semplicemente descrivere correlazioni tra variabili, ma comprendere i meccanismi generativi dei dati.\nFormulazione matematica: Si costruisce un modello probabilistico che rappresenti il processo generativo, spesso utilizzando linguaggi probabilistici (PPL) come Stan o PyMC.\nImplementazione: Il modello viene tradotto in codice utilizzando interfacce software come R, Python o Julia, che permettono di adattare modelli complessi ai dati.\nVerifiche predittive a priori: Si simulano dati basandosi sulle distribuzioni a priori per verificare che i parametri scelti siano ragionevoli.\nAdattamento del modello: Si utilizza un algoritmo di campionamento per stimare i parametri del modello dai dati osservati (ad esempio, cmdstanr o cmdstanpy).\nDiagnostiche di convergenza: Si verifica che le catene MCMC abbiano raggiunto la convergenza, utilizzando strumenti come il valore R-hat.\nVerifiche predittive a posteriori: Si generano dati simulati a partire dalla distribuzione a posteriori per confrontarli con i dati reali e valutare la bont√† del modello.\nIterazione: Sulla base dei risultati, il modello viene raffinato e migliorato.\n\nQuesto processo iterativo consente di costruire modelli che siano sia robusti sia interpretabili.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>¬† <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html#analisi-multiverso",
    "href": "chapters/mcmc/07_bayesian_workflow.html#analisi-multiverso",
    "title": "52¬† Flusso di lavoro bayesiano",
    "section": "52.4 Analisi Multiverso",
    "text": "52.4 Analisi Multiverso\nL‚Äôanalisi multiverso, introdotta recentemente (Riha et al., 2024), amplia il workflow bayesiano, permettendo di esplorare simultaneamente molteplici modelli alternativi. Ogni modello rappresenta una combinazione unica di scelte modellistiche (ad esempio, covariate, distribuzioni a priori, o assunzioni sul processo generativo).\nI vantaggi principali dell‚Äôanalisi multiverso includono:\n\nTrasparenza: Documenta tutte le scelte di modellizzazione.\nEsplorazione completa: Riduce il rischio di trascurare ipotesi rilevanti.\nConfronto diretto: Permette di identificare i modelli pi√π adatti basandosi su criteri come l‚ÄôExpected Log-Predictive Density (ELPD).\nRobustezza: Esamina come le conclusioni cambiano tra diversi modelli.\nReplicabilit√†: Fornisce informazioni dettagliate per riprodurre l‚Äôanalisi e i risultati.\n\nQuesto approccio incorpora anche verifiche computazionali e analisi di sensibilit√†. Le prime identificano i modelli che necessitano di ulteriori verifiche per garantire l‚Äôaffidabilit√† dei risultati, mentre le seconde esaminano la robustezza delle conclusioni rispetto alle diverse scelte di modellazione e all‚Äôinfluenza delle priori sulle stime posteriori.\nTuttavia, la generazione di numerosi modelli pu√≤ complicare la gestione e l‚Äôinterpretazione dei risultati. Per affrontare questa sfida, Riha et al. (2024) propongono un metodo di ‚Äúiterative filtering‚Äù che comprende:\n\nCreazione di un multiverso iniziale di modelli.\nValutazione delle capacit√† predittive attraverso controlli predittivi posteriori (PPC) e calcolo dell‚Äôexpected log point-wise predictive density (elpd).\nVerifica della qualit√† computazionale, esaminando convergenza ed efficienza del campionamento MCMC.\nFiltraggio iterativo basato su criteri di qualit√† predefiniti.\nPossibilit√† di estendere il multiverso e ripetere il processo.\n\nQuesto approccio mantiene i vantaggi della multiverse analysis riducendo al contempo la complessit√† attraverso un filtraggio sistematico. Il risultato √® un workflow bayesiano pi√π robusto e informativo, che bilancia la necessit√† di considerare molteplici ipotesi modellistiche con l‚Äôesigenza pratica di focalizzarsi sui modelli pi√π promettenti per il problema in esame.\nUno dei casi di studio esaminati da Riha et al. (2024) riguarda l‚Äôanalisi del numero di crisi epilettiche in relazione a diverse variabili (covariate) e scelte di modellazione. I dati utilizzati provengono dallo studio di Leppik et al. (1987) e sono disponibili nel pacchetto R brms.\nSono stati confrontati 24 modelli statistici, ciascuno con una specifica formulazione matematica (illustrata nella Tabella seguente). La scelta dei modelli ha riguardato diverse combinazioni di covariate e di distribuzioni di probabilit√† per descrivere il fenomeno in esame.\n\n\n\nTabella 1 ricavata da Riha et al. (2024).\n\n\nPer valutare la capacit√† predittiva dei modelli, √® stato utilizzato il criterio ELPD (Expected Log-Predictive Density). I risultati sono riportati nel grafico seguente.\n\n\n\nFigura 12 ricavata da Riha et al. (2024).\n\n\nCome si pu√≤ osservare, i modelli presentano performance predittive differenti.\nOltre all‚ÄôELPD, sono stati condotti controlli predittivi posteriori (PPC) per valutare la plausibilit√† dei modelli rispetto ai dati osservati. I risultati dei PPC sono visualizzati nella figura seguente.\n\n\n\nFigura 13 ricavata da Riha et al. (2024).\n\n\nIl modello selezionato √® quello che ha mostrato il miglior valore di ELPD, evidenziando una buona capacit√† predittiva. Inoltre, i controlli PPC hanno confermato la plausibilit√† del modello rispetto ai dati osservati. Infine, il modello selezionato non ha presentato problemi computazionali durante la stima dei parametri.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>¬† <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html#riflessioni-conclusive",
    "href": "chapters/mcmc/07_bayesian_workflow.html#riflessioni-conclusive",
    "title": "52¬† Flusso di lavoro bayesiano",
    "section": "52.5 Riflessioni Conclusive",
    "text": "52.5 Riflessioni Conclusive\nIl workflow bayesiano rappresenta una strategia strutturata e iterativa per affrontare l‚Äôanalisi dei dati complessi. Attraverso strumenti come le verifiche predittive e l‚Äôanalisi multiverso, consente di sviluppare modelli solidi e capaci di adattarsi a nuovi dati e conoscenze. La sua integrazione con linguaggi come Stan o PyMC ne facilita l‚Äôapplicazione, rendendolo un approccio essenziale per la ricerca moderna.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>¬† <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html#bibliografia",
    "href": "chapters/mcmc/07_bayesian_workflow.html#bibliografia",
    "title": "52¬† Flusso di lavoro bayesiano",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlei, D. M. (2014). Build, compute, critique, repeat: Data analysis with latent variable models. Annual Review of Statistics and Its Application, 1(1), 203‚Äì232.\n\n\nBulbulia, J. A. (2023). A workflow for causal inference in cross-cultural psychology. Religion, Brain & Behavior, 13(3), 291‚Äì306.\n\n\nGelman, A., Vehtari, A., Simpson, D., Margossian, C. C., Carpenter, B., Yao, Y., Kennedy, L., Gabry, J., B√ºrkner, P.-C., & Modr√°k, M. (2020). Bayesian workflow. arXiv preprint arXiv:2011.01808.\n\n\nLeppik, I., Dreifuss, F., Porter, R., Bowman, T., Santilli, N., Jacobs, M., Crosby, C., Cloyd, J., Stackman, J., Graves, N., et al. (1987). A controlled study of progabide in partial seizures: methodology and results. Neurology, 37(6), 963‚Äì963.\n\n\nRiha, A. E., Siccha, N., Oulasvirta, A., & Vehtari, A. (2024). Supporting Bayesian modelling workflows with iterative filtering for multiverse analysis. arXiv preprint arXiv:2404.01688.\n\n\nSteegen, S., Tuerlinckx, F., Gelman, A., & Vanpaemel, W. (2016). Increasing transparency through a multiverse analysis. Perspectives on Psychological Science, 11(5), 702‚Äì712.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>¬† <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/introduction_linear_models.html",
    "href": "chapters/linear_models/introduction_linear_models.html",
    "title": "Introduzione",
    "section": "",
    "text": "Gli obiettivi di questo insegnamento riguardano i casi pi√π semplici di inferenza statistica, cio√® l‚Äôinferenza su una singola media, la differenza tra due medie, e l‚Äôanalisi del modello di regressione lineare (bivariato e multiplo) con predittori sia quantitativi sia qualitativi.\nTradizionalmente, l‚Äôinferenza su una media o sulla differenza tra due medie viene affrontata tramite il test t di Student, in un‚Äôottica frequentista. In una prospettiva pi√π moderna, tuttavia, questi argomenti possono essere inquadrati nel framework generale del modello lineare. Di conseguenza, in questa sezione della dispensa presenteremo il modello lineare sia dal punto di vista bayesiano sia frequentista, mostrando come l‚Äôinferenza su una o due medie rappresenti in realt√† un caso particolare di questo impianto metodologico.",
    "crumbs": [
      "Regressione",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html",
    "href": "chapters/linear_models/01_reglin_frequentist.html",
    "title": "53¬† La regressione lineare bivariata: un approccio frequentista",
    "section": "",
    "text": "53.1 Introduzione\nLa regressione √® un metodo fondamentale che consente ai ricercatori di riassumere come le previsioni o i valori medi di una variabile risultato (dipendente) variano in funzione di un insieme di predittori (indipendenti). Grazie alla sua versatilit√†, la regressione √® utilizzata in un‚Äôampia gamma di contesti, dai modelli predittivi alla valutazione degli effetti causali.\nSecondo Gelman et al. (2021), i principali utilizzi della regressione includono:\nIn tutti questi contesti, √® cruciale che il modello includa tutte le variabili rilevanti. Ad esempio, in uno studio sull‚Äôefficacia di una terapia per la depressione, fattori come et√†, condizioni di salute preesistenti e supporto sociale devono essere inclusi nel modello per evitare conclusioni fuorvianti.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>53</span>¬† <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#introduzione",
    "href": "chapters/linear_models/01_reglin_frequentist.html#introduzione",
    "title": "53¬† La regressione lineare bivariata: un approccio frequentista",
    "section": "",
    "text": "Previsione: Modellare osservazioni esistenti o prevedere nuovi dati, sia continui che categoriali.\n\nAd esempio: prevedere punteggi futuri in un test, monitorare il benessere psicologico in uno studio longitudinale o classificare individui in base alla probabilit√† di successo in un compito cognitivo.\n\nEsplorazione delle associazioni: Quantificare il grado di relazione tra una o pi√π variabili indipendenti e un risultato.\n\nAd esempio: studiare i tratti di personalit√† associati alla resilienza allo stress, analizzare la relazione tra stili di attaccamento infantile e capacit√† relazionali in et√† adulta, o valutare l‚Äôimpatto di fattori socio-economici sullo sviluppo cognitivo nei bambini.\n\nEstrapolazione: Generalizzare i risultati osservati in un campione a una popolazione pi√π ampia.\n\nAd esempio: stimare l‚Äôefficacia di una terapia testata su studenti universitari per la popolazione generale, oppure prevedere l‚Äôimpatto di un intervento scolastico su un intero distretto partendo dai risultati osservati in alcune scuole.\n\nInferenza causale: Stimare gli effetti di un trattamento o intervento.\n\nAd esempio: valutare l‚Äôefficacia di un programma di mindfulness sui livelli di ansia, stimare l‚Äôimpatto di una tecnica psicoterapeutica per il disturbo post-traumatico da stress o determinare l‚Äôeffetto di un intervento educativo su una popolazione diversificata.\n\n\n\n\n\n53.1.1 Approccio frequentista\nI modelli lineari hanno una lunga storia nella statistica. Come riportato da Stigler (1986), il metodo dei minimi quadrati per adattare un modello di regressione lineare bivariata fu introdotto nel XVIII secolo per problemi di analisi dei dati in astronomia. Ad esempio, gli astronomi lo utilizzavano per determinare il moto della Luna o per modellare i movimenti non periodici di Giove e Saturno. In quel contesto, l‚Äôomogeneit√† dei dati raccolti direttamente dagli astronomi favor√¨ l‚Äôadozione di questi metodi, in netto contrasto con le scienze sociali, dove la variabilit√† dei dati raccolti ritardava l‚Äôadozione della regressione.\n\n\n\n53.1.2 Il modello lineare bivariato\nNel contesto frequentista, il modello di regressione lineare bivariata consente di predire una variabile continua \\(y\\) sulla base di un singolo predittore continuo \\(x\\). La relazione tra le due variabili √® espressa dall‚Äôequazione della retta di regressione:\n\\[\ny_i = a + b x_i + e_i, \\quad i = 1, \\dots, n,\n\\tag{53.1}\\]\ndove:\n\n\\(a\\) √® l‚Äôintercetta (valore atteso di \\(y\\) quando \\(x = 0\\)),\n\\(b\\) √® la pendenza della retta (coefficiente di regressione, che misura il cambiamento atteso in \\(y\\) per unit√† di incremento in \\(x\\)),\n\\(e_i\\) √® l‚Äôerrore residuo (la differenza tra il valore osservato di \\(y_i\\) e il valore predetto dal modello).\n\n\n\n53.1.2.1 Aspetti principali\n\nStima dei coefficienti\nI coefficienti \\(a\\) e \\(b\\) vengono stimati mediante il metodo dei minimi quadrati, che minimizza la somma dei quadrati degli errori residui (\\(\\sum e_i^2\\)).\nInterpretazione dei coefficienti\n\n\\(a\\): rappresenta il valore medio previsto di \\(y\\) quando \\(x = 0\\).\n\n\\(b\\): indica la variazione media prevista in \\(y\\) per ogni unit√† di variazione in \\(x\\).\n\nValutazione del modello\nLa bont√† di adattamento del modello viene valutata attraverso:\n\nL‚Äôindice di determinazione (\\(R^2\\)), che misura la proporzione della varianza di \\(y\\) spiegata dal modello.\nL‚Äôanalisi dei residui, che verifica la presenza di eventuali pattern non catturati dal modello.\n\n\n\nQuesto capitolo illustrer√† come applicare e interpretare il modello di regressione bivariata, collegandolo successivamente al modello lineare multiplo e agli approcci pi√π avanzati per l‚Äôinferenza causale.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>53</span>¬† <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#la-predizione-dellintelligenza",
    "href": "chapters/linear_models/01_reglin_frequentist.html#la-predizione-dellintelligenza",
    "title": "53¬† La regressione lineare bivariata: un approccio frequentista",
    "section": "53.2 La Predizione dell‚ÄôIntelligenza",
    "text": "53.2 La Predizione dell‚ÄôIntelligenza\nNella presente discussione, esamineremo i dati kidiq che consistono in una raccolta di dati provenienti da una survey su donne adulte americane e i loro figli, selezionati da un sotto-campione del National Longitudinal Survey of Youth (Gelman et al., 2021).\nNello specifico, ci concentreremo sulla relazione tra il punteggio di intelligenza del bambino (kid_score) e quello della madre (mom_iq). Ci proponiamo di valutare se e in quale misura l‚Äôintelligenza della madre possa prevedere l‚Äôintelligenza del bambino. Per fare ci√≤, inizieremo ad importare i dati nell‚Äôambiente R.\n\n# Caricamento dei dati\nkidiq &lt;- rio::import(here::here(\"data\", \"kidiq.dta\"))\n\n\n# Anteprima dei dati\nhead(kidiq)\n#&gt;   kid_score mom_hs mom_iq mom_work mom_age\n#&gt; 1        65      1  121.1        4      27\n#&gt; 2        98      1   89.4        4      25\n#&gt; 3        85      1  115.4        4      27\n#&gt; 4        83      1   99.4        3      25\n#&gt; 5       115      1   92.7        4      27\n#&gt; 6        98      0  107.9        1      18\n\nUn diagramma a dispersione per i dati di questo campione suggerisce la presenza di un‚Äôassociazione positiva tra l‚Äôintelligenza del bambino (kid_score) e l‚Äôintelligenza della madre (mom_iq).\n\nggplot(kidiq, aes(x = mom_iq, y = kid_score)) +\n  geom_point(alpha = 0.4) +\n  labs(x = \"QI della madre\", y = \"QI del bambino\") +\n  ggtitle(\"Diagramma a dispersione\")",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>53</span>¬† <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#stima-del-modello-di-regressione-lineare",
    "href": "chapters/linear_models/01_reglin_frequentist.html#stima-del-modello-di-regressione-lineare",
    "title": "53¬† La regressione lineare bivariata: un approccio frequentista",
    "section": "53.3 Stima del modello di regressione lineare",
    "text": "53.3 Stima del modello di regressione lineare\nCalcoliamo i coefficienti della retta di regressione utilizzando la funzione lm.\n\n# Modello di regressione lineare\nmod &lt;- lm(kid_score ~ mom_iq, data = kidiq)\n\n\n# Coefficienti stimati\ncoef(mod)\n#&gt; (Intercept)      mom_iq \n#&gt;       25.80        0.61\n\nCi sono per√≤ infinite rette che, in linea di principio, possono essere usate per ‚Äúapprossimare‚Äù la nube di punti nel diagramma a dispersione. √à dunque necessario introdurre dei vincoli per selezionare una di queste possibili rette. Il vincolo che viene introdotto dal modello di regressione √® quello di costringere la retta a passare per il punto \\((\\bar{x}, \\bar{y})\\).\n\n# Calcola le medie per mom_iq e kid_score\nmean_x &lt;- mean(kidiq$mom_iq, na.rm = TRUE)\nmean_y &lt;- mean(kidiq$kid_score, na.rm = TRUE)\n\n# Aggiungi il punto medio al grafico\nggplot(kidiq, aes(x = mom_iq, y = kid_score)) +\n  geom_point(alpha = 0.4) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"blue\") +\n  annotate(\n    \"point\", x = mean_x, y = mean_y, color = \"red\", size = 5, \n    shape = 4, stroke = 3) +\n  labs(x = \"QI della madre\", y = \"QI del bambino\") +\n  ggtitle(\"Retta di regressione\")\n#&gt; `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nUna retta di regressione che passa per il punto medio \\((\\bar{x}, \\bar{y})\\) (che rappresenta il centro di massa dei dati) √® preferibile dal punto di vista statistico poich√© minimizza la somma dei quadrati degli errori residui.\nIl campione √® costituito da \\(n\\) coppie di osservazioni (\\(x, y\\)).\n\\[\n\\begin{array}{cc}\n\\hline\nx_1 & y_1 \\\\\nx_2 & y_2 \\\\\nx_3 & y_3 \\\\\n\\vdots & \\vdots \\\\\nx_n & y_n \\\\\n\\hline\n\\end{array}\n\\]\nPer ciascuna coppia di valori \\(x_i, y_i\\), il modello di regressione si aspetta che il valore \\(y_i\\) sia associato al corrispondente valore \\(x_i\\) come indicato dalla seguente equazione\n\\[\n\\begin{equation}\n\\mathbb{E}(y_i) = a + b x_i ,\n\\end{equation}\n\\tag{53.2}\\]\novvero:\n\\[\n\\begin{array}{ccc}\n\\hline\nx_i & y_i & \\mathbb{E}(y_i) = a + b x_i \\\\\n\\hline\nx_1 & y_1 & a + b x_1 \\\\\nx_2 & y_2 & a + b x_2 \\\\\nx_3 & y_3 & a + b x_3 \\\\\n\\vdots & \\vdots & \\vdots \\\\\nx_n & y_n & a + b x_n \\\\\n\\hline\n\\end{array}\n\\]\nI valori \\(y_i\\) corrispondono, nell‚Äôesempio che stiamo discutendo, alla variabile kid_score. I primi 10 valori della variabile \\(y\\) sono i seguenti:\n\nkidiq$kid_score[0:10]\n#&gt;  [1]  65  98  85  83 115  98  69 106 102  95\n\nPer fare riferimento a ciascuna osservazione usiamo l‚Äôindice \\(i\\). Quindi, ad esempio, \\(y_2\\) √® uguale a\n\nkidiq$kid_score[2]\n#&gt; [1] 98\n\nIl modello di regressione lineare bivariata, rappresentato dall‚Äôequazione \\(y_i = a + b x_i + e_i\\), descrive la relazione tra le variabili \\(x\\) e \\(y\\), dove \\(y\\) √® la variabile dipendente (nel nostro esempio, la variabile kid_score) e \\(x\\) √® la variabile indipendente (nel nostro esempio, la variabile mom_iq).\nIl valore di \\(y\\) √® la somma di due componenti:\n\nla componente deterministica, \\(\\hat{y}_i = a + b x_i\\), rappresenta la porzione della \\(y\\) che √® prevedibile conoscendo il valore di \\(x\\);\nla componente aleatoria, \\(e_i\\), rappresenta la porzione della \\(y\\) che non √® prevedibile dal modello.\n\nIl modello lineare cerca di trovare i coefficienti \\(a\\) e \\(b\\) che permettono di prevedere la componente deterministica di \\(y\\) conoscendo il valore di \\(x\\). Tuttavia, poich√© la retta √® solo un‚Äôapprossimazione della relazione tra \\(x\\) e \\(y\\), la componente deterministica rappresenta solo una stima approssimata della vera relazione tra le due variabili.\nPer valutare l‚Äôaccuratezza del modello di regressione lineare, √® necessario calcolare il residuo\n\\[\ne_i = y_i - (a + b x_i) ,\n\\tag{53.3}\\]\novvero la differenza tra il valore osservato di \\(y\\) e il valore previsto dal modello, \\(\\hat{y}\\). La dimensione del residuo indica quanto la componente aleatoria contribuisce al valore osservato di \\(y\\).\nIl modello di regressione lineare ha tre obiettivi (Fox, 2015):\n\nil primo √® quello di trovare i coefficienti \\(a\\) e \\(b\\) che permettono di prevedere la componente deterministica di \\(y\\) conoscendo il valore di \\(x\\);\nil secondo obiettivo √® quello di valutare l‚Äôaccuratezza della predizione fornita dal modello di regressione lineare;\ninfine, il terzo obiettivo √® quello dell‚Äôinferenza, ovvero quello di capire quali relazioni esistono tra la relazione tra \\(x\\) e \\(y\\) osservata nel campione e la relazione tra le due variabili nella popolazione.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>53</span>¬† <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#stima-dei-coefficienti-di-regressione",
    "href": "chapters/linear_models/01_reglin_frequentist.html#stima-dei-coefficienti-di-regressione",
    "title": "53¬† La regressione lineare bivariata: un approccio frequentista",
    "section": "53.4 Stima dei coefficienti di regressione",
    "text": "53.4 Stima dei coefficienti di regressione\nIn breve, stiamo cercando di descrivere una relazione tra due variabili, il QI della madre e il QI del bambino, utilizzando un modello di regressione lineare. L‚Äôequazione lineare che descrive la relazione tra le due variabili √® della forma \\(\\hat{y}_i = a_i + bx_i\\), dove \\(\\hat{y}_i\\) rappresenta la previsione per il QI del bambino \\(i\\)-esimo, \\(a_i\\) e \\(b\\) sono i coefficienti di regressione che vogliamo trovare e \\(x_i\\) √® il QI della madre del bambino \\(i\\)-esimo.\nPer trovare i coefficienti di regressione, dobbiamo introdurre dei vincoli per limitare lo spazio delle possibili soluzioni. Il primo vincolo √® che la retta di regressione deve passare per il baricentro del grafico a dispersione. Il secondo vincolo √® che vogliamo minimizzare la somma dei quadrati dei residui, ovvero la differenza tra il valore osservato e il valore previsto dal modello. I coefficienti di regressione che soddisfano questi vincoli si chiamano coefficienti dei minimi quadrati.\nIl problema di trovare i coefficienti di regressione \\(a\\) e \\(b\\) che minimizzano la somma dei quadrati dei residui ha una soluzione analitica. Questa soluzione si ottiene trovando il punto di minimo di una superficie tridimensionale che rappresenta la somma dei quadrati dei residui. Il punto di minimo √® quello per cui il piano tangente alla superficie nelle due direzioni \\(a\\) e \\(b\\) √® piatto, cio√® le derivate parziali rispetto ad \\(a\\) e \\(b\\) sono uguali a zero. In pratica, ci√≤ significa risolvere un sistema di equazioni lineari con due incognite \\(a\\) e \\(b\\), noto come equazioni normali.\nLa soluzione delle equazioni normali ci fornisce i coefficienti di regressione stimati, che minimizzano la somma dei quadrati dei residui. La formula per il coefficiente \\(a\\) √®\n\\[\na = \\bar{y} - b \\bar{x} ,\n\\tag{53.4}\\]\nla formula per il coefficiente \\(b\\) √®\n\\[\nb = \\frac{Cov(x, y)}{Var(x)},\n\\tag{53.5}\\]\ndove \\(\\bar{x}\\) e \\(\\bar{y}\\) sono le medie delle variabili \\(x\\) e \\(y\\), \\(Cov(x,y)\\) √® la covarianza tra \\(x\\) e \\(y\\) e \\(Var(x)\\) √® la varianza di \\(x\\).\nQueste equazioni rappresentano la stima dei minimi quadrati dei coefficienti di regressione che ci permettono di trovare la retta che minimizza la somma dei quadrati dei residui.\n\n53.4.1 Calcolo manuale dei coefficienti di regressione\nCalcoliamo i coefficientii dei minimi quadrati con l‚ÄôEquazione¬†53.4 e l‚ÄôEquazione¬†53.5:\n\n# Calcolo manuale dei coefficienti\ncov_xy &lt;- cov(kidiq$kid_score, kidiq$mom_iq)  # Covarianza tra le due variabili\nvar_x &lt;- var(kidiq$mom_iq)  # Varianza della variabile indipendente\nb &lt;- cov_xy / var_x  # Pendenza (coefficiente b)\nb\n#&gt; [1] 0.61\n\n\n# Intercetta (coefficiente a)\na &lt;- mean(kidiq$kid_score) - b * mean(kidiq$mom_iq)\na\n#&gt; [1] 25.8\n\nI risultati replicano quelli ottenuti in precedenza con lm().\n\n\n53.4.2 Interpretazione\nIl coefficiente \\(a\\) indica l‚Äôintercetta della retta di regressione nel diagramma a dispersione. Questo valore rappresenta il punto in cui la retta di regressione interseca l‚Äôasse \\(y\\) del sistema di assi cartesiani. Tuttavia, in questo caso specifico, il valore di \\(a\\) non √® di particolare interesse poich√© corrisponde al valore della retta di regressione quando l‚Äôintelligenza della madre √® pari a 0, il che non ha senso nella situazione reale. Successivamente, vedremo come √® possibile trasformare i dati per fornire un‚Äôinterpretazione utile del coefficiente \\(a\\).\nInvece, il coefficiente \\(b\\) indica la pendenza della retta di regressione, ovvero di quanto aumenta (se \\(b\\) √® positivo) o diminuisce (se \\(b\\) √® negativo) la retta di regressione in corrispondenza di un aumento di 1 punto della variabile \\(x\\). Nel caso specifico del QI delle madri e dei loro figli, il coefficiente \\(b\\) ci indica che un aumento di 1 punto del QI delle madri √® associato, in media, a un aumento di 0.61 punti del QI dei loro figli.\nIn pratica, il modello di regressione lineare cerca di prevedere le medie dei punteggi del QI dei figli in base al QI delle madri. Ci√≤ significa che non √® in grado di prevedere esattamente il punteggio di ciascun bambino in funzione del QI della madre, ma solo una stima della media dei punteggi dei figli quando il QI delle madri aumenta o diminuisce di un punto.\nIl coefficiente \\(b\\) ci dice di quanto aumenta (o diminuisce) in media il QI dei figli per ogni unit√† di aumento (o diminuzione) del QI della madre. Nel nostro caso, se il QI della madre aumenta di un punto, il QI dei figli aumenta in media di 0.61 punti.\n√à importante comprendere che il modello statistico di regressione lineare non √® in grado di prevedere il valore preciso di ogni singolo bambino, ma solo una stima della media dei punteggi del QI dei figli quando il QI delle madri aumenta o diminuisce. Questa stima √® basata su una distribuzione di valori possibili che si chiama distribuzione condizionata \\(p(y \\mid x_i)\\).\nUna rappresentazione grafica del valore predetto dal modello di regressione, \\(\\hat{y}_i = a + bx_i\\) √® stato fornito in precedenza. Il diagramma presenta ciascun valore \\(\\hat{y}_i = a + b x_i\\) in funzione di \\(x_i\\). I valori predetti dal modello di regressione sono i punti che stanno sulla retta di regressione.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>53</span>¬† <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#residui",
    "href": "chapters/linear_models/01_reglin_frequentist.html#residui",
    "title": "53¬† La regressione lineare bivariata: un approccio frequentista",
    "section": "53.5 Residui",
    "text": "53.5 Residui\nIn precedenza abbiamo detto che il residuo, ovvero la componente di ciascuna osservazione \\(y_i\\) che non viene predetta dal modello di regressione, corrisponde alla distanza verticale tra il valore \\(y_i\\) osservato e il valore \\(\\hat{y}_i\\) predetto dal modello di regressione:\n\\[\ne_i = y_i - (a + b x_i).\n\\]\nPer fare un esempio numerico, consideriamo il punteggio osservato del QI del primo bambino.\n\nkidiq$kid_score[1]\n#&gt; [1] 65\n\nIl QI della madre √®\n\nkidiq$mom_iq[1]\n#&gt; [1] 121\n\nPer questo bambino, il valore predetto dal modello di regressione √®\n\na + b * kidiq$mom_iq[1]\n#&gt; [1] 99.7\n\nL‚Äôerrore che compiamo per predire il QI del bambino utilizzando il modello di regressione (ovvero, il residuo) √®\n\nkidiq$kid_score[1] - (a + b * kidiq$mom_iq[1])\n#&gt; [1] -34.7\n\nPer tutte le osservazioni abbiamo\n\nres &lt;- kidiq$kid_score - (a + b * kidiq$mom_iq)\n\n√à una propriet√† del modello di regressione (calcolato con il metodo dei minimi quadrati) che la somma dei residui sia uguale a zero.\n\nsum(res)\n#&gt; [1] 1.44e-11\n\nQuesto significa che ogni valore osservato \\(y_i\\) viene scomposto dal modello di regressione in due componenti distinte. La componente deterministica \\(\\hat{y}_i\\), che √® predicibile da \\(x_i\\), √® data da \\(\\hat{y}_i = a + b x_i\\). Il residuo, invece, √® dato da \\(e_i = y_i - \\hat{y}_i\\). La somma di queste due componenti, ovviamente, riproduce il valore osservato.\n\n# Creazione di un data frame con i valori calcolati\ndf &lt;- data.frame(\n  kid_score = kidiq$kid_score,\n  mom_iq = kidiq$mom_iq,\n  y_hat = a + b * kidiq$mom_iq,\n  e = kidiq$kid_score - (a + b * kidiq$mom_iq),\n  y_hat_plus_e = (a + b * kidiq$mom_iq) + (kidiq$kid_score - (a + b * kidiq$mom_iq))\n)\n\n# Visualizzazione dei primi 6 valori\nhead(df)\n#&gt;   kid_score mom_iq y_hat      e y_hat_plus_e\n#&gt; 1        65  121.1  99.7 -34.68           65\n#&gt; 2        98   89.4  80.3  17.69           98\n#&gt; 3        85  115.4  96.2 -11.22           85\n#&gt; 4        83   99.4  86.5  -3.46           83\n#&gt; 5       115   92.7  82.4  32.63          115\n#&gt; 6        98  107.9  91.6   6.38           98",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>53</span>¬† <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#trasformazione-dei-dati",
    "href": "chapters/linear_models/01_reglin_frequentist.html#trasformazione-dei-dati",
    "title": "53¬† La regressione lineare bivariata: un approccio frequentista",
    "section": "53.6 Trasformazione dei dati",
    "text": "53.6 Trasformazione dei dati\nIn generale, per variabili a livello di scala ad intervalli, l‚Äôintercetta del modello di regressione lineare non ha un‚Äôinterpretazione utile. Questo perch√© l‚Äôintercetta indica il valore atteso di \\(y\\) quando \\(x = 0\\), ma in caso di variabili a scala di intervalli, il valore ‚Äú0‚Äù di \\(x\\) √® arbitrario e non corrisponde ad un ‚Äúassenza‚Äù della variabile \\(x\\). Ad esempio, un QI della madre pari a 0 non indica un‚Äôassenza di intelligenza, ma solo un valore arbitrario del test usato per misurare il QI. Quindi, sapere il valore medio del QI dei bambini quando il QI della madre √® 0 non √® di alcun interesse.\nPer fornire all‚Äôintercetta del modello di regressione un‚Äôinterpretazione pi√π utile, dobbiamo trasformare le osservazioni di \\(x\\). Per esempio, esprimiamo \\(x\\) come differenza dalla media. Chiamiamo questa nuova variabile \\(xd\\):\n\nkidiq$xd &lt;- kidiq$mom_iq - mean(kidiq$mom_iq)\n\nkidiq |&gt; \n  head()\n#&gt;   kid_score mom_hs mom_iq mom_work mom_age     xd\n#&gt; 1        65      1  121.1        4      27  21.12\n#&gt; 2        98      1   89.4        4      25 -10.64\n#&gt; 3        85      1  115.4        4      27  15.44\n#&gt; 4        83      1   99.4        3      25  -0.55\n#&gt; 5       115      1   92.7        4      27  -7.25\n#&gt; 6        98      0  107.9        1      18   7.90\n\nSe ora usiamo le coppie di osservazioni \\((xd_i, y_i)\\), il diagramma a dispersione assume la forma seguente.\n\n# Aggiungiamo una nuova variabile centrata (scarti dalla media)\nkidiq &lt;- kidiq %&gt;%\n  mutate(xd = mom_iq - mean(mom_iq))\n\n# Calcolo della retta di regressione\nb &lt;- cov(kidiq$xd, kidiq$kid_score) / var(kidiq$xd)\na &lt;- mean(kidiq$kid_score) - b * mean(kidiq$xd)\n\n# Grafico con ggplot2\nggplot(kidiq, aes(x = xd, y = kid_score)) +\n  geom_point(alpha = 0.4) +  # Punti del grafico\n  geom_abline(intercept = a, slope = b, color = \"blue\") +  # Retta di regressione\n  labs(\n    x = \"QI della madre (scarti dalla media)\", \n    y = \"QI del bambino\"\n  ) +\n  ggtitle(\"Retta di regressione sui dati centrati\")\n\n\n\n\n\n\n\n\nIn pratica, abbiamo spostato tutti i punti del grafico lungo l‚Äôasse delle \\(x\\), in modo tale che la media dei valori di \\(x\\) sia uguale a 0. Questo non ha cambiato la forma dei punti nel grafico, ma ha solo spostato l‚Äôorigine dell‚Äôasse \\(x\\). La pendenza della linea di regressione tra \\(x\\) e \\(y\\) rimane la stessa, sia per i dati originali che per quelli trasformati. L‚Äôunica cosa che cambia √® il valore dell‚Äôintercetta della linea di regressione, che ora ha un‚Äôinterpretazione pi√π significativa.\n\nfm1 &lt;- lm(kid_score ~ xd, data = kidiq)\ncoef(fm1)\n#&gt; (Intercept)          xd \n#&gt;       86.80        0.61\n\nL‚Äôintercetta rappresenta il punto in cui la retta di regressione incontra l‚Äôasse \\(y\\) nel diagramma a dispersione. Nel caso dei dati trasformati, abbiamo spostato la nube di punti lungo l‚Äôasse \\(x\\) di una quantit√† pari a \\(x - \\bar{x}\\), ma le relazioni spaziali tra i punti rimangono invariate. Pertanto, la pendenza della retta di regressione non cambia rispetto ai dati non trasformati. Tuttavia, il valore dell‚Äôintercetta viene influenzato dalla trasformazione. In particolare, poich√© \\(xd = 0\\) corrisponde a \\(x = \\bar{x}\\) nei dati grezzi, l‚Äôintercetta del modello di regressione lineare calcolata sui dati trasformati corrisponde al valore atteso di \\(y\\) quando \\(x\\) assume il valore medio sulla scala dei dati grezzi. In altre parole, l‚Äôintercetta del modello di regressione lineare sui dati trasformati rappresenta il valore atteso del QI dei bambini corrispondente al QI medio delle madri.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>53</span>¬† <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#il-metodo-dei-minimi-quadrati",
    "href": "chapters/linear_models/01_reglin_frequentist.html#il-metodo-dei-minimi-quadrati",
    "title": "53¬† La regressione lineare bivariata: un approccio frequentista",
    "section": "53.7 Il metodo dei minimi quadrati",
    "text": "53.7 Il metodo dei minimi quadrati\nPer stimare i coefficienti \\(a\\) e \\(b\\), possiamo minimizzare la somma dei quadrati dei residui tra i valori osservati \\(y_i\\) e quelli previsti \\(a + b x_i\\).\nIniziamo con il creare una griglia per i valori di \\(b\\). Supponiamo che il valore di \\(a\\) sia noto (\\(a = 25.79978\\)). Usiamo R per creare una griglia di valori possibili per \\(b\\).\n\n# Griglia di valori per b\nb_grid &lt;- seq(0, 1, length.out = 1001)\na &lt;- 25.79978  # Intercetta nota\n\nDefiniamo ora una funzione che calcola la somma dei quadrati dei residui (\\(SSE\\)) per ciascun valore di \\(b\\).\n\n# Funzione per la somma dei quadrati dei residui\nsse &lt;- function(a, b, x, y) {\n  sum((y - (a + b * x))^2)\n}\n\nApplichiamo la funzione sse alla griglia di valori \\(b\\) per calcolare la somma dei quadrati dei residui per ogni valore di \\(b\\).\n\n# Calcolo di SSE per ciascun valore di b\nsse_vals &lt;- sapply(\n  b_grid, \n  function(b) sse(a, b, kidiq$mom_iq, kidiq$kid_score)\n)\n\n\nsapply:\n\n√à una funzione di R che applica una funzione ad ogni elemento di un vettore (o lista) e restituisce i risultati in un vettore.\nQui, applica la funzione sse a ciascun valore di \\(b\\) contenuto in b_grid.\n\nfunction(b):\n\n√à una funzione anonima definita al volo per specificare come calcolare \\(SSE\\) per ciascun valore di \\(b\\).\nAll‚Äôinterno, viene chiamata la funzione sse(a, b, x, y) con i seguenti parametri:\n\na: il valore dell‚Äôintercetta (fissato in precedenza o noto).\nb: il valore corrente nella griglia b_grid.\nx: la variabile indipendente del dataset (kidiq$mom_iq).\ny: la variabile dipendente del dataset (kidiq$kid_score).\n\n\nIl risultato √® un vettore, sse_vals, che contiene i valori di \\(SSE\\) corrispondenti a ciascun valore di \\(b\\) in b_grid.\n\nTracciamo un grafico che mostra la somma dei quadrati dei residui (\\(SSE\\)) in funzione dei valori di \\(b\\), evidenziando il minimo.\n\n# Identificazione del valore di b che minimizza SSE\nb_min &lt;- b_grid[which.min(sse_vals)]\n\n# Creazione del dataframe per ggplot\ndat &lt;- data.frame(b_grid = b_grid, sse_vals = sse_vals)\n\n# Genera il grafico\nggplot(dat, aes(x = b_grid, y = sse_vals)) +\n  geom_line(color = \"blue\", linewidth = 1) +  \n  annotate(\n    \"point\", x = b_min, y = min(sse_vals),\n    color = \"red\", size = 3\n  ) +  # Punto minimo\n  labs(\n    x = expression(paste(\"Possibili valori di \", hat(beta))),\n    y = \"Somma dei quadrati dei residui (SSE)\",\n    title = \"Minimizzazione dei residui quadratici\"\n  ) +\n  annotate(\n    \"text\", x = b_min, y = min(sse_vals), \n    label = expression(hat(beta)), color = \"red\", vjust = -1, hjust = 0.5\n  )\n#&gt; Warning in is.na(x): is.na() applicato ad un oggetto di tipo 'expression'\n#&gt; (ne lista, ne vettore)\n\n\n\n\n\n\n\n\nInfine, identifichiamo il valore di \\(b\\) che minimizza la somma dei quadrati dei residui.\n\nb_min\n#&gt; [1] 0.61\n\nCon questa simulazione, abbiamo stimato il coefficiente \\(b\\) minimizzando la somma dei quadrati dei residui.\nQuesto approccio pu√≤ essere esteso per stimare simultaneamente entrambi i coefficienti (\\(a\\) e \\(b\\)) utilizzando metodi di ottimizzazione pi√π avanzati, come optim in R.\n\noptim_result &lt;- optim(\n  par = c(a = 25, b = 0.5),  # Valori iniziali\n  fn = function(params) {\n    a &lt;- params[1]\n    b &lt;- params[2]\n    sse(a, b, kidiq$mom_iq, kidiq$kid_score)\n  }\n)\n\n# Coefficienti stimati\noptim_result$par\n#&gt;     a     b \n#&gt; 25.79  0.61\n\nQuesta simulazione illustra come, tramite il metodo dei minimi quadrati, sia possibile stimare i parametri di un modello bivariato di regressione.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>53</span>¬† <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#lerrore-standard-della-regressione",
    "href": "chapters/linear_models/01_reglin_frequentist.html#lerrore-standard-della-regressione",
    "title": "53¬† La regressione lineare bivariata: un approccio frequentista",
    "section": "53.8 L‚Äôerrore standard della regressione",
    "text": "53.8 L‚Äôerrore standard della regressione\nIl secondo obiettivo del modello di regressione lineare √® quello di misurare quanto della variabilit√† di \\(y\\) possa essere spiegata dalla variabilit√† di \\(x\\) per ogni osservazione. L‚Äôindice di bont√† di adattamento del modello viene fornito dalla deviazione standard dei residui, chiamata anche errore standard della stima (o errore standard della regressione), \\(s_e\\).\nPer calcolare \\(s_e\\), si sommano i quadrati dei residui \\(e_i\\) per ogni osservazione e si divide per \\(n-2\\), dove \\(n\\) rappresenta la numerosit√† del campione e \\(2\\) il numero di coefficienti stimati nel modello di regressione. Si prende poi la radice quadrata del risultato:\n\\[\n\\sqrt{\\frac{1}{n-2} \\sum_{i=1}^n \\big(y_i - (\\hat{a} + \\hat{b}x_i)\\big)^2},\n\\tag{53.6}\\]\nL‚Äôindice \\(s_e\\) possiede la stessa unit√† di misura di \\(y\\) ed √® una stima della deviazione standard dei residui nella popolazione.\nIllustriamo il calcolo di \\(s_e\\) con i dati a disposizione. I residui \\(e\\) possono essere calcolati sottraendo ai valori osservati \\(y_i\\) i valori predetti dal modello \\(a + b x_i\\):\n\n# Calcolo dei residui\ne &lt;- kidiq$kid_score - (a + b * kidiq$mom_iq)\n\n# Mostriamo i primi 10 residui\nhead(e, 10)\n#&gt;  [1] -34.68  17.69 -11.22  -3.46  32.63   6.38 -41.52   3.86  26.41  11.21\n\nCalcoliamo il valore medio assoluto dei residui per avere un‚Äôindicazione della deviazione media rispetto alla retta di regressione.\n\n# Media assoluta dei residui\nmean(abs(e))\n#&gt; [1] 14.5\n\nL‚Äôerrore standard della stima \\(s_e\\) si calcola come la radice quadrata della somma dei quadrati dei residui divisa per \\(n-2\\):\n\n# Calcolo di s_e\nse &lt;- sqrt(sum(e^2) / (length(e) - 2))\nse\n#&gt; [1] 18.3\n\nNotiamo che il valore medio assoluto dei residui e l‚Äôerrore standard \\(s_e\\) non sono identici, ma hanno lo stesso ordine di grandezza. \\(s_e\\) √® una misura pi√π rigorosa della deviazione standard dei residui.\nQuesta analisi dimostra come \\(s_e\\) consenta di valutare quanto le previsioni del modello si discostino (in media) dai dati osservati.\n\n53.8.1 Sottostima dell‚ÄôErrore nel Modello di Regressione\nCome discusso da Gelman et al. (2021), l‚Äôerrore standard della regressione tende a sottostimare la vera deviazione standard \\(\\sigma\\) dell‚Äôerrore nel modello di regressione nella popolazione. Questa sottostima √® dovuta al fenomeno del sovradimensionamento, dato che i parametri \\(a\\) e \\(b\\) sono stimati utilizzando gli stessi \\(n\\) punti dati su cui vengono calcolati i residui. In altre parole, i residui non sono del tutto indipendenti dal modello.\nUn approccio alternativo per valutare l‚Äôerrore predittivo e mitigare il problema del sovradimensionamento √® la validazione incrociata. In particolare, l‚Äôapproccio leave-one-out (LOOCV) offre una soluzione semplice ed efficace. Questo metodo consiste nell‚Äôadattare il modello \\(n\\) volte, escludendo ogni volta un punto dati, adattando il modello ai rimanenti \\(n-1\\) punti, e utilizzando tale modello per predire l‚Äôosservazione esclusa.\n\n53.8.1.1 Procedura Leave-One-Out:\n\nPer \\(i = 1, \\ldots, n\\):\n\nAdatta il modello \\(y = a + bx + \\text{errore}\\) ai \\(n-1\\) punti dati \\((x, y)_j, j \\neq i\\). Denomina i coefficienti stimati come \\(\\hat{a}_{-i}\\) e \\(\\hat{b}_{-i}\\).\nCalcola il residuo validato incrociato:\n\\[\ne_{\\text{CV}} = y_i - (\\hat{a}_{-i} + \\hat{b}_{-i} x_i).\n\\]\nSalva il residuo al quadrato per il calcolo successivo.\n\nCalcola infine la stima di \\(\\sigma_{\\text{CV}}\\) come:\n\\[\n\\sigma_{\\text{CV}} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n e_{\\text{CV}}^2}.\n\\]\n\n\n\n53.8.1.2 Applicazione Pratica:\nEcco un esempio applicato al modello che predice l‚Äôintelligenza del bambino (\\(\\texttt{kid\\_score}\\)) in funzione dell‚Äôintelligenza della madre (\\(\\texttt{mom\\_iq}\\)) utilizzando il dataset kidiq.\n\noptions(round = 5)\n\n# Array per salvare i residui validati incrociati\nresiduals_cv &lt;- numeric(nrow(kidiq))\n\n# Loop per la validazione incrociata leave-one-out\nfor (i in 1:nrow(kidiq)) {\n  # Dati di training escludendo l'i-esimo punto\n  train_data &lt;- kidiq[-i, ]\n  test_data &lt;- kidiq[i, ]\n  \n  # Addestramento del modello\n  model &lt;- lm(kid_score ~ mom_iq, data = train_data)\n  \n  # Predizione sull'i-esimo punto\n  y_pred &lt;- predict(model, newdata = test_data)\n  \n  # Calcolo del residuo validato incrociato\n  residual_cv &lt;- test_data$kid_score - y_pred\n  residuals_cv[i] &lt;- residual_cv^2\n}\n\n# Calcolo di sigma_cv\nsigma_cv &lt;- sqrt(mean(residuals_cv))\n\ncat(\"Stima di œÉ_CV:\", sigma_cv, \"\\n\")\n#&gt; Stima di œÉ_CV: 18.3\n\nCalcoliamo ora la stima tradizionale di \\(\\sigma\\) utilizzando il modello completo e confrontiamola con \\(\\sigma_{\\text{CV}}\\).\n\n# Modello completo\nfm2 &lt;- lm(kid_score ~ mom_iq, data = kidiq)\n\n# Stima tradizionale dell'errore standard della regressione\nres &lt;- summary(fm2)\ncat(\"Errore standard della regressione (tradizionale):\", res$sigma, \"\\n\")\n#&gt; Errore standard della regressione (tradizionale): 18.3\n\nNel caso analizzato, i valori stimati di \\(\\sigma_{\\text{CV}}\\) e \\(\\hat{\\sigma}_e\\) tradizionale possono risultare molto simili. Tuttavia, in generale, la stima di \\(\\sigma_{\\text{CV}}\\) tende a essere leggermente superiore, in quanto riflette meglio l‚Äôerrore predittivo su dati non utilizzati per adattare il modello. Questo rende \\(\\sigma_{\\text{CV}}\\) una misura pi√π robusta e conservativa dell‚Äôincertezza del modello.\nIn conclusione, la validazione incrociata, e in particolare l‚Äôapproccio LOOCV, rappresenta uno strumento importante per valutare le performance predittive di un modello di regressione e per ottenere stime pi√π affidabili della deviazione standard dell‚Äôerrore.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>53</span>¬† <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#indice-di-determinazione",
    "href": "chapters/linear_models/01_reglin_frequentist.html#indice-di-determinazione",
    "title": "53¬† La regressione lineare bivariata: un approccio frequentista",
    "section": "53.9 Indice di determinazione",
    "text": "53.9 Indice di determinazione\nUn importante risultato dell‚Äôanalisi di regressione riguarda la scomposizione della varianza della variabile dipendente \\(y\\) in due componenti: la varianza spiegata dal modello e la varianza residua. Questa scomposizione √® descritta mediante l‚Äôindice di determinazione \\(R^2\\), che fornisce una misura della bont√† di adattamento del modello ai dati del campione.\nPer una generica osservazione \\(x_i, y_i\\), la deviazione di \\(y_i\\) rispetto alla media \\(\\bar{y}\\) pu√≤ essere espressa come la somma di due componenti: il residuo \\(e_i=y_i- \\hat{y}_i\\) e lo scarto di \\(\\hat{y}_i\\) rispetto alla media \\(\\bar{y}\\):\n\\[\ny_i - \\bar{y} = (y_i- \\hat{y}_i) + (\\hat{y}_i - \\bar{y}) = e_i + (\\hat{y}_i - \\bar{y}).\n\\]\nLa varianza totale di \\(y\\) pu√≤ quindi essere scritta come:\n\\[\n\\sum_{i=1}^{n}(y_i - \\bar{y})^2 = \\sum_{i=1}^{n}(e_i + (\\hat{y}_i - \\bar{y}))^2.\n\\]\nSviluppando il quadrato e sommando, si ottiene:\n\\[\n\\sum_{i=1}^{n}(y_i - \\bar{y})^2 = \\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2 + \\sum_{i=1}^{n}(\\hat{y}_i - \\bar{y})^2.\n\\tag{53.7}\\]\nIl primo termine rappresenta la varianza residua, mentre il secondo termine rappresenta la varianza spiegata dal modello. Questa scomposizione della devianza va sotto il nome di teorema della scomposizione della devianza.\nL‚Äôindice di determinazione \\(R^2\\) √® definito come il rapporto tra la varianza spiegata e la varianza totale:\n\\[\nR^2 = \\frac{\\sum_{i=1}^{n}(\\hat{y}_i - \\bar{y})^2}{\\sum_{i=1}^{n}(y_i - \\bar{y})^2}.\n\\tag{53.8}\\]\nQuesto indice varia tra 0 e 1 e indica la frazione di varianza totale di \\(y\\) spiegata dal modello di regressione lineare. Un valore alto di \\(R^2\\) indica che il modello di regressione lineare si adatta bene ai dati, in quanto una grande parte della varianza di \\(y\\) √® spiegata dalla variabile indipendente \\(x\\).\nPer l‚Äôesempio in discussione, possiamo calcolare la devianza totale, la devianza spiegata e l‚Äôindice di determinazione \\(R^2\\) come segue:\nLa devianza totale misura la variabilit√† complessiva dei punteggi osservati \\(y\\) rispetto alla loro media:\n\n# Devianza totale\ndev_t &lt;- sum((kidiq$kid_score - mean(kidiq$kid_score))^2)\ndev_t\n#&gt; [1] 180386\n\nLa devianza spiegata misura la variabilit√† che il modello √® in grado di spiegare, considerando i valori predetti \\(a + b x\\):\n\n# Devianza spiegata\ndev_r &lt;- sum(((a + b * kidiq$mom_iq) - mean(kidiq$kid_score))^2)\ndev_r\n#&gt; [1] 36249\n\nL‚Äôindice \\(R^2\\) √® il rapporto tra la devianza spiegata e la devianza totale, e indica la frazione della variabilit√† totale che √® spiegata dal modello di regressione:\n\n# Indice di determinazione\nR2 &lt;- dev_r / dev_t\nround(R2, 3)\n#&gt; [1] 0.201\n\nPer verificare i calcoli, utilizziamo il modello di regressione lineare in R e leggiamo \\(R^2\\) direttamente dal sommario del modello:\n\n# Modello di regressione lineare\nmod &lt;- lm(kid_score ~ mom_iq, data = kidiq)\n\n# Sommario del modello per leggere R^2\nsummary(mod)$r.squared\n#&gt; [1] 0.201\n\nIl risultato mostra che circa il 20% della variabilit√† nei punteggi del QI dei bambini √® spiegabile conoscendo il QI delle madri. Questo significa che il modello cattura una porzione rilevante della relazione, ma lascia anche spazio a fattori non inclusi nel modello che influenzano il QI dei bambini.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>53</span>¬† <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#inferenza-sul-modello-di-regressione",
    "href": "chapters/linear_models/01_reglin_frequentist.html#inferenza-sul-modello-di-regressione",
    "title": "53¬† La regressione lineare bivariata: un approccio frequentista",
    "section": "53.10 Inferenza sul modello di regressione",
    "text": "53.10 Inferenza sul modello di regressione\nIl terzo obiettivo del modello di regressione √® l‚Äôinferenza. Nell‚Äôapproccio frequentista, l‚Äôinferenza viene effettuata calcolando la distribuzione campionaria dei parametri e gli intervalli di fiducia per i parametri. Ad esempio, se si vuole determinare se la pendenza della retta di regressione √® maggiore di zero, si calcola l‚Äôintervallo di fiducia al 95% per il parametro \\(\\beta\\). Se l‚Äôintervallo non include lo zero e se il limite inferiore dell‚Äôintervallo √® maggiore di zero, si conclude che c‚Äô√® evidenza di un‚Äôassociazione lineare positiva tra \\(x\\) e \\(y\\) con un grado di confidenza del 95%.1 Il prossimo capitolo spiegher√† come effettuare l‚Äôinferenza sui coefficienti del modello di regressione lineare in un contesto bayesiano.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>53</span>¬† <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#riflessioni-conclusive",
    "href": "chapters/linear_models/01_reglin_frequentist.html#riflessioni-conclusive",
    "title": "53¬† La regressione lineare bivariata: un approccio frequentista",
    "section": "53.11 Riflessioni Conclusive",
    "text": "53.11 Riflessioni Conclusive\nIl modello lineare bivariato √® uno strumento fondamentale nell‚Äôanalisi delle relazioni tra due variabili e rappresenta una pietra miliare dell‚Äôapproccio frequentista. Questo capitolo ha mostrato come il modello consenta di quantificare il grado di associazione tra una variabile indipendente \\(x\\) e una variabile dipendente \\(y\\), utilizzando una relazione lineare.\nGrazie all‚Äôapproccio frequentista, abbiamo imparato a stimare i coefficienti \\(a\\) (intercetta) e \\(b\\) (pendenza) attraverso il metodo dei minimi quadrati, che minimizza la somma dei quadrati dei residui per trovare la retta che meglio approssima i dati osservati. Inoltre, l‚Äôindice di determinazione (\\(R^2\\)) ci ha permesso di valutare la bont√† di adattamento del modello e di quantificare quanta parte della variabilit√† di \\(y\\) √® spiegata dalla variabile \\(x\\).\nIn pratica, il modello lineare bivariato consente di rispondere a domande fondamentali, come:\n\nSe il valore della variabile indipendente aumenta o diminuisce, come si comporta la variabile dipendente?\nQual √® l‚Äôintensit√† e il segno della relazione tra le due variabili?\n\nLa semplicit√† del modello lo rendono uno strumento utile non solo per descrivere e analizzare relazioni tra variabili, ma anche per effettuare previsioni. Pur limitandosi a un singolo predittore, il modello lineare bivariato fornisce una base per comprendere relazioni pi√π complesse, come quelle coinvolgenti pi√π variabili indipendenti (regressione multivariata).\nL‚Äôapproccio frequentista offre una metodologia consolidata per stimare i parametri e valutare il modello, fornendo inferenze utili per analisi pratiche e decisioni informate. Con una solida comprensione di questi concetti, si √® pronti a esplorare modelli lineari pi√π complessi e a estendere queste tecniche a scenari pi√π articolati.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>53</span>¬† <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/01_reglin_frequentist.html#informazioni-sullambiente-di-sviluppo",
    "title": "53¬† La regressione lineare bivariata: un approccio frequentista",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: US/Pacific\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] broom_1.0.7      ggokabeito_0.1.0 see_0.9.0        gridExtra_2.3   \n#&gt;  [5] patchwork_1.3.0  bayesplot_1.11.1 psych_2.4.12     scales_1.3.0    \n#&gt;  [9] markdown_1.13    knitr_1.49       lubridate_1.9.4  forcats_1.0.0   \n#&gt; [13] stringr_1.5.1    dplyr_1.1.4      purrr_1.0.2      readr_2.1.5     \n#&gt; [17] tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0 \n#&gt; [21] rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     Matrix_1.7-1      R.oo_1.27.0      \n#&gt; [13] rprojroot_2.0.4   jsonlite_1.8.9    R.utils_2.12.3    backports_1.5.0  \n#&gt; [17] mgcv_1.9-1        mnormt_2.1.1      cli_3.6.3         rlang_1.1.4      \n#&gt; [21] R.methodsS3_1.8.2 splines_4.4.2     munsell_0.5.1     withr_3.0.2      \n#&gt; [25] tools_4.4.2       parallel_4.4.2    tzdb_0.4.0        colorspace_2.1-1 \n#&gt; [29] pacman_0.5.1      vctrs_0.6.5       R6_2.5.1          lifecycle_1.0.4  \n#&gt; [33] htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.1     gtable_0.3.6     \n#&gt; [37] glue_1.8.0        haven_2.5.4       xfun_0.50         tidyselect_1.2.1 \n#&gt; [41] farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-166      labeling_0.4.3   \n#&gt; [45] rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>53</span>¬† <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#bibliografia",
    "href": "chapters/linear_models/01_reglin_frequentist.html#bibliografia",
    "title": "53¬† La regressione lineare bivariata: un approccio frequentista",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nCaudek, C., & Luccio, R. (2001). Statistica per psicologi (III rist. 2023, Vol. 11, p. 320). Laterza.\n\n\nFox, J. (2015). Applied regression analysis and generalized linear models. Sage publications.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other stories. Cambridge University Press.\n\n\nStigler, S. (1986). The History of Statistics. Belknap Harvard.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>53</span>¬† <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#footnotes",
    "href": "chapters/linear_models/01_reglin_frequentist.html#footnotes",
    "title": "53¬† La regressione lineare bivariata: un approccio frequentista",
    "section": "",
    "text": "Per un approfondimento sull‚Äôapproccio frequentista alla regressione, si veda, per esempio, Caudek & Luccio (2001).‚Ü©Ô∏é",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>53</span>¬† <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_reglin_bayes.html",
    "href": "chapters/linear_models/02_reglin_bayes.html",
    "title": "54¬† Modello bayesiano di regressione lineare bivariata",
    "section": "",
    "text": "54.1 Introduzione\nIn questa sezione della dispensa, esploreremo il modello di regressione lineare bivariata bayesiano, confrontandolo con l‚Äôapproccio frequentista.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>54</span>¬† <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_reglin_bayes.html#introduzione",
    "href": "chapters/linear_models/02_reglin_bayes.html#introduzione",
    "title": "54¬† Modello bayesiano di regressione lineare bivariata",
    "section": "",
    "text": "54.1.1 Modello di Regressione Bayesiano\nL‚Äôapproccio bayesiano si distingue dai metodi dei minimi quadrati o della massima verosimiglianza, poich√© combina le informazioni derivanti dai dati con conoscenze preesistenti, rappresentate da distribuzioni a priori. Questo processo produce distribuzioni a posteriori che aggiornano le credenze iniziali dopo l‚Äôosservazione dei dati, superando i limiti delle stime puntuali dei metodi classici.\nNel contesto di un modello lineare bayesiano, indichiamo con \\(y\\) la variabile di risposta, con \\(x\\) le variabili predittive, e con \\(i\\) l‚Äôindice delle osservazioni, da 1 al numero totale di dati.\n\n\n54.1.2 Verosimiglianza\nNel modello bayesiano bivariato, la relazione tra la variabile \\(y\\) e la variabile \\(x\\) √® descritta dalla verosimiglianza:\n\\[\ny \\sim \\text{Normale}(\\alpha + \\beta x, \\sigma).\n\\]\nCi√≤ implica che i valori osservati di \\(y\\) sono distribuiti attorno alla retta di regressione \\(\\alpha + \\beta x\\), con una deviazione standard \\(\\sigma\\). Ogni osservazione √® quindi una combinazione lineare dell‚Äôintercetta \\(\\alpha\\), del coefficiente \\(\\beta\\) che moltiplica la variabile predittiva, e di un termine di errore distribuito normalmente.\n\n\n54.1.3 Distribuzioni a Priori\nPer definire il modello bayesiano, si specificano distribuzioni a priori per i parametri \\(\\alpha\\), \\(\\beta\\) e \\(\\sigma\\). Sebbene siano possibili prior uniformi, che esprimono una totale assenza di conoscenza iniziale, √® preferibile adottare prior debolmente informativi per garantire maggiore robustezza. Per esempio:\n\\[\n\\alpha \\sim \\mathcal{N}(0, 2.5), \\quad \\beta \\sim \\mathcal{N}(0, 2.5), \\quad \\sigma \\sim \\text{Cauchy}(0, 2.5).\n\\]\nQueste distribuzioni riflettono ipotesi iniziali ragionevoli senza introdurre eccessiva informazione a priori.\n\n\n54.1.4 Distribuzioni a Posteriori\nLe distribuzioni a posteriori sono ottenute combinando la verosimiglianza dei dati con le distribuzioni a priori tramite il teorema di Bayes. Esse rappresentano lo stato aggiornato delle conoscenze sui parametri, integrando l‚Äôinformazione empirica con le ipotesi iniziali. L‚Äôapproccio bayesiano non si limita a fornire stime puntuali, ma restituisce una descrizione completa dell‚Äôincertezza associata ai parametri sotto forma di distribuzioni probabilistiche.\nNel contesto di un modello di regressione bivariata, le distribuzioni a posteriori dei parametri \\(\\alpha\\) (intercetta), \\(\\beta\\) (coefficiente angolare), e \\(\\sigma\\) (deviazione standard residua) vengono stimate utilizzando algoritmi MCMC (Markov Chain Monte Carlo). Questi algoritmi consentono di campionare iterativamente dalle distribuzioni a posteriori, garantendo una stima accurata anche in modelli complessi.\nNella sezione successiva, esploreremo come utilizzare la funzione brm() del pacchetto brms per implementare un modello di regressione bayesiano e ottenere le stime a posteriori, analizzandone le propriet√† e le implicazioni.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>54</span>¬† <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_reglin_bayes.html#adattare-una-retta-di-regressione-a-dati-simulati",
    "href": "chapters/linear_models/02_reglin_bayes.html#adattare-una-retta-di-regressione-a-dati-simulati",
    "title": "54¬† Modello bayesiano di regressione lineare bivariata",
    "section": "54.2 Adattare una Retta di Regressione a Dati Simulati",
    "text": "54.2 Adattare una Retta di Regressione a Dati Simulati\nDefiniamo i parametri e simuliamo i dati.\n\nset.seed(123)\n\n# Definizione delle variabili\nx &lt;- 1:100\nn &lt;- length(x)\na &lt;- 1.5\nb &lt;- 0.5\nsigma &lt;- 10\n\n# Generazione di y\ny &lt;- a + b * x + rnorm(n, 0, sigma)\n\n# Creazione del dataframe\nfake &lt;- tibble(x = x, y = y)\nhead(fake)\n#&gt; # A tibble: 6 √ó 2\n#&gt;       x      y\n#&gt;   &lt;int&gt;  &lt;dbl&gt;\n#&gt; 1     1 -3.60 \n#&gt; 2     2  0.198\n#&gt; 3     3 18.6  \n#&gt; 4     4  4.21 \n#&gt; 5     5  5.29 \n#&gt; 6     6 21.7\n\nIniziamo adattando ai dati un modello frequentista:\n\nfm1 &lt;- lm(y ~ x, data = fake)\n\n\nsummary(fm1)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = y ~ x, data = fake)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -24.536  -5.524  -0.346   6.485  20.949 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)\n#&gt; (Intercept)   1.1360     1.8429    0.62     0.54\n#&gt; x             0.5251     0.0317   16.57   &lt;2e-16\n#&gt; \n#&gt; Residual standard error: 9.15 on 98 degrees of freedom\n#&gt; Multiple R-squared:  0.737,  Adjusted R-squared:  0.734 \n#&gt; F-statistic:  275 on 1 and 98 DF,  p-value: &lt;2e-16\n\nPer ottenere l‚Äôintervallo di confidenza (nel senso frequentista) della stima dei parametri usiamo:\n\nconfint(fm1, level = 0.95)\n#&gt;              2.5 % 97.5 %\n#&gt; (Intercept) -2.521  4.793\n#&gt; x            0.462  0.588\n\nAdattiamo ora ai dati un modello di regressione bayesiano utilizzando brms. Si noti che, anche in questo caso, usiamo la sintassi di Wilkinson y ~ x, come per lm(). Eseguiamo il campionamento:\n\nfm2 &lt;- brm(\n  y ~ x, \n  data = fake,\n  backend = \"cmdstanr\"\n)\n\nCome discusso nell‚Äôanalisi dell‚Äôalgoritmo di Metropolis, il primo passo √® esaminare le tracce dei parametri per verificare la convergenza dell‚Äôalgoritmo. La convergenza pu√≤ essere considerata raggiunta se le catene (nel caso di brm, sono 4 per impostazione predefinita) risultano ben mescolate. Questo si manifesta in un trace plot che mostra una distribuzione uniforme e casuale dei campioni attorno a un valore centrale, senza pattern evidenti o tendenze sistematiche.\nLe tracce dei parametri si ottengono nel modo seguente:\n\nmcmc_trace(\n  fm2, \n  pars = c(\"b_Intercept\", \"b_x\", \"sigma\"),\n  facet_args = list(nrow = 3)\n)\n\n\n\n\n\n\n\n\nGli istogrammi delle distribuzioni a posteriori dei parametri si generano nel modo seguente:\n\nmcmc_hist(\n  fm2, \n  pars =c(\"b_Intercept\", \"b_x\", \"sigma\"),\n  facet_args = list(nrow = 3)\n)\n#&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nPer valutare l‚Äôautocorrelazione tra i campioni a posteriori del parametro beta, possiamo utilizzare il seguente comando:\n\nmcmc_acf(fm2, \"b_x\")\n\n\n\n\n\n\n\n\nL‚Äôautocorrelazione fornisce informazioni sulla dipendenza tra campioni successivi nella catena di Markov. √à normale che i campioni successivi non siano completamente indipendenti, poich√© le catene di Markov generano campioni correlati per costruzione. Tuttavia, se l‚Äôalgoritmo ha raggiunto la convergenza, l‚Äôautocorrelazione dovrebbe diminuire rapidamente e diventare trascurabile dopo un numero relativamente piccolo di lag. Questo significa che, dopo un certo numero di passi, i campioni diventano progressivamente meno correlati tra loro, comportandosi in modo simile a campioni indipendenti estratti dalla distribuzione target.\nUn‚Äôelevata autocorrelazione su lag pi√π lunghi potrebbe invece indicare problemi di mescolamento delle catene o una mancata convergenza, richiedendo ulteriori verifiche o aggiustamenti, come l‚Äôaumento del numero di iterazioni o una diversa parametrizzazione del modello.\nNel caso presente, notiamo una rapida diminuzione dell‚Äôautocorrelazione in funzione del numero di passi. Ci√≤ √® indicativo del fatto che la convergenza √® stata raggiunta.\nUna sintesi numerica dei risultati si trova nel modo seguente:\n\nsummary(fm2)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: y ~ x \n#&gt;    Data: fake (Number of observations: 100) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept     1.11      1.85    -2.55     4.77 1.00     3976     2968\n#&gt; x             0.53      0.03     0.46     0.59 1.00     4028     3041\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     9.26      0.69     7.99    10.75 1.00     3753     3097\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nConfrontiamo le stime ottenute con i valori reali dei parametri simulati. L‚Äôintercetta √® stata stimata attorno a 1.14, con un‚Äôincertezza al 95% che varia tra -2.4 e 4.8. Questo risultato rientra negli intervalli di credibilit√† previsti, confermando l‚Äôaccuratezza del modello. Analogamente, per la pendenza \\(b\\), l‚Äôintervallo di credibilit√† al 95% include il valore reale simulato, dimostrando come le stime bayesiane riflettano accuratamente l‚Äôincertezza sui parametri.\nSe si utilizza la funzione conditional_effects() viene prodotto un grafico che rappresenta la relazione stimata tra il predittore \\(x\\) e la variabile di risposta \\(y\\).\n\nconditional_effects(fm2) |&gt;\n  plot(points = TRUE)\n\n\n\n\n\n\n\n\n\nLinea stimata (effetto medio):\n\nLa linea centrale del grafico rappresenta il valore medio previsto di\\(y\\) per ogni valore di\\(x\\), dato dalla relazione\\(y = \\alpha + \\beta x\\).\nQuesta linea √® calcolata usando i valori medi a posteriori stimati per\\(\\alpha\\) e\\(\\beta\\).\n\nBande di incertezza (intervalli di credibilit√†):\n\nLe bande attorno alla linea rappresentano gli intervalli di credibilit√† (ad esempio, al 95%). Questi mostrano l‚Äôincertezza associata alle stime del modello per ogni valore di\\(x\\).\nPi√π strette sono le bande, maggiore √® la certezza del modello riguardo alla relazione stimata.\n\nDati osservati:\n\nI punti rappresentano i valori effettivi di\\(y\\) osservati nei dati. Questo consente di confrontare visivamente come i dati reali si allineano con le previsioni del modello.\n\n\nIl grafico consente\n\nuna verifica visiva della relazione stimata tra\\(y\\) e\\(x\\);\ndi identificazione di eventuali discrepanze tra i dati osservati e le previsioni del modello;\nuna rappresentazione dell‚Äôincertezza nelle stime.\n\nAd esempio, il grafico pu√≤ mostrare se\\(x\\) ha un effetto credibile su\\(y\\) e con quale livello di incertezza. Se l‚Äôeffetto di\\(x\\) √® debole o nullo, la linea stimata sar√† piatta (vicina a zero) e le bande di incertezza saranno ampie.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>54</span>¬† <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_reglin_bayes.html#simulazione-di-livelli-di-copertura",
    "href": "chapters/linear_models/02_reglin_bayes.html#simulazione-di-livelli-di-copertura",
    "title": "54¬† Modello bayesiano di regressione lineare bivariata",
    "section": "54.3 Simulazione di Livelli di Copertura",
    "text": "54.3 Simulazione di Livelli di Copertura\nVerifichiamo la copertura degli intervalli di credibilit√† al 95% attraverso simulazioni ripetute.\n\nset.seed(42)\n# Parametri veri\na_true &lt;- 0.2\nb_true &lt;- 0.3\nsigma_true &lt;- 0.5\n# Numero di simulazioni\nnum_simulations &lt;- 1000\n# Conteggio delle coperture\ncoverage_a &lt;- 0\ncoverage_b &lt;- 0\nfor (i in 1:num_simulations) {\n  # Generazione dei dati\n  x &lt;- 1:20\n  y &lt;- a_true + b_true * x + sigma_true * rnorm(length(x))\n  # Adattamento del modello\n  fit &lt;- lm(y ~ x)\n  ci &lt;- confint(fit) # Intervalli di confidenza\n  # Verifica delle coperture\n  if (ci[1,1] &lt;= a_true & ci[1, 2] &gt;= a_true) {\n    coverage_a &lt;- coverage_a + 1\n  }\n  if (ci[2,1] &lt;= b_true & ci[2, 2] &gt;= b_true) {\n    coverage_b &lt;- coverage_b + 1\n  }\n}\n\n\n# Risultati\ncat(\"Coverage for a:\", coverage_a / num_simulations, \"\\n\")\n#&gt; Coverage for a: 0.952\ncat(\"Coverage for b:\", coverage_b / num_simulations, \"\\n\")\n#&gt; Coverage for b: 0.955\n\nI risultati indicano che i livelli di copertura empirici ottenuti con l‚Äôapproccio frequentista corrispondono strettamente ai livelli teorici attesi.\nPer proseguire, ripeteremo la simulazione adottando un approccio bayesiano. Useremo la funzione brm() del pacchetto brms al posto di lm().\n#| message: false\n#| warning: false\n#| output: false\n#| \n# Definizione dei parametri\nset.seed(23)\nn_fake &lt;- 1000\ncover_68 &lt;- rep(NA, n_fake)\ncover_95 &lt;- rep(NA, n_fake)\na &lt;- 0.2 # Intercetta vera\nb &lt;- 0.3 # Pendenza vera\nsigma &lt;- 0.5 # Deviazione standard vera\nx &lt;- 1:20 # Variabile indipendente\nn &lt;- length(x) # Numero di osservazioni\n\n# Ciclo per simulazioni\nfor (s in 1:n_fake) {\n  # Generazione dei dati\n  y &lt;- a + b * x + rnorm(n, 0, sigma)\n  fake &lt;- data.frame(x = x, y = y)\n\n  # Adattamento del modello con brms\n  fit &lt;- brm(\n    bf(y ~ 1 + x, center = FALSE),\n    data = fake,\n    family = gaussian(),\n    prior = c(\n      prior(normal(0, 2.5), class = \"b\", coef = \"Intercept\"), # Prior per alpha\n      prior(normal(0, 2.5), class = \"b\", coef = \"x\"), # Prior per beta\n      prior(cauchy(0, 2.5), class = \"sigma\") # Prior per sigma\n    ),\n    seed = 42,\n    iter = 2000, \n    chains = 2, \n    refresh = 0, # Suppress console output\n    backend = \"cmdstanr\"\n  )\n\n  # Estrazione dei coefficienti stimati e delle deviazioni standard\n  posterior_summary &lt;- summary(fit)$fixed\n  b_hat &lt;- posterior_summary[\"x\", \"Estimate\"]\n  b_se &lt;- posterior_summary[\"x\", \"Est.Error\"]\n\n  # Calcolo della copertura\n  cover_68[s] &lt;- abs(b - b_hat) &lt; b_se\n  cover_95[s] &lt;- abs(b - b_hat) &lt; 2 * b_se\n}\n# Summarize the coverage results\nmean_cover_68 &lt;- mean(cover_68, na.rm = TRUE)\nmean_cover_95 &lt;- mean(cover_95, na.rm = TRUE)\ncat(\"Coverage for 68% interval:\", mean_cover_68, \"\\n\")\ncat(\"Coverage for 95% interval:\", mean_cover_95, \"\\n\")\nQuesta seconda simulazione evidenzia che anche i livelli di copertura empirici ottenuti con l‚Äôapproccio bayesiano si avvicinano ai valori teorici previsti.\nI risultati ottenuti confermano l‚Äôefficacia degli intervalli di confidenza e di credibilit√† stimati attraverso i modelli frequentisti e bayesiani.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>54</span>¬† <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_reglin_bayes.html#confronti-non-effetti",
    "href": "chapters/linear_models/02_reglin_bayes.html#confronti-non-effetti",
    "title": "54¬† Modello bayesiano di regressione lineare bivariata",
    "section": "54.4 Confronti, non Effetti",
    "text": "54.4 Confronti, non Effetti\nGelman et al. (2021) sottolineano che i coefficienti di regressione sono spesso denominati ‚Äúeffetti‚Äù, ma questa terminologia pu√≤ trarre in inganno. Gli ‚Äúeffetti‚Äù, infatti, implicano una relazione causale. Tuttavia, ci√≤ che un modello di regressione stima non √® necessariamente un effetto causale, ma piuttosto un pattern osservazionale. In particolare, ci√≤ che osserviamo √® che la media della variabile dipendente nella sottopopolazione con \\(X = x + 1\\) √® spesso maggiore o minore (a seconda del segno di \\(\\beta\\)) rispetto alla media della sottopopolazione con \\(X = x\\).\nLa regressione √® uno strumento matematico utilizzato principalmente per fare previsioni. I coefficienti di regressione devono quindi essere interpretati come confronti medi. Solo in circostanze specifiche, quando la regressione descrive un processo causale ben definito, √® possibile interpretarli come effetti. Tuttavia, questa interpretazione causale deve essere giustificata dal disegno dello studio e non pu√≤ essere dedotta unicamente dall‚Äôuso del modello statistico.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>54</span>¬† <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_reglin_bayes.html#riflessioni-conclusive",
    "href": "chapters/linear_models/02_reglin_bayes.html#riflessioni-conclusive",
    "title": "54¬† Modello bayesiano di regressione lineare bivariata",
    "section": "54.5 Riflessioni Conclusive",
    "text": "54.5 Riflessioni Conclusive\nIn questo capitolo abbiamo adottato un approccio bayesiano per stimare i parametri di un modello di regressione bivariato. √à emerso che, quando i prior sono debolmente informativi, le stime bayesiane tendono a coincidere con quelle ottenute tramite l‚Äôapproccio frequentista. Tuttavia, il valore dell‚Äôapproccio bayesiano risiede non solo nella stima dei parametri, ma anche nella possibilit√† di incorporare conoscenze a priori e di rappresentare esplicitamente l‚Äôincertezza nelle stime.\nAl di l√† della scelta tra approccio frequentista e bayesiano, √® cruciale riflettere sul ruolo dei modelli statistici nella ricerca scientifica, in particolare nel contesto psicologico. Come evidenziato da Alexander (2023), i modelli statistici non sono strumenti per rivelare una verit√† assoluta, ma mezzi per interpretare i dati e costruire significato a partire da essi. Essi non rappresentano la realt√† in modo fedele, ma piuttosto funzionano come ‚Äúlenti‚Äù attraverso le quali possiamo mettere a fuoco aspetti specifici del fenomeno studiato.\nI modelli statistici possono essere utilizzati principalmente per due scopi distinti ma complementari: inferenza e previsione.\n\nPrevisione: mira a descrivere le associazioni tra variabili, consentendo di formulare stime future basate sui dati disponibili. √à un processo empirico, in cui la bont√† del modello viene valutata sulla sua capacit√† di fare previsioni accurate.\nInferenza: si concentra sull‚Äôindividuazione di relazioni causali tra variabili. Questo tipo di analisi richiede una progettazione rigorosa, come esperimenti controllati o disegni quasi-sperimentali, e una chiara giustificazione delle ipotesi del modello. La regressione, in particolare, pu√≤ supportare inferenze causali solo se accompagnata da un contesto teorico robusto e da dati appropriati.\n\n√à fondamentale ricordare che la regressione rappresenta una forma di media ponderata e, di conseguenza, i suoi risultati possono essere influenzati da bias intrinseci e dalle caratteristiche specifiche del dataset. Pertanto:\n\nLa qualit√† dei risultati dipende dalla qualit√† dei dati e dalla correttezza delle ipotesi del modello.\n√à importante considerare potenziali fonti di bias, come la selezione dei dati, variabili confondenti non incluse nel modello, o ipotesi non verificate sulla linearit√† delle relazioni.\n\nIn conclusione, l‚Äôadozione di un modello statistico non √® un fine in s√©, ma uno strumento per esplorare, interpretare e comprendere il fenomeno di interesse. Sia che si utilizzi un approccio bayesiano o frequentista, il successo dell‚Äôanalisi dipende dalla capacit√† di integrare i risultati quantitativi con una riflessione teorica critica e da un‚Äôattenzione costante alla validit√† delle ipotesi e delle conclusioni.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>54</span>¬† <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_reglin_bayes.html#come-installare-cmdstan",
    "href": "chapters/linear_models/02_reglin_bayes.html#come-installare-cmdstan",
    "title": "54¬† Modello bayesiano di regressione lineare bivariata",
    "section": "54.6 Come installare CmdStan",
    "text": "54.6 Come installare CmdStan\n\nAssicurati di aver installato l‚Äôultima versione di R. Se non lo hai gi√† fatto, scarica e installa la versione pi√π recente seguendo le istruzioni disponibili su https://www.r-project.org/.\nCmdStanR √® un‚Äôinterfaccia leggera per utilizzare Stan con R.\nInstalla il pacchetto cmdstanr seguendo le istruzioni disponibili nella guida Getting Started with CmdStanR.\nVerifica che il tuo toolchain (gli strumenti di compilazione necessari) sia configurato correttamente eseguendo:\n\ncheck_cmdstan_toolchain()\nSu macOS e Linux, questa configurazione dovrebbe essere gi√† pronta di default.\n\nProcedi con l‚Äôinstallazione di CmdStan utilizzando il comando seguente (specificando il numero di core da utilizzare per la compilazione, ad esempio cores = 2):\n\ninstall_cmdstan(cores = 2)\n\n54.6.1 Windows\nSu Windows √® necessario installare RTools e configurare PATH:\n\nInstallazione di RTools:\n\nVai su https://cran.r-project.org/bin/windows/Rtools/\nScarica la versione di RTools compatibile con la tua versione di R (Generalmente, RTools 4.3 per R 4.3.x, RTools 4.2 per R 4.2.x, etc.)\nEsegui l‚Äôinstaller scaricato\nIMPORTANTE: Durante l‚Äôinstallazione, seleziona la casella ‚ÄúAdd rtools to system PATH‚Äù\n\nVerifica dell‚Äôinstallazione e configurazione del PATH:\n\nApri PowerShell o Command Prompt\nVerifica se RTools √® nel PATH digitando:\n\ngcc --version\nSe vedi la versione di gcc, RTools √® nel PATH.\nSe RTools non √® nel PATH, devi aggiungerlo manualmente:\n\nCerca ‚ÄúImpostazioni di Sistema‚Äù in Windows\nClicca su ‚ÄúImpostazioni di sistema avanzate‚Äù\nClicca su ‚ÄúVariabili d‚Äôambiente‚Äù\nNella sezione ‚ÄúVariabili di sistema‚Äù, trova ‚ÄúPath‚Äù\nClicca ‚ÄúModifica‚Äù\nClicca ‚ÄúNuovo‚Äù e aggiungi questi percorsi (sostituisci X.X con la tua versione di RTools):\nC:\\rtools4X\\mingw64\\bin\nC:\\rtools4X\\usr\\bin\n\nVerifica finale:\n\nChiudi e riapri il terminale\nProva questi comandi:\n\ngcc --version\nmake --version\nSe entrambi i comandi mostrano le versioni, l‚Äôinstallazione √® completa.\nTest in R:\n\nApri R o RStudio\nEsegui:\n\nSys.which(\"make\")\nDovrebbe mostrare il percorso di make.\n\nProblemi comuni:\n\nSe i comandi non vengono riconosciuti dopo aver aggiunto il PATH, prova a riavviare il computer.\nSe usi RStudio, potrebbe essere necessario riavviarlo dopo aver modificato il PATH.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>54</span>¬† <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_reglin_bayes.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/02_reglin_bayes.html#informazioni-sullambiente-di-sviluppo",
    "title": "54¬† Modello bayesiano di regressione lineare bivariata",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: US/Pacific\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] rstan_2.32.6         StanHeaders_2.32.10  brms_2.22.0         \n#&gt;  [4] Rcpp_1.0.13-1        posterior_1.6.0.9000 cmdstanr_0.8.1      \n#&gt;  [7] ggokabeito_0.1.0     see_0.9.0            gridExtra_2.3       \n#&gt; [10] patchwork_1.3.0      bayesplot_1.11.1     psych_2.4.12        \n#&gt; [13] scales_1.3.0         markdown_1.13        knitr_1.49          \n#&gt; [16] lubridate_1.9.4      forcats_1.0.0        stringr_1.5.1       \n#&gt; [19] dplyr_1.1.4          purrr_1.0.2          readr_2.1.5         \n#&gt; [22] tidyr_1.3.1          tibble_3.2.1         ggplot2_3.5.1       \n#&gt; [25] tidyverse_2.0.0      rio_1.2.3            here_1.0.1          \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1     farver_2.1.2         loo_2.8.0           \n#&gt;  [4] fastmap_1.2.0        tensorA_0.36.2.1     pacman_0.5.1        \n#&gt;  [7] digest_0.6.37        timechange_0.3.0     lifecycle_1.0.4     \n#&gt; [10] processx_3.8.5       magrittr_2.0.3       compiler_4.4.2      \n#&gt; [13] rlang_1.1.4          tools_4.4.2          yaml_2.3.10         \n#&gt; [16] data.table_1.16.4    labeling_0.4.3       bridgesampling_1.1-2\n#&gt; [19] htmlwidgets_1.6.4    pkgbuild_1.4.5       mnormt_2.1.1        \n#&gt; [22] curl_6.1.0           plyr_1.8.9           abind_1.4-8         \n#&gt; [25] withr_3.0.2          grid_4.4.2           stats4_4.4.2        \n#&gt; [28] colorspace_2.1-1     inline_0.3.21        cli_3.6.3           \n#&gt; [31] mvtnorm_1.3-3        rmarkdown_2.29       generics_0.1.3      \n#&gt; [34] RcppParallel_5.1.9   reshape2_1.4.4       tzdb_0.4.0          \n#&gt; [37] parallel_4.4.2       matrixStats_1.5.0    vctrs_0.6.5         \n#&gt; [40] V8_6.0.0             Matrix_1.7-1         jsonlite_1.8.9      \n#&gt; [43] hms_1.1.3            glue_1.8.0           codetools_0.2-20    \n#&gt; [46] ps_1.8.1             distributional_0.5.0 stringi_1.8.4       \n#&gt; [49] gtable_0.3.6         QuickJSR_1.5.1       munsell_0.5.1       \n#&gt; [52] pillar_1.10.1        htmltools_0.5.8.1    Brobdingnag_1.2-9   \n#&gt; [55] R6_2.5.1             rprojroot_2.0.4      evaluate_1.0.1      \n#&gt; [58] lattice_0.22-6       backports_1.5.0      rstantools_2.4.0    \n#&gt; [61] coda_0.19-4.1        nlme_3.1-166         checkmate_2.3.2     \n#&gt; [64] xfun_0.50            pkgconfig_2.0.3",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>54</span>¬† <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_reglin_bayes.html#bibliografia",
    "href": "chapters/linear_models/02_reglin_bayes.html#bibliografia",
    "title": "54¬† Modello bayesiano di regressione lineare bivariata",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAlexander, R. (2023). Telling Stories with Data: With Applications in R. Chapman; Hall/CRC.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other stories. Cambridge University Press.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>54</span>¬† <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_synt_sugar.html",
    "href": "chapters/linear_models/03_synt_sugar.html",
    "title": "55¬† Zucchero sintattico",
    "section": "",
    "text": "55.1 Introduzione\nI modelli lineari sono cos√¨ ampiamente utilizzati che sono stati sviluppati appositamente una sintassi, dei metodi e delle librerie per la regressione. Una di queste librerie √® brms (Bayesian Regression Models using Stan), gi√† introdotta nel Capitolo 54. brms √® un pacchetto R progettato per adattare modelli gerarchici generalizzati lineari (di cui il modello lineare bivariato √® un caso particolare), utilizzando una sintassi simile a quella presente nei pacchetti R, come lme4, nlme, rstanarm. brms si basa su Stan, ma offre un‚ÄôAPI di livello superiore.\nIn questo capitolo esploreremo in maniera dettagliata come condurre un‚Äôanalisi di regressione utilizzando brms invece di Stan.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>55</span>¬† <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_synt_sugar.html#interfaccia-brms",
    "href": "chapters/linear_models/03_synt_sugar.html#interfaccia-brms",
    "title": "55¬† Zucchero sintattico",
    "section": "55.2 Interfaccia brms",
    "text": "55.2 Interfaccia brms\nPer fare un esempio, applicheremo il modello di regressione bivariato alla relazione tra altezza e peso. I dati contenuti nel file Howell_18.csv sono parte di un censimento parziale della popolazione !Kung San dell‚Äôarea di Dobe, raccolti tramite interviste condotte da Nancy Howell alla fine degli anni ‚Äô60 (McElreath, 2020). I !Kung San sono una delle popolazioni di raccoglitori-cacciatori pi√π conosciute del ventesimo secolo e sono stati oggetto di numerosi studi antropologici. In questa analisi, consideriamo un sottocampione di dati relativi alla popolazione adulta (di et√† superiore ai 18 anni).\nImportiamo i dati contenuti nel file Howell_18.csv.\n\ndf &lt;- rio::import(here::here(\"data\", \"Howell_18.csv\"))\n\n\ndf |&gt; \n  head()\n#&gt;   height weight age male\n#&gt; 1    152   47.8  63    1\n#&gt; 2    140   36.5  63    0\n#&gt; 3    137   31.9  65    0\n#&gt; 4    157   53.0  41    1\n#&gt; 5    145   41.3  51    0\n#&gt; 6    164   63.0  35    1\n\nGeneriamo un diagramma a dispersione tra le variabili height (altezza) e weight (peso):\n\nggplot(df, aes(x = weight, y = height)) +\n  geom_point() +  \n  labs(x = \"Weight\", y = \"Height\") \n\n\n\n\n\n\n\n\nbrms si concentra sui modelli di regressione, e questa specializzazione permette di adottare una sintassi pi√π semplice, conosciuta come sintassi di Wilkinson (Wilkinson & Rogers, 1973).\nAd esempio, il modello \\(y = \\alpha + \\beta x + \\varepsilon\\) si implementa come segue:\na_model = brm(y ‚àº 1 + x, data = df)\nNella sintassi di Wilkinson, il simbolo tilde (‚àº) separa la variabile dipendente (a sinistra) dalle variabili indipendenti (a destra). In questo caso, stiamo specificando solo la media (\\(\\mu\\)) della \\(y\\).\nbrms assume di default che la distribuzione di verosimiglianza sia gaussiana, ma √® possibile modificarla tramite l‚Äôargomento family.\nLa notazione 1 si riferisce all‚Äôintercetta. L‚Äôintercetta viene inclusa di default. Per cui il modello precedente si pu√≤ anche scrivere, in maniera equivalente, come\na_model = brm(y ‚àº x, data = df)\nSe desideriaamo escludere l‚Äôintercetta dal modello, possiamo farlo in questo modo\nno_intercept_model = brm(y ‚àº 0 + x, data = df)\noppure in questo modo\nno_intercept_model = brm(y ‚àº -1 + x, data = df)\nPer includere ulteriori variabili nel modello, possiamo procedere cos√¨:\nmodel_2 = brm(\"y ‚àº x + z\", data)\nbrms consente anche di includere effetti a livello di gruppo (gerarchici). Ad esempio, se desideriamo un modello ad effetti misti nel quale abbiamo un effetto diverso di \\(x\\) in ciascun gruppo g, possiamo usare la seguente sintassi:\nmodel_h = brm(y ‚àº x + z + (x | g), data = df)\nLa sintassi di Wilkinson non specifica le distribuzioni a priori, ma solo come le variabili dipendenti e indipendenti sono collegate. brms definir√† automaticamente delle distribuzioni a priori debolmente informative per noi, rendendo superflua la loro definizione esplicita. Tuttavia, se preferiamo avere un maggiore controllo, possiamo specificarle manualmente, come vedremo in seguito.\n\n55.2.1 Centrare le Variabili\nPer interpretare pi√π facilmente l‚Äôintercetta, centriamo la variabile weight rispetto alla media del campione:\n\ndf$weight_c = df$weight - mean(df$weight)\n\nOra, l‚Äôintercetta (\\(\\alpha\\)) rappresenter√† l‚Äôaltezza media quando il peso corrisponde alla media del campione.\nAdattiamo un modello lineare con la variabile weight centrata e esaminiamo i risultati:\n\nfit_1 = brm(\n  bf(height ~ 1 + weight_c, center = FALSE), \n  data = df, \n  backend = \"cmdstanr\", \n  silent = 0\n)\n\nLe tracce dei parametri si ottengono nel modo seguente:\n\nmcmc_trace(\n  fit_1, \n  pars = c(\"b_Intercept\", \"b_weight_c\", \"sigma\"),\n  facet_args = list(nrow = 3)\n)\n\n\n\n\n\n\n\n\n\nsummary(fit_1)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: height ~ 1 + weight_c \n#&gt;    Data: df (Number of observations: 352) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept   154.59      0.27   154.06   155.11 1.00     3947     2871\n#&gt; weight_c      0.91      0.04     0.82     0.99 1.00     3945     2996\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     5.10      0.20     4.74     5.51 1.00     4902     3275\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nLa stima dell‚Äôintercetta \\(\\alpha\\) = 154.60 suggerisce che, per le persone con un peso corrispondente al valore medio del campione analizzato, l‚Äôaltezza prevista √® di 154.60 cm.\nPossiamo confrontare i risultati ottenuti da brm() con quelli prodotti dall‚Äôappriccio frequentista:\n\nfit_2 &lt;- lm(height ~ 1 + weight_c, data = df)\n\n\nsummary(fit_2)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = height ~ 1 + weight_c, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -19.746  -2.884   0.022   3.142  14.774 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)\n#&gt; (Intercept)  154.597      0.271   570.2   &lt;2e-16\n#&gt; weight_c       0.905      0.042    21.5   &lt;2e-16\n#&gt; \n#&gt; Residual standard error: 5.09 on 350 degrees of freedom\n#&gt; Multiple R-squared:  0.57,   Adjusted R-squared:  0.568 \n#&gt; F-statistic:  463 on 1 and 350 DF,  p-value: &lt;2e-16\n\nAnche in questo caso, l‚Äôuso di prior debolmente informativi fa in modo che i risultati dei due approcci siano praticamente equivalenti.\n\n\n55.2.2 Visualizzazione dei Risultati\nPer comprendere la relazione stimata, utilizziamo la funzione conditional_effects:\n\nconditional_effects(fit_1, effects = \"weight_c\")\n\n\n\n\n\n\n\n\nIl grafico generato mostra:\n\nMedia posteriore: La linea rappresenta la stima centrale dell‚Äôaltezza per un dato peso.\nIntervallo di densit√† pi√π alta (HDI): L‚Äôarea evidenziata intorno alla linea mostra l‚Äôincertezza delle stime con un intervallo di probabilit√† del 95%.\n\nSe si desidera modificare la percentuale dell‚Äôintervallo di credibilit√†, √® possibile farlo utilizzando l‚Äôargomento prob, per esempio:\n\nconditional_effects(fit_1, effects = \"weight_c\", prob = 0.89)",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>55</span>¬† <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_synt_sugar.html#distribuzione-a-posteriori-dei-parametri",
    "href": "chapters/linear_models/03_synt_sugar.html#distribuzione-a-posteriori-dei-parametri",
    "title": "55¬† Zucchero sintattico",
    "section": "55.3 Distribuzione a Posteriori dei Parametri",
    "text": "55.3 Distribuzione a Posteriori dei Parametri\nPer esaminare la distribuzione a posteriori dei parametri usiamo la funzione mcmc_plot():\n\nmcmc_plot(fit_1, type = \"dens\")\n\n\n\n\n\n\n\n\nEsaminiamo in maggiori dettagli il sommario numerico dei parametri stimati:\n\ndraws &lt;- posterior::as_draws(fit_1, variable = \"^b_\", regex = TRUE)\nposterior::summarise_draws(draws, \"mean\", \"sd\", \"mcse_mean\", \"mcse_sd\")\n#&gt; # A tibble: 2 √ó 5\n#&gt;   variable       mean     sd mcse_mean  mcse_sd\n#&gt;   &lt;chr&gt;         &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 b_Intercept 155.    0.269   0.00428  0.00391 \n#&gt; 2 b_weight_c    0.906 0.0423  0.000675 0.000681\n\nUtilizziamo la funzione as_draws() che trasforma un oggetto R in un formato compatibile con posterior. Gli argomenti variable = \"^b_\" e regex = TRUEconsentono di selezionare solo i parametri il cui nome inizia con b_: nel nostro caso saranno l‚Äôintercetta e la pendenza del modello di regressione lineare.\nSuccessivamente usiamo la funzione summarise_draws() con gli argomenti specificati per un sommario della distribuzione a posteriori dei parametri prescelti.\n\n55.3.1 Spiegazione di mcse_mean e mcse_sd\nI valori mcse_mean e mcse_sd sono le Monte Carlo Standard Errors (errori standard Monte Carlo) per la stima della media (mean) e della deviazione standard (sd), rispettivamente. Questi valori quantificano l‚Äôincertezza associata al processo di campionamento effettuato durante l‚Äôanalisi bayesiana, in particolare quando si utilizzano algoritmi Monte Carlo come MCMC (Markov Chain Monte Carlo).\n\n55.3.1.1 mcse_mean\n\nRappresenta l‚Äôerrore standard Monte Carlo per la stima della media.\nIndica quanto la media stimata (\\(\\text{mean}\\)) potrebbe variare a causa della finitezza dei campioni generati dall‚Äôalgoritmo MCMC.\nUn valore di mcse_mean basso rispetto alla deviazione standard (\\(\\text{sd}\\)) suggerisce che il numero di campioni generati √® sufficiente per ottenere una stima accurata della media.\n\n\n\n55.3.1.2 mcse_sd\n\nRappresenta l‚Äôerrore standard Monte Carlo per la stima della deviazione standard.\nIndica quanto potrebbe variare la stima della deviazione standard (\\(\\text{sd}\\)) a causa del numero finito di campioni generati.\nAnche qui, un valore basso di mcse_sd rispetto alla sd suggerisce che l‚Äôincertezza introdotta dal campionamento √® trascurabile.\n\n\n\n\n55.3.2 Come interpretarli?\n\nProporzione rispetto alla sd:\n\nmcse_mean e mcse_sd dovrebbero essere molto pi√π piccoli rispetto ai rispettivi parametri (mean e sd), idealmente almeno un ordine di grandezza inferiore.\nAd esempio, per b_Intercept, mcse_mean = 0.0044 √® molto pi√π piccolo rispetto a sd = 0.2695, indicando che la stima della media √® robusta.\n\nIndicazione della qualit√† del campionamento:\n\nValori alti di mcse_mean o mcse_sd rispetto alla sd potrebbero indicare che il numero di iterazioni MCMC non √® sufficiente, che le catene non sono ben mescolate o che ci sono problemi di convergenza.\n\n\nIn sintesi, mcse_mean e mcse_sd sono utili per valutare l‚Äôaffidabilit√† delle stime derivate dal campionamento Monte Carlo. Se questi valori sono bassi, possiamo essere confidenti che il numero di campioni √® sufficiente per rappresentare accuratamente la distribuzione a posteriori.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>55</span>¬† <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_synt_sugar.html#specificare-i-priors",
    "href": "chapters/linear_models/03_synt_sugar.html#specificare-i-priors",
    "title": "55¬† Zucchero sintattico",
    "section": "55.4 Specificare i Priors",
    "text": "55.4 Specificare i Priors\nSe vogliamo personalizzare i priors, possiamo utilizzare la funzione get_prior per esplorare quelli predefiniti:\n\nget_prior(height ~ 1 + weight_c, data = df)\n#&gt;                     prior     class     coef group resp dpar nlpar lb ub\n#&gt;  student_t(3, 154.3, 8.5) Intercept                                     \n#&gt;                    (flat)         b                                     \n#&gt;                    (flat)         b weight_c                            \n#&gt;      student_t(3, 0, 8.5)     sigma                                 0   \n#&gt;        source\n#&gt;       default\n#&gt;       default\n#&gt;  (vectorized)\n#&gt;       default\n\n\nprior: descrive il prior predefinito assegnato a ciascun parametro del modello. Ad esempio:\n\nstudent_t(3, 154.3, 8.5): prior t di Student per l‚Äôintercetta con 3 gradi di libert√†, una media di 154.3, e una scala di 8.5.\n(flat): prior piatto (non informativo) per i coefficienti delle variabili predittive, come \\(b\\) e \\(b_{weight_c}\\).\nstudent_t(3, 0, 8.5): prior t di Student per il parametro \\(\\sigma\\) (deviazione standard residua), centrato su 0 con una scala di 8.5.\n\nclass: identifica la classe di parametro a cui il prior si applica:\n\nIntercept: prior per l‚Äôintercetta (\\(\\alpha\\)).\nb: prior per i coefficienti delle variabili predittive (\\(\\beta\\)).\nsigma: prior per il parametro della deviazione standard residua (\\(\\sigma\\)).\n\ncoef: specifica a quale predittore si riferisce il prior, se applicabile. Ad esempio:\n\nVuoto per l‚Äôintercetta (poich√© non dipende da un predittore specifico).\nweight_c per il coefficiente relativo al predittore weight_c.\n\nlb e ub: rappresentano rispettivamente i limiti inferiori (lower bound) e superiori (upper bound) per il prior, se specificati. Ad esempio:\n\nPer sigma, il limite inferiore √® \\(0\\), dato che la deviazione standard non pu√≤ essere negativa.\n\nsource: indica l‚Äôorigine del prior. Se il prior √® predefinito (default), il valore sar√† default. Se un prior √® specificato manualmente dall‚Äôutente, sar√† indicato come tale.\n\nOra impostiamo priors espliciti e adattiamo un nuovo modello:\n\nprior_guassian &lt;-\n  prior(normal(160, 10), class = \"b\", coef = \"Intercept\") +\n  prior(normal(0, 5), class = \"b\", coef = \"weight_c\") +\n  prior(cauchy(0, 5), class = \"sigma\")\n\n\nfit_2 = brm(\n  bf(height ~ 1 + weight_c, center = FALSE), \n  prior = prior_guassian,\n  data = df, \n  backend = \"cmdstanr\", \n  silent = 0\n)\n\nOtteniamo un sommario numerico dei parametri stimati:\n\ndraws &lt;- posterior::as_draws(fit_2, variable = \"^b_\", regex = TRUE)\nposterior::summarise_draws(draws, \"mean\", \"sd\", \"mcse_mean\", \"mcse_sd\")\n#&gt; # A tibble: 2 √ó 5\n#&gt;   variable       mean     sd mcse_mean  mcse_sd\n#&gt;   &lt;chr&gt;         &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 b_Intercept 155.    0.274   0.00445  0.00425 \n#&gt; 2 b_weight_c    0.906 0.0436  0.000661 0.000697\n\nI prior che abbiamo specificato non cambiano in maniera rilevante la soluzione a posteriori.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>55</span>¬† <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_synt_sugar.html#predizioni-predittive-a-posteriori",
    "href": "chapters/linear_models/03_synt_sugar.html#predizioni-predittive-a-posteriori",
    "title": "55¬† Zucchero sintattico",
    "section": "55.5 Predizioni Predittive a Posteriori",
    "text": "55.5 Predizioni Predittive a Posteriori\nUn aspetto fondamentale nella valutazione di un modello statistico, sia frequentista che bayesiano, √® verificare quanto bene i dati osservati siano rappresentati dalle predizioni del modello. Tuttavia, l‚Äôapproccio e l‚Äôinterpretazione differiscono tra i due paradigmi.\n\n55.5.1 Confronto Frequentista\nNel caso frequentista, si confrontano i valori predetti dal modello, \\(\\hat{y} = \\hat{\\alpha} + \\hat{\\beta}x\\), con i dati osservati. Questo confronto si basa sull‚Äôanalisi di: - La vicinanza della retta di regressione stimata ai dati osservati. - L‚Äôeventuale presenza di pattern nei dati che si discostano da un andamento lineare. - La variazione della dispersione dei valori di \\(y\\) rispetto a \\(x\\) (ad esempio, per verificare l‚Äôipotesi di omoschedasticit√†).\n\n\n55.5.2 Approccio Bayesiano\nNell‚Äôapproccio bayesiano, si eseguono le stesse verifiche di base, ma l‚Äôanalisi si arricchisce attraverso l‚Äôuso delle Predizioni Predittive a Posteriori (Posterior Predictive Checks, PPCs). Questo metodo consente di confrontare i dati osservati con dati simulati dal modello, utilizzando l‚Äôincertezza stimata nelle distribuzioni a posteriori dei parametri.\n\n\n55.5.3 Costruzione delle Predizioni Predittive a Posteriori\nNel caso di un modello bivariato, il processo per generare un grafico delle Predizioni Predittive a Posteriori √® il seguente:\n\nDati osservati: Si parte dall‚Äôistogramma lisciato dei dati osservati, che rappresenta la distribuzione empirica di \\(y\\).\nSimulazione di dati predetti:\n\nSi estrae un campione casuale di valori \\(\\alpha'\\), \\(\\beta'\\), e \\(\\sigma'\\) dalle distribuzioni a posteriori dei parametri (\\(\\alpha\\), \\(\\beta\\), e \\(\\sigma\\)).\nUsando questi valori, si calcolano dati simulati da una distribuzione normale: \\[\ny_{\\text{sim}} \\sim \\mathcal{N}(\\alpha' + \\beta'x, \\sigma')\n\\] dove \\(x\\) sono i valori predittori osservati.\n\nCreazione di istogrammi: Per ogni campione simulato, si costruisce un istogramma lisciato che rappresenta la distribuzione predetta dal modello.\nRipetizione: Il processo viene ripetuto pi√π volte, generando molti istogrammi lisciati.\nConfronto: Tutti gli istogrammi predetti vengono sovrapposti all‚Äôistogramma dei dati osservati. Questo consente di confrontare visivamente la capacit√† del modello di rappresentare la distribuzione dei dati.\n\n\n\n55.5.4 Interpretazione\n\nBuona corrispondenza: Se gli istogrammi lisciati dei dati simulati si sovrappongono bene all‚Äôistogramma dei dati osservati, significa che il modello √® in grado di rappresentare adeguatamente il campione corrente.\nDiscrepanze: Se vi sono discrepanze sistematiche (ad esempio, picchi o code mancanti nei dati predetti rispetto agli osservati), ci√≤ indica che il modello potrebbe non essere adeguato o che vi sono aspetti dei dati non catturati dal modello.\n\nL‚Äôapproccio delle Predizioni Predittive a Posteriori √® particolarmente potente perch√©:\n\nIntegra l‚Äôincertezza nei parametri del modello.\nPermette di verificare non solo la bont√† di adattamento complessiva, ma anche specifici aspetti delle distribuzioni predette.\n√à visivo e intuitivo, facilitando l‚Äôidentificazione di discrepanze tra modello e dati.\n\nIn conclusione, le Predizioni Predittive a Posteriori forniscono un modo robusto per valutare l‚Äôadeguatezza di un modello bayesiano rispetto ai dati osservati. Se il modello riproduce bene la distribuzione dei dati osservati, si pu√≤ concludere che √® adatto almeno per il campione corrente. In caso contrario, potrebbe essere necessario rivedere le specifiche del modello, come i priors o la struttura delle variabili.\nVerifichiamo dunque le predizioni del modello confrontandole con i dati osservati del campione corrente:\n\npp_check(fit_2)\n#&gt; Using 10 posterior draws for ppc type 'dens_overlay' by default.\n\n\n\n\n\n\n\n\nNel caso presente, vi √® una buona corrispondenza tra i dati simulati dal modello e i dati osservati.\nIl grafico seguente analizza gli errori del modello rispetto alla retta di regressione stimata.\n\npp_check(fit_1, type = \"error_scatter_avg\")\n#&gt; Using all posterior draws for ppc type 'error_scatter_avg' by default.\n\n\n\n\n\n\n\n\nQuesto comando utilizza la funzione pp_check() per produrre un grafico che mostra i residui bayesiani, ovvero le differenze tra i dati osservati e quelli predetti dal modello. Nel tipo specifico di grafico scelto (\"error_scatter_avg\"), i residui sono rappresentati rispetto ai valori predetti, consentendo di valutare visivamente se sono distribuiti in modo uniforme.\nDal grafico, si osserva che i residui bayesiani appaiono distribuiti in modo omogeneo rispetto alla retta di regressione (che non √® direttamente mostrata nel grafico). Questo suggerisce che:\n\nIl modello cattura correttamente la relazione tra la variabile predittiva e la variabile di risposta.\nNon ci sono pattern sistematici nei residui, come deviazioni non lineari o variazioni della dispersione (eteroschedasticit√†).\n\nSe fossero presenti pattern evidenti nei residui (ad esempio, una struttura curva o una variazione sistematica della dispersione), ci√≤ indicherebbe che il modello potrebbe non essere adeguato, richiedendo una rivalutazione della sua struttura (ad esempio, aggiungendo termini non lineari o trasformando le variabili).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>55</span>¬† <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_synt_sugar.html#regressione-robusta",
    "href": "chapters/linear_models/03_synt_sugar.html#regressione-robusta",
    "title": "55¬† Zucchero sintattico",
    "section": "55.6 Regressione Robusta",
    "text": "55.6 Regressione Robusta\nIn questa sezione introduciamo la regressione robusta. Lo scopo √® quello di mostrare quanto sia facile modificare il modello definito da brm per specificare una diversa distribuzione degli errori. Questo non √® possibile nel caso dell‚Äôapproccio frequentista.\nI modelli robusti sono utili in presenza di outlier. Ad esempio, introduciamo un outlier nei dati:\n\ndf_outlier &lt;- df\ndf_outlier$height[1] &lt;- 200\ndf_outlier$weight_c[1] &lt;- -15\n\n\ndf_outlier |&gt; \n  ggplot(aes(x = weight_c, y = height)) +\n    geom_point() +  \n    labs(x = \"Weight\", y = \"Height\") \n\n\n\n\n\n\n\n\nNotiamo come la presenza di un solo outlier introduce una distorsione nei risultati:\n\nfit_3 = brm(\n  bf(height ~ 1 + weight_c, center = FALSE), \n  prior = prior_guassian,\n  data = df_outlier, \n  backend = \"cmdstanr\", \n  silent = 0\n)\n\n\ndraws &lt;- posterior::as_draws(fit_3, variable = \"^b_\", regex = TRUE)\nposterior::summarise_draws(draws, \"mean\", \"sd\", \"mcse_mean\", \"mcse_sd\")\n#&gt; # A tibble: 2 √ó 5\n#&gt;   variable       mean     sd mcse_mean  mcse_sd\n#&gt;   &lt;chr&gt;         &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 b_Intercept 155.    0.319   0.00488  0.00496 \n#&gt; 2 b_weight_c    0.846 0.0483  0.000810 0.000734\n\nAdattiamo ora un modello robusto utilizzando una distribuzione \\(t\\) di Student:\n\nfit_4 = brm(\n  bf(height ~ 1 + weight_c, center = FALSE), \n  prior = prior_guassian,\n  family = student(),\n  data = df_outlier, \n  backend = \"cmdstanr\", \n  silent = 0\n)\n\nI risultati mostrano che il modello \\(t\\) √® meno influenzato dagli outlier rispetto al modello gaussiano.\n\ndraws &lt;- posterior::as_draws(fit_4, variable = \"^b_\", regex = TRUE)\nposterior::summarise_draws(draws, \"mean\", \"sd\", \"mcse_mean\", \"mcse_sd\")\n#&gt; # A tibble: 2 √ó 5\n#&gt;   variable       mean     sd mcse_mean  mcse_sd\n#&gt;   &lt;chr&gt;         &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 b_Intercept 155.    0.273   0.00447  0.00495 \n#&gt; 2 b_weight_c    0.920 0.0415  0.000652 0.000777\n\nIl parametro \\(\\nu\\) della \\(t\\) di Student viene stimato dal modello. Nel caso presente\n\ndraws &lt;- posterior::as_draws(fit_4, variable = \"nu\")\nposterior::summarise_draws(draws, \"mean\", \"sd\", \"mcse_mean\", \"mcse_sd\")\n#&gt; # A tibble: 1 √ó 5\n#&gt;   variable  mean    sd mcse_mean mcse_sd\n#&gt;   &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 nu        6.16  1.68    0.0294  0.0353\n\nCon un parametro \\(\\nu\\) = 6, la \\(t\\) di Student ha delle ‚Äúcode‚Äù molto maggiori di una gaussiana, e questo le consene di ‚Äúassorbire‚Äù gli outliers in maniera maggiore che la gaussiana.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>55</span>¬† <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_synt_sugar.html#indice-di-determinazione-bayesiano",
    "href": "chapters/linear_models/03_synt_sugar.html#indice-di-determinazione-bayesiano",
    "title": "55¬† Zucchero sintattico",
    "section": "55.7 Indice di Determinazione Bayesiano",
    "text": "55.7 Indice di Determinazione Bayesiano\nCon il pacchetto brms, possiamo calcolare il Bayes \\(R^2\\), che rappresenta l‚Äôequivalente bayesiano del classico indice di determinazione \\(R^2\\). Questo indice quantifica la proporzione di varianza spiegata dal modello, tenendo conto dell‚Äôincertezza intrinseca delle stime bayesiane.\nIl comando per calcolarlo √®:\n\nbayes_R2(fit_4)\n#&gt;    Estimate Est.Error  Q2.5 Q97.5\n#&gt; R2      0.5    0.0208 0.457 0.537\n\nIl comando restituisce un tibble (una tabella ordinata) con le seguenti informazioni:\n\nEstimate: La stima media del Bayes \\(R^2\\), cio√® la proporzione di varianza spiegata dal modello, basata sulle distribuzioni a posteriori dei parametri.\nEst.Error: L‚Äôerrore standard associato alla stima del \\(R^2\\).\nQ2.5 e Q97.5: I limiti inferiore e superiore dell‚Äôintervallo di credibilit√† al 95% per il Bayes \\(R^2\\). Questi valori indicano l‚Äôincertezza sul \\(R^2\\), riflettendo la distribuzione a posteriori.\n\nNel caso presente\n\nStima del \\(R^2\\): Il modello spiega in media circa il 50% della varianza osservata nella variabile dipendente.\nErrore Standard: L‚Äôincertezza sulla stima √® relativamente bassa (¬±0.02).\nIntervallo di Credibilit√†: C‚Äô√® un 95% di probabilit√† che il vero valore del \\(R^2\\) si trovi tra 0.457 e 0.537.\n\n\n55.7.1 Differenze rispetto al Frequentista \\(R^2\\)\n\nIncertezza: Il Bayes \\(R^2\\) include un‚Äôintera distribuzione a posteriori, permettendo di rappresentare l‚Äôincertezza attraverso l‚Äôintervallo di credibilit√†. Questo non √® possibile con il \\(R^2\\) frequentista, che fornisce una stima puntuale.\nPriors: Il Bayes \\(R^2\\) √® influenzato dai priors scelti per i parametri del modello, il che consente una maggiore flessibilit√† e incorpora conoscenze preesistenti.\n\nIn conclusione, il Bayes \\(R^2\\) √® uno strumento potente per valutare l‚Äôadattamento di un modello bayesiano, permettendo di quantificare non solo la proporzione di varianza spiegata, ma anche l‚Äôincertezza associata alla stima.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>55</span>¬† <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_synt_sugar.html#riflessioni-conclusive",
    "href": "chapters/linear_models/03_synt_sugar.html#riflessioni-conclusive",
    "title": "55¬† Zucchero sintattico",
    "section": "55.8 Riflessioni conclusive",
    "text": "55.8 Riflessioni conclusive\nQuesto capitolo ha mostrato come utilizzare brms per costruire e interpretare modelli lineari, evidenziando le sue capacit√† di gestione dei priors, diagnostica e modellizzazione robusta. Grazie alla sua semplicit√† e flessibilit√†, brms rappresenta un potente strumento per l‚Äôinferenza bayesiana.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>55</span>¬† <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_synt_sugar.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/03_synt_sugar.html#informazioni-sullambiente-di-sviluppo",
    "title": "55¬† Zucchero sintattico",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: US/Pacific\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] rstan_2.32.6         StanHeaders_2.32.10  cmdstanr_0.8.1      \n#&gt;  [4] posterior_1.6.0.9000 brms_2.22.0          Rcpp_1.0.13-1       \n#&gt;  [7] ggokabeito_0.1.0     see_0.9.0            gridExtra_2.3       \n#&gt; [10] patchwork_1.3.0      bayesplot_1.11.1     psych_2.4.12        \n#&gt; [13] scales_1.3.0         markdown_1.13        knitr_1.49          \n#&gt; [16] lubridate_1.9.4      forcats_1.0.0        stringr_1.5.1       \n#&gt; [19] dplyr_1.1.4          purrr_1.0.2          readr_2.1.5         \n#&gt; [22] tidyr_1.3.1          tibble_3.2.1         ggplot2_3.5.1       \n#&gt; [25] tidyverse_2.0.0      rio_1.2.3            here_1.0.1          \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1     farver_2.1.2         loo_2.8.0           \n#&gt;  [4] R.utils_2.12.3       fastmap_1.2.0        tensorA_0.36.2.1    \n#&gt;  [7] pacman_0.5.1         digest_0.6.37        timechange_0.3.0    \n#&gt; [10] lifecycle_1.0.4      processx_3.8.5       magrittr_2.0.3      \n#&gt; [13] compiler_4.4.2       rlang_1.1.4          tools_4.4.2         \n#&gt; [16] utf8_1.2.4           yaml_2.3.10          data.table_1.16.4   \n#&gt; [19] labeling_0.4.3       bridgesampling_1.1-2 htmlwidgets_1.6.4   \n#&gt; [22] curl_6.1.0           pkgbuild_1.4.5       mnormt_2.1.1        \n#&gt; [25] plyr_1.8.9           abind_1.4-8          withr_3.0.2         \n#&gt; [28] R.oo_1.27.0          grid_4.4.2           stats4_4.4.2        \n#&gt; [31] colorspace_2.1-1     inline_0.3.21        cli_3.6.3           \n#&gt; [34] mvtnorm_1.3-3        rmarkdown_2.29       generics_0.1.3      \n#&gt; [37] RcppParallel_5.1.9   reshape2_1.4.4       tzdb_0.4.0          \n#&gt; [40] parallel_4.4.2       matrixStats_1.5.0    vctrs_0.6.5         \n#&gt; [43] V8_6.0.0             Matrix_1.7-1         jsonlite_1.8.9      \n#&gt; [46] hms_1.1.3            glue_1.8.0           codetools_0.2-20    \n#&gt; [49] ps_1.8.1             distributional_0.5.0 stringi_1.8.4       \n#&gt; [52] gtable_0.3.6         QuickJSR_1.5.1       munsell_0.5.1       \n#&gt; [55] pillar_1.10.1        htmltools_0.5.8.1    Brobdingnag_1.2-9   \n#&gt; [58] R6_2.5.1             rprojroot_2.0.4      evaluate_1.0.1      \n#&gt; [61] lattice_0.22-6       R.methodsS3_1.8.2    backports_1.5.0     \n#&gt; [64] rstantools_2.4.0     coda_0.19-4.1        nlme_3.1-166        \n#&gt; [67] checkmate_2.3.2      xfun_0.50            pkgconfig_2.0.3",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>55</span>¬† <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_synt_sugar.html#bibliografia",
    "href": "chapters/linear_models/03_synt_sugar.html#bibliografia",
    "title": "55¬† Zucchero sintattico",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nWilkinson, G., & Rogers, C. (1973). Symbolic description of factorial models for analysis of variance. Journal of the Royal Statistical Society Series C: Applied Statistics, 22(3), 392‚Äì399.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>55</span>¬† <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_one_mean.html",
    "href": "chapters/linear_models/04_one_mean.html",
    "title": "56¬† Inferenza bayesiana su una media",
    "section": "",
    "text": "56.1 Preparazione del Notebook\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(cmdstanr, posterior, bayestestR, brms)",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>56</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_one_mean.html#introduzione",
    "href": "chapters/linear_models/04_one_mean.html#introduzione",
    "title": "56¬† Inferenza bayesiana su una media",
    "section": "56.2 Introduzione",
    "text": "56.2 Introduzione\nL‚Äôobiettivo principale di questo capitolo √® esaminare un contesto che abbiamo gi√† preso in considerazione in precedenza: ci troviamo di fronte a un campione di dati misurati su una scala a intervalli o rapporti e desideriamo effettuare inferenze sulla media della popolazione da cui il campione √® stato estratto. Tuttavia, anzich√© procedere con una derivazione analitica della distribuzione a posteriori della media della popolazione, in questo caso utilizzeremo brms.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>56</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_one_mean.html#il-modello-normale",
    "href": "chapters/linear_models/04_one_mean.html#il-modello-normale",
    "title": "56¬† Inferenza bayesiana su una media",
    "section": "56.3 Il modello Normale",
    "text": "56.3 Il modello Normale\nI priori coniugati Normali di una Normale non richiedono l‚Äôapprossimazione numerica ottenuta mediante metodi MCMC. In questo capitolo, tuttavia, ripetiamo l‚Äôesercizio descritto nel Capitolo 44 usando brms.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>56</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_one_mean.html#un-esempio-concreto",
    "href": "chapters/linear_models/04_one_mean.html#un-esempio-concreto",
    "title": "56¬† Inferenza bayesiana su una media",
    "section": "56.4 Un esempio concreto",
    "text": "56.4 Un esempio concreto\nPer applicare il modello Normale, utilizzeremo i dati del censimento parziale dell‚Äôarea di Dobe dei !Kung San, raccolti attraverso interviste condotte da Nancy Howell alla fine degli anni ‚Äô60. I !Kung San sono una suddivisione della popolazione San, che vive nel deserto del Kalahari, tra Namibia, Botswana e Angola, e mantengono un‚Äôeconomia basata su caccia e raccolta. Riprodurremo l‚Äôanalisi descritta da McElreath (2020), esaminando unicamente i valori dell‚Äôaltezza di individui di et√† superiore ai 18 anni.\n\ndf &lt;- rio::import(here::here(\"data\", \"Howell_18.csv\"))\ndf |&gt; \n  head()\n#&gt;   height weight age male\n#&gt; 1    152   47.8  63    1\n#&gt; 2    140   36.5  63    0\n#&gt; 3    137   31.9  65    0\n#&gt; 4    157   53.0  41    1\n#&gt; 5    145   41.3  51    0\n#&gt; 6    164   63.0  35    1\n\nIl campione include 352 osservazioni:\n\nlength(df$height)\n#&gt; [1] 352\n\n\nggplot(df, aes(x = height)) +\n  geom_histogram(binwidth = 5, color = \"black\", fill = \"lightgray\") +\n  labs(title = \"Istogramma di Height\", x = \"Altezza (cm)\", y = \"Frequenza\")\n\n\n\n\n\n\n\n\nCome indicato dall‚Äôistogramma, i dati sono approssimativamente distribuiti in maniera gaussiana:\n\ndf |&gt;\n  ggplot(aes(sample = height)) +\n  stat_qq() +\n  stat_qq_line(colour = \"red\") +\n  labs(\n    title = \"Normal Q-Q plot\",\n    x = \"Teorici (Z-score)\",\n    y = \"Valori osservati\"\n  )\n\n\n\n\n\n\n\n\nIn realt√†, dal Q-Q plot si nota un piccolo scostamento sistematico. Quando la retta che approssima i punti empirici risulta pi√π piatta rispetto alla diagonale teorica (che avrebbe pendenza 1 se i dati fossero perfettamente normali), la distribuzione empirica risulta meno dispersa di una Gaussiana di riferimento: i quantili empirici aumentano pi√π lentamente di quelli teorici, indicando una varianza leggermente inferiore (o code meno ampie). Nel caso presente, tuttavia, questo scostamento √® di modesta entit√† e si pu√≤ comunque procedere all‚Äôadattamento di un modello gaussiano.\nLa media dei valori dell‚Äôaltezza nel campione √®:\n\nmean(df$height)\n#&gt; [1] 155\n\ncon una deviazione standard pari a:\n\nsd(df$height)\n#&gt; [1] 7.74",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>56</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_one_mean.html#modello-frequentista-semplice",
    "href": "chapters/linear_models/04_one_mean.html#modello-frequentista-semplice",
    "title": "56¬† Inferenza bayesiana su una media",
    "section": "56.5 Modello frequentista semplice",
    "text": "56.5 Modello frequentista semplice\nIniziamo con un modello frequentista molto semplice, in cui ipotizziamo che ogni osservazione \\(y_i\\) sia generata dal modello:\n\\[\ny_i = \\alpha + \\varepsilon_i,\n\\]\ndove \\(\\varepsilon_i\\) √® un errore aleatorio con media zero (ad esempio, \\(\\varepsilon_i \\sim \\mathcal{N}(0, \\sigma^2)\\)) e \\(\\alpha\\) √® la sola incognita (intercetta). Poich√© non ci interessa includere altre variabili predittive, stiamo stimando semplicemente la media di \\(y\\).\nLa stima di \\(\\alpha\\) √® basata sul principio di massima verosimiglianza, senza informazioni a priori. In R, con l‚Äôapproccio frequentista, ci basta usare:\n\nfm1 &lt;- lm(\n  formula = height ~ 1, \n  data = df\n)\n\nQui, height ~ 1 indica che vogliamo un modello con sola intercetta (nessuna covariata). Analizziamo il risultato:\n\nsummary(fm1)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = height ~ 1, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -18.072  -6.007  -0.292   6.058  24.473 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)\n#&gt; (Intercept)  154.597      0.413     375   &lt;2e-16\n#&gt; \n#&gt; Residual standard error: 7.74 on 351 degrees of freedom\n\n\nsummary(fm1) mostra la stima puntuale di \\(\\alpha\\) (che √® la media campionaria di height) assieme ad altri indicatori (p-value, R-squared e cos√¨ via, anche se in questo caso non ha senso parlare di R-squared con un solo parametro).\n\n\n56.5.1 Intervallo di confidenza al 95%\nPer ottenere l‚Äôintervallo di confidenza (nel senso frequentista) della stima di \\(\\alpha\\), usiamo:\n\nconfint(fm1, level = 0.95)\n#&gt;             2.5 % 97.5 %\n#&gt; (Intercept)   154    155\n\nQuesto produce l‚Äôintervallo di confidenza al 95% basato su procedure di inferenza classica (stima della varianza e dell‚Äôerrore standard di \\(\\alpha\\)).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>56</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_one_mean.html#modello-bayesiano-senza-specificare-priori-priori-uniformi",
    "href": "chapters/linear_models/04_one_mean.html#modello-bayesiano-senza-specificare-priori-priori-uniformi",
    "title": "56¬† Inferenza bayesiana su una media",
    "section": "56.6 Modello bayesiano senza specificare priori (priori uniformi)",
    "text": "56.6 Modello bayesiano senza specificare priori (priori uniformi)\nOra vogliamo replicare lo stesso modello usando un approccio bayesiano con il pacchetto brms. Se non specifichiamo esplicitamente la distribuzione a priori di \\(\\alpha\\), brms usa di default un priore piatto (o debolmente informativo), di fatto molto simile a non avere un‚Äôinformazione a priori.\nIl codice √® analogo:\n\nfm2 &lt;- brm(\n  formula = height ~ 1, \n  data = df,\n  backend = \"cmdstanr\"\n)\n\n\nAnche qui, il modello √® \\(y_i = \\alpha + \\varepsilon_i\\), ma gestito in modo bayesiano.\nsummary(fm2) mostrer√† la posterior mean (o mediana, a seconda dei parametri di configurazione) per \\(\\alpha\\), l‚Äôerrore standard e l‚Äôintervallo di credibilit√†.\n\n\nsummary(fm2)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: height ~ 1 \n#&gt;    Data: df (Number of observations: 352) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept   154.59      0.41   153.76   155.38 1.00     2729     2179\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     7.77      0.30     7.20     8.37 1.00     3096     2129\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n56.6.1 Intervallo di credibilit√†\nL‚Äôoutput di summary(fm2) presenta di default l‚Äôintervallo di credibilit√† al 95%. Questo valore pu√≤ essere modificato con l‚Äôargomento prob =, ad esempio summary(fm2, prob = 0.90) per un 90% di credibilit√†.\nIn assenza di un priore informativo, la distribuzione a posteriori √® sostanzialmente uguale a quella massima verosimiglianza (pi√π un‚Äôeventuale correzione di normalizzazione), quindi i risultati numerici corrispondono molto da vicino a quelli ottenuti dal metodo frequentista. Piccole discrepanze sono dovute alle approssimazioni MCMC.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>56</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_one_mean.html#differenze-di-interpretazione-degli-intervalli",
    "href": "chapters/linear_models/04_one_mean.html#differenze-di-interpretazione-degli-intervalli",
    "title": "56¬† Inferenza bayesiana su una media",
    "section": "56.7 Differenze di interpretazione degli intervalli",
    "text": "56.7 Differenze di interpretazione degli intervalli\n\nApproccio frequentista:\n\nL‚Äôintervallo di confidenza (ad esempio \\([153.78, 155.41]\\)) √® un procedimento statistico che, se ripetuto molte volte su campioni diversi, ‚Äúcatturer√†‚Äù il vero valore di \\(\\alpha\\) nel 95% dei casi. In altre parole, √® un‚Äôaffermazione sul metodo di costruzione dell‚Äôintervallo, non sull‚Äôincertezza del parametro in s√©.\n\nNon √® lecito dire ‚Äúc‚Äô√® il 95% di probabilit√† che \\(\\alpha\\) stia nell‚Äôintervallo \\([153.78, 155.41]\\)‚Äù. La probabilit√† si riferisce alla procedura di campionamento dei dati, non al parametro (che nel frequentismo √® considerato fisso e ignoto).\n\nApproccio bayesiano:\n\nL‚Äôintervallo di credibilit√† \\([153.78, 155.41]\\) al 95% dice che, dati i dati osservati e la prior (qui praticamente uniforme), c‚Äô√® il 95% di probabilit√† che \\(\\alpha\\) appartenga a quell‚Äôintervallo.\n\nQui la probabilit√† √® assegnata direttamente al parametro \\(\\alpha\\), perch√© nella prospettiva bayesiana il parametro √® visto come una variabile aleatoria che riflette la nostra incertezza prima dell‚Äôosservazione dei dati (prior) e dopo l‚Äôosservazione dei dati (posterior).\n\n\nIn sintesi:\n\nFrequentista: l‚Äôintervallo di fiducia √® una propriet√† della procedura di stima; il parametro √® fisso, i dati sono casuali.\n\nBayesiano: l‚Äôintervallo di credibilit√† √® una propriet√† della distribuzione a posteriori; il parametro √® casuale (nel senso che abbiamo incertezza su di esso), e i dati sono osservati.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>56</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_one_mean.html#riportare-i-risultati",
    "href": "chapters/linear_models/04_one_mean.html#riportare-i-risultati",
    "title": "56¬† Inferenza bayesiana su una media",
    "section": "56.8 Riportare i Risultati",
    "text": "56.8 Riportare i Risultati\nNel caso frequentista, il risultato pu√≤ essere riportato nel modo seguente:\n\nL‚Äôanalisi ha fornito una stima puntuale di Œ± pari a 154.6, con un intervallo di confidenza al 95% compreso tra [153.8; 155.4].\n\nNel caso bayesiano:\n\nL‚Äôanalisi bayesiana, condotta con una prior non informativa, ha restituito una stima a posteriori di Œ± pari a 154.6, con un intervallo di credibilit√† al 95% [153.8; 155.4].",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>56</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_one_mean.html#conclusioni-intermedie",
    "href": "chapters/linear_models/04_one_mean.html#conclusioni-intermedie",
    "title": "56¬† Inferenza bayesiana su una media",
    "section": "56.9 Conclusioni Intermedie",
    "text": "56.9 Conclusioni Intermedie\n\nCon lm() (modello lineare frequen¬≠tista), otteniamo la stima di \\(\\alpha\\) con massima verosimiglianza e un intervallo di confidenza al 95%.\n\nCon brm() e un priore piatto (o molto debole), il risultato numerico √® essenzialmente lo stesso, ma la filosofia interpretativa dell‚Äôintervallo \\([153.78, 155.41]\\) cambia.\n\nSe volessimo aggiungere informazioni a priori, potremmo specificare un priore su \\(\\alpha\\) in brm(), e otterremmo stime a posteriori diverse dalle frequentiste, soprattutto se i dati sono poco informativi.\n\nIn questo modo, abbiamo mostrato come lo stesso modello (una semplice stima di media) produca numeri quasi identici in ottica frequentista e bayesiana se il priore √® non informativo, pur differendo profondamente nell‚Äôinterpretazione degli intervalli risultanti.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>56</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_one_mean.html#modello-bayesiano-con-prior",
    "href": "chapters/linear_models/04_one_mean.html#modello-bayesiano-con-prior",
    "title": "56¬† Inferenza bayesiana su una media",
    "section": "56.10 Modello Bayesiano con Prior",
    "text": "56.10 Modello Bayesiano con Prior\nImpostiamo una distribuzione a priori \\(\\mathcal{N}(181, 30)\\) per il parametro \\(\\mu\\) e una distribuzione a priori \\(\\mathcal{N}(0, 20)\\) per il parametro \\(\\sigma\\). Seguendo McElreath (2020), ho impostato la distribuzione a priori per \\(\\mu\\) sul valore della mia altezza, per incorporare nel modello le mie conoscenze precedenti rispetto ai valori dell‚Äôaltezza.\nPertanto, il modello Normale si definisce nel modo seguente:\n\\[\n\\begin{align}\nY_i &\\sim \\mathcal{N}(\\mu, \\sigma) \\notag\\\\\n\\mu &\\sim \\mathcal{N}(181, 30) \\notag\\\\\n\\sigma &\\sim \\mathcal{N}(0, 20) \\notag\n\\end{align}\n\\]\nCon questa specifica del modello:\n\nLa variabile casuale \\(Y_i\\) segue una distribuzione normale con parametri \\(\\mu\\) e \\(\\sigma\\).\nIl parametro \\(\\mu\\) ha una distribuzione a priori normale con media 181 e deviazione standard 30.\nIl parametro \\(\\sigma\\) ha una distribuzione a priori normale con deviazione standard 20, troncata inferiormente a 0.\n\nPer \\(\\sigma\\), la normale troncata con deviazione standard pari a 20 permette una grande variabilit√†, garantendo valori positivi per la deviazione standard della distribuzione normale di \\(Y_i\\). I parametri \\(\\mu\\) e \\(\\sigma\\) sono sconosciuti e rappresentano l‚Äôoggetto dell‚Äôinferenza.\n\nfm3 &lt;- brm(\n  formula = height ~ 1,   # Modello con sola intercetta (mu)\n  data    = df,\n  family  = gaussian(),   # Distribuzione Normale\n  prior   = c(\n    prior(normal(181, 30), class = \"Intercept\"),  # Prior su mu\n    prior(normal(0, 20),   class = \"sigma\")       # Prior su sigma\n  ),\n  chains  = 4,\n  iter    = 2000,\n  seed    = 1234,\n  backend = \"cmdstanr\"\n)\n\n\nsummary(fm3)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: height ~ 1 \n#&gt;    Data: df (Number of observations: 352) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept   154.60      0.41   153.80   155.41 1.00     3156     2659\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     7.77      0.29     7.20     8.38 1.00     3256     2596\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nAnche usando questi prior debolmente informativi per \\(\\alpha\\) e \\(\\sigma\\), l‚Äôintervallo a posteriori per \\(\\alpha\\) coincide con quello frequentista.\nCalcoliamo ora l‚Äôintervallo di credibilit√† all‚Äô89%:\n\nsummary(fm3, prob = 0.89)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: height ~ 1 \n#&gt;    Data: df (Number of observations: 352) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-89% CI u-89% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept   154.60      0.41   153.94   155.27 1.00     3156     2659\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-89% CI u-89% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     7.77      0.29     7.32     8.25 1.00     3256     2596\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nIl risultato ottenuto replica i valori riportati da McElreath (2020) nella sua discussione dell‚Äôanalisi di questi dati, anche se McElreath usa una procedura bayesiana diversa da quella presentata qui. McElreath (2020) giustifica la scelta dell‚Äô89% nel modo seguente:\n\nWhy 89%? It‚Äôs just the default. It displays a quite wide interval, so it shows a high-probability range of parameter values. If you want another interval, such as the conventional and mindless 95%, you can use precis(m4.1,prob=0.95). But I don‚Äôt recommend 95% intervals, because readers will have a hard time not viewing them as significance tests. 89 is also a prime number, so if someone asks you to justify it, you can stare at them meaningfully and incant, ‚ÄúBecause it is prime.‚Äù That‚Äôs no worse justification than the conventional justification for 95%.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>56</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_one_mean.html#funzioni-bayesplot",
    "href": "chapters/linear_models/04_one_mean.html#funzioni-bayesplot",
    "title": "56¬† Inferenza bayesiana su una media",
    "section": "56.11 Funzioni bayesplot",
    "text": "56.11 Funzioni bayesplot\nIl pacchetto bayesplot mette a disposizione un insieme di funzioni molto utili per visualizzare la distribuzione a posteriori di uno o pi√π parametri e per verificare la bont√† di adattamento del modello ai dati.\n\n56.11.1 Traceplot\nUn traceplot consente di verificare la convergenza delle catene MCMC e di controllare l‚Äôautocorrelazione dei campioni a posteriori. Nel seguente esempio, si mostrano le tracce (i valori campionati lungo le iterazioni) per i parametri ‚ÄúIntercept‚Äù e ‚Äúsigma‚Äù:\n\nmcmc_trace(\n  fm3, \n  pars = c(\"Intercept\", \"sigma\"),\n  facet_args = list(nrow = 2)\n)\n\n\n\n\n\n\n\n\n\nL‚Äôasse orizzontale indica il numero di iterazione MCMC,\n\nL‚Äôasse verticale mostra il valore assunto dal parametro in quella iterazione,\n\nAvere catene che si mescolano bene e appaiono ‚Äústazionarie‚Äù (senza trend crescenti o calanti) √® un buon segnale di convergenza.\n\n\n\n56.11.2 Distribuzione a posteriori di un singolo parametro\nSe vogliamo visualizzare la distribuzione a posteriori di un singolo parametro (ad esempio l‚Äôintercetta, qui chiamata ‚Äúb_Intercept‚Äù nel modello brms), possiamo usare:\n\nmcmc_areas(fm3, regex_pars = \"b_Intercept\", prob = 0.89)\n\n\n\n\n\n\n\n\n\nViene mostrata la densit√† a posteriori, con un‚Äôarea evidenziata corrispondente all‚Äô89% di credibilit√† (specificabile con prob = 0.89 o un altro valore).\n\nSe desideriamo un intervallo di credibilit√† al 95%, useremo prob = 0.95.\n\n\n\n56.11.3 Rappresentazione congiunta di due parametri\nPer studiare la relazione tra due parametri (ad esempio ‚ÄúIntercept‚Äù e ‚Äúsigma‚Äù):\n\nmcmc_scatter(fm3, pars = c(\"Intercept\", \"sigma\"))\n\n\n\n\n\n\n\n\n\nSi ottiene un diagramma di dispersione dei campioni a posteriori sui due assi, uno per ciascun parametro, con eventuali isodensit√† che mostrano le aree pi√π probabili nella distribuzione congiunta.\n\n\n\n56.11.4 Posterior Predictive Check\nLa funzione pp_check() √® essenziale per valutare se il modello √® in grado di riprodurre i dati osservati:\n\npp_check(fm3)\n#&gt; Using 10 posterior draws for ppc type 'dens_overlay' by default.\n\n\n\n\n\n\n\n\n\nQuesta funzione genera un confronto tra la distribuzione dei dati reali (rappresentati, ad esempio, con una linea nera su un istogramma) e la distribuzione di diversi dataset simulati dal modello, sfruttando la distribuzione a posteriori dei parametri (\\(\\alpha\\), \\(\\sigma\\), ecc.).\n\nPoich√© il modello bayesiano √® generativo, possiamo campionare nuovi dati ‚Äúfittizi‚Äù a partire da ogni draw della posterior: in questo modo otteniamo molteplici dataset simulati, ognuno generato con un diverso valore di \\(\\alpha\\) e \\(\\sigma\\) estratto dalle distribuzioni posteriori.\n\nNel grafico prodotto da pp_check(), i dati osservati compaiono spesso come linea continua nera, mentre i dati simulati dal modello (ad esempio, 8 repliche di default) sono mostrati in colori pi√π chiari o linee semitrasparenti. Se la distribuzione empirica si sovrappone bene a quelle generate, significa che il modello spiega adeguatamente i dati.\n\nNel nostro caso, notiamo che le distribuzioni simulate risultano molto simili a quella osservata, indicando che la stima di \\(\\alpha\\) e \\(\\sigma\\) cattura in modo soddisfacente la variabilit√† dei dati.\n\nSe invece avessimo osservato discrepanze sistematiche (ad esempio, dati reali con code pi√π pesanti, oppure un picco in posizioni diverse rispetto alle distribuzioni simulate), ci saremmo insospettiti riguardo all‚Äôadeguatezza del modello. In situazioni del genere, conviene rivedere le assunzioni (e.g.¬†normalit√†, varianza costante, eventuali covariate assenti, ecc.) prima di trarre conclusioni dai risultati a posteriori.\n\n\nIn sintesi, il pacchetto bayesplot fornisce strumenti fondamentali per:\n\nValutare la convergenza delle catene MCMC (traceplot, autocorrelation plots),\n\nEsplorare la distribuzione a posteriori dei parametri (mcmc_areas, mcmc_density, mcmc_scatter, ‚Ä¶),\n\nVerificare la bont√† del modello rispetto ai dati osservati mediante posterior predictive checks (pp_check).\n\nQueste analisi grafiche forniscono informazioni cruciali sia sulla qualit√† del campionamento (e dunque sulla stabilit√† delle stime) sia sull‚Äôadeguatezza delle ipotesi modellistiche adottate.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>56</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_one_mean.html#lapproccio-tradizionale",
    "href": "chapters/linear_models/04_one_mean.html#lapproccio-tradizionale",
    "title": "56¬† Inferenza bayesiana su una media",
    "section": "56.12 L‚Äôapproccio Tradizionale",
    "text": "56.12 L‚Äôapproccio Tradizionale\nPrima dell‚Äôavvento dei metodi bayesiani e di altri approcci moderni, l‚Äôinferenza sulla media di una popolazione veniva spesso affrontata ricorrendo al test t di Student.\n\n56.12.1 La statistica T di Student\nIl test si basa sulla seguente statistica:\n\\[\nT = \\frac{\\bar{X} - \\mu_0}{s / \\sqrt{n}},\n\\]\ndove:\n\n\\(\\bar{X}\\) √® la media campionaria di \\(n\\) osservazioni,\n\n\\(\\mu_0\\) √® il valore ipotizzato dalla cosiddetta ‚Äúipotesi nulla‚Äù (solitamente \\(\\mu_0 = 0\\), ma pu√≤ essere qualsiasi valore di riferimento),\n\n\\(s\\) √® la deviazione standard campionaria corretta (ovvero stimatore di \\(\\sigma\\)),\n\n\\(n\\) √® la dimensione del campione.\n\nQuando \\(\\sigma\\) (deviazione standard vera) √® sconosciuta e sostituita da \\(s\\), la statistica \\(\\,T\\) segue (in teoria) una distribuzione t di Student con \\(n - 1\\) gradi di libert√†:\n\\[\nT \\sim t_{(n-1)}.\n\\]\n\n\n56.12.2 Collegamento con la distribuzione Z\nSe \\(\\sigma\\) fosse nota, useremmo la statistica:\n\\[\nZ = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}},\n\\]\nla quale segue una distribuzione Normale Standard (\\(Z \\sim \\mathcal{N}(0,1)\\)). Quando invece \\(\\sigma\\) √® sostituita da \\(s\\), la distribuzione di questa statistica diventa una t di Student (che, per \\(n\\) grande, si avvicina molto alla \\(\\mathcal{N}(0,1)\\)).\n\n\n56.12.3 Intervallo di confidenza\nCon il test t di Student, si ottiene anche il tradizionale intervallo di confidenza al 95% per \\(\\mu\\):\n\\[\n\\bar{X} \\pm t_{0.975,\\,n-1} \\cdot \\frac{s}{\\sqrt{n}},\n\\]\ndove \\(t_{0.975,\\,n-1}\\) √® il quantile al 97.5% della distribuzione t con \\(n-1\\) gradi di libert√† (circa 2.0 se \\(n\\) √® sufficientemente grande, mentre 1.96 √® il valore per la distribuzione normale standard).\n\n56.12.3.1 Esempio in R\nNell‚Äôesempio riportato, se vogliamo costruire l‚Äôintervallo di confidenza al 95% manualmente, possiamo scrivere:\n\nmean(df$height) + c(-1, 1) * \n  qt(0.975, length(df$height) - 1) * \n  (sd(df$height) / sqrt(length(df$height)))\n#&gt; [1] 154 155\n\noppure usare direttamente la funzione:\n\nt.test(df$height, mu = 0)\n#&gt; \n#&gt;  One Sample t-test\n#&gt; \n#&gt; data:  df$height\n#&gt; t = 375, df = 351, p-value &lt;2e-16\n#&gt; alternative hypothesis: true mean is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  154 155\n#&gt; sample estimates:\n#&gt; mean of x \n#&gt;       155\n\nche restituisce sia il valore della statistica T, sia l‚Äôintervallo di confidenza e il p-value del test t (ipotizzando, in questo esempio, \\(\\mu_0 = 0\\) come ipotesi nulla).\n\n\n\n56.12.4 Confronto con il modello di regressione a sola intercetta\nSi noti che i risultati (media stimata e intervallo di confidenza) coincidono con quanto si otterrebbe usando una regressione lineare con sola intercetta (come lm(height ~ 1, data=df)) e richiedendo l‚Äôintervallo di confidenza con confint(). Sia il test \\(t\\) di Student sia la regressione lineare semplice (senza covariate) condividono infatti le stesse assunzioni di base e forniscono risultati equivalenti per quanto riguarda l‚Äôinferenza sulla media.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>56</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_one_mean.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/04_one_mean.html#informazioni-sullambiente-di-sviluppo",
    "title": "56¬† Inferenza bayesiana su una media",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: US/Pacific\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] rstan_2.32.6         StanHeaders_2.32.10  brms_2.22.0         \n#&gt;  [4] Rcpp_1.0.13-1        bayestestR_0.15.0    posterior_1.6.0.9000\n#&gt;  [7] cmdstanr_0.8.1       ggokabeito_0.1.0     see_0.9.0           \n#&gt; [10] gridExtra_2.3        patchwork_1.3.0      bayesplot_1.11.1    \n#&gt; [13] psych_2.4.12         scales_1.3.0         markdown_1.13       \n#&gt; [16] knitr_1.49           lubridate_1.9.4      forcats_1.0.0       \n#&gt; [19] stringr_1.5.1        dplyr_1.1.4          purrr_1.0.2         \n#&gt; [22] readr_2.1.5          tidyr_1.3.1          tibble_3.2.1        \n#&gt; [25] ggplot2_3.5.1        tidyverse_2.0.0      rio_1.2.3           \n#&gt; [28] here_1.0.1          \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1     farver_2.1.2         loo_2.8.0           \n#&gt;  [4] R.utils_2.12.3       fastmap_1.2.0        tensorA_0.36.2.1    \n#&gt;  [7] pacman_0.5.1         digest_0.6.37        timechange_0.3.0    \n#&gt; [10] lifecycle_1.0.4      processx_3.8.5       magrittr_2.0.3      \n#&gt; [13] compiler_4.4.2       rlang_1.1.4          tools_4.4.2         \n#&gt; [16] yaml_2.3.10          data.table_1.16.4    labeling_0.4.3      \n#&gt; [19] bridgesampling_1.1-2 htmlwidgets_1.6.4    curl_6.1.0          \n#&gt; [22] pkgbuild_1.4.5       mnormt_2.1.1         plyr_1.8.9          \n#&gt; [25] abind_1.4-8          withr_3.0.2          R.oo_1.27.0         \n#&gt; [28] grid_4.4.2           stats4_4.4.2         colorspace_2.1-1    \n#&gt; [31] inline_0.3.21        ggridges_0.5.6       insight_1.0.1       \n#&gt; [34] cli_3.6.3            mvtnorm_1.3-3        rmarkdown_2.29      \n#&gt; [37] generics_0.1.3       RcppParallel_5.1.9   reshape2_1.4.4      \n#&gt; [40] tzdb_0.4.0           parallel_4.4.2       matrixStats_1.5.0   \n#&gt; [43] vctrs_0.6.5          V8_6.0.0             Matrix_1.7-1        \n#&gt; [46] jsonlite_1.8.9       hms_1.1.3            glue_1.8.0          \n#&gt; [49] codetools_0.2-20     ps_1.8.1             distributional_0.5.0\n#&gt; [52] stringi_1.8.4        gtable_0.3.6         QuickJSR_1.5.1      \n#&gt; [55] munsell_0.5.1        pillar_1.10.1        htmltools_0.5.8.1   \n#&gt; [58] Brobdingnag_1.2-9    R6_2.5.1             rprojroot_2.0.4     \n#&gt; [61] evaluate_1.0.1       lattice_0.22-6       R.methodsS3_1.8.2   \n#&gt; [64] backports_1.5.0      rstantools_2.4.0     coda_0.19-4.1       \n#&gt; [67] nlme_3.1-166         checkmate_2.3.2      xfun_0.50           \n#&gt; [70] pkgconfig_2.0.3",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>56</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_one_mean.html#bibliografia",
    "href": "chapters/linear_models/04_one_mean.html#bibliografia",
    "title": "56¬† Inferenza bayesiana su una media",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>56</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean_stan.html",
    "href": "chapters/linear_models/05_one_mean_stan.html",
    "title": "57¬† Inferenza bayesiana su una media (Stan) üî∏",
    "section": "",
    "text": "57.1 Preparazione del Notebook\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(cmdstanr, posterior, bayestestR)",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media (Stan) üî∏</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean_stan.html#introduzione",
    "href": "chapters/linear_models/05_one_mean_stan.html#introduzione",
    "title": "57¬† Inferenza bayesiana su una media (Stan) üî∏",
    "section": "57.2 Introduzione",
    "text": "57.2 Introduzione\nL‚Äôobiettivo di questo capitolo √® replicare l‚Äôanalisi del capitolo precedente usando Stan direttamente.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media (Stan) üî∏</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean_stan.html#un-esempio-concreto",
    "href": "chapters/linear_models/05_one_mean_stan.html#un-esempio-concreto",
    "title": "57¬† Inferenza bayesiana su una media (Stan) üî∏",
    "section": "57.3 Un esempio concreto",
    "text": "57.3 Un esempio concreto\nPer applicare il modello Normale, utilizzeremo i dati del censimento parziale dell‚Äôarea di Dobe dei !Kung San, raccolti attraverso interviste condotte da Nancy Howell alla fine degli anni ‚Äô60. Riprodurremo l‚Äôanalisi descritta da McElreath (2020), esaminando unicamente i valori dell‚Äôaltezza di individui di et√† superiore ai 18 anni.\n\ndf &lt;- rio::import(here::here(\"data\", \"Howell_18.csv\"))\n\nIl campione include 352 osservazioni:\n\nlength(df$height)\n#&gt; [1] 352\n\nLa media dei valori dell‚Äôaltezza nel campione √®:\n\nmean(df$height)\n#&gt; [1] 155\n\ncon una deviazione standard pari a:\n\nsd(df$height)\n#&gt; [1] 7.74\n\n\n57.3.1 Modello di Base\nImpostiamo una distribuzione a priori \\(\\mathcal{N}(181, 30)\\) per il parametro \\(\\mu\\) e una distribuzione a priori \\(\\mathcal{N}(0, 20)\\) per il parametro \\(\\sigma\\). Seguendo McElreath (2020), ho impostato la distribuzione a priori per \\(\\mu\\) sul valore della mia altezza, per incorporare nel modello le mie conoscenze precedenti rispetto ai valori dell‚Äôaltezza.\nPertanto, il modello Normale si definisce nel modo seguente:\n\\[\n\\begin{align}\nY_i &\\sim \\mathcal{N}(\\mu, \\sigma) \\notag\\\\\n\\mu &\\sim \\mathcal{N}(181, 30) \\notag\\\\\n\\sigma &\\sim \\mathcal{N}(0, 20) \\notag\n\\end{align}\n\\]\nCon questa specifica del modello:\n\nLa variabile casuale \\(Y_i\\) segue una distribuzione normale con parametri \\(\\mu\\) e \\(\\sigma\\).\nIl parametro \\(\\mu\\) ha una distribuzione a priori normale con media 181 e deviazione standard 30.\nIl parametro \\(\\sigma\\) ha una distribuzione a priori normale con deviazione standard 20, troncata inferiormente a 0.\n\nPer \\(\\sigma\\), la normale troncata con deviazione standard pari a 20 permette una grande variabilit√†, garantendo valori positivi per la deviazione standard della distribuzione normale di \\(Y_i\\). I parametri \\(\\mu\\) e \\(\\sigma\\) sono sconosciuti e rappresentano l‚Äôoggetto dell‚Äôinferenza.\n\n# Path to the Stan file\nstan_file &lt;- here::here(\"stan\", \"gaussian_height.stan\")\n\n# Create a CmdStanModel object\nmod &lt;- cmdstan_model(stan_file)\n\n\nmod$print()\n#&gt; data {\n#&gt;     int&lt;lower=1&gt; N;\n#&gt;     vector[N] y;\n#&gt; }\n#&gt; parameters {\n#&gt;     real mu;\n#&gt;     real&lt;lower=0&gt; sigma;\n#&gt; }\n#&gt; model {\n#&gt;   y ~ normal(mu, sigma);\n#&gt;   sigma ~ normal(0, 20);\n#&gt;   mu ~ normal(181, 30);\n#&gt; }\n\nCreaiamo un dizionario con i dati in formato appropriato per Stan:\n\nstan_data = list(\n  N = length(df$height),\n  y = df$height\n)\n\nEseguiamo il campionamento:\n\nfit &lt;- mod$sample(\n  data = stan_data,\n  seed = 123,\n  chains = 4,\n  parallel_chains = 4,\n  iter_sampling = 2000, \n  iter_warmup = 2000,\n  show_messages = FALSE\n)\n\nEsaminiamo le distribuzioni a posteriori dei due parametri oggetto dell‚Äôinferenza insieme alle loro tracce (cio√® i vettori dei campioni dei parametri \\(\\mu\\) e \\(\\sigma\\) prodotti dalla procedura di campionamento MCMC) mediante un trace plot .\n\nmcmc_trace(fit$draws(c(\"mu\", \"sigma\")))\n\n\n\n\n\n\n\n\nGli istogrammi delle distribuzioni a posteriori si ottengono nel modo seguente:\n\nmcmc_hist(fit$draws(c(\"mu\", \"sigma\")))\n#&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nUna sintesi delle distribuzioni a posteriori dei parametri si ottiene nel modo seguente.\n\nfit$summary(c(\"mu\", \"sigma\"))\n#&gt; # A tibble: 2 √ó 10\n#&gt;   variable   mean median    sd   mad     q5    q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 mu       155.   155.   0.421 0.415 154.   155.    1.00    6854.    5308.\n#&gt; 2 sigma      7.77   7.76 0.295 0.290   7.31   8.27  1.00    6442.    5030.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media (Stan) üî∏</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean_stan.html#parametrizzazione-non-centrata",
    "href": "chapters/linear_models/05_one_mean_stan.html#parametrizzazione-non-centrata",
    "title": "57¬† Inferenza bayesiana su una media (Stan) üî∏",
    "section": "57.4 Parametrizzazione Non Centrata",
    "text": "57.4 Parametrizzazione Non Centrata\nNella versione precedente del modello Normale abbiamo specificato le distribuzioni a priori per i parametri oggetto dell‚Äôinferenza (\\(\\mu\\) e \\(\\sigma\\)) sulla scala dei dati grezzi osservati, i quali hanno una media di 154.6 e una deviazione standard di 7.7. Sul parametro \\(\\mu\\) abbiamo imposto una distribuzione a priori normale con media 181 e deviazione standard 30, e sul parametro \\(\\sigma\\) abbiamo imposto una distribuzione a priori normale con media 0 e deviazione standard 20. Queste distribuzioni a priori sono specifiche per ciascun particolare campione che possiamo osservare.\n√à possibile usare un approccio diverso, che consente di definire delle distribuzioni a priori sui parametri che sono indipendenti dal particolare campione che osserviamo. Questa procedura √® chiamata ‚Äúparametrizzazione non centrata‚Äù (non-centered parametrization). In questo modello, utilizziamo variabili latenti \\(\\mu_{\\text{raw}}\\) e \\(\\sigma_{\\text{raw}}\\), che seguono una distribuzione normale standard:\n\\[\n\\begin{align}\n\\mu_{\\text{raw}} &\\sim \\mathcal{N}(0, 1) \\notag\\\\\n\\sigma_{\\text{raw}} &\\sim \\mathcal{N}(0, 1) \\notag\n\\end{align}\n\\]\nQueste variabili vengono poi trasformate per ottenere i parametri \\(\\mu\\) e \\(\\sigma\\) sulla scala originale:\n\\[\n\\begin{align}\n\\mu &= y_{\\text{mean}} + y_{\\text{sd}} \\cdot \\mu_{\\text{raw}} \\notag\\\\\n\\sigma &= y_{\\text{sd}} \\cdot \\sigma_{\\text{raw}} \\notag\n\\end{align}\n\\]\ndove:\n\n\\(y_{\\text{mean}}\\) √® la media dei dati osservati \\(y\\).\n\\(y_{\\text{sd}}\\) √® la deviazione standard dei dati osservati \\(y\\).\n\nDi seguito √® riportato il codice Stan per questo modello con la parametrizzazione non centrata:\n\n# Path to the Stan file\nstan_file &lt;- here::here(\"stan\", \"gaussian_ncp.stan\")\n\n# Create a CmdStanModel object\nmod_ncp &lt;- cmdstan_model(stan_file)\n\n\nmod_ncp$print()\n#&gt; data {\n#&gt;     int&lt;lower=1&gt; N;\n#&gt;     vector[N] y;\n#&gt; }\n#&gt; transformed data {\n#&gt;     real y_mean = mean(y);\n#&gt;     real y_sd = sd(y);\n#&gt; }\n#&gt; parameters {\n#&gt;     real mu_raw;\n#&gt;     real&lt;lower=0&gt; sigma_raw;\n#&gt; }\n#&gt; transformed parameters {\n#&gt;     real mu;\n#&gt;     real&lt;lower=0&gt; sigma;\n#&gt;     mu = y_mean + y_sd * mu_raw;\n#&gt;     sigma = y_sd * sigma_raw;\n#&gt; }\n#&gt; model {\n#&gt;     // Priors:\n#&gt;     mu_raw ~ normal(0, 1);\n#&gt;     sigma_raw ~ normal(0, 1);\n#&gt;     // Likelihood:\n#&gt;     y ~ normal(mu, sigma);\n#&gt; }\n#&gt; generated quantities {\n#&gt;     vector[N] y_rep;\n#&gt;     for (n in 1:N) {\n#&gt;         y_rep[n] = normal_rng(mu, sigma);\n#&gt;     }\n#&gt; }\n\nEcco una spiegazione dettagliata del modello Stan con parametrizzazione non centrata.\n\nBlocco Dati:\n\nint&lt;lower=1&gt; N;: Il numero totale di prove o osservazioni.\nvector[N] y;: Il vettore dei punteggi osservati per ciascuna prova. Questi punteggi sono sulla loro scala originale e non standardizzati.\n\nBlocco Dati Trasformati:\n\nreal y_mean = mean(y);: La media dei dati osservati y.\nreal y_sd = sd(y);: La deviazione standard dei dati osservati y.\n\nBlocco Parametri:\n\nreal mu_raw;: Un parametro latente che segue una distribuzione normale standard.\nreal&lt;lower=0&gt; sigma_raw;: Un parametro latente che segue una distribuzione normale standard vincolata a essere positiva.\n\nBlocco Parametri Trasformati:\n\nreal mu;: La media della distribuzione normale per y sulla sua scala originale.\nreal&lt;lower=0&gt; sigma;: La deviazione standard della distribuzione normale per y sulla sua scala originale.\nQuesti parametri trasformati sono definiti come:\nmu = y_mean + y_sd * mu_raw;\nsigma = y_sd * sigma_raw;\n\n\nLa parametrizzazione non centrata comporta la riparametrizzazione del modello in termini di variabili standardizzate (mu_raw e sigma_raw) e poi la loro trasformazione di nuovo sulla scala originale dei dati. Questo approccio spesso porta a una migliore efficienza di campionamento e propriet√† di convergenza, specialmente nei modelli gerarchici.\n\nParametri Latenti (mu_raw e sigma_raw):\n\nmu_raw ~ normal(0, 1);: mu_raw √® una variabile normale standardizzata.\nsigma_raw ~ normal(0, 1);: sigma_raw √® una variabile normale standardizzata vincolata a essere positiva.\n\nTrasformazione alla Scala Originale:\n\nmu = y_mean + y_sd * mu_raw;: Questo scala e trasla mu_raw alla posizione e scala dei dati osservati y.\nsigma = y_sd * sigma_raw;: Questo scala sigma_raw alla scala dei dati osservati y.\n\n\nLa dichiarazione della verosimiglianza y ~ normal(mu, sigma); indica che i dati osservati y seguono una distribuzione normale con media mu e deviazione standard sigma. Ecco perch√© ha senso anche se y √® sulla sua scala originale:\n\nDati Osservati sulla Scala Originale: I dati osservati y sono sulla loro scala originale.\nParametri sulla Scala Originale: I parametri mu e sigma, dopo la trasformazione nel blocco transformed parameters, sono anch‚Äôessi sulla scala originale di y.\n\nQuindi, la dichiarazione y ~ normal(mu, sigma); specifica correttamente che i dati osservati y (sulla loro scala originale) sono modellati da una distribuzione normale con media mu e deviazione standard sigma, entrambe sulla scala originale di y.\nInfine, il blocco generated quantities viene utilizzato per i controlli predittivi posteriori generando nuovi dati (y_rep) dalla distribuzione posteriore dei parametri (mu e sigma):\ngenerated quantities {\n    vector[N] y_rep;\n    for (n in 1:N) {\n        y_rep[n] = normal_rng(mu, sigma);\n    }\n}\n\ny_rep: Questo genera punti dati replicati dalla distribuzione normale con la media posteriore mu e la deviazione standard posteriore sigma. Questo ti permette di confrontare le previsioni del modello con i dati osservati per eseguire controlli predittivi posteriori.\n\nEseguiamo il campionamento MCMC per il modello che segue una parametrizzazione non centrata:\n\nfit_ncp &lt;- mod_ncp$sample(\n  data = stan_data,\n  seed = 123,\n  chains = 4,\n  parallel_chains = 4,\n  iter_sampling = 2000, \n  iter_warmup = 2000,\n  show_messages = FALSE\n)\n\nEsaminiamo la distribuzioni a posteriori e le tracce dei parametri \\(\\mu\\) e \\(\\sigma\\):\n\nmcmc_hist(fit_ncp$draws(c(\"mu\", \"sigma\")))\n#&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nmcmc_trace(fit_ncp$draws(c(\"mu\", \"sigma\")))\n\n\n\n\n\n\n\n\nOtteniamo una sintesi delle distribuzioni a posteriori dei parametri:\n\nfit_ncp$summary(c(\"mu\", \"sigma\"))\n#&gt; # A tibble: 2 √ó 10\n#&gt;   variable   mean median    sd   mad     q5    q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 mu       155.   155.   0.412 0.415 154.   155.    1.00    5880.    4902.\n#&gt; 2 sigma      7.76   7.75 0.292 0.291   7.30   8.26  1.00    7200.    5446.\n\nI risultati sono molto simili a quelli ottenuti in precedenza.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media (Stan) üî∏</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean_stan.html#posterior-predictive-check",
    "href": "chapters/linear_models/05_one_mean_stan.html#posterior-predictive-check",
    "title": "57¬† Inferenza bayesiana su una media (Stan) üî∏",
    "section": "57.5 Posterior predictive check",
    "text": "57.5 Posterior predictive check\nUno dei vantaggi del toolkit bayesiano √® che una volta ottenuta la distribuzione a posteriori congiunta dei parametri p(Œ∏|Y) √® possibile utilizzarla per generare le previsioni p(·ª∏). Matematicamente, questo pu√≤ essere fatto calcolando:\n\\[\np(\\tilde{y} \\mid y) = \\int p(\\tilde{y} \\mid \\theta) p(\\theta \\mid y) d\\theta.\n\\]\nQuesta distribuzione √® nota come distribuzione predittiva posteriore. √à predittiva perch√© viene utilizzata per fare previsioni e posteriore perch√© √® calcolata utilizzando la distribuzione posteriore. Quindi possiamo pensare a questa come la distribuzione dei dati futuri dati il modello e i dati osservati.\nUtilizzando Stan √® facile per ottenere campioni predittivi posteriori: non √® necessario calcolare alcun integrale. Dobbiamo convertire l‚Äôoggetto creato dalla funzione sample() nel formato richesto da {bayesplot}. Estraiamo i dati prodotti dal modello y_rep e i dati osservati y:\n\n# Extract posterior predictive samples for y_rep\ny_rep &lt;- fit_ncp$draws(variables = \"y_rep\", format = \"draws_matrix\")\n\n# Extract observed data\ny_obs &lt;- stan_data$y\n\nConvertiamo y_rep in una matrice per compatibilit√† con {bayesplot}.\n\n# Convert y_rep to a matrix\ny_rep_matrix &lt;- as.matrix(y_rep)\n\nGeneriamo il posterior predictive chech plot:\n\n# Posterior predictive check plot\nset.seed(123)\nselected_indices &lt;- sample(nrow(y_rep_matrix), 50)\nppc_dens_overlay(y = y_obs, yrep = y_rep_matrix[selected_indices, ])\n\n\n\n\n\n\n\n\nUn uso comune della distribuzione predittiva posteriore √® quello di eseguire controlli predittivi posteriori. Questi sono un insieme di test che possono essere utilizzati per verificare se il modello √® una buona rappresentazione dei dati. Nella figura, la linea nera rappresenta una KDE (Kernel Density Estimation) dei dati, mentre le linee grigie sono KDE calcolate da ciascuno dei 50 campioni predittivi posteriori. Le linee grigie riflettono l‚Äôincertezza associata alla distribuzione dei dati previsti.\nDato che il tracciato del KDE plot √® contenuto nell‚Äôinsieme di profili dei KDE plot dei campioni predittivi a posteriori, si pu√≤ concludere che il modello utilizzato offre una rappresentazione adeguata dei dati ed √® utile per la maggior parte delle analisi. Tuttavia, √® importante considerare che potrebbero esistere altri modelli in grado di adattarsi meglio all‚Äôintero dataset. Esploreremo ora come poter sviluppare un modello alternativo.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media (Stan) üî∏</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean_stan.html#modello-robusto",
    "href": "chapters/linear_models/05_one_mean_stan.html#modello-robusto",
    "title": "57¬† Inferenza bayesiana su una media (Stan) üî∏",
    "section": "57.6 Modello ‚Äúrobusto‚Äù",
    "text": "57.6 Modello ‚Äúrobusto‚Äù\nNon √® necessario presupporre che i dati seguano una distribuzione gaussiana. Le lievi deviazioni dalla gaussianit√† possono essere considerate attraverso l‚Äôutilizzo della distribuzione t di Student, che √® particolarmente utile quando queste deviazioni si manifestano nelle code della distribuzione, come sembra essere il caso in questa situazione. Pertanto, proponiamo di adottare un modello ‚Äòrobusto‚Äô, maggiormente adatto a gestire osservazioni che si discostano dalla normalit√† nelle code della distribuzione.\nLa distribuzione \\(t\\) di Student √® caratterizzata dal parametro \\(\\nu\\), noto come ‚Äògradi di libert√†‚Äô. Quando \\(\\nu\\) √® pari o superiore a 30, la distribuzione t di Student diventa quasi indistinguibile da una distribuzione normale.\n\n# Creare una funzione per generare dati di distribuzione t per un dato numero di gradi di libert√† (nu)\ngenerate_t_data &lt;- function(nu, n = 1000) {\n  x &lt;- seq(-5, 5, length.out = n)\n  y &lt;- dt(x, df = nu)\n  data.frame(x = x, y = y, nu = as.factor(nu))\n}\n\n# Valori di nu\nnu_values &lt;- c(1, 2, 10, Inf)  # Include infinito direttamente nella lista\n\n# Genera i dati per ciascun nu\ndata_list &lt;- lapply(nu_values, generate_t_data)\ndata &lt;- do.call(rbind, data_list)\n\n# Crea il grafico\np &lt;- ggplot(data, aes(x = x, y = y, color = nu, group = nu)) +\n  geom_line() +\n  scale_color_manual(values = c(\"#F8766D\", \"#00BA38\", \"#619CFF\", \"black\")) +  # Personalizza i colori\n  labs(title = \"Densit√† della Distribuzione t di Student\",\n       x = \"x\",\n       y = \"Densit√†\",\n       color = \"Gradi di libert√† ŒΩ\")\n\n# Stampa il grafico\nprint(p)\n\n\n\n\n\n\n\n\nTuttavia, le code della distribuzione t di Student risultano pi√π pesanti rispetto a quelle della normale quando \\(\\nu\\) √® basso. Pertanto, proponiamo di assegnare a \\(\\nu\\) una distribuzione a priori che concentri la maggior parte della sua massa su valori bassi, come ad esempio una distribuzione esponenziale con un parametro di rate pari a 1/30.\n\n# Definisci il parametro di rate per la distribuzione esponenziale\nrate &lt;- 1 / 30\n\n# Genera campioni dalla distribuzione esponenziale\nsamples &lt;- rexp(10000, rate = rate)\n\n# Crea l'istogramma dei campioni\np &lt;- ggplot(data.frame(Values = samples), aes(x = Values)) +\n  geom_histogram(aes(y = ..density..), bins = 50, alpha = 0.75, fill = \"lightgray\") +\n  ggtitle(\"Exponential Distribution (Œª = 1/30)\") +\n  xlab(\"Values\") +\n  ylab(\"Density\") +\n  theme(legend.position = \"none\") + \n  geom_density(col = \"black\", size = 1) # Aggiunge una linea di densit√† per il confronto\n#&gt; Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#&gt; ‚Ñπ Please use `linewidth` instead.\n\n# Visualizza il grafico\nprint(p)\n#&gt; Warning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\n#&gt; ‚Ñπ Please use `after_stat(density)` instead.\n\n\n\n\n\n\n\n\n\n# Path to the Stan file\nstan_file &lt;- here::here(\"stan\", \"student-model.stan\")\n\n# Create a CmdStanModel object\nmod_t &lt;- cmdstan_model(stan_file)\n\n\nmod_t$print()\n#&gt; data {\n#&gt;     int&lt;lower=1&gt; N;  // Numero totale di prove\n#&gt;     vector[N] y;  // Punteggio in ciascuna prova\n#&gt; }\n#&gt; transformed data {\n#&gt;     real y_mean = mean(y);  // Media dei dati osservati\n#&gt;     real y_sd = sd(y);  // Deviazione standard dei dati osservati\n#&gt; }\n#&gt; parameters {\n#&gt;     real mu_raw;  // Parametro latente standardizzato per mu\n#&gt;     real&lt;lower=0&gt; sigma_raw;  // Parametro latente standardizzato per sigma\n#&gt;     real&lt;lower=1&gt; nu;  // Gradi di libert√† per la distribuzione t di Student\n#&gt; }\n#&gt; transformed parameters {\n#&gt;     real mu;  // Media sulla scala originale\n#&gt;     real&lt;lower=0&gt; sigma;  // Deviazione standard sulla scala originale\n#&gt;     mu = y_mean + y_sd * mu_raw;\n#&gt;     sigma = y_sd * sigma_raw;\n#&gt; }\n#&gt; model {\n#&gt;     // Distribuzioni a priori non centrate\n#&gt;     mu_raw ~ normal(0, 1);\n#&gt;     sigma_raw ~ normal(0, 1);\n#&gt;     nu ~ exponential(1.0 / 30.0);  // Prior esponenziale per i gradi di libert√†\n#&gt;     // Verosimiglianza\n#&gt;     y ~ student_t(nu, mu, sigma);\n#&gt; }\n#&gt; generated quantities {\n#&gt;     vector[N] y_rep;\n#&gt;     for (n in 1:N) {\n#&gt;         y_rep[n] = student_t_rng(nu, mu, sigma);\n#&gt;     }\n#&gt; }\n\nEseguiamo il campionamento MCMC:\n\nfit_t &lt;- mod_t$sample(\n  data = stan_data,\n  seed = 123,\n  chains = 4,\n  parallel_chains = 4,\n  iter_sampling = 2000, \n  iter_warmup = 2000,\n  show_messages = FALSE\n)\n\nEsaminiamo la distribuzioni a posteriori e le tracce dei parametri \\(\\mu\\) e \\(\\sigma\\):\n\nmcmc_hist(fit_t$draws(c(\"mu\", \"sigma\")))\n#&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nmcmc_trace(fit_t$draws(c(\"mu\", \"sigma\")))\n\n\n\n\n\n\n\n\nGeneriamo la distribuzione predittiva a posteriori.\n\n# Extract posterior predictive samples for y_rep\ny_rep &lt;- fit_t$draws(variables = \"y_rep\", format = \"draws_matrix\")\n# Convert y_rep to a matrix\ny_rep_matrix &lt;- as.matrix(y_rep)\n# Posterior predictive check plot\nselected_indices &lt;- sample(nrow(y_rep_matrix), 50)\nppc_dens_overlay(y = y_obs, yrep = y_rep_matrix[selected_indices, ])\n\n\n\n\n\n\n\n\nLa figura illustra che la situazione √® analoga a quella del caso gaussiano. Questo non √® sorprendente, dato che i dati relativi all‚Äôaltezza si distribuiscono in maniera gaussiana nella popolazione. Pertanto, l‚Äôimpiego della distribuzione \\(t\\) di Student o della distribuzione normale producono risultati sostanzialmente equivalenti in questo contesto.\n\nfit_t$summary(c(\"mu\", \"sigma\"))\n#&gt; # A tibble: 2 √ó 10\n#&gt;   variable   mean median    sd   mad     q5    q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 mu       155.   155.   0.413 0.409 154.   155.    1.00    7996.    6269.\n#&gt; 2 sigma      7.64   7.62 0.306 0.301   7.16   8.16  1.00    6869.    5961.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media (Stan) üî∏</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean_stan.html#riflessioni-conclusive",
    "href": "chapters/linear_models/05_one_mean_stan.html#riflessioni-conclusive",
    "title": "57¬† Inferenza bayesiana su una media (Stan) üî∏",
    "section": "57.7 Riflessioni Conclusive",
    "text": "57.7 Riflessioni Conclusive\nIn questo capitolo abbiamo esplorato il metodo per calcolare l‚Äôintervallo di credibilit√† per la media di una variabile casuale normale utilizzando Stan. Inoltre, abbiamo illustrato come sia possibile ampliare l‚Äôinferenza sulla media utilizzando un modello robusto basato sulla distribuzione t di Student.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media (Stan) üî∏</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean_stan.html#esercizi",
    "href": "chapters/linear_models/05_one_mean_stan.html#esercizi",
    "title": "57¬† Inferenza bayesiana su una media (Stan) üî∏",
    "section": "57.8 Esercizi",
    "text": "57.8 Esercizi\n\nEsercizio 57.1 Utilizzando i dati dell‚Äôesempio sui bambini plusdotati discusso nella ?sec-grid-gauss, impiegare Stan per replicare i risultati ottenuti con il metodo basato su griglia.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media (Stan) üî∏</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean_stan.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/05_one_mean_stan.html#informazioni-sullambiente-di-sviluppo",
    "title": "57¬† Inferenza bayesiana su una media (Stan) üî∏",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: US/Pacific\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] bayestestR_0.15.0    posterior_1.6.0.9000 cmdstanr_0.8.1      \n#&gt;  [4] ggokabeito_0.1.0     see_0.9.0            gridExtra_2.3       \n#&gt;  [7] patchwork_1.3.0      bayesplot_1.11.1     psych_2.4.12        \n#&gt; [10] scales_1.3.0         markdown_1.13        knitr_1.49          \n#&gt; [13] lubridate_1.9.4      forcats_1.0.0        stringr_1.5.1       \n#&gt; [16] dplyr_1.1.4          purrr_1.0.2          readr_2.1.5         \n#&gt; [19] tidyr_1.3.1          tibble_3.2.1         ggplot2_3.5.1       \n#&gt; [22] tidyverse_2.0.0      rio_1.2.3            here_1.0.1          \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6         tensorA_0.36.2.1     xfun_0.50           \n#&gt;  [4] htmlwidgets_1.6.4    insight_1.0.1        processx_3.8.5      \n#&gt;  [7] lattice_0.22-6       tzdb_0.4.0           vctrs_0.6.5         \n#&gt; [10] tools_4.4.2          ps_1.8.1             generics_0.1.3      \n#&gt; [13] parallel_4.4.2       pacman_0.5.1         R.oo_1.27.0         \n#&gt; [16] pkgconfig_2.0.3      data.table_1.16.4    checkmate_2.3.2     \n#&gt; [19] distributional_0.5.0 lifecycle_1.0.4      compiler_4.4.2      \n#&gt; [22] farver_2.1.2         munsell_0.5.1        mnormt_2.1.1        \n#&gt; [25] htmltools_0.5.8.1    yaml_2.3.10          pillar_1.10.1       \n#&gt; [28] R.utils_2.12.3       abind_1.4-8          nlme_3.1-166        \n#&gt; [31] tidyselect_1.2.1     digest_0.6.37        stringi_1.8.4       \n#&gt; [34] reshape2_1.4.4       labeling_0.4.3       rprojroot_2.0.4     \n#&gt; [37] fastmap_1.2.0        grid_4.4.2           colorspace_2.1-1    \n#&gt; [40] cli_3.6.3            magrittr_2.0.3       utf8_1.2.4          \n#&gt; [43] withr_3.0.2          backports_1.5.0      timechange_0.3.0    \n#&gt; [46] rmarkdown_2.29       matrixStats_1.5.0    R.methodsS3_1.8.2   \n#&gt; [49] hms_1.1.3            evaluate_1.0.1       rlang_1.1.4         \n#&gt; [52] Rcpp_1.0.13-1        glue_1.8.0           jsonlite_1.8.9      \n#&gt; [55] plyr_1.8.9           R6_2.5.1",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media (Stan) üî∏</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean_stan.html#bibliografia",
    "href": "chapters/linear_models/05_one_mean_stan.html#bibliografia",
    "title": "57¬† Inferenza bayesiana su una media (Stan) üî∏",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media (Stan) üî∏</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_prediction_stan.html",
    "href": "chapters/linear_models/06_prediction_stan.html",
    "title": "58¬† Predizione e inferenza üî∏",
    "section": "",
    "text": "58.1 Introduzione\nGelman et al. (2021) osservano che l‚Äôinferenza bayesiana si sviluppa in tre passaggi fondamentali, che vanno oltre la stima classica. In primo luogo, i dati e il modello vengono combinati per formare una distribuzione a posteriori, che solitamente viene riassunta tramite le distribuzioni a posteriori dei parametri del modello. In secondo luogo, √® possibile propagare l‚Äôincertezza presente in questa distribuzione, ottenendo previsioni basate su simulazioni per risultati non osservati o futuri, tenendo conto dell‚Äôincertezza nei parametri del modello. Infine, √® possibile integrare ulteriori informazioni nel modello utilizzando una distribuzione a priori. Questo capitolo si concentra sui temi della previsione e dell‚Äôinferenza.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>58</span>¬† <span class='chapter-title'>Predizione e inferenza üî∏</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_prediction_stan.html#predizione",
    "href": "chapters/linear_models/06_prediction_stan.html#predizione",
    "title": "58¬† Predizione e inferenza üî∏",
    "section": "58.2 Predizione",
    "text": "58.2 Predizione\nPer discutere i temi della predizione e dell‚Äôinferenza bayesiana nel contesto del modello bayesiano di regressione lineare bivariata, esamineremo nuovamente il set di esaminati nel ?sec-bivariate-bayesian-regression e relativi alla relazione tra Tense Arousal e ansia di stato.\n\ndf &lt;- rio::import(here::here(\"data\", \"affect.csv\")) |&gt; \n  dplyr::select(state1, TA1)\ndf |&gt; \n  head()\n#&gt;   state1 TA1\n#&gt; 1     41  11\n#&gt; 2     26   5\n#&gt; 3     31   8\n#&gt; 4     28   8\n#&gt; 5     47  12\n#&gt; 6     43  10\n\nConsideriamo il modello bayesiano di regressione lineare bivariata che include prior uniformi per i parametri \\(\\alpha\\), \\(\\beta\\) e \\(\\sigma\\) che abbiamo discusso nel ?sec-bivariate-bayesian-regression. Compiliamo il modello.\n\nmodel &lt;- cmdstan_model(here::here(\"stan\", \"arousal_model_prior_raw.stan\"))\n\nIl modello ha questa forma:\n\nmodel$print()\n#&gt; data {\n#&gt;   int&lt;lower=1&gt; N; // numero totale di osservazioni \n#&gt;   vector[N] y; // variabile di risposta\n#&gt;   vector[N] x; // variabile predittore\n#&gt; }\n#&gt; parameters {\n#&gt;   real alpha; // intercetta\n#&gt;   real beta; // coefficiente angolare\n#&gt;   real&lt;lower=0&gt; sigma; // deviazione standard residua\n#&gt; }\n#&gt; model {\n#&gt;   // distribuzioni a priori\n#&gt;   alpha ~ normal(0, 5.0);\n#&gt;   beta ~ normal(0, 2.5);\n#&gt;   sigma ~ cauchy(0, 5.0);\n#&gt;   // verosimiglianza\n#&gt;   y ~ normal(alpha + beta * x, sigma);\n#&gt; }\n\nSistemiamo i dati in un dizionario come richiesto dal modello Stan.\n\nstan_data = list(\n  N = length(df$TA1),\n  x = df$state1,\n  y = df$TA1\n)\n\nEseguiamo il campionamento MCMC.\n\nfit1 &lt;- model$sample(\n  data = stan_data,\n  seed = 123,\n  iter_warmup = 2000,\n  iter_sampling = 2000,\n  show_message = FALSE\n)\n\nEsaminiamo le distribuzioni a posteriori dei parametri:\n\nfit1$summary(variables = c(\"alpha\", \"beta\", \"sigma\"))\n#&gt; # A tibble: 3 √ó 10\n#&gt;   variable  mean median     sd    mad     q5   q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 alpha    1.47   1.48  1.22   1.19   -0.528 3.46   1.00    2644.    3145.\n#&gt; 2 beta     0.269  0.269 0.0286 0.0279  0.223 0.316  1.00    2671.    3143.\n#&gt; 3 sigma    2.70   2.68  0.222  0.216   2.37  3.09   1.00    3463.    3616.\n\nIl punto importante qui √® che la distribuzione a posteriori non fornisce solo informazioni sui singoli parametri, ma anche sulle loro interdipendenze. Queste relazioni sono riflesse nei campioni a posteriori, che possono essere trasformati in vari modi. Ad esempio, possiamo calcolare la predizione a posteriori del modello lineare per il valore atteso di Tense Arousal quando l‚Äôansia di stato √® pari a 30 usando il seguente comando nel blocco generated quantities:\npred = alpha + beta * 30;\nModifichiamo il modello Stan che include la specifica di distribuzioni debolmente informative sui parametri \\(\\alpha\\), \\(\\beta\\) e \\(\\sigma\\) per aggiungere questo comando nel blocco generated quantities e compiliamo il modello.\n\nmodel2 &lt;- cmdstan_model(here::here(\"stan\", \"arousal_model2.stan\"))\n\nIl modello ha questa forma:\n\nmodel2$print()\n#&gt; data {\n#&gt;   int&lt;lower=1&gt; N; // numero totale di osservazioni \n#&gt;   vector[N] y; // variabile di risposta\n#&gt;   vector[N] x; // variabile predittore\n#&gt; }\n#&gt; parameters {\n#&gt;   real alpha; // intercetta\n#&gt;   real beta; // coefficiente angolare\n#&gt;   real&lt;lower=0&gt; sigma; // deviazione standard residua\n#&gt; }\n#&gt; model {\n#&gt;   // distribuzioni a priori\n#&gt;   alpha ~ normal(0, 5.0);\n#&gt;   beta ~ normal(0, 2.5);\n#&gt;   sigma ~ cauchy(0, 5.0);\n#&gt;   // verosimiglianza\n#&gt;   y ~ normal(alpha + beta * x, sigma);\n#&gt; }\n#&gt; generated quantities {\n#&gt;   real pred; // predizione\n#&gt;   \n#&gt;   pred = alpha + beta * 30;\n#&gt; }\n\nIn questo modello Stan aggiornato, il blocco generated quantities calcola la predizione a posteriori pred per una variabile predittore con valore 30. Questa modifica permette di ottenere la distribuzione a posteriori della predizione per un valore specifico del predittore.\nEseguiamo il campionamento.\n\nfit2 &lt;- model2$sample(\n  data = stan_data,\n  seed = 123,\n  iter_warmup = 2000,\n  iter_sampling = 2000,\n  show_message = FALSE\n)\n\nEsaminiamo la stima a posteriori del valore atteso di Tense Arousal quando l‚Äôansia di stato √® pari a 30. Questa analisi fornir√† sia una stima puntuale di Tense Arousal che una misura dell‚Äôincertezza associata, rappresentata dall‚Äôintervallo di credibilit√† al livello di confidenza scelto.\n\nfit2$summary(variables = \"pred\")\n#&gt; # A tibble: 1 √ó 10\n#&gt;   variable  mean median    sd   mad    q5   q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 pred      9.54   9.54 0.442 0.431  8.82  10.3  1.00    3443.    4427.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>58</span>¬† <span class='chapter-title'>Predizione e inferenza üî∏</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_prediction_stan.html#quantificazione-dellincertezza",
    "href": "chapters/linear_models/06_prediction_stan.html#quantificazione-dellincertezza",
    "title": "58¬† Predizione e inferenza üî∏",
    "section": "58.3 Quantificazione dell‚Äôincertezza",
    "text": "58.3 Quantificazione dell‚Äôincertezza\nPer quantificare l‚Äôincertezza complessiva nelle predizioni del modello, possiamo calcolare la distribuzione a posteriori delle predizioni per tutti i valori di \\(x\\) del campione. Questo ci permette di ottenere sia le stime puntuali delle predizioni sia una misura dell‚Äôincertezza associata.\nPer fare ci√≤, modifichiamo il blocco generated quantities nel seguente modo:\ngenerated quantities {\n  vector[N] y_rep; // Predizioni a posteriori per ciascun valore di x\n  \n  for (n in 1:N) {\n    y_rep[n] = normal_rng(alpha + beta * x[n], sigma);\n  }\n}\nEsaminiamo le modifiche:\n\nDichiarazione del vettore y_rep:\n\nvector[N] y_rep;: Dichiara un vettore y_rep di lunghezza N per contenere le predizioni a posteriori per ciascun valore di x.\n\nCiclo for per generare le predizioni:\n\nfor (n in 1:N): Itera su tutte le osservazioni.\ny_rep[n] = normal_rng(alpha + beta * x[n], sigma);: Per ogni valore di x[n], genera una predizione dalla distribuzione normale con media alpha + beta * x[n] e deviazione standard sigma. La funzione normal_rng genera numeri casuali dalla distribuzione normale specificata, rappresentando l‚Äôincertezza nelle predizioni.\n\n\nQuesto approccio consente di ottenere la distribuzione a posteriori delle predizioni, fornendo una visione completa dell‚Äôincertezza associata. Dalla distribuzione a posteriori di y_rep, possiamo calcolare sia la stima puntuale (come la media o la mediana delle predizioni) sia gli intervalli di credibilit√† (come l‚Äôintervallo al 95%) per ogni valore di x. Questo offre una misura dell‚Äôincertezza delle predizioni, riflettendo la variabilit√† e l‚Äôaffidabilit√† del modello.\nModifichiamo il modello imponendo distribuzioni a priori debolmente informative sui parametri:\n\nPer \\(\\alpha\\) e \\(\\beta\\), utilizziamo una distribuzione Normale centrata su 0 con una deviazione standard di 2.\nPer \\(\\sigma\\), utilizziamo una distribuzione di Cauchy centrata su 0 con una scala di 2.\n\n\nmodel3 &lt;- cmdstan_model(here::here(\"stan\", \"arousal_model3.stan\"))\n\nIl modello ha questa forma:\n\nmodel3$print()\n#&gt; data {\n#&gt;   int&lt;lower=1&gt; N; // numero totale di osservazioni \n#&gt;   vector[N] y; // variabile di risposta\n#&gt;   vector[N] x; // variabile predittore\n#&gt; }\n#&gt; parameters {\n#&gt;   real alpha; // intercetta\n#&gt;   real beta; // coefficiente angolare\n#&gt;   real&lt;lower=0&gt; sigma; // deviazione standard residua\n#&gt; }\n#&gt; model {\n#&gt;   // distribuzioni a priori\n#&gt;   alpha ~ normal(0, 5.0);\n#&gt;   beta ~ normal(0, 1.0);\n#&gt;   sigma ~ cauchy(0, 1.0);\n#&gt;   // verosimiglianza\n#&gt;   y ~ normal(alpha + beta * x, sigma);\n#&gt; }\n#&gt; generated quantities {\n#&gt;   vector[N] y_rep; // variabili predette\n#&gt;   \n#&gt;   for (n in 1 : N) {\n#&gt;     y_rep[n] = normal_rng(alpha + beta * x[n], sigma);\n#&gt;   }\n#&gt; }\n\nEseguiamo il campionamento.\n\nfit3 &lt;- model3$sample(\n  data = stan_data,\n  seed = 123,\n  iter_warmup = 2000,\n  iter_sampling = 2000,\n  show_message = FALSE\n)\n\nEsaminiamo la distribuzione a posteriori dei parametri.\n\nfit3$summary(variables = c(\"alpha\", \"beta\", \"sigma\"))\n#&gt; # A tibble: 3 √ó 10\n#&gt;   variable  mean median     sd    mad     q5   q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 alpha    1.44   1.42  1.23   1.19   -0.545 3.47   1.00    2185.    2421.\n#&gt; 2 beta     0.270  0.270 0.0287 0.0277  0.222 0.317  1.00    2050.    2391.\n#&gt; 3 sigma    2.68   2.66  0.219  0.220   2.35  3.06   1.00    3724.    3418.\n\n\n58.3.1 Manipolare le Stime a Posteriori dei Parametri\nCostruiamo un grafico che rappresenta i valori osservati e la linea di regressione stimata tramite un modello bayesiano. Al grafico aggiungeremo diverse linee di regressione, ognuna basata su valori campionati casualmente dalla distribuzione a posteriori dei parametri \\(\\alpha\\) e \\(\\beta\\).\n\n58.3.1.1 Recuperare le Stime a Posteriori\nCon cmdstanr, i risultati del campionamento sono accessibili come oggetti draws_matrix, draws_array, o draws_df. Per estrarre le distribuzioni a posteriori di specifici parametri, possiamo usare il metodo draws() o as_draws_df(). Ad esempio, per estrarre i campioni di \\(\\alpha\\) e \\(\\beta\\) dall‚Äôoggetto fit3, utilizziamo:\n\n# Estrazione dei campioni a posteriori\nalpha_samples &lt;- as_draws_df(fit3)$alpha\nbeta_samples &lt;- as_draws_df(fit3)$beta\n\nStampiamo i primi 20 valori di alpha_samples per verificare:\n\nhead(alpha_samples, 20)\n#&gt;  [1]  2.0171  2.3731  1.1427  2.8008  3.1059  1.7701  1.7726  0.5296  1.8151\n#&gt; [10]  0.0353  0.1250  0.7225 -0.0975 -0.3649  0.0669 -1.4457 -2.3480 -1.8796\n#&gt; [19] -1.9525 -0.1565\n\n\n\n58.3.1.2 Calcolare le Stime Puntuali\nPossiamo calcolare la media a posteriori dei parametri per stimare la retta di regressione media:\n\nmean_alpha &lt;- mean(alpha_samples)\nmean_beta &lt;- mean(beta_samples)\n\ncat(\"Mean alpha:\", mean_alpha, \"\\nMean beta:\", mean_beta)\n#&gt; Mean alpha: 1.44 \n#&gt; Mean beta: 0.27\n\n\n\n58.3.1.3 Grafico della Regressione con Incertezza\nSovrapponiamo una retta di regressione media e linee basate sui campioni a posteriori:\n\n# Dati osservati\nx &lt;- df$state1\ny &lt;- df$TA1\n\n# Creazione del data frame per ggplot\nplot_data &lt;- data.frame(x = x, y = y)\n\n# Costruzione del grafico\nggplot(plot_data, aes(x = x, y = y)) +\n  geom_point(color = \"blue\", size = 1) +\n  # Linee di regressione basate sui campioni\n  geom_abline(aes(intercept = mean_alpha, slope = mean_beta),\n              color = \"red\", size = 1, alpha = 0.8) +\n  lapply(1:300, function(i) {\n    geom_abline(aes(intercept = alpha_samples[i], slope = beta_samples[i]),\n                color = \"gray\", alpha = 0.1)\n  }) +\n  labs(\n    title = \"Regressione con Incertezza Posteriori\",\n    x = \"State Anxiety\",\n    y = \"Tense Arousal\"\n  ) \n#&gt; Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#&gt; ‚Ñπ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\n\n\n58.3.1.4 Incertezza delle Predizioni con \\(\\texttt{y\\_rep}\\)\nUn approccio alternativo consiste nel rappresentare l‚Äôincertezza delle predizioni usando \\(\\texttt{y\\_rep}\\), la distribuzione a posteriori delle osservazioni simulate:\n\n# Estrazione dei campioni posteriori di y_rep\ny_rep_samples &lt;- as_draws_df(fit3)\ny_rep_matrix &lt;- y_rep_samples[, grep(\"y_rep\", colnames(y_rep_samples))]\n#&gt; Warning: Dropping 'draws_df' class as required metadata was removed.\n\n# Compute posterior mean and intervals\ny_rep_mean &lt;- colMeans(y_rep_matrix)\ny_rep_lower &lt;- apply(y_rep_matrix, 2, quantile, 0.025)\ny_rep_upper &lt;- apply(y_rep_matrix, 2, quantile, 0.975)\n\n# Create plot_data with y_rep summaries\nplot_data &lt;- data.frame(\n  x = df$state1,\n  y = df$TA1,\n  y_rep_mean = y_rep_mean,\n  y_rep_lower = y_rep_lower,\n  y_rep_upper = y_rep_upper\n)\n\nggplot(plot_data, aes(x = x, y = y)) +\n  geom_point(color = \"blue\", size = 1) +\n  geom_line(aes(y = y_rep_mean), color = \"red\", size = 1, alpha = 0.8) +\n  geom_ribbon(aes(ymin = y_rep_lower, ymax = y_rep_upper),\n              fill = \"gray\", alpha = 0.3) +\n  labs(\n    title = \"Incertezza delle Predizioni del Modello\",\n    x = \"State Anxiety\",\n    y = \"Tense Arousal\"\n  ) \n\n\n\n\n\n\n\n\n\n\n\n58.3.1.5 Confronto tra Approcci\n\nDistribuzioni a Posteriori di \\(\\alpha\\) e \\(\\beta\\):\n\nVisualizza l‚Äôincertezza nei parametri del modello (\\(\\alpha\\) e \\(\\beta\\)).\nLe linee di regressione rappresentano variazioni nella pendenza e intercetta dovute all‚Äôincertezza dei parametri.\n\nDistribuzione a Posteriori di \\(\\texttt{y\\_rep}\\):\n\nInclude sia l‚Äôincertezza dei parametri sia la variabilit√† residua (\\(\\sigma\\)).\nFornisce una descrizione pi√π completa dell‚Äôincertezza predittiva.\n\n\nEntrambi gli approcci sono utili per esplorare diverse sfaccettature dell‚Äôincertezza nel modello bayesiano.\nNel primo approccio, calcoliamo l‚Äôincertezza delle predizioni utilizzando le distribuzioni a posteriori di alpha e beta. Questo metodo consiste nel generare predizioni lineari per ciascun campione a posteriori di alpha e beta, tracciando quindi le linee di regressione risultanti. Questo ci permette di vedere come varia la linea di regressione in base alle incertezze nei parametri alpha e beta. Questo metodo visualizza come l‚Äôincertezza nei parametri del modello si traduce in incertezza nelle predizioni.\nNel secondo approccio, descriviamo l‚Äôincertezza delle predizioni utilizzando direttamente la distribuzione a posteriori di y_rep. In questo caso, generiamo predizioni per ciascun valore osservato di x nel modello Stan, tenendo conto delle distribuzioni a posteriori dei parametri del modello. Questo metodo visualizza direttamente l‚Äôincertezza nelle predizioni, tenendo conto delle variazioni nei dati osservati e delle distribuzioni a posteriori dei parametri.\nLe due descrizioni dell‚Äôincertezza delle predizioni del modello sono diverse perch√© riflettono aspetti differenti della distribuzione a posteriori:\n\nDistribuzione a posteriori di alpha e beta: Questo approccio considera solo l‚Äôincertezza nei parametri del modello (alpha e beta). Le linee di regressione tracciate variano in base a questi parametri, ma non tengono conto dell‚Äôincertezza residua (sigma).\nDistribuzione a posteriori di y_rep: Questo approccio include non solo l‚Äôincertezza nei parametri alpha e beta, ma anche l‚Äôincertezza residua (sigma). La distribuzione di y_rep riflette la variabilit√† totale nel modello, inclusa la variabilit√† nei dati osservati. Pertanto, l‚Äôincertezza nelle predizioni √® maggiore perch√© tiene conto di tutte le fonti di variabilit√†.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>58</span>¬† <span class='chapter-title'>Predizione e inferenza üî∏</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_prediction_stan.html#posterior-predictive-check",
    "href": "chapters/linear_models/06_prediction_stan.html#posterior-predictive-check",
    "title": "58¬† Predizione e inferenza üî∏",
    "section": "58.4 Posterior-predictive check",
    "text": "58.4 Posterior-predictive check\nIl Posterior Predictive Check (PPC) √® un passaggio cruciale nella modellazione bayesiana, che ci permette di valutare quanto bene il modello si adatta ai dati osservati, tenendo conto delle informazioni aggiornate dai dati stessi. L‚Äôidea alla base del PPC √® confrontare le predizioni del modello, basate sulla distribuzione a posteriori dei parametri, con i dati reali, per vedere se il modello riesce a catturare correttamente le caratteristiche dei dati osservati.\n\nDopo aver adattato il modello ai dati, otteniamo campioni dai parametri a posteriori (\\(\\alpha\\), \\(\\beta\\), \\(\\sigma\\)). Questi campioni riflettono le nostre credenze aggiornate sui parametri, basate sia sulle distribuzioni a priori che sui dati osservati.\nUtilizzando i campioni della distribuzione a posteriori, simuliamo nuovi dati predetti (\\(y_{rep}\\)). Questi dati simulati rappresentano le previsioni del modello, date le nostre stime a posteriori dei parametri.\nConfrontiamo le osservazioni simulate (\\(y_{rep}\\)) con i dati osservati reali (\\(y\\)). Il PPC plot ci permette di vedere se il modello, con i parametri aggiornati, √® in grado di riprodurre correttamente i dati osservati.\n\nPer creare il PPC plot, usiamo ArviZ. Creiamo un oggetto InferenceData che contiene sia le predizioni a posteriori che i dati osservati, organizzati nel formato richiesto da ArviZ.\n\n# Estrai i campioni y_rep\ny_rep &lt;- fit3$draws(\"y_rep\", format = \"matrix\")\n\n# Crea il plot di controllo posteriore predittivo\nppc_plot &lt;- ppc_dens_overlay(stan_data$y, y_rep[1:100, ])\nprint(ppc_plot)\n\n\n\n\n\n\n\n\nIl Posterior Predictive Check √® uno strumento potente per verificare la validit√† del modello dopo l‚Äôanalisi, assicurando che le predizioni del modello siano realistiche e che riflettano accuratamente le osservazioni effettive.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>58</span>¬† <span class='chapter-title'>Predizione e inferenza üî∏</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_prediction_stan.html#riflessioni-conclusive",
    "href": "chapters/linear_models/06_prediction_stan.html#riflessioni-conclusive",
    "title": "58¬† Predizione e inferenza üî∏",
    "section": "58.5 Riflessioni Conclusive",
    "text": "58.5 Riflessioni Conclusive\nIn questo capitolo, abbiamo approfondito i temi della predizione bayesiana nel contesto del modello di regressione bivariato, evidenziando l‚Äôimportanza delle verifiche predittive a priori e a posteriori per la valutazione e la validazione del modello.\nAbbiamo visto come il Prior Predictive Check sia essenziale per verificare che le distribuzioni a priori siano appropriate per il modello e i dati del campione. Questo passaggio consente di esaminare se le ipotesi iniziali sono coerenti con la conoscenza preesistente e con i risultati attesi. Un‚Äôadeguata verifica predittiva a priori aiuta a prevenire l‚Äôadozione di distribuzioni a priori che possano portare a previsioni irrealistiche o fuorvianti. Se le predizioni basate sulle distribuzioni a priori risultano incompatibili con ci√≤ che ci si aspetta dai dati, √® un segnale che le distribuzioni a priori devono essere riviste.\nSuccessivamente, abbiamo esaminato il Posterior Predictive Check come strumento per valutare la capacit√† del modello di adattarsi ai dati osservati. Dopo aver integrato le informazioni dei dati con le distribuzioni a priori, il posterior predictive check permette di confrontare le predizioni del modello con i dati effettivamente osservati. Se il modello √® adeguato, le sue predizioni dovrebbero essere in linea con i dati reali. Tuttavia, se emerge una discrepanza sostanziale tra le predizioni e i dati osservati, questo √® un chiaro segnale che il modello potrebbe non essere appropriato per il fenomeno in esame e potrebbe richiedere una revisione. Tale revisione pu√≤ comportare la modifica delle assunzioni di base, l‚Äôinclusione di nuovi predittori, o l‚Äôadozione di un modello completamente diverso.\nIn conclusione, l‚Äôapproccio bayesiano alla predizione e alla verifica dei modelli offre un framework robusto e flessibile per l‚Äôanalisi statistica. I prior e posterior predictive checks non sono semplici passaggi tecnici, ma costituiscono una parte integrante del processo di modellizzazione, assicurando che il modello non solo sia ben adattato ai dati, ma anche che le sue assunzioni siano giustificate e realistiche. L‚Äôutilizzo di questi strumenti permette di costruire modelli che siano coerenti con la realt√† che intendono rappresentare.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>58</span>¬† <span class='chapter-title'>Predizione e inferenza üî∏</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_prediction_stan.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/06_prediction_stan.html#informazioni-sullambiente-di-sviluppo",
    "title": "58¬† Predizione e inferenza üî∏",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: US/Pacific\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] posterior_1.6.0.9000 cmdstanr_0.8.1       ggokabeito_0.1.0    \n#&gt;  [4] see_0.9.0            gridExtra_2.3        patchwork_1.3.0     \n#&gt;  [7] bayesplot_1.11.1     psych_2.4.12         scales_1.3.0        \n#&gt; [10] markdown_1.13        knitr_1.49           lubridate_1.9.4     \n#&gt; [13] forcats_1.0.0        stringr_1.5.1        dplyr_1.1.4         \n#&gt; [16] purrr_1.0.2          readr_2.1.5          tidyr_1.3.1         \n#&gt; [19] tibble_3.2.1         ggplot2_3.5.1        tidyverse_2.0.0     \n#&gt; [22] rio_1.2.3            here_1.0.1          \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6         tensorA_0.36.2.1     xfun_0.50           \n#&gt;  [4] htmlwidgets_1.6.4    processx_3.8.5       lattice_0.22-6      \n#&gt;  [7] tzdb_0.4.0           vctrs_0.6.5          tools_4.4.2         \n#&gt; [10] ps_1.8.1             generics_0.1.3       parallel_4.4.2      \n#&gt; [13] pacman_0.5.1         pkgconfig_2.0.3      R.oo_1.27.0         \n#&gt; [16] data.table_1.16.4    checkmate_2.3.2      distributional_0.5.0\n#&gt; [19] lifecycle_1.0.4      compiler_4.4.2       farver_2.1.2        \n#&gt; [22] munsell_0.5.1        mnormt_2.1.1         htmltools_0.5.8.1   \n#&gt; [25] yaml_2.3.10          pillar_1.10.1        R.utils_2.12.3      \n#&gt; [28] abind_1.4-8          nlme_3.1-166         tidyselect_1.2.1    \n#&gt; [31] digest_0.6.37        stringi_1.8.4        reshape2_1.4.4      \n#&gt; [34] labeling_0.4.3       rprojroot_2.0.4      fastmap_1.2.0       \n#&gt; [37] grid_4.4.2           colorspace_2.1-1     cli_3.6.3           \n#&gt; [40] magrittr_2.0.3       utf8_1.2.4           withr_3.0.2         \n#&gt; [43] backports_1.5.0      timechange_0.3.0     rmarkdown_2.29      \n#&gt; [46] matrixStats_1.5.0    R.methodsS3_1.8.2    hms_1.1.3           \n#&gt; [49] evaluate_1.0.1       rlang_1.1.4          Rcpp_1.0.13-1       \n#&gt; [52] glue_1.8.0           jsonlite_1.8.9       plyr_1.8.9          \n#&gt; [55] R6_2.5.1",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>58</span>¬† <span class='chapter-title'>Predizione e inferenza üî∏</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_prediction_stan.html#bibliografia",
    "href": "chapters/linear_models/06_prediction_stan.html#bibliografia",
    "title": "58¬† Predizione e inferenza üî∏",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other stories. Cambridge University Press.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>58</span>¬† <span class='chapter-title'>Predizione e inferenza üî∏</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html",
    "href": "chapters/linear_models/07_two_means.html",
    "title": "59¬† Confronto tra le medie di due gruppi",
    "section": "",
    "text": "59.1 Introduzione\nSpesso, ci troviamo ad affrontare la necessit√† di confrontare due gruppi di dati. Potrebbe interessarci sapere se la media di un gruppo √® maggiore o diversa rispetto a quella di un altro gruppo. Per effettuare tale confronto, √® fondamentale utilizzare un modello statistico, poich√© le vere differenze tra i gruppi sono spesso accompagnate da rumore di misurazione o fluttuazioni casuali del fenomeno in esame. Questo rende difficile trarre conclusioni basandosi unicamente sulle differenze calcolate dai dati osservati.\nIl metodo tradizionale per confrontare statisticamente due o pi√π gruppi √® quello di utilizzare un test di ipotesi statistico. Questo approccio prevede l‚Äôindividuazione di un‚Äôipotesi nulla, che solitamente afferma che non ci sono differenze tra i gruppi, e l‚Äôutilizzo di una statistica test per determinare se i dati osservati sono plausibili sotto questa ipotesi. L‚Äôipotesi nulla viene rifiutata quando la statistica test calcolata supera una soglia predefinita.\nTuttavia, i test di ipotesi possono essere complessi e i risultati spesso soggetti a interpretazioni errate. La scelta delle specifiche del test statistico (ad esempio, quale test utilizzare, quale ipotesi nulla testare, quale livello di significativit√† adottare) √® spesso arbitraria e basata su convenzioni piuttosto che sulla specificit√† del problema o delle decisioni da prendere (Johnson, 1999). Inoltre, i risultati forniti dai test sono spesso indiretti, incompleti e tendono a sovrastimare le evidenze contro l‚Äôipotesi nulla (Goodman, 1999).\nUn approccio pi√π informativo ed efficace per il confronto tra gruppi √® quello basato sulla stima invece che sul test dell‚Äôipotesi nulla, ed √® guidato dalla probabilit√† bayesiana anzich√© dalla frequentista. In pratica, invece di testare se ci sono differenze tra i gruppi, si cerca di ottenere una stima di quanto siano effettivamente diversi. Questo approccio √® intrinsecamente pi√π informativo. Inoltre, viene inclusa una stima dell‚Äôincertezza associata a tale differenza, che tiene conto sia dell‚Äôincertezza dovuta alla nostra mancanza di conoscenza dei parametri del modello (incertezza epistemica) sia dell‚Äôincertezza causata dalla variabilit√† intrinseca del sistema (incertezza aleatoria).\nPer affrontare tale problema possiamo usare un modello di regressione. In questo caso, anzich√© calcolare direttamente la differenza tra le medie, si introduce una variabile indicatrice (o ‚Äúdummy‚Äù) \\(D\\) nel modello di regressione, come segue:\n\\[\ny_i = \\alpha + \\gamma D_i + \\varepsilon_i.\n\\]\nLa variabile indicatrice \\(D\\) specifica l‚Äôappartenenza ai gruppi attraverso valori binari: 0 per il gruppo di riferimento e 1 per il gruppo di confronto, definita come:\n\\[\nD_i =\n\\begin{cases}\n0 & \\text{se l'osservazione } i \\text{ appartiene al gruppo 0,} \\\\\n1 & \\text{se l'osservazione } i \\text{ appartiene al gruppo 1.}\n\\end{cases}\n\\]\nEntrambi i metodi sono appropriati per studiare la differenza tra le medie di due gruppi indipendenti. Tuttavia, il modello di regressione offre maggiore flessibilit√† e possibilit√† di estensione. Questa metodologia consente di includere ulteriori variabili esplicative, migliorando la comprensione dei fattori che influenzano l‚Äôesito di interesse. Tale flessibilit√† diventa particolarmente utile per esplorare come altre variabili incidano sulla differenza tra le medie o per analizzare contemporaneamente pi√π variabili.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>59</span>¬† <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#regressione-bayesiana-per-due-gruppi-indipendenti",
    "href": "chapters/linear_models/07_two_means.html#regressione-bayesiana-per-due-gruppi-indipendenti",
    "title": "59¬† Confronto tra le medie di due gruppi",
    "section": "59.2 Regressione bayesiana per due gruppi indipendenti",
    "text": "59.2 Regressione bayesiana per due gruppi indipendenti\nIn un approccio bayesiano, il modello di regressione pu√≤ essere espresso come:\n\\[\n\\begin{align*}\ny_i & \\sim \\mathcal{N}(\\mu_i, \\sigma), \\\\\n\\mu_i & = \\alpha + \\gamma D_i.\n\\end{align*}\n\\]\nIn questo modello:\n\n\\(\\alpha\\) rappresenta l‚Äôintercetta, corrispondente alla media del gruppo con \\(D = 0\\) (gruppo di riferimento),\n\\(\\gamma\\) quantifica la differenza attesa tra le medie dei due gruppi,\n\\(\\sigma\\) rappresenta la deviazione standard associata agli errori casuali.\n\nPer il gruppo di riferimento (\\(D = 0\\)), il modello si riduce a:\n\\[\n\\begin{align*}\ny_i & \\sim \\mathcal{N}(\\mu_i, \\sigma), \\\\\n\\mu_i & = \\alpha.\n\\end{align*}\n\\]\nIn questo caso, \\(\\alpha\\) rappresenta direttamente la media del gruppo 0.\nPer il gruppo di confronto (\\(D = 1\\)), il modello diventa:\n\\[\n\\begin{align*}\ny_i & \\sim \\mathcal{N}(\\mu_i, \\sigma), \\\\\n\\mu_i & = \\alpha + \\gamma.\n\\end{align*}\n\\]\nQui, \\(\\alpha + \\gamma\\) rappresenta la media del gruppo 1, mentre \\(\\gamma\\) riflette la differenza tra la media del gruppo 1 e quella del gruppo 0.\nDi conseguenza, l‚Äôanalisi della differenza tra le medie dei due gruppi si traduce nell‚Äôinferenza sul parametro \\(\\gamma\\). In un contesto bayesiano, ci√≤ comporta l‚Äôesame della distribuzione a posteriori di \\(\\gamma\\), che consente di effettuare confronti diretti e di valutare l‚Äôincertezza associata alla stima di tale differenza.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>59</span>¬† <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#un-esempio-illustrativo",
    "href": "chapters/linear_models/07_two_means.html#un-esempio-illustrativo",
    "title": "59¬† Confronto tra le medie di due gruppi",
    "section": "59.3 Un esempio illustrativo",
    "text": "59.3 Un esempio illustrativo\nConsideriamo il dataset relativo al quoziente di intelligenza (QI) di un campione di bambini, distinguendo tra quelli le cui madri hanno completato la scuola superiore e quelli le cui madri non l‚Äôhanno completata. Vediamo come implementare l‚Äôanalisi descritta sopra passo per passo.\n\n59.3.1 Esplorazione iniziale dei dati\nCarichiamo i dati e osserviamo una sintesi delle prime righe per capire la struttura del dataset:\n\nkidiq &lt;- rio::import(here::here(\"data\", \"kidiq.dta\"))\nkidiq |&gt; \n  head()\n#&gt;   kid_score mom_hs mom_iq mom_work mom_age\n#&gt; 1        65      1  121.1        4      27\n#&gt; 2        98      1   89.4        4      25\n#&gt; 3        85      1  115.4        4      27\n#&gt; 4        83      1   99.4        3      25\n#&gt; 5       115      1   92.7        4      27\n#&gt; 6        98      0  107.9        1      18\n\nSuccessivamente, analizziamo la distribuzione dei bambini nei due gruppi, in base all‚Äôeducazione delle madri:\n\nkidiq |&gt; \n  group_by(mom_hs) |&gt; \n  summarize(\n    n = n()\n)\n#&gt; # A tibble: 2 √ó 2\n#&gt;   mom_hs     n\n#&gt;    &lt;dbl&gt; &lt;int&gt;\n#&gt; 1      0    93\n#&gt; 2      1   341\n\nI risultati mostrano che:\n\n93 bambini hanno madri che non hanno completato la scuola superiore.\n341 bambini hanno madri diplomate.\n\nCalcoliamo le medie e le deviazioni standard del QI dei bambini per ciascun gruppo:\n\nsummary_stats &lt;- kidiq %&gt;%\n  group_by(mom_hs) %&gt;%\n  summarise(\n    mean_kid_score = mean(kid_score, na.rm = TRUE),\n    sd_kid_score = sd(kid_score, na.rm = TRUE)\n  )\nsummary_stats\n#&gt; # A tibble: 2 √ó 3\n#&gt;   mom_hs mean_kid_score sd_kid_score\n#&gt;    &lt;dbl&gt;          &lt;dbl&gt;        &lt;dbl&gt;\n#&gt; 1      0           77.5         22.6\n#&gt; 2      1           89.3         19.0\n\nLa differenza tra le medie pu√≤ essere calcolata direttamente come:\n\nmean(kidiq[kidiq$mom_hs == 1, ]$kid_score) - \n  mean(kidiq[kidiq$mom_hs == 0, ]$kid_score)\n#&gt; [1] 11.8\n\nQuesta analisi preliminare evidenzia la differenza media tra i gruppi.\nPer comprendere meglio la distribuzione dei dati, utilizziamo un violin plot, che mostra la densit√† stimata dei punteggi del QI nei due gruppi:\n\nggplot(kidiq, aes(x = as.factor(mom_hs), y = kid_score)) +\n  geom_violin(trim = FALSE) + \n  labs(\n    x = \"Livello di istruzione della madre\",\n    y = \"QI del bambino\",\n    title = \"Distribuzione dei punteggi QI in base all'istruzione materna\"\n  ) +\n  scale_x_discrete(labels = c(\"0\" = \"Non diplomata\", \"1\" = \"Diplomata\"))",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>59</span>¬† <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#modello-di-regressione-bayesiana",
    "href": "chapters/linear_models/07_two_means.html#modello-di-regressione-bayesiana",
    "title": "59¬† Confronto tra le medie di due gruppi",
    "section": "59.4 Modello di regressione bayesiana",
    "text": "59.4 Modello di regressione bayesiana\nUtilizziamo il pacchetto bambi per costruire un modello di regressione bayesiano, che esprime il punteggio del QI come funzione della variabile indicatrice mom_hs (0 = non diplomata, 1 = diplomata). La sintassi √® semplice e le distribuzioni a priori sono selezionate automaticamente.\nDefiniamo e stimiamo il modello:\n\nfit_1 &lt;- brm(\n  kid_score ~ mom_hs, \n  backend = \"cmdstanr\", \n  silent = 0,\n  data = kidiq\n)\n\n\n59.4.1 Analisi dei risultati\n\n59.4.1.1 Riassunto dei parametri del modello\nIspezioniamo i parametri posteriori principali del modello:\n\ndraws &lt;- posterior::as_draws(fit_1, variable = \"^b_\", regex = TRUE)\nposterior::summarise_draws(draws, \"mean\", \"sd\", \"mcse_mean\", \"mcse_sd\")\n#&gt; # A tibble: 2 √ó 5\n#&gt;   variable     mean    sd mcse_mean mcse_sd\n#&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 b_Intercept  77.6  2.04    0.0299  0.0304\n#&gt; 2 b_mom_hs     11.8  2.31    0.0349  0.0344\n\n\n\n59.4.1.2 Intervallo di credibilit√†\nCalcoliamo l‚Äôintervallo di credibilit√† a densit√† massima (HDI) per il parametro associato a mom_hs, utilizzando un livello di credibilit√† del 89%:\n\nbayestestR::hdi(fit_1, parameters = \"mom_hs\", ci = 0.89)\n#&gt; Highest Density Interval\n#&gt; \n#&gt; Parameter |       89% HDI\n#&gt; -------------------------\n#&gt; mom_hs    | [8.36, 15.66]\n\n\n\n59.4.1.3 Verifica del modello\nEffettuiamo un controllo grafico per confrontare i dati osservati con quelli predetti dal modello:\n\npp_check(fit_1)\n#&gt; Using 10 posterior draws for ppc type 'dens_overlay' by default.\n\n\n\n\n\n\n\n\n\n\n59.4.1.4 R¬≤ bayesiano\nInfine, calcoliamo il coefficiente di determinazione (Bayesiano \\(R^2\\)) per valutare la capacit√† del modello di spiegare la variabilit√† nei dati:\n\nbayes_R2(fit_1)\n#&gt;    Estimate Est.Error   Q2.5 Q97.5\n#&gt; R2   0.0577    0.0206 0.0218 0.101\n\nQuesto esempio dimostra come l‚Äôanalisi di regressione bayesiana consenta di replicare e approfondire i risultati ottenuti in precedenza. Il modello non solo stima la differenza tra i gruppi, ma offre anche un quadro completo dell‚Äôincertezza associata, evidenziando la flessibilit√† e la potenza di questo approccio.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>59</span>¬† <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#una-parametrizzazione-alternativa",
    "href": "chapters/linear_models/07_two_means.html#una-parametrizzazione-alternativa",
    "title": "59¬† Confronto tra le medie di due gruppi",
    "section": "59.5 Una Parametrizzazione Alternativa",
    "text": "59.5 Una Parametrizzazione Alternativa\nPoich√© il posterior predictive check (pp-check) ha evidenziato una leggera discrepanza tra i valori osservati (\\(y\\)) e quelli predetti dal modello, consideriamo una parametrizzazione alternativa. Adottiamo un modello gaussiano esteso con un parametro aggiuntivo per modellare l‚Äôasimmetria nella distribuzione, utilizzando una famiglia di distribuzioni skew-normal.\nEcco come definiamo e stimiamo il nuovo modello:\n\nfit_2 &lt;- brm(\n  kid_score ~ mom_hs, \n  family = skew_normal(),\n  backend = \"cmdstanr\", \n  silent = 0,\n  data = kidiq\n)\n\n\n59.5.1 Verifica del modello\nDopo aver stimato il modello, eseguiamo nuovamente il pp-check per confrontare i dati osservati con quelli predetti:\n\npp_check(fit_2)\n#&gt; Using 10 posterior draws for ppc type 'dens_overlay' by default.\n\n\n\n\n\n\n\n\nI risultati mostrano un miglioramento nell‚Äôadattamento del modello, indicando che l‚Äôaggiunta del parametro per l‚Äôasimmetria ha contribuito a ridurre le discrepanze.\n\n\n59.5.2 Valutazione delle stime\nAnalizziamo le stime posteriori dei parametri per verificare eventuali variazioni rispetto al modello precedente:\n\ndraws &lt;- posterior::as_draws(fit_2, variable = \"^b_\", regex = TRUE)\nposterior::summarise_draws(draws, \"mean\", \"sd\", \"mcse_mean\", \"mcse_sd\")\n#&gt; # A tibble: 2 √ó 5\n#&gt;   variable     mean    sd mcse_mean mcse_sd\n#&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 b_Intercept 79.2   1.99    0.0325  0.0290\n#&gt; 2 b_mom_hs     9.65  2.24    0.0361  0.0321\n\n\n\n59.5.3 Intervallo di credibilit√†\nCalcoliamo l‚Äôintervallo di credibilit√† a densit√† massima (HDI) per il parametro associato a mom_hs:\n\nbayestestR::hdi(fit_2, parameters = \"mom_hs\", ci = 0.89)\n#&gt; Highest Density Interval\n#&gt; \n#&gt; Parameter |       89% HDI\n#&gt; -------------------------\n#&gt; mom_hs    | [6.10, 13.27]\n\n\n\n59.5.4 Valutazione della variabilit√† spiegata\nInfine, calcoliamo il coefficiente di determinazione Bayesiano (\\(R^2\\)) per quantificare la capacit√† del modello di spiegare la variabilit√† nei dati:\n\nbayes_R2(fit_2)\n#&gt;    Estimate Est.Error   Q2.5  Q97.5\n#&gt; R2     0.04    0.0171 0.0114 0.0769\n\nIn conclusioni, il modello con distribuzione skew-normal offre un adattamento migliore rispetto al modello gaussiano standard, come evidenziato dal pp-check. Tuttavia, le stime posteriori dei parametri differiscono solo marginalmente rispetto al modello precedente. Questo suggerisce che, sebbene l‚Äôaggiunta dell‚Äôasimmetria migliori l‚Äôadattamento, l‚Äôeffetto sulla stima della relazione tra kid_score e mom_hs √® limitato.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>59</span>¬† <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#prior-predictive-checks",
    "href": "chapters/linear_models/07_two_means.html#prior-predictive-checks",
    "title": "59¬† Confronto tra le medie di due gruppi",
    "section": "59.6 Prior Predictive Checks",
    "text": "59.6 Prior Predictive Checks\nIl punto di partenza per valutare le prestazioni predittive dei priori consiste nell‚Äôeffettuare controlli predittivi grafici sui priori. In brms, questi controlli possono essere eseguiti in modo quasi identico ai posterior predictive checks. Basta indicare a brms di ignorare i dati durante il campionamento, concentrandosi unicamente sui priori. Per fare ci√≤, √® fondamentale che tutti i parametri abbiano priori propri e, idealmente, non eccessivamente ampi o poco plausibili.\nPartiamo specificando priori debolmente informativi per il nostro modello gaussiano applicato ai dati kidiq. Esaminiamo prima i priori predefiniti da brms:\n\nget_prior(kid_score ~ mom_hs, data = kidiq)\n#&gt;                   prior     class   coef group resp dpar nlpar lb ub\n#&gt;  student_t(3, 90, 19.3) Intercept                                   \n#&gt;                  (flat)         b                                   \n#&gt;                  (flat)         b mom_hs                            \n#&gt;   student_t(3, 0, 19.3)     sigma                               0   \n#&gt;        source\n#&gt;       default\n#&gt;       default\n#&gt;  (vectorized)\n#&gt;       default\n\n\n59.6.1 Specifica dei Priori\nModifichiamo i priori predefiniti per utilizzare prior debolmente informativi personalizzati:\n\nprior_gaussian &lt;- \n  prior(normal(90, 20), class = \"b\", coef = \"Intercept\") +\n  prior(normal(0, 15), class = \"b\", coef = \"mom_hs\") +\n  prior(cauchy(0, 20), class = \"sigma\")\n\n\n\n59.6.2 Aggiunta dei Priori al Modello\nAggiungiamo i priori definiti alla funzione brm:\n\nfit_3 &lt;- brm(\n  bf(kid_score ~ 1 + mom_hs, center = FALSE), \n  kid_score ~ mom_hs, \n  prior = prior_gaussian,\n  family = gaussian(),\n  backend = \"cmdstanr\", \n  silent = 0,\n  data = kidiq\n)\n\nLe stime a posteriori per i parametri \\(\\alpha\\) e \\(\\beta\\) corrispondono ai valori ottenuti in precedenza:\n\ndraws &lt;- posterior::as_draws(fit_3, variable = \"^b_\", regex = TRUE)\nposterior::summarise_draws(draws, \"mean\", \"sd\", \"mcse_mean\", \"mcse_sd\")\n#&gt; # A tibble: 2 √ó 5\n#&gt;   variable     mean    sd mcse_mean mcse_sd\n#&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 b_Intercept  78.0  2.05    0.0534  0.0414\n#&gt; 2 b_mom_hs     11.2  2.29    0.0593  0.0469\n\n\n\n59.6.3 Esame della Distribuzione Predittiva a Priori\nPer generare campioni unicamente dalla distribuzione dei priori, specifichiamo l‚Äôargomento sample_prior = \"only\":\n\nfit_4 &lt;- brm(\n  bf(kid_score ~ 1 + mom_hs, center = FALSE), \n  kid_score ~ mom_hs, \n  prior = prior_gaussian,\n  family = gaussian(),\n  backend = \"cmdstanr\", \n  silent = 0,\n  data = kidiq,\n  sample_prior = \"only\"\n)\n\nQuando analizziamo il sommario del modello, osserviamo che i valori stimati dai ‚Äúposteriori‚Äù riflettono effettivamente i priori:\n\nsummary(fit_4)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: kid_score ~ 1 + mom_hs \n#&gt;          autocor ~ tructure(list(), class = \"formula\", .Environment = &lt;environment&gt;)\n#&gt;    Data: kidiq (Number of observations: 434) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept    89.89     20.01    50.65   128.40 1.00     3689     2858\n#&gt; mom_hs       -0.04     14.73   -27.63    28.42 1.00     3613     2922\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma   240.42   4297.30     0.66   578.48 1.00     3095     2039\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nPossiamo utilizzare pp_check per visualizzare i prior predictive checks:\n\npp_check(fit_4, ndraws = 100) + xlim(10, 180)\n#&gt; Warning: Removed 5225 rows containing non-finite outside the scale range\n#&gt; (`stat_density()`).\n\n\n\n\n\n\n\n\nLa distribuzione predittiva a priori risulta pi√π ampia rispetto alla distribuzione dei dati osservati, ma rimane comunque dello stesso ordine di grandezza. Questo √® esattamente ci√≤ che ci aspettiamo: i priori dovrebbero essere abbastanza ampi da consentire flessibilit√†, ma non cos√¨ eccessivi da risultare irrealistici. Sebbene questo controllo non garantisca con certezza che tutti i priori siano ragionevoli, √® utile per identificare priori potenzialmente troppo ampi o poco informativi.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>59</span>¬† <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#massima-verosimiglianza",
    "href": "chapters/linear_models/07_two_means.html#massima-verosimiglianza",
    "title": "59¬† Confronto tra le medie di due gruppi",
    "section": "59.7 Massima Verosimiglianza",
    "text": "59.7 Massima Verosimiglianza\nIn questa sezione confrontiamo diverse metodologie per stimare e testare la differenza tra due gruppi, adottando un approccio basato sulla massima verosimiglianza e confrontandolo sia con il test \\(t\\) di Student che con l‚Äôapproccio bayesiano.\n\n59.7.1 Modello di Regressione\nUtilizziamo un modello lineare per stimare la differenza tra i due gruppi nel dataset kidiq, in cui il punteggio di QI del bambino (kid_score) √® predetto dall‚Äôistruzione della madre (mom_hs):\n\nfm &lt;- lm(kid_score ~ mom_hs, data = kidiq)\nsummary(fm)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = kid_score ~ mom_hs, data = kidiq)\n#&gt; \n#&gt; Residuals:\n#&gt;    Min     1Q Median     3Q    Max \n#&gt; -57.55 -13.32   2.68  14.68  58.45 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)\n#&gt; (Intercept)    77.55       2.06   37.67   &lt;2e-16\n#&gt; mom_hs         11.77       2.32    5.07    6e-07\n#&gt; \n#&gt; Residual standard error: 19.9 on 432 degrees of freedom\n#&gt; Multiple R-squared:  0.0561, Adjusted R-squared:  0.0539 \n#&gt; F-statistic: 25.7 on 1 and 432 DF,  p-value: 5.96e-07\n\nIl modello calcola i parametri utilizzando la massimizzazione della funzione di verosimiglianza. I coefficienti stimati hanno la seguente interpretazione:\n\nIntercetta: rappresenta la media del punteggio QI per i bambini con madri non diplomate (mom_hs = 0).\nCoefficiente di mom_hs: rappresenta la differenza attesa nel punteggio medio di QI tra i bambini con madri diplomate (mom_hs = 1) e quelli con madri non diplomate.\n\n\n\n59.7.2 Test \\(t\\) di Student\nUn altro approccio frequente per confrontare due gruppi indipendenti √® il test \\(t\\) di Student. Questo test verifica l‚Äôipotesi nulla che le medie delle due popolazioni siano uguali:\n\nt.test(kid_score ~ mom_hs, data = kidiq)\n#&gt; \n#&gt;  Welch Two Sample t-test\n#&gt; \n#&gt; data:  kid_score by mom_hs\n#&gt; t = -5, df = 130, p-value = 1e-05\n#&gt; alternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  -16.83  -6.71\n#&gt; sample estimates:\n#&gt; mean in group 0 mean in group 1 \n#&gt;            77.5            89.3\n\nI risultati del test includono:\n\nStatistica t: quantifica la differenza standardizzata tra le medie dei gruppi.\np-value: la probabilit√† di osservare una differenza almeno cos√¨ estrema se l‚Äôipotesi nulla fosse vera.\nIntervallo di fiducia frequentista: l‚Äôintervallo in cui √® plausibile trovare la differenza media vera tra i gruppi.\n\n\n\n59.7.3 Equivalenza tra Modello di Regressione e Test \\(t\\)\nIl test \\(t\\) di Student √® matematicamente equivalente al test frequentista sull‚Äôipotesi che il coefficiente di regressione associato a mom_hs sia pari a zero. Entrambi assumono che i dati siano gaussiani e che le varianze dei gruppi siano uguali (o usano un‚Äôadeguata correzione in caso di varianze non uguali).\nNel caso del modello lineare, la stima puntuale della differenza tra i gruppi e l‚Äôintervallo di fiducia coincidono con quelli del test \\(t\\). Questo dimostra come il test \\(t\\) possa essere considerato una formulazione specifica del modello lineare per due gruppi.\n\n\n59.7.4 Confronto con l‚ÄôApproccio Bayesiano\nNell‚Äôapproccio bayesiano, abbiamo calcolato la differenza tra i due gruppi utilizzando priori debolmente informativi e stimando una distribuzione a posteriori per il parametro di interesse:\n\nfit_1 &lt;- brm(\n  kid_score ~ mom_hs, \n  data = kidiq,\n  backend = \"cmdstanr\"\n)\n\nI risultati del modello bayesiano sono:\n\nSimili ai metodi frequentisti quando i priori sono debolmente informativi e il campione √® grande.\nPi√π informativi, in quanto forniscono una distribuzione a posteriori per la differenza tra i gruppi, invece di limitarsi a un valore puntuale e un intervallo di fiducia (per un approfondimento, si veda Kruschke, 2013).\n\n\n\n59.7.5 Differenze Chiave tra i Metodi\n\nTest \\(t\\) di Student:\n\nOffre una statistica test e un intervallo di fiducia frequentista.\n√à rapido e semplice da calcolare per due gruppi indipendenti.\nNon consente di incorporare informazioni a priori.\n\nModello di Regressione:\n\nFornisce una maggiore flessibilit√†, permettendo di includere ulteriori predittori e interazioni.\n√à matematicamente equivalente al test \\(t\\) per due gruppi indipendenti.\n\nApproccio Bayesiano:\n\nConsente di combinare i dati osservati con informazioni a priori.\nProduce una distribuzione a posteriori che pu√≤ essere utilizzata per testare ipotesi e calcolare probabilit√†.\n√à particolarmente utile con campioni piccoli o quando si vuole includere conoscenze pregresse.\n\n\nIn conclusioni, sebbene il test \\(t\\) e il modello di regressione basato sulla massima verosimiglianza producano risultati identici per due gruppi, l‚Äôapproccio bayesiano si distingue per la sua flessibilit√† e capacit√† di incorporare informazioni a priori. In questo caso, utilizzando dei prior debolmente informativi, i risultati di tutti e tre i metodi sono coerenti, evidenziando che la differenza tra i due gruppi pu√≤ essere stimata in modo robusto con ciascun approccio.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>59</span>¬† <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#test-di-ipotesi-bayesiano",
    "href": "chapters/linear_models/07_two_means.html#test-di-ipotesi-bayesiano",
    "title": "59¬† Confronto tra le medie di due gruppi",
    "section": "59.8 Test di Ipotesi Bayesiano",
    "text": "59.8 Test di Ipotesi Bayesiano\nNel contesto bayesiano, il test di ipotesi non si basa sul rifiuto o accettazione di un‚Äôipotesi nulla come avviene nei test frequentisti. Invece, si calcolano le probabilit√† a posteriori associate a specifiche ipotesi, fornendo un quadro pi√π intuitivo e flessibile.\nUn test bayesiano di ipotesi consiste nel determinare la probabilit√† che un parametro, come \\(\\beta_{mean\\_diff}\\) (la differenza tra le medie dei due gruppi), sia maggiore di un valore specifico \\(\\mu_0\\). Qui, \\(\\mu_0\\) rappresenta un valore arbitrario scelto in base all‚Äôipotesi che desideriamo testare.\nAd esempio, possiamo calcolare la probabilit√† che la differenza tra i due gruppi sia maggiore di 10. Questo si traduce matematicamente nella probabilit√† a posteriori:\n\\[\nP(\\beta_{mean\\_diff} &gt; 10 \\mid \\text{dati}).\n\\]\nCon il pacchetto brms, tale calcolo √® molto semplice grazie alla funzione hypothesis():\n\nhypothesis(fit_1, \"mom_hs &gt; 10\")\n#&gt; Hypothesis Tests for class b:\n#&gt;          Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio\n#&gt; 1 (mom_hs)-(10) &gt; 0     1.73      2.41    -2.31     5.61       3.26\n#&gt;   Post.Prob Star\n#&gt; 1      0.77     \n#&gt; ---\n#&gt; 'CI': 90%-CI for one-sided and 95%-CI for two-sided hypotheses.\n#&gt; '*': For one-sided hypotheses, the posterior probability exceeds 95%;\n#&gt; for two-sided hypotheses, the value tested against lies outside the 95%-CI.\n#&gt; Posterior probabilities of point hypotheses assume equal prior probabilities.\n\nL‚Äôoutput della funzione hypothesis() fornisce diverse informazioni utili:\n\nProbabilit√† a posteriori: La probabilit√† che \\(\\beta_{mean\\_diff}\\) sia maggiore di 10, calcolata sulla base della distribuzione a posteriori stimata dal modello.\nIntervallo di Credibilit√†: Un intervallo intorno al valore stimato di \\(\\beta_{mean\\_diff}\\) che contiene una percentuale specificata di probabilit√† (es. 89% di default).\nBayes Factor (opzionale): In alcuni casi, viene calcolato un Bayes Factor per confrontare la plausibilit√† dell‚Äôipotesi testata con la sua negazione (es. \\(P(\\beta_{mean\\_diff} &gt; 10)\\) contro \\(P(\\beta_{mean\\_diff} \\leq 10)\\)).\n\n\n59.8.1 Vantaggi del Test Bayesiano\n\nInformazione Diretta: Fornisce una probabilit√† interpretabile, come ‚Äúc‚Äô√® una probabilit√† del 95% che la differenza tra i due gruppi sia maggiore di 10‚Äù.\nFlessibilit√†: Permette di testare qualsiasi valore ipotizzato per \\(\\mu_0\\), senza vincoli legati all‚Äôipotesi nulla.\nNessun Valore Critico Arbitrario: Non richiede una soglia convenzionale (es. \\(p &lt; 0.05\\)) per giudicare i risultati.\n\n\n\n59.8.2 Confronto con i Test Frequentisti\nNel test frequentista, il risultato sarebbe espresso come un \\(p\\)-value che indica la probabilit√† di ottenere dati cos√¨ estremi (o pi√π) sotto l‚Äôipotesi nulla \\(\\beta_{mean\\_diff} \\leq \\mu_0\\). Tuttavia, il \\(p\\)-value non quantifica direttamente la probabilit√† che l‚Äôipotesi alternativa sia vera, a differenza dell‚Äôapproccio bayesiano.\nIn conclusioni, il test di ipotesi bayesiano, come mostrato in questo esempio, rappresenta un approccio intuitivo e informativo per valutare ipotesi sui parametri di un modello, superando alcune delle limitazioni concettuali dei test frequentisti.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>59</span>¬† <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#riflessioni-conclusive",
    "href": "chapters/linear_models/07_two_means.html#riflessioni-conclusive",
    "title": "59¬† Confronto tra le medie di due gruppi",
    "section": "59.9 Riflessioni Conclusive",
    "text": "59.9 Riflessioni Conclusive\nIn questo capitolo abbiamo esplorato le numerose funzionalit√† offerte da brms per la modellazione bayesiana, dimostrando come questo pacchetto consenta di implementare analisi sofisticate in modo intuitivo e flessibile. Abbiamo visto come specificare modelli, eseguire controlli predittivi sui priori e posteriori, testare ipotesi bayesiane e interpretare i risultati in termini probabilistici. La semplicit√† della sintassi e l‚Äôautomatizzazione di aspetti complessi, come la scelta dei priori, rendono brms uno strumento potente e accessibile per affrontare una vasta gamma di problemi statistici, permettendo di ottenere inferenze solide e interpretabili con un approccio moderno e rigoroso.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>59</span>¬† <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/07_two_means.html#informazioni-sullambiente-di-sviluppo",
    "title": "59¬† Confronto tra le medie di due gruppi",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: US/Pacific\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] rstan_2.32.6         StanHeaders_2.32.10  insight_1.0.1       \n#&gt;  [4] bayestestR_0.15.0    brms_2.22.0          Rcpp_1.0.13-1       \n#&gt;  [7] posterior_1.6.0.9000 cmdstanr_0.8.1       ggokabeito_0.1.0    \n#&gt; [10] see_0.9.0            gridExtra_2.3        patchwork_1.3.0     \n#&gt; [13] bayesplot_1.11.1     psych_2.4.12         scales_1.3.0        \n#&gt; [16] markdown_1.13        knitr_1.49           lubridate_1.9.4     \n#&gt; [19] forcats_1.0.0        stringr_1.5.1        dplyr_1.1.4         \n#&gt; [22] purrr_1.0.2          readr_2.1.5          tidyr_1.3.1         \n#&gt; [25] tibble_3.2.1         ggplot2_3.5.1        tidyverse_2.0.0     \n#&gt; [28] rio_1.2.3            here_1.0.1          \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1     farver_2.1.2         loo_2.8.0           \n#&gt;  [4] R.utils_2.12.3       fastmap_1.2.0        tensorA_0.36.2.1    \n#&gt;  [7] pacman_0.5.1         digest_0.6.37        timechange_0.3.0    \n#&gt; [10] lifecycle_1.0.4      processx_3.8.5       magrittr_2.0.3      \n#&gt; [13] compiler_4.4.2       rlang_1.1.4          tools_4.4.2         \n#&gt; [16] utf8_1.2.4           yaml_2.3.10          data.table_1.16.4   \n#&gt; [19] labeling_0.4.3       bridgesampling_1.1-2 htmlwidgets_1.6.4   \n#&gt; [22] curl_6.1.0           pkgbuild_1.4.5       mnormt_2.1.1        \n#&gt; [25] plyr_1.8.9           abind_1.4-8          withr_3.0.2         \n#&gt; [28] R.oo_1.27.0          datawizard_1.0.0     grid_4.4.2          \n#&gt; [31] stats4_4.4.2         colorspace_2.1-1     inline_0.3.21       \n#&gt; [34] cli_3.6.3            mvtnorm_1.3-3        rmarkdown_2.29      \n#&gt; [37] generics_0.1.3       RcppParallel_5.1.9   reshape2_1.4.4      \n#&gt; [40] tzdb_0.4.0           parallel_4.4.2       matrixStats_1.5.0   \n#&gt; [43] vctrs_0.6.5          V8_6.0.0             Matrix_1.7-1        \n#&gt; [46] jsonlite_1.8.9       hms_1.1.3            glue_1.8.0          \n#&gt; [49] codetools_0.2-20     ps_1.8.1             distributional_0.5.0\n#&gt; [52] stringi_1.8.4        gtable_0.3.6         QuickJSR_1.5.1      \n#&gt; [55] munsell_0.5.1        pillar_1.10.1        htmltools_0.5.8.1   \n#&gt; [58] Brobdingnag_1.2-9    R6_2.5.1             rprojroot_2.0.4     \n#&gt; [61] evaluate_1.0.1       lattice_0.22-6       haven_2.5.4         \n#&gt; [64] R.methodsS3_1.8.2    backports_1.5.0      rstantools_2.4.0    \n#&gt; [67] coda_0.19-4.1        nlme_3.1-166         checkmate_2.3.2     \n#&gt; [70] xfun_0.50            pkgconfig_2.0.3",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>59</span>¬† <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#bibliografia",
    "href": "chapters/linear_models/07_two_means.html#bibliografia",
    "title": "59¬† Confronto tra le medie di due gruppi",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nKruschke, J. K. (2013). Bayesian estimation supersedes the t test. Journal of Experimental Psychology: General, 142(2), 573‚Äì603.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>59</span>¬† <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_two_means_stan.html",
    "href": "chapters/linear_models/08_two_means_stan.html",
    "title": "60¬† Confronto tra due gruppi",
    "section": "",
    "text": "60.1 Introduzione\nL‚Äôobiettivo di questo capitolo √® di ampliare la discussione del ?sec-stan-one-mean, affrontando il confronto tra le medie di due gruppi indipendenti.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>¬† <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_two_means_stan.html#stima-bayesiana-e-test-dellipotesi-nulla",
    "href": "chapters/linear_models/08_two_means_stan.html#stima-bayesiana-e-test-dellipotesi-nulla",
    "title": "60¬† Confronto tra due gruppi",
    "section": "60.2 Stima bayesiana e test dell‚Äôipotesi nulla",
    "text": "60.2 Stima bayesiana e test dell‚Äôipotesi nulla\nSpesso, ci troviamo ad affrontare la necessit√† di confrontare due gruppi di dati. Potrebbe interessarci sapere se la media di un gruppo √® maggiore o diversa rispetto a quella di un altro gruppo. Per effettuare tale confronto, √® fondamentale utilizzare un modello statistico, poich√© le vere differenze tra i gruppi sono spesso accompagnate da rumore di misurazione o fluttuazioni casuali del fenomeno in esame. Questo rende difficile trarre conclusioni basandosi unicamente sulle differenze calcolate dai dati osservati.\nIl metodo tradizionale per confrontare statisticamente due o pi√π gruppi √® quello di utilizzare un test statistico. Questo approccio prevede l‚Äôindividuazione di un‚Äôipotesi nulla, che solitamente afferma che non ci sono differenze tra i gruppi, e l‚Äôutilizzo di una statistica test per determinare se i dati osservati sono plausibili sotto questa ipotesi. L‚Äôipotesi nulla viene rifiutata quando la statistica test calcolata supera una soglia predefinita.\nTuttavia, i test di ipotesi possono essere complessi e i risultati spesso soggetti a interpretazioni errate. La scelta delle specifiche del test statistico (ad esempio, quale test utilizzare, quale ipotesi nulla testare, quale livello di significativit√† adottare) √® spesso arbitraria e basata su convenzioni piuttosto che sulla specificit√† del problema o delle decisioni da prendere (Johnson, 1999). Inoltre, i risultati forniti dai test sono spesso indiretti, incompleti e tendono a sovrastimare le evidenze contro l‚Äôipotesi nulla (Goodman, 1999).\nUn approccio pi√π informativo ed efficace per il confronto tra gruppi √® quello basato sulla stima invece che sul test dell‚Äôipotesi nulla, ed √® guidato dalla probabilit√† bayesiana anzich√© dalla frequentista. In pratica, invece di testare se ci sono differenze tra i gruppi, si cerca di ottenere una stima di quanto siano effettivamente diversi. Questo approccio √® intrinsecamente pi√π informativo. Inoltre, viene inclusa una stima dell‚Äôincertezza associata a tale differenza, che tiene conto sia dell‚Äôincertezza dovuta alla nostra mancanza di conoscenza dei parametri del modello (incertezza epistemica) sia dell‚Äôincertezza causata dalla variabilit√† intrinseca del sistema (incertezza aleatoria).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>¬† <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_two_means_stan.html#un-esempio-illustrativo",
    "href": "chapters/linear_models/08_two_means_stan.html#un-esempio-illustrativo",
    "title": "60¬† Confronto tra due gruppi",
    "section": "60.3 Un esempio illustrativo",
    "text": "60.3 Un esempio illustrativo\nIn questo esempio, l‚Äôobiettivo √® stimare la differenza tra le medie del quoziente di intelligenza dei bambini di due gruppi distinti in base al livello di scolarit√† della madre. Il primo gruppo include i bambini la cui madre non ha completato le scuole superiori, mentre il secondo gruppo comprende quelli la cui madre ha ottenuto il diploma superiore. Per questo, useremo i dati kidiq e un modello bayesiano al fine di ottenere una stima affidabile della differenza tra le medie dei due gruppi nella popolazione. I dati utilizzati sono forniti da Gelman e Hill (2007) e costituiscono un sottocampione estratto dal National Longitudinal Survey of Youth.\nImportiamo i dati in R.\n\ndf &lt;- rio::import(here::here(\"data\", \"kidiq.dta\"))\ndf |&gt; \n  head()\n#&gt;   kid_score mom_hs mom_iq mom_work mom_age\n#&gt; 1        65      1  121.1        4      27\n#&gt; 2        98      1   89.4        4      25\n#&gt; 3        85      1  115.4        4      27\n#&gt; 4        83      1   99.4        3      25\n#&gt; 5       115      1   92.7        4      27\n#&gt; 6        98      0  107.9        1      18\n\nIl dataset contiene le seguenti colonne:\n\n‚Äúkid_score‚Äù: il quoziente intellettivo (QI) dei bambini. √à una misura dell‚Äôintelligenza del bambino.\n‚Äúmom_hs‚Äù: una variabile binaria che indica se la madre del bambino ha completato o meno la scuola superiore. Pu√≤ assumere i valori 0 o 1, dove 0 rappresenta ‚Äúno‚Äù (la madre non ha completato la scuola superiore) e 1 rappresenta ‚Äús√¨‚Äù (la madre ha completato la scuola superiore).\n\nCi sono 93 bambini la cui madre non ha completato la scuola superiore e 341 bambini la cui madre ha ottenuto il diploma di scuola superiore.\n\ndf |&gt; \n  group_by(mom_hs) |&gt; \n  summarize(\n    n = n()\n  )\n#&gt; # A tibble: 2 √ó 2\n#&gt;   mom_hs     n\n#&gt;    &lt;dbl&gt; &lt;int&gt;\n#&gt; 1      0    93\n#&gt; 2      1   341\n\nLe statistiche descrittive si ottengono nel modo seguente.\n\ndf |&gt; \n  group_by(mom_hs) |&gt; \n  summarize(\n    avg = mean(kid_score),\n    std = sd(kid_score)\n  )\n#&gt; # A tibble: 2 √ó 3\n#&gt;   mom_hs   avg   std\n#&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1      0  77.5  22.6\n#&gt; 2      1  89.3  19.0\n\nI bambini la cui madre ha completato le superiori tendono ad avere un QI maggiore di 11.8 punti rispetto ai bambini la cui madre non ha concluso le superiori.\n\nmean(df[df$mom_hs == 1, ]$kid_score) - mean(df[df$mom_hs == 0, ]$kid_score)\n#&gt; [1] 11.8\n\nCreiamo due vettori che contengono il QI dei bambini dei due gruppi.\n\n# Vector of kid_score when mom_hs is 1\nkid_score_mom_hs_1 = df[df$mom_hs == 1, ]$kid_score\n\n# Vector of kid_score when mom_hs is 0\nkid_score_mom_hs_0 = df[df$mom_hs == 0, ]$kid_score",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>¬† <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_two_means_stan.html#dimensione-delleffetto",
    "href": "chapters/linear_models/08_two_means_stan.html#dimensione-delleffetto",
    "title": "60¬† Confronto tra due gruppi",
    "section": "60.4 Dimensione dell‚Äôeffetto",
    "text": "60.4 Dimensione dell‚Äôeffetto\nNel caso presente, la differenza tra le medie dei due gruppi √® di 11.8 punti sulla scala del QI, e potrebbe sembrare un risultato rilevante, considerando che la metrica del QI √® facilmente interpretabile. Tuttavia, √® importante notare che il test utilizzato in questo studio non √® il WISC, che ha una distribuzione normale con media 100 e deviazione standard 15, ma il test PIAT.\nIn generale, √® difficile comprendere il significato di una differenza tra le medie di due gruppi quando viene presentata solo come valore assoluto, soprattutto quando le varianze dei gruppi sono diverse. Per ottenere una misura pi√π informativa, √® necessario considerare sia la differenza tra le medie dei gruppi che l‚Äôincertezza associata a queste stime delle medie della popolazione. L‚Äôindice statistico che soddisfa questo scopo √® noto come ‚Äúdimensione dell‚Äôeffetto‚Äù (effect size).\nLa dimensione dell‚Äôeffetto √® una misura della forza dell‚Äôassociazione osservata, che tiene conto sia della grandezza della differenza tra i gruppi attesi che dell‚Äôincertezza sui dati. Tra gli indici pi√π comunemente utilizzati per quantificare la dimensione dell‚Äôeffetto, vi √® l‚Äôindice \\(d\\) di Cohen.\nNel caso di due medie, questo indice √® dato da:\n\\[\nd={\\frac {{\\bar {x}}_{1}-{\\bar {x}}_{2}}{s}},\n\\]\nladdove\n\\[\ns={\\sqrt {\\frac {(n_{1}-1)s_{1}^{2}+(n_{2}-1)s_{2}^{2}}{n_{1}+n_{2}-2}}}\n\\]\ne la varianza di ciascun gruppo √® calcolata come\n\\[\ns_{1}^{2}={\\frac {1}{n_{1}-1}}\\sum _{i=1}^{n_{1}}(x_{1,i}-{\\bar {x}}_{1})^{2}.\n\\]\nSolitamente, l‚Äôindice \\(d\\) di Cohen si interpreta usando la metrica seguente:\n\n\n\nDimensione dell‚Äôeffetto\n\\(d\\)\n\n\n\n\nVery small\n0.01\n\n\nSmall\n0.20\n\n\nMedim\n0.50\n\n\nLarge\n0.80\n\n\nVery large\n1.20\n\n\nHuge\n2.0\n\n\n\nPer una trattazione bayesiana della stima della dimensione dell‚Äôeffetto, si veda Kruschke (2014).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>¬† <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_two_means_stan.html#modello-bayesiano",
    "href": "chapters/linear_models/08_two_means_stan.html#modello-bayesiano",
    "title": "60¬† Confronto tra due gruppi",
    "section": "60.5 Modello bayesiano",
    "text": "60.5 Modello bayesiano\nIl modello bayesiano per il confronto tra le medie di due gruppi indipendenti comprende la definizione della verosimiglianza per i dati di ciascun gruppo e la descrizione delle distribuzioni a priori dei parametri rilevanti. Inoltre, in questo caso, abbiamo incluso anche la stima della dimensione dell‚Äôeffetto, che ci permette di valutare la forza dell‚Äôassociazione osservata tra i gruppi, tenendo conto dell‚Äôincertezza sui dati.\nCreiamo un dizonario con i dati rilevanti.\n\nstan_data = list(\n    N1 = length(kid_score_mom_hs_1), \n    N2 = length(kid_score_mom_hs_0), \n    y1 = kid_score_mom_hs_1,\n    y2 = kid_score_mom_hs_0\n)",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>¬† <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_two_means_stan.html#modello-stan",
    "href": "chapters/linear_models/08_two_means_stan.html#modello-stan",
    "title": "60¬† Confronto tra due gruppi",
    "section": "60.6 Modello Stan",
    "text": "60.6 Modello Stan\nPer analizzare questi dati ci serviremo del seguente modello Stan.\n\n# Path to the Stan file\nstan_file &lt;- here::here(\"stan\", \"kid-score.stan\")\n\n# Create a CmdStanModel object\nmod &lt;- cmdstan_model(stan_file)\n\n\nmod$print()\n#&gt; data {\n#&gt;   int&lt;lower=0&gt; N1;  // number of observations (group 1)\n#&gt;   int&lt;lower=0&gt; N2;  // number of observations (group 2)\n#&gt;   vector[N1] y1;  // response times (group 1)\n#&gt;   vector[N2] y2;  // response times (group 2)\n#&gt; }\n#&gt; \n#&gt; parameters {\n#&gt;   real mu_1;  // mean of group 1\n#&gt;   real mu_2;  // mean of group 2\n#&gt;   real&lt;lower=0&gt; sigma_1;  // standard deviation of group 1\n#&gt;   real&lt;lower=0&gt; sigma_2;  // standard deviation of group 2\n#&gt; }\n#&gt; \n#&gt; transformed parameters {\n#&gt;   real delta;  // difference in means\n#&gt;   real cohen_d;  // Cohen's d effect size\n#&gt;   delta = mu_1 - mu_2;\n#&gt;   cohen_d = delta / sqrt((sigma_1^2 + sigma_2^2) / 2);\n#&gt; }\n#&gt; \n#&gt; model {\n#&gt;   // Priors\n#&gt;   mu_1 ~ normal(80, 20);  // Prior for mean of group 1\n#&gt;   mu_2 ~ normal(80, 20);  // Prior for mean of group 2\n#&gt;   sigma_1 ~ normal(0, 10);  // Prior for standard deviation of group 1\n#&gt;   sigma_2 ~ normal(0, 10);  // Prior for standard deviation of group 2\n#&gt; \n#&gt;   // Likelihood\n#&gt;   y1 ~ normal(mu_1, sigma_1);\n#&gt;   y2 ~ normal(mu_2, sigma_2);\n#&gt; }\n#&gt; \n#&gt; generated quantities {\n#&gt;   vector[N1] y1_rep;  // replicated data for group 1\n#&gt;   vector[N2] y2_rep;  // replicated data for group 2\n#&gt;   for (i in 1:N1) {\n#&gt;     y1_rep[i] = normal_rng(mu_1, sigma_1);\n#&gt;   }\n#&gt;   for (i in 1:N2) {\n#&gt;     y2_rep[i] = normal_rng(mu_2, sigma_2);\n#&gt;   }\n#&gt; }\n\nNel nostro modello:\n\nN1 √® il numero di osservazioni nel primo gruppo (bambini le cui madri hanno completato le superiori)\nN2 √® il numero di osservazioni nel secondo gruppo (bambini le cui madri non hanno completato le superiori)\ny1 √® un vettore contenente i valori di QI per il primo gruppo\ny2 √® un vettore contenente i valori di QI per il secondo gruppo\n\n\n\n\n\n\n\nSpiegazione del modello\n\n\n\nParametri\n\nmu_1 e mu_2: Rappresentano le medie dei valori di QI per i due gruppi.\nsigma_1 e sigma_2: Rappresentano le deviazioni standard dei valori dei QI per i due gruppi.\n\nParametri trasformati\n\ndelta: √à la differenza tra le medie dei due gruppi (mu_1 - mu_2).\ncohen_d: √à la dimensione dell‚Äôeffetto di Cohen, che quantifica la differenza tra i gruppi in unit√† di deviazione standard.\n\nPrior\nImpostiamo delle prior per i parametri:\nmu_1 ~ normal(80, 20);\nmu_2 ~ normal(80, 20);\nsigma_1 ~ normal(0, 10);\nsigma_2 ~ normal(0, 10);\nQueste prior riflettono le nostre conoscenze o supposizioni iniziali sui possibili valori di questi parametri. Per esempio, ci aspettiamo che i QI medi siano intorno a 80, ma con una certa variabilit√†.\nLikelihood\ny1 ~ normal(mu_1, sigma_1);\ny2 ~ normal(mu_2, sigma_2);\nQuesta parte del modello descrive come i dati osservati (y1 e y2) sono generati, date le medie e le deviazioni standard per ciascun gruppo. Assumiamo che i valori del QI seguano una distribuzione normale in ciascun gruppo.\nQuantit√† generate\ny1_rep[i] = normal_rng(mu_1, sigma_1);\ny2_rep[i] = normal_rng(mu_2, sigma_2);\nQueste righe generano dati ‚Äúreplicati‚Äù basati sul modello stimato. Questi possono essere utilizzati per il controllo del modello (posterior predictive checks).\n\n\nI risultati si interpretano nel modo seguente:\n\nmu_1 e mu_2: Ci dicono i valori QI medi stimati per ciascun gruppo.\nsigma_1 e sigma_2: Ci dicono quanto variano i valori del QI all‚Äôinterno di ciascun gruppo.\ndelta: Ci dice quanto √® grande la differenza nei valori dei QI medi tra i due gruppi.\ncohen_d: Ci fornisce una misura standardizzata della dimensione dell‚Äôeffetto.\n\nIn sintesi, questo modello ci permette di:\n\nStimare i valori dei QI medi e la loro variabilit√† per ciascun gruppo.\nQuantificare la differenza tra i gruppi e la sua incertezza.\nCalcolare una misura standardizzata della dimensione dell‚Äôeffetto (Cohen‚Äôs d).\nGenerare previsioni basate sul modello per future osservazioni.\n\nIl vantaggio principale di questo approccio bayesiano √® che otteniamo distribuzioni di probabilit√† complete per tutti i parametri di interesse, permettendoci di fare affermazioni probabilistiche sulla differenza tra i gruppi e sulla dimensione dell‚Äôeffetto.\nEseguiamo il campionamento MCMC:\n\nfit &lt;- mod$sample(\n  data = stan_data,\n  seed = 123,\n  chains = 4,\n  parallel_chains = 4,\n  iter_sampling = 5000, \n  iter_warmup = 2000,\n  adapt_delta = 0.99,\n  show_messages = FALSE\n)\n\n\n60.6.1 Risultati\nEsaminiamo la traccia del parametro di interesse:\n\nmcmc_trace(fit$draws(\"cohen_d\"))\n\n\n\n\n\n\n\n\nGeneriamo un istogramma della distribuzione a posteriori del \\(d\\) di Cohen:\n\nmcmc_hist(\n  fit$draws(\"cohen_d\")\n) +\n  ggtitle(\"Istogramma della distribuzione a posteriori del d di Cohen\") +\n  xlab(\"Valori\") +\n  ylab(\"Frequenza\")\n#&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nUn sommario numerico del \\(d\\) di Cohen si ottiene nel modo seguente:\n\nfit$summary(\"cohen_d\")\n#&gt; # A tibble: 1 √ó 10\n#&gt;   variable  mean median    sd   mad    q5   q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 cohen_d  0.566  0.566 0.124 0.123 0.363 0.769  1.00   18906.   14125.\n\nL‚Äôintervallo di credibilit√† a densit√† pi√π alta si ottiene nel modo seguente:\n\nbayestestR::ci(fit$draws(\"cohen_d\"), method = \"HDI\")\n#&gt; Highest Density Interval\n#&gt; \n#&gt; Parameter |      95% HDI\n#&gt; ------------------------\n#&gt; cohen_d   | [0.32, 0.80]\n\nLe distribuzioni predittive a posteriori sono adeguate, senza essere perfette.\nEstraiamo i dati prodotti dal modello y1_rep e i dati osservati y1:\n\n# Extract posterior predictive samples for y1_rep\ny1_rep &lt;- fit$draws(variables = \"y1_rep\", format = \"draws_matrix\")\n\n# Extract observed data\ny1_obs &lt;- stan_data$y1\n\nConvertiamo y1_rep in una matrice per compatibilit√† con {bayesplot}.\n\n# Convert y1_rep to a matrix\ny1_rep_matrix &lt;- as.matrix(y1_rep)\n\nGeneriamo il posterior predictive chech plot:\n\n# Posterior predictive check plot\nset.seed(123)\nselected_indices &lt;- sample(nrow(y1_rep_matrix), 50)\nppc_dens_overlay(y = y1_obs, yrep = y1_rep_matrix[selected_indices, ])",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>¬† <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_two_means_stan.html#modello-robusto",
    "href": "chapters/linear_models/08_two_means_stan.html#modello-robusto",
    "title": "60¬† Confronto tra due gruppi",
    "section": "60.7 Modello Robusto",
    "text": "60.7 Modello Robusto\nUn modello bayesiano robusto per il confronto tra due medie indipendenti pu√≤ gestire deviazioni standard disuguali e outlier sostituendo la verosimiglianza normale con quella della distribuzione t di Student. Utilizzare una distribuzione t di Student al posto di una normale rende il modello pi√π resistente agli outlier. La distribuzione t di Student ha code pi√π pesanti rispetto alla normale, il che significa che √® meno influenzata da valori estremi nei dati. Questo √® particolarmente utile quando si sospetta la presenza di outlier nei dati o quando le deviazioni standard tra i gruppi sono disuguali. In questo modo, il modello bayesiano robusto offre stime pi√π affidabili delle medie e delle deviazioni standard dei gruppi, nonch√© della differenza tra le medie e della dimensione dell‚Äôeffetto.\n\n# Path to the Stan file\nstan_file &lt;- here::here(\"stan\", \"kid-score-t.stan\")\n\n# Create a CmdStanModel object\nmod_t &lt;- cmdstan_model(stan_file)\n\n\nmod_t$print()\n#&gt; data {\n#&gt;   int&lt;lower=0&gt; N1;  // number of observations (group 1)\n#&gt;   int&lt;lower=0&gt; N2;  // number of observations (group 2)\n#&gt;   vector[N1] y1;  // response time (group 1)\n#&gt;   vector[N2] y2;  // response time (group 2)\n#&gt; }\n#&gt; parameters {\n#&gt;   real mu_2;  // mean of group 2\n#&gt;   real delta;  // difference in means\n#&gt;   real&lt;lower=0&gt; sigma_1;  // scale parameter for group 1\n#&gt;   real&lt;lower=0&gt; sigma_2;  // scale parameter for group 2\n#&gt;   real&lt;lower=1&gt; nu;  // degrees of freedom of student's t distribution\n#&gt; }\n#&gt; transformed parameters {\n#&gt;   real mu_1 = mu_2 + delta; \n#&gt; }\n#&gt; model {\n#&gt;   y1 ~ student_t(nu, mu_1, sigma_1);\n#&gt;   y2 ~ student_t(nu, mu_2, sigma_2);\n#&gt;   // priors\n#&gt;   mu_2 ~ normal(80, 20);\n#&gt;   delta ~ normal(0, 10);\n#&gt;   sigma_1 ~ normal(0, 10);\n#&gt;   sigma_2 ~ normal(0, 10);\n#&gt;   nu ~ gamma(2, 0.1);\n#&gt; }\n#&gt; generated quantities {\n#&gt;   vector[N1] y1rep;\n#&gt;   vector[N2] y2rep;\n#&gt;   real pooled_sd = sqrt((sigma_1^2 + sigma_2^2) / 2);\n#&gt;   real cohen_d = delta / pooled_sd;\n#&gt;   \n#&gt;   for (i in 1:N1) {\n#&gt;     y1rep[i] = student_t_rng(nu, mu_1, sigma_1);\n#&gt;   }\n#&gt;   for (i in 1:N2) {\n#&gt;     y2rep[i] = student_t_rng(nu, mu_2, sigma_2);\n#&gt;   }\n#&gt; }\n\nNel caso presente, usare un modello robusto non produce nessuna differenza rispetto al modello precedente in quanto non ci sono deviazoni importanti rispetto alla gaussianit√† e le due deviazioni standard sono simili.\n\nfit_t &lt;- mod_t$sample(\n  data = stan_data,\n  seed = 123,\n  chains = 4,\n  parallel_chains = 4,\n  iter_sampling = 5000, \n  iter_warmup = 2000,\n  adapt_delta = 0.99,\n  show_messages = FALSE\n)\n\n\nfit_t$summary(\"cohen_d\")\n#&gt; # A tibble: 1 √ó 10\n#&gt;   variable  mean median    sd   mad    q5   q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 cohen_d  0.551  0.551 0.127 0.126 0.342 0.760  1.00    9904.   10452.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>¬† <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_two_means_stan.html#modello-con-iper-priors",
    "href": "chapters/linear_models/08_two_means_stan.html#modello-con-iper-priors",
    "title": "60¬† Confronto tra due gruppi",
    "section": "60.8 Modello con Iper-priors",
    "text": "60.8 Modello con Iper-priors\nIl seguente modello bayesiano per il confronto tra due medie indipendenti utilizza una distribuzione di Student‚Äôs t per gestire deviazioni standard disuguali e outlier. Inoltre, include iper-priors per una maggiore flessibilit√† nella definizione dei parametri delle distribuzioni a priori, che vengono stimate dai dati. Questo approccio permette di incorporare in modo pi√π efficace le incertezze sui parametri dei priors stessi, migliorando la robustezza del modello.\n\n# Path to the Stan file\nstan_file &lt;- here::here(\"stan\", \"kid-score-h.stan\")\n\n# Create a CmdStanModel object\nmod_h &lt;- cmdstan_model(stan_file)\n\n\nfit_h &lt;- mod_h$sample(\n  data = stan_data,\n  seed = 123,\n  chains = 4,\n  parallel_chains = 4,\n  iter_sampling = 5000, \n  iter_warmup = 2000,\n  adapt_delta = 0.99,\n  show_messages = FALSE\n)\n\nAnche in questo caso, la risposta non cambia:\n\nfit_h$summary(\"cohen_d\")\n#&gt; # A tibble: 1 √ó 10\n#&gt;   variable  mean median    sd   mad    q5   q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 cohen_d  0.555  0.556 0.125 0.125 0.349 0.761  1.00    9452.   11689.\n\nIl nostro obiettivo √® comprendere se le medie dei due gruppi sono diverse, e l‚Äôincertezza associata alla stima a posteriori del parametro delta √® fondamentale per rispondere a questa domanda.\n\nfit_h$summary(\"delta\")\n#&gt; # A tibble: 1 √ó 10\n#&gt;   variable  mean median    sd   mad    q5   q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 delta     11.2   11.2  2.47  2.46  7.14  15.3  1.00    9362.   11431.\n\nSe l‚Äôintervallo di credibilit√† associato a delta non include lo 0, allora possiamo concludere con un certo grado di sicurezza che le medie dei due gruppi sono diverse. In altre parole, se l‚Äôintervallo di credibilit√† non contiene lo 0, allora ci sono prove convincenti che le medie dei due gruppi sono diverse.\nNel caso presente, l‚Äôintervallo di credibilit√† al 95% non include lo 0. Pertanto, possiamo concludere, con un livello di sicurezza soggettivo del 95%, che il QI dei bambini le cui madri hanno completato le scuole superiori tende ad essere pi√π elevato rispetto a quello dei bambini le cui madri non hanno completato le scuole superiori.\nPossiamo dunque concludere che, per ci√≤ che concerne l‚Äôeffetto della scolarit√† della madre sul quoziente di intelligenza del bambino, la dimensione dell‚Äôeffetto √® ‚Äúmedia‚Äù.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>¬† <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_two_means_stan.html#verifica-di-ipotesi-bayesiana",
    "href": "chapters/linear_models/08_two_means_stan.html#verifica-di-ipotesi-bayesiana",
    "title": "60¬† Confronto tra due gruppi",
    "section": "60.9 Verifica di ipotesi bayesiana",
    "text": "60.9 Verifica di ipotesi bayesiana\nCome ulteriore approfondimento di questa analisi statistica, possiamo esaminare l‚Äôapproccio bayesiano equivalente al test di ipotesi tradizionale.\nDopo aver ottenuto un campione dalla distribuzione a posteriori del parametro di interesse \\(\\mu\\) per ciascun gruppo, possiamo porci la domanda: qual √® la probabilit√† che il QI di un bambino in un gruppo sia maggiore di quello di un bambino nell‚Äôaltro gruppo? Per rispondere a questa domanda, utilizzeremo campioni casuali dalle distribuzioni a posteriori dei parametri. Confronteremo le coppie di valori campionati dalle due distribuzioni a posteriori del parametro di interesse e calcoleremo la media di tali confronti. Questo ci fornir√† un‚Äôindicazione sulla probabilit√† che il QI di un bambino in un gruppo sia maggiore di quello di un bambino nell‚Äôaltro gruppo, basandoci sulla distribuzione a posteriori dei parametri stimati dal modello.\nPer eseguire un test d‚Äôipotesi per calcolare la probabilit√† che $ _1 &gt; _2 $ utilizzando il modello Stan fornito e cmdstanpy, √® necessario estrarre i campioni posteriori per i parametri \\(\\mu_1\\) e \\(\\mu_2\\) dopo aver adattato il modello. Successivamente, √® possibile calcolare la probabilit√† basandosi sui campioni posteriori. Ad esempio, ci possiamo chiedere quale sia la probabilit√† che un bambino la cui madre ha completato la scuola superiore abbia un QI maggiore di un bambino la cui madre non ha completato la scuola superiore.\n\nposterior &lt;- fit$draws(\n  variables = c(\"mu_1\", \"mu_2\", \"delta\"), format = \"draws_df\"\n)\nposterior$mu_1 &lt;- posterior$mu_2 + posterior$delta\n\nprob_mu1_greater_mu2 &lt;- mean(posterior$mu_1 &gt; posterior$mu_2)\ncat(sprintf(\"Probability that mu_1 &gt; mu_2: %.4f\\n\", prob_mu1_greater_mu2))\n#&gt; Probability that mu_1 &gt; mu_2: 1.0000\n\nUna tale probabilit√† √® effettivamente uguale a 1 il che conferma il risultato precedente, ovvero l‚Äôiportanza del livello di istruzione della madre per il QI del figlio.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>¬† <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_two_means_stan.html#riflessioni-conclusive",
    "href": "chapters/linear_models/08_two_means_stan.html#riflessioni-conclusive",
    "title": "60¬† Confronto tra due gruppi",
    "section": "60.10 Riflessioni conclusive",
    "text": "60.10 Riflessioni conclusive\nIn questo capitolo abbiamo esaminato la procedura bayesiana per calcolare la distribuzione a posteriori della differenza tra le medie di due gruppi indipendenti. Inoltre, abbiamo esplorato il calcolo della dimensione dell‚Äôeffetto in termini bayesiani. Nell‚Äôesempio trattato, abbiamo considerato il caso in cui la verosimiglianza √® descritta da una distribuzione Gaussiana. Tuttavia, va sottolineato che la scelta di una distribuzione specifica per la verosimiglianza non √® vincolante nella statistica bayesiana. √à possibile utilizzare qualsiasi distribuzione di probabilit√†, purch√© sia adeguata ai dati del campione.\nNel caso del confronto tra le medie di due gruppi indipendenti, una distribuzione molto utilizzata √® la distribuzione \\(t\\) di Student. Questa distribuzione √® particolarmente vantaggiosa quando si desidera condurre un‚Äôanalisi statistica ‚Äúrobusta‚Äù, ovvero un‚Äôanalisi che non sia influenzata da osservazioni anomale o outlier presenti nei dati. Per questo motivo, la distribuzione \\(t\\) di Student √® spesso preferita quando si lavora con dati che potrebbero contenere valori anomali.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>¬† <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_two_means_stan.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/08_two_means_stan.html#informazioni-sullambiente-di-sviluppo",
    "title": "60¬† Confronto tra due gruppi",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: US/Pacific\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] bayestestR_0.15.0    posterior_1.6.0.9000 cmdstanr_0.8.1      \n#&gt;  [4] ggokabeito_0.1.0     see_0.9.0            gridExtra_2.3       \n#&gt;  [7] patchwork_1.3.0      bayesplot_1.11.1     psych_2.4.12        \n#&gt; [10] scales_1.3.0         markdown_1.13        knitr_1.49          \n#&gt; [13] lubridate_1.9.4      forcats_1.0.0        stringr_1.5.1       \n#&gt; [16] dplyr_1.1.4          purrr_1.0.2          readr_2.1.5         \n#&gt; [19] tidyr_1.3.1          tibble_3.2.1         ggplot2_3.5.1       \n#&gt; [22] tidyverse_2.0.0      rio_1.2.3            here_1.0.1          \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6         tensorA_0.36.2.1     xfun_0.50           \n#&gt;  [4] htmlwidgets_1.6.4    insight_1.0.1        processx_3.8.5      \n#&gt;  [7] lattice_0.22-6       tzdb_0.4.0           vctrs_0.6.5         \n#&gt; [10] tools_4.4.2          ps_1.8.1             generics_0.1.3      \n#&gt; [13] datawizard_1.0.0     parallel_4.4.2       pacman_0.5.1        \n#&gt; [16] R.oo_1.27.0          pkgconfig_2.0.3      data.table_1.16.4   \n#&gt; [19] checkmate_2.3.2      distributional_0.5.0 lifecycle_1.0.4     \n#&gt; [22] compiler_4.4.2       farver_2.1.2         munsell_0.5.1       \n#&gt; [25] mnormt_2.1.1         htmltools_0.5.8.1    yaml_2.3.10         \n#&gt; [28] pillar_1.10.1        R.utils_2.12.3       abind_1.4-8         \n#&gt; [31] nlme_3.1-166         tidyselect_1.2.1     digest_0.6.37       \n#&gt; [34] stringi_1.8.4        reshape2_1.4.4       labeling_0.4.3      \n#&gt; [37] rprojroot_2.0.4      fastmap_1.2.0        grid_4.4.2          \n#&gt; [40] colorspace_2.1-1     cli_3.6.3            magrittr_2.0.3      \n#&gt; [43] utf8_1.2.4           withr_3.0.2          backports_1.5.0     \n#&gt; [46] timechange_0.3.0     rmarkdown_2.29       matrixStats_1.5.0   \n#&gt; [49] R.methodsS3_1.8.2    hms_1.1.3            evaluate_1.0.1      \n#&gt; [52] haven_2.5.4          rlang_1.1.4          Rcpp_1.0.13-1       \n#&gt; [55] glue_1.8.0           jsonlite_1.8.9       plyr_1.8.9          \n#&gt; [58] R6_2.5.1",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>¬† <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_two_means_stan.html#bibliografia",
    "href": "chapters/linear_models/08_two_means_stan.html#bibliografia",
    "title": "60¬† Confronto tra due gruppi",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBland, J. M., & Altman, D. G. (2011). Comparisons within randomised groups can be very misleading. Bmj, 342.\n\n\nKruschke, J. (2014). Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan. Academic Press.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>¬† <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_sample_size.html",
    "href": "chapters/linear_models/09_sample_size.html",
    "title": "61¬† Disegno della ricerca e potere statistico",
    "section": "",
    "text": "61.1 Introduzione\nLa potenza statistica √® definita come la probabilit√†, calcolata prima che uno studio venga condotto, che un determinato confronto raggiunga un livello predefinito di ‚Äúsignificativit√† statistica‚Äù (tipicamente un p-value inferiore a 0,05), dato un effetto reale ipotizzato. Per calcolare la potenza, si parte da un‚Äôipotesi sulla dimensione dell‚Äôeffetto, si fanno assunzioni sulla variabilit√† dei dati e sulla dimensione del campione, e si utilizzano calcoli probabilistici per determinare la probabilit√† che il p-value sia inferiore alla soglia stabilita.\nLa visione convenzionale sconsiglia di condurre studi con bassa potenza, poich√© hanno basse probabilit√† di ‚Äúsuccesso‚Äù. Tuttavia, in casi in cui i costi sono molto bassi rispetto ai potenziali benefici, un ricercatore potrebbe decidere di correre il rischio. Come vedremo, per√≤, questa scelta pu√≤ nascondere insidie significative.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>¬† <span class='chapter-title'>Disegno della ricerca e potere statistico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_sample_size.html#la-maledizione-del-vincitore-negli-studi-a-bassa-potenza",
    "href": "chapters/linear_models/09_sample_size.html#la-maledizione-del-vincitore-negli-studi-a-bassa-potenza",
    "title": "61¬† Disegno della ricerca e potere statistico",
    "section": "61.2 La maledizione del vincitore negli studi a bassa potenza",
    "text": "61.2 La maledizione del vincitore negli studi a bassa potenza\nIn uno studio con bassa potenza, il ‚Äúsuccesso‚Äù apparente di un risultato statisticamente significativo pu√≤ essere ingannevole. Quando il segnale √® debole e il rumore elevato, i risultati significativi tendono a essere erronei (esagerati o nel segno sbagliato), con scarse probabilit√† di replicabilit√†. Questi errori sono noti come errori di tipo M (esagerazione della dimensione dell‚Äôeffetto) e di tipo S (errore nel segno dell‚Äôeffetto). Di conseguenza, uno studio a bassa potenza rischia di generare informazioni fuorvianti, contribuendo alla crisi di replicazione.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>¬† <span class='chapter-title'>Disegno della ricerca e potere statistico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_sample_size.html#stimare-la-dimensione-del-campione",
    "href": "chapters/linear_models/09_sample_size.html#stimare-la-dimensione-del-campione",
    "title": "61¬† Disegno della ricerca e potere statistico",
    "section": "61.3 Stimare la dimensione del campione",
    "text": "61.3 Stimare la dimensione del campione\nPrima di raccogliere dati, √® utile stimare la dimensione del campione necessaria per ottenere un certo livello di precisione o per garantire una potenza desiderata. Vediamo i calcoli dettagliati.\n\n61.3.1 Determinazione della dimensione del campione per un errore standard specifico\nSupponiamo di voler stimare un valore medio \\(\\theta\\) della popolazione utilizzando un campione casuale di dimensione \\(n\\). La stima \\(\\bar{y}\\), cio√® la media campionaria, ha un errore standard dato da:\n\\[\n\\text{s.e.}(\\bar{y}) = \\frac{\\sigma}{\\sqrt{n}},\n\\]\ndove:\n\n\\(\\text{s.e.}(\\bar{y})\\) √® l‚Äôerrore standard della media campionaria,\n\\(\\sigma\\) √® la deviazione standard della popolazione,\n\\(n\\) √® la dimensione del campione.\n\nSe vogliamo ottenere un errore standard specifico, denotato con \\(\\text{s.e.}\\), impostiamo l‚Äôequazione:\n\\[\n\\text{s.e.} = \\frac{\\sigma}{\\sqrt{n}}.\n\\]\nPer risolvere rispetto a \\(n\\), procediamo come segue:\n\nMoltiplichiamo entrambi i lati per \\(\\sqrt{n}\\) per eliminare il denominatore: \\[\n\\text{s.e.} \\cdot \\sqrt{n} = \\sigma.\n\\]\nDividiamo entrambi i lati per \\(\\text{s.e.}\\): \\[\n\\sqrt{n} = \\frac{\\sigma}{\\text{s.e.}}.\n\\]\nEleviamo al quadrato entrambi i lati per eliminare la radice: \\[\nn = \\left(\\frac{\\sigma}{\\text{s.e.}}\\right)^2.\n\\]\n\nQuesta formula ci dice che la dimensione del campione necessaria per ottenere un determinato errore standard √® proporzionale al quadrato del rapporto tra la deviazione standard \\(\\sigma\\) e l‚Äôerrore standard desiderato \\(\\text{s.e.}\\).\n\n\n\n61.3.2 Dimensione del campione per una potenza dell‚Äô80%\nSupponiamo ora di voler determinare la dimensione del campione necessaria per ottenere l‚Äô80% di potenza nel distinguere un valore \\(\\theta\\) dalla media ipotizzata \\(\\theta_0\\).\nL‚Äôerrore standard della differenza \\(\\theta - \\theta_0\\) √® dato da:\n\\[\n\\text{s.e.} = \\frac{\\sigma}{\\sqrt{n}}.\n\\]\nPer ottenere l‚Äô80% di potenza, vogliamo che la differenza osservata \\(\\theta - \\theta_0\\) sia sufficientemente grande da essere rilevata con il livello di significativit√† prefissato (ad esempio, 5%).\n\n61.3.2.1 Passaggi algebrici per derivare la formula:\n\nPer una potenza dell‚Äô80%, la differenza \\(\\theta - \\theta_0\\) deve essere almeno 2,8 volte l‚Äôerrore standard, dove il valore \\(2.8\\) √® dato dalla somma dei quantili della distribuzione normale per il 95% di confidenza (\\(1.96\\)) e per l‚Äô80% di potenza (\\(0.84\\)): \\[\n\\theta - \\theta_0 = 2.8 \\cdot \\frac{\\sigma}{\\sqrt{n}}.\n\\]\nRisolviamo per \\(\\sqrt{n}\\): \\[\n\\sqrt{n} = \\frac{2.8 \\cdot \\sigma}{\\theta - \\theta_0}.\n\\]\nEleviamo al quadrato entrambi i lati: \\[\nn = \\left(\\frac{2.8 \\cdot \\sigma}{\\theta - \\theta_0}\\right)^2.\n\\]\n\nQuesta formula fornisce la dimensione del campione necessaria per ottenere l‚Äô80% di potenza, dove \\(2.8\\) rappresenta il valore soglia della distribuzione normale standard.\n\n\n61.3.2.2 Esempio pratico\nSe vogliamo distinguere \\(\\theta\\) da \\(\\theta_0\\) con \\(\\sigma = 10\\) e una differenza minima rilevabile di \\(\\theta - \\theta_0 = 5\\), possiamo calcolare \\(n\\) come segue:\n\\[\nn = \\left(\\frac{2.8 \\cdot 10}{5}\\right)^2 = \\left(5.6\\right)^2 = 31.36.\n\\]\nArrotondando, servono almeno 32 osservazioni.\n\n\n\n\n61.3.3 Correzione per campioni piccoli e distribuzione t\nPer studi con pochi gradi di libert√†, l‚Äôincertezza sulla stima di \\(\\sigma\\) aumenta, e la distribuzione t di Student diventa pi√π appropriata. In questi casi, il valore \\(2.8\\) deve essere sostituito con un valore pi√π grande, dipendente dai gradi di libert√†, per compensare l‚Äôincertezza aggiuntiva.\nAd esempio, per uno studio che confronta due gruppi di 6 pazienti ciascuno, i gradi di libert√† sono 10. In R, la somma dei quantili della distribuzione t con 10 gradi di libert√† per l‚Äô80% di potenza e il 95% di confidenza √® \\(3.1\\), quindi \\(2.8\\) viene sostituito da \\(3.1\\) nei calcoli per la potenza dell‚Äô80%.\n\n# Gradi di libert√†\ndf &lt;- 10\n\n# Calcola il quantile per l'80% di potenza (quindi 0.8) e il 95% di confidenza (quindi 0.975)\nt_value_80 &lt;- qt(0.8, df)\nt_value_95 &lt;- qt(0.975, df)\n\n# Somma dei due quantili\nt_total &lt;- t_value_80 + t_value_95\nt_total\n#&gt; [1] 3.11\n\nEseguendo questo codice in R, otteniamo il valore 3.107, che sostituisce il valore \\(2.8\\) nei calcoli per la potenza dell‚Äô80% quando si lavora con piccoli campioni e si utilizza la distribuzione t invece della normale standard.\n\n\n\n61.3.4 Nota\nQuesto esempio evidenzia come la distribuzione t tenga conto della maggiore variabilit√† introdotta dalla stima della deviazione standard in campioni di piccole dimensioni, aumentando leggermente il valore soglia richiesto per la potenza desiderata.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>¬† <span class='chapter-title'>Disegno della ricerca e potere statistico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_sample_size.html#confronto-di-medie",
    "href": "chapters/linear_models/09_sample_size.html#confronto-di-medie",
    "title": "61¬† Disegno della ricerca e potere statistico",
    "section": "61.4 Confronto di Medie",
    "text": "61.4 Confronto di Medie\nEsaminiamo ora il caso del confronto tra le medie di due gruppi indipendenti. Vogliamo determinare la dimensione del campione necessaria per rilevare una differenza significativa \\(\\Delta\\) tra le due medie con una potenza statistica dell‚Äô80%.\n\n61.4.1 Errore Standard della Differenza tra Due Medie\nL‚Äôerrore standard della differenza tra le medie campionarie \\(\\bar{y}_1\\) e \\(\\bar{y}_2\\) √® dato da:\n\\[\n\\text{s.e.}(\\bar{y}_1 - \\bar{y}_2) = \\sqrt{\\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}},\n\\]\ndove:\n\n\\(\\sigma_1^2\\) e \\(\\sigma_2^2\\) sono le varianze delle popolazioni dei due gruppi,\n\\(n_1\\) e \\(n_2\\) sono le dimensioni dei campioni nei due gruppi.\n\n\n61.4.1.1 Caso di Varianze e Dimensioni del Campione Uguali\nSe assumiamo che:\n\nle varianze sono uguali: \\(\\sigma_1 = \\sigma_2 = \\sigma\\),\nle dimensioni dei campioni sono uguali: \\(n_1 = n_2 = n\\),\n\nl‚Äôerrore standard diventa:\n\nSostituiamo le varianze e le dimensioni dei campioni:\n\\[\n\\text{s.e.} = \\sqrt{\\frac{\\sigma^2}{n} + \\frac{\\sigma^2}{n}} = \\sqrt{\\frac{2\\sigma^2}{n}}.\n\\]\nSemplifichiamo l‚Äôespressione:\n\\[\n\\text{s.e.} = \\frac{\\sqrt{2}\\sigma}{\\sqrt{n}}.\n\\]\n\n\n\n\n61.4.2 Dimensione del Campione per un Errore Standard Specifico\nSe desideriamo ottenere un errore standard specifico \\(\\text{s.e.}\\), possiamo determinare la dimensione del campione \\(n\\) seguendo questi passaggi:\n\nPartiamo dall‚Äôespressione dell‚Äôerrore standard:\n\\[\n\\text{s.e.} = \\frac{\\sqrt{2}\\sigma}{\\sqrt{n}}.\n\\]\nRisolviamo per \\(\\sqrt{n}\\):\n\\[\n\\sqrt{n} = \\frac{\\sqrt{2}\\sigma}{\\text{s.e.}}.\n\\]\nEleviamo al quadrato entrambi i membri:\n\\[\nn = \\left( \\frac{\\sqrt{2}\\sigma}{\\text{s.e.}} \\right)^2 = \\frac{2\\sigma^2}{\\text{s.e.}^2}.\n\\]\n\n\n\n61.4.3 Dimensione del Campione per una Differenza \\(\\Delta\\) con l‚Äô80% di Potenza\nPer garantire una potenza dell‚Äô80% nel rilevare una differenza \\(\\Delta\\) tra le due medie, seguiamo questi passaggi:\n\n61.4.3.1 Determinazione del Valore Critico\nPer un test bilaterale al livello di significativit√† del 5%, i valori critici della distribuzione normale standard sono:\n\n\\(z_{\\alpha/2} = 1.96\\) (per il 95% di confidenza),\n\\(z_{\\text{potenza}} = 0.84\\) (per l‚Äô80% di potenza).\n\nLa somma totale √®:\n\\[\nz_{\\text{totale}} = z_{\\alpha/2} + z_{\\text{potenza}} = 1.96 + 0.84 = 2.8.\n\\]\n\n\n61.4.3.2 Relazione tra \\(\\Delta\\) ed Errore Standard\nLa differenza minima rilevabile \\(\\Delta\\) √® legata all‚Äôerrore standard dalla relazione:\n\nImpostiamo l‚Äôequazione:\n\\[\n\\Delta = z_{\\text{totale}} \\times \\text{s.e.} = 2.8 \\times \\text{s.e.}.\n\\]\nSostituiamo l‚Äôespressione per \\(\\text{s.e.}\\):\n\\[\n\\Delta = 2.8 \\times \\frac{\\sqrt{2}\\sigma}{\\sqrt{n}}.\n\\]\nCalcoliamo il coefficiente:\n\\[\n2.8 \\times \\sqrt{2} = 2.8 \\times 1.4142 \\approx 3.96.\n\\]\nQuindi:\n\\[\n\\Delta = 3.96 \\times \\frac{\\sigma}{\\sqrt{n}}.\n\\]\nRisolviamo per \\(\\sqrt{n}\\):\n\\[\n\\sqrt{n} = \\frac{3.96 \\sigma}{\\Delta}.\n\\]\nEleviamo al quadrato entrambi i membri:\n\\[\nn = \\left( \\frac{3.96 \\sigma}{\\Delta} \\right)^2.\n\\]\n\n\n\n\n61.4.4 Formula Finale per la Dimensione del Campione\nLa dimensione del campione necessaria per ciascun gruppo √® data da:\n\\[\nn = \\left( \\frac{3.96 \\sigma}{\\Delta} \\right)^2.\n\\]\nPer semplificare i calcoli, possiamo arrotondare \\(3.96\\) a \\(4\\):\n\\[\nn = \\left( \\frac{4 \\sigma}{\\Delta} \\right)^2.\n\\]\nNota Importante: Questa formula si applica quando:\n\nLe varianze delle popolazioni sono uguali (\\(\\sigma_1 = \\sigma_2 = \\sigma\\)).\nLe dimensioni dei campioni nei due gruppi sono uguali (\\(n_1 = n_2 = n\\)).\nIl totale dei campioni √® \\(N = 2n\\).\n\n\n\n61.4.5 Interpretazione della Formula\n\nSe la deviazione standard \\(\\sigma\\) √® elevata: C‚Äô√® maggiore variabilit√† nei dati, quindi √® necessario un campione pi√π grande per rilevare una differenza \\(\\Delta\\) con la stessa potenza.\nSe la differenza \\(\\Delta\\) √® piccola: Serve un campione pi√π grande per garantire che la differenza sia rilevabile con l‚Äô80% di potenza.\n\n\n\n61.4.6 Esempio Pratico\nSupponiamo di voler rilevare una differenza \\(\\Delta = 5\\) unit√† tra due gruppi, con una deviazione standard comune \\(\\sigma = 10\\) unit√†.\nCalcolo della dimensione del campione per ciascun gruppo:\n\nUtilizziamo la formula:\n\\[\nn = \\left( \\frac{4 \\times 10}{5} \\right)^2 = \\left( \\frac{40}{5} \\right)^2 = \\left( 8 \\right)^2 = 64.\n\\]\nRisultato:\n\n64 partecipanti per gruppo.\nTotale di 128 partecipanti.\n\n\n\n\n61.4.7 Caso con Campione Totale Fissato\nSe il campione totale √® fissato a \\(n\\), con dimensioni dei gruppi \\(n_1 = n_2 = n/2\\), l‚Äôerrore standard cambia leggermente.\n\n61.4.7.1 Calcolo dell‚ÄôErrore Standard\n\nSostituiamo \\(n_1 = n_2 = n/2\\) nell‚Äôerrore standard:\n\\[\n\\text{s.e.} = \\sqrt{\\frac{\\sigma^2}{n/2} + \\frac{\\sigma^2}{n/2}} = \\sqrt{2 \\times \\frac{\\sigma^2}{n/2}}.\n\\]\nSemplifichiamo l‚Äôespressione:\n\\[\n\\text{s.e.} = \\sqrt{\\frac{4\\sigma^2}{n}} = \\frac{2\\sigma}{\\sqrt{n}}.\n\\]\n\n\n\n61.4.7.2 Dimensione del Campione\n\nRelazione tra \\(\\Delta\\) ed errore standard:\n\\[\n\\Delta = 2.8 \\times \\text{s.e.} = 2.8 \\times \\frac{2\\sigma}{\\sqrt{n}} = \\frac{5.6 \\sigma}{\\sqrt{n}}.\n\\]\nRisolviamo per \\(\\sqrt{n}\\):\n\\[\n\\sqrt{n} = \\frac{5.6 \\sigma}{\\Delta}.\n\\]\nEleviamo al quadrato:\n\\[\nn = \\left( \\frac{5.6 \\sigma}{\\Delta} \\right)^2.\n\\]\n\nIn questo scenario, la dimensione totale del campione √® \\(n\\), con \\(n/2\\) partecipanti per ciascun gruppo.\n\n\n\n61.4.8 Scelta della Formula Adeguata\n\nSe \\(n\\) rappresenta la dimensione del campione per gruppo:\n\\[\nn = \\left( \\frac{4 \\sigma}{\\Delta} \\right)^2.\n\\]\nSe \\(n\\) rappresenta la dimensione totale del campione:\n\\[\nn = \\left( \\frac{5.6 \\sigma}{\\Delta} \\right)^2.\n\\]\n\nAssicurarsi di chiarire come si definisce \\(n\\) √® fondamentale per applicare correttamente le formule.\n\n\n61.4.9 Sintesi\n\nVarianze e dimensioni uguali nei due gruppi semplificano i calcoli.\nLa dimensione del campione aumenta con l‚Äôaumentare della deviazione standard \\(\\sigma\\) e con la diminuzione della differenza \\(\\Delta\\) che si vuole rilevare.\nEssere chiari sulla definizione di \\(n\\) (per gruppo o totale) evita errori nei calcoli.\n\n\nEsempio 61.1 Se la differenza \\(\\Delta\\) che vogliamo rilevare √® pari a met√† della deviazione standard (\\(\\Delta = 0.5\\sigma\\)), allora la formula ci dir√† quanti partecipanti sono necessari in ciascun gruppo per rilevare questa differenza con l‚Äô80% di potenza. Ad esempio, se \\(\\Delta = 0.5\\sigma\\), la dimensione totale del campione sar√†:\n\\[\nn = \\left(\\frac{5.6 \\sigma}{0.5\\sigma}\\right)^2 = (11.2)^2 = 125.44 \\approx 126.\n\\]\nQuindi, servirebbero 63 partecipanti per gruppo.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>¬† <span class='chapter-title'>Disegno della ricerca e potere statistico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_sample_size.html#riflessioni-conclusive",
    "href": "chapters/linear_models/09_sample_size.html#riflessioni-conclusive",
    "title": "61¬† Disegno della ricerca e potere statistico",
    "section": "61.5 Riflessioni Conclusive",
    "text": "61.5 Riflessioni Conclusive\nLa determinazione della dimensione del campione √® un passaggio cruciale nella progettazione degli studi, poich√© garantisce che le inferenze siano robuste e i risultati affidabili. Questo capitolo ha mostrato come le caratteristiche dei dati, come la deviazione standard e la differenza attesa tra i gruppi, influenzino direttamente la dimensione del campione necessaria per ottenere una potenza statistica adeguata. Inoltre, l‚Äôattenzione ai dettagli, come l‚Äôuso della distribuzione t per piccoli campioni, sottolinea l‚Äôimportanza di considerare le fonti di variabilit√† e incertezza nei calcoli. Pianificare con rigore la dimensione del campione non solo aumenta la probabilit√† di rilevare effetti significativi, ma contribuisce anche a ridurre il rischio di risultati fuorvianti, migliorando cos√¨ la qualit√† complessiva della ricerca scientifica.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>¬† <span class='chapter-title'>Disegno della ricerca e potere statistico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_sample_size.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/09_sample_size.html#informazioni-sullambiente-di-sviluppo",
    "title": "61¬† Disegno della ricerca e potere statistico",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: US/Pacific\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pointblank_0.12.2 haven_2.5.4       labelled_2.14.0   mice_3.17.0      \n#&gt;  [5] ggokabeito_0.1.0  see_0.9.0         gridExtra_2.3     patchwork_1.3.0  \n#&gt;  [9] bayesplot_1.11.1  psych_2.4.12      scales_1.3.0      markdown_1.13    \n#&gt; [13] knitr_1.49        lubridate_1.9.4   forcats_1.0.0     stringr_1.5.1    \n#&gt; [17] dplyr_1.1.4       purrr_1.0.2       readr_2.1.5       tidyr_1.3.1      \n#&gt; [21] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [25] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      shape_1.4.6.1     xfun_0.50         htmlwidgets_1.6.4\n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2      \n#&gt;  [9] generics_0.1.3    parallel_4.4.2    pan_1.9           pacman_0.5.1     \n#&gt; [13] jomo_2.7-6        pkgconfig_2.0.3   Matrix_1.7-1      lifecycle_1.0.4  \n#&gt; [17] compiler_4.4.2    farver_2.1.2      munsell_0.5.1     mnormt_2.1.1     \n#&gt; [21] codetools_0.2-20  htmltools_0.5.8.1 glmnet_4.1-8      nloptr_2.1.1     \n#&gt; [25] pillar_1.10.1     MASS_7.3-64       iterators_1.0.14  rpart_4.1.23     \n#&gt; [29] boot_1.3-31       foreach_1.5.2     mitml_0.4-5       nlme_3.1-166     \n#&gt; [33] tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4     splines_4.4.2    \n#&gt; [37] rprojroot_2.0.4   fastmap_1.2.0     grid_4.4.2        blastula_0.3.5   \n#&gt; [41] colorspace_2.1-1  cli_3.6.3         magrittr_2.0.3    survival_3.7-0   \n#&gt; [45] broom_1.0.7       withr_3.0.2       backports_1.5.0   timechange_0.3.0 \n#&gt; [49] rmarkdown_2.29    nnet_7.3-19       lme4_1.1-35.5     hms_1.1.3        \n#&gt; [53] evaluate_1.0.1    rlang_1.1.4       Rcpp_1.0.13-1     glue_1.8.0       \n#&gt; [57] minqa_1.2.8       jsonlite_1.8.9    R6_2.5.1",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>¬† <span class='chapter-title'>Disegno della ricerca e potere statistico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_sample_size.html#bibliografia",
    "href": "chapters/linear_models/09_sample_size.html#bibliografia",
    "title": "61¬† Disegno della ricerca e potere statistico",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other stories. Cambridge University Press.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>¬† <span class='chapter-title'>Disegno della ricerca e potere statistico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_1via.html",
    "href": "chapters/linear_models/10_anova_1via.html",
    "title": "62¬† ANOVA ad una via",
    "section": "",
    "text": "62.1 Preparazione del Notebook\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(cmdstanr, posterior, bayestestR, brms, emmeans)\n\nsi installa anche la dipendenza 'estimability'\n\n\n\nI pacchetti binari scaricati sono in\n    /var/folders/gw/hc72by314msbfbhm58gh0fgc0000gn/T//RtmpAZLvh0/downloaded_packages\n\n\n\nemmeans installed",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>¬† <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_1via.html#introduzione",
    "href": "chapters/linear_models/10_anova_1via.html#introduzione",
    "title": "62¬† ANOVA ad una via",
    "section": "62.2 Introduzione",
    "text": "62.2 Introduzione\nNel Capitolo ?? abbiamo visto come costruire regressori fittizi (dummy) per rappresentare l‚Äôeffetto di variabili categoriche (fattori) a due livelli. Consideriamo ora il caso di un singolo fattore con pi√π di due livelli. Per esempio, nel caso di una classificazione a tre categorie, possiamo adottare il modello\n\\[\nY_i = \\alpha + \\gamma_1 D_{i1} + \\gamma_2 D_{i2} + \\varepsilon_i,\n\\tag{62.1}\\]\nutilizzando la seguente codifica per i regressori dummy:\n\\[\n\\begin{array}{c|cc}\n\\text{Gruppo} & D_1 & D_2 \\\\\n\\hline\n1 & 1 & 0 \\\\\n2 & 0 & 1 \\\\\n3 & 0 & 0\n\\end{array}\n\\tag{62.2}\\]\nL‚Äôaspettativa della variabile di risposta in ciascun gruppo (cio√® in ciascuna categoria o livello del fattore) corrisponde alla media di popolazione del gruppo, indicata con \\(\\mu_j\\) per il gruppo \\(j\\). Poich√© l‚Äôerrore \\(\\varepsilon\\) ha media zero, in base alle usuali ipotesi del modello lineare, prendendo l‚Äôaspettativa di entrambi i membri dell‚Äôequazione (8.1) si ottengono le relazioni seguenti tra le medie di gruppo e i parametri:\n\\[\n\\begin{aligned}\n\\text{Gruppo 1: } \\mu_1 &= \\alpha + \\gamma_1 \\cdot 1 + \\gamma_2 \\cdot 0 = \\alpha + \\gamma_1, \\\\\n\\text{Gruppo 2: } \\mu_2 &= \\alpha + \\gamma_1 \\cdot 0 + \\gamma_2 \\cdot 1 = \\alpha + \\gamma_2, \\\\\n\\text{Gruppo 3: } \\mu_3 &= \\alpha + \\gamma_1 \\cdot 0 + \\gamma_2 \\cdot 0 = \\alpha.\n\\end{aligned}\n\\tag{62.3}\\]\nQui troviamo tre parametri \\((\\alpha, \\gamma_1, \\gamma_2)\\) e tre medie di gruppo, per cui √® possibile risolvere in modo univoco i parametri in termini delle medie di gruppo:\n\\[\n\\alpha = \\mu_3, \\quad \\gamma_1 = \\mu_1 - \\mu_3, \\quad \\gamma_2 = \\mu_2 - \\mu_3.\n\\tag{62.4}\\]\nNon sorprende che \\(\\alpha\\) rappresenti la media della categoria di riferimento (il Gruppo 3), mentre \\(\\gamma_1\\) e \\(\\gamma_2\\) descrivono quanto le altre due medie di gruppo si discostino dalla media della categoria di riferimento.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>¬† <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_1via.html#simulazione",
    "href": "chapters/linear_models/10_anova_1via.html#simulazione",
    "title": "62¬† ANOVA ad una via",
    "section": "62.3 Simulazione",
    "text": "62.3 Simulazione\nPer esaminare un‚Äôapplicazione pratica, simuliamo i dati di un fattore con 3 livelli:\n\n# Imposta un seme per riproducibilit√† (opzionale)\nset.seed(123)\n\n# Definiamo il numero di osservazioni per ogni gruppo\nn &lt;- 30\n\n# Definiamo le medie\nmean_control &lt;- 30\nmean_psico1  &lt;- 25\nmean_psico2  &lt;- 20\n\n# Definiamo la deviazione standard (ipotizziamo la stessa per tutti i gruppi)\nsd_value &lt;- 5\n\n# Generiamo i dati casuali da distribuzioni normali\ncontrollo     &lt;- rnorm(n, mean_control, sd_value)\npsicoterapia1 &lt;- rnorm(n, mean_psico1,  sd_value)\npsicoterapia2 &lt;- rnorm(n, mean_psico2,  sd_value)\n\n# Creiamo un data frame con due colonne:\n# - \"condizione\": indica il gruppo (controllo / psicoterapia1 / psicoterapia2)\n# - \"punteggio\":  contiene i dati numerici generati\ndf &lt;- data.frame(\n  condizione = rep(c(\"controllo\", \"psicoterapia1\", \"psicoterapia2\"), each = n),\n  punteggio  = c(controllo, psicoterapia1, psicoterapia2)\n)\n\n\nhead(df)\n#&gt;   condizione punteggio\n#&gt; 1  controllo      27.2\n#&gt; 2  controllo      28.8\n#&gt; 3  controllo      37.8\n#&gt; 4  controllo      30.4\n#&gt; 5  controllo      30.6\n#&gt; 6  controllo      38.6\n\n\ntail(df)\n#&gt;       condizione punteggio\n#&gt; 85 psicoterapia2      18.9\n#&gt; 86 psicoterapia2      21.7\n#&gt; 87 psicoterapia2      25.5\n#&gt; 88 psicoterapia2      22.2\n#&gt; 89 psicoterapia2      18.4\n#&gt; 90 psicoterapia2      25.7\n\nEsaminiamo la distribuzione dei dati nei tre gruppi:\n\nggplot(df, aes(x = condizione, y = punteggio, fill = condizione)) +\n  # Il violin plot\n  geom_violin(trim = FALSE) +\n  # Boxplot interno al violino\n  geom_boxplot(width = 0.2, outlier.shape = NA) +\n  labs(\n    title = \"Depressione in funzione del gruppo\",\n    x = \"Gruppo\",\n    y = \"Depressione\"\n  ) +\n  # Rimuovi la legenda \n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nCalcoliamo le medie dei gruppi:\n\ndf |&gt; \n  group_by(condizione) |&gt; \n  summarize(\n    avg = mean(punteggio),\n    std = sd(punteggio)\n  )\n#&gt; # A tibble: 3 √ó 3\n#&gt;   condizione      avg   std\n#&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 controllo      29.8  4.91\n#&gt; 2 psicoterapia1  25.9  4.18\n#&gt; 3 psicoterapia2  20.1  4.35\n\nNel caso presente, desideriamo creare due variabili dummy per codificare il fattore \\(`condizione`\\), assumendo come gruppo di riferimento (baseline) la categoria controllo. Ecco come procedere:\n\ndf$condizione &lt;- factor(df$condizione)\ndf$condizione &lt;- relevel(df$condizione, ref = \"controllo\")\ncontrasts(df$condizione)\n#&gt;               psicoterapia1 psicoterapia2\n#&gt; controllo                 0             0\n#&gt; psicoterapia1             1             0\n#&gt; psicoterapia2             0             1\n\nCon questa impostazione, il modello di regressione assume la forma:\n\\[\nY_i = \\beta_0 \\;+\\; \\beta_1 \\,(\\text{psicoterapia1}_i) \\;+\\; \\beta_2 \\,(\\text{psicoterapia2}_i) \\;+\\; \\varepsilon_i,\n\\]\ndove:\n\n\\(\\beta_0\\) (l‚Äôintercetta) rappresenta la media della condizione di controllo.\n\n\\(\\beta_1\\) indica la differenza tra la media del gruppo psicoterapia1 e la media del gruppo controllo.\n\n\\(\\beta_2\\) indica la differenza tra la media del gruppo psicoterapia2 e la media del gruppo controllo.\n\nLe variabili \\(\\text{psicoterapia1}_i\\) e \\(\\text{psicoterapia2}_i\\) sono i regressori dummy (0/1) che R crea per i due gruppi di psicoterapia, mentre \\(\\varepsilon_i\\) √® il termine di errore.\nIn particolare, nei vari gruppi:\n\nGruppo di controllo: \\(\\text{psicoterapia1}_i = 0\\) e \\(\\text{psicoterapia2}_i = 0\\).\n\\[\nE[Y_{\\text{controllo}}] = \\beta_0.\n\\]\nGruppo psicoterapia1: \\(\\text{psicoterapia1}_i = 1\\) e \\(\\text{psicoterapia2}_i = 0\\).\n\\[\nE[Y_{\\text{psicoterapia1}}] = \\beta_0 + \\beta_1.\n\\]\nGruppo psicoterapia2: \\(\\text{psicoterapia1}_i = 0\\) e \\(\\text{psicoterapia2}_i = 1\\).\n\\[\nE[Y_{\\text{psicoterapia2}}] = \\beta_0 + \\beta_2.\n\\]\n\nIn altre parole, \\(\\beta_1\\) e \\(\\beta_2\\) misurano rispettivamente di quanto la media di psicoterapia1 e di psicoterapia2 si discostino dalla media del gruppo di riferimento (controllo).\n\n\n62.3.1 Stima del modello e interpretazione dei coefficienti\nPer verificare quanto detto, stimiamo il modello di regressione con l‚Äôapproccio frequentista:\n\nfm1 &lt;- lm(punteggio ~ condizione, data = df)\nsummary(fm1)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = punteggio ~ condizione, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -11.668  -2.620  -0.183   2.681  10.128 \n#&gt; \n#&gt; Coefficients:\n#&gt;                         Estimate Std. Error t value Pr(&gt;|t|)\n#&gt; (Intercept)               29.764      0.819   36.33  &lt; 2e-16\n#&gt; condizionepsicoterapia1   -3.873      1.159   -3.34   0.0012\n#&gt; condizionepsicoterapia2   -9.642      1.159   -8.32  1.1e-12\n#&gt; \n#&gt; Residual standard error: 4.49 on 87 degrees of freedom\n#&gt; Multiple R-squared:  0.446,  Adjusted R-squared:  0.434 \n#&gt; F-statistic: 35.1 on 2 and 87 DF,  p-value: 6.75e-12\n\nPossiamo anche calcolare le medie empiriche di ciascun gruppo:\n\nout &lt;- tapply(df$punteggio, df$condizione, mean)\nout\n#&gt;     controllo psicoterapia1 psicoterapia2 \n#&gt;          29.8          25.9          20.1\n\ne quindi le differenze rispetto al controllo:\n\nout[2] - out[1]  # Differenza psico1 - controllo\n#&gt; psicoterapia1 \n#&gt;         -3.87\nout[3] - out[1]  # Differenza psico2 - controllo\n#&gt; psicoterapia2 \n#&gt;         -9.64\n\nLe stime dei coefficienti ottenute da summary(fm1) coincideranno con queste differenze (a meno di arrotondamenti). In altre parole, l‚Äôinferenza (frequentista o bayesiana) sul coefficiente \\(\\beta_j\\) corrisponde all‚Äôinferenza su tale scostamento tra medie.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>¬† <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_1via.html#contrasti-personalizzati",
    "href": "chapters/linear_models/10_anova_1via.html#contrasti-personalizzati",
    "title": "62¬† ANOVA ad una via",
    "section": "62.4 Contrasti personalizzati",
    "text": "62.4 Contrasti personalizzati\nQuando abbiamo un fattore con tre livelli ‚Äî ad esempio, controllo, psicoterapia1 e psicoterapia2 ‚Äî esistono vari schemi di codifica per le variabili dummy. Scegliere lo schema di codifica adeguato significa decidere come interpretare i coefficienti del modello. Per esempio, se vogliamo rispondere alla domanda ¬´la media congiunta delle due psicoterapie √® minore (o maggiore) della media del controllo?¬ª, possiamo definire un contrasto lineare ad hoc che confronti il gruppo controllo con la media delle due psicoterapie.\n\n62.4.1 Possibili approcci\n\nCreare un contrasto lineare ad hoc che confronti \\(\\{\\text{psicoterapia1}, \\text{psicoterapia2}\\}\\) con controllo.\n\nRaggruppare i due livelli di psicoterapia in un nuovo fattore binario (controllo vs.¬†psicoterapia) e condurre un test su questo fattore a due livelli (ma in questo modo si perderebbe la distinzione tra ‚Äúpsicoterapia1‚Äù e ‚Äúpsicoterapia2‚Äù).\n\nIl metodo pi√π flessibile √® definire direttamente contrasti personalizzati sul fattore a tre livelli. In tal modo, possiamo gestire contemporaneamente pi√π confronti, ad esempio:\n\nContrasto 1: controllo vs.¬†media (psicoterapia1, psicoterapia2)\n\nContrasto 2: psicoterapia1 vs.¬†psicoterapia2\n\n\n\n\n62.4.2 Contrasti personalizzati in R\nObiettivo: definire due contrasti ortogonali per confrontare (1) il gruppo di controllo con la media delle due psicoterapie e (2) psicoterapia1 con psicoterapia2.\n\n\n62.4.3 Contrasto 1: Controllo vs.¬†(psico1 + psico2)\n\nContrasto ‚Äúgrezzo‚Äù (non normalizzato):\n\\[\n  (-2,\\; +1,\\; +1)\n  \\quad \\text{con} \\quad -2 + 1 + 1 = 0.\n\\]\nSe usassimo questi pesi direttamente, il coefficiente stimato \\(\\beta_1\\) sarebbe proporzionale alla differenza tra la media del controllo e la media delle due psicoterapie. Tuttavia, il passo da controllo (\\(-2\\)) a ciascuna psicoterapia (\\(+1\\)) √® di 3 unit√†, il che pu√≤ rendere il coefficiente meno intuitivo da leggere.\nNormalizzazione\nPossiamo dividere ogni valore di \\((-2, +1, +1)\\) per la somma assoluta (o per la radice della somma dei quadrati, o per un altro fattore) al fine di ottenere contrasti pi√π semplici.\nAd esempio, se dividiamo \\((-2, +1, +1)\\) per 3, otteniamo \\(\\bigl(-\\tfrac{2}{3}, +\\tfrac{1}{3}, +\\tfrac{1}{3}\\bigr)\\). In tal caso, passare da controllo a psicoterapia fa variare il contrasto di 1 (anzich√© di 3).\n\n\n\n62.4.4 Contrasto 2: psico1 vs.¬†psico2\n\nContrasto ‚Äúgrezzo‚Äù:\n\\[\n   (\\,0,\\; +1,\\; -1\\,)\n   \\quad \\text{con} \\quad 0 + 1 + (-1) = 0.\n\\]\nQuesto pesi confrontano direttamente psicoterapia1 con psicoterapia2.\nNormalizzazione (opzionale)\nPossiamo anche qui dividere per la radice della somma dei quadrati \\(\\sqrt{(0^2 + 1^2 + (-1)^2)}= \\sqrt{2}\\), oppure lasciare i pesi cos√¨ (poich√© qui gi√† passare da p1 a p2 equivale a 2 unit√†, e potrebbe essere chiaro abbastanza).\n\nNel codice seguente, si √® scelto di riscalare (o ‚Äúnormalizzare‚Äù) i pesi in modo leggermente diverso, ottenendo numeri come 0.6667 e -0.3333. L‚Äôimportante √® che:\n\nLa somma dei pesi in ciascun contrasto rimanga 0.\n\nI due contrasti siano ortogonali (i prodotti incrociati dei pesi per ogni livello sommano a 0).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>¬† <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_1via.html#codice-r-per-impostare-e-verificare-i-contrasti",
    "href": "chapters/linear_models/10_anova_1via.html#codice-r-per-impostare-e-verificare-i-contrasti",
    "title": "62¬† ANOVA ad una via",
    "section": "62.5 Codice R per impostare e verificare i Contrasti",
    "text": "62.5 Codice R per impostare e verificare i Contrasti\nDi seguito mostriamo un esempio concreto. Prima descriviamo la matrice di contrasti ‚Äúgrezza‚Äù e poi quella normalizzata usata nel codice.\n\n62.5.1 Matrice di contrasti ‚Äúgrezza‚Äù\n\n# Contrasto 1 (grezzo):  -2, +1, +1\n# Contrasto 2 (grezzo):   0, +1, -1\n\nmy_contrasts_raw &lt;- matrix(c(\n  -2,  0,  # controllo\n   1, +1,  # psicoterapia1\n   1, -1   # psicoterapia2\n), ncol = 2, byrow = TRUE)\n\ncolnames(my_contrasts_raw) &lt;- c(\"Ctrl_vs_PsicoMean\", \"P1_vs_P2\")\nrownames(my_contrasts_raw) &lt;- c(\"controllo\",\"psicoterapia1\",\"psicoterapia2\")\nmy_contrasts_raw\n#&gt;               Ctrl_vs_PsicoMean P1_vs_P2\n#&gt; controllo                    -2        0\n#&gt; psicoterapia1                 1        1\n#&gt; psicoterapia2                 1       -1\n\n\n\n62.5.2 Matrice di contrasti ‚Äúnormalizzata‚Äù (quella effettivamente nel codice)\nNel codice che segue, i pesi sono stati riscalati per avere differenze di ‚Äú1‚Äù anzich√© ‚Äú3‚Äù o ‚Äú2‚Äù quando si passa da un gruppo all‚Äôaltro. Puoi notare, per il primo contrasto, i valori \\((+0.6667, -0.3333, -0.3333)\\) invece di \\((+1, -0.5, -0.5)\\) o \\((-2, +1, +1)\\). Sono solo versioni multiplicativamente equivalenti.\n\nset.seed(123)\n\n# Esempio: definizione della matrice di contrasti\nmy_contrasts &lt;- matrix(c(\n  0.6667,  0,    # controllo  = +0.6667\n  -0.3333, 0.5,  # p1         = -0.3333\n  -0.3333, -0.5  # p2         = -0.3333\n), ncol = 2, byrow = TRUE)\n\ncolnames(my_contrasts) &lt;- c(\"Ctrl_vs_PsicoMean\", \"P1_vs_P2\")\nrownames(my_contrasts) &lt;- c(\"controllo\", \"psicoterapia1\", \"psicoterapia2\")\n\n# Verifica: ogni colonna deve sommare a 0\ncolSums(my_contrasts)  # dovrebbero essere circa (0, 0)\n#&gt; Ctrl_vs_PsicoMean          P1_vs_P2 \n#&gt;             1e-04             0e+00\n\n# Verifica: i due contrasti sono ortogonali?\nsum(my_contrasts[,1] * my_contrasts[,2])  # dovrebbe essere 0\n#&gt; [1] 0\n\n\n\n62.5.3 Applicazione al modello\n\n# 1) Convertiamo 'condizione' in fattore (se non gi√† fattore)\ndf$condizione &lt;- factor(df$condizione)\n\n# 2) Assegnamo la matrice di contrasti al fattore\ncontrasts(df$condizione) &lt;- my_contrasts\n\n# 3) Stimiamo il modello di regressione lineare\nmod_custom &lt;- lm(punteggio ~ condizione, data = df)\n\n# 4) Esaminiamo il riepilogo\nsummary(mod_custom)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = punteggio ~ condizione, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -11.668  -2.620  -0.183   2.681  10.128 \n#&gt; \n#&gt; Coefficients:\n#&gt;                             Estimate Std. Error t value Pr(&gt;|t|)\n#&gt; (Intercept)                   25.259      0.473   53.40  &lt; 2e-16\n#&gt; condizioneCtrl_vs_PsicoMean    6.758      1.003    6.73  1.7e-09\n#&gt; condizioneP1_vs_P2             5.770      1.159    4.98  3.2e-06\n#&gt; \n#&gt; Residual standard error: 4.49 on 87 degrees of freedom\n#&gt; Multiple R-squared:  0.446,  Adjusted R-squared:  0.434 \n#&gt; F-statistic: 35.1 on 2 and 87 DF,  p-value: 6.75e-12",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>¬† <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_1via.html#interpretazione-dei-coefficienti",
    "href": "chapters/linear_models/10_anova_1via.html#interpretazione-dei-coefficienti",
    "title": "62¬† ANOVA ad una via",
    "section": "62.6 Interpretazione dei coefficienti",
    "text": "62.6 Interpretazione dei coefficienti\n\nIntercetta (\\(\\hat{\\alpha}\\))\nIn base allo schema di contrasti adottato, pu√≤ non coincidere con la media effettiva di uno dei tre gruppi. Spesso rappresenta una qualche combinazione lineare delle medie di controllo, psicoterapia1 e psicoterapia2.\nPrimo coefficiente (‚ÄúCtrl_vs_PsicoMean‚Äù)\nConfronta la media del gruppo di controllo con la media (eventualmente pesata) delle due psicoterapie.\n\nSe √® positivo, il controllo ha una media maggiore rispetto a quella (combinata) delle psicoterapie.\n\nSe √® negativo, indica il contrario (psicoterapie &gt; controllo).\n\nSecondo coefficiente (‚ÄúP1_vs_P2‚Äù)\nConfronta direttamente psicoterapia1 con psicoterapia2.\n\nSe √® positivo, psicoterapia1 ha un punteggio maggiore (in media) di psicoterapia2.\n\nSe √® negativo, psicoterapia2 supera psicoterapia1.\n\n\nPer controllare manualmente queste differenze, puoi calcolare:\n\n\\(\\text{controllo} - \\frac{\\text{psicoterapia1} + \\text{psicoterapia2}}{2}\\):\n\n\nout[1] - (out[2] + out[3]) / 2\n#&gt; controllo \n#&gt;      6.76\n\ndove out[i] √® la media empirica del gruppo \\(i\\).\n\n\\(\\text{psicoterapia1} - \\text{psicoterapia2}\\):\n\n\nout[2] - out[3]\n#&gt; psicoterapia1 \n#&gt;          5.77\n\nIn sintesi,\n\nLa matrice grezza \\(\\begin{pmatrix} -2 & 0 \\\\ 1 & 1 \\\\ 1 & -1 \\end{pmatrix}\\) e la matrice normalizzata (con valori decimali) rappresentano lo stesso schema di contrasti, ma con differenti scale numeriche.\n\nL‚Äôaspetto essenziale √® che ciascun contrasto sommi a 0 e che i due contrasti siano ortogonali (prodotto incrociato dei pesi = 0), garantendo interpretazioni indipendenti.\n\nNormalizzare i pesi modifica il valore numerico dei coefficienti, ma non la loro significativit√† statistica.\n\nScegliendo opportunamente la matrice dei contrasti, possiamo verificare se la media congiunta di psicoterapia1 e psicoterapia2 differisce da quella di controllo e, contemporaneamente, se psicoterapia1 differisce da psicoterapia2. L‚Äôeventuale normalizzazione dei pesi non incide sulle conclusioni del test, ma influenza la scala numerica dei coefficienti.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>¬† <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_1via.html#pacchetto-emmeans",
    "href": "chapters/linear_models/10_anova_1via.html#pacchetto-emmeans",
    "title": "62¬† ANOVA ad una via",
    "section": "62.7 Pacchetto emmeans",
    "text": "62.7 Pacchetto emmeans\nLe stesse analisi descritte sopra possono essere svolte utilizzando le funzioni del pacchetto emmeans. L‚Äôidea √®:\n\nStimare un modello lineare (come prima).\n\nCalcolare le stime delle medie marginali (le ‚Äúmeans‚Äù del fattore condizione) tramite emmeans().\n\nDefinire i contrasti di interesse con la funzione contrast().\n\nIn questo modo, √® possibile ottenere stime delle medie di ciascun gruppo e confrontarle (ad esempio ‚Äúcontrollo‚Äù vs.¬†‚Äúmedia delle psicoterapie‚Äù o ‚Äúpsicoterapia1‚Äù vs.¬†‚Äúpsicoterapia2‚Äù), anche in forma di test statistici (p-value, intervalli di confidenza, ecc.).\n\n62.7.1 Preparazione del modello\nUsiamo ora un modello bayesiano, con prior non informativi o debolmente informativi:\n\nmod &lt;- brm(punteggio ~ condizione, data = df, backend = \"cmdstanr\")\n\n\nsummary(mod)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: punteggio ~ condizione \n#&gt;    Data: df (Number of observations: 90) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;                             Estimate Est.Error l-95% CI u-95% CI Rhat\n#&gt; Intercept                      25.25      0.48    24.30    26.21 1.00\n#&gt; condizioneCtrl_vs_PsicoMean     6.77      1.02     4.79     8.77 1.00\n#&gt; condizioneP1_vs_P2              5.73      1.20     3.34     8.03 1.00\n#&gt;                             Bulk_ESS Tail_ESS\n#&gt; Intercept                       4391     3161\n#&gt; condizioneCtrl_vs_PsicoMean     4794     3220\n#&gt; condizioneP1_vs_P2              4632     2764\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     4.54      0.35     3.93     5.30 1.00     4090     2859\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\n62.7.2 Calcolo delle medie marginali con emmeans\nCalcoliamo le stime delle medie (ls-means) per ciascun livello di ‚Äòcondizione‚Äô:\n\nem &lt;- emmeans(mod, specs = \"condizione\")\nem\n#&gt;  condizione    emmean lower.HPD upper.HPD\n#&gt;  controllo       29.8      28.3      31.5\n#&gt;  psicoterapia1   25.9      24.2      27.6\n#&gt;  psicoterapia2   20.1      18.4      21.8\n#&gt; \n#&gt; Point estimate displayed: median \n#&gt; HPD interval probability: 0.95\n\nQuesto oggetto em contiene le medie stimate (e i relativi errori standard) per i tre gruppi: ‚Äúcontrollo‚Äù, ‚Äúpsicoterapia1‚Äù e ‚Äúpsicoterapia2‚Äù.\n\n\n62.7.3 Confronti (pairwise) tra i gruppi\nConfronti a coppie tra tutti i livelli di ‚Äòcondizione‚Äô (psicoterapia1 vs controllo, ecc.):\n\npairs(em)\n#&gt;  contrast                      estimate lower.HPD upper.HPD\n#&gt;  controllo - psicoterapia1         3.91      1.62      6.21\n#&gt;  controllo - psicoterapia2         9.64      7.24     11.94\n#&gt;  psicoterapia1 - psicoterapia2     5.74      3.30      7.96\n#&gt; \n#&gt; Point estimate displayed: median \n#&gt; HPD interval probability: 0.95\n\n\n\n62.7.4 Contrasti personalizzati\nReplichiamo i contrasti ‚Äúad hoc‚Äù (‚Äúcontrollo vs (psico1+psico2)‚Äù e ‚Äúpsicoterapia1 vs psicoterapia2‚Äù) utilizzati in precedenza:\n\n# Definiamo i contrasti desiderati\nmy_list &lt;- list(\n  \"Ctrl_vs_PsicoMean\" = \n    c(\"controllo\" = 1, \"psicoterapia1\" = -0.5, \"psicoterapia2\" = -0.5),\n  \"P1_vs_P2\"          = \n    c(\"controllo\" = 0,  \"psicoterapia1\" = 1,    \"psicoterapia2\" = -1)\n)\n\ncontrast(em, method = my_list)\n#&gt;  contrast          estimate lower.HPD upper.HPD\n#&gt;  Ctrl_vs_PsicoMean     6.76      4.78      8.74\n#&gt;  P1_vs_P2              5.74      3.30      7.96\n#&gt; \n#&gt; Point estimate displayed: median \n#&gt; HPD interval probability: 0.95",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>¬† <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_1via.html#altre-opzioni-utili-di-emmeans",
    "href": "chapters/linear_models/10_anova_1via.html#altre-opzioni-utili-di-emmeans",
    "title": "62¬† ANOVA ad una via",
    "section": "62.8 Altre opzioni utili di emmeans",
    "text": "62.8 Altre opzioni utili di emmeans\n\nCredibility intervals:\n\n\nconfint( contrast(em, method = my_list) )\n#&gt;  contrast          estimate lower.HPD upper.HPD\n#&gt;  Ctrl_vs_PsicoMean     6.76      4.78      8.74\n#&gt;  P1_vs_P2              5.74      3.30      7.96\n#&gt; \n#&gt; Point estimate displayed: median \n#&gt; HPD interval probability: 0.95\n\nper intervalli di confidenza dei contrasti specificati.\n\nTest corretti per confronti multipli:\n\n\ncontrast(em, method = my_list, adjust = \"bonferroni\")\n#&gt;  contrast          estimate lower.HPD upper.HPD\n#&gt;  Ctrl_vs_PsicoMean     6.76      4.78      8.74\n#&gt;  P1_vs_P2              5.74      3.30      7.96\n#&gt; \n#&gt; Point estimate displayed: median \n#&gt; HPD interval probability: 0.95\n\no altre correzioni (ad es. \"holm\", \"sidak\", \"none\").\n\nVisualizzazione:\nIl pacchetto emmeans ha anche funzioni per la visualizzazione (plot(em), pwpp(), ecc.).\n\n\nplot(em)\n\n\n\n\n\n\n\n\nIn conclusione, usare emmeans semplifica notevolmente:\n\nIl calcolo delle medie stimate (o ‚Äúls-means‚Äù) di ciascun livello di un fattore in un modello lineare (o GLM, o mixed model, ecc.).\n\nLa definizione di contrasti personalizzati, senza dover ridefinire manualmente la matrice di contrasti nel modello (come si fa con contrasts(fattore) &lt;- ...).\n\nLa produzione di test e intervalli di confidenza per i confronti desiderati, integrando anche correzioni per confronti multipli se necessario.\n\nIn questo modo, √® possibile ottenere esattamente gli stessi risultati che otterresti impostando manualmente i contrasti a livello di design matrix, ma con un approccio pi√π flessibile e con meno passaggi.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>¬† <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_1via.html#riflessioni-conclusive",
    "href": "chapters/linear_models/10_anova_1via.html#riflessioni-conclusive",
    "title": "62¬† ANOVA ad una via",
    "section": "62.9 Riflessioni Conclusive",
    "text": "62.9 Riflessioni Conclusive\nL‚ÄôANOVA ad una via non √® altro che l‚Äôapplicazione del modello di regressione al caso di una variabile dipendente quantitativa e di un fattore con pi√π di due livelli. L‚Äôaspetto pi√π utile dell‚ÄôANOVA riguarda i contrasti, ovvero specifiche ipotesi sulla differenza tra le medie.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>¬† <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_1via.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/10_anova_1via.html#informazioni-sullambiente-di-sviluppo",
    "title": "62¬† ANOVA ad una via",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: US/Pacific\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] rstan_2.32.6         StanHeaders_2.32.10  emmeans_1.10.6      \n#&gt;  [4] brms_2.22.0          Rcpp_1.0.13-1        bayestestR_0.15.0   \n#&gt;  [7] posterior_1.6.0.9000 cmdstanr_0.8.1       ggokabeito_0.1.0    \n#&gt; [10] see_0.9.0            gridExtra_2.3        patchwork_1.3.0     \n#&gt; [13] bayesplot_1.11.1     psych_2.4.12         scales_1.3.0        \n#&gt; [16] markdown_1.13        knitr_1.49           lubridate_1.9.4     \n#&gt; [19] forcats_1.0.0        stringr_1.5.1        dplyr_1.1.4         \n#&gt; [22] purrr_1.0.2          readr_2.1.5          tidyr_1.3.1         \n#&gt; [25] tibble_3.2.1         ggplot2_3.5.1        tidyverse_2.0.0     \n#&gt; [28] rio_1.2.3            here_1.0.1          \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1     farver_2.1.2         loo_2.8.0           \n#&gt;  [4] fastmap_1.2.0        tensorA_0.36.2.1     pacman_0.5.1        \n#&gt;  [7] digest_0.6.37        timechange_0.3.0     estimability_1.5.1  \n#&gt; [10] lifecycle_1.0.4      processx_3.8.5       magrittr_2.0.3      \n#&gt; [13] compiler_4.4.2       rlang_1.1.4          tools_4.4.2         \n#&gt; [16] utf8_1.2.4           yaml_2.3.10          data.table_1.16.4   \n#&gt; [19] labeling_0.4.3       bridgesampling_1.1-2 htmlwidgets_1.6.4   \n#&gt; [22] curl_6.1.0           pkgbuild_1.4.5       mnormt_2.1.1        \n#&gt; [25] plyr_1.8.9           abind_1.4-8          withr_3.0.2         \n#&gt; [28] grid_4.4.2           stats4_4.4.2         colorspace_2.1-1    \n#&gt; [31] inline_0.3.21        insight_1.0.1        cli_3.6.3           \n#&gt; [34] mvtnorm_1.3-3        rmarkdown_2.29       generics_0.1.3      \n#&gt; [37] RcppParallel_5.1.9   reshape2_1.4.4       tzdb_0.4.0          \n#&gt; [40] parallel_4.4.2       matrixStats_1.5.0    vctrs_0.6.5         \n#&gt; [43] V8_6.0.0             Matrix_1.7-1         jsonlite_1.8.9      \n#&gt; [46] hms_1.1.3            glue_1.8.0           codetools_0.2-20    \n#&gt; [49] ps_1.8.1             distributional_0.5.0 stringi_1.8.4       \n#&gt; [52] gtable_0.3.6         QuickJSR_1.5.1       munsell_0.5.1       \n#&gt; [55] pillar_1.10.1        htmltools_0.5.8.1    Brobdingnag_1.2-9   \n#&gt; [58] R6_2.5.1             rprojroot_2.0.4      evaluate_1.0.1      \n#&gt; [61] lattice_0.22-6       backports_1.5.0      rstantools_2.4.0    \n#&gt; [64] coda_0.19-4.1        nlme_3.1-166         checkmate_2.3.2     \n#&gt; [67] xfun_0.50            pkgconfig_2.0.3",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>¬† <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_1via.html#bibliografia",
    "href": "chapters/linear_models/10_anova_1via.html#bibliografia",
    "title": "62¬† ANOVA ad una via",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>¬† <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_anova_2vie.html",
    "href": "chapters/linear_models/11_anova_2vie.html",
    "title": "63¬† ANOVA ad due vie",
    "section": "",
    "text": "63.1 Introduzione\nL‚ÄôANOVA a due o pi√π vie estende il caso dell‚ÄôANOVA ad una via alla presenza di molteplici criteri di classificazione. Qui ci concentreremo sull‚ÄôANOVA a due vie.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>¬† <span class='chapter-title'>ANOVA ad due vie</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_anova_2vie.html#introduzione",
    "href": "chapters/linear_models/11_anova_2vie.html#introduzione",
    "title": "63¬† ANOVA ad due vie",
    "section": "",
    "text": "63.1.1 Pattern delle medie nella classificazione a due vie\nImmaginiamo di disporre delle medie di popolazione. La notazione per la classificazione a due vie √® illustrata nella seguente tabella:\n\n\n\n\nC1\nC2\n‚Ä¶\nCc\nTotale colonna\n\n\n\n\nR1\n¬µ11\n¬µ12\n‚Ä¶\n¬µ1c\n¬µ1:\n\n\nR2\n¬µ21\n¬µ22\n‚Ä¶\n¬µ2c\n¬µ2:\n\n\n‚Ä¶\n‚Ä¶\n‚Ä¶\n‚Ä¶\n‚Ä¶\n‚Ä¶\n\n\nRr\n¬µr1\n¬µr2\n‚Ä¶\n¬µrc\n¬µr:\n\n\n‚Äî‚Äî‚Äî‚Äî\n‚Äî‚Äî-\n‚Äî‚Äî-\n‚Äî‚Äî\n‚Äî‚Äî-\n‚Äî‚Äî‚Äî‚Äî‚Äî-\n\n\nTotale riga\n¬µ:1\n¬µ:2\n‚Ä¶\n¬µ:c\n¬µ::\n\n\n\nQui, i fattori \\(R\\) e \\(C\\) (cos√¨ denominati in riferimento alle righe e alle colonne della tabella delle medie) presentano rispettivamente \\(r\\) e \\(c\\) categorie. Indichiamo le categorie dei fattori come \\(R_j\\) e \\(C_k\\).\nAll‚Äôinterno di ogni cella del disegno sperimentale‚Äîcio√® per ciascuna combinazione di categorie \\(\\{R_j, C_k\\}\\) dei due fattori‚Äîsi trova una media di popolazione \\(\\mu_{jk}\\) relativa alla variabile di risposta.\nPer descrivere le medie su righe, colonne e quella complessiva, utilizziamo la notazione a ‚Äúpunti‚Äù:\n\\[\n\\mu_{j:} \\;=\\; \\frac{\\sum_{k=1}^{c} \\mu_{jk}}{c}\n\\quad\\text{(media marginale sulla riga $j$)},\n\\]\n\\[\n\\mu_{:k} \\;=\\; \\frac{\\sum_{j=1}^{r} \\mu_{jk}}{r}\n\\quad\\text{(media marginale sulla colonna $k$)},\n\\]\n\\[\n\\mu_{::} \\;=\\; \\frac{\\sum_{j=1}^{r}\\sum_{k=1}^{c} \\mu_{jk}}{r\\,c}\n\\;=\\; \\frac{\\sum_{j=1}^{r} \\mu_{j:}}{r}\n\\;=\\; \\frac{\\sum_{k=1}^{c} \\mu_{:k}}{c}\n\\quad\\text{(media generale, o grand mean)}.\n\\]\n\n\n\n63.1.2 Effetti principali e interazione\nSe i fattori \\(R\\) e \\(C\\) non interagiscono nel determinare la variabile di risposta, allora l‚Äôeffetto di uno di essi, a parit√† di categoria dell‚Äôaltro, rimane costante. In termini pratici, la differenza fra le medie di cella \\(\\mu_{jk} - \\mu_{j'k}\\)‚Äîquando confrontiamo due categorie di \\(R\\), ad esempio \\(R_j\\) e \\(R_{j'}\\)‚Äî√® la stessa per tutte le categorie di \\(C\\) (cio√® per \\(k = 1, 2, \\dots, c\\)).\nDi conseguenza, la differenza fra le medie nelle righe √® uguale alla differenza fra le corrispondenti medie marginali di riga:\n\\[\n\\mu_{jk} - \\mu_{j'k} \\;=\\; \\mu_{jk'} - \\mu_{j'k'} \\;=\\; \\mu_{j:} - \\mu_{j':}\n\\quad\\text{per ogni } j, j' \\text{ e } k, k'.\n\\]\nUn altro modo di vedere questa assenza di interazione √® attraverso i profili di medie di cella, che in questo caso risultano ‚Äúparalleli‚Äù. Se i profili sono paralleli, allora la differenza fra \\(\\mu_{j1}\\) e \\(\\mu_{j2}\\) (categorie \\(C_1\\) e \\(C_2\\)) resta costante fra le diverse righe \\(j = 1, 2\\), e coincide con la differenza fra le medie marginali di colonna, \\(\\mu_{:1} - \\mu_{:2}\\).\nL‚Äôinterazione √® un concetto simmetrico: se il fattore \\(R\\) interagisce con il fattore \\(C\\), vale anche il contrario. Quando non si verifica interazione, l‚Äôeffetto principale (o main effect) di ogni fattore corrisponde semplicemente alla differenza fra le medie marginali di popolazione relative a quel fattore.\nLa figura seguente presentata diversi scenari possibili.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>¬† <span class='chapter-title'>ANOVA ad due vie</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_anova_2vie.html#simulazione",
    "href": "chapters/linear_models/11_anova_2vie.html#simulazione",
    "title": "63¬† ANOVA ad due vie",
    "section": "63.2 Simulazione",
    "text": "63.2 Simulazione\nPer fare un esempio concreto, simuliamo dei dati seguendo lo schema utilizzato con l‚ÄôANOVA ad una via. In questo caso, aggiungiamo un secondo fattore: la gravit√† dei sintomi.\n\n# Imposta un seme per riproducibilit√† (opzionale)\nset.seed(123)\n\n# Definiamo il numero di osservazioni per ogni cella\nn &lt;- 30\n\n# Definiamo le categorie dei fattori\ngravita &lt;- c(\"molto_gravi\", \"poco_gravi\")\ncondizione &lt;- c(\"controllo\", \"psicoterapia1\", \"psicoterapia2\")\n\n# Definiamo la deviazione standard (ipotizziamo la stessa per tutte le celle)\nsd_value &lt;- 5\n\n# Definiamo le medie attese per ciascuna combinazione (gravita x condizione)\n# Esempio:\n# - Pazienti molto gravi:  (controllo=30, psico1=25, psico2=20)\n# - Pazienti poco gravi:   (controllo=25, psico1=20, psico2=15)\n\nmean_table &lt;- matrix(\n  c(30, 25, 20,  # molto_gravi\n    25, 20, 15), # poco_gravi\n  nrow = 2,      # 2 righe per \"molto_gravi\" e \"poco_gravi\"\n  ncol = 3,      # 3 colonne per \"controllo\", \"psicoterapia1\", \"psicoterapia2\"\n  byrow = TRUE\n)\n\n# Crea un data frame vuoto che riempiremo con i dati simulati\ndf &lt;- data.frame()\n\nfor (i in seq_along(gravita)) {\n  for (j in seq_along(condizione)) {\n    # Estraiamo la media corrispondente alla combinazione (i, j)\n    current_mean &lt;- mean_table[i, j]\n    \n    # Generiamo 'n' osservazioni normali con media = current_mean e sd = sd_value\n    simulated_data &lt;- rnorm(n, mean = current_mean, sd = sd_value)\n    \n    # Creiamo un data frame temporaneo per questa combinazione\n    temp_df &lt;- data.frame(\n      gravita    = gravita[i],\n      condizione = condizione[j],\n      punteggio  = simulated_data\n    )\n    \n    # Append al data frame finale\n    df &lt;- rbind(df, temp_df)\n  }\n}\n\nEsaminiamo le medie:\n\n# Esempio di sintesi statistica\naggregate(punteggio ~ gravita + condizione, data = df, mean)\n#&gt;       gravita    condizione punteggio\n#&gt; 1 molto_gravi     controllo      29.8\n#&gt; 2  poco_gravi     controllo      24.5\n#&gt; 3 molto_gravi psicoterapia1      25.9\n#&gt; 4  poco_gravi psicoterapia1      19.1\n#&gt; 5 molto_gravi psicoterapia2      20.1\n#&gt; 6  poco_gravi psicoterapia2      15.8\n\nRappresentiamo graficamente la distribuzione dei dati nelle varie condizioni:\n\nggplot(df, aes(x = condizione, y = punteggio, fill = gravita)) +\n  geom_boxplot(position = position_dodge()) +\n  labs(title = \"Simulazione dati: Effetto gravit√† e condizione\",\n       x = \"Condizione sperimentale\",\n       y = \"Punteggio\")\n\n\n\n\n\n\n\n\nAddattiamo ai dati un modello bayesiano:\n\nmod &lt;- brm(\n  punteggio ~ gravita * condizione, \n  data = df,\n  backend = \"cmdstanr\"\n)\n\nEsaminiamo le stime del modello:\n\nconditional_effects(mod, \"condizione:gravita\")\n\n\n\n\n\n\n\n\nUn sommario delle stime a posteriori si ottiene nel modo seguente:\n\nsummary(mod)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: punteggio ~ gravita * condizione \n#&gt;    Data: df (Number of observations: 180) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;                                           Estimate Est.Error l-95% CI\n#&gt; Intercept                                    29.75      0.86    28.03\n#&gt; gravitapoco_gravi                            -5.20      1.21    -7.61\n#&gt; condizionepsicoterapia1                      -3.86      1.23    -6.24\n#&gt; condizionepsicoterapia2                      -9.61      1.23   -12.05\n#&gt; gravitapoco_gravi:condizionepsicoterapia1    -1.61      1.72    -4.99\n#&gt; gravitapoco_gravi:condizionepsicoterapia2     0.83      1.72    -2.53\n#&gt;                                           u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept                                    31.45 1.00     2133     2829\n#&gt; gravitapoco_gravi                            -2.87 1.00     1866     2352\n#&gt; condizionepsicoterapia1                      -1.36 1.00     2240     2404\n#&gt; condizionepsicoterapia2                      -7.16 1.00     2274     2624\n#&gt; gravitapoco_gravi:condizionepsicoterapia1     1.85 1.00     1924     2338\n#&gt; gravitapoco_gravi:condizionepsicoterapia2     4.23 1.00     2071     2416\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     4.79      0.25     4.33     5.32 1.00     3481     2699\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nL‚Äôesame dell‚Äôoutput precedente mostra come sia difficile rispondere alle domende di interesse mediante l‚Äôesame dei singoli coefficienti. Per valutare gli effetti principali e la presenza di interazione si usa invece un metodo basato sul confronto tra modelli.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>¬† <span class='chapter-title'>ANOVA ad due vie</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_anova_2vie.html#confronto-tra-modelli",
    "href": "chapters/linear_models/11_anova_2vie.html#confronto-tra-modelli",
    "title": "63¬† ANOVA ad due vie",
    "section": "63.3 Confronto tra Modelli",
    "text": "63.3 Confronto tra Modelli\nIl test degli effetti principali e dell‚Äôinterazione viene eseguito, nell‚Äôapproccio frequentista, calcolando R^2 per i vari modelli per poi fare una differenza tra gli R^2 pesati per i gradi di libert√†. Questa differenza si distribuisce come F e quindi disponiamo di una distribuzione campionaria nota per questa statistica. Il test si fa nel solito modo, ovvero ci si chiede se la differenza in R^2 osservata √® sufficientemente piccola da potere essere attribuita al caso, sotto l‚Äôipotesi che i due modelli sono equivalenti, oppure no.\nI test bayesiani si basano su una logica diversa, anche se ha alcuni punti in comune. Il confronto tra modelli si basa su una quantit√† chiamata LOO (Leave-One-Out cross-validation).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>¬† <span class='chapter-title'>ANOVA ad due vie</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_anova_2vie.html#cos√®-loo-leave-one-out-cross-validation",
    "href": "chapters/linear_models/11_anova_2vie.html#cos√®-loo-leave-one-out-cross-validation",
    "title": "63¬† ANOVA ad due vie",
    "section": "63.4 Cos‚Äô√® LOO (Leave-One-Out cross-validation)?",
    "text": "63.4 Cos‚Äô√® LOO (Leave-One-Out cross-validation)?\nLOO √® un metodo per stimare quanto bene un modello predice nuovi dati. In particolare, misura quanto il modello √® in grado di generalizzare oltre i dati usati per costruirlo.\n\nCome funziona:\nSi rimuove iterativamente una osservazione dal dataset, si stima il modello sui dati rimanenti e si valuta quanto bene il modello predice l‚Äôosservazione esclusa. Questo processo viene ripetuto per tutte le osservazioni.\nNel contesto Bayesiano:\nPoich√© ricalcolare il modello per ogni possibile sottogruppo di dati sarebbe computazionalmente oneroso, si usa una stima approssimativa di LOO basata sul concetto di PSIS-LOO (Pareto Smoothed Importance Sampling). Questa stima √® disponibile direttamente in brms tramite il comando loo().",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>¬† <span class='chapter-title'>ANOVA ad due vie</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_anova_2vie.html#indicatori-principali-nei-risultati-di-loo",
    "href": "chapters/linear_models/11_anova_2vie.html#indicatori-principali-nei-risultati-di-loo",
    "title": "63¬† ANOVA ad due vie",
    "section": "63.5 Indicatori principali nei risultati di LOO",
    "text": "63.5 Indicatori principali nei risultati di LOO\n\nelpd (expected log predictive density):\n√à la somma logaritmica delle probabilit√† predittive del modello per ogni osservazione, calcolata dopo aver escluso quella stessa osservazione. Valori pi√π alti indicano un modello che predice meglio.\nelpd_diff:\nDifferenza di elpd tra due modelli. Se \\(\\text{elpd}_{\\text{model1}} &gt; \\text{elpd}_{\\text{model2}}\\), il modello 1 √® preferito.\nse_diff (standard error of difference):\nL‚Äôincertezza associata a elpd_diff. Se |elpd_diff| √® molto piccolo rispetto a se_diff, la differenza tra i modelli non √® considerata robusta.\n\n\nNel caso presente, confrontiamo due modelli:\n\nmod1: Modello completo (con interazione).\n\nmod: Modello senza interazione (solo effetti principali).\n\n\nmod1 &lt;- brm(\n  punteggio ~ gravita + condizione, \n  data = df,\n  backend = \"cmdstanr\"\n)\n\n\n63.5.1 Confronto LOO\n\n# Confronto via LOO\nloo_full &lt;- loo(mod)\nloo_noint  &lt;- loo(mod1)\nloo_compare(loo_full, loo_noint)\n#&gt;      elpd_diff se_diff\n#&gt; mod1  0.0       0.0   \n#&gt; mod  -0.7       1.5\n\n\nelpd_diff = -0.9: Il modello con interazione (mod) ha un elpd leggermente pi√π basso rispetto al modello senza interazione (mod1). Questo significa che il modello senza interazione √® leggermente preferibile in termini di capacit√† predittiva sui nuovi dati.\nse_diff = 1.5: L‚Äôincertezza associata alla differenza di elpd √® molto pi√π grande della differenza stessa (elpd_diff / se_diff). Questo implica che non c‚Äô√® evidenza sufficiente per concludere che uno dei due modelli sia chiaramente migliore.\n\nIn conclusione,\n\nIl modello senza interazione (mod1) √® leggermente preferibile in termini di LOO-IC, ma la differenza √® trascurabile e non robusta, data l‚Äôelevata incertezza (se_diff = 1.5).\nInterpretazione pratica:\n\nNon ci sono prove sufficienti per preferire il modello con interazione (mod) rispetto al modello senza interazione (mod1).\nIn assenza di altre considerazioni teoriche che giustifichino l‚Äôinclusione dell‚Äôinterazione, il modello pi√π semplice (mod1, senza interazione) √® probabilmente una scelta migliore.\n\n\nSi procede in un modo simile per i test degli effetti principali. In quel caso potremmo confrontrare un modello con gli effetti additivi dei due fattori con un modello con un unico fattore.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>¬† <span class='chapter-title'>ANOVA ad due vie</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_anova_2vie.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/11_anova_2vie.html#informazioni-sullambiente-di-sviluppo",
    "title": "63¬† ANOVA ad due vie",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: US/Pacific\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] rstan_2.32.6         StanHeaders_2.32.10  bridgesampling_1.1-2\n#&gt;  [4] loo_2.8.0            emmeans_1.10.6       brms_2.22.0         \n#&gt;  [7] Rcpp_1.0.13-1        bayestestR_0.15.0    posterior_1.6.0.9000\n#&gt; [10] cmdstanr_0.8.1       ggokabeito_0.1.0     see_0.9.0           \n#&gt; [13] gridExtra_2.3        patchwork_1.3.0      bayesplot_1.11.1    \n#&gt; [16] psych_2.4.12         scales_1.3.0         markdown_1.13       \n#&gt; [19] knitr_1.49           lubridate_1.9.4      forcats_1.0.0       \n#&gt; [22] stringr_1.5.1        dplyr_1.1.4          purrr_1.0.2         \n#&gt; [25] readr_2.1.5          tidyr_1.3.1          tibble_3.2.1        \n#&gt; [28] ggplot2_3.5.1        tidyverse_2.0.0      rio_1.2.3           \n#&gt; [31] here_1.0.1          \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1     farver_2.1.2         fastmap_1.2.0       \n#&gt;  [4] tensorA_0.36.2.1     pacman_0.5.1         digest_0.6.37       \n#&gt;  [7] timechange_0.3.0     estimability_1.5.1   lifecycle_1.0.4     \n#&gt; [10] processx_3.8.5       magrittr_2.0.3       compiler_4.4.2      \n#&gt; [13] rlang_1.1.4          tools_4.4.2          yaml_2.3.10         \n#&gt; [16] data.table_1.16.4    labeling_0.4.3       htmlwidgets_1.6.4   \n#&gt; [19] pkgbuild_1.4.5       mnormt_2.1.1         curl_6.1.0          \n#&gt; [22] plyr_1.8.9           abind_1.4-8          withr_3.0.2         \n#&gt; [25] grid_4.4.2           stats4_4.4.2         colorspace_2.1-1    \n#&gt; [28] inline_0.3.21        insight_1.0.1        cli_3.6.3           \n#&gt; [31] mvtnorm_1.3-3        rmarkdown_2.29       generics_0.1.3      \n#&gt; [34] RcppParallel_5.1.9   reshape2_1.4.4       tzdb_0.4.0          \n#&gt; [37] parallel_4.4.2       matrixStats_1.5.0    vctrs_0.6.5         \n#&gt; [40] V8_6.0.0             Matrix_1.7-1         jsonlite_1.8.9      \n#&gt; [43] hms_1.1.3            glue_1.8.0           codetools_0.2-20    \n#&gt; [46] ps_1.8.1             distributional_0.5.0 stringi_1.8.4       \n#&gt; [49] gtable_0.3.6         QuickJSR_1.5.1       munsell_0.5.1       \n#&gt; [52] pillar_1.10.1        htmltools_0.5.8.1    Brobdingnag_1.2-9   \n#&gt; [55] R6_2.5.1             rprojroot_2.0.4      evaluate_1.0.1      \n#&gt; [58] lattice_0.22-6       backports_1.5.0      rstantools_2.4.0    \n#&gt; [61] coda_0.19-4.1        nlme_3.1-166         checkmate_2.3.2     \n#&gt; [64] xfun_0.50            pkgconfig_2.0.3",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>¬† <span class='chapter-title'>ANOVA ad due vie</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_anova_2vie.html#bibliografia",
    "href": "chapters/linear_models/11_anova_2vie.html#bibliografia",
    "title": "63¬† ANOVA ad due vie",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>¬† <span class='chapter-title'>ANOVA ad due vie</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/introduction_frequentist_inference.html",
    "href": "chapters/frequentist_inference/introduction_frequentist_inference.html",
    "title": "Introduzione",
    "section": "",
    "text": "Nell‚Äôinferenza statistica esistono due approcci principali: la statistica frequentista e la statistica bayesiana. Entrambi i metodi permettono di trarre conclusioni sulla popolazione di interesse analizzando i dati, stimare quantit√† sconosciute, fare previsioni e testare ipotesi. Tuttavia, differiscono nell‚Äôinterpretazione della probabilit√† e nell‚Äôintegrazione di conoscenze precedenti ed evidenze.\nLa statistica bayesiana interpreta la probabilit√† come una misura di convinzione o grado di certezza riguardo a un evento. Questo approccio consente di incorporare conoscenze pregresse ed evidenze nell‚Äôanalisi statistica utilizzando il teorema di Bayes. In questo contesto, il valore vero di un parametro della popolazione √® trattato come una variabile casuale, che viene costantemente aggiornata man mano che nuovi dati vengono raccolti. Ci√≤ porta alla formazione di una distribuzione completa nello spazio dei parametri, nota come distribuzione a posteriori, utilizzabile per fare previsioni probabilistiche e quantificare l‚Äôincertezza associata.\nD‚Äôaltra parte, la statistica frequentista interpreta la probabilit√† come la frequenza relativa a lungo termine di un evento in un numero infinito di prove. Questo approccio si basa sull‚Äôidea che il vero valore di un parametro della popolazione sia fisso ma sconosciuto e debba essere stimato dai dati. In questo contesto, le inferenze statistiche vengono ottenute dai dati osservati utilizzando varie tecniche statistiche e facendo alcune assunzioni riguardo al processo sottostante che genera i dati.\nIn questa sezione della dispensa esamineremo i metodi frequentisti della stima puntuale, degli intervalli di confidenza e del test di ipotesi.",
    "crumbs": [
      "Frequentismo",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html",
    "title": "64¬† Introduzione all‚Äôinferenza frequentista",
    "section": "",
    "text": "64.1 Introduzione\nCi sono due approcci principali per l‚Äôinferenza statistica: la statistica frequentista e la statistica bayesiana. Questi metodi consentono di fare conclusioni sulla popolazione di interesse attraverso l‚Äôanalisi dei dati. Entrambi gli approcci sono usati per stimare quantit√† sconosciute, fare previsioni e testare ipotesi, ma differiscono nella loro interpretazione della probabilit√† e in come integrano le conoscenze precedenti ed evidenze.\nNella statistica frequentista, la probabilit√† viene interpretata come la frequenza relativa a lungo termine di un evento in un numero infinito di prove. Questo approccio si basa sull‚Äôidea che il vero valore di un parametro della popolazione sia fisso, ma sconosciuto e debba essere stimato dai dati. In questo contesto, le inferenze statistiche vengono ottenute a partire dai dati osservati, mediante l‚Äôutilizzo di tecniche come la stima puntuale, gli intervalli di confidenza e il test di ipotesi, e facendo alcune assunzioni riguardo al processo sottostante che genera i dati.\nD‚Äôaltra parte, la statistica bayesiana interpreta la probabilit√† come una misura di convinzione o grado di certezza riguardo a un evento (Jaynes, 2003). Questo approccio consente di incorporare conoscenze pregresse ed evidenze nell‚Äôanalisi statistica attraverso l‚Äôuso del teorema di Bayes. In questo contesto, il vero valore di un parametro della popolazione √® trattato come una variabile casuale e viene continuamente aggiornato man mano che vengono raccolti nuovi dati. Ci√≤ porta alla formazione di una distribuzione completa nello spazio dei parametri, nota come distribuzione a posteriori, che pu√≤ essere utilizzata per fare previsioni probabilistiche e quantificare l‚Äôincertezza associata.\nIn questo capitolo, approfondiremo il concetto di distribuzione campionaria che costituisce uno dei pilastri dell‚Äôinferenza statistica frequentista. La distribuzione campionaria ci permette di comprendere come le stime dei parametri della popolazione, come la media o la varianza, cambiano da campione a campione. In particolare, la distribuzione campionaria ci consente di stabilire delle propriet√† probabilistiche delle stime campionarie, come ad esempio la loro media e la loro varianza. Queste propriet√† sono utili per costruire gli intervalli di fiducia e i test di ipotesi che costituiscono gli strumenti principali dell‚Äôinferenza statistica frequentista.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>64</span>¬† <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#i-frequentisti-sono-razzisti",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#i-frequentisti-sono-razzisti",
    "title": "64¬† Introduzione all‚Äôinferenza frequentista",
    "section": "64.2 I Frequentisti sono Razzisti?",
    "text": "64.2 I Frequentisti sono Razzisti?\nNel ?sec-bayes_theorem, abbiamo esaminato le origini storiche e il contesto culturale che ha contribuito all‚Äôinterpretazione applicativa del teorema di Bayes fornita da Richard Price. Queste origini sono legate alle idee alla base della rivoluzione americana, rappresentando quello che potremmo definire il ‚Äúlato luminoso‚Äù del liberalismo moderno.\nLe origini culturali dell‚Äôapproccio frequentista, invece, sono diametralmente opposte e strettamente connesse a quella che potremmo chiamare la ‚Äúparte oscura‚Äù della modernit√†. Si potrebbe dire che l‚Äôavversione per la soggettivit√† abbia guidato l‚Äôascesa del frequentismo.\nFrancis Galton (1822-1911) fu un uomo straordinario sotto molti aspetti. Cugino di Charles Darwin e medico qualificato, eredit√≤ una fortuna che gli permise di dedicarsi liberamente ai suoi interessi. Esplor√≤ l‚ÄôAfrica, ricevendo una medaglia dalla Royal Geographical Society, e diede un importante contributo alla meteorologia, notando per primo il fenomeno degli ‚Äúanticicloni‚Äù. Tuttavia, il suo contributo pi√π significativo riguard√≤ l‚Äôuso della statistica nello studio degli esseri umani, in particolare nell‚Äôanalisi della trasmissione ereditaria del talento.\nGalton trascorse gran parte della sua carriera all‚ÄôUniversity College di Londra, dove fece numerose scoperte. Tra queste, un importante contributo riguardava la distribuzione normale. Fu anche il primo a spiegare il concetto che oggi conosciamo come ‚Äúregressione verso la media‚Äù, da lui chiamato ‚Äúregressione verso la mediocrit√†‚Äù.\nIl suo interesse per l‚Äôereditariet√† del talento port√≤ Francis Galton a scrivere il libro Hereditary Genius, in cui analizzava come individui brillanti tendessero a concentrarsi in specifiche famiglie. Fu lui a coniare l‚Äôespressione ‚Äúnature and nurture‚Äù per riferirsi ai due fattori fondamentali che influenzano lo sviluppo umano: l‚Äôereditariet√† (ci√≤ che oggi chiamiamo genetica) e l‚Äôambiente.\nTuttavia, Galton non si limit√≤ a osservare e documentare la distribuzione dell‚Äôintelligenza. Il suo obiettivo era ambizioso e controverso: creare una scienza per il ‚Äúmiglioramento della specie umana‚Äù, che egli chiam√≤ ‚Äúeugenetica‚Äù. Promuoveva l‚Äôidea di incoraggiare la riproduzione tra le famiglie considerate di maggior successo e, al contrario, di scoraggiarla tra quelle ritenute meno fortunate.\nVa per√≤ sottolineato che Galton abbracciava idee profondamente razziste. In una lettera pubblicata sul Times di Londra, descrisse gli africani come ‚Äúinferiori‚Äù e li defin√¨ ‚Äúselvaggi pigri e chiacchieroni‚Äù. Gli arabi, secondo lui, erano ‚Äúpoco pi√π che consumatori della produzione altrui‚Äù. Proponeva inoltre di consegnare l‚ÄôAfrica orientale ai cinesi, che giudicava ‚Äúinclini alla menzogna e alla servilit√†‚Äù ma anche, a suo dire, ‚Äúnaturalmente industriosi e amanti dell‚Äôordine‚Äù. Per Galton, gli anglosassoni rappresentavano la razza migliore esistente, sebbene ritenesse che gli antichi ateniesi fossero stati il vertice dell‚Äôumanit√†.\nIl lavoro di Galton ispir√≤ una generazione successiva di statistici, in particolare Karl Pearson (1857-1936) e Ronald Fisher (1890-1962). Come Galton, Fisher e Pearson erano brillanti, ma condividevano anche le sue idee razziste, considerate inaccettabili sia per gli standard attuali che per quelli del loro tempo.\nKarl Pearson, poliedrico studioso e innovatore, divenne professore di matematica applicata all‚ÄôUCL nel 1885, seguendo le orme di Francis Galton. Dopo la morte di quest‚Äôultimo, eredit√≤ la cattedra di eugenetica, istituita e finanziata da Galton stesso. Pearson fond√≤ la rivista di statistica Biometrika e diede un contributo fondamentale alla disciplina, sviluppando il test del chi quadrato e coniando il termine ‚Äúdeviazione standard‚Äù.\nRonald Fisher, pi√π giovane, succedette a Pearson come professore di eugenetica presso l‚ÄôUCL. Considerato un gigante della teoria statistica, Fisher contribu√¨ in modo decisivo allo sviluppo della disciplina, inventando o perfezionando strumenti fondamentali come l‚Äôanalisi della varianza (ANOVA), il concetto di ‚Äúsignificativit√† statistica‚Äù e il metodo della massima verosimiglianza (MLE).\nTutti questi ricercatori cercarono di allontanare la statistica dall‚Äôapproccio soggettivo di Laplace e Bayes. Come Galton, sia Pearson che Fisher erano convinti sostenitori dell‚Äôeugenetica.\n√à interessante riflettere su quanto le idee di Galton, Pearson e Fisher sull‚Äôeugenetica possano aver influenzato le loro visioni scientifiche. Secondo alcuni studiosi, la storia della statistica e quella dell‚Äôeugenetica sono strettamente intrecciate. Fisher, e in misura minore Pearson, rigettavano il bayesianesimo perch√© desideravano conferire un fondamento apparentemente ‚Äúoggettivo‚Äù alle loro idee eugenetiche. Se fosse stata la scienza a ‚Äúdimostrare‚Äù che alcune razze erano inferiori ad altre, o che la riproduzione tra i poveri dovesse essere scoraggiata, queste teorie sarebbero state presentate come indiscutibili. Il bayesianesimo, con la sua componente intrinseca di soggettivit√†, rappresentava una minaccia a questa pretesa di oggettivit√†.\nQuanto dovremmo considerare le implicazioni storiche ed etiche quando valutiamo la statistica frequentista? Chivers (2024) risponde cos√¨: √® indubbio che una parte dell‚Äôideologia razziale nazista possa essere ricondotta a Galton senza troppe difficolt√†. Tuttavia, questa riflessione, per quanto cruciale dal punto di vista storico ed etico, non √® direttamente rilevante in ambito strettamente statistico. La domanda fondamentale rimane: ‚ÄúQuale approccio √® corretto?‚Äù o, meglio ancora, ‚ÄúQuale approccio √® pi√π utile?‚Äù, anzich√© chiedersi ‚ÄúQuale approccio ha avuto i sostenitori pi√π discutibili?‚Äù.\nPur riconoscendo il valore di questa risposta in termini di focalizzazione sulla metodologia, ritengo che sia intrinsecamente inadeguata. Consideriamo uno scenario ipotetico: supponiamo che in una ‚Äútorre d‚Äôavorio‚Äù ‚Äì che sia la statistica, l‚Äôaccademia o la scienza in generale ‚Äì la teoria A risulti pi√π efficace della teoria B. Tuttavia, al di fuori di questo contesto isolato, la teoria A comporta conseguenze etiche inaccettabili, mentre la teoria B no. Dovremmo davvero accettare A semplicemente perch√© funziona meglio in un sistema chiuso e teorico? La mia risposta √® un categorico no.\nLe cosiddette ‚Äútorri d‚Äôavorio‚Äù sono costruzioni ideologiche che non rispecchiano la realt√†. Non esiste una netta separazione tra ‚Äúdentro‚Äù e ‚Äúfuori‚Äù: scienza ed etica non operano in compartimenti stagni, ma interagiscono costantemente. L‚Äôidea di giudicare una teoria esclusivamente sulla base della sua efficacia all‚Äôinterno di un contesto limitato ignora le sue implicazioni pi√π ampie e potenzialmente dannose.\nNel caso specifico del frequentismo, √® evidente ‚Äì come dimostreremo in seguito ‚Äì che questo approccio non solo presenta implicazioni etiche problematiche, ma √® anche intrinsecamente fallace dal punto di vista metodologico. La sua supposta efficacia in un ambito ristretto √® un‚Äôillusione che non regge a un‚Äôanalisi critica pi√π ampia. Non possiamo, n√© dobbiamo, separare l‚Äôefficacia teorica dalle conseguenze pratiche ed etiche. Il frequentismo fallisce su entrambi i fronti: morale e scientifico. Difenderlo, quindi, risulta insostenibile in ogni contesto.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>64</span>¬† <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#stime-stimatori-e-parametri",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#stime-stimatori-e-parametri",
    "title": "64¬† Introduzione all‚Äôinferenza frequentista",
    "section": "64.3 Stime, stimatori e parametri",
    "text": "64.3 Stime, stimatori e parametri\nSpostiamo ora il discorso da un piano culturale ad un piano strettamente statistico. Consideriamo il concetto di stima statistica.\nQuando si analizzano i dati, solitamente si √® interessati a una quantit√† a livello di popolazione; tuttavia, di solito si ha accesso solo a un campione di osservazioni. La quantit√† sconosciuta di nostro interesse viene chiamata parametro. La statistica che calcoliamo utilizzando i dati del campione viene chiamata stima, e la formula che la produce viene chiamata stimatore. Formalmente, uno stimatore √® una funzione dei dati osservati utilizzata per produrre una stima di un parametro.\nIn altre parole, quando analizziamo un campione di dati, vogliamo inferire alcune propriet√† della popolazione di cui il campione √® rappresentativo. Il parametro rappresenta la misura di tali propriet√†, ma spesso non √® possibile calcolarlo direttamente sulla popolazione. Pertanto, lo stimiamo utilizzando le osservazioni del campione. La stima √® quindi l‚Äôapprossimazione del valore del parametro che otteniamo dal nostro campione, mentre lo stimatore √® la formula matematica utilizzata per calcolare questa stima.\nTuttavia, le stime non sono necessariamente identiche ai parametri di nostro interesse. Le stime presentano una certa incertezza dovuta alla variabilit√† del campionamento. In questo capitolo esamineremo come l‚Äôapproccio frequentista quantifica l‚Äôincertezza nelle nostre stime, in modo da poter trarre conclusioni sul parametro.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>64</span>¬† <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#distribuzione-campionaria",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#distribuzione-campionaria",
    "title": "64¬† Introduzione all‚Äôinferenza frequentista",
    "section": "64.4 Distribuzione campionaria",
    "text": "64.4 Distribuzione campionaria\nIn questo capitolo esploreremo come la media di un campione casuale pu√≤ essere utilizzata per stimare la media \\(\\mu\\) di una popolazione. Per valutare l‚Äôincertezza di questa stima, ci avvaliamo del concetto di distribuzione campionaria, un‚Äôimportante idea dell‚Äôapproccio frequentista.\nPer introdurre il concetto, utilizzeremo una popolazione finita di piccole dimensioni, pur sapendo che le propriet√† illustrate valgono anche per popolazioni di dimensioni maggiori.\n\n64.4.1 Esempio introduttivo\nConsideriamo la seguente popolazione:\n\nx &lt;- c(2, 4.5, 5, 5.5)\nx\n#&gt; [1] 2.0 4.5 5.0 5.5\n\nL‚Äôistogramma sottostante rappresenta la distribuzione di frequenza della popolazione:\n\nhist(\n  x, breaks = 5, \n  freq = FALSE, \n  main = \"Distribuzione della popolazione\", \n  xlab = \"Valori\"\n)\n\n\n\n\n\n\n\n\nCalcoliamo la media e la varianza della popolazione:\n\nmean(x)  # Media\n#&gt; [1] 4.25\nvar(x)   # Varianza\n#&gt; [1] 2.42\n\n\n\n64.4.2 Campionamento\nSupponiamo ora di estrarre tutti i possibili campioni di dimensione \\(n = 2\\) dalla popolazione. Per generare queste combinazioni:\n\nsamples &lt;- expand.grid(x, x)\nsamples\n#&gt;    Var1 Var2\n#&gt; 1   2.0  2.0\n#&gt; 2   4.5  2.0\n#&gt; 3   5.0  2.0\n#&gt; 4   5.5  2.0\n#&gt; 5   2.0  4.5\n#&gt; 6   4.5  4.5\n#&gt; 7   5.0  4.5\n#&gt; 8   5.5  4.5\n#&gt; 9   2.0  5.0\n#&gt; 10  4.5  5.0\n#&gt; 11  5.0  5.0\n#&gt; 12  5.5  5.0\n#&gt; 13  2.0  5.5\n#&gt; 14  4.5  5.5\n#&gt; 15  5.0  5.5\n#&gt; 16  5.5  5.5\n\nOgni riga rappresenta un campione possibile. Calcoliamo il numero totale di campioni:\n\nnrow(samples)\n#&gt; [1] 16\n\nOra calcoliamo la media di ciascun campione, ottenendo la distribuzione campionaria delle medie per \\(n = 2\\):\n\nsample_means &lt;- rowMeans(samples)\nsample_means\n#&gt;  [1] 2.00 3.25 3.50 3.75 3.25 4.50 4.75 5.00 3.50 4.75 5.00 5.25 3.75 5.00\n#&gt; [15] 5.25 5.50\n\n\n\n64.4.3 Visualizzazione della distribuzione campionaria\nPossiamo rappresentare graficamente questa distribuzione:\n\nhist(\n  sample_means, \n  breaks = 5, \n  freq = FALSE, \n  main = \"Distribuzione campionaria delle medie (n = 2)\", \n  xlab = \"Media campionaria\"\n)\n\n\n\n\n\n\n\n\n\n\n64.4.4 Verifiche teoriche\n\n64.4.4.1 Media della distribuzione campionaria\nLa media della distribuzione campionaria deve essere uguale alla media della popolazione:\n\nmean(x)  # Media della popolazione\n#&gt; [1] 4.25\nmean(sample_means)  # Media della distribuzione campionaria\n#&gt; [1] 4.25\n\n\n\n64.4.4.2 Varianza della distribuzione campionaria\nLa varianza della distribuzione campionaria deve essere pari alla varianza della popolazione divisa per \\(n\\):\n\n# Evito la divisione per (n - 1)\nvariance &lt;- function(x) {\n  mean((x - mean(x))^2)\n}\n\n\nvariance(x) / 2  # Varianza teorica\n#&gt; [1] 0.906\nvariance(sample_means)  # Varianza empirica\n#&gt; [1] 0.906\n\n\n\n\n64.4.5 Esempio di campione osservato\nConsideriamo un singolo campione, ad esempio \\(\\{5, 5.5\\}\\):\n\nobserved_sample &lt;- c(5, 5.5)\nobserved_sample\n#&gt; [1] 5.0 5.5\n\nTroviamo la sua media e deviazione standard:\n\nmean(observed_sample)  # Media del campione\n#&gt; [1] 5.25\nsqrt(variance(observed_sample))    # Deviazione standard del campione\n#&gt; [1] 0.25\n\nConfrontiamo questi valori con quelli della popolazione:\n\nmean(x)  # Media della popolazione\n#&gt; [1] 4.25\nsqrt(variance(x))     # Deviazione standard della popolazione\n#&gt; [1] 1.35\n\nIn conclusione, dalla simulazione emergono due risultati fondamentali:\n\nLa media della distribuzione campionaria coincide con la media della popolazione. Questo significa che, se si considera la media \\(\\bar{X}_n\\) di campioni casuali di ampiezza \\(n\\), il valore atteso di \\(\\bar{X}_n\\) √® uguale alla media della popolazione \\(\\mu\\). Formalmente:\n\\[\n\\mathbb{E}(\\bar{X}_n) = \\frac{1}{n} \\mathbb{E}(S_n) = \\frac{1}{n} n \\mu = \\mu,\n\\] dove \\(\\mathbb{E}(\\cdot)\\) rappresenta il valore atteso e \\(S_n\\) la somma delle osservazioni nel campione.\nLa varianza della distribuzione campionaria √® inferiore alla varianza della popolazione. In particolare, la varianza delle medie campionarie √® data dalla varianza della popolazione divisa per l‚Äôampiezza del campione, ovvero:\n\\[\n\\mathbb{V}(\\bar{X}) = \\frac{\\sigma^2}{n}.\n\\]\n\n\n\n\n\n\n\nIl secondo risultato sopra pu√≤ essere dimostrato come segue.\nSia \\(X_1, X_2, \\dots, X_n\\) un campione casuale di \\(n\\) osservazioni indipendenti estratte da una popolazione con media \\(\\mu\\) e varianza \\(\\sigma^2\\). La media campionaria √® definita come:\n\\[\n\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i.\n\\]\nPer definizione, la varianza di \\(\\bar{X}\\) √®:\n\\[\n\\mathbb{V}(\\bar{X}) = \\mathbb{V}\\left(\\frac{1}{n} \\sum_{i=1}^n X_i\\right).\n\\]\nPoich√© una costante moltiplicata da una variabile aleatoria pu√≤ essere ‚Äúestratta‚Äù dalla varianza, otteniamo:\n\\[\n\\mathbb{V}(\\bar{X}) = \\frac{1}{n^2} \\mathbb{V}\\left(\\sum_{i=1}^n X_i\\right).\n\\]\nOra dobbiamo calcolare \\(\\mathbb{V}\\left(\\sum_{i=1}^n X_i\\right)\\). Le variabili \\(X_1, X_2, \\dots, X_n\\) sono indipendenti, quindi la varianza della somma √® la somma delle varianze:\n\\[\n\\mathbb{V}\\left(\\sum_{i=1}^n X_i\\right) = \\sum_{i=1}^n \\mathbb{V}(X_i).\n\\]\nPoich√© tutte le variabili \\(X_i\\) hanno la stessa varianza \\(\\sigma^2\\):\n\\[\n\\mathbb{V}\\left(\\sum_{i=1}^n X_i\\right) = n \\sigma^2.\n\\]\nSostituendo nella formula precedente, otteniamo:\n\\[\n\\mathbb{V}(\\bar{X}) = \\frac{1}{n^2} \\cdot n \\sigma^2 = \\frac{\\sigma^2}{n}.\n\\]\nIn generale, dunque, per un campione di ampiezza \\(n\\), vale la relazione \\(\\mathbb{V}(\\bar{X}) = \\frac{\\sigma^2}{n}\\).\n\n\n\n\n\n64.4.6 Propriet√† della distribuzione campionaria\nInfine, osserviamo una propriet√† fondamentale della distribuzione campionaria:\n\nSe la popolazione segue una distribuzione normale, allora anche la distribuzione delle medie campionarie seguir√† una distribuzione normale, indipendentemente dall‚Äôampiezza del campione.\nSe invece la popolazione non segue una distribuzione normale, il teorema del limite centrale garantisce che, all‚Äôaumentare della dimensione del campione \\(n\\), la distribuzione campionaria delle medie tender√† a una distribuzione normale.\n\nQueste propriet√† sono centrali in molti metodi statistici, poich√© consentono di fare inferenza sulla popolazione utilizzando campioni.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>64</span>¬† <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#teorema-del-limite-centrale",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#teorema-del-limite-centrale",
    "title": "64¬† Introduzione all‚Äôinferenza frequentista",
    "section": "64.5 Teorema del Limite Centrale",
    "text": "64.5 Teorema del Limite Centrale\nEsaminiamo ora pi√π in dettaglio il Teorema del Limite Centrale (TLC). Nel 1812, Laplace dimostr√≤ il TLC, che afferma che la somma di una sequenza di variabili casuali indipendenti tende a distribuirsi secondo una distribuzione Normale. Inoltre, il TLC stabilisce i parametri della distribuzione Normale risultante in base ai valori attesi e alle varianze delle variabili casuali sommate.\n\nTeorema 64.1 Si supponga che \\(Y = Y_1, \\dots, Y_i, \\ldots, Y_n\\) sia una sequenza di v.a. i.i.d. (variabili aleatorie identicamente distribuite e indipendenti) con \\(\\mathbb{E}(Y_i) = \\mu\\) e \\(SD(Y_i) = \\sigma\\). Si definisca una nuova variabile casuale come:\n\\[\nZ = \\frac{1}{n} \\sum_{i=1}^n Y_i.\n\\]\nCon \\(n \\rightarrow \\infty\\), \\(Z\\) tender√† a seguire una distribuzione Normale con lo stesso valore atteso di \\(Y_i\\) e una deviazione standard ridotta di un fattore pari a \\(\\frac{1}{\\sqrt{n}}\\):\n\\[\np_Z(z) \\rightarrow \\mathcal{N}\\left(z \\ \\Bigg| \\ \\mu, \\, \\frac{\\sigma}{\\sqrt{n}} \\right).\n\\]\n\nIl TLC pu√≤ essere generalizzato a variabili casuali che non sono identicamente distribuite, a condizione che siano indipendenti e abbiano aspettative e varianze finite. Molti fenomeni naturali, come l‚Äôaltezza degli adulti, sono il risultato di una combinazione di effetti additivi relativamente piccoli. Questi effetti, indipendentemente dalla loro distribuzione individuale, tendono a portare alla normalit√† della distribuzione risultante. Questa √® la ragione per cui la distribuzione normale fornisce una buona approssimazione per la distribuzione di molti fenomeni naturali.\n\n64.5.1 Illustrazione del TLC\nPer dimostrare il Teorema del Limite Centrale, consideriamo una popolazione iniziale con una distribuzione fortemente asimmetrica: una distribuzione Beta con parametri \\(\\alpha = 2\\) e \\(\\beta = 1\\). Estraiamo 50.000 campioni casuali di ampiezza \\(n\\) da questa popolazione e costruiamo la distribuzione campionaria delle medie.\nDefiniamo una funzione per simulare e visualizzare la distribuzione campionaria per diversi valori di \\(n\\):\n\n# Parametri della distribuzione Beta\nalpha &lt;- 2\nbeta &lt;- 1\n\n# Funzione per simulare e visualizzare la distribuzione campionaria\nplot_samples &lt;- function(n) {\n  # Media e deviazione standard della distribuzione Beta\n  mu &lt;- alpha / (alpha + beta)\n  sigma &lt;- sqrt(alpha * beta / ((alpha + beta)^2 * (alpha + beta + 1)))\n  \n  # Generazione di 50.000 campioni casuali di dimensione n\n  sample_means &lt;- replicate(50000, mean(rbeta(n, alpha, beta)))\n  \n  # Dati per la distribuzione normale teorica\n  x &lt;- seq(mu - 3 * sigma, mu + 3 * sigma, length.out = 100)\n  y &lt;- dnorm(x, mean = mu, sd = sigma / sqrt(n))\n  \n  # Creazione del grafico\n  hist(\n    sample_means, \n    breaks = 50, \n    probability = TRUE, \n    main = paste(\"Ampiezza campionaria =\", n), \n    xlab = \"Media campionaria\", \n    ylab = \"Densit√†\"\n  )\n  lines(x, y, col = \"black\", lwd = 2)\n}\n\n\n\n64.5.2 Visualizzazione per diverse dimensioni campionarie\n\nAmpiezza campionaria \\(n = 1\\)\n\nSe \\(n = 1\\), la distribuzione campionaria delle medie coincide con la popolazione di partenza.\n\nplot_samples(1)\n\n\n\n\n\n\n\n\n\nAmpiezza campionaria \\(n = 2\\)\n\nPer \\(n = 2\\), la distribuzione delle medie dei campioni inizia ad avvicinarsi alla normalit√†.\n\nplot_samples(2)\n\n\n\n\n\n\n\n\n\nAmpiezza campionaria \\(n = 4\\)\n\nPer \\(n = 4\\), l‚Äôapprossimazione alla distribuzione normale migliora.\n\nplot_samples(4)\n\n\n\n\n\n\n\n\n\nAmpiezza campionaria \\(n = 30\\)\n\nPer \\(n = 30\\), la distribuzione campionaria delle medie √® ben approssimata dalla normale.\n\nplot_samples(30)\n\n\n\n\n\n\n\n\nIn conclusione, il Teorema del Limite Centrale (TLC) afferma che, indipendentemente dalla forma della distribuzione della popolazione:\n\nPer campioni di dimensione sufficiente, la distribuzione campionaria delle medie \\(\\bar{X}\\) tende a una distribuzione normale.\nLa media \\(\\mu\\) e la deviazione standard \\(\\sigma\\) della popolazione determinano la distribuzione delle medie campionarie come segue:\n\\[\n\\bar{X} \\sim \\mathcal{N}(\\mu, \\sigma / \\sqrt{n}),\n\\]\ndove \\(n\\) √® l‚Äôampiezza del campione.\n\nQuesta propriet√† ha implicazioni fondamentali:\n\nLa normalit√† emergente giustifica l‚Äôuso della distribuzione normale anche quando i dati non sono inizialmente normali.\nIl TLC fornisce una formula esplicita per calcolare l‚Äôerrore standard \\(\\sigma / \\sqrt{n}\\), che quantifica la precisione della media campionaria come stima della media della popolazione.\n\n\n\n64.5.3 Applicazioni in psicologia\nMolti fenomeni psicologici che misuriamo (ad esempio, il QI come media di molte abilit√† cognitive) derivano dalla media di pi√π variabili, e quindi seguono la distribuzione normale grazie al TLC. Questo spiega perch√© la distribuzione normale appare cos√¨ frequentemente nei dati sperimentali di psicologia e in molte altre discipline scientifiche.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>64</span>¬† <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#distribuzioni-campionarie-di-altre-statistiche",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#distribuzioni-campionarie-di-altre-statistiche",
    "title": "64¬† Introduzione all‚Äôinferenza frequentista",
    "section": "64.6 Distribuzioni campionarie di altre statistiche",
    "text": "64.6 Distribuzioni campionarie di altre statistiche\nAbbiamo gi√† analizzato la distribuzione campionaria della media dei campioni. Tuttavia, √® possibile costruire distribuzioni campionarie per altre statistiche campionarie. Ad esempio, consideriamo la distribuzione campionaria del valore massimo e della varianza.\n\n64.6.1 Distribuzione campionaria del valore massimo\nSupponiamo di avere una popolazione normalmente distribuita con media \\(\\mu = 100\\) e deviazione standard \\(\\sigma = 15\\). Generiamo 10.000 campioni casuali di ampiezza \\(n = 5\\) e calcoliamo il valore massimo per ogni campione.\n\n64.6.1.1 Simulazione e visualizzazione\n\nset.seed(123)  # Per risultati riproducibili\n\n# Parametri della distribuzione\nmu &lt;- 100\nsigma &lt;- 15\n\n# Simulazione: calcolo del valore massimo per ciascun campione\nn_samples &lt;- 10000\nsample_maxes &lt;- replicate(\n  n_samples, \n  max(rnorm(5, mean = mu, sd = sigma))\n)\n\n# Istogramma della distribuzione campionaria del valore massimo\nhist(\n  sample_maxes, \n  breaks = 50, \n  probability = TRUE, \n  main = \"Distribuzione campionaria del valore massimo\",\n  xlab = \"Valore massimo\", \n  ylab = \"Densit√†\"\n)\n\n# Sovrapposizione della distribuzione normale della popolazione\ncurve(dnorm(x, mean = mu, sd = sigma), add = TRUE, col = \"black\", lwd = 2)\n\n\n\n\n\n\n\n\nOsserviamo che il valore atteso della distribuzione campionaria del massimo √® maggiore della media della popolazione \\(\\mu\\).\n\n\n\n64.6.2 Distribuzione campionaria della varianza\nUn‚Äôaltra statistica interessante √® la varianza campionaria. La formula della varianza campionaria, basata sulla statistica descrittiva, √®:\n\\[\nS^2 = \\frac{\\sum_{i=1}^n (Y_i - \\bar{Y})^2}{n}.\n\\]\nCalcoliamo la distribuzione campionaria della varianza per campioni di ampiezza \\(n = 5\\).\n\n64.6.2.1 Simulazione e visualizzazione\n\nset.seed(123)\n\n# Simulazione: calcolo della varianza per ciascun campione\nsample_vars &lt;- replicate(\n  n_samples, \n  variance(rnorm(5, mean = mu, sd = sigma))\n)\n\n# Istogramma della distribuzione campionaria della varianza\nhist(\n  sample_vars, \n  breaks = 50, \n  probability = TRUE, \n  main = \"Distribuzione campionaria della varianza\",\n  xlab = \"Varianza\", ylab = \"Densit√†\"\n)\n\n\n\n\n\n\n\n\n\n# Media empirica della varianza campionaria\nmean(sample_vars)\n#&gt; [1] 181\n\nSappiamo che la varianza della popolazione √® \\(\\sigma^2 = 15^2 = 225\\). Tuttavia, il valore medio empirico delle varianze campionarie calcolate con \\(S^2\\) risulta minore di 225. Questo avviene perch√© lo stimatore \\(S^2\\) √® distorto.\n\n\n\n64.6.3 Correzione della distorsione\nPer eliminare la distorsione, utilizziamo il seguente stimatore della varianza della popolazione:\n\\[\ns^2 = \\frac{\\sum_{i=1}^n (Y_i - \\bar{Y})^2}{n-1}.\n\\]\n\n64.6.3.1 Verifica con simulazione\n\nset.seed(123)\n\n# Simulazione: calcolo della varianza con la correzione\nsample_vars_unbiased &lt;- replicate(\n  n_samples, \n  var(rnorm(5, mean = mu, sd = sigma))\n)\n\n# Istogramma della distribuzione campionaria della varianza corretta\nhist(\n  sample_vars_unbiased, \n  breaks = 50, \n  probability = TRUE, \n  main = \"Distribuzione campionaria della varianza (corretta)\",\n  xlab = \"Varianza\", \n  ylab = \"Densit√†\"\n)\n\n\n\n\n\n\n\n\n\n# Media empirica della varianza corretta\nmean(sample_vars_unbiased)\n#&gt; [1] 226\n\nCon questo stimatore, la media della distribuzione campionaria coincide con la varianza reale della popolazione \\(\\sigma^2 = 225\\).\nIn conclusione:\n\nLa distribuzione campionaria del massimo mostra che il valore massimo dei campioni √®, in media, maggiore della media della popolazione.\nLa varianza campionaria non corretta (\\(S^2\\)) √® uno stimatore distorto, poich√© il suo valore atteso non coincide con la varianza della popolazione.\nLo stimatore corretto \\(s^2\\), che utilizza il divisore \\(n - 1\\), elimina la distorsione e fornisce una stima non distorta della varianza della popolazione.\n\nIn generale, uno stimatore √® considerato non distorto quando il valore atteso delle sue stime coincide con il valore reale del parametro. Nel caso della media campionaria e della varianza corretta, entrambi gli stimatori sono non distorti.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>64</span>¬† <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#riflessioni-conclusive",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#riflessioni-conclusive",
    "title": "64¬† Introduzione all‚Äôinferenza frequentista",
    "section": "64.7 Riflessioni Conclusive",
    "text": "64.7 Riflessioni Conclusive\nIn generale, i parametri della popolazione sono sconosciuti, ma possiamo stimarli utilizzando le informazioni del campione. Di seguito viene presentata una tabella che riassume i simboli comuni utilizzati per indicare le quantit√† note e sconosciute nel contesto dell‚Äôinferenza statistica. Questo ci aiuter√† a tenere traccia di ci√≤ che sappiamo e ci√≤ che non sappiamo.\n\n\n\n\n\n\n\n\nSimbolo\nNome\n√à qualcosa che conosciamo?\n\n\n\n\n\\(s\\)\nDeviazione standard del campione\nS√¨, la calcoliamo dai dati grezzi\n\n\n\\(\\sigma\\)\nDeviazione standard della popolazione\nNo, tranne in casi particolari o nelle simulazioni\n\n\n\\(\\hat{\\sigma}\\)\nStima della deviazione standard della popolazione\nS√¨, ma non √® uguale a \\(\\sigma\\)\n\n\n\\(s^2\\)\nVarianza del campione\nS√¨, la calcoliamo dai dati grezzi\n\n\n\\(\\sigma^2\\)\nVarianza della popolazione\nNo, tranne in casi particolari o nelle simulazioni\n\n\n\\(\\hat{\\sigma}^2\\)\nStima della varianza della popolazione\nS√¨, ma non √® uguale a \\(\\sigma^2\\)\n\n\n\n\nUtilizzando le informazioni di un campione casuale di ampiezza \\(n\\):\n\nLa stima migliore che possiamo ottenere per la media \\(\\mu\\) della popolazione √® la media del campione \\(\\bar{Y}\\).\nLa stima migliore che possiamo ottenere per la varianza \\(\\sigma^2\\) della popolazione √®:\n\n\\[\n\\hat{\\sigma}^2 = \\frac{1}{n-1} \\sum_{i=1}^n (Y_i - \\bar{Y})^2.\n\\]",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>64</span>¬† <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#informazioni-sullambiente-di-sviluppo",
    "title": "64¬† Introduzione all‚Äôinferenza frequentista",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: US/Pacific\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] ggokabeito_0.1.0 see_0.9.0        gridExtra_2.3    patchwork_1.3.0 \n#&gt;  [5] bayesplot_1.11.1 psych_2.4.12     scales_1.3.0     markdown_1.13   \n#&gt;  [9] knitr_1.49       lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1   \n#&gt; [13] dplyr_1.1.4      purrr_1.0.2      readr_2.1.5      tidyr_1.3.1     \n#&gt; [17] tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3       \n#&gt; [21] here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.3         rlang_1.1.4       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       yaml_2.3.10       tools_4.4.2       parallel_4.4.2   \n#&gt; [21] tzdb_0.4.0        colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5      \n#&gt; [25] R6_2.5.1          lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3  \n#&gt; [29] pillar_1.10.1     gtable_0.3.6      glue_1.8.0        xfun_0.50        \n#&gt; [33] tidyselect_1.2.1  farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-166     \n#&gt; [37] rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>64</span>¬† <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#bibliografia",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#bibliografia",
    "title": "64¬† Introduzione all‚Äôinferenza frequentista",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nChivers, T. (2024). Everything is Predictable: How Bayesian Statistics Explain Our World. Simon; Schuster.\n\n\nJaynes, E. T. (2003). Probability theory: The logic of science. Cambridge University Press.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>64</span>¬† <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html",
    "href": "chapters/frequentist_inference/02_conf_interv.html",
    "title": "65¬† Intervalli di fiducia",
    "section": "",
    "text": "65.1 Introduzione\nGli intervalli di confidenza sono uno strumento fondamentale nell‚Äôinferenza statistica frequentista. Essi consentono di stimare un parametro sconosciuto di una popolazione, come la media \\(\\mu\\), tenendo conto dell‚Äôincertezza derivante dal fatto che la stima si basa su un campione. Questo materiale didattico si propone di spiegare in modo dettagliato e chiaro la costruzione di un intervallo di confidenza per la media di una popolazione, sia nel caso di varianza nota sia in quello di varianza incognita.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>65</span>¬† <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#inferenza-statistica-frequentista-e-media-campionaria",
    "href": "chapters/frequentist_inference/02_conf_interv.html#inferenza-statistica-frequentista-e-media-campionaria",
    "title": "65¬† Intervalli di fiducia",
    "section": "65.2 Inferenza Statistica Frequentista e Media Campionaria",
    "text": "65.2 Inferenza Statistica Frequentista e Media Campionaria\nQuando estraiamo un campione casuale semplice \\(X_1, X_2, \\dots, X_n\\) da una popolazione con media \\(\\mu\\) e varianza \\(\\sigma^2\\), la media campionaria \\(\\bar{X}\\) √® definita come:\n\\[\n\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i.\n\\]\nLa media campionaria \\(\\bar{X}\\) √® una variabile casuale perch√© dipende dai valori osservati nel campione, che sono essi stessi casuali. Le propriet√† della media campionaria sono le seguenti:\n\nMedia della distribuzione campionaria: \\(E[\\bar{X}] = \\mu\\). La media campionaria √® uno stimatore non distorto della media della popolazione.\nVarianza della distribuzione campionaria: \\(\\text{Var}(\\bar{X}) = \\frac{\\sigma^2}{n}\\). Questo significa che la precisione di \\(\\bar{X}\\) come stima di \\(\\mu\\) aumenta con il numero di osservazioni \\(n\\).\n\nQueste propriet√† sono fondamentali per calcolare un intervallo di confidenza, poich√© ci permettono di descrivere la distribuzione di \\(\\bar{X}\\).",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>65</span>¬† <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#intervallo-di-confidenza-per-la-media-caso-di-varianza-nota",
    "href": "chapters/frequentist_inference/02_conf_interv.html#intervallo-di-confidenza-per-la-media-caso-di-varianza-nota",
    "title": "65¬† Intervalli di fiducia",
    "section": "65.3 Intervallo di Confidenza per la Media: Caso di Varianza Nota",
    "text": "65.3 Intervallo di Confidenza per la Media: Caso di Varianza Nota\nSupponiamo che la popolazione sia distribuita normalmente con media \\(\\mu\\) e varianza \\(\\sigma^2\\), e che \\(\\sigma^2\\) sia nota. La distribuzione della media campionaria \\(\\bar{X}\\) √® anch‚Äôessa normale:\n\\[\n\\bar{X} \\sim \\mathcal{N}\\left(\\mu, \\frac{\\sigma^2}{n}\\right).\n\\]\n\n65.3.1 Passo 1: Standardizzazione della Media Campionaria\nPer lavorare con una distribuzione normale standard (media 0 e varianza 1), standardizziamo \\(\\bar{X}\\) utilizzando la formula:\n\\[\nZ = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}}.\n\\]\nQui, \\(\\sigma / \\sqrt{n}\\) √® la deviazione standard della distribuzione campionaria di \\(\\bar{X}\\).\nDopo questa trasformazione, la variabile \\(Z\\) segue una distribuzione normale standard:\n\\[\nZ \\sim \\mathcal{N}(0, 1).\n\\]\n\n\n65.3.2 Passo 2: Determinazione del Livello di Confidenza\nScegliamo un livello di confidenza \\(\\gamma\\), ad esempio \\(\\gamma = 0.95\\). Per una distribuzione normale standard, troviamo il valore critico \\(z\\) tale che la probabilit√† tra \\(-z\\) e \\(+z\\) sia pari al livello di confidenza:\n\\[\nP(-z \\leq Z \\leq z) = \\gamma.\n\\]\nPer un livello di confidenza del 95%, \\(z \\approx 1.96\\).\n\n\n65.3.3 Passo 3: Formulazione dell‚ÄôIntervallo di Confidenza\nPartiamo dalla probabilit√† per \\(Z\\):\n\\[\nP(-z \\leq Z \\leq z) = \\gamma.\n\\]\nSostituiamo la definizione di \\(Z\\):\n\\[\nP\\left(-z \\leq \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}} \\leq z\\right) = \\gamma.\n\\]\nMoltiplichiamo tutti i membri per \\(\\sigma / \\sqrt{n}\\) per rimuovere il denominatore:\n\\[\nP\\left(-z \\cdot \\frac{\\sigma}{\\sqrt{n}} \\leq \\bar{X} - \\mu \\leq z \\cdot \\frac{\\sigma}{\\sqrt{n}}\\right) = \\gamma.\n\\]\nAggiungiamo \\(\\mu\\) a tutti i membri per isolare \\(\\mu\\):\n\\[\nP\\left(\\bar{X} - z \\cdot \\frac{\\sigma}{\\sqrt{n}} \\leq \\mu \\leq \\bar{X} + z \\cdot \\frac{\\sigma}{\\sqrt{n}}\\right) = \\gamma.\n\\]\n\n\n65.3.4 Passo 4: Limiti dell‚ÄôIntervallo di Confidenza\nDefiniamo i limiti inferiore e superiore dell‚Äôintervallo di confidenza:\n\\[\n\\hat{a} = \\bar{X} - z \\cdot \\frac{\\sigma}{\\sqrt{n}}, \\quad \\hat{b} = \\bar{X} + z \\cdot \\frac{\\sigma}{\\sqrt{n}}.\n\\]\nL‚Äôintervallo di confidenza per \\(\\mu\\) √® quindi:\n\\[\n(\\hat{a}, \\hat{b}) = \\left(\\bar{X} - z \\cdot \\frac{\\sigma}{\\sqrt{n}}, \\bar{X} + z \\cdot \\frac{\\sigma}{\\sqrt{n}}\\right).\n\\]",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>65</span>¬† <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#intervallo-di-confidenza-per-la-media-caso-di-varianza-incognita",
    "href": "chapters/frequentist_inference/02_conf_interv.html#intervallo-di-confidenza-per-la-media-caso-di-varianza-incognita",
    "title": "65¬† Intervalli di fiducia",
    "section": "65.4 Intervallo di Confidenza per la Media: Caso di Varianza Incognita",
    "text": "65.4 Intervallo di Confidenza per la Media: Caso di Varianza Incognita\nNella maggior parte dei casi pratici, la varianza \\(\\sigma^2\\) non √® nota. In questi casi, stimiamo \\(\\sigma\\) con la deviazione standard campionaria \\(s\\) e utilizziamo la distribuzione t di Student, che tiene conto dell‚Äôincertezza aggiuntiva.\n\n65.4.1 Passo 1: Distribuzione t di Student\nLa statistica che seguiamo √®:\n\\[\nT = \\frac{\\bar{X} - \\mu}{s / \\sqrt{n}},\n\\]\ndove \\(T\\) segue una distribuzione t con \\(n-1\\) gradi di libert√†.\n\n\n65.4.2 Passo 2: Costruzione dell‚ÄôIntervallo di Confidenza\nAnalogamente al caso precedente, costruiamo l‚Äôintervallo partendo da:\n\\[\nP(-t^\\ast \\leq T \\leq t^\\ast) = \\gamma,\n\\]\ndove \\(t^\\ast\\) √® il valore critico della distribuzione t per il livello di confidenza \\(\\gamma\\) e \\(n-1\\) gradi di libert√†.\nSostituendo \\(T\\):\n\\[\nP\\left(-t^\\ast \\leq \\frac{\\bar{X} - \\mu}{s / \\sqrt{n}} \\leq t^\\ast\\right) = \\gamma.\n\\]\nMoltiplichiamo per \\(s / \\sqrt{n}\\):\n\\[\nP\\left(-t^\\ast \\cdot \\frac{s}{\\sqrt{n}} \\leq \\bar{X} - \\mu \\leq t^\\ast \\cdot \\frac{s}{\\sqrt{n}}\\right) = \\gamma.\n\\]\nAggiungiamo \\(\\mu\\):\n\\[\nP\\left(\\bar{X} - t^\\ast \\cdot \\frac{s}{\\sqrt{n}} \\leq \\mu \\leq \\bar{X} + t^\\ast \\cdot \\frac{s}{\\sqrt{n}}\\right) = \\gamma.\n\\]\n\n\n65.4.3 Passo 3: Limiti dell‚ÄôIntervallo\nI limiti dell‚Äôintervallo sono:\n\\[\n\\hat{a} = \\bar{X} - t^\\ast \\cdot \\frac{s}{\\sqrt{n}}, \\quad \\hat{b} = \\bar{X} + t^\\ast \\cdot \\frac{s}{\\sqrt{n}}.\n\\]\nIn conclusione, gli intervalli di confidenza forniscono un modo per quantificare l‚Äôincertezza nelle stime di parametri sconosciuti. La loro costruzione dipende dalla distribuzione campionaria dello stimatore e dall‚Äôinformazione disponibile sulla varianza.\n\n\n65.4.4 Applicabilit√† e Limitazioni\n\nIl metodo presuppone che la popolazione segua una distribuzione normale e √® valido anche per campioni di piccole dimensioni (ad esempio, \\(n &lt; 30\\)) prelevati da tale popolazione.\nSe la popolazione non √® normalmente distribuita e la dimensione del campione √® ridotta, questo metodo potrebbe non essere idoneo.\nTuttavia, per campioni di grandi dimensioni (\\(n \\geq 30\\)), questo approccio rimane valido per la stima dell‚Äôintervallo di confidenza grazie al teorema del limite centrale, che si applica anche a popolazioni con distribuzioni non normali.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>65</span>¬† <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#livello-di-copertura",
    "href": "chapters/frequentist_inference/02_conf_interv.html#livello-di-copertura",
    "title": "65¬† Intervalli di fiducia",
    "section": "65.5 Livello di Copertura",
    "text": "65.5 Livello di Copertura\nPer interpretare correttamente gli intervalli di fiducia √® fondamentale considerare il concetto di ‚Äúlivello di copertura‚Äù. Questo livello indica la frequenza con cui l‚Äôintervallo di fiducia include il valore reale del parametro della popolazione, in una serie di esperimenti ripetuti.\nEsempio di Livello di Copertura:\n\nSe il livello di copertura √® del 95%, significa che, nel lungo periodo, il 95% degli intervalli di fiducia costruiti conterr√† il valore vero del parametro.\nImportante: Questo non implica che ci sia una probabilit√† del 95% che il valore vero del parametro cada in un particolare intervallo di fiducia. Infatti, il parametro della popolazione √® un valore fisso e non soggetto a probabilit√†; piuttosto, l‚Äôincertezza risiede nell‚Äôintervallo di fiducia stesso.\n\nCome Funziona la Copertura:\n\nNel contesto frequentista, la ‚Äúprobabilit√†‚Äù si riferisce alla frequenza a lungo termine di un certo evento in un gran numero di ripetizioni dell‚Äôesperimento.\nNel caso degli intervalli di fiducia, l‚Äô‚Äúesperimento‚Äù √® l‚Äôestrazione di un campione dalla popolazione, e l‚Äô‚Äúevento‚Äù √® la generazione di un intervallo di fiducia che contiene il valore vero del parametro.\nIl livello di copertura, generalmente indicato come \\(1-\\alpha\\), rappresenta la probabilit√† a lungo termine che intervalli di fiducia costruiti con questa metodologia includano il vero valore del parametro.\n\n\n65.5.1 Simulazione\n\nPer illustrare questo concetto, eseguiamo una simulazione con la popolazione degli adulti maschi italiani, assunta come normalmente distribuita con media 175 cm e varianza 49 cm¬≤.\nEseguiamo 1000 ripetizioni di un esperimento, estraendo ogni volta un campione di 30 individui.\nPer ciascun campione, calcoliamo l‚Äôintervallo di fiducia al 95% usando la formula:\n\n\\[\n\\bar{X} \\pm t \\frac{s}{\\sqrt{n}},\n\\]\ndove \\(\\bar{X}\\) √® la media campionaria, \\(s\\) √® la deviazione standard campionaria e \\(t\\) √® il valore critico della distribuzione t-Student per \\(n-1\\) gradi di libert√† al livello di significativit√† \\(\\alpha/2 = 0.025\\). - Registriamo i limiti di ciascun intervallo e controlliamo quanti di essi includono effettivamente il vero valore medio della popolazione.\nAttraverso questa simulazione, possiamo visualizzare concretamente il concetto di livello di copertura e la sua importanza nella statistica frequentista.\nIn questa simulazione, genereremo 1000 campioni casuali di dimensione \\(n = 30\\) da una distribuzione normale con media \\(\\mu = 175\\) e deviazione standard \\(\\sigma = 7\\). Successivamente, calcoleremo gli intervalli di confidenza al 95% per ciascun campione e valuteremo il livello di copertura.\n\nset.seed(123)  # Per riproducibilit√†\n\n# Parametri della distribuzione\nmu &lt;- 175\nsigma &lt;- 7\nn &lt;- 30\nn_samples &lt;- 1000\n\n# Generazione dei campioni\nsamples &lt;- replicate(n_samples, rnorm(n, mean = mu, sd = sigma))\ndim(samples)  # Verifica dimensioni: 30 righe per 1000 colonne\n#&gt; [1]   30 1000\n\nIl primo campione di ampiezza \\(n = 30\\) che abbiamo ottenuto √® il seguente:\n\nsamples[, 1]  # Primo campione\n#&gt;  [1] 171 173 186 175 176 187 178 166 170 172 184 178 178 176 171 188 178 161\n#&gt; [19] 180 172 168 173 168 170 171 163 181 176 167 184\n\nStampiamo le medie dei primi dieci campioni:\n\nsample_means &lt;- colMeans(samples)  # Medie di tutti i campioni\nsample_means[1:10]  # Prime dieci medie\n#&gt;  [1] 175 176 175 174 174 176 175 174 175 177\n\nTroviamo il valore critico della distribuzione \\(t\\) di Student con \\(n - 1\\) gradi di libert√† e livello di confidenza del 95% (\\(\\alpha = 0.05\\)):\n\nalpha &lt;- 0.05\nt_critical &lt;- qt(1 - alpha / 2, df = n - 1)  # Valore critico\nt_critical\n#&gt; [1] 2.05\n\nUtilizzando il valore critico \\(t\\), calcoliamo 1000 intervalli di confidenza per la media della popolazione:\n\n# Calcolo della deviazione standard campionaria\nsample_sds &lt;- apply(samples, 2, sd)\n\n# Ampiezza degli intervalli\ninterval_width &lt;- t_critical * sample_sds / sqrt(n)\n\n# Limiti degli intervalli di confidenza\nCI_low &lt;- sample_means - interval_width\nCI_high &lt;- sample_means + interval_width\n\nTroviamo il livello di copertura, ovvero la proporzione di intervalli di confidenza che contengono il vero valore della media della popolazione \\(\\mu\\):\n\ncoverage &lt;- mean(CI_low &lt; mu & mu &lt; CI_high)  # Proporzione di copertura\ncoverage\n#&gt; [1] 0.956\n\nIn conclusione, ripetendo la simulazione per 1000 campioni, abbiamo ottenuto un livello di copertura molto vicino al valore nominale di \\(1 - \\alpha = 0.95\\). Questo risultato dimostra che, con un campione di dimensione \\(n = 30\\), gli intervalli di confidenza al 95% calcolati utilizzando la distribuzione \\(t\\) di Student forniscono stime accurate della media della popolazione.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>65</span>¬† <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#il-concetto-di-livello-di-confidenza",
    "href": "chapters/frequentist_inference/02_conf_interv.html#il-concetto-di-livello-di-confidenza",
    "title": "65¬† Intervalli di fiducia",
    "section": "65.6 Il Concetto di Livello di Confidenza",
    "text": "65.6 Il Concetto di Livello di Confidenza\nGli intervalli di confidenza sono range di valori che, con una certa sicurezza statistica, si ritiene includano il parametro di interesse.\nSecondo l‚Äôapproccio frequentista, l‚Äôintervallo di confidenza si deve considerare come una metodologia:\n\nSe ripetiamo l‚Äôesperimento (estrarre un campione e calcolare l‚Äôintervallo di confidenza) molte volte, il metodo produce un intervallo che coprir√† il valore vero del parametro nel 95% dei casi, assumendo un livello di confidenza del 95%.\n\n\n65.6.1 Un Malinteso Comune nell‚ÄôInterpretazione degli Intervalli di Confidenza\n√à inesatto affermare che un determinato intervallo di confidenza contenga il valore vero di un parametro con una probabilit√† del 95%. Questo √® un errore diffuso, persino tra i ricercatori, che spesso interpretano l‚Äôintervallo di confidenza come indicativo della probabilit√† che il parametro (ad esempio, la media della popolazione \\(\\mu\\)) si trovi effettivamente all‚Äôinterno di un dato intervallo (es. \\([\\hat{a}, \\hat{b}]\\)).\nLa descrizione corretta √® la seguente:\n\n‚ÄúLa metodologia impiegata per calcolare l‚Äôintervallo \\([\\hat{a}, \\hat{b}]\\) ha il 95% di probabilit√† di generare un intervallo che include il vero valore del parametro‚Äù.\nCi√≤ significa che l‚Äôintervallo di confidenza non esprime una probabilit√† circa la posizione precisa del parametro, ma riflette la probabilit√† che la procedura adottata per determinarlo generi un intervallo che lo includa.\n\nIn conclusione, l‚Äôintervallo di confidenza ci fornisce una garanzia statistica riguardo alla affidabilit√† del metodo usato per la sua stima, piuttosto che sulla esatta ubicazione del parametro in questione.\n\n\n65.6.2 Fraintendimenti Comuni sugli Intervalli di Confidenza\nNel loro lavoro, Hoekstra et al. (2014) evidenziano come, nonostante l‚Äôampio riconoscimento dei limiti dei test di ipotesi nulle, gli intervalli di confidenza siano spesso consigliati per l‚Äôinferenza statistica. Anche l‚ÄôAmerican Psychological Association (APA) suggerisce che gli intervalli di confidenza siano ‚Äúin generale, la migliore strategia di reportistica‚Äù. Tuttavia, Hoekstra et al. (2014) sottolineano che queste raccomandazioni non considerano la difficolt√† nel fornire una corretta interpretazione degli intervalli di confidenza.\nPer indagare l‚Äôinterpretazione degli intervalli di confidenza, Hoekstra et al. (2014) hanno condotto uno studio con due domande principali:\n\nQuanto frequentemente intervalli di confidenza sono mal interpretati da studenti e ricercatori?\nL‚Äôesperienza nella ricerca riduce le interpretazioni errate degli intervalli di confidenza?\n\nPrima di presentare lo studio, {cite}hoekstra2014robust ricordano qual √® l‚Äôinterpretazione corretta degli intervalli di confidenza.\n\nA CI is a numerical interval constructed around the estimate of a parameter. Such an interval does not, however, directly indicate a property of the parameter; instead, it indicates a property of the procedure, as is typical for a frequentist technique. Specifically, we may find that a particular procedure, when used repeatedly across a series of hypothetical data sets (i.e., the sample space), yields intervals that contain the true parameter value in 95% of the cases. When such a procedure is applied to a particular data set, the resulting interval is said to be a 95% CI. The key point is that the CIs do not provide for a statement about the parameter as it relates to the particular sample at hand; instead, they provide for a statement about the performance of the procedure of drawing such intervals in repeated use. Hence, it is incorrect to interpret a CI as the probability that the true value is within the interval (e.g., Berger & Wolpert, 1988). As is the case with \\(p\\)-values, CIs do not allow one to make probability statements about parameters or hypotheses.\n\nNel loro studio, Hoekstra et al. (2014) hanno presentato un questionario a 596 partecipanti, tra cui studenti universitari e ricercatori, con le seguenti affermazioni riguardanti l‚Äôinterpretazione degli intervalli di confidenza.\n\nProfessor Bumbledorf conducts an experiment, analyzes the data, and reports: ‚ÄúThe 95% confidence interval for the mean ranges from 0.1 to 0.4.‚Äù Please mark each of the statements below as ‚Äòtrue‚Äô or ‚Äòfalse‚Äô.\n\n\n\nThe probability that the true mean is greater than 0 is at least 95%.\nThe probability that the true mean equals 0 is smaller than 5%.\nThe ‚Äúnull hypothesis‚Äù that the true mean equals 0 is likely to be incorrect.\nThere is a 95% probability that the true mean lies between 0.1 and 0.4.\nWe can be 95% confident that the true mean lies between 0.1 and 0.4.\nIf we were to repeat the experiment over and over, then 95% of the time the true mean falls between 0.1 and 0.4.\n\n\nSorprendentemente, anche se tutte le sei affermazioni nel questionario sono errate, molti partecipanti hanno concordato con esse. I risultati mostrano che, in media, i partecipanti hanno concordato con circa 3.5 affermazioni errate su 6. Non √® stata rilevata una differenza di rilievo nell‚Äôinterpretazione degli intervalli di confidenza tra studenti e ricercatori, suggerendo che l‚Äôesperienza nella ricerca non migliora la comprensione di questo concetto.\nI risultati indicano che molte persone interpretano erroneamente gli intervalli di confidenza, e che anche l‚Äôesperienza nella ricerca non garantisce una migliore comprensione. Questo solleva dubbi sull‚Äôefficacia degli intervalli di confidenza frequentisti e suggerisce che gli ‚Äúintervalli di credibilit√†‚Äù bayesiani possano rappresentare un‚Äôalternativa pi√π vantaggiosa. Quest‚Äôultimi tendono ad essere pi√π intuitivi e di pi√π facile interpretazione corretta.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>65</span>¬† <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#confronto-tra-intervalli-frequentisti-e-bayesiani",
    "href": "chapters/frequentist_inference/02_conf_interv.html#confronto-tra-intervalli-frequentisti-e-bayesiani",
    "title": "65¬† Intervalli di fiducia",
    "section": "65.7 Confronto tra Intervalli Frequentisti e Bayesiani",
    "text": "65.7 Confronto tra Intervalli Frequentisti e Bayesiani\nConcludiamo questo capitolo esaminando le differenze tra l‚Äôintervallo di confidenza frequentista e l‚Äôintervallo di credibilit√† bayesiano, utilizzando lo stesso set di dati per entrambi i calcoli.\n\n65.7.1 Intervallo di confidenza frequentista\nImmaginiamo di avere un gruppo di 20 osservazioni relative alla performance in un test cognitivo. Il nostro obiettivo √® stimare la media della popolazione da cui queste osservazioni sono tratte. Supponiamo che i dati provengano da una distribuzione normale con media \\(\\mu = 50\\) e deviazione standard \\(\\sigma = 10\\).\n\nset.seed(123)  # Per risultati riproducibili\n\n# Parametri della popolazione\nsample_size &lt;- 20\nmu &lt;- 50\nsigma &lt;- 10\n\n# Simulazione del campione\nsample_data &lt;- rnorm(sample_size, mean = mu, sd = sigma)\nprint(sample_data)\n#&gt;  [1] 44.4 47.7 65.6 50.7 51.3 67.2 54.6 37.3 43.1 45.5 62.2 53.6 54.0 51.1\n#&gt; [15] 44.4 67.9 55.0 30.3 57.0 45.3\n\nVisualizziamo la distribuzione dei dati:\n\nhist(\n  sample_data, \n  probability = TRUE, \n  main = \"Distribuzione dei dati campionari\", \n  xlab = \"Valori\", \n  ylab = \"Densit√†\"\n)\n\n\n\n\n\n\n\n\nLa media campionaria (\\(\\hat{\\mu}\\)) viene calcolata come:\n\\[\n\\hat{\\mu} = \\frac{1}{n} \\sum_{i=1}^n X_i\n\\]\nIn R:\n\nsample_mean &lt;- mean(sample_data)\nsample_mean\n#&gt; [1] 51.4\n\nLa deviazione standard campionaria (\\(s\\)) si calcola come:\n\\[\ns = \\sqrt{\\frac{\\sum_{i=1}^n (X_i - \\bar{X})^2}{n-1}}\n\\]\nIn R:\n\nvariance &lt;- function(x) {\n  sum((x - mean(x))^2) / length(x)\n}\n\nsample_sd &lt;- sqrt(variance(sample_data))  # Deviazione standard campionaria\nsample_sd\n#&gt; [1] 9.48\n\nL‚Äôerrore standard della media (\\(SE\\)) √®:\n\\[\nSE = \\frac{s}{\\sqrt{n}}\n\\]\nIn R:\n\nstandard_error &lt;- sample_sd / sqrt(sample_size)\nstandard_error\n#&gt; [1] 2.12\n\nUn intervallo di confidenza √® definito come:\n\\[\n\\bar{X} \\pm t_{\\text{critico}} \\cdot SE\n\\]\ndove \\(t_{\\text{critico}}\\) √® il valore critico della distribuzione \\(t\\) di Student per un livello di confidenza del 95% (\\(\\alpha = 0.05\\)) e \\(n-1\\) gradi di libert√†. In R:\n\nalpha &lt;- 0.05\ndf &lt;- sample_size - 1\nt_critical &lt;- qt(1 - alpha / 2, df)\nt_critical\n#&gt; [1] 2.09\n\nCalcoliamo il margine di errore:\n\nmargin_of_error &lt;- t_critical * standard_error\nmargin_of_error\n#&gt; [1] 4.44\n\nCalcoliamo i limiti inferiore e superiore dell‚Äôintervallo di confidenza:\n\nconfidence_interval &lt;- \n  c(sample_mean - margin_of_error, sample_mean + margin_of_error)\nconfidence_interval\n#&gt; [1] 47.0 55.9\n\nPossiamo interpretare questo risultato dicendo che la procedura utilizzata per calcolare l‚Äôintervallo include il valore vero della media della popolazione nel 95% dei casi.\nCreiamo un grafico per mostrare la distribuzione dei dati, la media campionaria e l‚Äôintervallo di confidenza:\n\nhist(\n  sample_data, \n  probability = TRUE, \n  main = \"Intervallo di Confidenza per la Media\", \n  xlab = \"Valori\", \n  ylab = \"Densit√†\"\n)\nabline(v = sample_mean, col = \"blue\", lwd = 2, lty = 2)  # Media campionaria\nabline(v = confidence_interval, col = \"darkgreen\", lwd = 2)  # Limiti dell'intervallo\nlegend(\n  \"topright\", \n  legend = c(\"Media campionaria\", \"Intervallo di Confidenza\"),\n  col = c(\"blue\", \"darkgreen\"), \n  lty = c(2, 1), \n  lwd = 2\n)\n\n\n\n\n\n\n\n\n\n\n65.7.2 Intervallo di Credibilit√† Bayesiano\nPer determinare l‚Äôintervallo di credibilit√† bayesiano, utilizziamo un modello Bayesiano che assume una distribuzione normale per i dati osservati. Le distribuzioni a priori sono scelte in modo da riflettere una conoscenza preliminare debolmente informativa:\n\nDistribuzione a priori di \\(\\mu\\): Normale centrata su \\(\\mu_0 = 0\\) con deviazione standard ampia (\\(\\sigma_0 = 200\\)).\nDistribuzione a priori di \\(\\sigma\\): Normale troncata positiva (\\(\\text{HalfNormal}\\)) con deviazione standard di 100.\n\nQueste scelte sono progettate per minimizzare l‚Äôintroduzione di bias, mantenendo l‚Äôanalisi conservativa.\nL‚Äôintervallo di credibilit√† calcolato fornisce una gamma di valori entro cui si trova il parametro \\(\\mu\\) con un grado di credenza del 95%, date le informazioni a priori e i dati osservati.\n\n\n65.7.3 Confronto tra i Due Approcci\nIntervallo di Credibilit√† Bayesiano:\n\nRappresenta il grado di credenza (posteriori) che il parametro \\(\\mu\\) si trovi all‚Äôinterno dell‚Äôintervallo calcolato.\nDipende sia dai dati osservati sia dalle distribuzioni a priori utilizzate nel modello, che possono influenzare il risultato in base alla loro specificit√† o vaghezza.\n\nIntervallo di Confidenza Frequentista:\n\nNon esprime la probabilit√† che il parametro \\(\\mu\\) appartenga a un determinato intervallo.\nSi riferisce invece alla procedura di costruzione dell‚Äôintervallo: se il campionamento fosse ripetuto infinite volte, il 95% degli intervalli costruiti conterrebbe il vero valore di \\(\\mu\\).\n\nIn sintesi:\n\nL‚Äôintervallo di credibilit√† bayesiano fornisce una stima probabilistica diretta e interpretabile della posizione di \\(\\mu\\), basata su dati osservati e informazioni a priori.\nL‚Äôintervallo di confidenza frequentista, invece, valuta la affidabilit√† della procedura nel lungo termine, senza fare affermazioni dirette sulla probabilit√† che il parametro rientri nell‚Äôintervallo specifico.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>65</span>¬† <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#riflessioni-conclusive",
    "href": "chapters/frequentist_inference/02_conf_interv.html#riflessioni-conclusive",
    "title": "65¬† Intervalli di fiducia",
    "section": "65.8 Riflessioni Conclusive",
    "text": "65.8 Riflessioni Conclusive\nCome sottolineato da Hoekstra et al. (2014), √® comune riscontrare fraintendimenti riguardo agli intervalli di fiducia. Il ‚Äúlivello di confidenza del 95%‚Äù √® da interpretarsi come la probabilit√† a lungo termine che, in una serie di intervalli di fiducia calcolati, il 95% di essi includa il vero valore del parametro sconosciuto. Tuttavia, per un singolo intervallo di fiducia, non √® possibile dichiarare con sicurezza che questo contenga effettivamente il parametro di interesse. In altre parole, la certezza sulla presenza del parametro sconosciuto all‚Äôinterno di un dato intervallo di fiducia non √® garantita per ogni singolo caso analizzato.\n√à inoltre inesatto presumere che esista un legame diretto tra la varianza e la media di un campione, ipotizzando che un intervallo di fiducia pi√π ristretto implichi maggiore precisione. Nella prospettiva frequentista, la ‚Äúprecisione‚Äù √® strettamente legata al livello di copertura a lungo termine assicurato dal metodo usato per creare gli intervalli di fiducia. Questo concetto non si applica al singolo intervallo di fiducia osservato. Dunque, un intervallo di fiducia che si presenta estremamente ristretto potrebbe in realt√† essere significativamente lontano dal valore vero del parametro non noto.\n√à importante sottolineare che l‚Äôapproccio frequentista offre un metodo per calcolare gli intervalli di confidenza per una vasta gamma di statistiche. Questo include, ad esempio, la stima dell‚Äôintervallo di confidenza per la differenza tra due medie, per una proporzione o per la differenza tra due proporzioni. Ecco le formule per calcolare gli intervalli di confidenza per i casi menzionati:\nIntervallo di confidenza per la differenza tra due medie.\nSe abbiamo due campioni indipendenti di dimensione \\(n_1\\) e \\(n_2\\), con medie \\(\\bar{x}_1\\) e \\(\\bar{x}_2\\) e deviazioni standard \\(s_1\\) e \\(s_2\\), l‚Äôintervallo di confidenza per la differenza tra le medie √® calcolato come:\n\\[\n(\\bar{x}_1 - \\bar{x}_2) \\pm t_{\\alpha/2} \\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}},\n\\]\ndove \\(t_{\\alpha/2}\\) √® il valore critico della distribuzione t di Student con \\(\\alpha/2\\) di probabilit√† di coda e gradi di libert√† \\(df = n_1 + n_2 - 2\\).\nIntervallo di confidenza per una proporzione.\nPer stimare l‚Äôintervallo di confidenza per una proporzione \\(p\\) in un campione binomiale di dimensione \\(n\\), la formula √®:\n\\[\n\\hat{p} \\pm z_{\\alpha/2} \\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}},\n\\]\ndove \\(\\hat{p}\\) √® la proporzione campionaria e \\(z_{\\alpha/2}\\) √® il valore critico della distribuzione normale standard con \\(\\alpha/2\\) di probabilit√† di coda.\nIntervallo di confidenza per la differenza tra due proporzioni.\nPer stimare l‚Äôintervallo di confidenza per la differenza tra due proporzioni \\(p_1\\) e \\(p_2\\) in due campioni binomiali di dimensioni \\(n_1\\) e \\(n_2\\), la formula √®:\n\\[\n(\\hat{p}_1 - \\hat{p}_2) \\pm z_{\\alpha/2} \\sqrt{\\frac{\\hat{p}_1(1 - \\hat{p}_1)}{n_1} + \\frac{\\hat{p}_2(1 - \\hat{p}_2)}{n_2}},\n\\]\ndove \\(\\hat{p}_1\\) e \\(\\hat{p}_2\\) sono le proporzioni campionarie e \\(z_{\\alpha/2}\\) √® il valore critico della distribuzione normale standard con \\(\\alpha/2\\) di probabilit√† di coda.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>65</span>¬† <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/02_conf_interv.html#informazioni-sullambiente-di-sviluppo",
    "title": "65¬† Intervalli di fiducia",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: US/Pacific\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] bayestestR_0.15.0    posterior_1.6.0.9000 cmdstanr_0.8.1      \n#&gt;  [4] ggokabeito_0.1.0     see_0.9.0            gridExtra_2.3       \n#&gt;  [7] patchwork_1.3.0      bayesplot_1.11.1     psych_2.4.12        \n#&gt; [10] scales_1.3.0         markdown_1.13        knitr_1.49          \n#&gt; [13] lubridate_1.9.4      forcats_1.0.0        stringr_1.5.1       \n#&gt; [16] dplyr_1.1.4          purrr_1.0.2          readr_2.1.5         \n#&gt; [19] tidyr_1.3.1          tibble_3.2.1         ggplot2_3.5.1       \n#&gt; [22] tidyverse_2.0.0      rio_1.2.3            here_1.0.1          \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tensorA_0.36.2.1     generics_0.1.3       stringi_1.8.4       \n#&gt;  [4] lattice_0.22-6       hms_1.1.3            digest_0.6.37       \n#&gt;  [7] magrittr_2.0.3       evaluate_1.0.1       grid_4.4.2          \n#&gt; [10] timechange_0.3.0     fastmap_1.2.0        rprojroot_2.0.4     \n#&gt; [13] jsonlite_1.8.9       processx_3.8.5       backports_1.5.0     \n#&gt; [16] ps_1.8.1             abind_1.4-8          mnormt_2.1.1        \n#&gt; [19] cli_3.6.3            rlang_1.1.4          munsell_0.5.1       \n#&gt; [22] withr_3.0.2          yaml_2.3.10          tools_4.4.2         \n#&gt; [25] parallel_4.4.2       tzdb_0.4.0           checkmate_2.3.2     \n#&gt; [28] colorspace_2.1-1     pacman_0.5.1         vctrs_0.6.5         \n#&gt; [31] R6_2.5.1             lifecycle_1.0.4      htmlwidgets_1.6.4   \n#&gt; [34] insight_1.0.1        pkgconfig_2.0.3      pillar_1.10.1       \n#&gt; [37] gtable_0.3.6         glue_1.8.0           xfun_0.50           \n#&gt; [40] tidyselect_1.2.1     farver_2.1.2         htmltools_0.5.8.1   \n#&gt; [43] nlme_3.1-166         rmarkdown_2.29       compiler_4.4.2      \n#&gt; [46] distributional_0.5.0",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>65</span>¬† <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#bibliografia",
    "href": "chapters/frequentist_inference/02_conf_interv.html#bibliografia",
    "title": "65¬† Intervalli di fiducia",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nHoekstra, R., Morey, R. D., Rouder, J. N., & Wagenmakers, E.-J. (2014). Robust misinterpretation of confidence intervals. Psychonomic Bulletin & Review, 21(5), 1157‚Äì1164.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>65</span>¬† <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html",
    "href": "chapters/frequentist_inference/03_sample_size.html",
    "title": "66¬† La grandezza del campione",
    "section": "",
    "text": "66.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nPreparazione del Notebook\nLa scelta della dimensione campionaria √® cruciale per garantire che i risultati di uno studio siano affidabili, bilanciando precisione e costi. In questo capitolo, analizzeremo come calcolare la dimensione campionaria necessaria per stimare la media di una popolazione con un margine di errore prefissato e un determinato livello di confidenza. Utilizzeremo un esempio psicologico per illustrare il processo e fornire implementazioni in R.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>66</span>¬† <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html#la-logica-dietro-la-scelta-della-dimensione-campionaria",
    "href": "chapters/frequentist_inference/03_sample_size.html#la-logica-dietro-la-scelta-della-dimensione-campionaria",
    "title": "66¬† La grandezza del campione",
    "section": "66.2 La Logica Dietro la Scelta della Dimensione Campionaria",
    "text": "66.2 La Logica Dietro la Scelta della Dimensione Campionaria\nIn psicologia, stimare la media di una variabile (ad esempio, il punteggio medio di una scala psicometrica) √® un‚Äôoperazione comune. Campioni pi√π grandi garantiscono:\n\nStime pi√π precise: La varianza dell‚Äôestimatore diminuisce con l‚Äôaumentare della dimensione campionaria.\nMaggiore fiducia nei risultati: Il margine di errore si restringe.\n\nTuttavia, i campioni pi√π grandi comportano costi pi√π elevati in termini di tempo e risorse. Pertanto, il problema si riduce spesso a determinare il campione pi√π piccolo che garantisce la precisione richiesta.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>66</span>¬† <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html#calcolo-della-dimensione-campionaria-derivazione-della-formula",
    "href": "chapters/frequentist_inference/03_sample_size.html#calcolo-della-dimensione-campionaria-derivazione-della-formula",
    "title": "66¬† La grandezza del campione",
    "section": "66.3 Calcolo della Dimensione Campionaria: Derivazione della Formula",
    "text": "66.3 Calcolo della Dimensione Campionaria: Derivazione della Formula\nPer campioni sufficientemente grandi, la media stimata \\(\\bar{X}\\) segue una distribuzione normale:\n\\[\n\\bar{X} \\sim \\mathcal{N}\\left(\\mu, \\frac{\\sigma^2}{n}\\right),\n\\]\ndove \\(n\\) √® la dimensione del campione, \\(\\mu\\) √® la vera media della popolazione e \\(\\sigma^2\\) √® la varianza della popolazione.\nIl nostro obiettivo √® trovare la dimensione campionaria \\(n\\) tale che:\n\\[\nP\\left(|\\bar{X} - \\mu| &lt; E\\right) \\geq 0.95,\n\\]\ndove:\n\n\\(\\bar{X}\\) √® la media campionaria,\n\\(\\mu\\) √® la media della popolazione,\n\\(E\\) √® il margine di errore massimo accettabile.\n\nSappiamo che, per il teorema centrale del limite o per le propriet√† della distribuzione normale:\n\\[\n\\bar{X} \\sim \\mathcal{N}\\left(\\mu, \\frac{\\sigma^2}{n}\\right),\n\\]\ndove \\(\\sigma^2\\) √® la varianza della popolazione e \\(n\\) √® la dimensione campionaria.\nPer trasformare in termini della variabile standardizzata \\(Z\\), utilizziamo:\n\\[\nZ = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}},\n\\]\nche implica:\n\\[\n\\bar{X} \\sim \\mathcal{N}\\left(0, 1\\right).\n\\]\nPertanto, la probabilit√† richiesta si riscrive:\n\\[\nP\\left(|\\bar{X} - \\mu| &lt; E\\right) = P\\left(|Z| &lt; z_{0.025}\\right),\n\\]\ndove \\(z_{0.025} = 1.96\\) √® il quantile superiore della distribuzione normale standard, corrispondente a un livello di confidenza del \\(95\\%\\).\nDalla definizione della variabile standardizzata:\n\\[\nZ = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}},\n\\]\npossiamo ricavare la relazione per il margine di errore:\n\\[\n|\\bar{X} - \\mu| &lt; E \\implies Z = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}} \\implies |\\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}}| &lt; \\frac{E}{\\sigma / \\sqrt{n}}.\n\\]\nSostituendo la condizione \\(|Z| &lt; z_{0.025}\\), otteniamo:\n\\[\n\\frac{E}{\\sigma / \\sqrt{n}} = z_{0.025}.\n\\]\nMoltiplichiamo entrambi i membri per \\(\\sigma / \\sqrt{n}\\):\n\\[\nE = z_{0.025} \\cdot \\frac{\\sigma}{\\sqrt{n}}.\n\\]\nIsoliamo \\(\\sqrt{n}\\) dividendo entrambi i membri per \\(z_{0.025} \\cdot \\sigma\\):\n\\[\n\\sqrt{n} = \\frac{z_{0.025} \\cdot \\sigma}{E}.\n\\]\nPer ottenere \\(n\\), eleviamo entrambi i membri al quadrato:\n\\[\nn = \\left(\\frac{z_{0.025} \\cdot \\sigma}{E}\\right)^2.\n\\]\nIn conclusione, la dimensione campionaria minima \\(n\\) necessaria per soddisfare il margine di errore \\(E\\) e il livello di confidenza richiesto √®:\n\\[\nn = \\left(\\frac{z_{0.025} \\cdot \\sigma}{E}\\right)^2.\n\\]",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>66</span>¬† <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html#stima-della-media-del-punteggio-di-autostima",
    "href": "chapters/frequentist_inference/03_sample_size.html#stima-della-media-del-punteggio-di-autostima",
    "title": "66¬† La grandezza del campione",
    "section": "66.4 Stima della Media del Punteggio di Autostima",
    "text": "66.4 Stima della Media del Punteggio di Autostima\nPer fare un esempio, immaginiamo di voler stimare la media del punteggio di autostima in una popolazione di giovani adulti. Utilizziamo la Rosenberg Self-Esteem Scale (RSES), che assegna un punteggio compreso tra 0 e 30.\nDettagli del problema:\n\nDeviazione standard del punteggio: \\(\\sigma = 6\\) (stimata da studi precedenti).\nMargine di errore massimo accettabile: \\(E = 2\\).\nLivello di confidenza: \\(95\\%\\).\n\nImplementiamo in R la formula derivata in precedenza.\n\n# Parametri del problema\nsigma &lt;- 6     # Deviazione standard del punteggio RSES\nE &lt;- 2         # Margine di errore desiderato\nz_alpha &lt;- qnorm(0.975)  # Quantile superiore della distribuzione normale (95% confidenza)\n\n# Calcolo della dimensione campionaria\nn &lt;- (z_alpha * sigma / E)^2\nn &lt;- ceiling(n)  # Arrotondamento all'intero successivo\nn\n#&gt; [1] 35\n\nIn conclusione, la dimensione campionaria minima necessaria per stimare la media del punteggio di autostima con un margine di errore massimo di 2 punti e un livello di confidenza del 95% √® \\(n = 35\\).\n\n66.4.1 Approfondimenti\n\nPrecisione e Livello di Confidenza\nAumentando \\(n\\), la varianza di \\(\\bar{X}\\) diminuisce:\n\\[\n\\text{Var}(\\bar{X}) = \\frac{\\sigma^2}{n}.\n\\]\nQuesto restringe l‚Äôintervallo di confidenza e migliora la precisione.\nCosto e Praticit√†\nUn campione pi√π grande aumenta i costi. √à importante trovare il giusto compromesso tra precisione e fattibilit√†.\nAdattamento ad Altri Livelli di Confidenza\nPer altri livelli di confidenza, basta modificare il quantile \\(z_{\\alpha/2}\\). Ad esempio, per un livello di confidenza del 99%, \\(z_{0.005} \\approx 2.576\\).",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>66</span>¬† <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html#riflessioni-conclusive",
    "href": "chapters/frequentist_inference/03_sample_size.html#riflessioni-conclusive",
    "title": "66¬† La grandezza del campione",
    "section": "66.5 Riflessioni Conclusive",
    "text": "66.5 Riflessioni Conclusive\nDeterminare la dimensione del campione √® essenziale per ogni studio psicologico. Un approccio matematico rigoroso ci permette di bilanciare la precisione delle stime con i vincoli di risorse.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>66</span>¬† <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/03_sample_size.html#informazioni-sullambiente-di-sviluppo",
    "title": "66¬† La grandezza del campione",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: US/Pacific\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] ggokabeito_0.1.0 see_0.9.0        gridExtra_2.3    patchwork_1.3.0 \n#&gt;  [5] bayesplot_1.11.1 psych_2.4.12     scales_1.3.0     markdown_1.13   \n#&gt;  [9] knitr_1.49       lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1   \n#&gt; [13] dplyr_1.1.4      purrr_1.0.2      readr_2.1.5      tidyr_1.3.1     \n#&gt; [17] tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3       \n#&gt; [21] here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.3         rlang_1.1.4       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       yaml_2.3.10       tools_4.4.2       parallel_4.4.2   \n#&gt; [21] tzdb_0.4.0        colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5      \n#&gt; [25] R6_2.5.1          lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3  \n#&gt; [29] pillar_1.10.1     gtable_0.3.6      glue_1.8.0        xfun_0.50        \n#&gt; [33] tidyselect_1.2.1  farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-166     \n#&gt; [37] rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>66</span>¬† <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html",
    "title": "67¬† Significativit√† statistica",
    "section": "",
    "text": "67.1 Introduzione\nIl test di ipotesi √® un metodo fondamentale della ricerca scientifica, utilizzato per fare inferenze sui parametri della popolazione a partire dai dati campionari. Nel contesto della psicologia, questo approccio viene frequentemente impiegato per valutare l‚Äôefficacia di interventi psicologici, confrontare teorie o approcci, analizzare l‚Äôinfluenza di variabili psicologiche su comportamenti e processi cognitivi, e approfondire i meccanismi alla base di fenomeni complessi come apprendimento, memoria ed emozioni.\nIn questo capitolo ci focalizzeremo sul test di ipotesi frequentista, un metodo largamente utilizzato ma non privo di limiti. √à importante sottolineare che la comunit√† statistica sconsiglia di affidarsi esclusivamente a questo approccio come criterio decisionale per valutare la validit√† di un risultato sperimentale.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>67</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#introduzione",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#introduzione",
    "title": "67¬† Significativit√† statistica",
    "section": "",
    "text": "67.1.1 Significativit√† Statistica: Un Concetto da Riconsiderare\nTradizionalmente, un risultato √® considerato ‚Äústatisticamente significativo‚Äù se la probabilit√† che sia dovuto al caso √® bassa, il che suggerisce che il risultato sia stabile o reale. Al contrario, risultati ‚Äúnon significativi‚Äù vengono spesso etichettati come privi di valore e ignorati. Questa semplificazione, per√≤, pu√≤ portare a gravi fraintendimenti. Ad esempio:\n\nDipendenza dal campione: La significativit√† statistica √® fortemente influenzata dalla dimensione del campione; risultati apparentemente ‚Äúsignificativi‚Äù possono emergere anche da effetti molto piccoli in campioni ampi.\nRisultati non significativi: Un risultato non significativo non implica che l‚Äôeffetto sia nullo o irrilevante.\nScelte soggettive: Livelli di confidenza e test statistici differenti possono influenzare l‚Äôesito dell‚Äôanalisi, portando a interpretazioni arbitrarie.\n\n\n\n67.1.2 Limiti e Applicazioni del Metodo Frequentista\nL‚Äôapproccio frequentista non sempre mantiene la ‚Äúpromessa‚Äù di fornire una base oggettiva per la decisione statistica. Spesso, nella pratica scientifica, il ricorso esclusivo alla significativit√† statistica conduce a risultati opposti a quelli desiderati, aumentando il rischio di pubblicare risultati non replicabili o di trascurare evidenze importanti.\nIn alternativa, √® pi√π utile considerare il risultato osservato nel contesto scientifico pi√π ampio, integrandolo con altre analisi. Questo approccio critico e completo consente di superare i limiti della significativit√† statistica e di interpretare i risultati con maggiore rigore.\n\n\n67.1.3 Un Caso Specifico: La Media del Campione\nInfine, analizzeremo il caso della media campionaria come stimatore della media della popolazione, discutendone i limiti e le applicazioni nel contesto della statistica inferenziale frequentista. Questo esempio ci permetter√† di evidenziare aspetti pratici e teorici del test di ipotesi e di riflettere su come migliorare l‚Äôinterpretazione dei risultati nella ricerca psicologica.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>67</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#il-test-di-ipotesi",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#il-test-di-ipotesi",
    "title": "67¬† Significativit√† statistica",
    "section": "67.2 Il Test di Ipotesi",
    "text": "67.2 Il Test di Ipotesi\nIl test di ipotesi √® un metodo statistico utilizzato per valutare se i dati sono coerenti con l‚Äôipotesi nulla (\\(H_0\\)). L‚Äôipotesi nulla solitamente afferma che non vi √® alcun effetto o differenza significativa, mentre l‚Äôipotesi alternativa (\\(H_1\\)) rappresenta l‚Äôaffermazione che si desidera testare. I dati del campione vengono analizzati per determinare se forniscono prove sufficienti per rifiutare l‚Äôipotesi nulla. Un passaggio cruciale consiste nel calcolare il value-p.\n\n67.2.1 La procedura di Test di Ipotesi\nPasso 1: Formulare l‚Äôipotesi nulla (\\(H_0\\)) e l‚Äôipotesi alternativa (\\(H_1\\)) basandosi sulla domanda di ricerca.\nPasso 2: Stabilire un livello di significativit√†, Œ± (solitamente 0.05).\nPasso 3: Selezionare il Test Statistico appropriato, verificare eventuali assunzioni e calcolare il test statistico.\nPasso 4: Decidere se il risultato √® ‚Äústatisticamente significativo‚Äù secondo (a) la regione di rifiuto o (b) il valore-p.\n\nL‚Äôapproccio della regione di rifiuto. Basandosi sulla distribuzione campionaria nota del test statistico, la regione di rifiuto √® un insieme di valori per il test statistico per i quali l‚Äôipotesi nulla viene rifiutata. Se il valore osservato del test statistico rientra nella regione di rifiuto, allora si rifiuta l‚Äôipotesi nulla.\nL‚Äôapproccio del valore-p.¬†Il valore-p √® la probabilit√† di ottenere i risultati osservati, o risultati ancora pi√π estremi, se l‚Äôipotesi nulla √® vera.\n\nConfrontiamo il valore-p calcolato con il livello di significativit√† Œ±:\n\nSe il valore-p &lt; Œ±, si rifiuta l‚Äôipotesi nulla (\\(H_0\\)).\nSe il valore-p ‚â• Œ±, non si rifiuta l‚Äôipotesi nulla (\\(H_0\\)).",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>67</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#il-test-di-ipotesi-nel-contesto-frequentista",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#il-test-di-ipotesi-nel-contesto-frequentista",
    "title": "67¬† Significativit√† statistica",
    "section": "67.3 Il Test di Ipotesi nel Contesto Frequentista",
    "text": "67.3 Il Test di Ipotesi nel Contesto Frequentista\nSi noti che i metodi bayesiani e frequentisti non sono semplicemente due approcci diversi per rispondere alla stessa domanda, ma formulano domande fondamentalmente diverse. Pertanto, per comprendere il test di ipotesi frequentista, √® essenziale chiarire cosa si intende per valore-p.\nL‚ÄôAmerican Statistical Association (ASA) definisce il valore-p come:\n\nthe probability under a specified statistical model that a statistical summary of the data (e.g., the sample mean difference between two compared groups) would be equal to or more extreme than its observed value (Wasserstein e Lazar 2016).\n\nQuesta definizione pu√≤ risultare difficile da comprendere perch√© contiene concetti complessi come ‚Äúprobabilit√†‚Äù e ‚Äúmodello statistico specificato‚Äù. Per capire meglio cosa rappresenta un valore-p, √® necessario esaminare attentamente entrambi questi concetti. Questo ci porter√† anche a una comprensione pi√π profonda di altri concetti fondamentali per l‚Äôinferenza frequentista e ci aiuter√† a distinguere tra inferenza frequentista e inferenza bayesiana.\nUna distinzione fondamentale tra l‚Äôapproccio frequentista e quello bayesiano riguarda l‚Äôinterpretazione della probabilit√†: il primo si basa sulla frequenza relativa degli eventi nel lungo periodo, mentre il secondo si basa sulla ‚Äúcertezza soggettiva‚Äù o sul grado di fiducia che un individuo attribuisce a un evento specifico.\nChiarito che la probabilit√† assume significati diversi nei contesti frequentista e bayesiano, possiamo chiederci quale nozione di probabilit√† sia implicita nella definizione del valore-p fornita dall‚ÄôASA. La visione comune suggerisce che si riferisca alle frequenze relative. Ma frequenze relative di cosa e ripetizioni di cosa?\nPossiamo riformulare la definizione dell‚ÄôASA in questo modo:\n\nIl valore-p si riferisce alla frequenza relativa di ottenere un riassunto statistico dei dati grande quanto o pi√π grande del valore osservato in ripetizioni ipotetiche di un esperimento descritto da un modello statistico specificato.\n\nQuindi, l‚Äôapproccio frequentista pu√≤ essere descritto come un metodo per stimare il valore di un parametro attraverso esperimenti ipotetici, confrontando i nostri dati con i risultati di tali esperimenti per giudicare se i nostri dati sono sorprendenti o meno.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>67</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#applicazione-alla-media-campionaria",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#applicazione-alla-media-campionaria",
    "title": "67¬† Significativit√† statistica",
    "section": "67.4 Applicazione alla Media Campionaria",
    "text": "67.4 Applicazione alla Media Campionaria\nIn questo capitolo ci concentreremo sull‚Äôapplicazione del processo di test di ipotesi frequentista alla media campionaria. Vedremo come la media di un campione possa essere impiegata per trarre inferenze sulla media di una popolazione, analizzandone limiti e possibili utilizzi nell‚Äôambito dell‚Äôinferenza statistica frequentista.\nI test su uno o due campioni (one-sample e two-sample tests) hanno rappresentato le prime fondamenta dell‚Äôanalisi statistica dei dati. Al giorno d‚Äôoggi, tuttavia, i nostri disegni sperimentali tendono a essere pi√π complessi di quanto questi semplici test possano gestire. Nonostante ci√≤, tali test ‚Äì in particolare il celebre t-test di Student ‚Äì costituiscono ancora un‚Äôottima porta d‚Äôingresso alla modellazione statistica, poich√© i principi su cui si basano sono relativamente intuitivi e consentono di familiarizzare con il processo di verifica dell‚Äôipotesi.\nPer comprendere meglio i valori-p e la verifica del test di ipotesi, pu√≤ essere molto utile ricorrere a simulazioni. Attraverso queste ultime √® possibile ricreare condizioni sperimentali ipotetiche e osservare la variabilit√† dei risultati, fornendo cos√¨ una prospettiva pi√π chiara sulle implicazioni della statistica frequentista.\n\n67.4.1 La Distribuzione della Media Campionaria\nQuando consideriamo la media campionaria come stima della media di una popolazione, assumiamo che questa popolazione segua una distribuzione normale. Vogliamo quindi esplorare la distribuzione della media campionaria (\\(\\bar{X}\\)), che descrive la variazione di \\(\\bar{X}\\) attraverso infiniti campioni di dimensione \\(n\\). Abbiamo gi√† dimostrato che, se la popolazione √® normalmente distribuita, anche la distribuzione campionaria di \\(\\bar{X}\\) seguir√† una distribuzione normale, con media \\(\\mu\\) (la media della popolazione) e deviazione standard \\(\\frac{\\sigma}{\\sqrt{n}}\\) (dove \\(\\sigma\\) √® la deviazione standard della popolazione e \\(n\\) √® la dimensione del campione).\n\n\n67.4.2 Test di Ipotesi sulla Media Campionaria\nSupponendo di conoscere \\(\\sigma\\) ma non \\(\\mu\\), utilizziamo i test di ipotesi per indagare quanto la media campionaria osservata si discosti da un valore ipotetico \\(\\mu_0\\), specificato dall‚Äôipotesi nulla. Questo processo ci permette di valutare la plausibilit√† di \\(\\mu_0\\) come vera media della popolazione.\n\n\n67.4.3 Calcolo della Statistica del Test\nPer valutare quanto la media campionaria osservata si discosti dall‚Äôipotesi nulla che propone \\(\\mu = \\mu_0\\), standardizziamo \\(\\bar{X}\\) usando la formula:\n\\[\nZ = \\frac{\\bar{X} - \\mu_0}{\\sigma/\\sqrt{n}}\n\\]\nQuesta trasformazione produce una variabile \\(Z\\) che segue una distribuzione normale standard \\(\\mathcal{N}(0, 1)\\). Valori estremi di \\(Z\\) (sia molto grandi che molto piccoli) suggeriscono che la media campionaria osservata √® incompatibile con \\(\\mu_0\\), portando al rigetto dell‚Äôipotesi nulla.\n\n67.4.3.1 Simulazione\nPer illustrare quanto espresso sopra attraverso una simulazione, consideriamo un esempio numerico. Supponiamo che \\(\\mu_0 = 100\\), \\(\\sigma = 15\\) e \\(n = 30\\). Vogliamo calcolare il valore-p per l‚Äôevento \\(\\bar{X} &gt; 105\\).\nLa simulazione pu√≤ essere eseguita come segue:\n\n# To make the simulation reproducible\nset.seed(123)\n\nmu_0 &lt;- 100\nsigma &lt;- 15\nn &lt;- 30\nn_sim &lt;- 10000  # Number of simulations\n\n# Generate n_sim sample means from a N(mu_0, sigma/sqrt(n))\nsample_means &lt;- rnorm(n_sim, mean = mu_0, sd = sigma / sqrt(n))\n\n# Calculate the p-value as the proportion of sample means &gt; 105\np_value &lt;- mean(sample_means &gt; 105)\n\n# Print the p-value\nprint(p_value)\n#&gt; [1] 0.0339\n\nQuesto script simula la distribuzione campionaria di \\(\\bar{X}\\) sotto l‚Äôipotesi nulla che \\(\\mu = \\mu_0\\) e calcola il valore-p per l‚Äôevento \\(\\bar{X} &gt; 105\\). Il valore-p indica la probabilit√† di osservare un valore di \\(\\bar{X}\\) cos√¨ estremo (o pi√π estremo) se l‚Äôipotesi nulla fosse vera.\nIl risultato della simulazione pu√≤ essere confrontato con il calcolo teorico del valore-p usando la distribuzione normale standard. Il valore \\(Z\\) per \\(\\bar{X} = 120\\) √® calcolato come:\n\\[\nZ = \\frac{105 - 100}{15/\\sqrt{30}}\n\\]\nPossiamo usare la funzione stats.norm.sf() per trovare l‚Äôarea sotto la curva normale standard a destra di questo valore \\(Z\\), che corrisponde al valore-p teorico.\n\n# Calculate the Z-score\nZ &lt;- (105 - 100) / (15 / sqrt(30))\nprint(Z)\n#&gt; [1] 1.83\n\n\n# Calculate the upper tail probability\nupper_tail_prob &lt;- pnorm(Z, lower.tail = FALSE)\n\nprint(upper_tail_prob)\n#&gt; [1] 0.0339\n\nOppure, in maniera equivalente\n\n# Calculate the upper tail probability\nupper_tail_prob &lt;- 1 - pnorm(105, mean = 100, sd = 15 / sqrt(30))\nprint(upper_tail_prob)\n#&gt; [1] 0.0339\n\nIl calcolo teorico mostra che il valore \\(Z\\) per una media campionaria di 105 √® 1.82. Questo valore indica una deviazione sostanziale dalla media ipotizzata sotto l‚Äôipotesi nulla (\\(\\mu_0 = 100\\)). Tale deviazione pu√≤ essere quantificata dalla ‚Äúsorpresa‚Äù indicata dal valore-p, dove valori-p piccoli rappresentano una maggiore sorpresa. Il valore-p ottenuto, pari a 0.0339, indica un elevato grado di sorpresa: come mostrato dalla simulazione, un valore di 105 o superiore si verifica solo nel 3.4% dei casi se l‚Äôesperimento viene ripetuto numerose volte sotto l‚Äôipotesi nulla. Questo suggerisce che un risultato del genere √® altamente improbabile se l‚Äôipotesi nulla fosse vera.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>67</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#applicazioni-pratiche",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#applicazioni-pratiche",
    "title": "67¬† Significativit√† statistica",
    "section": "67.5 Applicazioni pratiche",
    "text": "67.5 Applicazioni pratiche\nNella precedente discussione, abbiamo supposto \\(\\sigma\\) nota. Tuttavia, poich√© di solito non conosciamo il valore di \\(\\sigma\\) nella pratica, dobbiamo stimarlo utilizzando la deviazione standard campionaria \\(s\\). Pertanto, al posto di \\(\\sigma\\), possiamo utilizzare \\(s\\), ottenendo cos√¨ la statistica:\n\\[\nT = \\frac{\\bar{X} - \\mu_0}{\\frac{s}{\\sqrt{n}}}.\n\\]\nSi pu√≤ dimostrare che la statistica \\(T\\) segue una distribuzione \\(t\\) di Student con \\(n-1\\) gradi di libert√† se il campione casuale √® stato estratto da una popolazione normale.\nA questo punto, possiamo applicare la stessa logica descritta in precedenza e possiamom basarci sulla statistica \\(T\\) per testare un‚Äôipotesi sulla media della popolazione. Utilizzando il valore critico appropriato dalla distribuzione \\(t\\) di Student con \\(n-1\\) gradi di libert√† e un livello di significativit√† predefinito, possiamo determinare se i dati osservati supportano o respingono l‚Äôipotesi nulla sulla media della popolazione.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>67</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#ipotesi-statistiche",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#ipotesi-statistiche",
    "title": "67¬† Significativit√† statistica",
    "section": "67.6 Ipotesi statistiche",
    "text": "67.6 Ipotesi statistiche\nEsaminiamo in maggior dettaglio la procedura di test di ipotesi statistiche nel contesto frequentista. Definiamo innanzitutto l‚Äôipotesi statistica come una dichiarazione riguardante la distribuzione di probabilit√† di una variabile casuale. Tale ipotesi pu√≤ riguardare la forma funzionale della distribuzione o i parametri che la caratterizzano.\nIn particolare, l‚Äôipotesi che riguarda i parametri di una o pi√π popolazioni viene denominata ipotesi nulla e viene rappresentata come \\(H_0\\). Per un parametro sconosciuto \\(\\theta\\), l‚Äôipotesi nulla viene formulata come:\n\\[\nH_0: \\theta \\in \\Theta_0 \\subset \\Theta,\n\\]\ndove \\(\\Theta_0\\) √® un sottoinsieme del dominio \\(\\Theta\\), che rappresenta tutti i possibili valori del parametro \\(\\theta\\) coerenti con il modello statistico adottato. L‚Äôipotesi nulla pu√≤ essere semplice se \\(\\Theta_0\\) contiene un unico elemento, oppure composta se contiene pi√π di un elemento.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>67</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#i-passi-di-un-test-di-ipotesi",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#i-passi-di-un-test-di-ipotesi",
    "title": "67¬† Significativit√† statistica",
    "section": "67.7 I passi di un test di ipotesi",
    "text": "67.7 I passi di un test di ipotesi\nPer prendere una decisione tra accettare o respingere l‚Äôipotesi nulla, i frequentisti utilizzano un test statistico. Un test statistico frequentista ci permette di valutare se i dati osservati forniscono prove sufficienti per respingere o accettare un‚Äôipotesi riguardante una propriet√† di una popolazione di interesse e si pu√≤ descrivere nel modo seguente.\nIniziamo formulando l‚Äôipotesi nulla \\(H_0\\), che rappresenta un‚Äôaffermazione specifica sulla popolazione. L‚Äôipotesi alternativa \\(H_1\\) viene formulata come l‚Äôevento complementare rispetto all‚Äôevento specificato dall‚Äôipotesi nulla. Successivamente, definiamo una statistica campionaria \\(\\mathcal{G}_n(X_1, \\dots, X_n)\\) che viene calcolata a partire dai dati campionari e che ha una distribuzione nota quando l‚Äôipotesi nulla √® vera.\nSuccessivamente, suddividiamo l‚Äôinsieme di tutte le possibili realizzazioni della statistica \\(\\mathcal{G}_n\\) in due insiemi disgiunti: la ‚Äúregione di accettazione‚Äù \\(\\mathcal{A}\\) e la sua regione complementare, la ‚Äúregione di rifiuto‚Äù \\(\\mathcal{R}\\). La regione di accettazione rappresenta l‚Äôinsieme dei valori che la statistica pu√≤ assumere sotto l‚Äôipotesi nulla, mentre la regione di rifiuto rappresenta l‚Äôinsieme dei valori che la statistica pu√≤ assumere se l‚Äôipotesi nulla √® falsa.\nInfine, selezioniamo un livello di significativit√† \\(\\alpha\\), che rappresenta la massima probabilit√† di respingere erroneamente l‚Äôipotesi nulla quando questa √® vera. Se l‚Äôosservazione della statistica \\(\\mathcal{G}_n\\) rientra nella regione di accettazione, allora l‚Äôipotesi nulla non viene respinta; altrimenti, viene respinta a favore dell‚Äôipotesi alternativa.\nIn sintesi, il test statistico ci consente di stabilire se i dati osservati forniscono sufficienti evidenze per rifiutare l‚Äôipotesi nulla a favore dell‚Äôipotesi alternativa.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>67</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#ipotesi-alternativa",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#ipotesi-alternativa",
    "title": "67¬† Significativit√† statistica",
    "section": "67.8 Ipotesi alternativa",
    "text": "67.8 Ipotesi alternativa\nDurante un test di ipotesi, dopo aver definito l‚Äôipotesi nulla \\(H_0\\), possono essere considerate diverse ipotesi alternative \\(H_1\\). Le ipotesi alternative pi√π comuni si suddividono in tre tipi:\n\n\\(H_1: \\theta \\neq \\theta_0\\),\n\\(H_1: \\theta &gt; \\theta_0\\),\n\\(H_1: \\theta &lt; \\theta_0\\).\n\nQueste corrispondono rispettivamente a un test bidirezionale, un test unilaterale superiore (o destro) e un test unilaterale inferiore (o sinistro).\nLa scelta dell‚Äôipotesi alternativa determina la definizione della regione di rifiuto \\(\\mathcal{R}\\) dell‚Äôipotesi nulla \\(H_0\\). La regione di rifiuto rappresenta i valori estremi della distribuzione, nella direzione dell‚Äôipotesi alternativa \\(H_1\\). Nel caso di un test unilaterale inferiore, \\(\\mathcal{R}\\) si trova nella coda sinistra della distribuzione, nell‚Äôintervallo [\\(-\\infty\\), \\(\\theta_0\\)]. Nel caso di un test unilaterale superiore, \\(\\mathcal{R}\\) si trova nella coda destra della distribuzione, nell‚Äôintervallo [\\(\\theta_0\\), \\(\\infty\\)].\nI valori critici sono i valori che delimitano la regione di rifiuto \\(\\mathcal{R}\\) in un test unilaterale e i valori che delimitano le regioni di rifiuto \\(\\mathcal{R}\\) in un test bidirezionale. Il risultato di un test viene considerato statisticamente significativo se il valore della statistica del test si trova nella regione di rifiuto \\(\\mathcal{R}\\).",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>67</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#valore-p",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#valore-p",
    "title": "67¬† Significativit√† statistica",
    "section": "67.9 Valore-p",
    "text": "67.9 Valore-p\nIl valore-p √® definito come la probabilit√† che la statistica del test assuma un valore uguale o pi√π estremo di quello osservato, considerando la distribuzione campionaria costruita assumendo come vera l‚Äôipotesi nulla. La significativit√† statistica viene convenzionalmente definita come un valore-p inferiore a 0.05, indicando che l‚Äôevidenza osservata √® improbabile da ottenere se l‚Äôipotesi nulla √® vera. Se il risultato osservato non raggiunge la significativit√† statistica, significa che la stima non √® statisticamente significativa e che il valore osservato pu√≤ essere spiegato da una semplice variazione casuale.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>67</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#un-esempio-motivante",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#un-esempio-motivante",
    "title": "67¬† Significativit√† statistica",
    "section": "67.10 Un esempio motivante",
    "text": "67.10 Un esempio motivante\nPer esplorare il concetto di significativit√† statistica, possiamo prendere in considerazione uno studio svolto da Mehr et al. (2016) sul ruolo della musica nella trasmissione di messaggi sociali ai bambini. La musica √® una forma d‚Äôarte presente in molte attivit√† quotidiane e pu√≤ trasmettere informazioni relative alla cultura e all‚Äôappartenenza sociale. Gli autori dello studio hanno voluto indagare se i bambini di soli 5 mesi avessero una preferenza per individui sconosciuti che cantavano loro una canzone familiare rispetto ad altri individui sconosciuti che cantavano una canzone simile, ma con una diversa melodia.\nDalle analisi condotte da Mehr et al. (2016) √® emerso che la preferenza dei bambini si manifestava solo quando la canzone veniva cantata dai loro genitori durante la fase di familiarizzazione, ma non quando la stessa canzone veniva cantata da un estraneo. Secondo gli autori, questo dimostra che il significato sociale √® un elemento chiave nella preferenza dei bambini, oltre alla familiarit√† con la canzone.\n\n67.10.1 Domanda della ricerca e ipotesi statistiche\nLa ricerca condotta da Mehr et al. (2016) si √® concentrata sullo studio dell‚Äôinfluenza della musica sui messaggi sociali trasmessi ai bambini molto piccoli. Tuttavia, come molte altre ipotesi psicologiche, l‚Äôipotesi principale non pu√≤ essere valutata direttamente in termini quantitativi. Pertanto, i ricercatori devono formulare ipotesi statistiche, che, sebbene non coincidano con l‚Äôipotesi della ricerca, possono essere esaminate in termini probabilistici.\nPer chiarire questo punto, consideriamo l‚Äôesperimento condotto sui bambini da Mehr et al. (2016). Dopo la fase di familiarizzazione con la canzone di prova, i bambini partecipanti sono stati sottoposti a un test in laboratorio, durante il quale sono stati mostrati due video. Nel primo video, un estraneo cantava la canzone di prova, mentre nel secondo video, un altro individuo cantava una canzone simile ma non familiare ai bambini. I ricercatori hanno misurato il tempo in cui i bambini fissavano ciascun video. Nel primo esperimento, la variabile dipendente era la media delle proporzioni di tempo che i bambini fissavano il video ‚Äúfamiliare‚Äù rispetto al tempo di fissazione totale. Poich√© l‚Äôipotesi principale non pu√≤ essere valutata direttamente, i ricercatori hanno formulato ipotesi statistiche che possono essere esaminate in termini probabilistici.\nPoich√© nei tipici esperimenti psicologici, come nel caso della ricerca di Mehr et al. (2016), l‚Äôipotesi della ricerca non pu√≤ essere valutata direttamente, √® necessario stabilire una connessione tra l‚Äôipotesi della ricerca e l‚Äôipotesi statistica. Nel caso specifico, ci sono tre possibili scenari da considerare:\n\nNel caso in cui i bambini non mostrino alcuna preferenza tra i due tipi di video-registrazione, la media delle proporzioni di tempo di fissazione per la popolazione sar√† uguale a \\(\\mu = 0.5\\), in quanto i tempi di fissazione saranno uguali in media per le due video-registrazioni.\nSe invece gli autori della ricerca hanno ragione, i bambini mostreranno una preferenza per il video con la canzone familiare rispetto a quello con la canzone non familiare. In questo caso, l‚Äôipotesi statistica sar√† \\(\\mu &gt; 0.5\\), dove \\(\\mu = 0.5\\) rappresenta il livello di probabilit√† casuale.\nInfine, una terza possibilit√† √® che i bambini siano maggiormente attratti da una melodia non familiare, contrariamente a quanto suggerito dagli autori della ricerca. In tal caso, l‚Äôipotesi statistica diventa \\(\\mu &lt; 0.5\\).\n\nLe tre ipotesi precedenti sono esempi di ipotesi statistiche, che sono delle affermazioni riguardanti i valori di un parametro di un modello statistico. Nel caso dell‚Äôesperimento di Mehr et al. (2016), il modello statistico riguarda la distribuzione delle proporzioni dei tempi di fissazione di una popolazione virtuale di infiniti bambini di sei mesi di et√†. Ogni bambino avr√† una proporzione di tempi di fissazione diversa dagli altri bambini. Il modello statistico descritto dai ricercatori rappresenta la distribuzione dei possibili valori della proporzione del tempo di fissazione nei confronti del video ‚Äúfamiliare‚Äù. I dati raccolti dagli sperimentatori corrispondono alla media della proporzione del tempo di fissazione del video ‚Äúfamiliare‚Äù e possono essere messi in relazione con il modello statistico.\n\n\n67.10.2 Domanda della ricerca e ipotesi statistiche\nLa distinzione tra l‚Äôipotesi della ricerca e l‚Äôipotesi statistica √® cruciale durante il test delle ipotesi. L‚Äôipotesi della ricerca riguarda l‚Äôaffermazione che si intende testare sulla natura dei fenomeni psicologici, mentre l‚Äôipotesi statistica riguarda il modello generativo dei dati, ovvero le propriet√† della popolazione. Nel caso dell‚Äôesperimento condotto da Mehr e colleghi, l‚Äôipotesi della ricerca afferma che la preferenza sociale dei bambini √® influenzata dalla musica e, in particolare, dalla familiarit√† con i materiali musicali. L‚Äôipotesi statistica, invece, sostiene che la media della proporzione del tempo di fissazione dei bambini sul video ‚Äúfamiliare‚Äù sia maggiore di 0.5.\nI test di ipotesi vengono applicati alle ipotesi statistiche, non alle ipotesi della ricerca. Ci√≤ significa che se l‚Äôesperimento non viene condotto nella maniera appropriata, il collegamento tra l‚Äôipotesi statistica e la domanda della ricerca pu√≤ essere spezzato. Ad esempio, se l‚Äôattore che canta la melodia familiare assomiglia ad uno dei genitori del bambino, mentre l‚Äôaltro attore ha un aspetto molto diverso, allora potrebbe essere facile trovare evidenze a supporto dell‚Äôipotesi statistica secondo cui la proporzione media del tempo di fissazione dei bambini nei confronti del video ‚Äúfamiliare‚Äù √® maggiore di 0.5, ma ci√≤ non avrebbe nulla a che fare con la domanda della ricerca.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>67</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#ipotesi-nulla-e-ipotesi-alternativa",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#ipotesi-nulla-e-ipotesi-alternativa",
    "title": "67¬† Significativit√† statistica",
    "section": "67.11 Ipotesi nulla e ipotesi alternativa",
    "text": "67.11 Ipotesi nulla e ipotesi alternativa\nFino a qui il ragionamento √® stato semplice: il ricercatore ha un‚Äôipotesi a proposito dei fenomeni psicologici e a tale ipotesi di ricerca corrisponde un‚Äôipotesi statistica che riguarda il meccanismo generativo dei dati. Se il fenomeno psicologico possiede le propriet√† suggerite dall‚Äôipotesi della ricerca, allora il ricercatore pu√≤ aspettarsi che i dati osservati abbiano alcune specifiche caratteristiche. A questo punto, per√≤, il ragionamento diventa contro-intuitivo perch√© non √® possibile verificare direttamente l‚Äôipotesi statistica che corrisponde alla domanda della ricerca.\n\n67.11.1 Apagogia\nIn linea di principio, non √® mai possibile dimostrare direttamente la verit√† di una proposizione. Tuttavia, possiamo dimostrare la sua verit√† in modo indiretto, ovvero provando la falsit√† della sua proposizione complementare.\nL‚Äôesempio classico √® il seguente. Consideriamo la seguente proposizione: ‚ÄúTutti i cigni sono bianchi‚Äù (questo √® l‚Äôesempio ornitologico preferito da Popper). L‚Äôosservazione di un numero qualsiasi di cigni bianchi non √® sufficiente a dimostrare la verit√† di questa proposizione ‚Äì infatti, ci potrebbe essere da qualche parte un cigno non bianco che non abbiamo osservato (e infatti c‚Äô√®). D‚Äôaltra parte, invece, l‚Äôosservazione di un solo cigno che non sia bianco (ovvero, per esempio, l‚Äôosservazione di un cigno nero proveniente dall‚ÄôAustralia) pu√≤ falsificare la proposizione considerata. Questa √® la logica del falsificazionismo di Popper.\nQuesto modo di pensare √® stato trasferito nella procedura di test di ipotesi di stampo frequentista. Dato che non possiamo dimostrare vera l‚Äôipotesi statistica associata alla domanda della ricerca, seguiamo il percorso opposto. Ovvero, ci poniamo l‚Äôobiettivo di dimostrare falso l‚Äôevento complementare a quello specificato dall‚Äôipotesi statistica associata alla domanda della ricerca. L‚Äôipotesi statistica che vorremmo falsificare si chiama ‚Äúipotesi nulla‚Äù e viene denotata con \\(H_0\\). Nel caso dell‚Äôesempio che stiamo discutendo, l‚Äôipotesi nulla √®: \\(\\mu \\leq 0.5\\). Si noti che l‚Äôipotesi nulla include tutte le possibili ipotesi statistiche che si possono formulare (ovvero, \\(\\mu = 0.5\\) e \\(\\mu &lt; 0.5\\)), ad eccezione di quella che √® associata all‚Äôipotesi della ricerca (ovvero, \\(\\mu &gt; 0.5\\)). Questo definisce, nel caso presente, un test unilaterale.\nIn pratica, ci√≤ che stiamo facendo √® dividere tutti i possibili valori di \\(\\mu\\) in due gruppi: quei valori che sono coerenti con l‚Äôipotesi della ricerca (ovvero, i valori che specificano l‚Äôipotesi alternativa, denotata con \\(H_1\\)) e quei valori che non sono coerenti con l‚Äôipotesi della ricerca (ovvero, i valori che specificano l‚Äôipotesi nulla).\nAvendo detto questo, la cosa importante da riconoscere √® che l‚Äôobiettivo di un test di ipotesi frequentista non √® quello di dimostrare che l‚Äôipotesi alternativa √® (probabilmente) vera; l‚Äôobiettivo √® mostrare che l‚Äôipotesi nulla √® (probabilmente) falsa. La maggior parte delle persone ritiene che questo modo di ragionare sia piuttosto strano.\n\n\n67.11.2 La similitudine del processo penale\nUn test di ipotesi √® spesso comparato ad un processo penale, dove l‚Äôipotesi nulla rappresenta l‚Äôimputato, il ricercatore il pubblico ministero, e il test statistico il giudice. Cos√¨ come in un processo penale, anche in un test di ipotesi c‚Äô√® una presunzione di innocenza, dove l‚Äôipotesi nulla viene considerata vera a meno che il ricercatore non dimostri, con evidenza al di l√† di ogni ragionevole dubbio, che √® falsa. Il ricercatore progetta l‚Äôesperimento in modo da massimizzare la possibilit√† che i dati producano una condanna dell‚Äôipotesi nulla. Il test statistico, rappresentato dal giudice in questa metafora, stabilisce le regole che devono essere seguite per giungere al verdetto e tali regole sono pensate per proteggere l‚Äôipotesi nulla. In particolare, sono studiate per garantire che la probabilit√† di una condanna sia bassa se l‚Äôipotesi nulla √® effettivamente vera. √à importante sottolineare che l‚Äôipotesi nulla deve essere protetta, poich√© il ricercatore sta cercando di dimostrare che essa √® falsa.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>67</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#due-tipi-di-errori",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#due-tipi-di-errori",
    "title": "67¬† Significativit√† statistica",
    "section": "67.12 Due tipi di errori",
    "text": "67.12 Due tipi di errori\nPrima di entrare nei dettagli su come viene costruito un test statistico √® utile capire la logica su cui esso √® basato. In precedenza abbiamo paragonato il test di ipotesi nulla ad un processo penale, ma ora dobbiamo essere pi√π espliciti. Idealmente, vorremmo costruire il nostro test in modo da non commettere errori. Sfortunatamente, per√≤, questo non √® possibile: a volte il ricercatore √® sfortunato e finisce per prendere la decisione sbagliata, anche se adotta un processo decisionale razionale. Ad esempio, pu√≤ succedere che una moneta venga lanciata 10 volte di fila e produca testa tutte le 10 volte. Ci√≤ sembra fornire una prova molto forte del fatto che la moneta √® sbilanciata, ma c‚Äô√® una possibilit√† su 1024 che ci√≤ accada anche se la moneta √® equilibrata. In altre parole, nella vita reale dobbiamo sempre accettare la possibilit√† che le nostre scelte siano sbagliate, anche quando sembrano ragionevoli. Di conseguenza, l‚Äôobiettivo dei test delle ipotesi statistiche non √® quello di eliminare completamente gli errori (questo √® impossibile), ma di ridurre gli errori al minimo.\nA questo punto, dobbiamo precisare meglio cosa intendiamo per ‚Äúerrori‚Äù. Iniziamo con il rendere esplicito quello che √® ovvio: l‚Äôipotesi nulla pu√≤ essere vera o falsa, e il nostro test ci pu√≤ condurre a rifiutare l‚Äôipotesi nulla o a non rifiutarla. La decisione di rigettare o non rigettare l‚Äôipotesi nulla ci espone dunque al rischio di commettere uno di due tipi di errore, come indicato nella figura seguente. L‚Äôerrore di I tipo, denotato con \\(\\alpha\\), √® quello che commettiamo se rigettiamo l‚Äôipotesi nulla quando essa √® vera; l‚Äôerrore di II tipo, denotato con \\(\\beta\\), √® quello che commettiamo se accettiamo l‚Äôipotesi nulla mentre invece √® vera l‚Äôipotesi alternativa.\n\n\n67.12.1 Errore di I tipo: la protezione dei diritti dell‚Äôimputato\nIn precedenza abbiamo paragonato il test statistico ad un processo penale. Infatti, un processo penale richiede che si stabilisca la colpevolezza dell‚Äôimputato ‚Äúoltre ogni ragionevole dubbio‚Äù. Le regole del processo penale sono state progettate per garantire che non ci sia (quasi) nessuna possibilit√† di condannare ingiustamente un imputato innocente: il processo penale √® progettato (almeno in teoria) per proteggere i diritti dell‚Äôimputato. Detto in altri termini, il processo penale non mette sullo stesso piano i due tipi di errore che si possono commettere: punire un innocente o assolvere un colpevole. L‚Äôerrore che consiste nel punire un innocente viene considerato assai pi√π grave di quello che porta ad assolvere un colpevole.\nUn test statistico fa praticamente la stessa cosa: i test di ipotesi statistiche sono costruiti in modo tale da controllare la probabilit√† di un errore di I tipo, con l‚Äôobiettivo di mantenerla al di sotto di una certa soglia prefissata. Questa probabilit√†, denotata con \\(\\alpha\\), viene chiamata ‚Äúlivello di significativit√† del test‚Äù. Usando parole diverse, possiamo dire che un test di ipotesi ha un livello di significativit√† \\(\\alpha\\) se il tasso di errore di I tipo non √® pi√π grande di \\(\\alpha\\). Per convenzione, i ricercatori fanno uso di tre diversi livelli \\(\\alpha\\): 0.05, 0.01 e 0.001.\n\n\n67.12.2 Errore di II tipo: l‚Äôasimmetria del giudizio\nChe dire del tasso di errore di II tipo? In realt√†, vorremmo tenere anche quello sotto controllo e denotiamo la probabilit√† di un errore di II tipo con \\(\\beta\\). Il livello d‚Äôerrore \\(\\beta\\) viene raramente discusso ed √® molto pi√π comune fare riferimento alla potenza del test, che √® la probabilit√† dell‚Äôevento complementare, ovvero la probabilit√† con cui rifiutiamo l‚Äôipotesi nulla quando √® realmente falsa, ovvero \\(1-\\beta\\). Un test viene detto ‚Äúpotente‚Äù quando √® caratterizzato da un piccolo valore \\(\\beta\\) pur mantenendo il livello \\(\\alpha\\) sotto una piccola soglia di probabilit√† prefissata.\nSi noti l‚Äôasimmetria qui rivelata: i test di ipotesi sono progettati per garantire che il livello \\(\\alpha\\) sia mantenuto sotto la soglia prefissata, ma non esiste alcuna corrispondente garanzia a proposito di \\(\\beta\\). Sicuramente √® preferibile che il tasso di errore di II tipo sia piccolo, e in generale i ricercatori cercano di progettare i loro esperimenti in maniera tale da avere una ragionevole potenza del test (\\(1 - \\beta\\)) ‚Äì questo si ottiene utilizzando un campione sufficientemente grande ‚Äì ma nella logica della costruzione del test di ipotesi questo aspetto √® secondario rispetto alla necessit√† di controllare il tasso di errore di I tipo.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>67</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#come-si-costruisce-un-test-di-ipotesi",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#come-si-costruisce-un-test-di-ipotesi",
    "title": "67¬† Significativit√† statistica",
    "section": "67.13 Come si costruisce un test di ipotesi?",
    "text": "67.13 Come si costruisce un test di ipotesi?\nRitorniamo all‚Äôesempio relativo allo studio di Mehr et al. (2016). In questo caso, sulla base all‚Äôipotesi della ricerca, l‚Äôipotesi nulla pu√≤ essere formulata come \\(H_0: \\mu \\leq 0.5\\). Esaminando un campione di 32 bambini di et√† media pari a 5.6 mesi, Mehr et al. (2016) hanno scoperto che, in media, i bambini dirigevano lo sguardo verso il video ‚Äúfamiliare‚Äù nel 56% del tempo totale di fissazione. Dunque, la media campionaria √® \\(\\bar{X} = 0.56\\) Questo √® il valore campionario rilevante per il test dell‚Äôipotesi nulla.\nIngenuamente, potremmo pensare che, per decidere se \\(H_0\\) sia falsa o meno, sia sufficiente confrontare la proporzione calcolata nel campione con il valore \\(\\pi\\) specificato dall‚Äôipotesi nulla. Nel caso presente, l‚Äôipotesi nulla non specifica un unico valore \\(\\mu\\) ma bens√¨ un intervallo di valori: \\([0, 0.5]\\). I dati campionari specificano un valore \\(\\bar{X} = 0.56\\), ovvero un valore che non √® incluso nell‚Äôintervallo specificato da \\(H_0\\). Questo √® incoraggiante. Se invece avessimo osservato \\(\\bar{X} = 0.41\\), per esempio, allora non ci sarebbe stato nient‚Äôaltro da dire: se i dati osservati sono compatibili con \\(H_0\\) non c‚Äô√® bisogno di eseguire alcun test statistico ‚Äì abbiamo gi√† trovato la risposta alla domanda della ricerca.\n\n67.13.1 La variabilit√† campionaria\nNel caso dell‚Äôesperimento di Mehr et al. (2016) che stiamo discutendo, \\(\\bar{X}\\) non cade nell‚Äôintervallo specificato da \\(H_0\\). Sulla base del valore osservato \\(\\bar{X} = 0.56\\) possiamo dunque concludere che \\(H_0\\) √® falsa? Non cos√¨ presto. Non √® sufficiente trovare una differenza \\(\\bar{X} - \\mu\\) nella direzione giusta (cio√® positiva, nel nostro caso). √à anche necessario tenere in considerazione il fenomeno della variabilit√† campionaria.\nInfatti, la media \\(\\bar{X}\\) osservata in ogni singolo campione di ampiezza \\(n=32\\) √® una variabile aleatoria: in ciascun possibile campione di ampiezza 32 i bambini si comportano in maniera diversa e, di conseguenza, \\(\\bar{X}\\) assumer√† un valore diverso da campione a campione. Le statistiche campionarie ‚Äì nel nostro caso la media \\(\\bar{X}\\) ‚Äì sono di necessit√† diverse dai parametri. Ci√≤ a cui noi siamo interessati √® la media della popolazione, ovvero \\(\\mu\\), ma sfortunatamente conosciamo solo una sua realizzazione campionaria, ovvero \\(\\bar{X}\\).\nRisulta dunque chiaro che la nostra decisione rispetto ad \\(H_0\\) non pu√≤ essere unicamente basata sulla differenza tra \\(\\bar{X} - \\mu\\). Infatti, √® ragionevole pensare che, indipendentemente dal fatto che l‚Äôipotesi nulla sia vera o meno, in alcuni campioni la differenza \\(\\bar{X} - \\mu\\) sar√† positive mentre in altri campioni sar√† negativa. Dobbiamo dunque trovare una procedura che riduca la possibilit√† di rifiutare \\(H_0\\) per effetto del caso soltanto. Possiamo (e dobbiamo) fare di meglio che considerare unicamente la differenza \\(\\bar{X} - \\mu\\).\n\n\n67.13.2 Le distribuzioni delle statistiche test\nIl metodo seguito dall‚Äôapproccio frequentista per affrontare questo problema √® quello di costruire la distribuzione della statistica test \\(\\mathcal{G}_n\\), rilevante per il test di \\(H_0\\), assumendo come vera l‚Äôipotesi nulla. Questo √® il concetto pi√π contro-intuitivo di tutta la procedura di test di ipotesi dell‚Äôapproccio frequentista. Esaminiamolo pi√π in dettaglio.\nLo scopo della procedura di test statistici dell‚Äôapproccio frequentista non √® quello di verificare l‚Äôipotesi alternativa: questo non √® logicamente possibile. Invece, come suggerito dalla similitudine del processo penale all‚Äôipotesi nulla, l‚Äôapproccio frequentista si pone l‚Äôobiettivo di determinare se ci siano indizi sufficienti per ‚Äúcondannare‚Äù l‚Äôipotesi nulla, ovvero, per rigettarla. In questa reductio ad absurdum, la ‚Äúpresunzione di innocenza‚Äù di \\(H_0\\) corrisponde all‚Äôidea che dobbiamo assumere come vera l‚Äôipotesi nulla fino a prova contraria.\nNell‚Äôesempio che stiamo discutendo, assumere come vera l‚Äôipotesi nulla significa assumere che il parametro \\(\\mu\\) (la media della popolazione) sia uguale a 0.5. Sulla base di questa assunzione, per i dati dell‚Äôesempio presente, √® possibile costruire la distribuzione delle medie dei campioni di ampiezza 32. Standardizzando poi la media del campione, √® possibile stabilire quanto sia ‚Äúdistante‚Äù dal valore atteso della distribuzione campionaria costruita assumento come vera \\(H_0\\).\nLa standardizzazione di \\(\\bar{X}\\) si effettua mediante il rapporto\n\\[\nT = \\frac{\\bar{X} - \\mu}{\\frac{s}{\\sqrt{n}}},\n\\]\ndove \\(\\bar{X}\\) √® la media del campione (nel nostro caso, 0.56), \\(s\\) √® la deviazione standard del campione (gli autori riportano \\(s\\) = 0.179) e \\(n\\) √® l‚Äôampiezza del campione (ovvero, \\(n\\) = 32). Per il caso presente otteniamo:\n\nT &lt;- (0.56 - 0.50) / (0.179 / sqrt(32))\nprint(T)\n#&gt; [1] 1.9\n\n\n\n67.13.3 Regioni di rifiuto e regioni di non rifiuto\nConoscendo la distribuzione dei valori della statistica test (distribuzione determinata assumendo come vera \\(H_0\\)) diventa poi possibile dividere l‚Äôinsieme dei valori possibili di \\(\\mathcal{G}_n\\) (il nome che abbiamo assegnato ad una generica statistica test) in due regioni: i valori che ci portano a rigettare \\(H_0\\) (regione di rifiuto) e quelli che non ci consentono di rigettare \\(H_0\\) (regione di non rifiuto).\nPer decidere quanto deve essere grande la regione di rifiuto di \\(H_0\\) √® sufficiente collocare nella regione di rifiuto i valori estremi della statistica test \\(\\mathcal{G}_n\\), ovvero quelli che sarebbe molto improbabile osservare se \\(H_0\\) fosse vera.\n\n\n67.13.4 Quando rifiutare l‚Äôipotesi nulla\nSupponiamo che la figura seguente rappresenti la distribuzione campionaria della statistica test \\(\\mathcal{G}_n\\).\n\nSe i dati producono la statistica test \\(\\mathcal{G}_n^1\\), non possiamo rifiutare l‚Äôipotesi nulla \\(H_0\\). Se invece i dati producono \\(\\mathcal{G}_n^2\\) allora possiamo rifiutare l‚Äôipotesi nulla in favore dell‚Äôipotesi alternativa. Ci sono varie cose da notare.\n\nLa regione di rifiuto √® costituita da valori lontani dal centro della distribuzione campionaria della statistica test, la quale √® stata costruita assumendo come vera \\(H_0\\).\nLa regione di rifiuto √® situata nelle code della distribuzione. Vedremo in seguito anche degli esempi di regioni di rifiuto unilaterali.\nIn questa discussione, l‚Äôipotesi alternativa non √® menzionata. Rifiutiamo o non rifiutiamo \\(H_0\\) basandoci unicamente sulla distribuzione campionaria \\(f(\\mathcal{G}_n \\mid H_0)\\), cio√® sulla probabilit√† della statistica test condizionata all‚Äôipotesi nulla \\(H_0\\). L‚Äôipotesi alternativa \\(H_1\\) viene presa in considerazione quando si sceglie dove posizionare la regione di rifiuto di \\(H_0\\), ma formalmente non gioca alcun ruolo nel rigettare o meno \\(H_0\\).\n\n\n\n67.13.5 Specificazione delle regioni di rifiuto\nL‚Äôipotesi alternativa \\(H_1\\) pu√≤ assumere forme diverse e ci√≤ conduce a specificazioni diverse della regione di rifiuto \\(\\mathcal{R}\\) di \\(H_0\\). La regione di rifiuto \\(\\mathcal{R}\\) dell‚Äôipotesi nulla corrisponde ai valori collocati agli estremi della distribuzione secondo la direzione dell‚Äôipotesi alternativa \\(H_1\\).\n\nSe l‚Äôipotesi alternativa √® \\(H_1: \\theta \\neq \\theta_0\\) (dove \\(\\theta\\) √® un generico parametro e \\(\\theta_0\\) √® uno specifico valore del parametro), allora le evidenze coerenti con l‚Äôipotesi alternativa (e che portano al rigetto di \\(H_0\\)) sono contenute negli intervalli \\([-\\infty, \\theta_0]\\) e \\([\\theta_0, +\\infty]\\).\nSe l‚Äôipotesi alternativa √® \\(H_1: \\theta &lt; \\theta_0\\), allora le evidenze coerenti con l‚Äôipotesi alternativa (e che portano al rigetto di \\(H_0\\)) sono contenute nell‚Äôintervallo \\([-\\infty, \\theta_0]\\) e l‚Äôintera regione di rifiuto \\(\\mathcal{R}\\) √® collocata nella coda di sinistra della distribuzione.\nSe l‚Äôipotesi alternativa √® \\(H_1: \\theta &gt; \\theta_0\\), allora le evidenze coerenti con l‚Äôipotesi alternativa (e che portano al rigetto di \\(H_0\\)) sono contenute nell‚Äôintervallo \\([\\theta_0, \\infty]\\) e l‚Äôintera regione di rifiuto \\(\\mathcal{R}\\) √® collocata nella coda di destra della distribuzione.\n\nSi chiamano valori critici i valori che delimitano la regione di rifiuto \\(\\mathcal{R}\\) in un test unilaterale e i valori che delimitano le regioni di rifiuto \\(\\mathcal{R}\\) in un test bilaterale. In un test bidirezionale, i valori critici lasciano in ciascuna delle due code della distribuzione della statistica test una probabilit√† pari a \\(\\alpha/2\\); in un test unidirezionale lasciano una probabilit√† pari ad \\(\\alpha\\) in una sola coda. Il risultato di un test si dice statisticamente significativo quando il valore della statistica test ricade nella regione di rifiuto \\(\\mathcal{R}\\).\n\n\n67.13.6 La decisione statistica\nIl processo di decisione statistica viene descritto da von Mises (1964) nel modo seguente:\n\nControllare (checking) o saggiare (testing) ha la forma seguente: se il ‚Äúrisultato osservato‚Äù ha una ‚Äòpiccola‚Äô probabilit√† subordinatamente all‚Äôipotesi assunta, respingiamo l‚Äôipotesi. (p.¬†441)\n\nOvviamente l‚Äôipotesi a cui von Mises fa riferimento √® l‚Äôipotesi nulla.\nIn pratica, possiamo decidere se rigettare o meno l‚Äôipotesi nulla in due modi: determinando se la statistica test \\(\\mathcal{G}_n\\) cade o meno nella regione di rifiuto (come abbiamo descritto sopra) o confrontando il valore-\\(p\\) con \\(\\alpha\\) ‚Äì i due metodi sono equivalenti.\nIl valore-p rappresenta la probabilit√† di osservare un valore della statistica test \\(\\mathcal{G}_n\\) pari a quello effettivamente osservato, o maggiore, quanto l‚Äôipotesi nulla √® vera. Se il valore-\\(p\\) √® minore del livello di significativit√† \\(\\alpha\\), allora la statistica test cade nella regione di rifiuto di \\(H_0\\) e ci√≤ conduce al rifiuto dell‚Äôipotesi nulla. Tali concetti sono riassunti nella tabella seguente.\n\nPer l‚Äôesempio in discussione, la statistica \\(T\\) calcolata sopra si distribuisce come \\(t\\) di Student con \\(\\nu = 31\\) gradi di libert√†. Il valore-p corrisponde dunque all‚Äôarea sottesa ad una \\(t_{31}\\) nell‚Äôintervallo \\([1.896, +\\infty]\\) (test unidirezionale destro), ovvero\n\n# Calculate the upper tail probability for the t-distribution\np &lt;- 1 - pt(T, df = 31)\nprint(p)\n#&gt; [1] 0.0336\n\nDato che il valore-p √® minore di \\(\\alpha = 0.05\\), Mehr et al. (2016) rifiutano \\(H_0\\) (cio√® che la proporzione media del tempo di fissazione dei bambini nei confronti del video ‚Äúfamiliare‚Äù sia 0.5, o minore) e concludono che i bambini mostrano una preferenza per il video familiare.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>67</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#potenza-del-test",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#potenza-del-test",
    "title": "67¬† Significativit√† statistica",
    "section": "67.14 Potenza del test",
    "text": "67.14 Potenza del test\nRitorniamo ora al concetto di potenza del test. Il livello di significativit√† e la potenza del test vengono usati per quantificare la qualit√† dell‚Äôinferenza statistica. Idealmente, la procedura di test di ipotesi non dovrebbe giungere alla conclusione sbagliata. Ovvero, non dovrebbe respingere \\(H_0\\) quando essa √® vera e dovrebbe respingere \\(H_0\\) in favore dell‚Äôalternativa quando \\(H_1\\) √® vera. Ma questi sono solo due dei quattro esiti che, in principio, sono possibili, e corrispondono alle probabilit√† indicate di seguito.\n\nPossiamo pensare a \\(H_0\\) come all‚Äôipotesi che descrive l‚Äôevento ‚Äúnulla di interessante sta succedendo‚Äù ‚Äì ad esempio, ‚Äúla moneta √® bilanciata‚Äù, ‚Äúil trattamento non √® migliore del placebo‚Äù, ecc. ‚Äì e pensare ad \\(H_1\\) come al caso contrario, ovvero: ‚Äústa accadendo qualcosa di interessante‚Äù. Quindi la potenza del test, ovvero la probabilit√† \\(1 - \\beta\\) di rigettare \\(H_0\\) quando essa √® falsa, corrisponde alla probabilit√† di rilevare qualcosa di interessante, quando qualcosa di interessante √® effettivamente successo, mentre il livello di significativit√† corrisponde alla probabilit√† di affermare che qualcosa di interessante si √® verificato, quando in realt√† non √® successo nulla di interessante.\nIl calcolo della potenza di un test √® spesso difficile, perch√© richiede la conoscenza della distribuzione campionaria di \\(\\mathcal{G}_n\\) quando √® vera l‚Äôipotesi alternativa \\(H_1\\). Tipicamente possiamo aumentare la potenza di un test aumentando la numerosit√† del campione in maniera tale da diminuire la varianza delle distribuzioni della statistica test condizionate a \\(H_0\\) e ad \\(H_1\\). In un disegno sperimentale √® importante determinare in anticipo il numero di prove o dei soggetti necessari per raggiungere la potenza desiderata.\n\n67.14.1 Neyman e Fisher\nLa procedura di test di ipotesi statistiche descritta sopra combina due approcci teorici diversi, proposti da Sir Ronald Fisher e Jerzy Neyman. La storia di questi due approcci non √® lineare, poich√© Fisher e Neyman hanno modificato le loro opinioni nel tempo, senza mai fornire una ‚Äúverit√† definitiva‚Äù su come interpretare il loro lavoro.\nIn sintesi, Fisher considerava che il ricercatore avesse un‚Äôunica ipotesi (quella nulla) e che lo scopo fosse verificare se i dati fossero coerenti o meno con essa. In questo senso, il valore-\\(p\\) rappresenta la probabilit√† di osservare, sotto l‚Äôipotesi nulla, il risultato ottenuto o uno ancora pi√π estremo. Se il valore-\\(p\\) √® piccolo, Fisher rifiutava l‚Äôipotesi nulla. Tuttavia, poich√© non venivano formulate altre ipotesi, non c‚Äôera modo di ‚Äúaccettare l‚Äôalternativa‚Äù.\nAl contrario, Neyman adottava un approccio pi√π formale rispetto a Fisher e pensava che lo scopo della verifica delle ipotesi fosse quello di prendere decisioni. Secondo Neyman, il problema era decidere se accettare l‚Äôipotesi nulla o l‚Äôalternativa e il test serviva a stabilire quale supporto venisse fornito alle due alternative. Per questo motivo, era fondamentale specificare in modo preciso l‚Äôipotesi alternativa. Nel suo approccio, il valore-\\(p\\) non misurava la probabilit√† del risultato del test o di uno pi√π estremo sotto l‚Äôipotesi nulla, ma forniva una descrizione astratta dei ‚Äúpossibili test‚Äù che portavano all‚Äôaccettazione dell‚Äôipotesi nulla o dell‚Äôalternativa.\nAttualmente ci troviamo in una situazione strana e ambigua, dove sono presenti elementi di entrambi gli approcci. La procedura di verifica di ipotesi statistiche distingue tra un‚Äôipotesi nulla e un‚Äôipotesi alternativa, seguendo la visione di Neyman, ma definisce il valore-\\(p\\) in termini di dati estremi, come avrebbe fatto Fisher, in confronto con un livello \\(\\alpha\\) stabilito da Neyman. Alcuni test statistici specificano in modo chiaro l‚Äôipotesi alternativa, mentre altri sono pi√π vaghi in merito, adottando l‚Äôapproccio di Fisher. Inoltre, c‚Äô√® disaccordo tra i ricercatori riguardo alla possibilit√† di ‚Äúaccettare l‚Äôalternativa‚Äù, a seconda che si segua Neyman o Fisher. Questa confusione costituisce il ‚Äúpeccato originale‚Äù della procedura di verifica di ipotesi statistiche. Tuttavia, ci sono motivi pi√π specifici per cui questo approccio, noto come significativit√† statistica, viene criticato da molti ricercatori come una delle cause principali della crisi della replicabilit√† dei risultati della ricerca in psicologia e in altri campi. Nel capitolo ?sec-errors-s-m esploreremo queste ragioni in dettaglio.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>67</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#la-storia-del-test-dellipotesi-nulla-di-fisher-e-le-sue-contraddizioni",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#la-storia-del-test-dellipotesi-nulla-di-fisher-e-le-sue-contraddizioni",
    "title": "67¬† Significativit√† statistica",
    "section": "67.15 La Storia del Test dell‚ÄôIpotesi Nulla di Fisher e le Sue Contraddizioni",
    "text": "67.15 La Storia del Test dell‚ÄôIpotesi Nulla di Fisher e le Sue Contraddizioni\nConcludiamo l‚Äôanalisi della procedura dei test di ipotesi statistici esaminando l‚Äôevento che ha ispirato Ronald A. Fisher a sviluppare la sua teoria dell‚Äôinferenza statistica, focalizzata sul test dell‚Äôipotesi nulla. Questo episodio √® descritto dettagliatamente da Etz et al. (2018). L‚Äôaneddoto riguarda un t√® che Fisher aveva offerto alla sua collega, la Dott.ssa Muriel Bristol. Durante la preparazione della bevanda, la Dr.ssa Bristol contest√≤ il metodo adottato da Fisher, asserendo che il t√® avrebbe avuto un gusto migliore se il latte fosse stato versato prima dell‚Äôacqua bollente. Per verificare l‚Äôaffermazione della Dr.ssa Bristol, Fisher ide√≤ un esperimento di discriminazione sensoriale. Nei test condotti, la Dr.ssa Bristol fu in grado di individuare correttamente il processo di preparazione del t√® in cinque occasioni su sei.\nQuesto risultato pose Fisher di fronte a un interrogativo: la sua collega stava semplicemente facendo una supposizione fortunata, oppure era effettivamente in grado di discernere tra le due diverse modalit√† di preparazione? Per risolvere questa questione, Fisher elabor√≤ la sua metodologia per il test dell‚Äôipotesi nulla. Utilizz√≤ un valore-\\(p\\) calcolato sulla base della probabilit√† dell‚Äôevento osservato, nonch√© di qualsiasi altro evento pi√π estremo che potrebbe verificarsi sotto l‚Äôipotesi nulla.\nTuttavia, √® stato fatto notare che l‚Äôapproccio di Fisher al test dell‚Äôipotesi nulla pu√≤ essere insufficiente e portare a conclusioni errate (Etz et al., 2018). Una delle questioni fondamentali riguarda la definizione di un evento ‚Äúpi√π estremo‚Äù rispetto a quello osservato.\nSupponiamo che lo scopo dell‚Äôesperimento casuale sia di determinare l‚Äôaccuratezza delle riposte della Dr.ssa Bristol in esattamente sei tentativi (e non di pi√π). In tale caso, con 5 risposte corrette, il valore-\\(p\\) √® pari a 0.109, che non √® statisticamente significativo. In questo scenario, secondo la logica di Fisher, non si dovrebbe respingere l‚Äôipotesi nulla che la Dr.¬†Bristol stesse semplicemente indovinando.\nSupponiamo ora che lo scopo dell‚Äôesperimento casuale sia di continuare a servire t√® fino a quando la Dr.ssa Bristol non abbia raggiunto cinque risposte corrette (un risultato che, per coincidenza, si √® verificato dopo sei tentativi). Se analizziamo i dati in questo secondo scenario, il valore-\\(p\\) diventa pari a 0.031, che √® statisticamente significativo. In quest‚Äôultimo caso, l‚Äôipotesi nulla verrebbe respinta.\nQuello che emerge √® che, nonostante i dati osservati nei due scenari siano identici, giungiamo a conclusioni opposte come conseguenza delle diverse modalit√† di campionamento impiegate. Questa variabilit√† √® problematica poich√© il valore-\\(p\\), e quindi la nostra valutazione delle capacit√† discriminative della Dr.ssa Bristol, dipendono non solo dai dati effettivamente raccolti, ma anche dal disegno sperimentale adottato. Questa constatazione mette in discussione la robustezza del test dell‚Äôipotesi nulla come strumento fondamentale per l‚Äôinferenza scientifica.\nPer illustrare il problema, svolgiamo i calcoli utilizzando le distribuzioni statistiche richieste per i due tipi di campionamento: la distribuzione binomiale e la distribuzione geometrica negativa.\n\n67.15.1 Distribuzione Binomiale\nLa distribuzione binomiale √® la distribuzione da utilizzare quando il numero di tentativi √® prefissato e conosciuto a priori. Nel contesto dell‚Äôesempio del t√®, assumiamo che siano state servite esattamente sei tazze. La formula per determinare la probabilit√† di registrare esattamente \\(k\\) successi in \\(n\\) tentativi √® la seguente:\n\\[\nP(X = k) = \\binom{n}{k} \\times p^k \\times (1-p)^{(n-k)}\n\\]\nQui, \\(\\binom{n}{k}\\) rappresenta il coefficiente binomiale, \\(p\\) √® la probabilit√† di un singolo successo (ossia di indovinare correttamente la preparazione del t√®), e \\((1-p)\\) √® la probabilit√† di un singolo fallimento.\nPer calcolare il valore-\\(p\\) in questo specifico contesto, dobbiamo sommare le probabilit√† di ottenere un risultato di 5 o pi√π estremo su un totale di 6 tentativi.\n\n# Parameters\nn_binomial &lt;- 6  # Number of fixed trials for the binomial distribution\nn_success &lt;- 5  # Desired number of successes\np &lt;- 0.5  # Probability of success\n\n# Calculate the p-value for the binomial distribution\np_value_binomial &lt;- 1 - pbinom(n_success - 1, size = n_binomial, prob = p)\n\np_value_binomial\n#&gt; [1] 0.109\n\n\n\n67.15.2 Distribuzione Geometrica Negativa\nNel contesto dell‚Äôesperimento del t√®, quando il test continua fino al raggiungimento di un numero prefissato di successi (nel nostro caso, cinque identificazioni corrette), la distribuzione di riferimento appropriata √® la distribuzione geometrica negativa.\nLa distribuzione geometrica negativa modella il numero di fallimenti \\(k\\) che si verificano prima di ottenere un numero prefissato \\(r\\) di successi in una sequenza di prove indipendenti di Bernoulli, dove ogni prova ha probabilit√† di successo \\(p\\).\nLa probabilit√† di osservare esattamente \\(k\\) fallimenti prima di ottenere \\(r\\) successi √® data da:\n\\[\nP(X = k) = \\binom{k+r-1}{k} p^r (1-p)^k,\n\\]\ndove:\n\n\\(k\\) √® il numero di fallimenti,\n\\(r\\) √® il numero di successi desiderato,\n\\(p\\) √® la probabilit√† di successo in ogni prova,\n\\(\\binom{k+r-1}{k}\\) √® il coefficiente binomiale che rappresenta il numero di modi possibili in cui \\(k\\) fallimenti e \\(r\\) successi possono essere ordinati.\n\nNel nostro caso specifico:\n\n\\(r = 5\\) (successi desiderati),\n\\(p = 0.5\\) (probabilit√† di indovinare correttamente sotto l‚Äôipotesi nulla),\n\\(k\\) varia da 0 a 1 (possibili fallimenti prima del quinto successo).\n\nIl valore-p si calcola sommando le probabilit√† per tutti i casi ‚Äúpi√π estremi‚Äù di quello osservato:\n\\[\n\\text{valore-p} = \\sum_{k=0}^{1} \\binom{k+5-1}{k} (0.5)^5 (0.5)^k.\n\\]\nImplementazione:\n\n# Parameters\nn_binomial &lt;- 6  # Number of fixed trials for the binomial distribution\nn_success &lt;- 5  # Desired number of successes\np &lt;- 0.5  # Probability of success (guessing the tea cup)\n\n# Calculate the p-value for the negative binomial distribution\np_value_geom_corrected &lt;- 0\nfor (k in 0:(n_binomial - n_success - 1)) {  # Number of failures before the 5th success\n  p_value_geom_corrected &lt;- p_value_geom_corrected + \n    choose(k + n_success - 1, k) * ((1 - p)^k) * (p^n_success)\n}\n\np_value_geom_corrected\n#&gt; [1] 0.0312\n\nIn conclusione,\n\nper la distribuzione binomiale, il p-value √® \\(0.109\\), che non √® statisticamente significativo (dato che √® maggiore di 0.05); quindi, secondo Fisher, in questo caso non dovremmo rigettare l‚Äôipotesi nulla che Dr.¬†Bristol stia indovinando.\nper la distribuzione geometrica negativa, il p-value √® \\(0.031\\), che √® statisticamente significativo (dato che √® minore di 0.05); in questo caso, dovremmo rigettare l‚Äôipotesi nulla, suggerendo che Dr.¬†Bristol non sta semplicemente indovinando.\n\nLa presente discussione mostra che, in base alla procedura del test dell‚Äôipotesi nulla, la stessa sequenza di eventi (5 successi su 6 tentativi) pu√≤ portare a conclusioni opposte a seconda delle ipotesi sul processo di campionamento. Questo paradosso √® uno dei motivi (per ulteriori critiche, si veda Wasserstein & Lazar (2016); Benjamin et al. (2018)) per cui l‚Äôinferenza bayesiana √® diventata pi√π popolare negli ultimi anni come quadro alternativo per il test delle ipotesi e la stima dei parametri.\n\n\n67.15.3 Approccio Bayesiano\nNel loro lavoro, Etz et al. (2018) propongono un‚Äôalternativa bayesiana per risolvere il problema esaminato da Fisher. Questa soluzione bayesiana evita le contraddizioni che emergono quando si cercano di definire ‚Äúrisultati pi√π estremi‚Äù che non sono stati osservati. L‚Äôapproccio bayesiano si focalizza esclusivamente sui dati effettivamente raccolti e utilizza queste osservazioni per aggiornare le probabilit√† iniziali (o ‚Äúa priori‚Äù) associate a diverse ipotesi. Il processo si basa sulla regola di Bayes e si sviluppa in tre fasi principali:\n\nStabilire Probabilit√† a Priori: Iniziamo assegnando una distribuzione di probabilit√† a priori a tutti i possibili tassi di successo che la Dr.¬†Bristol potrebbe avere. Questo include una probabilit√† specifica per l‚Äôipotesi nulla, che suggerisce che la Dr.¬†Bristol stia semplicemente indovinando (con un tasso di successo del 50%).\nAggiornare le Probabilit√† con Dati Osservati: Utilizziamo i dati raccolti nell‚Äôesperimento per aggiornare le nostre probabilit√† a priori. Questo aggiornamento √® fatto utilizzando la regola di Bayes.\nCalcolare il Fattore di Bayes: Questa metrica ci dice quanto i dati osservati influenzano le probabilit√† delle diverse ipotesi. Un Fattore di Bayes molto maggiore di 1 indicherebbe un forte supporto per l‚Äôipotesi alternativa rispetto all‚Äôipotesi nulla.\n\nNel caso specifico, il Fattore di Bayes calcolato √® risultato essere circa 147.33, un valore notevolmente alto. Questo suggerisce che i dati osservati sono molto pi√π compatibili con l‚Äôipotesi che la Dr.ssa Bristol possa effettivamente distinguere tra le diverse preparazioni del t√®, piuttosto che con l‚Äôipotesi che stia indovinando.\nEtz et al. (2018) concludono che l‚Äôapproccio bayesiano offre un quadro pi√π robusto e coerente per il test delle ipotesi. A differenza del metodo frequentista, esso non dipende dalla definizione di ‚Äúrisultati pi√π estremi‚Äù non osservati e si concentra invece esclusivamente sui dati effettivamente raccolti. Questa focalizzazione, in generale, rende l‚Äôapproccio bayesiano una soluzione pi√π solida per valutare le ipotesi scientifiche. Per una rivisitazione bayesiana dell‚Äôesperimento ‚ÄúThe Lady Tasting Tea‚Äù, si veda anche la discussione di Doorn et al. (2020).",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>67</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#malintesi-sul-valore-p",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#malintesi-sul-valore-p",
    "title": "67¬† Significativit√† statistica",
    "section": "67.16 Malintesi sul valore-p",
    "text": "67.16 Malintesi sul valore-p\nSono diffusi molti malintesi sul valore-p.¬†Ne esaminiamo qui quelli pi√π comuni.\nMalinteso 1: Un valore p non significativo significa che l‚Äôipotesi nulla √® vera.\nIl malinteso che un valore p non significativo (p &gt; 0.05) implichi l‚Äôassenza di effetto o la verit√† dell‚Äôipotesi nulla √® diffuso e porta a conclusioni errate. La chiave per evitare questo errore sta nel comprendere che i valori p riflettono la probabilit√† dei dati osservati sotto l‚Äôipotesi nulla, e non la probabilit√† dell‚Äôipotesi stessa. Un valore p elevato non dimostra che l‚Äôipotesi nulla sia vera, ma indica semplicemente che i dati osservati non sono sufficientemente insoliti da rifiutare l‚Äôipotesi nulla con un livello di confidenza predefinito.\nRisultati non significativi possono verificarsi anche quando esiste un effetto reale, ma i dati non sono abbastanza estremi da superare la soglia di significativit√† statistica.\nInvece di concludere affrettatamente l‚Äôassenza di effetto da un valore p non significativo, dovremmo riconoscere l‚Äôambiguit√† e considerare altre possibilit√†. Dichiarazioni come ‚Äúnon c‚Äôera differenza‚Äù dovrebbero essere riformulate in termini di assenza di differenza statisticamente significativa, lasciando aperta la questione dell‚Äôesistenza di un effetto reale.\nL‚Äôapproccio bayesiano offre una prospettiva diversa che pu√≤ essere particolarmente utile per interpretare risultati non significativi. A differenza dei valori p, che si limitano a valutare la probabilit√† dei dati sotto l‚Äôipotesi nulla, l‚Äôinferenza bayesiana permette di calcolare direttamente la probabilit√† delle ipotesi date i dati.\nL‚Äôapproccio bayesiano, quindi, non si limita a rifiutare o non rifiutare l‚Äôipotesi nulla, ma quantifica la forza dell‚Äôevidenza a favore di un‚Äôipotesi rispetto all‚Äôaltra, fornendo una conclusione pi√π informativa rispetto al semplice ‚Äúnon posso rifiutare l‚Äôipotesi nulla‚Äù.\nMalintesto 2: Un valore p significativo significa che l‚Äôipotesi nulla √® falsa.\nCome spiegato in precedenza, il valore-p quantifica la ‚Äúsorpresa‚Äù suscitata dai dati, alla luce dell‚Äôipotesi nulla. Non ci dice niente sull‚Äôipotesi che abbiamo assunto per quantificare la ‚Äúsorpresa‚Äù.\nMalinteso 3: Un valore p significativo significa che √® stato scoperto un effetto importante.\nLa distinzione tra ‚Äúsignificativit√† statistica‚Äù e ‚Äúrilevanza pratica‚Äù √® fondamentale: mentre la prima indica semplicemente che un risultato √® improbabile sotto l‚Äôipotesi nulla, la seconda valuta l‚Äôeffetto nel contesto di applicazioni reali e le sue implicazioni.\nUn effetto statisticamente significativo non garantisce che l‚Äôeffetto abbia un impatto pratico notevole o utile.\nInoltre, al di l√† della significativit√† pratica, l‚Äôabitudine di molti psicologi di escludere i predittori che non risultano ‚Äústatisticamente significativi‚Äù √® un grossolano errore: la significativit√† statistica non pu√≤ essere usata come un metodo per la selezione di variabili in un modello statistico.\nUn p &lt; 0.05 indica che, se l‚Äôipotesi nulla √® vera, abbiamo osservato dati che dovrebbero essere considerati sorprendenti. Tuttavia, solo perch√© i dati sono sorprendenti, non significa che dobbiamo preoccuparcene. √à principalmente l‚Äôetichetta verbale ‚Äúsignificativo‚Äù che causa confusione qui: in un contesto frequentista, un effetto ‚Äúsignificativo‚Äù √® un effetto ‚Äúsorprendente‚Äù alla luce di \\(H_0\\), non √® necessariamente un effetto ‚Äúimportante‚Äù.\nMalinteso 4: Se avete osservato un risultato significativo, la probabilit√† che abbiate commesso un errore di Tipo 1 (un falso positivo) √® del 5%.\nIl malinteso che la presenza di un risultato significativo (per esempio, p &lt; 0.05) indichi una probabilit√† del 5% di aver commesso un errore di Tipo 1 (falso positivo) riflette una comprensione errata della statistica frequentista. La probabilit√† del 5% si riferisce al tasso di errore di Tipo 1, che √® la proporzione di volte che potremmo aspettarci di rifiutare erroneamente l‚Äôipotesi nulla se questa fosse vera, su molteplici ripetizioni dell‚Äôesperimento sotto le stesse condizioni. In altre parole, se potessimo ripetere lo stesso studio infinite volte, osserveremmo risultati falsamente positivi nel 5% di questi studi, assumendo che l‚Äôipotesi nulla sia effettivamente vera in ogni caso.\nTuttavia, una volta che abbiamo raccolto i dati e ottenuto un risultato significativo in un unico studio, non possiamo dire che ‚Äúla probabilit√† che questo particolare risultato sia un errore di Tipo 1 √® del 5%‚Äù. In realt√†, in quel momento specifico, l‚Äôevento (commettere un errore di Tipo 1) √® gi√† accaduto o non √® accaduto; la probabilit√† associata a quel singolo risultato non √® pi√π applicabile nel modo in cui potremmo aspettarci intuitivamente. Il risultato √®, per cos√¨ dire, una realt√† fissa: o abbiamo rilevato un effetto che in realt√† non esiste (errore di Tipo 1), oppure abbiamo correttamente identificato un effetto reale. Senza ulteriori esperimenti o dati, non possiamo determinare con certezza in quale di queste categorie cade il nostro risultato.\nIn breve, il tasso del 5% di errore di Tipo 1 non si applica retroattivamente a un singolo risultato ottenuto, ma piuttosto descrive il comportamento a lungo termine di un test statistico sotto ripetute campionature. Questa distinzione √® cruciale per una corretta interpretazione dei risultati degli esperimenti e sottolinea l‚Äôimportanza di non sovrastimare la certezza di un singolo risultato statistico significativo.\nMalinteso 5: Uno meno il valore p √® la probabilit√† che l‚Äôeffetto si replichi quando ripetuto.\nIl concetto che 1 meno il valore p rappresenti la probabilit√† di replicazione di un effetto √® un malinteso diffuso. In realt√†, la probabilit√† di replicazione di un effetto non pu√≤ essere direttamente calcolata dal valore p di un singolo studio a causa della complessit√† dei fattori coinvolti, tra cui la vera differenza media tra i gruppi. La potenza statistica di un test, che dipende dalla dimensione dell‚Äôeffetto, dalla dimensione del campione e dal livello di significativit√† Œ±, fornisce una stima della probabilit√† di rilevare un effetto significativo se questo effetto esiste davvero. Tuttavia, osservare un effetto significativo in un unico studio (ad esempio, p = 0.03) non significa che vi sia una probabilit√† del 97% che tale effetto si replichi in studi futuri. La possibilit√† di replicare un risultato dipende dalla presenza di un vero effetto e dalla potenza statistica del test originale.\nIn sintesi, la replicabilit√† di un effetto √® influenzata da molti fattori e non pu√≤ essere inferita semplicemente dal valore p di un singolo risultato. La comprensione e l‚Äôinterpretazione corrette della replicabilit√† richiedono un‚Äôanalisi dettagliata della potenza statistica e della dimensione dell‚Äôeffetto, oltre che della consistenza dei risultati attraverso studi multipli.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>67</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#informazioni-sullambiente-di-sviluppo",
    "title": "67¬† Significativit√† statistica",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: US/Pacific\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.17.0      ggokabeito_0.1.0 see_0.9.0        gridExtra_2.3   \n#&gt;  [5] patchwork_1.3.0  bayesplot_1.11.1 psych_2.4.12     scales_1.3.0    \n#&gt;  [9] markdown_1.13    knitr_1.49       lubridate_1.9.4  forcats_1.0.0   \n#&gt; [13] stringr_1.5.1    dplyr_1.1.4      purrr_1.0.2      readr_2.1.5     \n#&gt; [17] tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0 \n#&gt; [21] rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      shape_1.4.6.1     xfun_0.50         htmlwidgets_1.6.4\n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2      \n#&gt;  [9] generics_0.1.3    parallel_4.4.2    pan_1.9           pacman_0.5.1     \n#&gt; [13] jomo_2.7-6        pkgconfig_2.0.3   Matrix_1.7-1      lifecycle_1.0.4  \n#&gt; [17] compiler_4.4.2    farver_2.1.2      munsell_0.5.1     mnormt_2.1.1     \n#&gt; [21] codetools_0.2-20  htmltools_0.5.8.1 glmnet_4.1-8      nloptr_2.1.1     \n#&gt; [25] pillar_1.10.1     MASS_7.3-64       iterators_1.0.14  rpart_4.1.23     \n#&gt; [29] boot_1.3-31       foreach_1.5.2     mitml_0.4-5       nlme_3.1-166     \n#&gt; [33] tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4     splines_4.4.2    \n#&gt; [37] rprojroot_2.0.4   fastmap_1.2.0     grid_4.4.2        colorspace_2.1-1 \n#&gt; [41] cli_3.6.3         magrittr_2.0.3    survival_3.7-0    broom_1.0.7      \n#&gt; [45] withr_3.0.2       backports_1.5.0   timechange_0.3.0  rmarkdown_2.29   \n#&gt; [49] nnet_7.3-19       lme4_1.1-35.5     hms_1.1.3         evaluate_1.0.1   \n#&gt; [53] rlang_1.1.4       Rcpp_1.0.13-1     glue_1.8.0        minqa_1.2.8      \n#&gt; [57] jsonlite_1.8.9    R6_2.5.1",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>67</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#bibliografia",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#bibliografia",
    "title": "67¬† Significativit√† statistica",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBenjamin, D. J., Berger, J. O., Johannesson, M., Nosek, B. A., Wagenmakers, E.-J., Berk, R., Bollen, K. A., Brembs, B., Brown, L., Camerer, C., et al. (2018). Redefine statistical significance. Nature Human Behaviour, 2(1), 6‚Äì10.\n\n\nDoorn, J. van, Matzke, D., & Wagenmakers, E.-J. (2020). An in-class demonstration of Bayesian inference. Psychology Learning & Teaching, 19(1), 36‚Äì45.\n\n\nEtz, A., Gronau, Q. F., Dablander, F., Edelsbrunner, P. A., & Baribault, B. (2018). How to become a Bayesian in eight easy steps: An annotated reading list. Psychonomic bulletin & review, 25(1), 219‚Äì234.\n\n\nMehr, S. A., Song, L. A., & Spelke, E. S. (2016). For 5-month-old infants, melodies are social. Psychological Science, 27(4), 486‚Äì501.\n\n\nWasserstein, R. L., & Lazar, N. A. (2016). The ASA‚Äôs statement on p-values: context, process, and purpose. The American Statistician, 70(2), 129‚Äì133.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>67</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html",
    "title": "68¬† Test t di Student per campioni indipendenti",
    "section": "",
    "text": "68.1 Introduzione\nIn questo capitolo, esamineremo il test \\(t\\) di Student per campioni indipendenti, uno dei test statistici frequentisti pi√π ampiamente utilizzati nella pratica.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>68</span>¬† <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html#applicazioni-del-test-t-di-student",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html#applicazioni-del-test-t-di-student",
    "title": "68¬† Test t di Student per campioni indipendenti",
    "section": "68.2 Applicazioni del Test t di Student",
    "text": "68.2 Applicazioni del Test t di Student\nIl test t di Student per due campioni indipendenti √® un metodo statistico utilizzato per determinare se le medie di due campioni indipendenti sono significativamente diverse. Questo test si applica quando i due campioni sono estratti da popolazioni diverse e non vi √® alcuna correlazione tra le osservazioni di un campione e quelle dell‚Äôaltro.\nPer condurre il test t di Student per due campioni indipendenti, calcoliamo la differenza tra le medie dei due campioni e le stime delle varianze campionarie delle rispettive popolazioni. L‚Äôipotesi nulla del test √® che le medie dei due campioni siano uguali, mentre l‚Äôipotesi alternativa a due code √® che le medie dei due campioni siano diverse. La statistica del test t viene calcolata come il rapporto tra la differenza delle medie campionarie e la deviazione standard media campionaria.\nSuccessivamente, confrontiamo la statistica t con la distribuzione t di Student con \\(n_1 + n_2 - 2\\) gradi di libert√†, dove \\(n_1\\) e \\(n_2\\) sono le dimensioni dei due campioni. Calcoliamo quindi il valore-p dalla distribuzione t per determinare la significativit√† del test.\nEsistono due approcci per stimare la varianza. Se assumiamo che le due popolazioni abbiano la stessa varianza (omoschedasticit√†), utilizziamo una stima pooled della varianza. Questo metodo √® considerato efficiente quando l‚Äôomoschedasticit√† √® verificata (argomento correction = False in pg.ttest()). Invece, se supponiamo che le due popolazioni abbiano varianze diverse, utilizziamo due stime separate delle varianze per i due campioni, chiamato test di Welch (argomento correction = True in pg.ttest()). Questo approccio √® pi√π robusto quando le varianze dei due gruppi sono significativamente diverse.\nLe principali assunzioni del test t di Student per due campioni indipendenti sono l‚Äôindipendenza dei due campioni e la normalit√† della distribuzione delle popolazioni da cui sono stati estratti i campioni.\nDi seguito √® riportato il calcolo della stima della deviazione standard pooled, utilizzata per standardizzare la differenza tra le medie dei due campioni quando l‚Äôassunzione di omoschedasticit√† √® verificata:\n\\[\ns_p = \\sqrt{\\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2}},\n\\]\ndove \\(s_p\\) √® la deviazione standard pooled, \\(n\\) e \\(m\\) sono le dimensioni dei due campioni, \\(s^2_0\\) e \\(s^2_1\\) sono le varianze campionarie dei due gruppi.\nLa statistica del test t √® quindi calcolata come:\n\\[\nt = \\frac{\\bar{x}_1 - \\bar{x}_2}{s_p \\sqrt{1/n_1 + 1/n_2}},\n\\]\ndove \\(\\bar{x}_1\\) e \\(\\bar{x}_2\\) sono le medie campionarie dei due gruppi.\n\n68.2.1 Dimostrazione\nPer dimostrare come calcolare la varianza della differenza tra due medie campionarie, supponiamo di avere due campioni casuali indipendenti \\(X_1, X_2, \\dots, X_n\\) e \\(Y_1, Y_2, \\dots, Y_m\\) che sono estratti dalla stessa popolazione con media \\(\\mu\\) e varianza \\(\\sigma^2\\). Definiamo \\(\\bar{X}\\) e \\(\\bar{Y}\\) come le medie campionarie di questi due campioni, rispettivamente.\nLe medie campionarie \\(\\bar{X}\\) e \\(\\bar{Y}\\) sono date da:\n\\[\n\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i\n\\] \\[\n\\bar{Y} = \\frac{1}{m} \\sum_{j=1}^m Y_j\n\\]\nLe medie campionarie \\(\\bar{X}\\) e \\(\\bar{Y}\\) sono entrambe stimatori non distorti della media della popolazione \\(\\mu\\). Le loro varianze sono date da:\n\\[\n\\text{Var}(\\bar{X}) = \\frac{\\sigma^2}{n}\n\\]\n\\[\n\\text{Var}(\\bar{Y}) = \\frac{\\sigma^2}{m}\n\\]\nSiamo interessati a calcolare la varianza della differenza \\(\\bar{X} - \\bar{Y}\\). Utilizzando le propriet√† di varianza per combinazioni lineari di variabili aleatorie indipendenti, otteniamo:\n\\[\n\\text{Var}(\\bar{X} - \\bar{Y}) = \\text{Var}(\\bar{X}) + \\text{Var}(\\bar{Y})\n\\]\ndato che i termini incrociati si annullano per l‚Äôindipendenza di \\(\\bar{X}\\) e \\(\\bar{Y}\\). Sostituendo le varianze di \\(\\bar{X}\\) e \\(\\bar{Y}\\) abbiamo:\n\\[\n\\text{Var}(\\bar{X} - \\bar{Y}) = \\frac{\\sigma^2}{n} + \\frac{\\sigma^2}{m}\n\\]\n\\[\n\\text{Var}(\\bar{X} - \\bar{Y}) = \\sigma^2 \\left(\\frac{1}{n} + \\frac{1}{m}\\right)\n\\]\nQuindi, la varianza della differenza tra le due medie campionarie √® una combinazione delle varianze delle singole medie, ponderate in base alle dimensioni dei campioni corrispondenti.\nPer giungere alla formula del test \\(t\\) di Student per due campioni indipendenti dobbiamo considerare l‚Äôincertezza aggiuntiva che deriva dal fatto che non conosciamo \\(\\sigma\\). Il modo migliore di stimare \\(\\sigma\\) √® quello di utilizzare le due deviazioni standard dei campioni (calcolate come stimatori della varianza della popolazione) ponderate per i rispettivi gradi di libert√†, come indicato in precedenza per la deviazione standard pooled:\n\\[\ns_p = \\sqrt{\\frac{(n - 1)s^2_x + (m - 1)s^2_y}{n + m - 2}},\n\\]\ndove \\(s_x\\) e \\(s_y\\) sono le deviazioni standard dei due campioni, e \\(n\\) e \\(m\\) sono le numerosit√† dei due campioni.\n\n\n68.2.2 Un esempio concreto\nEsaminiamo un esempio concreto. Supponiamo di disporre di nove misure del peso per un gruppo di donne e di nove misure di peso per un gruppo di uomini. Ci chiediamo se, nella popolazione, la media del peso dei due gruppi sia diversa.\nCreiamo due array con i dati e li inseriamo in un DataFrame.\n\nwomen_weight &lt;- c(38.9, 61.2, 73.3, 21.8, 63.4, 64.6, 48.4, 48.8, 48.5)\nmen_weight &lt;- c(67.8, 60, 63.4, 76, 89.4, 73.3, 67.3, 61.3, 62.4)\n\nweight &lt;- c(women_weight, men_weight)\nprint(weight)\n#&gt;  [1] 38.9 61.2 73.3 21.8 63.4 64.6 48.4 48.8 48.5 67.8 60.0 63.4 76.0 89.4\n#&gt; [15] 73.3 67.3 61.3 62.4\n\nCreazione di una variabile che specifica l‚Äôappartenenza al gruppo:\n\n# Creazione della variabile is_female\nis_female &lt;- rep(c(1, 0), each = 9)  # 1 = Femmina, 0 = Maschio\nis_female\n#&gt;  [1] 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0\n\n\n\n68.2.3 Creazione del DataFrame\n\n# Creazione del DataFrame\ndf &lt;- data.frame(is_female = is_female, weight = weight)\nprint(df)\n#&gt;    is_female weight\n#&gt; 1          1   38.9\n#&gt; 2          1   61.2\n#&gt; 3          1   73.3\n#&gt; 4          1   21.8\n#&gt; 5          1   63.4\n#&gt; 6          1   64.6\n#&gt; 7          1   48.4\n#&gt; 8          1   48.8\n#&gt; 9          1   48.5\n#&gt; 10         0   67.8\n#&gt; 11         0   60.0\n#&gt; 12         0   63.4\n#&gt; 13         0   76.0\n#&gt; 14         0   89.4\n#&gt; 15         0   73.3\n#&gt; 16         0   67.3\n#&gt; 17         0   61.3\n#&gt; 18         0   62.4\n\nKDE Plot per tutto il campione\n\n# Calcolo della densit√†\ndensity &lt;- density(df$weight)\ndensity_df &lt;- data.frame(x = density$x, y = density$y)\n\n# Plot KDE\nggplot(density_df, aes(x = x, y = y)) +\n  geom_line() +\n  labs(x = \"Weight\", y = \"Density\")\n\n\n\n\n\n\n\n\nEstrazione dei dati per i due gruppi\n\n# Valori di peso per i due gruppi\nweight_f &lt;- df$weight[df$is_female == 1]\nweight_m &lt;- df$weight[df$is_female == 0]\n\nCalcolo della deviazione standard pooled\n\n# Numeratore della deviazione standard pooled\ns_pool_num &lt;- ((length(weight_f) - 1) * var(weight_f)) +\n              ((length(weight_m) - 1) * var(weight_m))\n\n# Denominatore della deviazione standard pooled\ns_pool_denom &lt;- length(weight_f) + length(weight_m) - 2\n\n# Deviazione standard pooled\ns_pool &lt;- sqrt(s_pool_num / s_pool_denom)\ns_pool\n#&gt; [1] 12.9\n\nCalcolo della statistica t:\n\n# Numeratore della statistica t\nt_num &lt;- mean(weight_f) - mean(weight_m)\n\n# Denominatore della statistica t\nt_denom &lt;- s_pool * sqrt(1 / length(weight_f) + 1 / length(weight_m))\n\n# Statistica t\nT &lt;- t_num / t_denom\nT\n#&gt; [1] -2.78\n\nGradi di libert√†:\n\n# Gradi di libert√†\ndf &lt;- length(weight_f) + length(weight_m) - 2\ndf\n#&gt; [1] 16\n\nCalcolo del valore p:\n\n# Valore p\np_value &lt;- 2 * pt(T, df = df, lower.tail = FALSE)\np_value\n#&gt; [1] 1.99\n\nTest t con la funzione t.test in R:\n\n# Test t senza correzione di Welch\nres &lt;- t.test(weight_f, weight_m, var.equal = TRUE)\nprint(res)\n#&gt; \n#&gt;  Two Sample t-test\n#&gt; \n#&gt; data:  weight_f and weight_m\n#&gt; t = -3, df = 16, p-value = 0.01\n#&gt; alternative hypothesis: true difference in means is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  -29.75  -4.03\n#&gt; sample estimates:\n#&gt; mean of x mean of y \n#&gt;      52.1      69.0\n\n# Interpretazione: Possiamo rifiutare l'ipotesi nulla di uguaglianza delle medie.\n\nTest t con la correzione di Welch\n\n# Test t con correzione di Welch\nres_welch &lt;- t.test(weight_f, weight_m, var.equal = FALSE)\nprint(res_welch)\n#&gt; \n#&gt;  Welch Two Sample t-test\n#&gt; \n#&gt; data:  weight_f and weight_m\n#&gt; t = -3, df = 13, p-value = 0.02\n#&gt; alternative hypothesis: true difference in means is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  -30.0  -3.8\n#&gt; sample estimates:\n#&gt; mean of x mean of y \n#&gt;      52.1      69.0\n\n# Con correzione di Welch, il p-value pu√≤ risultare pi√π alto a causa della stima aggiustata dei gradi di libert√†.\n\nIn conclusione, i risultati del test t confermano quanto trovato attraverso i calcoli manuali. Con un livello di confidenza del 95%, possiamo concludere che il peso medio degli uomini √® significativamente superiore al peso medio delle donne nella popolazione analizzata. La correzione di Welch offre una stima pi√π robusta dei gradi di libert√† in caso di varianze disuguali, ma non modifica sostanzialmente la statistica test.\nQuesta traduzione mantiene la logica originale del codice Python, adattandola all‚Äôambiente R e utilizzando librerie native per una migliore leggibilit√† e funzionalit√†.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>68</span>¬† <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html#interpretazione-dei-risultati",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html#interpretazione-dei-risultati",
    "title": "68¬† Test t di Student per campioni indipendenti",
    "section": "68.3 Interpretazione dei Risultati",
    "text": "68.3 Interpretazione dei Risultati\nIl test t di Student per campioni indipendenti ha generato un p-valore di 0.013, inferiore alla soglia di significativit√† di Œ± = 0.05. Questo indica che la differenza osservata tra i gruppi √® statisticamente significativa. Tuttavia, anzich√© limitarci a etichettare il risultato come ‚Äústatisticamente significativo‚Äù, √® importante considerare cosa implica questo esito nel contesto della ricerca.\nIn sostanza, il basso p-valore ci porta a rifiutare l‚Äôipotesi nulla, suggerendo che √® improbabile che le differenze osservate nei dati siano dovute al caso. Questo ci permette di concludere con una certa fiducia che esiste una differenza reale tra le medie delle popolazioni da cui i campioni sono stati estratti. Questa interpretazione apre la strada a ulteriori indagini sulle cause di tale differenza e sulle loro implicazioni teoriche o pratiche.\nSe il p-valore fosse stato superiore alla soglia di significativit√† Œ±, avremmo interpretato il risultato in modo diverso. Un p-valore maggiore di Œ± indica che i dati osservati non sono incompatibili con l‚Äôipotesi nulla. In altre parole, non avremmo avuto motivi statistici sufficienti per rifiutare l‚Äôipotesi nulla. Tuttavia, √® importante sottolineare che questo non equivale a dimostrare che l‚Äôipotesi nulla sia vera; piuttosto, i dati non forniscono evidenza sufficiente per confutarla.\nIn pratica, la non rifiutazione dell‚Äôipotesi nulla significa che i dati sono compatibili sia con l‚Äôipotesi nulla sia con altre possibili ipotesi sulle caratteristiche della popolazione. Di conseguenza, in assenza di evidenza contraria, ci asteniamo dal fare affermazioni conclusive e manteniamo una posizione di neutralit√† riguardo l‚Äôipotesi nulla, rimanendo aperti alla possibilit√† di ulteriori indagini e dati futuri che potrebbero chiarire meglio la questione.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>68</span>¬† <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html#riportare-i-risultati",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html#riportare-i-risultati",
    "title": "68¬† Test t di Student per campioni indipendenti",
    "section": "68.4 Riportare i risultati",
    "text": "68.4 Riportare i risultati\nPer riportare i risultati si pu√≤ usare un testo come quello seguente:\n\nAbbiamo condotto un test \\(t\\) di Student per campioni indipendenti per confrontare le medie dei due gruppi. I risultati indicano una differenza tra le medie dei gruppi (\\(t\\)(16) = 2.78, \\(p\\) = 0.013). L‚Äôintervallo di confidenza al 95% per la differenza delle medie √® tra 4.03 e 29.75. L‚Äôampiezza dell‚Äôeffetto, misurata con Cohen‚Äôs \\(d\\), √® stata di 1.31, indicando un effetto grande secondo le convenzioni comunemente accettate. La potenza statistica del test, calcolata post hoc, √® stata del 74.4%, indicando una buona probabilit√† di rilevare un effetto, se presente.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>68</span>¬† <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html#test-unidirezionali-e-bidirezionali",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html#test-unidirezionali-e-bidirezionali",
    "title": "68¬† Test t di Student per campioni indipendenti",
    "section": "68.5 Test Unidirezionali e Bidirezionali",
    "text": "68.5 Test Unidirezionali e Bidirezionali\nIl criterio secondo il quale un p-valore inferiore a Œ± indica una ‚Äúsignificativit√† statistica‚Äù √® comune sia nei test bidirezionali sia nei test unidirezionali, ma l‚Äôapplicazione differisce a seconda della natura dell‚Äôipotesi testata.\n\n68.5.1 Test Bidirezionale\nNel caso di un test bidirezionale, le ipotesi sono formulate come segue: - Ipotesi nulla (H‚ÇÄ): \\(\\mu_1 = \\mu_2\\) (cio√®, \\(\\mu_1 - \\mu_2 = 0\\)); si assume uguaglianza delle varianze (\\(\\sigma^2_1 = \\sigma^2_2\\)). - Ipotesi alternativa (H‚ÇÅ): \\(\\mu_1 \\neq \\mu_2\\); ancora con uguaglianza delle varianze.\nLa statistica test √® calcolata come $ {Y}_1 - {Y}_2 $, dove \\(\\bar{Y}_1\\) e \\(\\bar{Y}_2\\) sono le medie campionarie dei due gruppi. La regione di rifiuto dell‚Äôipotesi nulla √® equamente divisa tra le due code della distribuzione della statistica test, con Œ±/2 per coda.\n\n\n68.5.2 Test Unidirezionale\nPer i test unidirezionali, la direzione della differenza che si sta testando √® cruciale:\n\nQuando si testa se \\(\\mu_1\\) √® minore di \\(\\mu_2\\):\n\nIpotesi nulla (H‚ÇÄ): \\(\\mu_1 \\geq \\mu_2\\);\nIpotesi alternativa (H‚ÇÅ): \\(\\mu_1 &lt; \\mu_2\\).\n\nLa statistica test √® calcolata come $ {Y}_1 - {Y}_2 $. Se questa differenza √® significativamente negativa (cio√® cade nella coda sinistra oltre il valore critico), supporta H‚ÇÅ.\nQuando si testa se \\(\\mu_1\\) √® maggiore di \\(\\mu_2\\):\n\nIpotesi nulla (H‚ÇÄ): \\(\\mu_1 \\leq \\mu_2\\);\nIpotesi alternativa (H‚ÇÅ): \\(\\mu_1 &gt; \\mu_2\\).\n\nAnche qui, la statistica test √® $ {Y}_1 - {Y}_2 $. Un risultato che supera il valore critico nella coda destra indica supporto per H‚ÇÅ.\n\nIn ogni tipo di test unidirezionale, la regione di rifiuto occupa l‚Äôintero Œ± dell‚Äôarea sotto la curva di densit√†, ma √® posizionata completamente nella coda specificata dall‚Äôipotesi alternativa.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>68</span>¬† <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html#considerazioni-sugli-errori-di-tipo-i-e-tipo-ii",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html#considerazioni-sugli-errori-di-tipo-i-e-tipo-ii",
    "title": "68¬† Test t di Student per campioni indipendenti",
    "section": "68.6 Considerazioni sugli Errori di Tipo I e Tipo II",
    "text": "68.6 Considerazioni sugli Errori di Tipo I e Tipo II\nLa scelta di un livello di significativit√† \\(\\alpha = 0.05\\) implica che, nel contesto di un test d‚Äôipotesi, esiste una probabilit√† del 5% di commettere un errore di Tipo I. Questo tipo di errore si verifica quando l‚Äôipotesi nulla √® vera ma, a causa della variabilit√† casuale nei dati del campione, otteniamo risultati abbastanza estremi da rifiutare erroneamente \\(H_0\\).\nUn errore di Tipo II, invece, si verifica quando l‚Äôipotesi nulla √® falsa, ma i dati del campione non sono sufficientemente estremi da giustificare il suo rifiuto. La probabilit√† di commettere un errore di Tipo II √® spesso influenzata dalla dimensione del campione: campioni pi√π piccoli tendono ad avere una potenza statistica inferiore, aumentando il rischio di non rifiutare \\(H_0\\) quando sarebbe appropriato farlo. La potenza statistica di un test, che rappresenta la probabilit√† di rifiutare correttamente l‚Äôipotesi nulla quando √® falsa, pu√≤ essere stimata, ma questa stima pu√≤ diventare complessa.\nPer i modelli statistici complessi, la stima della potenza pu√≤ essere particolarmente difficile. Non solo i calcoli possono essere intricati, ma non esiste un metodo unico e standardizzato per effettuare tali stime, richiedendo l‚Äôintroduzione di diverse assunzioni.\nLa funzione t.test offre un modo per calcolare la potenza di un test in contesti di test statistici relativamente semplici.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>68</span>¬† <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html#informazioni-sullambiente-di-sviluppo",
    "title": "68¬† Test t di Student per campioni indipendenti",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: US/Pacific\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.17.0      ggokabeito_0.1.0 see_0.9.0        gridExtra_2.3   \n#&gt;  [5] patchwork_1.3.0  bayesplot_1.11.1 psych_2.4.12     scales_1.3.0    \n#&gt;  [9] markdown_1.13    knitr_1.49       lubridate_1.9.4  forcats_1.0.0   \n#&gt; [13] stringr_1.5.1    dplyr_1.1.4      purrr_1.0.2      readr_2.1.5     \n#&gt; [17] tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0 \n#&gt; [21] rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      shape_1.4.6.1     xfun_0.50         htmlwidgets_1.6.4\n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2      \n#&gt;  [9] generics_0.1.3    parallel_4.4.2    pan_1.9           pacman_0.5.1     \n#&gt; [13] jomo_2.7-6        pkgconfig_2.0.3   Matrix_1.7-1      lifecycle_1.0.4  \n#&gt; [17] compiler_4.4.2    farver_2.1.2      munsell_0.5.1     mnormt_2.1.1     \n#&gt; [21] codetools_0.2-20  htmltools_0.5.8.1 glmnet_4.1-8      nloptr_2.1.1     \n#&gt; [25] pillar_1.10.1     MASS_7.3-64       iterators_1.0.14  rpart_4.1.23     \n#&gt; [29] boot_1.3-31       foreach_1.5.2     mitml_0.4-5       nlme_3.1-166     \n#&gt; [33] tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4     labeling_0.4.3   \n#&gt; [37] splines_4.4.2     rprojroot_2.0.4   fastmap_1.2.0     grid_4.4.2       \n#&gt; [41] colorspace_2.1-1  cli_3.6.3         magrittr_2.0.3    survival_3.7-0   \n#&gt; [45] broom_1.0.7       withr_3.0.2       backports_1.5.0   timechange_0.3.0 \n#&gt; [49] rmarkdown_2.29    nnet_7.3-19       lme4_1.1-35.5     hms_1.1.3        \n#&gt; [53] evaluate_1.0.1    rlang_1.1.4       Rcpp_1.0.13-1     glue_1.8.0       \n#&gt; [57] minqa_1.2.8       jsonlite_1.8.9    R6_2.5.1",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>68</span>¬† <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html#bibliografia",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html#bibliografia",
    "title": "68¬† Test t di Student per campioni indipendenti",
    "section": "Bibliografia",
    "text": "Bibliografia",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>68</span>¬† <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/introduction_replication_crisis.html",
    "href": "chapters/replication_crisis/introduction_replication_crisis.html",
    "title": "Introduzione",
    "section": "",
    "text": "Bibliografia\nIn psicologia, nelle scienze sociali e in altre discipline √® in corso una Riforma Metodologica, scaturita da una profonda crisi che ha colpito la scienza contemporanea: la crisi di replicazione dei risultati delle ricerche. Un esempio emblematico √® rappresentato dal sito Retraction Watch, che monitora le ritrattazioni di studi scientifici. Questa crisi mina la credibilit√† della ricerca scientifica e ha spinto a una revisione radicale delle metodologie alla base delle scienze psicologiche e di altre discipline affini (Korbmacher et al., 2023). Le cause della crisi di replicazione sono molteplici: frodi, pratiche di ricerca scorrette e incentivi distorti offerti dal sistema accademico. Una delle cause pi√π rilevanti per un corso sull‚Äôanalisi dei dati psicologici √® l‚Äôuso delle tecniche inferenziali di stampo frequentista, che ha contribuito alla proliferazione di pubblicazioni contenenti falsi positivi.\nUn articolo di Altmejd et al. (2019) identifica alcuni fattori semplici ma altamente predittivi della replicabilit√† degli studi: il campione era di dimensioni adeguate? I ricercatori hanno ottenuto un risultato appena sotto la soglia di significativit√† di p = 0.05? (Spesso un articolo pu√≤ rivendicare un risultato ‚Äúsignificativo‚Äù se questa soglia viene raggiunta, e molti utilizzano vari trucchi statistici per superare tale limite.) Lo studio ha rilevato un effetto sull‚Äôintera popolazione studiata o ha individuato un ‚Äúeffetto di interazione‚Äù (ad esempio, un effetto presente solo in un segmento pi√π piccolo della popolazione), che √® molto meno probabile che si riproduca?\n√à emerso inoltre che prevedere la replicazione di uno studio √® sorprendentemente semplice. Non √® necessario un approfondimento della metodologia statistica n√© un esame rigoroso dei dati, n√© tantomeno una scrupolosa analisi delle teorie pi√π esoteriche per individuare errori sottili: questi articoli presentano problemi evidenti, a livello superficiale. Uno studio pubblicato su Nature ha coinvolto scienziati in una scommessa su quali studi di scienze sociali sarebbero stati replicati. Camerer et al. (2018) ha scoperto che le previsioni degli scienziati in questo mercato delle scommesse erano estremamente accurate nel determinare quali articoli avrebbero avuto successo nella replicazione.\nUlteriori ricerche hanno dimostrato che non √® nemmeno necessario consultare esperti del settore per indovinare quali studi resisteranno a un esame rigoroso. Uno studio di Hoogeveen et al. (2020) ha coinvolto partecipanti senza un background professionale nelle scienze sociali, chiedendo loro di leggere articoli di psicologia e prevedere se questi si sarebbero replicati. ‚ÄúI non-esperti senza una formazione professionale nelle scienze sociali sono in grado di prevedere la replicabilit√† degli studi con una precisione superiore al caso,‚Äù conclude lo studio, ‚Äúbasandosi esclusivamente su semplici descrizioni verbali degli studi.‚Äù\nSebbene i non esperti non siano stati altrettanto precisi nelle loro previsioni rispetto agli scienziati nello studio pubblicato su Nature, il fatto che siano comunque riusciti a individuare molte replicazioni fallite suggerisce che molti di questi studi presentano difetti evidenti, riconoscibili anche da chi non √® un addetto ai lavori.\nLa pubblicazione di un articolo peer-reviewed non rappresenta l‚Äôultimo passo del processo scientifico. Dopo la pubblicazione, altri studi potrebbero citare l‚Äôarticolo originale, diffondendo eventuali errori o fraintendimenti. Uno studio di Yang et al. (2020) mostra che non esiste alcuna correlazione tra la replicabilit√† di uno studio e la sua frequenza di citazione. ‚ÄúGli studi falliti si diffondono nella letteratura scientifica con la stessa rapidit√† degli studi replicabili,‚Äù affermano Yang et al. (2020). Questo solleva una domanda: se gli scienziati sono abbastanza bravi nel prevedere se uno studio si replicher√†, perch√© sono altrettanto inclini a citare studi non replicabili quanto quelli validi?\nQueste considerazioni suggeriscono che la crisi di replicazione non richiede solo una revisione metodologica, ma √® il sintomo di un sistema scientifico che necessita di un ripensamento pi√π ampio. Le riviste scientifiche non sono sufficientemente responsabili per la pubblicazione di articoli discutibili, e il sistema accademico promuove incentivi distorti. In alcuni casi, la cultura accademica sembra addirittura incentivare la produzione di ricerche di bassa qualit√†. La pressione a pubblicare un elevato numero di articoli favorisce chi riesce a farlo rapidamente, spesso ricorrendo a ‚Äúscorciatoie‚Äù. Di conseguenza, si √® creato un sistema in cui gli incentivi continuano a promuovere la cattiva ricerca, nonostante si comprenda sempre meglio cosa costituisca una ricerca di qualit√†.\nIn questa sezione della dispensa, ci concentreremo su uno dei problemi che stanno alla base della crisi della riproducibilit√† dei risultati della ricerca, ovvero i limiti dell‚Äôinferenza frequentista (Baker, 2016). Analizzeremo gli errori di tipo S e di tipo M, concetti introdotti da Gelman & Carlin (2014), che hanno contribuito a migliorare la comprensione dei limiti della statistica frequentista. Inoltre, discuteremo alcuni possibili metodi per affrontare la crisi e le implicazioni che derivano dall‚Äôintegrit√† della ricerca.",
    "crumbs": [
      "Crisi",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/introduction_replication_crisis.html#bibliografia",
    "href": "chapters/replication_crisis/introduction_replication_crisis.html#bibliografia",
    "title": "Introduzione",
    "section": "",
    "text": "Altmejd, A., Dreber, A., Forsell, E., Huber, J., Imai, T., Johannesson, M., Kirchler, M., Nave, G., & Camerer, C. (2019). Predicting the replicability of social science lab experiments. PloS one, 14(12), e0225826.\n\n\nBaker, M. (2016). Reproducibility Crisis. Nature, 533(7604), 452‚Äì454.\n\n\nCamerer, C. F., Dreber, A., Holzmeister, F., Ho, T.-H., Huber, J., Johannesson, M., Kirchler, M., Nave, G., Nosek, B. A., Pfeiffer, T., et al. (2018). Evaluating the replicability of social science experiments in Nature and Science between 2010 and 2015. Nature human behaviour, 2(9), 637‚Äì644.\n\n\nGelman, A., & Carlin, J. (2014). Beyond Power Calculations: Assessing Type S (Sign) and Type M (Magnitude) Errors. Perspectives on Psychological Science, 9(6), 641‚Äì651.\n\n\nHoogeveen, S., Sarafoglou, A., & Wagenmakers, E.-J. (2020). Laypeople can predict which social-science studies will be replicated successfully. Advances in Methods and Practices in Psychological Science, 3(3), 267‚Äì285.\n\n\nKorbmacher, M., Azevedo, F., Pennington, C. R., Hartmann, H., Pownall, M., Schmidt, K., Elsherif, M., Breznau, N., Robertson, O., Kalandadze, T., et al. (2023). The replication crisis has led to positive structural, procedural, and community changes. Communications Psychology, 1(1), 3.\n\n\nYang, Y., Youyou, W., & Uzzi, B. (2020). Estimating the deep replicability of scientific findings using human and artificial intelligence. Proceedings of the National Academy of Sciences, 117(20), 10762‚Äì10768.",
    "crumbs": [
      "Crisi",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html",
    "href": "chapters/replication_crisis/01_crisis.html",
    "title": "69¬† La crisi della replicazione",
    "section": "",
    "text": "69.1 Introduzione\nIl presente capitolo introduce la crisi di replicazione che affligge la ricerca psicologica, analizzandone le cause precipue e ponendo in rilievo il ruolo che l‚Äôapproccio statistico frequentista ha avuto nel concorrere a tale problematica. Il contenuto di questo capitolo costituisce una sintesi rielaborata del testo A student‚Äôs guide to open science: Using the replication crisis to reform psychology (Pennington, 2023).",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>69</span>¬† <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#cosa-dovrebbe-essere-la-scienza",
    "href": "chapters/replication_crisis/01_crisis.html#cosa-dovrebbe-essere-la-scienza",
    "title": "69¬† La crisi della replicazione",
    "section": "69.2 Cosa dovrebbe essere la scienza",
    "text": "69.2 Cosa dovrebbe essere la scienza\nPennington (2023) avvia la sua discussione sulla crisi di replicazione delineando le caratteristiche di uno scenario ‚Äúideale‚Äù cui la prassi scientifica dovrebbe aspirare. Affinch√© la psicologia possa essere considerata una disciplina scientifica a pieno titolo, √® imprescindibile l‚Äôadesione ai principi di replicabilit√† e riproducibilit√†. In altri termini, qualora un effetto sia reale e robusto, qualsiasi ricercatore, a parit√† di procedure e con un‚Äôadeguata dimensione campionaria, dovrebbe essere in grado di rilevarlo. Ulteriori attributi auspicabili della ricerca scientifica sono i seguenti:\n\nCredibile: La scienza dovrebbe essere credibile, non incredibile. Gli scienziati dovrebbero essere disposti a sottoporre le loro affermazioni e scoperte a un esame equo e rigoroso.\n\nAffidabile: I risultati scientifici dovrebbero essere riportati in modo accurato. Il pubblico dovrebbe poterli considerare attendibili e usarli per prendere decisioni informate.\n\nTrasparente: La scienza dovrebbe essere assolutamente chiara. I metodi e i risultati scientifici dovrebbero essere descritti in dettaglio, permettendo repliche indipendenti, valutazioni e l‚Äôaccumulo di conoscenze.\n\nAccessibile: La scienza dovrebbe essere accessibile a tutti. Sia i ricercatori sia il pubblico generale dovrebbero poter accedere, leggere e valutare facilmente i risultati scientifici.\n\nInclusiva: La scienza dovrebbe essere diversificata e inclusiva. Gli scienziati appartenenti a gruppi sottorappresentati dovrebbero avere pari opportunit√† di partecipazione e accesso.\n\nCollaborativa: La scienza dovrebbe massimizzare l‚Äôuso delle risorse disponibili, incoraggiando la cooperazione tra ricercatori piuttosto che la competizione, per produrre lavori di alta qualit√†.\n\nAutocorrettiva: La scienza dovrebbe basarsi su prove accurate nel perseguimento della conoscenza. Gli errori riscontrati negli articoli dovrebbero essere corretti e spiegati, rendendo questa pratica normale nel processo scientifico.\n\nA questo punto, Pennington (2023) propone una riflessione retorica: ‚ÄúImmaginate di chiudere gli occhi e visualizzare uno scienziato stereotipato. Quale immagine vi si presenta? Quali azioni compie? Quali sono i suoi comportamenti?‚Äù.\nL‚Äôautore offre la propria visualizzazione: ‚ÄúIo vedo un uomo bianco, di mezza et√†, all‚Äôinterno di un laboratorio contrassegnato da un grande cartello con la scritta ‚ÄòDIVIETO DI ACCESSO!‚Äô. I suoi risultati rappresentano un tesoro personale, gelosamente custodito, precluso a qualsiasi osservatore esterno. Egli teme che qualcuno possa appropriarsi delle sue brillanti intuizioni, replicare il suo lavoro o tentare di riprodurne i risultati. Si tratta della sua scienza, non di una scienza condivisa.‚Äù\nTale rappresentazione incarna una scienza priva di trasparenza, accessibilit√† e spirito collaborativo.\nNella psicologia contemporanea √® in corso un ampio dibattito su quali cambiamenti siano necessari per superare le criticit√† emerse negli ultimi anni e promuovere una scienza pi√π rigorosa e affidabile. Nonostante la scienza si fondi su principi chiave, come replicabilit√† e riproducibilit√†, la prassi scientifica non √® sempre stata coerente con questi ideali. Questa discrepanza ha portato a ci√≤ che molti definiscono una crisi nella psicologia moderna.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>69</span>¬† <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#la-crisi-della-replicazione-in-psicologia",
    "href": "chapters/replication_crisis/01_crisis.html#la-crisi-della-replicazione-in-psicologia",
    "title": "69¬† La crisi della replicazione",
    "section": "69.3 La Crisi della Replicazione in Psicologia",
    "text": "69.3 La Crisi della Replicazione in Psicologia\nNegli ultimi decenni, la psicologia si √® trovata al centro di una crisi che ha messo in discussione molte delle sue basi epistemologiche e metodologiche: la crisi della replicazione. Questo fenomeno indica l‚Äôincapacit√† di replicare con successo un‚Äôampia parte degli studi pubblicati, con implicazioni rilevanti per la cultura accademica e il modo di concepire la ricerca scientifica (Parsons et al., 2022).\nPer fallimento della replicazione si intende il caso in cui uno studio, ripetuto da altri ricercatori seguendo le stesse procedure e utilizzando campioni simili, non riesce a ottenere risultati comparabili a quelli originali. Questo ha portato alla luce problemi sistemici legati alla metodologia di ricerca, all‚Äôinterpretazione dei dati e alle dinamiche del sistema accademico. La crisi della replicazione ha dunque evidenziato la necessit√† di un cambiamento strutturale nella pratica scientifica, sottolineando l‚Äôurgenza di un approccio pi√π trasparente, rigoroso e collaborativo.\nNelle sezioni seguenti vengono presentati gli eventi chiave di quella che possiamo chiamare la storia della crisi della replicazione.\n\n69.3.1 2005: ‚ÄúPerch√© la maggior parte dei risultati pubblicati √® falsa‚Äù (Ioannidis)\nUn primo momento cruciale √® stato l‚Äôarticolo di ‚ÄúWhy Most Published Research Findings Are False‚Äù (Ioannidis, 2005) che ha evidenziato come molti risultati scientifici fossero in realt√† falsi positivi. Ioannidis attribu√¨ questo fenomeno a campioni di piccole dimensioni, un‚Äôeccessiva enfasi sui valori-p per indicare significativit√†, flessibilit√† nei metodi di analisi e la competizione per produrre risultati ‚Äúinnovativi‚Äù. Questo articolo ha messo in luce problemi che trascendono la psicologia, ma che in seguito sarebbero emersi come centrali anche per questa disciplina.\n\n\n69.3.2 2011: Lo Studio di Daryl Bem, ‚ÄúFeeling the Future‚Äù\nUno degli eventi pi√π controversi √® stato lo studio di Daryl Bem ‚ÄúFeeling the Future‚Äù (Bem, 2011), che suggeriva l‚Äôesistenza della precognizione, ovvero la capacit√† di ‚Äúsentire‚Äù eventi futuri. Attraverso nove esperimenti, Bem pubblic√≤ risultati statisticamente significativi che sembravano sfidare le leggi della causalit√†.\nLo studio di Bem si inseriva nella tradizione degli esperimenti di ‚Äúpriming‚Äù, una tecnica ampiamente utilizzata in psicologia sociale dagli anni ‚Äô70. Gli esperimenti di priming tipicamente coinvolgevano studenti universitari, remunerati con modeste somme o crediti accademici. I partecipanti venivano esposti a determinati concetti per poi osservare come questi influenzassero il loro comportamento successivo. Un celebre esempio √® lo studio di John Bargh del 1996, che dimostr√≤ come l‚Äôesposizione a parole associate all‚Äôet√† avanzata inducesse i soggetti a camminare pi√π lentamente (Bargh et al., 1996). Un altro studio del 2006 rivel√≤ che il priming con concetti legati al denaro rendeva le persone meno propense ad aiutare gli altri. Questi studi sembravano dimostrare una straordinaria malleabilit√† della mente umana, suggerendo che il nostro comportamento potesse essere inconsciamente manipolato da sottili segnali ambientali. Tuttavia, lo studio di Bem introdusse un elemento nuovo in questo paradigma sperimentale.\nTra i vari esperimenti condotti da Bem, uno in particolare si distingueva. I soggetti venivano esposti a una parola con connotazione positiva o negativa e successivamente dovevano valutare rapidamente la piacevolezza di alcune immagini. Fin qui, nulla di insolito. La svolta radicale consisteva nel fatto che in met√† delle prove, il priming avveniva dopo che i soggetti avevano gi√† visto e valutato l‚Äôimmagine (Bem, 2011).\nSorprendentemente, i risultati mostravano che il priming funzionava anche in queste condizioni: i partecipanti erano pi√π veloci a giudicare piacevoli le immagini quando successivamente venivano esposti a una parola positiva. Questo effetto risultava statisticamente significativo, con un p-value di 0.01, sufficiente secondo gli standard correnti per rifiutare l‚Äôipotesi nulla.\nBem interpret√≤ questi risultati come prova della chiaroveggenza, una conclusione che suscit√≤ notevoli controversie e ridicolizz√≤ la psicologia. Gli altri otto esperimenti dello studio, tutti basati su classici paradigmi della psicologia sociale con l‚Äôordine temporale invertito, mostrarono risultati altrettanto statisticamente significativi.\nQuesti risultati ponevano la comunit√† scientifica di fronte a un dilemma: accettare l‚Äôesistenza di fenomeni paranormali o mettere in discussione le pratiche statistiche e metodologiche consolidate nella disciplina. Bem stesso continua a sostenere la validit√† dei suoi risultati come prova dell‚Äôesistenza di capacit√† precognitive.\nSebbene pubblicato su una rivista prestigiosa, lo studio sollev√≤ enormi dubbi metodologici. Le repliche successive non riuscirono a confermare i risultati di Bem, mostrando come pratiche discutibili, quali il p-hacking (modifiche al metodo di analisi per ottenere risultati significativi), potessero produrre falsi positivi apparentemente robusti.\n\n\n69.3.3 2011: Il Caso di Frode di Diederik Stapel\nNello stesso anno, Diederik Stapel, una figura di spicco della psicologia sociale, fu accusato di aver falsificato dati in decine di studi pubblicati. Tra i suoi esperimenti pi√π famosi vi era quello secondo cui ambienti disordinati aumenterebbero il razzismo. Un altro studio suggeriva che mangiare carne rendeva le persone pi√π antisociali. Tuttavia, si scopr√¨ che per quegli studi, e molti altri, non aveva mai condotto gli esperimenti n√© raccolto i dati. Li aveva semplicemente inventati. A volte le frodi accadono. Stapel fu scoperto (alla fine), licenziato e decine dei suoi articoli furono ritirati. Questo scandalo scosse profondamente la comunit√† accademica e divenne un simbolo della crisi.\n\n\n69.3.4 2011: La Meta-ricerca e le Pratiche di Ricerca Discutibili (QRPs)\nLa meta-ricerca √® un campo di studio che si concentra sul modo in cui viene condotta la ricerca scientifica. Comprende temi come i metodi, la trasparenza nella comunicazione, la riproducibilit√†, la valutazione e i sistemi di incentivi che regolano la scienza (Ioannidis et al., 2015). Questo ambito √® emerso con urgenza dopo una serie di casi controversi e di frodi conclamate, come gli studi di Daryl Bem e Diederik Stapel, che hanno evidenziato falle nei processi di ricerca. I ricercatori hanno cos√¨ iniziato ad analizzare pratiche note come Questionable Research Practices (QRPs, Pratiche di Ricerca Discutibili), che sfruttano aree grigie nelle norme scientifiche per raccogliere e analizzare i dati.\nSimmons et al.¬†(2011) hanno dimostrato come la flessibilit√† nella raccolta, analisi e comunicazione dei dati permetta ai ricercatori di far apparire ‚Äúsignificativo‚Äù praticamente qualsiasi risultato. Tra le pratiche discusse, spiccano:\n\nOptional stopping: Interrompere la raccolta dei dati non appena si raggiunge la significativit√† statistica, invece di seguire un piano prestabilito.\n\nP-hacking: Condurre molteplici test non pianificati, selezionando variabili o analisi solo quando producono un valore p inferiore a 0.05.\n\nHARKing (Hypothesizing After Results are Known): Modificare le ipotesi a posteriori per adattarle ai risultati ottenuti, presentandole come ipotesi iniziali.\n\nQueste pratiche non solo compromettono l‚Äôintegrit√† scientifica, ma rendono estremamente facile produrre falsi positivi. Per dimostrarlo, Simmons e colleghi hanno condotto simulazioni al computer e due esperimenti, rivelando quanto fosse ‚Äútroppo facile‚Äù raccogliere prove a sostegno di ipotesi false.\nLa portata di queste pratiche √® sorprendente. Simmons et al.¬†hanno scoperto che:\n\nUsare una sola QRP pu√≤ quasi raddoppiare il tasso di falsi positivi, portandolo dal 5% al 10%.\n\nCombinare pi√π QRPs pu√≤ far salire questa percentuale oltre il 60%.\n\nPer sottolineare il problema, i ricercatori hanno dimostrato, in modo volutamente ironico, che ascoltare la canzone dei Beatles ‚ÄúWhen I‚Äôm Sixty-Four‚Äù potrebbe far apparire le persone pi√π giovani di quanto fossero prima di ascoltarla. Questa dimostrazione satirica evidenziava che inseguire la significativit√† statistica senza un rigore metodologico pu√≤ produrre risultati assurdi.\nJohn et al.¬†(2012) hanno condotto un‚Äôindagine su larga scala, intervistando 2000 ricercatori per comprendere la diffusione delle QRPs. Con un approccio innovativo, hanno chiesto ai partecipanti non solo di riferire le proprie pratiche, ma anche quelle dei colleghi. I risultati sono stati sconvolgenti:\n\nOltre il 60% degli intervistati ha ammesso di non aver riportato tutte le variabili dipendenti misurate.\n\nPi√π del 50% ha interrotto la raccolta dati non appena ottenuti risultati significativi (optional stopping).\n\nPi√π del 40% ha selezionato e riportato solo esperimenti ‚Äúriusciti‚Äù.\n\nSorprendentemente, i ricercatori tendevano a dichiarare che i colleghi adottavano queste pratiche pi√π frequentemente di loro stessi. Molti giustificavano queste pratiche come ‚Äúnorme accademiche‚Äù del tempo.\nLa meta-ricerca ha giocato un ruolo cruciale nell‚Äôaprire gli occhi della comunit√† scientifica sui pericoli di queste decisioni apparentemente ‚Äúbanali‚Äù. In un contesto in cui le QRPs erano ampiamente accettate, la meta-ricerca ha evidenziato come queste pratiche possano seriamente danneggiare il progresso scientifico. Grazie al movimento dell‚ÄôOpen Science, si stanno introducendo norme che migliorano la credibilit√† della ricerca, spostando l‚Äôenfasi dalla produzione di risultati ‚Äúsignificativi‚Äù alla conduzione di studi rigorosi e trasparenti.\n\n\n69.3.5 2012: La Crisi di Fiducia della Psicologia\nSiamo nel 2012, un anno segnato da una serie di eventi che spingono Harold Pashler ed Eric-Jan Wagenmakers a dichiarare che la psicologia sta affrontando una ‚Äúcrisi di fiducia‚Äù. In un numero speciale della rivista Perspectives on Psychological Science (PoPs), i due autori raccolgono una molteplicit√† di prospettive sulla nascente crisi della replicazione, cercando di individuarne le cause e le implicazioni.\nLe reazioni alla crisi sono variegate e, in alcuni casi, contrastanti. Alcuni studiosi sostengono che le affermazioni di una crisi siano premature (Stroebe e Strack, 2014) e che i problemi di replicazione non siano un fenomeno nuovo (Spellman, 2015). Altri, invece, sottolineano come incentivare e valorizzare gli studi di replicazione rappresenti un metodo efficace e diretto per migliorare la qualit√† della scienza psicologica (Koole e Lakens, 2012).\nIl numero speciale evidenzia anche iniziative in corso per affrontare il problema. Tra queste, l‚ÄôOpen Science Collaboration (OSC), un progetto di larga scala avviato nel 2012, si propone di verificare empiricamente se la psicologia sia effettivamente alle prese con una crisi della replicazione. L‚Äôobiettivo del progetto √® ambizioso: replicare numerosi studi pubblicati per valutare la robustezza dei risultati originari. Sebbene i risultati di questa iniziativa non fossero ancora disponibili al momento della pubblicazione del numero speciale, il progetto rappresentava gi√† una pietra miliare per la disciplina.\nNonostante le preoccupazioni, il numero speciale si chiude con una nota positiva, destinata a risuonare nella comunit√† scientifica. I casi di frode, le pratiche di ricerca discutibili (QRPs) e i fallimenti nei tentativi di replicazione, sebbene dannosi, hanno aperto la strada a una riflessione critica. Questo processo ha permesso alla psicologia di affrontare i propri limiti, correggere errori, superare i bias e costruire una letteratura pi√π affidabile e trasparente.\nQuesto periodo storico segna un punto di svolta: la crisi di fiducia ha messo in discussione le fondamenta della disciplina, ma ha anche creato l‚Äôopportunit√† per un rinnovamento scientifico, stimolando pratiche pi√π rigorose e una maggiore attenzione alla replicabilit√† e alla trasparenza.\n\n\n69.3.6 2014: Il Progetto ‚ÄúMany Labs‚Äù\nNel 2014 fu pubblicato il primo tentativo su larga scala di replicare risultati psicologici: il progetto ‚ÄúMany Labs‚Äù. Questo imponente sforzo collaborativo, guidato da Klein et al.¬†(2014), test√≤ la replicabilit√† di 13 risultati classici della psicologia, coinvolgendo 6344 partecipanti in 12 paesi. Gli studi selezionati rispettavano tre criteri principali: erano relativamente brevi, avevano un design semplice e potevano essere facilmente condotti online.\nTra i fenomeni esaminati figurava la fallacia del costo irrecuperabile (sunk cost fallacy), secondo cui le persone tendono a proseguire un‚Äôattivit√† quando vi hanno gi√† investito tempo, sforzi o denaro. Un esempio classico: se hai acquistato un biglietto per vedere la tua squadra di calcio preferita e, il giorno della partita, inizia a piovere a dirotto, sarai pi√π propenso a partecipare perch√© hai gi√† speso i soldi per il biglietto (Oppenheimer e Monin, 2009).\nAltri studi replicati includevano:\n\nL‚Äôinfluenza del framing dei guadagni e delle perdite sul rischio (Tversky e Kahneman, 1981).\n\nLe differenze di genere negli atteggiamenti impliciti verso la matematica e le arti (Nosek et al., 2002).\n\nI risultati sembravano promettenti: il 77% degli studi replic√≤ con successo i risultati originali (10 su 13). Tuttavia, non tutti gli studi fornirono lo stesso livello di evidenza. Ad esempio:\n\nUno studio sull‚Äôefficacia del contatto sociale immaginato nel ridurre i pregiudizi (Husnu e Crisp, 2010) mostr√≤ supporto limitato, con solo 4 campioni su 36 che evidenziarono un effetto significativo.\n\nDue studi di priming non furono replicati. Nel primo, i ricercatori non trovarono che l‚Äôesposizione alla bandiera americana aumentasse il conservatorismo (Carter et al., 2011). Nel secondo, il priming con concetti legati al denaro non port√≤ a un incremento delle credenze o dei comportamenti capitalistici (Caruso et al., 2013).\n\nSebbene i risultati fossero accolti come una vittoria per la replicabilit√†, alcuni ricercatori sottolinearono limiti nel progetto Many Labs 1. Gli stessi autori riconobbero che molti degli studi selezionati erano gi√† noti per essere altamente replicabili. Secondo alcuni critici, il principale contributo di questo progetto era dimostrare che almeno dieci effetti psicologici erano replicabili, ma non forniva una panoramica pi√π ampia sulla replicabilit√† complessiva nella psicologia (Yarkoni, 2013).\nQuesto progetto rappresent√≤ comunque un passo fondamentale per affrontare la crisi della replicazione, sottolineando l‚Äôimportanza della collaborazione scientifica e del rigore metodologico.\n\n\n69.3.7 2015: Il Progetto di Riproducibilit√† della Open Science Collaboration\nNel 2015, la Open Science Collaboration (OSC) pubblic√≤ i risultati del Reproducibility Project: Psychology, dimostrando che la buona scienza richiede tempo e rigore. Superando i limiti del progetto Many Labs 1, un team composto da oltre 270 ricercatori internazionali si impegn√≤ a replicare 100 studi scelti casualmente da riviste di punta nel campo della psicologia.\nPer garantire risultati solidi e inattaccabili, il team adott√≤ una metodologia rigorosa:\n- Consultazione con gli autori originali: gli autori degli studi originali furono coinvolti per confermare il design sperimentale e ridurre al minimo eventuali discrepanze.\n- Aumento delle dimensioni campionarie: i campioni furono ampliati per garantire una potenza statistica sufficiente.\n- Registrazione preventiva dei metodi: i piani di analisi e raccolta dati furono registrati in anticipo per prevenire bias da parte dei ricercatori.\nGli studi selezionati per la replicazione includevano domande di ricerca come:\n- La convinzione che il comportamento umano sia predeterminato incoraggia il tradimento?\n- I bambini seguono automaticamente lo sguardo per trovare oggetti nascosti?\n- √à possibile osservare un ‚Äúeffetto after-motion‚Äù da fotografie fisse che rappresentano movimento?\nI risultati del progetto fecero scalpore e conquistarono i titoli dei giornali a livello globale. Solo il 36% degli studi replic√≤ con successo, ottenendo un valore-p inferiore a 0.05. La psicologia sociale si rivel√≤ particolarmente problematica, con un tasso di replicazione del 25%, rispetto al 50% degli studi di psicologia cognitiva.\nPer contestualizzare questi numeri, se gli effetti originali fossero stati realmente validi, il tasso minimo di replicazione atteso sarebbe stato dell‚Äô89% (Field et al., 2019). Anche tra gli studi replicati, le dimensioni degli effetti risultarono dimezzate rispetto a quelle riportate negli studi originali.\nQuesti risultati provocarono una forte reazione nella comunit√† scientifica. Ci si chiedeva: era la fine della psicologia? La disciplina avrebbe mai recuperato credibilit√†? Sebbene i dati fossero allarmanti, aprirono un dibattito pi√π ampio. Come sottolineato da Kuhn (1962) e Redish et al.¬†(2018), fallimenti nella replicazione possono segnare l‚Äôinizio di una rivoluzione scientifica, stimolando un ripensamento dei metodi, delle ipotesi e delle pratiche di ricerca.\nIl Reproducibility Project: Psychology non solo mise in luce le fragilit√† della disciplina, ma divenne un punto di partenza per migliorare la trasparenza, la collaborazione e la robustezza nella ricerca psicologica.\n\n\n69.3.8 2015: 1500 Scienziati Sollevano il Velo sulla Riproducibilit√†\nI risultati del progetto dell‚ÄôOpen Science Collaboration (2015) colpirono il mondo della psicologia come un fulmine a ciel sereno. Molti risultati psicologici, considerati affidabili, crollarono improvvisamente, generando un‚Äôondata di discussioni nei dipartimenti universitari: quale sarebbe stato il prossimo ‚Äúeffetto‚Äù a fallire? Tuttavia, nonostante la psicologia fosse diventata l‚Äôemblema delle repliche fallite, presto si comprese che non era un problema esclusivo della disciplina.\nNel 2016, Baker condusse un‚Äôindagine su 1500 scienziati provenienti da diverse discipline, tra cui chimica, medicina, fisica e ingegneria, per esplorare le preoccupazioni riguardo alla replicazione e alla riproducibilit√†. I risultati furono sorprendenti: circa il 90% dei partecipanti concord√≤ sull‚Äôesistenza di una crisi di riproducibilit√†, definita come significativa dal 52% e lieve dal 38%.\nUn dato particolarmente allarmante emerse dall‚Äôindagine:\n\nIn media, il 40% degli scienziati aveva riscontrato difficolt√† nel riprodurre i propri esperimenti.\n\nQuesta percentuale saliva a oltre il 60% quando si tentava di riprodurre gli esperimenti di altri ricercatori.\n\nTra le discipline, la chimica risult√≤ la pi√π problematica, con oltre l‚Äô85% dei ricercatori che riportavano fallimenti nel riprodurre i risultati altrui.\nL‚Äôarticolo di Baker riportava anche esperienze personali che riflettevano il senso di smarrimento generato da questa crisi. Il professor Marcus Munaf√≤, per esempio, descrisse cos√¨ il suo percorso:\n\n‚ÄúHo cercato di replicare ci√≤ che dalla letteratura sembrava semplice, ma non ci sono riuscito. Ho avuto una crisi di fiducia, e poi ho scoperto che questa esperienza non era affatto rara.‚Äù (Baker, 2016, p.¬†452)\n\nL‚Äôindagine di Baker non si limit√≤ a evidenziare il problema, ma esplor√≤ anche le possibili cause della crisi, come pratiche metodologiche inadeguate e pressioni accademiche, offrendo al contempo suggerimenti per interventi correttivi.\nL‚Äôindagine segn√≤ un momento cruciale: la crisi della riproducibilit√†, inizialmente confinata a discussioni accademiche, raggiunse una visibilit√† globale. Non era pi√π solo un problema della psicologia, ma un fenomeno che colpiva l‚Äôintero mondo scientifico, portando con s√© la necessit√† di una trasformazione radicale delle pratiche di ricerca.\nQuesto evento contribu√¨ a consolidare il riconoscimento della crisi della riproducibilit√† come una sfida centrale per tutta la scienza, spingendo verso un cambiamento culturale che mettesse al centro trasparenza, rigore e collaborazione.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>69</span>¬† <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#la-cultura-della-frode-nel-sistema-accademico",
    "href": "chapters/replication_crisis/01_crisis.html#la-cultura-della-frode-nel-sistema-accademico",
    "title": "69¬† La crisi della replicazione",
    "section": "69.4 La Cultura della Frode nel Sistema Accademico",
    "text": "69.4 La Cultura della Frode nel Sistema Accademico\nIn alcuni casi, la crisi della replicazione si intreccia con episodi di frode scientifica, rivelando un lato oscuro della ricerca accademica. Uno degli aspetti pi√π preoccupanti √® che il sistema accademico, con i suoi meccanismi di incentivo basati su pubblicazioni frequenti e finanziamenti competitivi, pu√≤ indirettamente favorire comportamenti disonesti. Questo sistema, orientato al publish or perish (pubblica o scompari), crea pressioni che talvolta spingono i ricercatori a compromettere l‚Äôintegrit√† scientifica per raggiungere i propri obiettivi di carriera.\n\n69.4.1 Il Caso Brian Wansink\nUn caso emblematico √® quello di Brian Wansink, ex ricercatore di spicco alla Cornell University, che ricevette cospicui finanziamenti federali durante l‚Äôamministrazione Obama. I suoi studi sul comportamento alimentare, come quello sugli uomini che mangiano di pi√π in presenza di donne o sull‚Äôeffetto dei nomi ‚Äúattraenti‚Äù dati alle verdure sul consumo da parte dei bambini, attirarono grande attenzione mediatica ma si rivelarono in seguito non replicabili. Le conseguenze per Wansink furono severe: diciotto suoi articoli furono ritirati, sette ricevettero ‚Äúespressioni di preoccupazione‚Äù, e quindici furono corretti. Nel 2019, Wansink si dimise dalla Cornell University dopo essere stato giudicato colpevole di cattiva condotta scientifica.\n\n\n69.4.2 Il Caso Sylvain Lesn√©\nUn altro esempio rilevante riguarda Sylvain Lesn√© e i suoi coautori che, nel 2006, pubblicarono su Nature un importante articolo sul morbo di Alzheimer. Questo lavoro era fondamentale per lo sviluppo dell‚Äôipotesi amiloide, un meccanismo proposto per spiegare come la malattia affligge le sue vittime. La ricerca sulla malattia di Alzheimer, che colpisce oltre 50 milioni di persone nel mondo, ha ricevuto oltre un miliardo di dollari in finanziamenti governativi fino al 2022, incoraggiata da studi come quello di Lesn√©.\nNel 2022, il neuroscienziato Matthew Schrag scopr√¨ immagini manipolate in questo e in molti altri articoli di Lesn√©, inclusi quelli che sostenevano l‚Äôipotesi amiloide. Le immagini erano state manualmente modificate e accorpate per mostrare falsamente supporto alle ipotesi degli articoli. Queste frodi passarono inosservate attraverso i processi di peer review formali di Nature e di altre sei riviste accademiche, venendo infine scoperte solo tramite canali non ufficiali.\nLe conseguenze di queste scoperte furono lente e frammentarie. Gli altri coautori dell‚Äôarticolo del 2006 alla fine accettarono di ritirarlo, ma non Lesn√© stesso. La lentezza della risposta a queste evidenze di frode, e il fatto che Lesn√© continui a essere finanziato dal National Institutes of Health e impiegato presso l‚ÄôUniversit√† del Minnesota, dimostra un fallimento sistemico nell‚Äôaffrontare la cattiva condotta scientifica.\n\n\n69.4.3 Altri Casi di Rilievo\nNel mondo accademico, diversi altri recenti scandali hanno messo in luce il problema della frode scientifica e le sue conseguenze spesso limitate per i responsabili. Ecco alcuni casi emblematici:\n\nMarc Tessier-Lavigne, ex presidente della Stanford University: Nel 2023, fu costretto a dimettersi dopo la rivelazione di dati falsificati in sue ricerche precedenti presso Genentech. Nonostante lo scandalo, Tessier-Lavigne ha subito conseguenze minime, diventando successivamente CEO di una nuova azienda di ricerca farmacologica. Lo scandalo fu portato alla luce grazie all‚Äôindagine condotta da Theo Baker, uno studente diciassettenne di Stanford.\nDan Ariely e Francesca Gino: Questi due rinomati psicologi, noti per le loro ricerche sulla disonest√† e il comportamento non etico, sono stati coinvolti in uno scandalo di frode scientifica.\n\nDan Ariely, nel 2021, fu implicato nella fabbricazione di dati in un articolo del 2012 sulla disonest√†.\nFrancesca Gino, docente presso la Harvard Business School, √® stata accusata di aver presentato lavori contenenti risultati falsificati. Il sito del Dipartimento ora riporta che √® in ‚Äúadministrative leave‚Äù.\n\n\nL‚Äôinefficacia delle istituzioni accademiche nel gestire la frode scientifica sembra riflettere un problema culturale di carattere sistemico. Gli incentivi attuali favoriscono la pubblicazione di risultati positivi e innovativi, spesso a scapito dell‚Äôintegrit√† scientifica. Gli studiosi che resistono a queste pressioni rischiano di essere emarginati, mentre chi adotta pratiche discutibili per ottenere risultati desiderati viene premiato con finanziamenti, promozioni e prestigio accademico.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>69</span>¬† <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#cosa-significa-fallimento-della-replicazione",
    "href": "chapters/replication_crisis/01_crisis.html#cosa-significa-fallimento-della-replicazione",
    "title": "69¬† La crisi della replicazione",
    "section": "69.5 Cosa Significa ‚ÄúFallimento della Replicazione‚Äù?",
    "text": "69.5 Cosa Significa ‚ÄúFallimento della Replicazione‚Äù?\nIl fallimento della replicazione non coincide necessariamente con l‚Äôidea che il fenomeno studiato sia inesistente. Al contrario, le cause di un esito negativo in un tentativo di replicazione possono essere molteplici e spesso difficili da individuare con precisione. Comprendere queste ragioni √® fondamentale per identificare le criticit√† metodologiche, migliorare il rigore scientifico e favorire il progresso della conoscenza. Al di l√† dei casi evidenti di frode, i fallimenti della replicazione rappresentano un‚Äôopportunit√† per riflettere sulla qualit√† delle pratiche di ricerca.\n\n69.5.1 Possibili Cause di Fallimento nella Replicazione\n\nFalsi positivi nello studio originale\nUn fallimento pu√≤ indicare che lo studio originale abbia rilevato un effetto inesistente per puro caso. Questo rischio √® particolarmente elevato in studi con campioni di piccole dimensioni e bassa potenza statistica, dove gli effetti riportati risultano spesso sovrastimati o instabili.\nFalsi negativi nella replica\nIl fallimento pu√≤ derivare da un falso negativo, ovvero la mancata rilevazione di un effetto realmente esistente. Le cause principali includono:\n\nDifferenze metodologiche o di popolazione tra studio originale e replica.\n\nConfondenti metodologici o una potenza statistica insufficiente.\n\nPresenza di variabili moderatrici che influenzano l‚Äôintensit√† dell‚Äôeffetto in determinati contesti.\n\n\n\n\n69.5.2 La Scienza tra Incertezza e Riproducibilit√†\nLa scienza raramente offre certezze assolute. Come evidenziato dall‚ÄôOpen Science Collaboration, un singolo studio, sia esso originale o di replica, non √® sufficiente a fornire una risposta definitiva. Solo replicazioni multiple e sistematiche possono distinguere effetti reali da errori casuali, offrendo una visione pi√π affidabile di un fenomeno. Questo approccio richiede tempo e risorse, ma rappresenta il cuore del metodo scientifico.\n\n\n69.5.3 Psicologia e Altri Campi\nSebbene la crisi della replicazione sia stata ampiamente discussa in psicologia, problemi simili affliggono molte altre discipline scientifiche. Studi di replicazione hanno evidenziato risultati preoccupanti: in oncologia, meno della met√† degli studi replicati ha prodotto risultati coerenti, con tassi di riproducibilit√† estremamente bassi in alcuni casi; nelle neuroscienze, i tentativi di replicare correlazioni cervello-comportamento hanno mostrato un altissimo tasso di insuccesso. Anche in discipline come l‚Äôeconomia e la filosofia sperimentale, pur registrando tassi di replicazione relativamente pi√π elevati, permangono dubbi sulla selezione degli studi replicati e sulla rappresentativit√† dei risultati (Pennington, 2023).\nQuesti dati dimostrano che la problematica della replicazione non √® esclusiva della psicologia, ma comune a diverse aree del sapere. Tuttavia, sollevano anche un interrogativo critico: √® corretto parlare di ‚Äúcrisi‚Äù o si tratta piuttosto di una fase di trasformazione necessaria per migliorare il rigore e la trasparenza nella ricerca scientifica?",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>69</span>¬† <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#dibattito-sulla-natura-della-crisi",
    "href": "chapters/replication_crisis/01_crisis.html#dibattito-sulla-natura-della-crisi",
    "title": "69¬† La crisi della replicazione",
    "section": "69.6 Dibattito sulla Natura della Crisi",
    "text": "69.6 Dibattito sulla Natura della Crisi\nIl tema della crisi della replicazione ha suscitato un dibattito acceso e opinioni contrastanti all‚Äôinterno della comunit√† scientifica:\n\nApproccio alle repliche: Alcuni ricercatori ritengono che le repliche esatte siano poco significative, preferendo le repliche concettuali che possano approfondire la comprensione di un fenomeno. Altri, invece, sostengono che solo repliche rigorose ed esatte siano in grado di verificare la robustezza di un effetto, garantendo maggiore affidabilit√†.\nInterpretazione dei dati dell‚ÄôOpen Science Collaboration (OSC): Il tasso di successo delle repliche riportato dall‚ÄôOSC, pari al 36%, ha alimentato ulteriori discussioni. Alcuni attribuiscono questo risultato a differenze metodologiche tra studi originali e tentativi di replica, come campioni diversi o contesti modificati. Tuttavia, ricerche successive hanno smentito queste ipotesi, indicando che tali variazioni non spiegano interamente i bassi tassi di replicazione.\n\nInvece di considerare i fallimenti di replicazione come una crisi, molti studiosi li interpretano come un‚Äôopportunit√† per rafforzare la scienza. La replicazione, infatti, rappresenta un elemento fondamentale del metodo scientifico: permette di identificare i limiti di un fenomeno e di migliorare la comprensione delle condizioni in cui si manifesta. Ogni fallimento diventa, cos√¨, uno stimolo per il progresso.\nQuesta visione ha dato origine a un movimento noto come ‚Äúrivoluzione della credibilit√†‚Äù, che punta a migliorare la qualit√† della ricerca attraverso trasparenza, autocorrezione e valorizzazione delle repliche. Progetti come il Loss of Confidence dimostrano che riconoscere i limiti e le incertezze degli studi precedenti non rappresenta una debolezza, ma un segno di integrit√† scientifica.\nIl passaggio dalla percezione di crisi a una rivoluzione della credibilit√† rappresenta un profondo cambiamento culturale nella comunit√† accademica. La scienza non √® un processo statico, ma un percorso dinamico che evolve grazie al confronto critico e alla riflessione. In questa prospettiva, ogni fallimento nella replicazione non √® un punto d‚Äôarrivo, ma un trampolino di lancio verso una conoscenza pi√π affidabile e trasparente.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>69</span>¬† <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#cause-della-crisi",
    "href": "chapters/replication_crisis/01_crisis.html#cause-della-crisi",
    "title": "69¬† La crisi della replicazione",
    "section": "69.7 Cause della Crisi",
    "text": "69.7 Cause della Crisi\n\n69.7.1 Incentivi Accademici e la Quantit√† che Sovrasta la Qualit√†\nPer comprendere i problemi legati alla ricerca, √® necessario analizzare da vicino il contesto in cui operano i ricercatori. Nonostante l‚Äôimmagine idealizzata degli scienziati come obiettivi e razionali, non dobbiamo dimenticare che sono anche esseri umani, con ambizioni di carriera, responsabilit√† economiche e pressioni lavorative. Le loro performance sono continuamente valutate: oltre a insegnare e gestire incarichi amministrativi, devono pubblicare articoli in riviste di alto livello e ottenere finanziamenti per sostenere i propri gruppi di ricerca. Questo sistema incentiva la quantit√† a scapito della qualit√†, alimentando una mentalit√† di ‚Äúpubblica o perisci‚Äù.\nQuesta pressione genera un paradosso: ci√≤ che √® vantaggioso per la carriera di uno scienziato spesso non coincide con ci√≤ che √® meglio per il progresso scientifico. Le motivazioni intrinseche di fare buona scienza vengono sopraffatte da motivazioni estrinseche legate a metriche di produttivit√†. Non sorprende che oltre il 60% dei ricercatori identifichi questa pressione come la causa principale dei problemi di replicazione e riproducibilit√†.\n\n\n\n69.7.2 Bias Cognitivi e Distorsioni nella Ricerca\nI bias cognitivi rappresentano un ulteriore ostacolo alla qualit√† della ricerca. Tra i principali si trovano:\n\nBias di conferma: la tendenza a cercare o interpretare informazioni che confermano le proprie ipotesi iniziali, trascurando dati contrari.\nApofenia: il riconoscimento di schemi in dati casuali, spesso combinato con una preferenza per risultati positivi.\nBias retrospettivo: la convinzione che un evento fosse prevedibile solo dopo che si √® verificato, portando i ricercatori a presentare risultati in modo fuorviante.\n\nQuesti bias favoriscono la ricerca di risultati positivi a scapito di quelli nulli o contrari, contribuendo a creare un problema pi√π grande: il bias di pubblicazione.\n\n\n\n69.7.3 Bias di Pubblicazione e il Problema dei ‚ÄúFile Drawer‚Äù\nIl sistema di pubblicazione accademica incentiva risultati innovativi e positivi, spesso trascurando studi con risultati nulli o repliche. Questo bias, noto come file drawer problem, descrive la tendenza a relegare nei ‚Äúcassetti‚Äù studi non statisticamente significativi, rendendoli inaccessibili e distorcendo la letteratura scientifica.\nIn psicologia, l‚Äôimpatto di questo fenomeno √® particolarmente grave. Studi hanno rilevato che oltre il 90% degli articoli in psicologia riporta risultati positivi, una percentuale notevolmente pi√π alta rispetto ad altre discipline. Questo non solo crea una rappresentazione distorta della realt√†, ma amplifica il rischio di undead theories, teorie prive di solide basi empiriche che continuano a dominare il dibattito scientifico.\n\n\n\n69.7.4 Pratiche di Ricerca Dubbiamente Etiche\nLa pressione a pubblicare ha portato all‚Äôemergere di comportamenti noti come Questionable Research Practices (QRPs). Tra questi:\n\nP-hacking: manipolazione dei dati o analisi fino a ottenere un p-value significativo (&lt; 0.05).\nHARKing (Hypothesizing After Results are Known): modificare l‚Äôipotesi iniziale per adattarla ai risultati ottenuti.\nStopping opzionale: interrompere la raccolta dei dati quando si raggiunge un p-value desiderato.\n\nQueste pratiche, pur non essendo sempre considerate frodi, distorcono i risultati e compromettono la replicabilit√† degli studi, creando teorie difficili da falsificare.\n\n\n\n69.7.5 La Centralit√† dei Valori-p e la Crisi della Significativit√† Statistica\nIl valore-p, elemento centrale della metodologia scientifica basata sull‚Äôipotesi nulla (Null Hypothesis Significance Testing), √® diventato una ‚Äúvaluta‚Äù per la pubblicazione. Tuttavia, affidarsi esclusivamente ai valori-p presenta gravi limiti:\n\nParadosso di Lindley: con campioni di grandi dimensioni, valori-p vicini a 0.05 possono supportare l‚Äôipotesi nulla invece di confutarla.\nDistorsioni da QRPs: l‚Äôutilizzo di pratiche discutibili pu√≤ produrre falsi positivi statisticamente significativi.\n\nBench√© alcuni studiosi abbiano proposto l‚Äôabbassamento della soglia di significativit√† statistica a 0.005 o l‚Äôintegrazione dei valori-p con stime degli effetti e intervalli di confidenza, il punto centrale continua ad essere il fatto che l‚Äôenfasi dovrebbe spostarsi dai risultati statistici alla qualit√† metodologica degli studi.\nPer affrontare questi problemi, √® necessario un cambiamento culturale e strutturale. La trasparenza, l‚Äôautocorrezione e l‚Äôadozione di pratiche come la preregistrazione degli studi possono aiutare a ridurre l‚Äôimpatto dei bias e delle QRPs. Inoltre, incentivare repliche rigorose e promuovere un sistema di pubblicazione che premi la qualit√† rispetto alla quantit√† sono passi fondamentali per migliorare la credibilit√† della scienza.\n\n\n69.7.6 Campioni Troppo Piccoli\nUno dei fattori chiave che contribuiscono alla crisi della replicazione in psicologia √® l‚Äôuso di campioni di dimensioni ridotte. Questo approccio ha permesso ai ricercatori di massimizzare la quantit√† di pubblicazioni a scapito della qualit√† e dell‚Äôaffidabilit√† degli effetti rilevati. Higginson e Munaf√≤ (2016) sottolineano come questo fenomeno rappresenti una ‚Äúselezione naturale della cattiva scienza‚Äù, dove incentivi strutturali premiano metodologie di ricerca poco rigorose.\nContrariamente a quanto si potrebbe pensare, ottenere un effetto significativo con un campione piccolo non garantisce che lo stesso effetto rimanga significativo con un campione pi√π grande. Questo problema √® strettamente legato alla potenza statistica, che rappresenta la probabilit√†, nel lungo periodo, di rifiutare correttamente l‚Äôipotesi nulla quando l‚Äôipotesi alternativa √® vera. Una potenza statistica bassa comporta un‚Äôelevata probabilit√† di errori di Tipo II (falsi negativi) e, allo stesso tempo, riduce la probabilit√† che un risultato significativo rifletta un effetto reale.\nIn psicologia, la potenza statistica viene solitamente fissata a un minimo dell‚Äô80%, il che significa che, nel lungo termine, uno studio dovrebbe avere l‚Äô80% di possibilit√† di rilevare un effetto reale. Tuttavia, molti studi pi√π datati raramente menzionano la potenza statistica, nonostante il concetto sia noto dagli anni ‚Äô30. Questo ha contribuito a generare una letteratura scientifica con effetti sovrastimati o poco affidabili.\nIn un approccio frequentista, per calcolare la potenza di uno studio, √® necessario conoscere almeno due dei seguenti tre parametri: dimensione dell‚Äôeffetto atteso, criterio di significativit√† e dimensione del campione pianificata. Per esempio, un ricercatore che si aspetta di trovare un effetto ‚Äúmedio‚Äù (Cohen‚Äôs d = 0.50) con un criterio di significativit√† di p &lt; .05 pu√≤ determinare la dimensione del campione necessaria per garantire una potenza sufficiente. Tuttavia, molti studi psicologici hanno ignorato questo tipo di pianificazione, basandosi su campioni troppo piccoli per rilevare effetti affidabili.\nL‚Äôuso di campioni piccoli, combinato con pratiche discutibili di ricerca (Questionable Research Practices, QRPs) e bias di pubblicazione, ha portato a una letteratura scientifica piena di effetti inflazionati. Ad esempio, meta-analisi iniziali sul concetto di esaurimento dell‚Äôego (ego depletion) stimavano un effetto medio (d = 0.62). Tuttavia, repliche successive hanno trovato effetti molto pi√π piccoli, spesso inferiori a d = 0.10. Allo stesso modo, il progetto dell‚ÄôOpen Science Collaboration (2015) ha evidenziato che le dimensioni degli effetti nelle repliche erano, in media, dimezzate rispetto agli studi originali.\nCampioni di piccole dimensioni non solo riducono la probabilit√† di rilevare effetti reali, ma compromettono anche la credibilit√† dei risultati significativi. Una bassa potenza statistica mina l‚Äôobiettivo fondamentale della ricerca scientifica, limitando la capacit√† di trarre conclusioni solide e contribuendo alla crisi della replicazione. Per migliorare la qualit√† della scienza, √® essenziale adottare pratiche di ricerca pi√π rigorose, pianificando adeguatamente la dimensione del campione e garantendo una potenza statistica sufficiente.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>69</span>¬† <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#la-misurazione-un-problema-sottovalutato",
    "href": "chapters/replication_crisis/01_crisis.html#la-misurazione-un-problema-sottovalutato",
    "title": "69¬† La crisi della replicazione",
    "section": "69.8 La Misurazione: Un Problema Sottovalutato",
    "text": "69.8 La Misurazione: Un Problema Sottovalutato\nOltre alle dimensioni campionarie inadeguate, la psicologia potrebbe soffrire di problemi legati alla misurazione. Per rispondere a domande scientifiche, i ricercatori devono definire e misurare con precisione il costrutto oggetto di indagine. Ad esempio, per investigare se una mentalit√† di crescita possa migliorare l‚Äôintelligenza, un ricercatore deve prima definire e poi misurare sia la mentalit√† che l‚Äôintelligenza. Tuttavia, la misurazione √® un processo complesso e impegnativo.\nL‚Äôintelligenza √® un costrutto latente, il che significa che, a differenza dell‚Äôaltezza di una persona, non pu√≤ essere osservata o misurata direttamente. Gli psicologi inferiscono l‚Äôintelligenza stimando il quoziente intellettivo (QI) di un individuo, basandosi sulle risposte a numerose domande di un test di intelligenza, adattate all‚Äôet√† del partecipante. Ma come possiamo sapere se il QI rappresenta un buon indicatore dell‚Äôintelligenza? √à necessario valutare la validit√† di costrutto, definita come la capacit√† di una misura di comportarsi in modo coerente con le ipotesi teoriche (Cronbach e Meehl, 1955; Fink, 2010). Alcuni ricercatori hanno sostenuto che una spiegazione spesso trascurata della crisi della replicazione risieda nella scarsa validit√† di costrutto delle nostre misure (Lilienfeld e Strother, 2020; Loken e Gelman, 2017).\nPer evidenziare il problema della misurazione in psicologia, Flake e colleghi hanno condotto una revisione di articoli pubblicati in una rivista prestigiosa. La loro analisi ha mostrato che molte scale di misurazione utilizzate non avevano una chiara fonte dichiarata, mentre altre erano state sviluppate senza una documentazione adeguata. Inoltre, una parte significativa delle scale citate era stata modificata rispetto alla versione originale, rendendo sconosciute le loro propriet√† psicometriche.\nGli autori hanno anche rilevato l‚Äôuso di Pratiche di Misurazione Discutibili (Questionable Measurement Practices, QMPs), che includono la mancata divulgazione di informazioni sulla validit√† delle misure quando questa non risulta soddisfacente. Questi problemi suggeriscono che molti costrutti psicologici non siano adeguatamente validati, un fattore che potrebbe contribuire alle difficolt√† di replicazione degli studi.\nAltri ricercatori hanno argomentato che problemi di validit√† interna ed esterna possano contribuire alla crisi della replicazione (Fabrigar et al., 2020). La validit√† interna si riferisce a come uno studio stabilisce una relazione di causa-effetto tra le variabili indipendenti e dipendenti (Cook e Campbell, 1979). Fabrigar et al.¬†suggeriscono che un tentativo di replicazione possa fallire se:\n\nLo studio originale ha sofferto di minacce alla validit√† che hanno causato un effetto spurio (alta validit√† interna nella replica).\nI ricercatori introducono elementi assenti nello studio originale (bassa validit√† interna nella replica).\n\nLa validit√† esterna riguarda la possibilit√† di generalizzare i risultati di uno studio ad altri contesti o popolazioni. Questo pu√≤ influenzare le repliche se, ad esempio, la replica viene condotta su una popolazione diversa o se i materiali dello studio sono tradotti da un‚Äôaltra lingua, causando incomprensioni nei partecipanti.\nPer sintetizzare questi problemi, Flake e Fried (2020) li definiscono ‚Äúmeasurement schmeasurement‚Äù, espressione che descrive la mancanza di attenzione verso la validit√† delle misure nella scienza psicologica. Se le misure utilizzate in uno studio non sono valide, ne consegue che anche i risultati e le conclusioni tratte non possono essere considerati affidabili. Quando tali studi vengono replicati, potrebbero essere destinati al fallimento ancor prima di iniziare.\n\n69.8.1 Privilegiare la novit√† a scapito della replicazione\nLa psicologia sperimentale nasce alla fine del XIX secolo con la fondazione del primo laboratorio dedicato alla ricerca psicologica da parte di Wilhelm Wundt nel 1879. Tuttavia, nonostante pi√π di un secolo di progresso scientifico, oggi la psicologia si trova ad affrontare una crisi di replicazione. Una delle ragioni principali risiede nella scarsa attenzione dedicata agli studi di replicazione, che non sono mai stati valorizzati n√© premiati adeguatamente nelle scienze sociali.\nL‚Äôattuale cultura della pubblicazione accademica privilegia risultati nuovi e positivi, rendendo gli studi di replicazione e i risultati nulli una rarit√†. Questa tendenza riflette quello che Antonakis (2017) definisce significosis ‚Äì un‚Äôattenzione sproporzionata verso risultati significativi ‚Äì e neofilia ‚Äì un‚Äôeccessiva enfasi sulla novit√†. Tale dinamica non √® nuova; gi√† Sterling (1959) avvertiva che i ricercatori potevano testare ripetutamente un‚Äôipotesi fino a ottenere, per puro caso, un risultato significativo, pubblicando poi questi risultati senza verificarli attraverso replicazioni. In mancanza di tali verifiche, un intero campo di studio rischia di poggiare su un numero allarmante di affermazioni false.\nQuesto squilibrio non riguarda solo la letteratura scientifica, ma si manifesta anche nei progetti di ricerca degli studenti. Ad esempio, le tesi di laurea in psicologia spesso consistono in progetti empirici condotti in solitudine, senza finanziamenti e con tempistiche ristrette. Tali progetti, per loro natura, soffrono degli stessi problemi riscontrati nella letteratura pi√π ampia: campioni insufficienti, studi sottopotenziati e un‚Äôelevata probabilit√† di falsi positivi. Se questi studi vengono pubblicati selettivamente, si premia la fortuna pi√π che la qualit√† della ricerca. Iniziative come il Collaborative Replications and Education Project (CREP), che incoraggiano gli studenti a condurre studi di replicazione come parte del loro percorso formativo, mirano a contrastare questa tendenza e promuovere una cultura scientifica pi√π solida e collaborativa.\n\n\n\n69.8.2 La scienza non si autocorregge come dovrebbe\nUn principio cardine della scienza √® l‚Äôautocorrezione, ma nella pratica accademica moderna, questo processo sembra spesso ostacolato da incentivi e preoccupazioni reputazionali. I ricercatori, pressati dalle scadenze per nuovi progetti o richieste di finanziamento, raramente dedicano il tempo necessario a rivedere e correggere i propri lavori passati. Questo mancato impegno rappresenta una delle spiegazioni della crisi di replicazione.\nUn esempio significativo √® il Registered Replication Report dello studio di Srull e Wyer (1979), replicato da McCarthy et al.¬†(2018). Lo studio originale aveva mostrato che il priming con stimoli aggressivi portava i partecipanti a interpretare un comportamento ambiguo come pi√π ostile. Tuttavia, il tentativo di replicazione ha rilevato un effetto trascurabile. Una possibile spiegazione √® che alcune statistiche dello studio originale fossero riportate in modo errato, un errore che, nonostante tutto, non √® mai stato corretto. Similmente, altri casi documentano gravi discrepanze nei dati riportati in letteratura, come dimostrato da van der Zee et al.¬†(2017) nel loro riesame di articoli del Cornell Food Lab, che ha rivelato oltre 150 incongruenze.\nLa microbiologa Elizabeth Bik ha inoltre evidenziato che la manipolazione di immagini scientifiche √® diventata una forma emergente di cattiva condotta, volta a rendere i risultati pi√π impressionanti o a mascherare dati problematici. Sebbene alcuni casi di manipolazione portino a ritrazioni o correzioni, il lavoro di revisione √® spesso svolto da altri ricercatori come attivit√† volontaria, suggerendo che la scienza sia pi√π ‚Äúeterocorrettiva‚Äù che autocorrettiva.\nNonostante le difficolt√†, il processo di autocorrezione √® fondamentale per il progresso scientifico. Vazire (2020) sostiene che il disagio provocato dalla revisione critica sia salutare e necessiti di una maggiore umilt√† intellettuale da parte dei ricercatori. Questo include il riconoscimento pubblico delle limitazioni dei propri studi e, quando necessario, la pubblicazione di correzioni o dichiarazioni di perdita di fiducia nei risultati originali.\n\n\n69.8.3 La scienza chiusa come ostacolo alla replicazione\nUn altro importante ostacolo alla replicazione √® la mancanza di trasparenza e dettaglio negli studi precedenti. La scienza chiusa, in cui i dati e i metodi sono trattati come ricette segrete, rende difficile, se non impossibile, ricreare esperimenti e verificare analisi. Questa opacit√† riguarda vari aspetti della ricerca, dai materiali utilizzati ai dati raccolti, fino alle decisioni analitiche prese durante lo studio.\nPer esempio, le decisioni prese durante l‚Äôanalisi dei dati ‚Äì come la gestione dei valori anomali o le correzioni per analisi multiple ‚Äì possono influenzare significativamente i risultati. Se tali decisioni non vengono riportate in modo trasparente, gli altri ricercatori incontreranno grandi difficolt√† nel riprodurre gli stessi risultati. Questo fenomeno √® noto come il giardino dei sentieri che si biforcano (garden of forking paths), dove una moltitudine di scelte non documentate porta a risultati divergenti.\nLa soluzione appare ovvia: rendere i dati e i metodi apertamente disponibili. Tuttavia, la condivisione dei dati √® tutt‚Äôaltro che una pratica comune, nonostante i progressi tecnici che ne facilitano l‚Äôimplementazione. Le ragioni per non condividere i dati possono essere valide, come considerazioni etiche per garantire l‚Äôanonimato dei partecipanti, ma queste dovrebbero sempre essere dichiarate esplicitamente.\nQuesti ostacoli evidenziano come la cultura scientifica debba evolversi verso una maggiore trasparenza e collaborazione, affrontando le limitazioni strutturali che contribuiscono alla crisi di replicazione. Solo cos√¨ la scienza pu√≤ continuare a correggersi e avanzare in modo affidabile.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>69</span>¬† <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#il-progetto-di-riproducibilit√†",
    "href": "chapters/replication_crisis/01_crisis.html#il-progetto-di-riproducibilit√†",
    "title": "69¬† La crisi della replicazione",
    "section": "69.9 Il Progetto di Riproducibilit√†",
    "text": "69.9 Il Progetto di Riproducibilit√†\n\n69.9.1 L‚ÄôIniziativa di Brian Nosek\nNel 2011, Brian Nosek dell‚ÄôUniversit√† della Virginia avvi√≤ il Progetto di Riproducibilit√† (Collaboration, 2015), coinvolgendo 270 ricercatori nel tentativo di replicare cento studi di psicologia. L‚Äôobiettivo era ripetere gli esperimenti originali, utilizzando gli stessi metodi ma con nuovi campioni, per verificare la solidit√† e la replicabilit√† dei risultati precedentemente pubblicati.\nI risultati di questo imponente lavoro, pubblicati nel 2015, furono a dir poco sconvolgenti. Dei cento studi esaminati, ben novantasette avevano inizialmente riportato risultati statisticamente significativi. Tuttavia, il team di Nosek riusc√¨ a replicare questi risultati solo in trentasei casi. Non solo: le dimensioni degli effetti nelle replicazioni risultarono, in media, dimezzate rispetto agli studi originali. Inoltre, pi√π della met√† di queste dimensioni degli effetti cadeva al di fuori degli intervalli di confidenza al 95% riportati nei lavori originali.\n\n\n69.9.2 Studi Successivi\nQuesti risultati sono stati ulteriormente corroborati da numerosi studi successivi, tra cui una ricerca pi√π recente basata su tecniche di machine learning, che ha esaminato studi di psicologia pubblicati in sei importanti riviste nell‚Äôarco di vent‚Äôanni. Questa ricerca suggerisce che poco pi√π della met√† di questi articoli di psicologia non supererebbe i test di replicazione (Youyou et al., 2023). Discipline come la psicologia sociale sono state oggetto di particolare preoccupazione, con un tasso di replicazione del solo 25% riportato dal Progetto di Riproducibilit√† (Collaboration, 2015). Questo dato √® in linea con il lavoro di Youyou et al. (2023), che ha mostrato come la replicabilit√† degli articoli di psicologia vari considerevolmente per sottocampo, con la psicologia sociale che mostra un tasso di replicazione stimato del 37%, un risultato leggermente pi√π incoraggiante rispetto a quanto riportato in precedenza, ma ancora tra i pi√π bassi dei sottocampi esaminati. Altri settori come la psicologia dello sviluppo, cognitiva e clinica hanno mostrato tassi di replicazione stimati rispettivamente del 36%, 42% e 44%, mentre aree come la psicologia delle organizzazioni e della personalit√† hanno mostrato tassi leggermente pi√π incoraggianti (50% e 55%, rispettivamente). Complessivamente, le evidenze suggeriscono che le preoccupazioni diffuse sulla robustezza e replicabilit√† dei risultati della ricerca psicologica siano fondate. Sebbene il problema non sia limitato esclusivamente alla psicologia, le questioni rilevate in questo campo hanno ricevuto notevole attenzione a causa dell‚Äôapparente portata del fenomeno.\nQuesti risultati confermavano in modo drammatico le previsioni formulate anni prima da John Ioannidis e Dennis Lindley. Le loro avvertenze riguardo alla possibilit√† che una larga parte, se non la maggioranza, dei risultati scientifici pubblicati potesse essere falsa, si rivelavano ora profetiche.\nIl Progetto di Riproducibilit√† di Nosek ha segnato un punto di svolta nel dibattito sulla crisi della replicazione in psicologia e, pi√π in generale, nelle scienze sociali e biomediche. Ha evidenziato non solo la fragilit√† di molti risultati ritenuti consolidati, ma anche la necessit√† di un riesame critico delle pratiche di ricerca e pubblicazione scientifica. Questo ripensamento delle metodologie scientifiche √® ancora in atto.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>69</span>¬† <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#cause-profonde-della-crisi-della-replicazione",
    "href": "chapters/replication_crisis/01_crisis.html#cause-profonde-della-crisi-della-replicazione",
    "title": "69¬† La crisi della replicazione",
    "section": "69.10 Cause Profonde della Crisi della Replicazione",
    "text": "69.10 Cause Profonde della Crisi della Replicazione\nLa crisi della replicazione in psicologia e in altre scienze ha radici profonde e non pu√≤ essere attribuita esclusivamente a pratiche di ricerca disoneste. Diverse cause immediate sono state identificate, tra cui:\n\nPressione a pubblicare (‚Äúpublish or perish‚Äù): L‚Äôintensa pressione sui ricercatori a pubblicare prolificamente √® un fattore importante che pu√≤ contribuire a molti dei problemi legati alla crisi della replicazione. La cultura del ‚Äúpublish or perish‚Äù mette i ricercatori sotto stress continuo per produrre risultati significativi e pubblicarli rapidamente (Gopalakrishna et al., 2022; Grimes et al., 2018).\nRicerca della novit√† a ogni costo e incentivi accademici distorti: La ricerca di risultati innovativi e il valore eccessivo attribuito alle scoperte significative incentivano pratiche di ricerca distorte. Questo include la sovrarappresentazione dei risultati positivi e la mancanza di rigore metodologico (Ferguson & Heene, 2012; Ware & Munaf√≤, 2015).\nBassa potenza statistica e scarsit√† di sforzi di replicazione: Molti studi soffrono di bassa potenza statistica, il che rende difficile ottenere risultati affidabili. Inoltre, la mancanza di sforzi di replicazione contribuisce a mantenere e diffondere risultati non replicabili.\nMancanza di trasparenza nella reportistica: La reportistica selettiva e la flessibilit√† non dichiarata nei metodi e nei dati sono pratiche comuni che compromettono l‚Äôintegrit√† scientifica. Inoltre, la riluttanza a condividere dati e materiali e il bias di pubblicazione, per cui i risultati nulli hanno meno probabilit√† di essere pubblicati rispetto a quelli statisticamente significativi, aggravano il problema (Bruton et al., 2020; Nosek et al., 2012).\n\n\n69.10.1 La Probabilit√† Inversa\nOltre a questi fattori, alcuni studiosi sostengono che la radice della crisi della replicazione sia ancora pi√π profonda e risieda nell‚Äôapproccio statistico stesso, ampiamente adottato dalla comunit√† scientifica (Chivers, 2024; Gelman & Loken, 2014; Loken & Gelman, 2017). Questo punto di vista suggerisce che le difficolt√† nella replicazione dei risultati non siano solo il prodotto di comportamenti individuali discutibili, ma derivino in larga parte da un‚Äôinterpretazione e un‚Äôapplicazione problematica dei metodi statistici.\nPer comprendere meglio questa questione, dobbiamo tornare alle basi della statistica inferenziale. L‚Äôapproccio frequentista, dominante nella ricerca scientifica, si basa sulle probabilit√† di campionamento. Questo metodo, che risale a Jakob Bernoulli nel XVIII secolo, calcola la probabilit√† di osservare certi dati assumendo che una determinata ipotesi sia vera. Il famoso ‚Äúp-value‚Äù √® un esempio di questa logica: esso indica la probabilit√† di ottenere risultati estremi quanto o pi√π estremi di quelli osservati, supponendo che l‚Äôipotesi nulla sia vera.\nTuttavia, questo approccio ha un limite fondamentale: non ci dice direttamente quanto √® probabile che la nostra ipotesi sia vera alla luce dei dati raccolti. In altre parole, non fornisce una ‚Äúprobabilit√† inferenziale‚Äù, cio√® la probabilit√† che l‚Äôipotesi sia corretta in base ai risultati ottenuti. Qui entra in gioco l‚Äôapproccio bayesiano. Il teorema di Bayes offre un metodo per calcolare proprio questa probabilit√† inferenziale. L‚Äôapproccio bayesiano tiene conto non solo dei dati osservati, ma anche delle conoscenze pregresse (le ‚Äúprior‚Äù) relative all‚Äôipotesi in esame.\nLa differenza tra questi due approcci √® cruciale. Mentre il p-value ci dice quanto sono improbabili i nostri dati se l‚Äôipotesi nulla √® vera, l‚Äôapproccio bayesiano ci fornisce la probabilit√† che la nostra ipotesi sia vera alla luce dei dati raccolti e delle conoscenze precedenti.\n\n\n69.10.2 Implicazioni per la Pratica Scientifica\nQuesta distinzione ha implicazioni profonde per la pratica scientifica. L‚Äôuso esclusivo dell‚Äôapproccio frequentista pu√≤ portare a sovrastimare la forza delle evidenze a favore di un‚Äôipotesi, specialmente quando si lavora con campioni piccoli o si conducono molti test statistici, come spesso accade in psicologia.\nAlcune soluzioni proposte per affrontare la crisi della replicazione includono:\n\nAbbassare la soglia di significativit√† statistica, rendendo pi√π difficile dichiarare un risultato ‚Äúsignificativo‚Äù.\nRichiedere la preregistrazione delle ipotesi per prevenire l‚ÄôHARKing (Hypothesizing After Results are Known).\nFar s√¨ che le riviste accettino gli articoli basandosi sui metodi piuttosto che sui risultati, per evitare il bias verso la pubblicazione di risultati solo ‚Äúpositivi‚Äù o ‚Äúnuovi‚Äù.\n\nTuttavia, queste soluzioni, pur utili, non affrontano il problema fondamentale dell‚Äôinterpretazione delle evidenze statistiche. L‚Äôadozione di un approccio bayesiano offre una soluzione pi√π radicale, fornendo un quadro pi√π completo e realistico della forza delle evidenze a favore o contro un‚Äôipotesi scientifica.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>69</span>¬† <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#guardare-i-dati",
    "href": "chapters/replication_crisis/01_crisis.html#guardare-i-dati",
    "title": "69¬† La crisi della replicazione",
    "section": "69.11 Guardare i Dati",
    "text": "69.11 Guardare i Dati\nConsideriamo una simulazione, ispirata da Lakens (2015), che illustra come una pratica apparentemente innocua ‚Äì osservare i risultati man mano che vengono raccolti nell‚Äôapproccio frequentista ‚Äì possa avere conseguenze significative sulle conclusioni di uno studio. In particolare, questa pratica pu√≤ influire sulla probabilit√† di ottenere un risultato statisticamente significativo.\nNella simulazione seguente, due campioni casuali vengono estratti dalla stessa popolazione normale di partenza. Di conseguenza, l‚Äô‚Äúipotesi nulla‚Äù √® vera: non c‚Äô√® differenza tra le medie delle popolazioni. Tuttavia, a causa della variabilit√† campionaria, il p-valore risulta fortemente influenzato da ogni singola osservazione aggiunta al campione.\n\nsimulate_t_tests &lt;- function(seed, max_sample_size, mu = 0, sigma = 1) {\n  set.seed(seed)\n\n  # Intervallo di grandezza campionaria\n  sample_sizes &lt;- seq(2, max_sample_size, by = 2)\n  p_values &lt;- numeric(length(sample_sizes))\n\n  # Genera due campioni grandi iniziali da una distribuzione normale\n  full_sample1 &lt;- rnorm(max_sample_size, mean = mu, sd = sigma)\n  full_sample2 &lt;- rnorm(max_sample_size, mean = mu, sd = sigma)\n\n  # Simulazione\n  for (i in seq_along(sample_sizes)) {\n    n &lt;- sample_sizes[i]\n\n    # Estrai sottoinsiemi incrementali dai campioni completi\n    sample1 &lt;- full_sample1[1:n]\n    sample2 &lt;- full_sample2[1:n]\n\n    # Esegui il t-test per il confronto delle medie di due gruppi indipendenti\n    t_test &lt;- t.test(sample1, sample2, var.equal = TRUE)\n    p_values[i] &lt;- t_test$p.value\n  }\n\n  # Crea il grafico del p-valore in funzione della grandezza campionaria\n  plot(\n    sample_sizes, p_values, type = \"l\", col = \"#b97c7c\",\n    xlab = \"Grandezza Campionaria\", ylab = \"P-valore\",\n    main = \"P-valore in funzione della grandezza campionaria\"\n  )\n  abline(h = 0.05, col = \"#8f2727\", lty = 2, lwd = 1.5)\n  legend(\"topright\", legend = \"Significativit√† a 0.05\", col = \"#8f2727\", lty = 2, cex = 0.8)\n}\n\nNelle due simulazioni seguenti, osserviamo come il p-valore cambi progressivamente aumentando la dimensione dei campioni casuali da \\(n = 2\\) a \\(n = 300\\). √à evidente come il p-valore vari drasticamente con l‚Äôaggiunta di nuove osservazioni ai campioni. Inoltre, in alcune configurazioni, il p-valore pu√≤ scendere al di sotto della soglia critica di 0.05 per puro caso. Se un ricercatore interrompesse la raccolta dei dati in quel momento, otterrebbe un risultato ‚Äústatisticamente significativo‚Äù, pur avendo campioni estratti dalla stessa popolazione.\n\nsimulate_t_tests(seed = 1234, max_sample_size = 300, mu = 0, sigma = 2)\nsimulate_t_tests(seed = 2, max_sample_size = 300, mu = 0, sigma = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuesta simulazione mette in evidenza una limitazione fondamentale dell‚Äôapproccio frequentista: ogni test statistico considera esclusivamente i dati del campione corrente, ignorando le conoscenze accumulate in precedenza. Questo rende il processo decisionale estremamente volatile, poich√©, teoricamente, ad ogni nuovo studio si ‚Äúdimentica‚Äù tutta l‚Äôinformazione derivante dagli studi precedenti.\n\n69.11.1 Analisi Bayesiana\nL‚Äôapproccio bayesiano offre una soluzione elegante a questo problema. Nel framework bayesiano, la distribuzione a posteriori (cio√®, la nostra convinzione aggiornata dopo aver osservato i dati) bilancia sempre l‚Äôinformazione a priori (ci√≤ che sapevamo prima dell‚Äôesperimento) con la verosimiglianza (ci√≤ che i dati ci dicono). Questo equilibrio √® particolarmente prezioso quando i dati sono deboli o contengono molto rumore, come nel caso dei dati della simulazione che stiamo discutendo. In tali situazioni, l‚Äôinformazione a priori assume un ruolo pi√π rilevante, impedendo conclusioni affrettate basate su dati poco informativi.\nPer illustrare questa differenza, consideriamo l‚Äôanalisi bayesiana dei dati simulati in precedenza. Se questi dati vengono analizzati con l‚Äôapproccio frequentista, forniscono un risultato ‚Äústatisticamente significativo‚Äù, suggerendo una differenza tra i due gruppi.\nTuttavia, analizzando gli stessi dati con un approccio bayesiano, otteniamo un intervallo di credibilit√† al 95% compreso tra -0.52 e 1.12. Poich√© questo intervallo include lo zero, possiamo affermare, con un livello di certezza soggettiva del 95%, che non c‚Äô√® una differenza sostanziale tra le medie delle due popolazioni da cui sono stati estratti i campioni.\nQuesta discrepanza nei risultati evidenzia un punto cruciale: l‚Äôapproccio bayesiano √® pi√π resistente ai falsi positivi in presenza di dati rumorosi o campioni piccoli. Invece di forzare una decisione binaria (significativo/non significativo) basata su una soglia arbitraria, l‚Äôanalisi bayesiana fornisce una rappresentazione pi√π sfumata e realistica dell‚Äôincertezza associata alle nostre conclusioni.\nInoltre, l‚Äôapproccio bayesiano offre il vantaggio di essere cumulativo: ogni nuovo studio non parte da zero, ma incorpora naturalmente le conoscenze precedenti attraverso la distribuzione a priori.\n\n# Imposta il seme per la riproducibilit√†\nset.seed(12)\n\n# Parametri della distribuzione normale\nmu &lt;- 0\nsigma &lt;- 2\nmax_sample_size &lt;- 50\n\n# Genera due campioni indipendenti\nfull_sample1 &lt;- rnorm(max_sample_size, mean = mu, sd = sigma)\nfull_sample2 &lt;- rnorm(max_sample_size, mean = mu, sd = sigma)\n\n\n# Prepara i dati per Stan\nstan_data &lt;- list(\n  N1 = length(full_sample1),\n  N2 = length(full_sample2),\n  y1 = full_sample1,\n  y2 = full_sample2\n)\n\n# Visualizza i dati preparati\nprint(stan_data)\n#&gt; $N1\n#&gt; [1] 50\n#&gt; \n#&gt; $N2\n#&gt; [1] 50\n#&gt; \n#&gt; $y1\n#&gt;  [1] -2.9611  3.1543 -1.9135 -1.8400 -3.9953 -0.5446 -0.6307 -1.2565 -0.2129\n#&gt; [10]  0.8560 -1.5554 -2.5878 -1.5591  0.0239 -0.3048 -1.4069  2.3778  0.6810\n#&gt; [19]  1.0139 -0.5866  0.4473  4.0144  2.0240 -0.6049 -2.0505 -0.5348 -0.3982\n#&gt; [28]  0.2622  0.2916  0.7241  1.3480  4.1441 -1.0821 -2.1410 -0.7449 -0.9703\n#&gt; [37]  0.5496 -0.9590  1.5962 -2.0089  0.2100 -2.3120  1.1563 -3.1913 -0.6170\n#&gt; [46]  0.8989 -1.9541  0.3800  1.4629 -0.9852\n#&gt; \n#&gt; $y2\n#&gt;  [1] -0.08537 -0.22534  0.91365  4.04067 -2.10178  1.46930  1.07850 -2.62855\n#&gt;  [9] -0.50008  0.62841  0.81309  1.98884  1.71154  0.39426  1.66865  1.69358\n#&gt; [17]  3.90821 -4.29852  1.94224  2.29012 -1.05080  0.50064 -0.85881 -0.36504\n#&gt; [25] -0.20662 -1.26768 -2.54211 -0.76790  1.03351 -0.35594  0.00852 -2.54812\n#&gt; [33] -0.40422  2.32893 -0.04676  1.79431 -0.35345  2.22742 -1.08378 -1.92680\n#&gt; [41]  0.75290 -1.96935  1.79512  0.25853  2.06741 -0.68458  0.90456 -1.38948\n#&gt; [49] -0.47803 -2.01460\n\n\n# Path to the Stan file\nstan_file &lt;- here::here(\"stan\", \"two_means_diff.stan\")\n\n# Create a CmdStanModel object\nmod &lt;- cmdstan_model(stan_file)\nmod$code() # Stampa il codice del modello\n#&gt;  [1] \"data {\"                                                                \n#&gt;  [2] \"  int&lt;lower=0&gt; N1; // Numero di osservazioni nel gruppo 1\"             \n#&gt;  [3] \"  int&lt;lower=0&gt; N2; // Numero di osservazioni nel gruppo 2\"             \n#&gt;  [4] \"  vector[N1] y1; // Dati del gruppo 1\"                                 \n#&gt;  [5] \"  vector[N2] y2; // Dati del gruppo 2\"                                 \n#&gt;  [6] \"}\"                                                                     \n#&gt;  [7] \"parameters {\"                                                          \n#&gt;  [8] \"  real mu1; // Media del gruppo 1\"                                     \n#&gt;  [9] \"  real delta; // Differenza tra le medie\"                              \n#&gt; [10] \"  real&lt;lower=0&gt; sigma; // Deviazione standard comune\"                  \n#&gt; [11] \"  real&lt;lower=0&gt; nu; // Gradi di libert√† per la distribuzione t\"        \n#&gt; [12] \"}\"                                                                     \n#&gt; [13] \"transformed parameters {\"                                              \n#&gt; [14] \"  real mu2; // Media del gruppo 2\"                                     \n#&gt; [15] \"  mu2 = mu1 + delta;\"                                                  \n#&gt; [16] \"}\"                                                                     \n#&gt; [17] \"model {\"                                                               \n#&gt; [18] \"  // Priori\"                                                           \n#&gt; [19] \"  mu1 ~ normal(0, 5);\"                                                 \n#&gt; [20] \"  delta ~ normal(0, 2); // Priore su delta\"                            \n#&gt; [21] \"  sigma ~ cauchy(0, 5);\"                                               \n#&gt; [22] \"  nu ~ gamma(2, 0.1); // Priore sulla t-student\"                       \n#&gt; [23] \"  \"                                                                    \n#&gt; [24] \"  // Verosimiglianza\"                                                  \n#&gt; [25] \"  y1 ~ student_t(nu, mu1, sigma);\"                                     \n#&gt; [26] \"  y2 ~ student_t(nu, mu2, sigma);\"                                     \n#&gt; [27] \"}\"                                                                     \n#&gt; [28] \"generated quantities {\"                                                \n#&gt; [29] \"  real diff; // Differenza tra le medie (alias di delta per chiarezza)\"\n#&gt; [30] \"  diff = delta;\"                                                       \n#&gt; [31] \"}\"\n\nEsegui il campionamento:\n\nfit &lt;- mod$sample(\n  data = stan_data,\n  seed = 123,\n  chains = 4,\n  iter_sampling = 2000,\n  iter_warmup = 1000,\n  show_messages = FALSE\n)\n\nRiassumi i risultati per mu1, mu2 e delta:\n\nfit_summary &lt;- fit$summary(variables = c(\"mu1\", \"mu2\", \"delta\"))\nprint(fit_summary)\n#&gt; # A tibble: 3 √ó 10\n#&gt;   variable   mean median    sd   mad      q5    q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 mu1      -0.313 -0.312 0.241 0.238 -0.707  0.0818  1.00    5378.    5491.\n#&gt; 2 mu2       0.164  0.166 0.246 0.248 -0.235  0.568   1.00    9428.    6234.\n#&gt; 3 delta     0.477  0.474 0.341 0.344 -0.0887 1.04    1.00    5155.    5260.\n\nEstrai i campioni di delta:\n\ndelta_samples &lt;- fit$draws(variables = \"delta\", format = \"matrix\")[, 1]\n\nDisegna la distribuzione a posteriori di delta:\n\ndelta_df &lt;- data.frame(delta = delta_samples)\n\nggplot(delta_df, aes(x = delta)) +\n  geom_histogram(aes(y = ..density..), bins = 30, fill = \"#b97c7c\", alpha = 0.75) +\n  geom_vline(\n    xintercept = mean(delta_samples),\n    linetype = \"dashed\",\n    linewidth = 1.2,\n    label = paste(\"Mean:\", round(mean(delta_samples), 2))\n  ) +\n  labs(\n    x = \"delta\",\n    y = \"Density\",\n    title = \"Posterior distribution of delta\"\n  ) \n#&gt; Warning in geom_vline(xintercept = mean(delta_samples), linetype =\n#&gt; \"dashed\", : Ignoring unknown parameters: `label`\n#&gt; Warning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\n#&gt; ‚Ñπ Please use `after_stat(density)` instead.\n\n\n\n\n\n\n\n\nPuoi calcolare l‚Äôintervallo di credibilit√† usando per un intervallo al 95%:\n\nquantile(delta_samples, probs = c(0.025, 0.975))\n#&gt;   2.5%  97.5% \n#&gt; -0.187  1.155",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>69</span>¬† <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#il-giardino-dei-sentieri-che-si-biforcano",
    "href": "chapters/replication_crisis/01_crisis.html#il-giardino-dei-sentieri-che-si-biforcano",
    "title": "69¬† La crisi della replicazione",
    "section": "69.12 Il Giardino dei Sentieri che si Biforcano",
    "text": "69.12 Il Giardino dei Sentieri che si Biforcano\nLo psicologo Paul Meehl condusse uno studio su un campione di cinquantasettamila studenti delle scuole superiori del Minnesota, indagando su variabili quali religione, abitudini nel tempo libero, ordine di nascita, numero di fratelli, piani post-diploma e numerosi altri aspetti (Meehl, 2012). Complessivamente, le diverse risposte dei partecipanti potevano essere combinate in 990 modi distinti, permettendo analisi del tipo: ‚ÄúGli studenti appassionati di cucina hanno una maggiore probabilit√† di essere figli unici?‚Äù o ‚ÄúGli studenti provenienti da famiglie battiste sono pi√π inclini a partecipare a club politici scolastici?‚Äù. Meehl evidenzi√≤ che, analizzando i dati, il 92% di queste possibili combinazioni risultava in correlazioni statisticamente significative. Queste differenze, sebbene reali, presumibilmente derivano da cause multifattoriali e complesse.\nAndrew Gelman ha denominato questo fenomeno ‚ÄúIl Giardino dei Sentieri che si Biforcano‚Äù [Garden of Forking Paths; Gelman & Loken (2013)], riferendosi ai molteplici gradi di libert√† a disposizione del ricercatore nell‚Äôanalisi dei dati. Come nell‚Äôesempio di Meehl, √® possibile esaminare le differenze intergruppo (se questo √® l‚Äôoggetto di interesse) da molteplici prospettive. Con un campione sufficientemente ampio, alcune di queste differenze risulteranno ‚Äústatisticamente significative‚Äù. Ci√≤ indica che, in quello specifico campione, quel particolare aspetto dei dati √® rilevante. Tuttavia, questa differenza ‚Äústatisticamente significativa‚Äù non sar√† necessariamente generalizzabile ad un altro campione, il quale presenter√† le proprie idiosincrasie.\nIn altri termini, come sottolineato da Gelman, l‚Äôapproccio basato sul test dell‚Äôipotesi nulla si limita a ‚Äúdescrivere il rumore‚Äù. Da un punto di vista teorico, simili esercizi statistici risultano privi di valore euristico e non contribuiscono in nessun modo all‚Äôavanzamento delle conoscenze sul fenomeno oggetto di studio.\nIn un‚Äôottica di inferenza statistica, questo problema √® riconducibile al concetto di ‚Äúp-hacking‚Äù o ‚Äúdata dredging‚Äù, dove l‚Äôesplorazione esaustiva di molteplici ipotesi statistiche su un singolo set di dati pu√≤ portare a falsi positivi e a una sovrastima della significativit√† statistica.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>69</span>¬† <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#garbage-in-garbage-out",
    "href": "chapters/replication_crisis/01_crisis.html#garbage-in-garbage-out",
    "title": "69¬† La crisi della replicazione",
    "section": "69.13 Garbage In, Garbage Out",
    "text": "69.13 Garbage In, Garbage Out\nLa natura della statistica frequentista impone di prendere una decisione dicotomica: o si rifiuta l‚Äôipotesi nulla o non la si rifiuta. Ci√≤ implica che o esiste un effetto reale, oppure non esiste. Con un campione abbastanza grande, √® inevitabile trovare qualche effetto, anche se di minima entit√†.\nUn approccio bayesiano, invece, permette di stimare la dimensione dell‚Äôeffetto e di fornire una distribuzione di probabilit√†. Una distribuzione di probabilit√† √® una rappresentazione grafica delle diverse possibilit√† che potrebbero verificarsi. In questo contesto, si tratta della ‚Äúprobabilit√† inversa‚Äù, ovvero della plausibilit√† dell‚Äôipotesi alla luce dei dati osservati e delle conoscenze pregresse. Qui, il parametro \\(\\delta\\) rappresenta la differenza tra le due medie ed √® il parametro di interesse. Le credenze precedenti su \\(\\delta\\) sono espresse tramite una distribuzione a priori: in questo caso, una distribuzione Normale centrata su 0 con una deviazione standard di 2. La distribuzione a posteriori rappresenta la nostra conoscenza aggiornata su \\(\\delta\\) dopo l‚Äôaggiornamento bayesiano. Il parametro \\(\\delta\\) √® la nostra ipotesi sulla differenza tra le due medie, e l‚Äôinferenza bayesiana riguarda il cambiamento della nostra credenza dopo aver osservato i dati.\nL‚Äôapproccio frequentista, al contrario, produce una decisione dicotomica che non modifica la nostra concezione dell‚Äôipotesi dopo aver osservato i dati. Assume una determinata ipotesi come vera e verifica se i dati sono coerenti con essa. Tramite il concetto binario di ‚Äúsignificativit√† statistica‚Äù, non si modificano le ipotesi di interesse, ma si accettano o si rifiutano le ipotesi nulle.\nSebbene l‚Äôapproccio frequentista sia spesso considerato ‚Äúingenuo‚Äù da molti ricercatori, adottare l‚Äôapproccio bayesiano non rappresenta una soluzione miracolosa ai problemi della scienza contemporanea. Risolve alcuni problemi, ma non altri. In particolare, non affronta la questione degli incentivi accademici che favoriscono la pubblicazione di un elevato numero di articoli, indipendentemente dalla loro qualit√†. Un principio fondamentale della ricerca √® ‚ÄúGarbage in, garbage out‚Äù. Se i dati derivano da un disegno di ricerca fallace o poco creativo, se la ricerca non ha un solido fondamento teorico capace di avanzare le nostre conoscenze, o se la qualit√† delle misurazioni √® insufficiente, i dati raccolti sono puro rumore. Nessun metodo statistico, nemmeno quello bayesiano, pu√≤ trasformare la spazzatura in oro.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>69</span>¬† <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#esercizi",
    "href": "chapters/replication_crisis/01_crisis.html#esercizi",
    "title": "69¬† La crisi della replicazione",
    "section": "69.14 Esercizi",
    "text": "69.14 Esercizi\n\nEsercizio 69.1 Esistono numerosi esempi di ricerche che non riescono a essere replicate (posso citare anche uno studio di replicazione che ho condotto io stesso: Caudek et al. (2017)). Un recente caso emblematico √® rappresentato dallo studio di Karata≈ü & Cutright (2023) e dal successivo tentativo di replicazione condotto da Moore et al. (2024). Analizzando le quattro principali argomentazioni sollevate da Gelman & Brown (2024) per criticare lo studio di Aungle & Langer (2023), si offra un‚Äôinterpretazione del perch√© lo studio di Karata≈ü & Cutright (2023) non sia stato replicato con successo.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>69</span>¬† <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/replication_crisis/01_crisis.html#informazioni-sullambiente-di-sviluppo",
    "title": "69¬† La crisi della replicazione",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: US/Pacific\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] posterior_1.6.0.9000 cmdstanr_0.8.1       ggokabeito_0.1.0    \n#&gt;  [4] see_0.9.0            gridExtra_2.3        patchwork_1.3.0     \n#&gt;  [7] bayesplot_1.11.1     psych_2.4.12         scales_1.3.0        \n#&gt; [10] markdown_1.13        knitr_1.49           lubridate_1.9.4     \n#&gt; [13] forcats_1.0.0        stringr_1.5.1        dplyr_1.1.4         \n#&gt; [16] purrr_1.0.2          readr_2.1.5          tidyr_1.3.1         \n#&gt; [19] tibble_3.2.1         ggplot2_3.5.1        tidyverse_2.0.0     \n#&gt; [22] rio_1.2.3            here_1.0.1          \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6         tensorA_0.36.2.1     xfun_0.50           \n#&gt;  [4] htmlwidgets_1.6.4    processx_3.8.5       lattice_0.22-6      \n#&gt;  [7] tzdb_0.4.0           vctrs_0.6.5          tools_4.4.2         \n#&gt; [10] ps_1.8.1             generics_0.1.3       parallel_4.4.2      \n#&gt; [13] pacman_0.5.1         pkgconfig_2.0.3      data.table_1.16.4   \n#&gt; [16] checkmate_2.3.2      distributional_0.5.0 lifecycle_1.0.4     \n#&gt; [19] compiler_4.4.2       farver_2.1.2         munsell_0.5.1       \n#&gt; [22] mnormt_2.1.1         htmltools_0.5.8.1    yaml_2.3.10         \n#&gt; [25] pillar_1.10.1        abind_1.4-8          nlme_3.1-166        \n#&gt; [28] tidyselect_1.2.1     digest_0.6.37        stringi_1.8.4       \n#&gt; [31] labeling_0.4.3       rprojroot_2.0.4      fastmap_1.2.0       \n#&gt; [34] grid_4.4.2           colorspace_2.1-1     cli_3.6.3           \n#&gt; [37] magrittr_2.0.3       utf8_1.2.4           withr_3.0.2         \n#&gt; [40] backports_1.5.0      timechange_0.3.0     rmarkdown_2.29      \n#&gt; [43] matrixStats_1.5.0    hms_1.1.3            evaluate_1.0.1      \n#&gt; [46] rlang_1.1.4          glue_1.8.0           jsonlite_1.8.9      \n#&gt; [49] R6_2.5.1",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>69</span>¬† <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#bibliografia",
    "href": "chapters/replication_crisis/01_crisis.html#bibliografia",
    "title": "69¬† La crisi della replicazione",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAungle, P., & Langer, E. (2023). Physical healing as a function of perceived time. Scientific Reports, 13(1), 22432.\n\n\nBargh, J. A., Chen, M., & Burrows, L. (1996). Automaticity of social behavior: Direct effects of trait construct and stereotype activation on action. Journal of Personality and Social Psychology, 71(2), 230‚Äì244.\n\n\nBem, D. J. (2011). Feeling the future: experimental evidence for anomalous retroactive influences on cognition and affect. Journal of Personality and Social Psychology, 100(3), 407‚Äì425.\n\n\nBruton, S. V., Medlin, M., Brown, M., & Sacco, D. F. (2020). Personal motivations and systemic incentives: Scientists on questionable research practices. Science and Engineering Ethics, 26(3), 1531‚Äì1547.\n\n\nCaudek, C., Lorenzino, M., & Liperoti, R. (2017). Delta plots do not reveal response inhibition in lying. Consciousness and Cognition, 55, 232‚Äì244.\n\n\nChivers, T. (2024). Everything is Predictable: How Bayesian Statistics Explain Our World. Simon; Schuster.\n\n\nCollaboration, O. S. (2015). Estimating the reproducibility of psychological science. Science, 349(6251), aac4716.\n\n\nFerguson, C. J., & Heene, M. (2012). A vast graveyard of undead theories: Publication bias and psychological science‚Äôs aversion to the null. Perspectives on Psychological Science, 7(6), 555‚Äì561.\n\n\nGelman, A., & Brown, N. J. (2024). How statistical challenges and misreadings of the literature combine to produce unreplicable science: An example from psychology.\n\n\nGelman, A., & Loken, E. (2013). The garden of forking paths: Why multiple comparisons can be a problem, even when there is no ¬´fishing expedition¬ª or ¬´p-hacking¬ª and the research hypothesis was posited ahead of time. Department of Statistics, Columbia University, 348(1-17), 3.\n\n\nGelman, A., & Loken, E. (2014). The statistical crisis in science. American scientist, 102(6), 460‚Äì465.\n\n\nGopalakrishna, G., Ter Riet, G., Vink, G., Stoop, I., Wicherts, J. M., & Bouter, L. M. (2022). Prevalence of questionable research practices, research misconduct and their potential explanatory factors: A survey among academic researchers in The Netherlands. PloS one, 17(2), e0263023.\n\n\nGrimes, D. R., Bauch, C. T., & Ioannidis, J. P. (2018). Modelling science trustworthiness under publish or perish pressure. Royal Society open science, 5(1), 171511.\n\n\nIoannidis, J. P. (2005). Why most published research findings are false. PLoS medicine, 2(8), e124.\n\n\nKarata≈ü, M., & Cutright, K. M. (2023). Thinking about God increases acceptance of artificial intelligence in decision-making. Proceedings of the National Academy of Sciences, 120(33), e2218961120.\n\n\nLakens, D. (2015). On the challenges of drawing conclusions from p-values just below 0.05. PeerJ, 3, e1142.\n\n\nLoken, E., & Gelman, A. (2017). Measurement Error and the Replication Crisis. Science, 355(6325), 584‚Äì585.\n\n\nMeehl, P. E. (2012). Why summaries of research on psychological theories are often uninterpretable. In Improving inquiry in social science (pp. 13‚Äì59). Routledge.\n\n\nMoore, D. A., Schroeder, J., Bailey, E. R., Gershon, R., Moore, J. E., & Simmons, J. P. (2024). Does thinking about God increase acceptance of artificial intelligence in decision-making? Proceedings of the National Academy of Sciences, 121(31), e2402315121.\n\n\nNosek, B. A., Spies, J. R., & Motyl, M. (2012). Scientific utopia: II. Restructuring incentives and practices to promote truth over publishability. Perspectives on Psychological Science, 7(6), 615‚Äì631.\n\n\nPennington, C. (2023). A student‚Äôs guide to open science: Using the replication crisis to reform psychology. McGraw-Hill Education (UK).\n\n\nWare, J. J., & Munaf√≤, M. R. (2015). Significance chasing in research practice: causes, consequences and possible solutions. Addiction, 110(1), 4‚Äì8.\n\n\nYouyou, W., Yang, Y., & Uzzi, B. (2023). A discipline-wide investigation of the replicability of Psychology papers over the past two decades. Proceedings of the National Academy of Sciences, 120(6), e2208863120.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>69</span>¬† <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html",
    "title": "70¬† Limiti dell‚Äôinferenza frequentista",
    "section": "",
    "text": "Introduzione\nPrerequisiti\nConcetti e Competenze Chiave\nIn questa sezione della dispensa abbiamo esaminato il metodo ‚Äútradizionale‚Äù per il test di significativit√† dell‚Äôipotesi nulla (NHST). Comprendere la logica alla base dell‚Äôapproccio NHST √® essenziale poich√© questo √® stato l‚Äôapproccio predominante alla statistica inferenziale fin dalla sua introduzione all‚Äôinizio del XX secolo e la maggior parte dei ricercatori ancora si affida a questa procedura per analizzare i dati. Tuttavia, recentemente, l‚Äôapproccio NHST √® stato oggetto di aspre critiche, poich√© molti ricercatori hanno iniziato a pensare che questo approccio possa creare pi√π problemi di quanti ne risolva. Pertanto, √® importante conoscere le critiche mosse alla procedura inferenziale NHST all‚Äôinterno della comunit√† scientifica. In questa sezione esamineremo alcuni dei dubbi sorti riguardo a questo approccio.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>70</span>¬† <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#luso-del-valore-p-nel-mondo-della-ricerca",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#luso-del-valore-p-nel-mondo-della-ricerca",
    "title": "70¬† Limiti dell‚Äôinferenza frequentista",
    "section": "70.1 L‚Äôuso del valore-\\(p\\) nel mondo della ricerca",
    "text": "70.1 L‚Äôuso del valore-\\(p\\) nel mondo della ricerca\nNel suo articolo ‚ÄúStatistical Errors‚Äù (2014), Nuzzo evidenzia i limiti dell‚Äôapproccio NHST nella pratica scientifica Nuzzo (2014). Infatti, sebbene il valore-\\(p\\) sia stato introdotto da Ronald Fisher negli anni ‚Äô20, egli non lo ha mai concepito come un test formale. Invece, Fisher lo considerava uno strumento informale per valutare se l‚Äôevidenza empirica fosse significativa in un senso colloquiale, ovvero meritevole di attenzione. In pratica, Fisher suggeriva di assumere un‚Äôipotesi nulla e di calcolare la probabilit√† di osservare un risultato altrettanto estremo o pi√π estremo di quello trovato, se il risultato fosse completamente dovuto alla sola variabilit√† campionaria. Sebbene sia possibile calcolare il valore-\\(p\\) tramite una procedura matematica, per Fisher esso era solo uno strumento da utilizzare all‚Äôinterno di un processo decisionale non numerico, in grado di combinare le evidenze empiriche attuali con le conoscenze pregresse del ricercatore. In altre parole, il valore-\\(p\\) rappresentava uno strumento da utilizzare all‚Äôinterno del processo decisionale, non la conclusione del processo decisionale stesso.\nVerso la fine degli anni ‚Äô20, Jerzy Neyman e Egon Pearson, rivali di Fisher, formalizzarono le procedure di decisione statistica con l‚Äôobiettivo di renderle ‚Äúrigorose e oggettive‚Äù. In particolare, introdussero i concetti di potere statistico e di falso positivo, ma non utilizzarono la nozione di valore-\\(p\\) come aveva fatto Fisher.\nLe divergenze tra i tre autori portarono a un acceso dibattito, in cui Neyman critic√≤ il lavoro di Fisher come matematicamente ‚Äúpeggiore dell‚Äôinutilit√†‚Äù, mentre Fisher defin√¨ l‚Äôapproccio di Neyman ‚Äúinfantile‚Äù e ‚Äúorribile per la libert√† intellettuale dell‚Äôoccidente‚Äù.\nDurante questo dibattito, altri autori iniziarono a scrivere manuali di statistica per fornire uno strumento di lavoro ai ricercatori. Poich√© molti di questi autori non erano statistici e avevano solo una comprensione superficiale della distinzione tra i vari approcci, crearono un sistema ibrido che utilizzava il valore-\\(p\\) proposto da Fisher all‚Äôinterno del ‚Äúsistema rigoroso‚Äù proposto da Neyman e Pearson. √à in questo contesto che la soglia di un valore-\\(p\\) pari a 0.05 venne definita come ‚Äústatisticamente significativa‚Äù.\nTuttavia, dal punto di vista storico, il valore-\\(p\\) proposto da Fisher aveva un significato molto diverso da quello che viene attribuito oggi nel mondo della ricerca. Come abbiamo visto, il valore-\\(p\\) era solo uno strumento informale utilizzato da Fisher all‚Äôinterno di un processo decisionale pi√π ampio, e il suo uso all‚Äôinterno del sistema ibrido creato dai manuali di statistica era privo di giustificazione e fondamento.\nNel 2016 l‚ÄôAmerican Statistical Association ha pubblicato un articolo nel quale si esprime una grande preoccupazione per l‚Äôuso inappropriato che viene fatto del valore-\\(p\\) nella pratica scientifica odierna Wasserstein & Lazar (2016):\n\n\\(P\\)-values do not measure the probability that the studied hypothesis is true, or the probability that the data were produced by random chance alone. Researchers often wish to turn a \\(p\\)-value into a statement about the truth of a null hypothesis, or about the probability that random chance produced the observed data. The \\(p\\)-value is neither. It is a statement about data in relation to a specified hypothetical explanation, and is not a statement about the explanation itself.\n\nL‚Äôarticolo prosegue affermando che:\n\nScientific conclusions and business or policy decisions should not be based only on whether a \\(p\\)-value passes a specific threshold. Practices that reduce data analysis or scientific inference to mechanical ‚Äúbright-line‚Äù rules (such as ‚Äú\\(p &lt; 0.05\\)‚Äù) for justifying scientific claims or conclusions can lead to erroneous beliefs and poor decision making. A conclusion does not immediately become ‚Äòtrue‚Äô on one side of the divide and ‚Äòfalse‚Äô on the other. Researchers should bring many contextual factors into play to derive scientific inferences, including the design of a study, the quality of the measurements, the external evidence for the phenomenon under study, and the validity of assumptions that underlie the data analysis. Pragmatic considerations often require binary, ‚Äòyes-no‚Äô decisions, but this does not mean that \\(p\\)-values alone can ensure that a decision is correct or incorrect. The widespread use of ‚Äústatistical significance‚Äù (generally interpreted as ) as a license for making a claim of a scientific finding (or implied truth) leads to considerable distortion of the scientific process.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>70</span>¬† <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#p-hacking",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#p-hacking",
    "title": "70¬† Limiti dell‚Äôinferenza frequentista",
    "section": "70.2 \\(P\\)-hacking",
    "text": "70.2 \\(P\\)-hacking\nLa pratica del \\(P\\)-hacking rappresenta la principale fallacia associata all‚Äôutilizzo del valore-\\(p\\) ed √® nota anche come ‚Äú\\(P\\)-hacking‚Äù, ‚Äúdata-dredging‚Äù, ‚Äúsnooping‚Äù, ‚Äúfishing‚Äù, ‚Äúsignificance-chasing‚Äù o ‚Äúdouble-dipping‚Äù. Secondo Uri Simonsohn, docente presso l‚ÄôUniversit√† della Pennsylvania, il \\(P\\)-hacking consiste nel tentativo di provare diverse ipotesi finch√© non si ottiene il risultato desiderato. Ad esempio, si potrebbe dire: ‚ÄúQuel risultato sembra essere stato ottenuto attraverso il \\(p\\)-hacking, gli autori hanno eliminato una delle condizioni in modo che il valore-\\(p\\) complessivo fosse inferiore a 0.05‚Äù oppure ‚ÄúLei √® una \\(p\\)-hacker, controlla sempre i dati mentre vengono raccolti‚Äù.\nQuesta pratica ha l‚Äôeffetto di trasformare uno studio esplorativo, che dovrebbe essere sempre interpretato con cautela, in uno studio (apparentemente) confermativo, il cui risultato appare ‚Äúrobusto‚Äù, ma che in realt√† ha una probabilit√† pressoch√© nulla di essere replicato in studi successivi. Secondo le simulazioni di Simonsohn, il cambiamento di poche decisioni nel processo di analisi dei dati pu√≤ aumentare fino al 60% il tasso di falsi positivi in un singolo studio.\nIl \\(P\\)-hacking √® diffuso soprattutto negli studi che tentano di dimostrare piccoli effetti usando dati molto rumorosi. Un‚Äôanalisi della letteratura psicologica ha mostrato che i valori-\\(p\\) riportati dagli psicologi tendono a concentrarsi su valori appena superiori alla soglia minima dello 0.05. Questo risultato pu√≤ essere interpretato come conseguenza della pratica del \\(P\\)-hacking: i ricercatori eseguono molteplici test statistici fino a trovare uno che risulta ‚Äústatisticamente significativo‚Äù e poi riportano solo quello. Come mostra la figura seguente, questa pratica non riguarda solo la psicologia, ma √® diffusa in tutti i campi della ricerca scientifica.\n\n\n\nDistribuzione dei valori-\\(p\\) nelle pubblicazioni scientifiche di economia, psicologia e biologia.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>70</span>¬† <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#critiche-al-valore-p",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#critiche-al-valore-p",
    "title": "70¬† Limiti dell‚Äôinferenza frequentista",
    "section": "70.3 Critiche al valore-\\(p\\)",
    "text": "70.3 Critiche al valore-\\(p\\)\nIl valore-\\(p\\) √® stato paragonato a creature noiose e ostinate come le zanzare, ai vestiti nuovi dell‚Äôimperatore, ovvero alla tendenza di non voler riconoscere evidenti problemi, ma preferire di far finta di nulla, o ad un intellectual rake sterile, che non porta alcun frutto. Si √® anche ironizzato sul fatto che la procedura di statistical hypothesis inference testing venga chiamata cos√¨ solo per l‚Äôacronimo che produce.\nIl valore-\\(p\\) incoraggia un modo di pensare errato, spostando l‚Äôattenzione dal problema centrale della ricerca, ovvero la forza della manipolazione sperimentale, alla dimostrazione di una falsa ipotesi che si sa a priori essere falsa (l‚Äôipotesi nulla). Ad esempio, uno studio con pi√π di 19.000 individui ha dimostrato che coloro che incontrano il loro partner online hanno una probabilit√† minore di divorziare (\\(p &lt;\\) 0,002) e sono pi√π soddisfatti della loro vita matrimoniale (\\(p &lt;\\) 0,001) rispetto a chi non si √® conosciuto online. Questo pu√≤ sembrare un risultato interessante, ma senza considerare la dimensione dell‚Äôeffetto, ovvero il tasso di divorzio che scende dal 7.67% al 5.96% e l‚Äôaumento dell‚Äôindice di soddisfazione matrimoniale da 5.48 a 5.64 su una scala a sette punti, il risultato perde di interesse. In generale, la domanda cruciale non √® ‚Äúc‚Äô√® un effetto o no?‚Äù ma piuttosto ‚Äúqual √® la dimensione dell‚Äôeffetto?‚Äù.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>70</span>¬† <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#leffetto-sperimentale-√®-esattamente-nullo",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#leffetto-sperimentale-√®-esattamente-nullo",
    "title": "70¬† Limiti dell‚Äôinferenza frequentista",
    "section": "70.4 L‚Äôeffetto sperimentale √® esattamente nullo?",
    "text": "70.4 L‚Äôeffetto sperimentale √® esattamente nullo?\nUna delle critiche pi√π frequenti alla logica di verifica delle ipotesi statistiche riguarda l‚Äôassunzione irrealistica che l‚Äôeffetto della manipolazione sperimentale sia ‚Äúesattamente‚Äù nullo. Ad esempio, la fisica ci insegna che lo spostamento di un grammo di massa in una stella distante qualche anno luce dalla Terra pu√≤ influenzare il movimento delle molecole di un gas sulla Terra Borel (1914). Questo ci suggerisce che ogni manipolazione sperimentale produca, in qualche modo, un effetto. Pertanto, secondo Andrew Gelman, il problema non √® dimostrare falsa l‚Äôipotesi nulla, ovvero che la manipolazione sperimentale non produca alcun effetto, ma piuttosto valutare se la dimensione dell‚Äôeffetto √® sufficientemente grande da avere un impatto pratico e se l‚Äôeffetto sia riproducibile. In questo senso, la logica di verifica dell‚Äôipotesi nulla pu√≤ essere problematica, soprattutto quando si lavora con piccoli campioni e piccoli effetti, come nella maggior parte degli studi in psicologia, poich√© pu√≤ portare ad una sovrastima della dimensione dell‚Äôeffetto e ad una visione binaria del risultato (vero/falso), invece di concentrarsi sulla stima non distorta della dimensione effettiva dell‚Äôeffetto.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>70</span>¬† <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#attenti-al-valore-p",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#attenti-al-valore-p",
    "title": "70¬† Limiti dell‚Äôinferenza frequentista",
    "section": "70.5 Attenti al valore-\\(p\\)!",
    "text": "70.5 Attenti al valore-\\(p\\)!\nConsideriamo il seguente problema. Eseguiamo un \\(t\\)-test per due campioni indipendenti e sottoponiamo a verifica l‚Äôipotesi nulla dell‚Äôeguaglianza delle due medie. Sia \\(\\alpha = 0.05\\). Otteniamo un valore-\\(p\\) di \\(0.04\\). Qual √® la probabilit√† che i due campioni siano tratti da distribuzioni con la stessa media?\n\n\\(19/20; \\quad\\) (b) \\(1/19; \\quad\\) (c) \\(1/20; \\quad\\) (d) \\(95/100; \\quad\\) (e) sconosciuta.\n\nLa risposta corretta √®: (e) sconosciuta. La statistica frequentista definisce le probabilit√† dei dati condizionatamente alle ipotesi (assunte come vere). Non consente di stabilire la probabilit√† di un‚Äôipotesi.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>70</span>¬† <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#la-crisi-della-riprodicibilit√†-dei-risultati-della-ricerca",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#la-crisi-della-riprodicibilit√†-dei-risultati-della-ricerca",
    "title": "70¬† Limiti dell‚Äôinferenza frequentista",
    "section": "70.6 La crisi della riprodicibilit√† dei risultati della ricerca",
    "text": "70.6 La crisi della riprodicibilit√† dei risultati della ricerca\nNegli ultimi anni, la mancanza di replicabilit√† dei risultati della ricerca - inclusa la ricerca psicologica - √® diventata un tema di grande rilevanza. In questo contesto, √® stato evidenziato che alcuni aspetti del metodo scientifico, in particolare il concetto di valore-p e la pratica di verificare la significativit√† dell‚Äôipotesi nulla (NHST, Null Hypothesis Significance Testing), potrebbero contribuire a questa ‚Äúcrisi della ricerca scientifica‚Äù. Un‚Äôanalisi pi√π approfondita di questo problema √® stata fornita da Gelman (2016), il quale sostiene che la pratica della NHST sia intrinsecamente problematica. Infatti, essa incoraggia il ricercatore a cercare di rigettare un‚Äôipotesi ‚Äúfantoccio‚Äù (straw-man) che √® certamente falsa a priori o, almeno, poco interessante dal punto di vista scientifico, a favore di un‚Äôipotesi alternativa che il ricercatore preferisce. In generale, sembra pi√π ragionevole affermare che la differenza tra due condizioni sia molto piccola, piuttosto che affermare che sia esattamente uguale a zero.\nSpesso nei libri di statistica viene trasmesso il messaggio che la NHST sia una forma di ‚Äúalchimia‚Äù che cerca di trasformare la casualit√† in una sorta di certezza, con l‚Äôuso di termini come ‚Äúconfidenza‚Äù e ‚Äúsignificativit√†‚Äù Gelman (2016). Il processo di raccolta dei dati, analisi e inferenza statistica che ne segue viene poi riassunto in una conclusione espressa in termini di valore-p e di intervallo di confidenza che escludono lo zero. Tuttavia, ci√≤ pu√≤ dare l‚Äôimpressione errata che il ricercatore abbia una comprensione completa delle propriet√† del fenomeno in questione. Il problema principale della NHST √® che spesso produce risultati ‚Äústatisticamente significativi‚Äù in situazioni in cui le caratteristiche del fenomeno non giustificano la conclusione a cui il ricercatore arriva. Questo pu√≤ portare alla non replicabilit√† dei risultati della ricerca.\nLa comunit√† degli statistici ha evidenziato come la non replicabilit√† dei risultati delle ricerche sia particolarmente evidente quando i ricercatori, utilizzando la metodologia NHST, giungono a conclusioni errate basate sull‚Äôosservazione di piccoli campioni con effetti di dimensioni ridotte. Queste condizioni, insieme ad altre, rendono estremamente problematica l‚Äôapplicazione della NHST. Purtroppo, queste situazioni descrivono molte delle ricerche recenti in psicologia.\nLa statistica √® stata definita come un metodo per prendere decisioni razionali in situazioni di incertezza. Gli statistici consigliano ai ricercatori di non solo diventare esperti nelle tecniche statistiche, ma anche di imparare a convivere con l‚Äôincertezza, nonostante la sempre crescente sofisticazione delle tecniche disponibili. Convivere con l‚Äôincertezza implica evitare di pensare che ottenere un valore-\\(p\\) ‚Äústatisticamente significativo‚Äù significhi risolvere un problema scientifico. Come possiamo allora avere fiducia in ci√≤ che abbiamo appreso dai dati? Una possibile strategia √® la replicazione e la convalida esterna, ma nella ricerca in psicologia e nelle scienze sociali, questo pu√≤ spesso essere difficile da perseguire a causa degli oneri elevati che comporta. Il problema di quali strumenti metodologici e metodi statistici siano pi√π appropriati per indagare sui fenomeni psicologici, senza essere ingannati, rimane dunque un problema aperto.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>70</span>¬† <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#commenti-e-considerazioni-finali",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#commenti-e-considerazioni-finali",
    "title": "70¬† Limiti dell‚Äôinferenza frequentista",
    "section": "70.7 Commenti e considerazioni finali",
    "text": "70.7 Commenti e considerazioni finali\nNon possiamo concludere senza sottolineare la controversia che circonda la nozione di valore-\\(p\\). Pur essendo ancora ampiamente utilizzato e spesso interpretato erroneamente, il valore-\\(p\\) conferisce solo una patina di legittimit√† ai risultati di studi dubbi, incoraggia cattive pratiche di ricerca e promuove la produzione di falsi positivi. Inoltre, √® difficile comprendere appieno il significato di questa nozione. Anche gli esperti, quando chiamati a fornire una definizione di valore-\\(p\\), spesso sbagliano la risposta. Ci√≤ che i ricercatori vogliono sapere √® se i risultati della ricerca sono corretti o meno, ma il valore-\\(p\\) non fornisce questa informazione. Non dice nulla sulla dimensione dell‚Äôeffetto, sulla forza dell‚Äôevidenza o sulla probabilit√† che il risultato sia stato ottenuto casualmente. Quindi, qual √® il suo significato? Stuart Buck risponde cos√¨:\n\nImagine that you have a coin that you suspect is weighted toward heads. (Your null hypothesis is then that the coin is fair.) You flip it 100 times and get more heads than tails. The \\(p\\)-value won‚Äôt tell you whether the coin is fair, but it will tell you the probability that you‚Äôd get at least as many heads as you did if the coin was fair. That‚Äôs it ‚Äì nothing more.\n\nIn sintesi, possiamo concludere che il valore-\\(p\\) risponde a una domanda molto specifica che non ha alcuna rilevanza per la validit√† scientifica dei risultati della ricerca. In un‚Äôepoca in cui la crisi della riproducibilit√† dei risultati √® sempre pi√π evidente Baker (2016), il test dell‚Äôipotesi nulla e gli intervalli di confidenza frequentisti sono stati identificati come una delle principali cause del problema, spingendo molti ricercatori a cercare soluzioni alternative.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>70</span>¬† <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#bibliografia",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#bibliografia",
    "title": "70¬† Limiti dell‚Äôinferenza frequentista",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBaker, M. (2016). Reproducibility Crisis. Nature, 533(7604), 452‚Äì454.\n\n\nBorel, E. (1914). Introduction G√©om√©trique. G. Villars, New York.\n\n\nGelman, A. (2016). Commentary on ¬´Crisis in Science? Or Crisis in Statistics! Mixed Messages in Statistics with Impact on Science¬ª. Journal of Statistical Research, 48-50(1), 11‚Äì12.\n\n\nGoligher, E. C., Heath, A., & Harhay, M. O. (2024). Bayesian statistics for clinical research. The Lancet, 404(10457), 1067‚Äì1076. https://doi.org/10.1016/S0140-6736(24)00055-9\n\n\nNuzzo, R. (2014). Statistical Errors. Nature, 506(7487), 150‚Äì152.\n\n\nWasserstein, R. L., & Lazar, N. A. (2016). The ASA‚Äôs statement on p-values: context, process, and purpose. The American Statistician, 70(2), 129‚Äì133.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>70</span>¬† <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html",
    "href": "chapters/replication_crisis/03_effect_size.html",
    "title": "71¬† La grandezza dell‚Äôeffetto",
    "section": "",
    "text": "71.1 Introduzione\nLa dimensione dell‚Äôeffetto (effect size) √® un concetto fondamentale nella metodologia della ricerca, utilizzato per quantificare la forza della relazione statistica tra due variabili. Questa misura rappresenta l‚Äôentit√† dell‚Äôeffetto di un intervento o di un trattamento in modo standardizzato, descrivendo in termini quantitativi l‚Äôimportanza di un fenomeno osservato.\n√à cruciale distinguere tra la dimensione dell‚Äôeffetto e la significativit√† statistica. Un risultato pu√≤ essere ‚Äústatisticamente significativo‚Äù pur avendo un effetto di piccole dimensioni, e viceversa. La conoscenza di uno di questi concetti non fornisce automaticamente informazioni sull‚Äôaltro, evidenziando la necessit√† di considerare entrambi gli aspetti nell‚Äôanalisi dei dati.\nL‚Äôimportanza della dimensione dell‚Äôeffetto √® ampiamente riconosciuta nel campo della ricerca scientifica. Il manuale dell‚ÄôAmerican Psychological Association (APA) del 2010 ne sottolinea la rilevanza, raccomandando di riportare questa misura negli studi pubblicati. Di conseguenza, la maggior parte degli articoli nelle riviste associate all‚ÄôAPA include la dimensione dell‚Äôeffetto, generalmente indicata tra parentesi accanto al valore di p.\nNonostante la sua importanza e la prassi di riportarla, la psicologia scientifica spesso mostra una carenza nella corretta valutazione e interpretazione delle dimensioni dell‚Äôeffetto. Molti ricercatori si limitano a comunicare questi valori senza esaminarli approfonditamente, portando a conclusioni che possono risultare superficiali, poco informative, fuorvianti o addirittura errate. Questa tendenza rivela una sottovalutazione sistematica e una diffusa incomprensione delle dimensioni dell‚Äôeffetto, anche tra i professionisti della ricerca.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>71</span>¬† <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html#misurazione-delleffetto-approcci-e-applicazioni",
    "href": "chapters/replication_crisis/03_effect_size.html#misurazione-delleffetto-approcci-e-applicazioni",
    "title": "71¬† La grandezza dell‚Äôeffetto",
    "section": "71.2 Misurazione dell‚ÄôEffetto: Approcci e Applicazioni",
    "text": "71.2 Misurazione dell‚ÄôEffetto: Approcci e Applicazioni\nTra le metriche pi√π adottate per quantificare la dimensione dell‚Äôeffetto si annoverano il \\(d\\) di Cohen e l‚Äô\\(r\\) di Pearson. Il \\(d\\) di Cohen √® prevalentemente impiegato per descrivere le differenze tra le medie di gruppi sperimentali, quantificando questa differenza in termini di una deviazione standard aggregata.\nLa differenza standardizzata delle medie tra due gruppi pu√≤ essere calcolata con la seguente formula (equazione 5.1, Glass et al., 1981),\n\\[\nd_p = \\frac{M_1 - M_2}{S_p}.\n\\]\nUn valore positivo di \\(d_p\\) indica che la media del gruppo 1 √® maggiore della media del gruppo 2. Dividere la differenza delle medie per la deviazione standard combinata, \\(S_p\\), √® la formulazione classica del \\(d\\) di Cohen. La deviazione standard combinata, \\(S_p\\), pu√≤ essere calcolata come la radice quadrata della varianza media (ponderata per i gradi di libert√†, \\(df = n-1\\)) del gruppo 1 e del gruppo 2 (pp.¬†108, Glass et al., 1981):\n\\[\nS_p = \\sqrt{\\frac{(n_1 - 1) S_1^2 + (n_2 - 1) S_2^2}{n_1 + n_2 - 2}}.\n\\]\nSi noti che il termine varianza si riferisce al quadrato della deviazione standard (\\(S^2\\)). Il \\(d_p\\) di Cohen √® correlato alla statistica t di un test t per campioni indipendenti. Infatti, possiamo calcolare il valore di \\(d_p\\) a partire dalla statistica \\(t\\) con la seguente formula (equazione 5.3, Glass et al., 1981):\n\\[\nd = t \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}.\n\\]\nL‚Äôerrore standard corrispondente di \\(d_p\\) √®,\n\\[\nSE_{d_p} = \\sqrt{\\frac{n_1 + n_2}{n_1 n_2} + \\frac{d_p^2}{2(n_1 + n_2)}}.\n\\]\nLa statistica \\(r\\) di Pearson, d‚Äôaltro canto, viene utilizzato per esprimere il grado di previsione di una variabile attraverso un‚Äôaltra, fornendo una misura della correlazione. √à interessante notare come queste due misure possano essere convertite l‚Äôuna nell‚Äôaltra attraverso la relazione:\n\\[\nd = \\frac{2r}{\\sqrt{1-r^2}}.\n\\]",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>71</span>¬† <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html#interpretare-la-dimensione-delleffetto",
    "href": "chapters/replication_crisis/03_effect_size.html#interpretare-la-dimensione-delleffetto",
    "title": "71¬† La grandezza dell‚Äôeffetto",
    "section": "71.3 Interpretare la Dimensione dell‚ÄôEffetto",
    "text": "71.3 Interpretare la Dimensione dell‚ÄôEffetto\nL‚Äôinterpretazione delle dimensioni dell‚Äôeffetto solitamente avviene in due modi comuni: uno √® privo di significato e l‚Äôaltro √® seriamente fuorviante.\n\nGli Standard di Cohen. Funder (2019) affermano che l‚Äôinterpretazione pi√π ampiamente utilizzata ma priva di senso delle dimensioni dell‚Äôeffetto richiama gli standard stabiliti da Jacob Cohen (1977, 1988). Cohen ha fissato i valori di r di .10, .30 e .50 come soglie per effetti piccoli, medi e grandi, rispettivamente. Tuttavia, Cohen stesso ha dichiarato che queste soglie dovrebbero essere utilizzate solo in assenza di una base migliore e in seguito ha espresso rammarico per averle proposte.\nI termini ‚Äúpiccolo‚Äù, ‚Äúmedio‚Äù e ‚Äúgrande‚Äù sono privi di significato senza un contesto di riferimento. √à necessario rispondere a due domande fondamentali: (a) piccolo, medio o grande rispetto a cosa? e (b) piccolo, medio o grande a quale scopo?\nElevare al Quadrato la Correlazione. Secondo Funder & Ozer (2019), un altro metodo comune per valutare la dimensione dell‚Äôeffetto √® ancora pi√π problematico: elevare al quadrato il valore di r. Ad esempio, un r di .30 elevato al quadrato produce .09, interpretato come ‚Äúproporzione di varianza spiegata‚Äù. Questa conversione spesso viene riportata con la parola ‚Äúsolo‚Äù, come in ‚Äúla correlazione di .30 ha spiegato solo il 9% della varianza‚Äù.\nNon esiste una giustificazione valida per considerare r¬≤ come una misura appropriata della dimensione dell‚Äôeffetto. La statistica r corrisponde alla pendenza di regressione quando entrambe le variabili sono standardizzate, mentre r¬≤ √® molto meno interpretabile perch√© riflette la proporzione di varianza in una variabile spiegata da un‚Äôaltra.\nUn esempio illustrativo √® fornito da Darlington (1990). Immaginiamo un gioco in cui si lanciano prima un nickel (5¬¢) e poi un dime (10¬¢), ricevendo un pagamento di 5¬¢ o 10¬¢ rispettivamente se la moneta mostra testa. Le correlazioni tra il valore del nickel e il pagamento (r = .4472) e tra il valore del dime e il pagamento (r = .8944) sono calcolate. Elevando al quadrato queste correlazioni, si ottiene che i nickel spiegano il 20% della varianza nel pagamento, mentre i dime spiegano l‚Äô80%. Tuttavia, interpretare questi valori come indicazione che i dime contano quattro volte tanto quanto i nickel √® fuorviante. Le correlazioni originali (.8944 √® esattamente il doppio di .4472) offrono un confronto pi√π informativo. In conclusione, elevare al quadrato r per valutare la dimensione dell‚Äôeffetto non solo √® poco informativo, ma pu√≤ anche essere fuorviante.\n\n\n71.3.1 Alternative migliori\n√à cruciale interpretare le dimensioni degli effetti in modo che ne arricchisca il significato. Funder & Ozer (2019) propongono due strategie principali: l‚Äôadozione di benchmark (criteri di riferimento) e la valutazione delle implicazioni pratiche dei risultati.\n\nUtilizzare criteri di riferimento significa confrontare l‚Äôentit√† di un risultato con quella di risultati ben noti e ampiamente compresi. Simile al modo in cui giudichiamo l‚Äôaltezza di una persona basandoci su confronti con altri, i ricercatori possono ottenere una percezione accurata dell‚Äôimportanza di un risultato confrontandolo con la dimensione di effetti noti, sia quelli tipici del campo di studio sia quelli emersi da ricerche passate.\nUn approccio al benchmarking pu√≤ includere l‚Äôanalisi di risultati considerati ‚Äúclassici‚Äù nel campo di interesse o la considerazione di dimensioni dell‚Äôeffetto per risultati che hanno ottenuto un solido consenso nella comunit√† psicologica.\nIn un‚Äôottica pi√π ampia, alcuni ricercatori hanno proposto benchmark per la dimensione dell‚Äôeffetto calcolando medie su vasti corpi di letteratura. Ad esempio, uno studio di psicologia sociale ha esaminato 708 correlazioni ottenute meta-analiticamente, rivelando che la dimensione media dell‚Äôeffetto \\(r\\) era di .19.\nLa conoscenza comune o i risultati di ricerche non psicologiche possono offrire benchmark per valutare la forza di una relazione tra variabili. Un esempio √® l‚Äôefficacia degli antistaminici contro il comune raffreddore, che corrisponde a un \\(r\\) di .11, mentre l‚Äôeffetto degli anti-infiammatori non steroidei (come l‚Äôibuprofene) sul dolore √® di \\(r = .14\\).\n\nTali confronti illustrano come l‚Äôinterpretazione delle dimensioni dell‚Äôeffetto possa essere notevolmente approfondita e resa pi√π significativa attraverso il riferimento a benchmark consolidati o intuitivamente comprensibili, sia dentro che fuori il campo della psicologia. Questo metodo consente di inserire i risultati di nuove ricerche in un contesto pi√π vasto, favorendo una valutazione pi√π consapevole della loro rilevanza relativa.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>71</span>¬† <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html#raccomandazioni-per-la-pratica-di-ricerca",
    "href": "chapters/replication_crisis/03_effect_size.html#raccomandazioni-per-la-pratica-di-ricerca",
    "title": "71¬† La grandezza dell‚Äôeffetto",
    "section": "71.4 Raccomandazioni per la Pratica di Ricerca",
    "text": "71.4 Raccomandazioni per la Pratica di Ricerca\nFunder & Ozer (2019) concludono il loro articolo con una serie di raccomandazioni per migliorare la pratica di riportare le dimensioni degli effetti negli studi scientifici.\nRiportare sempre e in modo evidente le dimensioni degli effetti. Ogni studio dovrebbe evidenziare chiaramente le dimensioni degli effetti. Una conseguenza di questa raccomandazione √® che la dimensione del campione di uno studio deve essere adeguata affinch√© la stima della dimensione dell‚Äôeffetto sia affidabile.\nCondurre studi con campioni ampi. Studi con campioni ampi sono ideali. Sebbene questo non sia sempre fattibile con certi tipi di ricerca o popolazioni specifiche, dovrebbe essere una priorit√† aumentare il pi√π possibile la dimensione del campione.\nRiportare le dimensioni degli effetti in termini utili nel contesto. Il coefficiente di correlazione \\(r\\) di Pearson, essendo una misura standardizzata della dimensione dell‚Äôeffetto, non fornisce informazioni sulle unit√† di misura dello studio. Pertanto, √® necessario utilizzare misure delle dimensioni degli effetti che siano utili nel contesto specifico dello studio, come differenze medie o coefficienti di regressione grezzi, accanto a misure standardizzate, quando possibile.\nEvitare terminologia vuota. Si dovrebbe smettere di elevare al quadrato i valori di \\(r\\) per minimizzare l‚Äôapparente piccola percentuale di varianza spiegata e di utilizzare senza riflettere le linee guida di J. Cohen (1977, 1988), che lo stesso Cohen ha successivamente disconosciuto. Idealmente, termini come ‚Äúpiccolo‚Äù e ‚Äúgrande‚Äù dovrebbero essere eliminati dal vocabolario delle dimensioni degli effetti, poich√© sono etichette soggettive e spesso arbitrarie che non aggiungono informazioni utili ai risultati quantitativi.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>71</span>¬† <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html#commenti-e-considerazioni-finali",
    "href": "chapters/replication_crisis/03_effect_size.html#commenti-e-considerazioni-finali",
    "title": "71¬† La grandezza dell‚Äôeffetto",
    "section": "71.5 Commenti e considerazioni finali",
    "text": "71.5 Commenti e considerazioni finali\nLa sovrastima della grandezza dell‚Äôeffetto in psicologia costituisce un problema diffuso. Un principio fondamentale della psicologia sociale e dell‚Äôeconomia comportamentale, almeno come viene presentato nei media e insegnato in molte scuole di business, √® che piccoli ‚Äúnudge‚Äù o spinte gentili, spesso cose che potremmo pensare non ci influenzino affatto, possono avere grandi effetti sul comportamento. Questo ha portato a numerose affermazioni sensazionalistiche, come l‚Äôidea che le elezioni siano decise da partite di football, o che la presentazione subliminale di una faccina sorridente possa causare enormi cambiamenti negli atteggiamenti verso l‚Äôimmigrazione.\nIl modello di mondo alla base di queste affermazioni non √® solo ‚Äúl‚Äôeffetto farfalla‚Äù, ovvero che piccoli cambiamenti possono avere grandi effetti, ma piuttosto che piccoli cambiamenti possono avere effetti grandi e prevedibili. √à quello che a volte viene chiamato il modello ‚Äúa pulsante‚Äù delle scienze sociali: l‚Äôidea che se fai X, puoi aspettarti di vedere Y.\nTuttavia, questa visione presenta diversi problemi:\n\nSovrastima degli effetti: Molti studi riportano effetti sorprendentemente grandi per interventi minimi, che spesso non vengono replicati in studi successivi.\nMancanza di considerazione delle interazioni: Se esistessero molti effetti grandi e prevedibili sul comportamento, questi interferirebbero tra loro, rendendo difficile osservare effetti coerenti nei dati osservazionali.\nInstabilit√†: Un sistema sociale con molti effetti grandi e prevedibili sarebbe instabile e difficile da studiare.\nGeneralizzazione eccessiva: Spesso si tende a generalizzare risultati ottenuti in condizioni di laboratorio molto specifiche a contesti pi√π ampi e complessi della vita reale.\nBias di pubblicazione: Gli studi che riportano effetti grandi e statisticamente significativi hanno maggiori probabilit√† di essere pubblicati, creando una rappresentazione distorta della realt√†.\n\n√à importante sottolineare che la psicologia descrive molti fenomeni robusti, per esempio nella psicologia clinica e nella psicologia della percezione. Tuttavia, √® fondamentale adottare un approccio pi√π cauto e sfumato nell‚Äôinterpretazione e nella comunicazione dei risultati della ricerca psicologica. La consapevolezza di questo problema ha portato a una maggiore enfasi sulla replicabilit√† degli studi, sull‚Äôuso di campioni pi√π ampi e su metodi statistici pi√π robusti. Inoltre, sta emergendo un approccio pi√π critico e riflessivo nella comunit√† scientifica, che riconosce la complessit√† dei fenomeni psicologici e la necessit√† di evitare semplificazioni eccessive.\nIn conclusione, mentre la psicologia offre preziose intuizioni sul comportamento umano, √® essenziale mantenere un sano scetticismo verso affermazioni di effetti grandi e facilmente ottenibili. La realt√† √® spesso pi√π complessa e sfumata di quanto suggerito da titoli sensazionalistici o da singoli studi.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>71</span>¬† <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/replication_crisis/03_effect_size.html#informazioni-sullambiente-di-sviluppo",
    "title": "71¬† La grandezza dell‚Äôeffetto",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: US/Pacific\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pointblank_0.12.2 haven_2.5.4       labelled_2.14.0   mice_3.17.0      \n#&gt;  [5] ggokabeito_0.1.0  see_0.9.0         gridExtra_2.3     patchwork_1.3.0  \n#&gt;  [9] bayesplot_1.11.1  psych_2.4.12      scales_1.3.0      markdown_1.13    \n#&gt; [13] knitr_1.49        lubridate_1.9.4   forcats_1.0.0     stringr_1.5.1    \n#&gt; [17] dplyr_1.1.4       purrr_1.0.2       readr_2.1.5       tidyr_1.3.1      \n#&gt; [21] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [25] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      shape_1.4.6.1     xfun_0.50         htmlwidgets_1.6.4\n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2      \n#&gt;  [9] generics_0.1.3    parallel_4.4.2    pan_1.9           pacman_0.5.1     \n#&gt; [13] jomo_2.7-6        pkgconfig_2.0.3   Matrix_1.7-1      lifecycle_1.0.4  \n#&gt; [17] compiler_4.4.2    farver_2.1.2      munsell_0.5.1     mnormt_2.1.1     \n#&gt; [21] codetools_0.2-20  htmltools_0.5.8.1 glmnet_4.1-8      nloptr_2.1.1     \n#&gt; [25] pillar_1.10.1     MASS_7.3-64       iterators_1.0.14  rpart_4.1.23     \n#&gt; [29] boot_1.3-31       foreach_1.5.2     mitml_0.4-5       nlme_3.1-166     \n#&gt; [33] tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4     splines_4.4.2    \n#&gt; [37] rprojroot_2.0.4   fastmap_1.2.0     grid_4.4.2        blastula_0.3.5   \n#&gt; [41] colorspace_2.1-1  cli_3.6.3         magrittr_2.0.3    survival_3.7-0   \n#&gt; [45] broom_1.0.7       withr_3.0.2       backports_1.5.0   timechange_0.3.0 \n#&gt; [49] rmarkdown_2.29    nnet_7.3-19       lme4_1.1-35.5     hms_1.1.3        \n#&gt; [53] evaluate_1.0.1    rlang_1.1.4       Rcpp_1.0.13-1     glue_1.8.0       \n#&gt; [57] minqa_1.2.8       jsonlite_1.8.9    R6_2.5.1",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>71</span>¬† <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html#bibliografia",
    "href": "chapters/replication_crisis/03_effect_size.html#bibliografia",
    "title": "71¬† La grandezza dell‚Äôeffetto",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nFunder, D. C., & Ozer, D. J. (2019). Evaluating effect size in psychological research: Sense and nonsense. Advances in Methods and Practices in Psychological Science, 2(2), 156‚Äì168.\n\n\nGlass, G. V., McGaw, B., & Smith, M. L. (1981). Meta-analysis in Social Research. Sage Publications.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>71</span>¬† <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html",
    "href": "chapters/replication_crisis/04_s_m_errors.html",
    "title": "72¬† Errori di segno e errori di grandezza",
    "section": "",
    "text": "72.1 Introduzione\nIn questo capitolo verr√† esaminata la relazione tra la crisi della replicabilit√† e la procedura di decisione statistica dell‚Äôapproccio frequentista. In particolare, verranno discussi gli errori di tipo M (magnitude) e di tipo S (sign) che sono stati discussi da Loken & Gelman (2017).",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>72</span>¬† <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#il-filtro-della-significativit√†-statistica",
    "href": "chapters/replication_crisis/04_s_m_errors.html#il-filtro-della-significativit√†-statistica",
    "title": "72¬† Errori di segno e errori di grandezza",
    "section": "72.2 Il Filtro della Significativit√† Statistica",
    "text": "72.2 Il Filtro della Significativit√† Statistica\nNel ?sec-crisis abbiamo esaminato come la pratica scientifica contemporanea sia spesso compromessa da casi di frode, principalmente a causa delle notevoli implicazioni economiche legate alla pubblicazione su riviste scientifiche prestigiose. Questo problema √® frequentemente sottovalutato, poich√© le riviste sono riluttanti ad ammettere la necessit√† di correzioni o ritrattazioni degli articoli gi√† pubblicati.\nLa frode scientifica rappresenta una minaccia evidente alla riproducibilit√† dei risultati, pilastro fondamentale del metodo scientifico. Tuttavia, le difficolt√† nel replicare i risultati pubblicati non sono attribuibili esclusivamente alla frode o a ‚Äúpratiche di ricerca disoneste‚Äù (Nelson et al., 2018). Un problema intrinseco riguarda il metodo statistico ampiamente adottato dai ricercatori: l‚Äôapproccio del test di ipotesi nulla e della significativit√† statistica di stampo fisheriano. Secondo questo metodo, i risultati che non raggiungono la ‚Äúsignificativit√† statistica‚Äù dovrebbero essere scartati, mentre quelli che la superano possono essere considerati credibili, basandosi unicamente su questo criterio (Wagenmakers et al., 2008).\nTuttavia, l‚Äôidea che la significativit√† statistica sia un filtro affidabile per distinguere i risultati di ricerca ‚Äúvalidi‚Äù da quelli ‚Äúnon validi‚Äù √® fondamentalmente errata. Numerose evidenze dimostrano la fallacia di questo approccio. Per approfondire questo aspetto, esamineremo lo studio di Loken & Gelman (2017), che mette in luce la relazione tra la crisi della replicabilit√† e la procedura di decisione statistica dell‚Äôapproccio frequentista.\nUno dei principali problemi evidenziati dallo studio di Loken & Gelman (2017) √® che, in contesti di ricerca complessi, la significativit√† statistica fornisce prove molto deboli riguardo al segno o all‚Äôentit√† di eventuali effetti sottostanti. In altre parole, il raggiungimento della significativit√† statistica non garantisce n√© la rilevanza n√© la consistenza dei risultati ottenuti.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>72</span>¬† <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#errori-di-tipo-m-e-s",
    "href": "chapters/replication_crisis/04_s_m_errors.html#errori-di-tipo-m-e-s",
    "title": "72¬† Errori di segno e errori di grandezza",
    "section": "72.3 Errori di tipo M e S",
    "text": "72.3 Errori di tipo M e S\nPer evidenziare le implicazioni del processo decisionale basato sulla significativit√† statistica, gli autori di Loken & Gelman (2017) hanno condotto una simulazione. In questa simulazione, hanno immaginato una ricerca ipotetica in cui un effetto reale, seppur molto debole, era presente, ma difficilmente individuabile senza una grande quantit√† di dati. I ricercatori hanno quindi cercato di rilevare questo effetto utilizzando l‚Äôapproccio frequentista e valutando la significativit√† statistica.\nI risultati della simulazione hanno rivelato che, anche quando un effetto reale ma debole era presente, l‚Äôapproccio frequentista tendeva a individuare un effetto significativo solo in una piccola percentuale dei casi. Inoltre, quando veniva individuato un effetto significativo, la sua stima di grandezza risultava molto imprecisa e instabile.\nIn altre parole, la significativit√† statistica fornisce solo un‚Äôindicazione generale sulla presenza o assenza di un effetto, ma non offre informazioni precise sulla sua dimensione o replicabilit√†. Questo problema diventa ancora pi√π evidente quando si considera che molte ricerche in psicologia e scienze sociali utilizzano campioni relativamente piccoli, e gli effetti osservati in tali studi tendono ad essere molto modesti. In tali contesti, l‚Äôapproccio frequentista rischia di fornire prove molto deboli e instabili riguardo alla presenza o assenza di un effetto, mettendo a rischio la replicabilit√† e l‚Äôaffidabilit√† dei risultati della ricerca.\nRiproduciamo qui, in maniera semplificata, la simulazione condotta da Loken & Gelman (2017). Iniziamo ad importare le librerie necessarie.\nSupponiamo di considerare due campioni casuali indipendenti di dimensioni \\(n_1 = 20\\) e \\(n_2 = 25\\), estratti dalle distribuzioni normali \\(\\mathcal{N}(102, 10)\\) e \\(\\mathcal{N}(100, 10)\\) rispettivamente. La dimensione effettiva dell‚Äôeffetto per la differenza tra le medie di questi due campioni √® rappresentata da \\(d\\), calcolato attraverso la formula:\n\\[\nd = \\frac{\\bar{y}_1 - \\bar{y}_2}{s_p},\n\\]\ndove \\(\\bar{y}_1\\) e \\(\\bar{y}_2\\) sono le medie campionarie dei due gruppi, mentre \\(s_p\\) √® la deviazione standard combinata definita come:\n\\[\ns_p = \\sqrt{\\frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1 + n_2 - 2}},\n\\]\ncon \\(s_1\\) e \\(s_2\\) rappresentanti le deviazioni standard campionarie dei due gruppi.\nNel caso specifico preso in esame, la dimensione effettiva dell‚Äôeffetto √® molto piccola, indicando che la differenza osservata tra le medie manca di significativit√† pratica. Questo suggerisce che la distinzione tra i due gruppi non ha un impatto sostanziale nella pratica.\n\n# Parametri\nmu_1 &lt;- 102  # Media del primo gruppo\nmu_2 &lt;- 100  # Media del secondo gruppo\nsigma &lt;- 10  # Deviazione standard comune\nn1 &lt;- 20     # Numero di osservazioni nel primo gruppo\nn2 &lt;- 25     # Numero di osservazioni nel secondo gruppo\n\n# Calcolo della differenza media\nmean_difference &lt;- abs(mu_1 - mu_2)\n\n# Calcolo della deviazione standard pooled\npooled_sd &lt;- sqrt(((n1 - 1) * sigma^2 + (n2 - 1) * sigma^2) / (n1 + n2 - 2))\n\n# Calcolo di Cohen's d\ncohen_d &lt;- mean_difference / pooled_sd\n\n# Output del risultato\ncat(\"Dimensione dell'effetto (Cohen's d):\", cohen_d, \"\\n\")\n#&gt; Dimensione dell'effetto (Cohen's d): 0.2\n\nEsaminiamo ora quali sarebbero le conclusioni derivanti dall‚Äôapproccio frequentista mediante la procedura di decisione statistica in queste circostanze. Consideriamo una simulazione in cui vengono estratti due campioni: uno composto da 20 osservazioni dalla prima popolazione e l‚Äôaltro da 25 osservazioni dalla seconda popolazione. Successivamente, viene eseguito il test \\(t\\) di Student.\nNell‚Äôapproccio frequentista, se il valore-\\(p\\) risulta essere superiore a 0.05, i risultati vengono considerati non significativi e quindi scartati. Al contrario, se il valore-\\(p\\) √® inferiore a 0.05, il risultato √® considerato ‚Äúpubblicabile‚Äù e si conclude che esiste una differenza significativa tra i due gruppi.\nPer comprendere appieno le conclusioni ottenute mediante la procedura frequentista in questa situazione, √® necessario ripetere il processo sopra descritto per un ampio numero di iterazioni, ad esempio 50,000 volte. Questo implica che il processo di estrazione dei campioni e il calcolo dei valori-\\(p\\) vengono ripetuti numerose volte al fine di ottenere una visione completa delle possibili distribuzioni dei risultati.\n\n# Parametri\nn_samples &lt;- 50000\nmu_1 &lt;- 102\nmu_2 &lt;- 100\nsigma &lt;- 10\nn1 &lt;- 20\nn2 &lt;- 25\n\n# Inizializzazione del risultato\nres &lt;- c()\n\n# Simulazioni\nset.seed(123)  # Per la riproducibilit√†\nfor (i in 1:n_samples) {\n  # Generazione dei campioni casuali\n  y1 &lt;- rnorm(n1, mean = mu_1, sd = sigma)\n  y2 &lt;- rnorm(n2, mean = mu_2, sd = sigma)\n  \n  # Calcolo della dimensione dell'effetto\n  y1bar &lt;- mean(y1)\n  y2bar &lt;- mean(y2)\n  v1 &lt;- var(y1)\n  v2 &lt;- var(y2)\n  s &lt;- sqrt(((n1 - 1) * v1 + (n2 - 1) * v2) / (n1 + n2 - 2))\n  efsize &lt;- (y1bar - y2bar) / s\n  \n  # Calcolo del valore p\n  t_test &lt;- t.test(y1, y2, var.equal = TRUE)\n  \n  # Salvataggio della dimensione dell'effetto solo per risultati \"statisticamente significativi\"\n  if (t_test$p.value &lt; 0.05) {\n    res &lt;- c(res, efsize)\n  }\n}\n\n\nres_df &lt;- data.frame(effect_size = res)\n\nggplot(res_df, aes(x = effect_size)) +\n  geom_histogram(bins = 20, fill = \"blue\", color = \"black\", alpha = 0.7) +\n  geom_vline(\n    xintercept = 0.2, color = \"red\", linetype = \"dashed\", \n    size = 1.2, label = \"True Effect Size\") +\n  labs(\n    x = \"Effect Size\",\n    y = \"Frequency\",\n    title = \"Histogram of Effect Sizes for 'Statistically Significant' Results\"\n  ) \n#&gt; Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#&gt; ‚Ñπ Please use `linewidth` instead.\n#&gt; Warning in geom_vline(xintercept = 0.2, color = \"red\", linetype = \"dashed\",\n#&gt; : Ignoring unknown parameters: `label`\n\n\n\n\n\n\n\n\nCome sottolineato da Loken & Gelman (2017), l‚Äôutilizzo dell‚Äôapproccio frequentista nella procedura di decisione statistica pu√≤ portare a due tipi di errori significativi. Il primo errore, noto come ‚Äúmagnitude‚Äù, si manifesta nel fatto che i risultati pubblicati tendono a sovrastimare la vera grandezza dell‚Äôeffetto. Nella simulazione effettuata, sebbene la vera grandezza dell‚Äôeffetto fosse modesta (0.2), la media della grandezza dell‚Äôeffetto per i risultati dichiarati ‚Äústatisticamente significativi‚Äù era di circa 0.8, indicando una grandezza dell‚Äôeffetto ‚Äúampia‚Äù.\nIl secondo errore, denominato ‚Äúsegno‚Äù, si verifica in alcune situazioni in cui, a causa della variabilit√† campionaria, viene commesso un errore nella direzione dell‚Äôeffetto. In tali circostanze, il ricercatore potrebbe erroneamente concludere che \\(\\mu_2 &gt; \\mu_1\\), quando in realt√† non √® cos√¨. √à importante notare che, anche in questi casi, la grandezza dell‚Äôeffetto viene sovrastimata in termini assoluti.\n√à interessante notare che le stesse conclusioni si applicherebbero anche se avessimo considerato l‚Äôintervallo di confidenza per la differenza tra le medie. In sintesi, l‚Äôapproccio frequentista introduce un errore sistematico nella stima della grandezza dell‚Äôeffetto, che √® la quantit√† pi√π importante che il ricercatore deve stimare. In alcune situazioni, pu√≤ persino causare errori nella stima della direzione dell‚Äôeffetto.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>72</span>¬† <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#riflessioni-conclusive",
    "href": "chapters/replication_crisis/04_s_m_errors.html#riflessioni-conclusive",
    "title": "72¬† Errori di segno e errori di grandezza",
    "section": "72.4 Riflessioni Conclusive",
    "text": "72.4 Riflessioni Conclusive\nIn conclusione, l‚Äôapproccio frequentista non fornisce un metodo affidabile per valutare i risultati della ricerca e determinare la loro attendibilit√† o la necessit√† di scartarli [gelman2014beyond; Loken & Gelman (2017)]. Questa mancanza di affidabilit√† deriva dall‚Äôintroduzione di errori sistematici nella stima delle dimensioni dell‚Äôeffetto, che pu√≤ anche portare a errori nella direzione dell‚Äôeffetto in alcune circostanze. Di conseguenza, non sembra esserci motivo valido per continuare a impiegare questo approccio.\nAl contrario, l‚Äôadozione dell‚Äôapproccio bayesiano sembra offrire risultati pi√π precisi e affidabili nella valutazione dei dati di ricerca. Tale approccio considera la probabilit√† delle ipotesi alla luce dei dati osservati, evitando gli errori intrinseci dell‚Äôapproccio frequentista e fornendo una base pi√π solida per le decisioni sulla validit√† dei risultati.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>72</span>¬† <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#esercizi",
    "href": "chapters/replication_crisis/04_s_m_errors.html#esercizi",
    "title": "72¬† Errori di segno e errori di grandezza",
    "section": "72.5 Esercizi",
    "text": "72.5 Esercizi\n\nEsercizio 72.1 Esegui una simulazione con 10.000 ripetizioni (nrep = 10000) in cui vengono estratti due campioni casuali dalla stessa popolazione normale con media 0 e deviazione standard 10. Per ogni simulazione, esegui un t-test per confrontare le medie di due gruppi indipendenti.\n\nProporzione di risultati statisticamente significativi: Calcola la proporzione di risultati in cui si ottiene un risultato statisticamente significativo (p &lt; 0.05) in questa condizione in cui i campioni provengono dalla stessa popolazione, e quindi non c‚Äô√® una differenza reale tra i gruppi. Questo ti dar√† un‚Äôidea della frequenza dei falsi positivi.\nGrandezza dell‚Äôeffetto media: Calcola la grandezza dell‚Äôeffetto (d di Cohen) media, considerando solo quei test in cui si √® ottenuta una differenza statisticamente significativa. Questo valore ti mostrer√† quanto grande appare l‚Äôeffetto quando il risultato √® significativo, nonostante la realt√† sia priva di un effetto reale.\nRipetizione della simulazione con diverse grandezze campionarie: Ripeti la simulazione usando due diverse dimensioni campionarie: 20 osservazioni per gruppo e 200 osservazioni per gruppo. Confronta i risultati per capire come la dimensione del campione influenzi la proporzione di falsi positivi e la grandezza dell‚Äôeffetto media.\nInterpretazione dei risultati: Interpreta i risultati alla luce del concetto del ‚Äúfiltro della significativit√† statistica‚Äù. Questo concetto suggerisce che tra tutti gli studi effettuati, tendono ad essere pubblicati e riportati solo quelli che ottengono risultati statisticamente significativi. Di conseguenza, i risultati significativi pubblicati possono sovrastimare la vera grandezza dell‚Äôeffetto o indicare erroneamente che un effetto esiste quando in realt√† non c‚Äô√®. Questa simulazione dovrebbe mostrare come, anche in assenza di una differenza reale tra gruppi, si possano ottenere risultati apparentemente significativi con una certa frequenza, soprattutto quando la dimensione campionaria √® piccola.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>72</span>¬† <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/replication_crisis/04_s_m_errors.html#informazioni-sullambiente-di-sviluppo",
    "title": "72¬† Errori di segno e errori di grandezza",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: US/Pacific\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] ggokabeito_0.1.0 see_0.9.0        gridExtra_2.3    patchwork_1.3.0 \n#&gt;  [5] bayesplot_1.11.1 psych_2.4.12     scales_1.3.0     markdown_1.13   \n#&gt;  [9] knitr_1.49       lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1   \n#&gt; [13] dplyr_1.1.4      purrr_1.0.2      readr_2.1.5      tidyr_1.3.1     \n#&gt; [17] tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3       \n#&gt; [21] here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.3         rlang_1.1.4       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       yaml_2.3.10       tools_4.4.2       parallel_4.4.2   \n#&gt; [21] tzdb_0.4.0        colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5      \n#&gt; [25] R6_2.5.1          lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3  \n#&gt; [29] pillar_1.10.1     gtable_0.3.6      glue_1.8.0        xfun_0.50        \n#&gt; [33] tidyselect_1.2.1  farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-166     \n#&gt; [37] labeling_0.4.3    rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>72</span>¬† <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#bibliografia",
    "href": "chapters/replication_crisis/04_s_m_errors.html#bibliografia",
    "title": "72¬† Errori di segno e errori di grandezza",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nLoken, E., & Gelman, A. (2017). Measurement Error and the Replication Crisis. Science, 355(6325), 584‚Äì585.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nNelson, L. D., Simmons, J., & Simonsohn, U. (2018). Psychology‚Äôs renaissance. Annual review of psychology, 69(1), 511‚Äì534.\n\n\nWagenmakers, E.-J., Lee, M., Lodewyckx, T., & Iverson, G. J. (2008). Bayesian versus frequentist inference. Bayesian evaluation of informative hypotheses, 181‚Äì207.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>72</span>¬† <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/05_p_values.html",
    "href": "chapters/replication_crisis/05_p_values.html",
    "title": "73¬† La fragilit√† del p-valore",
    "section": "",
    "text": "73.1 Introduzione\nIl codice seguente √® ispirato da un post sul blog di Andrew Gelman.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>73</span>¬† <span class='chapter-title'>La fragilit√† del *p*-valore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/05_p_values.html#simulazione",
    "href": "chapters/replication_crisis/05_p_values.html#simulazione",
    "title": "73¬† La fragilit√† del p-valore",
    "section": "73.2 Simulazione",
    "text": "73.2 Simulazione\nLa seguente simulazione ha l‚Äôobiettivo di mostrare quanto i p-valori possano essere ‚Äúfragili‚Äù e variare notevolmente da campione a campione, anche quando i dati provengono da una distribuzione con parametri molto simili. Questo serve a dimostrare che il p-valore, spesso usato per determinare la significativit√† statistica di un effetto, pu√≤ essere influenzato pesantemente dalla variabilit√† campionaria, soprattutto in campioni di piccole dimensioni o con effetti deboli. Gelman esprime questo concetto dicendo che\n\nthe difference between ‚Äúsignificant‚Äù and ‚Äúnot significant‚Äù is not itself statistically significant.\n\n\n73.2.1 Logica della Simulazione\n\nObiettivo:\n\nDimostrare la variabilit√† dei p-valori calcolati per diversi campioni estratti da una popolazione con una media molto vicina a zero.\nMostrare come, nonostante l‚Äôeffetto vero sia piccolo, i p-valori possano essere significativamente diversi tra loro, a seconda della variabilit√† e delle dimensioni del campione.\n\nSetup della Simulazione:\n\nGeneriamo \\(J = 10\\) campioni indipendenti, ognuno con un numero ridotto di osservazioni (\\(n = 10\\)), per massimizzare la variabilit√† dei risultati.\nOgni campione √® generato da una distribuzione normale con una media vera di \\(\\mu = 0.05\\) e una deviazione standard di \\(\\sigma = 0.1\\). Questi parametri sono scelti per rendere la media dei campioni vicina a zero e, al tempo stesso, abbastanza variabile.\n\nCalcolo della media campionaria:\n\nPer ciascun campione, calcoliamo la media (\\(\\hat{\\mu}\\)) e la deviazione standard (\\(\\hat{\\sigma}\\)).\nLa media del campione (\\(\\hat{\\mu}\\)) √® utilizzata come stima del parametro.\n\nCalcolo del p-valore:\n\nApplichiamo un t-test per ciascun campione per verificare l‚Äôipotesi nulla (\\(H_0\\)) che la media del campione sia zero.\nIl p-valore viene calcolato utilizzando la formula classica del t-test:\n\\[\nt = \\frac{\\hat{\\mu}}{\\frac{\\hat{\\sigma}}{\\sqrt{n}}}\n\\]\ndove:\n\n\\(\\hat{\\mu}\\) √® la media del campione,\n\\(\\hat{\\sigma}\\) √® la deviazione standard del campione,\n\\(n\\) √® il numero di osservazioni per campione.\n\nSuccessivamente, il p-valore √® calcolato come:\n\\[\n\\text{p-value} = 2 \\times (1 - \\text{CDF}(|t|))\n\\]\ndove \\(\\text{CDF}\\) √® la funzione cumulativa della distribuzione t con \\(n-1\\) gradi di libert√†.\n\n\n\n\n73.2.2 Descrizione della Sintassi\nIl codice R √® strutturato come segue:\n\nGenerazione dei campioni:\n\n\nCreiamo una lista di campioni (10 campioni in totale), ognuno con 10 osservazioni, utilizzando la distribuzione normale con media 0.05 e deviazione standard 0.1.\n\n\nCalcolo delle medie e dei p-valori:\n\nIteriamo su ciascun campione per calcolare la media (\\(\\hat{\\mu}\\)) e la deviazione standard (\\(\\hat{\\sigma}\\)).\nCalcoliamo il valore statistico \\(t\\) e il corrispondente p-valore utilizzando la distribuzione t.\n\nStampa dei risultati:\n\nI p-valori vengono arrotondati e stampati per osservare quanto siano variabili.\n\n\n\n# Imposta il seme per riproducibilit√†\nset.seed(1234)\n\n# Parametri della simulazione\nJ &lt;- 10              # Numero di campioni indipendenti\nn &lt;- 10              # Numero di osservazioni per campione\ntrue_mean &lt;- 0.05    # Media vera della popolazione\ntrue_sd &lt;- 0.1       # Deviazione standard della popolazione\n\n# Genera i campioni casuali\nsamples &lt;- replicate(J, rnorm(n, mean = true_mean, sd = true_sd), simplify = FALSE)\n\n# Calcola statistiche campionarie e p-valori\nresults &lt;- lapply(samples, function(sample) {\n  sample_mean &lt;- mean(sample)                         # Media campionaria\n  sample_sd &lt;- sd(sample)                             # Deviazione standard campionaria\n  t_statistic &lt;- sample_mean / (sample_sd / sqrt(n))  # Statistica t\n  p_value &lt;- 2 * (1 - pt(abs(t_statistic), df = n - 1))  # p-valore bilaterale\n  list(mean = sample_mean, sd = sample_sd, t = t_statistic, p_value = p_value)\n})\n\n# Converti i risultati in un data frame per facilitarne la visualizzazione\nresults_df &lt;- do.call(rbind, lapply(results, as.data.frame))\nrownames(results_df) &lt;- paste(\"C\", 1:J)\n\n# Visualizza i risultati\nprint(results_df)\n#&gt;         mean     sd      t p_value\n#&gt; C 1   0.0117 0.0996  0.371 0.71918\n#&gt; C 2   0.0382 0.1067  1.131 0.28718\n#&gt; C 3   0.0112 0.0666  0.532 0.60758\n#&gt; C 4  -0.0266 0.0894 -0.941 0.37112\n#&gt; C 5  -0.0110 0.0787 -0.441 0.66955\n#&gt; C 6   0.0221 0.1186  0.590 0.56994\n#&gt; C 7   0.1117 0.1144  3.086 0.01301\n#&gt; C 8   0.0458 0.0924  1.567 0.15157\n#&gt; C 9   0.0342 0.0735  1.470 0.17575\n#&gt; C 10  0.1061 0.0984  3.409 0.00776\n\n\nggplot(results_df, aes(x = rownames(results_df), y = p_value)) +\n  geom_point(size = 3, color = \"blue\") +\n  geom_hline(yintercept = 0.05, linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Variabilit√† dei p-valori nei campioni\",\n    x = \"Campioni\",\n    y = \"p-valore\"\n  ) \n\n\n\n\n\n\n\n\nImmaginiamo che questo sia un esperimento reale. Alcuni campioni potrebbero mostrare risultati compatibili con il puro rumore, altri fornire deboli indicazioni contro l‚Äôipotesi nulla, mentre altri ancora potrebbero sembrare altamente significativi dal punto di vista statistico. Verrebbe naturale cercare di categorizzare questi risultati in qualche modo. Tuttavia, la differenza tra ‚Äúsignificativo‚Äù e ‚Äúnon significativo‚Äù non √® di per s√© statisticamente significativa. Ad esempio, si potrebbe essere tentati di considerare rilevante una differenza tra un p-valore di 0.336 e uno di 0.003, ma non √® cos√¨.\nQuesto scenario estremo riflette una situazione in cui non c‚Äô√® una reale variazione sottostante. Se si utilizzasse un modello multilivello, probabilmente emergerebbe l‚Äôassenza di una variazione effettiva significativa.\n\n\n73.2.3 Punti chiave:\n\nIl p-valore descrive solo l‚Äôipotesi nulla: √à una misura relativa all‚Äôassenza di effetto, ma non ha necessariamente un significato diretto rispetto a un effetto reale, anche se piccolo.\nIl p-valore √® altamente variabile: Essendo una trasformazione non lineare dello z-score (che ha un‚Äôinterpretazione pi√π chiara), il p-valore pu√≤ comportarsi in modi non intuitivi, soprattutto con campioni piccoli.\nLe simulazioni sono istruttive: Anche esperimenti semplici come questo possono essere estremamente utili per comprendere le limitazioni e l‚Äôinterpretazione dei risultati.\n\n\n\n73.2.4 Un avvertimento importante:\nAnche le inferenze bayesiane sono soggette a variabilit√†. Qualsiasi sintesi dei dati porta con s√© un certo grado di incertezza. Il problema non risiede nei p-valori in s√©, ma nel loro utilizzo scorretto. Interpretare un p-valore come una dichiarazione forte sulla realt√†, invece di considerarlo un riassunto rumoroso di un esperimento specifico, √® un errore comune.\nAllo stesso modo, fraintendimenti e sovrainterpretazioni possono verificarsi anche con approcci bayesiani. Ad esempio, l‚Äôadattamento di un modello con prior non informativi e l‚Äôinterpretazione della probabilit√† posteriore di un parametro (ad esempio, maggiore di zero) sulla base di una soglia arbitraria pu√≤ portare a conclusioni altrettanto problematiche. Questi risultati ci ricordano l‚Äôimportanza di una sana cautela nell‚Äôinterpretazione statistica, indipendentemente dal metodo utilizzato.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>73</span>¬† <span class='chapter-title'>La fragilit√† del *p*-valore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/05_p_values.html#riflessioni-conclusive",
    "href": "chapters/replication_crisis/05_p_values.html#riflessioni-conclusive",
    "title": "73¬† La fragilit√† del p-valore",
    "section": "73.3 Riflessioni Conclusive",
    "text": "73.3 Riflessioni Conclusive\nLa simulazione mostra che, nonostante le medie dei campioni siano generate con una distribuzione simile, i p-valori possono variare drasticamente. Questo effetto √® amplificato dalla scelta di campioni piccoli e di una media vera molto vicina all‚Äôipotesi nulla (zero). Dimostra quanto il p-valore possa essere influenzato da piccole variazioni nei dati e perch√© non sia sempre un indicatore affidabile per valutare l‚Äôefficacia o la presenza di un effetto.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>73</span>¬† <span class='chapter-title'>La fragilit√† del *p*-valore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/05_p_values.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/replication_crisis/05_p_values.html#informazioni-sullambiente-di-sviluppo",
    "title": "73¬† La fragilit√† del p-valore",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: US/Pacific\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] ggokabeito_0.1.0 see_0.9.0        gridExtra_2.3    patchwork_1.3.0 \n#&gt;  [5] bayesplot_1.11.1 psych_2.4.12     scales_1.3.0     markdown_1.13   \n#&gt;  [9] knitr_1.49       lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1   \n#&gt; [13] dplyr_1.1.4      purrr_1.0.2      readr_2.1.5      tidyr_1.3.1     \n#&gt; [17] tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3       \n#&gt; [21] here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.3         rlang_1.1.4       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       tools_4.4.2       parallel_4.4.2    tzdb_0.4.0       \n#&gt; [21] colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5       R6_2.5.1         \n#&gt; [25] lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.1    \n#&gt; [29] gtable_0.3.6      glue_1.8.0        xfun_0.50         tidyselect_1.2.1 \n#&gt; [33] farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-166      labeling_0.4.3   \n#&gt; [37] rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>73</span>¬† <span class='chapter-title'>La fragilit√† del *p*-valore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/05_p_values.html#bibliografia",
    "href": "chapters/replication_crisis/05_p_values.html#bibliografia",
    "title": "73¬† La fragilit√† del p-valore",
    "section": "Bibliografia",
    "text": "Bibliografia",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>73</span>¬† <span class='chapter-title'>La fragilit√† del *p*-valore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html",
    "href": "chapters/replication_crisis/06_changes.html",
    "title": "74¬† Riforma",
    "section": "",
    "text": "74.1 Introduzione\nLa crisi della riproducibilit√† ha portato a una profonda riflessione sullo stato della ricerca nelle scienze comportamentali, cognitive e sociali. La scoperta che molti studi pubblicati non erano replicabili ha scosso la fiducia nella ricerca scientifica e ha messo in evidenza le carenze metodologiche e strutturali che affliggono il sistema accademico. Di fronte a questa crisi, sono state avanzate diverse proposte di riforma volte a migliorare la qualit√† e l‚Äôaffidabilit√† della ricerca scientifica.\nSecondo Korbmacher et al. (2023) sono neccessarie riforme strutturali, cambiamenti procedurali e cambiamenti nella comunit√† scientifica.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>74</span>¬† <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#riforme-strutturali",
    "href": "chapters/replication_crisis/06_changes.html#riforme-strutturali",
    "title": "74¬† Riforma",
    "section": "74.2 Riforme Strutturali",
    "text": "74.2 Riforme Strutturali\n\n74.2.1 Integrazione della Riproducibilit√† nei Curriculum Educativi\nUna delle principali proposte per affrontare la crisi della riproducibilit√† √® l‚Äôintegrazione delle pratiche di riproducibilit√† nei curriculum educativi delle scienze psicologiche e affini. Attualmente, molti programmi di formazione non pongono sufficiente enfasi sull‚Äôimportanza della replicabilit√† e della trasparenza nella ricerca. Incorporare queste tematiche nei corsi di metodologia della ricerca pu√≤ sensibilizzare le nuove generazioni di ricercatori alla necessit√† di adottare pratiche pi√π rigorose e trasparenti. Ad esempio, alcuni programmi universitari hanno iniziato a includere repliche di studi famosi come parte del percorso formativo degli studenti, offrendo loro l‚Äôopportunit√† di comprendere meglio i limiti e le potenzialit√† del processo scientifico.\n\n\n74.2.2 Incentivi per la Scienza Aperta\nOltre alla formazione, un altro aspetto cruciale √® la riforma dei sistemi di incentivazione accademica. Tradizionalmente, il sistema accademico ha privilegiato la quantit√† di pubblicazioni e la novit√† dei risultati, piuttosto che la loro qualit√† e replicabilit√†. Per promuovere pratiche di scienza aperta, come la preregistrazione degli studi e la condivisione aperta dei dati, si propone l‚Äôintroduzione di riconoscimenti ufficiali, come badge di ‚Äúopen science‚Äù o crediti accademici per la pubblicazione di rapporti registrati. Questi cambiamenti potrebbero favorire una maggiore adozione di pratiche che promuovono la trasparenza e rafforzano la fiducia nella ricerca scientifica.\nA tal proposito, √® interessante considerare uno studio di Scheel et al. (2021). Gli autori hanno confrontato i risultati di rapporti registrati pubblicati (N = 71) con un campione casuale di studi ipotetico-deduttivi della letteratura standard (N = 152) in psicologia. Analizzando la prima ipotesi di ciascun articolo, hanno riscontrato che il 96% dei risultati nei rapporti standard erano positivi, contro solo il 44% nei rapporti registrati.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>74</span>¬† <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#cambiamenti-procedurali",
    "href": "chapters/replication_crisis/06_changes.html#cambiamenti-procedurali",
    "title": "74¬† Riforma",
    "section": "74.3 Cambiamenti Procedurali",
    "text": "74.3 Cambiamenti Procedurali\n\n74.3.1 Mercati di Previsione per la Credibilit√† della Ricerca\nI mercati di previsione sono stati proposti come uno strumento innovativo per valutare la credibilit√† della ricerca. In questi mercati, esperti e non esperti scommettono sulla probabilit√† che i risultati di determinati studi siano replicabili. Questo approccio ha dimostrato di avere un‚Äôelevata accuratezza nella classificazione della replicabilit√† degli studi, offrendo un metodo alternativo e complementare alla replicazione diretta. I mercati di previsione potrebbero essere particolarmente utili in contesti in cui la raccolta dati √® costosa o difficile da realizzare, fornendo una prima indicazione sulla solidit√† dei risultati di ricerca.\n\n\n74.3.2 Strumenti di Valutazione Statistica\nUn‚Äôaltra proposta riguarda l‚Äôadozione di nuovi strumenti di valutazione statistica per identificare e correggere il bias di pubblicazione e migliorare la potenza degli studi. Strumenti come la curva-p e la curva-z sono stati sviluppati per analizzare la distribuzione dei valori p e identificare eventuali distorsioni nei risultati pubblicati. Inoltre, alcuni studiosi hanno suggerito di abbassare il livello di significativit√† statistica standard da 0,05 a 0,005 per ridurre il tasso di falsi positivi e aumentare la robustezza dei risultati. Queste proposte, sebbene non risolutive, rappresentano passi importanti verso una maggiore precisione nelle analisi statistiche.\n\n\n74.3.3 Analisi Multiverso\nL‚Äôanalisi multiverso √® un‚Äôaltra proposta innovativa che mira a gestire la molteplicit√† di scelte analitiche possibili in un singolo studio. Questa tecnica prevede l‚Äôesecuzione di molteplici analisi su uno stesso dataset, variando i parametri e le scelte metodologiche, per testare la stabilit√† dei risultati. L‚Äôadozione di questo approccio permette di evidenziare quanto i risultati siano sensibili alle scelte analitiche, contribuendo a una maggiore trasparenza e affidabilit√† nelle conclusioni tratte dagli studi.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>74</span>¬† <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#cambiamenti-nella-comunit√†",
    "href": "chapters/replication_crisis/06_changes.html#cambiamenti-nella-comunit√†",
    "title": "74¬† Riforma",
    "section": "74.4 Cambiamenti nella Comunit√†",
    "text": "74.4 Cambiamenti nella Comunit√†\n\n74.4.1 Big Team Science\nIl concetto di ‚ÄúBig Team Science‚Äù rappresenta un cambiamento significativo nella modalit√† di condurre ricerca. Questo approccio prevede la collaborazione su larga scala tra scienziati di diversi paesi e discipline, con l‚Äôobiettivo di replicare studi, raccogliere grandi campioni e condividere risorse. Questo modello di lavoro collettivo non solo aumenta l‚Äôefficienza della ricerca, ma promuove anche una maggiore diversit√† nei campioni e nei team di ricerca. Tuttavia, esistono anche criticit√†, come la possibilit√† di perpetuare disuguaglianze tra ricercatori di paesi sviluppati e in via di sviluppo, e la difficolt√† nel riconoscere adeguatamente i contributi individuali all‚Äôinterno di grandi consorzi.\n\n\n74.4.2 Collaborazioni Avversariali\nLe collaborazioni avversariali rappresentano un altro approccio interessante per migliorare la qualit√† della ricerca. In queste collaborazioni, ricercatori con visioni teoriche contrastanti lavorano insieme per progettare e condurre studi che testino le loro ipotesi in modo rigoroso. Questo tipo di collaborazione pu√≤ ridurre i bias personali e promuovere un confronto costruttivo, portando a conclusioni pi√π solide e condivise all‚Äôinterno della comunit√† scientifica.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>74</span>¬† <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#crisi-della-generalizzabilit√†",
    "href": "chapters/replication_crisis/06_changes.html#crisi-della-generalizzabilit√†",
    "title": "74¬† Riforma",
    "section": "74.5 Crisi della generalizzabilit√†",
    "text": "74.5 Crisi della generalizzabilit√†\nYarkoni (2022) affronta la questione critica della scarsa validit√† delle inferenze quantitative presenti nella letteratura psicologica pubblicata proponendo tre strategie principali che, se adottate, potrebbero migliorare significativamente la qualit√† della ricerca in psicologia.\n\n74.5.1 Do Something Else\nIl primo suggerimento dell‚Äôautore √® quello di considerare la possibilit√† di abbandonare la ricerca psicologica quantitativa laddove risulti troppo difficile estrarre conclusioni significative e generalizzabili da effetti complessi e variabili. L‚Äôautore critica la tendenza nella psicologia (e in altre discipline) di concludere ogni contributo di ricerca con una nota positiva o ‚Äúcostruttiva‚Äù, indipendentemente dalla realt√† delle evidenze raccolte. Secondo l‚Äôautore, non √® realistico pensare che ogni domanda di ricerca meriti una risposta empirica, soprattutto quando le risorse necessarie per ottenere risultati minimamente informativi superano di gran lunga gli standard convenzionali. In queste circostanze, potrebbe essere pi√π saggio riconoscere i limiti della ricerca e, in alcuni casi, scegliere percorsi di carriera alternativi, specialmente per i ricercatori alle prime armi, che potrebbero trovare prospettive di carriera migliori al di fuori dell‚Äôaccademia.\n\n\n74.5.2 Abbracciare l‚ÄôAnalisi Qualitativa\nLa seconda opzione proposta √® continuare a fare ricerca psicologica, ma abbandonando in gran parte i metodi statistici inferenziali a favore di metodi qualitativi. L‚Äôautore sostiene che gran parte di ci√≤ che attualmente passa per scienza quantitativa in psicologia sia in realt√† un‚Äôanalisi qualitativa mascherata. Alcune teorie psicologiche, secondo l‚Äôautore, non traggono beneficio da un‚Äôanalisi quantitativa poich√© sono o troppo vaghe o troppo ovvie per essere falsificabili attraverso procedure statistiche. L‚Äôautore suggerisce che in molti casi l‚Äôanalisi qualitativa potrebbe fornire risposte pi√π profonde e significative rispetto a un approccio quantitativo superficiale, evitando cos√¨ l‚Äôillusione di una precisione scientifica inesistente.\nIn un approccio qualitativo, i ricercatori potrebbero concentrarsi sulla descrizione e sull‚Äôesplorazione delle relazioni tra variabili senza cercare di trarre conclusioni causali definitive. L‚Äôautore menziona l‚Äôesempio della rivista Basic and Applied Social Psychology, che ha bandito l‚Äôuso dei p-value, come un esempio di come l‚Äôabbandono della statistica inferenziale possa essere gestito in modo costruttivo. Sebbene questa mossa sia stata accolta con scetticismo, l‚Äôautore suggerisce che, se affrontata correttamente, potrebbe essere un passo positivo verso una maggiore integrit√† nella ricerca psicologica.\n\n\n74.5.3 Adottare Standard Migliori\nLa terza e ultima strategia consiste nel migliorare gli standard della ricerca quantitativa in psicologia per renderla pi√π rigorosa e affidabile. L‚Äôautore propone diverse pratiche che, se implementate, potrebbero migliorare la qualit√† e la validit√† delle inferenze psicologiche:\n\nInferenze pi√π conservative: I ricercatori dovrebbero evitare di fare generalizzazioni ampie basate su dati limitati e dovrebbero esplicitamente indicare quando stanno speculando al di l√† dei dati disponibili. La formulazione di titoli di articoli e affermazioni dovrebbe riflettere in modo pi√π accurato la portata dei risultati ottenuti.\nRicerca descrittiva: L‚Äôautore esorta a prendere pi√π seriamente la ricerca descrittiva, che si concentra sulla caratterizzazione delle relazioni tra variabili senza ricorrere a spiegazioni causali. Questo tipo di ricerca pu√≤ fornire un‚Äôimportante base empirica che √® spesso trascurata a favore di teorie semplificate e sovrastimate.\nModelli statistici pi√π espansivi: I ricercatori dovrebbero abituarsi a utilizzare modelli statistici che considerino una pi√π ampia gamma di variabili e fattori, oltre a includere effetti random per elementi come stimoli, compiti e siti di ricerca. Questo approccio richiede l‚Äôuso di modelli misti che permettano di gestire la complessit√† della realt√† psicologica in modo pi√π adeguato.\nProgettare con la variazione in mente: Yarkoni (2022) sostiene l‚Äôimportanza di progettare studi che abbraccino la variabilit√† naturale delle condizioni sperimentali, piuttosto che cercare di controllare rigidamente ogni variabile. Questo approccio, sebbene pi√π costoso in termini di risorse, permetterebbe di ottenere risultati pi√π generalizzabili e utili.\nStime della varianza: Un maggiore enfasi dovrebbe essere posta sull‚Äôanalisi dele componenti della varianza piuttosto che sulle stime puntuali. Questo permetterebbe di comprendere meglio l‚Äôimportanza relativa delle diverse fonti di variazione nei dati e di pianificare studi futuri in modo pi√π informato.\nPredizioni pi√π rischiose: Yarkoni (2022) incoraggia i ricercatori a formulare predizioni teoriche che comportino un alto grado di rischio. Predizioni pi√π precise e rischiose ridurrebbero le preoccupazioni sulla generalizzabilit√†, poich√© solo modelli teorici accurati sarebbero in grado di fare previsioni con tale precisione.\nUtilit√† predittiva pratica: Infine, Yarkoni (2022) suggerisce un approccio pi√π pragmatico che si concentri sull‚Äôutilit√† pratica delle predizioni piuttosto che su considerazione puramente teoriche. Invece di chiedersi se un fenomeno esiste, dovremmo chiederci se possiamo costruire modelli che predicano efficacemente comportamenti rilevanti in situazioni specifiche.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>74</span>¬† <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#sviluppare-teorie-formali",
    "href": "chapters/replication_crisis/06_changes.html#sviluppare-teorie-formali",
    "title": "74¬† Riforma",
    "section": "74.6 Sviluppare teorie formali",
    "text": "74.6 Sviluppare teorie formali\nOltre alle carenze metodologiche o statistiche, √® stato spesso sottolineato che la crisi di replicabilit√† che affligge le scienze psicologiche trova le sue radici nella mancanza di un quadro teorico cumulativo. Senza un quadro teorico generale che generi ipotesi in diversi ambiti, i programmi empirici si sviluppano a partire da intuizioni personali e teorie popolari influenzate culturalmente. Fornendo strumenti per formulare previsioni chiare, anche attraverso l‚Äôuso di modelli formali, i quadri teorici stabiliscono aspettative che permettono di determinare se un nuovo risultato conferma le ricerche esistenti, integrandosi con esse, oppure se √® inaspettato e, pertanto, richiede ulteriori verifiche e approfondimenti (Muthukrishna & Henrich, 2019).",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>74</span>¬† <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#riflessioni-conclusive",
    "href": "chapters/replication_crisis/06_changes.html#riflessioni-conclusive",
    "title": "74¬† Riforma",
    "section": "74.7 Riflessioni Conclusive",
    "text": "74.7 Riflessioni Conclusive\nL‚Äôampio utilizzo dei test statistici frequentisti in psicologia risulta spesso fuorviante, poich√© attribuisce un‚Äôapparenza di rigore scientifico a inferenze che, in realt√†, sono principalmente qualitative. Si rende quindi necessaria una profonda riforma delle pratiche di ricerca, volta a promuovere una maggiore trasparenza e precisione, oltre a incoraggiare la disponibilit√† a mettere in discussione e abbandonare approcci metodologici che non superano una rigorosa analisi critica (Yarkoni, 2022).\nLa crisi di replicabilit√† ha spinto verso una serie di riforme con il potenziale di trasformare positivamente la ricerca psicologica. Tra queste iniziative vi sono la promozione della scienza aperta, l‚Äôadozione di standard metodologici pi√π rigorosi e una maggiore attenzione a pratiche di ricerca che privilegiano la qualit√† e la replicabilit√† dei risultati rispetto alla loro quantit√† e novit√†. Sebbene questi cambiamenti possano sembrare meno spettacolari rispetto ai metodi attualmente utilizzati, essi rappresentano un percorso fondamentale per garantire la credibilit√† e la sostenibilit√† a lungo termine della disciplina.\nAffinch√© queste riforme abbiano un impatto duraturo, √® essenziale un cambiamento strutturale a tutti i livelli della comunit√† scientifica:\n\nI ricercatori devono impegnarsi ad adottare pratiche pi√π rigorose e trasparenti, privilegiando la solidit√† metodologica e la replicabilit√† dei loro studi.\nGli enti finanziatori devono incentivare la qualit√† e la replicabilit√† degli studi, piuttosto che premiare esclusivamente la produzione di risultati innovativi o appariscenti.\nLe istituzioni accademiche devono rivedere i criteri di valutazione del merito scientifico, dando maggior peso all‚Äôimpatto a lungo termine delle ricerche e alla loro solidit√† metodologica.\nLe riviste scientifiche devono assicurarsi che i risultati pubblicati siano realmente robusti e generalizzabili, anzich√© limitarsi a privilegiare i risultati nuovi o sorprendenti.\n\nQuesti cambiamenti, sebbene complessi e talvolta impopolari, sono fondamentali per ristabilire la fiducia nel processo scientifico e per garantire che la ricerca psicologica continui a offrire contributi utili e affidabili nella comprensione della mente umana e del comportamento.\nIn conclusione, la sfida posta dalla crisi di replicabilit√† offre un‚Äôopportunit√† unica per ridefinire e rafforzare le fondamenta metodologiche della ricerca psicologica. Abbracciando questi cambiamenti, la psicologia pu√≤ emergere come una disciplina pi√π robusta, trasparente e affidabile, capace di fornire intuizioni utili e durature sul funzionamento della mente e del comportamento umano.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>74</span>¬† <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#bibliografia",
    "href": "chapters/replication_crisis/06_changes.html#bibliografia",
    "title": "74¬† Riforma",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nKorbmacher, M., Azevedo, F., Pennington, C. R., Hartmann, H., Pownall, M., Schmidt, K., Elsherif, M., Breznau, N., Robertson, O., Kalandadze, T., et al. (2023). The replication crisis has led to positive structural, procedural, and community changes. Communications Psychology, 1(1), 3.\n\n\nMuthukrishna, M., & Henrich, J. (2019). A problem in theory. Nature Human Behaviour, 3(3), 221‚Äì229.\n\n\nScheel, A. M., Schijen, M. R., & Lakens, D. (2021). An excess of positive results: Comparing the standard psychology literature with registered reports. Advances in Methods and Practices in Psychological Science, 4(2), 25152459211007467.\n\n\nYarkoni, T. (2022). The generalizability crisis. Behavioral and Brain Sciences, 45, e1.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>74</span>¬† <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/07_piranha.html",
    "href": "chapters/replication_crisis/07_piranha.html",
    "title": "75¬† Il Problema del priming: sfide e paradossi nella psicologia sociale",
    "section": "",
    "text": "75.1 Introduzione\nUn recente articolo di Tosh et al. (2025) affronta una questione centrale per la psicologia e la crisi della replicabilit√†: il cosiddetto ‚Äúproblema del piranha.‚Äù L‚Äôargomento riguarda la convinzione, diffusa in molti studi psicologici, che piccoli interventi (o ‚Äúnudges‚Äù), apparentemente insignificanti, possano generare effetti notevoli sul comportamento. L‚Äôarticolo dimostra formalmente, con il supporto del teorema di Van der Corput (Tao, 2014), che se tali effetti fossero davvero cos√¨ grandi e consistenti, allora sarebbe possibile manipolare il comportamento umano in modi empiricamente irrealistici.\nIn altre parole, la letteratura psicologica spesso riporta effetti di dimensioni tali che richiederebbero assunzioni incompatibili con le evidenze empiriche. Questi risultati suggeriscono che le affermazioni di grandi effetti indipendenti sono pi√π probabilmente attribuibili a problemi metodologici, come bassa potenza statistica o ‚Äúgradi di libert√† del ricercatore‚Äù (Simmons et al., 2011).",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>75</span>¬† <span class='chapter-title'>Il Problema del priming: sfide e paradossi nella psicologia sociale</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/07_piranha.html#il-problema-del-piranha",
    "href": "chapters/replication_crisis/07_piranha.html#il-problema-del-piranha",
    "title": "75¬† Il Problema del priming: sfide e paradossi nella psicologia sociale",
    "section": "75.2 Il problema del piranha",
    "text": "75.2 Il problema del piranha\nTosh et al. (2025) evidenziano che, in un sistema complesso, se molte variabili esplicative hanno un forte impatto su una singola variabile di esito, queste devono inevitabilmente mostrare interazioni o correlazioni rilevanti tra loro.\n\n75.2.1 Punti chiave del problema\n\nEffetti ampi e interazioni: Il ‚Äúproblema del piranha‚Äù sottolinea che √® improbabile che molte variabili esplicative abbiano effetti ampi e indipendenti su una singola variabile di esito all‚Äôinterno di un sistema stabile. Questo principio si basa sulla disuguaglianza di Van der Corput, che dimostra come l‚Äôaumento del numero di variabili con grandi effetti richieda una considerazione delle loro interazioni. Tali interazioni generano una rete complessa di influenze, rendendo difficile isolare l‚Äôimpatto di un singolo fattore. Gli effetti osservati in un dato studio potrebbero non essere generalizzabili, poich√© dipendono dai livelli di altre variabili presenti nello stesso contesto.\nAnalogia con i piranha: L‚Äôanalogia del piranha descrive un sistema sovraffollato di variabili esplicative con grandi effetti, che interagiscono tra loro fino a ridurre la stabilit√† complessiva. Proprio come i piranha in un acquario competono tra loro fino a ridurre il loro numero, un sistema con molte variabili di forte impatto tende a generare interazioni che limitano la prevedibilit√† e la stabilit√† del sistema. In altre parole, gli effetti individuali vengono alterati, ridotti o cancellati attraverso la competizione tra variabili.\n\n\n\n75.2.2 Rilevanza per la crisi di replicabilit√†\nIl problema del piranha offre una prospettiva cruciale per comprendere le cause della crisi di replicabilit√† nelle scienze sociali e biologiche. Secondo Tosh et al. (2025), questa crisi non √® attribuibile soltanto a problemi metodologici come la bassa potenza statistica, ma riflette un limite intrinseco dell‚Äôidea stessa che numerosi grandi effetti indipendenti possano coesistere in un sistema complesso.\nI teoremi discussi nell‚Äôarticolo dimostrano che un sistema stabile non pu√≤ contenere numerosi effetti forti e indipendenti senza generare predizioni empiricamente insostenibili. Ci√≤ implica che la ricerca di molteplici ‚Äúgrandi effetti‚Äù rischia di essere basata su assunzioni irrealistiche riguardo alla natura delle interazioni tra variabili.\nIl problema del piranha √® particolarmente rilevante per la psicologia, dove spesso si cercano numerose cause indipendenti per spiegare fenomeni complessi. Tosh et al. (2025) mettono in discussione non tanto i singoli effetti riportati, quanto l‚Äôassunzione di base secondo cui il comportamento umano e le interazioni sociali sarebbero influenzati da un gran numero di effetti indipendenti.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>75</span>¬† <span class='chapter-title'>Il Problema del priming: sfide e paradossi nella psicologia sociale</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/07_piranha.html#il-priming-nella-psicologia-sociale",
    "href": "chapters/replication_crisis/07_piranha.html#il-priming-nella-psicologia-sociale",
    "title": "75¬† Il Problema del priming: sfide e paradossi nella psicologia sociale",
    "section": "75.3 Il priming nella psicologia sociale",
    "text": "75.3 Il priming nella psicologia sociale\nUno degli esempi analizzati da Tosh et al. (2025) riguarda la ricerca sul priming sociale, una linea di indagine ampiamente discussa e criticata nella psicologia sociale. Gli autori utilizzano uno studio classico per illustrare le loro argomentazioni: un esperimento del 1996 condotto da Bargh et al. (1996), in cui i partecipanti riorganizzavano frasi contenenti parole associate alla vecchiaia (ad esempio, ‚ÄúFlorida‚Äù o ‚Äúsolo‚Äù). I risultati riportavano che questi partecipanti camminavano pi√π lentamente rispetto a un gruppo di controllo, con una riduzione del 13% nella velocit√† di camminata (Bargh et al., 1996).\nL‚Äôidea che una manipolazione cos√¨ semplice possa produrre un effetto tanto marcato √® stata successivamente oggetto di numerose critiche. I tentativi di replicare lo studio non hanno avuto successo, e il lavoro di Bargh et al. (1996) √® ora considerato un esempio emblematico di risultati impossibili da replicare. Questo studio rappresenta solo uno dei molti casi in cui sono stati riportati effetti sorprendentemente grandi per manipolazioni apparentemente insignificanti.\nTosh et al. (2025) sostengono che, se davvero piccoli interventi (nudges) producono effetti cos√¨ rilevanti, emergerebbe inevitabilmente il problema delle interazioni con numerosi altri fattori gi√† noti per influire sul comportamento umano. La letteratura psicologica include infatti studi che attribuiscono grandi effetti a fattori come ormoni, immagini subliminali, notizie di partite di calcio o attacchi di squali, incontri casuali con sconosciuti, stato socioeconomico dei genitori, condizioni meteorologiche, l‚Äôultima cifra dell‚Äôet√†, il genere del nome di un uragano, e molti altri. Secondo gli autori, se tutti questi fattori influenzassero realmente un singolo esito, le loro interazioni diventerebbero incredibilmente complesse e imprevedibili, rendendo impossibile individuare effetti stabili e replicabili.\nPer illustrare l‚Äôassurdit√† di alcuni di questi risultati, Tosh et al. (2025) propongono un esempio ipotetico. Supponiamo che 100 nudges producano ciascuno un effetto del 13% sulla velocit√† di camminata, come riportato da Bargh et al. (1996) Se questi effetti fossero indipendenti, l‚Äôeffetto combinato sarebbe enorme: la velocit√† di camminata potrebbe facilmente raddoppiare, dimezzarsi o variare ancora di pi√π. Tuttavia, tali variazioni sono empiricamente irrealistiche. In altre parole, le assunzioni su cui si basano molte di queste ricerche porterebbero a predizioni che non trovano riscontro nei dati osservabili.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>75</span>¬† <span class='chapter-title'>Il Problema del priming: sfide e paradossi nella psicologia sociale</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/07_piranha.html#conclusione",
    "href": "chapters/replication_crisis/07_piranha.html#conclusione",
    "title": "75¬† Il Problema del priming: sfide e paradossi nella psicologia sociale",
    "section": "75.4 Conclusione",
    "text": "75.4 Conclusione\nIl ‚Äúproblema del piranha‚Äù evidenzia i limiti intrinseci nell‚Äôassumere che numerosi effetti indipendenti e di grande entit√† possano coesistere all‚Äôinterno di un sistema complesso. In realt√†, tali effetti devono necessariamente interagire tra loro o essere correlati, rendendo improbabile la loro indipendenza. Questa dinamica crea instabilit√† nel sistema e porta a variazioni degli effetti nel tempo o tra popolazioni, compromettendo la possibilit√† di generalizzarne i risultati.\nTosh et al. (2025) suggeriscono che molti risultati pubblicati, che riportano effetti improbabilmente grandi, siano attribuibili non tanto a reali fenomeni psicologici, quanto a problemi metodologici, come bassa potenza statistica e i ‚Äúgradi di libert√† del ricercatore‚Äù (Simmons et al., 2011). La proliferazione di questi risultati contribuisce alla crisi di replicabilit√†, poich√© i presunti effetti si rivelano spesso instabili o non replicabili.\nLa consapevolezza dei limiti imposti dal problema del piranha invita la ricerca psicologica a focalizzarsi maggiormente sulla robustezza metodologica, sull‚Äôidentificazione di effetti plausibili e sulla considerazione delle interazioni tra variabili. Piuttosto che cercare di identificare molteplici grandi effetti, √® essenziale riconoscere che un sistema complesso, per essere stabile e prevedibile, richiede un approccio che consideri l‚Äôinterdipendenza delle variabili e la struttura complessiva del sistema. Questo approccio pu√≤ contribuire a migliorare la validit√† e la replicabilit√† della ricerca nelle scienze sociali.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>75</span>¬† <span class='chapter-title'>Il Problema del priming: sfide e paradossi nella psicologia sociale</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/07_piranha.html#bibliografia",
    "href": "chapters/replication_crisis/07_piranha.html#bibliografia",
    "title": "75¬† Il Problema del priming: sfide e paradossi nella psicologia sociale",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBargh, J. A., Chen, M., & Burrows, L. (1996). Automaticity of social behavior: Direct effects of trait construct and stereotype activation on action. Journal of Personality and Social Psychology, 71(2), 230‚Äì244.\n\n\nSimmons, J. P., Nelson, L. D., & Simonsohn, U. (2011). False-positive psychology: Undisclosed flexibility in data collection and analysis allows presenting anything as significant. Psychological science, 22(11), 1359‚Äì1366.\n\n\nTosh, C., Greengard, P., Goodrich, B., Gelman, A., Vehtari, A., & Hsu, D. (2025). The Piranha Problem: Large Effects Swimming in a Small Pond. Notices of the American Mathematical Society.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>75</span>¬† <span class='chapter-title'>Il Problema del priming: sfide e paradossi nella psicologia sociale</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/08_integrity.html",
    "href": "chapters/replication_crisis/08_integrity.html",
    "title": "76¬† Integrit√† della ricerca",
    "section": "",
    "text": "76.1 Introduzione\nL‚Äôintegrit√† della ricerca si basa su principi e standard professionali che mirano a garantire l‚Äôaffidabilit√† e la qualit√† della ricerca, distinguendosi dall‚Äôetica della ricerca, che si focalizza su principi morali. La condivisione dei dati, il consenso informato, e la trasparenza nelle pratiche di ricerca sono elementi chiave. I codici di condotta sono essenziali per orientare i comportamenti etici, tanto dei ricercatori quanto delle istituzioni. Le pratiche di ricerca discutibili, la fabbricazione e falsificazione dei dati, il plagio, e la gestione dei conflitti di interesse sono sfide da affrontare per mantenere l‚Äôintegrit√† della ricerca. √à fondamentale promuovere una cultura di ricerca che privilegi l‚Äôonest√†, la trasparenza e il rispetto dei principi etici.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>76</span>¬† <span class='chapter-title'>Integrit√† della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/08_integrity.html#standard-professionali-nei-codici-di-condotta-per-lintegrit√†-della-ricerca",
    "href": "chapters/replication_crisis/08_integrity.html#standard-professionali-nei-codici-di-condotta-per-lintegrit√†-della-ricerca",
    "title": "76¬† Integrit√† della ricerca",
    "section": "76.2 Standard Professionali nei Codici di Condotta per l‚ÄôIntegrit√† della Ricerca",
    "text": "76.2 Standard Professionali nei Codici di Condotta per l‚ÄôIntegrit√† della Ricerca\nNel campo della ricerca, √® essenziale aderire a principi di condotta responsabile. Questi principi, comunemente definiti come buone pratiche di ricerca, stabiliscono gli standard professionali che mirano a ottimizzare qualit√† e affidabilit√† degli studi condotti. Se √® vero che le idee di base su cosa costituisca una buona pratica di ricerca rimangono relativamente stabili nel tempo, la loro applicazione pratica si evolve in risposta ai cambiamenti sociali, politici e tecnologici. Un esempio lampante di questo adattamento √® la crescente enfasi sulla condivisione dei dati di ricerca, facilitata oggi dall‚Äôesistenza di repository online gratuiti, che ha portato a un‚Äôaspettativa diffusa di massima trasparenza e accessibilit√† dei dati raccolti. Molto incoraggiata √® anche la ‚Äúbuona pratica‚Äù corrispondente alla condivisione del codice utilizzato dai ricercatori per analizzare i dati raccolti.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>76</span>¬† <span class='chapter-title'>Integrit√† della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/08_integrity.html#differenziazione-tra-integrit√†-e-etica-della-ricerca",
    "href": "chapters/replication_crisis/08_integrity.html#differenziazione-tra-integrit√†-e-etica-della-ricerca",
    "title": "76¬† Integrit√† della ricerca",
    "section": "76.3 Differenziazione tra Integrit√† e Etica della Ricerca",
    "text": "76.3 Differenziazione tra Integrit√† e Etica della Ricerca\nL‚Äôintegrit√† della ricerca si fonda su standard professionali e si distingue nettamente dall‚Äôetica della ricerca, che si basa su principi morali quali l‚Äôautonomia, la beneficenza, la non-maleficenza e la giustizia. Questi ultimi si traducono in pratiche specifiche, come il consenso informato e la garanzia di verit√† e confidenzialit√† nei confronti dei partecipanti. L‚Äôadozione di tali principi etici implica l‚Äôobbligo per i ricercatori di evitare studi che possano arrecare danno o risultare eccessivamente onerosi per i soggetti coinvolti.\nI codici di condotta per l‚Äôintegrit√† della ricerca variano leggermente tra le diverse fonti. Ad esempio, Il codice di condotta europeo per l‚ÄôintegritaÃÄ della ricerca enfatizza l‚Äôimportanza di principi come l‚Äôonest√†, la trasparenza, l‚Äôaccuratezza, la responsabilit√†, l‚Äôaffidabilit√†, il rispetto e l‚Äôindipendenza. Questi principi sono interpretati in termini di comportamenti specifici attesi sia dai ricercatori sia dalle istituzioni di ricerca, come la condivisione dei dati di ricerca nel rispetto delle normative sulla protezione dei dati, come il GDPR europeo.\nUn esempio pratico della variazione degli standard nei codici di condotta √® rappresentato dall‚Äôevoluzione della condivisione dei dati di ricerca. In precedenza, la condivisione dei dati poteva essere limitata dalla mancanza di infrastrutture adeguate. Oggi, l‚Äôaccesso facilitato attraverso i repository online e la pressione esercitata dalle riviste scientifiche e dai finanziatori della ricerca hanno reso la condivisione dei dati una pratica standard, riflettendo un cambiamento verso una maggiore apertura e trasparenza nella ricerca.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>76</span>¬† <span class='chapter-title'>Integrit√† della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/08_integrity.html#pressioni-e-sfide-nelladesione-ai-codici-di-condotta",
    "href": "chapters/replication_crisis/08_integrity.html#pressioni-e-sfide-nelladesione-ai-codici-di-condotta",
    "title": "76¬† Integrit√† della ricerca",
    "section": "76.4 Pressioni e Sfide nell‚ÄôAdesione ai Codici di Condotta",
    "text": "76.4 Pressioni e Sfide nell‚ÄôAdesione ai Codici di Condotta\nNonostante l‚Äôesistenza di questi codici, i ricercatori, specialmente quelli in fase iniziale della loro carriera, possono trovarsi sotto pressione da parte dei supervisori per adottare comportamenti che si discostano dagli standard stabiliti, spesso a causa della competitivit√† nel campo scientifico e del sistema di valutazione basato sul numero di pubblicazioni. Queste dinamiche possono indurre a pratiche di ricerca discutibili (PRD), che includono la pubblicazione selettiva dei risultati e l‚Äôuso di analisi dei dati flessibili per aumentare artificialmente la probabilit√† di ottenere risultati statisticamente significativi.\nPer mantenere l‚Äôintegrit√† della ricerca, √® fondamentale creare un ambiente di lavoro che valorizzi l‚Äôapertura, l‚Äôinclusivit√† e la discussione franca delle pressioni e delle sfide etiche. Questo implica non solo l‚Äôadesione ai codici di condotta esistenti ma anche l‚Äôimpegno attivo delle istituzioni di ricerca nel promuovere la formazione etica e l‚Äôintegrit√† tra i ricercatori. Attraverso un tale approccio, la comunit√† scientifica pu√≤ aspirare a una ricerca di alta qualit√† che sia sia eticamente responsabile sia metodologicamente solida.\n√à degno di nota che Nature, una delle riviste scientifiche pi√π prestigiose al mondo, abbia recentemente promosso il gioco da tavolo Publish or Perish. La descrizione del gioco √® particolarmente provocatoria:\n\n‚ÄúFalsificare dati, screditare altri scienziati, pubblicare una montagna di articoli che ricevono una torre di citazioni: i cinici potrebbero descrivere questi come passi necessari per raggiungere il successo accademico.‚Äù\n\nQuesta mossa solleva importanti questioni sullo stato attuale della ricerca scientifica. Non solo il mondo accademico sembra fornire inventivi distorti, ma anche il sistema economico delle riviste scientifiche presenta una componente di monetizzazione che appare in conflitto con gli obiettivi fondamentali della ricerca scientifica. Questo porta all‚Äôaccettazione di pratiche disoneste, perch√© funzionali allo status quo.\nIn questo panorama complesso, emergono voci di dissenso che auspicano e si impegnano per una riforma del mondo pragmatico della scienza (McElreath, 2020; Smaldino & McElreath, 2016). Questa situazione invita a una riflessione profonda sulla necessit√† di bilanciare la produttivit√† accademica con l‚Äôetica e la qualit√† della ricerca, nonch√© sul ruolo delle riviste scientifiche nel plasmare il panorama della ricerca contemporanea.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>76</span>¬† <span class='chapter-title'>Integrit√† della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/08_integrity.html#bibliografia",
    "href": "chapters/replication_crisis/08_integrity.html#bibliografia",
    "title": "76¬† Integrit√† della ricerca",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nSmaldino, P. E., & McElreath, R. (2016). The natural selection of bad science. Royal Society open science, 3(9), 160384.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>76</span>¬† <span class='chapter-title'>Integrit√† della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/epiloque/epiloque.html",
    "href": "chapters/epiloque/epiloque.html",
    "title": "Considerazioni Conclusive",
    "section": "",
    "text": "Limiti dell‚ÄôInferenza Frequentista\nL‚Äôinferenza bayesiana offre un modo rigoroso e trasparente per integrare conoscenze pregresse e dati empirici nell‚Äôanalisi psicologica. A differenza degli approcci frequentisti, l‚Äôapproccio bayesiano ci permette di quantificare l‚Äôincertezza e di costruire modelli che riflettono le nostre aspettative a priori. Questa flessibilit√† √® particolarmente utile in psicologia, dove le teorie e le ipotesi giocano un ruolo fondamentale nella guida della ricerca. L‚Äôapproccio bayesiano rende esplicita la nostra assunzione iniziale e ci permette di valutare l‚Äôimpatto dei dati sulla nostra comprensione dei fenomeni psicologici.\nNel corso di questa trattazione, abbiamo esaminato i limiti dell‚Äôinferenza frequentista, in particolare quando viene impiegata come ‚Äúfiltro‚Äù per distinguere i risultati scientifici rilevanti da quelli trascurabili. L‚Äôeccessiva dipendenza dai valori-p √® stata oggetto di critiche per la sua associazione con inferenze inadeguate; gli effetti possono essere notevolmente sovrastimati, talvolta persino nella direzione errata, quando la stima √® vincolata alla significativit√† statistica in presenza di dati altamente variabili (Loken & Gelman, 2017).\nLa persistenza e la resistenza del valore-p come indicatore di significativit√† sono sorprendenti, nonostante le critiche di lunga data e i dibattiti sul suo uso improprio e sulla sua errata interpretazione (Gardner e Altman, 1986; Cohen, 1994; Anderson et al., 2000; Fidler et al., 2004; Finch et al., 2004). Il continuo uso di questa tenacia pu√≤ offrire spunti su come tali indici, insieme alle euristiche utilizzate per interpretarli (ad esempio, l‚Äôassegnazione di soglie come 0.05, 0.01 e 0.001 per determinati livelli di significativit√†), siano adottati dai ricercatori per ottenere una comprensione intuitiva, sebbene eccessivamente semplificata, della struttura dei loro dati. Inoltre, l‚Äôuso di un simile indice risulta particolarmente rilevante in contesti che richiedono decisioni e relative giustificazioni (ad esempio, in ambito medico).\nPurtroppo, queste euristiche sono diventate estremamente rigide, e il raggiungimento della significativit√† si √® trasformato in un obiettivo fine a se stesso, piuttosto che in uno strumento per comprendere i dati (Cohen, 1994; Kirk, 1996). Ci√≤ √® particolarmente problematico considerando che i valori-p possono essere utilizzati solo per rifiutare l‚Äôipotesi nulla e non per accettarla come vera, poich√© un risultato statisticamente non significativo non implica l‚Äôassenza di differenze tra gruppi o l‚Äôassenza di un effetto di un trattamento (Wagenmakers, 2007; Amrhein et al., 2019).\nI fraintendimenti e l‚Äôuso improprio dei valori-p, il cosiddetto ‚Äúp-hacking‚Äù (Simmons et al., 2011), hanno incentivato pratiche scientifiche discutibili, contribuendo in modo rilevante alla crisi di riproducibilit√† nella scienza psicologica (Chambers et al., 2014; Szucs e Ioannidis, 2016).",
    "crumbs": [
      "Epilogo",
      "Considerazioni Conclusive"
    ]
  },
  {
    "objectID": "chapters/epiloque/epiloque.html#la-crisi-della-replicabilit√†",
    "href": "chapters/epiloque/epiloque.html#la-crisi-della-replicabilit√†",
    "title": "Considerazioni Conclusive",
    "section": "La Crisi della Replicabilit√†",
    "text": "La Crisi della Replicabilit√†\nLa crisi della replicabilit√† rappresenta una sfida non solo per la ricerca psicologica, ma anche per l‚Äôapplicazione pratica delle sue teorie. Quando i risultati degli studi non possono essere replicati in contesti diversi, si mette in dubbio la validit√† e l‚Äôaffidabilit√† delle teorie psicologiche su cui si basano gli interventi clinici e le politiche pubbliche. Questo non solo mina la fiducia nella scienza psicologica, ma limita anche la capacit√† dei professionisti di sviluppare trattamenti efficaci e basati sull‚Äôevidenza. Pertanto, √® fondamentale che la comunit√† scientifica adotti pratiche di ricerca rigorose e trasparenti per garantire che le scoperte siano replicabili e applicabili nel mondo reale.",
    "crumbs": [
      "Epilogo",
      "Considerazioni Conclusive"
    ]
  },
  {
    "objectID": "chapters/epiloque/epiloque.html#come-uscirne",
    "href": "chapters/epiloque/epiloque.html#come-uscirne",
    "title": "Considerazioni Conclusive",
    "section": "Come uscirne?",
    "text": "Come uscirne?\nL‚Äôabbandono dell‚Äôinferenza frequentista a favore dei metodi bayesiani, per ragioni quali la maggiore flessibilit√†, una migliore accuratezza in presenza di dati rumorosi e campioni piccoli, una minore predisposizione agli errori di tipo I, la possibilit√† di incorporare conoscenze pregresse nell‚Äôanalisi e la chiarezza e facilit√† di interpretazione dei risultati (Kruschke, 2010; Kruschke et al., 2012; Etz e Vandekerckhove, 2016; Wagenmakers et al., 2016, 2018; Dienes e Mclatchie, 2018), √® una delle strategie proposte per affrontare la crisi della replicabilit√† nella ricerca psicologica. Tuttavia, sebbene questo cambiamento sia rilevante, non √® sufficiente da solo. I problemi pi√π profondi derivano anche da un sistema accademico caratterizzato da incentivi distorti, come la pressione a pubblicare risultati significativi, e dalla riluttanza delle riviste scientifiche a riconoscere e affrontare casi di frode o a ritirare articoli quando necessario.\nUna proposta su cui insiste molto McElreath (2020) √® quella di passare da un approccio descrittivo della relazione tra variabili ‚Äî tipico dei modelli lineari e dei modelli lineari generalizzati ‚Äî a una prospettiva che miri a descrivere formalmente il meccanismo generatore dei dati sottostante al fenomeno in esame. In questo contesto, il ricercatore dovrebbe formulare ipotesi esplicite sul processo che genera i dati e fornire un test quantitativo di tali ipotesi. Questo approccio porta naturalmente alla pratica del confronto tra modelli, un metodo che abbiamo discusso in diversi capitoli di questo testo. Tale confronto pu√≤ essere effettuato utilizzando tecniche come la validazione incrociata bayesiana Leave-One-Out (LOO), che permette di valutare la robustezza dei modelli e la loro capacit√† di generalizzare a nuovi dati. Ma si tengano anche a mente i limiti di tale approccio (Navarro, 2019).\nUn altro approccio attuale per superare la cosiddetta ‚Äújunk science‚Äù (Calin-Jageman & Caldwell, 2014; Gelman & Weakliem, 2009; Jung et al., 2014), che troppo spesso affligge la psicologia e non solo, √® la ‚Äúrivoluzione causale‚Äù. Questo movimento si concentra sul tentativo di comprendere e identificare le relazioni causali in contesti naturali, superando l‚Äôarbitrariet√† e l‚Äôartificialit√† degli esperimenti di laboratorio tradizionali. La ‚Äúrivoluzione causale‚Äù ha molto in comune con l‚Äôapproccio di McElreath (2020), poich√© anche qui si richiede ai ricercatori di formulare ipotesi causali in maniera esplicita e di confrontare modelli alternativi che rappresentano diverse ipotesi sui rapporti causali. Questo approccio non solo migliora la comprensione dei fenomeni studiati, ma aumenta anche la credibilit√† e la replicabilit√† dei risultati scientifici.\nQuesti cambiamenti prevedono anche una profonda revisione dei metodi didattici e dei programmi dei corsi, in cui si insegna agli studenti come formulare inferenze basate sui dati empirici raccolti in psicologia. Questo tema √® stato approfondito da studiosi come Mine Dogucu [Johnson et al. (2022); dogucu2022current; rosenberg2022making; dogucu2021web]. Come dovrebbe ormai essere evidente al lettore, il presente testo ha accettato questa sfida.",
    "crumbs": [
      "Epilogo",
      "Considerazioni Conclusive"
    ]
  },
  {
    "objectID": "chapters/epiloque/epiloque.html#conclusioni",
    "href": "chapters/epiloque/epiloque.html#conclusioni",
    "title": "Considerazioni Conclusive",
    "section": "Conclusioni",
    "text": "Conclusioni\nL‚Äôapproccio bayesiano rappresenta una risorsa fondamentale per l‚Äôanalisi dei dati psicologici, offrendo strumenti avanzati per gestire l‚Äôincertezza, integrare conoscenze pregresse e adattarsi a modelli complessi. La sua capacit√† di fornire previsioni robuste e aggiornare continuamente le ipotesi alla luce di nuovi dati lo rende particolarmente adatto per esplorare e comprendere la mente umana e il comportamento in tutte le loro sfaccettature.\nTuttavia, per affrontare la crisi della replicabilit√† e migliorare la qualit√† della ricerca scientifica in psicologia, non √® sufficiente adottare esclusivamente metodi bayesiani. √à essenziale combinare questi metodi con altre pratiche rigorose e principi metodologici solidi. Tra queste pratiche, la formalizzazione dei modelli generativi consente di descrivere chiaramente i processi sottostanti che generano i dati, migliorando la trasparenza e la validit√† delle inferenze. Inoltre, il confronto rigoroso tra modelli, ad esempio tramite tecniche di validazione incrociata, aiuta a determinare quale modello meglio rappresenta i dati e a evitare interpretazioni errate.\nInfine, l‚Äôadozione di una prospettiva causale esplicita √® cruciale per identificare correttamente le relazioni di causa-effetto, evitando l‚Äôarbitrariet√† e l‚Äôartificialit√† degli esperimenti tradizionali. Solo attraverso un approccio integrato, che combini l‚Äôinferenza bayesiana con queste pratiche metodologiche avanzate, sar√† possibile progredire verso una scienza psicologica pi√π affidabile e riproducibile, capace di fornire una comprensione pi√π profonda e accurata del comportamento umano.",
    "crumbs": [
      "Epilogo",
      "Considerazioni Conclusive"
    ]
  },
  {
    "objectID": "chapters/epiloque/epiloque.html#bibliografia",
    "href": "chapters/epiloque/epiloque.html#bibliografia",
    "title": "Considerazioni Conclusive",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nCalin-Jageman, R. J., & Caldwell, T. L. (2014). Replication of the superstition and performance study by Damisch, Stoberock, and Mussweiler (2010). Social Psychology.\n\n\nGelman, A., & Weakliem, D. (2009). Of beauty, sex and power: Too little attention has been paid to the statistical challenges in estimating small effects. American Scientist, 97(4), 310‚Äì316.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nJung, K., Shavitt, S., Viswanathan, M., & Hilbe, J. M. (2014). Female hurricanes are deadlier than male hurricanes. Proceedings of the National Academy of Sciences, 111(24), 8782‚Äì8787.\n\n\nLoken, E., & Gelman, A. (2017). Measurement Error and the Replication Crisis. Science, 355(6325), 584‚Äì585.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nNavarro, D. J. (2019). Between the devil and the deep blue sea: Tensions between scientific judgement and statistical model selection. Computational Brain & Behavior, 2(1), 28‚Äì34.",
    "crumbs": [
      "Epilogo",
      "Considerazioni Conclusive"
    ]
  },
  {
    "objectID": "chapters/appendix/a02_shell.html",
    "href": "chapters/appendix/a02_shell.html",
    "title": "77¬† La Shell",
    "section": "",
    "text": "77.1 Che cos‚Äô√® una Shell?\nUna shell √® un programma che riceve comandi dall‚Äôutente tramite tastiera (o da file) e li passa al sistema operativo per l‚Äôesecuzione. Pu√≤ essere accessibile tramite un terminale (o un emulatore di terminale).",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>77</span>¬† <span class='chapter-title'>La Shell</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a02_shell.html#che-cos√®-una-shell",
    "href": "chapters/appendix/a02_shell.html#che-cos√®-una-shell",
    "title": "77¬† La Shell",
    "section": "",
    "text": "77.1.1 Breve Storia della Shell\n\n1971: Ken Thompson di Bell Labs sviluppa la shell per UNIX.\n1977: Stephen Bourne introduce la Bourne shell (sh).\nDopo il 1977: Viene sviluppata la C shell (csh) e tcsh.\nBash: Sviluppata da Brian Fox come sostituto migliorato della Bourne shell.\n1990: Paul Falsted sviluppa Zsh, che diventa la shell predefinita per macOS dal 2019.\n\n\n\n77.1.2 Windows vs macOS/Linux\n\nWindows 10: √à possibile utilizzare Bash attivando il Windows Subsystem for Linux. Tuttavia, l‚Äôambiente preferito √® solitamente PowerShell.\nmacOS/Linux: Zsh √® la shell predefinita in entrambi i sistemi. √à consigliabile sfruttare l‚Äôapplicazione warp per un‚Äôesperienza utente moderna e ottimizzata.\n\n\n\n77.1.3 Comandi di Base Unix\n\npwd: Mostra il percorso della directory corrente.\nls: Elenca file e cartelle nella directory corrente.\ncd: Cambia directory. Senza argomenti, ti porta alla directory home.\nmkdir: Crea una nuova directory.\nrmdir: Rimuove una directory vuota.\nImportante: Evitare spazi nei nomi di file e cartelle.\n\n\n77.1.3.1 Gestione File\n\nmv: Rinomina o sposta file (usa \\ o '' per i nomi di file con spazi).\ncp: Copia file o cartelle (usa -r per le cartelle).\nrm: Rimuove file o cartelle (usa -i per confermare prima di eliminare).\n\n\n\n77.1.3.2 Visualizzazione e Manipolazione Contenuti dei File\n\nless / more: Visualizza il contenuto dei file con possibilit√† di navigazione.\ncat: Mostra l‚Äôintero contenuto di un file.\nhead: Mostra le prime righe di un file.\ntail: Mostra le ultime righe di un file.\n\n\n\n\n77.1.4 Comandi di Base PowerShell\nPer adattare i comandi Unix per l‚Äôutilizzo in PowerShell di Windows, molti dei comandi rimangono simili grazie alla natura cross-platform di PowerShell e alla sua flessibilit√† nel gestire sia gli stili di comando Unix che quelli tradizionali di Windows. Ecco come si traducono i comandi:\n\nGet-Location o semplicemente pwd: Mostra il percorso della directory corrente, simile a pwd in Unix.\nGet-ChildItem o semplicemente ls: Elenca file e cartelle nella directory corrente, equivalente a ls in Unix.\nSet-Location o semplicemente cd: Cambia directory. cd senza argomenti ti porta alla directory home in PowerShell con cd ~.\nNew-Item -ItemType Directory -Name 'nomeDirectory': Crea una nuova directory, simile a mkdir in Unix.\nRemove-Item -Path 'nomeDirectory' -Force: Rimuove una directory, anche se non vuota. Equivalente a rmdir in Unix, ma pi√π potente perch√© pu√≤ rimuovere anche directory con contenuti utilizzando il parametro -Force.\n\n\n77.1.4.1 Gestione File\n\nMove-Item -Path 'origine' -Destination 'destinazione': Rinomina o sposta file, equivalente a mv in Unix.\nCopy-Item -Path 'origine' -Destination 'destinazione': Copia file o cartelle, simile a cp in Unix. Usa -Recurse per copiare cartelle.\nRemove-Item -Path 'file' -Force: Rimuove file o cartelle, simile a rm in Unix. Usa -Force per rimuovere senza conferme e -Recurse per rimuovere cartelle con contenuti.\n\n\n\n77.1.4.2 Visualizzazione e Manipolazione Contenuti dei File\n\nGet-Content 'file' | More: Visualizza il contenuto dei file con possibilit√† di navigazione, simile a less/more in Unix.\nGet-Content 'file': Mostra l‚Äôintero contenuto di un file, equivalente a cat in Unix.\nGet-Content 'file' -Head &lt;numero&gt;: Mostra le prime righe di un file, simile a head in Unix.\nGet-Content 'file' -Tail &lt;numero&gt;: Mostra le ultime righe di un file, equivalente a tail in Unix.\n\n\n\n\n\n\n\n√à cruciale familiarizzarsi con l‚Äôutilizzo dei percorsi relativi per semplificare gli spostamenti tra le diverse directory. L‚Äôimpiego dei percorsi relativi rende il processo di navigazione pi√π intuitivo e meno incline agli errori.\n\nNomi Chiari e Concisi: Evitate di includere spazi nei nomi dei file e delle cartelle. Preferite l‚Äôutilizzo di trattini bassi (_) per separare le parole e mantenere una struttura leggibile e facilmente comprensibile.\nEvitare Caratteri Speciali: √à importante evitare l‚Äôinserimento di caratteri speciali come asterischi (*), dollari ($), slash (/, \\), punti (.), virgole (,), punti e virgole (;), parentesi (()), parentesi quadre ([]), parentesi graffe ({}), ampersand (&), barre verticali (|), punti esclamativi (!), punti interrogativi (?) nei nomi dei file e delle cartelle. Talvolta, anche l‚Äôuso del trattino (-) pu√≤ causare problemi; quindi √® consigliabile evitarlo. Questi caratteri possono generare problemi di compatibilit√† con alcuni sistemi operativi o applicazioni, rendendo pi√π complessa la gestione dei file.\nDifferenziazione tra Maiuscole e Minuscole: Unix distingue tra maiuscole e minuscole (tratta le lettere come oggetti distinti), mentre Windows non lo fa. Per evitare confusioni, √® consigliabile adottare una politica conservativa: considerate i nomi che differiscono solo per la case delle lettere come distinti.\n\nSeguendo questi consigli, √® possibile ottimizzare notevolmente l‚Äôorganizzazione e la gestione dei propri file, migliorando l‚Äôefficienza del lavoro e riducendo il rischio di errori.\n\n\n\nCon la pratica, la riga di comando diventa uno strumento molto efficiente. Questa breve guida fornisce le basi per iniziare a esplorare e gestire i file dal terminale, offrendo una base di partenza per ulteriori apprendimenti. La familiarit√† con la shell √® fondamentale nella data science.",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>77</span>¬† <span class='chapter-title'>La Shell</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a10_math_symbols.html",
    "href": "chapters/appendix/a10_math_symbols.html",
    "title": "78¬† Simbologia di base",
    "section": "",
    "text": "Per una scrittura pi√π sintetica possono essere utilizzati alcuni simboli matematici.\n\n\\(\\log(x)\\): il logaritmo naturale di \\(x\\).\nL‚Äôoperatore logico booleano \\(\\land\\) significa ‚Äúe‚Äù (congiunzione forte) mentre il connettivo di disgiunzione \\(\\lor\\) significa ‚Äúo‚Äù (oppure) (congiunzione debole).\nIl quantificatore esistenziale \\(\\exists\\) vuol dire ‚Äúesiste almeno un‚Äù e indica l‚Äôesistenza di almeno una istanza del concetto/oggetto indicato. Il quantificatore esistenziale di unicit√† \\(\\exists!\\) (‚Äúesiste soltanto un‚Äù) indica l‚Äôesistenza di esattamente una istanza del concetto/oggetto indicato. Il quantificatore esistenziale \\(\\nexists\\) nega l‚Äôesistenza del concetto/oggetto indicato.\nIl quantificatore universale \\(\\forall\\) vuol dire ‚Äúper ogni.‚Äù\n\\(\\mathcal{A, S}\\): insiemi.\n\\(x \\in A\\): \\(x\\) √® un elemento dell‚Äôinsieme \\(A\\).\nL‚Äôimplicazione logica ‚Äú\\(\\Rightarrow\\)‚Äù significa ‚Äúimplica‚Äù (se ‚Ä¶allora). \\(P \\Rightarrow Q\\) vuol dire che \\(P\\) √® condizione sufficiente per la verit√† di \\(Q\\) e che \\(Q\\) √® condizione necessaria per la verit√† di \\(P\\).\nL‚Äôequivalenza matematica ‚Äú\\(\\iff\\)‚Äù significa ‚Äúse e solo se‚Äù e indica una condizione necessaria e sufficiente, o corrispondenza biunivoca.\nIl simbolo \\(\\vert\\) si legge ‚Äútale che.‚Äù\nIl simbolo \\(\\triangleq\\) (o \\(:=\\)) si legge ‚Äúuguale per definizione.‚Äù\nIl simbolo \\(\\Delta\\) indica la differenza fra due valori della variabile scritta a destra del simbolo.\nIl simbolo \\(\\propto\\) si legge ‚Äúproporzionale a.‚Äù\nIl simbolo \\(\\approx\\) si legge ‚Äúcirca.‚Äù\nIl simbolo \\(\\in\\) della teoria degli insiemi vuol dire ‚Äúappartiene‚Äù e indica l‚Äôappartenenza di un elemento ad un insieme. Il simbolo \\(\\notin\\) vuol dire ‚Äúnon appartiene.‚Äù\nIl simbolo \\(\\subseteq\\) si legge ‚Äú√® un sottoinsieme di‚Äù (pu√≤ coincidere con l‚Äôinsieme stesso). Il simbolo \\(\\subset\\) si legge ‚Äú√® un sottoinsieme proprio di.‚Äù\nIl simbolo \\(\\#\\) indica la cardinalit√† di un insieme.\nIl simbolo \\(\\cap\\) indica l‚Äôintersezione di due insiemi. Il simbolo \\(\\cup\\) indica l‚Äôunione di due insiemi.\nIl simbolo \\(\\emptyset\\) indica l‚Äôinsieme vuoto o evento impossibile.\nIn matematica, \\(\\mbox{argmax}\\) identifica l‚Äôinsieme dei punti per i quali una data funzione raggiunge il suo massimo. In altre parole, \\(\\mbox{argmax}_x f(x)\\) √® l‚Äôinsieme dei valori di \\(x\\) per i quali \\(f(x)\\) raggiunge il valore pi√π alto.\n\\(a, c, \\alpha, \\gamma\\): scalari.\n\\(\\boldsymbol{x}, \\boldsymbol{y}\\): vettori.\n\\(\\boldsymbol{X}, \\boldsymbol{Y}\\): matrici.\n\\(X \\sim p\\): la variabile casuale \\(X\\) si distribuisce come \\(p\\).\n\\(p(\\cdot)\\): distribuzione di massa o di densit√† di probabilit√†.\n\\(p(y \\mid \\boldsymbol{x})\\): la probabilit√† o densit√† di \\(y\\) dato \\(\\boldsymbol{x}\\), ovvero \\(p(y = \\boldsymbol{Y} \\mid x = \\boldsymbol{X})\\).\n\\(f(x)\\): una funzione arbitraria di \\(x\\).\n\\(f(\\boldsymbol{X}; \\theta, \\gamma)\\): \\(f\\) √® una funzione di \\(\\boldsymbol{X}\\) con parametri \\(\\theta, \\gamma\\). Questa notazione indica che \\(\\boldsymbol{X}\\) sono i dati che vengono passati ad un modello di parametri \\(\\theta, \\gamma\\).\n\\(\\mathcal{N}(\\mu, \\sigma^2)\\): distribuzione gaussiana di media \\(\\mu\\) e varianza \\(sigma^2\\).\n\\(\\mbox{Beta}(\\alpha, \\beta)\\): distribuzione Beta di parametri \\(\\alpha\\) e \\(\\beta\\).\n\\(\\mathcal{U}(a, b)\\): distribuzione uniforme con limite inferiore \\(a\\) e limite superiore \\(b\\).\n\\(\\mbox{Cauchy}(\\alpha, \\beta)\\): distribuzione di Cauchy di parametri \\(\\alpha\\) (posizione: media) e \\(\\beta\\) (scala: radice quadrata della varianza).\n\\(\\mathcal{B}(p)\\): distribuzione di Bernoulli di parametro \\(p\\) (probabilit√† di successo).\n\\(\\mbox{Bin}(n, p)\\): distribuzione binomiale di parametri \\(n\\) (numero di prove) e \\(p\\) (probabilit√† di successo).\n\\(\\mathbb{KL} (p \\mid\\mid q)\\): la divergenza di Kullback-Leibler da \\(p\\) a \\(q\\).",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>78</span>¬† <span class='chapter-title'>Simbologia di base</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html",
    "href": "chapters/appendix/a11_numbers.html",
    "title": "79¬† Numeri e intervalli",
    "section": "",
    "text": "79.1 Numeri binari\nI numeri binari rappresentano il sistema numerico pi√π elementare utilizzato in informatica, poich√© sono composti unicamente da due simboli: 0 e 1. Questa caratteristica li rende particolarmente adatti alla rappresentazione di situazioni dicotomiche (vero/falso, presente/assente) e consente ai computer di operare rapidamente ed efficacemente sui dati.\nUn esempio semplice d‚Äôimpiego dei valori logici binari si ottiene quando raccogliamo risposte a una domanda chiusa. Immaginiamo, ad esempio, di porre la domanda ‚ÄúTi piacciono i mirtilli?‚Äù a 10 studenti. Se le risposte vengono memorizzate in R come valori logici (TRUE per ‚ÄúS√¨‚Äù e FALSE per ‚ÄúNo‚Äù), potremmo avere:\nopinion &lt;- c(TRUE, FALSE, TRUE, TRUE, TRUE, FALSE, TRUE, TRUE, TRUE, FALSE)\nopinion\n\n [1]  TRUE FALSE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE FALSE\nIn questo caso, TRUE e FALSE corrispondono a 1 e 0 rispettivamente quando utilizzati in operazioni numeriche. Lo stesso avviene in Python, dove True √® interpretato come 1 e False come 0. Questa rappresentazione binaria permette di ottenere facilmente statistiche sintetiche. Per esempio, per calcolare la proporzione di risposte positive rispetto al totale, √® sufficiente sommare i valori (contando cos√¨ il numero di TRUE) e dividere per la lunghezza del vettore:\nsum(opinion) / length(opinion)\n\n[1] 0.7\nQuesto fornisce immediatamente la percentuale di studenti che hanno risposto ‚ÄúS√¨‚Äù alla domanda.",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>79</span>¬† <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#numeri-interi",
    "href": "chapters/appendix/a11_numbers.html#numeri-interi",
    "title": "79¬† Numeri e intervalli",
    "section": "79.2 Numeri interi",
    "text": "79.2 Numeri interi\nI numeri interi sono caratterizzati dall‚Äôassenza di componenti decimali. Essi includono sia i numeri naturali (1, 2, 3, ‚Ä¶), tradizionalmente utilizzati per il conteggio, sia i loro opposti negativi. L‚Äôinsieme dei numeri naturali √® indicato con \\(\\mathbb{N}\\), mentre l‚Äôinsieme dei numeri interi (che include i numeri naturali, i loro negativi e lo zero) si denota con \\(\\mathbb{Z}\\):\n\\[\n\\mathbb{Z} = \\{0, \\pm 1, \\pm 2, \\pm 3, \\dots\\}\n\\]",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>79</span>¬† <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#numeri-razionali",
    "href": "chapters/appendix/a11_numbers.html#numeri-razionali",
    "title": "79¬† Numeri e intervalli",
    "section": "79.3 Numeri razionali",
    "text": "79.3 Numeri razionali\nI numeri razionali sono quei numeri che possono essere espressi come il rapporto tra due numeri interi, con il denominatore diverso da zero. Essi formano l‚Äôinsieme:\n\\[\n\\mathbb{Q} = \\left\\{\\frac{m}{n} \\mid m,n \\in \\mathbb{Z}, n \\neq 0\\right\\}.\n\\]\nPoich√© ogni numero naturale √® anche un intero, e ogni intero pu√≤ essere rappresentato come razionale (ad esempio \\(5 = \\frac{5}{1}\\)), si ha una catena d‚Äôinclusioni tra i diversi insiemi di numeri:\n\\[\n\\mathbb{N} \\subseteq \\mathbb{Z} \\subseteq \\mathbb{Q}.\n\\]\nSe si desidera considerare solo i numeri razionali non negativi, si utilizza la notazione:\n\\[\n\\mathbb{Q}^+ = \\{q \\in \\mathbb{Q} \\mid q \\geq 0\\}.\n\\]",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>79</span>¬† <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#numeri-irrazionali",
    "href": "chapters/appendix/a11_numbers.html#numeri-irrazionali",
    "title": "79¬† Numeri e intervalli",
    "section": "79.4 Numeri irrazionali",
    "text": "79.4 Numeri irrazionali\nNon tutti i numeri possono essere espressi come rapporto di due interi. I numeri che non hanno questa propriet√† sono detti irrazionali. Essi non possono essere scritti in forma frazionaria e la loro espansione decimale √® infinita e non periodica. Esempi tipici di numeri irrazionali sono:\n\n\\(\\sqrt{2}\\)\n\\(\\sqrt{3}\\)\n\\(\\pi = 3.141592...\\)",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>79</span>¬† <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#numeri-reali",
    "href": "chapters/appendix/a11_numbers.html#numeri-reali",
    "title": "79¬† Numeri e intervalli",
    "section": "79.5 Numeri reali",
    "text": "79.5 Numeri reali\nI numeri razionali non coprono tutti i possibili punti sulla retta reale. Per rappresentare ogni possibile misura, grandezza o punto su una linea continua, si considerano i numeri reali, denotati con \\(\\mathbb{R}\\). L‚Äôinsieme dei numeri reali comprende sia i razionali sia gli irrazionali:\n\\[\n\\mathbb{N} \\subseteq \\mathbb{Z} \\subseteq \\mathbb{Q} \\subseteq \\mathbb{R}.\n\\]\nIn statistica, la precisione con cui si esprime una misura √® spesso legata al numero di cifre decimali utilizzate, sfruttando cos√¨ appieno la ‚Äúcontinuit√†‚Äù offerta dai numeri reali.",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>79</span>¬† <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#intervalli-numerici",
    "href": "chapters/appendix/a11_numbers.html#intervalli-numerici",
    "title": "79¬† Numeri e intervalli",
    "section": "79.6 Intervalli Numerici",
    "text": "79.6 Intervalli Numerici\nDefinizione: Un intervallo numerico √® un sottoinsieme connesso della retta reale. Intuitivamente, rappresenta tutti i numeri reali compresi tra due estremi, che possono o meno essere inclusi nell‚Äôintervallo stesso.\nClassificazione degli intervalli: Gli intervalli vengono classificati in base all‚Äôinclusione o meno degli estremi:\n\nIntervallo chiuso: Include entrambi gli estremi. Si indica con \\([a, b]\\) e rappresenta l‚Äôinsieme dei numeri reali \\(x\\) tali che \\(a \\leq x \\leq b\\).\nIntervallo aperto: Non include alcun estremo. Si indica con \\((a, b)\\) e rappresenta l‚Äôinsieme dei numeri reali \\(x\\) tali che \\(a &lt; x &lt; b\\).\nIntervalli semiaperti:\n\nChiuso a sinistra e aperto a destra: Include l‚Äôestremo sinistro ma non quello destro. Si indica con \\([a, b)\\) e rappresenta l‚Äôinsieme dei numeri reali \\(x\\) tali che \\(a \\leq x &lt; b\\).\nAperto a sinistra e chiuso a destra: Include l‚Äôestremo destro ma non quello sinistro. Si indica con \\((a, b]\\) e rappresenta l‚Äôinsieme dei numeri reali \\(x\\) tali che \\(a &lt; x \\leq b\\).\n\n\nTabella riassuntiva:\n\n\n\nIntervallo\nNotazione\nCondizione\n\n\n\n\nChiuso\n\\([a, b]\\)\n\\(a \\leq x \\leq b\\)\n\n\nAperto\n\\((a, b)\\)\n\\(a &lt; x &lt; b\\)\n\n\nChiuso a sinistra, aperto a destra\n\\([a, b)\\)\n\\(a \\leq x &lt; b\\)\n\n\nAperto a sinistra, chiuso a destra\n\\((a, b]\\)\n\\(a &lt; x \\leq b\\)\n\n\n\nOsservazioni: * La scelta della notazione con parentesi quadre o tonde indica rispettivamente l‚Äôinclusione o l‚Äôesclusione degli estremi.",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>79</span>¬† <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a12_sum_notation.html",
    "href": "chapters/appendix/a12_sum_notation.html",
    "title": "80¬† Sommatorie",
    "section": "",
    "text": "80.1 Manipolazione di somme\nLe somme si incontrano costantemente in svariati contesti matematici e statistici quindi abbiamo bisogno di una notazione adeguata che ci consenta di gestirle. La somma dei primi \\(n\\) numeri interi pu√≤ essere scritta come \\(1+2+\\dots+(n-1)+n\\), dove `\\(\\dots\\)‚Äô ci dice di completare la sequenza definita dai termini che vengono prima e dopo. Ovviamente, una notazione come \\(1+7+\\dots+73.6\\) non avrebbe alcun senso senza qualche altro tipo di precisazione. In generale, nel seguito incontreremo delle somme nella forma\n\\[\nx_1+x_2+\\dots+x_n,\n\\]\ndove \\(x_n\\) √® un numero che √® stato definito altrove. La notazione precedente, che fa uso dei tre puntini di sospensione, √® utile in alcuni contesti ma in altri risulta ambigua. Pertanto la notazione di uso corrente √® del tipo\n\\[\n\\sum_{i=1}^n x_i\n\\] e si legge ‚Äúsommatoria per \\(i\\) che va da \\(1\\) a \\(n\\) di \\(x_i\\)‚Äù. Il simbolo \\(\\sum\\) (lettera sigma maiuscola dell‚Äôalfabeto greco) indica l‚Äôoperazione di somma, il simbolo \\(x_i\\) indica il generico addendo della sommatoria, le lettere \\(1\\) ed \\(n\\) indicano i cosiddetti estremi della sommatoria, ovvero l‚Äôintervallo (da \\(1\\) fino a \\(n\\) estremi inclusi) in cui deve variare l‚Äôindice \\(i\\) allorch√© si sommano gli addendi \\(x_i\\). Solitamente l‚Äôestremo inferiore √® \\(1\\) ma potrebbe essere qualsiasi altri numero \\(m &lt; n\\). Quindi\n\\[\n\\sum_{i=1}^n x_i = x_1 + x_{2} + \\dots + x_{n}.\n\\]\nPer esempio, se i valori \\(x\\) sono \\(\\{3, 11, 4, 7\\}\\), si avr√†\n\\[\n\\sum_{i=1}^4 x_i = 3+11+4+7 = 25\n\\]\nladdove \\(x_1 = 3\\), \\(x_2 = 11\\), eccetera. La quantit√† \\(x_i\\) nella formula precedente si dice l‚Äôargomento della sommatoria, mentre la variabile \\(i\\), che prende i valori naturali successivi indicati nel simbolo, si dice indice della sommatoria.\nLa notazione di sommatoria pu√≤ anche essere fornita nella forma seguente\n\\[\n\\sum_{P(i)} x_i\n\\]\ndove \\(P(i)\\) √® qualsiasi proposizione riguardante \\(i\\) che pu√≤ essere vera o falsa. Quando √® ovvio che si vogliono sommare tutti i valori di \\(n\\) osservazioni, la notazione pu√≤ essere semplificata nel modo seguente: \\(\\sum_{i} x_i\\) oppure \\(\\sum x_i\\). Al posto di \\(i\\) si possono trovare altre lettere: \\(k, j, l, \\dots\\),.\n√à conveniente utilizzare le seguenti regole per semplificare i calcoli che coinvolgono l‚Äôoperatore della sommatoria.",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>80</span>¬† <span class='chapter-title'>Sommatorie</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a12_sum_notation.html#manipolazione-di-somme",
    "href": "chapters/appendix/a12_sum_notation.html#manipolazione-di-somme",
    "title": "80¬† Sommatorie",
    "section": "",
    "text": "80.1.1 Propriet√† 1\nLa sommatoria di \\(n\\) valori tutti pari alla stessa costante \\(a\\) √® pari a \\(n\\) volte la costante stessa:\n\\[\n\\sum_{i=1}^{n} a = \\underbrace{a + a + \\dots + a} = {n\\text{ volte } a} = n a.\n\\]\n\n\n80.1.2 Propriet√† 2 (propriet√† distributiva)\nNel caso in cui l‚Äôargomento contenga una costante, √® possibile riscrivere la sommatoria. Ad esempio con\n\\[\n\\sum_{i=1}^{n} a x_i = a x_1 + a x_2 + \\dots + a x_n\n\\]\n√® possibile raccogliere la costante \\(a\\) e fare \\(a(x_1 +x_2 + \\dots + x_n)\\). Quindi possiamo scrivere\n\\[\n\\sum_{i=1}^{n} a x_i = a \\sum_{i=1}^{n} x_i.\n\\]\n\n\n80.1.3 Propriet√† 3 (propriet√† associativa)\nNel caso in cui\n\\[\n\\sum_{i=1}^{n} (a + x_i) = (a + x_1) + (a + x_1) + \\dots  (a + x_n)\n\\]\nsi ha che\n\\[\n\\sum_{i=1}^{n} (a + x_i) = n a + \\sum_{i=1}^{n} x_i.\n\\]\n√à dunque chiaro che in generale possiamo scrivere\n\\[\n\\sum_{i=1}^{n} (x_i + y_i) = \\sum_{i=1}^{n} x_i + \\sum_{i=1}^{n} y_i.\n\\]\n\n\n80.1.4 Propriet√† 4\nSe deve essere eseguita un‚Äôoperazione algebrica (innalzamento a potenza, logaritmo, ecc.) sull‚Äôargomento della sommatoria, allora tale operazione algebrica deve essere eseguita prima della somma. Per esempio,\n\\[\n\\sum_{i=1}^{n} x_i^2 = x_1^2 + x_2^2 + \\dots + x_n^2 \\neq \\left(\\sum_{i=1}^{n} x_i \\right)^2.\n\\]\n\n\n80.1.5 Propriet√† 5\nNel caso si voglia calcolare \\(\\sum_{i=1}^{n} x_i y_i\\), il prodotto tra i punteggi appaiati deve essere eseguito prima e la somma dopo:\n\\[\n\\sum_{i=1}^{n} x_i y_i = x_1 y_1 + x_2 y_2 + \\dots + x_n y_n,\n\\]\ninfatti, \\(a_1 b_1 + a_2 b_2 \\neq (a_1 + a_2)(b_1 + b_2)\\).",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>80</span>¬† <span class='chapter-title'>Sommatorie</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a12_sum_notation.html#doppia-sommatoria",
    "href": "chapters/appendix/a12_sum_notation.html#doppia-sommatoria",
    "title": "80¬† Sommatorie",
    "section": "80.2 Doppia sommatoria",
    "text": "80.2 Doppia sommatoria\n√à possibile incontrare la seguente espressione in cui figurano una doppia sommatoria e un doppio indice:\n\\[\n\\sum_{i=1}^{n}\\sum_{j=1}^{m} x_{ij}.\n\\]\nLa doppia sommatoria comporta che per ogni valore dell‚Äôindice esterno, \\(i\\) da \\(1\\) ad \\(n\\), occorre sviluppare la seconda sommatoria per \\(j\\) da \\(1\\) ad \\(m\\). Quindi,\n\\[\n\\sum_{i=1}^{3}\\sum_{j=4}^{6} x_{ij} = (x_{1, 4} + x_{1, 5} + x_{1, 6}) + (x_{2, 4} + x_{2, 5} + x_{2, 6}) + (x_{3, 4} + x_{3, 5} + x_{3, 6}).\n\\]\nUn caso particolare interessante di doppia sommatoria √® il seguente:\n\\[\n\\sum_{i=1}^{n}\\sum_{j=1}^{n} x_i y_j\n\\]\nSi pu√≤ osservare che nella sommatoria interna (quella che dipende dall‚Äôindice \\(j\\)), la quantit√† \\(x_i\\) √® costante, ovvero non dipende dall‚Äôindice (che √® \\(j\\)). Allora possiamo estrarre \\(x_i\\) dall‚Äôoperatore di sommatoria interna e scrivere\n\\[\n\\sum_{i=1}^{n} \\left( x_i \\sum_{j=1}^{n} y_j \\right).\n\\]\nAllo stesso modo si pu√≤ osservare che nell‚Äôargomento della sommatoria esterna la quantit√† costituita dalla sommatoria in \\(j\\) non dipende dall‚Äôindice \\(i\\) e quindi questa quantit√† pu√≤ essere estratta dalla sommatoria esterna. Si ottiene quindi\n\\[\n\\sum_{i=1}^{n}\\sum_{j=1}^{n} x_i y_j = \\sum_{i=1}^{n} \\left( x_i \\sum_{j=1}^{n} y_j \\right) = \\sum_{i=1}^{n}¬†x_i \\sum_{j=1}^{n} y_j.\n\\]\nFacciamo un esercizio. Verifichiamo quanto detto sopra nel caso particolare di \\(x = \\{2, 3, 1\\}\\) e \\(y = \\{1, 4, 9\\}\\), svolgendo prima la doppia sommatoria per poi verificare che quanto cos√¨ ottenuto sia uguale al prodotto delle due sommatorie.\n\\[\n\\begin{align}\n\\sum_{i=1}^3 \\sum_{j=1}^3 x_i y_j &= x_1y_1 + x_1y_2 + x_1y_3 +\nx_2y_1 + x_2y_2 + x_2y_3 +\nx_3y_1 + x_3y_2 + x_3y_3 \\notag\\\\\n&= 2 \\times (1+4+9) + 3 \\times (1+4+9) + 2 \\times (1+4+9) = 84,\\notag\n\\end{align}\n\\]\novvero\n\\[\n(2 + 3 + 1) \\times (1+4+9) = 84.\n\\]",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>80</span>¬† <span class='chapter-title'>Sommatorie</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html",
    "href": "chapters/appendix/a13_sets.html",
    "title": "81¬† Insiemi",
    "section": "",
    "text": "81.1 Diagrammi di Eulero-Venn\nUn insieme (o collezione, classe, gruppo, ‚Ä¶) √® stato definito da Georg Cantor nel modo seguente:\nMentre non √® rilevante la natura degli oggetti che costituiscono l‚Äôinsieme, ci√≤ che importa √® distinguere se un dato oggetto appartenga o meno ad un insieme. Deve essere vera una delle due possibilit√†: il dato oggetto √® un elemento dell‚Äôinsieme considerato oppure non √® elemento dell‚Äôinsieme considerato. Due insiemi \\(A\\) e \\(B\\) si dicono uguali se sono formati dagli stessi elementi, anche se disposti in ordine diverso: \\(A=B\\). Due insiemi \\(A\\) e \\(B\\) si dicono diversi se non contengono gli stessi elementi: \\(A \\neq B\\). Ad esempio, i seguenti insiemi sono uguali:\n\\[\n\\{1, 2, 3\\} = \\{3, 1, 2\\} = \\{1, 3, 2\\}= \\{1, 1, 1, 2, 3, 3, 3\\}.\n\\]\nGli insiemi sono denotati da una lettera maiuscola, mentre le lettere minuscole, di solito, designano gli elementi di un insieme. Per esempio, un generico insieme \\(A\\) si indica con\n\\[\nA = \\{a_1, a_2, \\dots, a_n\\}, \\quad \\text{con } n &gt; 0.\n\\]\nLa scrittura \\(a \\in A\\) dice che \\(a\\) √® un elemento di \\(A\\). Per dire che \\(b\\) non √® un elemento di \\(A\\) si scrive \\(b \\notin A.\\)\nPer quegli insiemi i cui elementi soddisfano una certa propriet√† che li caratterizza, tale propriet√† pu√≤ essere usata per descrivere pi√π sinteticamente l‚Äôinsieme:\n\\[\nA = \\{x ~\\vert~ \\text{propriet√† posseduta da } x\\},\n\\]\nche si legge come ‚Äú\\(A\\) √® l‚Äôinsieme degli elementi \\(x\\) per cui √® vera la propriet√† indicata.‚Äù Per esempio, per indicare l‚Äôinsieme \\(A\\) delle coppie di numeri reali \\((x,y)\\) che appartengono alla parabola \\(y = x^2 + 1\\) si pu√≤ scrivere:\n\\[\nA = \\{(x,y) ~\\vert~ y = x^2 + 1\\}.\n\\]\nDati due insiemi \\(A\\) e \\(B\\), diremo che \\(A\\) √® un sottoinsieme di \\(B\\) se e solo se tutti gli elementi di \\(A\\) sono anche elementi di \\(B\\):\n\\[\nA \\subseteq B \\iff (\\forall x \\in A \\Rightarrow x \\in B).\n\\]\nSe esiste almeno un elemento di \\(B\\) che non appartiene ad \\(A\\) allora diremo che \\(A\\) √® un sottoinsieme proprio di \\(B\\):\n\\[\nA \\subset B \\iff (A \\subseteq B, \\exists~ x \\in B ~\\vert~ x \\notin A).\n\\]\nUn altro insieme, detto insieme delle parti, o insieme potenza, che si associa all‚Äôinsieme \\(A\\) √® l‚Äôinsieme di tutti i sottoinsiemi di \\(A\\), inclusi l‚Äôinsieme vuoto e \\(A\\) stesso. Per esempio, per l‚Äôinsieme \\(A = \\{a, b, c\\}\\), l‚Äôinsieme delle parti √®:\n\\[\n\\mathcal{P}(A) = \\{\n\\emptyset, \\{a\\}, \\{b\\}, \\{c\\},\n\\{a, b\\}, \\{a, c\\}, \\{c, b\\},\n\\{a, b, c\\}\n\\}.\n\\]\nI diagrammi di Venn sono uno strumento grafico molto utile per rappresentare gli insiemi e per verificare le propriet√† delle operazioni tra di essi. Questi diagrammi prendono il nome dal matematico inglese del 19¬∞ secolo John Venn, anche se rappresentazioni simili erano gi√† state utilizzate in precedenza da Leibniz e Eulero.\nI diagrammi di Venn rappresentano gli insiemi come regioni del piano delimitate da una curva chiusa. Nel caso di insiemi finiti, √® possibile evidenziare alcuni elementi di un insieme tramite punti, e in alcuni casi possono essere evidenziati tutti gli elementi degli insiemi considerati.\nIn sostanza, questi diagrammi sono un modo visuale per rappresentare le propriet√† degli insiemi e delle operazioni tra di essi. Sono uno strumento molto utile per visualizzare la relazione tra gli insiemi e per capire meglio come si combinano gli elementi all‚Äôinterno di essi.",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>81</span>¬† <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html#appartenenza-ad-un-insieme",
    "href": "chapters/appendix/a13_sets.html#appartenenza-ad-un-insieme",
    "title": "81¬† Insiemi",
    "section": "81.2 Appartenenza ad un insieme",
    "text": "81.2 Appartenenza ad un insieme\nUsiamo ora R\n\nSet1 &lt;- c(1, 2)\nprint(Set1)\n\n[1] 1 2\n\nprint(class(Set1))\n\n[1] \"numeric\"\n\n\n\nmy_list &lt;- c(1, 2, 3, 4)\nmy_set_from_list &lt;- unique(my_list)\nprint(my_set_from_list)\n\n[1] 1 2 3 4\n\n\nL‚Äôappartenenza ad un insieme si verifica con %in%.\n\nmy_set &lt;- c(1, 3, 5)\nprint(\"Ecco il mio insieme:\")\n\n[1] \"Ecco il mio insieme:\"\n\nprint(my_set)\n\n[1] 1 3 5\n\nprint(\"1 appartiene all'insieme:\")\n\n[1] \"1 appartiene all'insieme:\"\n\nprint(1 %in% my_set)\n\n[1] TRUE\n\nprint(\"2 non appartiene all'insieme:\")\n\n[1] \"2 non appartiene all'insieme:\"\n\nprint(2 %in% my_set)\n\n[1] FALSE\n\nprint(\"4 NON appartiene all'insieme:\")\n\n[1] \"4 NON appartiene all'insieme:\"\n\nprint(!(4 %in% my_set))\n\n[1] TRUE",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>81</span>¬† <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html#relazioni-tra-insiemi",
    "href": "chapters/appendix/a13_sets.html#relazioni-tra-insiemi",
    "title": "81¬† Insiemi",
    "section": "81.3 Relazioni tra insiemi",
    "text": "81.3 Relazioni tra insiemi\nEsaminiamo le funzioni Python per descrivere le relazioni tra insiemi. In particolare, dopo avere definito l‚Äôinsieme universo e l‚Äôinsieme vuoto, considereremo la relazione di inclusione che conduce al concetto di sottoinsieme. Analogamente si definisce il concetto di sovrainsieme. Mostreremo anche come valutare se due insiemi sono disgiunti (si dicono disgiunti gli insiemi con intersezione vuota).\n\nUniv &lt;- 0:10\nSuper &lt;- Univ[Univ %% 2 == 0]\nDisj &lt;- Univ[Univ %% 2 == 1]\nSub &lt;- c(4, 6)\nNull &lt;- Univ[Univ &gt; 10]\n\n\nprint(\"Insieme Universo (tutti gli interi positivi fino a 10):\")\n\n[1] \"Insieme Universo (tutti gli interi positivi fino a 10):\"\n\nprint(Univ)\n\n [1]  0  1  2  3  4  5  6  7  8  9 10\n\nprint(\"Tutti gli interi positivi pari fino a 10:\")\n\n[1] \"Tutti gli interi positivi pari fino a 10:\"\n\nprint(Super)\n\n[1]  0  2  4  6  8 10\n\nprint(\"Tutti gli interi positivi dispari fino a 10:\")\n\n[1] \"Tutti gli interi positivi dispari fino a 10:\"\n\nprint(Disj)\n\n[1] 1 3 5 7 9\n\nprint(\"Insieme di due elementi, 4 e 6:\")\n\n[1] \"Insieme di due elementi, 4 e 6:\"\n\nprint(Sub)\n\n[1] 4 6\n\nprint(\"Un insieme vuoto:\")\n\n[1] \"Un insieme vuoto:\"\n\nprint(Null)\n\ninteger(0)\n\n\n\nprint('√à \"Super\" un sovrainsieme di \"Sub\"?')\n\n[1] \"√à \\\"Super\\\" un sovrainsieme di \\\"Sub\\\"?\"\n\nprint(all(Sub %in% Super))\n\n[1] TRUE\n\nprint('√à \"Super\" un sottoinsieme di \"Univ\"?')\n\n[1] \"√à \\\"Super\\\" un sottoinsieme di \\\"Univ\\\"?\"\n\nprint(all(Super %in% Univ))\n\n[1] TRUE\n\nprint('√à \"Sub\" un sovrainsieme di \"Super\"?')\n\n[1] \"√à \\\"Sub\\\" un sovrainsieme di \\\"Super\\\"?\"\n\nprint(all(Super %in% Sub))\n\n[1] FALSE\n\nprint('Sono \"Super\" e \"Disj\" insiemi disgiunti?')\n\n[1] \"Sono \\\"Super\\\" e \\\"Disj\\\" insiemi disgiunti?\"\n\nprint(length(intersect(Super, Disj)) == 0)\n\n[1] TRUE",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>81</span>¬† <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html#operazioni-tra-insiemi",
    "href": "chapters/appendix/a13_sets.html#operazioni-tra-insiemi",
    "title": "81¬† Insiemi",
    "section": "81.4 Operazioni tra insiemi",
    "text": "81.4 Operazioni tra insiemi\nSi definisce intersezione di \\(A\\) e \\(B\\) l‚Äôinsieme \\(A \\cap B\\) di tutti gli elementi \\(x\\) che appartengono ad \\(A\\) e contemporaneamente a \\(B\\):\n\\[\nA \\cap B = \\{x ~\\vert~ x \\in A \\land x \\in B\\}.\n\\]\nSi definisce unione di \\(A\\) e \\(B\\) l‚Äôinsieme \\(A \\cup B\\) di tutti gli elementi \\(x\\) che appartengono ad \\(A\\) o a \\(B\\), cio√®\n\\[\nA \\cup B = \\{x ~\\vert~ x \\in A \\lor x \\in B\\}.\n\\]\nDifferenza. Si indica con \\(A \\setminus B\\) l‚Äôinsieme degli elementi di \\(A\\) che non appartengono a \\(B\\):\n\\[\nA \\setminus B = \\{x ~\\vert~ x \\in A \\land x \\notin B\\}.\n\\]\nInsieme complementare. Nel caso che sia \\(B \\subseteq A\\), l‚Äôinsieme differenza \\(A \\setminus B\\) √® detto insieme complementare di \\(B\\) in \\(A\\) e si indica con \\(B^C\\).\nDato un insieme \\(S\\), una partizione di \\(S\\) √® una collezione di sottoinsiemi di \\(S\\), \\(S_1, \\dots, S_k\\), tali che\n\\[\nS = S_1 \\cup S_2 \\cup \\dots S_k\n\\]\ne\n\\[\nS_i \\cap S_j, \\quad \\text{con } i \\neq j.\n\\]\nLa relazione tra unione, intersezione e insieme complementare √® data dalle leggi di DeMorgan:\n\\[\n(A \\cup B)^c = A^c \\cap B^c,\n\\]\n\\[\n(A \\cap B)^c = A^c \\cup B^c.\n\\]\nIn tutte le seguenti figure, \\(S\\) √® la regione delimitata dal rettangolo, \\(L\\) √® la regione all‚Äôinterno del cerchio di sinistra e \\(R\\) √® la regione all‚Äôinterno del cerchio di destra. La regione evidenziata mostra l‚Äôinsieme indicato sotto ciascuna figura.\n\n\n\nDiagrammi di Venn\n\n\nI diagrammi di Eulero-Venn che illustrano le leggi di DeMorgan sono forniti nella figura seguente.\n\n\n\nLeggi di DeMorgan\n\n\nVediamo ora come si eseguono le operazioni tra insiemi con R.\nIntersezione.\n\nS1 &lt;- seq(1, 10, by = 3)\nS2 &lt;- 1:6\nS_intersection &lt;- intersect(S1, S2)\nprint(\"Intersezione di S1 e S2:\")\n\n[1] \"Intersezione di S1 e S2:\"\n\nprint(S_intersection)\n\n[1] 1 4\n\n\nUnione. Si noti che il connettivo logico | corrisponde all‚Äôunione.\n\nS_union &lt;- union(S1, S2)\nprint(\"Unione di S1 e S2:\")\n\n[1] \"Unione di S1 e S2:\"\n\nprint(S_union)\n\n[1]  1  4  7 10  2  3  5  6\n\n\nInsieme complementare.\n\nS &lt;- seq(0, 20, by = 2)\nS_complement &lt;- setdiff(0:20, S)\nprint(\"S √® l'insieme dei numeri interi pari tra 0 e 20:\")\n\n[1] \"S √® l'insieme dei numeri interi pari tra 0 e 20:\"\n\nprint(S)\n\n [1]  0  2  4  6  8 10 12 14 16 18 20\n\nprint(\"S_complement √® l'insieme dei numeri interi dispari tra 0 e 20:\")\n\n[1] \"S_complement √® l'insieme dei numeri interi dispari tra 0 e 20:\"\n\nprint(S_complement)\n\n [1]  1  3  5  7  9 11 13 15 17 19\n\n\n\nprint(\"√à l'unione di S e S_complement uguale a tutti i numeri interi tra 0 e 20?\")\n\n[1] \"√à l'unione di S e S_complement uguale a tutti i numeri interi tra 0 e 20?\"\n\nprint(setequal(union(S, S_complement), 0:20))\n\n[1] TRUE\n\n\nDifferenza tra insiemi.\n\nS1 &lt;- seq(0, 30, by = 3)\nS2 &lt;- seq(0, 30, by = 5)\nprint(\"Differenza tra S2 e S1:\")\n\n[1] \"Differenza tra S2 e S1:\"\n\nprint(setdiff(S2, S1))\n\n[1]  5 10 20 25\n\nprint(\"Differenza tra S1 e S2:\")\n\n[1] \"Differenza tra S1 e S2:\"\n\nprint(setdiff(S1, S2))\n\n[1]  3  6  9 12 18 21 24 27\n\n\nDifferenza simmetrica. La differenza simmetrica, indicata con il simbolo Œî, √® un‚Äôoperazione insiemistica definita come unione tra la differenza tra il primo e il secondo insieme e la differenza tra il secondo e il primo insieme. In modo equivalente, la differenza simmetrica equivale all‚Äôunione tra i due insiemi meno la loro intersezione.\n\nsym_diff &lt;- union(setdiff(S1, S2), setdiff(S2, S1))\nprint(\"Differenza simmetrica:\")\n\n[1] \"Differenza simmetrica:\"\n\nprint(sym_diff)\n\n [1]  3  6  9 12 18 21 24 27  5 10 20 25",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>81</span>¬† <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html#coppie-ordinate-e-prodotto-cartesiano",
    "href": "chapters/appendix/a13_sets.html#coppie-ordinate-e-prodotto-cartesiano",
    "title": "81¬† Insiemi",
    "section": "81.5 Coppie ordinate e prodotto cartesiano",
    "text": "81.5 Coppie ordinate e prodotto cartesiano\nUna coppia ordinata \\((x,y)\\) √® l‚Äôinsieme i cui elementi sono \\(x \\in A\\) e \\(y \\in B\\) e nella quale \\(x\\) √® la prima componente (o prima coordinata) e \\(y\\) la seconda. L‚Äôinsieme di tutte le coppie ordinate costruite a partire dagli insiemi \\(A\\) e \\(B\\) viene detto prodotto cartesiano:\n\\[\nA \\times B = \\{(x, y) ~\\vert~ x \\in A \\land y \\in B\\}.\n\\]\nAd esempio, sia \\(A = \\{1, 2, 3\\}\\) e \\(B = \\{a, b\\}\\). Allora,\n\\[\n\\{1, 2\\} \\times \\{a, b, c\\} = \\{(1, a), (1, b), (1, c), (2, a), (2, b), (2, c)\\}.\n\\]\nPi√π in generale, un prodotto cartesiano di \\(n\\) insiemi pu√≤ essere rappresentato da un array di \\(n\\) dimensioni, dove ogni elemento √® una ennupla o tupla ordinata (ovvero, una collezione o un elenco ordinato di \\(n\\) oggetti). Una n-pla ordinata si distingue da un insieme di \\(n\\) elementi in quanto fra gli elementi di un insieme non √® dato alcun ordine. Inoltre gli elementi di una ennupla possono anche essere ripetuti. Essendo la n-pla un elenco ordinato, in generale di ogni suo elemento √® possibile dire se sia il primo, il secondo, il terzo, eccetera, fino all‚Äôn-esimo. Il prodotto cartesiano prende il nome da Ren√© Descartes la cui formulazione della geometria analitica ha dato origine al concetto.\n\nA &lt;- c(\"a\", \"b\", \"c\")\nS &lt;- 1:3\ncartesian_product &lt;- expand.grid(A, S)\nprint(\"Prodotto cartesiano di A e S:\")\n\n[1] \"Prodotto cartesiano di A e S:\"\n\nprint(cartesian_product)\n\n  Var1 Var2\n1    a    1\n2    b    1\n3    c    1\n4    a    2\n5    b    2\n6    c    2\n7    a    3\n8    b    3\n9    c    3\n\n\nSi definisce cardinalit√† (o potenza) di un insieme finito il numero degli elementi dell‚Äôinsieme. Viene indicata con \\(\\vert A\\vert, \\#(A)\\) o \\(\\text{c}(A)\\).\n\nprint(\"La cardinalit√† dell'insieme prodotto cartesiano √®:\")\n\n[1] \"La cardinalit√† dell'insieme prodotto cartesiano √®:\"\n\nprint(nrow(cartesian_product))\n\n[1] 9\n\n\nPotenza del prodotto cartesiano\n\nA &lt;- c(\"Head\", \"Tail\")\np2 &lt;- expand.grid(A, A)\nprint(\"Il quadrato dell'insieme A √® un insieme che contiene:\")\n\n[1] \"Il quadrato dell'insieme A √® un insieme che contiene:\"\n\nprint(nrow(p2))\n\n[1] 4\n\nprint(p2)\n\n  Var1 Var2\n1 Head Head\n2 Tail Head\n3 Head Tail\n4 Tail Tail\n\n\n\np3 &lt;- expand.grid(A, A, A)\nprint(\"L'insieme A elevato alla terza potenza √® costituito da:\")\n\n[1] \"L'insieme A elevato alla terza potenza √® costituito da:\"\n\nprint(nrow(p3))\n\n[1] 8\n\nprint(p3)\n\n  Var1 Var2 Var3\n1 Head Head Head\n2 Tail Head Head\n3 Head Tail Head\n4 Tail Tail Head\n5 Head Head Tail\n6 Tail Head Tail\n7 Head Tail Tail\n8 Tail Tail Tail",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>81</span>¬† <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html",
    "href": "chapters/appendix/a14_combinatorics.html",
    "title": "82¬† Calcolo combinatorio",
    "section": "",
    "text": "82.1 Principio della somma\nIl calcolo combinatorio si occupa di determinare il numero di modi in cui √® possibile combinare, ordinare o disporre elementi di uno o pi√π insiemi, seguendo regole predefinite. Molti problemi di probabilit√† richiedono l‚Äôapplicazione di tecniche combinatorie per calcolare le probabilit√† di eventi complessi. In questo capitolo, esploreremo le nozioni fondamentali del calcolo combinatorio, mettendo in relazione i suoi concetti con i vari metodi di campionamento dall‚Äôurna. Descriveremo i principi della somma e del prodotto che costituiscono le basi del calcolo combinatorio e trovano applicazione in problemi pi√π complessi, come permutazioni, disposizioni e combinazioni.\nIl principio della somma si applica quando un insieme pu√≤ essere suddiviso in sottoinsiemi disgiunti (cio√® senza sovrapposizioni). In questo caso, il numero totale di elementi √® dato dalla somma degli elementi dei sottoinsiemi:\n\\[\nn_{\\text{tot}} = n_1 + n_2 + \\dots + n_k .\n\\]",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>82</span>¬† <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#principio-della-somma",
    "href": "chapters/appendix/a14_combinatorics.html#principio-della-somma",
    "title": "82¬† Calcolo combinatorio",
    "section": "",
    "text": "Esempio 82.1 Un distributore contiene tre diversi scomparti di caramelle:\n\nScomparto A: 10 caramelle alla menta,\nScomparto B: 8 caramelle alla frutta,\nScomparto C: 12 caramelle al cioccolato.\n\nQuante caramelle diverse ci sono in totale nel distributore?\nSecondo il principio della somma, il totale √® dato dalla somma delle caramelle nei tre scomparti:\n\\[\nn_{\\text{tot}} = n_A + n_B + n_C .\n\\]\nCalcolo in R:\n\nA &lt;- 10\nB &lt;- 8\nC &lt;- 12\n\ntotale_caramelle &lt;- A + B + C\ntotale_caramelle\n#&gt; [1] 30\n\nRisultato: Nel distributore ci sono 30 caramelle in totale.",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>82</span>¬† <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#principio-del-prodotto",
    "href": "chapters/appendix/a14_combinatorics.html#principio-del-prodotto",
    "title": "82¬† Calcolo combinatorio",
    "section": "82.2 Principio del prodotto",
    "text": "82.2 Principio del prodotto\nIl principio del prodotto si applica quando un‚Äôoperazione pu√≤ essere suddivisa in pi√π fasi indipendenti, ciascuna con un numero di possibilit√† specifico. Il numero totale di combinazioni √® dato dal prodotto delle possibilit√† offerte da ciascuna fase:\n\\[\nn_{\\text{tot}} = n_1 \\cdot n_2 \\cdot \\dots \\cdot n_k .\n\\]\n\nEsempio 82.2 Poniamo di avere quattro urne:\n\nUrna A: 5 palline,\n\nUrna B: 6 palline,\n\nUrna C: 3 palline,\n\nUrna D: 2 palline.\n\nVogliamo formare insiemi di due palline, ciascuna estratta da urne differenti.\nSecondo il principio del prodotto, per ogni coppia di urne, il numero di combinazioni √® dato dal prodotto delle palline nelle due urne. Successivamente, usiamo il principio della somma per sommare tutte le possibilit√†.\n\\[\nn_{\\text{tot}} = AB + AC + AD + BC + BD + CD\n\\]\nCalcolo in R:\n\nAB &lt;- 5 * 6\nAC &lt;- 5 * 3\nAD &lt;- 5 * 2\nBC &lt;- 6 * 3\nBD &lt;- 6 * 2\nCD &lt;- 3 * 2\n\ntotale_insiemi &lt;- AB + AC + AD + BC + BD + CD\ntotale_insiemi\n#&gt; [1] 91\n\nRisultato: Si possono formare 91 insiemi di due palline, ciascuna estratta da urne differenti.\n\n\n82.2.1 Il modello dell‚Äôurna e i metodi di campionamento\nI problemi combinatori spesso si riducono a modelli di estrazione di palline da urne, con quattro principali varianti:\n\nCon ripetizione e ordine: ogni estrazione rimette la pallina nell‚Äôurna (campionamento Bernoulliano).\nSenza ripetizione e con ordine: ogni estrazione rimuove la pallina.\nCon ripetizione e senza ordine: si considerano le combinazioni, ignorando l‚Äôordine.\nSenza ripetizione e senza ordine: si contano le combinazioni senza rimettere la pallina.\n\n\nEsempio 82.3 ¬†\n\nurna &lt;- c(\"a\", \"b\", \"c\")\n\n# Con ripetizione e ordine\ncampionamento1 &lt;- expand.grid(urna, urna) |&gt;\n    rename(Elemento1 = Var1, Elemento2 = Var2)\n\n# Senza ripetizione e con ordine\ncampionamento2 &lt;- permutations(n = length(urna), r = 2, v = urna) |&gt;\n    as.data.frame() |&gt;\n    rename(Elemento1 = V1, Elemento2 = V2)\n\n# Con ripetizione e senza ordine\ncampionamento3 &lt;- combinations(\n    n = length(urna), r = 2, v = urna, repeats.allowed = TRUE\n) |&gt;\n    as.data.frame() |&gt;\n    rename(Elemento1 = V1, Elemento2 = V2)\n\n# Senza ripetizione e senza ordine\ncampionamento4 &lt;- combinations(n = length(urna), r = 2, v = urna) |&gt;\n    as.data.frame() |&gt;\n    rename(Elemento1 = V1, Elemento2 = V2)\n\n# Risultati\nlist(\n    `Con ripetizione e ordine` = campionamento1,\n    `Senza ripetizione e con ordine` = campionamento2,\n    `Con ripetizione e senza ordine` = campionamento3,\n    `Senza ripetizione e senza ordine` = campionamento4\n)\n#&gt; $`Con ripetizione e ordine`\n#&gt;   Elemento1 Elemento2\n#&gt; 1         a         a\n#&gt; 2         b         a\n#&gt; 3         c         a\n#&gt; 4         a         b\n#&gt; 5         b         b\n#&gt; 6         c         b\n#&gt; 7         a         c\n#&gt; 8         b         c\n#&gt; 9         c         c\n#&gt; \n#&gt; $`Senza ripetizione e con ordine`\n#&gt;   Elemento1 Elemento2\n#&gt; 1         a         b\n#&gt; 2         a         c\n#&gt; 3         b         a\n#&gt; 4         b         c\n#&gt; 5         c         a\n#&gt; 6         c         b\n#&gt; \n#&gt; $`Con ripetizione e senza ordine`\n#&gt;   Elemento1 Elemento2\n#&gt; 1         a         a\n#&gt; 2         a         b\n#&gt; 3         a         c\n#&gt; 4         b         b\n#&gt; 5         b         c\n#&gt; 6         c         c\n#&gt; \n#&gt; $`Senza ripetizione e senza ordine`\n#&gt;   Elemento1 Elemento2\n#&gt; 1         a         b\n#&gt; 2         a         c\n#&gt; 3         b         c\n\n\n\n\n\n82.2.2 Permutazioni Semplici\nLe permutazioni rappresentano tutte le disposizioni possibili di un insieme di \\(n\\) elementi distinti, considerando l‚Äôordine. Il numero totale di permutazioni √® dato dalla formula:\n\\[\nP_n = n!\n\\]\ndove \\(n!\\) (n fattoriale) indica il prodotto di tutti i numeri interi da 1 a \\(n\\):\n\\[\nn! = n \\cdot (n-1) \\cdot (n-2) \\cdot \\dots \\cdot 1 .\n\\]\n\nEsempio 82.4 Calcoliamo tutte le permutazioni possibili per un insieme di tre elementi distinti \\(\\{a, b, c\\}\\). Il numero di permutazioni atteso √®:\n\\[\nP_3 = 3! = 3 \\cdot 2 \\cdot 1 = 6 .\n\\]\nImplementazione in R:\n\n# Insieme di partenza\nA &lt;- c(\"a\", \"b\", \"c\")\n\n# Calcolo delle permutazioni\nperm &lt;- permutations(n = length(A), r = length(A), v = A)\n\n# Visualizzazione delle permutazioni\nprint(perm)\n#&gt;      [,1] [,2] [,3]\n#&gt; [1,] \"a\"  \"b\"  \"c\" \n#&gt; [2,] \"a\"  \"c\"  \"b\" \n#&gt; [3,] \"b\"  \"a\"  \"c\" \n#&gt; [4,] \"b\"  \"c\"  \"a\" \n#&gt; [5,] \"c\"  \"a\"  \"b\" \n#&gt; [6,] \"c\"  \"b\"  \"a\"\n\n# Verifica del numero di permutazioni\nnrow(perm)\n#&gt; [1] 6\n\nLe permutazioni dell‚Äôinsieme sono:\n\\[\n  \\begin{aligned}\n  &\\{a, b, c\\}, \\{a, c, b\\}, \\{b, a, c\\}, \\{b, c, a\\}, \\{c, a, b\\}, \\{c, b, a\\} .\n  \\end{aligned}\n  \\]\nIl numero totale √® \\(P_3 = 6\\).\n\n\n\n82.2.2.1 Caratteristiche delle Permutazioni\nLe permutazioni rappresentano un caso di campionamento senza ripetizione con ordine:\n\nSenza ripetizione: Ogni elemento pu√≤ essere utilizzato una sola volta.\nCon ordine: La disposizione degli elementi √® importante.\n\n\n\n\n\n82.2.3 Disposizioni Semplici\nLe disposizioni semplici sono sequenze ordinate di \\(k\\) elementi scelti da un insieme di \\(n\\) elementi distinti. Il numero totale di disposizioni si calcola con la formula:\n\\[\nD_{n,k} = \\frac{n!}{(n-k)!}\n\\]\ndove:\n\n\\(n!\\) (fattoriale di \\(n\\)) √® il prodotto dei numeri interi da 1 a \\(n\\),\n\\((n-k)!\\) rappresenta il fattoriale della differenza tra il numero totale di elementi e quelli scelti.\n\n\nEsempio 82.5 Consideriamo l‚Äôinsieme\\(\\{a, b, c\\}\\) (\\(n = 3\\)) e calcoliamo tutte le disposizioni possibili di 2 elementi (\\(k = 2\\)).\nIl numero di disposizioni atteso √®:\n\\[\nD_{3,2} = \\frac{3!}{(3-2)!} = \\frac{3 \\cdot 2 \\cdot 1}{1} = 6 .\n\\]\nImplementazione in R:\n\n# Insieme di partenza\nA &lt;- c(\"a\", \"b\", \"c\")\n\n# Calcolo delle disposizioni di 2 elementi\ndisp &lt;- permutations(n = length(A), r = 2, v = A)\n\n# Visualizzazione delle disposizioni\nprint(disp)\n#&gt;      [,1] [,2]\n#&gt; [1,] \"a\"  \"b\" \n#&gt; [2,] \"a\"  \"c\" \n#&gt; [3,] \"b\"  \"a\" \n#&gt; [4,] \"b\"  \"c\" \n#&gt; [5,] \"c\"  \"a\" \n#&gt; [6,] \"c\"  \"b\"\n\n# Verifica del numero di disposizioni\nnrow(disp)\n#&gt; [1] 6\n\n\nLe disposizioni di 2 elementi sono: \\[\n\\{a, b\\}, \\{a, c\\}, \\{b, a\\}, \\{b, c\\}, \\{c, a\\}, \\{c, b\\} .\n\\]\nIl numero totale √® \\(D_{3,2} = 6\\).\n\n\n\n\n82.2.3.1 Caratteristiche delle Disposizioni Semplici\nLe disposizioni semplici rappresentano un caso di campionamento senza ripetizione e con ordine:\n\nSenza ripetizione: Ogni elemento pu√≤ essere utilizzato una sola volta.\nCon ordine: La disposizione degli elementi selezionati √® importante.\n\n\n\n\n\n82.2.4 Combinazioni Semplici\nLe combinazioni semplici rappresentano i modi di selezionare \\(k\\) elementi da un insieme di \\(n\\) elementi senza considerare l‚Äôordine. Il numero totale di combinazioni si calcola con la formula:\n\\[\nC_{n,k} = \\binom{n}{k} = \\frac{n!}{k!(n-k)!}\n\\]\ndove:\n\n\\(n!\\) √® il fattoriale di \\(n\\),\n\\(k!\\) √® il fattoriale di \\(k\\),\n\\((n-k)!\\) √® il fattoriale della differenza tra il numero totale di elementi e quelli scelti.\n\n\n\nEsempio 82.6 Consideriamo l‚Äôinsieme \\(\\{a, b, c\\}\\) (\\(n = 3\\)) e calcoliamo tutte le combinazioni possibili di 2 elementi (\\(k = 2\\)).\nIl numero di combinazioni atteso √®:\n\\[\nC_{3,2} = \\binom{3}{2} = \\frac{3!}{2! \\cdot (3-2)!} = \\frac{3 \\cdot 2 \\cdot 1}{2 \\cdot 1 \\cdot 1} = 3 .\n\\]\nImplementazione in R:\n\n# Insieme di partenza\nA &lt;- c(\"a\", \"b\", \"c\")\n\n# Calcolo delle combinazioni di 2 elementi\ncomb &lt;- combinations(n = length(A), r = 2, v = A)\n\n# Visualizzazione delle combinazioni\nprint(comb)\n#&gt;      [,1] [,2]\n#&gt; [1,] \"a\"  \"b\" \n#&gt; [2,] \"a\"  \"c\" \n#&gt; [3,] \"b\"  \"c\"\n\n# Verifica del numero di combinazioni\nnrow(comb)\n#&gt; [1] 3\n\n\nLe combinazioni di 2 elementi sono: \\[\n\\{a, b\\}, \\{a, c\\}, \\{b, c\\} .\n\\]\nIl numero totale √® \\(C_{3,2} = 3\\).\n\n\n\n\n82.2.4.1 Caratteristiche delle Combinazioni Semplici\nLe combinazioni semplici rappresentano un caso di campionamento senza ripetizione e senza ordine:\n\nSenza ripetizione: Ogni elemento pu√≤ essere selezionato una sola volta.\nSenza ordine: L‚Äôordine degli elementi selezionati non ha importanza (\\(\\{a, b\\}\\) √® uguale a\\(\\{b, a\\}\\)).\n\n\nQuesto capitolo ha illustrato i legami tra i metodi del calcolo combinatorio e le diverse modalit√† di campionamento, mostrando come implementare questi concetti in R.",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>82</span>¬† <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#bibliografia",
    "href": "chapters/appendix/a14_combinatorics.html#bibliografia",
    "title": "82¬† Calcolo combinatorio",
    "section": "Bibliografia",
    "text": "Bibliografia",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>82</span>¬† <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a15_calculus.html",
    "href": "chapters/appendix/a15_calculus.html",
    "title": "83¬† Per liberarvi dai terrori preliminari",
    "section": "",
    "text": "83.1 Integrali\nFornisco qui la traduzione del capitolo Per liberarvi dai terrori preliminari di Calculus made easy.",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>83</span>¬† <span class='chapter-title'>Per liberarvi dai terrori preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a15_calculus.html#integrali",
    "href": "chapters/appendix/a15_calculus.html#integrali",
    "title": "83¬† Per liberarvi dai terrori preliminari",
    "section": "",
    "text": "Il terrore preliminare, che impedisce a molti studenti anche solo di tentare di imparare l‚Äôanalisi, pu√≤ essere abolito una volta per tutte semplicemente affermando qual √® il significato ‚Äì in termini di buon senso ‚Äì dei due simboli principali che sono usati nell‚Äôanalisi matematica.\nQuesti terribili simboli sono:\n\n\\(d\\) che significa semplicemente ‚Äúun po‚Äô di‚Äù. Quindi \\(\\operatorname{d}\\!x\\) significa un po‚Äô di \\(x\\); o \\(\\operatorname{d}\\!u\\) significa un po‚Äô di \\(u\\). I matematici pensano che sia pi√π educato dire ‚Äúun elemento di‚Äù invece di ‚Äúun po‚Äô di‚Äù. Fai come ti pare. Ma scoprirai che questi piccoli pezzi (o elementi) possono essere considerati indefinitamente piccoli.\n\\(\\int\\) che √® semplicemente una S allungata, e pu√≤ essere chiamata (se volete) ‚Äúla somma di‚Äù. Quindi \\(\\int \\operatorname{d}\\!x\\) significa la somma di tutti i pezzettini di \\(x\\); oppure \\(\\int \\operatorname{d}\\!t\\) significa la somma di tutti i pezzettini di \\(t\\). I matematici chiamano questo simbolo ‚Äúl‚Äôintegrale di‚Äù. Ora qualsiasi sciocco pu√≤ vedere che se \\(x\\) √® considerato come composto da tanti piccoli pezzetti, ognuno dei quali √® chiamato \\(\\operatorname{d}\\!x\\), se li sommi tutti insieme ottieni la somma di tutti i \\(\\operatorname{d}\\!x\\), (che √® la stessa cosa dell‚Äôinsieme di \\(x\\)). La parola ‚Äúintegrale‚Äù significa semplicemente ‚Äúil tutto‚Äù. Se pensi alla durata di un‚Äôora, puoi (se vuoi) pensarla come suddivisa in 3600 piccoli pezzetti chiamati secondi. L‚Äôinsieme dei 3600 pezzetti sommati fa un‚Äôora. Quando vedrete un‚Äôespressione che inizia con questo simbolo terrificante, d‚Äôora in poi saprete che √® stato messo l√¨ semplicemente per darvi l‚Äôistruzione che ora dovete eseguire (se potete) l‚Äôoperazione di sommare tutti i piccoli pezzetti che sono indicati dai simboli che seguono.\n\n√à tutto.\n\n\n\n\n83.1.1 Verifica con Simulazioni in R\nPer calcolare e visualizzare l‚Äôintegrale di una funzione di densit√†, possiamo utilizzare R. Per fare un esempio, consideriamo la funzione di densit√† gaussiana. La funzione di densit√† gaussiana √® definita dalla seguente formula:\n\\[\nf(x; \\mu, \\sigma) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} e^{-\\frac{(x - \\mu)^2}{2 \\sigma^2}}.\n\\]\nIn R:\n\ngaussian &lt;- function(x, mu, sigma) {\n  1 / (sigma * sqrt(2 * pi)) * exp(-((x - mu)^2) / (2 * sigma^2))\n}\n\nDefiniamo i parametri e generiamo i valori per il calcolo della funzione di densit√† su un intervallo:\n\nmu &lt;- 0      # Media\nsigma &lt;- 1   # Deviazione standard\na &lt;- -10     # Limite inferiore\nb &lt;- 10      # Limite superiore\nn &lt;- 10000   # Numero di punti\n\nx_range &lt;- seq(a, b, length.out = n)  # Valori x\nfx &lt;- gaussian(x_range, mu, sigma)   # Ordinata della funzione\n\nVisualizziamo la funzione:\n\nlibrary(ggplot2)\nlibrary(scales)\n\nggplot(data.frame(x = x_range, fx = fx), aes(x, fx)) +\n  geom_line(color = \"blue\") +\n  labs(\n    title = \"Funzione di densit√† gaussiana\", \n    x = \"x\", \n    y = \"f(x)\"\n  )\n\n\n\n\n\n\n\n\nCreiamo una funzione per approssimare l‚Äôintegrale sommando i prodotti \\(\\Delta x \\cdot f(x)\\):\n\nintegral_approximation &lt;- function(f, a, b, n) {\n  delta &lt;- (b - a) / n\n  sum(delta * f)\n}\n\n# Calcolo dell'integrale approssimato\napprox &lt;- integral_approximation(fx, a, b, n)\napprox\n\n[1] 0.9999\n\n\nConfrontiamo il risultato con il calcolo fornito da R:\n\nintegrate(\n  function(x) gaussian(x, mu, sigma),\n  lower = a,\n  upper = b\n)\n\n1 with absolute error &lt; 7.4e-05\n\n\nCalcoliamo l‚Äôarea sotto la curva in intervalli di interesse. Ad esempio, per \\([-1.96, 1.96]\\), che corrisponde al 95% dell‚Äôarea nella distribuzione normale standard:\n\na &lt;- -1.96\nb &lt;- 1.96\nx_range &lt;- seq(a, b, length.out = n)\nfx &lt;- gaussian(x_range, mu, sigma)\n\napprox &lt;- integral_approximation(fx, a, b, n)\napprox\n\n[1] 0.9499321\n\n\nConfrontiamo con il risultato fornito da integrate():\n\nintegrate(\n  function(x) gaussian(x, mu, sigma),\n  lower = a,\n  upper = b\n)\n\n0.9500042 with absolute error &lt; 1e-11\n\n\nVerifichiamo l‚Äôarea sotto la curva per \\([-1, 1]\\), che rappresenta circa il 68% dell‚Äôarea totale:\n\na &lt;- -1.0\nb &lt;- 1.0\nx_range &lt;- seq(a, b, length.out = n)\nfx &lt;- gaussian(x_range, mu, sigma)\n\napprox &lt;- integral_approximation(fx, a, b, n)\napprox\n\n[1] 0.6826696\n\n\nConfronto:\n\nintegrate(\n  function(x) gaussian(x, mu, sigma),\n  lower = a,\n  upper = b\n)\n\n0.6826895 with absolute error &lt; 7.6e-15\n\n\nIn sintesi, questo approccio dimostra come calcolare l‚Äôintegrale di una funzione di densit√† in un intervallo utilizzando sia un metodo approssimativo basato sulla somma dei rettangoli sia il metodo numerico integrato. In entrambi i casi, l‚Äôobiettivo √® calcolare l‚Äôarea sotto la curva, che corrisponde all‚Äôintegrale della funzione di densit√†.",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>83</span>¬† <span class='chapter-title'>Per liberarvi dai terrori preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a15_calculus.html#potenze",
    "href": "chapters/appendix/a15_calculus.html#potenze",
    "title": "83¬† Per liberarvi dai terrori preliminari",
    "section": "83.2 Potenze",
    "text": "83.2 Potenze\nLe potenze sono un‚Äôoperazione matematica che rappresenta un prodotto ripetuto. Si indicano generalmente come:\n\\[\na^n,\n\\]\ndove:\n\n\\(a\\) √® la base,\n\\(n\\) √® l‚Äôesponente.\n\nLa potenza rappresenta il prodotto della base \\(a\\) ripetuto \\(n\\) volte.\n\n83.2.1 Definizione di potenza\n\\[\na^n = \\underbrace{a \\cdot a \\cdot \\dots \\cdot a}_{n \\text{ fattori}} \\quad \\text{con } n \\in \\mathbb{N}.\n\\]\nAd esempio:\n\n\\(2^3 = 2 \\cdot 2 \\cdot 2 = 8\\),\n\\(3^4 = 3 \\cdot 3 \\cdot 3 \\cdot 3 = 81\\).\n\n\n\n\n83.2.2 Propriet√† delle potenze\n\nMoltiplicazione di potenze con la stessa base:\n\\[\na^m \\cdot a^n = a^{m+n}\n\\]\nEsempio: \\(2^3 \\cdot 2^2 = 2^{3+2} = 2^5 = 32\\).\nDivisione di potenze con la stessa base:\n\\[\n\\frac{a^m}{a^n} = a^{m-n}, \\quad \\text{con } m \\geq n.\n\\]\nEsempio: \\(\\frac{5^4}{5^2} = 5^{4-2} = 5^2 = 25\\).\nPotenze di potenze:\n\\[\n(a^m)^n = a^{m \\cdot n}.\n\\]\nEsempio: \\((3^2)^3 = 3^{2 \\cdot 3} = 3^6 = 729\\).\nProdotto di potenze con basi diverse ma lo stesso esponente:\n\\[\na^n \\cdot b^n = (a \\cdot b)^n.\n\\]\nEsempio: \\(2^3 \\cdot 3^3 = (2 \\cdot 3)^3 = 6^3 = 216\\).\nDivisione di potenze con basi diverse ma lo stesso esponente:\n\\[\n\\frac{a^n}{b^n} = \\left(\\frac{a}{b}\\right)^n.\n\\]\nEsempio: \\(\\frac{4^2}{2^2} = \\left(\\frac{4}{2}\\right)^2 = 2^2 = 4\\).\nEsponente zero:\n\\[\na^0 = 1, \\quad \\text{con } a \\neq 0.\n\\]\nEsempio: \\(5^0 = 1\\).\nEsponente negativo:\n\\[\na^{-n} = \\frac{1}{a^n}.\n\\]\nEsempio: \\(2^{-3} = \\frac{1}{2^3} = \\frac{1}{8}\\).\nRadice come potenza frazionaria:\n\\[\na^{\\frac{1}{n}} = \\sqrt[n]{a}, \\quad a^{\\frac{m}{n}} = \\sqrt[n]{a^m}.\n\\]\nEsempio: \\(8^{\\frac{1}{3}} = \\sqrt[3]{8} = 2\\).\n\n\n\n\n83.2.3 Esempi pratici\n\nCalcolo semplice:\n\\[\n4^3 = 4 \\cdot 4 \\cdot 4 = 64.\n\\]\nUtilizzo delle propriet√†:\n\\[\n3^5 \\cdot 3^2 = 3^{5+2} = 3^7 = 2187.\n\\]\nDivisione:\n\\[\n\\frac{6^4}{6^2} = 6^{4-2} = 6^2 = 36.\n\\]\nEsponente negativo:\n\\[\n10^{-2} = \\frac{1}{10^2} = \\frac{1}{100} = 0.01.\n\\]\nRadice come potenza:\n\\[\n16^{\\frac{1}{2}} = \\sqrt{16} = 4.\n\\]\n\n\n\n\n83.2.4 Nota sui numeri razionali e reali\n\nLe potenze con esponenti interi sono definite per ogni base.\nLe potenze con esponenti frazionari o reali richiedono che la base sia positiva per evitare ambiguit√†.",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>83</span>¬† <span class='chapter-title'>Per liberarvi dai terrori preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a15_calculus.html#logaritmi",
    "href": "chapters/appendix/a15_calculus.html#logaritmi",
    "title": "83¬† Per liberarvi dai terrori preliminari",
    "section": "83.3 Logaritmi",
    "text": "83.3 Logaritmi\nIl logaritmo √® una funzione matematica che risponde alla domanda: ‚Äúquante volte devo moltiplicare un certo numero (chiamato‚Äùbase‚Äù) per ottenere un altro numero?‚Äù Matematicamente, questo √® espresso come:\n\\[\n\\log_b(a) = x \\iff b^x = a\n\\]\nAd esempio, \\(\\log_2(8) = 3\\) perch√© \\(2^3 = 8\\).\nNel contesto dei logaritmi, i valori molto piccoli (compresi tra 0 e 1) diventano pi√π grandi (in termini assoluti) e negativi quando applichiamo una funzione logaritmica. Questo √® utile per stabilizzare i calcoli, specialmente quando lavoriamo con prodotti di numeri molto piccoli che potrebbero portare a problemi di underflow.\nPer esempio:\n\n\\(\\log(1) = 0\\)\n\\(\\log(0.1) = -1\\)\n\\(\\log(0.01) = -2\\)\n\\(\\log(0.001) = -3\\)\n\nCome si pu√≤ vedere, i valori assoluti dei logaritmi crescono man mano che il numero originale si avvicina a zero.\nUna delle propriet√† pi√π utili dei logaritmi √® che consentono di trasformare un prodotto in una somma:\n\\[\n\\log_b(a \\times c) = \\log_b(a) + \\log_b(c)\n\\]\nQuesta propriet√† √® estremamente utile in calcoli complessi, come nella statistica bayesiana, dove il prodotto di molte probabilit√† potrebbe diventare un numero molto piccolo e causare problemi numerici.\nUn‚Äôaltra propriet√† utile dei logaritmi √® che un rapporto tra due numeri diventa la differenza dei loro logaritmi:\n\\[\n\\log_b\\left(\\frac{a}{c}\\right) = \\log_b(a) - \\log_b(c)\n\\]\nAnche questa propriet√† √® molto utilizzata in matematica, specialmente in situazioni in cui √® necessario normalizzare i dati.\nIn sintesi, i logaritmi sono strumenti potenti per semplificare e stabilizzare i calcoli matematici. Essi consentono di lavorare pi√π agevolmente con numeri molto grandi o molto piccoli e di trasformare operazioni complesse come prodotti e divisioni in somme e differenze, rendendo i calcoli pi√π gestibili e meno inclini a errori numerici.",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>83</span>¬† <span class='chapter-title'>Per liberarvi dai terrori preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a44_montecarlo.html",
    "href": "chapters/appendix/a44_montecarlo.html",
    "title": "84¬† Simulazione Monte Carlo",
    "section": "",
    "text": "84.1 Funzioni in R\nIl Metodo Monte Carlo utilizza simulazioni casuali per risolvere problemi complessi. √à applicato in numerosi ambiti per calcolare stime quando non √® possibile ottenere soluzioni analitiche semplici.\nPer fare un esempio semplice, stimiamo œÄ con il Metodo Monte Carlo. Per fare questo, calcoleremo approssimativamente œÄ simulando il rapporto tra l‚Äôarea di un cerchio e quella di un quadrato circoscritto.\nDefiniamo una funzione per verificare se un punto √® all‚Äôinterno del cerchio e una per stimare \\(\\pi\\) e generare una figura visualizzabile nel file HTML.\n# Funzione per verificare se un punto √® dentro il cerchio\nin_circle &lt;- function(x, y, r) {\n  sqrt(x^2 + y^2) &lt;= r\n}\n\n# Funzione per stimare œÄ e creare una figura\napprox_pi &lt;- function(r, n) {\n  # Genera punti casuali\n  points &lt;- data.frame(\n    x = runif(n, 0, r),\n    y = runif(n, 0, r)\n  )\n  \n  # Determina se i punti sono dentro il cerchio\n  points &lt;- points %&gt;%\n    mutate(in_circle = in_circle(x, y, r),\n           color = ifelse(in_circle, \"inside\", \"outside\"))\n  \n  # Conta i punti dentro il cerchio\n  count &lt;- sum(points$in_circle)\n  \n  # Calcola œÄ\n  pi_approx &lt;- 4 * count / n\n  \n  # Genera il grafico\n  ggplot(points, aes(x, y, color = color)) +\n    geom_point(size = 1, alpha = 0.5) +\n    labs(\n      title = paste(\"Monte Carlo Approximation of œÄ ‚âà\", round(pi_approx, 3)),\n      subtitle = paste(count, \"points inside the circle out of\", n, \"total points\"),\n      x = \"x\",\n      y = \"y\"\n    ) +\n    coord_equal() \n}\nEseguiamo la simulazione per diverse dimensioni del campione:\n# Simulazioni con diverse quantit√† di punti\nr &lt;- 1\nn_points &lt;- c(50, 500, 5000)\n\n# Ciclo per calcolare œÄ e generare i grafici\nfor (n in n_points) {\n  cat(\"Stima di œÄ con\", n, \"punti:\\n\")\n  print(approx_pi(r, n))\n}\n#&gt; Stima di œÄ con 50 punti:\n#&gt; Stima di œÄ con 500 punti:\n#&gt; Stima di œÄ con 5000 punti:",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>84</span>¬† <span class='chapter-title'>Simulazione Monte Carlo</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a44_montecarlo.html#simulazione-di-monte-carlo-in-stan",
    "href": "chapters/appendix/a44_montecarlo.html#simulazione-di-monte-carlo-in-stan",
    "title": "84¬† Simulazione Monte Carlo",
    "section": "84.2 Simulazione di Monte Carlo in Stan",
    "text": "84.2 Simulazione di Monte Carlo in Stan\nSimuliamo œÄ utilizzando Stan, un potente strumento per la modellazione probabilistica. Definiamo il modello in Stan come segue:\ngenerated quantities {\n  real x = uniform_rng(0, 1);\n  real y = uniform_rng(0, 1);\n  int inside = x^2 + y^2 &lt;= 1;\n  real pi_estimate = 4 * inside;\n}\nUtilizziamo il pacchetto cmdstanr per compilare ed eseguire il modello Stan.\n\n# Definisce il modello Stan\nstan_code &lt;- \"\ngenerated quantities {\n  real x = uniform_rng(0, 1);\n  real y = uniform_rng(0, 1);\n  int inside = x^2 + y^2 &lt;= 1;\n  real pi_estimate = 4 * inside;\n}\n\"\n\n# Scrive il modello su un file temporaneo\nwriteLines(stan_code, con = \"monte_carlo_pi.stan\")\n\n# Compila il modello\nmodel &lt;- cmdstan_model(\"monte_carlo_pi.stan\")\n\n# Esegue il campionamento\nsamples &lt;- model$sample(\n  chains = 1, \n  iter_sampling = 10000, \n  iter_warmup = 0, \n  seed = 42, \n  fixed_param = TRUE, \n  show_messages = FALSE\n)\n\n# Analisi dei risultati\npi_samples &lt;- samples$draws(variables = \"pi_estimate\", format = \"df\")\n\n# Calcolo di œÄ stimato\npi_est &lt;- mean(pi_samples$pi_estimate)\ncat(\"Stima di œÄ:\", round(pi_est, 3), \"\\n\")\n#&gt; Stima di œÄ: 3.15\n\nQuesta combinazione di R e Stan dimostra l‚Äôefficacia e la flessibilit√† del Metodo Monte Carlo e delle sue varianti. Sia per problemi semplici come la stima di \\(\\pi\\), sia per applicazioni pi√π complesse come l‚Äôintegrazione e l‚Äôimportance sampling, questi strumenti offrono soluzioni potenti e scalabili.",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>84</span>¬† <span class='chapter-title'>Simulazione Monte Carlo</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a46_stan_lang.html",
    "href": "chapters/appendix/a46_stan_lang.html",
    "title": "85¬† Linguaggio Stan",
    "section": "",
    "text": "85.1 Interfaccia cmdstanr\n√à possibile accedere al linguaggio Stan tramite diverse interfacce:\nInoltre, vengono fornite interfacce di livello superiore con i pacchetti che utilizzano Stan come backend, sia in Python che in Linguaggio \\(\\mathsf{R}\\):\nNegli esempi di questa dispensa verr√† utilizzata l‚Äôinterfaccia cmdstanr. CmdStanR √® un‚Äôinterfaccia R per Stan che consente di definire, eseguire e analizzare modelli bayesiani in modo semplice ed efficace. Questa libreria integra l‚Äôinterfaccia a riga di comando di CmdStan con una serie di funzioni R intuitive, che permettono di gestire modelli, dati e risultati dell‚Äôinferenza a posteriori.\nPer installare CmdStanR, √® possibile seguire la guida ufficiale disponibile a questo link.",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>85</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a46_stan_lang.html#codice-stan",
    "href": "chapters/appendix/a46_stan_lang.html#codice-stan",
    "title": "85¬† Linguaggio Stan",
    "section": "85.2 Codice Stan",
    "text": "85.2 Codice Stan\nStan consente agli utenti di definire un modello bayesiano attraverso il linguaggio Stan. Questo modello, di solito, viene salvato in un file di testo con estensione .stan.\nIl codice Stan deve poi essere compilato. Il processo di compilazione di un modello in Stan avviene in due fasi: innanzitutto, Stan traduce il modello dal formato .stan in codice C++, il quale viene successivamente compilato in codice macchina.\nDopo la compilazione del modello (ovvero, dopo che il codice macchina √® stato generato), l‚Äôutente pu√≤ utilizzare l‚Äôinterfaccia prescelta (per esempio, CmdStan) per campionare la distribuzione definita dal modello e per eseguire altri calcoli correlati al modello stesso.\nIl codice Stan √® costituito da una serie di blocchi che vengono usati per specificare un modello statistico. In ordine, questi blocchi sono:\nfunctions {\n  // ... function declarations and definitions ...\n}\ndata {\n  // ... declarations ...\n}\ntransformed data {\n   // ... declarations ... statements ...\n}\nparameters {\n   // ... declarations ...\n}\ntransformed parameters {\n   // ... declarations ... statements ...\n}\nmodel {\n   // ... declarations ... statements ...\n}\ngenerated quantities {\n   // ... declarations ... statements ...\n}\nQuesti blocchi devono sempre essere in questo ordine, ma non tutti i programmi Stan richiedono tutti i blocchi.\n\n85.2.1 Blocco data\nNel blocco data vengono specificate le variabili di input utilizzate nel modello Stan. Per ogni variabile, √® necessario definire il tipo di dato, le dimensioni e, se necessario, applicare vincoli sui valori che tali variabili possono assumere.\nEsempio di blocco data:\ndata {\n  int&lt;lower=0&gt; ntrials; // Numero di prove\n  int&lt;lower=0&gt; y;       // Successi osservati\n  real&lt;lower=0&gt; alpha_prior; // Parametro alpha per il prior Beta\n  real&lt;lower=0&gt; beta_prior;  // Parametro beta per il prior Beta\n}\nStan offre diversi tipi di dati per le variabili, tra cui:\n\nint: Rappresenta numeri interi senza parte decimale. Esempio: int N = 10;.\nreal: Rappresenta numeri reali, inclusi i decimali. Esempio: real pi = 3.14159;.\nvector: Un vettore unidimensionale di numeri reali. Esempio: vector[3] y;.\nmatrix: Una matrice bidimensionale di numeri reali. Esempio: matrix[2,3] A;.\narray: Tipo generico per contenere elementi di qualsiasi tipo, incluso array di array. Esempio: array[3] int my_array;.\n\n\n85.2.1.1 Dichiarazione di dimensioni e applicazione di vincoli\nQuando si dichiara una variabile, √® essenziale specificarne le dimensioni e, se appropriato, applicare vincoli sui valori che pu√≤ assumere. I vincoli pi√π comuni sono:\n\nlower: Specifica il valore minimo.\nupper: Specifica il valore massimo.\n\nEsempio di variabile reale compresa tra 0 e 1:\nreal&lt;lower=0, upper=1&gt; x;\n\n\n\n85.2.2 Tipi di Dati in Stan\n\n85.2.2.1 Interi\nLe variabili intere vengono dichiarate con la parola chiave int. Per dichiarare un intero positivo, si aggiunge un vincolo inferiore:\nint&lt;lower=1&gt; N;\n\n\n85.2.2.2 Reali\nLe variabili reali, dichiarate con real, possono essere vincolate allo stesso modo degli interi:\nreal&lt;lower=0&gt; sigma;\n\n\n85.2.2.3 Tipi di Dati Vettoriali e Matriciali\n\nVector: Rappresenta una sequenza unidimensionale di numeri reali. Esempio: vector[3] u;.\nMatrix: Una matrice bidimensionale di numeri reali. Esempio: matrix[3, 3] A;.\n\nLe variabili vettoriali e matriciali possono contenere solo valori reali, non interi, e sono trattate come strutture dati distinte dagli array.\n\n85.2.2.3.1 Vettori\nI vettori in Stan sono vettori colonna. Esempio di vettore reale di lunghezza 3:\nvector[3] u;\n\n\n85.2.2.3.2 Matrici\nLe matrici vengono dichiarate specificando il numero di righe e colonne:\nmatrix[3, 3] A;\nmatrix[M, N] B;\nLe dimensioni devono essere definite come variabili intere nel blocco dati.\n\n\n\n85.2.2.4 Array\nGli array possono contenere variabili di qualsiasi tipo (inclusi array di array). Ad esempio, un array di interi:\narray[5] int n;\nGli array multidimensionali sono array di array. Un array bidimensionale di interi si dichiara cos√¨:\narray[3, 4] int a;\n\n\n\n85.2.3 Indicizzazione e Miscelazione dei Tipi\n\nStan indicizza vettori, matrici e array a partire da 1.\nNon √® possibile assegnare tra loro variabili di tipo array, vettore o matrice, anche se hanno le stesse dimensioni.\n\n\n\n85.2.4 Liste in CmdStanR\nQuando si forniscono dati a Stan tramite CmdStanR, questi devono essere organizzati in una lista R. Ogni elemento della lista corrisponde a una variabile dichiarata nel blocco data di Stan, e il valore associato rappresenta i dati forniti al modello.\nEsempio di lista:\ndata_list &lt;- list(\n  ntrials = 100,\n  y = 45,\n  alpha_prior = 2.0,\n  beta_prior = 5.0\n)\nQuesta struttura consente di mappare correttamente i dati alle variabili definite nel modello Stan.\nIn Stan, ogni variabile deve avere un tipo di dato ben definito, con la possibilit√† di applicare vincoli per garantire validit√† e coerenza. I tipi principali includono numeri interi, numeri reali, vettori, matrici e array, ciascuno progettato per supportare operazioni specifiche e migliorare l‚Äôefficienza computazionale.\n\n\n85.2.5 Blocco parameters\nI parametri da stimare sono definiti all‚Äôinterno del blocco parameters.\nAd esempio, consideriamo il seguente codice, dove viene dichiarata la variabile theta per rappresentare una probabilit√†. Si notino i vincoli che specificano che i valori possibili per theta devono essere contenuti nell‚Äôintervallo [0, 1].\nparameters {\n  real&lt;lower=0, upper=1&gt; theta; // Parametro stimato, limitato tra 0 e 1\n}\n\n\n85.2.6 Blocco model\nLa sezione model √® il cuore di un modello Stan, dove si specificano le relazioni statistiche tra i dati osservati e i parametri incogniti. In questa sezione, si definisce la verosimiglianza, ovvero la distribuzione di probabilit√† dei dati condizionata dai parametri, e si assegnano le distribuzioni a priori ai parametri stessi.\n\nLa verosimiglianza modella il processo generativo dei dati. Essa descrive come i dati osservati si sarebbero potuti generare a partire da specifici valori dei parametri. In Stan, la verosimiglianza viene specificata utilizzando il simbolo ~ (tilde).\nLe distribuzioni a priori riflettono le nostre conoscenze o credenze a priori sui parametri prima di osservare i dati. Esse agiscono come regolarizzatori, prevenendo sovrastima o sottostima dei parametri.\n\nAd esempio, nel codice seguente\nmodel {\n  // Modello Beta-Binomiale\n  theta ~ beta(alpha_prior, beta_prior); // Distribuzione a priori di theta\n  y ~ binomial(ntrials, theta); // Verosimiglianza binomiale\n}\n\ntheta ~ beta(alpha_prior, beta_prior);: Questa riga assegna una distribuzione a priori Beta al parametro theta, con parametri di forma alpha_prior e beta_prior.\ny ~ binomial(ntrials, theta);: Questa riga specifica che i dati osservati y seguono una distribuzione binomiale con ntrials prove e probabilit√† di successo theta.\n\nIn generale, possiamo leggere il simbolo ~ come ‚Äú√® distribuito come‚Äù. Pertanto, l‚Äôesempio sopra pu√≤ essere scritto anche come:\n\\[\np(\\theta \\mid \\alpha_p, \\beta_p) = \\text{Beta}(\\alpha_p, \\beta_p)\n\\]\ne\n\\[\np(y \\mid \\theta) = \\text{Binomiale}(y \\mid n, \\theta).\n\\]\nLa notazione compatta usata da Stan facilita la definizione delle relazioni probabilistiche nel modello.\nIn assenza di specifiche, Stan assume una distribuzione non informativa, ovvero una distribuzione a priori uniforme tra meno infinito e pi√π infinito. Per ulteriori raccomandazioni sulle scelte delle distribuzioni a priori, √® possibile consultare questo link.\nIn sintesi, la sezione model definisce il modello statistico completo, combinando la nostra conoscenza a priori sui parametri (attraverso le distribuzioni a priori) con le informazioni contenute nei dati (attraverso la verosimiglianza). Stan utilizza poi tecniche di inferenza Bayesiana per stimare i valori pi√π probabili dei parametri alla luce dei dati osservati.\n\n\n85.2.7 Blocchi opzionali\nCi sono inoltre tre blocchi opzionali:\n\nIl blocco transformed data consente il pre-processing dei dati. √à possibile trasformare i parametri del modello; solitamente ci√≤ viene fatto nel caso dei modelli pi√π avanzati per consentire un campionamento MCMC pi√π efficiente.\nIl blocco transformed parameters consente la manipolazione dei parametri prima del calcolo della distribuzione a posteriori.\nIl blocco generated quantities consente il post-processing riguardante qualsiasi quantit√† che non fa parte del modello ma pu√≤ essere calcolata a partire dai parametri del modello, per ogni iterazione dell‚Äôalgoritmo. Esempi includono la generazione dei campioni a posteriori e le dimensioni degli effetti.\n\n\n\n85.2.8 Sintassi\nIl codice Stan richiede i punti e virgola (;) alla fine di ogni istruzione di assegnazione. Questo accade per le dichiarazioni dei dati, per le dichiarazioni dei parametri e ovunque si acceda ad un elemento di un tipo data e lo si assegni a qualcos‚Äôaltro. I punti e virgola non sono invece richiesti all‚Äôinizio di un ciclo o di un‚Äôistruzione condizionale, dove non viene assegnato nulla.\nIn Stan, qualsiasi stringa che segue il marcatore // denota un commento e viene ignorata dal programma.\nUna descrizione dettagliata della sintassi del linguaggio Stan √® disponibile al seguente link.",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>85</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a50_lin_fun.html",
    "href": "chapters/appendix/a50_lin_fun.html",
    "title": "86¬† La funzione lineare",
    "section": "",
    "text": "86.1 Concetto di Funzione\nNello studio dei fenomeni naturali e nella risoluzione di problemi tecnici e matematici, √® spesso necessario considerare la variazione di una grandezza come dipendente dalla variazione di un‚Äôaltra. Ad esempio, nello studio del moto, il percorso compiuto da un oggetto pu√≤ essere visto come una grandezza variabile in funzione del tempo: il cammino percorso √®, dunque, una funzione del tempo.\nQuesta considerazione ci conduce alla seguente definizione:\nSe a ogni valore della variabile \\(x\\) (all‚Äôinterno di un certo intervallo) corrisponde un valore ben definito di un‚Äôaltra variabile \\(y\\), allora si dice che \\(y\\) √® una funzione di \\(x\\). In notazione funzionale si scrive:\n\\[\ny = f(x) \\quad \\text{o anche} \\quad y = \\varphi(x).\n\\]\nLa variabile \\(x\\) √® detta variabile indipendente o argomento della funzione. La relazione che lega \\(x\\) a \\(y\\) si chiama relazione funzionale. La lettera \\(f\\) nella notazione \\(y = f(x)\\) indica che per ottenere il valore di \\(y\\) a partire da \\(x\\) √® necessario applicare una certa ‚Äúregola‚Äù o ‚Äúoperazione‚Äù. In modo analogo, si possono utilizzare anche altre notazioni come \\(u = \\varphi(x)\\).\nLa notazione \\(y = C\\), dove \\(C\\) √® una costante, indica una funzione il cui valore rimane invariato per qualunque valore di \\(x\\).\nL‚Äôinsieme dei valori di \\(x\\) per cui la funzione \\(y = f(x)\\) √® definita si chiama dominio di definizione della funzione.\nSe per valori crescenti della variabile indipendente \\(x\\) anche il valore della funzione \\(y = f(x)\\) aumenta, allora la funzione si dice crescente. Analogamente, se a valori crescenti di \\(x\\) corrispondono valori decrescenti della funzione \\(y = f(x)\\), la funzione si dice decrescente.",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>86</span>¬† <span class='chapter-title'>La funzione lineare</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a50_lin_fun.html#la-retta",
    "href": "chapters/appendix/a50_lin_fun.html#la-retta",
    "title": "86¬† La funzione lineare",
    "section": "86.2 La Retta",
    "text": "86.2 La Retta\nLa funzione lineare √® definita come:\n\\[\nf(x) = a + b x,\n\\]\ndove \\(a\\) e \\(b\\) sono costanti. Il grafico di tale funzione √® una retta. Qui, \\(b\\) √® detto coefficiente angolare, mentre \\(a\\) √® l‚Äôintercetta con l‚Äôasse delle \\(y\\). In altri termini, la retta interseca l‚Äôasse \\(y\\) nel punto \\((0, a)\\).\nPer comprendere il ruolo di \\(a\\) e \\(b\\), consideriamo prima il caso particolare:\n\\[\ny = b x.\n\\]\nQuesta espressione rappresenta una proporzionalit√† diretta tra \\(x\\) e \\(y\\): al crescere di \\(x\\), \\(y\\) varia in proporzione. Nel caso generale:\n\\[\ny = a + b x,\n\\]\nil termine \\(a\\) ‚Äútrasla‚Äù verticalmente il grafico, aggiungendo una costante a ogni valore \\(b x\\).\nIl segno del coefficiente \\(b\\) determina il comportamento della funzione lineare:\n\nSe \\(b &gt; 0\\), il valore di \\(y\\) aumenta all‚Äôaumentare di \\(x\\).\n\nSe \\(b &lt; 0\\), il valore di \\(y\\) diminuisce all‚Äôaumentare di \\(x\\).\n\nSe \\(b = 0\\), il grafico √® una retta orizzontale e \\(y\\) rimane costante.\n\nPossiamo dare un‚Äôinterpretazione geometrica ancora pi√π intuitiva se consideriamo variazioni (incrementi) di \\(x\\). Preso un punto \\(x_0\\) e aggiungendo un piccolo incremento \\(\\varepsilon\\), definiamo:\n\\[\n\\Delta x = (x_0 + \\varepsilon) - x_0 = \\varepsilon,\n\\] \\[\n\\Delta y = f(x_0 + \\varepsilon) - f(x_0).\n\\]\nIl coefficiente angolare \\(b\\) pu√≤ essere interpretato come il rapporto tra la variazione di \\(y\\) e la variazione di \\(x\\):\n\\[\nb = \\frac{\\Delta y}{\\Delta x} = \\frac{f(x_0 + \\varepsilon) - f(x_0)}{(x_0 + \\varepsilon) - x_0}.\n\\]\nQuesto rapporto √® costante e non dipende dalla scelta di \\(x_0\\) o di \\(\\varepsilon\\). In particolare, se scegliamo \\(\\Delta x = 1\\), il coefficiente angolare \\(b\\) rappresenta semplicemente di quanto varia \\(y\\) quando \\(x\\) aumenta di un‚Äôunit√†.\n\n\n\n\n\n\n\nFigura¬†86.1: La funzione lineare \\(y = a + bx\\).\n\n\n\nCome mostrato in figura, il coefficiente \\(b\\) indica la pendenza della retta, ossia quanto ‚Äúripida‚Äù √® la sua inclinazione rispetto all‚Äôasse orizzontale.",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>86</span>¬† <span class='chapter-title'>La funzione lineare</span>"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Psicometria",
    "section": "",
    "text": "Benvenuti\nBenvenuti nel sito web dell‚Äôinsegnamento di Psicometria, parte del Corso di Laurea in Scienze e Tecniche Psicologiche dell‚ÄôUniversit√† degli Studi di Firenze.",
    "crumbs": [
      "Benvenuti"
    ]
  },
  {
    "objectID": "index.html#descrizione",
    "href": "index.html#descrizione",
    "title": "Psicometria",
    "section": "Descrizione",
    "text": "Descrizione\nIl corso offre una formazione teorico-pratica nell‚Äôanalisi dei dati psicologici, con particolare attenzione alle applicazioni in R. Vengono affrontati temi come analisi descrittiva, esplorazione dei dati, flusso di lavoro, organizzazione di progetti e modelli statistici di base, sia bayesiani che frequentisti. Grande enfasi √® posta sulle buone pratiche di Open Science, promuovendo trasparenza e riproducibilit√† nelle analisi.\n\nAnno Accademico: 2024-2025\nCodice Insegnamento: B000286\nOrario e Luogo: Luned√¨ e Marted√¨ (8:30-10:30), Gioved√¨ (11:30-13:30), Plesso didattico La Torretta.\n\n\n\n\n\n\n\nQuesto sito web ospita la dispensa ufficiale dell‚Äôinsegnamento¬†B000286 - Psicometria, che include tutte le note e i materiali relativi alle lezioni.",
    "crumbs": [
      "Benvenuti"
    ]
  },
  {
    "objectID": "index.html#struttura-dellinsegnamento",
    "href": "index.html#struttura-dellinsegnamento",
    "title": "Psicometria",
    "section": "Struttura dell‚ÄôInsegnamento",
    "text": "Struttura dell‚ÄôInsegnamento\nIl corso √® strutturato per fornire una solida base teorica e pratica nell‚Äôanalisi dei dati psicologici, combinando approcci metodologici, applicazioni pratiche ed esercitazioni mirate.\n\nIntroduzione a R: Approccio pratico all‚Äôutilizzo di R per l‚Äôanalisi dei dati, con enfasi sulla scrittura di script replicabili e sulla creazione di workflow efficienti.\n\nGestione di Progetti di Analisi: Strategie per organizzare, documentare e comunicare progetti di data analysis, seguendo le buone pratiche della Open Science e della ricerca trasparente.\n\nStatistica Descrittiva: Esplorazione dei dati attraverso misure descrittive, distribuzioni statistiche e visualizzazioni grafiche.\n\nFondamenti di Probabilit√†: Introduzione ai concetti di probabilit√†, distribuzioni e incertezza, come base essenziale per l‚Äôinferenza statistica.\n\nInferenza Frequentista e Bayesiana: Panoramica sui due principali approcci all‚Äôinferenza statistica, con esempi pratici e confronto tra i metodi.\n\nVisualizzazione e Comunicazione: Tecniche avanzate per rappresentare risultati statistici in modo chiaro, efficace e persuasivo, includendo la creazione di report e grafici professionali.\n\nIl corso integra questi argomenti in un percorso didattico coerente, che combina lezioni teoriche, esercitazioni pratiche e momenti di riflessione critica. Gli studenti saranno cos√¨ preparati ad applicare l‚Äôanalisi dei dati sia in contesti accademici che pratici.",
    "crumbs": [
      "Benvenuti"
    ]
  },
  {
    "objectID": "index.html#esercizi",
    "href": "index.html#esercizi",
    "title": "Psicometria",
    "section": "Esercizi",
    "text": "Esercizi\nLe esercitazioni pratiche e gli esempi applicativi sono disponibili sulla pagina Moodle dedicata all‚Äôinsegnamento.",
    "crumbs": [
      "Benvenuti"
    ]
  },
  {
    "objectID": "index.html#syllabus",
    "href": "index.html#syllabus",
    "title": "Psicometria",
    "section": "Syllabus",
    "text": "Syllabus\nConsulta il syllabus completo per ulteriori dettagli.",
    "crumbs": [
      "Benvenuti"
    ]
  },
  {
    "objectID": "chapters/R/07_environment.html",
    "href": "chapters/R/07_environment.html",
    "title": "12¬† L‚Äôambiente di programmazione in R",
    "section": "",
    "text": "12.1 Introduzione\nProgrammare presuppone necessariamente un ambiente di programmazione. Una cattiva gestione di questo ambiente pu√≤ causare il malfunzionamento degli script, rendendo fondamentale imparare a gestirlo correttamente.\nL‚Äôambiente pu√≤ influenzare persino il comportamento delle funzioni pi√π basilari. Considera il seguente esempio:\nQuesto potrebbe produrre il seguente output:\nTuttavia, modificando l‚Äôopzione di larghezza in R, il comportamento cambia:\nIn questo caso, l‚Äôoutput potrebbe essere:\nLa differenza √® dovuta a un‚Äôopzione dell‚Äôambiente, width, che regola il numero massimo di caratteri visualizzati per ogni riga.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>L'ambiente di programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/07_environment.html#introduzione",
    "href": "chapters/R/07_environment.html#introduzione",
    "title": "12¬† L‚Äôambiente di programmazione in R",
    "section": "",
    "text": "Nota: In R, il termine ‚Äúambiente‚Äù ha un significato specifico, riferendosi allo spazio di lavoro in cui gli oggetti vengono memorizzati durante una sessione. In questo capitolo, tuttavia, il termine si riferisce allo stato complessivo del tuo computer mentre programmi, inclusa l‚Äôorganizzazione dei file, la versione di R che stai usando e altre impostazioni.\n\n\nprint(1:9)\n\n[1] 1 2 3 4 5 6 7 8 9\n\n# Dopo aver modificato options(width)\noptions(width = 10)\nprint(1:9)\n\n[1] 1 2 3\n[4] 4 5 6\n[7] 7 8 9",
    "crumbs": [
      "R",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>L'ambiente di programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/07_environment.html#file-system",
    "href": "chapters/R/07_environment.html#file-system",
    "title": "12¬† L‚Äôambiente di programmazione in R",
    "section": "12.2 File system",
    "text": "12.2 File system\nPrima di iniziare a organizzare un progetto in R, √® fondamentale seguire alcune linee guida per strutturare e nominare i file in modo efficace. Spesso si tende a sottovalutare l‚Äôimportanza di una buona organizzazione, ma adottare un sistema coerente pu√≤ far risparmiare tempo prezioso nella ricerca e gestione dei progetti passati. Danielle Navarro ha creato una presentazione sulla struttura dei progetti, nella quale propone tre principi fondamentali per la gestione dei file:\n\nessere gentili con le macchine;\nessere gentili con gli esseri umani;\nfacilitare l‚Äôordinamento e la ricerca.\n\n\n12.2.1 Essere gentili con le macchine\nLe macchine possono confondersi con spazi, caratteri speciali (come ^.*?+|$\"), e lettere accentate. Per evitare problemi:\n\nusa solo lettere minuscole, numeri, trattini _ o -;\nevita caratteri speciali e spazi nei nomi dei file;\nevita le lettere accentate;\nusa estensioni coerenti, come .R per gli script R.\n\nEsempi:\n# Buono\nprogetto01_analisi_dati.R\n\n# Cattivo\nProgetto \"Analisi Dati\".R\n\n\n12.2.2 Essere gentili con gli umani\nGli esseri umani hanno bisogno di contesto. Evita nomi vaghi e usa descrizioni significative.\n# Buono\nanalisi01_statistiche_descrittive.R\nnote02_intro_modello.docx\n\n# Cattivo\n01.R\nappunti.docx\n\n\n\n\n\n\nEvitate categoricamente l‚Äôuso di spazi nei nomi di file, cartelle o oggetti in R. Anche se il sistema operativo potrebbe consentirlo, questa pratica pu√≤ generare problemi futuri, complicare il debugging e rendere il codice meno leggibile e portabile. Per evitare questi inconvenienti, adottate sempre nomi privi di spazi, preferendo separatori come trattini bassi (_) o trattini (-).\n\n\n\n\n\n12.2.3 Facilitare l‚Äôordinamento e la ricerca\nSe i nomi dei file includono date, usa sempre il formato YYYY-MM-DD per permettere un ordinamento automatico.\n# Buono\n2024-01-01_analisi.R\n2024-02-15_riassunto.docx\n\n# Cattivo\n1-gennaio-2024.R\nriassunto-15-02-2024.docx\nSe devi ordinare i file in base a qualcosa di diverso dalle date, usa numeri con lo zero iniziale per mantenere l‚Äôordine.\nreading01_shakespeare_romeo-and-juliet.docx\nreading02_shakespeare_romeo-and-juliet.docx\n...\nreading11_shakespeare_romeo-and-juliet.docx\nnotes01_shakespeare_romeo-and-juliet.docx\n...",
    "crumbs": [
      "R",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>L'ambiente di programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/07_environment.html#versioni-di-r-e-pacchetti",
    "href": "chapters/R/07_environment.html#versioni-di-r-e-pacchetti",
    "title": "12¬† L‚Äôambiente di programmazione in R",
    "section": "12.3 Versioni di R e pacchetti",
    "text": "12.3 Versioni di R e pacchetti\nAggiornare regolarmente R e i pacchetti √® essenziale per evitare bug e sfruttare le nuove funzionalit√†. Ecco alcune buone pratiche:\n\nEsegui update.packages() ogni poche settimane per aggiornare i pacchetti.\nAggiorna la versione di R ogni pochi mesi. Su Windows puoi usare il pacchetto installr, mentre su altri sistemi puoi scaricare l‚Äôultima versione dal sito ufficiale di R.\nMantieni aggiornato anche il sistema operativo.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>L'ambiente di programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/07_environment.html#progetti-in-r",
    "href": "chapters/R/07_environment.html#progetti-in-r",
    "title": "12¬† L‚Äôambiente di programmazione in R",
    "section": "12.4 Progetti in R",
    "text": "12.4 Progetti in R\nSe hai seguito i consigli finora, avrai creato una cartella per tutti i tuoi progetti di programmazione e la tua installazione di R sar√† aggiornata. Ora √® il momento di organizzare i tuoi progetti in R.\n\n12.4.1 Percorsi Assoluti e Relativi\nUn percorso assoluto parte dalla directory principale del tuo computer (ad esempio, / su Linux/MacOS o C:/ su Windows) e indica in modo completo e univoco la posizione di un file o di una cartella. Un percorso relativo, invece, parte dalla directory corrente del progetto o dalla directory di lavoro impostata e descrive la posizione di un file in relazione a questa.\nAd esempio, il percorso assoluto del file utilizzato per generare questa pagina HTML potrebbe essere ottenuto cos√¨:\n\nfs::path_abs(\"05_environment.qmd\")\n#&gt; /Users/corrado/_repositories/psicometria-r/chapters/R/05_environment.qmd",
    "crumbs": [
      "R",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>L'ambiente di programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/07_environment.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/R/07_environment.html#informazioni-sullambiente-di-sviluppo",
    "title": "12¬† L‚Äôambiente di programmazione in R",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] ggokabeito_0.1.0 see_0.9.0        gridExtra_2.3    patchwork_1.3.0 \n#&gt;  [5] bayesplot_1.11.1 psych_2.4.12     scales_1.3.0     markdown_1.13   \n#&gt;  [9] knitr_1.49       lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1   \n#&gt; [13] dplyr_1.1.4      purrr_1.0.2      readr_2.1.5      tidyr_1.3.1     \n#&gt; [17] tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3       \n#&gt; [21] here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.8.9   \n#&gt; [13] mnormt_2.1.1      cli_3.6.3         crayon_1.5.3      rlang_1.1.4      \n#&gt; [17] munsell_0.5.1     withr_3.0.2       yaml_2.3.10       tools_4.4.2      \n#&gt; [21] parallel_4.4.2    tzdb_0.4.0        colorspace_2.1-1  pacman_0.5.1     \n#&gt; [25] vctrs_0.6.5       R6_2.5.1          lifecycle_1.0.4   fs_1.6.5         \n#&gt; [29] htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.1     gtable_0.3.6     \n#&gt; [33] glue_1.8.0        xfun_0.50         tidyselect_1.2.1  farver_2.1.2     \n#&gt; [37] htmltools_0.5.8.1 nlme_3.1-166      rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "R",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>L'ambiente di programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/07_environment.html#bibliografia",
    "href": "chapters/R/07_environment.html#bibliografia",
    "title": "12¬† L‚Äôambiente di programmazione in R",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nYu, B., & Barter, R. L. (2024). Veridical data science: The practice of responsible data analysis and decision making. MIT Press.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>L'ambiente di programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/07_environment.html#funzione-here",
    "href": "chapters/R/07_environment.html#funzione-here",
    "title": "12¬† L‚Äôambiente di programmazione in R",
    "section": "12.5 Funzione here()",
    "text": "12.5 Funzione here()\nSe il progetto si trova nella cartella psicometria-r, possiamo utilizzare la funzione here() del pacchetto here per indicare la posizione del file 05_environment.qmd in modo relativo. Ecco un esempio:\n\nfile.exists(here::here(\"chapters\", \"R\", \"07_environment.qmd\"))\n#&gt; [1] TRUE\n\nIn questo caso, il file 07_environment.qmd √® contenuto nella cartella chapters/R, che si trova all‚Äôinterno della directory principale del progetto. Grazie a here(), non √® necessario specificare manualmente la posizione del progetto: questa funzione identifica automaticamente la directory principale e consente di indicare solo il percorso relativo del file rispetto ad essa. In altre parole, puoi riferirti al file 07_environment.qmd semplicemente fornendo il percorso relativo all‚Äôinterno della struttura del progetto, lasciando a here() il compito di gestire il contesto globale.\n\n12.5.1 Perch√© preferire i percorsi relativi?\nL‚Äôutilizzo di percorsi relativi con here() offre numerosi vantaggi:\n\nPortabilit√†: Il codice diventa pi√π semplice da condividere, poich√© non dipende dalla struttura delle directory specifica del computer su cui √® stato scritto.\nOrganizzazione: Favorisce una struttura chiara e coerente all‚Äôinterno del progetto, rendendo pi√π facile individuare e accedere ai file.\nAffidabilit√†: Riduce il rischio di errori dovuti a percorsi assoluti errati, soprattutto quando il progetto viene spostato o condiviso.\n\n\n\n12.5.2 Buone pratiche\n\nUsare sempre percorsi relativi: Questo assicura che il progetto sia facilmente eseguibile su altri sistemi senza necessit√† di modifiche ai percorsi.\nImpostare una struttura coerente del progetto: Organizzare i file in cartelle ben definite (ad esempio, data, scripts, outputs) facilita l‚Äôuso di percorsi relativi.\n\nIn sintesi, specificare i percorsi relativi rispetto alla directory principale del progetto √® una buona pratica essenziale per garantire portabilit√†, organizzazione e riproducibilit√† del lavoro.\n\n\n12.5.3 Creare un progetto in R\nUn progetto R √® semplicemente una cartella con un file .Rproj. Puoi crearne uno con RStudio o con il pacchetto usethis.\nIn RStudio:\n\nVai su File &gt; New Project.\nSeleziona New Directory &gt; New Project.\nDai un nome al progetto e scegli la sua posizione.\n\nCon usethis:\nusethis::create_project(\"path/alla/cartella\")\nEsempio:\nusethis::create_project(\"/Users/corrado/_repositories\")\nVedremo nel Capitolo 14 come organizzare i file all‚Äôinterno di un progetto.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>L'ambiente di programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/07_environment.html#creare-un-progetto-in-r",
    "href": "chapters/R/07_environment.html#creare-un-progetto-in-r",
    "title": "12¬† L‚Äôambiente di programmazione in R",
    "section": "12.6 Creare un progetto in R",
    "text": "12.6 Creare un progetto in R\nUn progetto R √® semplicemente una cartella con un file .Rproj. Puoi crearne uno con RStudio o con il pacchetto usethis.\nIn RStudio:\n\nVai su File &gt; New Project.\nSeleziona New Directory &gt; New Project.\nDai un nome al progetto e scegli la sua posizione.\n\nCon usethis:\nusethis::create_project(\"path/alla/cartella\")\nEsempio:\nusethis::create_project(\"/Users/corradocaudek/_repositories\")\nVedremo nel Capitolo 14 come organizzare i file all‚Äôinterno di un progetto.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>L'ambiente di programmazione in R</span>"
    ]
  }
]