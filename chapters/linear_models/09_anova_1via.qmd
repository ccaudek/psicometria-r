# ANOVA ad una via {#sec-anova1via}

::: callout-important
## In questo capitolo imparerai a

- fare inferenza sulla media di un campione;
- trovare le distribuzioni a posteriori usando `brms`;
- verificare il modello usando i pp-check plots.
:::

::: callout-tip
## Prerequisiti

- Leggere il capitolo *Geocentric models* di Statistical rethinking [@McElreath_rethinking].
:::

::: .callout-caution
## Preparazione del Notebook

```{r}
here::here("code", "_common.R") |> 
  source()

# Load packages
if (!requireNamespace("pacman")) install.packages("pacman")
pacman::p_load(cmdstanr, posterior, bayestestR, brms, emmeans)
```
:::

## Introduzione

Nel @sec-linear-models-two-groups abbiamo visto come rappresentare **fattori a due livelli** mediante **variabili dummy**, per includere effetti categoriali all'interno di un modello lineare. In questa sezione estendiamo tale approccio al caso in cui un singolo fattore abbia **più di due categorie**.

Supponiamo, ad esempio, di voler analizzare un fattore con **tre gruppi**. In questo caso possiamo utilizzare due variabili dummy per rappresentare le prime due categorie, e assumere implicitamente la terza come **categoria di riferimento**. Il modello lineare diventa:

$$
Y_i = \alpha + \gamma_1 D_{i1} + \gamma_2 D_{i2} + \varepsilon_i
$$ {#eq-anova1}

dove:

* $\alpha$ è l’intercetta del modello,
* $\gamma_1$ e $\gamma_2$ sono i coefficienti associati alle variabili dummy,
* $D_{i1}$ e $D_{i2}$ indicano l’appartenenza dell’osservazione $i$ ai gruppi 1 e 2, rispettivamente,
* $\varepsilon_i$ è l’errore aleatorio.

La seguente tabella mostra come codificare le dummy per ciascun gruppo:

$$
\begin{array}{c|cc}
\text{Gruppo} & D_{1} & D_{2} \\
\hline
1 & 1 & 0 \\
2 & 0 & 1 \\
3 & 0 & 0
\end{array}
$$ {#eq-anova1a}

### Significato dei parametri

L’obiettivo è stimare le **medie di popolazione** per ciascun gruppo, indicate con $\mu_j$ per il gruppo $j$. Poiché l’errore $\varepsilon$ ha media zero, possiamo calcolare l’aspettativa del modello per ciascun gruppo:

$$
\begin{aligned}
\text{Gruppo 1: } \mu_1 &= \mathbb{E}(Y \mid D_1 = 1, D_2 = 0) = \alpha + \gamma_1 \\
\text{Gruppo 2: } \mu_2 &= \mathbb{E}(Y \mid D_1 = 0, D_2 = 1) = \alpha + \gamma_2 \\
\text{Gruppo 3: } \mu_3 &= \mathbb{E}(Y \mid D_1 = 0, D_2 = 0) = \alpha
\end{aligned}
$$ {#eq-anova1b}

Queste espressioni mostrano come i coefficienti del modello siano **relativi alla categoria di riferimento**, cioè il Gruppo 3. Possiamo dunque esprimere i parametri del modello in funzione delle medie di gruppo:

$$
\alpha = \mu_3, \quad \gamma_1 = \mu_1 - \mu_3, \quad \gamma_2 = \mu_2 - \mu_3 .
$$ {#eq-anova1c}

In sintesi:

* $\alpha$ rappresenta la media del **gruppo di riferimento** (Gruppo 3),
* $\gamma_1$ è la **differenza tra la media del Gruppo 1 e quella del Gruppo 3**,
* $\gamma_2$ è la **differenza tra la media del Gruppo 2 e quella del Gruppo 3**.

Questa struttura rende il modello facilmente interpretabile: i coefficienti delle dummy indicano quanto ciascun gruppo si discosta dalla categoria di riferimento, mentre l’intercetta fornisce direttamente la media di quest’ultima. Questo schema può essere esteso a fattori con un numero arbitrario di categorie.

## Simulazione

Per illustrare il funzionamento di un modello con un fattore a tre livelli, simuliamo un dataset con tre condizioni sperimentali: `controllo`, `psicoterapia1` e `psicoterapia2`. Supponiamo che ogni gruppo abbia una diversa media, ma la stessa deviazione standard:

```{r}
set.seed(123)

n <- 30  # numero di osservazioni per gruppo

# Medie di ciascun gruppo
mean_control <- 30
mean_psico1  <- 25
mean_psico2  <- 20

# Deviazione standard comune
sd_value <- 5

# Generazione dei dati
controllo     <- rnorm(n, mean_control, sd_value)
psicoterapia1 <- rnorm(n, mean_psico1,  sd_value)
psicoterapia2 <- rnorm(n, mean_psico2,  sd_value)

# Creazione del data frame
df <- data.frame(
  condizione = rep(c("controllo", "psicoterapia1", "psicoterapia2"), each = n),
  punteggio  = c(controllo, psicoterapia1, psicoterapia2)
)

df |> head()
```

### Esplorazione dei dati

Visualizziamo le distribuzioni con un violin plot arricchito da un boxplot:

```{r}
ggplot(df, aes(x = condizione, y = punteggio, fill = condizione)) +
  geom_violin(trim = FALSE) +
  geom_boxplot(width = 0.2, outlier.shape = NA) +
  labs(
    title = "Distribuzione dei punteggi di depressione per gruppo",
    x = "Condizione sperimentale",
    y = "Punteggio di depressione"
  ) +
  theme(legend.position = "none")
```

Calcoliamo media e deviazione standard per ogni gruppo:

```{r}
df |> 
  group_by(condizione) |> 
  summarize(
    media = mean(punteggio),
    sd = sd(punteggio)
  )
```


## Codifica con variabili dummy

Convertiamo `condizione` in fattore e definiamo `controllo` come categoria di riferimento:

```{r}
df$condizione <- factor(df$condizione)
df$condizione <- relevel(df$condizione, ref = "controllo")
contrasts(df$condizione)
```

Il modello di regressione con dummy sarà:

$$
Y_i = \beta_0 + \beta_1 \cdot \text{psicoterapia1}_i + \beta_2 \cdot \text{psicoterapia2}_i + \varepsilon_i,
$$

dove:

* $\beta_0$ è la media del gruppo di **controllo**;
* $\beta_1$ e $\beta_2$ sono le differenze tra le rispettive psicoterapie e il gruppo di controllo.

### Stima del modello

Eseguiamo una prima analisi usando il metodo di massima verosimiglianza:

```{r}
fm1 <- lm(punteggio ~ condizione, data = df)
```

```{r}
summary(fm1)
```

Verifica delle medie e differenze tra gruppi:

```{r}
out <- tapply(df$punteggio, df$condizione, mean)
out[2] - out[1]  # psicoterapia1 - controllo
out[3] - out[1]  # psicoterapia2 - controllo
```

## Contrasti personalizzati

L’uso di contrasti personalizzati ci permette di testare ipotesi più specifiche. Ad esempio:

* **contrasto 1**: controllare se la media del gruppo `controllo` differisce dalla media combinata delle due psicoterapie;
* **contrasto 2**: confrontare direttamente `psicoterapia1` con `psicoterapia2`.

### Matrice dei contrasti

```{r}
my_contrasts <- matrix(c(
  0.6667,  0,     # controllo
 -0.3333,  0.5,   # psicoterapia1
 -0.3333, -0.5    # psicoterapia2
), ncol = 2, byrow = TRUE)

colnames(my_contrasts) <- c("Ctrl_vs_PsicoMean", "P1_vs_P2")
rownames(my_contrasts) <- c("controllo", "psicoterapia1", "psicoterapia2")

contrasts(df$condizione) <- my_contrasts
```

```{r}
mod_custom <- lm(punteggio ~ condizione, data = df)
```

```{r}
summary(mod_custom)
```

## Interpretazione dei coefficienti

* **Intercetta**: non rappresenta più una singola media, ma una combinazione lineare dei gruppi.
* **Ctrl\_vs\_PsicoMean**: confronta la media di `controllo` con la media combinata delle due psicoterapie.
* **P1\_vs\_P2**: differenza tra le due psicoterapie.

Verifica manuale:

```{r}
# Controllo - media delle psicoterapie
out[1] - (out[2] + out[3]) / 2
```

```{r}
# Psicoterapia1 - Psicoterapia2
out[2] - out[3]
```

## Uso del pacchetto `emmeans`

Il pacchetto `emmeans` consente di ottenere gli stessi risultati in modo più diretto e modulare.

### Stima con `brms`

Usiamo ora `emmeans` con `brms`:

```{r}
#| output: false
#| 
mod <- brm(punteggio ~ condizione, data = df, backend = "cmdstanr")
```

```{r}
summary(mod)
```

### Calcolo delle medie marginali

```{r}
em <- emmeans(mod, specs = "condizione")
em
```

### Confronti tra gruppi

```{r}
pairs(em)  # confronti a coppie
```

### Contrasti personalizzati con `emmeans`

```{r}
my_list <- list(
  "Ctrl_vs_PsicoMean" = c(
    "controllo" = 1, "psicoterapia1" = -0.5, "psicoterapia2" = -0.5
  ),
  "P1_vs_P2" = c(
    "controllo" = 0, "psicoterapia1" = 1, "psicoterapia2" = -1
  )
)
```

```{r}
contrast(em, method = my_list)
```

```{r}
# Visualizzazione
plot(em)
```

## Riflessioni Conclusive

Un’ANOVA a una via può essere vista come un caso speciale di regressione lineare, applicato a un fattore con più di due livelli. L’elemento più informativo dell’analisi non è tanto la verifica globale dell’effetto del fattore, ma l’esplorazione mirata di **contrasti specifici tra le medie**.

La possibilità di definire **contrasti personalizzati**, come quelli che confrontano un singolo gruppo con la media degli altri, oppure due gruppi tra loro, permette di rispondere a **domande teoriche mirate**. Questo approccio si integra perfettamente con il framework bayesiano, in cui i contrasti possono essere interpretati in termini di **probabilità a posteriori**, anziché solo di significatività.

Il pacchetto `emmeans` rende questo processo ancora più accessibile, offrendo strumenti per:

* calcolare medie marginali stimate;
* specificare contrasti personalizzati;
* ottenere intervalli di confidenza (o credibilità) e p-value corretti.

In definitiva, l’uso combinato di regressione, contrasti e strumenti come `emmeans` o `brms` fornisce un approccio potente, flessibile e interpretabile per analizzare l’effetto di fattori categoriali in modelli lineari.

## Informazioni sull'Ambiente di Sviluppo {.unnumbered} 

```{r}
sessionInfo()
```

## Bibliografia {.unnumbered}

