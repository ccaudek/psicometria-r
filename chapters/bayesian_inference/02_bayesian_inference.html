<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="it" xml:lang="it"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<meta name="author" content="Corrado Caudek">
<title>42&nbsp; Inferenza bayesiana</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>

<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../chapters/bayesian_inference/03_subj_prop.html" rel="next">
<link href="../../chapters/bayesian_inference/01_intro_bayes.html" rel="prev">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-f7890bc79a3f65ef06a5b1c5352a79fb.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark-977d937b251e2ed3bf977ac42bcf4d56.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-d49b56d3e35d452f999b5a62cbdb201d.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark-744dfb578d2f27956ecc45a15ae97852.min.css" rel="prefetch" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Nessun risultato",
    "search-matching-documents-text": "documenti trovati",
    "search-copy-link-title": "Copiare il link nella ricerca",
    "search-hide-matches-text": "Nascondere i risultati aggiuntivi",
    "search-more-match-text": "ci sono altri risultati in questo documento",
    "search-more-matches-text": "ulteriori risultati in questo documento",
    "search-clear-button-title": "Pulire",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancellare",
    "search-submit-button-title": "Inviare",
    "search-label": "Ricerca"
  }
}</script><script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script><script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>
</head>
<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Attiva/disattiva la barra laterale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../chapters/bayesian_inference/introduction_bayes_inference.html">Inferenza</a></li><li class="breadcrumb-item"><a href="../../chapters/bayesian_inference/02_bayesian_inference.html"><span class="chapter-number">42</span>&nbsp; <span class="chapter-title">Inferenza bayesiana</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Attiva/disattiva la barra laterale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Ricerca" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../../">Psicometria</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/ccaudek/psicometria-r/" title="Eseguire il codice" class="quarto-navigation-tool px-1" aria-label="Eseguire il codice"><i class="bi bi-github"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Attiva/disattiva la modalità oscura"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Attiva/disattiva la modalità lettore">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Ricerca"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Benvenuti</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../prefazione.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Prefazione</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false">
 <span class="menu-text">Calendario</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../programmazione2024.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Incontri</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../chapters/key_notions/introduction_key_notions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Fondamenti</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/key_notions/01_uncertainty.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Abbracciare l’incertezza</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/key_notions/02_key_notions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Concetti chiave</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/key_notions/03_design.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Campionamento, metodologia sperimentale e studi osservazionali</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/key_notions/04_measurement.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">La misurazione in psicologia</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/key_notions/05_data_analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../chapters/R/introduction_r_lang.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">R</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/R/01_r_syntax.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Data Science e R: un approccio moderno all’analisi dei dati</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/R/02_utility_functions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Utility functions in R</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/R/03_r_programming.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Programmazione in R</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/R/04_r_packages.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Pacchetti in R</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/R/05_dplyr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Introduzione a <code>dplyr</code></span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/R/06_quarto.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Quarto</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/R/07_environment.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">L’ambiente di programmazione in R</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/R/08_ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Utilizzo di strumenti AI per la programmazione</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../chapters/eda/introduction_eda.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">EDA</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/01_project_structure.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Le fasi del progetto di analisi dei dati</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/02_data_cleaning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Flusso di lavoro per la pulizia dei dati</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/04_exploring_qualitative_data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Esplorare i dati qualitativi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/05_exploring_numeric_data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Esplorare i dati numerici</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/06_data_visualization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Principi della visualizzazione dei dati</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/07_loc_scale.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Indicatori di tendenza centrale e variabilità</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/08_correlation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Relazioni tra variabili</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/09_causality.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Causalità dai dati osservazionali 🔸</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/10_estimand.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Estimandi teorici e estimandi empirici 🔸</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/11_outlier.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Outlier</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/12_pixi.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Flusso di lavoro riproducibile 🔸</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../chapters/probability/introduction_probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Probabilità</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/01_intro_prob.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Interpretazione della probabilità</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/02_prob_spaces.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Misura di Probabilità</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/03_prob_on_general_spaces.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Fondamenti della probabilità</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/04_conditional_prob.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Probabilità condizionata</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/05_random_var.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Variabili casuali</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/06_expval_var.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Proprietà delle variabili casuali</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/07_bayes_theorem.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">Il teorema di Bayes</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/08_sampling_distr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">Stime, stimatori e parametri</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/09_joint_prob.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">34</span>&nbsp; <span class="chapter-title">Probabilità congiunta</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/10_prob_distributions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">35</span>&nbsp; <span class="chapter-title">Distribuzioni di massa e di densità</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/11_discr_rv_distr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">36</span>&nbsp; <span class="chapter-title">Distribuzioni di v.c. discrete</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/12_cont_rv_distr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">37</span>&nbsp; <span class="chapter-title">Distribuzioni di v.c. continue</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/13_gauss.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">38</span>&nbsp; <span class="chapter-title">Assunzione di gaussianità e trasformazioni dei dati</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/14_likelihood.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">39</span>&nbsp; <span class="chapter-title">La verosimiglianza</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/15_simulation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">40</span>&nbsp; <span class="chapter-title">Simulazioni</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">Inferenza</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/introduction_bayes_inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/01_intro_bayes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">41</span>&nbsp; <span class="chapter-title">La quantificazione dell’incertezza</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/02_bayesian_inference.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">42</span>&nbsp; <span class="chapter-title">Inferenza bayesiana</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/03_subj_prop.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">43</span>&nbsp; <span class="chapter-title">Pensare ad una proporzione in termini soggettivi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/04_grid_gauss.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">44</span>&nbsp; <span class="chapter-title">Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/05_conjugate_families_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">45</span>&nbsp; <span class="chapter-title">Distribuzioni coniugate (1)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/06_conjugate_families_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">46</span>&nbsp; <span class="chapter-title">Distribuzioni coniugate (2)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/07_summary_posterior.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">47</span>&nbsp; <span class="chapter-title">Sintesi a posteriori</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/08_balance_prior_post.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">48</span>&nbsp; <span class="chapter-title">L’influenza della distribuzione a priori</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/09_gamma_poisson_model.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">49</span>&nbsp; <span class="chapter-title">Modello coniugato Gamma-Poisson 🔸</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/10_gamma_exponential_model.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">50</span>&nbsp; <span class="chapter-title">Modello gamma-esponenziale 🔸</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/11_post_pred_distr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">51</span>&nbsp; <span class="chapter-title">Distribuzione predittiva a posteriori</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="false">
 <span class="menu-text">MCMC</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/introduction_mcmc.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/01_metropolis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">52</span>&nbsp; <span class="chapter-title">L’algoritmo di Metropolis-Hastings</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/02_ppl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">53</span>&nbsp; <span class="chapter-title">Linguaggi di programmazione probabilistici</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/03_stan_language.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">54</span>&nbsp; <span class="chapter-title">Linguaggio Stan 🔸</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/04_stan_summary_posterior.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">55</span>&nbsp; <span class="chapter-title">Metodi di sintesi della distribuzione a posteriori 🔸</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/06_mcmc_prediction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">56</span>&nbsp; <span class="chapter-title">La predizione bayesiana 🔸</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/07_bayesian_workflow.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">57</span>&nbsp; <span class="chapter-title">Flusso di lavoro bayesiano</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/18_cmdstanr_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">58</span>&nbsp; <span class="chapter-title">Introduzione a CmdStanR 🔸</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="false">
 <span class="menu-text">Regressione</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/introduction_linear_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/01_reglin_frequentist.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">59</span>&nbsp; <span class="chapter-title">La regressione lineare bivariata: un approccio frequentista</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/02_reglin_bayes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">60</span>&nbsp; <span class="chapter-title">Modello bayesiano di regressione lineare bivariata</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/03_synt_sugar.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">61</span>&nbsp; <span class="chapter-title">Zucchero sintattico</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/04_one_mean.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">62</span>&nbsp; <span class="chapter-title">Inferenza bayesiana su una media</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/05_one_mean_stan.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">63</span>&nbsp; <span class="chapter-title">Inferenza bayesiana su una media (Stan) 🔸</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/06_prediction_stan.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">64</span>&nbsp; <span class="chapter-title">Predizione e inferenza 🔸</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/07_two_means.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">65</span>&nbsp; <span class="chapter-title">Confronto tra le medie di due gruppi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/08_two_means_stan.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">66</span>&nbsp; <span class="chapter-title">Confronto tra due gruppi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/09_sample_size.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">67</span>&nbsp; <span class="chapter-title">Disegno della ricerca e potere statistico</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/10_anova_1via.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">68</span>&nbsp; <span class="chapter-title">ANOVA ad una via</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/11_anova_2vie.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">69</span>&nbsp; <span class="chapter-title">ANOVA ad due vie</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="false">
 <span class="menu-text">Entropia</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/entropy/introduction_entropy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/entropy/01_entropy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">70</span>&nbsp; <span class="chapter-title">Entropia</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="false">
 <span class="menu-text">Frequentismo</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/frequentist_inference/introduction_frequentist_inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/frequentist_inference/01_intro_frequentist.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">71</span>&nbsp; <span class="chapter-title">Introduzione all’inferenza frequentista</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/frequentist_inference/02_conf_interv.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">72</span>&nbsp; <span class="chapter-title">Intervalli di fiducia</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/frequentist_inference/03_sample_size.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">73</span>&nbsp; <span class="chapter-title">La grandezza del campione</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/frequentist_inference/04_test_ipotesi.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">74</span>&nbsp; <span class="chapter-title">Significatività statistica</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/frequentist_inference/05_two_ind_samples.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">75</span>&nbsp; <span class="chapter-title">Test t di Student per campioni indipendenti</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="false">
 <span class="menu-text">Crisi</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-11" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/introduction_replication_crisis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/01_crisis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">76</span>&nbsp; <span class="chapter-title">La crisi della replicazione</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/02_limits_stat_freq.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">77</span>&nbsp; <span class="chapter-title">Limiti dell’inferenza frequentista</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/03_effect_size.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">78</span>&nbsp; <span class="chapter-title">La grandezza dell’effetto</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/04_s_m_errors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">79</span>&nbsp; <span class="chapter-title">Errori di segno e errori di grandezza</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/05_p_values.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">80</span>&nbsp; <span class="chapter-title">La fragilità del <em>p</em>-valore</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/06_changes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">81</span>&nbsp; <span class="chapter-title">Riforma</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/07_piranha.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">82</span>&nbsp; <span class="chapter-title">Il Problema del priming: sfide e paradossi nella psicologia sociale</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/08_integrity.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">83</span>&nbsp; <span class="chapter-title">Integrità della ricerca</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="false">
 <span class="menu-text">Epilogo</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-12" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/epiloque/epiloque.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Considerazioni Conclusive</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" role="navigation" aria-expanded="false">
 <span class="menu-text">Appendice</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-13" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a02_shell.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">84</span>&nbsp; <span class="chapter-title">La Shell</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a10_math_symbols.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">85</span>&nbsp; <span class="chapter-title">Simbologia di base</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a11_numbers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">86</span>&nbsp; <span class="chapter-title">Numeri e intervalli</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a12_sum_notation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">87</span>&nbsp; <span class="chapter-title">Sommatorie</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a13_sets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">88</span>&nbsp; <span class="chapter-title">Insiemi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a14_combinatorics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">89</span>&nbsp; <span class="chapter-title">Calcolo combinatorio</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a15_calculus.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">90</span>&nbsp; <span class="chapter-title">Per liberarvi dai terrori preliminari</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a44_montecarlo.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">91</span>&nbsp; <span class="chapter-title">Simulazione Monte Carlo</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a46_stan_lang.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">92</span>&nbsp; <span class="chapter-title">Linguaggio Stan</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a50_lin_fun.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">93</span>&nbsp; <span class="chapter-title">La funzione lineare</span></span></a>
  </div>
</li>
      </ul>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Indice</h2>
   
  <ul>
<li><a href="#introduzione" id="toc-introduzione" class="nav-link active" data-scroll-target="#introduzione"><span class="header-section-number">42.1</span> Introduzione</a></li>
  <li>
<a href="#paradigma-bayesiano" id="toc-paradigma-bayesiano" class="nav-link" data-scroll-target="#paradigma-bayesiano"><span class="header-section-number">42.2</span> Paradigma Bayesiano</a>
  <ul class="collapse">
<li><a href="#vantaggi-dellapproccio-bayesiano" id="toc-vantaggi-dellapproccio-bayesiano" class="nav-link" data-scroll-target="#vantaggi-dellapproccio-bayesiano"><span class="header-section-number">42.2.1</span> Vantaggi dell’Approccio Bayesiano</a></li>
  </ul>
</li>
  <li>
<a href="#densit%C3%A0-di-probabilit%C3%A0" id="toc-densità-di-probabilità" class="nav-link" data-scroll-target="#densit%C3%A0-di-probabilit%C3%A0"><span class="header-section-number">42.3</span> Densità di Probabilità</a>
  <ul class="collapse">
<li><a href="#le-regole-di-somma-e-prodotto" id="toc-le-regole-di-somma-e-prodotto" class="nav-link" data-scroll-target="#le-regole-di-somma-e-prodotto"><span class="header-section-number">42.3.1</span> Le Regole di Somma e Prodotto</a></li>
  <li><a href="#la-distribuzione-marginale" id="toc-la-distribuzione-marginale" class="nav-link" data-scroll-target="#la-distribuzione-marginale"><span class="header-section-number">42.3.2</span> La Distribuzione Marginale</a></li>
  <li><a href="#il-teorema-di-bayes" id="toc-il-teorema-di-bayes" class="nav-link" data-scroll-target="#il-teorema-di-bayes"><span class="header-section-number">42.3.3</span> Il Teorema di Bayes</a></li>
  <li><a href="#modellizzazione-e-inferenza-bayesiana" id="toc-modellizzazione-e-inferenza-bayesiana" class="nav-link" data-scroll-target="#modellizzazione-e-inferenza-bayesiana"><span class="header-section-number">42.3.4</span> Modellizzazione e Inferenza Bayesiana</a></li>
  <li><a href="#il-modello-osservazionale" id="toc-il-modello-osservazionale" class="nav-link" data-scroll-target="#il-modello-osservazionale"><span class="header-section-number">42.3.5</span> Il Modello Osservazionale</a></li>
  <li><a href="#la-distribuzione-a-priori" id="toc-la-distribuzione-a-priori" class="nav-link" data-scroll-target="#la-distribuzione-a-priori"><span class="header-section-number">42.3.6</span> La Distribuzione a Priori</a></li>
  <li><a href="#inferenza-sui-parametri" id="toc-inferenza-sui-parametri" class="nav-link" data-scroll-target="#inferenza-sui-parametri"><span class="header-section-number">42.3.7</span> Inferenza sui Parametri</a></li>
  <li><a href="#inferenza-bayesiana-in-sintesi-verosimiglianza-prior-posteriore" id="toc-inferenza-bayesiana-in-sintesi-verosimiglianza-prior-posteriore" class="nav-link" data-scroll-target="#inferenza-bayesiana-in-sintesi-verosimiglianza-prior-posteriore"><span class="header-section-number">42.3.8</span> Inferenza bayesiana in sintesi: verosimiglianza, prior, posteriore</a></li>
  <li><a href="#il-ruolo-dei-priors" id="toc-il-ruolo-dei-priors" class="nav-link" data-scroll-target="#il-ruolo-dei-priors"><span class="header-section-number">42.3.9</span> Il Ruolo dei Priors</a></li>
  </ul>
</li>
  <li><a href="#inferenza-predittiva" id="toc-inferenza-predittiva" class="nav-link" data-scroll-target="#inferenza-predittiva"><span class="header-section-number">42.4</span> Inferenza Predittiva</a></li>
  <li>
<a href="#come-possiamo-eseguire-linferenza-bayesiana" id="toc-come-possiamo-eseguire-linferenza-bayesiana" class="nav-link" data-scroll-target="#come-possiamo-eseguire-linferenza-bayesiana"><span class="header-section-number">42.5</span> Come possiamo eseguire l’inferenza bayesiana?</a>
  <ul class="collapse">
<li><a href="#metodi-numerici" id="toc-metodi-numerici" class="nav-link" data-scroll-target="#metodi-numerici"><span class="header-section-number">42.5.1</span> Metodi Numerici</a></li>
  </ul>
</li>
  <li>
<a href="#programmazione-probabilistica" id="toc-programmazione-probabilistica" class="nav-link" data-scroll-target="#programmazione-probabilistica"><span class="header-section-number">42.6</span> Programmazione Probabilistica</a>
  <ul class="collapse">
<li><a href="#vantaggi-della-programmazione-probabilistica-in-psicologia" id="toc-vantaggi-della-programmazione-probabilistica-in-psicologia" class="nav-link" data-scroll-target="#vantaggi-della-programmazione-probabilistica-in-psicologia"><span class="header-section-number">42.6.1</span> Vantaggi della Programmazione Probabilistica in Psicologia</a></li>
  <li><a href="#come-funzionano-i-ppl" id="toc-come-funzionano-i-ppl" class="nav-link" data-scroll-target="#come-funzionano-i-ppl"><span class="header-section-number">42.6.2</span> Come Funzionano i PPL?</a></li>
  </ul>
</li>
  <li><a href="#notazione" id="toc-notazione" class="nav-link" data-scroll-target="#notazione"><span class="header-section-number">42.7</span> Notazione</a></li>
  <li><a href="#addendum-la-verosimiglianza-marginale" id="toc-addendum-la-verosimiglianza-marginale" class="nav-link" data-scroll-target="#addendum-la-verosimiglianza-marginale"><span class="header-section-number">42.8</span> Addendum: La Verosimiglianza Marginale</a></li>
  <li>
<a href="#implementazione-in-r" id="toc-implementazione-in-r" class="nav-link" data-scroll-target="#implementazione-in-r"><span class="header-section-number">42.9</span> Implementazione in R</a>
  <ul class="collapse">
<li><a href="#caso-discreto" id="toc-caso-discreto" class="nav-link" data-scroll-target="#caso-discreto"><span class="header-section-number">42.9.1</span> Caso discreto</a></li>
  <li><a href="#caso-continuo" id="toc-caso-continuo" class="nav-link" data-scroll-target="#caso-continuo"><span class="header-section-number">42.9.2</span> Caso continuo</a></li>
  <li><a href="#caso-continuo-con-prior-beta" id="toc-caso-continuo-con-prior-beta" class="nav-link" data-scroll-target="#caso-continuo-con-prior-beta"><span class="header-section-number">42.9.3</span> Caso continuo con prior Beta</a></li>
  </ul>
</li>
  <li><a href="#riflessioni-conclusive" id="toc-riflessioni-conclusive" class="nav-link" data-scroll-target="#riflessioni-conclusive"><span class="header-section-number">42.10</span> Riflessioni Conclusive</a></li>
  <li><a href="#informazioni-sullambiente-di-sviluppo" id="toc-informazioni-sullambiente-di-sviluppo" class="nav-link" data-scroll-target="#informazioni-sullambiente-di-sviluppo">Informazioni sull’Ambiente di Sviluppo</a></li>
  <li><a href="#bibliografia" id="toc-bibliografia" class="nav-link" data-scroll-target="#bibliografia">Bibliografia</a></li>
  </ul><div class="toc-actions"><ul><li><a href="https://github.com/ccaudek/psicometria-r/blob/main/chapters/bayesian_inference/02_bayesian_inference.qmd" class="toc-action"><i class="bi bi-github"></i>Mostra il codice</a></li><li><a href="https://github.com/ccaudek/psicometria-r/issues/new" class="toc-action"><i class="bi empty"></i>Segnala un problema</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../chapters/bayesian_inference/introduction_bayes_inference.html">Inferenza</a></li><li class="breadcrumb-item"><a href="../../chapters/bayesian_inference/02_bayesian_inference.html"><span class="chapter-number">42</span>&nbsp; <span class="chapter-title">Inferenza bayesiana</span></a></li></ol></nav><div class="quarto-title">
<h1 class="title"><span id="sec-bayes-inference" class="quarto-section-identifier"><span class="chapter-number">42</span>&nbsp; <span class="chapter-title">Inferenza bayesiana</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header><p><strong>Prerequisiti</strong></p>
<ul>
<li>Leggere il capitolo <em>Bayes’ Rule</em> del testo di <span class="citation" data-cites="Johnson2022bayesrules">Johnson et al. (<a href="#ref-Johnson2022bayesrules" role="doc-biblioref">2022</a>)</span>.</li>
</ul>
<p><strong>Concetti e Competenze Chiave</strong></p>
<ul>
<li>Distribuzione marginale.</li>
<li>Approccio analitico e numerico per determinare la distribuzione a posteriori.</li>
<li>Linguaggi di programmazione probabilistici.</li>
<li>Inferenza predittiva.</li>
</ul>
<p><strong>Preparazione del Notebook</strong></p>
<div class="cell">
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">here</span><span class="fu">::</span><span class="fu"><a href="https://here.r-lib.org//reference/here.html">here</a></span><span class="op">(</span><span class="st">"code"</span>, <span class="st">"_common.R"</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/source.html">source</a></span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Load packages</span></span>
<span><span class="kw">if</span> <span class="op">(</span><span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/base/ns-load.html">requireNamespace</a></span><span class="op">(</span><span class="st">"pacman"</span><span class="op">)</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/utils/install.packages.html">install.packages</a></span><span class="op">(</span><span class="st">"pacman"</span><span class="op">)</span></span>
<span><span class="fu">pacman</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/pacman/man/p_load.html">p_load</a></span><span class="op">(</span><span class="va">mice</span><span class="op">)</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="introduzione" class="level2" data-number="42.1"><h2 data-number="42.1" class="anchored" data-anchor-id="introduzione">
<span class="header-section-number">42.1</span> Introduzione</h2>
<p>Questo capitolo approfondisce i concetti introdotti nel capitolo precedente, presentando l’aggiornamento bayesiano in modo più formale e dettagliato.</p>
</section><section id="paradigma-bayesiano" class="level2" data-number="42.2"><h2 data-number="42.2" class="anchored" data-anchor-id="paradigma-bayesiano">
<span class="header-section-number">42.2</span> Paradigma Bayesiano</h2>
<p>L’approccio bayesiano alla statistica si fonda sull’idea di rappresentare la conoscenza a priori sui parametri che governano un fenomeno attraverso distribuzioni di probabilità. Queste distribuzioni a priori riflettono le credenze iniziali del ricercatore riguardo ai parametri, prima di osservare i dati. Quando nuovi dati vengono raccolti, l’informazione fornita da tali dati viene integrata nel modello tramite la funzione di verosimiglianza, che rappresenta la probabilità di osservare quei dati dati i parametri ipotizzati.</p>
<p>Attraverso l’applicazione del Teorema di Bayes, le credenze a priori vengono aggiornate combinando la distribuzione a priori con la verosimiglianza dei dati. Questo processo produce la distribuzione a posteriori, che rappresenta una nuova e più informata stima dei parametri, tenendo conto sia delle credenze iniziali sia dei dati osservati.</p>
<p>L’approccio bayesiano richiede un cambiamento di prospettiva rispetto ai metodi classici di stima dei parametri. Non ci si limita più a trovare un singolo valore “ottimale” per i parametri del modello. Invece, l’obiettivo è determinare l’intera distribuzione a posteriori dei parametri, che descrive in modo completo lo stato di conoscenza attuale. Solo questa distribuzione fornisce una rappresentazione adeguata dell’incertezza associata ai parametri, permettendo di quantificare non solo quali valori sono più probabili, ma anche l’ampiezza dell’incertezza su tali stime.</p>
<section id="vantaggi-dellapproccio-bayesiano" class="level3" data-number="42.2.1"><h3 data-number="42.2.1" class="anchored" data-anchor-id="vantaggi-dellapproccio-bayesiano">
<span class="header-section-number">42.2.1</span> Vantaggi dell’Approccio Bayesiano</h3>
<p>Un aspetto distintivo dell’inferenza bayesiana è la sua capacità di gestire l’incertezza in modo esplicito. Invece di limitarsi a una singola stima puntuale, l’approccio bayesiano considera l’intero spettro di valori possibili per i parametri e le loro rispettive probabilità. Questo consente una rappresentazione più ricca delle informazioni disponibili e una valutazione più robusta delle ipotesi.</p>
<p>Inoltre, l’approccio bayesiano è altamente flessibile, permettendo di incorporare informazioni precedenti sotto forma di distribuzioni a priori. In contesti in cui si dispone di conoscenze pregresse, come dati di studi precedenti o teorie consolidate, questa caratteristica offre un vantaggio notevole rispetto agli approcci frequentisti, che non integrano facilmente tali informazioni.</p>
<p>In conclusione, il paradigma bayesiano offre una visione più ampia e completa dell’incertezza e della variabilità dei parametri rispetto ai metodi tradizionali, rappresentando un quadro teorico e pratico fondamentale per l’inferenza statistica e la modellazione.</p>
</section></section><section id="densità-di-probabilità" class="level2" data-number="42.3"><h2 data-number="42.3" class="anchored" data-anchor-id="densità-di-probabilità">
<span class="header-section-number">42.3</span> Densità di Probabilità</h2>
<p>Nei capitoli precedenti abbiamo esaminato alcuni esempi di <font color="orange">funzioni di densità di probabilità (PDF)</font>. Ma quali sono le caratteristiche generali di una PDF?</p>
<p>Se <span class="math inline">\(X\)</span> è una variabile casuale con una funzione di densità di probabilità <span class="math inline">\(p(x)\)</span>, la probabilità che <span class="math inline">\(X\)</span> assuma un valore nell’intervallo <span class="math inline">\((a, b)\)</span> può essere calcolata come:</p>
<p><span class="math display">\[
p(X \in (a,b)) = \int_a^b p(x)dx.
\]</span></p>
<p>Per variabili discrete, l’integrazione si trasforma in una somma.</p>
<section id="le-regole-di-somma-e-prodotto" class="level3" data-number="42.3.1"><h3 data-number="42.3.1" class="anchored" data-anchor-id="le-regole-di-somma-e-prodotto">
<span class="header-section-number">42.3.1</span> Le Regole di Somma e Prodotto</h3>
<p>Date due variabili casuali continue <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span>, le regole di somma e prodotto per le densità di probabilità si esprimono come:</p>
<p><span class="math display">\[
\begin{align*}
p(y) = \int p(x,y)dx \quad &amp;\text{- regola della somma},\\
p(x,y) = p(y|x) p(x) = p(x|y) p(y) \quad &amp;\text{- regola del prodotto}.
\end{align*}
\]</span></p>
<p>La probabilità <span class="math inline">\(p(y)\)</span> è chiamata <font color="orange">probabilità marginale</font>.</p>
<p>La regola del prodotto specifica che la distribuzione congiunta di due variabili può essere espressa come il prodotto di una distribuzione condizionata <span class="math inline">\(p(y \mid x)\)</span> e una distribuzione marginale <span class="math inline">\(p(x)\)</span>, o viceversa.</p>
</section><section id="la-distribuzione-marginale" class="level3" data-number="42.3.2"><h3 data-number="42.3.2" class="anchored" data-anchor-id="la-distribuzione-marginale">
<span class="header-section-number">42.3.2</span> La Distribuzione Marginale</h3>
<p>La distribuzione marginale si riferisce alla distribuzione di probabilità di una variabile quando si tiene conto di tutte le possibili variazioni dell’altra variabile in una distribuzione congiunta. In altre parole, essa descrive la probabilità di una variabile indipendentemente dall’altra.</p>
<p>Consideriamo due variabili correlate, <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span>. Possiamo esprimere la relazione tra di esse con la <font color="orange">regola del prodotto</font>:</p>
<p><span class="math display">\[
p(x, y) = p(y \mid x)p(x),
\]</span></p>
<p>dove <span class="math inline">\(p(y \mid x)\)</span> è la probabilità di <span class="math inline">\(y\)</span> dato un certo valore di <span class="math inline">\(x\)</span>, e <span class="math inline">\(p(x)\)</span> è la distribuzione di probabilità di <span class="math inline">\(x\)</span>.</p>
<p>Per ottenere la distribuzione marginale di <span class="math inline">\(y\)</span>, dobbiamo sommare o integrare <span class="math inline">\(p(y \mid x)\)</span> su tutti i possibili valori di <span class="math inline">\(x\)</span>:</p>
<p><span class="math display">\[
p(y) = \int p(y \mid x)p(x)dx.
\]</span></p>
<p>In questo modo, la distribuzione marginale di <span class="math inline">\(y\)</span> rappresenta la probabilità di <span class="math inline">\(y\)</span>, tenendo conto di tutte le possibili variazioni di <span class="math inline">\(x\)</span>.</p>
</section><section id="il-teorema-di-bayes" class="level3" data-number="42.3.3"><h3 data-number="42.3.3" class="anchored" data-anchor-id="il-teorema-di-bayes">
<span class="header-section-number">42.3.3</span> Il Teorema di Bayes</h3>
<p>Dalla regola di prodotto, e sfruttando la proprietà di simmetria <span class="math inline">\(p(x \mid y)p(y) = p(y \mid x)p(x)\)</span>, deriviamo immediatamente la regola di Bayes:</p>
<p><span class="math display">\[
p(y \mid x) = \frac{p(x \mid y)p(y)}{p(x)} = \frac{p(x \mid y)p(y)}{\int p(x \mid y)p(y)dy}.
\]</span></p>
<p>Questa formula è l’elemento chiave nell’inferenza bayesiana, poiché definisce la densità a posteriori di <span class="math inline">\(y\)</span>, <span class="math inline">\(p(y \mid x)\)</span>, dopo aver incorporato l’informazione <span class="math inline">\(x\)</span> attraverso il modello di probabilità condizionata <span class="math inline">\(p(x \mid y)\)</span>. La probabilità marginale di <span class="math inline">\(x\)</span>, <span class="math inline">\(p(x)\)</span>, funge da costante di normalizzazione, garantendo che <span class="math inline">\(p(y \mid x)\)</span> sia una corretta funzione di densità di probabilità.</p>
</section><section id="modellizzazione-e-inferenza-bayesiana" class="level3" data-number="42.3.4"><h3 data-number="42.3.4" class="anchored" data-anchor-id="modellizzazione-e-inferenza-bayesiana">
<span class="header-section-number">42.3.4</span> Modellizzazione e Inferenza Bayesiana</h3>
<p>La modellizzazione bayesiana consiste nel descrivere matematicamente tutti i dati osservabili <span class="math inline">\(y\)</span> e i parametri non osservabili, detti anche parametri “latenti” <span class="math inline">\(\theta\)</span>, definendo la distribuzione congiunta di dati e parametri <span class="math inline">\(p(y, \theta)\)</span>.</p>
<p>Si costruiscono modelli probabilistici per le quantità osservate condizionate ai parametri <span class="math inline">\(p(y \mid \theta)\)</span> e per le quantità non osservate, rappresentate dalla distribuzione a priori <span class="math inline">\(p(\theta)\)</span>, che rappresenta le nostre conoscenze precedenti sui parametri. Questi due elementi vengono combinati, seguendo la regola del prodotto, per formare una distribuzione congiunta:</p>
<p><span class="math display">\[
p(y, \theta) = p(y \mid \theta)p(\theta).
\]</span></p>
</section><section id="il-modello-osservazionale" class="level3" data-number="42.3.5"><h3 data-number="42.3.5" class="anchored" data-anchor-id="il-modello-osservazionale">
<span class="header-section-number">42.3.5</span> Il Modello Osservazionale</h3>
<p>La funzione</p>
<p><span class="math display">\[
p(y \mid \theta)
\]</span></p>
<p>è un <font color="orange">modello probabilistico dei dati osservati</font> che mette in relazione <span class="math inline">\(y\)</span> con i parametri sconosciuti <span class="math inline">\(\theta\)</span> che vogliamo stimare. Questo modello rappresenta l’evidenza fornita dai dati e costituisce la principale fonte di informazione. In questo contesto, viene chiamato <font color="orange">funzione di verosimiglianza</font> (<em>likelihood</em>). È importante notare che la funzione di verosimiglianza nel contesto bayesiano non è diversa da quella utilizzata nell’approccio frequentista: in entrambi i casi collega i dati osservati ai parametri sconosciuti.</p>
</section><section id="la-distribuzione-a-priori" class="level3" data-number="42.3.6"><h3 data-number="42.3.6" class="anchored" data-anchor-id="la-distribuzione-a-priori">
<span class="header-section-number">42.3.6</span> La Distribuzione a Priori</h3>
<p>La distribuzione</p>
<p><span class="math display">\[
p(\theta)
\]</span></p>
<p>rappresenta la <font color="orange">distribuzione a priori</font> dei parametri, che codifica le conoscenze preesistenti sui parametri stessi. Questa distribuzione a priori può essere <font color="orange">informativa</font> o <font color="orange">non informativa</font>, a seconda della quantità di informazioni affidabili che si possiedono sui parametri. Uno degli aspetti principali che differenziano l’approccio bayesiano da quello frequentista è l’uso delle distribuzioni di probabilità per i parametri sconosciuti. Queste distribuzioni vengono poi combinate con la funzione di verosimiglianza per ottenere una distribuzione a posteriori, che incorpora sia le informazioni precedenti che le evidenze fornite dai nuovi dati.</p>
</section><section id="inferenza-sui-parametri" class="level3" data-number="42.3.7"><h3 data-number="42.3.7" class="anchored" data-anchor-id="inferenza-sui-parametri">
<span class="header-section-number">42.3.7</span> Inferenza sui Parametri</h3>
<p>Ottenere la distribuzione a posteriori dei parametri sconosciuti è l’elemento centrale dell’approccio bayesiano. Riformulando la regola di Bayes in termini di <span class="math inline">\(y\)</span> e <span class="math inline">\(\theta\)</span>, otteniamo una formula che ci mostra come calcolare la distribuzione a posteriori:</p>
<p><span class="math display">\[
p(\theta \mid y) = \frac{p(y \mid \theta)p(\theta)}{p(y)} = \frac{p(y \mid \theta)p(\theta)}{\int p(y \mid \theta)p(\theta) d\theta}.
\]</span></p>
<p>Il denominatore della regola di Bayes,</p>
<p><span class="math display">\[
p(y) = \int p(y \mid \theta)p(\theta) d \theta,
\]</span></p>
<p>è chiamato <font color="orange">verosimiglianza marginale</font>, poiché integra la verosimiglianza rispetto all’informazione a priori sui parametri. Questa quantità è anche nota come <font color="orange">evidenza</font> del modello e serve a normalizzare la distribuzione a posteriori, rendendola una vera distribuzione di probabilità. L’inferenza finale sarà un compromesso tra l’evidenza fornita dai dati e l’informazione a priori disponibile.</p>
</section><section id="inferenza-bayesiana-in-sintesi-verosimiglianza-prior-posteriore" class="level3" data-number="42.3.8"><h3 data-number="42.3.8" class="anchored" data-anchor-id="inferenza-bayesiana-in-sintesi-verosimiglianza-prior-posteriore">
<span class="header-section-number">42.3.8</span> Inferenza bayesiana in sintesi: verosimiglianza, prior, posteriore</h3>
<p>Per riassumere, ecco tutti i componenti fondamentali dell’inferenza bayesiana.</p>
<p>Il teorema di Bayes, espresso in termini di dati <span class="math inline">\(y\)</span> e parametri del modello <span class="math inline">\(\theta\)</span>, è</p>
<p><span class="math display">\[
p(\theta \mid y) = \frac{p(y \mid \theta)p(\theta)}{p(y)},
\]</span></p>
<p>dove:</p>
<ul>
<li>Il denominatore <span class="math inline">\(p(y)\)</span> è la costante di normalizzazione o <em>evidenza</em>.</li>
<li>
<span class="math inline">\(p(\theta)\)</span> rappresenta il <em>prior</em>, ovvero le credenze iniziali sui parametri.</li>
<li>
<span class="math inline">\(p(y \mid \theta)\)</span> è la <em>verosimiglianza</em>, che collega i dati osservati ai parametri del modello.</li>
<li>
<span class="math inline">\(p(\theta \mid y)\)</span> è la <em>distribuzione a posteriori</em>, che rappresenta le credenze aggiornate sui parametri dopo aver osservato i dati.</li>
</ul>
<p>La distribuzione a posteriori riassume il nostro stato di credenza sui possibili valori di <span class="math inline">\(\theta\)</span>, aggiornato sulla base delle evidenze fornite dai dati.</p>
<p>Si noti che <span class="math inline">\(p(y)\)</span> non dipende dai parametri <span class="math inline">\(\theta\)</span>. Pertanto, in molte situazioni pratiche, è sufficiente calcolare la distribuzione a posteriori fino a una costante. Per questo motivo, spesso la regola di Bayes viene riassunta come:</p>
<p><span class="math display">\[p(\theta \mid y) \propto p(y \mid \theta)p(\theta).\]</span></p>
<p>In questa forma, si ignora il denominatore poiché è una costante (indipendente da <span class="math inline">\(\theta\)</span>).</p>
</section><section id="il-ruolo-dei-priors" class="level3" data-number="42.3.9"><h3 data-number="42.3.9" class="anchored" data-anchor-id="il-ruolo-dei-priors">
<span class="header-section-number">42.3.9</span> Il Ruolo dei Priors</h3>
<p>Una delle caratteristiche distintive dell’approccio bayesiano è l’incorporazione delle conoscenze a priori riguardo ai parametri del modello. Dichiarare questi priors ci obbliga a esplicitare tutte le assunzioni che facciamo sulla struttura del modello e sui suoi parametri. Allo stesso tempo, i priors sono spesso oggetto di critica nell’inferenza bayesiana a causa della soggettività che possono introdurre.</p>
<p>Tuttavia, l’inferenza bayesiana offre alcuni vantaggi meno evidenti a prima vista, tra cui:</p>
<ul>
<li>la capacità di lavorare efficacemente con piccoli set di dati,</li>
<li>la capacità di eseguire la regolarizzazione del modello.</li>
</ul>
<p>Questi aspetti rendono l’approccio bayesiano particolarmente utile in situazioni in cui i dati sono scarsi o le assunzioni esplicite sul modello possono contribuire a migliorare le previsioni.</p>
</section></section><section id="inferenza-predittiva" class="level2" data-number="42.4"><h2 data-number="42.4" class="anchored" data-anchor-id="inferenza-predittiva">
<span class="header-section-number">42.4</span> Inferenza Predittiva</h2>
<p>La distribuzione a posteriori dei parametri può essere utilizzata per modellare l’incertezza nelle previsioni <span class="math inline">\(\tilde{y}\)</span> relative a nuove osservazioni. La <font color="orange">distribuzione predittiva a posteriori</font> di <span class="math inline">\(\tilde{y}\)</span> si ottiene marginalizzando la distribuzione congiunta delle previsioni <span class="math inline">\(\tilde{y}\)</span> e dei parametri <span class="math inline">\(\theta\)</span> rispetto ai parametri del modello:</p>
<p><span class="math display">\[
p(\tilde{y} \mid y) = \int p(\tilde{y}, \theta \mid y)d \theta = \int p(\tilde{y} \mid \theta, y)p(\theta|y)d\theta.
\]</span></p>
<p>In questo modo, la distribuzione predittiva può essere vista come una media delle previsioni del modello <span class="math inline">\(p(\tilde{y} \mid \theta, y)\)</span> ponderata sulla distribuzione a posteriori dei parametri del modello <span class="math inline">\(p(\theta \mid y)\)</span>. Questo consente di incorporare l’incertezza sui parametri nel processo di previsione, rendendo le stime più robuste.</p>
</section><section id="come-possiamo-eseguire-linferenza-bayesiana" class="level2" data-number="42.5"><h2 data-number="42.5" class="anchored" data-anchor-id="come-possiamo-eseguire-linferenza-bayesiana">
<span class="header-section-number">42.5</span> Come possiamo eseguire l’inferenza bayesiana?</h2>
<p>Esistono due approcci principali per determinare la distribuzione posteriore:</p>
<ol type="1">
<li><p><strong>Approccio Analitico (o Coniugato)</strong>: Questo metodo è applicabile quando la distribuzione a priori scelta e la funzione di verosimiglianza appartengono alla stessa famiglia di distribuzioni, definite <em>coniugate</em>. In questi casi, la distribuzione posteriore può essere calcolata analiticamente, ovvero attraverso formule matematiche esatte. L’approccio coniugato è computazionalmente efficiente ma presenta una limitazione significativa: è applicabile solo in situazioni in cui si può assumere una coniugazione tra la distribuzione a priori e la verosimiglianza. Di conseguenza, trova un impiego limitato nelle analisi di dati reali, dove spesso le assunzioni di coniugazione risultano troppo restrittive.</p></li>
<li><p><strong>Approccio Numerico</strong>: Quando non è possibile ottenere una forma analitica chiusa per la distribuzione posteriore, a causa della complessità del modello o della mancanza di coniugazione tra la distribuzione a priori e la verosimiglianza, si ricorre a metodi numerici. Questi algoritmi consentono di ottenere una stima approssimata, ma spesso accurata, della distribuzione posteriore.</p></li>
</ol>
<section id="metodi-numerici" class="level3" data-number="42.5.1"><h3 data-number="42.5.1" class="anchored" data-anchor-id="metodi-numerici">
<span class="header-section-number">42.5.1</span> Metodi Numerici</h3>
<p>Le catene di Markov Monte Carlo (MCMC) sono una classe di algoritmi ampiamente utilizzati in questo contesto. Essi costruiscono una catena di Markov che converge alla distribuzione posteriore desiderata. Tra i metodi MCMC più comuni troviamo:</p>
<ul>
<li>
<em>Metropolis-Hastings</em>: Un algoritmo generale che consente di campionare da una vasta gamma di distribuzioni posteriori.</li>
<li>
<em>Gibbs Sampling</em>: Un caso particolare di Metropolis-Hastings, particolarmente efficiente quando la distribuzione congiunta è difficile da campionare direttamente, ma le distribuzioni condizionali sono note.</li>
</ul>
<p>Oltre alle MCMC, esistono altre tecniche numeriche:</p>
<ul>
<li>
<em>Variational Bayes</em>: Questo approccio consiste nel trovare la distribuzione <span class="math inline">\(q(z)\)</span> che meglio approssima la distribuzione posteriore <span class="math inline">\(p(z \mid x)\)</span>, secondo un criterio di divergenza (ad esempio, la divergenza di Kullback-Leibler). L’obiettivo è trasformare il problema di inferenza esatta in un problema di ottimizzazione. Variational Bayes offre spesso una soluzione più veloce rispetto alle MCMC, ma l’approssimazione può essere meno accurata in alcuni casi.</li>
<li>
<em>Laplace approximation</em>: Questa tecnica consiste nell’approssimare la distribuzione posteriore con una distribuzione normale centrata sul massimo a posteriori (MAP) e con matrice di covarianza pari all’inverso della matrice di Hessiano negativa calcolata nel MAP. L’approssimazione di Laplace è computazionalmente efficiente, ma è valida solo localmente attorno al MAP e può portare a stime inaccurate della varianza posteriore.</li>
</ul>
<p>Vantaggi:</p>
<ul>
<li>Versatilità: L’approccio numerico è applicabile a una vasta gamma di modelli e distribuzioni.</li>
<li>Flessibilità: Consente di incorporare facilmente informazioni a priori complesse.</li>
</ul>
<p>Svantaggi:</p>
<ul>
<li>Costo computazionale: Può richiedere un tempo di calcolo considerevole, soprattutto per modelli complessi o grandi dataset.</li>
<li>Tuning: La scelta dei parametri degli algoritmi MCMC (ad esempio, la proposta iniziale) può influenzare la convergenza e l’efficienza del campionamento.</li>
</ul>
<p>In sintesi, l’approccio numerico offre una soluzione generale e flessibile per l’inferenza bayesiana, ma richiede una maggiore attenzione alla scelta degli algoritmi e alla valutazione della convergenza delle catene.</p>
</section></section><section id="programmazione-probabilistica" class="level2" data-number="42.6"><h2 data-number="42.6" class="anchored" data-anchor-id="programmazione-probabilistica">
<span class="header-section-number">42.6</span> Programmazione Probabilistica</h2>
<p>I linguaggi di programmazione probabilistica (PPL) rappresentano un’importante innovazione nella modellazione bayesiana, facilitando l’uso di tecniche di approssimazione numerica per stimare le distribuzioni posteriori. Grazie ai PPL, la modellizzazione probabilistica diventa più accessibile, riducendo le barriere tecniche e computazionali. Questi strumenti consentono di definire modelli in modo dichiarativo, descrivendo le relazioni tra le variabili in termini probabilistici senza doversi occupare dei dettagli algoritmici sottostanti. In altre parole, i PPL permettono ai ricercatori di concentrarsi sull’espressione del modello, lasciando ai linguaggi il compito di gestire l’implementazione computazionale.</p>
<p>Tra i PPL più utilizzati troviamo:</p>
<ul>
<li>
<strong>Stan</strong>: Uno dei linguaggi più popolari, noto per la sua efficienza e flessibilità.</li>
<li>
<strong>PyMC</strong>: Molto utilizzato nell’ecosistema Python, offre un’interfaccia user-friendly per la modellazione bayesiana.</li>
<li>
<strong>TensorFlow</strong>: Un framework che combina un approccio probabilistico con le reti neurali.</li>
</ul>
<section id="vantaggi-della-programmazione-probabilistica-in-psicologia" class="level3" data-number="42.6.1"><h3 data-number="42.6.1" class="anchored" data-anchor-id="vantaggi-della-programmazione-probabilistica-in-psicologia">
<span class="header-section-number">42.6.1</span> Vantaggi della Programmazione Probabilistica in Psicologia</h3>
<p>La programmazione probabilistica offre numerosi vantaggi per la ricerca psicologica, in particolare per l’analisi di processi complessi come l’apprendimento, le emozioni e il comportamento. Alcuni dei principali vantaggi includono:</p>
<ul>
<li><p><strong>Flessibilità</strong>: I PPL, come Stan, Pyro, Numpyro, PyMC e Turing.jl, offrono un quadro flessibile per la definizione e la personalizzazione dei modelli probabilistici. In psicologia, questa flessibilità è cruciale, poiché i modelli devono adattarsi a una vasta gamma di processi mentali e comportamentali che variano tra individui e contesti.</p></li>
<li><p><strong>Quantificazione dell’Incertezza</strong>: La programmazione probabilistica permette di rappresentare esplicitamente e quantificare l’incertezza, un aspetto fondamentale in psicologia, dove molte variabili di interesse, come stati emotivi o atteggiamenti, sono latenti e soggette a incertezza. Incorporare questa incertezza nei modelli consente di ottenere stime più realistiche e affidabili.</p></li>
<li><p><strong>Validazione del Modello</strong>: I PPL facilitano la validazione dei modelli psicologici, consentendo ai ricercatori di confrontare le previsioni dei modelli con i dati osservati. Tecniche come i <em>posterior predictive checks</em> permettono di valutare la qualità e l’affidabilità del modello, contribuendo a una maggiore solidità delle conclusioni.</p></li>
<li><p><strong>Modellazione Gerarchica</strong>: Molti studi psicologici raccolgono dati a più livelli (ad esempio, misurazioni ripetute per individuo, sessioni sperimentali, contesti diversi). I PPL semplificano la costruzione e l’analisi di modelli gerarchici, catturando la variabilità sia intra- che inter-individuale.</p></li>
<li><p><strong>Selezione e Confronto dei Modelli</strong>: In psicologia è spesso necessario confrontare modelli con strutture diverse o ipotesi alternative. I PPL permettono di confrontare le capacità predittive dei modelli in modo sistematico e rigoroso, supportando la scelta del modello più adatto basandosi sull’accuratezza predittiva e non solo sulla complessità.</p></li>
<li><p><strong>Comunicazione Trasparente</strong>: La programmazione probabilistica favorisce la trasparenza nella modellizzazione. I ricercatori possono specificare chiaramente le assunzioni del modello, i <em>prior</em> e le funzioni di verosimiglianza, rendendo più facile la comunicazione e la collaborazione con altri esperti.</p></li>
<li><p><strong>Librerie Estensibili</strong>: I PPL offrono librerie estese e strumenti avanzati per lo sviluppo di modelli, l’inferenza e la visualizzazione. Questo riduce il carico computazionale e di implementazione, rendendo più agevole l’analisi di dati complessi tipici della psicologia sperimentale e clinica.</p></li>
</ul></section><section id="come-funzionano-i-ppl" class="level3" data-number="42.6.2"><h3 data-number="42.6.2" class="anchored" data-anchor-id="come-funzionano-i-ppl">
<span class="header-section-number">42.6.2</span> Come Funzionano i PPL?</h3>
<p>I linguaggi di programmazione probabilistica richiedono semplicemente la descrizione del modello probabilistico. Successivamente, utilizzano algoritmi di inferenza, come le catene di Markov Monte Carlo (MCMC) o l’inferenza variazionale, per stimare la distribuzione posteriore delle variabili di interesse. Ciò consente ai ricercatori di ottenere stime delle variabili sconosciute e di valutare l’incertezza associata.</p>
<p>In conclusione, i linguaggi di programmazione probabilistica hanno trasformato il modo in cui affrontiamo l’inferenza bayesiana, rendendola più accessibile e potente. Grazie alla loro semplicità d’uso e alla potenza computazionale, i PPL hanno reso l’inferenza bayesiana uno strumento sempre più diffuso in molte discipline, inclusa la psicologia. Questo approccio facilita la modellazione di fenomeni complessi e l’analisi rigorosa di dati, offrendo un metodo efficace per rispondere a domande di ricerca psicologica in modo trasparente e accurato.</p>
</section></section><section id="notazione" class="level2" data-number="42.7"><h2 data-number="42.7" class="anchored" data-anchor-id="notazione">
<span class="header-section-number">42.7</span> Notazione</h2>
<p>In seguito, utilizzeremo <span class="math inline">\(y\)</span> per rappresentare i dati osservati e <span class="math inline">\(\theta\)</span> per indicare i parametri sconosciuti di un modello statistico. Entrambi, <span class="math inline">\(y\)</span> e <span class="math inline">\(\theta\)</span>, saranno trattati come variabili casuali. Utilizzeremo <span class="math inline">\(x\)</span> per denotare le quantità note, come i predittori di un modello lineare.</p>
<p>È comune scrivere modelli statistici utilizzando la seguente notazione:</p>
<p><span class="math display">\[
\begin{aligned}
y &amp; \sim \mathrm{normal}(\mu, \sigma) \\
\mu &amp; \sim \mathrm{normal}(0, 10) \\
\sigma &amp; \sim \mathrm{normal}^+(\sigma \mid  0, 1),
\end{aligned}
\]</span></p>
<p>dove il simbolo <span class="math inline">\(\sim\)</span> è chiamato <em>tilde</em> (<code>\sim</code> in LaTeX).</p>
<p>In generale, possiamo leggere <span class="math inline">\(\sim\)</span> come <em>“è distribuito come”</em>, e questa notazione è usata come una scorciatoia per definire distribuzioni. L’esempio sopra può essere scritto anche come:</p>
<p><span class="math display">\[
\begin{aligned}
   p(y \mid \mu, \sigma) &amp; = \mathrm{normal}(y \mid  \mu, \sigma)\\
   p(\mu) &amp; = \mathrm{normal}(\mu \mid 0, 10)\\
   p(\sigma) &amp; = \mathrm{normal}^+(\sigma \mid  0, 1).
\end{aligned}
\]</span></p>
</section><section id="addendum-la-verosimiglianza-marginale" class="level2" data-number="42.8"><h2 data-number="42.8" class="anchored" data-anchor-id="addendum-la-verosimiglianza-marginale">
<span class="header-section-number">42.8</span> Addendum: La Verosimiglianza Marginale</h2>
<p>Nella discussione precedente, abbiamo introdotto la verosimiglianza marginale <span class="math inline">\(p(y)\)</span> come una costante di normalizzazione. Ma <font color="orange">perché è così importante normalizzare la distribuzione posteriore?</font> La verosimiglianza marginale rappresenta la probabilità dei dati osservati, integrata su tutti i possibili valori del parametro <span class="math inline">\(\theta\)</span>. In altre parole, esprime la probabilità di osservare i dati senza fare riferimento a un particolare valore del parametro.</p>
<p>Per comprendere intuitivamente, immagina di voler stimare la temperatura media di una stanza. Usando un termometro, ottieni una misurazione, ma sei consapevole che variabili come la posizione del termometro o l’ora del giorno potrebbero influenzare la lettura. La verosimiglianza marginale è equivalente a considerare la probabilità di ottenere una certa misurazione, prendendo in considerazione tutte queste possibili variabili.</p>
<p>Senza la normalizzazione, la somma delle probabilità assegnate ai diversi valori del parametro non sarebbe uguale a 1, il che significherebbe che non avremmo una distribuzione di probabilità valida. Questo renderebbe difficile interpretare correttamente i risultati. La verosimiglianza marginale agisce come una costante di normalizzazione, garantendo che l’area sotto la curva della distribuzione posteriore sia esattamente pari a 1, come richiesto da una distribuzione di probabilità.</p>
<p>La verosimiglianza marginale si calcola integrando (o sommando, nel caso di parametri discreti) la funzione di verosimiglianza rispetto a tutti i possibili valori del parametro, pesando ciascun valore con la sua probabilità a priori.</p>
<p>Consideriamo un esempio con una variabile casuale binomiale <span class="math inline">\(Y\)</span>, la cui funzione di massa di probabilità (PMF) <span class="math inline">\(p(Y)\)</span> dipende dal parametro <span class="math inline">\(\theta\)</span>. Supponiamo che <span class="math inline">\(\theta\)</span> possa assumere uno tra tre valori specifici: 0.1, 0.5 o 0.9, ciascuno con una probabilità a priori di <span class="math inline">\(\frac{1}{3}\)</span>.</p>
<p>Se i dati indicano <span class="math inline">\(n = 10\)</span> prove e <span class="math inline">\(k = 7\)</span> successi, la funzione di verosimiglianza è data da:</p>
<p><span class="math display">\[
p(k = 7, n = 10 \mid \theta) = \binom{10}{7} \theta^7 (1 - \theta)^3.
\]</span></p>
<p>Per calcolare la verosimiglianza marginale <span class="math inline">\(p(k = 7, n = 10)\)</span>, marginalizziamo su <span class="math inline">\(\theta\)</span>, valutando la verosimiglianza per ciascun valore di <span class="math inline">\(\theta\)</span>, moltiplicando per la probabilità a priori di ciascun <span class="math inline">\(\theta\)</span>, e sommando i risultati:</p>
<p><span class="math display">\[
p(k = 7, n = 10) = \sum_{i=1}^{3} p(k = 7, n = 10 \mid \theta_i) \cdot p(\theta_i).
\]</span></p>
<p>Sostituendo i valori di <span class="math inline">\(\theta\)</span> e le probabilità corrispondenti:</p>
<p><span class="math display">\[
p(k = 7, n = 10) = \frac{1}{3} \binom{10}{7} 0.1^7 (1 - 0.1)^3 + \frac{1}{3} \binom{10}{7} 0.5^7 (1 - 0.5)^3 + \frac{1}{3} \binom{10}{7} 0.9^7 (1 - 0.9)^3.
\]</span></p>
<p>Questo calcolo dimostra come la marginalizzazione su <span class="math inline">\(\theta\)</span> incorpori tutte le sue possibili variazioni, ottenendo una stima complessiva che tiene conto dell’incertezza su <span class="math inline">\(\theta\)</span>.</p>
</section><section id="implementazione-in-r" class="level2" data-number="42.9"><h2 data-number="42.9" class="anchored" data-anchor-id="implementazione-in-r">
<span class="header-section-number">42.9</span> Implementazione in R</h2>
<p>Per calcolare la verosimiglianza marginale in R, possiamo distinguere tra il caso discreto (in cui <span class="math inline">\(\theta\)</span> assume valori specifici) e il caso continuo (in cui <span class="math inline">\(\theta\)</span> è trattato come una variabile continua su un intervallo). Per il caso discreto, sommiamo direttamente i contributi della funzione di verosimiglianza pesati dalla probabilità a priori. Per il caso continuo, utilizziamo l’integrazione numerica.</p>
<section id="caso-discreto" class="level3" data-number="42.9.1"><h3 data-number="42.9.1" class="anchored" data-anchor-id="caso-discreto">
<span class="header-section-number">42.9.1</span> Caso discreto</h3>
<p>Nel caso in cui <span class="math inline">\(\theta\)</span> assuma valori discreti, possiamo implementare il calcolo della verosimiglianza marginale sommando i prodotti della verosimiglianza <span class="math inline">\(p(k \mid \theta)\)</span> e della probabilità a priori <span class="math inline">\(p(\theta)\)</span>:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Funzione di verosimiglianza per il caso binomiale</span></span>
<span><span class="va">likelihood_binomial</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">theta</span>, <span class="va">k</span>, <span class="va">n</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/function.html">return</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Special.html">choose</a></span><span class="op">(</span><span class="va">n</span>, <span class="va">k</span><span class="op">)</span> <span class="op">*</span> <span class="op">(</span><span class="va">theta</span><span class="op">^</span><span class="va">k</span><span class="op">)</span> <span class="op">*</span> <span class="op">(</span><span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">theta</span><span class="op">)</span><span class="op">^</span><span class="op">(</span><span class="va">n</span> <span class="op">-</span> <span class="va">k</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Valori di theta e probabilità a priori</span></span>
<span><span class="va">theta_values</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.1</span>, <span class="fl">0.5</span>, <span class="fl">0.9</span><span class="op">)</span></span>
<span><span class="va">prior</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">theta_values</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">theta_values</span><span class="op">)</span><span class="op">)</span> <span class="co"># Prior uniforme</span></span>
<span><span class="va">k</span> <span class="op">&lt;-</span> <span class="fl">7</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">10</span></span>
<span></span>
<span><span class="co"># Calcolo della verosimiglianza marginale discreta</span></span>
<span><span class="va">marginal_likelihood_discrete</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">prior</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">sapply</a></span><span class="op">(</span><span class="va">theta_values</span>, <span class="va">likelihood_binomial</span>, k <span class="op">=</span> <span class="va">k</span>, n <span class="op">=</span> <span class="va">n</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sprintf.html">sprintf</a></span><span class="op">(</span><span class="st">"Likelihood Marginale (discreta): %.4f\n"</span>, <span class="va">marginal_likelihood_discrete</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; Likelihood Marginale (discreta): 0.0582</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Il risultato rappresenta la verosimiglianza marginale calcolata sommando i contributi discreti.</p>
</section><section id="caso-continuo" class="level3" data-number="42.9.2"><h3 data-number="42.9.2" class="anchored" data-anchor-id="caso-continuo">
<span class="header-section-number">42.9.2</span> Caso continuo</h3>
<p>Nel caso in cui <span class="math inline">\(\theta\)</span> sia una variabile continua definita su <span class="math inline">\([0, 1]\)</span>, utilizziamo l’integrazione numerica per calcolare la verosimiglianza marginale. L’approccio assume una distribuzione a priori uniforme su <span class="math inline">\([0, 1]\)</span> (se non diversamente specificato):</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Funzione per il calcolo della verosimiglianza marginale continua</span></span>
<span><span class="va">likelihood_binomial_continuous</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">theta</span>, <span class="va">k</span>, <span class="va">n</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="co"># La verosimiglianza è 0 per valori di theta fuori dall'intervallo [0, 1]</span></span>
<span>  <span class="va">theta</span><span class="op">[</span><span class="va">theta</span> <span class="op">&lt;</span> <span class="fl">0</span> <span class="op">|</span> <span class="va">theta</span> <span class="op">&gt;</span> <span class="fl">1</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fl">0</span></span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/function.html">return</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Special.html">choose</a></span><span class="op">(</span><span class="va">n</span>, <span class="va">k</span><span class="op">)</span> <span class="op">*</span> <span class="op">(</span><span class="va">theta</span><span class="op">^</span><span class="va">k</span><span class="op">)</span> <span class="op">*</span> <span class="op">(</span><span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">theta</span><span class="op">)</span><span class="op">^</span><span class="op">(</span><span class="va">n</span> <span class="op">-</span> <span class="va">k</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Parametri</span></span>
<span><span class="va">k</span> <span class="op">&lt;-</span> <span class="fl">7</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">10</span></span>
<span></span>
<span><span class="co"># Calcolo dell'integrale numerico</span></span>
<span><span class="va">marginal_likelihood_continuous</span> <span class="op">&lt;-</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/integrate.html">integrate</a></span><span class="op">(</span></span>
<span>    <span class="kw">function</span><span class="op">(</span><span class="va">theta</span><span class="op">)</span> <span class="fu">likelihood_binomial_continuous</span><span class="op">(</span><span class="va">theta</span>, <span class="va">k</span>, <span class="va">n</span><span class="op">)</span>, </span>
<span>    lower <span class="op">=</span> <span class="fl">0</span>, </span>
<span>    upper <span class="op">=</span> <span class="fl">1</span></span>
<span>  <span class="op">)</span><span class="op">$</span><span class="va">value</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/sprintf.html">sprintf</a></span><span class="op">(</span></span>
<span>    <span class="st">"Likelihood Marginale (continua): %.4f\n"</span>, </span>
<span>    <span class="va">marginal_likelihood_continuous</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Likelihood Marginale (continua): 0.0909</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Qui l’integrazione numerica restituisce la verosimiglianza marginale considerando <span class="math inline">\(\theta\)</span> come una variabile continua.</p>
</section><section id="caso-continuo-con-prior-beta" class="level3" data-number="42.9.3"><h3 data-number="42.9.3" class="anchored" data-anchor-id="caso-continuo-con-prior-beta">
<span class="header-section-number">42.9.3</span> Caso continuo con prior Beta</h3>
<p>Per utilizzare una distribuzione a priori diversa (ad esempio, una distribuzione Beta), è necessario moltiplicare la funzione di verosimiglianza per la densità della distribuzione a priori:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Funzione prior Beta</span></span>
<span><span class="va">prior_beta</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">theta</span>, <span class="va">alpha</span>, <span class="va">beta</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/function.html">return</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Beta.html">dbeta</a></span><span class="op">(</span><span class="va">theta</span>, <span class="va">alpha</span>, <span class="va">beta</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Funzione combinata di verosimiglianza e prior</span></span>
<span><span class="va">likelihood_with_beta_prior</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">theta</span>, <span class="va">k</span>, <span class="va">n</span>, <span class="va">alpha_prior</span>, <span class="va">beta_prior</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="co"># La verosimiglianza è 0 per valori di theta fuori dall'intervallo [0, 1]</span></span>
<span>  <span class="va">valid_theta</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="va">theta</span> <span class="op">&gt;=</span> <span class="fl">0</span> <span class="op">&amp;</span> <span class="va">theta</span> <span class="op">&lt;=</span> <span class="fl">1</span><span class="op">)</span></span>
<span>  <span class="va">likelihood</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">valid_theta</span>, <span class="fu"><a href="https://rdrr.io/r/base/Special.html">choose</a></span><span class="op">(</span><span class="va">n</span>, <span class="va">k</span><span class="op">)</span> <span class="op">*</span> <span class="op">(</span><span class="va">theta</span><span class="op">^</span><span class="va">k</span><span class="op">)</span> <span class="op">*</span> <span class="op">(</span><span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">theta</span><span class="op">)</span><span class="op">^</span><span class="op">(</span><span class="va">n</span> <span class="op">-</span> <span class="va">k</span><span class="op">)</span><span class="op">)</span>, <span class="fl">0</span><span class="op">)</span></span>
<span>  <span class="va">prior</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">valid_theta</span>, <span class="fu">prior_beta</span><span class="op">(</span><span class="va">theta</span>, <span class="va">alpha_prior</span>, <span class="va">beta_prior</span><span class="op">)</span>, <span class="fl">0</span><span class="op">)</span></span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/function.html">return</a></span><span class="op">(</span><span class="va">likelihood</span> <span class="op">*</span> <span class="va">prior</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Parametri</span></span>
<span><span class="va">alpha_prior</span> <span class="op">&lt;-</span> <span class="fl">2</span></span>
<span><span class="va">beta_prior</span> <span class="op">&lt;-</span> <span class="fl">2</span></span>
<span><span class="va">k</span> <span class="op">&lt;-</span> <span class="fl">7</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">10</span></span>
<span></span>
<span><span class="co"># Calcolo dell'integrale numerico con prior Beta</span></span>
<span><span class="va">marginal_likelihood_continuous_beta</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/integrate.html">integrate</a></span><span class="op">(</span></span>
<span>  <span class="kw">function</span><span class="op">(</span><span class="va">theta</span><span class="op">)</span> <span class="fu">likelihood_with_beta_prior</span><span class="op">(</span><span class="va">theta</span>, <span class="va">k</span>, <span class="va">n</span>, <span class="va">alpha_prior</span>, <span class="va">beta_prior</span><span class="op">)</span>,</span>
<span>  lower <span class="op">=</span> <span class="fl">0</span>, upper <span class="op">=</span> <span class="fl">1</span></span>
<span><span class="op">)</span><span class="op">$</span><span class="va">value</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sprintf.html">sprintf</a></span><span class="op">(</span><span class="st">"Likelihood Marginale con prior Beta: %.4f\n"</span>, <span class="va">marginal_likelihood_continuous_beta</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; Likelihood Marginale con prior Beta: 0.1119</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In questo caso, la distribuzione a priori Beta(2,2) dà maggiore peso ai valori centrali di <span class="math inline">\(\theta\)</span>, riflettendo una conoscenza a priori che privilegia valori intermedi. Il calcolo combina la verosimiglianza e il prior per fornire una verosimiglianza marginale ponderata.</p>
</section></section><section id="riflessioni-conclusive" class="level2" data-number="42.10"><h2 data-number="42.10" class="anchored" data-anchor-id="riflessioni-conclusive">
<span class="header-section-number">42.10</span> Riflessioni Conclusive</h2>
<p>Al cuore della ricerca scientifica c’è una domanda del tipo: “dimmi qualcosa sulla variabile <span class="math inline">\(\theta\)</span> dato che ho osservato i dati <span class="math inline">\(D\)</span> e ho una certa conoscenza del meccanismo sottostante che genera i dati”. La regola di Bayes fornisce la seguente risposta:</p>
<p><span class="math display">\[
p(\theta \mid D) = \frac{p(D \mid\theta) p(\theta)}{p(D)} = \frac{p(D \mid \theta) p(\theta)}{\int_\theta p(D \mid\theta) p(\theta) d\theta}.
\]</span></p>
<p>Questa equazione mostra come, partendo da un modello generativo <span class="math inline">\(p(D \mid\theta)\)</span> dei dati osservati e abbinato a una credenza a priori <span class="math inline">\(p(\theta)\)</span> su quali valori della variabile <span class="math inline">\(\theta\)</span> siano plausibili, possiamo inferire la distribuzione a posteriori <span class="math inline">\(p(\theta \mid D)\)</span> della variabile alla luce dei dati osservati.</p>
<p>La stima MAP (Massimo A Posteriori), che corrisponde al valore di <span class="math inline">\(\theta\)</span> che massimizza la distribuzione a posteriori, rappresenta una stima puntuale del parametro:</p>
<p><span class="math display">\[
\theta^* = \arg \max_\theta p(\theta \mid D).
\]</span></p>
<p>Nel caso di un prior non informativo (piatto), la stima MAP coincide con la stima di massima verosimiglianza, ovvero il valore di <span class="math inline">\(\theta\)</span> che massimizza la probabilità che il modello generi i dati osservati.</p>
</section><section id="informazioni-sullambiente-di-sviluppo" class="level2 unnumbered"><h2 class="unnumbered anchored" data-anchor-id="informazioni-sullambiente-di-sviluppo">Informazioni sull’Ambiente di Sviluppo</h2>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/sessionInfo.html">sessionInfo</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">#&gt; R version 4.4.2 (2024-10-31)</span></span>
<span><span class="co">#&gt; Platform: aarch64-apple-darwin20</span></span>
<span><span class="co">#&gt; Running under: macOS Sequoia 15.2</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Matrix products: default</span></span>
<span><span class="co">#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib </span></span>
<span><span class="co">#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; locale:</span></span>
<span><span class="co">#&gt; [1] C/UTF-8/C/C/C/C</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; time zone: Europe/Rome</span></span>
<span><span class="co">#&gt; tzcode source: internal</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; attached base packages:</span></span>
<span><span class="co">#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; other attached packages:</span></span>
<span><span class="co">#&gt;  [1] mice_3.17.0      see_0.9.0        gridExtra_2.3    patchwork_1.3.0 </span></span>
<span><span class="co">#&gt;  [5] bayesplot_1.11.1 psych_2.4.12     scales_1.3.0     markdown_1.13   </span></span>
<span><span class="co">#&gt;  [9] knitr_1.49       lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1   </span></span>
<span><span class="co">#&gt; [13] dplyr_1.1.4      purrr_1.0.2      readr_2.1.5      tidyr_1.3.1     </span></span>
<span><span class="co">#&gt; [17] tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3       </span></span>
<span><span class="co">#&gt; [21] here_1.0.1      </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; loaded via a namespace (and not attached):</span></span>
<span><span class="co">#&gt;  [1] gtable_0.3.6      shape_1.4.6.1     xfun_0.49         htmlwidgets_1.6.4</span></span>
<span><span class="co">#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2      </span></span>
<span><span class="co">#&gt;  [9] generics_0.1.3    parallel_4.4.2    pan_1.9           pacman_0.5.1     </span></span>
<span><span class="co">#&gt; [13] pkgconfig_2.0.3   jomo_2.7-6        Matrix_1.7-1      lifecycle_1.0.4  </span></span>
<span><span class="co">#&gt; [17] compiler_4.4.2    farver_2.1.2      munsell_0.5.1     mnormt_2.1.1     </span></span>
<span><span class="co">#&gt; [21] codetools_0.2-20  htmltools_0.5.8.1 yaml_2.3.10       glmnet_4.1-8     </span></span>
<span><span class="co">#&gt; [25] nloptr_2.1.1      pillar_1.10.0     MASS_7.3-61       iterators_1.0.14 </span></span>
<span><span class="co">#&gt; [29] rpart_4.1.23      boot_1.3-31       foreach_1.5.2     mitml_0.4-5      </span></span>
<span><span class="co">#&gt; [33] nlme_3.1-166      tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4    </span></span>
<span><span class="co">#&gt; [37] splines_4.4.2     rprojroot_2.0.4   fastmap_1.2.0     grid_4.4.2       </span></span>
<span><span class="co">#&gt; [41] colorspace_2.1-1  cli_3.6.3         magrittr_2.0.3    survival_3.8-3   </span></span>
<span><span class="co">#&gt; [45] broom_1.0.7       withr_3.0.2       backports_1.5.0   timechange_0.3.0 </span></span>
<span><span class="co">#&gt; [49] rmarkdown_2.29    nnet_7.3-19       lme4_1.1-35.5     hms_1.1.3        </span></span>
<span><span class="co">#&gt; [53] evaluate_1.0.1    rlang_1.1.4       Rcpp_1.0.13-1     glue_1.8.0       </span></span>
<span><span class="co">#&gt; [57] minqa_1.2.8       jsonlite_1.8.9    R6_2.5.1</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section><section id="bibliografia" class="level2 unnumbered"><h2 class="unnumbered anchored" data-anchor-id="bibliografia">Bibliografia</h2>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2" role="list">
<div id="ref-Johnson2022bayesrules" class="csl-entry" role="listitem">
Johnson, A. A., Ott, M., &amp; Dogucu, M. (2022). <em><span>Bayes Rules! An Introduction to Bayesian Modeling with R</span></em>. CRC Press.
</div>
</div>
</section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copiato!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copiato!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/ccaudek\.github\.io\/psicometria-r\/intro\.html");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="../../chapters/bayesian_inference/01_intro_bayes.html" class="pagination-link" aria-label="La quantificazione dell'incertezza">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">41</span>&nbsp; <span class="chapter-title">La quantificazione dell’incertezza</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../chapters/bayesian_inference/03_subj_prop.html" class="pagination-link" aria-label="Pensare ad una proporzione in termini soggettivi">
        <span class="nav-page-text"><span class="chapter-number">43</span>&nbsp; <span class="chapter-title">Pensare ad una proporzione in termini soggettivi</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer"><div class="nav-footer">
    <div class="nav-footer-left">
<p><strong>Psicometria</strong> è una risorsa didattica creata per il corso di Scienze e Tecniche Psicologiche dell’Università degli Studi di Firenze.</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/ccaudek/psicometria-r/blob/main/chapters/bayesian_inference/02_bayesian_inference.qmd" class="toc-action"><i class="bi bi-github"></i>Mostra il codice</a></li><li><a href="https://github.com/ccaudek/psicometria-r/issues/new" class="toc-action"><i class="bi empty"></i>Segnala un problema</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>Realizzato con <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>


</body></html>