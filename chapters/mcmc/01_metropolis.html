<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="it" xml:lang="it"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.43">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Corrado Caudek">

<title>58&nbsp; L’algoritmo di Metropolis-Hastings – Psicometria</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../chapters/mcmc/02_ppl.html" rel="next">
<link href="../../chapters/mcmc/introduction_mcmc.html" rel="prev">
<link href="../../style/gauss.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-24780e440b7fb1b729fbeae6f8e00b05.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-22738fe745beb213ea0c51c98f19f718.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Nessun risultato",
    "search-matching-documents-text": "documenti trovati",
    "search-copy-link-title": "Copiare il link nella ricerca",
    "search-hide-matches-text": "Nascondere i risultati aggiuntivi",
    "search-more-match-text": "ci sono altri risultati in questo documento",
    "search-more-matches-text": "ulteriori risultati in questo documento",
    "search-clear-button-title": "Pulire",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancellare",
    "search-submit-button-title": "Inviare",
    "search-label": "Ricerca"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-QT5S3P9D31"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-QT5S3P9D31', { 'anonymize_ip': true});
</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Attiva/disattiva la barra laterale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../chapters/mcmc/introduction_mcmc.html">MCMC</a></li><li class="breadcrumb-item"><a href="../../chapters/mcmc/01_metropolis.html"><span class="chapter-number">58</span>&nbsp; <span class="chapter-title">L’algoritmo di Metropolis-Hastings</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Attiva/disattiva la barra laterale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Ricerca" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../../">Psicometria</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/ccaudek/psicometria-r/" title="Eseguire il codice" class="quarto-navigation-tool px-1" aria-label="Eseguire il codice"><i class="bi bi-github"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Attiva/disattiva la modalità lettore">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Ricerca"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Informazioni Generali</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../prefazione.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Prefazione</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../chapters/key_notions/introduction_key_notions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Fondamenti</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/key_notions/01_key_notions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Concetti chiave</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/key_notions/02_design.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Campionamento, metodologia sperimentale e studi osservazionali</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/key_notions/03_measurement.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">La misurazione in psicologia</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/key_notions/04_data_analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/key_notions/05_cognitive_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Modelli cognitivi</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../chapters/R/introduction_r_lang.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">R</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/R/01_r_syntax.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Un approccio moderno all’analisi dei dati</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/R/02_utility_functions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Utility functions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/R/03_r_programming.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Programmazione</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/R/04_r_packages.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Pacchetti</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/R/05_dplyr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Introduzione a <code>dplyr</code></span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/R/06_quarto.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Quarto</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/R/07_environment.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">L’ambiente di programmazione</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/R/08_ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Utilizzo di strumenti AI</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../chapters/eda/introduction_eda.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">EDA</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/01_project_structure.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Le fasi del progetto di analisi dei dati</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/02_data_cleaning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Flusso di lavoro per la pulizia dei dati</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/04_exploring_qualitative_data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Esplorare i dati qualitativi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/05_exploring_numeric_data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Esplorare i dati numerici</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/06_data_visualization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Principi della visualizzazione dei dati</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/07_loc_scale.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Indicatori di tendenza centrale e variabilità</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/07a_introduction_normal_distribution.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Introduzione alla distribuzione normale</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/08_correlation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Relazioni tra variabili</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/09_causality.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Causalità dai dati osservazionali</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/10_estimand.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Estimandi teorici e estimandi empirici</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/eda/11_outlier.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Outlier</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../chapters/probability/introduction_probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Probabilità</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/01_intro_prob.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Interpretazione della probabilità</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/02_probability_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Modelli probabilistici</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/03_prob_spaces.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">La Probabilità come misura della certezza razionale: un’interpretazione Bayesiana</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/04_sigma-algebra.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Dal Discreto al Continuo: la <span class="math inline">\(\sigma\)</span>-algebra</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/05_conditional_prob.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Probabilità condizionata</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/06_bayes_theorem.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Il teorema di Bayes</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/07_random_var.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Variabili casuali</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/08_prob_distributions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">Distribuzioni di massa e di densità</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/09_expval_var.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">Proprietà delle variabili casuali</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/10_sampling_distr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">34</span>&nbsp; <span class="chapter-title">Stime, stimatori e parametri</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/11a_joint_prob.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">35</span>&nbsp; <span class="chapter-title">Probabilità congiunta</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/11b_cov_cor.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">36</span>&nbsp; <span class="chapter-title">Covarianza e correlazione</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/11c_joint_prob_cont.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">37</span>&nbsp; <span class="chapter-title">Caso continuo</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/12a_intro_distributions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">38</span>&nbsp; <span class="chapter-title">Introduzione alle distribuzioni di probabilità</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/12_discr_rv_distr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">39</span>&nbsp; <span class="chapter-title">Distribuzioni di v.c. discrete</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/13_cont_rv_distr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">40</span>&nbsp; <span class="chapter-title">Distribuzioni di v.c. continue</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/14_gauss.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">41</span>&nbsp; <span class="chapter-title">Assunzione di gaussianità e trasformazioni dei dati</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/15_likelihood.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">42</span>&nbsp; <span class="chapter-title">La verosimiglianza</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/16_likelihood_gauss.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">43</span>&nbsp; <span class="chapter-title">La verosimiglianza gaussiana</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/probability/17_likelihood_ratio.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">44</span>&nbsp; <span class="chapter-title">Il rapporto di verosimiglianze</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false">
 <span class="menu-text">Inferenza</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/introduction_bayes_inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/01_uncertainty.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">45</span>&nbsp; <span class="chapter-title">Abbracciare l’incertezza</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/02_intro_bayes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">46</span>&nbsp; <span class="chapter-title">La quantificazione dell’incertezza</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/03_statistical_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">47</span>&nbsp; <span class="chapter-title">Modelli statistici</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/04_bayesian_inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">48</span>&nbsp; <span class="chapter-title">Inferenza bayesiana</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/05_subj_prop.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">49</span>&nbsp; <span class="chapter-title">Pensare ad una proporzione in termini soggettivi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/06_grid_gauss.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">50</span>&nbsp; <span class="chapter-title">Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/07_conjugate_families_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">51</span>&nbsp; <span class="chapter-title">Distribuzioni coniugate (1)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/08_conjugate_families_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">52</span>&nbsp; <span class="chapter-title">Distribuzioni coniugate (2)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/09_summary_posterior.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">53</span>&nbsp; <span class="chapter-title">Sintesi a posteriori</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/10_balance_prior_post.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">54</span>&nbsp; <span class="chapter-title">L’influenza della distribuzione a priori</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/11_gamma_poisson_model.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">55</span>&nbsp; <span class="chapter-title">Modello coniugato Gamma-Poisson</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/12_gamma_exponential_model.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">56</span>&nbsp; <span class="chapter-title">Modello gamma-esponenziale</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/13_post_pred_distr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">57</span>&nbsp; <span class="chapter-title">Distribuzione predittiva a posteriori</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">MCMC</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/introduction_mcmc.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/01_metropolis.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">58</span>&nbsp; <span class="chapter-title">L’algoritmo di Metropolis-Hastings</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/02_ppl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">59</span>&nbsp; <span class="chapter-title">Linguaggi di programmazione probabilistici</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/07_bayesian_workflow.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">60</span>&nbsp; <span class="chapter-title">Flusso di lavoro bayesiano</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="false">
 <span class="menu-text">Regressione</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/introduction_linear_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/01_reglin_frequentist.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">61</span>&nbsp; <span class="chapter-title">La regressione lineare bivariata: un approccio frequentista</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/02_regr_toward_mean.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">62</span>&nbsp; <span class="chapter-title">La regressione verso la media</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/03_reglin_bayes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">63</span>&nbsp; <span class="chapter-title">Modello bayesiano di regressione lineare bivariata</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/04_synt_sugar.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">64</span>&nbsp; <span class="chapter-title">Zucchero sintattico</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/05_one_mean.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">65</span>&nbsp; <span class="chapter-title">Inferenza bayesiana su una media</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/06_prediction_stan.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">66</span>&nbsp; <span class="chapter-title">Predizione e inferenza</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/07_two_means.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">67</span>&nbsp; <span class="chapter-title">Confronto tra le medie di due gruppi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/08_sample_size.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">68</span>&nbsp; <span class="chapter-title">Disegno della ricerca e potere statistico</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/09_anova_1via.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">69</span>&nbsp; <span class="chapter-title">ANOVA ad una via</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/10_anova_2vie.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">70</span>&nbsp; <span class="chapter-title">ANOVA ad due vie</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/11_one_proportion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">71</span>&nbsp; <span class="chapter-title">Inferenza sulle proporzioni</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/12_two_proportions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">72</span>&nbsp; <span class="chapter-title">Confronto tra due proporzioni indipendenti</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/13_poisson_model.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">73</span>&nbsp; <span class="chapter-title">Modello di Poisson</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="false">
 <span class="menu-text">Frequentismo</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/frequentist_inference/introduction_frequentist_inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/frequentist_inference/01_intro_frequentist.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">74</span>&nbsp; <span class="chapter-title">Inferenza frequentista</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/frequentist_inference/01a_stime_parametri.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">75</span>&nbsp; <span class="chapter-title">Stime, stimatori e parametri</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/frequentist_inference/02_conf_interv.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">76</span>&nbsp; <span class="chapter-title">Intervalli di fiducia</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/frequentist_inference/03_sample_size.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">77</span>&nbsp; <span class="chapter-title">La grandezza del campione</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/frequentist_inference/04_test_ipotesi.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">78</span>&nbsp; <span class="chapter-title">Significatività statistica</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/frequentist_inference/05_two_ind_samples.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">79</span>&nbsp; <span class="chapter-title">Test t di Student per campioni indipendenti</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="false">
 <span class="menu-text">Crisi</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/introduction_replication_crisis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/01_crisis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">80</span>&nbsp; <span class="chapter-title">La crisi della replicazione</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/02_limits_stat_freq.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">81</span>&nbsp; <span class="chapter-title">Limiti dell’inferenza frequentista</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/03_effect_size.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">82</span>&nbsp; <span class="chapter-title">La grandezza dell’effetto</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/04_s_m_errors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">83</span>&nbsp; <span class="chapter-title">Errori di segno e errori di grandezza</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/05_p_values.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">84</span>&nbsp; <span class="chapter-title">La fragilità del <em>p</em>-valore</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/06_changes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">85</span>&nbsp; <span class="chapter-title">Riforma</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/07_piranha.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">86</span>&nbsp; <span class="chapter-title">Il Problema del priming: sfide e paradossi nella psicologia sociale</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/08_degrees_of_freedom.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">87</span>&nbsp; <span class="chapter-title">I gradi di libertà del ricercatore</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/09_integrity.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">88</span>&nbsp; <span class="chapter-title">Integrità della ricerca</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="false">
 <span class="menu-text">Epilogo</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/epiloque/epiloque.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Considerazioni Conclusive</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="false">
 <span class="menu-text">Appendici</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-11" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a01_shell.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">La Shell</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a01a_files.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Cartelle e documenti</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a02_math_symbols.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Simbologia di base</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a03_latex.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Equazioni Matematiche in LaTeX</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a11_numbers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">E</span>&nbsp; <span class="chapter-title">Numeri e intervalli</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a12_sum_notation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">F</span>&nbsp; <span class="chapter-title">Sommatorie</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a13_sets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">G</span>&nbsp; <span class="chapter-title">Insiemi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a14_combinatorics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">H</span>&nbsp; <span class="chapter-title">Calcolo combinatorio</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a15_calculus.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">I</span>&nbsp; <span class="chapter-title">Per liberarvi dai terrori preliminari</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a47_first_order_markov.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">J</span>&nbsp; <span class="chapter-title">Catene di Markov</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a50_lin_fun.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">K</span>&nbsp; <span class="chapter-title">La funzione lineare</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a71_install_cmdstan.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">L</span>&nbsp; <span class="chapter-title">Come installare CmdStan</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Indice</h2>
   
  <ul class="collapse">
  <li><a href="#introduzione" id="toc-introduzione" class="nav-link active" data-scroll-target="#introduzione"><span class="header-section-number">58.1</span> Introduzione</a></li>
  <li><a href="#il-denominatore-bayesiano" id="toc-il-denominatore-bayesiano" class="nav-link" data-scroll-target="#il-denominatore-bayesiano"><span class="header-section-number">58.2</span> Il denominatore bayesiano</a></li>
  <li><a href="#il-metodo-monte-carlo-e-le-sue-limitazioni" id="toc-il-metodo-monte-carlo-e-le-sue-limitazioni" class="nav-link" data-scroll-target="#il-metodo-monte-carlo-e-le-sue-limitazioni"><span class="header-section-number">58.3</span> Il metodo Monte Carlo e le sue limitazioni</a></li>
  <li><a href="#perché-i-metodi-mcmc-sono-necessari" id="toc-perché-i-metodi-mcmc-sono-necessari" class="nav-link" data-scroll-target="#perché-i-metodi-mcmc-sono-necessari"><span class="header-section-number">58.4</span> Perché i metodi MCMC sono necessari</a></li>
  <li><a href="#le-catene-di-markov" id="toc-le-catene-di-markov" class="nav-link" data-scroll-target="#le-catene-di-markov"><span class="header-section-number">58.5</span> Le Catene di Markov</a></li>
  <li><a href="#estrazione-di-campioni-dalla-distribuzione-a-posteriori" id="toc-estrazione-di-campioni-dalla-distribuzione-a-posteriori" class="nav-link" data-scroll-target="#estrazione-di-campioni-dalla-distribuzione-a-posteriori"><span class="header-section-number">58.6</span> Estrazione di campioni dalla distribuzione a posteriori</a></li>
  <li><a href="#esempio-di-implementazione" id="toc-esempio-di-implementazione" class="nav-link" data-scroll-target="#esempio-di-implementazione"><span class="header-section-number">58.7</span> Esempio di Implementazione</a></li>
  <li><a href="#catene-di-markov-e-convergenza" id="toc-catene-di-markov-e-convergenza" class="nav-link" data-scroll-target="#catene-di-markov-e-convergenza"><span class="header-section-number">58.8</span> Catene di Markov e Convergenza</a></li>
  <li><a href="#diagnostiche-della-soluzione-mcmc" id="toc-diagnostiche-della-soluzione-mcmc" class="nav-link" data-scroll-target="#diagnostiche-della-soluzione-mcmc"><span class="header-section-number">58.9</span> Diagnostiche della soluzione MCMC</a></li>
  <li><a href="#vantaggi-del-campionamento-mcmc-rispetto-alle-soluzioni-analitiche" id="toc-vantaggi-del-campionamento-mcmc-rispetto-alle-soluzioni-analitiche" class="nav-link" data-scroll-target="#vantaggi-del-campionamento-mcmc-rispetto-alle-soluzioni-analitiche"><span class="header-section-number">58.10</span> Vantaggi del Campionamento MCMC rispetto alle Soluzioni Analitiche</a></li>
  <li><a href="#caso-normale-normale-con-soluzione-analitica" id="toc-caso-normale-normale-con-soluzione-analitica" class="nav-link" data-scroll-target="#caso-normale-normale-con-soluzione-analitica"><span class="header-section-number">58.11</span> Caso Normale-Normale con Soluzione Analitica</a></li>
  <li><a href="#riflessioni-conclusive" id="toc-riflessioni-conclusive" class="nav-link" data-scroll-target="#riflessioni-conclusive"><span class="header-section-number">58.12</span> Riflessioni Conclusive</a></li>
  <li><a href="#informazioni-sullambiente-di-sviluppo" id="toc-informazioni-sullambiente-di-sviluppo" class="nav-link" data-scroll-target="#informazioni-sullambiente-di-sviluppo">Informazioni sull’Ambiente di Sviluppo</a></li>
  <li><a href="#bibliografia" id="toc-bibliografia" class="nav-link" data-scroll-target="#bibliografia">Bibliografia</a></li>
  </ul>
<div class="toc-actions"><ul class="collapse"><li><a href="https://github.com/ccaudek/psicometria-r/blob/main/chapters/mcmc/01_metropolis.qmd" class="toc-action"><i class="bi bi-github"></i>Mostra il codice</a></li><li><a href="https://github.com/ccaudek/psicometria-r/issues/new" class="toc-action"><i class="bi empty"></i>Segnala un problema</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../chapters/mcmc/introduction_mcmc.html">MCMC</a></li><li class="breadcrumb-item"><a href="../../chapters/mcmc/01_metropolis.html"><span class="chapter-number">58</span>&nbsp; <span class="chapter-title">L’algoritmo di Metropolis-Hastings</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="sec-mcmc-metropolis" class="quarto-section-identifier"><span class="chapter-number">58</span>&nbsp; <span class="chapter-title">L’algoritmo di Metropolis-Hastings</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
In questo capitolo imparerai a
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>utilizzare metodi Monte Carlo per stimare valori attesi e probabilità, evitando calcoli integrali complessi</li>
<li>comprendere il ruolo delle catene di Markov nel campionamento dalla distribuzione a posteriori</li>
<li>implementare l’algoritmo di Metropolis per il campionamento a posteriori.<br>
</li>
<li>valutare la convergenza delle catene con strumenti diagnostici come trace plot e autocorrelazione</li>
<li>gestire la fase di burn-in e utilizzare più catene per garantire stazionarietà e ridurre l’autocorrelazione<br>
</li>
</ul>
</div>
</div>
<div class="callout callout-style-simple callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Prerequisiti
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Leggere l’appendice <a href="../appendix/a15_calculus.html" class="quarto-xref"><span>Appendice I</span></a>.</li>
</ul>
</div>
</div>
<div class="callout callout-style-simple callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Preparazione del Notebook
</div>
</div>
<div class="callout-body-container callout-body">
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>here<span class="sc">::</span><span class="fu">here</span>(<span class="st">"code"</span>, <span class="st">"_common.R"</span>) <span class="sc">|&gt;</span> </span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">source</span>()</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Load packages</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> (<span class="sc">!</span><span class="fu">requireNamespace</span>(<span class="st">"pacman"</span>)) <span class="fu">install.packages</span>(<span class="st">"pacman"</span>)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>pacman<span class="sc">::</span><span class="fu">p_load</span>(cmdstanr)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
<section id="introduzione" class="level2" data-number="58.1">
<h2 data-number="58.1" class="anchored" data-anchor-id="introduzione"><span class="header-section-number">58.1</span> Introduzione</h2>
<p>In precedenza, abbiamo esplorato diversi esempi di inferenza bayesiana riguardanti la distribuzione a posteriori di un singolo parametro, come nel caso del modello bernoulliano. Abbiamo anche trattato metodi come l’approssimazione tramite griglia e l’utilizzo dei priori coniugati per ottenere o approssimare la distribuzione a posteriori. In questo capitolo, ci concentreremo sul metodo di simulazione Monte Carlo a Catena di Markov (MCMC).</p>
<p>Il metodo MCMC è una tecnica computazionale utilizzata per approssimare distribuzioni di probabilità complesse, generando una sequenza di campioni (correlati) attraverso una catena di Markov, in cui ogni campione viene ottenuto tramite una transizione iterativa con probabilità attentamente progettate.</p>
<p>Il metodo MCMC rappresenta l’approccio moderno per approssimare distribuzioni a posteriori complesse. L’idea di base è simile al concetto di considerare la distribuzione a posteriori come una popolazione da cui estraiamo campioni ripetutamente. Con un numero sufficientemente grande di campioni (ad esempio 1000), la distribuzione del campione si avvicina molto alla distribuzione della popolazione, consentendo stime affidabili dei parametri incogniti.</p>
<p>Una differenza rispetto all’analogia precedente è che i campioni generati con MCMC sono correlati: se il primo campione ha un valore alto, anche il successivo ha maggiori probabilità di essere alto. Questo accade perché non abbiamo un modo diretto per estrarre campioni dalla distribuzione a posteriori, che spesso ha una forma molto complessa; utilizziamo invece algoritmi che ci permettono di arrivarci indirettamente. La correlazione tra i campioni non rappresenta un problema rilevante, ma rende necessario estrarre un numero maggiore di campioni per compensare questa correlazione e ottenere stime accurate.</p>
</section>
<section id="il-denominatore-bayesiano" class="level2" data-number="58.2">
<h2 data-number="58.2" class="anchored" data-anchor-id="il-denominatore-bayesiano"><span class="header-section-number">58.2</span> Il denominatore bayesiano</h2>
<p>Nell’approccio bayesiano, l’obiettivo principale è determinare la distribuzione a posteriori <span class="math inline">\(p(\theta \mid y)\)</span> di un parametro <span class="math inline">\(\theta\)</span>, utilizzando i dati osservati <span class="math inline">\(y\)</span> e la distribuzione a priori <span class="math inline">\(p(\theta)\)</span>. Questo si ottiene attraverso il teorema di Bayes:</p>
<p><span class="math display">\[
p(\theta \mid y) = \frac{p(y \mid \theta) p(\theta)}{\int p(y \mid \theta) p(\theta) d\theta}.
\]</span></p>
<p>Il denominatore <span class="math inline">\(\int p(y \mid \theta) p(\theta) d\theta\)</span> rappresenta la probabilità marginale di <span class="math inline">\(y\)</span>, chiamata <strong>evidenza</strong>. Tale integrale garantisce che <span class="math inline">\(p(\theta \mid y)\)</span> sia una distribuzione di probabilità valida. Tuttavia, il calcolo di questo integrale è spesso complesso, soprattutto in modelli articolati o ad alta dimensionalità, rendendo difficile ottenere una rappresentazione esplicita della distribuzione a posteriori.</p>
<p>Una possibile semplificazione analitica è l’uso di distribuzioni a priori coniugate, che offrono una soluzione esatta per la distribuzione a posteriori. Tuttavia, questo approccio è limitato a casi specifici e impone forti vincoli sulla scelta delle distribuzioni a priori e delle verosimiglianze.</p>
<p>Un approccio più generale è ricorrere a soluzioni numeriche. In precedenza abbiamo discusso il metodo di campionamento a griglia. Tuttavia, i metodi di campionamento a griglia, sebbene efficaci per modelli con pochi parametri, diventano impraticabili man mano che il numero di parametri aumenta, poiché richiedono una copertura densa dell’intero spazio parametrico. Di conseguenza, per modelli più complessi e con più parametri, si rende necessario un metodo che possa esplorare lo spazio dei parametri in maniera più efficiente.</p>
</section>
<section id="il-metodo-monte-carlo-e-le-sue-limitazioni" class="level2" data-number="58.3">
<h2 data-number="58.3" class="anchored" data-anchor-id="il-metodo-monte-carlo-e-le-sue-limitazioni"><span class="header-section-number">58.3</span> Il metodo Monte Carlo e le sue limitazioni</h2>
<p>Il metodo Monte Carlo fornisce una soluzione a questo problema generando campioni casuali dalla distribuzione a posteriori <span class="math inline">\(p(\theta \mid y)\)</span>. L’idea centrale è semplice: se possiamo generare un numero sufficiente di campioni casuali dalla distribuzione a posteriori, possiamo usare questi campioni per stimare le proprietà d’interesse, come la media o la varianza del parametro <span class="math inline">\(\theta\)</span>. Questa procedura ci permette di evitare il calcolo diretto dell’integrale complicato nel denominatore del teorema di Bayes.</p>
<p>Per esempio, se fossimo in grado di generare una serie di campioni <span class="math inline">\(\theta^{(1)}, \theta^{(2)}, \dots, \theta^{(T)}\)</span> dalla distribuzione a posteriori, potremmo approssimare il valore atteso di <span class="math inline">\(\theta\)</span> con la media campionaria:</p>
<p><span class="math display">\[
\mathbb{E}[\theta] \approx \frac{1}{T} \sum_{t=1}^T \theta^{(t)}.
\]</span></p>
<p>Tuttavia, un problema nei metodi Monte Carlo tradizionali è che generare campioni indipendenti dalla distribuzione a posteriori non è semplice, soprattutto quando questa distribuzione ha una forma complessa, è multimodale o definita su spazi di alta dimensionalità. Le regioni di alta densità, che contribuiscono maggiormente al valore dell’integrale, possono essere difficili da individuare e campionare adeguatamente. Per ottenere una buona copertura dello spazio dei parametri, sarebbe necessario generare un numero enorme di campioni, rendendo il metodo Monte Carlo inefficiente e computazionalmente oneroso.</p>
</section>
<section id="perché-i-metodi-mcmc-sono-necessari" class="level2" data-number="58.4">
<h2 data-number="58.4" class="anchored" data-anchor-id="perché-i-metodi-mcmc-sono-necessari"><span class="header-section-number">58.4</span> Perché i metodi MCMC sono necessari</h2>
<p>È qui che entrano in gioco i Metodi Monte Carlo a Catena di Markov (MCMC). Questi metodi risolvono il problema generando campioni <strong>dipendenti</strong> dalla distribuzione a posteriori, sfruttando la struttura di una catena di Markov. A differenza dei campioni indipendenti utilizzati nei metodi Monte Carlo tradizionali, i metodi MCMC costruiscono una sequenza di campioni, in cui ciascun campione dipende dal precedente. Questa dipendenza permette di esplorare in modo più efficiente le regioni di alta densità della distribuzione a posteriori, riducendo il numero di campioni necessari per ottenere stime accurate.</p>
<p>In pratica, MCMC consente di evitare di campionare inutilmente da regioni di bassa densità, concentrandosi invece sulle aree più rilevanti della distribuzione. Questo approccio è particolarmente potente nei contesti ad alta dimensionalità o in presenza di distribuzioni multimodali, dove i metodi Monte Carlo tradizionali risulterebbero inefficaci o richiederebbero un numero sproporzionato di campioni.</p>
<p>In sintesi, i metodi Monte Carlo classici sono limitati quando si tratta di campionare da distribuzioni complesse e multidimensionali. I metodi MCMC, invece, offrono una soluzione efficiente e flessibile, permettendo di esplorare le distribuzioni a posteriori anche in contesti complessi, senza la necessità di campionare indipendentemente ogni punto. Nel prossimo paragrafo introdurremo i concetti fondamentali delle catene di Markov e vedremo come queste vengono utilizzate nei metodi MCMC per campionare efficacemente da distribuzioni a posteriori difficili da trattare analiticamente.</p>
</section>
<section id="le-catene-di-markov" class="level2" data-number="58.5">
<h2 data-number="58.5" class="anchored" data-anchor-id="le-catene-di-markov"><span class="header-section-number">58.5</span> Le Catene di Markov</h2>
<p>Le catene di Markov, introdotte da Andrey Markov nel 1906, rappresentano un’estensione della legge dei grandi numeri per descrivere sequenze di variabili casuali <strong>non indipendenti</strong>. Nella statistica tradizionale, si lavora spesso con sequenze di variabili casuali indipendenti e identicamente distribuite (i.i.d.), come <span class="math inline">\(X_0, X_1, \ldots, X_n, \ldots\)</span>, dove ogni variabile è indipendente dalle altre e segue la stessa distribuzione. Tuttavia, nei modelli più realistici che descrivono fenomeni complessi, l’indipendenza tra variabili è un’assunzione troppo rigida e spesso irrealistica.</p>
<p>Le catene di Markov superano questo limite introducendo una dipendenza locale, detta <strong>dipendenza a un passo</strong>, formalizzata nella cosiddetta <strong>proprietà di Markov</strong>. Secondo questa proprietà, il valore futuro di una variabile casuale <span class="math inline">\(X_{n+1}\)</span> dipende unicamente dal valore attuale <span class="math inline">\(X_n\)</span>, ignorando tutta la storia precedente della catena. Questo permette di semplificare notevolmente i calcoli relativi alle probabilità condizionali. La proprietà di Markov è formalmente espressa come:</p>
<p><span class="math display">\[
P(X_{n+1} = j | X_n = i, X_{n-1} = i_{n-1}, \ldots, X_0 = i_0) = P(X_{n+1} = j | X_n = i).
\]</span></p>
<p>In altre parole, la previsione di un evento futuro dipende soltanto dallo stato attuale e non da tutti gli eventi precedenti, semplificando così il processo di modellazione. Questa caratteristica rende le catene di Markov particolarmente utili per descrivere sistemi dinamici in cui gli eventi successivi sono influenzati solo dallo stato immediatamente precedente.</p>
<section id="catene-di-markov-e-metodi-mcmc" class="level3" data-number="58.5.1">
<h3 data-number="58.5.1" class="anchored" data-anchor-id="catene-di-markov-e-metodi-mcmc"><span class="header-section-number">58.5.1</span> Catene di Markov e Metodi MCMC</h3>
<p>Le catene di Markov sono fondamentali nei metodi Monte Carlo a Catena di Markov (MCMC) perché forniscono un modo efficiente per generare sequenze di campioni che approssimano distribuzioni di probabilità complesse. Mentre i metodi Monte Carlo classici generano campioni indipendenti, i metodi MCMC costruiscono una sequenza di campioni dipendenti attraverso una catena di Markov, in cui ciascun campione è ottenuto in base al campione precedente. Questo approccio consente di concentrarsi sulle regioni di alta probabilità della distribuzione, migliorando l’efficienza del campionamento.</p>
<p>Per esempio, consideriamo una distribuzione di probabilità <span class="math inline">\(P(x_1, x_2, ..., x_n)\)</span> definita su un insieme di variabili <span class="math inline">\(x_1, x_2, ..., x_n\)</span>. Nei metodi MCMC, si genera una sequenza di configurazioni <span class="math inline">\(\{x(0)\}, \{x(1)\}, \{x(2)\}, \dots\)</span>, tale che la frequenza con cui ogni configurazione <span class="math inline">\(\{x\}\)</span> viene visitata è proporzionale alla sua probabilità <span class="math inline">\(P(x)\)</span>. In questo modo, le configurazioni più probabili vengono visitate più spesso, garantendo che l’algoritmo converga alla distribuzione di interesse.</p>
</section>
<section id="condizioni-fondamentali-per-le-catene-di-markov" class="level3" data-number="58.5.2">
<h3 data-number="58.5.2" class="anchored" data-anchor-id="condizioni-fondamentali-per-le-catene-di-markov"><span class="header-section-number">58.5.2</span> Condizioni fondamentali per le Catene di Markov</h3>
<p>Affinché un algoritmo MCMC funzioni correttamente e converga alla distribuzione desiderata, la catena di Markov deve soddisfare alcune condizioni fondamentali:</p>
<ul>
<li><strong>Proprietà di Markov:</strong> La prossima configurazione dipende solo dalla configurazione attuale, non dalla storia passata. Questo garantisce che l’evoluzione della catena sia “locale” e non influenzata dagli stati remoti.</li>
<li><strong>Irriducibilità:</strong> Ogni configurazione della catena può essere raggiunta da qualsiasi altra in un numero finito di passi. Ciò assicura che l’intero spazio dei parametri possa essere esplorato.</li>
<li><strong>Aperiodicità:</strong> La catena non segue cicli fissi e non ritorna sistematicamente allo stesso stato dopo un certo numero di passi. Questo garantisce che la catena possa esplorare lo spazio dei parametri in modo casuale.</li>
<li><strong>Condizione di bilanciamento dettagliato:</strong> La probabilità di passare da uno stato a un altro deve essere bilanciata dalla probabilità di tornare allo stato iniziale, assicurando così che la distribuzione di equilibrio della catena sia proprio la distribuzione a posteriori desiderata.</li>
</ul>
</section>
<section id="algoritmi-mcmc" class="level3" data-number="58.5.3">
<h3 data-number="58.5.3" class="anchored" data-anchor-id="algoritmi-mcmc"><span class="header-section-number">58.5.3</span> Algoritmi MCMC</h3>
<p>Esistono diversi algoritmi basati su MCMC, ognuno con caratteristiche specifiche:</p>
<ul>
<li><p><strong>Metropolis-Hastings:</strong> Questo è uno degli algoritmi più noti. Si basa sulla generazione di una configurazione proposta che viene accettata o rifiutata in base a un criterio di probabilità. Se la configurazione proposta ha una probabilità più alta, viene accettata; se ha una probabilità più bassa, può essere accettata con una certa probabilità, che dipende dal rapporto tra le probabilità delle due configurazioni.</p></li>
<li><p><strong>Gibbs Sampling:</strong> In questo algoritmo, le variabili vengono aggiornate una alla volta, campionando ogni variabile dalla sua distribuzione condizionale data la configurazione corrente delle altre variabili. È particolarmente utile quando le distribuzioni condizionali sono note o facili da campionare.</p></li>
<li><p><strong>Hamiltonian Monte Carlo (HMC):</strong> Utilizza principi della meccanica hamiltoniana per esplorare lo spazio dei parametri in modo più efficiente, considerando non solo le probabilità, ma anche le “forze” che muovono i campioni attraverso lo spazio dei parametri. Questo approccio è particolarmente vantaggioso per modelli complessi e ad alta dimensionalità, poiché consente di generare campioni lontani dallo stato corrente senza ricorrere a piccoli passi.</p></li>
</ul>
<p>In sintesi, le catene di Markov forniscono il fondamento teorico e pratico per i metodi MCMC, offrendo un modo efficiente per esplorare lo spazio dei parametri nei modelli complessi. Grazie alle proprietà specifiche delle catene di Markov, i metodi MCMC permettono di affrontare problemi di inferenza bayesiana che sarebbero intrattabili con approcci analitici o con i metodi Monte Carlo classici. Essendo flessibili e potenti, le catene di Markov continueranno a essere uno strumento fondamentale nella statistica e nella scienza dei dati.</p>
</section>
</section>
<section id="estrazione-di-campioni-dalla-distribuzione-a-posteriori" class="level2" data-number="58.6">
<h2 data-number="58.6" class="anchored" data-anchor-id="estrazione-di-campioni-dalla-distribuzione-a-posteriori"><span class="header-section-number">58.6</span> Estrazione di campioni dalla distribuzione a posteriori</h2>
<p>In questo capitolo presenteremo l’algoritmo di Metropolis, che è uno dei più semplici e potenti metodi MCMC. Sfruttando la struttura delle catene di Markov, esplora in modo efficiente lo spazio dei parametri, permettendo di ottenere campioni dalla distribuzione a posteriori anche in casi complessi, dove i metodi analitici falliscono. In sostanza, il MCMC genera un gran numero di valori per il parametro <span class="math inline">\(\theta\)</span> che, nel loro insieme, approssimano la distribuzione di interesse <span class="math inline">\(p(\theta \mid y)\)</span>. A questo fine, il capitolo è strutturato in varie sezioni che facilitano la comprensione progressiva del tema.</p>
<ul>
<li>Inizieremo discutendo di come la distribuzione a posteriori possa essere approssimata mediante tecniche di simulazione convenzionali. Questa prima parte presuppone che la distribuzione target, o “a posteriori,” sia già conosciuta o disponibile per l’analisi.</li>
<li>In seguito, passeremo a illustrare come l’algoritmo di Metropolis possa essere utilizzato per affrontare situazioni in cui la distribuzione a posteriori non è direttamente nota. In questi casi, spesso abbiamo a disposizione informazioni riguardanti la distribuzione a priori e la funzione di verosimiglianza, che possono essere utilizzate per ottenere un’approssimazione efficace della distribuzione a posteriori.</li>
</ul>
<p>A titolo esemplificativo, utilizzeremo il dataset <code>moma_sample.csv</code>, il quale costituisce un campione casuale di 100 artisti provenienti dal Museo di Arte Moderna di New York (MoMA) e contiene diverse informazioni relative a ciascun artista.</p>
<p>Il nostro interesse è focalizzato sulla determinazione della probabilità che un artista presente nel MoMA appartenga alla generazione X o a una generazione successiva (nati dopo il 1965). Questa probabilità sarà indicata come <span class="math inline">\(\pi\)</span>.</p>
<p>Importiamo i dati.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>moma_sample <span class="ot">&lt;-</span> rio<span class="sc">::</span><span class="fu">import</span>(here<span class="sc">::</span><span class="fu">here</span>(<span class="st">"data"</span>, <span class="st">"moma_sample.csv"</span>))</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Esaminiamo le prime cinque righe del DataFrame.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>moma_sample <span class="sc">|&gt;</span> </span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">head</span>()</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;                artist  country birth death alive  genx gender count</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1        Ad Gerritsen    dutch  1940  2015 FALSE FALSE   male     1</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 Kirstine Roepstorff   danish  1972    NA  TRUE  TRUE female     3</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3    Lisa Baumgardner american  1958  2015 FALSE FALSE female     2</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4         David Bates american  1952    NA  TRUE FALSE   male     1</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 5          Simon Levy american  1946    NA  TRUE FALSE   male     1</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 6      Pierre Mercure canadian  1927  1966 FALSE FALSE   male     8</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   year_acquired_min year_acquired_max</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1              1981              1981</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2              2005              2005</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3              2016              2016</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4              2001              2001</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 5              2012              2012</span></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 6              2008              2008</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Dai dati osserviamo che solo 14 artisti su 100 appartengono alla generazione X o a una generazione successiva.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calcoliamo la distribuzione delle generazioni</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>result <span class="ot">&lt;-</span> <span class="fu">table</span>(moma_sample<span class="sc">$</span>genx)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>result</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; FALSE  TRUE </span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    86    14</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Il valore campionato <span class="math inline">\(y = 14\)</span> riflette le caratteristiche del campione che è stato osservato. Tuttavia, poiché il MOMA contiene opere di migliaia di artisti, sorge una domanda riguardante il vero valore di <span class="math inline">\(\theta\)</span> (la probabilità di appartenere alla generazione X o a una generazione successiva) all’interno di questa popolazione.</p>
<p>Possiamo interpretare i dati <span class="math inline">\(y = 14\)</span> come l’esito di una variabile casuale Binomiale con parametri <span class="math inline">\(N = 100\)</span> e <span class="math inline">\(\theta\)</span> sconosciuto.</p>
<p>Supponiamo che le nostre credenze pregresse riguardo a <span class="math inline">\(\theta\)</span> possano essere modellate attraverso una distribuzione Beta(4, 6).</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(<span class="at">x =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, .<span class="dv">01</span>),</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="fu">dbeta</span>(x, <span class="dv">4</span>, <span class="dv">6</span>)) <span class="sc">|&gt;</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x=</span>x, <span class="at">y=</span>y)) <span class="sc">+</span> </span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>()</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="01_metropolis_files/figure-html/unnamed-chunk-5-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<p>Sfruttando le proprietà delle distribuzioni coniugate, possiamo calcolare esattamente la distribuzione a posteriori:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Y ~ Binomiale(100, π)</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="co"># θ ~ Beta(4, 6)</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Posteriori: θ | (Y = 14) ~ Beta(4 + 14, 6 + 100 - 14) → Beta(18, 92)</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Nella figura seguente, è rappresentata la distribuzione a posteriori del parametro <span class="math inline">\(\theta\)</span>, insieme alla distribuzione a priori specificata.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Generiamo la sequenza dei valori per θ</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="at">length.out =</span> <span class="dv">1000</span>)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Calcoliamo le densità della prior e della posterior</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>prior_density <span class="ot">&lt;-</span> <span class="fu">dbeta</span>(x, <span class="dv">4</span>, <span class="dv">6</span>)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>posterior_density <span class="ot">&lt;-</span> <span class="fu">dbeta</span>(x, <span class="dv">18</span>, <span class="dv">92</span>)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Creare un dataframe contenente i dati per il grafico</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> x,</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">prior =</span> prior_density,</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">posterior =</span> posterior_density</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Convertiamo i dati in formato "lungo" per facilitare la visualizzazione con ggplot2</span></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>df_long <span class="ot">&lt;-</span> reshape2<span class="sc">::</span><span class="fu">melt</span>(df, <span class="at">id.vars =</span> <span class="st">"x"</span>, </span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>                          <span class="at">measure.vars =</span> <span class="fu">c</span>(<span class="st">"prior"</span>, <span class="st">"posterior"</span>),</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>                          <span class="at">variable.name =</span> <span class="st">"distribuzione"</span>, <span class="at">value.name =</span> <span class="st">"densita"</span>)</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Creare il grafico con ggplot2</span></span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(df_long, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> densita, <span class="at">fill =</span> distribuzione)) <span class="sc">+</span></span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">color =</span> distribuzione), <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span>  <span class="co"># Aggiungere le linee per le distribuzioni</span></span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_area</span>(<span class="fu">aes</span>(<span class="at">fill =</span> distribuzione), <span class="at">alpha =</span> <span class="fl">0.5</span>, <span class="at">position =</span> <span class="st">"identity"</span>) <span class="sc">+</span>  <span class="co"># Aggiungere le aree sotto le curve</span></span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_manual</span>(</span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>    <span class="at">values =</span> <span class="fu">c</span>(<span class="st">"prior"</span> <span class="ot">=</span> <span class="fu">adjustcolor</span>(okabe_ito_palette[<span class="dv">1</span>], <span class="at">alpha.f =</span> <span class="fl">0.5</span>), </span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a>               <span class="st">"posterior"</span> <span class="ot">=</span> <span class="fu">adjustcolor</span>(okabe_ito_palette[<span class="dv">2</span>], <span class="at">alpha.f =</span> <span class="fl">0.5</span>)),</span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>    <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">"Prior: Beta(4, 6)"</span>, <span class="st">"Posterior: Beta(18, 92)"</span>)</span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(</span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a>    <span class="at">values =</span> <span class="fu">c</span>(<span class="st">"prior"</span> <span class="ot">=</span> okabe_ito_palette[<span class="dv">1</span>], <span class="st">"posterior"</span> <span class="ot">=</span> okabe_ito_palette[<span class="dv">2</span>]),</span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a>    <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">"Prior: Beta(4, 6)"</span>, <span class="st">"Posterior: Beta(18, 92)"</span>)</span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"Densità a Priori e a Posteriori"</span>,</span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Valore del Parametro"</span>,</span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Densità"</span>,</span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a>    <span class="at">fill =</span> <span class="cn">NULL</span>, <span class="at">color =</span> <span class="cn">NULL</span></span>
<span id="cb7-38"><a href="#cb7-38" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb7-39"><a href="#cb7-39" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(</span>
<span id="cb7-40"><a href="#cb7-40" aria-hidden="true" tabindex="-1"></a>    <span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">hjust =</span> <span class="fl">0.5</span>),  <span class="co"># Centrare il titolo</span></span>
<span id="cb7-41"><a href="#cb7-41" aria-hidden="true" tabindex="-1"></a>    <span class="at">legend.position =</span> <span class="st">"top"</span>  <span class="co"># Posizionare la legenda in alto</span></span>
<span id="cb7-42"><a href="#cb7-42" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="01_metropolis_files/figure-html/unnamed-chunk-6-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<p>In questo grafico, la curva blu rappresenta la distribuzione a priori <span class="math inline">\(\text{Beta}(4, 6)\)</span>, mentre la curva rossa mostra la distribuzione a posteriori <span class="math inline">\(\text{Beta}(18, 92)\)</span>. La sovrapposizione delle aree evidenzia come l’evidenza fornita dai dati modifichi la conoscenza iniziale sul parametro <span class="math inline">\(\theta\)</span>.</p>
<p>Se vogliamo conoscere il valore della media a posteriori di <span class="math inline">\(\theta\)</span>, il risultato esatto è</p>
<p><span class="math display">\[
\bar{\theta}_{post} = \frac{\alpha}{\alpha + \beta} = \frac{18}{18 + 92} \approx 0.1636.
\]</span></p>
<section id="simulazione-con-distribuzione-target-nota" class="level3" data-number="58.6.1">
<h3 data-number="58.6.1" class="anchored" data-anchor-id="simulazione-con-distribuzione-target-nota"><span class="header-section-number">58.6.1</span> Simulazione con distribuzione target nota</h3>
<p>Usiamo ora una simulazione numerica per stimare la media a posteriori di <span class="math inline">\(\theta\)</span>. Conoscendo la forma della distribuzione a posteriori <span class="math inline">\(Beta(18, 92)\)</span>, possiamo generare un campione di osservazioni casuali da questa distribuzione. Successivamente, calcoliamo la media delle osservazioni ottenute per ottenere un’approssimazione della media a posteriori.</p>
<p>Se vogliamo ottenere un risultato approssimato con un numero limitato di campioni (ad esempio, 10), possiamo utilizzare la seguente simulazione:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Generiamo 10 campioni dalla distribuzione Beta(18, 92)</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)  <span class="co"># Per riproducibilità</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">rbeta</span>(<span class="dv">10</span>, <span class="at">shape1 =</span> <span class="dv">18</span>, <span class="at">shape2 =</span> <span class="dv">92</span>)</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>y</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [1] 0.1396 0.1711 0.1319 0.1774 0.1325 0.1844 0.1963 0.1517 0.2418 0.1800</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calcoliamo la media dei campioni</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(y)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.1707</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Tuttavia, con soli 10 campioni, l’approssimazione potrebbe non essere molto accurata. Aumentando il numero di campioni, ad esempio a 10.000, possiamo ottenere una stima molto più precisa:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Generiamo 10.000 campioni e calcoliamo la media</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)  <span class="co"># Per riproducibilità</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(<span class="fu">rbeta</span>(<span class="dv">10000</span>, <span class="at">shape1 =</span> <span class="dv">18</span>, <span class="at">shape2 =</span> <span class="dv">92</span>))</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.1637</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Quando il numero di campioni dalla distribuzione a posteriori diventa molto grande, la media campionaria <em>converge</em> al valore atteso della distribuzione della popolazione. Questo principio non si applica solo alla media, ma anche ad altre statistiche descrittive come la moda e la varianza.</p>
<p>È importante sottolineare che l’applicazione della simulazione di Monte Carlo è efficace per calcolare distribuzioni a posteriori solo quando conosciamo la distribuzione stessa e possiamo utilizzare funzioni R per estrarre campioni casuali da tale distribuzione. Ciò è stato possibile nel caso della distribuzione a posteriori <span class="math inline">\(Beta(18, 92)\)</span>.</p>
<p>Tuttavia, questa situazione ideale non si verifica sempre nella pratica, poiché le distribuzioni a priori coniugate alla verosimiglianza sono spesso rare. Per esempio, nel caso di una verosimiglianza binomiale e una distribuzione a priori gaussiana, l’espressione</p>
<p><span class="math display">\[
p(\theta \mid y) = \frac{\mathrm{e}^{-(\theta - 1 / 2)^2} \theta^y (1 - \theta)^{n - y}} {\int_0^1 \mathrm{e}^{-(t - 1 / 2)^2} t^y (1 - t)^{n - y} dt}
\]</span></p>
<p>rende impossibile calcolare analiticamente la distribuzione a posteriori di <span class="math inline">\(\theta\)</span>, precludendo quindi l’utilizzo diretto di R per generare campioni casuali.</p>
<p>In queste circostanze, però, è possibile ottenere campioni casuali dalla distribuzione a posteriori mediante l’uso di metodi Monte Carlo basati su Catena di Markov (MCMC). Gli algoritmi MCMC, come ad esempio l’algoritmo Metropolis, costituiscono una classe di metodi che consentono di estrarre campioni casuali dalla distribuzione a posteriori <em>senza richiedere la conoscenza della sua rappresentazione analitica</em>. Le tecniche MCMC sono ampiamente adottate per risolvere problemi di inferenza bayesiana e rappresentano il principale strumento computazionale per ottenere stime approssimate di distribuzioni a posteriori in situazioni complesse e non analiticamente trattabili.</p>
</section>
<section id="algoritmo-di-metropolis" class="level3" data-number="58.6.2">
<h3 data-number="58.6.2" class="anchored" data-anchor-id="algoritmo-di-metropolis"><span class="header-section-number">58.6.2</span> Algoritmo di Metropolis</h3>
<p>L’algoritmo di Metropolis appartiene alla famiglia dei metodi Monte Carlo basati su catene di Markov (MCMC), sfruttando le proprietà di queste catene per generare campioni da una distribuzione target. Il suo obiettivo principale è di esplorare lo spazio dei parametri in modo efficiente, producendo campioni che approssimano la distribuzione a posteriori di interesse.</p>
</section>
<section id="principio-di-funzionamento" class="level3" data-number="58.6.3">
<h3 data-number="58.6.3" class="anchored" data-anchor-id="principio-di-funzionamento"><span class="header-section-number">58.6.3</span> Principio di Funzionamento</h3>
<p>L’algoritmo inizia da un valore iniziale per i parametri e, in ogni iterazione, genera un nuovo campione tramite una distribuzione di proposta (solitamente una distribuzione normale centrata sul valore corrente). Successivamente, decide se accettare il nuovo campione in base al confronto tra le densità posteriori del nuovo campione e di quello precedente. Questa accettazione avviene in modo probabilistico, favorendo campioni con una densità più alta ma consentendo anche l’accettazione di campioni peggiori per evitare che la catena rimanga bloccata in minimi locali.</p>
</section>
<section id="burn-in-e-convergenza" class="level3" data-number="58.6.4">
<h3 data-number="58.6.4" class="anchored" data-anchor-id="burn-in-e-convergenza"><span class="header-section-number">58.6.4</span> Burn-in e Convergenza</h3>
<p>Poiché i primi campioni potrebbero non rappresentare bene la distribuzione target, si esclude spesso una porzione iniziale della catena (fase di burn-in). Con il progredire delle iterazioni, i campioni si distribuiscono in accordo con la distribuzione stazionaria desiderata, indipendentemente dallo stato iniziale scelto. Questo processo permette di esplorare lo spazio dei parametri in modo efficiente.</p>
</section>
<section id="meccanismo-di-accettazione-e-rifiuto" class="level3" data-number="58.6.5">
<h3 data-number="58.6.5" class="anchored" data-anchor-id="meccanismo-di-accettazione-e-rifiuto"><span class="header-section-number">58.6.5</span> Meccanismo di Accettazione e Rifiuto</h3>
<p>L’algoritmo di Metropolis bilancia due esigenze opposte:</p>
<ol type="1">
<li><strong>Esplorazione</strong> di nuove aree dello spazio dei parametri.</li>
<li><strong>Sfruttamento</strong> delle informazioni già acquisite dai campioni precedenti.</li>
</ol>
<p>Utilizzando una regola probabilistica per accettare campioni peggiori (con minore densità a posteriori), l’algoritmo evita di restare intrappolato in minimi locali, esplorando così in modo più completo l’intera distribuzione.</p>
</section>
<section id="passaggi-fondamentali-dellalgoritmo-di-metropolis" class="level3" data-number="58.6.6">
<h3 data-number="58.6.6" class="anchored" data-anchor-id="passaggi-fondamentali-dellalgoritmo-di-metropolis"><span class="header-section-number">58.6.6</span> Passaggi Fondamentali dell’Algoritmo di Metropolis</h3>
<ol type="1">
<li><strong>Scelta di uno stato iniziale <span class="math inline">\(\theta_1\)</span> e impostazione del contatore <span class="math inline">\(t = 1\)</span>.</strong>
<ul>
<li>Questo è il punto di partenza della catena, dove <span class="math inline">\(\theta_1\)</span> rappresenta il primo campione.</li>
</ul></li>
<li><strong>Proposta di un nuovo campione <span class="math inline">\(\theta_p\)</span>.</strong>
<ul>
<li>Un nuovo valore <span class="math inline">\(\theta_p\)</span> viene generato da una distribuzione di proposta <span class="math inline">\(g(\theta_p \mid \theta_t)\)</span>, solitamente una distribuzione normale centrata sul campione corrente <span class="math inline">\(\theta_t\)</span> con una deviazione standard <span class="math inline">\(\tau\)</span> che controlla l’ampiezza dei passi.</li>
</ul></li>
<li><strong>Verifica dei vincoli del campione proposto.</strong>
<ul>
<li>Se il nuovo campione deve rispettare dei vincoli (ad esempio, essere compreso tra 0 e 1 per probabilità), campioni non validi vengono automaticamente rifiutati.</li>
</ul></li>
<li><strong>Calcolo del rapporto di accettazione <span class="math inline">\(\alpha\)</span>.</strong>
<ul>
<li>Si calcola <span class="math inline">\(\alpha = \frac{p(\theta_p \mid y)}{p(\theta_t \mid y)}\)</span>, che rappresenta il rapporto tra le densità a posteriori del nuovo campione <span class="math inline">\(\theta_p\)</span> e del campione corrente <span class="math inline">\(\theta_t\)</span>. Questo valore guida la decisione di accettazione.</li>
</ul></li>
<li><strong>Decisione di accettazione.</strong>
<ul>
<li>Se <span class="math inline">\(\alpha \geq 1\)</span>, il nuovo campione <span class="math inline">\(\theta_p\)</span> viene accettato incondizionatamente.</li>
<li>Se <span class="math inline">\(\alpha &lt; 1\)</span>, il campione <span class="math inline">\(\theta_p\)</span> viene accettato con probabilità <span class="math inline">\(\alpha\)</span>. In caso di rifiuto, si mantiene il campione corrente <span class="math inline">\(\theta_t\)</span> per la prossima iterazione.</li>
</ul></li>
<li><strong>Ripetizione del processo.</strong>
<ul>
<li>Si ripetono i passaggi dal 2 al 5 fino a ottenere il numero desiderato di campioni.</li>
</ul></li>
</ol>
</section>
<section id="dettagli-aggiuntivi" class="level3" data-number="58.6.7">
<h3 data-number="58.6.7" class="anchored" data-anchor-id="dettagli-aggiuntivi"><span class="header-section-number">58.6.7</span> Dettagli Aggiuntivi</h3>
<ul>
<li><p><strong>Distribuzione di proposta</strong>: La distribuzione di proposta <span class="math inline">\(g(\theta_p \mid \theta_t)\)</span> genera nuovi campioni attorno a <span class="math inline">\(\theta_t\)</span>. Tipicamente si usa una normale <span class="math inline">\(N(\theta_t, \tau)\)</span>, dove <span class="math inline">\(\tau\)</span> controlla quanto il nuovo campione si discosta da quello corrente. Scegliere un <span class="math inline">\(\tau\)</span> troppo piccolo può rendere l’esplorazione lenta, mentre un <span class="math inline">\(\tau\)</span> troppo grande può far rifiutare troppi campioni, riducendo l’efficienza.</p></li>
<li><p><strong>Rapporto di accettazione <span class="math inline">\(\alpha\)</span></strong>: Se il nuovo campione ha una densità a posteriori maggiore del campione corrente, viene sempre accettato. Se ha una densità inferiore, viene accettato con probabilità <span class="math inline">\(\alpha\)</span>, il che consente di esplorare anche regioni meno probabili della distribuzione.</p></li>
<li><p><strong>Accettazione probabilistica</strong>: Accettare campioni peggiori occasionalmente aiuta l’algoritmo a evitare di bloccarsi in minimi locali. Questo è uno dei punti di forza dell’algoritmo di Metropolis, che garantisce una buona esplorazione dello spazio dei parametri.</p></li>
</ul>
</section>
</section>
<section id="esempio-di-implementazione" class="level2" data-number="58.7">
<h2 data-number="58.7" class="anchored" data-anchor-id="esempio-di-implementazione"><span class="header-section-number">58.7</span> Esempio di Implementazione</h2>
<p>Supponiamo di voler stimare la probabilità <span class="math inline">\(\theta\)</span> che un artista della Generazione X sia esposto al MoMA. Disponiamo di 14 successi (presenze) osservati su un campione di 100 artisti. Adottiamo un modello binomiale con distribuzione a priori Beta(4, 6) per <span class="math inline">\(\theta\)</span>, integrando dati osservati e conoscenza a priori mediante l’algoritmo MCMC. Seguiremo l’impostazione metodologica proposta da <a href="https://elizaveta-semenova.com/">Elizaveta Semenova</a>, implementando l’algoritmo di Metropolis-Hastings in R. Cominciamo definendo alcune funzioni fondamentali.</p>
<section id="definizione-della-distribuzione-a-priori" class="level3" data-number="58.7.1">
<h3 data-number="58.7.1" class="anchored" data-anchor-id="definizione-della-distribuzione-a-priori"><span class="header-section-number">58.7.1</span> Definizione della Distribuzione a Priori</h3>
<p>La funzione <code>prior</code> calcola la densità della distribuzione Beta(4, 6) per un dato <span class="math inline">\(\theta\)</span>:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Distribuzione a priori Beta(4, 6)</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>prior <span class="ot">&lt;-</span> <span class="cf">function</span>(p) {</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">dbeta</span>(p, <span class="at">shape1 =</span> <span class="dv">4</span>, <span class="at">shape2 =</span> <span class="dv">6</span>)</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Questa distribuzione esprime la nostra plausibilità iniziale sui valori di <span class="math inline">\(\theta\)</span> prima di osservare i dati.</p>
</section>
<section id="funzione-di-verosimiglianza" class="level3" data-number="58.7.2">
<h3 data-number="58.7.2" class="anchored" data-anchor-id="funzione-di-verosimiglianza"><span class="header-section-number">58.7.2</span> Funzione di Verosimiglianza</h3>
<p>La funzione <code>likelihood</code> modella la probabilità di osservare 14 successi su 100 prove:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Verosimiglianza binomiale (y = 14 successi su n = 100 prove)</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>likelihood <span class="ot">&lt;-</span> <span class="cf">function</span>(p) {</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>  y <span class="ot">&lt;-</span> <span class="dv">14</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>  n <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">dbinom</span>(y, <span class="at">size =</span> n, <span class="at">prob =</span> p)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="distribuzione-a-posteriori-non-normalizzata" class="level3" data-number="58.7.3">
<h3 data-number="58.7.3" class="anchored" data-anchor-id="distribuzione-a-posteriori-non-normalizzata"><span class="header-section-number">58.7.3</span> Distribuzione a Posteriori Non Normalizzata</h3>
<p>La posteriori si ottiene combinando priori e verosimiglianza:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Posteriori non normalizzata (prodotto tra verosimiglianza e priori)</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>posterior <span class="ot">&lt;-</span> <span class="cf">function</span>(p) {</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">likelihood</span>(p) <span class="sc">*</span> <span class="fu">prior</span>(p)</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="distribuzione-proposta" class="level3" data-number="58.7.4">
<h3 data-number="58.7.4" class="anchored" data-anchor-id="distribuzione-proposta"><span class="header-section-number">58.7.4</span> Distribuzione Proposta</h3>
<p>La distribuzione proposta sarà una distribuzione normale centrata sullo stato corrente con una deviazione standard specificata:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Generazione proposta (normale con media sullo stato corrente)</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>proposal_distribution <span class="ot">&lt;-</span> <span class="cf">function</span>(current_state, proposal_sigma) {</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rnorm</span>(<span class="dv">1</span>, <span class="at">mean =</span> current_state, <span class="at">sd =</span> proposal_sigma)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="implementazione-dellalgoritmo-metropolis-hastings" class="level3" data-number="58.7.5">
<h3 data-number="58.7.5" class="anchored" data-anchor-id="implementazione-dellalgoritmo-metropolis-hastings"><span class="header-section-number">58.7.5</span> Implementazione dell’Algoritmo Metropolis-Hastings</h3>
<p>Procediamo ora con l’implementazione dell’algoritmo di Metropolis-Hastings, considerando i dati relativi agli artisti della Generazione X presenti al MoMA. La distribuzione a priori per <span class="math inline">\(\theta\)</span> è modellata come una Beta(4, 6).</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Algoritmo Metropolis-Hastings</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>metropolis_hastings <span class="ot">&lt;-</span> <span class="cf">function</span>(n_samples, start, proposal_sigma) {</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>  samples <span class="ot">&lt;-</span> <span class="fu">numeric</span>(n_samples)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>  current <span class="ot">&lt;-</span> start  <span class="co"># Stato iniziale</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="fu">seq_len</span>(n_samples)) {</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>    proposal <span class="ot">&lt;-</span> <span class="fu">proposal_distribution</span>(current, proposal_sigma)</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Verifica validità e calcolo rapporto di accettazione</span></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (proposal <span class="sc">&gt;=</span> <span class="dv">0</span> <span class="sc">&amp;&amp;</span> proposal <span class="sc">&lt;=</span> <span class="dv">1</span>) {</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>      acceptance_ratio <span class="ot">&lt;-</span> <span class="fu">min</span>(<span class="dv">1</span>, <span class="fu">posterior</span>(proposal) <span class="sc">/</span> <span class="fu">posterior</span>(current))</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>      <span class="co"># Accetta/rifiuta con probabilità acceptance_ratio</span></span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> (<span class="fu">runif</span>(<span class="dv">1</span>) <span class="sc">&lt;</span> acceptance_ratio) {</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>        current <span class="ot">&lt;-</span> proposal</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>      }</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>    samples[i] <span class="ot">&lt;-</span> current  <span class="co"># Aggiorna la catena</span></span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(samples)</span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="callout callout-style-simple callout-tip callout-titled" title="Interpretazione intuitiva">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Interpretazione intuitiva
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Immaginate di esplorare un paesaggio montuoso (la posteriori) avvolto dalla nebbia, dove le alture rappresentano regioni ad alta densità di probabilità. L’algoritmo replica il comportamento di un escursionista che:</p>
<ol type="1">
<li><strong>Valuta la posizione corrente</strong> (<code>current</code>) tramite l’altezza locale (<code>posterior(current)</code>).</li>
<li><strong>Propone un passo casuale</strong> in una direzione vicina (<code>proposal</code>), determinata da una distribuzione normale.</li>
<li><strong>Decide il movimento</strong> confrontando le altezze relative:
<ul>
<li>Se il nuovo punto è più alto (<span class="math inline">\(R \geq 1\)</span>), lo accetta immediatamente.</li>
<li>Se è più basso (<span class="math inline">\(R &lt; 1\)</span>), lo accetta con probabilità <span class="math inline">\(R\)</span>, simulando un’<em>accettazione stocastica</em> per evitare massimi locali.</li>
</ul></li>
<li><strong>Registra ogni posizione</strong> visitata, costruendo gradualmente una mappa proporzionale alla vera distribuzione.</li>
</ol>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-tip callout-titled" title="Dettagli dell'implementazione (1)">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Dettagli dell’implementazione (1)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Nel codice la “regola &gt; 1 → accetta” è incorporata in queste <strong>due istruzioni consecutive</strong>:</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>acceptance_ratio <span class="ot">&lt;-</span> <span class="fu">min</span>(<span class="dv">1</span>, <span class="fu">posterior</span>(proposal) <span class="sc">/</span> <span class="fu">posterior</span>(current))</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>...</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> (<span class="fu">runif</span>(<span class="dv">1</span>) <span class="sc">&lt;</span> acceptance_ratio) {</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>    current <span class="ot">&lt;-</span> proposal</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ol type="1">
<li><strong>Clipping a 1 con <code>min(1, …)</code></strong>
<ul>
<li>Se il rapporto $ $ è maggiore di 1 (cioè il nuovo punto ha densità a‐posteriori più alta), <code>min()</code> lo tronca a 1.<br>
</li>
<li>Quindi <code>acceptance_ratio</code> vale esattamente 1 in tutti i casi in cui il “vero” rapporto sarebbe &gt; 1.</li>
</ul></li>
<li><strong>Accettazione certa con il confronto <code>runif(1) &lt; 1</code></strong>
<ul>
<li><code>runif(1)</code> genera un numero uniforme in <span class="math inline">\([0,1)\)</span>; qualunque valore estratto sarà sempre &lt; 1.<br>
</li>
<li>Di conseguenza, quando <code>acceptance_ratio</code> è 1 l’<code>if</code> è sempre vero e il punto proposto viene accettato con probabilità 1, esattamente come prescrive l’algoritmo di Metropolis (o di Metropolis-Hastings nel caso simmetrico).</li>
</ul></li>
</ol>
<p>In sintesi, la riga con <code>min(1, …)</code> <strong>traduce</strong> la regola teorica “accetta se il rapporto è &gt; 1” in una forma pratica che si integra con il test probabilistico successivo.</p>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-tip callout-titled" title="Dettagli dell'implementazione (2)">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Dettagli dell’implementazione (2)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>Proprietà della proposta simmetrica</strong>: L’algoritmo di Metropolis (quello base come questo) funziona bene se la maniera in cui proponi di “spostarti” da un punto A a un punto B è esattamente la stessa della maniera in cui proporresti di spostarti da B ad A. Pensa a una proposta “neutra” rispetto alla direzione. Questa “simmetria” nella proposta è utile perché ci permette di decidere se accettare un passo basandoci esclusivamente sul confronto della ‘probabilità’ (la densità) dei due punti (proposto e attuale) sotto la distribuzione che vogliamo esplorare. In pratica, non dobbiamo preoccuparci di ‘correggere’ il rapporto di accettazione per tenere conto di proposte che potrebbero essere più facili in una direzione che nell’altra. Questa semplicità aiuta l’algoritmo a trovare il giusto bilanciamento negli spostamenti, permettendogli di campionare correttamente dalla distribuzione desiderata nel lungo periodo.</p>
</div>
</div>
</div>
</section>
<section id="esecuzione-dellalgoritmo" class="level3" data-number="58.7.6">
<h3 data-number="58.7.6" class="anchored" data-anchor-id="esecuzione-dellalgoritmo"><span class="header-section-number">58.7.6</span> Esecuzione dell’Algoritmo</h3>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Parametri dell'algoritmo</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>n_samples <span class="ot">&lt;-</span> <span class="dv">10000</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>start <span class="ot">&lt;-</span> <span class="fl">0.5</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>proposal_sigma <span class="ot">&lt;-</span> <span class="fl">0.1</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Esecuzione del campionamento</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)  <span class="co"># Per riproducibilità</span></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>samples <span class="ot">&lt;-</span> <span class="fu">metropolis_hastings</span>(n_samples, start, proposal_sigma)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="analisi-dei-risultati" class="level3" data-number="58.7.7">
<h3 data-number="58.7.7" class="anchored" data-anchor-id="analisi-dei-risultati"><span class="header-section-number">58.7.7</span> Analisi dei Risultati</h3>
<p>Scartiamo i primi 5000 campioni per considerare solo quelli generati dopo il burn-in:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>burnin <span class="ot">&lt;-</span> <span class="fu">floor</span>(n_samples <span class="sc">*</span> <span class="fl">0.5</span>)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>post_burnin_samples <span class="ot">&lt;-</span> samples[<span class="sc">-</span><span class="fu">seq_len</span>(burnin)]</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Calcoliamo la media e la deviazione standard dei campioni:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Media a posteriori</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(post_burnin_samples)</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.1631</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Deviazione standard a posteriori</span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a><span class="fu">sd</span>(post_burnin_samples)</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.03535</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Visualizziamo l’evoluzione della catena per i primi 200 campioni e per quelli post-burn-in:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">Iterazione =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">200</span>,</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">Theta =</span> samples[<span class="dv">1</span><span class="sc">:</span><span class="dv">200</span>]</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>) <span class="sc">|&gt;</span> </span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> Iterazione, <span class="at">y =</span> Theta)) <span class="sc">+</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_line</span>() <span class="sc">+</span> <span class="co"># Specifica che vuoi un grafico a linea</span></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ggtitle</span>(<span class="st">"Trace Plot (Primi 200 Campioni)"</span>) <span class="sc">+</span> <span class="co"># Aggiunge il titolo principale</span></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">xlab</span>(<span class="st">"Iterazioni"</span>) <span class="sc">+</span> <span class="co"># Etichetta l'asse X</span></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ylab</span>(<span class="fu">expression</span>(theta)) <span class="co"># Etichetta l'asse Y usando l'espressione per theta</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="01_metropolis_files/figure-html/unnamed-chunk-18-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">Iterazione =</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(post_burnin_samples), </span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">Theta =</span> post_burnin_samples</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>) <span class="sc">|&gt;</span> </span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> Iterazione, <span class="at">y =</span> Theta)) <span class="sc">+</span></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_line</span>() <span class="sc">+</span> <span class="co"># Specifica un grafico a linea</span></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ggtitle</span>(<span class="st">"Trace Plot (Post Burn-in)"</span>) <span class="sc">+</span> <span class="co"># Aggiunge il titolo</span></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">xlab</span>(<span class="st">"Iterazioni"</span>) <span class="sc">+</span> <span class="co"># Indice all'interno della serie post-burn-in</span></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ylab</span>(<span class="fu">expression</span>(theta)) <span class="co"># Etichetta l'asse Y</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="01_metropolis_files/figure-html/unnamed-chunk-19-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<p>Sovrapponiamo la distribuzione analitica <span class="math inline">\(\text{Beta}(18, 92)\)</span> all’istogramma dei campioni post-burn-in:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(<span class="at">Theta =</span> post_burnin_samples) <span class="sc">|&gt;</span> </span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> Theta)) <span class="sc">+</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">y =</span> <span class="fu">after_stat</span>(density), <span class="at">fill =</span> <span class="st">"Istogramma MCMC"</span>),</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>                 <span class="at">bins =</span> <span class="dv">30</span>, </span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>                 <span class="at">color =</span> <span class="st">"black"</span>, </span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>                 <span class="at">alpha =</span> <span class="fl">0.7</span>) <span class="sc">+</span> </span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_function</span>(<span class="fu">aes</span>(<span class="at">color =</span> <span class="st">"Beta(18, 92)"</span>),</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>                <span class="at">fun =</span> dbeta, <span class="co"># Specifica la funzione da disegnare (densità Beta)</span></span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>                <span class="at">args =</span> <span class="fu">list</span>(<span class="at">shape1 =</span> <span class="dv">18</span>, <span class="at">shape2 =</span> <span class="dv">92</span>), </span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>                <span class="at">linewidth =</span> <span class="fl">1.2</span>) <span class="sc">+</span> </span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Istogramma e Distribuzione Posteriori"</span>,</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="fu">expression</span>(theta),</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"Densità"</span>,</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>       <span class="at">fill =</span> <span class="st">"Distribuzione"</span>, </span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a>       <span class="at">color =</span> <span class="st">"Distribuzione"</span>) <span class="sc">+</span></span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"Istogramma MCMC"</span> <span class="ot">=</span> okabe_ito_palette[<span class="dv">1</span>])) <span class="sc">+</span></span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"Beta(18, 92)"</span> <span class="ot">=</span> okabe_ito_palette[<span class="dv">2</span>]))</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="01_metropolis_files/figure-html/unnamed-chunk-20-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<p>Calcoliamo l’intervallo di credibilità al 94%:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="fu">quantile</span>(post_burnin_samples, <span class="at">probs =</span> <span class="fu">c</span>(<span class="fl">0.03</span>, <span class="fl">0.97</span>))</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     3%    97% </span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 0.1020 0.2347</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>I valori ottenuti con l’algoritmo di Metropolis (usando solo un piccolo numero di iterazioni) sono quasi identici ai valori esatti:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qbeta</span>(<span class="fu">c</span>(<span class="fl">0.03</span>, <span class="fl">0.97</span>), <span class="dv">18</span>, <span class="dv">92</span>)</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.1030 0.2346</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Questa implementazione in R dimostra come utilizzare l’algoritmo di Metropolis per stimare una distribuzione a posteriori e analizzare i risultati in modo dettagliato e riproducibile.</p>
</section>
</section>
<section id="catene-di-markov-e-convergenza" class="level2" data-number="58.8">
<h2 data-number="58.8" class="anchored" data-anchor-id="catene-di-markov-e-convergenza"><span class="header-section-number">58.8</span> Catene di Markov e Convergenza</h2>
<p>Nell’ambito delle simulazioni Monte Carlo, una <em>catena</em> rappresenta una sequenza di valori campionati dall’algoritmo durante le sue iterazioni. Ogni valore nella catena corrisponde a un possibile stato del sistema che stiamo modellando. In altre parole, una catena traccia il percorso che l’algoritmo segue nello spazio dei parametri, esplorando le diverse configurazioni possibili.</p>
<p>Per verificare se l’algoritmo ha raggiunto la convergenza e se i campioni generati rappresentano effettivamente la distribuzione di interesse, è utile eseguire <em>multiple catene</em>. Ogni catena parte da un punto iniziale diverso nello spazio dei parametri.</p>
<p><strong>I vantaggi delle multiple catene:</strong></p>
<ul>
<li><strong>Diagnostica della convergenza:</strong> Confrontando le diverse catene, possiamo valutare se si stabilizzano verso la stessa distribuzione. Se le catene si mescolano bene, ovvero si intersecano frequentemente nel grafico dei valori campionati (trace plot), è un forte indicatore di convergenza.</li>
<li><strong>Robustezza:</strong> L’utilizzo di multiple catene rende l’analisi meno sensibile alla scelta del punto di partenza. Se una singola catena potesse rimanere “intrappolata” in una regione dello spazio dei parametri, multiple catene aumentano la probabilità di esplorare lo spazio in modo più completo.</li>
</ul>
</section>
<section id="diagnostiche-della-soluzione-mcmc" class="level2" data-number="58.9">
<h2 data-number="58.9" class="anchored" data-anchor-id="diagnostiche-della-soluzione-mcmc"><span class="header-section-number">58.9</span> Diagnostiche della soluzione MCMC</h2>
<section id="stazionarietà-e-convergenza" class="level3" data-number="58.9.1">
<h3 data-number="58.9.1" class="anchored" data-anchor-id="stazionarietà-e-convergenza"><span class="header-section-number">58.9.1</span> Stazionarietà e Convergenza</h3>
<p>Un aspetto cruciale nell’analisi delle catene di Markov MCMC è la <strong>convergenza</strong> alla <strong>distribuzione stazionaria</strong>. Intuitivamente, la catena converge quando i campioni generati rappresentano fedelmente la distribuzione di interesse, indipendentemente dal punto di partenza. Questo fenomeno è spesso indicato come “mixing”.</p>
<section id="valutazione-visuale-trace-plots-e-grafici-di-densità" class="level4" data-number="58.9.1.1">
<h4 data-number="58.9.1.1" class="anchored" data-anchor-id="valutazione-visuale-trace-plots-e-grafici-di-densità"><span class="header-section-number">58.9.1.1</span> Valutazione Visuale: Trace Plots e Grafici di Densità</h4>
<ul>
<li><em>Trace Plots:</em> Questi grafici visualizzano l’evoluzione dei parametri nel tempo. Una catena convergente mostra tracce stabili e senza trend evidenti. Tracce irregolari o con andamenti sistematici suggeriscono problemi di convergenza.</li>
<li><em>Grafici di Densità:</em> Confrontando i grafici di densità dei campioni con la distribuzione teorica, è possibile valutare visivamente se la catena sta esplorando adeguatamente lo spazio dei parametri. Una buona convergenza si manifesta con una sovrapposizione tra i due grafici.</li>
</ul>
<p><strong>Segni di Convergenza:</strong></p>
<ul>
<li><em>Stabilità:</em> I valori campionati oscillano attorno a un valore medio costante, senza trend marcati.</li>
<li><em>Omogeneità:</em> La variabilità dei campioni rimane relativamente uniforme nel tempo.</li>
<li><em>Assenza di Periodicità:</em> Non si osservano pattern ciclici o ripetitivi.</li>
</ul>
<p>In sintesi, i trace plots e i grafici di densità offrono strumenti visivi rapidi per valutare la convergenza di una catena di Markov MCMC. Una convergenza soddisfacente è fondamentale per garantire la validità delle inferenze statistiche basate sui campioni generati.</p>
</section>
</section>
<section id="autocorrelazione-nelle-catene-di-markov-mcmc" class="level3" data-number="58.9.2">
<h3 data-number="58.9.2" class="anchored" data-anchor-id="autocorrelazione-nelle-catene-di-markov-mcmc"><span class="header-section-number">58.9.2</span> Autocorrelazione nelle catene di Markov MCMC</h3>
<p>A differenza dei generatori di numeri casuali indipendenti, gli algoritmi MCMC producono una sequenza di campioni <em>correlati</em>. Ogni valore campionato dipende da quello precedente, formando una <em>catena di Markov</em>. Questa interdipendenza è un aspetto fondamentale dell’MCMC.</p>
<p>L’<em>autocorrelazione</em> quantifica il grado di dipendenza tra valori distanti di una certa quantità (detta <em>lag</em>) nella catena. Un’alta autocorrelazione a lag bassi indica una forte dipendenza tra campioni successivi. Al contrario, una rapida diminuzione dell’autocorrelazione al crescere del lag suggerisce che la catena “miscela” bene, ovvero esplora lo spazio dei parametri in modo efficiente.</p>
<ul>
<li><em>Lag 1:</em> Misura la correlazione tra valori consecutivi nella catena.</li>
<li><em>Lag 2:</em> Misura la correlazione tra valori separati da un passo intermedio.</li>
<li><em>Lag k:</em> Generalizza il concetto ai valori separati da k passi.</li>
</ul>
<p>Un <em>correlogramma</em> è un grafico che mostra l’autocorrelazione in funzione del lag. Un decadimento rapido dell’autocorrelazione verso zero indica una buona convergenza della catena.</p>
<p>L’autocorrelazione di ordine <span class="math inline">\(k\)</span> è data da <span class="math inline">\(\rho_k\)</span> e può essere stimata come:</p>
<p><span id="eq-autocor"><span class="math display">\[
\begin{align}
\rho_k &amp;= \frac{Cov(\theta_m, \theta_{m+k})}{Var(\theta_m)}\notag\\
&amp;= \frac{\sum_{m=1}^{n-k}(\theta_m - \bar{\theta})(\theta_{m-k} - \bar{\theta})}{\sum_{m=1}^{n-k}(\theta_m - \bar{\theta})^2} \qquad\text{con }\quad \bar{\theta} = \frac{1}{n}\sum_{m=1}^{n}\theta_m.
\end{align}
\tag{58.1}\]</span></span></p>
</section>
<section id="esempio-di-simulazione-di-dati-autocorrelati" class="level3" data-number="58.9.3">
<h3 data-number="58.9.3" class="anchored" data-anchor-id="esempio-di-simulazione-di-dati-autocorrelati"><span class="header-section-number">58.9.3</span> Esempio di Simulazione di Dati Autocorrelati</h3>
<p>Per fare un esempio pratico, creiamo un vettore di dati autocorrelati:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Creiamo un vettore di dati</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">22</span>, <span class="dv">24</span>, <span class="dv">25</span>, <span class="dv">25</span>, <span class="dv">28</span>, <span class="dv">29</span>, <span class="dv">34</span>, <span class="dv">37</span>, <span class="dv">40</span>, <span class="dv">44</span>, <span class="dv">51</span>, <span class="dv">48</span>, <span class="dv">47</span>, <span class="dv">50</span>, <span class="dv">51</span>)</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>x</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [1] 22 24 25 25 28 29 34 37 40 44 51 48 47 50 51</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="calcolo-dellautocorrelazione" class="level4" data-number="58.9.3.1">
<h4 data-number="58.9.3.1" class="anchored" data-anchor-id="calcolo-dellautocorrelazione"><span class="header-section-number">58.9.3.1</span> Calcolo dell’Autocorrelazione</h4>
<p>L’autocorrelazione di ordine 1 è la correlazione tra ciascun elemento e il successivo nella sequenza. In R possiamo utilizzare la funzione <code>acf()</code> per calcolare l’autocorrelazione.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calcolo dell'autocorrelazione</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>acf_values <span class="ot">&lt;-</span> <span class="fu">acf</span>(x, <span class="at">plot =</span> <span class="cn">FALSE</span>)</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>acf_values</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Autocorrelations of series 'x', by lag</span></span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;      0      1      2      3      4      5      6      7      8      9 </span></span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  1.000  0.832  0.656  0.491  0.279  0.031 -0.165 -0.304 -0.401 -0.458 </span></span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     10     11 </span></span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; -0.450 -0.369</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Nell’esempio, il vettore <code>x</code> rappresenta una serie temporale di 15 elementi. Il calcolo dell’autocorrelazione restituisce i seguenti valori per i primi ritardi (<em>lag</em>):</p>
<ul>
<li><strong>0.8317</strong>: autocorrelazione di ordine 1 (lag = 1),</li>
<li><strong>0.6563</strong>: autocorrelazione di ordine 2 (lag = 2),</li>
<li><strong>0.4910</strong>: autocorrelazione di ordine 3 (lag = 3),<br>
ecc.</li>
</ul>
</section>
<section id="specifica-del-numero-di-ritardi-lag" class="level4" data-number="58.9.3.2">
<h4 data-number="58.9.3.2" class="anchored" data-anchor-id="specifica-del-numero-di-ritardi-lag"><span class="header-section-number">58.9.3.2</span> Specifica del Numero di Ritardi (<em>Lag</em>)</h4>
<p>Possiamo limitare il numero di ritardi calcolati utilizzando l’argomento <code>lag.max</code> nella funzione <code>acf()</code>:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calcolo dell'autocorrelazione per i primi 4 lag</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="fu">acf</span>(x, <span class="at">lag.max =</span> <span class="dv">4</span>, <span class="at">plot =</span> <span class="cn">FALSE</span>)</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Autocorrelations of series 'x', by lag</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     0     1     2     3     4 </span></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1.000 0.832 0.656 0.491 0.279</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="grafico-della-funzione-di-autocorrelazione-correlogramma" class="level4" data-number="58.9.3.3">
<h4 data-number="58.9.3.3" class="anchored" data-anchor-id="grafico-della-funzione-di-autocorrelazione-correlogramma"><span class="header-section-number">58.9.3.3</span> Grafico della Funzione di Autocorrelazione (Correlogramma)</h4>
<p>In R possiamo creare un correlogramma con la funzione <code>acf()</code>:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Correlogramma per la serie temporale</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="fu">acf</span>(x, <span class="at">main =</span> <span class="st">"Correlogramma della Serie Temporale"</span>, <span class="at">lag.max =</span> <span class="dv">9</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="01_metropolis_files/figure-html/unnamed-chunk-26-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="analisi-della-catena-di-markov" class="level3" data-number="58.9.4">
<h3 data-number="58.9.4" class="anchored" data-anchor-id="analisi-della-catena-di-markov"><span class="header-section-number">58.9.4</span> Analisi della Catena di Markov</h3>
<p>Applichiamo lo stesso approccio alla catena di Markov ottenuta precedentemente, considerando i campioni post burn-in:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Definizione dei campioni post burn-in</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>post_burnin_samples <span class="ot">&lt;-</span> samples[<span class="sc">-</span><span class="fu">seq_len</span>(burnin)]</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Correlogramma per i campioni post burn-in</span></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a><span class="fu">acf</span>(</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>  post_burnin_samples, </span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">main =</span> <span class="st">"Correlogramma della Catena Post Burn-in"</span>, </span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">lag.max =</span> <span class="dv">9</span></span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="01_metropolis_files/figure-html/unnamed-chunk-27-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<p>In situazioni ideali, l’autocorrelazione diminuisce rapidamente, diventando insignificante per piccoli lag. Questo comportamento è un’indicazione del “mixing” efficace della catena, ossia della sua convergenza alla distribuzione stazionaria.</p>
</section>
<section id="sottocampionamento-thinning" class="level3" data-number="58.9.5">
<h3 data-number="58.9.5" class="anchored" data-anchor-id="sottocampionamento-thinning"><span class="header-section-number">58.9.5</span> Sottocampionamento (<em>Thinning</em>)</h3>
<p>Per ridurre l’autocorrelazione, possiamo applicare una strategia di sottocampionamento (<em>thinning</em>), memorizzando solo ogni <span class="math inline">\(m\)</span>-esimo campione.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Sottocampionamento con un fattore di 5</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>thin <span class="ot">&lt;-</span> <span class="dv">5</span></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>sampsthin <span class="ot">&lt;-</span> </span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>  post_burnin_samples[<span class="fu">seq</span>(<span class="dv">1</span>, <span class="fu">length</span>(post_burnin_samples), <span class="at">by =</span> thin)]</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Correlogramma per i campioni sottocampionati</span></span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a><span class="fu">acf</span>(</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>  sampsthin, </span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">main =</span> <span class="st">"Correlogramma con Sottocampionamento (Thinning)"</span>, </span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">lag.max =</span> <span class="dv">9</span></span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="01_metropolis_files/figure-html/unnamed-chunk-28-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<p>In conclusione, il correlogramma con <em>thinning</em> mostra che l’autocorrelazione diminuisce più rapidamente rispetto ai campioni originali, suggerendo che la strategia di sottocampionamento è efficace nel migliorare l’indipendenza tra i campioni successivi. Questo migliora la qualità delle inferenze basate sulla catena di Markov.</p>
<section id="tasso-di-accettazione" class="level4" data-number="58.9.5.1">
<h4 data-number="58.9.5.1" class="anchored" data-anchor-id="tasso-di-accettazione"><span class="header-section-number">58.9.5.1</span> Tasso di accettazione</h4>
<p>Quando si utilizza l’algoritmo Metropolis, è importante monitorare il tasso di accettazione e assicurarsi che sia nell’intervallo ottimale. Se si accetta quasi sempre il candidato proposto, probabilmente significa che, in ogni iterazione, la catena salta solo di un piccolo passo (in modo che il rapporto di accettazione sia vicino a 1 ogni volta). Di conseguenza, la catena impiegherà molte iterazioni per raggiungere altre regioni della distribuzione stazionaria e i campioni consecutivi saranno molto fortemente correlati. D’altra parte, se il tasso di accettazione è molto basso, la catena rimarrà bloccata nella stessa posizione per molte iterazioni prima di spostarsi verso uno stato diverso. Per l’algoritmo Metropolis base con un singolo parametro con una distribuzione proposta Gaussiana normale, un tasso di accettazione ottimale è compreso tra il 40% e il 50%.</p>
</section>
</section>
<section id="test-statistici-per-la-convergenza" class="level3" data-number="58.9.6">
<h3 data-number="58.9.6" class="anchored" data-anchor-id="test-statistici-per-la-convergenza"><span class="header-section-number">58.9.6</span> Test Statistici per la Convergenza</h3>
<p>Oltre agli approcci grafici, esistono test statistici specifici che possono aiutare a determinare se la catena ha raggiunto uno stato stazionario.</p>
<section id="test-di-geweke" class="level4" data-number="58.9.6.1">
<h4 data-number="58.9.6.1" class="anchored" data-anchor-id="test-di-geweke"><span class="header-section-number">58.9.6.1</span> Test di Geweke</h4>
<p>Il test di Geweke è una procedura che confronta le medie di due segmenti della catena di campionamento, tipicamente il primo 10% e l’ultimo 50% dei campioni, dopo aver escluso un iniziale periodo di “burn-in” (una fase iniziale durante la quale la catena potrebbe non essere ancora convergente). La premessa di base è che, se la catena è in uno stato stazionario, le medie di questi due segmenti dovrebbero essere sostanzialmente uguali. Differenze importanti tra queste medie possono indicare che la catena non ha ancora raggiunto la convergenza.</p>
</section>
<section id="geweke-z-score" class="level4" data-number="58.9.6.2">
<h4 data-number="58.9.6.2" class="anchored" data-anchor-id="geweke-z-score"><span class="header-section-number">58.9.6.2</span> Geweke Z-score</h4>
<p>Una variante del test di Geweke è lo z-score di Geweke, che offre un modo quantitativo per valutare le differenze tra i segmenti della catena. Questo test calcola uno z-score che confronta le medie dei due segmenti tenendo conto della varianza. Un valore di z-score:</p>
<ul>
<li><strong>Al di sotto di 2 (in valore assoluto)</strong> suggerisce che non ci sono differenze degne di nota tra i segmenti, indicando che la catena potrebbe essere in stato stazionario.</li>
<li><strong>Superiore a 2 (in valore assoluto)</strong> indica che esiste una differenza degna di nota tra i segmenti, suggerendo che la catena non ha raggiunto la convergenza e potrebbe essere necessario un periodo di burn-in più esteso.</li>
</ul>
<p>Entrambi i metodi forniscono strumenti utili per valutare la convergenza delle catene MCMC. È importante notare che nessun test può garantire con certezza la convergenza, ma l’utilizzo congiunto di approcci grafici e test statistici può offrire una buona indicazione dello stato della catena.</p>
</section>
</section>
<section id="dimensione-del-campione-effettiva-ess" class="level3" data-number="58.9.7">
<h3 data-number="58.9.7" class="anchored" data-anchor-id="dimensione-del-campione-effettiva-ess"><span class="header-section-number">58.9.7</span> Dimensione del campione effettiva (ESS)</h3>
<p>La correlazione tra campioni consecutivi in una catena MCMC riduce l’informazione effettiva contenuta in ogni iterazione. La <strong>dimensione del campione effettiva (ESS)</strong> quantifica questa perdita di informazione dovuta alla dipendenza tra i campioni, stimando il numero equivalente di campioni indipendenti. Un valore basso di ESS indica una forte correlazione tra i campioni e una convergenza più lenta della catena.</p>
<p>L’ESS descrive l’efficacia del campionamento dipendente in termini di campioni indipendenti estratti dalla stessa distribuzione. Rappresenta un indicatore dell’efficienza del campionamento e dell’autocorrelazione della catena.</p>
<p>La formula per stimare la dimensione del campione effettiva (ESS) di una catena di Markov è:</p>
<p><span class="math display">\[
\text{ESS} = \frac{N}{1 + 2 \sum_{t=1}^{T} \rho_t},
\]</span></p>
<p>dove:</p>
<ul>
<li><span class="math inline">\(N\)</span> è il numero totale di campioni nella catena,</li>
<li><span class="math inline">\(T\)</span> è il lag, ovvero il numero massimo di termini di autocorrelazione considerati,</li>
<li><span class="math inline">\(\rho_t\)</span> è l’autocorrelazione al lag <span class="math inline">\(t\)</span>, ossia la correlazione tra due campioni consecutivi separati da <span class="math inline">\(t\)</span> iterazioni.</li>
</ul>
<p>In pratica, <span class="math inline">\(T\)</span> viene scelto in modo tale che <span class="math inline">\(\rho_T\)</span> sia sufficientemente piccolo, indicando che l’autocorrelazione è quasi svanita. La somma <span class="math inline">\(\sum_{t=1}^T \rho_t\)</span> viene quindi troncata approssimativamente a <span class="math inline">\(T\)</span>, poiché i contributi delle autocorrelazioni successive diventano trascurabili.</p>
</section>
<section id="calcolo-della-statistica-di-gelman-rubin-hatr" class="level3" data-number="58.9.8">
<h3 data-number="58.9.8" class="anchored" data-anchor-id="calcolo-della-statistica-di-gelman-rubin-hatr"><span class="header-section-number">58.9.8</span> Calcolo della Statistica di Gelman-Rubin (<span class="math inline">\(\hat{R}\)</span>)</h3>
<p>Per calcolare la statistica di Gelman-Rubin (spesso indicata come <span class="math inline">\(\hat{R}\)</span>), è necessario eseguire più catene e confrontare la variabilità all’interno di ciascuna catena con la variabilità tra le catene. Ecco i passaggi per calcolare <span class="math inline">\(\hat{R}\)</span>:</p>
<ol type="1">
<li>Esegui <span class="math inline">\(m\)</span> catene di Markov di lunghezza <span class="math inline">\(n\)</span>, dove <span class="math inline">\(m\)</span> è solitamente maggiore di 1.</li>
<li>Per ciascun parametro scalare <span class="math inline">\(\theta\)</span>, calcola la varianza all’interno delle catene (<span class="math inline">\(W\)</span>) e la varianza tra le catene (<span class="math inline">\(B\)</span>).</li>
<li>Calcola la varianza combinata <span class="math inline">\(\hat{V}\)</span> come media ponderata delle varianze all’interno delle catene.</li>
<li>Calcola il fattore di riduzione della scala potenziale <span class="math inline">\(\hat{R}\)</span> come la radice quadrata del rapporto tra la varianza combinata <span class="math inline">\(\hat{V}\)</span> e la varianza all’interno delle catene <span class="math inline">\(W\)</span>:</li>
</ol>
<p><span class="math display">\[
\hat{R} = \sqrt{\frac{\hat{V}}{W}}.
\]</span></p>
<ol start="5" type="1">
<li>Se <span class="math inline">\(\hat{R}\)</span> è vicino a 1, ciò indica che le catene sono in convergenza.</li>
</ol>
<p>La statistica di Gelman-Rubin <span class="math inline">\(\hat{R}\)</span> è una misura di convergenza per le catene di Markov. Essa quantifica il grado di accordo tra più catene, fornendo uno strumento diagnostico per valutare la convergenza nelle simulazioni MCMC.</p>
</section>
</section>
<section id="vantaggi-del-campionamento-mcmc-rispetto-alle-soluzioni-analitiche" class="level2" data-number="58.10">
<h2 data-number="58.10" class="anchored" data-anchor-id="vantaggi-del-campionamento-mcmc-rispetto-alle-soluzioni-analitiche"><span class="header-section-number">58.10</span> Vantaggi del Campionamento MCMC rispetto alle Soluzioni Analitiche</h2>
<p>Il campionamento MCMC offre notevoli vantaggi pratici rispetto alle soluzioni analitiche nella statistica bayesiana, in particolare quando si tratta di manipolare distribuzioni a posteriori. Sebbene l’impossibilità di calcolare analiticamente la distribuzione a posteriori sia spesso la motivazione principale per l’uso di MCMC, i benefici di questo approccio si estendono ben oltre questa necessità <span class="citation" data-cites="buerkner2024brms">(<a href="#ref-buerkner2024brms" role="doc-biblioref">Bürkner, 2024</a>)</span>.</p>
<section id="facilità-di-manipolazione-e-flessibilità" class="level3" data-number="58.10.1">
<h3 data-number="58.10.1" class="anchored" data-anchor-id="facilità-di-manipolazione-e-flessibilità"><span class="header-section-number">58.10.1</span> Facilità di Manipolazione e Flessibilità</h3>
<p>Il vantaggio chiave del campionamento MCMC risiede nella semplicità con cui si possono manipolare i campioni ottenuti. Mentre le densità calcolate analiticamente possono richiedere trasformazioni matematiche complesse, i campioni MCMC possono essere facilmente trasformati con operazioni dirette.</p>
<p>In conclusione, il campionamento MCMC non è solo una necessità quando le soluzioni analitiche sono introvabili, ma offre vantaggi in termini di facilità di manipolazione, flessibilità computazionale e applicabilità pratica.</p>
</section>
</section>
<section id="caso-normale-normale-con-soluzione-analitica" class="level2" data-number="58.11">
<h2 data-number="58.11" class="anchored" data-anchor-id="caso-normale-normale-con-soluzione-analitica"><span class="header-section-number">58.11</span> Caso Normale-Normale con Soluzione Analitica</h2>
<p>Applichiamo ora l’algoritmo di Metropolis al caso Normale-Normale di cui conosciamo la soluzione analitica. In pratica, ci poniamo il problema di capire quale valore di <span class="math inline">\(\mu\)</span> (la media vera di una popolazione) sia più plausibile, dopo aver osservato alcuni dati. Abbiamo:</p>
<ul>
<li>un’idea iniziale (prior) che dice che <span class="math inline">\(\mu\)</span> dovrebbe stare attorno a 30, con una certa incertezza (deviazione standard 5),</li>
<li>e abbiamo i dati osservati (<span class="math inline">\(y\)</span>) che ci danno informazioni aggiuntive su dove si trova davvero <span class="math inline">\(\mu\)</span>.</li>
</ul>
<p>Ma non conosciamo esattamente la distribuzione a posteriori di <span class="math inline">\(\mu\)</span>.</p>
<p>Vogliamo costruire una “nuvola” di valori plausibili per <span class="math inline">\(\mu\)</span> basandoci su dati e prior. Il metodo che usiamo per risolvere questo problema è l’algoritmo di Metropolis.</p>
<p><strong>Step 1. Partiamo da un punto.</strong></p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>x_prev <span class="ot">&lt;-</span> xinit</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li><strong>xinit</strong> è il valore iniziale: il nostro “primo sospetto” su dove si trovi <span class="math inline">\(\mu\)</span>.</li>
<li>È come partire da un punto sulla mappa (“Penso che <span class="math inline">\(\mu\)</span> sia circa qui”).</li>
</ul>
<p><strong>Step 2. Proponiamo un nuovo punto vicino.</strong></p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>x_star <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">1</span>, <span class="at">mean =</span> x_prev, <span class="at">sd =</span> <span class="fl">0.5</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li>Immaginiamo di essere bendati e di provare a fare <strong>un piccolo passo a caso</strong> partendo da dove siamo ora.</li>
<li>Quel passo è generato con una distribuzione normale centrata su <strong>x_prev</strong> e con una deviazione standard piccola (<strong>0.5</strong>): <strong>piccoli passi casuali</strong> attorno al punto attuale.</li>
</ul>
<p><strong>Nota intuitiva:</strong><br>
Il valore 0.5 decide quanto “grandi” o “piccoli” sono i nostri passi. Più è grande, più possiamo saltare lontano; più è piccolo, più restiamo vicino.</p>
<p><strong>Step 3. Calcoliamo quanto è “buono” il nuovo punto.</strong></p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="fu">posterior</span>(x_star, data)</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="fu">posterior</span>(x_prev, data)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li>Ogni punto sulla mappa (<span class="math inline">\(\mu\)</span>) ha un certo <strong>valore di plausibilità</strong>: quanto è probabile dati i dati osservati e il prior.</li>
<li><strong>posterior(x_star, data)</strong> ci dice: “quanto è buono il nuovo punto?”</li>
<li><strong>posterior(x_prev, data)</strong> ci dice: “quanto era buono quello vecchio?”</li>
</ul>
<p><strong>Step 4. Decidiamo se accettare il nuovo punto.</strong></p>
<div class="sourceCode" id="cb34"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> (<span class="fu">runif</span>(<span class="dv">1</span>) <span class="sc">&lt;</span> <span class="fu">min</span>(<span class="dv">1</span>, <span class="fu">posterior</span>(x_star, data) <span class="sc">/</span> <span class="fu">posterior</span>(x_prev, data))) {</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>  x_prev <span class="ot">&lt;-</span> x_star</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Qui applichiamo il meccanismo di base dell’algoritmo di Metropolis per decidere sull’accettazione di un nuovo punto:</p>
<ul>
<li><strong>se il nuovo punto è migliore</strong> (cioè, la probabilità a posteriori è maggiore), allora lo <strong>accettiamo sicuramente</strong> (<span class="math inline">\(\alpha &gt; 1\)</span>, quindi <span class="math inline">\(\min(1, \alpha) = 1\)</span>);</li>
<li><strong>se il nuovo punto è peggiore</strong>, possiamo comunque <strong>accettarlo con una certa probabilità</strong>:
<ul>
<li>la probabilità di accettazione diminuisce all’aumentare di quanto il punto è “peggiore”;</li>
<li>ciò è essenziale per <strong>non rimanere bloccati</strong> nei massimi locali.</li>
</ul></li>
</ul>
<p><strong>In parole semplici:</strong></p>
<ul>
<li>se troviamo un posto migliore, ci andiamo;</li>
<li>se troviamo un posto peggiore, possiamo comunque andarci… ma tirando una monetina.</li>
</ul>
<p><strong>Step 5. Registriamo il punto attuale</strong></p>
<p>Dopo aver deciso se accettare o meno il nuovo valore proposto, salviamo sempre un punto nella catena.</p>
<p>Ma attenzione:</p>
<ul>
<li><strong>se la proposta è stata accettata</strong>, ci spostiamo al nuovo punto e lo registriamo;</li>
<li><strong>se la proposta è stata rifiutata</strong>, restiamo fermi e registriamo <strong>di nuovo</strong> la posizione attuale.</li>
</ul>
<div class="sourceCode" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> (<span class="fu">runif</span>(<span class="dv">1</span>) <span class="sc">&lt;</span> <span class="fu">min</span>(<span class="dv">1</span>, <span class="fu">posterior</span>(x_star, data) <span class="sc">/</span> <span class="fu">posterior</span>(x_prev, data))) {</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>  x_prev <span class="ot">&lt;-</span> x_star  <span class="co"># accettiamo: ci spostiamo</span></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>samples[i] <span class="ot">&lt;-</span> x_prev  <span class="co"># salviamo dove ci troviamo ORA</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>In entrambi i casi, <code>samples[i]</code> tiene traccia della posizione in cui ci troviamo dopo l’iterazione.</p>
<p><strong>Intuizione: l’escursionista bendato.</strong></p>
<p>Immaginiamo un’escursionista bendato che vuole esplorare un paesaggio fatto di colline di plausibilità (la distribuzione a posteriori):</p>
<ul>
<li>a ogni passo, <strong>prova a fare un salto</strong> in una nuova direzione (<code>x_star</code>);</li>
<li>se quel punto è più alto o non troppo peggiore, <strong>accetta</strong> di andarci e si sposta.</li>
<li>se il punto è troppo brutto, <strong>rimane fermo</strong> dov’è;</li>
<li><strong>in ogni caso, segna nel diario la sua posizione attuale.</strong></li>
</ul>
<p>Ecco perché, quando guardiamo la catena, possiamo trovare <strong>valori ripetuti</strong> consecutivi: l’escursionista non si è mosso.</p>
<p>Questa caratteristica – il fatto che i campioni non siano tutti diversi – <strong>non è un errore</strong>, ma una <strong>proprietà fondamentale</strong> dell’algoritmo Metropolis: i campioni sono <strong>dipendenti</strong> e possono <strong>ripetersi</strong>.</p>
<p><strong>Step 6. Ripetiamo tante volte.</strong></p>
<div class="sourceCode" id="cb36"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="fu">seq_len</span>(nsamp)) { ... }</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li>Più a lungo ripetiamo il processo (più iterazioni), più densa e accurata sarà la nostra approssimazione della distribuzione a posteriori di <span class="math inline">\(\mu\)</span>.</li>
<li>Dopo un po’, <strong>i valori salvati</strong> formeranno un disegno della distribuzione plausibile di <span class="math inline">\(\mu\)</span>.</li>
</ul>
<p><strong>🎯 Riassunto in 3 frasi:</strong></p>
<ul>
<li><ol type="1">
<li>Partiamo da un valore sospettato di <span class="math inline">\(\mu\)</span>.</li>
</ol></li>
<li><ol start="2" type="1">
<li>Facciamo piccoli passi casuali e decidiamo se accettarli in base a quanto sono “buoni” rispetto ai dati + prior.</li>
</ol></li>
<li><ol start="3" type="1">
<li>Dopo molti passi, la sequenza dei punti disegna la distribuzione a posteriori di <span class="math inline">\(\mu\)</span>.</li>
</ol></li>
</ul>
<p><strong>📈 Dopo il sampling:</strong></p>
<ul>
<li>possiamo <strong>calcolare la media</strong> dei campioni = stima puntuale di <span class="math inline">\(\mu\)</span>;</li>
<li>possiamo <strong>costruire un intervallo di credibilità</strong> = incertezza su <span class="math inline">\(\mu\)</span>;</li>
<li>possiamo <strong>disegnare un istogramma</strong> dei campioni = forma della distribuzione a posteriori.</li>
</ul>
<p>Anche se l’algoritmo di Metropolis può sembrare “rozzo” (tanti piccoli passi + accettare/rifiutare), funziona <strong>benissimo</strong> ed è uno dei motivi per cui oggi possiamo applicare la statistica bayesiana a modelli anche <strong>molto complessi</strong>.</p>
<p>Applichiamo dunque l’algoritmo di Metropolis all’esercizio in discussione. Iniziamo a definire le funzioni per il prior, la verosimiglianza e il posterior non normalizzato.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Prior: Normal(30, 5^2)</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>prior <span class="ot">&lt;-</span> <span class="cf">function</span>(mu) {</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">dnorm</span>(mu, <span class="at">mean =</span> <span class="dv">30</span>, <span class="at">sd =</span> <span class="dv">5</span>)</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Likelihood: Normal(mu, sigma^2) con sigma calcolata dai dati</span></span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>likelihood <span class="ot">&lt;-</span> <span class="cf">function</span>(mu, data) {</span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>  sigma <span class="ot">&lt;-</span> <span class="fu">sd</span>(data)  <span class="co"># Deviazione standard dei dati</span></span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">prod</span>(<span class="fu">dnorm</span>(data, <span class="at">mean =</span> mu, <span class="at">sd =</span> sigma))</span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Posterior non normalizzato</span></span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a>posterior <span class="ot">&lt;-</span> <span class="cf">function</span>(mu, data) {</span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">likelihood</span>(mu, data) <span class="sc">*</span> <span class="fu">prior</span>(mu)</span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Implementiamo l’algoritmo di Metropolis per il caso normale-normale:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Algoritmo di Metropolis</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>metropolis_for_normal <span class="ot">&lt;-</span> <span class="cf">function</span>(nsamp, xinit, data) {</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>  samples <span class="ot">&lt;-</span> <span class="fu">numeric</span>(nsamp)</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>  x_prev <span class="ot">&lt;-</span> xinit</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="fu">seq_len</span>(nsamp)) {</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>    x_star <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">1</span>, <span class="at">mean =</span> x_prev, <span class="at">sd =</span> <span class="fl">0.5</span>)  <span class="co"># Proposta</span></span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (<span class="fu">runif</span>(<span class="dv">1</span>) <span class="sc">&lt;</span> <span class="fu">min</span>(<span class="dv">1</span>, <span class="fu">posterior</span>(x_star, data) <span class="sc">/</span> <span class="fu">posterior</span>(x_prev, data))) {</span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a>      x_prev <span class="ot">&lt;-</span> x_star</span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a>    samples[i] <span class="ot">&lt;-</span> x_prev</span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb38-14"><a href="#cb38-14" aria-hidden="true" tabindex="-1"></a>  samples</span>
<span id="cb38-15"><a href="#cb38-15" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Utilizziamo un campione di 30 valori BDI-II forniti da <span class="citation" data-cites="zetsche_2019future">Zetsche et al. (<a href="#ref-zetsche_2019future" role="doc-biblioref">2019</a>)</span>:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Dati osservati</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">c</span>(</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>  <span class="dv">26</span>, <span class="dv">35</span>, <span class="dv">30</span>, <span class="dv">25</span>, <span class="dv">44</span>, <span class="dv">30</span>, <span class="dv">33</span>, <span class="dv">43</span>, <span class="dv">22</span>, <span class="dv">43</span>, <span class="dv">24</span>, <span class="dv">19</span>, <span class="dv">39</span>, <span class="dv">31</span>, <span class="dv">25</span>, </span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>  <span class="dv">28</span>, <span class="dv">35</span>, <span class="dv">30</span>, <span class="dv">26</span>, <span class="dv">31</span>, <span class="dv">41</span>, <span class="dv">36</span>, <span class="dv">26</span>, <span class="dv">35</span>, <span class="dv">33</span>, <span class="dv">28</span>, <span class="dv">27</span>, <span class="dv">34</span>, <span class="dv">27</span>, <span class="dv">22</span></span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Esecuzione dell’algoritmo:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>samples <span class="ot">&lt;-</span> <span class="fu">metropolis_for_normal</span>(<span class="dv">100000</span>, <span class="fu">mean</span>(y), y)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Nel caso normale-normale, il posterior può essere calcolato analiticamente come segue:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Parametri del prior</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>mu_prior <span class="ot">&lt;-</span> <span class="dv">30</span></span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>std_prior <span class="ot">&lt;-</span> <span class="dv">5</span></span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>var_prior <span class="ot">&lt;-</span> std_prior<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Calcolo dei parametri posterior</span></span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">length</span>(y)</span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>sum_y <span class="ot">&lt;-</span> <span class="fu">sum</span>(y)</span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>var_data <span class="ot">&lt;-</span> <span class="fu">var</span>(y)</span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a>mu_post <span class="ot">&lt;-</span> (mu_prior <span class="sc">/</span> var_prior <span class="sc">+</span> sum_y <span class="sc">/</span> var_data) <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">/</span> var_prior <span class="sc">+</span> n <span class="sc">/</span> var_data)</span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a>var_post <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">/</span> var_prior <span class="sc">+</span> n <span class="sc">/</span> var_data)</span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a>std_post <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(var_post)</span>
<span id="cb41-14"><a href="#cb41-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-15"><a href="#cb41-15" aria-hidden="true" tabindex="-1"></a>mu_post</span>
<span id="cb41-16"><a href="#cb41-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 30.88</span></span>
<span id="cb41-17"><a href="#cb41-17" aria-hidden="true" tabindex="-1"></a>std_post</span>
<span id="cb41-18"><a href="#cb41-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 1.173</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Visualizziamo i risultati con un istogramma dei campioni MCMC e la curva della distribuzione analitica:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Campioni post burn-in</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>burnin <span class="ot">&lt;-</span> <span class="fu">floor</span>(<span class="fu">length</span>(samples) <span class="sc">*</span> <span class="fl">0.5</span>)</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>post_samples <span class="ot">&lt;-</span> samples[<span class="sc">-</span><span class="fu">seq_len</span>(burnin)]</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Dati per la curva analitica</span></span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">seq</span>(mu_post <span class="sc">-</span> <span class="dv">4</span> <span class="sc">*</span> std_post, mu_post <span class="sc">+</span> <span class="dv">4</span> <span class="sc">*</span> std_post, <span class="at">length.out =</span> <span class="dv">1000</span>)</span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a>analytical_posterior <span class="ot">&lt;-</span> <span class="fu">dnorm</span>(x, <span class="at">mean =</span> mu_post, <span class="at">sd =</span> std_post)</span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Creazione del grafico</span></span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">x =</span> post_samples, <span class="at">y =</span> <span class="fu">after_stat</span>(density)), <span class="at">bins =</span> <span class="dv">30</span>, <span class="at">fill =</span> <span class="st">"blue"</span>, <span class="at">alpha =</span> <span class="fl">0.4</span>) <span class="sc">+</span></span>
<span id="cb42-12"><a href="#cb42-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> analytical_posterior), <span class="at">color =</span> <span class="st">"red"</span>, <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb42-13"><a href="#cb42-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Distribuzione Posterior: MCMC vs Analitico"</span>,</span>
<span id="cb42-14"><a href="#cb42-14" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="fu">expression</span>(mu), <span class="at">y =</span> <span class="st">"Densità"</span>) </span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="01_metropolis_files/figure-html/unnamed-chunk-34-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<p>Troviamo le proprietà del Posterior derivato con MCMC:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(samples)</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 30.91</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sd</span>(samples)</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 1.177</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In conclusione, questo esempio illustra l’applicazione dell’algoritmo di Metropolis per la stima di una distribuzione a posteriori nel caso Normale-Normale e dimostra come confrontare i risultati del campionamento con la soluzione analitica, confermando così la coerenza tra le due approcci.</p>
</section>
<section id="riflessioni-conclusive" class="level2" data-number="58.12">
<h2 data-number="58.12" class="anchored" data-anchor-id="riflessioni-conclusive"><span class="header-section-number">58.12</span> Riflessioni Conclusive</h2>
<p>In molti casi, la distribuzione a posteriori dei parametri di un modello statistico non ha una forma analitica risolvibile. Per affrontare questa limitazione, si utilizzano metodi Monte Carlo basati su catene di Markov (MCMC). Questi algoritmi permettono di campionare efficacemente dalla distribuzione a posteriori, anche per modelli complessi, generando una sequenza di valori che approssima la distribuzione desiderata. L’algoritmo di Metropolis-Hastings <span class="citation" data-cites="hastings_1970">(<a href="#ref-hastings_1970" role="doc-biblioref">Hastings, 1970</a>)</span>, un’estensione dell’algoritmo di Metropolis originale <span class="citation" data-cites="metropolist_etal_1953">(<a href="#ref-metropolist_etal_1953" role="doc-biblioref">Metropolis et al., 1953</a>)</span>, è uno dei metodi MCMC più ampiamente utilizzati.</p>
<p>In sintesi, l’algoritmo segue questi passaggi principali:</p>
<ul>
<li><strong>Generazione del nuovo stato proposto</strong>: Si crea un nuovo stato vicino a quello corrente utilizzando una distribuzione di proposta.</li>
<li><strong>Confronto tra densità posteriori</strong>: Si confrontano le densità a posteriori del nuovo stato proposto e dello stato corrente.</li>
<li><strong>Accettazione probabilistica</strong>: Il nuovo stato viene sempre accettato se ha una densità posteriore maggiore, oppure accettato con una certa probabilità se ha una densità minore.</li>
<li><strong>Burn-in e tasso di accettazione</strong>: I primi campioni vengono scartati (fase di burn-in) per garantire che la catena abbia raggiunto la distribuzione stazionaria, e si monitora il tasso di accettazione per ottimizzare l’efficienza del campionamento.</li>
</ul>
<p>Questo approccio consente di ottenere campioni che approssimano la distribuzione a posteriori, ma l’algoritmo di Metropolis può presentare limiti di efficienza, soprattutto per problemi ad alta dimensionalità o distribuzioni con geometrie complesse. Un aspetto cruciale è il <strong>tasso di accettazione</strong>, che rappresenta il rapporto tra il numero di proposte accettate e il numero totale di proposte. Un tasso troppo basso può indicare che la catena esplora lo spazio dei parametri in modo inefficiente, mentre un tasso troppo alto può segnalare che i passi effettuati sono troppo piccoli per consentire una buona esplorazione.</p>
<p>Rispetto alle varianti più moderne, l’algoritmo di Metropolis tende a essere meno efficiente. Metodi come il <strong>No-U-Turn Sampler (NUTS)</strong> e l’<strong>Hamiltonian Monte Carlo (HMC)</strong> offrono importanti miglioramenti, specialmente in spazi di parametri di grandi dimensioni. NUTS, ad esempio, viene utilizzato in strumenti avanzati come <strong>Stan</strong> e <strong>PyMC</strong> <span class="citation" data-cites="hoffman2014no">(<a href="#ref-hoffman2014no" role="doc-biblioref">Hoffman et al., 2014</a>)</span>, permettendo un’esplorazione più rapida e accurata della distribuzione a posteriori.</p>
<p>Tra gli altri algoritmi MCMC degni di nota troviamo il <strong>campionatore di Gibbs</strong> <span class="citation" data-cites="geman_geman_1984">(<a href="#ref-geman_geman_1984" role="doc-biblioref">Geman &amp; Geman, 1984</a>)</span> e l’<strong>Hamiltonian Monte Carlo</strong> <span class="citation" data-cites="duane1987hybrid">(<a href="#ref-duane1987hybrid" role="doc-biblioref">Duane et al., 1987</a>)</span>. Questi metodi, insieme a Metropolis-Hastings, formano la base di numerose tecniche moderne per il campionamento da distribuzioni complesse. Per un approfondimento dettagliato sulle tecniche MCMC, si consiglia di consultare <span class="citation" data-cites="hanada2022mcmc">Hanada &amp; Matsuura (<a href="#ref-hanada2022mcmc" role="doc-biblioref">2022</a>)</span>.</p>
<div class="callout callout-style-simple callout-important callout-titled" title="Esercizio 1: Autostima negli Studenti Universitari">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-11-contents" aria-controls="callout-11" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Esercizio 1: Autostima negli Studenti Universitari
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-11" class="callout-11-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>In un campione casuale di 100 studenti, 25 hanno mostrato livelli alti di autostima.<br>
Supponiamo un prior Beta(2,8) sulla proporzione <span class="math inline">\(\theta\)</span> di studenti con alta autostima.</p>
<p>Obiettivo: stimare la distribuzione a posteriori di <span class="math inline">\(\theta\)</span> usando l’<strong>algoritmo di Metropolis</strong>.</p>
<p><strong>Definizione delle Funzioni.</strong></p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)  <span class="co"># per riproducibilità</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Prior: Beta(2,8)</span></span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a>prior <span class="ot">&lt;-</span> <span class="cf">function</span>(p) <span class="fu">dbeta</span>(p, <span class="at">shape1 =</span> <span class="dv">2</span>, <span class="at">shape2 =</span> <span class="dv">8</span>)</span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Likelihood: binomiale 25 successi su 100</span></span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a>likelihood <span class="ot">&lt;-</span> <span class="cf">function</span>(p) <span class="fu">dbinom</span>(<span class="dv">25</span>, <span class="at">size =</span> <span class="dv">100</span>, <span class="at">prob =</span> p)</span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-9"><a href="#cb45-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Posterior non normalizzata</span></span>
<span id="cb45-10"><a href="#cb45-10" aria-hidden="true" tabindex="-1"></a>posterior <span class="ot">&lt;-</span> <span class="cf">function</span>(p) <span class="fu">prior</span>(p) <span class="sc">*</span> <span class="fu">likelihood</span>(p)</span>
<span id="cb45-11"><a href="#cb45-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-12"><a href="#cb45-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Distribuzione di proposta</span></span>
<span id="cb45-13"><a href="#cb45-13" aria-hidden="true" tabindex="-1"></a>proposal_distribution <span class="ot">&lt;-</span> <span class="cf">function</span>(current, proposal_sigma) {</span>
<span id="cb45-14"><a href="#cb45-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rnorm</span>(<span class="dv">1</span>, <span class="at">mean =</span> current, <span class="at">sd =</span> proposal_sigma)</span>
<span id="cb45-15"><a href="#cb45-15" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb45-16"><a href="#cb45-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-17"><a href="#cb45-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Algoritmo di Metropolis</span></span>
<span id="cb45-18"><a href="#cb45-18" aria-hidden="true" tabindex="-1"></a>metropolis <span class="ot">&lt;-</span> <span class="cf">function</span>(n_samples, start, proposal_sigma) {</span>
<span id="cb45-19"><a href="#cb45-19" aria-hidden="true" tabindex="-1"></a>  samples <span class="ot">&lt;-</span> <span class="fu">numeric</span>(n_samples)</span>
<span id="cb45-20"><a href="#cb45-20" aria-hidden="true" tabindex="-1"></a>  current <span class="ot">&lt;-</span> start</span>
<span id="cb45-21"><a href="#cb45-21" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb45-22"><a href="#cb45-22" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="fu">seq_len</span>(n_samples)) {</span>
<span id="cb45-23"><a href="#cb45-23" aria-hidden="true" tabindex="-1"></a>    proposal <span class="ot">&lt;-</span> <span class="fu">proposal_distribution</span>(current, proposal_sigma)</span>
<span id="cb45-24"><a href="#cb45-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (proposal <span class="sc">&gt;=</span> <span class="dv">0</span> <span class="sc">&amp;&amp;</span> proposal <span class="sc">&lt;=</span> <span class="dv">1</span>) {</span>
<span id="cb45-25"><a href="#cb45-25" aria-hidden="true" tabindex="-1"></a>      acceptance_ratio <span class="ot">&lt;-</span> <span class="fu">min</span>(<span class="dv">1</span>, <span class="fu">posterior</span>(proposal) <span class="sc">/</span> <span class="fu">posterior</span>(current))</span>
<span id="cb45-26"><a href="#cb45-26" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> (<span class="fu">runif</span>(<span class="dv">1</span>) <span class="sc">&lt;</span> acceptance_ratio) {</span>
<span id="cb45-27"><a href="#cb45-27" aria-hidden="true" tabindex="-1"></a>        current <span class="ot">&lt;-</span> proposal</span>
<span id="cb45-28"><a href="#cb45-28" aria-hidden="true" tabindex="-1"></a>      }</span>
<span id="cb45-29"><a href="#cb45-29" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb45-30"><a href="#cb45-30" aria-hidden="true" tabindex="-1"></a>    samples[i] <span class="ot">&lt;-</span> current</span>
<span id="cb45-31"><a href="#cb45-31" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb45-32"><a href="#cb45-32" aria-hidden="true" tabindex="-1"></a>  samples</span>
<span id="cb45-33"><a href="#cb45-33" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Esecuzione dell’Algoritmo.</strong></p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Parametri</span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>n_samples <span class="ot">&lt;-</span> <span class="dv">10000</span></span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>start <span class="ot">&lt;-</span> <span class="fl">0.5</span></span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>proposal_sigma <span class="ot">&lt;-</span> <span class="fl">0.1</span></span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Esecuzione</span></span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a>samples <span class="ot">&lt;-</span> <span class="fu">metropolis</span>(n_samples, start, proposal_sigma)</span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Burn-in</span></span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a>burnin <span class="ot">&lt;-</span> <span class="fu">floor</span>(n_samples <span class="sc">*</span> <span class="fl">0.5</span>)</span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a>post_samples <span class="ot">&lt;-</span> samples[<span class="sc">-</span><span class="fu">seq_len</span>(burnin)]</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Analisi dei Risultati.</strong></p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Media e deviazione standard</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(post_samples)</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.2444</span></span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a><span class="fu">sd</span>(post_samples)</span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.03947</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Calcolo dell’Intervallo di Credibilità al 94%.</strong></p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="fu">quantile</span>(post_samples, <span class="at">probs =</span> <span class="fu">c</span>(<span class="fl">0.03</span>, <span class="fl">0.97</span>))</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     3%    97% </span></span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 0.1699 0.3190</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Confronto con la Soluzione Analitica.</strong></p>
<p>La distribuzione a posteriori teorica è:</p>
<p><span class="math display">\[
\theta \sim \text{Beta}(27, 83)
\]</span></p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Media teorica</span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>mean_beta <span class="ot">&lt;-</span> <span class="dv">27</span> <span class="sc">/</span> (<span class="dv">27</span> <span class="sc">+</span> <span class="dv">83</span>)</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a>mean_beta</span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.2455</span></span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Intervallo teorico</span></span>
<span id="cb49-7"><a href="#cb49-7" aria-hidden="true" tabindex="-1"></a><span class="fu">qbeta</span>(<span class="fu">c</span>(<span class="fl">0.03</span>, <span class="fl">0.97</span>), <span class="dv">27</span>, <span class="dv">83</span>)</span>
<span id="cb49-8"><a href="#cb49-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.1727 0.3260</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Trace Plot.</strong></p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Trace plot</span></span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>post_samples <span class="sc">|&gt;</span> </span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tibble</span>(<span class="at">Iteration =</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(post_samples), <span class="at">Theta =</span> post_samples) <span class="sc">|&gt;</span> </span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> Iteration, <span class="at">y =</span> Theta)) <span class="sc">+</span></span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Trace Plot dopo Burn-in"</span>, <span class="at">x =</span> <span class="st">"Iterazione"</span>, <span class="at">y =</span> <span class="fu">expression</span>(theta))</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="01_metropolis_files/figure-html/unnamed-chunk-42-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<p><strong>Istogramma e Curva Teorica.</strong></p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Prima generiamo il dataset della curva teorica separatamente</span></span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="at">length.out =</span> <span class="dv">1000</span>)</span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>dens_teorica <span class="ot">&lt;-</span> <span class="fu">dbeta</span>(x, <span class="dv">27</span>, <span class="dv">83</span>)</span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>curva_teorica <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">x =</span> x, <span class="at">y =</span> dens_teorica)</span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Ora costruiamo il grafico correttamente</span></span>
<span id="cb51-7"><a href="#cb51-7" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(<span class="at">Theta =</span> post_samples) <span class="sc">|&gt;</span> </span>
<span id="cb51-8"><a href="#cb51-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> Theta)) <span class="sc">+</span></span>
<span id="cb51-9"><a href="#cb51-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">y =</span> <span class="fu">after_stat</span>(density)), <span class="at">bins =</span> <span class="dv">30</span>, </span>
<span id="cb51-10"><a href="#cb51-10" aria-hidden="true" tabindex="-1"></a>                 <span class="at">color =</span> <span class="st">"black"</span>, <span class="at">fill =</span> <span class="st">"lightblue"</span>, <span class="at">alpha =</span> <span class="fl">0.6</span>) <span class="sc">+</span></span>
<span id="cb51-11"><a href="#cb51-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">data =</span> curva_teorica, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y), </span>
<span id="cb51-12"><a href="#cb51-12" aria-hidden="true" tabindex="-1"></a>            <span class="at">color =</span> <span class="st">"red"</span>, <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb51-13"><a href="#cb51-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Posterior: Campioni MCMC vs Beta(27,83)"</span>, </span>
<span id="cb51-14"><a href="#cb51-14" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="fu">expression</span>(theta), <span class="at">y =</span> <span class="st">"Densità"</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="01_metropolis_files/figure-html/unnamed-chunk-43-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<p><strong>Risultati Riassunti.</strong></p>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: left;">Metodo</th>
<th style="text-align: left;">Media</th>
<th style="text-align: left;">Intervallo 94%</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">MCMC (Metropolis)</td>
<td style="text-align: left;">circa 0.245</td>
<td style="text-align: left;">circa [0.176, 0.320]</td>
</tr>
<tr class="even">
<td style="text-align: left;">Teorico Beta(27,83)</td>
<td style="text-align: left;">0.245</td>
<td style="text-align: left;">[0.177, 0.318]</td>
</tr>
</tbody>
</table>
<p><strong>Spiegazioni Didattiche Finali.</strong></p>
<div class="callout callout-style-simple callout-note callout-titled" title="Distribuzione a posteriori: interpretazione">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Distribuzione a posteriori: interpretazione
</div>
</div>
<div class="callout-body-container callout-body">
<p>La distribuzione a posteriori ci dice quanto sono plausibili i diversi valori di <span class="math inline">\(\theta\)</span> dopo aver osservato i dati.</p>
<blockquote class="blockquote">
<p>Ad esempio: “C’è una probabilità del 94% che la vera proporzione di studenti con alta autostima sia tra 17% e 32%.”</p>
</blockquote>
</div>
</div>
<div class="callout callout-style-simple callout-tip callout-titled" title="Accettare mosse peggiori: motivo">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Accettare mosse peggiori: motivo
</div>
</div>
<div class="callout-body-container callout-body">
<p>Accettiamo campioni con probabilità più bassa per permettere alla catena di esplorare anche aree meno probabili e <strong>non restare bloccata</strong> nei massimi locali.</p>
</div>
</div>
<div class="callout callout-style-simple callout-warning callout-titled" title="Larghezza della proposta: trade-off">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Larghezza della proposta: trade-off
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>Proposta stretta</strong> (piccoli passi): alta accettazione, ma esplorazione lenta.</li>
<li><strong>Proposta larga</strong> (grandi passi): bassa accettazione, ma esplorazione più ampia.</li>
</ul>
<p>Si cerca un tasso di accettazione tra 40% e 50%.</p>
</div>
</div>
<div class="callout callout-style-simple callout-important callout-titled" title="Diagnostica grafica">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Diagnostica grafica
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>Trace plot</strong>: deve mostrare fluttuazioni stabili senza trend.</li>
<li><strong>Correlogramma</strong>: l’autocorrelazione deve decrescere rapidamente.</li>
</ul>
<p>Questi strumenti aiutano a diagnosticare una buona esplorazione della distribuzione a posteriori.</p>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-important callout-titled" title="Esercizio 2 - Depressione (BDI-II)">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-14-contents" aria-controls="callout-14" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Esercizio 2 - Depressione (BDI-II)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-14" class="callout-14-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>In uno studio clinico, sono stati raccolti i punteggi BDI-II (Beck Depression Inventory) di 30 pazienti. Vogliamo stimare il valore medio della depressione nella popolazione da cui provengono questi soggetti.</p>
<p>Supponiamo di avere una conoscenza a priori modellata da una distribuzione <strong>Normale(30, 5²)</strong> per la media <span class="math inline">\(\mu\)</span>.</p>
<p>I dati osservati sono i seguenti:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">26</span>, <span class="dv">35</span>, <span class="dv">30</span>, <span class="dv">25</span>, <span class="dv">44</span>, <span class="dv">30</span>, <span class="dv">33</span>, <span class="dv">43</span>, <span class="dv">22</span>, <span class="dv">43</span>,</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>       <span class="dv">24</span>, <span class="dv">19</span>, <span class="dv">39</span>, <span class="dv">31</span>, <span class="dv">25</span>, <span class="dv">28</span>, <span class="dv">35</span>, <span class="dv">30</span>, <span class="dv">26</span>, <span class="dv">31</span>,</span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a>       <span class="dv">41</span>, <span class="dv">36</span>, <span class="dv">26</span>, <span class="dv">35</span>, <span class="dv">33</span>, <span class="dv">28</span>, <span class="dv">27</span>, <span class="dv">34</span>, <span class="dv">27</span>, <span class="dv">22</span>)</span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a><span class="fu">length</span>(y)  </span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 30</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Funzioni a priori, verosimiglianza e posteriori.</strong></p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Prior: Normal(30, 5^2)</span></span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>prior <span class="ot">&lt;-</span> <span class="cf">function</span>(mu) {</span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">dnorm</span>(mu, <span class="at">mean =</span> <span class="dv">30</span>, <span class="at">sd =</span> <span class="dv">5</span>)</span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-6"><a href="#cb53-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Likelihood: Normal(mu, sigma^2), sigma stimato dai dati</span></span>
<span id="cb53-7"><a href="#cb53-7" aria-hidden="true" tabindex="-1"></a>likelihood <span class="ot">&lt;-</span> <span class="cf">function</span>(mu, data) {</span>
<span id="cb53-8"><a href="#cb53-8" aria-hidden="true" tabindex="-1"></a>  sigma <span class="ot">&lt;-</span> <span class="fu">sd</span>(data)</span>
<span id="cb53-9"><a href="#cb53-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">prod</span>(<span class="fu">dnorm</span>(data, <span class="at">mean =</span> mu, <span class="at">sd =</span> sigma))</span>
<span id="cb53-10"><a href="#cb53-10" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb53-11"><a href="#cb53-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-12"><a href="#cb53-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Posterior non normalizzata</span></span>
<span id="cb53-13"><a href="#cb53-13" aria-hidden="true" tabindex="-1"></a>posterior <span class="ot">&lt;-</span> <span class="cf">function</span>(mu, data) {</span>
<span id="cb53-14"><a href="#cb53-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">likelihood</span>(mu, data) <span class="sc">*</span> <span class="fu">prior</span>(mu)</span>
<span id="cb53-15"><a href="#cb53-15" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Algoritmo di Metropolis.</strong></p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>metropolis_for_normal <span class="ot">&lt;-</span> <span class="cf">function</span>(nsamp, xinit, data) {</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>  samples <span class="ot">&lt;-</span> <span class="fu">numeric</span>(nsamp)</span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a>  x_prev <span class="ot">&lt;-</span> xinit</span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="fu">seq_len</span>(nsamp)) {</span>
<span id="cb54-6"><a href="#cb54-6" aria-hidden="true" tabindex="-1"></a>    x_star <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">1</span>, <span class="at">mean =</span> x_prev, <span class="at">sd =</span> <span class="fl">0.5</span>)  <span class="co"># proposta</span></span>
<span id="cb54-7"><a href="#cb54-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (<span class="fu">runif</span>(<span class="dv">1</span>) <span class="sc">&lt;</span> <span class="fu">min</span>(<span class="dv">1</span>, <span class="fu">posterior</span>(x_star, data) <span class="sc">/</span> <span class="fu">posterior</span>(x_prev, data))) {</span>
<span id="cb54-8"><a href="#cb54-8" aria-hidden="true" tabindex="-1"></a>      x_prev <span class="ot">&lt;-</span> x_star</span>
<span id="cb54-9"><a href="#cb54-9" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb54-10"><a href="#cb54-10" aria-hidden="true" tabindex="-1"></a>    samples[i] <span class="ot">&lt;-</span> x_prev</span>
<span id="cb54-11"><a href="#cb54-11" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb54-12"><a href="#cb54-12" aria-hidden="true" tabindex="-1"></a>  samples</span>
<span id="cb54-13"><a href="#cb54-13" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Esecuzione dell’algoritmo.</strong></p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>samples <span class="ot">&lt;-</span> <span class="fu">metropolis_for_normal</span>(<span class="dv">100000</span>, <span class="fu">mean</span>(y), y)</span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a>burnin <span class="ot">&lt;-</span> <span class="dv">50000</span></span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a>post_samples <span class="ot">&lt;-</span> samples[<span class="sc">-</span><span class="fu">seq_len</span>(burnin)]</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Confronto con la soluzione analitica.</strong></p>
<p>Nel caso prior Normale e likelihood Normale con varianza nota, la posterior è ancora Normale:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Prior</span></span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>mu_prior <span class="ot">&lt;-</span> <span class="dv">30</span></span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a>std_prior <span class="ot">&lt;-</span> <span class="dv">5</span></span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a>var_prior <span class="ot">&lt;-</span> std_prior<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb56-5"><a href="#cb56-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-6"><a href="#cb56-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Likelihood</span></span>
<span id="cb56-7"><a href="#cb56-7" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">length</span>(y)</span>
<span id="cb56-8"><a href="#cb56-8" aria-hidden="true" tabindex="-1"></a>sum_y <span class="ot">&lt;-</span> <span class="fu">sum</span>(y)</span>
<span id="cb56-9"><a href="#cb56-9" aria-hidden="true" tabindex="-1"></a>var_data <span class="ot">&lt;-</span> <span class="fu">var</span>(y)</span>
<span id="cb56-10"><a href="#cb56-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-11"><a href="#cb56-11" aria-hidden="true" tabindex="-1"></a>mu_post <span class="ot">&lt;-</span> (mu_prior <span class="sc">/</span> var_prior <span class="sc">+</span> sum_y <span class="sc">/</span> var_data) <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">/</span> var_prior <span class="sc">+</span> n <span class="sc">/</span> var_data)</span>
<span id="cb56-12"><a href="#cb56-12" aria-hidden="true" tabindex="-1"></a>var_post <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">/</span> var_prior <span class="sc">+</span> n <span class="sc">/</span> var_data)</span>
<span id="cb56-13"><a href="#cb56-13" aria-hidden="true" tabindex="-1"></a>std_post <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(var_post)</span>
<span id="cb56-14"><a href="#cb56-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-15"><a href="#cb56-15" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(mu_post, std_post)</span>
<span id="cb56-16"><a href="#cb56-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 30.882  1.173</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Trace Plot.</strong></p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Trace plot</span></span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>post_samples <span class="sc">|&gt;</span> </span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tibble</span>(<span class="at">Iteration =</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(post_samples), <span class="at">Mu =</span> post_samples) <span class="sc">|&gt;</span> </span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> Iteration, <span class="at">y =</span> Mu)) <span class="sc">+</span></span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb57-6"><a href="#cb57-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Trace Plot (Post Burn-in)"</span>, <span class="at">x =</span> <span class="st">"Iterazione"</span>, <span class="at">y =</span> <span class="fu">expression</span>(mu))</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="01_metropolis_files/figure-html/unnamed-chunk-49-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<p><strong>Istogramma vs Posterior Analitica.</strong></p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">seq</span>(mu_post <span class="sc">-</span> <span class="dv">4</span> <span class="sc">*</span> std_post, mu_post <span class="sc">+</span> <span class="dv">4</span> <span class="sc">*</span> std_post, <span class="at">length.out =</span> <span class="dv">1000</span>)</span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>dens_teorica <span class="ot">&lt;-</span> <span class="fu">dnorm</span>(x, <span class="at">mean =</span> mu_post, <span class="at">sd =</span> std_post)</span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a>curva_teorica <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">x =</span> x, <span class="at">y =</span> dens_teorica)</span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true" tabindex="-1"></a>post_samples <span class="sc">|&gt;</span> </span>
<span id="cb58-6"><a href="#cb58-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tibble</span>(<span class="at">Mu =</span> post_samples) <span class="sc">|&gt;</span> </span>
<span id="cb58-7"><a href="#cb58-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> Mu)) <span class="sc">+</span></span>
<span id="cb58-8"><a href="#cb58-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">y =</span> <span class="fu">after_stat</span>(density)), <span class="at">bins =</span> <span class="dv">30</span>, <span class="at">fill =</span> <span class="st">"skyblue"</span>, <span class="at">color =</span> <span class="st">"black"</span>, <span class="at">alpha =</span> <span class="fl">0.6</span>) <span class="sc">+</span></span>
<span id="cb58-9"><a href="#cb58-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">data =</span> curva_teorica, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y), <span class="at">color =</span> <span class="st">"red"</span>, <span class="at">linewidth =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb58-10"><a href="#cb58-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Posterior: MCMC vs Analitica"</span>, <span class="at">x =</span> <span class="fu">expression</span>(mu), <span class="at">y =</span> <span class="st">"Densit\u00e0"</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="01_metropolis_files/figure-html/unnamed-chunk-50-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<p><strong>Cosa significa la distribuzione a posteriori?</strong></p>
<p>In termini concreti, la distribuzione a posteriori rappresenta la nostra incertezza residua sul valore di <span class="math inline">\(\mu\)</span>, la media dei punteggi BDI-II nella popolazione, <strong>dopo aver visto i dati</strong>. Per esempio, se calcoliamo che il 94% della distribuzione a posteriori cade tra 27.5 e 32.3, possiamo dire:</p>
<blockquote class="blockquote">
<p>“Date le nostre ipotesi iniziali e i dati osservati, c’è una probabilità del 94% che il vero valore medio della depressione nella popolazione stia tra 27.5 e 32.3”.</p>
</blockquote>
<p>Questa è una <strong>affermazione probabilistica sul parametro</strong>, che è una caratteristica distintiva dell’inferenza bayesiana.</p>
<p>Questa distribuzione combina:</p>
<ul>
<li>le credenze precedenti (il prior),</li>
<li>con l’evidenza osservata (i dati).</li>
</ul>
<p>Il risultato è una distribuzione che riflette cosa sappiamo del parametro dopo aver osservato i dati, e può essere usata per ottenere medie, intervalli di credibilità, probabilità soggettive, ecc.</p>
<div class="callout callout-style-simple callout-tip callout-titled" title="Perché accettare anche campioni con densità più bassa?">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Perché accettare anche campioni con densità più bassa?
</div>
</div>
<div class="callout-body-container callout-body">
<p>Nell’algoritmo di Metropolis, a ogni passo si propone un nuovo valore di <span class="math inline">\(\theta\)</span>. Se questo valore ha una densità a posteriori più alta, viene accettato.</p>
<p>Ma se ha una densità più bassa, viene comunque accettato con una certa probabilità.</p>
<p><strong>Perché farlo?</strong></p>
<p>Per evitare che la catena si “blocchi” in un massimo locale. Per esplorare anche le aree meno probabili, ma comunque possibili, della distribuzione.</p>
<p>È un meccanismo simile a quello con cui gli esseri umani esplorano: ogni tanto vale la pena provare strade meno promettenti, per evitare di restare intrappolati. Accettare “mosse peggiori” è quindi un meccanismo di esplorazione utile a garantire che la catena possa visitare l’intero spazio dei parametri e convergere correttamente alla distribuzione desiderata.</p>
</div>
</div>
<div class="callout callout-style-simple callout-warning callout-titled" title="Larghezza della proposta: un equilibrio delicato">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Larghezza della proposta: un equilibrio delicato
</div>
</div>
<div class="callout-body-container callout-body">
<p>Nel Metropolis, il nuovo valore proposto viene scelto spostandosi dal valore corrente secondo una distribuzione normale:</p>
<p><span class="math display">\[\theta_{new} \sim \mathcal{N}(\theta_{attuale}, \sigma).\]</span></p>
<p>Il parametro <span class="math inline">\(\sigma\)</span> controlla la distanza dei passi.</p>
<p>Se <span class="math inline">\(\sigma\)</span> è:</p>
<ul>
<li>Piccolo → i passi sono molto corti:
<ul>
<li>Molte proposte vengono accettate (alta accettazione),</li>
<li>Ma la catena esplora lentamente → i campioni sono fortemente autocorrelati.</li>
</ul></li>
<li>Grande → i passi sono molto lunghi:
<ul>
<li>Si propongono salti drastici → molte proposte vengono rifiutate,</li>
<li>La catena si muove poco → anche in questo caso, esplorazione inefficiente.</li>
</ul></li>
</ul>
<p>🎯 Obiettivo: trovare un compromesso ottimale.</p>
<ul>
<li>Per un parametro unidimensionale, si consiglia spesso un tasso di accettazione tra 40% e 50%.</li>
<li>Negli esercizi puoi provare diversi valori di proposal_sigma e osservare il tasso di accettazione per imparare.</li>
</ul>
</div>
</div>
<p><strong>Risultati.</strong></p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(post_samples)</span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 30.87</span></span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a><span class="fu">sd</span>(post_samples)</span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 1.152</span></span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a><span class="fu">quantile</span>(post_samples, <span class="at">probs =</span> <span class="fu">c</span>(<span class="fl">0.03</span>, <span class="fl">0.97</span>))</span>
<span id="cb59-6"><a href="#cb59-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    3%   97% </span></span>
<span id="cb59-7"><a href="#cb59-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 28.71 33.06</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Valori teorici:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a>mu_post  <span class="co"># media teorica</span></span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 30.88</span></span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a><span class="fu">qnorm</span>(<span class="fu">c</span>(<span class="fl">0.03</span>, <span class="fl">0.97</span>), <span class="at">mean =</span> mu_post, <span class="at">sd =</span> std_post)</span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 28.68 33.09</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Spiegazione Didattica.</strong></p>
<ul>
<li>La media <span class="math inline">\(\mu\)</span> rappresenta il livello medio di depressione nella popolazione.</li>
<li>Il prior rappresenta la nostra credenza iniziale (Normale con media 30).</li>
<li>L’evidenza fornita dai dati modifica questa credenza.</li>
<li>L’algoritmo di Metropolis permette di campionare da una distribuzione posterior anche senza conoscere la forma analitica.</li>
<li>Il confronto tra distribuzione teorica e campioni MCMC mostra un ottimo accordo.</li>
</ul>
<p><strong>Conclusione.</strong></p>
<p>In questo esercizio abbiamo:</p>
<ul>
<li>implementato l’algoritmo di Metropolis per un caso con prior e likelihood Normali;</li>
<li>stimato la media della distribuzione posterior;</li>
<li>confrontato i risultati con la soluzione analitica;</li>
<li>verificato la coerenza dei campioni MCMC con la distribuzione teorica.</li>
</ul>
<p>Questo mostra la potenza dell’approccio MCMC anche in situazioni dove la soluzione analitica sarebbe disponibile, e pone le basi per affrontare problemi più complessi.</p>
</div>
</div>
</div>
</section>
<section id="informazioni-sullambiente-di-sviluppo" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="informazioni-sullambiente-di-sviluppo">Informazioni sull’Ambiente di Sviluppo</h2>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sessionInfo</span>()</span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; R version 4.5.0 (2025-04-11)</span></span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Platform: aarch64-apple-darwin20</span></span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Running under: macOS Sequoia 15.4.1</span></span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb61-6"><a href="#cb61-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Matrix products: default</span></span>
<span id="cb61-7"><a href="#cb61-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib </span></span>
<span id="cb61-8"><a href="#cb61-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1</span></span>
<span id="cb61-9"><a href="#cb61-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb61-10"><a href="#cb61-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; locale:</span></span>
<span id="cb61-11"><a href="#cb61-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] C/UTF-8/C/C/C/C</span></span>
<span id="cb61-12"><a href="#cb61-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb61-13"><a href="#cb61-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; time zone: Europe/Rome</span></span>
<span id="cb61-14"><a href="#cb61-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; tzcode source: internal</span></span>
<span id="cb61-15"><a href="#cb61-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb61-16"><a href="#cb61-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; attached base packages:</span></span>
<span id="cb61-17"><a href="#cb61-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     </span></span>
<span id="cb61-18"><a href="#cb61-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb61-19"><a href="#cb61-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; other attached packages:</span></span>
<span id="cb61-20"><a href="#cb61-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [1] cmdstanr_0.9.0   thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0</span></span>
<span id="cb61-21"><a href="#cb61-21" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [5] see_0.11.0       gridExtra_2.3    patchwork_1.3.0  bayesplot_1.12.0</span></span>
<span id="cb61-22"><a href="#cb61-22" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [9] psych_2.5.3      scales_1.3.0     markdown_2.0     knitr_1.50      </span></span>
<span id="cb61-23"><a href="#cb61-23" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [13] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     </span></span>
<span id="cb61-24"><a href="#cb61-24" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [17] purrr_1.0.4      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    </span></span>
<span id="cb61-25"><a href="#cb61-25" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [21] ggplot2_3.5.2    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      </span></span>
<span id="cb61-26"><a href="#cb61-26" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb61-27"><a href="#cb61-27" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; loaded via a namespace (and not attached):</span></span>
<span id="cb61-28"><a href="#cb61-28" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [1] gtable_0.3.6         tensorA_0.36.2.1     xfun_0.52           </span></span>
<span id="cb61-29"><a href="#cb61-29" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [4] htmlwidgets_1.6.4    processx_3.8.6       lattice_0.22-7      </span></span>
<span id="cb61-30"><a href="#cb61-30" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [7] tzdb_0.5.0           vctrs_0.6.5          tools_4.5.0         </span></span>
<span id="cb61-31"><a href="#cb61-31" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [10] ps_1.9.1             generics_0.1.3       parallel_4.5.0      </span></span>
<span id="cb61-32"><a href="#cb61-32" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [13] pacman_0.5.1         R.oo_1.27.0          pkgconfig_2.0.3     </span></span>
<span id="cb61-33"><a href="#cb61-33" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [16] data.table_1.17.0    checkmate_2.3.2      distributional_0.5.0</span></span>
<span id="cb61-34"><a href="#cb61-34" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [19] lifecycle_1.0.4      compiler_4.5.0       farver_2.1.2        </span></span>
<span id="cb61-35"><a href="#cb61-35" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [22] munsell_0.5.1        mnormt_2.1.1         htmltools_0.5.8.1   </span></span>
<span id="cb61-36"><a href="#cb61-36" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [25] pillar_1.10.2        R.utils_2.13.0       abind_1.4-8         </span></span>
<span id="cb61-37"><a href="#cb61-37" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [28] nlme_3.1-168         posterior_1.6.1      tidyselect_1.2.1    </span></span>
<span id="cb61-38"><a href="#cb61-38" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [31] digest_0.6.37        stringi_1.8.7        reshape2_1.4.4      </span></span>
<span id="cb61-39"><a href="#cb61-39" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [34] labeling_0.4.3       rprojroot_2.0.4      fastmap_1.2.0       </span></span>
<span id="cb61-40"><a href="#cb61-40" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [37] grid_4.5.0           colorspace_2.1-1     cli_3.6.4           </span></span>
<span id="cb61-41"><a href="#cb61-41" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [40] magrittr_2.0.3       withr_3.0.2          backports_1.5.0     </span></span>
<span id="cb61-42"><a href="#cb61-42" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [43] timechange_0.3.0     rmarkdown_2.29       R.methodsS3_1.8.2   </span></span>
<span id="cb61-43"><a href="#cb61-43" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [46] hms_1.1.3            evaluate_1.0.3       rlang_1.1.6         </span></span>
<span id="cb61-44"><a href="#cb61-44" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [49] Rcpp_1.0.14          glue_1.8.0           rstudioapi_0.17.1   </span></span>
<span id="cb61-45"><a href="#cb61-45" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [52] jsonlite_2.0.0       plyr_1.8.9           R6_2.6.1</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="bibliografia" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="bibliografia">Bibliografia</h2>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2" role="list">
<div id="ref-buerkner2024brms" class="csl-entry" role="listitem">
Bürkner, P.-C. (2024). <em>The brms Book: Applied Bayesian Regression Modelling Using R and Stan (Early Draft)</em>. <a href="https://paulbuerkner.com/software/brms-book">https://paulbuerkner.com/software/brms-book</a>
</div>
<div id="ref-duane1987hybrid" class="csl-entry" role="listitem">
Duane, S., Kennedy, A. D., Pendleton, B. J., &amp; Roweth, D. (1987). Hybrid monte carlo. <em>Physics letters B</em>, <em>195</em>(2), 216–222.
</div>
<div id="ref-geman_geman_1984" class="csl-entry" role="listitem">
Geman, S., &amp; Geman, D. (1984). Stochastic relaxation, <span>Gibbs</span> distributions, and the <span>Bayesian</span> restoration of images. <em>IEEE Transactions on pattern analysis and machine intelligence</em>, <em>6</em>, 721–741.
</div>
<div id="ref-hanada2022mcmc" class="csl-entry" role="listitem">
Hanada, M., &amp; Matsuura, S. (2022). <em>MCMC from Scratch</em>. Springer.
</div>
<div id="ref-hastings_1970" class="csl-entry" role="listitem">
Hastings, W. K. (1970). <span>Monte</span> <span>Carlo</span> sampling methods using <span>Markov</span> chains and their applications. <em>Biometrika</em>, <em>57</em>(1), 97–109.
</div>
<div id="ref-hoffman2014no" class="csl-entry" role="listitem">
Hoffman, M. D., Gelman, A., et al. (2014). The No-U-Turn sampler: adaptively setting path lengths in Hamiltonian Monte Carlo. <em>Journal of Machine Learning Research</em>, <em>15</em>(1), 1593–1623.
</div>
<div id="ref-metropolist_etal_1953" class="csl-entry" role="listitem">
Metropolis, N., Rosenbluth, A. W., Rosenbluth, M. N., Teller, A. H., &amp; Teller, E. (1953). Equation of state calculations by fast computing machines. <em>The Journal of Chemical Physics</em>, <em>21</em>(6), 1087–1092.
</div>
<div id="ref-zetsche_2019future" class="csl-entry" role="listitem">
Zetsche, U., Buerkner, P.-C., &amp; Renneberg, B. (2019). Future expectations in clinical depression: biased or realistic? <em>Journal of Abnormal Psychology</em>, <em>128</em>(7), 678–688.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copiato!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copiato!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/ccaudek\.github\.io\/psicometria-r\/intro\.html");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
          // default icon
          link.classList.add("external");
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../chapters/mcmc/introduction_mcmc.html" class="pagination-link" aria-label="Introduzione">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Introduzione</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../chapters/mcmc/02_ppl.html" class="pagination-link" aria-label="Linguaggi di programmazione probabilistici">
        <span class="nav-page-text"><span class="chapter-number">59</span>&nbsp; <span class="chapter-title">Linguaggi di programmazione probabilistici</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p><strong>Psicometria</strong> è una risorsa didattica creata per il corso di Scienze e Tecniche Psicologiche dell’Università degli Studi di Firenze.</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/ccaudek/psicometria-r/blob/main/chapters/mcmc/01_metropolis.qmd" class="toc-action"><i class="bi bi-github"></i>Mostra il codice</a></li><li><a href="https://github.com/ccaudek/psicometria-r/issues/new" class="toc-action"><i class="bi empty"></i>Segnala un problema</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>Realizzato con <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>




</body></html>