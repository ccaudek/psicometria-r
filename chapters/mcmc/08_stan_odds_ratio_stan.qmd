# Analisi bayesiana dell'odds ratio {#sec-bayes-odds-ratio}

::: callout-note
*Obiettivo.* Stimare e interpretare l’*odds ratio* (OR) tra due proporzioni con Stan, partendo da un esperimento classico di etologia, quantificando l’incertezza tramite la distribuzione a posteriori e un intervallo di credibilità.
:::

*Prerequisiti*

* Nozioni di base su Bernoulli/Binomiale, odds e odds ratio.
* Concetto di prior e posteriore.

*Concetti e Competenze Chiave*

* Modellazione binomiale di due proporzioni $(\theta_1,\theta_2)$.
* Priori debolmente informativi (Beta(2,2)) e loro interpretazione.
* Calcolo e lettura dell’OR e del log-OR.
* Riassunti posteriori (mediana, CrI), probabilità di superare una soglia ($\Pr(\text{OR}>1)$).

*Preparazione del Notebook*

```{r}
#| output: false

here::here("code", "_common.R") |> 
  source()

if (!requireNamespace("pacman")) install.packages("pacman")
pacman::p_load(cmdstanr, posterior, bayesplot, ggplot2, dplyr, tibble)
conflicts_prefer(posterior::ess_bulk)
conflicts_prefer(posterior::ess_tail)
```


## Introduzione {.unnumbered .unlisted}

::: {.lead}
Nelle scienze psicologiche e sociali ci interessa spesso capire se esiste un’associazione tra due variabili dicotomiche. Per esempio: *gli studenti che hanno seguito un corso di preparazione hanno più probabilità di superare l’esame rispetto a chi non lo ha seguito?*  
:::

Un modo naturale per quantificare questo tipo di relazione è l’*odds ratio*. È una misura intuitiva, perché confronta due probabilità trasformandole in termini di *odds* (rapporti di chance).  

In questo capitolo vedremo:

- come si definiscono probabilità, odds e odds ratio;  
- come si interpreta l’odds ratio in contesti psicologici;  
- come stimarlo in ottica bayesiana, implementando un modello in *Stan*;  
- come presentare i risultati con intervalli di credibilità.  


## Il contesto sperimentale 
  
Nella prima metà del Novecento, Karl von Frisch si chiese se le api possedessero la *visione dei colori*. Per verificarlo, progettò esperimenti in cui le api potevano associare un colore a una ricompensa. Ispirandoci a una ricostruzione di @hoffmann2022bayesian, immaginiamo un disegno sperimentale semplificato:
  
* *Gruppo sperimentale*: api addestrate ad associare un disco blu a una soluzione zuccherina.
* *Gruppo di controllo*: api che non ricevono alcun addestramento.

Nella fase di *test*, la soluzione zuccherina viene rimossa, e si osserva quante volte le api si avvicinano al disco blu (evento critico).

I risultati osservati sono:
  
  | Gruppo       | Successi (scelta blu) | Totale |
  | ------------ | --------------------- | ------ |
  | Sperimentale | 130                   | 200    |
  | Controllo    | 100                   | 200    |
  
La domanda è chiara: *le api addestrate hanno odds maggiori di preferire il disco blu rispetto alle api non addestrate?*


## Da probabilità a odds
  
La probabilità di successo (scelta blu) nel gruppo sperimentale è:
  
$$
p\_1 = \frac{130}{200} = 0.65.
$$
  
Gli *odds* corrispondenti sono:
  
$$
\text{odds}\_1 = \frac{p\_1}{1-p\_1} = \frac{0.65}{0.35} \approx 1.86.
$$
  
  Per il gruppo di controllo:
  
$$
p\_2 = \frac{100}{200} = 0.50, \quad \text{odds}\_2 = \frac{0.5}{0.5} = 1.
$$
  
## Odds ratio
  
L’odds ratio (OR) confronta i due odds:
  
$$
\text{OR} = \frac{\text{odds}\_1}{\text{odds}\_2} = \frac{1.86}{1} \approx 1.86.
$$
  
**Interpretazione:** le api addestrate hanno odds circa 1.9 volte maggiori di scegliere il disco blu rispetto alle api non addestrate. Questo non significa che la loro probabilità sia il doppio, ma che il rapporto tra successi e insuccessi è quasi raddoppiato.

Ma quanto è credibile questa stima? È qui che l’approccio bayesiano diventa utile: invece di fermarci a una stima puntuale, otteniamo un’intera distribuzione a posteriori per l’OR.


## Approccio bayesiano

Con l’approccio frequentista, l’odds ratio viene stimato come rapporto di stime puntuali, con un intervallo di confidenza ottenuto tramite approssimazioni asintotiche.  Con l’approccio bayesiano, invece, otteniamo direttamente la *distribuzione a posteriori dell’odds ratio*. Questo ci permette di calcolare:  

- la probabilità che l’OR sia maggiore di 1;  
- la probabilità che cada in un intervallo di equivalenza (ROPE);  
- intervalli di credibilità (ETI o HDI).  

In questo modo il risultato non solo è più intuitivo, ma ci permette anche di rispondere a domande in termini probabilistici, ad esempio: qual è la probabilità che l’OR sia maggiore di 1?.


### Relazione con la regressione logistica

Il collegamento chiave è la *regressione logistica*. Se modelliamo la probabilità di successo $p_i$ come:

$$
\text{logit}(p_i) = \alpha + \beta x_i,
$$

dove $x_i$ è una variabile dicotomica (0 = controllo, 1 = trattamento), allora:  

- $\exp(\beta)$ è proprio l’*odds ratio* tra i due gruppi.  

Questo significa che stimare un modello logistico equivale a stimare l’odds ratio, con il vantaggio di poter estendere facilmente il modello a più predittori.  


### Versione logistica

Rappresentiamo i dati individuali: ogni ape è codificata come 1 (ha scelto il blu) o 0 (non ha scelto il blu).

```{r}
# Dati individuali
y <- c(rep(1, 130), rep(0, 70),  # gruppo sperimentale
       rep(1, 100), rep(0, 100)) # gruppo controllo
x <- c(rep(1, 200), rep(0, 200)) # 1 = sperimentale, 0 = controllo

data_list <- list(N = length(y), y = y, x = x)
glimpse(data_list)
```



### Modello Stan 

```{r}
stancode_or <- "
data {
  int<lower=1> N;                  
  array[N] int<lower=0,upper=1> y; // esiti 0/1
  vector[N] x;                     // gruppo (0/1)
}
parameters {
  real alpha;    // log-odds nel controllo
  real beta;     // differenza di log-odds (sperimentale vs controllo)
}
model {
  alpha ~ normal(0, 5);
  beta  ~ normal(0, 5);
  y ~ bernoulli_logit(alpha + beta * x);
}
generated quantities {
  real OR = exp(beta);
}
"
```

Compilazione ed esecuzione

```{r}
#| output: false

stanmod_or <- cmdstanr::cmdstan_model(write_stan_file(stancode_or))

fit_or <- stanmod_or$sample(
  data = data_list,
  iter_warmup = 1000,
  iter_sampling = 4000,
  chains = 4,
  seed = 123,
  refresh = 0
)
```

### Interpretazione dei risultati

Riassunto dei parametri:

```{r}
print(fit_or$summary(c("alpha","beta","OR")), n = Inf)
```

* $\alpha$ = log-odds di successo nel gruppo di controllo;
* $\beta$ = differenza di log-odds tra i due gruppi;
* $\exp(\beta)$ = odds ratio.

Distribuzione a posteriori dell’OR:

```{r}
posterior::summarise_draws(
  fit_or$draws("OR"),
  mean, sd, ~quantile(.x, c(0.025, 0.5, 0.975))
)
```

Questo riassume la media, la mediana e l’intervallo di credibilità (es. 95%) dell’odds ratio.

Visualizzazione:

```{r}
bayesplot::mcmc_hist(fit_or$draws("OR")) +
  ggtitle("Distribuzione a posteriori dell’odds ratio")
```

```{r}
bayesplot::mcmc_areas(fit_or$draws("OR"), prob = 0.95) +
  ggtitle("Intervallo di credibilità al 95% per l’odds ratio")
```

Il grafico mostra che l’odds ratio è ben sopra 1, con alta probabilità.

**Interpretazione:** è molto plausibile che l’addestramento aumenti le probabilità che le api scelgano il disco blu rispetto al gruppo di controllo.



### Diagnostica essenziale 

```{r}
# Indicatori numerici chiave: Rhat ~ 1, ESS adeguati
posterior::summarize_draws(
  fit_or$draws(c("alpha","beta","OR")),
  "rhat", "ess_bulk", "ess_tail"
)
```

```{r}
# Traceplot di controllo su OR
bayesplot::mcmc_trace(fit_or$draws("OR")) +
  ggtitle("Traceplot di OR")
```

Se emergono problemi (Rhat > 1.01, ESS basso, divergenze riportate in output), conviene aumentare `iter_warmup`/`iter_sampling`, alzare `adapt_delta` o, in ultima istanza, riconsiderare i prior se sono eccessivamente stretti.


## Versione binomiale con prior Beta

Finora abbiamo stimato l’odds ratio tramite la regressione logistica: $\exp(\beta)$ fornisce direttamente l’OR tra i due gruppi. Un’alternativa altrettanto corretta — spesso preferita quando i dati sono naturalmente riassumibili in una tabella 2×2 — è modellare *separatamente* le due proporzioni $(\theta_1,\theta_2)$ con una *binomiale* e prior *Beta* debolmente informativi, e calcolare l’OR come trasformazione dei due parametri:

$$
\text{OR} \;=\; \frac{\theta_1/(1-\theta_1)}{\theta_2/(1-\theta_2)} \;=\; \exp\!\big(\operatorname{logit}(\theta_1)-\operatorname{logit}(\theta_2)\big).
$$

Questa formulazione è didatticamente trasparente: stimiamo le due probabilità di successo e poi traduciamo il risultato nell’odds ratio. Con prior *Beta(2,2)* manteniamo coerenza con le impostazioni del capitolo (prior debolmente informativi).

### Stan: due binomiali + prior Beta(2,2)

```{r}
stancode_or_beta <- "
data {
  int<lower=0> k1; int<lower=1> n1; // successi, prove sperimentale
  int<lower=0> k2; int<lower=1> n2; // successi, prove controllo
}
parameters {
  real<lower=0,upper=1> theta1;
  real<lower=0,upper=1> theta2;
}
model {
  theta1 ~ beta(2, 2);
  theta2 ~ beta(2, 2);
  k1 ~ binomial(n1, theta1);
  k2 ~ binomial(n2, theta2);
}
generated quantities {
  real logOR = logit(theta1) - logit(theta2);
  real OR    = exp(logOR);
}
"
```

```{r}
data_list_beta <- list(
  k1 = 130, n1 = 200,
  k2 = 100, n2 = 200
)
data_list_beta
```


Compilazione e campionamento:

```{r}
#| output: false

stanmod_or_beta <- cmdstanr::cmdstan_model(write_stan_file(stancode_or_beta))

fit_or_beta <- stanmod_or_beta$sample(
  data = data_list_beta,
  iter_warmup   = 1000,
  iter_sampling = 4000,
  chains        = 4,
  parallel_chains = 4,
  seed = 123,
  refresh = 0
)
```

**Riassunti posteriori e confronto con la logistica.**

Cominciamo dai riassunti posteriori dell’OR nel modello Beta–Binomiale:

```{r}
posterior::summarise_draws(
  fit_or_beta$draws(c("theta1","theta2","logOR","OR")),
  mean, sd, ~quantile(.x, c(0.025, 0.5, 0.975))
)
```

Ora affianchiamo i risultati dei *due* modelli (logistico vs Beta–Binomiale). In primo luogo, confrontiamo gli *intervalli di credibilità* dell’OR:

```{r}
summ_logit <- posterior::summarise_draws(
  fit_or$draws("OR"),
  mean, sd, ~quantile(.x, c(0.025, 0.5, 0.975))
)
summ_beta <- posterior::summarise_draws(
  fit_or_beta$draws("OR"),
  mean, sd, ~quantile(.x, c(0.025, 0.5, 0.975))
)

list(logistico = summ_logit, beta_binomiale = summ_beta)
```

Per una *verifica visiva*, sovrapponiamo le densità posteriori dell’OR:

```{r}
OR_logit <- as.numeric(fit_or$draws("OR"))
OR_beta  <- as.numeric(fit_or_beta$draws("OR"))

tibble(
  OR = c(OR_logit, OR_beta),
  modello = rep(c("Logistico", "Beta–Binomiale"), 
                c(length(OR_logit), length(OR_beta)))
) |>
  ggplot(aes(x = OR, fill = modello)) +
  geom_density(alpha = 0.35) +
  labs(title = "Posteriori dell'odds ratio: Logistico vs Beta–Binomiale",
       x = "Odds Ratio", y = "Densità")
```

Infine, verifichiamo che la *probabilità a posteriori* di OR>1 sia sostanzialmente la stessa in entrambe le specificazioni:

```{r}
c(
  P_OR_gt_1_logistico   = mean(OR_logit > 1),
  P_OR_gt_1_betaBinom   = mean(OR_beta  > 1)
)
```

**Cosa aspettarsi?**

I due approcci devono produrre risultati *coerenti* (entro le ovvie fluttuazioni Monte Carlo). Entrambi stimano, in modi diversi ma equivalenti sul piano inferenziale, la stessa quantità di interesse: l’odds ratio tra i due gruppi. La scelta pratica dipende dalla struttura dei dati e dagli obiettivi comunicativi:

* Se hai dati *individuali* (successo/insuccesso per soggetto) e vuoi estendere a covariate, *la regressione logistica* è naturale e scalabile.
* Se lavori con *conteggi* per cella (tabella 2×2) e vuoi la via più *diretta* alla misura d’effetto, il *modello Beta–Binomiale* è compatto e trasparente.

Entrambe le vie portano, correttamente, alla *stessa conclusione* sul valore di OR e sulla sua incertezza.


## Riflessioni conclusive {.unnumbered .unlisted}

In questo capitolo, abbiamo esplorato come applicare un approccio bayesiano per analizzare e interpretare l'odds ratio tra due proporzioni. Attraverso l'uso del modello statistico, siamo stati in grado di stimare la distribuzione a posteriori dell'odds ratio e di calcolare l'intervallo di credibilità.

I risultati ottenuti, supportati da un controllo diagnostico delle catene Markoviane, indicano che la differenza osservata tra i due gruppi è credibile e supportata dai dati. L'odds ratio stimato e il relativo intervallo di credibilità si collocano sopra il valore 1, indicando che, dati i nostri assunti, è altamente probabile che il gruppo sperimentale abbia odds maggiori rispetto al gruppo di controllo. L'approccio bayesiano si è dimostrato efficace, non solo per stimare i parametri di interesse, ma anche per quantificare l'incertezza associata a tali stime. 

In sintesi, l'analisi bayesiana dell'odds ratio ha permesso di rispondere alla domanda di ricerca, confermando che le api mostrano comportamenti coerenti con una capacità di distinzione cromatica. L'approccio presentato in questo capitolo può essere esteso ad altre applicazioni, offrendo una struttura versatile per il confronto tra proporzioni in diversi contesti sperimentali.


## Informazioni sull’ambiente di sviluppo {.unnumbered .unlisted}

```{r}
sessionInfo()
```


## Bibliografia {.unnumbered .unlisted}

