---
execute:
  freeze: auto
---

# Probabilità condizionata {#sec-prob-conditional-prob}

::: callout-important
## In questo capitolo imparerai a:

- comprendere e applicare i concetti di probabilità congiunta, marginale e condizionata;
- approfondire la comprensione e l'applicazione dei principi di indipendenza e probabilità condizionata;
- analizzare e interpretare il paradosso di Simpson;
- applicare il Teorema della Probabilità Composta per calcolare la probabilità di eventi interdipendenti;
- utilizzare il Teorema della Probabilità Totale per scomporre e calcolare probabilità complesse. 
:::

::: callout-tip
## Prerequisiti

- Leggere il capitolo *Conditional probability* di **Introduction to Probability** [@blitzstein2019introduction]. 
- Leggere il capitolo *Conditional Probability* [@schervish2014probability].
:::

::: callout-caution
## Preparazione del Notebook

```{r}
here::here("code", "_common.R") |> 
  source()
```
:::


## Introduzione

La probabilità condizionata si riferisce al calcolo della probabilità di un evento, tenendo conto che un altro evento si è già verificato. Questo concetto è cruciale perché riflette come aggiorniamo le nostre credenze alla luce di nuove evidenze o informazioni. Per esempio, immaginiamo di voler stimare la probabilità di pioggia per domani. La nostra stima iniziale cambia se oggi osserviamo un cielo nuvoloso. Il fatto che oggi sia nuvoloso "condiziona" la nostra valutazione della probabilità di pioggia per domani.

Questo processo di aggiornamento delle nostre credenze in base a nuove osservazioni è continuo. Una nuova evidenza coerente con una credenza esistente potrebbe rafforzarla, mentre un'osservazione inaspettata potrebbe metterla in discussione. La probabilità condizionata non è solo un concetto teorico, ma ha applicazioni pratiche sia nella vita quotidiana che in ambito scientifico. In realtà, si potrebbe argomentare che tutte le probabilità sono in qualche modo condizionate da un certo contesto o da informazioni preesistenti, anche se non sempre lo specifichiamo esplicitamente.

In sintesi, la probabilità condizionata ci fornisce un framework per comprendere e quantificare come le nostre credenze dovrebbero evolversi man mano che acquisiamo nuove informazioni, rendendo il concetto di probabilità uno strumento dinamico e potente per gestire l'incertezza.

## Indipendenza Stocastica

Il concetto di indipendenza è cruciale nel contesto della probabilità condizionata, facilitando notevolmente i calcoli in numerosi problemi e indicando come la presenza di un evento non influenzi l'occorrenza di un altro.

### Indipendenza di Due Eventi

Due eventi, $A$ e $B$, sono considerati **indipendenti** se la realizzazione di uno non altera la probabilità di occorrenza dell'altro. Formalmente, questa relazione è espressa come:

$$P(A \cap B) = P(A) P(B),$$

dove $P(A \cap B)$ è la probabilità che $A$ e $B$ si verifichino contemporaneamente. Se questa condizione è verificata, denotiamo $A \text{ ⫫ } B$, indicando che $A$ è indipendente da $B$.

### Indipendenza di un Insieme di Eventi

L'indipendenza stocastica è un principio fondamentale nell'applicazione statistica della probabilità. Un insieme di eventi $\{ A_i : i \in I \}$ è definito **indipendente** se per ogni sottoinsieme finito $J$ di $I$, la probabilità dell'intersezione degli eventi in $J$ equivale al prodotto delle loro probabilità individuali:

$$P \left( \bigcap_{i \in J} A_i \right) = \prod_{i \in J} P(A_i).$$

Questo implica che ogni combinazione finita di eventi nell'insieme agisce in maniera indipendente.

L'indipendenza può essere **assunta** o **derivata**, a seconda del contesto. In alcuni modelli o situazioni, assumiamo l'indipendenza per semplificare i calcoli o per riflettere una conoscenza preesistente. In altri contesti, l'indipendenza può emergere dai dati o da altre proprietà del modello.

### Eventi Disgiunti e Indipendenza

Eventi disgiunti, o mutuamente esclusivi, sono quelli che non possono verificarsi contemporaneamente, ossia $\mathbb{P}(A \cap B) = 0$. Se due eventi disgiunti hanno probabilità positive, essi non possono essere indipendenti, poiché l'equazione $P(A \cap B) = P(A) P(B)$ non può essere soddisfatta; $P(A \cap B) = 0$ non uguaglia $P(A) P(B) > 0$.

## Probabilità Condizionata

La probabilità di un evento è sempre contestualizzata e varia a seconda del nostro stato di informazione. Con un insieme di informazioni disponibile, attribuiamo una probabilità specifica a un evento. Se lo stato informativo cambia, anche la probabilità associata deve essere aggiornata. In sostanza, tutte le probabilità possono essere considerate condizionate, anche se l'evento condizionante non è esplicitato.

La **probabilità condizionata** di un evento $A$ dato un altro evento $B$, con $P(B) > 0$, è definita come:

$$ 
P(A \mid B) = \frac{P(A \cap B)}{P(B)},
$$ {#eq-prob-cond-definition}

dove $P(A \cap B)$ è la probabilità congiunta di $A$ e $B$. Questa relazione permette di derivare la regola della moltiplicazione:

$$ 
P(A \cap B) = P(A \mid B)P(B) = P(B \mid A)P(A), 
$$

e una forma alternativa della legge della probabilità totale:

$$ 
P(A) = P(A \mid B)P(B) + P(A \mid B^c)P(B^c),
$$

dove $B^c$ rappresenta il complemento di $B$.

Per spazi campionari discreti, possiamo esprimere la probabilità condizionata come:

$$
P(A \mid B) = \frac{| A \cap B |}{| B |}.
$$

La probabilità condizionata ricalibra lo spazio campionario, riducendolo da $S$ a $B$, e non è definita se $P(B) = 0$.

::: {#exm-}
Lanciamo due dadi equilibrati consecutivamente.  
Dato che la somma dei dadi è 10, qual è la probabilità che uno dei due dadi mostri un 6?  

Definiamo:  

- **B** come l'evento che la somma sia 10:  
  $$ B = \{(4, 6), (5, 5), (6, 4)\}. $$  
- **A** come l'evento che uno dei due dadi mostri un 6:  
  $$ A = \{(1, 6), \dots, (5, 6), (6, 1), \dots, (6, 5)\}. $$  

L'intersezione tra **A** e **B** è:  
$$ A \cap B = \{(4, 6), (6, 4)\}. $$  

Poiché in questo esperimento tutti gli eventi elementari sono equiprobabili, la probabilità condizionata $P(A | B)$ è data da:  
$$
P(A | B) = \frac{P(A \cap B)}{P(B)} = \frac{\frac{2}{36}}{\frac{3}{36}} = \frac{2}{3}.
$$  

Quindi, la probabilità che uno dei due dadi mostri un 6, sapendo che la somma è 10, è $\frac{2}{3}$.
:::

::: {#exm-}
Lanciamo due dadi equilibrati e vogliamo calcolare la probabilità che la somma dei punteggi ottenuti sia minore di 8.

Inizialmente, quando non abbiamo ulteriori informazioni, possiamo calcolare la probabilità in modo tradizionale. Ci sono 21 risultati possibili con somma minore di 8. Poiché ci sono 36 possibili combinazioni di lancio dei due dadi, la probabilità di ottenere una somma minore di 8 è 21/36, che equivale a circa 0.58.

Supponiamo ora di sapere che la somma del lancio di due dadi ha prodotto un risultato dispari. In questo caso, ci sono solo 18 possibili combinazioni di lancio dei due dadi (dato che abbiamo escluso i risultati pari). Tra essi, vi sono 12 risultati che soddisfano la condizione per cui la somma è minore di 8. Quindi, la probabilità di ottenere una somma minore di 8 cambia da circa 0.58 a 12/18, ovvero 0.67 quando consideriamo l'informazione aggiuntiva del risultato dispari.

Svolgiamo il problema in R:

```{r}
r <- 1:6
sample <- expand.grid(i = r, j = r)
sample
```

```{r}
event <- subset(sample, i + j < 8)
cat(nrow(event), "/", nrow(sample), "\n")
```

```{r}
sample_odd <- subset(sample, (i + j) %% 2 != 0)
sample_odd
```

```{r}
event <- subset(sample_odd, i + j < 8)
cat(nrow(event), "/", nrow(sample_odd), "\n")
```

Se applichiamo l'@eq-prob-cond-definition, abbiamo: $P(A \cap B)$ = 12/36, $P(B)$ = 18/36 e 

$$
P(A \mid B) = \frac{12}{18}.
$$

Questo esempio illustra come la probabilità di un evento possa variare in base alle informazioni aggiuntive di cui disponiamo. Nel secondo caso, avendo l'informazione che la somma è dispari, la probabilità di ottenere una somma minore di 8 aumenta notevolmente rispetto al caso iniziale in cui non avevamo questa informazione.
:::

::: {#exm-}

Consideriamo uno screening per la diagnosi precoce del tumore mammario utilizzando un test con determinate caratteristiche:

- Sensibilità del test: 90%. Questo significa che il test classifica correttamente come positivo il 90% delle donne colpite dal cancro al seno.
- Specificità del test: 90%. Ciò indica che il test classifica correttamente come negativo il 90% delle donne che non hanno il cancro al seno.
- Prevalenza del cancro al seno nella popolazione sottoposta allo screening: 1% (0.01). Questo è il 1% delle donne che ha effettivamente il cancro al seno, mentre il restante 99% (0.99) non ne è affetto.

Ora cerchiamo di rispondere alle seguenti domande:

- Qual è la probabilità che una donna scelta a caso ottenga una mammografia positiva? Poiché il 1% delle donne ha il cancro al seno, la probabilità di ottenere una mammografia positiva (test positivo) è pari alla sensibilità del test, ovvero 0.90 (cioè 90%).

- Se la mammografia è positiva, qual è la probabilità che vi sia effettivamente un tumore al seno?

Per risolvere questo problema, consideriamo un campione di 1000 donne sottoposte al test di screening per il tumore al seno. Di queste 1000 donne:

- 10 donne (1% del campione) hanno effettivamente il cancro al seno. Per queste 10 donne con il cancro, il test darà un risultato positivo (vera positività) in 9 casi (90%).
- Per le restanti 990 donne (99% del campione) che non hanno il cancro al seno, il test darà un risultato positivo (falsa positività) in 99 casi (10%).

Questa situazione può essere rappresentata graficamente nel seguente modo:

::: {#fig-mammography}
![](../../figures/mammografia.png){width="64%"}

Esiti della mammografia per 1000 donne.
:::

Combinando i due risultati precedenti, vediamo che il test dà un risultato positivo per 9 donne che hanno effettivamente il cancro al seno e per 99 donne che non lo hanno, per un totale di 108 risultati positivi su 1000. Pertanto, la probabilità di ottenere un risultato positivo al test è $\frac{108}{1000}$ = 0.108.

Tuttavia, tra le 108 donne che hanno ottenuto un risultato positivo al test, solo 9 hanno effettivamente il cancro al seno. Quindi, la probabilità di avere il cancro al seno, dato un risultato positivo al test, è pari a $\frac{9}{108}$ = 0.083, corrispondente all'8.3%.

In questo esempio, la probabilità dell'evento "ottenere un risultato positivo al test" è una probabilità non condizionata, poiché calcoliamo semplicemente la proporzione di risultati positivi nel campione totale. D'altra parte, la probabilità dell'evento "avere il cancro al seno, dato che il test ha prodotto un risultato positivo" è una probabilità condizionata, poiché calcoliamo la proporzione delle donne con il cancro al seno tra quelle che hanno ottenuto un risultato positivo al test.

Questo esempio illustra come la conoscenza di ulteriori informazioni (il risultato positivo al test) può influenzare la probabilità di un evento (avere il cancro al seno), mostrando chiaramente la differenza tra probabilità condizionate e non condizionate.
:::


## Il Problema di Monty Hall

Il **problema di Monty Hall** è un famoso quesito di teoria della probabilità che illustra in modo efficace il concetto di probabilità condizionata. Questo problema è diventato celebre grazie a una rubrica tenuta da Marilyn vos Savant nella rivista *Parade*, in cui rispose a una lettera pubblicata il 9 settembre 1990:

> "Supponiamo di partecipare a un quiz televisivo e di dover scegliere tra tre porte. Dietro una di esse c'è un'auto, mentre dietro le altre due ci sono delle capre. Scegli una porta, ad esempio la numero 1, e il conduttore, che sa cosa c'è dietro ogni porta, ne apre un'altra, diciamo la numero 3, rivelando una capra. A questo punto, ti chiede se vuoi cambiare la tua scelta e passare alla porta numero 2. È vantaggioso cambiare porta?"
> Craig. F. Whitaker, Columbia, MD

La situazione descritta ricorda quella del popolare quiz televisivo degli anni '70 *Let's Make a Deal*, condotto da Monty Hall e Carol Merrill. Marilyn vos Savant rispose che il concorrente dovrebbe cambiare porta, poiché la probabilità di vincere l'auto raddoppia passando da 1/3 a 2/3. Tuttavia, la sua risposta suscitò un acceso dibattito, con molte persone, inclusi alcuni matematici, che sostenevano che cambiare porta non avrebbe offerto alcun vantaggio. Questo episodio ha reso il problema di Monty Hall uno dei più famosi esempi di come l'intuizione possa portare a conclusioni errate in ambito probabilistico.

### Chiarire il Problema

La lettera originale di Craig Whitaker è piuttosto vaga, quindi per analizzare il problema in modo rigoroso è necessario fare alcune ipotesi:

1. **Posizione dell'auto**: L'auto è nascosta in modo casuale ed equiprobabile dietro una delle tre porte.
2. **Scelta iniziale del giocatore**: Il giocatore sceglie una porta in modo casuale, indipendentemente dalla posizione dell'auto.
3. **Azione del conduttore**: Dopo la scelta del giocatore, il conduttore apre una delle due porte rimanenti, rivelando una capra, e offre al giocatore la possibilità di cambiare porta.
4. **Scelta del conduttore**: Se il conduttore ha la possibilità di scegliere tra due porte (entrambe con capre), ne apre una in modo casuale.

Con queste assunzioni, possiamo rispondere alla domanda: **Qual è la probabilità che il giocatore vinca l'auto se decide di cambiare porta?**

Di seguito, esploreremo tre metodi per risolvere il problema di Monty Hall: il diagramma ad albero, l'analisi delle probabilità e una simulazione.

### Metodo 1: Diagramma ad Albero

Il diagramma ad albero è uno strumento utile per visualizzare tutti i possibili esiti di un esperimento probabilistico. Nel caso del problema di Monty Hall, possiamo suddividere il processo in tre fasi:

1. **Posizione dell'auto**: L'auto può trovarsi dietro una delle tre porte (A, B o C), ciascuna con probabilità 1/3.
2. **Scelta del giocatore**: Il giocatore sceglie una porta in modo casuale, indipendentemente dalla posizione dell'auto.
3. **Azione del conduttore**: Il conduttore apre una delle due porte rimanenti, rivelando una capra.

Il diagramma ad albero mostra tutte le possibili combinazioni di questi eventi. Ad esempio, se l'auto è dietro la porta A e il giocatore sceglie la porta B, il conduttore aprirà la porta C (l'unica porta rimanente con una capra).

**Passo 1: Identificare lo spazio campionario**  
Lo spazio campionario è composto da 12 esiti possibili, rappresentati dalle combinazioni di:

- Posizione dell'auto (A, B, C).
- Scelta iniziale del giocatore (A, B, C).
- Porta aperta dal conduttore (una delle due rimanenti con una capra).

Ecco un diagramma ad albero che rappresenta questa situazione:

::: {#fig-monthy-hall-tree}
![](../../figures/monthy-hall-tree.png){width="75%"}

Il diagramma ad albero per il Problema di Monty Hall mostra le probabilità associate a ogni possibile esito. I pesi sugli archi rappresentano la probabilità di seguire quel particolare percorso, dato che ci troviamo nel nodo padre. Ad esempio, se l'auto si trova dietro la porta A, la probabilità che il giocatore scelga inizialmente la porta B è pari a 1/3. La colonna più a destra del diagramma mostra la probabilità di ciascun esito finale. Ogni probabilità di esito è calcolata moltiplicando le probabilità lungo il percorso che parte dalla radice (auto dietro una certa porta) e termina alla foglia (esito finale) (Figura tratta da Lehman, Leighton e Meyer, 2018).
:::

**Passo 2: Definire l'evento di interesse**  
L'evento di interesse è "il giocatore vince cambiando porta". Questo si verifica quando la porta inizialmente scelta dal giocatore non nasconde l'auto, e il giocatore decide di cambiare porta.

Gli esiti che soddisfano questa condizione sono:

- `(Auto A, Scelta B, Apertura C)`
- `(Auto A, Scelta C, Apertura B)`
- `(Auto B, Scelta A, Apertura C)`
- `(Auto B, Scelta C, Apertura A)`
- `(Auto C, Scelta A, Apertura B)`
- `(Auto C, Scelta B, Apertura A)`

Questi esiti sono in totale 6.

**Passo 3: Calcolare le probabilità degli esiti**  
Ogni esito ha una probabilità specifica, calcolata moltiplicando le probabilità lungo il percorso nel diagramma ad albero. 

Esempio di calcolo per l'esito `(Auto A, Scelta B, Apertura C)`:

- La probabilità che l'auto sia dietro la porta A è $\frac{1}{3}$.
- La probabilità che il giocatore scelga la porta B è $\frac{1}{3}$.
- La probabilità che il conduttore apra la porta C (che contiene una capra) è $1$ (poiché il conduttore deve aprire una porta con una capra, e la porta C è l'unica possibile).

La probabilità totale per questo esito è:

$$
P(\text{Auto A, Scelta B, Apertura C}) = \frac{1}{3} \times \frac{1}{3} \times 1 = \frac{1}{9}.
$$

Procedendo in modo simile per tutti gli altri esiti, otteniamo le probabilità per tutti i 12 esiti.

**Passo 4: Calcolare la probabilità dell'evento**  
La probabilità di vincere cambiando porta è la somma delle probabilità degli esiti favorevoli. 

$$
\begin{aligned}
P&(\text{vincere cambiando porta}) = \notag \\
&\quad P(\text{Auto A, Scelta B, Apertura C}) + P(\text{Auto A, Scelta C, Apertura B}) + \notag\\  
&\quad P(\text{Auto B, Scelta A, Apertura C}) + \dots \notag
\end{aligned}
$$

$$
= \frac{1}{9} + \frac{1}{9} + \frac{1}{9} + \frac{1}{9} + \frac{1}{9} + \frac{1}{9} = \frac{6}{9} = \frac{2}{3}.
$$

La probabilità di vincere mantenendo la scelta originale è il complemento:

$$
P(\text{vincere mantenendo la scelta}) = 1 - P(\text{vincere cambiando porta}) = 1 - \frac{2}{3} = \frac{1}{3}.
$$

La conclusione è che il giocatore ha una probabilità di vincere pari a $\frac{2}{3}$ se cambia porta, contro una probabilità di $\frac{1}{3}$ se mantiene la sua scelta iniziale. Cambiare porta è quindi la strategia vincente. 

### Metodo 2: Analisi delle Probabilità

Il problema di Monty Hall può essere chiarito analizzando i tre scenari possibili, immaginando di essere osservatori esterni che sanno cosa si nasconde dietro ogni porta:

1. **Primo scenario**:  

   - Il giocatore sceglie inizialmente la porta con una capra (chiamiamola "capra 1").  
   - Il conduttore apre l'altra porta con la "capra 2".  
   - Se il giocatore cambia porta, vince l'automobile.  

2. **Secondo scenario**:  

   - Il giocatore sceglie inizialmente la porta con l'altra capra ("capra 2").  
   - Il conduttore apre la porta con la "capra 1".  
   - Se il giocatore cambia porta, vince l'automobile.  

3. **Terzo scenario**:  

   - Il giocatore sceglie inizialmente la porta con l'automobile.  
   - Il conduttore apre una delle due porte con una capra (non importa quale).  
   - Se il giocatore cambia porta, perde l'automobile.  

All'inizio del gioco, il giocatore ha:  

- **1/3 di probabilità** di scegliere l'automobile.  
- **2/3 di probabilità** di scegliere una capra.  

Dopo la scelta iniziale, il conduttore apre una porta con una capra, ma questa azione non altera le probabilità iniziali. Il giocatore si trova quindi con due porte chiuse: quella scelta inizialmente e una rimanente.  

- Se il giocatore ha scelto l'automobile inizialmente (1/3 di probabilità), cambiando porta perde.  
- Se il giocatore ha scelto una capra inizialmente (2/3 di probabilità), cambiando porta vince l'automobile.  

In sintesi, cambiando porta, il giocatore ha **2/3 di probabilità** di vincere l'automobile, mentre mantenendo la scelta iniziale ha solo **1/3 di probabilità**. Pertanto, la strategia migliore è cambiare porta per massimizzare le possibilità di vittoria.

### Metodo 3: Simulazione

Per confermare il risultato, possiamo eseguire una simulazione. Ripetendo il gioco migliaia di volte, possiamo confrontare la frequenza con cui il giocatore vince cambiando porta rispetto a quando mantiene la scelta iniziale.

Ecco un esempio di codice in R per la simulazione:

```{r}
set.seed(123)  # Per riproducibilità

porte <- c("capra1", "capra2", "macchina")  # Definizione del gioco
contatore_mantieni <- 0
contatore_cambia <- 0
n <- 10000  # Numero di simulazioni

for (i in 1:n) {
  # Posizione casuale dell'auto
  auto <- sample(porte, 1)
  
  # Scelta iniziale del giocatore
  scelta <- sample(porte, 1)
  
  # Porta aperta dal conduttore (una capra non scelta)
  porte_rimaste <- porte[porte != scelta & porte != auto]
  porta_aperta <- sample(porte_rimaste, 1)
  
  # Porta alternativa
  porta_alternativa <- porte[porte != scelta & porte != porta_aperta]
  
  # Verifica se cambiare porta porta alla vittoria
  if (porta_alternativa == auto) {
    contatore_cambia <- contatore_cambia + 1
  }
  
  # Verifica se mantenere la scelta porta alla vittoria
  if (scelta == auto) {
    contatore_mantieni <- contatore_mantieni + 1
  }
}

cat("Probabilità di vincere mantenendo la scelta:", contatore_mantieni / n, "\n")
cat("Probabilità di vincere cambiando porta:", contatore_cambia / n, "\n")
```

La simulazione conferma che cambiare porta aumenta la probabilità di vincere da 1/3 a 2/3.

In sintesi, il problema di Monty Hall mette in luce in modo eloquente come l'intuizione possa trarci in inganno quando ci confrontiamo con scenari probabilistici. Attraverso l'uso del diagramma ad albero, un'analisi rigorosa delle probabilità e l'esecuzione di simulazioni, abbiamo dimostrato che cambiare porta raddoppia le possibilità di vincita, facendole passare da 1/3 a 2/3. Questo risultato, in apparente contrasto con ciò che potrebbe sembrare intuitivo, costituisce un esempio emblematico dell'importanza di adottare un approccio metodico e matematico nella valutazione delle probabilità, anziché affidarsi esclusivamente a impressioni iniziali che spesso si rivelano fuorvianti.


## Il paradosso di Simpson {#sec-simpson-paradox}

Nel contesto della **probabilità condizionata**, un fenomeno particolarmente interessante e, al tempo stesso, controintuitivo è il **paradosso di Simpson**. Questo paradosso si verifica quando una tendenza osservata in diversi gruppi di dati separati scompare o addirittura si inverte una volta che i gruppi vengono combinati. 

Il paradosso di Simpson evidenzia l'importanza di considerare le **variabili confondenti** e di analizzare i dati con grande attenzione per evitare di trarre conclusioni errate o fuorvianti. È un esempio emblematico di come l'interpretazione dei dati statistici richieda non solo strumenti matematici, ma anche una profonda comprensione del contesto e delle relazioni tra le variabili coinvolte.

Consideriamo il paradosso di Simpson nella forma seguente. Due psicoterapeuti, Rossi e Bianchi, praticano due tipi di terapie: terapia per disturbi d'ansia e coaching per migliorare le prestazioni lavorative. Ogni terapia può avere un esito positivo o negativo. 

I rispettivi bilanci dei due terapeuti sono riportati nelle seguenti tabelle.

**Rossi**

| Tipo di terapia             | Successo | Fallimento |
|-----------------------------|----------|------------|
| Disturbi d'ansia            | 70       | 20         |
| Coaching lavorativo         | 10       | 0          |
| **Totale**                  | 80       | 20         |

**Bianchi**

| Tipo di terapia             | Successo | Fallimento |
|-----------------------------|----------|------------|
| Disturbi d'ansia            | 2        | 8          |
| Coaching lavorativo         | 81       | 9          |
| **Totale**                  | 83       | 17         |

Rossi ha un tasso di successo superiore a Bianchi nella terapia per i disturbi d'ansia: 70 su 90 rispetto a 2 su 10. Anche nel coaching lavorativo, Rossi ha un tasso di successo superiore: 10 su 10 rispetto a 81 su 90. Tuttavia, se aggregiamo i dati dei due tipi di terapia per confrontare i tassi di successo globali, Rossi è efficace in 80 su 100 terapie, mentre Bianchi in 83 su 100: il tasso di successo globale di Bianchi risulta superiore!

Questo fenomeno è un esempio del paradosso di Simpson, dove una tendenza osservata in diversi gruppi si inverte quando i gruppi sono combinati.

Per essere più precisi, possiamo calcolare i tassi di successo per ciascun terapeuta e per ciascun tipo di terapia, oltre al tasso di successo globale.

1. **Rossi**
   - Tasso di successo in terapia per disturbi d'ansia: $\frac{70}{70+20} = \frac{70}{90} \approx 0.778$
   - Tasso di successo in coaching lavorativo: $\frac{10}{10+0} = \frac{10}{10} = 1$
   - Tasso di successo globale: $\frac{70+10}{70+20+10+0} = \frac{80}{100} = 0.8$

2. **Bianchi**
   - Tasso di successo in terapia per disturbi d'ansia: $\frac{2}{2+8} = \frac{2}{10} = 0.2$
   - Tasso di successo in coaching lavorativo: $\frac{81}{81+9} = \frac{81}{90} \approx 0.9$
   - Tasso di successo globale: $\frac{2+81}{2+8+81+9} = \frac{83}{100} = 0.83$

Quello che sta succedendo è che Rossi, presumibilmente a causa della sua reputazione come terapeuta più esperto, sta effettuando un numero maggiore di terapie per disturbi d'ansia, che sono intrinsecamente più complesse e con una probabilità di successo variabile rispetto al coaching lavorativo. Il suo tasso di successo globale è inferiore non a causa di una minore abilità in un particolare tipo di terapia, ma perché una frazione maggiore delle sue terapie riguarda casi più complessi.

L'aggregazione dei dati tra diversi tipi di terapia presenta un quadro fuorviante delle abilità dei terapeuti perché perdiamo l'informazione su quale terapeuta tende a effettuare quale tipo di terapia. Quando sospettiamo la presenza di variabili di confondimento, come ad esempio il tipo di terapia in questo contesto, è fondamentale analizzare i dati in modo disaggregato per comprendere con precisione la dinamica in atto.


## Teorema del Prodotto

Il **Teorema del Prodotto**, noto anche come **teorema della probabilità composta**, **regola moltiplicativa** o **regola della catena**, consente di calcolare la probabilità congiunta di due o più eventi a partire dalle loro probabilità marginali e condizionate. Tale teorema deriva direttamente dalla definizione di probabilità condizionata.

Per due eventi $A$ e $B$, la probabilità congiunta $P(A \cap B)$ può essere espressa tramite la seguente relazione:

$$
P(A \cap B) = P(B) \, P(A \mid B) = P(A) \, P(B \mid A).
$$ {#eq-probcondinv}

Questa formula indica che la probabilità che entrambi gli eventi $A$ e $B$ si verifichino è data dalla probabilità che uno degli eventi si realizzi, moltiplicata per la probabilità che l'altro evento accada, condizionatamente al verificarsi del primo.

È possibile generalizzare questo risultato al caso di $n$ eventi, ovvero alla probabilità congiunta $P(A_1 \cap A_2 \cap \cdots \cap A_n)$ (abbreviata in $P(A_1 A_2 \cdots A_n)$). Questa generalizzazione corrisponde alla regola del prodotto della probabilità:

**Teorema 1.3 (Regola del Prodotto).**  
Siano $A_1, A_2, \dots, A_n$ una sequenza di eventi per cui $P(A_1 \cap A_2 \cap \cdots \cap A_{n-1}) > 0$. Allora:

$$
\begin{align}
P(A_1 \cap A_2 \cap \cdots \cap A_n) &= P(A_1) \, P(A_2 \mid A_1) \, P(A_3 \mid A_1 \cap A_2) \, \cdots \notag\\
& \quad\cdot P(A_n \mid A_1 \cap A_2 \cap \cdots \cap A_{n-1})\notag
\end{align}
$$ {#eq-probcomposte}

In altre parole, per calcolare la probabilità congiunta di $n$ eventi, si procede nel seguente modo:

1. Si considera la probabilità incondizionata del primo evento $P(A_1)$.
2. Si moltiplica per la probabilità del secondo evento, condizionata al verificarsi del primo $P(A_2 \mid A_1)$.
3. Si moltiplica per la probabilità del terzo evento, condizionata al verificarsi dei primi due $P(A_3 \mid A_1 \cap A_2)$.
4. E così via, fino al $n$-esimo evento, la cui probabilità è calcolata condizionata al verificarsi di tutti gli eventi precedenti $P(A_n \mid A_1 \cap A_2 \cap \cdots \cap A_{n-1})$.

::: {#exm-}
**Esempio.**  
Consideriamo quattro eventi $A_1, A_2, A_3, A_4$. La probabilità congiunta si esprime come:

$$
P(A_1 \cap A_2 \cap A_3 \cap A_4) = P(A_1) \cdot P(A_2 \mid A_1) \cdot P(A_3 \mid A_1 \cap A_2) \cdot P(A_4 \mid A_1 \cap A_2 \cap A_3).
$$

In questa espressione:

- $P(A_1)$ rappresenta la probabilità incondizionata del primo evento.
- $P(A_2 \mid A_1)$ è la probabilità del secondo evento dato il verificarsi del primo.
- $P(A_3 \mid A_1 \cap A_2)$ è la probabilità del terzo evento, condizionata al verificarsi sia del primo che del secondo.
- $P(A_4 \mid A_1 \cap A_2 \cap A_3)$ è la probabilità del quarto evento, condizionata al verificarsi dei tre eventi precedenti.
:::

Il Teorema del Prodotto rappresenta uno dei fondamenti teorici più importanti della probabilità e trova applicazioni in numerosi contesti, quali:

- La modellazione di processi sequenziali o temporali.
- La scomposizione di problemi complessi in calcoli più semplici e gestibili.
- La teoria delle reti bayesiane e l’analisi della probabilità condizionata.

Grazie a questo teorema, è possibile affrontare problemi complessi suddividendoli in passaggi progressivi, in cui ogni probabilità condizionata contribuisce alla costruzione della soluzione complessiva in maniera sistematica.

::: {#exm-}
Da un'urna contenente 6 palline bianche e 4 nere si estrae una pallina per volta, senza reintrodurla nell'urna. Indichiamo con $B_i$ l'evento: "esce una pallina bianca alla $i$-esima estrazione" e con $N_i$ l'estrazione di una pallina nera. L'evento: "escono due palline bianche nelle prime due estrazioni" è rappresentato dalla intersezione $\{B_1 \cap B_2\}$ e, per l'@eq-probcondinv, la sua probabilità vale

$$
P(B_1 \cap B_2) = P(B_1)P(B_2 \mid B_1).
$$

$P(B_1)$ vale 6/10, perché nella prima estrazione $\Omega$ è costituito da 10 elementi: 6 palline bianche e 4 nere. La probabilità condizionata $P(B_2 \mid B_1)$ vale 5/9, perché nella seconda estrazione, se è verificato l'evento $B_1$, lo spazio campionario consiste di 5 palline bianche e 4 nere. Si ricava pertanto:

$$
P(B_1 \cap B_2) = \frac{6}{10} \cdot \frac{5}{9} = \frac{1}{3}.
$$

In modo analogo si ha che

$$
P(N_1 \cap N_2) = P(N_1)P(N_2 \mid N_1) = \frac{4}{10} \cdot \frac{3}{9} = \frac{4}{30}.
$$

Se l'esperimento consiste nell'estrazione successiva di 3 palline, la probabilità che queste siano tutte bianche, per l'@eq-probcomposte, vale

$$
\begin{aligned}
P(B_1 \cap B_2 \cap B_3) &=P(B_1)P(B_2 \mid B_1)P(B_3 \mid B_1 \cap B_2) \notag\\ 
&=\frac{6}{10}\cdot\frac{5}{9} \cdot\frac{4}{8} \notag\\ 
&= \frac{1}{6}.
\end{aligned}
$$

La probabilità dell'estrazione di tre palline nere è invece:

$$
\begin{aligned}
P(N_1 \cap N_2 \cap N_3) &= P(N_1)P(N_2 \mid N_1)P(N_3 \mid N_1 \cap N_2)\notag\\ 
&= \frac{4}{10} \cdot \frac{3}{9} \cdot \frac{2}{8} \notag\\ 
&= \frac{1}{30}.\notag
\end{aligned}
$$

:::


## Il Teorema della Probabilità Totale

Il **teorema della probabilità totale** (o **teorema delle partizioni**), che abbiamo già discusso nel capitolo precedente, può essere riformulato nei termini della probabilità condizionata. Il teorema afferma che, dato uno spazio campionario $\Omega$ suddiviso in una partizione di $n$ eventi mutualmente esclusivi (cioè non sovrapposti) e tali che la loro unione formi $\Omega$, è possibile calcolare la probabilità di un qualsiasi evento $E \subseteq \Omega$ sommando la probabilità di $E$ su ciascun sottoinsieme della partizione, pesata per la probabilità del sottoinsieme.

### Definizione 

Siano $H_1, H_2, \dots, H_n$ eventi che costituiscono una partizione dello spazio campionario $\Omega$, ossia:

1. $H_i \cap H_j = \varnothing$ per $i \neq j$ (mutualmente esclusivi),
2. $\bigcup_{i=1}^n H_i = \Omega$ (copertura completa dello spazio campionario).

Allora, per ogni evento $E \subseteq \Omega$, la probabilità di $E$ è data da:

$$
P(E) = \sum_{i=1}^n P(E \mid H_i)P(H_i),
$$ {#eq-prob-tot}

dove:

- $P(E \mid H_i)$ è la probabilità condizionata di $E$ dato che si è verificato l'evento $H_i$,
- $P(H_i)$ è la probabilità dell'evento $H_i$.

Il teorema afferma dunque che la probabilità di un evento $E$ può essere calcolata considerando il contributo di ciascun sottoinsieme della partizione. Ogni termine nella somma rappresenta la probabilità di $E$ "passando" attraverso un sottoinsieme $H_i$, pesata per la probabilità che $H_i$ si verifichi.

Il teorema della probabilità totale è cruciale in molte applicazioni della probabilità, in particolare:

- **Teorema di Bayes**: Fornisce il denominatore necessario per normalizzare la probabilità condizionata e garantire che la distribuzione a posteriori sia valida.
- **Problemi con partizioni**: È utile per calcolare la probabilità di un evento $E$ quando si conoscono le probabilità condizionate $P(E \mid H_i)$ e le probabilità dei sottoinsiemi $P(H_i)$.

Nella sua forma più semplice, l'applicazione del teorema si basa su una partizione dello spazio campionario $\Omega$ in due sottoinsiemi disgiunti, $H_1$ e $H_2$.

::: {#fig-bayes}
![](../../figures/bayes_theorem.png){width="50%"}

Partizione dello spazio campionario in due sottoinsiemi.
:::

La probabilità di un evento $E$ può essere calcolata come

$$
P(E) = P(E \cap H_1) + P(E \cap H_2),
$$

ovvero

$$
P(E) = P(E \mid H_1) P(H_1) + P(E \mid H_2) P(H_2).
$$

In sintesi, l'@eq-prob-tot ci consente di calcolare probabilità complesse sfruttando partizioni dello spazio campionario. È particolarmente utile quando $P(E \mid H_i)$ e $P(H_i)$ sono disponibili, consentendo una valutazione della probabilità di $E$.

::: {#exm-}

Abbiamo tre urne, ciascuna delle quali contiene 100 palline:

-   Urna 1: 75 palline rosse e 25 palline blu,
-   Urna 2: 60 palline rosse e 40 palline blu,
-   Urna 3: 45 palline rosse e 55 palline blu.

Una pallina viene estratta a caso da un'urna anch'essa scelta a caso. Qual è la probabilità che la pallina estratta sia di colore rosso?

Sia $R$ l'evento "la pallina estratta è rossa" e sia $U_i$ l'evento che corrisponde alla scelta dell'$i$-esima urna. Sappiamo che

$$
P(R \mid U_1) = 0.75, \quad P(R \mid U_2) = 0.60, \quad P(R \mid U_3) = 0.45.
$$

Gli eventi $U_1$, $U_2$ e $U_3$ costituiscono una partizione dello spazio campione in quanto $U_1$, $U_2$ e $U_3$ sono eventi mutualmente esclusivi ed esaustivi, ovvero $P(U_1 \cup U_2 \cup U_3) = 1.0$. In base al teorema della probabilità totale, la probabilità di estrarre una pallina rossa è dunque

$$
\begin{split}
P(R) &= P(R \mid U_1)P(U_1) + P(R \mid U_2)P(U_2) + P(R \mid U_3)P(U_3) \\
&= 0.75 \cdot \frac{1}{3}+0.60 \cdot \frac{1}{3}+0.45 \cdot \frac{1}{3} \\
&=0.60.
\end{split}
$$

:::

## Indipendenza e Probabilità Condizionata

L’indipendenza tra due eventi $A$ e $B$ può essere interpretata intuitivamente attraverso la probabilità condizionata. Due eventi sono indipendenti se il verificarsi di uno non influenza la probabilità di verificarsi dell’altro. In altre parole, conoscere che $B$ è accaduto non modifica la probabilità di $A$, e viceversa.

Questa relazione può essere formalizzata con le seguenti equazioni:

$$
P(A \mid B) = \frac{P(A \cap B)}{P(B)} = P(A),
$$

$$
P(B \mid A) = \frac{P(A \cap B)}{P(A)} = P(B).
$$

Pertanto, $A$ e $B$ sono indipendenti se e solo se:

$$
P(A \mid B) = P(A),
$$

$$
P(B \mid A) = P(B).
$$

Queste condizioni significano che la probabilità di $A$ non cambia, indipendentemente dal fatto che $B$ sia accaduto, e lo stesso vale per $B$.

<!-- ### Un'Altra Forma di Indipendenza -->

<!-- L'indipendenza può essere espressa anche in termini di probabilità congiunta: -->

<!-- $$ -->
<!-- P(A \cap B) = P(A) P(B). -->
<!-- $$ -->

<!-- Se questa condizione è soddisfatta, possiamo affermare che $A$ e $B$ sono indipendenti. Questo approccio si basa sull'idea che, per eventi indipendenti, la probabilità che si verifichino entrambi è semplicemente il prodotto delle loro probabilità individuali. -->

### Indipendenza di Tre Eventi

La definizione di indipendenza si estende naturalmente a tre eventi $A$, $B$, e $C$, ma con condizioni aggiuntive. Tre eventi sono **indipendenti** se:

1. Ogni coppia di eventi è indipendente:

   $$
   \begin{align}
   P(A \cap B) &= P(A) P(B), \\
   P(A \cap C) &= P(A) P(C), \\
   P(B \cap C) &= P(B) P(C).
   \end{align}
   $$

2. La probabilità congiunta di tutti e tre gli eventi è uguale al prodotto delle loro probabilità individuali:

   $$
   P(A \cap B \cap C) = P(A) P(B) P(C).
   $$

Le prime tre condizioni verificano l’indipendenza a coppie (indipendenza a due a due), mentre l’ultima condizione garantisce che i tre eventi siano **completamente indipendenti**. È importante notare che l’indipendenza a due a due non implica necessariamente l’indipendenza completa: per essere indipendenti nel senso completo, tutte e quattro le condizioni devono essere soddisfatte.

In sintesi, l’indipendenza tra eventi implica che il verificarsi di uno di essi non fornisce alcuna informazione sulla probabilità del verificarsi degli altri. Nel caso di due eventi, questa proprietà si traduce nell’invarianza della probabilità condizionata. Per tre o più eventi, l’indipendenza richiede sia l’indipendenza a coppie sia la condizione più forte sull’intersezione di tutti gli eventi.

Questi concetti sono fondamentali nella probabilità e nella statistica, poiché semplificano molti calcoli e forniscono una base per modelli più complessi.

::: {#exm-}

Consideriamo un esempio utilizzando un mazzo di 52 carte. Ogni seme contiene 13 carte e ci sono 4 regine in totale. Definiamo i seguenti eventi:

- Evento A: pescare una carta di picche,
- Evento B: pescare una regina.

**Probabilità con un mazzo completo**

In un mazzo completo, la probabilità di pescare una carta di picche ($P(A)$) è $\frac{13}{52} = \frac{1}{4}$, poiché ci sono 13 picche su 52 carte totali. La probabilità di pescare una regina ($P(B)$) è $\frac{4}{52} = \frac{1}{13}$, poiché ci sono 4 regine su 52 carte.

Ora consideriamo la probabilità congiunta di pescare la regina di picche ($P(AB)$). Poiché esiste solo una regina di picche nel mazzo, la probabilità di pescare questa specifica carta è $\frac{1}{52}$.

Secondo la definizione di indipendenza, se gli eventi $A$ e $B$ sono indipendenti, allora:

$$ P(AB) = P(A)P(B) $$

Calcoliamo $P(A)P(B)$:

$$ P(A)P(B) = \left( \frac{1}{4} \right) \left( \frac{1}{13} \right) = \frac{1}{52} $$

Poiché $P(AB) = \frac{1}{52}$ è uguale a $P(A)P(B)$, possiamo affermare che gli eventi $A$ e $B$ sono indipendenti con un mazzo completo di 52 carte.

**Probabilità dopo la rimozione di una carta**

Consideriamo ora un mazzo con una carta in meno, ad esempio il due di quadri, riducendo il numero totale di carte a 51. Ricalcoliamo le probabilità con questo mazzo ridotto:

La probabilità di pescare la regina di picche ($P(AB)$) è ora $\frac{1}{51}$, poiché ci sono 51 carte nel mazzo.

Ricalcoliamo anche $P(A)$ e $P(B)$:

- $P(A)$ diventa $\frac{13}{51}$, poiché ci sono ancora 13 picche, ma su 51 carte.
- $P(B)$ diventa $\frac{4}{51}$, poiché ci sono ancora 4 regine, ma su 51 carte.

Ora calcoliamo il prodotto $P(A)P(B)$ con queste nuove probabilità:

$$ P(A)P(B) = \left( \frac{13}{51} \right) \left( \frac{4}{51} \right) = \frac{52}{2601} $$

Confrontiamo $P(AB)$ e $P(A)P(B)$:

$$ \frac{1}{51} \neq \frac{52}{2601} $$

Poiché $\frac{1}{51} \neq \frac{52}{2601}$, gli eventi $A$ e $B$ non sono più indipendenti dopo la rimozione del due di quadri.

Questo esempio mostra come l'indipendenza tra due eventi dipenda dal contesto. Con un mazzo completo, i due eventi sono indipendenti. Tuttavia, rimuovendo una carta dal mazzo, le probabilità cambiano e gli eventi non sono più indipendenti. Questo evidenzia l'importanza di considerare la composizione e le condizioni iniziali quando si analizzano probabilità e indipendenza. Modifiche nella composizione del mazzo possono alterare le probabilità, influenzando le relazioni di indipendenza tra eventi specifici.
:::

## Riflessioni Conclusive

La probabilità condizionata è uno dei concetti fondamentali della statistica, poiché fornisce il quadro teorico necessario per comprendere l'indipendenza statistica e molte altre relazioni tra eventi e variabili. 

Un punto chiave è che l'indipendenza implica l'assenza di una **associazione** tra due variabili. Nei capitoli successivi esploreremo strumenti per misurare la correlazione correlazione, ovvero la presenza e l'intensità di una relazione **lineare** tra di esse.

La probabilità condizionata ha inoltre permesso di riformulare la legge della probabilità totale, che consente di scomporre probabilità complesse utilizzando partizioni dello spazio campionario. Questa legge si rivela cruciale per il teorema di Bayes, uno degli strumenti cardine dell'inferenza statistica.

In particolare, nel contesto dell'inferenza bayesiana, il condizionamento assume un ruolo fondamentale. Grazie a questo principio, è possibile aggiornare continuamente le credenze o le incertezze riguardo a ipotesi, integrando nuove informazioni man mano che diventano disponibili. Questa capacità di adattamento rende l'inferenza bayesiana uno strumento estremamente flessibile e potente, capace di modellare situazioni complesse e dinamiche.

In sintesi, la probabilità condizionata non solo è essenziale per comprendere l'indipendenza statistica, ma costituisce anche la base di metodi inferenziali avanzati, come l'inferenza bayesiana. Attraverso di essa, possiamo costruire modelli che evolvono e migliorano con l'aggiunta di nuove informazioni, rendendo l'analisi statistica uno strumento dinamico e versatile per interpretare il mondo reale.

## Informazioni sull'Ambiente di Sviluppo {.unnumbered} 

```{r}
sessionInfo()
```

## Bibliografia {.unnumbered}

