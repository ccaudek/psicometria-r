[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Psicometria",
    "section": "",
    "text": "Informazioni Generali",
    "crumbs": [
      "Informazioni Generali"
    ]
  },
  {
    "objectID": "index.html#informazioni-generali",
    "href": "index.html#informazioni-generali",
    "title": "Psicometria",
    "section": "",
    "text": "Anno Accademico: 2024-2025\nCodice Insegnamento: B000286 (coorte L-Z)\nOrario:\nüìÖ Luned√¨ e Marted√¨ (8:30-10:30)\nüìÖ Gioved√¨ (11:30-13:30)\nüìç Plesso Didattico La Torretta",
    "crumbs": [
      "Informazioni Generali"
    ]
  },
  {
    "objectID": "index.html#panoramica-del-corso",
    "href": "index.html#panoramica-del-corso",
    "title": "Psicometria",
    "section": "Panoramica del Corso",
    "text": "Panoramica del Corso\nIl corso offre una formazione teorico-pratica nell‚Äôanalisi dei dati psicologici, con particolare attenzione alle applicazioni in R. Vengono affrontati temi come analisi descrittiva, esplorazione dei dati, flusso di lavoro, organizzazione di progetti e modelli statistici di base, sia bayesiani che frequentisti. Grande enfasi √® posta sulle buone pratiche di Open Science, promuovendo trasparenza e riproducibilit√† nelle analisi.\nIl corso integra questi argomenti in un percorso didattico che combina lezioni teoriche, esercitazioni pratiche e momenti di riflessione critica. Gli studenti saranno cos√¨ preparati ad applicare l‚Äôanalisi dei dati sia in contesti accademici che pratici.\n\nüìö Syllabus dettagliato\nüìÖ Calendario delle lezioni",
    "crumbs": [
      "Informazioni Generali"
    ]
  },
  {
    "objectID": "index.html#licenza-duso",
    "href": "index.html#licenza-duso",
    "title": "Psicometria",
    "section": "Licenza d‚ÄôUso",
    "text": "Licenza d‚ÄôUso\n\n\n\nCC BY 4.0\n\n\nI materiali sono rilasciati con licenza CC BY 4.0. √à consentito qualsiasi utilizzo previa attribuzione. Per usi commerciali o derivati, consultare le linee guida complete.",
    "crumbs": [
      "Informazioni Generali"
    ]
  },
  {
    "objectID": "prefazione.html",
    "href": "prefazione.html",
    "title": "Prefazione",
    "section": "",
    "text": "Bibliografia\nCome possiamo migliorare l‚Äôanalisi dei dati psicologici per renderla pi√π affidabile e robusta? √à possibile affrontare questa sfida semplicemente applicando una serie di algoritmi o procedure standard? L‚Äôanalisi dei dati in psicologia pu√≤ davvero essere ridotta a un insieme di ‚Äúricette‚Äù preconfezionate (McElreath, 2020)?\nQueste domande ci portano a riflettere sulla natura stessa dell‚Äôanalisi dei dati psicologici. A differenza di ci√≤ che suggerisce l‚Äôapproccio frequentista del test dell‚Äôipotesi nulla, l‚Äôanalisi dei dati non √® una disciplina che si esaurisce con l‚Äôapplicazione meccanica di metodi predefiniti. Anzi, considerare l‚Äôanalisi dei dati come un insieme di procedure automatiche contribuisce a uno dei problemi pi√π gravi della psicologia contemporanea: la crisi della replicabilit√† dei risultati (Korbmacher et al., 2023).\nMa perch√© la replicabilit√† √® cos√¨ cruciale? Se i risultati delle ricerche psicologiche non sono replicabili, significa che la nostra comprensione dei fenomeni psicologici √® superficiale e inaffidabile. Questo non √® solo un problema teorico o accademico; ha implicazioni dirette sulle applicazioni pratiche della psicologia. Se le basi scientifiche sono incerte, anche le strategie di intervento psicologico rischiano di essere inefficaci o addirittura dannose (Funder et al., 2014; Ioannidis, 2019; Shrout & Rodgers, 2018; Tackett et al., 2019).\nPerch√© le pratiche di analisi dei dati derivanti dal frequentismo potrebbero contribuire a questa crisi? In che modo gli incentivi accademici influenzano la qualit√† della ricerca psicologica? E, soprattutto, quali alternative abbiamo per migliorare l‚Äôaffidabilit√† e la validit√† delle nostre conclusioni?\nL‚Äôanalisi bayesiana emerge come una delle proposte per superare i limiti dell‚Äôapproccio frequentista (Gelman et al., 1995). Tuttavia, √® sufficiente abbandonare l‚Äôinferenza frequentista per risolvere i problemi della psicologia? Come possiamo integrare metodi robusti e flessibili, come quelli bayesiani, con una comprensione pi√π approfondita e trasparente dei fenomeni psicologici?\nIn questo corso, esploreremo queste domande, cercando di identificare le ‚Äúbuone pratiche‚Äù dell‚Äôanalisi dei dati psicologici. Discuteremo i limiti delle metodologie attuali, esamineremo le cause sottostanti della crisi della replicabilit√† e valuteremo come l‚Äôadozione di metodi avanzati, come l‚Äôinferenza bayesiana e la modellazione causale, possa offrire soluzioni efficaci (Oberauer & Lewandowsky, 2019; Wagenmakers et al., 2018; Yarkoni, 2022). Il nostro obiettivo √® fornire una visione critica e costruttiva, che non solo identifichi le sfide della ricerca psicologica, ma proponga anche percorsi concreti per migliorare la qualit√† e l‚Äôaffidabilit√† della scienza psicologica.",
    "crumbs": [
      "Prefazione"
    ]
  },
  {
    "objectID": "prefazione.html#bibliografia",
    "href": "prefazione.html#bibliografia",
    "title": "Prefazione",
    "section": "",
    "text": "Funder, D. C., Levine, J. M., Mackie, D. M., Morf, C. C., Sansone, C., Vazire, S., & West, S. G. (2014). Improving the dependability of research in personality and social psychology: Recommendations for research and educational practice. Personality and Social Psychology Review, 18(1), 3‚Äì12.\n\n\nGelman, A., Carlin, J. B., Stern, H. S., & Rubin, D. B. (1995). Bayesian data analysis. Chapman; Hall/CRC.\n\n\nIoannidis, J. P. (2019). What have we (not) learnt from millions of scientific papers with P values? The American Statistician, 73(sup1), 20‚Äì25.\n\n\nKorbmacher, M., Azevedo, F., Pennington, C. R., Hartmann, H., Pownall, M., Schmidt, K., Elsherif, M., Breznau, N., Robertson, O., Kalandadze, T., et al. (2023). The replication crisis has led to positive structural, procedural, and community changes. Communications Psychology, 1(1), 3.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nOberauer, K., & Lewandowsky, S. (2019). Addressing the theory crisis in psychology. Psychonomic Bulletin & Review, 26, 1596‚Äì1618.\n\n\nShrout, P. E., & Rodgers, J. L. (2018). Psychology, science, and knowledge construction: Broadening perspectives from the replication crisis. Annual Review of Psychology, 69(1), 487‚Äì510.\n\n\nTackett, J. L., Brandes, C. M., King, K. M., & Markon, K. E. (2019). Psychology‚Äôs replication crisis and clinical psychological science. Annual Review of Clinical Psychology, 15(1), 579‚Äì604.\n\n\nWagenmakers, E.-J., Marsman, M., Jamil, T., Ly, A., Verhagen, J., Love, J., Selker, R., Gronau, Q. F., ≈†mƒ±ÃÅra, M., Epskamp, S., et al. (2018). Bayesian inference for psychology. Part I: Theoretical advantages and practical ramifications. Psychonomic Bulletin & Review, 25, 35‚Äì57.\n\n\nYarkoni, T. (2022). The generalizability crisis. Behavioral and Brain Sciences, 45, e1.",
    "crumbs": [
      "Prefazione"
    ]
  },
  {
    "objectID": "chapters/key_notions/introduction_key_notions.html",
    "href": "chapters/key_notions/introduction_key_notions.html",
    "title": "Fondamenti",
    "section": "",
    "text": "La data science √® un campo che si sviluppa all‚Äôintersezione tra la statistica e l‚Äôinformatica. La statistica fornisce una serie di metodologie per analizzare i dati e ottenere informazioni significative, mentre l‚Äôinformatica si occupa dello sviluppo di software e strumenti per implementare tali metodologie. In questa sezione della dispensa, approfondiremo alcuni concetti fondamentali della statistica e della misurazione psicologica. Considereremo anche in termini generali quali sono gli obiettivi e i limiti dell‚Äôanalisi dei dati psicologici.",
    "crumbs": [
      "Fondamenti"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html",
    "href": "chapters/key_notions/01_key_notions.html",
    "title": "1¬† Concetti chiave",
    "section": "",
    "text": "1.1 Introduzione\nNella ricerca scientifica, la formulazione di risposte a specifiche domande di indagine avviene attraverso l‚Äôapplicazione di metodologie rigorose e l‚Äôesecuzione di osservazioni accurate e controllate. Le informazioni raccolte mediante diverse tecniche di indagine‚Äîcome ricerche sul campo, indagini campionarie e protocolli sperimentali‚Äîvengono definite con il termine tecnico di dati. Questo capitolo introduce i principi fondamentali dell‚Äôanalisi dei dati, concentrandosi sia sulle caratteristiche dei dati stessi sia sui metodi di raccolta.\nL‚Äôanalisi dei dati permette di sintetizzare grandi quantit√† di informazioni e di verificare le previsioni avanzate dalle teorie. Tuttavia, senza una teoria che dia significato ai dati, le osservazioni rimangono mere descrizioni prive di un contesto esplicativo. √à attraverso l‚Äôintegrazione tra dati e teoria che si raggiunge una comprensione profonda dei fenomeni e si favorisce l‚Äôavanzamento scientifico [es., Wertheimer (1880‚Äì1943), scoperta del movimento-\\(\\phi\\) e nascita del movimento della Gestalt; Steinman et al. (2000)].",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#introduzione",
    "href": "chapters/key_notions/01_key_notions.html#introduzione",
    "title": "1¬† Concetti chiave",
    "section": "",
    "text": "Statistica\n\n\n\nIl termine ‚Äústatistica‚Äù pu√≤ assumere diversi significati a seconda del contesto:\n\nPrimo significato: La statistica √® una scienza che si occupa dello studio e dell‚Äôapplicazione di metodi per la raccolta, organizzazione, analisi, interpretazione e presentazione dei dati.\nSecondo significato: Il termine si riferisce a una misura o valore numerico calcolato a partire da un campione di dati, come la media campionaria, la deviazione standard campionaria o il coefficiente di correlazione campionario.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#la-spiegazione-scientifica",
    "href": "chapters/key_notions/01_key_notions.html#la-spiegazione-scientifica",
    "title": "1¬† Concetti chiave",
    "section": "1.2 La Spiegazione Scientifica",
    "text": "1.2 La Spiegazione Scientifica\nLa scienza non si limita a descrivere o prevedere i fenomeni: il suo obiettivo principale √® spiegare il perch√© degli eventi, offrendo una comprensione approfondita delle cause e dei meccanismi che li regolano. La spiegazione scientifica √® cruciale per costruire teorie capaci non solo di descrivere e prevedere, ma anche di chiarire le dinamiche causali e le connessioni tra i fenomeni, contribuendo a un controllo pi√π consapevole e informato su di essi.\nConsideriamo, ad esempio, il rapporto tra il background familiare e il rendimento scolastico. Numerose ricerche evidenziano una forte correlazione tra il livello di istruzione dei genitori e il successo accademico dei figli. Una prospettiva puramente descrittiva potrebbe limitarsi a constatare che: ‚ÄúGli studenti provenienti da famiglie con basso livello di istruzione hanno minori probabilit√† di conseguire un titolo universitario‚Äù. Tuttavia, la vera sfida scientifica consiste nell‚Äôandare oltre questa previsione, ponendosi domande pi√π profonde:\n\nquali meccanismi causali determinano questa disparit√†?\n\nquali interventi possono efficacemente ridurre tali disuguaglianze?\n\nPer superare il livello di semplice previsione, la ricerca deve identificare i fattori causali alla base del fenomeno, in modo da comprendere come l‚Äôazione su questi fattori possa modificare gli esiti. Nel caso dell‚Äôesempio sul rapporto tra background familiare e rendimento scolastico, ci√≤ implica comprendere, ad esempio:\n\nse e in che modo il sostegno finanziario possa favorire il percorso degli studenti svantaggiati;\nquali politiche educative possano produrre effetti positivi sul lungo termine;\ncome i meccanismi sociali e individuali influenzino il processo educativo.\n\nAcquisire una conoscenza approfondita dei meccanismi causali permette di andare oltre la semplice previsione, rendendo possibile la progettazione di interventi mirati e strategici che possano realmente incidere sui fenomeni in modo efficace e duraturo.\n\n1.2.1 Elementi Fondamentali della Spiegazione Scientifica\nLa filosofia della scienza identifica tre componenti fondamentali di una spiegazione scientifica:\n\nExplanandum\n√à il fenomeno che desideriamo comprendere, ovvero ci√≤ di cui cerchiamo le cause o i meccanismi. Un esempio: ‚ÄúGli studenti con alti livelli di ansia da prestazione ottengono punteggi pi√π bassi nei test scolastici rispetto ai loro pari.‚Äù\nExplanans\n√à l‚Äôinsieme dei fattori che spiegano il fenomeno. Nel caso dell‚Äôansia da prestazione, un possibile explanans potrebbe essere: ‚ÄúL‚Äôansia danneggia la concentrazione e la memoria di lavoro, influendo negativamente sulla performance nei test.‚Äù\nLegame esplicativo\nComprende i principi o i meccanismi che dimostrano come l‚Äôexplanans produca l‚Äôexplanandum. Seguendo l‚Äôesempio precedente: ‚ÄúLivelli elevati di ansia innescano il sistema nervoso simpatico, aumentando lo stress fisiologico e riducendo l‚Äôefficienza dei processi cognitivi necessari per compiti complessi.‚Äù\n\nQuesti tre elementi si combinano all‚Äôinterno di modelli scientifici, che costituiscono le strutture teoriche e metodologiche impiegate per formulare e verificare spiegazioni. In psicologia, tali modelli includono:\n\nIl fenomeno da spiegare (ad es. le prestazioni scolastiche).\n\nI fattori che lo influenzano (ad es. ansia, regolazione emotiva).\n\nI meccanismi sottostanti che collegano cause ed effetti (ad es. attivazione fisiologica, memoria di lavoro compromessa).\n\nUn modello psicologico sull‚Äôansia da prestazione, ad esempio, potrebbe considerare la relazione tra livello di ansia percepita, capacit√† di regolazione emotiva e memoria di lavoro. A differenza di modelli esclusivamente descrittivi o predittivi, i modelli esplicativi rispondono a domande causali: non si limitano ad attestare che ansia e prestazioni sono correlate, ma mostrano come e perch√© l‚Äôansia riduca il rendimento. Inoltre, tali modelli suggeriscono strategie d‚Äôintervento per attenuare l‚Äôeffetto dell‚Äôansia, come il potenziamento della regolazione emotiva o l‚Äôuso di tecniche di gestione dello stress.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#modelli-psicologici",
    "href": "chapters/key_notions/01_key_notions.html#modelli-psicologici",
    "title": "1¬† Concetti chiave",
    "section": "1.3 Modelli Psicologici",
    "text": "1.3 Modelli Psicologici\n\n\n\n\n\n\nUn modello √® una rappresentazione concettuale ‚Äì spesso supportata da formalismi matematici ‚Äì di un fenomeno reale, basata su un insieme di equazioni e ipotesi che descrivono le relazioni tra variabili e la struttura probabilistica sottostante. L‚Äôobiettivo √® coglierne gli aspetti essenziali senza includere ogni dettaglio superfluo, formulando predizioni quantitative che possano essere verificate empiricamente. Poich√© spesso esistono molteplici modelli in grado di spiegare lo stesso fenomeno, il compito della ricerca consiste nel selezionare quello che meglio descrive i dati e soddisfa criteri di validit√†, accuratezza e parsimonia.\n\n\n\nI modelli psicologici, in particolare, sono strumenti teorici finalizzati a descrivere, spiegare e prevedere il comportamento umano e i processi mentali. Un modello ben costruito dovrebbe possedere le seguenti caratteristiche:\n\nCoerenza descrittiva\nIl modello deve fornire una rappresentazione logica e coerente del fenomeno, includendo tutti gli elementi chiave del processo psicologico e organizzando le osservazioni in una struttura interpretativa chiara.\nCapacit√† predittiva\nDeve essere in grado di formulare previsioni verificabili e di produrre ipotesi testabili sulla base dei dati raccolti, permettendo cos√¨ di valutare la validit√† del modello.\nSupporto empirico\nLe previsioni e le ipotesi del modello vanno confrontate con l‚Äôevidenza empirica, ottenuta attraverso ricerche sistematiche e rigorose. I dati devono corroborare le relazioni proposte dal modello.\nFalsificabilit√†\nIl modello deve poter essere sottoposto a verifica empirica e, all‚Äôoccorrenza, smentito. Se emergono osservazioni in conflitto con le sue previsioni, il modello deve essere revisionato o sostituito.\nParsimonia\nLa spiegazione deve risultare semplice e lineare, includendo solo gli elementi indispensabili per rendere conto del fenomeno. Assunzioni superflue o ridondanti ne riducono la robustezza.\nGeneralizzabilit√†\nIl modello dovrebbe poter essere esteso a contesti e situazioni diverse, superando i limiti di specifiche condizioni sperimentali o campioni ristretti.\nUtilit√† pratica\nDovrebbe offrire linee guida concrete per l‚Äôapplicazione nel mondo reale, ad esempio negli interventi clinici, nei programmi di prevenzione o nelle terapie, cos√¨ da avere un impatto positivo sugli individui e sulla societ√†.\n\nUno degli ostacoli maggiori nella costruzione di modelli in psicologia √® la natura soggettiva, dinamica e variabile dell‚Äôesperienza umana. √à quindi necessario bilanciare la precisione teorica (spesso supportata da formalizzazioni matematiche o computazionali) con la flessibilit√† necessaria a catturare l‚Äôeterogeneit√† dei fenomeni psicologici. A questo si aggiungono i vincoli etici della ricerca sull‚Äôessere umano e le potenziali ricadute sociali dei risultati.\nL‚Äôanalisi quantitativa dei dati gioca un ruolo centrale nella validazione dei modelli psicologici: mediante metodologie statistiche e computazionali avanzate, i ricercatori possono verificare se le predizioni di un modello trovano riscontro nei dati empirici e se tali predizioni si mantengono valide in contesti diversi. Questo processo non solo consolida la comprensione del fenomeno, ma consente anche di anticipare e, in alcune circostanze, influenzare il comportamento e i processi mentali. Un modello rigorosamente formulato e testabile diviene quindi un potente strumento per lo sviluppo di interventi efficaci e il progresso teorico.\n\n1.3.1 Rappresentare i Fenomeni per Ragionare e Comunicare\nLa spiegazione scientifica non si limita a far luce sui meccanismi causali, ma fornisce anche un linguaggio formale per analizzare e condividere conoscenze sui fenomeni. In psicologia, i modelli scientifici costituiscono strumenti fondamentali per descrivere i processi attraverso variabili, funzioni e parametri, offrendo una struttura che facilita l‚Äôindividuazione di relazioni e propriet√† essenziali. Un modello efficace semplifica la complessit√† del fenomeno, agevolando sia la comunicazione tra studiosi sia la comprensione intuitiva.\nInoltre, i modelli non si limitano a organizzare le informazioni esistenti: stimolano anche l‚Äôemergere di nuove ipotesi di ricerca, promuovono collegamenti tra concetti apparentemente lontani e consentono di trasferire conoscenze tra discipline, ampliando cos√¨ l‚Äôorizzonte dell‚Äôindagine scientifica.\n\n\n1.3.2 Il Ruolo dell‚ÄôAnalisi dei Dati\nL‚Äôanalisi dei dati √® parte integrante del metodo scientifico e, in psicologia, assolve due funzioni primarie:\n\nSemplificare e sintetizzare informazioni complesse\nAttraverso statistiche descrittive, rappresentazioni grafiche e altre tecniche di sintesi, l‚Äôanalisi dei dati aiuta a individuare schemi, tendenze e anomalie. Questo passaggio √® essenziale per comprendere le differenze tra individui o gruppi e per formulare ipotesi di ricerca pi√π mirate.\nValutare le predizioni dei modelli\nConfrontando i dati raccolti con le previsioni teoriche, si misura la validit√† di un modello. Tale confronto √® indispensabile per confermare, raffinare o rivedere le ipotesi di partenza, orientando cos√¨ il progresso della conoscenza scientifica.\n\nTuttavia, limitarsi alla ricerca di correlazioni o di pattern nei dati, senza un solido quadro teorico, non basta a comprendere pienamente il fenomeno. Risultati empirici privi di spiegazioni causali rimangono frammentari. Per questo motivo, integrare i dati in un modello teorico esplicativo √® cruciale: si possono cos√¨ proporre meccanismi causali, identificare relazioni e avanzare nuove ipotesi di ricerca.\n\n\n1.3.3 Carattere Multidisciplinare dell‚ÄôAnalisi dei Dati\nPer rispondere alle complesse domande poste in psicologia, l‚Äôanalisi dei dati si fonda sull‚Äôintegrazione di pi√π discipline: statistica, teoria della probabilit√† e informatica. Ciascuna offre contributi indispensabili per affrontare la complessit√† dei processi psicologici:\n\nStatistica\nFornisce tecniche per la raccolta, l‚Äôorganizzazione e l‚Äôinterpretazione dei dati, consentendo di riassumere le informazioni, individuare pattern significativi e valutare empiricamente le ipotesi dei modelli psicologici.\nTeoria della probabilit√†\nCostituisce la base matematica della statistica e della modellazione scientifica, offrendo strumenti per quantificare l‚Äôincertezza, descrivere la variabilit√† delle osservazioni e costruire modelli predittivi rigorosi.\nInformatica\nContribuisce con strumenti per la gestione, l‚Äôanalisi e la visualizzazione di grandi quantit√† di dati, nonch√© per l‚Äôimplementazione di modelli computazionali sofisticati. Questi modelli si rivelano fondamentali nel simulare e testare dinamiche dei processi psicologici.\n\nLa natura multidisciplinare dell‚Äôanalisi dei dati rispecchia l‚Äôesigenza di competenze diverse per comprendere e modellizzare i fenomeni psicologici in modo rigoroso. L‚Äôapproccio quantitativo e computazionale ai modelli non si limita a descrivere e interpretare i dati, ma consente di formulare predizioni precise e sottoponibili a verifica, contribuendo cos√¨ all‚Äôavanzamento della psicologia come scienza.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#concetti-chiave-nellanalisi-dei-dati",
    "href": "chapters/key_notions/01_key_notions.html#concetti-chiave-nellanalisi-dei-dati",
    "title": "1¬† Concetti chiave",
    "section": "1.4 Concetti Chiave nell‚ÄôAnalisi dei Dati",
    "text": "1.4 Concetti Chiave nell‚ÄôAnalisi dei Dati\nPer condurre un‚Äôanalisi dei dati efficace, √® fondamentale comprendere alcuni concetti chiave che guidano il processo di indagine, dall‚Äôidentificazione del fenomeno alla formulazione di inferenze.\n\n1.4.1 Popolazioni e Campioni\nL‚Äôanalisi dei dati inizia con l‚Äôidentificazione della popolazione di interesse, che rappresenta l‚Äôinsieme completo degli individui o delle entit√† coinvolte nel fenomeno studiato. Poich√© studiare un‚Äôintera popolazione √® spesso impraticabile, si ricorre ai campioni, sottoinsiemi rappresentativi della popolazione. La qualit√† e la rappresentativit√† del campione sono cruciali: un campione non rappresentativo pu√≤ portare a conclusioni errate, limitando la generalizzabilit√† dei risultati.\n\n\n\n\n\n\nParametri e Statistiche\n\n\n\nUn parametro √® una caratteristica numerica della popolazione (es. media \\(\\mu\\), deviazione standard \\(\\sigma\\)). Una statistica √® una caratteristica numerica calcolata sul campione (es. media campionaria \\(\\bar{x}\\), deviazione standard campionaria \\(s\\)). L‚Äôinferenza statistica si occupa di stimare i parametri della popolazione a partire dalle statistiche campionarie.\n\n\n\n\n1.4.2 Bias nella Raccolta Dati\nI bias nella raccolta e interpretazione dei dati possono compromettere l‚Äôaccuratezza dei risultati. Comprendere chi ha raccolto i dati, come e con quali scopi √® essenziale per una corretta interpretazione (Johnson et al., 2022). I dati non sono mai completamente neutri; i metodi e gli obiettivi di raccolta influenzano i risultati. Ad esempio, selezionare partecipanti da una popolazione di studenti universitari potrebbe introdurre un bias sistematico, limitando la generalizzabilit√† ad altri contesti (Murray & Carr, 2024; Nobles, 2000).\n\n\n1.4.3 Variabili e Costanti\nNell‚Äôanalisi statistica, le variabili rappresentano le caratteristiche osservate che possono assumere diversi valori (numerici o categorici). Le costanti, al contrario, rimangono fisse in un determinato contesto. Le variabili si distinguono in:\n\nvariabili indipendenti (o predittive): influenzano altri fenomeni;\n\nvariabili dipendenti: rappresentano gli esiti di interesse influenzati dalle variabili indipendenti.\n\nAd esempio, in uno studio sugli effetti della terapia cognitivo-comportamentale, la variabile indipendente potrebbe essere la partecipazione alla terapia, mentre la variabile dipendente sarebbe la riduzione dei sintomi di ansia.\n\n\n1.4.4 Studi Osservazionali ed Esperimenti\nEsistono due principali metodi di raccolta dati.\n\nEsperimenti: I ricercatori manipolano una o pi√π variabili per valutare il loro effetto su altre variabili, controllando per i fattori confondenti. Ad esempio, per valutare l‚Äôefficacia di un trattamento, i partecipanti possono essere assegnati casualmente a un gruppo di controllo (placebo) e a un gruppo sperimentale (trattamento attivo). La randomizzazione riduce il rischio di bias sistematici.\nStudi osservazionali: I dati vengono raccolti senza interferire con il fenomeno osservato. Ad esempio, un‚Äôindagine su come lo stress influenza la produttivit√† lavorativa potrebbe basarsi su questionari senza manipolare lo stress dei partecipanti. Questi studi forniscono correlazioni tra variabili, ma non dimostrano relazioni causali.\n\n\n\n1.4.5 Effetti\nIn statistica, un effetto rappresenta il cambiamento osservato nella variabile dipendente in relazione a una variabile indipendente. Questo cambiamento pu√≤ indicare un‚Äôassociazione tra le due variabili, ma la sua interpretazione come relazione causale dipende strettamente dal disegno sperimentale con cui i dati sono stati raccolti.\nAd esempio, se si osserva una riduzione dei sintomi tra la fase pre-trattamento e quella post-trattamento in un gruppo di pazienti sottoposti a una terapia, √® possibile identificare un effetto della terapia. Tuttavia, senza un disegno sperimentale adeguato ‚Äì come un esperimento controllato randomizzato (RCT) ‚Äì non √® possibile stabilire con certezza che la riduzione dei sintomi sia causata dalla terapia e non da altri fattori, come il decorso naturale della malattia o l‚Äôeffetto placebo (Huntington-Klein, 2021).\nI modelli statistici, da soli, non possono determinare relazioni causali: possono quantificare l‚Äôentit√† di un effetto e valutare la forza dell‚Äôassociazione tra variabili, ma la causalit√† pu√≤ essere inferita solo se i dati provengono da un disegno sperimentale che isola il meccanismo di interesse, controllando per possibili fattori di confondimento. Pertanto, per trarre conclusioni causali robuste, √® essenziale integrare l‚Äôanalisi statistica con un approccio metodologico rigoroso basato su strategie di manipolazione sperimentale, assegnazione casuale o tecniche avanzate per il controllo dei bias nei dati osservazionali.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#stima-e-inferenza-statistica-dal-campione-alla-popolazione",
    "href": "chapters/key_notions/01_key_notions.html#stima-e-inferenza-statistica-dal-campione-alla-popolazione",
    "title": "1¬† Concetti chiave",
    "section": "1.5 Stima e Inferenza Statistica: Dal Campione alla Popolazione",
    "text": "1.5 Stima e Inferenza Statistica: Dal Campione alla Popolazione\nLa stima e l‚Äôinferenza statistica costituiscono i pilastri della metodologia quantitativa, poich√© permettono di estendere le conclusioni tratte da un campione ‚Äì una porzione limitata di individui osservati ‚Äì all‚Äôintera popolazione di interesse. L‚Äôuso dei campioni risulta indispensabile a causa dei vincoli di tempo, costi e risorse, che spesso rendono impossibile lo studio dell‚Äôintera popolazione.\nTuttavia, il ricorso al campione introduce inevitabilmente un‚Äôincertezza intrinseca: le statistiche campionarie (come media o varianza del campione) sono stime dei parametri della popolazione e di norma non coincidono esattamente con i valori ‚Äúveri‚Äù della popolazione. Tale discrepanza √® nota come errore di campionamento, la cui entit√† dipende, tra l‚Äôaltro, dalla dimensione del campione e dalla strategia di campionamento adottata.\nLa teoria degli stimatori e gli strumenti di inferenza statistica (ad esempio, intervalli di confidenza in un approccio frequentista o intervalli di credibilit√† in un approccio bayesiano) consentono di quantificare e gestire quest‚Äôincertezza, fornendo un quadro che permette di trarre conclusioni credibili sulla popolazione partendo dai dati raccolti.\n\n1.5.1 Stima: Inferire le Caratteristiche della Popolazione\nLa stima √® il processo con cui, a partire dai dati di un campione, si inferiscono propriet√† della popolazione, come la media o la varianza. Poich√© ogni campione rappresenta solo una frazione della popolazione, pu√≤ fornire stime diverse; questo fenomeno √® noto come variabilit√† campionaria. Proprio tale variabilit√† costituisce la principale fonte di incertezza nelle inferenze: se un singolo campione non √® sufficientemente ampio o rappresentativo, la stima potrebbe discostarsi in misura rilevante dai valori effettivi presenti nella popolazione.\n\n1.5.1.1 Fattori che Influenzano l‚ÄôAccuratezza\nTre fattori fondamentali influiscono sull‚Äôaccuratezza di una stima:\n\nDimensione del campione\nUn campione pi√π grande tende a ridurre la variabilit√† campionaria, aumentando la precisione delle stime.\nRappresentativit√†\nUn campione ben progettato e rappresentativo rispecchia le caratteristiche essenziali della popolazione. Al contrario, un campione distorto (ad esempio, selezionato per convenienza) pu√≤ condurre a stime fuorvianti.\nVariabilit√† della popolazione\nSe la popolazione √® estremamente eterogenea, sono necessari campioni pi√π ampi per produrre stime affidabili.\n\n\n\n1.5.1.2 Gli Stimatori: Propriet√† Fondamentali\nGli stimatori sono formule matematiche o procedure statistiche usate per calcolare le stime. La loro qualit√† si valuta principalmente in base a:\n\nConsistenza\nUno stimatore √® consistente se, all‚Äôaumentare della dimensione del campione, la stima tende a convergere verso il valore reale del parametro.\nNon distorsione (unbiasedness)\nUno stimatore √® non distorto se il suo valore atteso corrisponde al parametro della popolazione. In altri termini, in media, lo stimatore coincide con il valore reale.\nEfficienza\nTra stimatori non distorti, √® pi√π efficiente quello con varianza minore, poich√© fornisce stime pi√π stabili.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#inferenza-statistica",
    "href": "chapters/key_notions/01_key_notions.html#inferenza-statistica",
    "title": "1¬† Concetti chiave",
    "section": "1.6 Inferenza Statistica",
    "text": "1.6 Inferenza Statistica\nL‚Äôinferenza statistica si basa sulle stime campionarie per trarre conclusioni sull‚Äôintera popolazione. In particolare, risponde a tre grandi interrogativi:\n\nStima dei parametri della popolazione\nOttenere valori plausibili per parametri quali media, varianza e proporzioni, quantificando contestualmente l‚Äôincertezza (ad esempio, costruendo intervalli di confidenza o di credibilit√†).\nValutazione di ipotesi\nConfrontare ipotesi rivali, come l‚Äôesistenza di differenze tra gruppi o di relazioni tra variabili. Attraverso il confronto tra ipotesi e dati, si determina quale ipotesi √® meglio supportata.\nPrevisione\nUtilizzare i dati esistenti per anticipare risultati futuri, tenendo conto delle fonti di incertezza legate sia alla variabilit√† intrinseca dei dati sia ai parametri non perfettamente noti.\n\nSia l‚Äôapproccio frequentista sia quello bayesiano affrontano questi problemi in modo rigoroso, ma differiscono nel modo di concettualizzare l‚Äôincertezza e di incorporare l‚Äôinformazione nei modelli.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#le-sfide-dellinferenza-statistica-in-psicologia",
    "href": "chapters/key_notions/01_key_notions.html#le-sfide-dellinferenza-statistica-in-psicologia",
    "title": "1¬† Concetti chiave",
    "section": "1.7 Le Sfide dell‚ÄôInferenza Statistica in Psicologia",
    "text": "1.7 Le Sfide dell‚ÄôInferenza Statistica in Psicologia\nIn psicologia e, pi√π in generale, nelle scienze sociali, l‚Äôinferenza statistica incontra specifiche problematiche spesso connesse alla complessit√† dei fenomeni oggetto di studio (Gelman et al., 2021). Tra le sfide principali figurano:\n\nLimiti nella generalizzazione dei risultati\nIn molti studi psicologici, le condizioni sperimentali create in laboratorio o in ambienti altamente controllati non sempre rispecchiano le dinamiche reali in cui i fenomeni si manifestano. L‚Äôuso di procedure standardizzate e compiti artificiali pu√≤ semplificare notevolmente le variabili in gioco, a scapito della validit√† esterna: i risultati ottenuti potrebbero non essere direttamente trasferibili a contesti naturali o situazioni di vita quotidiana. Inoltre, se i partecipanti vengono selezionati per ragioni pratiche (ad esempio, studenti universitari reclutati su base volontaria), ci√≤ limita ulteriormente la rappresentativit√† del campione, rendendo pi√π difficile estendere le conclusioni a gruppi pi√π eterogenei o a popolazioni diverse.\nRischio di semplificare eccessivamente i meccanismi causali ipotizzati\nL‚Äôinferenza causale ‚Äì implicita o esplicita nella maggior parte delle ricerche in psicologia ‚Äì mira a comprendere se e come un fattore influisca su un altro. Tuttavia, in contesti cos√¨ complessi, i modelli causali proposti possono risultare eccessivamente semplificati, trascurando interazioni tra variabili, fattori contestuali o processi multilivello. Quando tali aspetti non vengono adeguatamente considerati, le conclusioni possono rivelarsi poco utili o non sufficientemente applicabili ai contesti reali.\nDistorsioni legate alla misurazione\nMolti costrutti di interesse psicologico (es. ansia, autostima, intelligenza) non sono direttamente osservabili, bens√¨ misurati attraverso questionari, test o altre metodologie indirette. Tale approccio introduce possibili errori di misurazione e distorsioni legate allo strumento di valutazione. L‚Äôinferenza statistica deve quindi tenere conto di questa complessit√†, collegando in modo rigoroso le osservazioni empiriche ai costrutti teorici sottostanti.\n\nIn sintesi, la stima e l‚Äôinferenza statistica rappresentano strumenti fondamentali per trasformare i dati campionari in conoscenza generalizzabile, soprattutto in un contesto come quello psicologico, caratterizzato da un‚Äôelevata variabilit√† nei comportamenti e nei processi mentali. Da un lato, la metodologia quantitativa offre un quadro consolidato per gestire l‚Äôincertezza e testare ipotesi; dall‚Äôaltro, √® cruciale prestare attenzione alla qualit√† del campione, alla validit√† degli strumenti di misura e all‚Äôintrinseca complessit√† dei costrutti indagati.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#la-quantificazione-dellincertezza",
    "href": "chapters/key_notions/01_key_notions.html#la-quantificazione-dellincertezza",
    "title": "1¬† Concetti chiave",
    "section": "1.8 La Quantificazione dell‚ÄôIncertezza",
    "text": "1.8 La Quantificazione dell‚ÄôIncertezza\nLe considerazioni introduttive di questo capitolo mettono in evidenza come la gestione e la quantificazione dell‚Äôincertezza rappresentino un aspetto cruciale della stima e dell‚Äôinferenza statistica. Qualunque stima ottenuta da un campione √® inevitabilmente soggetta a errore, poich√© il campione costituisce soltanto una frazione della popolazione di riferimento. L‚Äôinferenza statistica offre gli strumenti necessari per quantificare tale incertezza, ad esempio tramite gli intervalli di confidenza (nell‚Äôapproccio frequentista) o le distribuzioni a posteriori (nell‚Äôapproccio bayesiano), consentendo di esprimere in modo rigoroso il grado di fiducia nelle conclusioni raggiunte.\nIn conclusione, la stima e l‚Äôinferenza statistica rappresentano strumenti essenziali per trasformare i dati empirici in conoscenza solida e applicabile. √à tuttavia indispensabile avvalersene in maniera critica, tenendo sempre presenti le possibili distorsioni insite nel processo di raccolta e analisi dei dati. Ci√≤ significa prestare particolare attenzione alla rappresentativit√† del campione, alla validit√† delle misurazioni e all‚Äôinterpretazione corretta dei risultati, cos√¨ da evitare generalizzazioni indebite o conclusioni fuorvianti.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#riflessioni-conclusive",
    "href": "chapters/key_notions/01_key_notions.html#riflessioni-conclusive",
    "title": "1¬† Concetti chiave",
    "section": "1.9 Riflessioni Conclusive",
    "text": "1.9 Riflessioni Conclusive\nL‚Äôanalisi dei dati acquisisce valore solo quando √® integrata con una solida teoria scientifica, che fornisce il contesto e il quadro interpretativo necessario per attribuire senso ai risultati. Ad esempio, osservare che un trattamento psicologico riduce i sintomi √® un‚Äôosservazione empirica che, senza una teoria che chiarisca i meccanismi sottostanti, rimane priva di potere esplicativo. √à la teoria che orienta il processo analitico, formulando ipotesi verificabili e offrendo interpretazioni che si inseriscono in un modello pi√π ampio.\nIn definitiva, la relazione tra teoria e analisi dei dati √® intrinsecamente circolare e dinamica: le teorie guidano la raccolta, l‚Äôanalisi e l‚Äôinterpretazione dei dati, mentre i dati, a loro volta, stimolano il perfezionamento e l‚Äôevoluzione delle teorie. Questo dialogo continuo √® ci√≤ che permette un progresso costante nella comprensione dei fenomeni psicologici.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#esercizi",
    "href": "chapters/key_notions/01_key_notions.html#esercizi",
    "title": "1¬† Concetti chiave",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n\nChe cos‚Äô√® una spiegazione scientifica e in che modo si differenzia da una mera descrizione o previsione di un fenomeno?\nPerch√©, quando si parla di popolazione e campione, √® fondamentale assicurarsi che il campione sia rappresentativo, e quali conseguenze possono derivare da un campione non rappresentativo?\nChe differenza c‚Äô√® tra un parametro e una statistica, e perch√© in inferenza statistica si cerca di stimare il parametro sconosciuto a partire dalla statistica campionaria?\nCosa si intende per bias nella raccolta e interpretazione dei dati, e in che modo la consapevolezza dei possibili bias pu√≤ migliorare la qualit√† della ricerca?\nPerch√© in psicologia e nelle scienze sociali risulta essenziale integrare l‚Äôanalisi dei dati con un quadro teorico solido e coerente?\nQual √® la differenza principale tra uno studio osservazionale e un esperimento, e perch√© la distinzione √® importante per comprendere la causalit√†?\nChe ruolo svolgono i modelli scientifici in psicologia, e quali caratteristiche fondamentali dovrebbero possedere per essere considerati validi e utili?\nIn che modo l‚Äôanalisi dei dati aiuta a passare dalle semplici correlazioni o tendenze osservate all‚Äôelaborazione di ipotesi e spiegazioni pi√π profonde?\nChe differenza c‚Äô√® tra variabili indipendenti e variabili dipendenti, e perch√© questa distinzione √® cruciale per disegnare uno studio e interpretarne i risultati?\nPerch√© parlare di incertezza √® inevitabile quando si utilizzano i dati di un campione, e come la statistica (frequentista o bayesiana) ci aiuta a gestirla?\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n1. Che cos‚Äô√® una spiegazione scientifica e in che modo si differenzia da una mera descrizione o previsione di un fenomeno?\nUna spiegazione scientifica mira a individuare le cause e i meccanismi che generano o influenzano un fenomeno. Non si limita quindi a descrivere cosa accade o a prevedere ci√≤ che potrebbe accadere (come una semplice correlazione o un modello predittivo), ma cerca di chiarire perch√© il fenomeno si verifica. Ad esempio, dire ‚Äúi bambini con genitori laureati hanno migliori prestazioni scolastiche‚Äù √® una descrizione (o previsione) utile; spiegare che ci√≤ avviene a causa di un maggior sostegno nel percorso di studi, di un ambiente pi√π ricco di stimoli culturali, o di un contesto socioeconomico facilitante, fornisce invece una spiegazione che va oltre la pura correlazione statistica.\n2. Perch√©, quando si parla di popolazione e campione, √® fondamentale assicurarsi che il campione sia rappresentativo, e quali conseguenze possono derivare da un campione non rappresentativo?\nIl campione √® il sottoinsieme di individui selezionati da una popolazione pi√π ampia. Affinch√© i risultati di uno studio siano validi e generalizzabili, il campione deve rispecchiare le principali caratteristiche della popolazione (ad esempio in termini di et√†, genere, livello socioeconomico, ecc.). Se il campione non √® rappresentativo (per esempio, se si reclutano solo studenti universitari per uno studio su tutta la popolazione italiana), possono emergere bias di selezione che rendono impossibile estendere correttamente i risultati a gruppi sociali diversi. Conseguenze tipiche di un campione non rappresentativo includono stime distorte dei parametri d‚Äôinteresse, conclusioni fuorvianti e ridotta validit√† esterna della ricerca.\n3. Che differenza c‚Äô√® tra un parametro e una statistica, e perch√© in inferenza statistica si cerca di stimare il parametro sconosciuto a partire dalla statistica campionaria?\n\nUn parametro √® una caratteristica numerica della popolazione (ad esempio la media reale di un determinato tratto o la proporzione di individui con una certa caratteristica).\n\nUna statistica √® una misura analoga, ma calcolata sul campione (ad esempio la media o la proporzione campionaria).\n\nPoich√© in genere √® impossibile o molto costoso misurare l‚Äôintera popolazione, si raccoglie un campione pi√π piccolo e gestibile. La statistica del campione (ad es. la media campionaria) √® quindi usata per stimare il parametro (ad es. la media della popolazione). L‚Äôobiettivo dell‚Äôinferenza statistica √® fornire, insieme a questa stima, una misura dell‚Äôincertezza associata (per esempio un intervallo di confidenza), cos√¨ da comprendere quanto la statistica campionaria potrebbe ‚Äúavvicinarsi‚Äù al vero valore del parametro.\n4. Cosa si intende per bias nella raccolta e interpretazione dei dati, e in che modo la consapevolezza dei possibili bias pu√≤ migliorare la qualit√† della ricerca?\nIl bias √® un errore sistematico che altera i risultati di uno studio in una direzione specifica, dovuto a scelte o condizioni nel disegno della ricerca, nella selezione del campione, nella misurazione o nell‚Äôinterpretazione dei dati. Ad esempio, se reclutiamo solo volontari particolarmente motivati a partecipare a una ricerca, potremmo ottenere risultati che sovrastimano un certo fenomeno e non rispecchiano la popolazione generale.\nEssere consapevoli di come i bias possano nascere aiuta i ricercatori a mitigarli (ad esempio, bilanciando il reclutamento dei partecipanti o rendendo anonima la compilazione di un questionario) e a tenere conto dei loro effetti quando si interpretano i risultati. Cos√¨, la ricerca risulta pi√π affidabile e validamente interpretata.\n5. Perch√© in psicologia e nelle scienze sociali risulta essenziale integrare l‚Äôanalisi dei dati con un quadro teorico solido e coerente?\nNelle scienze sociali e in psicologia, i fenomeni studiati sono spesso complessi e influenzati da molte variabili. I dati da soli, senza una teoria, forniscono soltanto una descrizione o una misurazione di ci√≤ che accade in un dato momento. La teoria invece permette di:\n\nIdentificare le variabili rilevanti e formulare ipotesi specifiche;\n\nInterpretare i risultati, attribuendo un senso e un contesto alle relazioni osservate;\n\nComprendere i meccanismi causali e sviluppare spiegazioni che vadano oltre la pura descrizione.\n\nSenza un quadro teorico di riferimento, sarebbe difficile capire perch√© si osservano determinate relazioni e come possano cambiare in contesti diversi o in situazioni sperimentali alternative.\n6. Qual √® la differenza principale tra uno studio osservazionale e un esperimento, e perch√© la distinzione √® importante per comprendere la causalit√†?\n\nStudio osservazionale: Il ricercatore raccoglie i dati senza intervenire n√© manipolare alcuna variabile. Ad esempio, si misura il livello di stress delle persone e la loro produttivit√† sul lavoro, senza modificare artificialmente il livello di stress. Questi studi mostrano correlazioni, ma √® difficile stabilire con certezza relazioni di causa-effetto.\n\nEsperimento: Il ricercatore manipola una o pi√π variabili (variabili indipendenti) e controlla le condizioni, ad esempio assegnando in modo casuale i partecipanti a un gruppo di trattamento e a uno di controllo. Ci√≤ facilita la comprensione di eventuali nessi causali, perch√© la randomizzazione e il controllo degli altri fattori riducono il rischio che variabili esterne influenzino i risultati.\n\nLa distinzione √® cruciale perch√©, nei fenomeni complessi della psicologia, gli studi osservazionali possono suggerire ipotesi di relazione, ma di solito occorre un disegno sperimentale (quando possibile) per trarre conclusioni pi√π solide sulla causalit√†.\n7. Che ruolo svolgono i modelli scientifici in psicologia, e quali caratteristiche fondamentali dovrebbero possedere per essere considerati validi e utili?\nI modelli scientifici in psicologia forniscono una struttura concettuale e spesso formale (matematica o simulativa) per rappresentare e spiegare processi mentali e comportamentali. Servono a:\n\nOrganizzare osservazioni ed evidenze in un sistema coerente;\n\nFare previsioni verificabili empiricamente;\n\nGuidare l‚Äôinterpretazione di nuovi dati e la progettazione di futuri studi.\n\nCaratteristiche di un buon modello sono:\n\nCoerenza descrittiva (rappresenta fedelmente il fenomeno);\n\nCapacit√† predittiva (prevede correttamente i risultati di situazioni nuove);\n\nSupporto empirico (confermato dai dati raccolti rigorosamente);\n\nFalsificabilit√† (dev‚Äôessere possibile smentirlo con evidenze contrarie);\n\nParsimonia (non dev‚Äôessere inutilmente complicato);\n\nGeneralizzabilit√† (applicabile a diversi contesti e situazioni);\n\nUtilit√† pratica (fornisce indicazioni utili per interventi o comprensione teorica).\n\n8. In che modo l‚Äôanalisi dei dati aiuta a passare dalle semplici correlazioni o tendenze osservate all‚Äôelaborazione di ipotesi e spiegazioni pi√π profonde?\nL‚Äôanalisi dei dati non si limita a segnalare che ‚Äúdue variabili sono associate‚Äù (correlazioni), ma offre:\n\nStrumenti per isolare l‚Äôeffetto di una variabile sulle altre (regressioni multiple, modelli a effetti misti, ecc.);\n\nMetodologie per la verifica di ipotesi specifiche sulla direzione e sulla natura delle relazioni (ad es. test statistici o modelli di mediazione-moderazione in psicologia);\n\nIndicatori dell‚Äôincertezza e della robustezza dei risultati (intervalli di confidenza, analisi della potenza, analisi bayesiane).\n\nCon questi strumenti, i ricercatori possono integrare i risultati quantitativi con le teorie esistenti, sviluppare nuove ipotesi su meccanismi causali e proporre spiegazioni pi√π articolate su come e perch√© le variabili si influenzino reciprocamente.\n9. Che differenza c‚Äô√® tra variabili indipendenti e variabili dipendenti, e perch√© questa distinzione √® cruciale per disegnare uno studio e interpretarne i risultati?\n\nVariabile indipendente (VI): √® quella che si sospetta abbia un effetto su un‚Äôaltra variabile, o che si desidera manipolare in un disegno sperimentale (per esempio, l‚Äôintroduzione di un nuovo metodo di studio).\n\nVariabile dipendente (VD): √® la variabile che si misura per valutare l‚Äôeventuale effetto della variabile indipendente (ad esempio, i risultati di un test di apprendimento).\nLa distinzione √® basilare perch√© chiarisce la direzione del rapporto di interesse e permette di formulare ipotesi come ‚ÄúVI ‚Üí VD‚Äù (es. ‚Äúil nuovo metodo di studio migliora i risultati del test‚Äù). Sbagliare a identificare quali sono le variabili indipendenti e dipendenti pu√≤ portare a disegni di ricerca confusi e interpretazioni errate.\n\n10. Perch√© parlare di incertezza √® inevitabile quando si utilizzano i dati di un campione, e come la statistica (frequentista o bayesiana) ci aiuta a gestirla?\nQuando raccogliamo dati da un campione (necessariamente limitato), non possiamo osservare l‚Äôintera popolazione. Questo introduce un margine di incertezza su quanto la misura campionaria (statistica) rispecchi il parametro reale della popolazione. Inoltre, possono sempre esserci fattori non controllati o errori di misurazione.\n\nNell‚Äôapproccio frequentista, l‚Äôincertezza √® gestita tramite concetti come gli intervalli di confidenza e i valori p, che quantificano la probabilit√† di osservare determinati risultati assumendo determinate ipotesi (per es. l‚Äôipotesi nulla).\n\nNell‚Äôapproccio bayesiano, l‚Äôincertezza √® modellata tramite distribuzioni di probabilit√† (posteriori) che incorporano sia i dati osservati sia le informazioni pregresse (priors).\n\nEntrambi gli approcci forniscono metodologie per valutare quanto ci si possa fidare di una data conclusione, riconoscendo il carattere aleatorio e parziale dei dati e rendendo esplicito il grado di incertezza.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#bibliografia",
    "href": "chapters/key_notions/01_key_notions.html#bibliografia",
    "title": "1¬† Concetti chiave",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other stories. Cambridge University Press.\n\n\nHuntington-Klein, N. (2021). The effect: An introduction to research design and causality. Chapman; Hall/CRC.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nMurray, E. J., & Carr, K. C. (2024). Measuring Racial Sentiment Using Social Media Is Harder Than It Seems. Epidemiology, 35(1), 60‚Äì63.\n\n\nNobles, M. (2000). Shades of citizenship: Race and the census in modern politics. Stanford University Press.\n\n\nSteinman, R. M., Pizlo, Z., & Pizlo, F. J. (2000). Phi is not beta, and why Wertheimer‚Äôs discovery launched the Gestalt revolution. Vision research, 40(17), 2257‚Äì2264.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_design.html",
    "href": "chapters/key_notions/02_design.html",
    "title": "2¬† Campionamento, metodologia sperimentale e studi osservazionali",
    "section": "",
    "text": "2.1 Introduzione\nQuesto capitolo si propone di approfondire i concetti introdotti in precedenza, concentrandosi in particolare sul processo di campionamento e sull‚Äôimportanza delle diverse metodologie di ricerca in psicologia. Dopo aver compreso il ruolo fondamentale dei dati nella verifica delle teorie, emerge una questione cruciale: come vengono raccolti questi dati?\nLa raccolta dei dati non √® un‚Äôattivit√† neutra o priva di conseguenze metodologiche. I dati, infatti, non hanno lo stesso valore scientifico a seconda di come vengono ottenuti. Alcune modalit√† di raccolta generano informazioni preziose e utili per testare le teorie, mentre altre possono produrre risultati fuorvianti, distorti o addirittura dannosi per la validit√† della ricerca.\nIl metodo scientifico fornisce un quadro di riferimento che delinea le caratteristiche ideali di un processo di raccolta dati in grado di produrre informazioni valide e affidabili. Tuttavia, le prescrizioni del metodo scientifico sono per loro natura generali e astratte. Tradurre questi principi in procedure concrete e applicarli efficacemente in un contesto di ricerca specifico rappresenta una sfida significativa.\nQuesto passaggio, che collega la teoria alla pratica, dipende dalle risorse disponibili, dalla competenza metodologica e dalla creativit√† del ricercatore. La capacit√† di ideare e attuare strategie di raccolta dati adeguate al contesto specifico della ricerca √® fondamentale per garantire la qualit√† e la validit√† dei risultati ottenuti. In questo capitolo, approfondiremo i principi del campionamento e introdurremo i concetti chiave relativi ai disegni di ricerca.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Campionamento, metodologia sperimentale e studi osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_design.html#popolazioni-e-campioni",
    "href": "chapters/key_notions/02_design.html#popolazioni-e-campioni",
    "title": "2¬† Campionamento, metodologia sperimentale e studi osservazionali",
    "section": "2.2 Popolazioni e Campioni",
    "text": "2.2 Popolazioni e Campioni\nNella ricerca scientifica, √® essenziale distinguere tra popolazione e campione.\n\nPopolazione: rappresenta l‚Äôinsieme completo di unit√† che condividono una o pi√π caratteristiche specifiche oggetto di studio. La dimensione della popolazione √® indicata con N.\nCampione: √® un sottoinsieme della popolazione, di dimensione n. L‚Äôobiettivo del campionamento √® ottenere un campione rappresentativo, ovvero un sottoinsieme che rifletta accuratamente le caratteristiche della popolazione di riferimento.\n\n\n2.2.1 Metodi di Campionamento\nEsistono diverse strategie per selezionare un campione rappresentativo da una popolazione. Queste strategie si dividono principalmente in due categorie: campionamento probabilistico e campionamento non probabilistico.\n\n2.2.1.1 Campionamento Probabilistico\nNel campionamento probabilistico, ogni unit√† della popolazione ha una probabilit√† nota e non nulla di essere inclusa nel campione. Questo approccio minimizza il rischio di distorsioni sistematiche (bias) e consente di stimare l‚Äôerrore di campionamento.\n\nCampionamento Casuale Semplice (CCS):\nOgni unit√† della popolazione ha la stessa probabilit√† di essere inclusa nel campione. Questo metodo richiede una lista completa di tutte le unit√† della popolazione, nota come frame di campionamento. La selezione pu√≤ avvenire con o senza reinserimento. Il CCS senza reinserimento √® il pi√π comune nella pratica, ma nelle ricerche psicologiche √® raramente utilizzabile a causa della difficolt√† di ottenere un frame completo della popolazione.\nCampionamento Stratificato:\nLa popolazione viene divisa in strati (H), ovvero sottogruppi omogenei in base a una o pi√π variabili rilevanti (es. et√†, genere, regione geografica). Da ogni strato h viene estratto un campione casuale semplice di dimensione nh. Questo metodo pu√≤ essere:\n\nProporzionale: la dimensione del campione in ogni strato √® proporzionale alla dimensione dello strato nella popolazione.\nNon proporzionale: utilizzato per sovra-campionare gruppi minoritari, consentendo analisi dettagliate di sottogruppi altrimenti poco rappresentati.\nNelle ricerche psicologiche, il campionamento stratificato √® utile per garantire che variabili come il genere o l‚Äôet√† siano adeguatamente rappresentate, ma pu√≤ essere complesso da implementare.\n\nCampionamento a Grappolo (Cluster Sampling):\nLa popolazione viene suddivisa in grappoli (cluster), che rappresentano gruppi eterogenei (es. scuole, ospedali, quartieri). Vengono selezionati casualmente alcuni grappoli, includendo tutte le unit√† al loro interno. Questo metodo √® economico e pratico, specialmente in contesti dove accedere all‚Äôintera popolazione √® difficile. Tuttavia, la precisione pu√≤ essere ridotta se i grappoli differiscono notevolmente tra loro.\nCampionamento Multistadio:\nCombinazione di campionamento a grappolo e CCS. Vengono selezionati casualmente alcuni grappoli e, successivamente, all‚Äôinterno di ciascun grappolo, si estrae un campione casuale di unit√†. Questo metodo bilancia costi e precisione, risultando particolarmente adatto a studi su larga scala, ad esempio a livello nazionale.\n\n\n\n2.2.1.2 Campionamento Non Probabilistico\nNel campionamento non probabilistico, la probabilit√† di inclusione di ogni unit√† nel campione non √® nota. Questo approccio √® spesso adottato per ragioni di praticit√† o quando non √® disponibile un frame di campionamento. Tuttavia, aumenta il rischio di distorsioni e limita la generalizzabilit√† dei risultati alla popolazione.\n\nCampionamento di Convenienza:\n√à il metodo pi√π diffuso nella ricerca psicologica. I partecipanti vengono selezionati in base alla loro facile accessibilit√† (es., studenti universitari, volontari). Questo metodo √® rapido ed economico, ma introduce significativi bias di selezione, poich√© il campione non √® rappresentativo della popolazione generale.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Campionamento, metodologia sperimentale e studi osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_design.html#il-campionamento-nella-ricerca-psicologica",
    "href": "chapters/key_notions/02_design.html#il-campionamento-nella-ricerca-psicologica",
    "title": "2¬† Campionamento, metodologia sperimentale e studi osservazionali",
    "section": "2.3 Il Campionamento nella Ricerca Psicologica",
    "text": "2.3 Il Campionamento nella Ricerca Psicologica\nIl tema del campionamento nella ricerca psicologica √® cruciale perch√© influisce in modo diretto sulla validit√† esterna e sulla generalizzabilit√† dei risultati. Nella pratica, per√≤, l‚Äôideale metodologico del campionamento probabilistico √® spesso difficile da perseguire, a causa di vincoli di tempo, di risorse economiche e di accessibilit√† ai partecipanti (Henrich et al., 2010a). Per queste ragioni, molti studi in psicologia fanno ricorso al campionamento di convenienza, che prevede la selezione dei partecipanti sulla base della loro facile reperibilit√†, come studenti universitari o volontari reclutati online.\n\n2.3.1 Perch√© il Campionamento di Convenienza √® cos√¨ Diffuso?\n\nVincoli di Risorse\nLa ricerca psicologica, specie in ambito accademico, spesso non dispone di finanziamenti sufficienti per condurre campionamenti su larga scala. Reclutare partecipanti rappresentativi di un‚Äôintera popolazione richiederebbe budget, logistica e tempo ben superiori a quelli generalmente disponibili (Peterson & Merunka, 2014). Il campionamento di convenienza diventa quindi un compromesso ‚Äúnecessario‚Äù per poter portare avanti gli studi.\nAccessibilit√† ai Partecipanti\nNel contesto universitario, gli studenti rappresentano il bacino pi√π facilmente accessibile e motivato a partecipare a studi psicologici, talvolta in cambio di crediti formativi o rimborsi simbolici (Sears, 1986). In altri contesti, si ricorre a piattaforme online che forniscono volontari in tempi brevi, consentendo di raccogliere dati in modo rapido e a costi contenuti.\nRapidit√† di Raccolta Dati\nIl vantaggio principale del campionamento di convenienza √® la possibilit√† di raccogliere dati in tempi molto pi√π ridotti rispetto a strategie di campionamento probabilistico. Tale rapidit√† pu√≤ risultare essenziale per studi pilota o ricerche che richiedono analisi preliminari di fenomeni ancora poco esplorati.\n\n\n\n2.3.2 Limiti e Implicazioni\nIl ricorso al campionamento di convenienza comporta inevitabilmente dei limiti in termini di rappresentativit√† del campione. Gli individui che si prestano a partecipare a uno studio potrebbero avere caratteristiche socio-demografiche, cognitive o motivazionali peculiari (ad esempio, essere pi√π giovani, con livelli di istruzione pi√π alti, culturalmente pi√π omogenei), portando ad un fenomeno noto come ‚Äúcampioni WEIRD‚Äù [Western, Educated, Industrialized, Rich, Democratic; Henrich et al. (2010b)]. Ci√≤ significa che i risultati ottenuti potrebbero non riflettere adeguatamente l‚Äôintera variabilit√† della popolazione umana.\n\nGeneralizzabilit√† Ridotta: Uno studio condotto su studenti di psicologia in un‚Äôuniversit√† europea pu√≤ non essere applicabile a individui di diverse fasce di et√†, provenienti da altre aree geografiche o con retroterra socio-culturali differenti.\nBias di Selezione: I partecipanti volontari, specialmente online, possono essere attratti dallo studio per ragioni specifiche (ad esempio, curiosit√† verso la psicologia, tempo libero a disposizione, motivazione a ottenere un compenso), introducendo distorsioni non presenti nella popolazione pi√π ampia.\nLimitazioni nei Risultati: Se i processi psicologici oggetto di indagine sono influenzati da cultura, et√† o altre variabili, lo studio potrebbe non catturare in modo esaustivo la complessit√† del fenomeno.\n\n\n\n2.3.3 Perch√© in Psicologia √® (in Parte) Accettabile\nSebbene il campionamento di convenienza costituisca un limite, √® bene ricordare che molti fenomeni psicologici presentano elementi di base che sono relativamente generali o universali nell‚Äôessere umano [ad esempio, i processi di percezione, l‚Äôapprendimento di base, alcune dinamiche emotive e motivazionali; cfr. Tooby & Cosmides (2005)]. Ci√≤ significa che, entro certi confini, studiare un campione di convenienza pu√≤ comunque fornire indicazioni utili e trasferibili ad altre popolazioni. Inoltre, buona parte delle ricerche in psicologia mira ad approfondire meccanismi e processi interna corporis ‚Äì cio√® aspetti di natura cognitiva, emotiva o sociale che, pur potendo variare in intensit√† o manifestazione, hanno basi comuni tra gli individui.\nIn altre parole, esiste un trade-off tra la necessit√† di disporre di campioni rappresentativi per garantire la massima generalizzabilit√† e la specificit√† dei fenomeni psicologici, che talvolta risiedono in processi considerati ‚Äúuniversali‚Äù. Se lo scopo di uno studio √® quello di testare meccanismi cognitivi di base (per esempio, l‚Äôelaborazione di stimoli visivi o di memoria), un campione di studenti potrebbe comunque fornire dati sufficientemente robusti, purch√© si riconoscano i limiti del contesto di raccolta.\n\n2.3.3.1 Considerazioni Etiche e Pratiche\nTalvolta, per ragioni etiche, non √® semplice reperire partecipanti da particolari fasce di popolazione (ad esempio minori, pazienti clinici, soggetti in contesti istituzionali). In alcune ricerche, poi, l‚Äôuso di questionari lunghi o procedure sperimentali intense rende difficile attrarre volontari al di fuori dell‚Äôambiente universitario. Da questo punto di vista, avere un bacino di partecipanti noti (ad es. studenti di psicologia) agevola la raccolta dei dati.\n\nRicompense: Spesso i dipartimenti offrono crediti formativi o piccoli compensi ai partecipanti, innescando un circolo virtuoso di interesse per la ricerca.\nLibert√† di rifiuto: Le universit√† dispongono di comitati etici che tutelano i diritti dei partecipanti, garantendo che anche i reclutamenti ‚Äúdi comodo‚Äù rispettino i principi etici fondamentali (consenso informato, anonimato, diritto al recesso, ecc.).\n\n\n\n\n2.3.4 Come Mitigare i Limiti del Campionamento di Convenienza\n\nReplicazione Incrociata (Cross-Replication)\nUn metodo efficace per aumentare la validit√† dei risultati √® replicare lo stesso studio su campioni differenti, di et√† diversa o provenienti da contesti socio-culturali eterogenei. Ripetere la ricerca in pi√π contesti e ottenere risultati simili fornisce evidenza della generalizzabilit√† del fenomeno.\nCampionamento Diversificato\nAnche se si ricorre a un campionamento di convenienza, si pu√≤ tentare di diversificare la provenienza dei partecipanti (ad esempio, includendo studenti di diverse facolt√† o atenei, oppure reclutando volontari su piattaforme online internazionali). Un campione che rifletta almeno in parte una maggiore variet√† di background socio-culturali √® comunque preferibile alla selezione di un solo gruppo omogeneo.\nCaratterizzazione Dettagliata del Campione\n√à fondamentale fornire informazioni precise su et√†, genere, livello di istruzione, estrazione socio-culturale e altre variabili rilevanti. Questo permette ai lettori di valutare in che misura i risultati dello studio possano essere trasferiti ad altre popolazioni.\nIntegrazione di Metodi di Campionamento Misti\nAlcuni ricercatori scelgono di integrare campionamenti non probabilistici con piccole porzioni di campionamento pi√π stratificato o di selezionare sotto-campioni rappresentativi per determinati sottogruppi. Non si tratta di un vero e proprio campionamento probabilistico, ma pu√≤ comunque migliorare la robustezza dei risultati rispetto al puro campionamento di convenienza.\n\n\n\n2.3.5 Considerazioni Economiche e Future Prospettive\nAlla luce di questi punti, appare chiaro che il ricorso a metodi di campionamento probabilistici pi√π rigorosi (campionamento casuale semplice, stratificato o a grappolo) richiederebbe aumenti significativi nei finanziamenti e un impegno logistico maggiore. Ci√≤ non √® sempre fattibile in contesti di ricerca accademica o quando i progetti sono condotti con budget limitati.\nD‚Äôaltro canto, i finanziamenti aggiuntivi permetterebbero di:\n\nReclutare campioni pi√π ampi e diversificati, ad esempio attraverso agenzie di rilevazione professionali o sondaggi a livello nazionale.\n\nImplementare studi longitudinali su popolazioni geograficamente distribuite, riducendo il rischio di raccogliere dati esclusivamente da aree limitrofe ai centri di ricerca.\nSostenere progetti multicentrici a livello internazionale, che consentono di testare l‚Äôuniversalit√† o la specificit√† culturale dei fenomeni psicologici.\n\nFino a quando queste risorse non saranno disponibili su larga scala, il campionamento di convenienza rimarr√† la soluzione pi√π diffusa e ‚Äúrealistica‚Äù nella ricerca psicologica. Tuttavia, non bisogna considerarlo esclusivamente un limite: la specificit√† dei fenomeni psicologici, legati a processi condivisi tra gli individui, talvolta permette di estrarre conclusioni valide anche da campioni meno rappresentativi, purch√© si utilizzino adeguate cautele nell‚Äôinterpretazione e si persegua la replicazione come prassi consolidata.\nIn sintesi, il campionamento di convenienza √® una strategia inevitabile nell‚Äôattuale panorama della ricerca psicologica, caratterizzato da forti limitazioni di risorse, ma in molti casi risulta comunque sufficiente per investigare dinamiche e processi psicologici di base. L‚Äôauspicio per il futuro √® di poter disporre di finanziamenti e collaborazioni che permettano di ampliare il raggio d‚Äôazione e la diversit√† dei partecipanti, rafforzando la validit√† e la generalizzabilit√† della produzione scientifica in psicologia.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Campionamento, metodologia sperimentale e studi osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_design.html#metodologia-sperimentale",
    "href": "chapters/key_notions/02_design.html#metodologia-sperimentale",
    "title": "2¬† Campionamento, metodologia sperimentale e studi osservazionali",
    "section": "2.4 Metodologia Sperimentale",
    "text": "2.4 Metodologia Sperimentale\n\n2.4.1 Principi Fondamentali del Disegno Sperimentale\n\nControllo\nL‚Äôobiettivo √® ridurre l‚Äôinfluenza di variabili confondenti (Z) sulla relazione tra la variabile indipendente (X) e quella dipendente (Y). Utilizzare un gruppo di controllo consente di stabilire un riferimento per valutare l‚Äôeffetto del trattamento.\nRandomizzazione\nL‚Äôassegnazione casuale dei partecipanti ai gruppi sperimentali distribuisce le variabili confondenti in modo equilibrato tra i gruppi, aumentando la credibilit√† dell‚Äôinferenza causale tra X e Y. Questo approccio garantisce che eventuali differenze osservate siano attribuibili al trattamento e non a fattori esterni.\n\n\n\n2.4.2 Strategie di Mitigazione dei Bias\n\nCecit√† (Blinding)\nStrumento chiave per minimizzare l‚Äôinfluenza di aspettative e pregiudizi, sia nei partecipanti che nei ricercatori. Le principali modalit√† includono:\n\nCecit√† singola: I partecipanti non sono consapevoli del trattamento assegnato.\nCecit√† doppia: Sia i partecipanti che i ricercatori che interagiscono direttamente con loro non conoscono l‚Äôassegnazione dei trattamenti.\nCecit√† tripla: N√© i partecipanti, n√© i ricercatori, n√© gli analisti dei dati sono a conoscenza dei trattamenti durante la raccolta e l‚Äôanalisi dei dati.\n\nGruppo di Controllo\nL‚Äôintroduzione di un gruppo che riceve un trattamento inerte (controllo) consente di isolare gli effetti psicologici legati alle aspettative dei partecipanti, distinguendoli dagli effetti specifici del trattamento.\nStandardizzazione delle Procedure\nGarantire che tutte le condizioni sperimentali, eccetto la variabile manipolata, siano mantenute costanti tra i gruppi. Questo riduce la variabilit√† non controllata, migliorando la comparabilit√† dei risultati.\n\n\n\n2.4.3 Nota sulla Replicazione\nLa replicazione degli esperimenti non √® una caratteristica intrinseca del metodo sperimentale, ma rappresenta una pratica fondamentale nella scienza per verificare l‚Äôaffidabilit√† e la generalizzabilit√† dei risultati. Si distingue in:\n\nReplicazione diretta: Ripetere lo stesso studio con le stesse condizioni.\nReplicazione concettuale: Ripetere lo studio modificando aspetti specifici per testare la robustezza del risultato.\n\n\n\n2.4.4 Tipologie di Disegni Sperimentali\n\nDisegno a Gruppi Indipendenti (Between-Subjects):\nI partecipanti vengono assegnati a un unico gruppo e sono esposti a una sola condizione sperimentale. Questo disegno √® utile quando l‚Äôesposizione multipla potrebbe introdurre confondenti, ma richiede un campione pi√π ampio per raggiungere lo stesso livello di precisione.\nDisegno a Misure Ripetute (Within-Subjects):\nGli stessi partecipanti vengono esposti a tutte le condizioni sperimentali. Questo approccio riduce la variabilit√† tra soggetti, migliorando la precisione delle stime. Tuttavia, richiede attenzione nel controllare gli effetti di ordine, come affaticamento o apprendimento, spesso attraverso il bilanciamento dell‚Äôordine di presentazione dei trattamenti.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Campionamento, metodologia sperimentale e studi osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_design.html#studi-osservazionali",
    "href": "chapters/key_notions/02_design.html#studi-osservazionali",
    "title": "2¬† Campionamento, metodologia sperimentale e studi osservazionali",
    "section": "2.5 Studi Osservazionali",
    "text": "2.5 Studi Osservazionali\nGli studi osservazionali possono essere classificati in:\n\nStudi Trasversali (Cross-Sectional)\nI dati vengono raccolti in un singolo momento. Utili per stimare la prevalenza di una condizione, ma non permettono di stabilire relazioni causali.\nStudi di Coorte (Cohort Studies)\nUn gruppo di individui (coorte) viene seguito nel tempo per osservare l‚Äôincidenza di un evento. Permettono di studiare la relazione tra esposizione e outcome, ma possono essere costosi e richiedere molto tempo.\nStudi Caso-Controllo (Case-Control Studies)\nVengono confrontati individui con una determinata condizione (casi) con individui senza la condizione (controlli) per identificare possibili fattori di rischio. Utili per studiare malattie rare, ma soggetti a bias di selezione e di ricordo.\n\nLe principali limitazioni degli studi osservazionali sono la presenza di variabili confondenti e la difficolt√† di stabilire relazioni causali.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Campionamento, metodologia sperimentale e studi osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_design.html#riflessioni-conclusive",
    "href": "chapters/key_notions/02_design.html#riflessioni-conclusive",
    "title": "2¬† Campionamento, metodologia sperimentale e studi osservazionali",
    "section": "2.6 Riflessioni Conclusive",
    "text": "2.6 Riflessioni Conclusive\nNel corso di questo capitolo, abbiamo esplorato l‚Äôimportanza del campionamento e delle diverse strategie di ricerca in psicologia, mettendo in luce i vincoli metodologici e le implicazioni derivanti da scelte spesso guidate dalle risorse a disposizione. Se da un lato i metodi di campionamento probabilistico garantiscono maggiore controllo sulla rappresentativit√† del campione, dall‚Äôaltro, la realt√† accademica e il contesto operativo di molti studi psicologici spingono verso soluzioni di comodo, inevitabilmente limitanti ma non per questo prive di valore scientifico.\nLe complessit√† intrinseche nello studio di fenomeni psicologici ‚Äì spesso universali e al tempo stesso influenzati da variabili culturali e individuali ‚Äì ci ricordano quanto sia importante mantenere un equilibrato senso critico. Da un punto di vista metodologico, l‚Äôesigenza di replicare gli studi in pi√π contesti rimane la prassi fondamentale per rafforzare la credibilit√† dei risultati. Altrettanto cruciale √® la volont√† di caratterizzare in modo trasparente i propri campioni, rendendo chiaro in che misura siano (o non siano) rappresentativi della popolazione d‚Äôinteresse. In tal modo, la comunit√† scientifica pu√≤ valutare con maggiore consapevolezza la trasferibilit√† delle conclusioni a contesti diversi.\nUn ulteriore spunto di riflessione riguarda la tensione tra la desiderabilit√† di disegni di ricerca ideali (con campioni estesi e probabilistici) e le inevitabili restrizioni di tempo e budget. Se l‚Äôimplementazione di studi su larga scala o a livello multicentrico consentirebbe di cogliere le sfumature culturali e socio-demografiche dei fenomeni, √® altrettanto vero che, nel panorama attuale, molte ricerche non potrebbero essere realizzate senza ricorrere a partecipanti di pi√π facile accesso, come gli studenti universitari o i volontari online. Tale flessibilit√† operativa pu√≤ comunque produrre conoscenza significativa, a condizione che il ricercatore rimanga vigile rispetto ai possibili bias introdotti.\nIn definitiva, l‚Äôinvito a chiunque conduca ricerche psicologiche √® quello di coltivare una mentalit√† aperta, volta a bilanciare i limiti contingenti (economici, logistici, etici) con la necessit√† di mantenere standard metodologici solidi. Ci√≤ implica sfruttare le potenzialit√† dell‚Äôintegrazione tra disegni sperimentali e osservazionali, prestare attenzione alle forme di bias e, soprattutto, adottare la replicazione come pratica sistematica. Solo attraverso questa sinergia fra rigore scientifico e consapevolezza delle risorse disponibili √® possibile far progredire la disciplina su basi empiriche sempre pi√π solide e generalizzabili.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Campionamento, metodologia sperimentale e studi osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_design.html#esercizi",
    "href": "chapters/key_notions/02_design.html#esercizi",
    "title": "2¬† Campionamento, metodologia sperimentale e studi osservazionali",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n\nPerch√© la fase di raccolta dei dati √® considerata ‚Äúnon neutrale‚Äù e quali conseguenze pu√≤ avere sull‚Äôaffidabilit√† dei risultati di una ricerca psicologica?\nIn che modo i diversi metodi di campionamento (probabilistico vs.¬†non probabilistico) influiscono sulla generalizzabilit√† delle conclusioni di uno studio e quali situazioni giustificano l‚Äôuso dell‚Äôuno o dell‚Äôaltro?\nQuali sono i principali rischi nell‚Äôadottare un campionamento di convenienza in ricerche psicologiche, e quali strategie si possono utilizzare per mitigare questi rischi?\nIn che modo la randomizzazione e l‚Äôuso di gruppi di controllo supportano l‚Äôinferenza causale in un disegno sperimentale, e perch√© queste caratteristiche sono spesso pi√π difficili da mantenere negli studi osservazionali?\nQuali sono i principali criteri da considerare quando si valuta la validit√† di uno studio in termini di campionamento, disegno di ricerca e replicabilit√†?\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n1. Perch√© la fase di raccolta dei dati √® considerata ‚Äúnon neutrale‚Äù e quali conseguenze pu√≤ avere sull‚Äôaffidabilit√† dei risultati di una ricerca psicologica?\nLa raccolta dei dati non √® mai un processo completamente neutrale perch√© comporta scelte metodologiche e pratiche che possono influenzare la qualit√† e la natura delle informazioni ottenute. Ad esempio:\n\nSelezione del campione: Scegliere chi includere o escludere nella ricerca incide sulla rappresentativit√† del campione. Un campione non rappresentativo pu√≤ produrre risultati distorti e difficilmente generalizzabili.\n\nModalit√† di somministrazione degli strumenti: La maniera in cui vengono somministrati questionari, test o interviste pu√≤ influire sulle risposte dei partecipanti (per esempio, differenze tra somministrazione online vs.¬†cartacea, questionari anonimi vs.¬†non anonimi, ecc.).\n\nContesto e tempistiche: Il contesto ambientale (es., rumori, distrazioni) o il momento in cui i dati vengono raccolti (es., in prossimit√† di esami universitari) possono influenzare lo stato emotivo o motivazionale dei partecipanti.\n\nCome conseguenza, tutte queste variabili possono introdurre bias ‚Äì ossia distorsioni sistematiche ‚Äì che compromettono l‚Äôaffidabilit√† e la validit√† dei risultati, rendendo l‚Äôinterpretazione dei dati pi√π complessa e potenzialmente fuorviante. In altre parole, se la fase di raccolta dati non √® accuratamente progettata e condotta, la ricerca potrebbe fornire conclusioni scorrette o di limitata utilit√† scientifica.\n2. In che modo i diversi metodi di campionamento (probabilistico vs.¬†non probabilistico) influiscono sulla generalizzabilit√† delle conclusioni di uno studio e quali situazioni giustificano l‚Äôuso dell‚Äôuno o dell‚Äôaltro?\n\nCampionamento probabilistico:\n\nOgni unit√† della popolazione ha una probabilit√† nota e non nulla di essere selezionata.\n\nMetodi come il campionamento casuale semplice, stratificato o a grappolo forniscono un quadro pi√π solido per stimare l‚Äôerrore di campionamento e minimizzare i bias.\n\nI risultati ottenuti sono, in linea di massima, pi√π facilmente generalizzabili all‚Äôintera popolazione di riferimento.\n\n√à preferibile in studi di larga scala, in cui esiste un buon frame di campionamento (lista esaustiva della popolazione) e le risorse (tempo, fondi) consentono di implementare un disegno rigoroso.\n\nCampionamento non probabilistico:\n\nLa probabilit√† di inclusione di un‚Äôunit√† non √® nota, per cui non si possono calcolare in modo rigoroso le stime di errore.\n\nIl metodo pi√π comune √® il campionamento di convenienza, in cui vengono reclutate persone facilmente accessibili (es., studenti universitari, volontari, piattaforme online).\n\nLa generalizzabilit√† dei risultati √® ridotta, poich√© il campione potrebbe non rispecchiare le caratteristiche della popolazione di interesse.\n\n√à spesso utilizzato per studi esplorativi, ricerche a budget limitato o quando non si dispone di un elenco completo della popolazione.\n\n\nIn sintesi, il campionamento probabilistico √® preferibile quando si mira a ottenere risultati solidi e generalizzabili a una popolazione pi√π ampia e le condizioni logistiche lo consentono. Il campionamento non probabilistico, invece, √® giustificato in studi preliminari, in situazioni in cui la popolazione non √® ben definita o difficilmente accessibile, o quando si hanno vincoli di risorse che rendono impraticabile un campionamento probabilistico.\n3. Quali sono i principali rischi nell‚Äôadottare un campionamento di convenienza in ricerche psicologiche, e quali strategie si possono utilizzare per mitigare questi rischi?\n\nPrincipali rischi:\n\nBias di selezione: I partecipanti reclutati con metodi di convenienza (ad es. studenti di psicologia) potrebbero non rispecchiare l‚Äôeterogeneit√† della popolazione generale, limitando la generalizzabilit√† dei risultati.\n\nOmogeneit√† del campione: Se il campione √® molto omogeneo (per et√†, livello di istruzione, contesto culturale), diventa difficile estendere le conclusioni a gruppi con caratteristiche diverse.\n\nAutoselezione: I volontari che si offrono di partecipare potrebbero differire sistematicamente da coloro che non partecipano (ad esempio, maggiore interesse per il tema della ricerca o per la ricompensa economica offerta).\n\nStrategie di mitigazione:\n\nSovra-campionamento: Includere deliberatamente pi√π partecipanti appartenenti a gruppi minoritari o sottorappresentati, per disporre di sottocampioni pi√π completi.\n\nReplicazione: Ripetere l‚Äôesperimento con campioni diversi (per et√†, contesto geografico, cultura) per verificare se i risultati si mantengono coerenti.\n\nDescrizione dettagliata del campione: Fornire informazioni precise sulle caratteristiche sociodemografiche (et√†, genere, livello di istruzione, ecc.) in modo che altri ricercatori o lettori possano valutare la trasferibilit√† dei risultati.\n\nCautela nell‚Äôinterpretazione: Esplicitare nelle conclusioni i limiti relativi alla natura del campionamento e invitare a considerare possibili fattori confondenti legati alla non rappresentativit√† del campione.\n\n\n4. In che modo la randomizzazione e l‚Äôuso di gruppi di controllo supportano l‚Äôinferenza causale in un disegno sperimentale, e perch√© queste caratteristiche sono spesso pi√π difficili da mantenere negli studi osservazionali?\n\nRandomizzazione:\n\nAssegna i partecipanti ai gruppi sperimentali (condizione sperimentale vs.¬†condizione di controllo) in maniera casuale.\n\nGarantisce che variabili potenzialmente confondenti vengano distribuite equamente tra i gruppi, aumentando la probabilit√† che eventuali differenze nelle misure di esito (variabile dipendente) siano dovute esclusivamente alla manipolazione sperimentale (variabile indipendente).\n\nQuesto processo riduce l‚Äôinfluenza di fattori esterni non misurati o non conosciuti, favorendo un‚Äôinferenza causale pi√π solida.\n\nGruppi di controllo:\n\nConsentono di confrontare i risultati di chi riceve il trattamento/intervento con chi non lo riceve (o riceve un trattamento placebo).\n\nAiutano a isolare l‚Äôeffetto ‚Äúvero‚Äù del trattamento dalle variazioni dovute a effetti psicologici (ad es. effetto placebo), al passare del tempo o a eventi esterni.\n\nDifficolt√† negli studi osservazionali:\n\nNon prevedono la manipolazione diretta di una variabile indipendente n√© l‚Äôassegnazione casuale dei partecipanti: le persone ‚Äúsi assegnano da sole‚Äù alle condizioni.\n\nManca il controllo sperimentale: non √® sempre possibile includere un gruppo di controllo o applicare procedure di randomizzazione.\n\nLe variabili confondenti possono agire in modo non controllabile e compromettere l‚Äôinterpretazione causale: anche con analisi statistiche sofisticate, √® difficile escludere del tutto la presenza di fattori esterni che influenzano la relazione tra esposizione e outcome.\n\n\nPer questi motivi, gli studi sperimentali (con randomizzazione e controllo) rimangono il metodo privilegiato per stabilire nessi di causalit√†, mentre gli studi osservazionali servono principalmente a generare ipotesi, descrivere fenomeni, o analizzare relazioni di associazione pi√π che di causalit√†.\n5. Quali sono i principali criteri da considerare quando si valuta la validit√† di uno studio in termini di campionamento, disegno di ricerca e replicabilit√†?\n\nRappresentativit√† del campione:\n\nIl campione rispecchia realmente le caratteristiche della popolazione di interesse?\n\n√à stato usato un metodo di campionamento appropriato (probabilistico vs.¬†non probabilistico)?\n\nControllo e randomizzazione (validit√† interna):\n\nLo studio ha previsto un disegno sperimentale con assegnazione casuale e gruppo di controllo?\n\nQuanto √® efficace il controllo delle variabili confondenti (bias di selezione, aspettative, effetto placebo, ecc.)?\n\nGeneralizzabilit√† o validit√† esterna:\n\nI risultati dello studio sono applicabili oltre il contesto specifico in cui √® stato condotto?\n\nVi sono limitazioni dovute all‚Äôuso di un campione di convenienza o di un contesto culturale molto particolare?\n\nStandardizzazione delle procedure:\n\nLe istruzioni, i tempi di raccolta dati, i materiali utilizzati sono stati gestiti in modo uniforme per tutti i partecipanti?\n\nReplicabilit√†:\n\n√à possibile ripetere lo studio (replicazione diretta o concettuale) e ottenere risultati simili?\n\nGli autori forniscono informazioni sufficienti (materiali, protocolli, analisi) per consentire la replicazione?\n\nChiarezza nell‚Äôesposizione dei limiti:\n\nGli autori discutono apertamente le limitazioni del metodo di campionamento o del disegno di ricerca e suggeriscono possibili miglioramenti per studi futuri?\n\n\nNel complesso, una valutazione critica di uno studio deve integrare tutti questi aspetti (campionamento, disegno, replicabilit√†) per stabilire in che misura i risultati siano solidi, attendibili e utilmente generalizzabili.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Campionamento, metodologia sperimentale e studi osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_design.html#bibliografia",
    "href": "chapters/key_notions/02_design.html#bibliografia",
    "title": "2¬† Campionamento, metodologia sperimentale e studi osservazionali",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nHenrich, J., Heine, S. J., & Norenzayan, A. (2010a). Most people are not WEIRD. Nature, 466(7302), 29‚Äì29.\n\n\nHenrich, J., Heine, S. J., & Norenzayan, A. (2010b). The weirdest people in the world? Behavioral and Brain Sciences, 33(2-3), 61‚Äì83.\n\n\nPeterson, R. A., & Merunka, D. R. (2014). Convenience samples of college students and research reproducibility. Journal of Business Research, 67(5), 1035‚Äì1041.\n\n\nTooby, J., & Cosmides, L. (2005). Evolutionary psychology: Conceptual foundations. In D. M. Buss (A c. Di), The Handbook of Evolutionary Psychology (pp. 5‚Äì67). Wiley.\n\n\nYouyou, W., Yang, Y., & Uzzi, B. (2023). A discipline-wide investigation of the replicability of Psychology papers over the past two decades. Proceedings of the National Academy of Sciences, 120(6), e2208863120.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Campionamento, metodologia sperimentale e studi osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_measurement.html",
    "href": "chapters/key_notions/03_measurement.html",
    "title": "3¬† La misurazione in psicologia",
    "section": "",
    "text": "3.1 Introduzione\nLa scienza si avvale di modelli per interpretare i dati, ma opera sempre con teorie incomplete e misurazioni soggette a errori. Di conseguenza, √® fondamentale riconoscere le incertezze quando si cerca di estrarre informazioni dalle misurazioni utilizzando i nostri modelli. Nessuna misurazione, spiegazione o previsione √® perfettamente accurata e precisa, e non possiamo mai conoscere con esattezza l‚Äôentit√† dei loro errori. Questo riconoscimento √® alla base della teoria della misurazione, che cerca di quantificare e gestire queste incertezze per migliorare la qualit√† delle nostre conclusioni scientifiche.\nQuesta incertezza viene catturata in tre equazioni fondamentali. La prima √® l‚ÄôEquazione di Misurazione, che riconosce l‚Äôerrore osservativo:\n\\[\ny = z + \\varepsilon_y,\n\\]\ndove \\(y\\) rappresenta il valore misurato, \\(z\\) il valore reale e \\(\\varepsilon_y\\) l‚Äôerrore di misurazione. La seconda √® l‚ÄôEquazione di Modellazione, che esprime la presenza di un diverso tipo di errore:\n\\[\nz = f(x, \\theta) + \\varepsilon_\\text{model},\n\\]\ndove \\(f\\) √® il modello, \\(x\\) sono le condizioni ambientali per cui eseguiamo il modello, \\(\\theta\\) sono i valori dei parametri del modello e \\(\\varepsilon_\\text{model}\\) rappresenta l‚Äôerrore del modello, che sorge perch√© \\(f\\), \\(x\\) e \\(\\theta\\) saranno tutti in qualche misura imprecisi.\nCombinando queste due equazioni, otteniamo l‚ÄôEquazione della Scienza:\n\\[\ny = f(x, \\theta) + \\varepsilon_\\text{model} + \\varepsilon_y.\n\\]\nLa scienza √® il tentativo di spiegare le osservazioni \\(y\\) utilizzando un modello \\(f\\), cercando di minimizzare l‚Äôerrore di misurazione \\(\\varepsilon_y\\) e l‚Äôerrore del modello \\(\\varepsilon_\\text{model}\\), in modo che il modello possa essere utilizzato per fare previsioni sul mondo reale (\\(z\\)). L‚Äôapproccio bayesiano alla scienza riconosce e quantifica le incertezze su tutti e sei gli elementi dell‚ÄôEquazione della Scienza: \\(y\\), \\(f\\), \\(x\\), \\(\\theta\\), \\(\\varepsilon_\\text{model}\\) e \\(\\varepsilon_y\\).",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_measurement.html#la-teoria-della-misurazione",
    "href": "chapters/key_notions/03_measurement.html#la-teoria-della-misurazione",
    "title": "3¬† La misurazione in psicologia",
    "section": "3.2 La teoria della Misurazione",
    "text": "3.2 La teoria della Misurazione\nLa teoria della misurazione, oggetto di questo capitolo, si concentra sull‚Äôerrore di misurazione e sull‚Äôequazione fondamentale \\(y = z + \\varepsilon_y\\). Questa equazione pu√≤ essere esaminata da tre prospettive distinte. La prima concerne l‚Äôaffidabilit√† della misura, rappresentata dal termine \\(\\varepsilon_y\\). La psicometria, branca dedicata alla teoria della misurazione psicologica, si occupa di quantificare l‚Äôaffidabilit√† delle misure psicologiche attraverso metodi come la Teoria Classica dei Test e la Teoria di Risposta all‚ÄôItem.\nLa seconda prospettiva riguarda la validit√† delle misure psicologiche, ovvero quanto adeguatamente la misura \\(y\\) rappresenti il costrutto \\(z\\). Questo aspetto, pi√π complesso dell‚Äôaffidabilit√†, non pu√≤ essere risolto meramente con metodi statistici, ma richiede una profonda comprensione delle teorie psicologiche e della loro capacit√† di descrivere e prevedere i fenomeni psicologici.\nLa terza prospettiva si concentra sulle procedure di assegnazione dei valori a \\(y\\), esplorando quali metodi (questionari, interviste, esperimenti) siano pi√π appropriati e come valutarne l‚Äôadeguatezza.\n\n3.2.1 Costrutti Psicologici\nLa teoria della misurazione sottolinea l‚Äôimportanza di distinguere tra la procedura di misurazione e il costrutto che si intende misurare. Ad esempio, mentre la temperatura √® un costrutto, il termometro √® lo strumento di misurazione. Analogamente, l‚Äôabilit√† matematica √® un costrutto, mentre un test di matematica √® la procedura per misurarla.\nNelle scienze psicologiche e sociali, la misurazione presenta sfide uniche rispetto alle scienze fisiche, poich√© i costrutti in esame sono spesso astratti e non direttamente osservabili. Ci√≤ richiede una particolare attenzione alla validit√† e all‚Äôaffidabilit√† degli strumenti di misurazione, nonch√© una costante riflessione sulle limitazioni e le potenziali fonti di errore.\nIl capitolo introduce concetti fondamentali relativi alla misurazione quantitativa delle caratteristiche psicologiche, con un focus sulla teoria delle scale di misura di Stevens (1946). Questa teoria fornisce un quadro concettuale per comprendere i diversi tipi di scale di misurazione e le operazioni matematiche appropriate per ciascuna. Inoltre, vengono esplorate alcune procedure di scaling psicologico, ovvero l‚Äôassegnazione di numeri all‚Äôintensit√† di fenomeni psicologici.\n\n\n3.2.2 Scaling Psicologico\nLo scaling psicologico si occupa della trasformazione dei dati empirici raccolti durante uno studio psicologico in misure o punteggi che rappresentino accuratamente le caratteristiche psicologiche oggetto di indagine.\nScaling di Guttman. Uno dei metodi di scaling pi√π noti √® lo ¬´Scaling di Guttman¬ª, che viene utilizzato per rappresentare relazioni ordinate tra gli elementi di una scala. Ad esempio, in un questionario sui sintomi dell‚Äôansia, le domande possono essere disposte in ordine di intensit√† crescente dei sintomi. Secondo il modello di Guttman, se un partecipante risponde ‚Äús√¨‚Äù a una domanda che riflette un sintomo pi√π intenso, ci si aspetta che abbia risposto ‚Äús√¨‚Äù anche a tutte le domande precedenti, che rappresentano sintomi di intensit√† minore. Questo approccio consente di costruire una scala che riflette in modo sistematico e coerente la gravit√† dei sintomi.\nScaling Thurstoniano. Lo ¬´Scaling Thurstoniano¬ª √® un metodo utilizzato per misurare preferenze o giudizi soggettivi. Ad esempio, per valutare la preferenza tra diversi tipi di cibi, i partecipanti confrontano due cibi alla volta ed esprimono una preferenza. Le risposte vengono poi utilizzate per assegnare punteggi che riflettono la preferenza media per ciascun cibo.\nScaling Fechneriano. Lo scaling fechneriano si basa sulla legge di Fechner, secondo cui la percezione di uno stimolo aumenta in modo logaritmico rispetto alla sua intensit√† fisica. La misura fondamentale √® la JND (Just Noticeable Difference), ovvero la minima differenza percepibile tra due stimoli. Secondo Fechner, sommando le JND si ottiene una scala psicologica dell‚Äôintensit√† percepita, utile per studiare grandezze sensoriali come luminosit√†, peso e suono (per es., Domini & Caudek, 2009).\nQuestionari Likert. I questionari Likert richiedono ai partecipanti di esprimere il loro grado di accordo con una serie di affermazioni su una scala a pi√π livelli, che va da ¬´fortemente in disaccordo¬ª a ¬´fortemente d‚Äôaccordo¬ª. I punteggi ottenuti vengono sommati per rappresentare la posizione complessiva dell‚Äôindividuo rispetto all‚Äôoggetto di studio.\n\n\n3.2.3 Metodi di Valutazione delle Scale Psicologiche\nPer valutare le propriet√† delle scale psicologiche, vengono utilizzati vari metodi. Ad esempio, l‚Äôaffidabilit√† delle misure pu√≤ essere analizzata utilizzando il coefficiente alpha di Cronbach o il coefficiente Omega di McDonald, entrambi utilizzati per misurare la coerenza interna delle risposte ai diversi item di un questionario. Inoltre, la validit√† delle scale pu√≤ essere esaminata confrontando i risultati ottenuti con misure simili o attraverso analisi statistiche che verificano se la scala cattura accuratamente il costrutto psicologico che si intende misurare. La validit√† di costrutto √® particolarmente cruciale, poich√© riguarda la capacit√† della scala di misurare effettivamente il concetto psicologico che si intende esplorare.\n\n\n3.2.4 Prospettive Moderne\nNegli ultimi anni, il dibattito sulla misurazione psicologica si √® arricchito di nuove prospettive, grazie all‚Äôavvento di tecnologie avanzate e all‚Äôintegrazione di approcci interdisciplinari. Ecco alcune delle tendenze pi√π rilevanti.\nTeoria della Risposta agli Item. La Teoria della Risposta agli Item (IRT) ha guadagnato popolarit√† per la sua capacit√† di fornire stime pi√π precise delle abilit√† latenti rispetto ai modelli classici. La IRT considera la probabilit√† che un individuo risponda correttamente a un item in funzione della sua abilit√† e delle caratteristiche dell‚Äôitem stesso, offrendo una visione pi√π dettagliata delle propriet√† psicometriche degli strumenti di misurazione.\nApprocci Bayesiani. Gli approcci bayesiani stanno rivoluzionando il campo della psicometria, permettendo di incorporare informazioni a priori nelle stime e di aggiornare le credenze sulla base di nuovi dati. Questi metodi sono particolarmente utili per affrontare la complessit√† e l‚Äôincertezza inerenti alla misurazione psicologica.\nAnalisi di Rete. L‚Äôanalisi di rete √® un‚Äôaltra metodologia emergente che vede i costrutti psicologici non come variabili latenti indipendenti, ma come reti di sintomi interconnessi. Questo approccio pu√≤ offrire nuove intuizioni sulla struttura delle psicopatologie e sulla dinamica dei sintomi.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_measurement.html#le-scale-di-misurazione",
    "href": "chapters/key_notions/03_measurement.html#le-scale-di-misurazione",
    "title": "3¬† La misurazione in psicologia",
    "section": "3.3 Le scale di misurazione",
    "text": "3.3 Le scale di misurazione\nLe scale di misurazione sono strumenti fondamentali per assegnare numeri ai dati osservati, rappresentando le propriet√† psicologiche. La teoria delle scale di Stevens (1946) identifica quattro tipi di scale di misurazione: nominali, ordinali, a intervalli e di rapporti. Ognuna di queste scale consente di effettuare operazioni aritmetiche diverse, poich√© ciascuna di esse √® in grado di ‚Äúcatturare‚Äù solo alcune delle propriet√† dei fenomeni psicologici che si intende misurare.\n\n\n\nScale di misurazione.\n\n\n\n3.3.1 Scala nominale\nLa scala nominale √® il livello di misurazione pi√π semplice e corrisponde ad una tassonomia o classificazione delle categorie che utilizziamo per descrivere i fenomeni psicologici. I simboli o numeri che costituiscono questa scala rappresentano i nomi delle categorie e non hanno alcun valore numerico intrinseco. Con la scala nominale possiamo solo distinguere se una caratteristica psicologica √® uguale o diversa da un‚Äôaltra.\nI dati raccolti con la scala nominale sono suddivisi in categorie qualitative e mutuamente esclusive, in cui ogni dato appartiene ad una sola categoria. In questa scala, esiste solo la relazione di equivalenza tra le misure delle unit√† di studio: gli elementi del campione appartenenti a classi diverse sono differenti, mentre tutti quelli della stessa classe sono tra loro equivalenti.\nL‚Äôunica operazione algebrica consentita dalla scala nominale √® quella di contare le unit√† di studio che appartengono ad ogni categoria e il numero totale di categorie. Di conseguenza, la descrizione dei dati avviene tramite le frequenze assolute e le frequenze relative.\nDalla scala nominale √® possibile costruire altre scale nominali equivalenti alla prima, trasformando i valori della scala di partenza in modo tale da cambiare i nomi delle categorie, ma lasciando inalterata la suddivisione delle unit√† di studio nelle medesime classi di equivalenza. In altre parole, cambiando i nomi delle categorie di una variabile misurata su scala nominale, si ottiene una nuova variabile esattamente equivalente alla prima.\n\n\n3.3.2 Scala ordinale\nLa scala ordinale mantiene la caratteristica della scala nominale di classificare ogni unit√† di misura all‚Äôinterno di una singola categoria, ma introduce la relazione di ordinamento tra le categorie. In quanto basata su una relazione di ordine, una scala ordinale descrive solo il rango di ordine tra le categorie e non fornisce informazioni sulla distanza tra di esse. Non ci dice, ad esempio, se la distanza tra le categorie \\(a\\) e \\(b\\) √® uguale, maggiore o minore della distanza tra le categorie \\(b\\) e \\(c\\).\nUn esempio classico di scala ordinale √® quello della scala Mohs per la determinazione della durezza dei minerali. Per stabilire la durezza dei minerali si usa il criterio empirico della scalfittura. Vengono stabiliti livelli di durezza crescente da 1 a 10 con riferimento a dieci minerali: talco, gesso, calcite, fluorite, apatite, ortoclasio, quarzo, topazio, corindone e diamante. Un minerale appartenente ad uno di questi livelli se scalfisce quello di livello inferiore ed √® scalfito da quello di livello superiore.\n\n\n\nLa scala di durezza dei minerali di Mohs. Un oggetto √® considerato pi√π duro di X se graffia X. Sono incluse anche misure di durezza relativa utilizzando uno sclerometro, da cui emerge la non linearit√† della scala di Mohs (Burchard, 2004).\n\n\n\n\n3.3.3 Scala ad intervalli\nLa scala ad intervalli di misurazione include le propriet√† della scala nominale e della scala ordinale e permette di misurare le distanze tra le coppie di unit√† statistiche in termini di un intervallo costante, chiamato ‚Äúunit√† di misura‚Äù, a cui viene attribuito il valore ‚Äú1‚Äù. L‚Äôorigine della scala, ovvero il punto zero, √® scelta arbitrariamente e non indica l‚Äôassenza della propriet√† che si sta misurando. Ci√≤ significa che la scala ad intervalli consente anche valori negativi e lo zero non viene attribuito all‚Äôunit√† statistica in cui la propriet√† risulta assente.\nLa scala ad intervalli equivalenti consente l‚Äôesecuzione di operazioni algebriche basate sulla differenza tra i numeri associati ai diversi punti della scala, operazioni algebriche non possibili con le scale di misura nominale o ordinale. Tuttavia, il limite della scala ad intervalli √® che non consente di calcolare il rapporto tra coppie di misure. √à possibile affermare la differenza tra \\(a\\) e \\(b\\) come la met√† della differenza tra \\(c\\) e \\(d\\) o che le due differenze sono uguali, ma non √® possibile affermare che \\(a\\) abbia una propriet√† misurata in quantit√† doppia rispetto a \\(b\\). In altre parole, non √® possibile stabilire rapporti diretti tra le misure ottenute. Solo le differenze tra le modalit√† permettono tutte le operazioni aritmetiche, come la somma, l‚Äôelevazione a potenza o la divisione, che sono alla base della statistica inferenziale.\nNelle scale ad intervalli equivalenti, l‚Äôunit√† di misura √® arbitraria e pu√≤ essere cambiata attraverso una dilatazione, ovvero la moltiplicazione di tutti i valori della scala per una costante positiva. Inoltre, la traslazione, ovvero l‚Äôaggiunta di una costante a tutti i valori della scala, √® ammessa poich√© non altera le differenze tra i valori della scala. La scala rimane invariata rispetto a traslazioni e dilatazioni e dunque le uniche trasformazioni ammissibili sono le trasformazioni lineari:\n\\[\ny' = a + by, \\quad b &gt; 0.\n\\]\nInfatti, l‚Äôuguaglianza dei rapporti fra gli intervalli rimane invariata a seguito di una trasformazione lineare.\nEsempio di scala ad intervalli √® la temperatura misurata in gradi Celsius o Fahrenheit, ma non Kelvin. Come per la scala nominale, √® possibile stabilire se due modalit√† sono uguali o diverse: \\(30^\\circ C \\neq 20^\\circ C\\). Come per la scala ordinale √® possibile mettere due modalit√† in una relazione d‚Äôordine: \\(30^\\circ C &gt; 20^\\circ C\\). In aggiunta ai casi precedenti, per√≤, √® possibile definire una unit√† di misura per cui √® possibile dire che tra \\(30^\\circ C\\) e \\(20^\\circ C\\) c‚Äô√® una differenza di \\(30^\\circ - 20^\\circ = 10^\\circ C\\). I valori di temperatura, oltre a poter essere ordinati secondo l‚Äôintensit√† del fenomeno, godono della propriet√† che le differenze tra loro sono direttamente confrontabili e quantificabili.\nIl limite della scala ad intervalli √® quello di non consentire il calcolo del rapporto tra coppie di misure. Ad esempio, una temperatura di \\(80^\\circ C\\) non √® il doppio di una di \\(40^\\circ C\\). Se infatti esprimiamo le stesse temperature nei termini della scala Fahrenheit, allora i due valori non saranno in rapporto di 1 a 2 tra loro. Infatti, \\(20^\\circ C = 68^\\circ F\\) e \\(40^\\circ C = 104^\\circ F\\). Questo significa che la relazione ‚Äúil doppio di‚Äù che avevamo individuato in precedenza si applicava ai numeri della scala centigrada, ma non alla propriet√† misurata (cio√® la temperatura). La decisione di che scala usare (Centigrada vs.¬†Fahrenheit) √® arbitraria. Ma questa arbitrariet√† non deve influenzare le inferenze che traiamo dai dati. Queste inferenze, infatti, devono dirci qualcosa a proposito della realt√† empirica e non possono in nessun modo essere condizionate dalle nostre scelte arbitrarie che ci portano a scegliere la scala Centigrada piuttosto che quella Fahrenheit.\nConsideriamo ora l‚Äôaspetto invariante di una trasformazione lineare, ovvero l‚Äôuguaglianza dei rapporti fra intervalli. Prendiamo in esame, ad esempio, tre temperature: \\(20^\\circ C = 68^\\circ F\\), \\(15^\\circ C = 59^\\circ F\\), \\(10^\\circ C = 50 ^\\circ F\\).\n√à facile rendersi conto del fatto che i rapporti fra intervalli restano costanti indipendentemente dall‚Äôunit√† di misura che √® stata scelta:\n\\[\n  \\frac{20^\\circ C - 10^\\circ C}{20^\\circ C - 15^\\circ C} =\n  \\frac{68^\\circ F - 50^\\circ F}{68^\\circ F-59^\\circ F} = 2.\n\\]\n\n\n3.3.4 Scala di rapporti\nNella scala a rapporti equivalenti, lo zero non √® arbitrario e rappresenta l‚Äôelemento che ha intensit√† nulla rispetto alla propriet√† misurata. Per costruire questa scala, si associa il numero 0 all‚Äôelemento con intensit√† nulla e si sceglie un‚Äôunit√† di misura \\(u\\). Ad ogni elemento si assegna un numero \\(a\\) definito come \\(a = d / u\\), dove \\(d\\) rappresenta la distanza dall‚Äôorigine. In questo modo, i numeri assegnati riflettono le differenze e i rapporti tra le intensit√† della propriet√† misurata.\nIn questa scala, √® possibile effettuare operazioni aritmetiche non solo sulle differenze tra i valori della scala, ma anche sui valori stessi della scala. L‚Äôunica scelta arbitraria √® l‚Äôunit√† di misura, ma lo zero deve sempre rappresentare l‚Äôintensit√† nulla della propriet√† considerata.\nLe trasformazioni ammissibili in questa scala sono chiamate trasformazioni di similarit√† e sono del tipo \\(y' = by\\), dove \\(b &gt; 0\\). In questa scala, i rapporti tra i valori rimangono invariati dopo le trasformazioni. In altre parole, se rapportiamo due valori originali e due valori trasformati, il rapporto rimane lo stesso: \\(\\frac{y_i}{y_j} = \\frac{y'_i}{y'_j}\\).",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_measurement.html#gerarchia-dei-livelli-delle-scale-di-misurazione",
    "href": "chapters/key_notions/03_measurement.html#gerarchia-dei-livelli-delle-scale-di-misurazione",
    "title": "3¬† La misurazione in psicologia",
    "section": "3.4 Gerarchia dei livelli delle scale di misurazione",
    "text": "3.4 Gerarchia dei livelli delle scale di misurazione\nSecondo Stevens (1946), esiste una gerarchia dei livelli delle scale di misurazione, denominati ‚Äúlivelli di scala‚Äù. Questi livelli sono organizzati in modo gerarchico, in cui la scala nominale rappresenta il livello pi√π basso della misurazione, mentre la scala a rapporti equivalenti rappresenta il livello pi√π alto.\n\nScala nominale: Classifica le categorie senza un ordine specifico.\nScala ordinale: Classifica le categorie in un ordine specifico, ma senza una misura precisa delle distanze.\nScala a intervalli: Misura le distanze tra le categorie con un intervallo costante, ma senza un punto zero assoluto.\nScala di rapporti: Misura le distanze con un intervallo costante e un punto zero assoluto.\n\n\n\n\nRelazioni tra i livelli di misurazione.\n\n\nPassando da un livello di misurazione ad uno pi√π alto aumenta il numero di operazioni aritmetiche che possono essere compiute sui valori della scala.\n\n3.4.1 Variabili Discrete e Continue\nLe variabili possono essere classificate come variabili a livello di intervalli o di rapporti e possono essere sia discrete che continue.\n\nVariabili discrete: Assumono valori specifici ma non possono assumere valori intermedi.\nVariabili continue: Possono assumere qualsiasi valore all‚Äôinterno di un intervallo specificato.\n\n\n\n\nVariabili discrete e continue.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_measurement.html#interazione-tra-teoria-sostanziale-e-misurazione-nella-ricerca-scientifica",
    "href": "chapters/key_notions/03_measurement.html#interazione-tra-teoria-sostanziale-e-misurazione-nella-ricerca-scientifica",
    "title": "3¬† La misurazione in psicologia",
    "section": "3.5 Interazione tra Teoria Sostanziale e Misurazione nella Ricerca Scientifica",
    "text": "3.5 Interazione tra Teoria Sostanziale e Misurazione nella Ricerca Scientifica\n\n3.5.1 Un caso studio sul mind-body healing\nUn esempio di lettura critica della letteratura scientifica √® offerto dall‚Äôanalisi di uno studio sul mind-body healing pubblicato su Nature Aungle & Langer (2023). La ricerca riporta miglioramenti nella salute fisica associati a pratiche mente-corpo, ma √® stata oggetto di severe critiche metodologiche da parte del statistico Andrew Gelman sul blog Statistical Modeling. Questo caso rivela due aspetti fondamentali spesso trascurati: il ruolo della teoria sostanziale e i criteri di misurazione rigorosa.\n\n\n3.5.2 La Teoria Sostanziale come Fondamento\nGelman evidenzia un deficit epistemologico centrale: l‚Äôassenza di un framework teorico convincente che spieghi i meccanismi causali ipotizzati. Senza una teoria che:\n\nDefinisca in modo univoco i costrutti (es.: ‚Äúguarigione mente-corpo‚Äù)\n\nIdentifichi pathways biologici o psicologici plausibili\n\nSi integri con conoscenze consolidate (es.: neuroscienze, immunologia),\n\ni risultati empirici perdono significato scientifico, rischiando di degenerare in quella che Gelman definisce ‚Äújunk science‚Äù. Una teoria solida non √® solo un optional descrittivo, ma una precondizione per:\n\nFormulare ipotesi verificabili\n\nInterpretare correlazioni in termini causali\n\nEvitare inferenze speculative o tautologiche.\n\n\n\n3.5.3 Criticit√† nella Misurazione\nLo studio presenta inoltre problemi operazionali rilevanti:\n\n3.5.3.1 A. Validit√† degli strumenti\n\nLa misurazione delle pratiche mente-corpo non controlla adeguatamente:\n\nFattori confondenti (aspettative dei partecipanti, effetto placebo)\n\nBias di autovalutazione\n\n\nGli outcome clinici utilizzano scale non validate, compromettendo la comparabilit√† dei risultati.\n\n\n\n3.5.3.2 Questioni di validit√†\n\nInterna: L‚Äôassenza di blinding e randomizzazione rigorosa mina l‚Äôattribuzione causale.\n\nEsterna: Campioni non rappresentativi limitano la generalizzabilit√† (per approfondimenti, si veda Capitolo 34).\n\nCome discusso nella letteratura metodologica (Accuracy and Precision), la qualit√† delle misurazioni determina direttamente l‚Äôaffidabilit√† delle conclusioni. Misure distorte o imprecise generano un ‚Äúrumore‚Äù statistico che oscura eventuali segnali reali.\n\n\n\n3.5.4 Verso una Valutazione Integrata\nLa lettura critica di questo articolo mostra come la critica scientifica deve simultaneamente considerare due piani:\n\n\n\n\n\n\n\nDimensione\nRischi di Negligenza\n\n\n\n\nTeorica\nInterpretazioni ad hoc, ipotesi non falsificabili\n\n\nOperativa\nArtefatti metodologici, misurazioni inadeguate, conclusioni spurie\n\n\n\nUna ricerca rigorosa richiede un circolo ermeneutico tra teoria e dati: le misurazioni devono testare ipotesi derivate da framework teorici, mentre i risultati empirici devono raffinare le teorie stesse. Senza questo dialogo, si cade nel dualismo sterile tra:\n\nEmpirismo na√Øve (raccolta dati acritica)\n\nTeorizzazione dogmatica (slegata dall‚Äôevidenza).\n\nIn sintesi, la lettura critica di articoli scientifici esige:\n\ncompetenza transdisciplinare (statistica, epistemologia, conoscenze del dominio),\nconsapevolezza sui limiti della misurazione di costrutti.\n\nCome illustrato nell‚Äôanalisi di Gelman, solo integrando valutazioni teoriche e metodologiche √® possibile distinguere scienza robusta da pseudoscienza. Questo approccio non √® meramente ‚Äúdifensivo‚Äù, ma costituisce il motore stesso del progresso scientifico, come approfondito nelle riflessioni su validit√† interna/esterna.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_measurement.html#riflessioni-conclusive",
    "href": "chapters/key_notions/03_measurement.html#riflessioni-conclusive",
    "title": "3¬† La misurazione in psicologia",
    "section": "3.6 Riflessioni Conclusive",
    "text": "3.6 Riflessioni Conclusive\nLa misurazione in psicologia non √® un semplice atto di raccolta di dati, ma un processo fondamentale per garantire che le osservazioni empiriche siano interpretabili alla luce di modelli teorici solidi. Una buona misurazione non si limita a ridurre l‚Äôerrore, ma consente di attribuire un significato coerente ai punteggi ottenuti, facilitando cos√¨ il progresso della conoscenza scientifica. Senza strumenti adeguati per la misurazione, il rischio √® quello di costruire teorie su basi incerte, compromettendo la validit√† delle conclusioni tratte.\nDue pilastri sostengono dunque una ricerca psicologica rigorosa: la teoria e la misurazione. La teoria fornisce il quadro concettuale entro cui si interpretano i dati, definendo le ipotesi e orientando le analisi. La misurazione, invece, √® il ponte tra i costrutti astratti e le osservazioni empiriche, traducendo concetti complessi in variabili operative affidabili. Nessuna delle due componenti pu√≤ reggersi senza l‚Äôaltra: una teoria senza misurazione adeguata rischia di rimanere speculativa, mentre una misurazione priva di un solido fondamento teorico pu√≤ portare a dati privi di significato.\nNella valutazione di un qualsiasi studio psicologico, un approccio critico richiede quindi di esaminare sia la solidit√† del quadro teorico sia la qualit√† degli strumenti di misurazione adottati. Il progresso della ricerca dipende dalla capacit√† di integrare questi due elementi, attraverso metodologie che riducano l‚Äôincertezza e migliorino la precisione delle inferenze. Le moderne tecniche di analisi dei dati, i modelli psicometrici avanzati e le tecnologie digitali stanno ampliando le possibilit√† di misurazione, offrendo strumenti pi√π sensibili e adattabili alla complessit√† dei fenomeni psicologici. Tuttavia, la sfida principale rimane la stessa: garantire che la misurazione sia non solo accurata, ma anche teoricamente fondata, affinch√© le conoscenze acquisite possano davvero contribuire alla comprensione della mente e del comportamento umano.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_measurement.html#esercizi",
    "href": "chapters/key_notions/03_measurement.html#esercizi",
    "title": "3¬† La misurazione in psicologia",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nEsercizio 1: Identificazione del Livello di Misurazione\nObiettivo: Comprendere i diversi livelli di misurazione applicati alla psicologia.\n\nIdentifica il livello di misurazione (nominale, ordinale, intervalli, rapporti) per ciascuna delle seguenti variabili psicologiche:\n\n\nTipo di terapia psicologica (Cognitivo-comportamentale, Psicodinamica, Umanistica)\n\n\nLivello di ansia auto-riferito su una scala da 1 a 10\n\n\nNumero di episodi depressivi in un anno\n\n\nTempo di reazione in millisecondi in un test cognitivo\n\n\n\nEsercizio 2: Confronto tra Scale\nObiettivo: Comprendere le differenze tra le scale di misurazione.\n\nSpiega la differenza tra una scala ordinale e una scala a intervalli utilizzando l‚Äôesempio della soddisfazione lavorativa.\nPerch√© il punteggio QI √® misurato su una scala a intervalli e non su una scala a rapporti?\nIn che modo il punteggio di una scala di autostima su una scala Likert differisce da una misurazione su una scala di rapporti?\n\nEsercizio 3: Operazioni Aritmetiche Consentite\nObiettivo: Comprendere le operazioni matematiche consentite per ciascun livello di misurazione.\n\nQuali operazioni aritmetiche sono ammissibili per una scala nominale?\nPu√≤ avere senso calcolare la media di punteggi su una scala ordinale? Perch√©?\nSe hai misurato il tempo di reazione in secondi, quali operazioni aritmetiche puoi eseguire?\n\nEsercizio 4: Trasformazioni Ammissibili\nObiettivo: Comprendere le trasformazioni possibili per ogni scala di misurazione.\n\nSe una variabile √® misurata su una scala nominale, quale tipo di trasformazione √® consentita?\nPer una scala a intervalli, quali trasformazioni matematiche sono permesse senza alterare le propriet√† della scala?\nQuale tipo di trasformazione √® consentita su una scala di rapporti?\n\nEsercizio 5: Applicazione delle Scale a Dati Psicologici\nObiettivo: Applicare i concetti a contesti psicologici reali.\n\nUna scala di ansia clinica fornisce punteggi compresi tra 0 e 100. Quale livello di misurazione √® pi√π appropriato e perch√©?\nUn esperimento misura la memoria dichiarativa chiedendo ai partecipanti di ricordare un elenco di parole. Come dovrebbe essere misurata la variabile ‚Äúnumero di parole ricordate‚Äù?\nIn uno studio sulla personalit√†, i tratti vengono classificati come ‚Äúestroverso‚Äù e ‚Äúintroverso‚Äù. Qual √® il livello di misurazione?\n\nEsercizio 6: Valutazione della Scala di Misurazione\nObiettivo: Identificare la corretta scala di misurazione per vari fenomeni psicologici.\n\nIl livello di aggressivit√† misurato su una scala da 1 a 5 √® nominale, ordinale, intervalli o rapporti? Giustifica la tua risposta.\nIl numero di attacchi di panico in una settimana pu√≤ essere considerato su scala ordinale? Perch√© s√¨ o perch√© no?\nUn test di intelligenza misura il QI con una media di 100 e una deviazione standard di 15. Qual √® il livello di misurazione e quali sono le implicazioni per l‚Äôanalisi statistica?\n\nEsercizio 7: Costruzione di una Scala Psicologica\nObiettivo: Creare una scala di misurazione per una variabile psicologica.\n\nSe dovessi costruire una scala per misurare la resilienza, quale livello di misurazione sceglieresti e perch√©?\nCome potresti trasformare una scala nominale di preferenza musicale in una scala ordinale?\nUn questionario sulla qualit√† della vita chiede ai partecipanti di valutare la loro felicit√† su una scala da 1 a 10. √à una scala a intervalli o ordinale? Giustifica.\n\nEsercizio 8: Interpretazione Statistica dei Dati\nObiettivo: Collegare il livello di misurazione alle tecniche statistiche appropriate.\n\nPerch√© una mediana √® pi√π appropriata della media per dati ordinali?\nQuale test statistico sarebbe pi√π adatto per confrontare due gruppi su una variabile nominale?\nQuali analisi possono essere condotte su dati raccolti su una scala a rapporti?\n\nEsercizio 9: Misurazione e Inferenze Psicologiche\nObiettivo: Riflettere su come il livello di misurazione influisce sulle conclusioni di una ricerca.\n\nSe un test di personalit√† usa una scala Likert da 1 a 7, quali precauzioni devono essere prese nell‚Äôinterpretare le differenze tra punteggi?\nUn questionario di benessere assegna punteggi tra 0 e 100, ma non ha uno zero assoluto. Quale scala √® questa e quali sono le limitazioni?\nIn uno studio sulla depressione, i sintomi vengono codificati come ‚Äúassenti‚Äù, ‚Äúmoderati‚Äù o ‚Äúgravi‚Äù. Che tipo di scala √® questa e quali statistiche possono essere usate per analizzarla?\n\nEsercizio 10: Esperimenti Psicologici e Misurazione\nObiettivo: Applicare la teoria della misurazione nella progettazione di esperimenti psicologici.\n\nSe un esperimento misura la memoria a breve termine con un compito di richiamo di parole, quale scala di misurazione utilizzeresti?\nCome la scelta della scala di misurazione pu√≤ influenzare le inferenze che si possono trarre da un esperimento?\nQuali tipi di analisi statistica sono appropriati per dati misurati su scala ordinale rispetto a scala di rapporti?\n\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\nEsercizio 1: Identificazione del Livello di Misurazione\nObiettivo: Comprendere i diversi livelli di misurazione applicati alla psicologia.\n\nIdentifica il livello di misurazione (nominale, ordinale, intervalli, rapporti) per ciascuna delle seguenti variabili psicologiche:\n\n\nNominale (Tipo di terapia psicologica √® una classificazione senza ordine)\n\n\nOrdinale (Scala da 1 a 10, con ordine ma senza distanze uguali)\n\n\nRapporti (Numero di episodi depressivi ha uno zero assoluto e si possono fare rapporti tra valori)\n\n\nRapporti (Tempo di reazione ha uno zero assoluto e permette operazioni di rapporto)\n\n\n\nEsercizio 2: Confronto tra Scale\nObiettivo: Comprendere le differenze tra le scale di misurazione.\n\nLa scala ordinale fornisce un ordine ma non permette di calcolare differenze precise, mentre la scala a intervalli ha differenze costanti tra i valori. Ad esempio, ‚Äúsoddisfazione lavorativa‚Äù su una scala da 1 a 5 √® ordinale, mentre il punteggio di un test psicologico √® a intervalli.\nIl punteggio QI √® a intervalli perch√© la differenza tra punteggi √® significativa, ma non ha uno zero assoluto che rappresenta l‚Äôassenza di intelligenza.\nUna scala Likert misura il livello di accordo con una dichiarazione, quindi √® generalmente considerata ordinale, nonostante sia trattata spesso come una scala a intervalli.\n\nEsercizio 3: Operazioni Aritmetiche Consentite\nObiettivo: Comprendere le operazioni matematiche consentite per ciascun livello di misurazione.\n\nNella scala nominale si pu√≤ solo contare la frequenza delle categorie (ad es., il numero di partecipanti che usano un tipo di terapia).\nNo, la media su dati ordinali pu√≤ essere fuorviante perch√© le distanze tra le categorie non sono necessariamente uguali. Meglio usare la mediana.\nSul tempo di reazione si possono eseguire tutte le operazioni aritmetiche, inclusa la media, la moltiplicazione e i rapporti tra valori.\n\nEsercizio 4: Trasformazioni Ammissibili\nObiettivo: Comprendere le trasformazioni possibili per ogni scala di misurazione.\n\nSulla scala nominale, solo le trasformazioni di ricodifica (ad esempio, cambiare i nomi delle categorie) sono permesse.\nPer una scala a intervalli, si possono effettuare trasformazioni lineari della forma y‚Äô = a + by con b &gt; 0.\nPer una scala di rapporti, sono consentite trasformazioni di similarit√† della forma y‚Äô = by, dove b &gt; 0.\n\nEsercizio 5: Applicazione delle Scale a Dati Psicologici\nObiettivo: Applicare i concetti a contesti psicologici reali.\n\nScala a intervalli, perch√© ha differenze costanti tra i punteggi ma nessuno zero assoluto.\nScala di rapporti, perch√© il numero di parole ricordate ha uno zero assoluto e consente operazioni di rapporto.\nNominale, perch√© non vi √® un ordine gerarchico tra le categorie ‚Äúestroverso‚Äù e ‚Äúintroverso‚Äù.\n\nEsercizio 6: Valutazione della Scala di Misurazione\nObiettivo: Identificare la corretta scala di misurazione per vari fenomeni psicologici.\n\nOrdinale, perch√© il livello di aggressivit√† segue un ordine, ma le differenze tra i livelli non sono necessariamente uguali.\nNo, perch√© il numero di attacchi di panico √® una variabile discreta e misurabile su scala di rapporti.\nIntervalli, perch√© il punteggio QI ha distanze costanti tra i valori, ma non ha uno zero assoluto.\n\nEsercizio 7: Costruzione di una Scala Psicologica\nObiettivo: Creare una scala di misurazione per una variabile psicologica.\n\nOrdinale o a intervalli, a seconda della precisione della misurazione della resilienza.\nSi potrebbe assegnare un valore numerico crescente alle categorie di preferenza musicale per ottenere una scala ordinale.\n√à una scala ordinale, perch√© la differenza tra livelli non √® necessariamente costante.\n\nEsercizio 8: Interpretazione Statistica dei Dati\nObiettivo: Collegare il livello di misurazione alle tecniche statistiche appropriate.\n\nPerch√© la mediana √® meno sensibile ai valori estremi rispetto alla media.\nUn test chi-quadrato √® adatto per confrontare frequenze di dati nominali tra gruppi.\nSi possono calcolare media, deviazione standard e utilizzare test parametrici come t-test o ANOVA.\n\nEsercizio 9: Misurazione e Inferenze Psicologiche\nObiettivo: Riflettere su come il livello di misurazione influisce sulle conclusioni di una ricerca.\n\nI punteggi Likert sono ordinali, quindi confronti tra differenze di punteggio devono essere interpretati con cautela.\nIntervalli, perch√© non ha uno zero assoluto, il che limita l‚Äôuso di operazioni moltiplicative.\nOrdinale, e si possono usare test non parametrici come il test di Kruskal-Wallis o il test di Mann-Whitney.\n\nEsercizio 10: Esperimenti Psicologici e Misurazione\nObiettivo: Applicare la teoria della misurazione nella progettazione di esperimenti psicologici.\n\nRapporti, perch√© il numero di parole ricordate √® una variabile discreta con uno zero assoluto.\nSe si usa una scala ordinale, bisogna essere cauti nell‚Äôuso della media e della deviazione standard.\nScala ordinale ‚Üí test non parametrici (Mann-Whitney); scala di rapporti ‚Üí test parametrici (t-test, ANOVA).\n\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nEsercizio 1 ‚Äì Teoria Sostanziale e ‚ÄúJunk Science‚Äù\nObiettivo: Riconoscere il ruolo di una teoria sostanziale solida e comprendere come la sua assenza possa compromettere uno studio.\n\nLeggi la sezione in cui Gelman critica l‚Äôassenza di una teoria solida nello studio sulle pratiche mente-corpo.\n\nSpiega, in massimo 10 righe, perch√© secondo Gelman la mancanza di una teoria coerente rende i risultati del suddetto studio ‚Äúpoco significativi‚Äù o addirittura ‚Äújunk science‚Äù.\n\nProponi un esempio ipotetico (non correlato al mind-body healing) di uno studio psicologico che, pur presentando dati numerosi e analizzati con metodi statistici sofisticati, risulti privo di una teoria solida. Descrivi sinteticamente perch√© questo potrebbe rientrare nel concetto di ‚Äújunk science‚Äù.\n\nEsercizio 2 ‚Äì Problemi di Misurazione\nObiettivo: Identificare le criticit√† pi√π comuni nella misurazione dei fenomeni psicologici.\n\nElenca almeno tre possibili fattori confondenti che potrebbero influenzare la misurazione dell‚Äôefficacia di un intervento psicologico (ad esempio, l‚Äôeffetto placebo, le aspettative dei partecipanti, ecc.).\n\nSpiega come questi fattori confondenti potrebbero compromettere la validit√† interna dello studio.\n\nIndica almeno due caratteristiche fondamentali che una buona scala di misurazione (per una variabile psicologica) dovrebbe possedere per essere ritenuta affidabile e valida.\n\nEsercizio 3 ‚Äì Precisione e Bias\nObiettivo: Chiarire la distinzione tra precisione e distorsione (bias) e come questi aspetti si riflettano nella validit√† delle conclusioni.\n\nDefinisci, con parole tue, i concetti di precisione e bias in ambito psicometrico.\nFornisci un esempio concreto di uno strumento di misura preciso ma distorto (bias elevato) e di uno strumento poco preciso ma non distorto (bias basso).\n\nSpiega come la combinazione di scarsa precisione e alto bias possa influire sulla possibilit√† di trarre conclusioni affidabili in uno studio psicologico.\n\nEsercizio 4 ‚Äì Validit√† Interna ed Esterna\nObiettivo: Approfondire come le scelte di misurazione influiscano sulla validit√† interna ed esterna di uno studio.\n\nIn riferimento allo studio sul mind-body healing discusso nel capitolo, identifica due fattori che potrebbero compromettere la validit√† interna e due fattori che potrebbero limitarne la validit√† esterna.\n\nDescrivi in 5-8 righe le differenze principali tra validit√† interna e validit√† esterna, utilizzando esempi presi sia dal contesto della guarigione mente-corpo sia da altri contesti psicologici (ad esempio, studi sull‚Äôapprendimento o sulla motivazione).\n\nProponi una modifica al disegno di ricerca (ipotetico) che potrebbe migliorare la validit√† interna dello studio originale. Spiega brevemente come questa modifica ne influenzerebbe anche la validit√† esterna.\n\nEsercizio 5 ‚Äì Integrare Teoria e Misurazione: Breve Progetto di Ricerca\nObiettivo: Mettere in pratica i concetti di teoria e misurazione attraverso la progettazione di uno studio.\n\nImmagina di voler condurre uno studio su un intervento di ‚Äútraining di rilassamento mentale‚Äù finalizzato a ridurre l‚Äôansia negli studenti universitari.\n\nSviluppa una breve traccia di progetto (massimo 15 righe) rispondendo ai seguenti punti:\n\nTeoria di base: Qual √® la teoria sostanziale dietro l‚Äôefficacia del training di rilassamento? Quali meccanismi psicologici verrebbero attivati?\n\nIpotesi: Quale effetto prevedi sull‚Äôansia degli studenti?\n\nMisurazione: Che tipo di strumento useresti per valutare il livello di ansia e perch√© (ad esempio, questionari self-report validati, misure fisiologiche come battito cardiaco, ecc.)?\n\nControllo dei confondenti: Quali variabili secondarie possono influire sui risultati e come intendi gestirle?\n\nValidit√†: Come assicureresti una buona validit√† interna? Che strategie adotteresti per aumentare la validit√† esterna?\n\nSpiega brevemente in che modo la combinazione di un solido quadro teorico e di una misurazione accurata permette di evitare che lo studio venga etichettato come ‚Äújunk science‚Äù.\n\n\n\n\n\n\n\n\n\n\nSoluzioni 2\n\n\n\n\n\nEsercizio 1 ‚Äì Teoria Sostanziale e ‚ÄúJunk Science‚Äù\n\nPerch√© la mancanza di una teoria solida rende i risultati poco significativi?\n\n\nGelman critica lo studio sul mind-body healing perch√© non vi √® un modello teorico convincente che spieghi il meccanismo causale tra pratiche mente-corpo e miglioramenti di salute.\n\nSenza un quadro teorico robusto, i risultati sono interpretati in modo esplorativo e rischiano di essere attribuiti a variabili non controllate (effetto placebo, regressione alla media, ecc.).\n\nUna teoria ben formulata aiuta a delimitare le ipotesi, guidare il disegno di ricerca e interpretare correttamente i dati. In assenza di ci√≤, i numeri raccolti potrebbero essere viziati da fattori confondenti o da semplici correlazioni spurious.\n\n\n‚ÄúJunk science‚Äù in massimo 10 righe\n\n\nEsempio di testo in 10 righe (circa)\n**Lo studio sul mind-body healing viene talvolta definito ‚Äújunk science‚Äù da Gelman perch√©, in mancanza di una teoria sostanziale solida, i dati raccolti non forniscono indicazioni chiare sui processi psicologici o fisiologici coinvolti. Una ricerca classificata come ‚Äújunk science‚Äù √® priva di rigore metodologico o teorico, e pu√≤ presentare gravi problemi di replicabilit√† o di interpretazione dei risultati. In particolare, se non vi √® un modello plausibile che colleghi in modo coerente la pratica mente-corpo ai cambiamenti in variabili biologiche e comportamentali, i risultati empirici rischiano di essere semplici coincidenze. L‚Äôassenza di un costrutto ben definito e di ipotesi derivanti da una teoria coerente rende difficile capire se i cambiamenti osservati siano reali, casuali o dovuti ad altre cause non considerate (per esempio, l‚Äôeffetto placebo). Infine, senza un‚Äôadeguata cornice teorica, gli studiosi non sanno come interpretare o generalizzare i dati, e la scienza non progredisce realmente.*\n\n\nEsempio di uno studio privo di teoria solida (ipotesi di ‚Äújunk science‚Äù)\n\n\nSituazione ipotetica: Uno studio che raccoglie decine di variabili sulla personalit√† e sul benessere, poi usa tecniche statistiche sofisticate (analisi di big data, reti neurali, ecc.) per trovare correlazioni fra i tratti di personalit√† e centinaia di indicatori fisici.\nPerch√© ‚Äújunk science‚Äù: Se lo studio non definisce a priori quali ipotesi testare e non ha una teoria chiara che spieghi perch√© certe caratteristiche di personalit√† dovrebbero correlarsi con determinati parametri fisici, i risultati trovati potrebbero essere frutto di coincidenze casuali. Inoltre, in assenza di un modello teorico solido, anche risultati statisticamente significativi possono essere privi di significato dal punto di vista psicologico.\n\nEsercizio 2 ‚Äì Problemi di Misurazione\n\nTre possibili fattori confondenti nell‚Äôefficacia di un intervento psicologico\n\n\nEffetto placebo: I partecipanti migliorano perch√© si aspettano di migliorare, non per l‚Äôeffettiva efficacia dell‚Äôintervento.\n\nAspettative dei partecipanti: Se sanno di partecipare a uno studio, potrebbero modificare il proprio comportamento (effetto Hawthorne).\n\nDesiderabilit√† sociale: I partecipanti forniscono risposte che ritengono socialmente desiderabili, falsando i risultati (ad esempio, sottostimando i livelli di ansia o stress).\n\n\nCome questi fattori confondenti compromettono la validit√† interna\n\n\nLa validit√† interna riguarda il grado in cui √® possibile concludere che sia effettivamente la variabile indipendente (l‚Äôintervento) a causare le modifiche osservate nella variabile dipendente (es. livelli di ansia).\n\nSe subentrano l‚Äôeffetto placebo, aspettative non controllate o tendenze alla desiderabilit√† sociale, diventa difficile stabilire un nesso causale chiaro. Esiste sempre il dubbio che altri processi cognitivi o sociali (non l‚Äôintervento in s√©) abbiano prodotto il risultato.\n\n\nDue caratteristiche fondamentali di una buona scala di misurazione\n\n\nAffidabilit√†: Capacit√† dello strumento di fornire misure stabili e coerenti nel tempo (ad esempio, coerenza interna, stabilit√† test-retest).\n\nValidit√†: Capacit√† dello strumento di misurare effettivamente ci√≤ che si propone di misurare (validit√† di contenuto, di costrutto, di criterio).\n\nEsercizio 3 ‚Äì Precisione e Bias\n\nDefinizioni di precisione e bias\n\n\nPrecisione: Indica il grado di dispersione (o variabilit√†) delle misurazioni. Uno strumento preciso produce misure molto simili fra loro se ripetute nelle stesse condizioni (bassa varianza).\n\nBias (distorsione): Indica l‚Äôerrore sistematico, ossia la tendenza a sovra- o sottostimare sistematicamente il fenomeno in esame. Uno strumento pu√≤ essere molto coerente nelle misure, ma se √® ‚Äútarato‚Äù male, dar√† sempre un risultato distorto.\n\n\nEsempio concreto di misura ‚Äúprecisa ma distorta‚Äù e ‚Äúpoco precisa ma non distorta‚Äù\n\n\nPrecisa ma distorta: Un cronometro che, a causa di un difetto di fabbricazione, parte sempre con 2 secondi di ritardo ma poi misura i tempi con estrema coerenza. Risultato: tutte le misure saranno molto simili (alta precisione), ma sempre sfasate di 2 secondi (alto bias).\n\nPoco precisa ma non distorta: Un termometro vecchio che a volte segna 36,2¬∞C, altre 36,7¬∞C, altre 37,1¬∞C, senza un pattern sistematico. In media potrebbe risultare vicino ai 36,5¬∞C, quindi senza un bias chiaro, ma con un‚Äôalta variabilit√† tra una misurazione e l‚Äôaltra (bassa precisione).\n\n\nConseguenze di scarsa precisione e alto bias\n\n\nSe uno strumento √® poco preciso (alta variabilit√†) e altamente distorto (bias elevato), i risultati ottenuti non solo oscillano in modo imprevedibile, ma sono costantemente lontani dal valore ‚Äúvero‚Äù.\n\nIn queste condizioni, le conclusioni diventano inaffidabili, poich√© √® quasi impossibile distinguere l‚Äôeffetto reale (casuale o causale) dalle deformazioni introdotte dallo strumento e dall‚Äôerrore di misura.\n\nEsercizio 4 ‚Äì Validit√† Interna ed Esterna\n\nDue fattori che compromettono la validit√† interna e due fattori che compromettono la validit√† esterna (nell‚Äôesempio del mind-body healing)\n\n\nValidit√† interna:\n\nAssegnazione non casuale ai gruppi: se i partecipanti scelgono autonomamente di aderire alle pratiche mente-corpo, potrebbero essere pi√π motivati o avere caratteristiche iniziali diverse.\n\nMancata o inadeguata gestione dell‚Äôeffetto placebo: non sapere se l‚Äôintervento ‚Äúmente-corpo‚Äù sia stato percepito come particolarmente ‚Äúspeciale‚Äù dai partecipanti pu√≤ introdurre differenze di aspettativa.\n\nValidit√† esterna:\n\nCampione non rappresentativo: se lo studio √® condotto solo su persone che frequentano un determinato tipo di centro di benessere, i risultati potrebbero non essere generalizzabili all‚Äôintera popolazione.\n\nContesto specifico: pratiche mente-corpo svolte in un ambiente estremamente controllato (es. un laboratorio o un ritiro speciale) potrebbero non replicarsi nella vita quotidiana di chiunque.\n\n\n\nDifferenze tra validit√† interna ed esterna (5-8 righe di esempio)\n\n\nLa validit√† interna si riferisce alla correttezza del disegno di ricerca nel dimostrare un effetto causale. Un alto livello di validit√† interna implica che i ricercatori siano ragionevolmente sicuri che l‚Äôintervento (ad esempio, una tecnica mente-corpo) abbia causato i risultati osservati (miglioramento della salute). La validit√† esterna, invece, riguarda la possibilit√† di generalizzare i risultati a contesti, persone e tempi differenti. Se un intervento √® stato testato in condizioni molto specifiche, potrebbe funzionare bene solo in quel contesto e con quel particolare campione. Per esempio, un intervento sul mind-body healing con individui altamente motivati potrebbe non dare gli stessi risultati in una popolazione generalizzata. Allo stesso modo, uno studio sull‚Äôapprendimento condotto in un laboratorio altamente controllato potrebbe non riflettere le reali dinamiche di un‚Äôaula scolastica.\n\n\nModifica al disegno di ricerca per migliorare la validit√† interna e conseguenze sulla validit√† esterna\n\n\nProposta: Introdurre un gruppo di controllo con un intervento placebo o un‚Äôattivit√† simile ma priva di contenuto ‚Äúmente-corpo‚Äù (ad es. sessioni di lettura rilassante). In questo modo, si pu√≤ confrontare l‚Äôeffetto ‚Äúspec√≠fico‚Äù dell‚Äôintervento.\nCome influenza la validit√† interna: Con un gruppo di controllo placebo, diventa pi√π semplice escludere che il miglioramento sia dovuto solo alle aspettative dei partecipanti. Questo riduce il rischio di confondenti e aumenta la validit√† interna.\nCome influenza la validit√† esterna: Potrebbe rendere il contesto dello studio pi√π artificiale (un gruppo fa ‚Äúmeditazione‚Äù, l‚Äôaltro legge in silenzio), il che potrebbe ridurre la naturalezza della situazione e potenzialmente limitare la generalizzabilit√† ad ambienti reali (validit√† esterna).\n\nEsercizio 5 ‚Äì Integrare Teoria e Misurazione: Breve Progetto di Ricerca\n\nBreve traccia di progetto: ‚ÄúTraining di rilassamento mentale per ridurre l‚Äôansia negli studenti universitari‚Äù\n\n\nTeoria di base\nIl training di rilassamento mentale si fonda sul presupposto teorico che le tecniche di riduzione dello stress (es. respirazione consapevole, rilassamento muscolare progressivo) possano agire sui livelli di attivazione fisiologica e sui pensieri intrusivi. Riducendo l‚Äôiperattivazione del sistema nervoso simpatico e favorendo uno stato di calma, diminuisce l‚Äôansia percepita.\nIpotesi\nGli studenti che seguono il training di rilassamento per 4 settimane mostreranno una riduzione significativa nei punteggi di ansia, rispetto a un gruppo di controllo che non partecipa al training.\nMisurazione\nUtilizzo di una scala validata come lo STAI (State-Trait Anxiety Inventory) per misurare il livello di ansia pre e post intervento. Possibile integrazione con misure fisiologiche (battito cardiaco a riposo) per avere dati oggettivi.\nControllo dei confondenti\n\nRegistrare la storia clinica dei partecipanti (per escludere coloro che assumono farmaci ansiolitici).\n\nRichiedere che i partecipanti non modifichino drasticamente le proprie abitudini di studio o di vita durante l‚Äôintervento.\n\nAssicurarsi che i valutatori non sappiano chi fa parte del gruppo di training o del gruppo di controllo (blinding parziale).\n\nValidit√†\n\nValidit√† interna: Uso di un gruppo di controllo e assegnazione casuale (randomizzazione) per assicurare che i due gruppi siano comparabili.\n\nValidit√† esterna: Inclusione di studenti provenienti da diverse facolt√†, cos√¨ da riflettere una maggiore eterogeneit√† di popolazione.\n\n\n\nCome teoria solida e misurazione accurata evitano la ‚Äújunk science‚Äù\n\n\nUna solida cornice teorica spiega i meccanismi psicologici e fisiologici che legano l‚Äôintervento (training di rilassamento) all‚Äôesito (riduzione dell‚Äôansia).\n\nUna misurazione accurata e validata (STAI, misure fisiologiche) riduce errori e distorsioni. Se le misure sono ripetute nel tempo (pre e post), si possono confrontare i cambiamenti effettivi.\n\nIntegrando teoria e misurazione, i risultati assumono un significato scientifico pi√π robusto. Non basta osservare un miglioramento: occorre dimostrare come e perch√© tale miglioramento avvenga, evitando di cadere in semplici correlazioni prive di spiegazione (e quindi potenzialmente ‚Äújunk science‚Äù).\n\n\n\n\n\n\n\n\n\n\nProblemi 3\n\n\n\n\n\nEsercizio 1 ‚Äì Trasformazioni in Scala Nominale\nSituazione\nUn ricercatore vuole indagare la percezione di appartenenza sociale tra studenti universitari di Psicologia. A ciascuno studente viene chiesto di rispondere alla domanda: ‚ÄúQual √® il gruppo studentesco a cui ritieni di appartenere maggiormente?‚Äù, scegliendo una tra le seguenti categorie:\n\n\nGruppo A (focalizzato su ricerca e studio)\n\n\n\nGruppo B (focalizzato su attivit√† ricreative)\n\n\n\nGruppo C (focalizzato su volontariato e progetti sociali)\n\n\nIstruzioni\n\nIdentifica la scala di misurazione utilizzata per classificare gli studenti (nominale, ordinale, a intervalli o di rapporti).\n\nIndica quali trasformazioni sono ammissibili su questa scala e spiega perch√© non √® possibile applicare operazioni di tipo aritmetico (somme, differenze, etc.).\n\nProponi un esempio di nuova scala nominale equivalente, ossia una nuova denominazione delle categorie che rispetti la suddivisione originale. (Esempio: rinominarle in Gruppo X, Gruppo Y, Gruppo Z, oppure usare colori, animali-simbolo, ecc.). Spiega perch√© questa trasformazione non altera i risultati dell‚Äôindagine.\n\nEsercizio 2 ‚Äì Trasformazioni in Scala Ordinale\nSituazione\nIn un questionario sul benessere psicologico, agli studenti viene chiesto di classificare il loro stato di motivazione allo studio su una scala da 1 (bassa motivazione) a 5 (alta motivazione). Si ottiene cos√¨ un dato ordinalmente misurato.\nIstruzioni\n\nSpiega perch√© tale variabile (‚Äúlivello di motivazione‚Äù) rappresenta una scala ordinale. Quali propriet√† la rendono diversa da una semplice scala nominale?\n\nDescrivi in che modo √® possibile ridenominare i valori della scala (ad esempio, da [1,2,3,4,5] a [‚ÄúMolto bassa‚Äù, ‚ÄúBassa‚Äù, ‚ÄúMedia‚Äù, ‚ÄúAlta‚Äù, ‚ÄúMolto alta‚Äù]) senza alterare il rapporto d‚Äôordine tra le categorie.\n\nProponi un esempio di trasformazione non ammissibile: qual √® un‚Äôoperazione aritmetica che non avrebbe senso applicare su una scala ordinale e perch√© (ad esempio, calcolare ‚Äúil doppio di motivazione‚Äù)?\n\nEsercizio 3 ‚Äì Trasformazioni in Scala ad Intervalli\nSituazione\nUn gruppo di ricercatori in Psicometria vuole confrontare i punteggi di un test d‚Äôintelligenza (misurati secondo la scala tradizionale del QI, con media 100 e deviazione standard 15) con un nuovo test sperimentale. Come ben noto, la scala del QI √® considerata, nelle sue approssimazioni psicometriche, una scala ad intervalli.\nIstruzioni\n\nSpiega in cosa consiste la trasformazione lineare ammessa (del tipo \\(y' = a + b y\\), con \\(b &gt; 0\\)) e perch√© tale trasformazione preserva le differenze tra i punteggi.\n\nFai un esempio concreto di trasformazione lineare: supponi di voler ‚Äúriscalare‚Äù i punteggi del QI in modo che la nuova media sia 50. Definisci i valori di \\(a\\) e \\(b\\) (indicando un‚Äôipotesi di calcolo) e mostra come viene modificato il punteggio di un individuo con QI = 115.\n\nDiscuta perch√©, nonostante la somiglianza con le scale ordinale e nominale (puoi comunque distinguere punteggi e ordinarli), una scala ad intervalli consente operazioni matematiche pi√π complesse (ad esempio, differenze) che non sarebbero valide negli altri due livelli.\n\nEsercizio 4 ‚Äì Trasformazioni in Scala di Rapporti\nSituazione\nUn laboratorio di psicofisiologia misura i tempi di reazione (in millisecondi) a uno stimolo luminoso. Poich√© il tempo di reazione pari a 0 ms significa realmente assenza di risposta (ovvero, impossibile da misurare in pratica, ma concettualmente corrisponde a intensit√† nulla del fenomeno ‚Äútempo di reazione‚Äù), ci troviamo in una scala di rapporti.\nIstruzioni\n\nSpiega perch√© il tempo di reazione soddisfa i requisiti di una scala di rapporti, inclusa la presenza di uno zero assoluto e la possibilit√† di confrontare i punteggi con rapporti (ad esempio, ‚Äúil tempo di reazione del partecipante A √® il doppio di quello del partecipante B‚Äù).\n\nQuali sono le trasformazioni ammissibili su una scala di rapporti? Fornisci un esempio numerico (per esempio, se moltiplichi tutti i tempi di reazione per 2, che cosa accade al rapporto tra i punteggi di due partecipanti?).\n\nDescrivi il motivo per cui √® possibile dire che A ha una latenza doppia di B usando i millisecondi, ma non √® sempre possibile fare asserzioni analoghe usando scale ad intervalli. Fai un parallelo, ad esempio, con le temperature in Celsius.\n\nEsercizio 5 ‚Äì Riconoscere e Applicare le Trasformazioni nei Quattro Livelli di Scala\nSituazione\nUn docente di Psicologia sperimentale ha raccolto quattro serie di dati su vari aspetti:\n\nOrientamento politico (liberale, conservatore, centrista, ecc.).\n\nClassifica di soddisfazione sul tirocinio (1¬∞ posto, 2¬∞ posto, 3¬∞ posto, etc.).\n\nPunteggi di un test di personalit√† su un fattore (con media = 100, deviazione standard = 10) trattato come scala ad intervalli.\n\nFrequenza cardiaca a riposo misurata in battiti al minuto (bpm).\n\nIstruzioni\n\nIdentifica per ciascuno dei quattro insiemi di dati il livello di scala (nominale, ordinale, intervalli, rapporti).\n\nPer ognuno dei quattro livelli di scala elenca almeno una trasformazione ammessa (ad es. ridenominazione delle categorie per la nominale, traslazione e dilatazione per l‚Äôintervalli, ecc.) e una non ammessa (esempio: non puoi sommare categorie nominali, non puoi calcolare la radice quadrata di un rango ordinale dandogli significato, ecc.).\n\nRifletti in breve (2-3 righe) su come queste differenze nelle trasformazioni ammissibili incidano sull‚Äôinterpretazione dei dati e sulle analisi statistiche che il docente potr√† validamente utilizzare (ad esempio, test non parametrici per variabili ordinarie, test parametrici per scale ad intervalli/rapporti).\n\n\n\n\n\n\n\n\n\n\nSoluzioni 3\n\n\n\n\n\nEsercizio 1 ‚Äì Trasformazioni in Scala Nominale\n\nIdentificazione della scala La classificazione degli studenti in ‚ÄúGruppo A/B/C‚Äù √® scala nominale. Non esiste alcun ordine intrinseco tra le categorie; si tratta semplicemente di etichette qualitative.\nTrasformazioni ammissibili\n\n\nTrasformazioni ammissibili: ridenominare o rinominare le categorie senza modificare la partizione del campione (esempio: A ‚Üí ‚ÄúStudio‚Äù, B ‚Üí ‚ÄúRicreazione‚Äù, C ‚Üí ‚ÄúVolontariato‚Äù).\n\nL‚Äôunica operazione aritmetica consentita √® il conteggio delle frequenze nelle varie categorie.\n\n\nOperazioni non consentite: non √® possibile sommare o sottrarre etichette, n√© confrontare categorie in termini di ‚Äúpi√π/meno grande‚Äù o ‚Äúrapporto‚Äù.\n\n\nEsempio di nuova scala nominale equivalente\n\n\nPotresti chiamare i gruppi: ‚ÄúAlpha, Beta, Gamma‚Äù (oppure con colori: ‚ÄúRosso, Blu, Verde‚Äù).\n\nQuesta trasformazione non altera la classificazione in s√©: tutti gli studenti del Gruppo A rimangono nel ‚Äúnuovo‚Äù gruppo Alpha, e cos√¨ via.\n\nNon cambia la struttura dei dati e di conseguenza non altera i risultati della ricerca (restano invariate le frequenze e la suddivisione nelle categorie).\n\nEsercizio 2 ‚Äì Trasformazioni in Scala Ordinale\n\nPerch√© √® una scala ordinale? La variabile ‚Äúlivello di motivazione‚Äù da 1 (bassa) a 5 (alta) indica:\n\n\nClassificazione in categorie (come in una scala nominale).\n\nRelazione d‚Äôordine chiara (1 &lt; 2 &lt; 3 &lt; 4 &lt; 5).\n\nNon fornisce alcuna informazione sulle distanze reali tra i punti (non √® detto che la differenza tra 1 e 2 sia uguale a quella tra 3 e 4).\n√à quindi una scala ordinale e non semplicemente nominale.\n\n\nRidenominazione dei valori mantenendo l‚Äôordine\n\n\nPuoi sostituire i numeri con etichette testuali rispettando lo stesso ordine:\n1 ‚Üí ‚ÄúMolto bassa‚Äù\n2 ‚Üí ‚ÄúBassa‚Äù\n3 ‚Üí ‚ÄúMedia‚Äù\n4 ‚Üí ‚ÄúAlta‚Äù\n5 ‚Üí ‚ÄúMolto alta‚Äù\n\nL‚Äôordine rimane lo stesso: ‚ÄúMolto bassa‚Äù &lt; ‚ÄúBassa‚Äù &lt; ‚Ä¶ &lt; ‚ÄúMolto alta‚Äù.\n\n\nEsempio di trasformazione non ammissibile\n\n\nCalcolare ‚Äúil doppio di motivazione‚Äù: dire che la categoria 4 √® ‚Äúil doppio‚Äù della categoria 2 non ha senso, perch√© non c‚Äô√® un‚Äôunit√† di misura fissa che quantifichi la differenza tra i livelli. Le categorie ordinali servono solo a ordinare, non a quantificare in modo assoluto.\n\nEsercizio 3 ‚Äì Trasformazioni in Scala ad Intervalli\n\nTrasformazione lineare ammessa\n\n\nForma generale: \\(y' = a + b y\\), con \\(b &gt; 0\\).\n\nPreserva le differenze tra i valori (ad esempio, \\((y_2 - y_1) = (y'_2 - y'_1) / b\\)), perch√© la traslazione aggiunge una costante a tutti i punteggi e la dilatazione (moltiplicazione per \\(b\\)) mantiene le proporzioni fra gli intervalli.\n\n\nEsempio concreto\n\n\nScala QI: media = 100, deviazione standard = 15.\n\nVuoi che la nuova media sia 50.\n\nPer semplificare, supponiamo di voler ‚Äúspostare‚Äù ogni valore verso una nuova scala centrata a 50, mantenendo una deviazione standard proporzionale.\n\nUna possibile trasformazione lineare:\n\\[\n  y' = (y - 100) + 50 = y - 50.\n\\]\nIn questo caso, \\(a = -50\\), \\(b = 1\\).\n\nSe un individuo ha QI = 115, allora \\(y' = 115 - 50 = 65\\).\n\n\nSe invece volessi anche cambiare la deviazione standard, potresti usare un fattore \\(b \\neq 1\\). Ad esempio, se desideri una deviazione standard = 10, potresti usare \\(b = \\frac{10}{15} \\approx 0.67\\).\n\n\nDifferenze rispetto alle scale nominali/ordinali\n\n\nCon una scala ad intervalli puoi:\n\nOrdinare i punteggi.\n\nStabilire differenze (es. un individuo A ha 15 punti in pi√π di B).\n\n\nNon puoi invece stabilire rapporti (es. ‚ÄúA ha il doppio di X rispetto a B‚Äù non √® lecito), perch√© lo zero √® arbitrario e la distanza ‚Äú0‚Äù non rappresenta l‚Äôassenza del fenomeno (come invece avviene nella scala di rapporti).\n\nEsercizio 4 ‚Äì Trasformazioni in Scala di Rapporti\n\nPerch√© il tempo di reazione √® in una scala di rapporti?\n\n\nZero assoluto: un tempo di reazione (teoricamente) pari a 0 ms significherebbe nessun tempo trascorso ‚Üí totale assenza del fenomeno misurato (impossibile nella pratica, ma concettualmente definisce uno zero non arbitrario).\n\nPuoi confrontare i punteggi con rapporti: ‚Äúil tempo di reazione di A √® il doppio di quello di B‚Äù (200 ms vs.¬†100 ms).\n\n\nTrasformazioni ammissibili\n\n\nTrasformazione di similarit√†: \\(y' = b y\\) con \\(b &gt; 0\\).\n\nSe hai due tempi di reazione \\(y_1\\) e \\(y_2\\), il rapporto \\(\\frac{y_1}{y_2}\\) rimane invariato anche dopo la trasformazione:\n\\[\n  \\frac{y'_1}{y'_2} = \\frac{b y_1}{b y_2} = \\frac{y_1}{y_2}.\n\\]\nEsempio numerico: se i tempi di reazione di due partecipanti sono 100 ms e 200 ms, il rapporto √® 2. Se moltiplichi entrambi per 2, ottieni 200 ms e 400 ms, e il rapporto rimane 2.\n\n\nConfronto con scala ad intervalli (esempio delle temperature)\n\n\nIn una scala di rapporti puoi dire ‚ÄúA ha una latenza doppia di B‚Äù perch√© lo zero non √® arbitrario.\n\nCon la temperatura (scala ad intervalli) lo zero (es. 0¬∞C) non rappresenta l‚Äôassenza di calore, quindi non ha senso dire che 80¬∞C √® ‚Äúil doppio‚Äù di 40¬∞C. Cambiando la scala (ad es. Fahrenheit) il rapporto cambia.\n\nEsercizio 5 ‚Äì Riconoscere e Applicare le Trasformazioni nei Quattro Livelli di Scala\n\nIdentificazione del livello di scala\n\n\nOrientamento politico: scala nominale (categorie qualitative prive di ordine).\n\nClassifica di soddisfazione (1¬∞, 2¬∞, 3¬∞, ‚Ä¶): scala ordinale (c‚Äô√® un ordine, ma non si conosce la ‚Äúdistanza‚Äù fra i posti).\n\nPunteggi di un test di personalit√† (con media=100, dev.st=10), considerati approssimazione di una scala ad intervalli (si assumono le differenze significative, lo zero √® arbitrario).\n\nFrequenza cardiaca a riposo (bpm): scala di rapporti (zero assoluto e rapporti confrontabili).\n\n\nTrasformazioni ammesse e non ammesse\n\n\nNominale:\n\nAmmessa: cambiare etichette (A ‚Üí ‚ÄúLiberale‚Äù, B ‚Üí ‚ÄúConservatore‚Äù ecc.).\n\nNon ammessa: sommare categorie, ordinare, calcolare media delle categorie.\n\n\nOrdinale:\n\nAmmessa: rietichettare i ranghi (1¬∞ ‚Üí ‚ÄúMigliore‚Äù, 2¬∞ ‚Üí ‚ÄúSecondo posto‚Äù‚Ä¶).\n\nNon ammessa: calcolare rapporti (il 2¬∞ posto non √® ‚Äúil doppio‚Äù del 1¬∞), sommare posizioni in modo significativo.\n\n\nA intervalli:\n\nAmmessa: trasformazione lineare (traslazione + dilatazione).\n\nNon ammessa: dire che un punteggio √® ‚Äútre volte‚Äù un altro; lo zero √® arbitrario.\n\n\nA rapporti:\n\nAmmessa: trasformazione di similarit√† (\\(y' = b y\\)), in cui i rapporti rimangono invariati.\n\nNon ammessa: aggiunta di una costante a tutti i valori (questa sposterebbe lo zero, rendendolo arbitrario e trasformando la scala in una scala ad intervalli).\n\n\n\nImplicazioni per l‚Äôinterpretazione e le analisi\n\n\nUna variabile nominale consente solo frequenze e test non parametrici basati su conteggi (es. Chi-quadrato).\n\nUna variabile ordinale permette test di ordinamento (es. test di rank, come il Wilcoxon), ma non calcoli di media con significato forte.\n\nUna scala ad intervalli permette di usare statistiche parametriche (calcolo di media, varianza, test come t-test, ANOVA), assumendo che l‚Äôinterpretazione delle differenze sia coerente.\n\nUna scala di rapporti permette, in pi√π, il confronto di rapporti (ad esempio, si possono applicare modelli parametrici che includano il concetto di proporzioni o slope logico su dati che abbiano senso a zero assoluto).",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_measurement.html#bibliografia",
    "href": "chapters/key_notions/03_measurement.html#bibliografia",
    "title": "3¬† La misurazione in psicologia",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAungle, P., & Langer, E. (2023). Physical healing as a function of perceived time. Scientific Reports, 13(1), 22432.\n\n\nDomini, F., & Caudek, C. (2009). The intrinsic constraint model and Fechnerian sensory scaling. Journal of Vision, 9(2), 25‚Äì25.\n\n\nLilienfeld, S. O., & Strother, A. N. (2020). Psychological measurement and the replication crisis: Four sacred cows. Canadian Psychology/Psychologie Canadienne, 61(4), 281‚Äì288.\n\n\nMaul, A., Irribarra, D. T., & Wilson, M. (2016). On the philosophical foundations of psychological measurement. Measurement, 79, 311‚Äì320.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/04_data_analysis.html",
    "href": "chapters/key_notions/04_data_analysis.html",
    "title": "4¬† La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana",
    "section": "",
    "text": "Introduzione\nNegli ultimi vent‚Äôanni, le scienze sociali e la psicologia hanno vissuto una profonda trasformazione metodologica ed epistemologica. Questo cambiamento, spesso definito come ‚ÄúCredibility Revolution‚Äù (Angrist & Pischke, 2010), ‚ÄúCausal Revolution‚Äù (Pearl & Mackenzie, 2018) e ‚ÄúReplication Crisis‚Äù (Collaboration, 2015; Nosek et al., 2022), ha portato a un ripensamento delle pratiche di ricerca, specialmente in psicologia (Korbmacher et al., 2023). Questa transizione verso quella che Munger (2023) chiama ‚ÄúScience versione 2‚Äù √® stata motivata dalla consapevolezza di lacune metodologiche passate e ha spinto verso l‚Äôadozione di approcci pi√π rigorosi e replicabili.\nLe origini di questa riforma risiedono nel riconoscimento di problemi metodologici diffusi, come la proliferazione di falsi positivi (Simmons et al., 2011), l‚Äôabuso dei ‚Äúgradi di libert√† dei ricercatori‚Äù (Gelman & Loken, 2013), e l‚Äôinadeguatezza delle pratiche statistiche tradizionali (Gelman & Loken, 2014). Fenomeni come il p-hacking, l‚Äôuso di campioni di piccole dimensioni (Button et al., 2013), e la mancanza di trasparenza nei metodi di ricerca hanno contribuito a minare la credibilit√† delle scoperte psicologiche (Ioannidis, 2005; Meehl, 1967), portando alla cosiddetta ‚ÄúReplication Crisis‚Äù (Baker, 2016; Bishop, 2019) ‚Äî si veda il Capitolo 79.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/04_data_analysis.html#lapproccio-bayesiano",
    "href": "chapters/key_notions/04_data_analysis.html#lapproccio-bayesiano",
    "title": "4¬† La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana",
    "section": "4.1 L‚ÄôApproccio Bayesiano",
    "text": "4.1 L‚ÄôApproccio Bayesiano\nIn risposta a queste sfide, l‚Äôapproccio bayesiano √® emerso come un paradigma statistico chiave nella ‚ÄúCredibility Revolution‚Äù. A differenza dell‚Äôinferenza frequentista, che si basa sul Test dell‚ÄôIpotesi Nulla, la statistica bayesiana offre un framework pi√π flessibile e intuitivo per l‚Äôanalisi dei dati e l‚Äôinferenza causale. Il principio fondamentale dell‚Äôapproccio bayesiano √® l‚Äôaggiornamento delle distribuzioni di probabilit√† a priori (priors) alla luce di nuove evidenze, un processo che si allinea con l‚Äôobiettivo di una scienza cumulativa e auto-correttiva.\nL‚Äôadozione di metodi bayesiani in psicologia presenta numerosi vantaggi:\n\nQuantificazione dell‚Äôincertezza: L‚Äôinferenza bayesiana fornisce distribuzioni di probabilit√† posteriori complete per i parametri di interesse, offrendo una rappresentazione pi√π ricca e sfumata dell‚Äôincertezza rispetto agli intervalli di confidenza frequentisti.\nIncorporazione di conoscenze pregresse: Le priors bayesiane permettono di integrare formalmente conoscenze precedenti nel processo inferenziale, promuovendo un approccio cumulativo alla ricerca.\nRobustezza alle pratiche di ricerca discutibili: I metodi bayesiani sono meno suscettibili a pratiche come il p-hacking, poich√© l‚Äôinferenza si basa sull‚Äôintera distribuzione posteriore piuttosto che su soglie arbitrarie di significativit√†.\n\n\n4.1.1 Vantaggi e Applicazioni\nL‚Äôutilizzo delle statistiche bayesiane nella ricerca psicologica presenta notevoli vantaggi rispetto ai metodi statistici tradizionali, come i test di significativit√† basati sull‚Äôipotesi nulla. Uno dei principali punti di forza risiede nella sua indipendenza dalla teoria dei grandi campioni, rendendolo particolarmente adatto a studi con dimensioni campionarie ridotte, una condizione frequente in psicologia (Larson et al., 2023).\n\n4.1.1.1 Sfide dei Campioni Piccoli in Psicologia\nLa ricerca psicologica spesso si confronta con campioni limitati a causa di:\n\nBassa prevalenza di condizioni specifiche (es. disturbi rari);\n\nDifficolt√† nel reclutamento (es. popolazioni difficili da raggiungere);\n\nComplessit√† procedurali (es. valutazioni longitudinali o multimodali).\n\nQuesti campioni, oltre a essere numericamente ridotti, sono spesso caratterizzati da elevata eterogeneit√†, che si manifesta in:\n\nVariabilit√† fenotipica: Differenze comportamentali tra individui con la stessa condizione psicologica;\n\nDiscrepanza tra studi: Stime degli effetti divergenti in ricerche simili.\nTali fattori possono generare distorsioni nelle stime e risultati scarsamente riproducibili.\n\n\n\n4.1.1.2 Vantaggi dell‚ÄôApproccio Bayesiano\n\nValutazione dell‚ÄôAdeguatezza del Campione\n\nAttraverso l‚Äôanalisi di sensibilit√† delle distribuzioni a priori, √® possibile valutare quanto i risultati dipendano dalle assunzioni iniziali, identificando campioni troppo piccoli o ipotesi troppo influenti.\n\nPrecisione con Dati Limitati\n\nL‚Äôintegrazione di conoscenze a priori ben definite (es. dati di studi precedenti) permette di ottenere stime robuste anche con piccoli campioni, compensando la carenza di dati attraverso informazioni esterne.\n\nInclusione Equa di Popolazioni Sottorappresentate\n\nL‚Äôapproccio bayesiano riduce la necessit√† di campioni molto numerosi, evitando la pressione sul reclutamento di gruppi minoritari (es. minoranze etniche). Questo favorisce una ricerca pi√π equa e rappresentativa, senza sacrificare la validit√† statistica.\n\n\n\n\n4.1.1.3 Impatto sulla Riproducibilit√† e Politiche di Ricerca\nIn sintesi, la capacit√† di gestire l‚Äôeterogeneit√† e di ottimizzare l‚Äôuso dei dati rende il metodo bayesiano uno strumento chiave per affrontare la crisi di riproducibilit√† in psicologia. Inoltre, promuove politiche inclusive, riducendo barriere etiche e pratiche legate al sovra-reclutamento di gruppi vulnerabili.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/04_data_analysis.html#modellazione-formale-e-data-science",
    "href": "chapters/key_notions/04_data_analysis.html#modellazione-formale-e-data-science",
    "title": "4¬† La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana",
    "section": "4.2 Modellazione Formale e Data Science",
    "text": "4.2 Modellazione Formale e Data Science\nLa ‚ÄúCredibility Revolution‚Äù ha favorito l‚Äôintegrazione della Data Science nelle pratiche di ricerca psicologica. L‚Äôadozione di pipeline di analisi dei dati riproducibili, l‚Äôuso di controllo di versione e la condivisione di dati e codice sono diventati standard de facto nella comunit√† scientifica. Questi strumenti non solo migliorano la trasparenza e la replicabilit√† della ricerca, ma facilitano anche la collaborazione e l‚Äôaccumulo di conoscenze nel campo.\nParallelamente, si √® osservato un rinnovato interesse per la modellazione formale in psicologia, che consente non solo la verifica ma anche lo sviluppo di modelli dei meccanismi sottostanti ai fenomeni psicologici (Oberauer & Lewandowsky, 2019; Van Dongen et al., 2024). Questo approccio supera la mera descrizione delle associazioni tra variabili, tipica della pratica dominante dell‚ÄôANOVA nel contesto pre-riforma.\nLa modellazione bayesiana si presta particolarmente bene a questo approccio, offrendo un framework unificato per la specificazione di modelli formali, l‚Äôincorporazione di incertezza parametrica e la valutazione dell‚Äôevidenza empirica. Attraverso tecniche come il confronto tra modelli bayesiano e l‚Äôanalisi di sensibilit√†, i ricercatori possono valutare rigorosamente la plausibilit√† relativa di diverse teorie psicologiche.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/04_data_analysis.html#riflessioni-epistemologiche",
    "href": "chapters/key_notions/04_data_analysis.html#riflessioni-epistemologiche",
    "title": "4¬† La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana",
    "section": "4.3 Riflessioni Epistemologiche",
    "text": "4.3 Riflessioni Epistemologiche\nL‚Äôadozione di metodi bayesiani e della Data Science in psicologia deve essere accompagnata da una profonda riflessione epistemologica. Come sottolineato da George Box:\n\nTutti i modelli sono sbagliati, ma alcuni sono utili.\n\nQuesta massima risuona particolarmente nel contesto della ricerca psicologica, dove i fenomeni di interesse sono spesso complessi e multifattoriali.\nL‚Äôapproccio bayesiano, con la sua enfasi sull‚Äôaggiornamento iterativo delle credenze alla luce di nuove evidenze, si allinea naturalmente con una visione della scienza come processo di apprendimento continuo piuttosto che come ricerca di verit√† assolute. Questa prospettiva riconosce i limiti intrinseci dei nostri modelli e delle nostre teorie, pur valorizzandone l‚Äôutilit√† euristica e predittiva.\nIn particolare, McElreath (2020) sottolinea l‚Äôimportanza di riconoscere la dualit√† tra il ‚Äúmondo del modello‚Äù e il mondo reale pi√π ampio che cerchiamo di comprendere. Questa consapevolezza √® cruciale per evitare la reificazione dei nostri modelli statistici e per mantenere una prospettiva critica sulle nostre inferenze.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/04_data_analysis.html#riflessioni-conclusive",
    "href": "chapters/key_notions/04_data_analysis.html#riflessioni-conclusive",
    "title": "4¬† La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana",
    "section": "4.4 Riflessioni Conclusive",
    "text": "4.4 Riflessioni Conclusive\nL‚Äôintegrazione dell‚Äôapproccio bayesiano e della Data Science nella ricerca psicologica rappresenta una risposta promettente alle sfide poste dalla ‚ÄúReplication Crisis‚Äù. Offrendo un framework coerente per la modellazione formale, l‚Äôinferenza statistica e l‚Äôincorporazione di conoscenze pregresse, questi approcci promettono di elevare il rigore e la credibilit√† della ricerca psicologica. Tuttavia, √® fondamentale che l‚Äôadozione di questi metodi sia accompagnata da una adeguata consapevolezza metodologica ed epistemologica.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/04_data_analysis.html#esercizi",
    "href": "chapters/key_notions/04_data_analysis.html#esercizi",
    "title": "4¬† La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n\nQuali sono i principali fattori che hanno portato alla ‚ÄúCredibility Revolution‚Äù in psicologia e in che modo le nuove metodologie ‚Äî in particolare l‚Äôapproccio bayesiano e le buone pratiche di Data Science ‚Äî mirano a superare i limiti che hanno contribuito alla ‚ÄúReplication Crisis‚Äù?\nIn che modo il paradigma bayesiano differisce dall‚Äôapproccio frequentista nella gestione dell‚Äôincertezza e nell‚Äôaggiornamento della conoscenza, e quali vantaggi pratici offre quando si lavora con campioni di piccole dimensioni e popolazioni eterogenee?\nQual √® il ruolo delle distribuzioni a priori nelle analisi bayesiane e come ci si assicura che l‚Äôuso di priors non introduca bias indesiderati, specialmente in un contesto come quello psicologico dove le teorie e i dati pregressi possono essere incompleti o controversi?\nPerch√© la modellazione formale e le buone pratiche di Data Science (ad es. condivisione di codice, controllo di versione, pipeline riproducibili) risultano fondamentali per una scienza cumulativa e per mitigare gli errori sistematici nella ricerca psicologica?\nDal punto di vista epistemologico, in che modo il principio ‚Äútutti i modelli sono sbagliati, ma alcuni sono utili‚Äù influenza la costruzione, la valutazione e l‚Äôinterpretazione dei modelli in psicologia, e come si integra con la prospettiva bayesiana di scienza come processo iterativo di apprendimento?\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n1. Quali sono i principali fattori che hanno portato alla ‚ÄúCredibility Revolution‚Äù in psicologia e in che modo le nuove metodologie ‚Äî in particolare l‚Äôapproccio bayesiano e le buone pratiche di Data Science ‚Äî mirano a superare i limiti che hanno contribuito alla ‚ÄúReplication Crisis‚Äù?\nNegli ultimi decenni, la psicologia ha attraversato una ‚ÄúReplication Crisis‚Äù a causa di diverse pratiche di ricerca problematiche, tra cui l‚Äôutilizzo di campioni di piccole dimensioni, l‚Äôuso eccessivo di test di significativit√† frequentisti con p &lt; .05 come soglia rigida, il fenomeno del p-hacking (cio√® l‚Äôadattamento delle analisi per ottenere risultati ‚Äúsignificativi‚Äù), e la carenza di trasparenza e condivisione dei dati. Questi fattori hanno portato alla pubblicazione di molti falsi positivi e a un‚Äôerosione della fiducia nelle conclusioni psicologiche.\nLa ‚ÄúCredibility Revolution‚Äù nasce dalla presa di coscienza di questi problemi e dall‚Äôintroduzione di nuove metodologie che offrono maggior rigore e trasparenza. L‚Äôapproccio bayesiano, in particolare, consente di superare alcuni limiti della statistica frequentista, poich√© fornisce distribuzioni posteriori di plausibilit√† per i parametri e non si affida a soglie arbitrarie di significativit√†. Inoltre, la Data Science ha promosso la diffusione di pipeline analitiche riproducibili (tramite il controllo di versione, la condivisione del codice e dei dati), contribuendo a ridurre errori, bias e a favorire la replicabilit√†. Insieme, queste innovazioni mirano a creare una scienza pi√π aperta, solida e cumulativa.\n2. In che modo il paradigma bayesiano differisce dall‚Äôapproccio frequentista nella gestione dell‚Äôincertezza e nell‚Äôaggiornamento della conoscenza, e quali vantaggi pratici offre quando si lavora con campioni di piccole dimensioni e popolazioni eterogenee?\nIl paradigma frequentista si basa sull‚Äôidea di ripetizione ipotetica degli esperimenti e sull‚Äôapplicazione di test di significativit√†, focalizzandosi su p-value e intervalli di confidenza che rispondono a domande ‚Äúse si ripetesse infinite volte l‚Äôesperimento, in media cosa accadrebbe?‚Äù. L‚Äôinferenza bayesiana, al contrario, concepisce la probabilit√† come uno stato di conoscenza (o di credenza) e integra le informazioni precedenti (priors) con i dati osservati per produrre una distribuzione posteriore. Ci√≤ consente un aggiornamento continuo e iterativo delle ipotesi alla luce delle nuove evidenze.\nQuesta impostazione risulta particolarmente utile quando i campioni sono ridotti e le popolazioni indagate sono eterogenee. In tali condizioni, il paradigma frequentista rischia di generare stime instabili o intervalli di confidenza molto ampi. L‚Äôapproccio bayesiano, invece, permette di incorporare informazioni pregresse e di ottenere stime pi√π precise, a patto che le priors siano giustificate e non eccessivamente informative. L‚Äôattenzione alla distribuzione posteriore rende inoltre pi√π chiaro il grado di incertezza associato ai parametri di interesse e favorisce la formulazione di inferenze pi√π calibrate.\n3. Qual √® il ruolo delle distribuzioni a priori nelle analisi bayesiane e come ci si assicura che l‚Äôuso di priors non introduca bias indesiderati, specialmente in un contesto come quello psicologico dove le teorie e i dati pregressi possono essere incompleti o controversi?\nNell‚Äôapproccio bayesiano, le distribuzioni a priori (priors) rappresentano la conoscenza o le ipotesi iniziali di cui si dispone sui parametri in esame prima di raccogliere i dati. Se ben specificate, contribuiscono a rendere l‚Äôanalisi pi√π informativa, soprattutto quando il campione √® di piccole dimensioni. Tuttavia, un uso improprio delle priors pu√≤ introdurre bias, poich√© priors troppo ‚Äúforti‚Äù (ossia eccessivamente vincolanti) possono spingere i risultati verso determinate conclusioni.\nPer evitare questi rischi, i ricercatori devono adottare priors ben motivate e trasparenti. In psicologia, dove le teorie possono essere ancora in fase di sviluppo e i dati pregressi non sempre affidabili, √® spesso utile iniziare con priors non informative o debolmente informative, per ridurre il rischio di forzare troppo il modello. √à anche fondamentale effettuare analisi di sensibilit√†: testare differenti specificazioni di priors per verificare se i risultati sono robusti oppure fortemente dipendenti da particolari assunzioni iniziali. La documentazione delle scelte fatte (e le relative ragioni) √® parte integrante di una buona pratica di ricerca trasparente.\n4. Perch√© la modellazione formale e le buone pratiche di Data Science (ad es. condivisione di codice, controllo di versione, pipeline riproducibili) risultano fondamentali per una scienza cumulativa e per mitigare gli errori sistematici nella ricerca psicologica?\nLa modellazione formale consente di superare la mera descrizione delle relazioni tra variabili (tipica dell‚ÄôANOVA o dei modelli lineari tradizionali) e di entrare nel merito dei meccanismi sottostanti i fenomeni psicologici, costruendo teorie pi√π articolate e fondate. Questa prospettiva rende pi√π esplicite le assunzioni e le ipotesi su cui si basa la ricerca, permettendo un confronto chiaro tra diverse spiegazioni concorrenti.\nParallelamente, l‚Äôadozione di strumenti e pratiche di Data Science come la condivisione di codice (in repository pubblici), l‚Äôuso del controllo di versione (es. Git) e pipeline analitiche riproducibili riducono gli errori e favoriscono la verifica indipendente dei risultati. Ci√≤ aumenta la trasparenza, poich√© altri ricercatori possono ispezionare i passaggi compiuti, e consente la replicazione degli studi. In una scienza cumulativa, infatti, la possibilit√† di riprodurre, criticare e migliorare i risultati di lavori precedenti √® essenziale per costruire un corpus di conoscenze solido e affidabile.\n5. Dal punto di vista epistemologico, in che modo il principio ‚Äútutti i modelli sono sbagliati, ma alcuni sono utili‚Äù influenza la costruzione, la valutazione e l‚Äôinterpretazione dei modelli in psicologia, e come si integra con la prospettiva bayesiana di scienza come processo iterativo di apprendimento?\nLa celebre frase di George Box (‚Äútutti i modelli sono sbagliati, ma alcuni sono utili‚Äù) evidenzia come i modelli statistici e teorici non possano mai rappresentare perfettamente la realt√†, specialmente in un campo complesso come la psicologia, in cui le variabili spesso interagiscono in modo non lineare e multi-dimensionale. Ci√≤ non significa che i modelli siano inutili; anzi, se ben costruiti, possono offrire uno strumento potente per interpretare e prevedere i fenomeni.\nNell‚Äôottica bayesiana, la costruzione dei modelli √® un processo iterativo in cui le ipotesi iniziali (priors) vengono continuamente aggiornate alla luce di nuove evidenze (la distribuzione posteriore). Questo ciclo di apprendimento riflette un‚Äôidea di scienza non come ricerca della ‚Äúverit√† assoluta‚Äù, ma come progressivo affinamento delle teorie. Il principio di Box ricorda ai ricercatori che qualsiasi modello deve essere costantemente messo alla prova, confrontato con altri modelli, e aggiornato o abbandonato se i dati non lo supportano pi√π. In questo senso, la prospettiva bayesiana favorisce una mentalit√† flessibile e aperta, pronta a rivedere i propri presupposti e a migliorare progressivamente la comprensione dei fenomeni psicologici.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/04_data_analysis.html#bibliografia",
    "href": "chapters/key_notions/04_data_analysis.html#bibliografia",
    "title": "4¬† La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAngrist, J. D., & Pischke, J.-S. (2010). The credibility revolution in empirical economics: How better research design is taking the con out of econometrics. Journal of economic perspectives, 24(2), 3‚Äì30.\n\n\nBaker, M. (2016). 1,500 scientists lift the lid on reproducibility. Nature, 533(7604).\n\n\nBishop, D. (2019). The psychology of experimental psychologists: Overcoming cognitive constraints to improve research.\n\n\nButton, K. S., Ioannidis, J. P., Mokrysz, C., Nosek, B. A., Flint, J., Robinson, E. S., & Munaf√≤, M. R. (2013). Power failure: why small sample size undermines the reliability of neuroscience. Nature Reviews Neuroscience, 14(5), 365‚Äì376.\n\n\nCollaboration, O. S. (2015). Estimating the reproducibility of psychological science. Science, 349(6251), aac4716.\n\n\nGelman, A., & Loken, E. (2013). The garden of forking paths: Why multiple comparisons can be a problem, even when there is no ¬´fishing expedition¬ª or ¬´p-hacking¬ª and the research hypothesis was posited ahead of time. Department of Statistics, Columbia University, 348(1-17), 3.\n\n\nGelman, A., & Loken, E. (2014). The statistical crisis in science. American scientist, 102(6), 460‚Äì465.\n\n\nIoannidis, J. P. (2005). Why most published research findings are false. PLoS medicine, 2(8), e124.\n\n\nKorbmacher, M., Azevedo, F., Pennington, C. R., Hartmann, H., Pownall, M., Schmidt, K., Elsherif, M., Breznau, N., Robertson, O., Kalandadze, T., et al. (2023). The replication crisis has led to positive structural, procedural, and community changes. Communications Psychology, 1(1), 3.\n\n\nLabatut, B. (2021). Quando abbiamo smesso di capire il mondo. Adelphi Edizioni spa.\n\n\nLarson, C., Kaplan, D., Girolamo, T., Kover, S. T., & Eigsti, I.-M. (2023). A Bayesian statistics tutorial for clinical research: Prior distributions and meaningful results for small clinical samples. Journal of Clinical Psychology, 79(11), 2602‚Äì2624.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nMeehl, P. E. (1967). Theory-testing in psychology and physics: A methodological paradox. Philosophy of science, 34(2), 103‚Äì115.\n\n\nMunger, K. (2023). Temporal validity as meta-science. Research & Politics, 10(3), 20531680231187271.\n\n\nNosek, B. A., Hardwicke, T. E., Moshontz, H., Allard, A., Corker, K. S., Dreber, A., Fidler, F., Hilgard, J., Kline Struhl, M., Nuijten, M. B., et al. (2022). Replicability, robustness, and reproducibility in psychological science. Annual Review of Psychology, 73(1), 719‚Äì748.\n\n\nOberauer, K., & Lewandowsky, S. (2019). Addressing the theory crisis in psychology. Psychonomic Bulletin & Review, 26, 1596‚Äì1618.\n\n\nPearl, J., & Mackenzie, D. (2018). The book of why: the new science of cause and effect. Basic books.\n\n\nSimmons, J. P., Nelson, L. D., & Simonsohn, U. (2011). False-positive psychology: Undisclosed flexibility in data collection and analysis allows presenting anything as significant. Psychological science, 22(11), 1359‚Äì1366.\n\n\nVan Dongen, N., Bork, R. van, Finnemann, A., Haslbeck, J., Maas, H. L. van der, Robinaugh, D. J., Ron, J. de, Sprenger, J., & Borsboom, D. (2024). Productive explanation: A framework for evaluating explanations in psychological science. Psychological Review.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/05_cognitive_models.html",
    "href": "chapters/key_notions/05_cognitive_models.html",
    "title": "5¬† Modelli cognitivi",
    "section": "",
    "text": "5.1 Introduzione\nIn questo corso esploreremo perch√© un‚Äôanalisi puramente associativa tra variabili non sia sufficiente per comprendere i meccanismi causali nei fenomeni psicologici. Una strategia pi√π efficace consiste nel formalizzare quantitativamente i modelli dei processi psicologici di interesse e testarli empiricamente.\nPer rendere concreto il concetto di processo generatore dei dati in psicologia, introdurremo due modelli psicologici fondamentali: il modello di apprendimento associativo di Rescorla-Wagner e il Drift-Diffusion Model.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Modelli cognitivi</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/05_cognitive_models.html#modello-di-apprendimento-associativo-di-rescorla-wagner",
    "href": "chapters/key_notions/05_cognitive_models.html#modello-di-apprendimento-associativo-di-rescorla-wagner",
    "title": "5¬† Modelli cognitivi",
    "section": "\n5.2 Modello di Apprendimento Associativo di Rescorla-Wagner",
    "text": "5.2 Modello di Apprendimento Associativo di Rescorla-Wagner\nUno dei modelli pi√π influenti nello studio dell‚Äôapprendimento √® il modello di Rescorla-Wagner. Questo modello descrive come gli individui apprendano le associazioni tra stimoli e risposte sulla base dell‚Äôerrore di previsione. L‚Äôapprendimento avviene aggiornando le aspettative di ricompensa in base alle esperienze passate, utilizzando due parametri fondamentali:\n\n\nŒ± (tasso di apprendimento): determina quanto l‚Äôerrore di previsione influisce sull‚Äôaggiornamento dell‚Äôaspettativa.\n\nŒ≤ (temperatura della scelta): regola la probabilit√† di selezionare l‚Äôopzione con il valore atteso pi√π alto rispetto a esplorare alternative.\n\n\n5.2.1 L‚ÄôApprendimento Associativo\nL‚Äôapprendimento per rinforzo studia come le persone imparano a massimizzare le ricompense in ambienti in cui la scelta ottimale √® inizialmente sconosciuta. Immaginiamo un partecipante che deve scegliere ripetutamente tra due slot machine, ricevendo ricompense con probabilit√† diverse per ogni macchina. L‚Äôobiettivo √® massimizzare le vincite nel tempo.\nPer illustrare il modello, si usa spesso la metafora delle slot machine. Nel caso pi√π semplice, si immagina un agente che svolge il compito con \\(n\\) tentativi, due slot machine e probabilit√† di ricompensa fisse \\(\\mu = [0.2, 0.8]\\).\n\n5.2.2 Regola di Apprendimento per Rinforzo (\\(\\delta\\)-rule)\nIl modello di Rescorla-Wagner descrive l‚Äôapprendimento come un processo basato sull‚Äôerrore di previsione. L‚Äôaggiornamento del valore di uno stimolo avviene secondo la seguente equazione:\n\\[\nV_{s,t} = V_{s,t-1} + \\alpha (r_{t-1} - V_{s,t-1})\n\\]\nDove:\n\n\n\\(V_{s,t}\\) √® il valore atteso dello stimolo \\(s\\) al tempo \\(t\\).\n\n\\(r_{t-1}\\) √® la ricompensa ottenuta alla prova precedente.\n\n\\(\\alpha\\) (tra 0 e 1) √® il tasso di apprendimento, che determina la velocit√† con cui l‚Äôagente aggiorna le proprie aspettative.\n\nSe il valore di \\(\\alpha\\) √® alto, l‚Äôapprendimento sar√† rapido, mentre se √® basso, l‚Äôagente si baser√† maggiormente sulle esperienze passate.\n\n5.2.3 Modello di Scelta: Softmax\nDopo aver aggiornato i valori attesi delle opzioni, il partecipante deve scegliere tra esse.\nDue strategie possibili sono:\n\n\nSfruttamento: selezionare sempre l‚Äôopzione con il valore pi√π alto.\n\nEsplorazione: scegliere occasionalmente un‚Äôopzione con un valore pi√π basso per verificare se potrebbe essere migliore.\n\nPer modellare questo comportamento si usa la funzione Softmax:\n\\[\np(s) = \\frac{\\exp(\\beta \\cdot V_{s})}{\\sum_i \\exp(\\beta \\cdot V_{i})}\n\\]\nDove \\(\\beta\\) √® un parametro che determina il grado di esplorazione:\n\n\n\\(\\beta = 0\\): scelta completamente casuale.\n\n\\(\\beta \\to \\infty\\): scelta deterministica dell‚Äôopzione con il valore pi√π alto.\n\nUn individuo con \\(\\beta\\) alto sceglier√† quasi sempre l‚Äôopzione con il valore atteso pi√π elevato, mentre con un \\(\\beta\\) basso esplorer√† pi√π frequentemente.\n\n5.2.4 Simulazione dell‚ÄôApprendimento con il Modello di Rescorla-Wagner\nPossiamo implementare la regola di aggiornamento in R con la seguente funzione:\n\nupdate_rw &lt;- function(value, alpha=0.15, lambda=1) {\n  value + alpha * (lambda - value)\n}\n\nSimuliamo ora l‚Äôapprendimento per 40 prove, assumendo che il partecipante riceva sempre una ricompensa:\n\nn_trials &lt;- 40\nstrength &lt;- numeric(n_trials)\nfor(trial in 2:n_trials) {\n  strength[trial] &lt;- update_rw(strength[trial-1])\n}\nplot(1:n_trials, strength, type = 'l', ylim = c(0,1), xlab = \"Prove\", ylab = \"Aspettativa di ricompensa\")\n\n\n\n\n\n\n\nL‚Äôaspettativa di ricompensa aumenta progressivamente fino a stabilizzarsi.\n\n5.2.5 Estinzione dell‚ÄôAssociazione\nSe dopo 25 prove la ricompensa non viene pi√π fornita, il valore associato allo stimolo diminuisce gradualmente:\n\nn_trials &lt;- 50                \nstrength &lt;- numeric(n_trials)\nlambda &lt;- 1\n\nfor(trial in 2:n_trials) {\n  if(trial &gt; 25) {\n    lambda &lt;- 0\n  }\n  strength[trial] &lt;- update_rw(value = strength[trial-1], lambda = lambda)\n}\n\nplot(1:n_trials, strength, type = 'l', ylim = c(0,1), xlab = \"Prove\", ylab = \"Aspettativa di ricompensa\")\n\n\n\n\n\n\n\nL‚Äôassociazione si estingue gradualmente quando il rinforzo viene rimosso.\n\n5.2.6 Implementazione della Regola Softmax\nPer simulare le scelte di un partecipante utilizziamo la funzione Softmax:\n\nsoftmax &lt;- function(beta, x) {\n  1 / (1 + exp(-beta * x))\n}\n\nbeta &lt;- 5\nx &lt;- seq(-1, 1, length.out = 100)\ny &lt;- softmax(beta, x)\nplot(x, y, type = 'l', xlab = \"Valore (A) - valore (B)\", ylab = \"p(scelta = A)\")\n\n\n\n\n\n\n\nLa funzione mostra che:\n\nLa probabilit√† di scegliere un‚Äôopzione aumenta con il suo valore atteso.\nCon \\(\\beta\\) elevato, il partecipante sceglie quasi sempre l‚Äôopzione migliore.\nCon \\(\\beta\\) basso, le scelte sono pi√π casuali.\n\n5.2.7 Verifica e Applicazioni del Modello\nQuello descritto √® il meccanismo generatore dei dati ipotizzato dal modello di Rescorla-Wagner. Per testare il modello, √® necessario stimare i parametri \\(\\alpha\\) e \\(\\beta\\), e confrontare le previsioni del modello con i dati osservati. Tuttavia, in questo corso non affronteremo il problema della stima dei parametri del modello di Rescorla-Wagner. L‚Äôobiettivo principale √® comprendere cosa significhi formalizzare quantitativamente un modello psicologico e in che modo questo approccio si differenzi da una semplice analisi delle associazioni tra variabili.\nIn sintesi, il modello di Rescorla-Wagner rappresenta uno strumento essenziale per lo studio dell‚Äôapprendimento associativo. Attraverso la simulazione dell‚Äôaggiornamento delle aspettative e delle strategie decisionali, possiamo descrivere il comportamento di individui che apprendono in contesti di rinforzo. Questo modello ha trovato applicazione in numerosi ambiti della psicologia cognitiva e delle neuroscienze, contribuendo alla comprensione dei processi di apprendimento e decisione.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Modelli cognitivi</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/05_cognitive_models.html#drift-diffusion-model",
    "href": "chapters/key_notions/05_cognitive_models.html#drift-diffusion-model",
    "title": "5¬† Modelli cognitivi",
    "section": "\n5.3 Drift Diffusion Model",
    "text": "5.3 Drift Diffusion Model\nIl processo decisionale √® uno dei temi centrali della psicologia cognitiva e delle neuroscienze. Ogni giorno prendiamo decisioni, dalle pi√π semplici alle pi√π complesse, influenzate da fattori come la percezione, la memoria, l‚Äôattenzione e il contesto in cui ci troviamo. Una domanda fondamentale √®: Come prendiamo decisioni in condizioni di incertezza?\nUno dei modelli pi√π utilizzati per rispondere a questa domanda √® il Drift Diffusion Model (DDM), un modello matematico che descrive il processo di accumulo delle informazioni fino alla presa di una decisione. Questo modello consente di quantificare e comprendere i meccanismi alla base delle scelte umane.\n\n5.3.1 Cos‚Äô√® il Drift Diffusion Model?\nIl DDM descrive come le persone raccolgono informazioni nel tempo per prendere una decisione tra due alternative. Immagina di dover stabilire se un punto si sta muovendo verso destra o verso sinistra. Non hai una risposta immediata, ma accumuli informazioni (o ‚Äúevidenza‚Äù) nel tempo fino a quando non sei abbastanza sicuro per scegliere.\nQuesto processo √® influenzato da vari fattori, come la chiarezza delle prove disponibili e l‚Äôincertezza associata alla decisione.\n\n5.3.2 Come Funziona il Processo di Accumulo dell‚ÄôEvidenza?\nIl processo decisionale pu√≤ essere paragonato a un accumulo graduale di informazioni a favore di una delle due opzioni disponibili. Ecco come funziona:\n\nRaccolta delle informazioni\nOgni nuova informazione che ricevi si accumula a favore di una delle due alternative. Ad esempio, se stai cercando di determinare la direzione del movimento di un punto, ogni piccolo dettaglio visivo ti aiuta ad avvicinarti a una decisione.\nVelocit√† di accumulo (Drift rate)\nLa velocit√† con cui raccogli le informazioni dipende dalla qualit√† del segnale. Se le prove sono chiare e forti, l‚Äôaccumulo sar√† veloce. Se invece sono ambigue, il processo sar√† pi√π lento.\nRumore e incertezza\nDurante l‚Äôaccumulo, c‚Äô√® sempre una componente casuale o ‚Äúrumore‚Äù, che pu√≤ causare fluttuazioni nel processo. Questo significa che l‚Äôinformazione non si accumula in modo perfettamente lineare, ma pu√≤ oscillare a causa di fattori casuali.\nSoglie decisionali\nPrima di iniziare il compito, ci sono due ‚Äúsoglie‚Äù che rappresentano i punti di decisione. Quando l‚Äôevidenza accumulata raggiunge una di queste soglie, si prende la decisione corrispondente.\nTempo di reazione\nIl tempo impiegato per raggiungere una delle soglie √® il tempo di reazione. Se le informazioni sono chiare, la decisione sar√† rapida; se sono ambigue, il tempo sar√† pi√π lungo.\n\nUn‚Äôutile metafora per comprendere questo processo √® quella di riempire un secchio con informazioni: ogni evidenza raccolta equivale a una goccia d‚Äôacqua che viene aggiunta al secchio. Quando il livello d‚Äôacqua raggiunge una delle due soglie, viene presa la decisione.\n\n5.3.3 I Parametri del DDM\nIl DDM √® caratterizzato da quattro parametri principali che descrivono diversi aspetti del processo decisionale:\n\nTasso di drift (\\(v\\))\nRappresenta la velocit√† con cui l‚Äôevidenza si accumula a favore di una decisione. Valori pi√π alti indicano un processo decisionale pi√π efficiente, mentre valori pi√π bassi suggeriscono un‚Äôaccumulazione lenta e incerta.\nSeparazione delle soglie (\\(a\\))\nIndica la distanza tra le due soglie decisionali. Valori pi√π alti corrispondono a decisioni pi√π caute (tempi di reazione pi√π lunghi ma minore probabilit√† di errore), mentre valori pi√π bassi indicano decisioni pi√π rapide ma potenzialmente meno accurate.\nTempo di non-decisione (\\(t_0\\))\nCorrisponde al tempo necessario per processi che precedono e seguono l‚Äôaccumulo di evidenza, come la percezione dello stimolo e l‚Äôesecuzione della risposta. Questo tempo √® indipendente dall‚Äôaccumulo delle informazioni.\nBias iniziale (\\(z\\))\nDefinisce il punto di partenza del processo di accumulo. Se √® equidistante tra le due soglie, la decisione √® imparziale. Se invece √® spostato verso una delle due soglie, significa che la persona ha una predisposizione a scegliere una delle due alternative.\n\n5.3.4 Il Compromesso tra Velocit√† e Accuratezza\nUno degli aspetti pi√π interessanti del DDM √® il compromesso tra velocit√† e accuratezza.\n\nSe una persona desidera rispondere rapidamente, pu√≤ abbassare le soglie decisionali, ma questo aumenta la probabilit√† di errore.\n\nSe invece punta a una maggiore accuratezza, pu√≤ aumentare la distanza tra le soglie, rendendo il processo pi√π lento ma pi√π affidabile.\n\nQuesto compromesso √® evidente in compiti sperimentali come:\n\nIl compito di Stroop, dove bisogna ignorare un‚Äôinformazione interferente (es. leggere il colore di una parola e non il significato della parola stessa).\n\nIl compito di decisione lessicale, in cui si deve determinare se una stringa di lettere √® una parola esistente o meno.\n\nIl DDM permette di capire se le differenze nei tempi di reazione tra gruppi dipendono da una strategia pi√π cauta (maggiore \\(a\\)) o da una difficolt√† nell‚Äôaccumulare evidenza (minore \\(v\\)).\n\n5.3.5 Perch√© √® Importante il DDM?\nIl DDM √® uno strumento potente perch√© permette di quantificare aspetti del processo decisionale che altrimenti sarebbero difficili da misurare, come la velocit√† di accumulo dell‚Äôevidenza o l‚Äôeffetto del rumore sulla decisione.\n√à stato applicato in numerosi ambiti, tra cui:\n\n\nCompiti percettivi e decisionali: studi sulla discriminazione di stimoli visivi e uditivi.\n\nProcessi di controllo cognitivo: analisi delle differenze individuali nella regolazione dell‚Äôimpulsivit√†.\n\nPsicopatologia: esplorazione delle alterazioni nel processo decisionale in condizioni come depressione, ansia e schizofrenia.\n\nIl Drift Diffusion Model offre dunque una rappresentazione chiara e quantitativa del processo decisionale in condizioni di incertezza. Descrivendo l‚Äôaccumulo graduale delle informazioni e il raggiungimento delle soglie decisionali, il modello ci aiuta a comprendere il compromesso tra velocit√† e accuratezza e i fattori che influenzano le scelte.\nL‚Äôapplicazione del DDM in psicologia cognitiva e neuroscienze permette di studiare non solo il comportamento umano, ma anche i meccanismi neurali che regolano il processo decisionale.\n\n5.3.6 Simulazione del DDM\nUna delle potenzialit√† del DDM √® la possibilit√† di simulare dati sintetici per confrontare le predizioni del modello con dati empirici. In R, possiamo generare una simulazione semplificata del modello utilizzando pacchetti dedicati come rtdists o brms.\nUn esempio di codice per simulare dati con parametri definiti:\n\n# Nuova configurazione dei parametri\na &lt;- 1.2   # Separazione delle soglie (aumentato)\nv &lt;- 0.3   # Tasso di drift\nt0 &lt;- 0.2  # Tempo di non-decisione\nz &lt;- 0.5   # Bias iniziale (deve essere tra 0 e 1)\n\n# Generazione dei dati\nsim_data &lt;- rdiffusion(n = 1000, a = a, v = v, t0 = t0, z = z)\n\n# Visualizzazione dei tempi di reazione\nhist(\n  sim_data$rt, \n  breaks = 30, \n  main = \"Distribuzione dei tempi di reazione\", \n  xlab = \"RT (s)\"\n)\n\n\n\n\n\n\n\nQuesto codice genera una distribuzione di tempi di reazione e scelte coerenti con le ipotesi del DDM, permettendo di esplorare l‚Äôeffetto delle variazioni dei parametri sul comportamento del modello.\nIn sintesi, il Drift Diffusion Model fornisce un quadro teorico potente per l‚Äôanalisi del processo decisionale in psicologia cognitiva. Modellando il tempo di reazione e la probabilit√† di risposta in termini di parametri interpretabili, il DDM permette di distinguere tra strategie decisionali e difficolt√† cognitive, superando i limiti di un‚Äôanalisi puramente descrittiva. Grazie alla sua capacit√† di catturare la dinamica dei processi decisionali, il DDM √® oggi uno degli strumenti pi√π utilizzati per studiare il comportamento umano in contesti sperimentali e applicativi.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Modelli cognitivi</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/05_cognitive_models.html#riflessioni-conclusive",
    "href": "chapters/key_notions/05_cognitive_models.html#riflessioni-conclusive",
    "title": "5¬† Modelli cognitivi",
    "section": "\n5.4 Riflessioni Conclusive",
    "text": "5.4 Riflessioni Conclusive\nUn modo per approfondire la comprensione dei processi di apprendimento e decisione √® attraverso l‚Äôutilizzo di modelli computazionali. Questi modelli consentono di inferire i meccanismi cognitivi sottostanti partendo dai comportamenti osservabili, offrendo una formalizzazione quantitativa dei processi psicologici. In questo capitolo, abbiamo esaminato due modelli fondamentali: il modello di Rescorla-Wagner e il Drift Diffusion Model (DDM).\nIl modello di Rescorla-Wagner descrive l‚Äôapprendimento associativo come un aggiornamento incrementale delle aspettative basato sull‚Äôerrore di previsione. Questo modello ha dimostrato una notevole capacit√† di spiegare come gli individui apprendano a stimare la probabilit√† di una ricompensa sulla base delle esperienze passate. Il parametro chiave in questo processo √® il tasso di apprendimento \\(\\alpha\\), che determina la velocit√† con cui le aspettative vengono aggiornate in base alle nuove informazioni. L‚Äôutilizzo della funzione softmax, inoltre, permette di modellare il bilanciamento tra esplorazione ed sfruttamento nelle scelte.\nD‚Äôaltra parte, il Drift Diffusion Model (DDM) fornisce una descrizione dettagliata del processo decisionale in compiti a due alternative, modellando l‚Äôaccumulo graduale di evidenza fino al raggiungimento di una soglia decisionale. I parametri del DDM, tra cui il drift rate (\\(v\\)), la threshold separation (\\(a\\)), il non-decision time (\\(t_0\\)) e il starting point (\\(z\\)), permettono di distinguere tra velocit√† di elaborazione dell‚Äôinformazione, strategie di risposta pi√π o meno caute e tempi di esecuzione della risposta indipendenti dal processo decisionale.\nEntrambi i modelli evidenziano il valore della formalizzazione matematica nello studio dei processi cognitivi. Il modello di Rescorla-Wagner √® particolarmente utile per comprendere come gli individui apprendano e aggiornino le proprie credenze sulla base dell‚Äôesperienza, mentre il DDM fornisce una rappresentazione pi√π dettagliata delle dinamiche della presa di decisione e del compromesso tra velocit√† e accuratezza.\nIn conclusione, l‚Äôapproccio computazionale alla psicologia cognitiva permette di superare i limiti di un‚Äôanalisi puramente descrittiva, fornendo strumenti matematici per testare ipotesi sui processi cognitivi. L‚Äôuso combinato di modelli di apprendimento e di modelli decisionali consente di ottenere una visione pi√π completa dei meccanismi che guidano il comportamento umano, con implicazioni per la ricerca di base e le applicazioni cliniche.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Modelli cognitivi</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/05_cognitive_models.html#esercizi",
    "href": "chapters/key_notions/05_cognitive_models.html#esercizi",
    "title": "5¬† Modelli cognitivi",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n\nChe cosa descrive il modello di Rescorla-Wagner?\nQual √® il ruolo del parametro Œ± nel modello di Rescorla-Wagner?\nQuale funzione matematica viene utilizzata per modellare il bilanciamento tra esplorazione ed esploitazione nel modello di Rescorla-Wagner?\nQuali sono i principali parametri del Drift Diffusion Model (DDM)?\nIn che modo il DDM spiega il compromesso tra velocit√† e accuratezza nelle decisioni?\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n\nIl modello di Rescorla-Wagner descrive come gli individui apprendano le associazioni tra stimoli e risposte in base all‚Äôerrore di previsione. L‚Äôaspettativa di ricompensa viene aggiornata attraverso l‚Äôesperienza, con un processo regolato dal tasso di apprendimento (Œ±).\nIl parametro Œ± (tasso di apprendimento) determina quanto velocemente un individuo aggiorna le proprie aspettative in base all‚Äôerrore di previsione. Se Œ± √® alto, l‚Äôapprendimento √® rapido; se √® basso, l‚Äôindividuo si basa maggiormente sulle esperienze passate.\nLa funzione Softmax viene utilizzata per modellare il bilanciamento tra esplorazione ed esploitazione. Essa regola la probabilit√† di scegliere un‚Äôopzione in base al valore atteso e alla temperatura della scelta (Œ≤).\n\nI principali parametri del DDM sono:\n\n\nTasso di drift (v): velocit√† con cui viene accumulata l‚Äôevidenza.\n\n\nSeparazione delle soglie (a): distanza tra le soglie decisionali.\n\n\nTempo di non-decisione (t‚ÇÄ): tempo impiegato per processi indipendenti dall‚Äôaccumulo dell‚Äôevidenza.\n\n\nBias iniziale (z): punto di partenza dell‚Äôaccumulo dell‚Äôevidenza.\n\n\nIl DDM spiega il compromesso tra velocit√† e accuratezza attraverso la separazione delle soglie decisionali (a). Se le soglie sono pi√π vicine, le decisioni sono pi√π rapide ma meno accurate; se sono pi√π distanti, le decisioni sono pi√π lente ma pi√π precise.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Modelli cognitivi</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/05_cognitive_models.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/key_notions/05_cognitive_models.html#informazioni-sullambiente-di-sviluppo",
    "title": "5¬† Modelli cognitivi",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] rtdists_0.11-5   thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0\n#&gt;  [5] see_0.11.0       gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1\n#&gt;  [9] psych_2.5.3      scales_1.3.0     markdown_2.0     knitr_1.50      \n#&gt; [13] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [17] purrr_1.0.4      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [21] ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      xfun_0.51         htmlwidgets_1.6.4 lattice_0.22-6   \n#&gt;  [5] tzdb_0.5.0        vctrs_0.6.5       tools_4.4.2       generics_0.1.3   \n#&gt;  [9] parallel_4.4.2    pacman_0.5.1      pkgconfig_2.0.3   Matrix_1.7-3     \n#&gt; [13] lifecycle_1.0.4   compiler_4.4.2    farver_2.1.2      munsell_0.5.1    \n#&gt; [17] mnormt_2.1.1      htmltools_0.5.8.1 evd_2.3-7.1       pillar_1.10.1    \n#&gt; [21] nlme_3.1-167      tidyselect_1.2.1  digest_0.6.37     mvtnorm_1.3-3    \n#&gt; [25] stringi_1.8.4     splines_4.4.2     gsl_2.1-8         rprojroot_2.0.4  \n#&gt; [29] fastmap_1.2.0     grid_4.4.2        colorspace_2.1-1  expm_1.0-0       \n#&gt; [33] cli_3.6.4         magrittr_2.0.3    survival_3.8-3    withr_3.0.2      \n#&gt; [37] timechange_0.3.0  rmarkdown_2.29    hms_1.1.3         msm_1.8.2        \n#&gt; [41] evaluate_1.0.3    rlang_1.1.5       Rcpp_1.0.14       glue_1.8.0       \n#&gt; [45] rstudioapi_0.17.1 jsonlite_1.9.1    R6_2.6.1",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Modelli cognitivi</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/05_cognitive_models.html#bibliografia",
    "href": "chapters/key_notions/05_cognitive_models.html#bibliografia",
    "title": "5¬† Modelli cognitivi",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nSoto, F. A., Vogel, E. H., Uribe-Bahamonde, Y. E., & Perez, O. D. (2023). Why is the Rescorla-Wagner model so influential? Neurobiology of Learning and Memory, 204, 107794.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Modelli cognitivi</span>"
    ]
  },
  {
    "objectID": "chapters/R/introduction_r_lang.html",
    "href": "chapters/R/introduction_r_lang.html",
    "title": "R",
    "section": "",
    "text": "Scrivere Codice\nLa programmazione si fonda su un approccio strutturato che combina logica computazionale e strumenti tecnici, articolandosi su due piani complementari: il livello algoritmico e il livello sintattico.",
    "crumbs": [
      "R"
    ]
  },
  {
    "objectID": "chapters/R/introduction_r_lang.html#scrivere-codice",
    "href": "chapters/R/introduction_r_lang.html#scrivere-codice",
    "title": "R",
    "section": "",
    "text": "Livello algoritmico: l‚Äôastrazione del problema\nIn questa fase, si definisce la soluzione concettuale indipendentemente dal linguaggio, attraverso:\n\nanalisi degli input;\nspecifica dell‚Äôoutput;\n\nprogettazione dell‚Äôalgoritmo.\n\nPer esempio, l‚Äôinput pu√≤ essere costituito da un insieme di valori numerici; l‚Äôoutput pu√≤ corrispondere alla media aritmetica; l‚Äôalgorimo pu√≤ essere formalizzato come:\n\\[\n\\text{media} = \\frac{\\sum_{i=1}^{n} x_i}{n} .\n\\]\nQuesto processo richiede capacit√† di problem solving e modellizzazione astratta, competenze trasversali a qualsiasi linguaggio.\n\n\nLivello sintattico: l‚Äôimplementazione pratica\nLa soluzione algoritmica viene poi tradotta in codice seguendo le regole specifiche del linguaggio scelto:\nEsempio in R\nmedia &lt;- sum(x) / length(x)\nEsempio in Python\nmedia = sum(x) / len(x)\nPur mantenendo la stessa logica, le differenze sintattiche evidenziano come l‚Äôimplementazione sia vincolata allo strumento utilizzato.",
    "crumbs": [
      "R"
    ]
  },
  {
    "objectID": "chapters/R/introduction_r_lang.html#priorit√†-formative-nellera-dellia",
    "href": "chapters/R/introduction_r_lang.html#priorit√†-formative-nellera-dellia",
    "title": "R",
    "section": "Priorit√† formative nell‚Äôera dell‚ÄôIA",
    "text": "Priorit√† formative nell‚Äôera dell‚ÄôIA\nNell‚Äôattuale contesto tecnologico dominato dall‚Äôintelligenza artificiale, la formazione nella programmazione richiede una ridefinizione delle priorit√†. Abbiamo visto come sia necessario distinguere tra due dimensioni: da un lato, la capacit√† di pensare algoritmicamente, ossia l‚Äôabilit√† di scomporre problemi complessi in passaggi logici e astratti; dall‚Äôaltro, la padronanza della sintassi, ovvero delle regole specifiche dei linguaggi di programmazione.\nIl pensiero algoritmico rappresenta il cuore creativo e critico della programmazione. √à ci√≤ che permette di trasformare un problema in una sequenza ordinata di operazioni risolutive. Questa competenza, radicata nella logica e nell‚Äôastrazione, rimane un dominio squisitamente umano: per quanto avanzate, le IA non possono sostituire la capacit√† di formulare domande pertinenti, riconoscere pattern originali o immaginare soluzioni innovative. Senza questa base concettuale, ogni tentativo di risolvere problemi computazionali sarebbe destinato a fallire, anche con gli strumenti pi√π potenti a disposizione.\nLa sintassi computazionale, sebbene necessaria, assume oggi un ruolo diverso. Strumenti di code generation, stanno democratizzando l‚Äôaccesso alla scrittura del codice: piattaforme intelligenti possono suggerire implementazioni, correggere errori e persino tradurre algoritmi tra linguaggi diversi (Cooper et al., 2024). Gli errori sintattici ‚Äì un tempo ostacoli insormontabili per i principianti ‚Äì diventano sempre pi√π correggibili attraverso l‚Äôesperienza o l‚Äôautomazione.\nQuesta gerarchia di competenze riecheggia il framework teorico di Marr, sviluppato nel campo della visione artificiale. Marr distingue tre livelli di analisi: il ‚Äúperch√©‚Äù del sistema (l‚Äôobiettivo computazionale), il ‚Äúcome‚Äù logico (la progettazione algoritmica) e il ‚Äúcon cosa‚Äù concreto (l‚Äôimplementazione fisica). Nell‚Äôeducazione alla programmazione, questo si traduce in una scelta precisa: privilegiare la progettazione consapevole di algoritmi rispetto alla mera esecuzione tecnica.\nLa priorit√† formativa diventa quindi chiara. Coltivare il pensiero algoritmico significa allenare quella mentalit√† progettuale che permette di dialogare in modo critico con l‚ÄôIA: formulare prompt efficaci richiede prima di tutto di comprendere a fondo la struttura del problema; valutare soluzioni proposte dall‚Äôintelligenza artificiale presuppone la capacit√† di riconoscere logiche difettose o approcci subottimali. Allo stesso tempo, questa competenza agisce come un ‚Äúsesto senso tecnologico‚Äù, permettendo di adattarsi a linguaggi e strumenti in continua evoluzione.\nLa sintassi non viene certo abbandonata, ma contestualizzata. L‚Äôautomazione non sostituisce l‚Äôapprendimento, ma lo rende pi√π strategico: invece di memorizzare comandi, si impara a selezionarli e combinarli in modo funzionale agli obiettivi algoritmici.",
    "crumbs": [
      "R"
    ]
  },
  {
    "objectID": "chapters/R/introduction_r_lang.html#r-uno-strumento-per-lanalisi-dei-dati",
    "href": "chapters/R/introduction_r_lang.html#r-uno-strumento-per-lanalisi-dei-dati",
    "title": "R",
    "section": "R: Uno Strumento per l‚ÄôAnalisi dei Dati",
    "text": "R: Uno Strumento per l‚ÄôAnalisi dei Dati\nPer trovare la soluzione concreta a un problema di analisi dei dati, √® necessario implementare l‚Äôalgoritmo desiderato in un linguaggio di programmazione. In questo insegnamento, utilizzeremo R, uno dei linguaggi pi√π utilizzati per l‚Äôanalisi dei dati, apprezzato per la sua flessibilit√†, potenza e il supporto offerto da una vasta comunit√† di utenti e sviluppatori.\n\nPerch√© R?\n\nNato per l‚Äôanalisi statistica: R √® stato concepito specificamente per rispondere alle esigenze di analisi statistica e visualizzazione grafica, diventando rapidamente uno strumento essenziale nel panorama accademico e scientifico.\nGestione dei dati: R offre strumenti avanzati per gestire, manipolare e analizzare grandi quantit√† di dati, coprendo un‚Äôampia gamma di tecniche statistiche, dalla modellazione lineare all‚Äôanalisi delle serie temporali.\nVisualizzazione grafica: Con pacchetti come ggplot2 e plotly, R permette di creare grafici e visualizzazioni di alta qualit√†, fondamentali per comunicare risultati in modo efficace.\nComunit√† e pacchetti: L‚Äôecosistema di R √® arricchito da una vasta libreria di pacchetti, che estendono le capacit√† del linguaggio per soddisfare necessit√† specifiche e settoriali.\n\n\n\nR in Psicologia e nelle Scienze Sociali\nNato come linguaggio dedicato alla statistica, R si √® evoluto fino a diventare un punto di riferimento per psicologi, ricercatori e professionisti impegnati nella valutazione psicometrica, nell‚Äôanalisi del comportamento e nella modellizzazione di dati complessi. La sua flessibilit√†, unita alla vastissima collezione di pacchetti specifici, lo rende adatto a molteplici applicazioni in psicologia, dalla costruzione e validazione di test alla gestione di dati provenienti da studi sperimentali, longitudinali ed Ecological Momentary Assessment (EMA).",
    "crumbs": [
      "R"
    ]
  },
  {
    "objectID": "chapters/R/introduction_r_lang.html#riflessioni-conclusive",
    "href": "chapters/R/introduction_r_lang.html#riflessioni-conclusive",
    "title": "R",
    "section": "Riflessioni Conclusive",
    "text": "Riflessioni Conclusive\nImparare ad usare R non significa solo acquisire competenze tecniche, ma anche aprire le porte a nuove possibilit√† di analisi e ricerca. Tuttavia, √® fondamentale ricordare che la vera sfida nella programmazione non √® padroneggiare la sintassi di un linguaggio specifico, ma comprendere la logica algoritmica che sta alla base della soluzione di un problema. L‚ÄôIA pu√≤ aiutarci a trovare la sintassi corretta, ma spetta a noi decidere quale algoritmo implementare. Pertanto, i nostri sforzi devono essere rivolti a capire la logica del problema, piuttosto che concentrarci esclusivamente sull‚Äôimplementazione sintattica.",
    "crumbs": [
      "R"
    ]
  },
  {
    "objectID": "chapters/R/introduction_r_lang.html#bibliografia",
    "href": "chapters/R/introduction_r_lang.html#bibliografia",
    "title": "R",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nCooper, N., Clark, A. T., Lecomte, N., Qiao, H., & Ellison, A. M. (2024). Harnessing large language models for coding, teaching and inclusion to empower research in ecology and evolution. Methods in Ecology and Evolution.",
    "crumbs": [
      "R"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html",
    "href": "chapters/R/01_r_syntax.html",
    "title": "6¬† Un approccio moderno all‚Äôanalisi dei dati",
    "section": "",
    "text": "Introduzione\nNell‚Äôanalisi dei dati psicologici, R non √® solo uno strumento statistico avanzato, ma un vero e proprio linguaggio per organizzare il pensiero scientifico. La sua sintassi trasforma procedure complesse in passaggi chiari, verificabili e ripetibili, rispondendo alla crisi della replicabilit√† che ha coinvolto la psicologia negli ultimi anni (Obels et al., 2020). Imparare R significa quindi acquisire un metodo di lavoro rigoroso e trasparente.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#la-sintassi-di-r-come-garanzia-di-trasparenza",
    "href": "chapters/R/01_r_syntax.html#la-sintassi-di-r-come-garanzia-di-trasparenza",
    "title": "6¬† Un approccio moderno all‚Äôanalisi dei dati",
    "section": "\n6.1 La Sintassi di R come Garanzia di Trasparenza",
    "text": "6.1 La Sintassi di R come Garanzia di Trasparenza\nA differenza dei software a menu grafici (come Excel o SPSS), dove le operazioni restano ‚Äúnascoste‚Äù dietro click del mouse, R richiede di descrivere esplicitamente ogni passaggio. Prendiamo questo esempio base:\ndati &lt;- read.csv(\"esperimento1.csv\")\nmodello &lt;- lm(risposta ~ trattamento, data = dati)\nQuesto semplice script realizza tre cose fondamentali:\n\n\nDocumentazione automatica: Ogni operazione resta tracciata nel codice.\n\nVerifica immediata: √à possibile ispezionare ogni passaggio (Cosa contiene dati? Come √® definito modello?).\n\nModifiche controllate: Cambiare un parametro (es. il file di input) non richiede di rifare tutta l‚Äôanalisi manualmente.\n\n\n6.1.1 Perch√© R Favorisce la Replicabilit√†\nTre caratteristiche di R facilitano direttamente la replicabilit√†:\n\n\nStruttura basata su script: Scrivere codice in file .R o .qmd crea una traccia completa e ordinata dell‚Äôanalisi, integrando:\n\nistruzioni eseguibili,\nannotazioni metodologiche,\nvisualizzazione dei risultati.\n\n\nGestione esplicita dei pacchetti:\nComandi come library(lme4) o install.packages(\"brms\") rendono esplicite tutte le risorse usate, evitando il classico ‚ÄúSul mio computer funzionava!‚Äù.\n\nLiterate programming tramite R Markdown:\nLa combinazione di codice, testo narrativo e risultati dinamici (Knuth, 1984) in documenti Quarto (o R Markdown) consente di generare report che combinano:\n\ntesto esplicativo,\nanalisi eseguibile,\nrisultati dinamici (grafici, tabelle).\n\n\n\n6.1.2 Buone Abitudini da Adottare Subito\n\n\nNomi descrittivi\nUtilizzare sempre nomi chiari per oggetti e dati:\n# Da evitare\nx &lt;- read.csv(\"file1.csv\")  \n\n# Preferibile\ndemographics_data &lt;- read.csv(\"demographic_questionnaire.csv\")  \n\nSalvataggio progressivo delle modifiche (versionamento)\nR permette di salvare e tenere traccia delle modifiche ai file con sistemi come Git. Non √® necessario impararlo subito, ma √® utile sapere che strumenti come GitHub consentono facilmente di archiviare versioni successive del proprio lavoro, facilitando il recupero di versioni precedenti in caso di necessit√†.\n\nChecklist pre-invio\nPrima di condividere un‚Äôanalisi, √® buona norma verificare:\n\neseguire lo script integralmente (Ctrl+Shift+Enter su RStudio);\ncontrollare che i percorsi dei file siano corretti (es.: ‚ÄúIl file dati.csv si trova nella cartella giusta?‚Äù);\naggiornare tutti i pacchetti installati con update.packages(ask = FALSE).\n\n\n\nQueste pratiche rendono il codice pi√π robusto, l‚Äôanalisi pi√π affidabile e i risultati pi√π facilmente verificabili.\n\n6.1.3 Perch√© Queste Regole Contano nella Ricerca Psicologica\nL‚Äôapprendimento di R va oltre l‚Äôacquisizione di competenze tecniche. Ogni scelta sintattica riflette un principio scientifico:\n\n\nElemento del codice\nPrincipio metodologico\n\n\n\nset.seed(123)\nControllo delle fonti di casualit√†\n\n\ndplyr::filter()\nTracciabilit√† delle esclusioni\n\n\nAPA_style()\nStandardizzazione della reportistica\n\n\n\nIn un contesto dove il 50% degli studi psicologici mostra difficolt√† di replicazione (Collaboration, 2015), R offre un framework per costruire ricerche solide fin dalla fase di progettazione.\n\n6.1.4 Prossimi Passi\n\nScarica e installa R.\nVai al sito ufficiale di CRAN (https://cran.r-project.org/), scegli la versione per il tuo sistema operativo (Windows, Mac o Linux) e segui le istruzioni di installazione.\nScarica e installa RStudio.\nDopo aver installato R, scarica RStudio dal sito ufficiale (https://posit.co/download/rstudio-desktop/). Scegli la versione gratuita ‚ÄúRStudio Desktop‚Äù e segui le istruzioni per il tuo sistema operativo.\n\nUna spiegazione dettagliata del processo di installazione di R e RStudio √® disponibile in Okoye & Hosseini (2024).",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#panoramica-sullinterfaccia-di-rstudio",
    "href": "chapters/R/01_r_syntax.html#panoramica-sullinterfaccia-di-rstudio",
    "title": "6¬† Un approccio moderno all‚Äôanalisi dei dati",
    "section": "\n6.2 Panoramica sull‚Äôinterfaccia di RStudio",
    "text": "6.2 Panoramica sull‚Äôinterfaccia di RStudio\nRStudio rende l‚Äôuso di R pi√π intuitivo grazie alla sua interfaccia divisa in quattro pannelli principali:\n\n\nPannello degli script: Qui puoi scrivere e modificare i tuoi script, cio√® sequenze di comandi salvabili per analisi ripetibili e organizzate.\n\nConsole: Esegue i comandi scritti direttamente o lanciati dagli script, mostrando risultati, messaggi e errori.\n\nPannello dell‚Äôambiente: Mostra i dataset, le variabili e gli oggetti caricati nella sessione di lavoro, permettendoti di gestire facilmente i dati.\n\nPannello grafici/aiuto/file: Visualizza grafici, fornisce accesso alla documentazione di R e consente di navigare tra file e cartelle sul tuo sistema.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#creare-un-nuovo-progetto-in-rstudio",
    "href": "chapters/R/01_r_syntax.html#creare-un-nuovo-progetto-in-rstudio",
    "title": "6¬† Un approccio moderno all‚Äôanalisi dei dati",
    "section": "\n6.3 Creare un Nuovo Progetto in RStudio",
    "text": "6.3 Creare un Nuovo Progetto in RStudio\nAvviare un nuovo progetto\nDal menu di RStudio, seleziona File &gt; New Project‚Ä¶ per creare un nuovo progetto. I progetti in RStudio sono uno strumento efficace per organizzare il lavoro relativo a una specifica analisi o domanda di ricerca. All‚Äôinterno di un progetto puoi raccogliere script, file di dati e output, mantenendo tutto ben strutturato.\nScegliere la posizione del progetto\nPuoi creare una nuova directory dedicata al progetto oppure associare il progetto a una directory esistente. Organizzare i progetti in cartelle dedicate aiuta a mantenere i file in ordine e a utilizzare percorsi relativi, rendendo il tuo lavoro pi√π facile da condividere con collaboratori e pi√π portabile tra diversi sistemi.\nQuesta organizzazione √® particolarmente utile per evitare confusione e assicurarsi che tutti i file necessari siano facilmente accessibili e collegati al progetto corretto.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#concetti-di-base-nella-programmazione-in-r",
    "href": "chapters/R/01_r_syntax.html#concetti-di-base-nella-programmazione-in-r",
    "title": "6¬† Un approccio moderno all‚Äôanalisi dei dati",
    "section": "\n6.4 Concetti di Base nella Programmazione in R",
    "text": "6.4 Concetti di Base nella Programmazione in R\nIniziare a usare R, soprattutto per chi si avvicina per la prima volta a questo linguaggio nel contesto della psicologia, significa comprendere i concetti fondamentali che ne costituiscono la base. Questo capitolo introduce i principi essenziali della programmazione in R, tra cui:\n\nLa comprensione della sintassi di R.\nLa familiarizzazione con i principali tipi di dati e strutture.\nL‚Äôacquisizione delle operazioni di base.\n\nQuesti concetti sono fondamentali per manipolare efficacemente i dati e condurre analisi statistiche, rappresentando il punto di partenza per sfruttare al meglio le potenzialit√† di R.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#oggetti-in-r",
    "href": "chapters/R/01_r_syntax.html#oggetti-in-r",
    "title": "6¬† Un approccio moderno all‚Äôanalisi dei dati",
    "section": "\n6.5 Oggetti in R",
    "text": "6.5 Oggetti in R\nIn R, tutto √® un oggetto: dai numeri e stringhe di testo pi√π semplici fino a strutture pi√π complesse come vettori, data frame, funzioni, modelli statistici o persino grafici. Un oggetto in R √® semplicemente un contenitore che memorizza un valore o una serie di valori, permettendoti di manipolarli e riutilizzarli nel codice.\n\n6.5.1 Creare oggetti\nPer creare un oggetto, √® necessario assegnargli un nome e un valore utilizzando l‚Äôoperatore di assegnazione &lt;- (consigliato) o = (meno utilizzato):\n\nmy_obj &lt;- 48\n\nIn questo esempio, abbiamo creato un oggetto chiamato my_obj e gli abbiamo assegnato il valore 48. Ora questo numero √® memorizzato con quel nome e pu√≤ essere richiamato facilmente.\nPer visualizzare il valore di un oggetto, basta scriverne il nome e premere Invio:\n\nmy_obj\n#&gt; [1] 48\n\n\n6.5.1.1 Dove vengono salvati gli oggetti?\nGli oggetti creati vengono memorizzati nell‚Äôambiente di lavoro (workspace) e restano disponibili finch√© non vengono rimossi o finch√© la sessione di R non viene chiusa. Se stai usando RStudio, puoi vedere tutti gli oggetti attualmente presenti nella scheda Environment, dove vengono mostrati con dettagli come tipo, lunghezza e valore.\n\n6.5.1.2 Perch√© gli oggetti sono importanti?\nLavorare con oggetti in R permette di:\n\n\nRiutilizzare dati e risultati senza doverli digitare nuovamente.\n\n\nOrganizzare il codice in modo chiaro e leggibile, rendendo le analisi pi√π strutturate.\n\n\nManipolare facilmente i dati, combinando, trasformando e analizzando gli oggetti in base alle esigenze.\n\n6.5.1.3 Stringhe\n√à possibile assegnare a un oggetto anche una stringa di testo, racchiudendola tra virgolette:\n\nmy_obj2 &lt;- \"R √® fantastico\"\nmy_obj2\n#&gt; [1] \"R √® fantastico\"\n\nSe dimentichi le virgolette, R mostrer√† un errore.\n\n6.5.1.4 Modificare Oggetti\nPer modificare il valore di un oggetto esistente, basta riassegnarlo:\n\nmy_obj2 &lt;- 1024\n\nOra il tipo di my_obj2 √® cambiato da carattere a numerico. √à anche possibile usare oggetti per crearne di nuovi:\n\nmy_obj3 &lt;- my_obj + my_obj2\nmy_obj3\n#&gt; [1] 1072\n\n\n6.5.1.5 Manipolare Oggetti\nSe provi a sommare oggetti di tipo diverso, R restituir√† un errore:\nchar_obj &lt;- \"ciao\"\nchar_obj2 &lt;- \"mondo\"\nchar_obj3 &lt;- char_obj + char_obj2\n#&gt; Error in char_obj + char_obj2 : non-numeric argument to binary operator\nQuando incontri errori come questo, chiedi a AI la spiegazione del messaggio, per esempio: ‚Äúnon-numeric argument to binary operator error + r‚Äù. Un errore comune √® anche:\nmy_obj &lt;- 48\nmy_obj4 &lt;- my_obj + no_obj\n#&gt; Error: object 'no_obj' not found\nR segnala che no_obj non √® stato definito e, di conseguenza, l‚Äôoggetto my_obj4 non √® stato creato.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#nomi-degli-oggetti",
    "href": "chapters/R/01_r_syntax.html#nomi-degli-oggetti",
    "title": "6¬† Un approccio moderno all‚Äôanalisi dei dati",
    "section": "\n6.6 Nomi degli Oggetti",
    "text": "6.6 Nomi degli Oggetti\nAttribuire nomi agli oggetti potrebbe sembrare un dettaglio secondario, ma √® fondamentale scegliere nomi brevi e informativi. Un buon nome migliora la leggibilit√† del codice e ne facilita la manutenzione. √à importante adottare uno stile coerente, come uno dei seguenti:\n\n\nSnake case: output_summary\n\n\nDot case: output.summary\n\n\nCamel case: outputSummary\n\n\nIn questo corso useremo lo stile pi√π diffuso, Snake Case, che separa le parole con il carattere di sottolineatura _.\nCi sono alcune regole fondamentali da rispettare nella scelta dei nomi:\n\nNon possono iniziare con un numero (ad esempio, 2my_variable non √® valido).\n\nNon possono contenere caratteri speciali come &, ^, /, ecc.\n\nEvita di usare parole riservate (ad esempio, TRUE, NA) o nomi di funzioni esistenti (ad esempio, data).\n\nEsempio di cosa non fare:\ndata &lt;- read.table(\"mydatafile\", header = TRUE) # `data` √® gi√† una funzione!",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#commenti",
    "href": "chapters/R/01_r_syntax.html#commenti",
    "title": "6¬† Un approccio moderno all‚Äôanalisi dei dati",
    "section": "\n6.7 Commenti",
    "text": "6.7 Commenti\nI commenti sono uno strumento essenziale per rendere il codice pi√π chiaro e comprensibile, sia per te stesso sia per altri. Nel linguaggio R, i commenti iniziano con il simbolo #, e tutto ci√≤ che lo segue sulla stessa riga viene ignorato dall‚Äôinterprete durante l‚Äôesecuzione.\n\n6.7.1 Perch√© commentare?\nI commenti servono a spiegare perch√© il codice √® scritto in un certo modo, non solo come funziona (questo √® evidente leggendo il codice). Una buona pratica consiste nel commentare le decisioni o i passaggi che non risultano immediatamente evidenti.\nAd esempio, invece di scrivere un commento ridondante come:\n\n# Assegno 42 alla variabile x\nx &lt;- 42\n\n√® pi√π utile fornire un contesto:\n\n# Valore iniziale scelto per semplificare i calcoli successivi\nx &lt;- 42\n\n\n6.7.2 Vantaggi\nCommentare in modo appropriato aiuta a:\n\n\nRidurre il tempo necessario per comprendere o modificare il codice, anche mesi o anni dopo averlo scritto.\n\nFacilitare la collaborazione con altri, rendendo il codice leggibile e accessibile.\n\nMigliorare la manutenibilit√† e il riutilizzo del codice.\n\nUn codice ben commentato non √® solo pi√π facile da leggere, ma anche pi√π professionale e robusto nel lungo termine.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#usare-r-come-calcolatore",
    "href": "chapters/R/01_r_syntax.html#usare-r-come-calcolatore",
    "title": "6¬† Un approccio moderno all‚Äôanalisi dei dati",
    "section": "\n6.8 Usare R come Calcolatore",
    "text": "6.8 Usare R come Calcolatore\nR pu√≤ essere utilizzato come un semplice calcolatore digitando direttamente nella console numeri e operatori aritmetici per eseguire operazioni come somma, sottrazione, moltiplicazione e divisione (+, -, *, /). Questo lo rende uno strumento immediato e versatile per calcoli di base e avanzati.\n\nEsempio 6.1 La Satisfaction With Life Scale (SWLS) contiene 5 item, ciascuno valutato con una scala Likert a 7 punti, dove:\n1 = ‚Äúcompletamente in disaccordo‚Äù e 7 = ‚Äúcompletamente d‚Äôaccordo‚Äù.\nGli item sono:\n\nPer la maggior parte, la mia vita si avvicina al mio ideale.\n\nLe mie condizioni di vita sono eccellenti.\n\nSono soddisfatto della mia vita.\n\nFino ad ora, ho ottenuto le cose importanti che voglio nella vita.\n\nSe potessi vivere la mia vita di nuovo, non cambierei quasi nulla.\n\nSupponiamo che un individuo risponda nel seguente modo:\n\nItem 1: 5\n\nItem 2: 3\n\nItem 3: 4\n\nItem 4: 2\n\nItem 5: 2\n\nIl punteggio totale sulla SWLS si calcola sommando i punteggi di ciascun item:\n\nsogg1 &lt;- 5 + 3 + 4 + 2 + 2 \nsogg1\n#&gt; [1] 16\n\n\n\nEsempio 6.2 Il Body Mass Index (BMI) si calcola dividendo il peso, in chilogrammi, per il quadrato dell‚Äôaltezza, in metri.\nLa formula √®:\n\\[\n\\text{BMI} = \\frac{\\text{Peso (kg)}}{\\text{Altezza (m)}^2} .\n\\]\nSupponiamo che un individuo pesi 79000 grammi (79 kg) e sia alto 176 cm. Il calcolo in R sar√†:\n\nbmi &lt;- (79000 / 1000) / (176 / 100)^2\nbmi\n#&gt; [1] 25.5\n\n\nNota. L‚Äôuso di parentesi √® fondamentale per garantire che le operazioni vengano eseguite nell‚Äôordine corretto. In R, come in matematica, le operazioni racchiuse tra parentesi hanno la precedenza rispetto ad altre operazioni. Ad esempio, nel calcolo del BMI, abbiamo usato le parentesi per calcolare prima la conversione dei valori nell‚Äôunit√† di misura appropriata.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#ordine-di-precedenza-degli-operatori",
    "href": "chapters/R/01_r_syntax.html#ordine-di-precedenza-degli-operatori",
    "title": "6¬† Un approccio moderno all‚Äôanalisi dei dati",
    "section": "\n6.9 Ordine di precedenza degli operatori",
    "text": "6.9 Ordine di precedenza degli operatori\nLe operazioni algebriche vengono eseguite in una particolare sequenza in R, nota come ordine di precedenza degli operatori. Questo ordine determina quali operazioni vengono eseguite per prime quando un‚Äôespressione include pi√π operatori. In assenza di parentesi, l‚Äôordine di precedenza √® il seguente (dal pi√π alto al pi√π basso):\n\n\nParentesi: Le operazioni racchiuse tra parentesi () vengono eseguite per prime. Questo permette di sovrascrivere l‚Äôordine naturale delle operazioni.\n\nresult &lt;- (2 + 3) * 4  # Risultato: 20\n\n\n\nEsponenziazione: L‚Äôoperatore ^ viene eseguito dopo le parentesi.\n\nresult &lt;- 2^3  # Risultato: 8\n\n\n\nSegni unari: Il segno meno - o pi√π + applicato a un singolo valore.\n\nresult &lt;- -3 + 5  # Risultato: 2\n\n\n\nMoltiplicazione, divisione e modulo: Gli operatori *, /, %/% (divisione intera) e %% (resto) hanno la stessa precedenza e vengono eseguiti da sinistra a destra.\n\nresult &lt;- 10 / 2 * 3  # Risultato: 15\nresult &lt;- 10 %% 3     # Risultato: 1\n\n\n\nAddizione e sottrazione: Gli operatori + e - vengono eseguiti dopo quelli di moltiplicazione/divisione.\n\nresult &lt;- 5 + 3 - 2  # Risultato: 6\n\n\n\nOperatori di assegnazione: Gli operatori &lt;-, -&gt;, =, che assegnano valori a variabili, vengono valutati per ultimi.\n\nx &lt;- 2 + 3 * 4  # Risultato: 14\n\n\n\nNote importanti:\n\n\nAssociazione a sinistra: La maggior parte degli operatori in R viene valutata da sinistra a destra (ad esempio, +, *, /).\n\nUso delle parentesi: Quando l‚Äôordine di precedenza non √® immediatamente chiaro o si vuole assicurare un ordine specifico, √® sempre buona pratica usare le parentesi.\n\nCapire l‚Äôordine di precedenza √® fondamentale per evitare errori logici e garantire che il codice funzioni come previsto.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#funzioni",
    "href": "chapters/R/01_r_syntax.html#funzioni",
    "title": "6¬† Un approccio moderno all‚Äôanalisi dei dati",
    "section": "\n6.10 Funzioni",
    "text": "6.10 Funzioni\nFino ad ora abbiamo creato oggetti semplici assegnando loro direttamente un valore. Con l‚Äôaumento dell‚Äôesperienza in R, potresti voler creare oggetti pi√π complessi. Per aiutarti, R offre numerose funzioni gi√† disponibili nella sua installazione di base, e altre possono essere aggiunte installando pacchetti. Una funzione √® un insieme di istruzioni che eseguono un compito specifico. Inoltre, √® possibile creare funzioni personalizzate.\n\n6.10.1 La funzione c() per creare vettori\nLa prima funzione utile da imparare √® c(), che serve a concatenare valori in un vettore. Ad esempio:\n\nmy_vec &lt;- c(2, 3, 1, 6, 4, 3, 3, 7)\n\nQuesto codice crea un oggetto chiamato my_vec che contiene una sequenza di numeri. Alcuni concetti fondamentali sulle funzioni in R:\n\n\nNome e parentesi: Le funzioni in R sono sempre seguite da parentesi tonde ().\n\nArgomenti: Gli elementi passati alla funzione (tra le parentesi) ne personalizzano il comportamento e sono separati da virgole.\n\nPer vedere il contenuto del vettore:\n\nmy_vec\n#&gt; [1] 2 3 1 6 4 3 3 7\n\n\n6.10.2 Funzioni per analizzare vettori\nPuoi utilizzare altre funzioni per calcolare statistiche sul vettore:\n\nmean(my_vec)    # Media\n#&gt; [1] 3.625\n\n\nvar(my_vec)     # Varianza\n#&gt; [1] 3.982\n\n\nsd(my_vec)      # Deviazione standard\n#&gt; [1] 1.996\n\n\nlength(my_vec)  # Numero di elementi\n#&gt; [1] 8\n\nPuoi anche salvare i risultati in nuovi oggetti per riutilizzarli:\n\nvec_mean &lt;- mean(my_vec)\nvec_mean\n#&gt; [1] 3.625\n\n\n\n\n\n\n\nConcetto Chiave\n\n\n\n\n\nLa varianza e la deviazione standard sono misure statistiche descrittive che sintetizzano in un unico valore numerico la variabilit√† di un insieme di dati. Questi indici, che verranno approfonditi nel Capitolo 19, forniscono informazioni su quanto i valori di un dataset siano simili o diversi tra loro.\nIn particolare:\n\nla varianza e la deviazione standard sono pari a 0 quando tutti i valori nel dataset sono identici, indicando assenza di variabilit√†;\nassumono valori pi√π elevati all‚Äôaumentare delle differenze tra i dati, segnalando una maggiore dispersione.\n\nPer i nostri scopi attuali, √® sufficiente comprendere che queste misure descrivono il grado di diversit√† o omogeneit√† dei dati.\n\n\n\n\n6.10.3 Creare sequenze regolari\nPer creare sequenze di numeri in passi regolari, puoi usare i seguenti comandi.\nSimbolo : per sequenze semplici:\n\nmy_seq &lt;- 1:10\nmy_seq\n#&gt;  [1]  1  2  3  4  5  6  7  8  9 10\n\nFunzione seq() per maggiore controllo:\n\nmy_seq2 &lt;- seq(from = 1, to = 5, by = 0.5)\nmy_seq2\n#&gt; [1] 1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0\n\n\n6.10.4 Ripetere valori\nPuoi ripetere valori o sequenze con la funzione rep().\nRipetere un valore:\n\nmy_seq3 &lt;- rep(2, times = 10)\nmy_seq3\n#&gt;  [1] 2 2 2 2 2 2 2 2 2 2\n\nRipetere una sequenza:\n\nmy_seq5 &lt;- rep(1:5, times = 3)\n\nRipetere ogni elemento di una sequenza:\n\nmy_seq6 &lt;- rep(1:5, each = 3)\nmy_seq6\n#&gt;  [1] 1 1 1 2 2 2 3 3 3 4 4 4 5 5 5\n\n\n6.10.5 Annidare funzioni\n√à possibile combinare funzioni per creare comandi pi√π complessi, come nell‚Äôesempio:\n\nmy_seq7 &lt;- rep(c(3, 1, 10, 7), each = 3)\nmy_seq7\n#&gt;  [1]  3  3  3  1  1  1 10 10 10  7  7  7\n\nPer maggiore leggibilit√†, puoi separare i passaggi:\n\nin_vec &lt;- c(3, 1, 10, 7)\nmy_seq7 &lt;- rep(in_vec, each = 3)\nmy_seq7\n#&gt;  [1]  3  3  3  1  1  1 10 10 10  7  7  7\n\nQuesta pratica facilita la comprensione del codice e lo rende pi√π chiaro.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#lavorare-con-i-vettori-in-r",
    "href": "chapters/R/01_r_syntax.html#lavorare-con-i-vettori-in-r",
    "title": "6¬† Un approccio moderno all‚Äôanalisi dei dati",
    "section": "\n6.11 Lavorare con i Vettori in R",
    "text": "6.11 Lavorare con i Vettori in R\nIn R, i vettori sono uno degli elementi fondamentali per manipolare, riassumere e ordinare i dati. Qui trovi una panoramica su come estrarre, sostituire, ordinare, lavorare con dati mancanti e sfruttare la vettorizzazione dei vettori.\n\n6.11.1 Estrarre elementi da un vettore\nPuoi estrarre uno o pi√π elementi da un vettore usando le parentesi quadre [ ].\nPer posizione: Specifica la posizione degli elementi.\n\nmy_vec &lt;- c(2, 3, 1, 6, 4, 3, 3, 7)\nmy_vec[3]  # Terzo elemento\n#&gt; [1] 1\n\n\nmy_vec[c(1, 5, 6)]  # Elementi 1¬∞, 5¬∞ e 6¬∞\n#&gt; [1] 2 4 3\n\n\nmy_vec[3:8]  # Da 3¬∞ a 8¬∞\n#&gt; [1] 1 6 4 3 3 7\n\nCon condizioni logiche: Usa espressioni logiche per selezionare elementi.\n\nmy_vec[my_vec &gt; 4]  # Elementi &gt; 4\n#&gt; [1] 6 7\n\n\nmy_vec[my_vec &lt;= 4]  # Elementi ‚â§ 4\n#&gt; [1] 2 3 1 4 3 3\n\n\nmy_vec[my_vec != 4]  # Elementi diversi da 4\n#&gt; [1] 2 3 1 6 3 3 7\n\nOperatori logici: Combina condizioni con & (AND) e | (OR).\n\nmy_vec[my_vec &gt; 2 & my_vec &lt; 6]  # Tra 2 e 6\n#&gt; [1] 3 4 3 3\n\n\n6.11.2 Sostituire Elementi in un Vettore\nPuoi modificare i valori di un vettore usando [ ] e l‚Äôoperatore &lt;-.\nUn singolo elemento:\n\nmy_vec[4] &lt;- 500  # Cambia il 4¬∞ elemento\nmy_vec\n#&gt; [1]   2   3   1 500   4   3   3   7\n\nPi√π elementi:\n\nmy_vec[c(6, 7)] &lt;- 100  # Cambia il 6¬∞ e 7¬∞ elemento\nmy_vec\n#&gt; [1]   2   3   1 500   4 100 100   7\n\nCon condizioni logiche:\n\nmy_vec[my_vec &lt;= 4] &lt;- 1000  # Cambia valori ‚â§ 4\nmy_vec\n#&gt; [1] 1000 1000 1000  500 1000  100  100    7\n\n\n6.11.3 Ordinare un Vettore\nDal pi√π piccolo al pi√π grande:\n\nvec_sort &lt;- sort(my_vec)\nvec_sort\n#&gt; [1]    7  100  100  500 1000 1000 1000 1000\n\nDal pi√π grande al pi√π piccolo:\n\nvec_sort2 &lt;- sort(my_vec, decreasing = TRUE)\nvec_sort2\n#&gt; [1] 1000 1000 1000 1000  500  100  100    7\n\nOrdinare un vettore in base a un altro:\n\nheight &lt;- c(180, 155, 160, 167, 181)\np.names &lt;- c(\"Joanna\", \"Charlotte\", \"Helen\", \"Karen\", \"Amy\")\nheight_ord &lt;- order(height)\nnames_ord &lt;- p.names[height_ord]\nnames_ord\n#&gt; [1] \"Charlotte\" \"Helen\"     \"Karen\"     \"Joanna\"    \"Amy\"",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#operazioni-vettoriali-e-vettorizzazione-in-r",
    "href": "chapters/R/01_r_syntax.html#operazioni-vettoriali-e-vettorizzazione-in-r",
    "title": "6¬† Un approccio moderno all‚Äôanalisi dei dati",
    "section": "\n6.12 Operazioni Vettoriali e Vettorizzazione in R",
    "text": "6.12 Operazioni Vettoriali e Vettorizzazione in R\nLa vettorializzazione √® una delle caratteristiche pi√π potenti di R, che consente di applicare operazioni o funzioni direttamente a tutti gli elementi di un vettore in modo simultaneo, senza dover ricorrere a cicli espliciti. Questo approccio rende il codice pi√π conciso, leggibile ed efficiente, sfruttando al meglio le capacit√† intrinseche del linguaggio.\n\n6.12.1 Operazioni Aritmetiche su Vettori\nLe operazioni algebriche in R, come addizione, sottrazione, moltiplicazione e divisione, sono vettorizzate. Questo significa che ogni operazione viene applicata ‚Äúelemento per elemento‚Äù al vettore.\nConsideriamo ad esempio il seguente vettore:\n\nmy_vec &lt;- c(3, 5, 7, 1, 9, 20)\n\nSe vogliamo moltiplicare ciascun elemento di my_vec per 5, possiamo scrivere:\n\nmy_vec * 5\n#&gt; [1]  15  25  35   5  45 100\n\nAnalogamente, possiamo effettuare altre operazioni algebriche, come divisione o elevamento a potenza:\n\nmy_vec / 2\n#&gt; [1]  1.5  2.5  3.5  0.5  4.5 10.0\n\n\nmy_vec^2\n#&gt; [1]   9  25  49   1  81 400\n\nQueste operazioni vengono applicate automaticamente a ciascun elemento del vettore, senza dover iterare su di essi.\n\n6.12.2 Operazioni Elemento per Elemento tra Due Vettori\nLa vettorializzazione consente anche di eseguire operazioni tra due vettori, applicandole elemento per elemento. Supponiamo di avere un secondo vettore:\n\nmy_vec2 &lt;- c(17, 15, 13, 19, 11, 0)\n\nSe vogliamo sommare i due vettori, possiamo scrivere:\n\nmy_vec + my_vec2\n#&gt; [1] 20 20 20 20 20 20\n\nIn questo caso, il primo elemento di my_vec viene sommato al primo elemento di my_vec2, il secondo elemento al secondo, e cos√¨ via.\n\nEsempio 6.3 Di seguito mostriamo come calcolare i punteggi totali per 10 individui che hanno risposto ai 5 item della Satisfaction With Life Scale (SWLS), utilizzando le formule e l‚Äôaritmetica vettorializzata di R.\nStep 1: Definiamo i punteggi per ciascun item. Ogni vettore contiene i punteggi dati dai 10 individui a uno specifico item della scala:\n\n# Punteggi dei 10 individui per ciascun item\nitem1 &lt;- c(5, 4, 6, 7, 3, 2, 5, 6, 4, 7)\nitem2 &lt;- c(3, 2, 4, 6, 2, 1, 4, 5, 3, 6)\nitem3 &lt;- c(4, 5, 6, 5, 3, 2, 5, 7, 4, 5)\nitem4 &lt;- c(2, 3, 4, 3, 2, 1, 3, 4, 2, 5)\nitem5 &lt;- c(2, 2, 3, 4, 1, 1, 3, 3, 2, 4)\n\nI valori 5, 3, 4, 2, 2 sono i punteggi del primo individuo sui 5 item; i punteggio 4, 2, 5, 3, 2 sono i punteggi del secondo individuo sui 5 item, e cos√¨ via.\nStep 2: Sommiamo i punteggi per calcolare il totale. Il punteggio totale di ciascun individuo √® la somma dei punteggi relativi ai 5 item. Formalmente, per l‚Äôindividuo \\(i\\) (\\(i = 1, 2, \\ldots, 10\\)), il punteggio totale √® calcolato come:\n\\[\n\\text{PunteggioTotale}_i = \\text{item1}_i + \\text{item2}_i + \\text{item3}_i + \\text{item4}_i + \\text{item5}_i .\n\\]\nIn R, possiamo sommare i vettori direttamente grazie all‚Äôaritmetica vettorializzata:\n\n# Calcolo dei punteggi totali per ciascun individuo\ntotal_scores &lt;- item1 + item2 + item3 + item4 + item5\ntotal_scores\n#&gt;  [1] 16 16 23 25 11  7 20 25 15 27\n\nIl risultato √® un vettore con i punteggi totali per ciascun individuo.\nStep 3: Mostriamo i risultati. Per organizzare meglio i dati, creiamo una tabella che associa i punteggi totali agli individui:\n\n# Creiamo una tabella con i punteggi totali\nindividui &lt;- paste(\"Individuo\", 1:10)\nrisultati_swls &lt;- data.frame(Individuo = individui, PunteggioTotale = total_scores)\nprint(risultati_swls)\n#&gt;       Individuo PunteggioTotale\n#&gt; 1   Individuo 1              16\n#&gt; 2   Individuo 2              16\n#&gt; 3   Individuo 3              23\n#&gt; 4   Individuo 4              25\n#&gt; 5   Individuo 5              11\n#&gt; 6   Individuo 6               7\n#&gt; 7   Individuo 7              20\n#&gt; 8   Individuo 8              25\n#&gt; 9   Individuo 9              15\n#&gt; 10 Individuo 10              27\n\nSpiegazione delle operazioni:\n\nOgni vettore contiene i punteggi di 10 individui per un dato item. Ad esempio, il vettore item1 contiene i punteggi relativi al primo item, e cos√¨ via.\n\nGrazie all‚Äôaritmetica vettorializzata, quando sommiamo i vettori \\(\\text{item1}\\), \\(\\text{item2}\\), \\(\\text{item3}\\), \\(\\text{item4}\\), \\(\\text{item5}\\), R somma elemento per elemento:\n\\[\n\\text{total\\_scores}_i = \\text{item1}_i + \\text{item2}_i + \\text{item3}_i + \\text{item4}_i + \\text{item5}_i\n\\]\n\nQuesta tecnica consente di calcolare rapidamente i punteggi totali per tutti gli individui senza dover scrivere un ciclo esplicito, rendendo il codice pi√π semplice e leggibile.\n\nQuesto esempio illustra come R semplifichi operazioni complesse grazie al calcolo vettorializzato, migliorando l‚Äôefficienza e la chiarezza del codice.\n\n\n6.12.3 Attenzione al Riciclo dei Vettori\nSe i due vettori hanno lunghezze diverse, R applicher√† il meccanismo di riciclo: gli elementi del vettore pi√π corto verranno ripetuti ciclicamente per abbinarsi alla lunghezza del vettore pi√π lungo. Questo comportamento, sebbene utile, richiede attenzione per evitare risultati inattesi.\nAd esempio:\n\nshort_vec &lt;- c(1, 2)\nmy_vec + short_vec\n#&gt; [1]  4  7  8  3 10 22\n\nIn questo caso, gli elementi di short_vec vengono riciclati per abbinarsi alla lunghezza di my_vec. Il risultato √®:\n(3+1, 5+2, 7+1, 1+2, 9+1, 20+2)\n\n6.12.4 Applicazione di Funzioni su Vettori\nLa vettorializzazione non si limita alle operazioni algebriche, ma si estende anche all‚Äôuso di funzioni. Supponiamo di voler calcolare il logaritmo naturale di ciascun elemento di un vettore:\n\nlog(my_vec)\n#&gt; [1] 1.099 1.609 1.946 0.000 2.197 2.996\n\nLa funzione log() viene applicata automaticamente a ogni elemento del vettore. Analogamente, possiamo utilizzare altre funzioni predefinite di R, come:\n\nsqrt(my_vec)  # Calcola la radice quadrata di ciascun elemento\n#&gt; [1] 1.732 2.236 2.646 1.000 3.000 4.472\nexp(my_vec)   # Eleva e alla potenza specificata da ciascun elemento\n#&gt; [1] 2.009e+01 1.484e+02 1.097e+03 2.718e+00 8.103e+03 4.852e+08\n\nIn conclusione, la vettorializzazione in R rappresenta un approccio elegante ed efficiente per gestire calcoli su vettori. Che si tratti di operazioni algebriche, operazioni tra vettori o applicazione di funzioni, la possibilit√† di evitare cicli espliciti migliora la leggibilit√† e la velocit√† del codice. Tuttavia, √® importante prestare attenzione al riciclo dei vettori per evitare errori non intenzionali.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#gestire-dati-mancanti-na",
    "href": "chapters/R/01_r_syntax.html#gestire-dati-mancanti-na",
    "title": "6¬† Un approccio moderno all‚Äôanalisi dei dati",
    "section": "\n6.13 Gestire Dati Mancanti (NA)",
    "text": "6.13 Gestire Dati Mancanti (NA)\nR rappresenta i dati mancanti con NA. La gestione dei dati mancanti dipende dalla funzione utilizzata.\nCalcolo con dati mancanti:\n\ntemp &lt;- c(7.2, NA, 7.1, 6.9, 6.5, 5.8, 5.8, 5.5, NA, 5.5)\nmean(temp)  # Restituisce NA\n#&gt; [1] NA\n\n\nmean(temp, na.rm = TRUE)  # Ignora i valori mancanti\n#&gt; [1] 6.287\n\nNota: na.rm = TRUE √® un argomento comune per ignorare i NA, ma non tutte le funzioni lo supportano. Consulta la documentazione della funzione per verificare come gestisce i dati mancanti.\nIn conclusione, manipolare vettori √® un‚Äôabilit√† essenziale in R. Dalla selezione e modifica degli elementi all‚Äôordinamento e gestione di dati mancanti, queste tecniche sono alla base dell‚Äôanalisi dei dati in R.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#i-dati-in-r",
    "href": "chapters/R/01_r_syntax.html#i-dati-in-r",
    "title": "6¬† Un approccio moderno all‚Äôanalisi dei dati",
    "section": "\n6.14 I Dati in R",
    "text": "6.14 I Dati in R\nIn R, i dati possono essere rappresentati in diversi tipi e strutture. Comprendere come gestirli √® fondamentale per manipolare, analizzare e riassumere i dataset pi√π complessi.\n\n6.14.1 Tipi di Dati in R\nR supporta diversi tipi di dati:\n\n\nNumeric: Numeri decimali (es. 2.5).\n\nInteger: Numeri interi (es. 3).\n\nLogical: Valori booleani (TRUE o FALSE) e NA per dati mancanti.\n\nCharacter: Stringhe di testo (es. \"hello\").\n\nFactor: Variabili categoriche (es. livelli come \"low\", \"medium\", \"high\").\n\nPuoi verificare il tipo di un oggetto con class() e controllare se appartiene a un tipo specifico con funzioni come is.numeric(). √à anche possibile convertire un tipo in un altro con funzioni come as.character().\n\n6.14.2 Strutture di Dati in R\nVettori: Contengono dati dello stesso tipo (es. numeri, stringhe o logici).\n\nmy_vec &lt;- c(1, 2, 3)\nmy_vec\n#&gt; [1] 1 2 3\n\nMatrici e array: Strutture bidimensionali (matrici) o multidimensionali (array) con dati dello stesso tipo.\nCreare una matrice:\n\nmy_mat &lt;- matrix(1:12, nrow = 3, byrow = TRUE)\nmy_mat\n#&gt;      [,1] [,2] [,3] [,4]\n#&gt; [1,]    1    2    3    4\n#&gt; [2,]    5    6    7    8\n#&gt; [3,]    9   10   11   12\n\nOperazioni utili:\n\n\nTrasposizione: t(my_mat)\n\n\nDiagonale: diag(my_mat)\n\n\nMoltiplicazione matriciale: mat1 %*% mat2\n\n\nListe: Possono contenere elementi di tipi diversi, inclusi vettori, matrici o altre liste.\n\nmy_list &lt;- list(\n  numbers = c(1, 2), \n  text = \"hello\", \n  mat = matrix(1:4, nrow = 2)\n)\nmy_list$numbers  # Accedi agli elementi con il nome\n#&gt; [1] 1 2\n\nData frame: Strutture bidimensionali che possono contenere colonne di tipi diversi. Ideale per dataset strutturati.\nCreare un data frame:\n\nheight &lt;- c(180, 155, 160)\nweight &lt;- c(65, 50, 52)\nnames &lt;- c(\"Joanna\", \"Charlotte\", \"Helen\")\n\ndataf &lt;- data.frame(height = height, weight = weight, names = names)\nstr(dataf)  # Mostra la struttura del data frame\n#&gt; 'data.frame':    3 obs. of  3 variables:\n#&gt;  $ height: num  180 155 160\n#&gt;  $ weight: num  65 50 52\n#&gt;  $ names : chr  \"Joanna\" \"Charlotte\" \"Helen\"\n\nPer convertire le stringhe in fattori durante la creazione:\n\ndataf &lt;- data.frame(\n  height = height, \n  weight = weight, \n  names = names, \n  stringsAsFactors = TRUE\n)\n\ndataf\n#&gt;   height weight     names\n#&gt; 1    180     65    Joanna\n#&gt; 2    155     50 Charlotte\n#&gt; 3    160     52     Helen\n\n\n6.14.3 Operazioni Utili sui Data Frame\n\n\nVerificare dimensioni: dim(dataf)\n\n\nVisualizzare struttura: str(dataf)\n\n\nAccedere a colonne: dataf$height",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#operazioni-di-base-in-r",
    "href": "chapters/R/01_r_syntax.html#operazioni-di-base-in-r",
    "title": "6¬† Un approccio moderno all‚Äôanalisi dei dati",
    "section": "\n6.15 Operazioni di Base in R",
    "text": "6.15 Operazioni di Base in R\n\n6.15.1 Operazioni Aritmetiche\nCome abbiamo visto in precedenza, R supporta le classiche operazioni aritmetiche come somma (+), sottrazione (-), moltiplicazione (*), divisione (/) ed esponenziazione (^).\n\n6.15.2 Operazioni Logiche\nLe operazioni logiche in R includono:\n\n\n&: ‚Äúand‚Äù logico\n\n\n|: ‚Äúor‚Äù logico\n\n\n!: ‚Äúnot‚Äù logico\n\n\n&gt;: maggiore di\n\n\n&lt;: minore di\n\n\n==: uguale a\n\n\n!=: diverso da\n\nPer esempio:\n\n# Maggiore di\n3 &gt; 2\n#&gt; [1] TRUE\n# Uguale a\n3 == 2\n#&gt; [1] FALSE\n\n\nEsempio 6.4 Consideriamo l‚Äôesempio precedente, in cui abbiamo calcolato i punteggi totali dei 10 individui sulla Satisfaction With Life Scale (SWLS). Ora vogliamo determinare la proporzione di individui nel campione che ha ottenuto un punteggio totale maggiore di 15.\nI punteggi totali dei 10 individui sono memorizzati nella colonna PunteggioTotale del data frame risultati_swls:\n\nrisultati_swls$PunteggioTotale\n#&gt;  [1] 16 16 23 25 11  7 20 25 15 27\n\nPossiamo creare un vettore logico che indica, per ciascun individuo, se il suo punteggio totale supera 15. In R, l‚Äôoperatore di confronto &gt; restituisce un valore TRUE se la condizione √® soddisfatta e FALSE altrimenti:\n\nrisultati_swls$PunteggioTotale &gt; 15\n#&gt;  [1]  TRUE  TRUE  TRUE  TRUE FALSE FALSE  TRUE  TRUE FALSE  TRUE\n\nIn R, i valori TRUE e FALSE possono essere trattati come numeri: TRUE equivale a 1 e FALSE equivale a 0. Questo ci permette di sommare i valori logici per contare quante volte la condizione √® soddisfatta. Per calcolare la proporzione, dividiamo questa somma per il numero totale di individui:\n\nsum(risultati_swls$PunteggioTotale &gt; 15) / length(risultati_swls$PunteggioTotale)\n#&gt; [1] 0.7\n\nLa proporzione √® calcolata come:\n\\[\n\\text{Proporzione} = \\frac{\\sum_{i=1}^{n} I(\\text{PunteggioTotale}_i &gt; 15)}{n} ,\n\\]\ndove:\n\n\n\\(n\\) √® il numero totale di individui (in questo caso, 10),\n\n\\(I(\\text{PunteggioTotale}_i &gt; 15)\\) √® una funzione indicatrice che vale 1 se il punteggio dell‚Äôindividuo \\(i\\) √® maggiore di 15, e 0 altrimenti.\n\nNel nostro esempio, la proporzione degli individui con punteggio totale maggiore di 15 √® 0.7, cio√® il 70% del campione soddisfa questa condizione.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#estrazione-di-sottoinsiemi-di-oggetti-in-r",
    "href": "chapters/R/01_r_syntax.html#estrazione-di-sottoinsiemi-di-oggetti-in-r",
    "title": "6¬† Un approccio moderno all‚Äôanalisi dei dati",
    "section": "\n6.16 Estrazione di Sottoinsiemi di Oggetti in R",
    "text": "6.16 Estrazione di Sottoinsiemi di Oggetti in R\nIn R esistono tre operatori principali per estrarre sottoinsiemi di oggetti:\n\nOperatore [ ]\nQuesto operatore restituisce sempre un oggetto della stessa classe dell‚Äôoriginale. √à utile per selezionare pi√π elementi da un oggetto. √à importante chiudere l‚Äôestrazione con ].\nOperatore [[ ]]\nQuesto operatore viene utilizzato per estrarre elementi da liste o data frame. A differenza di [ ], permette di estrarre un solo elemento alla volta e la classe dell‚Äôoggetto restituito non sar√† necessariamente una lista o un data frame. L‚Äôestrazione va chiusa con ]].\nOperatore $\nCome visto in precedenza, questo operatore serve per estrarre elementi da una lista o un data frame utilizzando il loro nome letterale. Il comportamento semantico √® simile a quello di [[ ]].\n\n\n6.16.1 Gli Indici di un Data Frame in R\nIn R, gli indici di un data frame sono utilizzati per selezionare righe e colonne. La sintassi generale √®:\ndf[i, j]\ndove:\n\n\ni rappresenta l‚Äôindice o gli indici delle righe,\n\n\nj rappresenta l‚Äôindice o gli indici delle colonne.\n\nSe uno degli indici viene omesso, si considerano tutte le righe o tutte le colonne, a seconda della dimensione omessa.\n\n6.16.1.1 Esempi Pratici\n\n\nSelezione di righe specifiche su tutte le colonne\nSe vogliamo estrarre solo alcune righe, possiamo specificare gli indici delle righe nel primo argomento e lasciare vuoto il secondo. Ad esempio:\ndf[c(2, 3, 5), ]\nQuesto seleziona la seconda, terza e quinta riga del data frame df, includendo tutte le colonne.\n\n\nSelezione di colonne specifiche su tutte le righe\nPer selezionare solo alcune colonne, specifichiamo i loro indici nel secondo argomento e lasciamo vuoto il primo. Ad esempio:\ndf[, c(2, 3, 5)]\nQuesto seleziona la seconda, terza e quinta colonna del data frame df, includendo tutte le righe.\n\n\nSelezione di righe e colonne specifiche\nPossiamo combinare gli indici per selezionare una sotto-matrice specifica. Ad esempio:\ndf[c(2, 4), c(1, 3)]\nQuesto seleziona le righe 2 e 4 e le colonne 1 e 3.\n\n\n6.16.1.2 Ulteriori Dettagli\n\n\nSelezione singola di riga o colonna\nSe vogliamo estrarre una singola riga o colonna, possiamo specificare un solo valore per i o j. Ad esempio:\ndf[1, ]  # Prima riga, tutte le colonne\ndf[, 2]  # Seconda colonna, tutte le righe\n\n\nUso di nomi invece di indici\nSe il data frame ha nomi per righe o colonne, possiamo utilizzarli per la selezione. Ad esempio:\ndf[\"nome_riga\", ]        # Seleziona la riga con nome \"nome_riga\"\ndf[, \"nome_colonna\"]     # Seleziona la colonna con nome \"nome_colonna\"\n\n\nSelezione logica\nPossiamo utilizzare un vettore logico per selezionare righe o colonne. Ad esempio, per selezionare le righe dove il valore nella prima colonna √® maggiore di 10:\ndf[df[, 1] &gt; 10, ]\n\n\n6.16.1.3 Sintesi Visiva\n\n\n\n\n\n\nSintassi\nDescrizione\n\n\n\ndf[i, ]\nSeleziona la riga i con tutte le colonne.\n\n\ndf[, j]\nSeleziona la colonna j con tutte le righe.\n\n\ndf[c(i1, i2), c(j1, j2)]\nSeleziona righe e colonne specifiche.\n\n\ndf[i, j]\nSeleziona l‚Äôintersezione di righe e colonne.\n\n\ndf[ , ]\nRestituisce l‚Äôintero data frame.\n\n\n\nQuesta flessibilit√† rende l‚Äôindicizzazione dei data frame in R potente ed efficace per manipolare e analizzare i dati.\n\nEsempio 6.5 Consideriamo il data frame iris incluso di default in base R.\n\niris |&gt; head()\n#&gt;   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n#&gt; 1          5.1         3.5          1.4         0.2  setosa\n#&gt; 2          4.9         3.0          1.4         0.2  setosa\n#&gt; 3          4.7         3.2          1.3         0.2  setosa\n#&gt; 4          4.6         3.1          1.5         0.2  setosa\n#&gt; 5          5.0         3.6          1.4         0.2  setosa\n#&gt; 6          5.4         3.9          1.7         0.4  setosa\n\nUsiamo la funzione head() per stampare le prime 6 righe del data frame.\nL‚Äôistruzione seguente restituisce le prime tre colonne del dataset iris.\n\niris[, 1:3] |&gt; head()\n#&gt;   Sepal.Length Sepal.Width Petal.Length\n#&gt; 1          5.1         3.5          1.4\n#&gt; 2          4.9         3.0          1.4\n#&gt; 3          4.7         3.2          1.3\n#&gt; 4          4.6         3.1          1.5\n#&gt; 5          5.0         3.6          1.4\n#&gt; 6          5.4         3.9          1.7\n\nSelezione di colonne specifiche per nome:\n\niris[, c('Sepal.Length', 'Petal.Length')] |&gt; \n  head()  \n#&gt;   Sepal.Length Petal.Length\n#&gt; 1          5.1          1.4\n#&gt; 2          4.9          1.4\n#&gt; 3          4.7          1.3\n#&gt; 4          4.6          1.5\n#&gt; 5          5.0          1.4\n#&gt; 6          5.4          1.7\n\nSelezione di una singola colonna:\n\niris[, 'Petal.Length'] \n#&gt;   [1] 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 1.5 1.6 1.4 1.1 1.2 1.5 1.3\n#&gt;  [18] 1.4 1.7 1.5 1.7 1.5 1.0 1.7 1.9 1.6 1.6 1.5 1.4 1.6 1.6 1.5 1.5 1.4\n#&gt;  [35] 1.5 1.2 1.3 1.4 1.3 1.5 1.3 1.3 1.3 1.6 1.9 1.4 1.6 1.4 1.5 1.4 4.7\n#&gt;  [52] 4.5 4.9 4.0 4.6 4.5 4.7 3.3 4.6 3.9 3.5 4.2 4.0 4.7 3.6 4.4 4.5 4.1\n#&gt;  [69] 4.5 3.9 4.8 4.0 4.9 4.7 4.3 4.4 4.8 5.0 4.5 3.5 3.8 3.7 3.9 5.1 4.5\n#&gt;  [86] 4.5 4.7 4.4 4.1 4.0 4.4 4.6 4.0 3.3 4.2 4.2 4.2 4.3 3.0 4.1 6.0 5.1\n#&gt; [103] 5.9 5.6 5.8 6.6 4.5 6.3 5.8 6.1 5.1 5.3 5.5 5.0 5.1 5.3 5.5 6.7 6.9\n#&gt; [120] 5.0 5.7 4.9 6.7 4.9 5.7 6.0 4.8 4.9 5.6 5.8 6.1 6.4 5.6 5.1 5.6 6.1\n#&gt; [137] 5.6 5.5 4.8 5.4 5.6 5.1 5.1 5.9 5.7 5.2 5.0 5.2 5.4 5.1\n\noppure\n\niris$Petal.Length\n#&gt;   [1] 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 1.5 1.6 1.4 1.1 1.2 1.5 1.3\n#&gt;  [18] 1.4 1.7 1.5 1.7 1.5 1.0 1.7 1.9 1.6 1.6 1.5 1.4 1.6 1.6 1.5 1.5 1.4\n#&gt;  [35] 1.5 1.2 1.3 1.4 1.3 1.5 1.3 1.3 1.3 1.6 1.9 1.4 1.6 1.4 1.5 1.4 4.7\n#&gt;  [52] 4.5 4.9 4.0 4.6 4.5 4.7 3.3 4.6 3.9 3.5 4.2 4.0 4.7 3.6 4.4 4.5 4.1\n#&gt;  [69] 4.5 3.9 4.8 4.0 4.9 4.7 4.3 4.4 4.8 5.0 4.5 3.5 3.8 3.7 3.9 5.1 4.5\n#&gt;  [86] 4.5 4.7 4.4 4.1 4.0 4.4 4.6 4.0 3.3 4.2 4.2 4.2 4.3 3.0 4.1 6.0 5.1\n#&gt; [103] 5.9 5.6 5.8 6.6 4.5 6.3 5.8 6.1 5.1 5.3 5.5 5.0 5.1 5.3 5.5 6.7 6.9\n#&gt; [120] 5.0 5.7 4.9 6.7 4.9 5.7 6.0 4.8 4.9 5.6 5.8 6.1 6.4 5.6 5.1 5.6 6.1\n#&gt; [137] 5.6 5.5 4.8 5.4 5.6 5.1 5.1 5.9 5.7 5.2 5.0 5.2 5.4 5.1\n\nPer selezionare righe specifiche, definiamo gli indici corrispondenti. Per esempio, l‚Äôistruzione seguente restituisce le righe 1 e 3.\n\niris[c(1, 3), ]\n#&gt;   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n#&gt; 1          5.1         3.5          1.4         0.2  setosa\n#&gt; 3          4.7         3.2          1.3         0.2  setosa\n\nFiltraggio logico di righe:\n\niris[iris$Species == 'versicolor', ] |&gt; head()\n#&gt;    Sepal.Length Sepal.Width Petal.Length Petal.Width    Species\n#&gt; 51          7.0         3.2          4.7         1.4 versicolor\n#&gt; 52          6.4         3.2          4.5         1.5 versicolor\n#&gt; 53          6.9         3.1          4.9         1.5 versicolor\n#&gt; 54          5.5         2.3          4.0         1.3 versicolor\n#&gt; 55          6.5         2.8          4.6         1.5 versicolor\n#&gt; 56          5.7         2.8          4.5         1.3 versicolor\n\nRestituisce le righe con Species uguale a ‚Äúversicolor‚Äù. Numero di righe e colonne del sottoinsieme:\n\ndim(iris[iris$Species == 'versicolor', ])\n#&gt; [1] 50  5\n\n\n\n6.16.2 Filtraggio Avanzato con Operatori Logici\nGli operatori logici & (AND), | (OR) e ! (NOT) permettono un filtraggio pi√π sofisticato.\nEsempio: Filtrare le osservazioni di specie ‚Äúversicolor‚Äù con lunghezza del sepalo non superiore a 5.0:\n\niris[(iris$Species == 'versicolor') & (iris$Sepal.Length &lt;= 5.0), ]\n#&gt;    Sepal.Length Sepal.Width Petal.Length Petal.Width    Species\n#&gt; 58          4.9         2.4          3.3           1 versicolor\n#&gt; 61          5.0         2.0          3.5           1 versicolor\n#&gt; 94          5.0         2.3          3.3           1 versicolor\n\nNumero di osservazioni trovate:\n\ndim(iris[(iris$Species == 'versicolor') & (iris$Sepal.Length &lt;= 5.0), ])\n#&gt; [1] 3 5",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#riflessioni-conclusive",
    "href": "chapters/R/01_r_syntax.html#riflessioni-conclusive",
    "title": "6¬† Un approccio moderno all‚Äôanalisi dei dati",
    "section": "\n6.17 Riflessioni Conclusive",
    "text": "6.17 Riflessioni Conclusive\nR non √® soltanto un linguaggio di programmazione per la statistica, ma rappresenta una filosofia che si fonda su tre principi chiave: apertura, collaborazione e avanzamento della conoscenza scientifica.\nPer chi si avvicina a R, sia nel campo della comunicazione sia in altri ambiti, cogliere questa filosofia √® essenziale per apprezzarne appieno il valore. R promuove non solo competenze tecniche, ma anche un impegno verso pratiche di ricerca trasparente e riproducibile, che costituiscono un pilastro fondamentale per una scienza rigorosa e affidabile.\nOpen Source\nR √® un software open source, liberamente accessibile a tutti. Questo significa che chiunque pu√≤ visualizzarne, modificarne e distribuirne il codice sorgente, promuovendo un ambiente trasparente e collaborativo. Essendo gratuito, R garantisce accessibilit√† a ricercatori di tutto il mondo, indipendentemente dal budget o dal supporto istituzionale. Inoltre, grazie alla sua natura aperta, R beneficia del contributo collettivo di una comunit√† globale eterogenea.\nContributi della Comunit√†\nLa comunit√† di R √® uno dei suoi punti di forza principali. Statistici, ricercatori e data scientist di diverse discipline arricchiscono continuamente R sviluppando pacchetti: raccolte di funzioni, dati e codice che ampliano le sue funzionalit√†. Questa collaborazione ha portato alla creazione di migliaia di pacchetti che coprono tecniche statistiche, metodi grafici e strumenti per la manipolazione dei dati, rendendo R uno strumento sempre pi√π versatile e adatto a un‚Äôampia gamma di esigenze di ricerca.\nRicerca Riproducibile\nLa ricerca riproducibile consiste nel condurre studi in modo tale che altri possano replicarne i risultati utilizzando gli stessi dati e seguendo la stessa metodologia. Questo approccio √® cruciale per la validazione delle scoperte scientifiche, permettendo la verifica dei risultati e la costruzione di nuove conoscenze su basi solide.\nR facilita la ricerca riproducibile grazie a:\n\nUn ecosistema completo di pacchetti per l‚Äôanalisi dei dati e la generazione di report dinamici.\n\nStrumenti come R Markdown e Quarto, che permettono di integrare testo descrittivo e codice R in un unico documento. Questa integrazione consente di documentare ogni fase del processo di ricerca‚Äîdalla pulizia dei dati all‚Äôanalisi e alla presentazione dei risultati‚Äîgarantendo trasparenza e replicabilit√†.\n\nIn conclusione, comprendere la filosofia open source di R e il suo ruolo nella promozione della ricerca riproducibile fornisce un quadro chiaro del motivo per cui R √® diventato uno strumento essenziale per ricercatori e statistici di diverse discipline. Per chi opera in psicologia, sfruttare le potenzialit√† di R significa produrre risultati di ricerca pi√π trasparenti, replicabili e credibili, contribuendo alla robustezza e affidabilit√† della conoscenza scientifica nel settore.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#esercizi",
    "href": "chapters/R/01_r_syntax.html#esercizi",
    "title": "6¬† Un approccio moderno all‚Äôanalisi dei dati",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nSvolgere gli esercizi da 1 a 38, sia in modo manuale che utilizzando R. Gli esercizi sono disponibili al seguente link:Esercizi su Summation Notation.\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nIn questo esercizio, lavorerai con i dati della Satisfaction With Life Scale (SWLS) raccolti da ciascuno degli studenti del gruppo TPV di appartenenza.\nIstruzioni SWLS: Di seguito sono riportate alcune affermazioni con cui puoi descrivere la tua soddisfazione rispetto alla tua vita. Indica quanto sei d‚Äôaccordo con ciascuna affermazione utilizzando la scala di risposta fornita.\n\nIl pi√π delle volte la mia vita √® vicina al mio ideale di vita.\nLe condizioni della mia vita sono eccellenti.\nSono soddisfatto/a della mia vita.\nFinora ho ottenuto le cose importanti che voglio dalla vita.\nSe io potessi rivivere la mia vita, non cambierei quasi nulla.\n\nLa SWLS utilizza una scala Likert a 7 punti, con i seguenti ancoraggi:\n\nFortemente in disaccordo\nDisaccordo\nLeggermente in disaccordo\nN√© d‚Äôaccordo n√© in disaccordo\nLeggermente d‚Äôaccordo\nD‚Äôaccordo\nFortemente d‚Äôaccordo\n\nIl tuo compito sar√† analizzare i dati raccolti sia manualmente su carta che utilizzando R.\nParte 1: Calcolo Manuale\n\n\nCalcolo del punteggio totale\n\nLa SWLS √® composta da 5 item, ciascuno valutato su una scala Likert da 1 a 7.\nSomma i punteggi dei 5 item per ciascun partecipante per ottenere il punteggio totale.\n\nRegistra i punteggi totali su carta.\n\n\n\nDeterminazione della media del campione\n\nCalcola la media aritmetica dei punteggi totali dei 10 studenti.\nScrivi il calcolo e il risultato.\n\n\n\nCalcolo della deviazione standard\n\n\nCalcola la deviazione standard dei punteggi totali manualmente utilizzando la formula:\n\\[\ns^2 = \\sqrt{\\frac{\\sum_{i=1}^n (x_i - \\bar{x})^2}{n-1}}.\n\\]\n\nRegistra il risultato.\n\n\n\nParte 2: Analisi con R\n\n\nCreazione del dataset in R\n\nInserisci i dati in R come un vettore chiamato swls_scores.\n\n\n\nCalcolo della media e della deviazione standard in R\n\nUsa le funzioni mean() e sd() per ottenere la media e la deviazione standard dei punteggi totali.\n\n\n\nVisualizzazione dei dati\n\nCrea un istogramma per visualizzare la distribuzione dei punteggi totali utilizzando hist(). Se non conosci l‚Äôistogramma, fai una ricerca su web; commenta il risultato ottenuto.\n\n\n\nIdentificazione dei punteggi superiori a 20\n\nUtilizza un‚Äôoperazione logica per contare quanti partecipanti hanno un punteggio totale maggiore di 20.\n\n\n\nFiltraggio dei dati\n\nEstrai e visualizza solo i punteggi superiori alla media del campione.\n\n\n\nEsportazione dei risultati\n\nSalva i punteggi totali in un file CSV utilizzando la funzione write.csv().\n\n\n\nConsegna\n\nScrivi le risposte della Parte 1 su carta.\nScrivi il codice e i risultati della Parte 2 in un file .R e invialo come consegna.\n\n\n\n\n\n\n\n\n\n\nSoluzioni 2\n\n\n\n\n\nParte 1: Calcolo Manuale\n\n\nCalcolo del punteggio totale\n\n\nSupponiamo che i punteggi per 10 studenti siano:\n\n\nStudente\nItem 1\nItem 2\nItem 3\nItem 4\nItem 5\nTotale\n\n\n\n1\n5\n4\n6\n3\n2\n20\n\n\n2\n4\n2\n5\n3\n2\n16\n\n\n3\n6\n4\n6\n4\n3\n23\n\n\n4\n7\n6\n5\n3\n4\n25\n\n\n5\n3\n2\n3\n2\n1\n11\n\n\n6\n2\n1\n2\n1\n1\n7\n\n\n7\n5\n4\n5\n3\n3\n20\n\n\n8\n6\n5\n7\n4\n3\n25\n\n\n9\n4\n3\n4\n2\n2\n15\n\n\n10\n7\n6\n5\n5\n4\n27\n\n\n\n\n\n\n\nDeterminazione della media\n\n\nMedia:\n\\[\n\\bar{x} = \\frac{20+16+23+25+11+7+20+25+15+27}{10} = 18.9\n\\]\n\n\n\n\nCalcolo della deviazione standard\n\n\nLa deviazione standard √®:\n\\[\ns = \\sqrt{\\frac{1}{9} \\sum (x_i - 18.9)^2} \\approx 6.56\n\\]\n\n\n\n\nParte 2: Analisi con R\n\n\nCreazione del dataset in R\nswls_scores &lt;- c(20, 16, 23, 25, 11, 7, 20, 25, 15, 27)\n\n\nCalcolo della media e della deviazione standard\nmean(swls_scores)  # Media\nsd(swls_scores)    # Deviazione standard\n\n\nVisualizzazione dei dati\nhist(swls_scores, main=\"Distribuzione SWLS\", xlab=\"Punteggi\", col=\"lightblue\", border=\"black\")\n\n\nIdentificazione dei punteggi superiori a 20\nsum(swls_scores &gt; 20)  # Numero di studenti con punteggio &gt; 20\n\n\nFiltraggio dei dati\nswls_scores[swls_scores &gt; mean(swls_scores)]\n\n\nEsportazione dei risultati\nwrite.csv(data.frame(Student=1:10, Score=swls_scores), \"swls_results.csv\", row.names=FALSE)\n\n\nConclusione Questi esercizi hanno permesso di confrontare il calcolo manuale con l‚Äôautomatizzazione tramite R, facilitando l‚Äôanalisi statistica della SWLS.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/R/01_r_syntax.html#informazioni-sullambiente-di-sviluppo",
    "title": "6¬† Un approccio moderno all‚Äôanalisi dei dati",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.5.3     \n#&gt;  [9] scales_1.3.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.9.1   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         rlang_1.1.5       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       tools_4.4.2       parallel_4.4.2    tzdb_0.5.0       \n#&gt; [21] colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5       R6_2.6.1         \n#&gt; [25] lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.1    \n#&gt; [29] gtable_0.3.6      glue_1.8.0        xfun_0.51         tidyselect_1.2.1 \n#&gt; [33] rstudioapi_0.17.1 farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-167     \n#&gt; [37] rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#bibliografia",
    "href": "chapters/R/01_r_syntax.html#bibliografia",
    "title": "6¬† Un approccio moderno all‚Äôanalisi dei dati",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nCollaboration, O. S. (2015). Estimating the reproducibility of psychological science. Science, 349(6251), aac4716.\n\n\nIrizarry, R. A. (2024). Introduction to Data Science: Data Wrangling and Visualization with R. CRC Press.\n\n\nKnuth, D. E. (1984). Literate programming. The Computer Journal, 27(2), 97‚Äì111.\n\n\nObels, P., Lakens, D., Coles, N. A., Gottfried, J., & Green, S. A. (2020). Analysis of open data and computational reproducibility in registered reports in psychology. Advances in Methods and Practices in Psychological Science, 3(2), 229‚Äì237.\n\n\nOkoye, K., & Hosseini, S. (2024). Introduction to R Programming and RStudio Integrated Development Environment (IDE). In R Programming: Statistical Data Analysis in Research (pp. 3‚Äì24). Springer.\n\n\nWickham, H., √áetinkaya-Rundel, M., & Grolemund, G. (2023). R for data science. \" O‚ÄôReilly Media, Inc.\".",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/02_utility_functions.html",
    "href": "chapters/R/02_utility_functions.html",
    "title": "7¬† Utility functions",
    "section": "",
    "text": "7.1 Introduzione\nIn questo capitolo, esploreremo le principali funzioni di utilit√† in R per l‚Äôimportazione di dati da file esterni e la raccolta di statistiche descrittive, fornendo una panoramica generale sui data frame.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Utility functions</span>"
    ]
  },
  {
    "objectID": "chapters/R/02_utility_functions.html#importare-dati-in-r-con-rioimport",
    "href": "chapters/R/02_utility_functions.html#importare-dati-in-r-con-rioimport",
    "title": "7¬† Utility functions",
    "section": "\n7.2 Importare dati in R con rio::import()\n",
    "text": "7.2 Importare dati in R con rio::import()\n\nPrima di analizzare i dati, √® necessario importarli in R.\n\n7.2.1 Il problema: Tanti Formati, un‚ÄôUnica Soluzione\nNella ricerca psicologica i dati possono essere forniti in molti formati:\n\nFile Excel (.xlsx) da questionari compilati in laboratorio,\nCSV (.csv) da piattaforme online come Qualtrics,\nFile SPSS (.sav) per confrontare studi precedenti,\nSolo testo (.txt) da esperimenti comportamentali.\n\nInvece di imparare funzioni diverse, una specifica per ciascun formato, il pacchetto rio offre un solo comando universale per le importazioni.\n\n7.2.2 Come Funziona import()\n\n# Carica il pacchetto (installalo prima con install.packages(\"rio\"))\nlibrary(rio)\n\n# Importa un file CSV da una cartella \"dati\" nel tuo progetto\nrisposte &lt;- rio::import(\"dati/questionario.csv\")\n\n# Importa un foglio Excel con i tempi di reazione\ntempi_reazione &lt;- rio::import(\"dati/esperimento1.xlsx\")\n\n# Importa un file SPSS con dati demografici\ndati_demografici &lt;- rio::import(\"dati/partecipanti.sav\")\nPerch√© √® utile:\n\nriconosce automaticamente il formato dal nome del file;\ntraduce i dati in un formato R pronto per l‚Äôanalisi (data.frame);\nconserva le etichette delle variabili (cruciale per questionari!).\n\n7.2.3 Esportare Dati con rio::export()\n\nDopo aver pulito i dati, √® possibile salvarli in qualsiasi formato usando rio::export():\nrio::export(risposte, \"dati/cleaned/dati_puliti.xlsx\")\nrio::export(tempi_reazione, \"dati/cleaned/tempi_reazione.sav\")",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Utility functions</span>"
    ]
  },
  {
    "objectID": "chapters/R/02_utility_functions.html#utilizzare-percorsi-relativi-con-herehere",
    "href": "chapters/R/02_utility_functions.html#utilizzare-percorsi-relativi-con-herehere",
    "title": "7¬† Utility functions",
    "section": "\n7.3 Utilizzare Percorsi Relativi con here::here()\n",
    "text": "7.3 Utilizzare Percorsi Relativi con here::here()\n\nQuando importiamo i dati da file esterni in R, succede spesso di commettere uno dei tre errori seguenti. Vediamo come eviarli.\n\n\nPercatori sbagliati\n# SBAGLIATO (il file non √® nella cartella di lavoro)\nimport(\"questionario.csv\")  \n\n# CORRETTO: usa percorsi relativi o il pacchetto 'here'\nimport(\"dati/raw/questionario.csv\")  \n\nFile aperti in altri programmi\n‚ÄúErrore: non posso aprire il file‚Äù ‚Üí Chiudi Excel/SPSS e riprova\n\nCodifica caratteri strani\nSe vedi ÔøΩ nei testi, specifica l‚Äôencoding:\nimport(\"dati/testo.txt\", encoding = \"UTF-8\")\n\n\n\n7.3.1 Evitare Percorsi Assoluti\nCome vedremo meglio nel Capitolo 14, il primo passo di un progetto di analisi dei dati √® l‚Äôorganizzazione dei file in cartelle con una struttura chiara:\ntuo_progetto/\n‚îú‚îÄ‚îÄ dati/\n‚îÇ   ‚îú‚îÄ‚îÄ raw/        # Dati originali\n‚îÇ   ‚îî‚îÄ‚îÄ cleaned/    # Dati elaborati\n‚îú‚îÄ‚îÄ script/\n‚îî‚îÄ‚îÄ rapporti/\nTutti i file e le cartelle devono essere contenuti nella directory del progetto.\nIl pacchetto here rende l‚Äôimportazione dei dati pi√π semplice, evitando problemi dovuti a percorsi assoluti che possono cambiare se si modifica la directory di lavoro o si sposta il progetto.\nLa funzione here() crea percorsi relativi a partire dalla radice del progetto (cio√® dalla cartella che contiene il file .Rproj o da dove viene inizializzato il progetto RStudio).\nEsempio di utilizzo combinato con rio::import():\nlibrary(rio)\nlibrary(here)\n\n# Percorso robusto al file csv\ndati &lt;- import(here(\"data\", \"dati.csv\"))\n\n# Percorso robusto al file Excel\ndati_excel &lt;- import(here(\"data\", \"dati.xlsx\"))\nIn questo modo, l‚Äôimportazione diventa indipendente dalla cartella di lavoro attuale e il codice sar√† pi√π facilmente condivisibile e riproducibile.\nVantaggi:\n\n\nSemplicit√†: rio::import() riconosce automaticamente il tipo di file.\n\nRobustezza: here::here() garantisce che il percorso sia sempre corretto, indipendentemente da dove viene eseguito lo script.\n\nQuesta combinazione rende le analisi riproducibili e consente di collaborare facilmente con altri ricercatori o studenti.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Utility functions</span>"
    ]
  },
  {
    "objectID": "chapters/R/02_utility_functions.html#funzioni-principali-e-loro-utilizzo",
    "href": "chapters/R/02_utility_functions.html#funzioni-principali-e-loro-utilizzo",
    "title": "7¬† Utility functions",
    "section": "\n7.4 Funzioni Principali e Loro Utilizzo",
    "text": "7.4 Funzioni Principali e Loro Utilizzo\nR offre una serie di funzioni per esplorare rapidamente i dati e comprenderne la struttura prima di passare a manipolazioni pi√π avanzate.\n\n\n\n\n\n\nFunzione\nDescrizione\n\n\n\nsummary()\nRestituisce statistiche descrittive di base per ogni colonna di un data frame. Per le colonne numeriche, calcola valori come il minimo, massimo, media, mediana, primo e terzo quartile, e il numero di valori mancanti (se presenti). Per le colonne non numeriche, restituisce il tipo di dati (carattere, logico) e il conteggio delle categorie. Esempio: summary(iris) restituisce una sintesi delle colonne del dataset iris.\n\n\n\nstr() e glimpse()\n\nForniscono una rappresentazione sintetica delle informazioni di un data frame, come dimensione, nomi delle colonne, tipi di dati e valori iniziali. La funzione str() fa parte della configurazione base di R (pacchetto utils), mentre glimpse() √® inclusa in dplyr (pacchetto tidyverse). Esempio: str(mtcars) o glimpse(mtcars).\n\n\n\nhead() e tail()\n\nPermettono di visualizzare rispettivamente le prime o ultime righe di un data frame. Utile per una rapida ispezione del contenuto. Si pu√≤ specificare il numero di righe da mostrare (es. head(df, 10)), altrimenti il valore predefinito √® sei righe. Esempio: head(iris) per vedere le prime righe del dataset iris.\n\n\n\nView() e view()\n\nVisualizzano un data frame in una finestra grafica tipo foglio di calcolo all‚Äôinterno di RStudio. La funzione View() √® parte della configurazione base di R, mentre view() √® un alias fornito da tibble (pacchetto tidyverse). Utile per piccoli data frame, ma poco pratico per dataset di grandi dimensioni. Esempio: View(iris) apre il dataset iris nel visualizzatore di RStudio.\n\n\nunique()\nRestituisce i valori unici presenti in una colonna o in un vettore. Esempio: unique(iris$Species) restituisce le specie uniche nel dataset iris.\n\n\nnames()\nRestituisce i nomi delle colonne di un data frame. Esempio: names(mtcars) restituisce i nomi delle colonne del dataset mtcars.\n\n\nclass()\nIndica il tipo di dato di un oggetto in R, come numeric, character, logical, o data.frame. Esempio: class(iris) restituisce data.frame.\n\n\nlength()\nRestituisce il numero di elementi di un oggetto. Per i data frame, restituisce il numero di colonne. Esempio: length(iris) restituisce 5 (colonne).\n\n\n\nnrow() e ncol()\n\nRestituiscono rispettivamente il numero di righe e colonne di un data frame. Esempio: nrow(iris) restituisce 150 (righe), mentre ncol(iris) restituisce 5 (colonne).",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Utility functions</span>"
    ]
  },
  {
    "objectID": "chapters/R/02_utility_functions.html#illustrazione",
    "href": "chapters/R/02_utility_functions.html#illustrazione",
    "title": "7¬† Utility functions",
    "section": "\n7.5 Illustrazione",
    "text": "7.5 Illustrazione\nImmagina di dover analizzare i dati del tuo esperimento sul sonno e la memoria, salvati nel file msleep.csv. La struttura del tuo progetto RStudio √® organizzata cos√¨:\nmio_esperimento/\n‚îú‚îÄ‚îÄ mio_esperimento.Rproj\n‚îú‚îÄ‚îÄ data/\n‚îÇ   ‚îî‚îÄ‚îÄ msleep.csv\n‚îú‚îÄ‚îÄ script/\n‚îÇ   ‚îî‚îÄ‚îÄ analisi.R\n‚îî‚îÄ‚îÄ output/\nLa prima cosa da fare √® caricare i pacchetti necessari:\nlibrary(rio)    # Per importare i dati\nlibrary(here)   # Per gestire i percorsi in modo affidabile\nA questo punto possiamo importare i dati:\n\nmsleep &lt;- rio::import(\n  here::here(  # Costruisce il percorso automaticamente\n    \"data\",    # Cartella dei dati\n    \"msleep.csv\"  # Nome del file\n  )\n)\n\nControlli post-importazione (fondamentali!)\n\nhead(msleep)\n#&gt;                         name      genus  vore        order conservation\n#&gt; 1                    Cheetah   Acinonyx carni    Carnivora           lc\n#&gt; 2                 Owl monkey      Aotus  omni     Primates             \n#&gt; 3            Mountain beaver Aplodontia herbi     Rodentia           nt\n#&gt; 4 Greater short-tailed shrew    Blarina  omni Soricomorpha           lc\n#&gt; 5                        Cow        Bos herbi Artiodactyla domesticated\n#&gt; 6           Three-toed sloth   Bradypus herbi       Pilosa             \n#&gt;   sleep_total sleep_rem sleep_cycle awake brainwt  bodywt\n#&gt; 1        12.1        NA          NA  11.9      NA  50.000\n#&gt; 2        17.0       1.8          NA   7.0 0.01550   0.480\n#&gt; 3        14.4       2.4          NA   9.6      NA   1.350\n#&gt; 4        14.9       2.3      0.1333   9.1 0.00029   0.019\n#&gt; 5         4.0       0.7      0.6667  20.0 0.42300 600.000\n#&gt; 6        14.4       2.2      0.7667   9.6      NA   3.850\n\n\nstr(msleep)\n#&gt; 'data.frame':    83 obs. of  11 variables:\n#&gt;  $ name        : chr  \"Cheetah\" \"Owl monkey\" \"Mountain beaver\" \"Greater short-tailed shrew\" ...\n#&gt;  $ genus       : chr  \"Acinonyx\" \"Aotus\" \"Aplodontia\" \"Blarina\" ...\n#&gt;  $ vore        : chr  \"carni\" \"omni\" \"herbi\" \"omni\" ...\n#&gt;  $ order       : chr  \"Carnivora\" \"Primates\" \"Rodentia\" \"Soricomorpha\" ...\n#&gt;  $ conservation: chr  \"lc\" \"\" \"nt\" \"lc\" ...\n#&gt;  $ sleep_total : num  12.1 17 14.4 14.9 4 14.4 8.7 7 10.1 3 ...\n#&gt;  $ sleep_rem   : num  NA 1.8 2.4 2.3 0.7 2.2 1.4 NA 2.9 NA ...\n#&gt;  $ sleep_cycle : num  NA NA NA 0.133 0.667 ...\n#&gt;  $ awake       : num  11.9 7 9.6 9.1 20 9.6 15.3 17 13.9 21 ...\n#&gt;  $ brainwt     : num  NA 0.0155 NA 0.00029 0.423 NA NA NA 0.07 0.0982 ...\n#&gt;  $ bodywt      : num  50 0.48 1.35 0.019 600 ...\n\n\nglimpse(msleep)\n#&gt; Rows: 83\n#&gt; Columns: 11\n#&gt; $ name         &lt;chr&gt; \"Cheetah\", \"Owl monkey\", \"Mountain beaver\", \"Greater ‚Ä¶\n#&gt; $ genus        &lt;chr&gt; \"Acinonyx\", \"Aotus\", \"Aplodontia\", \"Blarina\", \"Bos\", ‚Ä¶\n#&gt; $ vore         &lt;chr&gt; \"carni\", \"omni\", \"herbi\", \"omni\", \"herbi\", \"herbi\", \"‚Ä¶\n#&gt; $ order        &lt;chr&gt; \"Carnivora\", \"Primates\", \"Rodentia\", \"Soricomorpha\", ‚Ä¶\n#&gt; $ conservation &lt;chr&gt; \"lc\", \"\", \"nt\", \"lc\", \"domesticated\", \"\", \"vu\", \"\", \"‚Ä¶\n#&gt; $ sleep_total  &lt;dbl&gt; 12.1, 17.0, 14.4, 14.9, 4.0, 14.4, 8.7, 7.0, 10.1, 3.‚Ä¶\n#&gt; $ sleep_rem    &lt;dbl&gt; NA, 1.8, 2.4, 2.3, 0.7, 2.2, 1.4, NA, 2.9, NA, 0.6, 0‚Ä¶\n#&gt; $ sleep_cycle  &lt;dbl&gt; NA, NA, NA, 0.1333, 0.6667, 0.7667, 0.3833, NA, 0.333‚Ä¶\n#&gt; $ awake        &lt;dbl&gt; 11.9, 7.0, 9.6, 9.1, 20.0, 9.6, 15.3, 17.0, 13.9, 21.‚Ä¶\n#&gt; $ brainwt      &lt;dbl&gt; NA, 0.01550, NA, 0.00029, 0.42300, NA, NA, NA, 0.0700‚Ä¶\n#&gt; $ bodywt       &lt;dbl&gt; 50.000, 0.480, 1.350, 0.019, 600.000, 3.850, 20.490, ‚Ä¶\n\n\nnames(msleep)\n#&gt;  [1] \"name\"         \"genus\"        \"vore\"         \"order\"       \n#&gt;  [5] \"conservation\" \"sleep_total\"  \"sleep_rem\"    \"sleep_cycle\" \n#&gt;  [9] \"awake\"        \"brainwt\"      \"bodywt\"\n\n\ndim(msleep)\n#&gt; [1] 83 11\n\nErrori comuni e soluzioni.\n\n\n‚ÄúFile not found‚Äù:\n\nVerifica che:\n\nil file sia realmente in data/;\nil nome del file sia esatto (attenzione a .csv vs .CSV);\n\nnon ci siano spazi nel nome del file.\n\n\n\n\n\nPacchetti non installati:\n# Esegui una volta\ninstall.packages(\"rio\")\ninstall.packages(\"here\")\n\n\nProgetto non aperto:\n\nAssicurati di aver aperto il file .Rproj prima di iniziare.\n\n\n\nEsaminiamo le modalit√† della variabile qualitativa vore:\n\nunique(msleep$vore)\n#&gt; [1] \"carni\"   \"omni\"    \"herbi\"   \"\"        \"insecti\"\n\nSe vogliamo la numerosit√† di ciascuna categoria, possiamo usare table():\n\ntable(msleep$vore)\n#&gt; \n#&gt;           carni   herbi insecti    omni \n#&gt;       7      19      32       5      20\n\nSi noti che table() esclude i dati mancanti.\nStampiamo i nomi delle colonne del data frame:\n\nnames(msleep)\n#&gt;  [1] \"name\"         \"genus\"        \"vore\"         \"order\"       \n#&gt;  [5] \"conservation\" \"sleep_total\"  \"sleep_rem\"    \"sleep_cycle\" \n#&gt;  [9] \"awake\"        \"brainwt\"      \"bodywt\"\n\nEsaminiamo il tipo di variabile della colonna vore:\n\nclass(msleep$vore)\n#&gt; [1] \"character\"\n\nLe dimensioni del data frame sono date da:\n\ndim(msleep)\n#&gt; [1] 83 11\n\nladdove il primo valore √® il numero di righe e il secondo valore √® il numero di colonne.\nIl numero di elementi di un vettore √® dato da:\n\nlength(msleep$vore)\n#&gt; [1] 83\n\nIn alternativa, possiamo usare nrow()\n\nnrow(msleep)\n#&gt; [1] 83\n\nper il numero di righe e ncol()\n\nncol(msleep)\n#&gt; [1] 11\n\nper il numero di colonne. In maniera equivalente:\n\ndim(msleep)[2]\n#&gt; [1] 11",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Utility functions</span>"
    ]
  },
  {
    "objectID": "chapters/R/02_utility_functions.html#esercizi",
    "href": "chapters/R/02_utility_functions.html#esercizi",
    "title": "7¬† Utility functions",
    "section": "\n7.6 Esercizi",
    "text": "7.6 Esercizi\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nIn questo esercizio, utilizzerai R per esplorare i dati raccolti con il questionario Satisfaction With Life Scale (SWLS) dagli studenti del tuo gruppo TPV. L‚Äôobiettivo √® familiarizzare con le funzioni di base di R per caricare, visualizzare e manipolare i dati.\nParte 1: Operazioni Manuali\n\n\nCreazione e gestione degli oggetti in R\n\nScrivi su carta i comandi R che creerebbero un oggetto chiamato swls_scores contenente i punteggi di 10 studenti.\nQuali sono le regole per assegnare un nome a un oggetto in R?\n\n\n\nVisualizzazione dei dati\n\nScrivi il comando R per visualizzare il contenuto dell‚Äôoggetto swls_scores.\nCome puoi visualizzare solo i primi 5 valori del vettore?\n\n\n\nEsplorazione della struttura dei dati\n\nScrivi i comandi R per verificare il tipo di dati contenuti in swls_scores.\nCome puoi verificare quanti elementi contiene?\n\n\n\nParte 2: Esecuzione in R\n\n\nCreazione del dataset in R\n\nInserisci i dati in un oggetto chiamato swls_scores in R.\n\n\n\nVerifica della struttura dei dati\n\nUsa le funzioni str(), class(), length(), nrow(), ncol() su swls_scores.\nAnnota i risultati e spiega a parole loro significato.\n\n\n\nVisualizzazione dei dati\n\nUsa head() e tail() per esplorare i dati.\n\nQual √® la differenza tra le due funzioni?\n\n\n\nIdentificazione dei valori unici\n\nUsa unique(swls_scores) per individuare i punteggi distinti.\n\n\n\nCreazione di una tabella con i dati\n\nTrasforma swls_scores in un data frame con una colonna \"Punteggio\" e una colonna \"Studente\" (numerata da 1 a 10).\n\n\n\nEsportazione dei dati\n\nSalva il data frame in un file CSV chiamato \"swls_data.csv\" usando write.csv().\n\n\n\nConsegna\n\nScrivi le risposte della Parte 1 su carta.\nScrivi il codice e i risultati della Parte 2 in un file .R e invialo come consegna.\n\n\n\n\n\n\n\n\n\n\nSoluzione\n\n\n\n\n\nParte 1: Operazioni Manuali\n\n\nCreazione e gestione degli oggetti in R\n\n\nConsideriamo dei valori di risposta arbitrari. Il comando per creare l‚Äôoggetto swls_scores √®:\nswls_scores &lt;- c(20, 16, 23, 25, 11, 7, 20, 25, 15, 27)\n\n\nRegole per assegnare un nome a un oggetto in R:\n\nNon pu√≤ iniziare con un numero.\nNon pu√≤ contenere spazi o caratteri speciali (tranne _ e .).\nNon deve avere lo stesso nome di funzioni gi√† esistenti.\n\n\n\n\n\nVisualizzazione dei dati\n\n\nPer visualizzare il contenuto:\nswls_scores\n\n\nPer visualizzare solo i primi 5 valori:\nhead(swls_scores, 5)\n\n\n\n\nEsplorazione della struttura dei dati\n\n\nPer verificare il tipo di dati:\nclass(swls_scores)\n\n\nPer verificare il numero di elementi:\nlength(swls_scores)\n\n\n\n\nParte 2: Esecuzione in R\n\n\nCreazione del dataset in R\nswls_scores &lt;- c(20, 16, 23, 25, 11, 7, 20, 25, 15, 27)\n\n\nVerifica della struttura dei dati\nstr(swls_scores)\nclass(swls_scores)\nlength(swls_scores)\n\n\nstr() mostra che swls_scores √® un vettore numerico.\n\nclass() conferma che √® di tipo \"numeric\".\n\nlength() indica che il vettore ha 10 elementi.\n\n\n\nVisualizzazione dei dati\nhead(swls_scores)\ntail(swls_scores)\n\n\nhead() mostra i primi 6 elementi, tail() gli ultimi 6.\n\n\n\nIdentificazione dei valori unici\nunique(swls_scores)\n\nRestituisce: 7, 11, 15, 16, 20, 23, 25, 27.\n\n\n\nCreazione di una tabella con i dati\ndf_swls &lt;- data.frame(Studente = 1:10, Punteggio = swls_scores)\ndf_swls\n\n\nEsportazione dei dati\nwrite.csv(df_swls, \"swls_data.csv\", row.names=FALSE)\n\n\nConclusione\nQuesti esercizi hanno introdotto i comandi di base per creare, visualizzare e manipolare dati in R.\n\n\n\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.5.3     \n#&gt;  [9] scales_1.3.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     R.oo_1.27.0       rprojroot_2.0.4  \n#&gt; [13] jsonlite_1.9.1    R.utils_2.13.0    mnormt_2.1.1      cli_3.6.4        \n#&gt; [17] rlang_1.1.5       R.methodsS3_1.8.2 munsell_0.5.1     withr_3.0.2      \n#&gt; [21] tools_4.4.2       parallel_4.4.2    tzdb_0.5.0        colorspace_2.1-1 \n#&gt; [25] pacman_0.5.1      vctrs_0.6.5       R6_2.6.1          lifecycle_1.0.4  \n#&gt; [29] htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.1     gtable_0.3.6     \n#&gt; [33] data.table_1.17.0 glue_1.8.0        xfun_0.51         tidyselect_1.2.1 \n#&gt; [37] rstudioapi_0.17.1 farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-167     \n#&gt; [41] rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Utility functions</span>"
    ]
  },
  {
    "objectID": "chapters/R/02_utility_functions.html#bibliografia",
    "href": "chapters/R/02_utility_functions.html#bibliografia",
    "title": "7¬† Utility functions",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nIrizarry, R. A. (2024). Introduction to Data Science: Data Wrangling and Visualization with R. CRC Press.\n\n\nWickham, H., √áetinkaya-Rundel, M., & Grolemund, G. (2023). R for data science. \" O‚ÄôReilly Media, Inc.\".",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Utility functions</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_programming.html",
    "href": "chapters/R/03_r_programming.html",
    "title": "8¬† Programmazione",
    "section": "",
    "text": "8.1 Introduzione\nIn questo capitolo esploreremo tre strumenti fondamentali per la scrittura di codice in R: le funzioni, le istruzioni condizionali e i cicli. Questi elementi costituiscono la base per sviluppare script flessibili, efficienti e riutilizzabili, essenziali per ogni programmatore o analista che utilizza R.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_programming.html#funzioni",
    "href": "chapters/R/03_r_programming.html#funzioni",
    "title": "8¬† Programmazione",
    "section": "\n8.2 Funzioni",
    "text": "8.2 Funzioni\nR offre un‚Äôampia gamma di funzioni integrate per supportare l‚Äôanalisi statistica, la manipolazione dei dati e la visualizzazione grafica, rendendolo uno strumento estremamente versatile per diverse esigenze.\nEsempi di funzioni comuni includono:\n\n# Sommare numeri\nsum(1, 2, 3)  # Restituisce la somma dei numeri\n#&gt; [1] 6\n\n\n# Creare un grafico semplice\nplot(1:10, 1:10)  # Crea un grafico a dispersione dei valori\n\n\n\n\n\n\n\nIn sostanza, una funzione √® un blocco di codice progettato per svolgere un‚Äôoperazione specifica. Puoi pensare a una funzione come a una ‚Äúblack box‚Äù: fornisci un input (i dati), la funzione elabora l‚Äôinformazione attraverso le sue istruzioni e restituisce un output (il risultato). Questo approccio modulare semplifica il lavoro, permettendo di riutilizzare e combinare facilmente diverse operazioni.\n\n8.2.1 Creare Funzioni Personalizzate\nLa creazione di funzioni personalizzate in R √® uno strumento essenziale per migliorare la programmazione, soprattutto per gestire operazioni ripetitive o complesse. Le funzioni consentono di rendere il codice pi√π leggibile, efficiente e riutilizzabile, promuovendo un approccio organizzato e chiaro alla risoluzione dei problemi.\n\n8.2.1.1 Vantaggi delle Funzioni Personalizzate\nL‚Äôuso di funzioni personalizzate offre numerosi benefici:\n\n\nChiarezza e leggibilit√†: Un nome descrittivo permette di comprendere immediatamente lo scopo della funzione, anche a distanza di tempo o per altri utenti che leggono il codice.\n\n\nManutenzione semplificata: Modificare il codice all‚Äôinterno di una funzione aggiorna automaticamente tutte le sue occorrenze, riducendo il rischio di errori e semplificando il debugging.\n\n\nRiduzione degli errori: Si evitano gli errori tipici del copia-e-incolla, come omissioni o incoerenze nei programmi complessi.\n\n\nRiutilizzabilit√†: Una funzione ben progettata pu√≤ essere utilizzata in pi√π contesti o progetti, risparmiando tempo e sforzi.\n\n8.2.1.2 Quando Creare una Funzione?\nUn buon criterio per decidere se creare una funzione √® osservare se il medesimo blocco di codice viene copiato pi√π volte. Se ti trovi a ripetere lo stesso codice pi√π di due volte, probabilmente √® il momento di creare una funzione. Questo aiuta a scrivere codice pi√π pulito, scalabile e professionale, migliorando anche la sostenibilit√† del lavoro a lungo termine.\n\n8.2.2 Sintassi di una Funzione\nLa struttura base di una funzione in R √® la seguente:\nnome_funzione &lt;- function(argomenti) {\n  # Corpo della funzione\n  codice\n  return(risultato)  # Facoltativo: restituisce il valore calcolato\n}\n\n\nnome_funzione: Nome della funzione, scelto per descrivere chiaramente la sua finalit√†.\n\n\nargomenti: Parametri necessari per eseguire le operazioni all‚Äôinterno della funzione.\n\n\ncodice: Le istruzioni che definiscono il comportamento della funzione.\n\n\nrisultato: Il valore restituito dalla funzione. Se non si usa return(), R restituisce l‚Äôultimo valore calcolato.\n\n\nEsempio 8.1 Immaginiamo di voler creare una funzione per sommare due numeri.\nsomma_due &lt;- function(a, b) {\n  a + b  # Restituisce la somma dei due numeri\n}\nPer utilizzarla, basta richiamarla specificando i parametri:\nsomma_due(5, 3)  # Restituisce 8\nQuesto approccio aiuta a scrivere codice pi√π leggibile e facile da gestire. Ad esempio, se in futuro volessi modificare il comportamento della somma (ad esempio, aggiungere un messaggio di log), baster√† intervenire solo all‚Äôinterno della funzione.\n\n\nEsempio 8.2 Immaginiamo di avere un dataset con i punteggi di 10 individui su 3 subscale di un test psicometrico. L‚Äôobiettivo √®:\n\nCreare una funzione per calcolare il punteggio totale di un individuo.\nCreare una funzione per trovare il massimo punteggio totale nel campione.\nCreare una funzione per individuare chi ha ottenuto il massimo punteggio.\n\nPasso 1: Simulazione dei Dati. Simuliamo i punteggi di 10 individui su 3 subscale:\n\n# Simulazione dei punteggi\nset.seed(123)\npunteggi &lt;- data.frame(\n  individuo = paste(\"Individuo\", 1:10),\n  subscale1 = sample(30:50, 10, replace = TRUE),\n  subscale2 = sample(40:60, 10, replace = TRUE),\n  subscale3 = sample(35:55, 10, replace = TRUE)\n)\nprint(punteggi)\n#&gt;       individuo subscale1 subscale2 subscale3\n#&gt; 1   Individuo 1        44        44        48\n#&gt; 2   Individuo 2        48        58        51\n#&gt; 3   Individuo 3        43        48        45\n#&gt; 4   Individuo 4        32        42        41\n#&gt; 5   Individuo 5        39        47        55\n#&gt; 6   Individuo 6        47        46        46\n#&gt; 7   Individuo 7        40        49        49\n#&gt; 8   Individuo 8        34        48        44\n#&gt; 9   Individuo 9        49        58        47\n#&gt; 10 Individuo 10        43        43        41\n\nLa funzione sample() in R √® utilizzata per estrarre casualmente un sottoinsieme di valori da un vettore. Nell‚Äôesempio sopra, sample() viene utilizzata per generare casualmente i punteggi delle subscale dei test psicometrici.\nNell‚Äôistruzione subscale1 &lt;- sample(30:50, 10, replace = TRUE)\n\n\n30:50: Rappresenta il vettore di numeri interi da cui vengono estratti i punteggi (valori possibili tra 30 e 50).\n\n10: Indica che vogliamo estrarre 10 valori.\n\nreplace = TRUE: Consente che lo stesso valore possa essere estratto pi√π volte (estrazione con ripetizione).\n\nPasso 2: Creazione delle Funzioni.\n\n\nCalcolo del punteggio totale per ogni individuo\nQuesta funzione somma i punteggi delle subscale di un individuo:\n\ncalcola_totale &lt;- function(subscale1, subscale2, subscale3) {\n  return(subscale1 + subscale2 + subscale3)\n}\n\n\n\nTrovare il punteggio massimo nel campione\nQuesta funzione accetta un vettore di punteggi totali e restituisce il valore massimo:\n\ntrova_massimo &lt;- function(punteggi_totali) {\n  return(max(punteggi_totali))\n}\n\n\n\nIndividuare l‚Äôindividuo con il punteggio massimo\nQuesta funzione accetta un data frame con i punteggi e restituisce il nome dell‚Äôindividuo con il punteggio pi√π alto:\n\ntrova_individuo_massimo &lt;- function(punteggi) {\n  punteggi_totali &lt;- rowSums(punteggi[, c(\"subscale1\", \"subscale2\", \"subscale3\")])\n  indice_massimo &lt;- which.max(punteggi_totali)\n  return(punteggi$individuo[indice_massimo])\n}\n\nLa funzione which.max() restituisce l‚Äôindice della posizione in cui si trova il valore massimo in un vettore.\n\n\nPasso 3: Applicazione delle Funzioni\n\n\nCalcolo dei punteggi totali per ogni individuo\nApplichiamo la funzione ai dati simulati:\n\npunteggi$punteggio_totale &lt;- with(\n  punteggi, calcola_totale(subscale1, subscale2, subscale3)\n )\nprint(punteggi)\n#&gt;       individuo subscale1 subscale2 subscale3 punteggio_totale\n#&gt; 1   Individuo 1        44        44        48              136\n#&gt; 2   Individuo 2        48        58        51              157\n#&gt; 3   Individuo 3        43        48        45              136\n#&gt; 4   Individuo 4        32        42        41              115\n#&gt; 5   Individuo 5        39        47        55              141\n#&gt; 6   Individuo 6        47        46        46              139\n#&gt; 7   Individuo 7        40        49        49              138\n#&gt; 8   Individuo 8        34        48        44              126\n#&gt; 9   Individuo 9        49        58        47              154\n#&gt; 10 Individuo 10        43        43        41              127\n\n\n\nTroviamo il punteggio massimo nel campione\n\nmassimo &lt;- trova_massimo(punteggi$punteggio_totale)\nprint(massimo)\n#&gt; [1] 157\n\n\n\nTroviamo chi ha il punteggio massimo\n\nindividuo_massimo &lt;- trova_individuo_massimo(punteggi)\nprint(individuo_massimo)\n#&gt; [1] \"Individuo 2\"\n\n\n\n\n\n8.2.3 Stile\n√à consigliato di usare nomi di funzioni chiari e descrittivi, preferibilmente verbi (es. compute_mean()). Inoltre, √® importante mantenere una struttura leggibile, con spazi coerenti e indentazione.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_programming.html#istruzioni-condizionali-in-r",
    "href": "chapters/R/03_r_programming.html#istruzioni-condizionali-in-r",
    "title": "8¬† Programmazione",
    "section": "\n8.3 Istruzioni Condizionali in R",
    "text": "8.3 Istruzioni Condizionali in R\nLe istruzioni condizionali permettono di introdurre logica nel tuo codice. Ad esempio, l‚Äôoperazione x * y si limita a moltiplicare i valori di x e y, senza alcuna logica aggiunta. Con le istruzioni condizionali, puoi dire al programma di eseguire diverse operazioni a seconda che una condizione sia vera (TRUE) o falsa (FALSE).\nL‚Äôistruzione condizionale pi√π comune in R √® if. Pu√≤ essere letta come: ‚ÄúSe la condizione √® vera, esegui un‚Äôazione‚Äù. Con else, si estende la logica: ‚ÄúSe la condizione √® vera, fai qualcosa; altrimenti fai qualcos‚Äôaltro‚Äù.\nLa struttura generale √® questa:\nif (condizione) {\n  # Codice eseguito se la condizione √® TRUE\n} else {\n  # Codice eseguito se la condizione √® FALSE\n}\nImmagina questa situazione:\n\n‚ÄúSe un partecipante al test psicologico riporta un punteggio elevato sulla scala di ansia (es. &gt; 15), consigliagli un esercizio di rilassamento. Altrimenti, non √® necessario.‚Äù\n\nVediamo come rappresentare questa situazione in R.\n\nanxiety_score &lt;- 18 # Punteggio riportato dal partecipante\n\nif (anxiety_score &gt; 15) {\n    exercise &lt;- \"rilassamento\"\n} else {\n    exercise &lt;- \"nessun esercizio\"\n}\n\nexercise\n#&gt; [1] \"rilassamento\"\n\nSe il punteggio √® maggiore di 15, il risultato sar√†:\n[1] \"rilassamento\"\nSe il punteggio √® inferiore o uguale a 15, il risultato sar√†:\n[1] \"nessun esercizio\"\n\n8.3.1 Uso di ifelse()\n\nUn‚Äôalternativa pi√π compatta a if e else √® la funzione ifelse(), utile soprattutto per vettori. Ad esempio, supponiamo di avere i punteggi di ansia di un gruppo di partecipanti e vogliamo decidere se assegnare un esercizio di rilassamento a ciascuno:\n\nanxiety_scores &lt;- c(12, 18, 9, 22, 15)\nexercises &lt;- ifelse(anxiety_scores &gt; 15, \"rilassamento\", \"nessun esercizio\")\n\nIl risultato sar√†:\n\nexercises\n#&gt; [1] \"nessun esercizio\" \"rilassamento\"     \"nessun esercizio\"\n#&gt; [4] \"rilassamento\"     \"nessun esercizio\"\n\n\n8.3.2 Creare una Funzione con Istruzioni Condizionali\nLe istruzioni condizionali possono essere racchiuse in una funzione per rendere il codice pi√π flessibile e riutilizzabile. Ad esempio, supponiamo di voler personalizzare un feedback per un partecipante in base al punteggio ottenuto in un questionario:\n\nfeedback &lt;- function(score) {\n    if (score &gt; 15) {\n        \"Consigliamo un esercizio di rilassamento.\"\n    } else if (score &gt; 10) {\n        \"Monitoriamo la situazione, ma non √® necessario alcun intervento.\"\n    } else {\n        \"Nessun intervento necessario.\"\n    }\n}\n\n\nfeedback(18)\n#&gt; [1] \"Consigliamo un esercizio di rilassamento.\"\n\n\nfeedback(12)\n#&gt; [1] \"Monitoriamo la situazione, ma non √® necessario alcun intervento.\"\n\n\nfeedback(8)\n#&gt; [1] \"Nessun intervento necessario.\"\n\nIn conclusione, le istruzioni condizionali come if, else e ifelse() sono strumenti fondamentali per introdurre logica e controllo nel tuo codice. Puoi usarle per prendere decisioni, gestire errori e rendere il tuo codice pi√π flessibile ed efficiente. Creare funzioni che incorporano queste istruzioni √® un passo fondamentale per scrivere codice ordinato e riutilizzabile in contesti psicologici e non solo.\n\n8.3.3 Combinare Operatori Logici in R\nFinora abbiamo creato funzioni abbastanza semplici e mirate. Ora proviamo a realizzare una funzione leggermente pi√π complessa. Immaginiamo di voler determinare se una persona ha avuto una buona giornata basandoci su due criteri:\n\n\nLivello di stress: basso (TRUE) o alto (FALSE).\n\nLivello di supporto sociale percepito: alto (TRUE) o basso (FALSE).\n\nVogliamo creare una funzione che prenda questi due fattori e restituisca un messaggio che descrive come potrebbe essere stata la giornata della persona.\nEcco come possiamo costruire la funzione:\n\ngood_day &lt;- function(low_stress, high_support) {\n    if (low_stress == TRUE && high_support == TRUE) {\n        \"Giornata fantastica! Ti senti calmo e supportato.\"\n    } else if (low_stress == FALSE && high_support == TRUE) {\n        \"Il supporto sociale ti aiuta a gestire lo stress elevato.\"\n    } else if (low_stress == TRUE && high_support == FALSE) {\n        \"Nonostante lo stress sia basso, la mancanza di supporto sociale pesa.\"\n    } else if (low_stress == FALSE && high_support == FALSE) {\n        \"Giornata difficile: stress elevato e poco supporto sociale.\"\n    }\n}\n\nEsempi di utilizzo.\nCaso 1: Stress basso e supporto sociale alto\n\ngood_day(low_stress = TRUE, high_support = TRUE)\n#&gt; [1] \"Giornata fantastica! Ti senti calmo e supportato.\"\n\nCaso 2: Stress elevato e supporto sociale alto.\n\ngood_day(FALSE, TRUE)\n#&gt; [1] \"Il supporto sociale ti aiuta a gestire lo stress elevato.\"\n\nCaso 3: Stress basso e supporto sociale basso.\n\ngood_day(TRUE, FALSE)\n#&gt; [1] \"Nonostante lo stress sia basso, la mancanza di supporto sociale pesa.\"\n\nCaso 4: Stress elevato e supporto sociale basso.\n\ngood_day(FALSE, FALSE)\n#&gt; [1] \"Giornata difficile: stress elevato e poco supporto sociale.\"\n\nLa funzione considera tutte le combinazioni di stress e supporto sociale:\n\n\nStress basso e supporto alto: giornata ideale.\n\nStress elevato e supporto alto: il supporto aiuta a mitigare lo stress.\n\nStress basso e supporto basso: la mancanza di supporto rovina una situazione potenzialmente buona.\n\nStress elevato e supporto basso: la situazione peggiore.\n\nNell‚Äôesempio abbiamo usato i seguenti operatori logici:\n\n\n&& (AND logico): Entrambe le condizioni devono essere vere.\n\n== (uguale a): Verifica se una variabile √® vera o falsa.\n\nAd esempio, questa condizione:\nif (low_stress == TRUE && high_support == TRUE)\nverifica se il livello di stress √® basso e il supporto sociale √® alto.\nIn conclusione, questa funzione dimostra come combinare condizioni logiche complesse utilizzando operatori logici come && (AND) e || (OR). Grazie a questi strumenti, possiamo gestire facilmente logiche pi√π articolate, mantenendo il codice leggibile e funzionale.\n\n8.3.4 Gli operatori Logici in R\nGli operatori logici sono essenziali per definire le condizioni nelle istruzioni if. Ecco una tabella riassuntiva con i principali operatori:\n\n\n\n\n\n\n\n\nOperatore\nDescrizione tecnica\nSignificato\nEsempio\n\n\n\n&&\nAND logico\nEntrambe le condizioni devono essere vere\nif(cond1 == test && cond2 == test)\n\n\n||\nOR logico\nAlmeno una condizione deve essere vera\nif(cond1 == test || cond2 == test)\n\n\n&lt;\nMinore di\nX √® minore di Y\nif(X &lt; Y)\n\n\n&gt;\nMaggiore di\nX √® maggiore di Y\nif(X &gt; Y)\n\n\n&lt;=\nMinore o uguale a\nX √® minore o uguale a Y\nif(X &lt;= Y)\n\n\n&gt;=\nMaggiore o uguale a\nX √® maggiore o uguale a Y\nif(X &gt;= Y)\n\n\n==\nUguale a\nX √® uguale a Y\nif(X == Y)\n\n\n!=\nDiverso da\nX √® diverso da Y\nif(X != Y)",
    "crumbs": [
      "R",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_programming.html#cicli-in-r",
    "href": "chapters/R/03_r_programming.html#cicli-in-r",
    "title": "8¬† Programmazione",
    "section": "\n8.4 Cicli in R",
    "text": "8.4 Cicli in R\nR √® particolarmente efficace nell‚Äôeseguire attivit√† ripetitive. Quando dobbiamo ripetere un‚Äôoperazione pi√π volte, possiamo utilizzare un ciclo. I cicli eseguono un insieme di istruzioni per un numero specifico di volte o fino a quando una determinata condizione non √® soddisfatta.\nIn R esistono tre tipi principali di cicli:\n\n\nCiclo for: ripete un‚Äôoperazione per un numero definito di iterazioni.\n\nCiclo while: continua a eseguire le istruzioni fino a quando una condizione logica √® soddisfatta.\n\nCiclo repeat: itera indefinitamente fino a quando non viene esplicitamente interrotto con un‚Äôistruzione break.\n\nI cicli sono strumenti essenziali in tutti i linguaggi di programmazione, ma in R il loro utilizzo dovrebbe essere valutato attentamente, poich√© spesso esistono alternative pi√π efficienti come le funzioni della famiglia apply.\n\n8.4.1 Il ciclo for\n\nIl ciclo for √® il pi√π utilizzato per eseguire un‚Äôoperazione un numero definito di volte. Ecco un esempio base:\n\nfor (i in 1:5) {\n    print(i)\n}\n#&gt; [1] 1\n#&gt; [1] 2\n#&gt; [1] 3\n#&gt; [1] 4\n#&gt; [1] 5\n\nCome funziona?\n\nL‚Äôindice i prende il primo valore della sequenza 1:5 (cio√® 1).\nIl corpo del ciclo, ovvero il codice tra { }, viene eseguito.\nAl termine di ogni iterazione, i assume il valore successivo nella sequenza, e il processo si ripete fino all‚Äôultimo valore (5 in questo caso).\n\nAggiungere logica nel corpo del ciclo\nPossiamo aggiungere operazioni all‚Äôinterno del ciclo, come ad esempio sommare 1 a ogni valore:\n\nfor (i in 1:5) {\n    print(i + 1)\n}\n#&gt; [1] 2\n#&gt; [1] 3\n#&gt; [1] 4\n#&gt; [1] 5\n#&gt; [1] 6\n\n\n8.4.2 Il ciclo while\n\nIl ciclo while continua a eseguire le istruzioni fino a quando una condizione logica √® soddisfatta. Ecco un esempio:\n\ni &lt;- 0\nwhile (i &lt;= 4) {\n    i &lt;- i + 1\n    print(i)\n}\n#&gt; [1] 1\n#&gt; [1] 2\n#&gt; [1] 3\n#&gt; [1] 4\n#&gt; [1] 5\n\nCome funziona?\n\nLa condizione logica (i &lt;= 4) viene verificata prima di ogni iterazione.\nSe la condizione √® vera, il ciclo esegue il codice tra { }.\nQuando la condizione diventa falsa (i &gt; 4), il ciclo si interrompe.\n\n8.4.3 Ciclo repeat\n\nIl ciclo repeat esegue il codice indefinitamente, a meno che non venga interrotto con un‚Äôistruzione break:\n\ni &lt;- 0\nrepeat {\n    i &lt;- i + 1\n    print(i)\n    if (i &gt;= 5) {\n        break\n    }\n}\n#&gt; [1] 1\n#&gt; [1] 2\n#&gt; [1] 3\n#&gt; [1] 4\n#&gt; [1] 5\n\nQuando usarlo?\nIl ciclo repeat √® raro e viene utilizzato solo in situazioni molto particolari. Nella maggior parte dei casi, for o while sono pi√π adatti.\n\n8.4.4 Evitare i cicli: la famiglia di funzioni apply\n\nI cicli in R sono relativamente lenti, specialmente con dataset di grandi dimensioni. Quando possibile, √® preferibile usare funzioni della famiglia apply per ottenere lo stesso risultato in modo pi√π efficiente e con meno rischi di errore.\n\n8.4.4.1 La funzione lapply()\n\nlapply() esegue una funzione su ciascun elemento di una lista o vettore e restituisce una lista con i risultati.\nEsempio:\n\nlapply(0:4, function(a) {\n    a + 1\n})\n#&gt; [[1]]\n#&gt; [1] 1\n#&gt; \n#&gt; [[2]]\n#&gt; [1] 2\n#&gt; \n#&gt; [[3]]\n#&gt; [1] 3\n#&gt; \n#&gt; [[4]]\n#&gt; [1] 4\n#&gt; \n#&gt; [[5]]\n#&gt; [1] 5\n\n\n8.4.4.2 La funzione sapply()\n\nlapply() restituisce una lista, ma se vuoi un vettore come output, usa sapply():\n\nsapply(0:4, function(a) {\n    a + 1\n})\n#&gt; [1] 1 2 3 4 5\n\n\n8.4.5 Quando usare i cicli?\nI cicli sono utili quando:\n\nDevi simulare modelli complessi (es. modelli ricorsivi).\nHai bisogno di operazioni che dipendono dai risultati delle iterazioni precedenti.\n\nIn tutti gli altri casi, considera alternative come apply(), lapply() o funzioni simili per un codice pi√π efficiente e meno soggetto a errori.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_programming.html#linee-guida-per-scrivere-codice",
    "href": "chapters/R/03_r_programming.html#linee-guida-per-scrivere-codice",
    "title": "8¬† Programmazione",
    "section": "\n8.5 Linee Guida per Scrivere Codice",
    "text": "8.5 Linee Guida per Scrivere Codice\nDi seguito trovi alcune linee guida per scrivere codice chiaro, conciso e riutilizzabile:\n\nEvita di ripeterti: Segui il principio Don‚Äôt Repeat Yourself (DRY). Scrivi funzioni e utilizza funzioni come map (per applicare un pezzo di codice iterativamente a tutti gli elementi di un oggetto) per evitare di copiare e incollare variazioni minime dello stesso codice in pi√π parti del progetto.\nSegui uno stile coerente: Adotta una guida di stile per mantenere uniformit√† nel tuo codice. Per R, raccomandiamo la guida di stile del ‚Äútidyverse‚Äù, scritta da Hadley Wickham. Questa guida, derivata dalla Google R Style Guide, fornisce istruzioni dettagliate su sintassi del codice, nomi delle variabili, spaziature, indentazioni, commenti, convenzioni per scrivere funzioni, utilizzo delle pipe (metodo per concatenare funzioni), e altro ancora.\nCommenta abbondantemente: Usa i commenti (ad esempio, con #) per spiegare perch√© ogni parte del codice √® necessaria e cosa fa. I commenti rendono il codice pi√π leggibile e facilitano la manutenzione futura.\nTesta il tuo codice: Ogni volta che scrivi codice, verifica che funzioni come previsto. Puoi farlo scrivendo funzioni di test specifiche o controllando manualmente che l‚Äôoutput corrisponda alle aspettative. Abituati a pensare a eventuali edge cases (casi limite) in cui il tuo codice potrebbe non comportarsi come previsto.\nEsegui una revisione del codice: Quando possibile, fai revisionare il tuo codice da un‚Äôaltra persona per individuare errori e incoerenze. Se non hai nessuno a disposizione, puoi rivedere il tuo codice autonomamente: rileggendo con attenzione, √® sorprendente il numero di errori che si possono individuare!\n\nSeguendo queste linee guida, potrai scrivere codice pi√π robusto, leggibile e facile da mantenere nel tempo.1",
    "crumbs": [
      "R",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_programming.html#riflessioni-conclusive",
    "href": "chapters/R/03_r_programming.html#riflessioni-conclusive",
    "title": "8¬† Programmazione",
    "section": "\n8.6 Riflessioni Conclusive",
    "text": "8.6 Riflessioni Conclusive\nScrivere funzioni √® un passaggio essenziale per migliorare la leggibilit√†, l‚Äôefficienza e la riutilizzabilit√† del codice. Funzioni ben progettate semplificano le modifiche, riducono errori e rendono il lavoro pi√π chiaro, sia per te stesso che per i collaboratori futuri. Se trovi che stai copiando e incollando codice pi√π volte, √® il momento di pensare a creare una funzione.\nLe istruzioni condizionali, come if, else e ifelse(), sono fondamentali per introdurre logica e controllo nel codice. Permettono di gestire scenari diversi e prendere decisioni dinamiche, migliorando la flessibilit√† e l‚Äôefficienza dei tuoi script. Combinando queste istruzioni con operatori logici come && e ||, puoi affrontare situazioni complesse con un codice chiaro e leggibile.\nI cicli sono potenti strumenti per eseguire operazioni ripetitive, ma in R il loro utilizzo dovrebbe essere limitato ai casi in cui non esistono alternative pi√π efficienti. Le funzioni apply() e simili rappresentano spesso un‚Äôopzione migliore per manipolare dati in modo pi√π rapido e leggibile.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_programming.html#esercizi",
    "href": "chapters/R/03_r_programming.html#esercizi",
    "title": "8¬† Programmazione",
    "section": "\n8.7 Esercizi",
    "text": "8.7 Esercizi\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nIn questo esercizio, utilizzerai R per praticare la creazione di funzioni, l‚Äôuso delle istruzioni condizionali e l‚Äôapplicazione dei cicli. L‚Äôobiettivo √® comprendere come scrivere codice pi√π strutturato, riutilizzabile ed efficiente.\nParte 1: Comprensione Teorica\n\n\nCos‚Äô√® una funzione in R?\n\nDescrivi con parole tue cosa fa una funzione e perch√© √® utile.\n\n\n\nSintassi delle funzioni\n\nScrivi la struttura generale di una funzione in R.\n\n\n\nUso di istruzioni condizionali\n\nQual √® la differenza tra if, else e ifelse()? Fornisci un esempio per ciascuno.\n\n\n\nCicli in R\n\nQual √® la differenza tra for, while e repeat?\n\n\n\nParte 2: Creazione ed Esecuzione in R\n\n\nCreazione di una funzione per calcolare il punteggio totale SWLS\n\nScrivi una funzione in R chiamata calcola_SWLS() che accetta un vettore con 5 punteggi SWLS e restituisce il totale.\n\n\n\nCondizione per determinare la soddisfazione\n\nScrivi una funzione valuta_soddisfazione() che prende un punteggio SWLS totale e restituisce:\n\n\n\"Alta soddisfazione\" se il punteggio √® sopra 24.\n\n\"Soddisfazione moderata\" se √® tra 15 e 24.\n\n\"Bassa soddisfazione\" se √® inferiore a 15.\n\n\n\n\n\nApplicare una funzione a pi√π individui\n\nScrivi un ciclo for che calcola la soddisfazione per un gruppo di 5 persone e stampa il risultato.\n\n\n\nUso di ifelse()\n\nUsa ifelse() per determinare rapidamente se i punteggi di 5 individui indicano soddisfazione alta (&gt; 24) o bassa (‚â§ 24).\n\n\n\nCiclo while per controllare input\n\nScrivi un ciclo while che continua a chiedere all‚Äôutente di inserire un punteggio SWLS fino a quando non inserisce un valore valido (compreso tra 5 e 35).\n\n\n\nEsportazione dei dati\n\n\n\nSalva in un file CSV \"swls_results.csv\" un data frame contenente i punteggi SWLS e la valutazione della soddisfazione.\n\nConsegna\n\nScrivi le risposte della Parte 1 su carta.\nScrivi il codice e i risultati della Parte 2 in un file .R e invialo come consegna.\n\n\n\n\n\n\n\n\n\n\nSoluzione\n\n\n\n\n\nParte 1: Comprensione Teorica\n\n\nCos‚Äô√® una funzione in R?\n\nUna funzione √® un blocco di codice che esegue un‚Äôoperazione specifica. Permette di scrivere codice riutilizzabile e pi√π organizzato.\n\n\n\nSintassi delle funzioni\nnome_funzione &lt;- function(argomenti) {\n  # Corpo della funzione\n  return(risultato)\n}\n\n\nUso di istruzioni condizionali\n\n\nif: Controlla una condizione e esegue codice solo se √® vera.\n\nif (x &gt; 10) { print(\"Maggiore di 10\") }\n\n\nelse: Esegue codice alternativo se la condizione √® falsa.\n\nif (x &gt; 10) { print(\"Maggiore di 10\") } else { print(\"10 o meno\") }\n\n\nifelse(): Alternativa vettorializzata a if.\n\ny &lt;- ifelse(x &gt; 10, \"Alto\", \"Basso\")\n\n\nCicli in R\n\n\nfor: Itera su una sequenza.\n\nfor (i in 1:5) { print(i) }\n\n\nwhile: Continua fino a quando una condizione √® vera.\n\ni &lt;- 1\nwhile (i &lt;= 5) { print(i); i &lt;- i + 1 }\n\n\nrepeat: Ripete fino a un break.\n\ni &lt;- 1\nrepeat { print(i); i &lt;- i + 1; if (i &gt; 5) break }\n\n\nParte 2: Creazione ed Esecuzione in R\n\n\nCreazione della funzione per il punteggio totale SWLS\ncalcola_SWLS &lt;- function(punteggi) {\n  return(sum(punteggi))\n}\n\n\nCondizione per determinare la soddisfazione\nvaluta_soddisfazione &lt;- function(score) {\n  if (score &gt; 24) {\n    return(\"Alta soddisfazione\")\n  } else if (score &gt;= 15) {\n    return(\"Soddisfazione moderata\")\n  } else {\n    return(\"Bassa soddisfazione\")\n  }\n}\n\n\nApplicazione della funzione a pi√π individui\npunteggi_lista &lt;- list(c(25, 27, 22, 24, 28), c(18, 20, 17, 16, 19))\nfor (punteggi in punteggi_lista) {\n  print(valuta_soddisfazione(calcola_SWLS(punteggi)))\n}\n\n\nUso di ifelse()\npunteggi_totali &lt;- c(28, 19, 15, 10, 25)\nsoddisfazione &lt;- ifelse(punteggi_totali &gt; 24, \"Alta\", \"Bassa\")\nprint(soddisfazione)\n\n\nCiclo while per controllare input\nscore &lt;- 0\nwhile (score &lt; 5 || score &gt; 35) {\n  score &lt;- as.numeric(readline(prompt = \"Inserisci un punteggio SWLS (5-35): \"))\n}\n\nEsportazione dei dati\n\ndf &lt;- data.frame(Punteggio = punteggi_totali, Soddisfazione = soddisfazione)\nwrite.csv(df, \"swls_results.csv\", row.names = FALSE)\nConclusione\nQuesti esercizi hanno mostrato come scrivere funzioni, utilizzare condizioni e cicli per strutturare meglio il codice in R.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_programming.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/R/03_r_programming.html#informazioni-sullambiente-di-sviluppo",
    "title": "8¬† Programmazione",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.5.3     \n#&gt;  [9] scales_1.3.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.9.1   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         rlang_1.1.5       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       tools_4.4.2       parallel_4.4.2    tzdb_0.5.0       \n#&gt; [21] colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5       R6_2.6.1         \n#&gt; [25] lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.1    \n#&gt; [29] gtable_0.3.6      glue_1.8.0        xfun_0.51         tidyselect_1.2.1 \n#&gt; [33] rstudioapi_0.17.1 farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-167     \n#&gt; [37] rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "R",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_programming.html#bibliografia",
    "href": "chapters/R/03_r_programming.html#bibliografia",
    "title": "8¬† Programmazione",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nIrizarry, R. A. (2024). Introduction to Data Science: Data Wrangling and Visualization with R. CRC Press.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_programming.html#footnotes",
    "href": "chapters/R/03_r_programming.html#footnotes",
    "title": "8¬† Programmazione",
    "section": "",
    "text": "Un‚Äôottima introduzione alle regole di stile per un progetto di analisi dei dati √® fornita in questo capitolo.‚Ü©Ô∏é",
    "crumbs": [
      "R",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/04_r_packages.html",
    "href": "chapters/R/04_r_packages.html",
    "title": "9¬† Pacchetti",
    "section": "",
    "text": "9.1 Introduzione\nI pacchetti R sono estensioni del linguaggio di programmazione statistica R. Questi pacchetti forniscono una raccolta di risorse che possono essere utilizzate per ampliare le funzionalit√† di base di R. Ogni pacchetto generalmente include:\nI pacchetti R sono distribuiti e installati attraverso repository centralizzati, il pi√π noto dei quali √® CRAN (Comprehensive R Archive Network). CRAN garantisce la qualit√† e l‚Äôaffidabilit√† dei pacchetti, sottoponendoli a controlli rigorosi prima della pubblicazione.\nLa vasta disponibilit√† di pacchetti √® una delle ragioni principali della popolarit√† di R.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Pacchetti</span>"
    ]
  },
  {
    "objectID": "chapters/R/04_r_packages.html#introduzione",
    "href": "chapters/R/04_r_packages.html#introduzione",
    "title": "9¬† Pacchetti",
    "section": "",
    "text": "Codice: funzioni e script scritti in R (e talvolta in altri linguaggi come C++ o Fortran) che implementano specifiche analisi o strumenti.\nDati: dataset di esempio o utili per testare e dimostrare le funzionalit√† del pacchetto.\nDocumentazione: file descrittivi che spiegano come utilizzare il pacchetto, spesso in formato manuale o vignette (tutorial pratici).",
    "crumbs": [
      "R",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Pacchetti</span>"
    ]
  },
  {
    "objectID": "chapters/R/04_r_packages.html#installare-i-pacchetti-r",
    "href": "chapters/R/04_r_packages.html#installare-i-pacchetti-r",
    "title": "9¬† Pacchetti",
    "section": "9.2 Installare i Pacchetti R",
    "text": "9.2 Installare i Pacchetti R\nQuando installi R, vengono installati automaticamente alcuni pacchetti base. Tuttavia, hai la possibilit√† di aggiungere ulteriori pacchetti che trovi utili per i tuoi scopi. Questi pacchetti sono memorizzati sui server di R (mirror), e l‚Äôinstallazione di un nuovo pacchetto richiede una connessione internet al mirror CRAN che hai scelto durante l‚Äôinstallazione di R.\nPer installare un pacchetto, utilizza il comando:\ninstall.packages(\"&lt;nome_pacchetto&gt;\")\nSostituisci &lt;nome_pacchetto&gt; con il nome del pacchetto che desideri installare. Ad esempio, se vuoi installare il pacchetto rio (utile per importare i dati in R), puoi digitare:\ninstall.packages(\"rio\")   # Non dimenticare le virgolette!",
    "crumbs": [
      "R",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Pacchetti</span>"
    ]
  },
  {
    "objectID": "chapters/R/04_r_packages.html#caricamento-di-un-pacchetto",
    "href": "chapters/R/04_r_packages.html#caricamento-di-un-pacchetto",
    "title": "9¬† Pacchetti",
    "section": "9.3 Caricamento di un pacchetto",
    "text": "9.3 Caricamento di un pacchetto\nOgni volta che avvii una nuova sessione di R, se desideri utilizzare un pacchetto, devi caricarlo manualmente. Questo si fa con il comando library(). Ad esempio, dopo aver installato rio, per utilizzarlo digita:\nlibrary(rio)   # Nota: le virgolette non sono necessarie, ma puoi usarle se preferisci.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Pacchetti</span>"
    ]
  },
  {
    "objectID": "chapters/R/04_r_packages.html#utilizzo-delle-funzioni-di-un-pacchetto-senza-caricarlo",
    "href": "chapters/R/04_r_packages.html#utilizzo-delle-funzioni-di-un-pacchetto-senza-caricarlo",
    "title": "9¬† Pacchetti",
    "section": "9.4 Utilizzo delle funzioni di un pacchetto senza caricarlo",
    "text": "9.4 Utilizzo delle funzioni di un pacchetto senza caricarlo\nSe hai bisogno di utilizzare una funzione specifica di un pacchetto, ma sai che la userai solo una volta, puoi evitare di caricare l‚Äôintero pacchetto con library(). Ad esempio, invece di scrivere:\nlibrary(nome_pacchetto)\nfunzione_specifica(x = 2, sd = 3)\npuoi accedere direttamente alla funzione usando l‚Äôoperatore ::, come indicato di segtuito:\nnome_pacchetto::funzione_specifica(x = 2, sd = 3)\nQuesto approccio √® utile per funzioni che usi raramente o una sola volta. Personalmente, utilizzo :: anche quando ho gi√† caricato il pacchetto, per ricordare ad un ‚Äúme futuro‚Äù da quale pacchetto proviene una determinata funzione. Questo pu√≤ rendere il codice pi√π leggibile e comprensibile nel tempo.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Pacchetti</span>"
    ]
  },
  {
    "objectID": "chapters/R/04_r_packages.html#bibliografia",
    "href": "chapters/R/04_r_packages.html#bibliografia",
    "title": "9¬† Pacchetti",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nIrizarry, R. A. (2024). Introduction to Data Science: Data Wrangling and Visualization with R. CRC Press.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Pacchetti</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_dplyr.html",
    "href": "chapters/R/05_dplyr.html",
    "title": "10¬† Introduzione a dplyr",
    "section": "",
    "text": "10.1 Introduzione\nL‚Äôobiettivo di questo capitolo √® fornire un‚Äôintroduzione alle funzioni principali del pacchetto dplyr per le operazioni di data wrangling, cio√® per il preprocessing e la pulizia dei dati. In R, queste operazioni sono strettamente legate al concetto di ‚Äúdata tidying‚Äù, che si riferisce all‚Äôorganizzazione sistematica dei dati per facilitare l‚Äôanalisi.\nPer comprendere meglio il concetto di ‚Äúdata tidying‚Äù, possiamo rifarci a una citazione tratta dal testo di riferimento R for Data Science (2e):\nL‚Äôessenza del ‚Äúdata tidying‚Äù √® organizzare i dati in un formato che sia facile da gestire e analizzare. Anche se gli stessi dati possono essere rappresentati in vari modi, non tutte le rappresentazioni sono ugualmente efficienti o facili da usare. Un dataset ‚Äútidy‚Äù segue tre principi fondamentali che lo rendono particolarmente pratico:\nIl pacchetto R {dplyr} e gli altri pacchetti del tidyverse sono progettati specificamente per lavorare con dati in formato ‚Äútidy‚Äù, permettendo agli utenti di eseguire operazioni di manipolazione e visualizzazione in modo pi√π intuitivo ed efficiente.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Introduzione a `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_dplyr.html#introduzione",
    "href": "chapters/R/05_dplyr.html#introduzione",
    "title": "10¬† Introduzione a dplyr",
    "section": "",
    "text": "‚ÄúHappy families are all alike; every unhappy family is unhappy in its own way.‚Äù ‚Äî Leo Tolstoy\n\n\n‚ÄúTidy datasets are all alike, but every messy dataset is messy in its own way.‚Äù ‚Äî Hadley Wickham\n\n\n\n\nOgni variabile √® una colonna: ogni colonna nel dataset rappresenta una singola variabile.\n\nOgni osservazione √® una riga: ogni riga nel dataset rappresenta un‚Äôunica osservazione.\n\nOgni valore √® una cella: ogni cella del dataset contiene un singolo valore.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Introduzione a `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_dplyr.html#pipe",
    "href": "chapters/R/05_dplyr.html#pipe",
    "title": "10¬† Introduzione a dplyr",
    "section": "\n10.2 Pipe",
    "text": "10.2 Pipe\nIl pacchetto dplyr, cos√¨ come l‚Äôintero ecosistema tidyverse, fa largo uso dell‚Äôoperatore pipe, che consente di concatenare una sequenza di operazioni in modo leggibile ed efficiente. In R, esistono due principali notazioni per il pipe:\n\n\n|&gt;: introdotto nativamente a partire dalla versione 4.1.0 di R.\n\n%&gt;%: introdotto dal pacchetto magrittr, ed √® una delle componenti centrali del tidyverse.\n\nEntrambi gli operatori permettono di ottenere risultati simili e, per la maggior parte degli utilizzi, possono essere considerati intercambiabili. Tuttavia, √® importante sottolineare alcune differenze:\n\n\n|&gt; √® integrato nel linguaggio R e non richiede pacchetti aggiuntivi.\n\n%&gt;%, essendo parte di magrittr, richiede che il pacchetto sia installato e caricato (library(magrittr) o automaticamente tramite tidyverse).\n\nConsideriamo l‚Äôesempio seguente (che anticipa l‚Äôuso della funzione filter() che descriveremo in seguito). Un‚Äôoperazione comune √® filtrare un data frame e calcolare la media di una colonna. Con il pipe, questa sequenza di operazioni diventa pi√π leggibile:\n\n# Usando %&gt;%\niris %&gt;%\n  dplyr::filter(Species == \"setosa\") |&gt; \n  summarise(\n    mean_sepal_length = mean(Sepal.Length)\n  ) \n#&gt;   mean_sepal_length\n#&gt; 1             5.006\n\n\n# Usando |&gt;\niris |&gt; \n  dplyr::filter(Species == \"setosa\") |&gt; \n  summarise(\n    mean_sepal_length = mean(Sepal.Length)\n  ) \n#&gt;   mean_sepal_length\n#&gt; 1             5.006\n\n\n10.2.1 Cosa Fa la Pipe?\nLa pipe √® uno strumento potente che permette di collegare in modo diretto l‚Äôoutput di una funzione come input della funzione successiva. Questo approccio:\n\nRiduce la necessit√† di creare variabili intermedie.\nMigliora la leggibilit√† del codice.\nRende il flusso delle operazioni pi√π chiaro e lineare.\n\nOgni funzione applicata con la pipe riceve automaticamente l‚Äôoutput della funzione precedente come suo primo argomento. Ci√≤ consente di scrivere sequenze di operazioni in un formato compatto e intuitivo.\nEcco un altro esempio:\n\n# Utilizzo della pipe per trasformare un dataset\ndf &lt;- data.frame(\n  id = 1:5,\n  value = c(10, 20, 30, 40, 50)\n)\n\n# Filtra i dati, seleziona colonne e calcola nuovi valori\ndf_clean &lt;- df |&gt;\n  dplyr::filter(value &gt; 20) |&gt;\n  dplyr::select(id, value) |&gt;\n  mutate(squared_value = value^2)\n\nIn questa sequenza, il dataset originale df viene filtrato, le colonne desiderate vengono selezionate e viene aggiunta una nuova colonna con il valore al quadrato.\n\nhead(df_clean)\n#&gt;   id value squared_value\n#&gt; 1  3    30           900\n#&gt; 2  4    40          1600\n#&gt; 3  5    50          2500\n\nIn sintesi, la pipe √® uno strumento fondamentale per scrivere codice R moderno e leggibile, indipendentemente dal fatto che si utilizzi |&gt; o %&gt;%.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Introduzione a `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_dplyr.html#verbi",
    "href": "chapters/R/05_dplyr.html#verbi",
    "title": "10¬† Introduzione a dplyr",
    "section": "\n10.3 Verbi",
    "text": "10.3 Verbi\nLe funzioni principali (‚Äúverbi) di dplyr sono le seguenti:\n\n\n\n\n\n\nVerbo dplyr\nDescrizione\n\n\n\nselect()\nSeleziona colonne\n\n\nfilter()\nFiltra righe\n\n\narrange()\nRiordina o organizza le righe\n\n\nmutate()\nCrea nuove colonne\n\n\nsummarise()\nRiassume i valori\n\n\ngroup_by()\nConsente di eseguire operazioni di gruppo\n\n\n\nI verbi di dplyr sono suddivisi in quattro gruppi, in base all‚Äôelemento su cui operano: righe, colonne, gruppi o tabelle.\nInoltre, le diverse funzioni bind_ e _joins permettono di combinare pi√π tibbles (ovvero, data frame) in uno solo.\nPer fare un esempio prarico, usiamo nuovamente il dataset msleep.\n\ndata(msleep)\ndim(msleep)\n#&gt; [1] 83 11\n\nEsaminiamo i dati:\n\nglimpse(msleep)\n#&gt; Rows: 83\n#&gt; Columns: 11\n#&gt; $ name         &lt;chr&gt; \"Cheetah\", \"Owl monkey\", \"Mountain beaver\", \"Greater ‚Ä¶\n#&gt; $ genus        &lt;chr&gt; \"Acinonyx\", \"Aotus\", \"Aplodontia\", \"Blarina\", \"Bos\", ‚Ä¶\n#&gt; $ vore         &lt;chr&gt; \"carni\", \"omni\", \"herbi\", \"omni\", \"herbi\", \"herbi\", \"‚Ä¶\n#&gt; $ order        &lt;chr&gt; \"Carnivora\", \"Primates\", \"Rodentia\", \"Soricomorpha\", ‚Ä¶\n#&gt; $ conservation &lt;chr&gt; \"lc\", NA, \"nt\", \"lc\", \"domesticated\", NA, \"vu\", NA, \"‚Ä¶\n#&gt; $ sleep_total  &lt;dbl&gt; 12.1, 17.0, 14.4, 14.9, 4.0, 14.4, 8.7, 7.0, 10.1, 3.‚Ä¶\n#&gt; $ sleep_rem    &lt;dbl&gt; NA, 1.8, 2.4, 2.3, 0.7, 2.2, 1.4, NA, 2.9, NA, 0.6, 0‚Ä¶\n#&gt; $ sleep_cycle  &lt;dbl&gt; NA, NA, NA, 0.1333, 0.6667, 0.7667, 0.3833, NA, 0.333‚Ä¶\n#&gt; $ awake        &lt;dbl&gt; 11.9, 7.0, 9.6, 9.1, 20.0, 9.6, 15.3, 17.0, 13.9, 21.‚Ä¶\n#&gt; $ brainwt      &lt;dbl&gt; NA, 0.01550, NA, 0.00029, 0.42300, NA, NA, NA, 0.0700‚Ä¶\n#&gt; $ bodywt       &lt;dbl&gt; 50.000, 0.480, 1.350, 0.019, 600.000, 3.850, 20.490, ‚Ä¶\n\nLe colonne, nell‚Äôordine, corrispondono a quanto segue:\n\n\nNome colonna\nDescrizione\n\n\n\nname\nNome comune\n\n\ngenus\nRango tassonomico\n\n\nvore\nCarnivoro, onnivoro o erbivoro?\n\n\norder\nRango tassonomico\n\n\nconservation\nStato di conservazione del mammifero\n\n\nsleep_total\nQuantit√† totale di sonno, in ore\n\n\nsleep_rem\nSonno REM, in ore\n\n\nsleep_cycle\nDurata del ciclo di sonno, in ore\n\n\nawake\nQuantit√† di tempo trascorso sveglio, in ore\n\n\nbrainwt\nPeso del cervello, in chilogrammi\n\n\nbodywt\nPeso corporeo, in chilogrammi",
    "crumbs": [
      "R",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Introduzione a `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_dplyr.html#righe",
    "href": "chapters/R/05_dplyr.html#righe",
    "title": "10¬† Introduzione a dplyr",
    "section": "\n10.4 Righe",
    "text": "10.4 Righe\nI verbi pi√π importanti che operano sulle righe di un dataset sono filter(), che seleziona le righe da includere senza modificarne l‚Äôordine, e arrange(), che cambia l‚Äôordine delle righe senza alterare la selezione delle righe presenti.\n\nmsleep |&gt;\n  dplyr::filter(sleep_total &lt; 4) |&gt;\n  arrange(sleep_total)\n#&gt; # A tibble: 9 √ó 11\n#&gt;   name             genus         vore  order          conservation\n#&gt;   &lt;chr&gt;            &lt;chr&gt;         &lt;chr&gt; &lt;chr&gt;          &lt;chr&gt;       \n#&gt; 1 Giraffe          Giraffa       herbi Artiodactyla   cd          \n#&gt; 2 Pilot whale      Globicephalus carni Cetacea        cd          \n#&gt; 3 Horse            Equus         herbi Perissodactyla domesticated\n#&gt; 4 Roe deer         Capreolus     herbi Artiodactyla   lc          \n#&gt; 5 Donkey           Equus         herbi Perissodactyla domesticated\n#&gt; 6 African elephant Loxodonta     herbi Proboscidea    vu          \n#&gt; 7 Caspian seal     Phoca         carni Carnivora      vu          \n#&gt; 8 Sheep            Ovis          herbi Artiodactyla   domesticated\n#&gt; 9 Asian elephant   Elephas       herbi Proboscidea    en          \n#&gt; # ‚Ñπ 6 more variables: sleep_total &lt;dbl&gt;, sleep_rem &lt;dbl&gt;,\n#&gt; #   sleep_cycle &lt;dbl&gt;, awake &lt;dbl&gt;, brainwt &lt;dbl&gt;, bodywt &lt;dbl&gt;\n\nPossiamo usare filter() speficicano pi√π di una condizione logica.\n\nmsleep |&gt;\n  dplyr::filter((sleep_total &lt; 4 & bodywt &gt; 100) | brainwt &gt; 1) |&gt;\n  arrange(sleep_total)\n#&gt; # A tibble: 7 √ó 11\n#&gt;   name             genus         vore  order          conservation\n#&gt;   &lt;chr&gt;            &lt;chr&gt;         &lt;chr&gt; &lt;chr&gt;          &lt;chr&gt;       \n#&gt; 1 Giraffe          Giraffa       herbi Artiodactyla   cd          \n#&gt; 2 Pilot whale      Globicephalus carni Cetacea        cd          \n#&gt; 3 Horse            Equus         herbi Perissodactyla domesticated\n#&gt; 4 Donkey           Equus         herbi Perissodactyla domesticated\n#&gt; 5 African elephant Loxodonta     herbi Proboscidea    vu          \n#&gt; 6 Asian elephant   Elephas       herbi Proboscidea    en          \n#&gt; 7 Human            Homo          omni  Primates       &lt;NA&gt;        \n#&gt; # ‚Ñπ 6 more variables: sleep_total &lt;dbl&gt;, sleep_rem &lt;dbl&gt;,\n#&gt; #   sleep_cycle &lt;dbl&gt;, awake &lt;dbl&gt;, brainwt &lt;dbl&gt;, bodywt &lt;dbl&gt;",
    "crumbs": [
      "R",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Introduzione a `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_dplyr.html#colonne",
    "href": "chapters/R/05_dplyr.html#colonne",
    "title": "10¬† Introduzione a dplyr",
    "section": "\n10.5 Colonne",
    "text": "10.5 Colonne\nEsistono quattro verbi principali che modificano le colonne di un dataset senza cambiare le righe:\n\n\nrelocate() cambia la posizione delle colonne;\n\nrename() modifica i nomi delle colonne;\n\nselect() seleziona le colonne da includere o escludere;\n\nmutate() crea nuove colonne a partire da quelle esistenti.\n\n\nmsleep2 &lt;- msleep |&gt;\n  mutate(\n    rem_prop = sleep_rem / sleep_total * 100\n  ) |&gt;\n  dplyr::select(name, vore, rem_prop, sleep_total) |&gt;\n  arrange(desc(rem_prop))\n\nglimpse(msleep2)\n#&gt; Rows: 83\n#&gt; Columns: 4\n#&gt; $ name        &lt;chr&gt; \"European hedgehog\", \"Thick-tailed opposum\", \"Giant ar‚Ä¶\n#&gt; $ vore        &lt;chr&gt; \"omni\", \"carni\", \"insecti\", \"omni\", \"carni\", \"omni\", \"‚Ä¶\n#&gt; $ rem_prop    &lt;dbl&gt; 34.65, 34.02, 33.70, 29.21, 28.71, 27.22, 26.37, 26.21‚Ä¶\n#&gt; $ sleep_total &lt;dbl&gt; 10.1, 19.4, 18.1, 8.9, 10.1, 18.0, 9.1, 10.3, 12.5, 8.‚Ä¶\n\nIn questo esempio, utilizziamo mutate() per creare una nuova colonna rem_prop che rappresenta la percentuale di sonno REM sul totale del sonno. Successivamente, select() viene utilizzato per scegliere solo alcune colonne del dataset, e infine desc(rem_prop) ordina i valori di rem_prop in ordine decrescente, dal valore maggiore a quello minore.\nPer cambiare il nome di una colonna possiamo usare rename(). Inoltre, possiamo cambiare l‚Äôordine delle variabili con relocate().\n\nmsleep2 |&gt;\n  rename(rem_perc = rem_prop) |&gt;\n  relocate(rem_perc, .before = name)\n#&gt; # A tibble: 83 √ó 4\n#&gt;    rem_perc name                   vore    sleep_total\n#&gt;       &lt;dbl&gt; &lt;chr&gt;                  &lt;chr&gt;         &lt;dbl&gt;\n#&gt;  1     34.7 European hedgehog      omni           10.1\n#&gt;  2     34.0 Thick-tailed opposum   carni          19.4\n#&gt;  3     33.7 Giant armadillo        insecti        18.1\n#&gt;  4     29.2 Tree shrew             omni            8.9\n#&gt;  5     28.7 Dog                    carni          10.1\n#&gt;  6     27.2 North American Opossum omni           18  \n#&gt;  7     26.4 Pig                    omni            9.1\n#&gt;  8     26.2 Desert hedgehog        &lt;NA&gt;           10.3\n#&gt;  9     25.6 Domestic cat           carni          12.5\n#&gt; 10     25   Eastern american mole  insecti         8.4\n#&gt; # ‚Ñπ 73 more rows",
    "crumbs": [
      "R",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Introduzione a `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_dplyr.html#gruppi",
    "href": "chapters/R/05_dplyr.html#gruppi",
    "title": "10¬† Introduzione a dplyr",
    "section": "\n10.6 Gruppi",
    "text": "10.6 Gruppi\nIl verbo group_by() viene utilizzato per suddividere un dataset in gruppi, in base a una o pi√π variabili, che siano rilevanti per l‚Äôanalisi. Questo permette di eseguire operazioni di sintesi su ciascun gruppo separatamente, ottenendo informazioni aggregate.\nAd esempio, nel codice seguente:\n\nmsleep |&gt;\n  group_by(order) |&gt;\n  summarise(\n    avg_sleep = mean(sleep_total),\n    min_sleep = min(sleep_total),\n    max_sleep = max(sleep_total),\n    total = n()\n  ) |&gt;\n  arrange(desc(avg_sleep))\n#&gt; # A tibble: 19 √ó 5\n#&gt;    order           avg_sleep min_sleep max_sleep total\n#&gt;    &lt;chr&gt;               &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;int&gt;\n#&gt;  1 Chiroptera          19.8       19.7      19.9     2\n#&gt;  2 Didelphimorphia     18.7       18        19.4     2\n#&gt;  3 Cingulata           17.8       17.4      18.1     2\n#&gt;  4 Afrosoricida        15.6       15.6      15.6     1\n#&gt;  5 Pilosa              14.4       14.4      14.4     1\n#&gt;  6 Rodentia            12.5        7        16.6    22\n#&gt;  7 Diprotodontia       12.4       11.1      13.7     2\n#&gt;  8 Soricomorpha        11.1        8.4      14.9     5\n#&gt;  9 Primates            10.5        8        17      12\n#&gt; 10 Erinaceomorpha      10.2       10.1      10.3     2\n#&gt; 11 Carnivora           10.1        3.5      15.8    12\n#&gt; 12 Scandentia           8.9        8.9       8.9     1\n#&gt; 13 Monotremata          8.6        8.6       8.6     1\n#&gt; 14 Lagomorpha           8.4        8.4       8.4     1\n#&gt; 15 Hyracoidea           5.67       5.3       6.3     3\n#&gt; 16 Artiodactyla         4.52       1.9       9.1     6\n#&gt; 17 Cetacea              4.5        2.7       5.6     3\n#&gt; 18 Proboscidea          3.6        3.3       3.9     2\n#&gt; 19 Perissodactyla       3.47       2.9       4.4     3\n\n\ngroup_by(order) suddivide il dataset msleep in gruppi, ciascuno corrispondente a un valore distinto della variabile order.\n\nSuccessivamente, summarise() calcola diverse statistiche per ogni gruppo:\n\n\navg_sleep √® la media del totale del sonno (sleep_total) all‚Äôinterno di ciascun gruppo.\n\nmin_sleep √® il valore minimo di sleep_total in ogni gruppo.\n\nmax_sleep √® il valore massimo di sleep_total in ogni gruppo.\n\ntotal √® il numero di osservazioni (o righe) per ciascun gruppo, calcolato con la funzione n().\n\n\nInfine, arrange(desc(avg_sleep)) ordina i risultati in ordine decrescente in base alla media del sonno totale (avg_sleep), mostrando prima i gruppi con la media di sonno pi√π alta.\n\nQuesto tipo di approccio √® utile quando si vuole analizzare come cambiano le caratteristiche dei dati a seconda dei gruppi specifici, fornendo una visione pi√π dettagliata e utile.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Introduzione a `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_dplyr.html#considerazioni-conclusive",
    "href": "chapters/R/05_dplyr.html#considerazioni-conclusive",
    "title": "10¬† Introduzione a dplyr",
    "section": "\n10.7 Considerazioni Conclusive",
    "text": "10.7 Considerazioni Conclusive\nIl data wrangling √® una delle fasi pi√π importanti in qualsiasi pipeline di analisi dei dati. In questo capitolo abbiamo introdotto l‚Äôuso del pacchetto tidyverse di R per la manipolazione dei dati e il suo utilizzo in scenari di base. Tuttavia, il tidyverse √® un ecosistema ampio e qui abbiamo trattato solo gli elementi fondamentali. Per approfondire, si consiglia di consultare ulteriori risorse come quelle disponibili sul sito web del tidyverse e il libro R for Data Science (2e), di cui esiste anche una traduzione italiana.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Introduzione a `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_dplyr.html#esercizi",
    "href": "chapters/R/05_dplyr.html#esercizi",
    "title": "10¬† Introduzione a dplyr",
    "section": "\n10.8 Esercizi",
    "text": "10.8 Esercizi\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nIn questo esercizio, utilizzerai il pacchetto dplyr per imparare a manipolare e trasformare i dati della SWLS (Satisfaction With Life Scale). Gli esercizi ti aiuteranno a consolidare la conoscenza dei principali verbi di dplyr, inclusi filter(), select(), mutate(), arrange() e group_by().\nParte 1: Comprensione Teorica\n\n\nCos‚Äô√® un dataset ‚Äútidy‚Äù?\n\nDescrivi con parole tue cosa significa avere un dataset ‚Äútidy‚Äù e quali sono le sue tre caratteristiche principali.\n\n\n\nCos‚Äô√® la pipe (%&gt;% o |&gt;) e perch√© √® utile?\n\nSpiega a cosa serve l‚Äôoperatore pipe e fornisci un esempio di utilizzo.\n\n\n\nQuali sono i verbi principali di dplyr?\n\nElenca e spiega brevemente i sei verbi principali di dplyr per la manipolazione dei dati.\n\n\n\nCosa fa il verbo group_by()?\n\nSpiega il suo scopo e come viene utilizzato in combinazione con summarise().\n\n\n\nParte 2: Applicazione Pratica con i Dati SWLS\n\n\nCaricamento dei dati SWLS\n\nCrea un data frame in R contenente i punteggi SWLS che hai raccolto.\n\n\n\nSelezione delle colonne\n\nUsa select() per mantenere solo le colonne con i punteggi degli item.\n\n\n\nFiltraggio dei dati\n\nUsa filter() per selezionare solo gli individui che hanno un punteggio totale superiore a 20.\n\n\n\nCreazione di una nuova colonna\n\nUsa mutate() per calcolare il punteggio totale della SWLS per ciascun individuo e salvarlo in una nuova colonna chiamata punteggio_totale.\n\n\n\nRiordinamento dei dati\n\nUsa arrange() per ordinare il dataset in base al punteggio totale, dal pi√π alto al pi√π basso.\n\n\n\nRaggruppamento e sintesi dei dati\n\n\n\nUsa group_by() e summarise() per calcolare la media e la deviazione standard del punteggio SWLS totale nel dataset.\n\nConsegna\n\nScrivi le risposte della Parte 1 su carta.\nScrivi il codice e i risultati della Parte 2 in un file .R e invialo come consegna.\n\n\n\n\n\n\n\n\n\n\nSoluzione\n\n\n\n\n\nParte 1: Comprensione Teorica\n\n\nCos‚Äô√® un dataset ‚Äútidy‚Äù?\n\nUn dataset ‚Äútidy‚Äù √® un dataset organizzato in modo sistematico per facilitare l‚Äôanalisi. Le sue tre caratteristiche principali sono:\n\nOgni variabile √® una colonna.\nOgni osservazione √® una riga.\nOgni valore √® una cella.\n\n\n\n\n\nCos‚Äô√® la pipe (%&gt;% o |&gt;) e perch√© √® utile?\n\nLa pipe (%&gt;% o |&gt;) permette di concatenare pi√π operazioni di manipolazione dati in modo leggibile ed efficiente.\n\nEsempio:\ndf |&gt; \n  filter(score &gt; 20) |&gt; \n  select(name, score)\n\n\n\n\nQuali sono i verbi principali di dplyr?\n\n\nselect(): Seleziona colonne.\n\nfilter(): Filtra righe.\n\narrange(): Riordina le righe.\n\nmutate(): Crea nuove colonne.\n\nsummarise(): Riassume i dati.\n\ngroup_by(): Permette di raggruppare i dati.\n\n\n\nCosa fa il verbo group_by()?\n\ngroup_by() suddivide i dati in gruppi, permettendo di applicare funzioni di aggregazione con summarise().\n\nEsempio:\ndf |&gt; \n  group_by(gruppo) |&gt; \n  summarise(media = mean(score), sd = sd(score))\n\n\n\n\nParte 2: Applicazione Pratica con i Dati SWLS\n\n\nCaricamento dei dati SWLS Per svolgere l‚Äôesercizio, simuliamo i dati di 10 individui su 5 item (numeri casuali da 1 a 7):\nset.seed(123)\nswls &lt;- data.frame(\n  id = 1:10,\n  item1 = sample(1:7, 10, replace = TRUE),\n  item2 = sample(1:7, 10, replace = TRUE),\n  item3 = sample(1:7, 10, replace = TRUE),\n  item4 = sample(1:7, 10, replace = TRUE),\n  item5 = sample(1:7, 10, replace = TRUE)\n)\nprint(swls)\n\n\nSelezione delle colonne\nswls_selected &lt;- swls |&gt; select(item1:item5)\n\n\nFiltraggio dei dati\nswls_filtered &lt;- swls |&gt; filter(rowSums(select(swls, item1:item5)) &gt; 20)\n\n\nCreazione di una nuova colonna\nswls &lt;- swls |&gt; mutate(punteggio_totale = rowSums(select(swls, item1:item5)))\n\n\nRiordinamento dei dati\nswls_sorted &lt;- swls |&gt; arrange(desc(punteggio_totale))\n\nRaggruppamento e sintesi dei dati\n\nswls_summary &lt;- swls |&gt; \n  summarise(media = mean(punteggio_totale), sd = sd(punteggio_totale))\nConclusione\nQuesti esercizi hanno mostrato come usare dplyr per manipolare dati in modo efficace e leggibile.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Introduzione a `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_dplyr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/R/05_dplyr.html#informazioni-sullambiente-di-sviluppo",
    "title": "10¬† Introduzione a dplyr",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] missForest_1.5   mice_3.17.0      thematic_0.1.6   MetBrewer_0.2.0 \n#&gt;  [5] ggokabeito_0.1.0 see_0.11.0       gridExtra_2.3    patchwork_1.3.0 \n#&gt;  [9] bayesplot_1.11.1 psych_2.5.3      scales_1.3.0     markdown_2.0    \n#&gt; [13] knitr_1.50       lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1   \n#&gt; [17] dplyr_1.1.4      purrr_1.0.4      readr_2.1.5      tidyr_1.3.1     \n#&gt; [21] tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3       \n#&gt; [25] here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1     farver_2.1.2         fastmap_1.2.0       \n#&gt;  [4] pacman_0.5.1         digest_0.6.37        rpart_4.1.24        \n#&gt;  [7] timechange_0.3.0     lifecycle_1.0.4      survival_3.8-3      \n#&gt; [10] magrittr_2.0.3       compiler_4.4.2       rngtools_1.5.2      \n#&gt; [13] rlang_1.1.5          tools_4.4.2          utf8_1.2.4          \n#&gt; [16] doRNG_1.8.6.1        htmlwidgets_1.6.4    mnormt_2.1.1        \n#&gt; [19] withr_3.0.2          itertools_0.1-3      nnet_7.3-20         \n#&gt; [22] grid_4.4.2           jomo_2.7-6           colorspace_2.1-1    \n#&gt; [25] iterators_1.0.14     MASS_7.3-65          cli_3.6.4           \n#&gt; [28] rmarkdown_2.29       reformulas_0.4.0     generics_0.1.3      \n#&gt; [31] rstudioapi_0.17.1    tzdb_0.5.0           minqa_1.2.8         \n#&gt; [34] splines_4.4.2        parallel_4.4.2       vctrs_0.6.5         \n#&gt; [37] boot_1.3-31          glmnet_4.1-8         Matrix_1.7-3        \n#&gt; [40] jsonlite_1.9.1       hms_1.1.3            mitml_0.4-5         \n#&gt; [43] foreach_1.5.2        glue_1.8.0           nloptr_2.2.1        \n#&gt; [46] pan_1.9              codetools_0.2-20     stringi_1.8.4       \n#&gt; [49] shape_1.4.6.1        gtable_0.3.6         lme4_1.1-36         \n#&gt; [52] munsell_0.5.1        pillar_1.10.1        htmltools_0.5.8.1   \n#&gt; [55] randomForest_4.7-1.2 R6_2.6.1             Rdpack_2.6.3        \n#&gt; [58] rprojroot_2.0.4      evaluate_1.0.3       lattice_0.22-6      \n#&gt; [61] rbibutils_2.3        backports_1.5.0      broom_1.0.7         \n#&gt; [64] Rcpp_1.0.14          nlme_3.1-167         xfun_0.51           \n#&gt; [67] pkgconfig_2.0.3",
    "crumbs": [
      "R",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Introduzione a `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_dplyr.html#bibliografia",
    "href": "chapters/R/05_dplyr.html#bibliografia",
    "title": "10¬† Introduzione a dplyr",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nIrizarry, R. A. (2024). Introduction to Data Science: Data Wrangling and Visualization with R. CRC Press.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Introduzione a `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/R/06_quarto.html",
    "href": "chapters/R/06_quarto.html",
    "title": "11¬† Quarto",
    "section": "",
    "text": "11.1 Introduzione\nLa crisi della riproducibilit√† scientifica rappresenta una delle sfide pi√π importanti della ricerca contemporanea. Con questo termine ci si riferisce alla difficolt√†, riscontrata in diverse discipline, di replicare i risultati degli studi scientifici. Sebbene le definizioni di riproducibilit√† varino tra i diversi ambiti, un‚Äôinterpretazione ampiamente condivisa la identifica come la capacit√† di ottenere gli stessi risultati utilizzando i medesimi dati di input e seguendo gli stessi passaggi computazionali nei metodi e nelle analisi.\nLa pratica scientifica √® profondamente radicata nella formazione accademica: ci√≤ che viene insegnato nelle aule universitarie si riflette direttamente nel lavoro svolto nei laboratori, sul campo e nell‚Äôanalisi dei dati. Riconoscendo questo stretto legame tra didattica e ricerca, molti studiosi sostengono l‚Äôimportanza di integrare i metodi di riproducibilit√† nei corsi universitari di data science, sia a livello undergraduate che graduate (Dogucu, 2024). L‚Äôeducazione alla data science che incorpora la riproducibilit√† nell‚Äôanalisi dei dati viene infatti considerata la ‚Äúcontroffensiva statistica‚Äù alla crisi della riproducibilit√†.\nIn questo contesto si inserisce Quarto, uno strumento innovativo che affronta direttamente le sfide della crisi della riproducibilit√†. Quarto si colloca nella tradizione del literate programming, un approccio pioneristico introdotto da Donald Knuth negli anni ‚Äô80. Questa metodologia nasce dalla visione di unificare codice e testo descrittivo in un unico documento, rendendo i programmi non solo eseguibili ma anche comprensibili agli esseri umani. L‚Äôobiettivo √® superare la tradizionale separazione tra codice e documentazione, permettendo di spiegare non solo il funzionamento tecnico di un programma, ma anche le ragioni delle scelte implementative.\nQuesta filosofia risulta particolarmente pertinente nell‚Äôambito della data science e dell‚Äôanalisi statistica, dove riproducibilit√† e trasparenza sono requisiti imprescindibili. Quarto eccelle in questo contesto, offrendo la possibilit√† di integrare in codice, risultati e narrazione. La sua versatilit√† si manifesta nella capacit√† di produrre diversi tipi di output - dai report agli articoli scientifici, dalle presentazioni ai documenti tecnici - in vari formati come HTML, PDF e Word, combinando efficacemente testo interpretativo, risultati numerici e visualizzazioni grafiche.\nUn punto di forza distintivo di Quarto √® la sua flessibilit√† nel supportare molteplici linguaggi di programmazione, tra cui R, Python e Julia. Lo strumento pu√≤ essere utilizzato secondo tre modalit√† principali: per presentare conclusioni condividendo i risultati senza esporre il codice sottostante; per documentare il processo analitico includendo sia il codice che i risultati, garantendo cos√¨ piena trasparenza e riproducibilit√†; e per annotare l‚Äôanalisi, integrando interpretazioni e motivazioni delle decisioni prese durante il processo analitico.\nNonostante Quarto sia tecnicamente uno strumento da riga di comando (CLI), l‚Äôintegrazione con RStudio ne semplifica notevolmente l‚Äôutilizzo, rendendo l‚Äôinstallazione e l‚Äôoperativit√† accessibili anche agli utenti meno esperti nell‚Äôuso del terminale. Questa caratteristica, unita alle sue potenti funzionalit√†, rende Quarto una naturale evoluzione del literate programming, offrendo un ambiente di lavoro che bilancia efficacemente praticit√† d‚Äôuso e rigore scientifico. In questo modo, Quarto si configura come una risposta concreta alle sfide della riproducibilit√† nella ricerca contemporanea, fornendo gli strumenti necessari per una scienza pi√π trasparente e verificabile. L‚Äôobiettivo di questo capitolo √® quello di fornire un‚Äôintroduzione pratica a Quarto.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "chapters/R/06_quarto.html#introduzione",
    "href": "chapters/R/06_quarto.html#introduzione",
    "title": "11¬† Quarto",
    "section": "",
    "text": "11.1.1 Creare un documento Quarto\nUn file Quarto ha estensione .qmd e segue questa struttura:\n\nQuesto file include:\n\nUn‚Äôintestazione YAML (metadati del documento).\nBlocchi di codice delimitati da ```.\nTesto scritto in Markdown con formattazioni semplici come titoli (# Titolo), corsivi (*testo*), ecc.\n\n11.1.2 Editor visivo e sorgente\n\n\nEditor visivo: simile a Google Docs, offre un‚Äôinterfaccia WYSIWYM (What You See Is What You Mean). Consente di inserire facilmente immagini, tabelle, citazioni e altro.\n\nEditor sorgente: consente un controllo diretto sul Markdown, utile per debug e personalizzazioni avanzate.\n\n11.1.3 Blocchi di codice\nI blocchi di codice (chiamati ‚Äúchunks‚Äù) eseguono codice e visualizzano i risultati. Ogni chunk √® delimitato da ``` e pu√≤ includere opzioni specifiche:\n#| label: esempio\n#| echo: false\n1 + 1\nLe opzioni pi√π comuni includono:\n\n\necho: false (nasconde il codice nel report),\n\neval: false (non esegue il codice),\n\nmessage: false e warning: false (nasconde messaggi o avvisi).\n\n11.1.4 Figure\nLe figure possono essere generate tramite codice (es. ggplot()) o inserite come file esterni. Le opzioni pi√π comuni per il controllo delle dimensioni sono:\n\n\nfig-width e fig-height (dimensioni della figura in pollici),\n\nout-width (percentuale di larghezza del documento),\n\nfig-asp (rapporto d‚Äôaspetto, es. 0.618 per il rapporto aureo).\n\nEsempio:\n#| fig-width: 6\nggplot(data, aes(x, y)) + geom_point()\n\n11.1.5 Equazioni\nLe equazioni possono essere scritte in \\(\\LaTeX\\), cos√¨ come spiegato nell‚ÄôAppendice D.\n\n11.1.6 Tabelle\nLe tabelle possono essere stampate direttamente o personalizzate con funzioni come knitr::kable() o pacchetti come gt:\n\nknitr::kable(head(mtcars))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmpg\ncyl\ndisp\nhp\ndrat\nwt\nqsec\nvs\nam\ngear\ncarb\n\n\n\nMazda RX4\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\nMazda RX4 Wag\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\nDatsun 710\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\nHornet 4 Drive\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\nHornet Sportabout\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\nValiant\n18.1\n6\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n\n\n\n\n11.1.7 Caching\nPer velocizzare i documenti con calcoli complessi, Quarto supporta la memorizzazione dei risultati:\n\n\ncache: true salva i risultati di un chunk, evitando di ricalcolarli se il codice non cambia.\n\ndependson specifica dipendenze tra chunk.\n\n11.1.8 Gestione delle Citazioni e delle Bibliografie in Quarto\nQuarto offre un supporto avanzato per la generazione automatica di citazioni e bibliografie, consentendo l‚Äôapplicazione di formati personalizzati come lo stile APA. Per includere riferimenti bibliografici, √® necessario creare un file .bib (ad esempio, references.bib) contenente le citazioni nel formato BibTeX. Queste citazioni possono essere ottenute direttamente da Google Scholar o altri database accademici.\nEcco un esempio di una citazione in formato BibTeX:\n@article{ceccarini2024age,\n  title={Age-dependent changes in the anger superiority effect: Evidence from a visual search task},\n  author={Ceccarini, Francesco and Colpizzi, Ilaria and Caudek, Corrado},\n  journal={Psychonomic Bulletin \\& Review},\n  pages={1--10},\n  year={2024},\n  publisher={Springer}\n}\nQuesta citazione deve essere inserita in un file .bib, ad esempio, references.bib. Tale file dovr√† poi essere specificato nell‚Äôintestazione del documento Quarto.\n\n11.1.8.1 Configurazione dell‚ÄôIntestazione YAML\nNel file .qmd, √® necessario aggiungere le seguenti righe all‚Äôintestazione YAML per collegare il file references.bib e configurare lo stile della bibliografia:\nbibliography: references.bib\nbiblio-style: apalike\ncsl: apa.csl\n\n\nbibliography: Specifica il percorso del file .bib. In questo esempio, si assume che il file si trovi nella stessa cartella del documento Quarto.\n\nbiblio-style: Imposta lo stile delle citazioni. Ad esempio, apalike √® uno stile simile allo stile APA.\n\ncsl: Consente di utilizzare uno stile di citazione personalizzato, come apa.csl. Puoi scaricare facilmente questi stili dal Zotero Style Repository.\n\n11.1.8.2 Esempio Completo\nDi seguito √® riportato un esempio completo di un documento Quarto che include una citazione e genera automaticamente la bibliografia:\n---\ntitle: \"Articolo di Esempio\"\nauthor: \"Autore di Esempio\"\ndate: \"2025-03-26\"\nbibliography: references.bib\nbiblio-style: apalike\ncsl: apa.csl\n---\n\n## Introduzione\n\nIn questo articolo, discutiamo i cambiamenti dipendenti dall'et√† nell'anger-superiority effect [@ceccarini2024age].\n\n## Risultati\n\nI risultati mostrano che...\n\n## Riferimenti\nIn questo esempio, l‚Äôidentificatore @ceccarini2024age viene utilizzato per fare riferimento alla citazione contenuta nel file references.bib. Al momento della compilazione, Quarto generer√† automaticamente la lista dei riferimenti bibliografici in base al formato specificato.\n\n11.1.8.3 Citazioni Inline\nAll‚Äôinterno di un documento .qmd, le citazioni vengono aggiunte utilizzando il simbolo @ seguito dall‚Äôidentificativo della citazione specificato nel file .bib. Ad esempio:\n... come evidenziato da @ceccarini2024age, si osserva che...\nQuarto genera automaticamente la bibliografia, includendo solo i riferimenti effettivamente citati nel documento. La bibliografia viene aggiunta alla fine del file renderizzato (ad esempio, in formato HTML o PDF).\nAd esempio, nel caso di un documento .qmd, il testo sopra sar√† visualizzato cos√¨:\n\n‚Ä¶ come evidenziato da Ceccarini et al.¬†(2024), si osserva che‚Ä¶\n\nLa citazione completa sar√† inclusa automaticamente nella bibliografia, posizionata alla fine della pagina web o del documento finale. Si noti che Quarto gestisce automaticamente la formattazione e la posizione della bibliografia, garantendo coerenza e precisione.\n\nEsempio 11.1 Per fare un esempio pratico, possiamo inserire la citazione @ceccarini2024age direttamente nel file .qmd di questa pagina web. Quando il documento viene compilato, Quarto render√† la citazione in modo appropriato, come mostrato qui: Ceccarini et al. (2024).\nSi noti che, in fondo a questa pagina web, √® presente un riferimento bibliografico corrispondente. Questo riferimento √® stato aggiunto automaticamente da Quarto in risposta all‚Äôuso della citazione @ceccarini2024age nel testo del documento. Questo processo automatizzato semplifica la gestione delle citazioni e garantisce che tutti i riferimenti siano correttamente inclusi e formattati.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "chapters/R/06_quarto.html#riflessioni-conclusive",
    "href": "chapters/R/06_quarto.html#riflessioni-conclusive",
    "title": "11¬† Quarto",
    "section": "\n11.2 Riflessioni Conclusive",
    "text": "11.2 Riflessioni Conclusive\nQuarto √® uno strumento potente per la creazione di documenti riproducibili e ben strutturati, integrando codice, risultati e testo descrittivo in un unico file. Questa introduzione dovrebbe essere sufficiente per iniziare a lavorare con Quarto, ma c‚Äô√® ancora molto da imparare. Il modo migliore per rimanere aggiornati √® consultare il sito ufficiale di Quarto: https://quarto.org.\nUn argomento importante che non abbiamo trattato qui riguarda i dettagli di come comunicare in modo accurato le proprie idee agli altri. Per migliorare le proprie capacit√† di scrittura, Wickham et al. (2023) consigliano due libri: Style: Lessons in Clarity and Grace di Joseph M. Williams & Joseph Bizup, e The Sense of Structure: Writing from the Reader‚Äôs Perspective di George Gopen. Una serie di brevi articoli sulla scrittura sono offerti da George Gopen e sono disponibili su https://www.georgegopen.com/litigation-articles.html.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "chapters/R/06_quarto.html#esercizi",
    "href": "chapters/R/06_quarto.html#esercizi",
    "title": "11¬† Quarto",
    "section": "\n11.3 Esercizi",
    "text": "11.3 Esercizi\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nIn questo esercizio esplorerai l‚Äôimportanza della riproducibilit√† nella scienza dei dati e le funzionalit√† principali di Quarto.\n1. Concetti di base sulla riproducibilit√†\n\nCos‚Äô√® la crisi della riproducibilit√† e perch√© √® rilevante nella scienza dei dati?\nIn che modo Quarto pu√≤ aiutare ad affrontare la crisi della riproducibilit√†?\nSpiega il concetto di literate programming e come si collega a Quarto.\n\n2. Struttura di un file Quarto\n\nQual √® l‚Äôestensione di un file Quarto e quali sono le sue tre sezioni principali?\nQual √® la differenza tra editor visivo ed editor sorgente in Quarto?\nQual √® la funzione dell‚Äôintestazione YAML in un file .qmd?\n\n3. Blocchi di codice e opzioni\n\nCome si scrive un blocco di codice in Quarto?\nQuali opzioni puoi utilizzare nei blocchi di codice per controllare l‚Äôesecuzione e la visualizzazione del codice e dei risultati?\nScrivi un blocco di codice Quarto che calcola la media di un vettore di numeri e stampa il risultato senza mostrare il codice.\n\n4. Figure e Tabelle\n\nQuali opzioni di formattazione delle figure offre Quarto?\nCome puoi creare una tabella formattata in Quarto usando knitr::kable()?\n\n5. Citazioni e Bibliografia\n\nCome si aggiunge una citazione bibliografica in Quarto?\nQuali file devono essere inclusi per gestire una bibliografia in Quarto?\nScrivi un esempio di citazione in formato BibTeX e mostra come collegarla a un documento .qmd.\n\n6. Considerazioni Finali\n\nQuali sono i vantaggi di usare Quarto rispetto a strumenti pi√π tradizionali come Word per la creazione di report scientifici?\n\n\n\n\n\n\n\n\n\n\nSoluzione\n\n\n\n\n\n1. Concetti di base sulla riproducibilit√†\n\nLa crisi della riproducibilit√† √® il fenomeno per cui molti studi scientifici non possono essere replicati con gli stessi metodi e dati. Questo mina la fiducia nella scienza e pu√≤ portare a risultati non affidabili.\nQuarto aiuta la riproducibilit√† integrando codice, testo e risultati in un unico documento, rendendo pi√π semplice verificare e riprodurre le analisi.\n\nLiterate programming √® un approccio introdotto da Donald Knuth che combina codice e spiegazioni testuali nello stesso file, migliorando la comprensione e documentazione delle analisi. Quarto segue questa filosofia.\n\n2. Struttura di un file Quarto\n\n\nL‚Äôestensione di un file Quarto √® .qmd. Le tre sezioni principali sono:\n\nL‚Äôintestazione YAML (metadati),\nIl codice (chunks),\nIl testo scritto in Markdown.\n\n\nL‚Äôeditor visivo √® un‚Äôinterfaccia intuitiva simile a Google Docs, mentre l‚Äôeditor sorgente permette di scrivere direttamente in Markdown e codice.\nL‚Äôintestazione YAML definisce le propriet√† del documento come titolo, autore, formato di output e opzioni di rendering.\n\n3. Blocchi di codice e opzioni\n\n\nUn blocco di codice in Quarto si scrive con tripli backtick (```) e un linguaggio specificato:\n#| echo: true\nprint(\"Esempio di codice in Quarto\")\n\n\nAlcune opzioni utili nei blocchi di codice sono:\n\n\necho: false per nascondere il codice,\n\neval: false per non eseguire il codice,\n\nwarning: false e message: false per nascondere messaggi e avvisi.\n\n\n\nEsempio di blocco di codice che calcola una media senza mostrare il codice:\n#| echo: false\nmean(c(1, 2, 3, 4, 5))\n\n\n\n11.4 4. Figure e Tabelle\n\n\nLe opzioni principali per le figure includono:\n\n\nfig-width e fig-height per le dimensioni,\n\nout-width per la larghezza relativa,\n\nfig-asp per il rapporto d‚Äôaspetto.\n\n\n\nPer creare una tabella formattata con knitr::kable():\nknitr::kable(head(mtcars))\n\n\n5. Citazioni e Bibliografia\n\nLe citazioni in Quarto si aggiungono usando il simbolo @ seguito dal riferimento BibTeX (es. @ceccarini2024age).\n\nPer gestire la bibliografia in Quarto servono:\n\nUn file .bib con le citazioni,\nUn‚Äôintestazione YAML che collega il file .bib e specifica lo stile (csl).\n\n\n\nEsempio di citazione BibTeX e collegamento in YAML:\n@article{ceccarini2024age,\n  title={Age-dependent changes in the anger superiority effect},\n  author={Ceccarini, Francesco et al.},\n  journal={Psychonomic Bulletin & Review},\n  year={2024}\n}\nYAML:\nbibliography: references.bib\nbiblio-style: apalike\n\n\n6. Considerazioni Finali\n\n\nI vantaggi di Quarto rispetto a Word includono:\n\nmaggiore riproducibilit√† e trasparenza,\npossibilit√† di integrare codice ed esecuzione in un unico documento,\nfacilit√† di gestione delle citazioni automatiche,\nsupporto per diversi formati di output (HTML, PDF, Word).",
    "crumbs": [
      "R",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "chapters/R/06_quarto.html#figure-e-tabelle",
    "href": "chapters/R/06_quarto.html#figure-e-tabelle",
    "title": "11¬† Quarto",
    "section": "\n11.4 4. Figure e Tabelle",
    "text": "11.4 4. Figure e Tabelle\n\n\nLe opzioni principali per le figure includono:\n\n\nfig-width e fig-height per le dimensioni,\n\nout-width per la larghezza relativa,\n\nfig-asp per il rapporto d‚Äôaspetto.\n\n\n\nPer creare una tabella formattata con knitr::kable():\nknitr::kable(head(mtcars))\n\n\n5. Citazioni e Bibliografia\n\nLe citazioni in Quarto si aggiungono usando il simbolo @ seguito dal riferimento BibTeX (es. @ceccarini2024age).\n\nPer gestire la bibliografia in Quarto servono:\n\nUn file .bib con le citazioni,\nUn‚Äôintestazione YAML che collega il file .bib e specifica lo stile (csl).\n\n\n\nEsempio di citazione BibTeX e collegamento in YAML:\n@article{ceccarini2024age,\n  title={Age-dependent changes in the anger superiority effect},\n  author={Ceccarini, Francesco et al.},\n  journal={Psychonomic Bulletin & Review},\n  year={2024}\n}\nYAML:\nbibliography: references.bib\nbiblio-style: apalike\n\n\n6. Considerazioni Finali\n\n\nI vantaggi di Quarto rispetto a Word includono:\n\nmaggiore riproducibilit√† e trasparenza,\npossibilit√† di integrare codice ed esecuzione in un unico documento,\nfacilit√† di gestione delle citazioni automatiche,\nsupporto per diversi formati di output (HTML, PDF, Word).",
    "crumbs": [
      "R",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "chapters/R/06_quarto.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/R/06_quarto.html#informazioni-sullambiente-di-sviluppo",
    "title": "11¬† Quarto",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.5.3     \n#&gt;  [9] scales_1.3.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.9.1   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         rlang_1.1.5       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       tools_4.4.2       parallel_4.4.2    tzdb_0.5.0       \n#&gt; [21] colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5       R6_2.6.1         \n#&gt; [25] lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.1    \n#&gt; [29] gtable_0.3.6      glue_1.8.0        xfun_0.51         tidyselect_1.2.1 \n#&gt; [33] rstudioapi_0.17.1 farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-167     \n#&gt; [37] rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "R",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "chapters/R/06_quarto.html#bibliografia",
    "href": "chapters/R/06_quarto.html#bibliografia",
    "title": "11¬† Quarto",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nCeccarini, F., Colpizzi, I., & Caudek, C. (2024). Age-dependent changes in the anger superiority effect: Evidence from a visual search task. Psychonomic Bulletin & Review, 1‚Äì10.\n\n\nDogucu, M. (2024). Reproducibility in the Classroom. Annual Review of Statistics and Its Application, 12.\n\n\nWickham, H., √áetinkaya-Rundel, M., & Grolemund, G. (2023). R for data science. \" O‚ÄôReilly Media, Inc.\".",
    "crumbs": [
      "R",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "chapters/R/07_environment.html",
    "href": "chapters/R/07_environment.html",
    "title": "12¬† L‚Äôambiente di programmazione",
    "section": "",
    "text": "12.1 Introduzione\nProgrammare presuppone necessariamente un ambiente di programmazione. Una cattiva gestione di questo ambiente pu√≤ causare il malfunzionamento degli script, rendendo fondamentale imparare a gestirlo correttamente.\nL‚Äôambiente pu√≤ influenzare persino il comportamento delle funzioni pi√π basilari. Considera il seguente esempio:\nQuesto potrebbe produrre il seguente output:\nTuttavia, modificando l‚Äôopzione di larghezza in R, il comportamento cambia:\nIn questo caso, l‚Äôoutput potrebbe essere:\nLa differenza √® dovuta a un‚Äôopzione dell‚Äôambiente, width, che regola il numero massimo di caratteri visualizzati per ogni riga.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>L'ambiente di programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/07_environment.html#introduzione",
    "href": "chapters/R/07_environment.html#introduzione",
    "title": "12¬† L‚Äôambiente di programmazione",
    "section": "",
    "text": "Nota: In R, il termine ‚Äúambiente‚Äù ha un significato specifico, riferendosi allo spazio di lavoro in cui gli oggetti vengono memorizzati durante una sessione. In questo capitolo, tuttavia, il termine si riferisce allo stato complessivo del tuo computer mentre programmi, inclusa l‚Äôorganizzazione dei file, la versione di R che stai usando e altre impostazioni.\n\n\nprint(1:9)\n\n[1] 1 2 3 4 5 6 7 8 9\n\n# Dopo aver modificato options(width)\noptions(width = 10)\nprint(1:9)\n\n[1] 1 2 3\n[4] 4 5 6\n[7] 7 8 9",
    "crumbs": [
      "R",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>L'ambiente di programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/07_environment.html#file-system",
    "href": "chapters/R/07_environment.html#file-system",
    "title": "12¬† L‚Äôambiente di programmazione",
    "section": "\n12.2 File system",
    "text": "12.2 File system\nPrima di iniziare a organizzare un progetto in R, √® fondamentale seguire alcune linee guida per strutturare e nominare i file in modo efficace. Spesso si tende a sottovalutare l‚Äôimportanza di una buona organizzazione, ma adottare un sistema coerente pu√≤ far risparmiare tempo prezioso nella ricerca e gestione dei progetti passati. Danielle Navarro ha creato una presentazione sulla struttura dei progetti, nella quale propone tre principi fondamentali per la gestione dei file:\n\nessere gentili con le macchine;\nessere gentili con gli esseri umani;\nfacilitare l‚Äôordinamento e la ricerca.\n\n\n12.2.1 Essere gentili con le macchine\nLe macchine possono confondersi con spazi, caratteri speciali (come ^.*?+|$\"), e lettere accentate. Per evitare problemi:\n\nusa solo lettere minuscole, numeri, trattini _ o -;\nevita caratteri speciali e spazi nei nomi dei file;\nevita le lettere accentate;\nusa estensioni coerenti, come .R per gli script R.\n\nEsempi:\n# Buono\nprogetto01_analisi_dati.R\n\n# Cattivo\nProgetto \"Analisi Dati\".R\n\n12.2.2 Essere gentili con gli umani\nGli esseri umani hanno bisogno di contesto. Evita nomi vaghi e usa descrizioni significative.\n# Buono\nanalisi01_statistiche_descrittive.R\nnote02_intro_modello.docx\n\n# Cattivo\n01.R\nappunti.docx\n\n\n\n\n\n\nEvitate categoricamente l‚Äôuso di spazi nei nomi di file, cartelle o oggetti in R. Anche se il sistema operativo potrebbe consentirlo, questa pratica pu√≤ generare problemi futuri, complicare il debugging e rendere il codice meno leggibile e portabile. Per evitare questi inconvenienti, adottate sempre nomi privi di spazi, preferendo separatori come trattini bassi (_) o trattini (-).\n\n\n\n\n12.2.3 Facilitare l‚Äôordinamento e la ricerca\nSe i nomi dei file includono date, usa sempre il formato YYYY-MM-DD per permettere un ordinamento automatico.\n# Buono\n2024-01-01_analisi.R\n2024-02-15_riassunto.docx\n\n# Cattivo\n1-gennaio-2024.R\nriassunto-15-02-2024.docx\nSe devi ordinare i file in base a qualcosa di diverso dalle date, usa numeri con lo zero iniziale per mantenere l‚Äôordine.\nreading01_shakespeare_romeo-and-juliet.docx\nreading02_shakespeare_romeo-and-juliet.docx\n...\nreading11_shakespeare_romeo-and-juliet.docx\nnotes01_shakespeare_romeo-and-juliet.docx\n...",
    "crumbs": [
      "R",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>L'ambiente di programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/07_environment.html#versioni-di-r-e-pacchetti",
    "href": "chapters/R/07_environment.html#versioni-di-r-e-pacchetti",
    "title": "12¬† L‚Äôambiente di programmazione",
    "section": "\n12.3 Versioni di R e pacchetti",
    "text": "12.3 Versioni di R e pacchetti\nAggiornare regolarmente R e i pacchetti √® essenziale per evitare bug e sfruttare le nuove funzionalit√†. Ecco alcune buone pratiche:\n\nEsegui update.packages() ogni poche settimane per aggiornare i pacchetti.\nAggiorna la versione di R ogni pochi mesi. Su Windows puoi usare il pacchetto installr, mentre su altri sistemi puoi scaricare l‚Äôultima versione dal sito ufficiale di R.\nMantieni aggiornato anche il sistema operativo.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>L'ambiente di programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/07_environment.html#progetti-in-r",
    "href": "chapters/R/07_environment.html#progetti-in-r",
    "title": "12¬† L‚Äôambiente di programmazione",
    "section": "\n12.4 Progetti in R",
    "text": "12.4 Progetti in R\nSe hai seguito i consigli finora, avrai creato una cartella per tutti i tuoi progetti di programmazione e la tua installazione di R sar√† aggiornata. Ora √® il momento di organizzare i tuoi progetti in R.\n\n12.4.1 Percorsi Assoluti e Relativi\nUn percorso assoluto parte dalla directory principale del tuo computer (ad esempio, / su Linux/MacOS o C:/ su Windows) e indica in modo completo e univoco la posizione di un file o di una cartella. Un percorso relativo, invece, parte dalla directory corrente del progetto o dalla directory di lavoro impostata e descrive la posizione di un file in relazione a questa.\nAd esempio, il percorso assoluto del file utilizzato per generare questa pagina HTML potrebbe essere ottenuto cos√¨:\n\nfs::path_abs(\"05_environment.qmd\")\n#&gt; /Users/corrado/_repositories/psicometria-r/chapters/R/05_environment.qmd",
    "crumbs": [
      "R",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>L'ambiente di programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/07_environment.html#funzione-here",
    "href": "chapters/R/07_environment.html#funzione-here",
    "title": "12¬† L‚Äôambiente di programmazione",
    "section": "\n12.5 Funzione here()\n",
    "text": "12.5 Funzione here()\n\nSe il progetto si trova nella cartella psicometria-r, possiamo utilizzare la funzione here() del pacchetto here per indicare la posizione del file 05_environment.qmd in modo relativo. Ecco un esempio:\n\nfile.exists(here::here(\"chapters\", \"R\", \"07_environment.qmd\"))\n#&gt; [1] TRUE\n\nIn questo caso, il file 07_environment.qmd √® contenuto nella cartella chapters/R, che si trova all‚Äôinterno della directory principale del progetto. Grazie a here(), non √® necessario specificare manualmente la posizione del progetto: questa funzione identifica automaticamente la directory principale e consente di indicare solo il percorso relativo del file rispetto ad essa. In altre parole, puoi riferirti al file 07_environment.qmd semplicemente fornendo il percorso relativo all‚Äôinterno della struttura del progetto, lasciando a here() il compito di gestire il contesto globale.\n\n12.5.1 Perch√© preferire i percorsi relativi?\nL‚Äôutilizzo di percorsi relativi con here() offre numerosi vantaggi:\n\n\nPortabilit√†: Il codice diventa pi√π semplice da condividere, poich√© non dipende dalla struttura delle directory specifica del computer su cui √® stato scritto.\n\nOrganizzazione: Favorisce una struttura chiara e coerente all‚Äôinterno del progetto, rendendo pi√π facile individuare e accedere ai file.\n\nAffidabilit√†: Riduce il rischio di errori dovuti a percorsi assoluti errati, soprattutto quando il progetto viene spostato o condiviso.\n\n12.5.2 Buone pratiche\n\n\nUsare sempre percorsi relativi: Questo assicura che il progetto sia facilmente eseguibile su altri sistemi senza necessit√† di modifiche ai percorsi.\n\nImpostare una struttura coerente del progetto: Organizzare i file in cartelle ben definite (ad esempio, data, scripts, outputs) facilita l‚Äôuso di percorsi relativi.\n\nIn sintesi, specificare i percorsi relativi rispetto alla directory principale del progetto √® una buona pratica essenziale per garantire portabilit√†, organizzazione e riproducibilit√† del lavoro.\n\n12.5.3 Creare un progetto in R\nUn progetto R √® semplicemente una cartella con un file .Rproj. Puoi crearne uno con RStudio o con il pacchetto usethis.\nIn RStudio:\n\nVai su File &gt; New Project.\nSeleziona New Directory &gt; New Project.\nDai un nome al progetto e scegli la sua posizione.\n\nCon usethis:\nusethis::create_project(\"path/alla/cartella\")\nEsempio:\nusethis::create_project(\"/Users/corrado/_repositories/psicometria-r\")\nVedremo nel Capitolo 14 come organizzare i file all‚Äôinterno di un progetto.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>L'ambiente di programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/07_environment.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/R/07_environment.html#informazioni-sullambiente-di-sviluppo",
    "title": "12¬† L‚Äôambiente di programmazione",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.5.3     \n#&gt;  [9] scales_1.3.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.9.1   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         crayon_1.5.3      rlang_1.1.5      \n#&gt; [17] munsell_0.5.1     withr_3.0.2       tools_4.4.2       parallel_4.4.2   \n#&gt; [21] tzdb_0.5.0        colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5      \n#&gt; [25] R6_2.6.1          lifecycle_1.0.4   fs_1.6.5          htmlwidgets_1.6.4\n#&gt; [29] pkgconfig_2.0.3   pillar_1.10.1     gtable_0.3.6      glue_1.8.0       \n#&gt; [33] xfun_0.51         tidyselect_1.2.1  rstudioapi_0.17.1 farver_2.1.2     \n#&gt; [37] htmltools_0.5.8.1 nlme_3.1-167      rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "R",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>L'ambiente di programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/07_environment.html#bibliografia",
    "href": "chapters/R/07_environment.html#bibliografia",
    "title": "12¬† L‚Äôambiente di programmazione",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nYu, B., & Barter, R. L. (2024). Veridical data science: The practice of responsible data analysis and decision making. MIT Press.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>L'ambiente di programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/08_ai.html",
    "href": "chapters/R/08_ai.html",
    "title": "13¬† Utilizzo di strumenti AI",
    "section": "",
    "text": "13.1 Introduzione\nIl panorama della programmazione sta attraversando una trasformazione radicale, guidata dall‚Äôavvento degli strumenti di intelligenza artificiale (AI). Questi assistenti innovativi stanno rivoluzionando il modo in cui sviluppatori, ricercatori e studenti scrivono, comprendono e ottimizzano il codice. Grazie a una nuova generazione di strumenti che vanno oltre i tradizionali ambienti di sviluppo, l‚Äôintelligenza artificiale sta aprendo possibilit√† inedite. Piattaforme come ChatGPT, Google Gemini, Claude.ai, DeepSeek e Qwen sono in grado di generare codice, spiegare concetti complessi e fornire supporto agli sviluppatori in modi che, fino a poco tempo fa, erano impensabili.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Utilizzo di strumenti AI</span>"
    ]
  },
  {
    "objectID": "chapters/R/08_ai.html#potenzialit√†-e-sfide-dellai-nella-programmazione",
    "href": "chapters/R/08_ai.html#potenzialit√†-e-sfide-dellai-nella-programmazione",
    "title": "13¬† Utilizzo di strumenti AI",
    "section": "13.2 Potenzialit√† e Sfide dell‚ÄôAI nella Programmazione",
    "text": "13.2 Potenzialit√† e Sfide dell‚ÄôAI nella Programmazione\nGli strumenti di intelligenza artificiale (AI) stanno trasformando radicalmente il modo in cui si programma, inclusa l‚Äôelaborazione di codice in linguaggi come R. Tuttavia, accanto alle immense potenzialit√†, emergono anche sfide significative. I modelli di linguaggio di grandi dimensioni (LLM, Large Language Models) possono ottimizzare e accelerare i flussi di lavoro, ma non sono privi di limitazioni. Tra queste, la possibilit√† di generare codice impreciso, introdurre bias involontari o produrre output che richiedono una verifica approfondita da parte dell‚Äôutente.\nNonostante queste sfide, gli strumenti di AI offrono un supporto prezioso in diverse aree chiave:\n\nSupporto Concettuale:\nGli LLM si dimostrano particolarmente efficaci nel rispondere a domande complesse su metodi statistici, algoritmi e tecniche di analisi dei dati. La qualit√† delle risposte migliora notevolmente quando le domande sono formulate in modo chiaro, specifico e dettagliato.\nGenerazione e Completamento del Codice:\nQuesti strumenti possono aiutare gli sviluppatori a scrivere codice pi√π rapidamente, suggerendo completamenti automatici, identificando potenziali errori e persino generando interi script a partire da descrizioni testuali. Questo riduce il tempo dedicato alla scrittura manuale e permette di concentrarsi su aspetti pi√π creativi o complessi del progetto.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Utilizzo di strumenti AI</span>"
    ]
  },
  {
    "objectID": "chapters/R/08_ai.html#panoramica-comparativa-dei-principali-strumenti-ai",
    "href": "chapters/R/08_ai.html#panoramica-comparativa-dei-principali-strumenti-ai",
    "title": "13¬† Utilizzo di strumenti AI",
    "section": "13.3 Panoramica Comparativa dei Principali Strumenti AI",
    "text": "13.3 Panoramica Comparativa dei Principali Strumenti AI\nCome scegliere il modello linguistico pi√π adatto per un determinato compito? Nell‚Äôarticolo di Gibney (2025), ricercatori condividono i loro strumenti preferiti attualmente in uso, offrendo una guida pratica a chi ha bisogno di orientarsi tra le varie opzioni.\n\n13.3.1 o3-mini (il ragionatore)\nOpenAI ha lanciato o3-mini, un modello di ragionamento gratuito per gli utenti registrati, sviluppato in risposta alla crescente concorrenza di DeepSeek. Questo modello si distingue per l‚Äôutilizzo di un processo di ragionamento a catena (chain-of-thought reasoning), che gli permette di affrontare problemi complessi in ambito matematico e scientifico con precisione. Oltre a eccellere nell‚Äôanalisi tecnica e nella riformattazione dei dati, o3-mini √® particolarmente efficace nel scomporre concetti intricati in passaggi pi√π semplici. Tuttavia, nonostante le sue capacit√† avanzate, non √® ancora in grado di eguagliare il ragionamento umano in contesti che richiedono creativit√† o intuizione profonda.\n\n\n13.3.2 DeepSeek (il tuttofare)\nDeepSeek-R1 √® un modello open-weight paragonabile a o1 di OpenAI, ma disponibile a un costo inferiore attraverso API. La sua natura trasparente lo rende particolarmente attraente per i ricercatori, che possono adattarlo ai propri progetti specifici. DeepSeek √® utile per generare ipotesi, migliorare la diagnostica medica e supportare attivit√† di ricerca avanzate. Tuttavia, presenta alcuni limiti: il suo processo di ragionamento √® pi√π lento rispetto ad altri modelli e offre meno filtri contro output potenzialmente dannosi. Inoltre, OpenAI ha sollevato dubbi sulla legittimit√† del suo processo di addestramento, alimentando un dibattito sulla trasparenza e l‚Äôetica degli LLM.\n\n\n13.3.3 Llama (il cavallo di battaglia)\nSviluppato da Meta, Llama √® uno dei modelli LLM pi√π utilizzati nella ricerca grazie alla sua natura open-weight, che consente agli scienziati di personalizzarlo e impiegarlo in ambienti controllati. √à stato applicato con successo in una vasta gamma di ambiti, dalla predizione delle strutture cristalline ai calcoli quantistici, dimostrando una grande versatilit√†. Tuttavia, l‚Äôaccesso a Llama richiede un‚Äôautorizzazione specifica, rendendolo meno immediato rispetto ad altri modelli open-source emergenti che sono disponibili senza restrizioni.\n\n\n13.3.4 Claude (lo sviluppatore)\nClaude 3.5 Sonnet, prodotto da Anthropic, √® particolarmente apprezzato per la sua capacit√† di scrivere codice e interpretare dati visivi. Questo modello si distingue per la sua abilit√† nel mantenere il significato tecnico anche durante la semplificazione del linguaggio, rendendolo ideale per redigere proposte di ricerca, annotare codice e supportare attivit√† di sviluppo software. Tuttavia, l‚Äôaccesso completo alle sue funzionalit√† richiede un‚ÄôAPI a pagamento, il che lo rende meno competitivo rispetto ai modelli open-source in rapida crescita, soprattutto per utenti con budget limitati.\n\n\n13.3.5 OLMo (il veramente open)\nOLMo 2 rappresenta un passo avanti nella trasparenza degli LLM. Questo modello non solo fornisce i pesi del modello, ma anche i dati di addestramento e il codice di sviluppo, offrendo una visione completa del suo funzionamento. Questa apertura lo rende ideale per ricercatori e sviluppatori che desiderano analizzare bias, ottimizzare le prestazioni o comprendere a fondo il processo di creazione di un LLM. L‚Äôunico svantaggio √® che richiede competenze tecniche avanzate per l‚Äôimplementazione, sebbene il numero di risorse educative e tutorial disponibili stia crescendo rapidamente.\nOgni modello presenta punti di forza e limiti specifici, rendendoli adatti a contesti diversi. Mentre o3-mini e DeepSeek si concentrano su ragionamento e analisi tecnica, Llama e OLMo offrono maggiore flessibilit√† e trasparenza per la ricerca. Claude, d‚Äôaltra parte, si distingue per le sue capacit√† di sviluppo e interpretazione di dati complessi. La scelta del modello dipende dalle esigenze specifiche dell‚Äôutente, dal budget disponibile e dalle competenze tecniche.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Utilizzo di strumenti AI</span>"
    ]
  },
  {
    "objectID": "chapters/R/08_ai.html#considerazioni-etiche-e-pratiche",
    "href": "chapters/R/08_ai.html#considerazioni-etiche-e-pratiche",
    "title": "13¬† Utilizzo di strumenti AI",
    "section": "13.4 Considerazioni Etiche e Pratiche",
    "text": "13.4 Considerazioni Etiche e Pratiche\nL‚Äôadozione di strumenti di intelligenza artificiale (AI) solleva questioni etiche e pratiche che richiedono un‚Äôattenta riflessione e un approccio responsabile.\n\nTrasparenza\nI dataset utilizzati per addestrare i modelli di AI sono spesso poco documentati e opachi, rendendo difficile valutarne la qualit√† e l‚Äôequit√†. Questo solleva interrogativi sulla presenza di bias involontari e sulla rappresentativit√† dei dati, con notevoli implicazioni per l‚Äôaffidabilit√† dei risultati.\nEquit√† di Accesso\nNonostante le potenzialit√† rivoluzionarie degli strumenti di AI, l‚Äôaccesso a queste tecnologie non √® uniformemente distribuito. Disparit√† economiche, geografiche e infrastrutturali possono creare disuguaglianze, limitando l‚Äôadozione di queste risorse in contesti meno privilegiati e ampliando il divario digitale.\nResponsabilit√†\nUno dei dilemmi pi√π complessi riguarda l‚Äôattribuzione della responsabilit√† per i risultati generati dai sistemi di AI. In caso di errori, bias o conseguenze indesiderate, non √® sempre chiaro chi debba assumersi la responsabilit√†: gli sviluppatori del modello, gli utenti o le organizzazioni che lo implementano.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Utilizzo di strumenti AI</span>"
    ]
  },
  {
    "objectID": "chapters/R/08_ai.html#riflessioni-conclusive",
    "href": "chapters/R/08_ai.html#riflessioni-conclusive",
    "title": "13¬† Utilizzo di strumenti AI",
    "section": "13.5 Riflessioni Conclusive",
    "text": "13.5 Riflessioni Conclusive\nGli strumenti di intelligenza artificiale stanno rivoluzionando il mondo della programmazione, offrendo un supporto senza precedenti per la risoluzione di problemi complessi, la generazione di codice e l‚Äôottimizzazione dei flussi di lavoro. Tuttavia, il loro utilizzo deve essere accompagnato da un approccio critico e consapevole. √à essenziale verificare i risultati, valutare le implicazioni etiche e garantire che l‚Äôadozione di queste tecnologie avvenga in modo equo e responsabile.\nL‚Äôintelligenza artificiale non sostituir√† gli sviluppatori, ma si affermer√† come un alleato indispensabile, ampliando la creativit√† e le competenze umane. Questa collaborazione tra uomo e macchina ridefinir√† il modo in cui affrontiamo le sfide del futuro, aprendo nuove opportunit√† e trasformando il panorama della tecnologia e della ricerca (Bonnefon et al., 2024; Liu & Li, 2024).",
    "crumbs": [
      "R",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Utilizzo di strumenti AI</span>"
    ]
  },
  {
    "objectID": "chapters/R/08_ai.html#bibliografia",
    "href": "chapters/R/08_ai.html#bibliografia",
    "title": "13¬† Utilizzo di strumenti AI",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBonnefon, J.-F., Rahwan, I., & Shariff, A. (2024). The moral psychology of Artificial Intelligence. Annual Review of Psychology, 75(1), 653‚Äì675.\n\n\nGibney, E. (2025). What are the best AI tools for research? Nature‚Äôs guide. Nature, 578(7795), 123‚Äì125. https://doi.org/10.1038/d41586-025-00437-0\n\n\nLiu, J., & Li, S. (2024). Toward Artificial Intelligence-Human Paired Programming: A Review of the Educational Applications and Research on Artificial Intelligence Code-Generation Tools. Journal of Educational Computing Research, 07356331241240460.\n\n\nMesk√≥, B. (2023). Prompt engineering as an important emerging skill for medical professionals: tutorial. Journal of Medical Internet Research, 25, e50638.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Utilizzo di strumenti AI</span>"
    ]
  },
  {
    "objectID": "chapters/eda/introduction_eda.html",
    "href": "chapters/eda/introduction_eda.html",
    "title": "EDA",
    "section": "",
    "text": "Dopo aver acquisito un dataset, √® fondamentale comprendere a fondo le caratteristiche dei dati in esso contenuti. Sebbene le statistiche descrittive e altre misure numeriche siano spesso efficaci per ottenere una visione d‚Äôinsieme, talvolta √® un‚Äôimmagine a valere pi√π di mille parole.\nIn questa sezione della dispensa, esploreremo alcuni concetti chiave della statistica descrittiva. Oltre a fornire definizioni teoriche, presenteremo istruzioni pratiche in R per condurre analisi statistiche su dati reali. Il capitolo si concluder√† con una riflessione critica sui limiti di un approccio epistemologico basato esclusivamente sull‚Äôanalisi delle associazioni tra variabili, evidenziando l‚Äôimportanza di indagare le cause sottostanti ai fenomeni osservati.",
    "crumbs": [
      "EDA"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html",
    "href": "chapters/eda/01_project_structure.html",
    "title": "14¬† Le fasi del progetto di analisi dei dati",
    "section": "",
    "text": "14.1 Introduzione\nUna gestione accurata ed efficace dei dati √® fondamentale in molte discipline, inclusa la psicologia, dove l‚Äôanalisi di dataset complessi rappresenta un aspetto centrale della ricerca. Garantire che i dati siano raccolti con precisione, organizzati in modo chiaro e facilmente accessibili per analisi e verifiche √® essenziale per preservare l‚Äôintegrit√† del lavoro scientifico e promuoverne la riproducibilit√†. Una gestione rigorosa dei dati assicura qualit√† e affidabilit√† in tutte le fasi di un progetto, dalla raccolta alla documentazione dei processi di elaborazione e delle eventuali modifiche apportate.\nDati ben organizzati e documentati non solo semplificano e rendono pi√π efficiente il processo di analisi, ma riducono anche il rischio di errori, migliorando l‚Äôutilizzabilit√† e l‚Äôinterpretazione delle informazioni. Questo √® particolarmente rilevante quando si lavora con dataset provenienti da fonti eterogenee o con strutture complesse. Inoltre, la trasparenza e la completezza nella gestione dei dati rappresentano una condizione imprescindibile per garantire la riproducibilit√† della ricerca, un pilastro fondamentale della scienza. La possibilit√† per altri ricercatori di replicare i risultati utilizzando gli stessi dati e metodi rafforza la credibilit√† delle conclusioni e contribuisce a costruire un progresso scientifico condiviso e solido. Di conseguenza, una gestione dei dati responsabile non √® solo una buona pratica, ma una necessit√† per la produzione di conoscenze affidabili e sostenibili.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#introduzione",
    "href": "chapters/eda/01_project_structure.html#introduzione",
    "title": "14¬† Le fasi del progetto di analisi dei dati",
    "section": "",
    "text": "Domande Iniziali\n\n\n\n\n\nPrima di immergerti nella lettura di questo capitolo, prenditi un momento per riflettere sulle seguenti domande. Quali risposte daresti prima di leggere il materiale?\n\nPerch√© √® importante organizzare e documentare accuratamente i dati in un progetto di ricerca?\nQuali problemi possono emergere se si inizia a scrivere codice senza una pianificazione adeguata?\nQuali vantaggi offre R per la gestione dei dati rispetto ad altri strumenti?\nQuali strategie potrebbero migliorare la riproducibilit√† del tuo lavoro?\nCome struttureresti un progetto di analisi dati per mantenerlo chiaro e facilmente replicabile?\n\nOra, mentre leggi il capitolo, confronta le tue risposte con i concetti discussi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#pianificazione-del-workflow-in-r-strategie-per-progetti-sostenibili",
    "href": "chapters/eda/01_project_structure.html#pianificazione-del-workflow-in-r-strategie-per-progetti-sostenibili",
    "title": "14¬† Le fasi del progetto di analisi dei dati",
    "section": "\n14.2 Pianificazione del workflow in R: strategie per progetti sostenibili",
    "text": "14.2 Pianificazione del workflow in R: strategie per progetti sostenibili\n\n14.2.1 L‚Äôimportanza della pianificazione iniziale\nAffrontare un progetto di analisi dati senza una pianificazione √® come iniziare un esperimento psicologico senza ipotesi: si rischia di perdersi in tentativi disordinati. I programmatori esperti sanno che scrivere codice √® solo il 20% del lavoro (Gillespie & Lovelace, 2016). Il restante 80% consiste nel definire obiettivi, prevenire errori e organizzare il processo.\nBerkun (2005) sintetizza questo concetto con una massima: ‚ÄúUna preparazione intelligente minimizza il lavoro‚Äù. Approcci casuali, come scrivere codice senza strategia e correggere errori ‚Äúal volo‚Äù, non solo sono inefficienti, ma espongono al rischio di debito tecnico (Kruchten et al., 2012) ‚Äì l‚Äôaccumulo di soluzioni temporanee che complicano il progetto nel lungo termine.\n\nEsempio 14.1 Immaginate di dover analizzare dati di un esperimento sull‚Äôattenzione. Senza pianificazione, potreste:\n\nImportare i dati in modo disorganizzato, mischiando file RAW e modificati.\n\nUtilizzare funzioni non ottimali (es.: merge() invece di *_join() di dplyr), rallentando l‚Äôanalisi.\n\nDimenticare di documentare passaggi critici, rendendo impossibile replicare i risultati.\n\n\n\n14.2.2 Cinque pilastri per un workflow efficiente\nGillespie & Lovelace (2016) propone un framework basato su cinque principi, adattabili a progetti di psicologia:\n\n\nDisegnare prima di programmare\n\nUtilizzare strumenti analogici (carta, lavagna) o digitali (Miro, draw.io) per:\n\nMappare le variabili chiave dell‚Äôesperimento.\n\nSchematizzare il flusso di analisi (es.: ‚ÄúDati grezzi ‚Üí Pulizia ‚Üí Inferenza ‚Üí Grafici ‚Üí Report‚Äù).\n\n\n\n\nEsempio: Per uno studio longitudinale, tracciare una timeline delle fasi di raccolta dati e analisi.\n\n\n\nSuddividere il lavoro in ‚Äúchunk‚Äù\n\nFrammentare il progetto in task gestibili, usando il metodo SMART:\n\n\nSpecifico: ‚ÄúCreare un grafico a boxplot per il gruppo controllo vs sperimentale‚Äù.\n\n\nMisurabile: ‚ÄúIl grafico deve includere valori p e intervalli di confidenza‚Äù.\n\n\nAssegnabile: Delegare la pulizia dati a un collaboratore usando script condivisi.\n\n\nRealistico: Stimare 3 ore per l‚Äôanalisi preliminare, non un intero pomeriggio.\n\n\nTemporalizzato: ‚ÄúCompletare l‚Äôimportazione dati entro venerd√¨‚Äù.\n\n\n\n\n\nSelezionare i pacchetti con criterio\n\nInvestire tempo nella ricerca di strumenti ottimali prima di iniziare:\n\n\njanitor per pulire nomi di colonne (es.: clean_names()).\n\n\nreport per generare automaticamente testi statistici in APA style.\n\n\n\n\n\nDocumentazione continua\n\n\nIntegrare annotazioni direttamente nel codice:\n# Pulizia dati: rimuovere partecipanti con &gt;50% risposte mancanti (protocollo Smith et al., 2020)\ndati_puliti &lt;- dati_raw %&gt;% \n  filter(complete.cases(.) &gt;= 0.5)\n\nUtilizzare Quarto per creare report dinamici che uniscono codice, risultati e interpretazioni.\n\n\n\nRiproducibilit√† come priorit√†\n\n\nStrutturare il progetto in cartelle chiaramente organizzate. Per esempio:\n/progetto_psicologia  \n‚îú‚îÄ‚îÄ data/  \n‚îú‚îÄ‚îÄ script/  \n‚îú‚îÄ‚îÄ output/  \n‚îî‚îÄ‚îÄ report/\n\n\n\n\n14.2.3 Strumenti di pianificazione visiva in R\nPer progetti articolati, DiagrammeR consente di creare diagrammi di Gantt direttamente in R. Per esempio:\n\nlibrary(DiagrammeR)\n\nmermaid(\"\ngantt\n  title Progetto di analisi dei dati per Psicometria\n  section Raccolta Dati\n  Reclutamento partecipanti   :a1, 2025-03-15, 7d\n  Sessioni di raccolta dati   :a2, after a1, 14d\n  section Analisi\n  Pulizia dati                :a3, after a2, 3d\n  Analisi esplorativa         :a4, after a3, 5d\n  Inferenza frequentista      :a5, after a4, 7d\n  Inferenza bayesiana         :a6, after a5, 7d\n  section Report\n  Creazione report            :c7, after a6, 2d\n\")\n\n\n\n\n\n\n14.2.4 Gestire il debito tecnico\nAnche in piccoli progetti, √® cruciale adottare buone pratiche per mantenere il codice leggibile e gestibile nel tempo. Ecco alcune strategie utili:\n1. Refactoring periodico\n- Dedica del tempo ogni settimana (ad esempio 1 ora) per riorganizzare il codice.\n- Sostituisci soluzioni complesse o ridondanti con alternative pi√π efficienti e leggibili (es.: semplificare cicli for con funzioni come map() in R).\n- Rimuovi codice non utilizzato o obsoleto.\n2. Commenti chiari e utili\n- Scrivi commenti esplicativi sopra ogni blocco di codice complesso per renderlo comprensibile anche a chi non ha scritto il progetto.\nEsempio:\n# Normalizza i dati usando la tecnica Min-Max scaling\nnormalized_data &lt;- (data - min(data)) / (max(data) - min(data))\n\nEvita commenti ovvi (es.: # Importa tidyverse quando scrivi library(tidyverse)).\n\nAggiorna i commenti se modifichi il codice, per mantenerli coerenti con le modifiche.\n\n3. Strutturare il progetto\nOrganizza il tuo progetto in cartelle e file ben definiti.\n4. Checklist pre-consegna del progetto\nPrima di consegnare o condividere il progetto, verifica:\n\nLa presenza di commenti utili nei punti critici del codice.\n\nChe i dati originali siano conservati intatti nella cartella dedicata (dati_raw/).\n\nChe l‚Äôambiente di lavoro sia documentato (es.: salva l‚Äôoutput di sessionInfo() in R).\n\n5. Migliorare la leggibilit√† del codice\n\nUsa nomi di variabili descrittivi (es.: media_punteggi invece di x).\n\nMantieni una struttura coerente per indentazione e spaziatura.\n\nDividi il codice in funzioni modulari per evitare script troppo lunghi e difficili da seguire.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#capacit√†-di-gestione-dei-dati-in-r",
    "href": "chapters/eda/01_project_structure.html#capacit√†-di-gestione-dei-dati-in-r",
    "title": "14¬† Le fasi del progetto di analisi dei dati",
    "section": "\n14.3 Capacit√† di Gestione dei Dati in R",
    "text": "14.3 Capacit√† di Gestione dei Dati in R\nUna volta compresi i benefici di una pianificazione strategica, √® importante disporre di strumenti adeguati per gestire, analizzare e documentare i dati. In questo capitolo ci concentreremo sul ruolo di R in un workflow efficiente di analisi dei dati. R √® uno strumento potente e versatile, pensato per supportare tutte le fasi del ciclo di vita dei dati, dalla raccolta alla documentazione, risultando cos√¨ un alleato indispensabile per chiunque lavori con dataset complessi. Le sue principali funzionalit√† includono:\n\n\nImportazione ed esportazione dei dati: Pacchetti come readr e rio semplificano l‚Äôimportazione di dati da fonti diverse (file CSV, database, API web) e l‚Äôesportazione in formati adatti a svariati utilizzi.\n\n\nPulizia e preparazione dei dati: Grazie a pacchetti come dplyr, tidyr e stringr, R offre strumenti intuitivi per manipolare, trasformare e preparare i dati in modo efficiente, rendendoli pronti per l‚Äôanalisi.\n\n\nEsplorazione e sintesi: Con pacchetti come dplyr e ggplot2, R permette di calcolare statistiche descrittive, individuare pattern significativi e visualizzare distribuzioni e relazioni in modo chiaro e informativo.\n\n\nDocumentazione dinamica: Strumenti come R Markdown e Quarto consentono di integrare in un unico documento codice, analisi, testo esplicativo e risultati, facilitando la riproducibilit√† e la trasparenza del lavoro.\n\n\nControllo delle versioni: L‚Äôintegrazione di Git in RStudio offre un sistema di gestione delle versioni che consente di monitorare modifiche, collaborare con altri e garantire la tracciabilit√† del processo analitico.\n\nLa combinazione di pianificazione strategica e strumenti avanzati come R rappresenta un approccio vincente per affrontare progetti complessi. Le funzionalit√† di R, se utilizzate in modo appropriato, riducono al minimo il rischio di errori e massimizzano l‚Äôefficienza e l‚Äôaffidabilit√† dei risultati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#configurare-lambiente-r",
    "href": "chapters/eda/01_project_structure.html#configurare-lambiente-r",
    "title": "14¬† Le fasi del progetto di analisi dei dati",
    "section": "\n14.4 Configurare l‚ÄôAmbiente R",
    "text": "14.4 Configurare l‚ÄôAmbiente R\nPer sfruttare al meglio le potenzialit√† di R √® essenziale configurare correttamente RStudio e integrare i pacchetti fondamentali per la gestione dei dati. Una configurazione adeguata favorisce la riproducibilit√† e l‚Äôorganizzazione del lavoro.\n\n14.4.1 Workspace e Cronologia\nAccedi a Tools &gt; Global Options &gt; General e modifica le seguenti impostazioni:\n\nDisabilita l‚Äôopzione Restore .RData into workspace at startup.\n\nImposta Save workspace to .RData on exit su Never.\n\nQueste scelte incoraggiano una gestione basata sugli script, rendendo il lavoro pi√π trasparente e riducendo possibili conflitti tra sessioni diverse. Ogni analisi sar√† cos√¨ chiaramente documentata nel codice, evitando dipendenze da file temporanei o precedenti sessioni di lavoro.\n\n14.4.2 Pacchetti Essenziali\nR √® composto da un modulo base che fornisce le funzionalit√† fondamentali del linguaggio, ma il suo potere deriva dall‚Äôampio ecosistema di pacchetti. Per questo corso (e in generale per un workflow efficiente), utilizzeremo regolarmente i seguenti pacchetti:\n\n\nhere: per la gestione ordinata dei percorsi relativi, evitando problemi con i percorsi assoluti.\n\n\ntidyverse: una raccolta di pacchetti (tra cui dplyr, tidyr, ggplot2) essenziali per la manipolazione, l‚Äôanalisi e la visualizzazione dei dati.\n\nAssicurati di installarli e caricarli all‚Äôinizio di ogni script con i comandi:\n# install.packages(c(\"here\", \"tidyverse\"))\n# installali solo la prima volta\nlibrary(here)\nlibrary(tidyverse)\n\n14.4.3 Gestione dei Progetti\nI progetti in RStudio rappresentano uno strumento chiave per mantenere il lavoro ben organizzato. Sfruttare i progetti consente di creare ambienti separati, in cui ogni progetto ha la propria directory dedicata.\nPer creare un nuovo progetto:\n\nVai su File &gt; New Project.\n\nSeleziona la directory dove verr√† creato il tuo progetto.\n\nSalva tutti i file correlati (script, dati, risultati) all‚Äôinterno di questa directory.\n\nQuesto approccio previene confusione e facilita la navigazione, in quanto ogni progetto diventa un‚Äôunit√† autonoma, ideale per mantenere ordine e coerenza nel lavoro.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#il-ciclo-di-vita-di-un-progetto-di-data-science",
    "href": "chapters/eda/01_project_structure.html#il-ciclo-di-vita-di-un-progetto-di-data-science",
    "title": "14¬† Le fasi del progetto di analisi dei dati",
    "section": "\n14.5 Il Ciclo di Vita di un Progetto di Data Science",
    "text": "14.5 Il Ciclo di Vita di un Progetto di Data Science\nUna volta configurato un ambiente stabile, organizzato e pronto per l‚Äôanalisi, √® possibile affrontare in modo sistematico le diverse fasi che caratterizzano tipicamente un progetto di Data Science. Secondo la proposta di (Yu & Barter, 2024), queste fasi sono:\n\n\nFormulazione del problema e raccolta dei dati: Definizione delle domande di ricerca e acquisizione dei dataset.\n\n\nPulizia, preprocessing e analisi esplorativa: Preparazione dei dati per l‚Äôanalisi attraverso trasformazioni e sintesi.\n\n\nAnalisi predittiva e/o inferenziale (opzionale): Modelli statistici o predittivi per rispondere alle domande di ricerca.\n\n\nValutazione dei risultati: Interpretazione e verifica delle conclusioni tratte.\n\n\nComunicazione dei risultati: Presentazione dei risultati in forma visiva e narrativa.\n\nNon tutti i progetti prevedono la fase di analisi predittiva, ma quasi tutti attraversano le altre fasi. Mantenere un approccio organizzato e ben strutturato lungo tutto il ciclo di vita riduce il rischio di errori e favorisce la riproducibilit√†.\n\n14.5.1 Fase 1: Formulazione del Problema e Raccolta dei Dati\nLa definizione di una domanda di ricerca chiara e precisa rappresenta la base di qualunque progetto di data science. √à cruciale stabilire con attenzione l‚Äôambito dell‚Äôanalisi:\n\nAmbito Applicativo\nIn un contesto applicativo, l‚Äôobiettivo principale √® spesso la realizzazione di un report descrittivo su un intervento o un‚Äôattivit√† specifica (ad esempio, valutare l‚Äôefficacia di un programma di educazione sessuale rivolto agli adolescenti). In questo caso, l‚Äôattenzione si focalizza sulla descrizione dei risultati ottenuti, senza necessariamente approfondire i fondamenti teorici.\nAmbito della Ricerca Psicologica\nIn un contesto di ricerca, invece, diventa essenziale giustificare le scelte metodologiche, la selezione degli strumenti di misura e la formulazione delle domande di ricerca sulla base della letteratura esistente e di teorie consolidate. (Questo √® oggetto di approfondimento nel Capitolo 3.)\n\n\n14.5.1.1 Caratteristiche di una Buona Domanda di Ricerca\nLa domanda di ricerca deve essere formulata in modo che sia possibile rispondervi analizzando i dati a disposizione. Talvolta, la domanda iniziale pu√≤ risultare troppo ampia o irrealistica rispetto ai dati disponibili, rendendo necessario un processo di revisione. L‚Äôobiettivo √® assicurare che i dati raccolti (o da raccogliere) siano appropriati e sufficienti a fornire una risposta solida al quesito di partenza.\n\n14.5.1.2 Raccolta dei Dati\nIn questa fase, √® altrettanto cruciale identificare chiaramente i dati da utilizzare e comprenderne la provenienza. Esistono principalmente due scenari:\n\nUtilizzo di Dati Esistenti\nAlcuni progetti si basano su dataset gi√† disponibili, reperiti da repository pubblici, database aziendali o esperimenti precedenti.\nNuova Raccolta di Dati\nAltri progetti richiedono la raccolta di dati ex novo. In entrambi i casi, √® importante pianificare con cura le analisi prima di avviare la raccolta, onde evitare di ritrovarsi con dataset incompleti o non adatti agli obiettivi.\n\n√à inoltre essenziale documentare accuratamente le tecniche e procedure utilizzate per la raccolta dati, nonch√© valutare e dichiarare eventuali limitazioni che possano inficiare l‚Äôinterpretazione dei risultati.\n\n14.5.2 Fase 2: Pulizia dei Dati e Analisi Esplorativa\n\n14.5.2.1 Importazione ed Esportazione dei Dati in R\nUna volta individuati i dati, occorre importarli in R in un formato adatto all‚Äôanalisi, tipicamente in un data frame. Il pacchetto rio fornisce la funzione universale import(), che rende superfluo l‚Äôuso di funzioni specifiche per ciascun formato (es. .csv, .xlsx, .json, ecc.). Per organizzare al meglio i file, si consiglia di creare una struttura di cartelle chiara (es. data/raw per i dati grezzi e data/processed per i dati elaborati) e di usare percorsi relativi attraverso il pacchetto here.\nEsempio di importazione:\nlibrary(here)\nlibrary(rio)\n\ndf &lt;- import(here(\"data\", \"raw\", \"my_data.csv\"))\nPer esportare i dati elaborati:\nexport(df, here(\"data\", \"processed\", \"my_data_processed.csv\"))\nQuesta strategia migliora la portabilit√† (il progetto pu√≤ essere facilmente trasferito su altri computer) e la riproducibilit√† (poich√© non √® necessario modificare manualmente i percorsi dei file).\n\n14.5.2.2 Pulizia dei Dati\nDopo avere definito la domanda di ricerca e recuperato i dati, il passo successivo √® la pulizia. Un dataset ‚Äúpulito‚Äù √® ordinato, coerente e privo di ambiguit√†, cos√¨ che sia comprensibile sia per il computer sia per l‚Äôanalista. La pulizia dei dati implica l‚Äôindividuazione di valori anomali, formattazioni errate, duplicati, incongruenze e valori mancanti, per poi sistemarli in modo appropriato (con codice, senza alterare i file dei dati grezzi originali).\nLa pulizia dei dati √® una fase cruciale: aiuta a sviluppare una comprensione pi√π approfondita del dataset e delle sue eventuali limitazioni. L‚Äôobiettivo √® creare una versione dei dati che rifletta il pi√π fedelmente possibile la realt√† e che sia interpretata correttamente dal computer.\n\n14.5.2.3 Preprocessing\nIl preprocessing consiste nell‚Äôeffettuare quelle trasformazioni sui dati puliti che sono richieste da specifici algoritmi di analisi o di modellazione. Ad esempio, alcuni modelli possono richiedere variabili su scale comparabili oppure l‚Äôassenza di valori mancanti. Durante il preprocessing, si possono anche generare nuove variabili ritenute utili all‚Äôanalisi.\nNon esiste una procedura di preprocessing ‚Äúuniversale‚Äù: ogni scelta va documentata e motivata, poich√© implica decisioni soggettive che influiscono sull‚Äôinterpretazione finale dei risultati.\n\n14.5.2.4 Analisi Esplorativa dei Dati\nDopo l‚Äôimportazione, la pulizia e il preprocessing, √® il momento di esplorare il dataset. L‚ÄôAnalisi Esplorativa dei Dati (Exploratory Data Analysis, EDA) comprende:\n\nCalcolo di statistiche descrittive (misure di tendenza centrale, dispersione, etc.)\n\nIdentificazione di pattern e distribuzioni insolite\n\nCreazione di tabelle di contingenza e diagrammi (istogrammi, boxplot, scatterplot, ecc.)\n\nL‚Äôobiettivo principale √® far familiarizzare il ricercatore con la struttura dei dati e fornire ipotesi da verificare nelle fasi successive.\n\n14.5.3 Fase 3: Analisi Predittiva e Inferenziale\nA seconda degli obiettivi del progetto, l‚Äôanalisi pu√≤ includere modelli statistici o algoritmi di machine learning orientati all‚Äôinferenza e/o alla previsione. In psicologia, ci√≤ pu√≤ tradursi nell‚Äôuso di modelli di regressione, test statistici, modelli misti o metodi di classificazione e clustering. L‚Äôobiettivo √® rispondere a domande di ricerca specifiche o fare inferenze su una popolazione pi√π ampia. Nei contesti applicativi, pu√≤ riguardare la costruzione di modelli predittivi per stimare il comportamento di variabili di interesse sulla base dei dati storici.\n\n14.5.4 Fase 4: Valutazione dei Risultati\nIn questa fase si valuta la bont√† dei risultati ottenuti, sia dal punto di vista quantitativo (applicando metriche appropriate o test statistici) sia qualitativo (interpretazione teorica o pratica dei risultati). √à il momento di ricollegarsi alla domanda di ricerca iniziale, per verificare se gli obiettivi sono stati raggiunti e quali implicazioni emergono.\n\n14.5.5 Fase 5: Comunicazione dei Risultati\nL‚Äôultima fase consiste nella comunicazione dei risultati a un pubblico pi√π ampio, che pu√≤ essere composto da ricercatori, committenti, stakeholder o utenti finali. √à essenziale presentare i risultati in maniera chiara e accessibile, evitando di dare per scontata una profonda conoscenza del progetto o del gergo tecnico. Si pu√≤ optare per:\n\n\nArticoli scientifici: per condividere le scoperte con la comunit√† accademica.\n\n\nReport interni: per informare un team di lavoro o un ente finanziatore.\n\n\nPresentazioni: per trasmettere rapidamente i risultati a un pubblico non specialistico.\n\nUna comunicazione efficace richiede di spiegare in modo comprensibile le analisi e le figure mostrate, fornendo una guida interpretativa. L‚Äôuso di grafici e diagrammi ben curati pu√≤ facilitare molto la fruizione delle informazioni.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#organizzazione-del-progetto",
    "href": "chapters/eda/01_project_structure.html#organizzazione-del-progetto",
    "title": "14¬† Le fasi del progetto di analisi dei dati",
    "section": "\n14.6 Organizzazione del Progetto",
    "text": "14.6 Organizzazione del Progetto\nUn aspetto fondamentale per il successo e la riproducibilit√† di un progetto di analisi dati √® l‚Äôorganizzazione efficiente dei file, che include dati, codice e documentazione. Questi file dovrebbero essere riuniti all‚Äôinterno di una singola cartella (o directory) dedicata al progetto.\n\n14.6.1 Home Directory\nIn RStudio, √® possibile creare un file nome_del_progetto.Rproj, che definisce la cartella principale (home directory) da cui R avvia il lavoro. Basta aprire RStudio cliccando su questo file per lavorare automaticamente all‚Äôinterno dell‚Äôambiente del progetto, rendendo pi√π agevole l‚Äôuso di percorsi relativi e la gestione di script, dati e output.\n\n14.6.2 Struttura di un Progetto\nYu & Barter (2024) propone un template per organizzare in modo chiaro un progetto di analisi dati:\nnome_progetto/\n‚îú‚îÄ‚îÄ nome_progetto.Rproj\n‚îú‚îÄ‚îÄ data/\n‚îÇ   ‚îú‚îÄ‚îÄ raw/\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ my_data.csv\n‚îÇ   ‚îú‚îÄ‚îÄ processed/\n‚îú‚îÄ‚îÄ dslc_documentation/\n‚îÇ   ‚îú‚îÄ‚îÄ 01_data_cleaning.qmd\n‚îÇ   ‚îú‚îÄ‚îÄ 02_analysis.qmd\n‚îÇ   ‚îî‚îÄ‚îÄ functions/\n‚îî‚îÄ‚îÄ README.md\n\n\ndata/:\n\n\nraw/: contiene i dati grezzi, mai modificati;\n\n\nprocessed/: ospita i dati puliti ed elaborati, pronti per l‚Äôanalisi;\n\nImportante inserire un codebook per documentare il significato delle variabili e le unit√† di misura.\n\n\n\ndslc_documentation/:\n\nContiene i file necessari per l‚Äôanalisi (in Quarto .qmd, Jupyter Notebook .ipynb, o altro).\n\nPu√≤ includere una sottocartella functions/ con script .R o .py contenenti funzioni personalizzate.\n\n\n\nREADME.md:\n\nDescrive la struttura del progetto, gli obiettivi e i passaggi per replicare le analisi.\n\n\n\n\n14.6.2.1 Vantaggi di questa struttura\n\n\nOrganizzazione Chiara: separare i dati grezzi da quelli elaborati riduce la confusione e il rischio di modifiche involontarie ai dati originali.\n\n\nRiproducibilit√†: la presenza di documentazione completa (codebook, file di analisi, README) consente di comprendere e replicare i risultati anche a distanza di tempo o da parte di terzi.\n\n\nPortabilit√†: lavorando con percorsi relativi (es. grazie al pacchetto here in R), l‚Äôintero progetto pu√≤ essere trasferito da un computer all‚Äôaltro senza bisogno di modificare il codice.\n\n\nEfficienza: la sottocartella functions/ permette di riutilizzare codice e funzioni personalizzate, evitando duplicazioni negli script principali.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#riflessioni-conclusive",
    "href": "chapters/eda/01_project_structure.html#riflessioni-conclusive",
    "title": "14¬† Le fasi del progetto di analisi dei dati",
    "section": "\n14.7 Riflessioni Conclusive",
    "text": "14.7 Riflessioni Conclusive\nLa forza e la bellezza del codice risiedono nella sua riusabilit√†: una volta scritto, pu√≤ essere eseguito infinite volte per ottenere risultati coerenti. Se l‚Äôambiente di lavoro √® configurato correttamente, lo stesso codice applicato agli stessi dati fornir√† sempre gli stessi output. Questo principio, chiamato riproducibilit√† computazionale, √® essenziale per garantire trasparenza e affidabilit√† nel lavoro scientifico.\nLa riproducibilit√† offre numerosi benefici:\n\nMonitorare le modifiche del progetto\nLa capacit√† di riprodurre il lavoro facilita il monitoraggio dell‚Äôevoluzione del progetto e delle scelte implementative nel tempo.\nRiprodurre il proprio lavoro\nIl primo vero vantaggio della riproducibilit√† √® per chi ha sviluppato il codice: tornare a distanza di mesi (o anni) su un progetto e ritrovare un flusso di lavoro chiaro e replicabile agevola enormemente la revisione o l‚Äôestensione delle analisi.\nCondivisione e crescita collettiva\nMettere a disposizione il proprio lavoro in forma riproducibile consente ad altri ricercatori di validare e ampliare i risultati, stimolando un progresso scientifico collettivo e robusto.\n\nRendere il proprio lavoro riproducibile richiede attenzione alla documentazione, un‚Äôorganizzazione solida del progetto e l‚Äôuso di strumenti adeguati per garantire la stabilit√† dell‚Äôambiente. I metodi e le tecniche esplorate in questo capitolo ‚Äì dalla pianificazione strategica alla pulizia dei dati, dalla struttura delle cartelle al controllo di versione ‚Äì sono tutti tasselli fondamentali per realizzare analisi rigorose, verificabili e di valore duraturo.\nIn sintesi, un progetto di Data Science di successo richiede sia un‚Äôaccurata pianificazione strategica ‚Äì per evitare debiti tecnici e massimizzare l‚Äôefficacia del proprio lavoro ‚Äì sia l‚Äôuso di strumenti adeguati, come R e i relativi pacchetti, in un ambiente ben configurato. Seguire un ciclo di vita del progetto ben definito e mantenere un‚Äôorganizzazione logica di dati, codice e documentazione consente di promuovere l‚Äôefficienza, ridurre i rischi di errore e favorire la riproducibilit√†, un valore fondante della scienza moderna.\n\n\n\n\n\n\nUn problema cruciale nella psicologia contemporanea √® la crisi di replicabilit√†, che evidenzia come molti risultati di ricerca non siano replicabili (Collaboration, 2015). La riproducibilit√† computazionale, pur avendo un obiettivo pi√π ristretto, si concentra sulla possibilit√† di ottenere gli stessi risultati applicando lo stesso codice agli stessi dati. Questo approccio, sebbene non risolva interamente la crisi, rappresenta un passo fondamentale verso una scienza pi√π trasparente e rigorosa.\n\n\n\n\n\n\n\n\n\nRisposte alle Domande Iniziali\n\n\n\n\n\nOra che hai completato il capitolo, confrontiamo le risposte alle domande iniziali con quanto appreso:\n\n\nPerch√© √® importante organizzare e documentare accuratamente i dati in un progetto di ricerca?\n\nUna gestione strutturata dei dati riduce il rischio di errori, facilita l‚Äôanalisi e migliora la riproducibilit√†, rendendo il lavoro scientifico pi√π affidabile e trasparente.\n\n\n\nQuali problemi possono emergere se si inizia a scrivere codice senza una pianificazione adeguata?\n\nSenza una pianificazione strategica si rischia di incorrere nel ‚Äúdebito tecnico‚Äù, accumulando codice disordinato che richiede correzioni costose in termini di tempo e risorse. Inoltre, si potrebbero fare scelte subottimali che compromettono la scalabilit√† e manutenibilit√† del progetto.\n\n\n\nQuali vantaggi offre R per la gestione dei dati rispetto ad altri strumenti?\n\nR fornisce strumenti avanzati per importazione, pulizia, analisi e visualizzazione dei dati, oltre a supportare la documentazione dinamica e il controllo delle versioni con Git. La sua ampia comunit√† e la disponibilit√† di pacchetti specializzati lo rendono particolarmente adatto per l‚Äôanalisi statistica e la ricerca.\n\n\n\nQuali strategie potrebbero migliorare la riproducibilit√† del tuo lavoro?\n\nUtilizzare strumenti come Quarto per documentare il codice e le analisi, adottare percorsi relativi con il pacchetto here, strutturare i dati in cartelle ben organizzate e integrare il controllo delle versioni con Git.\n\n\n\nCome struttureresti un progetto di analisi dati per mantenerlo chiaro e facilmente replicabile?\n\n\nAdottando una struttura chiara, ad esempio:\nnome_progetto/\n‚îú‚îÄ‚îÄ nome_progetto.Rproj\n‚îú‚îÄ‚îÄ data/\n‚îÇ   ‚îú‚îÄ‚îÄ raw/\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ my_data.csv\n‚îÇ   ‚îú‚îÄ‚îÄ processed/\n‚îú‚îÄ‚îÄ dslc_documentation/\n‚îÇ   ‚îú‚îÄ‚îÄ 01_data_cleaning.qmd\n‚îÇ   ‚îú‚îÄ‚îÄ 02_analysis.qmd\n‚îÇ   ‚îî‚îÄ‚îÄ functions/\n‚îî‚îÄ‚îÄ README.md\n\nQuesta organizzazione separa i dati grezzi da quelli elaborati, include documentazione chiara e facilita la riproducibilit√†.\n\n\n\n\n\nConclusione: Riflettere in anticipo sui problemi e sulle strategie di gestione dei dati aiuta a costruire workflow pi√π efficienti e affidabili. Se le tue risposte iniziali differivano da queste, quali nuovi spunti hai appreso da questo capitolo?",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#esercizi",
    "href": "chapters/eda/01_project_structure.html#esercizi",
    "title": "14¬† Le fasi del progetto di analisi dei dati",
    "section": "\n14.8 Esercizi",
    "text": "14.8 Esercizi\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nL‚Äôobiettivo di questo esercizio √® comprendere il ciclo di vita di un progetto di analisi dei dati, l‚Äôorganizzazione del progetto e la gestione della riproducibilit√†.\n\n\nGestione del progetto di analisi\n\nQuali sono le fasi principali di un progetto di analisi dei dati secondo Yu (2024)?\nSpiega il ruolo della fase di formulazione del problema e raccolta dei dati.\n\n\n\nOrganizzazione del workspace in R\n\nQuali impostazioni devono essere modificate in RStudio per favorire la riproducibilit√†?\nPerch√© √® importante usare percorsi relativi nei progetti in RStudio?\nDescrivi il ruolo del pacchetto here nella gestione dei percorsi dei file.\n\n\n\nStruttura dei progetti in R\n\nQuali sono i vantaggi dell‚Äôutilizzo dei progetti in RStudio?\nQuali sono le cartelle principali in una struttura organizzata di un progetto?\nPerch√© √® utile separare i dati grezzi dai dati processati?\n\n\n\nImportazione ed esportazione dei dati\n\nQuali pacchetti di R possono essere utilizzati per importare ed esportare dati?\n\nScrivi un esempio di codice per importare un file CSV usando rio e il pacchetto here.\n\nCome puoi esportare un dataset modificato in una cartella dedicata ai dati processati?\n\n\n\nPulizia e preprocessing dei dati\n\nQual √® la differenza tra pulizia e preprocessing dei dati?\n\nQuali strumenti di dplyr sono comunemente usati per pulire e trasformare i dati?\n\n\n\nAnalisi esplorativa dei dati (EDA)\n\nQuali sono alcuni strumenti utilizzati in R per effettuare un‚Äôanalisi esplorativa dei dati?\n\nScrivi un breve esempio di codice in R per calcolare statistiche descrittive di base su un dataset.\n\n\n\nRiproducibilit√† e comunicazione dei risultati\n\nPerch√© la riproducibilit√† √® un elemento chiave nella scienza dei dati?\n\nQuali strumenti offre Quarto per la documentazione e la condivisione dei risultati di un‚Äôanalisi?\n\n\n\n\n\n\n\n\n\n\n\n\nSoluzione\n\n\n\n\n\n1. Gestione del progetto di analisi\n\n\nFasi principali del progetto di analisi dei dati (Yu, 2024):\n\nFormulazione del problema e raccolta dei dati\n\nPulizia, preprocessing e analisi esplorativa\n\nAnalisi predittiva e/o inferenziale (se applicabile)\n\nValutazione dei risultati\n\nComunicazione dei risultati\n\n\n\nRuolo della fase di formulazione del problema:\nAiuta a definire gli obiettivi dell‚Äôanalisi e a selezionare le fonti di dati adeguate. Una domanda di ricerca ben definita garantisce che i dati siano pertinenti e che le analisi siano mirate.\n\n2. Organizzazione del workspace in R\n\n\nImpostazioni da modificare in RStudio:\n\nDisabilitare Restore .RData into workspace at startup\n\nImpostare Save workspace to .RData on exit su ‚ÄúNever‚Äù\n\n\nImportanza dei percorsi relativi:\nPermettono di rendere il progetto portabile e riproducibile, evitando problemi di percorsi assoluti specifici per un computer.\nRuolo del pacchetto here\nAiuta a gestire i percorsi relativi all‚Äôinterno del progetto senza dover specificare percorsi assoluti.\n\n3. Struttura dei progetti in R\n\nVantaggi dell‚Äôuso dei progetti in RStudio:\nMantengono ambienti separati, organizzano i file e facilitano la riproducibilit√†.\n\nCartelle principali in una struttura organizzata:\n\n\ndata/raw/ ‚Üí Dati grezzi\n\n\ndata/processed/ ‚Üí Dati elaborati\n\n\ndslc_documentation/ ‚Üí Documentazione e script\n\n\nfunctions/ ‚Üí Funzioni personalizzate\n\n\nSeparare dati grezzi da dati processati:\nEvita di modificare accidentalmente i dati originali, garantendo riproducibilit√†.\n\n4. Importazione ed esportazione dei dati\n\n\nPacchetti per importazione/esportazione:\n\n\nrio: unifica funzioni di import/export\n\n\nreadr: specifico per CSV e altri formati di testo\n\n\nhere: gestisce percorsi relativi\n\n\n\nEsempio di codice per importare dati CSV:\nlibrary(here)\nlibrary(rio)\ndf &lt;- rio::import(here(\"data\", \"raw\", \"my_data.csv\"))\n\n\nEsportare dati modificati:\nrio::export(df, here(\"data\", \"processed\", \"my_data_processed.csv\"))\n\n\n5. Pulizia e preprocessing dei dati\n\n\nDifferenza tra pulizia e preprocessing:\n\nPulizia: rimozione di errori, gestione dei dati mancanti, formattazione\n\nPreprocessing: trasformazione dei dati per adattarli a modelli specifici\n\n\n\nStrumenti di dplyr per pulizia e trasformazione:\n\n\nmutate(), filter(), select(), rename(), relocate()\n\n\n\n\n6. Analisi esplorativa dei dati (EDA)\n\n\nStrumenti comuni:\n\n\nsummary(), str(), glimpse(), ggplot2 per visualizzazione\n\n\n\nEsempio di codice per statistiche descrittive:\nsummary(df)\n\n\n7. Riproducibilit√† e comunicazione dei risultati\n\n\nImportanza della riproducibilit√†:\n\nFacilita la verifica e il miglioramento degli studi\n\nPreviene errori accidentali\n\nConsente a terzi di replicare e costruire su ricerche precedenti\n\n\n\nStrumenti di Quarto:\n\nPermette di combinare testo, codice e output in documenti riproducibili\n\nSupporta citazioni automatiche e gestione delle bibliografie",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/01_project_structure.html#informazioni-sullambiente-di-sviluppo",
    "title": "14¬† Le fasi del progetto di analisi dei dati",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] DiagrammeR_1.0.11 thematic_0.1.6    MetBrewer_0.2.0   ggokabeito_0.1.0 \n#&gt;  [5] see_0.11.0        gridExtra_2.3     patchwork_1.3.0   bayesplot_1.11.1 \n#&gt;  [9] psych_2.5.3       scales_1.3.0      markdown_2.0      knitr_1.50       \n#&gt; [13] lubridate_1.9.4   forcats_1.0.0     stringr_1.5.1     dplyr_1.1.4      \n#&gt; [17] purrr_1.0.4       readr_2.1.5       tidyr_1.3.1       tibble_3.2.1     \n#&gt; [21] ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3     stringi_1.8.4      lattice_0.22-6    \n#&gt;  [4] hms_1.1.3          digest_0.6.37      magrittr_2.0.3    \n#&gt;  [7] RColorBrewer_1.1-3 evaluate_1.0.3     grid_4.4.2        \n#&gt; [10] timechange_0.3.0   fastmap_1.2.0      rprojroot_2.0.4   \n#&gt; [13] jsonlite_1.9.1     mnormt_2.1.1       cli_3.6.4         \n#&gt; [16] rlang_1.1.5        visNetwork_2.1.2   munsell_0.5.1     \n#&gt; [19] yaml_2.3.10        withr_3.0.2        tools_4.4.2       \n#&gt; [22] parallel_4.4.2     tzdb_0.5.0         colorspace_2.1-1  \n#&gt; [25] pacman_0.5.1       vctrs_0.6.5        R6_2.6.1          \n#&gt; [28] lifecycle_1.0.4    htmlwidgets_1.6.4  pkgconfig_2.0.3   \n#&gt; [31] pillar_1.10.1      gtable_0.3.6       glue_1.8.0        \n#&gt; [34] xfun_0.51          tidyselect_1.2.1   rstudioapi_0.17.1 \n#&gt; [37] farver_2.1.2       htmltools_0.5.8.1  nlme_3.1-167      \n#&gt; [40] rmarkdown_2.29     compiler_4.4.2",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#bibliografia",
    "href": "chapters/eda/01_project_structure.html#bibliografia",
    "title": "14¬† Le fasi del progetto di analisi dei dati",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBerkun, S. (2005). The art of project management. O‚Äôreilly Sebastopol.\n\n\nCollaboration, O. S. (2015). Estimating the reproducibility of psychological science. Science, 349(6251), aac4716.\n\n\nGillespie, C., & Lovelace, R. (2016). Efficient R programming. O‚ÄôReilly Media, Incorporated.\n\n\nKruchten, P., Nord, R. L., & Ozkaya, I. (2012). Technical debt: From metaphor to theory and practice. Ieee software, 29(6), 18‚Äì21.\n\n\nYu, B., & Barter, R. L. (2024). Veridical data science: The practice of responsible data analysis and decision making. MIT Press.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html",
    "href": "chapters/eda/02_data_cleaning.html",
    "title": "15¬† Flusso di lavoro per la pulizia dei dati",
    "section": "",
    "text": "15.1 Introduzione\nNonostante la fase pi√π interessante di un progetto di analisi dei dati sia quella in cui si riesce a rispondere alla domanda che ha dato avvio all‚Äôindagine, gran parte del tempo di un analista √® in realt√† dedicata a una fase preliminare: la pulizia e il preprocessing dei dati, operazioni che vengono svolte ancor prima dell‚Äôanalisi esplorativa.\nIn questo capitolo, esamineremo un caso concreto di data cleaning e preprocessing, seguendo il tutorial di Crystal Lewis. Il problema viene presentato come segue:\nCrystal Lewis elenca i seguenti passaggi da seguire nel processo di data cleaning:\nSebbene l‚Äôordine di questi passaggi sia flessibile e possa essere adattato alle esigenze specifiche, c‚Äô√® un passaggio che non dovrebbe mai essere saltato: il primo, ovvero la revisione dei dati. Senza una revisione preliminare, l‚Äôanalista rischia di sprecare ore a pulire i dati per poi scoprire che mancano dei partecipanti, che i dati non sono organizzati come previsto o, peggio ancora, che si sta lavorando con i dati sbagliati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#introduzione",
    "href": "chapters/eda/02_data_cleaning.html#introduzione",
    "title": "15¬† Flusso di lavoro per la pulizia dei dati",
    "section": "",
    "text": "I am managing data for a longitudinal randomized controlled trial (RCT) study. For this RCT, schools are randomized to either a treatment or control group. Students who are in a treatment school receive a program to boost their math self-efficacy. Data is collected on all students in two waves (wave 1 is in the fall of a school year, and wave 2 is collected in the spring). At this point in time, we have collected wave 1 of our student survey on a paper form and we set up a data entry database for staff to enter the information into. Data has been double-entered, checked for entry errors, and has been exported in a csv format (‚Äúw1_mathproj_stu_svy_raw.csv‚Äù) to a folder (called ‚Äúdata‚Äù) where it is waiting to be cleaned.\n\n\n\nRevisione dei dati.\nRegolazione del numero di casi.\nDe-identificazione dei dati.\nEliminazione delle colonne irrilevanti.\nDivisione delle colonne, se necessario.\nRidenominazione delle variabili.\nTrasformazione/normalizzazione delle variabili.\nStandardizzazione delle variabili.\nAggiornamento dei tipi di variabili, se necessario.\nRicodifica delle variabili.\nCreazione di eventuali variabili necessarie.\nGestione dei valori mancanti, se necessario.\nAggiunta di metadati, se necessario.\nValidazione dei dati.\nFusione e/o unione dei dati, se necessario.\nTrasformazione dei dati, se necessario.\nSalvataggio dei dati puliti.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#tutorial",
    "href": "chapters/eda/02_data_cleaning.html#tutorial",
    "title": "15¬† Flusso di lavoro per la pulizia dei dati",
    "section": "\n15.2 Tutorial",
    "text": "15.2 Tutorial\nQuesto tutorial segue i passaggi descritti da Crystal Lewis per illustrare le buone pratiche nella gestione e pulizia dei dati.\n\n15.2.1 Organizzazione dei Dati\nUn principio fondamentale nella gestione dei dati √® preservare l‚Äôintegrit√† dei dati grezzi. I dati originali non devono mai essere modificati direttamente. √à quindi consigliabile strutturare i dati in una directory denominata data, suddivisa in due sottocartelle:\n\n\nraw: contiene i dati originali, mantenuti inalterati.\n\n\nprocessed: destinata ai dati ripuliti e preprocessati.\n\nAd esempio, importiamo i dati da un file denominato w1_mathproj_stu_svy_raw.csv per avviare il processo di pulizia. Tutte le operazioni dovranno essere effettuate utilizzando percorsi relativi alla home directory del progetto, che definiremo come primo passo.\n\n15.2.2 Passaggi del Tutorial\n\n15.2.2.1 Importare e Esaminare i Dati\nImportiamo i dati utilizzando la funzione import() della libreria rio e visualizziamo i primi valori di ciascuna colonna per verificarne la corretta importazione:\n\n# Importa i dati\nsvy &lt;- rio::import(here::here(\"data\", \"w1_mathproj_stu_svy_raw.csv\"))\n\n# Esamina la struttura del dataset\nglimpse(svy)\n#&gt; Rows: 6\n#&gt; Columns: 7\n#&gt; $ stu_id      &lt;int&gt; 1347, 1368, 1377, 1387, 1347, 1399\n#&gt; $ svy_date    &lt;IDate&gt; 2023-02-13, 2023-02-13, 2023-02-13, 2023-02-13, 2023-0‚Ä¶\n#&gt; $ grade_level &lt;int&gt; 9, 10, 9, 11, 9, 12\n#&gt; $ math1       &lt;int&gt; 2, 3, 4, 3, 2, 4\n#&gt; $ math2       &lt;chr&gt; \"1\", \"2\", \"\\n4\", \"3\", \"2\", \"1\"\n#&gt; $ math3       &lt;int&gt; 3, 2, 4, NA, 4, 3\n#&gt; $ math4       &lt;int&gt; 3, 2, 4, NA, 2, 1\n\nPer controllare visivamente i dati, possiamo esaminare le prime e le ultime righe del data frame:\n\n# Visualizza le prime righe\nsvy |&gt; \n  head()\n#&gt;   stu_id   svy_date grade_level math1 math2 math3 math4\n#&gt; 1   1347 2023-02-13           9     2     1     3     3\n#&gt; 2   1368 2023-02-13          10     3     2     2     2\n#&gt; 3   1377 2023-02-13           9     4   \\n4     4     4\n#&gt; 4   1387 2023-02-13          11     3     3    NA    NA\n#&gt; 5   1347 2023-02-14           9     2     2     4     2\n#&gt; 6   1399 2023-02-14          12     4     1     3     1\n\n# Visualizza le ultime righe\nsvy |&gt; \n  tail()\n#&gt;   stu_id   svy_date grade_level math1 math2 math3 math4\n#&gt; 1   1347 2023-02-13           9     2     1     3     3\n#&gt; 2   1368 2023-02-13          10     3     2     2     2\n#&gt; 3   1377 2023-02-13           9     4   \\n4     4     4\n#&gt; 4   1387 2023-02-13          11     3     3    NA    NA\n#&gt; 5   1347 2023-02-14           9     2     2     4     2\n#&gt; 6   1399 2023-02-14          12     4     1     3     1\n\n\n15.2.2.2 Individuare e Rimuovere i Duplicati\nIn questa fase, eseguiamo alcune modifiche necessarie al data frame, come rimuovere duplicati e ordinare i dati:\n\n\nVerifica duplicati: controlliamo i record duplicati nel dataset.\n\nRimuovi duplicati: manteniamo solo la prima occorrenza.\n\nOrdina per data: organizziamo i record in ordine crescente rispetto alla variabile svy_date.\n\nEsamina i dati puliti: controlliamo il risultato delle modifiche.\n\n\n# Identifica i duplicati basati su 'stu_id'\nduplicates &lt;- \n  svy[duplicated(svy$stu_id) | duplicated(svy$stu_id, fromLast = TRUE), ]\n\n\n# Visualizza i duplicati trovati\nduplicates\n#&gt;   stu_id   svy_date grade_level math1 math2 math3 math4\n#&gt; 1   1347 2023-02-13           9     2     1     3     3\n#&gt; 5   1347 2023-02-14           9     2     2     4     2\n\n\n# Ordina per 'svy_date' in ordine crescente\nsvy &lt;- svy[order(svy$svy_date), ]\n\n\n# Rimuove i duplicati mantenendo la prima occorrenza\nsvy &lt;- svy[!duplicated(svy$stu_id), ]\n\n\n# Esamina il dataset finale\nprint(svy)\n#&gt;   stu_id   svy_date grade_level math1 math2 math3 math4\n#&gt; 1   1347 2023-02-13           9     2     1     3     3\n#&gt; 2   1368 2023-02-13          10     3     2     2     2\n#&gt; 3   1377 2023-02-13           9     4   \\n4     4     4\n#&gt; 4   1387 2023-02-13          11     3     3    NA    NA\n#&gt; 6   1399 2023-02-14          12     4     1     3     1\n\nVerifichiamo le dimensioni del dataset pulito per assicurarci che le operazioni siano state eseguite correttamente:\n\n# Controlla il numero di righe e colonne\nsvy |&gt; \n  dim()\n#&gt; [1] 5 7\n\n\n15.2.2.3 De-identificazione dei Dati\n\n# Rimuovi la colonna 'svy_date'\nsvy &lt;- svy |&gt;\n  dplyr::select(-svy_date)\n\n# Mostra i nomi delle colonne rimaste\nnames(svy)\n#&gt; [1] \"stu_id\"      \"grade_level\" \"math1\"       \"math2\"       \"math3\"      \n#&gt; [6] \"math4\"\n\n\n15.2.2.4 Rimuovere le Colonne non Necessarie\nNel caso presente, la rimozione di colonne non √® necessaria. Tuttavia, in molti progetti di analisi dei dati, soprattutto quando i dati vengono raccolti utilizzando software di terze parti o strumenti specifici per esperimenti psicologici, √® comune trovarsi con colonne che non sono pertinenti allo studio in corso.\nQueste colonne possono includere dati come identificatori interni, timestamp generati automaticamente, informazioni di debug, o variabili che non sono rilevanti per l‚Äôanalisi che si intende condurre. Quando tali colonne sono irrilevanti per la ricerca, possono essere rimosse per semplificare il dataset e ridurre il rischio di confusione o errori durante l‚Äôanalisi. Rimuovere le colonne non necessarie non solo rende il dataset pi√π gestibile, ma aiuta anche a focalizzare l‚Äôanalisi sulle variabili che realmente importano per rispondere alle domande di ricerca.\n\n15.2.2.5 Dividere le Colonne Secondo Necessit√†\nNel caso presente, questa operazione non √® necessaria. Tuttavia, se si lavora con un dataset che include una colonna chiamata ‚ÄúNomeCompleto‚Äù, contenente sia il nome che il cognome di uno studente, per esempio, √® buona pratica separare questa colonna in due colonne distinte, ‚ÄúNome‚Äù e ‚ÄúCognome‚Äù. Questa suddivisione facilita l‚Äôanalisi e la manipolazione dei dati, rendendoli pi√π organizzati e accessibili.\n\n15.2.2.6 Rinominare le Colonne\n√à importante assegnare nomi chiari alle colonne del dataset. Utilizzare nomi di variabili comprensibili aiuta a rendere l‚Äôanalisi dei dati pi√π intuitiva e a ridurre il rischio di errori interpretativi.\nEsempi di buone pratiche:\n\nEvita nomi di colonne come ‚Äúx‚Äù o acronimi incomprensibili. Questi possono creare confusione durante l‚Äôanalisi, specialmente se il dataset viene condiviso con altri ricercatori o se viene ripreso dopo un lungo periodo di tempo.\nInvece, cerca di utilizzare nomi di variabili che descrivano chiaramente il contenuto della colonna. Ad esempio, invece di ‚Äúx1‚Äù o ‚ÄúVAR123‚Äù, un nome come ‚Äúansia_base‚Äù o ‚Äúliv_autoefficacia‚Äù √® molto pi√π comprensibile e immediato.\nPer i nomi composti, utilizza un separatore come il trattino basso _. Ad esempio, se stai lavorando con dati relativi a un test psicologico, potresti avere colonne chiamate ‚Äútest_ansia_pre‚Äù e ‚Äútest_ansia_post‚Äù per indicare i risultati del test di ansia prima e dopo un intervento.\n\nEsempi di nomi di colonne ben scelti:\n\n\nNome generico: TS, AE\n\n\nNome migliore: tempo_studio, auto_efficacia\n\n\n\n\nNome generico: S1, S2\n\n\nNome migliore: stress_situazione1, stress_situazione2\n\n\n\n\nNome generico: Q1, Q2\n\n\nNome migliore: qualit√†_sonno_sett1, qualit√†_sonno_sett2\n\n\n\n\n15.2.2.7 Trasformare le Variabili\nNel caso presente non si applica, ma √® un passo importante in molte analisi dei dati.\nEsempi di trasformazione delle variabili:\n\nLogaritmo di una variabile: Immaginiamo di avere una variabile che misura i tempi di reazione dei partecipanti a un esperimento. Se i tempi di reazione hanno una distribuzione fortemente asimmetrica (con alcuni valori molto elevati), potrebbe essere utile applicare una trasformazione logaritmica per rendere la distribuzione pi√π simmetrica e migliorare l‚Äôinterpretabilit√† dei risultati.\nCodifica delle variabili categoriche: Se √® presente una variabile categorica come il ‚Äútipo di intervento‚Äù con valori come ‚Äúcognitivo‚Äù, ‚Äúcomportamentale‚Äù e ‚Äúfarmacologico‚Äù, potrebbe essere necessario trasformare questa variabile in variabili dummy (ad esempio, intervento_cognitivo, intervento_comportamentale, intervento_farmacologico), dove ogni variabile assume il valore 0 o 1 a seconda della presenza o meno di quel tipo di intervento. Questo √® utile quando si utilizzano tecniche di regressione.\n\n15.2.2.8 Standardizzazione delle Variabili\nLa standardizzazione √® utile quando si desidera rendere comparabili variabili misurate su scale diverse, ad esempio per confronti tra gruppi o per inclusione in modelli di regressione.\nEsempio. Supponiamo di avere una variabile che misura il livello di ansia su una scala da 0 a 100. Per standardizzarla:\n\n\nSottrai la media del campione dalla variabile.\n\n\nDividi per la deviazione standard.\n\nIl risultato √® una variabile con media pari a 0 e deviazione standard pari a 1.\nVantaggi della standardizzazione:\n\nfacilita l‚Äôinterpretazione dei coefficienti in un modello di regressione;\npermette un confronto diretto tra variabili che hanno unit√† di misura diverse.\n\n15.2.2.9 Normalizzazione delle Variabili\n\nLa normalizzazione consiste nel ridimensionare i dati su una scala predefinita, spesso compresa tra 0 e 1. Questo processo √® particolarmente utile in analisi multivariate, dove variabili con scale molto diverse potrebbero influenzare in modo sproporzionato i risultati.\nEsempio. Hai dati su:\n\n\nOre di sonno (misurate in ore, da 0 a 24).\n\n\nLivello di stress (misurato su una scala da 1 a 50).\n\n\nAuto-efficacia (misurata su una scala da 0 a 100).\n\nPer garantire che ogni variabile abbia lo stesso peso nell‚Äôanalisi, puoi normalizzarle usando una formula come:\n\\[\nx_{\\text{norm}} = \\frac{x - \\text{min}(x)}{\\text{max}(x) - \\text{min}(x)} .\n\\]\nPerch√© Standardizzare o Normalizzare?\nTrasformare le variabili √® cruciale per:\n\n\nGestire scale diverse: Riduce il rischio che variabili con valori numericamente pi√π grandi dominino i risultati.\n\n\nGarantire validit√† e interpretabilit√†: Facilita il confronto tra dati provenienti da fonti o gruppi diversi.\n\n\nEvitare problemi numerici nei modelli statistici: Alcuni algoritmi di machine learning o tecniche di ottimizzazione richiedono che i dati siano su scale simili per funzionare correttamente.\n\nIn conclusione, la scelta tra standardizzazione e normalizzazione dipende dal contesto dell‚Äôanalisi e dagli obiettivi specifici. Entrambi i processi sono strumenti indispensabili per garantire che i dati siano trattati in modo adeguato, portando a risultati robusti e facilmente interpretabili.\n\n15.2.2.10 Aggiornare i Tipi delle Variabili\nNel caso presente non √® necessario. Supponiamo invece di avere una colonna in un dataset psicologico che contiene punteggi di un questionario, ma i dati sono stati importati come stringhe (testo) invece che come numeri. Per eseguire calcoli statistici, sar√† necessario convertire questa colonna da stringa a numerico.\nIn R, si potrebbe usare il seguente codice:\n\n# Supponiamo di avere un data frame chiamato 'df' con una colonna 'punteggio' importata come carattere\ndf$punteggio &lt;- as.numeric(df$punteggio)\n\n# Ora la colonna 'punteggio' √® stata convertita in un tipo numerico ed √® possibile eseguire calcoli su di essa\n\nIn questo esempio, la funzione as.numeric() viene utilizzata per convertire la colonna punteggio in un formato numerico, permettendo di eseguire analisi quantitative sui dati.\nUn altro caso molto comune si verifica quando si importano dati da file Excel. Spesso capita che, all‚Äôinterno di una cella di una colonna che dovrebbe contenere solo valori numerici, venga inserito erroneamente uno o pi√π caratteri alfanumerici. Di conseguenza, l‚Äôintera colonna viene interpretata come di tipo alfanumerico, anche se i valori dovrebbero essere numerici. In questi casi, √® fondamentale individuare la cella problematica, correggere manualmente il valore errato, e poi riconvertire l‚Äôintera colonna da alfanumerica a numerica.\n\n15.2.2.11 Ricodificare le Variabili\nAnche se in questo caso non √® necessario, la ricodifica delle variabili √® una pratica molto comune nelle analisi dei dati psicologici.\nPer esempio, consideriamo una variabile categoriale con modalit√† descritte da stringhe poco comprensibili, che vengono ricodificate con nomi pi√π chiari e comprensibili.\nSupponiamo di avere un DataFrame chiamato df con una colonna tipo_intervento che contiene le modalit√† \"CT\", \"BT\", e \"MT\" per rappresentare rispettivamente ‚ÄúTerapia Cognitiva‚Äù, ‚ÄúTerapia Comportamentale‚Äù e ‚ÄúTerapia Mista‚Äù. Queste abbreviazioni potrebbero non essere immediatamente chiare a chiunque analizzi i dati, quindi decidiamo di ricodificarle con nomi pi√π espliciti. Ecco come farlo in R:\n\n# Tibble chiamato 'df' con una colonna 'tipo_intervento'\ndf &lt;- tibble(tipo_intervento = c(\"CT\", \"BT\", \"MT\", \"CT\", \"BT\"))\ndf\n#&gt; # A tibble: 5 √ó 1\n#&gt;   tipo_intervento\n#&gt;   &lt;chr&gt;          \n#&gt; 1 CT             \n#&gt; 2 BT             \n#&gt; 3 MT             \n#&gt; 4 CT             \n#&gt; 5 BT\n\n\n# Ricodifica delle modalit√† della variabile 'tipo_intervento' in nomi pi√π comprensibili\ndf &lt;- df %&gt;%\n  mutate(tipo_intervento_ricodificato = dplyr::recode(\n    tipo_intervento,\n    \"CT\" = \"Terapia Cognitiva\",\n    \"BT\" = \"Terapia Comportamentale\",\n    \"MT\" = \"Terapia Mista\"\n  ))\n\n# Mostra il tibble con la nuova colonna ricodificata\ndf\n#&gt; # A tibble: 5 √ó 2\n#&gt;   tipo_intervento tipo_intervento_ricodificato\n#&gt;   &lt;chr&gt;           &lt;chr&gt;                       \n#&gt; 1 CT              Terapia Cognitiva           \n#&gt; 2 BT              Terapia Comportamentale     \n#&gt; 3 MT              Terapia Mista               \n#&gt; 4 CT              Terapia Cognitiva           \n#&gt; 5 BT              Terapia Comportamentale\n\n\n15.2.2.12 Aggiungere Nuove Variabili nel Data Frame\nNel caso presente non √® richiesto, ma aggiungere nuove variabili a un DataFrame √® un‚Äôoperazione comune durante l‚Äôanalisi dei dati. Un esempio √® il calcolo dell‚Äôindice di massa corporea (BMI).\nSupponiamo di avere un DataFrame chiamato df che contiene le colonne peso_kg (peso in chilogrammi) e altezza_m (altezza in metri) per ciascun partecipante a uno studio psicologico. Per arricchire il dataset, possiamo calcolare il BMI per ogni partecipante e aggiungerlo come una nuova variabile.\nIl BMI si calcola con la formula:\n\\[ \\text{BMI} = \\frac{\\text{peso in kg}}{\\text{altezza in metri}^2} .\\]\nEcco come aggiungere la nuova colonna.\n\n# Supponiamo di avere un tibble chiamato 'df' con le colonne 'peso_kg' e 'altezza_m'\ndf &lt;- tibble(\n  peso_kg = c(70, 85, 60, 95),\n  altezza_m = c(1.75, 1.80, 1.65, 1.90)\n)\ndf\n#&gt; # A tibble: 4 √ó 2\n#&gt;   peso_kg altezza_m\n#&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1      70      1.75\n#&gt; 2      85      1.8 \n#&gt; 3      60      1.65\n#&gt; 4      95      1.9\n\n\n# Calcola il BMI e aggiungilo come una nuova colonna 'BMI'\ndf &lt;- df %&gt;%\n  mutate(BMI = peso_kg / (altezza_m^2))\n\n# Mostra il tibble con la nuova variabile aggiunta\ndf\n#&gt; # A tibble: 4 √ó 3\n#&gt;   peso_kg altezza_m   BMI\n#&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1      70      1.75  22.9\n#&gt; 2      85      1.8   26.2\n#&gt; 3      60      1.65  22.0\n#&gt; 4      95      1.9   26.3\n\n\n15.2.3 Affrontare il Problema dei Dati Mancanti\nI dati mancanti sono un problema comune nelle ricerche psicologiche e in molte altre discipline. Quando mancano delle informazioni in un dataset, possono verificarsi gravi problemi per l‚Äôanalisi statistica, come risultati distorti, riduzione della precisione delle stime o, in alcuni casi, l‚Äôimpossibilit√† di applicare alcuni algoritmi.\n\n15.2.3.1 Perch√© i Dati Mancanti Sono un Problema?\nImmagina di voler capire il rendimento medio di una classe in un test, ma alcuni studenti hanno lasciato delle risposte in bianco. Se ignoriamo le risposte mancanti o eliminiamo gli studenti con dati incompleti, rischiamo di ottenere una stima che non rappresenta correttamente la realt√†. Questo succede perch√©:\n\n\nBias dei risultati: Se i dati mancanti non sono casuali (ad esempio, i dati mancanti sono presenti pi√π spesso in studenti con basso rendimento), le conclusioni possono essere errate.\n\nRiduzione della potenza statistica: Eliminare dati incompleti riduce il numero totale di osservazioni, rendendo pi√π difficile trovare risultati significativi.\n\nImpossibilit√† di applicare alcuni metodi: Molti algoritmi statistici richiedono dati completi e non funzionano con valori mancanti.\n\n15.2.3.2 Come Gestire i Dati Mancanti?\nCi sono diversi modi per affrontare i dati mancanti. Vediamo prima i metodi pi√π semplici e poi quelli pi√π avanzati.\nEsaminiamo il data frame iniziale:\n\nsvy |&gt; \n  summary()\n#&gt;      stu_id      grade_level       math1        math2          \n#&gt;  Min.   :1347   Min.   : 9.0   Min.   :2.0   Length:5          \n#&gt;  1st Qu.:1368   1st Qu.: 9.0   1st Qu.:3.0   Class :character  \n#&gt;  Median :1377   Median :10.0   Median :3.0   Mode  :character  \n#&gt;  Mean   :1376   Mean   :10.2   Mean   :3.2                     \n#&gt;  3rd Qu.:1387   3rd Qu.:11.0   3rd Qu.:4.0                     \n#&gt;  Max.   :1399   Max.   :12.0   Max.   :4.0                     \n#&gt;                                                                \n#&gt;      math3          math4     \n#&gt;  Min.   :2.00   Min.   :1.00  \n#&gt;  1st Qu.:2.75   1st Qu.:1.75  \n#&gt;  Median :3.00   Median :2.50  \n#&gt;  Mean   :3.00   Mean   :2.50  \n#&gt;  3rd Qu.:3.25   3rd Qu.:3.25  \n#&gt;  Max.   :4.00   Max.   :4.00  \n#&gt;  NA's   :1      NA's   :1\n\nSi noti la presenza di dati mancanti sulle variabili math3 e math4.\n\ndim(svy)\n#&gt; [1] 5 6\n\n\n\nEsclusione dei Casi Incompleti (Complete Case Analysis).\nUn approccio comune, ma spesso non ideale, √® quello di analizzare solo i casi completi, eliminando tutte le righe con valori mancanti. In R, questo si pu√≤ fare con il seguente comando:\n\nsvy_comp &lt;- svy |&gt;\n  drop_na()\n\nIn questo modo abbiamo escluso tutte le righe nelle quali sono presenti dei dati mancanti (in questo caso, una sola riga).\n\ndim(svy_comp)\n#&gt; [1] 4 6\n\nLimite: Questo metodo pu√≤ introdurre bias se i dati mancanti non sono casuali e riduce il campione, compromettendo l‚Äôaffidabilit√† delle analisi.\n\n\nImputazione Semplice\nSostituire i valori mancanti con stime semplici:\n\n\nMedia o mediana: Per le variabili numeriche, sostituire i valori mancanti con la media o la mediana. Questo metodo √® facile da implementare, ma pu√≤ ridurre la variabilit√† nei dati.\n\nModa: Per le variabili categoriche, sostituire i valori mancanti con il valore pi√π frequente. Tuttavia, pu√≤ introdurre distorsioni se i dati sono molto eterogenei.\n\n\n\nImputazione Multipla\nUn approccio pi√π avanzato √® l‚Äôimputazione multipla, che utilizza modelli statistici per stimare i valori mancanti in modo iterativo. L‚Äôidea di base √® semplice: ogni valore mancante viene stimato tenendo conto delle relazioni con tutte le altre variabili.\nVantaggi:\n\nMantiene la variabilit√† dei dati.\nPreserva le relazioni tra le variabili.\nRiduce il rischio di bias rispetto ai metodi semplici.\n\n\n\n15.2.3.3 Applicazione Pratica: Imputazione Multipla con mice in R\nSupponiamo di avere un dataset con alcune colonne numeriche che contengono valori mancanti. Possiamo utilizzare il pacchetto mice per imputare i dati mancanti.\nSelezioniamo le colonne numeriche da imputare.\n\nnumeric_columns &lt;- c(\"math1\", \"math2\", \"math3\", \"math4\")\nsvy &lt;- svy %&gt;%\n  mutate(across(all_of(numeric_columns), as.numeric))\n\nEseguiamo l‚Äôimputazione multipla.\n\nimputed &lt;- mice(\n  svy[numeric_columns], \n  m = 1, \n  maxit = 10, \n  method = \"norm.predict\", \n  seed = 123\n)\n#&gt; \n#&gt;  iter imp variable\n#&gt;   1   1  math3  math4\n#&gt;   2   1  math3  math4\n#&gt;   3   1  math3  math4\n#&gt;   4   1  math3  math4\n#&gt;   5   1  math3  math4\n#&gt;   6   1  math3  math4\n#&gt;   7   1  math3  math4\n#&gt;   8   1  math3  math4\n#&gt;   9   1  math3  math4\n#&gt;   10   1  math3  math4\n\nOttieniamo il dataset con i valori imputati.\n\nsvy_imputed &lt;- complete(imputed)\n\nArrotondiamo i valori imputati (se necessario).\n\nsvy_imputed &lt;- svy_imputed %&gt;%\n  mutate(across(everything(), round))\n\nSostituiamo i valori imputati nel dataset originale.\n\nsvy[numeric_columns] &lt;- svy_imputed\n\nEsaminiamo il risultato ottenuto.\n\nsvy |&gt; \n  summary()\n#&gt;      stu_id      grade_level       math1         math2         math3    \n#&gt;  Min.   :1347   Min.   : 9.0   Min.   :2.0   Min.   :1.0   Min.   :2.0  \n#&gt;  1st Qu.:1368   1st Qu.: 9.0   1st Qu.:3.0   1st Qu.:1.0   1st Qu.:3.0  \n#&gt;  Median :1377   Median :10.0   Median :3.0   Median :2.0   Median :3.0  \n#&gt;  Mean   :1376   Mean   :10.2   Mean   :3.2   Mean   :2.2   Mean   :3.2  \n#&gt;  3rd Qu.:1387   3rd Qu.:11.0   3rd Qu.:4.0   3rd Qu.:3.0   3rd Qu.:4.0  \n#&gt;  Max.   :1399   Max.   :12.0   Max.   :4.0   Max.   :4.0   Max.   :4.0  \n#&gt;      math4    \n#&gt;  Min.   :1.0  \n#&gt;  1st Qu.:2.0  \n#&gt;  Median :3.0  \n#&gt;  Mean   :2.8  \n#&gt;  3rd Qu.:4.0  \n#&gt;  Max.   :4.0\n\n\n15.2.3.4 Come Funziona l‚ÄôImputazione Multipla?\n\nOgni variabile con valori mancanti viene modellata come funzione delle altre variabili.\nI valori mancanti vengono stimati iterativamente. In ogni iterazione, si utilizza l‚Äôoutput precedente come input per migliorare le stime.\nDopo un numero sufficiente di iterazioni, le stime si stabilizzano (convergenza).\n\nIn conclusione, l‚Äôimputazione multipla √® una tecnica avanzata che permette di gestire i dati mancanti preservando la qualit√† delle analisi. Rispetto ai metodi semplici, consente di mantenere la variabilit√† e ridurre il rischio di bias, rendendola una scelta ideale per analisi psicologiche e di ricerca.\n\n15.2.3.5 Aggiungere i Metadati\nI metadati sono informazioni che descrivono i dati stessi, come etichette di variabili, etichette di valori, informazioni sull‚Äôorigine dei dati, unit√† di misura e altro ancora. Questi metadati sono essenziali per comprendere, documentare e condividere correttamente un dataset.\nIn R, i metadati sono gestiti in modo molto dettagliato e strutturato attraverso pacchetti come haven, labelled, e Hmisc. Questi pacchetti consentono di associare etichette ai dati, come etichette di variabili e di valori, e persino di gestire i valori mancanti con etichette specifiche.\n\n\nEtichette di variabili: Si possono aggiungere direttamente alle colonne di un DataFrame usando funzioni come labelled::set_variable_labels().\n\nEtichette di valori: Possono essere aggiunte a variabili categoriali utilizzando labelled::labelled().\n\nValori mancanti: In R, √® possibile etichettare specifici valori come mancanti usando labelled::na_values&lt;-.\n\nQuesti strumenti rendono molto facile documentare un dataset all‚Äôinterno del processo di analisi, assicurando che tutte le informazioni critiche sui dati siano facilmente accessibili e ben documentate.\nEsaminiamo un esempio pratico. Consideriamo nuovamente il data set svy:\n\nglimpse(svy)\n#&gt; Rows: 5\n#&gt; Columns: 6\n#&gt; $ stu_id      &lt;int&gt; 1347, 1368, 1377, 1387, 1399\n#&gt; $ grade_level &lt;int&gt; 9, 10, 9, 11, 12\n#&gt; $ math1       &lt;dbl&gt; 2, 3, 4, 3, 4\n#&gt; $ math2       &lt;dbl&gt; 1, 2, 4, 3, 1\n#&gt; $ math3       &lt;dbl&gt; 3, 2, 4, 4, 3\n#&gt; $ math4       &lt;dbl&gt; 3, 2, 4, 4, 1\n\nSi noti che la variabile math2 contiene un valore inamissibile, probabilmente un errore di battitura. Questo fa in modo che math2 sia di tipo char mentre dovrebbe essere una variabile numerica. Correggiamo.\n\n# Correzione di `math2`: Rimuovi valori non validi e converti in numerico\nsvy$math2 &lt;- gsub(\"\\\\n\", \"\", svy$math2)  # Rimuovi caratteri non validi come '\\n'\nsvy$math2 &lt;- as.numeric(svy$math2)      # Converte la variabile in numerico\n\n# Visualizzazione del dataset corretto\nprint(svy)\n#&gt;   stu_id grade_level math1 math2 math3 math4\n#&gt; 1   1347           9     2     1     3     3\n#&gt; 2   1368          10     3     2     2     2\n#&gt; 3   1377           9     4     4     4     4\n#&gt; 4   1387          11     3     3     4     4\n#&gt; 6   1399          12     4     1     3     1\n\nDefiniamo le etichette di valore per le variabili math1:math4.\n\nvalue_labels_math &lt;- set_names(\n  as.numeric(names(c(\n    `1` = \"strongly disagree\",\n    `2` = \"disagree\",\n    `3` = \"agree\",\n    `4` = \"strongly agree\"\n  ))),\n  c(\"strongly disagree\", \"disagree\", \"agree\", \"strongly agree\")\n)\n\nAggiungiamo le etichette di valore alle colonne math1:math4.\n\nsvy &lt;- svy %&gt;%\n  mutate(across(starts_with(\"math\"), ~ labelled(., labels = value_labels_math)))\n\nVerifica delle etichette.\n\nval_labels(svy$math1)\n#&gt; strongly disagree          disagree             agree    strongly agree \n#&gt;                 1                 2                 3                 4\n\n\nsvy\n#&gt;   stu_id grade_level math1 math2 math3 math4\n#&gt; 1   1347           9     2     1     3     3\n#&gt; 2   1368          10     3     2     2     2\n#&gt; 3   1377           9     4     4     4     4\n#&gt; 4   1387          11     3     3     4     4\n#&gt; 6   1399          12     4     1     3     1\n\n\n15.2.3.5.1 Utilizzo delle Etichette in R con Variabili Numeriche\nLe etichette dei valori (value labels) vengono utilizzate per rendere pi√π leggibili e interpretabili le variabili numeriche, associando ad ogni valore un‚Äôetichetta descrittiva. Questo approccio √® particolarmente utile in ambiti come la ricerca psicologica, dove le risposte ai questionari sono spesso codificate con numeri (ad esempio, 1 = ‚ÄúStrongly Disagree‚Äù, 2 = ‚ÄúDisagree‚Äù, ecc.) ma rappresentano concetti qualitativi.\nVantaggi dell‚ÄôUso delle Etichette\n\n\nChiarezza nelle Analisi: Le etichette descrittive rendono i dati pi√π facilmente comprensibili senza dover ricordare il significato numerico di ciascun valore.\n\n\nDocumentazione Integrata: Permettono di incorporare metadati direttamente nelle variabili, migliorando la trasparenza e riducendo il rischio di interpretazioni errate.\n\nCompatibilit√† con Software Statistici: Molti strumenti (ad esempio, SPSS o Stata) utilizzano etichette di valori. Il pacchetto haven in R consente di gestire facilmente i dati etichettati esportati/importati da questi software.\n\nManipolazione di Variabili Etichettate\nAnche se una variabile numerica √® etichettata con labelled (ad esempio, tramite il pacchetto haven), essa conserva la sua natura numerica e pu√≤ essere utilizzata in calcoli, modelli statistici, e trasformazioni. Le etichette non alterano il valore sottostante, ma lo arricchiscono con informazioni aggiuntive.\nIn conclusione, le etichette dei valori migliorano l‚Äôinterpretabilit√† dei dati senza comprometterne la manipolabilit√†. Questo approccio √® ideale per mantenere le variabili numeriche pienamente funzionali per analisi statistiche, mentre le etichette descrittive forniscono un contesto chiaro e leggibile.\n\n15.2.3.6 Validazione dei Dati\nLa validazione dei dati √® un passaggio fondamentale per garantire che il dataset soddisfi i criteri previsti e sia pronto per le analisi successive. Questo processo include il controllo della coerenza e della correttezza dei dati in base a specifiche regole definite dal dizionario dei dati. Alcune verifiche comuni includono:\n\n\nUnicit√† delle righe: Assicurarsi che ogni riga sia unica, verificando l‚Äôassenza di ID duplicati.\n\nValidit√† degli ID: Controllare che gli ID rientrino in un intervallo previsto (es. numerico).\n\nValori accettabili nelle variabili categoriali: Verificare che variabili come grade_level, int e le colonne math contengano esclusivamente valori appartenenti a un set di valori validi.\n\nIl pacchetto pointblank fornisce strumenti flessibili e intuitivi per eseguire verifiche di validazione e generare report dettagliati. Questo pacchetto consente di:\n\n\nDefinire le regole di validazione: Specificare controlli come unicit√†, intervalli di valori e appartenenza a insiemi predefiniti.\n\nEseguire i controlli: Applicare le regole di validazione su un dataset per identificare eventuali discrepanze.\n\nGenerare report interattivi: Creare un riepilogo chiaro e visivo dei controlli, evidenziando eventuali errori o anomalie.\n\nCon pointblank, √® possibile integrare la validazione dei dati come parte di un workflow strutturato, garantendo la qualit√† dei dati in modo sistematico e ripetibile.\n\ncreate_agent(svy) %&gt;%\n  rows_distinct(columns = vars(stu_id)) %&gt;%\n  col_vals_between(columns = c(stu_id), \n                   left = 1300, right = 1400, na_pass = TRUE) %&gt;%\n  col_vals_in_set(columns = c(grade_level), \n                  set = c(9, 10, 11, 12, NA)) %&gt;%\n  col_vals_in_set(columns = c(int),\n                  set = c(0, 1, NA)) %&gt;%\n  col_vals_in_set(columns = c(math1:math4),\n                  set = c(1, 2, 3, 4, NA)) %&gt;%\n  interrogate()\n\n\n\n\n\n\nPointblank Validation\n\n\n\n\n[2025-03-26|10:08:53]\n\n\ndata frame svy\n\n\n\n\n\n\nSTEP\nCOLUMNS\nVALUES\nTBL\nEVAL\nUNITS\nPASS\nFAIL\nW\nS\nN\nEXT\n\n\n\n\n\n1\n\n\n\nrows_distinct\n\n\n\n¬†rows_distinct()\n\n\n‚ñÆstu_id\n\n‚Äî\n\n\n‚úì\n5\n\n51\n\n\n00\n\n‚Äî\n‚Äî\n‚Äî\n‚Äî\n\n\n\n2\n\n\n\ncol_vals_between\n\n\n\n¬†col_vals_between()\n\n\n‚ñÆstu_id\n\n\n[1,300, 1,400]\n\n\n\n‚úì\n5\n\n51\n\n\n00\n\n‚Äî\n‚Äî\n‚Äî\n‚Äî\n\n\n\n3\n\n\n\ncol_vals_in_set\n\n\n\n¬†col_vals_in_set()\n\n\n‚ñÆgrade_level\n\n\n9, 10, 11, 12, NA\n\n\n\n‚úì\n5\n\n51\n\n\n00\n\n‚Äî\n‚Äî\n‚Äî\n‚Äî\n\n\n\n4\n\n\n\ncol_vals_in_set\n\n\n\n¬†col_vals_in_set()\n\n\n‚ñÆint\n\n\n0, 1, NA\n\n\n\nüí•\n‚Äî\n‚Äî\n‚Äî\n‚Äî\n‚Äî\n‚Äî\n‚Äî\n\n\n\n5\n\n\n\ncol_vals_in_set\n\n\n\n¬†col_vals_in_set()\n\n\n‚ñÆmath1\n\n\n1, 2, 3, 4, NA\n\n\n\n‚úì\n5\n\n51\n\n\n00\n\n‚Äî\n‚Äî\n‚Äî\n‚Äî\n\n\n\n6\n\n\n\ncol_vals_in_set\n\n\n\n¬†col_vals_in_set()\n\n\n‚ñÆmath2\n\n\n1, 2, 3, 4, NA\n\n\n\n‚úì\n5\n\n51\n\n\n00\n\n‚Äî\n‚Äî\n‚Äî\n‚Äî\n\n\n\n7\n\n\n\ncol_vals_in_set\n\n\n\n¬†col_vals_in_set()\n\n\n‚ñÆmath3\n\n\n1, 2, 3, 4, NA\n\n\n\n‚úì\n5\n\n51\n\n\n00\n\n‚Äî\n‚Äî\n‚Äî\n‚Äî\n\n\n\n8\n\n\n\ncol_vals_in_set\n\n\n\n¬†col_vals_in_set()\n\n\n‚ñÆmath4\n\n\n1, 2, 3, 4, NA\n\n\n\n‚úì\n5\n\n51\n\n\n00\n\n‚Äî\n‚Äî\n‚Äî\n‚Äî\n\n\n\n\n2025-03-26 10:08:53 CET &lt; 1 s 2025-03-26 10:08:53 CET\n\n\n\n\n\n\nIl dataset ripulito soddisfa tutte le aspettative delineate da Crystal Lewis.\n\n\nCompleto: Tutti i dati raccolti sono stati inseriti e/o recuperati. Non dovrebbero esserci dati estranei che non appartengono al dataset (come duplicati o partecipanti non autorizzati).\n\nValido: Le variabili rispettano i vincoli definiti nel tuo dizionario dei dati. Ricorda che il dizionario dei dati specifica i nomi delle variabili, i tipi, i range, le categorie e altre informazioni attese.\n\nAccurato: Sebbene non sia sempre possibile determinare l‚Äôaccuratezza dei valori durante il processo di pulizia dei dati (ovvero, se un valore √® realmente corretto o meno), in alcuni casi √® possibile valutarla sulla base della conoscenza pregressa riguardante quel partecipante o caso specifico.\n\nCoerente: I valori sono allineati tra le varie fonti. Ad esempio, la data di nascita raccolta attraverso un sondaggio studentesco dovrebbe avere un formato corrispondere alla data di nascita raccolta dal distretto scolastico.\n\nUniforme: I dati sono standardizzati attraverso i moduli e nel tempo. Ad esempio, lo stato di partecipazione ai programmi di pranzo gratuito o a prezzo ridotto √® sempre fornito come una variabile numerica con la stessa rappresentazione, oppure il nome della scuola √® sempre scritto in modo coerente in tutto il dataset.\n\nDe-identificato: Tutte le informazioni personali identificabili (PII) sono state rimosse dal dataset per proteggere la riservatezza dei partecipanti (se richiesto dal comitato etico/consenso informato).\n\nInterpretabile: I dati hanno nomi di variabili leggibili sia da umani che dal computer, e sono presenti etichette di variabili e valori laddove necessario per facilitare l‚Äôinterpretazione.\n\nAnalizzabile: Il dataset √® in un formato rettangolare (righe e colonne), leggibile dal computer e conforme alle regole di base della struttura dei dati.\n\nUna volta completati i 14 passaggi precedenti, √® possibile esportare questo dataset ripulito nella cartella processed per le successive analisi statistiche.\n\n15.2.3.7 Unire e/o aggiungere dati se necessario\nIn questo passaggio, √® possibile unire o aggiungere colonne o righe presenti in file diversi. √à importante eseguire nuovamente i controlli di validazione dopo l‚Äôunione/aggiunta di nuovi dati.\n\n15.2.3.8 Trasformare i dati se necessario\nEsistono vari motivi per cui potrebbe essere utile memorizzare i dati in formato long o wide. In questo passaggio, √® possibile ristrutturare i dati secondo le esigenze.\n\n15.2.3.9 Salvare il dataset pulito finale\nL‚Äôultimo passaggio del processo di pulizia consiste nell‚Äôesportare o salvare il dataset pulito. Come accennato in precedenza, pu√≤ essere utile esportare/salvare il dataset in pi√π di un formato di file (ad esempio, un file .csv e un file .parquet).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#organizzazione-dei-file-e-informazioni-aggiuntive",
    "href": "chapters/eda/02_data_cleaning.html#organizzazione-dei-file-e-informazioni-aggiuntive",
    "title": "15¬† Flusso di lavoro per la pulizia dei dati",
    "section": "\n15.3 Organizzazione dei file e informazioni aggiuntive",
    "text": "15.3 Organizzazione dei file e informazioni aggiuntive\nInfine, √® essenziale includere una documentazione adeguata per garantire che le informazioni siano interpretate correttamente, sia da altri utenti che da te stesso, se dovessi tornare a lavorare su questo progetto in futuro. La documentazione minima da fornire dovrebbe includere:\n\n\nDocumentazione a livello di progetto: Questa sezione fornisce informazioni contestuali sul perch√© e come i dati sono stati raccolti. √à utile per chiunque voglia comprendere lo scopo e la metodologia del progetto.\n\nMetadati a livello di progetto: Se condividi i dati in un repository pubblico o privato, √® importante includere metadati a livello di progetto. Questi metadati forniscono informazioni dettagliate che facilitano la ricerca, la comprensione e la consultabilit√† dei dati. I metadati a livello di progetto possono includere descrizioni generali del progetto, parole chiave, e riferimenti bibliografici.\n\nDizionario dei dati: Un documento che descrive tutte le variabili presenti nel dataset, inclusi i loro nomi, tipi, range di valori, categorie e qualsiasi altra informazione rilevante. Questo strumento √® fondamentale per chiunque voglia comprendere o analizzare i dati.\n\nREADME: Un file che fornisce una panoramica rapida dei file inclusi nel progetto, spiegando cosa contengono e come sono interconnessi. Il README √® spesso il primo documento consultato e serve a orientare l‚Äôutente tra i vari file e risorse del progetto. Questa documentazione non solo aiuta a mantenere il progetto organizzato, ma √® anche cruciale per facilitare la collaborazione e l‚Äôarchiviazione a lungo termine.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#dizionario-dei-dati",
    "href": "chapters/eda/02_data_cleaning.html#dizionario-dei-dati",
    "title": "15¬† Flusso di lavoro per la pulizia dei dati",
    "section": "\n15.4 Dizionario dei Dati",
    "text": "15.4 Dizionario dei Dati\nApprofondiamo qui il problema della creazione del Dizionario dei dati.\nUn dizionario dei dati √® un documento che descrive le caratteristiche di ciascuna variabile in un dataset. Include informazioni come il nome della variabile, il tipo di dato, il range di valori, le categorie (per le variabili categoriche), e altre informazioni rilevanti. Questo strumento √® essenziale per comprendere e analizzare correttamente il dataset.\nSi presti particolare attenzione alle guide di stile per la denominazione delle variabili e la codifica dei valori delle risposte.\n\n15.4.1 Esempio in R\n\nEcco come tradurre i passi per creare un dizionario dei dati in R, utilizzando il pacchetto tibble per creare il dizionario e writexl o readr per esportarlo in formato .xlsx o .csv.\n\n\nIdentificare le variabili: Elencare tutte le variabili presenti nel dataset.\n\nDescrivere ogni variabile: Per ciascuna variabile, definire il tipo (ad esempio, integer, numeric, character), il range di valori accettabili o le categorie, e fornire una descrizione chiara.\n\nSalvare il dizionario dei dati: Il dizionario pu√≤ essere salvato in un file .csv o .xlsx per una facile consultazione.\n\n\nsvy\n#&gt;   stu_id grade_level math1 math2 math3 math4\n#&gt; 1   1347           9     2     1     3     3\n#&gt; 2   1368          10     3     2     2     2\n#&gt; 3   1377           9     4     4     4     4\n#&gt; 4   1387          11     3     3     4     4\n#&gt; 6   1399          12     4     1     3     1\n\nCreeremo un dizionario dei dati per un dataset di esempio e lo salveremo sia in formato CSV che Excel.\n\nlibrary(tibble)\nlibrary(readr)\nlibrary(writexl)\n\n# Creazione del Dizionario dei Dati\ndata_dict &lt;- tibble(\n  `Variable Name` = c(\n    \"stu_id\",\n    \"svy_date\",\n    \"grade_level\",\n    \"math1\",\n    \"math2\",\n    \"math3\",\n    \"math4\"\n  ),\n  `Type` = c(\n    \"integer\",\n    \"datetime\",\n    \"integer\",\n    \"integer\",\n    \"integer\",\n    \"numeric\",\n    \"numeric\"\n  ),\n  `Description` = c(\n    \"Student ID\",\n    \"Survey Date\",\n    \"Grade Level\",\n    \"Math Response 1 (1: Strongly Disagree, 4: Strongly Agree)\",\n    \"Math Response 2 (1: Strongly Disagree, 4: Strongly Agree)\",\n    \"Math Response 3 (1: Strongly Disagree, 4: Strongly Agree)\",\n    \"Math Response 4 (1: Strongly Disagree, 4: Strongly Agree)\"\n  ),\n  `Range/Values` = c(\n    \"1347-1399\",\n    \"2023-02-13 to 2023-02-14\",\n    \"9-12\",\n    \"1-4\",\n    \"1-4\",\n    \"1.0-4.0 (NA allowed)\",\n    \"1.0-4.0 (NA allowed)\"\n  )\n)\n\n# Visualizza il Dizionario dei Dati\nprint(data_dict)\n#&gt; # A tibble: 7 √ó 4\n#&gt;   `Variable Name` Type     Description                       `Range/Values` \n#&gt;   &lt;chr&gt;           &lt;chr&gt;    &lt;chr&gt;                             &lt;chr&gt;          \n#&gt; 1 stu_id          integer  Student ID                        1347-1399      \n#&gt; 2 svy_date        datetime Survey Date                       2023-02-13 to ‚Ä¶\n#&gt; 3 grade_level     integer  Grade Level                       9-12           \n#&gt; 4 math1           integer  Math Response 1 (1: Strongly Dis‚Ä¶ 1-4            \n#&gt; 5 math2           integer  Math Response 2 (1: Strongly Dis‚Ä¶ 1-4            \n#&gt; 6 math3           numeric  Math Response 3 (1: Strongly Dis‚Ä¶ 1.0-4.0 (NA al‚Ä¶\n#&gt; 7 math4           numeric  Math Response 4 (1: Strongly Dis‚Ä¶ 1.0-4.0 (NA al‚Ä¶\n\n# Salva il Dizionario dei Dati in un file CSV\nwrite_csv(data_dict, here::here(\"data\", \"processed\", \"data_dictionary.csv\"))\n\n# Salva il Dizionario dei Dati in un file Excel\nwrite_xlsx(data_dict, here::here(\"data\", \"processed\", \"data_dictionary.xlsx\"))\n\nOutput Atteso: file CSV (data_dictionary.csv).\n\ndata_dict &lt;- rio::import(\n  here::here(\"data\", \"processed\", \"data_dictionary.csv\")\n)\n\n\nprint(data_dict)\n#&gt;   Variable Name     Type\n#&gt; 1        stu_id  integer\n#&gt; 2      svy_date datetime\n#&gt; 3   grade_level  integer\n#&gt; 4         math1  integer\n#&gt; 5         math2  integer\n#&gt; 6         math3  numeric\n#&gt; 7         math4  numeric\n#&gt;                                                 Description\n#&gt; 1                                                Student ID\n#&gt; 2                                               Survey Date\n#&gt; 3                                               Grade Level\n#&gt; 4 Math Response 1 (1: Strongly Disagree, 4: Strongly Agree)\n#&gt; 5 Math Response 2 (1: Strongly Disagree, 4: Strongly Agree)\n#&gt; 6 Math Response 3 (1: Strongly Disagree, 4: Strongly Agree)\n#&gt; 7 Math Response 4 (1: Strongly Disagree, 4: Strongly Agree)\n#&gt;               Range/Values\n#&gt; 1                1347-1399\n#&gt; 2 2023-02-13 to 2023-02-14\n#&gt; 3                     9-12\n#&gt; 4                      1-4\n#&gt; 5                      1-4\n#&gt; 6     1.0-4.0 (NA allowed)\n#&gt; 7     1.0-4.0 (NA allowed)\n\n\n15.4.1.1 Uso del pacchetto dataMeta\n\nIl pacchetto dataMeta √® progettato per generare metadati e dizionari dei dati in modo strutturato.\n\nlibrary(dataMeta)\nlibrary(tibble)\n\n# Descrizioni delle variabili\nvariable_descriptions &lt;- c(\n  \"Student ID\",\n  \"Grade Level\",\n  \"Math Response 1 (1: Strongly Disagree, 4: Strongly Agree)\",\n  \"Math Response 2 (1: Strongly Disagree, 4: Strongly Agree)\",\n  \"Math Response 3 (1: Strongly Disagree, 4: Strongly Agree)\",\n  \"Math Response 4 (1: Strongly Disagree, 4: Strongly Agree)\"\n)\n\nvar_type &lt;- c(1, 0, 0, 0, 0, 0)\n\nlinker &lt;- build_linker(\n  svy, \n  variable_description = variable_descriptions, \n  variable_type = var_type\n)\n\ndict &lt;- build_dict(\n  my.data = svy, \n  linker = linker, \n  option_description = NULL, \n  prompt_varopts = FALSE\n)\n\nkable(dict, format = \"html\", caption = \"Data dictionary for original dataset\")\n\n\nData dictionary for original dataset\n\nvariable_name\nvariable_description\nvariable_options\n\n\n\ngrade_level\nGrade Level\n9 to 12\n\n\nmath1\nMath Response 1 (1: Strongly Disagree, 4: Strongly Agree)\n2 to 4\n\n\nmath2\nMath Response 2 (1: Strongly Disagree, 4: Strongly Agree)\n1 to 4\n\n\nmath3\nMath Response 3 (1: Strongly Disagree, 4: Strongly Agree)\n2 to 4\n\n\nmath4\nMath Response 4 (1: Strongly Disagree, 4: Strongly Agree)\n1 to 4\n\n\nstu_id\nStudent ID\n1347\n\n\n\n\n1368\n\n\n\n\n1377\n\n\n\n\n1387\n\n\n\n\n1399\n\n\n\n\n\n\n15.4.1.2 Uso del pacchetto skimr\n\nIl pacchetto skimr √® utile per generare riassunti dettagliati delle variabili, che possono essere utilizzati come base per un dizionario.\n\nlibrary(skimr)\n\n# Riassunto del dataset\nskim_dict &lt;- skim(svy)\n\nkable(skim_dict, format = \"html\", caption = \"Data dictionary for original dataset\")\n\n\nData dictionary for original dataset\n\nskim_type\nskim_variable\nn_missing\ncomplete_rate\nnumeric.mean\nnumeric.sd\nnumeric.p0\nnumeric.p25\nnumeric.p50\nnumeric.p75\nnumeric.p100\nnumeric.hist\n\n\n\nnumeric\nstu_id\n0\n1\n1375.6\n19.7180\n1347\n1368\n1377\n1387\n1399\n‚ñÉ‚ñÅ‚ñá‚ñÉ‚ñÉ\n\n\nnumeric\ngrade_level\n0\n1\n10.2\n1.3038\n9\n9\n10\n11\n12\n‚ñá‚ñÉ‚ñÅ‚ñÉ‚ñÉ\n\n\nnumeric\nmath1\n0\n1\n3.2\n0.8367\n2\n3\n3\n4\n4\n‚ñÉ‚ñÅ‚ñá‚ñÅ‚ñá\n\n\nnumeric\nmath2\n0\n1\n2.2\n1.3038\n1\n1\n2\n3\n4\n‚ñá‚ñÉ‚ñÅ‚ñÉ‚ñÉ\n\n\nnumeric\nmath3\n0\n1\n3.2\n0.8367\n2\n3\n3\n4\n4\n‚ñÉ‚ñÅ‚ñá‚ñÅ‚ñá\n\n\nnumeric\nmath4\n0\n1\n2.8\n1.3038\n1\n2\n3\n4\n4\n‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñá",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#riflessioni-conclusive",
    "href": "chapters/eda/02_data_cleaning.html#riflessioni-conclusive",
    "title": "15¬† Flusso di lavoro per la pulizia dei dati",
    "section": "\n15.5 Riflessioni Conclusive",
    "text": "15.5 Riflessioni Conclusive\nNel processo di analisi dei dati, la fase di pulizia e pre-elaborazione √® cruciale per garantire la qualit√† e l‚Äôintegrit√† dei risultati finali. Sebbene questa fase possa sembrare meno interessante rispetto all‚Äôanalisi vera e propria, essa costituisce la base su cui si costruiscono tutte le successive elaborazioni e interpretazioni. Attraverso una serie di passaggi strutturati, come quelli illustrati in questo capitolo, √® possibile trasformare dati grezzi e disordinati in un dataset pulito, coerente e pronto per l‚Äôanalisi. La cura nella gestione dei dati, dalla rimozione di duplicati alla creazione di un dizionario dei dati, √® fondamentale per ottenere risultati affidabili e riproducibili.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#esercizi",
    "href": "chapters/eda/02_data_cleaning.html#esercizi",
    "title": "15¬† Flusso di lavoro per la pulizia dei dati",
    "section": "\n15.6 Esercizi",
    "text": "15.6 Esercizi\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nIn questo esercizio, applicherai le tecniche di pulizia e preprocessing dei dati utilizzando il dataset SWLS. Il tuo compito √® seguire i passaggi descritti per trasformare il dataset in una forma pronta per l‚Äôanalisi.\nIstruzioni\n\n\nImporta i dati SWLS (Survey of Life Satisfaction Scale). Introduci almeno due dati mancanti nei dati e almeno un duplicato.\n\nControlla i dati: verifica la struttura e individua eventuali anomalie.\n\nPulisci i dati:\n\nRimuovi eventuali duplicati.\nGestisci i valori mancanti in modo appropriato.\nRinomina le variabili per una maggiore chiarezza.\nStandardizza alcune variabili per l‚Äôanalisi.\n\n\n\nDocumenta le modifiche effettuate.\n\nEsporta il dataset pulito.\n\nConsegna\n\nSalva il tuo file Quarto con il nome swls_cleaning.qmd.\n\nUsa questo header YAML:\n---\ntitle: \"Assegnamento: Pulizia e Preprocessing dei Dati SWLS\"\nauthor: \"Nome Studente\"\ndate: \"2025-03-26\"\nformat: html\n---\n\nAssicurati che il codice sia commentato e spiegato chiaramente.\nEsporta il dataset pulito e allegalo alla consegna.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/02_data_cleaning.html#informazioni-sullambiente-di-sviluppo",
    "title": "15¬† Flusso di lavoro per la pulizia dei dati",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] skimr_2.1.5       dataMeta_0.1.1    writexl_1.5.2     pointblank_0.12.2\n#&gt;  [5] haven_2.5.4       labelled_2.14.0   mice_3.17.0       thematic_0.1.6   \n#&gt;  [9] MetBrewer_0.2.0   ggokabeito_0.1.0  see_0.11.0        gridExtra_2.3    \n#&gt; [13] patchwork_1.3.0   bayesplot_1.11.1  psych_2.5.3       scales_1.3.0     \n#&gt; [17] markdown_2.0      knitr_1.50        lubridate_1.9.4   forcats_1.0.0    \n#&gt; [21] stringr_1.5.1     dplyr_1.1.4       purrr_1.0.4       readr_2.1.5      \n#&gt; [25] tidyr_1.3.1       tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0  \n#&gt; [29] rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] Rdpack_2.6.3      mnormt_2.1.1      rlang_1.1.5       magrittr_2.0.3   \n#&gt;  [5] compiler_4.4.2    vctrs_0.6.5       pkgconfig_2.0.3   shape_1.4.6.1    \n#&gt;  [9] crayon_1.5.3      fastmap_1.2.0     backports_1.5.0   utf8_1.2.4       \n#&gt; [13] blastula_0.3.5    rmarkdown_2.29    tzdb_0.5.0        nloptr_2.2.1     \n#&gt; [17] bit_4.6.0         xfun_0.51         glmnet_4.1-8      jomo_2.7-6       \n#&gt; [21] litedown_0.6      jsonlite_1.9.1    pan_1.9           broom_1.0.7      \n#&gt; [25] parallel_4.4.2    R6_2.6.1          stringi_1.8.4     boot_1.3-31      \n#&gt; [29] rpart_4.1.24      Rcpp_1.0.14       iterators_1.0.14  base64enc_0.1-3  \n#&gt; [33] pacman_0.5.1      R.utils_2.13.0    Matrix_1.7-3      splines_4.4.2    \n#&gt; [37] nnet_7.3-20       timechange_0.3.0  tidyselect_1.2.1  rstudioapi_0.17.1\n#&gt; [41] codetools_0.2-20  lattice_0.22-6    withr_3.0.2       evaluate_1.0.3   \n#&gt; [45] survival_3.8-3    xml2_1.3.8        pillar_1.10.1     foreach_1.5.2    \n#&gt; [49] reformulas_0.4.0  generics_0.1.3    vroom_1.6.5       rprojroot_2.0.4  \n#&gt; [53] hms_1.1.3         munsell_0.5.1     commonmark_1.9.5  minqa_1.2.8      \n#&gt; [57] glue_1.8.0        tools_4.4.2       data.table_1.17.0 lme4_1.1-36      \n#&gt; [61] grid_4.4.2        rbibutils_2.3     colorspace_2.1-1  nlme_3.1-167     \n#&gt; [65] repr_1.1.7        cli_3.6.4         gt_0.11.1         gtable_0.3.6     \n#&gt; [69] R.methodsS3_1.8.2 sass_0.4.9        digest_0.6.37     htmlwidgets_1.6.4\n#&gt; [73] farver_2.1.2      htmltools_0.5.8.1 R.oo_1.27.0       lifecycle_1.0.4  \n#&gt; [77] mitml_0.4-5       bit64_4.6.0-1     MASS_7.3-65",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#bibliografia",
    "href": "chapters/eda/02_data_cleaning.html#bibliografia",
    "title": "15¬† Flusso di lavoro per la pulizia dei dati",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBuchanan, E. M., Crain, S. E., Cunningham, A. L., Johnson, H. R., Stash, H., Papadatou-Pastou, M., Isager, P. M., Carlsson, R., & Aczel, B. (2021). Getting started creating data dictionaries: How to create a shareable data set. Advances in Methods and Practices in Psychological Science, 4(1), 2515245920928007.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html",
    "href": "chapters/eda/04_exploring_qualitative_data.html",
    "title": "16¬† Esplorare i dati qualitativi",
    "section": "",
    "text": "16.1 Introduzione\nIn questo capitolo ci concentreremo sull‚Äôanalisi dei dati qualitativi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#il-dataset-penguins",
    "href": "chapters/eda/04_exploring_qualitative_data.html#il-dataset-penguins",
    "title": "16¬† Esplorare i dati qualitativi",
    "section": "\n16.2 Il dataset penguins\n",
    "text": "16.2 Il dataset penguins\n\nPer fornire esempi pratici, in questo capitolo utilizzeremo il dataset palmerpenguins, messo a disposizione da Allison Horst. I dati sono stati raccolti e resi disponibili da Dr.¬†Kristen Gorman e dalla Palmer Station, parte del programma di ricerca ecologica a lungo termine Long Term Ecological Research Network. Il dataset contiene informazioni su 344 pinguini, appartenenti a 3 diverse specie, raccolte su 3 isole dell‚Äôarcipelago di Palmer, in Antartide. Per semplicit√†, i dati sono organizzati nel file penguins.csv.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#importare-i-dati",
    "href": "chapters/eda/04_exploring_qualitative_data.html#importare-i-dati",
    "title": "16¬† Esplorare i dati qualitativi",
    "section": "\n16.3 Importare i Dati",
    "text": "16.3 Importare i Dati\nPossiamo caricare i dati grezzi dal file penguins.csv in un DataFrame con il seguente comando:\n\nd &lt;- rio::import(here::here(\"data\", \"penguins.csv\"))\n\nEsaminiamo i dati.\n\nglimpse(d)\n#&gt; Rows: 344\n#&gt; Columns: 8\n#&gt; $ species           &lt;chr&gt; \"Adelie\", \"Adelie\", \"Adelie\", \"Adelie\", \"Adelie\"‚Ä¶\n#&gt; $ island            &lt;chr&gt; \"Torgersen\", \"Torgersen\", \"Torgersen\", \"Torgerse‚Ä¶\n#&gt; $ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34‚Ä¶\n#&gt; $ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18‚Ä¶\n#&gt; $ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190,‚Ä¶\n#&gt; $ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 34‚Ä¶\n#&gt; $ sex               &lt;chr&gt; \"male\", \"female\", \"female\", NA, \"female\", \"male\"‚Ä¶\n#&gt; $ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, ‚Ä¶\n\nPer semplicit√†, rimuoviamo le righe con valori mancanti con la seguente istruzione:\n\ndf &lt;- d |&gt;\n  drop_na()",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#tabelle-di-contingenza",
    "href": "chapters/eda/04_exploring_qualitative_data.html#tabelle-di-contingenza",
    "title": "16¬† Esplorare i dati qualitativi",
    "section": "\n16.4 Tabelle di Contingenza",
    "text": "16.4 Tabelle di Contingenza\nUna tabella di contingenza √® uno strumento utilizzato per riassumere i dati di due variabili categoriali, ovvero variabili qualitative che assumono valori all‚Äôinterno di un insieme finito di categorie. In una tabella di contingenza, ogni cella mostra quante volte si √® verificata una combinazione specifica di categorie per le due variabili considerate.\nPer esempio, se prendiamo in esame due variabili categoriali come ‚Äúisland‚Äù e ‚Äúspecies‚Äù all‚Äôinterno di un DataFrame df, ciascuna delle quali rappresenta rispettivamente l‚Äôisola di provenienza e la specie dei pinguini, possiamo costruire una tabella che mostra quante volte ciascuna combinazione di ‚Äúisland‚Äù e ‚Äúspecies‚Äù appare nel nostro campione. In altre parole, la tabella di contingenza ci permette di vedere quante osservazioni ci sono per ogni combinazione di categorie tra queste due variabili. Usiamo la funzione tably() del pacchetto janitor.\n\ndf |&gt; \n  tabyl(island, species) |&gt; \n  adorn_totals(c(\"row\", \"col\")) \n#&gt;     island Adelie Chinstrap Gentoo Total\n#&gt;     Biscoe     44         0    119   163\n#&gt;      Dream     55        68      0   123\n#&gt;  Torgersen     47         0      0    47\n#&gt;      Total    146        68    119   333\n\nQuesta tabella di contingenza mostra la distribuzione di tre specie di pinguini (Adelie, Chinstrap, Gentoo) rispetto a tre isole (Biscoe, Dream, Torgersen). Ogni cella rappresenta il numero di pinguini di una determinata specie presenti su ciascuna isola. Ecco un‚Äôinterpretazione dettagliata:\n\n\nIsola Biscoe: Qui troviamo 44 pinguini della specie Adelie e 119 pinguini della specie Gentoo, mentre non sono presenti pinguini Chinstrap.\n\nIsola Dream: Questa isola ospita 55 pinguini Adelie e 68 pinguini Chinstrap, ma nessun pinguino della specie Gentoo.\n\nIsola Torgersen: Su quest‚Äôisola sono presenti solo 47 pinguini della specie Adelie, e nessun pinguino delle specie Chinstrap o Gentoo.\n\nPossiamo commentare dicendo:\n\nLa specie Adelie √® distribuita su tutte e tre le isole, con numeri notevoli sia su Biscoe (44), Dream (55), che Torgersen (47).\nLa specie Chinstrap si trova solo sull‚Äôisola Dream (68 esemplari) e non √® presente sulle altre due isole.\nLa specie Gentoo si trova esclusivamente sull‚Äôisola Biscoe (119 esemplari), non essendo presente su Dream e Torgersen.\n\nQuesto suggerisce una distribuzione geografica specifica delle diverse specie di pinguini, con alcune specie limitate a determinate isole e altre distribuite pi√π ampiamente.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#grafico-a-barre",
    "href": "chapters/eda/04_exploring_qualitative_data.html#grafico-a-barre",
    "title": "16¬† Esplorare i dati qualitativi",
    "section": "\n16.5 Grafico a barre",
    "text": "16.5 Grafico a barre\n\n16.5.1 Grafico a Barre con una Singola Variabile\nUn grafico a barre √® uno strumento comunemente utilizzato per rappresentare visivamente una singola variabile categoriale. Questo tipo di grafico mostra le diverse categorie su uno degli assi (solitamente l‚Äôasse orizzontale) e utilizza barre di altezza proporzionale per rappresentare la frequenza o il conteggio di ciascuna categoria sull‚Äôaltro asse (solitamente l‚Äôasse verticale).\nAd esempio, in un dataset che contiene informazioni su diverse specie di pinguini, un grafico a barre potrebbe mostrare il numero di pinguini per ciascuna specie. Le specie vengono visualizzate come etichette lungo l‚Äôasse delle ascisse, mentre l‚Äôaltezza delle barre rappresenta il numero di pinguini osservati per ciascuna specie.\nIl grafico a barre consente di confrontare le dimensioni delle categorie in modo semplice e intuitivo.\nPer i dati in esame, creiamo un grafico a barre che rappresenta il numero totale di pinguini per isola.\n\nggplot(df, aes(x = island)) +\n  geom_bar(fill = \"lightblue\") +\n  ggtitle(\"Numero totale di pinguini per isola\") +\n  xlab(\"Isola\") +\n  ylab(\"Numero di pinguini\") \n\n\n\n\n\n\n\nUn secondo grafico a barre mostra il numero totale di pinguini per specie.\n\nggplot(df, aes(x = species)) +\n  geom_bar(fill = \"lightblue\") +\n  ggtitle(\"Numero totale di pinguini per specie\") +\n  xlab(\"Specie\") +\n  ylab(\"Numero di pinguini\")\n\n\n\n\n\n\n\n\n16.5.2 Grafico a Barre con Due Variabili\n√à possibile visualizzare contemporaneamente le distribuzioni di due variabili categoriali utilizzando un grafico a barre. Questo tipo di grafico √® particolarmente utile per esaminare la relazione tra due variabili categoriali.\nIn un grafico a barre con due variabili, una delle variabili viene rappresentata sull‚Äôasse orizzontale come categoria principale, mentre la seconda variabile √® distinta tramite colori diversi o barre impilate. In questo modo, possiamo confrontare facilmente le frequenze o le proporzioni delle categorie della prima variabile, osservando allo stesso tempo come sono distribuite le categorie della seconda variabile all‚Äôinterno di ciascuna categoria principale.\nAd esempio, visualizziamo il numero di pinguini per specie e isola. A qusto fine possiamo creare un grafico a barre dove le isole sono rappresentate sull‚Äôasse delle ascisse e i diversi colori delle barre mostrano la distribuzione delle specie su ciascuna isola. Questo approccio consente di esplorare come le due variabili categoriali (specie e isola) interagiscono visivamente.\n\nggplot(df, aes(x = island, fill = species)) +\n  geom_bar(position = \"stack\") +\n  ggtitle(\"Numero di pinguini per specie e isola\") +\n  xlab(\"Isola\") +\n  ylab(\"Numero di pinguini\") +\n  labs(fill = \"Specie\") \n\n\n\n\n\n\n\nIn alternativa, √® possibile creare un grafico a barre dove le specie sono rappresentate sull‚Äôasse delle ascisse e i diversi colori delle barre mostrano la distribuzione delle isole per ciascuna specie.\n\nggplot(df, aes(x = species, fill = island)) +\n  geom_bar(position = \"stack\") +\n  ggtitle(\"Numero di pinguini per isola e specie\") +\n  xlab(\"Specie\") +\n  ylab(\"Numero di pinguini\") +\n  labs(fill = \"Isola\")\n\n\n\n\n\n\n\nIn alternativa all‚Äôuso delle frequenze assolute, possiamo rappresentare i dati utilizzando le frequenze relative. Questo approccio permette di confrontare meglio le categorie indipendentemente dal numero totale di osservazioni. Nella figura seguente, ad esempio, viene mostrata la proporzione di pinguini di ciascuna specie per ogni isola, evidenziando la distribuzione relativa delle specie su ogni isola, anzich√© il conteggio assoluto. Questa rappresentazione aiuta a visualizzare le differenze nella composizione delle specie, anche se il numero complessivo di pinguini varia tra le isole.\n\nggplot(df, aes(x = island, fill = species)) +\n  geom_bar(position = \"fill\") +\n  ggtitle(\"Proporzione di pinguini per specie e isola\") +\n  xlab(\"Isola\") +\n  ylab(\"Proporzione\") +\n  labs(fill = \"Specie\")",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#mosaic-plots",
    "href": "chapters/eda/04_exploring_qualitative_data.html#mosaic-plots",
    "title": "16¬† Esplorare i dati qualitativi",
    "section": "\n16.6 Mosaic plots",
    "text": "16.6 Mosaic plots\nIl Mosaic plot √® una tecnica di visualizzazione particolarmente adatta per rappresentare tabelle di contingenza. Questo tipo di grafico somiglia a un grafico a barre impilate standard, ma con un vantaggio importante: oltre a visualizzare la suddivisione interna delle categorie, permette di vedere anche le dimensioni relative dei gruppi della variabile principale.\nIn altre parole, il Mosaic plot non solo mostra come si distribuiscono le categorie di una variabile secondaria all‚Äôinterno di ogni gruppo della variabile principale, ma fornisce anche un‚Äôidea visiva della grandezza complessiva dei gruppi. Questo lo rende uno strumento utile per analizzare e interpretare le relazioni tra due variabili categoriali, evidenziando sia la proporzione all‚Äôinterno di ciascun gruppo, sia la grandezza relativa tra i gruppi stessi.\n\nmosaic(\n  ~ species + island, \n  data = df, \n  main = \"Mosaic Plot of Species and Island\",\n  shade = TRUE\n)\n\n\n\n\n\n\n\n\n\nisland: Variabile rappresentata come suddivisione orizzontale all‚Äôinterno di ogni gruppo di species (variabile principale).\n\nspecies: Variabile rappresentata lungo l‚Äôasse verticale (variabile secondaria suddivisa all‚Äôinterno di ogni gruppo di island).\n\n\n16.6.0.1 Interpretazione\n\n\nDimensione dei Rettangoli:\n\nLa larghezza dei rettangoli corrisponde alla dimensione relativa dei gruppi della variabile island.\nL‚Äôaltezza dei rettangoli rappresenta la proporzione delle categorie di species all‚Äôinterno di ciascun gruppo di island.\n\n\n\nColorazione (se shade = TRUE):\n\nI colori indicano deviazioni rispetto all‚Äôindipendenza statistica tra le variabili.\nUn rettangolo scuro rappresenta una frequenza maggiore o minore di quella attesa in caso di indipendenza tra species e island.\n\n\n\nOsservazioni Specifiche:\n\n\nRettangoli alti e larghi: Indicano una categoria di species molto rappresentata su un‚Äôisola specifica.\n\nRettangoli sottili o stretti: Indicano una rappresentazione meno significativa o assente di una specie su un‚Äôisola.\n\n\n\nIn conclusione, il Mosaic plot √® uno strumento grafico efficace per analizzare le relazioni tra due variabili categoriali. Ti permette di esplorare:\n\nLa proporzione interna delle categorie.\nLe dimensioni relative dei gruppi della variabile principale.\n\nQuesto grafico √® particolarmente utile per individuare schemi o associazioni, come una specie predominante su un‚Äôisola specifica o una distribuzione equilibrata tra gruppi. La sua rappresentazione intuitiva lo rende ideale per ricerche in psicologia, scienze sociali e biologia.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#proporzioni-di-riga-e-colonna",
    "href": "chapters/eda/04_exploring_qualitative_data.html#proporzioni-di-riga-e-colonna",
    "title": "16¬† Esplorare i dati qualitativi",
    "section": "\n16.7 Proporzioni di Riga e Colonna",
    "text": "16.7 Proporzioni di Riga e Colonna\nNelle sezioni precedenti abbiamo esaminato la visualizzazione di due variabili categoriali utilizzando grafici a barre e Mosaic plot. Tuttavia, non abbiamo ancora discusso come vengono calcolate le proporzioni mostrate in questi grafici. In questa sezione ci concentreremo sulla suddivisione frazionaria di una variabile rispetto a un‚Äôaltra, esplorando come possiamo modificare la nostra tabella di contingenza per ottenere una visione pi√π dettagliata delle proporzioni.\nQuesto ci permetter√† di comprendere meglio le relazioni tra le due variabili, visualizzando non solo i conteggi assoluti, ma anche le proporzioni relative per riga o per colonna. Le proporzioni di riga mostrano la distribuzione di una variabile all‚Äôinterno delle categorie di un‚Äôaltra, mentre le proporzioni di colonna evidenziano la distribuzione inversa.\nCalcoliamo le proporzioni di specie per isola.\n\ndf %&gt;%\n  tabyl(island, species) %&gt;%  # Crea la tabella di contingenza\n  adorn_percentages(\"row\") %&gt;%  # Calcola le proporzioni per riga\n  adorn_totals(\"col\") %&gt;%  # Aggiunge la colonna dei totali\n  adorn_pct_formatting(digits = 2)  # Formatta le percentuali con 2 decimali\n#&gt;     island  Adelie Chinstrap Gentoo   Total\n#&gt;     Biscoe  26.99%     0.00% 73.01% 100.00%\n#&gt;      Dream  44.72%    55.28%  0.00% 100.00%\n#&gt;  Torgersen 100.00%     0.00%  0.00% 100.00%\n\nCalcoliamo nuovamente le proporzioni, ma questa volta in funzione delle colonne (per isola).\n\ndf |&gt; \n  tabyl(island, species) |&gt; \n  adorn_percentages(\"col\") |&gt; \n  adorn_totals(\"row\") |&gt; \n  adorn_pct_formatting(digits = 2) # Formatta le percentuali con 2 decimali\n#&gt;     island  Adelie Chinstrap  Gentoo\n#&gt;     Biscoe  30.14%     0.00% 100.00%\n#&gt;      Dream  37.67%   100.00%   0.00%\n#&gt;  Torgersen  32.19%     0.00%   0.00%\n#&gt;      Total 100.00%   100.00% 100.00%",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#confronto-tra-gruppi",
    "href": "chapters/eda/04_exploring_qualitative_data.html#confronto-tra-gruppi",
    "title": "16¬† Esplorare i dati qualitativi",
    "section": "\n16.8 Confronto tra Gruppi",
    "text": "16.8 Confronto tra Gruppi\nAlcune delle analisi pi√π interessanti emergono confrontando i dati numerici tra diversi gruppi. In questa sezione approfondiremo alcune delle tecniche che abbiamo gi√† esplorato per visualizzare i dati numerici di pi√π gruppi su uno stesso grafico e introdurremo nuovi metodi per confrontare i dati numerici tra gruppi. Queste tecniche ci permetteranno di osservare meglio le differenze e le somiglianze tra gruppi, mettendo in evidenza tendenze, variazioni e altre caratteristiche rilevanti.\nQui consideriamo due variabili qualitative. Creiamo un grafico a barre per confrontare la distribuzione del genere per specie.\n\nggplot(df, aes(x = species, fill = sex)) +\n  geom_bar(position = \"dodge\") +\n  ggtitle(\"Distribuzione del genere per specie\") +\n  xlab(\"Specie\") +\n  ylab(\"Conteggio\")\n\n\n\n\n\n\n\nSpesso, i confronti pi√π interessanti riguardano come una variabile numerica varia in base a una o pi√π categorie. Questo tipo di analisi ci aiuta a capire differenze tra gruppi e a individuare modelli o tendenze.\nNel grafico seguente, confrontiamo la distribuzione del peso corporeo (body_mass_g) in base alla specie e al genere. Le aree colorate rappresentano come si distribuisce il peso per maschi e femmine all‚Äôinterno di ciascuna specie. Le linee pi√π strette al centro delle aree colorate aggiungono ulteriori dettagli, mostrando i valori pi√π comuni e come si concentrano i dati per ciascun gruppo.\n\nggplot(df, aes(x = species, y = body_mass_g, fill = sex)) +\n  geom_violin(\n    position = position_dodge(width = 0.9), alpha = 0.5\n  ) +\n  geom_boxplot(\n    position = position_dodge(width = 0.9), width = 0.2, alpha = 0.8\n  ) +\n  ggtitle(\n    \"Distribuzione della massa corporea\\nin base alla specie e al genere\"\n  ) +\n  xlab(\"Specie\") +\n  ylab(\"Massa corporea (g)\") +\n  labs(fill = \"Genere\")\n\n\n\n\n\n\n\n\n\nAree colorate (grafico a violino):\n\nRappresentano l‚Äôintera distribuzione dei pesi per ogni gruppo (specie e genere). Pi√π l‚Äôarea √® larga in un punto, maggiore √® il numero di pinguini con quel peso.\n\n\n\nLinee strette al centro (boxplot):\n\nForniscono un riassunto visivo dei dati, mostrando dove i pesi si concentrano maggiormente e quanto variano all‚Äôinterno di ciascun gruppo.\n\n\n\nCosa possiamo osservare:\n\nPossiamo vedere facilmente se i maschi e le femmine di una stessa specie tendono ad avere pesi simili o differenti, e se c‚Äô√® una certa sovrapposizione tra i due gruppi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#esercizi",
    "href": "chapters/eda/04_exploring_qualitative_data.html#esercizi",
    "title": "16¬† Esplorare i dati qualitativi",
    "section": "\n16.9 Esercizi",
    "text": "16.9 Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nIn questo esercizio analizzerai i dati qualitativi raccolti mediante la scala SWLS, concentrandoti su due variabili categoriali:\n\n\nGenere (gender): maschio / femmina.\n\nTipo di scuola superiore (school_type): liceo classico o scientifico vs tutto il resto.\n\nDovrai creare tabelle di contingenza e rappresentazioni grafiche per esplorare le relazioni tra queste variabili.\nImportazione dei dati\nImporta i dati da un file CSV e visualizza la loro struttura.\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(here)\n\n# Importa i dati\nswls_data &lt;- read_csv(here(\"data\", \"swls_students.csv\"))\n\n# Esamina i dati\nglimpse(swls_data)\nTabelle di Contingenza\n\nCrea una tabella di contingenza tra gender e school_type.\nCalcola le proporzioni di riga e colonna.\n\n# Tabella di contingenza\nswls_data |&gt; \n  tabyl(gender, school_type) |&gt; \n  adorn_totals(c(\"row\", \"col\"))\nCalcola ora le proporzioni relative.\n# Proporzioni di riga\nswls_data |&gt; \n  tabyl(gender, school_type) |&gt; \n  adorn_percentages(\"row\") |&gt; \n  adorn_pct_formatting(digits = 2)\n# Proporzioni di colonna\nswls_data |&gt; \n  tabyl(gender, school_type) |&gt; \n  adorn_percentages(\"col\") |&gt; \n  adorn_pct_formatting(digits = 2)\nVisualizzazione Grafica\n\nCrea un grafico a barre per visualizzare il numero di studenti per tipo di scuola.\nCrea un grafico a barre per la distribuzione del genere per tipo di scuola.\n\nggplot(swls_data, aes(x = school_type)) +\n  geom_bar() +\n  ggtitle(\"Numero di studenti per tipo di scuola\") +\n  xlab(\"Tipo di scuola\") +\n  ylab(\"Numero di studenti\")\nggplot(swls_data, aes(x = school_type, fill = gender)) +\n  geom_bar(position = \"dodge\") +\n  ggtitle(\"Distribuzione del genere per tipo di scuola\") +\n  xlab(\"Tipo di scuola\") +\n  ylab(\"Numero di studenti\") +\n  labs(fill = \"Genere\")\nDomande per la riflessione\n\nQuale tipo di scuola ha il maggior numero di studenti?\nCi sono differenze nella distribuzione del genere tra i tipi di scuola?\n\nConsegna\n\nCompila il file .qmd con il tuo codice e commenti.\nEsporta il documento in formato HTML o PDF.\nCarica il file su Moodle.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/04_exploring_qualitative_data.html#informazioni-sullambiente-di-sviluppo",
    "title": "16¬† Esplorare i dati qualitativi",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] grid      stats     graphics  grDevices utils     datasets  methods  \n#&gt; [8] base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] janitor_2.2.1     vcd_1.4-13        viridis_0.6.5     viridisLite_0.4.2\n#&gt;  [5] thematic_0.1.6    MetBrewer_0.2.0   ggokabeito_0.1.0  see_0.11.0       \n#&gt;  [9] gridExtra_2.3     patchwork_1.3.0   bayesplot_1.11.1  psych_2.5.3      \n#&gt; [13] scales_1.3.0      markdown_2.0      knitr_1.50        lubridate_1.9.4  \n#&gt; [17] forcats_1.0.0     stringr_1.5.1     dplyr_1.1.4       purrr_1.0.4      \n#&gt; [21] readr_2.1.5       tidyr_1.3.1       tibble_3.2.1      ggplot2_3.5.1    \n#&gt; [25] tidyverse_2.0.0   rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      xfun_0.51         htmlwidgets_1.6.4 lattice_0.22-6   \n#&gt;  [5] tzdb_0.5.0        vctrs_0.6.5       tools_4.4.2       generics_0.1.3   \n#&gt;  [9] parallel_4.4.2    pacman_0.5.1      R.oo_1.27.0       pkgconfig_2.0.3  \n#&gt; [13] data.table_1.17.0 lifecycle_1.0.4   compiler_4.4.2    farver_2.1.2     \n#&gt; [17] munsell_0.5.1     mnormt_2.1.1      snakecase_0.11.1  htmltools_0.5.8.1\n#&gt; [21] yaml_2.3.10       pillar_1.10.1     MASS_7.3-65       R.utils_2.13.0   \n#&gt; [25] nlme_3.1-167      tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4    \n#&gt; [29] labeling_0.4.3    rprojroot_2.0.4   fastmap_1.2.0     colorspace_2.1-1 \n#&gt; [33] cli_3.6.4         magrittr_2.0.3    withr_3.0.2       timechange_0.3.0 \n#&gt; [37] rmarkdown_2.29    zoo_1.8-13        R.methodsS3_1.8.2 hms_1.1.3        \n#&gt; [41] evaluate_1.0.3    lmtest_0.9-40     rlang_1.1.5       glue_1.8.0       \n#&gt; [45] rstudioapi_0.17.1 jsonlite_1.9.1    R6_2.6.1",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html",
    "href": "chapters/eda/05_exploring_numeric_data.html",
    "title": "17¬† Esplorare i dati numerici",
    "section": "",
    "text": "Introduzione\nIn questo capitolo ci concentreremo sull‚Äôanalisi dei dati numerici. In particolare, esamineremo le distribuzioni di frequenza e i quantili, insieme alle tecniche di visualizzazione pi√π comuni, come l‚Äôistogramma, l‚Äôistogramma smussato e il box-plot. Tratteremo sia gli aspetti computazionali che quelli interpretativi di queste misure, fornendo strumenti utili non solo per una comprensione personale, ma anche per la comunicazione efficace dei risultati, in particolare con chi utilizza questi dati per prendere decisioni pratiche nel mondo reale.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#i-dati-sulle-aspettative-negative-nella-depressione",
    "href": "chapters/eda/05_exploring_numeric_data.html#i-dati-sulle-aspettative-negative-nella-depressione",
    "title": "17¬† Esplorare i dati numerici",
    "section": "\n17.1 I dati sulle aspettative negative nella depressione",
    "text": "17.1 I dati sulle aspettative negative nella depressione\nConsideriamo i dati relativi alle aspettative negative, individuate come un meccanismo chiave nel mantenimento della depressione (Zetsche et al., 2019). Supponiamo di voler analizzare la distribuzione di una singola variabile quantitativa.\nImportiamo i dati:\n\ndf &lt;- rio::import(here::here(\"data\", \"data.mood.csv\"))\n\n\n17.1.1 Data Wrangling\nPer questo esercizio, ci concentreremo sulle variabili esm_id (il codice del soggetto), group (il gruppo) e bdi (il valore BDI-II).\n\ndf &lt;- df |&gt; \n  dplyr::select(\"esm_id\", \"group\", \"bdi\")\ndf |&gt; \n  head()\n#&gt;   esm_id group bdi\n#&gt; 1     10   mdd  25\n#&gt; 2     10   mdd  25\n#&gt; 3     10   mdd  25\n#&gt; 4     10   mdd  25\n#&gt; 5     10   mdd  25\n#&gt; 6     10   mdd  25\n\nSe elenchiamo le modalit√† presenti in group utilizzando il metodo unique(), scopriamo che corrispondono a mdd (pazienti) e ctl (controlli sani).\n\ndf$group |&gt; \n  unique()\n#&gt; [1] \"mdd\" \"ctl\"\n\nRimuoviamo i duplicati per ottenere un unico valore BDI-II per ogni soggetto:\n\ndf &lt;- df[!duplicated(df), ]\n\nVerifichiamo di avere ottenuto il risultato desiderato.\n\ndim(df)\n#&gt; [1] 67  3\n\n\nhead(df)\n#&gt;    esm_id group bdi\n#&gt; 1      10   mdd  25\n#&gt; 15      9   mdd  30\n#&gt; 30      6   mdd  26\n#&gt; 46      7   mdd  35\n#&gt; 65     12   mdd  44\n#&gt; 83     16   mdd  30\n\nSi noti che il nuovo DataFrame (con 67 righe) conserva il ‚Äúnome‚Äù delle righe (ovvero, l‚Äôindice di riga) del DataFrame originario (con 1188 righe). Per esempio, il secondo soggetto (con codice identificativo 9) si trova sulla seconda riga del DataFrame, ma il suo indice di riga √® 15. Questo non ha nessuna conseguenza perch√© non useremo l‚Äôindice di riga nelle analisi seguenti.\nEliminiamo eventuali valori mancanti:\n\ndf &lt;- df[!is.na(df$bdi), ]\n\nOtteniamo cos√¨ il DataFrame finale per gli scopi presenti (66 righe e 3 colonne):\n\ndim(df)\n#&gt; [1] 66  3\n\n\n17.1.2 Anteprima dei Dati\nPrima di approfondire l‚Äôanalisi, √® fondamentale esaminare una anteprima dei dati per comprenderne struttura, formati e potenziali anomalie.\nLa funzione glimpse()\n\nglimpse(df)  \n#&gt; Rows: 66\n#&gt; Columns: 3\n#&gt; $ esm_id &lt;int&gt; 10, 9, 6, 7, 12, 16, 21, 18, 20, 22, 23, 25, 24, 26, 41, 31‚Ä¶\n#&gt; $ group  &lt;chr&gt; \"mdd\", \"mdd\", \"mdd\", \"mdd\", \"mdd\", \"mdd\", \"mdd\", \"mdd\", \"md‚Ä¶\n#&gt; $ bdi    &lt;int&gt; 25, 30, 26, 35, 44, 30, 22, 33, 43, 43, 24, 39, 19, 3, 0, 2‚Ä¶\n\nFornisce una panoramica compatta del dataset: numero di righe/colonne, tipo di variabili (es. chr, num, dbl) ed esempi di valori. Utile per identificare rapidamente formati errati o colonne non attese.\nLa funzione summary()\n\nsummary(df)  \n#&gt;      esm_id         group                bdi       \n#&gt;  Min.   :  6.0   Length:66          Min.   : 0.00  \n#&gt;  1st Qu.: 30.2   Class :character   1st Qu.: 0.25  \n#&gt;  Median : 46.5   Mode  :character   Median : 6.00  \n#&gt;  Mean   : 51.6                      Mean   :14.94  \n#&gt;  3rd Qu.: 76.8                      3rd Qu.:29.50  \n#&gt;  Max.   :104.0                      Max.   :44.00\n\nGenera statistiche descrittive per ogni colonna:\n\nPer variabili numeriche: media, mediana, quartili, min/max.\n\nPer variabili categoriche: frequenza dei livelli.\n\nSegnala valori mancanti (NA), aiutando a valutare la qualit√† dei dati.\n\nI comandi head() e tail() ci permettono di visualizzare le prime o le ultime righe di un dataset.\n\nhead(df)\n#&gt;    esm_id group bdi\n#&gt; 1      10   mdd  25\n#&gt; 15      9   mdd  30\n#&gt; 30      6   mdd  26\n#&gt; 46      7   mdd  35\n#&gt; 65     12   mdd  44\n#&gt; 83     16   mdd  30\n\n\ntail(df)\n#&gt;      esm_id group bdi\n#&gt; 1087    101   ctl   9\n#&gt; 1105     99   ctl   0\n#&gt; 1121    100   ctl   2\n#&gt; 1133    104   ctl   0\n#&gt; 1152    103   ctl   0\n#&gt; 1171    102   ctl   1\n\n\n17.1.3 Conversione da char a factor\n\nIn R, i tipi di dato character e factor rappresentano informazioni testuali, ma hanno utilizzi distinti:\n\n\ncharacter: √® una semplice stringa di testo;\n\nfactor: √® una variabile categoriale, ideale per rappresentare dati con un numero finito di categorie (livelli). I dati in formato factor sono utili per analisi statistiche, poich√© trattano i valori come categorie discrete.\n\nNel seguente esempio, convertiamo una variabile group da character a factor, in modo da poterla utilizzare come variabile categoriale:\ndf$group &lt;- as.factor(df$group)  # Converte 'group' in un factor\nSuccessivamente, il comando summary() fornisce un riepilogo della variabile categoriale, mostrando il conteggio dei valori per ciascun livello:\nsummary(df$group)",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#distribuzioni-di-frequenza",
    "href": "chapters/eda/05_exploring_numeric_data.html#distribuzioni-di-frequenza",
    "title": "17¬† Esplorare i dati numerici",
    "section": "\n17.2 Distribuzioni di Frequenza",
    "text": "17.2 Distribuzioni di Frequenza\nLe distribuzioni di frequenza sono strumenti essenziali per visualizzare e comprendere la variabilit√† di una variabile. In questo capitolo verr√† illustrato come costruire una distribuzione di frequenza e, successivamente, come generare in R una distribuzione cumulativa empirica, un istogramma, un Kernel Density Plot e un boxplot.\nA titolo esemplificativo, consideriamo i punteggi del BDI-II. Iniziamo ordinando i dati in ordine crescente:\n\ndf$bdi |&gt; sort()\n#&gt;  [1]  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  1  1  1  1  1  1\n#&gt; [25]  1  2  2  2  2  3  3  3  5  7  9 12 19 22 22 24 25 25 26 26 26 27 27 28\n#&gt; [49] 28 30 30 30 31 31 33 33 34 35 35 35 36 39 41 43 43 44\n\nUna distribuzione di frequenza evidenzia quante volte i valori di una variabile ricorrono in determinati intervalli. Ad esempio, per i punteggi del BDI-II √® consuetudine raggruppare i dati nelle seguenti classi:\n\n\n0‚Äì13: depressione minima\n\n14‚Äì19: depressione lieve-moderata\n\n20‚Äì28: depressione moderata-severa\n\n29‚Äì63: depressione severa\n\nDefinendo ciascuna classe, indicata con \\(\\Delta_i\\), come un intervallo \\([a_i, b_i)\\) o \\((a_i, b_i]\\), possiamo calcolare le seguenti misure:\n\n\nFrequenza assoluta (\\(n_i\\)): numero di osservazioni in \\(\\Delta_i\\). La somma delle frequenze assolute corrisponde al totale delle osservazioni, \\(n\\).\n\nFrequenza relativa (\\(f_i\\)): proporzione di osservazioni in \\(\\Delta_i\\), calcolata come \\(f_i = n_i/n\\); la somma delle frequenze relative √® pari a 1.\n\nFrequenza cumulata (\\(N_i\\)): somma delle frequenze assolute fino alla classe \\(i\\), ovvero \\(N_i = \\sum_{j=1}^i n_j\\).\n\nFrequenza cumulata relativa (\\(F_i\\)): somma delle frequenze relative fino alla classe \\(i\\), data da \\(F_i = \\sum_{j=1}^i f_j\\).\n\nQueste misure consentono di sintetizzare la distribuzione dei punteggi, facilitando l‚Äôinterpretazione delle caratteristiche del campione.\n\n17.2.1 Frequenze Assolute e Relative\nPer analizzare la distribuzione dei punteggi BDI-II nel dataset di Zetsche et al. (2019), √® utile creare una variabile categoriale che classifichi ogni osservazione in una delle quattro classi di gravit√† della depressione. A tal fine, utilizziamo la funzione cut(), che permette di suddividere il vettore dei punteggi (bdi) in intervalli definiti.\nNel comando seguente, il parametro breaks specifica i limiti degli intervalli, mentre include.lowest = TRUE garantisce che il valore minimo sia incluso nel primo intervallo:\n\n# Creazione della variabile categoriale per i livelli di depressione\ndf &lt;- df %&gt;% \n  mutate(\n    bdi_class = cut(\n      bdi, \n      breaks = c(0, 13.5, 19.5, 28.5, 63),\n      include.lowest = TRUE\n    )\n  )\n\nI punteggi vengono suddivisi nelle seguenti classi:\n\n\n0‚Äì13: depressione minima\n\n14‚Äì19: depressione lieve-moderata\n\n20‚Äì28: depressione moderata-severa\n\n29‚Äì63: depressione severa\n\nUna volta creata la variabile bdi_class, possiamo calcolare le frequenze assolute e relative.\n\n17.2.1.1 Frequenze Assolute\nUtilizzando la funzione table(), si ottiene il numero di osservazioni in ciascuna classe:\n\ntable(df$bdi_class)\n#&gt; \n#&gt;    [0,13.5] (13.5,19.5] (19.5,28.5]   (28.5,63] \n#&gt;          36           1          12          17\n\n\n17.2.1.2 Frequenze Relative\nCon prop.table() √® possibile determinare la proporzione di osservazioni per ogni classe:\n\nprop.table(table(df$bdi_class))\n#&gt; \n#&gt;    [0,13.5] (13.5,19.5] (19.5,28.5]   (28.5,63] \n#&gt;     0.54545     0.01515     0.18182     0.25758\n\n\n17.2.2 Distribuzioni Congiunte\nLe distribuzioni congiunte di frequenze permettono di analizzare la relazione tra due variabili, considerando tutte le possibili combinazioni dei loro valori. Ad esempio, se analizziamo le variabili bdi_class e group, la tabella congiunta mostrer√† la frequenza (assoluta o relativa) per ogni coppia di valori.\nPer ottenere la distribuzione congiunta relativa, utilizziamo:\n\nprop.table(table(df$bdi_class, df$group))\n#&gt;              \n#&gt;                   ctl     mdd\n#&gt;   [0,13.5]    0.54545 0.00000\n#&gt;   (13.5,19.5] 0.00000 0.01515\n#&gt;   (19.5,28.5] 0.00000 0.18182\n#&gt;   (28.5,63]   0.00000 0.25758\n\nIn questo modo, possiamo esaminare come le classi di punteggi BDI-II si distribuiscono all‚Äôinterno dei diversi gruppi, con la somma complessiva delle frequenze relative pari a 1.\n\n17.2.3 La Distribuzione Cumulativa Empirica\nLa distribuzione cumulativa empirica (eCDF, empirical Cumulative Distribution Function) √® un modo utile per rappresentare la distribuzione di dati numerici. Questa funzione indica la proporzione di dati che sono inferiori o uguali a un certo valore \\(a\\), per tutti i possibili valori di \\(a\\). Matematicamente, la eCDF √® definita come:\n\\[\nF(a) = \\text{Proporzione dei dati con valore} \\leq a.\n\\]\nIn altre parole, la eCDF ci dice quale frazione dei dati osservati √® minore o uguale a un determinato valore \\(a\\). Questo √® particolarmente utile per comprendere come i dati sono distribuiti e per identificare pattern o caratteristiche specifiche della distribuzione, come la presenza di bimodalit√† (cio√®, due picchi distinti nella distribuzione).\n\n17.2.3.1 Esempio con i dati di Zetsche et al. (2019)\n\nNel contesto dei dati di Zetsche et al. (2019), possiamo utilizzare la eCDF per visualizzare la distribuzione dei punteggi BDI-II. Ecco come viene rappresentata la eCDF per l‚Äôintero dataset:\n\ndf |&gt; \n  ggplot(aes(bdi)) + \n  stat_ecdf() +\n  labs(x = \"BDI\", y = \"F(BDI)\")\n\n\n\n\n\n\n\nIn questo grafico:\n\nL‚Äôasse \\(x\\) rappresenta i valori del BDI-II.\nL‚Äôasse \\(y\\) rappresenta la proporzione cumulativa dei dati, cio√® \\(F(a)\\).\n\n17.2.3.2 Interpretazione del grafico\n\n\nCrescita della curva: La curva della eCDF parte da 0 (nessun dato √® inferiore al valore minimo osservato) e cresce gradualmente fino a 1 (tutti i dati sono inferiori o uguali al valore massimo osservato).\n\nBimodalit√†: Se la curva presenta dei ‚Äúgradini‚Äù o delle aree con una pendenza pi√π ripida, questo pu√≤ indicare la presenza di bimodalit√†, ovvero due gruppi distinti di dati con caratteristiche diverse. Nel caso dei dati BDI-II, la bimodalit√† potrebbe riflettere la presenza di due sottogruppi di partecipanti con livelli di depressione diversi.\n\n17.2.3.3 Filtrare i dati per il campione clinico\nSe vogliamo analizzare solo i dati relativi al campione clinico (ad esempio, i pazienti con depressione maggiore), possiamo filtrare i dati e rappresentare la eCDF solo per questo gruppo:\n\ndf |&gt; dplyr::filter(group == \"mdd\") |&gt; \n  ggplot(aes(bdi)) + \n  stat_ecdf() +\n  labs(x = \"a\", y = \"F(a)\")\n\n\n\n\n\n\n\nIn questo caso, la eCDF ci mostrer√† come i punteggi BDI-II sono distribuiti tra i pazienti con depressione maggiore, permettendoci di identificare eventuali pattern specifici per questo gruppo.\nIn sintesi, la eCDF √® uno strumento potente per analizzare e visualizzare la distribuzione di dati numerici, specialmente quando si vogliono identificare pattern specifici o confrontare distribuzioni tra diversi gruppi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#istogramma",
    "href": "chapters/eda/05_exploring_numeric_data.html#istogramma",
    "title": "17¬† Esplorare i dati numerici",
    "section": "\n17.3 Istogramma",
    "text": "17.3 Istogramma\nSebbene il concetto di Funzione di Distribuzione Empirica Cumulativa (eCDF) venga ampiamente discusso nei testi di statistica, in pratica tale rappresentazione non √® molto diffusa. Il motivo principale √® che l‚ÄôeCDF non rende immediatamente visibili alcune caratteristiche fondamentali della distribuzione, come il valore intorno al quale essa √® centrata, se la distribuzione sia simmetrica o quali intervalli contengano il 95% dei dati, ad esempio. Gli istogrammi, invece, sono molto pi√π utilizzati perch√© facilitano notevolmente la comprensione di queste propriet√†, sacrificando solo un po‚Äô di informazione per fornire una rappresentazione pi√π intuitiva.\nUn istogramma √® un grafico che rappresenta la distribuzione delle frequenze di una variabile. Sull‚Äôasse orizzontale (ascisse) vengono indicati i limiti delle classi \\(\\Delta_i\\), mentre sull‚Äôasse verticale (ordinate) si riporta la densit√† della frequenza relativa della variabile \\(X\\) per ciascuna classe \\(\\Delta_i\\).\nPer descrivere formalmente la densit√† della frequenza relativa, si utilizza una funzione costante a tratti definita come:\n\\[\n\\varphi_n(x) = \\frac{f_i}{b_i - a_i},\n\\]\ndove:\n\n\n\\(f_i\\) √® la frequenza relativa della classe \\(\\Delta_i\\),\n\n\\(b_i - a_i\\) √® l‚Äôampiezza della classe \\(\\Delta_i\\).\n\nIn questo modo, l‚Äôarea del rettangolo corrispondente a \\(\\Delta_i\\) in un istogramma risulta proporzionale alla frequenza relativa \\(f_i\\). Poich√© la somma delle frequenze relative deve essere pari a 1, l‚Äôarea totale di un istogramma delle frequenze relative risulta anch‚Äôessa uguale a 1, corrispondendo alla somma delle aree di tutti i rettangoli.\nGli istogrammi costituiscono quindi uno strumento essenziale per visualizzare e comprendere le principali caratteristiche di una distribuzione, agevolando l‚Äôanalisi della sua forma, della sua tendenza centrale e della sua dispersione.\nPer fare un esempio, costruiamo un istogramma per i valori BDI-II di Zetsche et al. (2019). Con i quattro intervalli individuati dai cut-off del BDI-II creiamo una prima versione dell‚Äôistogramma ‚Äì si notino le frequenze assolute sull‚Äôasse delle ordinate.\n\nggplot(df, aes(x = bdi)) +\n  geom_histogram(\n    color = \"black\",\n    fill = \"lightblue\",\n    breaks = c(0, 13.5, 19.5, 28.5, 63),\n    aes(y = after_stat(density)),\n  ) +\n  labs(\n    title = \"Istogramma delle frequenze relative\", \n    x = \"BDI-II\", \n    y = \"Densit√†\"\n  ) \n\n\n\n\n\n\n\nAnche se nel caso presente √® sensato usare ampiezze diverse per gli intervalli delle classi, in generale gli istogrammi si costruiscono utilizzando intervalli riportati sulle ascisse con un‚Äôampiezza uguale.\n\nggplot(df, aes(x = bdi)) +\n  geom_histogram(\n    color = \"black\",\n    fill = \"lightblue\",\n    aes(y = after_stat(density)),\n  ) +\n  labs(\n    title = \"Istogramma delle frequenze relative\", \n    x = \"BDI-II\", \n    y = \"Densit√†\"\n  )",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#kernel-density-plot",
    "href": "chapters/eda/05_exploring_numeric_data.html#kernel-density-plot",
    "title": "17¬† Esplorare i dati numerici",
    "section": "\n17.4 Kernel Density Plot",
    "text": "17.4 Kernel Density Plot\nUn limite evidente degli istogrammi √® che la loro forma dipende da scelte arbitrarie: il numero e l‚Äôampiezza delle classi (o bin) pu√≤ infatti influenzare in modo sostanziale l‚Äôaspetto finale del grafico, rendendo pi√π difficile l‚Äôinterpretazione della distribuzione dei dati. Una soluzione a questo problema √® offerta dalla stima della densit√† kernel (Kernel Density Estimation, KDE), un metodo che fornisce un profilo continuo e smussato della distribuzione, meno condizionato dall‚Äôarbitrariet√† delle classi.\n\n17.4.1 Differenza tra Istogramma e KDE\nNell‚Äôistogramma, dividiamo l‚Äôasse orizzontale in intervalli di ampiezza prefissata (i bin) e costruiamo rettangoli la cui altezza √® proporzionale alla frequenza (o densit√†) dei dati che ricadono in ciascun intervallo. Se cambiamo il numero o la larghezza dei bin, la forma dell‚Äôistogramma pu√≤ variare sensibilmente.\nLa KDE, invece, non suddivide i dati in intervalli fissi. Al contrario, ‚Äúappoggia‚Äù una piccola curva (il kernel) su ogni singola osservazione. Le curve utilizzate (ad esempio di tipo gaussiano) hanno una larghezza, detta bandwidth, che controlla il grado di smussamento: con un bandwidth molto piccolo, la stima segue da vicino le singole osservazioni, generando un profilo pi√π frastagliato; con un bandwidth pi√π ampio, la curva risultante √® pi√π liscia, ma rischia di nascondere dettagli importanti.\nPer comprendere in modo intuitivo il concetto di KDE, possiamo partire da un esempio semplice. Immaginiamo di costruire un istogramma con classi di ampiezza sempre pi√π piccola. Se avessimo a disposizione un numero enorme di dati (ad esempio, un milione di misurazioni dell‚Äôaltezza di individui) e li rappresentassimo con bin sempre pi√π stretti (0.1, 0.01, ecc.), l‚Äôistogramma diventerebbe sempre pi√π levigato, avvicinandosi a una curva continua. Questo processo illustra l‚Äôidea alla base della KDE, che approssima la distribuzione dei dati in modo fluido e continuo.\nLa KDE, tuttavia, opera in modo pi√π elegante e senza richiedere un numero enorme di punti: posiziona un piccolo ‚Äúdosso di campana‚Äù (o un altro tipo di kernel) su ciascun punto dati e somma tutte queste curve in un‚Äôunica curva finale.\n\n\n\n\n\n\nChe cosa vuol dire ‚Äúdosso di campana‚Äù?\n\n\n\nPossiamo immaginarlo come una piccola curva gaussiana: una curva simile alla forma di una campana che si innalza e poi discende dolcemente.\n\nOgni singolo dato viene ‚Äúcoperto‚Äù da questa mini-campana.\nL‚Äôampiezza (o ‚Äúlarghezza‚Äù) della campana √® regolata dal bandwidth, che stabilisce se la curva sar√† pi√π o meno ‚Äúdistesa‚Äù sul grafico.\nSommando tutte le piccole campane (una per ogni osservazione), otteniamo una curva di densit√† liscia e continua che rappresenta la distribuzione dei dati senza i ‚Äúsalti‚Äù tipici dell‚Äôistogramma.\n\n\n\nIl risultato √® una curva di densit√† che:\n\n\n√à continua: a differenza degli istogrammi, non presenta bruschi salti di altezza tra i bin: la curva scorre in modo uniforme lungo tutto l‚Äôasse orizzontale.\n\nMostra la proporzione di dati in ogni intervallo: l‚Äôarea sotto la curva in un determinato range corrisponde alla percentuale (o probabilit√†) di dati che cadono in quell‚Äôintervallo.\n\nDipende dal bandwidth:\n\nUn bandwidth piccolo produce una curva pi√π ondulata e ‚Äúfrastagliata‚Äù (poich√© segue da vicino ogni singolo dato).\nUn bandwidth grande genera una curva pi√π liscia e arrotondata, ma rischia di ‚Äúcoprire‚Äù troppi dettagli della distribuzione originaria.\n\n\n\nSi noti che la stima della densit√† kernel introduce, tuttavia, un‚Äôipotesi di fondo: che la distribuzione dei dati ‚Äúreali‚Äù sia ‚Äúliscia‚Äù e non presenti discontinuit√† improvvise. Questo √® spesso ragionevole (ad esempio per dati fisiologici come l‚Äôaltezza), ma in altri casi potrebbe non esserlo. √à quindi importante scegliere un bandwidth che rifletta adeguatamente il livello di dettaglio che vogliamo mostrare.\nInoltre, l‚Äôasse delle ordinate (l‚Äôasse y) rappresenta la densit√†, non la frequenza assoluta. √à possibile costruire un istogramma in cui l‚Äôaltezza dei rettangoli mostra quante osservazioni ricadono in ciascun bin. Nella KDE, l‚Äôaltezza della curva √® tale che l‚Äôarea totale sotto di essa sia pari a 1, rispecchiando la natura di una funzione di densit√† di probabilit√†.\nDi seguito esaminiamo un esempio che mostra la costruzione passo dopo passo di istogrammi con diversi valori di binwidth, fino a passare a una stima di densit√†. Consideriemo un dataset con un numero di osservazioni molto elevato (i valori di altezza, heights, riportati da 1050 partecipanti, estratti dal pacchetto dslabs), suddiviso in due gruppi: maschi e femmine. Ecco come potremmo prima costruire un istogramma di altezze per i maschi, per poi tracciare una curva di densit√† smussata:\n\n# Istogramma con bin di ampiezza 1\nggplot(heights |&gt; dplyr::filter(sex == \"Male\"), aes(height)) +\n  geom_histogram(binwidth = 1, color = \"black\", fill=\"lightblue\")\n\n\n\n\n\n\n\n\n# Aggiunta della curva di densit√† sopra l'istogramma\nggplot(heights |&gt; dplyr::filter(sex == \"Male\"), aes(height)) +\n  geom_histogram(\n    aes(y = after_stat(density)), \n    binwidth = 1, color = \"black\", fill=\"lightblue\"\n  ) +\n  geom_line(stat = 'density')\n\n\n\n\n\n\n\nVariando il parametro di regolazione (adjust o bandwidth) nella funzione geom_density(), possiamo modificare il livello di smussamento:\n\n# Esempio di smoothing differente\np &lt;- ggplot(heights |&gt; filter(sex == \"Male\"), aes(height)) +\n  geom_histogram(aes(y = after_stat(density)), binwidth = 1, alpha = 0.5)\n\n# Pi√π ondulato (bandwidth minore)\np1 &lt;- p + geom_line(stat = 'density', adjust = 0.5)\n\n# Pi√π liscio (bandwidth maggiore)\np2 &lt;- p + geom_line(stat = 'density', adjust = 2)\n\ngrid.arrange(p1, p2, ncol = 2)\n\n\n\n\n\n\n\nPer illustrare ulteriormente l‚Äôuso della KDE, ora consideriamo i punteggi BDI-II di Zetsche et al. (2019). Con il codice seguente creiamo due curve di densit√†, una per ogni gruppo:\n\nggplot(df, aes(x = bdi, fill = group)) +\n  geom_density(alpha = 0.5) +\n  labs(\n    title = \"Curva di densit√† (KDE) per i punteggi BDI-II\",\n    x = \"BDI-II\",\n    y = \"Densit√†\"\n  )\n\n\n\n\n\n\n\nQui, la sovrapposizione delle due curve ci consente di confrontare la distribuzione dei punteggi BDI-II tra i due gruppi in maniera molto pi√π fluida e intuitiva rispetto a quanto faremmo con due istogrammi separati o con un istogramma combinato. Inoltre, non siamo pi√π vincolati alla scelta dei bin: l‚Äôaspetto delle curve dipende soltanto dalla funzione kernel utilizzata e dal parametro di smussamento.\nIn conclusione,\n\nl‚Äôistogramma rimane uno strumento rapido e intuitivo, privo di assunzioni, ma sensibile alla scelta di numero e ampiezza dei bin;\nla stima della densit√† kernel (KDE) offre una rappresentazione continua della distribuzione dei dati, fornendo un quadro pi√π ‚Äúmorbido‚Äù e spesso pi√π informativo. Tuttavia, introduce alcune assunzioni e richiede la scelta del bandwidth ottimale.\n\nIn definitiva, √® consigliabile usare entrambe le tecniche per ottenere una panoramica completa dei propri dati: l‚Äôistogramma permette di dare un primo sguardo alla loro distribuzione ‚Äúgrezza‚Äù (senza presupposti), mentre la KDE aiuta a comprenderne l‚Äôeventuale struttura ‚Äúliscia‚Äù di fondo.\n\n17.4.2 Area Sottesa alla Curva di Densit√†: Un‚ÄôInterpretazione Probabilistica\nQuando si lavora con una curva di densit√†, √® importante capire che l‚Äôarea totale sotto la curva rappresenta la probabilit√† totale, che √® sempre pari a 1 (o 100%). Questo significa che l‚Äôarea sotto la curva in un determinato intervallo corrisponde alla probabilit√† che un dato valore cada in quell‚Äôintervallo.\n\n17.4.2.1 Come Interpretare l‚ÄôAsse Y\nL‚Äôasse y di un grafico di densit√† non rappresenta direttamente la probabilit√†, ma √® scalato in modo che l‚Äôarea totale sotto la curva sia uguale a 1. Se immaginiamo di creare un ‚Äúbin‚Äù (un intervallo) con una base di 1 unit√† di lunghezza, il valore sull‚Äôasse y ci indica la proporzione di valori che cadono in quel bin. Tuttavia, questa interpretazione √® valida solo per bin di dimensione 1. Per intervalli di altre dimensioni, il modo migliore per determinare la proporzione di dati in quell‚Äôintervallo √® calcolare la proporzione dell‚Äôarea totale sotto la curva che cade in quell‚Äôintervallo.\n\n17.4.2.2 Esempio Pratico\nConsideriamo un esempio con i dati delle altezze degli uomini. Supponiamo di voler sapere quale proporzione di uomini ha un‚Äôaltezza compresa tra 65 e 68 pollici. Per farlo, calcoliamo l‚Äôarea sotto la curva di densit√† in quell‚Äôintervallo.\nEcco come appare graficamente:\n\n\n\n\n\n\n\n\nL‚Äôarea evidenziata in azzurro rappresenta la proporzione di uomini con altezza tra 65 e 68 pollici. Calcolando questa area, troviamo che circa il 0.3 (ovvero il 30% degli uomini ha un‚Äôaltezza in questo intervallo.\n\n17.4.2.3 Utilizzo della Curva di Densit√† come Riepilogo\nComprendendo questo concetto, possiamo utilizzare la curva di densit√† come un efficace strumento di riepilogo. Per questo dataset, l‚Äôassunzione di smoothness (lisciatura) della curva √® ragionevole, e possiamo condividere questa rappresentazione grafica per comunicare in modo chiaro e intuitivo la distribuzione delle altezze degli uomini.\nEcco un esempio di come appare la curva di densit√† smooth per le altezze degli uomini:\n\n\n\n\n\n\n\n\nIn sintesi, l‚Äôarea sotto la curva di densit√† in un determinato intervallo rappresenta la probabilit√† che un valore casuale cada in quell‚Äôintervallo, rendendo la curva di densit√† uno strumento potente per comprendere e comunicare la distribuzione dei dati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#forma-di-una-distribuzione",
    "href": "chapters/eda/05_exploring_numeric_data.html#forma-di-una-distribuzione",
    "title": "17¬† Esplorare i dati numerici",
    "section": "\n17.5 Forma di una Distribuzione",
    "text": "17.5 Forma di una Distribuzione\nIn statistica, la forma di una distribuzione descrive come i dati sono distribuiti intorno ai valori centrali. Si distingue tra distribuzioni simmetriche e asimmetriche, e tra distribuzioni unimodali e multimodali. Un‚Äôillustrazione grafica √® fornita nella figura seguente. Nel pannello 1, la distribuzione √® unimodale con asimmetria negativa; nel pannello 2, la distribuzione √® unimodale con asimmetria positiva; nel pannello 3, la distribuzione √® simmetrica e unimodale; nel pannello 4, la distribuzione √® bimodale.\n\n\nDistribuzioni\n\nIl grafico della densit√† di kernel (Kernel Density Plot) dei valori BDI-II nel campione di Zetsche et al. (2019) √® bimodale. Questo indica che le osservazioni della distribuzione si raggruppano in due cluster distinti: un gruppo di osservazioni tende ad avere valori BDI-II bassi, mentre l‚Äôaltro gruppo tende ad avere valori BDI-II alti. Questi due cluster di osservazioni corrispondono al gruppo di controllo e al gruppo clinico nel campione di dati esaminato da Zetsche et al. (2019).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#indici-di-posizione",
    "href": "chapters/eda/05_exploring_numeric_data.html#indici-di-posizione",
    "title": "17¬† Esplorare i dati numerici",
    "section": "\n17.6 Indici di posizione",
    "text": "17.6 Indici di posizione\n\n17.6.1 Quantili\nLa distribuzione dei valori BDI-II di Zetsche et al. (2019) pu√≤ essere sintetizzata attraverso l‚Äôuso dei quantili, che sono valori caratteristici che suddividono i dati in parti ugualmente numerose. I quartili sono tre quantili specifici: il primo quartile, \\(q_1\\), divide i dati in due parti, lasciando a sinistra il 25% del campione; il secondo quartile, \\(q_2\\), corrisponde alla mediana e divide i dati in due parti uguali; il terzo quartile lascia a sinistra il 75% del campione.\nInoltre, ci sono altri indici di posizione chiamati decili e percentili che suddividono i dati in parti di dimensioni uguali a 10% e 1%, rispettivamente.\nPer calcolare i quantili, i dati vengono prima ordinati in modo crescente e poi viene determinato il valore di \\(np\\), dove \\(n\\) √® la dimensione del campione e \\(p\\) √® l‚Äôordine del quantile. Se \\(np\\) non √® un intero, il valore del quantile corrisponde al valore del dato che si trova alla posizione successiva alla parte intera di \\(np\\). Se \\(np\\) √® un intero, il valore del quantile corrisponde alla media dei dati nelle posizioni \\(k\\) e \\(k+1\\), dove \\(k\\) √® la parte intera di \\(np\\).\nGli indici di posizione possono essere utilizzati per creare un box-plot, una rappresentazione grafica della distribuzione dei dati che √® molto popolare e pu√≤ essere utilizzata in alternativa ad un istogramma.\nAd esempio, per calcolare la mediana della distribuzione dei nove soggetti con un unico episodio di depressione maggiore del campione clinico di Zetsche et al. (2019), si determina il valore di \\(np = 9 \\cdot 0.5 = 4.5\\), che non √® un intero. Pertanto, il valore del secondo quartile √® pari al valore del dato che si trova alla posizione successiva alla parte intera di \\(np\\), ovvero \\(q_2 = x_{4 + 1} = 27\\). Per calcolare il quantile di ordine \\(2/3\\), si determina il valore di \\(np = 9 \\cdot 2/3 = 6\\), che √® un intero. Quindi, il valore del quantile corrisponde alla media dei dati nelle posizioni \\(6\\) e \\(7\\), ovvero \\(q_{\\frac{2}{3}} = \\frac{1}{2} (x_{6} + x_{7}) = \\frac{1}{2} (33 + 33) = 33\\).\nUsiamo quantile() per trovare la soluzione dell‚Äôesercizio precedente.\n\nx = c(19, 26, 27, 28, 28, 33, 33, 41, 43)\nquantile(x, 2 / 3)\n#&gt; 66.66667% \n#&gt;        33",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#mostrare-i-dati",
    "href": "chapters/eda/05_exploring_numeric_data.html#mostrare-i-dati",
    "title": "17¬† Esplorare i dati numerici",
    "section": "\n17.7 Mostrare i dati",
    "text": "17.7 Mostrare i dati\n\n17.7.1 Diagramma a scatola\nIl box plot √® uno strumento grafico che visualizza la dispersione di una distribuzione. I boxplot forniscono una rappresentazione visiva sintetica di cinque valori caratteristici: minimo, primo quartile (25%), mediana (50%), terzo quartile (75%) e massimo. Spesso per√≤, i boxplot ‚Äúignorano‚Äù i valori considerati anomali (outlier), segnalandoli con punti isolati.\nPer creare un box plot, si disegna un rettangolo (la ‚Äúscatola‚Äù) di altezza arbitraria, basato sulla distanza interquartile (IQR), che corrisponde alla differenza tra il terzo quartile (\\(q_{0.75}\\)) e il primo quartile (\\(q_{0.25}\\)). La mediana (\\(q_{0.5}\\)) √® rappresentata da una linea all‚Äôinterno del rettangolo.\nAi lati della scatola, vengono tracciati due segmenti di retta, detti ‚Äúbaffi‚Äù, che rappresentano i valori adiacenti inferiore e superiore. Il valore adiacente inferiore √® il valore pi√π basso tra le osservazioni che √® maggiore o uguale al primo quartile meno 1.5 volte la distanza interquartile. Il valore adiacente superiore √® il valore pi√π alto tra le osservazioni che √® minore o uguale al terzo quartile pi√π 1.5 volte la distanza interquartile.\nSe ci sono dei valori che cadono al di fuori dei valori adiacenti, vengono chiamati ‚Äúvalori anomali‚Äù e sono rappresentati individualmente nel box plot per evidenziare la loro presenza e posizione. In questo modo, il box plot fornisce una rappresentazione visiva della distribuzione dei dati, permettendo di individuare facilmente eventuali valori anomali e di comprendere la dispersione dei dati.\n\n\n17.7.2 Stratificazione\nNell‚Äôanalisi dei dati, √® comune suddividere le osservazioni in gruppi in base ai valori di una o pi√π variabili associate a tali osservazioni. Questo processo √® chiamato stratificazione, e i gruppi risultanti sono detti strati. Ad esempio, nella sezione successiva, dividiamo i valori dei punteggi BDI-II in due gruppi in base alla condizione sperimentale: campione clinico e campione di controllo.\nLa stratificazione √® particolarmente utile nella visualizzazione dei dati, poich√© spesso siamo interessati a comprendere come la distribuzione di una variabile differisca tra diversi sottogruppi.\nPer esempio, per rappresentare graficamente la distribuzione dei punteggi BDI-II nel gruppo dei pazienti e nel gruppo di controllo, possiamo utilizzare un box-plot. Questo tipo di grafico ci permette di confrontare visivamente la distribuzione dei punteggi tra i due gruppi, evidenziando eventuali differenze.\n\nggplot(df, aes(x = group, y = bdi)) +\n  geom_boxplot() +\n  labs(\n    title = \"Box plot per gruppo\", \n    x = \"Gruppo\", \n    y = \"BDI-II\"\n  )\n\n\n\n\n\n\n\nIn questo grafico:\n\nL‚Äôasse x rappresenta i due gruppi (pazienti e controllo).\nL‚Äôasse y rappresenta i punteggi BDI-II.\nI box (scatole) mostrano la distribuzione dei punteggi, con la linea centrale che indica la mediana e i ‚Äúbaffi‚Äù che rappresentano la variabilit√† dei dati.\n\nLa stratificazione ci aiuta a identificare rapidamente se ci sono differenze nella distribuzione dei punteggi BDI-II tra i due gruppi. Nel caso presente, il grafico mostra come non vi sia alcuna sovrapposizione tra le due distribuzioni.\nUn risultato migliore si ottiene utilizzando un grafico a violino (violin plot) e includendo anche i dati grezzi.\n\n17.7.3 Grafico a Violino\nI grafici a violino combinano le caratteristiche dei box plot e dei grafici di densit√† di kernel (KDE plot) per offrire una rappresentazione pi√π dettagliata dei dati. A questi grafici vengono sovrapposti i dati grezzi, fornendo una visione completa della distribuzione e delle caratteristiche dei dati.\n\nggplot(df, aes(x = group, y = bdi, fill = group)) +\n  geom_violin() +\n  geom_dotplot(\n    binaxis = \"y\",\n    stackdir = \"center\",\n    dotsize = 0.5,\n    fill = 1\n  ) +\n  labs(\n    title = \"Violin plot con overlay dei punti grezzi\",\n    x = \"Gruppo\",\n    y = \"BDI-II\"\n  )\n\n\n\n\n\n\n\n\n17.7.4 Grafico Beeswarm\nIl pacchetto {ggbeeswarm} include una funzione chiamata geom_beeswarm, che pu√≤ essere utilizzata per creare un grafico beeswarm in ggplot2.\nUn grafico beeswarm √® una variazione del grafico a punti che disperde i dati in modo che non si sovrappongano, rendendo visibili tutti i singoli punti dati. Questo tipo di visualizzazione √® particolarmente utile quando si desidera esaminare la distribuzione e la densit√† di un set di dati, senza ricorrere all‚Äôuso di barre d‚Äôerrore o di scatole e baffi (boxplot), mantenendo un‚Äôalta leggibilit√† anche quando i set di dati sono densi.\n\nggplot(df, aes(x = group, y = bdi, color = group)) +\n  geom_beeswarm(cex = 2) +\n  labs(\n    title = \"Violin plot con overlay dei punti grezzi\",\n    x = \"Gruppo\",\n    y = \"BDI-II\"\n  )",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#riflessioni-conclusive",
    "href": "chapters/eda/05_exploring_numeric_data.html#riflessioni-conclusive",
    "title": "17¬† Esplorare i dati numerici",
    "section": "\n17.8 Riflessioni Conclusive",
    "text": "17.8 Riflessioni Conclusive\nIn questo capitolo abbiamo illustrato una variet√† di tecniche per sintetizzare e visualizzare i dati numerici, concentrandoci sia sugli aspetti descrittivi (come distribuzioni di frequenze, istogrammi e distribuzioni cumulative) sia su metodi pi√π raffinati come la stima della densit√† kernel. Questi strumenti non solo facilitano la comprensione immediata dei pattern e delle caratteristiche fondamentali dei dati, ma rappresentano anche un passaggio essenziale per identificare anomalie e guidare ulteriori analisi statistiche.\nLa capacit√† di trasformare dati grezzi in rappresentazioni grafiche chiare e intuitive √® fondamentale per comunicare in modo efficace i risultati dell‚Äôanalisi, soprattutto quando si tratta di supportare decisioni pratiche o di sviluppare ipotesi di ricerca. In questo senso, una visualizzazione accurata e ben strutturata consente di evidenziare aspetti come la forma della distribuzione, la presenza di outlier e le differenze tra sottogruppi, contribuendo a una pi√π profonda interpretazione dei fenomeni studiati.\nInfine, l‚Äôintegrazione di tecniche di visualizzazione con analisi statistiche sintetiche migliora la trasparenza e l‚Äôinterpretabilit√† dei dati, offrendo un quadro completo che supporta sia la valutazione critica che la comunicazione dei risultati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#esercizi",
    "href": "chapters/eda/05_exploring_numeric_data.html#esercizi",
    "title": "17¬† Esplorare i dati numerici",
    "section": "\n17.9 Esercizi",
    "text": "17.9 Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nIn questo esercizio, gli studenti raccoglieranno e analizzeranno dati relativi alla Satisfaction With Life Scale (SWLS) (Diener et al., 1985) e alla Scala della Rete Sociale di Lubben (LSNS-6) (Lubben et al., 2006). L‚Äôobiettivo √® comprendere la relazione tra la soddisfazione di vita e la qualit√† delle relazioni sociali, esplorando la distribuzione delle variabili e le possibili associazioni tra di esse.\nLa Scala della Rete Sociale di Lubben a 6 item (LSNS-6) √® uno strumento utilizzato per valutare l‚Äôisolamento sociale negli adulti pi√π anziani, misurando il supporto sociale percepito sia da parte dei familiari che degli amici. La scala comprende sei domande suddivise in due sezioni:\nFAMIGLIA: Considerando le persone a cui sei legato per nascita, matrimonio, adozione, ecc.\n\nQuanti parenti vedi o senti almeno una volta al mese?\nCon quanti parenti ti senti a tuo agio nel parlare di questioni personali?\nCon quanti parenti ti senti cos√¨ vicino da poter chiedere loro aiuto?\n\nAMICIZIE: Considerando tutti i tuoi amici, inclusi quelli che vivono nel tuo quartiere\n\nQuanti dei tuoi amici vedi o senti almeno una volta al mese?\nCon quanti amici ti senti a tuo agio nel parlare di questioni personali?\nCon quanti amici ti senti cos√¨ vicino da poter chiedere loro aiuto?\n\nLa scala di risposta √®:\n\n0 = nessuno\n1 = uno\n2 = due\n3 = tre o quattro\n4 = da cinque a otto\n5 = nove o pi√π\n\nIl punteggio totale della LSNS-6 si ottiene sommando i punteggi dei sei item, con un range che va da 0 a 30. Un punteggio di 12 o inferiore indica un rischio di isolamento sociale.\nDati da Raccogliere\nOgni studente dovr√† raccogliere i seguenti dati su se stesso e sui membri del proprio gruppo TPV:\n\n\nstudent_id: Identificativo univoco dello studente.\n\n\ngroup: Gruppo di appartenenza (es. Gruppo 1, Gruppo 2, ecc.).\n\n\nswls: Punteggio totale sulla Satisfaction With Life Scale (SWLS).\n\n\ngender: Genere (M, F).\n\n\nlsns_total: Punteggio totale della Scala della Rete Sociale di Lubben (LSNS-6).\n\n\nlsns_family: Punteggio della sottoscala engagement with family members (somma degli item 1-3).\n\n\nlsns_friends: Punteggio della sottoscala engagement with friends (somma degli item 4-6).\n\nQueste variabili permetteranno di investigare come la soddisfazione di vita sia associata alla quantit√† e qualit√† delle relazioni sociali, distinguendo tra contatti con la famiglia e con gli amici.\nObiettivi dell‚ÄôAnalisi\nL‚Äôesercizio √® strutturato in tre parti:\n\n\nEsplorazione dei dati e distribuzione delle variabili\n\n\nVisualizzazione e confronto tra gruppi\n\nAnalisi delle possibili associazioni tra SWLS e le componenti della rete sociale\n\nParte 1: Esplorazione dei Dati\n1.1 Caricamento e preparazione del dataset\n\nImporta il dataset swls_lsns_students.csv.\n\nSeleziona le variabili indicate sopra.\n\nControlla ed elimina eventuali duplicati.\n\nControlla ed elimina eventuali valori mancanti.\n\n# Caricamento del dataset\ndf &lt;- rio::import(here::here(\"data\", \"swls_lsns_students.csv\"))\n\n# Selezione delle variabili\ndf &lt;- df |&gt; dplyr::select(student_id, group, swls, gender, \n                          lsns_total, lsns_family, lsns_friends)\n\n# Rimozione dei duplicati\ndf &lt;- df[!duplicated(df$student_id), ]\n\n# Rimozione dei valori mancanti\ndf &lt;- df[complete.cases(df), ]\n1.2 Distribuzione delle variabili\n\nCalcola la distribuzione di frequenza per swls, lsns_total, lsns_family e lsns_friends:\n\nFrequenze assolute e relative\n\nFrequenze cumulative\n\n\n\n# Frequenze assolute e relative\ntable(df$swls)\nprop.table(table(df$swls))\n\ntable(df$lsns_total)\nprop.table(table(df$lsns_total))\n\nCrea un istogramma della distribuzione delle variabili.\n\nggplot(df, aes(x = swls)) +\n  geom_histogram(bins = 10, fill = \"lightblue\", color = \"black\") +\n  labs(title = \"Distribuzione dei punteggi SWLS\",\n       x = \"Punteggio SWLS\",\n       y = \"Frequenza\")\nggplot(df, aes(x = lsns_total)) +\n  geom_histogram(bins = 10, fill = \"lightblue\", color = \"black\") +\n  labs(title = \"Distribuzione dei punteggi LSNS-6 (totale)\",\n       x = \"Punteggio LSNS-6\",\n       y = \"Frequenza\")\n\nCostruisci la funzione di distribuzione empirica cumulativa (eCDF).\n\nggplot(df, aes(x = swls)) +\n  stat_ecdf(geom = \"step\", color = \"blue\") +\n  labs(title = \"Funzione di distribuzione empirica cumulativa SWLS\",\n       x = \"Punteggio SWLS\",\n       y = \"F(x)\")\n\nGenera la curva di densit√† kernel (KDE) per ogni variabile.\n\nggplot(df, aes(x = swls)) +\n  geom_density(fill = \"lightblue\", alpha = 0.5) +\n  labs(title = \"Curva di densit√† dei punteggi SWLS\",\n       x = \"Punteggio SWLS\",\n       y = \"Densit√†\")\nggplot(df, aes(x = lsns_total)) +\n  geom_density(fill = \"lightblue\", alpha = 0.5) +\n  labs(title = \"Curva di densit√† LSNS-6 (totale)\",\n       x = \"Punteggio LSNS-6\",\n       y = \"Densit√†\")\nParte 2: Confronto tra Gruppi\n\nCostruisci una tabella di contingenza per gender e livello di rete sociale (alta o bassa, separando sopra e sotto la mediana di lsns_total).\n\ndf &lt;- df |&gt; \n  mutate(lsns_level = ifelse(lsns_total &gt;= median(lsns_total), \"Alto\", \"Basso\"))\n\ntable(df$gender, df$lsns_level)\nprop.table(table(df$gender, df$lsns_level), margin = 1)\n\nCrea un grafico a barre per la distribuzione di lsns_level per genere.\n\nggplot(df, aes(x = lsns_level, fill = gender)) +\n  geom_bar(position = \"dodge\") +\n  labs(title = \"Distribuzione del livello di rete sociale per genere\",\n       x = \"Livello LSNS\",\n       y = \"Conteggio\",\n       fill = \"Genere\")\n\nCostruisci un box plot per confrontare swls tra i gruppi di rete sociale.\n\nggplot(df, aes(x = lsns_level, y = swls, fill = lsns_level)) +\n  geom_boxplot() +\n  labs(title = \"Distribuzione dei punteggi SWLS per livello di rete sociale\",\n       x = \"Livello di rete sociale\",\n       y = \"Punteggio SWLS\")\n\nUsa un violin plot per visualizzare la distribuzione dettagliata.\n\nggplot(df, aes(x = lsns_level, y = swls, fill = lsns_level)) +\n  geom_violin(alpha = 0.5) +\n  geom_jitter(width = 0.1, alpha = 0.5) +\n  labs(title = \"Violin plot con dati grezzi sovrapposti\",\n       x = \"Livello di rete sociale\",\n       y = \"Punteggio SWLS\")\nParte 3: Analisi delle Associazioni tra SWLS e la Rete Sociale\nIl concetto di correlazione verr√† approfondito nel Capitolo 21. Per i nostri scopi attuali, possiamo considerarlo come un indice numerico che misura l‚Äôintensit√† e la direzione dell‚Äôassociazione tra due variabili. Un valore di 0 indica l‚Äôassenza di una relazione lineare tra le variabili, mentre i valori +1 e -1 indicano una relazione lineare perfetta, positiva o negativa rispettivamente. I valori intermedi tra -1 e +1 rappresentano associazioni pi√π deboli o forti, a seconda della loro vicinanza agli estremi.\n\n\nCorrelazioni tra SWLS e le sottoscale della LSNS.\n\ncor(df$swls, df$lsns_total, method = \"pearson\")\ncor(df$swls, df$lsns_family, method = \"pearson\")\ncor(df$swls, df$lsns_friends, method = \"pearson\")\nSpiega in maniera inuitiva il significato dei valori ottenuti.\n\n\nGrafico di dispersione tra SWLS e LSNS-6 totale.\n\nUn grafico di dispersione √® un diagramma cartesiano in cui ogni punto rappresenta un‚Äôosservazione (nel caso attuale, uno studente). Le coordinate dei punti sui due assi, X e Y, indicano i valori delle due variabili considerate per ciascuno studente.\nggplot(df, aes(x = lsns_total, y = swls)) +\n  geom_point(alpha = 0.7) +\n  geom_smooth(method = \"lm\", color = \"red\") +\n  labs(title = \"Relazione tra rete sociale totale e SWLS\",\n       x = \"Punteggio LSNS-6 Totale\",\n       y = \"Punteggio SWLS\")\nPer ogni grafico generato, includi una descrizione chiara e concisa del suo significato in relazione ai dati analizzati.\nConclusioni\nL‚Äôobiettivo √® analizzare se e come la soddisfazione di vita degli studenti universitari √® influenzata dalle relazioni sociali, distinguendo tra engagement con la famiglia e con gli amici.\nConsegna\nConsegna il file .qmd contenente il codice, le visualizzazioni e le interpretazioni.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/05_exploring_numeric_data.html#informazioni-sullambiente-di-sviluppo",
    "title": "17¬† Esplorare i dati numerici",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] dslabs_0.8.0     ggbeeswarm_0.7.2 thematic_0.1.6   MetBrewer_0.2.0 \n#&gt;  [5] ggokabeito_0.1.0 see_0.11.0       gridExtra_2.3    patchwork_1.3.0 \n#&gt;  [9] bayesplot_1.11.1 psych_2.5.3      scales_1.3.0     markdown_2.0    \n#&gt; [13] knitr_1.50       lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1   \n#&gt; [17] dplyr_1.1.4      purrr_1.0.4      readr_2.1.5      tidyr_1.3.1     \n#&gt; [21] tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3       \n#&gt; [25] here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     R.oo_1.27.0       rprojroot_2.0.4  \n#&gt; [13] jsonlite_1.9.1    R.utils_2.13.0    mnormt_2.1.1      cli_3.6.4        \n#&gt; [17] rlang_1.1.5       R.methodsS3_1.8.2 munsell_0.5.1     withr_3.0.2      \n#&gt; [21] tools_4.4.2       parallel_4.4.2    tzdb_0.5.0        colorspace_2.1-1 \n#&gt; [25] pacman_0.5.1      vctrs_0.6.5       R6_2.6.1          lifecycle_1.0.4  \n#&gt; [29] htmlwidgets_1.6.4 vipor_0.4.7       beeswarm_0.4.0    pkgconfig_2.0.3  \n#&gt; [33] pillar_1.10.1     gtable_0.3.6      data.table_1.17.0 glue_1.8.0       \n#&gt; [37] xfun_0.51         tidyselect_1.2.1  rstudioapi_0.17.1 farver_2.1.2     \n#&gt; [41] htmltools_0.5.8.1 nlme_3.1-167      labeling_0.4.3    rmarkdown_2.29   \n#&gt; [45] compiler_4.4.2",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#bibliografia",
    "href": "chapters/eda/05_exploring_numeric_data.html#bibliografia",
    "title": "17¬† Esplorare i dati numerici",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nDiener, E., Emmons, R. A., Larsen, R. J., & Griffin, S. (1985). The Satisfaction With Life Scale. Journal of Personality Assessment, 49(1), 71‚Äì75. https://doi.org/10.1207/s15327752jpa4901_13\n\n\nLubben, J., Blozik, E., Gillmann, G., Iliffe, S., Renteln Kruse, W. von, Beck, J. C., & Stuck, A. E. (2006). Performance of an abbreviated version of the Lubben Social Network Scale among three European community-dwelling older adult populations. The Gerontologist, 46(4), 503‚Äì513. https://doi.org/10.1093/geront/46.4.503\n\n\nZetsche, U., Buerkner, P.-C., & Renneberg, B. (2019). Future expectations in clinical depression: biased or realistic? Journal of Abnormal Psychology, 128(7), 678‚Äì688.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html",
    "href": "chapters/eda/06_data_visualization.html",
    "title": "18¬† Principi della visualizzazione dei dati",
    "section": "",
    "text": "18.1 Introduzione\nIn questo capitolo vengono presentati i principi fondamentali della visualizzazione dei dati, accompagnati da una breve descrizione esplicativa. Per approfondimenti, si raccomanda di consultare il capitolo Data Visualization del libro Introduction to Data Science.\nVerranno inoltre analizzati errori, bias, imprecisioni sistematiche e altre problematiche che possono influenzare l‚Äôinterpretazione dei dati. Poich√© tali problematiche spesso sfuggono a una verifica diretta nel dataset, la visualizzazione diventa uno strumento indispensabile per identificarle e gestirle.\nL‚Äôaumento della disponibilit√† di dataset informativi e di strumenti software ha elevato l‚Äôimportanza della visualizzazione in numerosi ambiti. Essa non solo facilita la comunicazione dei risultati, ma stimola ulteriori analisi e consente di individuare errori e anomalie in modo immediato.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#unimmagine-vale-pi√π-di-mille-parole",
    "href": "chapters/eda/06_data_visualization.html#unimmagine-vale-pi√π-di-mille-parole",
    "title": "18¬† Principi della visualizzazione dei dati",
    "section": "\n18.2 Un‚ÄôImmagine Vale Pi√π di Mille Parole",
    "text": "18.2 Un‚ÄôImmagine Vale Pi√π di Mille Parole\nI numeri e le stringhe che compongono un dataset raramente offrono una visione chiara. Ad esempio, osservando la tabella dei dati relativi agli omicidi con armi da fuoco negli Stati Uniti:\n\nhead(murders)\n#&gt;        state abb region population total\n#&gt; 1    Alabama  AL  South    4779736   135\n#&gt; 2     Alaska  AK   West     710231    19\n#&gt; 3    Arizona  AZ   West    6392017   232\n#&gt; 4   Arkansas  AR  South    2915918    93\n#&gt; 5 California  CA   West   37253956  1257\n#&gt; 6   Colorado  CO   West    5029196    65\n\ndiventa difficile rispondere a domande quali:\n\nQuali stati hanno le popolazioni maggiori o minori?\n\nQual √® la dimensione ‚Äútipica‚Äù di uno stato?\n\nEsiste una relazione tra popolazione e numero totale di omicidi?\n\nCome variano i tassi di omicidio nelle diverse regioni?\n\nAl contrario, il grafico seguente rende evidenti tutte queste informazioni:\n\n\n\n\n\n\n\n\nIl detto ‚Äúun‚Äôimmagine vale pi√π di mille parole‚Äù si conferma: una buona visualizzazione comunica immediatamente il messaggio e spesso elimina la necessit√† di ulteriori analisi.\n\n18.2.1 Domande Guidate dalla Visualizzazione\nOsservando il grafico, possiamo rispondere rapidamente ad alcune domande:\n\nStati con popolazioni maggiori:\nGli stati con le popolazioni pi√π numerose si trovano a destra sull‚Äôasse delle ascisse (scala logaritmica), evidenziando, ad esempio, California, Texas e New York.\nStati con popolazioni minori:\nQuelli con popolazioni ridotte si posizionano a sinistra, come Wyoming, Vermont e Alaska.\nDimensione ‚Äútipica‚Äù di uno stato:\nLa densit√† delle osservazioni suggerisce che la maggior parte degli stati conta intorno a un milione di abitanti, mentre molti raggiungono i 5‚Äì10 milioni.\nRelazione tra popolazione e omicidi:\n√à evidente una relazione positiva: stati pi√π popolosi tendono ad avere un numero maggiore di omicidi, pur mostrando alcune discrepanze dovute ad altri fattori.\n\nVariazione dei tassi di omicidio per regione:\nIl grafico, attraverso la codifica cromatica, indica che:\n\nIl Sud registra generalmente tassi pi√π elevati.\n\nIl Nord-Est presenta tassi moderati e relativamente pi√π bassi.\n\nL‚ÄôOvest mostra una grande variabilit√†, in parte dovuta a grandi popolazioni.\n\nIl Midwest evidenzia tassi bassi o moderati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#codificare-i-dati-attraverso-segnali-visivi",
    "href": "chapters/eda/06_data_visualization.html#codificare-i-dati-attraverso-segnali-visivi",
    "title": "18¬† Principi della visualizzazione dei dati",
    "section": "\n18.3 Codificare i Dati Attraverso Segnali Visivi",
    "text": "18.3 Codificare i Dati Attraverso Segnali Visivi\nLe visualizzazioni si basano su segnali visivi come posizione, lunghezza, angoli, area, luminosit√† e tonalit√† del colore. Tra questi, posizione e lunghezza risultano i pi√π efficaci, in quanto il cervello umano √® particolarmente sensibile alle variazioni spaziali. Al contrario, angoli e aree ‚Äì tipici dei pie chart o bubble plot ‚Äì possono indurre errori interpretativi, soprattutto in presenza di differenze minime.\nIl colore, impiegato per rappresentare variabili qualitative o categoriali, √® particolarmente utile in visualizzazioni multidimensionali, come le heatmap, ma va usato con attenzione per garantire l‚Äôaccessibilit√† (ad es. evitare combinazioni rosso-verde per il daltonismo).\nMentre le tabelle garantiscono precisione numerica, i grafici (come i barplot) risultano pi√π efficaci per dataset complessi, in quanto facilitano l‚Äôindividuazione di pattern e tendenze.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#scelta-della-visualizzazione-pi√π-adeguata",
    "href": "chapters/eda/06_data_visualization.html#scelta-della-visualizzazione-pi√π-adeguata",
    "title": "18¬† Principi della visualizzazione dei dati",
    "section": "\n18.4 Scelta della Visualizzazione Pi√π Adeguata",
    "text": "18.4 Scelta della Visualizzazione Pi√π Adeguata\nLa scelta del tipo di visualizzazione dipende dalla natura dei dati e dall‚Äôobiettivo comunicativo. Ad esempio:\n\n\nBarplot e dot plot: Ideali per confrontare valori quantitativi tra categorie.\n\nIstogrammi, boxplot e raincloud plots: Efficaci per descrivere la distribuzione di dati continui.\n\nGrafici di dispersione (scatter plot): Utili per esplorare relazioni tra due variabili continue.\n\nLa chiarezza e la leggibilit√† sono fondamentali: l‚Äôaggiunta di elementi superflui pu√≤ distrarre e confondere, mentre una rappresentazione essenziale evidenzia il messaggio principale.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#aspetti-tecnici-della-visualizzazione",
    "href": "chapters/eda/06_data_visualization.html#aspetti-tecnici-della-visualizzazione",
    "title": "18¬† Principi della visualizzazione dei dati",
    "section": "\n18.5 Aspetti Tecnici della Visualizzazione",
    "text": "18.5 Aspetti Tecnici della Visualizzazione\n\n18.5.1 Inclusione dello Zero\nQuando la lunghezza √® usata come segnale visivo (come nei barplot), √® fondamentale far partire l‚Äôasse da zero per evitare distorsioni visive. In grafici basati sulla posizione (ad es. scatter plot), invece, l‚Äôinclusione dello zero non √® sempre necessaria.\n\n18.5.2 Prevenire le Distorsioni\nL‚Äôutilizzo di aree, ad esempio nei bubble plot, pu√≤ esagerare le differenze tra valori a causa della relazione quadratica tra raggio e area. Per confronti accurati, √® preferibile utilizzare la posizione o la lunghezza.\n\n\n\n\n\n\nState of the Union\n\n\n\n\n\n\n\n\n\n\nFigura¬†18.1: Fonte: Irizarry (2024).\n\n\nDurante il Discorso sullo Stato dell‚ÄôUnione del 2011 del Presidente Barack Obama, fu utilizzato il grafico sopra per confrontare il PIL statunitense con quello di quattro nazioni concorrenti.\nGiudicando dall‚Äôarea dei cerchi, gli Stati Uniti sembrerebbero avere un‚Äôeconomia oltre 5 volte pi√π grande di quella cinese e oltre 30 volte superiore a quella francese. Tuttavia, analizzando i dati reali, emergono discrepanze significative: i rapporti effettivi sono rispettivamente 2.6 volte quello della Cina e 5.8 volte quello della Francia.\nQuesta distorsione visiva nasce dall‚Äôavere reso il raggio (non l‚Äôarea) proporzionale al valore economico. Poich√© l‚Äôarea di un cerchio dipende dal quadrato del raggio (\\(Area = \\pi r^2\\)), le proporzioni vengono amplificate:\n\n\n\\(2.6^2 = 6.76\\) (approssimato a 6.5 nel grafico)\n\n\n\\(5.8^2 = 33.64\\) (approssimato a 34.1)\n\nIl confronto sottostante illustra l‚Äôimpatto della scelta tra raggio e area nella rappresentazione grafica:\n\n\n\n\n\nFigura¬†18.2: Fonte: Irizarry (2024).\n\n\nNon a caso, ggplot2 utilizza per impostazione predefinita l‚Äôarea anzich√© il raggio. Tuttavia, in casi come questo, la soluzione ottimale sarebbe evitare del tutto i cerchi a favore di strumenti pi√π intuitivi come posizione e lunghezza:\n\n\n\n\n\nFigura¬†18.3: Fonte: Irizarry (2024).\n\n\nQuesto caso dimostra chiaramente come, per evitare distorsioni percettive, sia una prassi consolidata ottimizzare la visualizzazione dei dati attraverso confronti basati su lunghezze (o posizioni) anzich√© su aree o volumi, come evidenziato dall‚Äôerrata rappresentazione del PIL nel grafico originale.\n\n\n\n\n18.5.3 Ordinamento delle Categorie\nDisporre le categorie in base al valore della variabile di interesse, anzich√© in ordine alfabetico, facilita l‚Äôinterpretazione visiva e mette in luce pattern significativi.\n\n18.5.4 Evitare i Dynamite Plots\nI dynamite plots, che rappresentano la media e l‚Äôerrore standard, sono spesso fuorvianti in quanto enfatizzano differenze che potrebbero non essere statisticamente rilevanti. Una rappresentazione tramite dot plot, mostrando tutti i dati, offre una visione pi√π completa della distribuzione (Weissgerber et al., 2015).\n\n\n\n\n\n\nMostrare i dati\n\n\n\n\n\nConsideriamo il seguente grafico a barre (dynamite plot) che mostra la media (estremit√† superiore delle barre) e gli errori standard.\n\n\n\n\n\nFigura¬†18.4: Fonte: Irizarry (2024).\n\n\nQuesta visualizzazione offre informazioni limitate:\n\nLe barre partono da 0, suggerendo erroneamente l‚Äôesistenza di esseri umani alti pochi centimetri.\n\nNon chiarisce se tutti i maschi siano pi√π alti delle femmine o come siano distribuite le altezze.\n\nUn approccio migliore √® quello di mostrare i dati:\n\n\n\n\n\nFigura¬†18.5: Fonte: Irizarry (2024).\n\n\nLa visualizzazione di tutti i punti (238 femmine e 812 maschi) rivela l‚Äôintervallo dei dati, ma persiste un problema: i punti sovrapposti ostacolano l‚Äôinterpretazione.\nOttimizzazioni: jitter e trasparenza\n\n\n\n\n\nFigura¬†18.6: Fonte: Irizarry (2024).\n\n\nDue miglioramenti chiave:\n\n\nJitter orizzontale: spostamento casuale dei punti per ridurre la sovrapposizione.\n\n\nAlpha blending: trasparenza graduale: le aree con pi√π dati appaiono pi√π scure.\n\nRisultati:\n\nsi osserva che i maschi sono in media pi√π alti;\n√® chiaro che vi √® una grande variabilit√† e una notevole sovrapposizione tra le due distribuzioni.\n\nIn sintesi, strumenti semplici, come jitter e trasparenza, migliorano drasticamente l‚Äôinterpretazione della distribuzione dei dati.\n\n\n\n\n18.5.5 Confronti Coerenti\nQuando si comparano distribuzioni (ad es. tramite istogrammi), √® essenziale utilizzare gli stessi assi per evitare interpretazioni errate. L‚Äôallineamento dei grafici, sia in verticale che in orizzontale, facilita il confronto diretto.\n\n\n\n\n\n\nFacilitare i confronti\n\n\n\n\n\nPoich√© ci sono molti punti, √® pi√π efficace mostrare la distribuzione dei dati anzich√© i singoli valori. Per questo motivo, utilizziamo istogrammi separati per ciascun gruppo:\n\n\n\n\n\nFigura¬†18.7: Fonte: Irizarry (2024).\n\n\nTuttavia, in questo grafico non √® immediatamente evidente che, in media, gli uomini siano pi√π alti delle donne. Per accorgersene, bisogna osservare con attenzione e notare che l‚Äôasse x del grafico maschile copre un intervallo di valori pi√π ampio. Un principio fondamentale nella comparazione di dati tra due grafici √® mantenere le stesse scale sugli assi.\nNegli istogrammi, l‚Äôaltezza media si riflette in spostamenti orizzontali: valori pi√π bassi a sinistra, valori pi√π alti a destra. Allineare i grafici in verticale aiuta a visualizzare meglio questa differenza quando gli assi sono coerenti:\n\n\n\n\n\nFigura¬†18.8: Fonte: Irizarry (2024).\n\n\nQuesto secondo grafico rende molto pi√π evidente che, in media, gli uomini sono pi√π alti delle donne.\n\n\n\n\n18.5.6 Trasformazioni Logaritmiche\nLe trasformazioni logaritmiche sono particolarmente utili per dati distribuiti su ampi ordini di grandezza o quando le variazioni sono di natura moltiplicativa. Esse riducono le distorsioni visive, rendendo pi√π chiara l‚Äôinterpretazione dei dati estremi.\n\n\n\n\n\n\nTrasformazioni logaritmiche\n\n\n\n\n\nConsideriamo questo grafico a barre, che mostra la popolazione media dei paesi di ciascun continente nel 2015:\n\n\n\n\n\nFigura¬†18.9: Fonte: Irizarry (2024).\n\n\nA prima vista, sembrerebbe che i paesi dell‚ÄôAsia siano molto pi√π popolosi rispetto a quelli degli altri continenti. Tuttavia, applicando il principio che ci chiede di mostrare i dati, notiamo rapidamente che questa differenza √® dovuta alla presenza di due paesi con una popolazione estremamente elevata, presumibilmente India e Cina:\n\n\n\n\n\nFigura¬†18.10: Fonte: Irizarry (2024).\n\n\nConsideriamo ora come la trasformazione logaritmica possa migliorare la visualizzazione di dati distribuiti in modo asimmetrico (right-skewed). Esistono anche altre trasformazioni utili, come la logistica (logit), impiegata per interpretare variazioni nei rapporti di probabilit√† (odds), e la radice quadrata (sqrt), spesso usata per stabilizzare la varianza nei dati basati su conteggi.\nNel caso della popolazione dei paesi, la distribuzione √® fortemente asimmetrica: la maggior parte delle nazioni ha una popolazione relativamente piccola, mentre poche hanno numeri estremamente elevati. Come mostrato nel boxplot precedente, questa disparit√† comprime la maggior parte dei dati in una piccola area del grafico, lasciando molto spazio inutilizzato. Questo rende difficile cogliere le differenze tra la maggior parte dei paesi.\nUna trasformazione logaritmica migliora la leggibilit√† di uno scatter plot quando i dati mostrano una forte asimmetria. Qui, applicando questa tecnica alle popolazioni nazionali, otteniamo una rappresentazione molto pi√π chiara e informativa. Di seguito, confrontiamo il barplot originale con un boxplot in cui l‚Äôasse y √® stato trasformato con il logaritmo:\n\n\n\n\n\nFigura¬†18.11: Fonte: Irizarry (2024).\n\n\nGrazie a questa trasformazione, scopriamo che la mediana della popolazione nei paesi africani √® in realt√† pi√π alta rispetto a quella dei paesi asiatici, un‚Äôinformazione che il grafico iniziale non rendeva evidente.\n\n\n\n\n18.5.7 Codifica di Variabili Aggiuntive\nPer rappresentare una terza variabile in un grafico di dispersione, si possono utilizzare dimensioni, colori o forme differenti. √à importante scegliere palette cromatiche accessibili e adatte anche a chi ha difficolt√† visive.\n\n\n\n\n\n\nCodificare una terza variabile\n\n\n\n\n\nEsaminiamo la relazione tra sopravvivenza infantile e reddito medio. Il grafico seguente rappresenta questa relazione includendo tre variabili aggiuntive: appartenenza all‚ÄôOPEC, regione geografica e popolazione.\n\n\n\n\n\nFigura¬†18.12: Fonte: Irizarry (2024).\n\n\nLe variabili categoriali sono rappresentate attraverso il colore e la forma dei punti. La forma pu√≤ essere modificata utilizzando l‚Äôargomento shape.\n\n\n\n\n18.5.8 Evitare Rappresentazioni Tridimensionali Inutili\nGrafici 3D, come barre o pie chart tridimensionali, possono essere visivamente accattivanti, ma tendono a distorcere la percezione dei dati. Le visualizzazioni 2D rimangono generalmente pi√π chiare e comprensibili.\n\n18.5.9 Scelta delle Cifre Significative\nMostrare un numero eccessivo di decimali pu√≤ confondere il lettore. Generalmente una o due cifre significative sono sufficienti per trasmettere il messaggio in modo accurato.\n\n18.5.10 Conoscere il Pubblico\nInfine, √® essenziale adattare la visualizzazione al pubblico di riferimento. Grafici destinati a un‚Äôanalisi interna possono includere dettagli tecnici, mentre per un pubblico non specializzato √® preferibile semplificare e spiegare chiaramente i dati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#introduzione-a-ggplot2",
    "href": "chapters/eda/06_data_visualization.html#introduzione-a-ggplot2",
    "title": "18¬† Principi della visualizzazione dei dati",
    "section": "\n18.6 Introduzione a ggplot2",
    "text": "18.6 Introduzione a ggplot2\nR offre strumenti potenti per creare grafici, e tra questi il pacchetto ggplot2 √® uno dei pi√π flessibili e facili da usare.\n\n18.6.1 Perch√© usare ggplot2?\nImmagina di voler analizzare il livello di ansia di un gruppo di studenti prima di un esame. Hai raccolto i dati, ma leggerli in una tabella pu√≤ essere poco intuitivo. Con un grafico ben fatto, invece, puoi subito vedere chi ha livelli di ansia molto alti o come varia l‚Äôansia in base all‚Äô‚Äúintolleranza all‚Äôincertezza‚Äù (IU), per esempio.\nSimuliamo i dati:\n\n# Imposta il seed per la riproducibilit√†\nset.seed(123)\n\n# Crea un campione di 200 partecipanti\nn &lt;- 200\n\n# Genera il genere (0 = maschio, 1 = femmina)\ngender &lt;- sample(c(0, 1), n, replace = TRUE)\n\n# Simula l'ansiet√† con livello pi√π alto per le femmine\nanxiety &lt;- rnorm(n, mean = 50 + 10 * gender, sd = 10)\n\n# Simula ore di studio con correlazione negativa con l'ansiet√†\nstudy_hours &lt;- rnorm(n, mean = 30 - 0.3 * anxiety, sd = 5)\n\n# Simula IU (Intolerance of Uncertainty) con correlazione positiva\nIU &lt;- rnorm(n, mean = 50 + 0.5 * anxiety, sd = 10)\n\n# Crea dataframe\ndf &lt;- data.frame(\n  id = 1:n,\n  gender = factor(gender, levels = c(0, 1), labels = c(\"Male\", \"Female\")),\n  anxiety = round(anxiety, 1),\n  study_hours = round(study_hours, 1),\n  IU = round(IU, 1)\n)\n\ndf |&gt;\n  head()\n#&gt;   id gender anxiety study_hours   IU\n#&gt; 1  1   Male    42.9        13.6 65.4\n#&gt; 2  2   Male    52.6        10.5 66.3\n#&gt; 3  3   Male    47.5        11.0 84.0\n#&gt; 4  4 Female    56.5         7.8 85.8\n#&gt; 5  5   Male    40.5        15.7 55.2\n#&gt; 6  6 Female    59.5        13.8 78.8\n\nggplot2 permette di creare grafici chiari e visivamente accattivanti, suddividendo ogni grafico in componenti:\n\n\nDati ‚Üí Il dataset che vogliamo analizzare.\n\n\nGeometrie ‚Üí Il tipo di grafico (es. punti, barre, linee).\n\n\nMappatura estetica ‚Üí Il modo in cui i dati vengono rappresentati graficamente (es. colori, posizioni).\n\n18.6.2 Creare un grafico con ggplot2\nPer usare ggplot2, bisogna prima installarlo e attivarlo con:\nlibrary(ggplot2)\nSupponiamo di avere un dataset con il livello di ansia di studenti prima di un esame e vogliamo vedere se c‚Äô√® una relazione con il numero di ore di studio. Creiamo un grafico a dispersione (scatterplot):\n\ndf |&gt;\n  ggplot(\n    aes(x = study_hours, y = anxiety)\n  ) +\n  geom_point()\n\n\n\n\n\n\n\nQui diciamo a ggplot2:\n\nUsa il dataset studenti\n\nMetti ore_studio sull‚Äôasse X e livello_ansia sull‚Äôasse Y\n\nRappresenta i dati con punti\n\n\n18.6.3 Personalizzare il grafico\nPossiamo migliorare il grafico aggiungendo colore e titoli:\n\ndf |&gt;\n  ggplot(\n    aes(x = study_hours, y = anxiety, color = gender)\n  ) +\n  geom_point(size = 3) +\n  labs(\n    title = \"Relazione tra ore di studio e ansia\",\n    x = \"Ore di studio\",\n    y = \"Livello di ansia\",\n    color = \"Genere\"\n  )\n\n\n\n\n\n\n\nCosa cambia?\n\ni punti hanno colori diversi in base al genere;\nil grafico ha titoli chiari .\n\n\n18.6.3.1 Altri tipi di grafici\n\n\nIstogrammi ‚Üí Per vedere la distribuzione dei punteggi di ansia\n\ndf |&gt;\nggplot(\n  aes(x = anxiety)\n) +\ngeom_histogram(binwidth = 5)\n\n\n\n\n\n\n\n\n\nBoxplot ‚Üí Per confrontare l‚Äôansia tra gruppi diversi\n\ndf |&gt;\nggplot(\n  aes(x = gender, y = anxiety)\n) +\ngeom_boxplot()\n\n\n\n\n\n\n\n\n\nIn sintesi, ggplot2 √® un ottimo strumento per visualizzare dati in psicologia. Anche con pochi comandi, possiamo creare grafici utili per interpretare i dati in modo intuitivo.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#riflessioni-conclusive",
    "href": "chapters/eda/06_data_visualization.html#riflessioni-conclusive",
    "title": "18¬† Principi della visualizzazione dei dati",
    "section": "\n18.7 Riflessioni Conclusive",
    "text": "18.7 Riflessioni Conclusive\nUna visualizzazione ben progettata trasforma informazioni complesse in messaggi immediati e facilmente interpretabili, riducendo il carico cognitivo e favorendo decisioni informate. Seguendo i principi illustrati, √® possibile prevenire errori interpretativi e comunicare in modo responsabile i risultati di un‚Äôanalisi.\nSuggerimenti Chiave per Visualizzazioni Efficaci:\n\nChiarezza del Messaggio:\nDefinire l‚Äôobiettivo della visualizzazione e assicurarsi che il grafico trasmetta il messaggio principale in modo inequivocabile.\nUso Appropriato del Colore:\nSelezionare una palette limitata (circa cinque o sei colori) e accessibile per garantire coerenza e leggibilit√†.\nGuida dell‚ÄôAttenzione:\nUtilizzare dimensioni, posizionamento e contrasto per mettere in evidenza i dati rilevanti, eventualmente integrando annotazioni esplicative.\nGestione del Sovraccarico Visivo:\nApplicare la trasparenza per ridurre il sovrapposizionamento dei dati e, se necessario, ricorrere a tecniche di sottocampionamento.\nCoerenza degli Elementi Testuali:\nTitoli, etichette e legende devono essere chiari e intuitivi, evitando abbreviazioni eccessive o termini troppo tecnici.\n\nUlteriori Accortezze:\n\nEvitare distorsioni:\nPrediligere grafici semplici (ad es. barplot con asse che parte da zero) per non alterare la percezione delle proporzioni.\nOrdinare le categorie:\nDisporre le categorie in base ai valori, anzich√© in ordine alfabetico, per facilitare il confronto.\nMostrare tutti i dati:\nPreferire rappresentazioni che evidenziano anche i dati grezzi (come dot plot o strip chart) per non occultare informazioni rilevanti.\nConfronti coerenti:\nUtilizzare assi comuni quando si confrontano distribuzioni diverse, garantendo una valutazione accurata.\nTrasformazioni logaritmiche:\nImpiegare scale logaritmiche per dati distribuiti su ampi intervalli, migliorando la leggibilit√† dei valori estremi.\nCodifica di variabili aggiuntive:\nIntegrare informazioni supplementari tramite colore, dimensione o forma dei punti, soprattutto nei grafici a dispersione.\nEvitare rappresentazioni 3D:\nMantenere le visualizzazioni in 2D per evitare distorsioni nella percezione dei dati.\nLimitare le cifre decimali:\nMostrare solo il numero necessario di cifre significative per garantire chiarezza.\nAdattare la visualizzazione al pubblico:\nSemplificare i grafici e spiegare chiaramente i dati quando il target √® non specializzato.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#esercizi",
    "href": "chapters/eda/06_data_visualization.html#esercizi",
    "title": "18¬† Principi della visualizzazione dei dati",
    "section": "\n18.8 Esercizi",
    "text": "18.8 Esercizi\n\n\n\n\n\n\nEsercizi\n\n\n\n\n\nIn questo esercizio analizzerai i dati raccolti dagli studenti sulla Satisfaction With Life Scale (SWLS) e sulla Lubben Social Network Scale (LSNS-6). Le variabili incluse sono:\n\n\nSWLS: Punteggio totale della Scala di Soddisfazione per la Vita.\n\nLSNS-6: Punteggio totale sulla scala della rete sociale.\n\nGenere: Maschio/Femmina.\n\nTipo di scuola superiore: Liceo classico o scientifico vs.¬†altro.\n\nNumero di amici: Auto-riferito.\n\nNumero di uscite settimanali con gli amici.\n\nUtilizzerai questi dati per esplorare le distribuzioni, creare visualizzazioni efficaci e interpretare i risultati.\nEsercizi Teorici\n\n\nPrincipi della visualizzazione\n\nQuali sono i principali segnali visivi utilizzati nella visualizzazione dei dati? Fornisci un esempio pratico per ognuno.\nPerch√© la posizione e la lunghezza sono considerati segnali visivi pi√π efficaci rispetto all‚Äôarea e agli angoli?\nSpiega perch√© i grafici tridimensionali (3D) sono spesso inutili o fuorvianti.\n\n\n\nScelta della visualizzazione\n\nQuale tipo di grafico useresti per mostrare la distribuzione della variabile SWLS? Giustifica la tua risposta.\nSe volessi confrontare la distribuzione della SWLS tra due gruppi (ad esempio, in base al genere), quale grafico useresti? Perch√©?\n\n\n\nErrori comuni nella visualizzazione\n\nPerch√© i dynamite plots (grafici a barre con errore standard) sono considerati una cattiva pratica?\nSpiega perch√© √® importante iniziare l‚Äôasse Y da zero in un barplot.\nPerch√© √® preferibile ordinare le categorie in base ai valori invece che alfabeticamente?\n\n\n\nEsercizi Pratici in R\n1. Caricamento e ispezione dei dati\nCarica il dataset raccolto dagli studenti (dati_SWLS_LSNS.csv) e stampa un‚Äôanteprima dei dati.\n# Caricamento dei dati\ndf &lt;- read.csv(\"dati_SWLS_LSNS.csv\")\n\n# Esamina le prime righe\nhead(df)\nRispondi alle seguenti domande:\n\nQuante osservazioni ci sono nel dataset?\nCi sono valori mancanti? Se s√¨, quanti?\n\n2. Distribuzione delle variabili\nCrea le seguenti visualizzazioni per analizzare la distribuzione di SWLS e LSNS-6:\n\n\nIstogramma con sovrapposta la curva di densit√†.\n\nFunzione di distribuzione cumulativa empirica (eCDF).\n\nBox plot per la variabile SWLS.\n\n3. Confronto tra gruppi\n\nCrea un box plot della SWLS per genere.\nCrea un violin plot della LSNS-6 in base al tipo di scuola superiore.\n\n4. Relazioni tra variabili\n\nCrea un grafico di dispersione (scatter plot) per verificare se c‚Äô√® una relazione tra il punteggio SWLS e il numero di amici.\nAggiungi una linea di regressione al grafico per facilitare l‚Äôinterpretazione.\n\nggplot(df, aes(x = numero_amici, y = SWLS)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(title = \"Relazione tra SWLS e numero di amici\",\n       x = \"Numero di amici\",\n       y = \"Satisfaction With Life Scale (SWLS)\")\nDomande:\n\nQuale relazione osservi tra il numero di amici e la SWLS?\nIl numero di amici √® un buon predittore della soddisfazione per la vita?\n\n5. Esplorazione della rete sociale\n\nCrea un barplot per mostrare la distribuzione delle risposte medie ai sei item della LSNS-6.\nEsplora la relazione tra la frequenza delle uscite settimanali e il punteggio totale LSNS-6 utilizzando un box plot.\n\nConsegna\nSalva i grafici creati e rispondi alle domande in forma scritta. Carica il file su Moodle.\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n1. Risposte alle domande teoriche\nPrincipi della visualizzazione\n\nI segnali visivi principali sono posizione, lunghezza, angoli, area, luminosit√† e colore.\nLa posizione e lunghezza sono i segnali pi√π efficaci perch√© l‚Äôocchio umano √® molto preciso nel confrontare distanze e altezze, mentre √® meno efficace nel confrontare angoli e aree.\nI grafici tridimensionali (3D) spesso aggiungono confusione senza migliorare la leggibilit√†.\n\nScelta della visualizzazione\n\nPer mostrare la distribuzione della SWLS, √® preferibile usare istogrammi e box plot perch√© evidenziano la forma della distribuzione e la presenza di outlier.\nPer confrontare la SWLS tra generi, un box plot o violin plot √® l‚Äôopzione migliore, perch√© mostra la distribuzione completa.\n\nErrori comuni\n\nI dynamite plots nascondono la distribuzione dei dati e non mostrano la variabilit√† interna ai gruppi.\nIn un barplot, l‚Äôasse Y deve iniziare da zero per evitare distorsioni visive.\nLe categorie nei barplot devono essere ordinate per valore per facilitare il confronto.\n\n2. Soluzioni pratiche in R\nCaricamento dei dati\ndf &lt;- read.csv(\"dati_SWLS_LSNS.csv\")\n\n# Esamina il dataset\ndim(df)  # Numero di righe e colonne\nsum(is.na(df))  # Conteggio valori mancanti\nDistribuzione delle variabili\nggplot(df, aes(x = SWLS)) +\n  geom_histogram(\n  aes(y = after_stat(density)), bins = 10, fill = \"blue\", alpha = 0.5\n  ) +\n  geom_density(color = \"red\", size = 1.2)\nggplot(df, aes(SWLS)) +\n  stat_ecdf(geom = \"step\")\nggplot(df, aes(x = \"\", y = SWLS)) +\n  geom_boxplot() +\n  coord_flip()\nConfronto tra gruppi\nggplot(df, aes(x = genere, y = SWLS, fill = genere)) +\n  geom_boxplot()\nggplot(df, aes(x = scuola, y = LSNS6, fill = scuola)) +\n  geom_violin()\nRelazioni tra variabili\nggplot(df, aes(x = numero_amici, y = SWLS)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE)\nggplot(df, aes(x = uscite_settimanali, y = LSNS6)) +\n  geom_boxplot()\nConclusioni\n(Ad esempio) Le visualizzazioni mostrano che:\n\nSWLS e LSNS-6 variano in base al genere e al tipo di scuola.\nIl numero di amici ha un impatto positivo sulla SWLS, ma la relazione √® moderata.\nIl numero di uscite settimanali √® correlato positivamente con la rete sociale (LSNS-6).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#bibliografia",
    "href": "chapters/eda/06_data_visualization.html#bibliografia",
    "title": "18¬† Principi della visualizzazione dei dati",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nHealy, K. (2018). Data visualization: a practical introduction. Princeton University Press.\n\n\nIrizarry, R. A. (2024). Introduction to Data Science: Data Wrangling and Visualization with R. CRC Press.\n\n\nWeissgerber, T. L., Milic, N. M., Winham, S. J., & Garovic, V. D. (2015). Beyond bar and line graphs: time for a new data presentation paradigm. PLoS biology, 13(4), e1002128.\n\n\nWickham, H., √áetinkaya-Rundel, M., & Grolemund, G. (2023). R for data science. \" O‚ÄôReilly Media, Inc.\".\n\n\nWilke, C. O. (2019). Fundamentals of data visualization: a primer on making informative and compelling figures. O‚ÄôReilly Media.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html",
    "href": "chapters/eda/07_loc_scale.html",
    "title": "19¬† Indicatori di tendenza centrale e variabilit√†",
    "section": "",
    "text": "19.1 Introduzione\nLa visualizzazione grafica dei dati rappresenta il pilastro fondamentale di ogni analisi quantitativa. Grazie alle rappresentazioni grafiche adeguate, √® possibile individuare importanti caratteristiche di una distribuzione, quali la simmetria o l‚Äôasimmetria, nonch√© la presenza di una o pi√π mode. Successivamente, al fine di descrivere sinteticamente le principali caratteristiche dei dati, si rende necessario l‚Äôutilizzo di specifici indici numerici. In questo capitolo, verranno presentati i principali indicatori della statistica descrittiva.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Indicatori di tendenza centrale e variabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#indici-di-tendenza-centrale",
    "href": "chapters/eda/07_loc_scale.html#indici-di-tendenza-centrale",
    "title": "19¬† Indicatori di tendenza centrale e variabilit√†",
    "section": "\n19.2 Indici di Tendenza Centrale",
    "text": "19.2 Indici di Tendenza Centrale\nGli indici di tendenza centrale sono misure statistiche che cercano di rappresentare un valore tipico o centrale all‚Äôinterno di un insieme di dati. Sono utilizzati per ottenere una comprensione immediata della distribuzione dei dati senza dover analizzare l‚Äôintero insieme. Gli indici di tendenza centrale sono fondamentali nell‚Äôanalisi statistica, in quanto forniscono una sintesi semplice e comprensibile delle caratteristiche principali di un insieme di dati. I principali indici di tendenza centrale sono:\n\n\nMedia: La media √® la somma di tutti i valori divisa per il numero totale di valori. √à spesso utilizzata come misura generale di tendenza centrale, ma √® sensibile agli estremi (valori molto alti o molto bassi).\n\nMediana: La mediana √® il valore che divide l‚Äôinsieme di dati in due parti uguali. A differenza della media, non √® influenzata da valori estremi ed √® quindi pi√π robusta in presenza di outlier.\n\nModa: La moda √® il valore che appare pi√π frequentemente in un insieme di dati. In alcuni casi, pu√≤ non essere presente o esserci pi√π di una moda.\n\nLa scelta dell‚Äôindice di tendenza centrale appropriato dipende dalla natura dei dati e dall‚Äôobiettivo dell‚Äôanalisi. Ad esempio, la mediana potrebbe essere preferita alla media se l‚Äôinsieme di dati contiene valori anomali che potrebbero distorcere la rappresentazione centrale. La conoscenza e l‚Äôapplicazione corretta di questi indici possono fornire una preziosa intuizione sulle caratteristiche centrali di una distribuzione di dati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Indicatori di tendenza centrale e variabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#moda",
    "href": "chapters/eda/07_loc_scale.html#moda",
    "title": "19¬† Indicatori di tendenza centrale e variabilit√†",
    "section": "\n19.3 Moda",
    "text": "19.3 Moda\nLa moda (\\(\\text{Mo}\\)) rappresenta il valore della variabile che compare con maggiore frequenza in una distribuzione. In altre parole, √® il valore pi√π ricorrente nei dati.\n- Nelle distribuzioni unimodali, esiste una sola moda, che coincide con il valore centrale della distribuzione pi√π frequente.\n- Tuttavia, in alcune distribuzioni, possono emergere pi√π di una moda, rendendole multimodali. In questi casi, la moda perde il suo significato di indicatore unico di tendenza centrale, poich√© la presenza di pi√π valori con frequenze elevate rende difficile individuare un singolo punto di riferimento.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Indicatori di tendenza centrale e variabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#mediana",
    "href": "chapters/eda/07_loc_scale.html#mediana",
    "title": "19¬† Indicatori di tendenza centrale e variabilit√†",
    "section": "\n19.4 Mediana",
    "text": "19.4 Mediana\nLa mediana (\\(\\tilde{x}\\)) corrisponde al valore che divide il campione in due met√†: il 50% dei dati √® inferiore o uguale alla mediana e il restante 50% √® superiore o uguale. A differenza della media, la mediana √® meno influenzata dai valori estremi, rendendola una misura particolarmente robusta in presenza di dati asimmetrici o outlier.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Indicatori di tendenza centrale e variabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#media",
    "href": "chapters/eda/07_loc_scale.html#media",
    "title": "19¬† Indicatori di tendenza centrale e variabilit√†",
    "section": "\n19.5 Media",
    "text": "19.5 Media\nLa media aritmetica di un insieme di valori rappresenta il punto centrale o il baricentro della distribuzione dei dati. √à calcolata come la somma di tutti i valori divisa per il numero totale di valori, ed √® espressa dalla formula:\n\\[\n\\bar{x}=\\frac{1}{n}\\sum_{i=1}^n x_i,\n\\tag{19.1}\\]\ndove \\(x_i\\) rappresenta i valori nell‚Äôinsieme, \\(n\\) √® il numero totale di valori, e \\(\\sum\\) indica la sommatoria.\n\n19.5.1 Calcolo della Media con R\n\nPer calcolare la media di un piccolo numero di valori in R, possiamo utilizzare la somma di questi valori e dividerla per il numero totale di elementi. Consideriamo ad esempio i valori 12, 44, 21, 62, 24:\n\n(12 + 44 + 21 + 62 + 24) / 5\n#&gt; [1] 32.6\n\novvero\n\nx &lt;- c(12, 44, 21, 62, 24)\nmean(x)\n#&gt; [1] 32.6\n\n\n19.5.2 Propriet√† della Media\nUna propriet√† fondamentale della media √® che la somma degli scarti di ciascun valore dalla media √® zero:\n\\[\n\\sum_{i=1}^n (x_i - \\bar{x}) = 0.\\notag\n\\tag{19.2}\\]\nInfatti,\n\\[\n\\begin{aligned}\n\\sum_{i=1}^n (x_i - \\bar{x}) &= \\sum_i x_i - \\sum_i \\bar{x}\\notag\\\\\n&= \\sum_i x_i - n \\bar{x}\\notag\\\\\n&= \\sum_i x_i - \\sum_i x_i = 0.\\notag\n\\end{aligned}\n\\]\nQuesta propriet√† implica che i dati sono equamente distribuiti intorno alla media.\nIn R abbiamo:\n\nsum(x - mean(x))\n#&gt; [1] -7.105e-15\n\n\n\n\n\n\n\nNota\n\n\n\n\n\nQuando in un terminale viene visualizzato un numero come -7.105e-15 in notazione scientifica, esso corrisponde a \\(-7.105 \\cdot 10^{-15}\\), che √® effettivamente zero nel contesto dei calcoli numerici.\nQuesta approssimazione √® una conseguenza diretta della precisione finita dei calcolatori. I sistemi digitali, infatti, rappresentano i numeri reali attraverso una codifica in virgola mobile (floating point), che comporta inevitabili errori di arrotondamento. La ragione risiede nell‚Äôimpossibilit√† di memorizzare numeri reali con precisione assoluta.\nLo standard IEEE 754 a doppia precisione (64 bit), ampiamente utilizzato, suddivide la memoria in tre componenti:\n\n1 bit per il segno (positivo/negativo),\n\n11 bit per l‚Äôesponente (intervallo di scala),\n\n52 bit per la mantissa (o significando), che definisce le cifre significative.\n\nGrazie a questa struttura, √® possibile rappresentare numeri con una precisione di circa 15-17 cifre decimali. Tuttavia, qualsiasi valore non esprimibile in formato binario entro questi limiti subisce un troncamento o un arrotondamento, generando piccole discrepanze rispetto al risultato teorico.\n\n\n\n\n19.5.3 La media come Centro di Gravit√† dell‚ÄôIstogramma\nLa media aritmetica pu√≤ essere interpretata come il centro di gravit√† o il punto di equilibrio della distribuzione dei dati. In termini fisici, il centro di gravit√† √® il punto in cui la massa di un sistema √® equilibrata o concentrata.\nIn termini statistici, possiamo considerare la media come il punto in cui la distribuzione dei dati √® in equilibrio. Ogni valore dell‚Äôinsieme di dati pu√≤ essere visto come un punto materiale con una massa proporzionale al suo valore. Se immaginiamo questi punti disposti su una linea, con valori pi√π grandi a destra e pi√π piccoli a sinistra, la media corrisponder√† esattamente al punto in cui la distribuzione sarebbe in equilibrio.\n\n19.5.4 Principio dei Minimi Quadrati\nIl metodo dei minimi quadrati afferma che la posizione della media minimizza la somma dei quadrati delle distanze dai dati. Matematicamente, ci√≤ significa che la somma dei quadrati degli scarti tra ciascun valore osservato e la media √® minima. Questo principio √® alla base dell‚Äôanalisi statistica della regressione e conferma il ruolo della media come centro di gravit√† della distribuzione dei dati.\n\n19.5.4.1 Simulazione\nUtilizziamo una simulazione per verificare questo principio, calcolando la somma dei quadrati degli scarti per diversi valori e visualizzando il risultato con ggplot2.\n\n# Definizione dell'intervallo di valori da testare\nnrep &lt;- 10000\nM &lt;- seq(20, 40, length.out = nrep)\nres &lt;- rep(NA, nrep)\n\n# Calcolo della somma dei quadrati degli scarti per ciascun valore di M\nfor (i in 1:nrep) {\n  res[i] = sum((x - M[i])^2)\n}\n\n# Identificazione del valore minimo\nmin_index &lt;- which.min(res)\nmin_M &lt;- M[min_index]\n\n# Creazione del dataframe per ggplot\ndf &lt;- data.frame(M, res)\n\ndf |&gt; \n  ggplot(aes(x = M, y = res)) +\n  geom_line(color = \"blue\") +\n  geom_vline(xintercept = min_M, linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Minimizzazione della somma dei quadrati\",\n    x = \"Valore di M\",\n    y = \"Somma dei quadrati degli scarti\"\n  ) \n\n\n\n\n\n\n\nStampiamo il minimo:\n\nmin_M\n#&gt; [1] 32.6\n\nConfronto con la media:\n\nmean(x)\n#&gt; [1] 32.6\n\nOsserviamo che il valore di M che minimizza la somma dei quadrati degli scarti coincide con la media dei dati, confermando il principio dei minimi quadrati.\n\n19.5.5 Le Proporzioni Sono Medie\nSe una collezione consiste solo di uni e zeri, allora la somma della collezione √® il numero di uni in essa, e la media della collezione √® la proporzione di uni.\n\nzero_one &lt;- c(1, 1, 1, 0)\nresult &lt;- mean(zero_one)\nresult\n#&gt; [1] 0.75\n\n√à possibile sostituire 1 con il valore booleano True e 0 con False:\n\nmean(c(TRUE, TRUE, TRUE, FALSE))\n#&gt; [1] 0.75\n\n\n19.5.6 Limiti della Media Aritmetica\nLa media aritmetica, tuttavia, ha alcune limitazioni: non sempre √® l‚Äôindice pi√π adeguato per descrivere accuratamente la tendenza centrale della distribuzione, specialmente quando si verificano asimmetrie o valori anomali (outlier). In queste situazioni, √® pi√π indicato utilizzare la mediana o la media spuntata (come spiegheremo successivamente).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Indicatori di tendenza centrale e variabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#come-descrivere-la-tendenza-centrale-in-distribuzioni-asimmetriche",
    "href": "chapters/eda/07_loc_scale.html#come-descrivere-la-tendenza-centrale-in-distribuzioni-asimmetriche",
    "title": "19¬† Indicatori di tendenza centrale e variabilit√†",
    "section": "\n19.6 Come Descrivere la Tendenza Centrale in Distribuzioni Asimmetriche",
    "text": "19.6 Come Descrivere la Tendenza Centrale in Distribuzioni Asimmetriche\nIl diverso significato degli indici di tendenza centrale ‚Äì moda, media e mediana ‚Äì diventa evidente quando si analizzano distribuzioni asimmetriche. Per illustrare questo concetto, utilizzeremo i dati del Progetto Natsal, contenuti nel file sexual-partners.csv.\nNegli anni ‚Äô80, con la crescente preoccupazione per l‚ÄôAIDS, le autorit√† sanitarie del Regno Unito si resero conto della mancanza di dati affidabili sui comportamenti sessuali della popolazione. In particolare, vi erano dubbi sulla frequenza con cui le persone cambiavano partner, sul numero di partner simultanei e sulle pratiche sessuali adottate. Questa conoscenza era essenziale per prevedere la diffusione delle malattie sessualmente trasmissibili nella societ√† e per pianificare adeguatamente i servizi sanitari. Tuttavia, si faceva ancora riferimento ai dati raccolti da Alfred Kinsey negli Stati Uniti negli anni ‚Äô40, che non tenevano conto della rappresentativit√† del campione.\nA partire dalla fine degli anni ‚Äô80, vennero dunque avviati nel Regno Unito e negli Stati Uniti ampi e rigorosi studi sui comportamenti sessuali, nonostante una forte opposizione in alcuni ambienti. Nel Regno Unito, il governo guidato da Margaret Thatcher ritir√≤ il proprio sostegno a un‚Äôimportante indagine sui comportamenti sessuali all‚Äôultimo momento. Fortunatamente, i ricercatori riuscirono a ottenere finanziamenti da enti benefici, dando vita al National Sexual Attitudes and Lifestyles Survey (Natsal). Da allora, questa indagine viene condotta ogni dieci anni, a partire dal 1990. La terza rilevazione, denominata Natsal-3, √® stata effettuata intorno al 2010.\nPoniamoci il problema di descrivere la tendenza centrale per i dati contenuti nel file sexual-partners.csv, separatamente per maschi e femmine. Il dataset fornisce la distribuzione del numero totale dichiarato di partner sessuali di sesso opposto nella vita per uomini e donne di et√† compresa tra 35 e 44 anni. I dati provengono dal sondaggio Natsal-3 e corrispondono a un totale di 796 uomini e 1193 donne.\nProcediamo all‚Äôimportazione dei dati per iniziare l‚Äôanalisi.\n\ndf &lt;- rio::import(here::here(\"data\", \"sexual-partners.csv\"))\n\nEsaminiamo alcune righe prese a caso dal data frame df:\n\ndf[sample(1:nrow(df), size = 10, replace = FALSE), ]\n#&gt;      Gender NumPartners\n#&gt; 561     Man          15\n#&gt; 321     Man           6\n#&gt; 1177  Woman           3\n#&gt; 1098  Woman           2\n#&gt; 1252  Woman           4\n#&gt; 1170  Woman           3\n#&gt; 634     Man          21\n#&gt; 49      Man           1\n#&gt; 1152  Woman           3\n#&gt; 1327  Woman           5\n\nLa colonna Gender riporta il genere del rispondente e la colonna NumPartners il numero di partner sessuali di sesso opposto dichiarati.\nEsaminiamo la numerosit√† di ciascun gruppo.\n\ndf |&gt; \n  group_by(Gender) |&gt; \n  summarize(count = n())\n#&gt; # A tibble: 2 √ó 2\n#&gt;   Gender count\n#&gt;   &lt;chr&gt;  &lt;int&gt;\n#&gt; 1 Man      796\n#&gt; 2 Woman   1193\n\nPoniamoci innnanzitutto il problema di visualizzare i dati con un istogramma, separatamente per maschi e femmine. Per ragioni di spazio ci limiteremo ad un numero massimo di partner sessuali di 50 (ma in questo campione il numero massimo arriva a 501 per gli uomini e 550 per le donne):\n\ndf |&gt; \n  group_by(Gender) |&gt; \n  summarize(maximum = max(NumPartners))\n#&gt; # A tibble: 2 √ó 2\n#&gt;   Gender maximum\n#&gt;   &lt;chr&gt;    &lt;int&gt;\n#&gt; 1 Man        501\n#&gt; 2 Woman      550\n\nIniziamo calcolando la percentuale di intervistati per ciascun valore possibile della variabile ‚Äúnumero di partner sessuali‚Äù, compreso tra 0 e 50. Il calcolo verr√† svolto in due passaggi:\n\nConteggio delle frequenze assolute: Per ogni valore della variabile ‚Äúnumero di partner sessuali‚Äù e per ciascun gruppo di genere (uomini e donne), contiamo quante volte quel valore compare nei dati.\nCalcolo delle percentuali relative: Per ciascun gruppo di genere, dividiamo il conteggio di ogni valore per il totale delle osservazioni nel gruppo e moltiplichiamo per 100 per ottenere la percentuale.\n\n\n# Filtra i dati troncando il numero di partner a 50\ndf_truncated &lt;- df[df$NumPartners &lt;= 50, ]\n\n# Calcola il conteggio per ciascun genere e numero di partner\ncounts_data &lt;- df_truncated %&gt;%\n  group_by(Gender, NumPartners) %&gt;%  # Raggruppa per genere e numero di partner\n  summarise(Count = n(), .groups = \"drop\")  # Conta le occorrenze\n\n# Aggiunge la percentuale relativa per ciascun genere\npercentage_data &lt;- counts_data %&gt;%\n  group_by(Gender) %&gt;%  # Raggruppa nuovamente per genere\n  mutate(Percentage = Count / sum(Count) * 100)  # Calcola la percentuale\n\nhead(percentage_data)\n#&gt; # A tibble: 6 √ó 4\n#&gt; # Groups:   Gender [1]\n#&gt;   Gender NumPartners Count Percentage\n#&gt;   &lt;chr&gt;        &lt;int&gt; &lt;int&gt;      &lt;dbl&gt;\n#&gt; 1 Man              0     6      0.789\n#&gt; 2 Man              1   100     13.2  \n#&gt; 3 Man              2    44      5.79 \n#&gt; 4 Man              3    39      5.13 \n#&gt; 5 Man              4    58      7.63 \n#&gt; 6 Man              5    51      6.71\n\nPossiamo ora creare gli istogrammi per maschi e femmine:\n\n# Crea l'istogramma separato per maschi e femmine\ngender_labels &lt;- c(\"Man\" = \"Uomini 35-44\", \"Woman\" = \"Donne 35-44\")\n\n# Trova il massimo valore di Percentage per impostare lo stesso limite\ny_max &lt;- max(percentage_data$Percentage)\n\n# Grafico con limiti dell'asse y uguali nei due pannelli\npercentage_data |&gt;\n  ggplot(aes(NumPartners, Percentage, fill = Gender)) +\n  geom_col(position = \"dodge\", color = \"black\") +\n  facet_wrap(~Gender, labeller = labeller(Gender = gender_labels)) +\n  scale_y_continuous(limits = c(0, y_max)) +  # Imposta i limiti dell'asse y\n  labs(\n    x = \"Numero di partner sessuali di sesso opposto dichiarati nella vita\",\n    y = \"Percentuale\"\n  ) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nNota\n\n\n\n\n\nSenza distinguere per genere, √® possibile ottenere l‚Äôistogramma con il seguente codice:\n\ndf_truncated |&gt;\n  ggplot(\n    aes(\n      x = NumPartners,\n      y = after_stat(density)\n    )\n  ) +\n  geom_histogram(binwidth = 2, fill = \"lightblue\", color = \"black\", alpha = 0.7) +\n  labs(\n    title = \"Distribuzione del Numero di Partner Sessuali\",\n    x = \"Numero di Partner\",\n    y = \"Densit√†\"\n  )\n\n\n\n\n\n\n\nSi noti l‚Äôuso di y = after_stat(density) all‚Äôinterno di aes(), che consente di normalizzare l‚Äôistogramma affinch√© l‚Äôarea totale sia pari a 1. In questo modo, l‚Äôistogramma rappresenta una densit√† di probabilit√† anzich√© una semplice frequenza assoluta.\n\n\n\nNotiamo che la distribuzione √® altamente asimmetrica positiva. Come possiamo descrivere la tendenza centrale di questi dati?\nCalcoliamo gli indici di tendenza centrale all‚Äôinterno dei due gruppi. Per la moda utilizziamo una funzione personalizzata:\n\n# Funzione personalizzata per calcolare la moda\nget_mode &lt;- function(x) {\n  # Calcola la tabella di frequenza e restituisce il valore con frequenza massima\n  tbl &lt;- table(x)\n  as.numeric(names(tbl)[which.max(tbl)])\n}\n\n# Calcolo delle statistiche per Gender\ndf |&gt; \n  group_by(Gender) |&gt; \n  summarise(\n    mean_sex_partner = mean(NumPartners, na.rm = TRUE),\n    median_sex_partner = median(NumPartners, na.rm = TRUE),\n    mode_sex_partner = get_mode(NumPartners)  # Usa la funzione personalizzata per la moda\n  )\n#&gt; # A tibble: 2 √ó 4\n#&gt;   Gender mean_sex_partner median_sex_partner mode_sex_partner\n#&gt;   &lt;chr&gt;             &lt;dbl&gt;              &lt;dbl&gt;            &lt;dbl&gt;\n#&gt; 1 Man               17.0                   8                1\n#&gt; 2 Woman              8.23                  5                1\n\n\n\n\n\n\n\nNota\n\n\n\n\n\nPer trovare la moda, anzich√© definire una funzione personalizzata come get_mode() √® anche possibile usare dplyr:\n\ndf |&gt; \n  group_by(Gender) |&gt; \n  summarise(\n    mean_sex_partner = mean(NumPartners, na.rm = TRUE),\n    median_sex_partner = median(NumPartners, na.rm = TRUE),\n    mode_sex_partner = as.numeric(names(which.max(table(NumPartners))))\n  )\n#&gt; # A tibble: 2 √ó 4\n#&gt;   Gender mean_sex_partner median_sex_partner mode_sex_partner\n#&gt;   &lt;chr&gt;             &lt;dbl&gt;              &lt;dbl&gt;            &lt;dbl&gt;\n#&gt; 1 Man               17.0                   8                1\n#&gt; 2 Woman              8.23                  5                1\n\nQuesta soluzione evita la definizione esplicita di una funzione get_mode(), ma il principio √® lo stesso.\n\n\n\n√à evidente che, quando la distribuzione dei dati √® altamente asimmetrica, come nel caso attuale, gli indici di tendenza centrale ‚Äì media, mediana e moda ‚Äì possono fornire risultati molto diversi, rendendo difficile individuare una misura rappresentativa della tendenza centrale.\n\nLa media risulta pi√π elevata rispetto alla mediana e alla moda. Questo √® tipico di una distribuzione asimmetrica positiva, caratterizzata da una lunga coda destra: pochi individui con valori estremamente alti influenzano la media, spostandola verso destra.\n\nLa mediana, invece, rappresenta il valore centrale della distribuzione e risulta meno influenzata dai valori estremi. Per questo motivo, √® spesso pi√π vicina alla ‚Äúrealt√†‚Äù dei dati, offrendo una stima pi√π robusta della tendenza centrale per la maggior parte degli individui.\n\nLa moda, infine, corrisponde al valore pi√π frequente nella distribuzione (in questo caso, 1 partner). Tuttavia, in presenza di un‚Äôelevata dispersione dei dati, la moda pu√≤ risultare poco rappresentativa della distribuzione complessiva.\n\nIn conclusione, quando la distribuzione √® fortemente asimmetrica, la mediana √® generalmente l‚Äôindice di tendenza centrale pi√π appropriato. Essendo insensibile ai valori estremi, fornisce una rappresentazione pi√π robusta della ‚Äúposizione centrale‚Äù dei dati. Tuttavia, √® utile integrare la mediana con la media e la moda per offrire un quadro pi√π completo della distribuzione.\nPer una descrizione efficace della tendenza centrale in distribuzioni asimmetriche, si consiglia dunque di seguire questa procedura:\n\nutilizzare la mediana come misura principale della tendenza centrale;\n\nriportare media e moda come complemento per confrontare i risultati e interpretare eventuali differenze.\n\n√à comunque fondamentale visualizzare la distribuzione dei dati attraverso grafici appropriati, come istogrammi o boxplot. Questi strumenti consentono di evidenziare chiaramente l‚Äôasimmetria, identificare valori estremi e comprendere meglio la struttura dei dati.\nInoltre, per arricchire i sommari numerici, √® importante associare indici di dispersione che tratteremo in seguito.\n\n19.6.1 Media Spuntata\nLa media spuntata, indicata come \\(\\bar{x}_t\\) o trimmed mean, √® un metodo di calcolo della media che prevede l‚Äôeliminazione di una determinata percentuale di dati estremi prima di effettuare la media aritmetica. Solitamente, viene eliminato il 10% dei dati, ovvero il 5% all‚Äôinizio e alla fine della distribuzione. Per ottenere la media spuntata, i dati vengono ordinati in modo crescente, \\(x_1 \\leq x_2 \\leq x_3 \\leq \\dots \\leq x_n\\), e quindi viene eliminato il primo 5% e l‚Äôultimo 5% dei dati nella sequenza ordinata. Infine, la media spuntata √® calcolata come la media aritmetica dei dati rimanenti. Questo approccio √® utile quando ci sono valori anomali o quando la distribuzione √® asimmetrica e la media aritmetica non rappresenta adeguatamente la tendenza centrale dei dati.\n\nEsempio 19.1 A titolo di esempio, procediamo al calcolo della media spuntata dei valori NumPartners per i due gruppi definiti dalla variabile Gender, escludendo il 10% dei valori pi√π estremi.\n\nglimpse(df)\n#&gt; Rows: 1,989\n#&gt; Columns: 2\n#&gt; $ Gender      &lt;chr&gt; \"Man\", \"Man\", \"Man\", \"Man\", \"Man\", \"Man\", \"Man\", \"Man\"‚Ä¶\n#&gt; $ NumPartners &lt;int&gt; 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ‚Ä¶\n\nUomini:\n\nsex_partners_men &lt;- df[df$Gender == \"Man\", \"NumPartners\"]\nmean(sex_partners_men, trim = 0.10, na.rm = TRUE)\n#&gt; [1] 10.6\n\nDonne:\n\nsex_partners_women &lt;- df[df$Gender == \"Woman\", \"NumPartners\"]\nmean(sex_partners_women, trim = 0.10, na.rm = TRUE)\n#&gt; [1] 6.013\n\n\n\n19.6.2 Quando Usare Media, Media Spuntata, Moda e Mediana\nLa scelta della misura di tendenza centrale pi√π appropriata dipende dal tipo di dati, dalla distribuzione e dalla presenza di valori anomali o asimmetrie.\n\n19.6.2.1 Moda\nLa moda √® il valore che compare con maggiore frequenza nei dati ed √® l‚Äôunica misura di tendenza centrale utilizzabile per dati a livello nominale (categorie senza ordine) o ordinale (categorie ordinate ma senza distanza definita). Tuttavia:\n- In una distribuzione unimodale, la moda pu√≤ rappresentare un indicatore significativo della tendenza centrale.\n- In distribuzioni multimodali (con pi√π valori ricorrenti), la moda diventa meno interpretabile, poich√© l‚Äôesistenza di pi√π ‚Äúpicchi‚Äù rende difficile individuare un singolo valore rappresentativo.\n- Nei dati continui, la moda pu√≤ non essere definita o risultare meno informativa, soprattutto in presenza di valori unici.\n\n19.6.2.2 Media\nLa media aritmetica √® una misura efficace di tendenza centrale se la distribuzione √® simmetrica e priva di valori anomali. In tali condizioni, la media rappresenta il ‚Äúbaricentro‚Äù della distribuzione, equilibrando i valori a sinistra e a destra. Tuttavia:\n\nIn distribuzioni asimmetriche o con outlier, la media √® fortemente influenzata dai valori estremi e tende a spostarsi nella direzione della coda pi√π lunga (asimmetria positiva o negativa).\n\nIn questi casi, la media potrebbe non essere rappresentativa della tendenza centrale reale.\n\n19.6.2.3 Media Spuntata\nLa media spuntata √® una versione modificata della media, calcolata dopo aver rimosso una certa percentuale di valori estremi (generalmente il 5% o il 10%) sia dalla coda inferiore che da quella superiore della distribuzione. Questa misura √® particolarmente utile quando:\n- La distribuzione √® asimmetrica o contiene outlier, ma si desidera comunque una stima della tendenza centrale che consideri gran parte dei dati.\n- La media spuntata √® meno sensibile ai valori anomali rispetto alla media tradizionale, pur mantenendo il vantaggio di considerare un‚Äôampia porzione dei dati.\n\n19.6.2.4 Mediana\nLa mediana √® il valore centrale che divide il campione in due met√†: il 50% dei dati √® inferiore e il restante 50% √® superiore. √à una misura robusta della tendenza centrale, particolarmente adatta quando:\n- La distribuzione √® asimmetrica o contiene valori anomali. Poich√© si basa sulla posizione dei dati e non sulle loro dimensioni, la mediana non √® influenzata da valori estremi.\n- Nei dati ordinali, la mediana √® spesso pi√π appropriata della media, poich√© non richiede una scala numerica con distanze precise.\n\n19.6.2.5 Quale Misura Scegliere?\n\nDistribuzioni Simmetriche:\nLa media √® la scelta pi√π appropriata, poich√© riflette bene la tendenza centrale.\nDistribuzioni Asimmetriche o con Outlier:\nLa mediana √® preferibile perch√© √® robusta e meno influenzata dai valori estremi. In alternativa, si pu√≤ utilizzare la media spuntata per ottenere un compromesso tra media e mediana.\nDati Categoriali:\nLa moda √® l‚Äôunica misura applicabile, ma √® interpretabile solo in distribuzioni unimodali.\nDistribuzioni Multimodali:\nIn questo caso, √® importante visualizzare i dati (ad esempio con un istogramma) e descrivere ciascun ‚Äúpicco‚Äù separatamente, poich√© nessuna delle misure tradizionali (media, mediana, moda) sar√† sufficiente da sola per rappresentare la tendenza centrale.\n\nIn conclusione\n\nLa media √® ideale per distribuzioni simmetriche senza valori estremi.\n\nLa mediana √® pi√π robusta e appropriata in caso di asimmetria o outlier.\n\nLa media spuntata rappresenta una soluzione intermedia utile nei casi con pochi valori anomali.\n\nLa moda √® rilevante solo per dati nominali o ordinale, ma perde significato in distribuzioni multimodali.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Indicatori di tendenza centrale e variabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#quantili-e-misure-di-dispersione",
    "href": "chapters/eda/07_loc_scale.html#quantili-e-misure-di-dispersione",
    "title": "19¬† Indicatori di tendenza centrale e variabilit√†",
    "section": "\n19.7 Quantili e Misure di Dispersione",
    "text": "19.7 Quantili e Misure di Dispersione\nAccanto alle misure di tendenza centrale (media, mediana, moda), i quantili descrivono la posizione relativa di un‚Äôosservazione all‚Äôinterno di una distribuzione. Mentre le misure di tendenza centrale identificano un ‚Äúvalore tipico‚Äù, i quantili rispondono alla domanda: Qual √® il valore al di sotto del quale si trova una certa proporzione dei dati?\n\n19.7.1 Definizione Formale\nIl quantile non interpolato di ordine \\(p\\) (\\(0 &lt; p &lt; 1\\)) √® il valore \\(q_p = x_{(k)}\\), dove:\n\n\n\\(x_{(k)}\\) √® il \\(k\\)-esimo elemento nei dati ordinati in modo crescente.\n\n\\(k = \\lceil p \\cdot n \\rceil\\), con \\(n =\\) numero totale di osservazioni e \\(\\lceil \\cdot \\rceil\\) la funzione arrotondamento all‚Äôintero superiore.\n\n\n19.7.1.1 Esempio di Calcolo\nDati ordinati: \\(\\{15, 20, 23, 25, 28, 30, 35, 40, 45, 50\\}\\).\nCalcolo del 30¬∞ percentile (\\(p = 0.3\\)):\n\n\n\\(k = \\lceil 0.3 \\cdot 10 \\rceil = 3\\).\nIl quantile corrisponde al terzo valore: \\(q_{0.3} = 23\\).\n\n19.7.2 Tipologie di Quantili\n\n19.7.2.1 Quantili Interpolati\nQuando \\(p \\cdot n\\) non √® un intero, si utilizza un quantile interpolato, calcolato con interpolazione lineare tra due valori consecutivi. Questo metodo √® standard in software statistici (es. R, Python).\n\n19.7.2.2 Percentili\nCaso particolare di quantili, dividono i dati in 100 parti uguali:\n\n\n25¬∞ percentile (primo quartile \\(Q_1\\)): 25% dei dati √® inferiore a questo valore.\n\n50¬∞ percentile (mediana): Divide la distribuzione in due met√† uguali.\n\n75¬∞ percentile (terzo quartile \\(Q_3\\)): 75% dei dati √® inferiore a questo valore.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Indicatori di tendenza centrale e variabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#importanza-dei-quantili-nellanalisi-dei-dati",
    "href": "chapters/eda/07_loc_scale.html#importanza-dei-quantili-nellanalisi-dei-dati",
    "title": "19¬† Indicatori di tendenza centrale e variabilit√†",
    "section": "\n19.8 Importanza dei Quantili nell‚ÄôAnalisi dei Dati",
    "text": "19.8 Importanza dei Quantili nell‚ÄôAnalisi dei Dati\nI quantili permettono di:\n\n\nEsplorare la variabilit√†: Identificare range, asimmetrie e code della distribuzione.\n\nConfrontare gruppi: Analizzare differenze nella dispersione tra sottopopolazioni.\n\nRilevare valori anomali: Utilizzando regole come \\(\\text{valore anomalo} &gt; Q_3 + 1.5 \\cdot \\text{IQR}\\).\n\n\nEsempio 19.2 Consideriamo ora la variabile NumPartners per due gruppi definiti dalla variabile Gender (‚ÄúMan‚Äù e ‚ÄúWoman‚Äù). Calcoleremo i quantili di ordine 0.1 e 0.9 per ciascun gruppo:\n\nIl quantile di ordine 0.1 rappresenta il valore al di sotto del quale si trova il 10% dei dati.\n\nIl quantile di ordine 0.9 rappresenta il valore al di sotto del quale si trova il 90% dei dati.\n\nCalcolo per il Gruppo ‚ÄúMan‚Äù:\n\n# Quantili di ordine 0.1 e 0.9 per i maschi\nquantile(df[df$Gender == \"Man\", \"NumPartners\"], probs = c(0.1, 0.9))\n#&gt;  10%  90% \n#&gt;  1.0 34.5\n\n\n10¬∞ percentile (0.1): \\(1.0\\) ‚Üí Il 10% degli uomini ha dichiarato al massimo 1 partner sessuale.\n\n90¬∞ percentile (0.9): \\(34.5\\) ‚Üí Il 10% degli uomini con i valori pi√π alti ha dichiarato pi√π di 34 partner sessuali.\n\nCalcolo per il Gruppo ‚ÄúWoman‚Äù:\n\n# Quantili di ordine 0.1 e 0.9 per le femmine\nquantile(df[df$Gender == \"Woman\", \"NumPartners\"], probs = c(0.1, 0.9))\n#&gt; 10% 90% \n#&gt;   1  18\n\n\n10¬∞ percentile (0.1): \\(1.0\\) ‚Üí Anche per le donne, il 10% dei valori pi√π bassi corrisponde a 1 partner sessuale.\n\n90¬∞ percentile (0.9): \\(18.0\\) ‚Üí Il 10% delle donne con i valori pi√π alti ha dichiarato pi√π di 18 partner sessuali.\n\nI quantili calcolati forniscono una descrizione chiara della dispersione e della variabilit√† dei dati nei due gruppi:\n\nIl fatto che il 10¬∞ percentile sia identico per entrambi i gruppi suggerisce che una porzione simile di intervistati dichiara un numero molto basso di partner sessuali.\n\nLa differenza nel 90¬∞ percentile tra uomini e donne √® significativa:\n\nPer gli uomini, il valore √® pi√π alto (\\(34.5\\)), indicando una maggiore presenza di valori estremi nella coda superiore della distribuzione.\n\nPer le donne, il valore (\\(18.0\\)) √® inferiore, suggerendo una minore dispersione nella parte alta della distribuzione.\n\n\n\nQuesta differenza evidenzia una asimmetria positiva pi√π pronunciata nel gruppo degli uomini, dove pochi individui con valori elevati ‚Äútirano‚Äù la coda della distribuzione verso destra.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Indicatori di tendenza centrale e variabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#la-media-come-rappresentazione-della-psicologia-umana-unarma-a-doppio-taglio",
    "href": "chapters/eda/07_loc_scale.html#la-media-come-rappresentazione-della-psicologia-umana-unarma-a-doppio-taglio",
    "title": "19¬† Indicatori di tendenza centrale e variabilit√†",
    "section": "\n19.9 La Media come Rappresentazione della Psicologia Umana: Un‚ÄôArma a Doppio Taglio?",
    "text": "19.9 La Media come Rappresentazione della Psicologia Umana: Un‚ÄôArma a Doppio Taglio?\nLa media √® uno degli strumenti statistici pi√π semplici e intuitivi che i ricercatori utilizzano per sintetizzare i dati. √à un indice di tendenza centrale familiare e intuitivo: se chiediamo a un gruppo di persone la loro et√† e calcoliamo la media, otteniamo un valore che sintetizza in un‚Äôunica cifra l‚Äôinformazione disponibile. Ma cosa significa, in realt√†, ‚Äúriassumere‚Äù i dati con la media? E soprattutto, questa operazione ha senso quando si studiano i processi psicologici e il comportamento umano?\nIn molte discipline scientifiche, il concetto di media √® utile perch√© descrive fenomeni che tendono a essere stabili e uniformi. Per esempio, se misuriamo l‚Äôaltezza di un gruppo di persone, possiamo aspettarci che la distribuzione sia approssimativamente normale e che la media offra una stima ragionevole di un valore tipico. Tuttavia, la mente umana e i processi psicologici non funzionano come il sistema cardiovascolare o i muscoli. Ogni persona ha esperienze uniche che plasmano le sue risposte, i suoi pensieri e le sue emozioni.\nUn problema centrale, sollevato da Speelman & McGann (2013), riguarda l‚Äôimplicita assunzione che ci sia un vero valore sottostante ai processi psicologici che possiamo stimare attraverso la media, come se il comportamento umano fosse determinato da meccanismi identici in ogni individuo, con le differenze attribuibili solo a ‚Äúrumore‚Äù sperimentale. Questo approccio, tipico della psicologia sperimentale tradizionale, assume che testare un gruppo di persone e mediare i loro risultati ci permetta di rivelare la struttura comune della mente umana. Ma questa assunzione √® davvero giustificata?\n\n19.9.1 La Fallacia Ergodica e l‚ÄôIllusione dell‚ÄôUniversalit√†\nUn errore metodologico frequente nella psicologia √® la cosiddetta fallacia ergodica, ovvero l‚Äôerrata convinzione che le caratteristiche medie di un gruppo possano essere automaticamente applicate ai singoli individui che lo compongono (Speelman et al., 2024). Questo equivoco nasce dall‚Äôidea che la media descriva un valore ‚Äútipico‚Äù valido per tutti, senza considerare le differenze individuali o le variazioni nel tempo.\nImmaginiamo di studiare la felicit√† di un gruppo di persone nel corso di una settimana e di calcolare la media dei loro punteggi di benessere giornalieri. Se luned√¨ una persona ha un punteggio di 2 (molto infelice), mercoled√¨ 5 (moderatamente felice) e sabato 8 (molto felice), il suo punteggio medio sar√† 5. Tuttavia, questo valore intermedio non rappresenta in alcun modo la realt√† soggettiva vissuta da quella persona nei singoli giorni. Lo stesso problema si pone quando si usano le medie per descrivere abilit√† cognitive, tratti di personalit√† o stati emotivi: la media pu√≤ nascondere fluttuazioni e differenze individuali fondamentali per comprendere la psicologia umana.\nIl rischio, come sottolineato da Molden & Dweck (2006), √® che il nostro desiderio di trovare universalit√† nei processi cognitivi ci porti a enfatizzare somiglianze tra le persone, ignorando le variazioni individuali che possono essere altrettanto, se non pi√π, informative. Per esempio, due studenti con lo stesso punteggio medio in un test di memoria potrebbero aver ottenuto quel risultato in modi completamente diversi: uno potrebbe aver avuto prestazioni costantemente nella media, mentre l‚Äôaltro potrebbe aver avuto picchi di eccellenza alternati a difficolt√† estreme.\n\n19.9.2 La Media: Uno Strumento da Usare con Cautela\nQuesti problemi non significano che la media sia inutile in psicologia. √à un indicatore potente e spesso informativo, ma deve essere interpretato con cautela. In particolare, non pu√≤ essere usata per fare inferenze sui singoli individui senza considerare altre misure, come la varianza e la deviazione standard, che ci dicono quanto i dati siano dispersi intorno alla media.\nIn psicologia, comprendere la variabilit√† √® tanto importante quanto individuare una tendenza centrale. Se vogliamo davvero capire il comportamento umano, dobbiamo chiederci non solo qual √® il valore medio? ma anche quanto variano i dati? e cosa ci dice questa variabilit√† sulle differenze individuali? Nella prossima sezione, esamineremo questi concetti e vedremo come la varianza e la deviazione standard ci aiutano a catturare le differenze che la media, da sola, non pu√≤ rivelare.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Indicatori di tendenza centrale e variabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#la-variabilit√†-nei-dati-psicologici",
    "href": "chapters/eda/07_loc_scale.html#la-variabilit√†-nei-dati-psicologici",
    "title": "19¬† Indicatori di tendenza centrale e variabilit√†",
    "section": "\n19.10 La Variabilit√† nei Dati Psicologici",
    "text": "19.10 La Variabilit√† nei Dati Psicologici\nNei fenomeni psicologici e comportamentali, la variabilit√† √® una caratteristica intrinseca. Ad esempio, se misuriamo il livello di stress percepito da una persona pi√π volte nella stessa giornata, √® raro osservare lo stesso valore anche utilizzando strumenti identici. Allo stesso modo, un questionario standardizzato sull‚Äôautostima somministrato a un gruppo di studenti universitari restituir√† punteggi differenti per ciascun partecipante. Anche registrando i tempi di reazione in un compito cognitivo, noteremo fluttuazioni sia tra individui diversi sia nelle prestazioni dello stesso individuo in prove ripetute.\nQuesta dispersione sistematica non √® un ‚Äúrumore‚Äù da ignorare, ma un elemento informativo cruciale. L‚Äôanalisi statistica in psicologia ha infatti uno scopo duplice: da un lato, quantificare la variabilit√†; dall‚Äôaltro, identificarne le origini. Differenze individuali, contesto ambientale, errori di misurazione o interazioni tra fattori sono solo alcune delle possibili fonti che contribuiscono alla variazione osservata.\nIn questa sezione esploreremo:\n\n\nLa scomposizione della variabilit√† in componenti spiegate (attribuibili a fattori noti, come un intervento sperimentale) e non spiegate (legate a elementi casuali o non controllati).\n\n\nStrumenti per descriverla, sia attraverso rappresentazioni grafiche (boxplot, istogrammi) sia mediante indici numerici (differenza interquartile, varianza, deviazione standard).\n\nComprendere la variabilit√† non √® un esercizio tecnico, ma un passo fondamentale per interpretare fenomeni complessi come le differenze di personalit√†, le oscillazioni emotive o l‚Äôefficacia di una terapia. Ogni modello psicologico, infatti, deve fare i conti con questa dimensione dinamica e multideterminata dei dati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Indicatori di tendenza centrale e variabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#misure-di-dispersione-basate-sui-quantili",
    "href": "chapters/eda/07_loc_scale.html#misure-di-dispersione-basate-sui-quantili",
    "title": "19¬† Indicatori di tendenza centrale e variabilit√†",
    "section": "\n19.11 Misure di Dispersione Basate sui Quantili",
    "text": "19.11 Misure di Dispersione Basate sui Quantili\nPer descrivere la variabilit√† dei dati, uno dei metodi pi√π semplici consiste nell‚Äôutilizzo di indici basati sui quantili. Questi indici forniscono informazioni sulla dispersione dei valori senza fare assunzioni sulla forma della distribuzione.\n\n19.11.1 Intervallo di Variazione\nL‚Äôintervallo di variazione √® la differenza tra il valore massimo e il valore minimo dei dati:\n\\[\n\\text{Intervallo} = \\max(X) - \\min(X)\n\\]\nVantaggi:\n\nFacile da calcolare e interpretare.\n\nOffre un‚Äôindicazione immediata dell‚Äôampiezza della distribuzione.\n\nLimitazioni:\n\nConsidera solo due valori estremi della distribuzione, ignorando tutti gli altri dati.\n\n√à fortemente influenzato dalla presenza di valori anomali (outlier), risultando poco rappresentativo della variabilit√† generale.\n\nEsempio:\nSupponiamo di misurare i punteggi di autostima in un campione di adolescenti e di ottenere:\\[\n\\max(X) = 35, \\quad \\min(X) = 12 .\n\\]\nL‚Äôintervallo di variazione sar√†:\n\\[\n35 - 12 = 23 .\n\\]\nQuesto valore indica che i punteggi variano su un intervallo di 23 punti.\n\n19.11.2 Differenza Interquartile (Interquartile Range, IQR)\nLa differenza interquartile (IQR) misura la dispersione del 50% centrale della distribuzione, escludendo i valori pi√π estremi:\n\\[\n\\text{IQR} = Q_3 - Q_1 .\n\\]\ndove:\n\n\n\\(Q_1\\) √® il primo quartile (25¬∞ percentile), ovvero il valore sotto il quale si trova il 25% dei dati;\n\n\n\\(Q_3\\) √® il terzo quartile (75¬∞ percentile), ovvero il valore sotto il quale si trova il 75% dei dati.\n\nVantaggi:\n\n\nRobusto rispetto ai valori anomali, poich√© considera solo la parte centrale della distribuzione.\n\nUtile per identificare asimmetrie e la presenza di outlier.\n\nLimitazioni:\n\nNon tiene conto della dispersione complessiva dei dati, ma solo di quella nella fascia centrale.\n\nPu√≤ essere meno informativo in distribuzioni fortemente asimmetriche o con pi√π picchi.\n\nEsempio:\nSe analizziamo il livello di ansia in un gruppo di studenti e troviamo:\n\\[\nQ_1 = 25, \\quad Q_3 = 40 .\n\\]\nallora la differenza interquartile sar√†:\n\\[\nIQR = 40 - 25 = 15 .\n\\] Ci√≤ significa che il 50% centrale dei punteggi di ansia si distribuisce in un intervallo di 15 unit√†.\n\n19.11.3 Considerazioni Finali\nL‚Äôintervallo di variazione e la differenza interquartile sono due strumenti utili per descrivere la dispersione di una distribuzione, ma presentano anche delle limitazioni. L‚Äôintervallo di variazione √® molto sensibile ai valori estremi, mentre la differenza interquartile, pur essendo pi√π robusta, considera solo una parte della distribuzione.\nPer ottenere una misura della dispersione pi√π completa, che tenga conto di tutti i dati senza essere eccessivamente influenzata dagli outlier, si ricorre spesso a misure basate sulla deviazione dai valori medi, come la varianza e la deviazione standard. Queste ultime saranno oggetto della prossima sezione.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Indicatori di tendenza centrale e variabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#la-varianza",
    "href": "chapters/eda/07_loc_scale.html#la-varianza",
    "title": "19¬† Indicatori di tendenza centrale e variabilit√†",
    "section": "\n19.12 La Varianza",
    "text": "19.12 La Varianza\nLa varianza √® una delle misure di dispersione pi√π utilizzate in statistica perch√© tiene conto di tutte le osservazioni e descrive quanto i valori si discostano dalla loro media. Formalmente, se abbiamo \\(n\\) osservazioni \\(x_1, x_2, \\dots, x_n\\) e indichiamo con \\(\\bar{x} = \\frac{1}{n} \\sum_{i=1}^n x_i\\) la loro media, la varianza (in versione descrittiva) si calcola cos√¨:\n\\[\nS^2 = \\frac{1}{n} \\sum_{i=1}^n (x_i - \\bar{x})^2.\n\\tag{19.3}\\]\nIn altre parole, per trovare la varianza:\n\nCalcoliamo la media di tutti i valori (\\(\\bar{x}\\)).\nSottraiamo la media a ciascun valore, ottenendo cos√¨ lo scarto \\((x_i - \\bar{x})\\).\nEleviamo ogni scarto al quadrato, per rendere positivi i valori ed enfatizzare gli scostamenti pi√π grandi.\nInfine, facciamo la media di questi quadrati.\n\nMaggiore √® la varianza, maggiore √® la variabilit√† (o dispersione) dei dati rispetto alla media. Al contrario, una varianza prossima allo zero indica che le osservazioni sono molto vicine tra loro e quasi coincidenti con la media.\n\nNota su popolazione e campione: spesso, nell‚Äôanalisi di dati campionari, la varianza viene calcolata usando \\(\\frac{1}{n-1}\\) al denominatore al posto di \\(\\frac{1}{n}\\). In questo modo otteniamo una stima corretta (non distorta) della varianza della popolazione. Nel contesto della formula sopra riportata, invece, stiamo calcolando la varianza descrittiva (o popolazione completa).\n\n\n19.12.1 Esempio pratico\nImmaginiamo di aver misurato il numero di ore di studio giornaliere di un piccolo gruppo di partecipanti a un esperimento di psicologia. I dati raccolti sono:\n\\[\nx = \\{3,\\, 1,\\, 4,\\, 2\\}.\n\\]\nPasso 1: Calcolo della media\n\\[\n\\bar{x} = \\frac{3 + 1 + 4 + 2}{4} = \\frac{10}{4} = 2.5.\n\\]\nPasso 2: Scarti dalla media\n\nPer il primo valore (\\(x_1 = 3\\)): \\(3 - 2.5 = 0.5\\)\n\nPer il secondo valore (\\(x_2 = 1\\)): \\(1 - 2.5 = -1.5\\)\n\nPer il terzo valore (\\(x_3 = 4\\)): \\(4 - 2.5 = 1.5\\)\n\nPer il quarto valore (\\(x_4 = 2\\)): \\(2 - 2.5 = -0.5\\)\n\n\nPasso 3: Quadrati degli scarti\n\n\\((0.5)^2 = 0.25\\)\n\\((-1.5)^2 = 2.25\\)\n\\((1.5)^2 = 2.25\\)\n\\((-0.5)^2 = 0.25\\)\n\nPasso 4: Calcolo della varianza\nFacciamo la media di questi valori:\n\\[\nS^2 = \\frac{0.25 + 2.25 + 2.25 + 0.25}{4} = \\frac{5}{4} = 1.25.\n\\]\nDunque la varianza √® 1.25.\n\n19.12.2 Interpretazione\nUna varianza pari a 1.25 indica che le ore di studio giornaliere si discostano, in media, di 1.25 unit√† quadrate dalla media di 2.5 ore. Per comprendere meglio l‚Äôordine di grandezza di questa dispersione, solitamente si fa riferimento alla deviazione standard, che √® la radice quadrata della varianza. In questo caso, \\(\\sqrt{1.25} \\approx 1.12\\) ore.\n\nSe la varianza (o la deviazione standard) fosse stata molto pi√π grande, avremmo dedotto che gli studenti del campione presentano abitudini di studio molto diverse.\nAl contrario, se la varianza fosse prossima a 0, significherebbe che quasi tutti studiano un numero di ore molto simile a 2.5.\n\n19.12.3 Calcolo in R\nSe volessimo effettuare lo stesso calcolo in R, potremmo fare cos√¨:\n\n# Dati\nx &lt;- c(3, 1, 4, 2)\n\n# Calcolo manuale della media\nmedia_x &lt;- mean(x)\n\n# Calcolo manuale della varianza secondo la formula descrittiva\nvarianza_descr &lt;- mean((x - media_x)^2)\nvarianza_descr\n#&gt; [1] 1.25\n# [1] 1.25\n\n# Calcolo della varianza con la funzione var() di R\n# (Attenzione: per default var() usa n-1 al denominatore)\nvarianza_campionaria &lt;- var(x)\nvarianza_campionaria\n#&gt; [1] 1.667\n# [1] 1.666667\n\nOsserviamo che var(x) d√† un valore di circa 1.67 perch√© R, di default, calcola la varianza campionaria (con \\(n-1\\) al denominatore). Se vogliamo la varianza descrittiva (come nella formula con \\(n\\) al denominatore), usiamo la nostra varianza_descr.\nIn sintesi, la varianza fornisce un modo per quantificare quanto siano diverse tra loro le osservazioni. Nel caso dell‚Äôesempio sulle ore di studio, abbiamo visto che i valori, pur non essendo tutti identici, non mostrano una dispersione eccessiva (la varianza √® 1.25). Se i comportamenti di studio fossero estremamente diversificati (per esempio, se qualcuno studiasse 0 ore al giorno e qualcun altro 10), la varianza sarebbe molto pi√π elevata, indicando una marcata eterogeneit√† nel campione.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Indicatori di tendenza centrale e variabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#stima-della-varianza-della-popolazione",
    "href": "chapters/eda/07_loc_scale.html#stima-della-varianza-della-popolazione",
    "title": "19¬† Indicatori di tendenza centrale e variabilit√†",
    "section": "\n19.13 Stima della Varianza della Popolazione",
    "text": "19.13 Stima della Varianza della Popolazione\nSi noti il denominatore della formula della varianza. Nell‚ÄôEquazione¬†19.3, ho utilizzato \\(n\\) come denominatore (l‚Äôampiezza campionaria, ovvero il numero di osservazioni nel campione). In questo modo, otteniamo la varianza come statistica descrittiva del campione. Tuttavia, √® possibile utilizzare \\(n-1\\) come denominatore alternativo:\n\\[\n\\begin{equation}\ns^2 = \\frac{1}{n-1} \\sum_{i=1}^n (x_i - \\bar{x})^2 .\n\\end{equation}\n\\tag{19.4}\\]\nIn questo secondo caso, otteniamo la varianza come stimatore della varianza della popolazione. Si pu√≤ dimostrare che l‚ÄôEquazione¬†19.4 fornisce una stima corretta (ovvero, non distorta) della varianza della popolazione da cui abbiamo ottenuto il campione, mentre l‚ÄôEquazione¬†19.3 fornisce (in media) una stima troppo piccola della varianza della popolazione. Si presti attenzione alla notazione: \\(S^2\\) rappresenta la varianza come statistica descrittiva, mentre \\(s^2\\) rappresenta la varianza come stimatore.\n\n19.13.1 Simulazione\nPer illustrare questo punto, svolgiamo una simulazione. Consideriamo la distribuzione dei punteggi del quoziente di intelligenza (QI). I valori del QI seguono una particolare distribuzione chiamata distribuzione normale (v. Capitolo 20), con media 100 e deviazione standard 15. La forma di questa distribuzione √® illustrata nella figura seguente.\n\n# Define parameters\nx &lt;- seq(100 - 4 * 15, 100 + 4 * 15, by = 0.001)\nmu &lt;- 100\nsigma &lt;- 15\n\n# Compute the PDF\npdf &lt;- dnorm(x, mean = mu, sd = sigma)\n\n# Plot using ggplot2\ndata &lt;- tibble(x = x, pdf = pdf)\nggplot(data, aes(x = x, y = pdf)) +\n  geom_line() +\n  labs(\n    x = \"QI\", \n    y = \"Densit√†\", \n    title = \"Distribuzione del QI nella popolazione\"\n  ) \n\n\n\n\n\n\n\nSupponiamo di estrarre un campione casuale di 4 osservazioni dalla popolazione del quoziente di intelligenza ‚Äì in altre parole, supponiamo di misurare il quoziente di intelligenza di 4 persone prese a caso dalla popolazione.\n\nset.seed(123) \nx &lt;- rnorm(4, mean = 100, sd = 15)\nprint(x)\n#&gt; [1]  91.59  96.55 123.38 101.06\n\nCalcoliamo la varianza usando \\(n\\) al denominatore. Si noti che la vera varianza del quoziente di intelligenza √® \\(15^2\\) = 225.\n\nvar(x)\n#&gt; [1] 196.9\n\nConsideriamo ora 10 campioni casuali del QI, ciascuno di ampiezza 4.\n\nmu &lt;- 100\nsigma &lt;- 15\nsize &lt;- 4\nniter &lt;- 10\nrandom_samples &lt;- list()\n\nset.seed(123) \n\nfor (i in 1:niter) {\n  one_sample &lt;- rnorm(size, mean = mu, sd = sigma)\n  random_samples[[i]] &lt;- one_sample\n}\n\nIl primo campione √®\n\nrandom_samples[1]\n#&gt; [[1]]\n#&gt; [1]  91.59  96.55 123.38 101.06\n\nIl decimo campione √®\n\nrandom_samples[10]\n#&gt; [[1]]\n#&gt; [1] 108.31  99.07  95.41  94.29\n\nStampiamo i valori di tutti i 10 campioni.\n\nrs &lt;- do.call(rbind, random_samples)\nrs\n#&gt;         [,1]   [,2]   [,3]   [,4]\n#&gt;  [1,]  91.59  96.55 123.38 101.06\n#&gt;  [2,] 101.94 125.73 106.91  81.02\n#&gt;  [3,]  89.70  93.32 118.36 105.40\n#&gt;  [4,] 106.01 101.66  91.66 126.80\n#&gt;  [5,] 107.47  70.50 110.52  92.91\n#&gt;  [6,]  83.98  96.73  84.61  89.07\n#&gt;  [7,]  90.62  74.70 112.57 102.30\n#&gt;  [8,]  82.93 118.81 106.40  95.57\n#&gt;  [9,] 113.43 113.17 112.32 110.33\n#&gt; [10,] 108.31  99.07  95.41  94.29\n\nPer ciascun campione (ovvero, per ciascuna riga della matrice precedente), calcoliamo la varianza usando la formula con \\(n\\) al denominatore. Otteniamo cos√¨ 10 stime della varianza della popolazione del QI.\n\nx_var &lt;- apply(rs, 1, var)  # Applica la funzione var su ciascuna riga\nprint(x_var)\n#&gt;  [1] 196.940 337.536 168.547 218.684 333.476  34.520 264.378 234.081   1.971\n#&gt; [10]  40.468\n\nNotiamo due cose:\n\nle stime sono molto diverse tra loro; questo fenomeno √® noto con il nome di variabilit√† campionaria;\nin media le stime sono troppo piccole.\n\nPer aumentare la sicurezza riguardo al secondo punto menzionato in precedenza, ripeteremo la simulazione utilizzando un numero di iterazioni maggiore.\n\nmu &lt;- 100\nsigma &lt;- 15\nsize &lt;- 4\nniter &lt;- 10000\nrandom_samples &lt;- list()\n\nset.seed(123) # Replace 123 with your desired seed for reproducibility\n\nfor (i in 1:niter) {\n  one_sample &lt;- rnorm(size, mean = mu, sd = sigma)\n  random_samples[[i]] &lt;- one_sample\n}\n\nrs &lt;- do.call(rbind, random_samples)\nx_var &lt;- apply(rs, 1, var) * (size - 1) / size  # Adjust for population variance (ddof = 0)\n\nEsaminiamo la distribuzione dei valori ottenuti.\n\n# Create a data frame for plotting\ndata &lt;- data.frame(x_var = x_var)\n\n# Plot the histogram using ggplot2\nggplot(data, aes(x = x_var)) +\n  geom_histogram(fill = \"lightblue\", bins = 30, color = \"black\") +\n  scale_x_continuous(limits = c(0, 1500)) +\n  scale_y_continuous(limits = c(0, 2250)) +\n  labs(\n    x = \"Varianza\", \n    y = \"Frequenza\", \n    title = \"Varianza del QI in campioni di n = 4\"\n  )\n\n\n\n\n\n\n\nLa stima pi√π verosimile della varianza del QI √® dato dalla media di questa distribuzione.\n\nmean(x_var)\n#&gt; [1] 168.9\n\nSi noti che il nostro spospetto √® stato confermato: il valore medio della stima della varianza ottenuta con l‚ÄôEquazione¬†19.3 √® troppo piccolo rispetto al valore corretto di \\(15^2 = 225\\).\nRipetiamo ora la simulazione usando la formula della varianza con \\(n-1\\) al denominatore.\n\nset.seed(123) \n\nmu &lt;- 100\nsigma &lt;- 15\nsize &lt;- 4\nniter &lt;- 10000\nrandom_samples &lt;- list()\n\nfor (i in 1:niter) {\n  one_sample &lt;- rnorm(size, mean = mu, sd = sigma)\n  random_samples[[i]] &lt;- one_sample\n}\n\nrs &lt;- do.call(rbind, random_samples)\nx_var &lt;- apply(rs, 1, var)  # ddof = 1 is default for var in R\n\nEsaminiamo la distribuzione dei valori ottenuti.\n\n# Create a data frame for plotting\ndata &lt;- data.frame(x_var = x_var)\n\n# Plot the histogram using ggplot2\nggplot(data, aes(x = x_var)) +\n  geom_histogram(fill = \"lightblue\", bins = 30, color = \"black\") +\n  scale_x_continuous(limits = c(0, 1500)) +\n  scale_y_continuous(limits = c(0, 2250)) +\n  labs(\n    x = \"Varianza Corretta\", \n    y = \"Frequenza\", \n    title = \"Varianza corretta del QI in campioni di n = 4\"\n  )\n\n\n\n\n\n\n\nNel secondo caso, se utilizziamo \\(n-1\\) come denominatore per calcolare la stima della varianza, il valore atteso di questa stima √® molto vicino al valore corretto di 225. Se il numero di campioni fosse infinito, i due valori sarebbero identici.\n\nmean(x_var)\n#&gt; [1] 225.2\n\nIn conclusione, le due formule della varianza hanno scopi diversi.\n\nLa formula della varianza con \\(n\\) al denominatore viene utilizzata come statistica descrittiva per descrivere la variabilit√† di un particolare campione di osservazioni.\nD‚Äôaltro canto, la formula della varianza con \\(n-1\\) al denominatore viene utilizzata come stimatore per ottenere la migliore stima della varianza della popolazione da cui quel campione √® stato estratto.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Indicatori di tendenza centrale e variabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#deviazione-standard",
    "href": "chapters/eda/07_loc_scale.html#deviazione-standard",
    "title": "19¬† Indicatori di tendenza centrale e variabilit√†",
    "section": "\n19.14 Deviazione Standard",
    "text": "19.14 Deviazione Standard\nPer interpretare la varianza in modo pi√π intuitivo, si pu√≤ calcolare la deviazione standard (o scarto quadratico medio o scarto tipo) prendendo la radice quadrata della varianza. La deviazione standard √® espressa nell‚Äôunit√† di misura originaria dei dati, a differenza della varianza che √® espressa nel quadrato dell‚Äôunit√† di misura dei dati. La deviazione standard fornisce una misura della dispersione dei dati attorno alla media, rendendo pi√π facile la comprensione della variabilit√† dei dati.\nLa deviazione standard (o scarto quadratico medio, o scarto tipo) √® definita come:\n\\[\ns^2 = \\sqrt{(n-1)^{-1} \\sum_{i=1}^n (x_i - \\bar{x})^2}.\n\\tag{19.5}\\]\nQuando tutte le osservazioni sono uguali, \\(s = 0\\), altrimenti \\(s &gt; 0\\).\n\n\n\n\n\n\nIl termine standard deviation √® stato introdotto in statistica da Pearson nel 1894 assieme alla lettera greca \\(\\sigma\\) che lo rappresenta. Il termine italiano ‚Äúdeviazione standard‚Äù ne √® la traduzione pi√π utilizzata nel linguaggio comune; il termine dell‚ÄôEnte Nazionale Italiano di Unificazione √® tuttavia ‚Äúscarto tipo‚Äù, definito come la radice quadrata positiva della varianza.\n\n\n\nLa deviazione standard \\(s\\) dovrebbe essere utilizzata solo quando la media √® una misura appropriata per descrivere il centro della distribuzione, ad esempio nel caso di distribuzioni simmetriche. Tuttavia, √® importante tener conto che, come la media \\(\\bar{x}\\), anche la deviazione standard √® fortemente influenzata dalla presenza di dati anomali, ovvero pochi valori che si discostano notevolmente dalla media rispetto agli altri dati della distribuzione. In presenza di dati anomali, la deviazione standard pu√≤ risultare ingannevole e non rappresentare accuratamente la variabilit√† complessiva della distribuzione. Pertanto, √® fondamentale considerare attentamente il contesto e le caratteristiche dei dati prima di utilizzare la deviazione standard come misura di dispersione. In alcune situazioni, potrebbe essere pi√π appropriato ricorrere a misure di dispersione robuste o ad altre statistiche descrittive per caratterizzare la variabilit√† dei dati in modo pi√π accurato e affidabile.\n\n19.14.1 Interpretazione\nLa deviazione standard misura la dispersione dei dati rispetto alla media aritmetica. In termini semplici, indica quanto, in media, ciascun valore osservato si discosta dalla media del campione. Anche se √® simile allo scarto semplice medio campionario (la media dei valori assoluti degli scarti rispetto alla media), la deviazione standard utilizza lo scarto quadratico medio e produce un valore leggermente diverso.\n\nEsempio 19.3 Per verificare l‚Äôinterpretazione della deviazione standard, utilizziamo i punteggi relativi alle ore di studio di un piccolo numero di studenti.\n\nx &lt;- c(3, 1, 4, 2)\n\nstd_x &lt;- sqrt(var(x) * 3 / 4)\nstd_x\n#&gt; [1] 1.118\n\nLa deviazione standard calcolata √® 1.12. Questo valore ci dice che, in media, ciascun punteggio si discosta di circa 1.12 ore dalla media aritmetica delle ore di studio di questo gruppo di studenti.\n\nValore pi√π alto: indica maggiore dispersione dei dati intorno alla media.\nValore pi√π basso: i dati sono pi√π concentrati vicino alla media.\n\nSe calcoliamo anche lo scarto semplice medio campionario per confronto, otteniamo:\n\nmean(abs(x - mean(x)))\n#&gt; [1] 1\n\nI due valori (deviazione standard e scarto semplice medio) sono simili ma non identici, a causa delle diverse definizioni matematiche.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Indicatori di tendenza centrale e variabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#varianza-spiegata-e-non-spiegata",
    "href": "chapters/eda/07_loc_scale.html#varianza-spiegata-e-non-spiegata",
    "title": "19¬† Indicatori di tendenza centrale e variabilit√†",
    "section": "\n19.15 Varianza Spiegata e Non Spiegata",
    "text": "19.15 Varianza Spiegata e Non Spiegata\nLa varianza, come abbiamo visto, misura quanto i dati si disperdono attorno alla media. Un concetto fondamentale nei modelli statistici lineari √® la distinzione tra varianza spiegata e varianza non spiegata, che ci permette di valutare quanto bene un modello teorico riesca a chiarire la variabilit√† osservata nei dati.\n\n19.15.1 Decomposizione della Varianza\nQuando osserviamo un fenomeno (ad esempio i risultati di un test), troviamo inevitabilmente differenze tra individui. Queste differenze possono essere suddivise in due componenti principali:\n\n\nvarianza spiegata: la parte di variabilit√† che pu√≤ essere attribuita a fattori identificati e misurabili;\n\nvarianza non spiegata: la parte rimanente di variabilit√† che non √® chiarita dai fattori considerati.\n\nFormalmente, questa decomposizione pu√≤ essere espressa come:\n\\[\n\\sum_{i=1}^{n}(Y_i - \\bar{Y})^2 = \\sum_{i=1}^{n}(\\hat{Y}_i - \\bar{Y})^2 + \\sum_{i=1}^{n}(Y_i - \\hat{Y}_i)^2 ,\n\\]\ndove:\n\n\n\\(Y_i\\) sono i dati osservati,\n\n\\(\\bar{Y}\\) √® la media dei dati osservati,\n\n\\(\\hat{Y}_i\\) sono i valori attesi (previsti) dal modello teorico.\n\nIntuitivamente:\n\nla varianza totale (lato sinistro della formula) rappresenta la dispersione complessiva dei dati attorno alla loro media;\nla varianza spiegata (primo termine a destra) indica quanto bene i valori previsti dal modello descrivono il comportamento dei dati;\nla varianza non spiegata (secondo termine a destra) riflette ci√≤ che il modello non riesce a prevedere.\n\n19.15.2 Simulazione in R\nSupponiamo di analizzare i punteggi di un esame universitario di ‚ÄúPsicometria‚Äù ottenuti da 200 studenti. La nostra teoria indica che i punteggi dipendano da:\n\nOre settimanali dedicate allo studio;\nPresenza o assenza di ‚Äúpaura della matematica‚Äù (math anxiety) (Barroso et al., 2021).\n\nNello specifico, ipotizziamo:\n\nuna relazione positiva tra ore di studio e punteggio ottenuto;\nuna riduzione del 30% del punteggio per chi presenta paura della matematica rispetto agli altri studenti, a parit√† di ore di studio.\n\nEcco la simulazione in R:\n\nset.seed(123)\n\n# Simuliamo i dati per 200 studenti\nn &lt;- 200\nore_studio &lt;- runif(n, min = 2, max = 15) |&gt; round()\npaura_mat &lt;- rbinom(n, 1, prob = 0.3)\n\nk &lt;- 2  # Ogni ora di studio corrisponde a circa 2 punti\n\n# Calcoliamo i punteggi attesi, limitati a 30 punti massimo\npunteggio_atteso &lt;- ore_studio * k * ifelse(paura_mat == 1, 0.7, 1) |&gt; round()\npunteggio_atteso &lt;- ifelse(punteggio_atteso &gt; 30, 30, punteggio_atteso)\n\n# Generiamo punteggi reali aggiungendo casualit√† (tra 0 e 30 punti)\npunteggio_reale &lt;- (punteggio_atteso + rnorm(n, mean = 0, sd = 3)) |&gt; round()\npunteggio_reale &lt;- pmin(pmax(punteggio_reale, 0), 30)\n\n# Creiamo il dataset finale\ndata &lt;- data.frame(ore_studio, paura_mat, punteggio_atteso, punteggio_reale)\nhead(data)\n#&gt;   ore_studio paura_mat punteggio_atteso punteggio_reale\n#&gt; 1          6         0               12              19\n#&gt; 2         12         1               24              28\n#&gt; 3          7         0               14              13\n#&gt; 4         13         0               26              28\n#&gt; 5         14         0               28              27\n#&gt; 6          3         1                6               5\n\nCalcoliamo ora la decomposizione della varianza usando le formule indicate:\n\n# Media dei punteggi reali\nmedia_reale &lt;- mean(data$punteggio_reale)\n\n# Calcolo delle componenti della varianza\nvarianza_totale &lt;- mean((data$punteggio_reale - media_reale)^2)\nvarianza_spiegata &lt;- mean((data$punteggio_atteso - media_reale)^2)\nvarianza_non_spiegata &lt;- mean((data$punteggio_reale - data$punteggio_atteso)^2)\n\n# Risultati\nc(varianza_totale, varianza_spiegata, varianza_non_spiegata)\n#&gt; [1] 60.37 51.65  8.29\n\n\n19.15.3 Interpretazione dei Risultati\n\n\nVarianza totale indica quanto in generale i punteggi differiscono tra loro.\n\nVarianza spiegata rappresenta quanto della variabilit√† totale pu√≤ essere attribuita ai fattori teorici (ore di studio e paura della matematica).\n\nVarianza non spiegata evidenzia la variabilit√† residua che il modello non riesce a cogliere.\n\nLa proporzione di varianza spiegata √® data dal rapporto:\n\nprop_spiegata &lt;- varianza_spiegata / varianza_totale\nprop_spiegata\n#&gt; [1] 0.8555\n\nQuesta proporzione √® sempre compresa tra 0 e 1:\n\nvalori vicini a 1 indicano che il modello √® efficace nel descrivere i dati;\nvalori vicini a 0 suggeriscono che il modello non cattura adeguatamente la realt√† osservata.\n\nQuesta decomposizione della varianza √® uno strumento cruciale per valutare l‚Äôefficacia delle teorie e dei modelli statistici. Approfondiremo ulteriormente questi aspetti nel capitolo dedicato ai modelli di regressione (v. Capitolo 60).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Indicatori di tendenza centrale e variabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#deviazione-mediana-assoluta",
    "href": "chapters/eda/07_loc_scale.html#deviazione-mediana-assoluta",
    "title": "19¬† Indicatori di tendenza centrale e variabilit√†",
    "section": "\n19.16 Deviazione Mediana Assoluta",
    "text": "19.16 Deviazione Mediana Assoluta\nLa deviazione mediana assoluta (MAD) √® una misura robusta di dispersione basata sulla mediana. √à definita come la mediana dei valori assoluti delle deviazioni dei dati rispetto alla mediana:\n\\[\n\\text{MAD} = \\text{median} \\left( |X_i - \\text{median}(X)| \\right)\n\\tag{19.6}\\]\nLa MAD √® particolarmente utile per analizzare dati contenenti outlier o distribuzioni asimmetriche, poich√© √® meno influenzata dai valori estremi rispetto alla deviazione standard.\n\n19.16.1 Relazione tra MAD e Deviazione Standard in una Distribuzione Normale\nQuando i dati seguono una distribuzione normale (gaussiana), esiste una relazione approssimativa tra MAD e deviazione standard. La MAD pu√≤ essere convertita in una stima della deviazione standard moltiplicandola per una costante di 1.4826:\n\\[\n\\sigma \\approx k \\times \\text{MAD},\n\\]\ndove:\n\n\n\\(\\sigma\\) √® la deviazione standard,\nMAD √® la Mediana della Deviazione Assoluta,\n\n\\(k\\) √® una costante che, per una distribuzione normale, √® tipicamente presa come circa 1.4826.\n\nQuesta costante deriva dalla propriet√† della distribuzione normale, in cui circa il 50% dei valori si trova entro 0.6745 deviazioni standard dalla media.\nLa formula completa per convertire la MAD in una stima della deviazione standard in una distribuzione normale √®:\n\\[\n\\sigma \\approx 1.4826 \\times \\text{MAD}\n\\]\nQuesta relazione √® utile per stimare la deviazione standard in modo pi√π robusto, specialmente quando si sospetta la presenza di outlier o si ha a che fare con campioni piccoli. Di conseguenza, molti software restituiscono il valore MAD moltiplicato per questa costante per fornire un‚Äôindicazione pi√π intuitiva della variabilit√† dei dati. Tuttavia, √® importante notare che questa relazione si mantiene accurata solo per le distribuzioni che sono effettivamente normali. In presenza di distribuzioni fortemente asimmetriche o con elevati outlier, la deviazione standard e la MAD possono fornire indicazioni molto diverse sulla variabilit√† dei dati.\n\nEsempio 19.4 Per verificare questo principio, usiamo un campione di dati simulati dalla distribuzione del QI:\n\nqi &lt;- rnorm(200, 100, 15)\n1.4826 * median(abs(qi - median(qi)), na.rm = TRUE)\n#&gt; [1] 14.06\n\nOtteniamo un valore che √® simile alla deviazione standard calcolata con:\n\nsqrt(\n  var(qi) * (length(qi) - 1) / length(qi)\n)\n#&gt; [1] 14.44\n\nCi√≤ conferma la relazione tra MAD e deviazione standard in distribuzioni gaussiane.\nSe invece usiamo dei dati non normali, l‚Äôapprossimazione non √® buona:\n\nset.seed(123) \ny &lt;- rchisq(200, 1)\n1.4826 * median(abs(y - median(y)))\n#&gt; [1] 0.4743\n\n\nsqrt(\n  var(y) * (length(y) - 1) / length(y)\n)\n#&gt; [1] 1.412\n\n\n\n19.16.2 Quando Usare Deviazione Standard e MAD\n\nDeviazione standard: √à la misura pi√π appropriata per dati normalmente distribuiti e situazioni in cui l‚Äôobiettivo √® descrivere la dispersione dei dati rispetto alla media. Tuttavia, √® sensibile ai valori anomali (outlier).\nDeviazione mediana assoluta: √à ideale quando i dati sono non normali, asimmetrici o contengono outlier. La MAD √® pi√π robusta poich√© utilizza la mediana anzich√© la media e non √® influenzata da valori estremi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Indicatori di tendenza centrale e variabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#indici-di-variabilit√†-relativi",
    "href": "chapters/eda/07_loc_scale.html#indici-di-variabilit√†-relativi",
    "title": "19¬† Indicatori di tendenza centrale e variabilit√†",
    "section": "\n19.17 Indici di Variabilit√† Relativi",
    "text": "19.17 Indici di Variabilit√† Relativi\nA volte pu√≤ essere necessario confrontare la variabilit√† di grandezze incommensurabili, ovvero di caratteri misurati con differenti unit√† di misura. In queste situazioni, le misure di variabilit√† descritte in precedenza diventano inadeguate poich√© dipendono dall‚Äôunit√† di misura utilizzata. Per superare questo problema, si ricorre a specifici numeri adimensionali chiamati indici relativi di variabilit√†.\nIl pi√π importante di questi indici √® il coefficiente di variazione (\\(C_v\\)), definito come il rapporto tra la deviazione standard (\\(\\sigma\\)) e la media dei dati (\\(\\bar{x}\\)):\n\\[\nC_v = \\frac{\\sigma}{\\bar{x}}.\n\\tag{19.7}\\]\nIl coefficiente di variazione √® un numero puro e permette di confrontare la variabilit√† di distribuzioni con unit√† di misura diverse.\nUn altro indice relativo di variabilit√† √® la differenza interquartile rapportata a uno dei tre quartili (primo quartile, terzo quartile o mediana). Questo indice √® definito come:\n\\[\n\\frac{x_{0.75} - x_{0.25}}{x_{0.25}}, \\qquad \\frac{x_{0.75} - x_{0.25}}{x_{0.75}}, \\qquad \\frac{x_{0.75} - x_{0.25}}{x_{0.50}}.\n\\]\nQuesti indici relativi di variabilit√† forniscono una misura adimensionale della dispersione dei dati, rendendo possibile il confronto tra grandezze con diverse unit√† di misura e facilitando l‚Äôanalisi delle differenze di variabilit√† tra i dati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Indicatori di tendenza centrale e variabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#riflessioni-conclusive",
    "href": "chapters/eda/07_loc_scale.html#riflessioni-conclusive",
    "title": "19¬† Indicatori di tendenza centrale e variabilit√†",
    "section": "\n19.18 Riflessioni Conclusive",
    "text": "19.18 Riflessioni Conclusive\nLe statistiche descrittive forniscono strumenti essenziali per sintetizzare e comprendere i dati raccolti in psicologia e nelle scienze sociali. Le misure di tendenza centrale, come la media, la mediana e la moda, ci permettono di individuare un valore tipico o rappresentativo di una distribuzione, facilitando la sintesi e l‚Äôinterpretazione generale dei dati raccolti. Parallelamente, gli indici di dispersione, come la deviazione standard, la varianza e l‚Äôintervallo interquartile, offrono informazioni cruciali sulla variabilit√†, mostrandoci quanto i singoli dati siano vicini o distanti da questa tendenza centrale.\nTuttavia, √® fondamentale riflettere attentamente sulle implicazioni teoriche e metodologiche che accompagnano l‚Äôuso di queste misure. In particolare, √® importante considerare il rischio della fallacia ergodica, ovvero l‚Äôerrata convinzione che i risultati ottenuti da medie e statistiche aggregate possano automaticamente applicarsi ai singoli individui. Nella pratica psicologica, infatti, ogni persona √® caratterizzata da una notevole variabilit√† intra- e inter-individuale, che spesso non pu√≤ essere adeguatamente rappresentata da semplici indicatori aggregati.\nLe statistiche descrittive rappresentano quindi un primo e fondamentale passo nella comprensione dei dati psicologici, ma devono essere integrate da analisi pi√π approfondite e attente alle differenze individuali. L‚Äôuso critico e consapevole di questi strumenti statistici ci consente di evitare generalizzazioni eccessive, fornendo una visione pi√π accurata e realistica dei fenomeni psicologici e comportamentali che studiamo.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Indicatori di tendenza centrale e variabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#esercizi",
    "href": "chapters/eda/07_loc_scale.html#esercizi",
    "title": "19¬† Indicatori di tendenza centrale e variabilit√†",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nParte 1: Domande Teoriche\n\n\nDefinizione e comprensione dei concetti\n\nSpiega la differenza tra media, mediana e moda.\nIn quali situazioni la mediana fornisce una misura della tendenza centrale migliore rispetto alla media?\nPerch√© la media √® sensibile ai valori estremi?\nQuali sono i vantaggi della deviazione mediana assoluta (MAD) rispetto alla deviazione standard?\n\n\n\nInterpretazione della variabilit√†\n\nSpiega il concetto di varianza e la sua interpretazione.\nQual √® la differenza tra varianza e deviazione standard?\nDescrivi in quali casi l‚Äôutilizzo del coefficiente di variazione √® pi√π appropriato rispetto alla deviazione standard.\nQuali sono i limiti della moda come indice di tendenza centrale?\n\n\n\nParte 2: Calcoli Manuali\n\n\nCalcolo della media, mediana e moda\n\n\nConsidera i seguenti punteggi totali della SWLS che sono stati raccolti in un campione di studenti. Calcola manualmente:\n\nLa media\nLa mediana\nLa moda\nIl range\n\n\n\n\n\nCalcolo della varianza e della deviazione standard\n\nUsando gli stessi dati dell‚Äôesercizio precedente, calcola:\n\nLa varianza\nLa deviazione standard\nLa deviazione mediana assoluta (MAD)\n\n\n\n\n\nParte 3: Esercizi con R\n\n\nAnalisi descrittiva con R\n\nCarica il dataset swls_scores.csv contenente i punteggi SWLS degli studenti.\nCalcola media, mediana e moda utilizzando R.\nCalcola la varianza e la deviazione standard utilizzando le funzioni appropriate in R.\n\nCodice suggerito:\nlibrary(tidyverse)\nlibrary(rio)\n\n# Caricamento del dataset\ndf &lt;- import(\"swls_scores.csv\")\n\n# Calcolo delle statistiche descrittive\nmean(df$swls_total)\nmedian(df$swls_total)\n\n# Moda (funzione personalizzata)\nget_mode &lt;- function(x) {\n  tbl &lt;- table(x)\n  as.numeric(names(tbl)[which.max(tbl)])\n}\nget_mode(df$swls_total)\n\n# Varianza e deviazione standard\nvar(df$swls_total)\nsd(df$swls_total)\n\n# Deviazione mediana assoluta\nmad(df$swls_total)\n\n\nVisualizzazione della distribuzione dei dati\n\nCrea un istogramma dei punteggi totali della SWLS.\nAggiungi una linea verticale che rappresenti la media e una che rappresenti la mediana.\n\nCodice suggerito:\nggplot(df, aes(x = swls_total)) +\n  geom_histogram(binwidth = 2, fill = \"blue\", alpha = 0.5, color = \"black\") +\n  geom_vline(aes(xintercept = mean(swls_total)), color = \"red\", linetype = \"dashed\", size = 1) +\n  geom_vline(aes(xintercept = median(swls_total)), color = \"green\", linetype = \"dotted\", size = 1) +\n  labs(title = \"Distribuzione dei punteggi SWLS\", x = \"Punteggio SWLS\", y = \"Frequenza\")\n\n\nParte 4: Domande di Comprensione\n\n\nAnalisi concettuale\n\nPerch√© la media aritmetica pu√≤ essere considerata il ‚Äúbaricentro‚Äù della distribuzione dei dati?\nSe aggiungiamo un valore estremo al dataset, quale delle misure di tendenza centrale subir√† il maggior impatto?\nIn quali situazioni la varianza campionaria √® preferibile rispetto alla varianza della popolazione?\nQual √® la relazione tra la deviazione standard e la varianza?\nFornisci un‚Äôinterpretazione intuitiva della deviazione standard.\nDiscuti le differenze e le somiglianze tra la deviazione standard e MAD. Usa queste informazioni per ridescrivere in maniera intuitiva il significato di deviazione standard.\n\n\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\nPoniamo che i valori SWLS siano [ 18, 22, 26, 19, 24, 30, 26, 22, 18, 28, 21 ].\n\nMedia: \\[ \\bar{x} = \\frac{18 + 22 + 26 + 19 + 24 + 30 + 26 + 22 + 18 + 28 + 21}{11} = 23.36 \\]\nMediana: Ordinando i dati: [ 18, 18, 19, 21, 22, 22, 24, 26, 26, 28, 30 ] La mediana √® il valore centrale: \\(22\\)\nModa: Il valore pi√π frequente √® 22 (appare due volte).\nVarianza: \\[ s^2 = \\frac{\\sum (x_i - \\bar{x})^2}{n-1} = 13.96 \\]\nDeviazione Standard: \\[ s = \\sqrt{13.96} = 3.73 \\]\nMAD: \\[ \\text{MAD} = \\text{mediana}(|X_i - \\text{mediana}(X)|) = 4 \\]\n\nSoluzioni con R\nI risultati eseguendo il codice R:\n\n\nMedia: 23.36\n\nMediana: 22\n\nModa: 22\n\nVarianza: 13.96\n\nDeviazione standard: 3.73\n\nMAD: 4\n\nSoluzioni alle Domande di Comprensione\n\nLa media √® il baricentro poich√© minimizza la somma degli scarti quadrati.\nLa media √® pi√π influenzata dai valori estremi rispetto alla mediana.\nLa varianza campionaria corregge la sottostima della varianza popolazionale.\nLa deviazione standard √® la radice quadrata della varianza, consentendo un‚Äôinterpretazione del risultato sulla scala dei dati grezzi.\nLa deviazione standard √® simile, ma non identica, al valore medio degli scarti assoluti tra ciascun valore della distribuzione e la media. In altre parole, rappresenta la ‚Äúdistanza tipica‚Äù media tra le osservazioni e il valore medio della distribuzione.\nLa deviazione standard e il MAD (Median Absolute Deviation, o scarto medio assoluto) sono entrambi misure di variabilit√† che descrivono quanto i valori in un insieme di dati si discostino dal centro della distribuzione. Tuttavia, presentano alcune importanti differenze e somiglianze.\n\nSomiglianze\n\nEntrambe le misure quantificano la dispersione dei dati attorno a un punto centrale.\nSia la deviazione standard che il MAD utilizzano lo scarto (la differenza tra ciascun valore e un punto centrale) per calcolare la variabilit√†.\n\nDifferenze\n\n\nPunto centrale usato: La deviazione standard si basa sulla media aritmetica, mentre il MAD si basa sulla mediana.\n\nTrattamento degli scarti: Nella deviazione standard, gli scarti vengono elevati al quadrato prima di essere mediati, quindi la radice quadrata viene applicata al risultato finale. Questo processo penalizza maggiormente gli scarti pi√π grandi, rendendo la deviazione standard pi√π sensibile agli outlier. Il MAD, invece, considera semplicemente il valore assoluto degli scarti, rendendolo meno influenzato dagli estremi.\n\nSensibilit√† agli outlier: Poich√© la deviazione standard dipende dai quadrati degli scarti, √® pi√π sensibile alle osservazioni estreme (outlier). Il MAD, essendo basato sulla mediana, √® una misura pi√π robusta e resiste meglio alla presenza di valori anomali.\n\nRidescrizione Intuitiva della Deviazione Standard\n\nLa deviazione standard pu√≤ essere vista come una misura della ‚Äúdispersione tipica‚Äù dei dati attorno alla media, ma con un‚Äôenfasi particolare sugli scarti pi√π grandi. Immagina di prendere ogni valore del dataset, calcolarne la distanza dalla media, amplificare queste distanze attraverso il quadrato, poi trovare una sorta di ‚Äúdistanza media‚Äù ponderata. Questo processo d√† maggiore peso agli scarti pi√π grandi, fornendo cos√¨ una visione della variabilit√† che tiene conto sia delle fluttuazioni ordinarie sia di eventuali valori estremi. In sintesi, mentre il MAD offre una visione pi√π resistente e diretta della variabilit√† centrata sulla mediana, la deviazione standard fornisce una misura pi√π dettagliata e sensibile alla forma complessiva della distribuzione, inclusi i suoi possibili outliers.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Indicatori di tendenza centrale e variabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/07_loc_scale.html#informazioni-sullambiente-di-sviluppo",
    "title": "19¬† Indicatori di tendenza centrale e variabilit√†",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] grid      stats     graphics  grDevices utils     datasets  methods  \n#&gt; [8] base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] vcd_1.4-13        viridis_0.6.5     viridisLite_0.4.2 thematic_0.1.6   \n#&gt;  [5] MetBrewer_0.2.0   ggokabeito_0.1.0  see_0.11.0        gridExtra_2.3    \n#&gt;  [9] patchwork_1.3.0   bayesplot_1.11.1  psych_2.5.3       scales_1.3.0     \n#&gt; [13] markdown_2.0      knitr_1.50        lubridate_1.9.4   forcats_1.0.0    \n#&gt; [17] stringr_1.5.1     dplyr_1.1.4       purrr_1.0.4       readr_2.1.5      \n#&gt; [21] tidyr_1.3.1       tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0  \n#&gt; [25] rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      xfun_0.51         htmlwidgets_1.6.4 lattice_0.22-6   \n#&gt;  [5] tzdb_0.5.0        vctrs_0.6.5       tools_4.4.2       generics_0.1.3   \n#&gt;  [9] parallel_4.4.2    pacman_0.5.1      pkgconfig_2.0.3   R.oo_1.27.0      \n#&gt; [13] data.table_1.17.0 lifecycle_1.0.4   compiler_4.4.2    farver_2.1.2     \n#&gt; [17] munsell_0.5.1     mnormt_2.1.1      htmltools_0.5.8.1 pillar_1.10.1    \n#&gt; [21] MASS_7.3-65       R.utils_2.13.0    nlme_3.1-167      tidyselect_1.2.1 \n#&gt; [25] digest_0.6.37     stringi_1.8.4     labeling_0.4.3    rprojroot_2.0.4  \n#&gt; [29] fastmap_1.2.0     colorspace_2.1-1  cli_3.6.4         magrittr_2.0.3   \n#&gt; [33] utf8_1.2.4        withr_3.0.2       timechange_0.3.0  rmarkdown_2.29   \n#&gt; [37] zoo_1.8-13        R.methodsS3_1.8.2 hms_1.1.3         evaluate_1.0.3   \n#&gt; [41] lmtest_0.9-40     rlang_1.1.5       glue_1.8.0        rstudioapi_0.17.1\n#&gt; [45] jsonlite_1.9.1    R6_2.6.1",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Indicatori di tendenza centrale e variabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#bibliografia",
    "href": "chapters/eda/07_loc_scale.html#bibliografia",
    "title": "19¬† Indicatori di tendenza centrale e variabilit√†",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBarroso, C., Ganley, C. M., McGraw, A. L., Geer, E. A., Hart, S. A., & Daucourt, M. C. (2021). A meta-analysis of the relation between math anxiety and math achievement. Psychological Bulletin, 147(2), 134‚Äì168.\n\n\nMolden, D. C., & Dweck, C. S. (2006). Finding\" meaning\" in psychology: a lay theories approach to self-regulation, social perception, and social development. American Psychologist, 61(3), 192‚Äì203.\n\n\nSpeelman, C. P., & McGann, M. (2013). How mean is the mean? Frontiers in Psychology, 4, 451.\n\n\nSpeelman, C. P., Parker, L., Rapley, B. J., & McGann, M. (2024). Most Psychological Researchers Assume Their Samples Are Ergodic: Evidence From a Year of Articles in Three Major Journals. Collabra: Psychology, 10(1).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Indicatori di tendenza centrale e variabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07a_introduction_normal_distribution.html",
    "href": "chapters/eda/07a_introduction_normal_distribution.html",
    "title": "20¬† Introduzione alla distribuzione normale",
    "section": "",
    "text": "Introduzione\nIn questo capitolo forniremo un primo sguardo alla distribuzione normale, che sar√† trattata in modo pi√π approfondito nel Capitolo 38. Introduciamo la distribuzione normale a questo punto poich√© essa spiega in modo chiaro perch√©, in molte analisi, media e deviazione standard siano impiegate come principali descrittori di una distribuzione.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Introduzione alla distribuzione normale</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07a_introduction_normal_distribution.html#sec-normal-distribution",
    "href": "chapters/eda/07a_introduction_normal_distribution.html#sec-normal-distribution",
    "title": "20¬† Introduzione alla distribuzione normale",
    "section": "\n20.1 La distribuzione normale",
    "text": "20.1 La distribuzione normale\nNel Capitolo 17, abbiamo visto come gli istogrammi e i grafici di densit√† forniscano utili riassunti visivi di una distribuzione. In questo capitolo, ci chiediamo se sia possibile riassumere una distribuzione in modo ancora pi√π sintetico. Spesso si fa riferimento a media e deviazione standard come statistiche riassuntive fondamentali: in sostanza, un riassunto in due numeri. Per comprendere appieno il ruolo di questi valori, dobbiamo prima capire come √® definita la distribuzione normale.\nLa distribuzione normale, nota anche come curva a campana o distribuzione gaussiana, √® uno dei concetti matematici pi√π conosciuti (si veda il Capitolo 38). Uno dei motivi della sua fama √® che numerose variabili nella realt√† seguono, almeno approssimativamente, una distribuzione normale. Esempi includono le vincite nel gioco d‚Äôazzardo, l‚Äôaltezza e il peso delle persone, la pressione sanguigna, i punteggi di alcuni test standardizzati e gli errori di misura negli esperimenti. I motivi matematici e probabilistici di queste approssimazioni verranno discussi in seguito; qui ci concentreremo sul come la distribuzione normale aiuti a riassumere i dati.\nAnzich√© partire da dati empirici, la distribuzione normale si definisce tramite una formula matematica. Per un intervallo generico \\((a,b)\\), la proporzione di valori che cade in tale intervallo si ottiene mediante:\n\\[\n\\text{Pr}(a &lt; x \\leq b) \\;=\\; \\int_a^b \\frac{1}{\\sqrt{2\\pi}\\,\\sigma} \\, e^{-\\tfrac12\\,\\bigl(\\tfrac{x - \\mu}{\\sigma}\\bigr)^2}\\, dx .\n\\tag{20.1}\\]\nNon √® necessario memorizzare o padroneggiare i dettagli di questa formula, ma √® importante sapere che la distribuzione normale √® completamente determinata da due soli parametri: \\(\\mu\\) e \\(\\sigma\\). Gli altri simboli nella formula (\\(\\pi\\), \\(e\\), \\(a\\), \\(b\\)) rappresentano costanti matematiche o gli estremi dell‚Äôintervallo. In particolare, \\(\\mu\\) √® il valore medio (o media) e \\(\\sigma\\) √® la deviazione standard.\nQuesta distribuzione √® simmetrica, centrata sulla media \\(\\mu\\), e la maggior parte dei valori (circa il 95%) si trova entro 2 deviazioni standard dalla media, cio√® nell‚Äôintervallo \\(\\mu \\pm 2\\sigma\\). Ecco un esempio di come appare la distribuzione normale quando \\(\\mu = 0\\) e \\(\\sigma = 1\\):\n\nm &lt;- 0; s &lt;- 1\nnorm_dist &lt;- tibble(x = seq(-4, 4, length.out = 50)*s + m) |&gt; \n  mutate(density = dnorm(x, m, s))\nnorm_dist |&gt; \n  ggplot(aes(x, density)) + geom_line()\n\n\n\n\n\n\n\nIl fatto che la distribuzione sia descritta da due parametri implica che, se un insieme di dati reali si approssima bene a una distribuzione normale, due soli numeri (media e deviazione standard) possono fornire un riassunto sintetico della distribuzione. Vediamo ora come si calcolano, in pratica, questi due parametri per una lista di valori arbitraria.\nSupponiamo di avere un vettore x che contiene una serie di valori numerici. Abbiamo visto come, in R, la media si trova come:\nm &lt;- sum(x) / length(x)\ne la deviazione standard √®:\ns &lt;- sqrt(sum((x - m)^2) / length(x))\nLa deviazione standard si pu√≤ interpretare come la distanza media dei valori dalla loro media.\n\n20.1.1 Un esempio con i dati di altezza\nPer calcolare media e deviazione standard dell‚Äôaltezza maschile in un dataset, ipotizziamo che il vettore heights$height contenga le altezze di alcuni individui, mentre heights$sex contenga il genere corrispondente. Se vogliamo estrarre solo i valori relativi ai maschi, possiamo scrivere:\n\nindex &lt;- heights$sex == \"Male\"\nx &lt;- heights$height[index]\n\nQuindi usiamo le funzioni predefinite di R:\n\nm &lt;- mean(x)\ns &lt;- sd(x)\n\n\n\n\n\n\n\nNota: Per motivi che verranno chiariti in seguito, la funzione sd(x) effettua una divisione per \\(\\text{length}(x) - 1\\) invece che per \\(\\text{length}(x)\\). Tuttavia, se il numero di osservazioni √® elevato, questa differenza √® trascurabile.\n\n\n\nPossiamo ora mettere a confronto la curva di densit√† osservata dei dati (in blu) con quella teorica (in nero) della distribuzione normale con media e deviazione standard stimate:\n\nnorm_dist &lt;- tibble(\n  x = seq(-4, 4, length.out = 50)*s + m) |&gt; \n  mutate(density = dnorm(x, m, s))\n\nheights |&gt; \n  dplyr::filter(sex == \"Male\") |&gt; \n  ggplot(aes(height)) +\n  geom_density(fill = \"lightblue\") +\n  geom_line(aes(x, density), linewidth=1.5, data = norm_dist)\n\n\n\n\n\n\n\nCome si vede, la curva normale fornisce una buona approssimazione per i dati sull‚Äôaltezza maschile. Vedremo ora come verificare l‚Äôaderenza di una distribuzione ai dati, osservando le proporzioni di valori entro intervalli specifici.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Introduzione alla distribuzione normale</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07a_introduction_normal_distribution.html#unit√†-standard",
    "href": "chapters/eda/07a_introduction_normal_distribution.html#unit√†-standard",
    "title": "20¬† Introduzione alla distribuzione normale",
    "section": "\n20.2 Unit√† standard",
    "text": "20.2 Unit√† standard\nPer i dati che seguono (o quasi) una distribuzione normale, √® molto comodo utilizzare le cosiddette unit√† standard (Standard Units). Un valore \\(x\\) viene convertito in unit√† standard tramite la formula:\n\\[\nz = \\frac{x - m}{s} ,\n\\]\ndove \\(m\\) e \\(s\\) sono la media e la deviazione standard della distribuzione. Questa trasformazione ci dice di quante deviazioni standard un particolare valore si discosta dalla media. Ad esempio, se \\(z=0\\), il valore \\(x\\) corrisponde esattamente alla media; se \\(z = 2\\), il valore \\(x\\) si trova a due deviazioni standard sopra la media; se \\(z = -2\\), a due deviazioni standard sotto la media, e cos√¨ via.\nIn R, possiamo calcolare le unit√† standard con la funzione:\n\nz &lt;- scale(x) |&gt; as.numeric()\nhead(z)\n#&gt; [1]  1.5744  0.1898 -0.3641  1.2975 -2.3026 -0.6410\n\nSe vogliamo sapere, ad esempio, quale frazione di individui si trova entro 2 deviazioni standard dalla media (cio√® \\(|z| &lt; 2\\)), basta scrivere:\n\nmean(abs(z) &lt; 2)\n#&gt; [1] 0.9495\n\nVedremo, in molti casi, un valore intorno al 95%, in linea con quanto previsto dalla distribuzione normale. Per confermare la bont√† dell‚Äôapprossimazione, si usano spesso i grafici quantile-quantile, detti anche qqplot.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Introduzione alla distribuzione normale</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07a_introduction_normal_distribution.html#grafici-quantile-quantile-qqplot",
    "href": "chapters/eda/07a_introduction_normal_distribution.html#grafici-quantile-quantile-qqplot",
    "title": "20¬† Introduzione alla distribuzione normale",
    "section": "\n20.3 Grafici quantile-quantile (qqplot)",
    "text": "20.3 Grafici quantile-quantile (qqplot)\nUn modo sistematico per verificare quanto la distribuzione normale descriva bene i dati osservati consiste nel confrontare i quantili empirici con quelli teorici di una normale. Se i due insiemi di quantili sono molto simili, abbiamo un‚Äôulteriore conferma dell‚Äôaderenza alla normalit√†.\n\nLa funzione di ripartizione della distribuzione normale standard si indica spesso con \\(\\Phi(x)\\). Ad esempio, \\(\\Phi(-1.96) \\approx 0.025\\) e \\(\\Phi(1.96) \\approx 0.975\\).\n\nL‚Äôinversa di \\(\\Phi\\), indicata come \\(\\Phi^{-1}(p)\\), ci d√† il quantile corrispondente a una determinata probabilit√† \\(p\\). In R, pnorm calcola \\(\\Phi(x)\\) e qnorm calcola \\(\\Phi^{-1}(p)\\). Di default, pnorm e qnorm si riferiscono alla normale standard (media 0, deviazione standard 1), ma possiamo specificare valori diversi di media e deviazione standard tramite gli argomenti mean e sd.\n\nPer ottenere il quantile empirico da un vettore di dati in R, possiamo usare la funzione quantile. Ad esempio, se abbiamo un vettore x, il quantile associato alla probabilit√† \\(p\\) √® il valore \\(q\\) per il quale mean(x &lt;= q) = p.\nEcco lo schema logico per costruire un qqplot:\n\nDefiniamo un vettore di proporzioni \\(p_1, p_2, \\dots, p_m\\).\n\nCalcoliamo i relativi quantili empirici dei nostri dati \\(\\{q_1, \\dots, q_m\\}\\) usando quantile(x, p_i).\n\nCalcoliamo i quantili teorici della normale (con la stessa media e la stessa deviazione standard dei dati) usando qnorm(p_i, mean, sd).\n\nRappresentiamo i punti \\((\\text{quantile teorico}, \\text{quantile empirico})\\). Se i dati sono davvero normali, tali punti si disporranno approssimativamente lungo la retta diagonale y = x.\n\nEsempio in R:\n\np &lt;- seq(0.05, 0.95, 0.05)\nsample_quantiles &lt;- quantile(x, p)\ntheoretical_quantiles &lt;- qnorm(p, mean = mean(x), sd = sd(x))\n\nqplot(theoretical_quantiles, sample_quantiles) + geom_abline()\n\n\n\n\n\n\n\nSe per√≤ abbiamo gi√† convertito in unit√† standard (quindi \\(\\mu = 0\\) e \\(\\sigma = 1\\)), il confronto si semplifica:\n\nsample_quantiles &lt;- quantile(z, p)\ntheoretical_quantiles &lt;- qnorm(p)\nqplot(theoretical_quantiles, sample_quantiles) + geom_abline()\n\n\n\n\n\n\n\nIn pratica, per creare rapidamente un qqplot si usa spesso ggplot2 con la geometria geom_qq:\n\nheights |&gt; filter(sex == \"Male\") |&gt;\n  ggplot(aes(sample = scale(height))) + \n  geom_qq() +\n  geom_abline()\n\n\n\n\n\n\n\nCome abbiamo sottolineato, se i punti nel qqplot si dispongono lungo una retta, significa che la distribuzione dei dati √® in accordo con la distribuzione teorica considerata (in questo caso, la normale). I qqplot possono essere usati anche per confrontare qualsiasi coppia di distribuzioni, non solo dati e normale teorica.\nQuesto indica che l‚Äôapprossimazione normale √® accurata per il gruppo maschile (nel nostro dataset).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Introduzione alla distribuzione normale</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07a_introduction_normal_distribution.html#media-e-deviazione-standard-come-statistiche-descrittive-della-distribuzione",
    "href": "chapters/eda/07a_introduction_normal_distribution.html#media-e-deviazione-standard-come-statistiche-descrittive-della-distribuzione",
    "title": "20¬† Introduzione alla distribuzione normale",
    "section": "\n20.4 Media e Deviazione Standard come Statistiche Descrittive della Distribuzione",
    "text": "20.4 Media e Deviazione Standard come Statistiche Descrittive della Distribuzione\nLa media e la deviazione standard sono due delle statistiche pi√π comunemente utilizzate per descrivere la distribuzione di un insieme di dati. Queste misure sono particolarmente utili quando i dati seguono una distribuzione normale. In questo caso, la media e la deviazione standard contengono tutte le informazioni necessarie per caratterizzare completamente la forma della distribuzione.\n\n20.4.1 Distribuzione Normale e Statistiche Descrittive\nLa distribuzione normale √® definita dalla sua media (\\(\\mu\\)) e dalla sua deviazione standard (\\(\\sigma\\)). La formula della densit√† di probabilit√† della distribuzione normale √® data dall‚ÄôEquazione¬†20.1. Questa formula mostra che, conoscendo solo \\(\\mu\\) e \\(\\sigma\\), possiamo ricostruire l‚Äôintera curva di densit√†. Pertanto, se i dati empirici sono ben approssimati da una distribuzione normale, la media e la deviazione standard sono sufficienti per descrivere la distribuzione.\nSupponiamo di avere un dataset che segue una distribuzione normale con media 50 e deviazione standard 10. Possiamo generare dati casuali e visualizzare la curva di densit√† in R:\n\n# Generiamo dati da una distribuzione normale\nset.seed(123)\ndati &lt;- rnorm(1000, mean = 50, sd = 10)\n\n# Calcoliamo media e deviazione standard\nmedia &lt;- mean(dati)\ndeviazione_standard &lt;- sd(dati)\n\n# Visualizziamo la curva di densit√†\nggplot(data.frame(dati), aes(x = dati)) +\n  geom_density(fill = \"lightblue\") +\n  geom_vline(xintercept = media, color = \"red\", linetype = \"dashed\") +\n  labs(title = \"Curva di Densit√† di una Distribuzione Normale\",\n       x = \"Valori\",\n       y = \"Densit√†\") +\n  annotate(\"text\", x = media + 5, y = 0.03, label = paste(\"Media =\", round(media, 2)), color = \"red\") +\n  annotate(\"text\", x = media + 5, y = 0.025, label = paste(\"Deviazione Standard =\", round(deviazione_standard, 2)), color = \"blue\")\n\n\n\n\n\n\n\nIn questo esempio:\n\nLa curva di densit√† √® centrata attorno alla media (\\(\\mu = 50\\)).\nLa deviazione standard (\\(\\sigma = 10\\)) determina la dispersione dei dati attorno alla media.\n\n20.4.2 Quando Media e Deviazione Standard Non Sono Sufficienti\nSebbene media e deviazione standard siano strumenti estremamente utili per descrivere distribuzioni normali, non sempre bastano a cogliere tutte le caratteristiche di un insieme di dati. In particolare, ci sono situazioni in cui la forma della distribuzione rende necessario ricorrere a misure aggiuntive. Di seguito presentiamo alcuni casi tipici.\n\n\nDistribuzioni Asimmetriche\nUna distribuzione si dice asimmetrica (o skewed) quando una coda √® pi√π ‚Äúestesa‚Äù dell‚Äôaltra.\n\nSe la coda pi√π lunga √® a destra, la distribuzione √® asimmetrica positiva (o a destra).\n\nSe la coda pi√π lunga √® a sinistra, la distribuzione √® asimmetrica negativa (o a sinistra).\nIn queste circostanze, la media tende a spostarsi verso la coda pi√π lunga, mentre la mediana rimane pi√π stabile e rappresentativa del valore centrale.\n\n\nDistribuzioni Multimodali\nUna distribuzione √® multimodale quando presenta pi√π picchi (o ‚Äúmodi‚Äù). Ci√≤ significa che i dati si concentrano attorno a pi√π di un valore, formando veri e propri sotto-gruppi. In questi casi, media e deviazione standard possono risultare poco significative, poich√© non colgono la presenza di pi√π poli di concentrazione.\n\nKurtosi\nLa kurtosi descrive quanto una distribuzione sia ‚Äúappuntita‚Äù o ‚Äúpiatta‚Äù rispetto a una normale.\n\n\nAlta kurtosi indica picchi molto accentuati e code pi√π lunghe, con una maggiore probabilit√† di valori estremi.\n\n\nBassa kurtosi segnala una forma pi√π appiattita, con code ridotte e meno outlier.\n\n\n\nQuando le distribuzioni mostrano una di queste peculiarit√†, altre statistiche possono rivelarsi pi√π informative:\n\nLa mediana, insensibile ai valori estremi, fornisce una descrizione pi√π robusta del centro.\n\nI quartili, e in particolare l‚Äôintervallo interquartile, danno un‚Äôidea della dispersione principale trascurando le code.\n\nL‚Äôindice di asimmetria (skewness) misura il grado di sbilanciamento della distribuzione.\n\nL‚Äôindice di curtosi (kurtosis) quantifica la ‚Äúpesantezza‚Äù delle code.\n\nNel seguente esempio, generiamo dati da una distribuzione esponenziale, notoriamente asimmetrica:\n\n# Generiamo dati da una distribuzione esponenziale\nset.seed(123)\ndati_esponenziali &lt;- rexp(1000, rate = 0.5)\n\n# Calcoliamo media e deviazione standard\nmedia_esp &lt;- mean(dati_esponenziali)\ndeviazione_standard_esp &lt;- sd(dati_esponenziali)\n\n# Visualizziamo la curva di densit√†\nggplot(data.frame(dati_esponenziali), aes(x = dati_esponenziali)) +\n  geom_density(fill = \"#F8766D\", alpha = 0.6) +\n  geom_vline(xintercept = media_esp, color = \"red\", linetype = \"dashed\") +\n  labs(title = \"Curva di Densit√† di una Distribuzione Esponenziale\",\n       x = \"Valori\",\n       y = \"Densit√†\") +\n  annotate(\"text\", x = media_esp + 1, y = 0.2, \n           label = paste(\"Media =\", round(media_esp, 2)), \n           color = \"red\") +\n  annotate(\"text\", x = media_esp + 1, y = 0.18, \n           label = paste(\"Deviazione Standard =\", round(deviazione_standard_esp, 2)), \n           color = \"blue\")\n\n\n\n\n\n\n\nL‚Äôistogramma (o la densit√†) mostra chiaramente una coda lunga a destra, con molti valori piccoli e pochi valori grandi. In questo contesto:\n\nLa media tende a seguire la coda, diventando meno rappresentativa del ‚Äúcentro‚Äù.\n\nLa deviazione standard non descrive in modo efficace la variabilit√†, perch√© non considera adeguatamente la forte asimmetria.\n\nMisure alternative, come la mediana e i quartili, forniscono informazioni pi√π affidabili:\n\n# Calcoliamo mediana e quartili\nmediana &lt;- median(dati_esponenziali)\nquartili &lt;- quantile(dati_esponenziali, probs = c(0.25, 0.75))\n\ncat(\"Mediana:\", mediana, \"\\n\")\n#&gt; Mediana: 1.462\ncat(\"Primo Quartile (Q1):\", quartili[1], \"\\n\")\n#&gt; Primo Quartile (Q1): 0.6134\ncat(\"Terzo Quartile (Q3):\", quartili[2], \"\\n\")\n#&gt; Terzo Quartile (Q3): 2.853\n\nIn conclusione, quando i dati non presentano una forma vicina alla normalit√† (ad esempio perch√© asimmetrici, multimodali o con kurtosi anomala), media e deviazione standard possono risultare fuorvianti o poco utili. In questi casi, √® fondamentale adottare misure alternative o complementari (mediana, quartili, skewness, kurtosis) per ottenere una descrizione pi√π accurata della distribuzione.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Introduzione alla distribuzione normale</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07a_introduction_normal_distribution.html#riflessioni-conclusive",
    "href": "chapters/eda/07a_introduction_normal_distribution.html#riflessioni-conclusive",
    "title": "20¬† Introduzione alla distribuzione normale",
    "section": "\n20.5 Riflessioni Conclusive",
    "text": "20.5 Riflessioni Conclusive\nIn questo capitolo, abbiamo esplorato alcuni concetti fondamentali per l‚Äôanalisi dei dati e consolidato le basi per un‚Äôinterpretazione pi√π approfondita delle distribuzioni. In particolare, abbiamo:\n\n\nStudiato la distribuzione normale, una delle distribuzioni pi√π importanti in statistica, e compreso perch√© la media e la deviazione standard siano parametri cruciali per descriverla. Questi indicatori ci permettono di riassumere in modo efficace le caratteristiche centrali e la variabilit√† dei dati.\n\nImparato a standardizzare i dati convertendoli in unit√† standard (z-score), il che ci consente di confrontare variabili con scale diverse o di valutare quanto un dato specifico si discosti dalla media in termini di deviazioni standard.\n\nIntrodotto il grafico quantile-quantile (QQ-plot), uno strumento visivo prezioso per verificare se i nostri dati seguono una distribuzione normale. Attraverso il QQ-plot, possiamo confrontare i quantili empirici dei nostri dati con quelli teorici della distribuzione normale, identificando eventuali deviazioni.\n\nGli strumenti descritti in questo capitolo rappresentano il primo passo essenziale nell‚Äôanalisi esplorativa dei dati. Essi ci aiutano a formulare ipotesi solide e a riconoscere potenziali problemi o caratteristiche peculiari dei dati prima di applicare metodi statistici pi√π avanzati, che approfondiremo nei prossimi capitoli.\nL‚Äôanalisi esplorativa, combinando grafici intuitivi e statistiche descrittive appropriate, riveste quindi un ruolo fondamentale nel processo analitico. Essa non solo ci aiuta a comprendere meglio la natura dei dati, ma ci fornisce anche una base solida su cui costruire conclusioni statistiche attendibili e informate.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Introduzione alla distribuzione normale</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07a_introduction_normal_distribution.html#esercizi",
    "href": "chapters/eda/07a_introduction_normal_distribution.html#esercizi",
    "title": "20¬† Introduzione alla distribuzione normale",
    "section": "\n20.6 Esercizi",
    "text": "20.6 Esercizi\n\n\n\n\n\n\nEsercizi\n\n\n\n\n\nEsercizi Teorici\nüìå Rispondi alle seguenti domande per consolidare la comprensione teorica della distribuzione normale e dei suoi concetti chiave.\n\n\nCaratteristiche della distribuzione normale\n\nQuali sono i due parametri principali della distribuzione normale?\n\nPerch√© la distribuzione normale √® utilizzata cos√¨ frequentemente in statistica?\n\nIn quali situazioni reali possiamo aspettarci che una variabile segua una distribuzione normale?\n\n\n\nMedia e deviazione standard\n\nQual √® il significato della media in una distribuzione normale?\n\nCosa rappresenta la deviazione standard?\n\nIn che modo la deviazione standard influenza la forma della curva normale?\n\n\n\nZ-score e standardizzazione\n\nCos‚Äô√® uno z-score e come si calcola?\n\nQual √® il significato di un valore z=2? E di un valore z=-1.5?\n\nDopo la standardizzazione, quali saranno la media e la deviazione standard della variabile?\n\n\n\nVerifica della normalit√†\n\nSe hai un piccolo campione di dati (circa 15 osservazioni), quali metodi grafici puoi utilizzare per valutare se segue una distribuzione normale?\n\nQuali strumenti statistici puoi impiegare per testare la normalit√†?\n\nIn un QQ-plot, come puoi riconoscere se i dati seguono una distribuzione normale?\n\n\n\nEsercizi Pratici in R\nüìå Obiettivo: Analizzare i dati raccolti dagli studenti sulla Satisfaction With Life Scale (SWLS), comprendere la loro distribuzione e confrontarli con una distribuzione normale teorica.\nüíæ Dati disponibili:\nUsa i dati della SWLS. I dati contengono anche informazioni sul genere e su un indice di rete sociale (LSNS).\n1. Esplorazione e Visualizzazione dei Dati SWLS\n\n\nCarica i dati raccolti dagli studenti e verifica la struttura del dataset.\n\n\nCalcola i valori di base: media, deviazione standard, minimo, massimo, e quantili della SWLS.\n\n\nCrea una rappresentazione visiva dei dati:\n\nIstogramma con sovrapposta una curva di densit√†.\n\nBoxplot per identificare eventuali outlier.\n\nViolin plot per osservare la distribuzione.\n\n\n\n2. Confronto con la Distribuzione Normale\n\n\nSovrapponi ai dati osservati una curva normale teorica basata su media e deviazione standard stimate dal campione.\n\n\nConfronta i quantili empirici con quelli teorici mediante un QQ-plot.\n\n\nCommenta il risultato: i dati SWLS seguono approssimativamente una normale? Se no, quali differenze noti?\n\n3. Standardizzazione dei Punteggi SWLS\n\n\nTrasforma i dati della SWLS in z-score per analizzarli in unit√† standardizzate.\n\nVerifica la nuova media e deviazione standard: dovrebbero essere 0 e 1 rispettivamente.\n\n\nConta quanti punteggi standardizzati si trovano entro 1, 2 e 3 deviazioni standard dalla media e confronta i valori attesi di 68%, 95% e 99.7%.\n\n4. Relazione tra SWLS e Interazione Sociale (LSNS)\n\n\nEsplora la relazione tra SWLS e il punteggio della Scala della Rete Sociale di Lubben (LSNS-6).\n\n\nCostruisci un grafico a dispersione per osservare la correlazione tra le due variabili.\n\n\nCalcola il coefficiente di correlazione di Pearson e commenta il risultato. Esiste una relazione tra soddisfazione della vita e supporto sociale?\n\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n1. Caratteristiche della distribuzione normale\na. Quali sono i due parametri principali della distribuzione normale?\nI due parametri principali che definiscono una distribuzione normale sono:\n\n\nLa media (Œº): Indica il centro della distribuzione. Tutte le osservazioni si raggruppano attorno a questo valore.\n\nLa deviazione standard (œÉ): Descrive la dispersione o la variabilit√† dei dati attorno alla media.\n\nb. Perch√© la distribuzione normale √® utilizzata cos√¨ frequentemente in statistica?\nLa distribuzione normale √® ampiamente usata per diversi motivi:\n\n\nTeorema del limite centrale: Afferma che, quando si sommano molte variabili casuali indipendenti, la loro distribuzione tende ad avvicinarsi a una normale, indipendentemente dalla forma originale delle singole distribuzioni.\n\nSemplicit√† matematica: La normale ha propriet√† matematiche ben definite e permette di calcolare probabilit√† e intervalli con facilit√†.\n\nModellizzazione naturale: Molte variabili naturali e sociali (ad esempio, altezze, pesi, punteggi standardizzati) seguono approssimativamente una distribuzione normale.\n\nc.¬†In quali situazioni reali possiamo aspettarci che una variabile segua una distribuzione normale?\nSi pu√≤ aspettare una distribuzione normale in situazioni in cui:\n\nLe osservazioni sono influenzate da molti fattori casuali indipendenti (es. altezza di un individuo, errore di misurazione).\nI dati derivano da fenomeni naturali o biologici (es. pressione sanguigna, peso corporeo).\nSi analizzano medie campionarie di grandi dimensioni (grazie al teorema del limite centrale).\n\n2. Media e deviazione standard\na. Qual √® il significato della media in una distribuzione normale?\nNella distribuzione normale, la media rappresenta il punto centrale della curva, ovvero il valore pi√π probabile. √à anche il punto di simmetria della distribuzione, dove met√† delle osservazioni si trova a sinistra e l‚Äôaltra met√† a destra.\nb. Cosa rappresenta la deviazione standard?\nLa deviazione standard misura quanto i dati si discostano in media dalla media. Una deviazione standard bassa indica che i dati sono raggruppati strettamente attorno alla media, mentre una deviazione standard alta indica una maggiore dispersione.\nc.¬†In che modo la deviazione standard influenza la forma della curva normale?\n\nUna deviazione standard piccola produce una curva alta e stretta, indicando una bassa variabilit√†.\nUna deviazione standard grande produce una curva bassa e larga, indicando una maggiore variabilit√†.\n\n3. Z-score e standardizzazione\na. Cos‚Äô√® uno z-score e come si calcola?\nUno z-score misura quante deviazioni standard un dato si discosta dalla media. Viene calcolato come:\n\\[\nz = \\frac{x - \\mu}{\\sigma}\n\\]\ndove \\(x\\) √® il valore osservato, \\(\\mu\\) √® la media e \\(\\sigma\\) √® la deviazione standard.\nb. Qual √® il significato di un valore z=2? E di un valore z=-1.5?\n\nUn \\(z = 2\\) significa che il dato √® posizionato a 2 deviazioni standard sopra la media.\nUn \\(z = -1.5\\) significa che il dato √® posizionato a 1.5 deviazioni standard sotto la media.\n\nc.¬†Dopo la standardizzazione, quali saranno la media e la deviazione standard della variabile?\nDopo la standardizzazione:\n\nLa media diventa \\(0\\).\nLa deviazione standard diventa \\(1\\).\n\n4. Verifica della normalit√†\na. Se hai un piccolo campione di dati (circa 15 osservazioni), quali metodi grafici puoi utilizzare per valutare se segue una distribuzione normale?\nPer piccoli campioni, i metodi grafici pi√π utili sono:\n\n\nQQ-plot (Quantile-Quantile plot): Confronta i quantili dei dati con quelli di una distribuzione normale. Se i punti seguono una retta diagonale, i dati sono normali.\n\nIstogramma: Mostra la distribuzione dei dati, ma con campioni piccoli pu√≤ essere meno preciso.\n\nb. Quali strumenti statistici puoi impiegare per testare la normalit√†?\nGli strumenti statistici pi√π comuni per verificare la normalit√† sono:\n\n\nTest di Shapiro-Wilk: Ideale per piccoli campioni.\n\nTest di Kolmogorov-Smirnov: Usato per confrontare la distribuzione empirica con una normale.\n\nTest di Anderson-Darling: Sensibile alle code della distribuzione.\n\nc.¬†In un QQ-plot, come puoi riconoscere se i dati seguono una distribuzione normale?\nIn un QQ-plot:\n\nSe i dati seguono una distribuzione normale, i punti si allineeranno lungo una retta diagonale.\nDeviazioni dalla retta indicano departi dalla normalit√†:\n\nCode pesanti: Punti esterni alla retta suggeriscono outlier.\nAsimmetria: Punti curvati suggeriscono skewness (asimmetria).\n\n\n\nEsplorazione e Visualizzazione dei Dati SWLS\nCaricamento e struttura dei dati\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Supponiamo che i dati siano i seguenti\nset.seed(42)\nswls &lt;- data.frame(\n  ID = 1:15,\n  SWLS = c(18, 22, 25, 21, 26, 19, 20, 23, 24, 17, 22, 27, 28, 21, 19),\n  Genere = c(\"M\", \"F\", \"F\", \"M\", \"F\", \"M\", \"M\", \"F\", \"M\", \"F\", \"M\", \"F\", \"F\", \"M\", \"M\"),\n  LSNS = c(16, 20, 22, 14, 19, 18, 17, 25, 23, 12, 21, 28, 26, 19, 15)\n)\n\nstr(swls)\nsummary(swls$SWLS)\nVisualizzazioni\n# Istogramma con curva di densit√†\nggplot(swls, aes(x = SWLS)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 6, fill = \"blue\", alpha = 0.5) +\n  geom_density(color = \"red\", size = 1) +\n  ggtitle(\"Distribuzione dei punteggi SWLS\")\n\n# Boxplot\nggplot(swls, aes(y = SWLS)) +\n  geom_boxplot(fill = \"cyan\") +\n  ggtitle(\"Boxplot dei punteggi SWLS\")\n2. Confronto con la Distribuzione Normale\n# QQ-plot per valutare la normalit√†\nggplot(swls, aes(sample = SWLS)) +\n  geom_qq() +\n  geom_abline() +\n  ggtitle(\"QQ-plot dei punteggi SWLS\") +\n  theme_minimal()\nOsservazione:\n\nSe i punti si allineano lungo la diagonale, i dati sono approssimativamente normali.\nSe ci sono deviazioni marcate, la distribuzione potrebbe essere asimmetrica o presentare code pesanti.\n\n3. Standardizzazione dei punteggi SWLS\nswls$Z_SWLS &lt;- scale(swls$SWLS)\n\nmean(swls$Z_SWLS)  # Dovrebbe essere circa 0\nsd(swls$Z_SWLS)    # Dovrebbe essere circa 1\n\n# Proporzione entro 1, 2, 3 deviazioni standard\nmean(abs(swls$Z_SWLS) &lt; 1)  # Atteso ~68%\nmean(abs(swls$Z_SWLS) &lt; 2)  # Atteso ~95%\nmean(abs(swls$Z_SWLS) &lt; 3)  # Atteso ~99.7%\n4. Relazione tra SWLS e LSNS\n# Grafico di dispersione\nggplot(swls, aes(x = LSNS, y = SWLS)) +\n  geom_point(color = \"blue\", size = 3) +\n  geom_smooth(method = \"lm\", color = \"red\", se = FALSE) +\n  ggtitle(\"Relazione tra SWLS e LSNS\") \n\n# Calcolo della correlazione\ncor(swls$SWLS, swls$LSNS)\nInterpretazione:\n\nUn valore di correlazione positivo indica che livelli pi√π alti di supporto sociale (LSNS) sono associati a una maggiore soddisfazione della vita (SWLS).\n\nSe la correlazione √® debole, il supporto sociale potrebbe non essere un predittore forte della soddisfazione della vita in questo campione ristretto.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Introduzione alla distribuzione normale</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07a_introduction_normal_distribution.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/07a_introduction_normal_distribution.html#informazioni-sullambiente-di-sviluppo",
    "title": "20¬† Introduzione alla distribuzione normale",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] dslabs_0.8.0     ggbeeswarm_0.7.2 thematic_0.1.6   MetBrewer_0.2.0 \n#&gt;  [5] ggokabeito_0.1.0 see_0.11.0       gridExtra_2.3    patchwork_1.3.0 \n#&gt;  [9] bayesplot_1.11.1 psych_2.5.3      scales_1.3.0     markdown_2.0    \n#&gt; [13] knitr_1.50       lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1   \n#&gt; [17] dplyr_1.1.4      purrr_1.0.4      readr_2.1.5      tidyr_1.3.1     \n#&gt; [21] tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3       \n#&gt; [25] here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.9.1   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         rlang_1.1.5       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       tools_4.4.2       parallel_4.4.2    tzdb_0.5.0       \n#&gt; [21] colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5       R6_2.6.1         \n#&gt; [25] lifecycle_1.0.4   htmlwidgets_1.6.4 vipor_0.4.7       beeswarm_0.4.0   \n#&gt; [29] pkgconfig_2.0.3   pillar_1.10.1     gtable_0.3.6      glue_1.8.0       \n#&gt; [33] xfun_0.51         tidyselect_1.2.1  rstudioapi_0.17.1 farver_2.1.2     \n#&gt; [37] htmltools_0.5.8.1 nlme_3.1-167      labeling_0.4.3    rmarkdown_2.29   \n#&gt; [41] compiler_4.4.2",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Introduzione alla distribuzione normale</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07a_introduction_normal_distribution.html#bibliografia",
    "href": "chapters/eda/07a_introduction_normal_distribution.html#bibliografia",
    "title": "20¬† Introduzione alla distribuzione normale",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nIrizarry, R. A. (2024). Introduction to Data Science: Data Wrangling and Visualization with R. CRC Press.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Introduzione alla distribuzione normale</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html",
    "href": "chapters/eda/08_correlation.html",
    "title": "21¬† Relazioni tra variabili",
    "section": "",
    "text": "21.1 Introduzione\nL‚Äôanalisi delle associazioni tra variabili √® un‚Äôoperazione fondamentale nell‚Äôambito della ricerca psicologica, ma nonostante la sua apparente semplicit√†, rappresenta uno degli aspetti pi√π controversi e metodologicamente complessi. Sebbene possa sembrare un passaggio naturale successivo all‚Äôanalisi univariata, questo processo solleva numerose questioni concettuali e pratiche che richiedono un‚Äôattenta riflessione.\nStoricamente, in psicologia, l‚Äôanalisi delle associazioni tra variabili √® stata spesso considerata come l‚Äôobiettivo finale del processo di ricerca. Questa visione si basa sull‚Äôidea che la descrizione delle relazioni tra variabili possa fornire una spiegazione esaustiva dei fenomeni psicologici. Tale approccio affonda le sue radici nel pensiero di Karl Pearson (1911), il quale sosteneva che la spiegazione scientifica si esaurisse una volta delineate le associazioni tra le variabili osservate. Pearson affermava:\nSebbene sia indubbio che rispondere alla domanda posta da Pearson sia relativamente semplice, √® altrettanto evidente che la nostra comprensione di un fenomeno non pu√≤ dipendere unicamente dalle informazioni fornite dalle correlazioni. Le associazioni, infatti, non implicano causalit√† e possono risultare fuorvianti se interpretate in modo superficiale.\nIn contrasto con questa visione tradizionale, la cosiddetta ‚ÄúCausal Revolution‚Äù propone un paradigma radicalmente diverso, secondo il quale le associazioni tra variabili sono considerate come epifenomeni, ovvero manifestazioni superficiali di meccanismi pi√π profondi. L‚Äôobiettivo principale della ricerca, in questo quadro, diventa l‚Äôidentificazione e la comprensione delle relazioni causali. Per comprendere veramente i fenomeni psicologici, √® essenziale indagare le cause sottostanti, andando oltre la mera descrizione delle associazioni.\nUn esempio emblematico √® l‚Äôassociazione tra il numero di scarpe e le abilit√† matematiche nei bambini. Questa correlazione √® molto forte, ma se controlliamo per la variabile confondente ‚Äúet√†‚Äù, l‚Äôassociazione scompare. Questo dimostra che, in psicologia cos√¨ come in altri campi, trovare correlazioni molto forti tra variabili non √® necessariamente informativo riguardo ai meccanismi sottostanti al fenomeno studiato. √à ovvio che il numero di scarpe non influisce sulle abilit√† matematiche, ma senza controllare per l‚Äôet√†, l‚Äôassociazione rimane ingannevolmente forte.\nAllo stesso modo, pu√≤ accadere che un‚Äôassociazione apparentemente forte scompaia se non si tiene conto di variabili confondenti. Consideriamo, ad esempio, la relazione tra autostima e rendimento scolastico in un campione di adolescenti. Analizzando l‚Äôintera popolazione, la correlazione tra autostima e rendimento potrebbe risultare prossima a zero. Questo apparente risultato nullo, tuttavia, potrebbe nascondere una relazione pi√π complessa, influenzata da un fattore confondente come il supporto familiare.\nQuando si controlla per il supporto familiare (ad esempio analizzando separatamente i gruppi con alto e basso sostegno), emerge una relazione positiva credibile tra autostima e rendimento scolastico all‚Äôinterno del gruppo con supporto elevato. Questo esempio mostra come, a livello aggregato, l‚Äôeffetto di due variabili possa apparire nullo, mentre il controllo per un confondente svela una relazione causale rilevante.\nIn conclusione, l‚Äôanalisi delle associazioni rappresenta un punto di partenza fondamentale, ma non pu√≤ sostituire l‚Äôindagine delle relazioni causali. Per progredire nella comprensione dei fenomeni psicologici, √® necessario integrare l‚Äôanalisi dei dati con modelli teorici robusti e un approccio critico volto a identificare e controllare i fattori confondenti. Solo cos√¨ possiamo passare dalla semplice descrizione delle relazioni alla vera comprensione dei meccanismi causali che le governano.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#introduzione",
    "href": "chapters/eda/08_correlation.html#introduzione",
    "title": "21¬† Relazioni tra variabili",
    "section": "",
    "text": "‚ÄúQuanto spesso, quando √® stato osservato un nuovo fenomeno, sentiamo che viene posta la domanda: ‚Äòqual √® la sua causa?‚Äô. Questa √® una domanda a cui potrebbe essere assolutamente impossibile rispondere. Invece, pu√≤ essere pi√π facile rispondere alla domanda: ‚Äòin che misura altri fenomeni sono associati con esso?‚Äô. Dalla risposta a questa seconda domanda possono risultare molte preziose conoscenze.‚Äù\n\n\n\n\n\n\nIn presenza di un forte supporto familiare, una maggiore autostima potrebbe effettivamente favorire migliori risultati scolastici.\n\nAl contrario, in assenza di tale supporto, anche livelli elevati di autostima potrebbero non tradursi in un rendimento scolastico migliore, a causa di risorse emotive e pratiche limitate.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#terminologia",
    "href": "chapters/eda/08_correlation.html#terminologia",
    "title": "21¬† Relazioni tra variabili",
    "section": "\n21.2 Terminologia",
    "text": "21.2 Terminologia\nLa discussione dei metodi utilizzati per individuare le relazioni causali sar√† trattata successivamente. In questo capitolo, ci concentreremo sui concetti statistici fondamentali necessari per descrivere le associazioni lineari tra variabili. √à importante sottolineare che, sebbene esistano indici statistici per quantificare associazioni non lineari, la maggior parte degli psicologi si limita all‚Äôutilizzo di indici lineari.\nNel linguaggio comune, termini come ‚Äúdipendenza‚Äù, ‚Äúassociazione‚Äù e ‚Äúcorrelazione‚Äù vengono spesso usati in modo intercambiabile. Tuttavia, da un punto di vista tecnico, √® importante distinguere questi concetti:\n\n\nAssociazione: questo termine indica una relazione generale tra variabili, dove la conoscenza del valore di una variabile fornisce informazioni su un‚Äôaltra.\n\nCorrelazione: descrive una relazione specifica e quantificabile, indicando se due variabili tendono a variare insieme in modo sistematico. Ad esempio, in una correlazione positiva, se \\(X &gt; \\mu_X\\), √® probabile che anche \\(Y &gt; \\mu_Y\\). La correlazione specifica il segno e l‚Äôintensit√† di una relazione lineare.\n\nDipendenza: indica una relazione causale tra le variabili, dove la variazione della variabile causale porta probabilisticamente alla variazione della variabile dipendente.\n\n√à cruciale comprendere che non tutte le associazioni sono correlazioni e, soprattutto, che la correlazione non implica necessariamente causalit√†. Questa distinzione √® fondamentale per interpretare correttamente i dati e evitare conclusioni errate sulle relazioni tra variabili.\nIn questo capitolo, esamineremo due misure statistiche fondamentali per valutare la relazione lineare tra due variabili: la covarianza e la correlazione. Questi indici ci permettono di descrivere il grado e la direzione dell‚Äôassociazione lineare tra variabili, quantificando come queste variano congiuntamente.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#analisi-della-relazione-tra-due-misure-della-depressione",
    "href": "chapters/eda/08_correlation.html#analisi-della-relazione-tra-due-misure-della-depressione",
    "title": "21¬† Relazioni tra variabili",
    "section": "\n21.3 Analisi della Relazione tra Due Misure della Depressione",
    "text": "21.3 Analisi della Relazione tra Due Misure della Depressione\nL‚Äôobiettivo di questo esempio √® esaminare la relazione tra due scale psicometriche che misurano la depressione: il Beck Depression Inventory II (BDI-II) e la Center for Epidemiologic Studies Depression Scale (CES-D). Lo studio di Zetsche et al. (2019) ha indagato se le aspettative negative possano costituire un meccanismo centrale nel mantenimento e nella reiterazione della depressione. In particolare, i ricercatori hanno confrontato 30 soggetti con almeno un episodio depressivo maggiore e 37 individui senza diagnosi depressiva.\n\n21.3.1 Strumenti di Misurazione\n\nBDI-II:\nStrumento di autovalutazione che misura l‚Äôintensit√† dei sintomi depressivi riscontrati nelle ultime due settimane. Composto da 21 item, ciascuno valutato su una scala da 0 a 3, fornisce una stima della gravit√† della depressione.\nCES-D:\nScala anch‚Äôessa di autovalutazione, progettata per quantificare i sintomi depressivi sperimentati nella settimana precedente, principalmente in popolazioni generali, con particolare attenzione ad adolescenti e giovani adulti.\n\nPoich√© entrambi gli strumenti mirano a misurare lo stesso costrutto, √® ragionevole aspettarsi una relazione lineare tra i punteggi ottenuti, pur riconoscendo che errori di misurazione e unit√† di misura diverse possono generare discrepanze.\n\n21.3.2 Analisi Statistica e Visualizzazione\nPer verificare la relazione tra i punteggi BDI-II e CES-D, i dati sono stati processati come segue:\n\n# Leggi i dati dal file CSV\ndf &lt;- rio::import(here::here(\"data\", \"data.mood.csv\"))\n\n# Seleziona le colonne di interesse\ndf &lt;- df |&gt;\n  dplyr::select(\"esm_id\", \"group\", \"bdi\", \"cesd_sum\")\n\n# Rimuovi righe duplicate e casi con valori mancanti in 'bdi'\ndf &lt;- df[!duplicated(df), ]\ndf &lt;- df[!is.na(df$bdi), ]\n\nSuccessivamente, √® stato realizzato un grafico a dispersione (scatterplot) in cui i valori del BDI-II sono stati posti sull‚Äôasse delle ascisse e quelli del CES-D sull‚Äôasse delle ordinate. Ogni punto rappresenta un partecipante, suddiviso per gruppo (soggetti depressi e controlli). L‚Äôaggiunta di una retta di regressione, ottenuta mediante un modello lineare, consente di valutare visivamente la tendenza di associazione tra le due misure.\n\n# Separazione dei dati per gruppo\nmdd_data &lt;- df[df$group == \"mdd\", ]\nctl_data &lt;- df[df$group == \"ctl\", ]\n\n# Calcolo dei coefficienti di regressione lineare\ncoeff_combined &lt;- lm(cesd_sum ~ bdi, data = df)$coefficients\n\n# Funzione per la retta di regressione\nline_combined &lt;- function(x) coeff_combined[1] + coeff_combined[2] * x\n\n# Generazione dei valori x per la retta\nx_values &lt;- seq(min(df$bdi), max(df$bdi), length.out = 100)\nokabe_ito_colors &lt;- c(\"Pazienti\" = \"#E69F00\",  # Arancione\n                      \"Controlli\" = \"#56B4E9\")  # Azzurro\n\n# Creazione del grafico a dispersione e della retta di regressione\nggplot() +\n  geom_point(\n    data = mdd_data,\n    aes(x = bdi, y = cesd_sum, color = \"Pazienti\"), alpha = 0.7\n  ) +\n  geom_point(\n    data = ctl_data,\n    aes(x = bdi, y = cesd_sum, color = \"Controlli\"), alpha = 0.7\n  ) +\n  geom_line(\n    aes(x = x_values, y = line_combined(x_values)),\n    linetype = \"dashed\", color = okabe_ito_colors[\"Pazienti\"]\n  ) +\n  geom_vline(\n    aes(xintercept = mean(mdd_data$bdi, na.rm = TRUE)),\n    color = okabe_ito_colors[\"Pazienti\"], alpha = 0.2\n  ) +\n  geom_vline(\n    aes(xintercept = mean(ctl_data$bdi, na.rm = TRUE)),\n    color = okabe_ito_colors[\"Controlli\"], alpha = 0.2\n  ) +\n  geom_hline(\n    aes(yintercept = mean(mdd_data$cesd_sum, na.rm = TRUE)),\n    color = okabe_ito_colors[\"Pazienti\"], alpha = 0.2\n  ) +\n  geom_hline(\n    aes(yintercept = mean(ctl_data$cesd_sum, na.rm = TRUE)),\n    color = okabe_ito_colors[\"Controlli\"], alpha = 0.2\n  ) +\n  labs(x = \"BDI-II\", y = \"CES-D\", color = \"Gruppo\") +\n  scale_color_manual(\n    values = okabe_ito_colors\n  )\n\n\n\n\n\n\n\n\n21.3.3 Interpretazione dei Risultati\nIl grafico a dispersione evidenzia una tendenza approssimativamente lineare tra i punteggi del BDI-II e della CES-D, indicando che, in linea teorica, le due scale sono associate nel misurare il livello di depressione. Tuttavia, la presenza di una certa dispersione dei dati rispetto alla retta ideale sottolinea l‚Äôinfluenza degli errori di misurazione e della natura arbitraria delle unit√† di misura utilizzate. Per una valutazione pi√π accurata della relazione, √® necessario ricorrere a indici statistici in grado di quantificare sia la forza che la direzione dell‚Äôassociazione.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#covarianza",
    "href": "chapters/eda/08_correlation.html#covarianza",
    "title": "21¬† Relazioni tra variabili",
    "section": "\n21.4 Covarianza",
    "text": "21.4 Covarianza\nIniziamo a considerare il pi√π importante di tali indici, chiamato covarianza. In realt√† la definizione di questo indice non ci sorprender√† pi√π di tanto in quanto, in una forma solo apparentemente diversa, l‚Äôabbiamo gi√† incontrata in precedenza. Ci ricordiamo infatti che la varianza di una generica variabile \\(X\\) √® definita come la media degli scarti quadratici di ciascuna osservazione dalla media:\n\\[\nS_{XX} = \\frac{1}{n} \\sum_{i=1}^n(X_i - \\bar{X}) (X_i - \\bar{X}).\n\\tag{21.1}\\]\nLa varianza viene talvolta descritta come la ‚Äúcovarianza di una variabile con s√© stessa‚Äù. Adesso facciamo un passo ulteriore. Invece di valutare la dispersione di una sola variabile, ci chiediamo come due variabili \\(X\\) e \\(Y\\) ‚Äúvariano insieme‚Äù (co-variano). √à facile capire come una risposta a tale domanda possa essere fornita da una semplice trasformazione della formula precedente che diventa:\n\\[\nS_{XY} = \\frac{1}{n} \\sum_{i=1}^n(X_i - \\bar{X}) (Y_i - \\bar{Y}).\n\\tag{21.2}\\]\nL‚ÄôEquazione¬†21.2 ci fornisce la definizione della covarianza.\n\n21.4.1 Interpretazione\nPer capire il significato dell‚ÄôEquazione¬†21.2, supponiamo di dividere il grafico riportato nella Sezione 21.3.2 in quattro quadranti definiti da una retta verticale passante per la media dei valori BDI-II e da una retta orizzontale passante per la media dei valori CES-D. Numeriamo i quadranti partendo da quello in basso a sinistra e muovendoci in senso antiorario.\nSe prevalgono punti nel I e III quadrante, allora la nuvola di punti avr√† un andamento crescente (per cui a valori bassi di \\(X\\) tendono ad associarsi valori bassi di \\(Y\\) e a valori elevati di \\(X\\) tendono ad associarsi valori elevati di \\(Y\\)) e la covarianza avr√† segno positivo. Mentre se prevalgono punti nel II e IV quadrante la nuvola di punti avr√† un andamento decrescente (per cui a valori bassi di \\(X\\) tendono ad associarsi valori elevati di \\(Y\\) e a valori elevati di \\(X\\) tendono ad associarsi valori bassi di \\(Y\\)) e la covarianza avr√† segno negativo. Dunque, il segno della covarianza ci informa sulla direzione della relazione lineare tra due variabili: l‚Äôassociazione lineare si dice positiva se la covarianza √® positiva, negativa se la covarianza √® negativa.\n\nEsempio 21.1 Implementiamo l‚ÄôEquazione¬†21.2 in R.\n\ncov_value &lt;- function(x, y) {\n  mean_x &lt;- sum(x) / length(x)\n  mean_y &lt;- sum(y) / length(y)\n\n  sub_x &lt;- x - mean_x\n  sub_y &lt;- y - mean_y\n\n  sum_value &lt;- sum(sub_y * sub_x)\n  denom &lt;- length(x)\n\n  cov &lt;- sum_value / denom\n  return(cov)\n}\n\nPer i dati mostrati nel diagramma, la covarianza tra BDI-II e CESD √® 207.4\n\nx &lt;- df$bdi\ny &lt;- df$cesd_sum\n\ncov_value(x, y)\n#&gt; [1] 207.4\n\nOppure, in maniera pi√π semplice:\n\nmean((x - mean(x)) * (y - mean(y)))\n#&gt; [1] 207.4\n\nLo stesso risultato si ottiene con la funzione cov:\n\ncov(x, y) * (length(x) - 1) / length(x)\n#&gt; [1] 207.4\n\nLa funzione cov(x, y) calcola la covarianza tra due array, x e y utilizzando \\(n-1\\) al denominatore.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#correlazione",
    "href": "chapters/eda/08_correlation.html#correlazione",
    "title": "21¬† Relazioni tra variabili",
    "section": "\n21.5 Correlazione",
    "text": "21.5 Correlazione\nLa direzione della relazione tra le variabili √® indicata dal segno della covarianza, ma il valore assoluto di questo indice non fornisce informazioni utili poich√© dipende dall‚Äôunit√† di misura delle variabili. Ad esempio, considerando l‚Äôaltezza e il peso delle persone, la covarianza sar√† pi√π grande se l‚Äôaltezza √® misurata in millimetri e il peso in grammi, rispetto al caso in cui l‚Äôaltezza √® in metri e il peso in chilogrammi. Pertanto, per descrivere la forza e la direzione della relazione lineare tra due variabili in modo adimensionale, si utilizza l‚Äôindice di correlazione.\nLa correlazione √® ottenuta standardizzando la covarianza tramite la divisione delle deviazioni standard (\\(s_X\\), \\(s_Y\\)) delle due variabili:\n\\[\nr = \\frac{S_{XY}}{S_X S_Y}.\n\\tag{21.3}\\]\nLa quantit√† che si ottiene dall‚ÄôEquazione¬†21.3 viene chiamata correlazione di Bravais-Pearson (dal nome degli autori che, indipendentemente l‚Äôuno dall‚Äôaltro, l‚Äôhanno introdotta).\nIn maniera equivalente, per una lista di coppie di valori \\((x_1, y_1), \\dots, (x_n, y_n)\\), il coefficiente di correlazione √® definito come la media del prodotto dei valori standardizzati:\n\\[\nr = \\frac{1}{n} \\sum_{i=1}^{n} \\left( \\frac{x_i - \\bar{x}}{\\sigma_x} \\right) \\left( \\frac{y_i - \\bar{y}}{\\sigma_y} \\right),\n\\tag{21.4}\\]\ndove \\(\\bar{x}\\) e \\(\\bar{y}\\) rappresentano, rispettivamente, le medie dei valori \\(x\\) e \\(y\\), e \\(\\sigma_x\\) e \\(\\sigma_y\\) sono le rispettive deviazioni standard.\nNell‚ÄôEquazione¬†21.4, i valori \\(x_i\\) e \\(y_i\\) vengono prima standardizzati sottraendo la media e dividendo per la deviazione standard, e poi si calcola la media del prodotto di questi valori standardizzati.\n\n21.5.1 Propriet√†\nIl coefficiente di correlazione ha le seguenti propriet√†:\n\nha lo stesso segno della covarianza, dato che si ottiene dividendo la covarianza per due numeri positivi;\n√® un numero puro, cio√® non dipende dall‚Äôunit√† di misura delle variabili;\nassume valori compresi tra -1 e +1.\n\n21.5.2 Interpretazione\nAll‚Äôindice di correlazione possiamo assegnare la seguente interpretazione:\n\n\n\\(r_{XY} = -1\\) \\(\\rightarrow\\) perfetta relazione negativa: tutti i punti si trovano esattamente su una retta con pendenza negativa (dal quadrante in alto a sinistra al quadrante in basso a destra);\n\n\\(r_{XY} = +1\\) \\(\\rightarrow\\) perfetta relazione positiva: tutti i punti si trovano esattamente su una retta con pendenza positiva (dal quadrante in basso a sinistra al quadrante in alto a destra);\n\n\\(-1 &lt; r_{XY} &lt; +1\\) \\(\\rightarrow\\) presenza di una relazione lineare di intensit√† diversa;\n\n\\(r_{XY} = 0\\) \\(\\rightarrow\\) assenza di relazione lineare tra \\(X\\) e \\(Y\\).\n\n\nEsempio 21.2 Per i dati riportati nel diagramma della Sezione 21.3.2, la covarianza √® 207.4. Il segno positivo della covarianza ci dice che tra le due variabili c‚Äô√® un‚Äôassociazione lineare positiva. Per capire quale sia l‚Äôintensit√† della relazione lineare calcoliamo la correlazione. Essendo le deviazioni standard del BDI-II e del CES-D rispettavamente uguali a 15.37 e 14.93, la correlazione diventa uguale a \\(\\frac{207.426}{15.38 \\cdot 14.93} = 0.904.\\) Tale valore √® prossimo a 1.0, il che vuol dire che i punti del diagramma a dispersione non si discostano troppo da una retta con una pendenza positiva.\nTroviamo la correlazione con la funzione corrcoef():\n\ncor(x, y)\n#&gt; [1] 0.9041\n\nReplichiamo il risultato implementando l‚ÄôEquazione¬†21.3:\n\ns_xy &lt;- mean((x - mean(x)) * (y - mean(y)))\ns_x &lt;- sqrt(mean((x - mean(x))^2)) # Deviazione standard popolazione\ns_y &lt;- sqrt(mean((y - mean(y))^2)) # Deviazione standard popolazione\nr_xy &lt;- s_xy / (s_x * s_y)\nprint(r_xy)\n#&gt; [1] 0.9041\n\nUn altro modo ancora per trovare la correlazione tra i punteggi BDI-II e CESD √® quello di applicare l‚ÄôEquazione¬†21.4:\n\nz_x &lt;- (x - mean(x)) / sqrt(mean((x - mean(x))^2)) \n# Standardizzazione con deviazione standard popolazione\nz_y &lt;- (y - mean(y)) / sqrt(mean((y - mean(y))^2)) \n# Standardizzazione con deviazione standard popolazione\nmean(z_x * z_y)\n#&gt; [1] 0.9041\n\n\n\nEsempio 21.3 Un uso interessante delle correlazioni viene fatto in un recente articolo di Guilbeault et al.¬†(2024). Il concetto di ‚Äúgender bias‚Äù si riferisce alla tendenza sistematica di favorire un sesso rispetto all‚Äôaltro, spesso a scapito delle donne. Lo studio di Guilbeault et al.¬†(2024) analizza come le immagini online influenzino la diffusione su vasta scala di questo preconcetto di genere.\nAttraverso un vasto insieme di immagini e testi raccolti online, gli autori dimostrano che sia le misurazioni basate sulle immagini che quelle basate sui testi catturano la frequenza con cui varie categorie sociali sono associate a rappresentazioni di genere, valutate su una scala da -1 (femminile) a 1 (maschile), con 0 che indica una neutralit√† di genere. Questo consente di quantificare il preconcetto di genere come una forma di bias statistico lungo tre dimensioni: la tendenza delle categorie sociali ad associarsi a un genere specifico nelle immagini e nei testi, la rappresentazione relativa delle donne rispetto agli uomini in tutte le categorie sociali nelle immagini e nei testi, e il confronto tra le associazioni di genere nei dati delle immagini e dei testi con la distribuzione empirica delle donne e degli uomini nella societ√†. Il lavoro di Guilbeault et al.¬†(2024) evidenzia che il preconcetto di genere √® molto pi√π evidente nelle immagini rispetto ai testi, come mostrato nel pannello C della figura.\nSi noti che, nel grafico del pannello C della figura, ogni punto pu√≤ essere interpretato come una misura di correlazione. La misura utilizzata da Guilbeault et al.¬†(2024) riflette il grado di associazione tra le categorie sociali e le rappresentazioni di genere presenti nelle immagini e nei testi analizzati. Quando la misura √® vicina a +1, indica una forte associazione positiva tra una categoria sociale specifica e una rappresentazione di genere maschile, mentre un valore vicino a -1 indica una forte associazione negativa con una rappresentazione di genere femminile. Un valore di 0, invece, suggerisce che non vi √® alcuna associazione tra la categoria sociale considerata e un genere specifico, indicando una sorta di neutralit√† di genere. In sostanza, questa misura di frequenza pu√≤ essere interpretata come una correlazione che riflette la tendenza delle categorie sociali a essere rappresentate in un modo o nell‚Äôaltro nelle immagini e nei testi analizzati, rispetto ai concetti di genere femminile e maschile.\n\n\nIl preconcetto di genere √® pi√π prevalente nelle immagini online (da Google Immagini) e nei testi online (da Google News). A. La correlazione tra le associazioni di genere nelle immagini da Google Immagini e nei testi da Google News per tutte le categorie sociali (n = 2.986), organizzate per decili. B. La forza dell‚Äôassociazione di genere in queste immagini e testi online per tutte le categorie (n = 2.986), suddivisa in base al fatto che queste categorie siano inclinate verso il femminile o il maschile. C. Le associazioni di genere per un campione di occupazioni secondo queste immagini e testi online; questo campione √® stato selezionato manualmente per evidenziare i tipi di categorie sociali e preconcetti di genere esaminati. (Figura tratta da Guilbeault et al.¬†(2024)).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#correlazione-di-spearman",
    "href": "chapters/eda/08_correlation.html#correlazione-di-spearman",
    "title": "21¬† Relazioni tra variabili",
    "section": "\n21.6 Correlazione di Spearman",
    "text": "21.6 Correlazione di Spearman\nUn‚Äôalternativa per valutare la relazione lineare tra due variabili √® il coefficiente di correlazione di Spearman, che si basa esclusivamente sull‚Äôordine dei dati e non sugli specifici valori. Questo indice di associazione √® particolarmente adatto quando gli psicologi sono in grado di misurare solo le relazioni di ordine tra diverse modalit√† di risposta dei soggetti, ma non l‚Äôintensit√† della risposta stessa. Tali variabili psicologiche che presentano questa caratteristica sono definite come ‚Äúordinali‚Äù.\n\n\n\n\n\n\n√à importante ricordare che, nel caso di una variabile ordinale, non √® possibile utilizzare le statistiche descrittive convenzionali come la media e la varianza per sintetizzare le osservazioni. Tuttavia, √® possibile riassumere le osservazioni attraverso una distribuzione di frequenze delle diverse modalit√† di risposta. Come abbiamo appena visto, la direzione e l‚Äôintensit√† dell‚Äôassociazione tra due variabili ordinali possono essere descritte utilizzando il coefficiente di correlazione di Spearman.\n\n\n\nPer fornire un esempio, consideriamo due variabili di scala ordinale e calcoliamo la correlazione di Spearman tra di esse.\n\ncor.test(c(1, 2, 3, 4, 5), c(5, 6, 7, 8, 7), method = \"spearman\")\n#&gt; \n#&gt;  Spearman's rank correlation rho\n#&gt; \n#&gt; data:  c(1, 2, 3, 4, 5) and c(5, 6, 7, 8, 7)\n#&gt; S = 3.6, p-value = 0.09\n#&gt; alternative hypothesis: true rho is not equal to 0\n#&gt; sample estimates:\n#&gt;    rho \n#&gt; 0.8208",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#oltre-la-correlazione-e-la-covarianza-auando-lassociazione-tra-variabili-√®-pi√π-complessa",
    "href": "chapters/eda/08_correlation.html#oltre-la-correlazione-e-la-covarianza-auando-lassociazione-tra-variabili-√®-pi√π-complessa",
    "title": "21¬† Relazioni tra variabili",
    "section": "\n21.7 Oltre la correlazione e la covarianza: Auando l‚ÄôAssociazione tra Variabili √® Pi√π Complessa",
    "text": "21.7 Oltre la correlazione e la covarianza: Auando l‚ÄôAssociazione tra Variabili √® Pi√π Complessa\nIn questo capitolo abbiamo introdotto due misure fondamentali per descrivere la relazione tra due variabili: covarianza e correlazione. La covarianza fornisce un‚Äôindicazione del modo in cui due variabili si discostano congiuntamente dalle proprie medie, mentre la correlazione ne standardizza i valori, permettendo un confronto pi√π immediato tra diverse coppie di variabili e garantendo un indice compreso tra -1 e +1. Una correlazione vicina a +1 indica una forte relazione lineare positiva, vicina a -1 una forte relazione lineare negativa, mentre un valore vicino a 0 segnala l‚Äôassenza di una chiara relazione lineare.\nTuttavia, √® cruciale comprendere che la correlazione descrive esclusivamente la dimensione lineare della relazione tra due variabili. Questo significa che una correlazione nulla (pari a zero) non implica affatto che non vi sia alcuna relazione tra le variabili, ma semplicemente che non esiste una relazione lineare. Possono esistere relazioni non lineari anche molto forti, non catturate da questo indice. Inoltre, altre situazioni possono trarre in inganno, come nei casi in cui i dati siano raggruppati in sottogruppi con propriet√† differenti o siano frutto di particolari processi di selezione.\n\n21.7.1 Correlazione Nulla e Relazioni Non Lineari\nUna correlazione pari a zero pu√≤ nascondere relazioni non lineari anche molto marcate. Per esempio, se una variabile Y aumenta solo quando X √® molto alta o molto bassa, ma rimane costante per valori intermedi di X, questa curva a ‚ÄúU‚Äù pu√≤ generare una correlazione vicina allo zero, pur esistendo un forte legame non lineare.\nUn esempio illustrativo √® fornito dal cosiddetto Datasaurus Dozen, un insieme di tredici dataset con la stessa media, deviazione standard e correlazione tra le variabili, ma con distribuzioni visivamente e strutturalmente molto diverse. In ognuno di questi dataset la correlazione di Pearson √® pari a zero, ma l‚Äôispezione grafica rivela pattern e forme ben definite. Questo ci ricorda che √® sempre bene accompagnare le misure numeriche con una visualizzazione grafica dei dati.\n\ndatasaurus_data &lt;- read.csv(\"../../data/datasaurus.csv\")\n\ndatasaurus_summary &lt;- datasaurus_data %&gt;%\n  group_by(dataset) %&gt;%\n  summarise(\n    x_count = n(),\n    x_mean = mean(x, na.rm = TRUE),\n    x_std = sd(x, na.rm = TRUE),\n    y_count = n(),\n    y_mean = mean(y, na.rm = TRUE),\n    y_std = sd(y, na.rm = TRUE)\n  )\n\ndatasaurus_summary\n#&gt; # A tibble: 13 √ó 7\n#&gt;    dataset    x_count x_mean x_std y_count y_mean y_std\n#&gt;    &lt;chr&gt;        &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt;\n#&gt;  1 away           142   54.3  16.8     142   47.8  26.9\n#&gt;  2 bullseye       142   54.3  16.8     142   47.8  26.9\n#&gt;  3 circle         142   54.3  16.8     142   47.8  26.9\n#&gt;  4 dino           142   54.3  16.8     142   47.8  26.9\n#&gt;  5 dots           142   54.3  16.8     142   47.8  26.9\n#&gt;  6 h_lines        142   54.3  16.8     142   47.8  26.9\n#&gt;  7 high_lines     142   54.3  16.8     142   47.8  26.9\n#&gt;  8 slant_down     142   54.3  16.8     142   47.8  26.9\n#&gt;  9 slant_up       142   54.3  16.8     142   47.8  26.9\n#&gt; 10 star           142   54.3  16.8     142   47.8  26.9\n#&gt; 11 v_lines        142   54.3  16.8     142   47.8  26.9\n#&gt; 12 wide_lines     142   54.3  16.8     142   47.8  26.9\n#&gt; 13 x_shape        142   54.3  16.8     142   47.8  26.9\n\n\ndatasaurus_data |&gt;\n  ggplot(aes(x = x, y = y)) +\n  geom_point(alpha = 0.7) +\n  facet_wrap(~dataset, nrow = 4, ncol = 4) +\n  labs(x = NULL, y = NULL)\n\n\n\n\n\n\n\nTutti questi esempi rafforzano l‚Äôidea che l‚Äôassenza di correlazione lineare non significa assenza di relazione: potremmo avere strutture curve, pattern complessi o punti anomali (outlier) capaci di modificare radicalmente la forma della relazione tra le variabili.\nOltre alle relazioni non lineari, esistono situazioni in cui la correlazione, da sola, pu√≤ fornire un‚Äôimmagine distorta dei dati. Tra queste ricordiamo due fenomeni noti come il paradosso di Simpson e il paradosso di Berkson.\n\n21.7.2 Paradosso di Simpson\nIl paradosso di Simpson si verifica quando, guardando i dati raggruppati per sottogruppi, si osserva una certa relazione tra due variabili, ma aggregando i dati di tutti i sottogruppi insieme emerge una relazione opposta. In altre parole, la tendenza che appare quando si considerano i dati divisi per gruppi scompare o si inverte quando si esamina l‚Äôintero campione senza tenere conto della suddivisione in sottogruppi.\nImmaginiamo di avere due dipartimenti universitari, A e B. All‚Äôinterno di ciascun dipartimento, la relazione tra il voto di laurea (X) e la performance in un successivo programma di specializzazione (Y) √® positiva: all‚Äôaumentare del voto di laurea aumenta, in media, la performance nella scuola di specializzazione.\nTuttavia, supponiamo che il Dipartimento A abbia in generale voti di laurea mediamente pi√π bassi, ma ottime performance nella specializzazione; mentre il Dipartimento B abbia voti di laurea mediamente pi√π alti, ma performance alla specializzazione un po‚Äô pi√π basse. Se uniamo tutti gli studenti dei due dipartimenti senza considerarne l‚Äôappartenenza, potremmo osservare una relazione negativa tra voto di laurea e performance, sovvertendo le conclusioni tratte guardando ai singoli sottogruppi.\nEcco come possiamo simulare questi dati in R:\n\nset.seed(123)\n\n# Numero di osservazioni per dipartimento\nn &lt;- 100\n\n# Dipartimento A:\n# Voti di laurea (X) pi√π bassi, ma performance (Y) pi√π alta.\n# Creiamo un legame positivo tra X e Y all'interno di A.\nX_A &lt;- rnorm(n, mean = 50, sd = 5)    # Voti laurea mediamente pi√π bassi\nY_A &lt;- X_A + rnorm(n, mean = 20, sd = 5) # Performance alta e correlata positivamente con X\n\n# Dipartimento B:\n# Voti di laurea (X) pi√π alti, ma performance (Y) pi√π bassa.\n# Anche qui creiamo un legame positivo tra X e Y all'interno di B, \n# ma con un offset tale che globalmente i voti alti coincidano con performance minori.\nX_B &lt;- rnorm(n, mean = 60, sd = 5)    # Voti laurea mediamente pi√π alti\nY_B &lt;- X_B - rnorm(n, mean = 10, sd = 5) # Performance pi√π bassa ma comunque correlata positivamente con X all‚Äôinterno di B\n\n# Creiamo un dataframe con tutti i dati\ndipartimento &lt;- c(rep(\"A\", n), rep(\"B\", n))\nX &lt;- c(X_A, X_B)\nY &lt;- c(Y_A, Y_B)\ndati &lt;- data.frame(dipartimento, X, Y)\n\n# Correlazioni all'interno dei dipartimenti\ncat(\"Correlazione nel Dipartimento A:\", cor(X_A, Y_A), \"\\n\")\n#&gt; Correlazione nel Dipartimento A: 0.6671\ncat(\"Correlazione nel Dipartimento B:\", cor(X_B, Y_B), \"\\n\")\n#&gt; Correlazione nel Dipartimento B: 0.6926\n\n# Correlazione sull'intero dataset (senza distinguere i dipartimenti)\ncat(\"Correlazione globale:\", cor(X, Y), \"\\n\")\n#&gt; Correlazione globale: -0.3353\n\n\n# Visualizziamo i dati\nggplot(dati, aes(x = X, y = Y, color = dipartimento)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  scale_fill_okabeito() + \n  labs(\n    title = \"Paradosso di Simpson\",\n    x = \"Voto di laurea\", \n    y = \"Performance nella specializzazione\",\n    color = \"Dipartimento\"\n  )\n\n\n\n\n\n\n\n\nAll‚Äôinterno del Dipartimento A: la correlazione tra voto di laurea (X) e performance (Y) √® positiva. Ci√≤ significa che, per gli studenti di A, avere un voto di laurea pi√π alto √® associato a una performance maggiore nella specializzazione.\nAll‚Äôinterno del Dipartimento B: la correlazione tra X e Y √® anch‚Äôessa positiva, indicando che anche nel secondo dipartimento voti pi√π alti tendono ad accompagnarsi a performance pi√π alte.\nConsiderando entrambi i dipartimenti insieme: a causa delle differenze nei livelli medi di X e Y tra i dipartimenti, unendo i dati senza distinguere il gruppo di appartenenza otteniamo una correlazione globale negativa. Questo significa che, ignorando la suddivisione in dipartimenti, sembra che aumentare il voto di laurea sia associato a una diminuzione della performance nella specializzazione ‚Äî una conclusione opposta a quella tratta dall‚Äôanalisi separata dei due sottogruppi.\n\nQuesto √® un esempio concreto del paradosso di Simpson: la relazione osservata in sottogruppi omogenei si inverte quando si aggregano i dati, mettendo in guardia sulla necessit√† di considerare con attenzione la struttura dei dati e i fattori confondenti prima di trarre conclusioni.\n\n21.7.3 Paradosso di Berkson\nIl paradosso di Berkson √® un fenomeno legato alla selezione del campione. Se il dataset non √® rappresentativo della popolazione generale, la relazione osservata pu√≤ risultare artificiale o opposta a quella esistente su un campione pi√π ampio. Per esempio, analizzando solo ciclisti professionisti, potremmo non vedere alcuna relazione tra VO2 max e probabilit√† di vincere una gara, poich√© tutti hanno gi√† superato una certa soglia di VO2 max. Considerando la popolazione generale, invece, potrebbe emergere chiaramente una relazione positiva tra questi due fattori. Questo paradosso evidenzia l‚Äôimportanza di considerare il processo di selezione dei dati e di chiedersi se il campione analizzato sia adeguato a rispondere alla domanda di ricerca.\n\n21.7.4 Limiti delle statistiche riassuntive semplici\nUn esempio famoso che dimostra i limiti delle semplici statistiche descrittive ‚Äî come media, deviazione standard e correlazione ‚Äî √® il quartetto di Anscombe. Questo insieme di quattro piccoli dataset possiede identiche medie, varianze e correlazioni tra variabili, ma rappresenta relazioni estremamente differenti tra X e Y (Anscombe, 1973).\nImportiamo il dataset anscombe gi√† disponibile nel pacchetto datasets di R:\n\ndata(\"anscombe\")\n\nanscombe |&gt; \n  head()\n#&gt;   x1 x2 x3 x4   y1   y2    y3   y4\n#&gt; 1 10 10 10  8 8.04 9.14  7.46 6.58\n#&gt; 2  8  8  8  8 6.95 8.14  6.77 5.76\n#&gt; 3 13 13 13  8 7.58 8.74 12.74 7.71\n#&gt; 4  9  9  9  8 8.81 8.77  7.11 8.84\n#&gt; 5 11 11 11  8 8.33 9.26  7.81 8.47\n#&gt; 6 14 14 14  8 9.96 8.10  8.84 7.04\n\nIl dataset anscombe contiene quattro serie di dati (x1, y1), (x2, y2), (x3, y3) e (x4, y4), ognuna costituita da 11 coppie di valori (x, y). Per comprendere meglio le loro caratteristiche, iniziamo calcolando alcune statistiche descrittive. La funzione apply() consente di applicare una funzione (ad esempio, mean) a tutte le colonne di un data frame. Usandola sulle colonne di anscombe, otteniamo le medie di ciascuna delle otto variabili (le quattro x e le quattro y):\n\napply(anscombe, MARGIN = 2, mean)\n#&gt;    x1    x2    x3    x4    y1    y2    y3    y4 \n#&gt; 9.000 9.000 9.000 9.000 7.501 7.501 7.500 7.501\n\nOsserviamo che le medie delle quattro variabili x sono identiche fino a sei cifre decimali, e le medie delle quattro variabili y differiscono solo in modo trascurabile (circa lo 0.01%). Analogamente, se calcoliamo le deviazioni standard per ciascuna variabile, notiamo una notevole somiglianza:\n\napply(anscombe, MARGIN = 2, sd)\n#&gt;    x1    x2    x3    x4    y1    y2    y3    y4 \n#&gt; 3.317 3.317 3.317 3.317 2.032 2.032 2.030 2.031\n\nAnche in questo caso, le deviazioni standard per le x coincidono fino alla sesta cifra decimale, mentre quelle delle y differiscono di meno dello 0.06%. Inoltre, se calcoliamo i coefficienti di correlazione tra x e y in ognuno dei quattro dataset, scopriamo che sono quasi identici:\n\n# Calcoliamo la correlazione per ciascuna coppia (x1,y1), (x2,y2), (x3,y3), (x4,y4)\nfor (i in 1:4) {\n  x_var &lt;- anscombe[[paste0(\"x\", i)]]\n  y_var &lt;- anscombe[[paste0(\"y\", i)]]\n  \n  corr_value &lt;- cor(x_var, y_var)\n  cat(\"Correlazione tra x\", i, \"e y\", i, \":\", corr_value, \"\\n\")\n}\n#&gt; Correlazione tra x 1 e y 1 : 0.8164 \n#&gt; Correlazione tra x 2 e y 2 : 0.8162 \n#&gt; Correlazione tra x 3 e y 3 : 0.8163 \n#&gt; Correlazione tra x 4 e y 4 : 0.8165\n\nSe ci limitassimo a guardare queste statistiche (media, deviazione standard, correlazione), potremmo facilmente essere indotti a concludere che i quattro dataset sono tra loro sostanzialmente indistinguibili. Tuttavia, la realt√† √® molto diversa. Le statistiche descrittive, prese da sole, non offrono una visione completa e possono nascondere importanti differenze nella struttura dei dati.\nQuesta differenza diventa evidente non appena decidiamo di visualizzare i dati. La rappresentazione grafica fornisce informazioni che non emergono dalle sole statistiche riassuntive:\n\nanscombe_m &lt;- tibble()\n\nfor (i in 1:4) {\n  anscombe_m &lt;- rbind(\n    anscombe_m, tibble(set = i, x = anscombe[, i], y = anscombe[, i + 4])\n  )\n}\n\nggplot(anscombe_m, aes(x, y)) +\n  geom_point(size = 3, color = \"red\", fill = \"orange\", shape = 21) +\n  geom_smooth(method = \"lm\", fill = NA, fullrange = TRUE) +\n  facet_wrap(~set, ncol = 2)\n\n\n\n\n\n\n\nOsservando i grafici, notiamo subito che i quattro dataset sono profondamente diversi:\n\n\nDataset 1: Qui la relazione tra x e y √® approssimativamente lineare, e la correlazione riflette in modo appropriato il legame tra le due variabili.\n\nDataset 2: Sebbene la correlazione sia simile a quella del Dataset 1, i dati mostrano una relazione curvilinea e non lineare. La semplice correlazione lineare non ne cattura la forma.\n\nDataset 3: La presenza di un singolo outlier distorce la percezione della relazione tra le variabili, altrimenti lineare. La correlazione alta √® influenzata in modo sproporzionato da questo punto anomalo.\n\nDataset 4: Qui i dati non mostrano alcuna relazione lineare. La correlazione elevata √® il frutto di un pattern fortemente atipico (ad esempio, una sola coppia di punti allineata).\n\nIl quartetto di Anscombe mette in luce un principio fondamentale: statistiche descrittive come media, deviazione standard e correlazione non sono sempre sufficienti per comprendere la natura dei dati. La visualizzazione grafica √® essenziale per cogliere relazioni, pattern non lineari, outlier e altre caratteristiche che le semplici statistiche non riescono a rivelare. In definitiva, questo esempio dimostra che analizzare i dati soltanto attraverso poche statistiche di sintesi pu√≤ portare a conclusioni fuorvianti, mentre l‚Äôintegrazione con la rappresentazione grafica fornisce una visione pi√π completa e accurata.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#riflessioni-conclusive",
    "href": "chapters/eda/08_correlation.html#riflessioni-conclusive",
    "title": "21¬† Relazioni tra variabili",
    "section": "\n21.8 Riflessioni Conclusive",
    "text": "21.8 Riflessioni Conclusive\nLa covarianza e la correlazione sono strumenti preziosi per capire l‚Äôintensit√† e la direzione lineare di una relazione tra due variabili. Tuttavia, non dobbiamo confondere la loro semplicit√† con completezza d‚Äôinformazione. Una correlazione nulla non implica assenza di relazione, ma solo assenza di una relazione lineare. Inoltre, il paradosso di Simpson e il paradosso di Berkson dimostrano che la semplice osservazione di correlazioni pu√≤ essere fuorviante se non si tiene conto della struttura dei dati o del processo di selezione del campione.\nInfine, esempi come il quartetto di Anscombe sottolineano quanto sia fondamentale accompagnare le statistiche riassuntive con analisi grafiche e un‚Äôattenzione costante ai possibili pattern non lineari, agli outlier e alle caratteristiche peculiari del dataset. Nel prossimo capitolo esamineremo approcci che consentono di avvicinarsi alla comprensione causale dei fenomeni, andando oltre la semplice osservazione dell‚Äôassociazione tra variabili.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#esercizi",
    "href": "chapters/eda/08_correlation.html#esercizi",
    "title": "21¬† Relazioni tra variabili",
    "section": "\n21.9 Esercizi",
    "text": "21.9 Esercizi\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nEsercizi Teorici\n\n\nDefinizioni fondamentali\n\nQual √® la differenza tra associazione, correlazione e dipendenza?\n\nPerch√© la correlazione non implica causalit√†? Fai un esempio.\n\nIn quali situazioni la correlazione di Spearman √® preferibile rispetto alla correlazione di Pearson?\n\n\n\nInterpretazione della correlazione\n\nQual √® il range dei valori che pu√≤ assumere la correlazione di Pearson?\n\nSe il coefficiente di correlazione tra due variabili √® 0.85, come interpreteresti la loro relazione?\n\nSe il coefficiente di correlazione √® -0.60, che tipo di relazione esiste tra le due variabili?\n\nQuali fattori potrebbero influenzare il valore della correlazione?\n\n\n\nCovarianza vs Correlazione\n\nQual √® la differenza tra covarianza e correlazione?\n\nPerch√© la covarianza non √® sempre interpretabile come misura della forza della relazione tra due variabili?\n\nQuali sono i vantaggi di usare la correlazione al posto della covarianza?\n\n\n\nGrafico a dispersione e correlazione\n\nOsservando un grafico a dispersione, quali caratteristiche ti permettono di identificare una relazione lineare positiva o negativa?\n\nDisegna (o descrivi verbalmente) un esempio di un dataset con una correlazione di circa 0, ma con una chiara relazione non lineare tra le variabili.\n\n\n\nEsercizi Pratici in R\nüìå Obiettivo: Analizzare le relazioni tra Satisfaction With Life Scale (SWLS) e Scala della Rete Sociale di Lubben (LSNS-6), calcolare covarianza e correlazione, e visualizzare i dati per individuare pattern.\nDati disponibili:\nUsa i dati raccolti per le variabili SWLS e LSNS, oltre al genere dei partecipanti.\n1. Esplorazione e Visualizzazione della Relazione tra SWLS e LSNS\n\n\nCarica i dati raccolti dagli studenti e verifica la struttura del dataset.\n\n\nCalcola le statistiche descrittive: media, deviazione standard, minimo, massimo e quartili delle variabili SWLS e LSNS.\n\n\nCrea un grafico a dispersione tra SWLS e LSNS:\n\nColora i punti in base al genere del partecipante.\n\nAggiungi una linea di regressione per evidenziare il trend della relazione.\n\n\n\n2. Calcolo della Covarianza e della Correlazione tra SWLS e LSNS\n\n\nCalcola la covarianza tra SWLS e LSNS usando la formula matematica della covarianza e confrontala con il valore ottenuto con cov().\n\n\nCalcola la correlazione di Pearson e commenta il risultato:\n\nLa relazione √® forte o debole?\n\nHa segno positivo o negativo?\n\n√à coerente con quanto osservato nel grafico a dispersione?\n\n\n\n\nCalcola la correlazione di Spearman e confrontala con quella di Pearson. Quale delle due √® pi√π appropriata per questi dati?\n\n3. Analisi delle Associazioni per Gruppi\n\n\nCalcola la correlazione separatamente per i partecipanti di genere maschile e femminile.\n\n\nConfronta i risultati: la relazione tra SWLS e LSNS √® simile nei due gruppi o ci sono differenze?\n\n\nVisualizza i dati con due grafici a dispersione distinti per maschi e femmine.\n\n4. Correlazione Nulla e Pattern Non Lineari\n\n\nSimula un dataset in cui la correlazione di Pearson √® vicina a 0, ma esiste una chiara relazione non lineare tra le variabili.\n\n\nCostruisci un grafico a dispersione per osservare il pattern nei dati.\n\n\nCalcola la correlazione di Spearman e confrontala con quella di Pearson. Quale delle due cattura meglio la relazione nei dati?\n\nConsegna il file .qmd compilato in PDF contenente il codice, le visualizzazioni e le interpretazioni.\n\n\n\n\n\n\n\n\n\nSoluzione\n\n\n\n\n\n1. Definizioni fondamentali\n1.1 Differenza tra associazione, correlazione e dipendenza:\n\n\nAssociazione: Indica una relazione generica tra due variabili, senza specificare la natura o la direzione della relazione.\n\nCorrelazione: Misura la forza e la direzione di una relazione lineare tra due variabili. Pu√≤ essere positiva (variabili aumentano insieme) o negativa (una variabile aumenta mentre l‚Äôaltra diminuisce).\n\nDipendenza: Indica che una variabile √® influenzata da un‚Äôaltra, ma non implica necessariamente una relazione lineare. La dipendenza pu√≤ essere causale o statistica.\n\n1.2 Perch√© la correlazione non implica causalit√†:\nLa correlazione misura solo la relazione lineare tra due variabili, ma non indica se una variabile causa l‚Äôaltra. Un esempio classico √® la correlazione tra il consumo di gelati e il numero di annegamenti: entrambi aumentano in estate, ma non c‚Äô√® un nesso causale diretto. Un terzo fattore (il caldo) influenza entrambe le variabili.\n1.3 Quando preferire la correlazione di Spearman rispetto a quella di Pearson:\n\nQuando i dati non sono distribuiti normalmente.\nQuando ci sono outlier che potrebbero distorcere la correlazione di Pearson.\nQuando la relazione tra le variabili √® monotona (sempre crescente o decrescente) ma non lineare.\n\n2. Interpretazione della correlazione\n2.1 Range dei valori della correlazione di Pearson:\nLa correlazione di Pearson assume valori compresi tra -1 e 1: - 1: Correlazione lineare positiva perfetta. - -1: Correlazione lineare negativa perfetta. - 0: Nessuna correlazione lineare.\n2.2 Interpretazione di un coefficiente di 0.85:\nUn coefficiente di 0.85 indica una forte relazione lineare positiva tra le due variabili. All‚Äôaumentare di una variabile, l‚Äôaltra tende ad aumentare in modo consistente.\n2.3 Interpretazione di un coefficiente di -0.60:\nUn coefficiente di -0.60 indica una relazione lineare negativa moderata. All‚Äôaumentare di una variabile, l‚Äôaltra tende a diminuire.\n2.4 Fattori che influenzano la correlazione:\n\n\nOutlier: Possono distorcere il valore della correlazione.\n\nDistribuzione non lineare: La correlazione di Pearson non cattura relazioni non lineari.\n\nRange ristretto delle variabili: Se i dati coprono solo una piccola parte del range possibile, la correlazione potrebbe essere sottostimata.\n\n3. Covarianza vs Correlazione\n3.1 Differenza tra covarianza e correlazione:\n\n\nCovarianza: Misura la direzione della relazione tra due variabili, ma il suo valore dipende dalle unit√† di misura delle variabili.\n\nCorrelazione: Standardizza la covarianza, rendendola adimensionale e consentendo confronti tra diverse coppie di variabili.\n\n3.2 Perch√© la covarianza non √® sempre interpretabile:\nLa covarianza non √® standardizzata, quindi il suo valore non fornisce informazioni sulla forza della relazione. Ad esempio, una covarianza di 1000 potrebbe indicare una relazione forte o debole, a seconda delle unit√† di misura.\n3.3 Vantaggi della correlazione rispetto alla covarianza:\n\n√à adimensionale, quindi pu√≤ essere confrontata tra diverse coppie di variabili.\nAssume valori compresi tra -1 e 1, facilitando l‚Äôinterpretazione della forza e della direzione della relazione.\n\n4. Grafico a dispersione e correlazione\n4.1 Caratteristiche di un grafico a dispersione per identificare relazioni lineari:\n\n\nRelazione lineare positiva: I punti si dispongono lungo una linea retta con pendenza positiva.\n\nRelazione lineare negativa: I punti si dispongono lungo una linea retta con pendenza negativa.\n\nNessuna relazione lineare: I punti sono sparsi senza un pattern evidente.\n\n4.2 Esempio di dataset con correlazione circa 0 ma relazione non lineare:\nImmagina un dataset in cui una variabile \\(x\\) assume valori simmetrici intorno a 0 (ad esempio, da -5 a 5), e la variabile \\(y\\) √® uguale a \\(x^2\\). In questo caso:\n\nLa correlazione di Pearson sar√† circa 0, perch√© non c‚Äô√® una relazione lineare.\nTuttavia, esiste una chiara relazione non lineare (quadratica) tra \\(x\\) e \\(y\\).\n\nDescrizione verbale:\nI punti formano una parabola, con \\(y\\) che aumenta sia quando \\(x\\) √® positivo che negativo. La correlazione di Pearson non cattura questa relazione, mentre la correlazione di Spearman potrebbe farlo.\n1. Esplorazione e Visualizzazione della Relazione tra SWLS e LSNS\n1.1 Carica i dati raccolti dagli studenti e verifica la struttura del dataset Simuliamo un dataset con 100 partecipanti, includendo le variabili SWLS (Soddisfazione di Vita), LSNS (Rete Sociale), e Genere.\n# Simulazione dei dati\nset.seed(123)\nn &lt;- 100\ngenere &lt;- sample(c(\"Maschio\", \"Femmina\"), n, replace = TRUE)\nswls &lt;- round(rnorm(n, mean = 20, sd = 5), 1)  # SWLS: Scala 5-35\nlsns &lt;- round(rnorm(n, mean = 12, sd = 4), 1)   # LSNS: Scala 0-30\n\n# Creazione del dataset\ndati &lt;- data.frame(Genere = genere, SWLS = swls, LSNS = lsns)\n\n# Verifica della struttura\nstr(dati)\nhead(dati)\n1.2 Calcola le statistiche descrittive\n# Statistiche descrittive per SWLS e LSNS\nsummary(dati$SWLS)\nsummary(dati$LSNS)\n\n# Media e deviazione standard\nmean(dati$SWLS)\nsd(dati$SWLS)\nmean(dati$LSNS)\nsd(dati$LSNS)\n1.3 Crea un grafico a dispersione\nlibrary(ggplot2)\n\nggplot(dati, aes(x = SWLS, y = LSNS, color = Genere)) +\n  geom_point(size = 3) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"black\") +\n  labs(title = \"Relazione tra SWLS e LSNS\",\n       x = \"Soddisfazione di Vita (SWLS)\",\n       y = \"Rete Sociale (LSNS)\") +\n  theme_minimal()\n2. Calcolo della Covarianza e della Correlazione tra SWLS e LSNS\n2.1 Calcola la covarianza\n# Covarianza manuale\ncov_manual &lt;- sum((dati$SWLS - mean(dati$SWLS)) * (dati$LSNS - mean(dati$LSNS))) / (n - 1)\ncov_manual\n\n# Covarianza con funzione R\ncov(dati$SWLS, dati$LSNS)\n2.2 Calcola la correlazione di Pearson\ncor_pearson &lt;- cor(dati$SWLS, dati$LSNS, method = \"pearson\")\ncor_pearson\n\n\nCommento: La correlazione √® [valore], indicando una relazione [forte/debole] e [positiva/negativa]. Questo √® coerente con il grafico a dispersione.\n\n2.3 Calcola la correlazione di Spearman\ncor_spearman &lt;- cor(dati$SWLS, dati$LSNS, method = \"spearman\")\ncor_spearman\n\n\nConfronto: La correlazione di Spearman √® pi√π appropriata se i dati non sono distribuiti normalmente o presentano outlier.\n\n3. Analisi delle Associazioni per Gruppi\n3.1 Calcola la correlazione separatamente per genere\n# Maschi\ncor_maschi &lt;- cor(dati$SWLS[dati$Genere == \"Maschio\"], dati$LSNS[dati$Genere == \"Maschio\"], method = \"pearson\")\n\n# Femmine\ncor_femmine &lt;- cor(dati$SWLS[dati$Genere == \"Femmina\"], dati$LSNS[dati$Genere == \"Femmina\"], method = \"pearson\")\n\ncor_maschi\ncor_femmine\n3.2 Confronta i risultati\n\n\nCommento: La correlazione √® [simile/diversa] tra maschi e femmine, suggerendo [presenza/assenza] di differenze di genere.\n\n3.3 Visualizza i dati con grafici distinti\nggplot(dati, aes(x = SWLS, y = LSNS, color = Genere)) +\n  geom_point(size = 3) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  facet_wrap(~ Genere) +\n  labs(title = \"Relazione tra SWLS e LSNS per Genere\",\n       x = \"Soddisfazione di Vita (SWLS)\",\n       y = \"Rete Sociale (LSNS)\") +\n  theme_minimal()\n4. Correlazione Nulla e Pattern Non Lineari\n4.1 Simula un dataset con correlazione nulla ma relazione non lineare\nset.seed(123)\nx &lt;- rnorm(100, mean = 0, sd = 1)\ny &lt;- x^2 + rnorm(100, mean = 0, sd = 0.5)  # Relazione quadratica\ndati_non_lineari &lt;- data.frame(x = x, y = y)\n\n# Correlazione di Pearson\ncor_pearson_non_lineare &lt;- cor(dati_non_lineari$x, dati_non_lineari$y, method = \"pearson\")\ncor_pearson_non_lineare  # Dovrebbe essere vicina a 0\n4.2 Costruisci un grafico a dispersione\nggplot(dati_non_lineari, aes(x = x, y = y)) +\n  geom_point(size = 3) +\n  labs(title = \"Relazione Non Lineare con Correlazione Nulla\",\n       x = \"Variabile X\",\n       y = \"Variabile Y\") +\n  theme_minimal()\n4.3 Calcola la correlazione di Spearman\ncor_spearman_non_lineare &lt;- cor(dati_non_lineari$x, dati_non_lineari$y, method = \"spearman\")\ncor_spearman_non_lineare  # Dovrebbe catturare la relazione non lineare\n\n\nConfronto: La correlazione di Spearman √® pi√π adatta per catturare relazioni non lineari.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/08_correlation.html#informazioni-sullambiente-di-sviluppo",
    "title": "21¬† Relazioni tra variabili",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.5.3     \n#&gt;  [9] scales_1.3.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] utf8_1.2.4        generics_0.1.3    stringi_1.8.4     lattice_0.22-6   \n#&gt;  [5] hms_1.1.3         digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3   \n#&gt;  [9] grid_4.4.2        timechange_0.3.0  fastmap_1.2.0     Matrix_1.7-3     \n#&gt; [13] R.oo_1.27.0       rprojroot_2.0.4   jsonlite_1.9.1    R.utils_2.13.0   \n#&gt; [17] mgcv_1.9-1        mnormt_2.1.1      cli_3.6.4         rlang_1.1.5      \n#&gt; [21] R.methodsS3_1.8.2 splines_4.4.2     munsell_0.5.1     withr_3.0.2      \n#&gt; [25] tools_4.4.2       parallel_4.4.2    tzdb_0.5.0        colorspace_2.1-1 \n#&gt; [29] pacman_0.5.1      vctrs_0.6.5       R6_2.6.1          lifecycle_1.0.4  \n#&gt; [33] htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.1     gtable_0.3.6     \n#&gt; [37] data.table_1.17.0 glue_1.8.0        xfun_0.51         tidyselect_1.2.1 \n#&gt; [41] rstudioapi_0.17.1 farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-167     \n#&gt; [45] labeling_0.4.3    rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#bibliografia",
    "href": "chapters/eda/08_correlation.html#bibliografia",
    "title": "21¬† Relazioni tra variabili",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAnscombe, F. J. (1973). Graphs in statistical analysis. The American Statistician, 27(1), 17‚Äì21.\n\n\nHamaker, E. (2024). The curious case of the cross-sectional correlation. Multivariate Behavioral Research, 59(6), 1111‚Äì1122.\n\n\nZetsche, U., Buerkner, P.-C., & Renneberg, B. (2019). Future expectations in clinical depression: biased or realistic? Journal of Abnormal Psychology, 128(7), 678‚Äì688.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html",
    "href": "chapters/eda/09_causality.html",
    "title": "[22¬† Causalit√† dai dati osservazionali]{#sec-eda-causalit\\(Y\\) .quarto-section-identifier}",
    "section": "",
    "text": "22.1 Introduzione\nLa pura osservazione dei dati pu√≤ rivelare correlazioni e pattern nei dati, ma senza un‚Äôindagine sulle cause che stanno alla base di tali correlazioni, le conclusioni tratte possono essere fuorvianti o incomplete.\nRichard McElreath, nel suo libro ‚ÄúStatistical Rethinking‚Äù (McElreath, 2020), utilizza l‚Äôanalogia dei Golem - creature potenti ma prive di saggezza - per descrivere un approccio metodologico che √® stato a lungo predominante in psicologia. Questo approccio si basa esclusivamente sull‚Äôanalisi delle associazioni statistiche tra variabili, trascurando considerazioni pi√π profonde sulla causalit√†.\nIl metodo in questione si concentra principalmente sul test delle ipotesi nulle, senza stabilire una chiara connessione tra le domande di ricerca riguardanti le relazioni causali e i test statistici impiegati. Questa disconnessione √® evidente nella figura successiva, tratta da un manuale di analisi dati di impostazione frequentista, che illustra la procedura raccomandata dai sostenitori di questo approccio per descrivere le associazioni tra variabili.\n√à importante notare come tale procedura non fornisca strumenti utili per identificare le effettive cause sottostanti ai fenomeni osservati. Questa limitazione metodologica √® stata identificata come uno dei fattori principali che hanno contribuito alla crisi di replicabilit√† nella ricerca psicologica, come approfondito nel Capitolo 79. L‚Äôapproccio descritto sopra, pur essendo potente nell‚Äôindividuare correlazioni, manca della ‚Äúsaggezza‚Äù necessaria per distinguere tra semplici associazioni e vere relazioni causali, analogamente ai Golem della metafora di McElreath.\nUn problema evidenziato da McElreath (2020) √® che processi causali completamente distinti possono generare la stessa distribuzione di risultati osservati. Pertanto, un approccio focalizzato esclusivamente sull‚Äôanalisi delle associazioni mediante il test dell‚Äôipotesi nulla non √® in grado di distinguere tra questi diversi scenari.\nL‚Äôapproccio frequentista, che si limita a descrivere le associazioni tra le variabili, ha una scarsa capacit√† di rilevare le caratteristiche cruciali dei fenomeni studiati e tende a produrre un alto tasso di falsi positivi (Zwet et al., 2023). √à invece necessario utilizzare una metodologia che non si limiti a confutare ipotesi nulle, ma sia in grado di sviluppare modelli causali che rispondano direttamente alle domande di ricerca. In questo capitolo, ci concentreremo sull‚Äôintroduzione dei concetti fondamentali dell‚Äôanalisi causale.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#introduzione",
    "href": "chapters/eda/09_causality.html#introduzione",
    "title": "[22¬† Causalit√† dai dati osservazionali]{#sec-eda-causalit\\(Y\\) .quarto-section-identifier}",
    "section": "",
    "text": "Esempio di albero decisionale per la selezione di una procedura statistica appropriata. Iniziando dall‚Äôalto, l‚Äôutente risponde a una serie di domande riguardanti la misurazione e l‚Äôintento, arrivando infine al nome di una procedura. Sono possibili molti alberi decisionali simili. (Figura tratta da McElreath (2020)).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#cos√®-la-causalit√†",
    "href": "chapters/eda/09_causality.html#cos√®-la-causalit√†",
    "title": "[22¬† Causalit√† dai dati osservazionali]{#sec-eda-causalit\\(Y\\) .quarto-section-identifier}",
    "section": "22.2 Cos‚Äô√® la causalit√†?",
    "text": "22.2 Cos‚Äô√® la causalit√†?\nHardt & Recht (2022) introducono il concetto di causalit√† distinguendo tra osservazione e azione. Ci√≤ che vediamo nell‚Äôosservazione passiva √® il modo in cui le persone seguono i loro comportamenti abituali, le loro inclinazioni naturali, proiettando lo stato del mondo su un insieme di caratteristiche che abbiamo scelto di evidenziare. Tuttavia, le domande pi√π importanti spesso non riguardano semplici osservazioni.\n\nNon ci basta sapere che le persone che praticano regolarmente attivit√† fisica soffrono meno d‚Äôansia; vogliamo capire se l‚Äôattivit√† fisica riduce effettivamente i livelli d‚Äôansia.\nNon ci accontentiamo di osservare che chi segue una terapia cognitivo-comportamentale (CBT) presenta meno sintomi depressivi; desideriamo verificare se la CBT riduce realmente questi sintomi.\nNon ci limitiamo a constatare che l‚Äôuso frequente dei social media √® associato a un calo del benessere mentale; vogliamo determinare se l‚Äôuso intensivo dei social media causa effettivamente una diminuzione del benessere mentale.\n\nAlla base, il ragionamento causale √® un quadro concettuale per affrontare domande sugli effetti di azioni o interventi ipotetici. Una volta compreso quale sia l‚Äôeffetto di un‚Äôazione, possiamo invertire la domanda e chiederci quale azione plausibile abbia causato un determinato evento.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#effetto-causale",
    "href": "chapters/eda/09_causality.html#effetto-causale",
    "title": "[22¬† Causalit√† dai dati osservazionali]{#sec-eda-causalit\\(Y\\) .quarto-section-identifier}",
    "section": "22.3 Effetto Causale",
    "text": "22.3 Effetto Causale\nLa causalit√† √® un concetto fondamentale in molte discipline, ma non esiste una definizione univoca universalmente accettata. Tuttavia, possiamo adottare una definizione operativa utile per l‚Äôanalisi empirica.\n\nDefinizione 22.1 Diciamo che \\(X\\) causa \\(Y\\) se, intervenendo e modificando il valore di \\(X\\) (il trattamento), la distribuzione di \\(Y\\) cambia di conseguenza.\n\nQuesta definizione enfatizza il ruolo centrale dell‚Äôintervento nel determinare una relazione causale. A differenza della correlazione, che si basa sull‚Äôosservazione passiva, la causalit√† implica un‚Äôazione attiva che modifica il sistema in esame.\n\n22.3.1 Effetto Medio del Trattamento\nSe \\(X\\) √® una variabile binaria, rappresentante la presenza (\\(X=1\\)) o l‚Äôassenza (\\(X=0\\)) del trattamento, l‚Äôeffetto dell‚Äôintervento √® misurato tramite l‚Äôeffetto medio del trattamento (Average Treatment Effect, ATE):\n\\[ ATE = \\mathbb{E}[Y \\mid X=1] - \\mathbb{E}[Y \\mid X=0] .\\]\nQuesto valore rappresenta quanto, in media, il trattamento modifica l‚Äôattesa di \\(Y\\). √à essenziale notare che gli effetti causali sono definiti a livello di popolazione e possono variare tra individui o gruppi, dando origine a effetti di trattamento eterogenei.\n\n\n22.3.2 Esempio: Terapia Cognitivo-Comportamentale e Ansia\nConsideriamo un esempio concreto: supponiamo di voler studiare l‚Äôefficacia della terapia cognitivo-comportamentale (CBT) nella riduzione dell‚Äôansia. Se un gruppo di persone ansiose non riceve alcun trattamento, il loro livello d‚Äôansia rimarr√† invariato in media. Se invece interveniamo introducendo la CBT (modificando \\(X\\) da 0 a 1), il livello medio d‚Äôansia nel gruppo tender√† a diminuire (modificando cos√¨ la distribuzione di \\(Y\\)).\nQuesto esempio chiarisce la distinzione tra correlazione e causalit√†:\n\nSe osserviamo che le persone che fanno CBT hanno meno ansia, potremmo erroneamente concludere che la CBT √® efficace. Tuttavia, la riduzione dell‚Äôansia potrebbe essere dovuta a fattori confondenti, come la maggiore motivazione delle persone che scelgono la terapia.\nSolo un intervento controllato (ad esempio, un esperimento randomizzato in cui √® presente un gruppo di controllo) permette di stabilire con certezza l‚Äôeffetto causale della CBT.\n\n\n\n22.3.3 Causalit√† Diretta e Indiretta\nIn alcuni casi, un effetto causale pu√≤ non essere diretto, ma manifestarsi attraverso un meccanismo intermedio. Ad esempio, l‚Äôautoefficacia potrebbe non influenzare direttamente le prestazioni accademiche, ma se un intervento aumenta l‚Äôautoefficacia, potremmo osservare un miglioramento nell‚Äôimpegno allo studio, che a sua volta porta a migliori prestazioni. In questo caso, possiamo dire che l‚Äôautoefficacia ha un effetto causale indiretto sulle prestazioni accademiche.\n\n\n22.3.4 Causalit√† Probabilistica\n√à importante sottolineare che una relazione causale tra \\(X\\) e \\(Y\\) non implica necessariamente che ogni cambiamento in \\(X\\) porti a un cambiamento immediato o deterministico in \\(Y\\). In molti contesti, specialmente in psicologia, le relazioni causali sono probabilistiche: l‚Äôintervento su \\(X\\) altera la distribuzione di probabilit√† di \\(Y\\), senza garantire un esito certo per ogni individuo. Questo approccio probabilistico √® cruciale per comprendere le dinamiche causali in sistemi complessi e multifattoriali.\nIn sintesi, l‚Äôanalisi causale √® uno strumento essenziale per la ricerca empirica, permettendo di andare oltre la semplice correlazione e comprendere i meccanismi che regolano i fenomeni osservati. La chiave per stabilire una relazione causale solida risiede nella progettazione di esperimenti o nell‚Äôuso di metodi statistici avanzati per identificare e correggere i possibili bias derivanti da fattori confondenti.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#i-limiti-dellosservazione",
    "href": "chapters/eda/09_causality.html#i-limiti-dellosservazione",
    "title": "[22¬† Causalit√† dai dati osservazionali]{#sec-eda-causalit\\(Y\\) .quarto-section-identifier}",
    "section": "22.4 I Limiti dell‚ÄôOsservazione",
    "text": "22.4 I Limiti dell‚ÄôOsservazione\nPer comprendere i limiti dell‚Äôosservazione passiva e la necessit√† di indagare le relazioni causali sottostanti, Hardt & Recht (2022) citano il celebre esempio delle ammissioni ai corsi di laurea dell‚ÄôUniversit√† della California, Berkeley, nel 1973. In quell‚Äôanno, 12,763 candidati furono considerati per l‚Äôammissione in uno dei 101 dipartimenti o major interdipartimentali. Di questi, 4,321 erano donne e 8,442 erano uomini. I dati aggregati mostrano che circa il 35% delle donne fu ammesso, rispetto al 44% degli uomini. Test statistici indicano che questa differenza non √® attribuibile al caso, suggerendo una disparit√† nei tassi di ammissione tra i generi.\nUn‚Äôanalisi simile si osserva considerando le decisioni aggregate di ammissione nei sei principali dipartimenti di UC Berkeley. Il tasso di ammissione complessivo per gli uomini era del 44%, mentre per le donne solo del 30%, una differenza statisticamente credibile.\nTuttavia, poich√© ogni dipartimento ha autonomia nelle decisioni di ammissione, √® utile esaminare il possibile bias di genere a livello di singolo dipartimento (dati disaggregati).\n\n22.4.1 Analisi dei Dati Disaggregati\nUomini\n\n\n\nDipartimento\nCandidati\nAmmessi (%)\n\n\n\n\nA\n825\n62\n\n\nB\n520\n60\n\n\nC\n325\n37\n\n\nD\n417\n33\n\n\nE\n191\n28\n\n\nF\n373\n6\n\n\n\nDonne\n\n\n\nDipartimento\nCandidati\nAmmessi (%)\n\n\n\n\nA\n108\n82\n\n\nB\n25\n68\n\n\nC\n593\n34\n\n\nD\n375\n35\n\n\nE\n393\n24\n\n\nF\n341\n7\n\n\n\nDall‚Äôanalisi dei dati disaggregati emerge che, tra i sei dipartimenti pi√π grandi, quattro presentano un tasso di ammissione pi√π alto per le donne, mentre due favoriscono gli uomini. Tuttavia, questi due dipartimenti da soli non possono spiegare la grande differenza nei tassi di ammissione osservata nei dati aggregati. Questo suggerisce che la tendenza generale di un tasso di ammissione pi√π alto per gli uomini si inverte quando si analizzano i dati suddivisi per dipartimento.\n\n\n22.4.2 La Vera Ragione della Differenza nei Tassi di Ammissione\nL‚Äôanalisi di questi dati suggerisce che l‚Äôapparente svantaggio per le donne non derivava da una discriminazione diretta nei criteri di selezione, ma piuttosto da una scelta differente dei corsi di studio. In generale, le donne tendevano a candidarsi per dipartimenti con un numero elevato di concorrenti e tassi di ammissione pi√π bassi (come lettere o psicologia), mentre gli uomini erano pi√π propensi a fare domanda per dipartimenti con tassi di accettazione pi√π alti (come ingegneria o fisica).\nQuesta dinamica riflette differenze sistemiche e strutturali nei percorsi educativi e professionali, pi√π che una discriminazione esplicita nei criteri di ammissione. Lo studio originale evidenzia che le donne erano spesso indirizzate, fin dalla scuola, verso campi di studio con meno finanziamenti, prospettive di carriera pi√π limitate e tassi di completamento inferiori.\nLa vera forma di discriminazione, dunque, non risiedeva nelle politiche di ammissione di UC Berkeley, ma in una cultura che alimentava aspettative diverse in base al genere, influenzando le scelte accademiche e professionali delle donne sin dall‚Äôinfanzia.\n\n\n22.4.3 Perch√© il Paradosso di Simpson Inganna?\nIl paradosso di Simpson (che si manifesta nei dati sulle ammissioni ai corsi di laurea dell‚ÄôUniversit√† della California, Berkeley, nel 1973) mette in luce un errore comune: assumere che una tendenza osservata nei dati aggregati sia necessariamente valida a livello di sottogruppi. L‚Äôintuizione ci porta a credere che, se nel complesso le donne hanno un tasso di ammissione pi√π basso, questo debba essere vero anche per ciascun dipartimento. In realt√†, il paradosso dimostra che le statistiche aggregate possono essere fuorvianti se non si tiene conto della distribuzione interna dei dati.\nQuesto caso ci ricorda anche l‚Äôimportanza di distinguere tra correlazione e causalit√†. Osservare un dato (meno donne ammesse) non implica automaticamente una causa (discriminazione diretta). Solo un‚Äôanalisi pi√π approfondita, che consideri le scelte individuali e le strutture socio-culturali di riferimento, pu√≤ portare a conclusioni pi√π accurate.\nIn sintesi, i dati delle ammissioni a UC Berkeley non dimostrano necessariamente una discriminazione di genere diretta, ma sollevano questioni pi√π ampie sulle differenze nei percorsi accademici di uomini e donne. Per comprendere realmente il fenomeno, servirebbero studi pi√π approfonditi, capaci di analizzare le cause profonde di queste scelte educative. L‚Äôinferenza causale √® uno strumento fondamentale in questo processo, poich√© permette non solo di selezionare le variabili chiave da analizzare, ma anche di formulare spiegazioni pi√π solide e plausibili.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#come-scoprire-le-relazioni-causali",
    "href": "chapters/eda/09_causality.html#come-scoprire-le-relazioni-causali",
    "title": "[22¬† Causalit√† dai dati osservazionali]{#sec-eda-causalit\\(Y\\) .quarto-section-identifier}",
    "section": "22.5 Come Scoprire le Relazioni Causali?",
    "text": "22.5 Come Scoprire le Relazioni Causali?\nIl metodo pi√π rigoroso per identificare relazioni causali √® rappresentato dagli studi randomizzati controllati (RCT, Randomized Controlled Trials). La randomizzazione, ovvero l‚Äôassegnazione casuale dei partecipanti ai gruppi di trattamento e controllo, assicura che l‚Äôinfluenza di eventuali variabili confondenti sia equamente distribuita tra i gruppi. Di conseguenza, se dopo l‚Äôintervento si osserva una differenza sistematica tra i gruppi, questa pu√≤ essere attribuita con elevata probabilit√† all‚Äôeffetto del trattamento, poich√© tutte le altre fonti di variazione sono state bilanciate grazie alla randomizzazione.\nGli RCT sono considerati il gold standard per l‚Äôinferenza causale, ma presentano alcuni limiti. In molti casi, l‚Äôimplementazione di un esperimento controllato √® impossibile per vincoli etici o pratici. Ad esempio, non si pu√≤ randomizzare l‚Äôesposizione a fattori di rischio nocivi o imporre determinate condizioni di vita ai partecipanti. Inoltre, le condizioni sperimentali sono spesso artificiali, il che pone un problema di validit√† esterna: i risultati ottenuti in un contesto controllato potrebbero non generalizzarsi a contesti reali.\nQuando gli RCT non sono praticabili, i ricercatori ricorrono a disegni osservazionali, che offrono maggiore flessibilit√† e adattabilit√† ai contesti naturali. Tuttavia, il principale limite di questi studi √® la difficolt√† nell‚Äôidentificazione causale, poich√© l‚Äôassenza di randomizzazione espone i risultati al rischio di bias da confondimento. Per affrontare questa sfida, vengono adottate tecniche statistiche avanzate che permettono di avvicinarsi a stime causali pi√π affidabili.\n\n22.5.1 Variabili Confondenti\nLe variabili confondenti rappresentano uno degli ostacoli principali nell‚Äôanalisi causale. Una variabile confondente √® un fattore che influenza sia la variabile indipendente (\\(X\\)) sia la variabile dipendente (\\(Y\\)), generando un‚Äôassociazione spuria tra le due. In altre parole, la relazione osservata tra \\(X\\) e \\(Y\\) potrebbe non riflettere un nesso causale diretto, ma essere il risultato dell‚Äôinfluenza esercitata da una terza variabile.\nNegli studi osservazionali, se le variabili confondenti non vengono adeguatamente identificate e controllate, possono introdurre bias nelle stime degli effetti, portando a conclusioni errate. In assenza di un disegno sperimentale controllato, ci√≤ che si osserva nei dati potrebbe non corrispondere a ci√≤ che accadrebbe se si potesse manipolare direttamente \\(X\\) in un esperimento randomizzato.\n\n\n22.5.2 Approcci per il Controllo delle Variabili Confondenti\nPer stabilire relazioni causali affidabili, √® fondamentale distinguere gli effetti della variabile indipendente (\\(X\\)) da quelli delle variabili confondenti (\\(Z\\)), che potrebbero generare associazioni spurie. Se le variabili confondenti non vengono adeguatamente controllate, possono introdurre bias nelle stime degli effetti e compromettere la validit√† delle conclusioni tratte dai dati osservazionali. Esistono due approcci principali per affrontare questo problema:\n\nControllo sperimentale: Questo metodo viene implementato attraverso il disegno dello studio e si basa sulla randomizzazione, che assicura una distribuzione casuale delle variabili confondenti tra il gruppo di trattamento e il gruppo di controllo. In questo modo, ogni differenza osservata tra i gruppi dopo il trattamento pu√≤ essere attribuita con maggiore certezza all‚Äôintervento, poich√© tutte le altre fonti di variazione sono bilanciate in media.\nControllo statistico: Quando la randomizzazione non √® possibile, √® necessario applicare tecniche statistiche per correggere il bias da confondimento. Questo approccio mira a stimare l‚Äôeffetto causale di \\(X\\) su \\(Y\\) eliminando l‚Äôinfluenza di eventuali variabili confondenti attraverso modelli appropriati.\n\n\n22.5.2.1 Controllo Statistico e le sue Sfide\nUno dei metodi pi√π comuni per il controllo statistico delle variabili confondenti √® il condizionamento su \\(Z\\). Questo implica stimare l‚Äôeffetto di \\(X\\) su \\(Y\\) all‚Äôinterno di ciascun livello della variabile confondente \\(Z\\), per poi calcolare una media ponderata dell‚Äôeffetto su tutta la popolazione. Tuttavia, questo approccio presenta due sfide fondamentali:\n\nIdentificazione delle variabili confondenti: √à necessario conoscere e includere tutte le possibili variabili confondenti nel modello. Tuttavia, alcune potrebbero essere sconosciute o latenti, rendendo incompleto il controllo del confondimento.\nAccuratezza della misurazione: Anche quando le variabili confondenti sono note, la loro misurazione potrebbe essere imprecisa o soggetta a errori, compromettendo la validit√† dell‚Äôanalisi e introducendo ulteriore bias.\n\nPer ovviare a questi problemi, vengono impiegate tecniche avanzate di controllo statistico, come:\n\nRegressione multipla: Include le variabili confondenti come covariate in un modello di regressione per stimare l‚Äôeffetto netto di \\(X\\) su \\(Y\\).\nPropensity Score Matching (PSM): Confronta individui con caratteristiche simili nei gruppi di trattamento e controllo, riducendo il bias da confondimento.\nStratificazione: Suddivide il campione in sottogruppi omogenei rispetto alle variabili confondenti e stima l‚Äôeffetto del trattamento all‚Äôinterno di ciascun sottogruppo.\n\n\n\n22.5.2.2 Inferenza Causale nei Dati Osservazionali\nL‚Äôassenza di randomizzazione negli studi osservazionali ha portato alla famosa affermazione ‚Äúla correlazione non implica causalit√†‚Äù. Tuttavia, questo non significa che l‚Äôinferenza causale sia impossibile senza esperimenti controllati. Esistono metodi statistici che permettono di affrontare il problema del confondimento e avvicinarsi a stime causali pi√π affidabili. Tra questi:\n\nGrafi Aciclici Diretti (DAG): Strumenti grafici che rappresentano le relazioni causali tra variabili e aiutano a identificare le variabili confondenti che devono essere controllate.\nModelli Causali Strutturali (SCM): Formalismi matematici che descrivono le relazioni causali e stabiliscono le condizioni necessarie per l‚Äôidentificazione degli effetti.\nDifferenze-differenze (DiD): Metodo che confronta l‚Äôevoluzione di \\(Y\\) prima e dopo il trattamento in gruppi esposti e non esposti, controllando per le tendenze temporali comuni.\nVariabili strumentali (IV): Tecnica che utilizza una variabile esogena correlata con \\(X\\) ma non direttamente con \\(Y\\), per isolare la parte di variazione di \\(X\\) non influenzata da confondenti.\nRegressione discontinua (RD): Metodo che sfrutta soglie arbitrarie per identificare effetti causali in situazioni quasi-sperimentali.\n\nIn sintesi, le variabili confondenti rappresentano una delle principali sfide nell‚Äôinferenza causale da dati osservazionali. Tuttavia, lo sviluppo di tecniche avanzate di analisi causale consente di ridurre il rischio di bias e migliorare l‚Äôaffidabilit√† delle stime. Sebbene nessun metodo osservazionale possa replicare perfettamente i benefici della randomizzazione, l‚Äôutilizzo di strumenti come DAG, SCM e tecniche di identificazione causale permette di ottenere risultati pi√π solidi e interpretabili. L‚Äôadozione di questi approcci √® fondamentale per garantire che le conclusioni tratte dai dati osservazionali siano quanto pi√π possibile accurate e prive di distorsioni.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#modelli-causali-strutturali",
    "href": "chapters/eda/09_causality.html#modelli-causali-strutturali",
    "title": "[22¬† Causalit√† dai dati osservazionali]{#sec-eda-causalit\\(Y\\) .quarto-section-identifier}",
    "section": "22.6 Modelli Causali Strutturali",
    "text": "22.6 Modelli Causali Strutturali\nI modelli causali strutturali (Structural Causal Models, SCM) sono strumenti fondamentali per l‚Äôinferenza causale nei dati osservazionali. Essi permettono di rappresentare il processo generativo sottostante a un fenomeno e di prevedere gli effetti di un intervento. Oltre a descrivere le relazioni causali tra variabili, gli SCM consentono di esplorare scenari controfattuali, ovvero ipotetiche alternative a ci√≤ che √® stato osservato, offrendo un quadro formale per rispondere a domande del tipo cosa sarebbe successo se‚Ä¶?\n\n22.6.1 Struttura di un Modello Causale Strutturale\nUn SCM √® definito da un insieme di equazioni strutturali che descrivono come ciascuna variabile dipende causalmente dalle altre. Il modello √® composto da:\n\nVariabili esogene: Fonti di variazione esterne al sistema modellato, che non dipendono da nessuna altra variabile del modello.\nVariabili endogene: Determinate dalle equazioni del modello e influenzate da altre variabili all‚Äôinterno dello stesso.\nRelazioni causali esplicite: Specificate attraverso funzioni matematiche che descrivono i meccanismi di generazione dei dati.\n\nIl processo di costruzione di un SCM segue una logica ben definita: si parte dalle variabili esogene e, attraverso una serie di assegnazioni, si generano le variabili endogene, costruendo progressivamente una distribuzione congiunta delle variabili osservate.\n\n\n22.6.2 Vantaggi degli SCM\nUno degli aspetti distintivi degli SCM √® la loro duplice funzione:\n\nDescrivono il processo generativo dei dati, rendendo esplicite le ipotesi sui meccanismi causali.\nInducono una distribuzione probabilistica congiunta, consentendo l‚Äôanalisi sia delle relazioni statistiche tra le variabili sia delle connessioni causali sottostanti.\n\nQuesta struttura consente di superare i limiti dei modelli puramente correlazionali, offrendo un framework solido per distinguere tra causalit√† e semplice associazione.\n\n\n22.6.3 Rappresentazione Grafica: DAG\nGli SCM sono spesso rappresentati graficamente tramite Grafi Aciclici Diretti (Directed Acyclic Graphs, DAG). Un DAG √® una rete di nodi (variabili) e archi direzionati che indicano relazioni causali. Questa rappresentazione:\n\nfacilita l‚Äôindividuazione delle variabili confondenti e dei percorsi di causalit√† indiretti;\naiuta a identificare strategie per il controllo del confondimento, come il criterio di separazione (d-separation);\npermette di determinare se un effetto causale √® identificabile o se √® necessario raccogliere dati aggiuntivi.\n\nIn sintesi, gli SCM rappresentano un‚Äôevoluzione rispetto ai modelli statistici tradizionali, poich√© incorporano esplicitamente informazioni sulle relazioni causali. L‚Äôuso combinato di equazioni strutturali e rappresentazioni grafiche tramite DAG consente di affrontare problemi di confondimento, identificare effetti causali e analizzare scenari controfattuali con maggiore rigore rispetto a modelli puramente correlazionali.\nL‚Äôadozione di SCM √® particolarmente utile nei dati osservazionali, dove la mancanza di randomizzazione rende necessaria una modellazione esplicita delle relazioni causali per ottenere inferenze affidabili.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#bias-da-variabile-omessa",
    "href": "chapters/eda/09_causality.html#bias-da-variabile-omessa",
    "title": "[22¬† Causalit√† dai dati osservazionali]{#sec-eda-causalit\\(Y\\) .quarto-section-identifier}",
    "section": "22.7 Bias da Variabile Omessa",
    "text": "22.7 Bias da Variabile Omessa\nL‚Äôomissione di variabili confondenti rappresenta una delle principali fonti di distorsione nelle stime statistiche. Il bias da variabile omessa [Omitted Variable Bias, OVB; Wilms et al. (2021)] si verifica quando una variabile confondente, nota ma non misurata, o sconosciuta, viene esclusa dall‚Äôanalisi, alterando la stima dell‚Äôeffetto causale. Come evidenziato da Byrnes & Dee (2024), l‚ÄôOVB pu√≤ portare a stime distorte della magnitudine degli effetti, inversioni del segno delle stime, correlazioni spurie e al mascheramento di reali relazioni causali.\nUn‚Äôillustrazione di questa problematica √® mostrata nella Figura¬†22.1, che rappresenta tre scenari diversi in cui una variabile non osservata (\\(U\\)) pu√≤ influenzare un modello causale:\n\nPannello di sinistra: La variabile non osservata \\(U\\) non √® correlata con la variabile indipendente \\(X\\), quindi la sua omissione non introduce bias nella stima dell‚Äôeffetto di \\(X\\) su \\(Y\\), ma pu√≤ ridurre la precisione del modello aumentando l‚Äôerrore standard della stima.\nPannello centrale: La variabile non osservata \\(U\\) √® una variabile confondente, poich√© influenza sia \\(X\\) che \\(Y\\). La sua omissione causa bias nella stima dell‚Äôeffetto di \\(X\\) su \\(Y\\), alterando le conclusioni causali.\nPannello di destra: \\(U\\) e \\(X\\) sono entrambi influenzati da un fattore comune \\(Z\\), generando un confondimento indiretto. In questo caso, omettere \\(U\\) introduce distorsione nella stima dell‚Äôeffetto di \\(X\\) su \\(Y\\).\n\n\n\n\n\n\n\nFigura¬†22.1: La figura mostra come l‚Äôomissione di una variabile confondente possa o meno introdurre bias nella stima dell‚Äôeffetto di \\(X\\) su \\(Y\\). Nel pannello di sinistra, \\(X\\) e \\(U\\) sono indipendenti, quindi la mancata inclusione di \\(U\\) non altera la stima dell‚Äôeffetto di \\(X\\) su \\(Y\\), ma riduce la precisione del modello. Nel pannello centrale, \\(U\\) influenza sia \\(X\\) che \\(Y\\), generando un bias da variabile omessa. Nel pannello di destra, \\(X\\) e \\(U\\) sono correlati tramite un fattore comune \\(Z\\), creando un confondimento indiretto. In entrambi questi ultimi casi, il controllo delle variabili confondenti √® essenziale per effettuare inferenze causali affidabili. La figura √® ispirata da Byrnes & Dee (2024).\n\n\n\n\n22.7.1 Superare il Bias da Variabile Omessa con gli SCM\nAffrontare il bias da variabile omessa √® una delle sfide principali nell‚Äôinferenza causale dai dati osservazionali. A differenza dell‚Äôerrore di misurazione nelle variabili predittive, che tende a ridurre l‚Äôampiezza delle stime senza necessariamente invertirne il segno (McElreath, 2020; Schennach, 2016), il bias da variabile omessa pu√≤ alterare in modo imprevedibile le stime, rendendole fuorvianti.\nNonostante queste difficolt√†, i dati osservazionali possono comunque essere utilizzati per l‚Äôinferenza causale, a condizione che vengano applicate strategie adeguate. L‚Äôadozione dei modelli causali strutturali (SCM) consente di esplicitare il meccanismo generativo sottostante ai dati, permettendo di modellare le relazioni tra variabili e di controllare il confondimento in modo pi√π rigoroso.\n\n\n22.7.2 Il Ruolo della Modellazione Esplicita\nL‚Äôuso degli SCM non elimina del tutto il problema delle variabili omesse, ma offre un quadro concettuale per affrontarlo. Questo approccio ha due vantaggi principali:\n\nEsplicitazione del modello generativo: Un SCM rende trasparente la struttura causale ipotizzata e permette di individuare le variabili mancanti che potrebbero influenzare le stime.\nPossibilit√† di affinamento progressivo: Ogni nuova evidenza empirica pu√≤ essere utilizzata per migliorare il modello, testando ipotesi alternative e perfezionando la comprensione dei meccanismi causali sottostanti.\n\nIn sintesi, l‚Äôinferenza causale non pu√≤ basarsi esclusivamente su correlazioni osservate tra variabili, poich√© il confondimento dovuto a variabili omesse pu√≤ distorcere le stime. L‚Äôutilizzo di modelli causali strutturali, supportati dall‚Äôanalisi tramite DAG, consente di ridurre questi problemi e di formulare inferenze pi√π affidabili. Sebbene nessun modello possa garantire conclusioni definitive, la costruzione di un quadro causale esplicito favorisce il progresso scientifico, permettendo di testare, correggere e affinare le ipotesi sui meccanismi che regolano i fenomeni psicologici.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#grafi-aciclici-diretti",
    "href": "chapters/eda/09_causality.html#grafi-aciclici-diretti",
    "title": "[22¬† Causalit√† dai dati osservazionali]{#sec-eda-causalit\\(Y\\) .quarto-section-identifier}",
    "section": "22.8 Grafi Aciclici Diretti",
    "text": "22.8 Grafi Aciclici Diretti\nI Grafi Aciclici Diretti (Directed Acyclic Graphs, DAG) sono strumenti fondamentali per rappresentare e analizzare relazioni causali. Offrono una rappresentazione visiva chiara delle ipotesi sui meccanismi causali e aiutano a identificare le variabili confondenti da controllare per ottenere stime causali affidabili.\nUn DAG √® un grafo in cui:\n\ni nodi rappresentano le variabili coinvolte nel fenomeno studiato;\nle frecce direzionate tra i nodi indicano relazioni causali;\nil grafo √® aciclico, il che significa che non si possono formare cicli: non esiste un percorso chiuso che permetta di tornare a un nodo di partenza seguendo le frecce.\n\n\n22.8.1 Terminologia nei DAG\n\nUn nodo \\(X\\) con una freccia diretta verso un altro nodo \\(Y\\) indica che \\(X\\) causa \\(Y\\).\nIl nodo che origina una freccia √® detto genitore, mentre quello di destinazione √® detto figlio.\nSe esiste un percorso tra un nodo \\(A\\) e un nodo \\(B\\), \\(A\\) √® detto antenato di \\(B\\), e \\(B\\) √® un discendente di \\(A\\).\n\nQuesta struttura permette di distinguere tra cause dirette e indirette: una causa diretta √® un nodo genitore, mentre una causa indiretta √® un qualsiasi antenato lungo un percorso nel grafo.\nI DAG sono particolarmente utili per l‚Äôidentificazione delle variabili confondenti e per stabilire quali variabili devono essere controllate per ottenere inferenze causali non distorte.\n\n\n22.8.2 La d-separazione\nLa d-separazione √® una regola che ci permette di capire se due variabili in un DAG sono indipendenti una volta che si √® controllato per un insieme di altre variabili. In termini semplici, ci aiuta a rispondere alla domanda: possiamo dire che due variabili non sono collegate dopo aver considerato certe informazioni?\nImmaginiamo un DAG come un sistema di percorsi attraverso cui scorre l‚Äôinformazione. Se due variabili sono collegate da un percorso aperto, significa che possono influenzarsi a vicenda, direttamente o indirettamente. Se invece il percorso √® bloccato, l‚Äôinformazione non pu√≤ passare e possiamo considerarle indipendenti. La d-separazione ci indica quando un percorso √® aperto e quando √® bloccato.\nPer determinare se due variabili sono indipendenti, si deve controllare il percorso che le collega nel DAG e verificare se ci sono ostacoli che ne impediscono il flusso informativo. Un percorso pu√≤ essere bloccato in tre modi principali:\n\nCatena (\\(X\\) ‚Üí \\(Z\\) ‚Üí \\(Y\\)): Il nodo intermedio (\\(Z\\)) √® un mediatore. Se si controlla per \\(Z\\), il flusso di informazioni tra \\(X\\) e \\(Y\\) viene interrotto, rendendole indipendenti.\nFork (\\(X\\) ‚Üê \\(Z\\) ‚Üí \\(Y\\)): \\(Z\\) √® una causa comune di \\(X\\) e \\(Y\\). Se si controlla per \\(Z\\), si elimina la correlazione spuria tra \\(X\\) e \\(Y\\), bloccando il percorso.\nCollider (\\(X\\) ‚Üí \\(Z\\) ‚Üê \\(Y\\)): \\(Z\\) √® un effetto comune di \\(X\\) e \\(Y\\). Se non si controlla per \\(Z\\), il percorso √® gi√† bloccato e \\(X\\) e \\(Y\\) sono indipendenti. Attenzione! Controllare per \\(Z\\) (o per una sua conseguenza) apre il percorso e introduce una correlazione spuria tra \\(X\\) e \\(Y\\).\n\nLa d-separazione √® cruciale perch√© ci permette di leggere direttamente dal DAG quali variabili dobbiamo controllare per ottenere inferenze causali affidabili, senza dover fare complessi calcoli probabilistici.\n\n\n22.8.3 Il Criterio del Back-Door e la d-separazione\nIl criterio del back-door √® strettamente legato alla d-separazione e serve a identificare un insieme di variabili da controllare per ottenere una stima non distorta dell‚Äôeffetto causale di \\(X\\) su \\(Y\\).\nUn back-door path √® un percorso tra \\(X\\) e \\(Y\\) che inizia con una freccia entrante in \\(X\\). Questo tipo di percorso rappresenta una fonte di confondimento che deve essere bloccata per stimare correttamente l‚Äôeffetto causale di \\(X\\) su \\(Y\\).\n\n22.8.3.1 Come bloccare i percorsi back-door\n\nSe il percorso contiene una catena (\\(X\\) ‚Üê \\(A\\) ‚Üí \\(B\\) ‚Üí \\(Y\\)), si blocca condizionando su una delle variabili intermedie (\\(A\\) o \\(B\\)).\nSe il percorso contiene un collider (\\(X\\) ‚Üí \\(Z\\) ‚Üê \\(Y\\)), il percorso √® gi√† bloccato e non bisogna condizionare su \\(Z\\).\nSe il percorso contiene un fork (\\(X\\) ‚Üê \\(Z\\) ‚Üí \\(Y\\)), il percorso si blocca condizionando su \\(Z\\).\n\n\n\n\n22.8.4 Relazione tra d-separazione e il criterio del back-door\nLa d-separazione ci permette di determinare se esiste un percorso aperto tra \\(X\\) e \\(Y\\). Se vogliamo stimare un effetto causale, dobbiamo assicurarci che tra \\(X\\) e \\(Y\\) esista solo il percorso causale diretto e che tutti gli altri percorsi (in particolare i back-door paths) siano bloccati.\nQuindi:\n\nse due variabili risultano d-separate dopo aver condizionato su un insieme di variabili di controllo, significa che ogni percorso non causale tra di esse √® stato bloccato, permettendo un‚Äôinterpretazione causale dell‚Äôeffetto stimato;\nse invece esistono percorsi back-door non bloccati, la stima dell‚Äôeffetto causale sar√† distorta a causa della presenza di confondimento.\n\nIn sintesi, l‚Äôuso dei DAG consente di visualizzare in modo chiaro le relazioni causali tra le variabili e di determinare quali percorsi devono essere chiusi per ottenere inferenze non distorte. Strumenti come la d-separazione e il criterio del back-door permettono di evitare errori comuni nell‚Äôanalisi causale e di migliorare la validit√† delle stime statistiche. L‚Äôadozione di questi metodi √® essenziale per garantire che le conclusioni tratte dai dati osservazionali siano affidabili e prive di bias.\n\n\n22.8.5 Applicazioni\nConsideriamo la struttura causale illustrata nella Figura¬†22.1, pannello centrale. Dopo aver costruito un DAG come descritto nella sezione precedente, possiamo identificare le possibili fonti di bias da variabili omesse, incluse quelle non misurate (ad esempio, \\(U\\)). Se una variabile confondente non viene inclusa nell‚Äôanalisi, si apre un back-door path, permettendo alla variazione confondente di influenzare la relazione tra la variabile causale e la variabile di risposta attraverso un percorso non controllato (Pearl, 2009).\nIn altre parole, omettere una variabile confondente come \\(U\\) nella Figura¬†22.1 (pannello centrale) implica che la sua influenza venga incorporata nel termine di errore del modello statistico, insieme ad altre fonti di errore casuali. Questo pu√≤ distorcere la stima dell‚Äôeffetto causale di \\(X\\) su \\(Y\\).\nLa Figura¬†22.2 illustra le conseguenze di un confondente \\(U\\) che ha un effetto positivo su \\(X\\) ma un effetto negativo su \\(Y\\):\n\nSe controlliamo per \\(U\\), come mostrato nella Figura¬†22.2 (Bi), l‚Äôeffetto stimato di \\(X\\) su \\(Y\\) riflette la relazione causale effettiva.\nSe non controlliamo per \\(U\\), come mostrato nella Figura¬†22.2 (Bii), \\(U\\) viene inglobato nel termine di errore, creando una correlazione spuriosa tra l‚Äôerrore e \\(X\\) (Figura¬†22.2, Biii). Questo induce una stima distorta dell‚Äôeffetto di \\(X\\) su \\(Y\\), evidenziata in blu.\n\nL‚Äôomissione di una variabile indipendente che √® correlata con altre variabili indipendenti nel modello e che ha un effetto diretto su \\(Y\\) costituisce un errore di specificazione. Nei modelli lineari, questa omissione viola un‚Äôipotesi fondamentale del teorema di Gauss-Markov, secondo cui il termine di errore deve essere incorrelato con le variabili esplicative. Di conseguenza, la stima dell‚Äôeffetto causale di \\(X\\) su \\(Y\\) risulta distorta, compromettendo l‚Äôaffidabilit√† dell‚Äôanalisi.\n\n\n\n\n\n\nFigura¬†22.2: Una visualizzazione del bias da variabile omessa e delle conseguenze per l‚Äôinferenza causale. (A) mostra un DAG di un sistema in cui \\(X\\) ha un effetto positivo su \\(Y\\), e una variabile confondente U ha un effetto positivo su \\(Y\\) ma un effetto negativo su \\(X\\). Le variabili non osservate (cio√® non misurate) sono rappresentate in ellissi, come la variabile U e il termine di errore e nel pannello B. (B) illustra diverse stime del DAG in (A) utilizzando un‚Äôanalisi del percorso. Vedi Bo\\(X\\) 1 per una breve spiegazione delle principali differenze tra DAG e diagrammi dei percorsi. Presumiamo che U non sia misurata. In (Bi), presumiamo di poter misurare e controllare U, rappresentata dalla freccia a doppia testa tra U e \\(X\\), che rappresenta la correlazione tra le due variabili considerata dal modello. La variabile non misurata e √® la fonte residua di variazione che si presume non sia correlata con nessun predittore. La freccia rossa rappresenta il percorso stimato. Al contrario, (Bii) e (Biii) rappresentano la realt√†, dove non abbiamo una misurazione di U e non la controlliamo nel modello dei percorsi. Il ricercatore pensa di adattare il modello in (Bii) ma in realt√† sta adattando il modello in (Biii), dove il termine di errore non √® solo e, ma la somma di e e la variazione dovuta alla variabile omessa U. A causa di ci√≤, c‚Äô√® un percorso diretto dal termine di errore del modello a \\(X\\) (e quindi \\(X\\) √® endogeno). (C) mostra le relazioni stimate risultanti dai modelli in (Bi) rispetto a (Bii). Le linee rappresentano la relazione stimata tra \\(X\\) e \\(Y\\) dai rispettivi modelli. La linea rossa √® la vera relazione causale, stimata da (Bi), mentre la linea blu contiene il bias da variabile omessa, poich√© non si tiene conto della variabile confondente U, come stimato dal modello in Bii/Biii (Figura tratta da Byrnes & Dee (2024)).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#le-pratiche-scientifiche-per-inferire-la-causalit√†",
    "href": "chapters/eda/09_causality.html#le-pratiche-scientifiche-per-inferire-la-causalit√†",
    "title": "[22¬† Causalit√† dai dati osservazionali]{#sec-eda-causalit\\(Y\\) .quarto-section-identifier}",
    "section": "22.9 Le Pratiche Scientifiche per Inferire la Causalit√†",
    "text": "22.9 Le Pratiche Scientifiche per Inferire la Causalit√†\nIn qualsiasi sistema complesso, possiamo osservare la distribuzione congiunta di due variabili, \\(X\\) e \\(Y\\), ma determinare se \\(X\\) causa \\(Y\\), se \\(Y\\) causa \\(X\\), o se una terza variabile \\(Z\\) influenza entrambe, √® un problema complesso (Salmon, 1984). Questa difficolt√† √® alla base del dibattito filosofico sulla causalit√† e ha stimolato lo sviluppo di metodi scientifici rigorosi per decifrare i meccanismi causali. Ad esempio, per stabilire se la terapia cognitivo-comportamentale (CBT) riduce i sintomi di ansia o se l‚Äôattivazione di un neurone influenza il comportamento, √® necessario adottare pratiche scientifiche che distinguano la correlazione dalla causalit√†.\n\n22.9.1 Il Framework Interventista di Judea Pearl\nIl lavoro di Judea Pearl ha rivoluzionato la formalizzazione dell‚Äôinferenza causale introducendo l‚Äôoperatore ‚Äúdo‚Äù, che distingue tra correlazione osservata e causalit√† determinata da un intervento attivo (ricordiamo il punto di vista di Hardt & Recht, 2022 descritto in precedenza). La probabilit√† condizionale tradizionale, \\(p(Y \\mid X)\\), descrive l‚Äôassociazione tra due variabili, ma non implica necessariamente causalit√†. L‚Äôoperatore do, invece, introduce il concetto di intervento forzato: \\(p(Y \\mid do(X))\\) rappresenta la probabilit√† di \\(Y\\) quando \\(X\\) viene manipolato direttamente (Pearl, 2009).\nAd esempio, osservare che i pazienti che partecipano alla CBT tendono a mostrare una riduzione dell‚Äôansia non √® sufficiente per concludere che la CBT ne sia la causa. Il problema √® che la decisione di seguire la CBT potrebbe dipendere da fattori come il livello di gravit√† dell‚Äôansia, lo stato socioeconomico o la predisposizione genetica, che possono influenzare sia la scelta di intraprendere la terapia sia la variazione nei sintomi.\nUtilizzando un modello causale strutturale (SCM) completo, possiamo esprimere formalmente le relazioni tra le variabili e determinare se l‚Äôeffetto di \\(X\\) su \\(Y\\) pu√≤ essere identificato, ovvero stimato correttamente dai dati. L‚Äôoperatore do ci consente di rispondere alla domanda: ‚ÄúCosa accadrebbe se tutti i pazienti seguissero la CBT indipendentemente da altri fattori?‚Äù. In pratica, uno SCM ben specificato permette di controllare statisticamente le variabili di disturbo e di rimuovere i percorsi di confondimento, simulando una condizione sperimentale in cui l‚Äôassegnazione al trattamento √® indipendente da fattori che influenzano sia la terapia sia l‚Äôoutcome.\nQuesta capacit√† di simulare interventi e stimare effetti causali √® ci√≤ che distingue i modelli causali strutturali dagli approcci puramente correlazionali e permette di ottenere inferenze pi√π affidabili anche in assenza di esperimenti randomizzati.\n\n\n22.9.2 Tre Fonti di Conoscenza Causale\nAlla luce delle considerazioni precedenti, possiamo individuare tre fonti fondamentali per inferire la causalit√†.\n\nEsperimenti Randomizzati Controllati (RCT). Gli RCT rappresentano il metodo pi√π affidabile per stabilire relazioni causali, assegnando casualmente i partecipanti a gruppi di trattamento e controllo. Questo processo minimizza l‚Äôinfluenza di confondenti e garantisce stime non distorte dell‚Äôeffetto di un intervento. Ad esempio, per verificare se il sonno migliora la memoria, possiamo assegnare casualmente alcuni volontari a dormire 8 ore e altri a restare svegli prima di un test cognitivo. Questo approccio elimina l‚Äôinfluenza di fattori come l‚Äôet√† o il livello di stress, consentendo di attribuire le differenze di performance esclusivamente alla quantit√† di sonno.\nConoscenza Specifica del Dominio. In discipline come la psicologia e le neuroscienze, la conoscenza specialistica permette di formulare ipotesi causali informate. Ad esempio, sebbene un semplice movimento della mano non causi direttamente l‚Äôaccensione di una luce, sappiamo che chiudere un interruttore completa un circuito elettrico. Questa comprensione ci guida nella progettazione di esperimenti e nell‚Äôinterpretazione dei risultati. Un esempio in neuroscienze √® il ruolo dell‚Äôamigdala nella risposta alla paura. Studi su pazienti con danni all‚Äôamigdala mostrano una ridotta capacit√† di riconoscere espressioni di paura, suggerendo un legame causale tra l‚Äôattivit√† dell‚Äôamigdala e la regolazione della paura. Allo stesso modo, la scoperta dell‚Äôafasia di Broca ha dimostrato il ruolo causale dell‚Äôarea di Broca nella produzione del linguaggio. Questa conoscenza permette di formulare ipotesi precise anche in assenza di RCT, come nel caso di studi clinici su pazienti con condizioni neurologiche rare.\nProve Cumulative e Consenso Scientifico. La conoscenza scientifica avanza attraverso la validazione collettiva dei risultati. Quando numerosi studi indipendenti convergono su una relazione causale, la comunit√† scientifica acquisisce una comprensione pi√π solida del fenomeno. Ad esempio, molteplici studi indicano che relazioni sociali positive aumentano il benessere psicologico. Anche se nessuno studio singolo pu√≤ offrire una prova definitiva, la convergenza di evidenze rafforza l‚Äôipotesi causale.\n\nSi noti che, mentre nel primo caso l‚Äôinferenza causale deriva direttamente da esperimenti randomizzati controllati (RCT), nei secondi due la conoscenza causale si basa su studi osservazionali e sulla convergenza di evidenze empiriche. La validit√† di queste inferenze dipende dall‚Äôuso di modelli adeguati, dal controllo delle variabili confondenti e dalla replicabilit√† dei risultati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#conciliare-pragmatismo-con-scetticismo-filosofico",
    "href": "chapters/eda/09_causality.html#conciliare-pragmatismo-con-scetticismo-filosofico",
    "title": "[22¬† Causalit√† dai dati osservazionali]{#sec-eda-causalit\\(Y\\) .quarto-section-identifier}",
    "section": "22.10 Conciliare Pragmatismo con Scetticismo Filosofico",
    "text": "22.10 Conciliare Pragmatismo con Scetticismo Filosofico\nNonostante l‚Äôefficacia degli RCT e degli strumenti teorici come l‚Äôoperatore do, il problema epistemologico della causalit√†, sollevato da filosofi come Hume, rimane aperto. Hume sosteneva che la causalit√† non √® direttamente osservabile, ma √® inferita dall‚Äôesperienza e dalla regolarit√† delle osservazioni. Questo scetticismo ci ricorda che la nostra comprensione causale √® sempre mediata da modelli, assunzioni e interpretazioni.\nTuttavia, l‚Äôapproccio pragmatico alla causalit√† non richiede una dimostrazione metafisica assoluta, ma si concentra sulla sua utilit√† pratica: se un intervento produce risultati coerenti e prevedibili, allora possiamo considerarlo una causa per tutti gli scopi pratici.\nAd esempio, la nostra fiducia nel volo aereo non deriva da una prova definitiva della causalit√† tra il design di un aereo e la sua capacit√† di volare, ma dall‚Äôaffidabilit√† e replicabilit√† delle leggi dell‚Äôaerodinamica. Analogamente, la CBT √® riconosciuta come trattamento efficace per l‚Äôansia non perch√© possiamo dimostrare una causalit√† assoluta, ma perch√© numerosi studi, tra cui RCT e analisi basate su modelli causali, ne confermano ripetutamente l‚Äôefficacia in diversi contesti.\nIn sintesi, l‚Äôinferenza causale √® una delle sfide centrali della scienza, ma strumenti come gli RCT, i modelli causali strutturali, la conoscenza del dominio e le prove cumulative forniscono metodi robusti per affrontarla. L‚Äôapproccio pragmatico ci consente di superare il problema filosofico della causalit√†, concentrandoci sulla replicabilit√†, sull‚Äôaffidabilit√† e sull‚Äôapplicabilit√† pratica dei risultati. Sebbene il dibattito sulla natura ultima della causalit√† rimanga aperto, le pratiche scientifiche ci permettono di prendere decisioni informate e mettere in atti interventi efficaci.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#riflessioni-conclusive",
    "href": "chapters/eda/09_causality.html#riflessioni-conclusive",
    "title": "[22¬† Causalit√† dai dati osservazionali]{#sec-eda-causalit\\(Y\\) .quarto-section-identifier}",
    "section": "22.11 Riflessioni Conclusive",
    "text": "22.11 Riflessioni Conclusive\nIl dibattito filosofico sulla causalit√† resta aperto, ma i progressi metodologici degli ultimi decenni hanno trasformato l‚Äôinferenza causale in una disciplina rigorosa e applicabile. L‚Äôuso di esperimenti randomizzati controllati (RCT), diagrammi causali (DAG) e l‚Äôoperatore do di Judea Pearl ha reso possibile analizzare le relazioni causali in modo pi√π trasparente e sistematico, senza dover risolvere le questioni metafisiche sulla natura ultima della causalit√†. La scienza, dunque, procede non con certezze assolute, ma con modelli sempre pi√π raffinati e verificabili.\nI DAG si sono affermati come strumenti essenziali per visualizzare e analizzare i rapporti causali, permettendo di esplicitare le assunzioni e di individuare le fonti di bias. Tuttavia, la loro validit√† dipende strettamente dalla qualit√† delle conoscenze del dominio: un DAG ben costruito pu√≤ guidare verso inferenze affidabili, ma un DAG con specificazioni errate o incomplete rischia di produrre conclusioni distorte. Per questa ragione, la loro applicazione richiede non solo competenza metodologica, ma anche un solido ancoraggio alla realt√† empirica.\nL‚Äôapproccio pragmatico alla causalit√† si fonda su un equilibrio tra fiducia nei modelli empirici e consapevolezza dei loro limiti. La nostra capacit√† di fare previsioni e intervenire sui fenomeni ‚Äî dall‚Äôingegneria aeronautica all‚Äôefficacia delle terapie psicologiche ‚Äî non si basa su una conoscenza definitiva della causalit√†, ma sulla robustezza delle evidenze accumulate. Questo pragmatismo non √® una debolezza, ma una strategia vincente per affrontare l‚Äôincertezza in modo efficace e produttivo.\nTuttavia, la solidit√† degli strumenti causali non √® garantita a priori: la qualit√† delle inferenze dipende dalla cura con cui vengono costruiti e validati. Un uso acritico dei DAG, degli RCT o dei modelli causali strutturali pu√≤ portare a interpretazioni fuorvianti, specialmente se si ignorano le limitazioni insite in ogni approccio. La ricerca causale, dunque, non √® solo una questione di strumenti, ma di metodo: richiede una costante riflessione critica sulle ipotesi sottostanti e un rigoroso controllo empirico per evitare semplificazioni eccessive.\nIn definitiva, il progresso nella comprensione della causalit√† dipende dalla capacit√† di bilanciare pragmatismo e scetticismo epistemologico. Da un lato, dobbiamo costruire modelli che ci permettano di fare previsioni affidabili e di prendere decisioni informate; dall‚Äôaltro, dobbiamo riconoscere che ogni modello √® una rappresentazione semplificata della realt√† e che le nostre inferenze devono essere costantemente riviste alla luce di nuove evidenze. Accettare questa tensione tra conoscenza e incertezza non √® una limitazione, ma una condizione essenziale per il progresso scientifico. In questo equilibrio tra umilt√† teorica e fiducia operativa risiede la vera forza dell‚Äôindagine causale.\nUn riassunto ironico di questi concetti √® offerto dalla vignetta di xkcd.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#esercizi",
    "href": "chapters/eda/09_causality.html#esercizi",
    "title": "[22¬† Causalit√† dai dati osservazionali]{#sec-eda-causalit\\(Y\\) .quarto-section-identifier}",
    "section": "22.12 Esercizi",
    "text": "22.12 Esercizi\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nEsercizi teorici\nEsercizio 1: Concetti chiave della causalit√†\nPer ciascuna delle seguenti affermazioni, indica se √® vera o falsa e spiega il motivo della tua risposta.\n\nSe \\(X\\) e \\(Y\\) sono correlate, allora \\(X\\) causa \\(Y\\).\n\nSe condizioniamo su una variabile collider, la correlazione tra \\(X\\) e \\(Y\\) aumenta.\n\nIl paradosso di Simpson dimostra che i risultati osservati in gruppi disaggregati devono sempre essere preferiti a quelli aggregati.\n\nGli esperimenti randomizzati controllati eliminano completamente il problema della confusione.\n\nUn DAG pu√≤ rappresentare relazioni causali solo se tutte le variabili sono misurate.\n\nEsercizio 2: Interpretazione di un DAG\nConsidera il seguente DAG che rappresenta l‚Äôeffetto dell‚Äôesercizio fisico (\\(X\\)) sulla salute cardiaca (\\(Y\\)):\n    $X$ ‚Üí $Y$\n    Z ‚Üí $X$\n    Z ‚Üí $Y$\ndove:\n\n\\(X\\) = Esercizio fisico\n\n\\(Y\\) = Salute cardiaca\n\n\\(Z\\) = Predisposizione genetica\n\n\nQuale ruolo svolge \\(Z\\) in questo DAG? √à una variabile confondente, collider o mediatore?\nPer stimare correttamente l‚Äôeffetto causale di \\(X\\) su \\(Y\\), √® necessario controllare per \\(Z\\)? Spiega il perch√©.\n\nSe aggiungiamo un‚Äôaltra variabile W che influenza sia \\(Z\\) che \\(X\\), ma non direttamente \\(Y\\), come cambierebbe il DAG?\n\nEsercizio 3: Causalit√† nei dati osservazionali\nLeggi le seguenti situazioni e identifica quale problema potrebbe invalidare l‚Äôinferenza causale:\n\nUno studio osservazionale mostra che le persone che bevono caff√® vivono pi√π a lungo. Tuttavia, chi beve caff√® tende ad avere un reddito pi√π alto e accesso a migliori cure mediche.\nUn‚Äôazienda scopre che i dipendenti che frequentano corsi di formazione hanno salari pi√π alti. Ma i corsi sono aperti solo a coloro che gi√† hanno pi√π esperienza lavorativa.\n\nUna ricerca mostra che gli studenti che usano di pi√π il tablet per studiare hanno punteggi pi√π bassi nei test. Tuttavia, gli studenti con difficolt√† di apprendimento tendono a usare di pi√π il tablet.\n\nPer ogni caso, identifica una possibile variabile confondente e suggerisci un metodo per controllare il bias.\nEsercizi pratici in R\nEsercizio 4: Paradosso di Simpson con dati reali\nUtilizziamo i dati delle ammissioni di UC Berkele\\(Y\\) per verificare il paradosso di Simpson.\n# Dati di UC Berkele$Y$\ndata(UCBAdmissions)\ndf &lt;- as.data.frame(UCBAdmissions)\n\n# Convertiamo i dati in formato long\ndf_long &lt;- df |&gt; tid$Y$r::pivot_wider(names_from = \"Admit\", values_from = \"Freq\") \n\n# Calcoliamo il tasso di ammissione per uomini e donne aggregati\ntotal_admitted_m &lt;- sum(df$Freq[df$Admit == \"Admitted\" & df$Gender == \"Male\"])\ntotal_applicants_m &lt;- sum(df$Freq[df$Gender == \"Male\"])\n\ntotal_admitted_f &lt;- sum(df$Freq[df$Admit == \"Admitted\" & df$Gender == \"Female\"])\ntotal_applicants_f &lt;- sum(df$Freq[df$Gender == \"Female\"])\n\nadmit_rate_m &lt;- total_admitted_m / total_applicants_m\nadmit_rate_f &lt;- total_admitted_f / total_applicants_f\n\nc(admit_rate_m, admit_rate_f)\n\n# Calcoliamo il tasso di ammissione per ogni dipartimento\ndf_long$rate_m &lt;- df_long$Admitted / (df_long$Admitted + df_long$Rejected)\n\ndf_long |&gt; dpl$Y$r::group_b$Y$(Dept) |&gt; dpl$Y$r::summarize(mean_rate_m = mean(rate_m))\n\n# Visualizziamo il tasso di ammissione per genere e dipartimento\nggplot(df_long, aes($X$ = Dept, $Y$ = rate_m, fill = Gender)) +\n  geom_bar(stat = \"identit$Y$\", position = \"dodge\") +\n  labs(title = \"Tasso di Ammissione per Genere nei Dipartimenti UC Berkele$Y$\",\n       $X$ = \"Dipartimento\", $Y$ = \"Tasso di Ammissione\")\nDomande:\n\nDai dati aggregati, sembra che le donne siano discriminate. Questo √® confermato dall‚Äôanalisi per dipartimento?\n\nQuale variabile confondente √® responsabile del paradosso di Simpson in questo caso?\n\nCome potrebbe essere interpretato male un modello che considera solo i dati aggregati?\n\nEsercizio 5: Analisi causale con DAG\nUsiamo il pacchetto dagitt$Y$ per costruire e analizzare un DAG.\nlibrar$Y$(dagitt$Y$)\n\ndag &lt;- dagitt$Y$(\"dag {\n    E -&gt; H\n    G -&gt; E\n    G -&gt; H\n}\")\n\nplot(graphLa$Y$out(dag))\nDomande:\n\nQuali sono le variabili confondenti nel DAG?\n\nQuali percorsi sono back-door paths?\n\nQuale set di variabili dovremmo controllare per ottenere una stima non distorta dell‚Äôeffetto di E su H?\n\n\n\n\n\n\n\n\n\n\n\nSoluzione\n\n\n\n\n\nEsercizio 1: Concetti chiave della causalit√†\n\nFalso ‚Äì La correlazione non implica causalit√†. Potrebbero esserci variabili confondenti o una relazione di causalit√† inversa tra \\(X\\) e \\(Y\\).\n\nVero ‚Äì Condizionare su un collider introduce un‚Äôassociazione spuriosa tra \\(X\\) e \\(Y\\), aumentando la correlazione.\n\nFalso ‚Äì Il paradosso di Simpson mostra che i dati aggregati possono essere fuorvianti, ma non significa che i dati disaggregati siano sempre pi√π affidabili. √à necessario analizzare il contesto e le possibili variabili confondenti.\n\nFalso ‚Äì Gli RCT minimizzano i problemi di confondimento grazie alla randomizzazione, ma possono comunque avere limitazioni dovute a bias di selezione, mancate assegnazioni casuali, e problemi etici.\n\nFalso ‚Äì Un DAG pu√≤ rappresentare le relazioni causali anche se alcune variabili non sono misurate. Tuttavia, la validit√† dell‚Äôinferenza dipende dalla correttezza del DAG.\n\nEsercizio 2: Interpretazione di un DAG\n\nZ √® una variabile confondente, poich√© influenza sia \\(X\\) che \\(Y\\), creando un percorso di back-door.\n\nS√¨, per stimare correttamente l‚Äôeffetto di \\(X\\) su \\(Y\\) dobbiamo controllare per Z. Se non lo facciamo, la relazione osservata tra \\(X\\) e \\(Y\\) includer√† l‚Äôinfluenza di Z.\n\nSe aggiungiamo una variabile W che influenza Z e \\(X\\), il DAG diventa:\n    W ‚Üí Z ‚Üí $X$ ‚Üí $Y$\n    W ‚Üí $X$\n    Z ‚Üí $Y$\nOra W √® una variabile a monte di \\(X\\) e Z, ma non confonde direttamente la relazione tra \\(X\\) e \\(Y\\).\n\nEsercizio 3: Causalit√† nei dati osservazionali\n\nConfondente: reddito ‚Äì Le persone con un reddito pi√π alto possono avere accesso a cure migliori, che a loro volta migliorano la salute. Soluzione: Propensit\\(Y\\) Score Matching (PSM) o regressione con controllo per il reddito.\n\nConfondente: esperienza lavorativa ‚Äì Chi ha pi√π esperienza pu√≤ gi√† avere salari pi√π alti. Soluzione: Matching o modello di regressione con controllo per esperienza lavorativa.\n\nConfondente: difficolt√† di apprendimento ‚Äì Studenti con difficolt√† possono usare pi√π il tablet e avere punteggi pi√π bassi. Soluzione: Includere il livello di abilit√† di partenza nei modelli statistici.\n\nSoluzioni esercizi pratici in R\nEsercizio 4: Paradosso di Simpson con dati reali\n\nDifferenza nei tassi di ammissione aggregati:\nadmit_rate_m &lt;- total_admitted_m / total_applicants_m\nadmit_rate_f &lt;- total_admitted_f / total_applicants_f\nRisultato:\n\nTasso di ammissione uomini: ~44%\n\nTasso di ammissione donne: ~35%\n‚Üí Sembra che le donne siano discriminate.\n\nAnalisi per dipartimento:\ndf_long |&gt; dpl$Y$r::group_b$Y$(Dept) |&gt; dpl$Y$r::summarize(mean_rate_m = mean(rate_m))\n\nNei singoli dipartimenti, le donne hanno tassi di ammissione uguali o superiori rispetto agli uomini.\n‚Üí Il problema non √® discriminazione diretta, ma la distribuzione delle domande nei dipartimenti.\n\nConclusione: Il paradosso di Simpson mostra che le donne tendono a candidarsi pi√π spesso a dipartimenti molto competitivi con bassi tassi di ammissione, mentre gli uomini si candidano di pi√π in dipartimenti con tassi di ammissione pi√π alti.\n\nMoralit√†: Non sempre una differenza aggregata indica un bias. Bisogna analizzare i sottogruppi.\nEsercizio 5: Analisi causale con DAG\n\nVariabili confondenti\n\nG √® una variabile confondente perch√© influenza sia E (esposizione) che H (esito).\n\nBack-door paths\n\nIl percorso E ‚Üê G ‚Üí H √® un back-door path che deve essere bloccato.\n\nSoluzione: controllare per G\nadjustmentSets(dag)\nOutput: {G}\n‚Üí Controllare per G permette di ottenere una stima causale non distorta di E su H.\n\nConclusioni\n\nLa correlazione non implica causalit√†. Abbiamo visto come variabili confondenti possano generare relazioni spurie.\n\nIl paradosso di Simpson dimostra che i dati aggregati possono essere fuorvianti. Bisogna sempre analizzare i sottogruppi.\n\nI DAG aiutano a identificare le variabili da controllare per ottenere stime causali corrette.\n\nL‚Äôanalisi causale √® fondamentale per evitare inferenze errate e migliorare la qualit√† della ricerca.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#bibliografia",
    "href": "chapters/eda/09_causality.html#bibliografia",
    "title": "[22¬† Causalit√† dai dati osservazionali]{#sec-eda-causalit\\(Y\\) .quarto-section-identifier}",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAlexander, R. (2023). Telling Stories with Data: With Applications in R. Chapman; Hall/CRC.\n\n\nByrnes, J. E., & Dee, L. E. (2024). Causal inference with observational data and unobserved confounding variables. bioRxiv, 2024‚Äì2002.\n\n\nHardt, M., & Recht, B. (2022). Patterns, Predictions, and Actions: Foundations of Machine Learning. Princeton University Press.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nPearl, J. (2009). Causality. Cambridge University Press.\n\n\nRiederer, E. (2021). Causal design patterns for data analysts. https://emilyriederer.netlify.app/post/causal-design-patterns/\n\n\nSchennach, S. M. (2016). Recent advances in the measurement error literature. Annual Review of Economics, 8(1), 341‚Äì377.\n\n\nWilms, R., M√§thner, E., Winnen, L., & Lanwehr, R. (2021). Omitted variable bias: A threat to estimating causal relationships. Methods in Psychology, 5, 100075.\n\n\nZwet, E. van, Gelman, A., Greenland, S., Imbens, G., Schwab, S., & Goodman, S. N. (2023). A New Look at P Values for Randomized Clinical Trials. NEJM Evidence, 3(1), EVIDoa2300003.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html",
    "href": "chapters/eda/10_estimand.html",
    "title": "23¬† Estimandi teorici e estimandi empirici",
    "section": "",
    "text": "23.1 Introduzione\nNei capitoli precedenti abbiamo esplorato diverse tecniche di analisi esplorativa dei dati, strumenti fondamentali per sintetizzare informazioni, rappresentare le distribuzioni delle variabili e descriverne le relazioni. Tuttavia, queste tecniche presuppongono che le variabili siano state misurate in modo appropriato rispetto alla domanda teorica di ricerca. √à quindi essenziale chiarire il legame tra le quantit√† che intendiamo stimare (estimandi) e il quadro teorico che guida l‚Äôanalisi.\nPer approfondire questa relazione tra teoria e misurazione, esamineremo il contributo di Lundberg et al. (2021), What Is Your Estimand? Defining the Target Quantity Connects Statistical Evidence to Theory. Questo lavoro evidenzia l‚Äôimportanza di una precisa definizione dell‚Äôestimando in uno studio e della distinzione tra estimando teorico ed estimando empirico, cruciale per interpretare correttamente i risultati statistici nel contesto della teoria sottostante.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Estimandi teorici e estimandi empirici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#definizione-di-estimando",
    "href": "chapters/eda/10_estimand.html#definizione-di-estimando",
    "title": "23¬† Estimandi teorici e estimandi empirici",
    "section": "23.2 Definizione di Estimando",
    "text": "23.2 Definizione di Estimando\nIn epistemologia e metodologia della ricerca, il concetto di estimando si riferisce alla quantit√† che desideriamo stimare attraverso l‚Äôosservazione e l‚Äôinferenza. Nelle scienze psicologiche, dove molti fenomeni di interesse non sono direttamente osservabili, √® fondamentale distinguere tra:\n\nEstimando teorico ‚Äì il costrutto latente definito dalla teoria.\nEstimando empirico ‚Äì la misura numerica ottenuta da dati osservabili.\n\n\n23.2.1 Estimando Teorico: Il Costrutto Latente\nL‚Äôestimando teorico √® la quantit√† di interesse che un modello teorico definisce, ma che non pu√≤ essere direttamente osservata. Nelle scienze psicologiche, la maggior parte dei costrutti ‚Äì come intelligenza, ansia, personalit√†, autoefficacia ‚Äì rientra in questa categoria.\n\nEsempio 23.1 Consideriamo il livello di ansia di tratto di un individuo, ovvero la sua tendenza stabile a sperimentare stati ansiosi in diverse situazioni:\n\nL‚Äôansia di tratto √® un costrutto teorico formulato nella teoria della personalit√†.\nNon possiamo osservarla direttamente, n√© esiste un singolo indicatore oggettivo che la rappresenti perfettamente.\nL‚Äôansia di tratto √® quindi un estimando teorico, inferibile solo tramite indicatori osservabili.\n\n\n\n\n23.2.2 Estimando Empirico: La Misura Osservabile\nL‚Äôestimando empirico √® la misura quantitativa che usiamo per approssimare l‚Äôestimando teorico. √à ottenuto attraverso strumenti di misurazione come test psicometrici, scale di valutazione o indicatori fisiologici.\n\nEsempio 23.2 Per stimare l‚Äôansia di tratto, possiamo utilizzare il State-Trait Anxiety Inventory (STAI-T), un questionario i cui item includono affermazioni come:\n\n‚ÄúMi sento spesso nervoso senza motivo apparente.‚Äù\n‚ÄúTendo a preoccuparmi molto anche per piccole cose.‚Äù\n\nLe risposte fornite dal soggetto vengono aggregate in un punteggio complessivo, che rappresenta un estimando empirico dell‚Äôansia di tratto. Tuttavia:\n\nQuesto punteggio √® solo una proxy quantitativa dell‚Äôansia di tratto.\nNon corrisponde all‚Äôansia di tratto in s√©, ma √® una stima basata su dati osservabili.\n\n\n\n\n23.2.3 Differenze tra Estimando Teorico ed Empirico\n\n\n\n\n\n\n\n\nAspetto\nEstimando Teorico\nEstimando Empirico\n\n\n\n\nDefinizione\nCostrutto latente, concettuale\nMisura osservabile, numerica\n\n\nEsempi\nIntelligenza, ansia, personalit√†\nPunteggi a test, risposte a questionari\n\n\nMisurabilit√†\nNon direttamente osservabile\nDerivato da dati empirici\n\n\nDipendenza dai dati\nDefinito dalla teoria\nDerivato da strumenti di misura",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Estimandi teorici e estimandi empirici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#le-sfide-della-stima-degli-estimandi",
    "href": "chapters/eda/10_estimand.html#le-sfide-della-stima-degli-estimandi",
    "title": "23¬† Estimandi teorici e estimandi empirici",
    "section": "23.3 Le Sfide della Stima degli Estimandi",
    "text": "23.3 Le Sfide della Stima degli Estimandi\nL‚Äôuso di estimandi empirici per inferire estimandi teorici presenta diverse sfide metodologiche:\n\nValidit√† della Misura\n\nIl test STAI-T misura veramente l‚Äôansia di tratto o cattura solo un aspetto superficiale dell‚Äôansia?\nIndicatori fisiologici come il cortisolo o la conduttanza cutanea possono offrire altre proxy dell‚Äôansia, ma con significati differenti.\n\nAffidabilit√† della Misura\n\nIl punteggio ottenuto √® stabile nel tempo?\nSe un soggetto compila il test in momenti diversi, ottiene risultati simili?\n\nDistorsioni e Errori di Misura\n\nGli item del questionario potrebbero influenzare le risposte?\nI soggetti rispondono in modo onesto o sono condizionati da desiderabilit√† sociale?\n\nModelli Statistici e Inferenza Bayesiana\n\nI modelli fattoriali, le equazioni strutturali (SEM) e i modelli bayesiani sono strumenti essenziali per inferire estimandi teorici dai dati empirici.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Estimandi teorici e estimandi empirici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#il-modello-fattoriale-latente",
    "href": "chapters/eda/10_estimand.html#il-modello-fattoriale-latente",
    "title": "23¬† Estimandi teorici e estimandi empirici",
    "section": "23.4 Il Modello Fattoriale Latente",
    "text": "23.4 Il Modello Fattoriale Latente\nL‚Äôansia di tratto (\\(\\theta\\)) pu√≤ essere modellata come una variabile latente tramite l‚Äôanalisi fattoriale. Il modello assume la seguente forma:\n\\[\ny_i = \\lambda_i \\theta + \\epsilon_i ,\n\\tag{23.1}\\]\ndove:\n\n\\(y_i\\) √® la risposta osservabile al singolo item (estimando empirico),\n\\(\\theta\\) √® il livello latente di ansia di tratto (estimando teorico),\n\\(\\lambda_i\\) √® il peso fattoriale dell‚Äôitem, che indica quanto l‚Äôitem misura il costrutto latente.\n\\(\\epsilon_i\\) √® l‚Äôerrore di misurazione.\n\nL‚Äôanalisi fattoriale permette di:\n\nidentificare la struttura del costrutto,\nquantificare il contributo di ciascun item attraverso i pesi fattoriali (\\(\\lambda_i\\)),\nseparare la variabilit√† spiegata dalla variabilit√† attribuibile all‚Äôerrore (\\(\\epsilon_i\\)).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Estimandi teorici e estimandi empirici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#framework-di-lundberg2021your-il-collegamento-tra-teoria-e-dati",
    "href": "chapters/eda/10_estimand.html#framework-di-lundberg2021your-il-collegamento-tra-teoria-e-dati",
    "title": "23¬† Estimandi teorici e estimandi empirici",
    "section": "23.5 Framework di Lundberg et al. (2021): Il Collegamento tra Teoria e Dati",
    "text": "23.5 Framework di Lundberg et al. (2021): Il Collegamento tra Teoria e Dati\nLundberg et al. (2021) propongono un approccio metodologico in tre fasi:\n\ndefinire l‚Äôestimando teorico, ancorandolo esplicitamente alla teoria di riferimento,\ntradurre l‚Äôestimando teorico in un estimando empirico, ovvero una misura osservabile,\nstimare l‚Äôestimando empirico, applicando procedure statistiche adeguate.\n\n\nEsempio 23.3 Un esempio concreto √® fornito dal modello di Rescorla-Wagner, applicato a compiti di Probabilistic Reversal Learning (PRL): l‚Äôestimando empirico potrebbe corrispondere a parametri come il tasso di apprendimento \\(\\alpha\\) o la temperatura inversa \\(\\beta\\). Questi parametri riflettono quanto i partecipanti modifichino i valori associati agli stimoli o regolino la strategia di scelta (esplorazione rispetto a sfruttamento).\n√à importante notare che l‚Äôestimando empirico pu√≤ essere stimato in modi diversi, utilizzando modelli, metodi di stima e disegni sperimentali vari. Il modello di Rescorla-Wagner √® solo una possibile rappresentazione dell‚Äôapprendimento associativo, e i suoi parametri possono essere ricavati con procedure differenti. Di conseguenza, il valore numerico che descrive la capacit√† di apprendimento associativo dipende dal modello, dalla tecnica di stima e dal contesto sperimentale.\n\n\n\n\n\n\n\nFigura¬†23.1: Aggiungo qui un simpatico meme di @RexDouglass.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Estimandi teorici e estimandi empirici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#conclusioni",
    "href": "chapters/eda/10_estimand.html#conclusioni",
    "title": "23¬† Estimandi teorici e estimandi empirici",
    "section": "23.6 Conclusioni",
    "text": "23.6 Conclusioni\nDefinire chiaramente l‚Äôestimando teorico √® un passo fondamentale per garantire la validit√† delle inferenze scientifiche. Il framework di Lundberg et al.¬†(2021) fornisce un metodo rigoroso per legare teoria e dati, migliorando la replicabilit√† e la coerenza degli studi psicologici.\nL‚Äôadozione di un approccio strutturato nella definizione degli estimandi consente di:\n\nChiarire gli obiettivi della ricerca.\nGarantire la coerenza tra teoria e dati.\nMigliorare la qualit√† e l‚Äôinterpretazione delle inferenze statistiche.\n\nIn questo modo, la ricerca quantitativa pu√≤ produrre risultati pi√π solidi e generalizzabili.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Estimandi teorici e estimandi empirici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#esercizi",
    "href": "chapters/eda/10_estimand.html#esercizi",
    "title": "23¬† Estimandi teorici e estimandi empirici",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nEsercizio 1: Distinguere Estimando Teorico ed Empirico\n\nObiettivo: Comprendere la differenza tra costrutti latenti e misure osservabili.\n\nAttivit√†: Scegli tre costrutti psicologici (es. autostima, ansia di tratto, empatia). Per ciascuno:\n\nDescrivi l‚Äôestimando teorico (cio√® il costrutto latente).\n\nIdentifica un possibile estimando empirico (es. punteggio a un questionario).\n\nSpiega in che modo il passaggio dal costrutto latente alla misura osservabile potrebbe introdurre errori o distorsioni.\n\n\nEsercizio 2: Validit√† e Affidabilit√† di una Scala di Misura\n\nObiettivo: Riflettere sugli aspetti di validit√† (contenuto, costrutto) e affidabilit√† (stabilit√† delle misure) di uno strumento.\n\nAttivit√†: Immagina di dover stimare il costrutto ‚Äúansia di prestazione‚Äù in atleti. Proponi:\n\nUn questionario o scala con 5 item, descrivendo i contenuti di ciascun item.\n\nUna strategia per valutare la validit√† (es. confrontare con un altro test gi√† validato, definire i criteri di inclusione degli item).\n\nUna procedura per valutare l‚Äôaffidabilit√† (es. test-retest, consistenza interna).\n\nUna breve discussione su possibili fonti di errore di misurazione (desiderabilit√† sociale, bias di risposta).\n\n\nEsercizio 3: Modello Fattoriale Latente\n\nObiettivo: Comprendere come un modello fattoriale colleghi risposte osservate a un costrutto latente.\n\nAttivit√†: Supponi di avere 4 item che misurano il costrutto ‚Äúsenso di autoefficacia‚Äù. I punteggi di ogni item vanno da 1 (per niente d‚Äôaccordo) a 5 (molto d‚Äôaccordo). Ti vengono forniti dati fittizi per 10 persone (es. risposte in tabella).\n\nProva a ipotizzare come si potrebbe rappresentare l‚Äôequazione di un modello fattoriale (simile all‚Äôesempio nel testo con \\(y_i = \\lambda_i \\theta + \\epsilon_i\\)).\n\nIndica in parole semplici che cosa rappresentano \\(\\theta\\), \\(\\lambda_i\\) ed \\(\\epsilon_i\\) nel tuo esempio.\n\nElenca due vantaggi che un modello fattoriale offre rispetto al calcolo semplice di una media su tutti gli item.\n\n\nEsercizio 4: Definire l‚ÄôEstimando per un Compito di Apprendimento\n\nObiettivo: Legare un esperimento e un modello a un preciso estimando teorico ed empirico.\n\nAttivit√†: Immagina uno studio sperimentale di apprendimento in cui i partecipanti devono imparare la regola di associazione tra uno stimolo visivo e una ricompensa. Hai deciso di usare il modello di Rescorla-Wagner per stimare il tasso di apprendimento (\\(\\alpha\\)) di ciascun partecipante.\n\nDescrivi l‚Äôestimando teorico che ti interessa (es. ‚Äúcapacit√† di aggiornare le aspettative in base al feedback‚Äù).\n\nSpiega in che modo l‚Äôestimando empirico (\\(\\alpha\\)) √® derivato dai dati osservati (scelte del partecipante, errori, risposte corrette).\n\nElenca due possibili ragioni per cui il valore di \\(\\alpha\\) ottenuto pu√≤ essere diverso in base alla procedura di stima (es. tipo di algoritmo, impostazioni iniziali).\n\n\nEsercizio 5: Criticit√† nell‚ÄôInterpretazione degli Estimandi\n\nObiettivo: Riflettere sui possibili fattori che rendono complessa l‚Äôinterpretazione del punteggio stimato.\n\nAttivit√†: Scegli un qualsiasi costrutto psicologico (es. impulsivit√†, motivazione al successo, stile di attaccamento). Immagina di avere uno strumento (questionario, test computerizzato o altro) che fornisce un punteggio finale come estimando empirico.\n\nSpiega come l‚Äôerrore di misurazione (rumore, bias di risposta, item poco chiari) pu√≤ influire sull‚Äôinterpretazione del punteggio.\n\nDescrivi una situazione in cui il punteggio osservato potrebbe non riflettere correttamente il costrutto latente (es. persona che risponde in modo poco sincero).\n\nProponi due strategie per migliorare la validit√† della misura (es. aggiungere item, utilizzare misurazioni multiple, integrazione con misure fisiologiche, controlli statistici, ecc.).\n\n\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\nEsercizio 1: Distinguere Estimando Teorico ed Empirico\n\nAutostima\n\nEstimando teorico: L‚Äôidea di ‚Äúauto-valutazione globale positiva o negativa di s√©‚Äù (construct della psicologia della personalit√†). Non si misura direttamente, ma √® un concetto chiave per spiegare comportamenti di auto-efficacia, soddisfazione, ecc.\n\nEstimando empirico: Punteggio ottenuto dal Rosenberg Self-Esteem Scale (RSES), una scala di 10 item con punteggi da 0 a 30.\n\nErrori/distorsioni: Possibile desiderabilit√† sociale: il partecipante potrebbe tendere a rispondere in modo da apparire migliore; eventuale variazione linguistica nella comprensione degli item.\n\nAnsia di tratto\n\nEstimando teorico: Tendenza stabile a sperimentare preoccupazione, nervosismo, e tensione in varie situazioni (componente relativamente stabile).\n\nEstimando empirico: Punteggio della sezione Trait (T) del State-Trait Anxiety Inventory (STAI-T).\n\nErrori/distorsioni: Bias di risposta (es. risposte casuali, eccessiva fretta), scarsa onest√†, influenza dell‚Äôumore momentaneo (che dovrebbe riflettere l‚Äôansia di stato, non di tratto).\n\nEmpatia\n\nEstimando teorico: Capacit√† di comprendere e condividere lo stato emotivo altrui, distinta in componente cognitiva e affettiva.\n\nEstimando empirico: Punteggio al Davis Interpersonal Reactivity Index (IRI) o un‚Äôaltra scala self-report sull‚Äôempatia.\n\nErrori/distorsioni: Limitazione del formato self-report nel catturare l‚Äôaspetto empatico reale in situazioni quotidiane, possibili misunderstanding di alcuni item.\n\n\nEsercizio 2: Validit√† e Affidabilit√† di una Scala di Misura\n\nQuestionario a 5 item (risposte su scala Likert 1‚Äì5):\n\n‚ÄúPrima di una gara, mi preoccupo di non riuscire a gestire la pressione.‚Äù\n\n‚ÄúPenso spesso a come potrei sbagliare durante la competizione.‚Äù\n\n‚ÄúMi sento nervoso/a e teso/a molto tempo prima di iniziare la performance.‚Äù\n\n‚ÄúHo la sensazione di non essere all‚Äôaltezza di ci√≤ che ci si aspetta da me.‚Äù\n\n‚ÄúFaccio fatica a concentrare l‚Äôattenzione sui miei obiettivi sportivi.‚Äù\n\nStrategia per valutare la validit√†\n\nValidit√† di contenuto: confrontare gli item con la letteratura specialistica sull‚Äôansia di prestazione (chiedere feedback a esperti in psicologia dello sport).\n\nValidit√† concorrente: somministrare il questionario insieme a un altro strumento gi√† validato per l‚Äôansia di prestazione (o con una misura fisiologica di stress, come frequenza cardiaca a riposo).\n\nValidit√† di costrutto: correlare i punteggi con scale simili (es. STAI) e verificare che siano pi√π alti in atleti di sport ad alta pressione (es. gare individuali).\n\nProcedura per valutare l‚Äôaffidabilit√†\n\nTest-retest: somministrare la scala a un gruppo di atleti a distanza di 2 settimane, verificando la correlazione tra i punteggi.\n\nConsistenza interna: calcolare l‚ÄôŒ± di Cronbach per stimare in che misura gli item misurano un costrutto coerente.\n\nPossibili fonti di errore\n\nBias di desiderabilit√† sociale (l‚Äôatleta potrebbe minimizzare la propria ansia).\n\nStato emotivo contingente (per es., stress esterno non legato allo sport).\n\nSituazione specifica dell‚Äôatleta il giorno della compilazione (stanchezza, problemi personali, ecc.).\n\n\nEsercizio 3: Modello Fattoriale Latente\n\nEquazione di un modello fattoriale (semplificata)\n\\[\ny_i = \\lambda_i \\,\\theta + \\epsilon_i \\quad\\quad (i=1,2,3,4),\n\\]\ndove\n\n\\(y_i\\) √® la risposta all‚Äôitem \\(i\\),\n\n\\(\\theta\\) √® il livello latente di autoefficacia,\n\n\\(\\lambda_i\\) √® il peso fattoriale per l‚Äôitem \\(i\\),\n\n\\(\\epsilon_i\\) √® l‚Äôerrore di misurazione per l‚Äôitem \\(i\\).\n\nDescrizione dei termini:\n\n\\(\\theta\\): il ‚Äúvero‚Äù senso di autoefficacia che non possiamo osservare direttamente.\n\n\\(\\lambda_i\\): indica quanto ciascun item riflette il costrutto; se \\(\\lambda_i\\) √® alto, l‚Äôitem √® molto rappresentativo.\n\n\\(\\epsilon_i\\): comprende errori casuali, interpretazioni errate, ecc.\n\nDue vantaggi del modello fattoriale:\n\nGestione dell‚Äôerrore: il modello separa la parte di variabilit√† dovuta al costrutto da quella dovuta all‚Äôerrore (mentre la media ‚Äúmescola‚Äù entrambe).\n\nIndagine del peso di ciascun item: possiamo capire se un item √® fortemente o debolmente collegato al costrutto, migliorando la validit√† dello strumento.\n\n\nEsercizio 4: Definire l‚ÄôEstimando per un Compito di Apprendimento\n\nEstimando teorico\n\nL‚Äô‚Äúabilit√† di adeguare il comportamento in funzione degli esiti passati‚Äù corrisponde al grado di plasticit√† dell‚Äôapprendimento. Non osserviamo ‚Äúdirettamente‚Äù questa abilit√†, che resta un costrutto astratto.\n\nEstimando empirico (\\(\\alpha\\))\n\nNel modello di Rescorla-Wagner, dopo ogni prova la stima del valore dello stimolo si aggiorna in base all‚Äôerrore di predizione.\n\nDati osservati: scelte del partecipante, premio o penalit√† ricevuti, differenze tra aspettative e risultati effettivi.\n\n\\(\\alpha\\) si stima applicando un metodo di ottimizzazione (per es. regressione non lineare, massima verosimiglianza, o un approccio bayesiano) che riduce lo scarto tra le previsioni del modello e il comportamento (scelte corrette/errate) del partecipante.\n\nDue ragioni per cui \\(\\alpha\\) varia\n\nDifferenti procedure di ottimizzazione: alcuni algoritmi convergono a un valore locale invece che globale, oppure usano penali diverse per la complessit√† del modello.\n\nVarie formulazioni del modello: si potrebbero introdurre parametri addizionali (ad es. \\(\\beta\\) per la ‚Äútemperatura inversa‚Äù o funzioni di apprendimento leggermente diverse) che modificano il valore ottimale di \\(\\alpha\\).\n\n\nEsercizio 5: Criticit√† nell‚ÄôInterpretazione degli Estimandi\n\nCostrutto: Impulsivit√†\n\nStrumento: Una scala di autovalutazione (es. Barratt Impulsiveness Scale)\n\n\nInfluenza dell‚Äôerrore di misurazione\n\nSe un individuo compila la scala in un momento di forte stress o fretta, le sue risposte possono enfatizzare un aspetto temporaneo invece che stabile.\n\nPiccoli errori (item poco chiari, interpretazioni ambigue) si sommano, distorcendo il punteggio finale.\n\nSituazione in cui il punteggio non rispecchia il costrutto latente\n\nUna persona tende a presentarsi in modo socialmente desiderabile, dunque minimizza i comportamenti impulsivi. Di fatto, il punteggio osservato sar√† basso, ma non rappresenta il vero livello di impulsivit√†.\n\nDue strategie per migliorare la validit√†\n\nAggiungere item e fonti multiple: utilizzare pi√π item su diverse sfaccettature dell‚Äôimpulsivit√† e integrare dati osservazionali o indicatori oggettivi (per es. tempi di reazione in un test computerizzato).\n\nRidurre la desiderabilit√† sociale: rendere le risposte anonime, istruendo i partecipanti sull‚Äôimportanza di risposte autentiche, o aggiungere un indice di tendenza alla risposta ‚Äúsocialmente accettabile‚Äù.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Estimandi teorici e estimandi empirici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#bibliografia",
    "href": "chapters/eda/10_estimand.html#bibliografia",
    "title": "23¬† Estimandi teorici e estimandi empirici",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nLundberg, I., Johnson, R., & Stewart, B. M. (2021). What is your estimand? Defining the target quantity connects statistical evidence to theory. American Sociological Review, 86(3), 532‚Äì565.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Estimandi teorici e estimandi empirici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_outlier.html",
    "href": "chapters/eda/11_outlier.html",
    "title": "24¬† Outlier",
    "section": "",
    "text": "24.1 Introduzione\nQuando analizziamo dati reali, ci imbattiamo spesso in osservazioni che sembrano molto diverse dalla maggior parte delle altre. Questi valori anomali, chiamati outlier, possono avere origini diverse. Ad esempio, potrebbero derivare da errori di misura o inserimento dati, oppure essere casi estremi ma comunque validi.\nIdentificare e trattare gli outlier in modo appropriato √® importante per evitare che distorcano i risultati dell‚Äôanalisi. Tuttavia, non esiste una definizione universale di outlier: dipende dal contesto e dall‚Äôobiettivo dell‚Äôanalisi.\nIn questo capitolo, esploreremo diversi metodi per individuare gli outlier, concentrandoci su tecniche robuste che minimizzano l‚Äôinfluenza di questi valori anomali sulle statistiche descrittive (Simmons et al., 2011).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_outlier.html#individuare-e-gestire-gli-outlier",
    "href": "chapters/eda/11_outlier.html#individuare-e-gestire-gli-outlier",
    "title": "24¬† Outlier",
    "section": "\n24.2 Individuare e Gestire gli outlier",
    "text": "24.2 Individuare e Gestire gli outlier\nIdentificare ed eventualmente eliminare gli outlier rappresenta una fase cruciale dell‚Äôanalisi dei dati, poich√© la presenza di valori anomali pu√≤ influenzare fortemente le conclusioni che si traggono da analisi statistiche. Gli outlier possono infatti alterare notevolmente statistiche descrittive come media e deviazione standard, ma anche misure di relazione come correlazioni e regressioni. Ci√≤ avviene perch√© molte tecniche statistiche comuni (ad esempio, la media aritmetica o la regressione lineare con metodo dei minimi quadrati) sono particolarmente sensibili ai valori estremi.\nAd esempio, se stiamo analizzando il reddito medio di un gruppo di persone e includiamo erroneamente dati di reddito estremamente elevati o inseriti per errore, la media risultante sar√† molto pi√π alta del reale valore tipico del gruppo, producendo una rappresentazione fuorviante della situazione.\n\n24.2.1 L‚Äôimportanza della Visualizzazione dei Dati\nLa rappresentazione grafica dei dati √® uno strumento fondamentale per individuare rapidamente la presenza di outlier. Grafici come boxplot, istogrammi e scatterplot consentono di identificare visivamente valori anomali che si discostano dalla distribuzione generale.\nTuttavia, queste tecniche sono efficaci principalmente per outlier unidimensionali o bidimensionali. Nel caso di outlier multidimensionali, l‚Äôanalisi visiva diventa insufficiente e si rende necessario l‚Äôutilizzo di metodi statistici pi√π avanzati, come il calcolo della distanza di Mahalanobis.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_outlier.html#come-identificare-gli-outlier",
    "href": "chapters/eda/11_outlier.html#come-identificare-gli-outlier",
    "title": "24¬† Outlier",
    "section": "\n24.3 Come Identificare gli Outlier",
    "text": "24.3 Come Identificare gli Outlier\nOltre alla visualizzazione grafica, esistono tecniche statistiche specifiche che consentono di identificare gli outlier in modo sistematico.\n\n24.3.1 I Boxplot\nUno strumento semplice e intuitivo per individuare gli outlier √® il boxplot. Il boxplot riassume la distribuzione di una variabile mostrando la mediana, il primo e il terzo quartile (Q1 e Q3) e due estremi, detti ‚Äúwhiskers‚Äù. I punti al di fuori di questi whiskers sono considerati potenziali outlier.\nEsempio in R:\n\ndata &lt;- data.frame(\n  value = c(rnorm(100, mean = 10, sd = 2), 30)\n  ) # Aggiungiamo un outlier\n\nggplot(data, aes(y = value)) +\n  geom_boxplot() +\n  coord_flip()\n\n\n\n\n\n\n\nSe il boxplot mostra un punto isolato lontano dagli altri dati, potrebbe essere un outlier.\n\n24.3.2 Metodi Basati sulla Variabilit√†\n\n24.3.2.1 Intervallo Interquartile (IQR)\nJohn Tukey ha introdotto una definizione operativa di outlier basata sull‚ÄôInterquartile Range (IQR), ovvero la differenza tra il terzo e il primo quartile:\n\nI valori inferiori a \\(Q1 - 1.5 \\times IQR\\) o superiori a \\(Q3 + 1.5 \\times IQR\\) sono considerati outlier moderati.\nI valori oltre \\(Q1 - 3 \\times IQR\\) o \\(Q3 + 3 \\times IQR\\) sono definiti far out outliers.\n\nEsempio in R:\n\nQ1 &lt;- quantile(data$value, 0.25)\nQ3 &lt;- quantile(data$value, 0.75)\nIQR_value &lt;- Q3 - Q1\nlower_bound &lt;- Q1 - 1.5 * IQR_value\nupper_bound &lt;- Q3 + 1.5 * IQR_value\n\noutliers &lt;- data$value[data$value &lt; lower_bound | data$value &gt; upper_bound]\noutliers\n#&gt; [1]  4.687  4.014 30.000\n\nQuesto metodo √® efficace per distribuzioni simmetriche, ma potrebbe non funzionare bene con dati asimmetrici.\n\n24.3.2.2 Median Absolute Deviation (MAD)\nUn metodo pi√π robusto rispetto all‚ÄôIQR √® il Median Absolute Deviation (MAD), che utilizza la mediana anzich√© la media per stimare la dispersione:\n\nmad_value &lt;- mad(data$value)\nthreshold &lt;- 3 * mad_value # Soglia classica per gli outlier\n\noutliers_mad &lt;- data$value[abs(data$value - median(data$value)) &gt; threshold]\noutliers_mad\n#&gt; [1]  4.014 30.000\n\nIl MAD √® meno sensibile agli outlier rispetto alla deviazione standard ed √® spesso preferito per dati con distribuzioni non normali.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_outlier.html#outlier-multivariati",
    "href": "chapters/eda/11_outlier.html#outlier-multivariati",
    "title": "24¬† Outlier",
    "section": "\n24.4 Outlier Multivariati",
    "text": "24.4 Outlier Multivariati\nQuando si considerano pi√π variabili contemporaneamente, un valore potrebbe non apparire anomalo su una singola variabile, ma esserlo nel contesto dell‚Äôintero dataset. Un metodo comune per individuare questi outlier √® la Distanza di Mahalanobis, che tiene conto delle correlazioni tra variabili.\n\nCon la distanza ‚Äúnormale‚Äù (come quella che misuri con un righello), se una persona √® pi√π alta o pi√π pesante della media, la distanza √® calcolata in modo ‚Äúisolato‚Äù, senza considerare che altezza e peso sono spesso correlate (persone pi√π alte tendono a pesare di pi√π).\nCon la distanza di Mahalanobis, invece, si osserva il ‚Äúcontesto‚Äù dei dati. Se tutti nel gruppo hanno un‚Äôaltezza e un peso che crescono in modo coordinato (ad esempio, ogni 10 cm in pi√π corrispondono a 8 kg in pi√π), questa distanza valuta se la nuova persona si allontana da questo schema generale. Ad esempio, una persona molto alta ma con peso medio potrebbe essere considerata pi√π ‚Äúanomala‚Äù di una persona altrettanto alta ma pi√π pesante, perch√© viola la relazione tipica del gruppo.\n\nPer comprendere intuitivamente la distanza di Mahalanobis, immaginiamo di avere una nube di punti che rappresentano individui, ciascuno con i propri valori di altezza e peso. Il ‚Äúcentro‚Äù di questa nube √® un punto ideale che rappresenta una sorta di media multivariata (tenendo conto sia dell‚Äôaltezza sia del peso). La distanza di Mahalanobis misura quanto ogni singolo individuo si allontana da questo centro, considerando la variabilit√† congiunta delle variabili (ad esempio, la correlazione tra altezza e peso). Se un individuo presenta caratteristiche molto diverse rispetto alla maggioranza, la sua distanza di Mahalanobis sar√† elevata, segnalando un potenziale outlier.\n\n\n\n\n\nFigura¬†24.1: Soglie per la detezione degli outliers (bande grigie) nel caso di una metrica unidimensionale (pannello di sinistra) e nel caso di una rappresentazione multivariata della varianza (pannello di destra) ‚Äì figura creata da Sergen Cansiz.\n\n\n\n\n\n\n\n\nDistanza di Mahalanobis\n\n\n\n\n\nConsideriamo ora una definizione della distanza di Mahalanobis nel caso bivariato (due variabili). Immaginiamo di avere due variabili come altezza (\\(X\\)) e peso (\\(Y\\)), con:\n\n\nMedie: \\(\\mu_X\\) (altezza media del gruppo), \\(\\mu_Y\\) (peso medio del gruppo).\n\n\nVarianze: \\(\\sigma_X^2\\) (quanto varia l‚Äôaltezza), \\(\\sigma_Y^2\\) (quanto varia il peso).\n\n\nCorrelazione: \\(\\rho\\) (quanto \\(X\\) e \\(Y\\) sono legate, ad esempio: se l‚Äôaltezza aumenta, di quanto aumenta solitamente il peso?).\n\nPer un nuovo individuo con altezza \\(x\\) e peso \\(y\\), la distanza di Mahalanobis (\\(D\\)) si calcola cos√¨:\n\n\nCalcolare le differenze rispetto alla media:\n\nQuanto si discosta l‚Äôaltezza: \\((x - \\mu_X)\\).\nQuanto si discosta il peso: \\((y - \\mu_Y)\\).\n\n\n\nScalare le differenze con le varianze:\n\n\nDividere ogni differenza per la sua ‚Äúvariabilit√† tipica‚Äù (deviazione standard \\(\\sigma_X\\) e \\(\\sigma_Y\\)):\n\\[\n\\frac{(x - \\mu_X)}{\\sigma_X} \\quad \\text{e} \\quad \\frac{(y - \\mu_Y)}{\\sigma_Y} .\n\\]\n\n\n\n\nCorreggere per la correlazione:\n\nSe \\(X\\) e \\(Y\\) sono correlate (\\(\\rho \\neq 0\\)), modifica le differenze per tenere conto di come di solito si ‚Äúmuovono insieme‚Äù.\n\nLa formula finale combina tutto in un unico valore:\\[\nD = \\sqrt{ \\frac{ \\left( \\frac{(x - \\mu_X)}{\\sigma_X} \\right)^2 + \\left( \\frac{(y - \\mu_Y)}{\\sigma_Y} \\right)^2 - 2 \\rho \\left( \\frac{(x - \\mu_X)}{\\sigma_X} \\right)\\left( \\frac{(y - \\mu_Y)}{\\sigma_Y} \\right) }{1 - \\rho^2} }\n\\]\n\n\n\n\nSpiegazione:\n\nSenza correlazione (\\(\\rho = 0\\)), sarebbe come una distanza Euclidea ‚Äúscalata‚Äù dalle varianze.\n\nCon correlazione (\\(\\rho \\neq 0\\)), sottrai un termine che ‚Äúaggiusta‚Äù la distanza in base a quanto \\(X\\) e \\(Y\\) tendono a variare insieme.\n\nIl denominatore \\(1 - \\rho^2\\) normalizza il risultato, per evitare che la correlazione distorca troppo la misura.\n\nEsempio:\nSe tutti gli alti sono anche pesanti (\\(\\rho\\) positivo), un individuo alto ma magro avr√† una distanza di Mahalanobis maggiore rispetto a uno altrettanto alto ma pesante, perch√© viola la relazione tipica del gruppo.\n\n\n\n\n\n\n\n\n\nDistanza Eucliea\n\n\n\n\n\nRicordiamo che la distanza euclidea tra due punti \\((x_1, y_1)\\) e \\((x_2, y_2)\\) in un piano cartesiano √® definita come:\n\\[\nd = \\sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2}\n\\]\n\n\n\nEsempio in R:\n\nX &lt;- as.matrix(mtcars[, c(\"mpg\", \"hp\")])\ncenter &lt;- colMeans(X)\ncov_matrix &lt;- cov(X)\nmahal_dist &lt;- mahalanobis(X, center, cov_matrix)\n\nthreshold &lt;- qchisq(0.975, df = ncol(X)) # Soglia al 97.5%\noutliers_mahal &lt;- X[mahal_dist &gt; threshold, ]\noutliers_mahal\n#&gt; mpg  hp \n#&gt;  15 335\n\nQuesto metodo √® utile per dataset con pi√π variabili correlate, come misure biometriche (altezza e peso).\nTuttavia, la versione classica di questa misura non √® particolarmente robusta: la presenza stessa di outlier pu√≤ distorcere il calcolo del ‚Äúcentro‚Äù e della variabilit√† complessiva, rendendo meno affidabile l‚Äôindividuazione di altri valori anomali. Per questo motivo, si preferisce utilizzare una variante pi√π resistente, la Minimum Covariance Determinant (MCD), che diminuisce l‚Äôinfluenza degli outlier stessi nel processo di identificazione.\nAll‚Äôinterno del pacchetto {performance} in R, √® possibile applicare questa variante robusta utilizzando la funzione check_outliers() con l‚Äôargomento method = \"mcd\". In questo modo, √® possibile individuare gli outlier multivariati in maniera pi√π solida e coerente, anche quando si lavora con dati fortemente influenzati da valori estremi.\n\nd &lt;- mtcars[, c(\"mpg\", \"hp\")]\noutliers &lt;- performance::check_outliers(d, method = \"mcd\", verbose = FALSE)\noutliers\n#&gt; 2 outliers detected: cases 20, 31.\n#&gt; - Based on the following method and threshold: mcd (13.816).\n#&gt; - For variables: mpg, hp.\n\nSi possono poi visualizzare questi outlier:\n\nplot(outliers)\n\n\n\n\n\n\n\nSono disponibili anche altre varianti multivariate documentate nella help page della funzione.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_outlier.html#cosa-fare-con-gli-outlier",
    "href": "chapters/eda/11_outlier.html#cosa-fare-con-gli-outlier",
    "title": "24¬† Outlier",
    "section": "\n24.5 Cosa Fare con gli Outlier?",
    "text": "24.5 Cosa Fare con gli Outlier?\nUna volta identificati gli outlier, dobbiamo decidere se rimuoverli, correggerli o mantenerli (Leys et al., 2019). Alcuni approcci comuni includono:\n\n\nVerificare la fonte del dato: un errore di inserimento pu√≤ essere corretto.\n\nRimuovere gli outlier estremi: utile se il valore √® chiaramente un errore di misura.\n\nUsare metodi robusti: strumenti come la mediana o il MAD sono meno influenzati dagli outlier.\n\nTrasformare i dati: applicare logaritmi o altre trasformazioni pu√≤ ridurre l‚Äôimpatto degli outlier.\n\nWinsorizzazione: invece di rimuovere gli outlier, possiamo limitarli a un massimo accettabile.\n\n\n\n\n\n\n\nWinsorizzazione\n\n\n\n\n\nNella Winsorizzazione, invece di eliminare gli outlier, si sostituiscono i valori troppo alti o troppo bassi con i valori pi√π vicini considerati ‚Äúaccettabili‚Äù, mantenendo per√≤ la struttura generale dei dati.\nCome funziona?\n1. Definisci i limiti:\n\nDecidi una ‚Äúsoglia‚Äù per identificare gli outlier, ad esempio il 5¬∞ percentile (valore sotto cui cade il 5% dei dati pi√π bassi) e il 95¬∞ percentile (valore sopra cui cade il 5% dei dati pi√π alti).\n\nQueste soglie dipendono dal contesto: puoi usare percentili diversi (es. 1¬∞ e 99¬∞) in base a quanto vuoi essere severo nel definire gli outlier.\n\n\n\nSostituisci gli outlier:\n\n\nValori troppo bassi: Tutti i dati sotto il 5¬∞ percentile vengono sostituiti con il valore del 5¬∞ percentile.\n\n\nValori troppo alti: Tutti i dati sopra il 95¬∞ percentile vengono sostituiti con il valore del 95¬∞ percentile.\n\n\n\nEsempio concreto:\nSupponiamo di avere i seguenti dati su 10 esami (ordinati):40, 55, 60, 65, 70, 75, 80, 85, 90, 200\n\n\n5¬∞ percentile: 55 (il valore sotto cui cade il 5% dei dati).\n\n\n95¬∞ percentile: 90 (il valore sopra cui cade il 5% dei dati).\n\nDopo la Winsorizzazione:\n- Il valore pi√π basso (40) diventa 55.\n- Il valore pi√π alto (200) diventa 90.\nNuovi dati: 55, 55, 60, 65, 70, 75, 80, 85, 90, 90.\nPerch√© usarla?\n\n\nMantiene la dimensione del dataset: Non si eliminano dati, ma si modificano solo gli outlier.\n\nRiduce la distorsione: Gli outlier estremi non ‚Äútrascinano‚Äù la media o altre statistiche.\n\n\nUtile in contesti sensibili: Ad esempio, in finanza (per gestire rendimenti anomali) o nelle analisi mediche (per evitare che valori estremi falsino i risultati).\n\n\n\n\nNel pacchetto easystats, la funzione winsorize() di datawizard semplifica il compito di Winsorizzazione:\nwinsorized_data &lt;- \n  winsorize(data$value, method = \"zscore\", robust = TRUE, threshold = 3)",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_outlier.html#importanza-della-trasparenza",
    "href": "chapters/eda/11_outlier.html#importanza-della-trasparenza",
    "title": "24¬† Outlier",
    "section": "\n24.6 Importanza della Trasparenza",
    "text": "24.6 Importanza della Trasparenza\nQualunque decisione va documentata chiaramente: quanti outlier sono stati individuati, con quale metodo, a quale threshold, come sono stati gestiti, e preferibilmente con il codice R utilizzato. La preregistrazione e la condivisione dei dati e del codice (ad es. su OSF) sono pratiche consigliate per garantire riproducibilit√† e trasparenza.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_outlier.html#riflessioni-conclusive",
    "href": "chapters/eda/11_outlier.html#riflessioni-conclusive",
    "title": "24¬† Outlier",
    "section": "\n24.7 Riflessioni Conclusive",
    "text": "24.7 Riflessioni Conclusive\nAbbiamo mostrato come identificare gli outlier in modo coerente e trasparente, allineandoci alle buone pratiche correnti. Tuttavia, la buona pratica non si limita alla scelta degli algoritmi: √® fondamentale anche preregistrare le decisioni, essere coerenti, trasparenti e fornire giustificazioni.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_outlier.html#esercizi",
    "href": "chapters/eda/11_outlier.html#esercizi",
    "title": "24¬† Outlier",
    "section": "\n24.8 Esercizi",
    "text": "24.8 Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nDomande teoriche\n\nCos‚Äô√® un outlier?\nPerch√© √® importante identificare e trattare correttamente gli outlier?\nDescrivi brevemente il metodo del boxplot per identificare gli outlier.\nCosa si intende per Interquartile Range (IQR) e come viene utilizzato per individuare gli outlier?\nQual √® la differenza tra il metodo IQR e il Median Absolute Deviation (MAD) per l‚Äôidentificazione degli outlier?\nCos‚Äô√® la distanza di Mahalanobis e in che modo pu√≤ aiutare nell‚Äôidentificazione degli outlier multivariati?\nPerch√© la distanza di Mahalanobis classica potrebbe non essere robusta? Come si pu√≤ migliorare l‚Äôapproccio?\nQuali sono le opzioni per gestire gli outlier una volta identificati?\nCos‚Äô√® la Winsorizzazione e in quali casi potrebbe essere utile?\nPerch√© √® importante la trasparenza nelle decisioni riguardanti gli outlier?\n\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\n\n\nCos‚Äô√® un outlier?\n\nUn outlier √® un‚Äôosservazione che si discosta significativamente dalla maggior parte delle altre osservazioni in un insieme di dati. Pu√≤ essere dovuto ad errori di misura, errori di inserimento dati o a casi estremi ma validi.\n\n\n\nPerch√© √® importante identificare e trattare correttamente gli outlier?\n\nGli outlier possono distorcere i risultati dell‚Äôanalisi statistica, portando a conclusioni errate. Identificarli e trattarli correttamente aiuta a ridurre l‚Äôeffetto di questi valori anomali sulle statistiche descrittive e sulle inferenze statistiche.\n\n\n\nDescrivi brevemente il metodo del boxplot per identificare gli outlier.\n\nIl boxplot visualizza la distribuzione di una variabile, mostrando la mediana, il primo e il terzo quartile, e due estremi (‚Äúwhiskers‚Äù). I punti al di fuori di questi whiskers sono considerati potenziali outlier.\n\n\n\nCosa si intende per Interquartile Range (IQR) e come viene utilizzato per individuare gli outlier?\n\nL‚ÄôIQR √® la differenza tra il terzo e il primo quartile di un insieme di dati. Valori inferiori a \\(Q1 - 1.5 \\times IQR\\) o superiori a \\(Q3 + 1.5 \\times IQR\\) sono considerati outlier moderati. Valori oltre \\(Q1 - 3 \\times IQR\\) o \\(Q3 + 3 \\times IQR\\) sono definiti ‚Äúfar out‚Äù outliers.\n\n\n\nQual √® la differenza tra il metodo IQR e il Median Absolute Deviation (MAD) per l‚Äôidentificazione degli outlier?\n\nIl metodo IQR si basa sulla differenza tra il terzo e il primo quartile, mentre il MAD utilizza la mediana delle deviazioni assolute dalla mediana per stimare la dispersione. Il MAD √® meno sensibile agli outlier rispetto all‚ÄôIQR e alla deviazione standard, rendendolo preferibile per dati con distribuzioni non normali.\n\n\n\nCos‚Äô√® la distanza di Mahalanobis e in che modo pu√≤ aiutare nell‚Äôidentificazione degli outlier multivariati?\n\nLa distanza di Mahalanobis misura quanto un punto si discosta dal centro della distribuzione di un set di dati multivariato, tenendo conto della correlazione tra le variabili. Valori con distanze di Mahalanobis elevate sono potenziali outlier multivariati.\n\n\n\nPerch√© la distanza di Mahalanobis classica potrebbe non essere robusta? Come si pu√≤ migliorare l‚Äôapproccio?\n\nLa distanza di Mahalanobis classica pu√≤ essere distorta dalla presenza di outlier, che influenzano il calcolo del centro e della variabilit√† complessiva. Un approccio pi√π robusto √® la Minimum Covariance Determinant (MCD), che riduce l‚Äôinfluenza degli outlier nel processo di identificazione.\n\n\n\nQuali sono le opzioni per gestire gli outlier una volta identificati?\n\nLe opzioni includono: verificare la fonte del dato per possibili errori, rimuovere gli outlier estremi, usare metodi robusti come la mediana o il MAD, trasformare i dati (ad esempio, logaritmi), e limitare gli outlier attraverso la Winsorizzazione.\n\n\n\nCos‚Äô√® la Winsorizzazione e in quali casi potrebbe essere utile?\n\nLa Winsorizzazione √® una tecnica che consiste nel sostituire gli outlier estremi con il valore massimo o minimo accettabile. √à utile quando si vuole mantenere la dimensione del dataset e ridurre l‚Äôimpatto degli outlier senza rimuoverli completamente.\n\n\nPerch√© √® importante la trasparenza nelle decisioni riguardanti gli outlier?\n\n\nLa trasparenza aiuta a garantire la riproducibilit√† e la validit√† dell‚Äôanalisi. Documentare le decisioni, inclusi i metodi e i threshold utilizzati, consente ad altri di capire e valutare l‚Äôimpatto di queste decisioni sui risultati dell‚Äôanalisi.\n\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nEsercizio: Gestione degli Outlier nella Scala di Soddisfazione di Vita (SWLS)\nScopo:\nImparare a individuare e correggere gli outlier in un dataset che misura la soddisfazione di vita (SWLS). L‚Äôesercizio prevede l‚Äôinserimento artificiale di due outlier (uno molto alto e uno molto basso) nei dati raccolti, per poi gestirli con i metodi discussi nel capitolo. Infine, bisogner√† consegnare:\n\nUn file .qmd (Quarto) con tutto il codice e i commenti delle operazioni svolte.\n\nUn file CSV finale con i dati ‚Äúpuliti‚Äù (ossia senza i due outlier anomali) o con i valori modificati mediante il metodo scelto (winsorizzazione, rimozione, correzione, ecc.).\n\nFasi e Istruzioni\n\n\nScarica o carica il dataset SWLS\n\nNominare il dataset originale, ad esempio SWLS_raw.csv, contenente i punteggi dei partecipanti sulla Scala di Soddisfazione di Vita (SWLS).\n\nAssicurati di avere nel dataset almeno le colonne:\n\n\nid (identificatore univoco del partecipante)\n\n\nswls_score (punteggio totale alla scala SWLS)\n\n\n\n\n\nCrea due outlier artificiali\n\nScegli un partecipante al quale assegnare un valore estremamente basso di swls_score (es. -999) e un altro partecipante con un valore estremamente alto (es. 999).\n\nSpiega brevemente nel .qmd dove e come hai inserito questi valori.\n\n\n\nAnalizza i dati alla ricerca di outlier\n\nVisualizza la distribuzione tramite un boxplot e/o un istogramma.\n\nCalcola i valori soglia utilizzando almeno uno dei metodi visti:\n\nIQR (intervallo interquartile)\n\nMAD (Median Absolute Deviation)\n\n\n\nMostra quali osservazioni vengono segnalate come potenziali outlier.\n\n\n\nDecidi come gestire gli outlier\n\nScegli se rimuoverli, winsorizzarli o correggerli.\n\nGiustifica la tua scelta: spiega perch√© quel metodo √® appropriato per questi dati o perch√© preferisci un approccio rispetto a un altro.\n\n\n\nGenera i dati ‚Äúpuliti‚Äù\n\nApplica il metodo selezionato.\n\nSalva il dataset risultante (senza i valori anomali o con i valori modificati) in un file CSV chiamato SWLS_clean.csv.\n\n\n\nDocumenta tutto in un file .qmd\n\nIncludi codice R, commenti e brevi spiegazioni testuali dei vari passaggi.\n\nMostra i risultati rilevanti (boxplot, calcolo dei soglie IQR/MAD, elenco degli outlier individuati, ecc.).\n\nAssicurati di eseguire il rendering del .qmd in modo che l‚Äôistruttore possa vedere sia l‚Äôoutput che il codice.\n\n\n\nConsegnare i file\n\n\nFile .qmd: deve contenere tutto il codice e i passaggi effettuati (inclusi grafici, calcoli e spiegazioni).\n\n\nFile CSV ‚Äúpulito‚Äù (SWLS_clean.csv): con i dati finali dopo il trattamento degli outlier.\n\n\n\nSuggerimenti\n\n\nStruttura il tuo .qmd in sezioni (ad es. Caricamento dati, Creazione outlier artificiali, Identificazione outlier, Gestione outlier, Salvataggio dati puliti).\n\n\nMotiva sempre le scelte, soprattutto se rimuovi o modifichi i dati originali: spiega perch√© il valore appare come un errore di misura o un valore estremo.\n\n\nFai controlli incrociati: potresti usare pi√π di un metodo (boxplot, IQR, MAD) per vedere se l‚Äôoutlier viene segnalato in tutti i casi.\n\n\nDocumenta la tua strategia di trasparenza nell‚Äôanalisi: note sull‚Äôeventuale preregistrazione di come avresti gestito gli outlier o su come hai deciso i threshold.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_outlier.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/11_outlier.html#informazioni-sullambiente-di-sviluppo",
    "title": "24¬† Outlier",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] MASS_7.3-65        datawizard_1.0.2   performance_0.13.0\n#&gt;  [4] thematic_0.1.6     MetBrewer_0.2.0    ggokabeito_0.1.0  \n#&gt;  [7] see_0.11.0         gridExtra_2.3      patchwork_1.3.0   \n#&gt; [10] bayesplot_1.11.1   psych_2.5.3        scales_1.3.0      \n#&gt; [13] markdown_2.0       knitr_1.50         lubridate_1.9.4   \n#&gt; [16] forcats_1.0.0      stringr_1.5.1      dplyr_1.1.4       \n#&gt; [19] purrr_1.0.4        readr_2.1.5        tidyr_1.3.1       \n#&gt; [22] tibble_3.2.1       ggplot2_3.5.1      tidyverse_2.0.0   \n#&gt; [25] rio_1.2.3          here_1.0.1        \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.9.1   \n#&gt; [13] viridisLite_0.4.2 mnormt_2.1.1      cli_3.6.4         rlang_1.1.5      \n#&gt; [17] munsell_0.5.1     withr_3.0.2       tools_4.4.2       parallel_4.4.2   \n#&gt; [21] tzdb_0.5.0        colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5      \n#&gt; [25] R6_2.6.1          lifecycle_1.0.4   htmlwidgets_1.6.4 insight_1.1.0    \n#&gt; [29] pkgconfig_2.0.3   pillar_1.10.1     gtable_0.3.6      glue_1.8.0       \n#&gt; [33] xfun_0.51         tidyselect_1.2.1  rstudioapi_0.17.1 farver_2.1.2     \n#&gt; [37] htmltools_0.5.8.1 nlme_3.1-167      labeling_0.4.3    rmarkdown_2.29   \n#&gt; [41] compiler_4.4.2",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_outlier.html#bibliografia",
    "href": "chapters/eda/11_outlier.html#bibliografia",
    "title": "24¬† Outlier",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nLeys, C., Delacre, M., Mora, Y. L., Lakens, D., & Ley, C. (2019). How to classify, detect, and manage univariate and multivariate outliers, with emphasis on pre-registration. International Review of Social Psychology, 32(1).\n\n\nSimmons, J. P., Nelson, L. D., & Simonsohn, U. (2011). False-positive psychology: Undisclosed flexibility in data collection and analysis allows presenting anything as significant. Psychological science, 22(11), 1359‚Äì1366.\n\n\nTh√©riault, R., Ben-Shachar, M. S., Patil, I., L√ºdecke, D., Wiernik, B. M., & Makowski, D. (2024). Check your outliers! An introduction to identifying statistical outliers in R with easystats. Behavior Research Methods, 56(4), 4162‚Äì4172.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/probability/introduction_probability.html",
    "href": "chapters/probability/introduction_probability.html",
    "title": "Probabilit√†",
    "section": "",
    "text": "Questa sezione della dispensa introduce la teoria della probabilit√†, una componente essenziale per la ricerca scientifica. Nell‚Äôambito della scienza, l‚Äôinferenza induttiva √® di fondamentale importanza, e la probabilit√† svolge un ruolo cruciale in questo processo. Poich√© la scienza non pu√≤ garantire verit√† assolute, ma solo approssimazioni corroborate da evidenze, la probabilit√† diventa lo strumento chiave per quantificare il grado di incertezza associato a un‚Äôipotesi, a una previsione o a un modello. Due scuole di pensiero dominano questo scenario: l‚Äôapproccio bayesiano, che interpreta la probabilit√† come misura soggettiva del grado di fiducia in una proposizione, e l‚Äôapproccio frequentista, che la definisce come frequenza relativa di un evento osservabile in condizioni ripetute. Sebbene queste prospettive differiscano radicalmente nell‚Äôinterpretazione filosofica, entrambe poggiano sullo stesso formalismo matematico. Padroneggiare i concetti fondamentali della probabilit√† √® dunque essenziale per comprendere sia gli strumenti dell‚Äôinferenza bayesiana, sia quelli classici dell‚Äôanalisi statistica.\nQuesta sezione fornisce le basi teoriche necessarie per navigare entrambi i paradigmi. Partiremo dalle definizioni di probabilit√† e dalle sue regole fondamentali, per poi introdurre concetti come la probabilit√† condizionale e il teorema di Bayes, che stanno alla base dell‚Äôaggiornamento delle credenze alla luce di nuovi dati. Esploreremo inoltre le propriet√† delle variabili casuali, distinguendo tra distribuzioni discrete (a massa di probabilit√†) e continue (a densit√† di probabilit√†). Infine, discuteremo la funzione di verosimiglianza, comune alle due scuole: mentre i bayesiani la integrano con informazioni a priori per costruire distribuzioni posteriori, i frequentisti ne sfruttano il principio della massima verosimiglianza per stimare parametri in modo puramente empirico, senza assumere conoscenze preliminari.",
    "crumbs": [
      "Probabilit√†"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html",
    "href": "chapters/probability/01_intro_prob.html",
    "title": "25¬† Interpretazione della probabilit√†",
    "section": "",
    "text": "25.1 Introduzione\nIn questo capitolo esamineremo come la teoria della probabilit√† si sia affermata come uno strumento per descrivere e interpretare l‚Äôincertezza, muovendoci tra diverse concezioni (classica, frequentista e bayesiana) e riconoscendo il ruolo fondamentale della simulazione nel chiarire concetti probabilistici, come la legge dei grandi numeri. Prima, per√≤, √® utile soffermarsi sull‚Äôidea di casualit√† e sul nesso che la lega all‚Äôincertezza.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Interpretazione della probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#casualit√†-e-incertezza",
    "href": "chapters/probability/01_intro_prob.html#casualit√†-e-incertezza",
    "title": "25¬† Interpretazione della probabilit√†",
    "section": "\n25.2 Casualit√† e Incertezza",
    "text": "25.2 Casualit√† e Incertezza\nDavid Spiegelhalter, in un recente articolo pubblicato su Nature, sottolinea come la vita sia pervasa dall‚Äôincertezza: non sappiamo con certezza cosa √® accaduto in passato, cosa avverr√† in futuro n√© abbiamo una completa comprensione di ci√≤ che ci circonda (Spiegelhalter, 2024). Questa condizione di ignoranza spinge a interpretare la casualit√† come un modello che, pur non fornendo previsioni deterministiche, rivela spesso regolarit√† statistiche. In altre parole, i singoli eventi possono apparire imprevedibili, ma l‚Äôosservazione di molti casi analoghi svela andamenti medi stabili e quantificabili.\nDa questa prospettiva nasce la teoria della probabilit√†, intesa come linguaggio matematico rigoroso per quantificare e modellare l‚Äôincertezza. Attraverso concetti quali valore atteso, distribuzioni di probabilit√† e frequenze relative, la probabilit√† permette di passare dalla nozione intuitiva di caso all‚Äôanalisi formale dei fenomeni incerti. Anche nell‚Äôambito psicologico, la probabilit√† supporta la ricerca, l‚Äôinterpretazione di dati sperimentali e la presa di decisioni cliniche, fornendo una base teorica su cui costruire ipotesi e valutare rischi e benefici.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Interpretazione della probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#il-ruolo-della-probabilit√†-nello-studio-dei-fenomeni",
    "href": "chapters/probability/01_intro_prob.html#il-ruolo-della-probabilit√†-nello-studio-dei-fenomeni",
    "title": "25¬† Interpretazione della probabilit√†",
    "section": "\n25.3 Il ruolo della probabilit√† nello studio dei fenomeni",
    "text": "25.3 Il ruolo della probabilit√† nello studio dei fenomeni\nLa teoria della probabilit√† consente di trasformare le intuizioni sulla casualit√† in un linguaggio rigoroso. Tra le sue funzioni fondamentali si evidenziano:\n\nQuantificare l‚Äôincertezza\nAssegnare valori numerici agli esiti possibili rende esplicita la probabilit√† di ogni evento. Per esempio, nel lancio di un dado, dire che ogni faccia ha 1/6 di probabilit√† di uscire equivale a tradurre la casualit√† in un concetto misurabile.\nCombinare informazioni\nLe regole di somma e prodotto permettono di integrare probabilit√† relative a eventi diversi: la somma si utilizza per eventi mutualmente esclusivi (es. prendere o non prendere un voto specifico a un esame), mentre il prodotto si applica a eventi ritenuti indipendenti (es. risultati di pi√π estrazioni da un‚Äôurna).\nAggiornare le credenze\nSecondo la prospettiva bayesiana, le probabilit√† non sono statiche, ma si modificano con il sopraggiungere di nuove evidenze. Un tipico esempio √® la revisione di previsioni meteorologiche alla luce di dati pi√π recenti, come la pressione atmosferica o l‚Äôumidit√†.\nOttimizzare le decisioni\nLa probabilit√† guida valutazioni di rischi e benefici, aiutando a scegliere in modo razionale quando l‚Äôesito di un‚Äôazione non √® garantito. Questa idea si applica tanto in campo clinico, per decidere il protocollo di un trattamento sperimentale, quanto in ambito psicologico, per valutare il processo terapeutico per un disturbo alimentare.\n\nQueste funzioni costituiscono l‚Äôossatura della teoria della probabilit√† e la rendono uno strumento essenziale per affrontare contesti in cui l‚Äôinformazione √® parziale o i fenomeni hanno una componente di casualit√† irriducibile.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Interpretazione della probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#due-tipi-di-incertezza-epistemica-e-ontologica",
    "href": "chapters/probability/01_intro_prob.html#due-tipi-di-incertezza-epistemica-e-ontologica",
    "title": "25¬† Interpretazione della probabilit√†",
    "section": "\n25.4 Due tipi di incertezza: epistemica e ontologica",
    "text": "25.4 Due tipi di incertezza: epistemica e ontologica\nL‚Äôanalisi probabilistica si confronta con due tipologie di incertezza:\n\nEpistemica\nDipende dai limiti della conoscenza o dai dati a disposizione. Se in un esperimento non si controllano adeguatamente variabili importanti, la nostra misura di probabilit√† risente di queste lacune. L‚Äôincertezza epistemica pu√≤ ridursi affinando il disegno sperimentale o ampliando il numero di osservazioni.\nOntologica\nInerente al fenomeno stesso, √® indipendente dal grado di controllo o di osservazione possibile. Il lancio di un dado rimane imprevedibile anche se conoscessimo le leggi fisiche in gioco e le condizioni iniziali con incredibile precisione. Questo tipo di casualit√† √® connaturato al sistema, e dunque impossibile da eliminare del tutto.\n\nUn celebre riferimento in questo contesto √® Niels Bohr, secondo il quale la scienza non fornisce verit√† assolute, ma costruisce modelli che descrivono la realt√† entro i limiti concettuali di cui disponiamo. In questa prospettiva, l‚Äôincertezza ontologica segna il confine tra ci√≤ che √® conoscibile e la complessit√† insita nella natura dei fenomeni.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Interpretazione della probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#cenni-storici",
    "href": "chapters/probability/01_intro_prob.html#cenni-storici",
    "title": "25¬† Interpretazione della probabilit√†",
    "section": "\n25.5 Cenni Storici",
    "text": "25.5 Cenni Storici\nLa teoria della probabilit√† affonda le sue radici nei giochi d‚Äôazzardo, pratiche antiche che stimolarono riflessioni sui meccanismi del caso. Fu per√≤ nel XVII secolo che inizi√≤ a prendere forma una sistematizzazione scientifica, grazie al dialogo tra Blaise Pascal e Pierre de Fermat. I due matematici risposero alle questioni poste dal Chevalier de M√©r√©, un aristocratico appassionato di scommesse. Tra i dilemmi pi√π noti vi era il cosiddetto ‚Äúproblema della ripartizione equa‚Äù: come distribuire il premio di un torneo di dadi interrotto prematuramente, basandosi sulle chance residuali di vittoria dei giocatori?\n\nDue giocatori, A e B, stanno partecipando a un gioco in cui il primo a vincere sei round consecutivi ottiene il premio. Dopo sei round, A ha vinto cinque round e B uno. Poich√© il gioco viene interrotto, come si dovrebbe dividere il premio in modo equo?\n\nQuesto problema spinse Pascal e Fermat a sviluppare i primi strumenti matematici per calcolare la probabilit√† degli eventi futuri, dando vita a un metodo rigoroso per affrontare l‚Äôincertezza. Stimando, ad esempio, che A avesse il 97% di probabilit√† di vincere e B il 3%, sembrava equo dividere il premio nella stessa proporzione. La soluzione, che prevedeva il calcolo degli esiti attesi e delle relative probabilit√†, segn√≤ una svolta epocale, gettando le basi per la formalizzazione matematica della disciplina.\nChristian Huygens, con il trattato De Ratiociniis in Ludo Aleae (1657), approfond√¨ le applicazioni nel gioco d‚Äôazzardo, mentre figure come Leibniz e John Graunt esplorarono rispettivamente la probabilit√† come strumento logico-giuridico e come frequenza statistica.\nJacob Bernoulli, nell‚ÄôArs Conjectandi (1713), formul√≤ la legge dei grandi numeri, evidenziando come ripetute osservazioni empiriche rivelino regolarit√† nascoste, nonostante l‚Äôapparente imprevedibilit√† dei singoli eventi. Questo lavoro pose le basi per due visioni contrapposte: la probabilit√† come misura dell‚Äôincertezza epistemica (grado di fiducia razionale) e come propriet√† oggettiva legata alla frequenza.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Interpretazione della probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#la-dualit√†-epistemologica-e-frequenziale",
    "href": "chapters/probability/01_intro_prob.html#la-dualit√†-epistemologica-e-frequenziale",
    "title": "25¬† Interpretazione della probabilit√†",
    "section": "\n25.6 La dualit√† Epistemologica e Frequenziale",
    "text": "25.6 La dualit√† Epistemologica e Frequenziale\nHacking (2006) ha sottolineato che, a partire dal contributo di Bernoulli, la probabilit√† si svilupp√≤ storicamente lungo due assi: da un lato come misura della credibilit√† di un‚Äôipotesi (prospettiva epistemologica), dall‚Äôaltro come descrizione della frequenza con cui un evento compare in circostanze ripetute (prospettiva frequenziale). Questa tensione √® tuttora visibile nella dicotomia fra metodi bayesiani e metodi frequentisti.\n\n25.6.1 Frequentismo\nIl frequentismo intende la probabilit√† come frequenza relativa dell‚Äôevento in un numero potenzialmente infinito di prove. I fondatori di questo approccio, tra cui Ronald A. Fisher e poi Jerzy Neyman ed Egon Pearson, hanno posto le basi dell‚Äôinferenza statistica classica (test di ipotesi, intervalli di confidenza, analisi di varianza).\nIl modello paradigmatico di questo approccio √® il cosiddetto modello dell‚Äôurna. Si immagina di estrarre in modo casuale una pallina da un‚Äôurna contenente palline visivamente indistinguibili, ma numerate: ogni pallina ha la stessa probabilit√† di essere scelta, riproducendo cos√¨ l‚Äôidea di eventi equiprobabili. Questa concezione si basa su una rappresentazione astratta e ideale della casualit√† che, nella realt√†, trova riscontro in ambiti quali il campionamento statistico e gli studi clinici randomizzati (in cui ogni paziente ha la stessa probabilit√† di essere assegnato al gruppo sperimentale o di controllo). Il limite di questa visione emerge nei casi in cui non √® possibile accumulare un gran numero di osservazioni o quando l‚Äôevento √® unico e irripetibile.\n\n25.6.2 Bayesianesimo\nIl bayesianesimo si basa sull‚Äôidea di un continuo aggiornamento delle nostre credenze. Con il teorema di Bayes si parte da una conoscenza iniziale (detta prior) e la si aggiorna con i dati osservati (likelihood) per giungere a una stima a posteriori.\n\n25.6.2.1 Probabilit√† come Costruzione Soggettiva\nL‚Äôapproccio bayesiano √® basato su un‚Äôinterpretazione soggettiva della probabilit√†, secondo cui tale concetto rappresenta il grado di fiducia (o credenza) che un individuo o un gruppo attribuisce al verificarsi di un evento, sulla base delle informazioni disponibili. Un esempio pratico √® la previsione di pioggia al 70%: non si tratta di un fenomeno fisico oggettivo ‚Äì come avverrebbe in un‚Äôottica frequenzialista ‚Äì bens√¨ del risultato di dati storici, modelli climatici e continue rivalutazioni.\nBruno de Finetti ha spinto all‚Äôestremo questa prospettiva soggettivista, riassumendo il suo pensiero con la celebre affermazione: ‚ÄúLa probabilit√† non esiste‚Äù. In altre parole, la probabilit√† non sarebbe una propriet√† fisica intrinseca degli eventi, ma un indicatore di quanto ‚Äúsi √® pronti a scommettere‚Äù sulla base delle informazioni e delle convinzioni possedute. Sebbene tali convinzioni debbano rispettare gli assiomi della probabilit√† per risultare logicamente coerenti, la definizione puntuale di quanto un evento sia ‚Äúcerto‚Äù o ‚Äúprobabile‚Äù dipende dalla prospettiva e dalle informazioni dell‚Äôosservatore.\nFrank Ramsey, nel 1926, fu uno dei primi a formalizzare questa idea, definendo la probabilit√† come grado di credenza individuale coerente con gli assiomi matematici (Ramsey, 1926). Pochi anni dopo, nel 1939, Jeffreys (1998) illustr√≤ in ‚ÄúTheory of Probability‚Äù una tra le prime esposizioni moderne dei metodi bayesiani. Successivamente, Fishburn (1986) forn√¨ una rigorosa formalizzazione matematica degli assiomi della probabilit√† soggettiva, mentre Press (2009) contribu√¨ ad ampliare l‚Äôambito di applicazione di questa prospettiva, dimostrando la sua importanza come strumento per affrontare l‚Äôincertezza in ambito scientifico. Per una panoramica storica sullo sviluppo del pensiero bayesiano, si vedano anche Bayesian Methods: General Background e Philosophy of Statistics.\nIn questo quadro, l‚Äôattenzione si sposta dalla realt√† oggettiva alla costruzione umana della probabilit√†, ponendo in evidenza il ruolo dei giudizi, delle ipotesi e delle informazioni disponibili. La probabilit√† non √® dunque una propriet√† del mondo, ma una misura del grado di fiducia razionale che un soggetto idealizzato assegna all‚Äôaffermazione di un evento, basandosi sulle conoscenze (spesso incomplete) di cui dispone. Questo soggetto ideale √® concepito come privo di emozioni, pregiudizi o bias cognitivi, cos√¨ da agire esclusivamente sulla base della logica e delle evidenze. Tale impostazione si applica in modo particolarmente efficace in contesti dove i dati sono limitati o l‚Äôincertezza √® elevata, come spesso accade negli studi psicologici, in cui il comportamento umano mal si presta a una descrizione puramente frequenzialista.\n\n\n\n\n\n\nTerminologia\n\n\n\nIl termine probabilit√† soggettiva viene spesso frainteso come mancanza di rigore. Per questo motivo sono state proposte alternative:\n\n\nLindley (2013) adotta il termine probabilit√† personale, per sottolineare l‚Äôaspetto individuale (ma razionale) di tale definizione.\n\n\nHowson & Urbach (2006) preferisce probabilit√† epistemica, enfatizzando il legame con la conoscenza e l‚Äôincertezza dovuta a informazioni limitate.\n\nAutori come Kaplan (2023) utilizzano tali alternative terminologiche per evidenziare in modo pi√π neutrale il ruolo fondamentale della probabilit√† come strumento scientifico.\n\n\nUn aspetto importante che ha contribuito a promuovere la diffusione contemporanea dell‚Äôapproccio bayesiano √® stata la scoperta, sul finire degli anni ‚Äô80, dei metodi Monte Carlo Markov chain (MCMC). Queste tecniche hanno reso computazionalmente accessibili modelli e calcoli altrimenti irrealizzabili, favorendo la rinascita e l‚Äôulteriore evoluzione dei metodi bayesiani.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Interpretazione della probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#i-due-paradigmi-della-probabilit√†-in-psicologia",
    "href": "chapters/probability/01_intro_prob.html#i-due-paradigmi-della-probabilit√†-in-psicologia",
    "title": "25¬† Interpretazione della probabilit√†",
    "section": "\n25.7 I Due Paradigmi della Probabilit√† in Psicologia",
    "text": "25.7 I Due Paradigmi della Probabilit√† in Psicologia\nIn psicologia, entrambi i paradigmi hanno risvolti importanti. L‚Äôapproccio frequentista √® ancora dominante nell‚Äôanalisi dei dati (si pensi al largo uso dei test di significativit√†), ma il bayesianesimo sta guadagnando terreno, poich√© permette di integrare informazioni pregresse in modo trasparente e di esprimere in modo diretto la probabilit√† di un‚Äôipotesi.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Interpretazione della probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#dalla-teoria-alla-pratica-simulazioni-con-r",
    "href": "chapters/probability/01_intro_prob.html#dalla-teoria-alla-pratica-simulazioni-con-r",
    "title": "25¬† Interpretazione della probabilit√†",
    "section": "\n25.8 Dalla teoria alla Pratica: Simulazioni con R",
    "text": "25.8 Dalla teoria alla Pratica: Simulazioni con R\nNello studio della probabilit√† e della statistica, l‚Äôanalisi analitica pu√≤ risultare complessa in contesti con modelli intricati o distribuzioni non standard. In questi casi, la simulazione al computer emerge come strumento didattico e metodologico essenziale. Utilizzando linguaggi di programmazione come R, √® possibile replicare virtualmente un esperimento migliaia di volte, osservando empiricamente la distribuzione degli esiti e stimando probabilit√† attraverso il metodo Monte Carlo. Questo approccio non solo facilita la comprensione di concetti astratti, ma consente anche di validare risultati teorici in scenari reali.\n\n25.8.1 Legge dei Grandi Numeri\nUn principio fondamentale esplorabile attraverso simulazioni √® la legge dei grandi numeri (LLN), pilastro dell‚Äôapproccio frequentista. La LLN stabilisce che la frequenza relativa di un evento converge alla sua probabilit√† teorica all‚Äôaumentare del numero di prove, pur preservando l‚Äôimprevedibilit√† dei singoli esiti. Ad esempio, in una sequenza di lanci di una moneta equa, la proporzione di ‚Äúteste‚Äù osciller√† inizialmente in modo marcato, ma tender√† progressivamente a stabilizzarsi attorno al 50%.\nQuesto fenomeno riflette due aspetti chiave:\n\n\nRiduzione della variabilit√†: la media campionaria diventa sempre pi√π affidabile con l‚Äôaumentare della numerosit√† del campione.\n\n\nSeparazione tra singoli eventi e comportamento aggregato: la LLN non elimina l‚Äôincertezza nei casi singoli (es., il risultato del prossimo lancio), ma descrive un pattern prevedibile a livello di popolazione.\n\nLa simulazione seguente illustra questo principio generando quattro sequenze indipendenti di lanci di moneta e calcolando la proporzione cumulativa di ‚Äúteste‚Äù:\n\n\n\n\n\n\n\n\nIl grafico evidenzia due fenomeni: la convergenza verso il valore teorico (linea tratteggiata) e la variabilit√† iniziale tra le sequenze, che si attenua progressivamente. Questo esempio dimostra come la LLN fornisca un ponte tra modelli teorici (es., ‚Äúmoneta equa‚Äù) e osservazioni empiriche, pur rimanendo valida solo in condizioni di ripetibilit√† (stesse probabilit√† in ogni prova) e assenza di bias sistematici.\nLe simulazioni trovano ampio utilizzo in psicologia sia nella formazione che nella ricerca:\n\n\nDidattica: visualizzare il comportamento di indicatori statistici (es., media campionaria) al variare della dimensione del campione, rendendo tangibili concetti come ‚Äúpotenza statistica‚Äù o ‚Äúerrore standard‚Äù.\n\n\nRicerca: testare la robustezza di modelli psicometrici in condizioni controllate, simulando dati con specifiche caratteristiche (es., correlazioni deboli, rumore sperimentale).\n\nQuesti strumenti favoriscono un apprendimento attivo, invitando gli studenti a manipolare parametri (es., probabilit√† di successo, numerosit√† campionaria) e osservarne gli effetti, consolidando cos√¨ l‚Äôintuizione statistica. Tuttavia, √® cruciale ricordare che le simulazioni non sostituiscono la teoria, ma la completano, evidenziandone limiti e presupposti applicativi.\n\n\n\n\n\n\nApprofondimento critico\n\n\n\nLa LLN non elimina sfide metodologiche come bias di campionamento, misurazione imperfetta o fenomeni non stazionari. In psicologia, dove molti costrutti (es., emozioni, attitudini) sono intrinsecamente dinamici, l‚Äôapplicazione della LLN richiede particolare attenzione.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Interpretazione della probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#riflessioni-conclusive",
    "href": "chapters/probability/01_intro_prob.html#riflessioni-conclusive",
    "title": "25¬† Interpretazione della probabilit√†",
    "section": "\n25.9 Riflessioni Conclusive",
    "text": "25.9 Riflessioni Conclusive\nLa teoria della probabilit√†, nata originariamente per analizzare il gioco d‚Äôazzardo, si √® gradualmente trasformata nel corso dei secoli in un pilastro metodologico per affrontare l‚Äôincertezza in un‚Äôampia gamma di contesti, compresa la psicologia. La sua evoluzione storica testimonia un confronto continuo fra interpretazioni epistemiche e frequenzialiste, contribuendo all‚Äôelaborazione di strumenti analitici e pratiche operative ‚Äî dalle procedure inferenziali alla simulazione computerizzata ‚Äî che consentono di modellizzare sistemi complessi.\nDa un punto di vista filosofico, la probabilit√† pu√≤ essere intesa sia come propriet√† del mondo (in chiave frequenzialista), sia come misura della nostra conoscenza (nell‚Äôottica bayesiana e soggettivista). Nel primo caso, le frequenze relative e la legge dei grandi numeri mostrano come, da una moltitudine di eventi, possano emergere regolarit√† e pattern stabili. Nel secondo, l‚Äôenfasi √® posta sulla dimensione umana e fallibile dell‚Äôinferenza: le credenze e le informazioni disponibili influenzano in modo diretto la nostra stima della probabilit√† di un evento.\nAl di l√† di queste differenze interpretative, la probabilit√† si rivela uno strumento insostituibile per pianificare esperimenti, analizzare dati e prendere decisioni in condizioni di incertezza ‚Äì attivit√† centrali nel campo della psicologia. Inoltre, la possibilit√† di integrare metodologie teoriche e simulazioni amplia ulteriormente le prospettive di ricerca e la capacit√† di comprendere i fenomeni studiati. Lungi dall‚Äôessere un semplice calcolo combinatorio, la probabilit√† abbraccia cos√¨ la complessit√† della realt√† e la ricchezza della conoscenza umana, mostrando una versatilit√† che la rende uno dei fondamenti del pensiero scientifico contemporaneo.\n\n\n\n\n\n\nPer chi desidera approfondire, il primo capitolo del testo Bernoulli‚Äôs Fallacy (Clayton, 2021) offre un‚Äôintroduzione molto leggibile alle tematiche della definizione della probabilit√† nella storia della scienza.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Interpretazione della probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#esercizi",
    "href": "chapters/probability/01_intro_prob.html#esercizi",
    "title": "25¬† Interpretazione della probabilit√†",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n\nQuali sono le principali concezioni della probabilit√† esplorate nel capitolo?\nCome viene definita l‚Äôincertezza secondo David Spiegelhalter?\nQual √® il ruolo della casualit√† nella teoria della probabilit√†?\nCome funziona il modello dell‚Äôurna per rappresentare la casualit√†?\nQuali sono alcune applicazioni del modello della casualit√†?\nQuali sono le due principali fonti di incertezza nei fenomeni non deterministici?\nCome viene interpretata la probabilit√† secondo l‚Äôapproccio soggettivista?\nQuali sono le due dimensioni principali del concetto di probabilit√† secondo Hacking?\nQual √® stato il contributo di Pascal e Fermat alla teoria della probabilit√†?\nQuali sono le differenze tra l‚Äôapproccio bayesiano e frequentista nella teoria della probabilit√†?\nQual √® la Legge dei Grandi Numeri e come si applica?\nQuali sono i limiti dell‚Äôinterpretazione frequentista della probabilit√†?\nCome ha influenzato Fisher lo sviluppo della statistica frequentista?\nQual √® stato il ruolo di Jeffreys nella rinascita dell‚Äôapproccio bayesiano?\nCome definisce Bruno de Finetti la probabilit√†?\nQuali sono i principi fondamentali della probabilit√† soggettivista secondo Jaynes?\nQuali sono le alternative terminologiche proposte per la ‚Äúprobabilit√† soggettiva‚Äù?\nQual √® l‚Äôimportanza della simulazione nella comprensione della probabilit√†?\nQuali sono le implicazioni filosofiche della dualit√† della probabilit√†?\nQuali sono i principali contributi storici alla teoria della probabilit√†?\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n\nLe principali concezioni della probabilit√† esplorate nel capitolo sono la visione classica, frequentista e bayesiana.\nSecondo David Spiegelhalter, l‚Äôincertezza √® definita come la ‚Äúconsapevolezza cosciente dell‚Äôignoranza‚Äù, riguardante eventi futuri o passati che non possiamo conoscere con certezza.\nLa casualit√† √® un modello concettuale che aiuta a gestire e quantificare eventi imprevedibili, ma che seguono schemi regolari e riconoscibili.\nIl modello dell‚Äôurna rappresenta la casualit√† attraverso l‚Äôestrazione di palline numerate da un‚Äôurna, dove ogni pallina ha la stessa probabilit√† di essere estratta.\nAlcune applicazioni del modello della casualit√† includono indagini statistiche, sperimentazione scientifica e simulazioni in fisica e psicologia.\nLe due principali fonti di incertezza sono l‚Äôincertezza epistemica (derivante dalla conoscenza limitata) e l‚Äôincertezza ontologica (intrinseca al fenomeno stesso).\nSecondo l‚Äôapproccio soggettivista, la probabilit√† √® una misura del grado di fiducia o convinzione di un individuo riguardo al verificarsi di un evento, basata sulle informazioni disponibili.\nSecondo Hacking, le due dimensioni principali del concetto di probabilit√† sono quella epistemologica (misura della credibilit√†) e quella frequenziale (tendenza osservabile nei fenomeni aleatori).\nPascal e Fermat hanno sviluppato i primi strumenti matematici per calcolare la probabilit√† degli eventi futuri, risolvendo problemi legati al gioco d‚Äôazzardo.\nL‚Äôapproccio bayesiano considera la probabilit√† come una misura soggettiva del grado di fiducia, mentre l‚Äôapproccio frequentista la definisce come la frequenza relativa di un evento in una serie infinita di prove.\nLa Legge dei Grandi Numeri afferma che al crescere del numero di prove, la media dei risultati osservati si avvicina al valore atteso teorico.\nI limiti dell‚Äôinterpretazione frequentista includono la difficolt√† di applicarla a eventi singolari e non ripetibili, e la necessit√† di un numero infinito di prove per definire la probabilit√†.\nFisher ha introdotto concetti chiave come la massima verosimiglianza, i test di significativit√† e l‚Äôanalisi della varianza, contribuendo allo sviluppo della statistica frequentista.\nJeffreys ha contribuito alla rinascita dell‚Äôapproccio bayesiano con il suo libro ‚ÄúTheory of Probability‚Äù, che ha riportato l‚Äôattenzione sui metodi bayesiani.\nBruno de Finetti definisce la probabilit√† come una misura del grado di fiducia razionale basata su informazioni incomplete, affermando che ‚Äúla probabilit√† non esiste‚Äù come propriet√† oggettiva.\nSecondo Jaynes, i principi fondamentali della probabilit√† soggettivista includono l‚Äôintervallo numerico (0-1) e la coerenza logica, basandosi su informazioni disponibili.\nLe alternative terminologiche proposte per la ‚Äúprobabilit√† soggettiva‚Äù includono ‚Äúprobabilit√† personale‚Äù e ‚Äúprobabilit√† epistemica‚Äù.\nLa simulazione √® importante per approssimare probabilit√† empiriche in contesti complessi, dove soluzioni analitiche non sono praticabili, e per comprendere fenomeni probabilistici attraverso modelli numerici.\nLe implicazioni filosofiche della dualit√† della probabilit√† riflettono la tensione tra una descrizione oggettiva della realt√† e la soggettivit√† del processo interpretativo.\nI principali contributi storici alla teoria della probabilit√† includono i lavori di Pascal, Fermat, Huygens, Bernoulli, Fisher, Jeffreys e de Finetti.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Interpretazione della probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#bibliografia",
    "href": "chapters/probability/01_intro_prob.html#bibliografia",
    "title": "25¬† Interpretazione della probabilit√†",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nClayton, A. (2021). Bernoulli‚Äôs Fallacy: Statistical Illogic and the Crisis of Modern Science. Columbia University Press.\n\n\nFishburn, P. C. (1986). The axioms of subjective probability. Statistical Science, 1(3), 335‚Äì345.\n\n\nHacking, I. (2006). The emergence of probability: A philosophical study of early ideas about probability, induction and statistical inference. Cambridge University Press.\n\n\nHowson, C., & Urbach, P. (2006). Scientific reasoning: the Bayesian approach. Open Court Publishing.\n\n\nJeffreys, H. (1998). The theory of probability. OuP Oxford.\n\n\nKaplan, D. (2023). Bayesian statistics for the social sciences. Guilford Publications.\n\n\nLindley, D. V. (2013). Understanding uncertainty. John Wiley & Sons.\n\n\nPress, S. J. (2009). Subjective and objective Bayesian statistics: Principles, models, and applications. John Wiley & Sons.\n\n\nRamsey, F. P. (1926). Truth and probability. In Readings in Formal Epistemology: Sourcebook (pp. 21‚Äì45). Springer.\n\n\nSpiegelhalter, D. (2024). Why probability probably doesn‚Äôt exist (but it is useful to act like it does). Nature, 636(8043), 560‚Äì563.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Interpretazione della probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html",
    "href": "chapters/probability/02_probability_models.html",
    "title": "26¬† Modelli probabilistici",
    "section": "",
    "text": "26.1 Introduzione\nDopo aver esaminato il significato filosofico della probabilit√† nel Capitolo 25, questo capitolo ne sviluppa una trattazione pi√π formale, creando un collegamento tra la riflessione teorica e gli strumenti operativi. Partendo dalla definizione di esperimento casuale ‚Äì come il lancio di una moneta o la somministrazione di un test psicologico ‚Äì costruiremo un framework matematico per analizzare e quantificare le propriet√† di tali esperimenti. In particolare, approfondiremo i concetti di spazio campionario, eventi e propriet√† della probabilit√†, fornendo le basi per un‚Äôinterpretazione rigorosa dei fenomeni complessi in psicologia e nelle scienze sociali.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#introduzione",
    "href": "chapters/probability/02_probability_models.html#introduzione",
    "title": "26¬† Modelli probabilistici",
    "section": "",
    "text": "Domande introduttive\n\n\n\nPrima di esaminare in maniera pi√π formale le basi della teoria della probabilit√†, consideriamo un classico problema della teoria della probabilit√†:\nüîç ‚ÄúQuante persone servono in una stanza perch√© ci sia almeno il 50% di probabilit√† che due condividano lo stesso compleanno?‚Äù\nQuesto problema, noto come problema dei compleanni, fu introdotto dal matematico Richard von Mises nel 1932. La sua soluzione sfida l‚Äôintuizione e rivela quanto le probabilit√† combinatorie possano essere ingannevoli.\nRispondi alle seguenti domande.\n\nCon quante persone pensi si superi il 50% di probabilit√†? (23? 100? 180?)\nCon 30 persone, quale probabilit√† stimi? (10%? 50%? 70%?)\n\nScrivi le tue risposte su un foglietto senza condividere con i compagni.\nPer svolgere un esercizio in classe, compila il seguente modulo su Google Forms.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#esperimenti-casuali",
    "href": "chapters/probability/02_probability_models.html#esperimenti-casuali",
    "title": "26¬† Modelli probabilistici",
    "section": "\n26.2 Esperimenti Casuali",
    "text": "26.2 Esperimenti Casuali\nIl concetto fondamentale della probabilit√† √® l‚Äôesperimento casuale, ovvero un procedimento il cui esito non pu√≤ essere previsto con certezza, ma che pu√≤ essere analizzato quantitativamente. Alcuni esempi di esperimenti casuali includono:\n\nLanciare un dado e osservare il numero ottenuto sulla faccia superiore.\nEstrarre una carta a caso da un mazzo e registrarne il seme e il valore.\nMisurare il livello di stress percepito da un gruppo di individui in un determinato contesto, come durante un esame o un evento stressante.\nContare il numero di risposte corrette fornite dai partecipanti a un test di memoria entro un tempo prestabilito.\nSelezionare casualmente 50 persone e determinare quante mostrano una predisposizione alla creativit√†, misurata attraverso un questionario standardizzato.\nScegliere a caso dieci individui e valutare il loro grado di introversione mediante uno strumento di autovalutazione psicologica.\nSelezionare casualmente 50 persone e contare quante sono mancine.\nScegliere a caso dieci individui e misurarne l‚Äôaltezza.\n\nL‚Äôanalisi probabilistica ha lo scopo di comprendere il comportamento di tali esperimenti attraverso la costruzione di modelli matematici. Una volta formalizzato matematicamente un esperimento casuale, √® possibile calcolare grandezze di interesse, come probabilit√† ed aspettative. Questi modelli possono essere implementati al computer per simulare l‚Äôesperimento e analizzarne i risultati. Inoltre, la modellizzazione matematica degli esperimenti casuali costituisce la base della statistica, disciplina che permette di confrontare diversi modelli e identificare quello pi√π adeguato ai dati osservati.\n\n26.2.1 Il Lancio di una Moneta\nUno degli esperimenti casuali pi√π semplici e fondamentali √® il lancio ripetuto di una moneta. Molti concetti chiave della teoria della probabilit√† possono essere illustrati partendo da questo esperimento elementare. Per studiarne il comportamento, possiamo simularlo al computer utilizzando il linguaggio R.\nDi seguito, un semplice script in R simula 100 lanci di una moneta equa (cio√® con probabilit√† uguali di ottenere Testa o Croce) e rappresenta graficamente la distribuzione dei risultati mediante un diagramma a barre.\n\nset.seed(123) # Imposta il seed per garantire la riproducibilit√†\nx &lt;- runif(100) &lt; 0.5 # Genera 100 numeri casuali e verifica se sono minori di 0.5\nx\n#&gt;   [1]  TRUE FALSE  TRUE FALSE FALSE  TRUE FALSE FALSE FALSE  TRUE FALSE\n#&gt;  [12]  TRUE FALSE FALSE  TRUE FALSE  TRUE  TRUE  TRUE FALSE FALSE FALSE\n#&gt;  [23] FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE FALSE FALSE FALSE\n#&gt;  [34] FALSE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n#&gt;  [45]  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE FALSE  TRUE FALSE\n#&gt;  [56]  TRUE  TRUE FALSE FALSE  TRUE FALSE  TRUE  TRUE  TRUE FALSE  TRUE\n#&gt;  [67] FALSE FALSE FALSE  TRUE FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE\n#&gt;  [78] FALSE  TRUE  TRUE  TRUE FALSE  TRUE FALSE  TRUE  TRUE FALSE FALSE\n#&gt;  [89] FALSE  TRUE  TRUE FALSE  TRUE FALSE  TRUE  TRUE FALSE  TRUE  TRUE\n#&gt; [100] FALSE\n\nNel codice, la funzione runif genera 100 numeri casuali distribuiti uniformemente nell‚Äôintervallo [0, 1]. Confrontando ciascun numero con 0.5, otteniamo un vettore logico che rappresenta il risultato di ogni lancio: Testa (TRUE) o Croce (FALSE).\n\nt &lt;- 1:100 # Sequenza degli indici dei lanci\n\n# Creazione del dataframe per ggplot2\ndat &lt;- tibble(\n  Lancio = t,\n  Risultato = ifelse(x, \"Testa\", \"Croce\")\n)\nhead(dat)\n#&gt; # A tibble: 6 √ó 2\n#&gt;   Lancio Risultato\n#&gt;    &lt;int&gt; &lt;chr&gt;    \n#&gt; 1      1 Testa    \n#&gt; 2      2 Croce    \n#&gt; 3      3 Testa    \n#&gt; 4      4 Croce    \n#&gt; 5      5 Croce    \n#&gt; 6      6 Testa\n\nIl grafico a barre mostra la distribuzione osservata degli esiti.\n\n# Creazione del grafico a barre della distribuzione dei risultati\ndat |&gt;\n  ggplot(aes(x = Risultato)) +\n  geom_bar(aes(y = after_stat(prop), group = 1),\n           fill = \"lightblue\", color = \"black\", width = 0.5) +\n  labs(\n    title = \"Distribuzione dei risultati del lancio della moneta\",\n    x = \"Risultato\",\n    y = \"Frequenza relativa\"\n  )\n\n\n\n\n\n\n\nUn aspetto rilevante di questo esperimento √® l‚Äôandamento della proporzione osservata di esiti ‚ÄúTesta‚Äù in funzione del numero di lanci. Il grafico riportato di seguito illustra l‚Äôevoluzione della media cumulativa degli esiti ‚ÄúTesta‚Äù, che, in accordo con la legge dei grandi numeri, dovrebbe convergere al valore teorico di 0.5.\n\ny &lt;- cumsum(x) / t # Calcola la media cumulativa delle Teste\n\n# Creazione del dataframe per il grafico della media mobile\ndata_mean &lt;- tibble(\n  Lancio = t, \n  Media_Testa = y\n)\n\n# Creazione del grafico della media cumulativa\ndata_mean |&gt;\n  ggplot(\n    aes(x = Lancio, y = Media_Testa)\n  ) +\n  geom_line(linewidth = 1.5) +\n  geom_hline(yintercept = 0.5, linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Media cumulativa del numero di Teste\",\n    x = \"Numero di lanci\",\n    y = \"Frequenza cumulativa di Teste\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nMedia cumulata\n\n\n\n\n\nLa media cumulata (o cumulativa) √® una media che si calcola progressivamente, aggiungendo un nuovo dato alla volta e ricalcolando la media considerando tutti i valori precedenti insieme al nuovo.\nIn pratica, mostra come la media si evolve man mano che vengono inclusi nuovi dati nella serie.\nCome si calcola?\n\nAl primo dato, la media cumulata √® il dato stesso.\n\nAl secondo dato, √® la media tra il primo e il secondo.\n\nAl terzo dato, √® la media tra il primo, il secondo e il terzo.\n\nE cos√¨ via‚Ä¶\n\nFormula intuitiva:\n\\[\n\\text{Media cumulata al passo } n = \\frac{\\text{somma di tutti i dati fino al passo } n}{n}\n\\]\nEsempio pratico:\nSupponiamo di avere i voti di uno studente in 3 verifiche:\n\nVerifica 1: 7\n\nVerifica 2: 6\n\nVerifica 3: 8\n\nLe medie cumulate saranno:\n\nDopo la 1¬™ verifica: \\(\\frac{7}{1} = 7\\).\n\nDopo la 2¬™ verifica: \\(\\frac{7 + 6}{2} = 6.5\\).\n\nDopo la 3¬™ verifica: \\(\\frac{7 + 6 + 8}{3} = 7\\).\n\nA cosa serve?\n\n\nTracciare l‚Äôandamento nel tempo (es.: mostrare come la frequenza di ‚ÄúTesta‚Äù si avvicina gradualmente al 50% teorico man mano che aumentano i lanci).\n\n\nLisciare le fluttuazioni: riduce l‚Äôimpatto di picchi temporanei, mostrando un trend pi√π stabile.\n\n\nValutare prestazioni progressive (es.: un atleta che migliora gradualmente).\n\n\n\n\n\nIl grafico mostra come la media delle Teste oscilla inizialmente a causa della variabilit√† intrinseca dell‚Äôesperimento, ma tende progressivamente a stabilizzarsi intorno a 0.5. Questo fenomeno √® un esempio della Legge dei Grandi Numeri, secondo cui, ripetendo un esperimento casuale un numero sempre maggiore di volte, la frequenza relativa di un evento si avvicina alla sua probabilit√† teorica.\n\n26.2.2 Domande di Interesse\nL‚Äôesperimento casuale del lancio di una moneta porta a numerose domande, tra cui:\n\nQual √® la probabilit√† di ottenere un certo numero \\(x\\) di Teste in 100 lanci?\nQual √® il numero atteso di Teste in un esperimento di 100 lanci?\n\nDal punto di vista statistico, quando osserviamo i risultati di un esperimento reale (ad esempio, 100 lanci di una moneta), possiamo anche porci domande come:\n\nLa moneta √® davvero equa o √® sbilanciata?\nQual √® il miglior metodo per stimare la probabilit√† \\(p\\) di ottenere Testa dalla sequenza osservata di lanci?\nQuanto √® precisa la stima ottenuta e con quale livello di incertezza?\n\nQuesti interrogativi costituiscono la base della statistica inferenziale, che permette di testare ipotesi sulla probabilit√† di un evento e stimare parametri sconosciuti sulla base di dati osservati.\n\n26.2.3 Modellizzazione\n\nLa descrizione matematica di un esperimento casuale si basa su tre elementi fondamentali:\n\nLo spazio campionario: rappresenta l‚Äôinsieme di tutti i possibili esiti dell‚Äôesperimento. Nel caso di esperimenti semplici, lo spazio campionario √® immediato da individuare, mentre in situazioni pi√π complesse √® necessario applicare i principi del calcolo combinatorio.\nGli eventi: sono sottoinsiemi dello spazio campionario e rappresentano gli esiti di interesse. Per analizzare e manipolare gli eventi, utilizziamo gli strumenti della teoria degli insiemi.\nLa probabilit√†: assegna un valore numerico a ciascun evento, indicando la sua probabilit√† di verificarsi. L‚Äôassegnazione delle probabilit√† avviene secondo gli assiomi di Kolmogorov.\n\nNei paragrafi seguenti, analizzeremo ciascuna di queste componenti in dettaglio.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#spazio-campionario",
    "href": "chapters/probability/02_probability_models.html#spazio-campionario",
    "title": "26¬† Modelli probabilistici",
    "section": "\n26.3 Spazio Campionario",
    "text": "26.3 Spazio Campionario\nAnche se non possiamo prevedere con esattezza l‚Äôesito di un singolo esperimento casuale, possiamo comunque definire tutti i risultati che potrebbero verificarsi. L‚Äôinsieme completo di questi esiti possibili si chiama spazio campionario.\n\nDefinizione 26.1 Lo spazio campionario \\(\\Omega\\) di un esperimento casuale √® l‚Äôinsieme di tutti i possibili esiti dell‚Äôesperimento.\n\n\n26.3.1 Esempi di Spazi Campionari\nConsideriamo lo spazio campionario di alcuni esperimenti casuali.\n\nLancio di due dadi consecutivi: \\[\n\\Omega = \\{(1,1), (1,2), \\dots, (6,6)\\}.\n\\]\nTempo di reazione a uno stimolo visivo: \\[\\Omega = \\mathbb{R}^+,\\] ovvero l‚Äôinsieme dei numeri reali positivi.\nNumero di errori in un test di memoria a breve termine: \\[\\Omega = \\{0, 1, 2, \\dots\\}.\\]\nMisurazione delle altezze di dieci persone: \\[\\Omega = \\{(x_1, \\dots, x_{10}) : x_i \\ge 0, \\; i=1,\\dots,10\\} \\subset \\mathbb{R}^{10}.\\]",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#eventi",
    "href": "chapters/probability/02_probability_models.html#eventi",
    "title": "26¬† Modelli probabilistici",
    "section": "\n26.4 Eventi",
    "text": "26.4 Eventi\nSolitamente non siamo interessati a un singolo esito, ma a un insieme di essi. Un evento √® un sottoinsieme dello spazio campionario a cui possiamo assegnare una probabilit√†.\n\nDefinizione 26.2 Un evento √® un sottoinsieme \\(A \\subseteq \\Omega\\) al quale viene assegnata una probabilit√†. Indichiamo gli eventi con lettere maiuscole \\(A, B, C, \\dots\\). Diciamo che l‚Äôevento \\(A\\) si verifica se l‚Äôesito dell‚Äôesperimento appartiene a \\(A\\).\n\n\n26.4.1 Esempi di Eventi\nConsideriamo alcuni possibili eventi definiti sugli spazi campionari descritti sopra.\n\nLancio di due dadi consecutivi.Evento: ‚ÄúLa somma dei due dadi √® uguale a 7‚Äù\\[\nA = \\{(1,6), (2,5), (3,4), (4,3), (5,2), (6,1)\\}.\n\\]\nTempo di reazione a uno stimolo visivo.Evento: ‚ÄúIl tempo di reazione √® inferiore a 2 secondi‚Äù\\[\nA = [0, 2).\n\\]\nNumero di errori in un test di memoria a breve termine.Evento: ‚ÄúIl numero di errori √® al massimo 3‚Äù\\[\nA = \\{0, 1, 2, 3\\}.\n\\]\nMisurazione delle altezze di dieci persone.Evento: ‚ÄúAlmeno due persone hanno un‚Äôaltezza superiore a 180 cm‚Äù\\[\nA = \\{(x_1, \\dots, x_{10}) : \\text{almeno due } x_i &gt; 180\\}.\n\\]\n\nQuesti esempi mostrano come gli eventi possano essere definiti in modo diverso a seconda della natura dello spazio campionario e del contesto di interesse.\n\nEsempio 26.1 Supponiamo di lanciare una moneta tre volte e di annotare se esce Testa (\\(H\\)) o Croce (\\(T\\)) in ogni lancio. Lo spazio campionario √®:\n\\[\n\\Omega = \\{HHH, HHT, HTH, HTT, THH, THT, TTH, TTT\\},\n\\]\ndove, ad esempio, \\(HTH\\) indica che il primo lancio d√† Testa, il secondo Croce e il terzo Testa.\nUn‚Äôalternativa √® rappresentare lo spazio campionario come l‚Äôinsieme dei vettori binari di lunghezza 3, \\(\\{0,1\\}^3\\), dove Testa (\\(H\\)) corrisponde a 1 e Croce (\\(T\\)) a 0.\nL‚Äôevento \\(A\\) ‚Äúil terzo lancio √® Testa‚Äù si esprime come:\n\\[\nA = \\{HHH, HTH, THH, TTH\\}.\n\\]",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#operazioni-sugli-eventi",
    "href": "chapters/probability/02_probability_models.html#operazioni-sugli-eventi",
    "title": "26¬† Modelli probabilistici",
    "section": "\n26.5 Operazioni sugli Eventi",
    "text": "26.5 Operazioni sugli Eventi\nPoich√© gli eventi sono definiti come insiemi, possiamo applicare loro le classiche operazioni insiemistiche.\nUnione (\\(\\cup\\)). L‚Äôunione di due eventi \\(A\\) e \\(B\\) √® l‚Äôinsieme di tutti gli esiti che appartengono almeno a uno dei due:\n\\[\nA \\cup B = \\{\\omega \\in \\Omega : \\omega \\in A \\text{ oppure } \\omega \\in B\\}.\n\\]\nIntersezione (\\(\\cap\\)). L‚Äôintersezione di due eventi √® l‚Äôinsieme degli esiti comuni:\n\\[\nA \\cap B = \\{\\omega \\in \\Omega : \\omega \\in A \\text{ e } \\omega \\in B\\}.\n\\]\nComplemento (\\(A^c\\)). Il complemento di un evento \\(A\\) √® l‚Äôinsieme di tutti gli esiti che non appartengono ad \\(A\\):\n\\[\nA^c = \\{\\omega \\in \\Omega : \\omega \\notin A\\}.\n\\]\nEventi mutuamente esclusivi. Due eventi sono mutuamente esclusivi se non hanno esiti in comune, ovvero:\n\\[\nA \\cap B = \\emptyset.\n\\]\n\nEsempio 26.2 ¬†\n\n# Universo\nU &lt;- 1:10  \n\n# Definizione degli insiemi A e B\nA &lt;- c(1, 2, 3, 4, 5)\nB &lt;- c(4, 5, 6, 7, 8)\n\n# Calcolare l'unione, l'intersezione e il complemento relativo a un universo U\nunion_AB &lt;- union(A, B)\nintersect_AB &lt;- intersect(A, B)\ncomplement_A &lt;- setdiff(U, A)\ncomplement_B &lt;- setdiff(U, B)\n\n# Visualizzazione testuale\ncat(\"Unione A ‚à™ B:\", union_AB, \"\\n\")\n#&gt; Unione A ‚à™ B: 1 2 3 4 5 6 7 8\ncat(\"Intersezione A ‚à© B:\", intersect_AB, \"\\n\")\n#&gt; Intersezione A ‚à© B: 4 5\ncat(\"Complemento di A:\", complement_A, \"\\n\")\n#&gt; Complemento di A: 6 7 8 9 10\ncat(\"Complemento di B:\", complement_B, \"\\n\")\n#&gt; Complemento di B: 1 2 3 9 10\n\n\n# Visualizzazione con diagrammi di Venn\nvenn.plot &lt;- draw.pairwise.venn(\n  area1 = length(A),\n  area2 = length(B),\n  cross.area = length(intersect_AB),\n  category = c(\"A\", \"B\"),\n  fill = c(\"blue\", \"red\"),\n  alpha = 0.5,\n  cat.col = c(\"blue\", \"red\")\n)\ngrid.draw(venn.plot)\n\n\n\n\n\n\n\n\n# Esempio di eventi mutualmente esclusivi\nC &lt;- c(9, 10)  # Insieme disgiunto da A e B\nintersect_AC &lt;- intersect(A, C)  # Deve essere vuoto\n\ncat(\"Intersezione A ‚à© C (eventi mutualmente esclusivi):\", intersect_AC, \"\\n\")\n#&gt; Intersezione A ‚à© C (eventi mutualmente esclusivi):\n\n\n# Visualizzazione di eventi mutualmente esclusivi\nvenn.plot2 &lt;- draw.pairwise.venn(\n  area1 = length(A),\n  area2 = length(C),\n  cross.area = 0,  # Nessuna intersezione\n  category = c(\"A\", \"C\"),\n  fill = c(\"blue\", \"green\"),\n  alpha = 0.5,\n  cat.col = c(\"blue\", \"green\")\n)\ngrid.draw(venn.plot2)\n\n\n\n\n\n\n\n\n\n26.5.1 Propriet√† Fondamentali delle Operazioni su Eventi\n\nIdempotenza: \\[\nA \\cup A = A, \\quad A \\cap A = A.\n\\]\nLeggi di De Morgan: \\[\n(A \\cup B)^c = A^c \\cap B^c, \\quad (A \\cap B)^c = A^c \\cup B^c.\n\\]\nUnione e Intersezione con l‚Äôinsieme vuoto: \\[\nA \\cup \\emptyset = A, \\quad A \\cap \\emptyset = \\emptyset.\n\\]\nUnione e Intersezione con lo spazio campionario: \\[\nA \\cup \\Omega = \\Omega, \\quad A \\cap \\Omega = A.\n\\]\n\nQueste operazioni forniscono la base per costruire e manipolare eventi in contesti probabilistici, permettendo di calcolare probabilit√† e prendere decisioni basate sull‚Äôanalisi degli esiti possibili.\n\nEsempio 26.3 Per gli insiemi definiti nell‚Äôesempio precedente, possiamo verificare la prima legge di De Morgan in R confrontando il complemento dell‚Äôunione con l‚Äôintersezione dei complementi:\n\ncomplemento dell‚Äôunione: \\((A \\cup B)^c\\),\nintersezione dei complementi: \\(A^c \\cap B^c\\).\n\nEseguiamo i calcoli in R:\n\n# Complemento dell'unione: (A ‚à™ B)^c\nsetdiff(U, union(A, B))\n#&gt; [1]  9 10\n\n\n# Intersezione dei complementi: A^c ‚à© B^c\nintersect(setdiff(U, A), setdiff(U, B))\n#&gt; [1]  9 10\n\nSecondo la legge di De Morgan, i due risultati devono coincidere.\n\n\nEsempio 26.4 Consideriamo l‚Äôesperimento del lancio di due dadi. Lo spazio campionario \\(\\Omega\\) √® costituito da tutte le possibili coppie di risultati che possono verificarsi. Ogni dado ha 6 facce, quindi lo spazio campionario √®:\n\\[\n\\Omega = \\{(1,1), (1,2), \\dots, (6,6)\\},\n\\]\nper un totale di \\(6 \\times 6 = 36\\) esiti possibili.\nSiamo interessati all‚Äôevento \\(A\\): ‚Äúla somma dei due dadi √® almeno 10‚Äù. Questo evento include tutte le coppie di risultati la cui somma √® 10, 11 o 12. Gli esiti che soddisfano questa condizione sono:\n\\[\nA = \\{(4,6), (5,5), (5,6), (6,4), (6,5), (6,6)\\}.\n\\]\nEcco come generare lo spazio campionario in R in modo algoritmico e definire l‚Äôevento ‚Äúla somma dei due dadi √® almeno 10‚Äù:\nLo spazio campionario \\(\\Omega\\) √® costituito da tutte le possibili coppie di risultati del lancio di due dadi. In R, possiamo generarlo utilizzando la funzione expand.grid, che crea tutte le combinazioni possibili tra i valori dei due dadi.\n\n# Generazione dello spazio campionario Omega\ndado &lt;- 1:6 # Facce di un dado\nOmega &lt;- expand.grid(Dado1 = dado, Dado2 = dado) # Tutte le combinazioni possibili\n\nL‚Äôoutput sar√† una tabella con 36 righe, una per ogni combinazione possibile:\n\n# Visualizzazione dello spazio campionario\nprint(Omega)\n#&gt;    Dado1 Dado2\n#&gt; 1      1     1\n#&gt; 2      2     1\n#&gt; 3      3     1\n#&gt; 4      4     1\n#&gt; 5      5     1\n#&gt; 6      6     1\n#&gt; 7      1     2\n#&gt; 8      2     2\n#&gt; 9      3     2\n#&gt; 10     4     2\n#&gt; 11     5     2\n#&gt; 12     6     2\n#&gt; 13     1     3\n#&gt; 14     2     3\n#&gt; 15     3     3\n#&gt; 16     4     3\n#&gt; 17     5     3\n#&gt; 18     6     3\n#&gt; 19     1     4\n#&gt; 20     2     4\n#&gt; 21     3     4\n#&gt; 22     4     4\n#&gt; 23     5     4\n#&gt; 24     6     4\n#&gt; 25     1     5\n#&gt; 26     2     5\n#&gt; 27     3     5\n#&gt; 28     4     5\n#&gt; 29     5     5\n#&gt; 30     6     5\n#&gt; 31     1     6\n#&gt; 32     2     6\n#&gt; 33     3     6\n#&gt; 34     4     6\n#&gt; 35     5     6\n#&gt; 36     6     6\n\nL‚Äôevento \\(A\\) √® definito come ‚Äúla somma dei due dadi √® almeno 10‚Äù. Per identificare queste combinazioni, aggiungiamo una colonna che calcola la somma dei due dadi e filtriamo le righe in cui la somma √® maggiore o uguale a 10.\n\n# Aggiunta di una colonna per la somma dei due dadi\nOmega$Somma &lt;- Omega$Dado1 + Omega$Dado2\n\n# Definizione dell'evento A: somma dei due dadi almeno 10\nA &lt;- Omega[Omega$Somma &gt;= 10, ]\n\nL‚Äôoutput sar√† un data frame con le combinazioni in cui la somma √® almeno 10:\n\n# Visualizzazione dell'evento A\nprint(A)\n#&gt;    Dado1 Dado2 Somma\n#&gt; 24     6     4    10\n#&gt; 29     5     5    10\n#&gt; 30     6     5    11\n#&gt; 34     4     6    10\n#&gt; 35     5     6    11\n#&gt; 36     6     6    12\n\nIn sintesi,\n\nlo spazio campionario \\(\\Omega\\) √® stato generato algoritmicamente utilizzando expand.grid;\nl‚Äôevento \\(A\\) √® stato definito filtrando le combinazioni in cui la somma dei due dadi √® almeno 10.\n\n\n\nEsempio 26.5 Consideriamo un esperimento in cui lanciamo una moneta tre volte consecutivamente. Ogni lancio pu√≤ risultare in Testa (H) o Croce (T). Lo spazio campionario \\(\\Omega\\) √® costituito da tutte le possibili sequenze di risultati dei tre lanci. Ci sono \\(2^3 = 8\\) possibili esiti, che possono essere rappresentati come:\n\\[\n\\Omega = \\{\\text{HHH}, \\text{HHT}, \\text{HTH}, \\text{HTT}, \\text{THH}, \\text{THT}, \\text{TTH}, \\text{TTT}\\}.\n\\]\nVogliamo definire in R l‚Äôevento \\(A\\): ‚ÄúIl terzo lancio della moneta dia Testa (H)‚Äù. Questo evento include tutte le sequenze in cui il terzo carattere √® ‚ÄúH‚Äù.\nIn R, possiamo rappresentare lo spazio campionario \\(\\Omega\\) come un vettore di stringhe, dove ogni stringa corrisponde a una sequenza di risultati.\n\n# Definizione dello spazio campionario Omega\nomega &lt;- c(\"HHH\", \"HHT\", \"HTH\", \"HTT\", \"THH\", \"THT\", \"TTH\", \"TTT\")\nomega\n#&gt; [1] \"HHH\" \"HHT\" \"HTH\" \"HTT\" \"THH\" \"THT\" \"TTH\" \"TTT\"\n\nL‚Äôevento \\(A\\) √® costituito da tutte le sequenze in cui il terzo lancio √® Testa (H). Per identificare queste sequenze, utilizziamo la funzione substr, che estrae il terzo carattere da ciascuna stringa e verifica se √® uguale a ‚ÄúH‚Äù.\n\n# Definizione dell'evento A: terzo lancio √® Testa (H)\nA &lt;- omega[substr(omega, 3, 3) == \"H\"]\n\nSpiegazione del codice:\n\n\nsubstr(omega, 3, 3) estrae il terzo carattere da ciascuna stringa nel vettore omega.\n\nsubstr(omega, 3, 3) == \"H\" crea un vettore logico (vero/falso) che indica se il terzo carattere √® ‚ÄúH‚Äù.\n\nomega[...] filtra il vettore omega, mantenendo solo le sequenze che soddisfano la condizione.\n\nL‚Äôoutput sar√†:\n\n# Visualizzazione dell'evento A\nA\n#&gt; [1] \"HHH\" \"HTH\" \"THH\" \"TTH\"\n\nQueste sono le sequenze in cui il terzo lancio √® Testa (H).\nIn sintesi,\n\nlo spazio campionario \\(\\Omega\\) √® stato definito come un vettore di stringhe in R;\nl‚Äôevento \\(A\\) √® stato costruito filtrando le sequenze in cui il terzo carattere √® ‚ÄúH‚Äù, utilizzando la funzione substr(x, start, stop);\nl‚Äôevento \\(A\\) corrisponde alle sequenze: HHH, HTH, THH, TTH.\n\nQuesto esercizio illustra come definire e manipolare eventi in R, utilizzando operazioni di base su stringhe e vettori.\n\n\nEsempio 26.6 Consideriamo l‚Äôesperimento del lancio consecutivo di due dadi. Lo spazio campionario \\(\\Omega\\) √® costituito da tutte le possibili coppie di risultati:\n\\[\n\\Omega = \\{(1, 1), (1, 2), \\dots, (6, 6)\\}.\n\\]\nDefiniamo due eventi:\n\nEvento \\(A\\): ‚ÄúIl primo dado mostra un 6‚Äù.\nQuesto evento include tutte le coppie in cui il primo dado √® 6:\\[\nA = \\{(6, 1), (6, 2), (6, 3), (6, 4), (6, 5), (6, 6)\\}.\n\\]\nEvento \\(B\\): ‚ÄúIl secondo dado mostra un 6‚Äù.\nQuesto evento include tutte le coppie in cui il secondo dado √® 6:\\[\nB = \\{(1, 6), (2, 6), (3, 6), (4, 6), (5, 6), (6, 6)\\}.\n\\]\n\nL‚Äôintersezione \\(A \\cap B\\) rappresenta l‚Äôevento in cui entrambi i dadi mostrano un 6:\n\\[\nA \\cap B = \\{(6, 6)\\}.\n\\]\nImplementazione in R\nPer analizzare gli eventi legati al lancio di due dadi, utilizziamo R per simulare lo spazio campionario e manipolare gli eventi.\n1. Generazione dello spazio campionario\nLa funzione expand.grid crea tutte le combinazioni possibili tra gli elementi di due vettori. Nel nostro caso, generiamo tutte le coppie (Dado1, Dado2):\n\n# Definizione delle facce dei dadi (1-6)\ndado &lt;- 1:6\n\n# Creazione di tutte le 36 combinazioni possibili\nOmega &lt;- expand.grid(\n  Dado1 = dado,\n  Dado2 = dado\n)\n\n# Visualizzazione delle prime 6 righe\nhead(Omega)\n#&gt;   Dado1 Dado2\n#&gt; 1     1     1\n#&gt; 2     2     1\n#&gt; 3     3     1\n#&gt; 4     4     1\n#&gt; 5     5     1\n#&gt; 6     6     1\n\n2. Definizione degli eventi\nEvento A - ‚ÄúPrimo dado = 6‚Äù:\nFiltriamo le righe dove la colonna Dado1 √® uguale a 6:\n\nA &lt;- Omega[Omega$Dado1 == 6, ] # Selezione condizionale\nprint(\"Evento A:\")\n#&gt; [1] \"Evento A:\"\nA\n#&gt;    Dado1 Dado2\n#&gt; 6      6     1\n#&gt; 12     6     2\n#&gt; 18     6     3\n#&gt; 24     6     4\n#&gt; 30     6     5\n#&gt; 36     6     6\n\nEvento B - ‚ÄúSecondo dado = 6‚Äù:\nFiltriamo le righe dove la colonna Dado2 √® uguale a 6:\n\nB &lt;- Omega[Omega$Dado2 == 6, ]\nprint(\"Evento B:\")\n#&gt; [1] \"Evento B:\"\nB\n#&gt;    Dado1 Dado2\n#&gt; 31     1     6\n#&gt; 32     2     6\n#&gt; 33     3     6\n#&gt; 34     4     6\n#&gt; 35     5     6\n#&gt; 36     6     6\n\n3. Calcolo dell‚Äôintersezione A ‚à© B\nMetodo 1: Funzione intersect()\nLa funzione base intersect() confronta intere righe tra due dataframe e restituisce quelle comuni:\n\nA_intersezione_B &lt;- intersect(A, B)\nprint(\"Intersezione con intersect():\")\n#&gt; [1] \"Intersezione con intersect():\"\nA_intersezione_B\n#&gt;   Dado1 Dado2\n#&gt; 1     6     6\n\nMetodo 2: Funzione merge()\nLa funzione base merge() esegue una join naturale sulle colonne con lo stesso nome:\n\nA_intersezione_B &lt;- merge(A, B)\nprint(\"Intersezione con merge():\")\n#&gt; [1] \"Intersezione con merge():\"\nA_intersezione_B\n#&gt;   Dado1 Dado2\n#&gt; 1     6     6\n\nMetodo 3: Pacchetto dplyr\nLa funzione inner_join() mantiene solo le righe presenti in entrambi i dataframe:\n\nA_intersezione_B &lt;- inner_join(A, B, by = c(\"Dado1\", \"Dado2\"))\nprint(\"Intersezione con dplyr:\")\n#&gt; [1] \"Intersezione con dplyr:\"\nA_intersezione_B\n#&gt;   Dado1 Dado2\n#&gt; 1     6     6\n\nIn sintesi,\n\nlo spazio campionario \\(\\Omega\\) √® stato generato algoritmicamente in R;\ngli eventi \\(A\\) e \\(B\\) sono stati definiti filtrando lo spazio campionario;\nl‚Äôintersezione \\(A \\cap B\\) corrisponde all‚Äôevento in cui entrambi i dadi mostrano un 6: \\(\\{(6, 6)\\}.\\)",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#sec-probabilita",
    "href": "chapters/probability/02_probability_models.html#sec-probabilita",
    "title": "26¬† Modelli probabilistici",
    "section": "\n26.6 Probabilit√†",
    "text": "26.6 Probabilit√†\nIl terzo elemento fondamentale del modello probabilistico √® la funzione di probabilit√†, che quantifica numericamente la possibilit√† di occorrenza degli eventi.\n\nDefinizione 26.3 Una probabilit√† \\(P\\) √® una funzione \\(P: \\mathcal{F} \\to [0,1]\\) definita su una \\(\\sigma\\)-algebra \\(\\mathcal{F}\\) di sottoinsiemi di \\(\\Omega\\). A ogni evento \\(A \\in \\mathcal{F}\\), la funzione assegna un valore reale compreso tra 0 e 1, rispettando i seguenti assiomi di Kolmogorov:\n\nNon-negativit√†\nPer ogni \\(A \\subseteq \\Omega\\), si richiede che \\(0 \\leq P(A) \\leq 1\\).\nNormalizzazione (evento certo)\\(P(\\Omega) = 1\\).\nAdditivit√† numerabile\nSe \\(A_1, A_2, \\dots\\) sono eventi mutuamente esclusivi (cio√® \\(A_i \\cap A_j = \\emptyset\\) per \\(i \\neq j\\)), allora: \\[\nP\\!\\Bigl(\\bigcup_{i=1}^{\\infty} A_i\\Bigr) \\;=\\; \\sum_{i=1}^{\\infty} P(A_i).\n\\]\n\nIn altre parole, una misura di probabilit√† non solo assegna numeri nell‚Äôintervallo \\([0,1]\\) a ogni evento, ma richiede che l‚Äôevento ‚Äúcerto‚Äù \\(\\Omega\\) abbia probabilit√† 1 e che la probabilit√† di un‚Äôunione numerabile di eventi disgiunti sia la somma delle loro probabilit√†. Queste condizioni garantiscono la coerenza formale e l‚Äôinterpretazione intuitiva del concetto di probabilit√†.\n\n\n26.6.1 Interpretazione degli Assiomi di Kolmogorov\n\nAssioma 1 (Non-negativit√† e limiti 0‚Äì1)\nLa probabilit√† di un evento √® sempre un numero reale compreso tra 0 e 1. Se la probabilit√† √® 0, l‚Äôevento pu√≤ considerarsi impossibile; se √® 1, l‚Äôevento √® certo.Esempio: Nel lancio di un dado a sei facce, l‚Äôevento ‚ÄúEsce 7‚Äù non pu√≤ verificarsi e ha probabilit√† 0, mentre l‚Äôevento ‚ÄúEsce un numero tra 1 e 6‚Äù ha probabilit√† 1.\nAssioma 2 (Evento certo)\nLo spazio campionario \\(\\Omega\\) √® l‚Äôinsieme di tutti i possibili esiti dell‚Äôesperimento. Poich√© in ogni prova deve accadere almeno uno degli esiti contenuti in \\(\\Omega\\), la probabilit√† di \\(\\Omega\\) √® necessariamente 1.Esempio: Nel lancio di un dado, lo spazio campionario \\(\\Omega\\) √® \\(\\{1,2,3,4,5,6\\}\\). L‚Äôevento ‚Äúesce un numero tra 1 e 6‚Äù coincide con l‚Äôintero spazio campionario, quindi \\(P(\\Omega) = 1\\).\nAssioma 3 (Additivit√† per eventi incompatibili)\nSe due o pi√π eventi sono mutuamente esclusivi (o incompatibili) ‚Äî cio√® non possono verificarsi contemporaneamente ‚Äî la probabilit√† della loro unione √® la somma delle probabilit√† di ciascuno.Esempio: Con un dado, l‚Äôevento ‚Äúesce un numero pari‚Äù e l‚Äôevento ‚Äúesce un numero dispari‚Äù non possono verificarsi nello stesso lancio. Di conseguenza,\\[\nP(\\text{‚Äúpari‚Äù} \\cup \\text{‚Äúdispari‚Äù}) \\;=\\; P(\\text{‚Äúpari‚Äù}) + P(\\text{‚Äúdispari‚Äù})\\,.\n\\]\n\nQuesti assiomi assicurano che la probabilit√†, intesa come funzione che assegna valori tra 0 e 1 a ogni evento, rispetti la coerenza matematica e l‚Äôinterpretazione intuitiva: non esistono eventi ‚Äúnegativi‚Äù o ‚Äúpi√π che certi‚Äù, e la probabilit√† totale dell‚Äôintero spazio dei possibili risultati deve sempre essere uguale a 1.\n\n26.6.2 Propriet√† Fondamentali\nDagli assiomi di Kolmogorov discendono alcune propriet√† fondamentali che descrivono come la probabilit√† si comporti in varie situazioni. Le principali sono elencate di seguito.\n\nTeorema 26.1 Siano \\(A\\) e \\(B\\) eventi qualsiasi nello spazio campionario \\(\\Omega\\). Allora valgono le seguenti relazioni:\n\nProbabilit√† dell‚Äôevento impossibile\\[\nP(\\emptyset) = 0.\n\\] Poich√© l‚Äôinsieme vuoto non include alcun esito sperimentale, non pu√≤ mai verificarsi.\nMonotonicit√†\\[\nA \\subseteq B \\quad \\Longrightarrow \\quad P(A) \\le P(B).\n\\] Se un evento √® interamente contenuto in un altro, non pu√≤ avere probabilit√† maggiore dell‚Äôevento che lo comprende.\nProbabilit√† del complementare\\[\nP(A^c) = 1 - P(A).\n\\] Poich√© \\(A\\) e il suo complementare \\(A^c\\) coprono l‚Äôintero spazio \\(\\Omega\\), la probabilit√† di \\(A^c\\) √® la parte ‚Äúrimanente‚Äù fino a 1.\nRegola dell‚Äôinclusione‚Äìesclusione\\[\nP(A \\cup B) \\;=\\; P(A) + P(B) \\;-\\; P(A \\cap B).\n\\] Per calcolare la probabilit√† dell‚Äôunione di due eventi qualsiasi, si sommano le probabilit√† di ciascun evento e si sottrae la probabilit√† della loro intersezione (altrimenti verrebbe conteggiata due volte).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#case-discreto-continuo",
    "href": "chapters/probability/02_probability_models.html#case-discreto-continuo",
    "title": "26¬† Modelli probabilistici",
    "section": "\n26.7 Spazi Discreti vs.¬†Continui",
    "text": "26.7 Spazi Discreti vs.¬†Continui\nLa natura dello spazio campionario determina come definiamo e calcoliamo le probabilit√†. Distinguiamo i due casi fondamentali: lo spazio campionario discreto\n\\[\n\\Omega = \\{a_1, a_2, \\dots, a_n\\} \\quad \\text{oppure} \\quad \\Omega = \\{a_1, a_2, \\dots\\}\n\\]\ne lo spazio campionario continuo\n\\[\n\\Omega = \\mathbb{R} .\n\\]\n\n26.7.1 Spazi Campionari Discreti\nCaratteristiche:\n\nGli esiti sono numerabili (finiti o infiniti ma separabili).\n\nEsempi:\n\nLancio di un dado: \\(\\Omega = \\{1, 2, 3, 4, 5, 6\\}\\).\n\nNumero di clienti in un negozio in un‚Äôora: \\(\\Omega = \\{0, 1, 2, \\dots\\}\\).\n\n\n\nDefinizione di Probabilit√†:\n\n\nAssegniamo una probabilit√† puntuale \\(p_i \\geq 0\\) a ogni esito \\(\\omega_i\\), con:\n\\[\n\\sum_{\\text{tutti gli } i} p_i = 1 \\quad \\text{(normalizzazione)}.\n\\]\n\n\nLa probabilit√† di un evento \\(A\\) si ottiene sommando le probabilit√† degli esiti in \\(A\\):\n\\[\nP(A) = \\sum_{\\omega_i \\in A} p_i.\n\\]\n\n\n\nEsempio 26.7 Lancio di un dado equilibrato.\n\nLa probabilit√† di ciascuna faccia √® uniforme: \\(p_i = \\frac{1}{6}\\), con \\(i = 1, 2, \\dots, 6\\).\nConsideriamo l‚Äôevento \\(A = \\text{‚ÄúEsce un numero pari\"}\\).\n\nPertanto, calcoliamo la probabilit√† di \\(A\\):\n\n\\[\nP(A) = p_2 + p_4 + p_6 = \\frac{1}{6} + \\frac{1}{6} + \\frac{1}{6} = \\frac{3}{6} = \\frac{1}{2}.\n\\]\nL‚Äôevento \\(A\\) ha dunque probabilit√† \\(\\frac{1}{2}\\).\n\n\n26.7.2 Spazi Campionari Continui\nCaratteristiche:\n\nGli esiti sono non numerabili (infiniti e ‚Äúdensi‚Äù).\n\nEsempi:\n\ntempo di attesa all‚Äôautobus: \\(\\Omega = [0, \\infty)\\);\n\naltezza di una persona: \\(\\Omega = [50\\, \\text{cm}, 250\\, \\text{cm}]\\).\n\n\n\nDefinizione di Probabilit√†:\n\nUsiamo una funzione di densit√† di probabilit√† (PDF) \\(f(x) \\geq 0\\), con:\\[\n\\int_{-\\infty}^{\\infty} f(x)\\, dx = 1 \\quad \\text{(normalizzazione)}.\n\\]\n\nLa probabilit√† di un evento \\(A\\) si ottiene integrando la PDF su \\(A\\):\\[\nP(A) = \\int_{A} f(x)\\, dx.\n\\]\n\n\n\nEsempio 26.8 Misurazione dell‚Äôaltezza degli uomini adulti, modellata come variabile aleatoria continua \\(X\\) (in cm) con distribuzione normale \\(\\mathcal{N}(170, 7^2)\\) (si veda la Sezione Capitolo 38):\nLa funzione di densit√† (PDF) corrispondente √®:\n\\[\nf(x)\n= \\frac{1}{7\\sqrt{2\\pi}} \\exp\\!\\Bigl(-\\frac{(x - 170)^2}{2 \\cdot 7^2}\\Bigr),\n\\quad\nX \\sim \\mathcal{N}(170,\\, 7^2).\n\\]\nEvento di interesse:\\[\nA = \\text{‚ÄúAltezza compresa tra 160 cm e 180 cm‚Äù}.\n\\]\nCalcolo della probabilit√†:\nLa probabilit√† di \\(A\\) √® l‚Äôarea sotto la curva della densit√† tra 160 cm e 180 cm:\n\\[\nP(A) \\;=\\; \\int_{160}^{180} \\frac{1}{7\\sqrt{2\\pi}}\n\\exp\\!\\Bigl(-\\frac{(x - 170)^2}{98}\\Bigr)\\,\\mathrm{d}x.\n\\]\nIn alternativa, si pu√≤ scrivere:\n\\[\nP(160 \\leq X \\leq 180) \\;\\approx\\; 0.847 \\quad (84.7\\%).\n\\]\nPi√π avanti vedremo come calcolare facilmente questa probabilit√† tramite R, ad esempio con il comando:\n\npnorm(180, 170, 7) - pnorm(160, 170, 7)\n#&gt; [1] 0.8469\n\nQuesto codice restituisce la differenza tra le funzioni di ripartizione (CDF) a 180 e a 160, corrispondente proprio all‚Äôarea desiderata sotto la PDF.\n\n\n26.7.3 Confronto Chiave\n\n\n\n\n\n\n\nCaratteristica\nSpazio Discreto\nSpazio Continuo\n\n\n\nEsiti\nNumerabili (es: 1, 2, 3)\nNon numerabili (es: intervalli)\n\n\nProbabilit√† di un singolo punto\n\n\\(P(\\{\\omega_i\\}) = p_i\\) (\\(\\geq\\) 0)\n\n\\(P(\\{x\\}) = 0\\) (sempre zero)\n\n\nStrumento matematico\nSomma \\(\\sum\\)\n\nIntegrale \\(\\int\\)\n\n\n\nEsempi comuni\nDadi, monete, conteggi\nMisure fisiche, tempi, temperature\n\n\n\n\n\n\n\n\n\nPropriet√† della PDF\n\n\n\n\nNegli spazi continui, la PDF non √® una probabilit√† (pu√≤ essere &gt; 1), ma la sua area sottesa su un intervallo fornisce la probabilit√†.\n\nPer eventi continui, ha senso solo calcolare probabilit√† su intervalli (es: \\(P(160 \\leq X \\leq 180)\\)).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#dai-concetti-base-alle-propriet√†-fondamentali-della-probabilit√†",
    "href": "chapters/probability/02_probability_models.html#dai-concetti-base-alle-propriet√†-fondamentali-della-probabilit√†",
    "title": "26¬† Modelli probabilistici",
    "section": "\n26.8 Dai Concetti Base alle Propriet√† Fondamentali della Probabilit√†",
    "text": "26.8 Dai Concetti Base alle Propriet√† Fondamentali della Probabilit√†\nAbbiamo visto come un esperimento casuale possa essere formalizzato matematicamente attraverso tre elementi chiave:\n\n\nSpazio campionario (\\(\\Omega\\)): l‚Äôinsieme di tutti i possibili esiti dell‚Äôesperimento.\n\nEventi: sottoinsiemi di \\(\\Omega\\) che rappresentano combinazioni di esiti di interesse.\n\nProbabilit√†: una funzione \\(P\\) che assegna a ogni evento un valore numerico compreso tra 0 e 1, misurandone il grado di verosimiglianza.\n\nPartendo da queste definizioni, √® possibile derivare propriet√† essenziali per il calcolo e l‚Äôanalisi probabilistica. Queste propriet√† consentono di determinare la probabilit√† di eventi complessi a partire da eventi elementari e di stabilire relazioni logiche tra di essi.\nIn questo corso, approfondiremo quattro teoremi fondamentali:\n\nteorema della somma;\nteorema del prodotto;\nteorema della probabilit√† totale;\nteorema di Bayes.\n\nL‚Äôintroduzione di operazioni sugli eventi (unione, intersezione, complemento) e delle propriet√† della probabilit√† (teorema della somma, probabilit√† condizionata, teorema della probabilit√† totale, ‚Ä¶) ci consente di costruire modelli probabilistici pi√π complessi e applicabili a problemi reali.\nQui di seguito, approfondiamo il teorema della somma.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#teorema-della-somma",
    "href": "chapters/probability/02_probability_models.html#teorema-della-somma",
    "title": "26¬† Modelli probabilistici",
    "section": "\n26.9 Teorema della Somma",
    "text": "26.9 Teorema della Somma\nIl teorema della somma (o regola additiva) permette di determinare la probabilit√† che si verifichi almeno uno tra due eventi \\(A\\) e \\(B\\). La sua formulazione dipende dalla relazione tra i due eventi:\nCaso 1: Eventi Mutuamente Esclusivi. Se \\(A\\) e \\(B\\) non possono verificarsi insieme (ossia \\(A \\cap B = \\emptyset\\)), la probabilit√† dell‚Äôunione √® la somma delle singole probabilit√†:\n\\[\nP(A \\cup B) = P(A) + P(B).\n\\tag{26.1}\\]\nCaso 2: Eventi Non Esclusivi. Se \\(A\\) e \\(B\\) possono coesistere, √® necessario evitare di contare due volte la loro intersezione:\n\\[\nP(A \\cup B) = P(A) + P(B) - P(A \\cap B).\n\\tag{26.2}\\]\nPerch√© questa differenza?\nLa probabilit√† √® una funzione d‚Äôinsieme coerente con le operazioni insiemistiche. L‚Äôaddizione diretta \\(P(A) + P(B)\\) conteggia due volte gli esiti comuni a \\(A\\) e \\(B\\) (rappresentati da \\(A \\cap B\\)). La sottrazione di \\(P(A \\cap B)\\) garantisce che ogni esito sia considerato una sola volta.\nIl teorema della somma sottolinea come le operazioni logiche tra eventi (unione, intersezione) si riflettano in relazioni algebriche tra le loro probabilit√†, fornendo uno strumento operativo per modellare scenari reali.\n\nEsempio 26.9 In uno studio sulla salute mentale, supponiamo di avere i seguenti dati relativi a un campione di partecipanti:\n\nla probabilit√† che un individuo soffra di ansia √® \\(P(A) = 0.30\\);\n\nla probabilit√† che un individuo soffra di depressione √® \\(P(B) = 0.25\\);\nla probabilit√† che un individuo soffra contemporaneamente di ansia e depressione √® \\(P(A \\cap B) = 0.15\\).\n\nVogliamo calcolare la probabilit√† che un individuo soffra di almeno uno dei due disturbi (ansia o depressione), ovvero \\(P(A \\cup B)\\).\nUtilizziamo la regola della somma per eventi non mutuamente esclusivi:\n\\[\nP(A \\cup B) = P(A) + P(B) - P(A \\cap B)\n\\]\nSvolgiamo questo calcolo in R:\n\n# Definiamo le probabilit√†\nP_A &lt;- 0.30 # Probabilit√† di soffrire di ansia\nP_B &lt;- 0.25 # Probabilit√† di soffrire di depressione\nP_A_intersect_B &lt;- 0.15 # Probabilit√† di soffrire di entrambi i disturbi\n\n# Applichiamo la formula della regola della somma\nP_A_union_B &lt;- P_A + P_B - P_A_intersect_B\nP_A_union_B\n#&gt; [1] 0.4\n\nInterpretazione: il 40% dei partecipanti soffre di almeno uno tra ansia e depressione. L‚Äôintersezione \\(P(A \\cap B) = 0.15\\) √® fondamentale, poich√© senza sottrarla avremmo contato due volte i soggetti che soffrono contemporaneamente di entrambi i disturbi.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#probabilit√†-calcolo-combinatorio-e-simulazioni",
    "href": "chapters/probability/02_probability_models.html#probabilit√†-calcolo-combinatorio-e-simulazioni",
    "title": "26¬† Modelli probabilistici",
    "section": "\n26.10 Probabilit√†, Calcolo Combinatorio e Simulazioni",
    "text": "26.10 Probabilit√†, Calcolo Combinatorio e Simulazioni\nIn molti problemi di probabilit√†, soprattutto quelli di taglio scolastico o introduttivo, si assume che ogni evento elementare abbia la stessa probabilit√† di verificarsi (equiprobabilit√†). In queste situazioni, il calcolo combinatorio risulta particolarmente utile per determinare la probabilit√† di un evento, poich√© basta:\n\n\nDefinire gli eventi di successo: identificare tutte le configurazioni compatibili con l‚Äôevento di interesse.\n\n\nContare le possibilit√†: calcolare il numero di eventi di successo e rapportarlo al numero totale di eventi nello spazio campionario.\n\n\nEsempio 26.10 Estrazione di una pallina da un‚Äôurna\nSupponiamo di avere un‚Äôurna con 10 palline numerate da 1 a 10, da cui estraiamo una sola pallina in modo casuale. Assumendo che ogni pallina abbia la stessa probabilit√† di essere estratta, calcoliamo la probabilit√† di estrarre un numero pari.\n\n\nEventi di successo: \\(\\{\\;2, 4, 6, 8, 10\\}\\) (5 casi)\n\n\nEventi totali: \\(\\{\\;1, 2, 3, 4, 5, 6, 7, 8, 9, 10\\}\\) (10 casi)\n\nLa probabilit√† cercata √® quindi:\n\\[\nP(\\text{numero pari}) \\;=\\; \\frac{\\text{numero di eventi di successo}}{\\text{numero totale di eventi}}\n\\;=\\; \\frac{5}{10} \\;=\\; 0.5.\n\\]\n\nNelle applicazioni pi√π complesse, come il calcolo della probabilit√† di ottenere una determinata combinazione di carte o il formare gruppi specifici partendo da una popolazione, utilizzeremo tecniche combinatorie pi√π avanzate ‚Äî ad esempio permutazioni e combinazioni (si veda la Sezione Appendice H) ‚Äî che consentono di contare in modo sistematico gli eventi possibili e quelli di successo.\n\n26.10.1 Simulazioni Monte Carlo\nUno degli aspetti pi√π impegnativi della probabilit√† √® che molti problemi non si prestano a soluzioni immediate o intuitive. Per affrontarli, si possono adottare due approcci principali. Il primo consiste nell‚Äôapplicare i teoremi della teoria della probabilit√†, un metodo rigoroso ma spesso controintuitivo. Il secondo approccio √® quello della simulazione Monte Carlo, che permette di ottenere una soluzione approssimata, ma molto vicina al valore reale, seguendo una procedura pi√π accessibile e intuitiva. Questo metodo prende il nome dal famoso Casin√≤ di Monte Carlo a Monaco, anche se pu√≤ essere semplicemente definito come ‚Äúmetodo di simulazione.‚Äù\nLa simulazione Monte Carlo appartiene a una classe generale di metodi stocastici che si contrappongono ai metodi deterministici. Questi metodi consentono di risolvere approssimativamente problemi analitici attraverso la generazione casuale delle quantit√† di interesse. Tra le tecniche comunemente utilizzate troviamo il campionamento con reinserimento, in cui la stessa unit√† pu√≤ essere selezionata pi√π volte, e il campionamento senza reinserimento, dove ogni unit√† pu√≤ essere selezionata una sola volta. Questi strumenti rappresentano un mezzo potente e pratico per affrontare problemi complessi.\n\n26.10.2 Il Problema dei Complenni\nUn esempio classico di applicazione del metodo Monte Carlo √® il calcolo delle probabilit√† relative a vari eventi definiti attraverso il modello dell‚Äôurna. Tra questi, abbiamo il celebre problema dei compleanni.\nIl problema dei compleanni esplora la probabilit√† che, in un gruppo di \\(n\\) persone, almeno due persone condividano la stessa data di nascita. Supponendo che i compleanni siano distribuiti uniformemente su 365 giorni (ignorando anni bisestili), il problema sorprende molte persone per il fatto che gi√† con 23 persone la probabilit√† di una coincidenza √® superiore al 50%.\n\n26.10.2.1 Soluzione analitica\nQuesto problema pu√≤ essere risolto utilizzando il concetto di probabilit√† complementari. Infatti, il problema pu√≤ essere visto da due prospettive complementari:\n\n\nCaso 1: tutti i compleanni sono diversi (nessuna persona condivide il compleanno con un‚Äôaltra);\n\nCaso 2: almeno due persone condividono lo stesso compleanno.\n\nQuesti due casi sono mutuamente esclusivi (non possono verificarsi contemporaneamente) ed esaustivi (coprono tutte le possibilit√†). Pertanto, la somma delle loro probabilit√† deve essere uguale a 1:\n\\[\nP(\\text{almeno un compleanno in comune}) = 1 - P(\\text{nessun compleanno in comune}).\n\\]\nIn altre parole, per calcolare la probabilit√† che almeno due persone abbiano lo stesso compleanno, possiamo prima calcolare la probabilit√† che tutti i compleanni siano diversi e poi sottrarre questo valore da 1.\nCaso 1: probabilit√† che tutti i compleanni siano diversi.\nPer calcolare \\(P(\\text{nessun compleanno in comune})\\), seguiamo questo ragionamento:\n\nPrima persona: Pu√≤ scegliere liberamente un giorno del calendario. Ci sono 365 possibilit√† (ignoriamo gli anni bisestili per semplicit√†).\nSeconda persona: Deve avere un compleanno diverso dalla prima persona. Quindi, ci sono 364 giorni disponibili.\nTerza persona: Deve avere un compleanno diverso dai primi due. Ci sono 363 giorni disponibili.\n\nQuesto processo continua fino alla \\(n\\)-esima persona, che avr√† \\(365 - n + 1\\) giorni disponibili.\nLa probabilit√† che tutti i compleanni siano diversi si ottiene moltiplicando le probabilit√† individuali di ogni persona di avere un compleanno diverso dai precedenti. Poich√© ogni scelta √® indipendente, possiamo scrivere:\n\\[\nP(\\text{nessun compleanno in comune}) = \\frac{365}{365} \\cdot \\frac{364}{365} \\cdot \\frac{363}{365} \\cdot \\ldots \\cdot \\frac{365-n+1}{365}.\n\\]\nQuesto prodotto pu√≤ essere espresso in forma compatta utilizzando il fattoriale:\n\\[\nP(\\text{nessun compleanno in comune}) = \\frac{365!}{(365-n)! \\cdot 365^n} ,\n\\]\ndove:\n\n\n\\(365!\\) √® il fattoriale di 365 (il prodotto di tutti i numeri interi da 1 a 365).\n\n\\((365-n)!\\) √® il fattoriale di \\(365 - n\\).\n\n\\(365^n\\) rappresenta tutte le possibili combinazioni di compleanni per \\(n\\) persone.\n\nCaso 2. Probabilit√† di almeno un compleanno in comune.\nOra che abbiamo calcolato la probabilit√† che tutti i compleanni siano diversi, possiamo trovare la probabilit√† che almeno due persone abbiano lo stesso compleanno come il complemento:\n\\[\nP(\\text{almeno un compleanno in comune}) = 1 - P(\\text{nessun compleanno in comune}).\n\\]\nSostituendo l‚Äôespressione precedente, otteniamo:\n\\[\nP(\\text{almeno un compleanno in comune}) = 1 - \\frac{365!}{(365-n)! \\cdot 365^n}.\n\\]\nOra che abbiamo le formule per i due eventi complementari, come funzione di \\(n\\), applichiamole al caso specifico in cui \\(n\\) = 23. Questo √® un valore interessante perch√©, come vedremo, la probabilit√† che almeno due persone su 23 condividano lo stesso compleanno supera il 50%.\nLa formula per la probabilit√† che tutti i compleanni siano diversi √®:\n\\[\nP(\\text{nessun compleanno in comune}) = \\frac{365!}{(365-n)! \\cdot 365^n}.\n\\]\nPer \\(n = 23\\), sostituiamo il valore nella formula:\n\\[\nP(\\text{nessun compleanno in comune}) = \\frac{365!}{(365-23)! \\cdot 365^{23}}.\n\\]\nSemplifichiamo:\n\\[\nP(\\text{nessun compleanno in comune}) = \\frac{365!}{342! \\cdot 365^{23}}.\n\\]\nUtilizzando R, troviamo:\n\n# Numero di persone\nn &lt;- 23\n\n# Calcolo della probabilit√† che tutti abbiano compleanni diversi\nnumeratore &lt;- prod(365:(365 - n + 1))\ndenominatore &lt;- 365^n\n\nP_diversi &lt;- numeratore / denominatore\nP_diversi  # stampa la probabilit√†\n#&gt; [1] 0.4927\n\n\\[\nP(\\text{nessun compleanno in comune}) \\approx 0{,}4927.\n\\]\nCi√≤ implica che la probabilit√† che 23 persone abbiano compleanni distinti sia approssimativamente 0.4927 (pari al 49.27%).\nLa probabilit√† che almeno due persone (su 23) condividano lo stesso compleanno corrisponde al complemento della probabilit√† appena calcolata:\n\\[\nP(\\text{almeno un compleanno in comune}) = 1 - P(\\text{nessun compleanno in comune}).\n\\]\nSostituendo il valore ottenuto:\n\\[\nP(\\text{almeno un compleanno in comune}) = 1 - 0{.}4927 = 0{.}5073.\n\\]\nRisultato finale:\nCon \\(n = 23\\), la probabilit√† che almeno una coppia condivida il compleanno supera il 50%, attestandosi intorno a 0.5073 (50.73%). Questo esito √® spesso sorprendente, poich√© intuitivamente si tende a sottostimare l‚Äôeffetto della combinatoria: sebbene 23 possano sembrare poche, le \\(\\binom{23}{2} = 253\\) possibili coppie rendono statisticamente probabile una corrispondenza.\n\n26.10.2.2 Soluzione con Simulazione in R\nPer risolvere il problema tramite simulazione, possiamo generare gruppi casuali di \\(n\\) persone, assegnando loro un compleanno casuale tra 1 e 365. Per ogni gruppo, verifichiamo se almeno due persone condividono lo stesso compleanno.\nEcco il codice R:\n\n# Numero di simulazioni\nnum_simulazioni &lt;- 10000\n\n# Funzione per simulare il problema del compleanno\nsimula_compleanno &lt;- function(n) {\n  # Conta il numero di successi (almeno un compleanno in comune)\n  successi &lt;- 0\n\n  # Loop per il numero di simulazioni\n  for (i in 1:num_simulazioni) {\n    # Genera n compleanni casuali\n    compleanni &lt;- sample(1:365, n, replace = TRUE)\n\n    # Verifica se ci sono duplicati\n    if (any(duplicated(compleanni))) {\n      successi &lt;- successi + 1\n    }\n  }\n\n  # Calcola la probabilit√† stimata\n  return(successi / num_simulazioni)\n}\n\nProviamo con diversi valori di n.\n\nset.seed(123) # Fissiamo il seme per la riproducibilit√†\nrisultati &lt;- sapply(1:50, simula_compleanno)\n\n# Creiamo un data frame con i risultati\ndf &lt;- data.frame(\n  n = 1:50,\n  prob = risultati\n)\n\n# Creiamo il grafico\nggplot(df, aes(x = n, y = prob)) +\n  geom_line(color = \"blue\") +\n  geom_point(color = \"blue\") +\n  geom_hline(yintercept = 0.5, color = \"red\", linetype = \"dashed\") +\n  labs(\n    x = \"Numero di persone (n)\",\n    y = \"Probabilit√† stimata\",\n    title = \"Problema del Compleanno (Simulazione)\"\n  )\n\n\n\n\n\n\n\n\n\nSimulazioni: Per ogni gruppo di \\(n\\), si eseguono 10000 simulazioni, in cui si generano \\(n\\) compleanni casuali tra 1 e 365.\n\nDuplicati: La funzione duplicated() verifica se ci sono compleanni ripetuti.\n\nCalcolo della probabilit√†: La proporzione di simulazioni in cui si verifica almeno un compleanno condiviso rappresenta la probabilit√† stimata.\n\nVisualizzazione: Si tracciano le probabilit√† per diversi valori di \\(n\\), evidenziando il punto in cui la probabilit√† supera il 50%.\n\nRisultati attesi:\n\ncon circa 23 persone, la probabilit√† stimata sar√† superiore a 0.5;\nil grafico mostra una curva crescente con un rapido aumento della probabilit√† per \\(n\\) piccoli e un asintoto vicino a 1 per \\(n\\) grandi.\n\nQuesto approccio permette di comprendere intuitivamente il problema e di verificare i risultati teorici con la simulazione.\n\n26.10.2.3 Assunzioni\nIl problema dei compleanni evidenzia non solo l‚Äôefficacia dell‚Äôapproccio simulativo nel semplificare la soluzione rispetto all‚Äôanalisi formale, ma anche l‚Äôimportanza delle assunzioni che entrambi i metodi condividono. In questo caso, l‚Äôassunzione √® che la probabilit√† di nascita sia uniformemente distribuita nei 365 giorni dell‚Äôanno ‚Äî un‚Äôipotesi semplificativa che non rispecchia la realt√†.\nQuesto esempio sottolinea un principio fondamentale dei modelli probabilistici (e scientifici in generale): ogni modello si basa su un insieme di assunzioni che ne delimitano la validit√† e l‚Äôapplicabilit√†. Valutare criticamente la plausibilit√† di tali assunzioni √® dunque essenziale per garantire che il modello fornisca una rappresentazione utile del fenomeno studiato.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#riflessioni-conclusive",
    "href": "chapters/probability/02_probability_models.html#riflessioni-conclusive",
    "title": "26¬† Modelli probabilistici",
    "section": "\n26.11 Riflessioni Conclusive",
    "text": "26.11 Riflessioni Conclusive\nLa teoria della probabilit√† fornisce un quadro rigoroso per descrivere e analizzare fenomeni caratterizzati dall‚Äôincertezza. In questo capitolo abbiamo introdotto i concetti fondamentali del calcolo delle probabilit√†, evidenziando come la modellazione matematica degli esperimenti casuali consenta di quantificare e prevedere eventi incerti. Abbiamo esplorato strumenti essenziali come la definizione di spazio campionario, la nozione di evento e le regole della probabilit√†, illustrando il loro utilizzo sia attraverso esempi teorici sia mediante simulazioni computazionali.\nUn aspetto cruciale della modellazione probabilistica √® il ruolo delle assunzioni su cui si basano i modelli. Ogni modello probabilistico si fonda su ipotesi specifiche riguardanti la natura del fenomeno studiato e il modo in cui gli esiti vengono generati. Queste ipotesi determinano non solo la validit√† del modello, ma anche il tipo di risposte che esso pu√≤ fornire. Ad esempio, nel problema del compleanno, abbiamo ipotizzato che i compleanni siano distribuiti in modo uniforme nei 365 giorni dell‚Äôanno. Sebbene questa assunzione semplifichi notevolmente i calcoli, sappiamo che nella realt√† esistono fluttuazioni stagionali nelle nascite che possono influenzare le probabilit√† effettive.\nQuesto ci porta a una considerazione pi√π ampia: la probabilit√† non √® solo un insieme di formule, ma uno strumento per rappresentare l‚Äôincertezza e prendere decisioni informate. Tuttavia, l‚Äôaccuratezza di qualsiasi modello probabilistico dipende strettamente dalla plausibilit√† delle ipotesi adottate. Modelli diversi, basati su ipotesi differenti, possono portare a risultati diversi, e l‚Äôinterpretazione dei risultati deve sempre tenere conto di queste assunzioni.\nIn definitiva, lo studio della probabilit√† non si limita alla manipolazione di formule, ma richiede un‚Äôattenta riflessione sulla relazione tra modelli teorici e fenomeni reali. Una comprensione critica delle assunzioni alla base di un modello √® essenziale per applicare correttamente i concetti probabilistici in contesti pratici, sia in ambito scientifico che nelle decisioni quotidiane.\n\n\n\n\n\n\nRisposte alle domande iniziali\n\n\n\nIl 92% delle persone sovrastima il numero necessario per la prima domanda e sottostima la seconda probabilit√†. Questo problema mostra come l‚Äôintuizione umana fallisca con eventi apparentemente ‚Äúrari‚Äù.\n\nLa risposta √® 23 persone.\nLa probabilit√† √® \\(\\sim 0.7\\)",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#esercizi",
    "href": "chapters/probability/02_probability_models.html#esercizi",
    "title": "26¬† Modelli probabilistici",
    "section": "\n26.12 Esercizi",
    "text": "26.12 Esercizi\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nQui di seguito sono presentati una serie di esercizi sbasati sulla Satisfaction with Life Scale (SWLS).\nEsercizi sullo Spazio Campionario e Eventi\n\n\nDefinizione dello Spazio Campionario\nSupponiamo che i punteggi della Satisfaction with Life Scale (SWLS) siano numeri interi compresi tra 5 e 35.\n\nQual √® lo spazio campionario \\(\\Omega\\) per questo esperimento?\nSe hai raccolto i dati di 15 studenti, come potresti rappresentare lo spazio campionario con i loro punteggi osservati?\n\n\n\nDefinizione di un Evento\nConsideriamo l‚Äôevento A: ‚ÄúUno studente ha un punteggio SWLS superiore a 25‚Äù.\n\nEsprimi l‚Äôevento A come un sottoinsieme dello spazio campionario.\nSe tra i 15 studenti osservati, 4 hanno punteggi superiori a 25, qual √® la proporzione sperimentale per l‚Äôevento A?\n\n\n\nEventi Complementari\nDefiniamo l‚Äôevento B: ‚ÄúUno studente ha un punteggio SWLS inferiore o uguale a 25‚Äù.\n\nScrivi l‚Äôevento B in relazione all‚Äôevento A.\nQual √® la probabilit√† empirica di B, sapendo che 4 studenti hanno punteggi superiori a 25?\n\n\n\nEsercizi sulle Operazioni tra Eventi\n\n\nUnione di Eventi\nDefiniamo due eventi:\n\n\nA: ‚ÄúIl punteggio SWLS √® superiore a 25‚Äù.\n\n\nC: ‚ÄúIl punteggio SWLS √® inferiore a 15‚Äù.\n\nScrivi l‚Äôevento A ‚à™ C (‚ÄúLo studente ha un punteggio maggiore di 25 o minore di 15‚Äù).\nSe nel campione di 15 studenti, 4 studenti hanno punteggi superiori a 25 e 3 hanno punteggi inferiori a 15, qual √® la proporzione empirica di A ‚à™ C?\n\n\n\nIntersezione di Eventi e Eventi Disgiunti\nSupponiamo che l‚Äôevento D sia: ‚ÄúUno studente ha un punteggio pari a 20‚Äù.\n\nL‚Äôevento D e l‚Äôevento A sono disgiunti?\nSe nessuno degli studenti ha ottenuto esattamente 20, qual √® la probabilit√† empirica di A ‚à© D?\n\n\n\nEsercizi sulle Regole della Probabilit√† 6. Probabilit√† dell‚ÄôUnione di Eventi\nSupponiamo di avere:\n\n\nP(A) = 0.3 (probabilit√† che un punteggio sia superiore a 25).\n\n\nP(C) = 0.2 (probabilit√† che un punteggio sia inferiore a 15).\n\n\nP(A ‚à© C) = 0 (perch√© un punteggio non pu√≤ essere contemporaneamente superiore a 25 e inferiore a 15).\n\nUsa la regola dell‚Äôunione per calcolare P(A ‚à™ C).\n\n\n\nProbabilit√† Condizionata\nConsideriamo:\n\n\nP(A) = 0.3 (probabilit√† che un punteggio sia superiore a 25).\n\n\nP(E) = 0.5 (probabilit√† che uno studente abbia pi√π di 20 anni).\n\n\nP(A | E) = 0.4 (probabilit√† che un soggetto con pi√π di 20 anni abbia un punteggio superiore a 25).\n\nUsa la formula della probabilit√† condizionata per calcolare P(A ‚à© E).\n\n\n\nEsercizi su Permutazioni e Combinazioni\n\n\nSelezione Casuale di Studenti\nDal campione di 15 studenti, supponiamo di voler selezionare casualmente 3 studenti per partecipare a un‚Äôintervista sulla loro soddisfazione di vita.\n\nQuanti modi ci sono per selezionare 3 studenti su 15?\n\n\n\nOrdinare gli Studenti per Discussione\nSupponiamo di voler formare un piccolo gruppo di discussione con 3 studenti, scegliendoli in ordine di intervento.\n\nQuante diverse sequenze di 3 studenti possiamo ottenere?\n\n\nFormare Coppie di Studenti\nSe vogliamo formare coppie di studenti per un esercizio collaborativo, senza considerare l‚Äôordine, quanti modi ci sono per farlo?\n\n\n\n\n\n\n\n\n\n\nSoluzione\n\n\n\n\n\n1. Definizione dello Spazio Campionario\n\n\nLo spazio campionario \\(\\Omega\\) per questo esperimento √® l‚Äôinsieme di tutti i possibili punteggi della Satisfaction with Life Scale (SWLS), quindi:\n\\[ \\Omega = \\{5, 6, 7, ..., 35\\} \\]\n\nSe abbiamo raccolto i dati di 15 studenti con punteggi osservati \\(\\{27, 21, 15, 30, 18, 23, 26, 35, 20, 22, 19, 25, 32, 29, 28\\}\\), possiamo considerare \\(\\Omega\\) come questo insieme specifico.\n\n2. Definizione di un Evento\n\n\nL‚Äôevento \\(A\\) ‚ÄúUno studente ha un punteggio SWLS superiore a 25‚Äù √® il sottoinsieme:\n\\[ A = \\{27, 30, 26, 35, 32, 29, 28\\}\\]\n\n\nSe 7 studenti su 15 hanno punteggi superiori a 25, la probabilit√† empirica √®:\n\\[ P(A) = \\frac{7}{15} = 0.467 \\]\n\n\n3. Eventi Complementari\n\n\nL‚Äôevento complementare \\(B\\) ‚ÄúUno studente ha un punteggio SWLS inferiore o uguale a 25‚Äù √®:\n\\[ B = \\{21, 15, 18, 23, 20, 22, 19, 25\\}\\]\n\n\nSe 8 studenti su 15 rientrano in \\(B\\), la probabilit√† empirica √®:\n\\[ P(B) = 1 - P(A) = \\frac{8}{15} = 0.533 \\]\n\n\nSoluzioni agli Esercizi sulle Operazioni tra Eventi\n4. Unione di Eventi\n\n\nL‚Äôevento \\(A \\cup C\\) (‚ÄúLo studente ha un punteggio maggiore di 25 o minore di 15‚Äù) √®:\n\\[ A \\cup C = \\{27, 30, 26, 35, 32, 29, 28, 15\\}\\]\n\n\nSe 8 studenti su 15 appartengono a \\(A \\cup C\\), la probabilit√† empirica √®:\n\\[ P(A \\cup C) = \\frac{8}{15} = 0.533 \\]\n\n\n5. Intersezione di Eventi e Eventi Disgiunti\n\nL‚Äôevento \\(D\\) ‚ÄúUno studente ha un punteggio pari a 20‚Äù √® \\(D = \\{20\\}\\).\n\nL‚Äôevento \\(A \\cap D\\) √® l‚Äôinsieme degli elementi comuni a \\(A\\) e \\(D\\), ma \\(D\\) non ha elementi in \\(A\\), quindi:\n\\[ A \\cap D = \\emptyset \\]\n\nEssendo \\(A \\cap D = \\emptyset\\), gli eventi sono disgiunti e \\(P(A \\cap D) = 0\\).\n\nSoluzioni agli Esercizi sulle Regole della Probabilit√†\n6. Probabilit√† dell‚ÄôUnione di Eventi\nUsiamo la formula:\n\\[ P(A \\cup C) = P(A) + P(C) - P(A \\cap C) \\]\nDato che \\(P(A \\cap C) = 0\\), abbiamo:\n\\[ P(A \\cup C) = 0.3 + 0.2 - 0 = 0.5 \\]\n7. Probabilit√† Condizionata\nLa probabilit√† congiunta \\(P(A \\cap E)\\) si calcola con:\n\\[ P(A \\cap E) = P(A | E) \\cdot P(E) \\]\nSostituendo i valori:\n\\[ P(A \\cap E) = 0.4 \\times 0.5 = 0.2 \\]\nSoluzioni agli Esercizi su Permutazioni e Combinazioni\n8. Selezione Casuale di Studenti\nIl numero di modi per scegliere 3 studenti su 15 (combinazioni) √®:\n\\[ C_{15,3} = \\frac{15!}{3!(15-3)!} = \\frac{15!}{3!12!} = \\frac{15 \\times 14 \\times 13}{3 \\times 2 \\times 1} = 455 \\]\n9. Ordinare gli Studenti per Discussione\nIl numero di modi per scegliere e ordinare 3 studenti su 15 (disposizioni) √®:\n\\[ D_{15,3} = \\frac{15!}{(15-3)!} = \\frac{15!}{12!} = 15 \\times 14 \\times 13 = 2730 \\]\n10. Formare Coppie di Studenti\nIl numero di modi per formare coppie (combinazioni di 2 studenti su 15) √®:\n\\[ C_{15,2} = \\frac{15!}{2!(15-2)!} = \\frac{15 \\times 14}{2 \\times 1} = 105 \\]",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#bibliografia",
    "href": "chapters/probability/02_probability_models.html#bibliografia",
    "title": "26¬† Modelli probabilistici",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nChan, J. C. C., & Kroese, D. P. (2025). Statistical Modeling and Computation (2¬™ ed.). Springer.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_spaces.html",
    "href": "chapters/probability/03_prob_spaces.html",
    "title": "27¬† La Probabilit√† come misura della certezza razionale: un‚Äôinterpretazione Bayesiana",
    "section": "",
    "text": "27.1 Introduzione\nNel Capitolo 26 abbiamo introdotto il concetto di probabilit√† come una funzione che soddisfa gli assiomi di Kolmogorov:\nSebbene questa formalizzazione matematica sia essenziale, rimane aperta una questione fondamentale: qual √® il significato intrinseco dei valori numerici che chiamiamo ‚Äúprobabilit√†‚Äù? Questo interrogativo ha alimentato un secolare dibattito filosofico che esploreremo in questo capitolo attraverso la lente dell‚Äôinterpretazione bayesiana.\nAdotteremo una prospettiva in cui la probabilit√† non descrive frequenze osservabili, bens√¨ quantifica il grado di convinzione razionale di un agente epistemico. In questa visione soggettivista, la probabilit√† diventa una misura normativa di come dovremmo allocare la nostra certezza totale (normalizzata a 1) tra proposizioni mutualmente esclusive ed esaustive.\nPer rendere operativo questo framework, seguiremo la trattazione proposta da Michael Betancourt. Ci concentreremo qui sull‚Äôinterpretazione della probabilit√† come distribuzione della nostra certezza soggettiva.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>La Probabilit√† come misura della certezza razionale: un'interpretazione Bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_spaces.html#introduzione",
    "href": "chapters/probability/03_prob_spaces.html#introduzione",
    "title": "27¬† La Probabilit√† come misura della certezza razionale: un‚Äôinterpretazione Bayesiana",
    "section": "",
    "text": "Non-negativit√† e normalizzazione: \\(0 \\leq P(A) \\leq 1\\) per ogni evento \\(A\\), con \\(P(\\Omega) = 1\\).\nAdditivit√† numerabile: Per una successione di eventi disgiunti \\(\\{A_i\\}\\), \\[\nP\\Bigl(\\bigcup_{i} A_i\\Bigr) = \\sum_{i} P(A_i) .\n\\]",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>La Probabilit√† come misura della certezza razionale: un'interpretazione Bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_spaces.html#distribuzione-della-certezza-soggettiva-sugli-elementi",
    "href": "chapters/probability/03_prob_spaces.html#distribuzione-della-certezza-soggettiva-sugli-elementi",
    "title": "27¬† La Probabilit√† come misura della certezza razionale: un‚Äôinterpretazione Bayesiana",
    "section": "27.2 Distribuzione della Certezza Soggettiva sugli Elementi",
    "text": "27.2 Distribuzione della Certezza Soggettiva sugli Elementi\nIn un approccio bayesiano, la probabilit√† rappresenta il grado di certezza soggettiva che attribuiamo al verificarsi di un certo evento. Immaginiamo di possedere una certezza totale pari a 1, che corrisponde alla nostra convinzione complessiva che, tra tutti gli esiti possibili, qualcosa avverr√†. Questa certezza totale deve essere ripartita tra i diversi eventi.\nConsideriamo il seguente spazio campionario discreto:\n\\[\nX = \\{\\Box, \\clubsuit, \\diamondsuit, \\heartsuit, \\spadesuit\\}.\n\\]\nAd ogni elemento \\(x_n \\in X\\) associamo un valore \\(p_n \\geq 0\\), interpretato come la frazione della nostra certezza totale che assegnamo a quell‚Äôevento. Poich√© la certezza complessiva √® 1, la somma dei valori deve essere:\n\\[\np_{\\Box} + p_{\\clubsuit} + p_{\\diamondsuit} + p_{\\heartsuit} + p_{\\spadesuit} = 1.\n\\]\nQuesta collezione \\(\\{ p_{\\Box}, p_{\\clubsuit}, p_{\\diamondsuit}, p_{\\heartsuit}, p_{\\spadesuit} \\}\\), in cui ciascun valore √® compreso tra 0 e 1, √® quella che chiamiamo distribuzione di probabilit√†. Ogni \\(p_n\\) esprime il grado di certezza (in termini relativi) che attribuiamo all‚Äôevento corrispondente a \\(x_n\\).\n\n\n\n\n\n\nFigura¬†27.1: Un‚Äôallocazione proporzionale √® anche conosciuta come distribuzione di probabilit√†.\n\n\n\nQuesta visione ci permette di passare da una certezza assoluta (1) a una distribuzione in cui la certezza √® divisa in porzioni proporzionali tra i vari eventi. Per esempio, se siamo particolarmente convinti che l‚Äôevento \\(\\Box\\) si verifichi, potremmo assegnargli un valore alto, mentre a un evento meno probabile corrisponder√† un valore pi√π basso.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>La Probabilit√† come misura della certezza razionale: un'interpretazione Bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_spaces.html#distribuzione-della-certezza-sugli-sottoinsiemi",
    "href": "chapters/probability/03_prob_spaces.html#distribuzione-della-certezza-sugli-sottoinsiemi",
    "title": "27¬† La Probabilit√† come misura della certezza razionale: un‚Äôinterpretazione Bayesiana",
    "section": "27.3 Distribuzione della Certezza Sugli Sottoinsiemi",
    "text": "27.3 Distribuzione della Certezza Sugli Sottoinsiemi\nUna volta che abbiamo assegnato un grado di certezza soggettiva a ciascun elemento di \\(X\\), possiamo estendere questa assegnazione a qualsiasi sottoinsieme di \\(X\\). In altre parole, se ad ogni elemento \\(x_n \\in X\\) assegniamo la probabilit√† (cio√®, il grado di certezza) \\(p_n\\), la certezza complessiva che un sottoinsieme \\(\\mathsf{x} \\subset X\\) si realizzi √® data dalla somma dei gradi di certezza dei suoi elementi:\n\\[\nP(\\mathsf{x}) = \\sum_{x_n \\in \\mathsf{x}} p_n.\n\\]\nPer costruzione, valgono le seguenti propriet√†:\n\nLa certezza associata all‚Äôinsieme vuoto √® zero:\n\\[\nP(\\emptyset) = 0.\n\\]\nLa certezza associata all‚Äôintero spazio campionario √® 1:\n\\[\nP(X) = \\sum_{n} p_n = 1.\n\\]\n\nQueste propriet√† sono in linea con l‚Äôidea che la nostra certezza totale (pari a 1) venga completamente distribuita tra tutti gli eventi possibili.\n\n27.3.1 Additivit√†\nSe un sottoinsieme pu√≤ essere suddiviso in parti che non si sovrappongono, il grado di certezza dell‚Äôintero sottoinsieme √® la somma dei gradi di certezza delle parti. Ad esempio, se \\(\\mathsf{x}_1\\) e \\(\\mathsf{x}_2\\) sono sottoinsiemi disgiunti (cio√®, non hanno elementi in comune), allora:\n\\[\nP(\\mathsf{x}_1 \\cup \\mathsf{x}_2) = P(\\mathsf{x}_1) + P(\\mathsf{x}_2).\n\\]\nIn particolare, se \\(\\mathsf{x}\\) √® un sottoinsieme di \\(X\\), il complemento \\(\\mathsf{x}^c\\) (cio√®, tutti gli elementi non in \\(\\mathsf{x}\\)) √® disgiunto da \\(\\mathsf{x}\\) e la loro unione d√† \\(X\\). Quindi:\n\\[\nP(\\mathsf{x}) + P(\\mathsf{x}^c) = 1 \\quad \\Longrightarrow \\quad P(\\mathsf{x}^c) = 1 - P(\\mathsf{x}).\n\\]\n\n\n27.3.2 Sovrapposizione di Sottoinsiemi\nQuando due sottoinsiemi si sovrappongono, la certezza degli elementi comuni viene conteggiata in entrambe le somme. Per chiarire, consideriamo:\n\n\\(\\mathsf{x}_1 = \\{\\Box, \\heartsuit\\}\\),\n\\(\\mathsf{x}_2 = \\{\\Box, \\spadesuit\\}\\).\n\nAllora:\n\nLa certezza di \\(\\mathsf{x}_1\\) √® \\(P(\\mathsf{x}_1) = p_{\\Box} + p_{\\heartsuit}\\).\nLa certezza di \\(\\mathsf{x}_2\\) √® \\(P(\\mathsf{x}_2) = p_{\\Box} + p_{\\spadesuit}\\).\nL‚Äôintersezione √® \\(\\mathsf{x}_1 \\cap \\mathsf{x}_2 = \\{\\Box\\}\\), con certezza \\(p_{\\Box}\\).\nL‚Äôunione √® \\(\\mathsf{x}_1 \\cup \\mathsf{x}_2 = \\{\\Box, \\heartsuit, \\spadesuit\\}\\), con certezza\n\\[\nP(\\mathsf{x}_1 \\cup \\mathsf{x}_2) = p_{\\Box} + p_{\\heartsuit} + p_{\\spadesuit}.\n\\]\n\nNotiamo che:\n\\[\nP(\\mathsf{x}_1) + P(\\mathsf{x}_2) = P(\\mathsf{x}_1 \\cup \\mathsf{x}_2) + p_{\\Box} = P(\\mathsf{x}_1 \\cup \\mathsf{x}_2) + P(\\mathsf{x}_1 \\cap \\mathsf{x}_2).\n\\]\nQuesto √® un esempio del principio di inclusione-esclusione, che garantisce che non contiamo pi√π volte la certezza degli elementi comuni.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>La Probabilit√† come misura della certezza razionale: un'interpretazione Bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_spaces.html#costruzione-delle-distribuzioni-di-certezza",
    "href": "chapters/probability/03_prob_spaces.html#costruzione-delle-distribuzioni-di-certezza",
    "title": "27¬† La Probabilit√† come misura della certezza razionale: un‚Äôinterpretazione Bayesiana",
    "section": "27.4 Costruzione delle Distribuzioni di Certezza",
    "text": "27.4 Costruzione delle Distribuzioni di Certezza\nEsistono diversi modi per ‚Äúcostruire‚Äù una distribuzione di certezza (cio√®, una distribuzione di probabilit√†) su uno spazio finito \\(X\\):\n\nDistribuzione globale:\nPossiamo assegnare simultaneamente il grado di certezza a tutti gli elementi di \\(X\\). In questo approccio si specifica direttamente la distribuzione \\(\\{p(x_n)\\}\\) per ciascun \\(x_n \\in X\\), in modo tale che\n\\[\n\\sum_{x_n \\in X} p(x_n) = 1.\n\\]\n\n\n\n\n\n\n\nFigura¬†27.2: Le misure possono essere costruite specificando le allocazioni degli elementi individuali tutte insieme.\n\n\n\n\nDistribuzione locale:\nPossiamo assegnare il grado di certezza a ciascun elemento uno alla volta, procedendo in maniera sequenziale. Questo metodo ci permette di ‚Äúcostruire‚Äù la distribuzione gradualmente, concentrandoci su un elemento alla volta.\n\n\n\n\n\n\n\nFigura¬†27.3: Le misure possono essere costruite specificando le allocazioni degli elementi individuali uno alla volta.\n\n\n\n\nDistribuzione iterativa:\nUn altro metodo consiste nel suddividere lo spazio campionario in sottoinsiemi disgiunti, assegnare ad ognuno un certo grado di certezza, e poi ripartire iterativamente la certezza all‚Äôinterno di ciascun sottoinsieme fino a raggiungere gli elementi individuali.\n\n\n\n\n\n\n\nFigura¬†27.4: Le misure possono essere costruite allocando la misura totale a sottoinsiemi disgiunti e poi raffinando iterativamente tale allocazione a sottoinsiemi sempre pi√π piccoli.\n\n\n\n\n\nQuesta flessibilit√† consente di adattare l‚Äôapproccio alle esigenze specifiche del problema in esame.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>La Probabilit√† come misura della certezza razionale: un'interpretazione Bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_spaces.html#riflessioni-conclusive",
    "href": "chapters/probability/03_prob_spaces.html#riflessioni-conclusive",
    "title": "27¬† La Probabilit√† come misura della certezza razionale: un‚Äôinterpretazione Bayesiana",
    "section": "27.5 Riflessioni Conclusive",
    "text": "27.5 Riflessioni Conclusive\nL‚Äôinterpretazione della probabilit√† come grado di certezza soggettiva ci offre un modo intuitivo per ragionare su eventi incerti. La nostra certezza totale, pari a 1, viene distribuita tra i vari possibili esiti secondo una distribuzione di probabilit√†:\n\\[\n\\{p_1, p_2, \\dots, p_N\\} \\quad \\text{con} \\quad 0 \\leq p_n \\leq 1 \\quad \\text{e} \\quad \\sum_{n=1}^{N} p_n = 1.\n\\]\nOgni valore \\(p_n\\) rappresenta la frazione della nostra certezza che attribuiamo all‚Äôevento corrispondente a \\(x_n\\). Questo approccio √® particolarmente utile nella statistica bayesiana, dove le probabilit√† vengono interpretate non come frequenze oggettive, ma come gradi di convinzione soggettivi basati sulle informazioni a nostra disposizione.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>La Probabilit√† come misura della certezza razionale: un'interpretazione Bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_spaces.html#esercizi",
    "href": "chapters/probability/03_prob_spaces.html#esercizi",
    "title": "27¬† La Probabilit√† come misura della certezza razionale: un‚Äôinterpretazione Bayesiana",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nEsercizi\n\n\n\n\n\nDal testo di Blitzstein & Hwang (2019), svolgere i seguenti esercizi: 1.4.3, 1.4.4, 1.4.5, 1.4.6, 1.4.9, 1.4.12, 1.4.13.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>La Probabilit√† come misura della certezza razionale: un'interpretazione Bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_spaces.html#bibliografia",
    "href": "chapters/probability/03_prob_spaces.html#bibliografia",
    "title": "27¬† La Probabilit√† come misura della certezza razionale: un‚Äôinterpretazione Bayesiana",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlitzstein, J. K., & Hwang, J. (2019). Introduction to probability. CRC Press.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>La Probabilit√† come misura della certezza razionale: un'interpretazione Bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_sigma-algebra.html",
    "href": "chapters/probability/04_sigma-algebra.html",
    "title": "28¬† Dal Discreto al Continuo: la \\(\\sigma\\)-algebra",
    "section": "",
    "text": "28.1 Introduzione\nNel Capitolo 27 abbiamo visto come definire la probabilit√† su insiemi finiti, ossia in situazioni dove ci sono un numero limitato di esiti (ad esempio, i risultati di un lancio di dado). In quel contesto, la probabilit√† di ogni evento veniva spesso assegnata contando i casi favorevoli su quelli totali.\nTuttavia, in molti casi reali, lo spazio degli esiti non √® finito, ma infinito (ad esempio, l‚Äôinsieme degli interi, o addirittura la retta reale). In queste situazioni, la somma dei casi favorevoli su quelli totali non ha pi√π senso o diventa tecnicamente inapplicabile. Per passare dal caso discreto a quello continuo, abbiamo quindi bisogno di strumenti pi√π sofisticati.\nUno di questi strumenti √® la \\(\\sigma\\)-algebra, che ci aiuta a definire in maniera rigorosa quali sottoinsiemi di uno spazio possiamo considerare ‚Äúmisurabili‚Äù e a cui possiamo assegnare una probabilit√†. In combinazione con gli assiomi di Kolmogorov, la \\(\\sigma\\)-algebra permette di estendere la teoria della probabilit√† dal caso discreto (discusso nel Capitolo 27) al caso continuo, dove la situazione √® pi√π delicata e non tutti i sottoinsiemi possono ricevere una probabilit√†.\nIn questo capitolo, dunque, approfondiremo:",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>Dal Discreto al Continuo: la $\\sigma$-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_sigma-algebra.html#introduzione",
    "href": "chapters/probability/04_sigma-algebra.html#introduzione",
    "title": "28¬† Dal Discreto al Continuo: la \\(\\sigma\\)-algebra",
    "section": "",
    "text": "perch√© non possiamo sempre ‚Äúmisurare tutto‚Äù nello spazio continuo;\ncome la \\(\\sigma\\)-algebra ci fornisce un metodo per assegnare le probabilit√† negli spazi continui;\nin che modo la \\(\\sigma\\)-algebra sia cruciale per soddisfare gli assiomi di Kolmogorov;\nle differenze principali rispetto al caso discreto.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>Dal Discreto al Continuo: la $\\sigma$-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_sigma-algebra.html#la-struttura-della-sigma-algebra",
    "href": "chapters/probability/04_sigma-algebra.html#la-struttura-della-sigma-algebra",
    "title": "28¬† Dal Discreto al Continuo: la \\(\\sigma\\)-algebra",
    "section": "\n28.2 La Struttura della \\(\\sigma\\)-Algebra",
    "text": "28.2 La Struttura della \\(\\sigma\\)-Algebra\nUna \\(\\sigma\\)-algebra \\(\\mathcal{F}\\) su uno spazio campionario \\(\\Omega\\) √® una collezione di sottoinsiemi (eventi) che soddisfa le seguenti propriet√†.\n\nInclusione dello spazio campionario:\\[\n  \\Omega \\in \\mathcal{F}.\n  \\]\nSignifica che l‚Äôevento ‚Äúqualcosa accade‚Äù √® sempre misurabile.\nChiusura rispetto al complemento:\\[\n\\text{Se } A \\in \\mathcal{F} \\text{ allora } A^c = \\Omega \\setminus A \\in \\mathcal{F}.\n\\]\nSe possiamo misurare la probabilit√† di un evento, dobbiamo anche poter misurare la probabilit√† che l‚Äôevento non accada.\nChiusura rispetto a unioni (anche numerabili):\\[\n\\text{Se } A_1, A_2, \\dots \\in \\mathcal{F}, \\text{ allora } \\bigcup_{i=1}^{\\infty} A_i \\in \\mathcal{F}.\n\\]\nSe possiamo misurare una collezione (anche infinita) di eventi, dobbiamo poter misurare anche l‚Äôevento ‚Äúalmeno uno di essi si verifica‚Äù.\n\nTali propriet√† non sono un semplice dettaglio tecnico, ma garantiscono la coerenza del sistema probabilistico: ci assicurano che certe operazioni sugli eventi (complementi, unioni) non producano risultati ‚Äúsenza senso‚Äù per la probabilit√†.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>Dal Discreto al Continuo: la $\\sigma$-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_sigma-algebra.html#relazione-tra-la-sigma-algebra-e-gli-assiomi-di-kolmogorov",
    "href": "chapters/probability/04_sigma-algebra.html#relazione-tra-la-sigma-algebra-e-gli-assiomi-di-kolmogorov",
    "title": "28¬† Dal Discreto al Continuo: la \\(\\sigma\\)-algebra",
    "section": "\n28.3 Relazione tra la \\(\\sigma\\)-algebra e gli Assiomi di Kolmogorov",
    "text": "28.3 Relazione tra la \\(\\sigma\\)-algebra e gli Assiomi di Kolmogorov\nL‚Äôintroduzione della \\(\\sigma\\)-algebra √® necessaria per garantire la coerenza del modello probabilistico. In sintesi:\n\nLa \\(\\sigma\\)-algebra delimita l‚Äôinsieme degli eventi ammessi, ossia quegli insiemi per cui possiamo calcolare la probabilit√†.\nGli assiomi di Kolmogorov specificano le propriet√† che la funzione di probabilit√† \\(P\\) deve rispettare su questi eventi.\nSenza la struttura di \\(\\sigma\\)-algebra, l‚Äôassioma di additivit√† numerabile non sarebbe formulabile in modo rigoroso, poich√© non avremmo garanzia che le operazioni di unione preservino l‚Äôappartenenza all‚Äôinsieme degli eventi ammessi.\n\nIn conclusione, la costruzione formale della probabilit√† richiede non solo una funzione che assegni valori compresi tra 0 e 1 agli eventi, ma anche una struttura matematica che garantisca la coerenza di tali assegnazioni. La \\(\\sigma\\)-algebra assicura che ogni operazione insiemistica fondamentale per il calcolo della probabilit√† sia ben definita, permettendo agli assiomi di Kolmogorov di essere applicati senza ambiguit√†.\n\nEsempio 28.1 (Costruzione di una \\(\\sigma\\)-algebra discreta) Consideriamo lo spazio campionario discreto:\n\\[\n\\Omega = \\{1,2,3\\}.\n\\]\nDefinizione della \\(\\sigma\\)-algebra discreta. La \\(\\sigma\\)-algebra discreta corrisponde all‚Äôinsieme di tutte le parti di \\(\\Omega\\), ovvero l‚Äôinsieme di tutti i suoi sottoinsiemi:\n\\[\n\\mathcal{F} = \\bigl\\{\\varnothing, \\{1\\}, \\{2\\}, \\{3\\}, \\{1,2\\}, \\{1,3\\}, \\{2,3\\}, \\Omega \\bigr\\}.\n\\]\nVerifica delle propriet√† della \\(\\sigma\\)-algebra. Per verificare che \\(\\mathcal{F}\\) sia effettivamente una \\(\\sigma\\)-algebra, controlliamo che soddisfi le seguenti propriet√†:\n\n\nInclusione dell‚Äôinsieme campionario e dell‚Äôinsieme vuoto:\n\nPer definizione, \\(\\Omega \\in \\mathcal{F}\\) e \\(\\varnothing \\in \\mathcal{F}\\).\n\n\n\nChiusura rispetto ai complementi:\n\n\nSe un insieme \\(A\\) appartiene a \\(\\mathcal{F}\\), anche il suo complemento \\(A^c\\) rispetto a \\(\\Omega\\) deve appartenere a \\(\\mathcal{F}\\). Ad esempio:\n\nSe \\(\\{1,2\\} \\in \\mathcal{F}\\), allora \\(\\{1,2\\}^c = \\{3\\} \\in \\mathcal{F}\\).\nAnalogamente, per ogni altro sottoinsieme di \\(\\mathcal{F}\\) il complemento appartiene sempre a \\(\\mathcal{F}\\).\n\n\n\n\n\nChiusura rispetto alle unioni numerabili:\n\n\nNel caso discreto e finito, ogni unione di elementi in \\(\\mathcal{F}\\) appartiene ancora a \\(\\mathcal{F}\\). Ad esempio:\n\n\n\\(\\{1\\} \\cup \\{2\\} = \\{1,2\\} \\in \\mathcal{F}\\).\n\n\\(\\{1,3\\} \\cup \\{2\\} = \\{1,2,3\\} = \\Omega \\in \\mathcal{F}\\).\nPoich√© \\(\\mathcal{F}\\) contiene tutti i possibili sottoinsiemi di \\(\\Omega\\), l‚Äôunione di qualsiasi collezione di elementi di \\(\\mathcal{F}\\) rimane in \\(\\mathcal{F}\\).\n\n\n\n\n\nInterpretazione intuitiva. Poich√© ogni sottoinsieme di \\(\\Omega\\) appartiene a \\(\\mathcal{F}\\), tutti gli eventi possibili sono misurabili. Ad esempio:\n\nL‚Äôevento ‚Äúesce 1 o 2‚Äù √® rappresentato da \\(\\{1,2\\}\\).\nL‚Äôevento ‚Äúnon esce 3‚Äù √® lo stesso evento \\(\\{1,2\\}\\), che √® complementare a \\(\\{3\\}\\).\n\nEsempio di funzione di probabilit√†. Una possibile assegnazione di probabilit√† √® quella di un dado equo a tre facce, dove ogni esito elementare ha la stessa probabilit√†:\n\\[\nP(\\{1\\}) = P(\\{2\\}) = P(\\{3\\}) = \\tfrac{1}{3}.\n\\]\nLe probabilit√† di eventi pi√π complessi si ottengono sommando le probabilit√† degli esiti contenuti nell‚Äôevento:\n\\[\nP(\\{1,2\\}) = P(\\{1\\}) + P(\\{2\\}) = \\tfrac{1}{3} + \\tfrac{1}{3} = \\tfrac{2}{3}.\n\\]\nI valori fondamentali della funzione di probabilit√† rispettano gli assiomi di Kolmogorov:\n\\[\nP(\\Omega) = 1, \\quad P(\\varnothing) = 0.\n\\]",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>Dal Discreto al Continuo: la $\\sigma$-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_sigma-algebra.html#dal-discreto-al-continuo",
    "href": "chapters/probability/04_sigma-algebra.html#dal-discreto-al-continuo",
    "title": "28¬† Dal Discreto al Continuo: la \\(\\sigma\\)-algebra",
    "section": "\n28.4 Dal Discreto al Continuo",
    "text": "28.4 Dal Discreto al Continuo\nDopo aver introdotto il concetto di \\(\\sigma\\)-algebra e il suo ruolo negli assiomi di Kolmogorov, analizziamo le differenze essenziali tra il caso discreto e quello continuo.\n\n28.4.1 Caso Discreto\nQuando lo spazio campionario \\(\\Omega\\) √® finito o numerabile (ad esempio, \\(\\{1, 2, 3, \\dots\\}\\)), la \\(\\sigma\\)-algebra pu√≤ coincidere con l‚Äôinsieme di tutte le parti di \\(\\Omega\\). In questo contesto:\n\nOgni sottoinsieme di \\(\\Omega\\) √® misurabile.\nGli eventi possono essere definiti in modo esplicito senza ambiguit√†.\nGli assiomi di Kolmogorov si applicano direttamente.\nLa probabilit√† di ogni singolo punto pu√≤ essere positiva.\n\n28.4.2 Caso Continuo\nQuando lo spazio campionario √® un insieme non numerabile come \\(\\Omega = [0,1]\\) o \\(\\mathbb{R}\\), la costruzione della \\(\\sigma\\)-algebra diventa pi√π complessa. Non √® possibile includere tutti i sottoinsiemi di \\(\\Omega\\) senza generare contraddizioni logiche. Un esempio classico √® il paradosso di Vitali, che mostra come alcuni insiemi non possano essere misurati in modo coerente.\n\n28.4.3 La \\(\\sigma\\)-algebra di Borel\nPer evitare tali problemi, nel caso continuo si utilizza la \\(\\sigma\\)-algebra di Borel, che include solo i sottoinsiemi ‚Äúben misurabili‚Äù di \\(\\Omega\\), escludendo quelli che potrebbero portare a incoerenze matematiche. Ad esempio:\n\nIntervalli del tipo \\([a,b]\\), \\((-\\infty, 0]\\).\nUnioni numerabili di intervalli.\nComplementi di insiemi misurabili.\n\nInvece, insiemi come quello di Vitali non sono inclusi nella \\(\\sigma\\)-algebra di Borel perch√© non ammettono una misura coerente.\nConfronto tra il caso discreto e il caso continuo.\n\n\n\n\n\n\n\nCaratteristica\nCaso Discreto\nCaso Continuo\n\n\n\nStruttura di \\(\\Omega\\)\nFinito o numerabile (\\(\\{1,2,3,\\dots\\}\\))\nNon numerabile (\\(\\mathbb{R}\\), \\([0,1]\\), ecc.)\n\n\n\\(\\sigma\\)-algebra naturale\nInsieme di tutte le parti di \\(\\Omega\\)\n\n\n\\(\\sigma\\)-algebra di Borel\n\n\nEsempio di evento\n\n\\(\\{\\omega\\}\\), \\(\\{\\omega_1, \\omega_2\\}\\)\n\n\n\\([a,b]\\), \\((-\\infty, 0]\\), unione di intervalli\n\n\nProbabilit√† di un singolo punto\nPu√≤ essere \\(&gt;0\\) (ad es. \\(P(\\{\\omega\\})=1/6\\))\nGeneralmente \\(0\\) se il fenomeno √® continuo\n\n\nProblemi di misurabilit√†\nNon presenti\nNecessaria selezione di insiemi misurabili\n\n\n\nIn sintesi, nel caso discreto, la costruzione della \\(\\sigma\\)-algebra √® immediata: includere tutti i sottoinsiemi non crea difficolt√†, portando alla cosiddetta \\(\\sigma\\)-algebra discreta (o triviale se \\(\\Omega\\) ha un solo elemento).\nNel caso continuo, invece, la costruzione √® pi√π delicata. Non tutti i sottoinsiemi possono essere inclusi nella \\(\\sigma\\)-algebra senza compromettere la coerenza matematica. Per questo motivo, si utilizza la \\(\\sigma\\)-algebra di Borel, che permette di definire correttamente la misura di probabilit√† evitando paradossi.\n\n\n\n\n\n\nCostruzione della \\(\\sigma\\)-algebra di Borel\n\n\n\n\n\nPer costruire la \\(\\sigma\\)-algebra di Borel in \\([0,1]\\) o in \\(\\mathbb{R}\\), si parte dagli intervalli e si aggiungono tutte le unioni e intersezioni numerabili di questi intervalli. Questa procedura genera la pi√π piccola collezione di sottoinsiemi che soddisfa le propriet√† di una \\(\\sigma\\)-algebra.\n\n\nInclusi: Intervalli aperti, chiusi, segmenti, unioni di segmenti, ecc.\n\nEsclusi: Strutture ‚Äúpatologiche‚Äù come l‚Äôinsieme di Vitali, che non possono essere misurate in modo coerente.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>Dal Discreto al Continuo: la $\\sigma$-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_sigma-algebra.html#riflessioni-conclusive",
    "href": "chapters/probability/04_sigma-algebra.html#riflessioni-conclusive",
    "title": "28¬† Dal Discreto al Continuo: la \\(\\sigma\\)-algebra",
    "section": "\n28.5 Riflessioni Conclusive",
    "text": "28.5 Riflessioni Conclusive\nIn questo capitolo, abbiamo esplorato come la probabilit√† possa essere estesa dal caso discreto, dove possiamo tranquillamente lavorare con insiemi finiti, al caso continuo, dove ci si confronta con spazi infinitamente densi. Abbiamo compreso che, in questa transizione, la \\(\\sigma\\)-algebra gioca un ruolo cruciale, definendo quali sottoinsiemi sono ‚Äúmisurabili‚Äù, ovvero a quali possiamo assegnare una probabilit√† senza incappare in contraddizioni logiche o matematiche.\nAttraverso la formalizzazione delle \\(\\sigma\\)-algebre e l‚Äôapplicazione degli assiomi di Kolmogorov, abbiamo stabilito le basi per un sistema probabilistico coerente e completo. Nel caso discreto, la costruzione della \\(\\sigma\\)-algebra √® diretta, potendo includere tutti i sottoinsiemi di uno spazio campionario finito o numerabile. Tuttavia, nel caso continuo, abbiamo appreso che non tutti i sottoinsiemi possono essere misurati con coerenza. La \\(\\sigma\\)-algebra di Borel emerge come uno strumento essenziale per navigare questo terreno pi√π complesso.\nLa distinzione tra il caso discreto e il continuo ci dimostra come la matematica possa affrontare con eleganza problemi di diversa natura. Nel discreto, ogni evento pu√≤ avere una probabilit√† positiva e ogni sottoinsieme √® misurabile. Nel continuo, invece, dobbiamo procedere con cautela, selezionando gli insiemi che possiamo ‚Äúmisurare‚Äù in modo coerente. In conclusione, la \\(\\sigma\\)-algebra non √® soltanto un artificio tecnico, ma un elemento fondamentale che permette di costruire un ponte tra il discreto e il continuo, garantendo la coerenza della teoria della probabilit√†.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>Dal Discreto al Continuo: la $\\sigma$-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_sigma-algebra.html#esercizi",
    "href": "chapters/probability/04_sigma-algebra.html#esercizi",
    "title": "28¬† Dal Discreto al Continuo: la \\(\\sigma\\)-algebra",
    "section": "\n28.6 Esercizi",
    "text": "28.6 Esercizi\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nConsidera i seguenti esercizi basati sulla Satisfaction with Life Scale (SWLS).\n\n\nQuali sottoinsiemi sono eventi ammissibili?\nSupponiamo che i punteggi SWLS raccolti siano numeri interi tra 5 e 35.\n\nTra i seguenti insiemi, quali potrebbero essere inclusi in una \\(\\sigma\\)-algebra su questo spazio campionario?\n\n\nA: Tutti gli studenti con punteggio pari o superiore a 25.\n\n\nB: Studenti con punteggio pari.\n\n\nC: Studenti con punteggio multiplo di 3.\n\n\nD: Studenti con punteggio superiore all‚Äôaltezza media degli unicorni.\n\n\n\nQuale criterio potremmo usare per decidere se un insieme √® ammissibile in una \\(\\sigma\\)-algebra?\n\n\n\nChiusura rispetto al complemento\nSe l‚Äôevento A rappresenta gli studenti con punteggio SWLS ‚â• 25, quale sar√† l‚Äôevento complementare A·∂ú?\n\nEsprimilo in termini di punteggi.\n\nSe il 40% degli studenti ha punteggi ‚â• 25, qual √® la probabilit√† empirica dell‚Äôevento A·∂ú?\n\n\n\nEsercizi sulle Operazioni tra Eventi 3. Unione di Eventi\nConsideriamo i seguenti eventi:\n\n\nB: ‚ÄúStudente ha un punteggio SWLS pari‚Äù.\n\n\nC: ‚ÄúStudente ha un punteggio multiplo di 3‚Äù.\n\nElenca i punteggi che appartengono a B ‚à™ C (cio√® lo studente ha un punteggio pari o multiplo di 3).\n\nSe nel campione di 15 studenti, 8 hanno un punteggio in B e 5 in C, e 3 di essi appartengono a entrambi gli insiemi, calcola la probabilit√† empirica di B ‚à™ C usando la formula dell‚Äôunione.\n\n\n\nIntersezione e additivit√† numerabile\n\nSe un evento D rappresenta gli studenti con punteggio ‚â•20 e ‚â§30, possiamo dire che √® incluso nella \\(\\sigma\\)-algebra se B e C lo sono? Perch√©?\nCalcola l‚Äôintersezione B ‚à© C e verifica se i dati raccolti rispettano l‚Äôadditivit√†.\n\n\n\nEsercizi sugli Assiomi di Kolmogorov 5. Assioma della Normalizzazione\n\nSupponiamo di assegnare probabilit√† a eventi definiti sui punteggi SWLS dei 15 studenti.\n\nSe la somma delle probabilit√† di tutti gli eventi possibili non √® 1, cosa significa?\n\nDai un esempio di una distribuzione di probabilit√† su SWLS che rispetti la normalizzazione.\n\n\n\nAssioma dell‚ÄôAdditivit√†\n\nSupponiamo che P(A) = 0.4 e P(A·∂ú) = 0.6.\n\nVerifica se questa distribuzione soddisfa l‚Äôassioma di Kolmogorov.\n\nSe introduciamo un terzo evento E (punteggi tra 15 e 20), come possiamo calcolare P(A ‚à™ E) rispettando gli assiomi?\n\n\n\nEsercizi su Spazi Misurabili e Applicazioni\n\n\nDefinire uno Spazio Misurabile\n\n\nConsideriamo lo spazio campionario \\(\\Omega\\) dei punteggi SWLS e la \\(\\sigma\\)-algebra \\(\\mathcal{F}\\) formata dai sottoinsiemi:\n\n{Punteggi pari}\n\n{Punteggi multipli di 5}\n\n{Punteggi ‚â• 25}\n\n\n\nQuesta collezione rispetta le condizioni di una \\(\\sigma\\)-algebra? Perch√©?\n\n\n\nEsempio di Probabilit√† in un Caso Continuo\n\nSe invece di punteggi discreti avessimo misurato il tempo di risposta a un questionario SWLS (espresso in secondi con valori reali), il modello discreto funzionerebbe?\n\nProva a descrivere un possibile evento misurabile in un caso continuo e spiega perch√© sarebbe pi√π complesso da gestire rispetto al caso discreto.\n\n\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n1. Quali sottoinsiemi sono eventi ammissibili?\n\nGli insiemi che possono essere inclusi in una \\(\\sigma\\)-algebra devono essere chiusi rispetto a unioni, intersezioni e complementi.\n\nA (punteggi ‚â• 25), B (punteggi pari), e C (punteggi multipli di 3) possono essere inclusi in una \\(\\sigma\\)-algebra, perch√© sono definiti su criteri chiari e permettono operazioni insiemistiche.\n\nD (punteggi superiori alla media degli unicorni) non √® un evento misurabile, poich√© dipende da valori soggettivi e non da una regola fissa applicabile all‚Äôintero spazio campionario.\n\n2. Chiusura rispetto al complemento\n\nL‚Äôevento complementare di A (punteggi ‚â• 25) √® A·∂ú (punteggi &lt; 25).\nSe la probabilit√† empirica di A √® 0.4, la probabilit√† empirica di A·∂ú √®: \\[ P(A·∂ú) = 1 - P(A) = 1 - 0.4 = 0.6 \\]\n\n\nSoluzioni agli Esercizi sulle Operazioni tra Eventi\n3. Unione di Eventi\n\nI punteggi in B sono {6, 8, 10, 12, ‚Ä¶, 34} e quelli in C sono {6, 9, 12, ‚Ä¶, 33}.\n\nB ‚à™ C √® l‚Äôinsieme {6, 8, 9, 10, 12, ‚Ä¶, 34}.\nApplicando la formula dell‚Äôunione: \\[ P(B ‚à™ C) = P(B) + P(C) - P(B ‚à© C) \\] \\[ P(B ‚à™ C) = \\frac{8}{15} + \\frac{5}{15} - \\frac{3}{15} = \\frac{10}{15} = 0.667 \\]\n\n\n4. Intersezione e additivit√† numerabile\n\nL‚Äôevento D (20 ‚â§ SWLS ‚â§ 30) √® un sottoinsieme di B ‚à™ C, quindi se B e C sono inclusi in una \\(\\sigma\\)-algebra, anche D lo sar√†.\n\nB ‚à© C (punteggi pari e multipli di 3) = {6, 12, 18, ‚Ä¶}.\nDalla distribuzione empirica, P(B ‚à© C) = \\(\\frac{3}{15} = 0.2\\).\n\nSoluzioni agli Esercizi sugli Assiomi di Kolmogorov\n5. Assioma della Normalizzazione\n\nSe la somma delle probabilit√† degli eventi possibili non √® 1, significa che il sistema di probabilit√† √® mal definito.\nEsempio corretto di distribuzione: \\[ P(A) = 0.4, P(B) = 0.3, P(A·∂ú) = 0.6, P(B·∂ú) = 0.7 \\] Tutti gli eventi coprono l‚Äôintero spazio campionario senza sovrapposizioni non gestite.\n\n6. Assioma dell‚ÄôAdditivit√†\n\nSe P(A) = 0.4 e P(A·∂ú) = 0.6, allora: \\[ P(A) + P(A·∂ú) = 1 \\] Quindi gli assiomi di Kolmogorov sono rispettati.\nSe introduciamo un evento E (SWLS tra 15 e 20) con P(E) = 0.2, possiamo usare la formula dell‚Äôunione per calcolare P(A ‚à™ E) se A ed E non sono disgiunti.\n\nSoluzioni agli Esercizi su Spazi Misurabili e Applicazioni\n7. Definire uno Spazio Misurabile\n\nL‚Äôinsieme \\(\\mathcal{F}\\) con {Punteggi pari, Punteggi multipli di 5, Punteggi ‚â• 25} rispetta:\n\nInclusione di \\(\\Omega\\).\nChiusura rispetto al complemento.\nChiusura rispetto all‚Äôunione.\n\n\nQuindi √® una \\(\\sigma\\)-algebra valida.\n\n8. Probabilit√† nel Caso Continuo\n\nSe misurassimo tempo di risposta al questionario SWLS in secondi (con valori reali), avremmo bisogno di una densit√† di probabilit√† anzich√© probabilit√† discrete.\nUn evento misurabile potrebbe essere: ‚ÄúTempo di risposta compreso tra 10 e 15 secondi‚Äù.\nLa probabilit√† di un singolo valore (es. esattamente 12 secondi) sarebbe zero nel caso continuo.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>Dal Discreto al Continuo: la $\\sigma$-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_sigma-algebra.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/04_sigma-algebra.html#informazioni-sullambiente-di-sviluppo",
    "title": "28¬† Dal Discreto al Continuo: la \\(\\sigma\\)-algebra",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] grid      stats     graphics  grDevices utils     datasets  methods  \n#&gt; [8] base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] VennDiagram_1.7.3   futile.logger_1.4.3 reshape2_1.4.4     \n#&gt;  [4] thematic_0.1.6      MetBrewer_0.2.0     ggokabeito_0.1.0   \n#&gt;  [7] see_0.11.0          gridExtra_2.3       patchwork_1.3.0    \n#&gt; [10] bayesplot_1.11.1    psych_2.5.3         scales_1.3.0       \n#&gt; [13] markdown_2.0        knitr_1.50          lubridate_1.9.4    \n#&gt; [16] forcats_1.0.0       stringr_1.5.1       dplyr_1.1.4        \n#&gt; [19] purrr_1.0.4         readr_2.1.5         tidyr_1.3.1        \n#&gt; [22] tibble_3.2.1        ggplot2_3.5.1       tidyverse_2.0.0    \n#&gt; [25] rio_1.2.3           here_1.0.1         \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3       futile.options_1.0.1 stringi_1.8.4       \n#&gt;  [4] lattice_0.22-6       hms_1.1.3            digest_0.6.37       \n#&gt;  [7] magrittr_2.0.3       evaluate_1.0.3       timechange_0.3.0    \n#&gt; [10] fastmap_1.2.0        plyr_1.8.9           rprojroot_2.0.4     \n#&gt; [13] jsonlite_1.9.1       formatR_1.14         mnormt_2.1.1        \n#&gt; [16] cli_3.6.4            rlang_1.1.5          munsell_0.5.1       \n#&gt; [19] withr_3.0.2          tools_4.4.2          parallel_4.4.2      \n#&gt; [22] tzdb_0.5.0           colorspace_2.1-1     pacman_0.5.1        \n#&gt; [25] lambda.r_1.2.4       vctrs_0.6.5          R6_2.6.1            \n#&gt; [28] lifecycle_1.0.4      htmlwidgets_1.6.4    pkgconfig_2.0.3     \n#&gt; [31] pillar_1.10.1        gtable_0.3.6         Rcpp_1.0.14         \n#&gt; [34] glue_1.8.0           xfun_0.51            tidyselect_1.2.1    \n#&gt; [37] rstudioapi_0.17.1    farver_2.1.2         htmltools_0.5.8.1   \n#&gt; [40] nlme_3.1-167         rmarkdown_2.29       compiler_4.4.2",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>Dal Discreto al Continuo: la $\\sigma$-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_sigma-algebra.html#bibliografia",
    "href": "chapters/probability/04_sigma-algebra.html#bibliografia",
    "title": "28¬† Dal Discreto al Continuo: la \\(\\sigma\\)-algebra",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlitzstein, J. K., & Hwang, J. (2019). Introduction to probability. CRC Press.\n\n\nChan, J. C. C., & Kroese, D. P. (2025). Statistical Modeling and Computation (2¬™ ed.). Springer.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>Dal Discreto al Continuo: la $\\sigma$-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_conditional_prob.html",
    "href": "chapters/probability/05_conditional_prob.html",
    "title": "29¬† Probabilit√† condizionata",
    "section": "",
    "text": "29.1 Introduzione\nLa probabilit√† condizionata esprime la probabilit√† di un evento tenendo conto del verificarsi di un altro evento. Questo concetto √® fondamentale perch√© riflette il modo in cui aggiorniamo le nostre credenze alla luce di nuove informazioni. Ad esempio, la probabilit√† che piova domani pu√≤ essere diversa a seconda delle condizioni atmosferiche di oggi: osservare un cielo nuvoloso modifica la nostra valutazione della probabilit√† di pioggia. In questo senso, ogni nuova informazione pu√≤ confermare, rafforzare o mettere in discussione le credenze preesistenti.\nLa probabilit√† condizionata ha un ruolo centrale non solo nella teoria della probabilit√†, ma anche nelle applicazioni quotidiane e scientifiche. In molti contesti, le probabilit√† sono implicitamente condizionate da informazioni preesistenti, anche quando non lo esplicitiamo formalmente. Comprendere e quantificare questo processo di aggiornamento delle credenze ci consente di gestire in modo pi√π efficace l‚Äôincertezza, rendendo la probabilit√† uno strumento dinamico per la decisione e l‚Äôinferenza.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>Probabilit√† condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_conditional_prob.html#indipendenza-stocastica",
    "href": "chapters/probability/05_conditional_prob.html#indipendenza-stocastica",
    "title": "29¬† Probabilit√† condizionata",
    "section": "\n29.2 Indipendenza Stocastica",
    "text": "29.2 Indipendenza Stocastica\nUn caso particolare di aggiornamento delle probabilit√† si verifica quando due eventi non si influenzano a vicenda. In tal caso, la probabilit√† congiunta di pi√π eventi si calcola in modo molto pi√π semplice, grazie alla propriet√† di indipendenza.\n\n29.2.1 Indipendenza di Due Eventi\n\nDefinizione 29.1 Due eventi \\(A\\) e \\(B\\) si dicono indipendenti se la probabilit√† che si verifichino entrambi √® uguale al prodotto delle probabilit√† dei singoli eventi:\n\\[\nP(A \\cap B) \\;=\\; P(A)\\, P(B).\n\\tag{29.1}\\]\n\nIn altre parole, sapere che \\(A\\) si √® verificato non influisce sul valore di \\(P(B)\\), e viceversa. Quando questa condizione √® soddisfatta, si scrive \\(A \\perp B\\) per indicare l‚Äôindipendenza dei due eventi.\n\nEsempio 29.1 Supponiamo di lanciare due monete distinte e di considerare i seguenti eventi:\n\n\n\\(A\\) = ‚ÄúLa prima moneta mostra Testa‚Äù\n\n\n\\(B\\) = ‚ÄúLa seconda moneta mostra Testa‚Äù\n\nPoich√© il risultato della prima moneta non influisce in alcun modo su quello della seconda, i due eventi sono indipendenti. In particolare, la probabilit√† di ottenere ‚ÄúTesta‚Äù su una moneta √®:\n\\[\nP(A) \\;=\\; P(B) \\;=\\; \\frac{1}{2}.\n\\]\nLa probabilit√† che entrambe le monete mostrino Testa (cio√® che si verifichino contemporaneamente gli eventi \\(A\\) e \\(B\\)) √® data dal prodotto delle loro probabilit√†:\n\\[\nP(A \\cap B) \\;=\\; P(A)\\,P(B)\n\\;=\\; \\frac{1}{2} \\times \\frac{1}{2}\n\\;=\\; \\frac{1}{4}.\n\\]\nPoich√© questa relazione √® soddisfatta, possiamo concludere che \\(A\\) e \\(B\\) sono eventi indipendenti.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>Probabilit√† condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_conditional_prob.html#indipendenza-di-un-insieme-di-eventi",
    "href": "chapters/probability/05_conditional_prob.html#indipendenza-di-un-insieme-di-eventi",
    "title": "29¬† Probabilit√† condizionata",
    "section": "\n29.3 Indipendenza di un Insieme di Eventi",
    "text": "29.3 Indipendenza di un Insieme di Eventi\nIl concetto di indipendenza non si limita a due soli eventi, ma pu√≤ estendersi a un insieme arbitrario di eventi. In generale, diciamo che \\(\\{A_i : i \\in I\\}\\) √® un insieme di eventi indipendente se, per ogni sottoinsieme finito \\(J \\subseteq I\\), la probabilit√† dell‚Äôintersezione degli eventi in \\(J\\) coincide con il prodotto delle probabilit√† di ciascun evento:\n\\[\nP \\Bigl(\\bigcap_{i \\in J} A_i\\Bigr)\n\\;=\\;\n\\prod_{i \\in J} P(A_i).\n\\tag{29.2}\\]\nQuesta condizione richiede che ogni combinazione di eventi presenti la stessa propriet√† di non influenzarsi a vicenda. L‚Äôindipendenza pu√≤ essere:\n\nun‚Äôassunzione semplificante in molti modelli (ad esempio, ipotizzare che le variabili di un questionario misurino propriet√† ‚Äúindipendenti‚Äù dei partecipanti);\n\nuna caratteristica empirica emersa dai dati, da verificare attraverso analisi apposite.\n\n\nEsempio 29.2 Consideriamo una sequenza di tre lanci di una moneta equilibrata e definiamo gli eventi:\n\n\n\\(A_1\\) = ‚ÄúIl primo lancio mostra Testa‚Äù.\n\n\\(A_2\\) = ‚ÄúIl secondo lancio mostra Testa‚Äù.\n\n\\(A_3\\) = ‚ÄúIl terzo lancio mostra Testa‚Äù.\n\nCiascuno di questi eventi ha probabilit√† \\(1/2\\). Poich√© ogni lancio non influenza gli altri, l‚Äôinsieme \\(\\{A_1, A_2, A_3\\}\\) √® indipendente nel senso pi√π ampio: non solo \\(P(A_1 \\cap A_2) = P(A_1)P(A_2)\\) e simili per coppie, ma vale anche\n\\[\nP(A_1 \\cap A_2 \\cap A_3)\n\\;=\\;\nP(A_1)\\,P(A_2)\\,P(A_3)\n\\;=\\;\n\\left(\\tfrac12\\right)\\left(\\tfrac12\\right)\\left(\\tfrac12\\right)\n\\;=\\;\n\\tfrac18.\n\\]\nIn effetti, per qualunque combinazione di Testa e Croce (ad esempio, ‚ÄúTesta al primo e terzo lancio, Croce al secondo‚Äù), la probabilit√† risulta sempre il prodotto delle probabilit√† dei singoli esiti, confermando l‚Äôindipendenza.\n\n\n29.3.1 Quando gli Eventi Non Sono Indipendenti\nSe per due eventi \\(A\\) e \\(B\\) si ha \\(P(A \\cap B) \\neq P(A) P(B)\\), essi non sono indipendenti. In tal caso, conoscere l‚Äôesito di uno fornisce informazioni sul probabile verificarsi dell‚Äôaltro, e occorre tenere conto di questa dipendenza nei calcoli (ad esempio, usando la probabilit√† condizionata).\n\n29.3.2 Differenza tra Indipendenza ed Eventi Disgiunti\nUn errore frequente √® confondere ‚Äúindipendenti‚Äù con ‚Äúdisgiunti (o mutuamente esclusivi)‚Äù. Due eventi sono disgiunti se non possono avvenire contemporaneamente, cio√®\n\\[\nP(A \\cap B) \\;=\\; 0.\n\\]\nSe \\(P(A)&gt;0\\) e \\(P(B)&gt;0\\) e gli eventi sono disgiunti, non possono essere indipendenti. Infatti, l‚Äôindipendenza richiederebbe\n\\[\nP(A \\cap B) \\;=\\; P(A)\\,P(B),\n\\]\nma, poich√© \\(P(A \\cap B)=0\\) e \\(P(A) P(B)\\) sarebbe positivo, la relazione non pu√≤ valere. Quindi, la disgiunzione implica l‚Äôesclusione reciproca, mentre l‚Äôindipendenza significa che la probabilit√† di uno non risente in alcun modo dell‚Äôaltro.\n\nEsempio 29.3 Nel lancio di un dado a sei facce:\n\n\n\\(C\\) = ‚ÄúEsce un numero pari‚Äù \\(\\{\\;2,4,6\\}\\).\n\n\\(D\\) = ‚ÄúEsce un numero dispari‚Äù \\(\\{\\;1,3,5\\}\\).\n\nI due eventi sono disgiunti, poich√© un numero non pu√≤ essere contemporaneamente pari e dispari; dunque \\(P(C \\cap D)=0\\).\nTuttavia, non sono indipendenti: se lo fossero, si dovrebbe avere \\(P(C \\cap D) = P(C)P(D)\\). Invece,\n\\[\n0 \\;\\neq\\; \\tfrac12 \\,\\times\\, \\tfrac12 \\;=\\; \\tfrac14,\n\\]\nda cui segue che \\(C\\) e \\(D\\) non sono eventi indipendenti.\n\nIn sintesi, gli eventi disgiunti non possono verificarsi insieme, mentre gli eventi indipendenti non influiscono uno sulla probabilit√† dell‚Äôaltro. Entrambe le propriet√† sono importanti ma rispondono a concetti nettamente diversi.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>Probabilit√† condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_conditional_prob.html#probabilit√†-condizionata",
    "href": "chapters/probability/05_conditional_prob.html#probabilit√†-condizionata",
    "title": "29¬† Probabilit√† condizionata",
    "section": "\n29.4 Probabilit√† Condizionata",
    "text": "29.4 Probabilit√† Condizionata\nLa probabilit√† condizionata esprime la probabilit√† di un evento \\(A\\) una volta che si sappia che un altro evento \\(B\\) √® gi√† avvenuto.\n\nDefinizione 29.2 Se \\(P(B) &gt; 0\\), si definisce:\n\\[\nP(A \\mid B)\n\\;=\\;\n\\frac{P(A \\cap B)}{P(B)}.\n\\tag{29.3}\\]\n\nQuesta formula pu√≤ essere letta come un ‚Äúricalcolo‚Äù della probabilit√† di \\(A\\) limitandosi al sottoinsieme di esiti in cui \\(B\\) √® vero.\n\n29.4.1 Interpretazione della Probabilit√† Condizionata\nLa probabilit√† condizionata funge da meccanismo di aggiornamento delle nostre conoscenze. Inizialmente, si dispone di una stima di \\(P(A)\\); dopo aver appreso che un evento correlato \\(B\\) si √® verificato, si ‚Äúrestringe‚Äù il campo agli esiti compatibili con \\(B\\) e si riassegna la probabilit√† di \\(A\\) su questa base.\n\n\nEsempio intuitivo: Se si sa che una persona ha la febbre (\\(B\\)), la probabilit√† che abbia l‚Äôinfluenza (\\(A\\)) aumenta rispetto a quella calcolata sull‚Äôintera popolazione.\n\nQuesta capacit√† di ‚Äúaggiornare le credenze‚Äù fa della probabilit√† condizionata uno strumento fondamentale in:\n\n\ninferenze statistiche, per gestire informazioni parziali o acquisite progressivamente;\n\n\nteoria dell‚Äôapprendimento, quando si valutano ipotesi o modelli a fronte di nuovi dati;\n\n\nmodellizzazione delle dipendenze tra eventi, in cui la conoscenza di un evento influenza la probabilit√† di un altro.\n\n\nEsempio 29.4 Lanciamo due dadi equilibrati consecutivamente.\nDato che la somma dei dadi √® 10, qual √® la probabilit√† che uno dei due dadi mostri un 6?\nDefiniamo:\n\n\nB come l‚Äôevento che la somma sia 10:\\[ B = \\{(4, 6), (5, 5), (6, 4)\\}. \\]\n\n\nA come l‚Äôevento che uno dei due dadi mostri un 6:\\[ A = \\{(1, 6), \\dots, (5, 6), (6, 1), \\dots, (6, 5)\\}. \\]\n\n\nL‚Äôintersezione tra A e B √®:\\[ A \\cap B = \\{(4, 6), (6, 4)\\}. \\]\nPoich√© in questo esperimento tutti gli eventi elementari sono equiprobabili, la probabilit√† condizionata \\(P(A | B)\\) √® data da:\\[\nP(A | B) = \\frac{P(A \\cap B)}{P(B)} = \\frac{\\frac{2}{36}}{\\frac{3}{36}} = \\frac{2}{3}.\n\\]\nQuindi, la probabilit√† che uno dei due dadi mostri un 6, sapendo che la somma √® 10, √® \\(\\frac{2}{3}\\).\n\n\nEsempio 29.5 Somma di due dadi\nConsideriamo il lancio di due dadi equilibrati e calcoliamo la probabilit√† che la somma dei punteggi risulti minore di 8.\n\n\nSenza informazioni aggiuntive\n\nOgni dado pu√≤ assumere valori da 1 a 6, per un totale di 36 possibili combinazioni \\((6 \\times 6)\\).\n\nTra queste 36, esistono 21 combinazioni in cui la somma √® minore di 8.\n\nDunque la probabilit√† iniziale √®: \\[\nP(\\text{Somma} &lt; 8)\n\\;=\\;\n\\frac{21}{36}\n\\;\\approx\\; 0{.}58.\n\\]\n\n\n\n\nCon informazione aggiuntiva\nSupponiamo di sapere che la somma uscita √® dispari. Questa nuova informazione restringe lo spazio degli esiti possibili:\n\nSolo 18 combinazioni su 36 producono un risultato dispari.\n\nTra queste 18, 12 combinazioni hanno somma minore di 8.\n\nPertanto, la probabilit√† condizionata diventa: \\[\nP(\\text{Somma} &lt; 8 \\,\\mid\\, \\text{Somma dispari})\n\\;=\\;\n\\frac{12}{18}\n\\;=\\;\n0{.}67.\n\\]\n\n\n\n\nConfrontando i due risultati (\\(0{,}58\\) senza informazioni contro \\(0{,}67\\) con l‚Äôinformazione ‚Äúsomma dispari‚Äù), osserviamo come la probabilit√† di un evento possa cambiare una volta ottenuta un‚Äôinformazione aggiuntiva.\nCodice in R.\nNel codice R che segue, utilizziamo l‚Äôinsieme di tutte le combinazioni di lanci per verificare numericamente i risultati:\n\n# 1. Definiamo i possibili valori di un dado\nr &lt;- 1:6  \n\n# 2. Costruiamo tutte le combinazioni possibili (i, j)\n#    in cui i e j vanno da 1 a 6.\n#    In totale ci aspettiamo 36 combinazioni (6 x 6).\nsample &lt;- expand.grid(i = r, j = r)  \nnrow(sample)  # Contiamo quante sono: dovrebbero essere 36\n#&gt; [1] 36\n\n# 3. Selezioniamo solo le coppie (i, j) in cui la somma √® minore di 8.\n#    Verifichiamo quante sono e le confrontiamo con il totale.\nevent &lt;- subset(sample, i + j &lt; 8)\ncat(nrow(event), \"/\", nrow(sample), \"\\n\")  # Dovrebbe stampare 21 / 36\n#&gt; 21 / 36\n\n# 4. Selezioniamo ora solo le coppie con somma dispari.\n#    %% √® l‚Äôoperatore \"modulo\": (i + j) %% 2 != 0 verifica se la somma √® dispari.\nsample_odd &lt;- subset(sample, (i + j) %% 2 != 0)\nnrow(sample_odd)  # Dovrebbe essere 18\n#&gt; [1] 18\n\n# 5. Calcoliamo quante coppie hanno somma minore di 8 tra quelle con somma dispari.\nevent_odd &lt;- subset(sample_odd, i + j &lt; 8)\ncat(nrow(event_odd), \"/\", nrow(sample_odd), \"\\n\")  # Dovrebbe stampare 12 / 18\n#&gt; 12 / 18\n\nSecondo la Equazione¬†29.3, se definiamo\n\n\n\\(A\\) = ‚ÄúSomma &lt; 8‚Äù\n\n\n\\(B\\) = ‚ÄúSomma dispari‚Äù,\n\nallora \\(P(A \\cap B) = 12/36\\) e \\(P(B) = 18/36\\). Di conseguenza,\n\\[\nP(A \\mid B)\n\\;=\\;\n\\frac{P(A \\cap B)}{P(B)}\n\\;=\\;\n\\frac{12/36}{18/36}\n\\;=\\;\n\\frac{12}{18}\n\\;=\\;\n0{.}67.\n\\]\nQuesto esempio dimostra come la probabilit√† condizionata consenta di aggiornare la stima di un evento alla luce di nuove informazioni.\n\n\n\n\n\n\n\nScreening per la diagnosi precoce del tumore mammario\n\n\n\n\n\nSupponiamo di utilizzare un test diagnostico con le seguenti caratteristiche:\n\n\nSensibilit√† (probabilit√† di test positivo fra le donne malate): 90%.\n\n\nSpecificit√† (probabilit√† di test negativo fra le donne sane): 90%.\n\n\nPrevalenza (percentuale di donne effettivamente malate nella popolazione): 1%.\n\n1. Esempio con 1000 donne.\nPer semplificare i calcoli, immaginiamo di sottoporre a screening 1000 donne a caso:\n\n\nDonne malate (1%): 10 su 1000.\n\nCon una sensibilit√† del 90%, circa 9 di queste 10 donne avranno un esito positivo al test (vere positive).\n\nCirca 1 donna avr√† invece un risultato negativo (falso negativo).\n\n\n\nDonne sane (99%): 990 su 1000.\n\nCon una specificit√† del 90%, circa 891 di queste 990 risulteranno negative al test (vere negative).\n\nLe restanti 99 donne avranno un esito positivo (false positive).\n\n\n\nQuesto ci permette di costruire uno schema riassuntivo (spesso rappresentato sotto forma di tabella o diagramma a blocchi):\n\n\npositive: \\(9\\) (vere positive) + \\(99\\) (false positive) = 108,\n\n\nnegative: \\(1\\) (falso negativo) + \\(891\\) (vero negativo) = 892.\n\n2. Probabilit√† non condizionata di un test positivo.\nLa probabilit√† che una donna, scelta a caso, risulti positiva allo screening (indipendentemente dal fatto che sia malata o sana) si ottiene rapportando il numero di test positivi al totale:\n\\[\nP(\\text{Test positivo})\n\\;=\\;\n\\frac{108}{1000}\n\\;=\\;\n0{.}108\n\\;\\; (10{.}8\\%).\n\\]\nQuesta √® una probabilit√† non condizionata, in quanto considera l‚Äôintera popolazione delle 1000 donne, senza ulteriori informazioni.\n3. Probabilit√† condizionata di essere malate dato un test positivo.\nCi interessa ora sapere: Se una donna ha appena ricevuto un risultato positivo, qual √® la probabilit√† che abbia davvero il cancro al seno?\nMatematicamente, riformuliamo la domanda come:\\[\nP(\\text{Cancro} \\mid \\text{Test positivo}).\n\\]\nOsservando il nostro esempio di 1000 donne:\n\nAbbiamo 108 test positivi in tutto.\n\nSolo 9 di questi test positivi provengono effettivamente da donne malate.\n\nPertanto,\n\\[\nP(\\text{Cancro} \\mid \\text{Test positivo})\n\\;=\\;\n\\frac{9}{108}\n\\;=\\;\n0{.}083\n\\;\\; (8{.}3\\%).\n\\]\nQuesta √® una probabilit√† condizionata, poich√© riguarda soltanto quelle donne gi√† selezionate in base all‚Äôesito positivo del test.\n4. Confronto fra probabilit√† non condizionata e condizionata.\n\n\nProbabilit√† non condizionata (esito positivo): \\(0{.}108\\) (10.8%).\n\n\nProbabilit√† condizionata (avere un tumore, sapendo che il test √® positivo): \\(0{.}083\\) (8.3%).\n\nNotiamo come l‚Äôinformazione aggiuntiva (‚Äúil test √® risultato positivo‚Äù) riduca il numero di casi osservati, focalizzando l‚Äôattenzione su un sottoinsieme della popolazione. In altre parole, la conoscenza di un test positivo aggiorna la nostra stima della probabilit√† di avere la malattia, mostrandoci che, nonostante l‚Äôalta sensibilit√† e specificit√†, la maggior parte dei test positivi riguarda donne sane (false positive), a causa della bassa prevalenza (1%).\nQuesto esempio illustra in modo tangibile la distinzione fra:\n\n\nprobabilit√† non condizionata: la probabilit√† di un evento considerando l‚Äôintera popolazione,\n\n\nprobabilit√† condizionata: la probabilit√† di un evento una volta appresa un‚Äôinformazione aggiuntiva (qui, l‚Äôesito positivo del test).\n\nQuesta differenza √® fondamentale nell‚Äôinterpretazione dei test diagnostici, specialmente quando la malattia √® relativamente rara.\n\n\n\n\n\n\n\n\n\nIl Problema di Monty Hall\n\n\n\n\n\nIl problema di Monty Hall √® un famoso quesito di teoria della probabilit√† che illustra in modo efficace il concetto di probabilit√† condizionata. Questo problema √® diventato celebre grazie a una rubrica tenuta da Marilyn vos Savant nella rivista Parade, in cui rispose a una lettera pubblicata il 9 settembre 1990:\n\n‚ÄúSupponiamo di partecipare a un quiz televisivo e di dover scegliere tra tre porte. Dietro una di esse c‚Äô√® un‚Äôauto, mentre dietro le altre due ci sono delle capre. Scegli una porta, ad esempio la numero 1, e il conduttore, che sa cosa c‚Äô√® dietro ogni porta, ne apre un‚Äôaltra, diciamo la numero 3, rivelando una capra. A questo punto, ti chiede se vuoi cambiare la tua scelta e passare alla porta numero 2. √à vantaggioso cambiare porta?‚Äù Craig. F. Whitaker, Columbia, MD\n\nLa situazione descritta ricorda quella del popolare quiz televisivo degli anni ‚Äô70 Let‚Äôs Make a Deal, condotto da Monty Hall e Carol Merrill. Marilyn vos Savant rispose che il concorrente dovrebbe cambiare porta, poich√© la probabilit√† di vincere l‚Äôauto raddoppia passando da 1/3 a 2/3. Tuttavia, la sua risposta suscit√≤ un acceso dibattito, con molte persone, inclusi alcuni matematici, che sostenevano che cambiare porta non avrebbe offerto alcun vantaggio. Questo episodio ha reso il problema di Monty Hall uno dei pi√π famosi esempi di come l‚Äôintuizione possa portare a conclusioni errate in ambito probabilistico.\nChiarire il Problema.\nLa lettera originale di Craig Whitaker √® piuttosto vaga, quindi per analizzare il problema in modo rigoroso √® necessario fare alcune ipotesi:\n\n\nPosizione dell‚Äôauto: L‚Äôauto √® nascosta in modo casuale ed equiprobabile dietro una delle tre porte.\n\nScelta iniziale del giocatore: Il giocatore sceglie una porta in modo casuale, indipendentemente dalla posizione dell‚Äôauto.\n\nAzione del conduttore: Dopo la scelta del giocatore, il conduttore apre una delle due porte rimanenti, rivelando una capra, e offre al giocatore la possibilit√† di cambiare porta.\n\nScelta del conduttore: Se il conduttore ha la possibilit√† di scegliere tra due porte (entrambe con capre), ne apre una in modo casuale.\n\nCon queste assunzioni, possiamo rispondere alla domanda: Qual √® la probabilit√† che il giocatore vinca l‚Äôauto se decide di cambiare porta?\nDi seguito, esploreremo tre metodi per risolvere il problema di Monty Hall: il diagramma ad albero, l‚Äôanalisi delle probabilit√† e una simulazione.\nMetodo 1: diagramma ad albero.\nIl diagramma ad albero √® uno strumento utile per visualizzare tutti i possibili esiti di un esperimento probabilistico. Nel caso del problema di Monty Hall, possiamo suddividere il processo in tre fasi:\n\n\nPosizione dell‚Äôauto: L‚Äôauto pu√≤ trovarsi dietro una delle tre porte (A, B o C), ciascuna con probabilit√† 1/3.\n\nScelta del giocatore: Il giocatore sceglie una porta in modo casuale, indipendentemente dalla posizione dell‚Äôauto.\n\nAzione del conduttore: Il conduttore apre una delle due porte rimanenti, rivelando una capra.\n\nIl diagramma ad albero mostra tutte le possibili combinazioni di questi eventi. Ad esempio, se l‚Äôauto √® dietro la porta A e il giocatore sceglie la porta B, il conduttore aprir√† la porta C (l‚Äôunica porta rimanente con una capra).\nPasso 1: Identificare lo spazio campionario\nLo spazio campionario √® composto da 12 esiti possibili, rappresentati dalle combinazioni di:\n\nPosizione dell‚Äôauto (A, B, C).\nScelta iniziale del giocatore (A, B, C).\nPorta aperta dal conduttore (una delle due rimanenti con una capra).\n\nEcco un diagramma ad albero che rappresenta questa situazione:\n\n\n\n\n\nFigura¬†29.1: Il diagramma ad albero per il Problema di Monty Hall mostra le probabilit√† associate a ogni possibile esito. I pesi sugli archi rappresentano la probabilit√† di seguire quel particolare percorso, dato che ci troviamo nel nodo padre. Ad esempio, se l‚Äôauto si trova dietro la porta A, la probabilit√† che il giocatore scelga inizialmente la porta B √® pari a 1/3. La colonna pi√π a destra del diagramma mostra la probabilit√† di ciascun esito finale. Ogni probabilit√† di esito √® calcolata moltiplicando le probabilit√† lungo il percorso che parte dalla radice (auto dietro una certa porta) e termina alla foglia (esito finale) (Figura tratta da Lehman, Leighton e Meyer, 2018).\n\n\nPasso 2: Definire l‚Äôevento di interesse\nL‚Äôevento di interesse √® ‚Äúil giocatore vince cambiando porta‚Äù. Questo si verifica quando la porta inizialmente scelta dal giocatore non nasconde l‚Äôauto, e il giocatore decide di cambiare porta.\nGli esiti che soddisfano questa condizione sono:\n\n(Auto A, Scelta B, Apertura C)\n(Auto A, Scelta C, Apertura B)\n(Auto B, Scelta A, Apertura C)\n(Auto B, Scelta C, Apertura A)\n(Auto C, Scelta A, Apertura B)\n(Auto C, Scelta B, Apertura A)\n\nQuesti esiti sono in totale 6.\nPasso 3: Calcolare le probabilit√† degli esiti\nOgni esito ha una probabilit√† specifica, calcolata moltiplicando le probabilit√† lungo il percorso nel diagramma ad albero.\nEsempio di calcolo per l‚Äôesito (Auto A, Scelta B, Apertura C):\n\nLa probabilit√† che l‚Äôauto sia dietro la porta A √® \\(\\frac{1}{3}\\).\nLa probabilit√† che il giocatore scelga la porta B √® \\(\\frac{1}{3}\\).\nLa probabilit√† che il conduttore apra la porta C (che contiene una capra) √® \\(1\\) (poich√© il conduttore deve aprire una porta con una capra, e la porta C √® l‚Äôunica possibile).\n\nLa probabilit√† totale per questo esito √®:\n\\[\nP(\\text{Auto A, Scelta B, Apertura C}) = \\frac{1}{3} \\times \\frac{1}{3} \\times 1 = \\frac{1}{9}.\n\\]\nProcedendo in modo simile per tutti gli altri esiti, otteniamo le probabilit√† per tutti i 12 esiti.\nPasso 4: Calcolare la probabilit√† dell‚Äôevento\nLa probabilit√† di vincere cambiando porta √® la somma delle probabilit√† degli esiti favorevoli.\n\\[\n\\begin{aligned}\nP&(\\text{vincere cambiando porta}) = \\notag \\\\\n&\\quad P(\\text{Auto A, Scelta B, Apertura C}) + P(\\text{Auto A, Scelta C, Apertura B}) + \\notag\\\\  \n&\\quad P(\\text{Auto B, Scelta A, Apertura C}) + \\dots \\notag\n\\end{aligned}\n\\]\n\\[\n= \\frac{1}{9} + \\frac{1}{9} + \\frac{1}{9} + \\frac{1}{9} + \\frac{1}{9} + \\frac{1}{9} = \\frac{6}{9} = \\frac{2}{3}.\n\\]\nLa probabilit√† di vincere mantenendo la scelta originale √® il complemento:\n\\[\nP(\\text{vincere mantenendo la scelta}) = 1 - P(\\text{vincere cambiando porta}) = 1 - \\frac{2}{3} = \\frac{1}{3}.\n\\]\nLa conclusione √® che il giocatore ha una probabilit√† di vincere pari a \\(\\frac{2}{3}\\) se cambia porta, contro una probabilit√† di \\(\\frac{1}{3}\\) se mantiene la sua scelta iniziale. Cambiare porta √® quindi la strategia vincente.\nMetodo 2: analisi delle probabilit√†.\nIl problema di Monty Hall pu√≤ essere chiarito analizzando i tre scenari possibili, immaginando di essere osservatori esterni che sanno cosa si nasconde dietro ogni porta:\n\n\nPrimo scenario:\n\nIl giocatore sceglie inizialmente la porta con una capra (chiamiamola ‚Äúcapra 1‚Äù).\n\nIl conduttore apre l‚Äôaltra porta con la ‚Äúcapra 2‚Äù.\n\nSe il giocatore cambia porta, vince l‚Äôautomobile.\n\n\n\nSecondo scenario:\n\nIl giocatore sceglie inizialmente la porta con l‚Äôaltra capra (‚Äúcapra 2‚Äù).\n\nIl conduttore apre la porta con la ‚Äúcapra 1‚Äù.\n\nSe il giocatore cambia porta, vince l‚Äôautomobile.\n\n\n\nTerzo scenario:\n\nIl giocatore sceglie inizialmente la porta con l‚Äôautomobile.\n\nIl conduttore apre una delle due porte con una capra (non importa quale).\n\nSe il giocatore cambia porta, perde l‚Äôautomobile.\n\n\n\nAll‚Äôinizio del gioco, il giocatore ha:\n\n\n1/3 di probabilit√† di scegliere l‚Äôautomobile.\n\n\n2/3 di probabilit√† di scegliere una capra.\n\nDopo la scelta iniziale, il conduttore apre una porta con una capra, ma questa azione non altera le probabilit√† iniziali. Il giocatore si trova quindi con due porte chiuse: quella scelta inizialmente e una rimanente.\n\nSe il giocatore ha scelto l‚Äôautomobile inizialmente (1/3 di probabilit√†), cambiando porta perde.\n\nSe il giocatore ha scelto una capra inizialmente (2/3 di probabilit√†), cambiando porta vince l‚Äôautomobile.\n\nIn sintesi, cambiando porta, il giocatore ha 2/3 di probabilit√† di vincere l‚Äôautomobile, mentre mantenendo la scelta iniziale ha solo 1/3 di probabilit√†. Pertanto, la strategia migliore √® cambiare porta per massimizzare le possibilit√† di vittoria.\nMetodo 3: simulazione.\nPer confermare il risultato, possiamo eseguire una simulazione. Ripetendo il gioco migliaia di volte, possiamo confrontare la frequenza con cui il giocatore vince cambiando porta rispetto a quando mantiene la scelta iniziale.\nEcco un esempio di codice in R per la simulazione:\n\n# Numero di simulazioni da effettuare.\n# Pi√π √® grande B, pi√π precisa sar√† la stima.\nB &lt;- 10000  \n\n# Definiamo una funzione \"monty_hall\" che\n# a) simula un gioco\n# b) restituisce TRUE/FALSE a seconda che il giocatore vinca l'auto o no.\nmonty_hall &lt;- function(strategy){\n  \n  # 1. Dichiariamo le porte possibili, in forma di stringhe.\n  doors &lt;- c(\"1\", \"2\", \"3\")\n  \n  # 2. Stabiliamo dove si trova il premio (auto) e le capre.\n  #    \"prize\" sar√† un vettore con dentro \"car\" per la porta con l‚Äôauto \n  #    e \"goat\" per quelle con la capra.\n  #    La funzione sample() crea una distribuzione casuale di \"car\" e \"goat\".\n  prize &lt;- sample(c(\"car\", \"goat\", \"goat\"))\n  \n  # 3. Troviamo qual √® la porta che ha la macchina.\n  prize_door &lt;- doors[ prize == \"car\" ]\n  \n  # 4. Il giocatore fa la sua prima scelta, pescando a caso fra le 3 porte.\n  my_pick &lt;- sample(doors, 1)\n  \n  # 5. Il conduttore deve aprire una porta che:\n  #    - non sia la mia (my_pick)\n  #    - non abbia la macchina (prize_door)\n  #    Cos√¨ facendo, rivela una porta con la capra.\n  #    Se ci sono due porte con capra, ne sceglie una a caso.\n  show &lt;- sample(doors[!doors %in% c(my_pick, prize_door)], 1)\n  \n  # 6. La strategia \"stick\" significa: RESTARE sulla scelta iniziale (my_pick).\n  #    La strategia \"switch\" significa: CAMBIARE porta, passando a quella\n  #    rimasta tra le due che NON sono state aperte.\n  stick &lt;- my_pick\n  switch &lt;- doors[!doors %in% c(my_pick, show)]\n  \n  # 7. Se la strategia scelta (in input) √® \"stick\", la mia scelta finale √® \"stick\".\n  #    Altrimenti, √® \"switch\".\n  final_choice &lt;- ifelse(strategy == \"stick\", stick, switch)\n  \n  # 8. La funzione restituisce TRUE se la scelta finale coincide con la porta premiata,\n  #    altrimenti FALSE.\n  return(final_choice == prize_door)\n}\n\nNel codice qui sopra:\n\n\nmy_pick √® la porta che il giocatore sceglie subito.\n\nshow √® la porta che il conduttore mostra, rivelando la capra.\n\nstick rimane la scelta iniziale (quindi √® my_pick).\n\nswitch √® la porta che rimane fra le non aperte e non scelte inizialmente.\n\nAl termine, la funzione monty_hall() stabilisce se, con la strategia considerata, si vince (TRUE) o si perde (FALSE).\n\n# Simuliamo B volte la strategia \"stick\" (non cambiare mai la scelta iniziale).\nstick_results &lt;- replicate(B, monty_hall(\"stick\"))\n\n# stick_results √® un vettore di TRUE/FALSE lungo B.\n# Per scoprire la percentuale di vittorie, calcoliamo la media dei TRUE.\nmean(stick_results)\n#&gt; [1] 0.3278\n\n\n# Simuliamo B volte la strategia \"switch\" (cambiare sempre la scelta iniziale).\nswitch_results &lt;- replicate(B, monty_hall(\"switch\"))\n\n# Anche qui, calcoliamo la media per sapere quante volte abbiamo vinto l‚Äôauto.\nmean(switch_results)\n#&gt; [1] 0.6678\n\n\nLa media di un vettore di TRUE/FALSE in R √® pari alla frazione di TRUE.\nIn questo modo, mean(stick_results) ci dice la probabilit√† di vincere restando sulla scelta iniziale.\n\nmean(switch_results) ci dice la probabilit√† di vincere se si cambia sempre porta dopo l‚Äôintervento del conduttore.\n\nRisultati attesi:\n\n\nMantenere la Scelta Iniziale: La frequenza di vittoria dovrebbe essere circa 1/3 (33.3%).\n\nCambiare Porta: La frequenza di vittoria dovrebbe essere circa 2/3 (66.6%).\n\nLa simulazione conferma che cambiare porta aumenta la probabilit√† di vincere da 1/3 a 2/3, dimostrando che la strategia ottimale nel problema di Monty Hall √® quella di cambiare porta dopo che il conduttore ha rivelato una capra.\nIn sintesi, il problema di Monty Hall mette in luce come l‚Äôintuizione possa trarci in inganno quando ci confrontiamo con scenari probabilistici. Attraverso l‚Äôuso del diagramma ad albero, un‚Äôanalisi delle probabilit√† e l‚Äôesecuzione di simulazioni, abbiamo dimostrato che cambiare porta raddoppia le possibilit√† di vincita, facendole passare da 1/3 a 2/3. Questo risultato, in apparente contrasto con ci√≤ che potrebbe sembrare intuitivo, costituisce un esempio emblematico dell‚Äôimportanza di adottare un approccio formale nella valutazione delle probabilit√†, anzich√© affidarsi esclusivamente a impressioni iniziali che spesso si rivelano fuorvianti.\n\n\n\n\n\n\n\n\n\nIl paradosso di Simpson\n\n\n\n\n\nNel contesto della probabilit√† condizionata, un fenomeno particolarmente interessante e, al tempo stesso, controintuitivo √® il paradosso di Simpson. Questo paradosso si verifica quando una tendenza osservata in diversi gruppi di dati separati scompare o addirittura si inverte una volta che i gruppi vengono combinati.\nIl paradosso di Simpson evidenzia l‚Äôimportanza di considerare le variabili confondenti e di analizzare i dati con grande attenzione per evitare di trarre conclusioni errate o fuorvianti. √à un esempio emblematico di come l‚Äôinterpretazione dei dati statistici richieda non solo strumenti matematici, ma anche una profonda comprensione del contesto e delle relazioni tra le variabili coinvolte.\nUn caso storico di paradosso di Simpson riguarda l‚Äôapplicazione della pena di morte negli Stati Uniti (Radelet & Pierce, 1991). Questo studio analizza 674 processi per omicidio in Florida tra il 1976 e il 1987, esaminando l‚Äôinfluenza della razza dell‚Äôimputato e della vittima sulla probabilit√† di ricevere la pena di morte. I dati riportano il numero di condannati alla pena di morte in base alla razza dell‚Äôimputato e della vittima:\n\n\n\n\n\n\n\n\n\nRazza dell‚Äôimputato\nRazza della vittima\nPena di morte\nNo pena di morte\nTasso di condanna\n\n\n\nBianco\nBianco\n19\n132\n19 / 151 ‚âà 12.6%\n\n\nBianco\nNero\n11\n52\n11 / 63 ‚âà 17.5%\n\n\nNero\nBianco\n6\n37\n6 / 43 ‚âà 14.0%\n\n\nNero\nNero\n1\n9\n1 / 10 = 10.0%\n\n\n\nSe analizziamo i dati separatamente per la razza della vittima, emerge che la probabilit√† di ricevere la pena di morte √® pi√π alta per gli imputati bianchi rispetto agli imputati neri, sia nei casi in cui la vittima era bianca (12.6% vs 14.0%) sia nei casi in cui la vittima era nera (17.5% vs 10.0%).\nTuttavia, quando i dati vengono aggregati senza tenere conto della razza della vittima, si osserva una tendenza opposta:\n\n\n\n\n\n\n\n\nRazza dell‚Äôimputato\nPena di morte\nNo pena di morte\nTasso di condanna\n\n\n\nBianco\n30\n184\n30 / 214 ‚âà 14.0%\n\n\nNero\n7\n46\n7 / 53 ‚âà 13.2%\n\n\n\nAggregando i dati, sembra che gli imputati neri abbiano meno probabilit√† di ricevere la pena di morte rispetto agli imputati bianchi (13.2% vs 14.0%).\nQuesta apparente contraddizione √® il risultato del paradosso di Simpson. La variabile confondente in questo caso √® la razza della vittima: gli omicidi con vittime bianche avevano una probabilit√† molto pi√π alta di portare alla pena di morte rispetto agli omicidi con vittime nere. Poich√© gli imputati bianchi erano pi√π spesso accusati di aver ucciso vittime bianche (per cui la probabilit√† di pena di morte era maggiore), il loro tasso di condanna complessivo risultava pi√π alto. Viceversa, gli imputati neri erano pi√π spesso accusati di aver ucciso vittime nere (per cui la probabilit√† di pena di morte era inferiore), abbassando il loro tasso di condanna complessivo.\nQuesto caso dimostra come l‚Äôaggregazione dei dati senza considerare una variabile confondente (in questo caso, la razza della vittima) possa portare a una conclusione errata e fuorviante. √à essenziale analizzare i dati in modo stratificato per evitare interpretazioni distorte e per comprendere i reali meccanismi sottostanti un fenomeno.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>Probabilit√† condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_conditional_prob.html#indipendenza-e-probabilit√†-condizionata",
    "href": "chapters/probability/05_conditional_prob.html#indipendenza-e-probabilit√†-condizionata",
    "title": "29¬† Probabilit√† condizionata",
    "section": "\n29.5 Indipendenza e Probabilit√† Condizionata",
    "text": "29.5 Indipendenza e Probabilit√† Condizionata\nL‚Äôindipendenza tra due eventi \\(A\\) e \\(B\\) pu√≤ essere interpretata intuitivamente attraverso la probabilit√† condizionata. Due eventi sono indipendenti se il verificarsi di uno non influenza la probabilit√† di verificarsi dell‚Äôaltro. In altre parole, conoscere che \\(B\\) √® accaduto non modifica la probabilit√† di \\(A\\), e viceversa.\nQuesta relazione pu√≤ essere formalizzata con le seguenti equazioni:\n\\[\nP(A \\mid B) = \\frac{P(A \\cap B)}{P(B)} = P(A),\n\\]\n\\[\nP(B \\mid A) = \\frac{P(A \\cap B)}{P(A)} = P(B).\n\\]\nPertanto, \\(A\\) e \\(B\\) sono indipendenti se e solo se:\n\\[\nP(A \\mid B) = P(A),\n\\]\n\\[\nP(B \\mid A) = P(B).\n\\]\nQueste condizioni significano che la probabilit√† di \\(A\\) non cambia, indipendentemente dal fatto che \\(B\\) sia accaduto, e lo stesso vale per \\(B\\).\n\n29.5.1 Indipendenza di Tre Eventi\nLa definizione di indipendenza si estende naturalmente a tre eventi \\(A\\), \\(B\\), e \\(C\\), ma con condizioni aggiuntive. Tre eventi sono indipendenti se:\n\n\nOgni coppia di eventi √® indipendente:\n\\[\n\\begin{align}\nP(A \\cap B) &= P(A) P(B), \\\\\nP(A \\cap C) &= P(A) P(C), \\\\\nP(B \\cap C) &= P(B) P(C).\n\\end{align}\n\\]\n\n\nLa probabilit√† congiunta di tutti e tre gli eventi √® uguale al prodotto delle loro probabilit√† individuali:\n\\[\nP(A \\cap B \\cap C) = P(A) P(B) P(C).\n\\]\n\n\nLe prime tre condizioni verificano l‚Äôindipendenza a coppie (indipendenza a due a due), mentre l‚Äôultima condizione garantisce che i tre eventi siano completamente indipendenti. √à importante notare che l‚Äôindipendenza a due a due non implica necessariamente l‚Äôindipendenza completa: per essere indipendenti nel senso completo, tutte e quattro le condizioni devono essere soddisfatte.\nIn sintesi, l‚Äôindipendenza tra eventi implica che il verificarsi di uno di essi non fornisce alcuna informazione sulla probabilit√† del verificarsi degli altri. Nel caso di due eventi, questa propriet√† si traduce nell‚Äôinvarianza della probabilit√† condizionata. Per tre o pi√π eventi, l‚Äôindipendenza richiede sia l‚Äôindipendenza a coppie sia la condizione pi√π forte sull‚Äôintersezione di tutti gli eventi.\nQuesti concetti sono fondamentali nella probabilit√† e nella statistica, poich√© semplificano molti calcoli e forniscono una base per modelli pi√π complessi.\n\nEsempio 29.6 Indipendenza tra Eventi in un Mazzo di Carte\nScenario 1: Mazzo Completo (52 Carte)\nConsideriamo un mazzo standard di 52 carte. Ogni seme (picche, cuori, quadri, fiori) contiene 13 carte, e nel mazzo ci sono 4 Regine in totale. Definiamo i seguenti eventi:\n\n\n\\(A\\) = ‚ÄúPescare una carta di picche‚Äù,\n\n\n\\(B\\) = ‚ÄúPescare una carta Regina‚Äù.\n\n\nProbabilit√† di \\(A\\). Poich√© ci sono 13 picche in un mazzo di 52 carte, \\[\nP(A) = \\frac{13}{52} = \\frac{1}{4}.\n\\]\nProbabilit√† di \\(B\\). Ci sono 4 Regine su 52 carte, quindi \\[\nP(B) = \\frac{4}{52} = \\frac{1}{13}.\n\\]\nProbabilit√† congiunta \\(P(A \\cap B)\\). L‚Äôunica carta che √® contemporaneamente ‚Äúpicche‚Äù e ‚ÄúRegina‚Äù √® la Regina di picche, perci√≤: \\[\nP(A \\cap B) = \\frac{1}{52}.\n\\]\n\nPer verificare l‚Äôindipendenza di \\(A\\) e \\(B\\), confrontiamo \\(P(A \\cap B)\\) con \\(P(A)\\,P(B)\\):\n\\[\nP(A)\\,P(B)\n= \\frac{1}{4} \\times \\frac{1}{13}\n= \\frac{1}{52},\n\\] \\[\nP(A \\cap B)\n= \\frac{1}{52}.\n\\]\nPoich√© \\(P(A \\cap B) = P(A)\\,P(B)\\), i due eventi sono indipendenti quando il mazzo √® completo.\nScenario 2: Mazzo Ridotto (51 Carte)\nOra rimuoviamo una carta qualunque dal mazzo ‚Äî ad esempio il ‚Äú2 di quadri‚Äù ‚Äî portando il totale a 51 carte. Notiamo che la Regina di picche non √® stata rimossa, ma il cambio di composizione potrebbe comunque influire sulle probabilit√†.\n\nProbabilit√† di \\(A \\cap B\\). Poich√© la Regina di picche √® ancora presente, pescare quella carta specifica ha ora probabilit√† \\[\nP(A \\cap B) = \\frac{1}{51}.\n\\]\nProbabilit√† di \\(A\\). Il seme di picche non √® stato modificato (restano 13 picche), ma il denominatore √® passato a 51 carte: \\[\nP(A) = \\frac{13}{51}.\n\\]\nProbabilit√† di \\(B\\). Nel mazzo restano ancora 4 Regine (nessuna √® stata rimossa), su 51 carte totali: \\[\nP(B) = \\frac{4}{51}.\n\\]\nProdotto \\(P(A)\\,P(B)\\). Calcolando: \\[\nP(A)\\,P(B)\n= \\frac{13}{51} \\times \\frac{4}{51}\n= \\frac{52}{2601}.\n\\]\n\nConfrontando:\n\\[\nP(A \\cap B)\n= \\frac{1}{51},\n\\quad\\text{mentre}\\quad\nP(A)\\,P(B)\n= \\frac{52}{2601}.\n\\]\nSi verifica che\n\\[\n\\frac{1}{51}\n\\;\\neq\\;\n\\frac{52}{2601}.\n\\]\nPertanto, \\(A\\) e \\(B\\) non sono pi√π indipendenti nel mazzo ridotto.\nIn sintesi, questo esempio mostra come l‚Äôindipendenza tra due eventi dipenda dal contesto:\n\ncon un mazzo completo (52 carte), ‚Äúpescare picche‚Äù e ‚Äúpescare una Regina‚Äù sono eventi indipendenti;\nbasta rimuovere una carta qualunque (anche non correlata direttamente a ‚Äúpicche‚Äù o ‚ÄúRegine‚Äù) perch√© le probabilit√† cambino e gli stessi eventi cessino di essere indipendenti.\n\nIn altre parole, ogni modifica alla composizione del mazzo pu√≤ influire sulle probabilit√† dei singoli eventi e, di conseguenza, sulle loro relazioni di dipendenza o indipendenza.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>Probabilit√† condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_conditional_prob.html#teorema-del-prodotto",
    "href": "chapters/probability/05_conditional_prob.html#teorema-del-prodotto",
    "title": "29¬† Probabilit√† condizionata",
    "section": "\n29.6 Teorema del Prodotto",
    "text": "29.6 Teorema del Prodotto\nA partire dalla definizione di probabilit√† condizionata, possiamo derivare quello che viene chiamato Teorema del Prodotto, noto anche come teorema della probabilit√† composta, regola moltiplicativa o regola della catena. Questo risultato permette di esprimere la probabilit√† congiunta di due o pi√π eventi come il prodotto di probabilit√† condizionate.\n\n29.6.1 Caso di Due Eventi\nPer due eventi \\(A\\) e \\(B\\), il Teorema del Prodotto asserisce che:\n\\[\nP(A \\cap B)\n\\;=\\;\nP(B) \\,\\cdot\\, P(A \\mid B)\n\\;=\\;\nP(A) \\,\\cdot\\, P(B \\mid A).\n\\tag{29.4}\\]\nIn altre parole, la probabilit√† che \\(A\\) e \\(B\\) si verifichino contemporaneamente pu√≤ essere calcolata in due modi equivalenti:\n\n\nprimo modo: prendi la probabilit√† di \\(B\\), quindi moltiplicala per la probabilit√† di \\(A\\), sapendo gi√† che \\(B\\) √® accaduto;\n\nsecondo modo: prendi la probabilit√† di \\(A\\), quindi moltiplicala per la probabilit√† di \\(B\\), sapendo gi√† che \\(A\\) √® accaduto.\n\nL‚Äôordine degli eventi in cui si applica la condizione √® arbitrario, a patto di rispettare la formula e scegliere la condizione corrispondente.\n\n29.6.2 Generalizzazione a \\(n\\) Eventi\nIl Teorema del Prodotto si estende naturalmente al caso di pi√π di due eventi. Se consideriamo \\(n\\) eventi \\(A_1, A_2, \\dots, A_n\\), e assumiamo che\n\\[\nP(A_1 \\cap A_2 \\cap \\cdots \\cap A_{n-1}) \\;&gt;\\; 0,\n\\]\nallora la probabilit√† che tutti questi eventi si verifichino √® data da:\n\\[\n\\begin{aligned}\nP(A_1 \\,\\cap\\, A_2 \\,\\cap\\, \\cdots \\,\\cap\\, A_n)\n&= P(A_1)\n\\;\\times\\; P(A_2 \\mid A_1)\n\\;\\times\\; P(A_3 \\mid A_1 \\cap A_2)\n\\;\\times\\; \\cdots \\\\\n&\\quad \\cdots \\times\\; P(A_n \\mid A_1 \\cap A_2 \\cap \\cdots \\cap A_{n-1}).\n\\end{aligned}\n\\tag{29.5}\\]\nIn pratica, ciascun fattore si ottiene considerando la probabilit√† dell‚Äôevento successivo, condizionata sul verificarsi di tutti gli eventi precedenti. Questa formulazione √® cruciale, ad esempio, nelle analisi di sequenze di eventi o in modelli statistici in cui le probabilit√† vengono ‚Äúaggiornate‚Äù gradualmente mano a mano che si verificano nuove condizioni.\nIl Teorema del Prodotto rappresenta uno dei fondamenti teorici pi√π importanti della probabilit√† e trova applicazioni in numerosi contesti, quali:\n\nla modellazione di processi sequenziali o temporali;\nla scomposizione di problemi complessi in calcoli pi√π semplici e gestibili;\nla teoria delle reti bayesiane e l‚Äôanalisi della probabilit√† condizionata.\n\nGrazie a questo teorema, √® possibile affrontare problemi complessi suddividendoli in passaggi progressivi, in cui ogni probabilit√† condizionata contribuisce alla costruzione della soluzione complessiva in maniera sistematica.\n\n29.6.2.1 Procedura di calcolo\nPer applicare la regola:\n\n\nparti dal primo evento: usa la probabilit√† incondizionata \\(P(A_1)\\);\n\n\ncondiziona progressivamente: moltiplica per \\(P(A_2 \\mid A_1)\\), poi per \\(P(A_3 \\mid A_1 \\cap A_2)\\), e cos√¨ via;\n\ntermina con l‚Äôultimo evento: includi \\(P(A_n \\mid A_1 \\cap \\cdots \\cap A_{n-1})\\).\n\n\nEsempio 29.7 Da un‚Äôurna contenente 6 palline bianche e 4 nere si estrae una pallina per volta, senza reintrodurla nell‚Äôurna. Indichiamo con \\(B_i\\) l‚Äôevento: ‚Äúesce una pallina bianca alla \\(i\\)-esima estrazione‚Äù e con \\(N_i\\) l‚Äôestrazione di una pallina nera. L‚Äôevento: ‚Äúescono due palline bianche nelle prime due estrazioni‚Äù √® rappresentato dalla intersezione \\(\\{B_1 \\cap B_2\\}\\) e, per l‚ÄôEquazione¬†29.4, la sua probabilit√† vale\n\\[\nP(B_1 \\cap B_2) = P(B_1)P(B_2 \\mid B_1).\n\\]\n\\(P(B_1)\\) vale 6/10, perch√© nella prima estrazione \\(\\Omega\\) √® costituito da 10 elementi: 6 palline bianche e 4 nere. La probabilit√† condizionata \\(P(B_2 \\mid B_1)\\) vale 5/9, perch√© nella seconda estrazione, se √® verificato l‚Äôevento \\(B_1\\), lo spazio campionario consiste di 5 palline bianche e 4 nere. Si ricava pertanto:\n\\[\nP(B_1 \\cap B_2) = \\frac{6}{10} \\cdot \\frac{5}{9} = \\frac{1}{3}.\n\\]\nIn modo analogo si ha che\n\\[\nP(N_1 \\cap N_2) = P(N_1)P(N_2 \\mid N_1) = \\frac{4}{10} \\cdot \\frac{3}{9} = \\frac{4}{30}.\n\\]\nSe l‚Äôesperimento consiste nell‚Äôestrazione successiva di 3 palline, la probabilit√† che queste siano tutte bianche, per l‚ÄôEquazione¬†29.5, vale\n\\[\n\\begin{aligned}\nP(B_1 \\cap B_2 \\cap B_3) &=P(B_1)P(B_2 \\mid B_1)P(B_3 \\mid B_1 \\cap B_2) \\notag\\\\\n&=\\frac{6}{10}\\cdot\\frac{5}{9} \\cdot\\frac{4}{8} \\notag\\\\\n&= \\frac{1}{6}.\n\\end{aligned}\n\\]\nLa probabilit√† dell‚Äôestrazione di tre palline nere √® invece:\n\\[\n\\begin{aligned}\nP(N_1 \\cap N_2 \\cap N_3) &= P(N_1)P(N_2 \\mid N_1)P(N_3 \\mid N_1 \\cap N_2)\\notag\\\\\n&= \\frac{4}{10} \\cdot \\frac{3}{9} \\cdot \\frac{2}{8} \\notag\\\\\n&= \\frac{1}{30}.\\notag\n\\end{aligned}\n\\]",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>Probabilit√† condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_conditional_prob.html#teorema-della-probabilit√†-totale",
    "href": "chapters/probability/05_conditional_prob.html#teorema-della-probabilit√†-totale",
    "title": "29¬† Probabilit√† condizionata",
    "section": "\n29.7 Teorema della Probabilit√† Totale",
    "text": "29.7 Teorema della Probabilit√† Totale\nIl Teorema della Probabilit√† Totale ‚Äî anche detto legge della probabilit√† totale ‚Äî permette di calcolare la probabilit√† di un evento \\(A\\) scomponendola rispetto a una partizione di sottoinsiemi che coprono l‚Äôintero spazio campionario. √à particolarmente utile quando si affrontano situazioni con pi√π scenari, categorie o gruppi nei quali ripartire il calcolo di probabilit√†.\n\n29.7.1 Enunciato Generale\n\nDefinizione 29.3 Supponiamo che lo spazio campionario \\(\\Omega\\) sia suddiviso in una partizione di eventi \\(B_1, B_2, \\dots, B_n\\), ossia:\n\n\nmutua esclusivit√†: \\(B_i \\cap B_j = \\varnothing\\) per \\(i \\neq j\\);\n\n\ncopertura totale: \\(\\bigcup_{i=1}^n B_i = \\Omega\\).\n\nAllora, per un qualsiasi evento \\(A \\subseteq \\Omega\\) vale:\n\\[\nP(A)\n\\;=\\;\n\\sum_{i=1}^n P(A \\cap B_i)\n\\;=\\;\n\\sum_{i=1}^n P(A \\mid B_i)\\, P(B_i).\n\\tag{29.6}\\]\nIn altre parole, \\(P(A)\\) pu√≤ essere visto come una media pesata delle probabilit√† condizionate \\(P(A \\mid B_i)\\), con pesi \\(P(B_i)\\).\n\n\n29.7.2 Caso di Due Partizioni\nQuando lo spazio campionario √® ripartito in due soli eventi, \\(B\\) e il suo complementare \\(B^c\\), la formula si semplifica in:\n\\[\n\\begin{aligned}\nP(A)\n&= P(A \\cap B) + P(A \\cap B^c) \\\\\n&= P(A \\mid B)\\,P(B) \\;+\\; P(A \\mid B^c)\\,P(B^c).\n\\end{aligned}\n\\tag{29.7}\\]\n\nEsempio 29.8 Test medico\nAbbiamo:\n\n\n\\(B\\): ‚ÄúUna persona √® malata‚Äù;\n\n\\(B^c\\): ‚ÄúUna persona √® sana‚Äù;\n\n\n\\(A\\): ‚ÄúTest positivo‚Äù.\n\nSecondo il Teorema della Probabilit√† Totale, la probabilit√† di un risultato positivo si ottiene sommando:\n\\[\nP(A)\n= P(\\text{Positivo} \\mid \\text{Malato}) \\,P(\\text{Malato})\n\\;+\\;\nP(\\text{Positivo} \\mid \\text{Sano}) \\,P(\\text{Sano}).\n\\]\n\n\n29.7.3 Applicazioni Principali\n\nAnalisi per Categorie\nQuando la popolazione √® divisa in gruppi \\(B_1, \\dots, B_n\\) (ad esempio, fasce d‚Äôet√† o regioni), la probabilit√† di un evento \\(A\\) si ottiene sommando le probabilit√† di \\(A\\) condizionate a ciascun gruppo, moltiplicate per la frequenza di quel gruppo.\nTeorema di Bayes\nIl denominatore della formula di Bayes √® la somma \\(\\sum_{j=1}^n P(E \\mid H_j)\\,P(H_j)\\), che √® appunto un‚Äôapplicazione della probabilit√† totale. Qui, \\(H_1, \\dots, H_n\\) rappresentano ipotesi alternative (partizione) e \\(E\\) un dato osservato.\n\n\nEsempio 29.9 Urne con Palline di Colori Diversi\nAbbiamo 3 urne, ciascuna con 100 palline:\n\nUrna 1: 75 rosse, 25 blu\n\nUrna 2: 60 rosse, 40 blu\n\nUrna 3: 45 rosse, 55 blu\n\nL‚Äôurna viene scelta a caso (probabilit√† \\(1/3\\) per ciascuna). Qual √® la probabilit√† di estrarre una pallina rossa?\nDefinisco:\n\n\n\\(R\\): ‚ÄúEstraggo una pallina rossa‚Äù;\n\n\n\\(U_i\\): ‚ÄúSeleziono l‚ÄôUrna \\(i\\)‚Äù.\n\nLe urne \\(U_1, U_2, U_3\\) costituiscono una partizione (disgiunte e coprenti \\(\\Omega\\)). Sappiamo:\n\\[\nP(R \\mid U_1)=0.75,\n\\quad\nP(R \\mid U_2)=0.60,\n\\quad\nP(R \\mid U_3)=0.45.\n\\]\nApplicando la probabilit√† totale:\n\\[\n\\begin{aligned}\nP(R)\n&= P(R \\mid U_1)\\,P(U_1) + P(R \\mid U_2)\\,P(U_2) + P(R \\mid U_3)\\,P(U_3)\\\\\n&= 0.75 \\times \\tfrac13 + 0.60 \\times \\tfrac13 + 0.45 \\times \\tfrac13\n= 0.60.\n\\end{aligned}\n\\]\n\n\nEsempio 29.10 Probabilit√† della Depressione in Diverse Fasce d‚ÄôEt√†\nUna popolazione √® suddivisa in 3 gruppi:\n\ngiovani (30%),\nadulti (40%),\n\nanziani (30%).\n\nLe probabilit√† condizionate di soffrire di depressione sono:\n\\[\nP(D \\mid \\text{Giovane}) = 0.10, \\quad\nP(D \\mid \\text{Adulto}) = 0.20, \\quad\nP(D \\mid \\text{Anziano}) = 0.35.\n\\]\nUsando la probabilit√† totale:\n\\[\nP(D)\n= 0.10\\times0.30 + 0.20\\times0.40 + 0.35\\times0.30\n= 0.215.\n\\]\nDunque, circa il 21.5% della popolazione totale soffre di depressione, combinando i tassi per ciascuna fascia.\n\nIn breve, il Teorema della Probabilit√† Totale ‚Äúscompone‚Äù un problema globale in sotto-problemi pi√π specifici, ciascuno condizionato su una porzione dello spazio campionario, permettendo di sommare i risultati finali per ottenere \\(P(A)\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>Probabilit√† condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_conditional_prob.html#riflessioni-conclusive",
    "href": "chapters/probability/05_conditional_prob.html#riflessioni-conclusive",
    "title": "29¬† Probabilit√† condizionata",
    "section": "\n29.8 Riflessioni Conclusive",
    "text": "29.8 Riflessioni Conclusive\nLa probabilit√† condizionata √® uno dei concetti pi√π importanti in statistica, poich√© fornisce il quadro teorico per:\n\ncomprendere e formalizzare l‚Äôindipendenza tra eventi o variabili (assenza di ogni tipo di relazione);\nespandere e generalizzare il calcolo delle probabilit√† (ad esempio, la legge della probabilit√† totale, che scompone in modo sistematico eventi complessi);\n\nalimentare metodi inferenziali avanzati, come il Teorema di Bayes.\n\nIn particolare, il Teorema di Bayes rappresenta uno strumento cardine dell‚Äôinferenza statistica: grazie alla probabilit√† condizionata, √® possibile ‚Äúaggiornare‚Äù in modo continuo le credenze sulle ipotesi (o sui parametri di un modello) alla luce di nuove osservazioni. Tale caratteristica di ‚Äúapprendimento‚Äù graduale rende l‚Äôinferenza bayesiana flessibile e potente, ideale per affrontare situazioni in cui vengono resi disponibili dati aggiuntivi o in cui le condizioni iniziali possono cambiare.\nIn definitiva, la probabilit√† condizionata non solo chiarisce la nozione di indipendenza e getta le fondamenta di metodi inferenziali evoluti, ma soprattutto rappresenta il ‚Äúmotore‚Äù di modelli che si adattano dinamicamente alle nuove informazioni. Questa prospettiva ‚Äúattiva‚Äù nell‚Äôaggiornamento delle probabilit√† √® ci√≤ che rende l‚Äôanalisi statistica uno strumento versatile per descrivere e interpretare il mondo reale.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>Probabilit√† condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_conditional_prob.html#esercizi",
    "href": "chapters/probability/05_conditional_prob.html#esercizi",
    "title": "29¬† Probabilit√† condizionata",
    "section": "\n29.9 Esercizi",
    "text": "29.9 Esercizi\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nEsercizio 1: Soddisfazione con la Vita e Stress Accademico\nUn gruppo di studenti ha compilato la Satisfaction with Life Scale (SWLS) e un questionario sullo stress accademico. Dai dati raccolti emerge che:\n\nIl 40% degli studenti ha riportato un alto livello di stress accademico.\nIl 60% degli studenti ha riportato un basso livello di stress accademico.\nTra gli studenti con alto stress, il 30% ha riportato una soddisfazione con la vita elevata.\nTra gli studenti con basso stress, il 70% ha riportato una soddisfazione con la vita elevata.\n\nCalcola la probabilit√† che uno studente scelto a caso abbia:\n\nUn alto livello di stress e una soddisfazione elevata.\nUna soddisfazione elevata.\nUn alto livello di stress, dato che ha una soddisfazione elevata.\n\nEsercizio 2: Studio del Paradosso di Simpson\nUn‚Äôuniversit√† vuole valutare la relazione tra la frequenza di partecipazione alle lezioni e il successo negli esami finali. I dati raccolti mostrano che:\n\n\n\n\n\n\n\n\nGruppo\nStudenti con alta frequenza\nSuperano l‚Äôesame\nNon superano l‚Äôesame\n\n\n\nA\n40\n30\n10\n\n\nB\n60\n20\n40\n\n\n\n\nCalcola la probabilit√† di superare l‚Äôesame per ciascun gruppo separatamente.\nCalcola la probabilit√† totale di superare l‚Äôesame.\nSpiega se il Paradosso di Simpson si manifesta in questi dati.\n\nEsercizio 3: Il Problema di Monty Hall\nIn un quiz televisivo, un concorrente deve scegliere tra tre porte: dietro una c‚Äô√® un‚Äôauto e dietro le altre due ci sono capre. Dopo la scelta iniziale, il conduttore, che sa cosa c‚Äô√® dietro ogni porta, apre una delle due porte rimanenti rivelando una capra. Il concorrente ha ora la possibilit√† di cambiare la sua scelta.\n\nQual √® la probabilit√† di vincere l‚Äôauto se il concorrente non cambia la sua scelta?\nQual √® la probabilit√† di vincere l‚Äôauto se il concorrente cambia la sua scelta?\nSpiega perch√© cambiare porta √® la strategia migliore.\n\nEsercizio 4: Teorema della Probabilit√† Totale\nUn‚Äôuniversit√† ha tre dipartimenti: Psicologia, Economia e Ingegneria. Le proporzioni di studenti iscritti sono:\n\nPsicologia: 40%\nEconomia: 35%\nIngegneria: 25%\n\nLa probabilit√† di laurearsi in tempo varia per ogni dipartimento:\n\nPsicologia: 70%\nEconomia: 60%\nIngegneria: 80%\n\nCalcola la probabilit√† che uno studente scelto a caso si laurei in tempo.\nEsercizio 5: Urne e Palline\nUn‚Äôurna contiene 5 palline rosse e 7 blu. Si estrae una pallina, si osserva il colore e poi la pallina viene rimessa nell‚Äôurna. Quindi si estrae una seconda pallina.\n\nQual √® la probabilit√† di estrarre due palline rosse?\nQual √® la probabilit√† di estrarre almeno una pallina blu?\nQual √® la probabilit√† di estrarre una pallina rossa alla seconda estrazione, dato che la prima estratta era blu?\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\nEsercizio 1: Soddisfazione con la Vita e Stress Accademico\n\n\nLa probabilit√† che uno studente abbia alto stress e soddisfazione elevata si calcola moltiplicando la probabilit√† condizionata di avere soddisfazione elevata dato l‚Äôalto stress per la probabilit√† di avere alto stress:\n\\[\nP(S \\cap V) = P(V | S) P(S) = 0.30 \\times 0.40 = 0.12.\n\\]\n\n\nLa probabilit√† che uno studente abbia una soddisfazione elevata, indipendentemente dal livello di stress, si ottiene applicando la legge della probabilit√† totale:\n\\[\nP(V) = P(V | S) P(S) + P(V | \\neg S) P(\\neg S)\n\\]\n\\[\n= (0.30 \\times 0.40) + (0.70 \\times 0.60) = 0.12 + 0.42 = 0.54.\n\\]\n\n\nLa probabilit√† che uno studente abbia alto stress sapendo che ha una soddisfazione elevata si calcola utilizzando la formula della probabilit√† condizionata:\n\\[\nP(S | V) = \\frac{P(S \\cap V)}{P(V)} = \\frac{0.12}{0.54} \\approx 0.22.\n\\]\n\n\nEsercizio 2: Studio del Paradosso di Simpson\n\n\n\\(P(E | A) = \\frac{30}{40} = 0.75\\), \\(P(E | B) = \\frac{20}{60} = 0.33\\)\n\n\\(P(E) = P(E | A) P(A) + P(E | B) P(B) = (0.75 \\times 0.40) + (0.33 \\times 0.60) = 0.30 + 0.198 = 0.498\\)\nSe i tassi di successo aggregati mostrano una relazione invertita, il Paradosso di Simpson si manifesta.\n\nEsercizio 3: Il Problema di Monty Hall\n\n\\(P(V | S) = \\frac{1}{3}\\)\n\\(P(V | C) = \\frac{2}{3}\\)\nCambiare porta aumenta le probabilit√† di vincita da \\(1/3\\) a \\(2/3\\), quindi conviene sempre cambiare.\n\nEsercizio 4: Teorema della Probabilit√† Totale\n\\(P(L) = (0.70 \\times 0.40) + (0.60 \\times 0.35) + (0.80 \\times 0.25) = 0.28 + 0.21 + 0.20 = 0.69\\)\nEsercizio 5: Urne e Palline\n\n\\(P(R_1 \\cap R_2) = (5/12) \\times (5/12) = 25/144\\)\n\\(1 - P(R_1 \\cap R_2) = 1 - 25/144 = 119/144\\)\n\\(P(R_2 | B_1) = 5/12\\)",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>Probabilit√† condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_conditional_prob.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/05_conditional_prob.html#informazioni-sullambiente-di-sviluppo",
    "title": "29¬† Probabilit√† condizionata",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.5.3     \n#&gt;  [9] scales_1.3.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.9.1   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         rlang_1.1.5       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       tools_4.4.2       parallel_4.4.2    tzdb_0.5.0       \n#&gt; [21] colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5       R6_2.6.1         \n#&gt; [25] lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.1    \n#&gt; [29] gtable_0.3.6      glue_1.8.0        xfun_0.51         tidyselect_1.2.1 \n#&gt; [33] rstudioapi_0.17.1 farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-167     \n#&gt; [37] rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>Probabilit√† condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_conditional_prob.html#bibliografia",
    "href": "chapters/probability/05_conditional_prob.html#bibliografia",
    "title": "29¬† Probabilit√† condizionata",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlitzstein, J. K., & Hwang, J. (2019). Introduction to probability. CRC Press.\n\n\nRadelet, M. L., & Pierce, G. L. (1991). Choosing Those Who Will Die: Race and the Death Penalty in Florida. Florida Law Review, 43(1), 1‚Äì34.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>Probabilit√† condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_bayes_theorem.html",
    "href": "chapters/probability/06_bayes_theorem.html",
    "title": "30¬† Il teorema di Bayes",
    "section": "",
    "text": "30.1 Introduzione\nIl teorema di Bayes costituisce un metodo matematico ottimale per risolvere problemi di inferenza induttiva, ovvero situazioni in cui si deducono cause sottostanti, principi generali o strutture complesse a partire da dati parziali e incerti. Trova applicazione in scenari disparati: dalla ricostruzione della percezione tridimensionale basata su segnali retinici all‚Äôinterpretazione degli stati mentali altrui attraverso il comportamento osservabile, fino alla stima di parametri fisici in condizioni sperimentali rumorose (Baker et al., 2011; Ma et al., 2023). La sua efficacia emerge soprattutto in contesti dove le evidenze disponibili non permettono di discriminare univocamente tra ipotesi concorrenti.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_bayes_theorem.html#introduzione",
    "href": "chapters/probability/06_bayes_theorem.html#introduzione",
    "title": "30¬† Il teorema di Bayes",
    "section": "",
    "text": "30.1.1 Incertezza come Fondamento dell‚ÄôInferenza\nUn principio cardine del ragionamento bayesiano √® il riconoscimento dell‚Äôincertezza intrinseca a qualsiasi processo conoscitivo. Anche in un universo deterministico, la complessit√† dei sistemi e i limiti dei nostri sensi rendono impossibile una conoscenza completa. Ad esempio, non possiamo determinare con esattezza infiniti dettagli (come posizione e stato di ogni neurone nel cervello di un interlocutore) n√© accedere direttamente a variabili latenti (come emozioni o intenzioni). Di conseguenza, ogni inferenza conserva un margine probabilistico, che Bayes quantifica e trasforma in uno strumento operativo.\n\n30.1.2 Dinamica Bayesiana: Aggiornare le Credenze\nLa realt√† pu√≤ essere paragonata a una partita di poker pi√π che a una di scacchi: operiamo sempre in condizioni di informazione imperfetta. Le decisioni si basano su un bilanciamento tra conoscenze pregresse (prior) e nuovi indizi (likelihood), in un processo dinamico formalizzato dall‚Äôequazione:\n\\[\nP(H \\mid E) = \\frac{P(E \\mid H) \\cdot P(H)}{P(E)} ,\n\\]\ndove:\n\n\n\\(P(H \\mid E)\\) (posterior): plausibilit√† rivista dell‚Äôipotesi \\(H\\) dopo aver osservato l‚Äôevidenza \\(E\\);\n\n\n\\(P(E \\mid H)\\) (likelihood): probabilit√† di osservare \\(E\\) se \\(H\\) fosse vera;\n\n\n\\(P(H)\\) (prior): fiducia iniziale in \\(H\\);\n\n\n\\(P(E)\\): fattore di normalizzazione.\n\nQuesto meccanismo permette di ricalibrare razionalmente le convinzioni, riducendo l‚Äôincertezza man mano che nuovi dati vengono integrati.\n\n30.1.3 Inferenza Induttiva e Razionalit√† Adattiva\nL‚Äôinferenza induttiva bayesiana rappresenta un pilastro della razionalit√† scientifica e quotidiana. A differenza della logica deduttiva (dove le conclusioni derivano necessariamente dalle premesse), Bayes riconcilia teoria ed evidenza empirica, consentendo previsioni robuste nonostante dati incompleti. Le applicazioni spaziano:\n\nIn psicologia cognitiva, modellando come il cervello interpreta segnali ambigui (Caudek & Bruno, 2024; Domini & Caudek, 2003);\n\nIn intelligenza artificiale, guidando algoritmi di apprendimento automatico (Chivers, 2024);\n\nNelle scienze sociali, per stimare preferenze nascoste da comportamenti osservati.\n\nIl teorema non elimina l‚Äôincertezza, ma fornisce un protocollo formale per gestirla, trasformando l‚Äôinduzione da atto intuitivo a procedura rigorosa. In questo senso, incarna un principio di razionalit√† adattiva, dove l‚Äôottimalit√† non richiede onniscienza, bens√¨ un aggiornamento coerente delle credenze in risposta all‚Äôesperienza.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_bayes_theorem.html#una-rivoluzione-nel-pensiero-probabilistico",
    "href": "chapters/probability/06_bayes_theorem.html#una-rivoluzione-nel-pensiero-probabilistico",
    "title": "30¬† Il teorema di Bayes",
    "section": "\n30.3 Una Rivoluzione nel Pensiero Probabilistico",
    "text": "30.3 Una Rivoluzione nel Pensiero Probabilistico\nNel XVIII secolo, Thomas Bayes (1701-1761), un ecclesiastico presbiteriano, gett√≤ le basi di una vera e propria rivoluzione nel calcolo delle probabilit√† e nella statistica. Il suo contributo √® passato alla storia come teorema di Bayes e, nel corso dei secoli, ha segnato profondamente la scienza e la tecnologia moderne, compresa l‚Äôintelligenza artificiale (Chivers, 2024).\n\n30.3.1 La Figura di Thomas Bayes\nBayes proveniva da una famiglia benestante e studi√≤ teologia a Edimburgo, preparandosi al ministero religioso. Come ricorda il biografo David Bellhouse, Bayes non era un accademico nel senso moderno del termine, ma un erudito libero, interessato alla conoscenza per passione personale (Bellhouse, 2004).\nDurante la sua vita, Bayes pubblic√≤ due testi:\n\n\nUn trattato di teologia: Divine Benevolence: Or, an Attempt to Prove that the Principal End of the Divine Providence and Government is the Happiness of His Creatures (1731), una teodicea che cerca di spiegare come la legge naturale possa ottimizzare il benessere universale.\n\n\nUna difesa del calcolo infinitesimale: An Introduction to the Doctrine of Fluxions (1736), in risposta alle critiche di George Berkeley sugli infinitesimi e i concetti fondamentali del calcolo newtoniano (Jesseph, 1993).\n\nIl lavoro che segn√≤ la svolta nella teoria della probabilit√† fu per√≤ pubblicato postumo, nel 1763, sulle Philosophical Transactions of the Royal Society: An Essay towards Solving a Problem in the Doctrine of Chances. Per la prima volta, si formalizzava un metodo per aggiornare le ipotesi probabilistiche alla luce di nuove evidenze, ponendo le fondamenta dell‚Äôinferenza bayesiana (Stigler, 1990).\n\n30.3.2 Bayes e il Ruolo Culturale della Scienza\nCome sottolinea ancora Bellhouse, nel XVIII secolo era comune, tra le √©lite colte, dedicarsi allo studio di discipline scientifiche per prestigio sociale. Per Bayes, la matematica era dunque una passione coltivata con spirito libero. Il suo merito straordinario fu di spingere l‚Äôinterpretazione della probabilit√† verso una prospettiva epistemologica innovativa, dove la probabilit√† diventa espressione quantitativa della nostra ignoranza sul mondo.\nIn contrapposizione alla visione ‚Äúclassica‚Äù, che vedeva la probabilit√† come frequenza osservabile in eventi ripetuti, Bayes propose che essa potesse rappresentare il grado di fiducia di un osservatore, inevitabilmente influenzato da conoscenze pregresse e da pregiudizi individuali. In questo senso, la probabilit√† assume un carattere dinamico e soggettivo, configurandosi come uno strumento di conoscenza che si aggiorna di continuo al variare dei dati (Spiegelhalter, 2019).\n\n30.3.2.1 Un Esperimento Mentale Illuminante\nPer illustrare la sua idea, Bayes propose un semplice esempio: immagina di lanciare alcune palline su un tavolo da biliardo. Dopo aver segnato con una linea il punto in cui si ferma una pallina bianca (e averla poi rimossa), si lanciano altre palline rosse e si conta quante cadono a destra e quante a sinistra di quella linea. Sulla base di queste osservazioni, come si pu√≤ ‚Äúindovinare‚Äù la posizione della linea? E con quale probabilit√† la prossima pallina rossa cadr√† a sinistra di essa?\nLa soluzione di Bayes combina i dati osservati (numero di palline cadute a sinistra o a destra) con le convinzioni iniziali dell‚Äôosservatore (il cosiddetto ‚Äúprior‚Äù), delineando un processo di apprendimento graduale che guida la revisione critica delle ipotesi.\n\n30.3.3 Il Ruolo di Richard Price\nDopo la morte di Bayes, fu un altro ecclesiastico, Richard Price (1723-1791), a dare impulso alla diffusione del saggio bayesiano. Price aveva un‚Äôottima reputazione negli ambienti intellettuali dell‚Äôepoca, grazie anche alle sue relazioni con figure di spicco come Benjamin Franklin, Thomas Jefferson e John Adams.\nPrice prese in carico il manoscritto di Bayes, lo sottopose al fisico John Canton e ne cur√≤ la pubblicazione postuma, operando modifiche significative. Rispetto alla versione originale di Bayes, concentrata quasi esclusivamente sugli aspetti teorici, Price aggiunse una parte dedicata alle applicazioni pratiche, rendendo il testo pi√π fruibile a un pubblico pi√π ampio. Per questo motivo, lo storico Stephen Stigler lo definisce ¬´il primo bayesiano della storia¬ª.\n\n30.3.4 Dal Silenzio alla Riscoperta\nPer oltre cinquant‚Äôanni, il lavoro di Bayes rimase in ombra, oscurato dall‚Äôopera pionieristica di Pierre-Simon Laplace. Gi√† nel 1774, Laplace pervenne indipendentemente a principi analoghi, e successivamente li sistematizz√≤ nella monumentale Th√©orie analytique des probabilit√©s (1812). Solo in tempi pi√π recenti, con l‚Äôavvento dei metodi di calcolo moderno e dell‚Äôinformatica, la statura del teorema di Bayes √® emersa in tutta la sua importanza.\nOggi, il teorema di Bayes √® considerato un cardine della statistica moderna: formalizza il modo in cui aggiorniamo le nostre credenze alla luce di nuovi dati. Questo schema √® cruciale in ogni disciplina scientifica e tecnologica che debba fare i conti con incertezza e dati incompleti. Dalla genomica all‚Äôeconometria, dalla fisica delle particelle alle scienze cognitive, il paradigma bayesiano risulta prezioso per gestire e interpretare informazioni in continuo aggiornamento.\n\n30.3.5 L‚ÄôEredit√† di Bayes nell‚ÄôEra Digitale\nNell‚Äôintelligenza artificiale, le idee bayesiane sono alla base di sistemi di apprendimento automatico e modelli probabilistici complessi. Strumenti come i moderni modelli linguistici (ad esempio ChatGPT e Claude) sfruttano strategie di inferenza bayesiana ‚Äì anche se in forme estremamente avanzate ‚Äì per generare risposte, fare previsioni e adattarsi costantemente agli input degli utenti.\nLa parabola storica di questo teorema, nato dalle speculazioni di un pastore presbiteriano del Settecento, mostra chiaramente il potenziale trasformativo delle idee matematiche. Come sottolinea Tom Chivers nel suo Everything Is Predictable: How Bayesian Statistics Explain Our World, la statistica bayesiana √® diventata una sorta di ‚Äúgrammatica universale‚Äù per interpretare la realt√†, permettendoci di affrontare con metodo situazioni complesse, modellare l‚Äôincertezza e formulare previsioni in contesti dove l‚Äôinformazione √® inevitabilmente limitata (Chivers, 2024).\nIn sintesi, la forza del teorema di Bayes non risiede soltanto nella sua eleganza formale, ma soprattutto nella sua portata epistemologica: esso traduce in termini matematici la nostra naturale tendenza ad apprendere da ci√≤ che osserviamo e a rivedere continuamente ci√≤ che crediamo. Per questo rimane, ancora oggi, un punto di riferimento fondamentale in qualunque disciplina che affronti il problema della conoscenza in condizioni di incertezza. ## La Regola di Bayes e l‚Äôinferenza probabilistica\nL‚Äôinferenza bayesiana utilizza un principio centrale della teoria delle probabilit√† noto come regola di Bayes. Questo principio consente di aggiornare in modo razionale le nostre credenze sulla base di nuovi dati osservati, integrandoli con conoscenze pregresse.\n\n30.3.6 Derivazione della Regola di Bayes\nConsideriamo due eventi casuali, \\(A\\) e \\(B\\). La probabilit√† congiunta \\(P(A, B)\\), ossia la probabilit√† che entrambi gli eventi accadano simultaneamente, pu√≤ essere espressa in due modi equivalenti:\n\nTramite la regola della catena, possiamo scrivere: \\[\nP(A, B) = P(A \\mid B)P(B).\n\\] Qui, \\(P(A \\mid B)\\) √® la probabilit√† condizionata che si verifichi l‚Äôevento \\(A\\) sapendo che l‚Äôevento \\(B\\) √® avvenuto, mentre \\(P(B)\\) √® la probabilit√† marginale di \\(B\\), indipendente da \\(A\\).\nUtilizzando la simmetria della probabilit√† congiunta, possiamo invertire gli eventi: \\[\nP(A, B) = P(B \\mid A)P(A).\n\\]\n\nDato che entrambe le espressioni rappresentano la stessa probabilit√† congiunta, possiamo eguagliarle:\n\\[\nP(A \\mid B)P(B) = P(B \\mid A)P(A).\n\\]\nRisolvendo per \\(P(B \\mid A)\\) otteniamo la regola di Bayes:\n\\[\nP(B \\mid A) = \\frac{P(A \\mid B) P(B)}{P(A)}.\n\\tag{30.1}\\]\n\n30.3.7 Interpretazione dei termini della regola di Bayes\nLa regola di Bayes permette di aggiornare la nostra credenza sulla probabilit√† di un‚Äôipotesi o evento (\\(B\\)), dopo aver osservato un dato o evidenza (\\(A\\)):\n\n\n\\(P(B)\\) (prior): √® la probabilit√† iniziale assegnata all‚Äôevento \\(B\\) prima di osservare il dato \\(A\\). Rappresenta la nostra conoscenza pregressa o il nostro grado iniziale di fiducia.\n\n\\(P(A \\mid B)\\) (verosimiglianza): √® la probabilit√† di osservare il dato \\(A\\) nell‚Äôipotesi che \\(B\\) sia vero. Indica quanto il dato sia compatibile con l‚Äôipotesi.\n\n\\(P(B \\mid A)\\) (posterior): √® la probabilit√† aggiornata, cio√® la nostra nuova credenza sull‚Äôevento \\(B\\) dopo aver osservato il dato \\(A\\).\n\n\\(P(A)\\) (evidenza): √® la probabilit√† marginale del dato osservato, calcolata sommando o integrando su tutte le possibili ipotesi alternative che potrebbero aver generato tale dato. Agisce da termine di normalizzazione per garantire che la somma delle probabilit√† a posteriori sia uguale a 1.\n\n30.3.8 Applicazioni della Regola di Bayes\nNella pratica, l‚Äôinferenza bayesiana si svolge tipicamente nel seguente modo:\n\nSi parte da uno spazio delle ipotesi \\(\\mathcal{H}\\), ovvero un insieme di tutte le possibili spiegazioni o modelli che potrebbero aver generato i dati osservati \\(D\\).\nA ciascuna ipotesi \\(H \\in \\mathcal{H}\\) viene assegnata una probabilit√† a priori \\(P(H)\\) che riflette la nostra fiducia iniziale.\nUna volta raccolti i dati \\(D\\), aggiorniamo le probabilit√† delle ipotesi usando la formula:\n\n\\[\nP(H \\mid D) = \\frac{P(D \\mid H) \\, P(H)}{P(D)},\n\\tag{30.2}\\]\ndove:\n\n\n\\(P(D \\mid H)\\) √® la verosimiglianza, cio√® la probabilit√† che l‚Äôipotesi \\(H\\) abbia generato i dati \\(D\\);\n\n\\(P(D)\\) √® la probabilit√† marginale (evidenza), calcolata considerando tutte le possibili ipotesi:\n\n\\[\nP(D) = \\sum_{H' \\in \\mathcal{H}} P(D \\mid H')P(H'),\n\\]\nnel caso discreto, oppure:\n\\[\nP(D) = \\int_{\\mathcal{H}} P(D \\mid H')P(H') \\, dH',\n\\]\nnel caso continuo.\n\n30.3.9 Il Processo Iterativo dell‚ÄôAggiornamento Bayesiano\nL‚Äôinferenza bayesiana √® intrinsecamente iterativa. Ogni volta che emergono nuovi dati, la distribuzione a posteriori \\(P(H \\mid D)\\) ottenuta diventa il nuovo prior per aggiornamenti successivi. Questo permette un affinamento continuo delle credenze, adattando la nostra comprensione del mondo in modo dinamico e coerente con le nuove evidenze.\n\n30.3.10 Considerazioni Pratiche\nSpesso, il calcolo diretto della probabilit√† marginale \\(P(D)\\) pu√≤ essere complesso, specialmente quando lo spazio delle ipotesi √® ampio o continuo. Per affrontare questa difficolt√†, si ricorre a metodi computazionali approssimati come il campionamento Monte Carlo o i metodi variazionali, che consentono di stimare efficacemente queste quantit√† in situazioni realistiche.\nIn sintesi, la regola di Bayes fornisce uno schema formale e razionale per integrare informazioni pregresse con nuove osservazioni. Questa capacit√† di aggiornare continuamente le nostre credenze rappresenta il cuore del ragionamento probabilistico e rende l‚Äôapproccio bayesiano uno strumento fondamentale in molte discipline scientifiche e applicazioni pratiche.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_bayes_theorem.html#un-esempio-intuitivo-la-moneta-bilanciata-o-truccata",
    "href": "chapters/probability/06_bayes_theorem.html#un-esempio-intuitivo-la-moneta-bilanciata-o-truccata",
    "title": "30¬† Il teorema di Bayes",
    "section": "\n30.4 Un Esempio Intuitivo: la Moneta Bilanciata o Truccata",
    "text": "30.4 Un Esempio Intuitivo: la Moneta Bilanciata o Truccata\nImmaginiamo di avere una moneta, che potrebbe essere:\n\n\nbilanciata (pari probabilit√† di Testa e Croce: 50% ciascuna);\n\ntruccata (sbilanciata, con probabilit√† di Testa del 80% e Croce del 20%).\n\nVogliamo capire quale delle due ipotesi (moneta bilanciata o moneta truccata) sia pi√π probabile dopo aver osservato un evento.\n\n30.4.1 Prior: le Credenze Iniziali\nPrima di lanciare la moneta, abbiamo una certa idea di quanto sia probabile ciascuna ipotesi:\n\nPotremmo essere abbastanza sicuri che la moneta sia bilanciata (ad esempio, perch√© la maggior parte delle monete lo √®). Diciamo che in questo caso:\n\n\\[\nP(\\text{Bilanciata}) = 0.85 \\quad\\text{e}\\quad P(\\text{Truccata}) = 0.15.\n\\]\nQueste probabilit√† rappresentano il prior, ovvero le nostre convinzioni iniziali prima di osservare qualunque risultato.\n\n30.4.2 Verosimiglianza: la Compatibilit√† con l‚ÄôEvidenza\nOra lanciamo la moneta una sola volta e osserviamo il risultato: esce Testa.\nCi chiediamo: ‚ÄúQuanto √® probabile osservare Testa se ciascuna delle due ipotesi fosse vera?‚Äù\n\nSe la moneta √® bilanciata, la probabilit√† di osservare Testa √® 0.5 (50%).\nSe la moneta √® truccata, la probabilit√† di osservare Testa √® 0.8 (80%).\n\nQueste due probabilit√† rappresentano la verosimiglianza:\n\\[\nP(\\text{Testa} \\mid \\text{Bilanciata}) = 0.5 \\quad\\text{e}\\quad P(\\text{Testa} \\mid \\text{Truccata}) = 0.8.\n\\]\n\n30.4.3 Evidenza: Probabilit√† Complessiva dell‚ÄôEvento Osservato\nVogliamo ora sapere quanto sia probabile osservare Testa in generale, considerando entrambe le ipotesi possibili. Per calcolarlo, usiamo la probabilit√† totale, che tiene conto di tutte le possibili ipotesi:\n\\[\nP(\\text{Testa}) = P(\\text{Testa} \\mid \\text{Bilanciata}) \\times P(\\text{Bilanciata}) + P(\\text{Testa} \\mid \\text{Truccata}) \\times P(\\text{Truccata}).\n\\]\nSostituiamo i valori numerici:\n\\[\nP(\\text{Testa}) = (0.5 \\times 0.85) + (0.8 \\times 0.15) = 0.425 + 0.12 = 0.545.\n\\]\nQuesta √® la probabilit√† marginale o evidenza del risultato osservato.\n\n30.4.4 Posterior: Aggiornamento delle Credenze dopo l‚ÄôEvidenza\nOra possiamo usare il Teorema di Bayes per aggiornare le nostre credenze iniziali alla luce dell‚Äôevento osservato (Testa):\n\\[\n\\begin{align}\nP(\\text{Bilanciata} \\mid \\text{Testa}) &= \\frac{P(\\text{Testa} \\mid \\text{Bilanciata}) \\times P(\\text{Bilanciata})}{P(\\text{Testa})}\\notag\\\\\n&= \\frac{0.5 \\times 0.85}{0.545} \\notag\\\\\n&= 0.7798 \\quad (77.98\\%).\n\\end{align} \\notag\n\\]\n\\[\n\\begin{align}\nP(\\text{Truccata} \\mid \\text{Testa}) &= \\frac{P(\\text{Testa} \\mid \\text{Truccata}) \\times P(\\text{Truccata})}{P(\\text{Testa})} \\notag\\\\\n&= \\frac{0.8 \\times 0.15}{0.545} \\notag\\\\\n&= 0.2202 \\quad (22.02\\%). \\notag\n\\end{align}\n\\]\n\n30.4.5 Interpretazione Intuitiva\nPrima del lancio, eravamo abbastanza sicuri (85%) che la moneta fosse bilanciata. Dopo aver osservato un singolo lancio che mostra Testa, questa certezza diminuisce (passa a circa 77.98%), mentre la probabilit√† che la moneta sia truccata aumenta (passa da 15% a circa 22.02%).\nSe continuassimo a osservare altri lanci della moneta, potremmo usare ripetutamente la regola di Bayes per aggiornare ulteriormente queste probabilit√†, rafforzando o indebolendo la nostra convinzione iniziale in funzione dei risultati osservati.\nQuesto esempio mostra come il prior, la verosimiglianza e l‚Äôevidenza si combinino nel ragionamento bayesiano per produrre un aggiornamento razionale e coerente delle credenze.\n\n30.4.6 Secondo Aggiornamento Bayesiano\nSupponiamo ora di lanciare la moneta una seconda volta, osservando ancora Testa. Usiamo le nuove probabilit√† ottenute (posteriori) come prior aggiornati:\n\\[\nP(\\text{Bilanciata}) = 0.7798 \\quad\\text{e}\\quad P(\\text{Truccata}) = 0.2202.\n\\]\nCalcoliamo nuovamente l‚Äôevidenza:\n\\[\nP(\\text{Testa}) = (0.5 \\times 0.7798) + (0.8 \\times 0.2202) = 0.3899 + 0.1762 = 0.5661.\n\\]\nAggiorniamo quindi le credenze con il teorema di Bayes:\n\\[\nP(\\text{Bilanciata} \\mid \\text{Testa}) = \\frac{0.5 \\times 0.7798}{0.5661} = 0.6887 \\quad (68.87\\%).\n\\]\n\\[\nP(\\text{Truccata} \\mid \\text{Testa}) = \\frac{0.8 \\times 0.2202}{0.5661} = 0.3113 \\quad (31.13\\%).\n\\]\n\n30.4.7 Interpretazione del Secondo Aggiornamento\nDopo il secondo lancio che mostra ancora Testa, la probabilit√† che la moneta sia bilanciata scende ulteriormente da 0.7798 a 0.6887, mentre la probabilit√† che la moneta sia truccata sale a 0.3113. Questo esempio dimostra chiaramente come l‚Äôaggiornamento bayesiano consenta di modificare progressivamente le nostre credenze, adattandole coerentemente a ogni nuova evidenza osservata.\n\n30.4.8 Applicazioni in Psicologia\nNegli ultimi anni, i modelli bayesiani hanno acquisito un ruolo centrale nello studio della cognizione umana, fornendo una struttura formale per comprendere come il cervello costruisca rappresentazioni del mondo e prenda decisioni sulla base di dati incerti. Come discusso da Griffiths et al. (2024), questi modelli sono stati applicati a una vasta gamma di processi cognitivi, tra cui:\n\n\nApprendimento e generalizzazione: i modelli bayesiani descrivono come gli individui apprendano nuove categorie e concetti sulla base di dati limitati e rumorosi (Tenenbaum, Griffiths, & Kemp, 2006).\n\nPercezione e interpretazione sensoriale: la percezione visiva e il riconoscimento di oggetti possono essere spiegati come un‚Äôinferenza bayesiana sulla base di segnali sensoriali ambigui (Domini & Caudek, 2003; Yuille & Kersten, 2006).\n\nControllo motorio: il sistema motorio umano sembra ottimizzare i movimenti attraverso una combinazione di modelli interni e aggiornamenti bayesiani (Kording & Wolpert, 2006).\n\nMemoria e recupero delle informazioni: i processi mnemonici, come il richiamo della memoria semantica, possono essere modellati come inferenze bayesiane basate su conoscenze pregresse (Steyvers, Griffiths, & Dennis, 2006).\n\nAcquisizione del linguaggio: l‚Äôapprendimento del linguaggio nei bambini pu√≤ essere descritto attraverso processi probabilistici che permettono di inferire le strutture grammaticali sulla base di dati linguistici limitati (Chater & Manning, 2006; Xu & Tenenbaum, in press).\n\nApprendimento causale: la capacit√† di inferire relazioni causali dagli eventi osservati √® coerente con un modello bayesiano, in cui la mente valuta la probabilit√† di una relazione causale sulla base dell‚Äôevidenza disponibile (Griffiths & Tenenbaum, 2005, 2007).\n\nRagionamento e decisione: il ragionamento simbolico e il processo decisionale possono essere formalizzati come un aggiornamento bayesiano delle credenze sulla base di nuove informazioni (Oaksford & Chater, 2001).\n\nCognizione sociale: le inferenze sulle intenzioni e credenze altrui possono essere modellate attraverso processi bayesiani, permettendo di spiegare come le persone comprendano il comportamento altrui (Baker, Tenenbaum, & Saxe, 2007).\n\n30.4.9 L‚ÄôInferenza Bayesiana nella Cognizione Umana\nUn tema centrale che emerge da questi programmi di ricerca √® la seguente domanda: come fa la mente umana ad andare oltre i dati dell‚Äôesperienza? In altre parole, come riesce il cervello a costruire modelli complessi del mondo a partire da informazioni limitate e spesso ambigue?\nL‚Äôapproccio bayesiano propone che il cervello utilizzi un processo di inferenza probabilistica per aggiornare continuamente le proprie credenze, combinando informazioni pregresse con nuove osservazioni per affinare le proprie rappresentazioni mentali. Questo meccanismo consente di spiegare molte delle capacit√† cognitive umane, dall‚Äôapprendimento rapido di nuove categorie alla capacit√† di adattarsi a un ambiente mutevole, fino alla formulazione di inferenze sociali e alla presa di decisioni in condizioni di incertezza.\nL‚Äôadozione dei modelli bayesiani nella psicologia cognitiva ha portato a una nuova comprensione della mente come sistema predittivo, in grado di formulare ipotesi probabilistiche sugli eventi futuri e di correggerle dinamicamente sulla base dell‚Äôesperienza. Questo approccio ha profonde implicazioni per lo studio del comportamento umano e per lo sviluppo di nuove tecniche di modellizzazione nei campi della psicologia, delle neuroscienze e dell‚Äôintelligenza artificiale.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_bayes_theorem.html#test-medici",
    "href": "chapters/probability/06_bayes_theorem.html#test-medici",
    "title": "30¬† Il teorema di Bayes",
    "section": "\n30.5 Test Medici",
    "text": "30.5 Test Medici\nUno degli esempi pi√π comuni per comprendere il teorema di Bayes riguarda i test diagnostici.\n\nEsempio 30.1 Consideriamo un test di mammografia utilizzato per diagnosticare il cancro al seno che abbiamo gi√† discusso nel Capitolo 29. Definiamo le seguenti ipotesi:\n\n\n\\(M^+\\): la persona ha il cancro al seno;\n\n\\(M^-\\): la persona non ha il cancro al seno.\n\nL‚Äôevidenza √® il risultato positivo del test, indicato con \\(T^+\\). Il nostro obiettivo √® calcolare la probabilit√† che una persona abbia il cancro al seno, dato un risultato positivo al test, ovvero \\(P(M^+ \\mid T^+)\\).\nDefinizione dei termini nella regola di Bayes.\nIl teorema di Bayes afferma che:\n\\[\nP(M^+ \\mid T^+) = \\frac{P(T^+ \\mid M^+) P(M^+)}{P(T^+)} ,\n\\]\ndove:\n\n\n\\(P(T^+ \\mid M^+)\\) √® la sensibilit√† del test, cio√® la probabilit√† che il test risulti positivo se la persona ha effettivamente il cancro. Nel nostro caso, \\(P(T^+ \\mid M^+) = 0.90\\).\n\n\\(P(M^+)\\) √® la probabilit√† a priori di avere il cancro al seno, ovvero la prevalenza della malattia nella popolazione. Supponiamo che sia \\(P(M^+) = 0.01\\) (1%).\n\n\\(P(T^+ \\mid M^-)\\) √® la probabilit√† di un falso positivo, cio√® la probabilit√† che il test risulti positivo anche in assenza di malattia. Questa √® complementare alla specificit√† del test:\n\n\\[\n  P(T^+ \\mid M^-) = 1 - \\text{Specificit√†} = 1 - 0.90 = 0.10.\n\\]\n\n\n\\(P(M^-)\\) √® la probabilit√† a priori che una persona non abbia il cancro, ovvero:\n\n\\[\n  P(M^-) = 1 - P(M^+) = 1 - 0.01 = 0.99.\n\\]\n\n\n\\(P(T^+)\\) √® la probabilit√† marginale che il test risulti positivo, calcolata considerando entrambe le possibilit√† (cio√® che la persona abbia o non abbia il cancro):\n\n\\[\n  P(T^+) = P(T^+ \\mid M^+) P(M^+) + P(T^+ \\mid M^-) P(M^-).\n\\]\nSostituendo i valori numerici:\n\\[\n  P(T^+) = (0.90 \\cdot 0.01) + (0.10 \\cdot 0.99) = 0.009 + 0.099 = 0.108.\n\\]\nApplicazione della Regola di Bayes.\nOra possiamo calcolare la probabilit√† a posteriori \\(P(M^+ \\mid T^+)\\):\n\\[\nP(M^+ \\mid T^+) = \\frac{0.90 \\cdot 0.01}{0.108} = \\frac{0.009}{0.108} = 0.0833.\n\\]\nInterpretazione del Risultato.\nQuesto risultato indica che, nonostante il test abbia una sensibilit√† e una specificit√† del 90%, la probabilit√† che una persona con un test positivo abbia effettivamente il cancro √® solo dell‚Äô8.3%. Questo effetto √® dovuto alla bassa prevalenza della malattia: anche se il test √® relativamente accurato, il numero di falsi positivi √® ancora alto rispetto ai veri positivi. Tale risultato conferma quanto precedentemente ottenuto nel Capitolo 29, attraverso un metodo di calcolo alternativo.\nQuesta formulazione mostra come la regola di Bayes permetta di aggiornare la probabilit√† di avere la malattia dopo aver osservato il risultato del test, combinando la sensibilit√†, la specificit√† e la prevalenza della malattia nella popolazione.\n\n\n30.5.1 Affidabilit√† di un Test HIV e Aggiornamento Bayesiano\nVogliamo valutare l‚Äôaffidabilit√† di un test per l‚ÄôHIV e capire come la nostra stima di infezione cambia dopo due test consecutivi positivi. Utilizzeremo la regola di Bayes per aggiornare la probabilit√† di avere l‚ÄôHIV man mano che otteniamo nuovi risultati.\n\nEsempio 30.2 Immaginiamo che una persona esegua due volte un test per l‚ÄôHIV.\nNotazione e dati iniziali.\nIndichiamo con:\n\n\n\\(M^+\\): la persona ha l‚ÄôHIV;\n\n\\(M^-\\): la persona non ha l‚ÄôHIV;\n\n\\(T^+\\): il test √® positivo;\n\n\\(T^-\\): il test √® negativo.\n\nAbbiamo inoltre i seguenti dati:\n\nPrevalenza (probabilit√† a priori di avere l‚ÄôHIV):\\[\nP(M^+) = 0.003 \\quad (0.3\\%).\n\\]\nSensibilit√† del test (probabilit√† che il test sia positivo se la persona √® malata):\\[\nP(T^+ \\mid M^+) = 0.95.\n\\]\nSpecificit√† del test (probabilit√† che il test sia negativo se la persona √® sana):\\[\nP(T^- \\mid M^-) = 0.9928 \\quad \\Longrightarrow \\quad P(T^+ \\mid M^-) = 0.0072.\n\\]\n\nPasso 1: dopo il primo test positivo.\nUsiamo la regola di Bayes per aggiornare la probabilit√† di essere malati, dopo un primo risultato positivo:\n\\[\nP(M^+ \\mid T^+) = \\frac{P(T^+ \\mid M^+)P(M^+)}{P(T^+)}.\n\\]\nCalcoliamo la probabilit√† marginale di un test positivo, considerando entrambe le ipotesi:\n\\[\nP(T^+) = P(T^+ \\mid M^+)P(M^+) + P(T^+ \\mid M^-)P(M^-).\n\\]\nSostituendo i valori noti, otteniamo:\n\\[\nP(T^+) = (0.95 \\times 0.003) + (0.0072 \\times 0.997) = 0.00285 + 0.00718 = 0.01003.\n\\]\nLa probabilit√† aggiornata (posterior) diventa quindi:\n\\[\nP(M^+ \\mid T^+) = \\frac{0.00285}{0.01003} \\approx 0.2844 \\quad (28.44\\%).\n\\]\nDopo un primo test positivo, la probabilit√† che la persona sia effettivamente HIV-positiva sale da un valore iniziale molto basso (0.3%) a 28.44%, aumentando notevolmente ma senza ancora garantire la certezza.\nPasso 2: aggiornamento dopo un secondo test positivo.\nAdesso immaginiamo di ripetere il test e ottenere nuovamente un risultato positivo. La nuova probabilit√† si calcola applicando ancora la regola di Bayes, utilizzando come prior il risultato appena trovato:\n\\[\nP(M^+ \\mid T_1^+, T_2^+) = \\frac{P(T_2^+ \\mid M^+, T_1^+)P(M^+ \\mid T_1^+)}{P(T_2^+ \\mid T_1^+)}.\n\\]\nAssumendo che i risultati dei test siano indipendenti dato lo stato di malattia o meno, possiamo semplificare:\n\n\\(P(T_2^+ \\mid M^+, T_1^+) = P(T^+ \\mid M^+) = 0.95\\)\n\\(P(T_2^+ \\mid M^-, T_1^+) = P(T^+ \\mid M^-) = 0.0072\\)\n\nLa probabilit√† di ottenere un secondo test positivo diventa quindi:\n\\[\nP(T_2^+ \\mid T_1^+) = P(T^+ \\mid M^+)P(M^+ \\mid T_1^+) + P(T^+ \\mid M^-)P(M^- \\mid T_1^+).\n\\]\nSostituendo i valori numerici calcolati in precedenza:\n\\[\nP(T_2^+ \\mid T_1^+) = (0.95 \\times 0.2844) + (0.0072 \\times 0.7156) = 0.2702 + 0.00515 = 0.27535.\n\\]\nOra calcoliamo la nuova probabilit√† a posteriori dopo due test positivi:\n\\[\nP(M^+ \\mid T_1^+, T_2^+) = \\frac{0.95 \\times 0.2844}{0.27535} \\approx 0.981 \\quad (98.1\\%).\n\\]\nInterpretazione finale.\n\nDopo il primo test positivo, la probabilit√† passa dallo 0.3% iniziale a circa il 28.44%, aumentando notevolmente ma restando incerta.\nDopo il secondo test positivo, la probabilit√† sale drasticamente al 98.1%, rendendo quasi certa la diagnosi.\n\nQuesto esempio dimostra chiaramente il valore dell‚Äôaggiornamento bayesiano: un singolo risultato positivo incrementa la probabilit√†, ma in presenza di una bassa prevalenza non basta per una diagnosi certa. Ripetere il test e ottenere conferme successive permette invece di raggiungere una certezza diagnostica molto elevata.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_bayes_theorem.html#la-fallacia-del-procuratore-e-il-teorema-di-bayes",
    "href": "chapters/probability/06_bayes_theorem.html#la-fallacia-del-procuratore-e-il-teorema-di-bayes",
    "title": "30¬† Il teorema di Bayes",
    "section": "\n30.6 La Fallacia del Procuratore e il Teorema di Bayes",
    "text": "30.6 La Fallacia del Procuratore e il Teorema di Bayes\nIl teorema di Bayes non trova applicazione solo in campo medico, ma √® essenziale anche nei procedimenti giudiziari. Infatti, fraintendimenti nell‚Äôinterpretazione di probabilit√† e statistiche possono portare a gravi errori di giudizio. Uno degli errori pi√π comuni in questo contesto √® la fallacia del procuratore.\n\n30.6.1 Che cos‚Äô√® la Fallacia del Procuratore?\nLa fallacia del procuratore consiste nel confondere la probabilit√† di osservare una certa evidenza se una persona √® innocente, \\(P(T^+ \\mid I)\\), con la probabilit√† che una persona sia innocente dopo aver osservato quella evidenza, \\(P(I \\mid T^+)\\).\n\nIn termini giudiziari, questo equivale a dire: ‚ÄúPoich√© √® estremamente improbabile ottenere un certo riscontro (ad es. un test positivo) se la persona √® innocente, allora √® estremamente improbabile che la persona sia innocente se si √® ottenuto un esito positivo‚Äù.\nIn realt√†, per stabilire se la persona √® innocente o colpevole dopo aver visto il risultato, occorre considerare sia la bassa frequenza delle persone effettivamente colpevoli nella popolazione (prevalenza) sia la possibilit√† di falsi positivi. Il teorema di Bayes fornisce lo strumento formale per integrare questi elementi.\n\n30.6.2 Esempio di Test del DNA\nSupponiamo di utilizzare un test del DNA per identificare un sospetto tra 65 milioni di persone. Il test ha:\n\n\nSensibilit√† (\\(P(T^+ \\mid C)\\)) = 99%\\(\\rightarrow\\) Se la persona √® effettivamente colpevole, il test risulta positivo il 99% delle volte.\n\nSpecificit√† (\\(P(T^- \\mid I)\\)) = 99.99997%\\(\\rightarrow\\) Se la persona √® innocente, il test risulta negativo il 99.99997% delle volte.\nDa cui segue che il tasso di falso positivo √® \\(1 - 0.9999997 = 0.0000003 = 0.00003\\%\\).\n\nPrevalenza (\\(P(C)\\)) = \\(1/65{,}000{,}000 \\approx 1.54 \\times 10^{-8}\\)\\(\\rightarrow\\) Un individuo scelto a caso ha una probabilit√† di circa \\(1.54 \\times 10^{-8}\\) (cio√® 1 su 65 milioni) di essere il vero colpevole.\n\nUn campione di DNA coincide con quello di una persona trovata nel database e il test d√† risultato positivo. Qual √® la probabilit√† che costui sia davvero colpevole? Formalmente, vogliamo \\(P(C \\mid T^+)\\).\nPasso 1: Calcolare \\(P(T^+)\\), la probabilit√† di un test positivo.\nLa probabilit√† complessiva di un esito positivo deriva da due scenari alternativi:\n\n\nLa persona √® colpevole e il test √® positivo:\\(P(T^+ \\mid C) \\times P(C)\\).\n\nLa persona √® innocente e il test √® positivo per errore (falso positivo):\\(P(T^+ \\mid I) \\times P(I)\\).\n\nPerci√≤, usando la regola della probabilit√† totale:\n\\[\nP(T^+)\n= P(T^+ \\mid C) \\, P(C) \\;+\\; P(T^+ \\mid I) \\, P(I).\n\\]\nAssegniamo i valori numerici:\n\n\n\\(P(T^+ \\mid C) = 0.99\\) (sensibilit√†).\n\n\\(P(C) = 1.54 \\times 10^{-8}\\).\n\n\\(P(T^+ \\mid I) = 1 - P(T^- \\mid I) = 1 - 0.9999997 = 0.0000003\\).\n\n\\(P(I) = 1 - P(C) \\approx 0.99999998\\).\n\nEseguiamo il calcolo:\n\\[\n\\begin{aligned}\nP(T^+)\n&= (0.99 \\times 1.54 \\times 10^{-8}) + (0.0000003 \\times 0.99999998)\\\\\n&= 1.5231 \\times 10^{-8} + 2.9999994 \\times 10^{-7}\\\\\n&= 3.1523 \\times 10^{-7}.\n\\end{aligned}\n\\]\nPasso 2: Applicare la regola di Bayes per \\(P(C \\mid T^+)\\).\nOra possiamo calcolare la probabilit√† di essere colpevoli dato che il test √® positivo:\n\\[\nP(C \\mid T^+)\n= \\frac{P(T^+ \\mid C)\\,P(C)}{P(T^+)}.\n\\]\nInseriamo i valori:\n\\[\n\\begin{aligned}\nP(C \\mid T^+)\n&= \\frac{(0.99 \\times 1.54 \\times 10^{-8})}{3.1523 \\times 10^{-7}}\\\\\n&= \\frac{1.5231 \\times 10^{-8}}{3.1523 \\times 10^{-7}}\\\\\n&\\approx 0.0483 \\quad (\\text{cio√® } 4.83\\%).\n\\end{aligned}\n\\]\nInterpretazione: perch√© √® ‚Äúsolo‚Äù il 4.83%?\nSebbene sensibilit√† e specificit√† del test siano entrambe molto alte, la prevalenza estremamente bassa del colpevole (1 su 65 milioni) riduce notevolmente la probabilit√† a posteriori \\(P(C \\mid T^+)\\). In una popolazione di 65 milioni di individui, anche un esiguo tasso di falsi positivi (\\(0.0000003\\)) genera un numero assoluto di risultati positivi fra gli innocenti molto pi√π grande del numero di colpevoli reali.\nIn pratica, pur avendo un test positivo, la probabilit√† che la persona sia davvero colpevole resta modesta (circa 4.83%), perch√© i ‚Äúfalsi allarmi‚Äù nella massa di individui innocenti superano di gran lunga i (pochi) veri positivi.\n\n30.6.3 Evitare la Fallacia del Procuratore\nLa fallacia del procuratore consiste nel confondere:\n\n\n\\(P(T^+ \\mid I)\\): la probabilit√† che un innocente risulti positivo (falso positivo),\n\n\\(P(I \\mid T^+)\\): la probabilit√† di essere innocenti dopo un test positivo.\n\nQuesta confusione porta a sovrastimare la colpevolezza di un individuo basandosi su una singola evidenza statistica. Applicando il teorema di Bayes, invece, si comprende che un test positivo non implica automaticamente colpevolezza, soprattutto quando la malattia (o il reato, in questo caso) √® molto raro. Nei processi giudiziari, ci√≤ significa che un dato probabilistico deve sempre essere contestualizzato alla popolazione di riferimento: la corretta interpretazione delle prove √® fondamentale per evitare errori giudiziari.\n\n30.6.3.1 Conclusione Epistemologica\nL‚Äôimpiego di test probabilistici in ambito giudiziario richiede un‚Äôapplicazione rigorosa del teorema di Bayes per evitare distorsioni interpretative. Solo un corretto aggiornamento delle credenze, integrando:\n\n\nla probabilit√† pre-test (\\(P(C)\\), prevalenza del colpevole nella popolazione investigata),\n\n\nla potenza diagnostica del test (sensibilit√† e specificit√†),\n\n\nil tasso di errore strumentale (falsi positivi e falsi negativi),\n\nconsente di ridurre il rischio di errori giudiziari sistematici. In assenza di questa integrazione, anche test estremamente precisi possono condurre a ingiuste condanne, trasformando strumenti scientifici affidabili in fonti di distorsione probatoria.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_bayes_theorem.html#probabilit√†-inversa-dal-problema-classico-allinferenza-bayesiana",
    "href": "chapters/probability/06_bayes_theorem.html#probabilit√†-inversa-dal-problema-classico-allinferenza-bayesiana",
    "title": "30¬† Il teorema di Bayes",
    "section": "\n30.7 Probabilit√† Inversa: Dal Problema Classico all‚ÄôInferenza Bayesiana",
    "text": "30.7 Probabilit√† Inversa: Dal Problema Classico all‚ÄôInferenza Bayesiana\nGli esempi precedenti mostrano due tipi di domande probabilistiche fondamentali:\n\n\nProbabilit√† diretta\n\n‚ÄúQual √® la probabilit√† di osservare un certo risultato, supponendo che l‚Äôipotesi sia vera?‚Äù\n\n\n\nProbabilit√† inversa\n\n‚ÄúQual √® la probabilit√† che un‚Äôipotesi sia vera, dati i risultati osservati?‚Äù\n\n\n\nQuesta distinzione √® cruciale per comprendere il teorema di Bayes e le differenze tra l‚Äôapproccio frequentista e quello bayesiano alla probabilit√†.\n\n30.7.1 Esempi di Probabilit√† Diretta e Inversa\nPrendiamo come esempio il lancio di una moneta:\n\nProbabilit√† diretta:\nSe riteniamo che la moneta sia equa (cio√® \\(P(\\text{Testa}) = 0{.}5\\)), qual √® la probabilit√† di osservare zero teste in cinque lanci? In questo caso, stiamo calcolando \\[\nP(D \\mid H) = (0.5)^5 = 0.03125,\n\\] dove \\(D\\) rappresenta il dato (‚Äúzero teste in cinque lanci‚Äù) e \\(H\\) l‚Äôipotesi (‚Äúla moneta √® equa‚Äù).\nProbabilit√† inversa:\nOra poniamo la domanda opposta. Abbiamo lanciato una moneta cinque volte e osservato zero teste. Quanto √® probabile che la moneta sia davvero equa?\nQui vogliamo conoscere \\(\\displaystyle P(H \\mid D)\\) (l‚Äôipotesi ‚Äúla moneta √® equa‚Äù dopo aver visto il risultato) anzich√© \\(P(D \\mid H)\\). Per rispondere correttamente, ci occorre il teorema di Bayes, che combina la probabilit√† dei dati (\\(P(D \\mid H)\\)) con una stima iniziale (il prior) su quanto riteniamo probabile l‚Äôipotesi prima dell‚Äôosservazione.\n\n30.7.2 Dalla Probabilit√† Diretta alla Probabilit√† Inversa: Il Contributo di Bayes\nPer lungo tempo, la teoria della probabilit√† si √® occupata quasi esclusivamente di probabilit√† diretta: ‚Äúse l‚Äôipotesi √® vera, qual √® la probabilit√† di osservare un certo esito?‚Äù.\nNel XVIII secolo, Thomas Bayes capovolse la prospettiva, concentrandosi su come determinare la probabilit√† dell‚Äôipotesi a partire dalle evidenze disponibili, introdusse cio√® l‚Äôidea di probabilit√† inversa. Questa svolta ha aperto la strada a ci√≤ che oggi chiamiamo inferenza bayesiana, permettendo di aggiornare in modo sistematico e rigoroso la credibilit√† di un‚Äôipotesi dopo aver osservato nuovi dati.\n\n30.7.3 L‚ÄôImpatto della Probabilit√† Inversa\nLa possibilit√† di stimare \\(\\displaystyle P(H \\mid D)\\), cio√® la probabilit√† di un‚Äôipotesi data l‚Äôevidenza osservata, si √® rivelata fondamentale in molti ambiti:\n\n\nScienza e sperimentazione: quanto √® probabile che un‚Äôipotesi sia vera dopo aver raccolto i dati di un esperimento?\n\n\nMedicina: quanto √® probabile che un paziente abbia una certa malattia, se il test diagnostico √® positivo?\n\n\nGiustizia: quanto √® probabile che una persona sia colpevole, se il DNA trovato sulla scena del crimine combacia col suo?\n\nIn tutti questi casi non basta calcolare la probabilit√† dei dati ‚Äúdato un‚Äôipotesi‚Äù \\(\\bigl(P(D \\mid H)\\bigr)\\); occorre invece aggiornare la stima della probabilit√† dell‚Äôipotesi alla luce dei dati \\(\\bigl(P(H \\mid D)\\bigr)\\).\nIn sintesi, l‚Äôinferenza bayesiana risponde appunto a questa seconda domanda, passando dalla probabilit√† diretta alla probabilit√† inversa in modo rigoroso. Grazie al teorema di Bayes, possiamo combinare in modo coerente le nostre conoscenze pregresse (il cosiddetto prior) con le evidenze raccolte, ottenendo una probabilit√† a posteriori che rappresenta la nostra nuova convinzione. Senza questa prospettiva, gran parte dei problemi scientifici e delle decisioni pratiche resterebbe priva di un metodo per collegare razionalmente le evidenze empiriche alle ipotesi da verificare.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_bayes_theorem.html#riflessioni-conclusive",
    "href": "chapters/probability/06_bayes_theorem.html#riflessioni-conclusive",
    "title": "30¬† Il teorema di Bayes",
    "section": "\n30.8 Riflessioni Conclusive",
    "text": "30.8 Riflessioni Conclusive\nIn questo capitolo abbiamo esplorato vari esempi, principalmente nel campo medico e forense, per illustrare come il teorema di Bayes permetta di combinare le informazioni derivate dalle osservazioni con le conoscenze precedenti (priori), aggiornando cos√¨ il nostro grado di convinzione rispetto a un‚Äôipotesi. Il teorema di Bayes fornisce un meccanismo razionale, noto come ‚Äúaggiornamento bayesiano‚Äù, che ci consente di ricalibrare le nostre convinzioni iniziali alla luce di nuove evidenze.\nUna lezione fondamentale che il teorema di Bayes ci insegna, sia nella ricerca scientifica che nella vita quotidiana, √® che spesso non ci interessa tanto conoscere la probabilit√† che qualcosa accada assumendo vera un‚Äôipotesi, quanto piuttosto la probabilit√† che un‚Äôipotesi sia vera, dato che abbiamo osservato una certa evidenza. In altre parole, la forza del teorema di Bayes sta nella sua capacit√† di affrontare direttamente il problema inverso, cio√® come dedurre la verit√† di un‚Äôipotesi a partire dalle osservazioni.\nIl framework bayesiano per l‚Äôinferenza probabilistica offre un approccio generale per comprendere come i problemi di induzione possano essere risolti in linea di principio e, forse, anche come possano essere affrontati dalla mente umana.\nIn questo capitolo ci siamo concentrati sull‚Äôapplicazione del teorema di Bayes utilizzando probabilit√† puntuali. Tuttavia, il teorema esprime pienamente il suo potenziale quando sia l‚Äôevidenza che i gradi di certezza a priori delle ipotesi sono rappresentati attraverso distribuzioni di probabilit√† continue. Questo sar√† l‚Äôargomento centrale nella prossima sezione della dispensa, dove approfondiremo il flusso di lavoro bayesiano e l‚Äôuso di distribuzioni continue nell‚Äôaggiornamento bayesiano.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_bayes_theorem.html#esercizi",
    "href": "chapters/probability/06_bayes_theorem.html#esercizi",
    "title": "30¬† Il teorema di Bayes",
    "section": "\n30.9 Esercizi",
    "text": "30.9 Esercizi\n√à facile trovare online esercizi sull‚Äôapplicazione del teorema di Bayes. Ad esempio, consiglio gli esercizi da 1 a 6 disponibili sulla seguente pagina web.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_bayes_theorem.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/06_bayes_theorem.html#informazioni-sullambiente-di-sviluppo",
    "title": "30¬† Il teorema di Bayes",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.5.3     \n#&gt;  [9] scales_1.3.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.9.1   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         rlang_1.1.5       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       tools_4.4.2       parallel_4.4.2    tzdb_0.5.0       \n#&gt; [21] colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5       R6_2.6.1         \n#&gt; [25] lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.1    \n#&gt; [29] gtable_0.3.6      glue_1.8.0        xfun_0.51         tidyselect_1.2.1 \n#&gt; [33] rstudioapi_0.17.1 farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-167     \n#&gt; [37] rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_bayes_theorem.html#bibliografia",
    "href": "chapters/probability/06_bayes_theorem.html#bibliografia",
    "title": "30¬† Il teorema di Bayes",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBaker, C., Saxe, R., & Tenenbaum, J. (2011). Bayesian theory of mind: Modeling joint belief-desire attribution. Proceedings of the annual meeting of the cognitive science society, 33.\n\n\nBellhouse, D. R. (2004). The Reverend Thomas Bayes, FRS: a biography to celebrate the tercentenary of his birth.\n\n\nCaudek, C., & Bruno, N. (2024). Fenomeni stereocinetici, teorie della percezione e sociologia della scienza. Giornale italiano di psicologia, 51(3), 451‚Äì466.\n\n\nChivers, T. (2024). Everything is Predictable: How Bayesian Statistics Explain Our World. Simon; Schuster.\n\n\nDomini, F., & Caudek, C. (2003). 3-D structure perceived from dynamic information: A new theory. Trends in Cognitive Sciences, 7(10), 444‚Äì449.\n\n\nGriffiths, T. L., Chater, N., & Tenenbaum, J. B. (2024). Bayesian models of cognition: reverse engineering the mind. MIT Press.\n\n\nJesseph, D. M. (1993). Berkeley‚Äôs philosophy of mathematics. University of Chicago Press.\n\n\nMa, W. J., Kording, K. P., & Goldreich, D. (2023). Bayesian models of perception and action: An introduction. MIT press.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:\n\n\nSpiegelhalter, D. (2019). The art of statistics: Learning from data. Penguin UK.\n\n\nStigler, S. M. (1990). The history of statistics: The measurement of uncertainty before 1900. Harvard University Press.\n\n\nYuille, A., & Kersten, D. (2006). Vision as Bayesian inference: analysis by synthesis? Trends in cognitive sciences, 10(7), 301‚Äì308.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_random_var.html",
    "href": "chapters/probability/07_random_var.html",
    "title": "31¬† Variabili casuali",
    "section": "",
    "text": "31.1 Introduzione\nFino ad ora abbiamo studiato le probabilit√† associate a eventi, come la possibilit√† di vincere il gioco di Monty Hall o di avere una rara condizione medica in seguito a un test positivo. Tuttavia, in molte situazioni pratiche vogliamo conoscere aspetti pi√π dettagliati. Ad esempio, potremmo chiederci:\nPer rispondere a tali domande √® necessario lavorare con le variabili casuali. In questo capitolo introdurremo il concetto di variabile casuale e ne analizzeremo le propriet√† fondamentali.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_random_var.html#introduzione",
    "href": "chapters/probability/07_random_var.html#introduzione",
    "title": "31¬† Variabili casuali",
    "section": "",
    "text": "quanti tentativi occorrono affinch√©, in un gioco simile a Monty Hall, un concorrente vinca?\nquanto durer√† un determinato evento o condizione?\nqual √® la perdita attesa giocando d‚Äôazzardo con un dado sbilanciato per molte ore?",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_random_var.html#definizione-di-variabile-casuale",
    "href": "chapters/probability/07_random_var.html#definizione-di-variabile-casuale",
    "title": "31¬† Variabili casuali",
    "section": "\n31.2 Definizione di Variabile Casuale",
    "text": "31.2 Definizione di Variabile Casuale\nUna variabile casuale √® una funzione che associa ogni elemento di uno spazio campionario a un valore numerico. Questo strumento permette di trasformare esiti qualitativi (ad esempio, il risultato di un lancio di carte, come cuori, quadri, fiori, picche) in valori numerici, facilitando cos√¨ l‚Äôanalisi matematica.\n\nDefinizione 31.1 Sia \\(S\\) lo spazio campionario di un esperimento aleatorio. Una variabile casuale \\(X\\) √® una funzione\\[\nX: S \\longrightarrow \\mathbb{R},\n\\] che associa ad ogni esito \\(s \\in S\\) un numero reale \\(X(s)\\).\n\n\nEsempio 31.1 Lanciamo due dadi equilibrati e annotiamo la somma dei valori delle loro facce. Ogni lancio genera una coppia di valori \\((i,j)\\), dove \\(i\\) √® il risultato del primo dado e \\(j\\) il risultato del secondo dado. Lo spazio campionario completo dei possibili esiti √®:\n\\[\n\\Omega = \\{(1,1), (1,2), \\dots, (6,5), (6,6)\\}.\n\\]\nDefiniamo una variabile casuale \\(X\\) che associa ciascun esito \\((i,j)\\) alla somma dei valori ottenuti dai due dadi, cio√®:\n\\[\nX(i,j) = i + j.\n\\]\nAd esempio, se il primo dado mostra 4 e il secondo dado mostra 4, allora l‚Äôesito √® \\((4,4)\\) e la variabile casuale \\(X\\) assume il valore 8.\n\n\nLa variabile aleatoria \\(X\\) rappresenta la somma di due dadi (figura tratta da Chan & Kroese, 2025).\n\nConsideriamo il valore specifico \\(X=8\\): questo valore pu√≤ essere ottenuto attraverso cinque diversi esiti dello spazio campionario: \\((2,6), (3,5), (4,4), (5,3), (6,2)\\). Indichiamo con \\(\\{X=8\\}\\) l‚Äôinsieme di questi esiti. Poich√© tutti gli esiti in \\(\\Omega\\) sono equiprobabili, possiamo calcolare la probabilit√† di ottenere una somma pari a 8 come:\n\\[\nP(X=8) = \\frac{5}{36}.\n\\]",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_random_var.html#tipologie-di-variabili-casuali",
    "href": "chapters/probability/07_random_var.html#tipologie-di-variabili-casuali",
    "title": "31¬† Variabili casuali",
    "section": "\n31.3 Tipologie di Variabili Casuali",
    "text": "31.3 Tipologie di Variabili Casuali\nLe variabili casuali si dividono in due categorie principali:\n\n31.3.1 Variabili Casuali Discrete\nUna variabile casuale discreta assume un insieme finito o numerabile di valori. Gli esempi includono il numero di teste ottenute in lanci di moneta o la somma dei risultati di due dadi. Per queste variabili, la funzione di massa di probabilit√† (PMF) assegna a ciascun valore \\(x\\) la probabilit√† \\(P(X = x)\\).\n\nEsempio 31.2 Nel lancio di due dadi, la variabile \\(X\\) (somma dei punti) pu√≤ assumere valori interi da 2 a 12. La distribuzione di \\(X\\) si ottiene contando i casi favorevoli per ciascun valore e dividendo per il numero totale di esiti (36).\n\n\n31.3.2 Variabili Casuali Continue\nUna variabile casuale continua pu√≤ assumere infiniti valori in un intervallo (ad esempio, l‚Äôaltezza di una persona). In questo caso non si assegna una probabilit√† a un singolo valore (che risulterebbe essere zero), ma si definisce una funzione di densit√† di probabilit√† (PDF), tale che l‚Äôintegrale della funzione su un intervallo fornisce la probabilit√† che la variabile cada in quell‚Äôintervallo.\n\nEsempio 31.3 Considera una variabile \\(X\\) che rappresenta l‚Äôaltezza in centimetri. Invece di \\(P(X = 170)\\), calcoliamo probabilit√† come \\(P(170 \\leq X \\leq 180)\\) mediante l‚Äôintegrale della PDF in quell‚Äôintervallo.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_random_var.html#notazione-convenzionale",
    "href": "chapters/probability/07_random_var.html#notazione-convenzionale",
    "title": "31¬† Variabili casuali",
    "section": "\n31.4 Notazione Convenzionale",
    "text": "31.4 Notazione Convenzionale\nNella teoria della probabilit√† si adotta una convenzione chiara per distinguere una variabile casuale dal suo valore osservato o realizzato:\n\nla variabile casuale viene indicata con lettere maiuscole (es. \\(X\\));\nil valore specifico assunto dalla variabile casuale viene indicato con lettere minuscole (es. \\(x\\)).\n\nQuesta convenzione aiuta a evitare ambiguit√†, soprattutto quando si definiscono:\n\nprobabilit√† cumulative: \\(P(X \\leq x)\\);\nvalore atteso: \\(E[X]\\);\nfunzioni di densit√† o massa di probabilit√†: \\(f_X(x)\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_random_var.html#variabili-casuali-multiple",
    "href": "chapters/probability/07_random_var.html#variabili-casuali-multiple",
    "title": "31¬† Variabili casuali",
    "section": "\n31.5 Variabili Casuali Multiple",
    "text": "31.5 Variabili Casuali Multiple\nIn molti esperimenti, √® utile considerare contemporaneamente pi√π variabili casuali. Ad esempio, supponiamo di lanciare una moneta equilibrata tre volte. Definiamo tre variabili casuali indipendenti \\(X_1\\), \\(X_2\\) e \\(X_3\\), ciascuna associata all‚Äôesito di un lancio:\n\\[\nP(X_n = 1) = 0.5 \\quad (\\text{testa}), \\qquad P(X_n = 0) = 0.5 \\quad (\\text{croce}), \\quad n = 1, 2, 3.\n\\]\nPossiamo poi definire una nuova variabile casuale derivata, ad esempio:\n\\[\nZ = X_1 + X_2 + X_3,\n\\]\nche rappresenta il numero totale di teste ottenute nei tre lanci. In questo scenario, \\(Z\\) √® una variabile casuale discreta che pu√≤ assumere esclusivamente i valori 0, 1, 2 o 3.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_random_var.html#distribuzione-di-probabilit√†",
    "href": "chapters/probability/07_random_var.html#distribuzione-di-probabilit√†",
    "title": "31¬† Variabili casuali",
    "section": "\n31.6 Distribuzione di Probabilit√†",
    "text": "31.6 Distribuzione di Probabilit√†\n\nDefinizione 31.2 La distribuzione di probabilit√† di una variabile casuale descrive come le probabilit√† sono assegnate ai possibili valori (o intervalli di valori) della variabile.\n\n\n31.6.1 Funzione di Massa di Probabilit√† (PMF) per Variabili Discrete\nPer una variabile casuale discreta \\(X\\), la distribuzione √® definita tramite la funzione di massa di probabilit√† (PMF), indicata con \\(f(x)\\), dove:\n\\[\nf(x) = P(X = x).\n\\]\nNota la PMF, √® possibile calcolare la probabilit√† di qualsiasi evento associato a \\(X\\). Ad esempio, per un insieme \\(B\\) di valori:\n\\[\nP(X \\in B) = \\sum_{x \\in B} f(x).\n\\]\n\nEsempio 31.4 Consideriamo nuovamente il lancio di due dadi, definendo \\(X\\) come la somma dei loro valori. La tabella seguente mostra chiaramente tutti i casi possibili, il numero di combinazioni per ogni somma, e la relativa probabilit√†:\n\n\n\n\n\n\n\n\n\\(X\\)\nCasi Favorevoli\nNumero di Casi\n\\(P(X = x)\\)\n\n\n\n2\n\\((1,1)\\)\n1\n\\(\\frac{1}{36}\\)\n\n\n3\n\\((1,2), (2,1)\\)\n2\n\\(\\frac{2}{36} = \\frac{1}{18}\\)\n\n\n4\n\\((1,3), (2,2), (3,1)\\)\n3\n\\(\\frac{3}{36} = \\frac{1}{12}\\)\n\n\n5\n\\((1,4), (2,3), (3,2), (4,1)\\)\n4\n\\(\\frac{4}{36} = \\frac{1}{9}\\)\n\n\n6\n\\((1,5), (2,4), (3,3), (4,2), (5,1)\\)\n5\n\\(\\frac{5}{36}\\)\n\n\n7\n\\((1,6), (2,5), (3,4), (4,3), (5,2), (6,1)\\)\n6\n\\(\\frac{6}{36} = \\frac{1}{6}\\)\n\n\n8\n\\((2,6), (3,5), (4,4), (5,3), (6,2)\\)\n5\n\\(\\frac{5}{36}\\)\n\n\n9\n\\((3,6), (4,5), (5,4), (6,3)\\)\n4\n\\(\\frac{4}{36} = \\frac{1}{9}\\)\n\n\n10\n\\((4,6), (5,5), (6,4)\\)\n3\n\\(\\frac{3}{36} = \\frac{1}{12}\\)\n\n\n11\n\\((5,6), (6,5)\\)\n2\n\\(\\frac{2}{36} = \\frac{1}{18}\\)\n\n\n12\n\\((6,6)\\)\n1\n\\(\\frac{1}{36}\\)\n\n\n\nPer esempio, la probabilit√† di ottenere una somma pari a 7 √® \\(\\frac{1}{6}\\) perch√© ci sono 6 combinazioni favorevoli su 36 possibili.\n\n\n31.6.2 Funzione di Distribuzione Cumulativa (CDF)\n\nDefinizione 31.3 La funzione di distribuzione cumulativa (CDF) di una variabile casuale \\(X\\) √® definita come: \\[\nF(x) = P(X \\leq x).\n\\] La CDF indica la probabilit√† che \\(X\\) assuma valori minori o uguali a un valore specifico \\(x\\).\n\n\n31.6.3 Propriet√† della CDF (Funzione di Ripartizione)\nLa CDF descrive la probabilit√† che una variabile casuale \\(X\\) assuma un valore minore o uguale a \\(x\\). Per capirla in psicologia (ad esempio, per analizzare dati di test, questionari, o esperimenti), bastano tre idee chiave:\n\n\nNon diminuisce mai:\nSe consideriamo valori \\(x\\) sempre pi√π grandi, la probabilit√† cumulata non pu√≤ diminuire.\n\n\nEsempio: Se la CDF a \\(x = 50\\) in un test √® \\(0.7\\), a \\(x = 60\\) sar√† almeno \\(0.7\\) (potrebbe salire, ma non scendere).\n\n\nPerch√©? Aggiungendo nuovi risultati (es.: punteggi pi√π alti), la probabilit√† totale pu√≤ solo aumentare o restare uguale.\n\n\n\nEstremi prevedibili:\n\nPer valori molto bassi (es.: \\(x \\to -\\infty\\)), la probabilit√† cumulata √® 0: non esistono punteggi infinitamente bassi.\n\nPer valori molto alti (es.: \\(x \\to +\\infty\\)), la probabilit√† cumulata √® 1: tutti i possibili risultati sono inclusi.\n\n\nEsempio: In una scala Likert da 1 a 5, la CDF a \\(x = 0\\) √® 0, e a \\(x = 10\\) √® 1.\n\n\n\nNiente salti ‚Äúa sorpresa‚Äù verso destra:\nLa CDF √® costruita in modo che, se ci spostiamo di pochissimo a destra di un punto \\(x\\), la probabilit√† cumulata non crolla improvvisamente.\n\n\nEsempio pratico:\nSupponiamo che in un questionario, il punteggio \\(x = 10\\) corrisponda a una certa probabilit√† cumulata (es.: \\(0.8\\)). Se ci spostiamo di un millesimo a destra (es.: \\(x = 10.001\\)), la probabilit√† rimane \\(0.8\\), a meno che \\(10.001\\) non sia un punteggio valido.\n\n\nA cosa serve? Garantisce coerenza: se un punteggio \\(x\\) ha una certa probabilit√†, questa non viene ‚Äúpersa‚Äù spostandosi di poco a destra.\n\n\n\n31.6.4 CDF per variabili discrete (es.: scale psicologiche)\nIn psicologia, spesso lavoriamo con dati discreti (es.: risposte a item di un test, come ‚Äú1 = Mai‚Äù a ‚Äú5 = Sempre‚Äù). In questi casi:\n\nLa CDF si calcola sommando le probabilit√† di tutti i valori \\(\\leq x\\).\n\n\nEsempio: Se in una scala da 1 a 5, il 30% degli studenti risponde 1 o 2, allora \\(F(2) = 0.3\\).\n\n\nGraficamente: La CDF avr√† ‚Äúgradini‚Äù nei punti corrispondenti ai valori possibili (es.: 1, 2, 3, 4, 5).\n\n\n31.6.4.1 Perch√© serve saperlo?\nQueste propriet√† aiutano a:\n\nInterpretare grafici cumulativi (es.: quanto √® probabile che un partecipante abbia un punteggio \\(\\leq\\) 20?).\n\nEvitare errori logici (es.: non ha senso aspettarsi un calo della probabilit√† cumulata all‚Äôaumentare di \\(x\\)).\n\nLeggere correttamente salti nei dati discreti (es.: un gradino in \\(x = 4\\) indica un accumulo di probabilit√† in quel punto).\n\n\nEsempio 31.5 Riprendendo l‚Äôesempio della variabile casuale \\(X\\) definita come la somma di due dadi, possiamo riassumere PMF e CDF in una tabella unica:\n\n\n\\(x\\)\n\\(P(X = x)\\)\n\\(F(x)\\)\n\n\n\n2\n\\(\\frac{1}{36}\\)\n\\(\\frac{1}{36}\\)\n\n\n3\n\\(\\frac{2}{36}\\)\n\\(\\frac{3}{36}\\)\n\n\n4\n\\(\\frac{3}{36}\\)\n\\(\\frac{6}{36}\\)\n\n\n5\n\\(\\frac{4}{36}\\)\n\\(\\frac{10}{36}\\)\n\n\n6\n\\(\\frac{5}{36}\\)\n\\(\\frac{15}{36}\\)\n\n\n7\n\\(\\frac{6}{36}\\)\n\\(\\frac{21}{36}\\)\n\n\n8\n\\(\\frac{5}{36}\\)\n\\(\\frac{26}{36}\\)\n\n\n9\n\\(\\frac{4}{36}\\)\n\\(\\frac{30}{36}\\)\n\n\n10\n\\(\\frac{3}{36}\\)\n\\(\\frac{33}{36}\\)\n\n\n11\n\\(\\frac{2}{36}\\)\n\\(\\frac{35}{36}\\)\n\n\n12\n\\(\\frac{1}{36}\\)\n\\(1\\)",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_random_var.html#distribuzioni-per-variabili-continue",
    "href": "chapters/probability/07_random_var.html#distribuzioni-per-variabili-continue",
    "title": "31¬† Variabili casuali",
    "section": "\n31.7 Distribuzioni per Variabili Continue",
    "text": "31.7 Distribuzioni per Variabili Continue\nPer le variabili casuali continue, non si usa la PMF ma la funzione di densit√† di probabilit√† (PDF). Una variabile casuale \\(X\\) si dice avere una distribuzione continua se esiste una funzione \\(f\\) positiva, tale che:\n\n\nL‚Äôintegrale totale di \\(f\\) risulta pari a 1:\n\\[\n\\int_{-\\infty}^{+\\infty} f(x) \\, dx = 1.\n\\]\n\n\nLa probabilit√† che \\(X\\) cada in un intervallo \\((a, b]\\) √® data da:\n\\[\nP(a &lt; X \\leq b) = \\int_a^b f(x) \\, dx.\n\\]\n\n\nAnche se usiamo lo stesso simbolo \\(f\\) per indicare la funzione di probabilit√† sia nel caso discreto che in quello continuo, il significato √® adattato al contesto. Nel caso continuo la probabilit√† di un valore specifico √® zero, mentre √® l‚Äôintegrale della PDF su un intervallo a fornire la probabilit√†.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_random_var.html#simulazione-della-distribuzione-di-probabilit√†",
    "href": "chapters/probability/07_random_var.html#simulazione-della-distribuzione-di-probabilit√†",
    "title": "31¬† Variabili casuali",
    "section": "\n31.8 Simulazione della Distribuzione di Probabilit√†",
    "text": "31.8 Simulazione della Distribuzione di Probabilit√†\nSpesso, anche se √® possibile calcolare analiticamente la distribuzione di probabilit√† (come nel caso dei due dadi), pu√≤ essere utile ottenere una stima empirica attraverso la simulazione. Questo approccio prevede di ripetere l‚Äôesperimento molte volte e di analizzare le frequenze relative dei risultati ottenuti.\n\nEsempio 31.6 Simulazione del lancio di due dadi in R.\n1. Simulare il lancio di un singolo dado\n\n# Funzione per simulare un dado a sei facce\nlancia_dado &lt;- function() {\n  sample(1:6, 1)\n}\n\n2. Simulare il lancio di due dadi\n\n# Funzione per simulare il lancio di due dadi ripetuto n volte\nlancia_due_dadi &lt;- function(n) {\n  risultati &lt;- numeric(n)\n  \n  for (i in 1:n) {\n    risultati[i] &lt;- lancia_dado() + lancia_dado()\n  }\n  \n  risultati\n}\n\n3. Eseguire la simulazione\n\n# Numero totale di simulazioni\nnumero_lanci &lt;- 100000\n\n# Simulazione dei lanci\nrisultati_simulazione &lt;- lancia_due_dadi(numero_lanci)\n\n# Visualizza i primi 20 risultati\ncat(\"Primi 20 risultati:\", risultati_simulazione[1:20], \"\\n\")\n#&gt; Primi 20 risultati: 6 2 6 4 5 6 10 4 4 4 9 10 6 7 3 8 9 6 10 7\n\n4. Calcolare e visualizzare la distribuzione empirica\n\n# Calcola la frequenza assoluta per ciascuna somma\nfrequenze_assolute &lt;- table(risultati_simulazione)\nfrequenze_assolute\n#&gt; risultati_simulazione\n#&gt;     2     3     4     5     6     7     8     9    10    11    12 \n#&gt;  2824  5655  8486 11128 13948 16526 13797 11024  8303  5458  2851\n\n# Calcola direttamente le frequenze relative (probabilit√† empiriche)\nprobabilita_empiriche &lt;- frequenze_assolute / numero_lanci\nprobabilita_empiriche\n#&gt; risultati_simulazione\n#&gt;       2       3       4       5       6       7       8       9      10 \n#&gt; 0.02824 0.05655 0.08486 0.11128 0.13948 0.16526 0.13797 0.11024 0.08303 \n#&gt;      11      12 \n#&gt; 0.05458 0.02851\n\n# Crea una tabella finale chiara e semplice\ndistribuzione_empirica &lt;- data.frame(\n  Somma = as.numeric(names(probabilita_empiriche)),\n  Probabilita = as.vector(probabilita_empiriche)\n)\n\n# Mostra la distribuzione empirica\nprint(distribuzione_empirica)\n#&gt;    Somma Probabilita\n#&gt; 1      2     0.02824\n#&gt; 2      3     0.05655\n#&gt; 3      4     0.08486\n#&gt; 4      5     0.11128\n#&gt; 5      6     0.13948\n#&gt; 6      7     0.16526\n#&gt; 7      8     0.13797\n#&gt; 8      9     0.11024\n#&gt; 9     10     0.08303\n#&gt; 10    11     0.05458\n#&gt; 11    12     0.02851\n\nChiarimento sintetico dei concetti chiave.\n\nCos‚Äô√® una simulazione?\n√à un esperimento realizzato al computer che replica pi√π volte un evento casuale per osservare i possibili risultati e la loro frequenza.\nDistribuzione empirica\n√à la frequenza con cui ogni risultato (in questo caso, la somma di due dadi) appare nella simulazione. Con pi√π simulazioni, questa distribuzione si avvicina sempre di pi√π a quella prevista dalla teoria.\nProbabilit√† teorica ed empirica\nLa probabilit√† teorica √® calcolata matematicamente: ad esempio, la somma ‚Äú7‚Äù √® teoricamente pi√π frequente perch√© ci sono pi√π modi di ottenerla (6+1, 5+2, 4+3, ecc.).\nLa probabilit√† empirica, invece, si ottiene dalla simulazione pratica, ed √® una buona approssimazione della probabilit√† teorica quando il numero di prove √® grande.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_random_var.html#conclusioni",
    "href": "chapters/probability/07_random_var.html#conclusioni",
    "title": "31¬† Variabili casuali",
    "section": "\n31.9 Conclusioni",
    "text": "31.9 Conclusioni\nIl concetto di variabile casuale ci consente di rappresentare numericamente i risultati di processi aleatori, trasformando osservazioni qualitative in dati quantitativi.\n\nLe variabili discrete utilizzano la funzione di massa di probabilit√† (PMF) per assegnare una probabilit√† a ciascun valore possibile.\nLe variabili continue sono descritte attraverso la funzione di densit√† di probabilit√† (PDF) e le probabilit√† sono calcolate integrando su intervalli.\n\nLa funzione di distribuzione cumulativa (CDF) √® un ulteriore strumento che consente di esprimere in forma cumulata la probabilit√† di ottenere valori minori o uguali a un certo punto.\nInfine, le simulazioni numeriche rappresentano un metodo pratico per verificare le distribuzioni teoriche, rendendo questi concetti pi√π tangibili e applicabili anche in situazioni complesse.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_random_var.html#esercizi",
    "href": "chapters/probability/07_random_var.html#esercizi",
    "title": "31¬† Variabili casuali",
    "section": "\n31.10 Esercizi",
    "text": "31.10 Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nConsiglio gli esercizi di base disponibili nella seguente pagina web.\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nEsercizi sulla distribuzione normale, risolvibili usando R, sono disponibili sulla seguente pagina web.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_random_var.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/07_random_var.html#informazioni-sullambiente-di-sviluppo",
    "title": "31¬† Variabili casuali",
    "section": "\n31.11 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "31.11 Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.5.3     \n#&gt;  [9] scales_1.3.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.9.1   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         rlang_1.1.5       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       tools_4.4.2       parallel_4.4.2    tzdb_0.5.0       \n#&gt; [21] colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5       R6_2.6.1         \n#&gt; [25] lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.1    \n#&gt; [29] gtable_0.3.6      glue_1.8.0        xfun_0.51         tidyselect_1.2.1 \n#&gt; [33] rstudioapi_0.17.1 farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-167     \n#&gt; [37] rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_random_var.html#bibliografia",
    "href": "chapters/probability/07_random_var.html#bibliografia",
    "title": "31¬† Variabili casuali",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlitzstein, J. K., & Hwang, J. (2019). Introduction to probability. CRC Press.\n\n\nChan, J. C. C., & Kroese, D. P. (2025). Statistical Modeling and Computation (2¬™ ed.). Springer.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_prob_distributions.html",
    "href": "chapters/probability/08_prob_distributions.html",
    "title": "32¬† Distribuzioni di massa e di densit√†",
    "section": "",
    "text": "32.1 Introduzione\nNel Capitolo 31 abbiamo introdotto il concetto di variabile casuale, distinguendo tra variabili casuali discrete e continue. Per le prime, abbiamo descritto formalmente come assegnare una distribuzione di massa di probabilit√†, mentre per le seconde abbiamo introdotto la nozione di funzione di densit√† di probabilit√†. Fino a questo punto, i concetti di distribuzione di massa e densit√† sono stati trattati in termini prevalentemente formali e matematici.\nLo scopo di questo capitolo √® quello di approfondire queste idee, fornendo un‚Äôinterpretazione pi√π intuitiva e concreta di tali concetti. Attraverso esempi ed analisi pratiche, cercheremo di chiarire il significato sottostante alle distribuzioni di probabilit√†, rendendo pi√π accessibili queste fondamentali strutture della teoria delle probabilit√†.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Distribuzioni di massa e di densit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_prob_distributions.html#variabili-casuali-discrete-e-continue",
    "href": "chapters/probability/08_prob_distributions.html#variabili-casuali-discrete-e-continue",
    "title": "32¬† Distribuzioni di massa e di densit√†",
    "section": "\n32.2 Variabili Casuali Discrete e Continue",
    "text": "32.2 Variabili Casuali Discrete e Continue\nUn elemento fondamentale nella comprensione delle distribuzioni di probabilit√† √® la distinzione tra variabili casuali discrete e continue, poich√© le distribuzioni di probabilit√† associate differiscono in modo sostanziale.\n\n\nVariabili Casuali Discrete: assumono un numero finito o numerabile di valori. Ad esempio, il numero di successi in una serie di esperimenti o il risultato del lancio di un dado.\n\nVariabili Casuali Continue: possono assumere un numero infinito di valori all‚Äôinterno di un intervallo. Esempi includono il tempo di attesa per un evento o il quoziente intellettivo (QI) di una persona.\n\nQuesta distinzione √® fondamentale perch√© le relative distribuzioni probabilistiche si comportano in modi diversi.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Distribuzioni di massa e di densit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_prob_distributions.html#distribuzioni-di-probabilit√†-discrete",
    "href": "chapters/probability/08_prob_distributions.html#distribuzioni-di-probabilit√†-discrete",
    "title": "32¬† Distribuzioni di massa e di densit√†",
    "section": "\n32.3 Distribuzioni di Probabilit√† Discrete",
    "text": "32.3 Distribuzioni di Probabilit√† Discrete\nLe distribuzioni di probabilit√† discrete descrivono fenomeni aleatori con un numero finito o numerabile di esiti possibili. Queste distribuzioni sono rappresentate da una funzione di massa di probabilit√† (PMF), che assegna una probabilit√† a ciascun valore della variabile casuale.\n\nEsempio 32.1 Consideriamo un dado sbilanciato con la seguente distribuzione di probabilit√†:\n\n\nValore di \\(X\\)\n\nProbabilit√† \\(p(x)\\)\n\n\n\n\n1\n0.10\n\n\n2\n0.15\n\n\n3\n0.20\n\n\n4\n0.25\n\n\n5\n0.20\n\n\n6\n0.10\n\n\n\nQuesta tabella rappresenta la funzione di massa di probabilit√† (PMF).\nPer visualizzare questa distribuzione, possiamo simulare 1000 lanci del dado e creare un diagramma a barre che rappresenta le frequenze relative osservate. In R:\n\n# Dati\nset.seed(123)\nprob &lt;- c(0.10, 0.15, 0.20, 0.25, 0.20, 0.10)\nlanci &lt;- sample(1:6, size = 1000, replace = TRUE, prob = prob)\n\n# Creazione di un data frame\ndf &lt;- data.frame(Valore = factor(lanci))\n\n# Creazione del diagramma a barre\nggplot(df, aes(x = Valore)) +\n  geom_bar(aes(y = after_stat(count) / sum(after_stat(count))), fill = \"lightblue\", color=\"black\") +\n  labs(\n    title = \"Distribuzione empirica dei lanci\",\n    x = \"Valore\",\n    y = \"Frequenza relativa\"\n  )\n\n\n\n\n\n\n\nQuando il numero di lanci aumenta, le frequenze relative si avvicinano sempre pi√π alle probabilit√† teoriche.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Distribuzioni di massa e di densit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_prob_distributions.html#distribuzioni-di-probabilit√†-continue",
    "href": "chapters/probability/08_prob_distributions.html#distribuzioni-di-probabilit√†-continue",
    "title": "32¬† Distribuzioni di massa e di densit√†",
    "section": "\n32.4 Distribuzioni di Probabilit√† Continue",
    "text": "32.4 Distribuzioni di Probabilit√† Continue\nLe distribuzioni di probabilit√† continue descrivono variabili casuali che possono assumere un numero infinito di valori in un intervallo. In questo caso, la probabilit√† √® rappresentata da una funzione di densit√† di probabilit√† (PDF), che descrive la probabilit√† che la variabile assuma valori in un dato intervallo.\n\n32.4.1 Probabilit√† come Area Sotto la Curva\nLe distribuzioni continue sono descritte dalla funzione di densit√† di probabilit√† (PDF). Per una variabile casuale continua \\(X\\), la probabilit√† che \\(X\\) assuma un valore compreso tra \\(a\\) e \\(b\\) √® data dall‚Äôarea sotto la curva della PDF tra \\(a\\) e \\(b\\):\n\\[\nP(a \\leq X \\leq b) = \\int_a^b f(x) \\, dx.\n\\]\n\nEsempio 32.2 Il quoziente intellettivo (QI) √® spesso modellato come una variabile casuale continua con distribuzione normale, con media \\(\\mu = 100\\) e deviazione standard \\(\\sigma = 15\\). Possiamo simulare questa distribuzione e confrontare l‚Äôistogramma dei dati con la PDF teorica.\nSimulazione con 50 osservazioni.\n\n# Parametri della distribuzione normale\nmu &lt;- 100\nsigma &lt;- 15\nsize &lt;- 50\n\n# Generare i dati\nset.seed(123)\nx &lt;- rnorm(size, mean = mu, sd = sigma)\n\n# Istogramma e densit√†\ndata_frame &lt;- data.frame(X = x)\nxmin &lt;- min(x)\nxmax &lt;- max(x)\ndensity_data &lt;- data.frame(\n  X = seq(xmin, xmax, length.out = 100),\n  Density = dnorm(seq(xmin, xmax, length.out = 100), mean = mu, sd = sigma)\n)\n\nggplot(data_frame, aes(x = X)) +\n  geom_histogram(\n    aes(y = after_stat(density)),\n    bins = 25,\n    fill = \"lightblue\", color = \"black\"\n  ) +\n  geom_line(\n    data = density_data,\n    aes(x = X, y = Density),\n    color = \"black\",\n    size = 1\n  ) +\n  labs(\n    title = \"Distribuzione del QI (50 osservazioni)\",\n    x = \"Valori del QI\",\n    y = \"Densit√†\"\n  )\n\n\n\n\n\n\n\nCon un campione piccolo, l‚Äôistogramma non corrisponde perfettamente alla PDF teorica. Tuttavia, aumentando il numero di osservazioni, l‚Äôapprossimazione migliora.\nSimulazione con 20000 osservazioni.\n\n# Generare un campione pi√π grande\nsize &lt;- 20000\nset.seed(123)\nx &lt;- rnorm(size, mean = mu, sd = sigma)\n\n# Aggiornare media e deviazione standard\nmu &lt;- mean(x)\nsigma &lt;- sd(x)\n\n# Creare il grafico\ndata_frame &lt;- data.frame(X = x)\nxmin &lt;- min(x)\nxmax &lt;- max(x)\ndensity_data &lt;- data.frame(\n  X = seq(xmin, xmax, length.out = 100),\n  Density = dnorm(seq(xmin, xmax, length.out = 100), mean = mu, sd = sigma)\n)\n\nggplot(data_frame, aes(x = X)) +\n  geom_histogram(\n    aes(y = after_stat(density)),\n    bins = 25,\n    fill = \"lightblue\",\n    color = \"black\"\n  ) +\n  geom_line(\n    data = density_data,\n    aes(x = X, y = Density),\n    color = \"black\",\n    size = 1\n  ) +\n  labs(\n    title = sprintf(\"Distribuzione del QI (%d osservazioni)\", size),\n    x = \"Valori del QI\",\n    y = \"Densit√†\"\n  )\n\n\n\n\n\n\n\nCon un campione di grandi dimensioni, l‚Äôistogramma riflette molto meglio la PDF teorica.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Distribuzioni di massa e di densit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_prob_distributions.html#interpretazione-della-funzione-di-densit√†",
    "href": "chapters/probability/08_prob_distributions.html#interpretazione-della-funzione-di-densit√†",
    "title": "32¬† Distribuzioni di massa e di densit√†",
    "section": "\n32.5 Interpretazione della Funzione di Densit√†",
    "text": "32.5 Interpretazione della Funzione di Densit√†\nLa funzione di densit√† di probabilit√† (PDF) rappresenta un‚Äôastrazione continua dell‚Äôistogramma. Quando il numero di osservazioni tende a infinito e la larghezza degli intervalli tende a zero, il profilo dell‚Äôistogramma si avvicina alla PDF.\n\n32.5.1 Propriet√† della PDF\n\n\nArea Totale: L‚Äôarea totale sotto la curva della PDF √® uguale a 1, poich√© rappresenta la probabilit√† totale.\n\nProbabilit√† per Intervalli: La probabilit√† che la variabile assuma un valore in un intervallo \\([a, b]\\) √® data dall‚Äôarea sotto la curva tra \\(a\\) e \\(b\\).\n\nProbabilit√† per Singoli Valori: Per una variabile continua, la probabilit√† di un singolo valore √® sempre zero, poich√© corrisponde all‚Äôarea sotto la curva in un punto.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Distribuzioni di massa e di densit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_prob_distributions.html#parametri-delle-distribuzioni-di-probabilit√†",
    "href": "chapters/probability/08_prob_distributions.html#parametri-delle-distribuzioni-di-probabilit√†",
    "title": "32¬† Distribuzioni di massa e di densit√†",
    "section": "\n32.6 Parametri delle Distribuzioni di Probabilit√†",
    "text": "32.6 Parametri delle Distribuzioni di Probabilit√†\nLe distribuzioni di probabilit√†, sia discrete che continue, sono definite da parametri che ne determinano le propriet√† fondamentali. Questi parametri consentono di adattare il modello probabilistico ai dati osservati.\n\n32.6.1 Propriet√† Influenzate dai Parametri\n\n\nPosizione (Tendenza Centrale): Indica il valore attorno al quale si concentra la distribuzione. Ad esempio, nella distribuzione normale, la media (\\(\\mu\\)) rappresenta il centro della distribuzione.\n\nDispersione: Misura quanto i valori della distribuzione si allontanano dalla posizione centrale. Nella distribuzione normale, la deviazione standard (\\(\\sigma\\)) controlla la larghezza della curva.\n\nForma: Determina l‚Äôasimmetria o la curtosi della distribuzione. Alcune distribuzioni, come quella gamma o beta, hanno parametri specifici per regolare la forma.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Distribuzioni di massa e di densit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_prob_distributions.html#il-paradosso-delle-variabili-casuali-continue",
    "href": "chapters/probability/08_prob_distributions.html#il-paradosso-delle-variabili-casuali-continue",
    "title": "32¬† Distribuzioni di massa e di densit√†",
    "section": "\n32.7 Il Paradosso delle Variabili Casuali Continue",
    "text": "32.7 Il Paradosso delle Variabili Casuali Continue\nUn aspetto controintuitivo delle variabili casuali continue √® che la probabilit√† di osservare esattamente un determinato valore √® sempre pari a zero. Per esempio, se consideriamo una variabile continua che rappresenta l‚Äôaltezza di una persona, la probabilit√† che l‚Äôaltezza sia esattamente 170 cm √® espressa da\n\\[\nP(X = 170) = 0.\n\\]\nPerch√© accade questo? La risposta sta nel concetto di ‚Äúesattezza‚Äù. Se riscriviamo 170 cm come 170.00000000000000000000000000000000000 cm (con infiniti decimali), diventa chiaro che stiamo cercando un singolo punto in un continuum infinito.\nQuesto non significa che l‚Äôevento sia impossibile, ma che nelle variabili continue la probabilit√† ha senso solo se riferita a intervalli di valori. Infatti, se sommiamo infinite probabilit√† diverse da zero, supereremmo 1, cosa impossibile.\n\n32.7.1 Due Implicazioni Importanti\nQuesto modo di definire la probabilit√† nelle variabili continue comporta due implicazioni chiave:\n\n\nCalcolo della probabilit√† su intervalli:\nNelle variabili continue, le probabilit√† si calcolano solo su intervalli (es.: tra 169.5 cm e 170.5 cm). Questo perch√©, se ogni singolo valore avesse probabilit√† &gt; 0, la somma di infiniti valori supererebbe 1 (il che √® impossibile).\n\nEventi con probabilit√† zero:\nIl fatto che un evento (ad esempio, \\(X = 170\\)) abbia probabilit√† zero non implica che l‚Äôevento sia impossibile. √à come cercare un granello di sabbia specifico su una spiaggia infinita: tecnicamente possibile, ma praticamente improbabile.\n\n32.7.2 Il Paradosso della Probabilit√† Zero\nQuesto ragionamento porta a un apparente paradosso: se la probabilit√† che l‚Äôaltezza di una persona sia esattamente 170 √® zero, come possiamo mai osservare un valore specifico, come 170 (o un qualsiasi altro valore), nella realt√†?\nUna metafora utile per comprendere questo fenomeno √® data dal celebre paradosso di Zenone della freccia. Nel paradosso, si sostiene che, in ogni istante, la freccia sia immobile, e dunque non si dovrebbe mai muovere. Analogamente, ogni singolo valore (es.: 170 cm) ha probabilit√† zero, ma l‚Äôinsieme di infiniti valori in un intervallo crea un‚Äôarea sotto la curva (probabilit√†) misurabile.\n\n32.7.3 La Prospettiva degli Infinitesimi\nNegli anni ‚Äô60, il matematico Abraham Robinson svilupp√≤ una teoria matematica rigorosa degli infinitesimi, ovvero numeri infinitamente piccoli, diversi da zero. In questo quadro, possiamo reinterpretare la probabilit√† dei singoli punti nel seguente modo:\n\n\nProbabilit√† infinitesimale:\nUn singolo valore puntuale non ha probabilit√† strettamente zero, bens√¨ infinitamente piccola (un infinitesimo). Pur essendo praticamente indistinguibile da zero nella teoria classica, l‚Äôaggregazione (tramite integrazione) di infiniti eventi con probabilit√† infinitesimali pu√≤ produrre un valore di probabilit√† finito e positivo per un intervallo. In altre parole, infiniti punti infinitamente piccoli sommati insieme generano un intervallo di probabilit√† misurabile e significativa.\n\nIn conclusione, il cosiddetto ‚Äúparadosso della probabilit√† zero‚Äù non rappresenta un vero paradosso, ma evidenzia piuttosto i limiti delle nostre intuizioni quando affrontiamo concetti inerenti variabili continue. La chiave per la comprensione risiede nella distinzione tra il contributo di un singolo punto (infinitesimale o zero, nell‚Äôanalisi classica) e l‚Äôarea complessiva calcolata mediante l‚Äôintegrazione.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Distribuzioni di massa e di densit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_prob_distributions.html#la-funzione-di-ripartizione-per-una-variabile-casuale-continua",
    "href": "chapters/probability/08_prob_distributions.html#la-funzione-di-ripartizione-per-una-variabile-casuale-continua",
    "title": "32¬† Distribuzioni di massa e di densit√†",
    "section": "\n32.8 La Funzione di Ripartizione per una Variabile Casuale Continua",
    "text": "32.8 La Funzione di Ripartizione per una Variabile Casuale Continua\nLa funzione di ripartizione, nota anche come distribuzione cumulativa, √® uno strumento fondamentale per descrivere il comportamento di una variabile casuale, sia essa discreta o continua. Per una variabile casuale continua \\(\\Theta\\), la funzione di ripartizione \\(F_{\\Theta}(\\theta)\\) √® definita come:\n\\[\nF_{\\Theta}(\\theta) = P(\\Theta \\leq \\theta).\n\\]\nIn altre parole, \\(F_{\\Theta}(\\theta)\\) rappresenta la probabilit√† che la variabile \\(\\Theta\\) assuma un valore minore o uguale a \\(\\theta\\). Questa definizione √® identica a quella utilizzata per le variabili casuali discrete, ma nel caso continuo assume un significato particolare a causa della natura continua della variabile.\n\n32.8.1 Propriet√† della Funzione di Ripartizione\nLa funzione di ripartizione per una variabile casuale continua gode di alcune propriet√† importanti:\n\n\nMonotonicit√† Crescente: \\(F_{\\Theta}(\\theta)\\) √® una funzione non decrescente. Ci√≤ significa che, all‚Äôaumentare di \\(\\theta\\), la probabilit√† \\(P(\\Theta \\leq \\theta)\\) non diminuisce.\n\nLimiti agli Estremi:\n\nQuando \\(\\theta \\to -\\infty\\), \\(F_{\\Theta}(\\theta) \\to 0\\).\nQuando \\(\\theta \\to +\\infty\\), \\(F_{\\Theta}(\\theta) \\to 1\\).\n\n\n\nContinuit√†: Per una variabile casuale continua, \\(F_{\\Theta}(\\theta)\\) √® una funzione continua. Questo differisce dal caso discreto, dove la funzione di ripartizione √® a gradini.\n\n32.8.2 Calcolo delle Probabilit√† per Intervalli\nUna delle applicazioni pi√π utili della funzione di ripartizione √® il calcolo della probabilit√† che la variabile casuale \\(\\Theta\\) assuma valori all‚Äôinterno di un intervallo specifico. Dati due valori \\(\\theta_1\\) e \\(\\theta_2\\) (con \\(\\theta_1 &lt; \\theta_2\\)), la probabilit√† che \\(\\Theta\\) sia compreso tra \\(\\theta_1\\) e \\(\\theta_2\\) √® data da:\n\\[\nP(\\theta_1 &lt; \\Theta \\leq \\theta_2) = F_{\\Theta}(\\theta_2) - F_{\\Theta}(\\theta_1).\n\\]\nQuesta formula √® particolarmente utile perch√©, nel caso delle variabili continue, la probabilit√† di un singolo punto √® sempre zero. Pertanto, per calcolare probabilit√† significative, √® necessario considerare intervalli di valori.\n\n32.8.3 Relazione con la Funzione di Densit√† di Probabilit√† (PDF)\nLa funzione di ripartizione √® strettamente legata alla funzione di densit√† di probabilit√† (PDF), \\(f(\\theta)\\). Mentre la PDF descrive la densit√† di probabilit√† in ogni punto, la funzione di ripartizione rappresenta l‚Äôarea sotto la curva della PDF fino a un certo valore \\(\\theta\\). Formalmente, la funzione di ripartizione si ottiene integrando la PDF:\n\\[\nF_{\\Theta}(\\theta) = \\int_{-\\infty}^{\\theta} f(t) \\, dt.\n\\]\nQuesta relazione evidenzia come la funzione di ripartizione sia una rappresentazione cumulativa della probabilit√†, ottenuta sommando (o integrando) i contributi della densit√† di probabilit√† fino al valore \\(\\theta\\).\n\nEsempio 32.3 Consideriamo una variabile casuale \\(\\Theta\\) con distribuzione normale standard (media \\(\\mu = 0\\) e deviazione standard \\(\\sigma = 1\\)). La PDF √® data da:\n\\[\nf(\\theta) = \\frac{1}{\\sqrt{2\\pi}} e^{-\\theta^2 / 2}.\n\\]\nLa funzione di ripartizione \\(F_{\\Theta}(\\theta)\\) √® l‚Äôintegrale di questa funzione da \\(-\\infty\\) a \\(\\theta\\):\n\\[\nF_{\\Theta}(\\theta) = \\int_{-\\infty}^{\\theta} \\frac{1}{\\sqrt{2\\pi}} e^{-t^2 / 2} \\, dt.\n\\]\nQuesta funzione non ha una forma chiusa semplice, ma pu√≤ essere calcolata numericamente o consultata in tabelle statistiche. Ad esempio, per \\(\\theta = 1\\), \\(F_{\\Theta}(1) \\approx 0.8413\\), il che significa che la probabilit√† che \\(\\Theta\\) sia minore o uguale a 1 √® circa l‚Äô84.13%.\n\n\n32.8.4 Interpretazione Grafica\nGraficamente, la funzione di ripartizione rappresenta l‚Äôarea sotto la curva della PDF a sinistra del valore \\(\\theta\\). Ad esempio, se consideriamo la distribuzione normale standard:\n\nPer \\(\\theta = 0\\), \\(F_{\\Theta}(0) = 0.5\\), poich√© la media della distribuzione √® 0 e la curva √® simmetrica.\nPer \\(\\theta = 1\\), \\(F_{\\Theta}(1) \\approx 0.8413\\), come visto sopra.\nPer \\(\\theta = -1\\), \\(F_{\\Theta}(-1) \\approx 0.1587\\), poich√© la coda sinistra della distribuzione contiene il 15.87% della probabilit√†.\n\n\n# Definisci i parametri della distribuzione normale standard\nmu &lt;- 0\nsigma &lt;- 1\n\n# Definisci i valori di theta\ntheta_values &lt;- c(-1, 0, 1)\n\n# Crea un data frame per la PDF e la CDF\nx &lt;- seq(-4, 4, length.out = 1000)  # Valori sull'asse x\npdf_values &lt;- dnorm(x, mean = mu, sd = sigma)  # Valori della PDF\ncdf_values &lt;- pnorm(x, mean = mu, sd = sigma)  # Valori della CDF\n\ndata &lt;- data.frame(x = x, PDF = pdf_values, CDF = cdf_values)\n\n# Crea il grafico\nggplot(data, aes(x = x)) +\n  # Plot della PDF\n  geom_line(aes(y = PDF), color = \"blue\", linewidth = 1) +\n  # Aggiungi aree sotto la PDF per i valori di theta\n  geom_area(data = subset(data, x &lt;= theta_values[1]), aes(y = PDF), fill = \"red\", alpha = 0.5) +\n  geom_area(data = subset(data, x &lt;= theta_values[2]), aes(y = PDF), fill = \"green\", alpha = 0.5) +\n  geom_area(data = subset(data, x &lt;= theta_values[3]), aes(y = PDF), fill = \"purple\", alpha = 0.5) +\n  # Plot della CDF\n  geom_line(aes(y = CDF), color = \"black\", linewidth = 1, linetype = \"dashed\") +\n  # Aggiungi linee verticali per i valori di theta\n  geom_vline(xintercept = theta_values, color = \"gray\", linetype = \"dotted\") +\n  # Aggiungi annotazioni per i valori di theta\n  annotate(\"text\", x = theta_values[1], y = 0, label = paste(\"Œ∏ =\", theta_values[1]), vjust = 2, hjust = 1.2, color = \"red\") +\n  annotate(\"text\", x = theta_values[2], y = 0, label = paste(\"Œ∏ =\", theta_values[2]), vjust = 2, hjust = 1.2, color = \"green\") +\n  annotate(\"text\", x = theta_values[3], y = 0, label = paste(\"Œ∏ =\", theta_values[3]), vjust = 2, hjust = -0.2, color = \"purple\") +\n  # Aggiungi titoli e etichette\n  labs(\n    title = \"Funzione di Densit√† di Probabilit√† (PDF) e\\nFunzione di Ripartizione (CDF)\",\n    subtitle = \"Distribuzione Normale Standard\",\n    x = \"Valori di Œ∏\",\n    y = \"Densit√† / Probabilit√† Cumulativa\"\n  )\n\n\n\n\n\n\n\nIn conclusione, la funzione di ripartizione √® uno strumento essenziale per comprendere e lavorare con variabili casuali continue. Essa non solo fornisce una rappresentazione cumulativa della probabilit√†, ma permette anche di calcolare probabilit√† per intervalli e di collegare la PDF alla distribuzione complessiva della variabile. Attraverso la sua relazione con la PDF, la funzione di ripartizione offre un ponte tra la descrizione locale (densit√†) e quella globale (probabilit√† cumulativa) di una variabile casuale continua.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Distribuzioni di massa e di densit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_prob_distributions.html#interpretazioni-bayesiana-e-frequentista-della-pdf",
    "href": "chapters/probability/08_prob_distributions.html#interpretazioni-bayesiana-e-frequentista-della-pdf",
    "title": "32¬† Distribuzioni di massa e di densit√†",
    "section": "\n32.9 Interpretazioni Bayesiana e Frequentista della PDF",
    "text": "32.9 Interpretazioni Bayesiana e Frequentista della PDF\nIn questo capitolo, abbiamo introdotto la funzione di densit√† di probabilit√† come limite del profilo di un istogramma, una descrizione intuitiva e utile per comprendere il concetto di densit√†. Questa interpretazione corrisponde, tuttavia, alla visione frequentista della densit√† di probabilit√†. Nella statistica Bayesiana, l‚Äôinterpretazione √® diversa e merita una spiegazione separata.\n\n32.9.1 Interpretazione Frequentista\nConcetto di ripetizione degli esperimenti:\n\nIdea di frequenza relativa:\nNel paradigma frequentista la probabilit√† √® intesa come il limite della frequenza relativa di un evento ottenuto al ripetere un esperimento un numero molto elevato di volte. Immaginiamo di eseguire un esperimento molte volte, ad ogni ripetizione si ottiene un valore di \\(x\\). Se costruiamo un istogramma di questi valori, questo istogramma diventa sempre pi√π ‚Äúliscio‚Äù man mano che il numero delle ripetizioni aumenta, fino a convergere alla PDF \\(p(x)\\).\nPDF come istogramma limite:\nLa PDF rappresenta la distribuzione dei valori osservati in una serie di ripetizioni dell‚Äôesperimento. In altre parole, essa descrive quanto frequentemente, in una ipotetica serie infinita di esperimenti, il valore \\(x\\) assume un determinato intervallo.\nEsempio intuitivo:\nSe misuriamo l‚Äôaltezza degli individui in una popolazione, nel contesto frequentista, la PDF ci dice quale frazione di individui cade in un certo intervallo di altezza se potessimo misurare ogni possibile individuo (o eseguire ripetutamente misurazioni indipendenti in una popolazione ‚Äúideale‚Äù).\n\n32.9.2 Interpretazione Bayesiana\nConcetto di incertezza e credenza:\n\n\nParametro come variabile casuale:\nIn statistica bayesiana, i parametri non sono visti come quantit√† fisse, ma come incerti. Si assume che ogni parametro (o dato osservato) abbia una propria distribuzione che riflette la nostra incertezza su di esso.\n\nAd esempio, se stiamo stimando un parametro \\(\\theta\\) (ad esempio la media di una distribuzione), in un approccio bayesiano attribuiamo a \\(\\theta\\) una distribuzione di probabilit√† che esprime quanto sia plausibile ciascun valore di \\(\\theta\\), dati i dati osservati e le nostre conoscenze pregresse.\n\n\n\nPDF come distribuzione di credenze:\nLa PDF, in questo contesto, non descrive una frequenza relativa osservabile sperimentalmente (perch√© l‚Äôesperimento non viene ripetuto infinite volte, o perch√© \\(x\\) √® un valore fisso ma incerto), ma esprime il grado di fiducia o la plausibilit√† che il valore ‚Äúvero‚Äù di \\(x\\) (o di un parametro) si trovi in un certo intervallo.\n\n√à come ‚Äúspalmare‚Äù la nostra incertezza su tutti i valori possibili: la sfumatura lungo l‚Äôasse \\(x\\) rappresenta la distribuzione delle nostre credenze.\n\n\nAnalogia con la densit√† di materia:\nUn‚Äôutile analogia √® quella della densit√† di materia \\(\\rho(x)\\) in meccanica classica: la densit√† non descrive la posizione precisa di ogni atomo, ma come la materia (o, in questo caso, la probabilit√†) √® distribuita lungo l‚Äôasse \\(x\\). Allo stesso modo, in una PDF bayesiana, non sono i ‚Äúvalori di \\(x\\)‚Äù ad essere distribuiti (in termini di frequenza osservabile), ma √® la nostra ‚Äúincertezza‚Äù a essere distribuita sui possibili valori.\nEsempio intuitivo:\nImmagina di dover stimare la probabilit√† che una certa ipotesi sia vera, ad esempio la media dell‚Äôaltezza in una popolazione. Invece di pensare a misurazioni ripetute, consideri il valore medio come fisso ma incerto. La PDF bayesiana esprime il grado di credenza per ciascun possibile valore della media, in base ai dati raccolti e alle informazioni a priori.\n\n32.9.3 Confronto\n\n\nFrequentista:\n\n\nFocus: Distribuzione dei dati.\n\nInterpretazione: La PDF descrive come i valori di \\(x\\) sarebbero distribuiti se ripetessimo l‚Äôesperimento infinite volte.\n\nEsempio: L‚Äôistogramma dei dati osservati in una lunga serie di esperimenti.\n\n\n\nBayesiano:\n\n\nFocus: Distribuzione della nostra incertezza o credenza.\n\nInterpretazione: La PDF riflette quanto sia plausibile ciascun valore di \\(x\\) (o di un parametro) dato l‚Äôinformazione disponibile, senza necessit√† di ripetere l‚Äôesperimento.\n\nEsempio: La distribuzione a posteriori di un parametro dopo aver combinato dati osservati e informazioni a priori.\n\n\n\n\n\n\n\n\nFigura¬†32.1: Interpretazioni frequentista e bayesiana di una PDF (curva blu) per una quantit√† reale \\(x\\). A sinistra: interpretazione frequentista come istogramma limite dei valori di \\(x\\) nelle ripetizioni; i valori di \\(x\\) sono distribuiti secondo la PDF. A destra: interpretazione bayesiana, con \\(x\\) che assume un valore fisso ma incerto per il caso specifico (rappresentato dal punto sull‚Äôasse \\(x\\)), con la probabilit√† distribuita sui valori possibili (raffigurata con una sfumatura lungo l‚Äôasse \\(x\\)). (Figura tratta da Loredo & Wolpert, 2024)\n\n\nIn sintesi, questa distinzione tra interpretazioni non √® solo una questione di semantica, ma ha implicazioni pratiche nella formulazione di modelli statistici e nell‚Äôinterpretazione dei risultati. Mentre l‚Äôapproccio frequentista √® spesso utilizzato quando si pu√≤ concettualmente pensare a ripetizioni infinite dell‚Äôesperimento, l‚Äôapproccio bayesiano √® particolarmente utile quando si vuole esprimere e aggiornare la propria incertezza su una quantit√† basandosi sia su dati che su conoscenze pregresse.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Distribuzioni di massa e di densit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_prob_distributions.html#riflessioni-conclusive",
    "href": "chapters/probability/08_prob_distributions.html#riflessioni-conclusive",
    "title": "32¬† Distribuzioni di massa e di densit√†",
    "section": "\n32.10 Riflessioni Conclusive",
    "text": "32.10 Riflessioni Conclusive\nLa funzione di densit√† di probabilit√† (PDF) costituisce il fondamento per la descrizione delle variabili casuali continue, consentendo di associare le probabilit√† ad intervalli, tramite il calcolo dell‚Äôarea sottesa alla curva. In questo contesto, la probabilit√† di osservare un valore esatto risulta zero, non per impossibilit√† dell‚Äôevento, ma perch√© in un insieme continuo ogni singolo punto contribuisce con un‚Äôarea infinitesimale.\nIl paradosso apparente, secondo cui la somma di infiniti contributi nulli porta a una probabilit√† totale positiva, si risolve grazie alla teoria dell‚Äôintegrazione. Integrando i contributi infinitesimali lungo un intervallo, si ottiene una quantit√† finita che rappresenta la probabilit√† complessiva dell‚Äôevento. Un‚Äôinterpretazione alternativa, fornita dalla teoria degli infinitesimi di Abraham Robinson, consente di attribuire a tali eventi probabilit√† infinitesimali, distinguendo tra diverse ‚Äúgrandezze‚Äù e chiarendo ulteriormente il processo di aggregazione verso un valore unitario.\nNel campo della data science, le distribuzioni di probabilit√†‚Äîformalmente rappresentate da \\(p(x)\\)‚Äîsono strumenti indispensabili per modellare la variabilit√† osservabile in una popolazione. Queste distribuzioni non mirano a riprodurre in maniera dettagliata ogni aspetto della realt√†, ma offrono un modello semplificato che consente di generalizzare i dati osservati e di formulare previsioni rigorose sui fenomeni futuri. In altre parole, \\(p(x)\\) non rappresenta la popolazione nel suo complesso, bens√¨ un‚Äôastrazione matematica che cattura l‚Äôincertezza e la variabilit√† del fenomeno studiato.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Distribuzioni di massa e di densit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_prob_distributions.html#esercizi",
    "href": "chapters/probability/08_prob_distributions.html#esercizi",
    "title": "32¬† Distribuzioni di massa e di densit√†",
    "section": "\n32.11 Esercizi",
    "text": "32.11 Esercizi\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nEsercizio 1: Variabili Casuali Discrete e Continue\nUtilizzando i dati raccolti sulla Satisfaction with Life Scale (SWLS) e sulla Scala della Rete Sociale di Lubben a 6 item (LSNS-6), classifica le seguenti variabili come discrete o continue:\n\nIl punteggio totale della SWLS.\nIl numero di amici con cui uno studente si sente a proprio agio nel parlare di questioni personali.\nIl tempo (in minuti) che uno studente trascorre con amici durante una settimana.\nIl numero di volte che uno studente ha contattato un parente nell‚Äôultimo mese.\nIl livello di soddisfazione della vita misurato su una scala da 1 a 7.\n\nSpiega il motivo della tua classificazione per ciascuna variabile.\nEsercizio 2: Distribuzioni di Probabilit√† Discrete\nConsideriamo la distribuzione del numero di amici con cui uno studente si sente a proprio agio nel parlare di questioni personali, misurata attraverso la LSNS-6. Supponiamo che la distribuzione sia la seguente (ma nell‚Äôesercizio usa le frequenze relative trovate nel campione di dati raccolto):\n\n\nNumero di amici\nProbabilit√†\n\n\n\n0\n0.05\n\n\n1\n0.15\n\n\n2\n0.25\n\n\n3\n0.30\n\n\n4\n0.15\n\n\n5\n0.10\n\n\n\n\nVerifica che questa sia una distribuzione di probabilit√† valida.\nQual √® la probabilit√† che uno studente abbia almeno 3 amici con cui si sente a proprio agio nel parlare di questioni personali?\nQual √® la probabilit√† che abbia meno di 2 amici?\nCalcola il valore atteso (media) e la varianza di questa distribuzione.\n\nEsercizio 3: Distribuzioni di Probabilit√† Continue\nIl punteggio totale della SWLS pu√≤ essere approssimato da una distribuzione normale con media 20 e deviazione standard 5.\n\nQual √® la probabilit√† che un individuo scelto a caso abbia un punteggio superiore a 25?\nQual √® la probabilit√† che un individuo abbia un punteggio compreso tra 15 e 25?\nQual √® il valore del punteggio che delimita il 10% superiore della distribuzione?\n\n(Suggerimento: utilizza la funzione di ripartizione della distribuzione normale standard per calcolare queste probabilit√†.)\nEsercizio 4: Legge della Probabilit√† Totale\nSi sa che il 60% degli studenti proviene da un ambiente con un forte supporto sociale, mentre il 40% ha un supporto sociale limitato. Inoltre, si sa che: - La probabilit√† che uno studente con forte supporto sociale abbia un punteggio SWLS superiore a 20 √® 0.75. - La probabilit√† che uno studente con supporto sociale limitato abbia un punteggio SWLS superiore a 20 √® 0.50.\nQual √® la probabilit√† che uno studente scelto a caso abbia un punteggio SWLS superiore a 20?\nEsercizio 5: Teorema di Bayes e Supporto Sociale\nRiprendendo l‚Äôesercizio precedente, calcola la probabilit√† che uno studente provenga da un ambiente con forte supporto sociale dato che il suo punteggio SWLS √® superiore a 20.\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\nEsercizio 1: Variabili Casuali Discrete e Continue\nUtilizzando i dati raccolti sulla Satisfaction with Life Scale (SWLS) e sulla Scala della Rete Sociale di Lubben a 6 item (LSNS-6), classifica le seguenti variabili come discrete o continue:\n\nIl punteggio totale della SWLS. (Continuo)\nIl numero di amici con cui uno studente si sente a proprio agio nel parlare di questioni personali. (Discreto)\nIl tempo (in minuti) che uno studente trascorre con amici durante una settimana. (Continuo)\nIl numero di volte che uno studente ha contattato un parente nell‚Äôultimo mese. (Discreto)\nIl livello di soddisfazione della vita misurato su una scala da 1 a 7. (Discreto)\n\nEsercizio 2: Distribuzioni di Probabilit√† Discrete\nConsideriamo la distribuzione del numero di amici con cui uno studente si sente a proprio agio nel parlare di questioni personali, misurata attraverso la LSNS-6. Supponiamo che la distribuzione sia la seguente:\n\n\nNumero di amici\nProbabilit√†\n\n\n\n0\n0.05\n\n\n1\n0.15\n\n\n2\n0.25\n\n\n3\n0.30\n\n\n4\n0.15\n\n\n5\n0.10\n\n\n\n\n\nVerifica della distribuzione: La somma delle probabilit√† deve essere 1:\n\\[ 0.05 + 0.15 + 0.25 + 0.30 + 0.15 + 0.10 = 1.00 \\]\nPoich√© la somma √® 1, la distribuzione √® valida.\n\n\nProbabilit√† di almeno 3 amici:\n\\[ P(X \\geq 3) = P(3) + P(4) + P(5) = 0.30 + 0.15 + 0.10 = 0.55 \\]\n\n\nProbabilit√† di meno di 2 amici:\n\\[ P(X &lt; 2) = P(0) + P(1) = 0.05 + 0.15 = 0.20 \\]\n\n\nValore atteso e varianza:\n\\[ E(X) = \\sum x P(x) = (0 \\times 0.05) + (1 \\times 0.15) + (2 \\times 0.25) + (3 \\times 0.30) + (4 \\times 0.15) + (5 \\times 0.10) = 2.65 \\]\n\\[ Var(X) = E(X^2) - (E(X))^2 \\]\n\\[ E(X^2) = (0^2 \\times 0.05) + (1^2 \\times 0.15) + (2^2 \\times 0.25) + (3^2 \\times 0.30) + (4^2 \\times 0.15) + (5^2 \\times 0.10) = 8.05 \\]\n\\[ Var(X) = 8.05 - (2.65)^2 = 1.06 \\]\n\n\nEsercizio 3: Distribuzioni di Probabilit√† Continue\nIl punteggio totale della SWLS pu√≤ essere approssimato da una distribuzione normale con media 20 e deviazione standard 5.\n\n\nProbabilit√† che il punteggio sia superiore a 25:\n\\[ P(X &gt; 25) = 1 - P(X \\leq 25) \\]\nStandardizziamo:\n\\[ Z = \\frac{25 - 20}{5} = 1 \\]\nUsando le tabelle della distribuzione normale:\n\\[ P(Z \\leq 1) = 0.8413 \\Rightarrow P(X &gt; 25) = 1 - 0.8413 = 0.1587 \\]\n\n\nProbabilit√† che il punteggio sia tra 15 e 25:\n\\[ P(15 \\leq X \\leq 25) = P(Z \\leq 1) - P(Z \\leq -1) \\]\n\\[ = 0.8413 - 0.1587 = 0.6826 \\]\n\n\nPercentile 90 della distribuzione:\nIl valore di Z per il 90% √® 1.28.\n\\[ X = 20 + (1.28 \\times 5) = 26.4 \\]\n\n\nEsercizio 4: Legge della Probabilit√† Totale\n\\[ P(SWLS &gt; 20) = P(SWLS &gt; 20 | S) P(S) + P(SWLS &gt; 20 | \\neg S) P(\\neg S) \\]\n\\[ = (0.75 \\times 0.60) + (0.50 \\times 0.40) \\]\n\\[ = 0.45 + 0.20 = 0.65 \\]\nEsercizio 5: Teorema di Bayes e Supporto Sociale\n\\[ P(S | SWLS &gt; 20) = \\frac{P(SWLS &gt; 20 | S) P(S)}{P(SWLS &gt; 20)} \\]\n\\[ = \\frac{(0.75 \\times 0.60)}{0.65} \\]\n\\[ = \\frac{0.45}{0.65} = 0.6923 \\]\nQuindi, la probabilit√† che uno studente provenga da un ambiente con forte supporto sociale dato che il suo punteggio SWLS √® superiore a 20 √® circa 69.2%.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Distribuzioni di massa e di densit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_prob_distributions.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/08_prob_distributions.html#informazioni-sullambiente-di-sviluppo",
    "title": "32¬† Distribuzioni di massa e di densit√†",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.5.3     \n#&gt;  [9] scales_1.3.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.9.1   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         rlang_1.1.5       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       yaml_2.3.10       tools_4.4.2       parallel_4.4.2   \n#&gt; [21] tzdb_0.5.0        colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5      \n#&gt; [25] R6_2.6.1          lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3  \n#&gt; [29] pillar_1.10.1     gtable_0.3.6      glue_1.8.0        xfun_0.51        \n#&gt; [33] tidyselect_1.2.1  rstudioapi_0.17.1 farver_2.1.2      htmltools_0.5.8.1\n#&gt; [37] nlme_3.1-167      labeling_0.4.3    rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Distribuzioni di massa e di densit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_prob_distributions.html#bibliografia",
    "href": "chapters/probability/08_prob_distributions.html#bibliografia",
    "title": "32¬† Distribuzioni di massa e di densit√†",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlitzstein, J. K., & Hwang, J. (2019). Introduction to probability. CRC Press.\n\n\nLoredo, T. J., & Wolpert, R. L. (2024). Bayesian inference: more than Bayes‚Äôs theorem. Frontiers in Astronomy and Space Sciences, 11, 1326926.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Distribuzioni di massa e di densit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_expval_var.html",
    "href": "chapters/probability/09_expval_var.html",
    "title": "33¬† Propriet√† delle variabili casuali",
    "section": "",
    "text": "33.1 Introduzione\n√à spesso molto utile sintetizzare la distribuzione di una variabile casuale attraverso indicatori caratteristici. Questi indicatori consentono di cogliere le principali propriet√† della distribuzione, come la posizione centrale (ovvero il ‚Äúbaricentro‚Äù) e la variabilit√† (ossia la dispersione attorno al centro). In questo modo, √® possibile ottenere una descrizione sintetica e significativa della distribuzione di probabilit√† della variabile casuale.\nIn questo capitolo, introdurremo i concetti fondamentali di valore atteso e varianza di una variabile casuale, che sono strumenti essenziali per comprendere e riassumere le propriet√† di una distribuzione probabilistica.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_expval_var.html#tendenza-centrale",
    "href": "chapters/probability/09_expval_var.html#tendenza-centrale",
    "title": "33¬† Propriet√† delle variabili casuali",
    "section": "\n33.2 Tendenza Centrale",
    "text": "33.2 Tendenza Centrale\nQuando vogliamo comprendere il comportamento tipico di una variabile casuale, ci interessa spesso determinare il suo ‚Äúvalore tipico‚Äù. Tuttavia, questa nozione pu√≤ essere interpretata in diversi modi:\n\n\nMedia: La somma dei valori divisa per il numero dei valori.\n\nMediana: Il valore centrale della distribuzione, quando i dati sono ordinati in senso crescente o decrescente.\n\nModa: Il valore che si verifica con maggiore frequenza.\n\nAd esempio, per il set di valori \\(\\{3, 1, 4, 1, 5\\}\\), la media √® \\(\\frac{3+1+4+1+5}{5} = 2.8\\), la mediana √® 3, e la moda √® 1. Tuttavia, quando ci occupiamo di variabili casuali, anzich√© di semplici sequenze di numeri, diventa necessario chiarire cosa intendiamo per ‚Äúvalore tipico‚Äù in questo contesto. Questo ci porta alla definizione formale del valore atteso.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_expval_var.html#valore-atteso",
    "href": "chapters/probability/09_expval_var.html#valore-atteso",
    "title": "33¬† Propriet√† delle variabili casuali",
    "section": "\n33.3 Valore Atteso",
    "text": "33.3 Valore Atteso\n\nDefinizione 33.1 Sia \\(X\\) una variabile casuale discreta che assume i valori \\(x_1, \\dots, x_n\\) con probabilit√† \\(P(X = x_i) = p(x_i)\\). Il valore atteso di \\(X\\), denotato con \\(\\mathbb{E}(X)\\), √® definito come:\n\\[\n\\mathbb{E}(X) = \\sum_{i=1}^n x_i \\cdot p(x_i).\n\\]\n\nIn altre parole, il valore atteso (noto anche come speranza matematica o aspettazione) di una variabile casuale √® la somma di tutti i valori che la variabile pu√≤ assumere, ciascuno ponderato dalla probabilit√† con cui esso si verifica.\n\nEsempio 33.1 Calcoliamo il valore atteso della variabile casuale \\(X\\) corrispondente al lancio di una moneta equilibrata, dove testa corrisponde a \\(X = 1\\) e croce corrisponde a \\(X = 0\\):\n\\[\n\\mathbb{E}(X) = \\sum_{i=1}^{2} x_i \\cdot P(x_i) = 0 \\cdot \\frac{1}{2} + 1 \\cdot \\frac{1}{2} = 0.5.\n\\]\n\n\nEsempio 33.2 Calcoliamo il valore atteso della variabile casuale \\(X\\) che rappresenta la somma dei punti ottenuti dal lancio di due dadi equilibrati a sei facce.\nLa variabile casuale \\(X\\) pu√≤ assumere i seguenti valori:\n\\[\n\\{2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12\\}.\n\\]\nLa probabilit√† associata a ciascun valore √® data dalla distribuzione di massa di probabilit√†. Ad esempio, il valore \\(X = 2\\) si ottiene solo se entrambi i dadi mostrano 1, quindi ha probabilit√†:\n\\[\nP(X = 2) = \\frac{1}{36}.\n\\]\nAnalogamente, \\(X = 7\\) pu√≤ essere ottenuto con sei combinazioni diverse: (1,6), (2,5), (3,4), (4,3), (5,2), (6,1), quindi:\n\\[\nP(X = 7) = \\frac{6}{36}.\n\\]\nLa distribuzione di massa di probabilit√† completa √®:\n\\[\nP(X) = \\left\\{\\frac{1}{36}, \\frac{2}{36}, \\frac{3}{36}, \\frac{4}{36}, \\frac{5}{36}, \\frac{6}{36}, \\frac{5}{36}, \\frac{4}{36}, \\frac{3}{36}, \\frac{2}{36}, \\frac{1}{36}\\right\\}.\n\\]\nIl valore atteso \\(\\mathbb{E}[X]\\) √® definito come:\n\\[\n\\mathbb{E}[X] = \\sum_{x} x \\cdot P(X = x).\n\\]\nApplicando questa formula:\n\\[\n\\mathbb{E}[X] = 2 \\cdot \\frac{1}{36} + 3 \\cdot \\frac{2}{36} + 4 \\cdot \\frac{3}{36} + \\cdots + 12 \\cdot \\frac{1}{36} = 7.\n\\]\nEcco come calcolarlo utilizzando R:\n\n# Valori di X e le loro probabilit√†\nvalori &lt;- 2:12\nprob &lt;- c(1, 2, 3, 4, 5, 6, 5, 4, 3, 2, 1) / 36\n\n# Calcolo del valore atteso\nvalore_atteso &lt;- sum(valori * prob)\nvalore_atteso\n#&gt; [1] 7\n\nIl risultato sar√†: \\[\n\\mathbb{E}[X] = 7.\n\\]\nPer rappresentare graficamente la distribuzione di massa di probabilit√†:\n\n# Creazione di un data frame\ndati &lt;- data.frame(Valore = valori, Probabilit√† = prob)\n\n# Plot\nggplot(dati, aes(x = Valore, y = Probabilit√†)) +\n  geom_col(fill = \"lightblue\") +\n  labs(\n    title = \"Distribuzione di Massa di Probabilit√† per X\",\n    x = \"Valore della Somma (X)\",\n    y = \"Probabilit√†\"\n  ) \n\n\n\n\n\n\n\n\n\n33.3.1 Interpretazione\nNel suo Ars conjectandi, Bernoulli introduce la nozione di valore atteso con le seguenti parole:\n\nil termine ‚Äúaspettativa‚Äù non deve essere inteso nel suo significato comune [‚Ä¶], bens√¨ come la speranza di ottenere il meglio diminuita dalla paura di ottenere il peggio. Pertanto, il valore della nostra aspettativa rappresenta sempre qualcosa di intermedio tra il meglio che possiamo sperare e il peggio che possiamo temere (Hacking, 2006).\n\nIn termini moderni, questa intuizione pu√≤ essere rappresentata in modo pi√π chiaro attraverso una simulazione. Possiamo affermare, infatti, che il valore atteso di una variabile casuale corrisponde alla media aritmetica di un gran numero di realizzazioni indipendenti della variabile stessa.\nPer fare un esempio concreto, consideriamo nuovamente il caso del lancio di due dadi bilanciati a sei facce, dove la variabile casuale \\(X\\) rappresenta la ‚Äúsomma dei due dadi‚Äù. Simuliamo un numero elevato di realizzazioni indipendenti di \\(X\\).\n\nset.seed(123)  \nx_samples &lt;- sample(valori, size = 1e6, replace = TRUE, prob = prob)\n\nL‚Äôistruzione sample(x, size = 1e6, replace = TRUE, prob = px)) utilizza R per generare un array di 1.000.000 di elementi (specificato dal parametro size), selezionati casualmente dall‚Äôarray x secondo le probabilit√† specificate nell‚Äôarray px.\nQuando il numero di realizzazioni indipendenti √® sufficientemente grande, la media aritmetica dei campioni generati si avvicina al valore atteso della variabile casuale:\n\nmean(x_samples)\n#&gt; [1] 6.998\n\nQuesto risultato conferma che il valore atteso \\(\\mathbb{E}[X] = 7\\) rappresenta la somma media dei punti ottenuti nel lancio di due dadi equilibrati su un numero elevato di prove. Anche se ogni singola somma pu√≤ variare tra 2 e 12, in media ci aspettiamo una somma di 7.\nL‚Äôaspettativa pu√≤ anche essere interpretata come un centro di massa. Immagina che delle masse puntiformi con pesi \\(p_1, p_2, \\dots, p_n\\) siano posizionate alle posizioni \\(x_1, x_2, \\dots, x_n\\) sulla retta reale. Il centro di massa‚Äîil punto in cui i pesi sono bilanciati‚Äî√® dato da:\n\\[\n\\text{centro di massa} = x_1 p_1 + x_2 p_2 + \\dots + x_n p_n,\n\\]\nche corrisponde esattamente all‚Äôaspettativa della variabile discreta \\(X\\), che assume valori \\(x_1, \\dots, x_n\\) con probabilit√† \\(p_1, \\dots, p_n\\). Una conseguenza ovvia di questa interpretazione √® che, per una funzione di densit√† di probabilit√† (pdf) simmetrica, l‚Äôaspettativa coincide con il punto di simmetria (a patto che l‚Äôaspettativa esista).\n\n\n\n\n\nFigura¬†33.1: L‚Äôaspettativa come centro di massa (figura tratta da Chan & Kroese, 2025).\n\n\n\n33.3.2 Propriet√† del Valore Atteso\nUna delle propriet√† pi√π importanti del valore atteso √® la sua linearit√†: il valore atteso della somma di due variabili casuali √® uguale alla somma dei loro rispettivi valori attesi:\n\\[\n\\mathbb{E}(X + Y) = \\mathbb{E}(X) + \\mathbb{E}(Y).\n\\tag{33.1}\\]\nQuesta propriet√†, espressa dalla formula sopra, √® intuitiva quando \\(X\\) e \\(Y\\) sono variabili casuali indipendenti, ma √® valida anche nel caso in cui \\(X\\) e \\(Y\\) siano correlate.\nInoltre, se moltiplichiamo una variabile casuale per una costante \\(c\\), il valore atteso del prodotto √® uguale alla costante moltiplicata per il valore atteso della variabile casuale:\n\\[\n\\mathbb{E}(cY) = c \\mathbb{E}(Y).\n\\tag{33.2}\\]\nQuesta propriet√† ci dice che una costante pu√≤ essere ‚Äúestratta‚Äù dall‚Äôoperatore di valore atteso, e si applica a qualunque numero di variabili casuali.\nUn‚Äôaltra propriet√† significativa riguarda il prodotto di variabili casuali indipendenti. Se \\(X\\) e \\(Y\\) sono indipendenti, allora il valore atteso del loro prodotto √® uguale al prodotto dei loro valori attesi:\n\\[\n\\mathbb{E}(XY) = \\mathbb{E}(X) \\mathbb{E}(Y).\n\\tag{33.3}\\]\nInfine, consideriamo la media aritmetica \\(\\bar{X} = \\frac{X_1 + \\ldots + X_n}{n}\\) di \\(n\\) variabili casuali indipendenti con la stessa distribuzione e con valore atteso \\(\\mu\\). Il valore atteso della media aritmetica √®:\n\\[\n\\mathbb{E}(\\bar{X}) = \\frac{1}{n} \\left(\\mathbb{E}(X_1) + \\dots + \\mathbb{E}(X_n)\\right) = \\frac{1}{n} \\cdot n \\cdot \\mathbb{E}(X) = \\mu.\n\\]\nQuesto risultato conferma che la media aritmetica di un campione di variabili casuali indipendenti ha lo stesso valore atteso della distribuzione originaria, rendendo il valore atteso uno strumento cruciale per l‚Äôanalisi statistica e probabilistica.\n\nEsempio 33.3 Consideriamo il seguente esperimento casuale. Sia \\(Y\\) il numero che si ottiene dal lancio di un dado equilibrato a sei facce e \\(Y\\) il numero di teste prodotto dal lancio di una moneta equilibrata (0 oppure 1). Troviamo il valore atteso di \\(X+Y\\).\nPer risolvere il problema iniziamo a costruire lo spazio campione dell‚Äôesperimento casuale.\n\n\n\n\n\n\n\n\n\n\n\n\\(x /\\ y\\)\n1\n2\n3\n4\n5\n6\n\n\n\n0\n(0, 1)\n(0, 2)\n(0, 3)\n(0, 4)\n(0, 5)\n(0, 6)\n\n\n1\n(1, 1)\n(1, 2)\n(1, 3)\n(1, 4)\n(1, 5)\n(1, 6)\n\n\n\novvero\n\n\n\\(x /\\ y\\)\n1\n2\n3\n4\n5\n6\n\n\n\n0\n1\n2\n3\n4\n5\n6\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\nIl risultato del lancio del dado √® indipendente dal risultato del lancio della moneta. Pertanto, ciascun evento elementare dello spazio campione avr√† la stessa probabilit√† di verificarsi, ovvero \\(P(\\omega) = \\frac{1}{12}\\). Il valore atteso di \\(X+Y\\) √® dunque uguale a:\n\\[\n\\mathbb{E}(X+Y) = 1 \\cdot \\frac{1}{12} + 2 \\cdot \\frac{1}{12} + \\dots + 7 \\cdot \\frac{1}{12} = 4.0.\n\\]\nSi ottiene lo stesso risultato usando l‚ÄôEquazione¬†33.1:\n\\[\n\\mathbb{E}(X+Y) = \\mathbb{E}(X) + E(Y) = 3.5 + 0.5 = 4.0.\n\\]\n\n\nEsempio 33.4 Svolgiamo ora l‚Äôesercizio in R\n\ncoin &lt;- 0:1  # Valori della moneta: testa (0) e croce (1)\ndie &lt;- 1:6   # Valori del dado: da 1 a 6\n\n# Creazione del campione come combinazione di valori (moneta, dado)\nsample &lt;- expand.grid(coin = coin, die = die)\nprint(sample)\n#&gt;    coin die\n#&gt; 1     0   1\n#&gt; 2     1   1\n#&gt; 3     0   2\n#&gt; 4     1   2\n#&gt; 5     0   3\n#&gt; 6     1   3\n#&gt; 7     0   4\n#&gt; 8     1   4\n#&gt; 9     0   5\n#&gt; 10    1   5\n#&gt; 11    0   6\n#&gt; 12    1   6\n\n\npx &lt;- numeric()  # Vettore per memorizzare le probabilit√†\n\nfor (i in 1:7) {\n  # Filtrare le combinazioni in cui la somma √® uguale a 'i'\n  event &lt;- subset(sample, coin + die == i)\n  # Calcolare la probabilit√†\n  prob &lt;- nrow(event) / nrow(sample)\n  px &lt;- c(px, prob)\n  \n  # Stampare la probabilit√†\n  cat(sprintf(\"P(X + Y = %d) = %d / %d\\n\", i, nrow(event), nrow(sample)))\n}\n#&gt; P(X + Y = 1) = 1 / 12\n#&gt; P(X + Y = 2) = 2 / 12\n#&gt; P(X + Y = 3) = 2 / 12\n#&gt; P(X + Y = 4) = 2 / 12\n#&gt; P(X + Y = 5) = 2 / 12\n#&gt; P(X + Y = 6) = 2 / 12\n#&gt; P(X + Y = 7) = 1 / 12\n\n\nx &lt;- 1:7  # Valori della variabile casuale (somma di moneta e dado)\nexpected_value &lt;- sum(x * px)\nexpected_value\n#&gt; [1] 4\n\n\n\nEsempio 33.5 Consideriamo le variabili casuali \\(X\\) e \\(Y\\) definite nel caso del lancio di tre monete equilibrate, dove \\(X\\) conta il numero delle teste nei tre lanci e \\(Y\\) conta il numero delle teste al primo lancio. Si calcoli il valore atteso di \\(Z = X \\cdot Y\\).\nLa distribuzione di probabilit√† congiunta \\(P(X, Y)\\) √® fornita nella tabella seguente.\n\n\n\\(x /\\ y\\)\n0\n1\n\\(p(Y)\\)\n\n\n\n0\n1/8\n0\n1/8\n\n\n1\n2/8\n1/8\n3/8\n\n\n2\n1/8\n2/8\n3/8\n\n\n3\n0\n1/8\n1/8\n\n\n\\(p(y)\\)\n4/8\n4/8\n1.0\n\n\n\nIl calcolo del valore atteso di \\(XY\\) si riduce a\n\\[\n\\mathbb{E}(Z) = 1 \\cdot \\frac{1}{8} + 2 \\cdot \\frac{2}{8} + 3 \\cdot \\frac{1}{8} = 1.0.\n\\]\nSi noti che le variabili casuali \\(Y\\) e \\(Y\\) non sono indipendenti. Dunque non possiamo usare l‚ÄôEquazione¬†33.3. Infatti, il valore atteso di \\(X\\) √®\n\\[\n\\mathbb{E}(X) = 1 \\cdot \\frac{3}{8} + 2 \\cdot \\frac{3}{8} + 3 \\cdot \\frac{1}{8} = 1.5\n\\]\ne il valore atteso di \\(Y\\) √®\n\\[\n\\mathbb{E}(Y) = 0 \\cdot \\frac{4}{8} + 1 \\cdot \\frac{4}{8} = 0.5.\n\\]\nPerci√≤\n\\[\n1.5 \\cdot 0.5 \\neq 1.0.\n\\]\n\n\n33.3.3 Variabili casuali continue\nNel caso di una variabile casuale continua \\(X\\), il valore atteso √® definito come:\n\\[\n\\mathbb{E}(X) = \\int_{-\\infty}^{+\\infty} x \\cdot p(x) \\, \\mathrm{d}x.\n\\]\nAnche in questo contesto, il valore atteso rappresenta una media ponderata dei valori di \\(x\\), dove ogni possibile valore di \\(x\\) √® ponderato in base alla densit√† di probabilit√† \\(p(x)\\).\nL‚Äôintegrale pu√≤ essere interpretato analogamente a una somma continua, in cui \\(x\\) rappresenta la posizione delle barre infinitamente strette di un istogramma, e \\(p(x)\\) rappresenta l‚Äôaltezza di tali barre. La notazione \\(\\int_{-\\infty}^{+\\infty}\\) indica che si sta sommando il contributo di ogni valore possibile di \\(x\\) lungo l‚Äôintero asse reale.\nQuesta interpretazione rende chiaro come l‚Äôintegrale calcoli una somma ponderata che si estende su tutti i possibili valori di \\(x\\), fornendo una misura centrale della distribuzione della variabile casuale continua. Per ulteriori dettagli sulla notazione dell‚Äôintegrale, si veda l‚Äô?sec-calculus.\n\n33.3.3.1 Moda\nUn‚Äôaltra misura di tendenza centrale delle variabili casuali continue √® la moda. La moda di \\(Y\\) individua il valore \\(y\\) pi√π plausibile, ovvero il valore \\(y\\) che massimizza la funzione di densit√† \\(p(y)\\):\n\\[\nMo(Y) = \\text{argmax}_y p(y).\n\\tag{33.4}\\]\n\n\n\n\n\n\nLa notazione \\(\\text{argmax}_y p(y)\\) significa: il valore \\(y\\) tale per cui la funzione \\(p(y)\\) assume il suo valore massimo.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_expval_var.html#varianza",
    "href": "chapters/probability/09_expval_var.html#varianza",
    "title": "33¬† Propriet√† delle variabili casuali",
    "section": "\n33.4 Varianza",
    "text": "33.4 Varianza\nDopo il valore atteso, la seconda propriet√† pi√π importante di una variabile casuale √® la varianza.\n\nDefinizione 33.2 Se \\(X\\) √® una variabile casuale discreta con distribuzione \\(p(x)\\), la varianza di \\(X\\), denotata con \\(\\mathbb{V}(X)\\), √® definita come:\n\\[\n\\mathbb{V}(X) = \\mathbb{E}\\Big[\\big(X - \\mathbb{E}(X)\\big)^2\\Big].\n\\tag{33.5}\\]\n\nIn altre parole, la varianza misura la deviazione media quadratica dei valori della variabile rispetto alla sua media. Se denotiamo il valore atteso di \\(X\\) con \\(\\mu = \\mathbb{E}(X)\\), la varianza \\(\\mathbb{V}(X)\\) diventa il valore atteso di \\((X - \\mu)^2\\).\n\n33.4.1 Interpretazione della Varianza\nLa varianza rappresenta una misura della ‚Äúdispersione‚Äù dei valori di \\(X\\) intorno al suo valore atteso. Quando calcoliamo la varianza, stiamo effettivamente misurando quanto i valori di \\(X\\) tendono a differire dalla media \\(\\mu\\).\nPer capire meglio, consideriamo la variabile casuale \\(X - \\mathbb{E}(X)\\), detta scarto o deviazione dalla media. Questa variabile rappresenta le ‚Äúdistanze‚Äù tra i valori di \\(X\\) e il valore atteso \\(\\mathbb{E}(X)\\). Tuttavia, poich√© lo scarto pu√≤ essere positivo o negativo, la media dello scarto √® sempre zero, il che lo rende inadatto a quantificare la dispersione.\nPer risolvere questo problema, eleviamo al quadrato gli scarti, ottenendo \\((X - \\mathbb{E}(X))^2\\), che rende tutte le deviazioni positive. La varianza √® quindi la media di questi scarti al quadrato, fornendo una misura efficace della dispersione complessiva dei valori di \\(X\\) rispetto alla sua media.\nQuesto concetto √® fondamentale per comprendere la variabilit√† di una distribuzione e per applicare strumenti statistici che richiedono una conoscenza approfondita della distribuzione dei dati.\n\nEsempio 33.6 Posta \\(S\\) uguale alla somma dei punti ottenuti nel lancio di due dadi equilibrati, si calcoli la varianza di \\(S\\).\nLa variabile casuale \\(S\\) ha la seguente distribuzione di probabilit√†:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(s\\)\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\\(P(S = s)\\)\n\\(\\frac{1}{36}\\)\n\\(\\frac{2}{36}\\)\n\\(\\frac{3}{36}\\)\n\\(\\frac{4}{36}\\)\n\\(\\frac{5}{36}\\)\n\\(\\frac{6}{36}\\)\n\\(\\frac{5}{36}\\)\n\\(\\frac{4}{36}\\)\n\\(\\frac{3}{36}\\)\n\\(\\frac{2}{36}\\)\n\\(\\frac{1}{36}\\)\n\n\nEssendo \\(\\mathbb{E}(S) = 7\\), la varianza diventa\n\\[\n\\begin{align}\n\\mathbb{V}(S) &= \\sum \\left(s - \\mathbb{E}(S)\\right)^2 \\cdot P(s) \\notag\\\\\n&= (2 - 7)^2 \\cdot \\frac{1}{36} + (3-7)^2 \\cdot \\frac{3}{36} + \\dots + (12 - 7)^2 \\cdot \\frac{1}{36} \\notag\\\\\n&= 5.8333.\\notag\n\\end{align}\n\\]\n\n\nEsempio 33.7 Svolgiamo l‚Äôesercizio in R\n\n# Definire i valori di x e le loro probabilit√† px\nx &lt;- 2:12\npx &lt;- c(\n  1 / 36, 2 / 36, 3 / 36, 4 / 36, 5 / 36, 6 / 36,\n  5 / 36, 4 / 36, 3 / 36, 2 / 36, 1 / 36\n)\n\n# Calcolare il valore atteso\nex &lt;- sum(x * px)\nex\n#&gt; [1] 7\n\nApplichiamo l‚ÄôEquazione¬†33.5:\n\n# Calcolo della varianza utilizzando la definizione\nvariance &lt;- sum((x - ex)^2 * px)\nvariance\n#&gt; [1] 5.833\n\nUsiamo la funzione var() di rv_discrete:\n\n# Calcolo della varianza con pesi\nvariance_check &lt;- weighted.mean((x - ex)^2, w = px)\nvariance_check\n#&gt; [1] 5.833\n\n\n\n33.4.2 Formula Alternativa per la Varianza\nLa varianza di una variabile casuale \\(X\\), indicata come \\(\\mathbb{V}(X)\\), misura la dispersione dei valori attorno alla media. La definizione classica √®:\n\\[\n\\mathbb{V}(X) = \\mathbb{E}\\Big[\\big(X - \\mathbb{E}(X)\\big)^2\\Big].\n\\]\nEsiste per√≤ una formula alternativa che semplifica il calcolo.\n\nDimostrazione. \n\nEspansione del quadrato\nConsideriamo la varianza, definita come \\(\\mathbb{V}(X) = \\mathbb{E}\\big[(X - \\mathbb{E}(X))^2\\big]\\).\nEspandiamo il quadrato \\((X - \\mathbb{E}(X))^2\\) utilizzando la regola \\((a - b)^2 = a^2 - 2ab + b^2\\): \\[\n(X - \\mathbb{E}(X))^2 = X^2 - 2\\,X\\,\\mathbb{E}(X) + \\big(\\mathbb{E}(X)\\big)^2.\n\\]\nApplicazione dell‚Äôaspettativa\nApplichiamo \\(\\mathbb{E}[\\cdot]\\) a ciascun termine, ricordando che l‚Äôaspettativa √® un operatore lineare: \\[\n\\mathbb{E}\\big[(X - \\mathbb{E}(X))^2\\big]\n= \\mathbb{E}\\big[X^2\\big]\n  \\;-\\; 2 \\,\\mathbb{E}\\big[X\\,\\mathbb{E}(X)\\big]\n  \\;+\\; \\mathbb{E}\\big[\\big(\\mathbb{E}(X)\\big)^2\\big].\n\\]\n\nGestione dei termini costanti\nL‚Äôaspettativa \\(\\mathbb{E}(X)\\) √® una costante (indipendente da \\(X\\)). Indichiamola con \\(\\mu\\). Quindi:\n\n\n\\(\\mathbb{E}(X^2)\\) resta com‚Äô√®.\n\n\\(\\mathbb{E}[X \\cdot \\mu] = \\mu \\, \\mathbb{E}[X] = \\mu \\cdot \\mu = \\mu^2\\).\n\n\\(\\mathbb{E}\\big(\\mu^2\\big) = \\mu^2\\).\n\n\n\nSostituzione e semplificazione\nRimpiazzando i risultati nel secondo passaggio si ottiene: \\[\n\\mathbb{E}(X^2) \\;-\\; 2\\,\\mu^2 \\;+\\; \\mu^2\n\\;=\\; \\mathbb{E}(X^2) - \\mu^2.\n\\]\nPoich√© \\(\\mu = \\mathbb{E}(X)\\), la varianza pu√≤ quindi essere scritta come:\n\\[\n\\boxed{\n\\mathbb{V}(X) = \\mathbb{E}(X^2) \\;-\\; \\bigl(\\mathbb{E}(X)\\bigr)^2.\n}\n\\tag{33.6}\\]\n\n\n\nQuesta forma risulta molto utile per ragioni di efficienza computazionale: invece di calcolare gli scarti \\((X - \\mu)\\) per ogni osservazione, √® sufficiente trovare \\(\\mathbb{E}(X^2)\\) e poi sottrarre \\(\\mu^2\\). In tal modo si riducono i passaggi intermedi e, di conseguenza, si minimizzano gli errori pratici. Inoltre, nelle dimostrazioni che richiedono manipolazioni algebriche ‚Äì come quelle tipiche della Teoria Classica dei Test ‚Äì questa espressione semplifica notevolmente le trasformazioni.\n\nEsempio 33.8 Consideriamo la variabile casuale \\(X\\) che corrisponde al numero di teste che si osservano nel lancio di una moneta truccata con probabilit√† di testa uguale a 0.8. Si trovi la varianza di \\(Y\\).\nIl valore atteso di \\(X\\) √®\n\\[\n\\mathbb{E}(X) = 0 \\cdot 0.2 + 1 \\cdot 0.8 = 0.8.\n\\]\nUsando la formula tradizionale della varianza otteniamo:\n\\[\n\\mathbb{V}(X) = (0 - 0.8)^2 \\cdot 0.2 + (1 - 0.8)^2 \\cdot 0.8 = 0.16.\n\\]\nLo stesso risultato si trova con la formula alternativa della varianza. Il valore atteso di \\(X^2\\) √®\n\\[\n\\mathbb{E}(X^2) = 0^2 \\cdot 0.2 + 1^2 \\cdot 0.8 = 0.8.\n\\]\ne la varianza diventa\n\\[\n\\mathbb{V}(X) = \\mathbb{E}(X^2) - \\big(\\mathbb{E}(Y) \\big)^2 = 0.8 - 0.8^2 = 0.16.\n\\]\n\n\nEsempio 33.9 Svolgiamo l‚Äôesercizio in R:\n\n# Definire i valori di x e le probabilit√† px\nx &lt;- c(0, 1)\npx &lt;- c(0.2, 0.8)\n\n# Calcolare il risultato\nresult &lt;- sum(x^2 * px) - (sum(x * px))^2\nresult\n#&gt; [1] 0.16\n\n\n\n33.4.3 Propriet√†\nSegno della varianza. La varianza di una variabile aleatoria non √® mai negativa, ed √® zero solamente quando la variabile assume un solo valore.\nInvarianza per traslazione. La varianza √® invariante per traslazione, che lascia fisse le distanze dalla media, e cambia quadraticamente per riscalamento:\n\\[\n\\mathbb{V}(a + bX) = b^2\\mathbb{V}(X).\n\\]\nDimostrazione. Iniziamo a scrivere\n\\[\n(aX+b)-{\\mathbb{E}}[aX+b]=aX+b-a{\\mathbb{E}}[X]-b=a(X-{\\mathbb  {E}}[X]).\n\\]\nQuindi\n\\[\n\\sigma _{{aX+b}}^{2}={\\mathbb{E}}[a^{2}(X-{\\mathbb  {E}}[X])^{2}]=a^{2}\\sigma _{X}^{2}.\n\\]\nEsaminiamo una dimostrazione numerica.\n\n# Definire i valori di x\nx &lt;- c(2, 1, 4, 7)\n\n# Calcolare y\ny &lt;- 100 + 2 * x\n\n# Verificare la relazione tra le varianze\nresult &lt;- var(y) == 2^2 * var(x)\nresult\n#&gt; [1] TRUE\n\nVarianza della somma di due variabili indipendenti. La varianza della somma di due variabili indipendenti o anche solo incorrelate √® pari alla somma delle loro varianze:\n\\[\n\\mathbb{V}(X+Y) = \\mathbb{V}(X) + \\mathbb{V}(Y).\n\\]\nDimostrazione. Se \\(\\mathbb{E}(X) = \\mathbb{E}(Y) = 0\\), allora \\(\\mathbb{E}(X+Y) = 0\\) e\n\\[\\mathbb{V}(X+Y) = \\mathbb{E}((X+Y)^2) = \\mathbb{E}(X^2) + 2 \\mathbb{E}(XY) + \\mathbb{E}(Y^2).\\]\nSiccome le variabili sono indipendenti risulta \\(\\mathbb{E}(XY) = \\mathbb{E}(X)\\mathbb{E}(Y) = 0\\).\nVarianza della differenza di due variabili indipendenti. La varianza della differenza di due variabili indipendenti √® pari alla somma delle loro varianze:\n\\[\n\\mathbb{V}(X-Y) = \\mathbb{V}(X) + \\mathbb{V}(Y).\n\\]\nDimostrazione.\n\\[\n\\mathbb{V}(X-Y) = \\mathbb{V}(X +(-Y)) = \\mathbb{V}(X) + \\mathbb{V}(-Y) = \\mathbb{V}(X) + \\mathbb{V}(Y).\n\\]\nVarianza della somma di due variabili non indipendenti. Se \\(X\\) e \\(Y\\) non sono indipendenti, la formula viene corretta dalla loro covarianza:\n\\[\n\\mathbb{V}(X+Y) = \\mathbb{V}(X) + \\mathbb{V}(Y) + 2 Cov(X,Y),\n\\]\ndove \\(Cov(X,Y) = \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y)\\).\nUna dimostrazione numerica di questo principio √® fornita sotto.\n\n# Definire i valori di x e y\nx &lt;- c(2, 1, 4, 7)\ny &lt;- c(1, 3, 5, 11)\n\n# Calcolare la varianza di x + y con ddof = 0\nvar_x_y &lt;- mean((x + y - mean(x + y))^2)\nvar_x_y\n#&gt; [1] 35.25\n\n\n# Definire i valori di x e y\nx &lt;- c(2, 1, 4, 7)\ny &lt;- c(1, 3, 5, 11)\n\n# Calcolo della varianza combinata\nresult &lt;- mean((x - mean(x))^2) + \n          mean((y - mean(y))^2) + \n          2 * cov(x, y) * (length(x) - 1) / length(x)\nresult\n#&gt; [1] 35.25\n\nVarianza della media di variabili indipendenti. La media aritmetica \\(\\textstyle {\\bar  {X}}={\\frac  {X_{1}+\\ldots +X_{n}}{n}}\\) di \\(n\\) variabili casuali indipendenti aventi la medesima distribuzione, ha varianza\n\\[\n\\mathbb{V}(\\bar{X}) = \\frac{1}{n^2} \\mathbb{V}(X_1)+ \\dots \\mathbb{V}(X_n) = \\frac{1}{n^2} n \\mathbb{V}(X) = \\frac{1}{n} \\mathbb{V}(X).\n\\]\nIl principio precedente √® illustrato dalla seguente simulazione.\n\n# Creare la popolazione\nset.seed(123)  # Per riproducibilit√†\npopulation &lt;- rnorm(10000, mean = 50, sd = 10)\n\n# Definire dimensione del campione e numero di campioni\nsample_size &lt;- 30\nnum_samples &lt;- 100000\n\n# Creare un vettore per memorizzare le medie campionarie\nsample_means &lt;- numeric(num_samples)\n\n# Generare i campioni e calcolare le medie\nfor (i in 1:num_samples) {\n  sample &lt;- sample(population, size = sample_size, replace = TRUE)\n  sample_means[i] &lt;- mean(sample)\n}\n\n# Calcolare la varianza delle medie campionarie\nsampling_dist_mean_var &lt;- var(sample_means) * ((num_samples - 1) / num_samples)  # ddof = 0\nsampling_dist_mean_var\n#&gt; [1] 3.331\n\nIl valore teorico della varianza della distribuzione campionaria della media √®\n\n10^2 / 30\n#&gt; [1] 3.333\n\n\n33.4.4 Variabili casuali continue\nPer una variabile casuale continua \\(X\\), la varianza √® definita come:\n\\[\n\\mathbb{V}(X) = \\int_{-\\infty}^{+\\infty} \\large[x - \\mathbb{E}(X)\\large]^2 p(x) \\,\\operatorname {d}\\!x.\n\\tag{33.7}\\]\nAnalogamente al caso discreto, la varianza di una variabile casuale continua \\(X\\) una misura della dispersione, ovvero la ‚Äúdistanza‚Äù media quadratica attesa dei valori \\(x\\) rispetto alla loro media \\(\\mathbb{E}(X)\\). In altre parole, la varianza quantifica quanto i valori della variabile casuale si discostano tipicamente dal loro valore medio.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_expval_var.html#deviazione-standard",
    "href": "chapters/probability/09_expval_var.html#deviazione-standard",
    "title": "33¬† Propriet√† delle variabili casuali",
    "section": "\n33.5 Deviazione Standard",
    "text": "33.5 Deviazione Standard\nQuando si lavora con le varianze, i valori sono elevati al quadrato, il che pu√≤ rendere i numeri significativamente pi√π grandi (o pi√π piccoli) rispetto ai dati originali. Per riportare questi valori all‚Äôunit√† di misura della scala originale, si prende la radice quadrata della varianza. Il risultato ottenuto √® chiamato deviazione standard ed √® comunemente indicato con la lettera greca \\(\\sigma\\).\n\nDefinizione 33.3 La deviazione standard, o scarto quadratico medio, √® definita come la radice quadrata della varianza:\n\\[\n\\sigma_X = \\sqrt{\\mathbb{V}(X)}.\n\\tag{33.8}\\]\n\nCome nella statistica descrittiva, la deviazione standard di una variabile casuale fornisce una misura della dispersione, ossia la ‚Äúdistanza‚Äù tipica o prevista dei valori \\(x\\) rispetto alla loro media.\n\nEsempio 33.10 Per i dadi equilibrati dell‚Äôesempio precedente, la deviazione standard della variabile casuale \\(S\\) √® pari a \\(\\sqrt{5.833} = 2.415\\). Questo valore indica quanto i risultati della somma dei due dadi tendono a variare attorno alla loro media.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_expval_var.html#standardizzazione",
    "href": "chapters/probability/09_expval_var.html#standardizzazione",
    "title": "33¬† Propriet√† delle variabili casuali",
    "section": "\n33.6 Standardizzazione",
    "text": "33.6 Standardizzazione\n\nDefinizione 33.4 Data una variabile casuale \\(X\\), si dice variabile standardizzata di \\(X\\) l‚Äôespressione\n\\[\nZ = \\frac{X - \\mathbb{E}(X)}{\\sigma_X}.\n\\tag{33.9}\\]\n\nSolitamente, una variabile standardizzata viene denotata con la lettera \\(Z\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_expval_var.html#il-teorema-di-chebyshev",
    "href": "chapters/probability/09_expval_var.html#il-teorema-di-chebyshev",
    "title": "33¬† Propriet√† delle variabili casuali",
    "section": "\n33.7 Il Teorema di Chebyshev",
    "text": "33.7 Il Teorema di Chebyshev\nIl Teorema di Chebyshev ci permette di stimare la probabilit√† che una variabile aleatoria si discosti dal suo valore atteso (media) di una certa quantit√†. In altre parole, ci fornisce un limite superiore alla probabilit√† che una variabile aleatoria assuma valori ‚Äúestremi‚Äù.\nIl teorema di Chebyshev afferma che, per qualsiasi variabile aleatoria X con media E(X) e varianza Var(X), e per qualsiasi numero reale k &gt; 0, si ha:\n\\[\nP(\\mid X - E(X)\\mid \\geq k \\sigma) \\leq 1/k^2,\n\\tag{33.10}\\]\ndove:\n\n\n\\(P(\\mid X - E(X)\\mid \\geq k \\sigma)\\) √® la probabilit√† che lo scarto assoluto tra X e la sua media sia maggiore o uguale a k volte la deviazione standard (œÉ).\nœÉ √® la radice quadrata della varianza, ovvero la deviazione standard.\n\nCosa ci dice questo teorema?\n\n\nLimite superiore: Il teorema ci fornisce un limite superiore alla probabilit√† che una variabile aleatoria si discosti dalla sua media di pi√π di k deviazioni standard.\n\nQualsiasi distribuzione: La bellezza di questo teorema √® che vale per qualsiasi distribuzione di probabilit√†, a patto che la media e la varianza esistano.\n\nUtilizzo: Il teorema di Chebyshev √® molto utile quando non conosciamo la distribuzione esatta di una variabile aleatoria, ma conosciamo la sua media e la sua varianza.\n\nIn sintesi, il teorema di Chebyshev ci fornisce un limite superiore alla probabilit√† che una variabile aleatoria si discosti dalla sua media di una certa quantit√†, in base alla sua varianza. Il teorema di Chebyshev ci permette quindi di fare inferenze sulla distribuzione di una variabile aleatoria anche quando abbiamo informazioni limitate.\n\nEsempio 33.11 Supponiamo di avere una variabile aleatoria \\(X\\) con media 100 e varianza 25. Vogliamo stimare la probabilit√† che \\(X\\) assuma valori al di fuori dell‚Äôintervallo [90, 110].\nIn questo caso, \\(k\\) = 2 (poich√© 10 √® uguale a 2 volte la deviazione standard, che √® 5). Applicando il teorema di Chebyshev, otteniamo:\n\\[\nP(\\mid X - 100 \\mid \\geq 10) \\leq \\left( \\frac{1}{2} \\right)^2 = 0.25\n\\]\nQuindi, possiamo affermare con certezza che al massimo il 25% dei valori di X saranno al di fuori dell‚Äôintervallo [90, 110].",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_expval_var.html#momenti-di-variabili-casuali",
    "href": "chapters/probability/09_expval_var.html#momenti-di-variabili-casuali",
    "title": "33¬† Propriet√† delle variabili casuali",
    "section": "\n33.8 Momenti di variabili casuali",
    "text": "33.8 Momenti di variabili casuali\n\nDefinizione 33.5 Si chiama momento di ordine \\(q\\) di una v.c. \\(X\\), dotata di densit√† \\(p(x)\\), la quantit√†\n\\[\n\\mathbb{E}(X^q) = \\int_{-\\infty}^{+\\infty} x^q p(x) \\; dx.\n\\tag{33.11}\\]\nSe \\(X\\) √® una v.c. discreta, i suoi momenti valgono:\n\\[\n\\mathbb{E}(X^q) = \\sum_i x_i^q P(x_i),\n\\tag{33.12}\\]\ndove:\n\n\n\\(E(X^q)\\) rappresenta il valore atteso di \\(X\\) elevato alla \\(q\\)-esima potenza.\n\n\\(x_i\\) sono i possibili valori della variabile discreta.\n\n\\(P(x_i)\\) √® la probabilit√† associata a ciascun valore discreto.\n\n\nI momenti sono parametri statistici che forniscono informazioni importanti sulle caratteristiche di una variabile casuale. Tra questi, i pi√π noti e utilizzati sono:\n\nIl momento del primo ordine (\\(q\\) = 1): corrisponde al valore atteso (o media) della variabile casuale \\(X\\).\nIl momento del secondo ordine (\\(q\\) = 2): quando calcolato rispetto alla media, corrisponde alla varianza.\n\nPer i momenti di ordine superiore al primo, √® comune calcolarli rispetto al valore medio di \\(X\\). Questo si ottiene applicando una traslazione: \\(x_0 = x ‚àí \\mathbb{E}(X)\\), dove \\(x_0\\) rappresenta lo scarto dalla media. In particolare, il momento centrale del secondo ordine, calcolato con questa traslazione, corrisponde alla definizione di varianza.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_expval_var.html#alcuni-esempi-in-r",
    "href": "chapters/probability/09_expval_var.html#alcuni-esempi-in-r",
    "title": "33¬† Propriet√† delle variabili casuali",
    "section": "\n33.9 Alcuni esempi in R",
    "text": "33.9 Alcuni esempi in R\nIn R, possiamo calcolare il valore atteso e la varianza di variabili casuali discrete utilizzando vettori di valori e probabilit√†.\nConsideriamo una variabile casuale \\(X\\) che rappresenta i valori ottenuti dal lancio di un dado non equilibrato, con valori possibili da 0 a 6, e con la seguente distribuzione di massa di probabilit√†: 0.1, 0.2, 0.3, 0.1, 0.1, 0.0, 0.2.\nIniziamo a definire un vettore che contiene i valori della v.c.:\n\nx &lt;- 0:6\nprint(x)\n#&gt; [1] 0 1 2 3 4 5 6\n\nIl vettore px conterr√† le probabilit√† associate ai valori x:\n\npx &lt;- c(0.1, 0.2, 0.3, 0.1, 0.1, 0.0, 0.2)\nprint(px)\n#&gt; [1] 0.1 0.2 0.3 0.1 0.1 0.0 0.2\n\nControlliamo che la somma sia 1:\n\nsum(px)\n#&gt; [1] 1\n\nCalcoliamo il valore atteso di \\(X\\) implementando la formula del valore atteso utilizzando i vettori x e px:\n\nx_ev &lt;- sum(x * px)\nx_ev\n#&gt; [1] 2.7\n\nCalcoliamo la varianza di \\(X\\) usando i vettori x e px:\n\nx_var &lt;- sum((x - x_ev)^2 * px)\nx_var\n#&gt; [1] 3.81\n\nCalcoliamo la deviazione standard di \\(X\\) prendendo la radice quadrata della varianza:\n\nx_sd &lt;- sqrt(x_var)\nx_sd\n#&gt; [1] 1.952\n\nPer rappresentare graficamente la distribuzione di massa, possiamo usare ggplot2:\n\ndf &lt;- data.frame(x = x, pmf = px)\nggplot(df, aes(x = x, y = pmf)) +\n  geom_point(color = \"#832F2B\", size = 3) +\n  geom_segment(aes(xend = x, yend = 0), linewidth = 1) +\n  labs(title = \"Distribuzione di massa di probabilit√†\", \n       x = \"Valori\", y = \"Probabilit√†\")\n\n\n\n\n\n\n\nQuesto codice calcola il valore atteso, la varianza e la deviazione standard di una variabile casuale discreta e rappresenta graficamente la distribuzione di massa, tutto in R.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_expval_var.html#riflessioni-conclusive",
    "href": "chapters/probability/09_expval_var.html#riflessioni-conclusive",
    "title": "33¬† Propriet√† delle variabili casuali",
    "section": "\n33.11 Riflessioni Conclusive",
    "text": "33.11 Riflessioni Conclusive\nIn conclusione, i concetti di valore atteso e varianza sono fondamentali per comprendere il comportamento delle variabili casuali. Il valore atteso fornisce una misura centrale, rappresentando il ‚Äúvalore tipico‚Äù che ci si aspetta di osservare, mentre la varianza quantifica la dispersione dei valori attorno a questa media, offrendo una visione pi√π completa della distribuzione. Questi strumenti sono essenziali per l‚Äôanalisi e la modellizzazione statistica, fornendo le basi per valutare e interpretare la variabilit√† nei fenomeni aleatori.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_expval_var.html#esercizi",
    "href": "chapters/probability/09_expval_var.html#esercizi",
    "title": "33¬† Propriet√† delle variabili casuali",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nEsercizio 1: Calcolo del Valore Atteso per Variabili Discrete\nUtilizzando i dati raccolti dagli studenti sulla SWLS, calcola il valore atteso della soddisfazione con la vita (\\(X\\)). Organizza i dati come nell‚Äôesempio seguente e interpretalo come se fosse la distribuzione di probabilit√† nella popolazione:\n\n\nSWLS Score\nProbabilit√† \\(P(X)\\)\n\n\n\n\n5\n0.05\n\n\n10\n0.10\n\n\n15\n0.20\n\n\n20\n0.30\n\n\n25\n0.20\n\n\n30\n0.10\n\n\n35\n0.05\n\n\n\n\nCalcola il valore atteso di \\(X\\), \\(\\mathbb{E}(X)\\).\nInterpreta il risultato ottenuto.\n\nEsercizio 2: Varianza e Deviazione Standard\nData la stessa distribuzione della SWLS utilizzata nell‚Äôesercizio precedente:\n\nCalcola la varianza \\(\\mathbb{V}(X)\\).\nCalcola la deviazione standard \\(\\sigma_X\\).\nCommenta il significato della dispersione dei valori rispetto alla media.\n\nEsercizio 3: Propriet√† del Valore Atteso\nUtilizzando la distribuzione della LSNS-6:\n\nDefinisci una nuova variabile casuale \\(Y = 2X + 3\\).\nCalcola il valore atteso di \\(Y\\), \\(\\mathbb{E}(Y)\\), utilizzando la linearit√† dell‚Äôoperatore di aspettazione.\nVerifica il risultato calcolando direttamente \\(\\mathbb{E}(Y)\\) dalla distribuzione di probabilit√† di \\(Y\\).\n\nUtilizza una distribuzione della LSNS-6 organizzata come segue (sostituisci i valori presenti con quelli del campione):\n\n\nLSNS-6 Score\nProbabilit√† \\(P(Y)\\)\n\n\n\n\n5\n0.10\n\n\n10\n0.15\n\n\n15\n0.25\n\n\n20\n0.25\n\n\n25\n0.15\n\n\n30\n0.10\n\n\n\nEsercizio 4: Applicazione del Teorema di Chebyshev\nSia la soddisfazione con la vita (SWLS) distribuita con media \\(\\mu = 3.2\\) e deviazione standard \\(\\sigma = 0.8\\).\n\nUsa il teorema di Chebyshev per trovare un limite superiore alla probabilit√† che un valore di SWLS sia oltre due deviazioni standard dalla media.\nConfronta questo risultato con la probabilit√† empirica calcolata utilizzando i dati raccolti.\n\nEsercizio 5: Standardizzazione e Distribuzione Normale\n# Definizione dei dati osservati della LSNS-6 (sostituisci con i dati reali se disponibili)\nlsns6_scores &lt;- c(5, 8, 10, 12, 15, 18, 20, 22, 25, 28)\n\n# Parametri della distribuzione\nmu &lt;- 12   # Media della LSNS-6\nsigma &lt;- 4  # Deviazione standard della LSNS-6\n\n# Standardizzazione dei valori osservati\nz_scores &lt;- (lsns6_scores - mu) / sigma\n\n# Creazione dell'istogramma della distribuzione standardizzata\nhist(z_scores, \n     breaks = 10, \n     col = \"lightblue\", \n     main = \"Istogramma della distribuzione standardizzata di LSNS-6\", \n     xlab = \"Z-score\", \n     ylab = \"Frequenza\",\n     probability = TRUE)\n\n# Sovrapposizione della curva normale standard\ncurve(dnorm(x, mean = 0, sd = 1), col = \"red\", lwd = 2, add = TRUE)\n\nStandardizzazione: La trasformazione dei punteggi della LSNS-6 in Z-score permette di esprimere ogni valore in termini di deviazioni standard rispetto alla media. Un valore \\(Z = 1\\) significa che il punteggio di LSNS-6 √® una deviazione standard sopra la media, mentre \\(Z = -1\\) significa che √® una deviazione standard sotto la media.\nIstogramma della distribuzione standardizzata: Il grafico mostra la distribuzione dei punteggi standardizzati. Se la distribuzione originale √® simile a una normale, l‚Äôistogramma dei punteggi standardizzati dovrebbe assomigliare a una distribuzione normale standard.\nConfronto con la distribuzione normale standard: La curva rossa rappresenta la densit√† di una normale standard (\\(\\mathcal{N}(0,1)\\)). Se i dati sono approssimativamente normali, l‚Äôistogramma dei punteggi standardizzati dovrebbe seguire la forma della curva normale standard. Differenze marcate potrebbero indicare asimmetria o curtosi anomale nella distribuzione dei punteggi LSNS-6.\n\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\nEsercizio 1: Calcolo del Valore Atteso della SWLS\nLa Satisfaction With Life Scale (SWLS) √® composta da 5 item, ciascuno valutato su una scala Likert da 1 a 7. Supponiamo di avere la seguente distribuzione di probabilit√† per il punteggio totale della SWLS basata su un campione di studenti:\n\n\nSWLS Score\nProbabilit√† \\(P(X)\\)\n\n\n\n\n5\n0.05\n\n\n10\n0.10\n\n\n15\n0.20\n\n\n20\n0.30\n\n\n25\n0.20\n\n\n30\n0.10\n\n\n35\n0.05\n\n\n\nDomanda:\nCalcola il valore atteso \\(\\mathbb{E}[X]\\) del punteggio SWLS.\nSoluzione: Il valore atteso si calcola come:\n\\[\n\\mathbb{E}[X] = \\sum x_i P(x_i)\n\\]\nCalcoliamo in R:\n# Definizione dei valori SWLS e delle probabilit√†\nswls_scores &lt;- c(5, 10, 15, 20, 25, 30, 35)\nprob_swls &lt;- c(0.05, 0.10, 0.20, 0.30, 0.20, 0.10, 0.05)\n\n# Calcolo del valore atteso\nexpected_swls &lt;- sum(swls_scores * prob_swls)\nexpected_swls\nRisultato:\\[\n\\mathbb{E}[X] = 20\n\\]\nIl valore atteso rappresenta la media teorica della soddisfazione con la vita nella popolazione, assumendo che la distribuzione dei punteggi SWLS segua esattamente le probabilit√† fornite. In altre parole, se prendessimo un numero molto grande di individui con questa distribuzione di probabilit√†, il punteggio medio atteso sarebbe 20. Questo suggerisce che, nella popolazione considerata, il livello medio di soddisfazione con la vita si colloca al centro della scala SWLS.\nEsercizio 2: Calcolo della Varianza e Deviazione Standard della SWLS\n# Definizione dei dati\nswls_scores &lt;- c(5, 10, 15, 20, 25, 30, 35)\nprobabilities &lt;- c(0.05, 0.10, 0.20, 0.30, 0.20, 0.10, 0.05)\n\n# Calcolo del valore atteso (media attesa)\nexpected_value &lt;- sum(swls_scores * probabilities)\n\n# Calcolo della varianza\nvariance &lt;- sum((swls_scores - expected_value)^2 * probabilities)\n\n# Calcolo della deviazione standard\nstd_deviation &lt;- sqrt(variance)\n\n# Stampa dei risultati\ncat(\"Valore atteso (E[X]):\", expected_value, \"\\n\")\ncat(\"Varianza (Var[X]):\", variance, \"\\n\")\ncat(\"Deviazione standard (œÉ_X):\", std_deviation, \"\\n\")\n\n\nVarianza: Misura la dispersione dei punteggi SWLS rispetto alla media attesa. Se la varianza √® alta, significa che i punteggi sono molto variabili; se √® bassa, significa che i punteggi sono pi√π concentrati attorno al valore atteso.\n\nDeviazione standard: √à la radice quadrata della varianza e ha la stessa unit√† di misura dei dati originali. Fornisce un‚Äôindicazione della dispersione media dei punteggi rispetto alla media.\n\nSe la deviazione standard √® elevata, significa che nella popolazione ci sono sia individui con livelli di soddisfazione molto bassi sia individui con livelli molto alti. Se √® bassa, i punteggi sono pi√π omogenei intorno alla media.\nEsercizio 3: Calcolo del Valore Atteso della Scala della Rete Sociale di Lubben (LSNS-6)\n# Definizione dei dati della LSNS-6\nlsns_scores &lt;- c(5, 10, 15, 20, 25, 30)\nprobabilities &lt;- c(0.10, 0.15, 0.25, 0.25, 0.15, 0.10)\n\n# Definizione della trasformazione della variabile casuale Y = 2X + 3\ny_values &lt;- 2 * lsns_scores + 3\n\n# Calcolo del valore atteso di X\nexpected_x &lt;- sum(lsns_scores * probabilities)\n\n# Utilizzo della linearit√† dell'operatore di aspettazione: E[Y] = 2E[X] + 3\nexpected_y_from_x &lt;- 2 * expected_x + 3\n\n# Calcolo diretto del valore atteso di Y\nexpected_y_direct &lt;- sum(y_values * probabilities)\n\n# Stampa dei risultati\ncat(\"Valore atteso di X (E[X]):\", expected_x, \"\\n\")\ncat(\"Valore atteso di Y calcolato con la linearit√† (E[Y] = 2E[X] + 3):\", expected_y_from_x, \"\\n\")\ncat(\"Valore atteso di Y calcolato direttamente dalla distribuzione di probabilit√† di Y:\", expected_y_direct, \"\\n\")\n\n\nLinearit√† dell‚Äôoperatore di aspettazione: Questo principio afferma che se una variabile casuale \\(X\\) viene trasformata linearmente in \\(Y = aX + b\\), allora il valore atteso di \\(Y\\) √® dato da:\n\\[\n\\mathbb{E}(Y) = a \\mathbb{E}(X) + b\n\\]\nQuesto semplifica il calcolo senza dover ridefinire una nuova distribuzione di probabilit√†.\n\nVerifica del risultato: Dopo aver calcolato \\(\\mathbb{E}(Y)\\) con la propriet√† di linearit√†, lo confrontiamo con il calcolo diretto utilizzando la distribuzione trasformata. Se i due valori coincidono, confermiamo che la propriet√† di linearit√† √® rispettata.\nSignificato pratico: La trasformazione lineare di una variabile casuale pu√≤ rappresentare un‚Äôoperazione reale come la conversione di punteggi da una scala all‚Äôaltra. Il valore atteso si comporta linearmente, il che √® utile per interpretare trasformazioni senza dover ricalcolare completamente la distribuzione.\n\nEsercizio 4: Probabilit√† secondo il Teorema di Chebyshev\nIl Teorema di Chebyshev afferma che per qualsiasi distribuzione, la probabilit√† che un valore sia oltre \\(k\\) deviazioni standard dalla media √® al massimo:\n\\[\nP(|X - \\mu| \\geq k\\sigma) \\leq \\frac{1}{k^2}\n\\]\nSostituendo \\(k = 2\\):\n\\[\nP(|X - 3.2| \\geq 2 \\cdot 0.8) \\leq \\frac{1}{2^2} = \\frac{1}{4} = 0.25\n\\]\nQuindi, il Teorema di Chebyshev fornisce un limite superiore del 25% alla probabilit√† che un valore di SWLS sia oltre due deviazioni standard dalla media.\nPer confrontare questo risultato con la probabilit√† empirica, √® necessaro usare i dati raccolti sulla SWLS.\nEsercizio 5: Standardizzazione del Punteggio LSNS-6\nDomanda:\nStandardizza il punteggio LSNS-6 trasformandolo nella variabile standardizzata \\(Z\\).\n\\[\nZ = \\frac{Y - \\mathbb{E}(Y)}{\\sigma_Y}\n\\]\nSoluzione: Calcoliamo in R:\n# Standardizzazione dei punteggi LSNS-6\nz_lsns &lt;- (lsns_scores - expected_lsns) / sd_lsns\nz_lsns\nRisultato:\n\n\nLSNS-6 Score\nZ-Score\n\n\n\n5\n-2.23\n\n\n10\n-1.34\n\n\n15\n-0.45\n\n\n20\n0.45\n\n\n25\n1.34\n\n\n30\n2.23\n\n\n\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nEsercizio 6: Personalizzazione degli Interventi Basati sulla Probabilit√† Condizionata\nUno psicologo scolastico vuole identificare quali studenti potrebbero trarre maggiore beneficio da un programma di supporto psicologico. Dalla letteratura, si sa che la probabilit√† di avere livelli bassi di soddisfazione con la vita (SWLS ‚â§ 15) √® pi√π alta tra gli studenti che riportano elevati livelli di stress accademico.\nDai dati raccolti su un campione di studenti:\n\n\\(P(\\text{SWLS} \\leq 15) = 0.35\\)\n\\(P(\\text{Stress Alto}) = 0.40\\)\n\\(P(\\text{SWLS} \\leq 15 \\mid \\text{Stress Alto}) = 0.60\\)\n\nDomanda Se uno studente √® scelto a caso, qual √® la probabilit√† che abbia un alto livello di stress dato che il suo punteggio SWLS √® ‚â§ 15?\nEsercizio 7: Prevedere il Successo di un Intervento Psicologico Uno psicologo clinico sta valutando l‚Äôefficacia di un intervento sulla riduzione dell‚Äôansia. Ha raccolto i dati di 100 pazienti e ha osservato che il miglioramento medio nei punteggi di ansia (misurati con DASS-21) √® di 5 punti con una deviazione standard di 2.5.\nSupponiamo che il miglioramento sia una variabile aleatoria normale con media 5 e deviazione standard 2.5.\nDomanda Qual √® la probabilit√† che un paziente scelto a caso migliori di almeno 7 punti?\nEsercizio 8: Allocazione Ottimale delle Risorse in un Programma di Prevenzione Uno psicologo organizza un programma di sensibilizzazione sulla salute mentale in diverse scuole. Ha raccolto dati sulla frequenza con cui gli studenti si rivolgono allo sportello di ascolto, con la seguente distribuzione:\n\n\nNumero di Visite\nProbabilit√†\n\n\n\n0\n0.40\n\n\n1\n0.30\n\n\n2\n0.15\n\n\n3+\n0.15\n\n\n\nDomanda Se lo psicologo ha risorse per organizzare colloqui individuali solo per il 30% degli studenti, quale soglia pu√≤ usare per selezionare gli studenti pi√π bisognosi in base alla distribuzione delle visite?\nEsercizio 9: Misurare la Variabilit√† della Risposta a un Trattamento Uno psicologo somministra un trattamento per la depressione e misura la variazione nei punteggi di depressione su un campione di pazienti prima e dopo l‚Äôintervento.\nLe variazioni seguono questa distribuzione:\n\n\nŒî Punteggio DASS-21\nProbabilit√†\n\n\n\n-10\n0.10\n\n\n-5\n0.20\n\n\n0\n0.40\n\n\n+5\n0.20\n\n\n+10\n0.10\n\n\n\nDomanda Qual √® la deviazione standard della variazione nei punteggi di depressione?\nEsercizio 10: Probabilit√† di un Fallimento in un Programma di Sensibilizzazione Uno psicologo organizza un programma per ridurre il pregiudizio sulla salute mentale. Dai dati precedenti, la probabilit√† di successo di ogni evento di sensibilizzazione √® del 70%. Se organizza 5 eventi indipendenti, qual √® la probabilit√† che almeno 1 fallisca?\n\n\n\n\n\n\n\n\n\nSoluzioni 2\n\n\n\n\n\nEsercizio 6: Personalizzazione degli Interventi Basati sulla Probabilit√† Condizionata\nUtilizziamo la formula della probabilit√† condizionata:\n\\[\nP(\\text{Stress Alto} \\mid \\text{SWLS} \\leq 15) = \\frac{P(\\text{SWLS} \\leq 15 \\mid \\text{Stress Alto}) P(\\text{Stress Alto})}{P(\\text{SWLS} \\leq 15)}\n\\]\nCalcoliamo in R:\np_swls_low &lt;- 0.35\np_stress_high &lt;- 0.40\np_swls_given_stress &lt;- 0.60\n\np_stress_given_swls &lt;- (p_swls_given_stress * p_stress_high) / p_swls_low\np_stress_given_swls\nRisultato Lo psicologo pu√≤ usare questa informazione per identificare studenti con alta probabilit√† di avere stress elevato, anche se non hanno segnalato direttamente il problema, e offrire supporto mirato.\nEsercizio 7: Prevedere il Successo di un Intervento Psicologico\nUsiamo la normalizzazione:\n\\[\nZ = \\frac{X - \\mu}{\\sigma}\n\\]\ne calcoliamo la probabilit√† corrispondente:\nmean_improvement &lt;- 5\nsd_improvement &lt;- 2.5\nthreshold &lt;- 7\n\np_improve_7 &lt;- 1 - pnorm(threshold, mean = mean_improvement, sd = sd_improvement)\np_improve_7\nRisultato Questo aiuta lo psicologo a comunicare ai pazienti la probabilit√† di ottenere miglioramenti significativi e ad adattare le aspettative dell‚Äôintervento.\nEsercizio 8: Allocazione Ottimale delle Risorse in un Programma di Prevenzione\nSoluzione Calcoliamo la probabilit√† cumulativa:\nvisits &lt;- c(0, 1, 2, 3)\nprobabilities &lt;- c(0.40, 0.30, 0.15, 0.15)\ncumulative_prob &lt;- cumsum(probabilities)\n\n# Determinare la soglia per il 30% pi√π bisognoso\nthreshold &lt;- visits[min(which(cumulative_prob &gt;= 0.70))]\nthreshold\nRisultato Lo psicologo pu√≤ decidere di offrire supporto prioritario a studenti con almeno 2 visite, massimizzando l‚Äôimpatto con risorse limitate.\nEsercizio 9: Misurare la Variabilit√† della Risposta a un Trattamento\nSoluzione Calcoliamo la varianza e la deviazione standard:\nscore_changes &lt;- c(-10, -5, 0, 5, 10)\nprobabilities &lt;- c(0.10, 0.20, 0.40, 0.20, 0.10)\n\n# Media attesa\nexpected_change &lt;- sum(score_changes * probabilities)\n\n# Varianza\nvariance_change &lt;- sum((score_changes - expected_change)^2 * probabilities)\n\n# Deviazione standard\nsd_change &lt;- sqrt(variance_change)\nsd_change\nRisultato Se la deviazione standard √® grande, significa che l‚Äôeffetto del trattamento √® molto variabile e potrebbero essere necessarie strategie personalizzate.\nEsercizio 10: Probabilit√† di un Fallimento in un Programma di Sensibilizzazione\nUsiamo la distribuzione binomiale:\np_success &lt;- 0.70\nn_events &lt;- 5\n\np_failure_at_least_one &lt;- 1 - dbinom(5, n_events, p_success)\np_failure_at_least_one\nRisultato Lo psicologo pu√≤ pianificare strategie di miglioramento sapendo la probabilit√† di un fallimento.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_expval_var.html#esercizi-1",
    "href": "chapters/probability/09_expval_var.html#esercizi-1",
    "title": "33¬† Propriet√† delle variabili casuali",
    "section": "\n33.12 Esercizi",
    "text": "33.12 Esercizi\nConsiglio gli esercizi di base disponibili nella seguente pagina web.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_expval_var.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/09_expval_var.html#informazioni-sullambiente-di-sviluppo",
    "title": "33¬† Propriet√† delle variabili casuali",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.5.3     \n#&gt;  [9] scales_1.3.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.9.1   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         rlang_1.1.5       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       tools_4.4.2       parallel_4.4.2    tzdb_0.5.0       \n#&gt; [21] colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5       R6_2.6.1         \n#&gt; [25] lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.1    \n#&gt; [29] gtable_0.3.6      glue_1.8.0        xfun_0.51         tidyselect_1.2.1 \n#&gt; [33] rstudioapi_0.17.1 farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-167     \n#&gt; [37] labeling_0.4.3    rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_expval_var.html#bibliografia",
    "href": "chapters/probability/09_expval_var.html#bibliografia",
    "title": "33¬† Propriet√† delle variabili casuali",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nChan, J. C. C., & Kroese, D. P. (2025). Statistical Modeling and Computation (2¬™ ed.). Springer.\n\n\nHacking, I. (2006). The emergence of probability: A philosophical study of early ideas about probability, induction and statistical inference. Cambridge University Press.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:\n\n\nWixted, J. T., & Mickes, L. (2010). A continuous dual-process model of remember/know judgments. Psychological Review, 117(4), 1025‚Äì1054.\n\n\nYonelinas, A. P. (2002). The nature of recollection and familiarity: A review of 30 years of research. Journal of Memory and Language, 46(3), 441‚Äì517.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_sampling_distr.html",
    "href": "chapters/probability/10_sampling_distr.html",
    "title": "34¬† Stime, stimatori e parametri",
    "section": "",
    "text": "34.1 Introduzione\nIn psicologia ‚Äì come in molte altre discipline ‚Äì ci si trova spesso nella situazione di voler comprendere una particolare caratteristica di un‚Äôintera popolazione. Tuttavia, difficilmente √® possibile raccogliere dati da tutti i membri di tale popolazione, a causa di limiti di tempo, risorse o accessibilit√†. Ad esempio, potremmo voler stimare la percentuale di persone che soffrono di un determinato disturbo d‚Äôansia oppure la media di un punteggio di memoria a breve termine, ma non siamo in grado di testare ogni singolo individuo appartenente al gruppo di interesse. Per far fronte a questo limite, si sceglie di selezionare un campione di partecipanti (idealmente in modo casuale), dal quale si ricavano le informazioni utili a inferire la caratteristica dell‚Äôintera popolazione, riconoscendo un certo grado di incertezza.\nNel linguaggio statistico:\nCome esempio, immaginiamo di voler conoscere la proporzione di adulti che manifestano un certo sintomo d‚Äôansia, indicandola con \\(p\\). Poich√© non possiamo (o non vogliamo) esaminare tutta la popolazione, estraiamo un campione casuale di \\(N\\) individui, verifichiamo quanti di loro presentino il sintomo e calcoliamo:\n\\[\n\\hat{p} = \\frac{\\text{numero di individui con il sintomo}}{N}.\n\\]\nQuesto rapporto (detto stima campionaria di \\(p\\)) difficilmente coincider√† esattamente con \\(p\\), ma la teoria probabilistica mostra che, in assenza di distorsioni sistematiche, \\(\\hat{p}\\) tender√† ad avvicinarsi al valore reale al crescere della dimensione del campione.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_sampling_distr.html#introduzione",
    "href": "chapters/probability/10_sampling_distr.html#introduzione",
    "title": "34¬† Stime, stimatori e parametri",
    "section": "",
    "text": "Popolazione: l‚Äôinsieme completo degli individui (o unit√†) di interesse. Esempi: tutte le persone che soddisfano certi criteri diagnostici, tutti gli studenti di una scuola, tutte le misurazioni di reazione a uno stimolo sperimentale.\n\nParametro: la quantit√† (sconosciuta) che descrive la caratteristica d‚Äôinteresse nella popolazione (esempio: la ‚Äúvera‚Äù proporzione di soggetti con un certo disturbo, oppure la ‚Äúvera‚Äù media di un test cognitivo).\n\nCampione: un sottoinsieme di individui (idealmente estratto in modo casuale) dalla popolazione di interesse.\n\nStima: il valore numerico, calcolato sul campione, che approssima il parametro.\n\nStimatore: la regola o funzione matematica con cui, a partire dai dati del campione, si ottiene la stima.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_sampling_distr.html#popolazione-e-campione",
    "href": "chapters/probability/10_sampling_distr.html#popolazione-e-campione",
    "title": "34¬† Stime, stimatori e parametri",
    "section": "\n34.2 Popolazione e campione",
    "text": "34.2 Popolazione e campione\nPer rendere tutto pi√π concreto, supponiamo di voler stimare la frequenza di un sintomo ansioso in un‚Äôampia popolazione, ad esempio l‚Äôinsieme di tutti gli studenti universitari di un paese. Non potendo sottoporre un questionario a ogni studente, scegliamo un sottoinsieme di individui in modo casuale (cio√® il nostro campione) e a ciascuno somministriamo uno strumento standardizzato volto a rilevare la presenza/assenza del sintomo. Il nostro obiettivo finale √® utilizzare i dati campionari per trarre inferenze sulla popolazione complessiva, cio√® per stimare la vera proporzione \\(p\\) di studenti che manifestano il sintomo.\nQuesta operazione di estrarre un sottogruppo rappresentativo si chiama campionamento. La proporzione di individui con il sintomo d‚Äôansia calcolata nel campione √® la nostra stima campionaria (simbolizzata con \\(\\bar{X}\\) o, pi√π spesso in contesto di proporzioni, con \\(\\hat{p}\\)). Se il campione √® selezionato in modo corretto e rappresentativo, ci aspettiamo che \\(\\bar{X}\\) rispecchi, con un certo margine di errore, il vero valore di \\(p\\) (il parametro).\n\n34.2.1 Lo stimatore: la proporzione campionaria\nPer formalizzare ulteriormente, consideriamo un modello ‚Äúurna‚Äù in cui la popolazione √® immaginata come un‚Äôurna piena di ‚Äúbiglie‚Äù di due colori (ad esempio, ‚Äúblu‚Äù per sintomo presente, ‚Äúrosso‚Äù per sintomo assente). Estraendo a caso \\(N\\) biglie (cio√® selezionando \\(N\\) soggetti), definiamo la variabile casuale \\(X_i\\) come:\n\\[\nX_i =\n\\begin{cases}\n1 & \\text{se l‚Äôindividuo } i \\text{ presenta il sintomo (biglia blu),}\\\\\n0 & \\text{se l‚Äôindividuo } i \\text{ non presenta il sintomo (biglia rossa).}\n\\end{cases}\n\\]\nLa proporzione campionaria ‚Äì ossia la nostra stima empirica di \\(p\\) ‚Äì √® data da:\n\\[\n\\bar{X} \\;=\\; \\frac{1}{N}\\sum_{i=1}^N X_i.\n\\]\nDal punto di vista interpretativo:\n\n\n\\(p\\) √® la vera proporzione di studenti (biglie ‚Äúblu‚Äù) nella popolazione;\n\n\\(\\bar{X}\\) √® la proporzione di studenti con il sintomo riscontrata nel campione.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_sampling_distr.html#distribuzione-campionaria-valore-atteso-e-varianza",
    "href": "chapters/probability/10_sampling_distr.html#distribuzione-campionaria-valore-atteso-e-varianza",
    "title": "34¬† Stime, stimatori e parametri",
    "section": "\n34.3 Distribuzione campionaria: valore atteso e varianza",
    "text": "34.3 Distribuzione campionaria: valore atteso e varianza\nIl passo cruciale per il ragionamento inferenziale √® capire come varia \\(\\bar{X}\\) se ripetiamo la procedura di campionamento molte volte. In altre parole, se estraessimo pi√π volte (indipendentemente) un campione di ampiezza \\(N\\), otterremmo ogni volta un valore di \\(\\bar{X}\\) in genere diverso. La collezione di tutti questi possibili valori (con le rispettive probabilit√†) si chiama distribuzione campionaria di \\(\\bar{X}\\).\n\n34.3.1 Valore atteso della media (o proporzione) campionaria\nSe \\(X_1, X_2, \\dots, X_n\\) sono variabili aleatorie indipendenti e identicamente distribuite (i.i.d.), ognuna con valore atteso \\(\\mathbb{E}[X_i] = \\mu\\), allora la loro media campionaria\n\\[\n\\bar{X} \\;=\\; \\frac{1}{n}\\sum_{i=1}^n X_i\n\\]\npossiede a sua volta valore atteso\n\\[\n\\mathbb{E}[\\bar{X}] \\;=\\; \\mu.\n\\]\nQuesta semplice formula rivela che \\(\\bar{X}\\) √® uno stimatore non distorto per \\(\\mu\\): in media, se ripetessimo infinite volte lo stesso tipo di campionamento, otterremmo una stima che coincide con il vero valore del parametro. Nel caso di variabili 0-1 (come presenza/assenza di sintomo), abbiamo \\(\\mu \\equiv p\\).\n\nDimostrazione. Consideriamo un campione casuale \\(X_1, X_2, \\dots, X_n\\) di variabili aleatorie indipendenti e identicamente distribuite (i.i.d.), ognuna con valore atteso \\(\\mathbb{E}[X_i] = \\mu\\). Vogliamo dimostrare che il valore atteso della media campionaria \\(\\bar{X}\\) √® uguale a \\(\\mu\\):\n\\[\n\\mathbb{E}[\\bar{X}] = \\mu.\n\\]\nPasso 1: Definizione di media campionaria.\nLa media campionaria √® definita come:\\[\n\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i.\n\\]\nPasso 2: Applicazione del valore atteso.\nCalcoliamo il valore atteso di \\(\\bar{X}\\), sfruttando la linearit√† del valore atteso (l‚Äôaspettativa di una somma √® la somma delle aspettative):\\[\n\\mathbb{E}[\\bar{X}] = \\mathbb{E}\\left[\\frac{1}{n} \\sum_{i=1}^n X_i\\right].\n\\]\nPasso 3: Portare fuori le costanti.\nIl fattore \\(\\frac{1}{n}\\) √® una costante rispetto all‚Äôoperatore \\(\\mathbb{E}\\):\\[\n\\mathbb{E}[\\bar{X}] = \\frac{1}{n} \\mathbb{E}\\left[\\sum_{i=1}^n X_i\\right].\n\\]\nPasso 4: Separare la somma.\nPer linearit√†, l‚Äôaspettativa della somma √® la somma delle aspettative:\\[\n\\mathbb{E}\\left[\\sum_{i=1}^n X_i\\right] = \\sum_{i=1}^n \\mathbb{E}[X_i].\n\\]\nPasso 5: Sfruttare l‚Äôidentica distribuzione.\nPoich√© tutte le \\(X_i\\) sono identicamente distribuite, \\(\\mathbb{E}[X_i] = \\mu\\) per ogni \\(i\\):\\[\n\\sum_{i=1}^n \\mathbb{E}[X_i] = \\sum_{i=1}^n \\mu = n\\mu.\n\\]\nPasso 6: Combinare i risultati.\nSostituendo nel Passo 3:\\[\n\\mathbb{E}[\\bar{X}] = \\frac{1}{n} \\cdot n\\mu = \\mu.\n\\]\nInterpretazione e Significato.\n\n\nNon distorsione (Unbiasedness):\nLa dimostrazione mostra che \\(\\bar{X}\\) √® uno stimatore non distorto di \\(\\mu\\). Questo significa che, in media su infinite replicazioni del campionamento, \\(\\bar{X}\\) coincide con il vero valore \\(\\mu\\).\n\n\nIndipendenza non necessaria per l‚Äôaspettativa:\nL‚Äôindipendenza tra le \\(X_i\\) non √® richiesta per questa dimostrazione. Bastano l‚Äôidentica distribuzione (per garantire \\(\\mathbb{E}[X_i] = \\mu\\)) e la linearit√† del valore atteso.\n\n\nCaso speciale: proporzione campionaria\nSe le \\(X_i\\) sono variabili di Bernoulli (0-1) con \\(\\mathbb{E}[X_i] = p\\), allora \\(\\bar{X} = \\frac{\\text{numero di successi}}{n}\\) stima la proporzione \\(p\\), e \\(\\mathbb{E}[\\bar{X}] = p\\).\n\nPerch√© √® importante?\nQuesta propriet√† √® alla base dell‚Äôinferenza statistica:\n\nGiustifica l‚Äôuso della media campionaria come stima affidabile di \\(\\mu\\).\n\n√à il fondamento della Legge dei Grandi Numeri: all‚Äôaumentare di \\(n\\), \\(\\bar{X}\\) converge a \\(\\mu\\).\n\n\n\n34.3.2 Varianza della media (o proporzione) campionaria\nOltre al valore atteso, un‚Äôaltra misura fondamentale √® la varianza della distribuzione campionaria, che quantifica quanto \\(\\bar{X}\\) tenda a fluttuare attorno a \\(\\mu\\). Se la varianza individuale di ciascun \\(X_i\\) √® \\(\\sigma^2\\), allora per la media campionaria si ha:\n\\[\n\\mathrm{Var}(\\bar{X}) \\;=\\; \\frac{\\sigma^2}{n}.\n\\tag{34.1}\\]\nNel caso Bernoulliano (variabili 0-1) con \\(\\mathbb{E}[X_i] = p\\), sappiamo che\n\\[\n\\sigma^2 \\;=\\; p(1-p).\n\\]\nPertanto:\n\\[\n\\mathrm{Var}(\\bar{X}) \\;=\\; \\frac{p \\bigl(1-p\\bigr)}{n}.\n\\]\nLa radice quadrata di questa varianza prende il nome di errore standard (in inglese Standard Error, SE) della media (o della proporzione), e risulta:\n\\[\n\\mathrm{SE}(\\bar{X}) \\;=\\; \\sqrt{\\frac{p\\,(1-p)}{n}}.\n\\]\nCon l‚Äôaumentare di \\(n\\), la varianza di \\(\\bar{X}\\) diminuisce, e quindi la nostra stima diventa pi√π ‚Äúprecisa‚Äù (in un senso statistico). Ci√≤ spiega perch√©, anche nella pratica psicologica, aumentare la dimensione del campione riduce l‚Äôincertezza nella stima e migliora l‚Äôaffidabilit√† dei risultati.\nOsservazione: nella ricerca psicologica, l‚Äôerrore standard fornisce un‚Äôindicazione chiara di quanto, in media, la nostra stima potrebbe deviare dal vero parametro, se ripetessimo il campionamento molte volte. Questo concetto √® centrale in molte procedure inferenziali, come la costruzione di intervalli di confidenza o il test di ipotesi, e prepara il terreno per comprendere la cosiddetta distribuzione campionaria della media (argomento che il capitolo proseguir√† a trattare).\n\nDimostrazione. Forniamo qui la dimostrazione dell‚ÄôEquazione¬†34.1. Assumiamo che \\(X_1, X_2, \\dots, X_n\\) siano variabili casuali indipendenti e identicamente distribuite (i.i.d.) con media \\(\\mu\\) e varianza \\(\\sigma^2\\). Definiamo la media campionaria\n\\[\n\\bar{X} \\;=\\; \\frac{1}{n}\\sum_{i=1}^n X_i.\n\\]\nVogliamo calcolare \\(\\mathrm{Var}(\\bar{X})\\). Per prima cosa, notiamo che:\n\\[\n\\mathrm{Var}(a\\,Y) \\;=\\; a^2 \\,\\mathrm{Var}(Y)\n\\]\nper qualunque costante \\(a\\). Nel nostro caso, poniamo \\(a = \\frac{1}{n}\\) e \\(Y = \\sum_{i=1}^n X_i\\). Otteniamo quindi:\n\\[\n\\mathrm{Var}(\\bar{X})\n\\;=\\;\n\\mathrm{Var}\\!\\Bigl(\\tfrac{1}{n}\\sum_{i=1}^n X_i\\Bigr)\n\\;=\\;\n\\frac{1}{n^2} \\, \\mathrm{Var}\\!\\Bigl(\\sum_{i=1}^n X_i\\Bigr).\n\\]\nOra sfruttiamo il fatto che \\(X_1, X_2, \\dots, X_n\\) siano indipendenti. In tal caso, la varianza della somma √® la somma delle varianze:\n\\[\n\\mathrm{Var}\\Bigl(\\sum_{i=1}^n X_i\\Bigr)\n\\;=\\;\n\\sum_{i=1}^n \\mathrm{Var}(X_i)\n\\;=\\;\nn \\,\\sigma^2,\n\\]\npoich√© \\(\\mathrm{Var}(X_i) = \\sigma^2\\) per tutti gli \\(i\\). Combiniamo dunque i due risultati:\n\\[\n\\mathrm{Var}(\\bar{X})\n\\;=\\;\n\\frac{1}{n^2}\\,\\bigl(n \\,\\sigma^2\\bigr)\n\\;=\\;\n\\frac{\\sigma^2}{n}.\n\\]\nIn sintesi, la chiave della dimostrazione sta nel fattore \\(\\tfrac{1}{n^2}\\) e nel fatto che, per variabili indipendenti, la varianza di una somma √® la somma delle varianze. Questo ci consente di concludere che la varianza della media campionaria √® \\(\\tfrac{\\sigma^2}{n}\\).\n\nQuesto risultato riflette un‚Äôimportante propriet√† statistica:\n\nall‚Äôaumentare di \\(n\\), la varianza della media campionaria diminuisce, rendendo la media campionaria una stima pi√π precisa del valore atteso \\(\\mu\\). La riduzione della varianza √® proporzionale a \\(1/n\\), quindi raddoppiare il campione riduce la varianza della media campionaria di un fattore 2.\n\nIn conclusione, la formula \\(\\text{Var}(\\bar{X}) = \\frac{\\sigma^2}{n}\\) mostra che la precisione della media campionaria aumenta con la dimensione del campione, poich√© la varianza diminuisce. Questo principio √® alla base dell‚Äôimportanza di campioni pi√π grandi nella stima statistica.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_sampling_distr.html#la-distribuzione-campionaria-della-media",
    "href": "chapters/probability/10_sampling_distr.html#la-distribuzione-campionaria-della-media",
    "title": "34¬† Stime, stimatori e parametri",
    "section": "\n34.4 La Distribuzione Campionaria della Media",
    "text": "34.4 La Distribuzione Campionaria della Media\nPer illustrare ulteriormente il concetto di distribuzione campionaria, consideriamo un caso semplice e specifico: una popolazione finita di dimensioni ridotte. Sebbene stiamo esaminando un caso particolare, √® fondamentale notare che le propriet√† e i principi che analizzeremo in questo contesto sono perfettamente applicabili a popolazioni di qualsiasi dimensione.\nLa distribuzione campionaria ci d√† una visione della variazione che potremmo aspettarci nelle stime derivate da diversi campioni estratti dalla stessa popolazione. Ogni volta che preleviamo un campione, otteniamo una stima diversa per il parametro di interesse (come la media). La distribuzione campionaria ci mostra come queste stime sono distribuite e ci aiuta a comprendere quanto siano affidabili.\nIn termini pratici, se vogliamo calcolare la media della popolazione, non possiamo farlo direttamente (a meno di non avere accesso all‚Äôintera popolazione). Invece, possiamo estrarre un campione casuale e calcolare la media del campione come stima di \\(\\mu\\). Tuttavia, un altro campione fornir√† una stima leggermente diversa. La distribuzione campionaria ci aiuta a capire quanto queste stime varino da campione a campione e ci fornisce un quadro completo dell‚Äôincertezza legata al processo di stima.\nNella simulazione seguente, ipotizziamo la seguente popolazione:\n\nx &lt;- c(2, 4.5, 5, 5.5)\nx\n#&gt; [1] 2.0 4.5 5.0 5.5\n\nL‚Äôistogramma seguente descrive la distribuzione della popolazione.\n\nggplot(data.frame(x = x), aes(x)) +\n  geom_histogram(\n    bins = 5,\n    aes(y = after_stat(density)),\n    fill = \"lightblue\",\n    color = \"black\"\n  )\n\n\n\n\n\n\n\nCalcoliamo la media e la varianza della popolazione. Media:\n\nmean_x &lt;- mean(x) # Media della popolazione\nmean_x\n#&gt; [1] 4.25\n\nVarianza:\n\nvar_x &lt;- var(x) * ((length(x) - 1) / length(x)) # Varianza popolazione\nvar_x\n#&gt; [1] 1.812\n\nConsideriamo tutti i possibili campioni di dimensione \\(n = 2\\) che possono essere estratti dalla popolazione rappresentata dal vettore x. Per generare questi campioni, utilizziamo la funzione expand.grid in R, che consente di creare tutte le combinazioni possibili di valori, includendo le ripetizioni.\nIl risultato sar√† un data frame con 16 righe e 2 colonne, dove ogni riga rappresenta una coppia possibile di valori estratti dal vettore x. Questo risultato √® in linea con il principio del calcolo combinatorio: quando selezioniamo \\(n\\) elementi da un insieme di \\(k\\) elementi e permettiamo ripetizioni, il numero totale di combinazioni √® dato da \\(k^n\\). Nel nostro caso, con \\(k = 4\\) e \\(n = 2\\), otteniamo:\n\\[\n4^2 = 16 \\text{ combinazioni}.\n\\]\nUtilizzando expand.grid, possiamo verificare questo risultato in R:\n\n# Generazione delle combinazioni con ripetizione\nsamples &lt;- expand.grid(x, x)\n\n# Visualizzazione del risultato\nprint(samples)\n#&gt;    Var1 Var2\n#&gt; 1   2.0  2.0\n#&gt; 2   4.5  2.0\n#&gt; 3   5.0  2.0\n#&gt; 4   5.5  2.0\n#&gt; 5   2.0  4.5\n#&gt; 6   4.5  4.5\n#&gt; 7   5.0  4.5\n#&gt; 8   5.5  4.5\n#&gt; 9   2.0  5.0\n#&gt; 10  4.5  5.0\n#&gt; 11  5.0  5.0\n#&gt; 12  5.5  5.0\n#&gt; 13  2.0  5.5\n#&gt; 14  4.5  5.5\n#&gt; 15  5.0  5.5\n#&gt; 16  5.5  5.5\n\nIl data frame risultante mostrer√† tutte le possibili coppie \\((x_1, x_2)\\), dove \\(x_1\\) e \\(x_2\\) possono essere scelti indipendentemente dalla popolazione \\(x = \\{2, 4.5, 5, 5.5\\}\\).\nPer calcolare la media di ogni campione di ampiezza \\(n = 2\\), possiamo utilizzare la funzione rowMeans, che calcola la media per ogni riga di una matrice. In questo modo, otteniamo un vettore contenente la media di ciascuna coppia di valori. Questo insieme di valori costituisce la distribuzione campionaria delle medie dei campioni di ampiezza \\(n = 2\\) che possono essere estratti dalla popolazione x.\n\n# Calcolare la media di ciascun campione\nsample_means &lt;- rowMeans(samples)\nprint(sample_means)\n#&gt;  [1] 2.00 3.25 3.50 3.75 3.25 4.50 4.75 5.00 3.50 4.75 5.00 5.25 3.75 5.00\n#&gt; [15] 5.25 5.50\n\nUna rappresentazione grafica della distribuzione campionaria delle medie dei campioni di ampiezza \\(n = 2\\) che possono essere estratti dalla popolazione x √® fornita qui sotto.\n\n# Istogramma delle medie campionarie\nggplot(data.frame(sample_means), aes(x = sample_means)) +\n  geom_histogram(\n    bins = 5,\n    aes(y = after_stat(density)),\n    fill = \"lightblue\",\n    color = \"black\"\n)\n\n\n\n\n\n\n\nMostriamo qui nuovamente la lista di tutti i possibili campioni di ampiezza 2 insieme alla media di ciascun campione.\n\n# Creare un data frame con i campioni e le loro medie\ndf &lt;- data.frame(\n  Samples = apply(samples, 1, paste, collapse = \", \"),\n  x_bar = rowMeans(samples)\n)\nprint(df)\n#&gt;     Samples x_bar\n#&gt; 1      2, 2  2.00\n#&gt; 2    4.5, 2  3.25\n#&gt; 3      5, 2  3.50\n#&gt; 4    5.5, 2  3.75\n#&gt; 5    2, 4.5  3.25\n#&gt; 6  4.5, 4.5  4.50\n#&gt; 7    5, 4.5  4.75\n#&gt; 8  5.5, 4.5  5.00\n#&gt; 9      2, 5  3.50\n#&gt; 10   4.5, 5  4.75\n#&gt; 11     5, 5  5.00\n#&gt; 12   5.5, 5  5.25\n#&gt; 13   2, 5.5  3.75\n#&gt; 14 4.5, 5.5  5.00\n#&gt; 15   5, 5.5  5.25\n#&gt; 16 5.5, 5.5  5.50\n\nProcediamo ora al calcolo della media della distribuzione campionaria delle medie di campioni di ampiezza \\(n = 2\\) che possono essere estratti dalla popolazione x.\n\n# Calcolare la media delle medie campionarie\nmean(sample_means)\n#&gt; [1] 4.25\n\nSi noti che questo valore coincide con la media della popolazione.\nLa varianza delle medie campionarie, calcolata empiricamente, pu√≤ essere ottenuta direttamente dai dati utilizzando la seguente formula:\n\nvar(x) * (length(x) - 1) / length(x) / length(x)\n#&gt; [1] 0.4531\n\nQuesto calcolo riflette la formula teorica per la varianza della media campionaria, definita come la varianza dei dati divisa per la dimensione del campione \\(n\\). Tuttavia, poich√© la funzione var() in R utilizza \\(n-1\\) al denominatore per fornire una stima non distorta della varianza della popolazione, √® necessario applicare un fattore di correzione \\(\\frac{n-1}{n}\\) per ottenere la varianza campionaria corretta. Successivamente, questa varianza viene divisa per \\(n\\) per ottenere la varianza della media campionaria.\nIn alternativa, possiamo calcolare lo stesso valore prendendo la varianza delle medie di tutti i campioni (16 in questo caso):\n\nvar(sample_means) * ((length(sample_means) - 1) / length(sample_means))\n#&gt; [1] 0.9062\n\nAnche in questo caso applichiamo il fattore di correzione \\(\\frac{n-1}{n}\\) per ottenere il calcolo corretto della varianza usando la funzione var() in R.\nEntrambi i calcoli forniscono risultati coerenti con la teoria, dimostrando che la varianza delle medie campionarie √® inferiore a quella della popolazione.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_sampling_distr.html#sec-lln",
    "href": "chapters/probability/10_sampling_distr.html#sec-lln",
    "title": "34¬† Stime, stimatori e parametri",
    "section": "\n34.5 Legge dei Grandi Numeri",
    "text": "34.5 Legge dei Grandi Numeri\nLa Legge dei Grandi Numeri (LLN, dall‚Äôinglese Law of Large Numbers) √® uno dei pilastri fondamentali della teoria della probabilit√†. Essa descrive come, all‚Äôaumentare del numero di osservazioni, la media campionaria si avvicini stabilmente al valore atteso teorico. In termini formali, se \\(\\bar{X}_n\\) rappresenta la media di \\(n\\) osservazioni indipendenti e identicamente distribuite (i.i.d.) con valore atteso \\(\\mu\\), allora \\(\\bar{X}_n \\to \\mu\\) quando \\(n \\to \\infty\\). Questo principio √® cruciale per comprendere la relazione tra dati empirici e modelli teorici, come discusso nella sezione sull‚Äôinterpretazione della probabilit√† (Capitolo 25).\nEsistono due versioni principali della Legge dei Grandi Numeri:\n\nLegge Forte: La media campionaria \\(\\bar{X}_n\\) converge quasi certamente a \\(\\mu\\), il che significa che, con probabilit√† 1, la media osservata si avvicina indefinitamente al valore teorico al crescere di \\(n\\).\n\nLegge Debole: La media campionaria \\(\\bar{X}_n\\) converge a \\(\\mu\\) in probabilit√†, ovvero, per ogni \\(\\varepsilon &gt; 0\\), la probabilit√† che la differenza tra \\(\\bar{X}_n\\) e \\(\\mu\\) superi \\(\\varepsilon\\) tende a zero al crescere di \\(n\\). Formalmente:\n\\[\n\\Pr\\bigl(| \\bar{X}_n - \\mu| &gt; \\varepsilon\\bigr) \\to 0 \\quad \\text{al crescere di }n.\n\\]\n\n\n\n34.5.1 Applicazioni in Psicologia\nIn psicologia, la Legge dei Grandi Numeri ha implicazioni significative. Ad esempio, se si vuole stimare con precisione la proporzione di individui che manifestano un determinato comportamento o la media di un test cognitivo in una popolazione, √® necessario raccogliere un numero sufficiente di osservazioni. Solo con un campione ampio la media campionaria si avviciner√† alla media ‚Äúvera‚Äù della popolazione, riducendo l‚Äôincertezza e migliorando l‚Äôaffidabilit√† delle stime.\n\n34.5.2 Forma Debole della Legge dei Grandi Numeri\nLa forma debole della LGN, dimostrata per la prima volta da Jacob Bernoulli nel suo lavoro Ars Conjectandi, afferma che la media campionaria converge in probabilit√† alla media teorica (Hacking, 2006). In termini pratici, questo significa che, man mano che il numero di osservazioni aumenta, la probabilit√† che la differenza tra la media osservata e la media teorica superi un margine di errore \\(\\varepsilon\\) diventa sempre pi√π piccola. Formalmente:\n\\[\n\\lim_{{n \\to \\infty}} P\\left(\\left|\\frac{1}{n} \\sum_{i=1}^n X_i - \\mu\\right| \\geq \\varepsilon\\right) = 0,\n\\]\ndove:\n\n\n\\(X_1, X_2, \\ldots, X_n\\) sono variabili casuali indipendenti e identicamente distribuite (i.i.d.),\n\n\\(\\mu\\) √® la media teorica,\n\n\\(\\varepsilon\\) √® un numero positivo arbitrariamente piccolo.\n\n34.5.3 Forma Forte della Legge dei Grandi Numeri\nLa forma forte della LGN, sviluppata successivamente da matematici come Kolmogorov, √® un enunciato pi√π potente. Essa stabilisce che la media campionaria converge quasi sicuramente alla media teorica. Questo implica che, con probabilit√† 1, la media osservata si avvicina indefinitamente al valore teorico man mano che il numero di prove tende all‚Äôinfinito. Formalmente:\n\\[\nP\\left(\\lim_{{n \\to \\infty}} \\frac{1}{n} \\sum_{i=1}^n X_i = \\mu\\right) = 1.\n\\]\n\n34.5.4 Importanza e Critiche\nLa Legge dei Grandi Numeri √® fondamentale per garantire la validit√† delle stime empiriche, ma la sua applicazione pratica richiede attenzione. Ad esempio, in psicologia, la raccolta di un numero sufficiente di osservazioni pu√≤ essere costosa o difficile, specialmente quando si studiano fenomeni rari o popolazioni specifiche. Inoltre, l‚Äôassunzione di indipendenza e identica distribuzione delle osservazioni potrebbe non essere sempre realistica in contesti applicativi complessi. Nonostante queste sfide, la LGN rimane un principio essenziale per comprendere come i dati empirici possano avvicinarsi alle propriet√† teoriche di una popolazione.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_sampling_distr.html#teorema-del-limite-centrale",
    "href": "chapters/probability/10_sampling_distr.html#teorema-del-limite-centrale",
    "title": "34¬† Stime, stimatori e parametri",
    "section": "\n34.6 Teorema del Limite Centrale",
    "text": "34.6 Teorema del Limite Centrale\nOltre alla convergenza, un ulteriore risultato importante √® che la distribuzione di \\(\\bar{X}_n\\) si approssima alla normale man mano che \\(n\\) cresce, anche se i singoli \\(X_i\\) non sono distribuiti normalmente.\n\nTeorema 34.1 Se \\(X_1, X_2, \\ldots, X_n\\) sono variabili iid con media \\(\\mu\\) e deviazione standard \\(\\sigma\\), la distribuzione di\n\\[\n\\bar{X}_n = \\frac{1}{n}\\sum_{i=1}^n X_i\n\\] diventa approssimativamente normale con media \\(\\mu\\) e deviazione standard \\(\\tfrac{\\sigma}{\\sqrt{n}}\\) quando \\(n\\) √® sufficientemente grande.\n\nPer il caso 0-1 (presenza/assenza di un tratto), \\(\\bar{X}\\) √® quindi circa normale con media \\(p\\) e varianza \\(\\frac{p(1-p)}{n}\\). Il TLC consente, tra l‚Äôaltro, di costruire intervalli di confidenza e di calcolare probabilit√† che la stima si discosti di una certa quantit√† dal vero valore.\n\nEsempio 34.1 Per visualizzare il Teorema del Limite Centrale (TLC) in azione, possiamo condurre una simulazione. Immaginiamo una popolazione distribuita in modo uniforme. Estraiamo 300 campioni di dimensione \\(n = 30\\) da questa popolazione e osserviamo come la distribuzione campionaria delle medie di questi campioni converga a una distribuzione normale. Questa simulazione fornir√† un‚Äôillustrazione concreta dell‚Äôefficacia del TLC nell‚Äôapprossimare distribuzioni reali.\n\n# Impostiamo il seed per la riproducibilit√† dei risultati\nset.seed(42)\n\n# Generiamo una popolazione con distribuzione uniforme\npopulation &lt;- runif(5000, min = 0, max = 1)\n\n# Passo 1: Visualizziamo l'istogramma della popolazione utilizzando ggplot2\nggplot(data.frame(population), aes(x = population)) +\n  geom_histogram(\n    aes(y = after_stat(density)),\n    bins = 30, fill = \"lightblue\", color = \"black\"\n  ) +\n  labs(title = \"Distribuzione della Popolazione\", x = \"Valore\", y = \"Densit√†\")\n\n\n\n\n\n\n\n\n# Passo 2 e 3: Estraiamo campioni casuali e calcoliamo le medie campionarie\nsample_size &lt;- 30\nnum_samples &lt;- 300\n\n# Vettore vuoto per memorizzare le medie campionarie\nsample_means &lt;- c()\n\nfor (i in 1:num_samples) {\n  # Estraiamo un campione casuale\n  sample &lt;- sample(population, size = sample_size, replace = TRUE)\n  \n  # Calcoliamo la media del campione\n  sample_means[i] &lt;- mean(sample)\n}\n\n# Calcoliamo media e varianza delle medie campionarie\nx_bar &lt;- mean(sample_means)\nstd &lt;- sd(sample_means)\n\nprint('Media e Varianza delle Medie Campionarie')\n#&gt; [1] \"Media e Varianza delle Medie Campionarie\"\nprint(x_bar)\n#&gt; [1] 0.501\nprint(std**2)\n#&gt; [1] 0.002745\n\n\n# Calcoliamo media e varianza della popolazione\nmu &lt;- mean(population)\nsigma &lt;- sd(population)\n\nprint('Media e Varianza della Popolazione')\n#&gt; [1] \"Media e Varianza della Popolazione\"\nprint(mu)\n#&gt; [1] 0.5032\nprint((sigma**2)/sample_size)\n#&gt; [1] 0.002824\n\n\n# Passo 4: Visualizziamo l'istogramma delle medie campionarie utilizzando ggplot2\nggplot(data.frame(sample_means), aes(x = sample_means)) +\n  geom_histogram(\n    aes(y = after_stat(density)),\n    bins = 30, fill = \"lightblue\", color = \"black\"\n  ) +\n  stat_function(\n    fun = dnorm, args = list(mean = x_bar, sd = std), color = \"black\", size = 1\n  ) +\n  labs(\n    title = \"Distribuzione delle Medie Campionarie\", x = \"Media Campionaria\", y = \"Densit√†\"\n  ) +\n  theme(legend.position = \"top\") \n\n\n\n\n\n\n\nSpiegazione del codice e dei risultati\n\nPopolazione: Abbiamo generato una popolazione di 5000 osservazioni distribuite uniformemente tra 0 e 1. La distribuzione uniforme √® stata scelta perch√© √® chiaramente non normale, il che rende pi√π evidente l‚Äôeffetto del TLC.\nCampionamento: Abbiamo estratto 300 campioni casuali, ciascuno di dimensione \\(n = 30\\), dalla popolazione. Per ogni campione, abbiamo calcolato la media.\nDistribuzione delle Medie Campionarie: Le medie dei campioni sono state raccolte e la loro distribuzione √® stata visualizzata tramite un istogramma. Nonostante la popolazione originale non fosse normale, la distribuzione delle medie campionarie si avvicina a una distribuzione normale, dimostrando il TLC.\nConfronto tra Popolazione e Campioni: Abbiamo confrontato la media e la varianza della popolazione con quelle delle medie campionarie. Come previsto dal TLC, la media delle medie campionarie √® molto vicina alla media della popolazione, mentre la varianza delle medie campionarie √® ridotta di un fattore pari alla dimensione del campione (\\(n = 30\\)).\n\nQuesta simulazione illustra chiaramente come il TLC permetta di approssimare la distribuzione delle medie campionarie a una distribuzione normale, anche quando la popolazione originale non √® normale. Questo risultato √® fondamentale per molte applicazioni pratiche della statistica inferenziale.\n\n\nEsempio 34.2 Sebbene i risultati teorici siano solidi, √® comune utilizzare la simulazione Monte Carlo per verificarne la validit√† in contesti pratici. Supponiamo, ad esempio, che la proporzione reale di individui che soffrono di un certo sintomo in una popolazione sia \\(p = 0.45\\). Possiamo simulare campioni di dimensione \\(n\\) e calcolare la media campionaria \\(\\bar{X}\\) (ovvero la proporzione osservata in ciascun campione). Ripetendo questo processo molte volte, otteniamo una distribuzione empirica delle \\(\\bar{X}\\). Se l‚Äôapprossimazione normale fornita dal Teorema del Limite Centrale (TLC) √® valida, ci aspettiamo che:\n\nLa media delle \\(\\bar{X}\\) sia molto vicina al valore teorico \\(p = 0.45\\).\nLa varianza delle \\(\\bar{X}\\) sia approssimativamente uguale a \\(p(1-p)/n\\), come previsto dalla teoria.\n\nUn esempio di codice in R per questa simulazione √® il seguente:\n\np &lt;- 0.45  # Proporzione reale nella popolazione\nn &lt;- 1000  # Dimensione del campione\nB &lt;- 10000 # Numero di campioni simulati\n\n# Simulazione Monte Carlo: generiamo B campioni e calcoliamo le medie campionarie\nx_hat &lt;- replicate(B, {\n  x &lt;- sample(c(0, 1), size = n, replace = TRUE, prob = c(1-p, p))\n  mean(x)\n})\n\n# Media delle medie campionarie (dovrebbe essere vicina a p)\nmean(x_hat)  # Risultato atteso: ~ 0.45\n#&gt; [1] 0.4501\n\n# Deviazione standard delle medie campionarie (dovrebbe essere vicina a sqrt(p*(1-p)/n))\nsd(x_hat)    # Risultato atteso: ~ sqrt(0.45 * 0.55 / 1000)\n#&gt; [1] 0.0157\n\nRisultati attesi e interpretazione:\n\n\nMedia delle medie campionarie: Il valore medio di x_hat dovrebbe essere molto vicino a \\(0.45\\), confermando che la media campionaria √® uno stimatore non distorto della proporzione reale \\(p\\).\n\nDeviazione standard delle medie campionarie: La deviazione standard di x_hat dovrebbe avvicinarsi a \\(\\sqrt{0.45 \\times 0.55 / 1000} \\approx 0.0157\\), in linea con la formula teorica \\(\\sqrt{p(1-p)/n}\\). Questo valore rappresenta l‚Äôincertezza associata alla stima della proporzione.\n\nEffetto della dimensione del campione:\n\nAumentando la dimensione del campione \\(n\\), l‚Äôampiezza della distribuzione delle medie campionarie (e quindi l‚Äôincertezza di \\(\\bar{X}\\)) diminuisce. Questo √® coerente con la teoria, poich√© la varianza delle medie campionarie √® inversamente proporzionale a \\(n\\). In altre parole, campioni pi√π grandi forniscono stime pi√π precise del parametro della popolazione.\n\nQuesta simulazione dimostra concretamente come il Teorema del Limite Centrale garantisca che, anche per popolazioni non normali (come in questo caso, dove i dati sono binari), la distribuzione delle medie campionarie si avvicini a una distribuzione normale con media \\(p\\) e varianza \\(p(1-p)/n\\), purch√© \\(n\\) sia sufficientemente grande.\n\n\n34.6.1 Margine di errore e intervalli di confidenza\nSe \\(\\bar{X}\\) √® approssimato da \\(\\mathcal{N}(p, \\frac{p(1-p)}{n})\\), allora \\[\nZ = \\frac{\\bar{X} - p}{\\sqrt{p(1-p)/n}}\n\\] segue (approssimativamente) la distribuzione normale standard \\(\\mathcal{N}(0,1)\\). In pratica, non conoscendo \\(p\\), possiamo sostituirlo con \\(\\bar{X}\\) nello stimatore di errore standard (\\(\\mathrm{plug\\text{-}in}\\)):\n\\[\n\\hat{\\mathrm{SE}}(\\bar{X}) = \\sqrt{\\frac{\\bar{X}(1-\\bar{X})}{n}}.\n\\] Spesso si costruisce un intervallo di confidenza approssimato al 95% come:\n\\[\n\\bar{X} \\,\\pm\\, 1.96 \\times \\hat{\\mathrm{SE}}(\\bar{X}),\n\\] dove 1.96 deriva dal fatto che circa il 95% della distribuzione normale standard sta nell‚Äôintervallo \\([-1.96,+1.96]\\). Questo intervallo rappresenta la fascia di incertezza attorno alla stima, che si restringe all‚Äôaumentare di \\(n\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_sampling_distr.html#oltre-la-media-altre-distribuzioni-campionarie",
    "href": "chapters/probability/10_sampling_distr.html#oltre-la-media-altre-distribuzioni-campionarie",
    "title": "34¬† Stime, stimatori e parametri",
    "section": "\n34.7 Oltre la Media: Altre Distribuzioni Campionarie",
    "text": "34.7 Oltre la Media: Altre Distribuzioni Campionarie\nFinora ci siamo concentrati sulla media campionaria (o proporzione), ma in molti casi di interesse psicologico o pi√π in generale statistico, potremmo voler studiare altre statistiche tratte da un campione. Due esempi importanti sono il massimo campionario (utile per analisi di eventi estremi, punteggi massimi nei test, tempi di reazione record, ecc.) e la varianza campionaria (fondamentale per misurare la variabilit√† dei punteggi in un test psicometrico, ad esempio).\n\n34.7.1 Massimo campionario\nQuando siamo interessati a misurare la performance ‚Äúestrema‚Äù di un gruppo (ad esempio il punteggio pi√π elevato in un test cognitivo, oppure la latenza di reazione pi√π veloce se si ragiona in termini di minimi), la statistica di riferimento √® il massimo (o il minimo) nel campione.\n\n34.7.1.1 Teoria e concetti chiave\n\nDefinizione: Dato un campione \\(\\{X_1, X_2, \\dots, X_n\\}\\), il massimo campionario √® \\[\nM = \\max\\{X_1, X_2, \\dots, X_n\\}.\n\\] Questa variabile casuale dipende ovviamente dalla distribuzione dei singoli \\(X_i\\).\n\nPropriet√†:\n\nLa distribuzione di \\(M\\) spesso risulta asimmetrica e ‚Äúspostata a destra‚Äù rispetto alla distribuzione di partenza. Anche se la popolazione originaria fosse normalmente distribuita, la distribuzione del massimo non sar√† normale.\n\nIl valore atteso \\(E[M]\\) supera la media \\(\\mu\\) della popolazione perch√©, fra i \\(n\\) individui osservati, ‚Äúvince‚Äù sempre il pi√π grande.\n\n\n\nImplicazioni pratiche:\n\nAnalizzare i massimi (o i minimi) √® cruciale nello studio di fenomeni estremi (per esempio, individuare il picco di stress in un compito cognitivo o la pi√π alta temperatura registrata in una sperimentazione ambientale).\nLa cosiddetta teoria degli estremi si fonda proprio sull‚Äôanalisi di come i massimi (o minimi) si distribuiscono al crescere di \\(n\\). Questa ha applicazioni in diverse discipline: dalla psicologia (prestazione massima) all‚Äôingegneria (carichi estremi) fino alla finanza (rischi estremi).\n\n\n\n\nEsempio 34.3 Nel seguente esempio, simuliamo 10.000 esperimenti. In ognuno:\n\nGeneriamo 5 osservazioni da una popolazione normale con media \\(\\mu = 100\\) e deviazione standard \\(\\sigma = 15\\).\n\nNe calcoliamo il massimo campionario.\n\nInfine, confrontiamo la distribuzione di questi massimi con la densit√† della distribuzione di partenza (cio√® la normale \\(\\mathcal{N}(100, 15^2)\\)).\n\n# Impostazioni iniziali\nmu &lt;- 100\nsigma &lt;- 15\nx &lt;- seq(mu - 3 * sigma, mu + 3 * sigma, length.out = 100)\ny &lt;- dnorm(x, mean = mu, sd = sigma)\n\n# Simulazione di 10.000 esperimenti con campioni di 5 osservazioni\nset.seed(123)  # Per riproducibilit√†\nsample_maxes &lt;- replicate(10000, max(rnorm(5, mean = mu, sd = sigma)))\n\n# Creiamo un data frame per il grafico\ndata &lt;- data.frame(SampleMaxes = sample_maxes)\ndensity_data &lt;- data.frame(x = x, y = y)\n\n# Grafico con ggplot2\nggplot(data, aes(x = SampleMaxes)) +\n  geom_histogram(\n    aes(y = after_stat(density)),\n    bins = 30,\n    fill = \"lightblue\",\n    color = \"black\",\n    alpha = 0.7\n  ) +\n  geom_line(data = density_data, aes(x = x, y = y), size = 1, color = \"black\") +\n  labs(\n    title = \"Distribuzione dei massimi campionari\",\n    subtitle = \"Confronto con la distribuzione originale\",\n    x = \"Massimo campionario\",\n    y = \"Densit√†\"\n  ) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = \"bold\"),\n    plot.subtitle = element_text(hjust = 0.5)\n  )\n\n\n\n\n\n\n\nOsservazioni:\n\nL‚Äôistogramma, che rappresenta la distribuzione dei massimi campionari, √® spostato a destra rispetto alla distribuzione della popolazione (tracciata in rosso).\nCi√≤ evidenzia che \\(M\\) tende a fornire valori pi√π alti della media \\(\\mu = 100\\). Se ripetessimo l‚Äôesperimento con campioni di dimensione maggiore di 5, questo effetto si accentuerebbe ulteriormente.\n\n\n\n34.7.2 2. Varianza campionaria\nLo studio della varianza (o in generale della variabilit√†) √® un altro esempio cruciale in contesti psicologici. Se vogliamo descrivere quanto differiscono i punteggi di un test di personalit√†, o di un test cognitivo, non basta guardare solo alla media campionaria: ci interessa anche la dispersione.\n\n34.7.2.1 Teoria e concetti chiave\n\nStima della varianza:\nStimare la varianza \\(\\sigma^2\\) di una popolazione non √® banale. La formula \\[\nS^2 = \\frac{1}{n} \\sum_{i=1}^n (Y_i - \\bar{Y})^2\n\\] tende a sottostimare \\(\\sigma^2\\). Per ottenere uno stimatore non distorto, si usa invece: \\[\nS^2 = \\frac{1}{n-1} \\sum_{i=1}^n (Y_i - \\bar{Y})^2.\n\\] L‚Äôuso di \\(n-1\\) serve a correggere la perdita di un grado di libert√† (poich√© \\(\\bar{Y}\\) √® calcolata sui dati) e garantisce che \\(E[S^2] = \\sigma^2\\).\nConcetto di distorsione:\nChiamiamo uno stimatore \\(\\hat{\\theta}\\) non distorto se il suo valore atteso √® uguale al parametro vero \\(\\theta\\): \\(E[\\hat{\\theta}] = \\theta\\). Con la formula a denominatore \\(n-1\\), la varianza campionaria risulta appunto non distorta.\n\n\nEsempio 34.4 Simuliamo 10.000 esperimenti, ognuno con \\(n=5\\) osservazioni generate da \\(\\mathcal{N}(100, 15^2)\\). Per ciascun campione, calcoliamo: 1. La varianza ‚Äúdistorta‚Äù \\(\\frac{1}{n}\\sum_i (X_i - \\bar{X})^2\\). 2. La varianza ‚Äúcorretta‚Äù con \\(n-1\\).\n\nset.seed(123)  # Per riproducibilit√†\n\n# Funzione per calcolare varianze con n e con n-1\ncalc_vars &lt;- function(n = 5, mu = 100, sigma = 15) {\n  sample_data &lt;- rnorm(n, mean = mu, sd = sigma)\n  var_n &lt;- sum((sample_data - mean(sample_data))^2) / n\n  var_n_minus_1 &lt;- var(sample_data)  # In R, var() usa di default n-1\n  c(var_n, var_n_minus_1)\n}\n\n# Simuliamo 10.000 campioni\nB &lt;- 10000\nvars_matrix &lt;- replicate(B, calc_vars())\nsample_vars_n &lt;- vars_matrix[1, ]\nsample_vars_n_minus_1 &lt;- vars_matrix[2, ]\n\n# Confrontiamo graficamente\ndata_n &lt;- data.frame(SampleVars = sample_vars_n, Type = \"Con n\")\ndata_n_minus_1 &lt;- data.frame(SampleVars = sample_vars_n_minus_1, Type = \"Con n-1\")\ncombined_data &lt;- rbind(data_n, data_n_minus_1)\n\nggplot(combined_data, aes(x = SampleVars, color = Type)) +\n  geom_density(size = 1.1) +\n  labs(\n    title = \"Distribuzione delle varianze campionarie\",\n    subtitle = \"Confronto: denominatore n vs. n-1\",\n    x = \"Varianza campionaria\",\n    y = \"Densit√†\"\n  ) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = \"bold\"),\n    plot.subtitle = element_text(hjust = 0.5)\n  ) +\n  scale_color_manual(values = c(\"Con n\" = \"gray\", \"Con n-1\" = \"black\"))\n\n\n\n\n\n\n\nOsservazioni:\n\nLa curva corrispondente a ‚ÄúCon \\(n\\)‚Äù tende a sottostimare la varianza, mentre quella ‚ÄúCon \\(n-1\\)‚Äù si centra meglio attorno a \\(\\sigma^2 = 15^2 = 225\\).\n\nSe verifichiamo le medie delle due distribuzioni:\n\nmean(sample_vars_n)\n#&gt; [1] 180.7\nmean(sample_vars_n_minus_1)\n#&gt; [1] 225.8\n\ntroveremo che la prima √® sensibilmente inferiore a 225, mentre la seconda si avvicina di pi√π al valore vero.\n\n\n\nSia il massimo campionario sia la varianza campionaria dimostrano come non tutte le distribuzioni campionarie ereditino le stesse propriet√† della media. Nel caso del massimo, la variabile risulta spostata verso valori elevati e non segue una forma gaussiana; nel caso della varianza, si deve porre attenzione alla formula usata, per evitare distorsioni sistematiche.\nIn sintesi:\n\n\nMassimo campionario: utile per l‚Äôanalisi di fenomeni estremi (o massimi prestazionali), con una distribuzione tipicamente asimmetrica.\n\n\nVarianza campionaria: richiede la correzione di Bessel (denominatore \\(n-1\\)) per essere uno stimatore non distorto di \\(\\sigma^2\\).\n\nCapire le propriet√† di queste (e altre) distribuzioni campionarie consente allo sperimentatore di valutare correttamente le incertezze nelle stime, di evitare errori di interpretazione e di utilizzare gli stimatori pi√π appropriati in base al tipo di fenomeno studiato.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_sampling_distr.html#errore-standard-incertezza-inferenziale-e-bias",
    "href": "chapters/probability/10_sampling_distr.html#errore-standard-incertezza-inferenziale-e-bias",
    "title": "34¬† Stime, stimatori e parametri",
    "section": "\n34.8 Errore standard, incertezza inferenziale e bias",
    "text": "34.8 Errore standard, incertezza inferenziale e bias\n\n34.8.1 Errore standard e incertezza\nL‚Äôerrore standard (SE) √® la misura di quanto una data statistica (ad esempio la media) pu√≤ variare da un campione all‚Äôaltro per pura casualit√† di campionamento. In un contesto psicologico, pu√≤ essere usato per mostrare graficamente l‚Äôaffidabilit√† di una misura. Esporre i risultati di un test psicometrico riportando solo la media, senza un‚Äôidea dell‚Äôerrore standard o di un intervallo di confidenza, rischia di dare un‚Äôillusione di precisione non giustificata.\n\n34.8.2 Bias: perch√© non basta un campione grandissimo\nAumentare la dimensione campionaria \\(n\\) riduce l‚Äôerrore standard, ma non elimina possibili bias sistematici (si veda, ad esempio, la disussione fornita dal Andrew Gelman su questo tema). Ad esempio:\n\nSe i partecipanti pi√π ansiosi evitano di partecipare allo studio (bias di selezione), la proporzione \\(\\bar{X}\\) sar√† sistematicamente sottostimata.\nSe qualcuno falsifica le risposte per desiderabilit√† sociale (bias di risposta), la media misurata pu√≤ allontanarsi dal valore vero in maniera non corretta da un semplice aumento del campione.\nSe lo strumento di misura (ad es. un questionario) √® mal tarato o concettualmente scorretto, l‚Äôintero studio pu√≤ soffrirne (misurazione errata).\n\nQuando √® presente un bias, nessun aumento del numero di partecipanti potr√† rimuoverlo: si otterranno stime molto ‚Äúprecise‚Äù (varianza piccola) ma sistematicamente lontane dal valore reale.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_sampling_distr.html#riflessioni-conclusive",
    "href": "chapters/probability/10_sampling_distr.html#riflessioni-conclusive",
    "title": "34¬† Stime, stimatori e parametri",
    "section": "\n34.9 Riflessioni Conclusive",
    "text": "34.9 Riflessioni Conclusive\nQuesto percorso illustra come, in un contesto frequentista, sia essenziale distinguere fra:\n\n\nPopolazione e parametro (ad es. la vera proporzione di un sintomo psicologico, o la vera media di un punteggio): entit√† teoriche che non osserviamo direttamente.\n\nCampione e stima (il dato empirico raccolto su un campione, e il calcolo ‚Äì ad esempio la media ‚Äì derivato dal campione).\n\nLa distribuzione campionaria di una statistica, specialmente la media o la proporzione, rivela:\n\nChe la media campionaria √® uno stimatore non distorto (il suo valore atteso coincide con quello della popolazione).\nChe la sua precisione (cio√® \\(\\frac{1}{\\mathrm{Var}(\\bar{X})}\\)) aumenta con la dimensione del campione.\nChe il Teorema del Limite Centrale garantisce un‚Äôapprossimazione normale per \\(\\bar{X}\\) se \\(n\\) √® sufficientemente ampio, consentendo di costruire intervalli di confidenza e valutare probabilisticamente le stime.\nChe l‚Äôerrore standard (SE) descrive la variabilit√† dovuta al campionamento, mentre i bias sistematici non vengono rimossi aumentando \\(n\\).\n\nIn sostanza, chi effettua ricerche in psicologia ‚Äì come in qualunque altra disciplina ‚Äì deve considerare sia l‚Äôincertezza intrinseca (errore casuale di campionamento) sia l‚Äôeventuale presenza di bias strutturali. Solo in questo modo si possono interpretare in modo appropriato i risultati delle analisi e valutare correttamente la credibilit√† delle conclusioni sui processi psicologici o sui fenomeni clinici d‚Äôinteresse.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_sampling_distr.html#esercizi",
    "href": "chapters/probability/10_sampling_distr.html#esercizi",
    "title": "34¬† Stime, stimatori e parametri",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nEsercizi sulla distribuzione campionaria sono disponibili sulla seguente pagina web.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_sampling_distr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/10_sampling_distr.html#informazioni-sullambiente-di-sviluppo",
    "title": "34¬† Stime, stimatori e parametri",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.5.3     \n#&gt;  [9] scales_1.3.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.9.1   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         rlang_1.1.5       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       tools_4.4.2       parallel_4.4.2    tzdb_0.5.0       \n#&gt; [21] colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5       R6_2.6.1         \n#&gt; [25] lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.1    \n#&gt; [29] gtable_0.3.6      glue_1.8.0        xfun_0.51         tidyselect_1.2.1 \n#&gt; [33] rstudioapi_0.17.1 farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-167     \n#&gt; [37] labeling_0.4.3    rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_sampling_distr.html#bibliografia",
    "href": "chapters/probability/10_sampling_distr.html#bibliografia",
    "title": "34¬† Stime, stimatori e parametri",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nHacking, I. (2006). The emergence of probability: A philosophical study of early ideas about probability, induction and statistical inference. Cambridge University Press.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_joint_prob.html",
    "href": "chapters/probability/11_joint_prob.html",
    "title": "35¬† Probabilit√† congiunta",
    "section": "",
    "text": "35.1 Introduzione\nPrerequisiti\nConcetti e Competenze Chiave\nPreparazione del Notebook\nIn questo capitolo ci proponiamo di analizzare in dettaglio il concetto di probabilit√† congiunta, focalizzando l‚Äôattenzione sul caso di variabili aleatorie discrete. La probabilit√† congiunta rappresenta la misura della probabilit√† che due o pi√π eventi si verifichino simultaneamente.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_joint_prob.html#funzione-di-probabilit√†-congiunta",
    "href": "chapters/probability/11_joint_prob.html#funzione-di-probabilit√†-congiunta",
    "title": "35¬† Probabilit√† congiunta",
    "section": "\n35.2 Funzione di Probabilit√† Congiunta",
    "text": "35.2 Funzione di Probabilit√† Congiunta\nFinora ci siamo concentrati sulla probabilit√† associata a un singolo evento o, pi√π precisamente, a un singolo valore assunto da una variabile aleatoria. Tuttavia, in molti contesti, siamo interessati a studiare la relazione tra due o pi√π eventi o variabili aleatorie. La funzione di probabilit√† congiunta ci permette di estendere il concetto di probabilit√† al caso di pi√π variabili aleatorie, descrivendo la probabilit√† che queste assumano specifici valori contemporaneamente.\nSpesso, un esperimento aleatorio √® descritto attraverso pi√π di una variabile aleatoria. Ecco alcuni esempi:\n\nAltezze di un gruppo di persone: Supponiamo di selezionare casualmente \\(n = 10\\) persone e di osservare le loro altezze. Siano \\(X_1, X_2, \\dots, X_n\\) le altezze individuali. In questo caso, siamo interessati a capire come le altezze dei singoli individui si relazionano tra loro.\nLancio ripetuto di una moneta: Consideriamo un esperimento in cui lanciamo una moneta pi√π volte. Definiamo \\(X_i = 1\\) se l‚Äô\\(i\\)-esimo lancio risulta in ‚Äútesta‚Äù e \\(X_i = 0\\) altrimenti. L‚Äôesperimento √® quindi descritto da una sequenza di variabili aleatorie di Bernoulli \\(X_1, X_2, \\dots\\). Qui, potremmo voler studiare la probabilit√† che si verifichino determinate sequenze di risultati.\nPeso e altezza di una persona: Selezioniamo casualmente una persona da una grande popolazione e misuriamo il suo peso \\(X\\) e la sua altezza \\(Y\\). In questo caso, siamo interessati a capire come peso e altezza sono correlati, ad esempio, se persone pi√π alte tendono a pesare di pi√π.\n\nPer descrivere il comportamento delle variabili aleatorie in questi esperimenti, non √® sufficiente specificare la funzione di densit√† di probabilit√† (PDF) o la funzione di massa di probabilit√† (PMF) delle singole variabili. √à necessario anche considerare l‚Äôinterazione tra le variabili aleatorie. Ad esempio:\n\nNel terzo esperimento (peso e altezza), se l‚Äôaltezza \\(Y\\) √® grande, √® probabile che anche il peso \\(X\\) sia grande. Questo suggerisce una dipendenza tra le due variabili.\nNei primi due esperimenti, invece, √® ragionevole assumere che le variabili aleatorie siano indipendenti: conoscere il valore di una variabile non fornisce informazioni aggiuntive sulle altre.\n\nPer catturare queste relazioni, abbiamo bisogno di specificare la distribuzione congiunta delle variabili aleatorie. La distribuzione congiunta descrive la probabilit√† che le variabili assumano specifici valori simultaneamente. Ad esempio:\n\nNel caso discreto, la funzione di massa di probabilit√† congiunta \\(p(x, y)\\) fornisce la probabilit√† che \\(X = x\\) e \\(Y = y\\) contemporaneamente.\nNel caso continuo, la funzione di densit√† di probabilit√† congiunta \\(f(x, y)\\) descrive la densit√† di probabilit√† associata ai valori \\(X = x\\) e \\(Y = y\\).\n\nConsideriamo un esempio psicologico: supponiamo di voler studiare la relazione tra il punteggio \\(X\\) ottenuto in un test cognitivo e il livello di ansia \\(Y\\) riportato da un gruppo di partecipanti. La distribuzione congiunta di \\(X\\) e \\(Y\\) ci permette di rispondere a domande come:\n\nQual √® la probabilit√† che un partecipante con un alto livello di ansia ottenga un punteggio basso nel test cognitivo?\nEsiste una relazione tra ansia e prestazione cognitiva, e se s√¨, come possiamo quantificarla?\n\nIn questo contesto, la distribuzione congiunta ci aiuta a modellare la relazione tra due variabili psicologiche, fornendo una base per analisi pi√π approfondite, come lo studio della correlazione o della dipendenza tra di esse.\nIn sintesi, la funzione di probabilit√† congiunta √® uno strumento essenziale per analizzare la relazione tra due o pi√π variabili aleatorie. Che si tratti di altezze e pesi, risultati di lanci di monete, o variabili psicologiche come ansia e prestazione cognitiva, la distribuzione congiunta ci permette di comprendere come queste variabili interagiscono e influenzano reciprocamente i loro valori.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_joint_prob.html#distribuzione-congiunta",
    "href": "chapters/probability/11_joint_prob.html#distribuzione-congiunta",
    "title": "35¬† Probabilit√† congiunta",
    "section": "\n35.3 Distribuzione Congiunta",
    "text": "35.3 Distribuzione Congiunta\n\nDefinizione 35.1 (Definizione: Distribuzione Congiunta) La distribuzione congiunta di due variabili aleatorie \\(X\\) e \\(Y\\) descrive la probabilit√† che \\(X\\) e \\(Y\\) assumano specifici valori simultaneamente. Nel caso discreto, √® rappresentata dalla funzione di massa di probabilit√† congiunta \\(p(x, y)\\), mentre nel caso continuo dalla funzione di densit√† di probabilit√† congiunta \\(f(x, y)\\).\n\n\n35.3.1 Propriet√† della Distribuzione Congiunta\nUna distribuzione di probabilit√† congiunta deve soddisfare le seguenti propriet√†:\n\nNon negativit√†:\nPer ogni coppia di valori \\((x_i, y_j)\\), la probabilit√† congiunta √® compresa tra 0 e 1: \\[\n0 \\leq P(x_i, y_j) \\leq 1.\n\\]\nNormalizzazione:\nLa somma delle probabilit√† congiunte su tutte le possibili coppie \\((x_i, y_j)\\) deve essere uguale a 1: \\[\n\\sum_{i} \\sum_{j} P(x_i, y_j) = 1.\n\\]\n\n35.3.2 Calcolo della Probabilit√† di Eventi Specifici\nData la distribuzione di probabilit√† congiunta, √® possibile determinare la probabilit√† di eventi definiti in termini delle variabili aleatorie \\(X\\) e \\(Y\\). Ad esempio, per calcolare la probabilit√† che \\(X + Y \\leq 1\\), si sommano le probabilit√† di tutte le coppie \\((x, y)\\) che soddisfano questa condizione.\nIn conclusione, la distribuzione congiunta √® uno strumento fondamentale per analizzare la relazione tra due o pi√π variabili aleatorie. Attraverso di essa, possiamo calcolare probabilit√† di eventi complessi e comprendere come le variabili interagiscono tra loro.\n\nEsempio 35.1 Supponiamo di avere la seguente distribuzione congiunta discreta per \\(X\\) e \\(Y\\):\n\n\n\n\\(Y = 0\\)\n\\(Y = 1\\)\n\\(Y = 2\\)\n\n\n\n\\(X = 0\\)\n\\(\\frac{1}{8}\\)\n\\(\\frac{1}{8}\\)\n\\(\\frac{1}{8}\\)\n\n\n\\(X = 1\\)\n\\(\\frac{1}{8}\\)\n\\(\\frac{1}{8}\\)\n\\(\\frac{1}{8}\\)\n\n\n\\(X = 2\\)\n\\(\\frac{1}{8}\\)\n\\(\\frac{1}{8}\\)\n\\(0\\)\n\n\n\nPer calcolare \\(P(X + Y \\leq 1)\\), identifichiamo le coppie \\((x, y)\\) che soddisfano \\(x + y \\leq 1\\):\n\n\n\\((0, 0)\\),\n\n\\((0, 1)\\),\n\n\\((1, 0)\\).\n\nLa probabilit√† √® quindi: \\[\nP(X + Y \\leq 1) = P(0, 0) + P(0, 1) + P(1, 0) = \\frac{1}{8} + \\frac{1}{8} + \\frac{1}{8} = \\frac{3}{8}.\n\\]\n\n\nEsempio 35.2 Per comprendere meglio il concetto di probabilit√† congiunta, immaginiamo di lanciare tre monete. Tutti i possibili risultati di questo esperimento (ad esempio, tre teste, due teste e una croce, ecc.) costituiscono quello che chiamiamo spazio campionario. In questo caso, lo spazio campionario \\(\\Omega\\) √® dato da:\n\\[\n\\Omega = \\{TTT, TTC, TCT, CTT, CCT, CTC, TCC, CCC\\},\n\\]\ndove \\(T\\) indica ‚Äútesta‚Äù e \\(C\\) indica ‚Äúcroce‚Äù. Assumendo che ogni lancio sia indipendente dagli altri, ogni risultato nello spazio campionario \\(\\Omega\\) ha la stessa probabilit√† di verificarsi, ovvero \\(1/8\\).\nDefiniamo ora le seguenti variabili casuali sullo spazio campionario \\(\\Omega\\):\n\n\n\\(X \\in \\{0, 1, 2, 3\\}\\) rappresenta il numero totale di teste ottenute nei tre lanci.\n\n\\(Y \\in \\{0, 1\\}\\) indica se il primo lancio ha dato testa (\\(1\\)) oppure croce (\\(0\\)).\n\nLa tabella seguente mostra lo spazio campionario con i valori di \\(X\\) e \\(Y\\) associati a ciascun esito, insieme alla probabilit√† di ciascun evento \\(\\omega\\):\n\n\n\\(\\omega\\)\n\\(X\\)\n\\(Y\\)\n\\(P(\\omega)\\)\n\n\n\n\n\\(\\omega_1\\) = TTT\n3\n1\n1/8\n\n\n\n\\(\\omega_2\\) = TTC\n2\n1\n1/8\n\n\n\n\\(\\omega_3\\) = TCT\n2\n1\n1/8\n\n\n\n\\(\\omega_4\\) = CTT\n2\n0\n1/8\n\n\n\n\\(\\omega_5\\) = CCT\n1\n0\n1/8\n\n\n\n\\(\\omega_6\\) = CTC\n1\n0\n1/8\n\n\n\n\\(\\omega_7\\) = TCC\n1\n1\n1/8\n\n\n\n\\(\\omega_8\\) = CCC\n0\n0\n1/8\n\n\n\nOra possiamo determinare la probabilit√† congiunta per ogni coppia \\((X, Y)\\), che rappresenta la probabilit√† di ottenere un determinato numero di teste \\(X\\) e un determinato risultato per il primo lancio \\(Y\\). Ad esempio:\n\\[P(X=0, Y=0) = P(\\text{CCC}) = 1/8,\\]\ne cos√¨ via per le altre coppie.\nLe probabilit√† congiunte per tutte le possibili combinazioni \\((X, Y)\\) sono calcolate come segue:\n\\[\n\\begin{aligned}\nP(X = 0, Y = 0) &= 1/8, \\\\\nP(X = 1, Y = 0) &= P(\\text{CCT}) + P(\\text{CTC}) = 1/4, \\\\\nP(X = 1, Y = 1) &= P(\\text{TCC}) = 1/8, \\\\\nP(X = 2, Y = 0) &= P(\\text{CTT}) = 1/8, \\\\\nP(X = 2, Y = 1) &= P(\\text{TTC}) + P(\\text{TCT}) = 1/4, \\\\\nP(X = 3, Y = 1) &= P(\\text{TTT}) = 1/8.\n\\end{aligned}\n\\]\nQueste probabilit√† costituiscono la distribuzione di probabilit√† congiunta delle variabili casuali \\(X\\) (numero di teste) e \\(Y\\) (testa al primo lancio). Questa distribuzione fornisce un quadro completo delle probabilit√† per tutte le combinazioni di risultati di queste due variabili.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_joint_prob.html#marginalizzazione",
    "href": "chapters/probability/11_joint_prob.html#marginalizzazione",
    "title": "35¬† Probabilit√† congiunta",
    "section": "\n35.4 Marginalizzazione",
    "text": "35.4 Marginalizzazione\nImmagina di condurre uno studio sul livello di stress tra studenti universitari, raccogliendo dati su variabili come l‚Äôanno di corso, il genere, il supporto sociale e il livello di stress. Se desideri comprendere come il livello di stress varia in funzione dell‚Äôanno di corso, indipendentemente dal genere e dal supporto sociale, puoi utilizzare la marginalizzazione.\nLa marginalizzazione consente di ottenere una distribuzione di probabilit√† focalizzata su una o pi√π variabili di interesse, ‚Äúeliminando‚Äù dal calcolo le variabili non rilevanti. Nel nostro esempio, per ottenere la distribuzione marginale del livello di stress rispetto all‚Äôanno di corso, occorre sommare (o integrare, nel caso di variabili continue) le probabilit√† associate a tutte le combinazioni di genere e supporto sociale, mantenendo fisso l‚Äôanno di corso. In questo modo, otteniamo una distribuzione che descrive come il livello di stress varia solo in relazione all‚Äôanno di corso.\nIl termine ‚Äúmarginalizzazione‚Äù deriva dalle tabelle di contingenza: quando rappresentiamo una distribuzione di probabilit√† congiunta in una tabella, le probabilit√† marginali‚Äîche descrivono la distribuzione di una variabile indipendentemente dalle altre‚Äîsi trovano nei margini della tabella (ovvero nelle righe e colonne finali).\n\n35.4.1 Formalizzazione della Marginalizzazione\nData una distribuzione di probabilit√† congiunta \\(P(X, Y)\\) di due variabili casuali \\(X\\) e \\(Y\\), possiamo ottenere la distribuzione marginale di \\(X\\) sommando tutte le probabilit√† associate a \\(Y\\). Formalmente:\n\\[\nP(X = x) = \\sum_y P(X = x, Y = y),\n\\]\ndove \\(P(X = x, Y = y)\\) rappresenta la probabilit√† congiunta di \\(X\\) e \\(Y\\). La marginalizzazione garantisce inoltre che le distribuzioni siano normalizzate, cio√® che le somme delle probabilit√† marginali per ciascuna variabile siano uguali a 1:\n\\[\n\\sum_x P(X = x) = 1 \\quad \\text{e} \\quad \\sum_y P(Y = y) = 1.\n\\]\nNel caso di variabili continue, questa operazione di somma viene sostituita dall‚Äôintegrazione.\nPer chiarire, consideriamo il seguente esempio. Supponiamo di studiare l‚Äôefficacia di una terapia cognitivo-comportamentale per l‚Äôansia, includendo variabili come l‚Äôet√† dei partecipanti e il livello iniziale di ansia. Se vogliamo valutare l‚Äôefficacia della terapia a prescindere dall‚Äôet√† e dal livello di ansia iniziale, marginalizziamo rispetto a queste due variabili, ottenendo cos√¨ una distribuzione che riflette solo l‚Äôassociazione tra terapia e riduzione dell‚Äôansia.\nIn sintesi, la marginalizzazione:\n\npermette di estrarre distribuzioni di probabilit√† per variabili specifiche, ‚Äúdimenticando‚Äù quelle non rilevanti;\nconsiste nel sommare o integrare le probabilit√† attraverso tutte le possibili combinazioni delle variabili non rilevanti, concentrandosi su quelle di interesse.\n\nIn conclusione, la marginalizzazione √® uno strumento essenziale per l‚Äôanalisi statistica, facilitando lo studio delle relazioni tra variabili complesse e aiutandoci a isolare gli effetti delle variabili di interesse in modo rigoroso.\n\nEsempio 35.3 Per fare un esempio, prendiamo come riferimento l‚Äôesperimento del lancio di tre monete equilibrate descritto precedentemente. Per calcolare le probabilit√† marginali di \\(X\\) e \\(Y\\), sommiamo le probabilit√† congiunte su una dimensione. La probabilit√† marginale di \\(X\\), \\(P_X\\), si ottiene sommando le probabilit√† lungo le colonne per ciascun valore fisso di \\(X\\); analogamente, la probabilit√† marginale di \\(Y\\), \\(P_Y\\), si calcola sommando le probabilit√† lungo le righe per ciascun valore fisso di \\(Y\\).\nLa tabella seguente mostra la distribuzione di probabilit√† congiunta \\(P(X, Y)\\) e le probabilit√† marginali \\(P(X)\\) e \\(P(Y)\\):\n\n\n\\(x \\setminus y\\)\n0\n1\n\\(P(x)\\)\n\n\n\n0\n1/8\n0\n1/8\n\n\n1\n2/8\n1/8\n3/8\n\n\n2\n1/8\n2/8\n3/8\n\n\n3\n0\n1/8\n1/8\n\n\n\\(P(y)\\)\n4/8\n4/8\n1.0\n\n\n\n\n\n35.4.2 Marginalizzazione per Variabili Casuali Continue\nNell‚Äôambito della statistica bayesiana, il concetto di marginalizzazione gioca un ruolo cruciale. Un esempio di equazione che emerge da questo processo √®:\n\\[\np(y) = \\int_{\\theta} p(y, \\theta) \\, d\\theta = \\int_{\\theta} p(y \\mid \\theta) p(\\theta) \\, d\\theta,\n\\]\ndove \\(y\\) e \\(\\theta\\) sono variabili casuali continue, con \\(y\\) che rappresenta i dati osservati e \\(\\theta\\) i parametri di un modello statistico. Questa equazione illustra come, in un contesto continuo, la marginalizzazione possa essere vista come l‚Äôestensione dell‚Äôapproccio discreto a un continuum di valori per le variabili in esame.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_joint_prob.html#indipendenza-tra-variabili-casuali",
    "href": "chapters/probability/11_joint_prob.html#indipendenza-tra-variabili-casuali",
    "title": "35¬† Probabilit√† congiunta",
    "section": "\n35.5 Indipendenza tra Variabili Casuali",
    "text": "35.5 Indipendenza tra Variabili Casuali\nL‚Äôindipendenza tra variabili casuali √® un concetto fondamentale in statistica e probabilit√†, parallelo all‚Äôidea di indipendenza tra eventi. Due variabili casuali si considerano indipendenti quando l‚Äôinformazione su una non altera in alcun modo la distribuzione di probabilit√† dell‚Äôaltra. Questa sezione offre una formalizzazione dell‚Äôindipendenza tra due variabili casuali discrete, basata sulla loro distribuzione di probabilit√† congiunta.\n\n35.5.1 Definizione di Indipendenza\nDue variabili casuali \\(X\\) e \\(Y\\), con una distribuzione congiunta, sono definite indipendenti se, e solo se, per ogni coppia di valori \\((x, y)\\) si verifica che:\n\\[\nP_{X, Y}(x, y) = P_X(x) \\cdot P_Y(y).\n\\]\nIn termini pratici, ci√≤ significa che se \\(X\\) e \\(Y\\) sono variabili casuali discrete indipendenti, la loro distribuzione di probabilit√† congiunta √® il prodotto delle rispettive distribuzioni di probabilit√† marginali. Se invece \\(P_{X, Y}(x, y) \\neq P_X(x) \\cdot P_Y(y)\\), le variabili non sono indipendenti e si dicono associate o dipendenti.\nQuesto concetto si applica anche alle variabili casuali continue, mantenendo la stessa logica: l‚Äôindipendenza si verifica quando la funzione di densit√† congiunta √® il prodotto delle funzioni di densit√† marginali.\n\n35.5.2 Associazione tra Variabili Casuali\nQuando due variabili casuali non sono indipendenti, si descrivono come associate o dipendenti. In questo contesto, √® utile introdurre il concetto di covarianza (e correlazione) come misura del grado di associazione lineare tra due variabili casuali. La covarianza e la correlazione quantificano in che modo la variazione di una variabile √® associata alla variazione dell‚Äôaltra, fornendo un indice della loro interdipendenza lineare.\nRiepilogando, l‚Äôindipendenza tra variabili casuali √® un concetto chiave per comprendere le relazioni tra fenomeni aleatori. Riconoscere se due variabili sono indipendenti o associate √® fondamentale per l‚Äôanalisi statistica e per la modellazione di relazioni causali o di correlazione tra variabili.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_joint_prob.html#covarianza",
    "href": "chapters/probability/11_joint_prob.html#covarianza",
    "title": "35¬† Probabilit√† congiunta",
    "section": "\n35.6 Covarianza",
    "text": "35.6 Covarianza\nLa covarianza √® un parametro statistico che quantifica il grado e la direzione della relazione lineare tra due variabili casuali, \\(X\\) e \\(Y\\). In termini semplici, misura come le variazioni di una variabile si accompagnano a quelle dell‚Äôaltra. Per esempio, considerando l‚Äôaltezza e il peso di giraffe, scopriremmo che queste due misure tendono ad aumentare insieme, evidenziando cos√¨ una covarianza positiva. La covarianza √® denotata come \\(Cov(X, Y) = \\sigma_{xy}\\).\n\n35.6.1 Definizione di Covarianza\n\nDefinizione 35.2 La covarianza tra due variabili casuali \\(X\\) e \\(Y\\) √® definita come:\n\\[\nCov(X, Y) = \\mathbb{E}\\left[\\left(X - \\mathbb{E}[X]\\right) \\left(Y - \\mathbb{E}[Y]\\right)\\right],\n\\]\ndove \\(\\mathbb{E}[X]\\) e \\(\\mathbb{E}[Y]\\) rappresentano i valori attesi (o medie) di \\(X\\) ed \\(Y\\), rispettivamente.\n\nIn termini pi√π espliciti, la covarianza pu√≤ essere espressa come:\n\\[\nCov(X, Y) = \\sum_{(x, y) \\in \\Omega} (x - \\mu_X) (y - \\mu_Y) f(x, y),\n\\]\ndove \\(\\mu_X\\) e \\(\\mu_Y\\) sono le medie di \\(X\\) ed \\(Y\\), e \\(f(x, y)\\) √® la funzione di probabilit√† congiunta delle variabili.\nQuesta definizione mostra una stretta analogia con la varianza, che √® la covarianza di una variabile con se stessa:\n\\[\n\\mathbb{V}(X) = Cov(X, X).\n\\]\nInoltre, la covarianza pu√≤ essere calcolata attraverso la relazione:\n\\[\nCov(X, Y) = \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y).\n\\]\n\n35.6.2 Dimostrazione\nLa formula alternativa per la covarianza si dimostra come segue.\nPassaggio 1: Partire dalla definizione di covarianza.\nPer definizione, la covarianza tra due variabili casuali \\(X\\) e \\(Y\\) √®:\n\\[\n\\mathrm{Cov}(X, Y) \\;=\\; \\mathbb{E}\\Bigl[\\bigl(X - \\mathbb{E}[X]\\bigr)\\,\\bigl(Y - \\mathbb{E}[Y]\\bigr)\\Bigr].\n\\]\nQuesta √® semplicemente la definizione formale, in cui consideriamo la ‚Äúdeviazione‚Äù di \\(X\\) dal proprio valor medio (\\(\\mathbb{E}[X]\\)) e la ‚Äúdeviazione‚Äù di \\(Y\\) dal proprio valor medio (\\(\\mathbb{E}[Y]\\)), e ne calcoliamo l‚Äôaspettativa del prodotto.\nPassaggio 2: Espandere il prodotto all‚Äôinterno dell‚Äôaspettativa.\nConsideriamo l‚Äôargomento dell‚Äôaspettativa: \\(\\bigl(X - \\mathbb{E}[X]\\bigr)\\,\\bigl(Y - \\mathbb{E}[Y]\\bigr)\\).\nPer prima cosa espandiamo il prodotto come faremmo con normali variabili algebriche:\n\\[\n\\bigl(X - \\mathbb{E}[X]\\bigr)\\,\\bigl(Y - \\mathbb{E}[Y]\\bigr)\n= X\\,Y \\;-\\; X\\,\\mathbb{E}[Y] \\;-\\; \\mathbb{E}[X]\\,Y \\;+\\; \\mathbb{E}[X]\\mathbb{E}[Y].\n\\]\nPassaggio 3: Applicare l‚Äôaspettativa (lineare) ai termini espansi.\nAdesso prendiamo l‚Äôaspettativa (o valore atteso) di ciascun termine che abbiamo ottenuto. Indichiamo con \\(\\mathbb{E}\\) l‚Äôoperatore di aspettativa:\n\\[\n\\mathbb{E}\\Bigl[\\bigl(X - \\mathbb{E}[X]\\bigr)\\,\\bigl(Y - \\mathbb{E}[Y]\\bigr)\\Bigr]\n= \\mathbb{E}[\\,X\\,Y \\;-\\; X\\,\\mathbb{E}[Y] \\;-\\; \\mathbb{E}[X]\\,Y \\;+\\; \\mathbb{E}[X]\\mathbb{E}[Y]\\,].\n\\]\nGrazie alla linearit√† dell‚Äôaspettativa, possiamo scindere questa grande aspettativa in una somma (e differenza) di aspettative di singoli termini:\n\\[\n= \\mathbb{E}[XY]\n\\;-\\; \\mathbb{E}[X\\,\\mathbb{E}[Y]]\n\\;-\\; \\mathbb{E}[\\mathbb{E}[X]\\,Y]\n\\;+\\; \\mathbb{E}[\\mathbb{E}[X]\\mathbb{E}[Y]].\n\\]\nPassaggio 4: Semplificare usando il fatto che le costanti possono uscire dall‚Äôaspettativa.\nRicordiamo che \\(\\mathbb{E}[X]\\) e \\(\\mathbb{E}[Y]\\) sono numeri (costanti) e non variabili casuali. Dunque, quando nell‚Äôaspettativa compare un fattore costante, possiamo estrarlo fuori dall‚Äôoperatore \\(\\mathbb{E}[\\cdot]\\).\n\n\\(\\mathbb{E}[X\\,\\mathbb{E}[Y]]\\) si semplifica in \\(\\mathbb{E}[Y]\\cdot \\mathbb{E}[X]\\) perch√© \\(\\mathbb{E}[Y]\\) √® una costante. In formula: \\[\n\\mathbb{E}[X\\,\\mathbb{E}[Y]]\n= \\mathbb{E}[Y] \\,\\mathbb{E}[X].\n\\]\nAllo stesso modo, \\(\\mathbb{E}[\\mathbb{E}[X]\\,Y]\\) si semplifica in \\(\\mathbb{E}[X]\\cdot \\mathbb{E}[Y]\\).\nInfine, \\(\\mathbb{E}[\\mathbb{E}[X]\\mathbb{E}[Y]]\\) √® \\(\\mathbb{E}[X]\\mathbb{E}[Y]\\) in quanto \\(\\mathbb{E}[X]\\mathbb{E}[Y]\\) √® gi√† una costante.\n\nUsando queste regole, riscriviamo i termini:\n\\[\n\\mathbb{E}[XY]\n\\;-\\; \\mathbb{E}[X]\\mathbb{E}[Y]\n\\;-\\; \\mathbb{E}[X]\\mathbb{E}[Y]\n\\;+\\; \\mathbb{E}[X]\\mathbb{E}[Y].\n\\]\nPassaggio 5: Combinare i termini.\nOsserviamo i termini rimanenti:\n\\[\n\\mathbb{E}[XY] \\;-\\; \\mathbb{E}[X]\\mathbb{E}[Y]\n\\;-\\; \\mathbb{E}[X]\\mathbb{E}[Y]\n\\;+\\; \\mathbb{E}[X]\\mathbb{E}[Y].\n\\]\n\nIl termine \\(\\mathbb{E}[X]\\mathbb{E}[Y]\\) compare due volte in negativo (\\(-\\,\\mathbb{E}[X]\\mathbb{E}[Y]\\)) e una volta in positivo (\\(+\\,\\mathbb{E}[X]\\mathbb{E}[Y]\\)).\n\nFacendo la somma algebrica, ne rimane solo \\(-\\,\\mathbb{E}[X]\\mathbb{E}[Y]\\) (perch√© \\(-\\,1 -\\,1 +\\,1 = -\\,1\\)).\n\nQuindi il risultato √®:\n\\[\n\\mathbb{E}[XY]\n\\;-\\; \\mathbb{E}[X]\\mathbb{E}[Y].\n\\]\nConclusione.\nAbbiamo quindi dimostrato in maniera esplicita che:\n\\[\n\\mathrm{Cov}(X, Y)\n= \\mathbb{E}\\bigl[(X - \\mathbb{E}[X]) (Y - \\mathbb{E}[Y])\\bigr]\n= \\mathbb{E}[XY] - \\mathbb{E}[X]\\mathbb{E}[Y].\n\\]\n\nEsempio 35.4 Consideriamo le variabili casuali \\(X\\) e \\(Y\\) con medie \\(\\mu_X = 1.5\\) e \\(\\mu_Y = 0.5\\). La covarianza di \\(X\\) e \\(Y\\) si calcola come:\n\\[\nCov(X, Y) = \\sum_{(x, y) \\in \\Omega} (x - \\mu_X) (y - \\mu_Y) f(x, y) = \\frac{1}{4}.\n\\]\nQuesto risultato si pu√≤ ottenere anche dalla formula alternativa, calcolando prima \\(\\mathbb{E}(XY)\\):\n\\[\n\\mathbb{E}(XY) = 1.0.\n\\]\nAllora, la covarianza tra \\(X\\) e \\(Y\\) √®:\n\\[\nCov(X, Y) = 1 - 1.5 \\cdot 0.5 = 0.25.\n\\]\n\n\nEsempio 35.5 Per calcolare la covarianza \\(Cov(X, Y)\\) in R, consideriamo l‚Äôesempio in cui \\(X\\) √® il numero totale di teste che si ottiene dal lancio di tre monete equilibrate e \\(Y\\) √® il risultato del primo lancio (testa = 1, croce = 0). Procediamo creando il prodotto cartesiano di tutti i possibili valori di \\(X\\) e \\(Y\\).\n\n# Creare il prodotto cartesiano di X (c3) e Y (c1)\nc3 &lt;- 0:3  # Numero totale di teste possibili\nc1 &lt;- 0:1  # Risultato del primo lancio (0 = croce, 1 = testa)\nsample &lt;- expand.grid(c1 = c1, c3 = c3)\nsample\n#&gt;   c1 c3\n#&gt; 1  0  0\n#&gt; 2  1  0\n#&gt; 3  0  1\n#&gt; 4  1  1\n#&gt; 5  0  2\n#&gt; 6  1  2\n#&gt; 7  0  3\n#&gt; 8  1  3\n\nIl primo numero di ogni coppia rappresenta il valore di \\(Y\\), mentre il secondo rappresenta il valore di \\(X\\). Tuttavia, queste coppie \\((X, Y)\\) non hanno tutte la stessa probabilit√† di verificarsi. La probabilit√† associata a ciascuna coppia √® data dai seguenti valori: \\(1/8, 2/8, 1/8, 0, 0, 1/8, 2/8, 1/8\\). Questa √® la distribuzione di massa di probabilit√† congiunta delle variabili casuali \\(X\\) e \\(Y\\). Applicando la formula per la covarianza:\n\\[\nCov(X, Y) = \\sum_{i=1}^n (X_i - E[X])(Y_i - E[Y]) P(X_i, Y_i)\n\\]\nCalcoliamo la covarianza in R:\n\n# Probabilit√† di ogni coppia (X, Y)\npmf &lt;- c(1 / 8, 2 / 8, 1 / 8, 0, 0, 1 / 8, 2 / 8, 1 / 8)\n\n# Calcolo della covarianza\nres &lt;- c()\nfor (i in 1:nrow(sample)) {\n  res &lt;- c(res, (sample$c1[i] - 0.5) * (sample$c3[i] - 1.5) * pmf[i])\n}\n\n# Somma dei prodotti ponderati\ncovariance &lt;- sum(res)\ncovariance\n#&gt; [1] -0.125\n\nLa covarianza tra \\(X\\) e \\(Y\\) √® dunque uguale a \\(-0.125\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_joint_prob.html#correlazione",
    "href": "chapters/probability/11_joint_prob.html#correlazione",
    "title": "35¬† Probabilit√† congiunta",
    "section": "\n35.7 Correlazione",
    "text": "35.7 Correlazione\nMentre la covarianza fornisce un‚Äôindicazione della tendenza di due variabili casuali a variare insieme, essa √® influenzata dalle unit√† di misura delle variabili, rendendo difficile valutare l‚Äôintensit√† della loro relazione lineare. Per ovviare a questo, si utilizza la correlazione, che normalizza la covarianza attraverso le deviazioni standard delle variabili, offrendo cos√¨ una misura standardizzata dell‚Äôassociazione lineare tra di esse.\n\nDefinizione 35.3 Il coefficiente di correlazione tra due variabili casuali \\(X\\) e \\(Y\\), denotato come \\(\\rho(X,Y)\\) o \\(\\rho_{X,Y}\\), √® definito come:\n\\[\n\\rho(X,Y) = \\frac{Cov(X,Y)}{\\sqrt{\\mathbb{V}(X)\\mathbb{V}(Y)}},\n\\]\ndove \\(\\mathbb{V}(X)\\) e \\(\\mathbb{V}(Y)\\) rappresentano le varianze di \\(X\\) e \\(Y\\), rispettivamente.\n\nIl coefficiente di correlazione \\(\\rho_{xy}\\) √® un valore adimensionale, ovvero non dipende dalle unit√† di misura delle variabili, e varia nell‚Äôintervallo \\(-1 \\leq \\rho \\leq 1\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_joint_prob.html#propriet√†",
    "href": "chapters/probability/11_joint_prob.html#propriet√†",
    "title": "35¬† Probabilit√† congiunta",
    "section": "\n35.8 Propriet√†",
    "text": "35.8 Propriet√†\n\n\nCovarianza con una Costante: La covarianza tra una variabile aleatoria \\(X\\) e una costante \\(c\\) √® sempre nulla: \\(Cov(c, X) = 0\\).\n\nSimmetria: La covarianza √® simmetrica: \\(Cov(X,Y) = Cov(Y,X)\\).\n\nIntervallo di Correlazione: Il coefficiente di correlazione \\(\\rho\\) varia tra -1 e 1: \\(-1 \\leq \\rho(X,Y) \\leq 1\\).\n\nIndipendenza dalle Unit√† di Misura: La correlazione √® indipendente dalle unit√† di misura: \\(\\rho(aX, bY) = \\rho(X,Y)\\) per ogni \\(a, b &gt; 0\\).\n\nRelazione Lineare Perfetta: Se \\(Y = a + bX\\) √® una funzione lineare di \\(X\\), allora \\(\\rho(X,Y) = \\pm 1\\), a seconda del segno di \\(b\\).\n\nCovarianza e Costanti: La covarianza tra \\(X\\) e \\(Y\\), ciascuna moltiplicata per una costante, √® \\(Cov(aX, bY) = ab \\, Cov(X,Y)\\).\n\nVarianza della Somma/Differenza: \\(\\mathbb{V}(X \\pm Y) = \\mathbb{V}(X) + \\mathbb{V}(Y) \\pm 2Cov(X,Y)\\).\n\nCovarianza e Somma di Variabili: \\(Cov(X + Y, Z) = Cov(X,Z) + Cov(Y,Z)\\).\n\nVarianza di una Somma di Variabili Aleatorie: Per variabili aleatorie \\(X_1, \\dots, X_n\\), si ha \\(\\mathbb{V}(\\sum_{i=1}^n X_i) = \\sum_{i=1}^n \\mathbb{V}(X_i) + 2\\sum_{i&lt;j} Cov(X_i, X_j)\\).\n\nCovarianza e Somme di Prodotti: \\(Cov(\\sum_{i=1}^n a_i X_i, \\sum_{j=1}^m b_j Y_j) = \\sum_{i=1}^n \\sum_{j=1}^m a_i b_j Cov(X_i, Y_j)\\).\n\nIndipendenza e Covarianza di Somme: Se \\(X_1, X_2, \\dots, X_n\\) sono indipendenti, allora \\(Cov(\\sum_{i=1}^n a_i X_i, \\sum_{j=1}^n b_j X_j) = \\sum_{i=1}^n a_i b_i \\mathbb{V}(X_i)\\).\n\n\n35.8.1 Incorrelazione\nDue variabili casuali \\(X\\) ed \\(Y\\) si dicono incorrelate, o linearmente indipendenti, se la loro covarianza √® nulla:\n\\[\nCov(X,Y) = \\mathbb{E}[(X - \\mu_X)(Y - \\mu_Y)] = 0,\n\\]\nequivalente a dire che \\(\\rho_{XY} = 0\\) e \\(\\mathbb{E}(XY) = \\mathbb{E}(X)\\mathbb{E}(Y)\\).\nQuesta condizione indica una forma di indipendenza pi√π debole rispetto all‚Äôindipendenza stocastica. Tuttavia, \\(Cov(X, Y) = 0\\) non implica necessariamente che \\(X\\) ed \\(Y\\) siano stocasticamente indipendenti.\n\nEsempio 35.6 Consideriamo una distribuzione di probabilit√† congiunta di due variabili aleatorie, \\(X\\) e \\(Y\\), definita come:\n\\[\nf_{XY}(x,y) = \\left\\{\n\\begin{array}{ll}\n\\frac{1}{4} & \\text{per } (x,y) \\in \\{(0,0), (1,1), (1, -1), (2,0) \\}, \\\\\n0 & \\text{altrimenti.}\n\\end{array}\n\\right.\n\\]\nQuesto implica che le variabili aleatorie \\(X\\) e \\(Y\\) assumono valori specifici con probabilit√† uniforme solo per determinate coppie \\((x, y)\\) e zero in tutti gli altri casi.\nDistribuzioni Marginali\nLa distribuzione marginale di \\(X\\) si ottiene sommando le probabilit√† congiunte su tutti i possibili valori di \\(Y\\), e viceversa per \\(Y\\). Le distribuzioni marginali risultano essere:\n\n\nPer \\(X\\):\n\\[\nf_X(x) = \\left\\{\n\\begin{array}{ll}\n\\frac{1}{4} & \\text{per } x=0, \\\\\n\\frac{1}{2} & \\text{per } x=1, \\\\\n\\frac{1}{4} & \\text{per } x=2.\n\\end{array}\n\\right.\n\\]\n\n\nPer \\(Y\\):\n\\[\nf_Y(y) = \\left\\{\n\\begin{array}{ll}\n\\frac{1}{4} & \\text{per } y=-1, \\\\\n\\frac{1}{2} & \\text{per } y=0, \\\\\n\\frac{1}{4} & \\text{per } y=1.\n\\end{array}\n\\right.\n\\]\n\n\nMedie e Varianze\nCalcoliamo ora le medie e le varianze di \\(X\\) e \\(Y\\):\n\n\nMedia di \\(X\\):\n\\[\n\\mathbb{E}(X) = 0 \\cdot \\frac{1}{4} + 1 \\cdot \\frac{1}{2} + 2 \\cdot \\frac{1}{4} = 1.\n\\]\n\n\nVarianza di \\(X\\):\n\\[\n\\mathbb{V}(X) = \\left(0^2 \\cdot \\frac{1}{4} + 1^2 \\cdot \\frac{1}{2} + 2^2 \\cdot \\frac{1}{4}\\right) - \\mathbb{E}(X)^2 = \\frac{3}{2} - 1 = \\frac{1}{2}.\n\\]\n\n\nMedia di \\(Y\\):\n\\[\n\\mathbb{E}(Y) = (-1) \\cdot \\frac{1}{4} + 0 \\cdot \\frac{1}{2} + 1 \\cdot \\frac{1}{4} = 0.\n\\]\n\n\nVarianza di \\(Y\\):\n\\[\n\\mathbb{V}(Y) = \\left((-1)^2 \\cdot \\frac{1}{4} + 0^2 \\cdot \\frac{1}{2} + 1^2 \\cdot \\frac{1}{4}\\right) - \\mathbb{E}(Y)^2 = \\frac{1}{2}.\n\\]\n\n\nCovarianza tra X e Y\nLa covarianza si calcola come:\n\\[\nCov(X,Y) = \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y),\n\\]\ndove \\(\\mathbb{E}(XY)\\) si trova sommando il prodotto delle coppie di valori \\((x, y)\\) per la loro probabilit√† congiunta:\n\\[\n\\mathbb{E}(XY) = 0.\n\\]\nDi conseguenza, la covarianza tra \\(X\\) e \\(Y\\) √® zero:\n\\[\nCov(X,Y) = 0 - 1 \\cdot 0 = 0.\n\\]\nConclusioni\nSebbene \\(X\\) e \\(Y\\) siano incorrelate (covarianza nulla), ci√≤ non implica la loro indipendenza. L‚Äôindipendenza richiede che la funzione di probabilit√† congiunta si possa esprimere come il prodotto delle funzioni di probabilit√† marginali per ogni \\(x\\) e \\(y\\), condizione che non si verifica in questo caso. Quindi, nonostante l‚Äôassenza di correlazione, \\(X\\) e \\(Y\\) non sono indipendenti, dimostrando che l‚Äôincorrelazione non garantisce l‚Äôindipendenza.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_joint_prob.html#variabili-continue",
    "href": "chapters/probability/11_joint_prob.html#variabili-continue",
    "title": "35¬† Probabilit√† congiunta",
    "section": "\n35.9 Variabili Continue",
    "text": "35.9 Variabili Continue\nPassiamo ora a considerare le distribuzioni di densit√† per variabili continue. Nella figura seguente, tratta da Martin (2024), √® illustrata la relazione tra la probabilit√† congiunta \\(p(A, B)\\), le probabilit√† marginali \\(p(A)\\) e \\(p(B)\\), e le probabilit√† condizionali \\(p(A \\mid B)\\).\n\n\nDistribuzioni di densit√† (figura tratta da Martin (2024)).\n\n\n35.9.1 Probabilit√† Congiunta \\(p(A, B)\\)\n\nLa probabilit√† congiunta \\(p(A, B)\\) rappresenta la probabilit√† che le variabili \\(A\\) e \\(B\\) assumano determinati valori contemporaneamente. Nel caso di variabili continue, questa probabilit√† √® data dall‚Äôintegrazione della funzione di densit√† congiunta \\(f(A, B)\\) su una regione di interesse (ad esempio, un‚Äôarea o un volume). Formalmente:\n\\[\nP(A \\in R_A, B \\in R_B) = \\iint_{R_A \\times R_B} f(A, B) \\, dA \\, dB,\n\\]\ndove \\(R_A\\) e \\(R_B\\) sono intervalli di valori per \\(A\\) e \\(B\\), rispettivamente.\n\n35.9.2 Probabilit√† Marginali \\(p(A)\\) e \\(p(B)\\)\n\nLe probabilit√† marginali \\(p(A)\\) e \\(p(B)\\) rappresentano la probabilit√† di osservare un particolare valore di \\(A\\) (o \\(B\\)) indipendentemente dal valore assunto dall‚Äôaltra variabile. Nel caso continuo, si ottengono integrando la funzione di densit√† congiunta rispetto all‚Äôaltra variabile:\n\\[\np(A) = \\int_{-\\infty}^{+\\infty} f(A, B) \\, dB,\n\\] \\[\np(B) = \\int_{-\\infty}^{+\\infty} f(A, B) \\, dA.\n\\]\nQueste distribuzioni marginali descrivono il comportamento individuale di ciascuna variabile, ignorando l‚Äôinformazione sull‚Äôaltra.\n\n35.9.3 Probabilit√† Condizionale \\(p(A \\mid B)\\)\n\nLa probabilit√† condizionale \\(p(A \\mid B)\\) esprime la probabilit√† che \\(A\\) assuma un certo valore, dato un valore specifico di \\(B\\). Nel contesto continuo, si calcola dividendo la funzione di densit√† congiunta per la densit√† marginale di \\(B\\):\n\\[\np(A \\mid B) = \\frac{f(A, B)}{p(B)}.\n\\]\nQuesta definizione estende il concetto di probabilit√† condizionale al caso continuo, mantenendo la stessa interpretazione fondamentale: la probabilit√† di \\(A\\) dato \\(B\\).\n\n35.9.4 Transizione da Variabili Discrete a Continue\nLa transizione dal trattamento delle variabili discrete a quello delle variabili continue richiede un cambiamento di strumenti matematici: le somme utilizzate nel caso discreto vengono sostituite da integrali nel caso continuo. Tuttavia, i concetti fondamentali di probabilit√† congiunta, marginale e condizionale rimangono invariati.\n\n35.9.5 Interpretazione Grafica\nNel caso continuo, la probabilit√† \\(P(X + Y \\leq 1)\\) corrisponde all‚Äôarea sotto la curva della funzione di densit√† congiunta \\(f(x, y)\\) nella regione definita da \\(x + y \\leq 1\\). Questa area pu√≤ essere calcolata tramite un integrale doppio:\n\\[\nP(X + Y \\leq 1) = \\iint_{x + y \\leq 1} f(x, y) \\, dx \\, dy.\n\\]\nQuesta rappresentazione grafica e matematica evidenzia come la probabilit√† sia legata all‚Äôarea sotto la curva di densit√†, estendendo il concetto di probabilit√† a variabili continue.\nIn conclusione, le distribuzioni di densit√† per variabili continue permettono di analizzare la relazione tra due o pi√π variabili in modo analogo al caso discreto, ma utilizzando strumenti matematici pi√π avanzati come gli integrali. La probabilit√† congiunta, marginale e condizionale rimangono concetti chiave, applicabili sia nel contesto discreto che continuo, e forniscono una base solida per l‚Äôanalisi statistica di fenomeni complessi.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_joint_prob.html#riflessioni-conclusive",
    "href": "chapters/probability/11_joint_prob.html#riflessioni-conclusive",
    "title": "35¬† Probabilit√† congiunta",
    "section": "\n35.10 Riflessioni Conclusive",
    "text": "35.10 Riflessioni Conclusive\nIn molti contesti, ogni elemento di una popolazione pu√≤ essere associato a pi√π variabili casuali. Ad esempio, consideriamo l‚Äôinsieme di tutti gli studenti iscritti a un‚Äôuniversit√†. Se selezioniamo uno studente a caso e misuriamo la sua altezza e il suo peso, ogni individuo della popolazione √® associato a due variabili casuali: l‚Äôaltezza \\(X\\) e il peso \\(Y\\). Questo scenario illustra come, in situazioni reali, sia comune avere pi√π variabili casuali associate a ciascun elemento di una popolazione.\nQuando si hanno due o pi√π variabili casuali associate a ogni elemento di una popolazione, √® possibile studiare la distribuzione congiunta di tali variabili. In questo capitolo, abbiamo esaminato:\n\nDistribuzione di Massa di Probabilit√† Congiunta: Abbiamo visto come rappresentare la probabilit√† congiunta \\(p(X, Y)\\) per due variabili casuali discrete, che descrive la probabilit√† che \\(X\\) e \\(Y\\) assumano specifici valori simultaneamente.\nDistribuzioni Marginali: Abbiamo mostrato come ottenere le distribuzioni marginali \\(p(X)\\) e \\(p(Y)\\) a partire dalla distribuzione congiunta, integrando (o sommando, nel caso discreto) rispetto all‚Äôaltra variabile. Queste distribuzioni descrivono il comportamento individuale di ciascuna variabile, ignorando l‚Äôinformazione sull‚Äôaltra.\nIncorrelazione e Indipendenza: Abbiamo discusso i concetti di incorrelazione e indipendenza tra variabili casuali. Due variabili sono indipendenti se la loro distribuzione congiunta √® il prodotto delle distribuzioni marginali: \\[\np(X, Y) = p(X) \\cdot p(Y).\n\\] L‚Äôindipendenza implica incorrelazione, ma non vale il viceversa: due variabili possono essere incorrelate senza essere indipendenti.\n\nLa distribuzione congiunta √® uno strumento fondamentale per analizzare la relazione tra due o pi√π variabili casuali. Essa permette di rispondere a domande come:\n\nQual √® la probabilit√† che uno studente abbia un‚Äôaltezza compresa tra 170 cm e 180 cm e un peso compreso tra 70 kg e 80 kg?\nEsiste una relazione tra altezza e peso, e se s√¨, come possiamo quantificarla?\n\nAttraverso la distribuzione congiunta, possiamo studiare non solo il comportamento individuale delle variabili, ma anche le loro interazioni e dipendenze.\nIl concetto di distribuzione congiunta pu√≤ essere esteso a pi√π di due variabili casuali, aprendo la strada all‚Äôanalisi di fenomeni pi√π complessi. Ad esempio, in uno studio psicologico, potremmo essere interessati a esaminare la relazione tra ansia, prestazione cognitiva e livello di stress, utilizzando una distribuzione congiunta a tre variabili.\nIn conclusione, lo studio delle distribuzioni congiunte fornisce una base solida per comprendere e modellare la relazione tra variabili casuali. Che si tratti di altezza e peso, ansia e prestazione, o altre coppie di variabili, la distribuzione congiunta ci permette di analizzare in modo rigoroso le interazioni tra di esse, aprendo la strada a previsioni e decisioni informate.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_joint_prob.html#esercizi",
    "href": "chapters/probability/11_joint_prob.html#esercizi",
    "title": "35¬† Probabilit√† congiunta",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nEsercizio 1: Distribuzione congiunta di due lanci di dado\nSi lancia due volte un dado a sei facce equilibrato. Siano:\n\n\n\\(X\\) il risultato del primo lancio.\n\n\\(Y\\) il risultato del secondo lancio.\n\n\nCostruisci la tabella della distribuzione congiunta \\(P(X, Y)\\), considerando che tutti i risultati possibili hanno la stessa probabilit√†.\nVerifica che la somma delle probabilit√† sia 1.\nDetermina la distribuzione marginale di \\(X\\) e di \\(Y\\).\nLe variabili \\(X\\) e \\(Y\\) sono indipendenti? Giustifica la risposta.\n\nEsercizio 2: Somma di due dadi\nSi lancia due volte un dado a sei facce. Definiamo:\n\n\n\\(S = X + Y\\), la somma dei due risultati.\n\n\nCostruisci la tabella di probabilit√† congiunta \\(P(X, Y)\\).\nCalcola la distribuzione di probabilit√† della variabile aleatoria \\(S\\).\nDetermina \\(P(S = 7)\\) e \\(P(S \\leq 5)\\).\nQual √® il valore pi√π probabile di \\(S\\)? E il meno probabile?\n\nEsercizio 3: Lancio di tre monete\nSi lanciano tre monete equilibrate. Definiamo:\n\n\n\\(X\\) il numero di teste ottenute.\n\n\\(Y\\) il risultato del primo lancio (1 se testa, 0 se croce).\n\n\nDetermina lo spazio campionario e associa i valori delle variabili aleatorie \\(X\\) e \\(Y\\).\nCostruisci la distribuzione congiunta \\(P(X, Y)\\).\nCalcola \\(P(X = 2 \\mid Y = 1)\\) e \\(P(Y = 1 \\mid X = 2)\\).\nLe variabili \\(X\\) e \\(Y\\) sono indipendenti?\n\nEsercizio 4: Minimo e massimo tra due dadi\nSi lancia due volte un dado a sei facce. Definiamo:\n\n\n\\(X = \\min \\{X_1, X_2\\}\\), il valore minimo tra i due lanci.\n\n\\(Y = \\max \\{X_1, X_2\\}\\), il valore massimo tra i due lanci.\n\n\nCostruisci la tabella della distribuzione congiunta \\(P(X, Y)\\).\nCalcola \\(P(X = 3, Y = 5)\\) e \\(P(X \\geq 3, Y \\leq 4)\\).\nDetermina la distribuzione marginale di \\(X\\) e di \\(Y\\).\nCalcola la covarianza tra \\(X\\) e \\(Y\\).\n\nEsercizio 5: Differenza tra due dadi\nSi lanciano due dadi a sei facce. Definiamo:\n\n\n\\(X\\) il risultato del primo lancio.\n\n\\(Y\\) la differenza assoluta tra i due risultati, ovvero \\(Y = |X - X_2|\\).\n\n\nDetermina la tabella della distribuzione congiunta \\(P(X, Y)\\).\nCalcola la distribuzione marginale di \\(Y\\).\nDetermina \\(P(Y = 0)\\) e \\(P(Y = 3)\\).\nLe variabili \\(X\\) e \\(Y\\) sono indipendenti? Giustifica la risposta.\n\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\nEsercizio 1: Distribuzione congiunta di due lanci di dado\nAbbiamo due variabili aleatorie discrete: - \\(X\\), risultato del primo lancio di un dado a sei facce. - \\(Y\\), risultato del secondo lancio.\n1. Tabella della distribuzione congiunta \\(P(X, Y)\\) Poich√© il dado √® equo, ogni coppia di risultati \\((x, y)\\) ha la stessa probabilit√†. Esistono \\(6 \\times 6 = 36\\) combinazioni possibili, e ognuna ha probabilit√†:\n\\[\nP(X = x, Y = y) = \\frac{1}{36}, \\quad \\text{per ogni } x, y \\in \\{1, 2, 3, 4, 5, 6\\}\n\\]\nLa tabella della distribuzione congiunta √®:\n\n\n\n\\(X\\) ¬†\\(Y\\)\n\n1\n2\n3\n4\n5\n6\n\n\n\n1\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n\n\n2\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n\n\n3\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n\n\n4\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n\n\n5\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n\n\n6\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n\n\n\n2. Verifica che la somma delle probabilit√† sia 1 La somma di tutte le probabilit√† √®:\n\\[\n\\sum_{x=1}^{6} \\sum_{y=1}^{6} P(X = x, Y = y) = 36 \\times \\frac{1}{36} = 1.\n\\]\n3. Distribuzione marginale di \\(X\\) e \\(Y\\) Per ottenere la distribuzione marginale di \\(X\\):\n\\[\nP(X = x) = \\sum_{y=1}^{6} P(X = x, Y = y) = 6 \\times \\frac{1}{36} = \\frac{1}{6}, \\quad \\forall x.\n\\]\nAnalogamente, per \\(Y\\):\n\\[\nP(Y = y) = \\sum_{x=1}^{6} P(X = x, Y = y) = \\frac{1}{6}, \\quad \\forall y.\n\\]\nEntrambe seguono una distribuzione uniforme su \\(\\{1, 2, 3, 4, 5, 6\\}\\).\n4. Indipendenza di \\(X\\) e \\(Y\\) Due variabili sono indipendenti se \\(P(X = x, Y = y) = P(X = x) P(Y = y)\\).\n\\[\n\\frac{1}{36} = \\frac{1}{6} \\times \\frac{1}{6} = \\frac{1}{36}, \\quad \\forall x, y.\n\\]\nPoich√© questa relazione vale per tutti i valori, \\(X\\) e \\(Y\\) sono indipendenti.\nEsercizio 2: Somma di due dadi\nAbbiamo:\n\\[\nS = X + Y\n\\]\n1. Tabella di probabilit√† congiunta \\(P(X, Y)\\) √à la stessa tabella costruita nel primo esercizio.\n2. Distribuzione di probabilit√† di \\(S\\) La somma \\(S\\) assume valori da \\(2\\) (1+1) a \\(12\\) (6+6). La probabilit√† di ogni valore di \\(S\\) si ottiene contando le coppie \\((x, y)\\) che lo producono:\n\n\n\\(S\\)\n\\(P(S)\\)\n\n\n\n2\n1/36\n\n\n3\n2/36\n\n\n4\n3/36\n\n\n5\n4/36\n\n\n6\n5/36\n\n\n7\n6/36\n\n\n8\n5/36\n\n\n9\n4/36\n\n\n10\n3/36\n\n\n11\n2/36\n\n\n12\n1/36\n\n\n\n3. Calcolo di \\(P(S = 7)\\) e \\(P(S \\leq 5)\\) - \\(P(S = 7) = 6/36 = 1/6\\). - \\(P(S \\leq 5) = P(S = 2) + P(S = 3) + P(S = 4) + P(S = 5)\\)\n\\[\n\\frac{1}{36} + \\frac{2}{36} + \\frac{3}{36} + \\frac{4}{36} = \\frac{10}{36} = \\frac{5}{18}.\n\\]\n4. Valori pi√π probabili e meno probabili - Il valore pi√π probabile √® \\(S = 7\\) (\\(P(S=7) = 1/6\\)). - I valori meno probabili sono \\(S = 2\\) e \\(S = 12\\) (\\(P(S) = 1/36\\)).\nEsercizio 3: Lancio di tre monete\nAbbiamo:\n\nTre monete equilibrare.\nVariabili:\n\n\n\\(X\\): numero di teste ottenute.\n\n\\(Y\\): risultato del primo lancio (1 se testa, 0 se croce).\n\n\n\n1. Spazio campionario e valori di \\(X\\) e \\(Y\\)\nLo spazio campionario dei lanci √®:\n\\[\n\\{ (C, C, C), (C, C, T), (C, T, C), (C, T, T), (T, C, C), (T, C, T), (T, T, C), (T, T, T) \\}\n\\]\nOra assegniamo \\(X\\) e \\(Y\\):\n\n\nLancio\n\n\\(X\\) (num. teste)\n\n\\(Y\\) (primo lancio)\n\n\n\nC, C, C\n0\n0\n\n\nC, C, T\n1\n0\n\n\nC, T, C\n1\n0\n\n\nC, T, T\n2\n0\n\n\nT, C, C\n1\n1\n\n\nT, C, T\n2\n1\n\n\nT, T, C\n2\n1\n\n\nT, T, T\n3\n1\n\n\n\n2. Distribuzione congiunta \\(P(X, Y)\\)\nPoich√© ogni lancio ha probabilit√† \\(\\frac{1}{8}\\), la tabella di probabilit√† congiunta √®:\n\n\n\n\\(X\\) ¬†\\(Y\\)\n\n0\n1\n\n\n\n0\n1/8\n0\n\n\n1\n2/8\n1/8\n\n\n2\n1/8\n3/8\n\n\n3\n0\n1/8\n\n\n\n3. Probabilit√† condizionate \\(P(X = 2 \\mid Y = 1)\\) \\[\nP(X = 2 \\mid Y = 1) = \\frac{P(X = 2, Y = 1)}{P(Y = 1)} = \\frac{3/8}{5/8} = \\frac{3}{5}.\n\\]\n\\(P(Y = 1 \\mid X = 2)\\) \\[\nP(Y = 1 \\mid X = 2) = \\frac{P(X = 2, Y = 1)}{P(X = 2)} = \\frac{3/8}{4/8} = \\frac{3}{4}.\n\\]\n4. Indipendenza di \\(X\\) e \\(Y\\)\nVerifichiamo se \\(P(X = x, Y = y) = P(X = x) P(Y = y)\\) per ogni coppia.\nEsempio: \\(P(X = 2, Y = 1) = 3/8\\) ma \\(P(X=2) P(Y=1) = (4/8)(5/8) = 20/64 = 5/16 \\neq 3/8\\).\nQuindi \\(X\\) e \\(Y\\) non sono indipendenti.\nEsercizio 4: Minimo e massimo tra due dadi\nAbbiamo:\n\n\n\\(X = \\min(X_1, X_2)\\), il minimo tra i due lanci.\n\n\\(Y = \\max(X_1, X_2)\\), il massimo tra i due lanci.\n\n1. Tabella della distribuzione congiunta\nPoich√© i due lanci sono indipendenti e simmetrici, ci sono 36 coppie \\((X_1, X_2)\\), e ogni coppia ha probabilit√† \\(\\frac{1}{36}\\).\nLa tabella congiunta si costruisce considerando che \\(X = \\min(X_1, X_2)\\) e \\(Y = \\max(X_1, X_2)\\):\n\n\n\n\\(X\\) ¬†\\(Y\\)\n\n1\n2\n3\n4\n5\n6\n\n\n\n1\n1/36\n2/36\n3/36\n4/36\n5/36\n6/36\n\n\n2\n-\n1/36\n2/36\n3/36\n4/36\n5/36\n\n\n3\n-\n-\n1/36\n2/36\n3/36\n4/36\n\n\n4\n-\n-\n-\n1/36\n2/36\n3/36\n\n\n5\n-\n-\n-\n-\n1/36\n2/36\n\n\n6\n-\n-\n-\n-\n-\n1/36\n\n\n\n2. Probabilit√† richieste\n\n\n\\(P(X = 3, Y = 5) = 3/36\\).\n\n\\(P(X \\geq 3, Y \\leq 4) = P(X = 3, Y = 3) + P(X = 3, Y = 4) + P(X = 4, Y = 4) = 1/36 + 2/36 + 1/36 = 4/36 = 1/9\\).\n\nEsercizio 5: Differenza tra due dadi\nAbbiamo:\n\n\n\\(X\\) = primo lancio.\n\n\\(Y = |X - X_2|\\).\n\n1. Tabella della distribuzione congiunta \\(P(X, Y)\\)\n\\(Y\\) assume valori da 0 a 5, a seconda della differenza tra i due dadi:\n\n\n\n\\(X\\) ¬†\\(Y\\)\n\n0\n1\n2\n3\n4\n5\n\n\n\n1\n1/6\n1/6\n1/6\n1/6\n1/6\n1/6\n\n\n2\n1/6\n2/6\n1/6\n1/6\n1/6\n0\n\n\n3\n1/6\n2/6\n2/6\n1/6\n0\n0\n\n\n4\n1/6\n2/6\n2/6\n1/6\n0\n0\n\n\n5\n1/6\n2/6\n1/6\n1/6\n0\n0\n\n\n6\n1/6\n1/6\n1/6\n1/6\n0\n0\n\n\n\n2. Distribuzione marginale di \\(Y\\)\nSommiamo lungo \\(X\\):\n\n\n\\(Y\\)\n\\(P(Y)\\)\n\n\n\n0\n6/36\n\n\n1\n10/36\n\n\n2\n8/36\n\n\n3\n6/36\n\n\n4\n4/36\n\n\n5\n2/36\n\n\n\n3. Probabilit√† richieste\n\n\n\\(P(Y = 0) = 6/36 = 1/6\\).\n\n\\(P(Y = 3) = 6/36 = 1/6\\).\n\n4. Indipendenza di \\(X\\) e \\(Y\\)\nCome nell‚Äôesercizio 3, verifichiamo che \\(P(X, Y) \\neq P(X) P(Y)\\) per alcune coppie. Essendo la tabella non simmetrica, \\(X\\) e \\(Y\\) non sono indipendenti.\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nConsidera il seguente esperimento casuale: si estrae una pallina da un‚Äôurna contenente tre palline numerate con i valori \\(1\\), \\(2\\) e \\(3\\).\nDopo l‚Äôestrazione, si definiscono due variabili casuali:\n\n\n\\(X\\), il valore della pallina estratta.\n\n\\(Y\\), il valore di un‚Äôaltra variabile definita come \\(Y = X^2\\).\n\n\nCostruisci la distribuzione congiunta di \\(X\\) e \\(Y\\).\nCalcola il valore atteso di \\(X\\) e \\(Y\\), ossia \\(E[X]\\) e \\(E[Y]\\).\nCalcola la covarianza tra \\(X\\) e \\(Y\\), ossia \\(\\text{Cov}(X, Y)\\).\nCalcola la correlazione tra \\(X\\) e \\(Y\\), ossia \\(\\rho(X, Y)\\).\nInterpreta il valore della correlazione: cosa indica il segno e il valore ottenuto?\n\n\n\n\n\n\n\n\n\n\nSoluzioni 2\n\n\n\n\n\n1. Distribuzione congiunta di \\(X\\) e \\(Y\\)\nPoich√© ogni pallina ha la stessa probabilit√† di essere estratta, la distribuzione congiunta √®:\n\n\n\\(X\\)\n\\(Y = X^2\\)\n\\(P(X, Y)\\)\n\n\n\n1\n1\n\\(\\frac{1}{3}\\)\n\n\n2\n4\n\\(\\frac{1}{3}\\)\n\n\n3\n9\n\\(\\frac{1}{3}\\)\n\n\n\n2. Calcolo di \\(E[X]\\) e \\(E[Y]\\)\n\\[\nE[X] = \\sum_{i} x_i P(X = x_i) = 1 \\cdot \\frac{1}{3} + 2 \\cdot \\frac{1}{3} + 3 \\cdot \\frac{1}{3} = \\frac{1 + 2 + 3}{3} = 2\n\\]\n\\[\nE[Y] = \\sum_{i} y_i P(Y = y_i) = 1 \\cdot \\frac{1}{3} + 4 \\cdot \\frac{1}{3} + 9 \\cdot \\frac{1}{3} = \\frac{1 + 4 + 9}{3} = \\frac{14}{3}\n\\]\n3. Calcolo della covarianza \\(\\text{Cov}(X, Y)\\)\nLa covarianza √® definita come:\n\\[\n\\text{Cov}(X, Y) = E[XY] - E[X]E[Y]\n\\]\nPrima calcoliamo \\(E[XY]\\):\n\\[\nE[XY] = \\sum_{i} x_i y_i P(X = x_i, Y = y_i) = 1 \\cdot 1 \\cdot \\frac{1}{3} + 2 \\cdot 4 \\cdot \\frac{1}{3} + 3 \\cdot 9 \\cdot \\frac{1}{3}\n\\]\n\\[\n= \\frac{1 + 8 + 27}{3} = \\frac{36}{3} = 12\n\\]\nOra possiamo calcolare la covarianza:\n\\[\n\\text{Cov}(X, Y) = E[XY] - E[X]E[Y] = 12 - \\left(2 \\cdot \\frac{14}{3}\\right) = 12 - \\frac{28}{3} = \\frac{36 - 28}{3} = \\frac{8}{3}\n\\]\n4. Calcolo della correlazione \\(\\rho(X, Y)\\)\nLa correlazione √® definita come:\n\\[\n\\rho(X, Y) = \\frac{\\text{Cov}(X, Y)}{\\sigma_X \\cdot \\sigma_Y}\n\\]\nCalcoliamo prima le varianze:\n\\[\n\\text{Var}(X) = E[X^2] - (E[X])^2\n\\]\n\\[\nE[X^2] = 1^2 \\cdot \\frac{1}{3} + 2^2 \\cdot \\frac{1}{3} + 3^2 \\cdot \\frac{1}{3} = \\frac{1 + 4 + 9}{3} = \\frac{14}{3}\n\\]\n\\[\n\\text{Var}(X) = \\frac{14}{3} - 2^2 = \\frac{14}{3} - 4 = \\frac{14 - 12}{3} = \\frac{2}{3}\n\\]\nOra la varianza di \\(Y\\):\n\\[\n\\text{Var}(Y) = E[Y^2] - (E[Y])^2\n\\]\n\\[\nE[Y^2] = 1^2 \\cdot \\frac{1}{3} + 4^2 \\cdot \\frac{1}{3} + 9^2 \\cdot \\frac{1}{3} = \\frac{1 + 16 + 81}{3} = \\frac{98}{3}\n\\]\n\\[\n\\text{Var}(Y) = \\frac{98}{3} - \\left(\\frac{14}{3}\\right)^2 = \\frac{98}{3} - \\frac{196}{9} = \\frac{98 \\cdot 3 - 196}{9} = \\frac{294 - 196}{9} = \\frac{98}{9}\n\\]\nCalcoliamo le deviazioni standard:\n\\[\n\\sigma_X = \\sqrt{\\text{Var}(X)} = \\sqrt{\\frac{2}{3}} = \\frac{\\sqrt{6}}{3}\n\\]\n\\[\n\\sigma_Y = \\sqrt{\\text{Var}(Y)} = \\sqrt{\\frac{98}{9}} = \\frac{\\sqrt{98}}{3}\n\\]\nOra possiamo calcolare la correlazione:\n\\[\n\\rho(X, Y) = \\frac{\\text{Cov}(X, Y)}{\\sigma_X \\cdot \\sigma_Y} = \\frac{\\frac{8}{3}}{\\frac{\\sqrt{6}}{3} \\cdot \\frac{\\sqrt{98}}{3}}\n\\]\n\\[\n= \\frac{\\frac{8}{3}}{\\frac{\\sqrt{6 \\cdot 98}}{9}} = \\frac{8 \\cdot 9}{3 \\cdot \\sqrt{6 \\cdot 98}} = \\frac{24}{\\sqrt{588}}\n\\]\nPoich√© \\(\\sqrt{588} = \\sqrt{4 \\cdot 147} = 2\\sqrt{147} = 2\\sqrt{49 \\cdot 3} = 2 \\cdot 7 \\cdot \\sqrt{3} = 14\\sqrt{3}\\):\n\\[\n\\rho(X, Y) = \\frac{24}{14\\sqrt{3}} = \\frac{12}{7\\sqrt{3}} = \\frac{12\\sqrt{3}}{21} \\approx 0.995\n\\]\n5. Interpretazione della correlazione\n\nIl valore \\(\\rho(X, Y) \\approx 0.995\\) √® molto vicino a 1, indicando una correlazione positiva quasi perfetta tra \\(X\\) e \\(Y\\).\nIl segno positivo indica che all‚Äôaumentare di \\(X\\), anche \\(Y\\) tende ad aumentare.\nL‚Äôalto valore (prossimo a 1) indica che la relazione tra \\(X\\) e \\(Y\\) √® quasi perfettamente lineare, il che √® coerente con la definizione \\(Y = X^2\\) nell‚Äôintervallo considerato (piccoli valori positivi di \\(X\\)).\n\n\n\n\n\n\n\n\n\n\nProblemi 3\n\n\n\n\n\nEsercizi sulla distribuzione di probabilit√† congiunta sono disponibili sulla seguente pagina web.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_joint_prob.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/11_joint_prob.html#informazioni-sullambiente-di-sviluppo",
    "title": "35¬† Probabilit√† congiunta",
    "section": "\n35.11 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "35.11 Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.5.3     \n#&gt;  [9] scales_1.3.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.9.1   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         rlang_1.1.5       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       tools_4.4.2       parallel_4.4.2    tzdb_0.5.0       \n#&gt; [21] colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5       R6_2.6.1         \n#&gt; [25] lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.1    \n#&gt; [29] gtable_0.3.6      glue_1.8.0        xfun_0.51         tidyselect_1.2.1 \n#&gt; [33] rstudioapi_0.17.1 farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-167     \n#&gt; [37] rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_joint_prob.html#bibliografia",
    "href": "chapters/probability/11_joint_prob.html#bibliografia",
    "title": "35¬† Probabilit√† congiunta",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlitzstein, J. K., & Hwang, J. (2019). Introduction to probability. CRC Press.\n\n\nChan, J. C. C., & Kroese, D. P. (2025). Statistical Modeling and Computation (2¬™ ed.). Springer.\n\n\nMartin, O. (2024). Bayesian analysis with python. Packt Publishing Ltd.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11a_intro_distributions.html",
    "href": "chapters/probability/11a_intro_distributions.html",
    "title": "36¬† Introduzione alle distribuzioni di probabilit√†",
    "section": "",
    "text": "36.1 Introduzione\nLe distribuzioni di probabilit√† ‚Äì discrete (a massa) e continue (a densit√†) ‚Äì rappresentano un pilastro dell‚Äôanalisi quantitativa. Strumenti come la distribuzione normale o binomiale non sono semplici modelli teorici, ma strutture matematiche che permettono di decodificare fenomeni dominati dalla variabilit√†. In psicologia, disciplina focalizzata sulla comprensione della mente e del comportamento, potrebbe apparire paradossale ricorrere a questi strumenti che sembrano lontani dai fenomeni oggetti del nostro interesse. Tuttavia, √® proprio l‚Äôintrinseca variabilit√† dei processi psicologici a renderli indispensabili: senza modelli in grado di mappare e interpretare la variabilit√†, ogni generalizzazione rischia di ridursi a un‚Äôapprossimazione inefficace.\nQuesta riflessione √® ben espressa in un recente articolo di Segal et al. (2025) sui disturbi mentali. L‚Äôautore osserva come i limiti nella comprensione della loro eziologia derivino dalla sottovalutazione della variabilit√†. Storicamente, la ricerca in psichiatria e psicologia ha confrontato gruppi clinici con controlli sani, identificando marcatori medi (biologici o comportamentali) come tratti distintivi. Sebbene utile, questo approccio trascura un dato fondamentale: i disturbi psichiatrici, come gran parte dei fenomeni psicologici, sono caratterizzati da un‚Äôeterogeneit√† interindividuale estrema, incompatibile con modelli basati su medie di gruppo.\nLa variabilit√†, dunque, non √® un ‚Äúdisturbo di fondo‚Äù da eliminare, ma un elemento informativo cruciale. Integrare questa prospettiva richiede non solo strumenti statistici avanzati, ma una riconfigurazione metodologica che ponga la diversit√† individuale al centro dell‚Äôindagine.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>36</span>¬† <span class='chapter-title'>Introduzione alle distribuzioni di probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11a_intro_distributions.html#la-variabilit√†-come-fattore-costitutivo-dei-disturbi-mentali",
    "href": "chapters/probability/11a_intro_distributions.html#la-variabilit√†-come-fattore-costitutivo-dei-disturbi-mentali",
    "title": "36¬† Introduzione alle distribuzioni di probabilit√†",
    "section": "\n36.2 La Variabilit√† come Fattore Costitutivo dei Disturbi Mentali",
    "text": "36.2 La Variabilit√† come Fattore Costitutivo dei Disturbi Mentali\nI disturbi psichiatrici sfuggono a definizioni rigide. Persone con la stessa diagnosi mostrano profili sintomatologici radicalmente diversi: ad esempio, nel disturbo da stress post-traumatico si osservano oltre 636.000 possibili combinazioni di sintomi, mentre nella depressione pi√π di 16.000. Uno studio discusso da Segal et al. (2025) rivela che quasi il 50% dei pazienti depressi presenta un‚Äôunica configurazione di sintomi. Questa variabilit√† si estende all‚Äôet√† di esordio, alla gravit√†, alla durata e alla dinamica temporale dei sintomi.\nUn singolo sintomo pu√≤ inoltre comparire in pi√π disturbi, spiegando i tassi elevati di comorbilit√†: circa il 50% dei pazienti soddisfa criteri diagnostici multipli. Questa sovrapposizione suggerisce che i disturbi non siano entit√† discrete, ma manifestazioni diverse di meccanismi psicopatologici condivisi. Non a caso, il 37% dei sintomi presenti nel DSM-5 non √® specifico di un singolo disturbo e, complessivamente, rappresenta il 72% di tutti i sintomi inclusi nei criteri diagnostici, evidenziando una significativa mancanza di specificit√† sintomatologica.\nFocalizzarsi sulle medie di gruppo, tuttavia, rischia di occultare questa complessit√†, producendo risultati inconsistenti. Come osservato da Thomas Insel nel riepilogare il suo mandato alla guida dei National Institutes of Mental Health (NIMH) degli Stati Uniti, nonostante i consistenti investimenti in neuroscienze e genetica, i progressi nella riduzione dei suicidi, nella diminuzione dei ricoveri e nel miglioramento delle prognosi sono stati limitati.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>36</span>¬† <span class='chapter-title'>Introduzione alle distribuzioni di probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11a_intro_distributions.html#verso-un-cambiamento-di-prospettiva",
    "href": "chapters/probability/11a_intro_distributions.html#verso-un-cambiamento-di-prospettiva",
    "title": "36¬† Introduzione alle distribuzioni di probabilit√†",
    "section": "\n36.3 Verso un Cambiamento di Prospettiva",
    "text": "36.3 Verso un Cambiamento di Prospettiva\nPer superare queste criticit√†, secondo Segal et al. (2025), √® necessario riconoscere la variabilit√† come propriet√† costitutiva dei fenomeni psicologici. Ci√≤ implica:\n\n\nAdottare approcci analitici che quantifichino la variabilit√† biologica e comportamentale a livello individuale, anzich√© di gruppo.\n\n\nUtilizzare modelli normativi per identificare deviazioni significative dalle traiettorie attese, anzich√© classificare soggetti in categorie rigide.\n\n\nAbbandonare l‚Äôidea di causalit√† univoca: una singola regione cerebrale pu√≤ contribuire a sintomi multipli, cos√¨ come meccanismi eterogenei possono generare lo stesso disturbo.\n\n\nAdottare framework dimensionali come l‚ÄôHiTOP (Hierarchical Taxonomy of Psychopathology), che organizza i sintomi in dimensioni gerarchiche, massimizzando la cattura della variabilit√† fenotipica.\n\nIn questo contesto, le distribuzioni di probabilit√† diventano alleati indispensabili. Consentono di modellare la dispersione dei dati, identificare outlier e mappare traiettorie individuali, trasformando la variabilit√† da ‚Äúproblema‚Äù a ‚Äúchiave interpretativa‚Äù. Analizzare la distribuzione di sintomi, tratti o risposte comportamentali permette di superare le medie di gruppo, consentendoci una migliore comprensione dei fenomeni psicologici.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>36</span>¬† <span class='chapter-title'>Introduzione alle distribuzioni di probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11a_intro_distributions.html#riflessioni-conclusive",
    "href": "chapters/probability/11a_intro_distributions.html#riflessioni-conclusive",
    "title": "36¬† Introduzione alle distribuzioni di probabilit√†",
    "section": "\n36.4 Riflessioni Conclusive",
    "text": "36.4 Riflessioni Conclusive\nLa teoria della probabilit√† offre gli strumenti concettuali per navigare la complessit√† dei dati psicologici. Come sottolineato da Segal et al. (2025), solo integrando sistematicamente la variabilit√† nell‚Äôanalisi empirica √® possibile sviluppare modelli predittivi robusti e interventi terapeutici mirati. La sfida non √® eliminare l‚Äôincertezza, ma rendere conto della variabilit√† attraverso modelli che riflettano la complessit√† dei fenomeni psicologici.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>36</span>¬† <span class='chapter-title'>Introduzione alle distribuzioni di probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11a_intro_distributions.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/11a_intro_distributions.html#informazioni-sullambiente-di-sviluppo",
    "title": "36¬† Introduzione alle distribuzioni di probabilit√†",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.5.3     \n#&gt;  [9] scales_1.3.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.9.1   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         rlang_1.1.5       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       tools_4.4.2       parallel_4.4.2    tzdb_0.5.0       \n#&gt; [21] colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5       R6_2.6.1         \n#&gt; [25] lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.1    \n#&gt; [29] gtable_0.3.6      glue_1.8.0        xfun_0.51         tidyselect_1.2.1 \n#&gt; [33] rstudioapi_0.17.1 farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-167     \n#&gt; [37] rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>36</span>¬† <span class='chapter-title'>Introduzione alle distribuzioni di probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11a_intro_distributions.html#bibliografia",
    "href": "chapters/probability/11a_intro_distributions.html#bibliografia",
    "title": "36¬† Introduzione alle distribuzioni di probabilit√†",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nSegal, A., Tiego, J., Parkes, L., Holmes, A. J., Marquand, A. F., & Fornito, A. (2025). Embracing variability in the search for biological mechanisms of psychiatric illness. Trends in Cognitive Sciences, 29(1), 85‚Äì99.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>36</span>¬† <span class='chapter-title'>Introduzione alle distribuzioni di probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_discr_rv_distr.html",
    "href": "chapters/probability/12_discr_rv_distr.html",
    "title": "37¬† Distribuzioni di v.c. discrete",
    "section": "",
    "text": "37.1 Introduzione\n√à importante distinguere tra variabili casuali discrete e continue, perch√© le distribuzioni di probabilit√† associate sono molto diverse nei due casi.\nIn questo capitolo ci focalizzeremo sulle distribuzioni di probabilit√† discrete, strumenti fondamentali per modellare fenomeni aleatori che generano un numero finito o numerabile di possibili esiti. Queste distribuzioni risultano particolarmente efficaci per descrivere eventi che si verificano in contesti discreti, come il numero di successi in un esperimento, l‚Äôoccorrenza di un evento, o la selezione casuale da un insieme di opzioni finite.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>37</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_discr_rv_distr.html#introduzione",
    "href": "chapters/probability/12_discr_rv_distr.html#introduzione",
    "title": "37¬† Distribuzioni di v.c. discrete",
    "section": "",
    "text": "37.1.1 Definizione di una Variabile Casuale Discreta\n\nDefinizione 37.1 Una variabile casuale \\(X\\) si dice avere una distribuzione discreta se assume valori in un insieme finito o numerabile di punti \\(\\{x_1, x_2, \\dots\\}\\), e per ciascun valore \\(x_i\\) nell‚Äôinsieme, la probabilit√† \\(P(X = x_i) &gt; 0\\). Inoltre, la somma delle probabilit√† associate a tutti i possibili valori di \\(X\\) deve essere uguale a 1, ovvero:\n\\[\n\\sum_{i} P(X = x_i) = 1.\n\\]\nLa funzione di massa di probabilit√† (o probability mass function, PMF) di \\(X\\), denotata con \\(f(x)\\), √® definita come:\n\\[\nf(x) = P(X = x),\n\\]\ndove \\(f(x) \\geq 0\\) per ogni \\(x\\) e \\(f(x) = 0\\) per tutti i valori \\(x\\) che non appartengono all‚Äôinsieme dei valori possibili di \\(X\\).\n\n\n37.1.2 Caratteristiche delle distribuzioni discrete\nUna distribuzione discreta √® caratterizzata da:\n\nun insieme finito o infinito numerabile di valori possibili per \\(X\\);\nuna probabilit√† positiva associata a ciascun valore possibile;\nla propriet√† che la somma delle probabilit√† su tutti i valori possibili √® pari a 1.\n\nLa funzione \\(f(x)\\) rappresenta quindi la probabilit√† che \\(X\\) assuma esattamente il valore \\(x\\). Per esempio, se \\(X\\) rappresenta il numero di teste ottenute lanciando una moneta tre volte, i possibili valori di \\(X\\) sono \\(\\{0, 1, 2, 3\\}\\), e la funzione \\(f(x)\\) specifica la probabilit√† di ciascuno di questi risultati.\nIn sintesi, una distribuzione discreta descrive fenomeni in cui le variabili casuali possono assumere solo valori isolati, e la funzione di massa di probabilit√† fornisce una descrizione completa della distribuzione di probabilit√† di \\(X\\).\n\n37.1.3 Panoramica delle Distribuzioni Discrete\nDi seguito, vengono presentate alcune delle principali distribuzioni discrete utilizzate in statistica e nella ricerca psicologica Ogni distribuzione √® descritta in termini di caratteristiche fondamentali, applicazioni pratiche e importanza teorica.\n\n37.1.3.1 Distribuzione di Bernoulli\n\n\nDescrizione: La distribuzione di Bernoulli modella esperimenti con due possibili esiti, generalmente etichettati come ‚Äúsuccesso‚Äù (con probabilit√† \\(p\\)) e ‚Äúfallimento‚Äù (con probabilit√† \\(1-p\\)).\n\nApplicazioni: Si applica a situazioni binarie, come il lancio di una moneta (testa/croce), la risposta a domande dicotomiche (s√¨/no), o l‚Äôesito di un evento che pu√≤ verificarsi o meno.\n\nParametro:\n\n\n\\(p\\): probabilit√† di successo.\n\n\n\nImportanza: Costituisce la base per molte altre distribuzioni discrete, come la distribuzione binomiale e geometrica. √à fondamentale per comprendere fenomeni con esiti dichotomici.\n\n37.1.3.2 Distribuzione Binomiale\n\n\nDescrizione: La distribuzione binomiale descrive il numero totale di successi in un numero fisso \\(n\\) di prove indipendenti, ciascuna governata da una distribuzione di Bernoulli con probabilit√† di successo \\(p\\).\n\nApplicazioni: Viene utilizzata per analizzare processi ripetuti con esiti binari, ad esempio:\n\nIl numero di voti favorevoli in un campione di opinione.\nIl numero di sintomi osservati in un gruppo di pazienti.\nIl conteggio di errori in un test di accuratezza.\n\n\n\nParametri:\n\n\n\\(n\\): numero di prove.\n\n\\(p\\): probabilit√† di successo in ogni prova.\n\n\n\nImportanza: Fornisce uno strumento essenziale per modellare fenomeni ripetuti in condizioni identiche, consentendo analisi probabilistiche avanzate e previsioni statistiche.\n\n37.1.3.3 Distribuzione di Poisson\n\n\nDescrizione: La distribuzione di Poisson modella il numero di eventi che si verificano in un intervallo fissato di tempo o spazio, quando tali eventi sono rari, indipendenti e accadono a un tasso medio costante \\(\\lambda\\).\n\nApplicazioni: Trova impiego in contesti dove gli eventi sono sporadici ma prevedibili, ad esempio:\n\nIl numero di episodi di ansia riportati in una settimana.\nIl numero di interazioni sociali spontanee di un bambino con disturbo dello spettro autistico durante una sessione di osservazione.\nLa frequenza di lapsus verbali durante una presentazione pubblica.\nIl numero di sogni vividi riportati durante una serie di notti consecutive in uno studio sul sonno.\n\n\n\nParametro:\n\n\n\\(\\lambda\\): tasso medio di eventi per unit√† di tempo o spazio.\n\n\n\nImportanza: √à cruciale per analizzare fenomeni psicologici o comportamentali rari ma significativi. Aiuta a comprendere i meccanismi sottostanti e a modellare la variabilit√† osservata in contesti clinici, sperimentali o quotidiani.\n\n37.1.3.4 Distribuzione Uniforme Discreta\n\n\nDescrizione: La distribuzione uniforme discreta rappresenta situazioni in cui tutti gli eventi all‚Äôinterno di un insieme finito hanno la stessa probabilit√† di verificarsi.\n\nApplicazioni: Si applica in contesti di scelta casuale equiprobabile, come:\n\nLa selezione casuale di uno stimolo da una lista di parole in un esperimento di memoria.\nL‚Äôassegnazione casuale di partecipanti a gruppi sperimentali in uno studio di psicologia sociale.\nLa scelta di un‚Äôimmagine tra un insieme di stimoli visivi in una ricerca sull‚Äôattenzione.\nLa probabilit√† uniforme che un partecipante scelga una delle opzioni in un questionario a risposte multiple, in assenza di preferenze o conoscenze specifiche.\n\n\n\nParametri:\n\nIntervallo di supporto: l‚Äôinsieme finito di valori possibili (ad esempio, \\(\\{1, 2, \\dots, k\\}\\)).\n\n\n\nImportanza: Funziona come modello di riferimento in situazioni di massima incertezza o mancanza di preferenze. √à utile per definire un punto di partenza in analisi pi√π complesse e per studiare comportamenti casuali.\n\nIn conclusione, le distribuzioni discrete sopra descritte rappresentano strumenti fondamentali per modellare una vasta gamma di fenomeni osservati in ambito scientifico, psicologico e applicativo. Ciascuna distribuzione offre una cornice teorica ben definita per interpretare e analizzare situazioni caratterizzate da variabili aleatorie discrete, fornendo cos√¨ le basi per inferenze statistiche robuste e previsioni quantitative affidabili.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>37</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_discr_rv_distr.html#distribuzioni-in-r",
    "href": "chapters/probability/12_discr_rv_distr.html#distribuzioni-in-r",
    "title": "37¬† Distribuzioni di v.c. discrete",
    "section": "\n37.2 Distribuzioni in R",
    "text": "37.2 Distribuzioni in R\nIn R, per ogni distribuzione sono disponibili quattro funzioni principali, i cui nomi iniziano con le lettere:\n\n\nd (density): per calcolare i valori teorici relativi alla distribuzione,\n\n\np (probability): per ottenere la probabilit√† cumulativa,\n\n\nq (quantile): per determinare i quantili,\n\n\nr (random): per generare campioni casuali.\n\nIl pacchetto di base stats include numerose funzioni dedicate alle principali distribuzioni statistiche, permettendo di calcolare valori teorici e simulare dati in modo semplice e flessibile. Per ulteriori dettagli sulle distribuzioni disponibili e sull‚Äôuso delle relative funzioni, √® possibile consultare la documentazione con il comando ?Distributions.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>37</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_discr_rv_distr.html#distribuzione-di-bernoulli-1",
    "href": "chapters/probability/12_discr_rv_distr.html#distribuzione-di-bernoulli-1",
    "title": "37¬† Distribuzioni di v.c. discrete",
    "section": "\n37.3 Distribuzione di Bernoulli",
    "text": "37.3 Distribuzione di Bernoulli\nIn statistica, un esperimento che ammette solo due esiti possibili √® modellato attraverso quella che viene chiamata ‚Äúprova Bernoulliana‚Äù. Un esempio tipico √® il lancio di una moneta, che pu√≤ dare come risultato testa o croce.\n\nDefinizione 37.2 Una variabile casuale \\(X\\) che assume valori in \\(\\{0, 1\\}\\) √® detta variabile di Bernoulli. La sua distribuzione di probabilit√† √® definita come:\n\\[\nP(X \\mid \\theta) =\n  \\begin{cases}\n    p     & \\text{se $X = 1$ (successo)}, \\\\\n    1 - p & \\text{se $X = 0$ (insuccesso)},\n  \\end{cases}\n\\]\ndove \\(0 \\leq p \\leq 1\\). Il parametro \\(p\\) rappresenta la probabilit√† del ‚Äúsuccesso‚Äù (\\(X = 1\\)), mentre \\(1 - p\\) √® la probabilit√† dell‚Äô‚Äúinsuccesso‚Äù (\\(X = 0\\)).\n\nLa distribuzione di Bernoulli descrive quindi un contesto in cui la probabilit√† di osservare l‚Äôesito 1 √® \\(p\\) e quella di osservare l‚Äôesito 0 √® \\(1 - p\\). Viene utilizzata per modellare situazioni binarie, come una risposta ‚Äús√¨‚Äù o ‚Äúno‚Äù, oppure un ‚Äúsuccesso‚Äù o ‚Äúinsuccesso‚Äù.\nCalcolando il valore atteso e la varianza, otteniamo:\n\\[\n\\begin{align}\n\\mathbb{E}(X) &= 0 \\cdot P(X=0) + 1 \\cdot P(X=1) = p, \\\\\n\\mathbb{V}(X) &= (0 - p)^2 \\cdot P(X=0) + (1 - p)^2 \\cdot P(X=1) = p(1-p).\n\\end{align}\n\\tag{37.1}\\]\n\n\n\n\n\n\nDimostrazione\n\n\n\nEsaminiamo la dimostrazione algebrica del calcolo della varianza.\nEspandiamo il calcolo della somma, considerando i due possibili valori di \\(X\\) (0 e 1).\n\n\nPrimo termine (\\(X = 0\\)):\n\\[\n(0 - \\mathbb{E}(X))^2 \\cdot P(X = 0) = (0 - p)^2 \\cdot (1 - p).\n\\]\nSemplificando \\((0 - p)^2 = p^2\\), quindi:\n\\[\n(0 - \\mathbb{E}(X))^2 \\cdot P(X = 0) = p^2 \\cdot (1 - p).\n\\]\n\n\nSecondo termine (\\(X = 1\\)):\n\\[\n(1 - \\mathbb{E}(X))^2 \\cdot P(X = 1) = (1 - p)^2 \\cdot p.\n\\]\nSemplificando \\((1 - p)^2 = 1 - 2p + p^2\\), quindi:\n\\[\n(1 - \\mathbb{E}(X))^2 \\cdot P(X = 1) = (1 - 2p + p^2) \\cdot p = p - 2p^2 + p^3.\n\\]\n\n\nSomma dei termini\nOra sommiamo i due contributi:\n\\[\n\\mathbb{V}(X) = p^2 \\cdot (1 - p) + (p - 2p^2 + p^3).\n\\]\nEspandendo il primo termine:\n\\[\np^2 \\cdot (1 - p) = p^2 - p^3.\n\\]\nSomma completa:\n\\[\n\\mathbb{V}(X) = (p^2 - p^3) + (p - 2p^2 + p^3).\n\\]\n\n\nRaggruppiamo i termini\n\\[\n\\mathbb{V}(X) = p - p^2.\n\\]\nRisultato finale:\n\\[\n\\mathbb{V}(X) = p(1 - p).\n\\]\n\n\nIn sintesi, la varianza di una variabile aleatoria binaria \\(X\\), distribuita secondo Bernoulli con parametro \\(p\\), √® data da \\(p(1-p)\\).\n\n\nTale risultato mostra come la varianza massima si ottenga per \\(p = 0.5\\), condizione che corrisponde alla massima incertezza intrinseca nel processo, ossia quando la probabilit√† di successo eguaglia quella di insuccesso.\n\n# Valori di p tra 0 e 1\np &lt;- seq(0, 1, length.out = 100)\nvariance &lt;- p * (1 - p)\ndata &lt;- data.frame(p = p, Variance = variance)\n\n# Creazione del grafico\nggplot(data, aes(x = p, y = Variance)) +\n  geom_line(color = \"blue\", linewidth = 1.2) +\n  labs(\n    x = expression(p),\n    y = \"Varianza\",\n    title = \"Varianza di una Variabile Bernoulliana in funzione di p\"\n  )\n\n\n\n\n\n\n\n\n37.3.1 Notazione\nPer indicare che la variabile casuale \\(X\\) segue una distribuzione Bernoulliana di parametro \\(p\\) Utilizziamo la notazione \\(X \\sim \\mathcal{Bern}(p)\\), o in maniera equivalente \\(\\mathcal{Bern}(X \\mid p)\\).\n\nEsempio 37.1 Nel caso del lancio di una moneta equilibrata, la variabile di Bernoulli assume i valori \\(0\\) e \\(1\\) con uguale probabilit√† di \\(\\frac{1}{2}\\). Pertanto, la funzione di massa di probabilit√† assegna una probabilit√† di \\(\\frac{1}{2}\\) sia per \\(X = 0\\) che per \\(X = 1\\), mentre la funzione di distribuzione cumulativa risulta essere \\(\\frac{1}{2}\\) per \\(X = 0\\) e \\(1\\) per \\(X = 1\\).\nGeneriamo dei valori casuali dalla distribuzione di Bernoulli. Iniziamo con un singolo valore:\n\n# Probabilit√† di successo\np &lt;- 0.5\n\n# Genera un singolo valore\nbernoulli_sample &lt;- rbinom(n = 1, size = 1, prob = p)\nprint(bernoulli_sample)\n#&gt; [1] 1\n\n# Genera un campione di 10 valori\nbernoulli_sample &lt;- rbinom(n = 10, size = 1, prob = p)\nprint(bernoulli_sample)\n#&gt;  [1] 1 0 1 1 1 1 0 1 1 0",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>37</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_discr_rv_distr.html#distribuzione-binomiale-1",
    "href": "chapters/probability/12_discr_rv_distr.html#distribuzione-binomiale-1",
    "title": "37¬† Distribuzioni di v.c. discrete",
    "section": "\n37.4 Distribuzione Binomiale",
    "text": "37.4 Distribuzione Binomiale\nLa distribuzione binomiale √® una distribuzione di probabilit√† discreta che modella il numero di successi \\(y\\) in un numero fissato \\(n\\) di prove di Bernoulli indipendenti e identiche, dove ciascuna prova ha solo due esiti possibili: ‚Äúsuccesso‚Äù (rappresentato da ‚Äú1‚Äù) con probabilit√† \\(p\\) o ‚Äúinsuccesso‚Äù (rappresentato da ‚Äú0‚Äù) con probabilit√† \\(1 - p\\). La notazione utilizzata √® la seguente:\n\\[\nY \\sim \\mathcal{Binom}(n, p).\n\\]\n\nDefinizione 37.3 La distribuzione binomiale descrive la probabilit√† di osservare esattamente \\(y\\) successi in \\(n\\) prove di Bernoulli indipendenti:\n\\[\nP(Y = y) = \\binom{n}{y} p^{y} (1 - p)^{n - y} = \\frac{n!}{y!(n - y)!} p^{y} (1 - p)^{n - y},\n\\tag{37.2}\\]\ndove \\(\\binom{n}{y}\\), noto come coefficiente binomiale, rappresenta il numero di modi possibili per ottenere \\(y\\) successi in \\(n\\) prove, e \\(p\\) √® la probabilit√† di successo in ciascuna prova.\n\nLa distribuzione binomiale si presta bene a esempi classici come il lancio ripetuto di una moneta o l‚Äôestrazione di biglie da un‚Äôurna. Ad esempio, nel caso del lancio di una moneta, questa distribuzione descrive la probabilit√† di ottenere un determinato numero di ‚Äúteste‚Äù in un certo numero di lanci, con ogni lancio che segue una distribuzione di Bernoulli con probabilit√† di successo \\(p\\).\nUna caratteristica interessante della distribuzione binomiale √® la sua propriet√† di riproducibilit√†: se due variabili casuali indipendenti, \\(y_1\\) e \\(y_2\\), seguono entrambe distribuzioni binomiali con lo stesso parametro \\(p\\), ma con un diverso numero di prove (\\(n_1\\) e \\(n_2\\)), la loro somma, \\(y = y_1 + y_2\\), sar√† ancora distribuita binomialmente, con parametri \\(n_1 + n_2\\) e \\(p\\).\n\n37.4.1 Calcolo delle Probabilit√†\nPer chiarire il calcolo delle probabilit√† nella distribuzione binomiale, consideriamo una serie di prove di Bernoulli. Supponiamo di avere \\(n\\) prove, con \\(y\\) successi. La configurazione di questi risultati pu√≤ essere rappresentata come:\n\\[\n\\overbrace{SS\\dots S}^\\text{$y$ successi} \\overbrace{II\\dots I}^\\text{$n - y$ insuccessi}\n\\]\nLa probabilit√† di ottenere esattamente \\(y\\) successi in una sequenza specifica di prove √® pari a:\n\\[\np^y \\cdot (1 - p)^{n - y},\n\\]\ndove \\(p^y\\) √® la probabilit√† di ottenere \\(y\\) successi, e \\((1 - p)^{n - y}\\) √® la probabilit√† di ottenere \\(n - y\\) insuccessi.\nTuttavia, siamo interessati alla probabilit√† complessiva di ottenere esattamente \\(y\\) successi in qualsiasi ordine. Il numero di modi in cui ci√≤ pu√≤ avvenire √® dato dal coefficiente binomiale \\(\\binom{n}{y}\\), che rappresenta tutte le possibili disposizioni dei successi e degli insuccessi nelle \\(n\\) prove.\nQuindi, moltiplicando la probabilit√† di una singola sequenza per il numero di sequenze possibili, otteniamo la probabilit√† di osservare esattamente \\(y\\) successi:\n\\[\nP(Y = y) = \\binom{n}{y} p^y (1 - p)^{n - y}.\n\\]\nQuesto risultato corrisponde alla formula della distribuzione binomiale.\n\n37.4.2 Caso particolare \\(n = 1\\)\n\nOra consideriamo il caso particolare in cui \\(n = 1\\). Quando \\(n = 1\\), il coefficiente binomiale diventa:\n\\[\n\\binom{1}{k} = \\frac{1!}{k! (1-k)!}.\n\\]\nEspandiamo i fattoriali per i due possibili valori di \\(k\\), che pu√≤ assumere solo 0 o 1 (poich√© \\(k \\in \\{0, 1, \\dots, n\\}\\)).\nCaso 1: \\(k = 0\\)\n\\[\n\\binom{1}{0} = \\frac{1!}{0! (1-0)!} = \\frac{1}{1 \\cdot 1} = 1.\n\\]\nQuindi, per \\(k = 0\\): \\[\nP(X = 0) = \\binom{1}{0} p^0 (1-p)^{1-0} = 1 \\cdot 1 \\cdot (1-p) = 1-p.\n\\]\nCaso 2: \\(k = 1\\)\n\\[\n\\binom{1}{1} = \\frac{1!}{1! (1-1)!} = \\frac{1}{1 \\cdot 1} = 1.\n\\]\nQuindi, per \\(k = 1\\): \\[\nP(X = 1) = \\binom{1}{1} p^1 (1-p)^{1-1} = 1 \\cdot p \\cdot 1 = p.\n\\]\nIn conclusione, la PMF per la distribuzione binomiale con \\(n = 1\\) diventa:\n\\[\nP(X = k) =\n\\begin{cases}\n1-p, & \\text{se } k = 0, \\\\\np, & \\text{se } k = 1.\n\\end{cases}\n\\]\nQuesta √® esattamente la PMF della distribuzione di Bernoulli con parametro \\(p\\):\n\\[\nP(X = x) = p^x (1-p)^{1-x}, \\quad x \\in \\{0, 1\\}.\n\\]\nPertanto, la distribuzione binomiale con \\(n = 1\\) √® equivalente alla distribuzione di Bernoulli con parametro \\(p\\).\n\n37.4.3 Applicazioni Pratiche della Distribuzione Binomiale\nConsideriamo un esempio pratico per illustrare l‚Äôapplicazione della distribuzione binomiale. Supponiamo di osservare 2 successi in 4 prove Bernoulliane, dove la probabilit√† di successo in ogni prova √® \\(p = 0.2\\). La probabilit√† di ottenere questo risultato specifico √® calcolata utilizzando l‚Äôeq. {eq}eq-binom-distr:\n\\[\nP(Y=2) = \\frac{4!}{2!(4-2)!} \\cdot 0.2^{2} \\cdot (1-0.2)^{4-2} = 0.1536.\n\\]\nQuesto calcolo pu√≤ essere replicato in Python. Utilizzando il modulo math, possiamo calcolare direttamente:\n\n# Parametri\nn &lt;- 4\np &lt;- 0.2\ny &lt;- 2\n\n# Probabilit√† di ottenere esattamente y successi\nprob &lt;- choose(n, y) * p^y * (1 - p)^(n - y)\nprint(prob)\n#&gt; [1] 0.1536\n\nIn alternativa, possiamo sfruttare la libreria SciPy per eseguire calcoli analoghi. SciPy offre una vasta gamma di funzioni per la gestione delle distribuzioni statistiche, tra cui la distribuzione binomiale.\n\n# Probabilit√† di ottenere esattamente y successi\nprob &lt;- choose(n, y) * p^y * (1 - p)^(n - y)\nprint(prob)\n#&gt; [1] 0.1536\n\nUtilizzando dbinom(y, n, p), possiamo trovare le probabilit√† per ogni possibile valore \\(y\\) in una distribuzione binomiale di parametri \\(n = 4\\) e \\(\\theta = 0.2\\):\n\n# Usando la funzione dbinom\nprob &lt;- dbinom(x = y, size = n, prob = p)\nprint(prob)\n#&gt; [1] 0.1536\n\nVisualizziamo la distribuzione di massa di probabilit√†:\n\ny &lt;- 0:n  # Numero di successi\nprobabilities &lt;- dbinom(y, size = n, prob = p)  # Probabilit√† associate\n\n# Preparare i dati in un data frame\ndf &lt;- data.frame(Successi = y, Probabilit√† = probabilities)\n\ndf |&gt; \n  ggplot(aes(x = Successi, y = Probabilit√†)) +\n    geom_segment(aes(xend = Successi, yend = 0), lwd = 1.2, color = \"blue\") +\n    geom_point(size = 3, color = \"blue\") +\n    labs(\n      x = \"Numero di Successi y\",\n      y = \"Probabilit√†\",\n      title = paste(\"Distribuzione Binomiale: n =\", n, \", p =\", p)\n  )\n\n\n\n\n\n\n\nUn campione casuale si ottiene con rbinom():\n\nset.seed(42)\nsamples &lt;- rbinom(n = 30, size = 5, prob = 0.5)\nprint(samples)\n#&gt;  [1] 4 4 2 4 3 3 3 1 3 3 2 3 4 2 2 4 5 1 2 3 4 1 5 4 1 3 2 4 2 4\n\nPer esplorare ulteriormente, consideriamo la distribuzione di probabilit√† di diverse distribuzioni binomiali per due valori di \\(n\\) e \\(\\theta\\). La seguente visualizzazione mostra come cambia la distribuzione al variare di \\(\\theta\\):\n\n# Parametri\nn &lt;- 20\np_values &lt;- seq(0.3, 0.9, by = 0.3) # Valori di probabilit√†\ny &lt;- 0:25 # Numero di successi\n\n# Creazione di un data frame per tutte le distribuzioni\ndf &lt;- data.frame()\n\nfor (p in p_values) {\n  binom_dist &lt;- dbinom(y, size = n, prob = p)\n  df &lt;- rbind(df, data.frame(y = y, Prob = binom_dist, p = factor(p)))\n}\n\n# Grafico con ggplot2\ndf |&gt; \n  ggplot(aes(x = y, y = Prob, color = p)) +\n    geom_point() +\n    geom_line() +\n    labs(\n      x = \"Numero di successi y\", \n      y = \"Probabilit√†\",\n      title = \"Distribuzione binomiale al variare di p\",\n      color = expression(theta)\n  )\n\n\n\n\n\n\n\nConsideriamo un altro esempio. Lanciando \\(5\\) volte una moneta onesta, qual √® la probabilit√† che esca testa almeno due volte? Troviamo la soluzione usando stats.binom.pmf().\n\n# Calcolo della somma delle probabilit√†\nresult &lt;- dbinom(2, size = 5, prob = 0.5) +\n          dbinom(3, size = 5, prob = 0.5) +\n          dbinom(4, size = 5, prob = 0.5) +\n          dbinom(5, size = 5, prob = 0.5)\n\nprint(result)\n#&gt; [1] 0.8125\n\nOppure, in modo pi√π compatto:\n\n# Valori di interesse\nresult &lt;- sum(dbinom(2:5, size = 5, prob = 0.5))\nprint(result)\n#&gt; [1] 0.8125\n\nRappresentiamo graficamente la funzione di ripartizione per una Binomiale di ordine \\(n\\) = 5 e \\(\\theta\\) = 0.5.\n\n# Parametri\nn &lt;- 5\np &lt;- 0.5\ny &lt;- 0:n\n\n# Calcolo della funzione di ripartizione cumulativa\ncdf_values &lt;- pbinom(y, size = n, prob = p)\n\n# Creazione del data frame per ggplot2\ndf &lt;- data.frame(y = y, cdf = cdf_values)\n\n# Grafico\ndf |&gt; \n  ggplot(aes(x = y, y = cdf)) +\n    geom_line() +\n    geom_point() +\n    geom_hline(yintercept = 1, color = \"black\", alpha = 0.7, linetype = \"dashed\") +\n    labs(\n      title = paste(\"Funzione di ripartizione binomiale: n =\", n, \", p =\", p),\n      x = \"y\",\n      y = \"Probabilit√†\"\n    )\n\n\n\n\n\n\n\nUn‚Äôaltra funzione utile √® quella che permette di trovare il numero di successi associato a una data probabilit√† cumulativa nella coda sinistra di una distribuzione binomiale. Questo si ottiene utilizzando la funzione qbinom, che rappresenta l‚Äôinversa della funzione di distribuzione cumulativa (CDF).\nAd esempio, consideriamo una distribuzione binomiale con \\(n = 5\\) prove e probabilit√† di successo \\(p = 0.5\\). Supponiamo di voler calcolare il numero minimo di successi per cui la probabilit√† cumulativa √® almeno \\(1 - 0.8125 = 0.1875\\). Possiamo farlo nel seguente modo:\n\n# Probabilit√† target\ntarget_probability &lt;- 1 - 0.8125\n\n# Numero di successi corrispondente alla probabilit√† target\nresult &lt;- qbinom(target_probability, size = 5, prob = 0.5)\n\nprint(result)\n#&gt; [1] 1\n\nIn questo esempio, il valore restituito √® \\(1\\), che indica che almeno 1 successo soddisfa la condizione di una probabilit√† cumulativa di \\(0.1875\\).\n\n37.4.4 Altro esempio\nConsideriamo ora una distribuzione binomiale con \\(n = 10\\) prove e probabilit√† di successo \\(p = 0.2\\). Per calcolare la probabilit√† cumulativa \\(P(Y \\leq 4)\\), ovvero la probabilit√† di ottenere al massimo 4 successi su 10 tentativi, possiamo utilizzare la funzione pbinom:\n\n# Calcolo della probabilit√† cumulativa\ntarget_probability &lt;- pbinom(4, size = 10, prob = 0.2)\nprint(target_probability)\n#&gt; [1] 0.9672\n\nIl risultato rappresenta la probabilit√† cumulativa associata a 4 o meno successi.\nSe invece vogliamo determinare il numero di successi corrispondente a questa probabilit√† cumulativa, possiamo utilizzare la funzione inversa qbinom:\n\n# Calcolo del numero di successi associato alla probabilit√† cumulativa\nresult &lt;- qbinom(target_probability, size = 10, prob = 0.2)\nprint(result)\n#&gt; [1] 4\n\nIn questo caso, il valore restituito rappresenta il numero massimo di successi \\(Y\\) per cui la probabilit√† cumulativa √® uguale o inferiore a \\(target\\_probability\\). Questo √® particolarmente utile per interpretare i risultati di una distribuzione binomiale in termini di successi associati a determinate probabilit√† cumulative.\n\n37.4.5 Valore atteso e deviazione standard\nLa media (numero atteso di successi in \\(n\\) prove) e la deviazione standard di una distribuzione binomiale si calcolano nel seguente modo:\n\\[\n\\begin{align}\n\\mu    &= np,  \\notag \\\\\n\\sigma &= \\sqrt{np(1-p)}.\n\\end{align}\n\\tag{37.3}\\]\nDimostrazione. Dato che \\(Y\\) rappresenta la somma di \\(n\\) prove di Bernoulli indipendenti \\(Y_i\\), possiamo scrivere:\n\\[\n\\begin{align}\n\\mathbb{E}(Y) &= \\mathbb{E}\\left( \\sum_{i=1}^n Y_i \\right) = \\sum_{i=1}^n \\mathbb{E}(Y_i) = np, \\\\\n\\mathbb{V}(Y) &= \\mathbb{V} \\left( \\sum_{i=1}^n Y_i \\right) = \\sum_{i=1}^n \\mathbb{V}(Y_i) = np(1-p).\n\\end{align}\n\\]\nPertanto, la deviazione standard √® data da \\(\\sigma = \\sqrt{np(1-p)}\\).\nPer esempio, prendiamo in considerazione il caso di un esperimento in cui vengono lanciate quattro monete, ciascuna con una probabilit√† di ottenere testa (successo) pari a \\(p = 0.2\\). Calcoliamo il valore atteso e la varianza per questo esperimento.\nIl valore atteso, \\(\\mu\\), rappresenta il numero medio di teste che ci aspettiamo di ottenere in ciascun lancio. Per la distribuzione binomiale, questo √® dato da \\(\\mu = n p\\), dove \\(n\\) √® il numero di prove (lanci di monete). Nel nostro caso, con \\(n = 4\\) e \\(p = 0.2\\), abbiamo:\n\\[\n\\mu = n p = 4 \\times 0.2 = 0.8.\n\\]\nQuesto significa che, in media, ci aspettiamo di ottenere circa 0.8 teste per ogni serie di quattro lanci.\nPer quanto riguarda la varianza, che misura quanto i risultati individuali tendono a differire dalla media, nella distribuzione binomiale √® calcolata come \\(n p (1-p)\\). Pertanto, per il nostro esperimento:\n\\[\n\\text{Varianza} = n p (1-p) = 4 \\times 0.2 \\times (1 - 0.2) = 0.64.\n\\]\nLa varianza di 0.64 suggerisce una certa dispersione intorno al valore medio di 0.8 teste.\nPer confermare queste aspettative teoriche, possiamo eseguire una simulazione. Creiamo una serie di esperimenti simulati in cui lanciamo quattro monete per un gran numero di volte, registrando il numero di teste ottenute in ogni serie. Calcoliamo poi la media e la varianza dei risultati ottenuti per vedere quanto si avvicinano ai valori teorici calcolati.\n\nset.seed(42)\n\n# Genera un campione di 1.000.000 di valori dalla distribuzione binomiale\nx &lt;- rbinom(n = 1000000, size = 4, prob = 0.2)\n\n\nmean(x)\n#&gt; [1] 0.8002\n\n\nvar(x)\n#&gt; [1] 0.639\n\n\n37.4.6 Funzioni R associate alle distribuzioni di probabilit√†\nLa seguente tabella riassume le funzioni di R utilizzate per manipolare le distribuzioni di probabilit√†, illustrando i casi della distribuzione Binomiale e della Normale.\n\n\n\n\n\n\n\nTipo\nEsempio: Binomiale (\\(y \\mid n, p\\))\nEsempio: Normale (\\(y \\mid \\mu, \\sigma\\))\n\n\n\nFunzione di verosimiglianza\ndbinom(y, size = n, prob = p)\ndnorm(y, mean = Œº, sd = œÉ)\n\n\nProb \\(Y = y\\)\n\ndbinom(y, size = n, prob = p)\nNon definita (variabili continue hanno pdf, non pmf)\n\n\nProb \\(Y \\geq y, Y \\leq y, y_1 &lt; Y &lt; y_2\\)\n\n\npbinom(y, size = n, prob = p) o 1 - pbinom(y - 1, ...)\n\n\npnorm(y, mean = Œº, sd = œÉ) o 1 - pnorm(y, ...)\n\n\n\nInversa della CDF\nqbinom(q, size = n, prob = p)\nqnorm(q, mean = Œº, sd = œÉ)\n\n\nGenerazione di dati simulati\nrbinom(n, size = trials, prob = p)\nrnorm(n, mean = Œº, sd = œÉ)\n\n\n\nIn seguito, useremo altre distribuzioni come Uniforme, Beta, ecc., ognuna delle quali ha un proprio insieme di funzioni disponibili in R. La sintassi segue uno schema generale comune:\n\n\nd*: Calcola la funzione di densit√† di probabilit√† (per distribuzioni continue) o di massa (per distribuzioni discrete). Esempi: dbinom, dnorm.\n\np*: Calcola la funzione di ripartizione cumulativa (CDF). Esempi: pbinom, pnorm.\n\nq*: Calcola l‚Äôinversa della funzione di ripartizione cumulativa (quantile function). Esempi: qbinom, qnorm.\n\nr*: Genera campioni casuali secondo una determinata distribuzione. Esempi: rbinom, rnorm.\n\n\nEsempio 37.2 ¬†\n\nCalcolare la probabilit√† di esattamente \\(y = 3\\) successi su \\(n = 5\\) prove con \\(p = 0.5\\):\n\n\ndbinom(3, size = 5, prob = 0.5)\n#&gt; [1] 0.3125\n\n\nCalcolare la probabilit√† cumulativa \\(P(Y \\leq 3)\\):\n\n\npbinom(3, size = 5, prob = 0.5)\n#&gt; [1] 0.8125\n\n\nCalcolare il valore minimo \\(y\\) tale che \\(P(Y \\leq y) \\geq 0.9\\):\n\n\nqbinom(0.9, size = 5, prob = 0.5)\n#&gt; [1] 4\n\n\nGenerare un campione di 100 numeri casuali da una distribuzione binomiale:\n\n\nrbinom(100, size = 5, prob = 0.5)\n#&gt;   [1] 2 2 4 1 3 2 3 2 2 2 3 3 3 3 1 4 1 1 0 2 2 2 4 1 2 3 3 1 5 2 3 3 0 3 2\n#&gt;  [36] 3 4 2 3 3 3 3 1 5 3 3 2 3 1 2 1 3 3 2 2 4 1 4 2 3 1 4 2 2 3 4 1 1 4 2\n#&gt;  [71] 3 2 3 3 3 1 4 4 3 3 4 3 3 3 2 2 3 3 2 4 4 3 2 2 0 3 1 3 1 2",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>37</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_discr_rv_distr.html#distribuzione-discreta-uniforme",
    "href": "chapters/probability/12_discr_rv_distr.html#distribuzione-discreta-uniforme",
    "title": "37¬† Distribuzioni di v.c. discrete",
    "section": "\n37.5 Distribuzione Discreta Uniforme",
    "text": "37.5 Distribuzione Discreta Uniforme\nLa distribuzione discreta uniforme √® un tipo particolare di distribuzione di probabilit√†, dove ogni risultato in un insieme finito e discreto \\(S\\) ha la stessa probabilit√† \\(p\\) di verificarsi. Questa distribuzione √® caratterizzata dalla sua semplicit√† e dalla sua propriet√† fondamentale di equiprobabilit√†.\nConsideriamo un esempio pratico con una variabile casuale discreta \\(X\\), che pu√≤ assumere valori nell‚Äôinsieme \\(\\{1, 2, \\dots, N\\}\\). Un‚Äôistanza classica di questa distribuzione si verifica quando si sceglie casualmente un numero intero tra 1 e \\(N\\), inclusi. Se \\(X\\) rappresenta il numero selezionato, allora la somma delle probabilit√† di tutti i possibili valori di \\(X\\) deve totalizzare 1, come indicato dalla formula di normalizzazione:\n\\[\n\\sum_{i=1}^N P(X_i) = Np = 1.\n\\]\nDi conseguenza, la probabilit√† che \\(X\\) assuma un valore specifico \\(x\\) √® uniformemente distribuita:\n\\[\nP(X = x) = \\frac{1}{N},\n\\]\nindicando che ogni evento ha la stessa probabilit√† di verificarsi.\nIl valore atteso, o la media, di \\(X\\) ci d√† un‚Äôidea del risultato medio atteso e si calcola come:\n\\[\n\\mathbb{E}(X) = \\sum_{x=1}^N x \\cdot \\frac{1}{N} = \\frac{1}{N} \\cdot \\sum_{x=1}^N x.\n\\]\nA questo punto, dobbiamo calcolare la somma \\(\\sum_{x=1}^{N} x\\), che √® la somma dei primi \\(N\\) numeri naturali. Questa somma √® data dalla formula:\n\\[\n\\sum_{x=1}^{N} x = \\frac{N(N + 1)}{2}.\n\\]\nSostituendo questa formula nel nostro calcolo del valore atteso, otteniamo:\n\\[\n\\mathbb{E}(X) = \\frac{1}{N} \\cdot \\frac{N(N + 1)}{2} = \\frac{N + 1}{2}.\n\\]\nQuindi, abbiamo dimostrato che il valore atteso $ (X) $ per una variabile casuale \\(X\\) che assume valori interi uniformemente distribuiti da 1 a \\(N\\) √® \\(\\frac{N + 1}{2}\\).\nPer determinare quanto i valori di \\(X\\) si disperdono attorno al valore medio, calcoliamo la varianza. Il primo passo √® calcolare \\(\\mathbb{E}(X^2)\\), il valore atteso del quadrato di \\(X\\). Per una variabile casuale discreta uniforme, questo si ottiene moltiplicando ogni valore al quadrato per la sua probabilit√† (che √® \\(1/N\\) per tutti i valori) e sommando i risultati:\n\\[\n\\mathbb{E}(X^2) = \\frac{1}{N} \\cdot \\sum_{x=1}^N x^2\n\\]\nUsando l‚Äôidentit√† per la somma dei quadrati dei primi \\(N\\) numeri naturali:\n\\[\n1^2 + 2^2 + \\dots + N^2 = \\frac{N(N + 1)(2N + 1)}{6}\n\\]\npossiamo sostituirla per trovare \\(\\mathbb{E}(X^2)\\):\n\\[\n\\mathbb{E}(X^2) = \\frac{1}{N} \\cdot \\frac{N(N + 1)(2N + 1)}{6} = \\frac{(N + 1)(2N + 1)}{6}\n\\]\nLa varianza di \\(X\\), denotata con \\(\\mathbb{V}(X)\\), si calcola usando la formula:\n\\[\n\\mathbb{V}(X) = \\mathbb{E}(X^2) - [\\mathbb{E}(X)]^2\n\\]\nAbbiamo gi√† stabilito che \\(\\mathbb{E}(X) = \\frac{N + 1}{2}\\) e \\(\\mathbb{E}(X^2) = \\frac{(N + 1)(2N + 1)}{6}\\). Sostituendo questi valori nella formula della varianza, otteniamo:\n\\[\n\\mathbb{V}(X) = \\frac{(N + 1)(2N + 1)}{6} - \\left(\\frac{N + 1}{2}\\right)^2\n\\]\nPer semplicare l‚Äôespressione della varianza, dobbiamo sottrarre il quadrato di \\(\\mathbb{E}(X)\\) da \\(\\mathbb{E}(X^2)\\):\n\\[\n\\begin{align*}\n\\mathbb{V}(X) &= \\frac{(N + 1)(2N + 1)}{6} - \\left(\\frac{N + 1}{2}\\right)^2 \\\\\n&= \\frac{(N + 1)(2N + 1)}{6} - \\frac{(N + 1)^2}{4} \\\\\n&= \\frac{2(N + 1)(2N + 1)}{12} - \\frac{3(N + 1)^2}{12} \\\\\n&= \\frac{(N + 1)(2(2N + 1) - 3(N + 1))}{12} \\\\\n&= \\frac{(N + 1)(4N + 2 - 3N - 3)}{12} \\\\\n&= \\frac{(N + 1)(N - 1)}{12}\n\\end{align*}\n\\]\nQuindi, la varianza \\(\\mathbb{V}(X)\\) di una variabile casuale uniforme discreta \\(X\\) che assume valori da 1 a \\(N\\) √® \\(\\frac{(N + 1)(N - 1)}{12}\\), il che mostra come la dispersione dei valori attorno al loro valore medio dipenda dalla grandezza di \\(N\\). Questa formula fornisce la varianza di una variabile casuale in una distribuzione discreta uniforme, offrendo una misura quantitativa della dispersione dei valori attorno al loro valore medio.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>37</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_discr_rv_distr.html#distribuzione-di-poisson-1",
    "href": "chapters/probability/12_discr_rv_distr.html#distribuzione-di-poisson-1",
    "title": "37¬† Distribuzioni di v.c. discrete",
    "section": "\n37.6 Distribuzione di Poisson",
    "text": "37.6 Distribuzione di Poisson\nLa distribuzione di Poisson √® utilizzata per modellare il numero di eventi che si verificano in un determinato intervallo di tempo o spazio, con eventi indipendenti e un tasso costante di occorrenza.\nLa funzione di massa di probabilit√† (PMF) √® data da:\n\\[\nP(Y = y \\mid \\lambda) = \\frac{\\lambda^y \\cdot e^{-\\lambda}}{y!}, \\quad y = 0, 1, 2, \\ldots\n\\]\ndove \\(\\lambda\\) rappresenta il tasso medio di eventi e \\(y\\) √® il numero di eventi.\nLa distribuzione di Poisson pu√≤ essere derivata come il limite di una distribuzione binomiale quando il numero di prove, \\(n\\), tende all‚Äôinfinito e la probabilit√† di successo in ciascuna prova, \\(p\\), tende a zero, in modo tale che \\(np = \\lambda\\).\n\n\n\n\n\n\nDimostrazione\n\n\n\nPartiamo dalla funzione di probabilit√† binomiale:\n\\[\np(k) = \\frac{n!}{k!(n - k)!} p^k (1 - p)^{n - k}.\n\\]\nImpostiamo \\(np = \\lambda\\), il che implica che \\(p = \\frac{\\lambda}{n}\\). Sostituendo \\(p\\) con \\(\\frac{\\lambda}{n}\\) nella formula binomiale, otteniamo:\n\\[\np(k) = \\frac{n!}{k!(n - k)!} \\left(\\frac{\\lambda}{n}\\right)^k \\left(1 - \\frac{\\lambda}{n}\\right)^{n - k}.\n\\]\nOra, separiamo i termini per rendere pi√π chiara la semplificazione. Possiamo riscrivere \\(\\left(\\frac{\\lambda}{n}\\right)^k\\) come \\(\\frac{\\lambda^k}{n^k}\\), e \\(\\left(1 - \\frac{\\lambda}{n}\\right)^{n - k}\\) come \\(\\left(1 - \\frac{\\lambda}{n}\\right)^n \\cdot \\left(1 - \\frac{\\lambda}{n}\\right)^{-k}\\). Quindi, l‚Äôespressione diventa:\n\\[\np(k) = \\frac{n!}{k!(n - k)!} \\cdot \\frac{\\lambda^k}{n^k} \\cdot \\left(1 - \\frac{\\lambda}{n}\\right)^n \\cdot \\left(1 - \\frac{\\lambda}{n}\\right)^{-k}.\n\\]\nOra, separiamo ulteriormente i termini:\n\\[\np(k) = \\frac{\\lambda^k}{k!} \\cdot \\frac{n!}{(n - k)! n^k} \\cdot \\left(1 - \\frac{\\lambda}{n}\\right)^n \\cdot \\left(1 - \\frac{\\lambda}{n}\\right)^{-k}.\n\\]\nQuesto passaggio mostra come la funzione di probabilit√† binomiale, sotto le condizioni \\(np = \\lambda\\) e \\(n \\to \\infty\\), si trasformi gradualmente nella forma che conduce alla distribuzione di Poisson.\nQuando \\(n \\to \\infty\\):\n\\[\n\\frac{\\lambda}{n} \\to 0\n\\]\n\\[\n\\frac{n!}{(n - k)! n^k} \\to 1\n\\]\n\\[\n\\left(1 - \\frac{\\lambda}{n}\\right)^n \\to e^{-\\lambda}\n\\]\n\\[\n\\left(1 - \\frac{\\lambda}{n}\\right)^{-k} \\to 1\n\\]\nSi ottiene quindi:\n\\[\np(k) \\to \\frac{\\lambda^k e^{-\\lambda}}{k!}\n\\]\nche √® la funzione di Poisson.\n\n\n\n\n\n\n\n\nDimostrazione\n\n\n\nAnalizziamo il limite:\n\\[\n\\left(1 - \\frac{\\lambda}{n}\\right)^n \\to e^{-\\lambda} \\quad \\text{quando} \\quad n \\to \\infty.\n\\]\nUn limite fondamentale in analisi matematica √®:\n\\[\n\\lim_{n \\to \\infty} \\left(1 + \\frac{a}{n}\\right)^n = e^a,\n\\]\ndove \\(e\\) √® la base del logaritmo naturale (\\(e \\approx 2.71828\\)) e \\(a\\) √® una costante. Questo limite √® alla base della definizione della funzione esponenziale.\nNel nostro caso, abbiamo l‚Äôespressione:\n\\[\n\\left(1 - \\frac{\\lambda}{n}\\right)^n .\n\\]\nNotiamo che questa √® molto simile al limite notevole, ma con un segno negativo. Possiamo riscriverla come:\n\\[\n\\left(1 - \\frac{\\lambda}{n}\\right)^n = \\left(1 + \\frac{-\\lambda}{n}\\right)^n.\n\\]\nApplicando il limite notevole con \\(a = -\\lambda\\), otteniamo:\n\\[\n\\lim_{n \\to \\infty} \\left(1 + \\frac{-\\lambda}{n}\\right)^n = e^{-\\lambda}.\n\\]\nQuindi, quando \\(n\\) diventa molto grande, l‚Äôespressione \\(\\left(1 - \\frac{\\lambda}{n}\\right)^n\\) si avvicina sempre di pi√π a \\(e^{-\\lambda}\\).\n\n\n\n37.6.1 Propriet√† principali\n\n\nMedia: \\(\\mathbb{E}[Y] = \\lambda\\)\n\n\nVarianza: \\(\\text{Var}(Y) = \\lambda\\)\n\n\nDi seguito, presentiamo esempi di calcolo e simulazione con R.\n\n37.6.2 Grafico della distribuzione di Poisson con \\(\\lambda = 2\\)\n\n\n# Parametro lambda\nlambda &lt;- 2\n\n# Valori di y (numero di eventi)\ny &lt;- 0:10\n\n# Calcolo delle probabilit√†\nprobabilities &lt;- dpois(y, lambda = lambda)\n\n# Creazione di un dataframe per ggplot\ndata &lt;- data.frame(\n  Numero_eventi = y,\n  Probabilita = probabilities\n)\n\n# Grafico della funzione di massa di probabilit√† con ggplot\nggplot(data, aes(x = Numero_eventi, y = Probabilita)) +\n  geom_col(fill = \"blue\") +  # Usa colonne verticali per rappresentare le probabilit√†\n  labs(\n    title = \"Distribuzione di Massa di Probabilit√† di Poisson\",\n    x = \"Numero di eventi (k)\",\n    y = \"Probabilit√†\"\n  ) \n\n\n\n\n\n\n\n\n37.6.3 Calcolo della probabilit√† per un numero specifico di eventi\nPer calcolare la probabilit√† di osservare esattamente 3 eventi con \\(\\lambda = 2\\):\n\nprob &lt;- dpois(3, lambda = 2)\nprint(prob)\n#&gt; [1] 0.1804\n\n\n37.6.4 Calcolo della probabilit√† cumulativa \\(P(Y \\leq 3)\\)\n\nPer calcolare \\(P(Y \\leq 3)\\), la probabilit√† cumulativa:\n\ncum_prob &lt;- ppois(3, lambda = 2)\nprint(cum_prob)\n#&gt; [1] 0.8571\n\n\n37.6.5 Trovare il quantile corrispondente a una probabilit√† data\nPer trovare il numero massimo di eventi per cui la probabilit√† cumulativa √® al massimo \\(0.8125\\):\n\nquantile &lt;- qpois(0.8125, lambda = 2)\nprint(quantile)\n#&gt; [1] 3\n\n\n37.6.6 Generazione di numeri casuali\nPer generare un campione di 1.000.000 di osservazioni da una distribuzione di Poisson con \\(\\lambda = 2\\):\n\nset.seed(42)\nsample &lt;- rpois(1000000, lambda = 2)\n\n# Calcolo di media e varianza del campione\nmean_sample &lt;- mean(sample)\nvar_sample &lt;- var(sample)\n\nprint(mean_sample)\n#&gt; [1] 2\nprint(var_sample)\n#&gt; [1] 1.996\n\n\nEsempio 37.3 Consideriamo un ospedale con una media storica di 4.5 nascite al giorno. Qual √® la probabilit√† che nascano esattamente 6 bambini in un giorno?\n\n# Calcolo della probabilit√†\nlambda &lt;- 4.5\nprob &lt;- dpois(6, lambda = lambda)\nprint(prob)\n#&gt; [1] 0.1281\n\nSimuliamo 365 giorni di nascite e confrontiamo la proporzione di giorni con esattamente 6 nascite:\n\nset.seed(42)\nn_days &lt;- 365\nsimulated_births &lt;- rpois(n_days, lambda = lambda)\n\n# Proporzione di giorni con esattamente 6 nascite\nproportion_six_births &lt;- mean(simulated_births == 6)\nprint(proportion_six_births)\n#&gt; [1] 0.1397\n\nIstogramma delle nascite simulate:\n\n# Creare un dataframe con i dati simulati\ndata &lt;- data.frame(Nascite = simulated_births)\n\n# Creare l'istogramma con ggplot\nggplot(data, aes(x = Nascite)) +\n  geom_histogram(\n    breaks = seq(-0.5, max(simulated_births) + 0.5, by = 1), \n    fill = \"blue\", \n    color = \"black\"\n  ) +\n  labs(\n    title = \"365 nascite simulate (Poisson)\",\n    x = \"Numero di nascite per giorno\",\n    y = \"Frequenza\"\n  )\n\n\n\n\n\n\n\nProbabilit√† di pi√π di 6 nascite in un giorno. Per calcolare la probabilit√† teorica \\(P(Y &gt; 6)\\):\n\nprob_more_than_six &lt;- 1 - ppois(6, lambda = lambda)\nprint(prob_more_than_six)\n#&gt; [1] 0.1689\n\nProporzione simulata di pi√π di 6 nascite:\n\nproportion_more_than_six &lt;- mean(simulated_births &gt; 6)\nprint(proportion_more_than_six)\n#&gt; [1] 0.1699\n\n\n\nEsempio 37.4 Questo esempio classico √® tratto da von Bortkiewicz (1898). Furono registrate le morti causate da calci di cavalli all‚Äôinterno di 10 squadroni della cavalleria prussiana, osservando i dati per un periodo di 20 anni, il che corrisponde a un totale di 200 ‚Äúsquadroni-anni‚Äù di dati.\nI dati e le probabilit√† ottenute da un modello di Poisson con parametro \\(\\lambda = 0.61\\) sono mostrati nella tabella seguente. La prima colonna della tabella indica il numero di decessi annui, che varia da 0 a 4. La seconda colonna elenca quante volte √® stato osservato quel particolare numero di decessi. Per esempio, in 65 dei 200 squadroni-anni ci fu un solo decesso. Nella terza colonna, i numeri osservati vengono convertiti in frequenze relative dividendo ciascun valore per 200. La quarta colonna mostra le probabilit√† di Poisson calcolate con il parametro \\(\\lambda = 0.61\\). Il valore \\(\\lambda = 0.61\\) √® stato scelto in modo da corrispondere al numero medio di decessi annui.\n\n\n\n\n\n\n\n\nNumero di decessi annui\nFrequenza osservata\nFrequenza relativa\nProbabilit√† di Poisson\n\n\n\n0\n109\n0.545\n0.543\n\n\n1\n65\n0.325\n0.331\n\n\n2\n22\n0.110\n0.101\n\n\n3\n3\n0.015\n0.021\n\n\n4\n1\n0.005\n0.003\n\n\n\nNote:\n\n\nFrequenza osservata: Indica quante volte un determinato numero di decessi √® stato registrato nei 200 squadroni-anni.\n\nFrequenza relativa: √à ottenuta dividendo la frequenza osservata per il totale dei dati (200).\n\nProbabilit√† di Poisson: Valori teorici calcolati usando il modello di Poisson con \\(\\lambda = 0.61\\), che rappresenta il tasso medio di decessi annui.\n\nQuesto esempio dimostra come il modello di Poisson possa essere utilizzato per descrivere fenomeni rari ma prevedibili, come le morti accidentali in questo caso.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>37</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_discr_rv_distr.html#distribuzione-beta-binomiale",
    "href": "chapters/probability/12_discr_rv_distr.html#distribuzione-beta-binomiale",
    "title": "37¬† Distribuzioni di v.c. discrete",
    "section": "\n37.7 Distribuzione Beta-Binomiale",
    "text": "37.7 Distribuzione Beta-Binomiale\nLa distribuzione beta-binomiale rappresenta una estensione della distribuzione binomiale che tiene conto della variabilit√† nella probabilit√† di successo tra i vari tentativi. Viene descritta da tre parametri principali: \\(N\\), \\(\\alpha\\) e \\(\\beta\\).\nNel dettaglio, la funzione di massa di probabilit√† per la distribuzione beta-binomiale √® data da:\n\\[\n\\text{BetaBinomiale}(y | N, \\alpha, \\beta) = \\binom{N}{y} \\cdot \\frac{B(y + \\alpha, N - y + \\beta)}{B(\\alpha, \\beta)},\n\\tag{37.4}\\]\ndove:\n\n\n\\(y\\) indica il numero di successi osservati.\n\n\\(N\\) rappresenta il numero totale di tentativi.\n\n\\(\\alpha\\) e \\(\\beta\\) sono i parametri della distribuzione beta, che modellano la variabilit√† nella probabilit√† di successo tra i tentativi.\n\nLa funzione \\(B(u, v)\\), nota come funzione beta, √® definita tramite l‚Äôuso della funzione gamma \\(\\Gamma\\), secondo la formula:\n\\[\nB(u, v) = \\frac{\\Gamma(u) \\Gamma(v)}{\\Gamma(u + v)},\n\\]\ndove la funzione gamma \\(\\Gamma\\) generalizza il concetto di fattoriale a numeri reali e complessi.\nL‚Äôimportanza della distribuzione beta-binomiale deriva dalla sua capacit√† di modellare situazioni in cui la probabilit√† di successo non √® fissa, ma segue una distribuzione di probabilit√†, specificatamente una distribuzione beta. Ci√≤ la rende particolarmente adatta per applicazioni in cui le probabilit√† di successo cambiano in maniera incerta da un tentativo all‚Äôaltro, come pu√≤ avvenire in contesti di ricerca clinica o in studi comportamentali. Rispetto alla distribuzione binomiale, che assume una probabilit√† di successo costante per tutti i tentativi, la beta-binomiale offre una rappresentazione pi√π realistica e flessibile per dati empirici che presentano variabilit√† nelle probabilit√† di successo.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>37</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_discr_rv_distr.html#riflessioni-conclusive",
    "href": "chapters/probability/12_discr_rv_distr.html#riflessioni-conclusive",
    "title": "37¬† Distribuzioni di v.c. discrete",
    "section": "\n37.8 Riflessioni Conclusive",
    "text": "37.8 Riflessioni Conclusive\nIn questo capitolo, abbiamo approfondito alcune delle distribuzioni discrete pi√π importanti, ognuna con caratteristiche uniche e campi di applicazione specifici. Abbiamo iniziato con la distribuzione di Bernoulli, che modella esperimenti con due soli esiti possibili, per poi passare alla distribuzione Binomiale, che generalizza la Bernoulli considerando un numero fisso di prove indipendenti. Successivamente, abbiamo esaminato la distribuzione di Poisson, utile per descrivere eventi rari in un intervallo di tempo o spazio, e la distribuzione Beta-Binomiale, un‚Äôestensione della Binomiale che incorpora la variabilit√† nella probabilit√† di successo, rendendola particolarmente adatta per modellare situazioni in cui tale probabilit√† non √® fissa. Infine, abbiamo discusso la distribuzione Discreta Uniforme, che assegna la stessa probabilit√† a ciascun evento in un insieme finito e discreto.\nQueste distribuzioni rappresentano il fondamento dell‚Äôanalisi statistica discreta e trovano applicazione in numerosi ambiti. In particolare, nel contesto dell‚Äôinferenza bayesiana, la comprensione della distribuzione Binomiale e della sua estensione Beta-Binomiale √® essenziale. Queste distribuzioni, infatti, forniscono gli strumenti necessari per l‚Äôaggiornamento bayesiano, un processo chiave che permette di rivedere le nostre credenze iniziali alla luce di nuovi dati. Questo concetto sar√† ulteriormente esplorato nei capitoli successivi, dove approfondiremo come le distribuzioni a priori e a posteriori interagiscono nel quadro bayesiano.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>37</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_discr_rv_distr.html#esercizi",
    "href": "chapters/probability/12_discr_rv_distr.html#esercizi",
    "title": "37¬† Distribuzioni di v.c. discrete",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nPer ciascuna delle distribuzioni di massa di probabilit√† discusse, utilizzare R per:\n\ncreare un grafico della funzione, scegliendo opportunamente i parametri;\nestrarre un campione di 1000 valori casuali dalla distribuzione e visualizzarlo con un istogramma;\ncalcolare la media e la deviazione standard dei campioni e confrontarle con i valori teorici attesi;\nstimare l‚Äôintervallo centrale del 94% utilizzando i campioni simulati;\ndeterminare i quantili della distribuzione per gli ordini 0.05, 0.25, 0.75 e 0.95;\nscegliendo un valore della distribuzione pari alla media pi√π una deviazione standard, calcolare la probabilit√† che la variabile aleatoria assuma un valore minore o uguale a questo valore.\n\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nEsercizi sulla distribuzione binomiale, risolvibili usando R, sono disponibili sulla seguente pagina web.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>37</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_discr_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/12_discr_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "title": "37¬† Distribuzioni di v.c. discrete",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.5.3     \n#&gt;  [9] scales_1.3.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.9.1   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         rlang_1.1.5       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       yaml_2.3.10       tools_4.4.2       parallel_4.4.2   \n#&gt; [21] tzdb_0.5.0        colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5      \n#&gt; [25] R6_2.6.1          lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3  \n#&gt; [29] pillar_1.10.1     gtable_0.3.6      glue_1.8.0        xfun_0.51        \n#&gt; [33] tidyselect_1.2.1  rstudioapi_0.17.1 farver_2.1.2      htmltools_0.5.8.1\n#&gt; [37] nlme_3.1-167      labeling_0.4.3    rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>37</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_discr_rv_distr.html#bibliografia",
    "href": "chapters/probability/12_discr_rv_distr.html#bibliografia",
    "title": "37¬† Distribuzioni di v.c. discrete",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlitzstein, J. K., & Hwang, J. (2019). Introduction to probability. CRC Press.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>37</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_cont_rv_distr.html",
    "href": "chapters/probability/13_cont_rv_distr.html",
    "title": "38¬† Distribuzioni di v.c. continue",
    "section": "",
    "text": "38.1 Introduzione\nProprio come per le variabili casuali discrete, anche per le variabili casuali continue √® possibile rappresentare la variabilit√† di una popolazione attraverso un modello statistico. Tuttavia, mentre le distribuzioni discrete si applicano a fenomeni con un numero finito o numerabile di esiti, le variabili casuali continue richiedono l‚Äôuso di funzioni di densit√† di probabilit√† (pdf), che descrivono fenomeni in cui i valori possono assumere un continuum di possibilit√†. Queste funzioni ci permettono di modellare e analizzare situazioni in cui i risultati non sono discreti, ma possono variare in modo continuo.\nLa funzione di densit√† di probabilit√† \\(f(x)\\) associata a una variabile casuale continua \\(X\\) rappresenta la distribuzione della probabilit√† all‚Äôinterno della popolazione. A differenza delle distribuzioni discrete, dove la probabilit√† √® assegnata direttamente a singoli valori, la pdf non fornisce la probabilit√† di un singolo punto, ma descrive la probabilit√† che \\(X\\) assuma valori all‚Äôinterno di un intervallo specifico. Questo approccio consente di costruire un modello matematico della popolazione, utile per fare previsioni e comprendere meglio i fenomeni aleatori continui.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>38</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_cont_rv_distr.html#introduzione",
    "href": "chapters/probability/13_cont_rv_distr.html#introduzione",
    "title": "38¬† Distribuzioni di v.c. continue",
    "section": "",
    "text": "38.1.1 Definizione di Variabile Casuale Continua\n\nDefinizione 38.1 Una variabile casuale continua √® una variabile aleatoria \\(X\\) caratterizzata da una distribuzione di probabilit√† continua. Formalmente, \\(X\\) si definisce continua se soddisfa le seguenti propriet√†:\n\n\nEsistenza della funzione di densit√† (pdf):\nEsiste una funzione non negativa \\(f(x)\\), detta funzione di densit√† di probabilit√† (pdf, dall‚Äôinglese probability density function), tale che:\n\n\n\\(f(x) \\geq 0\\) per ogni \\(x \\in \\mathbb{R}\\);\n\nL‚Äôarea totale sotto la curva di \\(f(x)\\) √® pari a 1:\\[\n\\int_{-\\infty}^{+\\infty} f(x) \\, dx = 1.\n\\]\n\n\n\n\nCalcolo delle probabilit√† tramite integrazione:\nPer ogni intervallo \\((a, b] \\subseteq \\mathbb{R}\\) (con \\(a &lt; b\\)), la probabilit√† che \\(X\\) assuma valori in \\((a, b]\\) √® data dall‚Äôintegrale della pdf su tale intervallo:\n\\[\nP(a &lt; X \\leq b) = \\int_{a}^{b} f(x) \\, dx.\n\\]\nQuesta probabilit√† coincide anche con la differenza della funzione di ripartizione (CDF, cumulative distribution function) \\(F(x) = P(X \\leq x)\\) agli estremi dell‚Äôintervallo:\n\\[\nP(a &lt; X \\leq b) = F(b) - F(a).\n\\]\n\n\n\n\n38.1.2 Propriet√† Chiave delle Variabili Continue\n\n\nProbabilit√† in un punto nulla:\nA differenza delle variabili discrete, per una variabile continua la probabilit√† di assumere un valore esatto \\(x_0\\) √® sempre zero:\n\\[\nP(X = x_0) = 0.\n\\]\nQuesto avviene perch√© la probabilit√† √® legata all‚Äôarea sotto la curva \\(f(x)\\), e un singolo punto ha ‚Äúlarghezza zero‚Äù, risultando in un‚Äôarea nulla. Di conseguenza, per variabili continue:\n\\[\nP(a \\leq X \\leq b) = P(a &lt; X \\leq b) = P(a \\leq X &lt; b) = P(a &lt; X &lt; b).\n\\]\n\nInterpretazione della densit√†:\nLa funzione \\(f(x)\\) non rappresenta direttamente una probabilit√†, ma descrive come la probabilit√† si distribuisce nello spazio campionario. Valori maggiori di \\(f(x)\\) indicano regioni in cui √® pi√π probabile che \\(X\\) assuma valori (densit√† di probabilit√†).\nModellizzazione di fenomeni continui:\nLe distribuzioni continue sono utilizzate per rappresentare grandezze misurabili con precisione arbitraria, come tempo, lunghezze, o temperature. Esempi comuni includono la distribuzione normale, esponenziale e uniforme continua.\n\nIniziamo ad esaminare la distribuzione continua uniforme.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>38</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_cont_rv_distr.html#la-distribuzione-uniforme-continua",
    "href": "chapters/probability/13_cont_rv_distr.html#la-distribuzione-uniforme-continua",
    "title": "38¬† Distribuzioni di v.c. continue",
    "section": "\n38.2 La Distribuzione Uniforme Continua",
    "text": "38.2 La Distribuzione Uniforme Continua\nLa distribuzione uniforme continua √® un modello probabilistico fondamentale in cui tutti i valori all‚Äôinterno di un intervallo specificato hanno la stessa densit√† di probabilit√†. √à ideale per descrivere fenomeni in cui non vi √® preferenza per alcun risultato particolare, come nel caso di uno spinner perfettamente bilanciato o di un generatore casuale ideale.\n\n38.2.1 Esempio Intuitivo: Lo Spinner\nImmaginiamo uno spinner circolare con valori angolari da 0¬∞ a 360¬∞. Se lo spinner √® perfettamente equilibrato, ogni angolo ha la stessa probabilit√† di essere selezionato. Questo esperimento rappresenta una realizzazione pratica della distribuzione uniforme sull‚Äôintervallo \\([0, 360)\\).\n\n38.2.2 Simulazione della Distribuzione\nCaso 1: Piccolo Campione. Generiamo 20 valori casuali e visualizziamoli con un istogramma:\n\nset.seed(123)  # Fissa il seme per riproducibilit√†\nspinner_results &lt;- runif(20, min = 0, max = 360)\nprint(spinner_results)  # Stampa i risultati\n#&gt;  [1] 103.53 283.79 147.23 317.89 338.57  16.40 190.12 321.27 198.52 164.38\n#&gt; [11] 344.46 163.20 243.93 206.15  37.05 323.94  88.59  15.14 118.05 343.62\n\n# Visualizzazione\nggplot(data.frame(Valori = spinner_results), aes(x = Valori)) +\n  geom_histogram(\n    binwidth = 10, \n    fill = \"skyblue\", \n    color = \"black\", \n    alpha = 0.5\n  ) +\n  labs(\n    x = \"Angolo (gradi)\", \n    y = \"Frequenza relativa\",\n    title = \"Distribuzione con 20 simulazioni\"\n  ) \n\n\n\n\n\n\n\nCon pochi dati, l‚Äôistogramma mostra una disomogeneit√† dovuta alla variabilit√† campionaria, tipica dei piccoli campioni.\nCaso 2: Grande Campione. Aumentando il numero di simulazioni, l‚Äôistogramma converge alla forma teorica:\n\nspinner_results_large &lt;- runif(100000, min = 0, max = 360)\n\nggplot(data.frame(Valori = spinner_results_large), aes(x = Valori)) +\n  geom_histogram(\n    binwidth = 10, \n    fill = \"skyblue\", \n    color = \"black\", \n    alpha = 0.5\n  ) +\n  labs(\n    x = \"Angolo (gradi)\", \n    y = \"Frequenza relativa\",\n    title = \"Distribuzione con 100.000 simulazioni\"\n  ) \n\n\n\n\n\n\n\nCon un campione grande, l‚Äôistogramma riflette chiaramente la uniformit√† teorica, dimostrando la Legge dei Grandi Numeri.\n\n38.2.3 Funzione di Densit√† di Probabilit√† (PDF)\nPer una variabile \\(X \\sim \\mathcal{U}(a, b)\\), la PDF √® costante nell‚Äôintervallo \\([a, b]\\):\n\\[\nf(x) =\n\\begin{cases}\n  \\displaystyle \\frac{1}{b - a} & \\text{se } x \\in [a, b], \\\\\n  0 & \\text{altrimenti}.\n\\end{cases}\n\\]\nInterpretazione:\n\nL‚Äôarea totale sotto la curva √® 1: \\(\\int_{a}^{b} \\frac{1}{b - a} \\, dx = 1\\).\n\nAl di fuori di \\([a, b]\\), la densit√† √® nulla.\n\nEsempio (spinner):\n\\[\nf(x) = \\frac{1}{360} \\quad \\text{per } x \\in [0, 360].\n\\]\nVisualizzazione in R:\n\nx &lt;- seq(-50, 410, length.out = 500)  # Estende l'intervallo per chiarezza\ndensity_uniform &lt;- dunif(x, min = 0, max = 360)\n\nggplot(data.frame(x = x, y = density_uniform), aes(x = x, y = y)) +\n  geom_line(linewidth = 1.2, color = \"blue\") +\n  geom_vline(xintercept = c(0, 360), linetype = \"dashed\", color = \"red\") +\n  labs(\n    x = \"x (gradi)\", \n    y = \"Densit√† f(x)\", \n    title = \"PDF della distribuzione uniforme\"\n  ) +\n  xlim(-50, 410) \n\n\n\n\n\n\n\n\n38.2.4 Calcolo delle Probabilit√†\nLa probabilit√† che \\(X\\) cada in un intervallo \\([c, d] \\subseteq [a, b]\\) √®:\n\\[\nP(c \\leq X \\leq d) = \\frac{d - c}{b - a}.\n\\]\nEsempio: Probabilit√† che lo spinner si fermi tra 150¬∞ e 250¬∞:\n\\[\nP(150 \\leq X \\leq 250) = \\frac{250 - 150}{360} = \\frac{100}{360} = \\frac{5}{18} \\approx 0.2778.\n\\]\nVerifica in R:\n\n# Metodo manuale\nprob_manuale &lt;- (250 - 150) / 360\nprob_manuale  # Restituisce 0.2777778\n#&gt; [1] 0.2778\n\n# Metodo con funzione cumulativa (CDF)\nprob_cdf &lt;- punif(250, min = 0, max = 360) - punif(150, min = 0, max = 360)\nprob_cdf  # Conferma: 0.2777778\n#&gt; [1] 0.2778\n\nVisualizzazione dell‚Äôarea:\n\nggplot(data.frame(x = x, fx = density_uniform), aes(x = x, y = fx)) +\n  geom_line(linewidth = 1.2, color = \"blue\") +\n  geom_area(\n    data = subset(data.frame(x, fx = density_uniform), x &gt;= 150 & x &lt;= 250),\n    aes(x = x, y = fx), \n    fill = \"gray\", \n    alpha = 0.5\n  ) +\n  labs(\n    x = \"x (gradi)\", \n    y = \"Densit√† f(x)\", \n    title = \"Area corrispondente a P(150 ‚â§ X ‚â§ 250)\"\n  ) \n\n\n\n\n\n\n\n\n38.2.5 Propriet√† Fondamentali\nPer \\(X \\sim \\mathcal{U}(a, b)\\):\n\n\nValore atteso (media):\n\\[\nE(X) = \\frac{a + b}{2}.\n\\]\nInterpretazione: Il centro dell‚Äôintervallo, punto di equilibrio della distribuzione.\n\n\nVarianza:\n\\[\n\\text{Var}(X) = \\frac{(b - a)^2}{12}.\n\\]\nInterpretazione: La dispersione aumenta col quadrato dell‚Äôampiezza dell‚Äôintervallo.\n\n\nEsempio (spinner):\n\nE_X &lt;- (0 + 360) / 2  # 180\nV_X &lt;- (360 - 0)^2 / 12  # 10800\n\n\n38.2.6 Funzioni R per la Distribuzione Uniforme\nR mette a disposizione quattro funzioni principali:\n\n\n\n\n\n\n\nFunzione\nDescrizione\nEsempio d‚Äôuso\n\n\n\nrunif()\nGenera valori casuali\nrunif(5, min=0, max=1)\n\n\ndunif()\nCalcola la densit√† \\(f(x)\\)\n\ndunif(180, min=0, max=360)\n\n\npunif()\nCalcola la CDF \\(P(X \\leq x)\\)\n\npunif(250, min=0, max=360)\n\n\nqunif()\nTrova il quantile \\(x\\) per \\(p\\)\n\nqunif(0.9, min=0, max=360)\n\n\n\nEsempi pratici:\n\n# 1. Generazione di 5 numeri casuali in [0, 1]\nrunif(5, min = 0, max = 1)  # Esempio: [0.287, 0.788, 0.409, 0.883, 0.940]\n#&gt; [1] 0.03716 0.92779 0.44799 0.91590 0.35575\n\n# 2. Calcolo della densit√† in x = 0.5 (per U(0,1))\ndunif(0.5, min = 0, max = 1)  # Restituisce 1\n#&gt; [1] 1\n\n# 3. Probabilit√† cumulativa fino a x = 0.8 (per U(0,1))\npunif(0.8, min = 0, max = 1)  # Restituisce 0.8\n#&gt; [1] 0.8\n\n# 4. Calcolo del quantile per p = 0.5 (mediana)\nqunif(0.5, min = 0, max = 360)  # Restituisce 180\n#&gt; [1] 180\n\nIn conclusione, la distribuzione uniforme offre un modello intuitivo per variabili continue con risultati equiprobabili. La sua semplicit√† analitica (PDF costante, formule esplicite per media e varianza) e il supporto completo in R la rendono uno strumento essenziale per:\n\nsimulare scenari casuali,\nverificare algoritmi probabilistici,\nintrodurre concetti base della statistica (legge dei grandi numeri, concetto di densit√†).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>38</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_cont_rv_distr.html#distribuzione-esponenziale",
    "href": "chapters/probability/13_cont_rv_distr.html#distribuzione-esponenziale",
    "title": "38¬† Distribuzioni di v.c. continue",
    "section": "\n38.3 Distribuzione Esponenziale",
    "text": "38.3 Distribuzione Esponenziale\nLa distribuzione esponenziale √® una distribuzione di probabilit√† continua utilizzata per modellare il tempo di attesa fino al verificarsi di un evento casuale. Una delle sue caratteristiche distintive √® la propriet√† di assenza di memoria, che la rende unica rispetto ad altre distribuzioni.\n\n38.3.1 Propriet√† di Assenza di Memoria\nL‚Äôassenza di memoria implica che la probabilit√† di un evento futuro √® indipendente dal tempo gi√† trascorso.\nAd esempio, supponiamo che il tempo di rottura di un bicchiere da vino dopo il primo utilizzo segua una distribuzione esponenziale. Se un bicchiere non si √® rotto dopo 3 anni, la probabilit√† che si rompa nel prossimo anno √® la stessa di quella di un bicchiere nuovo nel suo primo anno di utilizzo.\nQuesta propriet√† rende la distribuzione esponenziale ideale per modellare eventi senza ‚Äúusura accumulata‚Äù, come il tempo tra guasti indipendenti in un sistema.\n\nDefinizione 38.2 La funzione di densit√† di probabilit√† (PDF) di una variabile casuale esponenziale \\(X\\) √® data da:\n\\[\nf(x) = \\lambda e^{-\\lambda x}, \\quad \\lambda &gt; 0,\\, x \\geq 0,\n\\]\ndove:\n\n\n\\(\\lambda\\) √® il tasso di eventi per unit√† di tempo,\n\n\n\\(\\frac{1}{\\lambda} = \\mu\\) √® il tempo medio di attesa.\n\nEsprimendo la densit√† in funzione di \\(\\mu\\):\n\\[\nf(x) = \\frac{1}{\\mu} e^{-x / \\mu}.\n\\]\n\n\n38.3.2 Propriet√† Principali\n\nValore atteso (media):\\[\nE(X) = \\frac{1}{\\lambda} = \\mu.\n\\]\nVarianza:\\[\nV(X) = \\frac{1}{\\lambda^2} = \\mu^2.\n\\]\nDeviazione standard:\\[\n\\sigma_X = \\frac{1}{\\lambda} = \\mu.\n\\]\n\nQueste propriet√† confermano che la distribuzione esponenziale √® completamente determinata da un solo parametro: \\(\\lambda\\) (o, equivalentemente, \\(\\mu\\)).\n\n38.3.3 Esempio Pratico\nSupponiamo che il tempo medio per la pubblicazione dei voti di un esame sia \\(\\mu = 4\\) giorni. La funzione di densit√† assume la forma:\n\\[\nf(x) = \\frac{1}{4} e^{-x / 4}.\n\\]\nPossiamo visualizzare la distribuzione con R:\n\n# Parametri della distribuzione\nmu &lt;- 4\nlambda &lt;- 1 / mu\n\n# Generare valori per x\nx &lt;- seq(0, 20, by = 0.01)\n\n# Calcolare la densit√†\npdf &lt;- dexp(x, rate = lambda)\n\n# Grafico della densit√†\nggplot(data.frame(x, pdf), aes(x = x, y = pdf)) +\n  geom_line(linewidth = 1, color = \"blue\") +\n  labs(\n    x = \"x\", y = \"f(x)\", \n    title = \"Funzione di densit√† della distribuzione esponenziale\"\n  )\n\n\n\n\n\n\n\n\n38.3.4 Calcolo delle Probabilit√†\n1. Probabilit√† che \\(X \\leq 1.5\\)\nLa probabilit√† che il tempo di attesa sia inferiore o uguale a 1.5 giorni √® data dalla funzione di ripartizione cumulativa (CDF):\n\\[\nP(X \\leq 1.5) = F(1.5) = 1 - e^{-\\lambda \\cdot 1.5}.\n\\]\nIn R:\n\npexp(1.5, rate = lambda)\n#&gt; [1] 0.3127\n\nVisualizziamo quest‚Äôarea sotto la curva:\n\nggplot(data.frame(x, pdf), aes(x = x, y = pdf)) +\n  geom_line(linewidth = 1, color = \"blue\") +\n  geom_area(\n    data = subset(data.frame(x, pdf), x &lt;= 1.5), \n    aes(x = x, y = pdf), fill = \"gray\", alpha = 0.5\n  ) +\n  labs(\n    x = \"x\", y = \"f(x)\", \n    title = \"Probabilit√† P(X &lt;= 1.5)\"\n  )\n\n\n\n\n\n\n\n2. Probabilit√† che \\(1 \\leq X \\leq 6\\)\nSi ottiene come differenza tra le CDF:\n\\[\nP(1 \\leq X \\leq 6) = F(6) - F(1).\n\\]\nIn R:\n\npexp(6, rate = lambda) - pexp(1, rate = lambda)\n#&gt; [1] 0.5557\n\nVisualizzazione dell‚Äôarea:\n\nggplot(data.frame(x, pdf), aes(x = x, y = pdf)) +\n  geom_line(linewidth = 1, color = \"blue\") +\n  geom_area(\n    data = subset(data.frame(x, pdf), x &gt;= 1 & x &lt;= 6), \n    aes(x = x, y = pdf), fill = \"gray\", alpha = 0.5\n  ) +\n  labs(\n    x = \"x\", y = \"f(x)\", \n    title = \"Probabilit√† P(1 &lt;= X &lt;= 6)\"\n  )\n\n\n\n\n\n\n\n3. Probabilit√† che \\(X \\geq 5.5\\)\nSi calcola con la complementarit√†:\n\\[\nP(X \\geq 5.5) = 1 - F(5.5).\n\\]\nIn R:\n\n1 - pexp(5.5, rate = lambda)\n#&gt; [1] 0.2528\n# Oppure\npexp(5.5, rate = lambda, lower.tail = FALSE)\n#&gt; [1] 0.2528\n\nVisualizzazione:\n\nggplot(data.frame(x, pdf), aes(x = x, y = pdf)) +\n  geom_line(linewidth = 1, color = \"blue\") +\n  geom_area(\n    data = subset(data.frame(x, pdf), x &gt;= 5.5), \n    aes(x = x, y = pdf), fill = \"gray\", alpha = 0.5\n  ) +\n  labs(\n    x = \"x\", y = \"f(x)\", \n    title = \"Probabilit√† P(X &gt;= 5.5)\"\n  )\n\n\n\n\n\n\n\n\n38.3.5 Simulazione di Valori\nSimuliamo 1.000.000 di valori casuali da una distribuzione esponenziale con \\(\\lambda = 1/4\\) e costruiamo un istogramma confrontato con la densit√† teorica:\n\n# Simulazione\nset.seed(123)\nsamples &lt;- rexp(1000000, rate = lambda)\n\n# Istogramma con densit√† sovrapposta\nggplot(data.frame(samples), aes(x = samples)) +\n  geom_histogram(\n    aes(y = after_stat(density)), bins = 100, \n    fill = \"skyblue\", color = \"black\", alpha = 0.5\n  ) +\n  geom_line(\n    data = data.frame(x, pdf), aes(x = x, y = pdf), \n    color = \"red\", linewidth = 1\n  ) +\n  xlim(0, 20) +\n  labs(\n    x = \"Tempo di attesa\", y = \"Frequenza relativa\",\n    title = \"Istogramma dei valori simulati con densit√† teorica\"\n  )\n\n\n\n\n\n\n\nIn conclusione, la distribuzione esponenziale √® uno strumento fondamentale per modellare eventi basati su tempi di attesa. Grazie alla sua semplicit√† e alla propriet√† di assenza di memoria, trova applicazione in numerosi contesti. Con le funzioni di R (dexp, pexp, qexp, rexp), possiamo analizzare e visualizzare facilmente i dati che seguono questa distribuzione.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>38</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_cont_rv_distr.html#distribuzione-normale",
    "href": "chapters/probability/13_cont_rv_distr.html#distribuzione-normale",
    "title": "38¬† Distribuzioni di v.c. continue",
    "section": "\n38.4 Distribuzione Normale",
    "text": "38.4 Distribuzione Normale\nLa distribuzione normale, anche nota come distribuzione gaussiana, √® una delle distribuzioni di probabilit√† pi√π importanti in statistica. Deve il suo nome a Carl Friedrich Gauss, che ne scopr√¨ l‚Äôutilit√† per modellare gli errori di misurazione. Adolphe Quetelet, uno dei padri delle scienze sociali quantitative, fu il primo a utilizzare questa distribuzione per studiare le misurazioni dell‚Äôuomo. Karl Pearson introdusse il termine ‚Äúnormale‚Äù, pur riconoscendo che ci√≤ potesse erroneamente suggerire l‚Äôanormalit√† di altre distribuzioni.\n\n38.4.1 Una famiglia di distribuzioni\nLa distribuzione normale non √® unica, ma rappresenta una famiglia di distribuzioni definite da due parametri:\n\n\n\\(\\mu\\) (media): il valore attorno al quale i dati sono simmetricamente distribuiti.\n\n\\(\\sigma\\) (deviazione standard): misura la dispersione dei dati attorno alla media.\n\nLa densit√† di probabilit√† per una variabile casuale continua \\(Y\\) che segue una distribuzione normale √® data da:\n\\[\nf(y; \\mu, \\sigma) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left(-\\frac{(y - \\mu)^2}{2\\sigma^2}\\right),\n\\]\ndove \\(\\mu \\in \\mathbb{R}\\) e \\(\\sigma &gt; 0\\).\nQuesta curva ha una caratteristica forma a campana, simmetrica rispetto alla media \\(\\mu\\). La media, la mediana e la moda coincidono.\n\n38.4.2 Origini storiche: dal binomiale alla normale\nLa connessione tra distribuzioni binomiali e normali fu notata da Abraham de Moivre nel 1733. Egli osserv√≤ che, aumentando il numero di prove di una distribuzione binomiale, la forma della distribuzione si avvicina a quella di una curva normale. Questo fenomeno pu√≤ essere illustrato confrontando distribuzioni binomiali con pochi e molti eventi.\n\n38.4.3 Distribuzione binomiale con poche prove\nCon un numero di prove \\(n = 10\\) e una probabilit√† di successo \\(p = 0.9\\), la distribuzione binomiale √® chiaramente asimmetrica:\n\n# Parametri\nn &lt;- 10\np &lt;- 0.9\n\n# Calcolo della distribuzione binomiale\nr_values &lt;- 0:n\ndist &lt;- dbinom(r_values, size = n, prob = p)\n\n# Grafico\nggplot(data.frame(Successi = r_values, Probabilit√† = dist), aes(x = Successi, y = Probabilit√†)) +\n  geom_bar(stat = \"identity\", fill = \"skyblue\", color = \"black\") +\n  labs(\n    title = \"Distribuzione Binomiale: n = 10, p = 0.9\", \n    x = \"Numero di Successi\", y = \"Probabilit√†\"\n  )\n\n\n\n\n\n\n\n\n38.4.4 Distribuzione binomiale con molte prove\nAumentando il numero di prove a \\(n = 1000\\) con lo stesso \\(p\\), la distribuzione assume una forma pi√π simmetrica, simile a quella della normale:\n\n# Parametri aggiornati\nn &lt;- 1000\n\n# Calcolo della distribuzione binomiale\nr_values &lt;- 850:950  # Intervallo per una migliore visualizzazione\ndist &lt;- dbinom(r_values, size = n, prob = p)\n\n# Grafico\nggplot(data.frame(Successi = r_values, Probabilit√† = dist), aes(x = Successi, y = Probabilit√†)) +\n  geom_bar(stat = \"identity\", fill = \"skyblue\", color = \"black\") +\n  labs(\n    title = \"Distribuzione Binomiale: n = 1000, p = 0.9\", \n    x = \"Numero di Successi\", y = \"Probabilit√†\"\n  )\n\n\n\n\n\n\n\n\n38.4.5 La normale generata da simulazioni\nUn modo intuitivo per comprendere la distribuzione normale √® attraverso la simulazione di passeggiate casuali. Immaginiamo che 1000 persone partano da una posizione iniziale e facciano 16 passi, ciascuno determinato da un lancio di moneta che stabilisce se avanzare o arretrare. Dopo 16 passi, la distribuzione delle loro posizioni segue una curva normale.\n\n# Parametri\nnumero_passi &lt;- 16\nripetizioni &lt;- 1000\n\n# Generazione di passeggiate casuali\nset.seed(123)\nx &lt;- matrix(0, nrow = numero_passi + 1, ncol = ripetizioni)\n\nfor (i in 1:ripetizioni) {\n  passi &lt;- runif(numero_passi, min = -1, max = 1)\n  x[-1, i] &lt;- cumsum(passi)\n}\n\n# Grafico delle passeggiate casuali\ndf &lt;- data.frame(\n  Passo = rep(0:numero_passi, times = ripetizioni), \n  Distanza = as.vector(x)\n)\n\nggplot(\n  df, \n  aes(\n    x = Passo, \n    y = Distanza, \n    group = rep(1:ripetizioni, each = numero_passi + 1))\n  ) +\n  geom_line(color = \"blue\", alpha = 0.05) +\n  labs(\n    title = \"Passeggiate Casuali\", \n    x = \"Numero di Passi\", y = \"Distanza dall'Origine\"\n  )",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>38</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_cont_rv_distr.html#propriet√†-della-distribuzione-normale",
    "href": "chapters/probability/13_cont_rv_distr.html#propriet√†-della-distribuzione-normale",
    "title": "38¬† Distribuzioni di v.c. continue",
    "section": "\n38.5 Propriet√† della distribuzione normale",
    "text": "38.5 Propriet√† della distribuzione normale\n\n38.5.1 Media e varianza\n\n\nMedia: \\(\\mathbb{E}(Y) = \\mu\\)\n\n\nVarianza: \\(\\mathbb{V}(Y) = \\sigma^2\\)\n\n\n38.5.2 Regola empirica\nNella normale, una proporzione nota dei dati cade entro 1, 2 o 3 deviazioni standard dalla media:\n\n\n68.3% tra \\([\\mu - \\sigma, \\mu + \\sigma]\\)\n\n\n95.6% tra \\([\\mu - 2\\sigma, \\mu + 2\\sigma]\\)\n\n\n99.7% tra \\([\\mu - 3\\sigma, \\mu + 3\\sigma]\\)",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>38</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_cont_rv_distr.html#distribuzione-normale-standard",
    "href": "chapters/probability/13_cont_rv_distr.html#distribuzione-normale-standard",
    "title": "38¬† Distribuzioni di v.c. continue",
    "section": "\n38.6 Distribuzione normale standard",
    "text": "38.6 Distribuzione normale standard\nLa normale standard √® un caso speciale della normale con \\(\\mu = 0\\) e \\(\\sigma = 1\\). Ogni normale pu√≤ essere trasformata in una normale standard attraverso la formula:\n\\[\nZ = \\frac{Y - \\mu}{\\sigma}.\n\\]",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>38</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_cont_rv_distr.html#funzioni-principali-in-r",
    "href": "chapters/probability/13_cont_rv_distr.html#funzioni-principali-in-r",
    "title": "38¬† Distribuzioni di v.c. continue",
    "section": "\n38.7 Funzioni principali in R",
    "text": "38.7 Funzioni principali in R\nR offre funzioni integrate per la distribuzione normale:\n\n\ndnorm(): calcola la densit√† di probabilit√†.\n\n\npnorm(): calcola la funzione cumulativa (CDF).\n\n\nqnorm(): restituisce i quantili della distribuzione.\n\n\nrnorm(): genera valori casuali.\n\n\n38.7.1 Esempi\n\n\nDensit√†:\n\ndnorm(115, mean = 100, sd = 15)\n#&gt; [1] 0.01613\n\n\n\nProbabilit√† cumulativa:\n\npnorm(115, mean = 100, sd = 15)\n#&gt; [1] 0.8413\n\n\n\nQuantili:\n\nqnorm(0.975, mean = 100, sd = 15)\n#&gt; [1] 129.4\n\n\n\nValori casuali:\n\nset.seed(123)\nrnorm(10, mean = 100, sd = 15)\n#&gt;  [1]  91.59  96.55 123.38 101.06 101.94 125.73 106.91  81.02  89.70  93.32",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>38</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_cont_rv_distr.html#visualizzazione",
    "href": "chapters/probability/13_cont_rv_distr.html#visualizzazione",
    "title": "38¬† Distribuzioni di v.c. continue",
    "section": "\n38.8 Visualizzazione",
    "text": "38.8 Visualizzazione\nEsempio di confronto tra PDF, CDF e quantili:\n\n# Importare le librerie necessarie\nlibrary(gridExtra)\n\n# Definire i parametri\nmu &lt;- 100\nsigma &lt;- 15\n\n# Generare l'intervallo di valori per x\nx &lt;- seq(mu - 3 * sigma, mu + 3 * sigma, length.out = 1000)\n\n# PDF\npdf_plot &lt;- ggplot(\n  data.frame(x = x, pdf = dnorm(x, mean = mu, sd = sigma)), \n  aes(x = x, y = pdf)\n  ) +\n  geom_line(color = \"blue\") +\n  labs(title = \"PDF\", x = \"Valori\", y = \"Densit√†\") \n\n# CDF\ncdf_plot &lt;- ggplot(\n  data.frame(x = x, cdf = pnorm(x, mean = mu, sd = sigma)), \n  aes(x = x, y = cdf)\n  ) +\n  geom_line(color = \"orange\") +\n  labs(title = \"CDF\", x = \"Valori\", y = \"Cumulativa\")\n\n# PPF\nquantiles &lt;- seq(0.01, 0.99, length.out = 100)\nppf_plot &lt;- ggplot(\n  data.frame(\n    Quantile = quantiles, \n    Valori = qnorm(quantiles, mean = mu, sd = sigma)\n  ), \n  aes(x = Quantile, y = Valori)\n  ) +\n  geom_line(color = \"green\") +\n  labs(title = \"PPF\", x = \"Quantile\", y = \"Valori\") \n\n# Mostrare i grafici\ngrid.arrange(pdf_plot, cdf_plot, ppf_plot, ncol = 3)",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>38</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_cont_rv_distr.html#distribuzione-chi-quadrato",
    "href": "chapters/probability/13_cont_rv_distr.html#distribuzione-chi-quadrato",
    "title": "38¬† Distribuzioni di v.c. continue",
    "section": "\n38.9 Distribuzione Chi-Quadrato",
    "text": "38.9 Distribuzione Chi-Quadrato\nLa distribuzione \\(\\chi^2\\) deriva dalla distribuzione normale e descrive la somma dei quadrati di \\(k\\) variabili casuali indipendenti e identicamente distribuite (i.i.d.) che seguono la distribuzione normale standard \\(\\mathcal{N}(0, 1)\\). Una variabile casuale \\(\\chi^2_{~k}\\) con \\(k\\) gradi di libert√† √® definita come:\n\\[\nZ_1^2 + Z_2^2 + \\dots + Z_k^2,\n\\]\ndove \\(Z_1, Z_2, \\dots, Z_k \\sim \\mathcal{N}(0, 1)\\). Il parametro \\(k\\), detto gradi di libert√† (\\(\\nu\\)), determina la forma della distribuzione.\n\n38.9.1 Funzione di densit√†\nLa densit√† di probabilit√† della distribuzione \\(\\chi^2_{~\\nu}\\) √® data da:\n\\[\nf(x) = C_{\\nu} x^{\\nu/2 - 1} \\exp(-x/2), \\quad \\text{per } x &gt; 0,\n\\]\ndove \\(C_{\\nu}\\) √® una costante di normalizzazione.\n\n38.9.2 Simulazione della Distribuzione Chi-Quadrato\nUtilizziamo la definizione per simulare la distribuzione \\(\\chi^2\\) con 3 gradi di libert√†.\n\n# Impostare il seed per la riproducibilit√†\nset.seed(1234)\n\n# Generare 1000 valori casuali per 3 variabili gaussiane standard\nn &lt;- 1000\nvar1 &lt;- rnorm(n, mean = 0, sd = 1)\nvar2 &lt;- rnorm(n, mean = 0, sd = 1)\nvar3 &lt;- rnorm(n, mean = 0, sd = 1)\n\n# Calcolare la somma dei quadrati\nchi_sq_values &lt;- var1^2 + var2^2 + var3^2\n\n# Creare un dataframe per il grafico\ndata &lt;- data.frame(chi_sq_values = chi_sq_values)\n\n# Istogramma e densit√† teorica\nggplot(data, aes(x = chi_sq_values)) +\n  geom_histogram(\n    aes(y = after_stat(density)), \n    bins = 30, fill = \"lightblue\", color = \"black\", alpha = 0.7\n    ) +\n  stat_function(fun = dchisq, args = list(df = 3), color = \"red\", size = 1) +\n  labs(\n    title = \"Distribuzione Chi-Quadrato (df = 3)\",\n    x = \"Valore\",\n    y = \"Densit√†\"\n  )\n\n\n\n\n\n\n\nDescrizione:\n\nL‚Äôistogramma rappresenta i valori empirici simulati.\nLa curva rossa rappresenta la densit√† teorica della distribuzione \\(\\chi^2_{~3}\\).\n\n38.9.3 Media e Varianza Empiriche\nCalcoliamo la media e la varianza dei valori simulati:\n\n# Media empirica\nmean(chi_sq_values)\n#&gt; [1] 2.981\n\n# Varianza empirica\nvar(chi_sq_values)\n#&gt; [1] 5.968\n\nQuesti valori possono essere confrontati con le propriet√† teoriche della distribuzione \\(\\chi^2\\):\n\n\nMedia: \\(\\nu = 3\\).\n\nVarianza: \\(2\\nu = 6\\).\n\n38.9.4 Grafico per Diversi Gradi di Libert√†\nConfrontiamo le distribuzioni \\(\\chi^2\\) per diversi valori di \\(\\nu\\).\n\n# Intervallo di x\nx &lt;- seq(0, 40, by = 0.1)\n\n# Gradi di libert√†\nnus &lt;- c(2, 4, 8, 16)\n\n# Creare un dataframe\ndata &lt;- do.call(rbind, lapply(nus, function(nu) {\n  data.frame(x = x, f_x = dchisq(x, df = nu), nu = as.factor(nu))\n}))\n\n# Grafico\nggplot(data, aes(x = x, y = f_x, color = nu)) +\n  geom_line(size = 1) +\n  labs(\n    title = \"Distribuzioni Chi-Quadrato per Diversi Valori di \\u03bd\",\n    x = \"x\",\n    y = \"f(x)\",\n    color = expression(nu)\n  ) \n\n\n\n\n\n\n\n\n38.9.5 Propriet√† della Distribuzione Chi-Quadrato\n\n\nAsimmetria: La distribuzione \\(\\chi^2_{\\nu}\\) √® asimmetrica, ma diventa pi√π simmetrica al crescere di \\(\\nu\\).\n\nMedia: \\(\\mathbb{E}[\\chi^2_{\\nu}] = \\nu\\).\n\nVarianza: \\(\\mathbb{V}[\\chi^2_{\\nu}] = 2\\nu\\).\n\nConvergenza: Per \\(\\nu \\to \\infty\\), \\(\\chi^2_{\\nu} \\to \\mathcal{N}(\\nu, 2\\nu)\\).\n\nSomma: La somma di variabili \\(\\chi^2\\) indipendenti con gradi di libert√† \\(\\nu_1, \\nu_2, \\dots, \\nu_k\\) segue una distribuzione \\(\\chi^2\\) con \\(\\nu = \\sum_{i=1}^k \\nu_i\\).\n\n38.9.6 Applicazioni\nLa distribuzione \\(\\chi^2\\) √® utilizzata in molteplici ambiti statistici, tra cui:\n\n\nTest di indipendenza: Per verificare se due variabili categoriche sono indipendenti.\n\nTest di adattamento: Per confrontare una distribuzione empirica con una teorica.\n\nANOVA: Per valutare la variabilit√† nei dati.\n\nQuesta distribuzione √® particolarmente importante in contesti di inferenza statistica e si trova alla base di numerosi test parametrici.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>38</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_cont_rv_distr.html#distribuzione-t-di-student",
    "href": "chapters/probability/13_cont_rv_distr.html#distribuzione-t-di-student",
    "title": "38¬† Distribuzioni di v.c. continue",
    "section": "\n38.10 Distribuzione \\(t\\) di Student",
    "text": "38.10 Distribuzione \\(t\\) di Student\nLa distribuzione \\(t\\) di Student √® una delle distribuzioni fondamentali della statistica inferenziale. Deriva dalle distribuzioni Normale e Chi-quadrato ed √® particolarmente utile per analizzare campioni di piccole dimensioni o situazioni in cui la varianza della popolazione √® sconosciuta.\n\n38.10.1 Definizione Formale\nSe:\n\n\n\\(Z \\sim \\mathcal{N}(0, 1)\\) (distribuzione Normale standard),\n\n\\(W \\sim \\chi^2_{\\nu}\\) (distribuzione Chi-quadrato con \\(\\nu\\) gradi di libert√†),\n\ne \\(Z\\) e \\(W\\) sono indipendenti, allora la variabile casuale\n\\[\nT = \\frac{Z}{\\sqrt{\\frac{W}{\\nu}}}\n\\]\nsegue una distribuzione \\(t\\) di Student con \\(\\nu\\) gradi di libert√†. Si indica come \\(T \\sim t_{\\nu}\\).\n\n38.10.2 Propriet√† della Distribuzione \\(t\\) di Student\n\n\nForma della distribuzione:\n\nLa distribuzione \\(t\\) √® simmetrica rispetto a zero, come la Normale standard (\\(\\mathcal{N}(0, 1)\\)).\nPresenta code pi√π pesanti rispetto alla Normale, riflettendo una maggiore probabilit√† di osservare valori estremi.\n\n\n\nCode pesanti e gradi di libert√†:\n\nLa pesantezza delle code diminuisce con l‚Äôaumentare dei gradi di libert√† (\\(\\nu\\)).\nPer \\(\\nu \\to \\infty\\), la distribuzione \\(t\\) converge alla distribuzione Normale standard.\n\n\n\nMedia e varianza:\n\nLa media √® \\(0\\) per \\(\\nu &gt; 1\\).\n\nLa varianza √®:\n\\[\n\\text{Var}(T) = \\frac{\\nu}{\\nu - 2}, \\quad \\text{per } \\nu &gt; 2.\n\\]\nPer \\(\\nu \\leq 2\\), la varianza non √® definita.\n\n\n\n\nApplicazioni principali:\n\n\nTest t di Student: Confronto delle medie di due gruppi o test per una singola media.\n\nIntervalli di confidenza: Stima dell‚Äôintervallo per la media quando la varianza √® sconosciuta.\n\n\n\n38.10.3 Differenze tra la Distribuzione \\(t\\) e la Normale\n\n\n\n\n\n\n\nCaratteristica\nDistribuzione Normale\nDistribuzione \\(t\\) di Student\n\n\n\nForma\nSimmetrica, a campana\nSimmetrica, a campana\n\n\nCode\nSottili\nPesanti\n\n\nDipendenza dai gradi di libert√†\nNo\nS√¨\n\n\nConvergenza\nNon varia\nCon \\(\\nu \\to \\infty\\), converge alla Normale\n\n\n\n38.10.4 Visualizzazione della Distribuzione \\(t\\)\n\nConfrontiamo graficamente la distribuzione \\(t\\) con diversi gradi di libert√† e la distribuzione Normale standard:\n\n# Creazione dei dati\nx &lt;- seq(-4, 4, length.out = 1000)\ndf &lt;- c(1, 2, 5, 10)  # Gradi di libert√†\n\n# Dataframe con curve di densit√†\ndata &lt;- data.frame(\n  x = rep(x, length(df) + 1),\n  density = c(\n    dnorm(x),\n    dt(x, df[1]),\n    dt(x, df[2]),\n    dt(x, df[3]),\n    dt(x, df[4])\n  ),\n  distribution = rep(c(\"Normale\", paste(\"t (df =\", df, \")\")), each = length(x))\n)\n\n# Plot\nggplot(data, aes(x = x, y = density, color = distribution)) +\n  geom_line(size = 1) +\n  labs(\n    title = \"Distribuzione Normale e distribuzioni $t$ di Student\",\n    x = \"Valore\",\n    y = \"Densit√†\",\n    color = \"Distribuzione\"\n  ) \n\n\n\n\n\n\n\n\n38.10.5 Simulazione della Distribuzione \\(t\\)\n\nSimuliamo una distribuzione \\(t\\) con 10 gradi di libert√† e confrontiamola con la densit√† teorica.\n\n# Impostare il seed per la riproducibilit√†\nset.seed(123)\n\n# Simulare 1000 valori da una distribuzione t\nn &lt;- 1000\ndf &lt;- 10  # Gradi di libert√†\nt_values &lt;- rt(n, df = df)\n\n# Creare un dataframe per il grafico\ndata &lt;- data.frame(t_values = t_values)\n\n# Istogramma con densit√† teorica\nggplot(data, aes(x = t_values)) +\n  geom_histogram(\n    aes(y = after_stat(density)), \n    bins = 30, fill = \"lightblue\", color = \"black\", alpha = 0.7\n  ) +\n  stat_function(fun = dt, args = list(df = df), color = \"red\", size = 1) +\n  labs(\n    title = paste(\"Distribuzione $t$ di Student (df =\", df, \")\"),\n    x = \"Valore\",\n    y = \"Densit√†\"\n  ) \n\n\n\n\n\n\n\n\n38.10.6 Propriet√† Teoriche della Distribuzione \\(t\\)\n\n\nMedia: \\[\n\\mathbb{E}[T] = 0, \\quad \\text{per } \\nu &gt; 1.\n\\]\nVarianza: \\[\n\\mathbb{V}[T] = \\frac{\\nu}{\\nu - 2}, \\quad \\text{per } \\nu &gt; 2.\n\\]\n\nSimmetria:\n\nLa distribuzione √® simmetrica rispetto a zero, come la Normale.\n\n\n\nCode:\n\nLe code sono pi√π pesanti rispetto alla Normale, riflettendo una maggiore incertezza per piccoli campioni.\n\n\n\nIn conclusione, la distribuzione \\(t\\) di Student √® uno strumento versatile nell‚Äôinferenza statistica, trovando applicazione in contesti sia frequentisti che bayesiani. √à particolarmente utile in situazioni in cui la conoscenza della varianza √® limitata o i campioni sono di dimensioni ridotte. Grazie alla sua forma simmetrica e alle code pi√π pesanti rispetto alla distribuzione Normale, la distribuzione \\(t\\) pu√≤ modellare meglio l‚Äôincertezza, includendo una maggiore probabilit√† per valori estremi.\nNel contesto bayesiano, la distribuzione \\(t\\) viene utilizzata come:\n\n\nPrior informativo robusto, per modellare parametri con valori plausibili lontani dalla media ma con una penalizzazione graduale per valori estremi.\n\nDistribuzione predittiva per sintetizzare l‚Äôincertezza derivante da campioni piccoli o con variabilit√† elevata.\n\nIn entrambi i paradigmi, la distribuzione \\(t\\) rappresenta una scelta robusta, capace di riflettere in modo flessibile la natura dei dati. Inoltre, per valori elevati dei gradi di libert√†, la distribuzione \\(t\\) converge alla distribuzione Normale, un caso limite che ne estende ulteriormente l‚Äôutilit√† in vari contesti analitici.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>38</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_cont_rv_distr.html#funzione-beta-di-eulero",
    "href": "chapters/probability/13_cont_rv_distr.html#funzione-beta-di-eulero",
    "title": "38¬† Distribuzioni di v.c. continue",
    "section": "\n38.11 Funzione Beta di Eulero",
    "text": "38.11 Funzione Beta di Eulero\nLa funzione Beta di Eulero √® una funzione matematica, non una densit√† di probabilit√†, ma √® strettamente collegata alla distribuzione Beta, poich√© appare nella sua definizione. Indicata comunemente con il simbolo \\(\\mathcal{B}(\\alpha, \\beta)\\), la funzione Beta pu√≤ essere espressa in vari modi. Per i nostri scopi, utilizziamo la seguente definizione:\n\\[\n\\mathcal{B}(\\alpha, \\beta) = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)}\\,,\n\\]\ndove \\(\\Gamma(x)\\) rappresenta la funzione Gamma, una generalizzazione del fattoriale definita per numeri reali positivi. Quando \\(x\\) √® un numero intero, la funzione Gamma si riduce al fattoriale traslato:\n\\[\n\\Gamma(x) = (x-1)!.\n\\]\n\nEsempio 38.1 Supponiamo di voler calcolare \\(\\mathcal{B}(3, 9)\\). Utilizzando la definizione, abbiamo:\n\\[\n\\mathcal{B}(3, 9) = \\frac{\\Gamma(3) \\cdot \\Gamma(9)}{\\Gamma(3 + 9)}.\n\\]\nIn R, possiamo calcolarla in tre modi diversi.\n\nUtilizzando la definizione con la funzione gamma():\n\n\nalpha &lt;- 3\nbeta &lt;- 9\n\nbeta_function &lt;- gamma(alpha) * gamma(beta) / gamma(alpha + beta)\nbeta_function\n#&gt; [1] 0.00202\n\n\nUtilizzando direttamente la funzione beta() di R:\n\n\nbeta(alpha, beta)\n#&gt; [1] 0.00202\n\n\nCalcolo manuale con fattoriali:\n\n\n(factorial(alpha - 1) * factorial(beta - 1)) / factorial(alpha + beta - 1)\n#&gt; [1] 0.00202\n\nTutti e tre i metodi restituiscono lo stesso risultato, confermando la correttezza della definizione.\n\nLa funzione Beta √® utilizzata nella definizione della densit√† di probabilit√† Beta. Essa serve a normalizzare la densit√†, garantendo che l‚Äôarea sotto la curva sia pari a \\(1\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>38</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_cont_rv_distr.html#distribuzione-beta",
    "href": "chapters/probability/13_cont_rv_distr.html#distribuzione-beta",
    "title": "38¬† Distribuzioni di v.c. continue",
    "section": "\n38.12 Distribuzione Beta",
    "text": "38.12 Distribuzione Beta\nLa distribuzione Beta, indicata come \\(\\mathcal{Beta}(\\alpha, \\beta)\\), √® una distribuzione di probabilit√† continua definita sull‚Äôintervallo \\((0, 1)\\). √à particolarmente utile per modellare proporzioni, probabilit√† o qualsiasi fenomeno limitato tra 0 e 1.\n\nDefinizione 38.3 Se una variabile casuale \\(\\theta\\) segue una distribuzione Beta con parametri \\(\\alpha &gt; 0\\) e \\(\\beta &gt; 0\\), indicata come \\(\\theta \\sim \\mathcal{Beta}(\\alpha, \\beta)\\), la sua funzione di densit√† √® data da:\n\\[\n\\mathcal{Beta}(\\theta \\mid \\alpha, \\beta) = \\frac{1}{B(\\alpha, \\beta)} \\theta^{\\alpha-1} (1-\\theta)^{\\beta-1}, \\quad \\theta \\in (0, 1),\n\\]\ndove \\(\\mathcal{B}(\\alpha, \\beta)\\) √® la funzione Beta di Eulero.\n\nUn‚Äôaltra rappresentazione equivalente √®:\n\\[\n\\mathcal{Beta}(\\theta \\mid \\alpha, \\beta) = \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} \\theta^{\\alpha-1} (1-\\theta)^{\\beta-1}, \\quad \\theta \\in (0, 1).\n\\]\n\n38.12.1 Ruolo dei Parametri \\(\\alpha\\) e \\(\\beta\\)\n\nI parametri \\(\\alpha\\) e \\(\\beta\\) determinano la forma della distribuzione:\n\n\n\\(\\alpha &gt; 1\\): favorisce valori di \\(\\theta\\) vicini a 1.\n\n\\(\\beta &gt; 1\\): favorisce valori di \\(\\theta\\) vicini a 0.\n\n\\(\\alpha = \\beta = 1\\): corrisponde alla distribuzione uniforme sull‚Äôintervallo \\([0, 1]\\).\n\n\\(\\alpha, \\beta &lt; 1\\): la distribuzione √® bimodale, concentrandosi agli estremi (vicino a 0 e 1).\n\n38.12.2 Propriet√† della Distribuzione Beta\n\nValore atteso: \\[\n\\mathbb{E}(\\theta) = \\frac{\\alpha}{\\alpha + \\beta}.\n\\]\nVarianza: \\[\n\\mathbb{V}(\\theta) = \\frac{\\alpha \\beta}{(\\alpha + \\beta)^2 (\\alpha + \\beta + 1)}.\n\\]\nModa (se \\(\\alpha, \\beta &gt; 1\\)): \\[\n\\text{Moda}(\\theta) = \\frac{\\alpha - 1}{\\alpha + \\beta - 2}.\n\\]\n\nQueste propriet√† evidenziano come \\(\\alpha\\) e \\(\\beta\\) possano essere interpretati come ‚Äúsuccessi‚Äù e ‚Äúfallimenti‚Äù in una serie di prove, fornendo un collegamento intuitivo con la distribuzione binomiale.\n\n38.12.3 Relazione con la Distribuzione Binomiale\nLa distribuzione Beta pu√≤ essere vista come una generalizzazione continua della distribuzione binomiale. In particolare, mentre la distribuzione binomiale modella il numero di successi in una serie di prove, la distribuzione Beta modella la probabilit√† di successo come una variabile casuale.\nNell‚Äôinferenza bayesiana, la distribuzione Beta √® spesso utilizzata come prior coniugato per la distribuzione binomiale. Ad esempio:\n\nse \\(\\theta \\sim \\mathcal{Beta}(\\alpha, \\beta)\\) √® il prior,\ne osserviamo \\(x\\) successi in \\(n\\) prove, allora la distribuzione a posteriori √®:\n\n\\[\n\\theta \\mid \\text{dati} \\sim \\mathcal{Beta}(\\alpha + x, \\beta + n - x).\n\\]\nQuesta propriet√† consente un aggiornamento semplice delle credenze basato sui dati osservati.\n\n38.12.4 Visualizzazione della Distribuzione Beta\nDi seguito mostriamo come la forma della distribuzione Beta varia al variare dei parametri \\(\\alpha\\) e \\(\\beta\\):\n\n# Parametri\nx &lt;- seq(0, 1, length.out = 200)\nalphas &lt;- c(0.5, 5.0, 1.0, 2.0, 2.0)\nbetas &lt;- c(0.5, 1.0, 3.0, 2.0, 5.0)\n\n# Creare un dataframe\ndf &lt;- do.call(rbind, lapply(1:length(alphas), function(i) {\n  data.frame(\n    x = x,\n    density = dbeta(x, alphas[i], betas[i]),\n    label = paste0(\"Œ± = \", alphas[i], \", Œ≤ = \", betas[i])\n  )\n}))\n\n# Plot\nggplot(df, aes(x = x, y = density, color = label)) +\n  geom_line(size = 1) +\n  labs(\n    x = \"x\",\n    y = \"f(x)\",\n    title = \"Distribuzioni Beta\"\n  ) +\n  theme(legend.title = element_blank())\n\n\n\n\n\n\n\n\n38.12.5 Costante di Normalizzazione\nLa costante di normalizzazione della distribuzione Beta √® il reciproco della funzione Beta di Eulero, \\(B(\\alpha, \\beta)\\). Questa garantisce che:\n\\[\n\\int_0^1 \\mathcal{Beta}(\\theta \\mid \\alpha, \\beta) \\, d\\theta = 1.\n\\]\n\nEsempio 38.2 Di seguito viene proposto un esempio in R per calcolare l‚Äôarea sottesa alla distribuzione Beta non normalizzata e, con gli stessi parametri, ottenere il valore della funzione Beta di Eulero. L‚Äôobiettivo √® mostrare come la costante di normalizzazione, pari al reciproco di \\(B(\\alpha, \\beta)\\), garantisca che l‚Äôintegrale della densit√† normalizzata su \\([0,1]\\) sia pari a 1.\nSupponiamo di voler utilizzare i parametri:\n\n\\(\\alpha = 2\\)\n\\(\\beta = 5\\)\n\n\n# Parametri della distribuzione Beta\nalpha &lt;- 2\nbeta  &lt;- 5\n\n# Definiamo la funzione non normalizzata della distribuzione Beta\nunnormalized_beta &lt;- function(theta) {\n  theta^(alpha - 1) * (1 - theta)^(beta - 1)\n}\n\n# Calcoliamo l'integrale della funzione non normalizzata su [0, 1]\nintegrale &lt;- integrate(unnormalized_beta, lower = 0, upper = 1)$value\ncat(\"Integrale della funzione non normalizzata:\", integrale, \"\\n\")\n#&gt; Integrale della funzione non normalizzata: 0.03333\n\n# Calcoliamo il valore della funzione Beta usando la funzione beta() di R\nvalore_beta &lt;- beta(alpha, beta)\ncat(\"Valore della funzione Beta B(alpha, beta):\", valore_beta, \"\\n\")\n#&gt; Valore della funzione Beta B(alpha, beta): 0.03333\n\n# Verifichiamo che l'integrale calcolato coincide con B(alpha, beta)\nif (abs(integrale - valore_beta) &lt; 1e-8) {\n  cat(\"L'integrale coincide con il valore della funzione Beta.\\n\")\n} else {\n  cat(\"C'√® una discrepanza tra l'integrale e il valore della funzione Beta.\\n\")\n}\n#&gt; L'integrale coincide con il valore della funzione Beta.\n\n# Calcoliamo la costante di normalizzazione, che √® il reciproco della funzione Beta\ncostante_normalizzazione &lt;- 1 / valore_beta\ncat(\"Costante di normalizzazione (1 / B(alpha, beta)):\", costante_normalizzazione, \"\\n\")\n#&gt; Costante di normalizzazione (1 / B(alpha, beta)): 30\n\n# Verifica: l'integrale della densit√† normalizzata deve essere 1\ndensita_normalizzata &lt;- function(theta) {\n  costante_normalizzazione * unnormalized_beta(theta)\n}\nintegrale_normalizzato &lt;- integrate(densita_normalizzata, lower = 0, upper = 1)$value\ncat(\"Integrale della densit√† normalizzata:\", integrale_normalizzato, \"\\n\")\n#&gt; Integrale della densit√† normalizzata: 1\n\nSpiegazione del Codice\n\nDefinizione dei Parametri e della Funzione\nImpostiamo \\(\\alpha = 2\\) e \\(\\beta = 5\\) e definiamo la funzione non normalizzata: \\[\nf(\\theta) = \\theta^{\\alpha-1}(1-\\theta)^{\\beta-1}.\n\\]\nCalcolo dell‚ÄôIntegrale\nUtilizzando la funzione integrate(), calcoliamo l‚Äôarea sottesa a \\(f(\\theta)\\) nell‚Äôintervallo \\([0,1]\\), che corrisponde a \\(\\mathcal{B}(\\alpha, \\beta)\\).\nVerifica con la Funzione Beta\nLa funzione beta(alpha, beta) di R restituisce direttamente il valore di \\(\\mathcal{B}(\\alpha, \\beta)\\). La stampa dei due valori conferma che l‚Äôintegrale calcolato e il valore della funzione Beta coincidono.\nCostante di Normalizzazione\nIl reciproco di \\(\\mathcal{B}(\\alpha, \\beta)\\) √® calcolato e utilizzato per definire la densit√† normalizzata della distribuzione Beta. L‚Äôintegrazione della densit√† normalizzata su \\([0,1]\\) restituisce 1, confermando la corretta normalizzazione.\n\nQuesto esempio in R mostra in modo pratico come la costante di normalizzazione derivi dalla funzione Beta di Eulero e come essa venga applicata per ottenere una densit√† di probabilit√† correttamente normalizzata.\n\nIn conclusione, la distribuzione Beta si rivela particolarmente utile per modellare variabili continue comprese nell‚Äôintervallo [0, 1]. Grazie alla sua parametrizzazione tramite \\(\\alpha\\) e \\(\\beta\\), consente di adattare la forma della densit√† in modo specifico alle caratteristiche osservate dei dati, facilitando la stima di proporzioni. Inoltre, essendo il coniugato della distribuzione binomiale, permette un aggiornamento analitico nei modelli bayesiani, semplificando l‚Äôinferenza quando si raccolgono dati incrementali, come nella stima della probabilit√† di successo in esperimenti o studi psicologici.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>38</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_cont_rv_distr.html#distribuzione-di-cauchy",
    "href": "chapters/probability/13_cont_rv_distr.html#distribuzione-di-cauchy",
    "title": "38¬† Distribuzioni di v.c. continue",
    "section": "\n38.13 Distribuzione di Cauchy",
    "text": "38.13 Distribuzione di Cauchy\nLa distribuzione di Cauchy √® un caso speciale della distribuzione \\(t\\) di Student con un solo grado di libert√† (\\(t_1\\)). Questa distribuzione √® caratterizzata da code molto pesanti e da una media e varianza non definite, rendendola particolarmente utile in contesti dove valori estremi possono avere un‚Äôinfluenza importante.\n\nDefinizione 38.4 La funzione di densit√† di probabilit√† della distribuzione di Cauchy √® definita da due parametri:\n\n\n\\(\\alpha\\): posizione (location), che determina il centro della distribuzione.\n\n\\(\\beta &gt; 0\\): scala (scale), che controlla la larghezza della distribuzione.\n\nLa densit√† √® data da:\n\\[\nf(x \\mid \\alpha, \\beta) = \\frac{1}{\\pi \\beta \\left[1 + \\left( \\frac{x - \\alpha}{\\beta} \\right)^2\\right]} ,\n\\]\ndove:\n\n\n\\(x \\in \\mathbb{R}\\),\n\n\\(\\alpha \\in \\mathbb{R}\\),\n\n\\(\\beta &gt; 0\\).\n\nQuesta funzione descrive una distribuzione simmetrica attorno a \\(\\alpha\\), con code pi√π pesanti rispetto alla distribuzione Normale.\n\n\n38.13.1 Propriet√† della Distribuzione di Cauchy\n\n\nSimmetria: La distribuzione √® simmetrica rispetto a \\(\\alpha\\).\n\nCode Pesanti: Le code sono significativamente pi√π pesanti rispetto alla distribuzione Normale, con una decrescita pi√π lenta (\\(\\propto x^{-2}\\)).\n\nMedia e Varianza: La distribuzione non ha una media n√© una varianza definita.\n\nRelazione con \\(t_1\\): La distribuzione di Cauchy √® equivalente a una distribuzione \\(t\\) di Student con 1 grado di libert√†.\n\nCaratteristiche Estreme: I valori estremi hanno una probabilit√† pi√π alta rispetto ad altre distribuzioni comuni, rendendola utile per modellare fenomeni con outlier significativi.\n\n38.13.2 Visualizzazione della Distribuzione di Cauchy\nPer comprendere l‚Äôeffetto dei parametri \\(\\alpha\\) e \\(\\beta\\) sulla forma della distribuzione, consideriamo alcuni esempi con:\n\n\n\\(\\alpha = 0.0, 0.0, 0.0, -2.0\\),\n\n\\(\\beta = 0.5, 1.0, 2.0, 1.0\\).\n\n\n# Definire i parametri\nx &lt;- seq(-5, 5, length.out = 500)\nalphas &lt;- c(0.0, 0.0, 0.0, -2.0)\nbetas &lt;- c(0.5, 1.0, 2.0, 1.0)\n\n# Creare un data frame per i risultati\ndf &lt;- do.call(rbind, lapply(1:length(alphas), function(i) {\n  data.frame(\n    x = x,\n    density = dcauchy(x, location = alphas[i], scale = betas[i]),\n    label = paste0(\"Œ± = \", alphas[i], \", Œ≤ = \", betas[i])\n  )\n}))\n\n# Grafico\nggplot(df, aes(x = x, y = density, color = label)) +\n  geom_line(size = 1) +\n  labs(\n    x = \"x\",\n    y = \"f(x)\",\n    title = \"Distribuzioni di Cauchy con diversi parametri\"\n  ) +\n  theme(\n    legend.title = element_blank()\n  )\n\n\n\n\n\n\n\n\n38.13.3 Applicazioni della Distribuzione di Cauchy\n\n\nInferenza Bayesiana:\n\nUtilizzata come prior robusto in modelli bayesiani, particolarmente quando si vuole attribuire una probabilit√† maggiore a valori estremi rispetto a una distribuzione Normale.\n\n\n\nModellazione di Fenomeni con Outlier:\n\nLa distribuzione di Cauchy √® adatta per descrivere dati con valori estremi significativi che possono influenzare fortemente altre distribuzioni.\n\n\n\nIn conclusione, la distribuzione di Cauchy, con le sue propriet√† uniche come code pesanti e l‚Äôassenza di media e varianza definite, √® uno strumento fondamentale per modellare fenomeni in cui i valori estremi giocano un ruolo importante. La sua relazione con la distribuzione \\(t\\) di Student e la sua utilit√† nei modelli bayesiani ne ampliano ulteriormente le applicazioni in contesti statistici e probabilistici avanzati.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>38</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_cont_rv_distr.html#distribuzione-gamma",
    "href": "chapters/probability/13_cont_rv_distr.html#distribuzione-gamma",
    "title": "38¬† Distribuzioni di v.c. continue",
    "section": "\n38.14 Distribuzione Gamma",
    "text": "38.14 Distribuzione Gamma\nLa distribuzione Gamma √® una distribuzione di probabilit√† continua utilizzata principalmente per modellare variabili strettamente positive, come tassi, varianze, o tempi di attesa. √à usata nella statistica bayesiana come distribuzione a priori per parametri positivi e trova applicazione in ambiti come la modellazione di eventi rari.\n\nDefinizione 38.5 La distribuzione Gamma √® caratterizzata da due parametri principali:\n\n\nParametro di forma (\\(\\alpha\\)): determina la forma generale della distribuzione.\n\nParametro di scala (\\(\\theta\\)) o, alternativamente, il parametro di tasso (\\(\\beta = 1/\\theta\\)): regola la larghezza o la dispersione della distribuzione.\n\nLa funzione di densit√† di probabilit√† (PDF) √® data da:\n\\[\nf(x \\mid \\alpha, \\theta) = \\frac{x^{\\alpha-1} e^{-x/\\theta}}{\\theta^\\alpha \\Gamma(\\alpha)}, \\quad x &gt; 0,\n\\]\ndove:\n\n\n\\(x\\) √® la variabile casuale continua,\n\n\\(\\Gamma(\\alpha)\\) √® la funzione Gamma di Eulero, definita come:\n\n\\[\n\\Gamma(\\alpha) = \\int_0^\\infty t^{\\alpha-1} e^{-t} dt.\n\\]\nSe utilizziamo il parametro di tasso \\(\\beta = 1/\\theta\\), la PDF pu√≤ essere scritta come:\n\\[\nf(x \\mid \\alpha, \\beta) = \\frac{\\beta^\\alpha x^{\\alpha-1} e^{-\\beta x}}{\\Gamma(\\alpha)}, \\quad x &gt; 0.\n\\]\n\n\n38.14.1 Propriet√† della Distribuzione Gamma\n\nMedia: \\[\n\\mathbb{E}[X] = \\alpha \\cdot \\theta = \\frac{\\alpha}{\\beta}.\n\\]\nVarianza: \\[\n\\text{Var}(X) = \\alpha \\cdot \\theta^2 = \\frac{\\alpha}{\\beta^2}.\n\\]\nModa (per \\(\\alpha &gt; 1\\)): \\[\n\\text{Moda}(X) = (\\alpha - 1) \\cdot \\theta.\n\\]\n\nDi seguito, mostriamo un esempio per \\(\\alpha = 3\\) e \\(\\beta = 5/3\\), calcolando e rappresentando graficamente la distribuzione.\n\n\nCalcolo della Media e della Deviazione Standard:\n\n# Parametri\nalpha &lt;- 3\nbeta &lt;- 5 / 3\n\n# Calcolo\nmean &lt;- alpha / beta\nsigma &lt;- sqrt(alpha / beta^2)\n\ncat(\"Media:\", mean, \"\\n\")\n#&gt; Media: 1.8\ncat(\"Deviazione Standard:\", sigma, \"\\n\")\n#&gt; Deviazione Standard: 1.039\n\n\n\nGenerazione e Plot dei Dati:\n\n# Generazione di dati\nset.seed(123)\ndata &lt;- rgamma(100000, shape = alpha, rate = beta)\n\n# Data frame per ggplot\ndf &lt;- data.frame(values = data)\n\n# Plot\nggplot(df, aes(x = values)) +\n  geom_histogram(aes(y = ..density..), bins = 30, fill = \"green\", alpha = 0.6) +\n  stat_function(fun = function(x) dgamma(x, shape = alpha, rate = beta),\n                color = \"red\", size = 1) +\n  labs(\n    x = \"Valore\",\n    y = \"Densit√† di probabilit√†\",\n    title = \"Distribuzione Gamma con Œ±=3 e Œ≤=5/3\"\n  ) \n\n\n\n\n\n\n\n\n\n38.14.2 Applicazioni della Distribuzione Gamma\n\nModellazione del Tempo di Attesa:\nLa distribuzione Gamma √® ideale per modellare tempi di attesa, ad esempio, il tempo necessario affinch√© si verifichino \\(n\\) eventi in un processo di Poisson.\n\nInferenza Bayesiana:\n\nUtilizzata come prior per parametri positivi, come tassi (\\(\\lambda\\)) o varianze (\\(\\sigma^2\\)).\nAd esempio, nella modellazione bayesiana dei processi di Poisson, una distribuzione Gamma √® una scelta naturale per il prior su \\(\\lambda\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>38</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_cont_rv_distr.html#riflessioni-conclusive",
    "href": "chapters/probability/13_cont_rv_distr.html#riflessioni-conclusive",
    "title": "38¬† Distribuzioni di v.c. continue",
    "section": "\n38.15 Riflessioni conclusive",
    "text": "38.15 Riflessioni conclusive\nLe distribuzioni di probabilit√† costituiscono il cuore dell‚Äôinferenza statistica, sia bayesiana che frequentista. In questo capitolo, abbiamo esplorato come R offre un insieme completo di strumenti per lavorare con diverse distribuzioni, permettendo di modellare e analizzare una vasta gamma di fenomeni.\n\n38.15.1 Principali Applicazioni\n\n\nInferenza Bayesiana:\nLe distribuzioni di probabilit√†, come la Beta, la Gamma e la Normale, sono essenziali per definire priors, calcolare posteriori e quantificare l‚Äôincertezza nei modelli bayesiani. Ad esempio:\n\nLa distribuzione Beta √® ideale per modellare credenze a priori su proporzioni o probabilit√†.\nLa distribuzione Gamma √® ampiamente usata per modellare parametri positivi come tassi o varianze.\n\n\nAnalisi Statistica e Modellazione:\nLe distribuzioni, come la \\(t\\) di Student, sono fondamentali per il confronto tra campioni, mentre la Normale √® indispensabile per modellare fenomeni che seguono la legge del limite centrale.\nGenerazione e Simulazione di Dati:\nR permette di generare campioni casuali da distribuzioni comuni, utili per simulazioni, bootstrap e validazione di modelli.\n\n38.15.2 Funzionalit√† di R\nCon poche funzioni, R consente di:\n\n\nGenerare campioni casuali: con funzioni come rnorm, rgamma, rbeta, possiamo simulare dati da distribuzioni specifiche.\n\nCalcolare densit√†: ad esempio, con dnorm, dgamma, dbeta, possiamo visualizzare le funzioni di densit√†.\n\nCalcolare probabilit√† cumulate: con funzioni come pnorm, pbeta, possiamo determinare probabilit√† su intervalli specifici.\n\nDeterminare quantili: con funzioni come qnorm, qgamma, possiamo calcolare i punti corrispondenti a specifici livelli di probabilit√†.\n\n38.15.3 Versatilit√† delle Distribuzioni\nLe distribuzioni esplorate non solo descrivono fenomeni naturali, ma sono anche i ‚Äúmattoncini‚Äù per costruire modelli statistici complessi. Le loro propriet√†, come la media, la varianza, la simmetria o le code pesanti, consentono di adattare il modello al fenomeno studiato.\nIn conclusione, il linguaggio R, con la sua flessibilit√† e ricchezza di strumenti, permette di padroneggiare le distribuzioni di probabilit√†, non solo come oggetti matematici, ma anche come strumenti pratici per rispondere a domande complesse. La comprensione e l‚Äôuso delle distribuzioni presentate costituiscono le fondamenta per avanzare verso tecniche pi√π sofisticate, come l‚Äôinferenza bayesiana avanzata o la modellazione gerarchica.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>38</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_cont_rv_distr.html#esercizi",
    "href": "chapters/probability/13_cont_rv_distr.html#esercizi",
    "title": "38¬† Distribuzioni di v.c. continue",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nEsercizi sulla distribuzione normale, risolvibili usando R, sono disponibili sulla seguente pagina web.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>38</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_cont_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/13_cont_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "title": "38¬† Distribuzioni di v.c. continue",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.5.3     \n#&gt;  [9] scales_1.3.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.9.1   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         rlang_1.1.5       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       tools_4.4.2       parallel_4.4.2    tzdb_0.5.0       \n#&gt; [21] colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5       R6_2.6.1         \n#&gt; [25] lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.1    \n#&gt; [29] gtable_0.3.6      glue_1.8.0        xfun_0.51         tidyselect_1.2.1 \n#&gt; [33] rstudioapi_0.17.1 farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-167     \n#&gt; [37] labeling_0.4.3    rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>38</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_cont_rv_distr.html#bibliografia",
    "href": "chapters/probability/13_cont_rv_distr.html#bibliografia",
    "title": "38¬† Distribuzioni di v.c. continue",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlitzstein, J. K., & Hwang, J. (2019). Introduction to probability. CRC Press.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>38</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_gauss.html",
    "href": "chapters/probability/14_gauss.html",
    "title": "39¬† Assunzione di gaussianit√† e trasformazioni dei dati",
    "section": "",
    "text": "39.1 Introduzione\nNell‚Äôanalisi dei dati numerici, un aspetto cruciale da affrontare √® l‚Äôimprecisione delle misurazioni, una caratteristica intrinseca dei dati reali. Anche in condizioni ottimali, le misure sono soggette a incertezze: i dati rappresentano sempre una stima approssimativa della realt√†, accurata solo entro un certo margine (ad esempio, pochi punti percentuali). Inoltre, in molti contesti, come quelli demografici, commerciali o sociali, i dati possono essere arrotondati intenzionalmente o risultare imprecisi a causa di stime indirette, incompletezza delle informazioni o altri fattori.\nRiconoscere e gestire questa incertezza √® una componente essenziale del processo analitico. Gli strumenti statistici forniscono un framework formale per descrivere e quantificare l‚Äôincertezza, consentendo di trarre inferenze robuste dai dati. Tra le distribuzioni di probabilit√†, la distribuzione normale (o gaussiana) occupa un posto centrale per la sua ubiquit√† e versatilit√†. Spesso rappresentata dalla caratteristica ‚Äúcurva a campana,‚Äù questa distribuzione √® utilizzata per descrivere molte variabili naturali. Quando i dati approssimano una distribuzione normale, gran parte dei valori si concentra intorno alla media, con una diminuzione progressiva della probabilit√† di valori estremi.\nUna delle propriet√† pi√π utili della distribuzione normale √® la possibilit√† di esprimere affermazioni quantitative rigorose. Ad esempio, si pu√≤ calcolare la probabilit√† che un valore cada entro un determinato intervallo dalla media utilizzando parametri semplici come media (\\(\\mu\\)) e deviazione standard (\\(\\sigma\\)):\npnorm(1) - pnorm(-1)\n#&gt; [1] 0.6827\npnorm(3) - pnorm(-3)\n#&gt; [1] 0.9973\nQuesti calcoli costituiscono la base della ‚Äúregola delle tre sigma,‚Äù una strategia utilizzata per identificare valori anomali (outlier), come discusso nel Capitolo 24. Tuttavia, tale regola pu√≤ risultare fuorviante se i dati non seguono effettivamente una distribuzione normale.\nLa densit√† della distribuzione normale √® definita dalla formula:\n\\[\np(x) = \\frac{1}{\\sqrt{2\\pi}\\,\\sigma} \\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right),\n\\]\ndove \\(\\mu\\) rappresenta la media e \\(\\sigma\\) la deviazione standard. Conoscere questi due parametri permette di calcolare propriet√† fondamentali della distribuzione e di stimare probabilit√† associate a intervalli specifici.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>39</span>¬† <span class='chapter-title'>Assunzione di gaussianit√† e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_gauss.html#introduzione",
    "href": "chapters/probability/14_gauss.html#introduzione",
    "title": "39¬† Assunzione di gaussianit√† e trasformazioni dei dati",
    "section": "",
    "text": "Circa il 68.3% dei valori cade entro una deviazione standard dalla media:\n\n\n\nCirca il 99.7% cade entro tre deviazioni standard:\n\n\n\n\n\n\n\n39.1.1 Gaussianit√† e Inferenza Statistica\nLa distribuzione normale √® particolarmente rilevante per molti metodi statistici, in particolare nell‚Äôapproccio frequentista. Gran parte dei test di ipotesi e delle procedure inferenziali assume che i dati siano distribuiti normalmente, una condizione necessaria per derivare formalmente i risultati di molti test. Ad esempio, i test t di Student e l‚ÄôANOVA richiedono la normalit√† delle variabili o dei residui. Quando questa assunzione √® soddisfatta, tali strumenti offrono inferenze precise e affidabili.\nTuttavia, se i dati non sono gaussiani, molti test perdono validit√†. Sebbene si siano proposti approcci che dimostrano la robustezza di alcuni test a deviazioni moderate dalla normalit√† (Shatz, 2024), tale robustezza non √® garantita in tutte le situazioni. Inoltre, l‚Äôenfasi sui valori-p complica la questione, poich√© violazioni dell‚Äôassunzione di normalit√† possono compromettere l‚Äôinterpretazione di questi indicatori.\nUna strategia comune per affrontare la non-gaussianit√† √® l‚Äôapplicazione di trasformazioni dei dati, come la trasformazione logaritmica o quella della radice quadrata, per avvicinare i dati alla distribuzione normale (Osborne, 2002). Ad esempio, distribuzioni asimmetriche come quelle dei tempi di reazione possono essere rese pi√π gaussiane attraverso trasformazioni adeguate, rendendo applicabili i test frequentisti standard. Tuttavia, l‚Äôuso delle trasformazioni ha un costo: la perdita di interpretabilit√†. Se i dati originali avevano un significato chiaro e intuitivo, la trasformazione pu√≤ rendere i risultati pi√π difficili da collegare al fenomeno studiato.\nIn questo capitolo, esploreremo come verificare se i dati seguono una distribuzione normale, discuteremo l‚Äôimpatto di questa assunzione sui metodi frequentisti e valuteremo il ruolo delle trasformazioni. Il nostro obiettivo √® fornire al data analyst una guida pratica per decidere come trattare i dati non gaussiani, considerando sia i vantaggi che i limiti di ciascun approccio.\n\n39.1.2 L‚Äôassunzione di Gaussianit√†: Quando √® valida?\nSebbene la distribuzione normale sia spesso un buon modello per i dati numerici, non √® sempre una rappresentazione adeguata. Questo pu√≤ dipendere da caratteristiche intrinseche dei dati, come asimmetrie, code lunghe o la presenza di valori anomali. Valutare l‚Äôappropriatezza dell‚Äôassunzione di normalit√† √® un passaggio critico in qualsiasi analisi statistica.\nPer diagnosticare la normalit√†, presenteremo tre strumenti grafici:\n\n\nIstogrammi, una visualizzazione semplice ma spesso limitata.\n\nGrafici di densit√†, che forniscono un confronto pi√π fluido rispetto agli istogrammi.\n\nQQ-plot (Quantile-Quantile plot), uno strumento visivo particolarmente efficace per rilevare deviazioni dalla normalit√†.\n\nQuesti strumenti possono anche essere affiancati da test formali per consentire una diagnosi robusta e guidare le decisioni sul trattamento dei dati.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>39</span>¬† <span class='chapter-title'>Assunzione di gaussianit√† e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_gauss.html#istogramma",
    "href": "chapters/probability/14_gauss.html#istogramma",
    "title": "39¬† Assunzione di gaussianit√† e trasformazioni dei dati",
    "section": "\n39.2 Istogramma",
    "text": "39.2 Istogramma\nPer illustrare il concetto, utilizziamo un set di dati simulati che hanno propriet√† simili a quelle dei tempi di reazione. Creeremo un istogramma e vi sovrapporremo la curva di densit√† normale calcolata in base ai dati.\n\n# Dati simulati di tempi di reazione\nset.seed(123)\nrt &lt;- c(rexp(100, rate = 0.2), 50, 60) # Aggiunti valori estremi\n\n# Calcolare la media e la deviazione standard per sovrapporre la densit√† normale\nmean_rt &lt;- mean(rt, na.rm = TRUE)\nsd_rt &lt;- sd(rt, na.rm = TRUE)\n\n# Creare l'istogramma e sovrapporre la densit√† normale\nggplot(tibble(rt=rt), aes(x = rt)) +\n  geom_histogram(\n    aes(y = ..density..),\n    bins = 30, color = \"black\"\n  ) +\n  stat_function(\n    fun = dnorm,\n    args = list(mean = mean_rt, sd = sd_rt),\n    size = 1\n  ) +\n  labs(\n    title = \"Istogramma dei Tempi di Reazione\\ne Densit√† Normale\",\n    x = \"Tempi di Reazione\",\n    y = \"Densit√†\"\n  )\n\n\n\n\n\n\n\nL‚Äôistogramma mostra la distribuzione empirica dei dati, mentre la curva rossa rappresenta la densit√† normale con la stessa media e deviazione standard. Nel nostro caso, √® evidente una discrepanza tra la distribuzione empirica e la densit√† normale, indicando che l‚Äôassunzione di normalit√† non √® appropriata.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>39</span>¬† <span class='chapter-title'>Assunzione di gaussianit√† e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_gauss.html#grafico-di-densit√†",
    "href": "chapters/probability/14_gauss.html#grafico-di-densit√†",
    "title": "39¬† Assunzione di gaussianit√† e trasformazioni dei dati",
    "section": "\n39.3 Grafico di densit√†",
    "text": "39.3 Grafico di densit√†\nUn grafico di densit√† √® una versione lisciata dell‚Äôistogramma che facilita il confronto con la distribuzione normale. Utilizzando il dataset precedente, possiamo creare un grafico di densit√† sovrapposto alla curva gaussiana.\n\nggplot(tibble(rt=rt), aes(x = rt)) +\n  geom_density(alpha = 0.5) +\n  stat_function(\n    fun = dnorm,\n    args = list(mean = mean_rt, sd = sd_rt),\n    size = 1\n  ) +\n  labs(\n    title = \"Grafico di Densit√† del Peso dei Pulcini e\\nDensit√† Normale\",\n    x = \"Peso\",\n    y = \"Densit√†\"\n  )\n\n\n\n\n\n\n\nAnche questa rappresentazione rende chiaro come l‚Äôassunzione di normalit√† non sia appropriata.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>39</span>¬† <span class='chapter-title'>Assunzione di gaussianit√† e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_gauss.html#diagramma-quantile-quantile",
    "href": "chapters/probability/14_gauss.html#diagramma-quantile-quantile",
    "title": "39¬† Assunzione di gaussianit√† e trasformazioni dei dati",
    "section": "\n39.4 Diagramma quantile-quantile",
    "text": "39.4 Diagramma quantile-quantile\nIl diagramma quantile-quantile (QQ-plot) √® lo strumento pi√π utile per analizzare visivamente la conformit√† di un dataset a una distribuzione teorica, in particolare alla distribuzione normale. Il QQ-plot √® una tecnica essenziale per chi lavora con dati che si presume seguano una distribuzione specifica, e rappresenta un passaggio cruciale in molte analisi statistiche, soprattutto per verificare l‚Äôassunto di normalit√†.\nUn QQ-plot permette di:\n\n\nValutare graficamente la normalit√† dei dati: Se i punti nel diagramma seguono approssimativamente una linea retta, i dati possono essere considerati normalmente distribuiti. In caso contrario, il QQ-plot rivela deviazioni dalla normalit√†, come code pesanti o asimmetrie.\n\nConfrontare distribuzioni: Il QQ-plot non si limita solo alla distribuzione normale, ma pu√≤ essere utilizzato per confrontare la distribuzione del campione con qualsiasi distribuzione teorica, facilitando l‚Äôanalisi di dati con forme di distribuzione complesse.\n\nIdentificare outlier: Gli outlier nei dati saranno visibili come punti che si discostano significativamente dalla linea retta del QQ-plot.\n\nIl QQ-plot √® costruito tracciando i quantili del campione contro i quantili teorici di una distribuzione di riferimento. L‚Äôinterpretazione √® piuttosto semplice:\n\nSe il campione segue la distribuzione teorica, i punti nel QQ-plot si allineano lungo una linea retta di pendenza 1 (e intercetta 0 nel caso di distribuzione normale standardizzata).\nLa deviazione dalla linea retta indica differenze nella distribuzione del campione rispetto alla distribuzione teorica:\n\n\nIntercetta diversa da 0: indica che la media del campione differisce dalla media della distribuzione teorica.\n\nPendenza diversa da 1: indica una differenza nella varianza tra il campione e la distribuzione teorica.\n\nCurve: indicano deviazioni sistematiche, come code pesanti o distribuzioni asimmetriche.\n\n\n\nNella discussione seguente, costruiremo e analizzeremo QQ-plot per tre casi tipici:\n\n\nCampione con stessa media e varianza della distribuzione teorica.\n\nCampione con media diversa ma stessa varianza.\n\nCampione con media e varianza diverse.\n\nSimuleremo i dati, li ordineremo, calcoleremo manualmente i quantili teorici e infine utilizzeremo librerie specializzate per replicare e confrontare i risultati. Questo approccio pratico ci permetter√† di comprendere a fondo l‚Äôutilit√† e il funzionamento del QQ-plot.\n\n39.4.1 Comprendere e Costruire un QQ-Plot (Distribuzione Normale)\nUn QQ-plot (Quantile-Quantile plot) √® uno strumento grafico utilizzato per confrontare la distribuzione di un campione con una distribuzione teorica, spesso la distribuzione normale. Il QQ-plot aiuta a visualizzare se un dataset segue una distribuzione specifica, tracciando i quantili del campione contro i quantili della distribuzione teorica.\n\n39.4.2 Passi per Costruire un QQ-Plot\n\n\nOrdinare i Dati: Disporre i dati del campione in ordine crescente.\n\nDeterminare i Quantili Teorici: Per una distribuzione normale, i quantili corrispondono all‚Äôinverso della funzione di distribuzione cumulativa (CDF) della distribuzione normale.\n\nConfrontare i Quantili: Tracciare i quantili del campione rispetto ai quantili della distribuzione teorica. Se il campione proviene dalla distribuzione teorica, i punti dovrebbero trovarsi approssimativamente su una linea retta.\n\n39.4.3 Caso 1: Campione con Stessa Media e Varianza della Distribuzione Normale\nSupponiamo che il campione provenga da una distribuzione normale \\(N(\\mu = 0, \\sigma^2 = 1)\\), esattamente come la distribuzione teorica.\n\n39.4.3.1 Simulazione dei Dati\nIniziamo simulando un piccolo dataset da \\(N(0, 1)\\):\n\n# Generiamo 20 punti dati da N(0, 1)\nset.seed(42)  # Per garantire la riproducibilit√†\ndati_campione &lt;- rnorm(20, mean = 0, sd = 1)\n\n# Ordiniamo i dati del campione\ncampione_ordinato &lt;- sort(dati_campione)\n\n# Calcoliamo i quantili teorici da N(0, 1)\nquantili_teorici &lt;- qnorm((seq(1, 20) - 0.5) / 20)\n\n# Tracciamo il QQ-plot\nplot(quantili_teorici, campione_ordinato,\n     xlab = \"Quantili Teorici\", ylab = \"Quantili del Campione\",\n     main = \"QQ-Plot: Stessa Media e Varianza\", pch = 16)\nabline(0, 1, lwd = 2)  # Linea y = x\n\n\n\n\n\n\n\nIn questo caso, i punti del QQ-plot dovrebbero allinearsi alla linea rossa, indicando che la distribuzione del campione corrisponde a quella teorica.\n\n39.4.4 Caso 2: Campione con Media Diversa (Intercetta ‚â† 0)\nSimuliamo un campione da \\(N(2, 1)\\), con una media diversa ma la stessa varianza:\n\n# Generiamo 20 punti dati da N(2, 1)\ndati_campione_media_spostata &lt;- rnorm(20, mean = 2, sd = 1)\n\n# Ordiniamo i dati del campione\ncampione_ordinato_media_spostata &lt;- sort(dati_campione_media_spostata)\n\n# Tracciamo il QQ-plot\nplot(quantili_teorici, campione_ordinato_media_spostata,\n     xlab = \"Quantili Teorici\", ylab = \"Quantili del Campione\",\n     main = \"QQ-Plot: Media Diversa (Intercetta ‚â† 0)\", pch = 16)\nabline(0, 1, lwd = 2)  # Linea y = x\n\n\n\n\n\n\n\nIn questo caso, i punti dovrebbero seguire una linea retta ma essere spostati verticalmente, indicando una media diversa (intercetta ‚â† 0).\n\n39.4.5 Caso 3: Campione con Media e Varianza Diverse (Pendenza ‚â† 1)\nSimuliamo un campione da \\(N(2, 2^2)\\), con una media e una varianza diverse:\n\n# Generiamo 20 punti dati da N(2, 2^2)\ndati_campione_varianza_spostata &lt;- rnorm(20, mean = 2, sd = 2)\n\n# Ordiniamo i dati del campione\ncampione_ordinato_varianza_spostata &lt;- sort(dati_campione_varianza_spostata)\n\n# Tracciamo il QQ-plot\nplot(quantili_teorici, campione_ordinato_varianza_spostata,\n     xlab = \"Quantili Teorici\", ylab = \"Quantili del Campione\",\n     main = \"QQ-Plot: Media e Varianza Diverse (Pendenza ‚â† 1)\", pch = 16)\nabline(0, 1, lwd = 2)  # Linea y = x\n\n\n\n\n\n\n\nIn questo caso, i punti si discosteranno sia verticalmente (per la media diversa) sia rispetto alla pendenza della linea (per la varianza diversa).\n\n39.4.6 Calcolo Manuale del QQ-Plot\nPer ciascun caso sopra, i passaggi sono i seguenti:\n\n\nOrdinamento dei dati del campione: Questo fornisce i quantili del campione.\n\nCalcolo dei quantili teorici: Utilizzando la funzione inversa della CDF per la distribuzione normale.\n\nEsempio in R:\n\n# Calcolo manuale dei quantili teorici\nquantili_teorici_manuali &lt;- function(n) {\n  sapply(1:n, function(i) qnorm((i - 0.5) / n))\n}\n\nn &lt;- length(dati_campione)\nquantili_teorici_calcolati &lt;- quantili_teorici_manuali(n)\nquantili_teorici_calcolati\n#&gt;  [1] -1.95996 -1.43953 -1.15035 -0.93459 -0.75542 -0.59776 -0.45376 -0.31864\n#&gt;  [9] -0.18912 -0.06271  0.06271  0.18912  0.31864  0.45376  0.59776  0.75542\n#&gt; [17]  0.93459  1.15035  1.43953  1.95996\n\n\n39.4.7 Utilizzo di Funzioni Specializzate\nIn R, il pacchetto base offre la funzione qqnorm() per generare QQ-plot. Ad esempio:\n\n# Generazione del QQ-plot con qqnorm\nqqnorm(dati_campione, main = \"QQ-Plot: Stessa Media e Varianza\")\nqqline(dati_campione, lwd = 2)  # Linea di riferimento\n\n\n\n\n\n\n\nPossiamo ripetere lo stesso per i campioni con media e varianza spostate.\n\nQuesto approccio fornisce un‚Äôanalisi completa della corrispondenza tra distribuzioni teoriche e campioni simulati utilizzando QQ-plot.\nPer concludere, esaminiamo la distribuzione dei tempi di reazione simulati con il qq-plot.\n\nqqnorm(rt, main = \"Tempi di Reazione\")\n\n\n\n\n\n\n\nIl diagramma quantile-quantile rende molto chiaro che la distribuzione del peso dei pulcini non √® gaussiana.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>39</span>¬† <span class='chapter-title'>Assunzione di gaussianit√† e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_gauss.html#valutare-la-normalit√†-test-statistici",
    "href": "chapters/probability/14_gauss.html#valutare-la-normalit√†-test-statistici",
    "title": "39¬† Assunzione di gaussianit√† e trasformazioni dei dati",
    "section": "\n39.5 Valutare la Normalit√†: Test Statistici",
    "text": "39.5 Valutare la Normalit√†: Test Statistici\nSebbene esistano numerosi test statistici formali per valutare la conformit√† dei dati alla distribuzione normale, questi sono spesso troppo conservativi o sensibili a lievi deviazioni, e nella pratica sono frequentemente sostituiti da metodi visivi pi√π flessibili ed efficaci.\nIn R sono disponibili diversi test per verificare la normalit√† dei dati. Di seguito presentiamo i pi√π comuni, insieme a un esempio pratico basato sul dataset ChickWeight.\n\n39.5.1 Test di Shapiro-Wilk\nIl test di Shapiro-Wilk √® uno dei test pi√π utilizzati per verificare la normalit√†. Valuta l‚Äôipotesi nulla che i dati seguano una distribuzione normale.\n\nshapiro_test &lt;- shapiro.test(rt)\nshapiro_test\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  rt\n#&gt; W = 0.56, p-value = 5e-16\n\n\nIl p-value √® inferiore a 0.05 ‚Üí Rifiutiamo l‚Äôipotesi nulla, i dati non sono normali.\nIl p-value √® maggiore di 0.05 ‚Üí Non rifiutiamo l‚Äôipotesi nulla, i dati possono essere considerati normali.\n\n39.5.2 Test di Kolmogorov-Smirnov\nQuesto test confronta la distribuzione cumulativa dei dati con una distribuzione teorica, come la normale. Tuttavia, √® meno sensibile rispetto al test di Shapiro-Wilk.\n\nks_test &lt;- ks.test(\n  rt, \n  \"pnorm\", \n  mean = mean(rt), \n  sd = sd(rt)\n)\nks_test\n#&gt; \n#&gt;  Asymptotic one-sample Kolmogorov-Smirnov test\n#&gt; \n#&gt; data:  rt\n#&gt; D = 0.25, p-value = 5e-06\n#&gt; alternative hypothesis: two-sided\n\nIl test di Kolmogorov-Smirnov √® pi√π adatto per grandi dataset, ma √® noto per essere eccessivamente conservativo.\n\n39.5.3 Limitazioni dei test statistici\nNonostante la loro precisione formale, i test statistici per la normalit√† notevoli limitazioni:\n\nEccessiva sensibilit√† ai grandi campioni: Quando il campione √® ampio, anche lievi deviazioni dalla normalit√†, non rilevanti per l‚Äôanalisi, possono portare a un risultato di non-normalit√†.\nMancanza di sensibilit√† nei piccoli campioni: Con campioni ridotti, i test possono mancare di potere statistico, portando a falsi negativi (ovvero, non rilevare deviazioni significative dalla normalit√†).\n\n\nset.seed(123)\nshapiro.test(rchisq(20, 4))\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  rchisq(20, 4)\n#&gt; W = 0.94, p-value = 0.3\n\nIn questo esempio, vediamo come, con un campione di 20 osservazioni da una distribuzione \\(\\chi^2_4\\) si produca un falso negativo.\n\n\nDifficolt√† interpretative: Un p-value elevato non implica che i dati siano esattamente normali; semplicemente, non c‚Äô√® evidenza sufficiente per rifiutare l‚Äôipotesi di normalit√†.\n\nI metodi visivi, sebbene meno formali, sono spesso pi√π pratici ed efficaci per diagnosticare deviazioni dalla normalit√†.I metodi visivi sono preferibili sono preferibili perch√©\n\nforniscono una diagnosi immediata, che consente di identificare deviazioni rilevanti senza dipendere da un p-value.\nrivelano non solo se i dati non sono normali, ma anche come e dove differiscono dalla normalit√† (ad esempio, asimmetria o code pesanti).\noffrono indicazioni utili anche in presenza di grandi campioni, dove i test statistici possono risultare eccessivamente conservativi.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>39</span>¬† <span class='chapter-title'>Assunzione di gaussianit√† e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_gauss.html#trasformazione-dei-dati-affrontare-la-non-normalit√†",
    "href": "chapters/probability/14_gauss.html#trasformazione-dei-dati-affrontare-la-non-normalit√†",
    "title": "39¬† Assunzione di gaussianit√† e trasformazioni dei dati",
    "section": "\n39.6 Trasformazione dei dati: affrontare la non-normalit√†",
    "text": "39.6 Trasformazione dei dati: affrontare la non-normalit√†\nQuando i dati non rispettano l‚Äôassunzione di normalit√†, √® possibile utilizzare diverse strategie per affrontare questa violazione. Una delle pi√π comuni √® l‚Äôuso di trasformazioni dei dati, che permettono di adattare la distribuzione dei dati a una forma pi√π vicina a quella normale, mantenendo comunque la validit√† dell‚Äôanalisi che richiede l‚Äôassunzione di normalit√†. Due approcci comuni sono Winsorizing e trimming.\n\n39.6.1 Winsorizing e Trimming\nQuesti metodi si concentrano sulla gestione degli outlier, ossia valori estremi che possono distorcere la distribuzione dei dati. Entrambi gli approcci presumono che la non-normalit√† sia dovuta a dati contaminanti e agiscono in modo differente:\n\n\nWinsorizing: Sostituisce i valori estremi con valori meno estremi, come i percentili limite della distribuzione.\n\nTrimming: Rimuove completamente i valori estremi dalla distribuzione.\n\nConsideriamo i seguenti dati di esempio:\n\ndati &lt;- c(\n  1.0, 2.2, 3.0, 3.1, 4.0, 4.0, 4.1, 5.3, 6.5, 8.3,\n  10.9, 20.4, 21.4, 34.\n)\n\n# Winsorizing al 20%\ndati_winsorized &lt;- winsorize(\n  dati,\n  method = \"percentile\", percentile = 20\n)\nprint(dati_winsorized)\n#&gt;  [1]  3.0  3.0  3.0  3.1  4.0  4.0  4.1  5.3  6.5  8.3 10.9 20.4 20.4 20.4\n\n\n# Trimming al 20%\ndati_trimmed &lt;- dati[\n  dati &gt;= quantile(dati, 0.2) & dati &lt;= quantile(dati, 0.8)\n]\nprint(dati_trimmed)\n#&gt; [1]  3.1  4.0  4.0  4.1  5.3  6.5  8.3 10.9\n\n\n\nDati Winsorized: I valori estremi (inferiori e superiori ai percentili 20¬∞ e 80¬∞) sono sostituiti dai valori limite.\n\nDati Trimmed: I valori fuori dai percentili 20¬∞ e 80¬∞ sono completamente rimossi.\n\nQuesti metodi riducono l‚Äôimpatto degli outlier, ma possono introdurre bias se i valori estremi sono effettivamente parte della popolazione target.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>39</span>¬† <span class='chapter-title'>Assunzione di gaussianit√† e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_gauss.html#trasformazioni-comuni",
    "href": "chapters/probability/14_gauss.html#trasformazioni-comuni",
    "title": "39¬† Assunzione di gaussianit√† e trasformazioni dei dati",
    "section": "\n39.7 Trasformazioni comuni",
    "text": "39.7 Trasformazioni comuni\nQuando i dati non rispettano l‚Äôassunzione di normalit√†, √® possibile applicare trasformazioni matematiche per modificarne la forma e migliorare l‚Äôadattamento a una distribuzione normale. Di seguito, presentiamo le trasformazioni pi√π utilizzate.\nTrasformazione logaritmica.\nLa trasformazione logaritmica √® particolarmente utile per variabili con asimmetria positiva (code lunghe a destra), come i tempi di reazione.\n\n# Trasformazione logaritmica\ndati_log &lt;- log(rt)\nplot(density(dati_log), main = \"Densit√† dei dati log-transformati\")\n\n\n\n\n\n\n\nTrasformazione radice quadrata.\nAdatta per variabili di conteggio o proporzioni con valori vicini a zero.\n\ndati_sqrt &lt;- sqrt(rt)\nplot(density(dati_sqrt), main = \"Densit√† dei dati trasformati con radice quadrata\")\n\n\n\n\n\n\n\nTrasformazione inversa.\nEfficace per dati con forte asimmetria positiva, ma pu√≤ complicare l‚Äôinterpretazione.\n\ndati_inv &lt;- 1 / rt\nplot(density(dati_inv), main = \"Densit√† dei dati trasformati inversamente\")\n\n\n\n\n\n\n\nTrasformazione Box-Cox.\nLa trasformazione Box-Cox √® una tecnica parametrica che generalizza le precedenti. Utilizza il massimo della verosimiglianza per determinare la trasformazione ottimale per normalizzare i dati. La funzione di trasformazione dipende da un parametro \\(\\lambda\\):\n\\[\ny(\\lambda) =\n\\begin{cases}\n\\frac{y^\\lambda - 1}{\\lambda} & \\text{se } \\lambda \\neq 0, \\\\\n\\log(y) & \\text{se } \\lambda = 0.\n\\end{cases}\n\\]\n\nb &lt;- boxcox(lm(rt ~ 1))\n\n\n\n\n\n\n\n\n# Exact lambda\nlambda &lt;- b$x[which.max(b$y)]\nlambda\n#&gt; [1] 0.1818\n\nTrasformiamo i dati utilizzando lambda.\n\nrt_boxcox &lt;- (rt^lambda - 1) / lambda\nrt_boxcox |&gt; head()\n#&gt; [1]  1.6450  1.1676  2.2609 -1.5681 -1.1334  0.4787\n\n\nplot(\n  density(rt_boxcox), \n  main = \"Densit√† dei dati trasformati con Box-Cox\"\n)\n\n\n\n\n\n\n\n\n# Generazione del QQ-plot con qqnorm\nqqnorm(rt_boxcox, main = \"QQ-Plot\")\nqqline(rt_boxcox, lwd = 2) \n\n\n\n\n\n\n\n\n\n39.7.1 Pro e contro delle trasformazioni\nVantaggi:\nLe trasformazioni dei dati offrono molteplici benefici nell‚Äôanalisi statistica. In primo luogo, possono migliorare l‚Äôaderenza alla normalit√†, un requisito fondamentale per l‚Äôapplicazione di molti test statistici. Inoltre, contribuiscono a stabilizzare la varianza e a mitigare l‚Äôimpatto dei valori estremi, riducendo il rischio che questi ultimi influenzino eccessivamente i risultati. Tali vantaggi migliorano la robustezza e l‚Äôaccuratezza delle analisi.\nSvantaggi:\nNonostante i benefici, le trasformazioni presentano limitazioni rilevanti. La perdita di interpretabilit√† √® uno degli aspetti pi√π critici: i risultati su dati trasformati possono risultare meno intuitivi. Ad esempio, in un modello di regressione applicato a dati trasformati con il logaritmo, il coefficiente rappresenta un cambiamento percentuale anzich√© assoluto, rendendo l‚Äôinterpretazione meno diretta per i non esperti.\nInoltre, l‚Äôapplicazione di una trasformazione deve essere attentamente motivata in base alla natura dei dati e agli obiettivi dell‚Äôanalisi. Una trasformazione inappropriata pu√≤ introdurre distorsioni indesiderate, compromettendo la validit√† dei risultati e portando a conclusioni fuorvianti. Per questo motivo, √® essenziale valutare attentamente i costi e i benefici della trasformazione nel contesto specifico della ricerca.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>39</span>¬† <span class='chapter-title'>Assunzione di gaussianit√† e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_gauss.html#riflessioni-conclusive",
    "href": "chapters/probability/14_gauss.html#riflessioni-conclusive",
    "title": "39¬† Assunzione di gaussianit√† e trasformazioni dei dati",
    "section": "\n39.8 Riflessioni Conclusive",
    "text": "39.8 Riflessioni Conclusive\nLa verifica della normalit√† dei dati e l‚Äôeventuale utilizzo di trasformazioni matematiche costituiscono fasi fondamentali nell‚Äôanalisi statistica. Sebbene i test formali (come Shapiro-Wilk o Kolmogorov-Smirnov) offrano una valutazione strutturata, essi possono risultare troppo sensibili, portando a rigettare l‚Äôassunto di normalit√† anche in presenza di lievi deviazioni non rilevanti dal punto di vista pratico. In questi casi, l‚Äôimpiego di strumenti visivi‚Äîcome istogrammi, grafici di densit√† o QQ-plot‚Äîsi rivela spesso pi√π informativo e flessibile, consentendo di individuare la natura e l‚Äôentit√† delle deviazioni.\nLe trasformazioni dei dati rappresentano una strategia utile per normalizzare la distribuzione, ma richiedono una scelta oculata. √à essenziale verificare che la trasformazione adottata non comprometta il significato teorico della variabile in esame. Quando l‚Äôinterpretabilit√† risulta compromessa, potrebbe essere preferibile ricorrere a metodi robusti o modelli alternativi (ad esempio, approcci bayesiani) che non presuppongono la normalit√†. In definitiva, la decisione finale dipender√† dal contesto di ricerca, dalla natura dei dati e dagli obiettivi analitici, privilegiando sempre un equilibrio tra rigore statistico e interpretabilit√† dei risultati.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>39</span>¬† <span class='chapter-title'>Assunzione di gaussianit√† e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_gauss.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/14_gauss.html#informazioni-sullambiente-di-sviluppo",
    "title": "39¬† Assunzione di gaussianit√† e trasformazioni dei dati",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] MASS_7.3-65      datawizard_1.0.2 thematic_0.1.6   MetBrewer_0.2.0 \n#&gt;  [5] ggokabeito_0.1.0 see_0.11.0       gridExtra_2.3    patchwork_1.3.0 \n#&gt;  [9] bayesplot_1.11.1 psych_2.5.3      scales_1.3.0     markdown_2.0    \n#&gt; [13] knitr_1.50       lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1   \n#&gt; [17] dplyr_1.1.4      purrr_1.0.4      readr_2.1.5      tidyr_1.3.1     \n#&gt; [21] tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3       \n#&gt; [25] here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.9.1   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         rlang_1.1.5       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       yaml_2.3.10       tools_4.4.2       parallel_4.4.2   \n#&gt; [21] tzdb_0.5.0        colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5      \n#&gt; [25] R6_2.6.1          lifecycle_1.0.4   htmlwidgets_1.6.4 insight_1.1.0    \n#&gt; [29] pkgconfig_2.0.3   pillar_1.10.1     gtable_0.3.6      glue_1.8.0       \n#&gt; [33] xfun_0.51         tidyselect_1.2.1  rstudioapi_0.17.1 farver_2.1.2     \n#&gt; [37] htmltools_0.5.8.1 nlme_3.1-167      labeling_0.4.3    rmarkdown_2.29   \n#&gt; [41] compiler_4.4.2",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>39</span>¬† <span class='chapter-title'>Assunzione di gaussianit√† e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_gauss.html#bibliografia",
    "href": "chapters/probability/14_gauss.html#bibliografia",
    "title": "39¬† Assunzione di gaussianit√† e trasformazioni dei dati",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nOsborne, J. (2002). Notes on the use of data transformations. Practical Assessment, Research, and Evaluation, 8(1).\n\n\nShatz, I. (2024). Assumption-checking rather than (just) testing: The importance of visualization and effect size in statistical diagnostics. Behavior Research Methods, 56(2), 826‚Äì845.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>39</span>¬† <span class='chapter-title'>Assunzione di gaussianit√† e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html",
    "href": "chapters/probability/15_likelihood.html",
    "title": "40¬† La verosimiglianza",
    "section": "",
    "text": "Introduzione\nI ricercatori utilizzano diversi modelli matematici per descrivere e prevedere il comportamento dei dati osservati. Questi modelli si distinguono tra loro per la struttura funzionale, ovvero il modo in cui collegano le variabili osservate con parametri teorici. La scelta del modello migliore avviene confrontando le previsioni teoriche generate dal modello con i dati effettivamente osservati. Il modello che produce previsioni pi√π vicine ai dati reali viene considerato il pi√π adeguato per descrivere il fenomeno studiato.\nIn questo processo di confronto, la funzione di verosimiglianza gioca un ruolo fondamentale. Essa quantifica la probabilit√† che i dati osservati siano stati generati da un particolare modello con determinati valori dei suoi parametri. In altre parole, la verosimiglianza misura quanto i dati siano compatibili con il modello ipotizzato.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>40</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#il-principio-della-verosimiglianza-e-la-sua-formalizzazione",
    "href": "chapters/probability/15_likelihood.html#il-principio-della-verosimiglianza-e-la-sua-formalizzazione",
    "title": "40¬† La verosimiglianza",
    "section": "\n40.1 Il Principio della Verosimiglianza e la sua Formalizzazione",
    "text": "40.1 Il Principio della Verosimiglianza e la sua Formalizzazione\nLa verosimiglianza quantifica quanto i dati osservati siano compatibili con diversi valori dei parametri di un modello. In termini pi√π semplici, la verosimiglianza indica quanto ciascun valore possibile dei parametri sia plausibile nel descrivere il fenomeno osservato.\n\nDefinizione 40.1 Consideriamo un vettore aleatorio \\(X\\), la cui distribuzione √® descritta da una funzione di densit√† di probabilit√† (nel caso di variabili continue) o da una funzione di massa di probabilit√† (nel caso di variabili discrete), indicata con \\(f(x; \\theta)\\). Qui, \\(\\theta\\) rappresenta un vettore di parametri che appartiene a uno spazio parametrico \\(\\Theta\\). Una volta osservato un valore specifico \\(x\\) del vettore \\(X\\), possiamo definire la funzione di verosimiglianza per i parametri \\(\\theta\\) come:\n\\[\nL(\\theta; x) = f(x; \\theta).\n\\]\nQuesta definizione evidenzia che la funzione di verosimiglianza si concentra sui parametri, mentre i dati sono fissati.\n\n\n40.1.1 Relazione tra Verosimiglianza e Funzione di Probabilit√†\nLa formula matematica che collega i dati ai parametri √® la stessa sia per la funzione di verosimiglianza che per la funzione di densit√† (o massa) di probabilit√†. Ci√≤ che cambia √® l‚Äôinterpretazione e il modo in cui questa formula viene utilizzata nei due contesti.\n\nFunzione di densit√† (o massa) di probabilit√†:\nQuesta funzione descrive il processo generativo dei dati, indicando la probabilit√† (o densit√† di probabilit√†, nel caso continuo) che un determinato valore dei dati venga osservato, supponendo che i parametri del modello siano gi√† noti e fissati. Qui, quindi, i parametri sono fissi e i dati variano.\nFunzione di verosimiglianza:\nLa funzione di verosimiglianza inverte questo punto di vista. In essa, i dati osservati sono fissati, mentre i parametri \\(\\theta\\) variano. La verosimiglianza misura la plausibilit√† di ciascun valore possibile dei parametri nel descrivere i dati che sono stati effettivamente osservati. In sostanza, valuta la compatibilit√† di ogni valore dei parametri rispetto ai dati raccolti.\n\nFormalmente, la relazione tra queste due funzioni pu√≤ essere espressa come:\n\\[\nL(\\theta \\mid y) \\propto p(y \\mid \\theta),\n\\]\ndove:\n\n\n\\(L(\\theta \\mid y)\\) rappresenta la funzione di verosimiglianza, ossia la plausibilit√† dei parametri \\(\\theta\\) alla luce dei dati osservati \\(y\\);\n\n\\(p(y \\mid \\theta)\\) indica la funzione di densit√† (o massa) di probabilit√†, cio√® la probabilit√† di osservare i dati \\(y\\) assumendo che i parametri \\(\\theta\\) siano gi√† noti e fissi.\n\nIn sintesi, la funzione di probabilit√† risponde alla domanda ‚Äúdato un certo insieme di parametri, quanto √® probabile osservare questi dati?‚Äù, mentre la funzione di verosimiglianza si pone la domanda opposta: ‚Äúdati questi dati osservati, quali valori dei parametri sono pi√π plausibili?‚Äù Questa distinzione √® fondamentale per l‚Äôinferenza statistica e per determinare i parametri pi√π adatti a descrivere i fenomeni osservati.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>40</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#sequenza-di-lanci-di-una-moneta",
    "href": "chapters/probability/15_likelihood.html#sequenza-di-lanci-di-una-moneta",
    "title": "40¬† La verosimiglianza",
    "section": "\n40.2 Sequenza di Lanci di una Moneta",
    "text": "40.2 Sequenza di Lanci di una Moneta\nPer comprendere meglio il concetto di verosimiglianza, partiamo da un esempio semplice. Supponiamo di voler stimare la probabilit√† di ottenere testa in un lancio di moneta, indicata con \\(p_H\\). L‚Äôobiettivo √® capire quali valori di \\(p_H\\) rendano pi√π plausibili i dati osservati. Per farlo, calcoliamo la probabilit√† di osservare sequenze specifiche di lanci di una moneta assumendo che ogni lancio sia indipendente dagli altri.\n\n40.2.1 Perch√© moltiplichiamo le probabilit√†?\nQuando lanciamo una moneta pi√π volte, ogni lancio rappresenta un evento indipendente: il risultato di un lancio non influenza il successivo. Questo significa che la probabilit√† di osservare una specifica sequenza di successi (teste) e insuccessi (croci) si calcola moltiplicando le probabilit√† dei singoli eventi.\nAd esempio, consideriamo una moneta con probabilit√† \\(p_H\\) di ottenere testa e \\(1 - p_H\\) di ottenere croce. Se osserviamo la sequenza HTHT, la probabilit√† di ottenere questa specifica sequenza √®:\n\\[\nP(HTHT \\mid p_H) = p_H \\cdot (1 - p_H) \\cdot p_H \\cdot (1 - p_H) = p_H^2 (1 - p_H)^2.\n\\]\nSe invece osserviamo una sequenza diversa, come THTH o HHTT, la probabilit√† sar√† sempre \\(p_H^2 (1 - p_H)^2\\). Questo avviene perch√© l‚Äôordine specifico dei risultati non influisce sulla probabilit√† complessiva della sequenza, finch√© il numero totale di successi e insuccessi rimane lo stesso.\n\n40.2.2 Generalizzazione della Probabilit√† di una Sequenza\nIn generale, se osserviamo \\(n\\) lanci di una moneta e registriamo \\(y\\) successi (teste) e \\(n - y\\) insuccessi (croci), la probabilit√† di ottenere una qualsiasi sequenza con esattamente \\(y\\) teste e \\(n - y\\) croci √®:\n\\[\nP(Y = y \\mid p_H) = p_H^y (1 - p_H)^{n - y}.\n\\tag{40.1}\\]\nQuesta formula rappresenta la funzione di verosimiglianza, che misura la compatibilit√† tra i dati osservati e un dato valore di \\(p_H\\). In altre parole, ci dice quanto sia plausibile che il parametro \\(p_H\\) abbia un determinato valore, dati i risultati osservati.\n\n40.2.3 Connessione con la Distribuzione Binomiale\nA questo punto, dovrebbe risultare evidente che l‚Äôequazione Equazione¬†40.1 √® il nucleo della distribuzione binomiale. Infatti, la funzione di probabilit√† della distribuzione binomiale completa √®:\n\\[\nP(Y = y \\mid p_H) = \\binom{n}{y} p_H^y (1 - p_H)^{n - y}.\n\\]\nLa differenza tra questa formula e la funzione di verosimiglianza √® il coefficiente binomiale \\(\\binom{n}{y}\\), che rappresenta il numero di modi in cui possiamo ottenere esattamente \\(y\\) successi in \\(n\\) lanci.\nPossiamo rimuovere questa costante nella funzione di verosimiglianza perch√© non dipende dal parametro \\(p_H\\) che vogliamo stimare. Poich√© il nostro obiettivo √® trovare il valore di \\(p_H\\) che massimizza la funzione di verosimiglianza, qualsiasi termine costante rispetto a \\(p_H\\) non influenzer√† il risultato della massimizzazione.\nNota: il coefficiente binomiale modifica l‚Äôaltezza della verosimiglianza ma non la posizione del massimo, permettendo di ignorarlo nei calcoli di stima.\nPer questo motivo, nella ricerca della stima di massima verosimiglianza, possiamo considerare solo il nucleo della funzione binomiale:\n\\[\nL(p_H \\mid y) = p_H^y (1 - p_H)^{n - y}.\n\\tag{40.2}\\]\nQuesta semplificazione ci permette di concentrarci solo sui valori di \\(p_H\\) che rendono la funzione pi√π alta, ignorando costanti moltiplicative che non influiscono sulla posizione del massimo.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>40</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#esempi-di-verosimiglianza-senza-la-binomiale",
    "href": "chapters/probability/15_likelihood.html#esempi-di-verosimiglianza-senza-la-binomiale",
    "title": "40¬† La verosimiglianza",
    "section": "\n40.3 Esempi di Verosimiglianza senza la Binomiale",
    "text": "40.3 Esempi di Verosimiglianza senza la Binomiale\n\n40.3.1 Caso 1: Due Lanci\nSupponiamo di lanciare una moneta due volte e di osservare una testa e una croce. Per stimare \\(p_H\\), calcoliamo la probabilit√† di osservare questa specifica sequenza per diversi valori di \\(p_H\\).\n\n\nSe la moneta √® equa (\\(p_H = 0.5\\)):\n\\[\nP(H, T \\mid p_H = 0.5) = 0.5 \\times 0.5 = 0.25.\n\\]\n\n\nSe invece \\(p_H = 0.4\\):\n\\[\nP(H, T \\mid p_H = 0.4) = 0.4 \\times 0.6 = 0.24.\n\\]\n\n\nIn generale, la funzione di verosimiglianza per questo esperimento √®:\n\\[\nL(p_H) = p_H^1 (1 - p_H)^1.\n\\]\nPossiamo rappresentarla graficamente con il seguente codice R:\n\n# Definizione dei parametri\nn &lt;- 2  # Numero totale di lanci\ny &lt;- 1  # Numero di teste osservate\n\n# Sequenza di valori possibili per p_H\np_H &lt;- seq(0, 1, length.out = 100)\n\n# Calcolo della funzione di verosimiglianza\nlikelihood &lt;- p_H^y * (1 - p_H)^(n - y)\n\n# Creazione del dataframe\ndata &lt;- data.frame(p_H, likelihood)\n\n# Grafico della funzione di verosimiglianza\nggplot(data, aes(x = p_H, y = likelihood)) +\n  geom_line(color = \"blue\", linewidth = 1) +\n  labs(\n    title = \"Verosimiglianza per 2 Lanci di Moneta (1 Testa, 1 Croce)\",\n    x = expression(p[H]),\n    y = \"Verosimiglianza\"\n  ) \n\n\n\n\n\n\n\n\n40.3.2 Caso 2: Tre Lanci\nOra immaginiamo di aver lanciato la moneta tre volte e di aver osservato una testa e due croci. La probabilit√† di ottenere questa specifica sequenza per diversi valori di \\(p_H\\) √®:\n\n\nSe \\(p_H = 0.5\\):\n\\[\nP(H, T, T \\mid p_H = 0.5) = 0.5 \\times 0.5 \\times 0.5 = 0.125.\n\\]\n\n\nSe \\(p_H = 0.4\\):\n\\[\nP(H, T, T \\mid p_H = 0.4) = 0.4 \\times 0.6 \\times 0.6 = 0.144.\n\\]\n\n\nLa funzione di verosimiglianza per questo esperimento √®:\n\\[\nL(p_H) = p_H^1 (1 - p_H)^2.\n\\]\nPossiamo rappresentarla graficamente con il seguente codice R:\n\n# Definizione dei parametri\nn &lt;- 3  # Numero totale di lanci\ny &lt;- 1  # Numero di teste osservate\n\n# Sequenza di valori possibili per p_H\np_H &lt;- seq(0, 1, length.out = 100)\n\n# Calcolo della funzione di verosimiglianza\nlikelihood &lt;- p_H^y * (1 - p_H)^(n - y)\n\n# Creazione del dataframe\ndata &lt;- data.frame(p_H, likelihood)\n\n# Grafico della funzione di verosimiglianza\nggplot(data, aes(x = p_H, y = likelihood)) +\n  geom_line(color = \"blue\", linewidth = 1) +\n  labs(\n    title = \"Verosimiglianza per 3 Lanci di Moneta (1 Testa, 2 Croci)\",\n    x = expression(p[H]),\n    y = \"Verosimiglianza\"\n  ) \n\n\n\n\n\n\n\n\n40.3.3 Interpretazione dei Risultati\nOsservando i grafici, possiamo notare che:\n\nLa funzione di verosimiglianza √® massima per valori di \\(p_H\\) vicini alla proporzione osservata nel campione. Ad esempio, se abbiamo ottenuto 1 testa su 2 lanci, la verosimiglianza √® massima intorno a \\(p_H = 0.5\\).\nQuando aumentiamo il numero di lanci, la funzione di verosimiglianza diventa pi√π stretta, indicando che pi√π dati permettono una stima pi√π precisa di \\(p_H\\).\nPer valori estremi di \\(p_H\\) (molto vicini a 0 o 1), la verosimiglianza √® bassa, poich√© questi valori non spiegano bene i dati osservati. Ad esempio, se abbiamo osservato 1 testa e 2 croci, un valore di \\(p_H = 0.9\\) avrebbe una verosimiglianza molto bassa.\n\nQuesta sezione ha mostrato come calcolare la verosimiglianza basandoci solo sul prodotto delle probabilit√† dei singoli lanci (senza utilizzare la distribuzione binomiale). Nella prossima sezione, useremo la formula completa della distribuzione binomiale per formalizzare ulteriormente il concetto.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>40</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#esempio-di-verosimiglianza-con-la-binomiale",
    "href": "chapters/probability/15_likelihood.html#esempio-di-verosimiglianza-con-la-binomiale",
    "title": "40¬† La verosimiglianza",
    "section": "\n40.4 Esempio di Verosimiglianza con la Binomiale",
    "text": "40.4 Esempio di Verosimiglianza con la Binomiale\nConsideriamo ora un esperimento pi√π esteso: lanciamo una moneta \\(n = 30\\) volte e otteniamo \\(y = 23\\) teste. Per modellare il numero di successi, utilizziamo la distribuzione binomiale, che descrive la probabilit√† di osservare esattamente \\(y\\) successi in \\(n\\) prove indipendenti:\n\\[\nP(Y = y \\mid \\theta) = \\binom{n}{y} \\theta^y (1 - \\theta)^{n - y}.\n\\]\nPoich√© il coefficiente binomiale \\(\\binom{n}{y}\\) √® una costante rispetto a \\(\\theta\\), possiamo considerare la funzione di verosimiglianza, che esprime la probabilit√† dei dati osservati come funzione del parametro \\(\\theta\\):\n\\[\nL(\\theta \\mid y) = \\theta^{23} (1 - \\theta)^7.\n\\]\n\n40.4.1 Visualizzazione della Funzione di Verosimiglianza\nIl seguente codice R genera il grafico della funzione di verosimiglianza per diversi valori di \\(\\theta\\):\n\n# Definizione dei parametri\nn &lt;- 30  # Numero totale di lanci\ny &lt;- 23  # Numero di teste osservate\n\n# Sequenza di valori possibili per p_H (probabilit√† di ottenere testa)\np_H &lt;- seq(0, 1, length.out = 1000)\n\n# Calcolo della funzione di verosimiglianza binomiale\nlikelihood &lt;- dbinom(y, size = n, prob = p_H)\n\n# Creazione del dataframe per la visualizzazione\ndata &lt;- data.frame(p_H, likelihood)\n\n# Grafico della funzione di verosimiglianza\nggplot(data, aes(x = p_H, y = likelihood)) +\n  geom_line(color = \"blue\", linewidth = 1) +\n  labs(\n    title = \"Funzione di Verosimiglianza per 30 Lanci di Moneta\",\n    x = expression(p[H]),\n    y = \"Verosimiglianza\"\n  ) \n\n\n\n\n\n\n\nOsservando il grafico, notiamo che la funzione di verosimiglianza raggiunge il suo massimo intorno a \\(p_H \\approx 0.77\\). Questo significa che il valore di \\(p_H\\) che rende i dati osservati pi√π plausibili √® circa 0.77. Questo valore corrisponde alla stima di massima verosimiglianza (MLE) per la probabilit√† di ottenere testa, dato che abbiamo osservato 23 successi su 30 prove.\nL‚Äôintuizione alla base di questo risultato √® semplice: la funzione di verosimiglianza esprime quanto siano compatibili i dati osservati con ogni possibile valore di \\(p_H\\). Il valore che massimizza questa funzione rappresenta l‚Äôipotesi pi√π plausibile per il vero valore del parametro \\(p_H\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>40</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#la-stima-di-massima-verosimiglianza",
    "href": "chapters/probability/15_likelihood.html#la-stima-di-massima-verosimiglianza",
    "title": "40¬† La verosimiglianza",
    "section": "\n40.5 La Stima di Massima Verosimiglianza",
    "text": "40.5 La Stima di Massima Verosimiglianza\nPer trovare il valore di \\(\\theta\\) che massimizza la funzione di verosimilianza, possiamo calcolare la derivata della log-verosimiglianza e risolvere. Nel caso dell‚Äôesempio, abbiamo:\n\\[\n\\ell(\\theta) = 23 \\log \\theta + 7 \\log (1 - \\theta).\n\\]\nDerivando e ponendo uguale a zero:\n\\[\n\\frac{d \\ell(\\theta)}{d\\theta} = \\frac{23}{\\theta} - \\frac{7}{1 - \\theta} = 0.\n\\]\nRisolviamo per \\(\\theta\\):\n\\[\n\\theta_{MLE} = \\frac{y}{n} = \\frac{23}{30} \\approx 0.767.\n\\]\nQuesto significa che la stima di massima verosimiglianza della proporzione \\(p\\) √® la proporzione osservata nel campione. Per comprenderlo intuitivamente, possiamo pensare alla funzione di verosimiglianza come a una curva che rappresenta la plausibilit√† dei diversi valori di \\(p\\) nel descrivere i dati osservati. Il valore pi√π plausibile sar√† quello che corrisponde al massimo della funzione di verosimiglianza, ossia la sua moda.\n\n40.5.1 Un‚ÄôIntuizione Geometrica\nPossiamo immaginare di analizzare la funzione di verosimiglianza come se fosse un percorso collinare. Il punto pi√π alto della collina rappresenta il valore di \\(p\\) che rende i dati pi√π probabili. Se volessimo trovare il punto pi√π alto in modo sistematico, potremmo misurare la pendenza della collina in ogni punto. Se la pendenza √® positiva, significa che la funzione sta ancora crescendo; se √® negativa, significa che sta diminuendo. Il massimo della funzione si trova nel punto in cui la pendenza √® esattamente zero‚Äîcio√® quando la tangente alla curva √® una retta orizzontale.\nMatematicamente, questa intuizione si traduce nel calcolo della derivata della funzione di verosimiglianza: il massimo della funzione si trova imponendo che la derivata sia uguale a zero. Vediamo questo procedimento formalmente.\n\n40.5.1.1 Dimostrazione Formale per la Proporzione Campionaria\nSupponiamo di avere un campione di \\(n\\) osservazioni, in cui abbiamo osservato \\(y\\) successi. Se i dati seguono una distribuzione binomiale, la funzione di verosimiglianza √®:\n\\[\nL(p) = p^y (1 - p)^{n - y}.\n\\]\nPer trovare il valore di \\(p\\) che massimizza questa funzione, calcoliamo la log-verosimiglianza (per semplificare i calcoli):\n\\[\n\\ell(p) = \\log L(p) = y \\log p + (n - y) \\log (1 - p).\n\\]\nDeriviamo rispetto a \\(p\\):\n\\[\n\\frac{d\\ell(p)}{dp} = \\frac{y}{p} - \\frac{n - y}{1 - p}.\n\\]\n\n\n\n\n\n\nNota\n\n\n\n\n\nConsideriamo la funzione di log-verosimiglianza per una sequenza di \\(n\\) lanci di una moneta, con \\(y\\) successi (teste) e \\(n - y\\) insuccessi (croci):\n\\[\n\\ell(p) = \\log L(p) = y \\log p + (n - y) \\log (1 - p).\n\\]\nVogliamo ora derivare rispetto a \\(p\\) per determinare il valore che massimizza la funzione di verosimiglianza.\nPer farlo, utilizziamo le regole di derivazione dei logaritmi:\n\nLa derivata di \\(\\log p\\) √®: \\[\n\\frac{d}{dp} \\log p = \\frac{1}{p}.\n\\]\nPer la derivata di \\(\\log(1 - p)\\), notiamo che l‚Äôargomento del logaritmo √® \\(1 - p\\), quindi dobbiamo applicare la regola della catena.\n\nLa regola della catena afferma che, se abbiamo una funzione composta \\(f(g(p))\\), la sua derivata si calcola come:\n\\[\n\\frac{d}{dp} \\log g(p) = \\frac{1}{g(p)} \\cdot g'(p).\n\\]\nNel nostro caso, poniamo:\n\\[\ng(p) = 1 - p.\n\\]\nDerivandola rispetto a \\(p\\):\n\\[\ng'(p) = \\frac{d}{dp} (1 - p) = -1.\n\\]\nApplicando la regola della catena:\n\\[\n\\frac{d}{dp} \\log(1 - p) = \\frac{1}{1 - p} \\cdot (-1) = -\\frac{1}{1 - p}.\n\\]\nOra possiamo calcolare la derivata della funzione di log-verosimiglianza:\n\\[\n\\frac{d\\ell(p)}{dp} = y \\cdot \\frac{1}{p} + (n - y) \\cdot \\left(-\\frac{1}{1 - p}\\right).\n\\]\nSemplificando:\n\\[\n\\frac{d\\ell(p)}{dp} = \\frac{y}{p} - \\frac{n - y}{1 - p}.\n\\]\n\n\n\nImponiamo che la derivata sia zero:\n\\[\n\\frac{y}{p} - \\frac{n - y}{1 - p} = 0.\n\\]\nRisolviamo per \\(p\\):\n\\[\ny(1 - p) = (n - y) p.\n\\]\n\\[\ny - yp = np - yp.\n\\]\n\\[\ny = np.\n\\]\n\\[\n\\hat{p} = \\frac{y}{n}.\n\\]\nDunque, la stima di massima verosimiglianza della proporzione √® la proporzione campionaria \\(\\hat{p} = \\frac{y}{n}\\), che corrisponde esattamente all‚Äôintuizione che il valore pi√π plausibile per \\(p\\) √® quello che meglio rappresenta i dati osservati.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>40</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#stima-di-massima-verosimiglianza-mle-con-r",
    "href": "chapters/probability/15_likelihood.html#stima-di-massima-verosimiglianza-mle-con-r",
    "title": "40¬† La verosimiglianza",
    "section": "\n40.6 Stima di Massima Verosimiglianza (MLE) con R",
    "text": "40.6 Stima di Massima Verosimiglianza (MLE) con R\nLa stima di massima verosimiglianza (MLE) corrisponde al valore del parametro \\(\\theta\\) che massimizza la funzione di verosimiglianza \\(L(\\theta; X)\\) associata al modello statistico. Mentre in precedenza abbiamo derivato analiticamente lo stimatore MLE risolvendo l‚Äôequazione di verosimiglianza, in molti casi pratici‚Äîspecialmente con modelli complessi‚Äî√® preferibile adottare un approccio numerico. Questo metodo prevede il calcolo diretto della verosimiglianza su un intervallo di valori plausibili per \\(\\theta\\) e l‚Äôidentificazione del punto di massimo tramite algoritmi di ottimizzazione.\nNel contesto di un modello binomiale, possiamo implementare questa strategia in R seguendo due strade:\n\n\nValutazione su griglia: generare una sequenza di valori per \\(\\theta\\) (es. da 0 a 1), calcolare \\(L(\\theta; X)\\) per ogni valore utilizzando dbinom(), e individuare il massimo con which.max().\n\n\nOttimizzazione numerica: utilizzare funzioni come optim() o nlm() per trovare iterativamente il \\(\\theta\\) che massimizza la log-verosimiglianza, garantendo efficienza anche in casi multidimensionali.\n\nIllustreremo entrambe le metodologie. Iniziamo con la valutazione su griglia:\n\n# Parametri\nn &lt;- 30\ny &lt;- 23\ntheta &lt;- seq(0, 1, length.out = 10000)\n\n# Calcolo delle probabilit√† binomiali\nprobabilities &lt;- dbinom(y, size = n, prob = theta)\n\n# Identificazione dell'indice del massimo\nmax_index &lt;- which.max(probabilities)\n\n# Recupero del valore di theta corrispondente\noptimal_theta &lt;- theta[max_index]\noptimal_theta\n#&gt; [1] 0.7667\n\nSpiegazione del codice:\n\n\ndbinom(y, size = n, prob = theta) calcola la probabilit√† di osservare esattamente \\(y\\) successi su \\(n\\) tentativi, per ciascun valore di \\(\\theta\\).\n\nwhich.max(probabilities) trova l‚Äôindice del valore massimo nella sequenza delle probabilit√†.\n\ntheta[max_index] restituisce il valore di \\(\\theta\\) corrispondente al massimo trovato.\n\nConsideriamo ora il metodo di ottimizzazione numerica:\n\n# Funzione di log-verosimiglianza (negativa per minimizzazione)\nneg_log_likelihood &lt;- function(theta) {\n  - (y * log(theta) + (n - y) * log(1 - theta))  # Formula binomiale\n}\n\n# Ottimizzazione con metodo Brent (specifico per problemi 1D)\nresult &lt;- optim(\n  par = 0.5,               # Valore iniziale\n  fn = neg_log_likelihood, \n  method = \"Brent\",        # Ottimizzazione con limiti\n  lower = 1e-6,            # Evita theta = 0 (log(0) = -Inf)\n  upper = 1 - 1e-6         # Evita theta = 1\n)\n\noptimal_theta_numerical &lt;- result$par\noptimal_theta_numerical\n#&gt; [1] 0.7667\n\nSpiegazione del codice:\n\n\nneg_log_likelihood calcola la log-verosimiglianza negativa (necessaria perch√© optim() minimizza per default).\n\n\noptim() cerca il minimo della funzione tra lower e upper usando l‚Äôalgoritmo Brent, ottimizzato per problemi unidimensionali.\n\nI limiti 1e-6 e 1 - 1e-6 evitano valori di \\(\\theta\\) estremi che generano NaN nel logaritmo.\n\nIl risultato finale coincide esattamente con la soluzione analitica \\(\\hat{\\theta} = y/n\\) (‚âà 0.7667).\n\n# Confronto con la soluzione analitica (y/n)\nc(\"Numerico\" = optimal_theta_numerical, \"Analitico\" = y/n)\n#&gt;  Numerico Analitico \n#&gt;    0.7667    0.7667\n\nConfronto degli approcci\n\n\n\n\n\n\n\nMetodo\nVantaggi\nLimiti\n\n\n\nValutazione su griglia\nIntuitivo, visivo\nComputazionalmente costoso\n\n\nOttimizzazione numerica\nEfficiente, scalabile a parametri multipli\nRichiede scelta di algoritmo e parametri iniziali",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>40</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#verosimiglianza-congiunta-estensione-del-concetto-di-verosimiglianza",
    "href": "chapters/probability/15_likelihood.html#verosimiglianza-congiunta-estensione-del-concetto-di-verosimiglianza",
    "title": "40¬† La verosimiglianza",
    "section": "\n40.7 Verosimiglianza Congiunta: Estensione del Concetto di Verosimiglianza",
    "text": "40.7 Verosimiglianza Congiunta: Estensione del Concetto di Verosimiglianza\nAbbiamo visto che, nel caso di una sequenza di \\(n\\) lanci di una moneta, la funzione di verosimiglianza si basa sulla distribuzione binomiale. In questo caso, trattiamo un esperimento Bernoulliano ripetuto \\(n\\) volte, e la nostra osservazione √® il numero totale di successi (teste). Il numero complessivo di successi segue una distribuzione binomiale, e la funzione di verosimiglianza assume la forma:\n\\[\n\\mathcal{L}(\\theta) = P(Y = y \\mid \\theta) = \\binom{n}{y} \\theta^y (1 - \\theta)^{n - y}.\n\\]\nQui la verosimiglianza √® espressa direttamente in termini del numero totale di successi e insuccessi, senza dover scrivere il contributo di ogni singolo lancio.\nTuttavia, possiamo affrontare la questione da una prospettiva diversa: invece di considerare il numero totale di successi, possiamo pensare alla verosimiglianza come il prodotto delle probabilit√† di ogni singolo lancio. Questo ci porta a una generalizzazione importante: la verosimiglianza congiunta di pi√π osservazioni indipendenti.\n\n40.7.1 Dal Caso Binomiale alla Verosimiglianza Congiunta\nNel caso dei lanci della moneta, le singole osservazioni sono prove Bernoulliane indipendenti, ovvero ogni singolo lancio √® un‚Äôosservazione indipendente che segue una distribuzione Bernoulli con parametro \\(\\theta\\):\n\\[\nP(Y_i = 1 \\mid \\theta) = \\theta, \\quad P(Y_i = 0 \\mid \\theta) = 1 - \\theta.\n\\]\nSe trattiamo ogni prova individualmente, la funzione di verosimiglianza per una singola osservazione √®:\n\\[\n\\mathcal{L}(\\theta \\mid y_i) = \\theta^{y_i} (1 - \\theta)^{1 - y_i}.\n\\]\nOra, per un campione di \\(n\\) osservazioni indipendenti, la verosimiglianza congiunta √® il prodotto delle verosimiglianze delle singole osservazioni:\n\\[\n\\mathcal{L}(\\theta \\mid y_1, y_2, \\dots, y_n) = \\prod_{i=1}^{n} \\theta^{y_i} (1 - \\theta)^{1 - y_i}.\n\\]\nRiconosciamo che questa espressione √® identica alla funzione di verosimiglianza della distribuzione binomiale, perch√© il numero totale di successi √®:\n\\[\ny = \\sum_{i=1}^{n} y_i.\n\\]\nQuindi, riscrivendo la verosimiglianza congiunta, otteniamo:\n\\[\n\\mathcal{L}(\\theta) = \\theta^{\\sum y_i} (1 - \\theta)^{n - \\sum y_i} = \\theta^y (1 - \\theta)^{n - y}.\n\\]\nQuesta √® proprio la verosimiglianza della distribuzione binomiale! Questo mostra che il caso binomiale pu√≤ essere visto come una forma compatta di verosimiglianza congiunta per prove Bernoulliane indipendenti.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>40</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#perch√©-√®-importante-la-verosimiglianza-congiunta",
    "href": "chapters/probability/15_likelihood.html#perch√©-√®-importante-la-verosimiglianza-congiunta",
    "title": "40¬† La verosimiglianza",
    "section": "\n40.8 Perch√© √® Importante la Verosimiglianza Congiunta?",
    "text": "40.8 Perch√© √® Importante la Verosimiglianza Congiunta?\nL‚Äôidea della verosimiglianza congiunta √® fondamentale perch√© ci permette di estendere i concetti di verosimiglianza dal caso di una singola osservazione al caso di molte osservazioni indipendenti. Questo √® utile in molti contesti statistici:\n\n\nStimare parametri basandosi su un intero campione invece che su una singola osservazione.\n\nDefinire modelli statistici pi√π complessi, in cui le osservazioni sono indipendenti ma possono avere diverse distribuzioni.\n\nApplicare la log-verosimiglianza per rendere pi√π agevole il calcolo e l‚Äôottimizzazione.\n\nIn sintesi, l‚Äôesempio binomiale mostra che la verosimiglianza congiunta di prove Bernoulliane indipendenti si riconduce alla verosimiglianza binomiale, rendendo il concetto meno evidente a prima vista. Tuttavia, la vera potenza della verosimiglianza congiunta si manifesta in distribuzioni continue come la normale, dove la produttoria delle densit√† di probabilit√† per singole osservazioni √® chiaramente distinta dalla funzione di verosimiglianza per il campione intero.\nLa chiave per comprendere il concetto √® rendersi conto che la verosimiglianza di un‚Äôintera sequenza di prove indipendenti √® il prodotto delle singole verosimiglianze, e che nel caso binomiale questa propriet√† si manifesta in modo pi√π compatto grazie alla forma stessa della distribuzione.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>40</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#esempio-osservazioni-raggruppate",
    "href": "chapters/probability/15_likelihood.html#esempio-osservazioni-raggruppate",
    "title": "40¬† La verosimiglianza",
    "section": "\n40.9 Esempio: Osservazioni Raggruppate",
    "text": "40.9 Esempio: Osservazioni Raggruppate\nPer illustrare il concetto di verosimiglianza congiunta nel caso della distribuzione binomiale, consideriamo quattro gruppi distinti di osservazioni binomiali indipendenti:\n\n\nGruppo 1: 23 successi su 30 prove.\n\nGruppo 2: 20 successi su 28 prove.\n\nGruppo 3: 29 successi su 40 prove.\n\nGruppo 4: 29 successi su 36 prove.\n\nPoich√© ogni gruppo segue una distribuzione binomiale indipendente con lo stesso parametro \\(\\theta\\), la log-verosimiglianza congiunta si ottiene sommando le log-verosimiglianze di ciascun gruppo:\n\\[\n\\log \\mathcal{L}(\\theta) = \\sum_{i=1}^{4} \\left[ y_i \\log(\\theta) + (n_i - y_i) \\log(1 - \\theta) \\right],\n\\]\ndove:\n\n\n\\(n_i\\) √® il numero totale di prove nel gruppo \\(i\\),\n\n\\(y_i\\) √® il numero di successi nel gruppo \\(i\\).\n\nSostituendo i valori specifici:\n\\[\n\\begin{aligned}\n\\log \\mathcal{L}(\\theta) &= [23\\log(\\theta) + (30-23)\\log(1 - \\theta)] +\\\\\n&\\quad [20\\log(\\theta) + (28-20)\\log(1 - \\theta)] +\\\\\n&\\quad [29\\log(\\theta) + (40-29)\\log(1 - \\theta)] +\\\\\n&\\quad [29\\log(\\theta) + (36-29)\\log(1 - \\theta)].\n\\end{aligned}\n\\]\nQuesta formula ci permette di calcolare quanto √® plausibile il valore del parametro \\(\\theta\\), tenendo conto simultaneamente di tutte le osservazioni nei quattro gruppi.\n\n40.9.1 Implementazione in R\nConsideriamo ora un‚Äôimplementazione pratica in R, che ci consenta di stimare \\(\\theta\\) massimizzando la log-verosimiglianza congiunta.\nDefiniamo una funzione che calcola la log-verosimiglianza congiunta per un dato valore di \\(\\theta\\):\n\nlog_verosimiglianza_congiunta &lt;- function(theta, dati) {\n  # Per evitare problemi numerici, limitiamo theta tra (0,1)\n  theta &lt;- pmax(pmin(theta, 1 - 1e-10), 1e-10) \n  \n  log_likelihood &lt;- 0\n  for (gruppo in dati) {\n    n &lt;- gruppo[1]  # Numero totale di prove nel gruppo\n    y &lt;- gruppo[2]  # Numero di successi nel gruppo\n    log_likelihood &lt;- log_likelihood + y * log(theta) + (n - y) * log(1 - theta)\n  }\n  \n  return(-log_likelihood)  # Restituiamo il valore negativo per la minimizzazione\n}\n\nInseriamo i dati dei quattro gruppi in una lista:\n\ndati_gruppi &lt;- list(c(30, 23), c(28, 20), c(40, 29), c(36, 29))\n\nPer trovare il valore di \\(\\theta\\) che massimizza la log-verosimiglianza congiunta, utilizziamo la funzione optim():\n\nresult &lt;- optim(\n  par = 0.5,                          # Valore iniziale di theta\n  fn = log_verosimiglianza_congiunta, # Funzione da minimizzare\n  dati = dati_gruppi,                 # Dati dei gruppi\n  method = \"L-BFGS-B\",                # Metodo numerico con limiti\n  lower = 0,                          # Theta deve rimanere tra 0 e 1\n  upper = 1\n)\n\n# Stima ottimale di theta\nresult$par\n#&gt; [1] 0.7537\n\nLa funzione optim() minimizza la funzione data, perci√≤ passiamo il negativo della log-verosimiglianza per ottenere il massimo della verosimiglianza.\nVediamo ora come varia la log-verosimiglianza per diversi valori di \\(\\theta\\):\n\ntheta_values &lt;- seq(0.01, 0.99, length.out = 100)\nlog_likelihood_values &lt;- sapply(theta_values, function(t) log_verosimiglianza_congiunta(t, dati_gruppi))\n\nggplot(\n  data.frame(theta = theta_values, log_likelihood = log_likelihood_values), \n  aes(x = theta, y = log_likelihood)\n) +\n  geom_line(color = \"blue\") +\n  labs(\n    title = \"Funzione di Log-Verosimiglianza Congiunta\",\n    x = \"Theta\",\n    y = \"Log-verosimiglianza negativa\"\n  )\n\n\n\n\n\n\n\nQuesta curva mostra il comportamento della funzione di log-verosimiglianza, consentendoci di individuare visivamente il valore di \\(\\theta\\) che la massimizza.\nIn sintesi, la log-verosimiglianza congiunta ci permette di considerare tutti i dati disponibili simultaneamente per ottenere una stima pi√π affidabile del parametro \\(\\theta\\). In questo esempio, abbiamo visto come:\n\nLa log-verosimiglianza di pi√π gruppi indipendenti si somma.\nPossiamo stimare \\(\\theta\\) numericamente utilizzando optim().\n√à utile visualizzare la log-verosimiglianza per comprendere come varia rispetto a \\(\\theta\\).\n\nQuesto approccio √® fondamentale in inferenza statistica e pu√≤ essere esteso a molti altri contesti in cui abbiamo pi√π gruppi di dati indipendenti.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>40</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#la-verosimiglianza-marginale",
    "href": "chapters/probability/15_likelihood.html#la-verosimiglianza-marginale",
    "title": "40¬† La verosimiglianza",
    "section": "\n40.10 La Verosimiglianza Marginale",
    "text": "40.10 La Verosimiglianza Marginale\nLa verosimiglianza marginale √® un concetto fondamentale nell‚Äôinferenza bayesiana, utilizzato per valutare quanto un modello sia compatibile con i dati osservati, tenendo conto dell‚Äôincertezza sui parametri.\nA differenza della verosimiglianza standard, che misura la plausibilit√† dei dati per un valore fisso del parametro, la verosimiglianza marginale considera tutti i possibili valori del parametro, pesandoli in base alla loro probabilit√† a priori. Questo approccio permette di integrare l‚Äôincertezza nella valutazione del modello.\n\n40.10.1 Caso con Parametri Discreti\nPer comprendere meglio il concetto, consideriamo un esperimento in cui eseguiamo 10 tentativi e otteniamo 7 successi. Supponiamo che la probabilit√† di successo \\(\\theta\\) possa assumere solo tre valori discreti:\n\\[\n\\theta \\in \\{0.1, 0.5, 0.9\\}.\n\\]\nPer calcolare la verosimiglianza marginale, dobbiamo:\n\n\nAssegnare una probabilit√† a priori a ciascun valore di \\(\\theta\\), ad esempio:\n\nDistribuzione uniforme: \\[\np(\\theta = 0.1) = p(\\theta = 0.5) = p(\\theta = 0.9) = \\frac{1}{3}.\n\\]\n\nDistribuzione non uniforme (ad esempio, dando pi√π peso a \\(\\theta = 0.5\\)): \\[\np(\\theta = 0.1) = \\frac{1}{4}, \\quad p(\\theta = 0.5) = \\frac{1}{2}, \\quad p(\\theta = 0.9) = \\frac{1}{4}.\n\\]\n\n\n\n\nCalcolare la probabilit√† di osservare 7 successi su 10 prove per ogni valore di \\(\\theta\\):\n\\[\np(k=7 \\mid \\theta) = \\binom{10}{7} \\theta^7 (1 - \\theta)^3.\n\\]\n\n\nMoltiplicare ciascuna di queste probabilit√† per la corrispondente probabilit√† a priori e sommare i risultati:\n\\[\np(k=7 \\mid n=10) = \\sum_{i} p(k=7 \\mid \\theta_i) p(\\theta_i).\n\\]\n\n\nSostituendo i valori per la distribuzione uniforme:\n\\[\np(k=7 \\mid n=10) = \\binom{10}{7} 0.1^7 (0.9)^3 \\cdot \\frac{1}{3} +\n\\binom{10}{7} 0.5^7 (0.5)^3 \\cdot \\frac{1}{3} +\n\\binom{10}{7} 0.9^7 (0.1)^3 \\cdot \\frac{1}{3}.\n\\]\nQuesta somma rappresenta la verosimiglianza marginale, ossia la probabilit√† di ottenere 7 successi su 10, considerando tutte le possibili incertezze su \\(\\theta\\).\n\n40.10.2 Caso con Parametri Continui\nNella maggior parte delle situazioni, il parametro \\(\\theta\\) non assume solo pochi valori discreti, ma pu√≤ variare continuamente in un intervallo (ad esempio, tra 0 e 1). In questo caso, invece di sommare, dobbiamo integrare:\n\\[\np(k=7 \\mid n=10) = \\int_{0}^{1} \\binom{10}{7} \\theta^7 (1 - \\theta)^3 p(\\theta) \\, d\\theta.\n\\]\nQui:\n\n\n\\(p(\\theta)\\) √® la distribuzione a priori di \\(\\theta\\).\nL‚Äôintegrale rappresenta una media ponderata della probabilit√† di ottenere i dati, considerando tutti i valori di \\(\\theta\\).\n\nAd esempio, se \\(\\theta \\sim \\text{Beta}(2,2)\\), la verosimiglianza marginale diventa:\n\\[\np(k=7 \\mid n=10) = \\int_{0}^{1} \\binom{10}{7} \\theta^7 (1 - \\theta)^3 \\frac{\\theta (1-\\theta)}{B(2,2)} \\, d\\theta.\n\\]\nQuesto tipo di calcolo viene spesso risolto numericamente.\n\n40.10.3 Calcolo Numerico della Verosimiglianza Marginale in R\nSe vogliamo calcolare la verosimiglianza marginale numericamente, possiamo usare l‚Äôintegrazione numerica in R.\nCaso con Parametri Discreti.\n\n# Definiamo i valori possibili di theta e le probabilit√† a priori\ntheta_vals &lt;- c(0.1, 0.5, 0.9)\nprior_probs &lt;- c(1/3, 1/3, 1/3)  # Distribuzione uniforme\n\n# Calcoliamo la verosimiglianza per ciascun valore di theta\nlikelihoods &lt;- dbinom(7, size = 10, prob = theta_vals)\n\n# Calcoliamo la verosimiglianza marginale sommando i contributi ponderati\nmarginal_likelihood &lt;- sum(likelihoods * prior_probs)\nprint(marginal_likelihood)\n#&gt; [1] 0.0582\n\nCaso con Parametri Continui.\n\n# Definiamo la funzione di verosimiglianza pesata dalla prior\nintegrand &lt;- function(theta) {\n  dbinom(7, size = 10, prob = theta) * dbeta(theta, shape1 = 2, shape2 = 2)\n}\n\n# Eseguiamo l'integrazione numerica\nmarginal_likelihood &lt;- integrate(integrand, lower = 0, upper = 1)$value\nprint(marginal_likelihood)\n#&gt; [1] 0.1119\n\n\n40.10.4 Interpretazione della Verosimiglianza Marginale\nLa verosimiglianza marginale rappresenta la probabilit√† complessiva dei dati, tenendo conto di tutte le possibili incertezze sul parametro \\(\\theta\\).\n\nSe la verosimiglianza marginale √® alta, significa che il modello nel suo insieme √® compatibile con i dati osservati.\nSe la verosimiglianza marginale √® bassa, significa che, indipendentemente dal valore di \\(\\theta\\), il modello non spiega bene i dati.\n\nA differenza della verosimiglianza classica, che valuta quanto siano probabili i dati per un singolo valore di \\(\\theta\\), la verosimiglianza marginale considera tutte le possibili ipotesi sul parametro.\n\n40.10.5 Ruolo nella Statistica Bayesiana\nLa verosimiglianza marginale svolge un ruolo cruciale nell‚Äôinferenza bayesiana perch√© appare nella formula di Bayes:\n\\[\np(\\theta \\mid D) = \\frac{p(D \\mid \\theta) p(\\theta)}{p(D)},\n\\]\ndove \\(p(D)\\) √® la verosimiglianza marginale. Questa quantit√†: 1. Serve da fattore di normalizzazione per la distribuzione a posteriori \\(p(\\theta \\mid D)\\). 2. Permette di confrontare modelli diversi, attraverso il fattore di Bayes:\n\\[\n   BF = \\frac{p(D \\mid M_1)}{p(D \\mid M_2)},\n   \\]\ndove \\(M_1\\) e \\(M_2\\) sono due modelli diversi.\nIn conclusione, la verosimiglianza marginale √® un concetto chiave nell‚Äôinferenza bayesiana, che ci permette di valutare quanto un modello sia coerente con i dati, tenendo conto di tutte le possibili incertezze sui parametri.\n\nPer parametri discreti, si calcola come una somma ponderata.\nPer parametri continui, si calcola con un integrale.\n√à essenziale per il calcolo della distribuzione a posteriori e per il confronto tra modelli.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>40</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#riflessioni-conclusive",
    "href": "chapters/probability/15_likelihood.html#riflessioni-conclusive",
    "title": "40¬† La verosimiglianza",
    "section": "\n40.11 Riflessioni Conclusive",
    "text": "40.11 Riflessioni Conclusive\nLa funzione di verosimiglianza rappresenta un ponte fondamentale tra i dati osservati e i parametri di un modello statistico, offrendo una misura della plausibilit√† dei dati rispetto a diversi valori possibili dei parametri. La sua costruzione richiede l‚Äôintegrazione di tre elementi chiave: il modello statistico ipotizzato come generatore dei dati, lo spazio dei parametri associato al modello e le osservazioni empiriche disponibili.\nNell‚Äôambito dell‚Äôinferenza statistica, la funzione di verosimiglianza svolge un ruolo centrale. Essa consente di valutare quanto bene diversi valori dei parametri siano in grado di spiegare i dati osservati, diventando cos√¨ uno strumento essenziale per la stima dei parametri e la selezione del modello. La sua corretta applicazione √® determinante per garantire analisi dati rigorose e interpretazioni affidabili dei risultati.\nIn sintesi, padroneggiare il concetto di verosimiglianza e saperlo applicare in modo appropriato sono competenze indispensabili per chi si occupa di ricerca empirica e analisi di dati complessi. La verosimiglianza non √® solo uno strumento tecnico, ma un pilastro metodologico che supporta la comprensione e l‚Äôinterpretazione dei fenomeni osservati attraverso modelli statistici.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>40</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#esercizi",
    "href": "chapters/probability/15_likelihood.html#esercizi",
    "title": "40¬† La verosimiglianza",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nSpiega ciascuno dei concetti seguenti con una frase:\n\nprobabilit√†.\nfunzione di massa di probabilit√†.\nfunzione di densit√† di probabilit√†.\ndistribuzione di probabilit√†.\ndistribuzione di probabilit√† discreta.\ndistribuzione di probabilit√† continua.\nfunzione di distribuzione cumulativa (cdf).\nverosimiglianza\n\n\n\n\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nAll‚Äôesame ti verr√† chiesto di:\n\nCalcolare la funzione di verosimiglianza binomiale e riportare il valore della funzione in corrispondenza di specifici valori \\(\\theta\\).\nCalcolare la stima di massima verosimiglianza.\nRispondere a domande che implicano una adeguata comprensione del concetto di funzione di verosimiglianza.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>40</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/15_likelihood.html#informazioni-sullambiente-di-sviluppo",
    "title": "40¬† La verosimiglianza",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.5.3     \n#&gt;  [9] scales_1.3.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.9.1   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         rlang_1.1.5       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       tools_4.4.2       parallel_4.4.2    tzdb_0.5.0       \n#&gt; [21] colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5       R6_2.6.1         \n#&gt; [25] lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.1    \n#&gt; [29] gtable_0.3.6      glue_1.8.0        xfun_0.51         tidyselect_1.2.1 \n#&gt; [33] rstudioapi_0.17.1 farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-167     \n#&gt; [37] labeling_0.4.3    rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>40</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#bibliografia",
    "href": "chapters/probability/15_likelihood.html#bibliografia",
    "title": "40¬† La verosimiglianza",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>40</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/16_likelihood_gauss.html",
    "href": "chapters/probability/16_likelihood_gauss.html",
    "title": "41¬† La verosimiglianza gaussiana",
    "section": "",
    "text": "Introduzione\nLa distribuzione gaussiana (o distribuzione normale) √® una delle distribuzioni pi√π utilizzate in statistica perch√© descrive molti fenomeni naturali e psicologici. In questo capitolo esploreremo come si calcola la verosimiglianza, ovvero la plausibilit√† dei parametri, nel caso della distribuzione normale.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>41</span>¬† <span class='chapter-title'>La verosimiglianza gaussiana</span>"
    ]
  },
  {
    "objectID": "chapters/probability/16_likelihood_gauss.html#modello-gaussiano-e-verosimiglianza",
    "href": "chapters/probability/16_likelihood_gauss.html#modello-gaussiano-e-verosimiglianza",
    "title": "41¬† La verosimiglianza gaussiana",
    "section": "\n41.1 Modello Gaussiano e Verosimiglianza",
    "text": "41.1 Modello Gaussiano e Verosimiglianza\n\n41.1.1 Caso di una Singola Osservazione\nImmaginiamo di misurare il Quoziente Intellettivo (QI) di una persona e ottenere un valore specifico, ad esempio 114. Assumiamo che il QI segua una distribuzione normale con media \\(\\mu\\) sconosciuta e deviazione standard \\(\\sigma\\) nota (ad esempio \\(\\sigma = 15\\)).\nLa funzione di densit√† di probabilit√† per una distribuzione normale √®:\n\\[\nf(y \\mid \\mu, \\sigma) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left(-\\frac{(y-\\mu)^2}{2\\sigma^2}\\right) ,\n\\]\ndove:\n\n\n\\(y\\) √® il valore osservato,\n\n\\(\\mu\\) √® la media (il parametro che vogliamo stimare),\n\n\\(\\sigma\\) √® la deviazione standard (conosciuta).\n\nLa verosimiglianza misura quanto diversi valori di \\(\\mu\\) sono plausibili, dato il valore osservato (114).\nEsempio pratico in R:\n\n# Dati iniziali\ny_obs &lt;- 114\nsigma &lt;- 15\nmu_values &lt;- seq(70, 160, length.out = 1000)\n\n# Calcolo della verosimiglianza\nlikelihood &lt;- dnorm(y_obs, mean = mu_values, sd = sigma)\n\n# Grafico della verosimiglianza\nggplot(data.frame(mu = mu_values, likelihood = likelihood), aes(x = mu, y = likelihood)) +\n  geom_line(color = \"blue\") +\n  labs(\n    title = \"Verosimiglianza per un singolo valore di QI (114)\",\n    x = \"Media (Œº)\",\n    y = \"Verosimiglianza\"\n  )\n\n\n\n\n\n\n\nQual √® il valore migliore per \\(\\mu\\)?\nIl valore migliore di \\(\\mu\\) sar√† quello che rende massima la verosimiglianza. In questo semplice caso, √® esattamente il valore osservato (114):\n\nmu_ottimale &lt;- mu_values[which.max(likelihood)]\ncat(\"Il valore ottimale di Œº √®:\", mu_ottimale)\n#&gt; Il valore ottimale di Œº √®: 114\n\n\n41.1.2 Log-Verosimiglianza\nSpesso, per semplicit√† di calcolo, si usa la log-verosimiglianza, che trasforma i prodotti in somme, rendendo i calcoli pi√π semplici e stabili:\n\\[\n\\log L(\\mu \\mid y, \\sigma) = -\\frac{1}{2}\\log(2\\pi) - \\log(\\sigma) - \\frac{(y-\\mu)^2}{2\\sigma^2}.\n\\]\nCalcolo pratico con R:\n\nnegative_log_likelihood &lt;- function(mu, y, sigma) {\n  0.5 * log(2 * pi) + log(sigma) + ((y - mu)^2) / (2 * sigma^2)\n}\n\nresult &lt;- optim(\n  par = 100, # Valore iniziale\n  fn = negative_log_likelihood,\n  y = y_obs,\n  sigma = sigma,\n  method = \"L-BFGS-B\",\n  lower = 70,\n  upper = 160\n)\n\nmu_max_loglik &lt;- result$par\ncat(\"Il valore ottimale di Œº dalla log-verosimiglianza √®:\", mu_max_loglik)\n#&gt; Il valore ottimale di Œº dalla log-verosimiglianza √®: 114\n\nIn questo caso, otteniamo nuovamente \\(\\mu = 114\\).\n\n41.1.3 Campione di Osservazioni Indipendenti\nConsideriamo ora un insieme pi√π grande di osservazioni indipendenti, ciascuna co una distribuzione normale con la stessa media \\(\\mu\\) e la stessa deviazione standard \\(\\sigma\\). Supponiamo di aver misurato i punteggi di depressione (ad esempio, scala BDI-II) per 30 persone:\n\ny &lt;- c(\n  26, 35, 30, 25, 44, 30, 33, 43, 22, 43, 24, 19, 39, 31, 25, 28, 35, 30, 26, \n  31, 41, 36, 26, 35, 33, 28, 27, 34, 27, 22\n)\n\nAssumiamo inoltre che \\(\\sigma\\) sia nota (ad esempio \\(\\sigma = 6.50\\)). In questo caso, la log-verosimiglianza si calcola cos√¨:\n\nlog_likelihood &lt;- function(mu, y, sigma) {\n  n &lt;- length(y)\n  term1 &lt;- -n * log(sigma) - n * log(sqrt(2 * pi))\n  term2 &lt;- -sum((y - mu)^2) / (2 * sigma^2)\n  return(term1 + term2)\n}\n\nsigma &lt;- 6.50\nmu_range &lt;- seq(mean(y) - 2 * sigma, mean(y) + 2 * sigma, length.out = 1000)\n\n# Calcolo della log-verosimiglianza con un ciclo for\nlog_lik_values &lt;- numeric(length(mu_range))\n\nfor (i in seq_along(mu_range)) {\n  log_lik_values[i] &lt;- log_likelihood(mu_range[i], y, sigma)\n}\n\nIl ciclo for() scorre ogni valore di mu_range, calcolando la log-verosimiglianza per ciascun valore e salvando i risultati nel vettore log_lik_values.\nVisualizziamo la log-verosimiglianza:\n\nggplot(\n  data.frame(mu = mu_range, log_likelihood = log_lik_values),\n  aes(x = mu, y = log_likelihood)\n) +\n  geom_line(color = \"blue\") +\n  labs(\n    title = \"Log-verosimiglianza per dati BDI-II\",\n    x = \"Media (Œº)\",\n    y = \"Log-verosimiglianza\"\n  ) +\n  geom_vline(xintercept = mean(y), linetype = \"dashed\", color = \"red\")\n\n\n\n\n\n\n\nOttimizzazione numerica per \\(\\mu\\):\n\nnegative_log_likelihood &lt;- function(mu, y, sigma) {\n  -log_likelihood(mu, y, sigma)\n}\n\nresult &lt;- optim(\n  par = mean(y),\n  fn = negative_log_likelihood,\n  y = y,\n  sigma = sigma,\n  method = \"L-BFGS-B\",\n  lower = min(mu_range),\n  upper = max(mu_range)\n)\n\nmu_optimal &lt;- result$par\ncat(\"Il valore ottimale di Œº √®:\", mu_optimal)\n#&gt; Il valore ottimale di Œº √®: 30.93",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>41</span>¬† <span class='chapter-title'>La verosimiglianza gaussiana</span>"
    ]
  },
  {
    "objectID": "chapters/probability/16_likelihood_gauss.html#riflessioni-conclusive",
    "href": "chapters/probability/16_likelihood_gauss.html#riflessioni-conclusive",
    "title": "41¬† La verosimiglianza gaussiana",
    "section": "\n41.2 Riflessioni Conclusive",
    "text": "41.2 Riflessioni Conclusive\n\nNel caso di una distribuzione normale con \\(\\sigma\\) nota, la miglior stima di \\(\\mu\\) (stima di massima verosimiglianza) √® sempre la media delle osservazioni.\nVisualizzare la funzione di verosimiglianza aiuta a capire la plausibilit√† relativa dei diversi valori di \\(\\mu\\).\nLa log-verosimiglianza semplifica e rende pi√π stabili i calcoli numerici.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>41</span>¬† <span class='chapter-title'>La verosimiglianza gaussiana</span>"
    ]
  },
  {
    "objectID": "chapters/probability/16_likelihood_gauss.html#esercizi",
    "href": "chapters/probability/16_likelihood_gauss.html#esercizi",
    "title": "41¬† La verosimiglianza gaussiana",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nSupponi di aver misurato il livello di ansia (ad esempio usando una scala standardizzata) in un campione di 15 persone con i seguenti punteggi:\nansia &lt;- c(23, 27, 30, 29, 25, 28, 26, 24, 31, 29, 27, 26, 28, 30, 25)\nAssumendo che la deviazione standard sia nota e pari a 3.5, svolgi le seguenti attivit√† in R:\n\nCalcola la funzione di verosimiglianza gaussiana per diversi valori di \\(\\mu\\) nell‚Äôintervallo da 20 a 35.\nTrova numericamente il valore di \\(\\mu\\) che rende massima la verosimiglianza (stima di massima verosimiglianza, MLE).\nDisegna un grafico della funzione di verosimiglianza per visualizzare il risultato.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>41</span>¬† <span class='chapter-title'>La verosimiglianza gaussiana</span>"
    ]
  },
  {
    "objectID": "chapters/probability/16_likelihood_gauss.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/16_likelihood_gauss.html#informazioni-sullambiente-di-sviluppo",
    "title": "41¬† La verosimiglianza gaussiana",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.5.3     \n#&gt;  [9] scales_1.3.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.9.1   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         rlang_1.1.5       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       tools_4.4.2       parallel_4.4.2    tzdb_0.5.0       \n#&gt; [21] colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5       R6_2.6.1         \n#&gt; [25] lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.1    \n#&gt; [29] gtable_0.3.6      glue_1.8.0        xfun_0.51         tidyselect_1.2.1 \n#&gt; [33] rstudioapi_0.17.1 farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-167     \n#&gt; [37] labeling_0.4.3    rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>41</span>¬† <span class='chapter-title'>La verosimiglianza gaussiana</span>"
    ]
  },
  {
    "objectID": "chapters/probability/16_likelihood_gauss.html#bibliografia",
    "href": "chapters/probability/16_likelihood_gauss.html#bibliografia",
    "title": "41¬† La verosimiglianza gaussiana",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>41</span>¬† <span class='chapter-title'>La verosimiglianza gaussiana</span>"
    ]
  },
  {
    "objectID": "chapters/probability/17_likelihood_ratio.html",
    "href": "chapters/probability/17_likelihood_ratio.html",
    "title": "42¬† Il rapporto di verosimiglianze",
    "section": "",
    "text": "Introduzione\nIl rapporto di verosimiglianze (o likelihood ratio, LR) √® uno strumento per confrontare due modelli statistici alternativi, valutando quale dei due modelli spieghi meglio i dati osservati. La formula del likelihood ratio √®:\n\\[\n\\lambda = \\frac{L(\\mu_2 \\mid dati)}{L(\\mu_1 \\mid dati)} ,\n\\]\ndove:\nInterpretazione:",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>42</span>¬† <span class='chapter-title'>Il rapporto di verosimiglianze</span>"
    ]
  },
  {
    "objectID": "chapters/probability/17_likelihood_ratio.html#introduzione",
    "href": "chapters/probability/17_likelihood_ratio.html#introduzione",
    "title": "42¬† Il rapporto di verosimiglianze",
    "section": "",
    "text": "\\(L(\\mu_2 \\mid dati)\\) √® la verosimiglianza del modello alternativo (ad esempio con una media \\(\\mu_2\\)).\n\n\\(L(\\mu_1 \\mid dati)\\) √® la verosimiglianza del modello nullo (ad esempio con una media \\(\\mu_1\\)).\n\n\n\nSe \\(\\lambda &gt; 1\\), i dati supportano maggiormente il modello alternativo rispetto a quello nullo.\nSe \\(\\lambda &lt; 1\\), i dati supportano maggiormente il modello nullo rispetto all‚Äôalternativo.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>42</span>¬† <span class='chapter-title'>Il rapporto di verosimiglianze</span>"
    ]
  },
  {
    "objectID": "chapters/probability/17_likelihood_ratio.html#illustrazione",
    "href": "chapters/probability/17_likelihood_ratio.html#illustrazione",
    "title": "42¬† Il rapporto di verosimiglianze",
    "section": "\n42.1 Illustrazione",
    "text": "42.1 Illustrazione\nEcco un‚Äôimmagine illustrativa del rapporto di verosimiglianza (likelihood ratio) confrontando due modelli gaussiani (ipotesi nulla e ipotesi alternativa).\nQuesta figura mostra:\n\nLa curva blu rappresenta l‚Äôipotesi nulla (H0), secondo cui il fenomeno studiato non ha un effetto (ad esempio, la media √® \\(\\mu = 100\\)).\nLa curva arancione rappresenta invece l‚Äôipotesi alternativa (Ha), cio√® quella che ipotizza che ci sia un effetto (ad esempio, una media pi√π alta: \\(\\mu = 110\\)).\nLa linea tratteggiata indica il valore osservato (MLE), cio√® il valore effettivamente rilevato nei dati.\n\nIl rapporto di verosimiglianza √® dato dal rapporto tra la densit√† della curva alternativa (\\(H_a\\)) e quella della curva nulla (\\(H_0\\)) in corrispondenza del valore osservato (MLE). In questo esempio, tale rapporto √® 1.6, indicando che i dati osservati sono circa 1.6 volte pi√π probabili secondo l‚Äôipotesi alternativa rispetto a quella nulla.\n\n\n\n\n\nFigura¬†42.1: Rapporto di verosimiglianza (likelihood ratio) per il confronto tra due modelli gaussiani (ipotesi nulla e ipotesi alternativa).\n\n\n\n42.1.1 Interpretazione\n\nSe il LR √® alto (ad esempio, maggiore di 3 o 5), ci√≤ indica un forte supporto ai dati in favore del modello alternativo rispetto al modello nullo.\nUn LR vicino a 1 indica che non c‚Äô√® una chiara evidenza in favore di uno dei due modelli.\n\nQuesta metodologia permette un confronto diretto e semplice fra diverse ipotesi sulla base dei dati raccolti, facilitando l‚Äôinterpretazione statistica in contesti di ricerca psicologica.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>42</span>¬† <span class='chapter-title'>Il rapporto di verosimiglianze</span>"
    ]
  },
  {
    "objectID": "chapters/probability/17_likelihood_ratio.html#rapporti-di-verosimiglianza-aggiustati-e-criterio-di-akaike-aic",
    "href": "chapters/probability/17_likelihood_ratio.html#rapporti-di-verosimiglianza-aggiustati-e-criterio-di-akaike-aic",
    "title": "42¬† Il rapporto di verosimiglianze",
    "section": "\n42.2 Rapporti di Verosimiglianza Aggiustati e Criterio di Akaike (AIC)",
    "text": "42.2 Rapporti di Verosimiglianza Aggiustati e Criterio di Akaike (AIC)\nSpesso il rapporto di verosimiglianza ‚Äúgrezzo‚Äù (\\(\\lambda\\)) deve essere aggiustato per tenere conto della differenza nel numero di parametri tra i modelli confrontati. Infatti, quando confrontiamo due modelli, quello con pi√π parametri tende quasi sempre a descrivere meglio i dati osservati, ma ci√≤ pu√≤ essere dovuto semplicemente alla sua maggiore complessit√†. Questo fenomeno √® noto come sovradattamento (overfitting).\nPer correggere questa tendenza, si usa un rapporto di verosimiglianza aggiustato (Adjusted Likelihood Ratio, indicato con \\(\\lambda_{\\text{adj}}\\). Questo tipo di aggiustamento penalizza i modelli pi√π complessi, rendendo il confronto tra modelli pi√π equo e affidabile.\n\n42.2.1 Relazione con il Criterio di Akaike (AIC)\nUna modalit√† comune per effettuare questa correzione √® tramite il Criterio di Akaike (AIC). L‚ÄôAIC √® definito come:\n\\[\n\\text{AIC} = 2k - 2\\log(\\lambda),\n\\tag{42.1}\\]\nin cui:\n\n\n\\(k\\) √® il numero dei parametri del modello.\n\n\\(\\lambda\\) √® il rapporto di verosimiglianza grezzo.\n\nDa questa equazione possiamo ricavare una formula per calcolare il rapporto di verosimiglianza aggiustato utilizzando l‚ÄôAIC:\n\\[\n\\lambda_{\\text{adj}} = \\lambda \\times e^{(k_1 - k_2)},\n\\]\ndove:\n\n\n\\(k_1\\) √® il numero di parametri del modello pi√π semplice,\n\n\\(k_2\\) √® il numero di parametri del modello pi√π complesso,\n\n\\(e^{(k_1 - k_2)}\\) √® il fattore correttivo che penalizza il modello pi√π complesso.\n\nIn breve, pi√π parametri ha un modello, maggiore sar√† la penalizzazione applicata.\n\n42.2.2 Rapporto tra Likelihood Ratio e AIC\nIl rapporto di verosimiglianza aggiustato tramite l‚ÄôAIC consente di confrontare in modo equo modelli con un numero differente di parametri. Senza questa correzione, rischieremmo di scegliere sempre modelli pi√π complessi, indipendentemente dalla loro reale capacit√† esplicativa, con il rischio di sovrastimare la qualit√† della loro spiegazione.\nUtilizzare il rapporto di verosimiglianza aggiustato, quindi, permette di scegliere il modello migliore considerando sia la capacit√† di adattarsi ai dati, sia la semplicit√† del modello stesso.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>42</span>¬† <span class='chapter-title'>Il rapporto di verosimiglianze</span>"
    ]
  },
  {
    "objectID": "chapters/probability/17_likelihood_ratio.html#illustrazione-1",
    "href": "chapters/probability/17_likelihood_ratio.html#illustrazione-1",
    "title": "42¬† Il rapporto di verosimiglianze",
    "section": "\n42.3 Illustrazione",
    "text": "42.3 Illustrazione\nImmaginiamo un esperimento psicologico sulla memoria visiva: vogliamo capire se mostrare delle immagini che suscitano forti emozioni facilita la memorizzazione rispetto a immagini neutre. Abbiamo due gruppi:\n\n\nGruppo neutro: vede immagini neutre e ricorda correttamente 14 immagini su 30.\n\nGruppo emozionale: vede immagini emotivamente intense e ricorda correttamente 22 immagini su 30.\n\nVogliamo confrontare due modelli:\n\n\nModello nullo (Ho): la probabilit√† di ricordare √® uguale nei due gruppi.\n\nModello alternativo (Ha): i due gruppi hanno probabilit√† di ricordare diverse.\n\nDati osservati:\n\nsuccessi_neutro &lt;- 14\nsuccessi_emozione &lt;- 22\nprove &lt;- 30\n\nProbabilit√† comune sotto l‚Äôipotesi nulla (uguale nei due gruppi):\n\np_null &lt;- (successi_neutro + successi_emozione) / (30 + 30)\n\nLog-verosimiglianza sotto H0:\n\nll_null &lt;- dbinom(successi_neutro, prove, p_null, log = TRUE) + \n           dbinom(successi_emozione, prove, p_null, log = TRUE)\n\nLog-verosimiglianza sotto H1 (due probabilit√† diverse):\n\np_neutro &lt;- successi_neutro / prove\np_emozione &lt;- successi_emozione / prove\n\nll_alt &lt;- dbinom(successi_neutro, prove, p_neutro, log = TRUE) + \n          dbinom(successi_emozione, prove, p_emozione, log = TRUE)\n\nRapporto di verosimiglianza grezzo:\n\nlr &lt;- exp(ll_alt - ll_null)\n\nNumero di parametri dei due modelli:\n\nk_null &lt;- 1 # unica probabilit√†\nk_alt &lt;- 2 # probabilit√† distinte\n\nCalcolo dell‚ÄôAIC per penalizzare il modello pi√π complesso:\n\nAIC_null &lt;- 2 * k_null - 2 * ll_null\nAIC_alt &lt;- 2 * k_alt - 2 * ll_alt\n\nRapporto di verosimiglianza aggiustato (penalizzazione tramite AIC):\n\nlr_adj &lt;- exp((AIC_null - AIC_alt) / 2)\n\n\n# Output\ncat(\"Rapporto di verosimiglianza grezzo:\", round(lr, 2), \"\\n\")\n#&gt; Rapporto di verosimiglianza grezzo: 9.54\ncat(\"Rapporto di verosimiglianza aggiustato (Œª_adj):\", round(lr_adj, 2), \"\\n\")\n#&gt; Rapporto di verosimiglianza aggiustato (Œª_adj): 3.51\n\nInterpretazione:\n\nun rapporto aggiustato (Œª_adj) maggiore di 1 indica che i dati supportano maggiormente il modello alternativo (due probabilit√† diverse) rispetto al modello nullo (probabilit√† uguali):\nun valore di Œª_adj prossimo a 1 indica invece che i dati non permettono di preferire chiaramente un modello rispetto all‚Äôaltro.\n\n\n42.3.1 Significato del valore-p\n√à possibile testare formalmente se la differenza tra i due modelli √® sostanziale o pu√≤ essere spiegata dal caso. Il test statistico utilizzato √® il test del rapporto di verosimiglianza, che segue una distribuzione chi-quadrato con gradi di libert√† pari alla differenza del numero di parametri tra i modelli confrontati:\n\n# Test del rapporto di verosimiglianza\nLR_test &lt;- -2 * (ll_null - ll_alt)\ndf &lt;- k_alt - k_null\np_value &lt;- 1 - pchisq(LR_test, df)\n\ncat(\"Statistiche test (-2 log LR):\", round(LR_test, 2), \"\\n\")\n#&gt; Statistiche test (-2 log LR): 4.51\ncat(\"Gradi di libert√†:\", df, \"\\n\")\n#&gt; Gradi di libert√†: 1\ncat(\"Valore p del test:\", round(p_value, 4), \"\\n\")\n#&gt; Valore p del test: 0.0337\n\n\nUn valore-p piccolo (p &lt; .05) indica che √® improbabile che la differenza osservata sia dovuta solo al caso: possiamo preferire il modello alternativo.\nUn valore-p alto (vicino a 1) indica invece che non abbiamo abbastanza evidenza per preferire il modello alternativo rispetto al modello nullo.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>42</span>¬† <span class='chapter-title'>Il rapporto di verosimiglianze</span>"
    ]
  },
  {
    "objectID": "chapters/probability/17_likelihood_ratio.html#riflessioni-conclusive",
    "href": "chapters/probability/17_likelihood_ratio.html#riflessioni-conclusive",
    "title": "42¬† Il rapporto di verosimiglianze",
    "section": "\n42.4 Riflessioni Conclusive",
    "text": "42.4 Riflessioni Conclusive\nIn conclusione, usando il rapporto di verosimiglianza aggiustato e l‚ÄôAIC possiamo confrontare modelli statistici in maniera equilibrata, tenendo conto sia dell‚Äôadattamento ai dati che della semplicit√† del modello.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>42</span>¬† <span class='chapter-title'>Il rapporto di verosimiglianze</span>"
    ]
  },
  {
    "objectID": "chapters/probability/17_likelihood_ratio.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/17_likelihood_ratio.html#informazioni-sullambiente-di-sviluppo",
    "title": "42¬† Il rapporto di verosimiglianze",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.5.3     \n#&gt;  [9] scales_1.3.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.9.1   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         rlang_1.1.5       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       tools_4.4.2       parallel_4.4.2    tzdb_0.5.0       \n#&gt; [21] colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5       R6_2.6.1         \n#&gt; [25] lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.1    \n#&gt; [29] gtable_0.3.6      glue_1.8.0        xfun_0.51         tidyselect_1.2.1 \n#&gt; [33] rstudioapi_0.17.1 farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-167     \n#&gt; [37] rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>42</span>¬† <span class='chapter-title'>Il rapporto di verosimiglianze</span>"
    ]
  },
  {
    "objectID": "chapters/probability/17_likelihood_ratio.html#bibliografia",
    "href": "chapters/probability/17_likelihood_ratio.html#bibliografia",
    "title": "42¬† Il rapporto di verosimiglianze",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>42</span>¬† <span class='chapter-title'>Il rapporto di verosimiglianze</span>"
    ]
  },
  {
    "objectID": "chapters/probability/18_simulation.html",
    "href": "chapters/probability/18_simulation.html",
    "title": "43¬† Simulazioni",
    "section": "",
    "text": "43.1 Introduzione\nPrerequisiti\nConcetti e Competenze Chiave\nPreparazione del Notebook\nLa simulazione permette di sfruttare la potenza di calcolo dei moderni computer per sostituire i calcoli analitici, talvolta complessi o impossibili da risolvere. Attraverso la simulazione, non solo possiamo ottenere approssimazioni numeriche dei risultati attesi, ma possiamo anche studiare la distribuzione campionaria degli stimatori e delle funzioni complesse (come curve di regressione o istogrammi) quando le semplificazioni teoriche non sono pi√π applicabili.\nIn questo capitolo, discuteremo alcuni esercizi di simulazione presentati da Schervish & DeGroot (2014) e da Gelman et al. (2021). Simulare variabili casuali √® essenziale nelle statistiche applicate per diversi motivi:\nInoltre, il processo di simulazione si basa sul seguente ragionamento fondamentale: un modello matematico √® una narrazione di come i dati potrebbero essere stati generati. Simulare il modello significa seguirne i passaggi, compresi quelli casuali, per produrre dati sintetici (o surrogate data) che approssimino quelli reali. Questo approccio, noto come metodo Monte Carlo, sfrutta il Teorema dei Grandi Numeri per ottenere stime attendibili delle propriet√† del modello.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>43</span>¬† <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/18_simulation.html#introduzione",
    "href": "chapters/probability/18_simulation.html#introduzione",
    "title": "43¬† Simulazioni",
    "section": "",
    "text": "Comprensione della variazione casuale: i modelli di probabilit√† imitano la variabilit√† del mondo reale. La simulazione aiuta a sviluppare intuizioni sulle oscillazioni casuali nel breve termine e sui loro effetti nel lungo termine.\nDistribuzione campionaria: simulare dati consente di approssimare la distribuzione campionaria, trasferendo questa approssimazione alle stime e alle procedure statistiche.\nPrevisioni probabilistiche. i modelli di regressione producono previsioni probabilistiche. La simulazione √® il metodo pi√π generale per rappresentare l‚Äôincertezza nelle previsioni.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>43</span>¬† <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/18_simulation.html#calcolare-il-valore-medio-di-una-distribuzione",
    "href": "chapters/probability/18_simulation.html#calcolare-il-valore-medio-di-una-distribuzione",
    "title": "43¬† Simulazioni",
    "section": "\n43.2 Calcolare il valore medio di una distribuzione",
    "text": "43.2 Calcolare il valore medio di una distribuzione\nIl teorema dei grandi numeri ci garantisce che, osservando un grande campione di variabili casuali i.i.d. (indipendenti e identicamente distribuite) con media finita, la media campionaria sar√† vicina alla media della distribuzione. Utilizzando un computer per generare un ampio campione, possiamo calcolare la media delle variabili casuali al posto di affrontare calcoli analitici.\nPer utilizzare la simulazione, occorre:\n\nIdentificare il tipo di variabili casuali necessarie.\nCapire come farle generare al computer, sfruttando le funzioni built-in (ad esempio, rnorm, runif, rbinom, ecc.).\nDeterminare il numero di osservazioni necessarie per avere fiducia nei risultati numerici.\n\nDi seguito, vedremo un esempio pratico che verifica il concetto di simulazione confrontando i risultati numerici con quelli analitici.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>43</span>¬† <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/18_simulation.html#esempio-1-calcolo-della-media-di-una-distribuzione-uniforme",
    "href": "chapters/probability/18_simulation.html#esempio-1-calcolo-della-media-di-una-distribuzione-uniforme",
    "title": "43¬† Simulazioni",
    "section": "\n43.3 Esempio 1: Calcolo della media di una distribuzione uniforme",
    "text": "43.3 Esempio 1: Calcolo della media di una distribuzione uniforme\nLa distribuzione uniforme sull‚Äôintervallo \\([0, 1]\\) ha una media teorica pari a \\(0,5\\). Se generiamo \\(n\\) variabili casuali i.i.d. uniformi su \\([0, 1]\\), il teorema dei grandi numeri afferma che la media campionaria:\n\\[\n\\overline{X} = \\frac{1}{n} \\sum_{i=1}^n X_i\n\\]\nsar√† vicina alla media teorica \\(0,5\\), soprattutto per campioni di grandi dimensioni.\nVediamo come questo concetto si applica attraverso una simulazione in R.\n\n# Impostiamo il numero di simulazioni\nset.seed(123) # Per riproducibilit√†\nsample_sizes &lt;- c(100, 1000, 10000, 100000) # Dimensioni del campione\nresults &lt;- data.frame(Sample_Size = sample_sizes, Sample_Mean = NA)\n\n# Calcoliamo la media campionaria per ciascun campione\nfor (i in seq_along(sample_sizes)) {\n  n &lt;- sample_sizes[i]\n  sample &lt;- runif(n, min = 0, max = 1) # Generazione delle variabili uniformi\n  results$Sample_Mean[i] &lt;- mean(sample) # Media campionaria\n}\n\n# Stampiamo i risultati\nprint(results)\n#&gt;   Sample_Size Sample_Mean\n#&gt; 1         100      0.4986\n#&gt; 2        1000      0.4953\n#&gt; 3       10000      0.4984\n#&gt; 4      100000      0.4995\n\n\n# Visualizzazione grafica delle medie campionarie\nggplot(results, aes(x = Sample_Size, y = Sample_Mean)) +\n  geom_point() +\n  geom_hline(yintercept = 0.5, linetype = \"dashed\", color = \"red\") +\n  scale_x_log10() +\n  labs(\n    title = \"Convergenza della Media Campionaria alla Media Teorica\",\n    x = \"Dimensione del Campione (scala logaritmica)\",\n    y = \"Media Campionaria\"\n  ) \n\n\n\n\n\n\n\n\n\nGenerazione di variabili casuali: La funzione runif(n, min = 0, max = 1) genera \\(n\\) variabili uniformemente distribuite sull‚Äôintervallo \\([0, 1]\\).\n\nMedia campionaria: Per ogni dimensione del campione (\\(n\\)), calcoliamo la media con mean(sample).\n\nRisultati: Presentiamo i risultati in una tabella e li visualizziamo graficamente, mostrando la convergenza della media campionaria (\\(\\overline{X}\\)) verso il valore teorico \\(0,5\\).\n\nL‚Äôoutput mostrer√† una tabella con le medie campionarie per diverse dimensioni del campione. Il grafico evidenzier√† come la media campionaria si avvicini al valore teorico di \\(0,5\\) con l‚Äôaumentare della dimensione del campione.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>43</span>¬† <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/18_simulation.html#esempio-2-probabilit√†-di-una-normale-standard",
    "href": "chapters/probability/18_simulation.html#esempio-2-probabilit√†-di-una-normale-standard",
    "title": "43¬† Simulazioni",
    "section": "\n43.4 Esempio 2: Probabilit√† di una Normale Standard",
    "text": "43.4 Esempio 2: Probabilit√† di una Normale Standard\nLa probabilit√† che una variabile casuale standard normale sia almeno \\(1.0\\) √® nota e pari a \\(0.1587\\). Per verificare questa probabilit√† usando una simulazione, possiamo generare un grande numero di variabili casuali i.i.d. (indipendenti e identicamente distribuite) standard normali, ad esempio \\(X_1, \\ldots, X_n\\), e creare variabili casuali Bernoulli \\(Y_1, \\ldots, Y_n\\) definite come segue:\n\\[\nY_i =\n\\begin{cases}\n1 & \\text{se } X_i \\geq 1.0 \\\\\n0 & \\text{altrimenti.}\n\\end{cases}\n\\]\nIl teorema dei grandi numeri afferma che la proporzione:\n\\[\n\\overline{Y} = \\frac{1}{n} \\sum_{i=1}^n Y_i\n\\]\ndovrebbe essere vicina alla media teorica di \\(Y_i\\), ossia \\(\\text{Pr}(X_i \\geq 1.0) = 0.1587\\). In questo esempio, simuleremo campioni di diverse dimensioni \\(n\\) per calcolare la proporzione di \\(X_i \\geq 1.0\\) e confrontare i risultati con il valore teorico.\n\n# Impostiamo il seme per la riproducibilit√†\nset.seed(123)\n\n# Dimensioni dei campioni da analizzare\nsample_sizes &lt;- c(100, 1000, 10000, 100000)\n\n# Inizializziamo un data frame per salvare i risultati\nresults &lt;- data.frame(\n  Sample_Size = sample_sizes,\n  Proportion = NA\n)\n\n# Calcolo delle proporzioni per ciascun campione\nfor (i in seq_along(sample_sizes)) {\n  n &lt;- sample_sizes[i]\n  sample &lt;- rnorm(n)  # Generazione di variabili standard normali\n  Y &lt;- ifelse(sample &gt;= 1.0, 1, 0)  # Variabili Bernoulli\n  results$Proportion[i] &lt;- mean(Y)  # Proporzione di Y_i = 1\n}\n\n# Stampiamo i risultati\nprint(results)\n#&gt;   Sample_Size Proportion\n#&gt; 1         100     0.1700\n#&gt; 2        1000     0.1590\n#&gt; 3       10000     0.1571\n#&gt; 4      100000     0.1600\n\n\n# Grafico della proporzione rispetto alla dimensione del campione\nggplot(results, aes(x = Sample_Size, y = Proportion)) +\n  geom_point() +\n  geom_hline(yintercept = 0.1587, linetype = \"dashed\", color = \"red\") +\n  scale_x_log10() +\n  labs(\n    title = \"Convergenza della Proporzione Simulata alla Probabilit√† Teorica\",\n    x = \"Dimensione del Campione (scala logaritmica)\",\n    y = \"Proporzione di X ‚â• 1.0\"\n  ) \n\n\n\n\n\n\n\n\n\nGenerazione di variabili normali standard: La funzione rnorm(n) genera \\(n\\) variabili casuali dalla distribuzione normale standard.\n\nCreazione delle variabili Bernoulli: Tramite ifelse(sample &gt;= 1.0, 1, 0) trasformiamo le variabili normali standard in variabili Bernoulli.\n\nCalcolo della proporzione: La proporzione di \\(Y_i = 1\\) √® calcolata come la media delle variabili Bernoulli \\(Y\\).\n\nConfronto visivo: Il grafico mostra la convergenza della proporzione simulata al valore teorico (\\(0.1587\\)) con l‚Äôaumentare della dimensione del campione.\n\nIl codice dimostra che, con l‚Äôaumentare della dimensione del campione \\(n\\), la proporzione simulata di \\(X \\geq 1.0\\) converge verso la probabilit√† teorica \\(0.1587\\). Tuttavia, la variabilit√† delle simulazioni √® evidente per campioni pi√π piccoli, evidenziando l‚Äôimportanza della dimensione campionaria nella stima accurata delle probabilit√† tramite simulazione.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>43</span>¬† <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/18_simulation.html#esempio-3-attesa-per-il-cambiamento-dellumore",
    "href": "chapters/probability/18_simulation.html#esempio-3-attesa-per-il-cambiamento-dellumore",
    "title": "43¬† Simulazioni",
    "section": "\n43.5 Esempio 3: Attesa per il Cambiamento dell‚ÄôUmore",
    "text": "43.5 Esempio 3: Attesa per il Cambiamento dell‚ÄôUmore\nImmaginiamo un esperimento psicologico in cui due partecipanti completano un compito che induce stress, al termine del quale misurano il loro livello di umore su una scala da 1 a 10. Entrambi devono raggiungere un punteggio di umore pari a 7 prima di fermarsi. Si vuole stimare, in media, quanto tempo uno dei due dovr√† attendere affinch√© l‚Äôaltro raggiunga il punteggio stabilito.\nSupponiamo che il cambiamento dell‚Äôumore per ciascun partecipante sia modellato come una variabile casuale gamma con parametri \\(k = 10\\) (numero di tentativi per raggiungere il livello) e \\(\\lambda = 0.3\\) (frequenza del cambiamento per minuto). Denotiamo il tempo necessario al partecipante A come \\(X\\) e al partecipante B come \\(Y\\). Vogliamo calcolare la media di \\(Z = |X - Y|\\), cio√® la differenza assoluta nei tempi di completamento.\nAnzich√© affrontare calcoli analitici complessi, utilizzeremo una simulazione per stimare questa media.\n\n# Impostiamo il seme per la riproducibilit√†\nset.seed(123)\n\n# Parametri della distribuzione gamma\nk &lt;- 10  # Numero di eventi\nlambda &lt;- 0.3  # Frequenza degli eventi\n\n# Numero di simulazioni\nn_sim &lt;- 10000\n\n# Simuliamo i tempi di completamento per A e B\nX &lt;- rgamma(n_sim, shape = k, rate = lambda)\nY &lt;- rgamma(n_sim, shape = k, rate = lambda)\n\n# Calcoliamo la differenza assoluta\nZ &lt;- abs(X - Y)\n\n# Media della differenza assoluta\nmean_Z &lt;- mean(Z)\n\n# Stampa dei risultati\ncat(\"Media della differenza assoluta nei tempi di completamento:\", mean_Z, \"minuti\\n\")\n#&gt; Media della differenza assoluta nei tempi di completamento: 11.76 minuti\n\n\n# Istogramma della distribuzione di Z\nlibrary(ggplot2)\nggplot(data.frame(Z), aes(x = Z)) +\n  geom_histogram(binwidth = 1, color = \"black\", fill = \"lightblue\") +\n  labs(\n    title = \"Distribuzione dei Tempi di Attesa (Z)\",\n    x = \"Tempo di attesa Z (minuti)\",\n    y = \"Frequenza\"\n  ) \n\n\n\n\n\n\n\n\n\nGenerazione dei tempi gamma: Usiamo la funzione rgamma per generare \\(n = 10,000\\) tempi di completamento \\(X\\) e \\(Y\\), modellati come distribuzioni gamma con parametri \\(k = 10\\) e \\(\\lambda = 0.3\\).\n\nCalcolo della differenza assoluta: La differenza assoluta \\(Z = |X - Y|\\) rappresenta il tempo di attesa.\n\nStima della media: Utilizziamo la funzione mean per calcolare la media di \\(Z\\).\n\nIstogramma: Il grafico visualizza la distribuzione dei tempi di attesa \\(Z\\).\n\nSupponendo i parametri specificati, il codice produrr√† una stima della media del tempo di attesa e un istogramma che mostra la distribuzione di \\(Z\\).\nQuesto esperimento simulato fornisce una stima del tempo medio di attesa tra due partecipanti in un contesto di regolazione emotiva. La variabilit√† nei tempi di completamento evidenzia come i processi individuali (ad esempio, il recupero emotivo) possano differire, un aspetto rilevante per la progettazione di interventi psicologici.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>43</span>¬† <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/18_simulation.html#esempio-4-probabilit√†-di-sequenze-lunghe-in-un-lancio-di-monete",
    "href": "chapters/probability/18_simulation.html#esempio-4-probabilit√†-di-sequenze-lunghe-in-un-lancio-di-monete",
    "title": "43¬† Simulazioni",
    "section": "\n43.6 Esempio 4: Probabilit√† di Sequenze Lunghe in un Lancio di Monete",
    "text": "43.6 Esempio 4: Probabilit√† di Sequenze Lunghe in un Lancio di Monete\nIn questo esempio, esploriamo la probabilit√† di ottenere una sequenza di 12 teste consecutive in 100 lanci di una moneta. Anche se la probabilit√† di ottenere 12 teste in 12 lanci consecutivi √® estremamente bassa, la situazione cambia quando consideriamo un numero maggiore di lanci, come 100. Attraverso una simulazione, possiamo osservare come la probabilit√† di tale evento aumenti significativamente in un contesto di 100 lanci.\nImmagina di sentire qualcuno affermare di aver ottenuto 12 teste consecutive lanciando una moneta equa. La probabilit√† di ottenere esattamente 12 teste in 12 lanci indipendenti √® data da \\((0.5)^{12}\\), un valore molto piccolo. Tuttavia, se consideriamo una serie di 100 lanci, la probabilit√† che una sequenza di 12 teste consecutive appaia almeno una volta diventa molto pi√π alta. La domanda chiave √®: quanto aumenta la probabilit√† di osservare una sequenza di 12 teste consecutive quando si passano da 12 a 100 lanci?\nPer rispondere a questa domanda, utilizziamo una simulazione. Definiamo una variabile aleatoria \\(X\\) che assume il valore \\(1\\) se nei 100 lanci compare almeno una sequenza di 12 teste consecutive, e \\(0\\) altrimenti. La probabilit√† di ottenere una sequenza di 12 teste consecutive viene stimata come la media delle osservazioni di \\(X\\) in un gran numero di ripetizioni della simulazione. Questo approccio ci permette di quantificare l‚Äôaumento della probabilit√† rispetto al caso di soli 12 lanci.\n\n# Impostiamo il seme per la riproducibilit√†\nset.seed(123)\n\n# Parametri della simulazione\nn_sim &lt;- 10000  # Numero di simulazioni\nn_flips &lt;- 100  # Numero di lanci per simulazione\nsequence_length &lt;- 12  # Lunghezza della sequenza cercata\n\n# Funzione per verificare la presenza di una sequenza di almeno 'sequence_length' teste\ncheck_run &lt;- function(flips, sequence_length) {\n  # Trasformiamo i risultati in una stringa per contare sequenze consecutive\n  flip_string &lt;- paste(rbinom(flips, 1, 0.5), collapse = \"\")\n  return(any(grepl(paste(rep(1, sequence_length), collapse = \"\"), flip_string)))\n}\n\n# Eseguiamo la simulazione\nresults &lt;- replicate(n_sim, check_run(n_flips, sequence_length))\n\n# Calcoliamo la probabilit√† stimata\nestimated_probability &lt;- mean(results)\n\n# Stampiamo il risultato\ncat(\"Probabilit√† stimata di ottenere una sequenza di almeno\", sequence_length,\n    \"teste consecutive in\", n_flips, \"lanci:\", estimated_probability, \"\\n\")\n#&gt; Probabilit√† stimata di ottenere una sequenza di almeno 12 teste consecutive in 100 lanci: 0.0106\n\n\n# Distribuzione delle lunghezze massime delle sequenze\nlongest_runs &lt;- replicate(n_sim, {\n  flips &lt;- rbinom(n_flips, 1, 0.5)\n  max(rle(flips)$lengths[which(rle(flips)$values == 1)])\n})\n\n# Grafico della distribuzione delle sequenze pi√π lunghe\nggplot(data.frame(Longest_Run = longest_runs), aes(x = Longest_Run)) +\n  geom_histogram(binwidth = 1, color = \"black\", fill = \"lightblue\") +\n  labs(\n    title = \"Distribuzione delle Sequenze Pi√π Lunghe di Teste in 100 Lanci\",\n    x = \"Lunghezza della sequenza pi√π lunga\",\n    y = \"Frequenza\"\n  ) \n\n\n\n\n\n\n\n\n\nGenerazione dei lanci di moneta: Ogni lancio √® modellato come una variabile binaria con \\(\\text{Pr(Testa)} = 0.5\\), utilizzando rbinom.\n\nVerifica della sequenza: La funzione check_run cerca se una sequenza di lunghezza specificata appare nei lanci simulati. Questo √® realizzato trasformando i risultati dei lanci in una stringa e utilizzando la funzione grepl per rilevare la sequenza.\n\nStima della probabilit√†: La proporzione di simulazioni in cui appare una sequenza di almeno 12 teste fornisce una stima della probabilit√†.\n\nDistribuzione delle sequenze pi√π lunghe: Calcoliamo la lunghezza massima di una sequenza di teste per ogni simulazione e la visualizziamo con un istogramma.\n\nL‚Äôoutput fornisce:\n\nLa probabilit√† stimata di ottenere una sequenza di almeno 12 teste consecutive in 100 lanci.\nUn grafico che mostra la distribuzione delle sequenze pi√π lunghe osservate nei 10,000 esperimenti.\n\nQuesto approccio pu√≤ essere utilizzato per modellare eventi rari ma possibili in psicologia, come la comparsa di lunghe sequenze di comportamenti simili in compiti ripetuti (ad esempio, risposte corrette consecutive in un test di memoria). La simulazione offre una stima della probabilit√† di osservare tali eventi, fornendo informazioni utili per interpretare i risultati sperimentali.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>43</span>¬† <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/18_simulation.html#esempio-probabilit√†-della-media-campionaria",
    "href": "chapters/probability/18_simulation.html#esempio-probabilit√†-della-media-campionaria",
    "title": "43¬† Simulazioni",
    "section": "\n43.7 Esempio: Probabilit√† della Media Campionaria",
    "text": "43.7 Esempio: Probabilit√† della Media Campionaria\nConsideriamo un campione casuale di 30 persone estratte dalla popolazione generale, in cui il QI segue una distribuzione normale \\(\\mathcal{N}(100, 15)\\). Vogliamo calcolare la probabilit√† che la media campionaria superi 105, sia in maniera analitica che simulata.\nLa distribuzione della media campionaria √®:\n\\[\n\\text{Media campionaria: } \\mathcal{N}\\left(\\mu = 100, \\, \\sigma = \\frac{15}{\\sqrt{30}}\\right) ,\n\\]\ne la probabilit√† di superare 105 si calcola come:\n\\[\nP\\left(\\bar{X} &gt; 105\\right) = 1 - \\Phi\\left(\\frac{105 - 100}{15 / \\sqrt{30}}\\right) .\n\\]\n\n# Calcolo analitico della probabilit√†\nmu &lt;- 100        # Media della popolazione\nsigma &lt;- 15      # Deviazione standard della popolazione\nn &lt;- 30          # Dimensione del campione\nthreshold &lt;- 105 # Soglia per la media campionaria\n\n# Probabilit√† teorica\nprob_teorica &lt;- 1 - pnorm(threshold, mean = mu, sd = sigma / sqrt(n))\ncat(\"Probabilit√† teorica che la media campionaria sia maggiore di 105:\", prob_teorica, \"\\n\")\n#&gt; Probabilit√† teorica che la media campionaria sia maggiore di 105: 0.03394\n\nProcediamo ora ad una simulazione:\n\n# Simulazione\nset.seed(123)  # Per riproducibilit√†\nn_sim &lt;- 100000 # Numero di simulazioni\n\n# Generazione dei campioni e calcolo delle medie campionarie\nsample_means &lt;- replicate(n_sim, mean(rnorm(n, mean = mu, sd = sigma)))\n\n# Probabilit√† stimata tramite simulazione\nprob_simulata &lt;- mean(sample_means &gt; threshold)\ncat(\"Probabilit√† stimata tramite simulazione:\", prob_simulata, \"\\n\")\n#&gt; Probabilit√† stimata tramite simulazione: 0.0339\n\n\n# Istogramma delle medie campionarie\nggplot(data.frame(Sample_Means = sample_means), aes(x = Sample_Means)) +\n  geom_histogram(binwidth = 1, color = \"black\", fill = \"lightblue\") +\n  geom_vline(xintercept = threshold, linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Distribuzione delle Medie Campionarie\",\n    x = \"Media Campionaria\",\n    y = \"Frequenza\"\n  ) \n\n\n\n\n\n\n\n\nLa funzione pnorm calcola la probabilit√† cumulativa della normale. Sottraendo tale valore da 1, otteniamo la probabilit√† di superare la soglia specificata.\nLa funzione rnorm genera \\(n\\) valori casuali da una distribuzione normale \\(\\mathcal{N}(100, 15)\\). Ripetiamo il processo 100,000 volte con replicate, calcolando la media campionaria ogni volta.\nLa proporzione di medie campionarie che superano 105 fornisce la stima simulata della probabilit√†.\n\nLa simulazione offre un metodo pratico per stimare probabilit√† anche in situazioni pi√π complesse, dove il calcolo analitico potrebbe non essere semplice.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>43</span>¬† <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/18_simulation.html#esempio-5-simulazione-in-un-trial-clinico",
    "href": "chapters/probability/18_simulation.html#esempio-5-simulazione-in-un-trial-clinico",
    "title": "43¬† Simulazioni",
    "section": "\n43.8 Esempio 5: Simulazione in un Trial Clinico",
    "text": "43.8 Esempio 5: Simulazione in un Trial Clinico\nIn questo esempio, vogliamo analizzare i risultati di un trial clinico con quattro gruppi di trattamento (\\(i = 1, 2, 3, 4\\)), stimando la probabilit√† di successo (\\(P_i\\)) di ciascun trattamento. Il successo √® definito come la probabilit√† che un paziente non abbia una ricaduta dopo il trattamento.\nL‚Äôanalisi si basa su una distribuzione a posteriori di \\(P_i\\), calcolata combinando:\n\n\nLa verosimiglianza (likelihood): Derivata dai dati osservati \\(x_i\\) (successi) e \\(n_i\\) (pazienti totali per gruppo).\n\nLa distribuzione a priori: Una distribuzione Beta(\\(\\alpha_0, \\beta_0\\)) scelta per rappresentare le nostre convinzioni iniziali su \\(P_i\\).\n\n\n43.8.1 Derivazione della Distribuzione a Posteriori\n\nLikelihood (Verosimiglianza):\nLa probabilit√† di osservare \\(x_i\\) successi in \\(n_i\\) prove (pazienti) segue una distribuzione binomiale: \\[\nx_i \\sim \\text{Binomiale}(n_i, P_i)\n\\] La funzione di verosimiglianza per \\(P_i\\) √® quindi: \\[\n\\mathcal{L}(P_i \\mid x_i, n_i) \\propto P_i^{x_i} (1 - P_i)^{n_i - x_i}\n\\]\nDistribuzione a priori:\nAssumiamo che \\(P_i\\) segua una distribuzione Beta(\\(\\alpha_0, \\beta_0\\)), con densit√†: \\[\n\\pi(P_i) \\propto P_i^{\\alpha_0 - 1} (1 - P_i)^{\\beta_0 - 1}\n\\]\nDistribuzione a posteriori:\nCombinando la verosimiglianza e la distribuzione a priori, otteniamo la distribuzione a posteriori (tramite il Teorema di Bayes): \\[\n\\pi(P_i \\mid x_i, n_i) \\propto \\mathcal{L}(P_i \\mid x_i, n_i) \\cdot \\pi(P_i)\n\\] Sostituendo le espressioni della likelihood e della prior: \\[\n\\pi(P_i \\mid x_i, n_i) \\propto P_i^{x_i + \\alpha_0 - 1} (1 - P_i)^{n_i - x_i + \\beta_0 - 1}\n\\] Questa √® la densit√† di una distribuzione Beta con parametri aggiornati: \\[\nP_i \\sim \\text{Beta}(\\alpha_0 + x_i, \\beta_0 + n_i - x_i)\n\\]\n\n43.8.2 Simulazione con R\nIl nostro obiettivo √® stimare:\n\n\n\\(\\Pr(P_i &gt; P_4)\\), dove \\(P_4\\) rappresenta il placebo.\nLa probabilit√† che un trattamento sia il pi√π efficace (\\(P_i = \\max(P_1, P_2, P_3, P_4)\\)).\nLa probabilit√† che tutti i \\(P_i\\) siano vicini entro un intervallo \\(\\epsilon\\).\n\n\n# Parametri della distribuzione a priori\nalpha0 &lt;- 2  # Parametro a priori per i successi\nbeta0 &lt;- 2   # Parametro a priori per i fallimenti\n\n# Dati osservati\nn &lt;- c(50, 50, 50, 50)  # Numero totale di pazienti per ciascun gruppo\nx &lt;- c(35, 30, 25, 20)  # Numero di pazienti che non hanno avuto una ricaduta\n\n# Parametri posteriori\nposterior_alpha &lt;- alpha0 + x\nposterior_beta &lt;- beta0 + n - x\n\n# Numero di simulazioni\nn_sim &lt;- 10000\n\n# Simulazione delle distribuzioni posteriori\nset.seed(123)  # Per riproducibilit√†\nP &lt;- sapply(1:4, function(i) rbeta(n_sim, posterior_alpha[i], posterior_beta[i]))\n\n# 1. Probabilit√† che ciascun trattamento sia migliore del placebo\nprobs_better_than_placebo &lt;- colMeans(P[, 1:3] &gt; P[, 4])\nnames(probs_better_than_placebo) &lt;- paste0(\"P\", 1:3, \" &gt; P4\")\n# print(probs_better_than_placebo)\n\n# 2. Probabilit√† che un trattamento sia il migliore\nprobs_best &lt;- colMeans(apply(P, 1, function(row) row == max(row)))\nnames(probs_best) &lt;- paste0(\"P\", 1:4, \" √® il migliore\")\n# print(probs_best)\n\n# 3. Probabilit√† che tutti i Pi siano entro epsilon\nepsilon &lt;- 0.1\nprobs_within_epsilon &lt;- mean(apply(P, 1, function(row) max(row) - min(row) &lt;= epsilon))\ncat(\"Probabilit√† che tutti i Pi siano entro epsilon =\", epsilon, \":\", probs_within_epsilon, \"\\n\")\n#&gt; Probabilit√† che tutti i Pi siano entro epsilon = 0.1 : 0.0047\n\n# Visualizzazione: Distribuzioni posteriori\nP_df &lt;- data.frame(\n  Simulazione = rep(1:n_sim, 4),\n  P = as.vector(P),\n  Gruppo = factor(rep(1:4, each = n_sim), labels = paste0(\"P\", 1:4))\n)\n\nggplot(P_df, aes(x = P, fill = Gruppo)) +\n  geom_density(alpha = 0.6) +\n  labs(\n    title = \"Distribuzioni Posteriori dei Pi\",\n    x = \"Probabilit√† Pi\",\n    y = \"Densit√†\"\n  ) \n\n\n\n\n\n\n\n\n43.8.3 Risultati e Interpretazione\n\n\nProbabilit√† \\(\\Pr(P_i &gt; P_4)\\): Indicano quanto √® probabile che ogni trattamento superi il placebo.\n\nProbabilit√† che un trattamento sia il migliore: Mostrano quale trattamento √® pi√π efficace in termini probabilistici.\n\nProbabilit√† di vicinanza (\\(\\epsilon\\)): Forniscono informazioni sulla similarit√† tra le probabilit√† di successo dei trattamenti.\n\nQuesto approccio combina inferenza bayesiana e simulazione per rispondere a domande chiave in un trial clinico.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>43</span>¬† <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/18_simulation.html#esempio-6-quante-bambine-su-400-nascite",
    "href": "chapters/probability/18_simulation.html#esempio-6-quante-bambine-su-400-nascite",
    "title": "43¬† Simulazioni",
    "section": "\n43.9 Esempio 6: Quante bambine su 400 nascite?",
    "text": "43.9 Esempio 6: Quante bambine su 400 nascite?\nSupponiamo che la probabilit√† di nascita di una bambina sia \\(p\\) = 0.488. Se in un ospedale nascono 400 bambini in un anno, quante saranno bambine? Possiamo simulare questo processo usando una distribuzione binomiale, ripetendo la simulazione 10,000 volte.\n\n# Numero di simulazioni\nn_sims &lt;- 10000\n\n# Probabilit√† di nascita di una bambina\np_girl &lt;- 0.488\n\n# Simulazione del numero di bambine\nset.seed(123)\nn_girls &lt;- rbinom(n_sims, size = 400, prob = p_girl)\n\n# Visualizzazione dell'istogramma\nggplot(data.frame(n_girls), aes(x = n_girls)) +\n  geom_histogram(binwidth = 5, fill = \"lightblue\", color = \"black\", alpha = 0.6) +\n  labs(\n    title = \"Distribuzione del Numero di Bambine su 400 Nascite\",\n    x = \"Numero di Bambine\",\n    y = \"Frequenza\"\n  )",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>43</span>¬† <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/18_simulation.html#simulazione-di-probabilit√†-continue",
    "href": "chapters/probability/18_simulation.html#simulazione-di-probabilit√†-continue",
    "title": "43¬† Simulazioni",
    "section": "\n43.10 Simulazione di probabilit√† continue",
    "text": "43.10 Simulazione di probabilit√† continue\nI metodi di simulazione non si limitano a variabili discrete: come dimostrato da Gelman et al. (2021), √® possibile integrare anche distribuzioni continue. Ad esempio, per generare l‚Äôaltezza di un adulto in base al genere ‚Äì con il 52% di donne e il 48% di uomini ‚Äì si utilizzano due distribuzioni normali distinte. L‚Äôaltezza degli uomini segue approssimativamente una distribuzione normale con una media di 69.1 pollici e una deviazione standard di 2.9 pollici; per le donne, la media √® 63.7 pollici e la deviazione standard √® 2.7 pollici. Ecco il codice per generare l‚Äôaltezza di un adulto scelto casualmente:\n\nsimulate_height &lt;- function(N) {\n  gender &lt;- rbinom(N, size = 1, prob = 0.48) # 1 = uomo, 0 = donna\n  height &lt;- ifelse(\n    gender == 1,\n    rnorm(N, mean = 69.1, sd = 2.9),\n    rnorm(N, mean = 63.7, sd = 2.7)\n  )\n  return(mean(height))\n}\n\nSupponiamo di selezionare 10 adulti a caso. Cosa possiamo dire della loro altezza media?\n\nset.seed(123)\nn_sims &lt;- 10000\navg_heights &lt;- replicate(n_sims, simulate_height(10))\n\n# Visualizzazione dell'istogramma\nggplot(data.frame(avg_heights), aes(x = avg_heights)) +\n  geom_histogram(binwidth = 0.2, fill = \"lightblue\", color = \"black\", alpha = 0.6) +\n  labs(\n    title = \"Distribuzione dell'Altezza Media di 10 Adulti\",\n    x = \"Altezza Media\",\n    y = \"Frequenza\"\n  )",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>43</span>¬† <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/18_simulation.html#sommario-di-una-simulazione-con-media-e-mediana",
    "href": "chapters/probability/18_simulation.html#sommario-di-una-simulazione-con-media-e-mediana",
    "title": "43¬† Simulazioni",
    "section": "\n43.11 Sommario di una simulazione con media e mediana",
    "text": "43.11 Sommario di una simulazione con media e mediana\nQuando le nostre distribuzioni sono costruite come simulazioni al computer, pu√≤ essere conveniente riassumerle in qualche modo. Tipicamente, riassumiamo la posizione di una distribuzione con la sua media o mediana.\nLa variazione nella distribuzione √® tipicamente riassunta dalla deviazione standard, ma spesso preferiamo usare la deviazione mediana assoluta. Se la mediana di un insieme di simulazioni \\(z_1, \\ldots, z_n\\) √® \\(M\\), allora la deviazione mediana assoluta √®:\n\\[ \\text{mad} = \\text{mediana}_{n} |z_i - M| \\]\nTuttavia, poich√© siamo abituati a lavorare con le deviazioni standard, quando calcoliamo la deviazione mediana assoluta, la riscaliamo moltiplicandola per 1.483, il che riproduce la deviazione standard nel caso speciale della distribuzione normale:\n\\[ 1.483 * \\text{median}(|y - \\text{median}(z)|) \\]\nPreferiamo tipicamente i riassunti basati sulla mediana perch√© sono pi√π stabili computazionalmente, e riscaliamo il riassunto basato sulla mediana della variazione come descritto sopra in modo da essere comparabile alla deviazione standard, che sappiamo gi√† interpretare nella pratica statistica usuale.\nEcco come implementare quanto sopra in R per i dati relativi all‚Äôaltezza media di 10 adulti.\n\n# Calcolo della media e mediana\nmean_avg_height &lt;- mean(avg_heights)\nmedian_avg_height &lt;- median(avg_heights)\n\n# Calcolo della deviazione standard\nsd_avg_height &lt;- sd(avg_heights)\n\n# Calcolo della MAD (Deviazione Mediana Assoluta)\nmad_avg_height &lt;- median(abs(avg_heights - median_avg_height)) * 1.483\n\n# Risultati\ncat(\"Mean:\", mean_avg_height, \"\\n\")\n#&gt; Mean: 66.3\ncat(\"Median:\", median_avg_height, \"\\n\")\n#&gt; Median: 66.28\ncat(\"Standard Deviation:\", sd_avg_height, \"\\n\")\n#&gt; Standard Deviation: 1.226\ncat(\"MAD (scaled):\", mad_avg_height, \"\\n\")\n#&gt; MAD (scaled): 1.235\n\n\n43.11.1 Intervalli di Incertezza\nPer rappresentare l‚Äôincertezza, si calcolano intervalli centrali al 50% e al 95%.\n\n# Intervalli di incertezza\nlower_50 &lt;- quantile(avg_heights, 0.25)\nupper_50 &lt;- quantile(avg_heights, 0.75)\n\nlower_95 &lt;- quantile(avg_heights, 0.025)\nupper_95 &lt;- quantile(avg_heights, 0.975)\n\ncat(\"50% Interval:\", lower_50, \"-\", upper_50, \"\\n\")\n#&gt; 50% Interval: 65.46 - 67.13\ncat(\"95% Interval:\", lower_95, \"-\", upper_95, \"\\n\")\n#&gt; 95% Interval: 63.91 - 68.77\n\nEcco come interpretarli.\nIntervallo centrale al 50%.\n\nContiene i valori centrali che coprono il 50% della distribuzione. Questo intervallo si estende dal primo quartile (25¬∞ percentile) al terzo quartile (75¬∞ percentile).\nIndica la fascia di valori in cui si trovano i risultati ‚Äúpi√π comuni‚Äù o tipici. √à una misura di variabilit√† concentrata nella parte centrale della distribuzione, meno sensibile a valori estremi.\n\nPer le altezze medie simulate di 10 adulti, un intervallo centrale al 50% che va da 65 a 67 pollici indica che met√† delle medie osservate si trova in questo intervallo.\n\n\n\nIntervallo centrale al 95%.\n\nContiene il 95% della distribuzione simulata, lasciando solo il 2.5% dei valori al di sotto e il 2.5% al di sopra dell‚Äôintervallo. Questo intervallo si calcola tra il 2.5¬∞ percentile e il 97.5¬∞ percentile.\nIndica una fascia pi√π ampia che cattura quasi tutti i valori plausibili, inclusi quelli meno probabili ma comunque possibili.\n\nPer le altezze medie simulate, un intervallo al 95% che va da 64 a 68 pollici significa che, in quasi tutte le simulazioni, l‚Äôaltezza media si trova in questo intervallo, con poche eccezioni.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>43</span>¬† <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/18_simulation.html#commenti-e-considerazioni-finali",
    "href": "chapters/probability/18_simulation.html#commenti-e-considerazioni-finali",
    "title": "43¬† Simulazioni",
    "section": "\n43.12 Commenti e Considerazioni Finali",
    "text": "43.12 Commenti e Considerazioni Finali\nLa simulazione di dati fittizi, al di l√† del semplice calcolo numerico, ci permette di comprendere in profondit√† come le propriet√† dei metodi statistici si manifestino in scenari pratici. Una delle ragioni principali per cui si ricorre alla simulazione √® la difficolt√† ‚Äì o l‚Äôimpossibilit√† ‚Äì di derivare in forma chiusa le distribuzioni campionarie per stimatori complessi. In questi casi, simulare il modello significa generare in successione variabili casuali e utilizzare il metodo Monte Carlo per approssimare aspettative, varianze e perfino l‚Äôintera distribuzione di funzioni complesse.\nSimulare significa, in sostanza, seguire la ‚Äústoria‚Äù di come i dati potrebbero essere stati generati, replicando le fasi di un modello stocastico ‚Äì dalla generazione delle variabili ‚Äúesogenee‚Äù (quelle indipendenti) a quelle che dipendono dalle precedenti. Questo approccio √® fondamentale non solo per ottenere stime, ma anche per controllare e validare i modelli: se i dati simulati non assomigliano a quelli reali, il modello probabilmente necessita di revisione.\nInoltre, la simulazione offre un potente strumento per eseguire analisi di sensibilit√†: possiamo variare le assunzioni del modello e osservare come cambiano le inferenze, aiutandoci a valutare la robustezza delle conclusioni tratte.\nInfine, la capacit√† di simulare distribuzioni complesse e approssimare le distribuzioni campionarie di stimatori o funzioni (come curve di regressione o istogrammi) rappresenta uno strumento essenziale soprattutto quando si lavora con dati reali che violano le semplificazioni delle teorie classiche.\nPer questo motivo, molti autori raccomandano di eseguire simulazioni preliminari prima di raccogliere i dati, per valutare aspetti come la dimensione campionaria necessaria o il potere statistico, e successivamente utilizzarle per il controllo e la validazione del modello.\nCome sintetizzato da Gelman & Brown (2024), le simulazioni non sono solo un supporto numerico, ma un vero e proprio strumento per comprendere e interpretare la complessit√† dei processi di generazione dei dati, elemento chiave in ambito psicologico e in numerose altre discipline.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>43</span>¬† <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/18_simulation.html#esercizi",
    "href": "chapters/probability/18_simulation.html#esercizi",
    "title": "43¬† Simulazioni",
    "section": "\n43.13 Esercizi",
    "text": "43.13 Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nImmagina il caso di 220 studenti che devono sostenere tre prove in itinere in un corso. Il voto finale √® la media dei voti ottenuti in queste tre prove. Le distribuzioni dei voti per le prove sono descritte come segue:\n\nPrima prova: I voti sono distribuiti secondo una gaussiana con media 24. Il 15% degli studenti ottiene un voto inferiore a 18.\nSeconda prova: I voti sono distribuiti secondo una gaussiana con media 25. Il 10% degli studenti ottiene un voto inferiore a 18.\nTerza prova: I voti sono distribuiti secondo una gaussiana con media 26. Solo il 5% degli studenti ottiene un voto inferiore a 18.\n\nDei 220 studenti iniziali:\n\nIl 10% non partecipa alla prima prova.\nUn ulteriore 5% non partecipa alla seconda prova.\n\nPer ottenere il voto finale, uno studente deve partecipare a tutte e tre le prove.\nUtilizzando una simulazione, trova la media finale dei voti e calcola l‚Äôintervallo di incertezza al 90% per la stima della media.\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\nIl codice R segente esegue una simulazione completa del problema ed √® strutturato nei seguenti passi:\n\nCalcola le deviazioni standard per le tre prove usando la funzione qnorm\nDetermina il numero di studenti che partecipano a tutte le prove\nSimula i voti per ogni prova per ogni studente secondo le distribuzioni normali specificate\nCalcola la media finale per ogni studente\nRipete la simulazione 1000 volte per ottenere un intervallo di confidenza robusto\nCalcola e visualizza i risultati con un istogramma\n\nIl codice calcola automaticamente:\n\nIl numero finale di studenti che partecipano a tutte e tre le prove\nLa media dei voti finali\nL‚Äôintervallo di confidenza al 90% per questa media\n\n\n# Impostazione del seme per la riproducibilit√†\nset.seed(123)\n\n# Numero iniziale di studenti\ninitial_students &lt;- 220\n\n# Calcolo delle deviazioni standard per le tre prove\nsd1 &lt;- (18 - 24) / qnorm(0.15)\nsd2 &lt;- (18 - 25) / qnorm(0.10)\nsd3 &lt;- (18 - 26) / qnorm(0.05)\n\n# Parametri delle distribuzioni\nmean1 &lt;- 24\nmean2 &lt;- 25\nmean3 &lt;- 26\n\n# Calcolo del numero di studenti che partecipano a tutte le prove\nstudents_after_first &lt;- initial_students * 0.9    # 10% non partecipa alla prima prova\nstudents_after_second &lt;- students_after_first * 0.95  # 5% non partecipa alla seconda prova\nfinal_students &lt;- round(students_after_second)   # Numero di studenti che partecipano a tutte le prove\n\n# Generiamo i voti per ogni prova per ogni studente\nset.seed(123)  # Per la riproducibilit√†\n\n# Simulazione dei voti per la prima prova\ngrades_first &lt;- rnorm(final_students, mean = mean1, sd = sd1)\n\n# Simulazione dei voti per la seconda prova\ngrades_second &lt;- rnorm(final_students, mean = mean2, sd = sd2)\n\n# Simulazione dei voti per la terza prova\ngrades_third &lt;- rnorm(final_students, mean = mean3, sd = sd3)\n\n# Calcolo della media finale per ogni studente\nfinal_grades &lt;- (grades_first + grades_second + grades_third) / 3\n\n# Calcolo della media complessiva\nmean_final &lt;- mean(final_grades)\n\n# Ripetiamo la simulazione pi√π volte per ottenere un intervallo di confidenza\nn_simulations &lt;- 1000\nmeans &lt;- numeric(n_simulations)\n\nfor (i in 1:n_simulations) {\n  # Simulazione dei voti per tutte e tre le prove\n  sim_grades_first &lt;- rnorm(final_students, mean = mean1, sd = sd1)\n  sim_grades_second &lt;- rnorm(final_students, mean = mean2, sd = sd2)\n  sim_grades_third &lt;- rnorm(final_students, mean = mean3, sd = sd3)\n  \n  # Calcolo della media finale per questa simulazione\n  sim_final_grades &lt;- (sim_grades_first + sim_grades_second + sim_grades_third) / 3\n  means[i] &lt;- mean(sim_final_grades)\n}\n\n# Calcolo dell'intervallo di confidenza al 90%\nconfidence_interval &lt;- quantile(means, c(0.05, 0.95))\n\n# Risultati\nprint(paste(\"Numero di studenti che partecipano a tutte le prove:\", final_students))\n#&gt; [1] \"Numero di studenti che partecipano a tutte le prove: 188\"\nprint(paste(\"Deviazione standard per la prima prova:\", round(sd1, 4)))\n#&gt; [1] \"Deviazione standard per la prima prova: 5.7891\"\nprint(paste(\"Deviazione standard per la seconda prova:\", round(sd2, 4)))\n#&gt; [1] \"Deviazione standard per la seconda prova: 5.4621\"\nprint(paste(\"Deviazione standard per la terza prova:\", round(sd3, 4)))\n#&gt; [1] \"Deviazione standard per la terza prova: 4.8637\"\nprint(paste(\"Media finale dei voti:\", round(mean_final, 4)))\n#&gt; [1] \"Media finale dei voti: 25.1772\"\nprint(paste(\"Intervallo di confidenza al 90%:\", \n            round(confidence_interval[1], 4), \"-\", \n            round(confidence_interval[2], 4)))\n#&gt; [1] \"Intervallo di confidenza al 90%: 24.6456 - 25.3693\"\n\n# Visualizzazione dei risultati\nhist(means, main = \"Distribuzione delle medie finali\", \n     xlab = \"Media finale\", col = \"lightblue\", border = \"white\")\nabline(v = confidence_interval, col = \"red\", lwd = 2, lty = 2)\nabline(v = mean_final, col = \"blue\", lwd = 2)\nlegend(\"topright\", legend = c(\"Media stimata\", \"Intervallo di confidenza 90%\"), \n       col = c(\"blue\", \"red\"), lwd = 2, lty = c(1, 2))",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>43</span>¬† <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/18_simulation.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/18_simulation.html#informazioni-sullambiente-di-sviluppo",
    "title": "43¬† Simulazioni",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.5.3     \n#&gt;  [9] scales_1.3.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.9.1   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         rlang_1.1.5       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       tools_4.4.2       parallel_4.4.2    tzdb_0.5.0       \n#&gt; [21] colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5       R6_2.6.1         \n#&gt; [25] lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.1    \n#&gt; [29] gtable_0.3.6      glue_1.8.0        xfun_0.51         tidyselect_1.2.1 \n#&gt; [33] rstudioapi_0.17.1 farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-167     \n#&gt; [37] labeling_0.4.3    rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>43</span>¬† <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/18_simulation.html#bibliografia",
    "href": "chapters/probability/18_simulation.html#bibliografia",
    "title": "43¬† Simulazioni",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., & Brown, N. J. (2024). How statistical challenges and misreadings of the literature combine to produce unreplicable science: An example from psychology.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other stories. Cambridge University Press.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>43</span>¬† <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/introduction_bayes_inference.html",
    "href": "chapters/bayesian_inference/introduction_bayes_inference.html",
    "title": "Introduzione",
    "section": "",
    "text": "Bibliografia\nIn questa sezione della dispensa, esamineremo l‚Äôinferenza bayesiana applicata a modelli statistici in cui si stima un unico parametro scalare, ovvero quando l‚Äôestimando \\(\\theta\\) √® unidimensionale.\nIn particolare, considereremo quattro modelli fondamentali e ampiamente utilizzati: il modello binomiale, il modello normale, il modello di Poisson e il modello esponenziale. Approfondiremo il processo di aggiornamento bayesiano analizzando due approcci principali per derivare la distribuzione a posteriori: l‚Äôapprossimazione numerica tramite il metodo a griglia e l‚Äôimpiego delle distribuzioni coniugate, in cui una specifica combinazione tra distribuzione a priori e verosimiglianza consente di ottenere la distribuzione a posteriori in forma analitica. Inoltre, esploreremo l‚Äôinfluenza della scelta della distribuzione a priori sulla distribuzione a posteriori e discuteremo le tecniche per sintetizzarla e interpretarla in modo efficace.\nUn aspetto cruciale dell‚Äôinferenza bayesiana, particolarmente rilevante nel contesto della crisi della replicabilit√† in psicologia, √® la possibilit√† di formulare inferenze sulla distribuzione a posteriori dei parametri di interesse teorico senza dover ricorrere a decisioni binarie come ‚Äúsignificativo‚Äù o ‚Äúnon significativo‚Äù. Questo approccio promuove una modalit√† di analisi pi√π sfumata e rigorosa, con l‚Äôobiettivo di stabilire un nuovo standard per la presentazione e l‚Äôinterpretazione dei risultati, favorendo affermazioni pi√π ponderate nelle ricerche empiriche (Gelman et al., 1995; McElreath, 2020).",
    "crumbs": [
      "Inferenza",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/introduction_bayes_inference.html#bibliografia",
    "href": "chapters/bayesian_inference/introduction_bayes_inference.html#bibliografia",
    "title": "Introduzione",
    "section": "",
    "text": "Gelman, A., Carlin, J. B., Stern, H. S., & Rubin, D. B. (1995). Bayesian data analysis. Chapman; Hall/CRC.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.",
    "crumbs": [
      "Inferenza",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_uncertainty.html",
    "href": "chapters/bayesian_inference/01_uncertainty.html",
    "title": "44¬† Abbracciare l‚Äôincertezza",
    "section": "",
    "text": "44.1 Introduzione\nL‚Äôespressione ‚Äúabbracciare l‚Äôincertezza‚Äù √® una delle pi√π rappresentative nel contesto della statistica bayesiana. In questo capitolo, esploreremo il significato di questa affermazione, basandoci sulla trattazione introduttiva proposta nel primo capitolo di Understanding Uncertainty di Lindley (Lindley, 2013).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>¬† <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_uncertainty.html#lincertezza-nella-ricerca-psicologica",
    "href": "chapters/bayesian_inference/01_uncertainty.html#lincertezza-nella-ricerca-psicologica",
    "title": "44¬† Abbracciare l‚Äôincertezza",
    "section": "44.2 L‚Äôincertezza nella ricerca psicologica",
    "text": "44.2 L‚Äôincertezza nella ricerca psicologica\nL‚Äôincertezza √® un elemento centrale non solo nella statistica, ma in tutte le discipline scientifiche, con un‚Äôimportanza particolare in psicologia, dove si studiano fenomeni complessi e difficili da misurare. Nell‚Äôindagare processi cognitivi, emozioni e comportamenti, i ricercatori si trovano spesso ad affrontare dati intricati, ambigui e suscettibili di molteplici interpretazioni. Sebbene alcune affermazioni possano essere sostenute con elevata confidenza o confutate con certezza, la maggior parte delle ipotesi scientifiche si colloca in un‚Äôarea grigia dominata dall‚Äôincertezza.\nL‚Äôobiettivo di questo corso √® guidare gli studenti nella comprensione e nella gestione dell‚Äôincertezza nella ricerca psicologica, adottando l‚Äôapproccio bayesiano all‚Äôanalisi dei dati. Questo metodo, basato sulla quantificazione e sull‚Äôaggiornamento delle credenze alla luce di nuove evidenze, fornir√† agli studenti gli strumenti per affrontare l‚Äôincertezza in modo rigoroso e sistematico, sia nella carriera accademica sia nella pratica clinica.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>¬† <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_uncertainty.html#la-natura-soggettiva-dellincertezza",
    "href": "chapters/bayesian_inference/01_uncertainty.html#la-natura-soggettiva-dellincertezza",
    "title": "44¬† Abbracciare l‚Äôincertezza",
    "section": "44.3 La natura soggettiva dell‚Äôincertezza",
    "text": "44.3 La natura soggettiva dell‚Äôincertezza\nUn aspetto cruciale dell‚Äôincertezza, spesso trascurato, √® la sua dimensione soggettiva. De Finetti (Finetti, 1970) ha sottolineato come l‚Äôincertezza sia, almeno in parte, una questione personale: ci√≤ che √® incerto per uno psicologo potrebbe non esserlo per un altro, in funzione delle loro esperienze, conoscenze pregresse e interpretazioni dei dati disponibili. Anche di fronte alla stessa questione, due ricercatori possono condividere un‚Äôincertezza comune, ma con gradi di intensit√† diversi.\nQuesta componente soggettiva √® particolarmente rilevante in psicologia, dove le differenze individuali e culturali influenzano la percezione e l‚Äôinterpretazione dei fenomeni. L‚Äôapproccio bayesiano offre un potente strumento per affrontare questa soggettivit√†, consentendo di quantificare le differenze tra credenze individuali e di aggiornarle in modo coerente sulla base di nuove evidenze oggettive.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>¬† <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_uncertainty.html#lonnipresenza-dellincertezza",
    "href": "chapters/bayesian_inference/01_uncertainty.html#lonnipresenza-dellincertezza",
    "title": "44¬† Abbracciare l‚Äôincertezza",
    "section": "44.4 L‚Äôonnipresenza dell‚Äôincertezza",
    "text": "44.4 L‚Äôonnipresenza dell‚Äôincertezza\nL‚Äôincertezza permea ogni aspetto della ricerca psicologica. Ogni esperimento, misurazione o interpretazione dei dati comporta un margine di incertezza. Questa condizione √® particolarmente evidente nello studio di fenomeni complessi come il comportamento umano o i processi mentali, dove innumerevoli variabili interagiscono, molte delle quali difficili da misurare o controllare con precisione.\nTuttavia, l‚Äôincertezza non deve essere vista come un ostacolo insormontabile. Al contrario, riconoscerla e quantificarla pu√≤ favorire una comprensione pi√π profonda e realistica dei fenomeni psicologici. Attraverso l‚Äôapproccio bayesiano, diventa possibile integrare l‚Äôincertezza nel processo di indagine scientifica, trattandola non come un limite, ma come una risorsa (Koetke et al., 2024).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>¬† <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_uncertainty.html#superare-la-soppressione-dellincertezza",
    "href": "chapters/bayesian_inference/01_uncertainty.html#superare-la-soppressione-dellincertezza",
    "title": "44¬† Abbracciare l‚Äôincertezza",
    "section": "44.5 Superare la soppressione dell‚Äôincertezza",
    "text": "44.5 Superare la soppressione dell‚Äôincertezza\nNonostante la sua onnipresenza, l‚Äôincertezza √® spesso ignorata o minimizzata nella comunicazione scientifica. Questo pu√≤ avvenire attraverso interpretazioni eccessivamente ottimistiche dei risultati, la presentazione di conclusioni come fatti certi, o una riluttanza a riconoscere i limiti degli studi condotti. Tale atteggiamento, sebbene comprensibile, pu√≤ condurre a conclusioni errate e a una visione distorta della realt√†.\nL‚Äôapproccio bayesiano permette di affrontare l‚Äôincertezza in modo esplicito e costruttivo. Fornendo un quadro rigoroso per quantificarla, analizzarla e comunicarla chiaramente, migliora la trasparenza della ricerca e promuove conclusioni pi√π oneste e accurate.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>¬† <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_uncertainty.html#i-benefici-dellincertezza",
    "href": "chapters/bayesian_inference/01_uncertainty.html#i-benefici-dellincertezza",
    "title": "44¬† Abbracciare l‚Äôincertezza",
    "section": "44.6 I benefici dell‚Äôincertezza",
    "text": "44.6 I benefici dell‚Äôincertezza\nContrariamente a quanto si possa pensare, l‚Äôincertezza offre numerosi vantaggi per la ricerca psicologica:\n\nStimola l‚Äôesplorazione scientifica: La consapevolezza dell‚Äôincertezza incoraggia i ricercatori a formulare nuove ipotesi e a migliorare i metodi di studio.\nPromuove l‚Äôonest√† intellettuale: Accettare l‚Äôincertezza rende i ricercatori pi√π cauti e aperti a prospettive alternative.\nMigliora la qualit√† delle analisi: Integrare l‚Äôincertezza porta a disegni sperimentali pi√π robusti e interpretazioni pi√π accurate.\nFacilita la collaborazione interdisciplinare: Riconoscere i limiti delle proprie conoscenze stimola la ricerca di input da altri esperti.\nRiflette la complessit√† dei fenomeni psicologici: L‚Äôincertezza √® intrinseca ai processi mentali e riconoscerla consente di rappresentarli in modo pi√π realistico.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>¬† <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_uncertainty.html#tipi-di-incertezza",
    "href": "chapters/bayesian_inference/01_uncertainty.html#tipi-di-incertezza",
    "title": "44¬† Abbracciare l‚Äôincertezza",
    "section": "44.7 Tipi di incertezza",
    "text": "44.7 Tipi di incertezza\nL‚Äôincertezza nella ricerca pu√≤ essere classificata in tre categorie principali, in base alla sua origine: aleatoria, epistemica e ontologica (Gansch & Adee, 2020).\n\n44.7.1 Incertezza Aleatoria\nL‚Äôincertezza aleatoria √® intrinseca alla natura casuale di un processo e non pu√≤ essere eliminata per un dato modello probabilistico. Essa √® considerata irreducibile e viene quantificata tramite distribuzioni probabilistiche. Ad esempio, nella misurazione della risposta di un individuo a uno stimolo, la variabilit√† intrinseca nel comportamento umano, dovuta a fattori imprevedibili, rappresenta un caso di incertezza aleatoria. Questo tipo di incertezza √® una caratteristica fondamentale di molti fenomeni psicologici e biologici.\n\n\n44.7.2 Incertezza Epistemica\nL‚Äôincertezza epistemica deriva dalla conoscenza limitata o incompleta di un fenomeno. Essa rappresenta il ‚Äúnoto-ignoto‚Äù, cio√® ci√≤ che sappiamo di non sapere, ed √® legata alle semplificazioni insite in ogni modello scientifico. Ad esempio, un modello psicologico che non consideri le influenze culturali o ambientali potrebbe risultare incompleto, introducendo incertezza epistemica. Diversamente dall‚Äôincertezza aleatoria, l‚Äôincertezza epistemica pu√≤ essere ridotta attraverso il miglioramento dei modelli, l‚Äôinclusione di variabili rilevanti o la raccolta di ulteriori dati.\n\n\n44.7.3 Incertezza Ontologica\nL‚Äôincertezza ontologica riguarda l‚Äô‚Äúignoto-ignoto‚Äù, ovvero aspetti di un sistema che non sono ancora stati identificati. In psicologia, questo potrebbe riferirsi a variabili o processi non ancora scoperti che influenzano un comportamento. Ad esempio, studiando i disturbi mentali, potrebbero emergere nuovi fattori di rischio precedentemente sconosciuti.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>¬† <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_uncertainty.html#il-calcolo-dellincertezza-nellapproccio-bayesiano",
    "href": "chapters/bayesian_inference/01_uncertainty.html#il-calcolo-dellincertezza-nellapproccio-bayesiano",
    "title": "44¬† Abbracciare l‚Äôincertezza",
    "section": "44.8 Il calcolo dell‚Äôincertezza nell‚Äôapproccio bayesiano",
    "text": "44.8 Il calcolo dell‚Äôincertezza nell‚Äôapproccio bayesiano\nL‚Äôinsegnamento si propone di fornire agli studenti strumenti per affrontare e quantificare l‚Äôincertezza attraverso l‚Äôapproccio bayesiano (Gelman et al., 1995). Fondato sul teorema di Bayes, questo metodo rappresenta un quadro teorico rigoroso e sistematico per aggiornare le credenze alla luce di nuove evidenze, configurandosi come una componente centrale della metodologia scientifica.\nIl processo si basa su quattro passaggi essenziali. In primo luogo, si parte dalla quantificazione delle credenze iniziali, note come prior, che rappresentano le conoscenze pregresse o le ipotesi relative a un determinato fenomeno psicologico. Successivamente, si analizza la forza delle evidenze empiriche fornite dai dati raccolti, formalizzata nella likelihood. Queste due informazioni vengono combinate per generare le credenze aggiornate, chiamate posterior, che sintetizzano la conoscenza disponibile integrando i dati empirici e le ipotesi iniziali. Infine, le credenze aggiornate possono essere utilizzate per prendere decisioni pi√π informate, pianificare ricerche future e orientare interventi.\n\n44.8.1 Il ruolo delle credenze e delle decisioni nella ricerca psicologica\nLe credenze rivestono un ruolo fondamentale nella ricerca psicologica, influenzando tutte le fasi del processo scientifico, dalla progettazione degli esperimenti all‚Äôinterpretazione dei risultati, fino alla scelta di interventi clinici. L‚Äôapproccio bayesiano si distingue per la sua capacit√† di esplicitare e formalizzare queste credenze, consentendo di aggiornare il loro contenuto in modo coerente e trasparente man mano che emergono nuove evidenze.\nQuesto metodo permette non solo di ottimizzare le decisioni basandosi su informazioni aggiornate, ma anche di comunicare chiaramente l‚Äôincertezza associata alle conclusioni, evidenziandone i limiti e garantendo maggiore trasparenza scientifica. Affrontare l‚Äôincertezza come una componente intrinseca della ricerca non solo migliora la qualit√† dell‚Äôanalisi, ma consente anche di promuovere un approccio pi√π realistico e rigoroso nello studio dei fenomeni psicologici.\nIn sintesi, l‚Äôapproccio bayesiano offre un modello operativo per integrare l‚Äôincertezza nel processo decisionale, trattandola non come un ostacolo, ma come un elemento essenziale per una comprensione pi√π sfumata e accurata della realt√†.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>¬† <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_uncertainty.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/01_uncertainty.html#riflessioni-conclusive",
    "title": "44¬† Abbracciare l‚Äôincertezza",
    "section": "44.9 Riflessioni Conclusive",
    "text": "44.9 Riflessioni Conclusive\nQuesto insegnamento fornisce gli strumenti per applicare l‚Äôanalisi bayesiana nell‚Äôambito dei dati psicologici, insegnando a considerare l‚Äôincertezza come una parte integrante e preziosa del processo scientifico. Attraverso questo approccio, gli studenti potranno acquisire una comprensione pi√π raffinata e strutturata dei fenomeni psicologici, integrando l‚Äôincertezza come elemento fondamentale per interpretare i dati e formulare inferenze rigorose.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>¬† <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_uncertainty.html#esercizi",
    "href": "chapters/bayesian_inference/01_uncertainty.html#esercizi",
    "title": "44¬† Abbracciare l‚Äôincertezza",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n\nChe cosa significa ‚Äúabbracciare l‚Äôincertezza‚Äù nel contesto della statistica bayesiana e perch√© √® particolarmente rilevante nella ricerca psicologica?\nQuali sono le tre principali categorie di incertezza nella ricerca psicologica e come si differenziano tra loro?\nIn che modo l‚Äôapproccio bayesiano consente di affrontare l‚Äôincertezza in modo sistematico e rigoroso?\nQual √® il ruolo della soggettivit√† nell‚Äôincertezza secondo l‚Äôapproccio bayesiano, e perch√© questo √® particolarmente rilevante in psicologia?\nQuali sono alcuni dei principali vantaggi dell‚Äôincertezza nella ricerca psicologica e come pu√≤ essere utilizzata per migliorare la qualit√† della scienza?\n\nConsegna: Rispondi con parole tue e carica il file .qmd, convertito in PDF su Moodle.\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n\nAbbracciare l‚Äôincertezza nella statistica bayesiana significa riconoscerla come una parte inevitabile della ricerca e trattarla in modo esplicito e formale, anzich√© ignorarla o minimizzarla. Nella ricerca psicologica, l‚Äôincertezza √® centrale perch√© si studiano fenomeni complessi e difficili da misurare, come emozioni e processi cognitivi. L‚Äôapproccio bayesiano consente di quantificare e aggiornare l‚Äôincertezza in modo sistematico, offrendo un metodo pi√π realistico per interpretare i dati e formulare inferenze.\nLe tre principali categorie di incertezza sono:\n\nIncertezza aleatoria: √® intrinseca alla natura casuale di un fenomeno e non pu√≤ essere eliminata (es. variabilit√† nelle risposte di un individuo a uno stesso stimolo).\n\nIncertezza epistemica: deriva da una conoscenza incompleta del fenomeno studiato e pu√≤ essere ridotta con migliori modelli e raccolta di dati (es. omissione di variabili importanti in un modello psicologico).\n\nIncertezza ontologica: si riferisce a variabili o aspetti del sistema ancora sconosciuti (es. fattori di rischio per disturbi mentali non ancora identificati).\n\nL‚Äôapproccio bayesiano affronta l‚Äôincertezza attraverso quattro fasi fondamentali: (1) definizione delle credenze iniziali (prior), (2) valutazione delle nuove evidenze (likelihood), (3) aggiornamento delle credenze (posterior), e (4) utilizzo delle credenze aggiornate per prendere decisioni pi√π informate. Questo processo consente di integrare sistematicamente nuove informazioni e di migliorare continuamente la comprensione di un fenomeno.\nSecondo De Finetti, l‚Äôincertezza ha una componente soggettiva, poich√© le credenze degli individui influenzano il modo in cui interpretano i dati. Due ricercatori con esperienze diverse possono avere livelli di incertezza differenti riguardo allo stesso fenomeno. In psicologia, questa soggettivit√† √® particolarmente rilevante perch√© le percezioni e le interpretazioni dei fenomeni sono spesso influenzate da differenze individuali e culturali. L‚Äôapproccio bayesiano permette di quantificare e aggiornare queste credenze in modo formale e trasparente.\nL‚Äôincertezza offre diversi vantaggi nella ricerca psicologica:\n\nStimola l‚Äôesplorazione scientifica, incoraggiando nuove ipotesi e metodi.\n\nPromuove l‚Äôonest√† intellettuale, rendendo i ricercatori pi√π cauti e aperti a spiegazioni alternative.\n\nMigliora la qualit√† delle analisi, portando a modelli pi√π robusti e interpretazioni pi√π accurate.\n\nFacilita la collaborazione interdisciplinare, spingendo a integrare competenze diverse.\nRiflette meglio la complessit√† della psicologia, permettendo una rappresentazione pi√π realistica dei fenomeni studiati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>¬† <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_uncertainty.html#bibliografia",
    "href": "chapters/bayesian_inference/01_uncertainty.html#bibliografia",
    "title": "44¬† Abbracciare l‚Äôincertezza",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nFinetti, B. de. (1970). Teoria delle probabilit√†: sintesi introduttiva con appendice critica. Einaudi.\n\n\nGansch, R., & Adee, A. (2020). System theoretic view on uncertainties. 2020 Design, Automation & Test in Europe Conference & Exhibition (DATE), 1345‚Äì1350.\n\n\nGelman, A., Carlin, J. B., Stern, H. S., & Rubin, D. B. (1995). Bayesian data analysis. Chapman; Hall/CRC.\n\n\nKoetke, J., Schumann, K., Bowes, S. M., & Vaupotiƒç, N. (2024). The effect of seeing scientists as intellectually humble on trust in scientists and their research. Nature Human Behaviour, 1‚Äì14.\n\n\nLindley, D. V. (2013). Understanding uncertainty. John Wiley & Sons.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>¬† <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_intro_bayes.html",
    "href": "chapters/bayesian_inference/02_intro_bayes.html",
    "title": "45¬† La quantificazione dell‚Äôincertezza",
    "section": "",
    "text": "45.1 Introduzione\nL‚Äôapproccio bayesiano non si limita all‚Äôapplicazione del Teorema di Bayes, ma si distingue per una gestione esplicita dell‚Äôincertezza (si veda il Capitolo 44) e per l‚Äôuso delle distribuzioni di probabilit√† per rappresentare stime e soluzioni. Il processo di modellazione bayesiana, noto come workflow bayesiano (Baribault & Collins, 2023), comprende pi√π fasi iterative: dalla costruzione del modello, all‚Äôapplicazione del Teorema di Bayes, fino all‚Äôanalisi critica dei risultati. Questo approccio permette un continuo affinamento delle stime, adattandole alle nuove evidenze.\nL‚Äôobiettivo dell‚Äôapproccio bayesiano non √® scoprire una ‚Äúverit√† assoluta‚Äù, ma aggiornare razionalmente le credenze riguardo a un‚Äôipotesi integrando nuove informazioni. In psicologia, dove le misurazioni sono soggette a incertezza e i fenomeni complessi, questa capacit√† √® cruciale.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>¬† <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_intro_bayes.html#introduzione",
    "href": "chapters/bayesian_inference/02_intro_bayes.html#introduzione",
    "title": "45¬† La quantificazione dell‚Äôincertezza",
    "section": "",
    "text": "‚ÄúQuindi non avete una sola risposta alle vostre domande?‚Äù\n‚ÄúAdson, se l‚Äôavessi insegnerei teologia a Parigi.‚Äù\n‚ÄúA Parigi hanno sempre la risposta vera?‚Äù\n‚ÄúMai,‚Äù disse Guglielmo, ‚Äúma sono molto sicuri dei loro errori.‚Äù\n‚Äî Umberto Eco (Il Nome della Rosa)",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>¬† <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_intro_bayes.html#il-valore-dellincertezza",
    "href": "chapters/bayesian_inference/02_intro_bayes.html#il-valore-dellincertezza",
    "title": "45¬† La quantificazione dell‚Äôincertezza",
    "section": "\n45.2 Il Valore dell‚ÄôIncertezza",
    "text": "45.2 Il Valore dell‚ÄôIncertezza\nIn psicologia e nelle scienze sociali, l‚Äôincertezza √® una componente fondamentale: spesso lavoriamo con informazioni incomplete o imperfette e con variabili latenti che non possono essere osservate direttamente, come l‚Äôansia, la motivazione o l‚Äôautostima. La probabilit√† offre un linguaggio matematico per rappresentare questa incertezza in modo rigoroso e sistematico.\nIn particolare, la probabilit√† consente di esprimere il grado di fiducia o di conoscenza che abbiamo riguardo a un evento o a un parametro. L‚Äôinferenza bayesiana integra la probabilit√† come strumento per gestire l‚Äôincertezza, rappresentandola sotto forma di distribuzioni probabilistiche che possono essere aggiornate man mano che emergono nuove informazioni (Jaynes, 2003).\nA differenza dei modelli deterministici, che assumono la possibilit√† di prevedere i risultati con certezza, i modelli probabilistici ‚Äì e in particolare quelli bayesiani ‚Äì abbracciano l‚Äôincertezza come parte integrante della comprensione dei fenomeni. Questo approccio si rivela particolarmente potente in psicologia, dove l‚Äôincertezza √® intrinseca e i dati spesso offrono una visione parziale della realt√†.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>¬† <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_intro_bayes.html#interpretazione-frequentista-vs.-bayesiana-dellincertezza",
    "href": "chapters/bayesian_inference/02_intro_bayes.html#interpretazione-frequentista-vs.-bayesiana-dellincertezza",
    "title": "45¬† La quantificazione dell‚Äôincertezza",
    "section": "\n45.3 Interpretazione Frequentista vs.¬†Bayesiana dell‚ÄôIncertezza",
    "text": "45.3 Interpretazione Frequentista vs.¬†Bayesiana dell‚ÄôIncertezza\n\n45.3.1 Interpretazione Frequentista\nL‚Äôapproccio frequentista definisce la probabilit√† come la frequenza relativa con cui un evento si verifica nel lungo periodo, in un gran numero di prove simili. Per esempio, se si vuole stimare la probabilit√† che un individuo superi una certa soglia di ansia, si osserverebbe un ampio numero di individui simili e si calcolerebbe la proporzione di successi (\\(E\\)) rispetto al totale delle prove (\\(N\\)):\n\\[\n\\text{Pr}(E) = \\lim_{N \\to \\infty} \\frac{\\text{numero di volte in cui } E \\text{ si verifica}}{N}.\n\\]\nNel frequentismo, l‚Äôincertezza non √® rappresentata direttamente, ma emerge dall‚Äôimpossibilit√† pratica di osservare un numero infinito di eventi in condizioni identiche. Questo approccio presenta due limiti principali:\n\n\nOsservazioni infinite: Non √® realistico osservare un evento infinite volte.\n\nDefinizione del gruppo di riferimento: √à spesso difficile identificare con precisione le condizioni rilevanti che caratterizzano il fenomeno (la reference class).\n\nQuesti limiti rendono l‚Äôapproccio frequentista meno applicabile in psicologia, dove le condizioni sperimentali sono spesso uniche e non ripetibili.\n\n45.3.2 Interpretazione Bayesiana\nL‚Äôapproccio bayesiano interpreta la probabilit√† come una misura soggettiva del grado di fiducia in un evento, un‚Äôipotesi o un parametro. La probabilit√† riflette quindi la nostra incertezza riguardo a un fenomeno, tenendo conto sia delle conoscenze precedenti (priori) sia delle nuove evidenze (dati). Questo legame diretto tra probabilit√† e incertezza consente di aggiornare le credenze man mano che emergono nuove informazioni.\nIl teorema di Bayes formalizza questo processo:\n\\[\np(\\theta \\mid D) = \\frac{p(D \\mid \\theta) \\cdot p(\\theta)}{p(D)},\n\\]\ndove:\n\n\n\\(p(\\theta \\mid D)\\): probabilit√† a posteriori di \\(\\theta\\), aggiornata in base ai dati \\(D\\),\n\n\\(p(\\theta)\\): probabilit√† a priori di \\(\\theta\\),\n\n\\(p(D \\mid \\theta)\\): verosimiglianza dei dati dato \\(\\theta\\),\n\n\\(p(D)\\): probabilit√† totale dei dati.\n\nL‚Äôapproccio bayesiano rappresenta esplicitamente l‚Äôincertezza attraverso distribuzioni probabilistiche. Ogni stima incorpora la variabilit√† intrinseca dei dati e il grado di fiducia associato.\n\n\n\n\n\n\n\nCaratteristica\nFrequentismo\nBayesiano\n\n\n\nProbabilit√†\nFrequenza relativa nel lungo periodo\nGrado di credenza soggettiva\n\n\nIncertezza\nNon rappresentata esplicitamente\nModello centrale delle distribuzioni\n\n\nAggiornamento\nNon dinamico\nContinuo, basato sul Teorema di Bayes\n\n\nApplicabilit√† in Psicologia\nLimitata: richiede condizioni ripetibili\nFlessibile: integra dati e conoscenze\n\n\n\nIn conclusione, l‚Äôinferenza bayesiana offre un collegamento diretto tra incertezza e probabilit√†, rappresentando quest‚Äôultima come una misura della conoscenza attuale su un fenomeno. Questa flessibilit√† rende l‚Äôapproccio particolarmente potente per affrontare i problemi complessi della psicologia, dove variabili latenti e incertezza sono elementi centrali. Integrando dati empirici e conoscenze pregresse, l‚Äôinferenza bayesiana non solo migliora la precisione delle stime, ma fornisce anche un quadro intuitivo e rigoroso per la comprensione e la modellazione dell‚Äôincertezza.\n\nEsempio 45.1 Quando si misura l‚Äôansia tramite questionari, l‚Äôincertezza pu√≤ derivare da:\n\n\nSoggettivit√† delle risposte: L‚Äôinterpretazione delle domande varia tra individui.\n\nIncompletezza delle misure: Il questionario pu√≤ non cogliere tutte le sfumature dell‚Äôansia.\n\nRumore nei dati: Errori minori possono influenzare i risultati.\n\nL‚Äôinferenza bayesiana consente di rappresentare queste fonti di incertezza con una distribuzione a priori basata su studi precedenti. Man mano che si raccolgono nuovi dati, la distribuzione a posteriori fornisce stime aggiornate e pi√π affidabili.\n\n\nEsempio 45.2 In uno studio sull‚Äôeffetto del rinforzo negativo sulla motivazione, la ‚Äúmotivazione interna‚Äù √® una variabile latente non osservabile direttamente. Possiamo inferirla attraverso:\n\n\nMisure indirette: Tempo speso sul compito, velocit√† di risposta.\n\nModelli bayesiani: Collegano queste variabili osservabili alla motivazione latente, rappresentando l‚Äôincertezza individuale e il contributo del rinforzo.\n\nAd esempio, se un modello bayesiano stima che un individuo ha l‚Äô80% di probabilit√† di rispondere positivamente al rinforzo negativo, questa probabilit√† pu√≤ essere aggiornata con nuovi dati sperimentali, affinando la comprensione del fenomeno.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>¬† <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_intro_bayes.html#inferenza-bayesiana-e-incertezza-nelle-stime",
    "href": "chapters/bayesian_inference/02_intro_bayes.html#inferenza-bayesiana-e-incertezza-nelle-stime",
    "title": "45¬† La quantificazione dell‚Äôincertezza",
    "section": "\n45.4 Inferenza Bayesiana e Incertezza nelle Stime",
    "text": "45.4 Inferenza Bayesiana e Incertezza nelle Stime\nL‚Äôinferenza bayesiana utilizza le probabilit√† per aggiornare le credenze sui parametri di un modello basandosi sui dati osservati. Queste credenze sono rappresentate da distribuzioni di probabilit√†, e l‚Äôampiezza di queste distribuzioni riflette l‚Äôincertezza associata alle stime. In psicologia, dove spesso si lavora con campioni limitati e misurazioni indirette di variabili latenti, questa gestione dell‚Äôincertezza √® fondamentale per interpretare i risultati in modo robusto e realistico.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>¬† <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_intro_bayes.html#il-modello-bayesiano",
    "href": "chapters/bayesian_inference/02_intro_bayes.html#il-modello-bayesiano",
    "title": "45¬† La quantificazione dell‚Äôincertezza",
    "section": "\n45.5 Il Modello Bayesiano",
    "text": "45.5 Il Modello Bayesiano\nUn modello statistico combina una distribuzione probabilistica con ipotesi sui parametri per descrivere un fenomeno osservato. Ad esempio, possiamo modellare il lancio di una moneta equa con un modello binomiale, in cui la probabilit√† \\(\\theta\\) √® fissata a 0.5, oppure modellare l‚Äôaltezza degli uomini italiani con un modello normale, in cui \\(\\mu\\) √® 183 cm e \\(\\sigma\\) √® 5 cm. In termini bayesiani, il modello statistico include tre componenti principali:\n\nDistribuzione a Priori (Prior): Rappresenta le credenze iniziali sui valori dei parametri del modello, informate da ricerche precedenti o da assunzioni neutre.\nVerosimiglianza (Likelihood): Descrive la probabilit√† di osservare i dati dati i parametri del modello, riflettendo il processo che genera i dati.\nDistribuzione a Posteriori (Posterior): √à la distribuzione aggiornata dei parametri dopo aver osservato i dati, ottenuta combinando la prior e la verosimiglianza mediante il teorema di Bayes. La posterior rappresenta la conoscenza aggiornata dopo aver integrato le informazioni fornite dai dati.\n\nLa modellazione bayesiana descrive il processo generativo che ha prodotto i dati osservati, incorporando l‚Äôincertezza nei parametri e aggiornando continuamente le stime man mano che emergono nuovi dati. Questo approccio √® particolarmente utile in contesti come la psicologia, dove i fenomeni complessi e le variabili latenti rendono necessario modellare l‚Äôincertezza in modo esplicito.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>¬† <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_intro_bayes.html#componenti-chiave-della-modellazione-probabilistica",
    "href": "chapters/bayesian_inference/02_intro_bayes.html#componenti-chiave-della-modellazione-probabilistica",
    "title": "45¬† La quantificazione dell‚Äôincertezza",
    "section": "\n45.6 Componenti Chiave della Modellazione Probabilistica",
    "text": "45.6 Componenti Chiave della Modellazione Probabilistica\n\nVariabili Aleatorie: Quantit√† incerte che assumono diversi valori secondo una distribuzione di probabilit√†. Ad esempio, il livello di depressione di un paziente pu√≤ essere trattato come una variabile aleatoria.\nDistribuzioni di Probabilit√†: Descrivono come i valori di una variabile aleatoria sono distribuiti. Ad esempio, una distribuzione normale pu√≤ essere utilizzata per modellare la variabilit√† dell‚Äôansia in una popolazione.\nInferenza Bayesiana: Aggiorna la distribuzione di probabilit√† delle variabili di interesse sulla base dei nuovi dati, migliorando progressivamente le stime.\n\n\nEsempio 45.3 In uno studio clinico sulla depressione, possiamo utilizzare l‚Äôinferenza bayesiana per stimare il livello di depressione di un paziente partendo da una distribuzione a priori informata da studi precedenti. Ogni nuovo dato raccolto (come punteggi a questionari o osservazioni) permette di aggiornare questa stima, affinando progressivamente la comprensione del fenomeno.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>¬† <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_intro_bayes.html#il-potere-dellaggiornamento-bayesiano",
    "href": "chapters/bayesian_inference/02_intro_bayes.html#il-potere-dellaggiornamento-bayesiano",
    "title": "45¬† La quantificazione dell‚Äôincertezza",
    "section": "\n45.7 Il Potere dell‚ÄôAggiornamento Bayesiano",
    "text": "45.7 Il Potere dell‚ÄôAggiornamento Bayesiano\nIl vero punto di forza della modellazione bayesiana risiede nella sua capacit√† di aggiornare continuamente le credenze sui parametri del modello man mano che si raccolgono nuovi dati. Questo processo iterativo, basato sul teorema di Bayes, consente di integrare sia le credenze iniziali (a priori) sia le evidenze empiriche (verosimiglianza) per ottenere stime sempre pi√π precise.\n\nEsempio 45.4 Un esempio intuitivo per spiegare l‚Äôaggiornamento bayesiano √® quello proposto da McElreath (2020). Supponiamo di voler stimare la proporzione della superficie terrestre coperta d‚Äôacqua. L‚Äôesperimento consiste nel lanciare un globo terrestre in aria, afferrarlo e osservare se la superficie sotto il dito √® acqua o terra. Dopo ogni osservazione, possiamo aggiornare le nostre credenze sulla proporzione d‚Äôacqua (p).\nIniziamo con una distribuzione a priori che assegna la stessa probabilit√† a tutti i valori possibili di \\(p\\) (proporzione d‚Äôacqua). Dopo il primo lancio, in cui osserviamo acqua (‚ÄúW‚Äù), la probabilit√† che \\(p\\) sia zero diminuisce, mentre quella che \\(p\\) sia maggiore aumenta. Man mano che raccogliamo pi√π dati, la distribuzione si aggiorna, riducendo l‚Äôincertezza e convergendo verso una stima pi√π precisa di \\(p\\).\nCon l‚Äôaumento dei dati osservati, la distribuzione a posteriori si concentra sempre di pi√π attorno ai valori di \\(p\\) che meglio spiegano i dati. Questo processo rappresenta il continuo affinamento delle stime bayesiane, che diventano pi√π accurate man mano che le evidenze si accumulano.\nIn sintesi, l‚Äôaggiornamento bayesiano fornisce un quadro flessibile e sistematico per trattare l‚Äôincertezza e integrare nuove informazioni. √à particolarmente utile nelle scienze psicologiche e sociali, dove la complessit√† e la variabilit√† dei fenomeni rendono difficile ottenere stime precise. Questo approccio consente di migliorare costantemente la comprensione dei fenomeni, adattando le credenze man mano che emergono nuovi dati.\n\n\n\n\n\n\n\n\nIl grafico precedente illustra un processo di aggiornamento bayesiano, in cui vengono progressivamente aggiornate le credenze sulla proporzione di superficie coperta d‚Äôacqua (\\(p\\)) del globo terrestre, man mano che vengono raccolti nuovi dati. Dopo ogni lancio, le probabilit√† sui possibili valori di \\(p\\) vengono aggiornate sulla base delle osservazioni, utilizzando il teorema di Bayes. Il processo √® visualizzato attraverso una serie di grafici, organizzati in una griglia 3x3, con ogni pannello che rappresenta un‚Äôosservazione aggiuntiva.\nNota sui grafici.\n\n\nLinea Blu: La distribuzione a posteriori calcolata per il pannello corrente.\n\nLinea Grigia: La distribuzione a priori utilizzata, che √® il posterior del pannello precedente.\n\nAggiornamento Bayesiano: Ogni volta che vengono osservati nuovi dati, la distribuzione a posteriori diventa il a priori per il passo successivo, consentendo di incorporare progressivamente l‚Äôinformazione osservata.\n\n\n\n\n\n\n\n\nApprofondimento\n\n\n\n\n\nA una prima lettura, √® sufficiente focalizzarsi sul significato dell‚Äôaggiornamento bayesiano e sulle conseguenze che questo produce rispetto alle nostre credenze su \\(p\\), man mano che vengono osservati nuovi dati. Per il momento, il meccanismo dettagliato attraverso cui l‚Äôaggiornamento bayesiano viene realizzato non √® ancora stato esplicitato, e quindi gli studenti possono inizialmente tralasciare la spiegazione approfondita contenuta in questo riquadro.\nDopo aver letto il contenuto di Capitolo 50, sar√† possibile tornare sull‚Äôesempio discusso qui e comprenderne appieno l‚Äôaggiornamento bayesiano, interpretandolo alla luce delle propriet√† delle famiglie coniugate. Questo consentir√† di cogliere non solo il significato generale dell‚Äôaggiornamento, ma anche i dettagli tecnici che lo rendono particolarmente efficiente in contesti come quello descritto.\nPrimo Pannello.\n\n\nOsservazione iniziale: Abbiamo il primo dato, un successo (‚ÄúW‚Äù).\n\nA priori: La distribuzione a priori iniziale √® una distribuzione Beta(1, 1). Questa rappresenta una conoscenza iniziale non informativa, ovvero l‚Äôipotesi che qualsiasi proporzione di successi (\\(p\\)) sia ugualmente probabile.\n\nA posteriori: Con un successo su una prova: \\[\n\\text{Posterior} \\sim \\mathcal{Beta}(1 + 1, 1 + 0) = \\mathcal{Beta}(2, 1).\n\\] La distribuzione risultante √® concentrata verso i valori pi√π alti di \\(p\\), riflettendo il successo osservato.\n\nSecondo Pannello.\n\n\nOsservazioni: Ora abbiamo due dati, ‚ÄúW‚Äù e ‚ÄúL‚Äù, quindi un successo su due prove.\n\nA priori: La distribuzione a priori per questo passo √® il posterior del pannello precedente, ovvero \\(\\mathcal{Beta}(2, 1)\\).\n\nA posteriori: Con un successo (\\(W = 1\\)) e un insuccesso (\\(L = 1\\)): \\[\n\\text{Posterior} \\sim \\mathcal{Beta}(2 + 1, 1 + 1) = \\mathcal{Beta}(3, 2).\n\\] La nuova distribuzione riflette un aggiornamento che tiene conto sia del successo che dell‚Äôinsuccesso.\n\nTerzo Pannello.\n\n\nOsservazioni: Ora abbiamo tre dati, ‚ÄúW‚Äù, ‚ÄúL‚Äù, ‚ÄúW‚Äù, quindi due successi su tre prove.\n\nA priori: La distribuzione a priori √® il posterior del pannello precedente, \\(\\mathcal{Beta}(3, 2)\\).\n\nA posteriori: Con due successi (\\(W = 2\\)) e un insuccesso (\\(L = 1\\)): \\[\n\\text{Posterior} \\sim \\mathcal{Beta}(3 + 1, 2 + 0) = \\mathcal{Beta}(4, 2).\n\\]\n\n\nQuarto Pannello.\n\n\nOsservazioni: Ora abbiamo quattro dati, ‚ÄúW‚Äù, ‚ÄúL‚Äù, ‚ÄúW‚Äù, ‚ÄúW‚Äù, quindi tre successi su quattro prove.\n\nA priori: La distribuzione a priori √® il posterior del pannello precedente, \\(\\mathcal{Beta}(4, 2)\\).\n\nA posteriori: Con tre successi (\\(W = 3\\)) e un insuccesso (\\(L = 1\\)): \\[\n\\text{Posterior} \\sim \\mathcal{Beta}(4 + 1, 2 + 0) = \\mathcal{Beta}(5, 2).\n\\]\n\n\nQuinto Pannello.\n\n\nOsservazioni: Ora abbiamo cinque dati, ‚ÄúW‚Äù, ‚ÄúL‚Äù, ‚ÄúW‚Äù, ‚ÄúW‚Äù, ‚ÄúL‚Äù, quindi tre successi su cinque prove.\n\nA priori: La distribuzione a priori √® il posterior del pannello precedente, \\(\\mathcal{Beta}(5, 2)\\).\n\nA posteriori: Con tre successi (\\(W = 3\\)) e due insuccessi (\\(L = 2\\)): \\[\n\\text{Posterior} \\sim \\mathcal{Beta}(5 + 0, 2 + 1) = \\mathcal{Beta}(5, 3).\n\\]\n\n\nSesto Pannello.\n\n\nOsservazioni: Ora abbiamo sei dati, ‚ÄúW‚Äù, ‚ÄúL‚Äù, ‚ÄúW‚Äù, ‚ÄúW‚Äù, ‚ÄúL‚Äù, ‚ÄúW‚Äù, quindi quattro successi su sei prove.\n\nA priori: La distribuzione a priori √® il posterior del pannello precedente, \\(\\mathcal{Beta}(5, 3)\\).\n\nA posteriori: Con quattro successi (\\(W = 4\\)) e due insuccessi (\\(L = 2\\)): \\[\n\\text{Posterior} \\sim \\mathcal{Beta}(5 + 1, 3 + 0) = \\mathcal{Beta}(6, 3).\n\\]\n\n\nSettimo Pannello.\n\n\nOsservazioni: Ora abbiamo sette dati, ‚ÄúW‚Äù, ‚ÄúL‚Äù, ‚ÄúW‚Äù, ‚ÄúW‚Äù, ‚ÄúL‚Äù, ‚ÄúW‚Äù, ‚ÄúL‚Äù, quindi quattro successi su sette prove.\n\nA priori: La distribuzione a priori √® il posterior del pannello precedente, \\(\\mathcal{Beta}(6, 3)\\).\n\nA posteriori: Con quattro successi (\\(W = 4\\)) e tre insuccessi (\\(L = 3\\)): \\[\n\\text{Posterior} \\sim \\mathcal{Beta}(6 + 0, 3 + 1) = \\mathcal{Beta}(6, 4).\n\\]\n\n\nOttavo Pannello.\n\n\nOsservazioni: Ora abbiamo otto dati, ‚ÄúW‚Äù, ‚ÄúL‚Äù, ‚ÄúW‚Äù, ‚ÄúW‚Äù, ‚ÄúL‚Äù, ‚ÄúW‚Äù, ‚ÄúL‚Äù, ‚ÄúW‚Äù, quindi cinque successi su otto prove.\n\nA priori: La distribuzione a priori √® il posterior del pannello precedente, \\(\\mathcal{Beta}(6, 4)\\).\n\nA posteriori: Con cinque successi (\\(W = 5\\)) e tre insuccessi (\\(L = 3\\)): \\[\n\\text{Posterior} \\sim \\mathcal{Beta}(6 + 1, 4 + 0) = \\mathcal{Beta}(7, 4).\n\\]\n\n\nNono Pannello.\n\n\nOsservazioni: Ora abbiamo nove dati, ‚ÄúW‚Äù, ‚ÄúL‚Äù, ‚ÄúW‚Äù, ‚ÄúW‚Äù, ‚ÄúL‚Äù, ‚ÄúW‚Äù, ‚ÄúL‚Äù, ‚ÄúW‚Äù, ‚ÄúW‚Äù, quindi sei successi su nove prove.\n\nA priori: La distribuzione a priori √® il posterior del pannello precedente, \\(\\mathcal{Beta}(7, 4)\\).\n\nA posteriori: Con sei successi (\\(W = 6\\)) e tre insuccessi (\\(L = 3\\)): \\[\n\\text{Posterior} \\sim \\mathcal{Beta}(7 + 1, 4 + 0) = \\mathcal{Beta}(8, 4).\n\\]\n\n\n\n\n\nQuesto processo mostra come il modello bayesiano aggiorna continuamente le credenze man mano che i dati vengono osservati. Ogni nuovo pannello segue lo stesso schema: la distribuzione a priori (linea tratteggiata) viene aggiornata con la nuova osservazione (linea continua). Se viene osservata acqua (W), il picco della distribuzione si sposta a destra; se viene osservata terra (L), il picco si sposta a sinistra. In ogni caso, la curva diventa progressivamente pi√π ‚Äúappuntita‚Äù, indicando che l‚Äôincertezza sulla vera proporzione di acqua diminuisce con l‚Äôaumentare del numero di osservazioni.\nL‚Äôaspetto fondamentale dell‚Äôapproccio bayesiano √® che ogni distribuzione a posteriori aggiornata (linea continua) diventa la nuova distribuzione a priori per la successiva osservazione. Questo processo iterativo permette di apprendere progressivamente dai dati, integrando ogni nuova informazione per affinare la stima di \\(p\\). Alla fine, la distribuzione diventa sempre pi√π concentrata intorno al valore pi√π probabile di \\(p\\), man mano che raccogliamo pi√π dati.\nIn conclusione, l‚Äôesempio illustra come l‚Äôaggiornamento bayesiano modifichi le nostre credenze sulla proporzione d‚Äôacqua (\\(p\\)) sulla superficie del globo, basandosi sulle osservazioni raccolte. Ogni curva rappresenta la sintesi delle conoscenze attuali, combinando le osservazioni precedenti con l‚Äôultima evidenza raccolta. Il grafico dimostra visivamente come l‚Äôapproccio bayesiano consenta di trattare l‚Äôincertezza e aggiornare le stime in modo coerente e progressivo.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>¬† <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_intro_bayes.html#il-processo-generatore-dei-dati",
    "href": "chapters/bayesian_inference/02_intro_bayes.html#il-processo-generatore-dei-dati",
    "title": "45¬† La quantificazione dell‚Äôincertezza",
    "section": "\n45.8 Il Processo Generatore dei Dati",
    "text": "45.8 Il Processo Generatore dei Dati\nL‚Äôesempio precedente mette in evidenza come, nel contesto dell‚Äôaggiornamento bayesiano, sia cruciale fare un‚Äôassunzione sul processo generatore dei dati, ovvero il meccanismo che collega i parametri sconosciuti ai dati osservati. Questo processo √® formalizzato attraverso la funzione di verosimiglianza, che esprime la probabilit√† di osservare i dati disponibili per ogni valore possibile del parametro incognito.\nNel caso degli esperimenti bernoulliani, come il lancio del globo, ogni prova ha due possibili esiti: un successo (acqua) o un fallimento (terra). L‚Äôobiettivo √® stimare la probabilit√† di successo, denotata con \\(\\theta\\). Il processo generatore dei dati per questo tipo di esperimento √® ben rappresentato dalla distribuzione binomiale, che modella il numero di successi osservati su un certo numero di prove indipendenti, ciascuna con probabilit√† di successo pari a \\(\\theta\\):\n\\[\nP(W \\mid \\theta, n) = \\binom{n}{W} \\theta^W (1 - \\theta)^{n-W},\n\\]\ndove \\(\\binom{n}{W}\\) √® il coefficiente binomiale che calcola il numero di combinazioni possibili di \\(W\\) successi in \\(n\\) prove.\nIn questo contesto, \\(\\theta\\) rappresenta la proporzione di superficie coperta d‚Äôacqua sul globo. L‚Äôassunzione fondamentale √® che \\(\\theta\\) sia costante durante l‚Äôintero esperimento, garantendo che tutte le prove siano indipendenti e identicamente distribuite. Questo implica che ogni osservazione porta informazioni utili per aggiornare le nostre credenze su \\(\\theta\\), che si riflettono nella distribuzione a posteriori ad ogni passo.\nGrazie a questa struttura probabilistica, il processo di aggiornamento bayesiano ci consente di:\n\nIniziare con una distribuzione a priori che riflette le nostre conoscenze o ipotesi iniziali su \\(\\theta\\).\nUtilizzare la funzione di verosimiglianza per incorporare i dati osservati.\nCalcolare la distribuzione a posteriori, che sintetizza le nostre credenze aggiornate su \\(\\theta\\).\n\nQuesto processo iterativo consente di affinare progressivamente la stima del parametro \\(\\theta\\), integrando in modo rigoroso le informazioni provenienti dai dati.\n\n\n\n\n\nFigura¬†45.1: Gli stessi dati possono essere coerenti con diverse ipotesi riguardanti il processo che li ha generati (Figura tratta da Freiesleben & Molnar, 2024).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>¬† <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_intro_bayes.html#interpretazione-della-distribuzione-a-posteriori",
    "href": "chapters/bayesian_inference/02_intro_bayes.html#interpretazione-della-distribuzione-a-posteriori",
    "title": "45¬† La quantificazione dell‚Äôincertezza",
    "section": "\n45.9 Interpretazione della Distribuzione a Posteriori",
    "text": "45.9 Interpretazione della Distribuzione a Posteriori\nLa distribuzione a posteriori rappresenta l‚Äôaggiornamento delle nostre credenze su \\(\\theta\\) alla luce dei dati osservati. Questa distribuzione non solo sintetizza le informazioni provenienti dall‚Äôesperimento, ma ci permette anche di fare inferenze pi√π robuste e quantitative su \\(\\theta\\).\nLa distribuzione a posteriori pu√≤ essere interpretata utilizzando diverse statistiche riassuntive:\n\n\nModa: √à il valore di \\(\\theta\\) con la massima densit√† di probabilit√†. Questo rappresenta la stima pi√π plausibile di \\(\\theta\\) dato il modello e i dati osservati.\n\nMedia e Mediana: La media della distribuzione a posteriori fornisce una stima centrale ponderata da tutta la distribuzione, mentre la mediana individua il valore che divide la distribuzione in due met√† uguali. Queste misure possono variare leggermente a seconda della simmetria o asimmetria della distribuzione.\n\nL‚Äôincertezza associata alla stima di \\(\\theta\\) √® rappresentata dalla larghezza della distribuzione a posteriori:\n\nUna distribuzione stretta indica una bassa incertezza: la probabilit√† si concentra in un intervallo ristretto di valori, riflettendo una maggiore fiducia nella stima di \\(\\theta\\).\nUna distribuzione ampia suggerisce una maggiore incertezza: i dati osservati non sono sufficienti per restringere l‚Äôintervallo delle credenze su \\(\\theta\\).\n\nCon l‚Äôaumentare dei dati raccolti, la distribuzione a posteriori diventa progressivamente pi√π concentrata attorno al valore pi√π probabile di \\(\\theta\\), riducendo l‚Äôincertezza e migliorando la precisione delle inferenze.\n\nEsempio 45.5 Nel contesto dei lanci del globo, supponiamo che la distribuzione a posteriori abbia un picco vicino a \\(\\theta = 0.67\\). Questo significa che la stima pi√π plausibile della proporzione di superficie coperta d‚Äôacqua sul globo √® il 67%. Se la distribuzione √® stretta, possiamo affermare con maggiore sicurezza che la vera proporzione √® vicina a questo valore. Al contrario, una distribuzione pi√π ampia rifletterebbe una maggiore incertezza, indicando che ulteriori osservazioni sono necessarie per affinare la stima.\n\nIn conclusione, la distribuzione a posteriori non solo fornisce una stima puntuale di \\(\\theta\\), ma cattura anche l‚Äôincertezza associata a questa stima. Attraverso il suo utilizzo, possiamo integrare rigorosamente i dati con le ipotesi iniziali e ottenere inferenze che riflettono sia le informazioni disponibili sia la variabilit√† residua.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>¬† <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_intro_bayes.html#influenza-delle-distribuzioni-a-priori",
    "href": "chapters/bayesian_inference/02_intro_bayes.html#influenza-delle-distribuzioni-a-priori",
    "title": "45¬† La quantificazione dell‚Äôincertezza",
    "section": "\n45.10 Influenza delle Distribuzioni a Priori",
    "text": "45.10 Influenza delle Distribuzioni a Priori\nIn questo esempio, abbiamo utilizzato una distribuzione a priori uniforme, che esprime una totale mancanza di conoscenza iniziale su \\(\\theta\\). Tuttavia, in contesti in cui abbiamo informazioni preesistenti, √® possibile utilizzare distribuzioni a priori pi√π informative. Ad esempio, se sappiamo da studi precedenti che circa il 70% della superficie terrestre √® coperta d‚Äôacqua, possiamo utilizzare una distribuzione a priori che rifletta questa conoscenza. Questo tipo di distribuzione a priori informativa pu√≤ rendere l‚Äôaggiornamento bayesiano pi√π efficiente, portando a stime pi√π precise con meno dati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>¬† <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_intro_bayes.html#vantaggi-dellaggiornamento-bayesiano",
    "href": "chapters/bayesian_inference/02_intro_bayes.html#vantaggi-dellaggiornamento-bayesiano",
    "title": "45¬† La quantificazione dell‚Äôincertezza",
    "section": "\n45.11 Vantaggi dell‚ÄôAggiornamento Bayesiano",
    "text": "45.11 Vantaggi dell‚ÄôAggiornamento Bayesiano\nUno dei principali vantaggi dell‚Äôapproccio bayesiano √® che ogni nuova osservazione aggiorna automaticamente le credenze preesistenti, integrando le informazioni precedenti con i nuovi dati. Questo processo consente un apprendimento iterativo e progressivo, che diventa pi√π efficiente man mano che si accumulano dati. Inoltre, la flessibilit√† nella scelta della distribuzione a priori consente al ricercatore di adattare l‚Äôinferenza bayesiana al contesto specifico, migliorando ulteriormente la precisione delle stime.\nIn sintesi, il processo generatore dei dati, modellato tramite la verosimiglianza, gioca un ruolo centrale nell‚Äôaggiornamento bayesiano. Nel caso del globo, abbiamo modellato il fenomeno utilizzando una distribuzione binomiale e, attraverso l‚Äôapplicazione del Teorema di Bayes, abbiamo aggiornato progressivamente le nostre credenze sulla proporzione di acqua osservata. Il risultato √® una stima sempre pi√π precisa di \\(\\theta\\), con una distribuzione a posteriori che riflette sia le osservazioni passate sia le nuove evidenze, riducendo progressivamente l‚Äôincertezza.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>¬† <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_intro_bayes.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/02_intro_bayes.html#riflessioni-conclusive",
    "title": "45¬† La quantificazione dell‚Äôincertezza",
    "section": "\n45.12 Riflessioni Conclusive",
    "text": "45.12 Riflessioni Conclusive\nNegli ultimi anni, i metodi bayesiani stanno acquisendo sempre pi√π importanza nel campo dell‚Äôinferenza statistica, anche in discipline come la psicologia. Questa diffusione √® favorita dall‚Äôaccesso a risorse educative e a testi fondamentali, come quelli di Albert & Hu (2019), Johnson et al. (2022), McElreath (2020) e Kruschke (2014), che hanno reso la modellizzazione bayesiana pi√π accessibile, chiarendo i concetti centrali in modo pratico e comprensibile.\nL‚Äôapproccio bayesiano si distingue dalla metodologia frequentista tradizionale per la sua capacit√† di trattare i parametri di interesse come quantit√† probabilistiche. Invece di considerare i parametri come valori fissi e sconosciuti (come avviene nel paradigma frequentista), il bayesianesimo assegna ai parametri una distribuzione a priori, che rappresenta le credenze iniziali del ricercatore. Man mano che nuovi dati vengono raccolti, queste credenze vengono aggiornate tramite il teorema di Bayes, portando a una distribuzione a posteriori che riflette sia le informazioni pregresse sia l‚Äôevidenza empirica. Questa distribuzione aggiornata consente di esprimere l‚Äôincertezza sui parametri in modo pi√π completo e informato.\nUno dei principali vantaggi dell‚Äôapproccio bayesiano √® la sua capacit√† di combinare conoscenze pregresse con nuove osservazioni in modo fluido e sistematico. Ogni nuova informazione arricchisce e raffina le stime, rendendole pi√π accurate e interpretabili nel contesto del problema specifico. Questo non solo migliora la precisione delle inferenze, ma permette anche una migliore comprensione dell‚Äôincertezza che circonda i parametri studiati.\nIn definitiva, l‚Äôinferenza bayesiana non √® solo uno strumento analitico, ma un approccio dinamico che incoraggia un‚Äôinterazione continua tra teoria ed evidenza. Offrendo una flessibilit√† unica e una gestione esplicita dell‚Äôincertezza, il bayesianesimo si rivela un metodo potente per supportare il processo decisionale in contesti complessi, rendendo le sue applicazioni particolarmente rilevanti in campi come la psicologia, dove l‚Äôincertezza √® una componente inevitabile dell‚Äôanalisi dei dati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>¬† <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_intro_bayes.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/02_intro_bayes.html#informazioni-sullambiente-di-sviluppo",
    "title": "45¬† La quantificazione dell‚Äôincertezza",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.5.3     \n#&gt;  [9] scales_1.3.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.9.1   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         rlang_1.1.5       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       yaml_2.3.10       tools_4.4.2       parallel_4.4.2   \n#&gt; [21] tzdb_0.5.0        colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5      \n#&gt; [25] R6_2.6.1          lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3  \n#&gt; [29] pillar_1.10.1     gtable_0.3.6      glue_1.8.0        xfun_0.51        \n#&gt; [33] tidyselect_1.2.1  rstudioapi_0.17.1 farver_2.1.2      htmltools_0.5.8.1\n#&gt; [37] nlme_3.1-167      labeling_0.4.3    rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>¬† <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_intro_bayes.html#bibliografia",
    "href": "chapters/bayesian_inference/02_intro_bayes.html#bibliografia",
    "title": "45¬† La quantificazione dell‚Äôincertezza",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAlbert, J., & Hu, J. (2019). Probability and Bayesian Modeling. CRC Press.\n\n\nBaribault, B., & Collins, A. G. (2023). Troubleshooting Bayesian cognitive models. Psychological Methods.\n\n\nFreiesleben, T., & Molnar, C. (2024). Supervised Machine Learning for Science: How to stop worrying and love your black box. https://ml-science-book.com/\n\n\nGoligher, E. C., Heath, A., & Harhay, M. O. (2024). Bayesian statistics for clinical research. The Lancet, 404(10457), 1067‚Äì1076. https://doi.org/10.1016/S0140-6736(24)00055-9\n\n\nJaynes, E. T. (2003). Probability theory: The logic of science. Cambridge University Press.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nKruschke, J. (2014). Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan. Academic Press.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>¬† <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_statistical_models.html",
    "href": "chapters/bayesian_inference/03_statistical_models.html",
    "title": "46¬† Modelli statistici",
    "section": "",
    "text": "46.1 Introduzione\nIl quadro concettuale per la modellizzazione e l‚Äôanalisi statistica √® illustrato nella figura seguente. Il punto di partenza √® un problema reale (la realt√†) e un corrispondente insieme di dati. Sulla base di questi dati, desideriamo trarre delle conclusioni riguardo al problema reale. Il secondo passo consiste nell‚Äôindividuare un modello probabilistico per i dati. Questo modello incorpora ci√≤ che sappiamo sulla realt√† e su come i dati sono stati ottenuti. All‚Äôinterno del modello, eseguiamo i nostri calcoli e le nostre analisi, che portano a conclusioni riguardanti il modello stesso. Infine, queste conclusioni sul modello vengono tradotte in conclusioni sulla realt√†.\nLa statistica matematica utilizza la teoria della probabilit√† e altri rami della matematica per studiare i dati. In particolare, i dati sono considerati come realizzazioni di variabili casuali la cui distribuzione congiunta √® specificata in anticipo, eventualmente con alcuni parametri sconosciuti. L‚Äôanalisi matematica si concentra quindi esclusivamente sul modello e sui suoi parametri.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>¬† <span class='chapter-title'>Modelli statistici</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_statistical_models.html#introduzione",
    "href": "chapters/bayesian_inference/03_statistical_models.html#introduzione",
    "title": "46¬† Modelli statistici",
    "section": "",
    "text": "Figura¬†46.1: Modellizzazione e analisi statistica (figura tratta da Chan & Kroese, 2025).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>¬† <span class='chapter-title'>Modelli statistici</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_statistical_models.html#campionamento-indipendente-da-una-distribuzione-fissa",
    "href": "chapters/bayesian_inference/03_statistical_models.html#campionamento-indipendente-da-una-distribuzione-fissa",
    "title": "46¬† Modelli statistici",
    "section": "\n46.2 Campionamento indipendente da una distribuzione fissa",
    "text": "46.2 Campionamento indipendente da una distribuzione fissa\nUno dei modelli statistici pi√π semplici √® quello in cui i dati\\(X_1, \\ldots, X_n\\)sono considerati indipendenti e identicamente distribuiti (iid). Per indicare che le variabili casuali formano un campione iid da una distribuzione di probabilit√†, si utilizza la notazione:\n\\[\nX_1, \\ldots, X_n \\stackrel{\\text{iid}}{\\sim} f \\quad \\text{oppure} \\quad X_1, \\ldots, X_n \\stackrel{\\text{iid}}{\\sim} \\text{Dist},\n\\]\ndove \\(f\\) rappresenta la funzione di densit√† di probabilit√† (pdf) della distribuzione, e ‚ÄúDist‚Äù indica una generica distribuzione. Sia \\(f(x_1, \\ldots, x_n)\\) la pdf congiunta delle variabili \\(X_1, \\ldots, X_n\\). Allora, per la Regola del Prodotto, la pdf congiunta pu√≤ essere espressa come il prodotto delle pdf marginali:\n\\[\nf(x_1, \\ldots, x_n) = f(x_1) \\cdot f(x_2) \\cdot \\ldots \\cdot f(x_n).\n\\]\nIn altre parole, poich√© le variabili sono indipendenti e identicamente distribuite, la distribuzione congiunta √® semplicemente il prodotto delle distribuzioni individuali di ciascuna variabile.\n\nEsempio 46.1 Ogni scenario descritto di seguito pu√≤ essere modellato tramite un campione di variabili casuali indipendenti e identicamente distribuite (I.I.D.).\n\n\nLancio di un dado: Lanciamo un dado 100 volte e registriamo se al lancio i-esimo compare il numero 6 o meno. Definiamo \\(X_i = 1\\) se al lancio i-esimo esce un 6, e \\(X_i = 0\\) altrimenti, per \\(i = 1, \\dots, 100\\). Allora:\n\n\\[\n   X_1, \\dots, X_{100} \\sim \\text{Ber}(p) \\quad \\text{(indipendentemente e identicamente distribuite)},\n  \\]\ndove \\(p\\) √® la probabilit√† di ottenere un 6 in un singolo lancio (nota o sconosciuta). Ad esempio, se il dado √® equilibrato, \\(p = 1/6\\).\n\n\nMisurazione delle altezze: Selezioniamo casualmente 300 uomini tra i 40 e i 50 anni da una popolazione ampia e misuriamo le loro altezze. Sia \\(X_i\\)l‚Äôaltezza dell‚Äôuomo i-esimo selezionato, per \\(i = 1, \\dots, 300\\). Allora:\n\n\\[\n   X_1, \\dots, X_{300} \\sim N(\\mu, \\sigma^2),\n  \\]\ndove \\(\\mu\\) e \\(\\sigma^2\\) sono rispettivamente la media e la varianza della distribuzione delle altezze, parametri sconosciuti.\n\n\nValutazione delle reazioni a stimoli emotivi: Un gruppo di 20 partecipanti viene sottoposto a uno studio in cui vengono mostrati diversi stimoli emotivi (ad esempio, immagini positive, negative o neutre). Per ciascun partecipante, viene registrato il numero di volte in cui si verifica una risposta fisiologica significativa (come un aumento del battito cardiaco) durante l‚Äôesposizione agli stimoli. Sia \\(X_i\\) il numero di risposte fisiologiche significative registrate per il partecipante i-esimo, per \\(i = 1, \\dots, 20\\). Allora:\n\n\\[\n   X_1, \\dots, X_{20} \\sim \\text{Poi}(\\mu),\n  \\]\ndove \\(\\mu &gt; 0\\) √® il parametro di intensit√† della distribuzione di Poisson, che rappresenta la frequenza media di risposte fisiologiche significative per stimolo.\n\n\nSimulazione di test cognitivi: Un ricercatore sviluppa un modello computazionale per simulare le prestazioni cognitive di individui in un test di memoria. Il modello viene eseguito 10 volte con diverse configurazioni iniziali casuali (seed diversi), e per ogni esecuzione viene registrato il punteggio totale ottenuto nel test simulato. Sia \\(X_i\\) il punteggio totale ottenuto nella i-esima simulazione, per \\(i = 1, \\dots, 10\\). Allora:\n\n\\[\n   X_1, \\dots, X_{10} \\sim \\text{Dist},\n  \\]\ndove \\(\\text{Dist}\\) √® una distribuzione sconosciuta che descrive la variabilit√† dei punteggi totali nei test cognitivi simulati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>¬† <span class='chapter-title'>Modelli statistici</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_statistical_models.html#campioni-multipli-indipendenti",
    "href": "chapters/bayesian_inference/03_statistical_models.html#campioni-multipli-indipendenti",
    "title": "46¬† Modelli statistici",
    "section": "\n46.3 Campioni Multipli Indipendenti",
    "text": "46.3 Campioni Multipli Indipendenti\nIl caso di un singolo campione I.I.D. (indipendente e identicamente distribuito), descritto nella Sezione 4.1, pu√≤ essere facilmente generalizzato a pi√π campioni I.I.D. I modelli pi√π comuni coinvolgono variabili casuali di Bernoulli e normali.\n\nEsempio 46.2 Per valutare se esista una differenza tra i ragazzi e le ragazze riguardo alla propensione a rispondere ‚Äús√¨‚Äù a una domanda su un particolare tratto di personalit√† (ad esempio, ‚ÄúTi consideri una persona empatica?‚Äù), selezioniamo casualmente 100 ragazzi e 100 ragazze e chiediamo loro di rispondere ‚Äús√¨‚Äù o ‚Äúno‚Äù alla domanda. Questo scenario pu√≤ essere modellato tramite due campioni indipendenti di variabili casuali di Bernoulli.\nSpecificamente, per\\(i = 1, \\dots, 100\\):\n\nSia \\(X_i = 1\\) se il ragazzo i-esimo risponde ‚Äús√¨‚Äù alla domanda, e \\(X_i = 0\\) altrimenti.\n\nSia \\(Y_i = 1\\) se la ragazza i-esima risponde ‚Äús√¨‚Äù alla domanda, e \\(Y_i = 0\\) altrimenti.\n\nIn questo modo, otteniamo il seguente modello:\n\\[\nX_1, \\dots, X_{100} \\sim \\text{Ber}(p_1) \\quad \\text{(I.I.D.)},\n\\]\n\\[\nY_1, \\dots, Y_{100} \\sim \\text{Ber}(p_2) \\quad \\text{(I.I.D.)},\n\\]\ndove \\(X_1, \\dots, X_{100}, Y_1, \\dots, Y_{100}\\) sono variabili indipendenti, e \\(p_1\\) e \\(p_2\\) sono parametri sconosciuti che rappresentano, rispettivamente, la probabilit√† che un ragazzo o una ragazza risponda ‚Äús√¨‚Äù alla domanda.\nL‚Äôobiettivo √® stimare la differenza \\(p_1 - p_2\\) basandosi sui valori osservati di \\(X_1, \\dots, X_{100}\\) e \\(Y_1, \\dots, Y_{100}\\). Nota che √® sufficiente registrare il numero totale di ragazzi e ragazze che rispondono ‚Äús√¨‚Äù in ciascun gruppo, ovvero:\n\\[\nX = \\sum_{i=1}^{100} X_i \\quad \\text{e} \\quad Y = \\sum_{i=1}^{100} Y_i.\n\\]\nQuesto porta al modello binomiale a due campioni:\n\\[\nX \\sim \\text{Bin}(100, p_1), \\quad Y \\sim \\text{Bin}(100, p_2),\n\\]\ndove \\(X\\) e \\(Y\\) sono indipendenti, e \\(p_1\\) e \\(p_2\\) sono sconosciuti.\n\n\nEsempio 46.3 Da una popolazione ampia, selezioniamo 200 uomini tra i 25 e i 30 anni e misuriamo le loro altezze. Per ogni persona, registreremo anche se la madre ha fumato durante la gravidanza o meno. Supponiamo che 60 madri abbiano fumato durante la gravidanza.\nSia:\n\n\n\\(X_1, \\dots, X_{60}\\) le altezze degli uomini le cui madri hanno fumato,\n\n\\(Y_1, \\dots, Y_{140}\\) le altezze degli uomini le cui madri non hanno fumato.\n\nUn possibile modello √® quello normale a due campioni: \\[\nX_1, \\dots, X_{60} \\sim N(\\mu_1, \\sigma_1^2) \\quad \\text{(I.I.D.)},\n\\]\n\\[\nY_1, \\dots, Y_{140} \\sim N(\\mu_2, \\sigma_2^2) \\quad \\text{(I.I.D.)},\n\\]\ndove \\(X_1, \\dots, X_{60}, Y_1, \\dots, Y_{140}\\) sono variabili indipendenti, e i parametri \\(\\mu_1, \\mu_2, \\sigma_1^2, \\sigma_2^2\\) sono sconosciuti.\nTipicamente, si vorrebbe valutare la differenza \\(\\mu_1 - \\mu_2\\), ovvero se il fumo durante la gravidanza influisce sull‚Äôaltezza media dei figli. Invece di dividere i dati in due gruppi (madri fumatrici e non fumatrici), sarebbe possibile suddividere ulteriormente il gruppo ‚Äúmadri fumatrici‚Äù in sottogruppi in base all‚Äôintensit√† del fumo, ad esempio: raramente, moderatamente e intensamente. In tal caso, i dati potrebbero essere modellati tramite quattro campioni indipendenti da una distribuzione normale. Tale modello dipenderebbe, in generale, da otto parametri sconosciuti: quattro medie (\\(\\mu_1, \\mu_2, \\mu_3, \\mu_4\\)) e quattro varianze (\\(\\sigma_1^2, \\sigma_2^2, \\sigma_3^2, \\sigma_4^2\\)).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>¬† <span class='chapter-title'>Modelli statistici</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_statistical_models.html#modelli-di-regressione-lineare",
    "href": "chapters/bayesian_inference/03_statistical_models.html#modelli-di-regressione-lineare",
    "title": "46¬† Modelli statistici",
    "section": "\n46.4 Modelli di Regressione Lineare",
    "text": "46.4 Modelli di Regressione Lineare\nL‚Äôanalisi della regressione riguarda la ricerca di relazioni tra diverse variabili. In particolare, c‚Äô√® una variabile di risposta (o dipendente) che si vuole ‚Äúspiegare‚Äù tramite una o pi√π variabili esplicative (o indipendenti). Le variabili esplicative vengono anche chiamate predittori, covariate o variabili indipendenti. Nell‚Äôultimo caso, la variabile di risposta √® detta variabile dipendente. La regressione viene generalmente vista come una relazione funzionale tra variabili continue.\n\n46.4.1 Regressione Lineare Semplice\nIl modello di regressione pi√π basilare prevede una relazione lineare tra la variabile di risposta e una singola variabile esplicativa. Come nei dati sull‚Äôaltezza forniti da Pearson, abbiamo misurazioni \\((x_1, y_1), \\dots, (x_n, y_n)\\) che giacciono approssimativamente su una retta. Si assume che queste misurazioni siano realizzazioni di coppie \\((x_1, Y_1), \\dots, (x_n, Y_n)\\), dove, per ogni variabile esplicativa deterministica \\(x_i\\), la variabile di risposta \\(Y_i\\) √® una variabile casuale con:\n\\[\n\\mathbb{E}[Y_i] = \\beta_0 + \\beta_1 x_i, \\quad i = 1, \\dots, n,\n\\]\ndove \\(\\beta_0\\) e \\(\\beta_1\\) sono parametri sconosciuti. La retta sconosciuta:\n\\[\ny = \\beta_0 + \\beta_1 x\n\\]\n√® detta retta di regressione. Per specificare completamente il modello, √® necessario definire la distribuzione congiunta di \\(Y_1, \\dots, Y_n\\). Il modello di regressione lineare pi√π comune √® descritto di seguito. L‚Äôaggettivo ‚Äúsemplice‚Äù si riferisce al fatto che viene utilizzata una sola variabile esplicativa per spiegare la risposta.\n\n46.4.2 Regressione Lineare Multipla\nUn modello di regressione lineare che include pi√π di una variabile esplicativa √® detto modello di regressione lineare multipla. In un modello di regressione lineare multipla gaussiana, i dati di risposta \\(Y_1, \\dots, Y_n\\) dipendono da variabili esplicative multidimensionali \\(x_1, \\dots, x_n\\), con \\(x_i = [x_{i1}, \\dots, x_{id}]^T\\), attraverso la relazione lineare:\n\\[\nY_i = \\beta_0 + \\beta_1 x_{i1} + \\cdots + \\beta_d x_{id} + \\varepsilon_i, \\quad \\varepsilon_1, \\dots, \\varepsilon_n \\sim \\text{i.i.d. } N(0, \\sigma^2),\n\\]\ndove \\(\\varepsilon_i\\) rappresenta il termine di errore.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>¬† <span class='chapter-title'>Modelli statistici</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_statistical_models.html#regressione-generale",
    "href": "chapters/bayesian_inference/03_statistical_models.html#regressione-generale",
    "title": "46¬† Modelli statistici",
    "section": "\n46.5 Regressione Generale",
    "text": "46.5 Regressione Generale\n\n46.5.1 Modelli di Regressione Non Lineari\nLa regressione generale si occupa di modellare la relazione tra una variabile risposta \\(Y\\) e una o pi√π variabili esplicative \\(x\\). In molti casi, la relazione tra le variabili non √® lineare, ma pu√≤ essere descritta da funzioni pi√π complesse. Un modello di regressione generale pu√≤ essere espresso nella forma:\n\\[\nY_i = g(x_i; \\beta) + \\varepsilon_i, \\quad i = 1, \\dots, n,\n\\]\ndove:\n\n\n\\(g(x; \\beta)\\) √® una funzione nota che descrive la relazione tra la variabile risposta \\(Y\\) e le variabili esplicative \\(x\\), dipendente dai parametri \\(\\beta\\).\n\n\\(\\varepsilon_i\\) rappresenta il termine di errore, solitamente assunto indipendente e identicamente distribuito (i.i.d.) con media nulla.\n\nSe la funzione \\(g(x; \\beta)\\) √® lineare nei parametri \\(\\beta\\), il modello √® detto modello di regressione lineare. Tuttavia, quando \\(g(x; \\beta)\\) √® una funzione non lineare in \\(\\beta\\), il modello √® definito come modello di regressione non lineare.\n\n46.5.1.0.1 Esempi di Modelli Non Lineari\nAlcuni esempi comuni di modelli di regressione non lineari includono:\n\n\nModello Esponenziale\n\\[\ny = a e^{bx},\n\\]\ndove \\(a\\) e \\(b\\) sono parametri da stimare.\n\n\nModello di Legge di Potenza\n\\[\ny = a x^b,\n\\] utile per descrivere fenomeni in cui la relazione tra \\(y\\) e \\(x\\) √® proporzionale a una potenza di \\(x\\).\n\n\nModello Logistico\n\\[\ny = \\frac{L}{1 + e^{-(a + bx)}},\n\\]\nspesso utilizzato per modellare crescita limitata o curve a ‚ÄúS‚Äù.\n\n\nModello di Weibull\n\\[\ny = 1 - e^{-\\left(\\frac{x}{a}\\right)^b},\n\\]\ncomunemente usato in analisi della sopravvivenza e affidabilit√†.\n\n\nIn questi modelli, la funzione \\(g(x; \\beta)\\) non √® lineare nei parametri \\(\\beta\\), richiedendo metodi di stima specifici, come la minimizzazione della somma dei quadrati ponderati o l‚Äôuso di algoritmi iterativi.\n\n46.5.2 Modello Lineare Generalizzato (GLM)\nNel contesto dei modelli lineari standard, si assume che gli errori \\(\\varepsilon_i\\) siano distribuiti normalmente con media zero e varianza costante (\\(\\varepsilon_i \\sim N(0, \\sigma^2)\\)). Tuttavia, in molte applicazioni reali, questa ipotesi non √® soddisfatta. Ad esempio:\n\nLe variabili risposta possono essere binarie (successo/fallimento), conteggiate (numeri interi non negativi), o positive e skewed.\nLa varianza degli errori pu√≤ non essere costante (eteroschedasticit√†).\n\nPer affrontare queste situazioni, si utilizzano i modelli lineari generalizzati (GLM), che estendono i modelli lineari tradizionali rilassando l‚Äôipotesi di normalit√† sugli errori e consentendo relazioni non lineari tra la media della variabile risposta e le variabili esplicative.\nUn GLM √® definito da tre componenti principali:\n\n\nFunzione di Link: Una funzione \\(h(\\cdot)\\) che collega la media della variabile risposta \\(\\mu = \\mathbb{E}[Y]\\) alle variabili esplicative tramite un modello lineare:\n\\[\nh(\\mu) = \\mathbf{x}^T \\beta.\n\\]\nAd esempio, nel caso del modello logistico, la funzione di link √® il logit:\n\\[\nh(\\mu) = \\log\\left(\\frac{\\mu}{1 - \\mu}\\right).\n\\]\n\nDistribuzione della Variabile Risposta: Si assume che \\(Y\\) segua una distribuzione appartenente alla famiglia esponenziale, come Bernoulli, Poisson, Gamma, o Binomiale Negativa.\n\nRelazione di Varianza: La varianza di \\(Y\\) √® funzione della sua media \\(\\mu\\), ad esempio:\n\nPer la distribuzione Poisson: \\(\\text{Var}(Y) = \\mu\\),\nPer la distribuzione Gamma: \\(\\text{Var}(Y) = \\phi \\mu^2\\).\n\n\n\n\n46.5.2.0.1 Esempi di GLM\n\n\nRegressione Logistica\nUtilizzata quando la variabile risposta √® binaria (\\(Y \\in \\{0, 1\\}\\)):\n\\[\n\\log\\left(\\frac{\\mu}{1 - \\mu}\\right) = \\mathbf{x}^T \\beta,\n\\]\ndove \\(\\mu = \\mathbb{P}(Y = 1)\\).\n\n\nRegressione di Poisson\nUtilizzata per dati di conteggio (\\(Y \\in \\{0, 1, 2, \\dots\\}\\)):\n\\[\n\\log(\\mu) = \\mathbf{x}^T \\beta,\n\\]\ndove \\(\\mu = \\mathbb{E}[Y]\\).\n\n\nRegressione Gamma\nUtilizzata per dati continui positivi e skewed:\n\\[\n\\log(\\mu) = \\mathbf{x}^T \\beta.\n\\]\n\n\n46.5.3 Confronto tra Modelli Non Lineari e GLM\n\n\n\n\n\n\n\nCaratteristica\nModelli Non Lineari\nGLM\n\n\n\nFunzione di Relazione\nNon lineare nei parametri\nLineare dopo trasformazione (funzione di link)\n\n\nDistribuzione degli Errori\nSolitamente normale\nFamiglia esponenziale\n\n\nStima\nMetodi iterativi (ad es., NLSS)\nMassima verosimiglianza\n\n\nApplicazioni\nCurve di crescita, leggi fisiche\nDati binari, conteggi, positivi\n\n\n\nIn sintesi, i modelli non lineari permettono di catturare relazioni complesse tra le variabili, mentre i GLM forniscono una struttura flessibile per gestire distribuzioni non gaussiane delle variabili risposta. Entrambi i tipi di modelli sono fondamentali per l‚Äôanalisi statistica moderna.\n\n46.5.4 Modelli Psicologici\nI modelli di regressione descritti in precedenza rappresentano uno strumento essenziale per l‚Äôanalisi statistica, in quanto permettono di identificare e quantificare le relazioni tra variabili. Tuttavia, questi modelli hanno un carattere prevalentemente descrittivo: si limitano a evidenziare associazioni tra i dati senza fornire spiegazioni sui meccanismi causali o sui processi psicologici che le generano. Per comprendere appieno i fenomeni psicologici, √® necessario andare oltre l‚Äôanalisi delle associazioni statistiche e adottare modelli che descrivano i processi cognitivi e comportamentali sottostanti.\nIn questo contesto, i modelli computazionali sviluppati nell‚Äôambito della psichiatria computazionale e della psicologia cognitiva assumono un ruolo centrale (Hitchcock et al., 2022). A differenza dei modelli statistici tradizionali, i modelli computazionali cercano di simulare i processi mentali e decisionali, offrendo una rappresentazione dinamica e meccanicistica del comportamento umano. Due esempi particolarmente rilevanti sono:\n\nModello di Apprendimento Associativo:\nQuesto modello descrive come gli individui apprendono a associare stimoli e risposte attraverso meccanismi di condizionamento. Basato su principi derivati dalla psicologia comportamentale, il modello spiega come le esperienze passate influenzino le risposte future, modulando la forza delle associazioni tra stimoli e comportamenti. √à ampiamente utilizzato per studiare fenomeni come l‚Äôapprendimento per tentativi ed errori, il condizionamento classico e operante, e la formazione di abitudini.\nModello Drift-Diffusion:\nQuesto modello rappresenta il processo decisionale come un‚Äôaccumulazione progressiva di evidenza verso una soglia di decisione. Simula come le informazioni vengono integrate nel tempo, tenendo conto della velocit√† e dell‚Äôaccuratezza delle scelte. Il modello √® particolarmente utile per studiare situazioni in cui gli individui devono prendere decisioni in condizioni di incertezza, come nei compiti di discriminazione percettiva o nei test di attenzione e memoria.\n\nQuesti modelli computazionali non solo permettono di descrivere il comportamento osservato, ma offrono anche una finestra sui processi cognitivi e neurali che lo guidano. Attraverso la simulazione e la previsione del comportamento, √® possibile formulare ipotesi verificabili sui meccanismi interni che regolano l‚Äôapprendimento, la decisione e altre funzioni cognitive.\nPer chi desidera approfondire questi temi, √® disponibile una risorsa introduttiva sui modelli computazionali in psicologia al seguente sito. Questi strumenti rappresentano un ponte tra la teoria psicologica e l‚Äôanalisi empirica, contribuendo a una comprensione pi√π profonda e dinamica dei fenomeni mentali e comportamentali.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>¬† <span class='chapter-title'>Modelli statistici</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_statistical_models.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/03_statistical_models.html#riflessioni-conclusive",
    "title": "46¬† Modelli statistici",
    "section": "\n46.6 Riflessioni Conclusive",
    "text": "46.6 Riflessioni Conclusive\nIn questo capitolo abbiamo esaminato i principi di base della modellizzazione statistica, partendo da problemi reali e introducendo strumenti probabilistici per l‚Äôanalisi dei dati. Abbiamo presentato alcuni dei modelli pi√π semplici, come il campionamento da una singola distribuzione, il campionamento da pi√π distribuzioni e l‚Äôanalisi di regressione, sia semplice che multipla. Questi approcci rappresentano il fondamento per utilizzare i dati al fine di trarre conclusioni su fenomeni psicologici, applicando metodi matematici e probabilistici in modo rigoroso.\nNel prosieguo del corso, ci concentreremo sui modelli introdotti in questo capitolo, approfondendone sia gli aspetti teorici che quelli pratici. Questo percorso ci consentir√† di consolidare una comprensione solida dei principi statistici di base, che potr√† essere estesa in futuro per affrontare contesti pi√π articolati. Attraverso esempi applicativi e analisi dettagliate, svilupperemo le competenze necessarie per risolvere problemi concreti legati all‚Äôanalisi dei dati psicologici, adottando un approccio metodico e strutturato.\nIn particolare, approfondiremo temi come il campionamento da una o pi√π distribuzioni e i modelli di regressione, sia semplice che multipla, che costituiscono la base per tecniche statistiche pi√π avanzate. Lo studio di questi argomenti ci fornir√† gli strumenti per interpretare i dati, formulare ipotesi e trarre conclusioni, contribuendo cos√¨ a una migliore comprensione dei fenomeni psicologici oggetto di indagine.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>¬† <span class='chapter-title'>Modelli statistici</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_statistical_models.html#esercizi",
    "href": "chapters/bayesian_inference/03_statistical_models.html#esercizi",
    "title": "46¬† Modelli statistici",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n\nQual √® il processo concettuale alla base della modellizzazione e dell‚Äôanalisi statistica?\nCosa significa che un campione √® indipendente e identicamente distribuito (iid) e perch√© questa assunzione √® importante nei modelli statistici?\nCome si differenziano i modelli di campionamento da una singola distribuzione rispetto ai modelli di campioni multipli indipendenti?\nQual √® la differenza tra regressione lineare semplice e regressione lineare multipla?\nIn che modo i modelli computazionali, come il modello di apprendimento associativo e il modello drift-diffusion, si differenziano dai modelli statistici tradizionali?\n\nConsegna: Rispondi con parole tue e carica il file .qmd, convertito in PDF su Moodle.\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n\nIl processo concettuale della modellizzazione e analisi statistica inizia con un problema reale e i dati raccolti su tale problema. Si costruisce quindi un modello probabilistico che rappresenta le conoscenze disponibili e il modo in cui i dati sono stati ottenuti. L‚Äôanalisi viene condotta all‚Äôinterno del modello, producendo conclusioni sui suoi parametri. Infine, i risultati vengono tradotti in inferenze sulla realt√†, con lo scopo di migliorare la comprensione del fenomeno studiato.\nUn campione √® detto indipendente e identicamente distribuito (iid) se le osservazioni sono indipendenti tra loro e seguono la stessa distribuzione di probabilit√†. Questa assunzione √® fondamentale perch√© semplifica le analisi statistiche e permette di applicare risultati teorici importanti, come la legge dei grandi numeri e il teorema del limite centrale.\nNei modelli di campionamento da una singola distribuzione, si assume che tutte le osservazioni provengano da una stessa popolazione e seguano la stessa distribuzione. Nei modelli di campioni multipli indipendenti, invece, si confrontano pi√π gruppi distinti, ciascuno con la propria distribuzione, per studiare differenze tra le popolazioni. Un esempio √® il confronto tra altezze di individui con madri fumatrici e non fumatrici.\nLa regressione lineare semplice analizza la relazione tra una variabile dipendente e una sola variabile indipendente attraverso una relazione lineare. La regressione lineare multipla, invece, estende questo concetto a pi√π variabili indipendenti, permettendo di modellare fenomeni pi√π complessi e controllare l‚Äôeffetto di pi√π fattori simultaneamente.\nI modelli computazionali, come il modello di apprendimento associativo e il modello drift-diffusion, differiscono dai modelli statistici tradizionali perch√© mirano a simulare i processi mentali e decisionali sottostanti il comportamento umano. I modelli statistici descrivono principalmente relazioni tra variabili nei dati osservati, mentre i modelli computazionali cercano di rappresentare dinamicamente i meccanismi cognitivi e comportamentali che generano tali dati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>¬† <span class='chapter-title'>Modelli statistici</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_statistical_models.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/03_statistical_models.html#informazioni-sullambiente-di-sviluppo",
    "title": "46¬† Modelli statistici",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.5.3     \n#&gt;  [9] scales_1.3.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.9.1   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         rlang_1.1.5       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       tools_4.4.2       parallel_4.4.2    tzdb_0.5.0       \n#&gt; [21] colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5       R6_2.6.1         \n#&gt; [25] lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.1    \n#&gt; [29] gtable_0.3.6      glue_1.8.0        xfun_0.51         tidyselect_1.2.1 \n#&gt; [33] rstudioapi_0.17.1 farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-167     \n#&gt; [37] rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>¬† <span class='chapter-title'>Modelli statistici</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_statistical_models.html#bibliografia",
    "href": "chapters/bayesian_inference/03_statistical_models.html#bibliografia",
    "title": "46¬† Modelli statistici",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nChan, J. C. C., & Kroese, D. P. (2025). Statistical Modeling and Computation (2¬™ ed.). Springer.\n\n\nHitchcock, P. F., Fried, E. I., & Frank, M. J. (2022). Computational psychiatry needs time and context. Annual review of psychology, 73(1), 243‚Äì270.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>¬† <span class='chapter-title'>Modelli statistici</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_bayesian_inference.html",
    "href": "chapters/bayesian_inference/04_bayesian_inference.html",
    "title": "47¬† Inferenza bayesiana",
    "section": "",
    "text": "47.1 Introduzione\nRiprendiamo il quadro concettuale della modellizzazione e analisi statistica presentato nella Figura¬†46.1. L‚Äôinferenza statistica si concentra sulla parte centrale di questo schema, ovvero sul processo di trarre conclusioni sul modello a partire dai dati osservati. I due principali approcci all‚Äôinferenza statistica sono:\nNell‚Äôapproccio bayesiano, l‚Äôinferenza statistica si basa sull‚Äôintegrazione di informazioni a priori riguardo al vettore dei parametri \\(\\mathbf{\\theta}\\), spesso rappresentate da una densit√† di probabilit√† \\(f(\\mathbf{\\theta})\\), nota come distribuzione a priori. Questo permette di trattare \\(\\mathbf{\\theta}\\) come un vettore aleatorio ai fini computazionali. L‚Äôinferenza su \\(\\mathbf{\\theta}\\) viene condotta analizzando la densit√† di probabilit√† condizionata \\(f(\\mathbf{\\theta} \\mid \\mathbf{x})\\), nota come distribuzione a posteriori.\nIl teorema di Bayes fornisce il fondamento matematico per questa inferenza:\n\\[\nf(\\mathbf{\\theta} \\mid \\mathbf{x}) = \\frac{f(\\mathbf{x} \\mid \\mathbf{\\theta}) f(\\mathbf{\\theta})}{f(\\mathbf{x})},\n\\]\ndove:\nQuesto approccio fornisce un quadro rigoroso per aggiornare le nostre credenze alla luce di nuove evidenze, un aspetto fondamentale sia nel ragionamento scientifico che nelle decisioni quotidiane.\nNel resto di questo capitolo, esploreremo in dettaglio i principali elementi dell‚Äôapproccio bayesiano all‚Äôinferenza statistica, partendo da un semplice esempio introduttivo. Approfondiremo il processo di aggiornamento bayesiano, un meccanismo formale che consente di combinare nuove osservazioni con conoscenze pregresse in modo coerente e sistematico.\nPer contrasto, nella statistica frequentista, il vettore dei dati \\(\\mathbf{x}\\) √® interpretato come il risultato di un vettore aleatorio \\(\\mathbf{X}\\), descritto da un modello probabilistico. Solitamente, il modello √® definito fino a un parametro (multidimensionale) \\(\\mathbf{\\theta}\\), espresso come \\(\\mathbf{X} \\sim f(\\cdot; \\mathbf{\\theta})\\). L‚Äôinferenza statistica si focalizza quindi sul modello stesso e, in particolare, sul parametro \\(\\mathbf{\\theta}\\). Ad esempio, sulla base dei dati, si potrebbe voler:\nUna differenza chiave tra i due approcci risiede proprio nell‚Äôuso di informazioni a priori: mentre la statistica bayesiana le incorpora esplicitamente attraverso la distribuzione a priori \\(f(\\mathbf{\\theta})\\), la statistica frequentista si basa esclusivamente sui dati osservati \\(\\mathbf{x}\\).\nL‚Äôinferenza frequentista sar√† esaminata in una sezione successiva della dispensa, mentre questo capitolo si concentrer√† sull‚Äôapproccio bayesiano, evidenziandone la potenza e la flessibilit√† nel contesto della modellizzazione statistica. In particolare, vedremo come l‚Äôapproccio bayesiano consenta di integrare informazioni diverse (ad esempio, dati storici o esperti) in modo naturale, fornendo risultati interpretabili sotto forma di distribuzioni di probabilit√†.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>¬† <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_bayesian_inference.html#introduzione",
    "href": "chapters/bayesian_inference/04_bayesian_inference.html#introduzione",
    "title": "47¬† Inferenza bayesiana",
    "section": "",
    "text": "statistica bayesiana;\n\nstatistica frequentista.\n\n\n\n\n\n\n\n\\(f(\\mathbf{x} \\mid \\mathbf{\\theta})\\) √® la funzione di verosimiglianza, che descrive la probabilit√† (o densit√†) dei dati \\(\\mathbf{x}\\) dato il parametro \\(\\mathbf{\\theta}\\);\n\n\n\\(f(\\mathbf{\\theta})\\) √® la distribuzione a priori, che codifica le nostre conoscenze o credenze iniziali su \\(\\mathbf{\\theta}\\);\n\n\n\\(f(\\mathbf{x})\\) √® la marginal likelihood (o evidenza), che agisce come una costante di normalizzazione e dipende solo dai dati osservati \\(\\mathbf{x}\\).\n\n\n\n\n\n\nstimare il parametro, ad esempio calcolando un estimatore \\(\\hat{\\mathbf{\\theta}}\\);\n\n\neseguire test statistici sul parametro, valutando ipotesi specifiche riguardo a \\(\\mathbf{\\theta}\\).\n\n\n\n\n\n\n\n\n\nCaratteristica\nStatistica Bayesiana\nStatistica Frequentista\n\n\n\nInterpretazione del parametro\n\n\\(\\mathbf{\\theta}\\) √® un vettore aleatorio\n\n\\(\\mathbf{\\theta}\\) √® una quantit√† fissa\n\n\nUso delle informazioni a priori\n\nIncorporate esplicitamente\nNon utilizzate\n\n\nObiettivo principale\nAggiornare la distribuzione a posteriori\n\nStima e test sul parametro\n\n\nInferenza\nProbabilistica\nBasata sulla frequenza degli eventi\n\n\n\n\n\n47.1.1 L‚ÄôInferenza Bayesiana\nNella scienza, cos√¨ come nella vita quotidiana, spesso ci troviamo a valutare ipotesi con diversi gradi di credibilit√†. Ad esempio, consideriamo la domanda su quale nazione vincer√† il Campionato Mondiale di Calcio del 2026. Potremmo ritenere la Grecia un candidato molto improbabile, l‚ÄôInghilterra non del tutto implausibile, e l‚ÄôItalia, la Francia o la Germania come favoriti. Questo esempio illustra che lo stato epistemico di un‚Äôipotesi non √® una questione di ‚Äúvero o falso‚Äù, ma piuttosto di gradazione. √à qui che entra in gioco l‚Äôapproccio bayesiano: i bayesiani utilizzano il concetto di grado di credenza per descrivere gli atteggiamenti epistemici riguardo a proposizioni incerte, e rappresentano questi gradi di credenza attraverso una struttura matematica specifica: le funzioni di probabilit√†. Questi due presupposti modellistici sono gli elementi centrali dell‚Äôinferenza bayesiana. In sintesi, i bayesiani interpretano le probabilit√† come espressioni di incertezza soggettiva, un‚Äôinterpretazione che risale a Thomas Bayes (1701‚Äì1761).\nLa funzione di probabilit√† non solo assegna gradi di credenza a singole proposizioni, ma anche a combinazioni logiche di proposizioni (ad esempio, congiunzioni, disgiunzioni e negazioni). Tuttavia, per semplicit√†, concentriamoci su una singola proposizione. Consideriamo un esempio tratto dalla psicologia cognitiva, in cui una teoria afferma che ‚Äúl‚Äôesposizione a stimoli positivi migliora l‚Äôumore‚Äù. Questa proposizione pu√≤ essere rappresentata come:\n\n\n\\(A\\): ‚ÄúL‚Äôesposizione a stimoli positivi migliora l‚Äôumore.‚Äù\n\nAttraverso l‚Äôinferenza bayesiana, possiamo assegnare un grado di credenza iniziale (a priori) a questa proposizione, basandoci su conoscenze pregresse o evidenze preliminari. Ad esempio, potremmo iniziare con una probabilit√† iniziale:\n\n\n\\(p(A) = 0.7\\): crediamo che l‚Äôesposizione a stimoli positivi migliori l‚Äôumore con una probabilit√† del 70%.\n\nSupponiamo ora di condurre un esperimento in cui i partecipanti esposti a stimoli positivi mostrano un significativo miglioramento dell‚Äôumore. Alla luce di questi nuovi dati, possiamo aggiornare la nostra credenza utilizzando il teorema di Bayes. Se i dati supportano fortemente la proposizione \\(A\\), la probabilit√† a posteriori \\(p(A \\mid \\text{dati})\\) potrebbe aumentare, ad esempio, a 0.9.\nQuesto processo di aggiornamento bayesiano ci permette di affinare le nostre credenze in modo dinamico, integrando nuove evidenze empiriche con le conoscenze pregresse. In questo modo, l‚Äôinferenza bayesiana non solo quantifica l‚Äôincertezza, ma fornisce anche un quadro chiaro e sistematico per valutare la validit√† di singole proposizioni all‚Äôinterno di una teoria scientifica, sia in psicologia che in altre discipline.\n\n47.1.2 Argomenti a Favore della Probabilit√† come Misura di Credenza\nL‚Äôinterpretazione della probabilit√† come misura quantitativa dei gradi di credenza soggettivi √® sostenuta da tre principali linee di argomentazione, ciascuna delle quali fornisce una giustificazione teorica e pratica per l‚Äôadozione delle regole probabilistiche nella modellazione delle credenze. Tali argomenti provengono dai domini delle decisioni, della coerenza e dell‚Äôepistemologia.\n\n47.1.2.1 Argomenti della Scommessa Olandese (Dutch Book)\nGli argomenti della scommessa olandese costituiscono una dimostrazione formale del fatto che gradi di credenza non probabilistici portano a incoerenze logiche e vulnerabilit√† economiche. Se un individuo assegna gradi di credenza che violano gli assiomi della probabilit√† (ad esempio, la regola della somma per eventi mutuamente esclusivi), √® possibile costruire un insieme di scommesse (un ‚ÄúDutch Book‚Äù) che garantisce una perdita certa, indipendentemente dall‚Äôesito degli eventi (Ramsey, 1926; De Finetti, 1972).\nFormalmente, se \\(p(A)\\) rappresenta il grado di credenza di un evento \\(A\\) e non rispetta le leggi della probabilit√† (ad esempio, \\(p(A \\cup B) \\neq p(A) + p(B)\\) per eventi mutuamente esclusivi \\(A\\) e \\(B\\)), esiste una combinazione di scommesse che sfrutta questa incoerenza per generare una perdita sicura. La coerenza probabilistica protegge da tali situazioni di perdita certa, che sono considerate irrazionali.\n\n47.1.2.2 Argomenti Decisionistici\nGli argomenti basati sulla teoria della decisione razionale dimostrano che l‚Äôadozione di gradi di credenza probabilistici √® una condizione necessaria per massimizzare l‚Äôutilit√† attesa, un principio cardine delle scelte razionali (Savage, 1954; von Neumann & Morgenstern, 1947). Secondo questa teoria, un agente razionale assegna probabilit√† agli eventi per rappresentare il proprio grado di fiducia e combina tali probabilit√† con una funzione di utilit√† che riflette le proprie preferenze, al fine di scegliere l‚Äôalternativa che offre il massimo beneficio atteso.\nQuando i gradi di credenza non rispettano le regole della probabilit√†, l‚Äôagente non √® in grado di calcolare correttamente l‚Äôutilit√† attesa. Ci√≤ pu√≤ portare a incoerenze decisionali, come preferenze cicliche o scelte subottimali che contraddicono gli obiettivi dell‚Äôagente. Ad esempio,\n\nuna violazione della regola della somma (ad esempio, \\(p(A \\cup B) \\neq p(A) + p(B)\\) per eventi mutuamente esclusivi) pu√≤ comportare l‚Äôassegnazione di risorse in modo inefficiente tra opzioni alternative;\nuna violazione della regola del prodotto (ad esempio, \\(p(A \\cap B) \\neq p(A) \\cdot p(B)\\) per eventi indipendenti) pu√≤ indurre l‚Äôagente a sottostimare o sovrastimare i rischi associati a decisioni complesse.\n\nQueste incoerenze non solo compromettono la razionalit√† formale dell‚Äôagente, ma lo espongono a decisioni che possono portano a esiti non ottimali.\nIn sintesi, la coerenza probabilistica non √® un semplice requisito tecnico, ma un presupposto indispensabile affinch√© un agente possa agire in modo razionale e allineare le proprie decisioni agli obiettivi di massimizzazione dell‚Äôutilit√† attesa.\n\n47.1.2.3 Argomenti Epistemici\nGli argomenti epistemici si concentrano sulla relazione tra i gradi di credenza e la verit√†, sostenendo che le credenze probabilistiche rappresentano il modo pi√π razionale per minimizzare l‚Äôinaccuratezza epistemica rispetto alla realt√† (Cox, 1946). L‚Äôinaccuratezza epistemica pu√≤ essere definita come una misura della discrepanza tra il grado di credenza assegnato a una proposizione e il suo valore di verit√† oggettivo (ad esempio, 1 se la proposizione √® vera, 0 se √® falsa). In altre parole, l‚Äôinaccuratezza epistemica quantifica quanto una credenza si discosta dalla realt√†.\nLa minimizzazione dell‚Äôinaccuratezza epistemica richiede l‚Äôadozione di credenze probabilistiche che rispettino i principi fondamentali della teoria della probabilit√†. Studi condotti da autori come Joyce (1998, 2009) e Pettigrew (2016) dimostrano che le funzioni di probabilit√† sono l‚Äôunica struttura matematica in grado di minimizzare l‚Äôinaccuratezza media rispetto a un‚Äôampia gamma di possibili stati del mondo. In altre parole, le credenze probabilistiche non solo sono coerenti, ma sono anche ottimali nel ridurre l‚Äôerrore epistemico.\nIn sintesi, anche se ciascun argomento, preso singolarmente, non √® sufficiente a giustificare in modo definitivo l‚Äôapproccio probabilistico, insieme formano un quadro robusto a favore dell‚Äôutilizzo della probabilit√† come misura di credenza razionale. Questi principi costituiscono il fondamento dell‚Äôinferenza bayesiana, che rappresenta un approccio potente per modellare il ragionamento e il processo decisionale scientifico.\n\n47.1.3 Il Paradigma dell‚ÄôInferenza Bayesiana\nL‚Äôinferenza bayesiana si basa sull‚Äôidea che la probabilit√† misuri il grado di certezza soggettiva riguardo a un‚Äôipotesi o alla plausibilit√† di un valore per un parametro sconosciuto. Il cuore di questo approccio √® l‚Äôaggiornamento continuo: le credenze iniziali (priori) vengono riviste alla luce di nuove informazioni provenienti dai dati, producendo credenze aggiornate (posteriori).\nPer comprendere meglio questo processo, √® necessario introdurre due concetti chiave: il modello generativo dei dati e il parametro.\n\n47.1.3.1 Modello Generativo dei Dati\nUn modello generativo dei dati √® una rappresentazione matematica che descrive come i dati osservati potrebbero essere generati da un processo sottostante. In altre parole, √® un‚Äôastrazione che specifica le relazioni tra le variabili osservabili (i dati) e le variabili non osservabili (i parametri). Il modello generativo ci permette di simulare dati ipotetici e di fare previsioni su ci√≤ che potremmo osservare in base a determinate ipotesi.\nAd esempio, nel contesto del lancio di una moneta, il modello generativo potrebbe essere basato sulla distribuzione binomiale, che descrive la probabilit√† di ottenere un certo numero di ‚Äúteste‚Äù in un dato numero di lanci, assumendo una certa probabilit√† di successo (in questo caso, la probabilit√† di ottenere ‚Äútesta‚Äù).\n\n47.1.3.2 Parametro\nUn parametro √® una quantit√† sconosciuta che caratterizza il modello generativo. Nel caso del lancio della moneta, il parametro di interesse √® la probabilit√† \\(\\theta\\) di ottenere ‚Äútesta‚Äù. Questo parametro √® ci√≤ che vogliamo stimare o inferire attraverso l‚Äôosservazione dei dati. In generale, i parametri possono rappresentare diverse caratteristiche del processo generativo, come medie, varianze, coefficienti di regressione, ecc.\n\n47.1.3.3 Applicazione all‚ÄôEsempio del Lancio della Moneta\nOra che abbiamo introdotto i concetti di modello generativo dei dati e parametro, possiamo applicarli all‚Äôesempio del lancio della moneta. Immaginiamo di lanciare una moneta 10 volte e osservare 8 teste (\\(y = 8\\)). Vogliamo stabilire se la moneta sia equilibrata (\\(\\theta = 0.5\\)) o meno.\nPer rispondere a questa domanda, definiamo un modello generativo dei dati utilizzando la distribuzione binomiale, che √® caratterizzata dal parametro \\(\\theta\\), la probabilit√† di ottenere ‚Äútesta‚Äù. La distribuzione binomiale descrive la probabilit√† di osservare un certo numero di successi (in questo caso, ‚Äúteste‚Äù) in un numero fisso di prove indipendenti, assumendo un valore specifico per \\(\\theta\\).\nIn questo contesto, il parametro \\(\\theta\\) √® l‚Äôoggetto della nostra inferenza. Vogliamo aggiornare la nostra credenza iniziale su \\(\\theta\\) (ad esempio, che la moneta sia equilibrata, quindi \\(\\theta = 0.5\\)) alla luce dei nuovi dati osservati (8 teste su 10 lanci). Questo aggiornamento avviene attraverso l‚Äôapplicazione del teorema di Bayes, che combina la nostra credenza a priori, descritta da una distribuzione a priori e indicata come \\(p(\\theta)\\), con la verosimiglianza dei dati osservati per produrre una credenza a posteriori su \\(\\theta\\), descritta dalla distribuzione a posteriori e denotata come \\(p(\\theta \\mid \\text{dati})\\).\nLa distribuzione a priori, \\(p(\\theta)\\), riflette ci√≤ che riteniamo plausibile prima di osservare i dati. Quando raccogliamo nuove informazioni, rivediamo le nostre credenze, ridistribuendo la credibilit√† su tutto il range di valori possibili del parametro. Questo processo di aggiornamento produce la distribuzione a posteriori, \\(p(\\theta \\mid \\text{dati})\\), che rappresenta la nostra credenza aggiornata (Gelman et al., 1995).\nUn aspetto filosofico e matematico distintivo dell‚Äôapproccio bayesiano √® la concezione del parametro d‚Äôinteresse come una variabile casuale che pu√≤ assumere valori differenti, anzich√© come un valore fisso (come avviene nel paradigma frequentista). Questa prospettiva permette di trattare il parametro come una distribuzione, fornendo una rappresentazione pi√π flessibile delle incertezze (Kruschke, 2014). Ad esempio, se tracciassimo la distribuzione a posteriori, l‚Äôasse \\(x\\) rappresenterebbe l‚Äôintero intervallo di valori possibili per il parametro, mentre l‚Äôasse \\(y\\) indicherebbe la densit√† di probabilit√† associata a ciascun valore. Il valore ‚Äúutilizzabile‚Äù pi√π credibile √® spesso quello che massimizza la distribuzione (moda), o la sua media o mediana.\n\n47.1.4 Approccio Classico: Massima Verosimiglianza\nNel contesto classico, uno dei metodi pi√π utilizzati per stimare \\(\\theta\\) √® la massima verosimiglianza, che stima \\(\\theta\\) come il rapporto tra successi e tentativi: \\(\\hat{\\theta} = y/N = 0.8\\). Sebbene semplice, questa stima puntuale non fornisce informazioni sull‚Äôincertezza di \\(\\theta\\) n√© sulla plausibilit√† di valori alternativi. In altre parole, non ci dice quanto sia plausibile che \\(\\theta\\) sia, ad esempio, 0.7 o 0.9, n√© quantifica l‚Äôincertezza associata alla stima.\n\n47.1.5 Approccio Bayesiano: Priori e Posteriori\nL‚Äôapproccio bayesiano supera i limiti dell‚Äôapproccio classico basato sulla massima verosimiglianza, offrendo un quadro pi√π completo e flessibile per l‚Äôaggiornamento delle credenze. Questo risultato √® reso possibile dal teorema di Bayes, che formalizza il processo di integrazione tra le informazioni iniziali (rappresentate dalla distribuzione a priori) e le nuove evidenze fornite dai dati osservati. Attraverso questo meccanismo, l‚Äôapproccio bayesiano non solo fornisce stime puntuali, ma quantifica anche l‚Äôincertezza associata ai parametri, permettendo una valutazione pi√π robusta e informata delle ipotesi. L‚Äôequazione fondamentale √®:\n\\[\np(\\theta \\mid \\text{dati}) = \\frac{p(\\theta) \\cdot p(\\text{dati} \\mid \\theta)}{p(\\text{dati})},\n\\]\ndove:\n\n\n\\(p(\\theta)\\) √® la distribuzione a priori, che rappresenta ci√≤ che sappiamo del parametro prima di osservare i dati.\n\n\\(p(\\text{dati} \\mid \\theta)\\) √® la verosimiglianza, che descrive la probabilit√† di osservare i dati dati i valori ipotizzati del parametro.\n\n\\(p(\\text{dati})\\) √® la probabilit√† marginale dei dati, che funge da costante di normalizzazione per garantire che la distribuzione a posteriori sia una distribuzione di probabilit√† valida.\n\nLa distribuzione a posteriori \\(p(\\theta \\mid \\text{dati})\\) riflette la combinazione delle credenze iniziali con le informazioni derivanti dai dati osservati.\nEsempio: Moneta con \\(y = 8\\) e \\(N = 10\\). Supponiamo di adottare una distribuzione a priori uniforme su \\([0, 1]\\), che attribuisce la stessa plausibilit√† a tutti i valori di \\(p\\). Osservando \\(y = 8\\) teste su \\(N = 10\\) lanci, la verosimiglianza \\(p(y \\mid \\theta)\\) sar√† determinata dal modello binomiale:\n\\[\np(y \\mid \\theta) = \\binom{N}{y} p^y (1-p)^{N-y}.\n\\]\nCombinando prior e verosimiglianza attraverso il teorema di Bayes otteniamo:\n\\[\np(\\theta \\mid y) \\propto p(y \\mid \\theta) \\cdot p(\\theta).\n\\]\nLa distribuzione a posteriori risultante ci consente di:\n\n\nCalcolare stime plausibili di \\(\\theta\\), come la mediana o la moda.\n\nQuantificare l‚Äôincertezza su \\(\\theta\\), ad esempio tramite varianza o intervalli di credibilit√†.\n\nQuesto processo fornisce un quadro completo che integra informazioni iniziali e nuove evidenze, superando i limiti delle stime puntuali della massima verosimiglianza. Ad esempio, se la distribuzione a posteriori √® concentrata attorno a \\(\\theta = 0.8\\), possiamo concludere che √® plausibile che la moneta sia sbilanciata a favore di ‚Äútesta‚Äù. Tuttavia, l‚Äôintervallo di credibilit√† (ad esempio, \\([0.6, 0.95]\\)) ci fornisce anche una misura dell‚Äôincertezza associata a questa stima.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>¬† <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_bayesian_inference.html#unintroduzione-ai-priori",
    "href": "chapters/bayesian_inference/04_bayesian_inference.html#unintroduzione-ai-priori",
    "title": "47¬† Inferenza bayesiana",
    "section": "\n47.2 Un‚Äôintroduzione ai Priori",
    "text": "47.2 Un‚Äôintroduzione ai Priori\nCi√≤ che distingue l‚Äôapproccio bayesiano da quello basato sulla massima verosimiglianza √® l‚Äôuso esplicito di credenze iniziali riguardo al fenomeno di interesse. Nel linguaggio bayesiano, queste credenze sono formalizzate come distribuzioni di probabilit√†, chiamate distribuzioni a priori. Le distribuzioni a priori rappresentano la nostra conoscenza o le nostre ipotesi su un parametro o un‚Äôipotesi prima di osservare i dati. Esse forniscono un punto di partenza per l‚Äôinferenza, permettendo di incorporare informazioni pregresse nel processo di analisi.\nA seconda del grado di conoscenza o incertezza che abbiamo prima di raccogliere i dati, le distribuzioni a priori possono assumere forme diverse. Questa variabilit√† riflette il livello di fiducia o informazione iniziale e influenza in modo significativo il modo in cui le nuove evidenze vengono integrate nel processo di aggiornamento bayesiano. La scelta della distribuzione a priori √® quindi un aspetto cruciale, poich√© determina come le credenze iniziali interagiscono con i dati osservati per produrre la distribuzione a posteriori, ovvero la nostra credenza aggiornata.\n\n47.2.1 Priori Non Informativi\nCome suggerisce il nome, i priori non informativi (Flat Priors) sono generalmente privi di informazioni specifiche. Esistono diverse tipologie di distribuzioni a priori non informative, ma la loro distinzione dettagliata esula dallo scopo di questa trattazione. Sono spesso definiti flat priors perch√© la loro funzione di densit√† di probabilit√† appare come una linea orizzontale quando rappresentata graficamente. Questa distribuzione, classificata come uniforme, assegna la stessa probabilit√† a tutti i possibili valori del parametro, riflettendo cos√¨ un‚Äôignoranza totale riguardo al parametro (Gelman et al., 1995).\nIn generale, l‚Äôuso di priori non informativi √® sconsigliato, a meno che non si abbia effettivamente nessuna conoscenza preliminare o convinzione riguardo ai valori probabili del parametro (Johnson et al., 2022; McElreath, 2020). Infatti, in alcuni casi, l‚Äôuso di un prior non informativo porta a una distribuzione a posteriori identica alla funzione di verosimiglianza, con stime dei parametri indistinguibili da quelle ottenute con l‚Äôapproccio frequentista della massima verosimiglianza. Di conseguenza, l‚Äôadozione di un‚Äôinferenza bayesiana in tali contesti potrebbe essere non giustificata, poich√© il concetto di priors √® centrale nella statistica bayesiana.\n\n47.2.2 Priori Debolmente Informativi\nSpesso non abbiamo una conoscenza precisa del parametro d‚Äôinteresse, ma solo un‚Äôidea generale o vincoli noti (ad esempio, l‚Äôassociazione positiva tra ore di studio e punteggio in un test di matematica). In tali situazioni, possiamo utilizzare priori debolmente informativi (anche detti vaguely informative o default priors). Questi prior incorporano informazioni generali o vincoli sul parametro senza influenzare in modo eccessivo i risultati della posteriori.\nI priori debolmente informativi (Default Priors) rappresentano un compromesso tra l‚Äôintegrazione di conoscenze pregresse e l‚Äôevitare bias significativi, permettendo ai dati di ‚Äúdominare‚Äù i risultati (Gelman et al., 2021). Sono particolarmente utili quando le informazioni preliminari sono limitate o quando si desidera ridurre al minimo l‚Äôimpatto di credenze iniziali forti.\n\n47.2.3 Priori Informativi\nDiversamente dai priori debolmente informativi o non informativi, i priori informativi trasmettono informazioni deliberate e specifiche sul parametro d‚Äôinteresse. Questi priori si basano su conoscenze consolidate, risultati di studi precedenti o opinioni di esperti (Falconer et al., 2022) e hanno un‚Äôinfluenza maggiore sulla distribuzione a posteriori rispetto ai priori default o flat.\nI priori informativi sono particolarmente utili in presenza di campioni ridotti, poich√© restringono lo spazio credibile del parametro e consentono intervalli di incertezza pi√π stretti (Kruschke, 2014). Tuttavia, richiedono una definizione accurata, basata su evidenze solide.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>¬† <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_bayesian_inference.html#costante-di-normalizzazione-e-priori-coniugati",
    "href": "chapters/bayesian_inference/04_bayesian_inference.html#costante-di-normalizzazione-e-priori-coniugati",
    "title": "47¬† Inferenza bayesiana",
    "section": "\n47.3 Costante di Normalizzazione e Priori Coniugati",
    "text": "47.3 Costante di Normalizzazione e Priori Coniugati\nNell‚Äôequazione del teorema di Bayes:\n\\[\np(\\theta \\mid \\text{dati}) = \\frac{p(\\theta) \\cdot p(\\text{dati} \\mid \\theta)}{p(\\text{dati})},\n\\]\nla costante di normalizzazione, indicata come \\(p(\\text{dati})\\), rappresenta la probabilit√† complessiva di osservare i dati, indipendentemente dal valore specifico del parametro \\(\\theta\\). Questo termine garantisce che la distribuzione a posteriori sia una distribuzione di probabilit√† valida, cio√® che la somma (o l‚Äôintegrale) delle probabilit√† sia uguale a 1. In altre parole, la costante di normalizzazione ‚Äúaggiusta‚Äù la distribuzione risultante affinch√© sia coerente con le regole della probabilit√†.\nCalcolare \\(p(\\text{dati})\\) pu√≤ essere complesso, poich√© richiede di considerare tutte le possibili combinazioni di dati e valori del parametro. Tuttavia, in molti casi pratici, non √® necessario calcolarla esplicitamente, poich√© la forma della distribuzione a posteriori pu√≤ essere dedotta direttamente dal prodotto tra la distribuzione a priori e la verosimiglianza, a meno di una costante.\n\n47.3.1 Priori Coniugati\nI priori coniugati sono una scelta specifica di distribuzione a priori che, quando combinata con una determinata verosimiglianza, produce una distribuzione a posteriori della stessa famiglia. Questa propriet√† semplifica notevolmente i calcoli, rendendo l‚Äôaggiornamento bayesiano pi√π efficiente dal punto di vista computazionale.\nEsempio: Se la verosimiglianza √® binomiale e la distribuzione a priori √® una Beta, la distribuzione a posteriori sar√† ancora una Beta. Questo caso √® particolarmente utile, ad esempio, quando si studia la probabilit√† di successo in una serie di prove (come il lancio di una moneta).\nVantaggi dei Priori Coniugati:\n\n\nCalcolo diretto: La distribuzione a posteriori pu√≤ essere determinata analiticamente senza metodi numerici complessi.\n\nEfficienza computazionale: Ideale per modelli semplici e ben definiti.\n\nLimitazioni:\n\nApplicabile solo a modelli specifici e semplici.\nNon adatto a situazioni con dati complessi o modelli ad alta dimensionalit√†.\n\n47.3.2 Metodi Approssimativi\nQuando i priori coniugati non sono applicabili o il modello √® troppo complesso per soluzioni analitiche, si ricorre a metodi numerici approssimativi. Uno dei pi√π utilizzati √® il Markov-Chain Monte Carlo (MCMC), una tecnica di campionamento casuale che permette di stimare la distribuzione a posteriori anche in casi complessi.\nVantaggi dei Metodi Approssimativi:\n\n\nFlessibilit√†: Possono gestire modelli complessi e dati reali con molte variabili.\n\nPrecisione: Forniscono stime accurate della distribuzione a posteriori, anche in assenza di soluzioni analitiche.\n\nSvantaggi:\n\n\nCosto computazionale: Richiedono pi√π tempo e risorse rispetto ai metodi analitici.\n\nComplessit√† implementativa: Possono richiedere una maggiore attenzione nella scelta dei parametri e nella validazione dei risultati.\n\nIn sintesi, la scelta tra approccio analitico e numerico dipende dalla complessit√† del problema e dalle risorse disponibili. Mentre i priori coniugati e i metodi analitici sono ideali per modelli semplici, i metodi numerici come l‚ÄôMCMC offrono la flessibilit√† necessaria per affrontare problemi pi√π complessi. In ogni caso, l‚Äôobiettivo √® sempre lo stesso: aggiornare le nostre credenze in modo rigoroso e sistematico, integrando nuove evidenze con le conoscenze pregresse.\n\n47.3.3 Approfondimenti sull‚ÄôMCMC e Altri Metodi Numerici\nQuando i modelli diventano troppo complessi per essere risolti analiticamente, l‚Äôapproccio bayesiano si affida a metodi numerici per approssimare la distribuzione a posteriori. Uno dei metodi pi√π potenti e diffusi √® il Markov-Chain Monte Carlo (MCMC), che permette di campionare dalla distribuzione a posteriori anche in assenza di soluzioni esatte. Questo metodo √® particolarmente utile quando i priori coniugati non sono applicabili o quando il modello coinvolge molte variabili e parametri.\n\n47.3.3.1 Cos‚Äô√® l‚ÄôMCMC?\nL‚ÄôMCMC √® una famiglia di algoritmi che generano una sequenza di campioni (una ‚Äúcatena‚Äù) dalla distribuzione a posteriori. Ogni campione rappresenta un possibile valore del parametro di interesse, e i campioni successivi dipendono dai precedenti, come i collegamenti di una catena. Con un numero sufficiente di iterazioni, questa catena converge alla distribuzione a posteriori, permettendo di stimarne forma, centro e variabilit√†.\nCome funziona l‚ÄôMCMC? - Metropolis-Hastings: Questo algoritmo √® adatto a distribuzioni generiche. Richiede la definizione di una ‚Äúfunzione proposta‚Äù che suggerisce nuovi valori per il parametro, che vengono poi accettati o rifiutati in base a una regola probabilistica. - Gibbs Sampling: Questo metodo √® particolarmente efficace quando le distribuzioni condizionali dei parametri sono note, anche se la distribuzione congiunta √® complessa. In pratica, si campiona iterativamente da ciascuna distribuzione condizionale, aggiornando un parametro alla volta.\nPratiche comuni in MCMC: - Warm-up (o burn-in): All‚Äôinizio dell‚Äôalgoritmo, i campioni vengono scartati per permettere alla catena di stabilizzarsi e raggiungere la distribuzione target. Questa fase √® cruciale per evitare che i campioni iniziali, spesso non rappresentativi, influenzino i risultati. - Thinning: Per ridurre l‚Äôautocorrelazione tra i campioni, si seleziona solo uno ogni n campioni (ad esempio, ogni 5¬∞ campione). Questo migliora l‚Äôefficienza e l‚Äôindipendenza dei campioni utilizzati per l‚Äôanalisi.\n\n47.3.3.2 Altri Metodi Numerici\nOltre all‚ÄôMCMC, esistono altri metodi numerici per approssimare la distribuzione a posteriori, ciascuno con i propri vantaggi e svantaggi:\n\n\nVariational Bayes: Questo approccio approssima la distribuzione a posteriori risolvendo un problema di ottimizzazione, minimizzando la divergenza di Kullback-Leibler tra una distribuzione proposta \\(q(z)\\) e la distribuzione reale \\(p(z \\mid x)\\). √à pi√π veloce dell‚ÄôMCMC ma meno preciso, soprattutto per distribuzioni complesse.\n\nApprossimazione di Laplace: Questo metodo semplifica la distribuzione a posteriori approssimandola con una distribuzione normale centrata sul valore MAP (Maximum A Posteriori). √à utile per modelli semplici ma meno accurato per distribuzioni non gaussiane.\n\nVantaggi e Svantaggi degli Approcci Numerici: - Vantaggi: - Applicabilit√† a modelli complessi e ad alta dimensionalit√†. - Flessibilit√† nell‚Äôincorporare informazioni a priori dettagliate. - Svantaggi: - Richiedono risorse computazionali elevate. - Necessitano di un tuning accurato degli algoritmi (ad esempio, scelte iniziali in MCMC).\n\n47.3.4 Linguaggi di Programmazione Probabilistica (PPL)\nPer semplificare l‚Äôimplementazione dei metodi numerici, sono stati sviluppati linguaggi di programmazione probabilistica (PPL). Questi strumenti automatizzano il processo di inferenza bayesiana, permettendo ai ricercatori di concentrarsi sulla modellizzazione mentre il PPL gestisce l‚Äôinferenza sottostante.\n\n47.3.4.1 PPL pi√π Diffusi\n\n\nStan: Un linguaggio efficiente e flessibile, ampiamente utilizzato in ambito accademico per la sua capacit√† di gestire modelli complessi.\n\nPyMC: Una libreria user-friendly per Python, ideale per chi preferisce un approccio pi√π accessibile.\n\nTensorFlow Probability: Combina modellizzazione probabilistica e apprendimento automatico, offrendo strumenti avanzati per l‚Äôinferenza bayesiana.\n\nI PPL consentono di definire il modello probabilistico in modo intuitivo e delegare l‚Äôinferenza agli algoritmi numerici sottostanti, come MCMC o inferenza variazionale. Questo rende l‚Äôinferenza bayesiana pi√π accessibile e applicabile a una vasta gamma di problemi, inclusi quelli in psicologia, biologia, economia e scienze sociali.\n\n47.3.5 Notazione nei Modelli Bayesiani\nNella formulazione dei modelli bayesiani, √® comune utilizzare una notazione standard per descrivere le relazioni tra dati, parametri e distribuzioni. Ecco un esempio di come viene strutturata un‚Äôequazione bayesiana:\n\n\n\\(y\\): Dati osservati.\n\n\\(\\theta\\): Parametri sconosciuti.\n\n\\(x\\): Quantit√† note (ad esempio, predittori o variabili esplicative).\n\nEsempio di Modello: Supponiamo di voler modellare un insieme di dati \\(y\\) come provenienti da una distribuzione normale con media \\(\\mu\\) e deviazione standard \\(\\sigma\\). Le distribuzioni a priori per \\(\\mu\\) e \\(\\sigma\\) potrebbero essere specificate come segue:\n\\[\n\\begin{aligned}\ny & \\sim \\mathrm{normal}(\\mu, \\sigma), \\\\\n\\mu & \\sim \\mathrm{normal}(0, 10), \\\\\n\\sigma & \\sim \\mathrm{normal}^+(\\sigma \\mid 0, 1),\n\\end{aligned}\n\\]\ndove il simbolo \\(\\sim\\) indica ‚Äú√® distribuito come‚Äù. La stessa espressione pu√≤ essere scritta in termini di probabilit√†:\n\\[\n\\begin{aligned}\np(y \\mid \\mu, \\sigma) & = \\mathrm{normal}(y \\mid \\mu, \\sigma), \\\\\np(\\mu) & = \\mathrm{normal}(\\mu \\mid 0, 10), \\\\\np(\\sigma) & = \\mathrm{normal}^+(\\sigma \\mid 0, 1).\n\\end{aligned}\n\\]\nQuesta notazione chiarisce come i dati e i parametri siano collegati attraverso distribuzioni di probabilit√†, fornendo un quadro completo per l‚Äôinferenza bayesiana.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>¬† <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_bayesian_inference.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/04_bayesian_inference.html#riflessioni-conclusive",
    "title": "47¬† Inferenza bayesiana",
    "section": "\n47.4 Riflessioni Conclusive",
    "text": "47.4 Riflessioni Conclusive\nL‚Äôinferenza bayesiana √® un approccio potente e versatile per aggiornare le nostre credenze alla luce di nuove evidenze. La sua peculiarit√† risiede nella capacit√† di rispondere a una domanda fondamentale per la ricerca scientifica: qual √® la probabilit√† dei parametri (o delle ipotesi) dati i dati osservati? Questo concetto, noto come probabilit√† inversa, √® il cuore dell‚Äôapproccio bayesiano e lo distingue dall‚Äôinferenza frequentista, che si concentra invece sulla probabilit√† dei dati condizionata ai parametri.\nIl teorema di Bayes formalizza questa intuizione, permettendoci di calcolare la distribuzione a posteriori \\(p(\\theta \\mid D)\\), che rappresenta la nostra credenza aggiornata sui parametri \\(\\theta\\) dopo aver osservato i dati \\(D\\):\n\\[\np(\\theta \\mid D) = \\frac{p(D \\mid \\theta) \\cdot p(\\theta)}{p(D)}.\n\\]\nQuesta equazione mostra come, partendo da un modello generativo \\(p(D \\mid \\theta)\\) dei dati osservati e combinando questo con una distribuzione a priori \\(p(\\theta)\\), sia possibile inferire la distribuzione a posteriori \\(p(\\theta \\mid D)\\). Questo processo di aggiornamento consente di integrare in modo rigoroso e sistematico nuove evidenze con conoscenze pregresse.\nUna stima puntuale comunemente utilizzata nell‚Äôinferenza bayesiana √® il Massimo A Posteriori (MAP), ovvero il valore di \\(\\theta\\) che massimizza la distribuzione a posteriori:\n\\[\n\\theta^* = \\arg \\max_\\theta p(\\theta \\mid D).\n\\]\nNel caso di un prior non informativo (una distribuzione a priori piatta), la stima MAP coincide con la stima di massima verosimiglianza (MLE), che massimizza la probabilit√† dei dati osservati. Tuttavia, in presenza di informazioni a priori rilevanti e ben specificate, la stima MAP combina i dati osservati con le credenze iniziali, fornendo una stima pi√π robusta e informata.\nLa forza dell‚Äôapproccio bayesiano risiede nella sua capacit√† di affrontare diverse sfide:\n\n\nIncertezza delle ipotesi: In contesti come la psicologia, la medicina o le scienze sociali, dove le ipotesi sono spesso incerte, l‚Äôinferenza bayesiana permette di valutarne la plausibilit√†.\n\nDati limitati o rumorosi: Quando i dati sono scarsi o affetti da rumore, l‚Äôapproccio bayesiano garantisce stime pi√π robuste integrando informazioni a priori.\n\nConfronto tra ipotesi complesse: L‚Äôapproccio bayesiano consente di confrontare e valutare ipotesi multiple in modo rigoroso.\n\nIl teorema di Bayes offre un quadro formale per quantificare l‚Äôincertezza e aggiornare le credenze in modo dinamico. Questo √® particolarmente utile in situazioni in cui:\n\nLe informazioni a priori sono cruciali per guidare l‚Äôinferenza.\n√à necessario un compromesso tra conoscenze pregresse e nuove evidenze.\nI problemi analizzati sono complessi e richiedono strumenti avanzati.\n\nPer modelli semplici, i priori coniugati e i metodi analitici possono essere sufficienti. Tuttavia, per problemi pi√π complessi, l‚Äôuso di strumenti numerici come l‚ÄôMCMC (Markov Chain Monte Carlo) e i linguaggi di programmazione probabilistica (PPL) √® indispensabile. Questi strumenti consentono di applicare l‚Äôapproccio bayesiano a scenari realistici, superando le limitazioni computazionali e garantendo maggiore flessibilit√†.\nIn conclusione, l‚Äôinferenza bayesiana non √® solo un metodo statistico, ma un paradigma che trasforma il modo di pensare alla scienza e alla conoscenza. Essa permette di formulare domande scientificamente rilevanti, di quantificare l‚Äôincertezza e di aggiornare le credenze in modo rigoroso. Attraverso il teorema di Bayes, possiamo passare dalla domanda ‚Äúqual √® la probabilit√† dei dati dati i parametri?‚Äù alla domanda pi√π interessante: ‚Äúqual √® la probabilit√† dei parametri dati i dati?‚Äù\nQuesta inversione di prospettiva, unita agli strumenti computazionali moderni, rende l‚Äôapproccio bayesiano uno strumento indispensabile per la ricerca scientifica contemporanea. In un‚Äôepoca caratterizzata da dati complessi e incertezze diffuse, il paradigma bayesiano si pone come una guida affidabile per comprendere meglio il mondo attraverso l‚Äôanalisi rigorosa e l‚Äôaggiornamento continuo delle nostre credenze.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>¬† <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_bayesian_inference.html#esercizi",
    "href": "chapters/bayesian_inference/04_bayesian_inference.html#esercizi",
    "title": "47¬† Inferenza bayesiana",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n\nQual √® la differenza principale tra l‚Äôapproccio bayesiano e l‚Äôapproccio frequentista all‚Äôinferenza statistica?\nCosa rappresenta la distribuzione a priori in inferenza bayesiana e quale ruolo svolge nel processo inferenziale?\nCome si calcola la distribuzione a posteriori in inferenza bayesiana e quali sono i suoi elementi principali?\nQual √® il significato della funzione di verosimiglianza nel teorema di Bayes?\nCome viene interpretata la probabilit√† nell‚Äôapproccio bayesiano rispetto a quello frequentista?\nQuali sono i vantaggi principali dell‚Äôinferenza bayesiana rispetto all‚Äôinferenza frequentista?\nCos‚Äô√® una distribuzione a priori coniugata e quali vantaggi offre nel calcolo della distribuzione a posteriori?\nQuali sono i principali metodi numerici utilizzati per approssimare la distribuzione a posteriori quando i calcoli analitici non sono possibili?\nCosa sono i modelli generativi dei dati e quale ruolo svolgono nell‚Äôinferenza bayesiana?\nQuali sono le tre principali giustificazioni teoriche per l‚Äôuso delle probabilit√† come misura di credenza nell‚Äôinferenza bayesiana?\n\nConsegna: Rispondi con parole tue e carica il file .qmd, convertito in PDF su Moodle.\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n\nLa differenza principale tra l‚Äôapproccio bayesiano e quello frequentista riguarda l‚Äôinterpretazione del parametro \\(\\theta\\). Nell‚Äôapproccio bayesiano, il parametro √® considerato una variabile aleatoria con una distribuzione a priori, mentre nell‚Äôapproccio frequentista il parametro √® una quantit√† fissa e sconosciuta. Inoltre, l‚Äôinferenza bayesiana aggiorna le credenze attraverso il teorema di Bayes, mentre l‚Äôinferenza frequentista basa le proprie conclusioni solo sui dati osservati.\nLa distribuzione a priori rappresenta le credenze iniziali riguardo al parametro \\(\\theta\\) prima di osservare i dati. Essa consente di integrare informazioni pregresse o conoscenze esterne nel processo inferenziale, influenzando la distribuzione a posteriori e permettendo di aggiornare le credenze alla luce di nuove evidenze.\n\nLa distribuzione a posteriori si calcola applicando il teorema di Bayes:\n\\[\nf(\\theta \\mid x) = \\frac{f(x \\mid \\theta) f(\\theta)}{f(x)}\n\\]\nI suoi elementi principali sono:\n\nLa funzione di verosimiglianza \\(f(x \\mid \\theta)\\), che esprime la probabilit√† di osservare i dati dato un valore del parametro.\n\nLa distribuzione a priori \\(f(\\theta)\\), che rappresenta le credenze iniziali sul parametro.\n\nLa costante di normalizzazione \\(f(x)\\), che garantisce che la distribuzione a posteriori sia una distribuzione di probabilit√† valida.\n\n\nLa funzione di verosimiglianza, \\(f(x \\mid \\theta)\\), rappresenta la probabilit√† di osservare i dati dati i valori del parametro \\(\\theta\\). Essa √® fondamentale nel teorema di Bayes perch√© determina quanto bene un certo valore di \\(\\theta\\) spiega i dati osservati, contribuendo alla determinazione della distribuzione a posteriori.\nNell‚Äôapproccio bayesiano, la probabilit√† √® interpretata come un grado di credenza soggettivo su un evento o un parametro incerto. Nell‚Äôapproccio frequentista, invece, la probabilit√† √® definita come il limite della frequenza relativa di un evento dopo un numero infinito di ripetizioni. Questo porta a differenze metodologiche nel modo in cui vengono effettuate le inferenze.\n\nI principali vantaggi dell‚Äôinferenza bayesiana sono:\n\n\nIntegrazione di informazioni pregresse: Permette di combinare dati osservati con conoscenze precedenti.\n\n\nQuantificazione dell‚Äôincertezza: Fornisce una distribuzione completa dei parametri, anzich√© un singolo valore stimato.\n\n\nFlessibilit√†: Pu√≤ essere applicata a modelli complessi e a problemi con pochi dati.\n\n\nInterpretazione intuitiva: Le probabilit√† risultanti rappresentano direttamente il grado di credenza sui parametri.\n\n\nUna distribuzione a priori coniugata √® una scelta specifica di distribuzione a priori che, quando combinata con una verosimiglianza di una certa famiglia, produce una distribuzione a posteriori della stessa famiglia. Ad esempio, una distribuzione Beta come prior per un parametro binomiale produce una distribuzione Beta come a posteriori. Questo semplifica enormemente i calcoli, poich√© la distribuzione a posteriori pu√≤ essere determinata in modo analitico senza necessit√† di metodi numerici complessi.\n\nQuando non √® possibile calcolare la distribuzione a posteriori in modo analitico, si utilizzano metodi numerici come:\n\n\nMarkov Chain Monte Carlo (MCMC): Un insieme di algoritmi di campionamento (ad esempio, Metropolis-Hastings e Gibbs Sampling) che permette di stimare la distribuzione a posteriori generando campioni iterativi.\n\n\nInferenza Variazionale: Un metodo di approssimazione che ottimizza una distribuzione pi√π semplice per avvicinarsi alla distribuzione a posteriori.\n\n\nApprossimazione di Laplace: Un‚Äôapprossimazione basata sulla normalizzazione locale intorno al massimo a posteriori (MAP).\n\n\nUn modello generativo dei dati √® una rappresentazione matematica del processo che ha generato i dati osservati. Esso definisce la relazione tra il parametro sconosciuto \\(\\theta\\) e i dati \\(\\mathbf{x}\\) attraverso una distribuzione di probabilit√†. Nell‚Äôinferenza bayesiana, il modello generativo aiuta a formulare la funzione di verosimiglianza e a inferire i parametri che meglio spiegano i dati.\nLe tre principali giustificazioni per l‚Äôuso delle probabilit√† come misura di credenza nell‚Äôinferenza bayesiana sono:\n\n\n\nArgomento della scommessa olandese (Dutch Book): Se i gradi di credenza non rispettano le regole della probabilit√†, si possono costruire scommesse che garantiscono una perdita certa, dimostrando che √® irrazionale non seguire le leggi della probabilit√†.\n\n\nArgomento decisionistico: Per massimizzare l‚Äôutilit√† attesa nelle scelte razionali, i gradi di credenza devono seguire le regole della probabilit√†. Se non lo fanno, si possono prendere decisioni incoerenti o subottimali.\n\n\nArgomento epistemico: Le funzioni di probabilit√† minimizzano l‚Äôerrore epistemico rispetto alla verit√† oggettiva, rendendole la struttura pi√π razionale per rappresentare le credenze in condizioni di incertezza.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>¬† <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_bayesian_inference.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/04_bayesian_inference.html#informazioni-sullambiente-di-sviluppo",
    "title": "47¬† Inferenza bayesiana",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.5.3     \n#&gt;  [9] scales_1.3.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.9.1   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         rlang_1.1.5       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       tools_4.4.2       parallel_4.4.2    tzdb_0.5.0       \n#&gt; [21] colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5       R6_2.6.1         \n#&gt; [25] lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.1    \n#&gt; [29] gtable_0.3.6      glue_1.8.0        xfun_0.51         tidyselect_1.2.1 \n#&gt; [33] rstudioapi_0.17.1 farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-167     \n#&gt; [37] rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>¬† <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_bayesian_inference.html#bibliografia",
    "href": "chapters/bayesian_inference/04_bayesian_inference.html#bibliografia",
    "title": "47¬† Inferenza bayesiana",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAlter, U., Too, M. A., & Cribbie, R. A. (2025). Navigating the Bayes maze: The psychologist‚Äôs guide to Bayesian statistics, a hands-on tutorial with R code. International Journal of Psychology, 60(1), e13271.\n\n\nFalconer, J. R., Frank, E., Polaschek, D. L., & Joshi, C. (2022). Methods for eliciting informative prior distributions: A critical review. Decision Analysis, 19(3), 189‚Äì204.\n\n\nGelman, A., Carlin, J. B., Stern, H. S., & Rubin, D. B. (1995). Bayesian data analysis. Chapman; Hall/CRC.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other stories. Cambridge University Press.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nKruschke, J. (2014). Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan. Academic Press.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>¬† <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_subj_prop.html",
    "href": "chapters/bayesian_inference/05_subj_prop.html",
    "title": "48¬† Pensare ad una proporzione in termini soggettivi",
    "section": "",
    "text": "48.1 Introduzione\nL‚Äôinferenza bayesiana √® un metodo di inferenza statistica che utilizza la probabilit√† per aggiornare le credenze sui parametri di un modello, sulla base di nuove evidenze o dati osservati. Essa fornisce un quadro concettuale per stimare variabili sconosciute, tenendo conto dell‚Äôincertezza. Attraverso un modello che descrive le dipendenze tra variabili aleatorie, la teoria della probabilit√† pu√≤ essere impiegata per inferire tutte le quantit√† sconosciute. In questo approccio, tutte le incertezze, sia nelle osservazioni che nei parametri del modello, sono trattate come distribuzioni di probabilit√†.\nIn sintesi, l‚Äôinferenza bayesiana √® il processo di deduzione delle propriet√† di una distribuzione di probabilit√† a partire dai dati, utilizzando il teorema di Bayes. Questo processo incorpora l‚Äôidea che la probabilit√† rappresenti una misura della fiducia su una previsione o un risultato.\nQuesto capitolo ha lo scopo di esplorare in dettaglio il concetto di aggiornamento bayesiano, illustrandolo con un esempio concreto in un contesto semplificato. L‚Äôobiettivo √® dimostrare come le credenze preesistenti sulla probabilit√† di un parametro \\(\\theta\\) possano essere aggiornate attraverso l‚Äôosservazione di nuovi dati.\nIl primo passo nell‚Äôinferenza bayesiana consiste nel rappresentare le credenze iniziali, formulate prima di raccogliere i dati, tramite una distribuzione a priori. La distribuzione a priori riflette le nostre conoscenze o ipotesi preesistenti su \\(\\theta\\) e pu√≤ variare in base al contesto o alle informazioni pregresse disponibili.\nUna volta ottenuti nuovi dati, il passaggio successivo √® l‚Äôaggiornamento delle credenze tramite la distribuzione a posteriori. Questo aggiornamento si ottiene moltiplicando la distribuzione a priori per la verosimiglianza dei dati osservati, il che riflette quanto i dati supportino un determinato valore di \\(\\theta\\). Il prodotto di questi due termini fornisce una misura delle credenze aggiornate, che viene successivamente normalizzata per garantire che il risultato sia una distribuzione di probabilit√† valida (ovvero, che l‚Äôarea sotto la curva sia pari a 1).\nIl capitolo si concentra sul modello binomiale. Questo modello √® utilizzato per stimare una proporzione sconosciuta basata su una serie di dati binari \\(y_1, \\ldots, y_n\\), ciascuno dei quali pu√≤ assumere valore 0 o 1.\nInizieremo esplorando un esempio in cui la distribuzione a priori di \\(\\theta\\) √® discreta, un caso in cui i valori possibili di \\(\\theta\\) sono limitati a un insieme finito di opzioni. Successivamente, discuteremo scenari in cui la distribuzione a priori √® continua, ampliando il modello per affrontare casi pi√π complessi e realistici. Questo approccio progressivo consente di acquisire una comprensione graduale dei concetti centrali dell‚Äôinferenza bayesiana e del loro utilizzo pratico nel contesto di problemi statistici reali.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_subj_prop.html#introduzione",
    "href": "chapters/bayesian_inference/05_subj_prop.html#introduzione",
    "title": "48¬† Pensare ad una proporzione in termini soggettivi",
    "section": "",
    "text": "L‚Äôunica cosa rilevante √® l‚Äôincertezza ‚Äì il grado della nostra conoscenza e ignoranza. Il fatto che gli eventi considerati siano in qualche modo determinati, o conosciuti da altre persone, non ha alcuna importanza.\n‚Äî Bruno deFinetti",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_subj_prop.html#verosimiglianza-binomiale",
    "href": "chapters/bayesian_inference/05_subj_prop.html#verosimiglianza-binomiale",
    "title": "48¬† Pensare ad una proporzione in termini soggettivi",
    "section": "\n48.2 Verosimiglianza Binomiale",
    "text": "48.2 Verosimiglianza Binomiale\nLa distribuzione binomiale offre un modello naturale per dati che derivano da una sequenza di \\(n\\) prove indipendenti e identicamente distribuite, dove ciascuna prova d√† origine a uno dei due possibili esiti, convenzionalmente etichettati come ‚Äòsuccesso‚Äô e ‚Äòfallimento‚Äô. Grazie al fatto che le prove sono iid, i dati possono essere riassunti dal numero totale di successi nelle \\(n\\) prove, che denotiamo con \\(y\\). Il parametro \\(\\theta\\) rappresenta la proporzione di successi nella popolazione o, equivalentemente, la probabilit√† di successo in ciascuna prova. Il modello di campionamento binomiale √®:\n\\[\np(y \\mid \\theta) = \\text{Bin}(y \\mid n, \\theta) = \\binom{n}{y} \\theta^y (1 - \\theta)^{n-y},\n\\]\ndove nella parte sinistra dell‚Äôequazione non si indica la dipendenza da \\(n\\) perch√© viene considerato parte del disegno sperimentale e fissato; tutte le probabilit√† discusse per questo problema sono considerate condizionate su \\(n\\), cio√® assumono che il numero totale di prove sia fissato e noto.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_subj_prop.html#applicazione-specifica-del-modello-binomiale",
    "href": "chapters/bayesian_inference/05_subj_prop.html#applicazione-specifica-del-modello-binomiale",
    "title": "48¬† Pensare ad una proporzione in termini soggettivi",
    "section": "\n48.3 Applicazione Specifica del Modello Binomiale",
    "text": "48.3 Applicazione Specifica del Modello Binomiale\nIn questo capitolo, esaminiamo un‚Äôapplicazione specifica del modello binomiale per valutare la prestazione di un partecipante in un classico esperimento di psicologia, noto come Go/No-Go task (Shiffrin & Schneider, 1977). In questo tipo di compito, ai partecipanti viene richiesto di rispondere a determinati stimoli (prove Go) e di trattenere la risposta ad altri stimoli (prove No-Go). Ad esempio, i partecipanti possono vedere una serie di lettere presentate su uno schermo e devono premere un pulsante quando vedono qualsiasi lettera tranne una specifica lettera bersaglio (ad esempio, la lettera ‚ÄúX‚Äù). In questo esperimento, ogni prova rappresenta un evento di tipo bernoulliano con due possibili esiti: o il partecipante risponde correttamente o commette un errore. I ricercatori analizzano la percentuale di risposte corrette e di inibizioni, concentrandosi in particolare sulla capacit√† del partecipante di controllare l‚Äôimpulso di rispondere durante le prove No-Go.\nConsideriamo un piccolo numero di prove No-Go di un partecipante, dove i risultati sono: 1, 0, 1, 1, 1, 0, 1, 0, 1. Qui, il valore ‚Äú1‚Äù indica che il partecipante √® stato in grado di inibire la risposta, mentre ‚Äú0‚Äù indica che non √® riuscito a farlo. L‚Äôobiettivo dell‚Äôanalisi √® quantificare l‚Äôincertezza nella stima di \\(\\theta\\), che rappresenta la proporzione di risposte corrette nel compito No-Go, ovvero la capacit√† inibitoria del partecipante.\nConsideriamo questi dati come una sequenza di 9 prove bernoulliane indipendenti. Utilizzando il modello binomiale, stimiamo la probabilit√† \\(\\theta\\) che il partecipante riesca a controllare il proprio impulso di rispondere durante le prove No-Go e quantifichiamo l‚Äôincertezza associata a questa stima.\n\n48.3.1 Flusso di Lavoro Bayesiano\nMcElreath (2020) descrive il flusso di lavoro bayesiano nel modo seguente.\n\n\nDefinizione di un Modello Generativo per i Dati\nUn modello generativo rappresenta il processo attraverso cui i dati vengono prodotti. Per esempio, nel caso di un compito No-Go, ogni prova pu√≤ essere considerata come un esperimento di tipo Bernoulli, che pu√≤ produrre due possibili risultati:\n\n\nSuccesso: inibizione della risposta corretta (rappresentata da 1).\n\n\nErrore: mancata inibizione della risposta (rappresentata da 0).\n\nDenotiamo con \\(\\theta\\) la probabilit√† di inibire correttamente la risposta. Il modello generativo √® quindi formalizzato come:\n\\[\nX_i \\sim \\text{Bernoulli}(\\theta),\n\\]\ndove \\(i = 1, 2, \\dots, 9\\) indica le prove eseguite, e \\(X_i\\) rappresenta l‚Äôesito di ciascuna prova.\n\n\nDefinizione di uno Stimatore per il Parametro di Interesse\nLo stimatore √® uno strumento che ci permette di calcolare una stima del parametro di interesse (in questo caso \\(\\theta\\)) basandoci sui dati raccolti.\n\n\n\\(\\theta\\) rappresenta la probabilit√† di successo, ovvero di inibire correttamente la risposta.\n\nOltre a stimare \\(\\theta\\), √® importante quantificare l‚Äôincertezza della stima utilizzando i dati a disposizione.\n\n\n\nSviluppo di un Metodo Statistico per la Stima di \\(\\theta\\)\nUtilizziamo un approccio bayesiano per stimare \\(\\theta\\). Questo approccio combina:\n\n\nUna distribuzione a priori: rappresenta le convinzioni iniziali su \\(\\theta\\). Scegliamo una distribuzione Beta \\(\\text{Beta}(1, 1)\\), che corrisponde a una distribuzione uniforme, per indicare che non abbiamo informazioni iniziali preferenziali.\n\n\nLa verosimiglianza: rappresenta quanto i dati osservati siano compatibili con diversi valori di \\(\\theta\\). Per 6 successi e 3 errori, la verosimiglianza √® data da una distribuzione binomiale:\\[\nL(\\theta) = {9 \\choose 6} \\theta^{6} (1-\\theta)^{3}.\n\\]\n\n\nLa distribuzione a posteriori: si ottiene aggiornando la distribuzione a priori con i dati osservati, tramite il teorema di Bayes:\\[\n\\text{Posteriore} \\propto \\text{Verosimiglianza} \\times \\text{Priori}.\n\\]\n\n\n\n\nValidazione del Modello Tramite Simulazioni\nPrima di applicare il modello ai dati reali, verifichiamo che il modello sia realistico attraverso:\n\n\nSimulazioni predittive a priori: servono per controllare se il modello √® in grado di generare dati plausibili.\n\n\nSimulazioni predittive a posteriori: valutano se il modello, una volta adattato ai dati osservati, pu√≤ riprodurre risultati simili a quelli effettivamente ottenuti.\n\n\n\nAnalisi e Sintesi dei Risultati\nUna volta adattato il modello ai dati reali:\n\nUtilizziamo metodi computazionali come il Monte Carlo a catene di Markov (MCMC) per calcolare la distribuzione a posteriori.\n\nRiassumiamo i risultati tramite statistiche descrittive, come media, mediana e intervalli di credibilit√†, per fare inferenze su \\(\\theta\\).\n\n\n\nIn questo capitolo, mostreremo come calcolare numericamente la distribuzione a posteriori di \\(\\theta\\). Nei capitoli successivi esploreremo in dettaglio ogni fase del flusso di lavoro bayesiano descritto da McElreath (2020).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_subj_prop.html#metodo-basato-su-griglia-nellaggiornamento-bayesiano",
    "href": "chapters/bayesian_inference/05_subj_prop.html#metodo-basato-su-griglia-nellaggiornamento-bayesiano",
    "title": "48¬† Pensare ad una proporzione in termini soggettivi",
    "section": "\n48.4 Metodo Basato su Griglia nell‚ÄôAggiornamento Bayesiano",
    "text": "48.4 Metodo Basato su Griglia nell‚ÄôAggiornamento Bayesiano\nDopo aver discusso l‚Äôaggiornamento bayesiano e come permette di raffinare le nostre convinzioni preesistenti alla luce di nuove evidenze, esploreremo ora una tecnica specifica per realizzare questo aggiornamento: il metodo basato su griglia.\nIl metodo basato su griglia √® un approccio semplice e intuitivo per stimare la distribuzione a posteriori, particolarmente utile quando non sono disponibili soluzioni analitiche esatte o si desidera evitare l‚Äôuso di algoritmi computazionali complessi. La procedura si articola nei seguenti passi:\n\n\nSelezione di un intervallo per il parametro: Basandosi sulle convinzioni a priori, si definisce un intervallo ragionevole per il parametro di interesse.\n\nCreazione di una griglia di punti: Su questo intervallo, si distribuiscono una serie di punti, di solito equidistanti tra loro.\n\nCalcolo della posteriori per ogni punto: Per ogni punto della griglia, si moltiplica la verosimiglianza per il prior corrispondente.\n\nNormalizzazione dei risultati: Per garantire che la somma delle probabilit√† sia pari a 1, si normalizzano i valori ottenuti dividendo ciascun punto per l‚Äôarea totale sottesa dalla curva della distribuzione a posteriori.\n\nAttraverso questo metodo, si ottiene una rappresentazione approssimativa ma illustrativa della distribuzione a posteriori. Questo approccio offre un modo accessibile per visualizzare e comprendere il processo di aggiornamento bayesiano.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-discreta",
    "href": "chapters/bayesian_inference/05_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-discreta",
    "title": "48¬† Pensare ad una proporzione in termini soggettivi",
    "section": "\n48.5 Aggiornamento Bayesiano con una Distribuzione a Priori Discreta",
    "text": "48.5 Aggiornamento Bayesiano con una Distribuzione a Priori Discreta\n\n48.5.1 Distribuzione a priori\nQuando non disponiamo di informazioni specifiche preliminari su \\(\\theta\\), potremmo inizialmente assegnare un valore di 0.5, suggerendo una probabilit√† a priori uniforme tra le due alternative (la capacit√† di inibire la risposta e la mancanza di questa capacit√† in una prova del compito Go/No-Go). Tuttavia, questo valore non rappresenta adeguatamente l‚Äôintero spettro della nostra incertezza iniziale.\nPer riflettere meglio questa incertezza, utilizziamo una distribuzione a priori discreta, che assegna una probabilit√† distinta a ciascun valore plausibile di \\(\\theta\\). Questo approccio ci permette di quantificare le nostre convinzioni preliminari sulla distribuzione di questi valori.\nSupponiamo di considerare undici possibili valori per \\(\\theta\\), che variano da 0 a 1 con incrementi di 0.1. Possiamo attribuire a ciascun valore una probabilit√† a priori uguale, creando cos√¨ una distribuzione uniforme, oppure scegliere una distribuzione non uniforme che meglio rifletta le nostre aspettative sui valori di \\(\\theta\\) pi√π probabili.\nDopo aver osservato i dati ‚Äî nel nostro caso, 6 successi in 9 prove ‚Äî applichiamo il teorema di Bayes per trasformare la distribuzione a priori in una distribuzione a posteriori. Questo processo consiste nel combinare la probabilit√† a priori di \\(\\theta\\) con la verosimiglianza dei dati per produrre una probabilit√† a posteriori aggiornata per \\(\\theta\\).\n\n48.5.2 Distribuzione a Posteriori\nLa distribuzione a posteriori combina le informazioni a priori con i dati osservati, aggiornando le nostre credenze riguardo al parametro \\(\\theta\\). Vediamo passo passo come implementare il calcolo della distribuzione a posteriori e delle relative quantit√† in R, partendo dalla rappresentazione discreta di \\(\\theta\\).\n\n48.5.2.1 1. Definizione di \\(\\theta\\)\n\nIniziamo definendo un insieme discreto di valori per \\(\\theta\\).\n\ntheta &lt;- seq(0, 1, by = 0.1)\ntheta\n#&gt;  [1] 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0\n\n\n48.5.2.2 2. Distribuzione a Priori Uniforme\nSe non abbiamo motivi per preferire alcuni valori di \\(\\theta\\), assegniamo probabilit√† uguali a tutti i valori, \\(\\theta \\sim \\mathcal{Uniform}(0, 1)\\).\n\nunif_prior_not_norm &lt;- rep(1, length(theta))\nprint(unif_prior_not_norm)\n#&gt;  [1] 1 1 1 1 1 1 1 1 1 1 1\n\nStandardizziamo la distribuzione affinch√© le probabilit√† si sommino a 1.\n\nunif_prior &lt;- unif_prior_not_norm / length(theta)\nprint(unif_prior)\n#&gt;  [1] 0.09091 0.09091 0.09091 0.09091 0.09091 0.09091 0.09091 0.09091 0.09091\n#&gt; [10] 0.09091 0.09091\n\nVerifichiamo.\n\nsum(unif_prior) # Verifica che le probabilit√† sommino a 1\n#&gt; [1] 1\n\nVisualizziamo questa distribuzione a priori uniforme:\n\nggplot(data.frame(theta, unif_prior), aes(x = theta, y = unif_prior)) +\n  geom_segment(aes(xend = theta, yend = 0), linetype = \"solid\", linewidth = 1.2) +\n  labs(\n    title = \"Distribuzione a Priori (Uniforme)\",\n    x = expression(theta),\n    y = \"Probabilit√†\"\n  )\n\n\n\n\n\n\n\n\n48.5.2.3 3. Distribuzione a Priori Non Uniforme\nSe riteniamo pi√π probabili i valori centrali di \\(\\theta\\), definiamo una distribuzione a priori discreta non uniforme:\n\ntheta &lt;- seq(0, 1, length.out = 11)\n\nnot_unif_prior &lt;-\n  c(0, 0.05, 0.05, 0.05, 0.175, 0.175, 0.175, 0.175, 0.05, 0.05, 0.05)\n\ndata.frame(theta, not_unif_prior) |&gt;\n  ggplot(\n    aes(x = theta, y = not_unif_prior)\n  ) +\n  geom_segment(\n    aes(xend = theta, yend = 0),\n    linetype = \"solid\", linewidth = 1.2\n  ) +\n  labs(\n    title = \"Distribuzione a Priori (Non Uniforme)\",\n    x = expression(theta),\n    y = \"Probabilit√†\"\n  )\n\n\n\n\n\n\n\n\nsum(not_unif_prior) # Verifica che le probabilit√† sommino a 1\n#&gt; [1] 1\n\n\n48.5.2.4 4. Calcolo della Verosimiglianza\nLa funzione di verosimiglianza per il modello binomiale, \\(y \\sim \\mathcal{Binomial}(n, \\theta)\\), √® definita in R nel modo seguente:\n\nlikelihood &lt;- dbinom(6, size = 9, prob = theta)\n\nNormalizziamo.\n\nlikelihood &lt;- likelihood / sum(likelihood) \n\n\ndata.frame(theta, likelihood) |&gt;\n  ggplot(\n    aes(x = theta, y = likelihood)\n  ) +\n  geom_segment(\n    aes(xend = theta, yend = 0),\n    linetype = \"solid\", linewidth = 1.2\n  ) +\n  labs(\n    title = \"Funzione di Verosimiglianza\",\n    x = expression(theta),\n    y = expression(L(theta))\n  )\n\n\n\n\n\n\n\n\n48.5.2.5 5. Distribuzione a Posteriori\nLa distribuzione a posteriori, \\(Pr(\\theta \\mid y)\\), si calcola moltiplicando elemento per elemento la distribuzione a priori e la verosimiglianza, quindi dividendo per la probabilit√† marginale dei dati (normalizzazione).\n\npost_not_norm &lt;- (not_unif_prior * likelihood) \nprint(post_not_norm)\n#&gt;  [1] 0.00000000 0.00000306 0.00013754 0.00104951 0.01299717 0.02869228\n#&gt;  [7] 0.04386543 0.04666454 0.00880231 0.00223060 0.00000000\n\nNormalizziamo.\n\npost &lt;- post_not_norm / sum(post_not_norm)\nprint(post)\n#&gt;  [1] 0.00000000 0.00002118 0.00095219 0.00726597 0.08998163 0.19864159\n#&gt;  [7] 0.30368799 0.32306667 0.06093994 0.01544284 0.00000000\n\nVerifica che la distribuzione a posteriori sommi a 1.\n\nsum(post) \n#&gt; [1] 1\n\nVisualizziamo la distribuzione a posteriori.\n\ndata.frame(theta, post) |&gt;\n  ggplot(\n    aes(x = theta, y = post)\n  ) +\n  geom_segment(\n    aes(xend = theta, yend = 0),\n    linetype = \"solid\", linewidth = 1.2\n  ) +\n  labs(\n    title = \"Distribuzione a Posteriori\",\n    x = expression(theta),\n    y = expression(f(theta))\n  )\n\n\n\n\n\n\n\n\n48.5.2.6 6. Quantit√† a Posteriori\n\n\nMedia a Posteriori: Calcolata come il valore atteso di \\(\\theta\\) sotto la distribuzione a posteriori.\n\n\nposterior_mean &lt;- sum(theta * post)\nposterior_mean\n#&gt; [1] 0.6087\n\n\n\nVarianza a Posteriori: Calcolata come la varianza della distribuzione a posteriori.\n\n\nposterior_variance &lt;- sum((theta^2) * post) - posterior_mean^2\nposterior_variance\n#&gt; [1] 0.01338\n\n\n\nModa a Posteriori: Il valore di \\(\\theta\\) con la probabilit√† pi√π alta.\n\n\nposterior_mode &lt;- theta[which.max(post)]\nposterior_mode\n#&gt; [1] 0.7\n\nIn sintesi, abbiamo calcolato la distribuzione a posteriori di \\(\\theta\\) utilizzando una distribuzione a priori discreta non uniforme e osservando 6 successi su 9 prove. Abbiamo derivato quantit√† statistiche come media, varianza e moda a posteriori. Questo processo dimostra come l‚Äôinferenza bayesiana aggiorni le credenze a priori in base ai dati osservati, offrendo una visione quantitativamente informata del parametro \\(\\theta\\).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-continua",
    "href": "chapters/bayesian_inference/05_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-continua",
    "title": "48¬† Pensare ad una proporzione in termini soggettivi",
    "section": "\n48.6 Aggiornamento Bayesiano con una Distribuzione a Priori Continua",
    "text": "48.6 Aggiornamento Bayesiano con una Distribuzione a Priori Continua\nPassiamo ora all‚Äôaggiornamento bayesiano utilizzando una distribuzione a priori continua, in particolare la distribuzione Beta. Questo approccio √® particolarmente utile poich√© consente di rappresentare \\(\\theta\\) come una variabile continua definita nell‚Äôintervallo [0, 1].\n\n48.6.1 Definizione della Distribuzione Beta\nIniziamo con una distribuzione Beta simmetrica, Beta(2, 2), e calcoliamo la sua densit√† di probabilit√† su un intervallo continuo di valori \\(\\theta\\).\n\n# Parametri della distribuzione Beta\nalpha &lt;- 2\nbeta &lt;- 2\n\n# Valori di theta\ntheta &lt;- seq(0, 1, length.out = 1000)\n\n# Densit√† di probabilit√† della distribuzione Beta\npdf &lt;- dbeta(theta, alpha, beta)\n\n# Grafico della distribuzione Beta\ndata.frame(theta, pdf) |&gt;\n  ggplot(\n    aes(x = theta, y = pdf)\n  ) +\n  geom_line(linewidth = 1.2) +\n  labs(\n    title = \"Funzione di Densit√† di Probabilit√† Beta(2, 2)\",\n    x = expression(theta),\n    y = \"Densit√†\"\n  )\n\n\n\n\n\n\n\n\n48.6.2 Distribuzione a Priori Non Simmetrica\nConsideriamo una distribuzione a priori non simmetrica, Beta(2, 5), per rappresentare credenze che privilegiano valori bassi di \\(\\theta\\).\n\n# Parametri della distribuzione Beta non simmetrica\nalpha &lt;- 2\nbeta &lt;- 5\n\n# Valori di theta e densit√† di probabilit√†\ntheta &lt;- seq(0, 1, length.out = 100) # Valori di theta\npdf &lt;- dbeta(theta, alpha, beta) # Densit√† di probabilit√† Beta(2, 5)\n\n# Creazione del grafico\ndata.frame(theta, pdf) |&gt;\n  ggplot(aes(x = theta, y = pdf)) +\n  geom_line(linewidth = 1.2) +\n  labs(\n    title = \"Funzione di Densit√† di Probabilit√† Beta(2, 5)\",\n    x = expression(theta),\n    y = \"Densit√†\"\n  )\n\n\n\n\n\n\n\n\n48.6.3 Verosimiglianza\nConsideriamo un esperimento con 9 prove e 6 successi, modellato con una distribuzione binomiale. Calcoliamo la funzione di verosimiglianza normalizzata.\n\n# Parametri dell'esperimento\nn &lt;- 9\nk &lt;- 6\n\n# Calcolo della verosimiglianza\nlikelihood &lt;- dbinom(k, size = n, prob = theta)\nlikelihood &lt;- likelihood / sum(likelihood) # Normalizzazione\n\n# Grafico della verosimiglianza\ndata.frame(theta, likelihood) |&gt;\n  ggplot(\n    aes(x = theta, y = likelihood)\n  ) +\n  geom_line(linewidth = 1.2) +\n  labs(\n    title = \"Funzione di Verosimiglianza\",\n    x = expression(theta),\n    y = \"Densit√†\"\n  )\n\n\n\n\n\n\n\n\n48.6.4 Distribuzione a Posteriori\nLa distribuzione a posteriori si ottiene moltiplicando la distribuzione a priori per la verosimiglianza e normalizzando il risultato.\n\n# Calcolo della distribuzione a priori Beta(2, 5)\nprior &lt;- dbeta(theta, shape1 = 2, shape2 = 5)\nprior &lt;- prior / sum(prior)\n\n# Calcolo della distribuzione a posteriori\nposterior &lt;- (prior * likelihood) / sum(prior * likelihood)\n\n\n# Uniamo tutti i dati in un dataframe per ggplot2\ndat &lt;- tibble(\n  theta,\n  prior,\n  likelihood,\n  posterior\n)\n\n# Preparazione dei dati per il plot\nlong_data &lt;- dat |&gt;\n  pivot_longer(\n    cols = c(prior, likelihood, posterior),\n    names_to = \"distribution\",\n    values_to = \"density\"\n  )\n\n# Grafico\nlong_data |&gt;\n  ggplot(aes(x = theta, y = density, color = distribution)) +\n  geom_line(size = 1.2) +\n  labs(\n    title = \"Distribuzioni Bayesiane\",\n    x = expression(theta),\n    y = \"Densit√†\"\n  ) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n48.6.5 Quantit√† a Posteriori\nCalcoliamo alcune quantit√† riassuntive dalla distribuzione a posteriori.\n\nMedia a Posteriori\n\n\nposterior_mean &lt;- sum(theta * posterior)\nposterior_mean\n#&gt; [1] 0.5\n\n\nDeviazione Standard a Posteriori\n\n\nposterior_sd &lt;- sqrt(sum((theta^2) * posterior) - posterior_mean^2)\nposterior_sd\n#&gt; [1] 0.1213\n\n\nModa a Posteriori\n\n\nposterior_mode &lt;- theta[which.max(posterior)]\nposterior_mode\n#&gt; [1] 0.4949\n\n\n48.6.6 Campionamento dalla Distribuzione a Posteriori\nPossiamo generare campioni casuali dalla distribuzione a posteriori per effettuare inferenze.\n\n# Campionamento casuale basato sul posterior\nset.seed(123)\nsamples &lt;- sample(theta, size = 10000, prob = posterior, replace = TRUE)\n\n# Creazione dell'istogramma e della curva di densit√†\ndata_frame_samples &lt;- data.frame(samples)\n\n# Grafico con ggplot\ndata_frame_samples |&gt;\n  ggplot(aes(x = samples)) +\n  geom_histogram(\n    aes(y = after_stat(density)),\n    bins = 20,\n    fill = \"gray\", color = \"black\"\n  ) +\n  geom_density(color = \"black\", size = 1.2) +\n  labs(\n    title = \"Distribuzione dei Campioni dalla Posteriori\",\n    x = expression(theta),\n    y = \"Densit√†\"\n  )\n\n\n\n\n\n\n\n\n48.6.6.1 Intervalli di Credibilit√†\nCalcoliamo l‚Äôintervallo di credibilit√† al 94%.\n\ncredible_interval &lt;- quantile(samples, probs = c(0.03, 0.97))\ncredible_interval\n#&gt;     3%    97% \n#&gt; 0.2727 0.7273\n\nSe desideriamo calcolare l‚Äôintervallo di densit√† pi√π alta (HPDI), possiamo utilizzare pacchetti aggiuntivi come HDInterval.\n\n# Calcolo HPDI (richiede il pacchetto HDInterval)\nhdi(samples, credMass = 0.94)\n#&gt;  lower  upper \n#&gt; 0.2828 0.7273 \n#&gt; attr(,\"credMass\")\n#&gt; [1] 0.94\n\nIn sintesi, questo approccio dimostra l‚Äôapplicazione del metodo bayesiano con distribuzioni a priori continue, utilizzando sia formule analitiche che campionamento. I risultati mostrano come possiamo ottenere credenze aggiornate su \\(\\theta\\) e riassumerle con quantit√† come media, moda e intervalli di credibilit√†.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_subj_prop.html#metodo-basato-su-griglia",
    "href": "chapters/bayesian_inference/05_subj_prop.html#metodo-basato-su-griglia",
    "title": "48¬† Pensare ad una proporzione in termini soggettivi",
    "section": "\n48.7 Metodo basato su griglia",
    "text": "48.7 Metodo basato su griglia\nIl metodo utilizzato in questo capitolo per generare la distribuzione a posteriori √® noto come metodo basato su griglia. Questo metodo numerico esatto si basa sul calcolo della distribuzione a posteriori mediante una griglia di punti uniformemente spaziati. Nonostante la maggior parte dei parametri sia continua, l‚Äôapprossimazione della distribuzione a posteriori pu√≤ essere ottenuta considerando soltanto una griglia finita di valori dei parametri. Il metodo segue quattro fasi:\n\nFissare una griglia discreta di possibili valori dei parametri.\nValutare la distribuzione a priori e la funzione di verosimiglianza per ciascun valore della griglia.\nCalcolare l‚Äôapprossimazione della densit√† a posteriori, ottenuta moltiplicando la distribuzione a priori per la funzione di verosimiglianza per ciascun valore della griglia e normalizzando i prodotti in modo che la loro somma sia uguale a 1.\nSelezionare \\(n\\) valori casuali dalla griglia per ottenere un campione casuale della densit√† a posteriori normalizzata.\n\nQuesto metodo pu√≤ essere potenziato aumentando il numero di punti nella griglia, ma il limite principale risiede nel fatto che all‚Äôaumentare della dimensionalit√† dello spazio dei parametri, il numero di punti necessari per una stima accurata cresce in modo esponenziale, rendendo il metodo impraticabile per problemi complessi.\nIn sintesi, l‚Äôapproccio basato sulla griglia √® intuitivo e non richiede competenze di programmazione avanzate per l‚Äôimplementazione. Inoltre, fornisce un risultato che pu√≤ essere considerato, per tutti gli scopi pratici, come un campione casuale estratto dalla distribuzione di probabilit√† a posteriori condizionata ai dati. Tuttavia, questo metodo √® limitato a causa della maledizione della dimensionalit√†1, il che significa che pu√≤ essere applicato soltanto a modelli statistici semplici con non pi√π di due parametri. Di conseguenza, in pratica, √® spesso sostituito da altre tecniche pi√π efficienti, poich√© i modelli impiegati in psicologia richiedono frequentemente la stima di centinaia o anche migliaia di parametri.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_subj_prop.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/05_subj_prop.html#riflessioni-conclusive",
    "title": "48¬† Pensare ad una proporzione in termini soggettivi",
    "section": "\n48.8 Riflessioni Conclusive",
    "text": "48.8 Riflessioni Conclusive\nIn questo capitolo, abbiamo esplorato l‚Äôaggiornamento bayesiano utilizzando una distribuzione a priori discreta, accennando brevemente al caso delle distribuzioni a priori continue. Quando si affrontano scenari con distribuzioni a priori continue, l‚Äôelaborazione della distribuzione a posteriori generalmente richiede la risoluzione di un integrale che, nella maggior parte dei casi, non ammette una soluzione analitica. Tuttavia, ci sono eccezioni notevoli, come nell‚Äôinferenza relativa alle proporzioni, dove la distribuzione a priori √® modellata come una distribuzione Beta e la funzione di verosimiglianza segue una distribuzione binomiale. In queste circostanze particolari, √® possibile derivare analiticamente la distribuzione a posteriori. L‚Äôanalisi dettagliata di questo caso sar√† trattata nel capitolo successivo.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_subj_prop.html#esercizi",
    "href": "chapters/bayesian_inference/05_subj_prop.html#esercizi",
    "title": "48¬† Pensare ad una proporzione in termini soggettivi",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nIn uno studio sull‚Äôanalisi delle pratiche di trasparenza e riproducibilit√† nella ricerca in psicologia, Hardwicke et al. (2022) hanno riportato che la condivisione dei materiali di ricerca √® stata rilevata nel 14% dei casi (26 su 183 studi), con un intervallo di confidenza al 95% pari a [10%, 19%]. Questo suggerisce che la condivisione di materiali √® rara.\nIspirandoti ai risultati di questo studio, costruisci una distribuzione a priori per la probabilit√† \\(\\theta\\) che uno studio condivida i materiali di ricerca. Per semplicit√†, discretizza \\(\\theta\\) in 10 livelli equispaziati: \\(0.05, 0.15, 0.25, 0.35, 0.45, 0.55, 0.65, 0.75, 0.85, 0.95\\).\nAttribuisci le seguenti probabilit√† a priori ai 10 livelli, basandoti sull‚Äôinformazione che la condivisione dei materiali √® un evento raro ma non trascurabile: \\(0.05, 0.20, 0.30, 0.15, 0.10, 0.08, 0.05, 0.03, 0.02, 0.02\\).\nSupponiamo che siano stati osservati 20 studi su 100 che hanno condiviso i materiali di ricerca. Calcola la distribuzione a posteriori utilizzando il metodo basato su griglia. Calcola la media della distribuzione a posteriori e l‚Äôintervallo di credibilit√† al 89%.\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\n# Definizione dei possibili valori di theta (probabilit√† discreta)\ntheta &lt;- seq(0.05, 0.95, by = 0.10)\n\n# Definizione della distribuzione a priori\nprior &lt;- c(0.05, 0.20, 0.30, 0.15, 0.10, 0.08, 0.05, 0.03, 0.02, 0.02)\n\n# Normalizzazione della prior (se necessario, ma in questo caso gi√† normalizzata)\nprior &lt;- prior / sum(prior)\n\n# Dati osservati\nsuccessi &lt;- 20  # studi che hanno condiviso materiali\nn &lt;- 100        # studi totali\n\n# Calcolo della verosimiglianza usando la distribuzione binomiale\nlikelihood &lt;- dbinom(successi, size = n, prob = theta)\n\n# Calcolo della distribuzione a posteriori (applicazione del teorema di Bayes)\nposterior &lt;- likelihood * prior\nposterior &lt;- posterior / sum(posterior)  # Normalizzazione\n\n# Calcolo della media della distribuzione a posteriori\nposterior_mean &lt;- sum(theta * posterior)\n\n# Calcolo dell'intervallo di credibilit√† al 89%\ncdf &lt;- cumsum(posterior)  # Distribuzione cumulativa\nlower_bound &lt;- theta[which.min(abs(cdf - 0.055))]  # 5.5% quantile\nupper_bound &lt;- theta[which.min(abs(cdf - 0.945))]  # 94.5% quantile\n\n# Output dei risultati\nlist(\n  posterior_mean = posterior_mean,\n  credibility_interval_89 = c(lower_bound, upper_bound)\n)\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nL‚Äôobiettivo di questo esercizio √® applicare il metodo basato su griglia per stimare la distribuzione a posteriori di una proporzione, utilizzando dati dalla Scala della Rete Sociale di Lubben (LSNS-6). Si assume che un punteggio LSNS-6 superiore a una soglia prefissata indichi isolamento sociale. Il compito √®:\n\nScegliere una soglia per classificare i partecipanti in due gruppi (isolati vs.¬†non isolati), garantendo che la proporzione osservata non sia inferiore a 0.1 o superiore a 0.9.\nCalcolare la distribuzione a posteriori della proporzione usando un‚Äôapprossimazione discreta su una griglia di valori.\nDeterminare l‚Äôintervallo di credibilit√† all‚Äô89%.\nInterpretare i risultati.\n\nConsegna: caricare su Moodle il file .qmd compilato in pdf.\n\n\n\n\n\n\n\n\n\nSoluzioni 2\n\n\n\n\n\nDati e Modellizzazione\nSi assume che i dati siano rappresentati da una variabile binaria \\(y\\), con \\(y = 1\\) per individui classificati come isolati e \\(y = 0\\) altrimenti. Supponiamo che su un campione di \\(n\\) individui, \\(s\\) siano isolati.\nDefiniamo il modello statistico:\n\\[ y_i \\sim \\text{Bernoulli}(\\theta) \\]\ncon:\n\n\n\\(y_i \\in \\{0,1\\}\\) per \\(i=1,\\dots,n\\),\n\n\\(\\theta\\) proporzione di individui isolati nella popolazione.\n\nLa distribuzione a priori su \\(\\theta\\) √® scelta come \\(\\text{Beta}(2,2)\\), che rappresenta una conoscenza iniziale moderata e non estrema.\nMetodo basato su griglia\nIl metodo a griglia approssima la distribuzione a posteriori calcolando la probabilit√† per una serie di valori discreti di \\(\\theta\\).\n\n\nDefinire una griglia di valori per \\(\\theta\\):\ntheta &lt;- seq(0, 1, length.out = 100)\n\n\nCalcolare la distribuzione a priori:\nprior &lt;- dbeta(theta, 2, 2)\nprior &lt;- prior / sum(prior)  # Normalizzazione\n\n\nCalcolare la verosimiglianza:\nlikelihood &lt;- dbinom(s, size = n, prob = theta)\nlikelihood &lt;- likelihood / sum(likelihood)  # Normalizzazione\n\n\nCalcolare la distribuzione a posteriori:\nposterior &lt;- prior * likelihood\nposterior &lt;- posterior / sum(posterior)  # Normalizzazione\n\n\n** Calcolo dell‚Äôintervallo di credibilit√† all‚Äô89%**\nL‚Äôintervallo di credibilit√† √® calcolato come l‚Äôintervallo che contiene il 89% della probabilit√† a posteriori.\nci_89 &lt;- quantile(sample(theta, size = 10000, prob = posterior, replace = TRUE), probs = c(0.055, 0.945))\nci_89\nInterpretazione dei risultati\n\n\nValore atteso e moda a posteriori:\nmean_theta &lt;- sum(theta * posterior)\nmode_theta &lt;- theta[which.max(posterior)]\n\nIl valore atteso fornisce una stima puntuale di \\(\\theta\\).\nLa moda indica il valore pi√π probabile della proporzione di isolamento sociale.\n\n\n\nIntervallo di credibilit√†:\n\nL‚Äô89% della probabilit√† a posteriori cade tra i valori dell‚Äôintervallo di credibilit√†.\nSe l‚Äôintervallo √® stretto, c‚Äô√® maggiore certezza sulla proporzione stimata.\nSe l‚Äôintervallo √® ampio, vi √® maggiore incertezza sulla proporzione.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_subj_prop.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/05_subj_prop.html#informazioni-sullambiente-di-sviluppo",
    "title": "48¬† Pensare ad una proporzione in termini soggettivi",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] HDInterval_0.2.4 thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0\n#&gt;  [5] see_0.11.0       gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1\n#&gt;  [9] psych_2.5.3      scales_1.3.0     markdown_2.0     knitr_1.50      \n#&gt; [13] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [17] purrr_1.0.4      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [21] ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.9.1   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         rlang_1.1.5       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       tools_4.4.2       parallel_4.4.2    tzdb_0.5.0       \n#&gt; [21] colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5       R6_2.6.1         \n#&gt; [25] lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.1    \n#&gt; [29] gtable_0.3.6      glue_1.8.0        xfun_0.51         tidyselect_1.2.1 \n#&gt; [33] rstudioapi_0.17.1 farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-167     \n#&gt; [37] labeling_0.4.3    rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_subj_prop.html#bibliografia",
    "href": "chapters/bayesian_inference/05_subj_prop.html#bibliografia",
    "title": "48¬† Pensare ad una proporzione in termini soggettivi",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAlbert, J., & Hu, J. (2019). Probability and Bayesian Modeling. CRC Press.\n\n\nHardwicke, T. E., Thibault, R. T., Kosie, J. E., Wallach, J. D., Kidwell, M. C., & Ioannidis, J. P. (2022). Estimating the prevalence of transparency and reproducibility-related research practices in psychology (2014‚Äì2017). Perspectives on Psychological Science, 17(1), 239‚Äì251.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nShiffrin, R. M., & Schneider, W. (1977). Controlled and automatic human information processing: II. Perceptual learning, automatic attending and a general theory. Psychological Review, 84(2), 127‚Äì190.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_subj_prop.html#footnotes",
    "href": "chapters/bayesian_inference/05_subj_prop.html#footnotes",
    "title": "48¬† Pensare ad una proporzione in termini soggettivi",
    "section": "",
    "text": "Per comprendere la maledizione della dimensionalit√†, possiamo considerare l‚Äôesempio di una griglia di 100 punti equispaziati. Nel caso di un solo parametro, sarebbe necessario calcolare solo 100 valori. Tuttavia, se abbiamo due parametri, il numero di valori da calcolare diventa \\(100^2\\). Se invece abbiamo 10 parametri, il numero di valori da calcolare sarebbe di \\(10^{10}\\). √à evidente che la quantit√† di calcoli richiesta diventa troppo grande persino per un computer molto potente. Pertanto, per modelli che richiedono la stima di un numero significativo di parametri, √® necessario utilizzare un approccio diverso.‚Ü©Ô∏é",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_grid_gauss.html",
    "href": "chapters/bayesian_inference/06_grid_gauss.html",
    "title": "49¬† Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia",
    "section": "",
    "text": "49.1 Introduzione\nIn questo capitolo, estenderemo la discussione precedente sul calcolo della distribuzione a posteriori utilizzando il metodo basato su griglia, applicandolo questa volta a un caso con verosimiglianza gaussiana. In particolare, ci concentreremo su come costruire un modello gaussiano per descrivere l‚Äôintelligenza.\nImmaginiamo di condurre uno studio sulla plusdotazione, considerando l‚Äôapproccio psicometrico. Secondo questo approccio, una persona √® considerata plusdotata se ha un QI (Quoziente Intellettivo) di 130 o superiore (Robinson, Zigler, & Gallagher, 2000). Anche se l‚Äôuso di un QI di 130 come soglia √® il criterio pi√π comune, non √® universalmente accettato. L‚Äôintelligenza nei bambini plusdotati non √® solo superiore rispetto a quella dei loro pari, ma √® qualitativamente diversa (Lubart & Zenasni, 2010). I bambini plusdotati tendono a mostrare caratteristiche come un vocabolario ampio, un linguaggio molto sviluppato, processi di ragionamento avanzati, eccellente memoria, vasti interessi, forte curiosit√†, empatia, capacit√† di leadership, abilit√† visive elevate, impegno in situazioni sfidanti e un forte senso di giustizia (Song & Porath, 2005).\nNella simulazione che seguir√†, assumeremo che i dati provengano da una distribuzione normale. Per semplicit√†, considereremo che la deviazione standard sia nota e pari a 5. Il parametro della media sar√† l‚Äôoggetto della nostra inferenza.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>¬† <span class='chapter-title'>Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_grid_gauss.html#dati",
    "href": "chapters/bayesian_inference/06_grid_gauss.html#dati",
    "title": "49¬† Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia",
    "section": "\n49.2 Dati",
    "text": "49.2 Dati\nSupponiamo di avere un campione di 10 osservazioni. I dati saranno generati casualmente da una distribuzione normale con media 130 e deviazione standard 5.\n\nset.seed(123) # Per la riproducibilit√†\nvera_media &lt;- 130 # Media vera\nsigma_conosciuta &lt;- 5 # Deviazione standard conosciuta\ndimensione_campione &lt;- 10 # Dimensione del campione\n\n# Generare un campione\ncampione &lt;- round(rnorm(n = dimensione_campione, mean = vera_media, sd = sigma_conosciuta))\ncampione\n#&gt;  [1] 127 129 138 130 131 139 132 124 127 128",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>¬† <span class='chapter-title'>Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_grid_gauss.html#griglia",
    "href": "chapters/bayesian_inference/06_grid_gauss.html#griglia",
    "title": "49¬† Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia",
    "section": "\n49.3 Griglia",
    "text": "49.3 Griglia\nCreiamo ora una griglia di 100 valori compresi tra 110 e 150.\n\nmu_griglia &lt;- seq(110, 150, length.out = 100)\nmu_griglia\n#&gt;   [1] 110.0 110.4 110.8 111.2 111.6 112.0 112.4 112.8 113.2 113.6 114.0\n#&gt;  [12] 114.4 114.8 115.3 115.7 116.1 116.5 116.9 117.3 117.7 118.1 118.5\n#&gt;  [23] 118.9 119.3 119.7 120.1 120.5 120.9 121.3 121.7 122.1 122.5 122.9\n#&gt;  [34] 123.3 123.7 124.1 124.5 124.9 125.4 125.8 126.2 126.6 127.0 127.4\n#&gt;  [45] 127.8 128.2 128.6 129.0 129.4 129.8 130.2 130.6 131.0 131.4 131.8\n#&gt;  [56] 132.2 132.6 133.0 133.4 133.8 134.2 134.6 135.1 135.5 135.9 136.3\n#&gt;  [67] 136.7 137.1 137.5 137.9 138.3 138.7 139.1 139.5 139.9 140.3 140.7\n#&gt;  [78] 141.1 141.5 141.9 142.3 142.7 143.1 143.5 143.9 144.3 144.7 145.2\n#&gt;  [89] 145.6 146.0 146.4 146.8 147.2 147.6 148.0 148.4 148.8 149.2 149.6\n#&gt; [100] 150.0",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>¬† <span class='chapter-title'>Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_grid_gauss.html#calcolo-della-verosimiglianza",
    "href": "chapters/bayesian_inference/06_grid_gauss.html#calcolo-della-verosimiglianza",
    "title": "49¬† Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia",
    "section": "\n49.4 Calcolo della Verosimiglianza",
    "text": "49.4 Calcolo della Verosimiglianza\nPer ogni valore della griglia, calcoliamo la verosimiglianza complessiva come prodotto delle densit√† di probabilit√†.\n\nlikelihood &lt;- sapply(mu_griglia, function(mu) {\n    prod(dnorm(campione, mean = mu, sd = sigma_conosciuta))\n})\nlikelihood\n#&gt;   [1] 5.288e-50 1.406e-48 3.502e-47 8.172e-46 1.786e-44 3.658e-43 7.016e-42\n#&gt;   [8] 1.261e-40 2.122e-39 3.347e-38 4.944e-37 6.842e-36 8.870e-35 1.077e-33\n#&gt;  [15] 1.226e-32 1.306e-31 1.304e-30 1.220e-29 1.069e-28 8.772e-28 6.745e-27\n#&gt;  [22] 4.858e-26 3.278e-25 2.072e-24 1.227e-23 6.807e-23 3.537e-22 1.722e-21\n#&gt;  [29] 7.852e-21 3.355e-20 1.343e-19 5.033e-19 1.768e-18 5.816e-18 1.792e-17\n#&gt;  [36] 5.175e-17 1.400e-16 3.547e-16 8.418e-16 1.872e-15 3.899e-15 7.608e-15\n#&gt;  [43] 1.391e-14 2.381e-14 3.820e-14 5.741e-14 8.082e-14 1.066e-13 1.317e-13\n#&gt;  [50] 1.524e-13 1.652e-13 1.678e-13 1.596e-13 1.423e-13 1.188e-13 9.293e-14\n#&gt;  [57] 6.809e-14 4.674e-14 3.005e-14 1.810e-14 1.022e-14 5.400e-15 2.674e-15\n#&gt;  [64] 1.240e-15 5.391e-16 2.195e-16 8.370e-17 2.990e-17 1.001e-17 3.138e-18\n#&gt;  [71] 9.215e-19 2.535e-19 6.535e-20 1.578e-20 3.569e-21 7.563e-22 1.501e-22\n#&gt;  [78] 2.791e-23 4.863e-24 7.935e-25 1.213e-25 1.737e-26 2.330e-27 2.929e-28\n#&gt;  [85] 3.448e-29 3.802e-30 3.929e-31 3.802e-32 3.447e-33 2.928e-34 2.330e-35\n#&gt;  [92] 1.736e-36 1.212e-37 7.931e-39 4.860e-40 2.790e-41 1.500e-42 7.557e-44\n#&gt;  [99] 3.566e-45 1.576e-46",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>¬† <span class='chapter-title'>Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_grid_gauss.html#calcolo-della-distribuzione-a-posteriori",
    "href": "chapters/bayesian_inference/06_grid_gauss.html#calcolo-della-distribuzione-a-posteriori",
    "title": "49¬† Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia",
    "section": "\n49.5 Calcolo della Distribuzione a Posteriori",
    "text": "49.5 Calcolo della Distribuzione a Posteriori\nImpostiamo una prior uniforme e calcoliamo la distribuzione a posteriori normalizzata.\n\nprior &lt;- rep(1, length(mu_griglia)) # Prior uniforme\nposterior_non_norm &lt;- likelihood * prior\nposterior &lt;- posterior_non_norm / sum(posterior_non_norm) # Normalizzazione\n\nVisualizzazione:\n\n# Creazione del dataframe per il plot\ndat &lt;- tibble(\n  mu_griglia = mu_griglia, # Ascissa\n  posterior = posterior    # Ordinata\n)\n\n# Grafico con ggplot2\ndat |&gt;\n  ggplot(aes(x = mu_griglia, y = posterior)) +\n  geom_line(size = 1.2) + \n  labs(\n    title = \"Distribuzione a Posteriori della Media\",\n    x = \"Media\",\n    y = \"Probabilit√†\"\n  ) +\n  theme(\n    plot.title = element_text(hjust = 0.5), # Centra il titolo\n    legend.position = \"none\" \n  )\n\n\n\n\n\n\n\n\n49.5.1 Aggiunta di una Prior Informativa\nUsiamo una prior gaussiana con media 140 e deviazione standard 3.\n\n# Calcolo prior, posterior non normalizzato e posterior\nprior &lt;- dnorm(mu_griglia, mean = 140, sd = 3)\nposterior_non_norm &lt;- likelihood * prior\nposterior &lt;- posterior_non_norm / sum(posterior_non_norm)\n\n# Creazione del dataframe per il grafico\ndat &lt;- tibble(\n  mu_griglia = mu_griglia,\n  prior = prior / sum(prior),  # Normalizzazione del prior\n  posterior = posterior        # Posterior gi√† normalizzato\n)\n\n# Preparazione dei dati in formato lungo per ggplot2\nlong_data &lt;- dat |&gt;\n  pivot_longer(\n    cols = c(prior, posterior),\n    names_to = \"distribution\",\n    values_to = \"density\"\n  )\n\n# Grafico con ggplot2\nlong_data |&gt;\n  ggplot(aes(x = mu_griglia, y = density, color = distribution, linetype = distribution)) +\n  geom_line(size = 1.2) +\n  labs(\n    title = \"Distribuzione a Posteriori e Prior della Media\",\n    x = \"Media\",\n    y = \"Densit√†\",\n    color = \"Distribuzione\",\n    linetype = \"Distribuzione\"\n  ) +\n  theme(\n    plot.title = element_text(hjust = 0.5),\n    legend.position = \"bottom\"\n  )",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>¬† <span class='chapter-title'>Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_grid_gauss.html#campionamento-dalla-posterior",
    "href": "chapters/bayesian_inference/06_grid_gauss.html#campionamento-dalla-posterior",
    "title": "49¬† Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia",
    "section": "\n49.6 Campionamento dalla Posterior",
    "text": "49.6 Campionamento dalla Posterior\nGeneriamo un campione dalla distribuzione a posteriori.\n\n# Set seed for reproducibility\nset.seed(123)\n\n# Sampling from the posterior distribution\nindice_campionato &lt;- sample(1:length(mu_griglia), size = 1000, replace = TRUE, prob = posterior)\nmedia_campionata &lt;- mu_griglia[indice_campionato]\n\n# Create a dataframe for ggplot2\nsample_df &lt;- tibble(media_campionata = media_campionata)\n\n# Histogram using ggplot2\nggplot(sample_df, aes(x = media_campionata)) +\n  geom_histogram(\n    bins = 20, \n    color = \"white\", \n    alpha = 0.8\n  ) +\n  labs(\n    title = \"Campionamento dalla Posterior\",\n    x = \"Media\",\n    y = \"Frequenza\"\n  ) +\n  theme(\n    plot.title = element_text(hjust = 0.5)\n  )\n\n\n\n\n\n\n\n\n# Media e intervallo di credibilit√†\nmean(media_campionata)\n#&gt; [1] 132.6\nquantile(media_campionata, c(0.03, 0.97))\n#&gt;    3%   97% \n#&gt; 130.2 135.5",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>¬† <span class='chapter-title'>Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_grid_gauss.html#calcolo-della-log-verosimiglianza",
    "href": "chapters/bayesian_inference/06_grid_gauss.html#calcolo-della-log-verosimiglianza",
    "title": "49¬† Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia",
    "section": "\n49.7 Calcolo della Log-Verosimiglianza",
    "text": "49.7 Calcolo della Log-Verosimiglianza\nUtilizziamo i logaritmi per migliorare la stabilit√† numerica.\n\n# Calcolo log-likelihood, log-prior e posterior\nlog_likelihood &lt;- sapply(mu_griglia, function(mu) {\n  sum(dnorm(campione, mean = mu, sd = sigma_conosciuta, log = TRUE))\n})\nlog_prior &lt;- dnorm(mu_griglia, mean = 140, sd = 3, log = TRUE)\nlog_posterior_non_norm &lt;- log_likelihood + log_prior\nlog_posterior &lt;- log_posterior_non_norm - max(log_posterior_non_norm) # Stabilizzazione numerica\nposterior &lt;- exp(log_posterior) / sum(exp(log_posterior))\n\n# Creazione del dataframe per il grafico\ndat &lt;- tibble(\n  mu_griglia = mu_griglia,\n  posterior = posterior\n)\n\n# Grafico con ggplot2\ndat |&gt;\n  ggplot(aes(x = mu_griglia, y = posterior)) +\n  geom_line(size = 1.2) + \n  labs(\n    title = \"Distribuzione a Posteriori con Log-Verosimiglianza\",\n    x = \"Media\",\n    y = \"Probabilit√†\"\n  ) +\n  theme(\n    plot.title = element_text(hjust = 0.5), # Centra il titolo\n    legend.position = \"none\"               # Rimuove la legenda per una linea singola\n  )",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>¬† <span class='chapter-title'>Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_grid_gauss.html#estensione-alla-deviazione-standard-ignota",
    "href": "chapters/bayesian_inference/06_grid_gauss.html#estensione-alla-deviazione-standard-ignota",
    "title": "49¬† Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia",
    "section": "\n49.8 Estensione alla Deviazione Standard Ignota",
    "text": "49.8 Estensione alla Deviazione Standard Ignota\nPer una griglia bidimensionale di valori di \\(\\mu\\) e \\(\\sigma\\):\n\nmu_griglia &lt;- seq(110, 150, length.out = 100)\nsigma_griglia &lt;- seq(1, 10, length.out = 50)\n\n# Create combinations of mu and sigma using expand.grid\ngrid &lt;- expand.grid(mu = mu_griglia, sigma = sigma_griglia)\n\n# Compute the log-likelihood for each combination of mu and sigma\nlog_likelihood &lt;- apply(grid, 1, function(params) {\n    mu &lt;- params[\"mu\"]\n    sigma &lt;- params[\"sigma\"]\n    sum(dnorm(campione, mean = mu, sd = sigma, log = TRUE))\n})\n\n# Reshape log-likelihood into a matrix\nlog_likelihood_2d &lt;- matrix(log_likelihood, nrow = length(mu_griglia), ncol = length(sigma_griglia))\n\n# Compute priors for mu and sigma\nlog_prior_mu &lt;- dnorm(mu_griglia, mean = 140, sd = 5, log = TRUE)\nlog_prior_sigma &lt;- dnorm(sigma_griglia, mean = 5, sd = 2, log = TRUE)\n\n# Combine priors into a grid\nlog_prior_2d &lt;- outer(log_prior_mu, log_prior_sigma, \"+\")\n\n# Compute log-posterior\nlog_posterior_2d &lt;- log_likelihood_2d + log_prior_2d\nlog_posterior_2d &lt;- log_posterior_2d - max(log_posterior_2d) # Stabilize\nposterior_2d &lt;- exp(log_posterior_2d)\nposterior_2d &lt;- posterior_2d / sum(posterior_2d) # Normalize\n\n# Convert posterior_2d to a data frame for visualization\nposterior_df &lt;- reshape2::melt(posterior_2d)\nnames(posterior_df) &lt;- c(\"mu_idx\", \"sigma_idx\", \"posterior\")\nposterior_df$mu &lt;- mu_griglia[posterior_df$mu_idx]\nposterior_df$sigma &lt;- sigma_griglia[posterior_df$sigma_idx]\n\n# Plot the posterior distribution\nggplot(posterior_df, aes(x = mu, y = sigma, fill = posterior)) +\n  geom_tile() +\n  scale_fill_viridis_c(name = \"Posterior\") +\n  labs(\n    title = \"Distribuzione a Posteriori Bidimensionale\",\n    x = expression(mu), \n    y = expression(sigma)\n  ) +\n  theme(\n    plot.title = element_text(hjust = 0.5),\n    legend.position = \"right\"\n  )",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>¬† <span class='chapter-title'>Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_grid_gauss.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/06_grid_gauss.html#riflessioni-conclusive",
    "title": "49¬† Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia",
    "section": "\n49.9 Riflessioni Conclusive",
    "text": "49.9 Riflessioni Conclusive\nQuando si passa alla stima simultanea di pi√π parametri, come la media (\\(\\mu\\)) e la deviazione standard (\\(\\sigma\\)), l‚Äôanalisi diventa notevolmente pi√π complessa. Questo perch√© occorre considerare un numero molto maggiore di combinazioni di parametri rispetto alla stima di un solo parametro, aumentando cos√¨ il carico computazionale. Inoltre, la scelta delle priors per ciascun parametro richiede particolare attenzione, poich√© queste influenzeranno in modo diretto le stime a posteriori.\nIn scenari dove lo spazio dei parametri √® multidimensionale o quando l‚Äôesplorazione della griglia diventa impraticabile, l‚Äôuso di metodi avanzati come il campionamento di Markov Chain Monte Carlo (MCMC) diventa indispensabile. Questi metodi permettono di campionare in modo efficiente dalla distribuzione a posteriori, senza la necessit√† di esplorare esplicitamente ogni combinazione possibile di parametri, rendendo l‚Äôanalisi pi√π gestibile anche in contesti complessi.\nIn conclusione, l‚Äôestensione dell‚Äôapproccio bayesiano a problemi con pi√π parametri sconosciuti richiede un‚Äôattenzione ancora maggiore nella definizione dello spazio dei parametri, nella selezione delle priors appropriate e nel calcolo delle distribuzioni a posteriori. L‚Äôadozione di tecniche come l‚ÄôMCMC pu√≤ facilitare questo processo, permettendo di affrontare in modo efficiente problemi che altrimenti sarebbero proibitivi dal punto di vista computazionale.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>¬† <span class='chapter-title'>Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_grid_gauss.html#esercizi",
    "href": "chapters/bayesian_inference/06_grid_gauss.html#esercizi",
    "title": "49¬† Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n\nQuali sono i vantaggi dell‚Äôuso del metodo della griglia per il calcolo della distribuzione a posteriori? Quali sono le principali limitazioni di questo approccio?\nQual √® il ruolo della funzione di verosimiglianza nell‚Äôinferenza bayesiana e come si combina con la distribuzione a priori per ottenere la distribuzione a posteriori?\nIn che modo l‚Äôuso di una distribuzione a priori informativa pu√≤ influenzare l‚Äôinferenza bayesiana rispetto a una a priori uniforme? Fai riferimento a un esempio pratico.\nPerch√© in alcuni casi √® preferibile lavorare con la log-verosimiglianza anzich√© con la verosimiglianza stessa? Spiega i vantaggi di questa trasformazione.\nQual √® il significato del campionamento dalla distribuzione a posteriori e perch√© √® utile in un‚Äôanalisi bayesiana? Quali sono alcuni metodi alternativi per ottenere campioni dalla posterior quando il metodo della griglia non √® praticabile?\nUtilizzando i dati della Satisfaction With Life Scale (SWLS) raccolti dagli studenti, costruisci un modello bayesiano per stimare la media della soddisfazione di vita. Segui questi passaggi:\n\n\n\nCarica i dati della SWLS e visualizza la distribuzione delle risposte.\n\n\nDefinisci una griglia di valori possibili per la media della soddisfazione di vita (ad esempio, da 1 a 7 se il punteggio della SWLS √® su una scala Likert 1-7).\n\n\nAssumi che la deviazione standard sia nota (puoi stimarla dai dati o usare un valore ragionevole, come 1).\n\n\nCalcola la funzione di verosimiglianza per ogni valore della griglia assumendo una distribuzione normale.\n\n\nImposta una distribuzione a priori (uniforme o gaussiana centrata su un valore atteso, ad esempio 4).\n\n\nCalcola la distribuzione a posteriori e normalizzala.\n\n\nVisualizza la distribuzione a posteriori della media della soddisfazione di vita.\n\n\nEstrai campioni dalla distribuzione a posteriori e calcola un intervallo di credibilit√† al 94%.\n\nEsegui il codice in R e commenta i risultati ottenuti.\nConsegna: carica il file .qmd con le risposte, convertito in PDF, su Moodle.\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n\n\nIl metodo della griglia ha il vantaggio di essere intuitivo e facilmente implementabile, poich√© calcola direttamente la distribuzione a posteriori valutando la funzione di verosimiglianza e il prior su una griglia di valori possibili per il parametro di interesse. Questo approccio permette una visualizzazione chiara della distribuzione a posteriori e facilita il confronto tra diversi prior.\nTuttavia, presenta alcune limitazioni:\n\n\nScalabilit√†: Diventa impraticabile quando il numero di parametri cresce, poich√© il numero di combinazioni nella griglia aumenta esponenzialmente.\n\n\nRisoluzione: La precisione dell‚Äôinferenza dipende dalla densit√† della griglia, e una griglia troppo fine pu√≤ essere computazionalmente costosa.\n\n\nDifficolt√† per modelli complessi: Non √® adatto per modelli con parametri ad alta dimensionalit√† o con distribuzioni a posteriori complesse.\n\n\n\nLa funzione di verosimiglianza rappresenta la probabilit√† di osservare i dati dati i valori del parametro di interesse. Nell‚Äôinferenza bayesiana, questa informazione viene combinata con la distribuzione a priori attraverso il teorema di Bayes, che permette di aggiornare la conoscenza pregressa con le nuove osservazioni.\nMatematicamente, la distribuzione a posteriori √® data da:\n\\[\np(\\theta \\mid D) = \\frac{p(D \\mid \\theta) p(\\theta)}{p(D)}\n\\]\ndove:\n\n\n\\(p(D \\mid \\theta)\\) √® la verosimiglianza, che misura quanto bene il parametro \\(\\theta\\) spiega i dati \\(D\\).\n\n\n\\(p(\\theta)\\) √® il prior, che rappresenta la conoscenza iniziale sul parametro.\n\n\n\\(p(D)\\) √® la costante di normalizzazione.\n\nL‚Äôaggiornamento bayesiano consente di affinare le stime dei parametri alla luce di nuove evidenze in modo sistematico e coerente.\n\n\nL‚Äôuso di un prior informativo consente di incorporare conoscenze pregresse nella stima dei parametri, riducendo l‚Äôincertezza quando i dati sono scarsi. Tuttavia, se il prior √® troppo forte rispetto ai dati, potrebbe dominare la distribuzione a posteriori e introdurre un bias nelle stime.\nEsempio pratico: Supponiamo di voler stimare il QI medio di una popolazione sulla base di un piccolo campione. Se usiamo un prior informativo centrato su 140 con una deviazione standard di 3, la distribuzione a posteriori sar√† fortemente influenzata da questa assunzione. Se invece utilizziamo un prior uniforme, i dati avranno un impatto maggiore sulla stima a posteriori.\nIn generale, i prior informativi sono utili quando abbiamo conoscenze affidabili da incorporare, mentre i prior non informativi sono preferibili quando vogliamo lasciare che i dati guidino l‚Äôinferenza.\n\n\nLavorare con la log-verosimiglianza presenta diversi vantaggi:\n\n\nStabilit√† numerica: La moltiplicazione di molte probabilit√† pu√≤ portare a valori molto piccoli che causano underflow numerico. Usare il logaritmo trasforma i prodotti in somme, evitando questi problemi.\n\n\nEfficienza computazionale: Le somme sono pi√π efficienti da calcolare rispetto ai prodotti, specialmente per modelli con molti dati.\n\n\nInterpretabilit√†: La log-verosimiglianza fornisce una misura pi√π chiara della bont√† di adattamento del modello, poich√© la somma dei log-likelihood √® direttamente proporzionale alla probabilit√† complessiva dei dati dato il parametro.\n\nPer questi motivi, la log-verosimiglianza √® ampiamente usata in applicazioni statistiche e machine learning.\n\n\nIl campionamento dalla distribuzione a posteriori permette di ottenere stime dei parametri e di quantificare l‚Äôincertezza in modo efficace. Poich√© la posterior rappresenta la nostra credenza aggiornata sul parametro dopo aver osservato i dati, il campionamento consente di generare simulazioni di possibili valori di \\(\\theta\\).\nUtilit√† del campionamento:\n\nPermette di calcolare intervalli di credibilit√†.\n\nConsente di effettuare inferenze basate sulla distribuzione completa, anzich√© su un singolo valore puntuale.\n\n√à utile per simulare previsioni e testare ipotesi.\n\nMetodi alternativi per il campionamento dalla posterior:\n\n\nMetropolis-Hastings (MCMC): Un algoritmo di Markov Chain Monte Carlo che permette di esplorare distribuzioni complesse.\n\n\nGibbs Sampling: Un metodo MCMC particolarmente utile per modelli con pi√π parametri condizionali noti.\n\n\nHamiltonian Monte Carlo (HMC): Utilizza gradienti per esplorare lo spazio dei parametri in modo efficiente, come implementato in Stan.\n\nQuando il metodo della griglia non √® praticabile, questi metodi consentono di stimare la posterior in modo efficiente anche per modelli complessi e ad alta dimensionalit√†.\n\nEcco un codice in R che segue i passaggi richiesti.\n\n# Caricamento librerie necessarie\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tibble)\n\n# Dati SWLS\nswls_data &lt;- data.frame(\n  soddisfazione = c(4.2, 5.1, 4.7, 4.3, 5.5, 4.9, 4.8, 5.0, 4.6, 4.4)\n)\n\n# Usando la deviazione standard campionaria\nsigma_conosciuta &lt;- sd(swls_data$soddisfazione)  \nn &lt;- nrow(swls_data)\nmean_x &lt;- mean(swls_data$soddisfazione)\n\ncat(\"Deviazione standard campionaria:\", sigma_conosciuta, \"\\n\")\ncat(\"Media campionaria:\", mean_x, \"\\n\")\n\n# Definizione della griglia pi√π fine e centrata intorno alla media campionaria\nmu_griglia &lt;- seq(mean_x - 3*sigma_conosciuta/sqrt(n), \n                 mean_x + 3*sigma_conosciuta/sqrt(n), \n                 length.out = 1000)\n\n# Calcolo della verosimiglianza\nlog_likelihood &lt;- numeric(length(mu_griglia))\nfor (i in seq_along(mu_griglia)) {\n  # Utilizzo della log-likelihood per evitare problemi numerici\n  log_likelihood[i] &lt;- sum(dnorm(swls_data$soddisfazione, \n                                mean = mu_griglia[i], \n                                sd = sigma_conosciuta, \n                                log = TRUE))\n}\n\n# Prior uniforme (in scala logaritmica)\nlog_prior &lt;- rep(0, length(mu_griglia))\n\n# Calcolo della posteriori\nlog_posterior &lt;- log_likelihood + log_prior\nposterior &lt;- exp(log_posterior - max(log_posterior))\nposterior &lt;- posterior / sum(posterior)\n\n# Campionamento e calcolo statistiche\nsamples_grid &lt;- sample(mu_griglia, size = 10000, replace = TRUE, prob = posterior)\nmean_post_grid &lt;- mean(samples_grid)\nsd_post_grid &lt;- sd(samples_grid)\nci_grid &lt;- quantile(samples_grid, c(0.03, 0.97))\n\nresults &lt;- tibble(\n  `Media Posteriori` = c(mean_post_grid),\n  `Dev. Std. Posteriori` = c(sd_post_grid)\n)\n\n# Visualizzazione risultati\nprint(results)\n\n# Plot della distribuzione a posteriori per entrambi i metodi\nggplot() +\n  geom_line(data = data.frame(mu = mu_griglia, density = posterior),\n            aes(x = mu, y = density, color = \"Griglia\")) +\n  labs(title = \"Distribuzione a Posteriori\",\n       x = \"Media\", y = \"Densit√†\")\n  \n# Stampa intervallo di credibilit√† al 94%\ncat(\"\\nIntervallo di credibilit√† al 94% (metodo griglia):\\n\")\nprint(ci_grid)\nConclusione:\nIl modello bayesiano ci fornisce una stima della media della soddisfazione di vita con un intervallo di credibilit√†, quantificando l‚Äôincertezza in modo rigoroso.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>¬† <span class='chapter-title'>Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_grid_gauss.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/06_grid_gauss.html#informazioni-sullambiente-di-sviluppo",
    "title": "49¬† Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] reshape2_1.4.4   thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0\n#&gt;  [5] see_0.11.0       gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1\n#&gt;  [9] psych_2.5.3      scales_1.3.0     markdown_2.0     knitr_1.50      \n#&gt; [13] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [17] purrr_1.0.4      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [21] ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     plyr_1.8.9        rprojroot_2.0.4  \n#&gt; [13] jsonlite_1.9.1    viridisLite_0.4.2 mnormt_2.1.1      cli_3.6.4        \n#&gt; [17] rlang_1.1.5       munsell_0.5.1     withr_3.0.2       tools_4.4.2      \n#&gt; [21] parallel_4.4.2    tzdb_0.5.0        colorspace_2.1-1  pacman_0.5.1     \n#&gt; [25] vctrs_0.6.5       R6_2.6.1          lifecycle_1.0.4   htmlwidgets_1.6.4\n#&gt; [29] pkgconfig_2.0.3   pillar_1.10.1     gtable_0.3.6      Rcpp_1.0.14      \n#&gt; [33] glue_1.8.0        xfun_0.51         tidyselect_1.2.1  rstudioapi_0.17.1\n#&gt; [37] farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-167      labeling_0.4.3   \n#&gt; [41] rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>¬† <span class='chapter-title'>Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_grid_gauss.html#bibliografia",
    "href": "chapters/bayesian_inference/06_grid_gauss.html#bibliografia",
    "title": "49¬† Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>¬† <span class='chapter-title'>Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_conjugate_families_1.html",
    "href": "chapters/bayesian_inference/07_conjugate_families_1.html",
    "title": "50¬† Distribuzioni coniugate (1)",
    "section": "",
    "text": "50.1 Introduzione\nIn questo capitolo, esploriamo il concetto di distribuzioni a priori coniugate e il loro ruolo nell‚Äôinferenza bayesiana. Utilizzando il modello beta-binomiale come esempio paradigmatico, dimostreremo come queste distribuzioni semplifichino l‚Äôanalisi attraverso calcoli analitici diretti. L‚Äôuso di una distribuzione a priori coniugata non solo rende l‚Äôinferenza pi√π agevole, ma fornisce anche una chiara visione del modo in cui le credenze a priori influenzano le conclusioni.\nPer favorire la comprensione, procederemo in tre fasi principali:",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>50</span>¬† <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_conjugate_families_1.html#introduzione",
    "href": "chapters/bayesian_inference/07_conjugate_families_1.html#introduzione",
    "title": "50¬† Distribuzioni coniugate (1)",
    "section": "",
    "text": "Introduzione del modello beta-binomiale.\nAnalisi della distribuzione Beta e del suo ruolo come distribuzione a priori.\nDescrizione del processo di aggiornamento bayesiano e dei vantaggi derivanti dall‚Äôuso di distribuzioni coniugate.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>50</span>¬† <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_conjugate_families_1.html#il-modello-beta-binomiale",
    "href": "chapters/bayesian_inference/07_conjugate_families_1.html#il-modello-beta-binomiale",
    "title": "50¬† Distribuzioni coniugate (1)",
    "section": "\n50.2 Il Modello Beta-Binomiale",
    "text": "50.2 Il Modello Beta-Binomiale\nIl modello beta-binomiale √® un esempio classico per analizzare una proporzione \\(\\theta\\), ossia la probabilit√† di successo in una sequenza di prove binarie (ad esempio, successo/fallimento). Supponiamo di osservare \\(y\\) successi su \\(n\\) prove, dove ogni prova √® indipendente e con la stessa probabilit√† di successo \\(\\theta\\), che appartiene all‚Äôintervallo \\([0,1]\\).\nLa funzione di verosimiglianza, basata sulla distribuzione binomiale, √® espressa come:\n\\[\n\\mathcal{Binomial}(y \\mid n, \\theta) = \\binom{n}{y} \\theta^y (1 - \\theta)^{n - y},\n\\]\ndove \\(\\binom{n}{y}\\) √® il coefficiente binomiale che conta il numero di modi in cui \\(y\\) successi possono verificarsi in \\(n\\) prove.\nPer modellare la nostra conoscenza preliminare su \\(\\theta\\), scegliamo una distribuzione a priori Beta, che rappresenta un‚Äôampia gamma di credenze iniziali con parametri flessibili.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>50</span>¬† <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_conjugate_families_1.html#la-distribuzione-beta",
    "href": "chapters/bayesian_inference/07_conjugate_families_1.html#la-distribuzione-beta",
    "title": "50¬† Distribuzioni coniugate (1)",
    "section": "\n50.3 La Distribuzione Beta",
    "text": "50.3 La Distribuzione Beta\nLa distribuzione Beta √® definita come:\n\\[\n\\mathcal{Beta}(\\theta \\mid \\alpha, \\beta) = \\frac{1}{B(\\alpha, \\beta)} \\theta^{\\alpha - 1} (1 - \\theta)^{\\beta - 1}, \\quad \\text{con } \\theta \\in (0, 1),\n\\]\ndove:\n\n\\(\\alpha &gt; 0\\) e \\(\\beta &gt; 0\\) sono i iperparametri, che determinano la forma della distribuzione.\n\n\\(B(\\alpha, \\beta)\\) √® la funzione Beta di Eulero, calcolata come:\n\\[\n  B(\\alpha, \\beta) = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)},\n  \\]\ndove \\(\\Gamma(x)\\) √® la funzione Gamma, una generalizzazione del fattoriale.\n\n\nNel contesto bayesiano:\n\n\n\\(\\alpha -1\\) rappresenta il numero ipotetico di ‚Äúsuccessi‚Äù a priori.\n\n\\(\\beta -1\\) rappresenta il numero ipotetico di ‚Äúfallimenti‚Äù a priori.\n\nAd esempio:\n\nUna distribuzione Beta(1, 1) √® uniforme (0 successi a priori e 0 fallimenti), indicando totale incertezza iniziale (assenza di credenze informate).\nUna distribuzione Beta(10, 20) rappresenta una conoscenza a priori basata su 9 successi e 19 fallimenti ipotizzati, indicando una convinzione iniziale relativamente solida, poich√© deriva da un totale di 28 osservazioni virtuali che riflettono le credenze precedenti.\n\nQuesta interpretazione consente di calibrare le credenze a priori in base all‚Äôevidenza disponibile o alla fiducia nella stima.\nLa distribuzione Beta √® estremamente versatile:\n\n\nForma: Valori diversi di \\(\\alpha\\) e \\(\\beta\\) producono distribuzioni simmetriche, asimmetriche o uniformi.\n\nForza del prior: Valori elevati di \\(\\alpha\\) e \\(\\beta\\) riducono la varianza, riflettendo credenze pi√π forti.\n\nQuesta flessibilit√† rende la distribuzione Beta una scelta ideale per rappresentare credenze iniziali su proporzioni.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>50</span>¬† <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_conjugate_families_1.html#aggiornamento-bayesiano",
    "href": "chapters/bayesian_inference/07_conjugate_families_1.html#aggiornamento-bayesiano",
    "title": "50¬† Distribuzioni coniugate (1)",
    "section": "\n50.4 Aggiornamento Bayesiano",
    "text": "50.4 Aggiornamento Bayesiano\nL‚Äôaggiornamento bayesiano combina le informazioni iniziali (priori) con i dati osservati (verosimiglianza) per produrre una nuova distribuzione delle credenze (posteriori). Nel caso del modello beta-binomiale, questo processo √® particolarmente semplice grazie alla ‚Äúconiugazione‚Äù: il prior Beta e la verosimiglianza Binomiale producono una distribuzione a posteriori che appartiene ancora alla famiglia Beta.\nProblema\nDato \\(y\\) successi su \\(n\\) prove, vogliamo aggiornare la nostra distribuzione a priori Beta con i dati osservati per ottenere una distribuzione a posteriori Beta. I parametri aggiornati della distribuzione a posteriori sono dati da:\n\\[\n\\alpha' = \\alpha + y, \\quad \\beta' = \\beta + n - y.\n\\]\nEsaminiamo passo per passo come si arriva a questo risultato.\n1. Formula di Bayes\nLa regola di Bayes stabilisce che:\n\\[\np(\\theta \\mid y, n) \\propto p(\\theta) \\cdot \\mathcal{L}(\\theta),\n\\]\ndove:\n\n\n\\(p(\\theta)\\) √® la distribuzione a priori,\n\n\\(\\mathcal{L}(\\theta)\\) √® la verosimiglianza,\n\n\\(\\propto\\) indica ‚Äúproporzionale a‚Äù.\n\nCi concentriamo solo sui termini che dipendono da \\(\\theta\\), il parametro di interesse che rappresenta la probabilit√† di successo.\n2. Espressione del Prior\nIl prior √® una distribuzione Beta, definita come:\n\\[\np(\\theta) = \\theta^{\\alpha-1} (1-\\theta)^{\\beta-1},\n\\]\ndove:\n\n\n\\(\\alpha\\) e \\(\\beta\\) sono i parametri che riflettono le credenze iniziali:\n\n\n\\(\\alpha\\): successi attesi prima di osservare i dati,\n\n\\(\\beta\\): insuccessi attesi prima di osservare i dati.\n\n\n\n3. Espressione della Verosimiglianza\nLa verosimiglianza √® data dalla distribuzione binomiale, che descrive la probabilit√† di osservare \\(y\\) successi su \\(n\\) prove:\n\\[\n\\mathcal{L}(\\theta) \\propto \\theta^y (1-\\theta)^{n-y}.\n\\]\nQui:\n\n\n\\(y\\) √® il numero di successi osservati,\n\n\\(n\\) √® il numero totale di prove,\n\n\\(\\theta\\) √® la probabilit√† di successo.\n\n4. Moltiplicazione di Prior e Verosimiglianza\nCombinando il prior e la verosimiglianza otteniamo:\n\\[\np(\\theta \\mid y, n) \\propto \\underbrace{\\theta^{\\alpha-1} (1-\\theta)^{\\beta-1}}_{\\text{Prior}} \\cdot \\underbrace{\\theta^y (1-\\theta)^{n-y}}_{\\text{Verosimiglianza}}.\n\\]\n5. Raggruppamento dei Termini\nMoltiplicando i termini simili, raggruppiamo gli esponenti di \\(\\theta\\) e \\(1-\\theta\\):\n\\[\np(\\theta \\mid y, n) \\propto \\theta^{(\\alpha-1) + y} (1-\\theta)^{(\\beta-1) + (n-y)}.\n\\]\n6. Forma Finale\nSemplificando gli esponenti, otteniamo:\n\\[\np(\\theta \\mid y, n) \\propto \\theta^{\\alpha + y - 1} (1-\\theta)^{\\beta + n - y - 1}.\n\\]\nQuesta espressione ha la forma di una distribuzione Beta con parametri aggiornati:\n\\[\n\\alpha' = \\alpha + y, \\quad \\beta' = \\beta + n - y.\n\\]\n7. Normalizzazione\nPer ottenere una distribuzione di probabilit√† vera e propria, dobbiamo normalizzare dividendo per una costante di normalizzazione. La funzione Beta \\(B(\\alpha', \\beta')\\) √® definita come:\n\\[\nB(\\alpha', \\beta') = \\int_0^1 \\theta^{\\alpha' - 1} (1-\\theta)^{\\beta' - 1} \\, d\\theta.\n\\]\nLa distribuzione a posteriori normalizzata √® quindi:\n\\[\np(\\theta \\mid y, n) = \\frac{\\theta^{\\alpha' - 1} (1-\\theta)^{\\beta' - 1}}{B(\\alpha', \\beta')}.\n\\]\nConclusione\nI parametri aggiornati della distribuzione a posteriori sono:\n\n\n\\(\\alpha' = \\alpha + y\\): aggiorna il parametro dei successi con il numero di successi osservati,\n\n\\(\\beta' = \\beta + n - y\\): aggiorna il parametro degli insuccessi con il numero di insuccessi osservati.\n\n\n50.4.1 Vantaggi del Modello Beta-Binomiale\n\n\nSemplicit√† analitica: La coniugatezza della distribuzione Beta-Binomiale semplifica i calcoli, rendendo immediato l‚Äôaggiornamento dei parametri.\n\nInterpretazione intuitiva: L‚Äôaggiornamento dei parametri \\(\\alpha\\) e \\(\\beta\\) mostra in modo trasparente come i dati influenzino le credenze.\n\nIn sintesi, il modello Beta-Binomiale √® un esempio didattico fondamentale per comprendere l‚Äôinferenza bayesiana e rappresenta un punto di partenza ideale per approcci pi√π avanzati.\n\nEsempio 50.1 Nel Capitolo 48 abbiamo utilizzato il metodo basato su griglia per determinare la distribuzione a posteriori nel caso di \\(y = 6\\) successi su \\(n = 9\\) prove (vedi anche McElreath, 2020 per una discussione dettagliata). Ora esploriamo un approccio alternativo, sfruttando le propriet√† delle famiglie coniugate.\nLa verosimiglianza binomiale per questo esperimento √® espressa dalla seguente funzione:\n\\[\n\\mathcal{L}(\\theta) \\propto \\theta^y (1-\\theta)^{n-y},\n\\]\ndove \\(y = 6\\) rappresenta il numero di successi e \\(n = 9\\) il numero totale di prove.\nScegliendo una distribuzione a priori Beta con parametri \\(\\alpha = 2\\) e \\(\\beta = 5\\), possiamo applicare il teorema di Bayes per calcolare i parametri aggiornati della distribuzione a posteriori. In base alla regola di aggiornamento per distribuzioni coniugate, otteniamo:\n\\[\n\\alpha' = \\alpha + y = 2 + 6 = 8.\n\\] \\[\n\\beta' = \\beta + n - y = 5 + 9 - 6 = 8.\n\\]\nLa distribuzione a posteriori risultante √® quindi una distribuzione Beta con parametri \\(\\mathcal{Beta}(8, 8)\\).\nProcediamo ora a visualizzare le tre distribuzioni rilevanti:\n\n\nDistribuzione a priori: \\(\\mathcal{Beta}(2, 2)\\),\n\nVerosimiglianza binomiale: per \\(y = 6\\) e \\(n = 9\\),\n\nDistribuzione a posteriori: \\(\\text{Beta}(8, 5)\\).\n\nEcco il codice R per generare il grafico comparativo:\n\n# Definizione dei parametri\nalpha_prior &lt;- 2\nbeta_prior &lt;- 5\ny &lt;- 6\nn &lt;- 9\n\n# Parametri della distribuzione a posteriori\nalpha_post &lt;- alpha_prior + y\nbeta_post &lt;- beta_prior + n - y\n\n# Sequenza di valori di theta\ntheta &lt;- seq(0, 1, length.out = 1000)\n\n# Calcolo delle PDF\nprior_pdf &lt;- dbeta(theta, shape1 = alpha_prior, shape2 = beta_prior)\nlikelihood &lt;- theta^y * (1 - theta)^(n - y)\n\n# Normalizzazione della verosimiglianza\nlikelihood_integral &lt;- sum(likelihood) * (theta[2] - theta[1])\nnormalized_likelihood &lt;- likelihood / likelihood_integral\n\nposterior_pdf &lt;- dbeta(theta, shape1 = alpha_post, shape2 = beta_post)\n\n# Creare un dataframe contenente i dati per il grafico\ndf &lt;- data.frame(\n  theta = rep(theta, 3),\n  densita = c(prior_pdf, normalized_likelihood, posterior_pdf),\n  distribuzione = rep(c(\"Prior\", \"Likelihood\", \"Posterior\"), each = length(theta))\n)\n\n# Creare il grafico \nggplot(df, aes(x = theta, y = densita, color = distribuzione)) +\n  geom_line(size = 1) +  # Aggiungere le linee per le distribuzioni\n  scale_color_manual(values = c(\"Prior\" = \"blue\", \"Likelihood\" = \"green\", \"Posterior\" = \"red\")) +  # Assegnare i colori\n  labs(title = \"Distribuzioni Prior, Likelihood e Posterior\",\n       x = expression(theta),\n       y = \"Densit√†\",\n       color = \"Distribuzione\") +  # Aggiungere titoli e label\n  theme(legend.position = \"top\")  # Posizionare la legenda in alto\n\n\n\n\n\n\n\n\n\nCurva blu: Prior \\(\\mathcal{Beta}(2, 5)\\), che riflette le credenze iniziali prima dell‚Äôosservazione dei dati.\n\n\nCurva verde: Likelihood (normalizzata), rappresenta l‚Äôevidenza fornita dai dati osservati.\n\n\nCurva rossa: Posterior \\(\\mathcal{Beta}(8, 8)\\), risultato dell‚Äôaggiornamento bayesiano che combina prior e likelihood.\n\nNota sulla normalizzazione della verosimiglianza. La verosimiglianza binomiale non √® una distribuzione di probabilit√† (il suo integrale non √® pari a 1). Per rappresentarla visivamente accanto alla distribuzione a priori e a quella a posteriori, √® necessario normalizzarla. Questo √® fatto calcolando il suo integrale su \\(\\theta \\in [0, 1]\\) e dividendo la funzione per il risultato. La normalizzazione serve solo per la visualizzazione e non influisce sui calcoli analitici.\n\n\nEsempio 50.2 Esaminiamo ora un esempio discuso da Johnson et al. (2022). In uno studio molto famoso, Stanley Milgram ha studiato la propensione delle persone a obbedire agli ordini delle figure di autorit√†, anche quando tali ordini potrebbero danneggiare altre persone (Milgram 1963). Nell‚Äôarticolo, Milgram descrive lo studio come\n\nconsistente nell‚Äôordinare a un soggetto ingenuo di somministrare una scossa elettrica a una vittima. Viene utilizzato un generatore di scosse simulato, con 30 livelli di tensione chiaramente contrassegnati che vanno da IS a 450 volt. Lo strumento porta delle designazioni verbali che vanno da Scossa Lieve a Pericolo: Scossa Grave. Le risposte della vittima, che √® un complice addestrato dell‚Äôesperimentatore, sono standardizzate. Gli ordini di somministrare scosse vengono dati al soggetto ingenuo nel contesto di un ‚Äòesperimento di apprendimento‚Äô apparentemente organizzato per studiare gli effetti della punizione sulla memoria. Man mano che l‚Äôesperimento procede, al soggetto ingenuo viene ordinato di somministrare scosse sempre pi√π intense alla vittima, fino al punto di raggiungere il livello contrassegnato Pericolo: Scossa Grave.\n\nIn altre parole, ai partecipanti allo studio veniva dato il compito di testare un altro partecipante (che in realt√† era un attore addestrato) sulla loro capacit√† di memorizzare una serie di item. Se l‚Äôattore non ricordava un item, al partecipante veniva ordinato di somministrare una scossa all‚Äôattore e di aumentare il livello della scossa con ogni fallimento successivo. I partecipanti non erano consapevoli del fatto che le scosse fossero finte e che l‚Äôattore stesse solo fingendo di provare dolore dalla scossa.\nNello studio di Milgram, 26 partecipanti su 40 hanno somministrato scosse al livello ‚ÄúPericolo: Scossa Grave‚Äù. Il problema richiede di costruire la distribuzione a posteriori della probabilit√† \\(\\theta\\) di infliggere una scossa a l livello ‚ÄúPericolo: Scossa Grave‚Äù, ipotizzando che uno studio precedente aveva stabilito che \\(\\theta\\) segue una distribuzione Beta(1, 10).\nIniziamo a fornire una rappresentazione grafica della distribuzione a priori.\n\n# Impostazione dei parametri della distribuzione Beta\nalpha &lt;- 1\nbeta_val &lt;- 10\n\n# Creazione di valori x per il plot\nx_values &lt;- seq(0, 1, length.out = 1000)\n\n# Calcolo della densit√† di probabilit√† per ogni valore di x\nbeta_pdf &lt;- dbeta(x_values, shape1 = alpha, shape2 = beta_val)\n\n# Creare un dataframe contenente i dati per il grafico\ndf &lt;- data.frame(\n  x = x_values,\n  densita = beta_pdf\n)\n\n# Creare il grafico\nggplot(df, aes(x = x, y = densita)) +\n  geom_line(color = \"#b97c7c\", size = 1) +  # Aggiungere la linea per la densit√†\n  labs(title = \"Distribuzione Beta(1, 10)\",  # Aggiungere il titolo\n       x = \"x\",  # Label dell'asse x\n       y = \"Densit√† di probabilit√†\") +  # Label dell'asse y\n  theme(plot.title = element_text(hjust = 0.5)) +  # Centrare il titolo\n  geom_vline(xintercept = 0, color = \"black\", linetype = \"dashed\", size = 0.5) +  # Linea verticale opzionale\n  geom_vline(xintercept = 1, color = \"black\", linetype = \"dashed\", size = 0.5) +  # Linea verticale opzionale\n  annotate(\"text\", x = 0.8, y = max(beta_pdf) * 0.9, label = \"Beta(1, 10)\", color = \"#b97c7c\", size = 5)  # Aggiungere una legenda\n\n\n\n\n\n\n\nLa distribuzione a posteriori segue una distribuzione Beta con parametri aggiornati:\n\ny &lt;- 26\nn &lt;- 40\n\nalpha_prior &lt;- 1\nbeta_prior &lt;- 10\n\nalpha_post &lt;- alpha_prior + y\nbeta_post &lt;- beta_prior + n - y\n\nalpha_post\n#&gt; [1] 27\nbeta_post\n#&gt; [1] 24\n\nCreazione di un grafico per la distribuzione a posteriori:\n\n# Creazione di valori x per il plot\nx_values &lt;- seq(0, 1, length.out = 1000)\n\n# Calcolo della densit√† di probabilit√† per ogni valore di x\nbeta_pdf &lt;- dbeta(x_values, alpha_post, beta_post)\n\n# Creare un dataframe contenente i dati per il grafico\ndf &lt;- data.frame(\n  theta = x_values,\n  densita = beta_pdf\n)\n\n# Creare il grafico con ggplot2\nggplot(df, aes(x = theta, y = densita)) +\n  geom_line(color = \"blue\", size = 1) +  # Aggiungere la linea per la densit√†\n  labs(title = \"Distribuzione Beta(27, 24)\",  # Aggiungere il titolo\n       x = expression(theta),  # Label dell'asse x usando espressioni matematiche\n       y = \"Densit√† di probabilit√†\") +  # Label dell'asse y\n  theme(plot.title = element_text(hjust = 0.5)) +  # Centrare il titolo\n  annotate(\"text\", x = 0.8, y = max(beta_pdf) * 0.9, label = \"Beta(27, 24)\", color = \"blue\", size = 5)  \n\n\n\n\n\n\n\nCalcolo della media a posteriori di \\(\\theta\\):\n\nalpha_post / (alpha_post + beta_post)\n#&gt; [1] 0.5294\n\nCalcolo della moda a posteriori:\n\n(alpha_post - 1) / (alpha_post + beta_post - 2)\n#&gt; [1] 0.5306\n\nCalcolo della probabilit√† che \\(\\theta &gt; 0.6\\):\n\npbeta(0.6, alpha_post, beta_post, lower.tail = FALSE)\n#&gt; [1] 0.1562\n\nOvvero:\n\n1 - pbeta(0.6, alpha_post, beta_post)\n#&gt; [1] 0.1562\n\nEseguiamo il problema utilizzando il metodo basato su griglia. Definiamo la griglia di interesse:\n\ntheta &lt;- seq(0, 1, length.out = 100)\n\nCreiamo la distribuzione a priori:\n\nprior &lt;- dbeta(theta, alpha_prior, beta_prior)\n\n# Normalizzazione della densit√† per ottenere una somma pari a 1\nprior_normalized &lt;- prior / sum(prior)\n\n# Creare un dataframe contenente i dati per il grafico\ndf &lt;- data.frame(\n  theta = theta,\n  probabilita = prior_normalized\n)\n\n# Creare il grafico con ggplot2\nggplot(df, aes(x = theta, y = probabilita)) +\n  geom_segment(aes(x = theta, xend = theta, y = 0, yend = probabilita), \n               color = \"blue\", size = 1) +  # Linee verticali per rappresentare le probabilit√†\n  labs(title = \"Distribuzione a priori\",  # Aggiungere il titolo\n       x = expression(theta),  # Label dell'asse x usando espressioni matematiche\n       y = \"Probabilit√†\") +  # Label dell'asse y\n  theme(plot.title = element_text(hjust = 0.5))  # Centrare il titolo\n\n\n\n\n\n\n\nCreiamo la verosimiglianza:\n\nlk &lt;- dbinom(y, n, theta)\n\n# Normalizzazione della verosimiglianza per ottenere una somma pari a 1\nlk_normalized &lt;- lk / sum(lk)\n\n# Creare un dataframe contenente i dati per il grafico\ndf &lt;- data.frame(\n  theta = theta,\n  probabilita = lk_normalized\n)\n\n# Creare il grafico con ggplot2\nggplot(df, aes(x = theta, y = probabilita)) +\n  geom_segment(aes(x = theta, xend = theta, y = 0, yend = probabilita), \n               color = \"red\", size = 1) +  # Linee verticali per rappresentare la verosimiglianza\n  labs(title = \"Verosimiglianza\",  # Aggiungere il titolo\n       x = expression(theta),  # Label dell'asse x usando espressioni matematiche\n       y = \"Probabilit√†\") +  # Label dell'asse y\n  theme(plot.title = element_text(hjust = 0.5))  # Centrare il titolo\n\n\n\n\n\n\n\nCalcoliamo la distribuzione a posteriori:\n\npost &lt;- (prior * lk) / sum(prior * lk)\n\n# Normalizzazione della verosimiglianza per ottenere una somma pari a 1\nlk_normalized &lt;- lk / sum(lk)\n\n# Creare un dataframe contenente i dati per il grafico\ndf &lt;- data.frame(\n  theta = theta,\n  probabilita = lk_normalized\n)\n\n# Creare il grafico con ggplot2\nggplot(df, aes(x = theta, y = probabilita)) +\n  geom_segment(aes(x = theta, xend = theta, y = 0, yend = probabilita), \n               color = \"green\", size = 1) +  # Linee verticali per rappresentare la verosimiglianza\n  labs(title = \"Distribuzione a posteriori\",  # Aggiungere il titolo\n       x = expression(theta),  # Label dell'asse x usando espressioni matematiche\n       y = \"Probabilit√†\") +  # Label dell'asse y\n  theme(plot.title = element_text(hjust = 0.5))  # Centrare il titolo\n\n\n\n\n\n\n\nEstrazione di un campione dalla distribuzione a posteriori:\n\nsamples &lt;- sample(theta, size = 1e6, replace = TRUE, prob = post)\n\nTroviamo la media a posteriori:\n\nmean(samples)\n#&gt; [1] 0.5295\n\nCalcoliamo la probabilit√† che \\(\\theta &gt; 0.6\\):\n\nmean(samples &gt; 0.6)\n#&gt; [1] 0.1527\n\nQuesto codice mantiene la struttura logica del problema e produce risultati equivalenti utilizzando R.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>50</span>¬† <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_conjugate_families_1.html#principali-distribuzioni-coniugate",
    "href": "chapters/bayesian_inference/07_conjugate_families_1.html#principali-distribuzioni-coniugate",
    "title": "50¬† Distribuzioni coniugate (1)",
    "section": "\n50.5 Principali distribuzioni coniugate",
    "text": "50.5 Principali distribuzioni coniugate\nEsistono altre combinazioni di verosimiglianza e distribuzione a priori che producono una distribuzione a posteriori con la stessa forma della distribuzione a priori. Ecco alcune delle pi√π note coniugazioni tra modelli statistici e distribuzioni a priori:\n\nNel modello Normale-Normale \\(\\mathcal{N}(\\mu, \\sigma^2_0)\\), la distribuzione a priori √® \\(\\mathcal{N}(\\mu_0, \\tau^2)\\) e la distribuzione a posteriori √® \\(\\mathcal{N}\\left(\\frac{\\mu_0\\sigma^2 + \\bar{y}n\\tau^2}{\\sigma^2 + n\\tau^2}, \\frac{\\sigma^2\\tau^2}{\\sigma^2 + n\\tau^2} \\right)\\).\nNel modello Poisson-gamma \\(\\text{Po}(\\theta)\\), la distribuzione a priori √® \\(\\Gamma(\\lambda, \\delta)\\) e la distribuzione a posteriori √® \\(\\Gamma(\\lambda + n \\bar{y}, \\delta +n)\\).\nNel modello esponenziale \\(\\text{Exp}(\\theta)\\), la distribuzione a priori √® \\(\\Gamma(\\lambda, \\delta)\\) e la distribuzione a posteriori √® \\(\\Gamma(\\lambda + n, \\delta +n\\bar{y})\\).\nNel modello uniforme-Pareto \\(\\text{U}(0, \\theta)\\), la distribuzione a priori √® \\(\\text{Pa}(\\alpha, \\varepsilon)\\) e la distribuzione a posteriori √® \\(\\text{Pa}(\\alpha + n, \\max(y_{(n)}, \\varepsilon))\\).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>50</span>¬† <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_conjugate_families_1.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/07_conjugate_families_1.html#riflessioni-conclusive",
    "title": "50¬† Distribuzioni coniugate (1)",
    "section": "\n50.6 Riflessioni Conclusive",
    "text": "50.6 Riflessioni Conclusive\nIn conclusione, l‚Äôutilizzo di priori coniugati presenta vantaggi e svantaggi. Cominciamo con i vantaggi principali. Il principale vantaggio dell‚Äôadozione di distribuzioni a priori coniugate risiede nella loro capacit√† di rendere l‚Äôanalisi della distribuzione a posteriori trattabile da un punto di vista analitico. Ad esempio, nel corso di questo capitolo abbiamo esaminato come sia possibile formulare la distribuzione a posteriori in seguito a un esperimento composto da una serie di prove di Bernoulli (con una verosimiglianza binomiale), utilizzando una distribuzione Beta sia per la prior che per il posteriore.\nTuttavia, √® cruciale riconoscere che i modelli basati sul concetto di famiglie coniugate presentano delle limitazioni intrinseche. Le distribuzioni coniugate a priori sono disponibili solamente per distribuzioni di verosimiglianza di base e relativamente semplici. Per modelli complessi e pi√π realistici, la ricerca di priori coniugati diventa spesso un compito estremamente arduo, limitando quindi la loro utilit√†. Inoltre, anche quando le distribuzioni a priori coniugate sono disponibili, un modello che ne fa uso potrebbe non essere sufficientemente flessibile per adattarsi alle nostre credenze iniziali. Ad esempio, un modello basato su una distribuzione normale √® sempre unimodale e simmetrico rispetto alla media \\(\\mu\\). Tuttavia, se le nostre conoscenze iniziali non sono simmetriche o non seguono una distribuzione unimodale, la scelta di una distribuzione a priori normale potrebbe non risultare la pi√π adeguata (Johnson et al., 2022).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>50</span>¬† <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_conjugate_families_1.html#esercizi",
    "href": "chapters/bayesian_inference/07_conjugate_families_1.html#esercizi",
    "title": "50¬† Distribuzioni coniugate (1)",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nSi consideri lo studio ‚ÄúAn excess of positive results: Comparing the standard psychology literature with registered reports‚Äù di Scheel et al. (2021). In questo lavoro, gli autori confrontano il tasso di risultati positivi \\(\\theta\\) ottenuti in studi psicologici pubblicati senza preregistrazione con quelli pubblicati con preregistrazione. Si utilizzi il tasso di successo riportato negli studi preregistrati per costruire una distribuzione a priori per il parametro \\(\\theta\\).\nSecondo i risultati degli studi preregistrati, gli autori riscontrano un tasso di successo del 43.66%, con un intervallo di confidenza al 95% [CI] = [31.91, 55.95]. Sulla base di questi dati, si costruisca una distribuzione beta come distribuzione a priori per \\(\\theta\\), seguendo il metodo illustrato da Johnson et al. (2022).\nSuccessivamente, utilizzando questa distribuzione beta come distribuzione a priori, si determini la distribuzione a posteriori utilizzando il metodo delle famiglie coniugate per due scenari distinti, basati su 152 studi osservati: (a) Un tasso di successo del 60% (b) Un tasso di successo del 96% (come riportato per gli studi non preregistrati da Scheel et al. (2021)).\nInfine, si commentino i risultati derivanti dall‚Äôanalisi delle distribuzioni a posteriori ottenute per entrambi gli scenari.\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\n# Caricamento delle librerie necessarie\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(dplyr)\n\n# Funzione per trovare i parametri della distribuzione beta\nfind_beta_parameters &lt;- function(mean, lower, upper, conf_level = 0.95) {\n  # Funzione obiettivo da minimizzare\n  objective &lt;- function(alpha) {\n    beta &lt;- alpha * (1 - mean) / mean\n    predicted_ci &lt;- qbeta(c((1-conf_level)/2, 1-(1-conf_level)/2), alpha, beta)\n    error &lt;- (predicted_ci[1] - lower)^2 + (predicted_ci[2] - upper)^2\n    return(error)\n  }\n  \n  # Ottimizzazione per trovare alpha\n  result &lt;- optimize(objective, interval = c(0.1, 100))\n  alpha &lt;- result$minimum\n  beta &lt;- alpha * (1 - mean) / mean\n  \n  return(list(alpha = alpha, beta = beta))\n}\n\n# Parametri degli studi preregistrati\nmean_preregistered &lt;- 0.4366\nci_lower &lt;- 0.3191\nci_upper &lt;- 0.5595\n\n# Calcolo dei parametri della distribuzione beta a priori\nprior_params &lt;- find_beta_parameters(mean_preregistered, ci_lower, ci_upper)\nalpha_prior &lt;- prior_params$alpha\nbeta_prior &lt;- prior_params$beta\n\n# Dati osservati\nn &lt;- 152  # numero di studi\nsuccesses_60 &lt;- round(0.60 * n)  # scenario (a)\nsuccesses_96 &lt;- round(0.96 * n)  # scenario (b)\n\n# Calcolo delle distribuzioni a posteriori\nalpha_post_60 &lt;- alpha_prior + successes_60\nbeta_post_60 &lt;- beta_prior + (n - successes_60)\n\nalpha_post_96 &lt;- alpha_prior + successes_96\nbeta_post_96 &lt;- beta_prior + (n - successes_96)\n\n# Creazione del dataframe per il plotting\ntheta &lt;- seq(0, 1, length.out = 1000)\n\ndf &lt;- data.frame(\n  theta = rep(theta, 3),\n  density = c(\n    dbeta(theta, alpha_prior, beta_prior),\n    dbeta(theta, alpha_post_60, beta_post_60),\n    dbeta(theta, alpha_post_96, beta_post_96)\n  ),\n  distribution = rep(c(\"Priori\", \"Posteriori (60%)\", \"Posteriori (96%)\"), \n                    each = length(theta))\n)\n\n# Creazione del grafico\np &lt;- ggplot(df, aes(x = theta, y = density, color = distribution)) +\n  geom_line(size = 1) +\n  labs(\n    title = \"Distribuzioni a Priori e a Posteriori\",\n    x = expression(theta),\n    y = \"Densit√†\",\n    color = \"Distribuzione\"\n  ) +\n  theme(legend.position = \"bottom\")\n\n# Calcolo degli intervalli di credibilit√† al 95%\ncredible_intervals &lt;- data.frame(\n  Distribution = c(\"Priori\", \"Posteriori (60%)\", \"Posteriori (96%)\"),\n  Mean = c(\n    alpha_prior / (alpha_prior + beta_prior),\n    alpha_post_60 / (alpha_post_60 + beta_post_60),\n    alpha_post_96 / (alpha_post_96 + beta_post_96)\n  ),\n  Lower = c(\n    qbeta(0.025, alpha_prior, beta_prior),\n    qbeta(0.025, alpha_post_60, beta_post_60),\n    qbeta(0.025, alpha_post_96, beta_post_96)\n  ),\n  Upper = c(\n    qbeta(0.975, alpha_prior, beta_prior),\n    qbeta(0.975, alpha_post_60, beta_post_60),\n    qbeta(0.975, alpha_post_96, beta_post_96)\n  )\n)\n\n# Visualizzazione dei risultati\nprint(\"Parametri della distribuzione beta a priori:\")\nprint(paste(\"alpha =\", round(alpha_prior, 2)))\nprint(paste(\"beta =\", round(beta_prior, 2)))\n\nprint(\"\\nIntervalli di credibilit√† al 95%:\")\nprint(credible_intervals)\n\n# Visualizza il grafico\nprint(p)\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nTra i fattori che possono influenzare il rapporto tra i sessi alla nascita c‚Äô√® la condizione materna di placenta previa, una condizione insolita della gravidanza in cui la placenta √® impiantata in basso nell‚Äôutero, impedendo un normale parto vaginale del feto. Uno studio condotto in Germania ha esaminato il sesso dei neonati in casi di placenta previa e ha riscontrato che, su un totale di 980 nascite, 437 erano femmine.\nQuanta evidenza fornisce questo studio a supporto dell‚Äôipotesi che la proporzione di nascite femminili nella popolazione di placenta previa sia inferiore a 0.485, che rappresenta la proporzione di nascite femminili nella popolazione generale? (Esercizio tratto da Gelman et al. (1995))\n\n\n\n\n\n\n\n\n\nSoluzioni 2\n\n\n\n\n\n# Caricamento delle librerie necessarie\nlibrary(ggplot2)\n\n# Dati osservati\nn &lt;- 980        # numero totale di nascite\ny &lt;- 437        # numero di femmine\np0 &lt;- 0.485     # proporzione nella popolazione generale\n\n# Calcolo della proporzione osservata\np_hat &lt;- y/n\nprint(paste(\"Proporzione osservata di femmine:\", round(p_hat, 3)))\n\n# Test dell'ipotesi utilizzando il Bayes Factor\n# H0: p = 0.485 vs H1: p &lt; 0.485\n\n# Funzione per calcolare la verosimiglianza marginale sotto H1\nmarginal_likelihood_h1 &lt;- function(y, n, p_max = 0.485) {\n  # Integrazione numerica sulla distribuzione uniforme tra 0 e p_max\n  p_grid &lt;- seq(0, p_max, length.out = 1000)\n  likelihood &lt;- dbinom(y, n, p_grid)\n  prior &lt;- dunif(p_grid, 0, p_max)\n  mean(likelihood * prior) * p_max\n}\n\n# Verosimiglianza sotto H0\nlikelihood_h0 &lt;- dbinom(y, n, p0)\n\n# Verosimiglianza marginale sotto H1\nmarg_lik_h1 &lt;- marginal_likelihood_h1(y, n)\n\n# Calcolo del Bayes Factor\nbf10 &lt;- marg_lik_h1 / likelihood_h0\nprint(paste(\"Bayes Factor (H1 vs H0):\", round(bf10, 2)))\n\n# Visualizzazione delle distribuzioni a posteriori\np_grid &lt;- seq(0, 1, length.out = 1000)\nlikelihood &lt;- dbinom(y, n, p_grid)\nprior &lt;- dunif(p_grid, 0, 1)\nposterior &lt;- likelihood * prior\nposterior &lt;- posterior / sum(posterior)\n\n# Creazione del dataframe per il plotting\ndf &lt;- data.frame(\n  p = p_grid,\n  Posterior = posterior / max(posterior)  # normalizzato per la visualizzazione\n)\n\n# Creazione del grafico\np &lt;- ggplot(df, aes(x = p, y = Posterior)) +\n  geom_line(size = 1) +\n  geom_vline(xintercept = p0, linetype = \"dashed\", color = \"red\") +\n  geom_vline(xintercept = p_hat, linetype = \"dashed\", color = \"blue\") +\n  labs(\n    title = \"Distribuzione a Posteriori della Proporzione di Nascite Femminili\",\n    x = \"Proporzione di Nascite Femminili (p)\",\n    y = \"Densit√† a Posteriori (normalizzata)\"\n  ) +\n  annotate(\"text\", x = p0, y = 0.1, \n           label = \"Popolazione Generale\", \n           angle = 90, vjust = -0.5, color = \"red\") +\n  annotate(\"text\", x = p_hat, y = 0.1, \n           label = \"Proporzione Osservata\", \n           angle = 90, vjust = -0.5, color = \"blue\")\n\n# Calcolo dell'intervallo di credibilit√† al 95%\nsorted_p &lt;- sort(p_grid)\ncum_post &lt;- cumsum(posterior)\nlower &lt;- sorted_p[which(cum_post &gt; 0.025)[1]]\nupper &lt;- sorted_p[which(cum_post &gt; 0.975)[1]]\n\nprint(paste(\"Intervallo di credibilit√† al 95%: [\", \n            round(lower, 3), \",\", round(upper, 3), \"]\"))\n\n# Calcolo della probabilit√† a posteriori che p &lt; 0.485\nprob_less_than_p0 &lt;- sum(posterior[p_grid &lt; p0])\nprint(paste(\"Probabilit√† a posteriori che p &lt; 0.485:\", \n            round(prob_less_than_p0, 3)))\n\n# Visualizza il grafico\nprint(p)\n\n\n\n\n\n\n\n\n\nProblemi 3\n\n\n\n\n\nPer valutare la sensibilit√† della soluzione precedente alla scelta della distribuzione a priori, ripetere l‚Äôesercizio utilizzando come distribuzione a priori per la proporzione di nascite femminili una distribuzione Beta(48.5, 51.5). Questa distribuzione √® centrata su 0.485 e concentra la maggior parte della sua massa nell‚Äôintervallo [0.385, 0.585]. Interpretare i risultati ottenuti.\n\n\n\n\n\n\n\n\n\nSoluzioni 3\n\n\n\n\n\n# Caricamento delle librerie necessarie\nlibrary(ggplot2)\n\n# Dati osservati\nn &lt;- 980        # numero totale di nascite\ny &lt;- 437        # numero di femmine\np0 &lt;- 0.485     # proporzione nella popolazione generale\n\n# Parametri della distribuzione beta a priori\nalpha_prior &lt;- 48.5\nbeta_prior &lt;- 51.5\n\n# Calcolo dei parametri della distribuzione beta a posteriori\nalpha_post &lt;- alpha_prior + y\nbeta_post &lt;- beta_prior + (n - y)\n\n# Creazione della griglia per il plotting\np_grid &lt;- seq(0, 1, length.out = 1000)\n\n# Calcolo delle densit√†\nprior_density &lt;- dbeta(p_grid, alpha_prior, beta_prior)\nposterior_density &lt;- dbeta(p_grid, alpha_post, beta_post)\n\n# Creazione del dataframe per il plotting\ndf &lt;- data.frame(\n  p = rep(p_grid, 2),\n  density = c(prior_density, posterior_density),\n  distribution = rep(c(\"Priori Beta(48.5, 51.5)\", \"Posteriori\"), each = length(p_grid))\n)\n\n# Creazione del grafico\np &lt;- ggplot(df, aes(x = p, y = density, color = distribution)) +\n  geom_line(size = 1) +\n  geom_vline(xintercept = p0, linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Distribuzioni a Priori e a Posteriori\",\n    subtitle = \"Proporzione di Nascite Femminili con Placenta Previa\",\n    x = \"Proporzione di Nascite Femminili (p)\",\n    y = \"Densit√†\",\n    color = \"Distribuzione\"\n  ) +\n  theme(legend.position = \"bottom\") +\n  annotate(\"text\", x = p0, y = max(posterior_density)/2, \n           label = \"Popolazione Generale (0.485)\", \n           angle = 90, vjust = -0.5, color = \"red\")\n\n# Calcolo statistiche rilevanti\n# Media a priori e posteriori\nprior_mean &lt;- alpha_prior / (alpha_prior + beta_prior)\npost_mean &lt;- alpha_post / (alpha_post + beta_post)\n\n# Intervalli di credibilit√† al 95%\nprior_ci &lt;- qbeta(c(0.025, 0.975), alpha_prior, beta_prior)\npost_ci &lt;- qbeta(c(0.025, 0.975), alpha_post, beta_post)\n\n# Probabilit√† a posteriori che p &lt; 0.485\nprob_less_than_p0 &lt;- pbeta(p0, alpha_post, beta_post)\n\n# Output dei risultati\ncat(\"\\nRisultati dell'analisi:\\n\")\ncat(\"------------------------\\n\")\ncat(\"Dati osservati:\\n\")\ncat(sprintf(\"Numero totale di nascite: %d\\n\", n))\ncat(sprintf(\"Numero di femmine: %d\\n\", y))\ncat(sprintf(\"Proporzione osservata: %.3f\\n\\n\", y/n))\n\ncat(\"Analisi a priori:\\n\")\ncat(sprintf(\"Media a priori: %.3f\\n\", prior_mean))\ncat(sprintf(\"Intervallo di credibilit√† al 95%%: [%.3f, %.3f]\\n\\n\", \n            prior_ci[1], prior_ci[2]))\n\ncat(\"Analisi a posteriori:\\n\")\ncat(sprintf(\"Media a posteriori: %.3f\\n\", post_mean))\ncat(sprintf(\"Intervallo di credibilit√† al 95%%: [%.3f, %.3f]\\n\", \n            post_ci[1], post_ci[2]))\ncat(sprintf(\"Probabilit√† che p &lt; %.3f: %.3f\\n\", p0, prob_less_than_p0))\n\n# Visualizza il grafico\nprint(p)\n# Caricamento delle librerie necessarie\nlibrary(ggplot2)\n\n# Dati osservati\nn &lt;- 980        # numero totale di nascite\ny &lt;- 437        # numero di femmine\np0 &lt;- 0.485     # proporzione nella popolazione generale\n\n# Parametri della distribuzione beta a priori\nalpha_prior &lt;- 48.5\nbeta_prior &lt;- 51.5\n\n# Calcolo dei parametri della distribuzione beta a posteriori\nalpha_post &lt;- alpha_prior + y\nbeta_post &lt;- beta_prior + (n - y)\n\n# Creazione della griglia per il plotting\np_grid &lt;- seq(0, 1, length.out = 1000)\n\n# Calcolo delle densit√†\nprior_density &lt;- dbeta(p_grid, alpha_prior, beta_prior)\nposterior_density &lt;- dbeta(p_grid, alpha_post, beta_post)\n\n# Creazione del dataframe per il plotting\ndf &lt;- data.frame(\n  p = rep(p_grid, 2),\n  density = c(prior_density, posterior_density),\n  distribution = rep(c(\"Priori Beta(48.5, 51.5)\", \"Posteriori\"), each = length(p_grid))\n)\n\n# Creazione del grafico\np &lt;- ggplot(df, aes(x = p, y = density, color = distribution)) +\n  geom_line(size = 1) +\n  geom_vline(xintercept = p0, linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Distribuzioni a Priori e a Posteriori\",\n    subtitle = \"Proporzione di Nascite Femminili con Placenta Previa\",\n    x = \"Proporzione di Nascite Femminili (p)\",\n    y = \"Densit√†\",\n    color = \"Distribuzione\"\n  ) +\n  theme(legend.position = \"bottom\") +\n  annotate(\"text\", x = p0, y = max(posterior_density)/2, \n           label = \"Popolazione Generale (0.485)\", \n           angle = 90, vjust = -0.5, color = \"red\")\n\n# Calcolo statistiche rilevanti\n# Media a priori e posteriori\nprior_mean &lt;- alpha_prior / (alpha_prior + beta_prior)\npost_mean &lt;- alpha_post / (alpha_post + beta_post)\n\n# Intervalli di credibilit√† al 95%\nprior_ci &lt;- qbeta(c(0.025, 0.975), alpha_prior, beta_prior)\npost_ci &lt;- qbeta(c(0.025, 0.975), alpha_post, beta_post)\n\n# Probabilit√† a posteriori che p &lt; 0.485\nprob_less_than_p0 &lt;- pbeta(p0, alpha_post, beta_post)\n\n# Output dei risultati\ncat(\"\\nRisultati dell'analisi:\\n\")\ncat(\"------------------------\\n\")\ncat(\"Dati osservati:\\n\")\ncat(sprintf(\"Numero totale di nascite: %d\\n\", n))\ncat(sprintf(\"Numero di femmine: %d\\n\", y))\ncat(sprintf(\"Proporzione osservata: %.3f\\n\\n\", y/n))\n\ncat(\"Analisi a priori:\\n\")\ncat(sprintf(\"Media a priori: %.3f\\n\", prior_mean))\ncat(sprintf(\"Intervallo di credibilit√† al 95%%: [%.3f, %.3f]\\n\\n\", \n            prior_ci[1], prior_ci[2]))\n\ncat(\"Analisi a posteriori:\\n\")\ncat(sprintf(\"Media a posteriori: %.3f\\n\", post_mean))\ncat(sprintf(\"Intervallo di credibilit√† al 95%%: [%.3f, %.3f]\\n\", \n            post_ci[1], post_ci[2]))\ncat(sprintf(\"Probabilit√† che p &lt; %.3f: %.3f\\n\", p0, prob_less_than_p0))\n\n# Visualizza il grafico\nprint(p)\nI risultati mostrano che:\n\nLa proporzione osservata nel campione (0.446) √® inferiore al valore di riferimento della popolazione generale (0.485)\nLa distribuzione a priori Beta(48.5, 51.5):\n\n\nHa media 0.485\nRiflette la nostra conoscenza iniziale sulla proporzione di nascite femminili\nFornisce un‚Äôincertezza ragionevole attorno al valore di riferimento\n\n\nLa distribuzione a posteriori:\n\n\nHa una media di circa 0.447\nL‚Äôintervallo di credibilit√† al 95% esclude il valore di riferimento 0.485\nIndica una probabilit√† elevata che la vera proporzione sia inferiore a 0.485\n\n\nQuesta analisi suggerisce che:\n\n\nEsiste un‚Äôassociazione tra placenta previa e una minor proporzione di nascite femminili\nL‚Äôeffetto √® moderato ma statisticamente rilevante\nLa stima √® abbastanza precisa grazie alla dimensione campionaria considerevole\n\n\n\n\n\n\n\n\n\n\nProblemi 4\n\n\n\n\n\nIn uno studio recente, Gori et al. (2024) hanno esaminato un campione di 202 adulti italiani e hanno riscontrato una prevalenza di mancini del 6.4%. Una meta-analisi di Papadatou-Pastou et al. (2020), condotta su un totale di 2,396,170 soggetti, riporta che la proporzione di mancini varia tra il 9.3% e il 18.1%, a seconda di come viene misurata la lateralit√† manuale. Inoltre, Papadatou-Pastou et al. (2020) mostrano che la prevalenza della lateralit√† manuale varia tra i paesi e nel tempo. Considerata questa incertezza, si determini la distribuzione a posteriori che combina i dati dello studio di Gori et al. (2024) con le informazioni pregresse fornite da Papadatou-Pastou et al.¬†(2020). Le informazioni di Papadatou-Pastou et al. (2020) possono essere espresse in termini di una distribuzione Beta(8, 60).\n\n\n\n\n\n\n\n\n\nSoluzioni 4\n\n\n\n\n\n# Caricamento delle librerie necessarie\nlibrary(ggplot2)\n\n# Dati dello studio di Gori et al. (2024)\nn &lt;- 202       # dimensione del campione\ny &lt;- round(0.064 * n)  # numero di mancini (6.4% del campione)\n\n# Parametri della distribuzione beta a priori (da Papadatou-Pastou et al., 2020)\nalpha_prior &lt;- 8\nbeta_prior &lt;- 60\n\n# Calcolo dei parametri della distribuzione beta a posteriori\nalpha_post &lt;- alpha_prior + y\nbeta_post &lt;- beta_prior + (n - y)\n\n# Creazione della griglia per il plotting\np_grid &lt;- seq(0, 0.3, length.out = 1000)  # limitato a 0.3 per migliore visualizzazione\n\n# Calcolo delle densit√†\nprior_density &lt;- dbeta(p_grid, alpha_prior, beta_prior)\nposterior_density &lt;- dbeta(p_grid, alpha_post, beta_post)\n\n# Creazione del dataframe per il plotting\ndf &lt;- data.frame(\n  p = rep(p_grid, 2),\n  density = c(prior_density, posterior_density),\n  distribution = rep(c(\"Priori (Papadatou-Pastou et al., 2020)\", \n                      \"Posteriori (con dati Gori et al., 2024)\"), \n                    each = length(p_grid))\n)\n\n# Calcolo statistiche rilevanti\nprior_mean &lt;- alpha_prior / (alpha_prior + beta_prior)\npost_mean &lt;- alpha_post / (alpha_post + beta_post)\n\nprior_ci &lt;- qbeta(c(0.025, 0.975), alpha_prior, beta_prior)\npost_ci &lt;- qbeta(c(0.025, 0.975), alpha_post, beta_post)\n\n# Creazione del grafico\np &lt;- ggplot(df, aes(x = p, y = density, color = distribution)) +\n  geom_line(size = 1) +\n  geom_vline(xintercept = 0.064, linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Distribuzione della Prevalenza dei Mancini\",\n    subtitle = \"Confronto tra Distribuzione a Priori e a Posteriori\",\n    x = \"Proporzione di Mancini\",\n    y = \"Densit√†\",\n    color = \"Distribuzione\"\n  ) +\n  theme(legend.position = \"bottom\") +\n  annotate(\"text\", x = 0.064, y = max(posterior_density)/2, \n           label = \"Valore osservato (6.4%)\", \n           angle = 90, vjust = -0.5, color = \"red\")\n\n# Output dei risultati\ncat(\"\\nRisultati dell'analisi:\\n\")\ncat(\"------------------------\\n\")\ncat(\"Distribuzione a priori (Papadatou-Pastou et al., 2020):\\n\")\ncat(sprintf(\"Media: %.1f%%\\n\", prior_mean * 100))\ncat(sprintf(\"Intervallo di credibilit√† al 95%%: [%.1f%%, %.1f%%]\\n\\n\", \n            prior_ci[1] * 100, prior_ci[2] * 100))\n\ncat(\"Dati osservati (Gori et al., 2024):\\n\")\ncat(sprintf(\"Campione: %d individui\\n\", n))\ncat(sprintf(\"Mancini osservati: %d (%.1f%%)\\n\\n\", y, y/n * 100))\n\ncat(\"Distribuzione a posteriori:\\n\")\ncat(sprintf(\"Media: %.1f%%\\n\", post_mean * 100))\ncat(sprintf(\"Intervallo di credibilit√† al 95%%: [%.1f%%, %.1f%%]\\n\", \n            post_ci[1] * 100, post_ci[2] * 100))\n\n# Visualizza il grafico\nprint(p)\n# Caricamento delle librerie necessarie\nlibrary(ggplot2)\n\n# Dati dello studio di Gori et al. (2024)\nn &lt;- 202       # dimensione del campione\ny &lt;- round(0.064 * n)  # numero di mancini (6.4% del campione)\n\n# Parametri della distribuzione beta a priori (da Papadatou-Pastou et al., 2020)\nalpha_prior &lt;- 8\nbeta_prior &lt;- 60\n\n# Calcolo dei parametri della distribuzione beta a posteriori\nalpha_post &lt;- alpha_prior + y\nbeta_post &lt;- beta_prior + (n - y)\n\n# Creazione della griglia per il plotting\np_grid &lt;- seq(0, 0.3, length.out = 1000)  # limitato a 0.3 per migliore visualizzazione\n\n# Calcolo delle densit√†\nprior_density &lt;- dbeta(p_grid, alpha_prior, beta_prior)\nposterior_density &lt;- dbeta(p_grid, alpha_post, beta_post)\n\n# Creazione del dataframe per il plotting\ndf &lt;- data.frame(\n  p = rep(p_grid, 2),\n  density = c(prior_density, posterior_density),\n  distribution = rep(c(\"Priori (Papadatou-Pastou et al., 2020)\", \n                      \"Posteriori (con dati Gori et al., 2024)\"), \n                    each = length(p_grid))\n)\n\n# Calcolo statistiche rilevanti\nprior_mean &lt;- alpha_prior / (alpha_prior + beta_prior)\npost_mean &lt;- alpha_post / (alpha_post + beta_post)\n\nprior_ci &lt;- qbeta(c(0.025, 0.975), alpha_prior, beta_prior)\npost_ci &lt;- qbeta(c(0.025, 0.975), alpha_post, beta_post)\n\n# Creazione del grafico\np &lt;- ggplot(df, aes(x = p, y = density, color = distribution)) +\n  geom_line(size = 1) +\n  geom_vline(xintercept = 0.064, linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Distribuzione della Prevalenza dei Mancini\",\n    subtitle = \"Confronto tra Distribuzione a Priori e a Posteriori\",\n    x = \"Proporzione di Mancini\",\n    y = \"Densit√†\",\n    color = \"Distribuzione\"\n  ) +\n  theme(legend.position = \"bottom\") +\n  annotate(\"text\", x = 0.064, y = max(posterior_density)/2, \n           label = \"Valore osservato (6.4%)\", \n           angle = 90, vjust = -0.5, color = \"red\")\n\n# Output dei risultati\ncat(\"\\nRisultati dell'analisi:\\n\")\ncat(\"------------------------\\n\")\ncat(\"Distribuzione a priori (Papadatou-Pastou et al., 2020):\\n\")\ncat(sprintf(\"Media: %.1f%%\\n\", prior_mean * 100))\ncat(sprintf(\"Intervallo di credibilit√† al 95%%: [%.1f%%, %.1f%%]\\n\\n\", \n            prior_ci[1] * 100, prior_ci[2] * 100))\n\ncat(\"Dati osservati (Gori et al., 2024):\\n\")\ncat(sprintf(\"Campione: %d individui\\n\", n))\ncat(sprintf(\"Mancini osservati: %d (%.1f%%)\\n\\n\", y, y/n * 100))\n\ncat(\"Distribuzione a posteriori:\\n\")\ncat(sprintf(\"Media: %.1f%%\\n\", post_mean * 100))\ncat(sprintf(\"Intervallo di credibilit√† al 95%%: [%.1f%%, %.1f%%]\\n\", \n            post_ci[1] * 100, post_ci[2] * 100))\n\n# Visualizza il grafico\nprint(p)\nL‚Äôanalisi bayesiana della prevalenza dei mancini combina le informazioni provenienti dalla meta-analisi di Papadatou-Pastou et al.¬†(2020) con i dati pi√π recenti di Gori et al.¬†(2024). Di seguito sono riportati i principali risultati:\n\n\nDistribuzione a priori (basata su Papadatou-Pastou et al., 2020):\n\nModellata come una distribuzione Beta(8, 60).\n\nPresenta una media intorno all‚Äô11,8%.\n\nRiflette la variabilit√† osservata nella meta-analisi.\n\nL‚Äôintervallo di credibilit√† al 95% copre approssimativamente il range 9,3%-18,1%, come riportato nello studio.\n\n\n\nDati osservati (Gori et al., 2024):\n\n202 partecipanti italiani.\n\n13 mancini, corrispondenti al 6,4% del campione.\n\nQuesto valore √® inferiore alla media stimata dalla meta-analisi globale.\n\n\n\nDistribuzione a posteriori:\n\nCombina le informazioni a priori con i nuovi dati osservati.\n\nLa media a posteriori si √® spostata verso il basso rispetto alla distribuzione a priori.\n\nL‚Äôintervallo di credibilit√† si √® ristretto, indicando una riduzione dell‚Äôincertezza.\n\nMaggiore peso √® stato attribuito ai dati italiani rispetto alla meta-analisi globale.\n\n\n\nInterpretazione:\n\nLa stima finale suggerisce una prevalenza di mancini nella popolazione italiana inferiore alla media globale.\n\nQuesto risultato potrebbe riflettere specificit√† culturali o metodologiche dello studio italiano.\n\nL‚Äôincertezza nella stima finale √® diminuita rispetto alla meta-analisi, ma rimane significativa.\n\nI risultati supportano l‚Äôipotesi di una variabilit√† geografica nella prevalenza della mancinismo.\n\n\n\nLa distribuzione a posteriori fornisce una sintesi equilibrata tra le conoscenze globali precedenti e i dati specifici della popolazione italiana, suggerendo che potrebbero esistere peculiarit√† culturali o demografiche che influenzano la prevalenza del mancinismo in Italia.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>50</span>¬† <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_conjugate_families_1.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/07_conjugate_families_1.html#informazioni-sullambiente-di-sviluppo",
    "title": "50¬† Distribuzioni coniugate (1)",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.17.0      thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0\n#&gt;  [5] see_0.11.0       gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1\n#&gt;  [9] psych_2.5.3      scales_1.3.0     markdown_2.0     knitr_1.50      \n#&gt; [13] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [17] purrr_1.0.4      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [21] ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      shape_1.4.6.1     xfun_0.51         htmlwidgets_1.6.4\n#&gt;  [5] lattice_0.22-6    tzdb_0.5.0        Rdpack_2.6.3      vctrs_0.6.5      \n#&gt;  [9] tools_4.4.2       generics_0.1.3    parallel_4.4.2    pan_1.9          \n#&gt; [13] pacman_0.5.1      jomo_2.7-6        pkgconfig_2.0.3   Matrix_1.7-3     \n#&gt; [17] lifecycle_1.0.4   compiler_4.4.2    farver_2.1.2      munsell_0.5.1    \n#&gt; [21] mnormt_2.1.1      codetools_0.2-20  htmltools_0.5.8.1 glmnet_4.1-8     \n#&gt; [25] nloptr_2.2.1      pillar_1.10.1     MASS_7.3-65       reformulas_0.4.0 \n#&gt; [29] iterators_1.0.14  rpart_4.1.24      boot_1.3-31       mitml_0.4-5      \n#&gt; [33] foreach_1.5.2     nlme_3.1-167      tidyselect_1.2.1  digest_0.6.37    \n#&gt; [37] stringi_1.8.4     labeling_0.4.3    splines_4.4.2     rprojroot_2.0.4  \n#&gt; [41] fastmap_1.2.0     grid_4.4.2        colorspace_2.1-1  cli_3.6.4        \n#&gt; [45] magrittr_2.0.3    survival_3.8-3    broom_1.0.7       withr_3.0.2      \n#&gt; [49] backports_1.5.0   timechange_0.3.0  rmarkdown_2.29    nnet_7.3-20      \n#&gt; [53] lme4_1.1-36       hms_1.1.3         evaluate_1.0.3    rbibutils_2.3    \n#&gt; [57] rlang_1.1.5       Rcpp_1.0.14       glue_1.8.0        minqa_1.2.8      \n#&gt; [61] rstudioapi_0.17.1 jsonlite_1.9.1    R6_2.6.1",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>50</span>¬† <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_conjugate_families_1.html#bibliografia",
    "href": "chapters/bayesian_inference/07_conjugate_families_1.html#bibliografia",
    "title": "50¬† Distribuzioni coniugate (1)",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., Carlin, J. B., Stern, H. S., & Rubin, D. B. (1995). Bayesian data analysis. Chapman; Hall/CRC.\n\n\nGori, B., Grippo, A., Focardi, M., & Lolli, F. (2024). The Italian version of Edinburgh Handedness Inventory: Translation, transcultural adaptation, and validation in healthy subjects. Laterality, 29(2), 151‚Äì168.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nPapadatou-Pastou, M., Ntolka, E., Schmitz, J., Martin, M., Munaf√≤, M. R., Ocklenburg, S., & Paracchini, S. (2020). Human handedness: A meta-analysis. Psychological bulletin, 146(6), 481‚Äì524.\n\n\nScheel, A. M., Schijen, M. R., & Lakens, D. (2021). An excess of positive results: Comparing the standard psychology literature with registered reports. Advances in Methods and Practices in Psychological Science, 4(2), 25152459211007467.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>50</span>¬† <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_conjugate_families_2.html",
    "href": "chapters/bayesian_inference/08_conjugate_families_2.html",
    "title": "51¬† Distribuzioni coniugate (2)",
    "section": "",
    "text": "51.1 Introduzione\nLa statistica bayesiana ci permette di aggiornare le nostre credenze iniziali o conoscenze a priori sulla distribuzione di un parametro (in questo caso, la media della popolazione) in base ai dati osservati. Questo processo di aggiornamento ci porta a ottenere una distribuzione a posteriori che riflette una nuova comprensione del parametro, integrata con le informazioni fornite dal campione.\nIl concetto fondamentale √® che, attraverso l‚Äôaggiornamento bayesiano, l‚Äôincertezza sulla stima del parametro si riduce. Questo √® dovuto al fatto che l‚Äôinformazione aggiuntiva fornita dai dati osservati consente di ‚Äúrestringere‚Äù la distribuzione a posteriori rispetto alla distribuzione a priori, riducendo cos√¨ la varianza (o deviazione standard) della distribuzione del parametro di interesse.\nIn questo capitolo, approfondiremo il tema delle famiglie coniugate (Capitolo 50), focalizzandoci sul modello normale-normale. Una caratteristica distintiva di questo modello √® la sua capacit√† di auto-coniugazione rispetto a una funzione di verosimiglianza gaussiana. In termini pi√π semplici, se la funzione di verosimiglianza segue una distribuzione gaussiana, l‚Äôadozione di una distribuzione a priori gaussiana per la media garantisce che anche la distribuzione a posteriori mantenga la sua forma gaussiana.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>51</span>¬† <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_conjugate_families_2.html#perch√©-usare-la-distribuzione-normale",
    "href": "chapters/bayesian_inference/08_conjugate_families_2.html#perch√©-usare-la-distribuzione-normale",
    "title": "51¬† Distribuzioni coniugate (2)",
    "section": "\n51.2 Perch√© Usare la Distribuzione Normale?",
    "text": "51.2 Perch√© Usare la Distribuzione Normale?\nSpesso, quando la distribuzione a posteriori √® nota per essere unimodale e simmetrica, possiamo modellarla efficacemente con una distribuzione normale, anche se sappiamo che la sua forma √® solo approssimativamente normale. Nei casi in cui il ricercatore abbia un‚Äôidea approssimativa di dove sia centrato un parametro sconosciuto, la distribuzione normale fornisce un metodo utile per modellare questa stima, permettendo di descrivere il livello di incertezza tramite il termine di varianza della distribuzione normale. Questa convenienza pu√≤ offrire buone approssimazioni alla densit√† a posteriori desiderata, con la consapevolezza che, con l‚Äôaumentare dei dati osservati, tali assunzioni perdono di importanza.\nCome dimostrato di seguito, il modello normale bayesiano possiede propriet√† frequentiste desiderabili. Sebbene l‚Äôenfasi nell‚Äôanalisi bayesiana non sia sulle stime puntuali, si pu√≤ dimostrare che, con campioni sempre pi√π grandi, la media della distribuzione a posteriori bayesiana si avvicina alla stima di massima verosimiglianza. Questa propriet√† esiste perch√© la distribuzione a posteriori √® un compromesso ponderato tra la distribuzione a priori specificata dall‚Äôutente, che in questo capitolo √® normale, e la funzione di verosimiglianza derivata dai dati, anch‚Äôessa normale in questo capitolo. Con l‚Äôaumentare delle dimensioni del campione, la verosimiglianza diventa sempre pi√π dominante in questa ponderazione.\nNel caso di una media normale, illustrato qui, la varianza della distribuzione di campionamento frequentista diminuisce con l‚Äôaumento della dimensione del campione. Nel contesto bayesiano, la riduzione della varianza media dalla funzione di verosimiglianza alla fine prevale anche su una varianza a priori deliberatamente grande. Pertanto, se si prevede che la dimensione del dataset sia grande, i ricercatori possono permettersi di essere liberali nella specificazione della varianza a priori.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>51</span>¬† <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_conjugate_families_2.html#distribuzione-a-posteriori-in-un-contesto-normale-con-varianza-nota",
    "href": "chapters/bayesian_inference/08_conjugate_families_2.html#distribuzione-a-posteriori-in-un-contesto-normale-con-varianza-nota",
    "title": "51¬† Distribuzioni coniugate (2)",
    "section": "\n51.3 Distribuzione a Posteriori in un Contesto Normale con Varianza Nota",
    "text": "51.3 Distribuzione a Posteriori in un Contesto Normale con Varianza Nota\nConsideriamo un insieme di dati \\(y = [y_1, y_2, \\ldots, y_n]\\), composto da \\(n\\) osservazioni indipendenti e identicamente distribuite (i.i.d.) secondo una distribuzione normale \\(\\mathcal{N}(\\mu, \\sigma^2)\\). In questo scenario, il nostro obiettivo √® stimare il valore del parametro \\(\\mu\\), che rappresenta la media della popolazione da cui provengono i dati.\n\n51.3.1 Distribuzione a Priori\nNell‚Äôapproccio bayesiano, assumiamo una conoscenza iniziale sul parametro \\(\\mu\\) mediante una distribuzione a priori. In questo caso, utilizziamo una distribuzione normale coniugata, ovvero una distribuzione normale con media \\(\\mu_0\\) e varianza \\(\\sigma_0^2\\). Questa scelta riflette la nostra incertezza iniziale su \\(\\mu\\).\n\n51.3.2 Funzione di Verosimiglianza\nLa funzione di verosimiglianza, denotata da \\(p(y | \\mu, \\sigma)\\), rappresenta la probabilit√† di osservare i dati \\(y\\) dato il valore del parametro \\(\\mu\\) e la varianza nota \\(\\sigma^2\\). Per una distribuzione normale i.i.d., la funzione di verosimiglianza √® data da:\n\\[\np(y | \\mu, \\sigma) = \\prod_{i=1}^n \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp\\left(-\\frac{(y_i - \\mu)^2}{2\\sigma^2}\\right).\n\\]\n\n51.3.3 Teorema di Bayes e Distribuzione a Posteriori\nIl teorema di Bayes combina la distribuzione a priori con la funzione di verosimiglianza per ottenere la distribuzione a posteriori del parametro \\(\\mu\\), data l‚Äôevidenza osservata \\(y\\):\n\\[\np(\\mu | y) = \\frac{ p(y | \\mu) p(\\mu) }{ p(y) }.\n\\]\nPoich√© la distribuzione a priori e la funzione di verosimiglianza sono entrambe distribuzioni normali, la distribuzione a posteriori risulter√† anch‚Äôessa una distribuzione normale con media a posteriori \\(\\mu_p\\) e varianza a posteriori \\(\\sigma_p^2\\).\n\n51.3.4 Formula per la Media a Posteriori (\\(\\mu_p\\))\nLa media a posteriori \\(\\mu_p\\) rappresenta la stima aggiornata del parametro \\(\\mu\\) alla luce delle informazioni contenute nei dati osservati. La sua formula √®:\n\\[\n\\mu_p = \\frac{\\frac{1}{\\sigma_0^2} \\mu_0 + \\frac{n}{\\sigma^2} \\bar{y}}{\\frac{1}{\\sigma_0^2} + \\frac{n}{\\sigma^2}},\n\\]\ndove \\(\\bar{y}\\) rappresenta la media campionaria:\n\\[\n\\bar{y} = \\frac{\\sum_{i=1}^n y_i}{n}.\n\\]\nOsserviamo che \\(\\mu_p\\) √® una combinazione ponderata tra la media a priori \\(\\mu_0\\) e la media campionaria \\(\\bar{y}\\). Il peso di \\(\\bar{y}\\) aumenta con il numero di osservazioni \\(n\\), mentre il peso di \\(\\mu_0\\) diminuisce. Questo riflette il fatto che con pi√π dati, la nostra fiducia nella media campionaria cresce, mentre l‚Äôincertezza a priori diminuisce.\n\n51.3.5 Formula per la Varianza a Posteriori (\\(\\sigma_p^2\\))\nLa varianza a posteriori \\(\\sigma_p^2\\) rappresenta l‚Äôincertezza residua sulla stima del parametro \\(\\mu\\) dopo aver incorporato le informazioni dai dati. La sua formula √®:\n\\[\n\\sigma_p^2 = \\frac{1}{\\frac{1}{\\sigma_0^2} + \\frac{n}{\\sigma^2}}.\n\\]\nRispetto alla varianza a priori \\(\\sigma_0^2\\), la varianza a posteriori \\(\\sigma_p^2\\) √® sempre inferiore o uguale. In altre parole, l‚Äôincertezza sulla stima di \\(\\mu\\) si riduce con l‚Äôaumentare del numero di osservazioni. La varianza a posteriori rappresenta un bilanciamento tra l‚Äôincertezza a priori (\\(\\sigma_0^2\\)) e l‚Äôinformazione derivata dai dati (\\(\\sigma^2/n\\)).\nIn sintesi, nel caso normale-normale con varianza nota, la distribuzione a posteriori risulta essere una distribuzione normale con una media e una varianza che riflettono un‚Äôintegrazione bilanciata tra l‚Äôinformazione a priori e quella ottenuta dai dati osservati. Questo approccio garantisce una stima aggiornata e affinata del parametro \\(\\mu\\) che migliora con l‚Äôaumento del numero di osservazioni.\n\nEsempio 51.1 I test standard di QI sono progettati per misurare l‚Äôintelligenza con una media di 100 e una deviazione standard di 15. Tuttavia, si dice anche che questi test presentino bias culturali che favoriscono alcuni gruppi rispetto ad altri. Un‚Äôulteriore complicazione si verifica quando i punteggi di QI vengono aggregati a livello nazionale, poich√© le caratteristiche interne ai paesi vengono mascherate. Questo esempio analizza i dati di QI raccolti a livello internazionale (Lynn e Vanhanen, 2001) per 80 paesi da fonti nazionali pubblicate e discussi da Gill (2015). L‚Äôidea chiave nella descrizione della distribuzione a posteriori √® se le differenze tra le nazioni alterano la parametrizzazione prevista.\nI dati di Lynn e Vanhanen (2001) sono forniti di seguito:\n\n\n\n\n\n\n\n\n\n\n\n\nPaese\nIQ\nPaese\nIQ\nPaese\nIQ\nPaese\nIQ\n\n\n\nArgentina\n96\nAustralia\n98\nAustria\n102\nBarbados\n78\n\n\nBelgium\n100\nBrazil\n87\nBulgaria\n93\nCanada\n97\n\n\nChina\n100\nCongo (Br.)\n73\nCongo (Zr.)\n65\nCroatia\n90\n\n\nCuba\n85\nCzech Repub.\n97\nDenmark\n98\nEcuador\n80\n\n\nEgypt\n83\nEq. Guinea\n59\nEthiopia\n63\nFiji\n84\n\n\nFinland\n97\nFrance\n98\nGermany\n102\nGhana\n71\n\n\nGreece\n92\nGuatemala\n79\nGuinea\n66\nHong Kong\n107\n\n\nHungary\n99\nIndia\n81\nIndonesia\n89\nIran\n84\n\n\nIraq\n87\nIreland\n93\nIsrael\n94\nItaly\n102\n\n\nJamaica\n72\nJapan\n105\nKenya\n72\nKorea (S.)\n106\n\n\nLebanon\n86\nMalaysia\n92\nMarshall I.\n84\nMexico\n87\n\n\nMorocco\n85\nNepal\n78\nNetherlands\n102\nNew Zealand\n100\n\n\nNigeria\n67\nNorway\n98\nPeru\n90\nPhilippines\n86\n\n\nPoland\n99\nPortugal\n95\nPuerto Rico\n84\nQatar\n78\n\n\nRomania\n94\nRussia\n96\nSamoa\n87\nSierra Leone\n64\n\n\nSingapore\n103\nSlovakia\n96\nSlovenia\n95\nSouth Africa\n72\n\n\nSpain\n97\nSudan\n72\nSuriname\n89\nSweden\n101\n\n\nSwitzerland\n101\nTaiwan\n104\nTanzania\n72\nThailand\n91\n\n\nTonga\n87\nTurkey\n90\nUganda\n73\nU.K.\n100\n\n\nU.S.\n98\nUruguay\n96\nZambia\n77\nZimbabwe\n66\n\n\n\nImplementiamo le informazioni necessarie in Python.\n\n# Dati IQ delle 80 nazioni\niq &lt;- c(\n  96, 100, 100, 85, 83, 97, 92, 99, 87, 72, 86, 85, 67, 99, 94, 103, 97, 101, \n  87, 98, 87, 73, 97, 59, 98, 79, 81, 93, 105, 92, 78, 98, 95, 96, 72, 104, \n  90, 96, 98, 102, 78, 90, 63, 84, 84, 107, 86, 102, 106, 94, 102, 72, 101, \n  89, 72, 101, 91, 100, 100, 66, 107, 86, 78, 84, 78, 64, 72, 101, 91, 100, \n  67, 86\n)\n\n\n# Numero di osservazioni\nn &lt;- length(iq)\n\n# Media campionaria\ny_bar &lt;- mean(iq)\n\n# Deviazione standard nota\nsigma &lt;- 15\n\n# Parametri a priori\nmu_0 &lt;- 100\nsigma_0 &lt;- 15\n\nCalcoliamo la media a posteriori con la formula discussa in precedenza\n\\[\n\\mu_p = \\frac{\\frac{1}{\\sigma_0^2}\\mu_0 + \\frac{n}{\\sigma^2}\\bar{y}}{\\frac {1}{\\sigma_0^2} + \\frac{n}{\\sigma^2}}\n\\]\ndove:\n\n\n\\(\\mu_0\\) √® la media a priori\n\n\\(\\sigma_0\\) √® la deviazione standard a priori\n\n\\(n\\) √® il numero di osservazioni\n\n\\(\\sigma\\) √® la deviazione standard delle osservazioni (nota)\n\n\\(\\bar{y}\\) √® la media campionaria\n\n\nmu_p &lt;- ((1 / sigma_0^2) * mu_0 + (n / sigma^2) * y_bar) /\n  ((1 / sigma_0^2) + (n / sigma^2))\nprint(paste(\"Media a posteriori (mu_p):\", round(mu_p, 2)))\n#&gt; [1] \"Media a posteriori (mu_p): 89.36\"\n\nCalcoliamo la varianza a posteriori\n\\[\n\\sigma_p^2 = \\frac{1}{\\frac {1}{\\sigma_0^2}+ \\frac{n}{\\sigma^2}}\n\\]\n\nsigma_p_sq &lt;- 1 / ((1 / sigma_0^2) + (n / sigma^2))\nsigma_p &lt;- sqrt(sigma_p_sq)\nprint(paste(\"Varianza a posteriori (sigma_p_sq):\", round(sigma_p_sq, 2)))\n#&gt; [1] \"Varianza a posteriori (sigma_p_sq): 3.08\"\n\nGeneriamo una rappresentazione grafica della distribuzione a posteriori della media del IQ sulla base dei dati osservati, avendo assunto mu_0 = 100 e sigma_0 = 15 per la distribuzione a priori.\n\n# Definizione dei valori sull'asse x\nx &lt;- seq(mu_p - 4 * sigma_p, mu_p + 4 * sigma_p, length.out = 1000)\n\n# Calcolo della densit√† di probabilit√†\npdf &lt;- dnorm(x, mean = mu_p, sd = sigma_p)\n\n# Creazione del grafico\nggplot(data.frame(x = x, pdf = pdf), aes(x = x, y = pdf)) +\n  geom_line(color = \"blue\", linewidth = 1) +\n  geom_area(aes(fill = \"Posterior\"), alpha = 0.2) +\n  scale_fill_manual(values = c(\"blue\")) +\n  labs(\n    x = \"Media del Quoziente di Intelligenza\",\n    y = \"Densit√† di probabilit√†\"\n  ) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\nL‚Äôanalisi condotta mediante un modello bayesiano basato sulla distribuzione normale ha prodotto un risultato interessante: la media stimata della distribuzione a posteriori del QI si attesta a 89.36, un valore sensibilmente inferiore ai 100 punti previsti come media standard.\nTuttavia, per un‚Äôinterpretazione completa di questo dato, √® fondamentale adottare un approccio critico che consideri alcuni aspetti cruciali:\n\nLa media a posteriori √® ottenuta aggregando i dati QI di 80 nazioni diverse. Questo processo pu√≤ innescare un effetto di aggregazione, dove la media ‚Äúsmussata‚Äù risultante non rispecchia accuratamente la distribuzione del QI a livello individuale in ogni singola nazione. Di conseguenza, le differenze tra le nazioni in termini di QI medio e variabilit√† potrebbero essere mascherate da questa media aggregata.\n√à importante sottolineare che la media a posteriori viene calcolata utilizzando dati non ponderati per ogni nazione. Ci√≤ significa che nazioni con popolazioni pi√π piccole, anche se con punteggi QI mediamente pi√π alti o pi√π bassi, hanno lo stesso impatto sulla media aggregata rispetto a nazioni con popolazioni pi√π grandi. Questo aspetto potrebbe ulteriormente distorcere la rappresentazione della vera distribuzione globale del QI.\nLa deviazione osservata dalla media standard di 100 potrebbe non riflettere esclusivamente differenze nell‚Äôintelligenza media tra le nazioni, ma anche differenze nei contesti sanitari, sociologici e politici in cui i test sono stati somministrati. Fattori quali l‚Äôaccesso all‚Äôistruzione, la qualit√† della nutrizione e l‚Äôesposizione a stimoli cognitivi possono influenzare i punteggi QI ottenuti e contribuire alla variabilit√† osservata tra le nazioni.\nInoltre, √® fondamentale considerare la possibilit√† di un bias culturale intrinseco allo strumento stesso. I test del QI sono stati originariamente progettati per un contesto specifico (paese industrializzato di lingua inglese) e potrebbero non essere adatti o culturalmente sensibili a contesti differenti. Questo potrebbe portare a una sottostima dei punteggi QI in alcune nazioni e influenzare la media a posteriori aggregata.\n\nQuesti risultati evidenziano l‚Äôimportanza di un‚Äôattenta considerazione dei fattori metodologici quando si interpretano dati di test del QI a livello trans-culturale. L‚Äôeffetto di aggregazione, l‚Äôutilizzo di medie non ponderate, le differenze nei contesti e il potenziale bias culturale richiedono un‚Äôanalisi pi√π approfondita che consideri questi fattori e utilizzi metodi statistici pi√π sofisticati per ottenere una comprensione pi√π completa delle differenze nel QI tra le nazioni.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>51</span>¬† <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_conjugate_families_2.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/08_conjugate_families_2.html#riflessioni-conclusive",
    "title": "51¬† Distribuzioni coniugate (2)",
    "section": "\n51.4 Riflessioni Conclusive",
    "text": "51.4 Riflessioni Conclusive\nIn questo capitolo, abbiamo approfondito il meccanismo dell‚Äôaggiornamento bayesiano attraverso l‚Äôimplementazione del modello normale-normale. Il processo inizia definendo una distribuzione a priori per \\(\\mu\\), specificata da una media \\(\\mu_0\\) e una varianza \\(\\sigma_0^2\\). Dopo l‚Äôacquisizione di nuovi dati, ipotizzando che seguano una distribuzione Normale con media campionaria \\(\\bar{y}\\) e varianza nota \\(\\sigma^2\\), implementiamo il teorema normale-normale per derivare la distribuzione a posteriori del parametro.\nLa media della distribuzione a posteriori, denotata come \\(\\mu_{\\text{post}}\\), si configura come una media ponderata tra la media a priori \\(\\mu_0\\) e la media campionaria \\(\\bar{y}\\), dove il peso assegnato a ciascuna media √® determinato dalle rispettive varianze \\(\\sigma_0^2\\) e \\(\\sigma^2\\) della distribuzione a priori e dei dati osservati. Analogamente, la varianza a posteriori \\(\\sigma_{\\text{post}}^2\\) √® determinata utilizzando un‚Äôespressione che incorpora entrambe le varianze.\nIn sintesi, l‚Äôadozione del modello normale-normale in un contesto bayesiano facilita il calcolo delle distribuzioni a posteriori, grazie alla scelta di una distribuzione a priori Normale che mantiene la propriet√† di coniugatezza, semplificando cos√¨ l‚Äôintero processo analitico.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>51</span>¬† <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_conjugate_families_2.html#esercizi",
    "href": "chapters/bayesian_inference/08_conjugate_families_2.html#esercizi",
    "title": "51¬† Distribuzioni coniugate (2)",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nRiprendi i dati della SWLS che sono stati utilizzati nell‚Äôesercizio del Capitolo 49. Trova la media e la deviazione standard della distribuzione a posteriori usando il metodo delle distribuzioni coniugate. Confronta i risultati con quelli ottenuti con il metodo basato su griglia.\nConsegna: Carica il file .qmd, convertito in PDF, su Moodle.\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\nPer risolvere questo esercizio con il metodo delle distribuzioni coniugate, assumiamo che i dati provengano da una distribuzione normale con deviazione standard nota e media da stimare. Nel caso di una verosimiglianza gaussiana con prior gaussiano, la distribuzione a posteriori sar√† ancora una distribuzione normale. Questo approccio √® analitico e ci permette di ottenere la media e la deviazione standard della distribuzione a posteriori senza dover ricorrere a metodi numerici come la discretizzazione della griglia.\nPassaggi per il calcolo della distribuzione a posteriori\n\n\nDefiniamo i dati osservati:\n\nLa media campionaria: \\(\\bar{x}\\)\n\nLa deviazione standard nota dei dati: \\(\\sigma\\)\n\nIl numero di osservazioni: \\(n\\)\n\n\n\n\nScegliamo un prior gaussiano molto diffuso:\n\nMedia a priori: \\(\\mu_0\\)\n\nDeviazione standard a priori molto grande: \\(\\sigma_0\\)\n\n\n\n\nCalcoliamo la media e la varianza della distribuzione a posteriori:\n\n\nLa media a posteriori √®:\n\\[\n\\mu_{\\text{post}} = \\frac{\\sigma^2_0 \\bar{x} + \\sigma^2 n \\mu_0}{\\sigma^2_0 + \\sigma^2 n}\n\\]\n\n\nLa varianza a posteriori √®:\n\\[\n\\sigma^2_{\\text{post}} = \\frac{\\sigma^2_0 \\sigma^2}{\\sigma^2_0 + \\sigma^2 n}\n\\]\n\n\n\n\nImplementazione in R\n# Caricamento librerie necessarie\nlibrary(dplyr)\nlibrary(tibble)\n\n# Dati SWLS\nswls_data &lt;- data.frame(\n  soddisfazione = c(4.2, 5.1, 4.7, 4.3, 5.5, 4.9, 4.8, 5.0, 4.6, 4.4)\n)\n\n# Parametri comuni per entrambi i metodi\nsigma_conosciuta &lt;- sd(swls_data$soddisfazione)  # Usando la deviazione standard campionaria\nn &lt;- nrow(swls_data)\nmean_x &lt;- mean(swls_data$soddisfazione)\n\ncat(\"Deviazione standard campionaria:\", sigma_conosciuta, \"\\n\")\ncat(\"Media campionaria:\", mean_x, \"\\n\")\n\n# ---- Metodo 1: Griglia ----\n# Definizione della griglia pi√π fine e centrata intorno alla media campionaria\nmu_griglia &lt;- seq(mean_x - 3*sigma_conosciuta/sqrt(n), \n                 mean_x + 3*sigma_conosciuta/sqrt(n), \n                 length.out = 1000)\n\n# Calcolo della verosimiglianza\nlog_likelihood &lt;- numeric(length(mu_griglia))\nfor (i in seq_along(mu_griglia)) {\n  # Utilizzo della log-likelihood per evitare problemi numerici\n  log_likelihood[i] &lt;- sum(dnorm(swls_data$soddisfazione, \n                                mean = mu_griglia[i], \n                                sd = sigma_conosciuta, \n                                log = TRUE))\n}\n\n# Prior uniforme (in scala logaritmica)\nlog_prior &lt;- rep(0, length(mu_griglia))\n\n# Calcolo della posteriori\nlog_posterior &lt;- log_likelihood + log_prior\nposterior &lt;- exp(log_posterior - max(log_posterior))\nposterior &lt;- posterior / sum(posterior)\n\n# Campionamento e calcolo statistiche\nsamples_grid &lt;- sample(mu_griglia, size = 10000, replace = TRUE, prob = posterior)\nmean_post_grid &lt;- mean(samples_grid)\nsd_post_grid &lt;- sd(samples_grid)\nci_grid &lt;- quantile(samples_grid, c(0.03, 0.97))\n\n# ---- Metodo 2: Soluzione analitica ----\n# Prior poco informativo ma non improprio\nmu_prior &lt;- mean_x\nsigma_prior &lt;- 10\n\n# Calcolo posteriori\nmu_post_analytic &lt;- (sigma_prior^2 * mean_x + sigma_conosciuta^2 * mu_prior/n) / \n                    (sigma_prior^2 + sigma_conosciuta^2/n)\nsigma_post_analytic &lt;- sqrt((sigma_prior^2 * sigma_conosciuta^2/n) / \n                           (sigma_prior^2 + sigma_conosciuta^2/n))\n\n# Confronto risultati\nresults &lt;- tibble(\n  Metodo = c(\"Griglia\", \"Analitico\"),\n  `Media Posteriori` = c(mean_post_grid, mu_post_analytic),\n  `Dev. Std. Posteriori` = c(sd_post_grid, sigma_post_analytic)\n)\nresults\nInterpretazione dei risultati\n\nLa media a posteriori rappresenta la miglior stima aggiornata della media della popolazione dopo aver osservato i dati.\nLa deviazione standard a posteriori ci dice quanto √® incerta la nostra stima della media dopo aver integrato i dati e il prior.\n\nSiccome abbiamo scelto un prior molto diffuso (\\(\\sigma_0 = 10\\)), il risultato ottenuto √® molto vicino a quello ottenuto con il metodo della griglia, dove il prior uniforme aveva un impatto minimo sulla distribuzione a posteriori.\nQuesta implementazione analitica permette di ottenere il risultato in modo efficiente senza necessit√† di metodi numerici approssimati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>51</span>¬† <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_conjugate_families_2.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/08_conjugate_families_2.html#informazioni-sullambiente-di-sviluppo",
    "title": "51¬† Distribuzioni coniugate (2)",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.17.0      thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0\n#&gt;  [5] see_0.11.0       gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1\n#&gt;  [9] psych_2.5.3      scales_1.3.0     markdown_2.0     knitr_1.50      \n#&gt; [13] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [17] purrr_1.0.4      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [21] ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      shape_1.4.6.1     xfun_0.51         htmlwidgets_1.6.4\n#&gt;  [5] lattice_0.22-6    tzdb_0.5.0        Rdpack_2.6.3      vctrs_0.6.5      \n#&gt;  [9] tools_4.4.2       generics_0.1.3    parallel_4.4.2    pan_1.9          \n#&gt; [13] pacman_0.5.1      jomo_2.7-6        pkgconfig_2.0.3   Matrix_1.7-3     \n#&gt; [17] lifecycle_1.0.4   compiler_4.4.2    farver_2.1.2      munsell_0.5.1    \n#&gt; [21] mnormt_2.1.1      codetools_0.2-20  htmltools_0.5.8.1 glmnet_4.1-8     \n#&gt; [25] nloptr_2.2.1      pillar_1.10.1     MASS_7.3-65       reformulas_0.4.0 \n#&gt; [29] iterators_1.0.14  rpart_4.1.24      boot_1.3-31       mitml_0.4-5      \n#&gt; [33] foreach_1.5.2     nlme_3.1-167      tidyselect_1.2.1  digest_0.6.37    \n#&gt; [37] stringi_1.8.4     labeling_0.4.3    splines_4.4.2     rprojroot_2.0.4  \n#&gt; [41] fastmap_1.2.0     grid_4.4.2        colorspace_2.1-1  cli_3.6.4        \n#&gt; [45] magrittr_2.0.3    survival_3.8-3    broom_1.0.7       withr_3.0.2      \n#&gt; [49] backports_1.5.0   timechange_0.3.0  rmarkdown_2.29    nnet_7.3-20      \n#&gt; [53] lme4_1.1-36       hms_1.1.3         evaluate_1.0.3    rbibutils_2.3    \n#&gt; [57] rlang_1.1.5       Rcpp_1.0.14       glue_1.8.0        minqa_1.2.8      \n#&gt; [61] rstudioapi_0.17.1 jsonlite_1.9.1    R6_2.6.1",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>51</span>¬† <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_conjugate_families_2.html#bibliografia",
    "href": "chapters/bayesian_inference/08_conjugate_families_2.html#bibliografia",
    "title": "51¬† Distribuzioni coniugate (2)",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGill, J. (2015). Bayesian methods: A social and behavioral sciences approach (3rd Edition). Chapman; Hall/CRC.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>51</span>¬† <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_summary_posterior.html",
    "href": "chapters/bayesian_inference/09_summary_posterior.html",
    "title": "52¬† Sintesi a posteriori",
    "section": "",
    "text": "52.1 Introduzione\nIn questo capitolo, concentriamo la nostra attenzione sulla sintesi dell‚Äôinformazione racchiusa nella distribuzione a posteriori, la quale rappresenta il nostro livello di incertezza riguardo al parametro o ai parametri incogniti oggetto dell‚Äôinferenza.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>52</span>¬† <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_summary_posterior.html#riepilogo-numerico",
    "href": "chapters/bayesian_inference/09_summary_posterior.html#riepilogo-numerico",
    "title": "52¬† Sintesi a posteriori",
    "section": "\n52.2 Riepilogo numerico",
    "text": "52.2 Riepilogo numerico\nLa distribuzione a posteriori contiene in s√© tutte le informazioni disponibili sui potenziali valori del parametro. Nel caso di un parametro unidimensionale o bidimensionale, possiamo rappresentare la distribuzione a posteriori mediante un grafico \\(p(\\theta \\mid y)\\).\nTuttavia, quando ci troviamo di fronte a vettori di parametri con pi√π di due dimensioni, risulta vantaggioso eseguire una sintesi numerica della distribuzione a posteriori. Possiamo distinguere due forme di sintesi numerica della distribuzione a posteriori:\n\nStima puntuale;\nIntervallo di credibilit√†.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>52</span>¬† <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_summary_posterior.html#stima-puntuale",
    "href": "chapters/bayesian_inference/09_summary_posterior.html#stima-puntuale",
    "title": "52¬† Sintesi a posteriori",
    "section": "\n52.3 Stima puntuale",
    "text": "52.3 Stima puntuale\nNel contesto dell‚Äôinferenza bayesiana, stimare il valore pi√π credibile di un parametro \\(\\theta\\) a partire dalla distribuzione a posteriori pu√≤ avvenire attraverso tre statistiche principali: moda, mediana e media. La scelta tra queste dipende dalla forma della distribuzione a posteriori.\nQueste statistiche forniscono una stima puntuale della tendenza centrale della distribuzione, ossia il valore a cui attribuiamo il massimo grado di fiducia soggettiva, basandoci sia sui dati osservati sia sulle credenze a priori.\n1. Moda (Massimo a Posteriori, MAP)\nLa moda √® il valore pi√π probabile del parametro, ovvero quello che massimizza la distribuzione a posteriori. Questo valore √® noto come massimo a posteriori (MAP).\nIl concetto di MAP deriva dalla stima di massima verosimiglianza (MLE), che individua il valore di \\(\\theta\\) che massimizza la funzione di verosimiglianza:\n\\[\n\\hat{\\theta}_{ML} = \\arg \\max_\\theta L(\\theta \\mid y).  \n\\]\nNell‚Äôinferenza bayesiana, consideriamo \\(\\theta\\) come una variabile casuale con una distribuzione a priori \\(p(\\theta)\\). Incorporando questa informazione nella funzione di verosimiglianza, otteniamo la stima MAP:\n\\[\n\\hat{\\theta}_{MAP} = \\arg \\max_\\theta L(\\theta \\mid y)p(\\theta).  \n\\]\nQuesta formula mostra che il MAP √® il valore che massimizza la densit√† a posteriori di \\(\\theta\\) dato il set di dati osservati \\(y\\).\nLimitazioni della stima MAP:\n\n\nDifficolt√† computazionali: con metodi MCMC, √® complesso individuare con precisione il MAP nello spazio delle distribuzioni posteriori.\n\n\nSensibilit√† alla forma della distribuzione: se la distribuzione a posteriori √® asimmetrica o multimodale, il MAP potrebbe non rappresentare adeguatamente la tendenza centrale.\n\n\nMinor robustezza rispetto ad altre misure: il MAP si basa esclusivamente sul valore massimo della distribuzione e non tiene conto della distribuzione complessiva della probabilit√†.\n2. Media a posteriori\nLa media a posteriori √® il valore atteso di \\(\\theta\\) secondo la distribuzione a posteriori:\n\\[\nE(\\theta \\mid y) = \\int_{-\\infty}^{\\infty} \\theta \\, p(\\theta \\mid y) \\, d\\theta.  \n\\]\nQuesta stima √® spesso preferita perch√© considera l‚Äôintera distribuzione e minimizza l‚Äôerrore quadratico medio (Mean Squared Error, MSE). Tuttavia, se la distribuzione a posteriori √® asimmetrica, la media potrebbe non rappresentare bene la posizione della maggior parte della probabilit√†.\n3. Mediana a posteriori\nLa mediana a posteriori √® il valore che divide la distribuzione a posteriori in due parti uguali, con il 50% della probabilit√† a sinistra e il 50% a destra.\nLa mediana √® una stima robusta della tendenza centrale ed √® particolarmente utile in distribuzioni asimmetriche o multimodali, dove la moda e la media potrebbero risultare fuorvianti.\nMisurare l‚Äôincertezza: varianza a posteriori\nOltre a stimare la tendenza centrale, √® utile valutare l‚Äôincertezza associata alla stima di \\(\\theta\\). La varianza a posteriori misura la dispersione della distribuzione:\n\\[\nV(\\theta|y) = E[((\\theta - E[(\\theta|y)])^2 |y) = \\int_{-\\infty}^{\\infty} (\\theta - E[\\theta | y])^2 p(\\theta | y) d\\theta = E[\\theta^2 |y] - E[\\theta|y]^2.  \n\\]\nLa deviazione standard a posteriori (radice quadrata della varianza) esprime l‚Äôincertezza sulla stima \\(\\theta\\) con la stessa unit√† di misura dei dati.\nIn sintesi, la moda (MAP), la media e la mediana a posteriori offrono diverse prospettive sulla stima puntuale di un parametro \\(\\theta\\). Ciascuna ha vantaggi e limiti, e la scelta migliore dipende dalla forma della distribuzione a posteriori e dal contesto applicativo.\nInsieme alla varianza a posteriori, queste statistiche forniscono un quadro completo della distribuzione a posteriori, permettendo di esprimere non solo la stima pi√π credibile, ma anche l‚Äôincertezza associata.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>52</span>¬† <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_summary_posterior.html#intervallo-di-credibilit√†",
    "href": "chapters/bayesian_inference/09_summary_posterior.html#intervallo-di-credibilit√†",
    "title": "52¬† Sintesi a posteriori",
    "section": "\n52.4 Intervallo di credibilit√†",
    "text": "52.4 Intervallo di credibilit√†\nNell‚Äôinferenza bayesiana, l‚Äôintervallo di credibilit√† √® uno strumento utilizzato per definire un intervallo che contiene una determinata percentuale della massa della distribuzione a posteriori del parametro \\(\\theta\\). Questo intervallo riflette l‚Äôincertezza associata alla stima del parametro: un intervallo pi√π ampio suggerisce una maggiore incertezza. Lo scopo principale dell‚Äôintervallo di credibilit√† √® fornire una misura quantitativa dell‚Äôincertezza riguardante \\(\\theta\\).\nA differenza degli intervalli di confidenza frequentisti, non esiste un unico intervallo di credibilit√† per un dato livello di confidenza \\((1 - \\alpha) \\cdot 100\\%\\). In effetti, √® possibile costruire un numero infinito di tali intervalli. Per questo motivo, √® necessario stabilire criteri aggiuntivi per selezionare l‚Äôintervallo di credibilit√† pi√π appropriato. Tra le opzioni pi√π comuni ci sono l‚Äôintervallo di credibilit√† simmetrico e l‚Äôintervallo di massima densit√† posteriore (HPD).\n1. Intervallo di Credibilit√† Simmetrico\nQuesto tipo di intervallo √® centrato rispetto al punto di stima puntuale. Se \\(\\hat{\\theta}\\) rappresenta la stima del parametro, l‚Äôintervallo simmetrico avr√† la forma \\((\\hat{\\theta} - a, \\hat{\\theta} + a)\\), dove \\(a\\) √® un valore positivo scelto in modo tale che la massa totale inclusa sia pari a \\((1 - \\alpha)\\). Pi√π formalmente, un intervallo di credibilit√† simmetrico al livello \\(\\alpha\\) pu√≤ essere espresso come:\n\\[\nI_{\\alpha} = [q_{\\alpha/2}, q_{1 - \\alpha/2}],\n\\]\ndove \\(q_z\\) rappresenta il quantile \\(z\\) della distribuzione a posteriori. Ad esempio, un intervallo di credibilit√† simmetrico al 94% sar√†:\n\\[\nI_{0.06} = [q_{0.03}, q_{0.97}],\n\\]\ndove il 3% della massa a posteriori si trova in ciascuna delle due code della distribuzione.\n2. Intervallo di Credibilit√† Pi√π Stretto (Intervallo di Massima Densit√† Posteriore, HPD)\nL‚Äôintervallo di massima densit√† posteriore (HPD) √® l‚Äôintervallo pi√π stretto possibile che contiene il \\((1 - \\alpha) \\cdot 100\\%\\) della massa a posteriori. A differenza dell‚Äôintervallo simmetrico, l‚ÄôHPD include tutti i valori di \\(\\theta\\) che hanno la maggiore densit√† a posteriori. Per costruirlo, si disegna una linea orizzontale sulla distribuzione a posteriori e si regola l‚Äôaltezza della linea in modo che l‚Äôarea sotto la curva corrisponda a \\((1 - \\alpha)\\). L‚ÄôHPD risulta essere il pi√π stretto tra tutti gli intervalli possibili per lo stesso livello di confidenza. Nel caso di una distribuzione a posteriori unimodale e simmetrica, l‚ÄôHPD coincide con l‚Äôintervallo di credibilit√† simmetrico.\n\n52.4.1 Interpretazione\nIl calcolo degli intervalli di credibilit√†, in particolare dell‚Äôintervallo di massima densit√† posteriore (HPD), richiede spesso l‚Äôuso di software statistici avanzati. Questo perch√© determinare manualmente tali intervalli pu√≤ essere complicato, soprattutto nei modelli bayesiani con distribuzioni posteriori complesse o quando sono necessarie simulazioni numeriche per stimare la distribuzione a posteriori.\nUn aspetto cruciale dell‚Äôinferenza bayesiana riguarda l‚Äôinterpretazione dell‚Äôincertezza. Nel contesto frequentista, si considera il parametro, come ad esempio la media della popolazione \\(\\mu\\), come un valore fisso ma sconosciuto. L‚Äôinferenza frequentista si basa sull‚Äôimmaginare un numero infinito di campioni ripetuti dalla popolazione. Per ogni campione, si pu√≤ calcolare una media campionaria \\(\\bar{x}\\) e formare un intervallo di confidenza al \\(100(1-\\alpha)\\%\\). L‚Äôinterpretazione corretta in termini frequentisti √® che, nel lungo periodo, il \\(100(1-\\alpha)\\%\\) degli intervalli di confidenza costruiti con questo metodo conterr√† il vero valore del parametro \\(\\mu\\). Tuttavia, per un singolo intervallo calcolato, la probabilit√† che contenga effettivamente \\(\\mu\\) √® o 0 o 1, poich√© \\(\\mu\\) √® considerato un valore fisso.\nNel framework bayesiano, invece, il parametro √® trattato come una variabile aleatoria con una distribuzione di probabilit√†. Campionando dalla distribuzione a posteriori dei parametri, possiamo ottenere quantili che ci permettono di calcolare direttamente la probabilit√† che un parametro rientri in un determinato intervallo. Ad esempio, un intervallo di credibilit√† al 95% indica che c‚Äô√® una probabilit√† del 95% che il parametro sia contenuto all‚Äôinterno di quell‚Äôintervallo, data l‚Äôevidenza osservata. Questa interpretazione differisce profondamente da quella frequentista e risulta pi√π intuitiva, poich√© riflette direttamente il grado di incertezza che abbiamo riguardo al parametro.\nIn sintesi, mentre l‚Äôintervallo di confidenza frequentista riguarda la ripetizione ipotetica del campionamento, l‚Äôintervallo di credibilit√† bayesiano fornisce una misura diretta dell‚Äôincertezza attuale sul valore di un parametro, basata sui dati osservati e sulle informazioni a priori. Questo approccio √® spesso considerato pi√π vicino al senso comune quando si tratta di interpretare la probabilit√† associata ai parametri.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>52</span>¬† <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_summary_posterior.html#verifica-di-ipotesi-bayesiana",
    "href": "chapters/bayesian_inference/09_summary_posterior.html#verifica-di-ipotesi-bayesiana",
    "title": "52¬† Sintesi a posteriori",
    "section": "\n52.5 Verifica di ipotesi bayesiana",
    "text": "52.5 Verifica di ipotesi bayesiana\nL‚Äôinferenza bayesiana pu√≤ essere applicata anche nel contesto della verifica di ipotesi, in un approccio noto come verifica di ipotesi bayesiana. In questo tipo di inferenza, l‚Äôobiettivo √® valutare la plausibilit√† che un parametro \\(\\theta\\) assuma valori all‚Äôinterno di un determinato intervallo. Ad esempio, possiamo voler sapere quanto √® probabile che \\(\\theta\\) sia maggiore di 0.5 o che rientri in un intervallo specifico, come [0.5, 1.0].\nIn questo approccio, si calcola la probabilit√† a posteriori che \\(\\theta\\) si trovi all‚Äôinterno dell‚Äôintervallo di interesse. Questa probabilit√† viene ottenuta integrando la distribuzione a posteriori su tale intervallo. Quindi, invece di rifiutare o accettare un‚Äôipotesi come nel test di ipotesi frequentista, la verifica di ipotesi bayesiana fornisce una misura diretta della probabilit√† che un parametro rientri in un intervallo specifico, dato l‚Äôevidenza osservata e le informazioni a priori.\nIn altre parole, questo approccio consente di quantificare la nostra incertezza rispetto all‚Äôaffermazione che \\(\\theta\\) rientri in un certo intervallo, fornendo una probabilit√† che rappresenta direttamente la plausibilit√† di quell‚Äôipotesi.\n\nEsempio 52.1 Per illustrare l‚Äôapproccio bayesiano, consideriamo i dati relativi ai punteggi del BDI-II (Beck Depression Inventory - Second Edition) di 30 soggetti clinici, come riportato nello studio condotto da Zetsche et al. (2019). Il BDI-II √® uno strumento per valutare la gravit√† dei sintomi depressivi.\nI punteggi del BDI-II per i 30 soggetti sono:\n\n# Dati del BDI-II\nbdi &lt;- c(\n  26, 35, 30, 25, 44, 30, 33, 43, 22, 43, \n  24, 19, 39, 31, 25, 28, 35, 30, 26, 31, \n  41, 36, 26, 35, 33, 28, 27, 34, 27, 22\n)\nbdi\n#&gt;  [1] 26 35 30 25 44 30 33 43 22 43 24 19 39 31 25 28 35 30 26 31 41 36 26 35\n#&gt; [25] 33 28 27 34 27 22\n\nUn punteggio BDI-II \\(\\geq 30\\) indica un livello grave di depressione. Nel nostro campione, 17 pazienti su 30 manifestano un livello grave:\n\n# Conteggio di depressione grave\nsum(bdi &gt;= 30)\n#&gt; [1] 17\n\nStima della distribuzione a posteriori.\nSupponiamo di voler stimare la probabilit√† \\(\\theta\\) di depressione grave nei pazienti clinici utilizzando una distribuzione a priori \\(Beta(8, 2)\\). I dati possono essere visti come una sequenza di prove Bernoulliane indipendenti, dove la presenza di depressione grave √® un ‚Äúsuccesso‚Äù. La verosimiglianza √® quindi binomiale con parametri \\(n = 30\\) e \\(y = 17\\).\nCon una distribuzione a priori \\(Beta(8, 2)\\), la distribuzione a posteriori di \\(\\theta\\) sar√†:\n\\[\n\\text{Beta}(\\alpha = 8 + 17, \\beta = 2 + 30 - 17) = \\text{Beta}(25, 15).\n\\]\nTracciamo la distribuzione a posteriori.\n\n# Parametri della distribuzione Beta\nalpha &lt;- 25\nbeta &lt;- 15\n\n# Calcolo della densit√† per valori di theta\ntheta &lt;- seq(0, 1, length.out = 200)\nposterior_density &lt;- dbeta(theta, alpha, beta)\n\n# Grafico della distribuzione a posteriori\nggplot(data = data.frame(theta, posterior_density), aes(x = theta, y = posterior_density)) +\n  geom_line() +\n  labs(\n    title = \"Distribuzione a Posteriori Beta(25, 15)\",\n    x = expression(theta),\n    y = \"Densit√† di probabilit√†\"\n  ) \n\n\n\n\n\n\n\nStime puntuali.\n\n\nMedia a Posteriori\nLa media della distribuzione a posteriori √® calcolata come:\n\n\\[\n\\mathbb{E}(\\theta | y = 17) = \\frac{\\alpha}{\\alpha + \\beta} = \\frac{25}{25 + 15} = 0.625.\n\\]\nIn R:\n\n# Calcolo della media a posteriori\nposterior_mean &lt;- alpha / (alpha + beta)\nposterior_mean\n#&gt; [1] 0.625\n\n\n\nModa a Posteriori (MAP)\nLa moda della distribuzione a posteriori √®:\n\n\\[\nMo(\\theta | y = 17) = \\frac{\\alpha - 1}{\\alpha + \\beta - 2} = \\frac{25 - 1}{25 + 15 - 2} = 0.6316.\n\\]\nIn R:\n\n# Calcolo della moda a posteriori\nposterior_mode &lt;- (alpha - 1) / (alpha + beta - 2)\nposterior_mode\n#&gt; [1] 0.6316\n\n\n\nMediana a Posteriori\nLa mediana si ottiene utilizzando la funzione di distribuzione cumulativa inversa:\n\n\n# Calcolo della mediana a posteriori\nposterior_median &lt;- qbeta(0.5, alpha, beta)\nposterior_median\n#&gt; [1] 0.6271\n\nIntervallo di credibilit√†.\nL‚Äôintervallo di credibilit√† simmetrico al 94% √® dato dai percentili 3% e 97%:\n\n# Intervallo di credibilit√† simmetrico al 94%\ncred_interval &lt;- qbeta(c(0.03, 0.97), alpha, beta)\ncred_interval\n#&gt; [1] 0.4781 0.7613\n\nPossiamo interpretare questo intervallo come segue: c‚Äô√® una certezza soggettiva del 94% che \\(\\theta\\) sia compreso tra 0.478 e 0.761.\nVerifica di ipotesi bayesiana.\nInfine, calcoliamo la probabilit√† che \\(\\theta &gt; 0.5\\):\n\\[\nP(\\theta &gt; 0.5 | y = 17) = \\int_{0.5}^1 f(\\theta | y = 17) d\\theta.\n\\]\nIn R:\n\n# Probabilit√† P(theta &gt; 0.5)\nprob_theta_greater_0_5 &lt;- pbeta(0.5, alpha, beta, lower.tail = FALSE)\nprob_theta_greater_0_5\n#&gt; [1] 0.9459\n\nIn conclusione, utilizzando un approccio bayesiano, abbiamo stimato la distribuzione a posteriori di \\(\\theta\\), ottenuto stime puntuali e costruito intervalli di credibilit√†. Abbiamo inoltre calcolato la probabilit√† che \\(\\theta\\) superi una soglia specifica, mostrando la flessibilit√† e l‚Äôinterpretabilit√† delle analisi bayesiane.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>52</span>¬† <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_summary_posterior.html#sintesi-della-distribuzione-a-posteriori-questioni-multivariate",
    "href": "chapters/bayesian_inference/09_summary_posterior.html#sintesi-della-distribuzione-a-posteriori-questioni-multivariate",
    "title": "52¬† Sintesi a posteriori",
    "section": "\n52.6 Sintesi della distribuzione a posteriori: questioni multivariate",
    "text": "52.6 Sintesi della distribuzione a posteriori: questioni multivariate\nQuando si affronta un‚Äôanalisi bayesiana con pi√π parametri, la complessit√† aumenta. Le principali difficolt√† riguardano le interazioni tra i parametri e il modo in cui queste influenzano le distribuzioni marginali. Questi fattori possono complicare notevolmente la sintesi della distribuzione a posteriori e, se non considerati attentamente, possono portare a interpretazioni errate.\n\n52.6.1 Correlazioni nascoste e distribuzioni marginali\nUn problema comune nelle analisi con pi√π parametri √® rappresentato dalle correlazioni tra i parametri. Le distribuzioni marginali a posteriori, spesso riportate nei riassunti statistici, possono essere molto fuorvianti se considerate isolatamente. Quando i parametri sono fortemente correlati, le distribuzioni marginali possono apparire piatte o poco informative, inducendo a pensare che non ci sia molta informazione nella verosimiglianza.\nTuttavia, le correlazioni tra parametri possono restringere notevolmente lo spazio delle combinazioni plausibili, escludendo vaste aree dello spazio dei parametri. Questo significa che, nonostante le marginali possano sembrare non informative, l‚Äôanalisi congiunta dei parametri pu√≤ rivelare una struttura sottostante che riduce l‚Äôincertezza su specifiche combinazioni. Pertanto, √® essenziale esaminare le correlazioni congiunte tra i parametri per ottenere una visione pi√π completa dell‚Äôincertezza.\nCon un numero maggiore di parametri, anche i grafici di correlazione bidimensionali possono diventare limitati, poich√© potrebbero esistere correlazioni di ordine superiore che non emergono in rappresentazioni a due dimensioni.\n\n52.6.2 Correlazioni non lineari\nUn‚Äôaltra difficolt√† significativa riguarda le correlazioni non lineari tra i parametri. Quando queste correlazioni sono presenti, il massimo delle distribuzioni marginali non coincide necessariamente con il massimo della distribuzione congiunta. Per esempio, se due parametri presentano una correlazione complessa, come una forma a ‚Äúbanana‚Äù, il massimo delle distribuzioni marginali potrebbe trovarsi in una posizione diversa rispetto al massimo globale della distribuzione congiunta.\nQuesto fenomeno rende pi√π difficile sintetizzare correttamente la distribuzione a posteriori. In tali casi, la stima del massimo a posteriori (MAP) o altri riassunti, come gli intervalli di credibilit√† (CI) o gli intervalli di massima densit√† a posteriori (HPD), calcolati sulle marginali, potrebbero essere fuorvianti. Quando la distribuzione a posteriori √® asimmetrica nello spazio multivariato, le distribuzioni marginali non catturano adeguatamente le relazioni tra i parametri. Questa √® una fonte comune di confusione, poich√© si tende a sottovalutare l‚Äôimportanza della struttura multivariata nella distribuzione a posteriori.\n\n52.6.3 Strategie per affrontare queste sfide\n\n\nConfronto tra distribuzioni predittive:\n\nConfrontare la distribuzione predittiva a priori con quella a posteriori offre una visione pi√π completa della riduzione dell‚Äôincertezza.\nQuesto approccio √® particolarmente utile in presenza di parametri multipli e correlazioni complesse, poich√© la distribuzione predittiva a posteriori incorpora le interazioni tra i parametri, fornendo una rappresentazione pi√π accurata della plausibilit√† dei diversi valori parametrici.\n\n\n\nAnalisi congiunta:\n\nEsaminare le distribuzioni congiunte dei parametri, oltre alle distribuzioni marginali.\nUtilizzare grafici di dispersione bivariati o multivariati per visualizzare le relazioni tra i parametri.\nTecniche avanzate di visualizzazione, come i pair plots o le heatmap, possono essere utili per esplorare relazioni in spazi ad alta dimensionalit√†.\n\n\n\nMisure di dipendenza:\n\nUtilizzare misure di dipendenza non lineare, come la correlazione di Spearman o l‚Äôinformazione mutua, che possono catturare relazioni complesse che le misure lineari tradizionali potrebbero non rilevare.\n\n\n\nAnalisi di sensibilit√†:\n\nCondurre un‚Äôanalisi di sensibilit√† per valutare come i cambiamenti in un parametro influenzano gli altri parametri e le previsioni del modello. Questo permette di capire meglio le relazioni tra i parametri e il loro impatto sulle inferenze.\n\n\n\nTecniche di riduzione della dimensionalit√†:\n\nQuando ci sono molti parametri, l‚Äôuso di metodi come l‚Äôanalisi delle componenti principali (PCA) pu√≤ aiutare a identificare strutture latenti e ridurre la complessit√† del problema, facilitando l‚Äôinterpretazione dei risultati.\n\n\n\nIn sintesi, l‚Äôanalisi multivariata in un contesto bayesiano richiede particolare attenzione nella sintesi delle distribuzioni a posteriori. Le distribuzioni marginali possono fornire informazioni utili, ma spesso nascondono importanti correlazioni e strutture di dipendenza tra i parametri. Un‚Äôanalisi completa dovrebbe combinare l‚Äôesame delle marginali con una valutazione attenta delle relazioni congiunte tra i parametri, utilizzando tecniche di visualizzazione e misure di dipendenza adeguate. Questo approccio integrato permette di comprendere pi√π a fondo la distribuzione a posteriori e di trarre inferenze pi√π robuste e accurate.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>52</span>¬† <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_summary_posterior.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/09_summary_posterior.html#riflessioni-conclusive",
    "title": "52¬† Sintesi a posteriori",
    "section": "\n52.7 Riflessioni Conclusive",
    "text": "52.7 Riflessioni Conclusive\nIn conclusione, la distribuzione a posteriori rappresenta la nostra conoscenza aggiornata sui parametri sconosciuti. L‚Äôimpiego delle statistiche descrittive e l‚Äôanalisi degli intervalli di credibilit√† contribuiscono a tracciare un quadro completo della distribuzione a posteriori e delle nostre inferenze riguardo al parametro di interesse.\nLe stime puntuali, ottenute attraverso statistiche descrittive come media, mediana o moda a posteriori, offrono una singola valutazione numerica del parametro ignoto. Gli intervalli di credibilit√† forniscono un intervallo di valori all‚Äôinterno del quale si ritiene, con un certo grado di probabilit√† soggettiva, che il parametro incognito possa rientrare. Questi intervalli quantificano l‚Äôincertezza associata al parametro e consentono di esprimere il livello di fiducia soggettiva riguardo ai possibili valori del parametro dopo l‚Äôanalisi dei dati. Abbiamo inoltre esaminato il concetto di test di ipotesi bayesiano, il quale pu√≤ essere condotto agevolmente calcolando l‚Äôarea appropriata sotto la distribuzione a posteriori, in accordo con l‚Äôipotesi in questione.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>52</span>¬† <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_summary_posterior.html#esercizi",
    "href": "chapters/bayesian_inference/09_summary_posterior.html#esercizi",
    "title": "52¬† Sintesi a posteriori",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n1. Quali sono le principali statistiche utilizzate per la stima puntuale di un parametro nella distribuzione a posteriori?\n\nSpiega le differenze tra moda (MAP), media a posteriori e mediana.\nIn quali contesti √® preferibile utilizzare una di queste statistiche rispetto alle altre?\n\n2. Qual √® la differenza tra un intervallo di credibilit√† bayesiano e un intervallo di confidenza frequentista?\n\nSpiega le differenze concettuali tra i due approcci.\nQuale dei due √® pi√π intuitivo in termini di incertezza sui parametri?\n\n3. Cos‚Äô√® un intervallo di massima densit√† posteriore (HPD) e in cosa si differenzia dall‚Äôintervallo di credibilit√† simmetrico?\n\nSpiega il concetto di HPD e perch√© √® pi√π informativo in alcuni casi.\nIn quali situazioni l‚ÄôHPD √® preferibile rispetto all‚Äôintervallo di credibilit√† simmetrico?\n\n4. Quali sono le problematiche associate alla moda (MAP) come stima puntuale?\n\nPerch√© il MAP pu√≤ essere meno affidabile rispetto ad altre statistiche?\nQuali problemi si possono incontrare nei modelli bayesiani complessi?\n\n5. In che modo la sintesi della distribuzione a posteriori cambia nel caso di pi√π parametri incogniti?\n\nQuali sono le principali difficolt√† nell‚Äôinterpretare la distribuzione congiunta di pi√π parametri?\nCome si possono visualizzare e sintetizzare distribuzioni posteriori multivariate?\n\nüìå Domande applicative in R\nPer queste domande, usa il dataset basato sulla Satisfaction with Life Scale (SWLS), supponendo che i dati seguano una distribuzione normale.\n1. Calcola la media, la mediana e la moda a posteriori della distribuzione della media SWLS, assumendo una distribuzione a priori gaussiana molto diffusa. - Usa il metodo delle distribuzioni coniugate per ottenere la distribuzione a posteriori.\n2. Costruisci un intervallo di credibilit√† simmetrico al 94% per la media SWLS.\n\nUsa la distribuzione normale a posteriori per calcolare l‚Äôintervallo.\n\n3. Visualizza la distribuzione a posteriori della media SWLS con un grafico di densit√†.\n\nGenera un campione dalla distribuzione a posteriori e rappresentalo con ggplot2.\n\n4. Confronta l‚Äôintervallo di credibilit√† simmetrico con l‚Äôintervallo di massima densit√† posteriore (HPD).\n\nUsa la funzione hdi() del pacchetto bayestestR per calcolare l‚ÄôHPD.\n\n5. Calcola la probabilit√† a posteriori che la media SWLS sia minore di 23.\n\nUsa la distribuzione a posteriori per calcolare questa probabilit√†.\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n1. Quali sono le principali statistiche utilizzate per la stima puntuale di un parametro nella distribuzione a posteriori?\nLe tre principali statistiche usate per ottenere una stima puntuale del parametro \\(\\theta\\) nella distribuzione a posteriori sono:\n\n\nModa (Massimo a Posteriori, MAP)\n\n√à il valore di \\(\\theta\\) che massimizza la distribuzione a posteriori \\(p(\\theta \\mid y)\\).\n\nSe la distribuzione √® unimodale e simmetrica, il MAP coincide con la media a posteriori.\n\nIl MAP √® spesso simile alla stima di massima verosimiglianza (MLE) quando il prior √® uniforme.\n\n\n\nMedia a Posteriori\n\n√à il valore atteso della distribuzione a posteriori:\\[\nE(\\theta \\mid y) = \\int \\theta \\, p(\\theta \\mid y) \\, d\\theta\n\\]\n\n√à la stima pi√π utile quando si vuole minimizzare l‚Äôerrore quadratico medio (MSE).\n\nRisente dell‚Äôeventuale asimmetria della distribuzione, spostandosi verso le code.\n\n\n\nMediana a Posteriori\n\n√à il valore che divide la distribuzione a posteriori in due parti uguali:\\[\nP(\\theta \\leq \\theta_{\\text{mediana}} \\mid y) = 0.5\n\\]\n\n√à pi√π robusta agli outlier rispetto alla media ed √® utile quando la distribuzione √® fortemente asimmetrica.\n\n\n\nüí° Quando usarle? - Se la distribuzione √® simmetrica, tutte e tre le statistiche coincidono. - Se la distribuzione √® asimmetrica, la mediana √® pi√π robusta, la media pu√≤ essere influenzata dalle code e il MAP √® utile se si vuole un valore pi√π probabile.\n2. Qual √® la differenza tra un intervallo di credibilit√† bayesiano e un intervallo di confidenza frequentista?\n\n\n\n\n\n\n\nCaratteristica\nIntervallo di Credibilit√† (Bayesiano)\nIntervallo di Confidenza (Frequentista)\n\n\n\nSignificato\nEsprime la probabilit√† che il parametro sia nell‚Äôintervallo, dati i dati osservati.\n√à una propriet√† di un metodo di campionamento: se si ripetesse l‚Äôesperimento infinite volte, il \\((1 - \\alpha)100\\%\\) degli intervalli conterrebbe il vero valore del parametro.\n\n\nApproccio\nAssume che il parametro sia una variabile casuale con una distribuzione di probabilit√†.\nAssume che il parametro sia fisso e sconosciuto, mentre i dati sono casuali.\n\n\nInterpretazione\n‚ÄúC‚Äô√® il 95% di probabilit√† che il parametro sia tra questi valori.‚Äù\n‚ÄúSe ripetessimo l‚Äôesperimento molte volte, il 95% degli intervalli conterrebbe il vero parametro.‚Äù\n\n\n\nüí° Differenza fondamentale:\n\nL‚Äôintervallo di credibilit√† √® probabilistico e pi√π intuitivo: si pu√≤ direttamente dire che il parametro ha il 95% di probabilit√† di trovarsi nell‚Äôintervallo.\n\nL‚Äôintervallo di confidenza √® basato sulla ripetizione ipotetica dell‚Äôesperimento e non pu√≤ essere interpretato in termini probabilistici sul singolo intervallo.\n\n3. Cos‚Äô√® un intervallo di massima densit√† posteriore (HPD) e in cosa si differenzia dall‚Äôintervallo di credibilit√† simmetrico?\nL‚Äôintervallo di massima densit√† posteriore (HPD) √® l‚Äôintervallo pi√π stretto che contiene una percentuale fissata (es. 94%) della distribuzione a posteriori. Si distingue dall‚Äôintervallo di credibilit√† simmetrico perch√©:\n\n\n\n\n\n\n\nCaratteristica\nIntervallo HPD\nIntervallo di Credibilit√† Simmetrico\n\n\n\nDefinizione\nContiene il \\((1 - \\alpha)100\\%\\) della probabilit√† a posteriori, minimizzando la lunghezza dell‚Äôintervallo.\n√à centrato attorno alla mediana e copre una frazione fissa della distribuzione.\n\n\nForma\nPu√≤ essere asimmetrico e discontinuo se la distribuzione √® multimodale.\n√à sempre simmetrico.\n\n\nVantaggio\n√à pi√π informativo se la distribuzione √® asimmetrica o multimodale.\n√à pi√π facile da calcolare, specialmente per distribuzioni unimodali.\n\n\n\nüí° Quando usarli?\n\nSe la distribuzione √® simmetrica, entrambi gli intervalli danno risultati simili.\n\nSe la distribuzione √® asimmetrica o multimodale, l‚ÄôHPD √® pi√π informativo.\n\n4. Quali sono le problematiche associate alla moda (MAP) come stima puntuale?\nSebbene il MAP sia un concetto intuitivo (il valore pi√π probabile della distribuzione a posteriori), presenta alcune limitazioni:\n\n\nDifficolt√† computazionale con MCMC\n\nCon metodi di campionamento come Markov Chain Monte Carlo (MCMC), trovare il massimo della distribuzione a posteriori √® difficile perch√© la funzione viene stimata in modo discreto.\nSpesso si preferisce stimare media o mediana, pi√π facili da calcolare con MCMC.\n\n\n\nSensibilit√† ai dati e al prior\n\nIl MAP dipende fortemente dal prior scelto.\nSe il prior √® informativo, il MAP pu√≤ spostarsi troppo rispetto ai dati.\n\n\n\nProblemi con distribuzioni multimodali\n\nSe la distribuzione a posteriori ha pi√π di un massimo (moda), il MAP potrebbe non essere una buona rappresentazione della distribuzione.\n\n\n\nüí° Quando evitarlo?\n- Se la distribuzione a posteriori √® asimmetrica o multimodale. - Se si usa un metodo MCMC, dove la media o la mediana sono pi√π semplici da stimare.\n5. In che modo la sintesi della distribuzione a posteriori cambia nel caso di pi√π parametri incogniti?\nQuando l‚Äôinferenza bayesiana coinvolge pi√π parametri (es. \\(\\mu\\) e \\(\\sigma\\)), l‚Äôanalisi diventa pi√π complessa per diversi motivi:\n\n\nInterazioni tra parametri\n\nI parametri spesso non sono indipendenti: la distribuzione a posteriori congiunta pu√≤ mostrare correlazioni che non emergono dalle distribuzioni marginali.\n\n\n\nDifficolt√† di visualizzazione\n\nPer un parametro si usa un istogramma o una funzione di densit√†.\nPer due parametri si usa un contour plot o un grafico 3D.\nCon pi√π di due parametri, si ricorre a pair plots o matrici di correlazione.\n\n\n\nStimare margine e congiunta\n\nLa distribuzione marginale di un parametro si ottiene integrando la distribuzione congiunta rispetto agli altri parametri: \\[\np(\\theta_1) = \\int p(\\theta_1, \\theta_2) d\\theta_2\n\\]\n\nSe i parametri sono fortemente correlati, le marginali possono nascondere informazioni importanti.\n\n\n\nRischio di correlazioni non lineari\n\nLe correlazioni non lineari tra i parametri possono portare a distribuzioni con forme complesse (es. a banana), rendendo difficile la sintesi con MAP o media.\n\n\n\nüí° Strategie per affrontare il problema:\n- Visualizzare le correlazioni tra i parametri con scatter plot o heatmap.\n- Usare tecniche di riduzione della dimensionalit√† come PCA (Analisi delle Componenti Principali).\n- Utilizzare il MCMC per campionare direttamente dalla distribuzione congiunta.\nEsercizio in R con i dati SWLS\nNell‚Äôesercizio, usa i dati della SWLS che sono stati raccolti. Qui useremo i dati seguenti:\nswls_data &lt;- data.frame(\n  soddisfazione = c(4.2, 5.1, 4.7, 4.3, 5.5, 4.9, 4.8, 5.0, 4.6, 4.4)\n)\n1. Calcola la media, la mediana e la moda a posteriori della distribuzione della media SWLS, assumendo una distribuzione a priori gaussiana molto diffusa.\n\nUsa il metodo delle distribuzioni coniugate per ottenere la distribuzione a posteriori.\n\nlibrary(tibble)\n\n# Dati\nn &lt;- nrow(swls_data)\nmean_x &lt;- mean(swls_data$soddisfazione)\nsigma &lt;- 1  # Deviazione standard nota\n\n# Prior diffuso\nmu_prior &lt;- 4.5    \nsigma_prior &lt;- 10  \n\n# Media a posteriori\nmu_post &lt;- (sigma_prior^2 * mean_x + sigma^2 * n * mu_prior) / (sigma_prior^2 + sigma^2 * n)\n\n# Deviazione standard a posteriori\nsigma_post &lt;- sqrt((sigma_prior^2 * sigma^2) / (sigma_prior^2 + sigma^2 * n))\n\n# Moda (MAP)\nposterior_mode &lt;- mu_post  # Per una distribuzione normale, MAP coincide con la media\n\n# Mediana (simile alla media in una distribuzione normale)\nposterior_median &lt;- mu_post\n\ntibble(\"Media a Posteriori\" = mu_post,\n       \"Moda (MAP)\" = posterior_mode,\n       \"Mediana\" = posterior_median)\n2. Costruisci un intervallo di credibilit√† simmetrico al 94% per la media SWLS.\n\nUsa la distribuzione normale a posteriori per calcolare l‚Äôintervallo.\n\ncred_interval &lt;- qnorm(c(0.03, 0.97), mean = mu_post, sd = sigma_post)\ncred_interval\n3. Visualizza la distribuzione a posteriori della media SWLS con un grafico di densit√†.\n\nGenera un campione dalla distribuzione a posteriori e rappresentalo con ggplot2.\n\nlibrary(ggplot2)\n\n# Campionamento dalla distribuzione a posteriori\nset.seed(123)\nsamples &lt;- rnorm(1000, mean = mu_post, sd = sigma_post)\n\n# Creazione del dataframe\nsamples_df &lt;- tibble(media_campionata = samples)\n\n# Grafico della distribuzione a posteriori\nggplot(samples_df, aes(x = media_campionata)) +\n  geom_density(fill = \"blue\", alpha = 0.5) +\n  labs(title = \"Distribuzione a Posteriori della Media SWLS\",\n       x = \"Media\", y = \"Densit√†\")\n4. Confronta l‚Äôintervallo di credibilit√† simmetrico con l‚Äôintervallo di massima densit√† posteriore (HPD).\n\nUsa la funzione hdi() del pacchetto bayestestR per calcolare l‚ÄôHPD.\n\nlibrary(bayestestR)\n\n# Calcolo intervallo HPD al 94%\nhpd_interval &lt;- hdi(samples, ci = 0.94)\nhpd_interval\n5. Calcola la probabilit√† a posteriori che la media SWLS sia minore di 23 ‚Äì per fare un esempio, qui caloleremo per i dati simulati la probabilit√† a posteriori per la media SWLS maggiore di 4.7.\n\nUsa la distribuzione a posteriori per calcolare questa probabilit√†.\n\nprob_greater_4_7 &lt;- 1 - pnorm(4.7, mean = mu_post, sd = sigma_post)\nprob_greater_4_7",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>52</span>¬† <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_summary_posterior.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/09_summary_posterior.html#informazioni-sullambiente-di-sviluppo",
    "title": "52¬† Sintesi a posteriori",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.17.0      thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0\n#&gt;  [5] see_0.11.0       gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1\n#&gt;  [9] psych_2.5.3      scales_1.3.0     markdown_2.0     knitr_1.50      \n#&gt; [13] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [17] purrr_1.0.4      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [21] ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      shape_1.4.6.1     xfun_0.51         htmlwidgets_1.6.4\n#&gt;  [5] lattice_0.22-6    tzdb_0.5.0        Rdpack_2.6.3      vctrs_0.6.5      \n#&gt;  [9] tools_4.4.2       generics_0.1.3    parallel_4.4.2    pan_1.9          \n#&gt; [13] pacman_0.5.1      jomo_2.7-6        pkgconfig_2.0.3   Matrix_1.7-3     \n#&gt; [17] lifecycle_1.0.4   compiler_4.4.2    farver_2.1.2      munsell_0.5.1    \n#&gt; [21] mnormt_2.1.1      codetools_0.2-20  htmltools_0.5.8.1 glmnet_4.1-8     \n#&gt; [25] nloptr_2.2.1      pillar_1.10.1     MASS_7.3-65       reformulas_0.4.0 \n#&gt; [29] iterators_1.0.14  rpart_4.1.24      boot_1.3-31       mitml_0.4-5      \n#&gt; [33] foreach_1.5.2     nlme_3.1-167      tidyselect_1.2.1  digest_0.6.37    \n#&gt; [37] stringi_1.8.4     labeling_0.4.3    splines_4.4.2     rprojroot_2.0.4  \n#&gt; [41] fastmap_1.2.0     grid_4.4.2        colorspace_2.1-1  cli_3.6.4        \n#&gt; [45] magrittr_2.0.3    survival_3.8-3    broom_1.0.7       withr_3.0.2      \n#&gt; [49] backports_1.5.0   timechange_0.3.0  rmarkdown_2.29    nnet_7.3-20      \n#&gt; [53] lme4_1.1-36       hms_1.1.3         evaluate_1.0.3    rbibutils_2.3    \n#&gt; [57] rlang_1.1.5       Rcpp_1.0.14       glue_1.8.0        minqa_1.2.8      \n#&gt; [61] rstudioapi_0.17.1 jsonlite_1.9.1    R6_2.6.1",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>52</span>¬† <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_summary_posterior.html#bibliografia",
    "href": "chapters/bayesian_inference/09_summary_posterior.html#bibliografia",
    "title": "52¬† Sintesi a posteriori",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nZetsche, U., Buerkner, P.-C., & Renneberg, B. (2019). Future expectations in clinical depression: biased or realistic? Journal of Abnormal Psychology, 128(7), 678‚Äì688.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>52</span>¬† <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_balance_prior_post.html",
    "href": "chapters/bayesian_inference/10_balance_prior_post.html",
    "title": "53¬† L‚Äôinfluenza della distribuzione a priori",
    "section": "",
    "text": "53.1 Introduzione\nConsideriamo un semplice scenario medico: un paziente si presenta dal dottore con un mal di testa. Il medico, per formulare una diagnosi accurata, dovr√† considerare diversi fattori. Possiamo immaginare due medici con approcci leggermente differenti:\nQuale dei due medici √® in grado di fornire una diagnosi pi√π precisa? La risposta risiede nel concetto di probabilit√† a priori (o semplicemente prior), ovvero le credenze che un individuo ha su un evento prima di osservare nuovi dati.\nNel contesto medico, la storia clinica del paziente rappresenta una preziosa fonte di informazioni a priori. Conoscere gli antecedenti sanitari di un individuo permette al medico di formulare ipotesi pi√π plausibili sulla causa del mal di testa. In termini bayesiani, i priori agiscono come una sorta di ‚Äúlente‚Äù attraverso cui vengono interpretati i nuovi dati (in questo caso, i risultati dei test).\nQuando prendiamo decisioni nella vita quotidiana, utilizziamo costantemente le nostre conoscenze pregresse per interpretare nuove informazioni. Ad esempio, se vediamo una persona che indossa un camice bianco in un ospedale, inferiamo che si tratti di un medico, basandoci sulla nostra esperienza e sulle associazioni mentali che abbiamo costruito nel tempo. Questo processo di inferenza √® molto simile a quello che avviene nell‚Äôaggiornamento bayesiano.\nLa scelta dei priori ha un impatto fondamentale sulla qualit√† delle inferenze che possiamo trarre dai dati. Questo capitolo si focalizza sull‚Äôimportanza e sulle implicazioni che derivano dalla scelta dei priori sul processo di aggiornamento bayesiano. Per illustrare questi concetti, esamineremo alcuni esempi discussi da Johnson et al. (2022).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>53</span>¬† <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_balance_prior_post.html#introduzione",
    "href": "chapters/bayesian_inference/10_balance_prior_post.html#introduzione",
    "title": "53¬† L‚Äôinfluenza della distribuzione a priori",
    "section": "",
    "text": "Medico 1: Si basa principalmente sui risultati di test specifici, senza considerare una storia clinica pregressa del paziente.\n\nMedico 2: Oltre ai test, tiene conto della storia clinica del paziente, cercando di individuare eventuali fattori di rischio o condizioni preesistenti che potrebbero essere correlate al mal di testa.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>53</span>¬† <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_balance_prior_post.html#la-distribuzione-a-priori",
    "href": "chapters/bayesian_inference/10_balance_prior_post.html#la-distribuzione-a-priori",
    "title": "53¬† L‚Äôinfluenza della distribuzione a priori",
    "section": "\n53.2 La Distribuzione a Priori",
    "text": "53.2 La Distribuzione a Priori\nLa distribuzione a priori gioca un ruolo centrale nell‚Äôapproccio bayesiano, poich√© rappresenta le nostre conoscenze pregresse o le ipotesi sui parametri del modello prima di osservare i dati. Questo concetto √® fondamentale perch√© permette di integrare le informazioni disponibili in precedenza con i dati osservati, fornendo cos√¨ una stima pi√π precisa e robusta dei parametri. Le distribuzioni a priori possono variare a seconda del grado di certezza che si attribuisce ai valori dei parametri.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>53</span>¬† <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_balance_prior_post.html#tipologie-di-distribuzioni-a-priori",
    "href": "chapters/bayesian_inference/10_balance_prior_post.html#tipologie-di-distribuzioni-a-priori",
    "title": "53¬† L‚Äôinfluenza della distribuzione a priori",
    "section": "\n53.3 Tipologie di Distribuzioni a Priori",
    "text": "53.3 Tipologie di Distribuzioni a Priori\nLa scelta della distribuzione a priori (nota come elicitazione della prior) √® uno dei passaggi cruciali nell‚Äôanalisi bayesiana ed √® spesso vista come la fase pi√π controversa, poich√© √® considerata ‚Äúsoggettiva‚Äù. Tuttavia, √® importante sottolineare che la scelta della prior non √® necessariamente soggettiva. A differenza dell‚Äôapproccio frequentista, l‚Äôapproccio bayesiano incoraggia la raccolta e l‚Äôintegrazione di tutte le informazioni conosciute sul parametro in anticipo. Questo pu√≤ essere fatto in modo oggettivo, basandosi su evidenze pregresse o raccomandazioni consolidate.\nEsistono tre principali categorie di distribuzioni a priori.\n\nDistribuzioni a Priori Non Informative. Le distribuzioni a priori non informative sono caratterizzate da una totale mancanza di conoscenza pregressa e assegnano la stessa credibilit√† a tutti i valori dei parametri. Un esempio comune di distribuzione a priori non informativa √® la distribuzione uniforme, basata sul ‚ÄúPrincipio della Ragione Insufficiente‚Äù formulato da Laplace. Secondo questo principio, in assenza di evidenze rilevanti pregresse, tutte le possibili configurazioni dei parametri sono considerate equiprobabili.\n\nDistribuzioni a Priori Debolmente Informative. Le distribuzioni a priori debolmente informative consentendo di integrare una quantit√† limitata di informazioni pregresse nei modelli statistici. Queste distribuzioni sono progettate per riflettere le nostre assunzioni su quali possono essere i valori ‚Äúragionevoli‚Äù dei parametri del modello, tenendo conto delle incertezze presenti nell‚Äôanalisi. L‚Äôuso di informazioni a priori debolmente informative pu√≤ contribuire a migliorare la stabilit√† dell‚Äôanalisi senza influenzare in modo significativo le conclusioni derivate da essa.\nLe distribuzioni a priori debolmente informative hanno la caratteristica di non ‚Äúspostare‚Äù in modo significativo la distribuzione a posteriori in una direzione specifica. In altre parole, sono centrate su valori ‚Äúneutri‚Äù dei parametri. Ad esempio, quando si trattano parametri che possono assumere valori positivi o negativi, la distribuzione a priori debolmente informativa potrebbe essere centrata sullo zero. Nel caso di parametri che rappresentano proporzioni, essa potrebbe essere centrata su 0.5.\nTuttavia, ci√≤ che rende queste distribuzioni debolmente informative √® la specifica definizione di un intervallo ‚Äúplausibile‚Äù di valori dei parametri. Questo intervallo indica quali valori dei parametri sono considerati plausibili e quali sono invece considerati implausibili. Ad esempio, una distribuzione a priori debolmente informativa potrebbe suggerire che valori estremamente grandi o estremamente bassi dei parametri sono poco plausibili, concentrandosi su un intervallo pi√π stretto di valori considerati ragionevoli.\nIn sintesi, le distribuzioni a priori debolmente informative sono utilizzate per incorporare informazioni pregresse limitate nei modelli bayesiani, contribuendo a stabilizzare le stime dei parametri senza influenzare in modo significativo le conclusioni derivate dai dati. Queste distribuzioni definiscono un intervallo plausibile di valori dei parametri, aiutando a guidare l‚Äôanalisi verso soluzioni pi√π verosimili senza imporre vincoli eccessivi sui risultati.\n\n\nDistribuzioni a Priori Informativa. Le conoscenze pregresse, acquisite attraverso ricerche precedenti, pareri esperti o una combinazione di entrambi, possono essere meticolosamente integrate nel processo di analisi mediante l‚Äôincorporazione nelle distribuzioni a priori. Queste distribuzioni sono comunemente conosciute come distribuzioni a priori informative. Esse rappresentano un mezzo per codificare in modo sistematico informazioni concrete e rilevanti che possono avere un notevole impatto sull‚Äôanalisi statistica, fornendo una solida base di conoscenza su cui fondare l‚Äôinferenza bayesiana.\nLe distribuzioni a priori informative possono derivare da una vasta gamma di fonti, comprese ricerche pregresse, pareri di esperti nel campo e altre fonti affidabili. Questo approccio offre un metodo strutturato per integrare in modo coerente le conoscenze pregresse nel processo di analisi statistica. L‚Äôincorporazione di queste informazioni aggiuntive contribuisce notevolmente a migliorare la robustezza e l‚Äôaccuratezza delle conclusioni derivate dai dati, fornendo una solida base empirica su cui basare le stime dei parametri del modello e le decisioni basate sull‚Äôanalisi bayesiana.\nNell‚Äôambito della ricerca psicologica, l‚Äôutilizzo di distribuzioni a priori informative √® attualmente poco diffuso, tuttavia emergono segnali che all‚Äôinterno della comunit√† statistica sta crescendo l‚Äôinteresse per questa pratica, considerandola come un avanzamento promettente nel campo della data science.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>53</span>¬† <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_balance_prior_post.html#limportanza-della-prior-in-base-ai-dati",
    "href": "chapters/bayesian_inference/10_balance_prior_post.html#limportanza-della-prior-in-base-ai-dati",
    "title": "53¬† L‚Äôinfluenza della distribuzione a priori",
    "section": "\n53.4 L‚Äôimportanza della Prior in base ai Dati",
    "text": "53.4 L‚Äôimportanza della Prior in base ai Dati\nUn aspetto cruciale da considerare √® che l‚Äôinfluenza della prior diminuisce all‚Äôaumentare del numero di dati osservati. In altre parole, con un numero infinito di dati, la verosimiglianza diventa estremamente precisa (o ‚Äúaffilata‚Äù), rendendo la scelta della prior irrilevante, a patto che la prior non assegni probabilit√† zero a regioni dello spazio parametri dove la verosimiglianza √® positiva.\nTuttavia, la prior assume un‚Äôimportanza fondamentale quando si lavora con dataset di piccole dimensioni. In questi casi, la distribuzione a priori pu√≤ avere un‚Äôinfluenza significativa sulle stime, poich√© i dati da soli non sono sufficienti per ottenere stime precise.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>53</span>¬† <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_balance_prior_post.html#effetti-del-cambiamento-di-scala-dei-parametri",
    "href": "chapters/bayesian_inference/10_balance_prior_post.html#effetti-del-cambiamento-di-scala-dei-parametri",
    "title": "53¬† L‚Äôinfluenza della distribuzione a priori",
    "section": "\n53.5 Effetti del Cambiamento di Scala dei Parametri",
    "text": "53.5 Effetti del Cambiamento di Scala dei Parametri\nUn altro aspetto da tenere a mente √® che le priors possono cambiare quando si modificano le scale dei parametri. Se un parametro viene riscalato, ad esempio passando da metri a chilometri, anche la prior deve essere riscalata di conseguenza per mantenere la coerenza dell‚Äôinferenza.\n\n53.5.1 Scala e invariabilit√† della scelta delle distribuzioni a priori\nLa scelta delle distribuzioni a priori non informative non √® sempre banale e non pu√≤ sempre essere rappresentata da una prior piatta. Per capire questo concetto, √® fondamentale comprendere il ruolo della scala. Vediamo un esempio per chiarire meglio questo aspetto.\nImmaginiamo di avere un dataset che contiene la media dei diametri di alcuni alberi, e vogliamo stimare la media di questi diametri utilizzando un metodo bayesiano. Prima di osservare i dati, dobbiamo specificare la nostra distribuzione a priori, poich√© non vogliamo che i dati influenzino la nostra scelta. Supponiamo di scegliere una distribuzione a priori piatta tra 1 cm e 10 cm, per evitare di introdurre bias:\n\n# Creazione di un vettore da 1 a 5\nvalori &lt;- 1:5\n# Creazione di un vettore di 5 elementi, tutti uguali a 1/5\npesoPrior &lt;- rep(1/5, 5)\n# Mostra i risultati\npesoPrior\n#&gt; [1] 0.2 0.2 0.2 0.2 0.2\n\nIn questo caso, stiamo assegnando la stessa probabilit√† a ciascun diametro compreso tra 1 e 10 cm, senza dare pi√π peso a un valore rispetto a un altro. Questa sembra una scelta ragionevole e ‚Äúnon informativa‚Äù, poich√© non stiamo preferendo nessun diametro in particolare.\nOra, supponiamo di voler modificare leggermente la nostra analisi e di misurare la grandezza degli alberi in termini di area basale (cio√® la sezione trasversale dell‚Äôalbero alla base), che √® proporzionale al quadrato del diametro (cio√® \\(x^2\\)). Poich√© abbiamo gi√† specificato la nostra distribuzione a priori in termini di diametro, dovremmo trasformare questa distribuzione in modo coerente con la nuova scala (area basale).\nIl problema che emerge √® il seguente: quando riscaliamo l‚Äôasse \\(x\\) per riflettere l‚Äôarea basale (cio√®, passiamo da cm a cm\\(^2\\)), i valori pi√π grandi diventano pi√π ampi (poich√© l‚Äôarea cresce con il quadrato del diametro), mentre i valori pi√π piccoli diventano pi√π stretti. Se vogliamo mantenere la stessa distribuzione a priori in termini di probabilit√†, dobbiamo modificare il peso di ciascun valore.\nDi conseguenza, una distribuzione a priori che inizialmente era piatta (uguale per tutti i valori di diametro) non rimane piatta dopo la trasformazione in area basale. I valori pi√π grandi ora hanno un peso minore, mentre i valori pi√π piccoli hanno un peso maggiore. Questo dimostra che una distribuzione a priori non pu√≤ essere piatta per tutte le possibili trasformazioni dei parametri.\n\n53.5.2 Il concetto di invariabilit√† della scala\nUna delle chiavi per definire correttamente le distribuzioni a priori non informative √® l‚Äôinvariabilit√† rispetto alle trasformazioni dei parametri. Se possiamo scegliere liberamente come rappresentare i parametri (ad esempio, in termini di diametro o area basale), la nostra distribuzione a priori dovrebbe essere definita in modo che sia coerente indipendentemente dalla scala scelta.\n\n53.5.3 Attenzione alle trasformazioni dei parametri\nUn secondo messaggio importante riguarda la cautela nelle trasformazioni dei parametri nell‚Äôanalisi bayesiana. Quando cambiamo i parametri del nostro modello, non stiamo semplicemente osservando un singolo valore, ma una distribuzione intera. La forma di questa distribuzione pu√≤ cambiare notevolmente con la trasformazione dei parametri.\nAd esempio, se si sta conducendo uno studio psicologico e si vuole misurare un parametro legato alla gravit√† di un disturbo (ad esempio, la gravit√† della depressione su una scala numerica), e poi si decide di trasformare la scala in un‚Äôunit√† diversa (ad esempio, un punteggio quadratico per evidenziare differenze estreme), la distribuzione a priori che sembrava ragionevole prima della trasformazione potrebbe non esserlo pi√π dopo. Questo significa che bisogna prestare attenzione a come si scelgono le priors e come queste si comportano sotto diverse rappresentazioni del problema.\nIn conclusione, la scelta delle distribuzioni a priori non pu√≤ essere fatta superficialmente. Deve essere considerata con attenzione, tenendo conto delle possibili trasformazioni dei parametri e assicurandosi che le priors siano coerenti rispetto alla scala scelta. Questo rende evidente che le priors non informative non sono sempre piatte, e la loro scelta deve tenere conto della struttura del problema e delle variabili coinvolte.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>53</span>¬† <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_balance_prior_post.html#scelte-predefinite-per-le-distribuzioni-a-priori-non-informative",
    "href": "chapters/bayesian_inference/10_balance_prior_post.html#scelte-predefinite-per-le-distribuzioni-a-priori-non-informative",
    "title": "53¬† L‚Äôinfluenza della distribuzione a priori",
    "section": "\n53.6 Scelte predefinite per le distribuzioni a priori non informative",
    "text": "53.6 Scelte predefinite per le distribuzioni a priori non informative\nUna delle domande pi√π ricorrenti nell‚Äôinferenza bayesiana riguarda la scelta delle distribuzioni a priori non informative. La risposta, per√≤, √® piuttosto complessa: non esiste una soluzione generalmente accettata. Questo √® particolarmente importante perch√©, mentre le priors informative possono essere basate su conoscenze pregresse, una prior non informativa deve essere scelta con cura per evitare di influenzare eccessivamente i risultati.\nUna delle proposte pi√π famose, che soddisfa molte delle propriet√† desiderabili, √® la prior di Jeffreys, definita come:\n\\[\np(\\phi) \\propto \\sqrt{ \\det (F(\\phi)) },\n\\]\ndove \\(F(\\phi)\\) √® la matrice di informazione di Fisher, che misura quanto la verosimiglianza cambia quando variano i parametri. La prior di Jeffreys ha due caratteristiche fondamentali:\n\n\nInvarianza rispetto alla riscalatura dei parametri: Ci√≤ significa che se trasformiamo la scala del parametro, la prior si adatta automaticamente, rimanendo coerente con il problema.\n\nProporzionalit√† all‚Äôinfluenza dei parametri sulla verosimiglianza: Parametri che influenzano maggiormente la verosimiglianza hanno una prior pi√π informativa.\n\nQuesti aspetti sembrano coprire molti dei criteri comunemente accettati per la scelta delle distribuzioni a priori non informative. Tuttavia, la prior di Jeffreys presenta alcuni problemi nei modelli multivariati e gerarchici, il che limita la sua applicabilit√† come soluzione universale.\n\n53.6.1 Scelte predefinite comuni per le priors non informative\nNonostante le difficolt√† legate alla prior di Jeffreys, sono emerse alcune scelte predefinite comuni per le priors non informative, basate su intuizioni derivanti proprio da questa distribuzione. Di seguito sono elencate alcune di queste scelte:\n\n\nParametri di scala (es. coefficiente angolare o intercetta in una regressione):\n\nPer i parametri di scala, che influenzano l‚Äôoutput in modo lineare, si utilizzano comunemente priors piatte o quasi piatte. Queste possono essere distribuzioni uniformi con limiti fissati o, pi√π comunemente, una distribuzione normale ampia.\nUn esempio di prior modificata √® l‚Äôuso di una normalit√† centrata su un valore neutro, come 0, per ottenere l‚Äôanalogo bayesiano della regressione Lasso o Ridge, che introduce una penalizzazione sui parametri (Park & Casella, 2008; Kyung et al., 2010).\n\nSe questa penalizzazione √® lieve, si parla di priors debolmente regolarizzanti.\nSe √® forte, si parla di priors di riduzione (shrinkage), che possono essere fisse o adattative:\n\n\nShrinkage fisso: la forza della riduzione (ad es. controllata dalla deviazione standard nella prior normale) rimane costante.\n\nShrinkage adattativo: la prior di riduzione si adatta tramite un iperparametro (hyperprior), il che consente al modello di decidere autonomamente la forza della riduzione.\n\n\n\n\n\n\n\nParametri di varianza (es. la deviazione standard in una regressione lineare):\n\nPer i parametri di varianza, si utilizzano spesso priors che decrescono all‚Äôaumentare del valore. Un esempio classico √® la prior di Jeffrey‚Äôs, che per la varianza assume la forma \\(1/x\\), oppure la distribuzione inversa-gamma, molto comune per via della sua propriet√† di coniugazione, che semplifica il calcolo bayesiano.\n\n\n\nIperparametri di varianza nei modelli gerarchici:\n\nNei modelli gerarchici, gli iperparametri di varianza vengono trattati con priors decrescenti come l‚Äôinversa-gamma o la distribuzione half-t (Gelman, 2006). Queste priors sono progettate per gestire la varianza tra gruppi in modo efficace.\n\n\n\nDistribuzioni binomiali:\n\nPer una distribuzione binomiale, la prior di Jeffreys corrisponde a una distribuzione Beta(1/2, 1/2), che √® considerata una buona scelta predefinita non informativa. Questo tipo di prior assegna un peso equo alle possibili probabilit√† di successo, riflettendo una distribuzione equilibrata senza favorire un particolare risultato.\n\n\n\n53.6.2 Attenzione alle trasformazioni dei parametri\nUn aspetto importante da considerare nell‚Äôuso delle priors non informative √® che la loro forma pu√≤ cambiare significativamente in seguito a trasformazioni dei parametri. Per esempio, passando dalla scala lineare alla scala quadratica di un parametro, la prior pu√≤ assumere una forma diversa e introdurre involontariamente un bias. Pertanto, √® essenziale prestare attenzione a come i parametri sono scalati e trasformati nel modello.\n\n53.6.3 Analisi di sensibilit√†\nInfine, quando si √® incerti sulla scelta della prior, un buon approccio consiste nel condurre un‚Äôanalisi di sensibilit√†. Questa tecnica prevede di variare la prior e osservare come ci√≤ influenzi i risultati. Se i risultati sono robusti rispetto a diverse scelte di prior, ci√≤ suggerisce che la prior scelta non sta influenzando in modo eccessivo l‚Äôinferenza finale. Questo √® particolarmente utile nei casi in cui si dispone di pochi dati, situazione in cui la prior pu√≤ avere un impatto maggiore.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>53</span>¬† <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_balance_prior_post.html#priori-coniugate",
    "href": "chapters/bayesian_inference/10_balance_prior_post.html#priori-coniugate",
    "title": "53¬† L‚Äôinfluenza della distribuzione a priori",
    "section": "\n53.7 Priori coniugate",
    "text": "53.7 Priori coniugate\nUna distribuzione a priori √® detta coniugata rispetto a una funzione di verosimiglianza se la distribuzione a posteriori risultante ha la stessa forma funzionale della distribuzione a priori. In altre parole, la distribuzione a priori e quella a posteriori appartengono alla stessa famiglia di distribuzioni. Questo √® particolarmente utile perch√©, quando si usano priori coniugate, si ottiene una distribuzione a posteriori che pu√≤ essere espressa in forma chiusa, rendendo possibile risolverla analiticamente.\nUn esempio tipico √® quello delle funzioni di verosimiglianza appartenenti alla famiglia esponenziale, per le quali esiste sempre una distribuzione a priori coniugata. Questo √® uno dei motivi per cui le distribuzioni della famiglia esponenziale sono cos√¨ rilevanti: in modelli semplici, l‚Äôuso di una prior coniugata consente di ottenere una soluzione analitica per la distribuzione a posteriori, noto come modello coniugato-esponenziale.\nTradizionalmente, si preferiva specificare priori coniugate quando possibile, proprio per la semplicit√† analitica che garantivano. Tuttavia, l‚Äôimportanza delle priors coniugate √® diminuita con l‚Äôevoluzione dei metodi di campionamento. Oggi, la maggior parte dei campionatori moderni (come i metodi MCMC) non richiede pi√π la coniugazione per funzionare in modo efficiente, e l‚Äôuso di priors non coniugate √® diventato comune senza compromettere la qualit√† delle stime.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>53</span>¬† <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_balance_prior_post.html#simulazioni",
    "href": "chapters/bayesian_inference/10_balance_prior_post.html#simulazioni",
    "title": "53¬† L‚Äôinfluenza della distribuzione a priori",
    "section": "\n53.8 Simulazioni",
    "text": "53.8 Simulazioni\nIn questa sezione, esploriamo come le distribuzioni a priori influenzano la distribuzione a posteriori attraverso una serie di simulazioni. La formula di Bayes, \\(p(\\theta \\mid y) \\propto p(\\theta) \\times p(y \\mid \\theta)\\), evidenzia come la distribuzione a posteriori sia il risultato della combinazione tra la distribuzione a priori e la funzione di verosimiglianza basata sui dati osservati. Se abbiamo le valutazioni puntuali della verosimiglianza e della distribuzione a priori, possiamo moltiplicarle punto per punto per ottenere la distribuzione a posteriori.\n\n53.8.1 Verosimiglianza Binomiale con Distribuzioni a Priori Arbitrari\nConsideriamo un caso in cui la verosimiglianza √® binomiale, ma utilizziamo distribuzioni a priori non coniugate. Supponiamo che i dati consistano in 6 successi su 9 prove di tipo bernoulliano. Confronteremo l‚Äôeffetto di tre distribuzioni a priori diverse sulla distribuzione a posteriori e analizzeremo come ciascuna influisce sull‚Äôinferenza finale.\n\n53.8.1.1 Creazione della Griglia e Calcolo della Verosimiglianza\nIniziamo definendo una griglia di valori per \\(\\theta\\) e calcolando la verosimiglianza a ciascun punto della griglia.\n\n# Dati\nsuccess &lt;- 6\ntosses &lt;- 9\n\n# Griglia di valori per theta\ngrid_points &lt;- 100\np_grid &lt;- seq(0, 1, length.out = grid_points)\n\n# Verosimiglianza binomiale\nlikelihood &lt;- dbinom(success, tosses, p_grid)\n\n\n53.8.1.2 Funzione per Calcolare e Visualizzare la Posteriori\nDefiniamo una funzione che calcola la distribuzione a posteriori in base alla verosimiglianza e al priore fornito. La funzione visualizza anche il priore, la verosimiglianza e la distribuzione a posteriori.\n\ncomputePosterior &lt;- function(likelihood, prior, p_grid) {\n  # Calcolo della distribuzione a posteriori non normalizzata\n  unstd_posterior &lt;- likelihood * prior\n  \n  # Normalizzazione\n  posterior &lt;- unstd_posterior / sum(unstd_posterior)\n  \n  # Creazione del dataframe per il plotting\n  data &lt;- tibble(\n    theta = p_grid,\n    Prior = prior,\n    Likelihood = likelihood,\n    Posterior = posterior\n  ) |&gt; \n    pivot_longer(cols = c(Prior, Likelihood, Posterior), \n                 names_to = \"distribution\", \n                 values_to = \"density\")\n  \n  # Grafico con ggplot2\n  p &lt;- ggplot(data, aes(x = theta, y = density, color = distribution)) +\n    geom_line(size = 1.2) +\n    scale_color_manual(\n      values = MetBrewer::met.brewer(\"Hiroshige\", 10)[1:3], \n      # Usa i primi 3 colori della palette\n      labels = c(\"Prior\", \"Likelihood\", \"Posterior\")\n    ) +\n    facet_wrap(~distribution, scales = \"free_y\", ncol = 3) +\n    labs(\n      title = \"Distribuzioni: Prior, Likelihood, e Posterior\",\n      x = expression(theta),\n      y = \"Densit√†\"\n    ) +\n    theme(\n      plot.title = element_text(hjust = 0.5),\n      legend.position = \"none\",\n      strip.text = element_text(size = 12, face = \"bold\")\n    )\n  \n  # Restituzione della distribuzione a posteriori\n  print(p)\n  return(posterior)\n}\n\n\n53.8.2 Priore Uniforme\nIl nostro primo priore √® una distribuzione uniforme: \\(p(\\theta) = 1\\). Questo riflette una completa mancanza di informazioni a priori sulla probabilit√† di successo \\(\\theta\\).\n\n# Priore uniforme\nprior1 &lt;- rep(1, grid_points)\n\n# Calcolo e visualizzazione della distribuzione a posteriori\nposterior1 &lt;- computePosterior(likelihood, prior1, p_grid)\n\n\n\n\n\n\n\nCome previsto, la distribuzione a posteriori coincide con la verosimiglianza (a parte un fattore di scala), poich√© non abbiamo aggiunto informazioni.\n\n53.8.3 Priore a Gradino\nIl secondo priore √® una funzione a gradino che riflette la convinzione che \\(\\theta\\) sia almeno \\(0.5\\). Questo priore esprime la credenza che il successo (‚Äútesta‚Äù) sia pi√π probabile, ma non specifica di quanto.\n\n# Priore a gradino\nprior2 &lt;- ifelse(p_grid &gt;= 0.5, 1, 0)\n\n# Calcolo e visualizzazione della distribuzione a posteriori\nposterior2 &lt;- computePosterior(likelihood, prior2, p_grid)\n\n\n\n\n\n\n\nLa distribuzione a posteriori risultante esclude completamente i valori di \\(\\theta\\) inferiori a 0.5, coerentemente con le ipotesi del priore.\n\n53.8.4 Priore Esponenziale\nIl terzo priore √® una distribuzione centrata su 0.5, con un rapido decadimento esponenziale su entrambi i lati. Questo priore riflette la convinzione che \\(\\theta\\) sia vicina a 0.5.\n\n# Priore esponenziale\nprior3 &lt;- exp(-5 * abs(p_grid - 0.5))\n\n# Calcolo e visualizzazione della distribuzione a posteriori\nposterior3 &lt;- computePosterior(likelihood, prior3, p_grid)\n\n\n\n\n\n\n\nQuesto priore ‚Äúattrare‚Äù la distribuzione a posteriori verso 0.5, a meno che i dati non forniscano evidenze contrarie molto forti.\n\n53.8.5 Analisi del Modello Beta-Binomiale\nConsideriamo ora il caso coniugato, in cui il priore √® una distribuzione Beta e i dati seguono una distribuzione Binomiale.\nDefiniamo una funzione per visualizzare le distribuzioni del modello Beta-Binomiale: priore, verosimiglianza e posteriore.\n\nplot_beta_binomial &lt;- function(alpha, beta, y = NULL, n = NULL) {\n  # Griglia di valori per theta\n  theta &lt;- seq(0, 1, length.out = 100)\n  \n  # Priore\n  prior_density &lt;- dbeta(theta, alpha, beta)\n  \n  # Verosimiglianza e posterior\n  if (!is.null(y) && !is.null(n)) {\n    likelihood &lt;- dbinom(y, n, theta)\n    scaled_likelihood &lt;- likelihood / max(likelihood)\n    posterior_alpha &lt;- alpha + y\n    posterior_beta &lt;- beta + n - y\n    posterior_density &lt;- dbeta(theta, posterior_alpha, posterior_beta)\n  }\n  \n  # Creazione del dataframe\n  data &lt;- tibble(\n    theta = theta,\n    prior = prior_density,\n    likelihood = if (!is.null(y) && !is.null(n)) scaled_likelihood else NA,\n    posterior = if (!is.null(y) && !is.null(n)) posterior_density else NA\n  ) |&gt; \n    pivot_longer(cols = c(prior, likelihood, posterior), \n                 names_to = \"distribution\", \n                 values_to = \"density\")\n  \n  # Filtra i valori validi\n  data &lt;- data |&gt; filter(!is.na(density))\n  \n  # Grafico con ggplot2\n  ggplot(data, aes(x = theta, y = density, color = distribution)) +\n    geom_line(size = 1.2) +\n    scale_color_manual(\n      values = MetBrewer::met.brewer(\"Hiroshige\", 10)[c(1, 2, 3)], \n      # Usa la palette di MetBrewer\n      labels = c(\"Prior\", \"Likelihood (scaled)\", \"Posterior\")\n    ) +\n    labs(\n      title = \"Beta-Binomial Model\",\n      x = expression(theta),\n      y = \"Density\",\n      color = \"Distribution\"\n    ) +\n    theme(\n      plot.title = element_text(hjust = 0.5), # Centra il titolo\n      legend.position = \"bottom\",            # Posiziona la legenda in basso\n      legend.title = element_text(size = 12)\n    )\n}\n\n\n53.8.5.1 Priore Uniforme\n\nplot_beta_binomial(alpha = 1, beta = 1, y = 15, n = 20)\n\n\n\n\n\n\n\n\n53.8.5.2 Priore Informativo (Beta(2, 2))\n\nplot_beta_binomial(alpha = 2, beta = 2, y = 15, n = 20)\n\n\n\n\n\n\n\n\n53.8.5.3 Priore Fortemente Informativo (Beta(2, 5))\n\nplot_beta_binomial(alpha = 2, beta = 5, y = 15, n = 20)\n\n\n\n\n\n\n\nIn conclusione, abbiamo esplorato come i priori influenzano la distribuzione a posteriori in contesti binomiali, dimostrando che l‚Äôinfluenza del priore √® maggiore nei campioni piccoli e diminuisce con campioni di grandi dimensioni. L‚Äôanalisi bayesiana consente un‚Äôintegrazione flessibile delle conoscenze pregresse con i dati osservati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>53</span>¬† <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_balance_prior_post.html#connessione-tra-intuizioni-e-teoria",
    "href": "chapters/bayesian_inference/10_balance_prior_post.html#connessione-tra-intuizioni-e-teoria",
    "title": "53¬† L‚Äôinfluenza della distribuzione a priori",
    "section": "\n53.9 Connessione tra Intuizioni e Teoria",
    "text": "53.9 Connessione tra Intuizioni e Teoria\nL‚Äôequilibrio tra la distribuzione a priori e le evidenze provenienti dai dati, come dimostrato negli esempi precedenti, non solo rispecchia le nostre intuizioni, ma rappresenta anche una necessit√† matematica. Questo concetto diventa chiaro esaminando la formula del valore atteso della distribuzione a posteriori nel contesto del caso beta-binomiale, che pu√≤ essere riscritta come segue:\n\\[\n\\begin{align}\n\\mathbb{E}_{\\text{post}} &[\\text{Beta}(\\alpha + y, \\beta + n - y)] = \\frac{\\alpha + y}{\\alpha + \\beta + n} \\\\\n&= \\frac{a+b}{a+b+n} \\cdot \\frac{a}{a+b} + \\frac{n}{a+b+n} \\cdot \\frac{y}{n}.\n\\end{align}\n\\]\nL‚Äôequazione precedente rivela che il valore atteso a posteriori si ottiene come una media ponderata tra il valore atteso a priori \\(\\left( \\frac{\\alpha}{\\alpha+\\beta}\\right)\\) e la proporzione osservata dei successi \\(\\left(\\frac{y}{n}\\right)\\). I pesi sono dati da \\(\\left( \\frac{\\alpha+\\beta}{\\alpha+\\beta+n}\\right)\\) e \\(\\left( \\frac{n}{\\alpha+\\beta+n}\\right)\\). Pertanto, quando il numero di osservazioni \\(n\\) √® significativo rispetto alla somma dei parametri \\(\\alpha + \\beta\\), la distribuzione a posteriori sar√† principalmente influenzata dai dati osservati e in minor misura dalle credenze a priori. Al contrario, se \\(n\\) √® piccolo rispetto a \\(\\alpha + \\beta\\), i dati avranno un peso inferiore rispetto alle credenze a priori.\nQueste considerazioni indicano come scegliere i parametri \\(\\alpha\\) e \\(\\beta\\): se desideriamo rappresentare una totale ignoranza sul fenomeno, una scelta coerente √® \\(\\alpha = \\beta = 1\\) (attribuiamo uguale credibilit√† a ogni valore di \\(\\theta\\)). Se, invece, possediamo forti credenze a priori, possiamo selezionare \\(\\alpha\\) in modo da eguagliare il valore atteso a priori, mentre \\(\\alpha + \\beta\\) rifletter√† l‚Äôimportanza attribuita all‚Äôinformazione a priori: maggiore √® il valore di \\(\\alpha + \\beta\\), maggiore sar√† il numero di dati necessari per influenzare significativamente la distribuzione a posteriori rispetto a quella a priori. In situazioni in cui \\(n\\) √® considerevolmente grande, la distribuzione a posteriori avr√† un impatto ridotto sulla distribuzione a priori, a meno che non si facciano scelte estreme per i parametri a priori.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>53</span>¬† <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_balance_prior_post.html#conflitto-tra-prior-e-verosimiglianza",
    "href": "chapters/bayesian_inference/10_balance_prior_post.html#conflitto-tra-prior-e-verosimiglianza",
    "title": "53¬† L‚Äôinfluenza della distribuzione a priori",
    "section": "\n53.10 Conflitto tra Prior e Verosimiglianza",
    "text": "53.10 Conflitto tra Prior e Verosimiglianza\nEsaminiamo ora un altro esempio proposto da McElreath:\n\nLesson: Don‚Äôt trust intuition, for even simple prior+likelihood scenarios defy it. Four examples below, each producing radically different posteriors. Can you guess what each does?\n\n\nNella figura successiva vediamo la risposta alla domanda precedente.\n\nMcElreath descrive le caratteristiche di quattro diversi modelli in cui si combinano distribuzioni normali (Gaussiane) e Student-t (con 2 gradi di libert√†) per il prior e la likelihood. La distribuzione gaussiana ha code molto sottili, mentre quella di Student-t ha code pi√π spesse.\n\n\nIn Alto a Sinistra: Prior Normale, Likelihood Normale\n\ny ~ Normal(mu,1)\nmu ~ Normal(10,1)\n\nIn questo scenario classico di aggiornamento bayesiano, il posterior risulta essere un compromesso tra il prior e la likelihood. La distribuzione normale, con le sue code sottili, contribuisce a un aggiornamento pi√π ‚Äúprevedibile‚Äù e concentrato attorno al valore medio.\n\n\nIn Alto a Destra: Prior Student, Likelihood Student (df=2)\n\ny ~ Student(2,mu,1)\nmu ~ Student(2,10,1)\n\nIn questo caso, entrambe le distribuzioni hanno code pi√π spesse. La presenza di ‚Äúextra massa‚Äù nelle code significa che ciascuna distribuzione trova il modo dell‚Äôaltra pi√π plausibile, portando a una media che non rappresenta il miglior ‚Äúcompromesso‚Äù. Questo scenario risulta in una maggiore incertezza e un posterior meno definito.\n\n\nIn Basso a Sinistra: Prior Student, Likelihood Normale\n\ny ~ Normal(mu,1)\nmu ~ Student(2,10,1)\n\nQui, la likelihood normale, con le sue code sottili, tende a dominare. Essa √® molto scettica nei confronti del prior con code spesse, ma il prior di Student-t non √® sorpreso dalla likelihood. Questo porta a un posterior che √® pi√π influenzato dalla likelihood normale.\n\n\nIn Basso a Destra: Prior Normale, Likelihood Student\n\ny ~ Student(2,mu,1)\nmu ~ Normal(10,1)\n\nIn questo ultimo scenario, √® il prior normale a dominare. Il ragionamento √® simile a quello del caso precedente, ma in senso inverso. Il prior normale, con le sue code sottili, impone una maggiore influenza sul posterior, rendendolo meno influenzato dalle code pi√π spesse della likelihood di Student-t.\n\n\nIn sintesi, la combinazione di queste due distribuzioni in diversi modi porta a risultati di aggiornamento bayesiano molto differenti, a seconda di quale tra prior e likelihood abbia le code pi√π spesse e quindi eserciti una maggiore influenza sul posterior.\nIn conclusione, questo esercizio mostra come, ad eccezione del caso gaussiano, i risultati non sono affatto intuitivi. Pertanto, in contesti come questi, affidarsi esclusivamente alle proprie intuizioni non √® una scelta consigliabile. √à invece fondamentale procedere con l‚Äôesecuzione dei calcoli.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>53</span>¬† <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_balance_prior_post.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/10_balance_prior_post.html#riflessioni-conclusive",
    "title": "53¬† L‚Äôinfluenza della distribuzione a priori",
    "section": "\n53.11 Riflessioni Conclusive",
    "text": "53.11 Riflessioni Conclusive\nLa scelta della distribuzione a priori √® uno degli aspetti pi√π cruciali nell‚Äôinferenza bayesiana. Da un lato, le priors non informative possono essere utilizzate per minimizzare l‚Äôinfluenza delle conoscenze pregresse, permettendo ai dati osservati di guidare l‚Äôinferenza. Dall‚Äôaltro, le priors informative sono estremamente utili quando si dispone di informazioni affidabili sui parametri, consentendo una stima pi√π precisa. √à importante ricordare che, con un gran numero di dati, l‚Äôinfluenza della prior tende a ridursi, mentre nei contesti con pochi dati la scelta della prior pu√≤ avere un impatto significativo.\nUn aspetto essenziale dell‚Äôapproccio bayesiano, come evidenziato nell‚Äôesempio di Johnson (2022), √® che il processo di aggiornamento bayesiano riflette il modo in cui le persone ragionano intuitivamente: di fronte a evidenze deboli, le credenze rimangono stabili, mentre nuove informazioni robuste portano a un aggiornamento significativo delle credenze. Questo meccanismo formalizza in modo quantitativo e rigoroso le intuizioni che utilizziamo quotidianamente. Al contrario, l‚Äôapproccio frequentista ignora le conoscenze pregresse, il che pu√≤ portare a cambiamenti nelle inferenze senza tener conto delle credenze gi√† esistenti.\nTuttavia, come evidenziato dagli esempi di McElreath, la situazione pu√≤ essere pi√π complessa nei modelli non coniugati, dove l‚Äôintuizione pu√≤ fallire nel prevedere correttamente la distribuzione a posteriori. Questo ci ricorda che il contesto e la struttura del modello giocano un ruolo determinante nell‚Äôinferenza bayesiana.\n\n53.11.1 Il Ruolo della Prior nella Regolarizzazione\nNel contesto bayesiano, le distribuzioni a priori debolmente informative fungono da meccanismo di regolarizzazione, limitando l‚Äôinfluenza delle osservazioni estreme e garantendo inferenze pi√π stabili. Questo approccio √® ormai ampiamente accettato nella comunit√† statistica, poich√© permette di ottenere risultati pi√π prudenti senza introdurre un forte bias.\n\n53.11.2 L‚ÄôImportanza dei Prior Informativi\nNegli ultimi anni, l‚Äôuso di priori informativi ha guadagnato maggiore attenzione, soprattutto grazie all‚Äôintegrazione delle conoscenze esperte nel processo inferenziale. Questa pratica, nota come elicitazione della conoscenza esperta, richiede un rigoroso approccio metodologico per evitare bias cognitivi e assicurare che le informazioni pregresse siano incorporate in modo accurato. Questo √® particolarmente rilevante in campi come la psicologia, dove spesso la base teorica √® incerta, e l‚Äôelicitazione esperta pu√≤ contribuire a migliorare la solidit√† delle analisi bayesiane (O‚ÄôHagan, 2019).\n\n53.11.3 Conclusioni Finali\nIn conclusione, la scelta delle prior deve essere ponderata attentamente in base alla disponibilit√† di dati e al contesto dell‚Äôanalisi. Sebbene l‚Äôuso di priors non informative possa sembrare una scelta ‚Äúneutra‚Äù, √® spesso sub-ottimale. Le priors debolmente informative rappresentano lo standard attuale, poich√© favoriscono un‚Äôinferenza pi√π robusta grazie alla loro capacit√† di regolarizzare l‚Äôinfluenza dei dati. Infine, l‚Äôuso di priori informativi, sviluppati attraverso protocolli rigorosi di elicitazione esperta, √® una frontiera in crescita nell‚Äôanalisi bayesiana, poich√© consente di sfruttare al meglio le conoscenze pregresse per migliorare la qualit√† delle inferenze e ridurre l‚Äôincertezza.\nQuesto approccio, che bilancia conoscenza pregressa e nuovi dati, permette di sviluppare modelli bayesiani pi√π solidi e informati, riflettendo accuratamente sia l‚Äôincertezza sia la competenza specifica del dominio di studio.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>53</span>¬† <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_balance_prior_post.html#esercizi",
    "href": "chapters/bayesian_inference/10_balance_prior_post.html#esercizi",
    "title": "53¬† L‚Äôinfluenza della distribuzione a priori",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nL‚Äôobiettivo di questo esercizio √® comprendere come la distribuzione a priori influenzi la distribuzione a posteriori a seconda della grandezza del campione. Utilizzeremo dati raccolti della Satisfaction With Life Scale (SWLS), categorizzandoli in base a una soglia e analizzando la proporzione di risposte che superano tale soglia con un approccio bayesiano.\nFase 1: Raccolta e categorizzazione dei dati\n\nOgni studente utilizza i valori della scala SWLS che sono stati raccolti dal suo gruppo TPV.\nSi sceglie una soglia arbitraria (ad esempio, un punteggio superiore a 20 indica ‚Äúelevata soddisfazione‚Äù).\n\nSi calcola la proporzione di persone con punteggi superiori alla soglia:\n\\[\n\\hat{p} = \\frac{k}{n}\n\\]\ndove \\(k\\) √® il numero di persone con SWLS sopra la soglia e \\(n\\) √® la dimensione del campione (circa 15).\n\n\nFase 2: Inferenza Bayesiana con un Prior Mediamente Informativo\n\n\nSi assume una distribuzione Beta come prior per la proporzione di persone con SWLS sopra la soglia:\n\\[\np \\sim \\text{Beta}(a, b)\n\\]\ndove \\(a = 2\\) e \\(b = 2\\), un prior mediamente informativo (distribuzione simmetrica centrata su 0.5).\n\n\nSi calcola la distribuzione a posteriori utilizzando la coniugazione della Beta con la distribuzione binomiale:\n\\[\np \\mid D \\sim \\text{Beta}(a + k, b + n - k)\n\\]\n\n\nSi calcolano:\n\n\nStima puntuale della proporzione (valore atteso della Beta a posteriori):\n\\[\nE[p \\mid D] = \\frac{a + k}{a + b + n}\n\\]\n\nIntervallo di credibilit√† (CI al 95%), utilizzando i quantili della distribuzione Beta a posteriori.\n\n\n\nFase 3: Analisi con un Campione Pi√π Grande\n\nSi ripete lo stesso esercizio, ma immaginando che la stessa proporzione \\(\\hat{p}\\) provenga da un campione di n = 1000.\n\nSi calcola la nuova distribuzione a posteriori:\n\\[\np \\mid D \\sim \\text{Beta}(a + k', b + n' - k')\n\\] con \\(k' = \\hat{p} \\times 1000\\).\n\nSi ricalcolano stima puntuale e intervallo di credibilit√†.\n\nFase 4: Confronto e Interpretazione\n\n\nSi confrontano le due distribuzioni a posteriori:\n\nCome cambia la varianza della distribuzione a posteriori?\nCome cambia l‚Äôinfluenza del prior?\nQual √® la differenza nella precisione della stima puntuale e dell‚Äôintervallo di credibilit√†?\n\n\nSi discute come, all‚Äôaumentare del campione, l‚Äôinfluenza della distribuzione a priori diminuisce, facendo emergere il ruolo della likelihood.\n\nConsegna: caricare su Moodle il file .qmd compilato in pdf.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>53</span>¬† <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_balance_prior_post.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/10_balance_prior_post.html#informazioni-sullambiente-di-sviluppo",
    "title": "53¬† L‚Äôinfluenza della distribuzione a priori",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.17.0      thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0\n#&gt;  [5] see_0.11.0       gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1\n#&gt;  [9] psych_2.5.3      scales_1.3.0     markdown_2.0     knitr_1.50      \n#&gt; [13] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [17] purrr_1.0.4      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [21] ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      shape_1.4.6.1     xfun_0.51         htmlwidgets_1.6.4\n#&gt;  [5] lattice_0.22-6    tzdb_0.5.0        Rdpack_2.6.3      vctrs_0.6.5      \n#&gt;  [9] tools_4.4.2       generics_0.1.3    parallel_4.4.2    pan_1.9          \n#&gt; [13] pacman_0.5.1      jomo_2.7-6        pkgconfig_2.0.3   Matrix_1.7-3     \n#&gt; [17] lifecycle_1.0.4   compiler_4.4.2    farver_2.1.2      munsell_0.5.1    \n#&gt; [21] mnormt_2.1.1      codetools_0.2-20  htmltools_0.5.8.1 glmnet_4.1-8     \n#&gt; [25] nloptr_2.2.1      pillar_1.10.1     MASS_7.3-65       reformulas_0.4.0 \n#&gt; [29] iterators_1.0.14  rpart_4.1.24      boot_1.3-31       mitml_0.4-5      \n#&gt; [33] foreach_1.5.2     nlme_3.1-167      tidyselect_1.2.1  digest_0.6.37    \n#&gt; [37] stringi_1.8.4     labeling_0.4.3    splines_4.4.2     rprojroot_2.0.4  \n#&gt; [41] fastmap_1.2.0     grid_4.4.2        colorspace_2.1-1  cli_3.6.4        \n#&gt; [45] magrittr_2.0.3    survival_3.8-3    broom_1.0.7       withr_3.0.2      \n#&gt; [49] backports_1.5.0   timechange_0.3.0  rmarkdown_2.29    nnet_7.3-20      \n#&gt; [53] lme4_1.1-36       hms_1.1.3         evaluate_1.0.3    rbibutils_2.3    \n#&gt; [57] rlang_1.1.5       Rcpp_1.0.14       glue_1.8.0        minqa_1.2.8      \n#&gt; [61] rstudioapi_0.17.1 jsonlite_1.9.1    R6_2.6.1",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>53</span>¬† <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_balance_prior_post.html#bibliografia",
    "href": "chapters/bayesian_inference/10_balance_prior_post.html#bibliografia",
    "title": "53¬† L‚Äôinfluenza della distribuzione a priori",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A. (2006). Prior distributions for variance parameters in hierarchical models (comment on article by Browne and Draper). Bayesian Analysis, 1(3), 515‚Äì534. https://doi.org/10.1214/06-BA117A\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nO‚ÄôHagan, A. (2019). Expert knowledge elicitation: subjective but scientific. The American Statistician, 73(sup1), 69‚Äì81.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>53</span>¬† <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_gamma_poisson_model.html",
    "href": "chapters/bayesian_inference/11_gamma_poisson_model.html",
    "title": "54¬† Modello coniugato Gamma-Poisson",
    "section": "",
    "text": "54.1 Introduzione\nIn psicologia, le variabili di conteggio (\\(y\\)), che indicano il numero di occorrenze di un evento, trovano ampio impiego in diversi ambiti. Ad esempio, sono usate per quantificare la frequenza dei sintomi di un disturbo o per analizzare le frequenze delle parole negli studi di psicolinguistica. Queste variabili, assumendo valori discreti, richiedono modelli statistici specifici.\nQuesto capitolo si focalizza sulla stima del tasso medio di incidenza (\\(\\lambda_i\\)) di tali eventi, ovvero sul numero medio di occorrenze per unit√† di misura. Adotteremo un approccio bayesiano, utilizzando il modello di Poisson per descrivere la distribuzione di probabilit√† delle variabili di conteggio. In particolare, esploreremo la derivazione analitica della distribuzione a posteriori del parametro \\(\\lambda_i\\), considerando una distribuzione a priori Gamma. Successivamente, verificheremo la validit√† dei risultati analitici mediante simulazioni Monte Carlo.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>54</span>¬† <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_gamma_poisson_model.html#distribuzione-di-poisson",
    "href": "chapters/bayesian_inference/11_gamma_poisson_model.html#distribuzione-di-poisson",
    "title": "54¬† Modello coniugato Gamma-Poisson",
    "section": "\n54.2 Distribuzione di Poisson",
    "text": "54.2 Distribuzione di Poisson\nLa distribuzione di Poisson √® un modello probabilistico utilizzato per descrivere il numero di eventi che si verificano in un intervallo di tempo o spazio fisso, partendo dall‚Äôassunto che tali eventi si verifichino con una frequenza media costante e in modo indipendente rispetto al tempo trascorso dall‚Äôultimo evento. Se un dato \\(y\\) segue una distribuzione di Poisson con parametro \\(\\lambda\\), allora la probabilit√† di osservare un singolo valore \\(y_i\\) √® data da:\n\\[\nf(y_i \\mid \\lambda) = \\frac{e^{-\\lambda} \\lambda^{y_i}}{y_i!},\n\\]\ndove \\(\\lambda &gt; 0\\) rappresenta la frequenza media di occorrenza degli eventi e \\(y_i\\) √® il numero di eventi osservati. La distribuzione di Poisson ha la caratteristica che sia il valore atteso che la varianza di una variabile casuale \\(Y\\) che segue questa distribuzione sono pari a \\(\\lambda\\), cio√® \\(E(Y) = \\lambda\\) e \\(\\text{Var}(Y) = \\lambda\\).\n\n54.2.1 Simulazione\nPer capire meglio come funziona la distribuzione di Poisson, immaginiamo un paziente con un disturbo ossessivo-compulsivo. Supponiamo che in media questo paziente ripeta un‚Äôazione compulsiva 2 volte ogni ora. In questo caso, il parametro della distribuzione di Poisson √® Œª = 2.\nLa probabilit√† di osservare esattamente \\(k\\) eventi in un‚Äôora √® calcolata dalla formula:\n\\[\nf(k \\mid \\lambda) = \\frac{e^{-\\lambda} \\lambda^k}{k!}.\n\\]\nNel caso specifico con \\(\\lambda = 2\\), le probabilit√† per i primi valori di \\(k\\) sono:\n\nLa probabilit√† di osservare 0 eventi in un‚Äôora √® \\(\\frac{e^{-2} \\cdot 2^0}{0!} = e^{-2} \\approx 0{.}1353\\).\nLa probabilit√† di osservare 1 evento in un‚Äôora √® \\(\\frac{e^{-2} \\cdot 2^1}{1!} = 2e^{-2} \\approx 0{.}2707\\).\nLa probabilit√† di osservare 2 eventi in un‚Äôora √® \\(\\frac{e^{-2} \\cdot 2^2}{2!} = 2e^{-2} \\approx 0{.}2707\\).\nE cos√¨ via per \\(k = 3\\), \\(k = 4\\), \\(\\dots\\)\n\n\nQuesto esempio illustra come la distribuzione di Poisson possa essere utilizzata per modellare il numero di eventi rari che si verificano in un intervallo temporale fisso, con una frequenza media nota.\nSvolgiamo ora i calcoli utilizzando la funzione dpois in R:\n\nlam_true &lt;- 2\n# Creazione di un vettore di valori da 0 a 9\nk_values &lt;- 0:9\n\n# Calcolo delle probabilit√† per ogni valore in k_values\nprobabilities &lt;- dpois(k_values, lambda = lam_true)\n\n# Stampa delle probabilit√†\nfor (i in seq_along(k_values)) {\n  cat(sprintf(\"Probabilit√† di %d eventi: %.4f\\n\", k_values[i], probabilities[i]))\n}\n#&gt; Probabilit√† di 0 eventi: 0.1353\n#&gt; Probabilit√† di 1 eventi: 0.2707\n#&gt; Probabilit√† di 2 eventi: 0.2707\n#&gt; Probabilit√† di 3 eventi: 0.1804\n#&gt; Probabilit√† di 4 eventi: 0.0902\n#&gt; Probabilit√† di 5 eventi: 0.0361\n#&gt; Probabilit√† di 6 eventi: 0.0120\n#&gt; Probabilit√† di 7 eventi: 0.0034\n#&gt; Probabilit√† di 8 eventi: 0.0009\n#&gt; Probabilit√† di 9 eventi: 0.0002\n\nIl seguente codice R genera il grafico della funzione di massa di probabilit√† (PMF) di una distribuzione di Poisson con parametro \\(\\lambda = 2\\):\n\n# Definiamo il parametro lambda\nlambd &lt;- 2\n\n# Generiamo i valori sull'asse x (numero di eventi)\nx &lt;- 0:9  \n\n# Calcoliamo le probabilit√† corrispondenti \ny &lt;- dpois(x, lambda = lambd)\n\n# Creare un dataframe contenente i dati per il grafico\ndf &lt;- data.frame(\n  numero_eventi = x,\n  probabilita = y\n)\n\n# Creare il grafico \nggplot(df, aes(x = numero_eventi, y = probabilita)) +\n  geom_segment(aes(x = numero_eventi, xend = numero_eventi, y = 0, yend = probabilita), \n               color = \"blue\", size = 1) +  # Segmenti verticali\n  geom_point(color = \"red\", size = 3) +  # Cerchi sulla cima dei segmenti\n  labs(title = \"Distribuzione di Poisson (Œª = 2)\",  \n       x = \"Numero di eventi\", \n       y = \"Probabilit√†\") +  \n  theme(plot.title = element_text(hjust = 0.5))  # Centrare il titolo",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>54</span>¬† <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_gamma_poisson_model.html#distribuzione-gamma",
    "href": "chapters/bayesian_inference/11_gamma_poisson_model.html#distribuzione-gamma",
    "title": "54¬† Modello coniugato Gamma-Poisson",
    "section": "\n54.3 Distribuzione Gamma",
    "text": "54.3 Distribuzione Gamma\nLa distribuzione Gamma riveste un ruolo centrale nel modello coniugato Gamma-Poisson, poich√© funge da distribuzione a priori per il parametro di tasso \\(\\lambda\\) della distribuzione di Poisson. La sua scelta √® motivata dalla propriet√† di coniugatezza, che consente di ottenere una distribuzione a posteriori appartenente alla stessa famiglia della prior, semplificando i calcoli inferenziali e aggiornando in modo diretto le credenze alla luce dei dati osservati.\nLa funzione di densit√† della distribuzione Gamma √® definita come:\n\\[\nf(x \\mid \\alpha, \\beta) = \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)} x^{\\alpha - 1} e^{-\\beta x},\n\\]\ndove:\n\n\n\\(\\alpha\\) (detto parametro di forma) determina la forma della distribuzione: valori pi√π elevati di \\(\\alpha\\) tendono a rendere la distribuzione pi√π simmetrica;\n\n\\(\\beta\\) (detto parametro di tasso o scala inversa) controlla la scala: valori pi√π elevati di \\(\\beta\\) concentrano maggiormente la massa di probabilit√† vicino all‚Äôorigine.\n\nAd esempio:\n\nUna distribuzione Gamma con \\(\\alpha = 2\\) e \\(\\beta = 3\\) rappresenta un processo in cui eventi relativamente rari si verificano occasionalmente.\nUna distribuzione Gamma con \\(\\alpha = 10\\) e \\(\\beta = 1\\) descrive un processo pi√π regolare, con eventi che si verificano con maggiore frequenza e prevedibilit√†.\n\n\n\n\n\n\n\nIn R, la parametrizzazione della distribuzione Gamma utilizza direttamente il parametro \\(\\beta\\) come tasso (\\(rate\\)), che √® l‚Äôinverso del parametro di scala (\\(scale = 1 / \\beta\\)).\n\n\n\nPer calcolare la densit√† di probabilit√† in R, si utilizza:\ndgamma(x, shape = alpha, rate = beta)\n\n# Definizione dei parametri\nalpha &lt;- 2\nbeta &lt;- 3\n\n# Generazione dei valori di x\nx &lt;- seq(0, 3, length.out = 500)\n\n# Calcolo della densit√† di probabilit√†\npdf &lt;- dgamma(x, shape = alpha, rate = beta)\n\n# Creare un dataframe contenente i dati per il grafico\ndf &lt;- data.frame(\n  x = x,\n  densita = pdf\n)\n\n# Creare il grafico con ggplot2\nggplot(df, aes(x = x, y = densita)) +\n  geom_line(color = \"blue\", size = 1) +  # Aggiungere la linea per la densit√†\n  labs(\n    title = expression(\"Distribuzione Gamma (\" ~ alpha == 2 ~ \",\" ~ beta == 3 ~ \")\"),  # Titolo con espressioni matematiche\n    x = \"x\",  # Label dell'asse x\n    y = \"Densit√† di probabilit√†\"  # Label dell'asse y\n  ) +\n  theme(plot.title = element_text(hjust = 0.5))  # Centrare il titolo\n\n\n\n\n\n\n\nQuesto grafico mostra la densit√† di una distribuzione Gamma con \\(\\alpha = 2\\) e \\(\\beta = 3\\), calcolata su un intervallo \\([0, 3]\\).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>54</span>¬† <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_gamma_poisson_model.html#metodo-basato-su-griglia",
    "href": "chapters/bayesian_inference/11_gamma_poisson_model.html#metodo-basato-su-griglia",
    "title": "54¬† Modello coniugato Gamma-Poisson",
    "section": "\n54.4 Metodo Basato su Griglia",
    "text": "54.4 Metodo Basato su Griglia\nVogliamo calcolare la distribuzione a posteriori del parametro \\(\\lambda\\) di un modello di Poisson, usando una distribuzione a priori Gamma. Di seguito mostriamo come si pu√≤ procedere numericamente, discretizzando lo spazio dei possibili valori di \\(\\lambda\\).\nDati e Assunzioni.\nI dati osservati sono:\n\ny &lt;- c(2, 1, 3, 2, 2, 1, 1, 1)\n\ne la nostra distribuzione a priori √® \\(\\text{Gamma}(\\alpha=9, \\beta=2)\\).\n1. Definizione della Griglia e della Distribuzione A Priori.\n\nCreiamo una griglia di valori di \\(\\lambda\\), per esempio tra 0.01 e 10, con 1000 punti equidistanti.\n\nPer ciascun valore di \\(\\lambda\\), calcoliamo la densit√† della a priori Gamma corrispondente.\n\n\n# Parametri della distribuzione a priori Gamma\nalpha_prior &lt;- 9\nbeta_prior  &lt;- 2\n\n# Griglia di valori di lambda\nlambda_grid &lt;- seq(0.01, 10, length.out = 1000)\n\n# Densit√† della distribuzione a priori\nprior &lt;- dgamma(lambda_grid, shape = alpha_prior, rate = beta_prior)\n\n√à spesso utile visualizzare questa a priori e confrontarla con altre informazioni, ad esempio la media di \\(\\lambda\\) secondo la a priori (\\(\\alpha/\\beta\\)) e la media campionaria (\\(\\bar{y}\\)):\n\n# Calcolo di media a priori (media di una Gamma) e media campionaria\nmedia_gamma       &lt;- alpha_prior / beta_prior\nmedia_campionaria &lt;- mean(y)\n\n# Creazione di un dataframe per ggplot\ndf_prior &lt;- data.frame(\n  lambda  = lambda_grid,\n  densita = prior\n)\n\nggplot(df_prior, aes(x = lambda, y = densita)) +\n  geom_line() +\n  geom_vline(xintercept = media_gamma,       linetype = \"dashed\") +\n  geom_vline(xintercept = media_campionaria, linetype = \"dashed\") +\n  labs(\n    title = \"Distribuzione Gamma a Priori\",\n    x = expression(lambda),\n    y = \"Densit√†\"\n  )\n\n\n\n\n\n\n\n2. Calcolo della Verosimiglianza.\nPer una famiglia di distribuzioni di Poisson, la verosimiglianza di un insieme di dati \\(y_1, y_2, \\dots, y_n\\) √® il prodotto delle probabilit√†:\n\\[\n\\mathcal{L}(\\lambda) \\;=\\; \\prod_{i=1}^n \\mathrm{P}(Y=y_i \\mid \\lambda)\n\\;=\\; \\prod_{i=1}^n \\mathrm{dpois}(y_i, \\lambda).\n\\]\nIn R, possiamo calcolarla per tutti i valori di \\(\\lambda\\) della griglia in modo vettoriale:\n\n# Calcolo vettoriale della verosimiglianza\nlikelihood &lt;- sapply(lambda_grid, function(l) prod(dpois(y, l)))\n\nL‚Äôistruzione precedente fa questo:\n\n\nPasso su ciascun valore di \\(\\lambda\\) nella griglia (lambda_grid).\n\nPer ogni \\(\\lambda\\), calcola \\(\\mathrm{dpois}(y, \\lambda)\\), che restituisce un vettore di lunghezza \\(n\\) (il numero di osservazioni), ossia la probabilit√† di osservare ciascun \\(y_i\\) secondo una Poisson(\\(\\lambda\\)).\n\n\nMoltiplica insieme tutte queste probabilit√† con prod(...), ottenendo un singolo numero che √® la verosimiglianza \\(\\mathcal{L}(\\lambda)\\) per quell‚Äôinsieme di dati.\n\nRipete il procedimento per ogni \\(\\lambda\\) della griglia, restituendo un vettore di verosimiglianze (una per ciascun punto della griglia).\n\nIn altre parole, ogni elemento del vettore likelihood corrisponde alla verosimiglianza calcolata in un punto \\(\\lambda\\). E la verosimiglianza √® appunto il prodotto delle probabilit√† di ciascuno dei valori \\(y_i\\), assumendo che i dati provengano da una \\(\\mathrm{Poisson}(\\lambda)\\) e che le osservazioni siano indipendenti.\n3. Calcolo della A Posteriori (non normalizzata).\nLa distribuzione a posteriori, a meno di una costante di normalizzazione, √® data da:\n\\[\n\\pi(\\lambda \\mid y) \\; \\propto \\; \\mathcal{L}(\\lambda)\\,\\pi(\\lambda).\n\\]\nTradotto in codice:\n\nposterior_unnormalized &lt;- prior * likelihood\n\n4. Normalizzazione.\nPer ottenere la vera distribuzione di probabilit√†, dobbiamo normalizzare:\n\\[\n\\pi(\\lambda \\mid y) =\n  \\frac{\\mathcal{L}(\\lambda)\\,\\pi(\\lambda)}{\\int \\mathcal{L}(\\lambda)\\,\\pi(\\lambda)\\, d\\lambda}.\n\\]\nSul computer, l‚Äôintegrale si trasforma in una somma pesata dallo ‚Äúspessore‚Äù di ogni intervallo nella griglia:\n\n# Calcolo del fattore di normalizzazione\ngrid_width &lt;- lambda_grid[2] - lambda_grid[1]  # Ampiezza della griglia (costante)\nnormalization_factor &lt;- sum(posterior_unnormalized) * grid_width\n\n# Distribuzione a posteriori normalizzata\nposterior &lt;- posterior_unnormalized / normalization_factor\n\n5. Confronto Visivo: A Priori vs A Posteriori.\nInfine, possiamo confrontare le due curve (a priori e a posteriori) su un unico grafico:\n\n# Creazione del dataframe\ndf &lt;- data.frame(\n  lambda  = lambda_grid,\n  prior   = prior,\n  posterior = posterior\n)\n\n# Trasformiamo in formato \"lungo\" per ggplot\nlibrary(reshape2)\ndf_long &lt;- melt(\n  df, \n  id.vars = \"lambda\", \n  measure.vars = c(\"prior\", \"posterior\"),\n  variable.name = \"Distribuzione\", \n  value.name = \"Densita\"\n)\n\n# Grafico\nggplot(df_long, aes(x = lambda, y = Densita, color = Distribuzione)) +\n  geom_line() +\n  labs(\n    title = \"Distribuzione A Priori e A Posteriori\",\n    x = expression(lambda),\n    y = \"Densit√†\"\n  )\n\n\n\n\n\n\n\nInterpretazione.\n\nLa distribuzione a posteriori risulta spostata verso valori pi√π bassi rispetto alla a priori. Questo indica che i dati osservati suggeriscono \\(\\lambda\\) pi√π piccolo di quanto ipotizzato inizialmente dalla a priori.\nLa a posteriori appare pi√π concentrata (pi√π piccata) rispetto alla a priori. Ci√≤ riflette la minor incertezza residua dopo aver incorporato l‚Äôinformazione fornita dai dati.\n\nQuesto semplice approccio su griglia mostra chiaramente come la verosimiglianza, ‚Äúpesata‚Äù dalla a priori, generi la nuova distribuzione a posteriori. √à un metodo intuitivo che permette di visualizzare passo dopo passo in che modo i dati aggiornano le nostre credenze sul parametro \\(\\lambda\\).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>54</span>¬† <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_gamma_poisson_model.html#modello-coniugato-gamma-poission",
    "href": "chapters/bayesian_inference/11_gamma_poisson_model.html#modello-coniugato-gamma-poission",
    "title": "54¬† Modello coniugato Gamma-Poisson",
    "section": "\n54.5 Modello Coniugato Gamma-Poission",
    "text": "54.5 Modello Coniugato Gamma-Poission\nPer calcolare analiticamente la distribuzione a posteriori nel contesto di un modello gamma-Poisson possiamo seguire un processo diretto. Il modello Gamma-Poisson √® coniugato, il che significa che la distribuzione a posteriori sar√† ancora una distribuzione Gamma.\nSeguendo il teorema di Bayes, possiamo scrivere la distribuzione a posteriori come:\n\\(f(\\lambda \\mid y) \\propto f(y \\mid \\lambda) \\cdot f(\\lambda) ,\\)\ndove \\(f(\\lambda \\mid y)\\) √® la distribuzione a posteriori, \\(f(y \\mid \\lambda)\\) √® la verosimiglianza e \\(f(\\lambda)\\) √® la distribuzione a priori.\nDefiniamo la verosimiglianza (distribuzione di Poisson):\n\\(f(y \\mid \\lambda) = \\prod_{i=1}^n \\frac{e^{-\\lambda}\\lambda^{y_i}}{y_i!} = \\frac{e^{-n\\lambda}\\lambda^{\\sum_{i=1}^n y_i}}{\\prod_{i=1}^n y_i!}.\\)\nDefiniamo la distribuzione a priori (distribuzione Gamma):\n\\(f(\\lambda) = \\frac{b^a}{\\Gamma(a)}\\lambda^{a-1}e^{-b\\lambda}.\\)\nOra, moltiplichiamo la verosimiglianza per la distribuzione a priori:\n\\(f(\\lambda|y) \\propto \\frac{e^{-n\\lambda}\\lambda^{\\sum_{i=1}^n y_i}}{\\prod_{i=1}^n y_i!} \\cdot \\frac{b^a}{\\Gamma(a)}\\lambda^{a-1}e^{-b\\lambda}.\\)\nSemplifichiamo, eliminando i termini costanti (che non dipendono da \\(\\lambda\\)):\n\\(f(\\lambda \\mid y) \\propto e^{-n\\lambda}\\lambda^{\\sum_{i=1}^n y_i} \\cdot \\lambda^{a-1}e^{-b\\lambda}.\\)\nRaggruppiamo i termini:\n\\(f(\\lambda|y) \\propto \\lambda^{\\sum_{i=1}^n y_i} \\cdot \\lambda^{a-1} \\cdot e^{-n\\lambda} \\cdot e^{-b\\lambda}.\\)\nSemplifichiamo ulteriormente:\n\\(f(\\lambda \\mid y) \\propto \\lambda^{\\sum_{i=1}^n y_i + a - 1} \\cdot e^{-(n+b)\\lambda}.\\)\nRiconosciamo che questa √® la forma di una distribuzione Gamma con nuovi parametri:\n\\(f(\\lambda \\mid y) \\propto \\lambda^{(\\sum_{i=1}^n y_i + a) - 1} \\cdot e^{-(n+b)\\lambda}.\\)\nQuindi, la distribuzione a posteriori √® una Gamma con parametri:\n\n\n\\(\\alpha_{post} = a + \\sum_{i=1}^n y_i\\),\n\n\\(\\beta_{post} = b + n\\),\n\ndove:\n\n\n\\(a\\) e \\(b\\) sono i parametri della distribuzione Gamma a priori,\n\n\\(\\sum_{i=1}^n y_i\\) √® la somma di tutte le osservazioni,\n\n\\(n\\) √® il numero di osservazioni.\n\nQuesta derivazione mostra come la distribuzione a posteriori mantiene la forma di una Gamma, ma con parametri aggiornati che incorporano l‚Äôinformazione dai dati osservati.\nConsideriamo nuovamente l‚Äôesempio precedente. Utilizzando i parametri aggiornati, rappresentiamo graficamente la distribuzione a posteriori:\n\n# Parametri aggiornati della distribuzione a posteriori Gamma\nalpha_post &lt;- alpha_prior + sum(y)\nbeta_post &lt;- beta_prior + length(y)\n\n# Griglia dei valori di lambda\nlambda_grid &lt;- seq(0.01, 10, length.out = 1000)\n\n# Distribuzione a posteriori analitica\nposterior_analytic &lt;- dgamma(lambda_grid, shape = alpha_post, rate = beta_post)\n\n# Creare un dataframe contenente i dati per il grafico\ndf &lt;- data.frame(\n  lambda = lambda_grid,\n  densita = posterior_analytic\n)\n\n# Calcolo della media a posteriori\nmedia_posterior &lt;- alpha_post / beta_post\n\n# Creare il grafico con ggplot2\nggplot(df, aes(x = lambda, y = densita)) +\n  geom_line(color = \"blue\", size = 1) +  # Aggiungere la linea per la densit√† a posteriori\n  geom_vline(xintercept = media_posterior, color = \"red\", linetype = \"dashed\", size = 1) +  # Linea verticale per la media a posteriori\n  labs(\n    title = \"Distribuzione a Posteriori Analitica Gamma-Poisson\",\n    x = expression(lambda),  # Label dell'asse x usando espressioni matematiche\n    y = \"Densit√† di probabilit√†\"  # Label dell'asse y\n  ) +\n  theme(plot.title = element_text(hjust = 0.5)) +  # Centrare il titolo\n  annotate(\"text\", x = media_posterior + 0.5, y = max(posterior_analytic) * 0.8, \n           label = \"Media a Posteriori\", color = \"red\", size = 4) +  # Etichetta per la media a posteriori\n  scale_x_continuous(expand = expansion(mult = c(0, 0.1)))  # Aumentare lo spazio sull'asse x per migliorare la visualizzazione\n\n\n\n\n\n\n\nIl grafico mostra la distribuzione a posteriori analitica del parametro di tasso \\(\\lambda\\) di un modello di Poisson, ottenuta utilizzando una distribuzione a priori Gamma e aggiornando i parametri alla luce dei dati osservati. La distribuzione a posteriori √® calcolata come una Gamma aggiornata con i parametri \\(\\alpha_{\\text{post}}\\) e \\(\\beta_{\\text{post}}\\), e rappresenta la nostra conoscenza aggiornata dopo aver visto i dati. I risultati analitici concordano con quelli ottenuti tramite simulazione.\nProcediamo ora con il calcolo della soluzione analitica per la media della distribuzione a posteriori del parametro \\(\\lambda\\):\n\n# Media della distribuzione a posteriori\nposterior_mean &lt;- alpha_post / beta_post\ncat(sprintf(\"Media a Posteriori = %.3f\\n\", posterior_mean))\n#&gt; Media a Posteriori = 2.200\n\n# Parametri della distribuzione a posteriori\ncat(sprintf(\"Shape (Œ±) = %.1f\\n\", alpha_post))\n#&gt; Shape (Œ±) = 22.0\ncat(sprintf(\"Rate (Œ≤) = %.1f\\n\", beta_post))\n#&gt; Rate (Œ≤) = 10.0\n\nPossiamo calcolare la probabilit√† di qualsiasi evento di interesse. Per esempio, ci possiamo chiedere quale sia la probabilit√† di osservare pi√π di 3 compulsioni per ora:\n\n# Probabilit√† di osservare pi√π di 3 eventi\nprob_y_greater_than_3 &lt;- 1 - pgamma(3, shape = alpha_post, rate = beta_post)\ncat(sprintf(\"Probabilit√† di osservare pi√π di 3 eventi = %.3f\\n\", prob_y_greater_than_3))\n#&gt; Probabilit√† di osservare pi√π di 3 eventi = 0.054",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>54</span>¬† <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_gamma_poisson_model.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/11_gamma_poisson_model.html#riflessioni-conclusive",
    "title": "54¬† Modello coniugato Gamma-Poisson",
    "section": "\n54.6 Riflessioni Conclusive",
    "text": "54.6 Riflessioni Conclusive\nIl modello Gamma-Poisson offre un framework robusto per l‚Äôinferenza bayesiana su dati di conteggio in psicologia. Partendo da una distribuzione a priori Gamma, che rappresenta la nostra conoscenza iniziale sul tasso medio, siamo in grado di aggiornare questa conoscenza alla luce dei dati osservati, ottenendo una distribuzione a posteriori che riflette in modo pi√π preciso la realt√† sottostante. Questo approccio permette di quantificare l‚Äôincertezza associata alle nostre stime e di prendere decisioni informate sulla base dei dati disponibili.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>54</span>¬† <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_gamma_poisson_model.html#esercizi",
    "href": "chapters/bayesian_inference/11_gamma_poisson_model.html#esercizi",
    "title": "54¬† Modello coniugato Gamma-Poisson",
    "section": "\n54.7 Esercizi",
    "text": "54.7 Esercizi\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nConsideriamo uno studio longitudinale su coppie, dove i partecipanti registrano quotidianamente la frequenza con cui nascondono il loro comportamento di fumo al partner. Basandoci sui dati di Scholz et al. (2021), assumiamo che il tasso medio di nascondere il fumo sia di 1.52 volte al giorno. Supponiamo di avere i seguenti dati giornalieri per un partecipante:\n\nGiorno 1: 2 volte.\nGiorno 2: 0 volte.\nGiorno 3: 1 volta.\nGiorno 4: 3 volte.\n\nUtilizzare un modello Gamma-Poisson per stimare la distribuzione a posteriori del tasso individuale di nascondere il fumo per un partecipante specifico, dato il suo insieme di osservazioni giornaliere.\n\n\n\n\n\n\n\n\n\nSoluzione\n\n\n\n\n\nVogliamo stimare quante volte al giorno una persona tende a nascondere il proprio fumo al partner. Abbiamo quattro giorni di dati su questa persona e, grazie a un precedente studio, sappiamo che in media le persone lo fanno circa 1.52 volte al giorno.\nMa i dati di una sola persona sono pochi, quindi useremo un approccio bayesiano per combinare:\n\n\nLe informazioni preesistenti (dal precedente studio),\n\nLe nuove osservazioni (quanti eventi sono stati registrati nei quattro giorni).\n\nCon un modello Gamma-Poisson, possiamo aggiornare la nostra stima e ottenere una distribuzione a posteriori, che ci dir√† quali sono i valori pi√π probabili per il tasso di nascondimento di questa persona.\n# Dati osservati: numero di volte che la persona ha nascosto il fumo ogni giorno\nosservazioni &lt;- c(2, 0, 1, 3)\n\n# Numero totale di giorni osservati\nn_giorni &lt;- length(osservazioni)\n\n# Numero totale di eventi (quante volte ha nascosto il fumo in totale)\neventi_totali &lt;- sum(osservazioni)\n\n# Informazione a priori dallo studio precedente\nmedia_priori &lt;- 1.52\nforma_priori &lt;- 3   # Parametro di forma scelto per un'incertezza moderata\ntasso_priori &lt;- forma_priori / media_priori  # Parametro di scala\n\n# Aggiornamento bayesiano: parametri della distribuzione a posteriori\nforma_post &lt;- forma_priori + eventi_totali\ntasso_post &lt;- tasso_priori + n_giorni\n\n# Creazione della griglia di valori possibili per il tasso giornaliero (lambda)\nlambda_valori &lt;- seq(0, 5, length.out = 100)\n\n# Calcolo delle densit√† per le distribuzioni a priori e a posteriori\ndensita_priori &lt;- dgamma(lambda_valori, shape = forma_priori, rate = tasso_priori)\ndensita_post &lt;- dgamma(lambda_valori, shape = forma_post, rate = tasso_post)\n\n# Creazione di un dataframe per il grafico\ndati_plot &lt;- data.frame(\n  lambda = rep(lambda_valori, 2),\n  densita = c(densita_priori, densita_post),\n  distribuzione = rep(c(\"Priori\", \"Posteriori\"), each = length(lambda_valori))\n)\n\n# Creazione del grafico per confrontare la distribuzione a priori e quella aggiornata (posteriori)\nggplot(dati_plot, aes(x = lambda, y = densita, color = distribuzione)) +\n  geom_line(size = 1.2) +\n  labs(\n    title = \"Stima del tasso di nascondimento del fumo\",\n    x = \"Tasso giornaliero (Œª)\",\n    y = \"Densit√†\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\nCosa fa questo codice\n\n\nCarica i dati: abbiamo registrato per 4 giorni quante volte questa persona ha nascosto il fumo.\n\nImposta una conoscenza iniziale (priori): basata sullo studio precedente.\n\nApplica il teorema di Bayes per aggiornare la stima con i nuovi dati.\n\nGenera il grafico: confronta la distribuzione prima e dopo l‚Äôaggiornamento con i dati osservati.\n\nInterpretazione del risultato\n\nLa curva rossa (priori) rappresenta la nostra stima iniziale, basata sullo studio precedente.\nLa curva blu (posteriori) √® la nostra nuova stima dopo aver considerato i dati della persona.\nSe i dati raccolti sono molto diversi dal valore medio dello studio, la curva blu si sposter√† rispetto alla rossa.\n\nQuesta analisi ci permette di stimare il comportamento specifico di una persona integrando dati generali e osservazioni individuali, in modo pi√π informativo rispetto a una semplice media.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>54</span>¬† <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_gamma_poisson_model.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/11_gamma_poisson_model.html#informazioni-sullambiente-di-sviluppo",
    "title": "54¬† Modello coniugato Gamma-Poisson",
    "section": "\n54.8 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "54.8 Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] reshape2_1.4.4   mice_3.17.0      thematic_0.1.6   MetBrewer_0.2.0 \n#&gt;  [5] ggokabeito_0.1.0 see_0.11.0       gridExtra_2.3    patchwork_1.3.0 \n#&gt;  [9] bayesplot_1.11.1 psych_2.5.3      scales_1.3.0     markdown_2.0    \n#&gt; [13] knitr_1.50       lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1   \n#&gt; [17] dplyr_1.1.4      purrr_1.0.4      readr_2.1.5      tidyr_1.3.1     \n#&gt; [21] tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3       \n#&gt; [25] here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1  farver_2.1.2      fastmap_1.2.0     pacman_0.5.1     \n#&gt;  [5] digest_0.6.37     rpart_4.1.24      timechange_0.3.0  lifecycle_1.0.4  \n#&gt;  [9] survival_3.8-3    magrittr_2.0.3    compiler_4.4.2    rlang_1.1.5      \n#&gt; [13] tools_4.4.2       labeling_0.4.3    htmlwidgets_1.6.4 mnormt_2.1.1     \n#&gt; [17] plyr_1.8.9        withr_3.0.2       nnet_7.3-20       grid_4.4.2       \n#&gt; [21] jomo_2.7-6        colorspace_2.1-1  iterators_1.0.14  MASS_7.3-65      \n#&gt; [25] cli_3.6.4         rmarkdown_2.29    reformulas_0.4.0  generics_0.1.3   \n#&gt; [29] rstudioapi_0.17.1 tzdb_0.5.0        minqa_1.2.8       splines_4.4.2    \n#&gt; [33] parallel_4.4.2    vctrs_0.6.5       boot_1.3-31       glmnet_4.1-8     \n#&gt; [37] Matrix_1.7-3      jsonlite_1.9.1    hms_1.1.3         mitml_0.4-5      \n#&gt; [41] foreach_1.5.2     glue_1.8.0        nloptr_2.2.1      pan_1.9          \n#&gt; [45] codetools_0.2-20  stringi_1.8.4     shape_1.4.6.1     gtable_0.3.6     \n#&gt; [49] lme4_1.1-36       munsell_0.5.1     pillar_1.10.1     htmltools_0.5.8.1\n#&gt; [53] R6_2.6.1          Rdpack_2.6.3      rprojroot_2.0.4   evaluate_1.0.3   \n#&gt; [57] lattice_0.22-6    rbibutils_2.3     backports_1.5.0   broom_1.0.7      \n#&gt; [61] Rcpp_1.0.14       nlme_3.1-167      xfun_0.51         pkgconfig_2.0.3",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>54</span>¬† <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_gamma_poisson_model.html#bibliografia",
    "href": "chapters/bayesian_inference/11_gamma_poisson_model.html#bibliografia",
    "title": "54¬† Modello coniugato Gamma-Poisson",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nScholz, U., Stadler, G., Berli, C., L√ºscher, J., & Knoll, N. (2021). How do people experience and respond to social control from their partner? Three daily diary studies. Frontiers in Psychology, 11, 613546.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>54</span>¬† <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/12_gamma_exponential_model.html",
    "href": "chapters/bayesian_inference/12_gamma_exponential_model.html",
    "title": "55¬† Modello gamma-esponenziale",
    "section": "",
    "text": "55.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nPreparazione del Notebook\nNell‚Äôinferenza bayesiana, il modello coniugato Gamma-Esponenziale rappresenta un approccio analitico efficace per l‚Äôanalisi di dati che seguono una distribuzione esponenziale. Questa distribuzione √® comunemente utilizzata per modellare i tempi di attesa tra eventi in processi di Poisson, come ad esempio gli intervalli tra arrivi in un sistema a coda o la durata di eventi psicologici.\nConsideriamo, ad esempio, un esperimento in psicologia in cui si misurano i tempi di insorgenza di episodi di ansia in seguito a un evento stressante. In questo caso, si pu√≤ ipotizzare che i tempi di insorgenza siano distribuiti esponenzialmente. Il parametro \\(\\lambda\\) della distribuzione esponenziale rappresenta il tasso medio con cui si verificano gli episodi di ansia.\nIl modello coniugato Gamma-Esponenziale consente di stimare il parametro \\(\\lambda\\) utilizzando i dati osservati. La distribuzione a priori Gamma viene utilizzata per rappresentare l‚Äôincertezza iniziale su \\(\\lambda\\), mentre la distribuzione esponenziale modella i dati osservati. Grazie a questa coniugazione, l‚Äôaggiornamento delle credenze sul parametro \\(\\lambda\\) avviene in modo semplice e analitico, permettendo di ottenere una stima bayesiana del tasso medio di occorrenza degli episodi di ansia, fornendo cos√¨ una descrizione probabilistica accurata del fenomeno in esame.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>55</span>¬† <span class='chapter-title'>Modello gamma-esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/12_gamma_exponential_model.html#introduzione",
    "href": "chapters/bayesian_inference/12_gamma_exponential_model.html#introduzione",
    "title": "55¬† Modello gamma-esponenziale",
    "section": "",
    "text": "55.1.1 Il Modello Matematico\nCaso singolo. Supponiamo di osservare un singolo tempo di attesa \\(y_1\\) prima che si verifichi un evento, come un episodio di disagio psicologico. Assumiamo che questo tempo di attesa segua una distribuzione esponenziale con parametro \\(\\lambda\\). La funzione di densit√† di probabilit√† (pdf) della distribuzione esponenziale √® data da:\n\\[\nf(y_1 \\mid \\lambda) = \\lambda e^{-\\lambda y_1},\n\\]\ndove:\n\n\n\\(y_1\\) rappresenta il tempo di attesa,\n\n\\(\\lambda\\) √® il parametro della distribuzione, che rappresenta il tasso medio con cui gli eventi si verificano per unit√† di tempo.\n\nIn questa distribuzione, \\(\\lambda\\) √® il tasso di occorrenza o tasso di decadimento, ed √® l‚Äôinverso del tempo medio di attesa. Pi√π precisamente:\n\nIl tempo medio di attesa √® il valore medio del tempo che trascorre prima che l‚Äôevento si verifichi (ad esempio, quanto tempo ci si aspetta in media prima che arrivi un autobus).\nIl parametro \\(\\lambda\\) rappresenta la frequenza con cui l‚Äôevento si verifica per unit√† di tempo, e quindi \\(\\lambda = \\frac{1}{\\text{tempo medio}}\\).\n\nPertanto, nella funzione esponenziale \\(f(y_1 \\mid \\lambda) = \\lambda e^{-\\lambda y_1}\\), il parametro \\(\\lambda\\) √® inversamente proporzionale al tempo medio di attesa: pi√π grande √® \\(\\lambda\\), pi√π breve √® il tempo medio di attesa tra gli eventi.\nQuesta funzione descrive la probabilit√† di osservare un tempo di attesa esattamente uguale a \\(y_1\\), dato un valore specifico di \\(\\lambda\\). Per la distribuzione esponenziale, la media √® \\(\\frac{1}{\\lambda}\\) e la varianza √® \\(\\frac{1}{\\lambda^2}\\), il che riflette l‚Äôinfluenza del tasso \\(\\lambda\\) sulla dispersione dei tempi di attesa.\nPer fare un esempio, supponiamo che il tempo medio di attesa sia 2 ore. In questo caso, il parametro \\(\\lambda\\) (l‚Äôinverso del tempo medio di attesa) √® \\(\\frac{1}{2}\\).\n\n# Parametro lambda (l'inverso del tempo medio di attesa)\nlambda_value &lt;- 1 / 2\n\nDisegniamo la funzione di densit√† esponenziale per tempi di attesa compresi tra 0 e 10 ore.\n\n# Creazione dei valori di y1 su cui valutare la funzione\ny1_values &lt;- seq(0, 10, length.out = 500) # Intervallo da 0 a 10 ore\n\n# Definizione della funzione di densit√† esponenziale\nexponential_density &lt;- function(y1, lambda_value) {\n  lambda_value * exp(-lambda_value * y1)\n}\n\n# Calcolo dei valori di f(y1 | lambda)\nf_values &lt;- exponential_density(y1_values, lambda_value)\n\n# Creazione del grafico\nplot(\n  y1_values, f_values,\n  type = \"l\", lwd = 2,\n  main = expression(paste(\n    \"Funzione di Densit√† Esponenziale con \",\n    lambda, \" = 1/2\"\n  )),\n  xlab = \"Tempo di attesa (ore)\", ylab = \"Densit√†\"\n)\nlegend(\"topright\",\n  legend = expression(f(y[1] ~ \"|\" ~ lambda) == lambda ~ e^(-lambda * y[1])),\n  lty = 1, bty = \"n\"\n)\n\n\n\n\n\n\n\nQuesto codice crea un grafico della funzione di densit√† esponenziale per \\(\\lambda = 1/2\\) e tempi di attesa compresi tra 0 e 10 ore.\nIl caso di \\(n\\) osservazioni indipendenti. Consideriamo ora un campione di \\(n\\) osservazioni indipendenti \\(y_1, y_2, \\dots, y_n\\). L‚Äôindipendenza tra le osservazioni implica che il tempo di attesa osservato per un evento non influisce sulla probabilit√† di osservare altri tempi di attesa.\nPoich√© le osservazioni sono indipendenti, la probabilit√† congiunta di osservare tutti i tempi di attesa nel campione √® il prodotto delle probabilit√† individuali. Di conseguenza, la funzione di verosimiglianza per l‚Äôintero campione √® data da:\n\\[\nf(y_1, y_2, \\dots, y_n \\mid \\lambda) = f(y_1 \\mid \\lambda) \\cdot f(y_2 \\mid \\lambda) \\cdot \\dots \\cdot f(y_n \\mid \\lambda).\n\\]\nSostituendo la funzione di densit√† della distribuzione esponenziale per ciascuna osservazione, otteniamo:\n\\[\nf(y \\mid \\lambda) = \\lambda e^{-\\lambda y_1} \\cdot \\lambda e^{-\\lambda y_2} \\cdot \\dots \\cdot \\lambda e^{-\\lambda y_n}.\n\\]\nRaccogliendo i termini comuni, possiamo riscrivere la funzione di verosimiglianza come:\n\\[\nf(y \\mid \\lambda) = \\lambda^n e^{-\\lambda (y_1 + y_2 + \\dots + y_n)}.\n\\]\nUtilizzando la notazione di sommatoria, possiamo esprimere la funzione di verosimiglianza in modo compatto come:\n\\[\nf(y \\mid \\lambda) = \\lambda^n e^{-\\lambda \\sum_{i=1}^{n} y_i}.\n\\]\nLa funzione di verosimiglianza \\(f(y \\mid \\lambda)\\) rappresenta la probabilit√† di osservare il campione \\(y_1, y_2, \\dots, y_n\\) dato un particolare valore del parametro \\(\\lambda\\). Un valore pi√π alto della verosimiglianza indica una maggiore plausibilit√† del valore di \\(\\lambda\\), dato il campione osservato.\nSpesso √® pi√π conveniente lavorare con il logaritmo della funzione di verosimiglianza, poich√© il logaritmo trasforma i prodotti in somme, semplificando i calcoli. Il logaritmo della funzione di verosimiglianza √®:\n\\[\n\\log L(\\lambda \\mid y_1, y_2, \\dots, y_n) = n \\log \\lambda - \\lambda \\sum_{i=1}^{n} y_i.\n\\]\nQuesta forma semplificata della log-verosimiglianza √® utile per stimare il parametro \\(\\lambda\\) tramite tecniche come la massimizzazione della verosimiglianza.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>55</span>¬† <span class='chapter-title'>Modello gamma-esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/12_gamma_exponential_model.html#aggiornare-le-nostre-credenze-con-linferenza-bayesiana",
    "href": "chapters/bayesian_inference/12_gamma_exponential_model.html#aggiornare-le-nostre-credenze-con-linferenza-bayesiana",
    "title": "55¬† Modello gamma-esponenziale",
    "section": "\n55.2 Aggiornare le Nostre Credenze con l‚ÄôInferenza Bayesiana",
    "text": "55.2 Aggiornare le Nostre Credenze con l‚ÄôInferenza Bayesiana\nNell‚Äôapproccio bayesiano, non consideriamo solo i dati, ma anche le nostre conoscenze a priori sul parametro \\(\\lambda\\). Assegniamo a \\(\\lambda\\) una distribuzione a priori, tipicamente una distribuzione Gamma. Combinando la verosimiglianza con la distribuzione a priori, otteniamo la distribuzione a posteriori di \\(\\lambda\\), che rappresenta la nostra conoscenza aggiornata alla luce dei dati. La propriet√† della coniugazione assicura che la distribuzione a posteriori sia anch‚Äôessa una Gamma, facilitando i calcoli.\nPer fare un esempio concreto, simuleremo un campione di dati. Immaginiamo di raccogliere dati che rappresentano il tempo, misurato in ore, che intercorre tra episodi di ansia in individui con disturbi d‚Äôansia. La distribuzione esponenziale pu√≤ essere utilizzata per modellare questo tempo di attesa tra un episodio di ansia e il successivo. Ad esempio, possiamo ipotizzare che, una volta concluso un episodio, l‚Äôinsorgenza del prossimo segua un processo stocastico con un tasso costante, indipendentemente dal tempo trascorso dall‚Äôepisodio precedente. In questo contesto, il parametro \\(\\lambda\\) della distribuzione esponenziale rappresenta il tasso medio di occorrenza degli episodi di ansia, ossia quanti episodi ci si aspetta in media in una certa unit√† di tempo (ad esempio, in un giorno).\nSe \\(\\lambda\\) √® elevato, ci√≤ indica che gli episodi di ansia sono pi√π frequenti, con tempi di attesa pi√π brevi tra un episodio e l‚Äôaltro.\n\n# Impostiamo il seed per rendere i risultati riproducibili\nset.seed(42)\n\n# Parametro medio (tempo medio di attesa in ore)\nmean_time &lt;- 3.0\nlambda_param &lt;- 1 / mean_time # Parametro lambda per la distribuzione esponenziale\n\n# Numero di osservazioni nel campione\nn &lt;- 15\n\n# Generazione del campione casuale\ny &lt;- round(rexp(n, rate = lambda_param))\ny\n#&gt;  [1] 1 2 1 0 1 4 1 1 4 2 4 7 0 0 4\n\nImmaginiamo che questi dati rappresentino il tempo di attesa in ore tra episodi di ansia in 15 individui con disturbi d‚Äôansia. Il tempo di attesa medio √®:\n\nmean_time_observed &lt;- mean(y)\nmean_time_observed\n#&gt; [1] 2.133\n\nIl tasso di occorrenza, \\(\\lambda\\), calcolato sulla base dei dati osservati √®:\n\nlambda_estimated &lt;- 1 / mean_time_observed\nlambda_estimated\n#&gt; [1] 0.4688\n\nOra possiamo procedere a trovare la distribuzione a posteriori per il tasso di occorrenza \\(\\lambda\\).\n\n55.2.1 Passi per definire un prior debolmente informativo\nIl primo passo consiste nel definire una distribuzione a priori per \\(\\lambda\\), il tasso di occorrenza degli episodi di ansia in individui con disturbi d‚Äôansia. Se disponiamo di poche informazioni a priori riguardo al valore di \\(\\lambda\\), possiamo adottare una distribuzione a priori debolmente informativa. Un prior debolmente informativo ha lo scopo di esercitare una minima influenza sull‚Äôinferenza, consentendo ai dati osservati di guidare principalmente la stima del parametro.\nLa distribuzione a priori coniugata per la distribuzione esponenziale √® la distribuzione Gamma. Un prior debolmente informativo per \\(\\lambda\\) potrebbe essere impostato in modo tale da riflettere una conoscenza vaga, con una media che rappresenta un tempo di attesa ragionevole (basato su qualche informazione preliminare o ipotesi generale), ma con una varianza ampia, in modo da non vincolare eccessivamente l‚Äôinferenza.\nSupponiamo di voler impostare una distribuzione a priori per il tasso di occorrenza \\(\\lambda\\), in modo tale che il tempo medio di attesa sia 3.33 ore, con una deviazione standard ampia, ad esempio 5 ore. Poich√© \\(\\lambda\\) rappresenta il tasso di occorrenza (ovvero l‚Äôinverso del tempo medio di attesa), dobbiamo applicare la distribuzione Gamma ai valori di \\(\\lambda\\), non direttamente ai tempi di attesa.\nI parametri della distribuzione Gamma, \\(\\alpha\\) (forma) e \\(\\beta\\) (tasso), sono dati da:\n\n\\(\\alpha_{\\text{prior}} = 0.45\\)\n\\(\\beta_{\\text{prior}} = 1.5\\)\n\nVerifichiamo che questi parametri corrispondano alla media e alla varianza desiderate.\n\n# Parametri della distribuzione Gamma\nalpha_prior &lt;- 0.45 # Forma\nbeta_prior &lt;- 1.5 # Tasso (inverso della scala)\n\n# Calcolo della media e della varianza della distribuzione Gamma per Œª\nmean_lambda &lt;- alpha_prior / beta_prior\nvariance_lambda &lt;- alpha_prior / (beta_prior^2)\n\n# Calcolo della media del tempo di attesa (E[Y] = 1 / E[Œª])\nmean_waiting_time &lt;- 1 / mean_lambda\n\n# Stampiamo la media e la varianza di Œª e del tempo di attesa\ncat(\"Media di Œª:\", mean_lambda, \"\\n\")\n#&gt; Media di Œª: 0.3\ncat(\"Varianza di Œª:\", variance_lambda, \"\\n\")\n#&gt; Varianza di Œª: 0.2\ncat(\"Media del tempo di attesa:\", mean_waiting_time, \"ore\\n\")\n#&gt; Media del tempo di attesa: 3.333 ore\n\nLa media del tempo di attesa √® 3.33 ore, come desiderato. La varianza del tempo di attesa richiede un calcolo pi√π complesso e non √® semplicemente l‚Äôinverso della varianza di \\(\\lambda\\).\n\n55.2.2 Visualizzazione della Distribuzione a Priori\nDisegniamo la funzione di densit√† della distribuzione Gamma per \\(\\lambda\\), utilizzando i parametri specificati.\n\n# Creazione dei valori x per il grafico\nx &lt;- seq(0, 2, length.out = 500)\n\n# Funzione di densit√† della distribuzione Gamma con i parametri dati\ngamma_pdf &lt;- dgamma(x, shape = alpha_prior, rate = beta_prior)\n\n# Creazione del grafico\nplot(x, gamma_pdf,\n  type = \"l\", lwd = 2,\n  main = bquote(\"Funzione di Densit√† Gamma con \" ~ alpha == .(alpha_prior) ~ \",\" ~ beta == .(beta_prior)),\n  xlab = expression(lambda),\n  ylab = \"Densit√† di probabilit√†\"\n)\nlegend(\n  \"topright\",\n  legend = \"Distribuzione a Priori\",\n  lty = 1,\n  lwd = 2,\n  bty = \"n\"\n)",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>55</span>¬† <span class='chapter-title'>Modello gamma-esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/12_gamma_exponential_model.html#metodo-basato-su-griglia",
    "href": "chapters/bayesian_inference/12_gamma_exponential_model.html#metodo-basato-su-griglia",
    "title": "55¬† Modello gamma-esponenziale",
    "section": "\n55.3 Metodo Basato su Griglia",
    "text": "55.3 Metodo Basato su Griglia\nPoniamoci l‚Äôobiettivo di utilizzare il metodo basato su griglia per derivare la distribuzione a posteriori del parametro \\(\\lambda\\) della distribuzione esponenziale. Iniziamo creando una griglia per \\(\\lambda\\) nell‚Äôintervallo [0.01, 2].\n\n# Evitiamo zero per evitare divisione per zero\nlambda_grid &lt;- seq(0.01, 2, length.out = 1000)\n\n\n55.3.1 Calcolo della Distribuzione a Priori\n\n# Calcolo della distribuzione a priori\nprior &lt;- dgamma(lambda_grid, shape = alpha_prior, rate = beta_prior)\n\n\n55.3.2 Calcolo della Verosimiglianza\nImmaginiamo di avere i seguenti dati, che rappresentano i tempi di attesa (in ore) tra episodi di ansia per 15 individui:\n\n# Impostiamo il seed per rendere i risultati riproducibili\nset.seed(42)\n\n# Parametro medio (tempo medio di attesa in ore)\nmean_time &lt;- 3.0\nlambda_param &lt;- 1 / mean_time # Parametro Œª per la distribuzione esponenziale\n\n# Numero di osservazioni nel campione\nn &lt;- 15\n\n# Generazione del campione casuale\ny &lt;- round(rexp(n, rate = lambda_param))\ny\n#&gt;  [1] 1 2 1 0 1 4 1 1 4 2 4 7 0 0 4\n\nCalcoliamo la log-verosimiglianza per ciascun valore di \\(\\lambda\\) nella griglia:\n\n# Calcolo della log-verosimiglianza per ciascun valore di lambda\nlog_likelihood &lt;- sapply(\n  lambda_grid,\n  function(lam) sum(dexp(y, rate = lam, log = TRUE))\n)\n\n\n55.3.3 Calcolo della Distribuzione a Posteriori\nCalcoliamo la distribuzione a posteriori non normalizzata in logaritmo per evitare problemi di underflow numerico:\n\n# Calcolo del log-posteriori non normalizzato\nlog_posterior_unnormalized &lt;- log_likelihood + log(prior)\n\n# Normalizzazione per stabilit√† numerica\nlog_posterior_unnormalized &lt;- log_posterior_unnormalized - max(log_posterior_unnormalized)\n\n# Convertiamo in scala normale\nposterior_unnormalized &lt;- exp(log_posterior_unnormalized)\n\nNormalizziamo la distribuzione a posteriori:\n\n# Calcolo del passo nella griglia\ndelta_lambda &lt;- diff(lambda_grid)[1] # Assumendo che la griglia sia equispaziata\n\n# Normalizzazione della distribuzione a posteriori\nposterior &lt;-\n  posterior_unnormalized / sum(posterior_unnormalized * delta_lambda)\n\n\n55.3.4 Visualizzazione dei Risultati\n\n# Grafico della distribuzione a posteriori e a priori\nplot(lambda_grid, posterior,\n  type = \"l\",\n  lwd = 2,\n  xlab = expression(lambda),\n  ylab = \"Densit√† di probabilit√†\",\n  main = \"Distribuzione a Posteriori di Œª\"\n)\nlines(lambda_grid, prior, lwd = 2, lty = 2)\nlegend(\"topright\",\n  legend = c(\"Posteriori\", \"Priori\"),\n  lty = c(1, 2), \n  lwd = 2, \n  bty = \"n\"\n)\n\n\n\n\n\n\n\nDal grafico, possiamo osservare come la distribuzione a posteriori di \\(\\lambda\\) sia aggiornata rispetto alla distribuzione a priori in base ai dati osservati. La distribuzione a posteriori riflette sia le informazioni a priori sia l‚Äôevidenza fornita dai dati, fornendo una stima aggiornata del tasso di occorrenza degli episodi di ansia.\n\n55.3.5 Calcolo della Media e Varianza Posteriori\nPossiamo calcolare la media e la varianza a posteriori di \\(\\lambda\\) utilizzando la distribuzione a posteriori calcolata sulla griglia.\n\n# Calcolo della media a posteriori di Œª\nposterior_mean_lambda &lt;- sum(lambda_grid * posterior * delta_lambda)\n\n# Calcolo della varianza a posteriori di Œª\nposterior_variance_lambda &lt;-\n  sum((lambda_grid - posterior_mean_lambda)^2 * posterior * delta_lambda)\n\n# Stampiamo i risultati\ncat(\"Media a posteriori di Œª:\", posterior_mean_lambda, \"\\n\")\n#&gt; Media a posteriori di Œª: 0.4612\ncat(\"Varianza a posteriori di Œª:\", posterior_variance_lambda, \"\\n\")\n#&gt; Varianza a posteriori di Œª: 0.01377\n\n\n55.3.6 Stima del Tempo di Attesa Medio a Posteriori\nUtilizzando la media a posteriori di \\(\\lambda\\), possiamo stimare il tempo di attesa medio a posteriori:\n\n# Stima del tempo di attesa medio a posteriori\nposterior_mean_waiting_time &lt;- 1 / posterior_mean_lambda\ncat(\"Tempo di attesa medio a posteriori:\", posterior_mean_waiting_time, \"ore\\n\")\n#&gt; Tempo di attesa medio a posteriori: 2.168 ore\n\nIn conclusione, attraverso il metodo basato su griglia, abbiamo derivato la distribuzione a posteriori del tasso di occorrenza \\(\\lambda\\), tenendo conto della nostra conoscenza a priori e dei dati osservati. Questo approccio ci permette di aggiornare le nostre credenze su \\(\\lambda\\) in modo coerente con l‚Äôevidenza empirica, fornendo stime pi√π accurate e affidabili.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>55</span>¬† <span class='chapter-title'>Modello gamma-esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/12_gamma_exponential_model.html#modello-coniugato-gamma-esponenziale",
    "href": "chapters/bayesian_inference/12_gamma_exponential_model.html#modello-coniugato-gamma-esponenziale",
    "title": "55¬† Modello gamma-esponenziale",
    "section": "\n55.4 Modello Coniugato Gamma-Esponenziale",
    "text": "55.4 Modello Coniugato Gamma-Esponenziale\nQuando utilizziamo una distribuzione \\(\\text{Gamma}(\\alpha, \\beta)\\) come distribuzione coniugata a priori, la distribuzione a posteriori risulta anch‚Äôessa essere una distribuzione Gamma, con parametri aggiornati \\(\\alpha + n\\) e \\(\\beta + \\sum_{i=1}^{n} x_{i}\\).\nIn altre parole, se il parametro \\(\\lambda\\) della distribuzione esponenziale segue una distribuzione a priori Gamma con parametri \\(\\alpha\\) e \\(\\beta\\), allora, dopo aver osservato un campione di \\(n\\) osservazioni \\(x_1, x_2, \\dots, x_n\\), la distribuzione a posteriori di \\(\\lambda\\) sar√† ancora una distribuzione Gamma, ma con i parametri aggiornati:\n\\[\n\\lambda \\mid x \\sim \\text{Gamma}(\\alpha + n, \\beta + \\sum_{i=1}^{n} x_{i}).\n\\]\nQuesto aggiornamento dei parametri √® una conseguenza della propriet√† coniugata della distribuzione Gamma rispetto alla distribuzione esponenziale.\n\n55.4.1 Dimostrazione del Modello Coniugato Gamma-Esponenziale\nPer dimostrare questo risultato, partiamo dal teorema di Bayes:\n\\[\nf(\\lambda \\mid x) \\propto f(x \\mid \\lambda) \\cdot f(\\lambda),\n\\]\ndove \\(f(\\lambda \\mid x)\\) √® la distribuzione a posteriori di \\(\\lambda\\) dato il campione \\(x\\), \\(f(x \\mid \\lambda)\\) √® la verosimiglianza basata sul campione \\(x\\), e \\(f(\\lambda)\\) √® la distribuzione a priori di \\(\\lambda\\).\nLa funzione di verosimiglianza per un campione di \\(n\\) osservazioni indipendenti \\(x_1, x_2, \\dots, x_n\\), che seguono una distribuzione esponenziale con parametro \\(\\lambda\\), √® data da:\n\\[\nf(x \\mid \\lambda) = \\prod_{i=1}^{n} \\lambda e^{-\\lambda x_i} = \\lambda^n e^{-\\lambda \\sum_{i=1}^{n} x_i}.\n\\]\nSupponiamo che il parametro \\(\\lambda\\) segua una distribuzione a priori Gamma con parametri \\(\\alpha\\) e \\(\\beta\\):\n\\[\nf(\\lambda) = \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)} \\lambda^{\\alpha - 1} e^{-\\beta \\lambda}.\n\\]\nMoltiplicando la verosimiglianza per la distribuzione a priori, otteniamo la distribuzione a posteriori:\n\\[\nf(\\lambda \\mid x) \\propto \\lambda^n e^{-\\lambda \\sum_{i=1}^{n} x_i} \\cdot \\lambda^{\\alpha - 1} e^{-\\beta \\lambda}.\n\\]\nSemplificando, si ottiene:\n\\[\nf(\\lambda \\mid x) \\propto \\lambda^{n + \\alpha - 1} e^{-\\lambda \\left(\\beta + \\sum_{i=1}^{n} x_i\\right)}.\n\\]\nQuesta espressione corrisponde alla forma di una distribuzione Gamma con parametri aggiornati:\n\nparametro della forma (alpha): \\(\\alpha_{\\text{post}} = \\alpha + n\\);\nparametro della scala (beta): \\(\\beta_{\\text{post}} = \\beta + \\sum_{i=1}^{n} x_i\\).\n\nQuindi, la distribuzione a posteriori di \\(\\lambda\\) dato il campione \\(x\\) segue una distribuzione Gamma con parametri aggiornati:\n\\[\n\\lambda \\mid x \\sim \\text{Gamma}(\\alpha + n, \\beta + \\sum_{i=1}^{n} x_i).\n\\]\nQuesta derivazione mostra come l‚Äôinformazione contenuta nei dati osservati venga incorporata nei parametri della distribuzione a posteriori, mantenendo la forma della distribuzione a priori grazie alla propriet√† coniugata.\n\n55.4.2 Calcolo dei Parametri Aggiornati\nPer il caso dell‚Äôesempio in discussione:\n\nIl numero di osservazioni nel campione \\(n\\) √® 15;\nLa somma delle osservazioni nel campione √®:\n\n\\[\n\\sum_{i=1}^{n} y_i =\n1 + 9 + 4 + 3 + 1 + 1 + 0 + 6 + 3 + 4 + 0 + 11 + 5 + 1 + 1 = 50.\n\\]\nLa distribuzione a posteriori per \\(\\lambda\\) segue una distribuzione Gamma aggiornata con i seguenti parametri:\n\\[\n\\alpha_{\\text{post}} = \\alpha_{\\text{prior}} + n,\n\\]\n\\[\n\\beta_{\\text{post}} = \\beta_{\\text{prior}} + \\sum_{i=1}^{n} y_i.\n\\]\nUsando i valori \\(\\alpha_{\\text{prior}} = 0.009\\) e \\(\\beta_{\\text{prior}} = 0.03\\), otteniamo:\n\\[\n\\alpha_{\\text{post}} = 0.009 + 15 = 15.009,\n\\]\n\\[\n\\beta_{\\text{post}} = 0.03 + 50 = 50.03.\n\\]\n\n# Dati iniziali\nalpha_prior &lt;- 0.009\nbeta_prior &lt;- 0.03\nn &lt;- 15\ny &lt;- c(1, 9, 4, 3, 1, 1, 0, 6, 3, 4, 0, 11, 5, 1, 1)\nsum_y &lt;- sum(y)\n\n# Parametri aggiornati\nalpha_post &lt;- alpha_prior + n\nbeta_post &lt;- beta_prior + sum_y\n\n# Stampa dei parametri aggiornati\ncat(sprintf(\"alpha_post = %.3f; beta_post = %.3f\\n\", alpha_post, beta_post))\n#&gt; alpha_post = 15.009; beta_post = 50.030\n\nGeneriamo il grafico della distribuzione a posteriori.\n\n# Griglia di valori di lambda per il grafico\nlambda_grid &lt;- seq(0, 2, length.out = 1000)\n\n# Calcolo della densit√† della distribuzione Gamma a posteriori\nposterior_pdf &lt;- dgamma(lambda_grid, shape = alpha_post, rate = beta_post)\n\n# Creazione del grafico\nplot(\n  lambda_grid, posterior_pdf,\n  type = \"l\", lwd = 2,\n  main = bquote(\n    \"Distribuzione Gamma a Posteriori con \" ~ alpha[post] ==\n      .(alpha_post) ~ \",\" ~ beta[post] == .(beta_post)\n  ),\n  xlab = expression(lambda), ylab = \"Densit√† di probabilit√†\"\n)\nlegend(\n  \"topright\",\n  legend = bquote(\n    Gamma(alpha[post] == .(alpha_post) ~ \",\" ~ beta[post] == .(beta_post))\n  ),\n  lty = 1,\n  lwd = 2,\n  bty = \"n\"\n)\n\n\n\n\n\n\n\n\n55.4.3 Calcolo della Media e della Varianza a Posteriori\nLa media e la varianza della distribuzione a posteriori sono calcolate come:\n\\[\n\\text{E}[\\lambda \\mid y] = \\frac{\\alpha_{\\text{post}}}{\\beta_{\\text{post}}},\n\\]\n\\[\n\\text{Var}[\\lambda \\mid y] = \\frac{\\alpha_{\\text{post}}}{\\beta_{\\text{post}}^2}.\n\\]\nIn R:\n\n# Calcolo della media e della varianza a posteriori\nposterior_mean &lt;- alpha_post / beta_post\nposterior_variance &lt;- alpha_post / (beta_post^2)\n\n# Stampa dei risultati\ncat(sprintf(\"Media a posteriori di Œª: %.3f\\n\", posterior_mean))\n#&gt; Media a posteriori di Œª: 0.300\ncat(sprintf(\"Varianza a posteriori di Œª: %.6f\\n\", posterior_variance))\n#&gt; Varianza a posteriori di Œª: 0.005996\n\nLa distribuzione a posteriori di \\(\\lambda\\) √® aggiornata in base ai dati osservati e al prior. La media a posteriori rappresenta la stima del tasso di occorrenza degli episodi di ansia, mentre la varianza riflette l‚Äôincertezza nella stima.\n\n\nMedia a Posteriori: La media a posteriori di \\(\\lambda\\) √® circa 0.3, indicando un tasso di occorrenza medio di 0.3 episodi per ora.\n\nVarianza a Posteriori: La varianza di 0.006 riflette una moderata incertezza nella stima di \\(\\lambda\\).\n\nQuesti risultati evidenziano come la distribuzione Gamma aggiornata combini informazioni a priori e dati osservati per ottenere stime robuste del tasso di occorrenza \\(\\lambda\\).\n\n55.4.4 Trasformazione della media e della varianza\nPer interpretare questi risultati in termini di tempi di attesa, dobbiamo trasformare i valori sulla scala inversa, cio√® passare dal tasso \\(\\lambda\\) ai tempi di attesa \\(T = \\frac{1}{\\lambda}\\).\nLa media del tempo di attesa \\(T\\) √® l‚Äôinverso della media del tasso di occorrenza \\(\\lambda\\). Pertanto, la media dei tempi di attesa sar√†:\n\\[\n\\text{E}[T \\mid y] = \\frac{1}{\\text{E}[\\lambda \\mid y]} = \\frac{1}{0.3} \\approx 3.33 \\, \\text{ore}.\n\\]\nPer la varianza del tempo di attesa, dobbiamo applicare una trasformazione pi√π complessa. La varianza del tempo di attesa \\(T\\) √® legata alla varianza di \\(\\lambda\\) da:\n\\[\n\\text{Var}(T) = \\frac{\\text{Var}[\\lambda \\mid y]}{(\\text{E}[\\lambda \\mid y])^4}.\n\\]\nSostituendo i valori calcolati per la varianza e la media di \\(\\lambda\\), otteniamo:\n\\[\n\\text{Var}(T) \\approx \\frac{0.006}{(0.3)^4} \\approx 24.59 \\, \\text{ore}.\n\\]\nIn conclusione,\n\nla media del tempo di attesa a posteriori √® di circa 3.33 ore;\nla varianza del tempo di attesa a posteriori √® di circa 24.59 ore, che indica una certa dispersione dei tempi di attesa, con alcuni episodi che possono verificarsi molto pi√π rapidamente o pi√π lentamente rispetto alla media. Si noti che la distribuzione a posteriori √® pi√π concentrata rispetto al prior, poich√© incorpora l‚Äôinformazione aggiuntiva proveniente dai dati osservati.\n\nQuesta trasformazione ci permette di interpretare i risultati sulla scala dei tempi di attesa, che √® pi√π intuitiva per descrivere fenomeni psicologici come l‚Äôinsorgenza di episodi di ansia.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>55</span>¬† <span class='chapter-title'>Modello gamma-esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/12_gamma_exponential_model.html#applicazioni",
    "href": "chapters/bayesian_inference/12_gamma_exponential_model.html#applicazioni",
    "title": "55¬† Modello gamma-esponenziale",
    "section": "\n55.5 Applicazioni",
    "text": "55.5 Applicazioni\nUna volta ottenuta la distribuzione a posteriori per Œª, possiamo utilizzarla per rispondere a domande probabilistiche relative ai tempi di attesa tra episodi di ansia. Questo approccio ci consente di calcolare probabilit√† aggiornate alla luce dei dati osservati, rispecchiando meglio l‚Äôincertezza e le informazioni disponibili. Ad esempio, possiamo stimare la probabilit√† di osservare tempi di attesa compresi tra 2 e 5 ore.\nPer risolvere questo problema possiamo usare il metodo Monte Carlo:\n\nGeneriamo un gran numero di campioni dalla distribuzione Gamma a posteriori di \\(\\lambda\\), usando i parametri \\(\\alpha_{\\text{posteriori}}\\) e \\(\\beta_{\\text{posteriori}}\\).\nConvertiamo ciascun \\(\\lambda\\) campionato in un tempo di attesa \\(T = \\frac{1}{\\lambda}\\).\nCalcoliamo le probabilit√† richieste (ad esempio, \\(P(T &gt; 2)\\) e \\(P(T &lt; 5)\\)) semplicemente contando le proporzioni di campioni che soddisfano tali condizioni.\n\n\n55.5.1 Simulazione con Monte Carlo\nUtilizziamo i parametri posteriori della distribuzione Gamma per simulare campioni di \\(\\lambda\\) e calcolare la probabilit√† che il tempo di attesa tra due episodi di ansia sia compreso tra 2 e 5 ore.\n\n# Parametri posteriori per la distribuzione Gamma\nalpha_post &lt;- 15.009\nbeta_post &lt;- 50.03\n\n# Numero di campioni da generare\nn_samples &lt;- 100000\n\n# Simulazione di campioni dalla distribuzione Gamma per Œª\nlambda_samples &lt;- rgamma(n_samples, shape = alpha_post, rate = beta_post)\n\n# Conversione dei campioni di Œª in tempi di attesa T = 1/Œª\nwaiting_time_samples &lt;- 1 / lambda_samples\n\n# Calcolo della probabilit√† che il tempo di attesa sia compreso tra 2 e 5 ore\nprob_between_2_and_5_mc &lt;-\n  mean(waiting_time_samples &gt;= 2 & waiting_time_samples &lt;= 5)\n\n# Stampa del risultato\ncat(sprintf(\"Probabilit√† che il tempo di attesa sia tra 2 e 5 ore: %.4f\\n\", prob_between_2_and_5_mc))\n#&gt; Probabilit√† che il tempo di attesa sia tra 2 e 5 ore: 0.9027\n\nLa probabilit√† che il tempo di attesa tra due episodi di ansia sia compreso tra 2 e 5 ore √® di circa 0.9029, ovvero il 90.3%. Questa stima si basa su campioni simulati dalla distribuzione a posteriori di \\(\\lambda\\), trasformati nei corrispondenti tempi di attesa. L‚Äôapproccio Monte Carlo √® utile per calcolare probabilit√† che coinvolgono trasformazioni non lineari, come nel caso del tempo di attesa.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>55</span>¬† <span class='chapter-title'>Modello gamma-esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/12_gamma_exponential_model.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/12_gamma_exponential_model.html#riflessioni-conclusive",
    "title": "55¬† Modello gamma-esponenziale",
    "section": "\n55.6 Riflessioni Conclusive",
    "text": "55.6 Riflessioni Conclusive\nIl modello esponenziale si rivela uno strumento utile e versatile nella ricerca psicologica, in particolare per la modellazione di fenomeni caratterizzati da tempi di attesa o durate di eventi. √à applicabile in vari contesti, tra cui l‚Äôanalisi dei tempi di reazione, lo studio degli intervalli tra episodi di ansia o depressione e, pi√π in generale, in tutti quei processi psicologici che possono essere descritti come il tempo trascorso fino al verificarsi di un evento.\nUn aspetto particolarmente vantaggioso dell‚Äôuso di modelli basati sulla distribuzione esponenziale nell‚Äôinferenza bayesiana √® la possibilit√† di utilizzare le famiglie coniugate. Nella famiglia coniugata Gamma-Esponenziale, la distribuzione a priori Gamma per il tasso \\(\\lambda\\) si aggiorna in modo analitico quando si osservano nuovi dati esponenziali. Questo rende i calcoli bayesiani particolarmente efficienti e semplici da implementare, poich√© la distribuzione a posteriori rimane della stessa forma della distribuzione a priori (ossia, una Gamma). Tale propriet√† coniugata consente di ottenere una stima aggiornata del tasso \\(\\lambda\\) e di fare inferenze accurate sui tempi di attesa futuri.\nLa combinazione tra la distribuzione esponenziale e il prior Gamma non solo semplifica l‚Äôinferenza, ma fornisce anche una struttura interpretativa chiara. Ad esempio, il parametro \\(\\lambda\\), che rappresenta il tasso di occorrenza di un fenomeno, viene aggiornato sulla base dell‚Äôevidenza osservata, consentendo una stima dinamica della frequenza con cui gli episodi si verificano. Questo approccio bayesiano offre un‚Äôinterpretazione probabilistica naturale dei tempi di attesa futuri, rispecchiando l‚Äôincertezza presente nei dati.\nInoltre, grazie alla flessibilit√† del metodo Monte Carlo, √® possibile simulare campioni dalla distribuzione a posteriori di \\(\\lambda\\) e ottenere stime precise per una vasta gamma di probabilit√†, come la probabilit√† che il tempo di attesa sia compreso tra intervalli specifici. Questo approccio simulativo permette di rispondere a domande specifiche relative ai processi psicologici, ad esempio la probabilit√† che un episodio di ansia duri pi√π di un certo numero di ore.\nIn conclusione, il modello esponenziale, integrato in un framework bayesiano con famiglie coniugate, rappresenta un utile strumento per la ricerca psicologica. Offre un modo rigoroso per modellare e analizzare dati su tempi di attesa e durate, fornendo al contempo una base solida per l‚Äôinferenza e la previsione dei processi psicologici.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>55</span>¬† <span class='chapter-title'>Modello gamma-esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/12_gamma_exponential_model.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/12_gamma_exponential_model.html#informazioni-sullambiente-di-sviluppo",
    "title": "55¬† Modello gamma-esponenziale",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.5.3     \n#&gt;  [9] scales_1.3.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.9.1   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         rlang_1.1.5       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       tools_4.4.2       parallel_4.4.2    tzdb_0.5.0       \n#&gt; [21] colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5       R6_2.6.1         \n#&gt; [25] lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.1    \n#&gt; [29] gtable_0.3.6      glue_1.8.0        xfun_0.51         tidyselect_1.2.1 \n#&gt; [33] rstudioapi_0.17.1 farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-167     \n#&gt; [37] rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>55</span>¬† <span class='chapter-title'>Modello gamma-esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/13_post_pred_distr.html",
    "href": "chapters/bayesian_inference/13_post_pred_distr.html",
    "title": "56¬† Distribuzione predittiva a posteriori",
    "section": "",
    "text": "56.1 Introduzione\nNel contesto dell‚Äôinferenza bayesiana, uno degli obiettivi principali √® non solo stimare i parametri di un modello (ad esempio, la probabilit√† \\(p\\) di successo in un esperimento binomiale) ma anche fare previsioni su dati futuri basandosi su ci√≤ che abbiamo osservato. La distribuzione predittiva a posteriori risponde proprio a questa esigenza, combinando:\nIn termini semplici, la distribuzione predittiva a posteriori ci dice quali risultati futuri sono plausibili, dato ci√≤ che sappiamo dai dati osservati e dal modello.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>56</span>¬† <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/13_post_pred_distr.html#introduzione",
    "href": "chapters/bayesian_inference/13_post_pred_distr.html#introduzione",
    "title": "56¬† Distribuzione predittiva a posteriori",
    "section": "",
    "text": "La nostra incertezza sui parametri descritta dalla distribuzione a posteriori.\nLa variabilit√† intrinseca del processo che genera i dati futuri.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>56</span>¬† <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/13_post_pred_distr.html#definizione-formale",
    "href": "chapters/bayesian_inference/13_post_pred_distr.html#definizione-formale",
    "title": "56¬† Distribuzione predittiva a posteriori",
    "section": "\n56.2 Definizione Formale",
    "text": "56.2 Definizione Formale\nSupponiamo di avere un insieme di dati osservati \\(y = \\{y_1, y_2, \\ldots, y_n\\}\\), generati da un modello che dipende da un parametro sconosciuto \\(\\theta\\). Il parametro \\(\\theta\\) pu√≤ rappresentare qualsiasi caratteristica del modello, come una probabilit√† di successo, una media, o un coefficiente in un modello di regressione. Inizialmente, la nostra conoscenza su \\(\\theta\\) √® rappresentata dalla distribuzione a priori \\(p(\\theta)\\), che riflette ci√≤ che sappiamo (o non sappiamo) su \\(\\theta\\) prima di osservare i dati.\nDopo aver osservato i dati \\(y\\), possiamo aggiornare la nostra conoscenza su \\(\\theta\\) utilizzando la formula di Bayes per calcolare la distribuzione a posteriori \\(p(\\theta \\mid y)\\):\n\\[\np(\\theta \\mid y) = \\frac{p(y \\mid \\theta) p(\\theta)}{p(y)},\n\\]\ndove:\n\n\\(p(\\theta \\mid y)\\): la distribuzione a posteriori rappresenta la nostra conoscenza aggiornata su \\(\\theta\\) dopo aver osservato i dati.\n\\(p(y \\mid \\theta)\\): la verosimiglianza √® la probabilit√† di osservare i dati dati i parametri del modello.\n\\(p(\\theta)\\): la distribuzione a priori rappresenta la conoscenza iniziale su \\(\\theta\\).\n\n\\(p(y)\\): l‚Äôevidenza √® la probabilit√† totale dei dati osservati, calcolata come:\n\\[\np(y) = \\int p(y \\mid \\theta) p(\\theta) \\, d\\theta.\n\\]\n\n\n\n56.2.1 Previsione di Nuovi Dati\n\nQuando vogliamo prevedere un nuovo dato, indicato con \\(\\tilde{y}\\), la nostra attenzione si sposta sulla distribuzione predittiva a posteriori, \\(p(\\tilde{y} \\mid y)\\).\n\n56.2.1.1 Cosa rappresenta \\(\\tilde{y}\\)?\n\n\n\\(\\tilde{y}\\) rappresenta un dato futuro o non osservato. Ad esempio, se i dati \\(y\\) rappresentano il numero di successi osservati in una serie di lanci di una moneta, \\(\\tilde{y}\\) potrebbe rappresentare il numero di successi in una nuova serie di lanci.\nL‚Äôobiettivo √® stimare \\(p(\\tilde{y} \\mid y)\\), cio√® la probabilit√† del nuovo dato \\(\\tilde{y}\\) dato ci√≤ che abbiamo osservato in \\(y\\).\n\n56.2.1.2 Cosa rappresenta \\(p(\\tilde{y} \\mid \\theta)\\)?\n\n\n\\(p(\\tilde{y} \\mid \\theta)\\) √® la probabilit√† del nuovo dato \\(\\tilde{y}\\) dato un particolare valore del parametro \\(\\theta\\).\nAd esempio, in un modello binomiale, \\(p(\\tilde{y} \\mid \\theta)\\) corrisponde alla probabilit√† di ottenere \\(\\tilde{y}\\) successi su \\(n_{\\text{new}}\\) prove, data la probabilit√† di successo \\(\\theta\\).\n\n56.2.1.3 Combinazione di \\(p(\\tilde{y} \\mid \\theta)\\) con \\(p(\\theta \\mid y)\\)\n\nPoich√© non conosciamo esattamente \\(\\theta\\), dobbiamo considerare tutte le possibili ipotesi su \\(\\theta\\), pesandole in base alla loro probabilit√† a posteriori \\(p(\\theta \\mid y)\\). Questo porta alla formula per la distribuzione predittiva a posteriori:\n\\[\np(\\tilde{y} \\mid y) = \\int p(\\tilde{y} \\mid \\theta) p(\\theta \\mid y) \\, d\\theta.\n\\]\n\n56.2.1.4 Interpretazione\n\nLa distribuzione predittiva a posteriori, \\(p(\\tilde{y} \\mid y)\\), rappresenta la nostra miglior stima della probabilit√† del nuovo dato \\(\\tilde{y}\\), tenendo conto sia dei dati osservati \\(y\\) sia dell‚Äôincertezza su \\(\\theta\\).\n\n56.2.2 Caso Discreto\nSe il parametro \\(\\theta\\) assume un numero finito di valori, l‚Äôintegrale si semplifica in una somma:\n\\[\np(\\tilde{y} \\mid y) = \\sum_{\\theta} p(\\tilde{y} \\mid \\theta) p(\\theta \\mid y).\n\\]\nQuesto approccio √® utile nei modelli discreti o quando si approssimano i parametri con un numero finito di valori campionati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>56</span>¬† <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/13_post_pred_distr.html#il-caso-beta-binomiale",
    "href": "chapters/bayesian_inference/13_post_pred_distr.html#il-caso-beta-binomiale",
    "title": "56¬† Distribuzione predittiva a posteriori",
    "section": "\n56.3 Il Caso Beta-Binomiale",
    "text": "56.3 Il Caso Beta-Binomiale\nConsideriamo un classico esperimento binomiale: lanciare una moneta \\(n\\) volte e osservare il numero di successi \\(y\\) (ad esempio, il numero di ‚Äúteste‚Äù). In un contesto bayesiano, il processo di analisi si articola in tre fasi:\n\n\nDistribuzione a Priori: Prima di osservare i dati, formuliamo una distribuzione a priori sulla probabilit√† \\(p\\) di successo, che riflette le nostre conoscenze iniziali (o la loro assenza). Una scelta comune √® la distribuzione Beta(\\(\\alpha, \\beta\\)), perch√© √® flessibile e ben definita per probabilit√†. Per esempio:\n\n\n\\(\\alpha\\) rappresenta il numero ‚Äúfittizio‚Äù di successi osservati.\n\n\\(\\beta\\) rappresenta il numero ‚Äúfittizio‚Äù di insuccessi osservati.\n\n\n\nDistribuzione a Posteriori: Dopo aver osservato \\(y\\) successi su \\(n\\) prove, aggiorniamo la distribuzione a priori combinandola con i dati osservati, ottenendo la distribuzione a posteriori di \\(p\\):\n\\[\n\\alpha_{\\text{post}} = \\alpha_{\\text{prior}} + y, \\quad \\beta_{\\text{post}} = \\beta_{\\text{prior}} + (n - y).\n\\]\nQuesta distribuzione rappresenta ci√≤ che sappiamo di \\(p\\) dopo aver osservato i dati.\n\n\nDistribuzione Predittiva a Posteriori: Per prevedere il numero di successi futuri \\(y_{\\text{new}}\\) in un nuovo esperimento con \\(n_{\\text{new}}\\) prove, combiniamo la distribuzione a posteriori di \\(p\\) con la variabilit√† intrinseca del processo binomiale. In pratica:\n\nCampioniamo \\(p\\) dalla distribuzione a posteriori (\\(p \\sim \\text{Beta}(\\alpha_{\\text{post}}, \\beta_{\\text{post}})\\)).\nUsiamo ciascun campione di \\(p\\) per simulare nuovi dati (\\(y_{\\text{new}} \\sim \\text{Binomiale}(n_{\\text{new}}, p)\\)).\n\n\n\nQuesto processo tiene conto sia dell‚Äôincertezza sui parametri (\\(p\\)) sia della variabilit√† intrinseca nei dati futuri.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>56</span>¬† <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/13_post_pred_distr.html#simulazione-della-distribuzione-predittiva-a-posteriori",
    "href": "chapters/bayesian_inference/13_post_pred_distr.html#simulazione-della-distribuzione-predittiva-a-posteriori",
    "title": "56¬† Distribuzione predittiva a posteriori",
    "section": "\n56.4 Simulazione della Distribuzione Predittiva a Posteriori",
    "text": "56.4 Simulazione della Distribuzione Predittiva a Posteriori\n\n56.4.1 Impostazione dei Parametri\n\nSupponiamo di aver osservato \\(y = 70\\) successi su \\(n = 100\\) prove.\nUtilizziamo una distribuzione a priori Beta(\\(2, 2\\)), che rappresenta una conoscenza iniziale debolmente informativa, con una leggera preferenza per \\(p \\approx 0.5\\).\n\n56.4.2 Calcolo della Distribuzione a Posteriori\n\n\nAggiorniamo la distribuzione a priori con i dati osservati. I parametri aggiornati sono:\n\\[\n\\alpha_{\\text{post}} = \\alpha_{\\text{prior}} + y = 2 + 70 = 72, \\quad \\beta_{\\text{post}} = \\beta_{\\text{prior}} + (n - y) = 2 + 30 = 32.\n\\]\n\nLa distribuzione a posteriori √® quindi \\(p \\sim \\text{Beta}(72, 32)\\), che descrive la probabilit√† aggiornata di successo basata sui dati.\n\n56.4.3 Simulazione dei Dati Futuri\n\nGeneriamo \\(n_{\\text{sim}} = 1000\\) campioni di \\(p\\) dalla distribuzione a posteriori Beta(72, 32).\n\nPer ogni campione di \\(p\\), simuliamo \\(y_{\\text{new}}\\), il numero di successi futuri su \\(n_{\\text{new}} = 10\\) prove, utilizzando la distribuzione binomiale:\n\\[\ny_{\\text{new}} \\sim \\text{Binomiale}(n_{\\text{new}} = 10, p).\n\\]\n\n\nInfine, convertiamo \\(y_{\\text{new}}\\) in proporzioni predette:\n\\[\n\\text{Proporzione predetta} = \\frac{y_{\\text{new}}}{n_{\\text{new}}}.\n\\]\n\n\n\n# Impostazione del seed per riproducibilit√†\nset.seed(123)\n\n# Parametri osservati\ny &lt;- 70\nn &lt;- 100\n\n# Parametri a priori\nalpha_prior &lt;- 2\nbeta_prior &lt;- 2\n\n# Calcolo dei parametri a posteriori\nalpha_post &lt;- alpha_prior + y\nbeta_post &lt;- beta_prior + (n - y)\n\n# Simulazione della distribuzione a posteriori\np_samples &lt;- rbeta(1000, alpha_post, beta_post)\n\n# Simulazione di nuovi dati per n_new = 10\ny_preds &lt;- sapply(p_samples, function(p) {\n  rbinom(1, 10, p)\n})\n\n# Calcolo delle proporzioni predette\nprop_preds &lt;- y_preds / 10\n\n\n56.4.4 Risultati Attesi\n\n\nDistribuzione a Posteriori di \\(p\\):\n\nCentrata attorno a \\(0.7\\), con una varianza ridotta grazie alla dimensione del campione \\(n = 100\\).\n\n\n\nDistribuzione Predittiva per \\(n_{\\text{new}} = 10\\):\n\nVariabilit√† pi√π ampia rispetto a \\(p\\), dovuta al numero ridotto di prove (\\(n_{\\text{new}} = 10\\)).\nRiflette sia l‚Äôincertezza su \\(p\\) sia la variabilit√† intrinseca dei dati futuri.\n\n\n\n\n# Visualizzazione\npar(mfrow = c(1, 2))\ncurve(dbeta(x, alpha_prior, beta_prior), from = 0, to = 1, \n      main = \"Distribuzione a Priori\", col = \"blue\", lwd = 2)\ncurve(dbeta(x, alpha_post, beta_post), from = 0, to = 1, \n      main = \"Distribuzione a Posteriori\", col = \"red\", lwd = 2)\n\n\n\n\n\n\n\n\nhist(prop_preds, breaks = 20, col = \"lightblue\", freq = FALSE,\n     main = \"Distribuzione Predittiva (n_new = 10)\",\n     xlab = \"Proporzione di Successi\")\nabline(v = y / n, col = \"blue\", lwd = 3, lty = 2)\n\n\n\n\n\n\n\n\n56.4.5 Spiegazione del Codice\nSimulazione di nuovi dati per \\(n_{\\text{new}} = 10\\):\ny_preds &lt;- sapply(p_samples, function(p) {\n  rbinom(1, 10, p)\n})\n\n\np_samples contiene \\(1000\\) valori di \\(p\\) simulati dalla distribuzione Beta(72, 32).\nPer ciascun \\(p\\), rbinom(1, 10, p) genera un valore di \\(y_{\\text{new}}\\), simulando il numero di successi futuri su \\(n_{\\text{new}} = 10\\) prove.\n\nRisultato: un vettore di 1000 valori di \\(y_{\\text{new}}\\), uno per ciascun campione di \\(p\\).\nCalcolo delle proporzioni predette:\nprop_preds &lt;- y_preds / 10\n\nDivide ciascun valore di \\(y_{\\text{new}}\\) per \\(n_{\\text{new}} = 10\\), ottenendo le proporzioni di successi predette.\n\nRisultato: un vettore di 1000 proporzioni predette (\\(y_{\\text{new}} / n_{\\text{new}}\\)).\n\n56.4.6 Interpretazione\n\nLa distribuzione a posteriori di \\(p\\), Beta(72, 32), √® centrata attorno a \\(p \\approx 0.7\\), coerente con i dati osservati (\\(y / n = 0.7\\)).\nLe proporzioni predette mostrano la variabilit√† combinata dell‚Äôincertezza su \\(p\\) (dalla distribuzione a posteriori) e della variabilit√† binomiale per un campione futuro di 10 prove.\nL‚Äôistogramma delle proporzioni predette √® pi√π ampio rispetto alla distribuzione a posteriori di \\(p\\), riflettendo l‚Äôincertezza aggiuntiva derivante dal numero ridotto di prove (\\(n_{\\text{new}} = 10\\)).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>56</span>¬† <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/13_post_pred_distr.html#posterior-predictive-check-pp-check",
    "href": "chapters/bayesian_inference/13_post_pred_distr.html#posterior-predictive-check-pp-check",
    "title": "56¬† Distribuzione predittiva a posteriori",
    "section": "\n56.5 Posterior Predictive Check (PP-Check)",
    "text": "56.5 Posterior Predictive Check (PP-Check)\nLa distribuzione predittiva a posteriori ottenuta dalla simulazione (\\(n_{\\text{new}} = 10\\)) pu√≤ essere utilizzata per effettuare un Posterior Predictive Check (PP-Check). Questo controllo confronta i dati osservati con i dati simulati dal modello per verificare se il modello √® in grado di riprodurre caratteristiche rilevanti dei dati osservati.\nIn questa simulazione, il Posterior Predictive-Check suggerisce che il modello √® ben specificato per i dati osservati (\\(y = 70\\), \\(n = 100\\)): la proporzione osservata (\\(0.7\\)) √® vicina al centro della distribuzione predittiva. Questo significa che il modello pu√≤ essere considerato valido per fare previsioni sui dati futuri, almeno nel contesto specificato.\n\n\n\n\n\n\nIl fatto che la distribuzione predittiva a posteriori rappresenti accuratamente la proporzione osservata pu√≤ sembrare ovvio nel caso presente. Questo avviene perch√© stiamo lavorando con un modello semplice e ben specificato, utilizzato qui con l‚Äôintento di chiarire la logica del concetto di distribuzione predittiva a posteriori. Tuttavia, nei modelli pi√π complessi, tipici delle indagini psicologiche, la corrispondenza tra i dati osservati e quelli predetti dal modello non pu√≤ mai essere data per scontata. √à essenziale verificarla attraverso la distribuzione predittiva a posteriori.\nSe i dati osservati non sono ben rappresentati dalla distribuzione predittiva a posteriori, ci√≤ indica che il modello non √® adeguato a spiegare i dati e necessita di revisione. Questo processo di verifica non solo garantisce la coerenza del modello con i dati disponibili, ma consente anche di identificare eventuali aree problematiche nella specificazione del modello, come prior inappropriati o assunzioni non realistiche. In definitiva, il confronto tra i dati osservati e quelli predetti √® un passo fondamentale per la validazione di modelli complessi in contesti psicologici e scientifici.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>56</span>¬† <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/13_post_pred_distr.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/13_post_pred_distr.html#riflessioni-conclusive",
    "title": "56¬† Distribuzione predittiva a posteriori",
    "section": "\n56.6 Riflessioni Conclusive",
    "text": "56.6 Riflessioni Conclusive\nLa distribuzione predittiva a posteriori √® uno strumento centrale nell‚Äôinferenza bayesiana, poich√© consente di fare previsioni sui dati futuri integrando l‚Äôincertezza sui parametri del modello con la variabilit√† intrinseca del processo generativo. Questa capacit√† va oltre la semplice stima dei parametri, permettendo di confrontare le previsioni del modello con i dati reali, un passaggio fondamentale per verificare la coerenza e l‚Äôutilit√† del modello stesso.\nNel flusso di lavoro bayesiano, la distribuzione predittiva a posteriori svolge un ruolo chiave nella valutazione del modello. Ad esempio, consente di effettuare controlli predittivi a posteriori per identificare discrepanze tra i dati osservati e quelli previsti. Tali controlli aiutano a diagnosticare problemi di specificazione del modello, a valutare l‚Äôadeguatezza delle scelte a priori e a guidare eventuali revisioni del modello.\nInoltre, il caso beta-binomiale utilizzato in questo capitolo rappresenta un esempio intuitivo e potente: evidenzia come l‚Äôincertezza sui parametri possa essere tradotta in previsioni probabilistiche robuste, senza la necessit√† di fare assunzioni rigide o non realistiche. Questo approccio non solo formalizza l‚Äôincertezza in modo rigoroso, ma permette anche di comunicare le previsioni in modo trasparente e interpretabile, caratteristiche essenziali in ambito decisionale e scientifico.\nIn sintesi, la distribuzione predittiva a posteriori √® un elemento fondamentale della modellazione bayesiana, che lega l‚Äôinferenza paramatrica alla previsione empirica, contribuendo a rendere l‚Äôintero processo inferenziale pi√π affidabile, interpretabile e applicabile a scenari complessi.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>56</span>¬† <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/13_post_pred_distr.html#esercizi",
    "href": "chapters/bayesian_inference/13_post_pred_distr.html#esercizi",
    "title": "56¬† Distribuzione predittiva a posteriori",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nConsideriamo i dati della SWLS somministrata a un campione di studenti, ottenendo per ciascuno uno score complessivo. Per semplicit√†, vogliamo ‚Äúdichiarare positivo‚Äù lo studente se il punteggio SWLS supera una determinata soglia (ad esempio, 20 su 35). In questo modo otteniamo una variabile dicotomica (0/1), che useremo come ‚Äúsuccesso‚Äù in un modello binomiale.\n\n\nDati e conteggio dei successi\n\nCarica il dataset con le risposte SWLS.\n\nCostruisci la variabile binaria (ad esempio SWLS_dich) che vale 1 se lo score ‚â• 20, e 0 altrimenti.\n\nCalcola il numero di successi (numero di persone che superano la soglia) e il numero totale di osservazioni (N).\n\n\n\nModello beta-binomiale (approccio manuale via simulazione)\n\n\nSpecifica una distribuzione Beta(a, b) come prior per la probabilit√† di successo \\(p\\). Scegli una coppia \\((a, b)\\) relativamente poco informativa, ad esempio (2,2) o (1,1).\n\nOsservando \\(y\\) successi su \\(n\\) soggetti, aggiorna i parametri a posteriori: \\[\n  a_{\\text{post}} = a + y,\n  \\quad\n  b_{\\text{post}} = b + (n - y).\n\\]\n\nSimula un gran numero di campioni di \\(p\\) dalla distribuzione Beta\\(\\bigl(a_{\\text{post}},\\, b_{\\text{post}}\\bigr)\\).\n\nPer ciascun campione di \\(p\\), genera un valore \\(\\tilde{y}\\) da una Binomiale\\(\\bigl(n_{\\text{new}}, p\\bigr)\\), dove \\(n_{\\text{new}}\\) √® la dimensione di un ipotetico nuovo campione (che puoi scegliere, ad esempio, uguale a \\(n\\) oppure un valore diverso). Otterrai cos√¨ una posterior predictive distribution per \\(\\tilde{y}\\).\n\nInfine, calcola statistiche descrittive (media, varianza, intervalli) e/o disegna un istogramma di \\(\\tilde{y}\\) o della proporzione \\(\\tilde{y}/n_{\\text{new}}\\).\n\n\n\nReplicare con brms\n\n\nUsa il pacchetto brms per costruire un modello binomiale. Per esempio:\nlibrary(brms)\n\n# Crea un data frame con la variabile dicotomica\ndf_binom &lt;- data.frame(\n  successes = y,    # conteggio dei successi\n  failures  = n - y\n)\n\n# Modello binomiale con prior Beta(a,b) approssimato tramite logit\nfit_brms &lt;- brm(\n  bf(successes | trials(n) ~ 1), \n  data = df_binom,\n  family = binomial(link = \"logit\"),\n  prior = c(\n    prior(beta(2, 2), class = \"Intercept\", dpar = \"mu\") \n    # NOTA: la specifica di una \"beta(2,2)\" diretta sull'intercetta\n    # √® un'approssimazione, tipicamente serve passare a una scala logit.\n    # In brms, di solito si usa prior su scale normali dell'intercetta.\n  ),\n  seed = 123\n)\n(Le specifiche del prior potrebbero richiedere una formulazione differente se vuoi rispettare esattamente la corrispondenza con Beta(a,b). In ogni caso, l‚Äôidea √® mostrare come definire un prior e costruire un modello binomiale con brms.)\n\n\nVerifica la convergenza e poi estrai la posterior predictive distribution con le funzioni di brms:\npp_check(fit_brms, nsamples = 100)\nQuesto ti mostrer√† come i dati predetti dal modello (in termini di binomiale) si confrontano con i dati osservati.\n\n\n\n\nConfronto e interpretazione\n\nMetti a confronto i risultati della simulazione ‚Äúmanuale‚Äù (Beta-Binomial) e quelli ottenuti con brms. Noterai che le distribuzioni predittive dovrebbero essere coerenti, se hai impostato un prior per brms simile a quello del modello Beta-Binomiale.\n\nDiscuti brevemente se la distribuzione predittiva a posteriori acquisita √® plausibile rispetto ai dati osservati. Ad esempio, la probabilit√† di osservare \\(\\tilde{y}\\) simile a \\(y\\) dovrebbe essere relativamente alta se il modello √® appropriato.\n\nSe vuoi, puoi cambiare \\(n_{\\text{new}}\\) (es. previsione su 200 soggetti futuri) per vedere come la variabilit√† della previsione si ‚Äúridimensiona‚Äù o cresce a seconda della taglia del campione.\n\n\n\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n\n\nCostruzione del dataset\n\n\nSe la SWLS varia tra 5 e 35, e la soglia √® 20, puoi fare:\ndf$SWLS_dich &lt;- ifelse(df$SWLS_score &gt;= 20, 1, 0)\ny &lt;- sum(df$SWLS_dich)\nn &lt;- nrow(df)\n\n\n\n\nApproccio Beta-Binomial manuale\n\nPrior: \\((a, b) = (2, 2)\\)\nPosterior: \\((a_{\\text{post}}, b_{\\text{post}}) = (2 + y,\\, 2 + n - y)\\).\n\nGenerazione dei campioni:\nN_sim &lt;- 2000\np_post &lt;- rbeta(N_sim, a_post, b_post)\ny_pred &lt;- rbinom(N_sim, size = n_new, prob = p_post)\n\n# Se preferisci la proporzione futura:\nprop_pred &lt;- y_pred / n_new\n\n\nStatistiche:\nmean_p &lt;- mean(p_post) # media a posteriori di p\nquantile_p &lt;- quantile(p_post, c(0.025, 0.975))  \n\nmean_prop_pred &lt;- mean(prop_pred)\nquantile_prop_pred &lt;- quantile(prop_pred, c(0.025, 0.975))\n\n\nGrafici (istogramma e densit√†):\nhist(prop_pred, freq=FALSE, col='lightblue',\n     main='Posterior Predictive Distribution: prop. di successi')\n\n\n\n\nModello con brms\n\nUsa la sintassi di una binomiale con offset o con trials(n).\n\nSpecifica un prior che approssimi Beta(2,2) sullo scale logit, ad esempio:\n# Beta(2,2) ha media ~ 0.5, varianza relativamente ampia.\n# Approssimandola su scala logit ~ normal(0, 2.2) \n# (valore indicativo: la normal(0, 2) su logit copre un intervallo ampio).\n\nprior_approx &lt;- prior(normal(0, 2), class = \"Intercept\")\n\nEsegui pp_check(fit_brms) e interpreta.\n\n\n\nInterpretazione\n\nSe la soglia scelta per la SWLS cattura un ‚Äúbuon livello di soddisfazione‚Äù, potresti aspettarti una certa % di successi.\n\nSe i dati futuri simulati sono coerenti con i dati reali ‚Äî ad esempio, la media di \\(\\tilde{y}\\) √® vicina a \\(y\\) ‚Äî allora il modello sembra descrivere bene la realt√†. Altrimenti, potresti rivedere la soglia o la specifica del prior.\n\n\n\nL‚Äôelemento chiave √® che la distribuzione predittiva a posteriori (posterior predictive distribution) non si limita a considerare un solo valore di \\(p\\), bens√¨ campiona molteplici valori plausibili (dalla posterior), e per ciascuno simula un potenziale outcome. Cos√¨ facendo, si riflette pienamente l‚Äôincertezza residua sul parametro e l‚Äôaleatoriet√† del processo binomiale.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>56</span>¬† <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/13_post_pred_distr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/13_post_pred_distr.html#informazioni-sullambiente-di-sviluppo",
    "title": "56¬† Distribuzione predittiva a posteriori",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.5.3     \n#&gt;  [9] scales_1.3.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.9.1   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         rlang_1.1.5       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       tools_4.4.2       parallel_4.4.2    tzdb_0.5.0       \n#&gt; [21] colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5       R6_2.6.1         \n#&gt; [25] lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.1    \n#&gt; [29] gtable_0.3.6      glue_1.8.0        xfun_0.51         tidyselect_1.2.1 \n#&gt; [33] rstudioapi_0.17.1 farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-167     \n#&gt; [37] rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>56</span>¬† <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/13_post_pred_distr.html#bibliografia",
    "href": "chapters/bayesian_inference/13_post_pred_distr.html#bibliografia",
    "title": "56¬† Distribuzione predittiva a posteriori",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nSchoot, R. van de, Depaoli, S., King, R., Kramer, B., M√§rtens, K., Tadesse, M. G., Vannucci, M., Gelman, A., Veen, D., Willemsen, J., et al. (2021). Bayesian statistics and modelling. Nature Reviews Methods Primers, 1(1), 1.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>56</span>¬† <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/introduction_mcmc.html",
    "href": "chapters/mcmc/introduction_mcmc.html",
    "title": "Introduzione",
    "section": "",
    "text": "In questa sezione della dispensa, ci concentreremo sulle procedure Monte Carlo a catena di Markov, con particolare attenzione all‚Äôalgoritmo di Metropolis, che consente di approssimare la distribuzione a posteriori quando non √® possibile ottenere una soluzione analitica. Esploreremo il concetto di predizione bayesiana, fondamentale per la costruzione della distribuzione predittiva a posteriori, e discuteremo anche la distribuzione predittiva a priori. Applicheremo l‚Äôinferenza bayesiana a diversi contesti, tra cui la stima di una proporzione, il confronto tra due proporzioni, la stima di una media da una distribuzione normale e il confronto tra due medie. Esamineremo inoltre il modello bayesiano di Poisson per l‚Äôanalisi delle frequenze. Infine, introdurremo il modello gerarchico bayesiano, uno strumento potente per affrontare situazioni in cui le osservazioni sono strutturate su diversi livelli di incertezza.",
    "crumbs": [
      "MCMC",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html",
    "href": "chapters/mcmc/01_metropolis.html",
    "title": "57¬† L‚Äôalgoritmo di Metropolis-Hastings",
    "section": "",
    "text": "57.1 Introduzione\nIn precedenza, abbiamo esplorato diversi esempi di inferenza bayesiana riguardanti la distribuzione a posteriori di un singolo parametro, come nel caso del modello bernoulliano. Abbiamo anche trattato metodi come l‚Äôapprossimazione tramite griglia e l‚Äôutilizzo dei priori coniugati per ottenere o approssimare la distribuzione a posteriori. In questo capitolo, ci concentreremo sul metodo di simulazione Monte Carlo a Catena di Markov (MCMC).\nIl metodo MCMC √® una tecnica computazionale utilizzata per approssimare distribuzioni di probabilit√† complesse, generando una sequenza di campioni (correlati) attraverso una catena di Markov, in cui ogni campione viene ottenuto tramite una transizione iterativa con probabilit√† attentamente progettate.\nIl metodo MCMC rappresenta l‚Äôapproccio moderno per approssimare distribuzioni a posteriori complesse. L‚Äôidea di base √® simile al concetto di considerare la distribuzione a posteriori come una popolazione da cui estraiamo campioni ripetutamente. Con un numero sufficientemente grande di campioni (ad esempio 1000), la distribuzione del campione si avvicina molto alla distribuzione della popolazione, consentendo stime affidabili dei parametri incogniti.\nUna differenza rispetto all‚Äôanalogia precedente √® che i campioni generati con MCMC sono correlati: se il primo campione ha un valore alto, anche il successivo ha maggiori probabilit√† di essere alto. Questo accade perch√© non abbiamo un modo diretto per estrarre campioni dalla distribuzione a posteriori, che spesso ha una forma molto complessa; utilizziamo invece algoritmi che ci permettono di arrivarci indirettamente. La correlazione tra i campioni non rappresenta un problema rilevante, ma rende necessario estrarre un numero maggiore di campioni per compensare questa correlazione e ottenere stime accurate.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>57</span>¬† <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#il-denominatore-bayesiano",
    "href": "chapters/mcmc/01_metropolis.html#il-denominatore-bayesiano",
    "title": "57¬† L‚Äôalgoritmo di Metropolis-Hastings",
    "section": "\n57.2 Il denominatore bayesiano",
    "text": "57.2 Il denominatore bayesiano\nNell‚Äôapproccio bayesiano, l‚Äôobiettivo principale √® determinare la distribuzione a posteriori \\(p(\\theta \\mid y)\\) di un parametro \\(\\theta\\), utilizzando i dati osservati \\(y\\) e la distribuzione a priori \\(p(\\theta)\\). Questo si ottiene attraverso il teorema di Bayes:\n\\[\np(\\theta \\mid y) = \\frac{p(y \\mid \\theta) p(\\theta)}{\\int p(y \\mid \\theta) p(\\theta) d\\theta}.\n\\]\nIl denominatore \\(\\int p(y \\mid \\theta) p(\\theta) d\\theta\\) rappresenta la probabilit√† marginale di \\(y\\), chiamata evidenza. Tale integrale garantisce che \\(p(\\theta \\mid y)\\) sia una distribuzione di probabilit√† valida. Tuttavia, il calcolo di questo integrale √® spesso complesso, soprattutto in modelli articolati o ad alta dimensionalit√†, rendendo difficile ottenere una rappresentazione esplicita della distribuzione a posteriori.\nUna possibile semplificazione analitica √® l‚Äôuso di distribuzioni a priori coniugate, che offrono una soluzione esatta per la distribuzione a posteriori. Tuttavia, questo approccio √® limitato a casi specifici e impone forti vincoli sulla scelta delle distribuzioni a priori e delle verosimiglianze.\nUn approccio pi√π generale √® ricorrere a soluzioni numeriche. In precedenza abbiamo discusso il metodo di campionamento a griglia. Tuttavia, i metodi di campionamento a griglia, sebbene efficaci per modelli con pochi parametri, diventano impraticabili man mano che il numero di parametri aumenta, poich√© richiedono una copertura densa dell‚Äôintero spazio parametrico. Di conseguenza, per modelli pi√π complessi e con pi√π parametri, si rende necessario un metodo che possa esplorare lo spazio dei parametri in maniera pi√π efficiente.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>57</span>¬† <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#il-metodo-monte-carlo-e-le-sue-limitazioni",
    "href": "chapters/mcmc/01_metropolis.html#il-metodo-monte-carlo-e-le-sue-limitazioni",
    "title": "57¬† L‚Äôalgoritmo di Metropolis-Hastings",
    "section": "\n57.3 Il metodo Monte Carlo e le sue limitazioni",
    "text": "57.3 Il metodo Monte Carlo e le sue limitazioni\nIl metodo Monte Carlo fornisce una soluzione a questo problema generando campioni casuali dalla distribuzione a posteriori \\(p(\\theta \\mid y)\\). L‚Äôidea centrale √® semplice: se possiamo generare un numero sufficiente di campioni casuali dalla distribuzione a posteriori, possiamo usare questi campioni per stimare le propriet√† d‚Äôinteresse, come la media o la varianza del parametro \\(\\theta\\). Questa procedura ci permette di evitare il calcolo diretto dell‚Äôintegrale complicato nel denominatore del teorema di Bayes.\nPer esempio, se fossimo in grado di generare una serie di campioni \\(\\theta^{(1)}, \\theta^{(2)}, \\dots, \\theta^{(T)}\\) dalla distribuzione a posteriori, potremmo approssimare il valore atteso di \\(\\theta\\) con la media campionaria:\n\\[\n\\mathbb{E}[\\theta] \\approx \\frac{1}{T} \\sum_{t=1}^T \\theta^{(t)}.\n\\]\nTuttavia, un problema nei metodi Monte Carlo tradizionali √® che generare campioni indipendenti dalla distribuzione a posteriori non √® semplice, soprattutto quando questa distribuzione ha una forma complessa, √® multimodale o definita su spazi di alta dimensionalit√†. Le regioni di alta densit√†, che contribuiscono maggiormente al valore dell‚Äôintegrale, possono essere difficili da individuare e campionare adeguatamente. Per ottenere una buona copertura dello spazio dei parametri, sarebbe necessario generare un numero enorme di campioni, rendendo il metodo Monte Carlo inefficiente e computazionalmente oneroso.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>57</span>¬† <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#perch√©-i-metodi-mcmc-sono-necessari",
    "href": "chapters/mcmc/01_metropolis.html#perch√©-i-metodi-mcmc-sono-necessari",
    "title": "57¬† L‚Äôalgoritmo di Metropolis-Hastings",
    "section": "\n57.4 Perch√© i metodi MCMC sono necessari",
    "text": "57.4 Perch√© i metodi MCMC sono necessari\n√à qui che entrano in gioco i Metodi Monte Carlo a Catena di Markov (MCMC). Questi metodi risolvono il problema generando campioni dipendenti dalla distribuzione a posteriori, sfruttando la struttura di una catena di Markov. A differenza dei campioni indipendenti utilizzati nei metodi Monte Carlo tradizionali, i metodi MCMC costruiscono una sequenza di campioni, in cui ciascun campione dipende dal precedente. Questa dipendenza permette di esplorare in modo pi√π efficiente le regioni di alta densit√† della distribuzione a posteriori, riducendo il numero di campioni necessari per ottenere stime accurate.\nIn pratica, MCMC consente di evitare di campionare inutilmente da regioni di bassa densit√†, concentrandosi invece sulle aree pi√π rilevanti della distribuzione. Questo approccio √® particolarmente potente nei contesti ad alta dimensionalit√† o in presenza di distribuzioni multimodali, dove i metodi Monte Carlo tradizionali risulterebbero inefficaci o richiederebbero un numero sproporzionato di campioni.\nIn sintesi, i metodi Monte Carlo classici sono limitati quando si tratta di campionare da distribuzioni complesse e multidimensionali. I metodi MCMC, invece, offrono una soluzione efficiente e flessibile, permettendo di esplorare le distribuzioni a posteriori anche in contesti complessi, senza la necessit√† di campionare indipendentemente ogni punto. Nel prossimo paragrafo introdurremo i concetti fondamentali delle catene di Markov e vedremo come queste vengono utilizzate nei metodi MCMC per campionare efficacemente da distribuzioni a posteriori difficili da trattare analiticamente.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>57</span>¬† <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#le-catene-di-markov",
    "href": "chapters/mcmc/01_metropolis.html#le-catene-di-markov",
    "title": "57¬† L‚Äôalgoritmo di Metropolis-Hastings",
    "section": "\n57.5 Le Catene di Markov",
    "text": "57.5 Le Catene di Markov\nLe catene di Markov, introdotte da Andrey Markov nel 1906, rappresentano un‚Äôestensione della legge dei grandi numeri per descrivere sequenze di variabili casuali non indipendenti. Nella statistica tradizionale, si lavora spesso con sequenze di variabili casuali indipendenti e identicamente distribuite (i.i.d.), come \\(X_0, X_1, \\ldots, X_n, \\ldots\\), dove ogni variabile √® indipendente dalle altre e segue la stessa distribuzione. Tuttavia, nei modelli pi√π realistici che descrivono fenomeni complessi, l‚Äôindipendenza tra variabili √® un‚Äôassunzione troppo rigida e spesso irrealistica.\nLe catene di Markov superano questo limite introducendo una dipendenza locale, detta dipendenza a un passo, formalizzata nella cosiddetta propriet√† di Markov. Secondo questa propriet√†, il valore futuro di una variabile casuale \\(X_{n+1}\\) dipende unicamente dal valore attuale \\(X_n\\), ignorando tutta la storia precedente della catena. Questo permette di semplificare notevolmente i calcoli relativi alle probabilit√† condizionali. La propriet√† di Markov √® formalmente espressa come:\n\\[\nP(X_{n+1} = j | X_n = i, X_{n-1} = i_{n-1}, \\ldots, X_0 = i_0) = P(X_{n+1} = j | X_n = i).\n\\]\nIn altre parole, la previsione di un evento futuro dipende soltanto dallo stato attuale e non da tutti gli eventi precedenti, semplificando cos√¨ il processo di modellazione. Questa caratteristica rende le catene di Markov particolarmente utili per descrivere sistemi dinamici in cui gli eventi successivi sono influenzati solo dallo stato immediatamente precedente.\n\n57.5.1 Catene di Markov e Metodi MCMC\nLe catene di Markov sono fondamentali nei metodi Monte Carlo a Catena di Markov (MCMC) perch√© forniscono un modo efficiente per generare sequenze di campioni che approssimano distribuzioni di probabilit√† complesse. Mentre i metodi Monte Carlo classici generano campioni indipendenti, i metodi MCMC costruiscono una sequenza di campioni dipendenti attraverso una catena di Markov, in cui ciascun campione √® ottenuto in base al campione precedente. Questo approccio consente di concentrarsi sulle regioni di alta probabilit√† della distribuzione, migliorando l‚Äôefficienza del campionamento.\nPer esempio, consideriamo una distribuzione di probabilit√† \\(P(x_1, x_2, ..., x_n)\\) definita su un insieme di variabili \\(x_1, x_2, ..., x_n\\). Nei metodi MCMC, si genera una sequenza di configurazioni \\(\\{x(0)\\}, \\{x(1)\\}, \\{x(2)\\}, \\dots\\), tale che la frequenza con cui ogni configurazione \\(\\{x\\}\\) viene visitata √® proporzionale alla sua probabilit√† \\(P(x)\\). In questo modo, le configurazioni pi√π probabili vengono visitate pi√π spesso, garantendo che l‚Äôalgoritmo converga alla distribuzione di interesse.\n\n57.5.2 Condizioni fondamentali per le Catene di Markov\nAffinch√© un algoritmo MCMC funzioni correttamente e converga alla distribuzione desiderata, la catena di Markov deve soddisfare alcune condizioni fondamentali:\n\n\nPropriet√† di Markov: La prossima configurazione dipende solo dalla configurazione attuale, non dalla storia passata. Questo garantisce che l‚Äôevoluzione della catena sia ‚Äúlocale‚Äù e non influenzata dagli stati remoti.\n\nIrriducibilit√†: Ogni configurazione della catena pu√≤ essere raggiunta da qualsiasi altra in un numero finito di passi. Ci√≤ assicura che l‚Äôintero spazio dei parametri possa essere esplorato.\n\nAperiodicit√†: La catena non segue cicli fissi e non ritorna sistematicamente allo stesso stato dopo un certo numero di passi. Questo garantisce che la catena possa esplorare lo spazio dei parametri in modo casuale.\n\nCondizione di bilanciamento dettagliato: La probabilit√† di passare da uno stato a un altro deve essere bilanciata dalla probabilit√† di tornare allo stato iniziale, assicurando cos√¨ che la distribuzione di equilibrio della catena sia proprio la distribuzione a posteriori desiderata.\n\n57.5.3 Algoritmi MCMC\nEsistono diversi algoritmi basati su MCMC, ognuno con caratteristiche specifiche:\n\nMetropolis-Hastings: Questo √® uno degli algoritmi pi√π noti. Si basa sulla generazione di una configurazione proposta che viene accettata o rifiutata in base a un criterio di probabilit√†. Se la configurazione proposta ha una probabilit√† pi√π alta, viene accettata; se ha una probabilit√† pi√π bassa, pu√≤ essere accettata con una certa probabilit√†, che dipende dal rapporto tra le probabilit√† delle due configurazioni.\nGibbs Sampling: In questo algoritmo, le variabili vengono aggiornate una alla volta, campionando ogni variabile dalla sua distribuzione condizionale data la configurazione corrente delle altre variabili. √à particolarmente utile quando le distribuzioni condizionali sono note o facili da campionare.\nHamiltonian Monte Carlo (HMC): Utilizza principi della meccanica hamiltoniana per esplorare lo spazio dei parametri in modo pi√π efficiente, considerando non solo le probabilit√†, ma anche le ‚Äúforze‚Äù che muovono i campioni attraverso lo spazio dei parametri. Questo approccio √® particolarmente vantaggioso per modelli complessi e ad alta dimensionalit√†, poich√© consente di generare campioni lontani dallo stato corrente senza ricorrere a piccoli passi.\n\nIn sintesi, le catene di Markov forniscono il fondamento teorico e pratico per i metodi MCMC, offrendo un modo efficiente per esplorare lo spazio dei parametri nei modelli complessi. Grazie alle propriet√† specifiche delle catene di Markov, i metodi MCMC permettono di affrontare problemi di inferenza bayesiana che sarebbero intrattabili con approcci analitici o con i metodi Monte Carlo classici. Essendo flessibili e potenti, le catene di Markov continueranno a essere uno strumento fondamentale nella statistica e nella scienza dei dati.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>57</span>¬† <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#estrazione-di-campioni-dalla-distribuzione-a-posteriori",
    "href": "chapters/mcmc/01_metropolis.html#estrazione-di-campioni-dalla-distribuzione-a-posteriori",
    "title": "57¬† L‚Äôalgoritmo di Metropolis-Hastings",
    "section": "\n57.6 Estrazione di campioni dalla distribuzione a posteriori",
    "text": "57.6 Estrazione di campioni dalla distribuzione a posteriori\nIn questo capitolo presenteremo l‚Äôalgoritmo di Metropolis, che √® uno dei pi√π semplici e potenti metodi MCMC. Sfruttando la struttura delle catene di Markov, esplora in modo efficiente lo spazio dei parametri, permettendo di ottenere campioni dalla distribuzione a posteriori anche in casi complessi, dove i metodi analitici falliscono. In sostanza, il MCMC genera un gran numero di valori per il parametro \\(\\theta\\) che, nel loro insieme, approssimano la distribuzione di interesse \\(p(\\theta \\mid y)\\). A questo fine, il capitolo √® strutturato in varie sezioni che facilitano la comprensione progressiva del tema.\n\nInizieremo discutendo di come la distribuzione a posteriori possa essere approssimata mediante tecniche di simulazione convenzionali. Questa prima parte presuppone che la distribuzione target, o ‚Äúa posteriori,‚Äù sia gi√† conosciuta o disponibile per l‚Äôanalisi.\nIn seguito, passeremo a illustrare come l‚Äôalgoritmo di Metropolis possa essere utilizzato per affrontare situazioni in cui la distribuzione a posteriori non √® direttamente nota. In questi casi, spesso abbiamo a disposizione informazioni riguardanti la distribuzione a priori e la funzione di verosimiglianza, che possono essere utilizzate per ottenere un‚Äôapprossimazione efficace della distribuzione a posteriori.\n\nA titolo esemplificativo, utilizzeremo il dataset moma_sample.csv, il quale costituisce un campione casuale di 100 artisti provenienti dal Museo di Arte Moderna di New York (MoMA) e contiene diverse informazioni relative a ciascun artista.\nIl nostro interesse √® focalizzato sulla determinazione della probabilit√† che un artista presente nel MoMA appartenga alla generazione X o a una generazione successiva (nati dopo il 1965). Questa probabilit√† sar√† indicata come \\(\\pi\\).\nImportiamo i dati.\n\nmoma_sample &lt;- rio::import(here::here(\"data\", \"moma_sample.csv\"))\n\nEsaminiamo le prime cinque righe del DataFrame.\n\nmoma_sample |&gt; \n  head()\n#&gt;                artist  country birth death alive  genx gender count\n#&gt; 1        Ad Gerritsen    dutch  1940  2015 FALSE FALSE   male     1\n#&gt; 2 Kirstine Roepstorff   danish  1972    NA  TRUE  TRUE female     3\n#&gt; 3    Lisa Baumgardner american  1958  2015 FALSE FALSE female     2\n#&gt; 4         David Bates american  1952    NA  TRUE FALSE   male     1\n#&gt; 5          Simon Levy american  1946    NA  TRUE FALSE   male     1\n#&gt; 6      Pierre Mercure canadian  1927  1966 FALSE FALSE   male     8\n#&gt;   year_acquired_min year_acquired_max\n#&gt; 1              1981              1981\n#&gt; 2              2005              2005\n#&gt; 3              2016              2016\n#&gt; 4              2001              2001\n#&gt; 5              2012              2012\n#&gt; 6              2008              2008\n\nDai dati osserviamo che solo 14 artisti su 100 appartengono alla generazione X o a una generazione successiva.\n\n# Calcoliamo la distribuzione delle generazioni\nresult &lt;- table(moma_sample$genx)\nresult\n#&gt; \n#&gt; FALSE  TRUE \n#&gt;    86    14\n\nIl valore campionato \\(y = 14\\) riflette le caratteristiche del campione che √® stato osservato. Tuttavia, poich√© il MOMA contiene opere di migliaia di artisti, sorge una domanda riguardante il vero valore di \\(\\theta\\) (la probabilit√† di appartenere alla generazione X o a una generazione successiva) all‚Äôinterno di questa popolazione.\nPossiamo interpretare i dati \\(y = 14\\) come l‚Äôesito di una variabile casuale Binomiale con parametri \\(N = 100\\) e \\(\\theta\\) sconosciuto.\nSupponiamo che le nostre credenze pregresse riguardo a \\(\\theta\\) possano essere modellate attraverso una distribuzione Beta(4, 6).\nSfruttando le propriet√† delle distribuzioni coniugate, possiamo calcolare esattamente la distribuzione a posteriori:\n# Y ~ Binomiale(100, œÄ)\n# Œ∏ ~ Beta(4, 6)\n# Posteriori: Œ∏ | (Y = 14) ~ Beta(4 + 14, 6 + 100 - 14) ‚Üí Beta(18, 92)\nNella figura seguente, √® rappresentata la distribuzione a posteriori del parametro \\(\\theta\\), insieme alla distribuzione a priori specificata.\n\n# Generiamo la sequenza dei valori per Œ∏\nx &lt;- seq(0, 1, length.out = 1000)\n\n# Calcoliamo le densit√† della prior e della posterior\nprior_density &lt;- dbeta(x, 4, 6)\nposterior_density &lt;- dbeta(x, 18, 92)\n\n# Creare un dataframe contenente i dati per il grafico\ndf &lt;- data.frame(\n  x = x,\n  prior = prior_density,\n  posterior = posterior_density\n)\n\n# Convertiamo i dati in formato \"lungo\" per facilitare la visualizzazione con ggplot2\ndf_long &lt;- reshape2::melt(df, id.vars = \"x\", \n                          measure.vars = c(\"prior\", \"posterior\"),\n                          variable.name = \"distribuzione\", value.name = \"densita\")\n\n# Creare il grafico con ggplot2\nggplot(df_long, aes(x = x, y = densita, fill = distribuzione)) +\n  geom_line(aes(color = distribuzione), size = 1) +  # Aggiungere le linee per le distribuzioni\n  geom_area(aes(fill = distribuzione), alpha = 0.5, position = \"identity\") +  # Aggiungere le aree sotto le curve\n  scale_fill_manual(\n    values = c(\"prior\" = adjustcolor(\"blue\", alpha.f = 0.5), \n               \"posterior\" = adjustcolor(\"red\", alpha.f = 0.5)),\n    labels = c(\"Prior: Beta(4, 6)\", \"Posterior: Beta(18, 92)\")\n  ) +\n  scale_color_manual(\n    values = c(\"prior\" = \"blue\", \"posterior\" = \"red\"),\n    labels = c(\"Prior: Beta(4, 6)\", \"Posterior: Beta(18, 92)\")\n  ) +\n  labs(\n    title = \"Densit√† a Priori e a Posteriori\",\n    x = \"Valore del Parametro\",\n    y = \"Densit√†\",\n    fill = NULL, color = NULL\n  ) +\n  theme(\n    plot.title = element_text(hjust = 0.5),  # Centrare il titolo\n    legend.position = \"top\"  # Posizionare la legenda in alto\n  )\n\n\n\n\n\n\n\nIn questo grafico, la curva blu rappresenta la distribuzione a priori \\(\\text{Beta}(4, 6)\\), mentre la curva rossa mostra la distribuzione a posteriori \\(\\text{Beta}(18, 92)\\). La sovrapposizione delle aree evidenzia come l‚Äôevidenza fornita dai dati modifichi la conoscenza iniziale sul parametro \\(\\theta\\).\nSe vogliamo conoscere il valore della media a posteriori di \\(\\theta\\), il risultato esatto √®\n\\[\n\\bar{\\theta}_{post} = \\frac{\\alpha}{\\alpha + \\beta} = \\frac{18}{18 + 92} \\approx 0.1636.\n\\]\n\n57.6.1 Simulazione con distribuzione target nota\nUsiamo ora una simulazione numerica per stimare la media a posteriori di \\(\\theta\\). Conoscendo la forma della distribuzione a posteriori \\(Beta(18, 92)\\), possiamo generare un campione di osservazioni casuali da questa distribuzione. Successivamente, calcoliamo la media delle osservazioni ottenute per ottenere un‚Äôapprossimazione della media a posteriori.\nSe vogliamo ottenere un risultato approssimato con un numero limitato di campioni (ad esempio, 10), possiamo utilizzare la seguente simulazione:\n\n# Generiamo 10 campioni dalla distribuzione Beta(18, 92)\nset.seed(1)  # Per riproducibilit√†\ny &lt;- rbeta(10, shape1 = 18, shape2 = 92)\ny\n#&gt;  [1] 0.1396 0.1711 0.1319 0.1774 0.1325 0.1844 0.1963 0.1517 0.2418 0.1800\n\n\n# Calcoliamo la media dei campioni\nmean(y)\n#&gt; [1] 0.1707\n\nTuttavia, con soli 10 campioni, l‚Äôapprossimazione potrebbe non essere molto accurata. Aumentando il numero di campioni, ad esempio a 10.000, possiamo ottenere una stima molto pi√π precisa:\n\n# Generiamo 10.000 campioni e calcoliamo la media\nset.seed(123)  # Per riproducibilit√†\nmean(rbeta(10000, shape1 = 18, shape2 = 92))\n#&gt; [1] 0.1637\n\nQuando il numero di campioni dalla distribuzione a posteriori diventa molto grande, la media campionaria converge al valore atteso della distribuzione della popolazione. Questo principio non si applica solo alla media, ma anche ad altre statistiche descrittive come la moda e la varianza.\n√à importante sottolineare che l‚Äôapplicazione della simulazione di Monte Carlo √® efficace per calcolare distribuzioni a posteriori solo quando conosciamo la distribuzione stessa e possiamo utilizzare funzioni Python per estrarre campioni casuali da tale distribuzione. Ci√≤ √® stato possibile nel caso della distribuzione a posteriori \\(Beta(18, 92)\\).\nTuttavia, questa situazione ideale non si verifica sempre nella pratica, poich√© le distribuzioni a priori coniugate alla verosimiglianza sono spesso rare. Per esempio, nel caso di una verosimiglianza binomiale e una distribuzione a priori gaussiana, l‚Äôespressione\n\\[\np(\\theta \\mid y) = \\frac{\\mathrm{e}^{-(\\theta - 1 / 2)^2} \\theta^y (1 - \\theta)^{n - y}} {\\int_0^1 \\mathrm{e}^{-(t - 1 / 2)^2} t^y (1 - t)^{n - y} dt}\n\\]\nrende impossibile calcolare analiticamente la distribuzione a posteriori di \\(\\theta\\), precludendo quindi l‚Äôutilizzo diretto di Python per generare campioni casuali.\nIn queste circostanze, per√≤, √® possibile ottenere campioni casuali dalla distribuzione a posteriori mediante l‚Äôuso di metodi Monte Carlo basati su Catena di Markov (MCMC). Gli algoritmi MCMC, come ad esempio l‚Äôalgoritmo Metropolis, costituiscono una classe di metodi che consentono di estrarre campioni casuali dalla distribuzione a posteriori senza richiedere la conoscenza della sua rappresentazione analitica. Le tecniche MCMC sono ampiamente adottate per risolvere problemi di inferenza bayesiana e rappresentano il principale strumento computazionale per ottenere stime approssimate di distribuzioni a posteriori in situazioni complesse e non analiticamente trattabili.\n\n57.6.2 Algoritmo di Metropolis\nL‚Äôalgoritmo di Metropolis appartiene alla famiglia dei metodi Monte Carlo basati su catene di Markov (MCMC), sfruttando le propriet√† di queste catene per generare campioni da una distribuzione target. Il suo obiettivo principale √® di esplorare lo spazio dei parametri in modo efficiente, producendo campioni che approssimano la distribuzione a posteriori di interesse.\n\n57.6.3 Principio di Funzionamento\nL‚Äôalgoritmo inizia da un valore iniziale per i parametri e, in ogni iterazione, genera un nuovo campione tramite una distribuzione di proposta (solitamente una distribuzione normale centrata sul valore corrente). Successivamente, decide se accettare il nuovo campione in base al confronto tra le densit√† posteriori del nuovo campione e di quello precedente. Questa accettazione avviene in modo probabilistico, favorendo campioni con una densit√† pi√π alta ma consentendo anche l‚Äôaccettazione di campioni peggiori per evitare che la catena rimanga bloccata in minimi locali.\n\n57.6.4 Burn-in e Convergenza\nPoich√© i primi campioni potrebbero non rappresentare bene la distribuzione target, si esclude spesso una porzione iniziale della catena (fase di burn-in). Con il progredire delle iterazioni, i campioni si distribuiscono in accordo con la distribuzione stazionaria desiderata, indipendentemente dallo stato iniziale scelto. Questo processo permette di esplorare lo spazio dei parametri in modo efficiente.\n\n57.6.5 Meccanismo di Accettazione e Rifiuto\nL‚Äôalgoritmo di Metropolis bilancia due esigenze opposte:\n\n\nEsplorazione di nuove aree dello spazio dei parametri.\n\nSfruttamento delle informazioni gi√† acquisite dai campioni precedenti.\n\nUtilizzando una regola probabilistica per accettare campioni peggiori (con minore densit√† a posteriori), l‚Äôalgoritmo evita di restare intrappolato in minimi locali, esplorando cos√¨ in modo pi√π completo l‚Äôintera distribuzione.\n\n57.6.6 Passaggi Fondamentali dell‚ÄôAlgoritmo di Metropolis\n\n\nScelta di uno stato iniziale \\(\\theta_1\\) e impostazione del contatore \\(t = 1\\).\n\nQuesto √® il punto di partenza della catena, dove \\(\\theta_1\\) rappresenta il primo campione.\n\n\n\nProposta di un nuovo campione \\(\\theta_p\\).\n\nUn nuovo valore \\(\\theta_p\\) viene generato da una distribuzione di proposta \\(g(\\theta_p \\mid \\theta_t)\\), solitamente una distribuzione normale centrata sul campione corrente \\(\\theta_t\\) con una deviazione standard \\(\\tau\\) che controlla l‚Äôampiezza dei passi.\n\n\n\nVerifica dei vincoli del campione proposto.\n\nSe il nuovo campione deve rispettare dei vincoli (ad esempio, essere compreso tra 0 e 1 per probabilit√†), campioni non validi vengono automaticamente rifiutati.\n\n\n\nCalcolo del rapporto di accettazione \\(\\alpha\\).\n\nSi calcola \\(\\alpha = \\frac{p(\\theta_p \\mid y)}{p(\\theta_t \\mid y)}\\), che rappresenta il rapporto tra le densit√† a posteriori del nuovo campione \\(\\theta_p\\) e del campione corrente \\(\\theta_t\\). Questo valore guida la decisione di accettazione.\n\n\n\nDecisione di accettazione.\n\nSe \\(\\alpha \\geq 1\\), il nuovo campione \\(\\theta_p\\) viene accettato incondizionatamente.\nSe \\(\\alpha &lt; 1\\), il campione \\(\\theta_p\\) viene accettato con probabilit√† \\(\\alpha\\). In caso di rifiuto, si mantiene il campione corrente \\(\\theta_t\\) per la prossima iterazione.\n\n\n\nRipetizione del processo.\n\nSi ripetono i passaggi dal 2 al 5 fino a ottenere il numero desiderato di campioni.\n\n\n\n57.6.7 Dettagli Aggiuntivi\n\nDistribuzione di proposta: La distribuzione di proposta \\(g(\\theta_p \\mid \\theta_t)\\) genera nuovi campioni attorno a \\(\\theta_t\\). Tipicamente si usa una normale \\(N(\\theta_t, \\tau)\\), dove \\(\\tau\\) controlla quanto il nuovo campione si discosta da quello corrente. Scegliere un \\(\\tau\\) troppo piccolo pu√≤ rendere l‚Äôesplorazione lenta, mentre un \\(\\tau\\) troppo grande pu√≤ far rifiutare troppi campioni, riducendo l‚Äôefficienza.\nRapporto di accettazione \\(\\alpha\\): Se il nuovo campione ha una densit√† a posteriori maggiore del campione corrente, viene sempre accettato. Se ha una densit√† inferiore, viene accettato con probabilit√† \\(\\alpha\\), il che consente di esplorare anche regioni meno probabili della distribuzione.\nAccettazione probabilistica: Accettare campioni peggiori occasionalmente aiuta l‚Äôalgoritmo a evitare di bloccarsi in minimi locali. Questo √® uno dei punti di forza dell‚Äôalgoritmo di Metropolis, che garantisce una buona esplorazione dello spazio dei parametri.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>57</span>¬† <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#esempio-di-implementazione",
    "href": "chapters/mcmc/01_metropolis.html#esempio-di-implementazione",
    "title": "57¬† L‚Äôalgoritmo di Metropolis-Hastings",
    "section": "\n57.7 Esempio di Implementazione",
    "text": "57.7 Esempio di Implementazione\nPer questa simulazione, adattiamo l‚Äôapproccio proposto da Elizaveta Semenova, implementando l‚Äôalgoritmo di Metropolis-Hastings in R. Cominciamo definendo alcune funzioni fondamentali.\nDefiniamo una funzione prior che calcola la densit√† della distribuzione Beta(4, 6) per un dato valore di \\(\\theta\\):\n\n# Definizione della distribuzione a priori (Beta(4, 6))\nprior &lt;- function(p) {\n  dbeta(p, shape1 = 4, shape2 = 6)\n}\n\nDefiniamo la funzione likelihood, che calcola la densit√† della verosimiglianza binomiale per 14 successi su 100 prove:\n\n# Definizione della funzione di verosimiglianza (Binomiale \n# con y = 14 su n = 100)\nlikelihood &lt;- function(p) {\n  y &lt;- 14\n  n &lt;- 100\n  dbinom(y, size = n, prob = p)\n}\n\nDefiniamo la funzione posterior, che calcola la densit√† della distribuzione a posteriori non normalizzata come prodotto tra la distribuzione a priori e la verosimiglianza:\n\n# Definizione della distribuzione a posteriori (non normalizzata)\nposterior &lt;- function(p) {\n  likelihood(p) * prior(p)\n}\n\nLa distribuzione proposta sar√† una distribuzione normale centrata sullo stato corrente con una deviazione standard specificata:\n\n# Distribuzione proposta (normale centrata sullo stato corrente)\nproposal_distribution &lt;- function(current_state, proposal_sigma) {\n  rnorm(1, mean = current_state, sd = proposal_sigma)\n}\n\nDefiniamo infine la distribuzione target, che corrisponde alla distribuzione a posteriori:\n\n# Distribuzione target, equivalente alla distribuzione a posteriori\ntarget_distribution &lt;- function(p) {\n  posterior(p)\n}\n\nProcediamo ora con l‚Äôimplementazione dell‚Äôalgoritmo di Metropolis-Hastings, considerando i dati relativi agli artisti della Generazione X presenti al MoMA. La distribuzione a priori per \\(\\theta\\) √® modellata come una Beta(4, 6).\n\n# Algoritmo di Metropolis-Hastings\nmetropolis_hastings &lt;- function(num_samples, initial_state, proposal_sigma) {\n  # Inizializza lo stato corrente e la lista dei campioni\n  samples &lt;- numeric(num_samples)\n  current_state &lt;- initial_state\n\n  for (i in seq_len(num_samples)) {\n    # Proponi un nuovo stato dalla distribuzione proposta\n    proposed_state &lt;- proposal_distribution(current_state, proposal_sigma)\n\n    # Verifica che il valore proposto sia tra 0 e 1\n    if (proposed_state &gt;= 0 && proposed_state &lt;= 1) {\n      # Calcola il rapporto di accettazione\n      acceptance_ratio &lt;- min(\n        1,\n        target_distribution(proposed_state) / target_distribution(current_state)\n      )\n\n      # Accetta o rifiuta lo stato proposto\n      if (runif(1) &lt; acceptance_ratio) {\n        current_state &lt;- proposed_state\n      }\n    }\n\n    # Registra lo stato corrente (accettato o rifiutato)\n    samples[i] &lt;- current_state\n  }\n\n  return(samples)\n}\n\n\n\n\n\n\n\nPunti Chiave dell‚ÄôAlgoritmo\n\n\n\n\n\nGenerazione dei nuovi stati: Ogni nuovo stato viene proposto campionando da una distribuzione normale centrata sullo stato corrente. Questo approccio consente un‚Äôesplorazione sistematica dello spazio dei parametri.\n\n\nControllo dei limiti: Gli stati proposti devono rientrare nell‚Äôintervallo [0, 1], poich√© rappresentano probabilit√†. Questo assicura che i valori generati siano validi nel contesto dell‚Äôanalisi.\n\n\nRapporto di accettazione: La decisione di accettare o rifiutare un nuovo stato √® basata sul confronto tra la densit√† a posteriori del nuovo stato e quella dello stato corrente. Stati pi√π probabili vengono sempre accettati, mentre quelli meno probabili sono accettati con una probabilit√† proporzionale.\n\n\nMemorizzazione degli stati: Ogni iterazione salva lo stato corrente, sia che il nuovo stato venga accettato sia che venga rifiutato, garantendo una catena continua di valori.\n\n\n\nQuesta implementazione fornisce una stima robusta della distribuzione a posteriori utilizzando una combinazione di una distribuzione a priori e dei dati osservati.\nLa distribuzione normale utilizzata per la proposta √® simmetrica, soddisfacendo i requisiti dell‚Äôalgoritmo di Metropolis. Questa simmetria garantisce che la probabilit√† di proporre uno stato \\(\\theta_p\\) partendo da \\(\\theta_t\\) sia uguale alla probabilit√† inversa, assicurando l‚Äôequilibrio dettagliato necessario per la corretta convergenza della catena Markoviana.\n\n57.7.1 Esecuzione dell‚ÄôAlgoritmo\n\n# Parametri dell'algoritmo\nnum_samples &lt;- 10000\ninitial_state &lt;- 0.5\nproposal_sigma &lt;- 0.1\n\n# Esecuzione del campionamento\nset.seed(123)  # Per riproducibilit√†\nsamples &lt;- metropolis_hastings(num_samples, initial_state, proposal_sigma)\n\n\n57.7.2 Analisi dei Risultati\nScartiamo i primi 5000 campioni per considerare solo quelli generati dopo il burn-in:\n\nburnin &lt;- floor(num_samples * 0.5)\npost_burnin_samples &lt;- samples[-seq_len(burnin)]\n\nCalcoliamo la media e la deviazione standard dei campioni:\n\n# Media a posteriori\nmean(post_burnin_samples)\n#&gt; [1] 0.1631\n\n# Deviazione standard a posteriori\nsd(post_burnin_samples)\n#&gt; [1] 0.03535\n\nVisualizziamo l‚Äôevoluzione della catena per i primi 200 campioni e per quelli post-burn-in:\n\n# Trace plot dei primi 200 campioni\nplot(\n  samples[1:200], \n  type = \"l\", \n  main = \"Trace Plot (Primi 200 Campioni)\",\n  xlab = \"Iterazioni\", \n  ylab = expression(theta)\n)\n\n\n\n\n\n\n\n\n# Trace plot dopo il burn-in\nplot(\n  post_burnin_samples, \n  type = \"l\", \n  main = \"Trace Plot (Post Burn-in)\",\n  xlab = \"Iterazioni\", \n  ylab = expression(theta)\n)\n\n\n\n\n\n\n\nSovrapponiamo la distribuzione analitica \\(\\text{Beta}(18, 92)\\) all‚Äôistogramma dei campioni post-burn-in:\n\n# Istogramma e distribuzione analitica\nhist(\n  post_burnin_samples, \n  breaks = 20, \n  probability = TRUE, \n  col = \"lightblue\",\n  main = \"Istogramma e Distribuzione Posteriori\", \n  xlab = expression(theta)\n)\ncurve(\n  dbeta(x, 18, 92), \n  add = TRUE, \n  col = \"red\", \n  lwd = 2\n)\nlegend(\n  \"topright\", \n  legend = c(\"Istogramma MCMC\", \"Beta(18, 92)\"),\n  col = c(\"lightblue\", \"red\"), lwd = 2, fill = c(\"lightblue\", NA)\n)\n\n\n\n\n\n\n\nCalcoliamo l‚Äôintervallo di credibilit√† al 94%:\n\nquantile(post_burnin_samples, probs = c(0.03, 0.97))\n#&gt;     3%    97% \n#&gt; 0.1020 0.2347\n\nQuesta implementazione in R dimostra come utilizzare l‚Äôalgoritmo di Metropolis per stimare una distribuzione a posteriori e analizzare i risultati in modo dettagliato e riproducibile.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>57</span>¬† <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#catene-di-markov-e-convergenza",
    "href": "chapters/mcmc/01_metropolis.html#catene-di-markov-e-convergenza",
    "title": "57¬† L‚Äôalgoritmo di Metropolis-Hastings",
    "section": "\n57.8 Catene di Markov e Convergenza",
    "text": "57.8 Catene di Markov e Convergenza\nNell‚Äôambito delle simulazioni Monte Carlo, una catena rappresenta una sequenza di valori campionati dall‚Äôalgoritmo durante le sue iterazioni. Ogni valore nella catena corrisponde a un possibile stato del sistema che stiamo modellando. In altre parole, una catena traccia il percorso che l‚Äôalgoritmo segue nello spazio dei parametri, esplorando le diverse configurazioni possibili.\nPer verificare se l‚Äôalgoritmo ha raggiunto la convergenza e se i campioni generati rappresentano effettivamente la distribuzione di interesse, √® utile eseguire multiple catene. Ogni catena parte da un punto iniziale diverso nello spazio dei parametri.\nI vantaggi delle multiple catene:\n\n\nDiagnostica della convergenza: Confrontando le diverse catene, possiamo valutare se si stabilizzano verso la stessa distribuzione. Se le catene si mescolano bene, ovvero si intersecano frequentemente nel grafico dei valori campionati (trace plot), √® un forte indicatore di convergenza.\n\nRobustezza: L‚Äôutilizzo di multiple catene rende l‚Äôanalisi meno sensibile alla scelta del punto di partenza. Se una singola catena potesse rimanere ‚Äúintrappolata‚Äù in una regione dello spazio dei parametri, multiple catene aumentano la probabilit√† di esplorare lo spazio in modo pi√π completo.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>57</span>¬† <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#diagnostiche-della-soluzione-mcmc",
    "href": "chapters/mcmc/01_metropolis.html#diagnostiche-della-soluzione-mcmc",
    "title": "57¬† L‚Äôalgoritmo di Metropolis-Hastings",
    "section": "\n57.9 Diagnostiche della soluzione MCMC",
    "text": "57.9 Diagnostiche della soluzione MCMC\n\n57.9.1 Stazionariet√† e Convergenza\nUn aspetto cruciale nell‚Äôanalisi delle catene di Markov MCMC √® la convergenza alla distribuzione stazionaria. Intuitivamente, la catena converge quando i campioni generati rappresentano fedelmente la distribuzione di interesse, indipendentemente dal punto di partenza. Questo fenomeno √® spesso indicato come ‚Äúmixing‚Äù.\n\n57.9.1.1 Valutazione Visuale: Trace Plots e Grafici di Densit√†\n\n\nTrace Plots: Questi grafici visualizzano l‚Äôevoluzione dei parametri nel tempo. Una catena convergente mostra tracce stabili e senza trend evidenti. Tracce irregolari o con andamenti sistematici suggeriscono problemi di convergenza.\n\nGrafici di Densit√†: Confrontando i grafici di densit√† dei campioni con la distribuzione teorica, √® possibile valutare visivamente se la catena sta esplorando adeguatamente lo spazio dei parametri. Una buona convergenza si manifesta con una sovrapposizione tra i due grafici.\n\nSegni di Convergenza:\n\n\nStabilit√†: I valori campionati oscillano attorno a un valore medio costante, senza trend marcati.\n\nOmogeneit√†: La variabilit√† dei campioni rimane relativamente uniforme nel tempo.\n\nAssenza di Periodicit√†: Non si osservano pattern ciclici o ripetitivi.\n\nIn sintesi, i trace plots e i grafici di densit√† offrono strumenti visivi rapidi per valutare la convergenza di una catena di Markov MCMC. Una convergenza soddisfacente √® fondamentale per garantire la validit√† delle inferenze statistiche basate sui campioni generati.\n\n57.9.2 Autocorrelazione nelle catene di Markov MCMC\nA differenza dei generatori di numeri casuali indipendenti, gli algoritmi MCMC producono una sequenza di campioni correlati. Ogni valore campionato dipende da quello precedente, formando una catena di Markov. Questa interdipendenza √® un aspetto fondamentale dell‚ÄôMCMC.\nL‚Äôautocorrelazione quantifica il grado di dipendenza tra valori distanti di una certa quantit√† (detta lag) nella catena. Un‚Äôalta autocorrelazione a lag bassi indica una forte dipendenza tra campioni successivi. Al contrario, una rapida diminuzione dell‚Äôautocorrelazione al crescere del lag suggerisce che la catena ‚Äúmiscela‚Äù bene, ovvero esplora lo spazio dei parametri in modo efficiente.\n\n\nLag 1: Misura la correlazione tra valori consecutivi nella catena.\n\nLag 2: Misura la correlazione tra valori separati da un passo intermedio.\n\nLag k: Generalizza il concetto ai valori separati da k passi.\n\nUn correlogramma √® un grafico che mostra l‚Äôautocorrelazione in funzione del lag. Un decadimento rapido dell‚Äôautocorrelazione verso zero indica una buona convergenza della catena.\nL‚Äôautocorrelazione di ordine \\(k\\) √® data da \\(\\rho_k\\) e pu√≤ essere stimata come:\n\\[\n\\begin{align}\n\\rho_k &= \\frac{Cov(\\theta_m, \\theta_{m+k})}{Var(\\theta_m)}\\notag\\\\\n&= \\frac{\\sum_{m=1}^{n-k}(\\theta_m - \\bar{\\theta})(\\theta_{m-k} - \\bar{\\theta})}{\\sum_{m=1}^{n-k}(\\theta_m - \\bar{\\theta})^2} \\qquad\\text{con }\\quad \\bar{\\theta} = \\frac{1}{n}\\sum_{m=1}^{n}\\theta_m.\n\\end{align}\n\\tag{57.1}\\]\n\n57.9.3 Esempio di Simulazione di Dati Autocorrelati\nPer fare un esempio pratico, creiamo un vettore di dati autocorrelati:\n\n# Creiamo un vettore di dati\nx &lt;- c(22, 24, 25, 25, 28, 29, 34, 37, 40, 44, 51, 48, 47, 50, 51)\nx\n#&gt;  [1] 22 24 25 25 28 29 34 37 40 44 51 48 47 50 51\n\n\n57.9.3.1 Calcolo dell‚ÄôAutocorrelazione\nL‚Äôautocorrelazione di ordine 1 √® la correlazione tra ciascun elemento e il successivo nella sequenza. In R possiamo utilizzare la funzione acf() per calcolare l‚Äôautocorrelazione.\n\n# Calcolo dell'autocorrelazione\nacf_values &lt;- acf(x, plot = FALSE)\nacf_values\n#&gt; \n#&gt; Autocorrelations of series 'x', by lag\n#&gt; \n#&gt;      0      1      2      3      4      5      6      7      8      9 \n#&gt;  1.000  0.832  0.656  0.491  0.279  0.031 -0.165 -0.304 -0.401 -0.458 \n#&gt;     10     11 \n#&gt; -0.450 -0.369\n\nNell‚Äôesempio, il vettore x rappresenta una serie temporale di 15 elementi. Il calcolo dell‚Äôautocorrelazione restituisce i seguenti valori per i primi ritardi (lag):\n\n\n0.8317: autocorrelazione di ordine 1 (lag = 1),\n\n0.6563: autocorrelazione di ordine 2 (lag = 2),\n\n0.4910: autocorrelazione di ordine 3 (lag = 3),\necc.\n\n57.9.3.2 Specifica del Numero di Ritardi (Lag)\nPossiamo limitare il numero di ritardi calcolati utilizzando l‚Äôargomento lag.max nella funzione acf():\n\n# Calcolo dell'autocorrelazione per i primi 4 lag\nacf(x, lag.max = 4, plot = FALSE)\n#&gt; \n#&gt; Autocorrelations of series 'x', by lag\n#&gt; \n#&gt;     0     1     2     3     4 \n#&gt; 1.000 0.832 0.656 0.491 0.279\n\n\n57.9.3.3 Grafico della Funzione di Autocorrelazione (Correlogramma)\nIn R possiamo creare un correlogramma con la funzione acf():\n\n# Correlogramma per la serie temporale\nacf(x, main = \"Correlogramma della Serie Temporale\", lag.max = 9)\n\n\n\n\n\n\n\n\n57.9.4 Analisi della Catena di Markov\nApplichiamo lo stesso approccio alla catena di Markov ottenuta precedentemente, considerando i campioni post burn-in:\n\n# Definizione dei campioni post burn-in\npost_burnin_samples &lt;- samples[-seq_len(burnin)]\n\n# Correlogramma per i campioni post burn-in\nacf(\n  post_burnin_samples, \n  main = \"Correlogramma della Catena Post Burn-in\", \n  lag.max = 9\n)\n\n\n\n\n\n\n\nIn situazioni ideali, l‚Äôautocorrelazione diminuisce rapidamente, diventando insignificante per piccoli lag. Questo comportamento √® un‚Äôindicazione del ‚Äúmixing‚Äù efficace della catena, ossia della sua convergenza alla distribuzione stazionaria.\n\n57.9.5 Sottocampionamento (Thinning)\nPer ridurre l‚Äôautocorrelazione, possiamo applicare una strategia di sottocampionamento (thinning), memorizzando solo ogni \\(m\\)-esimo campione.\n\n# Sottocampionamento con un fattore di 5\nthin &lt;- 5\nsampsthin &lt;- \n  post_burnin_samples[seq(1, length(post_burnin_samples), by = thin)]\n\n# Correlogramma per i campioni sottocampionati\nacf(\n  sampsthin, \n  main = \"Correlogramma con Sottocampionamento (Thinning)\", \n  lag.max = 9\n)\n\n\n\n\n\n\n\nIn conclusione, il correlogramma con thinning mostra che l‚Äôautocorrelazione diminuisce pi√π rapidamente rispetto ai campioni originali, suggerendo che la strategia di sottocampionamento √® efficace nel migliorare l‚Äôindipendenza tra i campioni successivi. Questo migliora la qualit√† delle inferenze basate sulla catena di Markov.\n\n57.9.5.1 Tasso di accettazione\nQuando si utilizza l‚Äôalgoritmo Metropolis, √® importante monitorare il tasso di accettazione e assicurarsi che sia nell‚Äôintervallo ottimale. Se si accetta quasi sempre il candidato proposto, probabilmente significa che, in ogni iterazione, la catena salta solo di un piccolo passo (in modo che il rapporto di accettazione sia vicino a 1 ogni volta). Di conseguenza, la catena impiegher√† molte iterazioni per raggiungere altre regioni della distribuzione stazionaria e i campioni consecutivi saranno molto fortemente correlati. D‚Äôaltra parte, se il tasso di accettazione √® molto basso, la catena rimarr√† bloccata nella stessa posizione per molte iterazioni prima di spostarsi verso uno stato diverso. Per l‚Äôalgoritmo Metropolis base con un singolo parametro con una distribuzione proposta Gaussiana normale, un tasso di accettazione ottimale √® compreso tra il 40% e il 50%.\n\n57.9.6 Test Statistici per la Convergenza\nOltre agli approcci grafici, esistono test statistici specifici che possono aiutare a determinare se la catena ha raggiunto uno stato stazionario.\n\n57.9.6.1 Test di Geweke\nIl test di Geweke √® una procedura che confronta le medie di due segmenti della catena di campionamento, tipicamente il primo 10% e l‚Äôultimo 50% dei campioni, dopo aver escluso un iniziale periodo di ‚Äúburn-in‚Äù (una fase iniziale durante la quale la catena potrebbe non essere ancora convergente). La premessa di base √® che, se la catena √® in uno stato stazionario, le medie di questi due segmenti dovrebbero essere sostanzialmente uguali. Differenze importanti tra queste medie possono indicare che la catena non ha ancora raggiunto la convergenza.\n\n57.9.6.2 Geweke Z-score\nUna variante del test di Geweke √® lo z-score di Geweke, che offre un modo quantitativo per valutare le differenze tra i segmenti della catena. Questo test calcola uno z-score che confronta le medie dei due segmenti tenendo conto della varianza. Un valore di z-score:\n\n\nAl di sotto di 2 (in valore assoluto) suggerisce che non ci sono differenze degne di nota tra i segmenti, indicando che la catena potrebbe essere in stato stazionario.\n\nSuperiore a 2 (in valore assoluto) indica che esiste una differenza degna di nota tra i segmenti, suggerendo che la catena non ha raggiunto la convergenza e potrebbe essere necessario un periodo di burn-in pi√π esteso.\n\nEntrambi i metodi forniscono strumenti utili per valutare la convergenza delle catene MCMC. √à importante notare che nessun test pu√≤ garantire con certezza la convergenza, ma l‚Äôutilizzo congiunto di approcci grafici e test statistici pu√≤ offrire una buona indicazione dello stato della catena.\n\n57.9.7 Dimensione del campione effettiva (ESS)\nLa correlazione tra campioni consecutivi in una catena MCMC riduce l‚Äôinformazione effettiva contenuta in ogni iterazione. La dimensione del campione effettiva (ESS) quantifica questa perdita di informazione dovuta alla dipendenza tra i campioni, stimando il numero equivalente di campioni indipendenti. Un valore basso di ESS indica una forte correlazione tra i campioni e una convergenza pi√π lenta della catena.\nL‚ÄôESS descrive l‚Äôefficacia del campionamento dipendente in termini di campioni indipendenti estratti dalla stessa distribuzione. Rappresenta un indicatore dell‚Äôefficienza del campionamento e dell‚Äôautocorrelazione della catena.\nLa formula per stimare la dimensione del campione effettiva (ESS) di una catena di Markov √®:\n\\[\n\\text{ESS} = \\frac{N}{1 + 2 \\sum_{t=1}^{T} \\rho_t},\n\\]\ndove:\n\n\n\\(N\\) √® il numero totale di campioni nella catena,\n\n\\(T\\) √® il lag, ovvero il numero massimo di termini di autocorrelazione considerati,\n\n\\(\\rho_t\\) √® l‚Äôautocorrelazione al lag \\(t\\), ossia la correlazione tra due campioni consecutivi separati da \\(t\\) iterazioni.\n\nIn pratica, \\(T\\) viene scelto in modo tale che \\(\\rho_T\\) sia sufficientemente piccolo, indicando che l‚Äôautocorrelazione √® quasi svanita. La somma \\(\\sum_{t=1}^T \\rho_t\\) viene quindi troncata approssimativamente a \\(T\\), poich√© i contributi delle autocorrelazioni successive diventano trascurabili.\n\n57.9.8 Calcolo della Statistica di Gelman-Rubin (\\(\\hat{R}\\))\nPer calcolare la statistica di Gelman-Rubin (spesso indicata come \\(\\hat{R}\\)), √® necessario eseguire pi√π catene e confrontare la variabilit√† all‚Äôinterno di ciascuna catena con la variabilit√† tra le catene. Ecco i passaggi per calcolare \\(\\hat{R}\\):\n\nEsegui \\(m\\) catene di Markov di lunghezza \\(n\\), dove \\(m\\) √® solitamente maggiore di 1.\nPer ciascun parametro scalare \\(\\theta\\), calcola la varianza all‚Äôinterno delle catene (\\(W\\)) e la varianza tra le catene (\\(B\\)).\nCalcola la varianza combinata \\(\\hat{V}\\) come media ponderata delle varianze all‚Äôinterno delle catene.\nCalcola il fattore di riduzione della scala potenziale \\(\\hat{R}\\) come la radice quadrata del rapporto tra la varianza combinata \\(\\hat{V}\\) e la varianza all‚Äôinterno delle catene \\(W\\):\n\n\\[\n\\hat{R} = \\sqrt{\\frac{\\hat{V}}{W}}.\n\\]\n\nSe \\(\\hat{R}\\) √® vicino a 1, ci√≤ indica che le catene sono in convergenza.\n\nLa statistica di Gelman-Rubin \\(\\hat{R}\\) √® una misura di convergenza per le catene di Markov. Essa quantifica il grado di accordo tra pi√π catene, fornendo uno strumento diagnostico per valutare la convergenza nelle simulazioni MCMC.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>57</span>¬† <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#vantaggi-del-campionamento-mcmc-rispetto-alle-soluzioni-analitiche",
    "href": "chapters/mcmc/01_metropolis.html#vantaggi-del-campionamento-mcmc-rispetto-alle-soluzioni-analitiche",
    "title": "57¬† L‚Äôalgoritmo di Metropolis-Hastings",
    "section": "\n57.10 Vantaggi del Campionamento MCMC rispetto alle Soluzioni Analitiche",
    "text": "57.10 Vantaggi del Campionamento MCMC rispetto alle Soluzioni Analitiche\nIl campionamento MCMC offre notevoli vantaggi pratici rispetto alle soluzioni analitiche nella statistica bayesiana, in particolare quando si tratta di manipolare distribuzioni a posteriori. Sebbene l‚Äôimpossibilit√† di calcolare analiticamente la distribuzione a posteriori sia spesso la motivazione principale per l‚Äôuso di MCMC, i benefici di questo approccio si estendono ben oltre questa necessit√† (B√ºrkner, 2024).\n\n57.10.1 Facilit√† di Manipolazione e Flessibilit√†\nIl vantaggio chiave del campionamento MCMC risiede nella semplicit√† con cui si possono manipolare i campioni ottenuti. Mentre le densit√† calcolate analiticamente possono richiedere trasformazioni matematiche complesse, i campioni MCMC possono essere facilmente trasformati con operazioni dirette. Questa flessibilit√† si manifesta in diversi aspetti:\n\n\nTrasformazioni di Variabili: Consideriamo un caso in cui siamo interessati alla varianza residua (\\(\\sigma^2\\)) in un modello, ma abbiamo campioni solo della deviazione standard residua (\\(\\sigma\\)). Con il campionamento MCMC, la trasformazione √® immediata:\n\n\\[\n(\\sigma^{(s)})^2 = \\sigma^{2(s)},\n\\]\ndove \\(s\\) indica il singolo campione. Questa operazione si traduce semplicemente nell‚Äôelevare al quadrato ogni campione di \\(\\sigma\\), ottenendo direttamente campioni validi di \\(\\sigma^2\\). In contrasto, con una densit√† analitica di \\(\\sigma\\), la trasformazione richiederebbe l‚Äôapplicazione dell‚Äôaggiustamento del Jacobiano, un processo matematicamente pi√π complesso.\n\n\nCombinazione di Parametri: Il MCMC semplifica notevolmente la combinazione di parametri in modelli statistici. Per una quantit√† \\(\\theta\\) che dipende da parametri \\(\\beta_1\\) e \\(\\beta_2\\) attraverso una funzione \\(f\\), possiamo calcolare:\n\n\\[\n\\theta^{(s)} = f(\\beta_1^{(s)}, \\beta_2^{(s)}).\n\\]\nQuesta operazione si estende facilmente a combinazioni complesse e funzioni non lineari, contrastando nettamente con la complessit√† di derivare analiticamente la distribuzione di \\(\\theta\\).\nIn conclusione, il campionamento MCMC non √® solo una necessit√† quando le soluzioni analitiche sono introvabili, ma offre vantaggi in termini di facilit√† di manipolazione, flessibilit√† computazionale e applicabilit√† pratica.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>57</span>¬† <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#caso-normale-normale-con-soluzione-analitica",
    "href": "chapters/mcmc/01_metropolis.html#caso-normale-normale-con-soluzione-analitica",
    "title": "57¬† L‚Äôalgoritmo di Metropolis-Hastings",
    "section": "\n57.11 Caso Normale-Normale con Soluzione Analitica",
    "text": "57.11 Caso Normale-Normale con Soluzione Analitica\nConsideriamo un caso normale-normale per cui possiamo derivare una soluzione analitica. Supponiamo che il prior sia distribuito secondo \\(\\mathcal{N}(30, 5^2)\\).\nDefiniamo le funzioni per il prior, la verosimiglianza e il posterior non normalizzato.\n\n# Prior: Normal(30, 5^2)\nprior &lt;- function(mu) {\n  dnorm(mu, mean = 30, sd = 5)\n}\n\n# Likelihood: Normal(mu, sigma^2) con sigma calcolata dai dati\nlikelihood &lt;- function(mu, data) {\n  sigma &lt;- sd(data)  # Deviazione standard dei dati\n  prod(dnorm(data, mean = mu, sd = sigma))\n}\n\n# Posterior non normalizzato\nposterior &lt;- function(mu, data) {\n  likelihood(mu, data) * prior(mu)\n}\n\nImplementiamo l‚Äôalgoritmo di Metropolis per il caso normale-normale:\n\n# Algoritmo di Metropolis\nmetropolis_for_normal &lt;- function(nsamp, xinit, data) {\n  samples &lt;- numeric(nsamp)\n  x_prev &lt;- xinit\n  \n  for (i in seq_len(nsamp)) {\n    x_star &lt;- rnorm(1, mean = x_prev, sd = 0.5)  # Proposta\n    if (runif(1) &lt; min(1, posterior(x_star, data) / posterior(x_prev, data))) {\n      x_prev &lt;- x_star\n    }\n    samples[i] &lt;- x_prev\n  }\n  \n  samples\n}\n\nUtilizziamo un campione di 30 valori BDI-II forniti da Zetsche et al. (2019):\n\n# Dati osservati\ny &lt;- c(\n  26, 35, 30, 25, 44, 30, 33, 43, 22, 43, 24, 19, 39, 31, 25, \n  28, 35, 30, 26, 31, 41, 36, 26, 35, 33, 28, 27, 34, 27, 22\n)\n\nEsecuzione dell‚Äôalgoritmo:\n\nsamples &lt;- metropolis_for_normal(100000, mean(y), y)\n\nNel caso normale-normale, il posterior pu√≤ essere calcolato analiticamente come segue:\n\n# Parametri del prior\nmu_prior &lt;- 30\nstd_prior &lt;- 5\nvar_prior &lt;- std_prior^2\n\n# Calcolo dei parametri posterior\nn &lt;- length(y)\nsum_y &lt;- sum(y)\nvar_data &lt;- var(y)\n\nmu_post &lt;- (mu_prior / var_prior + sum_y / var_data) / (1 / var_prior + n / var_data)\nvar_post &lt;- 1 / (1 / var_prior + n / var_data)\nstd_post &lt;- sqrt(var_post)\n\nmu_post\n#&gt; [1] 30.88\nstd_post\n#&gt; [1] 1.173\n\nVisualizziamo i risultati con un istogramma dei campioni MCMC e la curva della distribuzione analitica:\n\n# Campioni post burn-in\nburnin &lt;- floor(length(samples) * 0.5)\npost_samples &lt;- samples[-seq_len(burnin)]\n\n# Dati per la curva analitica\nx &lt;- seq(mu_post - 4 * std_post, mu_post + 4 * std_post, length.out = 1000)\nanalytical_posterior &lt;- dnorm(x, mean = mu_post, sd = std_post)\n\n# Creazione del grafico\nggplot() +\n  geom_histogram(aes(x = post_samples, y = after_stat(density)), bins = 30, fill = \"blue\", alpha = 0.4) +\n  geom_line(aes(x = x, y = analytical_posterior), color = \"red\", size = 1) +\n  labs(title = \"Distribuzione Posterior: MCMC vs Analitico\",\n       x = expression(mu), y = \"Densit√†\") \n\n\n\n\n\n\n\nTroviamo le propriet√† del Posterior derivato con MCMC:\n\nmean(samples)\n#&gt; [1] 30.91\n\n\nsd(samples)\n#&gt; [1] 1.177\n\nIn conclusione, questo esempio mostra come applicare l‚Äôalgoritmo di Metropolis per stimare una distribuzione a posteriori e come confrontare i risultati del sampling con la soluzione analitica, confermando la coerenza tra le due tecniche.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>57</span>¬† <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#riflessioni-conclusive",
    "href": "chapters/mcmc/01_metropolis.html#riflessioni-conclusive",
    "title": "57¬† L‚Äôalgoritmo di Metropolis-Hastings",
    "section": "\n57.12 Riflessioni Conclusive",
    "text": "57.12 Riflessioni Conclusive\nIn molti casi, la distribuzione a posteriori dei parametri di un modello statistico non ha una forma analitica risolvibile. Per affrontare questa limitazione, si utilizzano metodi Monte Carlo basati su catene di Markov (MCMC). Questi algoritmi permettono di campionare efficacemente dalla distribuzione a posteriori, anche per modelli complessi, generando una sequenza di valori che approssima la distribuzione desiderata. L‚Äôalgoritmo di Metropolis-Hastings (Hastings, 1970), un‚Äôestensione dell‚Äôalgoritmo di Metropolis originale (Metropolis et al., 1953), √® uno dei metodi MCMC pi√π ampiamente utilizzati.\nIn sintesi, l‚Äôalgoritmo segue questi passaggi principali:\n\n\nGenerazione del nuovo stato proposto: Si crea un nuovo stato vicino a quello corrente utilizzando una distribuzione di proposta.\n\nConfronto tra densit√† posteriori: Si confrontano le densit√† a posteriori del nuovo stato proposto e dello stato corrente.\n\nAccettazione probabilistica: Il nuovo stato viene sempre accettato se ha una densit√† posteriore maggiore, oppure accettato con una certa probabilit√† se ha una densit√† minore.\n\nBurn-in e tasso di accettazione: I primi campioni vengono scartati (fase di burn-in) per garantire che la catena abbia raggiunto la distribuzione stazionaria, e si monitora il tasso di accettazione per ottimizzare l‚Äôefficienza del campionamento.\n\nQuesto approccio consente di ottenere campioni che approssimano la distribuzione a posteriori, ma l‚Äôalgoritmo di Metropolis pu√≤ presentare limiti di efficienza, soprattutto per problemi ad alta dimensionalit√† o distribuzioni con geometrie complesse. Un aspetto cruciale √® il tasso di accettazione, che rappresenta il rapporto tra il numero di proposte accettate e il numero totale di proposte. Un tasso troppo basso pu√≤ indicare che la catena esplora lo spazio dei parametri in modo inefficiente, mentre un tasso troppo alto pu√≤ segnalare che i passi effettuati sono troppo piccoli per consentire una buona esplorazione.\nRispetto alle varianti pi√π moderne, l‚Äôalgoritmo di Metropolis tende a essere meno efficiente. Metodi come il No-U-Turn Sampler (NUTS) e l‚ÄôHamiltonian Monte Carlo (HMC) offrono importanti miglioramenti, specialmente in spazi di parametri di grandi dimensioni. NUTS, ad esempio, viene utilizzato in strumenti avanzati come Stan e PyMC (Hoffman et al., 2014), permettendo un‚Äôesplorazione pi√π rapida e accurata della distribuzione a posteriori.\nTra gli altri algoritmi MCMC degni di nota troviamo il campionatore di Gibbs (Geman & Geman, 1984) e l‚ÄôHamiltonian Monte Carlo (Duane et al., 1987). Questi metodi, insieme a Metropolis-Hastings, formano la base di numerose tecniche moderne per il campionamento da distribuzioni complesse. Per un approfondimento dettagliato sulle tecniche MCMC, si consiglia di consultare Hanada & Matsuura (2022).",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>57</span>¬† <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/01_metropolis.html#informazioni-sullambiente-di-sviluppo",
    "title": "57¬† L‚Äôalgoritmo di Metropolis-Hastings",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] cmdstanr_0.8.1   thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0\n#&gt;  [5] see_0.11.0       gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1\n#&gt;  [9] psych_2.5.3      scales_1.3.0     markdown_2.0     knitr_1.50      \n#&gt; [13] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [17] purrr_1.0.4      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [21] ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6         tensorA_0.36.2.1     xfun_0.51           \n#&gt;  [4] htmlwidgets_1.6.4    processx_3.8.6       lattice_0.22-6      \n#&gt;  [7] tzdb_0.5.0           vctrs_0.6.5          tools_4.4.2         \n#&gt; [10] ps_1.9.0             generics_0.1.3       parallel_4.4.2      \n#&gt; [13] pacman_0.5.1         R.oo_1.27.0          pkgconfig_2.0.3     \n#&gt; [16] data.table_1.17.0    checkmate_2.3.2      distributional_0.5.0\n#&gt; [19] lifecycle_1.0.4      compiler_4.4.2       farver_2.1.2        \n#&gt; [22] munsell_0.5.1        mnormt_2.1.1         htmltools_0.5.8.1   \n#&gt; [25] pillar_1.10.1        R.utils_2.13.0       abind_1.4-8         \n#&gt; [28] nlme_3.1-167         posterior_1.6.1      tidyselect_1.2.1    \n#&gt; [31] digest_0.6.37        stringi_1.8.4        reshape2_1.4.4      \n#&gt; [34] labeling_0.4.3       rprojroot_2.0.4      fastmap_1.2.0       \n#&gt; [37] grid_4.4.2           colorspace_2.1-1     cli_3.6.4           \n#&gt; [40] magrittr_2.0.3       withr_3.0.2          backports_1.5.0     \n#&gt; [43] timechange_0.3.0     rmarkdown_2.29       R.methodsS3_1.8.2   \n#&gt; [46] hms_1.1.3            evaluate_1.0.3       rlang_1.1.5         \n#&gt; [49] Rcpp_1.0.14          glue_1.8.0           rstudioapi_0.17.1   \n#&gt; [52] jsonlite_1.9.1       plyr_1.8.9           R6_2.6.1",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>57</span>¬† <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#bibliografia",
    "href": "chapters/mcmc/01_metropolis.html#bibliografia",
    "title": "57¬† L‚Äôalgoritmo di Metropolis-Hastings",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nB√ºrkner, P.-C. (2024). The brms Book: Applied Bayesian Regression Modelling Using R and Stan (Early Draft). https://paulbuerkner.com/software/brms-book\n\n\nDuane, S., Kennedy, A. D., Pendleton, B. J., & Roweth, D. (1987). Hybrid monte carlo. Physics letters B, 195(2), 216‚Äì222.\n\n\nGeman, S., & Geman, D. (1984). Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images. IEEE Transactions on pattern analysis and machine intelligence, 6, 721‚Äì741.\n\n\nHanada, M., & Matsuura, S. (2022). MCMC from Scratch. Springer.\n\n\nHastings, W. K. (1970). Monte Carlo sampling methods using Markov chains and their applications. Biometrika, 57(1), 97‚Äì109.\n\n\nHoffman, M. D., Gelman, A., et al. (2014). The No-U-Turn sampler: adaptively setting path lengths in Hamiltonian Monte Carlo. Journal of Machine Learning Research, 15(1), 1593‚Äì1623.\n\n\nMetropolis, N., Rosenbluth, A. W., Rosenbluth, M. N., Teller, A. H., & Teller, E. (1953). Equation of state calculations by fast computing machines. The Journal of Chemical Physics, 21(6), 1087‚Äì1092.\n\n\nZetsche, U., Buerkner, P.-C., & Renneberg, B. (2019). Future expectations in clinical depression: biased or realistic? Journal of Abnormal Psychology, 128(7), 678‚Äì688.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>57</span>¬† <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_ppl.html",
    "href": "chapters/mcmc/02_ppl.html",
    "title": "58¬† Linguaggi di programmazione probabilistici",
    "section": "",
    "text": "58.1 Cos‚Äô√® la programmazione probabilistica\nLa programmazione probabilistica √® un paradigma della programmazione informatica che consente di creare modelli e algoritmi capaci di gestire l‚Äôincertezza e la casualit√†. Combina i principi della teoria delle probabilit√† con la programmazione, permettendo di costruire sistemi in grado di ragionare su dati incerti e di prendere decisioni informate. Questo approccio consente di esprimere modelli complessi in modo naturale e intuitivo, facilitando il processo di inferenza bayesiana.\nLa programmazione probabilistica si colloca all‚Äôintersezione tra algoritmi di machine learning, statistica e linguaggi di programmazione. I suoi obiettivi principali sono semplificare il processo di inferenza e automatizzarlo.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>58</span>¬† <span class='chapter-title'>Linguaggi di programmazione probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_ppl.html#perch√©-abbiamo-bisogno-della-programmazione-probabilistica",
    "href": "chapters/mcmc/02_ppl.html#perch√©-abbiamo-bisogno-della-programmazione-probabilistica",
    "title": "58¬† Linguaggi di programmazione probabilistici",
    "section": "58.2 Perch√© abbiamo bisogno della programmazione probabilistica?",
    "text": "58.2 Perch√© abbiamo bisogno della programmazione probabilistica?\nScrivere un proprio campionatore per l‚Äôinferenza bayesiana √® un compito estremamente difficile. Richiede competenze matematiche avanzate e una profonda conoscenza degli algoritmi di campionamento (sia MCMC che approssimati). Inoltre, ci sono numerosi problemi potenziali legati alla stabilit√† numerica e ai costi computazionali. Questo significa che per riuscirci bisogna essere allo stesso tempo degli ottimi sviluppatori e degli esperti statistici.\n√à per√≤ possibile delegare tutti questi compiti a un sistema che li automatizzi, permettendoci di concentrarci sulla risoluzione dei problemi scientifici.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>58</span>¬† <span class='chapter-title'>Linguaggi di programmazione probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_ppl.html#linguaggi-di-programmazione-probabilistica-ppls",
    "href": "chapters/mcmc/02_ppl.html#linguaggi-di-programmazione-probabilistica-ppls",
    "title": "58¬† Linguaggi di programmazione probabilistici",
    "section": "58.3 Linguaggi di programmazione probabilistica (PPLs)",
    "text": "58.3 Linguaggi di programmazione probabilistica (PPLs)\nIn questa sezione esamineremo il panorama moderno dei linguaggi di programmazione probabilistica (PPLs) e, nella sezione successiva, esploreremo le funzionalit√† di uno di questi, Stan.\n\n58.3.1 Linguaggi di Programmazione Probabilistica (PPL)\nUn linguaggio di programmazione probabilistica (PPL) consente di formalizzare modelli bayesiani e di eseguire inferenze utilizzando algoritmi avanzati. L‚Äôutente deve semplicemente definire il modello, selezionare un campionatore e avviare il processo di inferenza.\nIn generale, le funzionalit√† fondamentali richieste a un PPL sono:\n\ngenerare valori casuali da distribuzioni probabilistiche;\ncondizionare variabili su dati osservati.\n\nI primi linguaggi di programmazione probabilistica, come BUGS e WinBUGS, hanno gettato le basi offrendo tre capacit√† essenziali:\n\nrandom: per definire variabili casuali.\nconstraint: per vincolare variabili ai dati osservati.\ninfer: per calcolare e restituire la distribuzione delle variabili di interesse.\n\nNel corso del tempo, l‚Äôelenco dei PPL disponibili si √® notevolmente ampliato, comprendendo una vasta gamma di strumenti in continua evoluzione. Ecco alcuni esempi rappresentativi:\n\nBUGS, WinBUGS, JAGS\nStan\nPyMC3, PyMC4, PyMC\nNimble\nPyro, NumPyro\nEdward, TensorFlow Probability, Edward 2\nGen\nTuring\nStheno\nSOSS\nOmega\nInfer.NET",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>58</span>¬† <span class='chapter-title'>Linguaggi di programmazione probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_ppl.html#come-scegliere-un-ppl",
    "href": "chapters/mcmc/02_ppl.html#come-scegliere-un-ppl",
    "title": "58¬† Linguaggi di programmazione probabilistici",
    "section": "58.4 Come scegliere un PPL?",
    "text": "58.4 Come scegliere un PPL?\nDal punto di vista pratico, come si pu√≤ decidere quale linguaggio di programmazione probabilistica utilizzare? Ecco alcuni fattori chiave da considerare:\n\nDocumentazione: La presenza di risorse ben strutturate, come guide, tutorial e documentazione ufficiale, √® essenziale per facilitare l‚Äôapprendimento e migliorare la produttivit√†. Un PPL con documentazione chiara e completa √® sempre preferibile, specialmente per chi √® alle prime armi.\nPerformance: Alcuni PPL sono ottimizzati per offrire prestazioni superiori, ad esempio mediante l‚Äôelaborazione parallela o l‚Äôuso di acceleratori hardware come le GPU. Valuta le prestazioni in relazione alla complessit√† e alla scala dei modelli che desideri costruire.\nFunzionalit√†: √à importante verificare se il PPL offre un‚Äôampia gamma di distribuzioni probabilistiche e campionatori, oltre a strumenti avanzati per personalizzare i modelli e implementare inferenze specifiche.\nSupporto della comunit√†: Una comunit√† attiva pu√≤ fare la differenza quando incontri difficolt√†. Forum, gruppi di discussione e risorse condivise dagli utenti (come esempi pratici o risposte a domande frequenti) sono fondamentali per risolvere problemi in modo rapido e imparare dalle esperienze di altri.\nIntegrazione: Considera quanto bene il PPL si integra con gli strumenti e i framework gi√† in uso. Per esempio, se utilizzi librerie per la manipolazione dei dati, la visualizzazione o il machine learning, come pandas, ggplot o TensorFlow, verifica che il PPL scelto supporti queste interazioni senza complicazioni.\n\n\n58.4.1 API\nI linguaggi di programmazione probabilistica (PPL) permettono agli utenti di definire con precisione le caratteristiche dei priori, della verosimiglianza e dell‚Äôintero modello bayesiano. Inoltre, offrono strumenti per effettuare le necessarie trasformazioni sui dati, garantendo la flessibilit√† richiesta per affrontare una vasta gamma di problemi statistici. Tuttavia, anche se i PPL cercano di semplificare queste operazioni, l‚Äôutente deve comunque scrivere codice che rispetti i vincoli sintattici e logici specifici del linguaggio. Questo richiede non solo competenze di programmazione, ma anche una buona conoscenza dei principi statistici e bayesiani.\nPer venire incontro a utenti che desiderano utilizzare l‚Äôinferenza bayesiana senza doversi addentrare nella programmazione, sono state sviluppate interfacce di alto livello. Queste interfacce permettono di specificare modelli statistici comuni in modo intuitivo, utilizzando una sintassi semplificata. Sebbene offrano meno controllo sui dettagli tecnici del modello, garantiscono comunque la possibilit√† di personalizzare elementi cruciali, come i priori e la verosimiglianza, rendendo l‚Äôinferenza bayesiana accessibile anche a chi non ha competenze di programmazione.\n\n\n58.4.2 Principali Interfacce di Alto Livello\nTra le interfacce pi√π popolari troviamo:\n\nbrms: utilizza Stan come motore sottostante per eseguire l‚Äôinferenza.\nBambi: si basa su PyMC per eseguire l‚Äôinferenza bayesiana.\n\nEntrambe queste librerie adottano una sintassi semplificata, nota come sintassi di Wilkinson (Wilkinson & Rogers, 1973). Questo approccio consente di specificare modelli in modo dichiarativo, usando una struttura simile a quella adottata da pacchetti R come lm (per modelli di regressione lineare) o lme4 (per modelli multilivello con lmer).\nAd esempio, in brms √® possibile specificare un modello di regressione lineare con una sintassi simile a questa:\nfit &lt;- brm(y ~ x1 + x2, data = dataset)\nIn questo esempio y ~ x1 + x2 definisce la relazione tra la variabile dipendente (y) e le variabili indipendenti (x1 e x2).\n\n\n58.4.3 Vantaggi delle Interfacce di Alto Livello\n\nAccessibilit√†: Riduzione della complessit√† sintattica, rendendo l‚Äôinferenza bayesiana pi√π accessibile a un pubblico pi√π ampio, inclusi studenti e ricercatori con competenze di programmazione limitate.\nFlessibilit√†: Sebbene pi√π semplici, le interfacce consentono di specificare prior distribuiti in modo personalizzato e di modificare molteplici aspetti del modello.\nEfficienza: Automatizzano molti passaggi tecnici, permettendo di concentrarsi sulla definizione del modello e sull‚Äôinterpretazione dei risultati.\nCompatibilit√†: Integrazione con strumenti statistici familiari, come il framework di modelli lineari in R.\n\nIn questo corso, utilizzeremo principalmente brms per specificare e stimare modelli di regressione lineare e multilivello, sfruttandone la sintassi intuitiva e l‚Äôintegrazione con R. Negli approfondimenti, invece, esploreremo come scrivere direttamente modelli in Stan, per comprendere meglio le basi dei PPL e avere maggiore controllo sui dettagli tecnici.\nQuesta combinazione ci permetter√† di bilanciare semplicit√† e potenza, rendendo l‚Äôinferenza bayesiana sia accessibile che personalizzabile, a seconda delle esigenze specifiche del progetto o dell‚Äôanalisi.\n\n\n58.4.4 Introduzione alla sintassi di Wilkinson\nLa sintassi di Wilkinson in R fornisce un modo semplice ed efficace per specificare modelli di regressione lineare, consentendo di descrivere relazioni tra una variabile dipendente (risposta) e una o pi√π variabili indipendenti (predittori) utilizzando una notazione simbolica. Questa sintassi si allinea direttamente al modello matematico, rendendo immediata la corrispondenza tra i termini simbolici e il codice.\n\n58.4.4.1 Modello simbolico e modello Wilkinson\nSupponiamo di voler specificare un modello di regressione lineare multipla con la seguente formula:\n\\[\ny_i = \\alpha + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\varepsilon_i ,\n\\]\ndove:\n\n\\(y_i\\) √® la variabile dipendente per l‚Äôosservazione \\(i\\),\n\\(\\alpha\\) √® l‚Äôintercetta,\n\\(\\beta_1\\) e \\(\\beta_2\\) sono i coefficienti di regressione per i predittori \\(x_1\\) e \\(x_2\\),\n\\(\\varepsilon_i\\) rappresenta l‚Äôerrore residuo, normalmente distribuito (\\(\\varepsilon_i \\sim \\mathcal{N}(0, \\sigma^2)\\)).\n\nIn R, questo modello pu√≤ essere specificato con la sintassi Wilkinson:\ny ~ x1 + x2\n\n\n58.4.4.2 Dettaglio dei componenti\n\nIntercetta implicita:\nLa sintassi R include automaticamente l‚Äôintercetta (\\(\\alpha\\)) quando si utilizza il simbolo +. Ad esempio:\ny ~ x1 + x2\nequivale al modello: \\[\ny_i = \\alpha + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\varepsilon_i\n\\]\nEsclusione dell‚Äôintercetta:\nSe si desidera escludere l‚Äôintercetta (\\(\\alpha\\)), si utilizza - 1 nella specifica:\ny ~ x1 + x2 - 1\nQuesto produce un modello senza intercetta: \\[\ny_i = \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\varepsilon_i\n\\]\nInclusione esplicita dell‚Äôintercetta:\nAnche se √® implicita, l‚Äôintercetta pu√≤ essere specificata esplicitamente con 1 +:\ny ~ 1 + x1 + x2\nQuesto √® equivalente al modello con intercetta implicita.\nInterazione tra predittori:\nLa sintassi Wilkinson consente anche di specificare interazioni. Ad esempio, un‚Äôinterazione tra \\(x_1\\) e \\(x_2\\):\ny ~ x1 * x2\nEspande automaticamente il modello per includere: \\[\ny_i = \\alpha + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\beta_3 (x_{1i} \\cdot x_{2i}) + \\varepsilon_i\n\\]\n\n\n\n58.4.4.3 Esempio pratico\nSupponiamo di avere un dataset con una variabile dipendente y e due predittori x1 e x2. Ecco come specificare e adattare un modello di regressione lineare multipla in R:\n# Specifica del modello\nmodello &lt;- lm(y ~ x1 + x2, data = dataset)\n\n# Sommario del modello\nsummary(modello)\nQuesto codice:\n\nSpecifica un modello con intercetta e due predittori.\nAdatta il modello ai dati contenuti in dataset.\nCalcola i coefficienti (\\(\\alpha, \\beta_1, \\beta_2\\)), i valori di errore standard, i p-value (frequentisti) e altre statistiche di sintesi.\n\nIn sintesi, la sintassi di Wilkinson in R permette di esprimere modelli di regressione lineare in modo conciso e leggibile, rendendo il passaggio dal modello matematico al codice intuitivo e diretto.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>58</span>¬† <span class='chapter-title'>Linguaggi di programmazione probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_ppl.html#riflessioni-conclusive",
    "href": "chapters/mcmc/02_ppl.html#riflessioni-conclusive",
    "title": "58¬† Linguaggi di programmazione probabilistici",
    "section": "58.5 Riflessioni Conclusive",
    "text": "58.5 Riflessioni Conclusive\nI linguaggi di programmazione probabilistica (PPL) rappresentano strumenti potenti per la specificazione completa e flessibile di modelli bayesiani, consentendo agli utenti di definire ogni aspetto del modello, dai priori alla verosimiglianza, fino agli algoritmi di inferenza. Strumenti come Stan e PyMC permettono un controllo dettagliato sui modelli, rendendoli ideali per analisi avanzate e progetti personalizzati.\nTuttavia, questo livello di controllo richiede competenze di programmazione e una comprensione approfondita della statistica bayesiana. Per superare queste barriere e rendere l‚Äôinferenza bayesiana accessibile a un pubblico pi√π ampio, sono state sviluppate interfacce di alto livello come brms (basata su Stan) e Bambi (basata su PyMC). Questi strumenti semplificano enormemente il processo, consentendo agli utenti di specificare modelli statistici complessi senza la necessit√† di scrivere codice dettagliato, grazie a una sintassi intuitiva come quella di Wilkinson.\nIn sintesi:\n\nI PPL offrono flessibilit√† massima e un controllo completo, ma richiedono esperienza nella programmazione.\nLe interfacce di alto livello rendono possibile l‚Äôinferenza bayesiana anche a chi preferisce evitare la programmazione, garantendo un compromesso tra semplicit√† e capacit√† di personalizzazione.\n\nLa scelta tra un PPL e un‚Äôinterfaccia di alto livello dipende quindi dalle esigenze specifiche: chi necessita di modelli estremamente personalizzati e complessi opter√† per un PPL come Stan o PyMC, mentre chi desidera facilit√† d‚Äôuso senza rinunciare alla potenza dell‚Äôinferenza bayesiana trover√† in brms o Bambi strumenti ideali. In ogni caso, la crescente disponibilit√† di strumenti e risorse rende oggi l‚Äôinferenza bayesiana pi√π accessibile che mai, anche per chi non ha un background tecnico avanzato.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>58</span>¬† <span class='chapter-title'>Linguaggi di programmazione probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_ppl.html#bibliografia",
    "href": "chapters/mcmc/02_ppl.html#bibliografia",
    "title": "58¬† Linguaggi di programmazione probabilistici",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nWilkinson, G., & Rogers, C. (1973). Symbolic description of factorial models for analysis of variance. Journal of the Royal Statistical Society Series C: Applied Statistics, 22(3), 392‚Äì399.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>58</span>¬† <span class='chapter-title'>Linguaggi di programmazione probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html",
    "href": "chapters/mcmc/07_bayesian_workflow.html",
    "title": "59¬† Flusso di lavoro bayesiano",
    "section": "",
    "text": "59.1 Introduzione\nL‚Äôapplicazione dell‚Äôinferenza bayesiana nella risoluzione di problemi reali richiede un approccio strutturato e multidisciplinare, noto come workflow bayesiano. Questo processo iterativo e complesso va ben oltre la semplice applicazione della regola di Bayes, che pur costituendo il fondamento teorico dell‚Äôinferenza bayesiana, rappresenta solo il punto di partenza di un percorso analitico pi√π articolato.\nIl workflow bayesiano include molteplici fasi interconnesse, tra cui:\nPer esempio, immaginiamo di voler valutare l‚Äôefficacia di un intervento psicologico. Il ricercatore deve affrontare diverse decisioni: quali variabili includere (covariate), come modellare i dati gerarchici (ad esempio, individui e gruppi), e quali distribuzioni utilizzare per rappresentare incertezze (priori). Queste decisioni, lungi dall‚Äôessere definitive, richiedono continui aggiustamenti basati sui risultati intermedi.\nUn ulteriore aspetto critico √® la gestione di possibili problemi computazionali. Ad esempio, il campionamento MCMC (Markov Chain Monte Carlo) potrebbe non convergere correttamente, richiedendo modifiche al modello o all‚Äôapproccio algoritmico. Inoltre, il workflow bayesiano non si limita alla stima dei parametri: include la valutazione della capacit√† del modello di fare previsioni attendibili e il confronto tra modelli alternativi.\nInfine, √® fondamentale bilanciare la complessit√† del modello con la rilevanza pratica dei risultati. Modelli troppo semplici possono portare a conclusioni distorte, mentre modelli troppo complessi possono diventare difficili da interpretare. Il workflow bayesiano aiuta i ricercatori a navigare queste sfide, fornendo un quadro metodologico flessibile e iterativo.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>59</span>¬† <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html#introduzione",
    "href": "chapters/mcmc/07_bayesian_workflow.html#introduzione",
    "title": "59¬† Flusso di lavoro bayesiano",
    "section": "",
    "text": "Costruzione iterativa del modello: Definizione e revisione di modelli probabilistici che rappresentano i processi generativi dei dati.\nVerifica e validazione: Controllo della qualit√† delle stime e valutazione delle capacit√† predittive del modello.\nRisultati e interpretazione: Confronto tra modelli alternativi per trarre conclusioni solide.\nGestione di problemi computazionali: Identificazione e soluzione di eventuali difficolt√† nell‚Äôadattamento del modello.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>59</span>¬† <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html#principi-del-workflow-bayesiano",
    "href": "chapters/mcmc/07_bayesian_workflow.html#principi-del-workflow-bayesiano",
    "title": "59¬† Flusso di lavoro bayesiano",
    "section": "59.2 Principi del workflow bayesiano",
    "text": "59.2 Principi del workflow bayesiano\nUn workflow √® una sequenza strutturata di passi che definisce cosa costituisce una ‚Äúbuona pratica‚Äù in un determinato ambito. Nel contesto dell‚Äôinferenza bayesiana, il workflow si ispira a concetti come il Ciclo di Box e le pi√π recenti estensioni proposte da studiosi come Gelman e Riha.\n\n59.2.1 Il Ciclo di Box\nGeorge Box, uno dei pionieri della statistica moderna, ha sviluppato negli anni ‚Äô60 un approccio ciclico alla modellizzazione statistica, noto come Ciclo di Box. Questo paradigma sottolinea che la modellizzazione non √® un processo lineare, ma un ciclo continuo di miglioramento.\n\n\n\nFigura tratta da Blei (2014).\n\n\nIl Ciclo di Box si articola in una serie di fasi iterative:\n\nFormulazione del modello: Si costruisce un modello basato sulle conoscenze disponibili e sui dati osservati.\nInferenza: Si stimano i parametri del modello e si valutano le incertezze associate.\nValutazione del modello: Si verifica quanto il modello si adatta ai dati.\nRevisione del modello: Si corregge il modello in base alle discrepanze identificate.\n\nQuesto approccio iterativo √® il cuore del workflow bayesiano. La capacit√† dell‚Äôinferenza bayesiana di aggiornare le credenze a priori alla luce di nuovi dati lo rende particolarmente adatto a essere integrato nel Ciclo di Box. Pi√π recentemente, Gelman et al. (2020) hanno proposto una versione estesa del Ciclo di Box, fornendo una guida dettagliata per implementare un workflow bayesiano completo.\n\n\n\nFigura tratta da Gelman et al. (2020).",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>59</span>¬† <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html#costruzione-iterativa-del-modello",
    "href": "chapters/mcmc/07_bayesian_workflow.html#costruzione-iterativa-del-modello",
    "title": "59¬† Flusso di lavoro bayesiano",
    "section": "59.3 Costruzione iterativa del modello",
    "text": "59.3 Costruzione iterativa del modello\nIl processo di costruzione di un modello bayesiano pu√≤ essere descritto attraverso i seguenti passaggi:\n\nComprensione del fenomeno e formulazione del problema: Il punto di partenza √® definire chiaramente la domanda di ricerca. L‚Äôobiettivo non √® semplicemente descrivere correlazioni tra variabili, ma comprendere i meccanismi generativi dei dati.\nFormulazione matematica: Si costruisce un modello probabilistico che rappresenti il processo generativo, spesso utilizzando linguaggi probabilistici (PPL) come Stan o PyMC.\nImplementazione: Il modello viene tradotto in codice utilizzando interfacce software come R, Python o Julia, che permettono di adattare modelli complessi ai dati.\nVerifiche predittive a priori: Si simulano dati basandosi sulle distribuzioni a priori per verificare che i parametri scelti siano ragionevoli.\nAdattamento del modello: Si utilizza un algoritmo di campionamento per stimare i parametri del modello dai dati osservati (ad esempio, cmdstanr o cmdstanpy).\nDiagnostiche di convergenza: Si verifica che le catene MCMC abbiano raggiunto la convergenza, utilizzando strumenti come il valore R-hat.\nVerifiche predittive a posteriori: Si generano dati simulati a partire dalla distribuzione a posteriori per confrontarli con i dati reali e valutare la bont√† del modello.\nIterazione: Sulla base dei risultati, il modello viene raffinato e migliorato.\n\nQuesto processo iterativo consente di costruire modelli che siano sia robusti sia interpretabili.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>59</span>¬† <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html#analisi-multiverso",
    "href": "chapters/mcmc/07_bayesian_workflow.html#analisi-multiverso",
    "title": "59¬† Flusso di lavoro bayesiano",
    "section": "59.4 Analisi Multiverso",
    "text": "59.4 Analisi Multiverso\nL‚Äôanalisi multiverso, introdotta recentemente (Riha et al., 2024), amplia il workflow bayesiano, permettendo di esplorare simultaneamente molteplici modelli alternativi. Ogni modello rappresenta una combinazione unica di scelte modellistiche (ad esempio, covariate, distribuzioni a priori, o assunzioni sul processo generativo).\nI vantaggi principali dell‚Äôanalisi multiverso includono:\n\nTrasparenza: Documenta tutte le scelte di modellizzazione.\nEsplorazione completa: Riduce il rischio di trascurare ipotesi rilevanti.\nConfronto diretto: Permette di identificare i modelli pi√π adatti basandosi su criteri come l‚ÄôExpected Log-Predictive Density (ELPD).\nRobustezza: Esamina come le conclusioni cambiano tra diversi modelli.\nReplicabilit√†: Fornisce informazioni dettagliate per riprodurre l‚Äôanalisi e i risultati.\n\nQuesto approccio incorpora anche verifiche computazionali e analisi di sensibilit√†. Le prime identificano i modelli che necessitano di ulteriori verifiche per garantire l‚Äôaffidabilit√† dei risultati, mentre le seconde esaminano la robustezza delle conclusioni rispetto alle diverse scelte di modellazione e all‚Äôinfluenza delle priori sulle stime posteriori.\nTuttavia, la generazione di numerosi modelli pu√≤ complicare la gestione e l‚Äôinterpretazione dei risultati. Per affrontare questa sfida, Riha et al. (2024) propongono un metodo di ‚Äúiterative filtering‚Äù che comprende:\n\nCreazione di un multiverso iniziale di modelli.\nValutazione delle capacit√† predittive attraverso controlli predittivi posteriori (PPC) e calcolo dell‚Äôexpected log point-wise predictive density (elpd).\nVerifica della qualit√† computazionale, esaminando convergenza ed efficienza del campionamento MCMC.\nFiltraggio iterativo basato su criteri di qualit√† predefiniti.\nPossibilit√† di estendere il multiverso e ripetere il processo.\n\nQuesto approccio mantiene i vantaggi della multiverse analysis riducendo al contempo la complessit√† attraverso un filtraggio sistematico. Il risultato √® un workflow bayesiano pi√π robusto e informativo, che bilancia la necessit√† di considerare molteplici ipotesi modellistiche con l‚Äôesigenza pratica di focalizzarsi sui modelli pi√π promettenti per il problema in esame.\nUno dei casi di studio esaminati da Riha et al. (2024) riguarda l‚Äôanalisi del numero di crisi epilettiche in relazione a diverse variabili (covariate) e scelte di modellazione. I dati utilizzati provengono dallo studio di Leppik et al. (1987) e sono disponibili nel pacchetto R brms.\nSono stati confrontati 24 modelli statistici, ciascuno con una specifica formulazione matematica (illustrata nella Tabella seguente). La scelta dei modelli ha riguardato diverse combinazioni di covariate e di distribuzioni di probabilit√† per descrivere il fenomeno in esame.\n\n\n\nTabella 1 ricavata da Riha et al. (2024).\n\n\nPer valutare la capacit√† predittiva dei modelli, √® stato utilizzato il criterio ELPD (Expected Log-Predictive Density). I risultati sono riportati nel grafico seguente.\n\n\n\nFigura 12 ricavata da Riha et al. (2024).\n\n\nCome si pu√≤ osservare, i modelli presentano performance predittive differenti.\nOltre all‚ÄôELPD, sono stati condotti controlli predittivi posteriori (PPC) per valutare la plausibilit√† dei modelli rispetto ai dati osservati. I risultati dei PPC sono visualizzati nella figura seguente.\n\n\n\nFigura 13 ricavata da Riha et al. (2024).\n\n\nIl modello selezionato √® quello che ha mostrato il miglior valore di ELPD, evidenziando una buona capacit√† predittiva. Inoltre, i controlli PPC hanno confermato la plausibilit√† del modello rispetto ai dati osservati. Infine, il modello selezionato non ha presentato problemi computazionali durante la stima dei parametri.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>59</span>¬† <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html#riflessioni-conclusive",
    "href": "chapters/mcmc/07_bayesian_workflow.html#riflessioni-conclusive",
    "title": "59¬† Flusso di lavoro bayesiano",
    "section": "59.5 Riflessioni Conclusive",
    "text": "59.5 Riflessioni Conclusive\nIl workflow bayesiano rappresenta una strategia strutturata e iterativa per affrontare l‚Äôanalisi dei dati complessi. Attraverso strumenti come le verifiche predittive e l‚Äôanalisi multiverso, consente di sviluppare modelli solidi e capaci di adattarsi a nuovi dati e conoscenze. La sua integrazione con linguaggi come Stan o PyMC ne facilita l‚Äôapplicazione, rendendolo un approccio essenziale per la ricerca moderna.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>59</span>¬† <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html#bibliografia",
    "href": "chapters/mcmc/07_bayesian_workflow.html#bibliografia",
    "title": "59¬† Flusso di lavoro bayesiano",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlei, D. M. (2014). Build, compute, critique, repeat: Data analysis with latent variable models. Annual Review of Statistics and Its Application, 1(1), 203‚Äì232.\n\n\nBulbulia, J. A. (2023). A workflow for causal inference in cross-cultural psychology. Religion, Brain & Behavior, 13(3), 291‚Äì306.\n\n\nGelman, A., Vehtari, A., Simpson, D., Margossian, C. C., Carpenter, B., Yao, Y., Kennedy, L., Gabry, J., B√ºrkner, P.-C., & Modr√°k, M. (2020). Bayesian workflow. arXiv preprint arXiv:2011.01808.\n\n\nLeppik, I., Dreifuss, F., Porter, R., Bowman, T., Santilli, N., Jacobs, M., Crosby, C., Cloyd, J., Stackman, J., Graves, N., et al. (1987). A controlled study of progabide in partial seizures: methodology and results. Neurology, 37(6), 963‚Äì963.\n\n\nRiha, A. E., Siccha, N., Oulasvirta, A., & Vehtari, A. (2024). Supporting Bayesian modelling workflows with iterative filtering for multiverse analysis. arXiv preprint arXiv:2404.01688.\n\n\nSteegen, S., Tuerlinckx, F., Gelman, A., & Vanpaemel, W. (2016). Increasing transparency through a multiverse analysis. Perspectives on Psychological Science, 11(5), 702‚Äì712.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>59</span>¬† <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/introduction_linear_models.html",
    "href": "chapters/linear_models/introduction_linear_models.html",
    "title": "Introduzione",
    "section": "",
    "text": "Gli obiettivi di questo insegnamento riguardano i casi pi√π semplici di inferenza statistica, cio√® l‚Äôinferenza su una singola media, la differenza tra due medie, e l‚Äôanalisi del modello di regressione lineare (bivariato e multiplo) con predittori sia quantitativi sia qualitativi.\nTradizionalmente, l‚Äôinferenza su una media o sulla differenza tra due medie viene affrontata tramite il test t di Student, in un‚Äôottica frequentista. In una prospettiva pi√π moderna, tuttavia, questi argomenti possono essere inquadrati nel framework generale del modello lineare. Di conseguenza, in questa sezione della dispensa presenteremo il modello lineare sia dal punto di vista bayesiano sia frequentista, mostrando come l‚Äôinferenza su una o due medie rappresenti in realt√† un caso particolare di questo impianto metodologico.",
    "crumbs": [
      "Regressione",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html",
    "href": "chapters/linear_models/01_reglin_frequentist.html",
    "title": "60¬† La regressione lineare bivariata: un approccio frequentista",
    "section": "",
    "text": "60.1 Introduzione\nLa regressione √® una tecnica statistica che consente ai ricercatori di descrivere come i valori medi di una variabile risultato (variabile dipendente) variano in funzione di un insieme di predittori (variabili indipendenti).\nSecondo Gelman et al. (2021), i principali utilizzi della regressione includono:\nIn tutti questi contesti, √® fondamentale che il modello includa tutte le variabili rilevanti per la variabile di interesse. Ad esempio, in uno studio sull‚Äôefficacia di una psicoterapia per la depressione, fattori come et√†, condizioni di salute preesistenti e supporto sociale possono influenzare i risultati e dovrebbero essere considerati nell‚Äôanalisi. Se alcune di queste variabili vengono trascurate, le relazioni stimate tra predittori e risultato potrebbero risultare distorte. In altre parole, l‚Äôaccuratezza della regressione dipende dalla completezza del modello e dalla corretta selezione delle informazioni da includere.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>¬† <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#introduzione",
    "href": "chapters/linear_models/01_reglin_frequentist.html#introduzione",
    "title": "60¬† La regressione lineare bivariata: un approccio frequentista",
    "section": "",
    "text": "Previsione ‚Äì Modellare osservazioni esistenti o prevedere nuovi dati, sia continui che categoriali.\n\nAd esempio: prevedere punteggi futuri in un test, monitorare il benessere psicologico in uno studio longitudinale o classificare individui in base alla probabilit√† di successo in un compito cognitivo.\n\n\n\nEsplorazione delle associazioni ‚Äì Quantificare il grado di relazione tra una o pi√π variabili indipendenti e un risultato.\n\nAd esempio: studiare i tratti di personalit√† associati alla resilienza allo stress, analizzare la relazione tra stili di attaccamento infantile e capacit√† relazionali in et√† adulta, o valutare l‚Äôimpatto di fattori socio-economici sullo sviluppo cognitivo nei bambini.\n\n\n\nEstrapolazione ‚Äì Generalizzare i risultati osservati in un campione a una popolazione pi√π ampia.\n\nAd esempio: stimare l‚Äôefficacia di una terapia testata su studenti universitari per la popolazione generale, oppure prevedere l‚Äôimpatto di un intervento scolastico su un intero distretto partendo dai risultati osservati in alcune scuole.\n\n\n\nInferenza causale ‚Äì Stimare gli effetti di un trattamento o intervento.\n\nAd esempio: valutare l‚Äôefficacia di un programma di mindfulness sui livelli di ansia, stimare l‚Äôimpatto di una psicoterapia per il disturbo post-traumatico da stress o determinare l‚Äôeffetto di un intervento educativo su una popolazione diversificata.\n\n\n\n\n\n60.1.1 La storia dei modelli lineari\nI modelli lineari hanno una lunga storia nella statistica. Come riportato da Stigler (1986), il metodo dei minimi quadrati per adattare un modello di regressione lineare bivariata fu introdotto nel XVIII secolo per l‚Äôanalisi dei dati astronomici. Gli astronomi lo utilizzavano, ad esempio, per determinare il moto della Luna o per modellare i movimenti non periodici di Giove e Saturno.\nL‚Äôadozione di questi metodi fu favorita dalla qualit√† e dall‚Äôomogeneit√† delle misurazioni astronomiche, raccolte con strumenti standardizzati e sotto condizioni controllate. Al contrario, nelle scienze sociali, l‚Äôelevata variabilit√† dei dati‚Äîderivante da differenze individuali, contesti mutevoli e strumenti di misura meno precisi‚Äîrese pi√π complessa l‚Äôapplicazione della regressione e ne ritard√≤ la diffusione. Solo con lo sviluppo di tecniche statistiche pi√π avanzate, capaci di gestire questa complessit√†, la regressione divenne uno strumento essenziale anche nelle scienze umane e sociali.\n\n60.1.2 Tipologie di regressione\n√à utile distinguere tra tre principali categorie di regressione:\n\n\nRegressione bivariata ‚Äì Un solo predittore e una sola variabile dipendente.\n\n\nRegressione multipla ‚Äì Un solo risultato ma molteplici predittori.\n\n\nRegressione multivariata ‚Äì Molteplici risultati, con uno o pi√π predittori.\n\nIl caso bivariato, pur essendo il pi√π semplice, √® raramente sufficiente per descrivere fenomeni complessi, soprattutto in psicologia, dove molteplici fattori influenzano le variabili di interesse. Tuttavia, lo analizzeremo in dettaglio perch√© permette di comprendere la logica dell‚Äôanalisi di regressione in un contesto semplificato, privo di complicazioni matematiche. I concetti appresi saranno poi estesi ai modelli pi√π complessi, in cui la regressione multipla e la regressione multivariata richiederanno calcoli pi√π articolati e un‚Äôinterpretazione pi√π sofisticata dei parametri.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>¬† <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#il-modello-lineare-bivariato",
    "href": "chapters/linear_models/01_reglin_frequentist.html#il-modello-lineare-bivariato",
    "title": "60¬† La regressione lineare bivariata: un approccio frequentista",
    "section": "\n60.2 Il modello lineare bivariato",
    "text": "60.2 Il modello lineare bivariato\nNel contesto frequentista, il modello di regressione lineare bivariata consente di predire una variabile continua \\(y\\) sulla base di un singolo predittore continuo \\(x\\). La relazione tra le due variabili √® espressa dall‚Äôequazione della retta di regressione:\n\\[\ny_i = a + b x_i + e_i, \\quad i = 1, \\dots, n\n\\]\ndove:\n\n\n\\(a\\) √® l‚Äôintercetta (il valore atteso di \\(y\\) quando \\(x = 0\\)),\n\n\\(b\\) √® la pendenza della retta (coefficiente di regressione, che misura il cambiamento atteso in \\(y\\) per ogni unit√† di incremento in \\(x\\)),\n\n\\(e_i\\) √® l‚Äôerrore residuo (la differenza tra il valore osservato di \\(y_i\\) e il valore predetto dal modello).\n\n\n60.2.1 Aspetti principali\n\nStima dei coefficienti\nI coefficienti \\(a\\) e \\(b\\) vengono stimati mediante il metodo dei minimi quadrati, che minimizza la somma dei quadrati degli errori residui ((e_i^2)).\n\nInterpretazione dei coefficienti\n\n\n\\(a\\): rappresenta il valore medio previsto di \\(y\\) quando \\(x = 0\\).\n\n\n\\(b\\): indica la variazione media prevista in \\(y\\) per ogni unit√† di variazione in \\(x\\).\n\n\n\nValutazione del modello\nLa bont√† di adattamento del modello viene valutata attraverso:\n\nL‚Äôindice di determinazione (\\(R^2\\)), che misura la proporzione della varianza di \\(y\\) spiegata dal modello.\nL‚Äôanalisi dei residui, utile per individuare pattern non catturati dal modello e diagnosticare eventuali problemi.\n\n\n\n60.2.2 Verso modelli pi√π complessi\nQuesto capitolo illustrer√† come applicare e interpretare il modello di regressione bivariata, fornendo una base per comprendere il modello lineare multiplo e, pi√π in generale, gli approcci avanzati per l‚Äôinferenza causale. La logica della regressione bivariata sar√† estesa ai modelli con pi√π predittori, dove sar√† fondamentale distinguere tra relazioni spurie e reali effetti predittivi.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>¬† <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#la-predizione-dellintelligenza",
    "href": "chapters/linear_models/01_reglin_frequentist.html#la-predizione-dellintelligenza",
    "title": "60¬† La regressione lineare bivariata: un approccio frequentista",
    "section": "\n60.3 La Predizione dell‚ÄôIntelligenza",
    "text": "60.3 La Predizione dell‚ÄôIntelligenza\nNella presente discussione, esamineremo i dati kidiq che consistono in una raccolta di dati provenienti da un sondaggio su donne adulte americane e i loro figli, selezionati da un sotto-campione del National Longitudinal Survey of Youth (Gelman et al., 2021).\nNello specifico, ci concentreremo sulla relazione tra il punteggio di intelligenza del bambino (kid_score) e quello della madre (mom_iq). Ci proponiamo di valutare se e in quale misura l‚Äôintelligenza della madre possa prevedere l‚Äôintelligenza del bambino. Per fare ci√≤, inizieremo ad importare i dati nell‚Äôambiente R.\n\n# Caricamento dei dati\nkidiq &lt;- rio::import(here::here(\"data\", \"kidiq.dta\"))\n\n\n# Anteprima dei dati\nhead(kidiq)\n#&gt;   kid_score mom_hs mom_iq mom_work mom_age\n#&gt; 1        65      1 121.12        4      27\n#&gt; 2        98      1  89.36        4      25\n#&gt; 3        85      1 115.44        4      27\n#&gt; 4        83      1  99.45        3      25\n#&gt; 5       115      1  92.75        4      27\n#&gt; 6        98      0 107.90        1      18\n\nUn diagramma a dispersione per i dati di questo campione suggerisce la presenza di un‚Äôassociazione positiva tra l‚Äôintelligenza del bambino (kid_score) e l‚Äôintelligenza della madre (mom_iq).\n\nggplot(kidiq, aes(x = mom_iq, y = kid_score)) +\n  geom_point(alpha = 0.6) +\n  labs(x = \"QI della madre\", y = \"QI del bambino\") +\n  ggtitle(\"Diagramma a dispersione\")",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>¬† <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#stima-del-modello-di-regressione-lineare",
    "href": "chapters/linear_models/01_reglin_frequentist.html#stima-del-modello-di-regressione-lineare",
    "title": "60¬† La regressione lineare bivariata: un approccio frequentista",
    "section": "\n60.4 Stima del modello di regressione lineare",
    "text": "60.4 Stima del modello di regressione lineare\nCalcoliamo i coefficienti della retta di regressione utilizzando la funzione lm.\n\n# Modello di regressione lineare\nmod &lt;- lm(kid_score ~ mom_iq, data = kidiq)\n\n\n# Coefficienti stimati\ncoef(mod)\n#&gt; (Intercept)      mom_iq \n#&gt;       25.80        0.61\n\nCi sono per√≤ infinite rette che, in linea di principio, possono essere usate per ‚Äúapprossimare‚Äù la nube di punti nel diagramma a dispersione. √à dunque necessario introdurre dei vincoli per selezionare una di queste possibili rette. Il vincolo che viene introdotto dal modello di regressione √® quello di costringere la retta a passare per il punto \\((\\bar{x}, \\bar{y})\\).\n\n# Calcola le medie per mom_iq e kid_score\nmean_x &lt;- mean(kidiq$mom_iq, na.rm = TRUE)\nmean_y &lt;- mean(kidiq$kid_score, na.rm = TRUE)\n\n# Aggiungi il punto medio al grafico\nggplot(kidiq, aes(x = mom_iq, y = kid_score)) +\n  geom_point(alpha = 0.6) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"blue\") +\n  annotate(\n    \"point\", x = mean_x, y = mean_y, color = \"red\", size = 5, \n    shape = 4, stroke = 3) +\n  labs(x = \"QI della madre\", y = \"QI del bambino\") +\n  ggtitle(\"Retta di regressione\")\n\n\n\n\n\n\n\nUna retta di regressione che passa per il punto medio \\((\\bar{x}, \\bar{y})\\) (che rappresenta il centro di massa dei dati) √® preferibile dal punto di vista statistico poich√© minimizza la somma dei quadrati degli errori residui.\nIl campione √® costituito da \\(n\\) coppie di osservazioni (\\(x, y\\)).\n\\[\n\\begin{array}{cc}\n\\hline\nx_1 & y_1 \\\\\nx_2 & y_2 \\\\\nx_3 & y_3 \\\\\n\\vdots & \\vdots \\\\\nx_n & y_n \\\\\n\\hline\n\\end{array}\n\\]\nPer ciascuna coppia di valori \\(x_i, y_i\\), il modello di regressione si aspetta che il valore \\(y_i\\) sia associato al corrispondente valore \\(x_i\\) come indicato dalla seguente equazione\n\\[\n\\begin{equation}\n\\mathbb{E}(y_i) = a + b x_i ,\n\\end{equation}\n\\tag{60.1}\\]\novvero:\n\\[\n\\begin{array}{ccc}\n\\hline\nx_i & y_i & \\mathbb{E}(y_i) = a + b x_i \\\\\n\\hline\nx_1 & y_1 & a + b x_1 \\\\\nx_2 & y_2 & a + b x_2 \\\\\nx_3 & y_3 & a + b x_3 \\\\\n\\vdots & \\vdots & \\vdots \\\\\nx_n & y_n & a + b x_n \\\\\n\\hline\n\\end{array}\n\\]\nI valori \\(y_i\\) corrispondono, nell‚Äôesempio che stiamo discutendo, alla variabile kid_score. I primi 10 valori della variabile \\(y\\) sono i seguenti:\n\nkidiq$kid_score[0:10]\n#&gt;  [1]  65  98  85  83 115  98  69 106 102  95\n\nPer fare riferimento a ciascuna osservazione usiamo l‚Äôindice \\(i\\). Quindi, ad esempio, \\(y_2\\) √® uguale a\n\nkidiq$kid_score[2]\n#&gt; [1] 98\n\nIl modello di regressione lineare bivariata, rappresentato dall‚Äôequazione \\(y_i = a + b x_i + e_i\\), descrive la relazione tra le variabili \\(x\\) e \\(y\\), dove \\(y\\) √® la variabile dipendente (nel nostro esempio, la variabile kid_score) e \\(x\\) √® la variabile indipendente (nel nostro esempio, la variabile mom_iq).\nIl valore di \\(y\\) √® la somma di due componenti:\n\nla componente deterministica, \\(\\hat{y}_i = a + b x_i\\), rappresenta la porzione della \\(y\\) che √® prevedibile conoscendo il valore di \\(x\\);\nla componente aleatoria, \\(e_i\\), rappresenta la porzione della \\(y\\) che non √® prevedibile dal modello.\n\nIl modello lineare cerca di trovare i coefficienti \\(a\\) e \\(b\\) che permettono di prevedere la componente deterministica di \\(y\\) conoscendo il valore di \\(x\\). Tuttavia, poich√© la retta √® solo un‚Äôapprossimazione della relazione tra \\(x\\) e \\(y\\), la componente deterministica rappresenta solo una stima approssimata della vera relazione tra le due variabili.\nPer valutare l‚Äôaccuratezza del modello di regressione lineare, √® necessario calcolare il residuo\n\\[\ne_i = y_i - (a + b x_i) ,\n\\tag{60.2}\\]\novvero la differenza tra il valore osservato di \\(y\\) e il valore previsto dal modello, \\(\\hat{y}\\). La dimensione del residuo indica quanto la componente aleatoria contribuisce al valore osservato di \\(y\\).\nIl modello di regressione lineare ha tre obiettivi (Fox, 2015):\n\nil primo √® quello di trovare i coefficienti \\(a\\) e \\(b\\) che permettono di prevedere la componente deterministica di \\(y\\) conoscendo il valore di \\(x\\);\nil secondo obiettivo √® quello di valutare l‚Äôaccuratezza della predizione fornita dal modello di regressione lineare;\ninfine, il terzo obiettivo √® quello dell‚Äôinferenza, ovvero quello di capire quali relazioni esistono tra la relazione tra \\(x\\) e \\(y\\) osservata nel campione e la relazione tra le due variabili nella popolazione.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>¬† <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#stima-dei-coefficienti-di-regressione",
    "href": "chapters/linear_models/01_reglin_frequentist.html#stima-dei-coefficienti-di-regressione",
    "title": "60¬† La regressione lineare bivariata: un approccio frequentista",
    "section": "\n60.5 Stima dei coefficienti di regressione",
    "text": "60.5 Stima dei coefficienti di regressione\nIn breve, stiamo cercando di descrivere una relazione tra due variabili, il QI della madre e il QI del bambino, utilizzando un modello di regressione lineare. L‚Äôequazione lineare che descrive la relazione tra le due variabili √® della forma \\(\\hat{y}_i = a_i + bx_i\\), dove \\(\\hat{y}_i\\) rappresenta la previsione per il QI del bambino \\(i\\)-esimo, \\(a_i\\) e \\(b\\) sono i coefficienti di regressione che vogliamo trovare e \\(x_i\\) √® il QI della madre del bambino \\(i\\)-esimo.\nPer trovare i coefficienti di regressione, dobbiamo introdurre dei vincoli per limitare lo spazio delle possibili soluzioni. Il primo vincolo √® che la retta di regressione deve passare per il baricentro del grafico a dispersione. Il secondo vincolo √® che vogliamo minimizzare la somma dei quadrati dei residui, ovvero la differenza tra il valore osservato e il valore previsto dal modello. I coefficienti di regressione che soddisfano questi vincoli si chiamano coefficienti dei minimi quadrati.\nIl problema di trovare i coefficienti di regressione \\(a\\) e \\(b\\) che minimizzano la somma dei quadrati dei residui ha una soluzione analitica. Questa soluzione si ottiene trovando il punto di minimo di una superficie tridimensionale che rappresenta la somma dei quadrati dei residui. Il punto di minimo √® quello per cui il piano tangente alla superficie nelle due direzioni \\(a\\) e \\(b\\) √® piatto, cio√® le derivate parziali rispetto ad \\(a\\) e \\(b\\) sono uguali a zero. In pratica, ci√≤ significa risolvere un sistema di equazioni lineari con due incognite \\(a\\) e \\(b\\), noto come equazioni normali.\nLa soluzione delle equazioni normali ci fornisce i coefficienti di regressione stimati, che minimizzano la somma dei quadrati dei residui. La formula per il coefficiente \\(a\\) √®\n\\[\na = \\bar{y} - b \\bar{x} ,\n\\tag{60.3}\\]\nla formula per il coefficiente \\(b\\) √®\n\\[\nb = \\frac{Cov(x, y)}{Var(x)},\n\\tag{60.4}\\]\ndove \\(\\bar{x}\\) e \\(\\bar{y}\\) sono le medie delle variabili \\(x\\) e \\(y\\), \\(Cov(x,y)\\) √® la covarianza tra \\(x\\) e \\(y\\) e \\(Var(x)\\) √® la varianza di \\(x\\).\nQueste equazioni rappresentano la stima dei minimi quadrati dei coefficienti di regressione che ci permettono di trovare la retta che minimizza la somma dei quadrati dei residui.\n\n60.5.1 Calcolo manuale dei coefficienti di regressione\nCalcoliamo i coefficientii dei minimi quadrati con l‚ÄôEquazione¬†60.3 e l‚ÄôEquazione¬†60.4:\n\n# Calcolo manuale dei coefficienti\ncov_xy &lt;- cov(kidiq$kid_score, kidiq$mom_iq)  # Covarianza tra le due variabili\nvar_x &lt;- var(kidiq$mom_iq)  # Varianza della variabile indipendente\nb &lt;- cov_xy / var_x  # Pendenza (coefficiente b)\nb\n#&gt; [1] 0.61\n\n\n# Intercetta (coefficiente a)\na &lt;- mean(kidiq$kid_score) - b * mean(kidiq$mom_iq)\na\n#&gt; [1] 25.8\n\nI risultati replicano quelli ottenuti in precedenza con lm().\n\n60.5.2 Interpretazione\nIl coefficiente \\(a\\) indica l‚Äôintercetta della retta di regressione nel diagramma a dispersione. Questo valore rappresenta il punto in cui la retta di regressione interseca l‚Äôasse \\(y\\) del sistema di assi cartesiani. Tuttavia, in questo caso specifico, il valore di \\(a\\) non √® di particolare interesse poich√© corrisponde al valore della retta di regressione quando l‚Äôintelligenza della madre √® pari a 0, il che non ha senso nella situazione reale. Successivamente, vedremo come √® possibile trasformare i dati per fornire un‚Äôinterpretazione utile del coefficiente \\(a\\).\nInvece, il coefficiente \\(b\\) indica la pendenza della retta di regressione, ovvero di quanto aumenta (se \\(b\\) √® positivo) o diminuisce (se \\(b\\) √® negativo) la retta di regressione in corrispondenza di un aumento di 1 punto della variabile \\(x\\). Nel caso specifico del QI delle madri e dei loro figli, il coefficiente \\(b\\) ci indica che un aumento di 1 punto del QI delle madri √® associato, in media, a un aumento di 0.61 punti del QI dei loro figli.\nIn pratica, il modello di regressione lineare cerca di prevedere le medie dei punteggi del QI dei figli in base al QI delle madri. Ci√≤ significa che non √® in grado di prevedere esattamente il punteggio di ciascun bambino in funzione del QI della madre, ma solo una stima della media dei punteggi dei figli quando il QI delle madri aumenta o diminuisce di un punto.\nIl coefficiente \\(b\\) ci dice di quanto aumenta (o diminuisce) in media il QI dei figli per ogni unit√† di aumento (o diminuzione) del QI della madre. Nel nostro caso, se il QI della madre aumenta di un punto, il QI dei figli aumenta in media di 0.61 punti.\n√à importante comprendere che il modello statistico di regressione lineare non √® in grado di prevedere il valore preciso di ogni singolo bambino, ma solo una stima della media dei punteggi del QI dei figli quando il QI delle madri aumenta o diminuisce. Questa stima √® basata su una distribuzione di valori possibili che si chiama distribuzione condizionata \\(p(y \\mid x_i)\\).\nUna rappresentazione grafica del valore predetto dal modello di regressione, \\(\\hat{y}_i = a + bx_i\\) √® stato fornito in precedenza. Il diagramma presenta ciascun valore \\(\\hat{y}_i = a + b x_i\\) in funzione di \\(x_i\\). I valori predetti dal modello di regressione sono i punti che stanno sulla retta di regressione.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>¬† <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#residui",
    "href": "chapters/linear_models/01_reglin_frequentist.html#residui",
    "title": "60¬† La regressione lineare bivariata: un approccio frequentista",
    "section": "\n60.6 Residui",
    "text": "60.6 Residui\nIn precedenza abbiamo detto che il residuo, ovvero la componente di ciascuna osservazione \\(y_i\\) che non viene predetta dal modello di regressione, corrisponde alla distanza verticale tra il valore \\(y_i\\) osservato e il valore \\(\\hat{y}_i\\) predetto dal modello di regressione:\n\\[\ne_i = y_i - (a + b x_i).\n\\]\nPer fare un esempio numerico, consideriamo il punteggio osservato del QI del primo bambino.\n\nkidiq$kid_score[1]\n#&gt; [1] 65\n\nIl QI della madre √®\n\nkidiq$mom_iq[1]\n#&gt; [1] 121.1\n\nPer questo bambino, il valore predetto dal modello di regressione √®\n\na + b * kidiq$mom_iq[1]\n#&gt; [1] 99.68\n\nL‚Äôerrore che compiamo per predire il QI del bambino utilizzando il modello di regressione (ovvero, il residuo) √®\n\nkidiq$kid_score[1] - (a + b * kidiq$mom_iq[1])\n#&gt; [1] -34.68\n\nPer tutte le osservazioni abbiamo\n\nres &lt;- kidiq$kid_score - (a + b * kidiq$mom_iq)\n\n√à una propriet√† del modello di regressione (calcolato con il metodo dei minimi quadrati) che la somma dei residui sia uguale a zero.\n\nsum(res)\n#&gt; [1] 1.444e-11\n\nQuesto significa che ogni valore osservato \\(y_i\\) viene scomposto dal modello di regressione in due componenti distinte. La componente deterministica \\(\\hat{y}_i\\), che √® predicibile da \\(x_i\\), √® data da \\(\\hat{y}_i = a + b x_i\\). Il residuo, invece, √® dato da \\(e_i = y_i - \\hat{y}_i\\). La somma di queste due componenti, ovviamente, riproduce il valore osservato.\n\n# Creazione di un data frame con i valori calcolati\ndf &lt;- data.frame(\n  kid_score = kidiq$kid_score,\n  mom_iq = kidiq$mom_iq,\n  y_hat = a + b * kidiq$mom_iq,\n  e = kidiq$kid_score - (a + b * kidiq$mom_iq),\n  y_hat_plus_e = (a + b * kidiq$mom_iq) + (kidiq$kid_score - (a + b * kidiq$mom_iq))\n)\n\n# Visualizzazione dei primi 6 valori\nhead(df)\n#&gt;   kid_score mom_iq y_hat       e y_hat_plus_e\n#&gt; 1        65 121.12 99.68 -34.678           65\n#&gt; 2        98  89.36 80.31  17.692           98\n#&gt; 3        85 115.44 96.22 -11.217           85\n#&gt; 4        83  99.45 86.46  -3.462           83\n#&gt; 5       115  92.75 82.37  32.628          115\n#&gt; 6        98 107.90 91.62   6.383           98",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>¬† <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#trasformazione-dei-dati",
    "href": "chapters/linear_models/01_reglin_frequentist.html#trasformazione-dei-dati",
    "title": "60¬† La regressione lineare bivariata: un approccio frequentista",
    "section": "\n60.7 Trasformazione dei dati",
    "text": "60.7 Trasformazione dei dati\nIn generale, per variabili a livello di scala ad intervalli, l‚Äôintercetta del modello di regressione lineare non ha un‚Äôinterpretazione utile. Questo perch√© l‚Äôintercetta indica il valore atteso di \\(y\\) quando \\(x = 0\\), ma in caso di variabili a scala di intervalli, il valore ‚Äú0‚Äù di \\(x\\) √® arbitrario e non corrisponde ad un ‚Äúassenza‚Äù della variabile \\(x\\). Ad esempio, un QI della madre pari a 0 non indica un‚Äôassenza di intelligenza, ma solo un valore arbitrario del test usato per misurare il QI. Quindi, sapere il valore medio del QI dei bambini quando il QI della madre √® 0 non √® di alcun interesse.\nPer fornire all‚Äôintercetta del modello di regressione un‚Äôinterpretazione pi√π utile, dobbiamo trasformare le osservazioni di \\(x\\). Per esempio, esprimiamo \\(x\\) come differenza dalla media. Chiamiamo questa nuova variabile \\(xd\\):\n\nkidiq$xd &lt;- kidiq$mom_iq - mean(kidiq$mom_iq)\n\nkidiq |&gt; \n  head()\n#&gt;   kid_score mom_hs mom_iq mom_work mom_age       xd\n#&gt; 1        65      1 121.12        4      27  21.1175\n#&gt; 2        98      1  89.36        4      25 -10.6381\n#&gt; 3        85      1 115.44        4      27  15.4432\n#&gt; 4        83      1  99.45        3      25  -0.5504\n#&gt; 5       115      1  92.75        4      27  -7.2543\n#&gt; 6        98      0 107.90        1      18   7.9018\n\nSe ora usiamo le coppie di osservazioni \\((xd_i, y_i)\\), il diagramma a dispersione assume la forma seguente.\n\n# Aggiungiamo una nuova variabile centrata (scarti dalla media)\nkidiq &lt;- kidiq %&gt;%\n  mutate(xd = mom_iq - mean(mom_iq))\n\n# Calcolo della retta di regressione\nb &lt;- cov(kidiq$xd, kidiq$kid_score) / var(kidiq$xd)\na &lt;- mean(kidiq$kid_score) - b * mean(kidiq$xd)\n\n# Grafico con ggplot2\nggplot(kidiq, aes(x = xd, y = kid_score)) +\n  geom_point(alpha = 0.6) +  # Punti del grafico\n  geom_abline(intercept = a, slope = b, color = \"blue\") +  # Retta di regressione\n  labs(\n    x = \"QI della madre (scarti dalla media)\", \n    y = \"QI del bambino\"\n  ) +\n  ggtitle(\"Retta di regressione sui dati centrati\")\n\n\n\n\n\n\n\nIn pratica, abbiamo spostato tutti i punti del grafico lungo l‚Äôasse delle \\(x\\), in modo tale che la media dei valori di \\(x\\) sia uguale a 0. Questo non ha cambiato la forma dei punti nel grafico, ma ha solo spostato l‚Äôorigine dell‚Äôasse \\(x\\). La pendenza della linea di regressione tra \\(x\\) e \\(y\\) rimane la stessa, sia per i dati originali che per quelli trasformati. L‚Äôunica cosa che cambia √® il valore dell‚Äôintercetta della linea di regressione, che ora ha un‚Äôinterpretazione pi√π significativa.\n\nfm1 &lt;- lm(kid_score ~ xd, data = kidiq)\ncoef(fm1)\n#&gt; (Intercept)          xd \n#&gt;       86.80        0.61\n\nL‚Äôintercetta rappresenta il punto in cui la retta di regressione incontra l‚Äôasse \\(y\\) nel diagramma a dispersione. Nel caso dei dati trasformati, abbiamo spostato la nube di punti lungo l‚Äôasse \\(x\\) di una quantit√† pari a \\(x - \\bar{x}\\), ma le relazioni spaziali tra i punti rimangono invariate. Pertanto, la pendenza della retta di regressione non cambia rispetto ai dati non trasformati. Tuttavia, il valore dell‚Äôintercetta viene influenzato dalla trasformazione. In particolare, poich√© \\(xd = 0\\) corrisponde a \\(x = \\bar{x}\\) nei dati grezzi, l‚Äôintercetta del modello di regressione lineare calcolata sui dati trasformati corrisponde al valore atteso di \\(y\\) quando \\(x\\) assume il valore medio sulla scala dei dati grezzi. In altre parole, l‚Äôintercetta del modello di regressione lineare sui dati trasformati rappresenta il valore atteso del QI dei bambini corrispondente al QI medio delle madri.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>¬† <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#il-metodo-dei-minimi-quadrati",
    "href": "chapters/linear_models/01_reglin_frequentist.html#il-metodo-dei-minimi-quadrati",
    "title": "60¬† La regressione lineare bivariata: un approccio frequentista",
    "section": "\n60.8 Il metodo dei minimi quadrati",
    "text": "60.8 Il metodo dei minimi quadrati\nPer stimare i coefficienti \\(a\\) e \\(b\\), possiamo minimizzare la somma dei quadrati dei residui tra i valori osservati \\(y_i\\) e quelli previsti \\(a + b x_i\\).\nIniziamo con il creare una griglia per i valori di \\(b\\). Supponiamo che il valore di \\(a\\) sia noto (\\(a = 25.79978\\)). Usiamo R per creare una griglia di valori possibili per \\(b\\).\n\n# Griglia di valori per b\nb_grid &lt;- seq(0, 1, length.out = 1001)\na &lt;- 25.79978  # Intercetta nota\n\nDefiniamo ora una funzione che calcola la somma dei quadrati dei residui (\\(SSE\\)) per ciascun valore di \\(b\\).\n\n# Funzione per la somma dei quadrati dei residui\nsse &lt;- function(a, b, x, y) {\n  sum((y - (a + b * x))^2)\n}\n\nApplichiamo la funzione sse alla griglia di valori \\(b\\) per calcolare la somma dei quadrati dei residui per ogni valore di \\(b\\).\n\n# Calcolo di SSE per ciascun valore di b\nsse_vals &lt;- sapply(\n  b_grid, \n  function(b) sse(a, b, kidiq$mom_iq, kidiq$kid_score)\n)\n\n\n\nsapply:\n\n√à una funzione di R che applica una funzione ad ogni elemento di un vettore (o lista) e restituisce i risultati in un vettore.\nQui, applica la funzione sse a ciascun valore di \\(b\\) contenuto in b_grid.\n\n\n\nfunction(b):\n\n√à una funzione anonima definita al volo per specificare come calcolare \\(SSE\\) per ciascun valore di \\(b\\).\nAll‚Äôinterno, viene chiamata la funzione sse(a, b, x, y) con i seguenti parametri:\n\n\na: il valore dell‚Äôintercetta (fissato in precedenza o noto).\n\nb: il valore corrente nella griglia b_grid.\n\nx: la variabile indipendente del dataset (kidiq$mom_iq).\n\ny: la variabile dipendente del dataset (kidiq$kid_score).\n\n\n\n\nIl risultato √® un vettore, sse_vals, che contiene i valori di \\(SSE\\) corrispondenti a ciascun valore di \\(b\\) in b_grid.\n\nTracciamo un grafico che mostra la somma dei quadrati dei residui (\\(SSE\\)) in funzione dei valori di \\(b\\), evidenziando il minimo.\n\n# Identificazione del valore di b che minimizza SSE\nb_min &lt;- b_grid[which.min(sse_vals)]\n\n# Creazione del dataframe per ggplot\ndat &lt;- data.frame(b_grid = b_grid, sse_vals = sse_vals)\n\n# Genera il grafico\nggplot(dat, aes(x = b_grid, y = sse_vals)) +\n  geom_line(color = \"blue\", linewidth = 1) +  \n  annotate(\n    \"point\", x = b_min, y = min(sse_vals),\n    color = \"red\", size = 3\n  ) +  # Punto minimo\n  labs(\n    x = expression(paste(\"Possibili valori di \", hat(beta))),\n    y = \"Somma dei quadrati dei residui (SSE)\",\n    title = \"Minimizzazione dei residui quadratici\"\n  ) +\n  annotate(\n    \"text\", x = b_min, y = min(sse_vals), \n    label = expression(hat(beta)), color = \"red\", vjust = -1, hjust = 0.5\n  )\n\n\n\n\n\n\n\nInfine, identifichiamo il valore di \\(b\\) che minimizza la somma dei quadrati dei residui.\n\nb_min\n#&gt; [1] 0.61\n\nCon questa simulazione, abbiamo stimato il coefficiente \\(b\\) minimizzando la somma dei quadrati dei residui.\nQuesto approccio pu√≤ essere esteso per stimare simultaneamente entrambi i coefficienti (\\(a\\) e \\(b\\)) utilizzando metodi di ottimizzazione pi√π avanzati, come optim in R.\n\noptim_result &lt;- optim(\n  par = c(a = 25, b = 0.5),  # Valori iniziali\n  fn = function(params) {\n    a &lt;- params[1]\n    b &lt;- params[2]\n    sse(a, b, kidiq$mom_iq, kidiq$kid_score)\n  }\n)\n\n# Coefficienti stimati\noptim_result$par\n#&gt;       a       b \n#&gt; 25.7874  0.6101\n\nQuesta simulazione illustra come, tramite il metodo dei minimi quadrati, sia possibile stimare i parametri di un modello bivariato di regressione.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>¬† <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#lerrore-standard-della-regressione",
    "href": "chapters/linear_models/01_reglin_frequentist.html#lerrore-standard-della-regressione",
    "title": "60¬† La regressione lineare bivariata: un approccio frequentista",
    "section": "\n60.9 L‚Äôerrore standard della regressione",
    "text": "60.9 L‚Äôerrore standard della regressione\nIl secondo obiettivo del modello di regressione lineare √® quello di misurare quanto della variabilit√† di \\(y\\) possa essere spiegata dalla variabilit√† di \\(x\\) per ogni osservazione. L‚Äôindice di bont√† di adattamento del modello viene fornito dalla deviazione standard dei residui, chiamata anche errore standard della stima (o errore standard della regressione), \\(s_e\\).\nPer calcolare \\(s_e\\), si sommano i quadrati dei residui \\(e_i\\) per ogni osservazione e si divide per \\(n-2\\), dove \\(n\\) rappresenta la numerosit√† del campione e \\(2\\) il numero di coefficienti stimati nel modello di regressione. Si prende poi la radice quadrata del risultato:\n\\[\n\\sqrt{\\frac{1}{n-2} \\sum_{i=1}^n \\big(y_i - (\\hat{a} + \\hat{b}x_i)\\big)^2},\n\\tag{60.5}\\]\nL‚Äôindice \\(s_e\\) possiede la stessa unit√† di misura di \\(y\\) ed √® una stima della deviazione standard dei residui nella popolazione.\nIllustriamo il calcolo di \\(s_e\\) con i dati a disposizione. I residui \\(e\\) possono essere calcolati sottraendo ai valori osservati \\(y_i\\) i valori predetti dal modello \\(a + b x_i\\):\n\n# Calcolo dei residui\ne &lt;- kidiq$kid_score - (a + b * kidiq$mom_iq)\n\n# Mostriamo i primi 10 residui\nhead(e, 10)\n#&gt;  [1] -34.678  17.692 -11.217  -3.462  32.628   6.383 -41.521   3.865  26.414\n#&gt; [10]  11.208\n\nCalcoliamo il valore medio assoluto dei residui per avere un‚Äôindicazione della deviazione media rispetto alla retta di regressione.\n\n# Media assoluta dei residui\nmean(abs(e))\n#&gt; [1] 14.47\n\nL‚Äôerrore standard della stima \\(s_e\\) si calcola come la radice quadrata della somma dei quadrati dei residui divisa per \\(n-2\\):\n\n# Calcolo di s_e\nse &lt;- sqrt(sum(e^2) / (length(e) - 2))\nse\n#&gt; [1] 18.27\n\nNotiamo che il valore medio assoluto dei residui e l‚Äôerrore standard \\(s_e\\) non sono identici, ma hanno lo stesso ordine di grandezza. \\(s_e\\) √® una misura pi√π rigorosa della deviazione standard dei residui.\nQuesta analisi dimostra come \\(s_e\\) consenta di valutare quanto le previsioni del modello si discostino (in media) dai dati osservati.\n\n60.9.1 Sottostima dell‚ÄôErrore nel Modello di Regressione\nCome discusso da Gelman et al. (2021), l‚Äôerrore standard della regressione tende a sottostimare la vera deviazione standard \\(\\sigma\\) dell‚Äôerrore nel modello di regressione nella popolazione. Questa sottostima √® dovuta al fenomeno del sovradimensionamento, dato che i parametri \\(a\\) e \\(b\\) sono stimati utilizzando gli stessi \\(n\\) punti dati su cui vengono calcolati i residui. In altre parole, i residui non sono del tutto indipendenti dal modello.\nUn approccio alternativo per valutare l‚Äôerrore predittivo e mitigare il problema del sovradimensionamento √® la validazione incrociata. In particolare, l‚Äôapproccio leave-one-out (LOOCV) offre una soluzione semplice ed efficace. Questo metodo consiste nell‚Äôadattare il modello \\(n\\) volte, escludendo ogni volta un punto dati, adattando il modello ai rimanenti \\(n-1\\) punti, e utilizzando tale modello per predire l‚Äôosservazione esclusa.\n\n60.9.1.1 Procedura Leave-One-Out:\n\n\nPer \\(i = 1, \\ldots, n\\):\n\nAdatta il modello \\(y = a + bx + \\text{errore}\\) ai \\(n-1\\) punti dati \\((x, y)_j, j \\neq i\\). Denomina i coefficienti stimati come \\(\\hat{a}_{-i}\\) e \\(\\hat{b}_{-i}\\).\n\nCalcola il residuo validato incrociato:\n\\[\ne_{\\text{CV}} = y_i - (\\hat{a}_{-i} + \\hat{b}_{-i} x_i).\n\\]\n\nSalva il residuo al quadrato per il calcolo successivo.\n\n\n\nCalcola infine la stima di \\(\\sigma_{\\text{CV}}\\) come:\n\\[\n\\sigma_{\\text{CV}} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n e_{\\text{CV}}^2}.\n\\]\n\n\n60.9.1.2 Applicazione Pratica:\nEcco un esempio applicato al modello che predice l‚Äôintelligenza del bambino (\\(\\texttt{kid\\_score}\\)) in funzione dell‚Äôintelligenza della madre (\\(\\texttt{mom\\_iq}\\)) utilizzando il dataset kidiq.\n\noptions(round = 5)\n\n# Array per salvare i residui validati incrociati\nresiduals_cv &lt;- numeric(nrow(kidiq))\n\n# Loop per la validazione incrociata leave-one-out\nfor (i in 1:nrow(kidiq)) {\n  # Dati di training escludendo l'i-esimo punto\n  train_data &lt;- kidiq[-i, ]\n  test_data &lt;- kidiq[i, ]\n  \n  # Addestramento del modello\n  model &lt;- lm(kid_score ~ mom_iq, data = train_data)\n  \n  # Predizione sull'i-esimo punto\n  y_pred &lt;- predict(model, newdata = test_data)\n  \n  # Calcolo del residuo validato incrociato\n  residual_cv &lt;- test_data$kid_score - y_pred\n  residuals_cv[i] &lt;- residual_cv^2\n}\n\n# Calcolo di sigma_cv\nsigma_cv &lt;- sqrt(mean(residuals_cv))\n\ncat(\"Stima di œÉ_CV:\", sigma_cv, \"\\n\")\n#&gt; Stima di œÉ_CV: 18.31\n\nCalcoliamo ora la stima tradizionale di \\(\\sigma\\) utilizzando il modello completo e confrontiamola con \\(\\sigma_{\\text{CV}}\\).\n\n# Modello completo\nfm2 &lt;- lm(kid_score ~ mom_iq, data = kidiq)\n\n# Stima tradizionale dell'errore standard della regressione\nres &lt;- summary(fm2)\ncat(\"Errore standard della regressione (tradizionale):\", res$sigma, \"\\n\")\n#&gt; Errore standard della regressione (tradizionale): 18.27\n\nNel caso analizzato, i valori stimati di \\(\\sigma_{\\text{CV}}\\) e \\(\\hat{\\sigma}_e\\) tradizionale possono risultare molto simili. Tuttavia, in generale, la stima di \\(\\sigma_{\\text{CV}}\\) tende a essere leggermente superiore, in quanto riflette meglio l‚Äôerrore predittivo su dati non utilizzati per adattare il modello. Questo rende \\(\\sigma_{\\text{CV}}\\) una misura pi√π robusta e conservativa dell‚Äôincertezza del modello.\nIn conclusione, la validazione incrociata, e in particolare l‚Äôapproccio LOOCV, rappresenta uno strumento importante per valutare le performance predittive di un modello di regressione e per ottenere stime pi√π affidabili della deviazione standard dell‚Äôerrore.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>¬† <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#indice-di-determinazione",
    "href": "chapters/linear_models/01_reglin_frequentist.html#indice-di-determinazione",
    "title": "60¬† La regressione lineare bivariata: un approccio frequentista",
    "section": "\n60.10 Indice di determinazione",
    "text": "60.10 Indice di determinazione\nUn importante risultato dell‚Äôanalisi di regressione riguarda la scomposizione della varianza della variabile dipendente \\(y\\) in due componenti: la varianza spiegata dal modello e la varianza residua. Questa scomposizione √® descritta mediante l‚Äôindice di determinazione \\(R^2\\), che fornisce una misura della bont√† di adattamento del modello ai dati del campione.\nPer una generica osservazione \\(x_i, y_i\\), la deviazione di \\(y_i\\) rispetto alla media \\(\\bar{y}\\) pu√≤ essere espressa come la somma di due componenti: il residuo \\(e_i=y_i- \\hat{y}_i\\) e lo scarto di \\(\\hat{y}_i\\) rispetto alla media \\(\\bar{y}\\):\n\\[\ny_i - \\bar{y} = (y_i- \\hat{y}_i) + (\\hat{y}_i - \\bar{y}) = e_i + (\\hat{y}_i - \\bar{y}).\n\\]\nLa varianza totale di \\(y\\) pu√≤ quindi essere scritta come:\n\\[\n\\sum_{i=1}^{n}(y_i - \\bar{y})^2 = \\sum_{i=1}^{n}(e_i + (\\hat{y}_i - \\bar{y}))^2.\n\\]\nSviluppando il quadrato e sommando, si ottiene:\n\\[\n\\sum_{i=1}^{n}(y_i - \\bar{y})^2 = \\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2 + \\sum_{i=1}^{n}(\\hat{y}_i - \\bar{y})^2.\n\\tag{60.6}\\]\nIl primo termine rappresenta la varianza residua, mentre il secondo termine rappresenta la varianza spiegata dal modello. Questa scomposizione della devianza va sotto il nome di teorema della scomposizione della devianza.\nL‚Äôindice di determinazione \\(R^2\\) √® definito come il rapporto tra la varianza spiegata e la varianza totale:\n\\[\nR^2 = \\frac{\\sum_{i=1}^{n}(\\hat{y}_i - \\bar{y})^2}{\\sum_{i=1}^{n}(y_i - \\bar{y})^2}.\n\\tag{60.7}\\]\nQuesto indice varia tra 0 e 1 e indica la frazione di varianza totale di \\(y\\) spiegata dal modello di regressione lineare. Un valore alto di \\(R^2\\) indica che il modello di regressione lineare si adatta bene ai dati, in quanto una grande parte della varianza di \\(y\\) √® spiegata dalla variabile indipendente \\(x\\).\nPer l‚Äôesempio in discussione, possiamo calcolare la devianza totale, la devianza spiegata e l‚Äôindice di determinazione \\(R^2\\) come segue:\nLa devianza totale misura la variabilit√† complessiva dei punteggi osservati \\(y\\) rispetto alla loro media:\n\n# Devianza totale\ndev_t &lt;- sum((kidiq$kid_score - mean(kidiq$kid_score))^2)\ndev_t\n#&gt; [1] 180386\n\nLa devianza spiegata misura la variabilit√† che il modello √® in grado di spiegare, considerando i valori predetti \\(a + b x\\):\n\n# Devianza spiegata\ndev_r &lt;- sum(((a + b * kidiq$mom_iq) - mean(kidiq$kid_score))^2)\ndev_r\n#&gt; [1] 36249\n\nL‚Äôindice \\(R^2\\) √® il rapporto tra la devianza spiegata e la devianza totale, e indica la frazione della variabilit√† totale che √® spiegata dal modello di regressione:\n\n# Indice di determinazione\nR2 &lt;- dev_r / dev_t\nround(R2, 3)\n#&gt; [1] 0.201\n\nPer verificare i calcoli, utilizziamo il modello di regressione lineare in R e leggiamo \\(R^2\\) direttamente dal sommario del modello:\n\n# Modello di regressione lineare\nmod &lt;- lm(kid_score ~ mom_iq, data = kidiq)\n\n# Sommario del modello per leggere R^2\nsummary(mod)$r.squared\n#&gt; [1] 0.201\n\nIl risultato mostra che circa il 20% della variabilit√† nei punteggi del QI dei bambini √® spiegabile conoscendo il QI delle madri. Questo significa che il modello cattura una porzione rilevante della relazione, ma lascia anche spazio a fattori non inclusi nel modello che influenzano il QI dei bambini.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>¬† <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#inferenza-sul-modello-di-regressione",
    "href": "chapters/linear_models/01_reglin_frequentist.html#inferenza-sul-modello-di-regressione",
    "title": "60¬† La regressione lineare bivariata: un approccio frequentista",
    "section": "\n60.11 Inferenza sul modello di regressione",
    "text": "60.11 Inferenza sul modello di regressione\nIl terzo obiettivo del modello di regressione √® l‚Äôinferenza. Nell‚Äôapproccio frequentista, l‚Äôinferenza viene effettuata calcolando la distribuzione campionaria dei parametri e gli intervalli di fiducia per i parametri. Ad esempio, se si vuole determinare se la pendenza della retta di regressione √® maggiore di zero, si calcola l‚Äôintervallo di fiducia al 95% per il parametro \\(\\beta\\). Se l‚Äôintervallo non include lo zero e se il limite inferiore dell‚Äôintervallo √® maggiore di zero, si conclude che c‚Äô√® evidenza di un‚Äôassociazione lineare positiva tra \\(x\\) e \\(y\\) con un grado di confidenza del 95%.1 Il prossimo capitolo spiegher√† come effettuare l‚Äôinferenza sui coefficienti del modello di regressione lineare in un contesto bayesiano.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>¬† <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#riflessioni-conclusive",
    "href": "chapters/linear_models/01_reglin_frequentist.html#riflessioni-conclusive",
    "title": "60¬† La regressione lineare bivariata: un approccio frequentista",
    "section": "\n60.12 Riflessioni Conclusive",
    "text": "60.12 Riflessioni Conclusive\nIl modello lineare bivariato √® uno strumento fondamentale nell‚Äôanalisi delle relazioni tra due variabili e rappresenta una pietra miliare dell‚Äôapproccio frequentista. Questo capitolo ha mostrato come il modello consenta di quantificare il grado di associazione tra una variabile indipendente \\(x\\) e una variabile dipendente \\(y\\), utilizzando una relazione lineare.\nGrazie all‚Äôapproccio frequentista, abbiamo imparato a stimare i coefficienti \\(a\\) (intercetta) e \\(b\\) (pendenza) attraverso il metodo dei minimi quadrati, che minimizza la somma dei quadrati dei residui per trovare la retta che meglio approssima i dati osservati. Inoltre, l‚Äôindice di determinazione (\\(R^2\\)) ci ha permesso di valutare la bont√† di adattamento del modello e di quantificare quanta parte della variabilit√† di \\(y\\) √® spiegata dalla variabile \\(x\\).\nIn pratica, il modello lineare bivariato consente di rispondere a domande fondamentali, come:\n\nSe il valore della variabile indipendente aumenta o diminuisce, come si comporta la variabile dipendente?\nQual √® l‚Äôintensit√† e il segno della relazione tra le due variabili?\n\nLa semplicit√† del modello lo rendono uno strumento utile non solo per descrivere e analizzare relazioni tra variabili, ma anche per effettuare previsioni. Pur limitandosi a un singolo predittore, il modello lineare bivariato fornisce una base per comprendere relazioni pi√π complesse, come quelle coinvolgenti pi√π variabili indipendenti (regressione multivariata).\nL‚Äôapproccio frequentista offre una metodologia consolidata per stimare i parametri e valutare il modello, fornendo inferenze utili per analisi pratiche e decisioni informate. Con una solida comprensione di questi concetti, si √® pronti a esplorare modelli lineari pi√π complessi e a estendere queste tecniche a scenari pi√π articolati.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>¬† <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/01_reglin_frequentist.html#informazioni-sullambiente-di-sviluppo",
    "title": "60¬† La regressione lineare bivariata: un approccio frequentista",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] broom_1.0.7      thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0\n#&gt;  [5] see_0.11.0       gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1\n#&gt;  [9] psych_2.5.3      scales_1.3.0     markdown_2.0     knitr_1.50      \n#&gt; [13] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [17] purrr_1.0.4      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [21] ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      xfun_0.51         htmlwidgets_1.6.4 lattice_0.22-6   \n#&gt;  [5] tzdb_0.5.0        vctrs_0.6.5       tools_4.4.2       generics_0.1.3   \n#&gt;  [9] parallel_4.4.2    pacman_0.5.1      pkgconfig_2.0.3   R.oo_1.27.0      \n#&gt; [13] Matrix_1.7-3      lifecycle_1.0.4   compiler_4.4.2    farver_2.1.2     \n#&gt; [17] munsell_0.5.1     mnormt_2.1.1      htmltools_0.5.8.1 pillar_1.10.1    \n#&gt; [21] R.utils_2.13.0    nlme_3.1-167      tidyselect_1.2.1  digest_0.6.37    \n#&gt; [25] stringi_1.8.4     labeling_0.4.3    splines_4.4.2     rprojroot_2.0.4  \n#&gt; [29] fastmap_1.2.0     grid_4.4.2        colorspace_2.1-1  cli_3.6.4        \n#&gt; [33] magrittr_2.0.3    withr_3.0.2       backports_1.5.0   timechange_0.3.0 \n#&gt; [37] rmarkdown_2.29    R.methodsS3_1.8.2 hms_1.1.3         evaluate_1.0.3   \n#&gt; [41] haven_2.5.4       mgcv_1.9-1        rlang_1.1.5       glue_1.8.0       \n#&gt; [45] rstudioapi_0.17.1 jsonlite_1.9.1    R6_2.6.1",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>¬† <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#bibliografia",
    "href": "chapters/linear_models/01_reglin_frequentist.html#bibliografia",
    "title": "60¬† La regressione lineare bivariata: un approccio frequentista",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAlter, U., Too, M. A., & Cribbie, R. A. (2025). Navigating the Bayes maze: The psychologist‚Äôs guide to Bayesian statistics, a hands-on tutorial with R code. International Journal of Psychology, 60(1), e13271.\n\n\nCaudek, C., & Luccio, R. (2001). Statistica per psicologi (III rist. 2023, Vol. 11, p. 320). Laterza.\n\n\nFox, J. (2015). Applied regression analysis and generalized linear models. Sage publications.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other stories. Cambridge University Press.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:\n\n\nStigler, S. (1986). The History of Statistics. Belknap Harvard.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>¬† <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#footnotes",
    "href": "chapters/linear_models/01_reglin_frequentist.html#footnotes",
    "title": "60¬† La regressione lineare bivariata: un approccio frequentista",
    "section": "",
    "text": "Per un approfondimento sull‚Äôapproccio frequentista alla regressione, si veda, per esempio, Caudek & Luccio (2001).‚Ü©Ô∏é",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>¬† <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_regr_toward_mean.html",
    "href": "chapters/linear_models/02_regr_toward_mean.html",
    "title": "61¬† La regressione verso la media",
    "section": "",
    "text": "61.1 Introduzione\nIl concetto di regressione verso la media √® stato introdotto da Francis Galton, un pioniere della statistica, mentre studiava la trasmissione ereditaria di tratti fisici, in particolare l‚Äôaltezza. Galton osserv√≤ che, quando si confronta l‚Äôaltezza dei padri con quella dei figli, i figli tendono ad essere pi√π vicini alla media della popolazione rispetto ai loro padri. Questo fenomeno √® noto come regressione verso la media.\nImmaginiamo di avere un padre che √® pi√π alto della media della popolazione. Ci aspettiamo che suo figlio sia anch‚Äôesso pi√π alto della media, ma non tanto quanto il padre. In altre parole, l‚Äôaltezza del figlio ‚Äúregredisce‚Äù parzialmente verso la media della popolazione. Lo stesso principio si applica ai padri pi√π bassi della media: i loro figli tenderanno ad essere pi√π bassi della media, ma non tanto quanto i padri.\nPerch√© succede? Quando un padre √® alto 75 pollici (mentre la media magari √® 69.1), essere cos√¨ alto potrebbe essere dovuto a molti fattori ‚Äúeccezionali‚Äù combinati (genetici, ambientali, casuali). Il figlio, tuttavia, eredita solo una parte di quei fattori, e probabilmente avr√† altri fattori (positivi o negativi) in modo casuale, cosicch√© la sua altezza si sposta verso la media della popolazione. Questo non vuol dire che il figlio sia basso: rimane comunque al di sopra della media, ma non raggiunge l‚Äôestremo del padre.\nIl cuore statistico del fenomeno si trova nella correlazione tra due variabili (in questo caso, altezza del padre e altezza del figlio). Se la correlazione fosse 1 (perfetta), un padre alto in modo eccezionale avrebbe sempre un figlio proporzionalmente alto, senza ‚Äúriavvicinarsi‚Äù alla media. Se invece la correlazione √® minore di 1, come succede quasi sempre nel mondo reale, la relazione padre-figlio non √® perfetta e vi √® una certa variabilit√†.\nGalton misur√≤ in media una correlazione di circa 0.5 tra altezza paterna e altezza del figlio maschio. Questo valore implica che, se un padre si discosta di 2-3 deviazioni standard sopra la media, il figlio di solito ne recuperer√† una parte, ma non interamente.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>¬† <span class='chapter-title'>La regressione verso la media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_regr_toward_mean.html#introduzione",
    "href": "chapters/linear_models/02_regr_toward_mean.html#introduzione",
    "title": "61¬† La regressione verso la media",
    "section": "",
    "text": "61.1.1 I Dati di Galton\nEsaminiamo il fenomeno della regressione verso la media usando i dati di Galton. Nel pacchetto HistData di R sono disponibili i dati originali raccolti da Galton, che includono informazioni sull‚Äôaltezza di padri, madri, figli maschi e femmine. Per semplificare l‚Äôanalisi, possiamo creare un dataset che include solo l‚Äôaltezza del padre e l‚Äôaltezza di un figlio maschio scelto casualmente da ogni famiglia:\n\nset.seed(1234)\n\ngalton_heights &lt;- GaltonFamilies |&gt;\n  filter(gender == \"male\") |&gt;\n  group_by(family) |&gt;\n  sample_n(1) |&gt;\n  ungroup() |&gt;\n  select(father, childHeight) |&gt;\n  rename(son = childHeight)\n\nQuesto dataset contiene due colonne: father (altezza del padre) e son (altezza del figlio maschio). Calcolando la media e la deviazione standard delle altezze dei padri e dei figli, otteniamo:\n\ngalton_heights |&gt; \n  summarize(\n    mean_father = mean(father), \n    sd_father   = sd(father),\n    mean_son    = mean(son), \n    sd_son      = sd(son)\n  )\n#&gt; # A tibble: 1 √ó 4\n#&gt;   mean_father sd_father mean_son sd_son\n#&gt;         &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1        69.1      2.55     69.1   2.62\n\nI risultati mostrano che, in media, i padri e i figli hanno altezze simili, anche se le distribuzioni non sono identiche. Un grafico di dispersione (scatterplot) evidenzia una chiara tendenza: padri pi√π alti tendono ad avere figli pi√π alti:\n\ngalton_heights |&gt;\n  ggplot(aes(father, son)) +\n  geom_point(alpha = 0.5)\n\n\n\n\n\n\n\n\n61.1.2 Il Coefficiente di Correlazione\nPer quantificare la relazione lineare tra l‚Äôaltezza del padre e quella del figlio, utilizziamo il coefficiente di correlazione (indicato con \\(r\\) o \\(\\rho\\)). La formula del coefficiente di correlazione √®:\n\\[\n\\rho = \\frac{1}{n}\\sum_{i=1}^n\n\\left(\\frac{x_i - \\mu_x}{\\sigma_x}\\right)\n\\left(\\frac{y_i - \\mu_y}{\\sigma_y}\\right).\n\\]\nIn R, possiamo calcolare la correlazione tra l‚Äôaltezza del padre e quella del figlio con il seguente codice:\n\ngalton_heights |&gt; \n  summarize(r = cor(father, son)) |&gt; \n  pull(r)\n#&gt; [1] 0.4434\n\nNel nostro caso, la correlazione √® circa 0.5. Questo valore positivo indica che padri pi√π alti tendono ad avere figli pi√π alti, ma la correlazione non √® perfetta. Il coefficiente di correlazione varia tra -1 e 1, dove il valore assoluto misura la forza della relazione lineare.\n\n61.1.3 Stime Condizionate: Previsioni basate sull‚ÄôAltezza del Padre\nUn modo per fare previsioni √® chiedersi: ‚ÄúSe un padre √® alto 72 pollici, quale sar√† l‚Äôaltezza media dei figli di tutti i padri di 72 pollici?‚Äù In termini statistici, questa √® l‚Äôaspettativa condizionata \\(\\mathbb{E}(\\text{altezza figlio} \\mid \\text{altezza padre} = 72)\\).\n\nSe filtriamo i dati prendendo solo i padri di altezza 72 pollici, possiamo calcolare la media dell‚Äôaltezza dei figli in quel sottogruppo.\nTuttavia, questo metodo pu√≤ essere instabile se il numero di osservazioni nel sottogruppo √® piccolo.\n\nAd esempio:\n\ngalton_heights |&gt; \n  filter(round(father) == 72) |&gt;\n  summarize(avg_son = mean(son))\n#&gt; # A tibble: 1 √ó 1\n#&gt;   avg_son\n#&gt;     &lt;dbl&gt;\n#&gt; 1    70.2\n\nQuesto ci d√† la stima condizionata dell‚Äôaltezza media del figlio di un padre di 72 pollici. Spesso, questa media √® maggiore della media generale dei figli, ma meno di quanto il padre (72 pollici) sia sopra la media dei padri. Questo fenomeno √® noto come regressione verso la media.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>¬† <span class='chapter-title'>La regressione verso la media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_regr_toward_mean.html#visualizzare-la-regressione-verso-la-media",
    "href": "chapters/linear_models/02_regr_toward_mean.html#visualizzare-la-regressione-verso-la-media",
    "title": "61¬† La regressione verso la media",
    "section": "\n61.2 Visualizzare la Regressione verso la Media",
    "text": "61.2 Visualizzare la Regressione verso la Media\nRipetiamo ora lo stesso procedimento per tutti i dati. Stratifichiamo i dati raggruppadoli in base a valori simili di altezza del padre. Calcoliamo poi in ogni gruppo la media dell‚Äôaltezza del figlio:\n\ngalton_heights |&gt;\n  mutate(father_strata = factor(round(father))) |&gt;\n  group_by(father_strata) |&gt;\n  summarize(avg_son = mean(son)) |&gt;\n  ggplot(aes(x = father_strata, y = avg_son)) +\n  geom_point()\n\n\n\n\n\n\n\nNel grafico risultante, ogni punto rappresenta la media dei figli corrispondenti a un determinato ‚Äústrato‚Äù di padri. Se tracciamo anche la retta di regressione, noteremo che i punti si dispongono in modo approssimativamente lineare: a padri pi√π alti corrispondono figli pi√π alti, ma in media meno alti di quanto ci si aspetterebbe se la correlazione fosse perfetta.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>¬† <span class='chapter-title'>La regressione verso la media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_regr_toward_mean.html#la-retta-di-regressione",
    "href": "chapters/linear_models/02_regr_toward_mean.html#la-retta-di-regressione",
    "title": "61¬† La regressione verso la media",
    "section": "\n61.3 La Retta di Regressione",
    "text": "61.3 La Retta di Regressione\nPer capire perch√©, dal punto di vista statistico, si verifica la regressione verso la media, consideriamo il modello di regressione lineare semplice che prevede l‚Äôaltezza del figlio \\(\\hat{Y}\\) in base all‚Äôaltezza del padre \\(X\\):\n\\[\n\\hat{Y} = \\beta_0 + \\beta_1 X.\n\\]\n\nQuando standardizziamo i dati (cio√® trasformiamo sia \\(X\\) sia \\(Y\\) in ‚Äúpunti z‚Äù, sottraendo la media e dividendo per la deviazione standard), la pendenza \\(\\beta_1\\) della retta di regressione diventa esattamente la correlazione \\(\\rho\\).\n\nSe \\(\\rho = 1\\), la pendenza sarebbe 1 e non ci sarebbe alcun ‚Äúriavvicinamento‚Äù alla media: i valori alti di \\(X\\) corrisponderebbero a valori altrettanto alti di \\(Y\\).\n\nSe \\(\\rho &lt; 1\\), la pendenza risulta minore di 1 e ci√≤ significa che, partendo da un valore molto alto (o molto basso) di \\(X\\), la nostra previsione di \\(Y\\) si colloca in una posizione parzialmente pi√π vicina alla media di \\(Y\\) rispetto alla distanza del padre dalla media di \\(X\\). √à proprio questo il fenomeno della regressione verso la media.\n\n\n61.3.1 Forma non standardizzata\nNella forma originale (non standardizzata), i coefficienti si calcolano con:\n\\[\n\\beta_1\n= \\rho \\,\\frac{\\sigma_Y}{\\sigma_X},\n\\quad\n\\beta_0\n= \\mu_Y\n- \\beta_1 \\,\\mu_X,\n\\]\ndove:\n\n\n\\(\\mu_X, \\mu_Y\\) sono le medie di \\(X\\) (altezza del padre) e \\(Y\\) (altezza del figlio);\n\n\\(\\sigma_X, \\sigma_Y\\) sono le rispettive deviazioni standard;\n\n\\(\\rho\\) √® la correlazione tra \\(X\\) e \\(Y\\).\n\n61.3.2 Forma standardizzata\nNella forma standardizzata, le deviazioni standard di \\(X\\) e \\(Y\\) sono pari a 1 e i coefficienti di regressione diventano:\n\\[\n\\beta_1\n= \\rho,\n\\quad\n\\beta_0\n= 0,\n\\]\ndato che le medie di \\(X\\) e \\(Y\\) sono uguali a zero.\n\n61.3.3 Regressione Verso la Media\nNe segue dunque che, se la correlazione tra le variabili √® minore di 1, si verificher√† necessariamente il fenomeno della regressione verso la media.\nIn R, possiamo stimare la retta di regressione tramite la stima dei minimi quadrati:\n\nfit &lt;- lm(son ~ father, data = galton_heights)\nfit$coefficients\n#&gt; (Intercept)      father \n#&gt;     37.6324      0.4559\n\nLa funzione lm calcola gli stimatori \\(\\hat{\\beta}_0\\) e \\(\\hat{\\beta}_1\\) che minimizzano la somma dei quadrati degli scarti:\n\\[\n\\text{RSS} = \\sum_{i} \\left[y_i - (\\beta_0 + \\beta_1 x_i)\\right]^2.\n\\]\nPossiamo quindi tracciare la retta sullo scatterplot dei dati:\n\ngalton_heights |&gt;\n  ggplot(aes(father, son)) +\n  geom_point(alpha = 0.5) +\n  geom_abline(\n    slope = coef(fit)[2], \n    intercept = coef(fit)[1],\n    color = \"blue\"\n  )\n\n\n\n\n\n\n\nSe standardizziamo i dati, la pendenza della retta di regressione diventa uguale alla correlazione:\n\nfit_2 &lt;- lm(scale(son) ~ scale(father), data = galton_heights)\nfit_2$coefficients\n#&gt;   (Intercept) scale(father) \n#&gt;    -7.598e-15     4.434e-01\n\n\ngalton_heights |&gt;\n  ggplot(aes(scale(father), scale(son))) +\n  geom_point(alpha = 0.5) +\n  geom_abline(\n    slope = coef(fit_2)[2], \n    intercept = coef(fit_2)[1],\n    color = \"blue\"\n  )\n\n\n\n\n\n\n\nIl punto cruciale √® ricordare che la pendenza \\(\\beta_1\\) √® proporzionale alla correlazione \\(\\rho\\). Se la correlazione non √® perfetta (\\(\\rho &lt; 1\\)), allora qualsiasi previsione basata su \\(X\\) (ad esempio, l‚Äôaltezza del padre) risulter√† meno estrema di quanto sia \\(X\\) stesso rispetto alla sua media. In altre parole, un padre altissimo (molto sopra la media) avr√†, in media, un figlio sopra la media ma non altrettanto estremo, ‚Äúregredendo‚Äù parzialmente verso il centro della distribuzione.\nIn sintesi: la correlazione imperfetta (\\(\\rho &lt; 1\\)) √® la ragione principale per cui un valore estremo di \\(X\\) (ad esempio, un padre molto alto) porta a un valore \\(\\hat{Y}\\) che √® s√¨ superiore (o inferiore) alla media, ma meno estremo del padre. Questo ‚Äúritorno verso il centro‚Äù √® ci√≤ che chiamiamo regressione verso la media.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>¬† <span class='chapter-title'>La regressione verso la media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_regr_toward_mean.html#riflessioni-conclusive",
    "href": "chapters/linear_models/02_regr_toward_mean.html#riflessioni-conclusive",
    "title": "61¬† La regressione verso la media",
    "section": "\n61.4 Riflessioni Conclusive",
    "text": "61.4 Riflessioni Conclusive\n\n\nGalton scopr√¨ il fenomeno della regressione verso la media studiando l‚Äôaltezza di padri e figli: un padre pi√π alto della media tender√† ad avere un figlio pi√π alto della media, ma non tanto quanto ci si aspetterebbe se la correlazione fosse perfetta.\nQuesto concetto √® generale e applicabile in molti contesti. Spesso, un apparente ‚Äúcalo‚Äù o ‚Äúmiglioramento‚Äù delle prestazioni √® semplicemente un effetto statistico di regressione verso la media, non un effetto causale.\nLa retta di regressione minimizza la somma dei quadrati degli errori e la sua pendenza √® legata alla correlazione \\(\\rho\\) e al rapporto tra le deviazioni standard \\(\\sigma_Y\\) e \\(\\sigma_X\\).\n\nIn sintesi, la regressione verso la media √® un fenomeno statistico che spiega perch√©, in media, i valori estremi tendono a ‚Äúritornare‚Äù verso la media della popolazione. Questo concetto √® fondamentale per interpretare correttamente i dati e evitare errori di interpretazione causati da correlazioni imperfette.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>¬† <span class='chapter-title'>La regressione verso la media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_regr_toward_mean.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/02_regr_toward_mean.html#informazioni-sullambiente-di-sviluppo",
    "title": "61¬† La regressione verso la media",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] HistData_0.9-1   thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0\n#&gt;  [5] see_0.11.0       gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1\n#&gt;  [9] psych_2.5.3      scales_1.3.0     markdown_2.0     knitr_1.50      \n#&gt; [13] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [17] purrr_1.0.4      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [21] ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.9.1   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         rlang_1.1.5       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       tools_4.4.2       parallel_4.4.2    tzdb_0.5.0       \n#&gt; [21] colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5       R6_2.6.1         \n#&gt; [25] lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.1    \n#&gt; [29] gtable_0.3.6      glue_1.8.0        xfun_0.51         tidyselect_1.2.1 \n#&gt; [33] rstudioapi_0.17.1 farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-167     \n#&gt; [37] labeling_0.4.3    rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>¬† <span class='chapter-title'>La regressione verso la media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_regr_toward_mean.html#bibliografia",
    "href": "chapters/linear_models/02_regr_toward_mean.html#bibliografia",
    "title": "61¬† La regressione verso la media",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>¬† <span class='chapter-title'>La regressione verso la media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html",
    "href": "chapters/linear_models/03_reglin_bayes.html",
    "title": "62¬† Modello bayesiano di regressione lineare bivariata",
    "section": "",
    "text": "62.1 Introduzione\nIn questa sezione della dispensa, introdurremo il modello di regressione lineare bivariata bayesiano, mettendolo a confronto con l‚Äôapproccio frequentista. L‚Äôobiettivo √® offrire una chiara intuizione pratica delle differenze tra l‚Äôapproccio bayesiano e quello classico, evitando tecnicismi complessi.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>¬† <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html#introduzione",
    "href": "chapters/linear_models/03_reglin_bayes.html#introduzione",
    "title": "62¬† Modello bayesiano di regressione lineare bivariata",
    "section": "",
    "text": "62.1.1 Il Modello di Regressione Bayesiano\nA differenza dei metodi classici, come i minimi quadrati o la massima verosimiglianza, la regressione bayesiana integra le informazioni contenute nei dati con conoscenze preesistenti, rappresentate da distribuzioni a priori. Questo approccio consente di ottenere distribuzioni a posteriori, che aggiornano le credenze iniziali alla luce delle nuove osservazioni. In questo modo, il metodo bayesiano non fornisce semplicemente stime puntuali dei parametri, ma restituisce una descrizione completa dell‚Äôincertezza associata a ciascun parametro sotto forma di distribuzioni probabilistiche.\nNel contesto di un modello lineare bayesiano, consideriamo:\n\n\n\\(y\\) come variabile dipendente (risultato),\n\n\\(x\\) come variabile indipendente (predittore),\n\n\\(i\\) come indice delle osservazioni, da 1 al numero totale di dati.\n\n62.1.2 La Verosimiglianza\nIn un modello bayesiano di regressione bivariata, si assume che la relazione tra \\(y\\) e \\(x\\) segua una distribuzione normale centrata sulla retta di regressione:\n\\[\ny_i \\sim \\text{Normale}(\\alpha + \\beta x_i, \\sigma).\n\\]\nQuesto implica che ogni osservazione di \\(y\\) √® una combinazione lineare dell‚Äôintercetta \\(\\alpha\\), del coefficiente \\(\\beta\\) associato alla variabile \\(x\\), e di un termine di errore distribuito normalmente con deviazione standard \\(\\sigma\\). La regressione cerca quindi di stimare i parametri \\(\\alpha\\), \\(\\beta\\) e \\(\\sigma\\) in modo da rappresentare al meglio il legame tra \\(x\\) e \\(y\\).\n\n62.1.3 Le Distribuzioni a Priori\nUn elemento distintivo dell‚Äôapproccio bayesiano √® l‚Äôintroduzione di distribuzioni a priori per i parametri del modello. Queste rappresentano la conoscenza (o l‚Äôassenza di conoscenza) sui parametri prima di osservare i dati.\nUn‚Äôopzione potrebbe essere l‚Äôuso di prior non informativi, che esprimono un‚Äôassenza totale di informazioni iniziali. Tuttavia, √® spesso preferibile adottare prior debolmente informativi, che evitano stime estreme e migliorano la stabilit√† del modello. Un esempio comune √® il seguente:\n\\[\n\\alpha \\sim \\mathcal{N}(0, 2.5), \\quad \\beta \\sim \\mathcal{N}(0, 2.5), \\quad \\sigma \\sim \\text{Cauchy}(0, 2.5).\n\\]\nQueste scelte riflettono ipotesi iniziali ragionevoli senza imporre restrizioni rigide ai parametri.\n\n62.1.4 Le Distribuzioni a Posteriori\nUna volta specificata la verosimiglianza e le distribuzioni a priori, possiamo applicare il teorema di Bayes per ottenere le distribuzioni a posteriori dei parametri. Le posteriori rappresentano la conoscenza aggiornata sui parametri dopo aver osservato i dati, combinando l‚Äôinformazione empirica con le ipotesi iniziali.\nUn vantaggio cruciale dell‚Äôapproccio bayesiano √® che, invece di restituire un‚Äôunica stima puntuale (come accade nei metodi frequentisti), fornisce una distribuzione completa per ciascun parametro, permettendo di quantificare direttamente l‚Äôincertezza nelle stime.\n\n62.1.5 Stima dei Parametri: Algoritmi MCMC\nPoich√© le distribuzioni a posteriori spesso non hanno una forma analitica semplice, vengono approssimate mediante campionamento numerico. In particolare, si utilizzano algoritmi di Markov Chain Monte Carlo (MCMC), che permettono di generare un insieme di valori campionati dalla distribuzione a posteriori. Questo consente di stimare in modo accurato anche modelli complessi.\n\n62.1.6 Implementazione in brms\n\nNella prossima sezione, vedremo come implementare un modello di regressione bayesiano utilizzando la funzione brm() del pacchetto brms. Analizzeremo come ottenere le stime a posteriori, interpretarle e confrontarle con l‚Äôapproccio frequentista, evidenziando i vantaggi e le implicazioni dell‚Äôinferenza bayesiana.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>¬† <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html#adattare-una-retta-di-regressione-a-dati-simulati",
    "href": "chapters/linear_models/03_reglin_bayes.html#adattare-una-retta-di-regressione-a-dati-simulati",
    "title": "62¬† Modello bayesiano di regressione lineare bivariata",
    "section": "\n62.2 Adattare una Retta di Regressione a Dati Simulati",
    "text": "62.2 Adattare una Retta di Regressione a Dati Simulati\nDefiniamo i parametri e simuliamo i dati.\n\nset.seed(123)\n\n# Definizione delle variabili\nx &lt;- 1:100\nn &lt;- length(x)\na &lt;- 1.5\nb &lt;- 0.5\nsigma &lt;- 10\n\n# Generazione di y\ny &lt;- a + b * x + rnorm(n, 0, sigma)\n\n# Creazione del dataframe\nfake &lt;- tibble(x = x, y = y)\nhead(fake)\n#&gt; # A tibble: 6 √ó 2\n#&gt;       x      y\n#&gt;   &lt;int&gt;  &lt;dbl&gt;\n#&gt; 1     1 -3.60 \n#&gt; 2     2  0.198\n#&gt; 3     3 18.6  \n#&gt; 4     4  4.21 \n#&gt; 5     5  5.29 \n#&gt; 6     6 21.7\n\nIniziamo adattando ai dati un modello frequentista:\n\nfm1 &lt;- lm(y ~ x, data = fake)\n\n\nsummary(fm1)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = y ~ x, data = fake)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -24.536  -5.524  -0.346   6.485  20.949 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)\n#&gt; (Intercept)   1.1360     1.8429    0.62     0.54\n#&gt; x             0.5251     0.0317   16.57   &lt;2e-16\n#&gt; \n#&gt; Residual standard error: 9.15 on 98 degrees of freedom\n#&gt; Multiple R-squared:  0.737,  Adjusted R-squared:  0.734 \n#&gt; F-statistic:  275 on 1 and 98 DF,  p-value: &lt;2e-16\n\nPer ottenere l‚Äôintervallo di confidenza (nel senso frequentista) della stima dei parametri usiamo:\n\nconfint(fm1, level = 0.95)\n#&gt;               2.5 % 97.5 %\n#&gt; (Intercept) -2.5212  4.793\n#&gt; x            0.4622  0.588\n\nAdattiamo ora ai dati un modello di regressione bayesiano utilizzando brms. Si noti che, anche in questo caso, usiamo la sintassi di Wilkinson y ~ x, come per lm(). Eseguiamo il campionamento:\n\nfm2 &lt;- brm(\n  y ~ x, \n  data = fake,\n  backend = \"cmdstanr\"\n)\n\nCome discusso nell‚Äôanalisi dell‚Äôalgoritmo di Metropolis, il primo passo √® esaminare le tracce dei parametri per verificare la convergenza dell‚Äôalgoritmo. La convergenza pu√≤ essere considerata raggiunta se le catene (nel caso di brm, sono 4 per impostazione predefinita) risultano ben mescolate. Questo si manifesta in un trace plot che mostra una distribuzione uniforme e casuale dei campioni attorno a un valore centrale, senza pattern evidenti o tendenze sistematiche.\nLe tracce dei parametri si ottengono nel modo seguente:\n\nmcmc_trace(\n  fm2, \n  pars = c(\"b_Intercept\", \"b_x\", \"sigma\"),\n  facet_args = list(nrow = 3)\n)\n\n\n\n\n\n\n\nGli istogrammi delle distribuzioni a posteriori dei parametri si generano nel modo seguente:\n\nmcmc_hist(\n  fm2, \n  pars =c(\"b_Intercept\", \"b_x\", \"sigma\"),\n  facet_args = list(nrow = 3)\n)\n\n\n\n\n\n\n\nPer valutare l‚Äôautocorrelazione tra i campioni a posteriori del parametro beta, possiamo utilizzare il seguente comando:\n\nmcmc_acf(fm2, \"b_x\")\n\n\n\n\n\n\n\nL‚Äôautocorrelazione fornisce informazioni sulla dipendenza tra campioni successivi nella catena di Markov. √à normale che i campioni successivi non siano completamente indipendenti, poich√© le catene di Markov generano campioni correlati per costruzione. Tuttavia, se l‚Äôalgoritmo ha raggiunto la convergenza, l‚Äôautocorrelazione dovrebbe diminuire rapidamente e diventare trascurabile dopo un numero relativamente piccolo di lag. Questo significa che, dopo un certo numero di passi, i campioni diventano progressivamente meno correlati tra loro, comportandosi in modo simile a campioni indipendenti estratti dalla distribuzione target.\nUn‚Äôelevata autocorrelazione su lag pi√π lunghi potrebbe invece indicare problemi di mescolamento delle catene o una mancata convergenza, richiedendo ulteriori verifiche o aggiustamenti, come l‚Äôaumento del numero di iterazioni o una diversa parametrizzazione del modello.\nNel caso presente, notiamo una rapida diminuzione dell‚Äôautocorrelazione in funzione del numero di passi. Ci√≤ √® indicativo del fatto che la convergenza √® stata raggiunta.\nUna sintesi numerica dei risultati si trova nel modo seguente:\n\nsummary(fm2)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: y ~ x \n#&gt;    Data: fake (Number of observations: 100) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept     1.11      1.85    -2.55     4.77 1.00     3976     2968\n#&gt; x             0.53      0.03     0.46     0.59 1.00     4028     3041\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     9.26      0.69     7.99    10.75 1.00     3753     3097\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nConfrontiamo le stime ottenute con i valori reali dei parametri simulati. L‚Äôintercetta √® stata stimata attorno a 1.14, con un‚Äôincertezza al 95% che varia tra -2.4 e 4.8. Questo risultato rientra negli intervalli di credibilit√† previsti, confermando l‚Äôaccuratezza del modello. Analogamente, per la pendenza \\(b\\), l‚Äôintervallo di credibilit√† al 95% include il valore reale simulato, dimostrando come le stime bayesiane riflettano accuratamente l‚Äôincertezza sui parametri.\nSe si utilizza la funzione conditional_effects() viene prodotto un grafico che rappresenta la relazione stimata tra il predittore \\(x\\) e la variabile di risposta \\(y\\).\n\nconditional_effects(fm2) |&gt;\n  plot(points = TRUE)\n\n\n\n\n\n\n\n\n\nLinea stimata (effetto medio):\n\nLa linea centrale del grafico rappresenta il valore medio previsto di \\(y\\) per ogni valore di \\(x\\), dato dalla relazione \\(y = \\alpha + \\beta x\\).\nQuesta linea √® calcolata usando i valori medi a posteriori stimati per \\(\\alpha\\) e \\(\\beta\\).\n\n\n\nBande di incertezza (intervalli di credibilit√†):\n\nLe bande attorno alla linea rappresentano gli intervalli di credibilit√† (ad esempio, al 95%). Questi mostrano l‚Äôincertezza associata alle stime del modello per ogni valore di \\(x\\).\nPi√π strette sono le bande, maggiore √® la certezza del modello riguardo alla relazione stimata.\n\n\n\nDati osservati:\n\nI punti rappresentano i valori effettivi di \\(y\\) osservati nei dati. Questo consente di confrontare visivamente come i dati reali si allineano con le previsioni del modello.\n\n\n\nIl grafico consente\n\nuna verifica visiva della relazione stimata tra \\(y\\) e \\(x\\);\ndi identificazione di eventuali discrepanze tra i dati osservati e le previsioni del modello;\nuna rappresentazione dell‚Äôincertezza nelle stime.\n\nAd esempio, il grafico pu√≤ mostrare se \\(x\\) ha un effetto credibile su \\(y\\) e con quale livello di incertezza. Se l‚Äôeffetto di \\(x\\) √® debole o nullo, la linea stimata sar√† piatta (vicina a zero) e le bande di incertezza saranno ampie.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>¬† <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html#simulazione-di-livelli-di-copertura",
    "href": "chapters/linear_models/03_reglin_bayes.html#simulazione-di-livelli-di-copertura",
    "title": "62¬† Modello bayesiano di regressione lineare bivariata",
    "section": "\n62.3 Simulazione di Livelli di Copertura",
    "text": "62.3 Simulazione di Livelli di Copertura\nVerifichiamo la copertura degli intervalli di credibilit√† al 95% attraverso simulazioni ripetute.\n\nset.seed(42)\n# Parametri veri\na_true &lt;- 0.2\nb_true &lt;- 0.3\nsigma_true &lt;- 0.5\n# Numero di simulazioni\nnum_simulations &lt;- 1000\n# Conteggio delle coperture\ncoverage_a &lt;- 0\ncoverage_b &lt;- 0\nfor (i in 1:num_simulations) {\n  # Generazione dei dati\n  x &lt;- 1:20\n  y &lt;- a_true + b_true * x + sigma_true * rnorm(length(x))\n  # Adattamento del modello\n  fit &lt;- lm(y ~ x)\n  ci &lt;- confint(fit) # Intervalli di confidenza\n  # Verifica delle coperture\n  if (ci[1,1] &lt;= a_true & ci[1, 2] &gt;= a_true) {\n    coverage_a &lt;- coverage_a + 1\n  }\n  if (ci[2,1] &lt;= b_true & ci[2, 2] &gt;= b_true) {\n    coverage_b &lt;- coverage_b + 1\n  }\n}\n\n\n# Risultati\ncat(\"Coverage for a:\", coverage_a / num_simulations, \"\\n\")\n#&gt; Coverage for a: 0.952\ncat(\"Coverage for b:\", coverage_b / num_simulations, \"\\n\")\n#&gt; Coverage for b: 0.955\n\nI risultati indicano che i livelli di copertura empirici ottenuti con l‚Äôapproccio frequentista corrispondono strettamente ai livelli teorici attesi.\nPer proseguire, ripeteremo la simulazione adottando un approccio bayesiano. Useremo la funzione brm() del pacchetto brms al posto di lm().\n#| message: false\n#| warning: false\n#| output: false\n#| \n# Definizione dei parametri\nset.seed(23)\nn_fake &lt;- 1000\ncover_68 &lt;- rep(NA, n_fake)\ncover_95 &lt;- rep(NA, n_fake)\na &lt;- 0.2 # Intercetta vera\nb &lt;- 0.3 # Pendenza vera\nsigma &lt;- 0.5 # Deviazione standard vera\nx &lt;- 1:20 # Variabile indipendente\nn &lt;- length(x) # Numero di osservazioni\n\n# Ciclo per simulazioni\nfor (s in 1:n_fake) {\n  # Generazione dei dati\n  y &lt;- a + b * x + rnorm(n, 0, sigma)\n  fake &lt;- data.frame(x = x, y = y)\n\n  # Adattamento del modello con brms\n  fit &lt;- brm(\n    bf(y ~ 1 + x, center = FALSE),\n    data = fake,\n    family = gaussian(),\n    prior = c(\n      prior(normal(0, 2.5), class = \"b\", coef = \"Intercept\"), # Prior per alpha\n      prior(normal(0, 2.5), class = \"b\", coef = \"x\"), # Prior per beta\n      prior(cauchy(0, 2.5), class = \"sigma\") # Prior per sigma\n    ),\n    seed = 42,\n    iter = 2000, \n    chains = 2, \n    refresh = 0, # Suppress console output\n    backend = \"cmdstanr\"\n  )\n\n  # Estrazione dei coefficienti stimati e delle deviazioni standard\n  posterior_summary &lt;- summary(fit)$fixed\n  b_hat &lt;- posterior_summary[\"x\", \"Estimate\"]\n  b_se &lt;- posterior_summary[\"x\", \"Est.Error\"]\n\n  # Calcolo della copertura\n  cover_68[s] &lt;- abs(b - b_hat) &lt; b_se\n  cover_95[s] &lt;- abs(b - b_hat) &lt; 2 * b_se\n}\n# Summarize the coverage results\nmean_cover_68 &lt;- mean(cover_68, na.rm = TRUE)\nmean_cover_95 &lt;- mean(cover_95, na.rm = TRUE)\ncat(\"Coverage for 68% interval:\", mean_cover_68, \"\\n\")\ncat(\"Coverage for 95% interval:\", mean_cover_95, \"\\n\")\nQuesta seconda simulazione evidenzia che anche i livelli di copertura empirici ottenuti con l‚Äôapproccio bayesiano si avvicinano ai valori teorici previsti.\nI risultati ottenuti confermano l‚Äôefficacia degli intervalli di confidenza e di credibilit√† stimati attraverso i modelli frequentisti e bayesiani.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>¬† <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html#confronti-non-effetti",
    "href": "chapters/linear_models/03_reglin_bayes.html#confronti-non-effetti",
    "title": "62¬† Modello bayesiano di regressione lineare bivariata",
    "section": "\n62.4 Confronti, non Effetti",
    "text": "62.4 Confronti, non Effetti\nGelman et al. (2021) sottolineano che i coefficienti di regressione sono spesso denominati ‚Äúeffetti‚Äù, ma questa terminologia pu√≤ trarre in inganno. Gli ‚Äúeffetti‚Äù, infatti, implicano una relazione causale. Tuttavia, ci√≤ che un modello di regressione stima non √® necessariamente un effetto causale, ma piuttosto un pattern osservazionale. In particolare, ci√≤ che osserviamo √® che la media della variabile dipendente nella sottopopolazione con \\(X = x + 1\\) √® spesso maggiore o minore (a seconda del segno di \\(\\beta\\)) rispetto alla media della sottopopolazione con \\(X = x\\).\nLa regressione √® uno strumento matematico utilizzato principalmente per fare previsioni. I coefficienti di regressione devono quindi essere interpretati come confronti medi. Solo in circostanze specifiche, quando la regressione descrive un processo causale ben definito, √® possibile interpretarli come effetti. Tuttavia, questa interpretazione causale deve essere giustificata dal disegno dello studio e non pu√≤ essere dedotta unicamente dall‚Äôuso del modello statistico.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>¬† <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html#riflessioni-conclusive",
    "href": "chapters/linear_models/03_reglin_bayes.html#riflessioni-conclusive",
    "title": "62¬† Modello bayesiano di regressione lineare bivariata",
    "section": "\n62.5 Riflessioni Conclusive",
    "text": "62.5 Riflessioni Conclusive\nIn questo capitolo abbiamo adottato un approccio bayesiano per stimare i parametri di un modello di regressione bivariato. √à emerso che, quando i prior sono debolmente informativi, le stime bayesiane tendono a coincidere con quelle ottenute tramite l‚Äôapproccio frequentista. Tuttavia, il valore dell‚Äôapproccio bayesiano risiede non solo nella stima dei parametri, ma anche nella possibilit√† di incorporare conoscenze a priori e di rappresentare esplicitamente l‚Äôincertezza nelle stime.\nAl di l√† della scelta tra approccio frequentista e bayesiano, √® cruciale riflettere sul ruolo dei modelli statistici nella ricerca scientifica, in particolare nel contesto psicologico. Come evidenziato da Alexander (2023), i modelli statistici non sono strumenti per rivelare una verit√† assoluta, ma mezzi per interpretare i dati e costruire significato a partire da essi. Essi non rappresentano la realt√† in modo fedele, ma piuttosto funzionano come ‚Äúlenti‚Äù attraverso le quali possiamo mettere a fuoco aspetti specifici del fenomeno studiato.\nI modelli statistici possono essere utilizzati principalmente per due scopi distinti ma complementari: inferenza e previsione.\n\nPrevisione: mira a descrivere le associazioni tra variabili, consentendo di formulare stime future basate sui dati disponibili. √à un processo empirico, in cui la bont√† del modello viene valutata sulla sua capacit√† di fare previsioni accurate.\nInferenza: si concentra sull‚Äôindividuazione di relazioni causali tra variabili. Questo tipo di analisi richiede una progettazione rigorosa, come esperimenti controllati o disegni quasi-sperimentali, e una chiara giustificazione delle ipotesi del modello. La regressione, in particolare, pu√≤ supportare inferenze causali solo se accompagnata da un contesto teorico robusto e da dati appropriati.\n\n√à fondamentale ricordare che la regressione rappresenta una forma di media ponderata e, di conseguenza, i suoi risultati possono essere influenzati da bias intrinseci e dalle caratteristiche specifiche del dataset. Pertanto:\n\nLa qualit√† dei risultati dipende dalla qualit√† dei dati e dalla correttezza delle ipotesi del modello.\n√à importante considerare potenziali fonti di bias, come la selezione dei dati, variabili confondenti non incluse nel modello, o ipotesi non verificate sulla linearit√† delle relazioni.\n\nIn conclusione, l‚Äôadozione di un modello statistico non √® un fine in s√©, ma uno strumento per esplorare, interpretare e comprendere il fenomeno di interesse. Sia che si utilizzi un approccio bayesiano o frequentista, il successo dell‚Äôanalisi dipende dalla capacit√† di integrare i risultati quantitativi con una riflessione teorica critica e da un‚Äôattenzione costante alla validit√† delle ipotesi e delle conclusioni.\nPer un approfondimento sul modello bayesiano di regressione lineare, oltre al testo di Johnson et al. (2022), si consiglia Regression and Other Stories, un riferimento fondamentale che fornisce una trattazione chiara e approfondita del tema.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>¬† <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/03_reglin_bayes.html#informazioni-sullambiente-di-sviluppo",
    "title": "62¬† Modello bayesiano di regressione lineare bivariata",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] rstan_2.32.7        StanHeaders_2.32.10 brms_2.22.0        \n#&gt;  [4] Rcpp_1.0.14         posterior_1.6.1     cmdstanr_0.8.1     \n#&gt;  [7] thematic_0.1.6      MetBrewer_0.2.0     ggokabeito_0.1.0   \n#&gt; [10] see_0.11.0          gridExtra_2.3       patchwork_1.3.0    \n#&gt; [13] bayesplot_1.11.1    psych_2.5.3         scales_1.3.0       \n#&gt; [16] markdown_2.0        knitr_1.50          lubridate_1.9.4    \n#&gt; [19] forcats_1.0.0       stringr_1.5.1       dplyr_1.1.4        \n#&gt; [22] purrr_1.0.4         readr_2.1.5         tidyr_1.3.1        \n#&gt; [25] tibble_3.2.1        ggplot2_3.5.1       tidyverse_2.0.0    \n#&gt; [28] rio_1.2.3           here_1.0.1         \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1     farver_2.1.2         loo_2.8.0           \n#&gt;  [4] fastmap_1.2.0        TH.data_1.1-3        tensorA_0.36.2.1    \n#&gt;  [7] pacman_0.5.1         digest_0.6.37        timechange_0.3.0    \n#&gt; [10] estimability_1.5.1   lifecycle_1.0.4      survival_3.8-3      \n#&gt; [13] processx_3.8.6       magrittr_2.0.3       compiler_4.4.2      \n#&gt; [16] rlang_1.1.5          tools_4.4.2          yaml_2.3.10         \n#&gt; [19] data.table_1.17.0    labeling_0.4.3       bridgesampling_1.1-2\n#&gt; [22] htmlwidgets_1.6.4    curl_6.2.2           pkgbuild_1.4.7      \n#&gt; [25] mnormt_2.1.1         plyr_1.8.9           abind_1.4-8         \n#&gt; [28] multcomp_1.4-28      withr_3.0.2          stats4_4.4.2        \n#&gt; [31] grid_4.4.2           inline_0.3.21        xtable_1.8-4        \n#&gt; [34] colorspace_2.1-1     emmeans_1.11.0       MASS_7.3-65         \n#&gt; [37] cli_3.6.4            mvtnorm_1.3-3        rmarkdown_2.29      \n#&gt; [40] generics_0.1.3       RcppParallel_5.1.10  rstudioapi_0.17.1   \n#&gt; [43] reshape2_1.4.4       tzdb_0.5.0           splines_4.4.2       \n#&gt; [46] parallel_4.4.2       matrixStats_1.5.0    vctrs_0.6.5         \n#&gt; [49] V8_6.0.2             Matrix_1.7-3         sandwich_3.1-1      \n#&gt; [52] jsonlite_1.9.1       hms_1.1.3            glue_1.8.0          \n#&gt; [55] codetools_0.2-20     ps_1.9.0             distributional_0.5.0\n#&gt; [58] stringi_1.8.4        gtable_0.3.6         QuickJSR_1.6.0      \n#&gt; [61] munsell_0.5.1        pillar_1.10.1        htmltools_0.5.8.1   \n#&gt; [64] Brobdingnag_1.2-9    R6_2.6.1             rprojroot_2.0.4     \n#&gt; [67] evaluate_1.0.3       lattice_0.22-6       backports_1.5.0     \n#&gt; [70] rstantools_2.4.0     coda_0.19-4.1        nlme_3.1-167        \n#&gt; [73] checkmate_2.3.2      xfun_0.51            zoo_1.8-13          \n#&gt; [76] pkgconfig_2.0.3",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>¬† <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html#bibliografia",
    "href": "chapters/linear_models/03_reglin_bayes.html#bibliografia",
    "title": "62¬† Modello bayesiano di regressione lineare bivariata",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAlexander, R. (2023). Telling Stories with Data: With Applications in R. Chapman; Hall/CRC.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other stories. Cambridge University Press.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>¬† <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar.html",
    "href": "chapters/linear_models/04_synt_sugar.html",
    "title": "63¬† Zucchero sintattico",
    "section": "",
    "text": "63.1 Introduzione\nI modelli lineari sono cos√¨ ampiamente utilizzati che sono stati sviluppati appositamente una sintassi, dei metodi e delle librerie per la regressione. Una di queste librerie √® brms (Bayesian Regression Models using Stan), gi√† introdotta nel Capitolo 62. brms √® un pacchetto R progettato per adattare modelli gerarchici generalizzati lineari (di cui il modello lineare bivariato √® un caso particolare), utilizzando una sintassi simile a quella presente nei pacchetti R, come lme4, nlme, rstanarm. brms si basa su Stan, ma offre un‚ÄôAPI di livello superiore.\nIn questo capitolo esploreremo in maniera dettagliata come condurre un‚Äôanalisi di regressione utilizzando brms invece di Stan.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>¬† <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar.html#interfaccia-brms",
    "href": "chapters/linear_models/04_synt_sugar.html#interfaccia-brms",
    "title": "63¬† Zucchero sintattico",
    "section": "\n63.2 Interfaccia brms\n",
    "text": "63.2 Interfaccia brms\n\nPer fare un esempio, applicheremo il modello di regressione bivariato alla relazione tra altezza e peso. I dati contenuti nel file Howell_18.csv sono parte di un censimento parziale della popolazione !Kung San dell‚Äôarea di Dobe, raccolti tramite interviste condotte da Nancy Howell alla fine degli anni ‚Äô60 (McElreath, 2020). I !Kung San sono una delle popolazioni di raccoglitori-cacciatori pi√π conosciute del ventesimo secolo e sono stati oggetto di numerosi studi antropologici. In questa analisi, consideriamo un sottocampione di dati relativi alla popolazione adulta (di et√† superiore ai 18 anni).\nImportiamo i dati contenuti nel file Howell_18.csv.\n\ndf &lt;- rio::import(here::here(\"data\", \"Howell_18.csv\"))\n\n\ndf |&gt; \n  head()\n#&gt;   height weight age male\n#&gt; 1  151.8  47.83  63    1\n#&gt; 2  139.7  36.49  63    0\n#&gt; 3  136.5  31.86  65    0\n#&gt; 4  156.8  53.04  41    1\n#&gt; 5  145.4  41.28  51    0\n#&gt; 6  163.8  62.99  35    1\n\nGeneriamo un diagramma a dispersione tra le variabili height (altezza) e weight (peso):\n\nggplot(df, aes(x = weight, y = height)) +\n  geom_point() +  \n  labs(x = \"Weight\", y = \"Height\") \n\n\n\n\n\n\n\nbrms si concentra sui modelli di regressione, e questa specializzazione permette di adottare una sintassi pi√π semplice, conosciuta come sintassi di Wilkinson (Wilkinson & Rogers, 1973).\nAd esempio, il modello \\(y = \\alpha + \\beta x + \\varepsilon\\) si implementa come segue:\na_model = brm(y ‚àº 1 + x, data = df)\nNella sintassi di Wilkinson, il simbolo tilde (‚àº) separa la variabile dipendente (a sinistra) dalle variabili indipendenti (a destra). In questo caso, stiamo specificando solo la media (\\(\\mu\\)) della \\(y\\).\nbrms assume di default che la distribuzione di verosimiglianza sia gaussiana, ma √® possibile modificarla tramite l‚Äôargomento family.\nLa notazione 1 si riferisce all‚Äôintercetta. L‚Äôintercetta viene inclusa di default. Per cui il modello precedente si pu√≤ anche scrivere, in maniera equivalente, come\na_model = brm(y ‚àº x, data = df)\nSe desideriaamo escludere l‚Äôintercetta dal modello, possiamo farlo in questo modo\nno_intercept_model = brm(y ‚àº 0 + x, data = df)\noppure in questo modo\nno_intercept_model = brm(y ‚àº -1 + x, data = df)\nPer includere ulteriori variabili nel modello, possiamo procedere cos√¨:\nmodel_2 = brm(\"y ‚àº x + z\", data)\nbrms consente anche di includere effetti a livello di gruppo (gerarchici). Ad esempio, se desideriamo un modello ad effetti misti nel quale abbiamo un effetto diverso di \\(x\\) in ciascun gruppo g, possiamo usare la seguente sintassi:\nmodel_h = brm(y ‚àº x + z + (x | g), data = df)\nLa sintassi di Wilkinson non specifica le distribuzioni a priori, ma solo come le variabili dipendenti e indipendenti sono collegate. brms definir√† automaticamente delle distribuzioni a priori debolmente informative per noi, rendendo superflua la loro definizione esplicita. Tuttavia, se preferiamo avere un maggiore controllo, possiamo specificarle manualmente, come vedremo in seguito.\n\n63.2.1 Centrare le Variabili\nPer interpretare pi√π facilmente l‚Äôintercetta, centriamo la variabile weight rispetto alla media del campione:\n\ndf$weight_c &lt;- df$weight - mean(df$weight)\n\nOra, l‚Äôintercetta (\\(\\alpha\\)) rappresenter√† l‚Äôaltezza media quando il peso corrisponde alla media del campione.\nAdattiamo un modello lineare con la variabile weight centrata e esaminiamo i risultati:\n\nfit_1 = brm(\n  bf(height ~ 1 + weight_c, center = FALSE), \n  data = df, \n  backend = \"cmdstanr\", \n  silent = 0\n)\n\nUtilizzando center = FALSE nel modello Bayesiano garantiamo che il centraggio venga mantenuto e non applicato nuovamente da brms.\nLe tracce dei parametri si ottengono nel modo seguente:\n\nmcmc_trace(\n  fit_1, \n  pars = c(\"b_Intercept\", \"b_weight_c\", \"sigma\"),\n  facet_args = list(nrow = 3)\n)\n\n\n\n\n\n\n\n\nsummary(fit_1)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: height ~ 1 + weight_c \n#&gt;    Data: df (Number of observations: 352) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept   154.59      0.27   154.06   155.11 1.00     3947     2871\n#&gt; weight_c      0.91      0.04     0.82     0.99 1.00     3945     2996\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     5.10      0.20     4.74     5.51 1.00     4902     3275\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nLa stima dell‚Äôintercetta \\(\\alpha\\) = 154.60 suggerisce che, per le persone con un peso corrispondente al valore medio del campione analizzato, l‚Äôaltezza prevista √® di 154.60 cm.\nPossiamo confrontare i risultati ottenuti da brm() con quelli prodotti dall‚Äôappriccio frequentista:\n\nfit_2 &lt;- lm(height ~ 1 + weight_c, data = df)\n\n\nsummary(fit_2)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = height ~ 1 + weight_c, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -19.746  -2.884   0.022   3.142  14.774 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)\n#&gt; (Intercept)  154.597      0.271   570.2   &lt;2e-16\n#&gt; weight_c       0.905      0.042    21.5   &lt;2e-16\n#&gt; \n#&gt; Residual standard error: 5.09 on 350 degrees of freedom\n#&gt; Multiple R-squared:  0.57,   Adjusted R-squared:  0.568 \n#&gt; F-statistic:  463 on 1 and 350 DF,  p-value: &lt;2e-16\n\nAnche in questo caso, l‚Äôuso di prior debolmente informativi fa in modo che i risultati dei due approcci siano praticamente equivalenti.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>¬† <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar.html#visualizzazione-dei-risultati",
    "href": "chapters/linear_models/04_synt_sugar.html#visualizzazione-dei-risultati",
    "title": "63¬† Zucchero sintattico",
    "section": "\n63.3 Visualizzazione dei Risultati",
    "text": "63.3 Visualizzazione dei Risultati\nPer comprendere visivamente la relazione stimata tra peso e altezza nel nostro modello bayesiano, utilizziamo la funzione conditional_effects:\n\nconditional_effects(fit_1, effects = \"weight_c\")\n\n\n\n\n\n\n\nIl grafico generato fornisce una rappresentazione completa della relazione stimata:\n\n\nLinea centrale (media posteriore): Rappresenta la stima pi√π probabile dell‚Äôaltezza per ciascun valore del peso centrato.\n\nArea colorata (intervallo di credibilit√†): Mostra l‚Äôintervallo di densit√† pi√π alta (HDI) al 95%, indicando l‚Äôincertezza attorno alla stima centrale.\n\nPunti sul grafico: Rappresentano i dati reali osservati, permettendo di confrontare il modello con i dati originali.\n\n√à possibile adattare il livello di incertezza mostrato modificando l‚Äôargomento prob:\n\n# Visualizzazione con intervallo di credibilit√† all'89%\nconditional_effects(fit_1, effects = \"weight_c\", prob = 0.89)\n\n\n\n\n\n\n\nRidurre il valore di prob (es. a 0.80 o 0.50) produce un intervallo pi√π stretto, mentre aumentarlo (es. a 0.99) amplia l‚Äôarea di incertezza visualizzata.\n\n63.3.1 Interpretazione Pratica del Grafico\nNel grafico:\n\nIl punto dove la linea attraversa weight_c = 0 corrisponde all‚Äôaltezza prevista per un individuo con peso medio (poich√© abbiamo centrato la variabile).\nLa pendenza della linea indica quanto ci aspettiamo che l‚Äôaltezza aumenti per ogni kg di peso aggiuntivo.\nLa larghezza dell‚Äôintervallo di credibilit√† indica la nostra certezza sulle stime: pi√π stretto l‚Äôintervallo, maggiore la certezza.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>¬† <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar.html#due-tipi-di-incertezza-nei-modelli-bayesiani",
    "href": "chapters/linear_models/04_synt_sugar.html#due-tipi-di-incertezza-nei-modelli-bayesiani",
    "title": "63¬† Zucchero sintattico",
    "section": "\n63.4 Due Tipi di Incertezza nei Modelli Bayesiani",
    "text": "63.4 Due Tipi di Incertezza nei Modelli Bayesiani\nQuando visualizziamo i risultati di un modello bayesiano, esistono due tipi fondamentali di incertezza che possiamo rappresentare:\n\n\nIncertezza del parametro (metodo predefinito): Mostra quanto siamo incerti riguardo alla ‚Äúvera‚Äù relazione tra variabili.\n\nIncertezza predittiva (method = \"predict\"): Mostra quanto siamo incerti riguardo a singole osservazioni future.\n\nLa visualizzazione che incorpora l‚Äôincertezza sui parametri si ottiene con:\nconditional_effects(fit_1, effects = \"weight_c\")\nQuesta visualizzazione standard mostra:\n\n\nLa linea di regressione stimata (media posteriore)\n\nL‚Äôintervallo di credibilit√† attorno alla linea (solitamente al 95%)\n\nCi√≤ che vediamo √® l‚Äôincertezza della media condizionale - ovvero, quanto siamo incerti sul valore medio dell‚Äôaltezza per ogni valore del peso.\nLa visualizzazione predittiva si ottiene con:\n\nconditional_effects(fit_1, effects = \"weight_c\", method = \"predict\")\n\n\n\n\n\n\n\nQuesta visualizzazione alternativa mostra:\n\n\nLa stessa linea di regressione stimata.\n\nUn intervallo di predizione molto pi√π ampio.\n\nL‚Äôintervallo mostrato rappresenta:\n\nL‚Äôincertezza dei parametri (come nella visualizzazione standard).\n\nPI√ô la variabilit√† residua del modello (la dispersione naturale dei dati).\n\n\n63.4.1 Perch√© sono Diverse e Quale Scegliere?\n\n\nVisualizzazione standard: Risponde alla domanda ‚ÄúQuanto siamo sicuri della relazione media tra peso e altezza?‚Äù\n\nVisualizzazione predittiva: Risponde alla domanda ‚ÄúDove ci aspettiamo che cadr√† la prossima osservazione individuale?‚Äù\n\n\n63.4.1.1 Differenze Visive Notevoli:\n\n\nAmpiezza dell‚Äôintervallo: L‚Äôintervallo predittivo √® sempre considerevolmente pi√π ampio dell‚Äôintervallo di credibilit√† per la media.\n\nInterpretazione pratica: L‚Äôintervallo predittivo include la variabilit√† naturale delle osservazioni individuali.\n\n63.4.2 Quando Usare Ciascun Metodo:\n\n\nUsa il metodo predefinito quando sei interessato alla relazione tra variabili.\n\nUsa method = \"predict\" quando vuoi fare previsioni su nuove osservazioni individuali.\n\n\n63.4.2.1 Esempio Concreto\nImmagina di voler predire l‚Äôaltezza di una persona specifica con un dato peso:\n\nLa visualizzazione standard ti dir√† quanto sei sicuro del valore medio per persone con quel peso.\nLa visualizzazione predittiva ti dir√† in quale intervallo probabilmente cadr√† un‚Äôosservazione individuale, incorporando sia l‚Äôincertezza del modello che la variabilit√† naturale.\n\nIn sintesi, la differenza principale sta nell‚Äôinclusione o meno della variabilit√† residua. La visualizzazione predittiva √® pi√π onesta riguardo alla nostra capacit√† di fare previsioni per singole osservazioni, mentre quella standard √® pi√π adatta per comprendere la relazione generale tra le variabili.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>¬† <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar.html#distribuzione-a-posteriori-dei-parametri",
    "href": "chapters/linear_models/04_synt_sugar.html#distribuzione-a-posteriori-dei-parametri",
    "title": "63¬† Zucchero sintattico",
    "section": "\n63.5 Distribuzione a Posteriori dei Parametri",
    "text": "63.5 Distribuzione a Posteriori dei Parametri\nPer esaminare la distribuzione a posteriori dei parametri usiamo la funzione mcmc_plot():\n\nmcmc_plot(fit_1, type = \"dens\")\n\n\n\n\n\n\n\nEsaminiamo in maggiori dettagli il sommario numerico dei parametri stimati:\n\ndraws &lt;- posterior::as_draws(fit_1, variable = \"^b_\", regex = TRUE)\nposterior::summarise_draws(draws, \"mean\", \"sd\", \"mcse_mean\", \"mcse_sd\")\n#&gt; # A tibble: 2 √ó 5\n#&gt;   variable       mean     sd mcse_mean  mcse_sd\n#&gt;   &lt;chr&gt;         &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 b_Intercept 155.    0.269   0.00428  0.00391 \n#&gt; 2 b_weight_c    0.906 0.0423  0.000675 0.000681\n\nUtilizziamo la funzione as_draws() che trasforma un oggetto R in un formato compatibile con posterior. Gli argomenti variable = \"^b_\" e regex = TRUEconsentono di selezionare solo i parametri il cui nome inizia con b_: nel nostro caso saranno l‚Äôintercetta e la pendenza del modello di regressione lineare.\nSuccessivamente usiamo la funzione summarise_draws() con gli argomenti specificati per un sommario della distribuzione a posteriori dei parametri prescelti.\n\n63.5.1 Spiegazione di mcse_mean e mcse_sd\n\nI valori mcse_mean e mcse_sd sono le Monte Carlo Standard Errors (errori standard Monte Carlo) per la stima della media (mean) e della deviazione standard (sd), rispettivamente. Questi valori quantificano l‚Äôincertezza associata al processo di campionamento effettuato durante l‚Äôanalisi bayesiana, in particolare quando si utilizzano algoritmi Monte Carlo come MCMC (Markov Chain Monte Carlo).\n\n63.5.1.1 mcse_mean\n\n\nRappresenta l‚Äôerrore standard Monte Carlo per la stima della media.\nIndica quanto la media stimata (\\(\\text{mean}\\)) potrebbe variare a causa della finitezza dei campioni generati dall‚Äôalgoritmo MCMC.\nUn valore di mcse_mean basso rispetto alla deviazione standard (\\(\\text{sd}\\)) suggerisce che il numero di campioni generati √® sufficiente per ottenere una stima accurata della media.\n\n63.5.1.2 mcse_sd\n\n\nRappresenta l‚Äôerrore standard Monte Carlo per la stima della deviazione standard.\nIndica quanto potrebbe variare la stima della deviazione standard (\\(\\text{sd}\\)) a causa del numero finito di campioni generati.\nAnche qui, un valore basso di mcse_sd rispetto alla sd suggerisce che l‚Äôincertezza introdotta dal campionamento √® trascurabile.\n\n63.5.2 Come interpretarli?\n\n\nProporzione rispetto alla sd:\n\n\nmcse_mean e mcse_sd dovrebbero essere molto pi√π piccoli rispetto ai rispettivi parametri (mean e sd), idealmente almeno un ordine di grandezza inferiore.\nAd esempio, per b_Intercept, mcse_mean = 0.0044 √® molto pi√π piccolo rispetto a sd = 0.2695, indicando che la stima della media √® robusta.\n\n\n\nIndicazione della qualit√† del campionamento:\n\nValori alti di mcse_mean o mcse_sd rispetto alla sd potrebbero indicare che il numero di iterazioni MCMC non √® sufficiente, che le catene non sono ben mescolate o che ci sono problemi di convergenza.\n\n\n\nIn sintesi, mcse_mean e mcse_sd sono utili per valutare l‚Äôaffidabilit√† delle stime derivate dal campionamento Monte Carlo. Se questi valori sono bassi, possiamo essere confidenti che il numero di campioni √® sufficiente per rappresentare accuratamente la distribuzione a posteriori.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>¬† <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar.html#specificare-i-priors",
    "href": "chapters/linear_models/04_synt_sugar.html#specificare-i-priors",
    "title": "63¬† Zucchero sintattico",
    "section": "\n63.6 Specificare i Priors",
    "text": "63.6 Specificare i Priors\nSe vogliamo personalizzare i priors, possiamo utilizzare la funzione get_prior per esplorare quelli predefiniti:\n\nget_prior(height ~ 1 + weight_c, data = df)\n#&gt;                     prior     class     coef group resp dpar nlpar lb ub\n#&gt;  student_t(3, 154.3, 8.5) Intercept                                     \n#&gt;                    (flat)         b                                     \n#&gt;                    (flat)         b weight_c                            \n#&gt;      student_t(3, 0, 8.5)     sigma                                 0   \n#&gt;        source\n#&gt;       default\n#&gt;       default\n#&gt;  (vectorized)\n#&gt;       default\n\n\n\nprior: descrive il prior predefinito assegnato a ciascun parametro del modello. Ad esempio:\n\n\nstudent_t(3, 154.3, 8.5): prior t di Student per l‚Äôintercetta con 3 gradi di libert√†, una media di 154.3, e una scala di 8.5.\n\n(flat): prior piatto (non informativo) per i coefficienti delle variabili predittive, come \\(b\\) e \\(b_{weight_c}\\).\n\nstudent_t(3, 0, 8.5): prior t di Student per il parametro \\(\\sigma\\) (deviazione standard residua), centrato su 0 con una scala di 8.5.\n\n\n\nclass: identifica la classe di parametro a cui il prior si applica:\n\n\nIntercept: prior per l‚Äôintercetta (\\(\\alpha\\)).\n\nb: prior per i coefficienti delle variabili predittive (\\(\\beta\\)).\n\nsigma: prior per il parametro della deviazione standard residua (\\(\\sigma\\)).\n\n\n\ncoef: specifica a quale predittore si riferisce il prior, se applicabile. Ad esempio:\n\nVuoto per l‚Äôintercetta (poich√© non dipende da un predittore specifico).\n\nweight_c per il coefficiente relativo al predittore weight_c.\n\n\n\nlb e ub: rappresentano rispettivamente i limiti inferiori (lower bound) e superiori (upper bound) per il prior, se specificati. Ad esempio:\n\nPer sigma, il limite inferiore √® \\(0\\), dato che la deviazione standard non pu√≤ essere negativa.\n\n\n\nsource: indica l‚Äôorigine del prior. Se il prior √® predefinito (default), il valore sar√† default. Se un prior √® specificato manualmente dall‚Äôutente, sar√† indicato come tale.\n\nOra impostiamo priors espliciti e adattiamo un nuovo modello:\n\nprior_guassian &lt;-\n  prior(normal(160, 10), class = \"b\", coef = \"Intercept\") +\n  prior(normal(0, 5), class = \"b\", coef = \"weight_c\") +\n  prior(cauchy(0, 5), class = \"sigma\")\n\n\nfit_2 = brm(\n  bf(height ~ 1 + weight_c, center = FALSE), \n  prior = prior_guassian,\n  data = df, \n  backend = \"cmdstanr\", \n  silent = 0\n)\n\nOtteniamo un sommario numerico dei parametri stimati:\n\ndraws &lt;- posterior::as_draws(fit_2, variable = \"^b_\", regex = TRUE)\nposterior::summarise_draws(draws, \"mean\", \"sd\", \"mcse_mean\", \"mcse_sd\")\n#&gt; # A tibble: 2 √ó 5\n#&gt;   variable       mean     sd mcse_mean  mcse_sd\n#&gt;   &lt;chr&gt;         &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 b_Intercept 155.    0.273   0.00425  0.00409 \n#&gt; 2 b_weight_c    0.905 0.0428  0.000703 0.000678\n\nI prior che abbiamo specificato non cambiano in maniera rilevante la soluzione a posteriori.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>¬† <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar.html#predizioni-predittive-a-posteriori",
    "href": "chapters/linear_models/04_synt_sugar.html#predizioni-predittive-a-posteriori",
    "title": "63¬† Zucchero sintattico",
    "section": "\n63.7 Predizioni Predittive a Posteriori",
    "text": "63.7 Predizioni Predittive a Posteriori\nUn aspetto fondamentale nella valutazione di un modello statistico, sia frequentista che bayesiano, √® verificare quanto bene i dati osservati siano rappresentati dalle predizioni del modello. Tuttavia, l‚Äôapproccio e l‚Äôinterpretazione differiscono tra i due paradigmi.\n\n63.7.1 Confronto Frequentista\nNel caso frequentista, si confrontano i valori predetti dal modello, \\(\\hat{y} = \\hat{\\alpha} + \\hat{\\beta}x\\), con i dati osservati. Questo confronto si basa sull‚Äôanalisi di: - La vicinanza della retta di regressione stimata ai dati osservati. - L‚Äôeventuale presenza di pattern nei dati che si discostano da un andamento lineare. - La variazione della dispersione dei valori di \\(y\\) rispetto a \\(x\\) (ad esempio, per verificare l‚Äôipotesi di omoschedasticit√†).\n\n63.7.2 Approccio Bayesiano\nNell‚Äôapproccio bayesiano, si eseguono le stesse verifiche di base, ma l‚Äôanalisi si arricchisce attraverso l‚Äôuso delle Predizioni Predittive a Posteriori (Posterior Predictive Checks, PPCs). Questo metodo consente di confrontare i dati osservati con dati simulati dal modello, utilizzando l‚Äôincertezza stimata nelle distribuzioni a posteriori dei parametri.\n\n63.7.3 Costruzione delle Predizioni Predittive a Posteriori\nNel caso di un modello bivariato, il processo per generare un grafico delle Predizioni Predittive a Posteriori √® il seguente:\n\nDati osservati: Si parte dall‚Äôistogramma lisciato dei dati osservati, che rappresenta la distribuzione empirica di \\(y\\).\n\nSimulazione di dati predetti:\n\nSi estrae un campione casuale di valori \\(\\alpha'\\), \\(\\beta'\\), e \\(\\sigma'\\) dalle distribuzioni a posteriori dei parametri (\\(\\alpha\\), \\(\\beta\\), e \\(\\sigma\\)).\nUsando questi valori, si calcolano dati simulati da una distribuzione normale: \\[\ny_{\\text{sim}} \\sim \\mathcal{N}(\\alpha' + \\beta'x, \\sigma')\n\\] dove \\(x\\) sono i valori predittori osservati.\n\n\nCreazione di istogrammi: Per ogni campione simulato, si costruisce un istogramma lisciato che rappresenta la distribuzione predetta dal modello.\nRipetizione: Il processo viene ripetuto pi√π volte, generando molti istogrammi lisciati.\nConfronto: Tutti gli istogrammi predetti vengono sovrapposti all‚Äôistogramma dei dati osservati. Questo consente di confrontare visivamente la capacit√† del modello di rappresentare la distribuzione dei dati.\n\n63.7.4 Interpretazione\n\n\nBuona corrispondenza: Se gli istogrammi lisciati dei dati simulati si sovrappongono bene all‚Äôistogramma dei dati osservati, significa che il modello √® in grado di rappresentare adeguatamente il campione corrente.\n\nDiscrepanze: Se vi sono discrepanze sistematiche (ad esempio, picchi o code mancanti nei dati predetti rispetto agli osservati), ci√≤ indica che il modello potrebbe non essere adeguato o che vi sono aspetti dei dati non catturati dal modello.\n\nL‚Äôapproccio delle Predizioni Predittive a Posteriori √® particolarmente potente perch√©:\n\nIntegra l‚Äôincertezza nei parametri del modello.\nPermette di verificare non solo la bont√† di adattamento complessiva, ma anche specifici aspetti delle distribuzioni predette.\n√à visivo e intuitivo, facilitando l‚Äôidentificazione di discrepanze tra modello e dati.\n\nIn conclusione, le Predizioni Predittive a Posteriori forniscono un modo robusto per valutare l‚Äôadeguatezza di un modello bayesiano rispetto ai dati osservati. Se il modello riproduce bene la distribuzione dei dati osservati, si pu√≤ concludere che √® adatto almeno per il campione corrente. In caso contrario, potrebbe essere necessario rivedere le specifiche del modello, come i priors o la struttura delle variabili.\nVerifichiamo dunque le predizioni del modello confrontandole con i dati osservati del campione corrente:\n\npp_check(fit_2)\n\n\n\n\n\n\n\nNel caso presente, vi √® una buona corrispondenza tra i dati simulati dal modello e i dati osservati.\nIl grafico seguente analizza gli errori del modello rispetto alla retta di regressione stimata.\n\npp_check(fit_1, type = \"error_scatter_avg\")\n\n\n\n\n\n\n\nQuesto comando utilizza la funzione pp_check() per produrre un grafico che mostra i residui bayesiani, ovvero le differenze tra i dati osservati e quelli predetti dal modello. Nel tipo specifico di grafico scelto (\"error_scatter_avg\"), i residui sono rappresentati rispetto ai valori predetti, consentendo di valutare visivamente se sono distribuiti in modo uniforme.\nDal grafico, si osserva che i residui bayesiani appaiono distribuiti in modo omogeneo rispetto alla retta di regressione (che non √® direttamente mostrata nel grafico). Questo suggerisce che:\n\nIl modello cattura correttamente la relazione tra la variabile predittiva e la variabile di risposta.\nNon ci sono pattern sistematici nei residui, come deviazioni non lineari o variazioni della dispersione (eteroschedasticit√†).\n\nSe fossero presenti pattern evidenti nei residui (ad esempio, una struttura curva o una variazione sistematica della dispersione), ci√≤ indicherebbe che il modello potrebbe non essere adeguato, richiedendo una rivalutazione della sua struttura (ad esempio, aggiungendo termini non lineari o trasformando le variabili).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>¬† <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar.html#regressione-robusta",
    "href": "chapters/linear_models/04_synt_sugar.html#regressione-robusta",
    "title": "63¬† Zucchero sintattico",
    "section": "\n63.8 Regressione Robusta",
    "text": "63.8 Regressione Robusta\nIn questa sezione introduciamo la regressione robusta. Lo scopo √® quello di mostrare quanto sia facile modificare il modello definito da brm per specificare una diversa distribuzione degli errori. Questo non √® possibile nel caso dell‚Äôapproccio frequentista.\nI modelli robusti sono utili in presenza di outlier. Ad esempio, introduciamo un outlier nei dati:\n\ndf_outlier &lt;- df\ndf_outlier$height[1] &lt;- 200\ndf_outlier$weight_c[1] &lt;- -15\n\n\ndf_outlier |&gt; \n  ggplot(aes(x = weight_c, y = height)) +\n    geom_point() +  \n    labs(x = \"Weight\", y = \"Height\") \n\n\n\n\n\n\n\nNotiamo come la presenza di un solo outlier introduce una distorsione nei risultati:\n\nfit_3 = brm(\n  bf(height ~ 1 + weight_c, center = FALSE), \n  prior = prior_guassian,\n  data = df_outlier, \n  backend = \"cmdstanr\", \n  silent = 0\n)\n\n\ndraws &lt;- posterior::as_draws(fit_3, variable = \"^b_\", regex = TRUE)\nposterior::summarise_draws(draws, \"mean\", \"sd\", \"mcse_mean\", \"mcse_sd\")\n#&gt; # A tibble: 2 √ó 5\n#&gt;   variable       mean     sd mcse_mean  mcse_sd\n#&gt;   &lt;chr&gt;         &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 b_Intercept 155.    0.319   0.00489  0.00481 \n#&gt; 2 b_weight_c    0.845 0.0494  0.000792 0.000709\n\nAdattiamo ora un modello robusto utilizzando una distribuzione \\(t\\) di Student:\n\nfit_4 = brm(\n  bf(height ~ 1 + weight_c, center = FALSE), \n  prior = prior_guassian,\n  family = student(),\n  data = df_outlier, \n  backend = \"cmdstanr\", \n  silent = 0\n)\n\nI risultati mostrano che il modello \\(t\\) √® meno influenzato dagli outlier rispetto al modello gaussiano.\n\ndraws &lt;- posterior::as_draws(fit_4, variable = \"^b_\", regex = TRUE)\nposterior::summarise_draws(draws, \"mean\", \"sd\", \"mcse_mean\", \"mcse_sd\")\n#&gt; # A tibble: 2 √ó 5\n#&gt;   variable       mean     sd mcse_mean  mcse_sd\n#&gt;   &lt;chr&gt;         &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 b_Intercept 155.    0.267   0.00426  0.00429 \n#&gt; 2 b_weight_c    0.921 0.0395  0.000643 0.000593\n\nIl parametro \\(\\nu\\) della \\(t\\) di Student viene stimato dal modello. Nel caso presente\n\ndraws &lt;- posterior::as_draws(fit_4, variable = \"nu\")\nposterior::summarise_draws(draws, \"mean\", \"sd\", \"mcse_mean\", \"mcse_sd\")\n#&gt; # A tibble: 1 √ó 5\n#&gt;   variable  mean    sd mcse_mean mcse_sd\n#&gt;   &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 nu        6.09  1.69    0.0303  0.0341\n\nCon un parametro \\(\\nu\\) = 6, la \\(t\\) di Student ha delle ‚Äúcode‚Äù molto maggiori di una gaussiana, e questo le consene di ‚Äúassorbire‚Äù gli outliers in maniera maggiore che la gaussiana.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>¬† <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar.html#indice-di-determinazione-bayesiano",
    "href": "chapters/linear_models/04_synt_sugar.html#indice-di-determinazione-bayesiano",
    "title": "63¬† Zucchero sintattico",
    "section": "\n63.9 Indice di Determinazione Bayesiano",
    "text": "63.9 Indice di Determinazione Bayesiano\nCon il pacchetto brms, possiamo calcolare il Bayes \\(R^2\\), che rappresenta l‚Äôequivalente bayesiano del classico indice di determinazione \\(R^2\\). Questo indice quantifica la proporzione di varianza spiegata dal modello, tenendo conto dell‚Äôincertezza intrinseca delle stime bayesiane.\nIl comando per calcolarlo √®:\n\nbayes_R2(fit_4)\n#&gt;    Estimate Est.Error   Q2.5  Q97.5\n#&gt; R2   0.5006   0.01975 0.4599 0.5362\n\nIl comando restituisce un tibble (una tabella ordinata) con le seguenti informazioni:\n\n\nEstimate: La stima media del Bayes \\(R^2\\), cio√® la proporzione di varianza spiegata dal modello, basata sulle distribuzioni a posteriori dei parametri.\n\nEst.Error: L‚Äôerrore standard associato alla stima del \\(R^2\\).\n\nQ2.5 e Q97.5: I limiti inferiore e superiore dell‚Äôintervallo di credibilit√† al 95% per il Bayes \\(R^2\\). Questi valori indicano l‚Äôincertezza sul \\(R^2\\), riflettendo la distribuzione a posteriori.\n\nNel caso presente\n\n\nStima del \\(R^2\\): Il modello spiega in media circa il 50% della varianza osservata nella variabile dipendente.\n\nErrore Standard: L‚Äôincertezza sulla stima √® relativamente bassa (¬±0.02).\n\nIntervallo di Credibilit√†: C‚Äô√® un 95% di probabilit√† che il vero valore del \\(R^2\\) si trovi tra 0.457 e 0.537.\n\n\n63.9.1 Differenze rispetto al Frequentista \\(R^2\\)\n\n\n\nIncertezza: Il Bayes \\(R^2\\) include un‚Äôintera distribuzione a posteriori, permettendo di rappresentare l‚Äôincertezza attraverso l‚Äôintervallo di credibilit√†. Questo non √® possibile con il \\(R^2\\) frequentista, che fornisce una stima puntuale.\n\nPriors: Il Bayes \\(R^2\\) √® influenzato dai priors scelti per i parametri del modello, il che consente una maggiore flessibilit√† e incorpora conoscenze preesistenti.\n\nIn conclusione, il Bayes \\(R^2\\) √® uno strumento potente per valutare l‚Äôadattamento di un modello bayesiano, permettendo di quantificare non solo la proporzione di varianza spiegata, ma anche l‚Äôincertezza associata alla stima.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>¬† <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar.html#approfondimento-sulla-manipolazione-della-distribuzione-a-posteriori-con-brms",
    "href": "chapters/linear_models/04_synt_sugar.html#approfondimento-sulla-manipolazione-della-distribuzione-a-posteriori-con-brms",
    "title": "63¬† Zucchero sintattico",
    "section": "\n63.10 Approfondimento sulla manipolazione della distribuzione a posteriori con brms\n",
    "text": "63.10 Approfondimento sulla manipolazione della distribuzione a posteriori con brms\n\nDi seguito illustriamo come accedere e manipolare i campioni generati dal modello bayesiano in brms. Supponiamo di aver costruito un modello lineare semplice, dove vogliamo predire la variabile height in funzione di weight_c:\nfit_1 &lt;- brm(\n  bf(height ~ 1 + weight_c, center = FALSE), \n  data = df, \n  backend = \"cmdstanr\", \n  silent = 0\n)\nUna volta che il modello √® stato fit, possiamo estrarre le draws (ossia i campioni) della distribuzione a posteriori tramite la funzione as_draws():\n\nposterior_1 &lt;- as_draws(fit_1)\n\n\n63.10.1 Struttura dei campioni a posteriori\nL‚Äôoggetto posterior_1 ottenuto √® di tipo draws (una struttura definita dal pacchetto posterior), che internamente pu√≤ essere rappresentato come una lista o un array in cui sono memorizzati i campioni MCMC:\n\nstr(posterior_1)\n#&gt; List of 4\n#&gt;  $ 1:List of 5\n#&gt;   ..$ b_Intercept: num [1:1000] 155 155 154 155 154 ...\n#&gt;   ..$ b_weight_c : num [1:1000] 0.886 0.84 0.91 0.888 0.98 ...\n#&gt;   ..$ sigma      : num [1:1000] 5.36 5.21 5.07 4.97 5.36 ...\n#&gt;   ..$ lprior     : num [1:1000] -2.7 -2.68 -2.67 -2.66 -2.7 ...\n#&gt;   ..$ lp__       : num [1:1000] -1077 -1074 -1073 -1072 -1075 ...\n#&gt;  $ 2:List of 5\n#&gt;   ..$ b_Intercept: num [1:1000] 154 155 155 154 155 ...\n#&gt;   ..$ b_weight_c : num [1:1000] 0.967 0.924 0.865 0.929 0.891 ...\n#&gt;   ..$ sigma      : num [1:1000] 5.25 5.25 4.88 4.94 4.99 ...\n#&gt;   ..$ lprior     : num [1:1000] -2.69 -2.69 -2.66 -2.66 -2.67 ...\n#&gt;   ..$ lp__       : num [1:1000] -1074 -1073 -1073 -1073 -1072 ...\n#&gt;  $ 3:List of 5\n#&gt;   ..$ b_Intercept: num [1:1000] 155 155 154 155 155 ...\n#&gt;   ..$ b_weight_c : num [1:1000] 0.953 0.955 0.809 0.933 0.939 ...\n#&gt;   ..$ sigma      : num [1:1000] 4.97 4.94 5.12 5.3 5.7 ...\n#&gt;   ..$ lprior     : num [1:1000] -2.66 -2.66 -2.68 -2.69 -2.73 ...\n#&gt;   ..$ lp__       : num [1:1000] -1073 -1073 -1075 -1075 -1077 ...\n#&gt;  $ 4:List of 5\n#&gt;   ..$ b_Intercept: num [1:1000] 155 155 154 154 154 ...\n#&gt;   ..$ b_weight_c : num [1:1000] 0.905 0.899 0.878 0.913 0.938 ...\n#&gt;   ..$ sigma      : num [1:1000] 5.24 4.98 4.79 5.11 5.09 ...\n#&gt;   ..$ lprior     : num [1:1000] -2.69 -2.66 -2.65 -2.68 -2.67 ...\n#&gt;   ..$ lp__       : num [1:1000] -1072 -1072 -1074 -1072 -1073 ...\n#&gt;  - attr(*, \"class\")= chr [1:3] \"draws_list\" \"draws\" \"list\"\n\nQuesta ispezione ti permette di vedere che l‚Äôoggetto contiene le catene e i parametri campionati.\n\n63.10.2 Estrazione di un parametro specifico\nPossiamo estrarre i nomi dei parametri del modello dall‚Äôoggetto creato da brm() nel modo seguente:\n\nvariables(fit_1)\n#&gt; [1] \"b_Intercept\" \"b_weight_c\"  \"sigma\"       \"lprior\"      \"lp__\"\n\nNel nostro esempio, siamo interessati al coefficiente di regressione associato a weight_c, che in brms √® etichettato come b_weight_c. Per semplificare la manipolazione e l‚Äôanalisi, possiamo servirci di tidybayes, un pacchetto che fornisce funzioni utili per trasformare i campioni in formati ‚Äútidy‚Äù.\n\nlibrary(tidybayes)\n\nb_slope_draws &lt;- posterior_1 |&gt; \n  spread_draws(b_weight_c)\n\nLa funzione spread_draws() estrae e ‚Äúsrotola‚Äù le draw dei parametri in un tibble, che risulta pi√π comodo da esplorare:\n\nhead(b_slope_draws)\n#&gt; # A tibble: 6 √ó 4\n#&gt;   .chain .iteration .draw b_weight_c\n#&gt;    &lt;int&gt;      &lt;int&gt; &lt;int&gt;      &lt;dbl&gt;\n#&gt; 1      1          1     1      0.886\n#&gt; 2      1          2     2      0.840\n#&gt; 3      1          3     3      0.910\n#&gt; 4      1          4     4      0.888\n#&gt; 5      1          5     5      0.980\n#&gt; 6      1          6     6      0.884\n\nIn questo modo, ogni riga corrisponde a un singolo campione della catena MCMC, per quel parametro.\n\n63.10.3 Calcolo di statistiche riassuntive\nUna volta estratti i campioni del parametro di interesse (qui b_weight_c), possiamo calcolare facilmente statistiche come quantili e medie:\n\nquantile(b_slope_draws$b_weight_c, probs = c(0.03, 0.50, 0.97))\n#&gt;     3%    50%    97% \n#&gt; 0.8263 0.9060 0.9845\n\n\nmean(b_slope_draws$b_weight_c)\n#&gt; [1] 0.9056\n\n\nI quantili a 0.03, 0.50 e 0.97 forniscono, rispettivamente, un limite inferiore al 94% (0.03‚Äì0.97), la mediana a posteriori (0.50) e un limite superiore.\n\nLa funzione mean() restituisce la media a posteriori del coefficiente, un‚Äôaltra statistica utile per la stima puntuale.\n\n63.10.4 Visualizzazione della distribuzione a posteriori\nPer comprendere meglio la forma della distribuzione a posteriori, √® buona prassi tracciarne la densit√†. Con tidyverse e tidybayes, possiamo creare un grafico elegante in poche righe:\n\ntibble(beta = b_slope_draws$b_weight_c) %&gt;%\n  ggplot(aes(x = beta)) +\n  stat_halfeye(fill = \"skyblue\", alpha = 0.6) +\n  labs(\n    title = \"Distribuzione a posteriori di Œ≤ (b_weight_c)\",\n    x = \"Valore di Œ≤\",\n    y = \"Densit√† a posteriori\"\n  )\n\n\n\n\n\n\n\n\n\nstat_halfeye() mostra la densit√† stimata dei campioni, evidenziando in modo intuitivo i valori pi√π probabili.\n\nIl colore e l‚Äôalpha permettono di personalizzare l‚Äôaspetto del grafico.\n\nIn sintesi, utilizzando l‚Äôoggetto restituito da brm() e la funzione as_draws(), possiamo estrarre i campioni della distribuzione a posteriori e analizzare:\n\n\nstatistiche di sintesi, come media, mediana e quantili;\n\ndistribuzioni di densit√†, per una visualizzazione pi√π immediata della variabilit√† e della forma della distribuzione a posteriori di un parametro.\n\nLa combinazione di posterior, tidybayes e tidyverse rende l‚Äôintero flusso di lavoro ‚Äî dall‚Äôestrazione dei campioni fino alla creazione di grafici e statistiche ‚Äî semplice e molto flessibile.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>¬† <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar.html#riflessioni-conclusive",
    "href": "chapters/linear_models/04_synt_sugar.html#riflessioni-conclusive",
    "title": "63¬† Zucchero sintattico",
    "section": "\n63.11 Riflessioni Conclusive",
    "text": "63.11 Riflessioni Conclusive\nQuesto capitolo ha mostrato come utilizzare brms per costruire e interpretare modelli lineari, evidenziando le sue capacit√† di gestione dei priors, diagnostica e modellizzazione robusta. Grazie alla sua semplicit√† e flessibilit√†, brms rappresenta un potente strumento per l‚Äôinferenza bayesiana.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>¬† <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/04_synt_sugar.html#informazioni-sullambiente-di-sviluppo",
    "title": "63¬† Zucchero sintattico",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] tidybayes_3.0.7     rstan_2.32.7        StanHeaders_2.32.10\n#&gt;  [4] cmdstanr_0.8.1      posterior_1.6.1     brms_2.22.0        \n#&gt;  [7] Rcpp_1.0.14         thematic_0.1.6      MetBrewer_0.2.0    \n#&gt; [10] ggokabeito_0.1.0    see_0.11.0          gridExtra_2.3      \n#&gt; [13] patchwork_1.3.0     bayesplot_1.11.1    psych_2.5.3        \n#&gt; [16] scales_1.3.0        markdown_2.0        knitr_1.50         \n#&gt; [19] lubridate_1.9.4     forcats_1.0.0       stringr_1.5.1      \n#&gt; [22] dplyr_1.1.4         purrr_1.0.4         readr_2.1.5        \n#&gt; [25] tidyr_1.3.1         tibble_3.2.1        ggplot2_3.5.1      \n#&gt; [28] tidyverse_2.0.0     rio_1.2.3           here_1.0.1         \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] mnormt_2.1.1         inline_0.3.21        sandwich_3.1-1      \n#&gt;  [4] rlang_1.1.5          magrittr_2.0.3       multcomp_1.4-28     \n#&gt;  [7] matrixStats_1.5.0    compiler_4.4.2       loo_2.8.0           \n#&gt; [10] vctrs_0.6.5          reshape2_1.4.4       arrayhelpers_1.1-0  \n#&gt; [13] pkgconfig_2.0.3      fastmap_1.2.0        backports_1.5.0     \n#&gt; [16] labeling_0.4.3       utf8_1.2.4           rmarkdown_2.29      \n#&gt; [19] tzdb_0.5.0           ps_1.9.0             xfun_0.51           \n#&gt; [22] jsonlite_1.9.1       parallel_4.4.2       R6_2.6.1            \n#&gt; [25] stringi_1.8.4        estimability_1.5.1   zoo_1.8-13          \n#&gt; [28] pacman_0.5.1         R.utils_2.13.0       Matrix_1.7-3        \n#&gt; [31] splines_4.4.2        timechange_0.3.0     tidyselect_1.2.1    \n#&gt; [34] rstudioapi_0.17.1    abind_1.4-8          yaml_2.3.10         \n#&gt; [37] codetools_0.2-20     curl_6.2.2           processx_3.8.6      \n#&gt; [40] pkgbuild_1.4.7       lattice_0.22-6       plyr_1.8.9          \n#&gt; [43] withr_3.0.2          bridgesampling_1.1-2 coda_0.19-4.1       \n#&gt; [46] evaluate_1.0.3       survival_3.8-3       RcppParallel_5.1.10 \n#&gt; [49] ggdist_3.3.2         pillar_1.10.1        tensorA_0.36.2.1    \n#&gt; [52] checkmate_2.3.2      stats4_4.4.2         distributional_0.5.0\n#&gt; [55] generics_0.1.3       rprojroot_2.0.4      hms_1.1.3           \n#&gt; [58] rstantools_2.4.0     munsell_0.5.1        xtable_1.8-4        \n#&gt; [61] glue_1.8.0           emmeans_1.11.0       tools_4.4.2         \n#&gt; [64] data.table_1.17.0    mvtnorm_1.3-3        grid_4.4.2          \n#&gt; [67] QuickJSR_1.6.0       colorspace_2.1-1     nlme_3.1-167        \n#&gt; [70] cli_3.6.4            svUnit_1.0.6         Brobdingnag_1.2-9   \n#&gt; [73] V8_6.0.2             gtable_0.3.6         R.methodsS3_1.8.2   \n#&gt; [76] digest_0.6.37        TH.data_1.1-3        htmlwidgets_1.6.4   \n#&gt; [79] farver_2.1.2         htmltools_0.5.8.1    R.oo_1.27.0         \n#&gt; [82] lifecycle_1.0.4      MASS_7.3-65",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>¬† <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar.html#bibliografia",
    "href": "chapters/linear_models/04_synt_sugar.html#bibliografia",
    "title": "63¬† Zucchero sintattico",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAlter, U., Too, M. A., & Cribbie, R. A. (2025). Navigating the Bayes maze: The psychologist‚Äôs guide to Bayesian statistics, a hands-on tutorial with R code. International Journal of Psychology, 60(1), e13271.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nWilkinson, G., & Rogers, C. (1973). Symbolic description of factorial models for analysis of variance. Journal of the Royal Statistical Society Series C: Applied Statistics, 22(3), 392‚Äì399.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>¬† <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean.html",
    "href": "chapters/linear_models/05_one_mean.html",
    "title": "64¬† Inferenza bayesiana su una media",
    "section": "",
    "text": "64.1 Preparazione del Notebook\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(cmdstanr, posterior, bayestestR, brms)",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean.html#introduzione",
    "href": "chapters/linear_models/05_one_mean.html#introduzione",
    "title": "64¬† Inferenza bayesiana su una media",
    "section": "\n64.2 Introduzione",
    "text": "64.2 Introduzione\nL‚Äôobiettivo principale di questo capitolo √® esaminare un contesto che abbiamo gi√† preso in considerazione in precedenza: ci troviamo di fronte a un campione di dati misurati su una scala a intervalli o rapporti e desideriamo effettuare inferenze sulla media della popolazione da cui il campione √® stato estratto. Tuttavia, anzich√© procedere con una derivazione analitica della distribuzione a posteriori della media della popolazione, in questo caso utilizzeremo brms.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean.html#il-modello-normale",
    "href": "chapters/linear_models/05_one_mean.html#il-modello-normale",
    "title": "64¬† Inferenza bayesiana su una media",
    "section": "\n64.3 Il modello Normale",
    "text": "64.3 Il modello Normale\nI priori coniugati Normali di una Normale non richiedono l‚Äôapprossimazione numerica ottenuta mediante metodi MCMC. In questo capitolo, tuttavia, ripetiamo l‚Äôesercizio descritto nel Capitolo 51 usando brms.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean.html#un-esempio-concreto",
    "href": "chapters/linear_models/05_one_mean.html#un-esempio-concreto",
    "title": "64¬† Inferenza bayesiana su una media",
    "section": "\n64.4 Un esempio concreto",
    "text": "64.4 Un esempio concreto\nPer applicare il modello Normale, utilizzeremo i dati del censimento parziale dell‚Äôarea di Dobe dei !Kung San, raccolti attraverso interviste condotte da Nancy Howell alla fine degli anni ‚Äô60. I !Kung San sono una suddivisione della popolazione San, che vive nel deserto del Kalahari, tra Namibia, Botswana e Angola, e mantengono un‚Äôeconomia basata su caccia e raccolta. Riprodurremo l‚Äôanalisi descritta da McElreath (2020), esaminando unicamente i valori dell‚Äôaltezza di individui di et√† superiore ai 18 anni.\n\ndf &lt;- rio::import(here::here(\"data\", \"Howell_18.csv\"))\ndf |&gt; \n  head()\n#&gt;   height weight age male\n#&gt; 1  151.8  47.83  63    1\n#&gt; 2  139.7  36.49  63    0\n#&gt; 3  136.5  31.86  65    0\n#&gt; 4  156.8  53.04  41    1\n#&gt; 5  145.4  41.28  51    0\n#&gt; 6  163.8  62.99  35    1\n\nIl campione include 352 osservazioni:\n\nlength(df$height)\n#&gt; [1] 352\n\n\nggplot(df, aes(x = height)) +\n  geom_histogram(binwidth = 5, color = \"black\", fill = \"lightgray\") +\n  labs(title = \"Istogramma dell'Altezza\", x = \"Altezza (cm)\", y = \"Frequenza\") +\n  theme(\n    plot.title = element_text(hjust = 0.5)\n  )\n\n\n\n\n\n\n\nCome indicato dall‚Äôistogramma, i dati sono approssimativamente distribuiti in maniera gaussiana:\n\ndf |&gt;\n  ggplot(aes(sample = height)) +\n  stat_qq() +\n  stat_qq_line(colour = \"red\") +\n  labs(\n    title = \"Normal Q-Q plot\",\n    x = \"Teorici (Z-score)\",\n    y = \"Valori osservati\"\n  ) +\n  theme(\n    plot.title = element_text(hjust = 0.5)\n  )\n\n\n\n\n\n\n\nIn realt√†, dal Q-Q plot si nota un piccolo scostamento sistematico. Quando la retta che approssima i punti empirici risulta pi√π piatta rispetto alla diagonale teorica (che avrebbe pendenza 1 se i dati fossero perfettamente normali), la distribuzione empirica risulta meno dispersa di una Gaussiana di riferimento: i quantili empirici aumentano pi√π lentamente di quelli teorici, indicando una varianza leggermente inferiore (o code meno ampie). Nel caso presente, tuttavia, questo scostamento √® di modesta entit√† e si pu√≤ comunque procedere all‚Äôadattamento di un modello gaussiano.\nLa media dei valori dell‚Äôaltezza nel campione √®:\n\nmean(df$height)\n#&gt; [1] 154.6\n\ncon una deviazione standard pari a:\n\nsd(df$height)\n#&gt; [1] 7.742",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean.html#modello-frequentista-semplice",
    "href": "chapters/linear_models/05_one_mean.html#modello-frequentista-semplice",
    "title": "64¬† Inferenza bayesiana su una media",
    "section": "\n64.5 Modello frequentista semplice",
    "text": "64.5 Modello frequentista semplice\nIniziamo con un modello frequentista molto semplice, in cui ipotizziamo che ogni osservazione \\(y_i\\) sia generata dal modello:\n\\[\ny_i = \\alpha + \\varepsilon_i,\n\\]\ndove \\(\\varepsilon_i\\) √® un errore aleatorio con media zero (ad esempio, \\(\\varepsilon_i \\sim \\mathcal{N}(0, \\sigma^2)\\)) e \\(\\alpha\\) √® la sola incognita (intercetta). Poich√© non ci interessa includere altre variabili predittive, stiamo stimando semplicemente la media di \\(y\\).\nLa stima di \\(\\alpha\\) √® basata sul principio di massima verosimiglianza, senza informazioni a priori. In R, con l‚Äôapproccio frequentista, ci basta usare:\n\nfm1 &lt;- lm(\n  formula = height ~ 1, \n  data = df\n)\n\nQui, height ~ 1 indica che vogliamo un modello con sola intercetta (nessuna covariata). Analizziamo il risultato:\n\nsummary(fm1)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = height ~ 1, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -18.072  -6.007  -0.292   6.058  24.473 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)\n#&gt; (Intercept)  154.597      0.413     375   &lt;2e-16\n#&gt; \n#&gt; Residual standard error: 7.74 on 351 degrees of freedom\n\n\n\nsummary(fm1) mostra la stima puntuale di \\(\\alpha\\) (che √® la media campionaria di height) assieme ad altri indicatori (p-value, R-squared e cos√¨ via, anche se in questo caso non ha senso parlare di R-squared con un solo parametro).\n\n\n64.5.1 Intervallo di confidenza al 95%\nPer ottenere l‚Äôintervallo di confidenza (nel senso frequentista) della stima di \\(\\alpha\\), usiamo:\n\nconfint(fm1, level = 0.95)\n#&gt;             2.5 % 97.5 %\n#&gt; (Intercept) 153.8  155.4\n\nQuesto produce l‚Äôintervallo di confidenza al 95% basato su procedure di inferenza classica (stima della varianza e dell‚Äôerrore standard di \\(\\alpha\\)).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean.html#modello-bayesiano-senza-specificare-priori-priori-uniformi",
    "href": "chapters/linear_models/05_one_mean.html#modello-bayesiano-senza-specificare-priori-priori-uniformi",
    "title": "64¬† Inferenza bayesiana su una media",
    "section": "\n64.6 Modello bayesiano senza specificare priori (priori uniformi)",
    "text": "64.6 Modello bayesiano senza specificare priori (priori uniformi)\nOra vogliamo replicare lo stesso modello usando un approccio bayesiano con il pacchetto brms. Se non specifichiamo esplicitamente la distribuzione a priori di \\(\\alpha\\), brms usa di default un priore piatto (o debolmente informativo), di fatto molto simile a non avere un‚Äôinformazione a priori.\nIl codice √® analogo:\n\nfm2 &lt;- brm(\n  formula = height ~ 1, \n  data = df,\n  backend = \"cmdstanr\"\n)\n\n\nAnche qui, il modello √® \\(y_i = \\alpha + \\varepsilon_i\\), ma gestito in modo bayesiano.\n\nsummary(fm2) mostrer√† la posterior mean (o mediana, a seconda dei parametri di configurazione) per \\(\\alpha\\), l‚Äôerrore standard e l‚Äôintervallo di credibilit√†.\n\n\nsummary(fm2)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: height ~ 1 \n#&gt;    Data: df (Number of observations: 352) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept   154.59      0.41   153.76   155.38 1.00     2729     2179\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     7.77      0.30     7.20     8.37 1.00     3096     2129\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n64.6.1 Intervallo di credibilit√†\nL‚Äôoutput di summary(fm2) presenta di default l‚Äôintervallo di credibilit√† al 95%. Questo valore pu√≤ essere modificato con l‚Äôargomento prob =, ad esempio summary(fm2, prob = 0.90) per un 90% di credibilit√†.\nIn assenza di un priore informativo, la distribuzione a posteriori √® sostanzialmente uguale a quella massima verosimiglianza (pi√π un‚Äôeventuale correzione di normalizzazione), quindi i risultati numerici corrispondono molto da vicino a quelli ottenuti dal metodo frequentista. Piccole discrepanze sono dovute alle approssimazioni MCMC.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean.html#differenze-di-interpretazione-degli-intervalli",
    "href": "chapters/linear_models/05_one_mean.html#differenze-di-interpretazione-degli-intervalli",
    "title": "64¬† Inferenza bayesiana su una media",
    "section": "\n64.7 Differenze di interpretazione degli intervalli",
    "text": "64.7 Differenze di interpretazione degli intervalli\n\n\nApproccio frequentista:\n\nL‚Äôintervallo di confidenza (ad esempio \\([153.78, 155.41]\\)) √® un procedimento statistico che, se ripetuto molte volte su campioni diversi, ‚Äúcatturer√†‚Äù il vero valore di \\(\\alpha\\) nel 95% dei casi. In altre parole, √® un‚Äôaffermazione sul metodo di costruzione dell‚Äôintervallo, non sull‚Äôincertezza del parametro in s√©.\n\nNon √® lecito dire ‚Äúc‚Äô√® il 95% di probabilit√† che \\(\\alpha\\) stia nell‚Äôintervallo \\([153.78, 155.41]\\)‚Äù. La probabilit√† si riferisce alla procedura di campionamento dei dati, non al parametro (che nel frequentismo √® considerato fisso e ignoto).\n\n\n\nApproccio bayesiano:\n\nL‚Äôintervallo di credibilit√† \\([153.78, 155.41]\\) al 95% dice che, dati i dati osservati e la prior (qui praticamente uniforme), c‚Äô√® il 95% di probabilit√† che \\(\\alpha\\) appartenga a quell‚Äôintervallo.\n\nQui la probabilit√† √® assegnata direttamente al parametro \\(\\alpha\\), perch√© nella prospettiva bayesiana il parametro √® visto come una variabile aleatoria che riflette la nostra incertezza prima dell‚Äôosservazione dei dati (prior) e dopo l‚Äôosservazione dei dati (posterior).\n\n\n\nIn sintesi:\n\n\nFrequentista: l‚Äôintervallo di fiducia √® una propriet√† della procedura di stima; il parametro √® fisso, i dati sono casuali.\n\n\nBayesiano: l‚Äôintervallo di credibilit√† √® una propriet√† della distribuzione a posteriori; il parametro √® casuale (nel senso che abbiamo incertezza su di esso), e i dati sono osservati.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean.html#riportare-i-risultati",
    "href": "chapters/linear_models/05_one_mean.html#riportare-i-risultati",
    "title": "64¬† Inferenza bayesiana su una media",
    "section": "\n64.8 Riportare i Risultati",
    "text": "64.8 Riportare i Risultati\nNel caso frequentista, il risultato pu√≤ essere riportato nel modo seguente:\n\nL‚Äôanalisi ha fornito una stima puntuale di Œ± pari a 154.6, con un intervallo di confidenza al 95% compreso tra [153.8; 155.4].\n\nNel caso bayesiano:\n\nL‚Äôanalisi bayesiana, condotta con una prior non informativa, ha restituito una stima a posteriori di Œ± pari a 154.6, con un intervallo di credibilit√† al 95% [153.8; 155.4].",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean.html#conclusioni-intermedie",
    "href": "chapters/linear_models/05_one_mean.html#conclusioni-intermedie",
    "title": "64¬† Inferenza bayesiana su una media",
    "section": "\n64.9 Conclusioni Intermedie",
    "text": "64.9 Conclusioni Intermedie\n\nCon lm() (modello lineare frequen¬≠tista), otteniamo la stima di \\(\\alpha\\) con massima verosimiglianza e un intervallo di confidenza al 95%.\n\nCon brm() e un priore piatto (o molto debole), il risultato numerico √® essenzialmente lo stesso, ma la filosofia interpretativa dell‚Äôintervallo \\([153.78, 155.41]\\) cambia.\n\nSe volessimo aggiungere informazioni a priori, potremmo specificare un priore su \\(\\alpha\\) in brm(), e otterremmo stime a posteriori diverse dalle frequentiste, soprattutto se i dati sono poco informativi.\n\nIn questo modo, abbiamo mostrato come lo stesso modello (una semplice stima di media) produca numeri quasi identici in ottica frequentista e bayesiana se il priore √® non informativo, pur differendo profondamente nell‚Äôinterpretazione degli intervalli risultanti.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean.html#modello-bayesiano-con-prior",
    "href": "chapters/linear_models/05_one_mean.html#modello-bayesiano-con-prior",
    "title": "64¬† Inferenza bayesiana su una media",
    "section": "\n64.10 Modello Bayesiano con Prior",
    "text": "64.10 Modello Bayesiano con Prior\nImpostiamo una distribuzione a priori \\(\\mathcal{N}(181, 30)\\) per il parametro \\(\\mu\\) e una distribuzione a priori \\(\\mathcal{N}(0, 20)\\) per il parametro \\(\\sigma\\). Seguendo McElreath (2020), ho impostato la distribuzione a priori per \\(\\mu\\) sul valore della mia altezza, per incorporare nel modello le mie conoscenze precedenti rispetto ai valori dell‚Äôaltezza.\nPertanto, il modello Normale si definisce nel modo seguente:\n\\[\n\\begin{align}\nY_i &\\sim \\mathcal{N}(\\mu, \\sigma) \\notag\\\\\n\\mu &\\sim \\mathcal{N}(181, 30) \\notag\\\\\n\\sigma &\\sim \\mathcal{N}(0, 20) \\notag\n\\end{align}\n\\]\nCon questa specifica del modello:\n\nLa variabile casuale \\(Y_i\\) segue una distribuzione normale con parametri \\(\\mu\\) e \\(\\sigma\\).\nIl parametro \\(\\mu\\) ha una distribuzione a priori normale con media 181 e deviazione standard 30.\nIl parametro \\(\\sigma\\) ha una distribuzione a priori normale con deviazione standard 20, troncata inferiormente a 0.\n\nPer \\(\\sigma\\), la normale troncata con deviazione standard pari a 20 permette una grande variabilit√†, garantendo valori positivi per la deviazione standard della distribuzione normale di \\(Y_i\\). I parametri \\(\\mu\\) e \\(\\sigma\\) sono sconosciuti e rappresentano l‚Äôoggetto dell‚Äôinferenza.\n\nfm3 &lt;- brm(\n  formula = height ~ 1,   # Modello con sola intercetta (mu)\n  data    = df,\n  family  = gaussian(),   # Distribuzione Normale\n  prior   = c(\n    prior(normal(181, 30), class = \"Intercept\"),  # Prior su mu\n    prior(normal(0, 20),   class = \"sigma\")       # Prior su sigma\n  ),\n  chains  = 4,\n  iter    = 2000,\n  seed    = 1234,\n  backend = \"cmdstanr\"\n)\n\n\nsummary(fm3)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: height ~ 1 \n#&gt;    Data: df (Number of observations: 352) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept   154.60      0.41   153.80   155.41 1.00     3156     2659\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     7.77      0.29     7.20     8.38 1.00     3256     2596\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nAnche usando questi prior debolmente informativi per \\(\\alpha\\) e \\(\\sigma\\), l‚Äôintervallo a posteriori per \\(\\alpha\\) coincide con quello frequentista.\nCalcoliamo ora l‚Äôintervallo di credibilit√† all‚Äô89%:\n\nsummary(fm3, prob = 0.89)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: height ~ 1 \n#&gt;    Data: df (Number of observations: 352) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-89% CI u-89% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept   154.60      0.41   153.94   155.27 1.00     3156     2659\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-89% CI u-89% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     7.77      0.29     7.32     8.25 1.00     3256     2596\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nIl risultato ottenuto replica i valori riportati da McElreath (2020) nella sua discussione dell‚Äôanalisi di questi dati, anche se McElreath usa una procedura bayesiana diversa da quella presentata qui. McElreath (2020) giustifica la scelta dell‚Äô89% nel modo seguente:\n\nWhy 89%? It‚Äôs just the default. It displays a quite wide interval, so it shows a high-probability range of parameter values. If you want another interval, such as the conventional and mindless 95%, you can use precis(m4.1,prob=0.95). But I don‚Äôt recommend 95% intervals, because readers will have a hard time not viewing them as significance tests. 89 is also a prime number, so if someone asks you to justify it, you can stare at them meaningfully and incant, ‚ÄúBecause it is prime.‚Äù That‚Äôs no worse justification than the conventional justification for 95%.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean.html#funzioni-bayesplot",
    "href": "chapters/linear_models/05_one_mean.html#funzioni-bayesplot",
    "title": "64¬† Inferenza bayesiana su una media",
    "section": "\n64.11 Funzioni bayesplot\n",
    "text": "64.11 Funzioni bayesplot\n\nIl pacchetto bayesplot mette a disposizione un insieme di funzioni molto utili per visualizzare la distribuzione a posteriori di uno o pi√π parametri e per verificare la bont√† di adattamento del modello ai dati.\n\n64.11.1 Traceplot\nUn traceplot consente di verificare la convergenza delle catene MCMC e di controllare l‚Äôautocorrelazione dei campioni a posteriori. Nel seguente esempio, si mostrano le tracce (i valori campionati lungo le iterazioni) per i parametri ‚ÄúIntercept‚Äù e ‚Äúsigma‚Äù:\n\nmcmc_trace(\n  fm3, \n  pars = c(\"Intercept\", \"sigma\"),\n  facet_args = list(nrow = 2)\n)\n\n\n\n\n\n\n\n\nL‚Äôasse orizzontale indica il numero di iterazione MCMC,\n\nL‚Äôasse verticale mostra il valore assunto dal parametro in quella iterazione,\n\nAvere catene che si mescolano bene e appaiono ‚Äústazionarie‚Äù (senza trend crescenti o calanti) √® un buon segnale di convergenza.\n\n64.11.2 Distribuzione a posteriori di un singolo parametro\nSe vogliamo visualizzare la distribuzione a posteriori di un singolo parametro (ad esempio l‚Äôintercetta, qui chiamata ‚Äúb_Intercept‚Äù nel modello brms), possiamo usare:\n\nmcmc_areas(fm3, regex_pars = \"b_Intercept\", prob = 0.89)\n\n\n\n\n\n\n\n\nViene mostrata la densit√† a posteriori, con un‚Äôarea evidenziata corrispondente all‚Äô89% di credibilit√† (specificabile con prob = 0.89 o un altro valore).\n\nSe desideriamo un intervallo di credibilit√† al 95%, useremo prob = 0.95.\n\n64.11.3 Rappresentazione congiunta di due parametri\nPer studiare la relazione tra due parametri (ad esempio ‚ÄúIntercept‚Äù e ‚Äúsigma‚Äù):\n\nmcmc_scatter(fm3, pars = c(\"Intercept\", \"sigma\"))\n\n\n\n\n\n\n\n\nSi ottiene un diagramma di dispersione dei campioni a posteriori sui due assi, uno per ciascun parametro, con eventuali isodensit√† che mostrano le aree pi√π probabili nella distribuzione congiunta.\n\n64.11.4 Posterior Predictive Check\nLa funzione pp_check() √® essenziale per valutare se il modello √® in grado di riprodurre i dati osservati:\n\npp_check(fm3)\n\n\n\n\n\n\n\n\nQuesta funzione genera un confronto tra la distribuzione dei dati reali (rappresentati, ad esempio, con una linea nera su un istogramma) e la distribuzione di diversi dataset simulati dal modello, sfruttando la distribuzione a posteriori dei parametri (\\(\\alpha\\), \\(\\sigma\\), ecc.).\n\nPoich√© il modello bayesiano √® generativo, possiamo campionare nuovi dati ‚Äúfittizi‚Äù a partire da ogni draw della posterior: in questo modo otteniamo molteplici dataset simulati, ognuno generato con un diverso valore di \\(\\alpha\\) e \\(\\sigma\\) estratto dalle distribuzioni posteriori.\n\nNel grafico prodotto da pp_check(), i dati osservati compaiono spesso come linea continua nera, mentre i dati simulati dal modello (ad esempio, 8 repliche di default) sono mostrati in colori pi√π chiari o linee semitrasparenti. Se la distribuzione empirica si sovrappone bene a quelle generate, significa che il modello spiega adeguatamente i dati.\n\nNel nostro caso, notiamo che le distribuzioni simulate risultano molto simili a quella osservata, indicando che la stima di \\(\\alpha\\) e \\(\\sigma\\) cattura in modo soddisfacente la variabilit√† dei dati.\n\nSe invece avessimo osservato discrepanze sistematiche (ad esempio, dati reali con code pi√π pesanti, oppure un picco in posizioni diverse rispetto alle distribuzioni simulate), ci saremmo insospettiti riguardo all‚Äôadeguatezza del modello. In situazioni del genere, conviene rivedere le assunzioni (e.g.¬†normalit√†, varianza costante, eventuali covariate assenti, ecc.) prima di trarre conclusioni dai risultati a posteriori.\n\nIn sintesi, il pacchetto bayesplot fornisce strumenti fondamentali per:\n\n\nValutare la convergenza delle catene MCMC (traceplot, autocorrelation plots),\n\n\nEsplorare la distribuzione a posteriori dei parametri (mcmc_areas, mcmc_density, mcmc_scatter, ‚Ä¶),\n\n\nVerificare la bont√† del modello rispetto ai dati osservati mediante posterior predictive checks (pp_check).\n\nQueste analisi grafiche forniscono informazioni cruciali sia sulla qualit√† del campionamento (e dunque sulla stabilit√† delle stime) sia sull‚Äôadeguatezza delle ipotesi modellistiche adottate.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean.html#lapproccio-tradizionale",
    "href": "chapters/linear_models/05_one_mean.html#lapproccio-tradizionale",
    "title": "64¬† Inferenza bayesiana su una media",
    "section": "\n64.12 L‚Äôapproccio Tradizionale",
    "text": "64.12 L‚Äôapproccio Tradizionale\nPrima dell‚Äôavvento dei metodi bayesiani e di altri approcci moderni, l‚Äôinferenza sulla media di una popolazione veniva spesso affrontata ricorrendo al test t di Student.\n\n64.12.1 La statistica T di Student\nIl test si basa sulla seguente statistica:\n\\[\nT = \\frac{\\bar{X} - \\mu_0}{s / \\sqrt{n}},\n\\]\ndove:\n\n\n\\(\\bar{X}\\) √® la media campionaria di \\(n\\) osservazioni,\n\n\n\\(\\mu_0\\) √® il valore ipotizzato dalla cosiddetta ‚Äúipotesi nulla‚Äù (solitamente \\(\\mu_0 = 0\\), ma pu√≤ essere qualsiasi valore di riferimento),\n\n\n\\(s\\) √® la deviazione standard campionaria corretta (ovvero stimatore di \\(\\sigma\\)),\n\n\n\\(n\\) √® la dimensione del campione.\n\nQuando \\(\\sigma\\) (deviazione standard vera) √® sconosciuta e sostituita da \\(s\\), la statistica \\(\\,T\\) segue (in teoria) una distribuzione t di Student con \\(n - 1\\) gradi di libert√†:\n\\[\nT \\sim t_{(n-1)}.\n\\]\n\n64.12.2 Collegamento con la distribuzione Z\nSe \\(\\sigma\\) fosse nota, useremmo la statistica:\n\\[\nZ = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}},\n\\]\nla quale segue una distribuzione Normale Standard (\\(Z \\sim \\mathcal{N}(0,1)\\)). Quando invece \\(\\sigma\\) √® sostituita da \\(s\\), la distribuzione di questa statistica diventa una t di Student (che, per \\(n\\) grande, si avvicina molto alla \\(\\mathcal{N}(0,1)\\)).\n\n64.12.3 Intervallo di confidenza\nCon il test t di Student, si ottiene anche il tradizionale intervallo di confidenza al 95% per \\(\\mu\\):\n\\[\n\\bar{X} \\pm t_{0.975,\\,n-1} \\cdot \\frac{s}{\\sqrt{n}},\n\\]\ndove \\(t_{0.975,\\,n-1}\\) √® il quantile al 97.5% della distribuzione t con \\(n-1\\) gradi di libert√† (circa 2.0 se \\(n\\) √® sufficientemente grande, mentre 1.96 √® il valore per la distribuzione normale standard).\n\n64.12.3.1 Esempio in R\nNell‚Äôesempio riportato, se vogliamo costruire l‚Äôintervallo di confidenza al 95% manualmente, possiamo scrivere:\n\nmean(df$height) + c(-1, 1) * \n  qt(0.975, length(df$height) - 1) * \n  (sd(df$height) / sqrt(length(df$height)))\n#&gt; [1] 153.8 155.4\n\noppure usare direttamente la funzione:\n\nt.test(df$height, mu = 0)\n#&gt; \n#&gt;  One Sample t-test\n#&gt; \n#&gt; data:  df$height\n#&gt; t = 375, df = 351, p-value &lt;2e-16\n#&gt; alternative hypothesis: true mean is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  153.8 155.4\n#&gt; sample estimates:\n#&gt; mean of x \n#&gt;     154.6\n\nche restituisce sia il valore della statistica T, sia l‚Äôintervallo di confidenza e il p-value del test t (ipotizzando, in questo esempio, \\(\\mu_0 = 0\\) come ipotesi nulla).\n\n64.12.4 Confronto con il modello di regressione a sola intercetta\nSi noti che i risultati (media stimata e intervallo di confidenza) coincidono con quanto si otterrebbe usando una regressione lineare con sola intercetta (come lm(height ~ 1, data=df)) e richiedendo l‚Äôintervallo di confidenza con confint(). Sia il test \\(t\\) di Student sia la regressione lineare semplice (senza covariate) condividono infatti le stesse assunzioni di base e forniscono risultati equivalenti per quanto riguarda l‚Äôinferenza sulla media.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/05_one_mean.html#informazioni-sullambiente-di-sviluppo",
    "title": "64¬† Inferenza bayesiana su una media",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] rstan_2.32.7        StanHeaders_2.32.10 brms_2.22.0        \n#&gt;  [4] Rcpp_1.0.14         bayestestR_0.15.2   posterior_1.6.1    \n#&gt;  [7] cmdstanr_0.8.1      thematic_0.1.6      MetBrewer_0.2.0    \n#&gt; [10] ggokabeito_0.1.0    see_0.11.0          gridExtra_2.3      \n#&gt; [13] patchwork_1.3.0     bayesplot_1.11.1    psych_2.5.3        \n#&gt; [16] scales_1.3.0        markdown_2.0        knitr_1.50         \n#&gt; [19] lubridate_1.9.4     forcats_1.0.0       stringr_1.5.1      \n#&gt; [22] dplyr_1.1.4         purrr_1.0.4         readr_2.1.5        \n#&gt; [25] tidyr_1.3.1         tibble_3.2.1        ggplot2_3.5.1      \n#&gt; [28] tidyverse_2.0.0     rio_1.2.3           here_1.0.1         \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] mnormt_2.1.1         inline_0.3.21        sandwich_3.1-1      \n#&gt;  [4] rlang_1.1.5          magrittr_2.0.3       multcomp_1.4-28     \n#&gt;  [7] ggridges_0.5.6       matrixStats_1.5.0    compiler_4.4.2      \n#&gt; [10] loo_2.8.0            vctrs_0.6.5          reshape2_1.4.4      \n#&gt; [13] pkgconfig_2.0.3      fastmap_1.2.0        backports_1.5.0     \n#&gt; [16] labeling_0.4.3       rmarkdown_2.29       tzdb_0.5.0          \n#&gt; [19] ps_1.9.0             xfun_0.51            jsonlite_1.9.1      \n#&gt; [22] parallel_4.4.2       R6_2.6.1             stringi_1.8.4       \n#&gt; [25] estimability_1.5.1   zoo_1.8-13           pacman_0.5.1        \n#&gt; [28] R.utils_2.13.0       Matrix_1.7-3         splines_4.4.2       \n#&gt; [31] timechange_0.3.0     tidyselect_1.2.1     rstudioapi_0.17.1   \n#&gt; [34] abind_1.4-8          yaml_2.3.10          codetools_0.2-20    \n#&gt; [37] curl_6.2.2           processx_3.8.6       pkgbuild_1.4.7      \n#&gt; [40] lattice_0.22-6       plyr_1.8.9           withr_3.0.2         \n#&gt; [43] bridgesampling_1.1-2 coda_0.19-4.1        evaluate_1.0.3      \n#&gt; [46] survival_3.8-3       RcppParallel_5.1.10  pillar_1.10.1       \n#&gt; [49] tensorA_0.36.2.1     checkmate_2.3.2      stats4_4.4.2        \n#&gt; [52] insight_1.1.0        distributional_0.5.0 generics_0.1.3      \n#&gt; [55] rprojroot_2.0.4      hms_1.1.3            rstantools_2.4.0    \n#&gt; [58] munsell_0.5.1        xtable_1.8-4         glue_1.8.0          \n#&gt; [61] emmeans_1.11.0       tools_4.4.2          data.table_1.17.0   \n#&gt; [64] mvtnorm_1.3-3        grid_4.4.2           QuickJSR_1.6.0      \n#&gt; [67] colorspace_2.1-1     nlme_3.1-167         cli_3.6.4           \n#&gt; [70] Brobdingnag_1.2-9    V8_6.0.2             gtable_0.3.6        \n#&gt; [73] R.methodsS3_1.8.2    digest_0.6.37        TH.data_1.1-3       \n#&gt; [76] htmlwidgets_1.6.4    farver_2.1.2         htmltools_0.5.8.1   \n#&gt; [79] R.oo_1.27.0          lifecycle_1.0.4      MASS_7.3-65",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean.html#bibliografia",
    "href": "chapters/linear_models/05_one_mean.html#bibliografia",
    "title": "64¬† Inferenza bayesiana su una media",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_prediction_stan.html",
    "href": "chapters/linear_models/06_prediction_stan.html",
    "title": "65¬† Predizione e inferenza",
    "section": "",
    "text": "65.1 Introduzione\nGelman et al. (2021) osservano che l‚Äôinferenza bayesiana si sviluppa in tre passaggi fondamentali, che vanno oltre la stima classica. In primo luogo, i dati e il modello vengono combinati per formare una distribuzione a posteriori, che solitamente viene riassunta tramite le distribuzioni a posteriori dei parametri del modello. In secondo luogo, √® possibile propagare l‚Äôincertezza presente in questa distribuzione, ottenendo previsioni basate su simulazioni per risultati non osservati o futuri, tenendo conto dell‚Äôincertezza nei parametri del modello. Infine, √® possibile integrare ulteriori informazioni nel modello utilizzando una distribuzione a priori. Questo capitolo si concentra sui temi della previsione e dell‚Äôinferenza, con particolare attenzione all‚Äôincertezza della retta di regressione e alle distribuzioni predittive.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>¬† <span class='chapter-title'>Predizione e inferenza</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_prediction_stan.html#predizione",
    "href": "chapters/linear_models/06_prediction_stan.html#predizione",
    "title": "65¬† Predizione e inferenza",
    "section": "\n65.2 Predizione",
    "text": "65.2 Predizione\nPer discutere i temi della predizione e dell‚Äôinferenza bayesiana nel contesto del modello bayesiano di regressione lineare bivariata, esamineremo nuovamente il set di dati relativo alla relazione tra Tense Arousal (TA1) e ansia di stato (state1).\n\ndf &lt;- rio::import(here::here(\"data\", \"affect.csv\")) |&gt; \n  dplyr::select(state1, TA1)\ndf |&gt; \n  head()\n#&gt;   state1 TA1\n#&gt; 1     41  11\n#&gt; 2     26   5\n#&gt; 3     31   8\n#&gt; 4     28   8\n#&gt; 5     47  12\n#&gt; 6     43  10",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>¬† <span class='chapter-title'>Predizione e inferenza</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_prediction_stan.html#distribuzione-predittiva-a-priori",
    "href": "chapters/linear_models/06_prediction_stan.html#distribuzione-predittiva-a-priori",
    "title": "65¬† Predizione e inferenza",
    "section": "\n65.3 Distribuzione Predittiva a Priori",
    "text": "65.3 Distribuzione Predittiva a Priori\nConsideriamo il modello bayesiano di regressione lineare bivariata che include prior uniformi per i parametri \\(\\alpha\\), \\(\\beta\\) e \\(\\sigma\\). Utilizzeremo il pacchetto brms per specificare e adattare il modello, concentrandoci in particolare sulla distribuzione predittiva a priori, ovvero sulle previsioni generate dal modello basandosi esclusivamente sulle distribuzioni a priori, senza considerare i dati osservati.\n\n65.3.1 Specificazione del modello con prior predittivi\nPer esaminare la distribuzione predittiva a priori, specifichiamo il modello impostando l‚Äôargomento sample_prior = \"only\". Questo ci permette di generare previsioni basate solo sui prior, ignorando i dati del campione.\n\n# Prior predictive check con sample_prior = \"only\"\nmodel_prior &lt;- brm(\n  formula = TA1 ~ state1, \n  data = df, \n  prior = c(\n    prior(uniform(-50, 50), class = \"Intercept\"),  # Prior per alpha\n    prior(uniform(-50, 50), class = \"b\"),          # Prior per beta\n    prior(uniform(0, 50), class = \"sigma\")         # Prior per sigma\n  ), \n  sample_prior = \"only\",  # Campiona solo dai prior\n  backend = \"cmdstanr\",\n  silent = 0\n)\n\n\n65.3.2 Visualizzazione della distribuzione predittiva a priori\nUtilizziamo la funzione pp_check per visualizzare la distribuzione predittiva a priori e confrontarla con i dati osservati. Questo passaggio √® fondamentale per valutare se i prior scelti sono realistici e appropriati per il contesto del problema.\n\n# Visualizzazione del prior predictive check\npp_check(model_prior) + xlim(-100, 100)\n\n\n\n\n\n\n\n\n65.3.3 Interpretazione dei risultati\nDalla visualizzazione, notiamo che la distribuzione dei dati previsti dal modello, basata esclusivamente sui prior e sul modello generativo ipotizzato, √® molto pi√π ampia rispetto alla distribuzione dei dati effettivi. Questo suggerisce che i prior scelti sono troppo ampi e poco informativi. In altre parole, le previsioni generate dai prior coprono un intervallo di valori eccessivamente vasto, che non riflette adeguatamente la variabilit√† osservata nei dati reali.\n\n65.3.3.1 Implicazioni\n\n\nPrior troppo ampi: Quando i prior sono troppo ampi, il modello genera previsioni che possono essere irrealistiche o eccessivamente disperse. Questo pu√≤ portare a una scarsa capacit√† del modello di adattarsi ai dati osservati una volta che questi vengono incorporati.\n\nPrior informativi: Per migliorare il modello, potrebbe essere necessario utilizzare prior pi√π informativi, che riflettano meglio la conoscenza preesistente sul fenomeno in studio. Ad esempio, limitare l‚Äôintervallo dei prior per \\(\\alpha\\) e \\(\\beta\\) o scegliere distribuzioni a priori pi√π realistiche per \\(\\sigma\\).\n\nIn sintesi, il prior predictive check √® uno strumento essenziale per valutare l‚Äôadeguatezza delle distribuzioni a priori scelte. Attraverso questo controllo, possiamo identificare prior troppo ampi o inappropriati, che potrebbero compromettere la qualit√† delle inferenze bayesiane. Nel nostro caso, i risultati suggeriscono la necessit√† di rivedere i prior, adottando scelte pi√π informative e coerenti con la realt√† dei dati.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>¬† <span class='chapter-title'>Predizione e inferenza</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_prediction_stan.html#modello-di-regressione-lineare-bayesiana",
    "href": "chapters/linear_models/06_prediction_stan.html#modello-di-regressione-lineare-bayesiana",
    "title": "65¬† Predizione e inferenza",
    "section": "\n65.4 Modello di Regressione Lineare Bayesiana",
    "text": "65.4 Modello di Regressione Lineare Bayesiana\nIn questa sezione, specifichiamo e adattiamo un modello di regressione lineare bivariata utilizzando prior uniformi per i parametri \\(\\alpha\\) (intercetta), \\(\\beta\\) (coefficiente angolare) e \\(\\sigma\\) (deviazione standard). L‚Äôobiettivo √® ottenere la distribuzione a posteriori dei parametri del modello e confrontare i risultati con quelli ottenuti tramite il metodo di massima verosimiglianza.\n\n65.4.1 Specificazione del Modello con Prior Uniformi\nUtilizziamo il pacchetto brms per specificare il modello di regressione lineare. I prior scelti sono uniformi e coprono un intervallo ampio per ciascun parametro, riflettendo un approccio inizialmente non informativo.\n\n# Specificazione del modello con prior uniformi\nmodel &lt;- brm(\n  formula = TA1 ~ state1,  # Formula del modello\n  data = df,               # Dati\n  prior = c(\n    prior(uniform(-50, 50), class = \"Intercept\"),  # Prior per alpha\n    prior(uniform(-50, 50), class = \"b\"),          # Prior per beta\n    prior(uniform(0, 50), class = \"sigma\")         # Prior per sigma\n  ),\n  seed = 123,              # Seme per la riproducibilit√†\n  chains = 4,              # Numero di catene MCMC\n  iter = 4000,             # Numero totale di iterazioni (2000 warmup, 2000 sampling)\n  warmup = 2000,           # Iterazioni di warmup\n  backend = \"cmdstanr\",    # Backend per l'ottimizzazione\n  silent = 0               # Mostra messaggi di avviso\n)\n\n\n65.4.2 Esame delle Distribuzioni a Posteriori\nPer esaminare le distribuzioni a posteriori dei parametri, utilizziamo la funzione summary. Questo ci permette di ottenere stime puntuali, intervalli di credibilit√† e altre statistiche rilevanti.\n\nsummary(model)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: TA1 ~ state1 \n#&gt;    Data: df (Number of observations: 78) \n#&gt;   Draws: 4 chains, each with iter = 4000; warmup = 2000; thin = 1;\n#&gt;          total post-warmup draws = 8000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept     1.57      1.28    -1.01     4.07 1.00     8973     5508\n#&gt; state1        0.27      0.03     0.21     0.33 1.00     8503     4886\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     2.72      0.23     2.31     3.20 1.00     8001     6020\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nUn aspetto cruciale √® che la distribuzione a posteriori non fornisce solo informazioni sui singoli parametri, ma anche sulle loro interdipendenze. Queste relazioni sono riflesse nei campioni a posteriori, che possono essere ulteriormente analizzati e trasformati.\n\n65.4.3 Confronto con il Metodo di Massima Verosimiglianza\nPer confrontare i risultati bayesiani con quelli classici, stimiamo il modello di regressione lineare utilizzando il metodo di massima verosimiglianza.\n\nsummary(lm(TA1 ~ state1, data = df))\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = TA1 ~ state1, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;    Min     1Q Median     3Q    Max \n#&gt; -7.238 -1.754  0.159  1.973  6.302 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)\n#&gt; (Intercept)   1.5555     1.2485    1.25     0.22\n#&gt; state1        0.2671     0.0292    9.14  7.3e-14\n#&gt; \n#&gt; Residual standard error: 2.67 on 76 degrees of freedom\n#&gt; Multiple R-squared:  0.523,  Adjusted R-squared:  0.517 \n#&gt; F-statistic: 83.5 on 1 and 76 DF,  p-value: 7.35e-14\n\nNel caso di prior uniformi, la soluzione bayesiana coincide con quella di massima verosimiglianza. Questo risultato √® atteso, poich√© prior non informativi portano a distribuzioni a posteriori dominate dai dati osservati.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>¬† <span class='chapter-title'>Predizione e inferenza</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_prediction_stan.html#predizione-a-posteriori",
    "href": "chapters/linear_models/06_prediction_stan.html#predizione-a-posteriori",
    "title": "65¬† Predizione e inferenza",
    "section": "\n65.5 Predizione a Posteriori",
    "text": "65.5 Predizione a Posteriori\nUna volta ottenuta la distribuzione a posteriori dei parametri, possiamo utilizzarla per fare previsioni. In particolare, siamo interessati a due scenari: 1. Predizione per un valore specifico del predittore. 2. Quantificazione dell‚Äôincertezza nelle previsioni per tutti i valori osservati del predittore.\n\n65.5.1 Predizione a Posteriori per un Valore Specifico\nPer ottenere la distribuzione a posteriori della predizione per un valore specifico del predittore (ad esempio, state1 = 30), utilizziamo la funzione posterior_predict.\n\n# Predizione a posteriori per ansia di stato pari a 30\nnew_data &lt;- data.frame(state1 = 30)\npost_pred &lt;- posterior_predict(model, newdata = new_data)\n\n# Esame della distribuzione a posteriori della predizione\nsummary(post_pred)\n#&gt;        V1       \n#&gt;  Min.   :-2.43  \n#&gt;  1st Qu.: 7.67  \n#&gt;  Median : 9.55  \n#&gt;  Mean   : 9.56  \n#&gt;  3rd Qu.:11.45  \n#&gt;  Max.   :19.11\n\nQuesto ci fornisce una distribuzione di valori predetti per TA1 quando state1 = 30, riflettendo l‚Äôincertezza associata ai parametri del modello.\n\n65.5.2 Quantificazione dell‚ÄôIncertezza nelle Predizioni\nPer quantificare l‚Äôincertezza complessiva nelle previsioni del modello, calcoliamo la distribuzione a posteriori delle predizioni per tutti i valori osservati di \\(x\\). Questo ci permette di ottenere stime puntuali e intervalli di credibilit√†.\n\n# Predizione a posteriori per tutti i valori di x\npost_pred_all &lt;- posterior_predict(model)\n\n\n65.5.3 Visualizzazione dell‚ÄôIncertezza delle Predizioni\nVisualizziamo l‚Äôincertezza delle predizioni utilizzando un grafico che mostra la linea di regressione media e gli intervalli di credibilit√† al 95%.\n\n# Creazione del data frame per ggplot\nplot_data &lt;- data.frame(\n  state1 = df$state1,\n  TA1 = df$TA1,\n  pred_mean = colMeans(post_pred_all),  # Media delle predizioni\n  pred_lower = apply(post_pred_all, 2, quantile, 0.025),  # Limite inferiore\n  pred_upper = apply(post_pred_all, 2, quantile, 0.975)   # Limite superiore\n)\n\n# Costruzione del grafico\nggplot(plot_data, aes(x = state1, y = TA1)) +\n  geom_point(color = \"blue\", size = 1) +  # Punti osservati\n  geom_line(aes(y = pred_mean), color = \"red\", size = 1, alpha = 0.8) +  # Linea di regressione\n  geom_ribbon(\n    aes(ymin = pred_lower, ymax = pred_upper), fill = \"gray\", alpha = 0.3) +  \n  # Intervalli di credibilit√†\n  labs(\n    title = \"Incertezza delle Predizioni del Modello\",\n    x = \"State Anxiety\",\n    y = \"Tense Arousal\"\n  )",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>¬† <span class='chapter-title'>Predizione e inferenza</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_prediction_stan.html#interpretazione-dei-risultati-1",
    "href": "chapters/linear_models/06_prediction_stan.html#interpretazione-dei-risultati-1",
    "title": "65¬† Predizione e inferenza",
    "section": "\n65.6 Interpretazione dei Risultati",
    "text": "65.6 Interpretazione dei Risultati\n\n65.6.1 Significato della Predizione a Posteriori\nIl comando posterior_predict(model) genera una matrice in cui:\n\nOgni riga rappresenta un campione della distribuzione a posteriori.\nOgni colonna rappresenta una predizione per un valore specifico di \\(x\\).\n\nQuesta matrice ci permette di:\n\n\nVisualizzare l‚Äôincertezza: Gli intervalli di credibilit√† riflettono l‚Äôincertezza associata alle previsioni.\n\nValutare la bont√† del modello: Confrontando le predizioni con i dati osservati, possiamo verificare se il modello √® adeguato.\n\nFare previsioni robuste: Generiamo previsioni per nuovi dati, tenendo conto dell‚Äôincertezza nei parametri.\n\n65.6.2 Esempio di Interpretazione\nSupponiamo che per state1 = 30, la media delle predizioni a posteriori sia 50, con un intervallo di credibilit√† al 95% compreso tra 45 e 55. Questo significa che, dato il modello e i dati, c‚Äô√® una probabilit√† del 95% che il valore vero di TA1 per state1 = 30 sia compreso tra 45 e 55. L‚Äôampiezza dell‚Äôintervallo riflette l‚Äôincertezza associata alla predizione.\n\n65.6.3 Confronto con l‚ÄôApproccio Classico\nNell‚Äôapproccio classico (frequentista), le predizioni sono accompagnate da intervalli di confidenza, che riflettono solo l‚Äôincertezza nella stima dei parametri. Al contrario, l‚Äôapproccio bayesiano include sia l‚Äôincertezza nei parametri sia la variabilit√† residua, fornendo una visione pi√π completa dell‚Äôincertezza predittiva.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>¬† <span class='chapter-title'>Predizione e inferenza</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_prediction_stan.html#distribuzione-predittiva-a-posteriori",
    "href": "chapters/linear_models/06_prediction_stan.html#distribuzione-predittiva-a-posteriori",
    "title": "65¬† Predizione e inferenza",
    "section": "\n65.7 Distribuzione Predittiva a Posteriori",
    "text": "65.7 Distribuzione Predittiva a Posteriori\nIl Posterior Predictive Check (PPC) √® uno strumento fondamentale nella modellazione bayesiana, utilizzato per valutare la bont√† di adattamento del modello ai dati osservati. Questo controllo consiste nel confrontare i dati predetti dal modello (basati sulla distribuzione a posteriori dei parametri) con i dati effettivamente osservati. Se il modello √® adeguato, le previsioni generate dovrebbero essere coerenti con i dati reali.\n\n65.7.1 Esecuzione del Posterior Predictive Check\nPer eseguire un PPC, utilizziamo la funzione pp_check del pacchetto brms. Questa funzione genera un insieme di previsioni basate sulla distribuzione a posteriori e le confronta visivamente con i dati osservati.\n\npp_check(model, ndraws = 100)\n\n\n\n\n\n\n\n\n65.7.2 Interpretazione dei Risultati\nDall‚Äôoutput del PPC, notiamo che i dati predetti dal modello sono simili ai dati osservati nel campione. Questa corrispondenza suggerisce che il modello ipotizzato √® in grado di riprodurre adeguatamente le caratteristiche principali dei dati. In altre parole, il modello sembra essere appropriato per descrivere la relazione tra le variabili analizzate.\n\n65.7.2.1 Cosa Significa ‚ÄúSimili‚Äù?\n\n\nCoerenza nella forma: La distribuzione dei dati predetti ha una forma simile a quella dei dati osservati, indicando che il modello cattura correttamente la struttura sottostante dei dati.\n\nVariabilit√†: La variabilit√† delle previsioni √® in linea con quella dei dati osservati, suggerendo che il modello tiene conto adeguatamente dell‚Äôincertezza intrinseca nei dati.\n\nAssenza di discrepanze evidenti: Non ci sono differenze sistematiche tra le previsioni e i dati osservati, il che supporta l‚Äôipotesi che il modello sia ben specificato.\n\n65.7.3 Importanza del PPC\nIl PPC √® un passaggio cruciale perch√©:\n\n\nValuta l‚Äôadattamento del modello: Fornisce una verifica visiva e quantitativa della capacit√† del modello di riprodurre i dati osservati.\n\nIdentifica potenziali problemi: Se le previsioni non corrispondono ai dati osservati, ci√≤ pu√≤ indicare che il modello √® mal specificato o che mancano componenti importanti.\n\nSupporta la validit√† del modello: Un buon adattamento tra previsioni e dati osservati aumenta la fiducia nelle inferenze e nelle previsioni del modello.\n\nIn sintesi, nel nostro caso, la somiglianza tra i dati predetti e quelli osservati √® un‚Äôindicazione positiva che il modello di regressione lineare bivariata, con i prior uniformi specificati, √® adeguato per descrivere la relazione tra state1 e TA1. Tuttavia, √® sempre consigliabile eseguire ulteriori controlli e verifiche, come l‚Äôanalisi dei residui o l‚Äôuso di metriche quantitative (ad esempio, il Bayesian R-squared), per confermare ulteriormente la bont√† del modello.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>¬† <span class='chapter-title'>Predizione e inferenza</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_prediction_stan.html#riflessioni-conclusive",
    "href": "chapters/linear_models/06_prediction_stan.html#riflessioni-conclusive",
    "title": "65¬† Predizione e inferenza",
    "section": "\n65.8 Riflessioni Conclusive",
    "text": "65.8 Riflessioni Conclusive\nIn questo capitolo, abbiamo approfondito i temi della predizione bayesiana nel contesto del modello di regressione bivariato, evidenziando l‚Äôimportanza delle verifiche predittive a priori e a posteriori per la valutazione e la validazione del modello.\nAbbiamo visto come il Prior Predictive Check sia essenziale per verificare che le distribuzioni a priori siano appropriate per il modello e i dati del campione. Questo passaggio consente di esaminare se le ipotesi iniziali sono coerenti con la conoscenza preesistente e con i risultati attesi. Un‚Äôadeguata verifica predittiva a priori aiuta a prevenire l‚Äôadozione di distribuzioni a priori che possano portare a previsioni irrealistiche o fuorvianti.\nSuccessivamente, abbiamo esaminato il Posterior Predictive Check come strumento per valutare la capacit√† del modello di adattarsi ai dati osservati. Dopo aver integrato le informazioni dei dati con le distribuzioni a priori, il posterior predictive check permette di confrontare le predizioni del modello con i dati effettivamente osservati. Se il modello √® adeguato, le sue predizioni dovrebbero essere in linea con i dati reali.\nInoltre, abbiamo discusso l‚Äôincertezza della retta di regressione, mostrando come le distribuzioni a posteriori dei parametri possano essere utilizzate per quantificare l‚Äôincertezza nelle previsioni. Attraverso la visualizzazione degli intervalli di credibilit√†, abbiamo evidenziato come l‚Äôapproccio bayesiano fornisca una misura pi√π completa dell‚Äôincertezza rispetto ai metodi classici.\nIn conclusione, l‚Äôapproccio bayesiano alla predizione e alla verifica dei modelli offre un framework robusto e flessibile per l‚Äôanalisi statistica. I prior e posterior predictive checks non sono semplici passaggi tecnici, ma costituiscono una parte integrante del processo di modellizzazione, assicurando che il modello non solo sia ben adattato ai dati, ma anche che le sue assunzioni siano giustificate e realistiche. L‚Äôutilizzo di questi strumenti permette di costruire modelli che siano coerenti con la realt√† che intendono rappresentare.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>¬† <span class='chapter-title'>Predizione e inferenza</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_prediction_stan.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/06_prediction_stan.html#informazioni-sullambiente-di-sviluppo",
    "title": "65¬† Predizione e inferenza",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] rstan_2.32.7        StanHeaders_2.32.10 posterior_1.6.1    \n#&gt;  [4] brms_2.22.0         Rcpp_1.0.14         thematic_0.1.6     \n#&gt;  [7] MetBrewer_0.2.0     ggokabeito_0.1.0    see_0.11.0         \n#&gt; [10] gridExtra_2.3       patchwork_1.3.0     bayesplot_1.11.1   \n#&gt; [13] psych_2.5.3         scales_1.3.0        markdown_2.0       \n#&gt; [16] knitr_1.50          lubridate_1.9.4     forcats_1.0.0      \n#&gt; [19] stringr_1.5.1       dplyr_1.1.4         purrr_1.0.4        \n#&gt; [22] readr_2.1.5         tidyr_1.3.1         tibble_3.2.1       \n#&gt; [25] ggplot2_3.5.1       tidyverse_2.0.0     rio_1.2.3          \n#&gt; [28] here_1.0.1         \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1     farver_2.1.2         R.utils_2.13.0      \n#&gt;  [4] loo_2.8.0            fastmap_1.2.0        TH.data_1.1-3       \n#&gt;  [7] tensorA_0.36.2.1     pacman_0.5.1         digest_0.6.37       \n#&gt; [10] timechange_0.3.0     estimability_1.5.1   lifecycle_1.0.4     \n#&gt; [13] processx_3.8.6       survival_3.8-3       magrittr_2.0.3      \n#&gt; [16] compiler_4.4.2       rlang_1.1.5          tools_4.4.2         \n#&gt; [19] yaml_2.3.10          data.table_1.17.0    labeling_0.4.3      \n#&gt; [22] bridgesampling_1.1-2 htmlwidgets_1.6.4    curl_6.2.2          \n#&gt; [25] pkgbuild_1.4.7       mnormt_2.1.1         plyr_1.8.9          \n#&gt; [28] cmdstanr_0.8.1       abind_1.4-8          multcomp_1.4-28     \n#&gt; [31] withr_3.0.2          R.oo_1.27.0          stats4_4.4.2        \n#&gt; [34] grid_4.4.2           inline_0.3.21        xtable_1.8-4        \n#&gt; [37] colorspace_2.1-1     emmeans_1.11.0       MASS_7.3-65         \n#&gt; [40] cli_3.6.4            mvtnorm_1.3-3        rmarkdown_2.29      \n#&gt; [43] generics_0.1.3       RcppParallel_5.1.10  rstudioapi_0.17.1   \n#&gt; [46] reshape2_1.4.4       tzdb_0.5.0           splines_4.4.2       \n#&gt; [49] parallel_4.4.2       matrixStats_1.5.0    vctrs_0.6.5         \n#&gt; [52] V8_6.0.2             Matrix_1.7-3         sandwich_3.1-1      \n#&gt; [55] jsonlite_1.9.1       hms_1.1.3            glue_1.8.0          \n#&gt; [58] ps_1.9.0             codetools_0.2-20     distributional_0.5.0\n#&gt; [61] stringi_1.8.4        gtable_0.3.6         QuickJSR_1.6.0      \n#&gt; [64] munsell_0.5.1        pillar_1.10.1        htmltools_0.5.8.1   \n#&gt; [67] Brobdingnag_1.2-9    R6_2.6.1             rprojroot_2.0.4     \n#&gt; [70] evaluate_1.0.3       lattice_0.22-6       R.methodsS3_1.8.2   \n#&gt; [73] backports_1.5.0      rstantools_2.4.0     coda_0.19-4.1       \n#&gt; [76] nlme_3.1-167         checkmate_2.3.2      xfun_0.51           \n#&gt; [79] zoo_1.8-13           pkgconfig_2.0.3",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>¬† <span class='chapter-title'>Predizione e inferenza</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_prediction_stan.html#bibliografia",
    "href": "chapters/linear_models/06_prediction_stan.html#bibliografia",
    "title": "65¬† Predizione e inferenza",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other stories. Cambridge University Press.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>¬† <span class='chapter-title'>Predizione e inferenza</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html",
    "href": "chapters/linear_models/07_two_means.html",
    "title": "66¬† Confronto tra le medie di due gruppi",
    "section": "",
    "text": "66.1 Introduzione\nSpesso, ci troviamo ad affrontare la necessit√† di confrontare due gruppi di dati. Potrebbe interessarci sapere se la media di un gruppo √® maggiore o diversa rispetto a quella di un altro gruppo. Per effettuare tale confronto, √® fondamentale utilizzare un modello statistico, poich√© le vere differenze tra i gruppi sono spesso accompagnate da rumore di misurazione o fluttuazioni casuali del fenomeno in esame. Questo rende difficile trarre conclusioni basandosi unicamente sulle differenze calcolate dai dati osservati.\nIl metodo tradizionale per confrontare statisticamente due o pi√π gruppi √® quello di utilizzare un test di ipotesi statistico. Questo approccio prevede l‚Äôindividuazione di un‚Äôipotesi nulla, che solitamente afferma che non ci sono differenze tra i gruppi, e l‚Äôutilizzo di una statistica test per determinare se i dati osservati sono plausibili sotto questa ipotesi. L‚Äôipotesi nulla viene rifiutata quando la statistica test calcolata supera una soglia predefinita.\nTuttavia, i test di ipotesi possono essere complessi e i risultati spesso soggetti a interpretazioni errate. La scelta delle specifiche del test statistico (ad esempio, quale test utilizzare, quale ipotesi nulla testare, quale livello di significativit√† adottare) √® spesso arbitraria e basata su convenzioni piuttosto che sulla specificit√† del problema o delle decisioni da prendere (Johnson, 1999). Inoltre, i risultati forniti dai test sono spesso indiretti, incompleti e tendono a sovrastimare le evidenze contro l‚Äôipotesi nulla (Goodman, 1999).\nUn approccio pi√π informativo ed efficace per il confronto tra gruppi √® quello basato sulla stima invece che sul test dell‚Äôipotesi nulla, ed √® guidato dalla probabilit√† bayesiana anzich√© dalla frequentista. In pratica, invece di testare se ci sono differenze tra i gruppi, si cerca di ottenere una stima di quanto siano effettivamente diversi. Questo approccio √® intrinsecamente pi√π informativo. Inoltre, viene inclusa una stima dell‚Äôincertezza associata a tale differenza, che tiene conto sia dell‚Äôincertezza dovuta alla nostra mancanza di conoscenza dei parametri del modello (incertezza epistemica) sia dell‚Äôincertezza causata dalla variabilit√† intrinseca del sistema (incertezza aleatoria).\nPer affrontare tale problema possiamo usare un modello di regressione. In questo caso, anzich√© calcolare direttamente la differenza tra le medie, si introduce una variabile indicatrice (o ‚Äúdummy‚Äù) \\(D\\) nel modello di regressione, come segue:\n\\[\ny_i = \\alpha + \\gamma D_i + \\varepsilon_i.\n\\]\nLa variabile indicatrice \\(D\\) specifica l‚Äôappartenenza ai gruppi attraverso valori binari: 0 per il gruppo di riferimento e 1 per il gruppo di confronto, definita come:\n\\[\nD_i =\n\\begin{cases}\n0 & \\text{se l'osservazione } i \\text{ appartiene al gruppo 0,} \\\\\n1 & \\text{se l'osservazione } i \\text{ appartiene al gruppo 1.}\n\\end{cases}\n\\]\nEntrambi i metodi sono appropriati per studiare la differenza tra le medie di due gruppi indipendenti. Tuttavia, il modello di regressione offre maggiore flessibilit√† e possibilit√† di estensione. Questa metodologia consente di includere ulteriori variabili esplicative, migliorando la comprensione dei fattori che influenzano l‚Äôesito di interesse. Tale flessibilit√† diventa particolarmente utile per esplorare come altre variabili incidano sulla differenza tra le medie o per analizzare contemporaneamente pi√π variabili.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>¬† <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#regressione-bayesiana-per-due-gruppi-indipendenti",
    "href": "chapters/linear_models/07_two_means.html#regressione-bayesiana-per-due-gruppi-indipendenti",
    "title": "66¬† Confronto tra le medie di due gruppi",
    "section": "\n66.2 Regressione bayesiana per due gruppi indipendenti",
    "text": "66.2 Regressione bayesiana per due gruppi indipendenti\nIn un approccio bayesiano, il modello di regressione pu√≤ essere espresso come:\n\\[\n\\begin{align*}\ny_i & \\sim \\mathcal{N}(\\mu_i, \\sigma), \\\\\n\\mu_i & = \\alpha + \\gamma D_i.\n\\end{align*}\n\\]\nIn questo modello:\n\n\n\\(\\alpha\\) rappresenta l‚Äôintercetta, corrispondente alla media del gruppo con \\(D = 0\\) (gruppo di riferimento),\n\n\\(\\gamma\\) quantifica la differenza attesa tra le medie dei due gruppi,\n\n\\(\\sigma\\) rappresenta la deviazione standard associata agli errori casuali.\n\nPer il gruppo di riferimento (\\(D = 0\\)), il modello si riduce a:\n\\[\n\\begin{align*}\ny_i & \\sim \\mathcal{N}(\\mu_i, \\sigma), \\\\\n\\mu_i & = \\alpha.\n\\end{align*}\n\\]\nIn questo caso, \\(\\alpha\\) rappresenta direttamente la media del gruppo 0.\nPer il gruppo di confronto (\\(D = 1\\)), il modello diventa:\n\\[\n\\begin{align*}\ny_i & \\sim \\mathcal{N}(\\mu_i, \\sigma), \\\\\n\\mu_i & = \\alpha + \\gamma.\n\\end{align*}\n\\]\nQui, \\(\\alpha + \\gamma\\) rappresenta la media del gruppo 1, mentre \\(\\gamma\\) riflette la differenza tra la media del gruppo 1 e quella del gruppo 0.\nDi conseguenza, l‚Äôanalisi della differenza tra le medie dei due gruppi si traduce nell‚Äôinferenza sul parametro \\(\\gamma\\). In un contesto bayesiano, ci√≤ comporta l‚Äôesame della distribuzione a posteriori di \\(\\gamma\\), che consente di effettuare confronti diretti e di valutare l‚Äôincertezza associata alla stima di tale differenza.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>¬† <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#approccio-frequentista",
    "href": "chapters/linear_models/07_two_means.html#approccio-frequentista",
    "title": "66¬† Confronto tra le medie di due gruppi",
    "section": "\n66.3 Approccio Frequentista",
    "text": "66.3 Approccio Frequentista\nL‚Äôinferenza frequentista si basa sulla costruzione della distribuzione campionaria di una statistica di interesse. Nel caso presente, la statistica di interesse √® la differenza tra le medie di due gruppi indipendenti. Supponiamo che i dati provengano da due popolazioni distribuite normalmente:\n\\[\nY_1 \\sim \\mathcal{N}(\\mu_1, \\sigma_1) \\quad \\text{e} \\quad Y_2 \\sim \\mathcal{N}(\\mu_2, \\sigma_2),\n\\]\ndove \\(\\mu_1\\) e \\(\\mu_2\\) sono le medie delle popolazioni, e \\(\\sigma_1\\) e \\(\\sigma_2\\) sono le deviazioni standard. Assumiamo inoltre che le varianze delle due popolazioni siano uguali, ovvero \\(\\sigma_1 = \\sigma_2 = \\sigma\\).\n\n66.3.1 Inferenza sulla differenza delle medie\nSiamo interessati a fare inferenza sulla differenza \\(\\mu_1 - \\mu_2\\). La statistica campionaria corrispondente √® la differenza tra le medie campionarie:\n\\[\n\\bar{Y}_1 - \\bar{Y}_2.\n\\]\nPer fare inferenza, dobbiamo determinare la distribuzione di \\(\\bar{Y}_1 - \\bar{Y}_2\\) nell‚Äôuniverso dei campioni.\n\n66.3.1.1 Valore atteso\nIl valore atteso della differenza tra le medie campionarie √®:\n\\[\nE(\\bar{Y}_1 - \\bar{Y}_2) = E(\\bar{Y}_1) - E(\\bar{Y}_2) = \\mu_1 - \\mu_2.\n\\]\n\n66.3.1.2 Varianza\nLa varianza della differenza tra le medie campionarie dipende dall‚Äôindipendenza dei due campioni. Se \\(\\bar{Y}_1\\) e \\(\\bar{Y}_2\\) sono indipendenti, la covarianza tra di essi √® zero, e la varianza √® data da:\n\\[\n\\begin{align}\nV(\\bar{Y}_1 - \\bar{Y}_2) &= V(\\bar{Y}_1) + V(\\bar{Y}_2) - 2 \\text{Cov}(\\bar{Y}_1, \\bar{Y}_2) \\\\\n&= V(\\bar{Y}_1) + V(\\bar{Y}_2) \\quad \\text{(poich√© $\\text{Cov}(\\bar{Y}_1, \\bar{Y}_2) = 0$)} \\\\\n&= \\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2},\n\\end{align}\n\\]\ndove:\n\n\n\\(\\sigma_1^2\\) e \\(\\sigma_2^2\\) sono le varianze delle popolazioni da cui sono estratti i campioni,\n\n\\(n_1\\) e \\(n_2\\) sono le dimensioni dei campioni \\(\\bar{Y}_1\\) e \\(\\bar{Y}_2\\).\n\nSe invece \\(\\bar{Y}_1\\) e \\(\\bar{Y}_2\\) non sono indipendenti, la covarianza \\(\\text{Cov}(\\bar{Y}_1, \\bar{Y}_2)\\) deve essere inclusa nel calcolo:\n\\[\nV(\\bar{Y}_1 - \\bar{Y}_2) = \\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2} - 2 \\text{Cov}(\\bar{Y}_1, \\bar{Y}_2).\n\\]\nTuttavia, in generale, la covarianza non √® nota, e l‚Äôinferenza frequentista si applica principalmente al caso in cui i due campioni sono indipendenti, ovvero \\(\\text{Cov}(\\bar{Y}_1, \\bar{Y}_2) = 0\\).\n\n66.3.2 Distribuzione della statistica\nPer due campioni indipendenti provenienti da popolazioni normali, la statistica \\(\\bar{Y}_1 - \\bar{Y}_2\\) segue una distribuzione normale:\n\\[\n\\bar{Y}_1 - \\bar{Y}_2 \\sim \\mathcal{N}\\left(\\mu_1 - \\mu_2, \\sqrt{\\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}}\\right).\n\\]\nNel caso in cui \\(\\sigma_1 = \\sigma_2 = \\sigma\\), √® possibile stimare la varianza comune \\(\\sigma^2\\) utilizzando una varianza pooled:\n\\[\ns_p^2 = \\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2},\n\\]\ndove \\(s_1^2\\) e \\(s_2^2\\) sono le varianze campionarie dei due gruppi, calcolate come:\n\\[\ns_1^2 = \\frac{1}{n_1 - 1} \\sum_{i=1}^{n_1} (y_{1,i} - \\bar{y}_1)^2 \\quad \\text{e} \\quad s_2^2 = \\frac{1}{n_2 - 1} \\sum_{i=1}^{n_2} (y_{2,i} - \\bar{y}_2)^2.\n\\]\nIn sintesi, per due campioni indipendenti provenienti da popolazioni normali con varianze uguali, la differenza delle medie campionarie \\(\\bar{Y}_1 - \\bar{Y}_2\\) segue una distribuzione normale con:\n\n\nValore atteso: \\(\\mu_1 - \\mu_2\\),\n\nVarianza: \\(\\frac{\\sigma^2}{n_1} + \\frac{\\sigma^2}{n_2}\\), stimabile tramite la varianza pooled \\(s_p^2\\).\n\nQuesto risultato √® fondamentale per costruire test di ipotesi e intervalli di confidenza sulla differenza delle medie. Questi argomenti verranno approfonditi in seguito. Per ora, limitiamoci a costruire la distribuzione campionaria della statistica \\(\\bar{Y}_1 - \\bar{Y}_2\\) e a calcolare delle probabilit√†.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>¬† <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#un-esempio-illustrativo",
    "href": "chapters/linear_models/07_two_means.html#un-esempio-illustrativo",
    "title": "66¬† Confronto tra le medie di due gruppi",
    "section": "\n66.4 Un esempio illustrativo",
    "text": "66.4 Un esempio illustrativo\nConsideriamo il dataset relativo al quoziente di intelligenza (QI) di un campione di bambini, distinguendo tra quelli le cui madri hanno completato la scuola superiore e quelli le cui madri non l‚Äôhanno completata. Vediamo come implementare l‚Äôanalisi descritta sopra passo per passo.\n\n66.4.1 Esplorazione iniziale dei dati\nCarichiamo i dati e osserviamo una sintesi delle prime righe per capire la struttura del dataset:\n\nkidiq &lt;- rio::import(here::here(\"data\", \"kidiq.dta\"))\nkidiq |&gt; \n  head()\n#&gt;   kid_score mom_hs mom_iq mom_work mom_age\n#&gt; 1        65      1 121.12        4      27\n#&gt; 2        98      1  89.36        4      25\n#&gt; 3        85      1 115.44        4      27\n#&gt; 4        83      1  99.45        3      25\n#&gt; 5       115      1  92.75        4      27\n#&gt; 6        98      0 107.90        1      18\n\nSuccessivamente, analizziamo la distribuzione dei bambini nei due gruppi, in base all‚Äôeducazione delle madri:\n\nkidiq |&gt; \n  group_by(mom_hs) |&gt; \n  summarize(\n    avg = mean(kid_score),\n    std = sd(kid_score),\n    n = n()\n)\n#&gt; # A tibble: 2 √ó 4\n#&gt;   mom_hs   avg   std     n\n#&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n#&gt; 1      0  77.5  22.6    93\n#&gt; 2      1  89.3  19.0   341\n\nI risultati mostrano che:\n\n\n93 bambini hanno madri che non hanno completato la scuola superiore.\n\n341 bambini hanno madri diplomate,\n\ncon le medie e deviazioni standard del QI riportate sopra.\nLa differenza tra le medie del QI dei due gruppi pu√≤ essere calcolata direttamente come:\n\nmean(kidiq[kidiq$mom_hs == 1, ]$kid_score) - \n  mean(kidiq[kidiq$mom_hs == 0, ]$kid_score)\n#&gt; [1] 11.77\n\nQuesta analisi preliminare evidenzia la differenza media tra i gruppi.\nPer comprendere meglio la distribuzione dei dati, utilizziamo un violin plot, che mostra la densit√† stimata dei punteggi del QI nei due gruppi:\n\nggplot(kidiq, aes(x = as.factor(mom_hs), y = kid_score)) +\n  geom_violin(trim = FALSE) + \n  labs(\n    x = \"Livello di istruzione della madre\",\n    y = \"QI del bambino\",\n    title = \"Distribuzione dei punteggi QI in base all'istruzione materna\"\n  ) +\n  scale_x_discrete(labels = c(\"0\" = \"Non diplomata\", \"1\" = \"Diplomata\"))",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>¬† <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#parallelo-tra-approccio-frequentista-e-bayesiano-nel-confronto-tra-due-medie",
    "href": "chapters/linear_models/07_two_means.html#parallelo-tra-approccio-frequentista-e-bayesiano-nel-confronto-tra-due-medie",
    "title": "66¬† Confronto tra le medie di due gruppi",
    "section": "\n66.5 Parallelo tra approccio frequentista e bayesiano nel confronto tra due medie",
    "text": "66.5 Parallelo tra approccio frequentista e bayesiano nel confronto tra due medie\nIl confronto tra le medie di due gruppi indipendenti pu√≤ essere affrontato sia con un approccio frequentista, basato sulla distribuzione campionaria, sia con un approccio bayesiano, basato sull‚Äôaggiornamento delle credenze a posteriori. Vediamo i due approcci in dettaglio.\n\n66.5.1 Approccio Frequentista\nL‚Äôinferenza frequentista si basa sulla distribuzione campionaria della differenza tra le medie dei due gruppi. Supponiamo che i dati provengano da due popolazioni distribuite normalmente:\n\\[\nY_1 \\sim \\mathcal{N}(\\mu_1, \\sigma_1) \\quad \\text{e} \\quad Y_2 \\sim \\mathcal{N}(\\mu_2, \\sigma_2),\n\\]\ndove \\(\\mu_1\\) e \\(\\mu_2\\) sono le medie delle popolazioni, e \\(\\sigma_1\\) e \\(\\sigma_2\\) sono le deviazioni standard.\nSiamo interessati alla differenza delle medie campionarie, \\(\\bar{Y}_1 - \\bar{Y}_2\\), che ha una distribuzione normale:\n\\[\n\\bar{Y}_1 - \\bar{Y}_2 \\sim \\mathcal{N}\\left(\\mu_1 - \\mu_2, \\sqrt{\\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}}\\right).\n\\]\nSe le varianze delle due popolazioni sono uguali (\\(\\sigma_1 = \\sigma_2 = \\sigma\\)), possiamo stimare \\(\\sigma^2\\) tramite una varianza poolata:\n\\[\ns_p^2 = \\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2}.\n\\]\nCon questa stima, possiamo calcolare la probabilit√† che la differenza osservata tra le medie campionarie superi un certo valore, ad esempio 5 punti.\n\n66.5.1.1 Esempio pratico\nConsideriamo i dati:\n\n\nGruppo 1 (madri diplomate): \\(n_1 = 341\\), \\(\\bar{Y}_1 = 89.3\\), \\(s_1 = 19.0\\),\n\nGruppo 2 (madri non diplomate): \\(n_2 = 93\\), \\(\\bar{Y}_2 = 77.5\\), \\(s_2 = 22.6\\).\n\nCalcoliamo la probabilit√† che la differenza campionaria \\(\\bar{Y}_1 - \\bar{Y}_2\\) superi 5 punti:\n\n# Dati\nmean_1 &lt;- 89.3\nstd_1 &lt;- 19.0\nn_1 &lt;- 341\n\nmean_2 &lt;- 77.5\nstd_2 &lt;- 22.6\nn_2 &lt;- 93\n\n# Varianza poolata\npooled_variance &lt;- (((n_1 - 1) * std_1^2) + ((n_2 - 1) * std_2^2)) / (n_1 + n_2 - 2)\n\n# Deviazione standard della differenza\nstd_diff &lt;- sqrt(pooled_variance / n_1 + pooled_variance / n_2)\n\n# Probabilit√†\ndiff_threshold &lt;- 5\np_value &lt;- 1 - pnorm(diff_threshold, mean = 0, sd = std_diff)\np_value\n#&gt; [1] 0.01553\n\n\n66.5.2 Approccio Bayesiano\nL‚Äôapproccio bayesiano utilizza un modello di regressione con una variabile indicatrice (dummy) per distinguere i due gruppi. La formula del modello √®:\n\\[\nY = \\beta_0 + \\beta_1 \\cdot \\text{mom\\_hs} + \\epsilon,\n\\]\ndove:\n\n\n\\(\\beta_0\\) √® la media del gruppo di riferimento (madri non diplomate),\n\n\\(\\beta_1\\) √® la differenza tra le medie dei due gruppi,\n\n\\(\\epsilon \\sim \\mathcal{N}(0, \\sigma^2)\\).\n\n\n66.5.2.1 Specifica del modello e stima\nUtilizziamo il pacchetto brms per stimare il modello, con distribuzioni a priori debolmente informative:\n\nfit_1 &lt;- brm(\n  kid_score ~ mom_hs, \n  data = kidiq, \n  backend = \"cmdstanr\",\n  silent = 0\n)\n\nDopo aver stimato il modello, possiamo esaminare la distribuzione a posteriori del coefficiente \\(\\beta_1\\), che rappresenta la differenza tra le medie.\n\n66.5.2.2 Probabilit√† e intervalli di credibilit√†\nCalcoliamo la probabilit√† che la differenza tra le medie sia maggiore di 5 punti:\n\n# Campioni posteriori del coefficiente mom_hs\nposterior_samples &lt;- as_draws_df(fit_1)\nmom_hs_coef &lt;- posterior_samples$b_mom_hs\n\n# Probabilit√† che la differenza sia maggiore di 5\nprob_greater_than_5 &lt;- mean(mom_hs_coef &gt; 5)\nprob_greater_than_5\n#&gt; [1] 0.9975\n\n\n66.5.3 Differenze tra i due approcci\nI risultati ottenuti con i due approcci possono differire perch√© calcolano la probabilit√† sotto assunzioni e modelli differenti. Vediamo nel dettaglio le differenze tra i due approcci per chiarire la discrepanza.\n\n66.5.3.1 Approccio frequentista\n\n\nIpotesi: La differenza tra le medie campionarie \\(\\bar{Y}_1 - \\bar{Y}_2\\) √® distribuita secondo una normale centrata in \\(0\\) (sotto l‚Äôipotesi nulla che \\(\\mu_1 = \\mu_2\\)).\n\nDistribuzione utilizzata: La distribuzione normale ha una deviazione standard basata sulla stima poolata della varianza campionaria.\n\nRisultato: La probabilit√† calcolata rappresenta quanto √® improbabile osservare una differenza di almeno 5 punti sotto l‚Äôipotesi nulla.\n\nQuesto approccio parte dall‚Äôipotesi di uguali medie (\\(\\mu_1 = \\mu_2\\)) e misura l‚Äôevidenza contro questa ipotesi. In sostanza, stiamo testando un‚Äôipotesi frequentista sulla differenza campionaria.\n\n66.5.3.2 Approccio bayesiano\n\n\nIpotesi: Modello lineare bayesiano che stima il valore del coefficiente \\(\\beta\\) associato a mom_hs, usando i dati osservati per costruire una distribuzione a posteriori.\n\nDistribuzione utilizzata: La distribuzione a posteriori del coefficiente \\(\\beta\\), che rappresenta la plausibilit√† dei valori di \\(\\beta\\) dati i dati osservati.\n\nRisultato: La probabilit√† calcolata √® la proporzione di campioni posteriori in cui \\(\\beta &gt; 5\\).\n\nQuesto approccio riflette l‚Äôevidenza dei dati osservati rispetto al modello stimato, senza partire dall‚Äôipotesi che \\(\\mu_1 = \\mu_2\\).\n\n66.5.3.3 Perch√© i risultati differiscono?\n\n\nAssunzioni di partenza:\n\nFrequentista: Parte dall‚Äôipotesi nulla \\(\\mu_1 = \\mu_2\\) e calcola quanto √® improbabile osservare una differenza di almeno 5 punti sotto questa ipotesi.\nBayesiano: Parte da una distribuzione a priori per i parametri del modello, aggiornata con i dati osservati per stimare la distribuzione a posteriori. Non assume \\(\\mu_1 = \\mu_2\\), ma stima direttamente la probabilit√† che la differenza sia maggiore di 5.\n\n\n\nDistribuzione di riferimento:\n\nNel metodo frequentista, la distribuzione normale √® centrata su \\(0\\) con varianza stimata.\nNel metodo bayesiano, la distribuzione √® centrata sulla stima massima a posteriori (MAP) del coefficiente \\(\\beta\\), che riflette il valore pi√π plausibile dato i dati.\n\n\n\nEffetto dei dati osservati:\n\nNel metodo frequentista, il valore di \\(5\\) √® confrontato con una distribuzione teorica basata sull‚Äôipotesi nulla.\nNel metodo bayesiano, il valore di \\(5\\) √® confrontato con una distribuzione basata sui dati osservati.\n\n\n\nQuale metodo usare?\nDipende dall‚Äôinterpretazione desiderata: - se vogliamo testare quanto sono compatibili i dati con l‚Äôipotesi \\(\\mu_1 = \\mu_2\\), il metodo frequentista √® appropriato; - se vogliamo stimare direttamente la probabilit√† che la differenza sia maggiore di 5 punti, data la distribuzione a posteriori, il metodo bayesiano √® pi√π adatto.\nLa discrepanza tra i risultati riflette le diverse filosofie statistiche dei due approcci. Tuttavia, se partiamo dal presupposto che l‚Äôipotesi nulla (\\(\\mu_1 = \\mu_2\\)) sia sicuramente falsa, come accade quasi sempre nel mondo reale (poich√© una differenza, per quanto piccola, √® inevitabile), l‚Äôapproccio frequentista perde di utilit√† pratica. Testare cosa accadrebbe se la differenza fosse esattamente zero √® una costruzione teorica che raramente offre informazioni utili per comprendere i dati osservati.\nL‚Äôapproccio bayesiano, invece, permette di concentrarsi su una domanda pi√π pertinente: qual √® il grado di incertezza sulla differenza tra le medie delle due popolazioni? Questo approccio combina i dati osservati con informazioni a priori (esplicite o deboli) per costruire una distribuzione a posteriori che descrive la plausibilit√† dei possibili valori della differenza. In altre parole, ci consente di stimare direttamente quanto √® probabile che la differenza tra le medie superi una soglia significativa (ad esempio, 5 punti), senza fare affidamento su ipotesi non realistiche come quella di una differenza esattamente nulla.\nIn sintesi, l‚Äôapproccio bayesiano √® pi√π utile in questo contesto perch√©:\n\nNon si basa su un‚Äôipotesi nulla idealizzata che sappiamo non essere vera.\nStima direttamente la nostra incertezza rispetto alla differenza tra le medie, fornendo una risposta concreta e interpretabile in termini di probabilit√†.\nPermette di integrare le evidenze dei dati con la conoscenza preesistente, per ottenere inferenze pi√π realistiche e informate.\n\nPertanto, l‚Äôapproccio bayesiano √® particolarmente adatto quando l‚Äôobiettivo √® comprendere e quantificare l‚Äôincertezza riguardo alla differenza tra gruppi, piuttosto che testare una condizione ipotetica che difficilmente riflette la realt√†.\n\n66.5.4 Intervallo di credibilit√†\nSviluppiamo l‚Äôanalisi bayesiana. Calcoliamo anche l‚Äôintervallo di credibilit√† per \\(\\beta_1\\):\n\nbayestestR::hdi(fit_1, parameters = \"mom_hs\", ci = 0.89)\n#&gt; Highest Density Interval\n#&gt; \n#&gt; Parameter |       89% HDI\n#&gt; -------------------------\n#&gt; mom_hs    | [8.36, 15.66]\n\n\n66.5.5 Distribuzione Predittiva a Posteriori\nEffettuiamo un controllo grafico per confrontare i dati osservati con quelli predetti dal modello:\n\npp_check(fit_1)\n\n\n\n\n\n\n\n\n66.5.6 R¬≤ bayesiano\nInfine, calcoliamo il coefficiente di determinazione (Bayesiano \\(R^2\\)) per valutare la capacit√† del modello di spiegare la variabilit√† nei dati:\n\nbayes_R2(fit_1)\n#&gt;    Estimate Est.Error    Q2.5  Q97.5\n#&gt; R2  0.05766   0.02055 0.02176 0.1007\n\nQuesto esempio dimostra come l‚Äôanalisi di regressione bayesiana consenta di replicare e approfondire i risultati ottenuti in precedenza. Il modello non solo stima la differenza tra i gruppi, ma offre anche un quadro completo dell‚Äôincertezza associata, evidenziando la flessibilit√† e la potenza di questo approccio.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>¬† <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#una-parametrizzazione-alternativa",
    "href": "chapters/linear_models/07_two_means.html#una-parametrizzazione-alternativa",
    "title": "66¬† Confronto tra le medie di due gruppi",
    "section": "\n66.6 Una Parametrizzazione Alternativa",
    "text": "66.6 Una Parametrizzazione Alternativa\nPoich√© il posterior predictive check (pp-check) ha evidenziato una leggera discrepanza tra i valori osservati (\\(y\\)) e quelli predetti dal modello, consideriamo una parametrizzazione alternativa. Adottiamo un modello gaussiano esteso con un parametro aggiuntivo per modellare l‚Äôasimmetria nella distribuzione, utilizzando una famiglia di distribuzioni skew-normal.\nEcco come definiamo e stimiamo il nuovo modello:\n\nfit_2 &lt;- brm(\n  kid_score ~ mom_hs, \n  family = skew_normal(),\n  backend = \"cmdstanr\", \n  silent = 0,\n  data = kidiq\n)\n\n\n66.6.1 Verifica del modello\nDopo aver stimato il modello, eseguiamo nuovamente il pp-check per confrontare i dati osservati con quelli predetti:\n\npp_check(fit_2)\n\n\n\n\n\n\n\nI risultati mostrano un miglioramento nell‚Äôadattamento del modello, indicando che l‚Äôaggiunta del parametro per l‚Äôasimmetria ha contribuito a ridurre le discrepanze.\n\n66.6.2 Valutazione delle stime\nAnalizziamo le stime posteriori dei parametri per verificare eventuali variazioni rispetto al modello precedente:\n\ndraws &lt;- posterior::as_draws(fit_2, variable = \"^b_\", regex = TRUE)\nposterior::summarise_draws(draws, \"mean\", \"sd\", \"mcse_mean\", \"mcse_sd\")\n#&gt; # A tibble: 2 √ó 5\n#&gt;   variable     mean    sd mcse_mean mcse_sd\n#&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 b_Intercept 79.2   1.99    0.0325  0.0290\n#&gt; 2 b_mom_hs     9.65  2.24    0.0361  0.0321\n\n\n66.6.3 Intervallo di credibilit√†\nCalcoliamo l‚Äôintervallo di credibilit√† a densit√† massima (HDI) per il parametro associato a mom_hs:\n\nbayestestR::hdi(fit_2, parameters = \"mom_hs\", ci = 0.89)\n#&gt; Highest Density Interval\n#&gt; \n#&gt; Parameter |       89% HDI\n#&gt; -------------------------\n#&gt; mom_hs    | [6.10, 13.27]\n\n\n66.6.4 Valutazione della variabilit√† spiegata\nInfine, calcoliamo il coefficiente di determinazione Bayesiano (\\(R^2\\)) per quantificare la capacit√† del modello di spiegare la variabilit√† nei dati:\n\nbayes_R2(fit_2)\n#&gt;    Estimate Est.Error    Q2.5   Q97.5\n#&gt; R2  0.04003   0.01711 0.01137 0.07688\n\nIn conclusioni, il modello con distribuzione skew-normal offre un adattamento migliore rispetto al modello gaussiano standard, come evidenziato dal pp-check. Tuttavia, le stime posteriori dei parametri differiscono solo marginalmente rispetto al modello precedente. Questo suggerisce che, sebbene l‚Äôaggiunta dell‚Äôasimmetria migliori l‚Äôadattamento, l‚Äôeffetto sulla stima della relazione tra kid_score e mom_hs √® limitato.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>¬† <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#prior-predictive-checks",
    "href": "chapters/linear_models/07_two_means.html#prior-predictive-checks",
    "title": "66¬† Confronto tra le medie di due gruppi",
    "section": "\n66.7 Prior Predictive Checks",
    "text": "66.7 Prior Predictive Checks\nIl punto di partenza per valutare le prestazioni predittive dei priori consiste nell‚Äôeffettuare controlli predittivi grafici sui priori. In brms, questi controlli possono essere eseguiti in modo quasi identico ai posterior predictive checks. Basta indicare a brms di ignorare i dati durante il campionamento, concentrandosi unicamente sui priori. Per fare ci√≤, √® fondamentale che tutti i parametri abbiano priori propri e, idealmente, non eccessivamente ampi o poco plausibili.\nPartiamo specificando priori debolmente informativi per il nostro modello gaussiano applicato ai dati kidiq. Esaminiamo prima i priori predefiniti da brms:\n\nget_prior(kid_score ~ mom_hs, data = kidiq)\n#&gt;                   prior     class   coef group resp dpar nlpar lb ub\n#&gt;  student_t(3, 90, 19.3) Intercept                                   \n#&gt;                  (flat)         b                                   \n#&gt;                  (flat)         b mom_hs                            \n#&gt;   student_t(3, 0, 19.3)     sigma                               0   \n#&gt;        source\n#&gt;       default\n#&gt;       default\n#&gt;  (vectorized)\n#&gt;       default\n\n\n66.7.1 Specifica dei Priori\nModifichiamo i priori predefiniti per utilizzare prior debolmente informativi personalizzati:\n\nprior_gaussian &lt;- \n  prior(normal(90, 20), class = \"b\", coef = \"Intercept\") +\n  prior(normal(0, 15), class = \"b\", coef = \"mom_hs\") +\n  prior(cauchy(0, 20), class = \"sigma\")\n\n\n66.7.2 Aggiunta dei Priori al Modello\nAggiungiamo i priori definiti alla funzione brm:\n\nfit_3 &lt;- brm(\n  bf(kid_score ~ 1 + mom_hs, center = FALSE), \n  kid_score ~ mom_hs, \n  prior = prior_gaussian,\n  family = gaussian(),\n  backend = \"cmdstanr\", \n  silent = 0,\n  data = kidiq\n)\n\nLe stime a posteriori per i parametri \\(\\alpha\\) e \\(\\beta\\) corrispondono ai valori ottenuti in precedenza:\n\ndraws &lt;- posterior::as_draws(fit_3, variable = \"^b_\", regex = TRUE)\nposterior::summarise_draws(draws, \"mean\", \"sd\", \"mcse_mean\", \"mcse_sd\")\n#&gt; # A tibble: 2 √ó 5\n#&gt;   variable     mean    sd mcse_mean mcse_sd\n#&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 b_Intercept  78.0  2.05    0.0534  0.0414\n#&gt; 2 b_mom_hs     11.2  2.29    0.0593  0.0469\n\n\n66.7.3 Esame della Distribuzione Predittiva a Priori\nPer generare campioni unicamente dalla distribuzione dei priori, specifichiamo l‚Äôargomento sample_prior = \"only\":\n\nfit_4 &lt;- brm(\n  bf(kid_score ~ 1 + mom_hs, center = FALSE), \n  kid_score ~ mom_hs, \n  prior = prior_gaussian,\n  family = gaussian(),\n  backend = \"cmdstanr\", \n  silent = 0,\n  data = kidiq,\n  sample_prior = \"only\"\n)\n\nQuando analizziamo il sommario del modello, osserviamo che i valori stimati dai ‚Äúposteriori‚Äù riflettono effettivamente i priori:\n\nsummary(fit_4)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: kid_score ~ 1 + mom_hs \n#&gt;          autocor ~ tructure(list(), class = \"formula\", .Environment = &lt;environment&gt;)\n#&gt;    Data: kidiq (Number of observations: 434) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept    89.89     20.01    50.65   128.40 1.00     3689     2858\n#&gt; mom_hs       -0.04     14.73   -27.63    28.42 1.00     3613     2922\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma   240.42   4297.30     0.66   578.48 1.00     3095     2039\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nPossiamo utilizzare pp_check per visualizzare i prior predictive checks:\n\npp_check(fit_4, ndraws = 100) + xlim(10, 180)\n\n\n\n\n\n\n\nLa distribuzione predittiva a priori risulta pi√π ampia rispetto alla distribuzione dei dati osservati, ma rimane comunque dello stesso ordine di grandezza. Questo √® esattamente ci√≤ che ci aspettiamo: i priori dovrebbero essere abbastanza ampi da consentire flessibilit√†, ma non cos√¨ eccessivi da risultare irrealistici. Sebbene questo controllo non garantisca con certezza che tutti i priori siano ragionevoli, √® utile per identificare priori potenzialmente troppo ampi o poco informativi.\n\n66.7.4 Massima Verosimiglianza vs Approccio Bayesiano\nIl modello di regressione basato sulla massima verosimiglianza stima i parametri ottimizzando la funzione di verosimiglianza, che rappresenta la probabilit√† dei dati dati i parametri. Sebbene questo approccio sia robusto, si limita a fornire stime puntuali e intervalli di fiducia frequentisti, che non hanno un‚Äôinterpretazione probabilistica diretta (ad esempio, non possiamo dire che c‚Äô√® una probabilit√† del 95% che il vero parametro sia contenuto nell‚Äôintervallo).\nL‚Äôapproccio bayesiano, al contrario:\n\n\nCostruisce una distribuzione a posteriori per il parametro di interesse (ad esempio, la differenza tra gruppi), combinando i dati osservati con informazioni a priori.\n\nPermette di calcolare probabilit√† dirette: ad esempio, la probabilit√† che la differenza sia maggiore di un certo valore (\\(P(\\beta_{mean\\_diff} &gt; 5)\\)).\n\nIntegra incertezze multiple: ogni fonte di incertezza viene propagata naturalmente nella distribuzione a posteriori, rendendo l‚Äôanalisi pi√π realistica.\n\n66.7.5 Test \\(t\\) di Student vs Bayesiano\nIl test \\(t\\) di Student si basa su un‚Äôipotesi nulla rigida (\\(\\mu_1 = \\mu_2\\)), mentre l‚Äôapproccio bayesiano permette di valutare la probabilit√† che la differenza sia significativa rispetto a un valore ipotetico (es. 5 o 10 punti). Questo consente un‚Äôanalisi pi√π flessibile e rilevante:\n\n\nNessun focus sull‚Äôipotesi nulla: Invece di testare l‚Äôipotesi nulla che sappiamo essere quasi certamente falsa, l‚Äôapproccio bayesiano si concentra su ci√≤ che i dati ci dicono direttamente riguardo alla differenza.\n\nInformazioni aggiuntive: Il test bayesiano, attraverso la distribuzione a posteriori, permette di visualizzare l‚Äôincertezza e valutare intervalli di credibilit√† attorno alla stima.\n\n66.7.6 Esempio con Prior Informativi\nUn ulteriore approfondimento dell‚Äôapproccio bayesiano consiste nell‚Äôuso di prior informativi. Ad esempio, se studi precedenti indicano che le differenze tra i due gruppi tendono ad essere intorno a 10 punti, possiamo specificare un prior normale centrato su 10 con una deviazione standard moderata. Questo prior pu√≤ influenzare i risultati quando i dati sono scarsi o poco informativi, ma con un campione ampio come in questo caso, i dati tendono a prevalere sui prior.\n\nfit_5 &lt;- brm(\n  kid_score ~ mom_hs,\n  data = kidiq,\n  prior = c(set_prior(\"normal(10, 5)\", class = \"b\", coef = \"mom_hs\")),\n  backend = \"cmdstanr\",\n  silent = 0\n)\n\n\nsummary(fit_5)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: kid_score ~ mom_hs \n#&gt;    Data: kidiq (Number of observations: 434) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept    77.81      1.92    74.07    81.58 1.00     4427     3120\n#&gt; mom_hs       11.43      2.12     7.37    15.60 1.00     4265     3078\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma    19.88      0.66    18.62    21.20 1.00     4270     3219\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nCon prior informativi, i risultati rifletteranno sia le evidenze dei dati sia il nostro stato di conoscenza precedente, arricchendo ulteriormente l‚Äôinferenza.\n\n66.7.7 Test di Ipotesi Bayesiano con hypothesis()\n\nIl comando hypothesis() in brms consente di verificare ipotesi specifiche direttamente sulla distribuzione a posteriori. Ad esempio:\n\nhypothesis(fit_1, \"mom_hs &gt; 5\")\n#&gt; Hypothesis Tests for class b:\n#&gt;         Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio\n#&gt; 1 (mom_hs)-(5) &gt; 0     6.78      2.31     3.02    10.54        399\n#&gt;   Post.Prob Star\n#&gt; 1         1    *\n#&gt; ---\n#&gt; 'CI': 90%-CI for one-sided and 95%-CI for two-sided hypotheses.\n#&gt; '*': For one-sided hypotheses, the posterior probability exceeds 95%;\n#&gt; for two-sided hypotheses, the value tested against lies outside the 95%-CI.\n#&gt; Posterior probabilities of point hypotheses assume equal prior probabilities.\n\nConfrontando questo approccio al test frequentista:\n\nIl test bayesiano non restituisce un \\(p\\)-value, ma una probabilit√† interpretabile, come ‚Äúc‚Äô√® una probabilit√† del 99.8% che la differenza tra i gruppi sia maggiore di 5 punti‚Äù.\nL‚Äôoutput include un intervallo di credibilit√†, che rappresenta un range di valori plausibili per il parametro con una certa probabilit√† (ad esempio, 89%).\n\n66.7.8 Integrazione Bayesiana nella Pratica\nL‚Äôapproccio bayesiano si distingue per la sua flessibilit√†, soprattutto quando:\n\nL‚Äôipotesi nulla √® irrealistica o poco utile.\nSi desidera incorporare conoscenze precedenti in modo sistematico.\nSi vuole ottenere inferenze probabilistiche pi√π dirette e intuitive, come la probabilit√† che un parametro superi una soglia rilevante.\n\nCon l‚Äôaumentare della complessit√† dei modelli o della necessit√† di rispondere a domande pi√π sfumate, l‚Äôapproccio bayesiano diventa lo strumento pi√π adatto per catturare la reale incertezza e complessit√† dei dati.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>¬† <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#riflessioni-conclusive",
    "href": "chapters/linear_models/07_two_means.html#riflessioni-conclusive",
    "title": "66¬† Confronto tra le medie di due gruppi",
    "section": "\n66.8 Riflessioni Conclusive",
    "text": "66.8 Riflessioni Conclusive\nIn questo capitolo abbiamo esplorato le numerose funzionalit√† offerte da brms per la modellazione bayesiana, dimostrando come questo pacchetto consenta di implementare analisi sofisticate in modo intuitivo e flessibile. Dalla specifica dei modelli all‚Äôinterpretazione probabilistica dei risultati, brms si √® rivelato uno strumento particolarmente utile per tradurre domande di ricerca complesse in analisi statistiche rigorose.\nUn punto chiave emerso √® l‚Äôimportanza dell‚Äôapproccio bayesiano nel superare i limiti delle inferenze frequentiste, permettendo di stimare direttamente l‚Äôincertezza sui parametri e di testare ipotesi rilevanti senza fare affidamento su ipotesi nulle spesso irrealistiche. Inoltre, abbiamo visto come la capacit√† di incorporare conoscenze pregresse attraverso i priori consenta di adattare i modelli al contesto specifico della ricerca, rendendo l‚Äôapproccio bayesiano non solo potente, ma anche estremamente versatile.\nIn definitiva, brms non √® soltanto un software per l‚Äôanalisi statistica, ma uno strumento che favorisce un cambiamento nella mentalit√† analitica, promuovendo una visione pi√π completa e realistica dell‚Äôincertezza e della probabilit√†. Questo capitolo dovrebbe servire come base per l‚Äôapplicazione di modelli bayesiani in scenari reali, fornendo sia le competenze tecniche che una prospettiva critica sui vantaggi dell‚Äôapproccio bayesiano nella ricerca quantitativa moderna.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>¬† <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/07_two_means.html#informazioni-sullambiente-di-sviluppo",
    "title": "66¬† Confronto tra le medie di due gruppi",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] rstan_2.32.7        StanHeaders_2.32.10 insight_1.1.0      \n#&gt;  [4] bayestestR_0.15.2   brms_2.22.0         Rcpp_1.0.14        \n#&gt;  [7] posterior_1.6.1     cmdstanr_0.8.1      thematic_0.1.6     \n#&gt; [10] MetBrewer_0.2.0     ggokabeito_0.1.0    see_0.11.0         \n#&gt; [13] gridExtra_2.3       patchwork_1.3.0     bayesplot_1.11.1   \n#&gt; [16] psych_2.5.3         scales_1.3.0        markdown_2.0       \n#&gt; [19] knitr_1.50          lubridate_1.9.4     forcats_1.0.0      \n#&gt; [22] stringr_1.5.1       dplyr_1.1.4         purrr_1.0.4        \n#&gt; [25] readr_2.1.5         tidyr_1.3.1         tibble_3.2.1       \n#&gt; [28] ggplot2_3.5.1       tidyverse_2.0.0     rio_1.2.3          \n#&gt; [31] here_1.0.1         \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] mnormt_2.1.1         inline_0.3.21        sandwich_3.1-1      \n#&gt;  [4] rlang_1.1.5          magrittr_2.0.3       multcomp_1.4-28     \n#&gt;  [7] matrixStats_1.5.0    compiler_4.4.2       loo_2.8.0           \n#&gt; [10] reshape2_1.4.4       vctrs_0.6.5          pkgconfig_2.0.3     \n#&gt; [13] fastmap_1.2.0        backports_1.5.0      labeling_0.4.3      \n#&gt; [16] utf8_1.2.4           rmarkdown_2.29       tzdb_0.5.0          \n#&gt; [19] haven_2.5.4          ps_1.9.0             xfun_0.51           \n#&gt; [22] jsonlite_1.9.1       parallel_4.4.2       R6_2.6.1            \n#&gt; [25] stringi_1.8.4        estimability_1.5.1   zoo_1.8-13          \n#&gt; [28] pacman_0.5.1         R.utils_2.13.0       Matrix_1.7-3        \n#&gt; [31] splines_4.4.2        timechange_0.3.0     tidyselect_1.2.1    \n#&gt; [34] rstudioapi_0.17.1    abind_1.4-8          yaml_2.3.10         \n#&gt; [37] codetools_0.2-20     curl_6.2.2           processx_3.8.6      \n#&gt; [40] pkgbuild_1.4.7       plyr_1.8.9           lattice_0.22-6      \n#&gt; [43] withr_3.0.2          bridgesampling_1.1-2 coda_0.19-4.1       \n#&gt; [46] evaluate_1.0.3       survival_3.8-3       RcppParallel_5.1.10 \n#&gt; [49] pillar_1.10.1        tensorA_0.36.2.1     checkmate_2.3.2     \n#&gt; [52] stats4_4.4.2         distributional_0.5.0 generics_0.1.3      \n#&gt; [55] rprojroot_2.0.4      hms_1.1.3            rstantools_2.4.0    \n#&gt; [58] munsell_0.5.1        xtable_1.8-4         glue_1.8.0          \n#&gt; [61] emmeans_1.11.0       tools_4.4.2          data.table_1.17.0   \n#&gt; [64] mvtnorm_1.3-3        grid_4.4.2           QuickJSR_1.6.0      \n#&gt; [67] datawizard_1.0.2     colorspace_2.1-1     nlme_3.1-167        \n#&gt; [70] cli_3.6.4            Brobdingnag_1.2-9    V8_6.0.2            \n#&gt; [73] gtable_0.3.6         R.methodsS3_1.8.2    digest_0.6.37       \n#&gt; [76] TH.data_1.1-3        htmlwidgets_1.6.4    farver_2.1.2        \n#&gt; [79] htmltools_0.5.8.1    R.oo_1.27.0          lifecycle_1.0.4     \n#&gt; [82] MASS_7.3-65",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>¬† <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#bibliografia",
    "href": "chapters/linear_models/07_two_means.html#bibliografia",
    "title": "66¬† Confronto tra le medie di due gruppi",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nKruschke, J. K. (2013). Bayesian estimation supersedes the t test. Journal of Experimental Psychology: General, 142(2), 573‚Äì603.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>¬† <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_sample_size.html",
    "href": "chapters/linear_models/08_sample_size.html",
    "title": "67¬† Disegno della ricerca e potere statistico",
    "section": "",
    "text": "67.1 Introduzione\nLa potenza statistica √® definita come la probabilit√†, calcolata prima che uno studio venga condotto, che un determinato confronto raggiunga un livello predefinito di ‚Äúsignificativit√† statistica‚Äù (tipicamente un p-value inferiore a 0,05), dato un effetto reale ipotizzato. Per calcolare la potenza, si parte da un‚Äôipotesi sulla dimensione dell‚Äôeffetto, si fanno assunzioni sulla variabilit√† dei dati e sulla dimensione del campione, e si utilizzano calcoli probabilistici per determinare la probabilit√† che il p-value sia inferiore alla soglia stabilita.\nLa visione convenzionale sconsiglia di condurre studi con bassa potenza, poich√© hanno basse probabilit√† di ‚Äúsuccesso‚Äù. Tuttavia, in casi in cui i costi sono molto bassi rispetto ai potenziali benefici, un ricercatore potrebbe decidere di correre il rischio. Come vedremo, per√≤, questa scelta pu√≤ nascondere insidie significative.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>¬† <span class='chapter-title'>Disegno della ricerca e potere statistico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_sample_size.html#la-maledizione-del-vincitore-negli-studi-a-bassa-potenza",
    "href": "chapters/linear_models/08_sample_size.html#la-maledizione-del-vincitore-negli-studi-a-bassa-potenza",
    "title": "67¬† Disegno della ricerca e potere statistico",
    "section": "\n67.2 La maledizione del vincitore negli studi a bassa potenza",
    "text": "67.2 La maledizione del vincitore negli studi a bassa potenza\nIn uno studio con bassa potenza, il ‚Äúsuccesso‚Äù apparente di un risultato statisticamente significativo pu√≤ essere ingannevole. Quando il segnale √® debole e il rumore elevato, i risultati significativi tendono a essere erronei (esagerati o nel segno sbagliato), con scarse probabilit√† di replicabilit√†. Questi errori sono noti come errori di tipo M (esagerazione della dimensione dell‚Äôeffetto) e di tipo S (errore nel segno dell‚Äôeffetto). Di conseguenza, uno studio a bassa potenza rischia di generare informazioni fuorvianti, contribuendo alla crisi di replicazione.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>¬† <span class='chapter-title'>Disegno della ricerca e potere statistico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_sample_size.html#stimare-la-dimensione-del-campione",
    "href": "chapters/linear_models/08_sample_size.html#stimare-la-dimensione-del-campione",
    "title": "67¬† Disegno della ricerca e potere statistico",
    "section": "\n67.3 Stimare la dimensione del campione",
    "text": "67.3 Stimare la dimensione del campione\nPrima di raccogliere dati, √® utile stimare la dimensione del campione necessaria per ottenere un certo livello di precisione o per garantire una potenza desiderata. Vediamo i calcoli dettagliati.\n\n67.3.1 Determinazione della dimensione del campione per un errore standard specifico\nSupponiamo di voler stimare un valore medio \\(\\theta\\) della popolazione utilizzando un campione casuale di dimensione \\(n\\). La stima \\(\\bar{y}\\), cio√® la media campionaria, ha un errore standard dato da:\n\\[\n\\text{s.e.}(\\bar{y}) = \\frac{\\sigma}{\\sqrt{n}},\n\\]\ndove:\n\n\n\\(\\text{s.e.}(\\bar{y})\\) √® l‚Äôerrore standard della media campionaria,\n\n\\(\\sigma\\) √® la deviazione standard della popolazione,\n\n\\(n\\) √® la dimensione del campione.\n\nSe vogliamo ottenere un errore standard specifico, denotato con \\(\\text{s.e.}\\), impostiamo l‚Äôequazione:\n\\[\n\\text{s.e.} = \\frac{\\sigma}{\\sqrt{n}}.\n\\]\nPer risolvere rispetto a \\(n\\), procediamo come segue:\n\nMoltiplichiamo entrambi i lati per \\(\\sqrt{n}\\) per eliminare il denominatore: \\[\n\\text{s.e.} \\cdot \\sqrt{n} = \\sigma.\n\\]\nDividiamo entrambi i lati per \\(\\text{s.e.}\\): \\[\n\\sqrt{n} = \\frac{\\sigma}{\\text{s.e.}}.\n\\]\nEleviamo al quadrato entrambi i lati per eliminare la radice: \\[\nn = \\left(\\frac{\\sigma}{\\text{s.e.}}\\right)^2.\n\\]\n\nQuesta formula ci dice che la dimensione del campione necessaria per ottenere un determinato errore standard √® proporzionale al quadrato del rapporto tra la deviazione standard \\(\\sigma\\) e l‚Äôerrore standard desiderato \\(\\text{s.e.}\\).\n\n67.3.2 Dimensione del campione per una potenza dell‚Äô80%\nSupponiamo ora di voler determinare la dimensione del campione necessaria per ottenere l‚Äô80% di potenza nel distinguere un valore \\(\\theta\\) dalla media ipotizzata \\(\\theta_0\\).\nL‚Äôerrore standard della differenza \\(\\theta - \\theta_0\\) √® dato da:\n\\[\n\\text{s.e.} = \\frac{\\sigma}{\\sqrt{n}}.\n\\]\nPer ottenere l‚Äô80% di potenza, vogliamo che la differenza osservata \\(\\theta - \\theta_0\\) sia sufficientemente grande da essere rilevata con il livello di significativit√† prefissato (ad esempio, 5%).\n\n67.3.2.1 Passaggi algebrici per derivare la formula:\n\nPer una potenza dell‚Äô80%, la differenza \\(\\theta - \\theta_0\\) deve essere almeno 2,8 volte l‚Äôerrore standard, dove il valore \\(2.8\\) √® dato dalla somma dei quantili della distribuzione normale per il 95% di confidenza (\\(1.96\\)) e per l‚Äô80% di potenza (\\(0.84\\)): \\[\n\\theta - \\theta_0 = 2.8 \\cdot \\frac{\\sigma}{\\sqrt{n}}.\n\\]\nRisolviamo per \\(\\sqrt{n}\\): \\[\n\\sqrt{n} = \\frac{2.8 \\cdot \\sigma}{\\theta - \\theta_0}.\n\\]\nEleviamo al quadrato entrambi i lati: \\[\nn = \\left(\\frac{2.8 \\cdot \\sigma}{\\theta - \\theta_0}\\right)^2.\n\\]\n\nQuesta formula fornisce la dimensione del campione necessaria per ottenere l‚Äô80% di potenza, dove \\(2.8\\) rappresenta il valore soglia della distribuzione normale standard.\n\n67.3.2.2 Esempio pratico\nSe vogliamo distinguere \\(\\theta\\) da \\(\\theta_0\\) con \\(\\sigma = 10\\) e una differenza minima rilevabile di \\(\\theta - \\theta_0 = 5\\), possiamo calcolare \\(n\\) come segue:\n\\[\nn = \\left(\\frac{2.8 \\cdot 10}{5}\\right)^2 = \\left(5.6\\right)^2 = 31.36.\n\\]\nArrotondando, servono almeno 32 osservazioni.\n\n67.3.3 Correzione per campioni piccoli e distribuzione t\nPer studi con pochi gradi di libert√†, l‚Äôincertezza sulla stima di \\(\\sigma\\) aumenta, e la distribuzione t di Student diventa pi√π appropriata. In questi casi, il valore \\(2.8\\) deve essere sostituito con un valore pi√π grande, dipendente dai gradi di libert√†, per compensare l‚Äôincertezza aggiuntiva.\nAd esempio, per uno studio che confronta due gruppi di 6 pazienti ciascuno, i gradi di libert√† sono 10. In R, la somma dei quantili della distribuzione t con 10 gradi di libert√† per l‚Äô80% di potenza e il 95% di confidenza √® \\(3.1\\), quindi \\(2.8\\) viene sostituito da \\(3.1\\) nei calcoli per la potenza dell‚Äô80%.\n\n# Gradi di libert√†\ndf &lt;- 10\n\n# Calcola il quantile per l'80% di potenza (quindi 0.8) e il 95% di confidenza (quindi 0.975)\nt_value_80 &lt;- qt(0.8, df)\nt_value_95 &lt;- qt(0.975, df)\n\n# Somma dei due quantili\nt_total &lt;- t_value_80 + t_value_95\nt_total\n#&gt; [1] 3.107\n\nEseguendo questo codice in R, otteniamo il valore 3.107, che sostituisce il valore \\(2.8\\) nei calcoli per la potenza dell‚Äô80% quando si lavora con piccoli campioni e si utilizza la distribuzione t invece della normale standard.\n\n67.3.4 Nota\nQuesto esempio evidenzia come la distribuzione t tenga conto della maggiore variabilit√† introdotta dalla stima della deviazione standard in campioni di piccole dimensioni, aumentando leggermente il valore soglia richiesto per la potenza desiderata.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>¬† <span class='chapter-title'>Disegno della ricerca e potere statistico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_sample_size.html#confronto-di-medie",
    "href": "chapters/linear_models/08_sample_size.html#confronto-di-medie",
    "title": "67¬† Disegno della ricerca e potere statistico",
    "section": "\n67.4 Confronto di Medie",
    "text": "67.4 Confronto di Medie\nEsaminiamo ora il caso del confronto tra le medie di due gruppi indipendenti. Vogliamo determinare la dimensione del campione necessaria per rilevare una differenza significativa \\(\\Delta\\) tra le due medie con una potenza statistica dell‚Äô80%.\n\n67.4.1 Errore Standard della Differenza tra Due Medie\nL‚Äôerrore standard della differenza tra le medie campionarie \\(\\bar{y}_1\\) e \\(\\bar{y}_2\\) √® dato da:\n\\[\n\\text{s.e.}(\\bar{y}_1 - \\bar{y}_2) = \\sqrt{\\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}},\n\\]\ndove:\n\n\n\\(\\sigma_1^2\\) e \\(\\sigma_2^2\\) sono le varianze delle popolazioni dei due gruppi,\n\n\\(n_1\\) e \\(n_2\\) sono le dimensioni dei campioni nei due gruppi.\n\n\n67.4.1.1 Caso di Varianze e Dimensioni del Campione Uguali\nSe assumiamo che:\n\nle varianze sono uguali: \\(\\sigma_1 = \\sigma_2 = \\sigma\\),\nle dimensioni dei campioni sono uguali: \\(n_1 = n_2 = n\\),\n\nl‚Äôerrore standard diventa:\n\n\nSostituiamo le varianze e le dimensioni dei campioni:\n\\[\n\\text{s.e.} = \\sqrt{\\frac{\\sigma^2}{n} + \\frac{\\sigma^2}{n}} = \\sqrt{\\frac{2\\sigma^2}{n}}.\n\\]\n\n\nSemplifichiamo l‚Äôespressione:\n\\[\n\\text{s.e.} = \\frac{\\sqrt{2}\\sigma}{\\sqrt{n}}.\n\\]\n\n\n67.4.2 Dimensione del Campione per un Errore Standard Specifico\nSe desideriamo ottenere un errore standard specifico \\(\\text{s.e.}\\), possiamo determinare la dimensione del campione \\(n\\) seguendo questi passaggi:\n\n\nPartiamo dall‚Äôespressione dell‚Äôerrore standard:\n\\[\n\\text{s.e.} = \\frac{\\sqrt{2}\\sigma}{\\sqrt{n}}.\n\\]\n\n\nRisolviamo per \\(\\sqrt{n}\\):\n\\[\n\\sqrt{n} = \\frac{\\sqrt{2}\\sigma}{\\text{s.e.}}.\n\\]\n\n\nEleviamo al quadrato entrambi i membri:\n\\[\nn = \\left( \\frac{\\sqrt{2}\\sigma}{\\text{s.e.}} \\right)^2 = \\frac{2\\sigma^2}{\\text{s.e.}^2}.\n\\]\n\n\n67.4.3 Dimensione del Campione per una Differenza \\(\\Delta\\) con l‚Äô80% di Potenza\nPer garantire una potenza dell‚Äô80% nel rilevare una differenza \\(\\Delta\\) tra le due medie, seguiamo questi passaggi:\n\n67.4.3.1 Determinazione del Valore Critico\nPer un test bilaterale al livello di significativit√† del 5%, i valori critici della distribuzione normale standard sono:\n\n\n\\(z_{\\alpha/2} = 1.96\\) (per il 95% di confidenza),\n\n\\(z_{\\text{potenza}} = 0.84\\) (per l‚Äô80% di potenza).\n\nLa somma totale √®:\n\\[\nz_{\\text{totale}} = z_{\\alpha/2} + z_{\\text{potenza}} = 1.96 + 0.84 = 2.8.\n\\]\n\n67.4.3.2 Relazione tra \\(\\Delta\\) ed Errore Standard\nLa differenza minima rilevabile \\(\\Delta\\) √® legata all‚Äôerrore standard dalla relazione:\n\n\nImpostiamo l‚Äôequazione:\n\\[\n\\Delta = z_{\\text{totale}} \\times \\text{s.e.} = 2.8 \\times \\text{s.e.}.\n\\]\n\n\nSostituiamo l‚Äôespressione per \\(\\text{s.e.}\\):\n\\[\n\\Delta = 2.8 \\times \\frac{\\sqrt{2}\\sigma}{\\sqrt{n}}.\n\\]\n\n\nCalcoliamo il coefficiente:\n\\[\n2.8 \\times \\sqrt{2} = 2.8 \\times 1.4142 \\approx 3.96.\n\\]\nQuindi:\n\\[\n\\Delta = 3.96 \\times \\frac{\\sigma}{\\sqrt{n}}.\n\\]\n\n\nRisolviamo per \\(\\sqrt{n}\\):\n\\[\n\\sqrt{n} = \\frac{3.96 \\sigma}{\\Delta}.\n\\]\n\n\nEleviamo al quadrato entrambi i membri:\n\\[\nn = \\left( \\frac{3.96 \\sigma}{\\Delta} \\right)^2.\n\\]\n\n\n67.4.4 Formula Finale per la Dimensione del Campione\nLa dimensione del campione necessaria per ciascun gruppo √® data da:\n\\[\nn = \\left( \\frac{3.96 \\sigma}{\\Delta} \\right)^2.\n\\]\nPer semplificare i calcoli, possiamo arrotondare \\(3.96\\) a \\(4\\):\n\\[\nn = \\left( \\frac{4 \\sigma}{\\Delta} \\right)^2.\n\\]\nNota Importante: Questa formula si applica quando:\n\n\nLe varianze delle popolazioni sono uguali (\\(\\sigma_1 = \\sigma_2 = \\sigma\\)).\n\nLe dimensioni dei campioni nei due gruppi sono uguali (\\(n_1 = n_2 = n\\)).\n\nIl totale dei campioni √® \\(N = 2n\\).\n\n67.4.5 Interpretazione della Formula\n\n\nSe la deviazione standard \\(\\sigma\\) √® elevata: C‚Äô√® maggiore variabilit√† nei dati, quindi √® necessario un campione pi√π grande per rilevare una differenza \\(\\Delta\\) con la stessa potenza.\n\nSe la differenza \\(\\Delta\\) √® piccola: Serve un campione pi√π grande per garantire che la differenza sia rilevabile con l‚Äô80% di potenza.\n\n67.4.6 Esempio Pratico\nSupponiamo di voler rilevare una differenza \\(\\Delta = 5\\) unit√† tra due gruppi, con una deviazione standard comune \\(\\sigma = 10\\) unit√†.\nCalcolo della dimensione del campione per ciascun gruppo:\n\n\nUtilizziamo la formula:\n\\[\nn = \\left( \\frac{4 \\times 10}{5} \\right)^2 = \\left( \\frac{40}{5} \\right)^2 = \\left( 8 \\right)^2 = 64.\n\\]\n\n\nRisultato:\n\n\n64 partecipanti per gruppo.\n\nTotale di 128 partecipanti.\n\n\n\n67.4.7 Caso con Campione Totale Fissato\nSe il campione totale √® fissato a \\(n\\), con dimensioni dei gruppi \\(n_1 = n_2 = n/2\\), l‚Äôerrore standard cambia leggermente.\n\n67.4.7.1 Calcolo dell‚ÄôErrore Standard\n\n\nSostituiamo \\(n_1 = n_2 = n/2\\) nell‚Äôerrore standard:\n\\[\n\\text{s.e.} = \\sqrt{\\frac{\\sigma^2}{n/2} + \\frac{\\sigma^2}{n/2}} = \\sqrt{2 \\times \\frac{\\sigma^2}{n/2}}.\n\\]\n\n\nSemplifichiamo l‚Äôespressione:\n\\[\n\\text{s.e.} = \\sqrt{\\frac{4\\sigma^2}{n}} = \\frac{2\\sigma}{\\sqrt{n}}.\n\\]\n\n\n67.4.7.2 Dimensione del Campione\n\n\nRelazione tra \\(\\Delta\\) ed errore standard:\n\\[\n\\Delta = 2.8 \\times \\text{s.e.} = 2.8 \\times \\frac{2\\sigma}{\\sqrt{n}} = \\frac{5.6 \\sigma}{\\sqrt{n}}.\n\\]\n\n\nRisolviamo per \\(\\sqrt{n}\\):\n\\[\n\\sqrt{n} = \\frac{5.6 \\sigma}{\\Delta}.\n\\]\n\n\nEleviamo al quadrato:\n\\[\nn = \\left( \\frac{5.6 \\sigma}{\\Delta} \\right)^2.\n\\]\n\n\nIn questo scenario, la dimensione totale del campione √® \\(n\\), con \\(n/2\\) partecipanti per ciascun gruppo.\n\n67.4.8 Scelta della Formula Adeguata\n\n\nSe \\(n\\) rappresenta la dimensione del campione per gruppo:\n\\[\nn = \\left( \\frac{4 \\sigma}{\\Delta} \\right)^2.\n\\]\n\n\nSe \\(n\\) rappresenta la dimensione totale del campione:\n\\[\nn = \\left( \\frac{5.6 \\sigma}{\\Delta} \\right)^2.\n\\]\n\n\nAssicurarsi di chiarire come si definisce \\(n\\) √® fondamentale per applicare correttamente le formule.\n\n67.4.9 Sintesi\n\n\nVarianze e dimensioni uguali nei due gruppi semplificano i calcoli.\n\nLa dimensione del campione aumenta con l‚Äôaumentare della deviazione standard \\(\\sigma\\) e con la diminuzione della differenza \\(\\Delta\\) che si vuole rilevare.\n\nEssere chiari sulla definizione di \\(n\\) (per gruppo o totale) evita errori nei calcoli.\n\n\nEsempio 67.1 Se la differenza \\(\\Delta\\) che vogliamo rilevare √® pari a met√† della deviazione standard (\\(\\Delta = 0.5\\sigma\\)), allora la formula ci dir√† quanti partecipanti sono necessari in ciascun gruppo per rilevare questa differenza con l‚Äô80% di potenza. Ad esempio, se \\(\\Delta = 0.5\\sigma\\), la dimensione totale del campione sar√†:\n\\[\nn = \\left(\\frac{5.6 \\sigma}{0.5\\sigma}\\right)^2 = (11.2)^2 = 125.44 \\approx 126.\n\\]\nQuindi, servirebbero 63 partecipanti per gruppo.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>¬† <span class='chapter-title'>Disegno della ricerca e potere statistico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_sample_size.html#riflessioni-conclusive",
    "href": "chapters/linear_models/08_sample_size.html#riflessioni-conclusive",
    "title": "67¬† Disegno della ricerca e potere statistico",
    "section": "\n67.5 Riflessioni Conclusive",
    "text": "67.5 Riflessioni Conclusive\nLa determinazione della dimensione del campione √® un passaggio cruciale nella progettazione degli studi, poich√© garantisce che le inferenze siano robuste e i risultati affidabili. Questo capitolo ha mostrato come le caratteristiche dei dati, come la deviazione standard e la differenza attesa tra i gruppi, influenzino direttamente la dimensione del campione necessaria per ottenere una potenza statistica adeguata. Inoltre, l‚Äôattenzione ai dettagli, come l‚Äôuso della distribuzione t per piccoli campioni, sottolinea l‚Äôimportanza di considerare le fonti di variabilit√† e incertezza nei calcoli. Pianificare con rigore la dimensione del campione non solo aumenta la probabilit√† di rilevare effetti significativi, ma contribuisce anche a ridurre il rischio di risultati fuorvianti, migliorando cos√¨ la qualit√† complessiva della ricerca scientifica.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>¬† <span class='chapter-title'>Disegno della ricerca e potere statistico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_sample_size.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/08_sample_size.html#informazioni-sullambiente-di-sviluppo",
    "title": "67¬† Disegno della ricerca e potere statistico",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pointblank_0.12.2 haven_2.5.4       labelled_2.14.0   mice_3.17.0      \n#&gt;  [5] thematic_0.1.6    MetBrewer_0.2.0   ggokabeito_0.1.0  see_0.11.0       \n#&gt;  [9] gridExtra_2.3     patchwork_1.3.0   bayesplot_1.11.1  psych_2.5.3      \n#&gt; [13] scales_1.3.0      markdown_2.0      knitr_1.50        lubridate_1.9.4  \n#&gt; [17] forcats_1.0.0     stringr_1.5.1     dplyr_1.1.4       purrr_1.0.4      \n#&gt; [21] readr_2.1.5       tidyr_1.3.1       tibble_3.2.1      ggplot2_3.5.1    \n#&gt; [25] tidyverse_2.0.0   rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1  farver_2.1.2      fastmap_1.2.0     pacman_0.5.1     \n#&gt;  [5] digest_0.6.37     rpart_4.1.24      timechange_0.3.0  lifecycle_1.0.4  \n#&gt;  [9] survival_3.8-3    magrittr_2.0.3    compiler_4.4.2    rlang_1.1.5      \n#&gt; [13] tools_4.4.2       htmlwidgets_1.6.4 mnormt_2.1.1      withr_3.0.2      \n#&gt; [17] nnet_7.3-20       grid_4.4.2        jomo_2.7-6        colorspace_2.1-1 \n#&gt; [21] iterators_1.0.14  MASS_7.3-65       cli_3.6.4         rmarkdown_2.29   \n#&gt; [25] reformulas_0.4.0  generics_0.1.3    rstudioapi_0.17.1 tzdb_0.5.0       \n#&gt; [29] minqa_1.2.8       splines_4.4.2     parallel_4.4.2    vctrs_0.6.5      \n#&gt; [33] boot_1.3-31       glmnet_4.1-8      Matrix_1.7-3      jsonlite_1.9.1   \n#&gt; [37] hms_1.1.3         mitml_0.4-5       foreach_1.5.2     blastula_0.3.5   \n#&gt; [41] glue_1.8.0        nloptr_2.2.1      pan_1.9           codetools_0.2-20 \n#&gt; [45] stringi_1.8.4     shape_1.4.6.1     gtable_0.3.6      lme4_1.1-36      \n#&gt; [49] munsell_0.5.1     pillar_1.10.1     htmltools_0.5.8.1 R6_2.6.1         \n#&gt; [53] Rdpack_2.6.3      rprojroot_2.0.4   evaluate_1.0.3    lattice_0.22-6   \n#&gt; [57] rbibutils_2.3     backports_1.5.0   broom_1.0.7       Rcpp_1.0.14      \n#&gt; [61] nlme_3.1-167      xfun_0.51         pkgconfig_2.0.3",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>¬† <span class='chapter-title'>Disegno della ricerca e potere statistico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_sample_size.html#bibliografia",
    "href": "chapters/linear_models/08_sample_size.html#bibliografia",
    "title": "67¬† Disegno della ricerca e potere statistico",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other stories. Cambridge University Press.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>¬† <span class='chapter-title'>Disegno della ricerca e potere statistico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_anova_1via.html",
    "href": "chapters/linear_models/09_anova_1via.html",
    "title": "68¬† ANOVA ad una via",
    "section": "",
    "text": "68.1 Preparazione del Notebook\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(cmdstanr, posterior, bayestestR, brms, emmeans)",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>¬† <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_anova_1via.html#introduzione",
    "href": "chapters/linear_models/09_anova_1via.html#introduzione",
    "title": "68¬† ANOVA ad una via",
    "section": "\n68.2 Introduzione",
    "text": "68.2 Introduzione\nNel Capitolo 66 abbiamo visto come costruire regressori fittizi (dummy) per rappresentare l‚Äôeffetto di variabili categoriche (fattori) a due livelli. Consideriamo ora il caso di un singolo fattore con pi√π di due livelli. Per esempio, nel caso di una classificazione a tre categorie, possiamo adottare il modello\n\\[\nY_i = \\alpha + \\gamma_1 D_{i1} + \\gamma_2 D_{i2} + \\varepsilon_i,\n\\tag{68.1}\\]\nutilizzando la seguente codifica per i regressori dummy:\n\\[\n\\begin{array}{c|cc}\n\\text{Gruppo} & D_1 & D_2 \\\\\n\\hline\n1 & 1 & 0 \\\\\n2 & 0 & 1 \\\\\n3 & 0 & 0\n\\end{array}\n\\tag{68.2}\\]\nL‚Äôaspettativa della variabile di risposta in ciascun gruppo (cio√® in ciascuna categoria o livello del fattore) corrisponde alla media di popolazione del gruppo, indicata con \\(\\mu_j\\) per il gruppo \\(j\\). Poich√© l‚Äôerrore \\(\\varepsilon\\) ha media zero, in base alle usuali ipotesi del modello lineare, prendendo l‚Äôaspettativa di entrambi i membri dell‚Äôequazione (8.1) si ottengono le relazioni seguenti tra le medie di gruppo e i parametri:\n\\[\n\\begin{aligned}\n\\text{Gruppo 1: } \\mu_1 &= \\alpha + \\gamma_1 \\cdot 1 + \\gamma_2 \\cdot 0 = \\alpha + \\gamma_1, \\\\\n\\text{Gruppo 2: } \\mu_2 &= \\alpha + \\gamma_1 \\cdot 0 + \\gamma_2 \\cdot 1 = \\alpha + \\gamma_2, \\\\\n\\text{Gruppo 3: } \\mu_3 &= \\alpha + \\gamma_1 \\cdot 0 + \\gamma_2 \\cdot 0 = \\alpha.\n\\end{aligned}\n\\tag{68.3}\\]\nQui troviamo tre parametri \\((\\alpha, \\gamma_1, \\gamma_2)\\) e tre medie di gruppo, per cui √® possibile risolvere in modo univoco i parametri in termini delle medie di gruppo:\n\\[\n\\alpha = \\mu_3, \\quad \\gamma_1 = \\mu_1 - \\mu_3, \\quad \\gamma_2 = \\mu_2 - \\mu_3.\n\\tag{68.4}\\]\nNon sorprende che \\(\\alpha\\) rappresenti la media della categoria di riferimento (il Gruppo 3), mentre \\(\\gamma_1\\) e \\(\\gamma_2\\) descrivono quanto le altre due medie di gruppo si discostino dalla media della categoria di riferimento.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>¬† <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_anova_1via.html#simulazione",
    "href": "chapters/linear_models/09_anova_1via.html#simulazione",
    "title": "68¬† ANOVA ad una via",
    "section": "\n68.3 Simulazione",
    "text": "68.3 Simulazione\nPer esaminare un‚Äôapplicazione pratica, simuliamo i dati di un fattore con 3 livelli:\n\n# Imposta un seme per riproducibilit√† (opzionale)\nset.seed(123)\n\n# Definiamo il numero di osservazioni per ogni gruppo\nn &lt;- 30\n\n# Definiamo le medie\nmean_control &lt;- 30\nmean_psico1  &lt;- 25\nmean_psico2  &lt;- 20\n\n# Definiamo la deviazione standard (ipotizziamo la stessa per tutti i gruppi)\nsd_value &lt;- 5\n\n# Generiamo i dati casuali da distribuzioni normali\ncontrollo     &lt;- rnorm(n, mean_control, sd_value)\npsicoterapia1 &lt;- rnorm(n, mean_psico1,  sd_value)\npsicoterapia2 &lt;- rnorm(n, mean_psico2,  sd_value)\n\n# Creiamo un data frame con due colonne:\n# - \"condizione\": indica il gruppo (controllo / psicoterapia1 / psicoterapia2)\n# - \"punteggio\":  contiene i dati numerici generati\ndf &lt;- data.frame(\n  condizione = rep(c(\"controllo\", \"psicoterapia1\", \"psicoterapia2\"), each = n),\n  punteggio  = c(controllo, psicoterapia1, psicoterapia2)\n)\n\n\nhead(df)\n#&gt;   condizione punteggio\n#&gt; 1  controllo     27.20\n#&gt; 2  controllo     28.85\n#&gt; 3  controllo     37.79\n#&gt; 4  controllo     30.35\n#&gt; 5  controllo     30.65\n#&gt; 6  controllo     38.58\n\n\ntail(df)\n#&gt;       condizione punteggio\n#&gt; 85 psicoterapia2     18.90\n#&gt; 86 psicoterapia2     21.66\n#&gt; 87 psicoterapia2     25.48\n#&gt; 88 psicoterapia2     22.18\n#&gt; 89 psicoterapia2     18.37\n#&gt; 90 psicoterapia2     25.74\n\nEsaminiamo la distribuzione dei dati nei tre gruppi:\n\nggplot(df, aes(x = condizione, y = punteggio, fill = condizione)) +\n  # Il violin plot\n  geom_violin(trim = FALSE) +\n  # Boxplot interno al violino\n  geom_boxplot(width = 0.2, outlier.shape = NA) +\n  labs(\n    title = \"Depressione in funzione del gruppo\",\n    x = \"Gruppo\",\n    y = \"Depressione\"\n  ) +\n  # Rimuovi la legenda \n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\nCalcoliamo le medie dei gruppi:\n\ndf |&gt; \n  group_by(condizione) |&gt; \n  summarize(\n    avg = mean(punteggio),\n    std = sd(punteggio)\n  )\n#&gt; # A tibble: 3 √ó 3\n#&gt;   condizione      avg   std\n#&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 controllo      29.8  4.91\n#&gt; 2 psicoterapia1  25.9  4.18\n#&gt; 3 psicoterapia2  20.1  4.35\n\nNel caso presente, desideriamo creare due variabili dummy per codificare il fattore \\(`condizione`\\), assumendo come gruppo di riferimento (baseline) la categoria controllo. Ecco come procedere:\n\ndf$condizione &lt;- factor(df$condizione)\ndf$condizione &lt;- relevel(df$condizione, ref = \"controllo\")\ncontrasts(df$condizione)\n#&gt;               psicoterapia1 psicoterapia2\n#&gt; controllo                 0             0\n#&gt; psicoterapia1             1             0\n#&gt; psicoterapia2             0             1\n\nCon questa impostazione, il modello di regressione assume la forma:\n\\[\nY_i = \\beta_0 \\;+\\; \\beta_1 \\,(\\text{psicoterapia1}_i) \\;+\\; \\beta_2 \\,(\\text{psicoterapia2}_i) \\;+\\; \\varepsilon_i,\n\\]\ndove:\n\n\n\\(\\beta_0\\) (l‚Äôintercetta) rappresenta la media della condizione di controllo.\n\n\n\\(\\beta_1\\) indica la differenza tra la media del gruppo psicoterapia1 e la media del gruppo controllo.\n\n\n\\(\\beta_2\\) indica la differenza tra la media del gruppo psicoterapia2 e la media del gruppo controllo.\n\nLe variabili \\(\\text{psicoterapia1}_i\\) e \\(\\text{psicoterapia2}_i\\) sono i regressori dummy (0/1) che R crea per i due gruppi di psicoterapia, mentre \\(\\varepsilon_i\\) √® il termine di errore.\nIn particolare, nei vari gruppi:\n\nGruppo di controllo: \\(\\text{psicoterapia1}_i = 0\\) e \\(\\text{psicoterapia2}_i = 0\\).\\[\nE[Y_{\\text{controllo}}] = \\beta_0.\n\\]\nGruppo psicoterapia1: \\(\\text{psicoterapia1}_i = 1\\) e \\(\\text{psicoterapia2}_i = 0\\).\\[\nE[Y_{\\text{psicoterapia1}}] = \\beta_0 + \\beta_1.\n\\]\nGruppo psicoterapia2: \\(\\text{psicoterapia1}_i = 0\\) e \\(\\text{psicoterapia2}_i = 1\\).\\[\nE[Y_{\\text{psicoterapia2}}] = \\beta_0 + \\beta_2.\n\\]\n\nIn altre parole, \\(\\beta_1\\) e \\(\\beta_2\\) misurano rispettivamente di quanto la media di psicoterapia1 e di psicoterapia2 si discostino dalla media del gruppo di riferimento (controllo).\n\n\n68.3.1 Stima del modello e interpretazione dei coefficienti\nPer verificare quanto detto, stimiamo il modello di regressione con l‚Äôapproccio frequentista:\n\nfm1 &lt;- lm(punteggio ~ condizione, data = df)\nsummary(fm1)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = punteggio ~ condizione, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -11.668  -2.620  -0.183   2.681  10.128 \n#&gt; \n#&gt; Coefficients:\n#&gt;                         Estimate Std. Error t value Pr(&gt;|t|)\n#&gt; (Intercept)               29.764      0.819   36.33  &lt; 2e-16\n#&gt; condizionepsicoterapia1   -3.873      1.159   -3.34   0.0012\n#&gt; condizionepsicoterapia2   -9.642      1.159   -8.32  1.1e-12\n#&gt; \n#&gt; Residual standard error: 4.49 on 87 degrees of freedom\n#&gt; Multiple R-squared:  0.446,  Adjusted R-squared:  0.434 \n#&gt; F-statistic: 35.1 on 2 and 87 DF,  p-value: 6.75e-12\n\nPossiamo anche calcolare le medie empiriche di ciascun gruppo:\n\nout &lt;- tapply(df$punteggio, df$condizione, mean)\nout\n#&gt;     controllo psicoterapia1 psicoterapia2 \n#&gt;         29.76         25.89         20.12\n\ne quindi le differenze rispetto al controllo:\n\nout[2] - out[1]  # Differenza psico1 - controllo\n#&gt; psicoterapia1 \n#&gt;        -3.873\nout[3] - out[1]  # Differenza psico2 - controllo\n#&gt; psicoterapia2 \n#&gt;        -9.642\n\nLe stime dei coefficienti ottenute da summary(fm1) coincideranno con queste differenze (a meno di arrotondamenti). In altre parole, l‚Äôinferenza (frequentista o bayesiana) sul coefficiente \\(\\beta_j\\) corrisponde all‚Äôinferenza su tale scostamento tra medie.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>¬† <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_anova_1via.html#contrasti-personalizzati",
    "href": "chapters/linear_models/09_anova_1via.html#contrasti-personalizzati",
    "title": "68¬† ANOVA ad una via",
    "section": "\n68.4 Contrasti personalizzati",
    "text": "68.4 Contrasti personalizzati\nQuando abbiamo un fattore con tre livelli ‚Äî ad esempio, controllo, psicoterapia1 e psicoterapia2 ‚Äî esistono vari schemi di codifica per le variabili dummy. Scegliere lo schema di codifica adeguato significa decidere come interpretare i coefficienti del modello. Per esempio, se vogliamo rispondere alla domanda ¬´la media congiunta delle due psicoterapie √® minore (o maggiore) della media del controllo?¬ª, possiamo definire un contrasto lineare ad hoc che confronti il gruppo controllo con la media delle due psicoterapie.\n\n68.4.1 Possibili approcci\n\n\nCreare un contrasto lineare ad hoc che confronti \\(\\{\\text{psicoterapia1}, \\text{psicoterapia2}\\}\\) con controllo.\n\n\nRaggruppare i due livelli di psicoterapia in un nuovo fattore binario (controllo vs.¬†psicoterapia) e condurre un test su questo fattore a due livelli (ma in questo modo si perderebbe la distinzione tra ‚Äúpsicoterapia1‚Äù e ‚Äúpsicoterapia2‚Äù).\n\nIl metodo pi√π flessibile √® definire direttamente contrasti personalizzati sul fattore a tre livelli. In tal modo, possiamo gestire contemporaneamente pi√π confronti, ad esempio:\n\n\nContrasto 1: controllo vs.¬†media (psicoterapia1, psicoterapia2)\n\n\nContrasto 2: psicoterapia1 vs.¬†psicoterapia2\n\n\n\n68.4.2 Contrasti personalizzati in R\nObiettivo: definire due contrasti ortogonali per confrontare (1) il gruppo di controllo con la media delle due psicoterapie e (2) psicoterapia1 con psicoterapia2.\n\n68.4.3 Contrasto 1: Controllo vs.¬†(psico1 + psico2)\n\n\nContrasto ‚Äúgrezzo‚Äù (non normalizzato):\n\\[\n  (-2,\\; +1,\\; +1)\n  \\quad \\text{con} \\quad -2 + 1 + 1 = 0.\n\\]\nSe usassimo questi pesi direttamente, il coefficiente stimato \\(\\beta_1\\) sarebbe proporzionale alla differenza tra la media del controllo e la media delle due psicoterapie. Tuttavia, il passo da controllo (\\(-2\\)) a ciascuna psicoterapia (\\(+1\\)) √® di 3 unit√†, il che pu√≤ rendere il coefficiente meno intuitivo da leggere.\n\nNormalizzazione\nPossiamo dividere ogni valore di \\((-2, +1, +1)\\) per la somma assoluta (o per la radice della somma dei quadrati, o per un altro fattore) al fine di ottenere contrasti pi√π semplici.\nAd esempio, se dividiamo \\((-2, +1, +1)\\) per 3, otteniamo \\(\\bigl(-\\tfrac{2}{3}, +\\tfrac{1}{3}, +\\tfrac{1}{3}\\bigr)\\). In tal caso, passare da controllo a psicoterapia fa variare il contrasto di 1 (anzich√© di 3).\n\n68.4.4 Contrasto 2: psico1 vs.¬†psico2\n\n\nContrasto ‚Äúgrezzo‚Äù:\n\\[\n   (\\,0,\\; +1,\\; -1\\,)\n   \\quad \\text{con} \\quad 0 + 1 + (-1) = 0.\n\\]\nQuesto pesi confrontano direttamente psicoterapia1 con psicoterapia2.\n\nNormalizzazione (opzionale)\nPossiamo anche qui dividere per la radice della somma dei quadrati \\(\\sqrt{(0^2 + 1^2 + (-1)^2)}= \\sqrt{2}\\), oppure lasciare i pesi cos√¨ (poich√© qui gi√† passare da p1 a p2 equivale a 2 unit√†, e potrebbe essere chiaro abbastanza).\n\nNel codice seguente, si √® scelto di riscalare (o ‚Äúnormalizzare‚Äù) i pesi in modo leggermente diverso, ottenendo numeri come 0.6667 e -0.3333. L‚Äôimportante √® che:\n\nLa somma dei pesi in ciascun contrasto rimanga 0.\n\nI due contrasti siano ortogonali (i prodotti incrociati dei pesi per ogni livello sommano a 0).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>¬† <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_anova_1via.html#codice-r-per-impostare-e-verificare-i-contrasti",
    "href": "chapters/linear_models/09_anova_1via.html#codice-r-per-impostare-e-verificare-i-contrasti",
    "title": "68¬† ANOVA ad una via",
    "section": "\n68.5 Codice R per impostare e verificare i Contrasti",
    "text": "68.5 Codice R per impostare e verificare i Contrasti\nDi seguito mostriamo un esempio concreto. Prima descriviamo la matrice di contrasti ‚Äúgrezza‚Äù e poi quella normalizzata usata nel codice.\n\n68.5.1 Matrice di contrasti ‚Äúgrezza‚Äù\n\n# Contrasto 1 (grezzo):  -2, +1, +1\n# Contrasto 2 (grezzo):   0, +1, -1\n\nmy_contrasts_raw &lt;- matrix(c(\n  -2,  0,  # controllo\n   1, +1,  # psicoterapia1\n   1, -1   # psicoterapia2\n), ncol = 2, byrow = TRUE)\n\ncolnames(my_contrasts_raw) &lt;- c(\"Ctrl_vs_PsicoMean\", \"P1_vs_P2\")\nrownames(my_contrasts_raw) &lt;- c(\"controllo\",\"psicoterapia1\",\"psicoterapia2\")\nmy_contrasts_raw\n#&gt;               Ctrl_vs_PsicoMean P1_vs_P2\n#&gt; controllo                    -2        0\n#&gt; psicoterapia1                 1        1\n#&gt; psicoterapia2                 1       -1\n\n\n68.5.2 Matrice di contrasti ‚Äúnormalizzata‚Äù (quella effettivamente nel codice)\nNel codice che segue, i pesi sono stati riscalati per avere differenze di ‚Äú1‚Äù anzich√© ‚Äú3‚Äù o ‚Äú2‚Äù quando si passa da un gruppo all‚Äôaltro. Puoi notare, per il primo contrasto, i valori \\((+0.6667, -0.3333, -0.3333)\\) invece di \\((+1, -0.5, -0.5)\\) o \\((-2, +1, +1)\\). Sono solo versioni multiplicativamente equivalenti.\n\nset.seed(123)\n\n# Esempio: definizione della matrice di contrasti\nmy_contrasts &lt;- matrix(c(\n  0.6667,  0,    # controllo  = +0.6667\n  -0.3333, 0.5,  # p1         = -0.3333\n  -0.3333, -0.5  # p2         = -0.3333\n), ncol = 2, byrow = TRUE)\n\ncolnames(my_contrasts) &lt;- c(\"Ctrl_vs_PsicoMean\", \"P1_vs_P2\")\nrownames(my_contrasts) &lt;- c(\"controllo\", \"psicoterapia1\", \"psicoterapia2\")\n\n# Verifica: ogni colonna deve sommare a 0\ncolSums(my_contrasts)  # dovrebbero essere circa (0, 0)\n#&gt; Ctrl_vs_PsicoMean          P1_vs_P2 \n#&gt;            0.0001            0.0000\n\n# Verifica: i due contrasti sono ortogonali?\nsum(my_contrasts[,1] * my_contrasts[,2])  # dovrebbe essere 0\n#&gt; [1] 0\n\n\n68.5.3 Applicazione al modello\n\n# 1) Convertiamo 'condizione' in fattore (se non gi√† fattore)\ndf$condizione &lt;- factor(df$condizione)\n\n# 2) Assegnamo la matrice di contrasti al fattore\ncontrasts(df$condizione) &lt;- my_contrasts\n\n# 3) Stimiamo il modello di regressione lineare\nmod_custom &lt;- lm(punteggio ~ condizione, data = df)\n\n# 4) Esaminiamo il riepilogo\nsummary(mod_custom)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = punteggio ~ condizione, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -11.668  -2.620  -0.183   2.681  10.128 \n#&gt; \n#&gt; Coefficients:\n#&gt;                             Estimate Std. Error t value Pr(&gt;|t|)\n#&gt; (Intercept)                   25.259      0.473   53.40  &lt; 2e-16\n#&gt; condizioneCtrl_vs_PsicoMean    6.758      1.003    6.73  1.7e-09\n#&gt; condizioneP1_vs_P2             5.770      1.159    4.98  3.2e-06\n#&gt; \n#&gt; Residual standard error: 4.49 on 87 degrees of freedom\n#&gt; Multiple R-squared:  0.446,  Adjusted R-squared:  0.434 \n#&gt; F-statistic: 35.1 on 2 and 87 DF,  p-value: 6.75e-12",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>¬† <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_anova_1via.html#interpretazione-dei-coefficienti",
    "href": "chapters/linear_models/09_anova_1via.html#interpretazione-dei-coefficienti",
    "title": "68¬† ANOVA ad una via",
    "section": "\n68.6 Interpretazione dei coefficienti",
    "text": "68.6 Interpretazione dei coefficienti\n\nIntercetta (\\(\\hat{\\alpha}\\))\nIn base allo schema di contrasti adottato, pu√≤ non coincidere con la media effettiva di uno dei tre gruppi. Spesso rappresenta una qualche combinazione lineare delle medie di controllo, psicoterapia1 e psicoterapia2.\n\nPrimo coefficiente (‚ÄúCtrl_vs_PsicoMean‚Äù)\nConfronta la media del gruppo di controllo con la media (eventualmente pesata) delle due psicoterapie.\n\nSe √® positivo, il controllo ha una media maggiore rispetto a quella (combinata) delle psicoterapie.\n\nSe √® negativo, indica il contrario (psicoterapie &gt; controllo).\n\n\n\nSecondo coefficiente (‚ÄúP1_vs_P2‚Äù)\nConfronta direttamente psicoterapia1 con psicoterapia2.\n\nSe √® positivo, psicoterapia1 ha un punteggio maggiore (in media) di psicoterapia2.\n\nSe √® negativo, psicoterapia2 supera psicoterapia1.\n\n\n\nPer controllare manualmente queste differenze, puoi calcolare:\n\n\n\\(\\text{controllo} - \\frac{\\text{psicoterapia1} + \\text{psicoterapia2}}{2}\\):\n\n\nout[1] - (out[2] + out[3]) / 2\n#&gt; controllo \n#&gt;     6.758\n\ndove out[i] √® la media empirica del gruppo \\(i\\).\n\n\n\\(\\text{psicoterapia1} - \\text{psicoterapia2}\\):\n\n\nout[2] - out[3]\n#&gt; psicoterapia1 \n#&gt;          5.77\n\nIn sintesi,\n\nLa matrice grezza \\(\\begin{pmatrix} -2 & 0 \\\\ 1 & 1 \\\\ 1 & -1 \\end{pmatrix}\\) e la matrice normalizzata (con valori decimali) rappresentano lo stesso schema di contrasti, ma con differenti scale numeriche.\n\nL‚Äôaspetto essenziale √® che ciascun contrasto sommi a 0 e che i due contrasti siano ortogonali (prodotto incrociato dei pesi = 0), garantendo interpretazioni indipendenti.\n\nNormalizzare i pesi modifica il valore numerico dei coefficienti, ma non la loro significativit√† statistica.\n\nScegliendo opportunamente la matrice dei contrasti, possiamo verificare se la media congiunta di psicoterapia1 e psicoterapia2 differisce da quella di controllo e, contemporaneamente, se psicoterapia1 differisce da psicoterapia2. L‚Äôeventuale normalizzazione dei pesi non incide sulle conclusioni del test, ma influenza la scala numerica dei coefficienti.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>¬† <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_anova_1via.html#pacchetto-emmeans",
    "href": "chapters/linear_models/09_anova_1via.html#pacchetto-emmeans",
    "title": "68¬† ANOVA ad una via",
    "section": "\n68.7 Pacchetto emmeans\n",
    "text": "68.7 Pacchetto emmeans\n\nLe stesse analisi descritte sopra possono essere svolte utilizzando le funzioni del pacchetto emmeans. L‚Äôidea √®:\n\nStimare un modello lineare (come prima).\n\nCalcolare le stime delle medie marginali (le ‚Äúmeans‚Äù del fattore condizione) tramite emmeans().\n\nDefinire i contrasti di interesse con la funzione contrast().\n\nIn questo modo, √® possibile ottenere stime delle medie di ciascun gruppo e confrontarle (ad esempio ‚Äúcontrollo‚Äù vs.¬†‚Äúmedia delle psicoterapie‚Äù o ‚Äúpsicoterapia1‚Äù vs.¬†‚Äúpsicoterapia2‚Äù), anche in forma di test statistici (p-value, intervalli di confidenza, ecc.).\n\n68.7.1 Preparazione del modello\nUsiamo ora un modello bayesiano, con prior non informativi o debolmente informativi:\n\nmod &lt;- brm(punteggio ~ condizione, data = df, backend = \"cmdstanr\")\n\n\nsummary(mod)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: punteggio ~ condizione \n#&gt;    Data: df (Number of observations: 90) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;                             Estimate Est.Error l-95% CI u-95% CI Rhat\n#&gt; Intercept                      25.25      0.48    24.30    26.21 1.00\n#&gt; condizioneCtrl_vs_PsicoMean     6.77      1.02     4.79     8.77 1.00\n#&gt; condizioneP1_vs_P2              5.73      1.20     3.34     8.03 1.00\n#&gt;                             Bulk_ESS Tail_ESS\n#&gt; Intercept                       4391     3161\n#&gt; condizioneCtrl_vs_PsicoMean     4794     3220\n#&gt; condizioneP1_vs_P2              4632     2764\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     4.54      0.35     3.93     5.30 1.00     4090     2859\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n68.7.2 Calcolo delle medie marginali con emmeans\n\nCalcoliamo le stime delle medie (ls-means) per ciascun livello di ‚Äòcondizione‚Äô:\n\nem &lt;- emmeans(mod, specs = \"condizione\")\nem\n#&gt;  condizione    emmean lower.HPD upper.HPD\n#&gt;  controllo       29.8      28.3      31.5\n#&gt;  psicoterapia1   25.9      24.3      27.6\n#&gt;  psicoterapia2   20.1      18.4      21.8\n#&gt; \n#&gt; Point estimate displayed: median \n#&gt; HPD interval probability: 0.95\n\nQuesto oggetto em contiene le medie stimate (e i relativi errori standard) per i tre gruppi: ‚Äúcontrollo‚Äù, ‚Äúpsicoterapia1‚Äù e ‚Äúpsicoterapia2‚Äù.\n\n68.7.3 Confronti (pairwise) tra i gruppi\nConfronti a coppie tra tutti i livelli di ‚Äòcondizione‚Äô (psicoterapia1 vs controllo, ecc.):\n\npairs(em)\n#&gt;  contrast                      estimate lower.HPD upper.HPD\n#&gt;  controllo - psicoterapia1         3.91      1.62      6.21\n#&gt;  controllo - psicoterapia2         9.64      7.24     11.94\n#&gt;  psicoterapia1 - psicoterapia2     5.74      3.30      7.96\n#&gt; \n#&gt; Point estimate displayed: median \n#&gt; HPD interval probability: 0.95\n\n\n68.7.4 Contrasti personalizzati\nReplichiamo i contrasti ‚Äúad hoc‚Äù (‚Äúcontrollo vs (psico1+psico2)‚Äù e ‚Äúpsicoterapia1 vs psicoterapia2‚Äù) utilizzati in precedenza:\n\n# Definiamo i contrasti desiderati\nmy_list &lt;- list(\n  \"Ctrl_vs_PsicoMean\" = \n    c(\"controllo\" = 1, \"psicoterapia1\" = -0.5, \"psicoterapia2\" = -0.5),\n  \"P1_vs_P2\"          = \n    c(\"controllo\" = 0,  \"psicoterapia1\" = 1,    \"psicoterapia2\" = -1)\n)\n\ncontrast(em, method = my_list)\n#&gt;  contrast          estimate lower.HPD upper.HPD\n#&gt;  Ctrl_vs_PsicoMean     6.76      4.78      8.74\n#&gt;  P1_vs_P2              5.74      3.30      7.96\n#&gt; \n#&gt; Point estimate displayed: median \n#&gt; HPD interval probability: 0.95",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>¬† <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_anova_1via.html#altre-opzioni-utili-di-emmeans",
    "href": "chapters/linear_models/09_anova_1via.html#altre-opzioni-utili-di-emmeans",
    "title": "68¬† ANOVA ad una via",
    "section": "\n68.8 Altre opzioni utili di emmeans\n",
    "text": "68.8 Altre opzioni utili di emmeans\n\n\n\nCredibility intervals:\n\n\nconfint( contrast(em, method = my_list) )\n#&gt;  contrast          estimate lower.HPD upper.HPD\n#&gt;  Ctrl_vs_PsicoMean     6.76      4.78      8.74\n#&gt;  P1_vs_P2              5.74      3.30      7.96\n#&gt; \n#&gt; Point estimate displayed: median \n#&gt; HPD interval probability: 0.95\n\nper intervalli di confidenza dei contrasti specificati.\n\n\nTest corretti per confronti multipli:\n\n\ncontrast(em, method = my_list, adjust = \"bonferroni\")\n#&gt;  contrast          estimate lower.HPD upper.HPD\n#&gt;  Ctrl_vs_PsicoMean     6.76      4.78      8.74\n#&gt;  P1_vs_P2              5.74      3.30      7.96\n#&gt; \n#&gt; Point estimate displayed: median \n#&gt; HPD interval probability: 0.95\n\no altre correzioni (ad es. \"holm\", \"sidak\", \"none\").\n\n\nVisualizzazione:\nIl pacchetto emmeans ha anche funzioni per la visualizzazione (plot(em), pwpp(), ecc.).\n\n\n\nplot(em)\n\n\n\n\n\n\n\nIn conclusione, usare emmeans semplifica notevolmente:\n\n\nIl calcolo delle medie stimate (o ‚Äúls-means‚Äù) di ciascun livello di un fattore in un modello lineare (o GLM, o mixed model, ecc.).\n\n\nLa definizione di contrasti personalizzati, senza dover ridefinire manualmente la matrice di contrasti nel modello (come si fa con contrasts(fattore) &lt;- ...).\n\n\nLa produzione di test e intervalli di confidenza per i confronti desiderati, integrando anche correzioni per confronti multipli se necessario.\n\nIn questo modo, √® possibile ottenere esattamente gli stessi risultati che otterresti impostando manualmente i contrasti a livello di design matrix, ma con un approccio pi√π flessibile e con meno passaggi.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>¬† <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_anova_1via.html#riflessioni-conclusive",
    "href": "chapters/linear_models/09_anova_1via.html#riflessioni-conclusive",
    "title": "68¬† ANOVA ad una via",
    "section": "\n68.9 Riflessioni Conclusive",
    "text": "68.9 Riflessioni Conclusive\nL‚ÄôANOVA ad una via non √® altro che l‚Äôapplicazione del modello di regressione al caso di una variabile dipendente quantitativa e di un fattore con pi√π di due livelli. L‚Äôaspetto pi√π utile dell‚ÄôANOVA riguarda i contrasti, ovvero specifiche ipotesi sulla differenza tra le medie.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>¬† <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_anova_1via.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/09_anova_1via.html#informazioni-sullambiente-di-sviluppo",
    "title": "68¬† ANOVA ad una via",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] rstan_2.32.7        StanHeaders_2.32.10 emmeans_1.11.0     \n#&gt;  [4] brms_2.22.0         Rcpp_1.0.14         bayestestR_0.15.2  \n#&gt;  [7] posterior_1.6.1     cmdstanr_0.8.1      thematic_0.1.6     \n#&gt; [10] MetBrewer_0.2.0     ggokabeito_0.1.0    see_0.11.0         \n#&gt; [13] gridExtra_2.3       patchwork_1.3.0     bayesplot_1.11.1   \n#&gt; [16] psych_2.5.3         scales_1.3.0        markdown_2.0       \n#&gt; [19] knitr_1.50          lubridate_1.9.4     forcats_1.0.0      \n#&gt; [22] stringr_1.5.1       dplyr_1.1.4         purrr_1.0.4        \n#&gt; [25] readr_2.1.5         tidyr_1.3.1         tibble_3.2.1       \n#&gt; [28] ggplot2_3.5.1       tidyverse_2.0.0     rio_1.2.3          \n#&gt; [31] here_1.0.1         \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1     farver_2.1.2         loo_2.8.0           \n#&gt;  [4] fastmap_1.2.0        TH.data_1.1-3        tensorA_0.36.2.1    \n#&gt;  [7] pacman_0.5.1         digest_0.6.37        timechange_0.3.0    \n#&gt; [10] estimability_1.5.1   lifecycle_1.0.4      survival_3.8-3      \n#&gt; [13] processx_3.8.6       magrittr_2.0.3       compiler_4.4.2      \n#&gt; [16] rlang_1.1.5          tools_4.4.2          utf8_1.2.4          \n#&gt; [19] yaml_2.3.10          data.table_1.17.0    labeling_0.4.3      \n#&gt; [22] bridgesampling_1.1-2 htmlwidgets_1.6.4    curl_6.2.2          \n#&gt; [25] pkgbuild_1.4.7       mnormt_2.1.1         plyr_1.8.9          \n#&gt; [28] abind_1.4-8          multcomp_1.4-28      withr_3.0.2         \n#&gt; [31] stats4_4.4.2         grid_4.4.2           inline_0.3.21       \n#&gt; [34] xtable_1.8-4         colorspace_2.1-1     MASS_7.3-65         \n#&gt; [37] insight_1.1.0        cli_3.6.4            mvtnorm_1.3-3       \n#&gt; [40] rmarkdown_2.29       generics_0.1.3       RcppParallel_5.1.10 \n#&gt; [43] rstudioapi_0.17.1    reshape2_1.4.4       tzdb_0.5.0          \n#&gt; [46] splines_4.4.2        parallel_4.4.2       matrixStats_1.5.0   \n#&gt; [49] vctrs_0.6.5          V8_6.0.2             Matrix_1.7-3        \n#&gt; [52] sandwich_3.1-1       jsonlite_1.9.1       hms_1.1.3           \n#&gt; [55] glue_1.8.0           codetools_0.2-20     ps_1.9.0            \n#&gt; [58] distributional_0.5.0 stringi_1.8.4        gtable_0.3.6        \n#&gt; [61] QuickJSR_1.6.0       munsell_0.5.1        pillar_1.10.1       \n#&gt; [64] htmltools_0.5.8.1    Brobdingnag_1.2-9    R6_2.6.1            \n#&gt; [67] rprojroot_2.0.4      evaluate_1.0.3       lattice_0.22-6      \n#&gt; [70] backports_1.5.0      rstantools_2.4.0     coda_0.19-4.1       \n#&gt; [73] nlme_3.1-167         checkmate_2.3.2      xfun_0.51           \n#&gt; [76] zoo_1.8-13           pkgconfig_2.0.3",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>¬† <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_anova_1via.html#bibliografia",
    "href": "chapters/linear_models/09_anova_1via.html#bibliografia",
    "title": "68¬† ANOVA ad una via",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>¬† <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_2vie.html",
    "href": "chapters/linear_models/10_anova_2vie.html",
    "title": "69¬† ANOVA ad due vie",
    "section": "",
    "text": "69.1 Introduzione\nL‚ÄôANOVA a due o pi√π vie estende il caso dell‚ÄôANOVA ad una via alla presenza di molteplici criteri di classificazione. Qui ci concentreremo sull‚ÄôANOVA a due vie.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>69</span>¬† <span class='chapter-title'>ANOVA ad due vie</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_2vie.html#introduzione",
    "href": "chapters/linear_models/10_anova_2vie.html#introduzione",
    "title": "69¬† ANOVA ad due vie",
    "section": "",
    "text": "69.1.1 Pattern delle medie nella classificazione a due vie\nImmaginiamo di disporre delle medie di popolazione. La notazione per la classificazione a due vie √® illustrata nella seguente tabella:\n\n\n\nC1\nC2\n‚Ä¶\nCc\nTotale colonna\n\n\n\nR1\n¬µ11\n¬µ12\n‚Ä¶\n¬µ1c\n¬µ1:\n\n\nR2\n¬µ21\n¬µ22\n‚Ä¶\n¬µ2c\n¬µ2:\n\n\n‚Ä¶\n‚Ä¶\n‚Ä¶\n‚Ä¶\n‚Ä¶\n‚Ä¶\n\n\nRr\n¬µr1\n¬µr2\n‚Ä¶\n¬µrc\n¬µr:\n\n\n‚Äî‚Äî‚Äî‚Äî\n‚Äî‚Äî-\n‚Äî‚Äî-\n‚Äî‚Äî\n‚Äî‚Äî-\n‚Äî‚Äî‚Äî‚Äî‚Äî-\n\n\nTotale riga\n¬µ:1\n¬µ:2\n‚Ä¶\n¬µ:c\n¬µ::\n\n\n\nQui, i fattori \\(R\\) e \\(C\\) (cos√¨ denominati in riferimento alle righe e alle colonne della tabella delle medie) presentano rispettivamente \\(r\\) e \\(c\\) categorie. Indichiamo le categorie dei fattori come \\(R_j\\) e \\(C_k\\).\nAll‚Äôinterno di ogni cella del disegno sperimentale‚Äîcio√® per ciascuna combinazione di categorie \\(\\{R_j, C_k\\}\\) dei due fattori‚Äîsi trova una media di popolazione \\(\\mu_{jk}\\) relativa alla variabile di risposta.\nPer descrivere le medie su righe, colonne e quella complessiva, utilizziamo la notazione a ‚Äúpunti‚Äù:\n\\[\n\\mu_{j:} \\;=\\; \\frac{\\sum_{k=1}^{c} \\mu_{jk}}{c}\n\\quad\\text{(media marginale sulla riga $j$)},\n\\]\n\\[\n\\mu_{:k} \\;=\\; \\frac{\\sum_{j=1}^{r} \\mu_{jk}}{r}\n\\quad\\text{(media marginale sulla colonna $k$)},\n\\]\n\\[\n\\mu_{::} \\;=\\; \\frac{\\sum_{j=1}^{r}\\sum_{k=1}^{c} \\mu_{jk}}{r\\,c}\n\\;=\\; \\frac{\\sum_{j=1}^{r} \\mu_{j:}}{r}\n\\;=\\; \\frac{\\sum_{k=1}^{c} \\mu_{:k}}{c}\n\\quad\\text{(media generale, o grand mean)}.\n\\]\n\n69.1.2 Effetti principali e interazione\nSe i fattori \\(R\\) e \\(C\\) non interagiscono nel determinare la variabile di risposta, allora l‚Äôeffetto di uno di essi, a parit√† di categoria dell‚Äôaltro, rimane costante. In termini pratici, la differenza fra le medie di cella \\(\\mu_{jk} - \\mu_{j'k}\\)‚Äîquando confrontiamo due categorie di \\(R\\), ad esempio \\(R_j\\) e \\(R_{j'}\\)‚Äî√® la stessa per tutte le categorie di \\(C\\) (cio√® per \\(k = 1, 2, \\dots, c\\)).\nDi conseguenza, la differenza fra le medie nelle righe √® uguale alla differenza fra le corrispondenti medie marginali di riga:\n\\[\n\\mu_{jk} - \\mu_{j'k} \\;=\\; \\mu_{jk'} - \\mu_{j'k'} \\;=\\; \\mu_{j:} - \\mu_{j':}\n\\quad\\text{per ogni } j, j' \\text{ e } k, k'.\n\\]\nUn altro modo di vedere questa assenza di interazione √® attraverso i profili di medie di cella, che in questo caso risultano ‚Äúparalleli‚Äù. Se i profili sono paralleli, allora la differenza fra \\(\\mu_{j1}\\) e \\(\\mu_{j2}\\) (categorie \\(C_1\\) e \\(C_2\\)) resta costante fra le diverse righe \\(j = 1, 2\\), e coincide con la differenza fra le medie marginali di colonna, \\(\\mu_{:1} - \\mu_{:2}\\).\nL‚Äôinterazione √® un concetto simmetrico: se il fattore \\(R\\) interagisce con il fattore \\(C\\), vale anche il contrario. Quando non si verifica interazione, l‚Äôeffetto principale (o main effect) di ogni fattore corrisponde semplicemente alla differenza fra le medie marginali di popolazione relative a quel fattore.\nLa figura seguente presentata diversi scenari possibili.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>69</span>¬† <span class='chapter-title'>ANOVA ad due vie</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_2vie.html#simulazione",
    "href": "chapters/linear_models/10_anova_2vie.html#simulazione",
    "title": "69¬† ANOVA ad due vie",
    "section": "\n69.2 Simulazione",
    "text": "69.2 Simulazione\nPer fare un esempio concreto, simuliamo dei dati seguendo lo schema utilizzato con l‚ÄôANOVA ad una via. In questo caso, aggiungiamo un secondo fattore: la gravit√† dei sintomi.\n\n# Imposta un seme per riproducibilit√† (opzionale)\nset.seed(123)\n\n# Definiamo il numero di osservazioni per ogni cella\nn &lt;- 30\n\n# Definiamo le categorie dei fattori\ngravita &lt;- c(\"molto_gravi\", \"poco_gravi\")\ncondizione &lt;- c(\"controllo\", \"psicoterapia1\", \"psicoterapia2\")\n\n# Definiamo la deviazione standard (ipotizziamo la stessa per tutte le celle)\nsd_value &lt;- 5\n\n# Definiamo le medie attese per ciascuna combinazione (gravita x condizione)\n# Esempio:\n# - Pazienti molto gravi:  (controllo=30, psico1=25, psico2=20)\n# - Pazienti poco gravi:   (controllo=25, psico1=20, psico2=15)\n\nmean_table &lt;- matrix(\n  c(30, 25, 20,  # molto_gravi\n    25, 20, 15), # poco_gravi\n  nrow = 2,      # 2 righe per \"molto_gravi\" e \"poco_gravi\"\n  ncol = 3,      # 3 colonne per \"controllo\", \"psicoterapia1\", \"psicoterapia2\"\n  byrow = TRUE\n)\n\n# Crea un data frame vuoto che riempiremo con i dati simulati\ndf &lt;- data.frame()\n\nfor (i in seq_along(gravita)) {\n  for (j in seq_along(condizione)) {\n    # Estraiamo la media corrispondente alla combinazione (i, j)\n    current_mean &lt;- mean_table[i, j]\n    \n    # Generiamo 'n' osservazioni normali con media = current_mean e sd = sd_value\n    simulated_data &lt;- rnorm(n, mean = current_mean, sd = sd_value)\n    \n    # Creiamo un data frame temporaneo per questa combinazione\n    temp_df &lt;- data.frame(\n      gravita    = gravita[i],\n      condizione = condizione[j],\n      punteggio  = simulated_data\n    )\n    \n    # Append al data frame finale\n    df &lt;- rbind(df, temp_df)\n  }\n}\n\nEsaminiamo le medie:\n\n# Esempio di sintesi statistica\naggregate(punteggio ~ gravita + condizione, data = df, mean)\n#&gt;       gravita    condizione punteggio\n#&gt; 1 molto_gravi     controllo     29.76\n#&gt; 2  poco_gravi     controllo     24.53\n#&gt; 3 molto_gravi psicoterapia1     25.89\n#&gt; 4  poco_gravi psicoterapia1     19.08\n#&gt; 5 molto_gravi psicoterapia2     20.12\n#&gt; 6  poco_gravi psicoterapia2     15.77\n\nRappresentiamo graficamente la distribuzione dei dati nelle varie condizioni:\n\nggplot(df, aes(x = condizione, y = punteggio, fill = gravita)) +\n  geom_boxplot(position = position_dodge()) +\n  labs(title = \"Simulazione dati: Effetto gravit√† e condizione\",\n       x = \"Condizione sperimentale\",\n       y = \"Punteggio\")\n\n\n\n\n\n\n\nAddattiamo ai dati un modello bayesiano:\n\nmod &lt;- brm(\n  punteggio ~ gravita * condizione, \n  data = df,\n  backend = \"cmdstanr\"\n)\n\nEsaminiamo le stime del modello:\n\nconditional_effects(mod, \"condizione:gravita\")\n\n\n\n\n\n\n\nUn sommario delle stime a posteriori si ottiene nel modo seguente:\n\nsummary(mod)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: punteggio ~ gravita * condizione \n#&gt;    Data: df (Number of observations: 180) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;                                           Estimate Est.Error l-95% CI\n#&gt; Intercept                                    29.75      0.86    28.03\n#&gt; gravitapoco_gravi                            -5.20      1.21    -7.61\n#&gt; condizionepsicoterapia1                      -3.86      1.23    -6.24\n#&gt; condizionepsicoterapia2                      -9.61      1.23   -12.05\n#&gt; gravitapoco_gravi:condizionepsicoterapia1    -1.61      1.72    -4.99\n#&gt; gravitapoco_gravi:condizionepsicoterapia2     0.83      1.72    -2.53\n#&gt;                                           u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept                                    31.45 1.00     2133     2829\n#&gt; gravitapoco_gravi                            -2.87 1.00     1866     2352\n#&gt; condizionepsicoterapia1                      -1.36 1.00     2240     2404\n#&gt; condizionepsicoterapia2                      -7.16 1.00     2274     2624\n#&gt; gravitapoco_gravi:condizionepsicoterapia1     1.85 1.00     1924     2338\n#&gt; gravitapoco_gravi:condizionepsicoterapia2     4.23 1.00     2071     2416\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     4.79      0.25     4.33     5.32 1.00     3481     2699\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nL‚Äôesame dell‚Äôoutput precedente mostra come sia difficile rispondere alle domende di interesse mediante l‚Äôesame dei singoli coefficienti. Per valutare gli effetti principali e la presenza di interazione si usa invece un metodo basato sul confronto tra modelli.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>69</span>¬† <span class='chapter-title'>ANOVA ad due vie</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_2vie.html#confronto-tra-modelli",
    "href": "chapters/linear_models/10_anova_2vie.html#confronto-tra-modelli",
    "title": "69¬† ANOVA ad due vie",
    "section": "\n69.3 Confronto tra Modelli",
    "text": "69.3 Confronto tra Modelli\nIl test degli effetti principali e dell‚Äôinterazione viene eseguito, nell‚Äôapproccio frequentista, calcolando R^2 per i vari modelli per poi fare una differenza tra gli R^2 pesati per i gradi di libert√†. Questa differenza si distribuisce come F e quindi disponiamo di una distribuzione campionaria nota per questa statistica. Il test si fa nel solito modo, ovvero ci si chiede se la differenza in R^2 osservata √® sufficientemente piccola da potere essere attribuita al caso, sotto l‚Äôipotesi che i due modelli sono equivalenti, oppure no.\nI test bayesiani si basano su una logica diversa, anche se ha alcuni punti in comune. Il confronto tra modelli si basa su una quantit√† chiamata LOO (Leave-One-Out cross-validation).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>69</span>¬† <span class='chapter-title'>ANOVA ad due vie</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_2vie.html#cos√®-loo-leave-one-out-cross-validation",
    "href": "chapters/linear_models/10_anova_2vie.html#cos√®-loo-leave-one-out-cross-validation",
    "title": "69¬† ANOVA ad due vie",
    "section": "\n69.4 Cos‚Äô√® LOO (Leave-One-Out cross-validation)?",
    "text": "69.4 Cos‚Äô√® LOO (Leave-One-Out cross-validation)?\nLOO √® un metodo per stimare quanto bene un modello predice nuovi dati. In particolare, misura quanto il modello √® in grado di generalizzare oltre i dati usati per costruirlo.\n\nCome funziona:\nSi rimuove iterativamente una osservazione dal dataset, si stima il modello sui dati rimanenti e si valuta quanto bene il modello predice l‚Äôosservazione esclusa. Questo processo viene ripetuto per tutte le osservazioni.\nNel contesto Bayesiano:\nPoich√© ricalcolare il modello per ogni possibile sottogruppo di dati sarebbe computazionalmente oneroso, si usa una stima approssimativa di LOO basata sul concetto di PSIS-LOO (Pareto Smoothed Importance Sampling). Questa stima √® disponibile direttamente in brms tramite il comando loo().",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>69</span>¬† <span class='chapter-title'>ANOVA ad due vie</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_2vie.html#indicatori-principali-nei-risultati-di-loo",
    "href": "chapters/linear_models/10_anova_2vie.html#indicatori-principali-nei-risultati-di-loo",
    "title": "69¬† ANOVA ad due vie",
    "section": "\n69.5 Indicatori principali nei risultati di LOO\n",
    "text": "69.5 Indicatori principali nei risultati di LOO\n\n\nelpd (expected log predictive density):\n√à la somma logaritmica delle probabilit√† predittive del modello per ogni osservazione, calcolata dopo aver escluso quella stessa osservazione. Valori pi√π alti indicano un modello che predice meglio.\nelpd_diff:\nDifferenza di elpd tra due modelli. Se \\(\\text{elpd}_{\\text{model1}} &gt; \\text{elpd}_{\\text{model2}}\\), il modello 1 √® preferito.\nse_diff (standard error of difference):\nL‚Äôincertezza associata a elpd_diff. Se |elpd_diff| √® molto piccolo rispetto a se_diff, la differenza tra i modelli non √® considerata robusta.\n\n\nNel caso presente, confrontiamo due modelli:\n\n\nmod1: Modello completo (con interazione).\n\n\nmod: Modello senza interazione (solo effetti principali).\n\n\nmod1 &lt;- brm(\n  punteggio ~ gravita + condizione, \n  data = df,\n  backend = \"cmdstanr\"\n)\n\n\n69.5.1 Confronto LOO\n\n# Confronto via LOO\nloo_full &lt;- loo(mod)\nloo_noint  &lt;- loo(mod1)\nloo_compare(loo_full, loo_noint)\n#&gt;      elpd_diff se_diff\n#&gt; mod1  0.0       0.0   \n#&gt; mod  -0.7       1.5\n\n\nelpd_diff = -0.9: Il modello con interazione (mod) ha un elpd leggermente pi√π basso rispetto al modello senza interazione (mod1). Questo significa che il modello senza interazione √® leggermente preferibile in termini di capacit√† predittiva sui nuovi dati.\nse_diff = 1.5: L‚Äôincertezza associata alla differenza di elpd √® molto pi√π grande della differenza stessa (elpd_diff / se_diff). Questo implica che non c‚Äô√® evidenza sufficiente per concludere che uno dei due modelli sia chiaramente migliore.\n\nIn conclusione,\n\nIl modello senza interazione (mod1) √® leggermente preferibile in termini di LOO-IC, ma la differenza √® trascurabile e non robusta, data l‚Äôelevata incertezza (se_diff = 1.5).\n\nInterpretazione pratica:\n\nNon ci sono prove sufficienti per preferire il modello con interazione (mod) rispetto al modello senza interazione (mod1).\nIn assenza di altre considerazioni teoriche che giustifichino l‚Äôinclusione dell‚Äôinterazione, il modello pi√π semplice (mod1, senza interazione) √® probabilmente una scelta migliore.\n\n\n\nSi procede in un modo simile per i test degli effetti principali. In quel caso potremmo confrontrare un modello con gli effetti additivi dei due fattori con un modello con un unico fattore.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>69</span>¬† <span class='chapter-title'>ANOVA ad due vie</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_2vie.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/10_anova_2vie.html#informazioni-sullambiente-di-sviluppo",
    "title": "69¬† ANOVA ad due vie",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] rstan_2.32.7         StanHeaders_2.32.10  bridgesampling_1.1-2\n#&gt;  [4] loo_2.8.0            emmeans_1.11.0       brms_2.22.0         \n#&gt;  [7] Rcpp_1.0.14          bayestestR_0.15.2    posterior_1.6.1     \n#&gt; [10] cmdstanr_0.8.1       thematic_0.1.6       MetBrewer_0.2.0     \n#&gt; [13] ggokabeito_0.1.0     see_0.11.0           gridExtra_2.3       \n#&gt; [16] patchwork_1.3.0      bayesplot_1.11.1     psych_2.5.3         \n#&gt; [19] scales_1.3.0         markdown_2.0         knitr_1.50          \n#&gt; [22] lubridate_1.9.4      forcats_1.0.0        stringr_1.5.1       \n#&gt; [25] dplyr_1.1.4          purrr_1.0.4          readr_2.1.5         \n#&gt; [28] tidyr_1.3.1          tibble_3.2.1         ggplot2_3.5.1       \n#&gt; [31] tidyverse_2.0.0      rio_1.2.3            here_1.0.1          \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1     farver_2.1.2         fastmap_1.2.0       \n#&gt;  [4] TH.data_1.1-3        tensorA_0.36.2.1     pacman_0.5.1        \n#&gt;  [7] digest_0.6.37        timechange_0.3.0     estimability_1.5.1  \n#&gt; [10] lifecycle_1.0.4      survival_3.8-3       processx_3.8.6      \n#&gt; [13] magrittr_2.0.3       compiler_4.4.2       rlang_1.1.5         \n#&gt; [16] tools_4.4.2          yaml_2.3.10          data.table_1.17.0   \n#&gt; [19] labeling_0.4.3       htmlwidgets_1.6.4    curl_6.2.2          \n#&gt; [22] pkgbuild_1.4.7       mnormt_2.1.1         plyr_1.8.9          \n#&gt; [25] abind_1.4-8          multcomp_1.4-28      withr_3.0.2         \n#&gt; [28] stats4_4.4.2         grid_4.4.2           inline_0.3.21       \n#&gt; [31] xtable_1.8-4         colorspace_2.1-1     MASS_7.3-65         \n#&gt; [34] insight_1.1.0        cli_3.6.4            mvtnorm_1.3-3       \n#&gt; [37] rmarkdown_2.29       generics_0.1.3       RcppParallel_5.1.10 \n#&gt; [40] rstudioapi_0.17.1    reshape2_1.4.4       tzdb_0.5.0          \n#&gt; [43] splines_4.4.2        parallel_4.4.2       matrixStats_1.5.0   \n#&gt; [46] vctrs_0.6.5          V8_6.0.2             Matrix_1.7-3        \n#&gt; [49] sandwich_3.1-1       jsonlite_1.9.1       hms_1.1.3           \n#&gt; [52] glue_1.8.0           codetools_0.2-20     ps_1.9.0            \n#&gt; [55] distributional_0.5.0 stringi_1.8.4        gtable_0.3.6        \n#&gt; [58] QuickJSR_1.6.0       munsell_0.5.1        pillar_1.10.1       \n#&gt; [61] htmltools_0.5.8.1    Brobdingnag_1.2-9    R6_2.6.1            \n#&gt; [64] rprojroot_2.0.4      evaluate_1.0.3       lattice_0.22-6      \n#&gt; [67] backports_1.5.0      rstantools_2.4.0     coda_0.19-4.1       \n#&gt; [70] nlme_3.1-167         checkmate_2.3.2      xfun_0.51           \n#&gt; [73] zoo_1.8-13           pkgconfig_2.0.3",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>69</span>¬† <span class='chapter-title'>ANOVA ad due vie</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_2vie.html#bibliografia",
    "href": "chapters/linear_models/10_anova_2vie.html#bibliografia",
    "title": "69¬† ANOVA ad due vie",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>69</span>¬† <span class='chapter-title'>ANOVA ad due vie</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_one_proportion.html",
    "href": "chapters/linear_models/11_one_proportion.html",
    "title": "70¬† Inferenza sulle proporzioni",
    "section": "",
    "text": "70.1 Introduzione\nIn questo capitolo esploreremo come affrontare il problema dell‚Äôinferenza su una proporzione o sul confronto tra due proporzioni utilizzando un approccio bayesiano. Per tale scopo, utilizzeremo il pacchetto brms in R. L‚Äôapproccio bayesiano ci permette di ottenere una distribuzione completa della probabilit√† a posteriori del parametro di interesse, offrendo una visione pi√π ricca e flessibile rispetto all‚Äôapproccio frequentista tradizionale.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>70</span>¬† <span class='chapter-title'>Inferenza sulle proporzioni</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_one_proportion.html#inferenza-su-una-proporzione",
    "href": "chapters/linear_models/11_one_proportion.html#inferenza-su-una-proporzione",
    "title": "70¬† Inferenza sulle proporzioni",
    "section": "\n70.2 Inferenza su Una Proporzione",
    "text": "70.2 Inferenza su Una Proporzione\n\n70.2.1 Contesto e Dati\nCome esempio per l‚Äôinferenza su una proporzione, utilizzeremo i dati dello studio di Br√ºckner & Bearman (2005), discussi anche da Wagenmakers et al. (2010). Nell‚Äôarticolo ‚ÄúAfter the promise: the STD consequences of adolescent virginity pledges‚Äù, Br√ºckner & Bearman (2005) analizzano una serie di interviste condotte nell‚Äôambito del National Longitudinal Study of Adolescent Health (Add Health). Lo studio si concentra sul comportamento sessuale di adolescenti, di et√† compresa tra 18 e 24 anni, che hanno fatto un ‚Äúvirginity pledge‚Äù, ovvero una promessa pubblica o scritta di rimanere vergini fino al matrimonio. Studi scientifici indicano che il comportamento sessuale di questi adolescenti non sia statisticamente diverso da quello di chi non ha fatto tale promessa, con l‚Äôunica eccezione che i ‚Äúpledgers‚Äù hanno una minore probabilit√† di utilizzare il preservativo durante il primo rapporto sessuale.\nI dati rilevanti per la nostra analisi sono i seguenti:\n\nsu 777 adolescenti che hanno fatto il ‚Äúvirginity pledge‚Äù, 424 (54.6%) hanno dichiarato di aver usato il preservativo durante il primo rapporto sessuale;\nsu 9072 adolescenti che non hanno fatto la promessa, 5416 (59.7%) hanno dichiarato di aver usato il preservativo.\n\n70.2.2 Obiettivo dell‚ÄôAnalisi\nNella prima analisi, ci concentreremo sul campione di adolescenti che hanno fatto il ‚Äúvirginity pledge‚Äù. Ci chiediamo se sia credibile pensare che questi adolescenti tendano ad avere un rapporto protetto, nel loro primo rapporto sessuale, in una proporzione minore di quella che ci si potrebbe aspettare in caso di casualit√† (ovvero, una proporzione di 0.5).\n\n70.2.3 Analisi Frequentista\nIniziamo con un test frequentista per confrontare la proporzione osservata con il valore di riferimento 0.5.\n\nprop_test_freq_vol &lt;- prop.test(\n  x = 424,\n  n = 777,\n  p = 0.5\n)\n\ntidy(prop_test_freq_vol)\n#&gt; # A tibble: 1 √ó 8\n#&gt;   estimate statistic p.value parameter conf.low conf.high method            \n#&gt;      &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;             \n#&gt; 1    0.546      6.31  0.0120         1    0.510     0.581 1-sample proporti‚Ä¶\n#&gt; # ‚Ñπ 1 more variable: alternative &lt;chr&gt;\n\nL‚Äôintervallo di confidenza frequentista non include il valore di riferimento 0.5, quindi, in base a questa analisi, possiamo concludere che la proporzione osservata (0.546) sia significativamente maggiore del valore atteso in caso di casualit√† (0.5).\n\n70.2.4 Approccio Bayesiano con brms\n\nSe utilizziamo dei prior non informativi, ci aspettiamo di giungere alla stessa conclusione anche con un approccio bayesiano. Tuttavia, l‚Äôapproccio bayesiano ci permette di ottenere una distribuzione completa della probabilit√† a posteriori del parametro di interesse, offrendo una visione pi√π ricca e flessibile rispetto all‚Äôapproccio frequentista.\n\n70.2.4.1 Preparazione dei Dati\nIniziamo creando un data frame che sar√† utilizzato con la funzione brm().\n\npledge_binomial_df &lt;- tibble(\n  n_yes = 424,\n  n_total = 777\n)\n\n# tiny data\npledge_binomial_df\n#&gt; # A tibble: 1 √ó 2\n#&gt;   n_yes n_total\n#&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1   424     777\n\n\n70.2.4.2 Definizione delle Opzioni del Campionatore\nImpostiamo alcune opzioni globali per il campionatore Stan.\n\n# Set some global Stan options\nCHAINS &lt;- 4\nITER &lt;- 2000\nWARMUP &lt;- 1000\nBAYES_SEED &lt;- 1234\n\n\n70.2.4.3 Modello Bayesiano\nUtilizziamo un modello di regressione con una funzione link binomiale. Questo significa che stimeremo la proporzione \\(p\\) con un modello di regressione beta-binomiale bayesiano utilizzando brms. Useremo un prior non informativo \\(\\mathcal{Beta}(1, 1)\\). Questo √® un modello solo con intercetta, senza altre covariate, poich√© siamo interessati solo alla proporzione sottostante, senza condizionarla su altre variabili.\nIl modello pu√≤ essere rappresentato come segue:\n\\[\n\\begin{aligned}\ny_{\\text{condom\\_use}} &\\sim \\mathcal{Binomial}(n, \\pi) \\\\\n\\pi &= \\beta_0 \\\\\n\\beta_0 &\\sim \\mathcal{Beta}(1, 1)\n\\end{aligned}\n\\]\nEseguiamo l‚Äôanalisi bayesiana.\n\nmodel_pledge_binomial &lt;- brm(\n  n_yes | trials(n_total) ~ 1,\n  data = pledge_binomial_df,\n  family = binomial(link = \"identity\"),\n  prior = c(prior(beta(1, 1), class = \"Intercept\", lb = 0, ub = 1)),\n  chains = CHAINS, warmup = WARMUP, iter = ITER, seed = BAYES_SEED,\n  refresh = 0,\n  backend = \"cmdstanr\"\n)\n#&gt; Running MCMC with 4 sequential chains...\n#&gt; \n#&gt; Chain 1 finished in 0.0 seconds.\n#&gt; Chain 2 finished in 0.0 seconds.\n#&gt; Chain 3 finished in 0.0 seconds.\n#&gt; Chain 4 finished in 0.0 seconds.\n#&gt; \n#&gt; All 4 chains finished successfully.\n#&gt; Mean chain execution time: 0.0 seconds.\n#&gt; Total execution time: 0.5 seconds.\n\n\n70.2.4.4 Risultati del Modello\nPoich√© questo √® un modello di regressione, si comporta come qualsiasi altro modello brms. Il coefficiente per l‚Äôintercetta rappresenta la proporzione stimata di adolescenti tra i 18 e i 24 anni che hanno usato il preservativo durante il primo rapporto sessuale nel campione.\n\nsummary(model_pledge_binomial)\n#&gt;  Family: binomial \n#&gt;   Links: mu = identity \n#&gt; Formula: n_yes | trials(n_total) ~ 1 \n#&gt;    Data: pledge_binomial_df (Number of observations: 1) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept     0.55      0.02     0.51     0.58 1.00     1457     1756\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nSi noti come l‚Äôintervallo di credibilit√† al 95% riproduce l‚Äôintervallo frequentista calcolato in precedenza.\n\n70.2.5 Discussione e Confronto tra Approcci\nConfrontiamo ora i risultati ottenuti dai due approcci. L‚Äôanalisi frequentista ha mostrato che la proporzione osservata (0.546) √® significativamente maggiore del valore di riferimento 0.5. L‚Äôapproccio bayesiano conferma questa conclusione, fornendo una distribuzione completa della probabilit√† a posteriori per la proporzione œÄ. Uno dei vantaggi dell‚Äôapproccio bayesiano √® la possibilit√† di incorporare informazioni a priori, se disponibili, migliorando cos√¨ la robustezza delle inferenze. Inoltre, l‚Äôintervallo di credibilit√† bayesiano fornisce una descrizione pi√π completa della distribuzione dei parametri, consentendo una migliore interpretazione dei risultati.\n\n70.2.6 Modello Beta-Binomiale e Soluzione Analitica\nIn questo contesto, il problema pu√≤ essere modellato utilizzando una distribuzione beta-binomiale, per la quale esiste una soluzione analitica per la distribuzione a posteriori. Il modello beta-binomiale √® particolarmente adatto quando si lavora con dati binomiali (ad esempio, successi e fallimenti) e si desidera incorporare una distribuzione a priori coniugata per la proporzione \\(p\\).\n\n70.2.6.1 Contestualizzazione del Modello\nPer il gruppo ‚Äúpledgers‚Äù, abbiamo \\(y_1\\) successi su \\(n_1\\) prove. Se assumiamo una distribuzione a priori Beta(\\(\\alpha\\), \\(\\beta\\)), la distribuzione a posteriori per la proporzione \\(p_1\\) sar√† anch‚Äôessa una distribuzione Beta, data da:\n\\[\np_1 \\mid y_1, n_1 \\sim \\mathcal{Beta}(\\alpha + y_1, \\beta + n_1 - y_1)\n\\]\nNel nostro caso specifico, scegliamo una prior non informativa \\(\\mathcal{Beta}(1, 1)\\), che equivale a una distribuzione uniforme sull‚Äôintervallo [0, 1]. Questa scelta riflette l‚Äôassenza di informazioni pregresse sulla proporzione \\(p_1\\). Pertanto, la distribuzione a posteriori per il gruppo ‚Äúpledgers‚Äù diventa:\n\\[\np_1 \\mid y_1, n_1 \\sim \\mathcal{Beta}(1 + 424, 1 + 777 - 424) = \\mathcal{Beta}(425, 354)\n\\]\n\n70.2.6.2 Calcolo dell‚ÄôIntervallo di Credibilit√†\nUtilizziamo R per calcolare l‚Äôintervallo di credibilit√† al 95% basato sulla distribuzione a posteriori derivata analiticamente.\n\n# Parametri della distribuzione Beta\na_post &lt;- 425  # Parametro alpha\nb_post &lt;- 354  # Parametro beta\n\n# Calcolo dell'intervallo centrale al 95%\ncredibility_interval &lt;- qbeta(c(0.025, 0.975), shape1 = a_post, shape2 = b_post)\nprint(credibility_interval)\n#&gt; [1] 0.5105 0.5804\n\nIl risultato ottenuto dall‚Äôanalisi bayesiana analitica replica quello ottenuto tramite il modello brm() implementato in precedenza. Questo confronto tra approcci ci permette di validare i risultati e dimostra la coerenza tra le tecniche frequentista, bayesiana numerica e bayesiana analitica.\n\n70.2.7 Discussione e Confronto tra Approcci\nL‚Äôutilizzo della distribuzione beta-binomiale e della soluzione analitica offre diversi vantaggi:\n\n\nSemplicit√†: La soluzione analitica √® spesso pi√π semplice da implementare rispetto ai metodi numerici, come quelli utilizzati in brms.\n\nVelocit√†: I calcoli sono generalmente pi√π veloci poich√© non richiedono iterazioni o campionamenti.\n\nInterpretazione: L‚Äôuso di distribuzioni coniugate facilita l‚Äôinterpretazione dei risultati, fornendo direttamente la distribuzione a posteriori senza bisogno di complessi algoritmi di inferenza.\n\nTuttavia, l‚Äôapproccio bayesiano numerico tramite brms presenta anche vantaggi significativi:\n\n\nFlessibilit√†: Pu√≤ gestire modelli pi√π complessi e includere covariate multiple.\n\nPriori informativi: Permette di incorporare facilmente informazioni a priori, se disponibili.\n\nEstensioni: Facilita l‚Äôestensione del modello a casi pi√π complessi, come il confronto tra proporzioni di due gruppi.\n\n\n70.2.7.1 Analisi della Distribuzione a Posteriori\nEssendo un‚Äôanalisi bayesiana, possiamo lavorare con l‚Äôintera distribuzione a posteriori e calcolare direttamente l‚Äôestimando, come la differenza tra la proporzione campionaria e la proporzione di riferimento (0.5).\n\npledge_draws &lt;- model_pledge_binomial |&gt; \n  spread_draws(b_Intercept) |&gt; \n  mutate(diff = b_Intercept - 0.5)\n\nVisualizziamo la distribuzione a posteriori della proporzione.\n\np1 &lt;- ggplot(pledge_draws, aes(x = b_Intercept, y = \"Age 18‚Äì24\")) + \n  stat_halfeye(fill = \"gray\") +\n  geom_vline(xintercept = 0.5) +\n  scale_x_continuous(labels = label_percent()) +\n  coord_cartesian(ylim = c(1.5, 1.5)) +\n  labs(x = \"Proportion used a condom at first sex\", y = NULL)\np1\n\n\n\n\n\n\n\nIl valore di riferimento (0.5) non √® incluso nella distribuzione a posteriori, il che significa che la differenza tra la proporzione campionaria e la proporzione di riferimento non include lo zero, con un livello di credibilit√† del 95%. Possiamo quindi concludere, con un livello soggettivo di credibilit√† del 95%, che l‚Äôuso del preservativo durante il primo rapporto sessuale sia maggiore del caso, per gli adolescenti che hanno fatto il ‚Äúvirginity pledge‚Äù.\n\n70.2.8 La Regione di Equivalenza Pratica (ROPE)\nL‚Äôanalisi precedente confronta la proporzione osservata con un singolo valore di riferimento (0.5). Un approccio alternativo √® considerare un intervallo di valori attorno a 0.5 che possano essere considerati ‚Äúpraticamente equivalenti‚Äù al valore di riferimento. Questo intervallo √® chiamato Regione di Equivalenza Pratica (ROPE).\nSecondo Kruschke & Liddell (2018), la ROPE pu√≤ essere definita come un intervallo attorno al valore nullo (baseline) che corrisponde a un decimo della deviazione standard della distribuzione a posteriori del parametro di interesse. Nel nostro caso, il parametro di interesse √® la proporzione \\(p\\), e il valore nullo √® 0.5. Per calcolare la ROPE, estraiamo i campioni a posteriori dal modello.\n\nposterior_samples &lt;- as_draws_df(model_pledge_binomial)\n\nCalcoliamo la deviazione standard a posteriori di \\(p\\).\n\nposterior_std_dev &lt;- sd(posterior_samples$b_Intercept)\nposterior_std_dev\n#&gt; [1] 0.01809\n\nDefiniamo la ROPE come un intervallo attorno al valore di riferimento 0.5.\n\nbaseline &lt;- 0.5  # Valore nullo (baseline)\nrope_low &lt;- baseline - 0.1 * posterior_std_dev\nrope_high &lt;- baseline + 0.1 * posterior_std_dev\n\nCalcoliamo ora la probabilit√† che la proporzione \\(p\\) si trovi all‚Äôinterno della ROPE.\n\nrope_probability &lt;-\n  mean(\n    posterior_samples$b_Intercept &gt;= rope_low &\n      posterior_samples$b_Intercept &lt;= rope_high\n  )\nrope_probability\n#&gt; [1] 0.00325\n\nVisualizziamo la distribuzione a posteriori di \\(p\\) insieme alla ROPE.\n\nggplot(posterior_samples, aes(x = b_Intercept)) +\n  geom_density(fill = \"gray\", alpha = 0.5) +\n  annotate(\n    geom = \"rect\", \n    xmin = rope_low, \n    xmax = rope_high, \n    ymin = 0, ymax = Inf, \n    fill = \"lightgray\", alpha = 0.2\n  ) +\n  geom_vline(xintercept = baseline, color = \"lightgray\") +\n  scale_x_continuous(labels = scales::percent) +\n  labs(x = \"Proportion used a condom at first sex\", y = \"Density\")\n\n\n\n\n\n\n\nIn conclusione, dato che solo lo 0.325% (meno dell‚Äôuno per cento) della distribuzione a posteriori di \\(p\\) si trova nella ROPE, possiamo concludere che ci sono evidenze credibili che la distribuzione a posteriori del parametro \\(p\\) (la proporzione di adolescenti, di et√† compresa tra 18 e 24 anni, che hanno fatto il ‚Äúvirginity pledge‚Äù e hanno usato il preservativo durante il primo rapporto sessuale) sia diversa dal valore di riferimento 0.5. Nel caso specifico, questa proporzione √® pi√π alta, indicando che la tendenza ad avere un rapporto protetto √® maggiore rispetto al caso di casualit√†, per questa popolazione.\n\n70.2.8.1 Discussione sulla ROPE\nL‚Äôutilizzo della ROPE offre una prospettiva aggiuntiva e importante nell‚Äôinterpretazione delle inferenze bayesiane. Invece di semplicemente determinare se un parametro √® statisticamente significativo rispetto a un valore di riferimento, la ROPE permette di valutare se le differenze osservate siano praticamente rilevanti o significative in termini di impatto reale.\n\n\nSoglia di Rilevanza: L‚Äôimpostazione di una ROPE consente di stabilire una soglia di rilevanza pratica. Se la maggior parte della distribuzione a posteriori cade al di fuori della ROPE, possiamo concludere che la differenza √® non solo statistica ma anche pratica.\n\nInterpretazione Clinica: Nelle applicazioni pratiche, come in ambito medico o sociale, la ROPE aiuta a distinguere tra risultati statisticamente significativi ma clinicamente insignificanti e quelli che hanno un impatto rilevante.\n\nNel contesto dello studio sui ‚Äúpledgers‚Äù, l‚Äôuso della ROPE fornisce una valutazione pi√π completa della tendenza degli adolescenti a utilizzare il preservativo durante il primo rapporto sessuale, dimostrando che questa tendenza √® non solo statisticamente diversa dal caso di casualit√†, ma anche significativa dal punto di vista pratico.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>70</span>¬† <span class='chapter-title'>Inferenza sulle proporzioni</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_one_proportion.html#inferenza-sulla-differenza-tra-due-proporzioni",
    "href": "chapters/linear_models/11_one_proportion.html#inferenza-sulla-differenza-tra-due-proporzioni",
    "title": "70¬† Inferenza sulle proporzioni",
    "section": "\n70.3 Inferenza sulla Differenza tra Due Proporzioni",
    "text": "70.3 Inferenza sulla Differenza tra Due Proporzioni\nEstendiamo ora l‚Äôanalisi precedente per confrontare le proporzioni di due gruppi, un compito per il quale non esiste una soluzione analitica semplice. Nello studio in esame, ci poniamo la domanda: Fino a che punto l‚Äôanalisi statistica supporta l‚Äôipotesi che i ‚Äúpledgers‚Äù abbiano una minore probabilit√† rispetto ai ‚Äúnon-pledgers‚Äù di usare il preservativo durante il primo rapporto sessuale?\nPer testare questa ipotesi utilizzando brms, estendiamo il modello bayesiano includendo due gruppi: i pledgers (che hanno fatto il voto di astinenza) e i non-pledgers (che non lo hanno fatto). L‚Äôobiettivo √® stimare la differenza tra le due proporzioni e valutare se questa sia credibilmente diversa da zero.\n\n70.3.1 Creazione del Dataset\nCostruiamo un tibble con i dati relativi ai due gruppi:\n\npledge_data &lt;- tibble(\n  group = c(\"pledgers\", \"nonpledgers\"),\n  n_yes = c(424, 5416),   # Numero di partecipanti che hanno usato il preservativo\n  n_total = c(777, 9072)  # Totale dei partecipanti per ciascun gruppo\n)\nprint(pledge_data)\n#&gt; # A tibble: 2 √ó 3\n#&gt;   group       n_yes n_total\n#&gt;   &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 pledgers      424     777\n#&gt; 2 nonpledgers  5416    9072\n\n\n70.3.2 Specifica del Modello Bayesiano\nUtilizziamo un modello binomiale con un predittore categorico per distinguere tra i due gruppi. Il modello pu√≤ essere rappresentato come:\n\\[\np_i \\sim \\text{Binomiale}(n_i, \\theta_i)\n\\]\ndove \\(\\theta_i\\) √® la proporzione di utilizzo del preservativo nel gruppo \\(i\\), e modelliamo la probabilit√† di successo come:\n\\[\n\\theta = \\beta_0 + \\beta_1 \\cdot \\text{group}\n\\]\ndove: - \\(\\beta_0\\) rappresenta la proporzione di non-pledgers che usano il preservativo. - \\(\\beta_1\\) rappresenta la differenza tra pledgers e non-pledgers (cio√® la variazione della proporzione di utilizzo del preservativo associata all‚Äôappartenenza al gruppo dei pledgers).\nStimiamo il modello in brms utilizzando una distribuzione binomiale e un link identit√†:\n\nmodel_pledge_diff &lt;- brm(\n  n_yes | trials(n_total) ~ group,\n  data = pledge_data,\n  family = binomial(link = \"identity\"),\n  prior = c(\n    prior(beta(1, 1), class = \"Intercept\", lb = 0, ub = 1),  \n    # Prior per la proporzione nei non-pledgers\n    prior(normal(0, 1), class = \"b\")  # Prior per la differenza tra gruppi\n  ),\n  chains = CHAINS, warmup = WARMUP, iter = ITER, seed = BAYES_SEED,\n  refresh = 0,\n  backend = \"cmdstanr\"\n)\n#&gt; Running MCMC with 4 sequential chains...\n#&gt; \n#&gt; Chain 1 finished in 0.1 seconds.\n#&gt; Chain 2 finished in 0.0 seconds.\n#&gt; Chain 3 finished in 0.1 seconds.\n#&gt; Chain 4 finished in 0.0 seconds.\n#&gt; \n#&gt; All 4 chains finished successfully.\n#&gt; Mean chain execution time: 0.1 seconds.\n#&gt; Total execution time: 0.8 seconds.\n\n\n70.3.3 Analisi della Distribuzione A Posteriori\nEsaminiamo il sommario del modello per valutare la stima della differenza tra le proporzioni:\n\nsummary(model_pledge_diff)\n#&gt;  Family: binomial \n#&gt;   Links: mu = identity \n#&gt; Formula: n_yes | trials(n_total) ~ group \n#&gt;    Data: pledge_data (Number of observations: 2) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept         0.60      0.01     0.59     0.61 1.00     4511     3068\n#&gt; grouppledgers    -0.05      0.02    -0.09    -0.01 1.01      889      793\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nPer interpretare meglio i risultati, estraiamo i campioni a posteriori per la differenza tra le due proporzioni:\n\npledge_diff_draws &lt;- model_pledge_diff |&gt; \n  spread_draws(b_Intercept, b_grouppledgers) |&gt; \n  mutate(\n    nonpledgers_prop = b_Intercept,  # Stima della proporzione nei non-pledgers\n    pledgers_prop = b_Intercept + b_grouppledgers,  # Stima della proporzione nei pledgers\n    diff = nonpledgers_prop - pledgers_prop  # Differenza tra le due proporzioni\n  )\n\nVisualizziamo la distribuzione a posteriori della differenza:\n\np3 &lt;- ggplot(pledge_diff_draws, aes(x = diff)) + \n  stat_halfeye(fill = \"gray\") +\n  geom_vline(xintercept = 0, linetype = \"dashed\") +\n  scale_x_continuous(labels = label_percent()) +\n  labs(x = \"Differenza nella proporzione di utilizzo del preservativo\", \n       y = \"Densit√† a posteriori\") \nprint(p3)\n\n\n\n\n\n\n\nCalcoliamo la probabilit√† che la differenza tra le proporzioni sia maggiore di zero:\n\ndiff_probability &lt;- mean(pledge_diff_draws$diff &gt; 0)\nprint(diff_probability)\n#&gt; [1] 0.997\n\n\n70.3.4 Interpretazione dei Risultati\nLa probabilit√† calcolata √® 0.997; ci√≤ significa che c‚Äô√® una probabilit√† del 99.7% che la proporzione di non-pledgers che usano il preservativo sia maggiore rispetto a quella dei pledgers. Questo supporta con elevata credibilit√† l‚Äôipotesi che i pledgers abbiano meno probabilit√† di utilizzare il preservativo durante il primo rapporto sessuale.\nPossiamo quindi concludere che la differenza tra le due proporzioni √® credibilmente diversa da zero, con un‚Äôelevata probabilit√† a favore dell‚Äôipotesi che i pledgers abbiano una minore propensione all‚Äôuso del preservativo rispetto ai non-pledgers. Questi risultati riproducono quelli riportati dalla letteratura precedente, come discusso da Br√ºckner & Bearman (2005).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>70</span>¬† <span class='chapter-title'>Inferenza sulle proporzioni</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_one_proportion.html#riflessioni-conclusive",
    "href": "chapters/linear_models/11_one_proportion.html#riflessioni-conclusive",
    "title": "70¬† Inferenza sulle proporzioni",
    "section": "\n70.4 Riflessioni Conclusive",
    "text": "70.4 Riflessioni Conclusive\nL‚Äôinferenza su una proporzione tramite un approccio bayesiano offre una prospettiva pi√π ricca e flessibile rispetto agli approcci frequentisti tradizionali. Utilizzando il pacchetto brms in R, abbiamo dimostrato come sia possibile modellare la proporzione di adolescenti che hanno usato il preservativo durante il primo rapporto sessuale, ottenendo risultati coerenti con quelli frequentisti. La capacit√† di ottenere una distribuzione completa della probabilit√† a posteriori consente non solo stime puntuali ma anche una comprensione approfondita dell‚Äôincertezza associata ai parametri stimati, rendendo l‚Äôapproccio bayesiano uno strumento potente per l‚Äôanalisi statistica avanzata.\nL‚Äôestensione dell‚Äôanalisi alla differenza tra due proporzioni ha ulteriormente evidenziato i vantaggi dell‚Äôapproccio bayesiano. Attraverso brms, abbiamo confrontato le proporzioni di utilizzo del preservativo tra i ‚Äúpledgers‚Äù e i ‚Äúnon-pledgers‚Äù, ottenendo risultati coerenti e facilmente interpretabili. L‚Äôuso di distribuzioni a posteriori complete ci ha permesso di valutare in modo pi√π dettagliato la plausibilit√† delle differenze osservate, offrendo una maggiore profondit√† di interpretazione rispetto agli intervalli di confidenza frequentisti.\n\n70.4.1 Vantaggi dell‚ÄôApproccio Bayesiano\n\nDistribuzioni A Posteriori: L‚Äôapproccio bayesiano fornisce una visione completa della distribuzione dei parametri stimati, permettendo di calcolare probabilit√† direttamente e quantificare l‚Äôincertezza in modo pi√π intuitivo.\nFlessibilit√† Modellistica: brms consente di costruire modelli complessi, inclusi modelli gerarchici e multivariati, adattandosi alle specifiche esigenze dell‚Äôanalisi senza perdere di generalit√†.\nPrior Informativi e Non Informativi: La possibilit√† di incorporare prior informativi o utilizzare prior non informativi permette di integrare conoscenze pregresse o lavorare in assenza di informazioni preliminari, aumentando la robustezza delle inferenze.\nIntegrazione con Stan: Sfruttando la potenza di Stan, brms offre algoritmi di campionamento efficienti e accurati per modelli complessi, garantendo risultati affidabili anche in situazioni di alta dimensionalit√†.\nVisualizzazione e Interpretazione: L‚Äôintegrazione con pacchetti come tidyverse e ggplot2 facilita la visualizzazione e l‚Äôinterpretazione dei risultati, rendendo pi√π semplice comunicare le analisi bayesiane a un pubblico ampio e variegato.\n\n70.4.2 Applicazioni Pratiche\nI risultati ottenuti confermano che i ‚Äúpledgers‚Äù hanno una minore propensione all‚Äôuso del preservativo rispetto ai ‚Äúnon-pledgers‚Äù, supportando con elevata credibilit√† l‚Äôipotesi formulata. Questi risultati riproducono quelli riportati dalla letteratura precedente, rafforzando la validit√† dell‚Äôapproccio bayesiano nelle applicazioni pratiche.\n\n70.4.3 Conclusione\nIn sintesi, l‚Äôapproccio bayesiano, implementato attraverso il pacchetto brms, rappresenta uno strumento estremamente potente e flessibile per l‚Äôinferenza statistica. Offre una visione pi√π dettagliata e comprensiva rispetto agli approcci frequentisti tradizionali, permettendo di ottenere risultati coerenti e facilmente interpretabili. La capacit√† di fornire una distribuzione completa della probabilit√† a posteriori rende l‚Äôapproccio bayesiano ideale per affrontare problemi complessi e per sostenere decisioni basate su dati con maggiore fiducia e precisione.\nQuesto capitolo ha illustrato come l‚Äôinferenza bayesiana possa essere applicata efficacemente a problemi reali, fornendo una base solida per ulteriori sviluppi e applicazioni in ambiti diversi, dall‚Äôepidemiologia alla psicologia sociale, e oltre.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>70</span>¬† <span class='chapter-title'>Inferenza sulle proporzioni</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_one_proportion.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/11_one_proportion.html#informazioni-sullambiente-di-sviluppo",
    "title": "70¬† Inferenza sulle proporzioni",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] rstan_2.32.7        StanHeaders_2.32.10 tidybayes_3.0.7    \n#&gt;  [4] broom_1.0.7         brms_2.22.0         Rcpp_1.0.14        \n#&gt;  [7] bayestestR_0.15.2   posterior_1.6.1     cmdstanr_0.8.1     \n#&gt; [10] thematic_0.1.6      MetBrewer_0.2.0     ggokabeito_0.1.0   \n#&gt; [13] see_0.11.0          gridExtra_2.3       patchwork_1.3.0    \n#&gt; [16] bayesplot_1.11.1    psych_2.5.3         scales_1.3.0       \n#&gt; [19] markdown_2.0        knitr_1.50          lubridate_1.9.4    \n#&gt; [22] forcats_1.0.0       stringr_1.5.1       dplyr_1.1.4        \n#&gt; [25] purrr_1.0.4         readr_2.1.5         tidyr_1.3.1        \n#&gt; [28] tibble_3.2.1        ggplot2_3.5.1       tidyverse_2.0.0    \n#&gt; [31] rio_1.2.3           here_1.0.1         \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] mnormt_2.1.1         inline_0.3.21        sandwich_3.1-1      \n#&gt;  [4] rlang_1.1.5          magrittr_2.0.3       multcomp_1.4-28     \n#&gt;  [7] matrixStats_1.5.0    compiler_4.4.2       loo_2.8.0           \n#&gt; [10] vctrs_0.6.5          reshape2_1.4.4       pkgconfig_2.0.3     \n#&gt; [13] arrayhelpers_1.1-0   fastmap_1.2.0        backports_1.5.0     \n#&gt; [16] labeling_0.4.3       utf8_1.2.4           rmarkdown_2.29      \n#&gt; [19] tzdb_0.5.0           ps_1.9.0             xfun_0.51           \n#&gt; [22] jsonlite_1.9.1       parallel_4.4.2       R6_2.6.1            \n#&gt; [25] stringi_1.8.4        estimability_1.5.1   zoo_1.8-13          \n#&gt; [28] pacman_0.5.1         Matrix_1.7-3         splines_4.4.2       \n#&gt; [31] timechange_0.3.0     tidyselect_1.2.1     rstudioapi_0.17.1   \n#&gt; [34] abind_1.4-8          codetools_0.2-20     curl_6.2.2          \n#&gt; [37] processx_3.8.6       pkgbuild_1.4.7       plyr_1.8.9          \n#&gt; [40] lattice_0.22-6       withr_3.0.2          bridgesampling_1.1-2\n#&gt; [43] coda_0.19-4.1        evaluate_1.0.3       survival_3.8-3      \n#&gt; [46] RcppParallel_5.1.10  ggdist_3.3.2         pillar_1.10.1       \n#&gt; [49] tensorA_0.36.2.1     checkmate_2.3.2      stats4_4.4.2        \n#&gt; [52] insight_1.1.0        distributional_0.5.0 generics_0.1.3      \n#&gt; [55] rprojroot_2.0.4      hms_1.1.3            rstantools_2.4.0    \n#&gt; [58] munsell_0.5.1        xtable_1.8-4         glue_1.8.0          \n#&gt; [61] emmeans_1.11.0       tools_4.4.2          data.table_1.17.0   \n#&gt; [64] mvtnorm_1.3-3        grid_4.4.2           QuickJSR_1.6.0      \n#&gt; [67] colorspace_2.1-1     nlme_3.1-167         cli_3.6.4           \n#&gt; [70] svUnit_1.0.6         Brobdingnag_1.2-9    V8_6.0.2            \n#&gt; [73] gtable_0.3.6         digest_0.6.37        TH.data_1.1-3       \n#&gt; [76] htmlwidgets_1.6.4    farver_2.1.2         htmltools_0.5.8.1   \n#&gt; [79] lifecycle_1.0.4      MASS_7.3-65",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>70</span>¬† <span class='chapter-title'>Inferenza sulle proporzioni</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_one_proportion.html#bibliografia",
    "href": "chapters/linear_models/11_one_proportion.html#bibliografia",
    "title": "70¬† Inferenza sulle proporzioni",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAlbert, J., & Hu, J. (2019). Probability and Bayesian Modeling. CRC Press.\n\n\nBr√ºckner, H., & Bearman, P. (2005). After the promise: The STD consequences of adolescent virginity pledges. Journal of Adolescent Health, 36(4), 271‚Äì278.\n\n\nKruschke, J. K., & Liddell, T. M. (2018). Bayesian data analysis for newcomers. Psychonomic Bulletin & Review, 25(1), 155‚Äì177.\n\n\nWagenmakers, E.-J., Lodewyckx, T., Kuriyal, H., & Grasman, R. (2010). Bayesian hypothesis testing for psychologists: A tutorial on the Savage‚ÄìDickey method. Cognitive Psychology, 60(3), 158‚Äì189.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>70</span>¬† <span class='chapter-title'>Inferenza sulle proporzioni</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html",
    "href": "chapters/linear_models/12_two_proportions.html",
    "title": "71¬† Confronto tra due proporzioni indipendenti",
    "section": "",
    "text": "71.1 Introduzione\nSpesso, ci troviamo ad affrontare la necessit√† di confrontare due gruppi di dati. Mentre nel capitolo precedente abbiamo considerato il contronto tra le medie di due gruppi indipendenti, nel caso presente ci concentreremo sul confronto tra le proporzioni di due gruppi indipendenti. Per esempio, potrebbe interessarci sapere se la proporzione di un gruppo √® maggiore o diversa rispetto a quella di un altro gruppo. Come in precedenza, per effettuare tale confronto, √® fondamentale utilizzare un modello statistico, poich√© le vere differenze tra i gruppi sono spesso accompagnate da rumore di misurazione o fluttuazioni casuali del fenomeno in esame. Questo rende difficile trarre conclusioni basandosi unicamente sulle differenze calcolate dai dati osservati.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>71</span>¬† <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#confronto-tra-le-proporzioni-di-due-gruppi-indipendenti",
    "href": "chapters/linear_models/12_two_proportions.html#confronto-tra-le-proporzioni-di-due-gruppi-indipendenti",
    "title": "71¬† Confronto tra due proporzioni indipendenti",
    "section": "\n71.2 Confronto tra le proporzioni di due gruppi indipendenti",
    "text": "71.2 Confronto tra le proporzioni di due gruppi indipendenti\nAnche nel caso delle proporzioni, il metodo tradizionale per confrontare statisticamente due o pi√π gruppi consiste nell‚Äôutilizzare un test di ipotesi. Questo approccio prevede la definizione di un‚Äôipotesi nulla, che tipicamente afferma l‚Äôassenza di differenze tra i gruppi, e l‚Äôuso di una statistica test per valutare se i dati osservati sono compatibili con tale ipotesi. Se la statistica test supera una soglia prestabilita, l‚Äôipotesi nulla viene rifiutata, suggerendo che esiste una differenza significativa tra i gruppi.\nTuttavia, i test di ipotesi presentano alcune criticit√†. Innanzitutto, possono risultare complessi da applicare e interpretare, e i loro risultati sono spesso soggetti a errori di valutazione. La scelta delle specifiche del test statistico‚Äîquale test utilizzare, quale ipotesi nulla formulare, quale livello di significativit√† adottare‚Äî√® spesso basata su convenzioni piuttosto che sulle peculiarit√† del problema analizzato o sulle decisioni da prendere (Johnson, 1999). Inoltre, i risultati dei test di ipotesi sono spesso indiretti e incompleti, e tendono a sovrastimare le evidenze contro l‚Äôipotesi nulla (Goodman, 1999).\nUn approccio alternativo e pi√π informativo √® quello basato sulla stima anzich√© sul test dell‚Äôipotesi nulla, fondato sulla probabilit√† bayesiana piuttosto che su quella frequentista. In questo caso, l‚Äôobiettivo non √® semplicemente verificare se esiste una differenza tra i gruppi, ma stimare quanto siano effettivamente diversi. Questo metodo √® intrinsecamente pi√π informativo, poich√© fornisce una stima diretta della differenza tra i gruppi, accompagnata da una misura dell‚Äôincertezza associata. Tale incertezza riflette sia la nostra limitata conoscenza dei parametri del modello (incertezza epistemica) sia la variabilit√† intrinseca del sistema (incertezza aleatoria).\nIn sintesi, mentre i test di ipotesi si concentrano sul rigetto o meno di un‚Äôipotesi nulla, l‚Äôapproccio basato sulla stima offre una visione pi√π completa e utile, permettendo di quantificare direttamente la differenza tra i gruppi e di valutare l‚Äôincertezza associata a tale stima. Questo rende l‚Äôanalisi pi√π adatta a supportare decisioni informate e basate sui dati.\nPer affrontare tale problema possiamo usare un modello di regressione. In questo caso, anzich√© calcolare direttamente la differenza tra le proporzioni, si introduce una variabile indicatrice (o ‚Äúdummy‚Äù) \\(D\\) nel modello di regressione, come segue:\n\\[\ny_i \\sim \\text{Bernoulli}(p_i), \\\\\n\\text{logit}(p_i) = \\alpha + \\gamma D_i.\n\\]\nLa variabile indicatrice \\(D\\) specifica l‚Äôappartenenza ai gruppi attraverso valori binari: 0 per il gruppo di riferimento e 1 per il gruppo di confronto, definita come:\n\\[\nD_i =\n\\begin{cases}\n0 & \\text{se l'osservazione } i \\text{ appartiene al gruppo 0,} \\\\\n1 & \\text{se l'osservazione } i \\text{ appartiene al gruppo 1.}\n\\end{cases}\n\\]\nEntrambi i metodi sono appropriati per studiare la differenza tra le proporzioni di due gruppi indipendenti. Tuttavia, il modello di regressione offre maggiore flessibilit√† e possibilit√† di estensione. Questa metodologia consente di includere ulteriori variabili esplicative, migliorando la comprensione dei fattori che influenzano l‚Äôesito di interesse. Tale flessibilit√† diventa particolarmente utile per esplorare come altre variabili incidano sulla differenza tra le proporzioni o per analizzare contemporaneamente pi√π variabili.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>71</span>¬† <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#regressione-bayesiana-per-due-gruppi-indipendenti",
    "href": "chapters/linear_models/12_two_proportions.html#regressione-bayesiana-per-due-gruppi-indipendenti",
    "title": "71¬† Confronto tra due proporzioni indipendenti",
    "section": "\n71.3 Regressione bayesiana per due gruppi indipendenti",
    "text": "71.3 Regressione bayesiana per due gruppi indipendenti\nIn un approccio bayesiano, possiamo utilizzare un modello di regressione per confrontare le proporzioni di due gruppi indipendenti. Tuttavia, poich√© stiamo lavorando con dati binari (ad esempio, successo/fallimento, s√¨/no), la distribuzione di riferimento non √® pi√π la normale (gaussiana), come nel caso delle medie, ma la distribuzione di Bernoulli. Questo significa che ogni osservazione \\(y_i\\) pu√≤ assumere solo due valori: 0 (fallimento) o 1 (successo), e la probabilit√† di successo √® indicata con \\(p_i\\).\nIl modello di regressione pu√≤ essere espresso come:\n\\[\n\\begin{align*}\ny_i & \\sim \\text{Bernoulli}(p_i), \\\\\n\\text{logit}(p_i) & = \\alpha + \\gamma D_i.\n\\end{align*}\n\\]\n\n71.3.1 Cosa significa ‚Äúlogit‚Äù?\nIl logit √® una trasformazione matematica che ci permette di lavorare con probabilit√† (che sono limitate tra 0 e 1) nel contesto di un modello lineare. In particolare, il logit di una probabilit√† \\(p_i\\) √® definito come:\n\\[\n\\text{logit}(p_i) = \\log\\left(\\frac{p_i}{1 - p_i}\\right).\n\\]\nQuesta trasformazione ha due vantaggi principali:\n\nTrasforma l‚Äôintervallo [0, 1] in \\((-\\infty, +\\infty)\\): mentre una probabilit√† \\(p_i\\) √® confinata tra 0 e 1, il logit pu√≤ assumere qualsiasi valore reale. Questo √® fondamentale perch√© i modelli lineari (come quello che stiamo usando) funzionano meglio quando la variabile dipendente non ha limiti.\nInterpretazione come ‚Äúlog-odds‚Äù: il termine \\(\\frac{p_i}{1 - p_i}\\) √® chiamato odds (rapporto tra la probabilit√† di successo e quella di fallimento). Prendendo il logaritmo, otteniamo il log-odds, che √® pi√π facile da gestire in un modello lineare.\n\n71.3.2 Componenti del modello\nNel modello di regressione:\n\n\n\\(y_i \\sim \\text{Bernoulli}(p_i)\\): indica che ogni osservazione \\(y_i\\) segue una distribuzione di Bernoulli con probabilit√† di successo \\(p_i\\).\n\n\\(\\text{logit}(p_i) = \\alpha + \\gamma D_i\\): √® l‚Äôequazione lineare che collega la probabilit√† di successo \\(p_i\\) alla variabile indicatrice \\(D_i\\), che rappresenta l‚Äôappartenenza al gruppo.\n\n\n71.3.2.1 Parametri del modello\n\n\\(\\alpha\\): rappresenta l‚Äôintercetta, ovvero il logit della probabilit√† di successo per il gruppo di riferimento (\\(D = 0\\)). Per ottenere la probabilit√† \\(p\\) corrispondente, possiamo applicare la funzione inversa del logit, chiamata funzione logistica: \\[\np = \\frac{e^\\alpha}{1 + e^\\alpha}.\n\\]\n\\(\\gamma\\): rappresenta la differenza nel logit delle probabilit√† tra il gruppo di confronto (\\(D = 1\\)) e il gruppo di riferimento (\\(D = 0\\)). In altre parole, \\(\\gamma\\) quantifica quanto il logit della probabilit√† di successo del gruppo 1 si discosta da quello del gruppo 0.\n\n71.3.3 Interpretazione per i due gruppi\n\nGruppo di riferimento (\\(D = 0\\)): \\[\n\\text{logit}(p_i) = \\alpha.\n\\] Qui, \\(\\alpha\\) rappresenta direttamente il logit della probabilit√† di successo per il gruppo 0.\nGruppo di confronto (\\(D = 1\\)): \\[\n\\text{logit}(p_i) = \\alpha + \\gamma.\n\\] In questo caso, \\(\\alpha + \\gamma\\) rappresenta il logit della probabilit√† di successo per il gruppo 1. La differenza tra i due gruppi √® quindi catturata dal parametro \\(\\gamma\\).\n\n71.3.4 Inferenza bayesiana\nIn un contesto bayesiano, l‚Äôobiettivo √® stimare la distribuzione a posteriori dei parametri \\(\\alpha\\) e \\(\\gamma\\), che ci fornisce informazioni sulla probabilit√† di successo nei due gruppi e sulla differenza tra di essi. In particolare, ci interessa la distribuzione a posteriori di \\(\\gamma\\), che ci permette di valutare quanto sia plausibile che ci sia una differenza degna di nota tra i due gruppi e di quantificare l‚Äôincertezza associata a questa stima.\n\n71.3.5 Perch√© usare il logit?\nLa scelta di modellare il logit della probabilit√†, anzich√© la probabilit√† stessa, √® dettata dalla necessit√† di adattare un modello lineare a dati binari. Mentre una probabilit√† √® limitata tra 0 e 1, il logit pu√≤ assumere qualsiasi valore reale, rendendolo compatibile con la struttura del modello lineare. Senza questa trasformazione, non potremmo utilizzare un modello lineare per analizzare dati binari, poich√© le previsioni del modello potrebbero cadere al di fuori dell‚Äôintervallo [0, 1], il che non avrebbe senso per una probabilit√†.\nIn sintesi, il logit ci permette di ‚Äúaprire‚Äù l‚Äôintervallo [0, 1] e di utilizzare un modello lineare per analizzare dati binari, mantenendo al contempo un‚Äôinterpretazione chiara e intuitiva dei risultati.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>71</span>¬† <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#approccio-frequentista",
    "href": "chapters/linear_models/12_two_proportions.html#approccio-frequentista",
    "title": "71¬† Confronto tra due proporzioni indipendenti",
    "section": "\n71.4 Approccio Frequentista",
    "text": "71.4 Approccio Frequentista\nL‚Äôinferenza frequentista si basa sulla costruzione della distribuzione campionaria di una statistica di interesse. Nel caso presente, la statistica di interesse √® la differenza tra le proporzioni di due gruppi indipendenti. Supponiamo che i dati provengano da due popolazioni distribuite come Bernoulli:\n\\[\nY_1 \\sim \\text{Bernoulli}(p_1) \\quad \\text{e} \\quad Y_2 \\sim \\text{Bernoulli}(p_2),\n\\]\ndove \\(p_1\\) e \\(p_2\\) sono le proporzioni delle popolazioni.\n\n71.4.1 Inferenza sulla differenza delle proporzioni\nSiamo interessati a fare inferenza sulla differenza \\(p_1 - p_2\\). La statistica campionaria corrispondente √® la differenza tra le proporzioni campionarie:\n\\[\n\\hat{p}_1 - \\hat{p}_2.\n\\]\nPer fare inferenza, dobbiamo determinare la distribuzione di \\(\\hat{p}_1 - \\hat{p}_2\\) nell‚Äôuniverso dei campioni.\n\n71.4.1.1 Valore atteso\nIl valore atteso della differenza tra le proporzioni campionarie √®:\n\\[\nE(\\hat{p}_1 - \\hat{p}_2) = E(\\hat{p}_1) - E(\\hat{p}_2) = p_1 - p_2.\n\\]\n\n71.4.1.2 Varianza\nLa varianza della differenza tra le proporzioni campionarie dipende dall‚Äôindipendenza dei due campioni. Se \\(\\hat{p}_1\\) e \\(\\hat{p}_2\\) sono indipendenti, la covarianza tra di essi √® zero, e la varianza √® data da:\n\\[\n\\begin{align}\nV(\\hat{p}_1 - \\hat{p}_2) &= V(\\hat{p}_1) + V(\\hat{p}_2) - 2 \\text{Cov}(\\hat{p}_1, \\hat{p}_2) \\\\\n&= V(\\hat{p}_1) + V(\\hat{p}_2) \\quad \\text{(poich√© $\\text{Cov}(\\hat{p}_1, \\hat{p}_2) = 0$)} \\\\\n&= \\frac{p_1(1 - p_1)}{n_1} + \\frac{p_2(1 - p_2)}{n_2},\n\\end{align}\n\\]\ndove:\n\n\n\\(p_1\\) e \\(p_2\\) sono le proporzioni delle popolazioni da cui sono estratti i campioni,\n\n\\(n_1\\) e \\(n_2\\) sono le dimensioni dei campioni \\(\\hat{p}_1\\) e \\(\\hat{p}_2\\).\n\n71.4.2 Distribuzione della statistica\nPer due campioni indipendenti provenienti da popolazioni Bernoulli, la statistica \\(\\hat{p}_1 - \\hat{p}_2\\) segue una distribuzione normale approssimata:\n\\[\n\\hat{p}_1 - \\hat{p}_2 \\sim \\mathcal{N}\\left(p_1 - p_2, \\sqrt{\\frac{p_1(1 - p_1)}{n_1} + \\frac{p_2(1 - p_2)}{n_2}}\\right).\n\\]\nQuesto risultato √® fondamentale per costruire test di ipotesi e intervalli di confidenza sulla differenza delle proporzioni. Questi argomenti verranno approfonditi in seguito. Per ora, limitiamoci a costruire la distribuzione campionaria della statistica \\(\\hat{p}_1 - \\hat{p}_2\\) e a calcolare delle probabilit√†.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>71</span>¬† <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#un-esempio-illustrativo",
    "href": "chapters/linear_models/12_two_proportions.html#un-esempio-illustrativo",
    "title": "71¬† Confronto tra due proporzioni indipendenti",
    "section": "\n71.5 Un esempio illustrativo",
    "text": "71.5 Un esempio illustrativo\nConsideriamo i dati di un recente studio di Banerjee et al. (2025) sui bambini provenienti da contesti socioeconomici svantaggiati. Lo studio si √® concentrato sulle competenze matematiche di bambini che lavorano nei mercati di Kolkata e Delhi, in India, confrontandole con quelle di bambini che frequentano la scuola ma non hanno esperienza di lavoro. L‚Äôobiettivo era capire se le abilit√† matematiche apprese in contesti reali, come il mercato, possano trasferirsi in ambito scolastico e viceversa.\nI risultati principali dello studio sono i seguenti.\n\nBambini che lavorano nei mercati (n = 1.436): Quasi tutti questi bambini dimostravano di saper eseguire calcoli aritmetici complessi nel contesto lavorativo. Erano abili nel risolvere problemi matematici legati a situazioni concrete, come quelle che incontrano quotidianamente al mercato. Tuttavia, quando gli stessi problemi venivano presentati in formato astratto, tipico dei libri di scuola, le loro performance peggioravano notevolmente. Questo suggerisce che le loro abilit√† matematiche sono fortemente legate al contesto pratico in cui le hanno apprese.\nBambini che frequentano la scuola (n = 471): Al contrario, i bambini senza esperienza di lavoro nei mercati mostravano una buona capacit√† di risolvere problemi matematici semplici e astratti, ma solo l‚Äô1% di loro riusciva a risolvere correttamente un problema applicato al contesto del mercato, che invece era risolto da pi√π di un terzo dei bambini lavoratori. Inoltre, i bambini scolarizzati utilizzavano metodi di calcolo scritto inefficienti, faticavano a combinare diverse operazioni e impiegavano troppo tempo per arrivare a una soluzione, rendendo le loro abilit√† poco utili in situazioni reali o in matematica avanzata.\n\nLo studio evidenzia un contrasto netto tra le abilit√† matematiche dei due gruppi:\n\ni bambini lavoratori eccellono in problemi concreti ma faticano con quelli astratti;\ni bambini scolari sono pi√π abili con problemi astratti ma mostrano difficolt√† nel trasferire queste competenze in contesti pratici.\n\nQuesto risultato √® chiaro nei dati dello studio 3, illustrato dalla Figura 4 dell‚Äôarticolo.\n\n\n\n\n\nFigura¬†71.1: Confronto tra bambini lavoratori e non lavoratori in problemi astratti orali e problemi matematici di mercato (studio 3). A sinistra, confronto delle prestazioni dei bambini lavoratori e non lavoratori sui medesimi problemi astratti di sottrazione e divisione. Al centro, confronto delle prestazioni dei bambini lavoratori e non lavoratori sul problema matematico di mercato dopo un solo tentativo. A destra, confronto delle prestazioni dei bambini lavoratori e non lavoratori sul problema matematico di mercato dopo aver ricevuto un suggerimento per suddividere il problema e utilizzare strategie di arrotondamento. I problemi astratti orali e i problemi matematici di mercato non erano stati resi equivalenti per livello di difficolt√†. Le barre di errore mostrano gli intervalli di confidenza al 95% attorno alla media (media \\(\\pm\\) 1.96 \\(\\times\\) errore standard della media). I valori-p sono stati calcolati utilizzando test \\(t\\) di Student bilaterali senza correzioni per confronti multipli (figura tratta da Banerjee et al. (2025)).\n\n\nQuesti dati offrono un caso pratico per applicare modelli statistici che confrontano le proporzioni di successo tra due gruppi indipendenti. Nel caso presente, siamo interessati a stimare la differenza nella probabilit√† di risolvere correttamente un problema matematico tra i bambini lavoratori e quelli scolari. Utilizzando un approccio bayesiano, come descritto in precedenza, possiamo non solo quantificare questa differenza, ma anche valutare l‚Äôincertezza associata alla stima, fornendo cos√¨ una base solida per interpretare i risultati e trarre conclusioni.\nCi focalizzeremo sui pannelli di sinistra e centrale della figura per analizzare i risultati.\nPer quanto riguarda i problemi astratti, le prestazioni sono state le seguenti:\n\nI bambini lavoratori hanno ottenuto 670 successi su 1488 prove, corrispondenti a una proporzione di successo \\(p = 0.45\\).\nI bambini scolarizzati hanno raggiunto 320 successi su 542 prove, con una proporzione di successo \\(p = 0.59\\).\n\nInvece, per i problemi matematici di mercato, i risultati sono stati:\n\nI bambini lavoratori hanno registrato 134 successi su 373 prove, con una proporzione di successo \\(p = 0.36\\).\nI bambini scolarizzati hanno ottenuto solo 3 successi su 271 prove, equivalente a una proporzione di successo \\(p = 0.01\\).\n\nQuesta distribuzione evidenzia notevoli differenze nelle prestazioni tra i due gruppi nei diversi tipi di problemi.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>71</span>¬† <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#parallelo-tra-approccio-frequentista-e-bayesiano",
    "href": "chapters/linear_models/12_two_proportions.html#parallelo-tra-approccio-frequentista-e-bayesiano",
    "title": "71¬† Confronto tra due proporzioni indipendenti",
    "section": "\n71.6 Parallelo tra approccio frequentista e bayesiano",
    "text": "71.6 Parallelo tra approccio frequentista e bayesiano\nIl confronto tra le proporzioni di due gruppi indipendenti pu√≤ essere affrontato sia con un approccio frequentista, basato sulla distribuzione campionaria, sia con un approccio bayesiano, basato sull‚Äôaggiornamento delle credenze a posteriori. Vediamo i due approcci in dettaglio.\n\n71.6.1 Approccio Frequentista\nL‚Äôinferenza frequentista per il confronto tra due proporzioni si basa sulla distribuzione campionaria della differenza tra le proporzioni dei due gruppi. Supponiamo che i dati provengano da due campioni indipendenti di dimensioni \\(n_1\\) e \\(n_2\\), con proporzioni di successo \\(p_1\\) e \\(p_2\\), rispettivamente.\nLa differenza tra le proporzioni campionarie, \\(\\hat{p}_1 - \\hat{p}_2\\), segue una distribuzione approssimativamente normale, soprattutto quando le dimensioni dei campioni sono sufficientemente grandi (in genere, quando \\(n_1 p_1\\), \\(n_1 (1 - p_1)\\), \\(n_2 p_2\\) e \\(n_2 (1 - p_2)\\) sono tutti maggiori di 5). Questa approssimazione √® basata sul Teorema del Limite Centrale, che garantisce che la distribuzione della differenza tra le proporzioni campionarie tende a una distribuzione normale al crescere della dimensione del campione.\n\n71.6.1.1 Distribuzione della differenza tra proporzioni\nLa differenza \\(\\hat{p}_1 - \\hat{p}_2\\) ha una distribuzione normale con:\n\nValore atteso: \\[\nE(\\hat{p}_1 - \\hat{p}_2) = p_1 - p_2.\n\\] Questo significa che, in media, la differenza osservata tra le proporzioni campionarie riflette la differenza vera tra le proporzioni delle popolazioni.\nVarianza: \\[\nV(\\hat{p}_1 - \\hat{p}_2) = \\frac{p_1 (1 - p_1)}{n_1} + \\frac{p_2 (1 - p_2)}{n_2}.\n\\] La varianza della differenza dipende dalle proporzioni delle popolazioni e dalle dimensioni dei campioni. Maggiore √® la dimensione del campione, minore √® la varianza e quindi pi√π precisa √® la stima della differenza.\n\n71.6.1.2 Stima della varianza\nPoich√© le proporzioni delle popolazioni \\(p_1\\) e \\(p_2\\) sono generalmente sconosciute, utilizziamo le proporzioni campionarie \\(\\hat{p}_1\\) e \\(\\hat{p}_2\\) per stimare la varianza:\n\\[\nV(\\hat{p}_1 - \\hat{p}_2) \\approx \\frac{\\hat{p}_1 (1 - \\hat{p}_1)}{n_1} + \\frac{\\hat{p}_2 (1 - \\hat{p}_2)}{n_2}.\n\\]\n\n71.6.1.3 Intervallo di confidenza\nUn intervallo di confidenza per la differenza tra le proporzioni \\(p_1 - p_2\\) pu√≤ essere costruito utilizzando la distribuzione normale approssimata. L‚Äôintervallo di confidenza al 95% √® dato da:\n\\[\n(\\hat{p}_1 - \\hat{p}_2) \\pm z \\cdot \\sqrt{\\frac{\\hat{p}_1 (1 - \\hat{p}_1)}{n_1} + \\frac{\\hat{p}_2 (1 - \\hat{p}_2)}{n_2}},\n\\]\ndove \\(z\\) √® il valore critico della distribuzione normale standard (ad esempio, 1.96 per un intervallo di confidenza al 95%).\n\n71.6.1.4 Test di ipotesi\nPer testare l‚Äôipotesi nulla \\(H_0: p_1 = p_2\\) (cio√® che non c‚Äô√® differenza tra le proporzioni dei due gruppi), possiamo utilizzare una statistica test basata sulla differenza standardizzata tra le proporzioni campionarie:\n\\[\nZ = \\frac{\\hat{p}_1 - \\hat{p}_2}{\\sqrt{\\hat{p} (1 - \\hat{p}) \\left( \\frac{1}{n_1} + \\frac{1}{n_2} \\right)}},\n\\]\ndove \\(\\hat{p}\\) √® la proporzione pooled, calcolata come:\n\\[\n\\hat{p} = \\frac{n_1 \\hat{p}_1 + n_2 \\hat{p}_2}{n_1 + n_2}.\n\\]\nLa statistica \\(Z\\) segue una distribuzione normale standard sotto l‚Äôipotesi nulla. Se il valore assoluto di \\(Z\\) supera il valore critico (ad esempio, 1.96 per un livello di significativit√† del 5%), rifiutiamo l‚Äôipotesi nulla e concludiamo che c‚Äô√® una differenza significativa tra le proporzioni dei due gruppi.\n\n71.6.2 Vantaggi e limiti dell‚Äôapproccio frequentista\n\n\nVantaggi:\n\n√à un metodo ben consolidato e ampiamente utilizzato.\nFornisce risultati chiari e immediati, come intervalli di confidenza e p-value.\n√à relativamente semplice da applicare, soprattutto con software statistici.\n\n\n\nLimiti:\n\nL‚Äôapprossimazione normale funziona bene solo con campioni sufficientemente grandi. Per campioni piccoli o proporzioni vicine a 0 o 1, potrebbero essere necessari metodi alternativi.\nL‚Äôinterpretazione dei p-value pu√≤ essere fuorviante, soprattutto se non si considera l‚Äôeffetto della dimensione del campione.\nNon fornisce una stima diretta della probabilit√† che l‚Äôipotesi nulla sia vera, ma solo una misura di quanto i dati siano compatibili con essa.\n\n\n\nIn sintesi, l‚Äôapproccio frequentista offre un metodo robusto e intuitivo per confrontare due proporzioni, ma richiede attenzione alle condizioni di applicabilit√† e alla corretta interpretazione dei risultati.\n\n71.6.3 Esempio Pratico\nPer applicare l‚Äôapproccio frequentista ai dati forniti, possiamo utilizzare un test di proporzioni per confrontare le proporzioni di successo tra i bambini lavoratori e i bambini scolarizzati, sia per i problemi astratti che per i problemi matematici di mercato. L‚Äôapproccio frequentista si basa sull‚Äôuso di dati osservati per fare inferenze statistiche, e in questo caso, utilizzeremo un test z per proporzioni.\n\n71.6.4 1. Confronto per i problemi astratti\n\nIpotesi:\n\n\n\\(H_0\\): Non c‚Äô√® differenza tra le proporzioni di successo dei bambini lavoratori e dei bambini scolarizzati (\\(p_{\\text{lavoratori}} = p_{\\text{scolarizzati}}\\)).\n\n\\(H_1\\): C‚Äô√® una differenza tra le proporzioni di successo (\\(p_{\\text{lavoratori}} \\neq p_{\\text{scolarizzati}}\\)).\n\nDati:\n\nBambini lavoratori: 670 successi su 1488 prove, \\(p_{\\text{lavoratori}} = 0.45\\).\nBambini scolarizzati: 320 successi su 542 prove, \\(p_{\\text{scolarizzati}} = 0.59\\).\n\nCalcolo della statistica z:\nLa statistica z per il confronto di due proporzioni √® data da:\n\\[\nz = \\frac{p_1 - p_2}{\\sqrt{p(1 - p) \\left( \\frac{1}{n_1} + \\frac{1}{n_2} \\right)}}\n\\]\ndove \\(p\\) √® la proporzione complessiva di successi:\n\\[\np = \\frac{X_1 + X_2}{n_1 + n_2} = \\frac{670 + 320}{1488 + 542} = \\frac{990}{2030} \\approx 0.487\n\\]\nOra calcoliamo la statistica z:\n\\[\nz = \\frac{0.45 - 0.59}{\\sqrt{0.487 \\times (1 - 0.487) \\times \\left( \\frac{1}{1488} + \\frac{1}{542} \\right)}}\n\\]\n\\[\nz = \\frac{-0.14}{\\sqrt{0.487 \\times 0.513 \\times \\left( \\frac{1}{1488} + \\frac{1}{542} \\right)}}\n\\]\n\\[\nz = \\frac{-0.14}{\\sqrt{0.487 \\times 0.513 \\times (0.000672 + 0.001845)}}\n\\]\n\\[\nz = \\frac{-0.14}{\\sqrt{0.487 \\times 0.513 \\times 0.002517}}\n\\]\n\\[\nz = \\frac{-0.14}{\\sqrt{0.000629}}\n\\]\n\\[\nz = \\frac{-0.14}{0.0251} \\approx -5.58\n\\]\nConclusione: Il valore di z √® -5.58, che corrisponde a un p-value molto piccolo (inferiore a 0.0001). Pertanto, rifiutiamo l‚Äôipotesi nulla \\(H_0\\) e concludiamo che c‚Äô√® una differenza statisticamente significativa tra le proporzioni di successo dei bambini lavoratori e dei bambini scolarizzati nei problemi astratti.\n\n71.6.5 2. Confronto per i problemi matematici di mercato\n\nIpotesi:\n\n\n\\(H_0\\): Non c‚Äô√® differenza tra le proporzioni di successo dei bambini lavoratori e dei bambini scolarizzati (\\(p_{\\text{lavoratori}} = p_{\\text{scolarizzati}}\\)).\n\n\\(H_1\\): C‚Äô√® una differenza tra le proporzioni di successo (\\(p_{\\text{lavoratori}} \\neq p_{\\text{scolarizzati}}\\)).\n\nDati:\n\nBambini lavoratori: 134 successi su 373 prove, \\(p_{\\text{lavoratori}} = 0.36\\).\nBambini scolarizzati: 3 successi su 271 prove, \\(p_{\\text{scolarizzati}} = 0.01\\).\n\nCalcolo della statistica z:\nLa proporzione complessiva di successi √®:\n\\[\np = \\frac{134 + 3}{373 + 271} = \\frac{137}{644} \\approx 0.213\n\\]\nOra calcoliamo la statistica z:\n\\[\nz = \\frac{0.36 - 0.01}{\\sqrt{0.213 \\times (1 - 0.213) \\times \\left( \\frac{1}{373} + \\frac{1}{271} \\right)}}\n\\]\n\\[\nz = \\frac{0.35}{\\sqrt{0.213 \\times 0.787 \\times \\left( \\frac{1}{373} + \\frac{1}{271} \\right)}}\n\\]\n\\[\nz = \\frac{0.35}{\\sqrt{0.213 \\times 0.787 \\times (0.002681 + 0.00369)}}\n\\]\n\\[\nz = \\frac{0.35}{\\sqrt{0.213 \\times 0.787 \\times 0.006371}}\n\\]\n\\[\nz = \\frac{0.35}{\\sqrt{0.001067}}\n\\]\n\\[\nz = \\frac{0.35}{0.0327} \\approx 10.70\n\\]\nConclusione: Il valore di z √® 10.70, che corrisponde a un p-value molto piccolo (inferiore a 0.0001). Pertanto, rifiutiamo l‚Äôipotesi nulla \\(H_0\\) e concludiamo che c‚Äô√® una differenza statisticamente significativa tra le proporzioni di successo dei bambini lavoratori e dei bambini scolarizzati nei problemi matematici di mercato.\n\n71.6.6 Riassunto:\n\n\nProblemi astratti: C‚Äô√® una differenza significativa tra le proporzioni di successo dei bambini lavoratori e dei bambini scolarizzati (z = -5.58, p &lt; 0.0001).\n\nProblemi matematici di mercato: C‚Äô√® una differenza significativa tra le proporzioni di successo dei bambini lavoratori e dei bambini scolarizzati (z = 10.70, p &lt; 0.0001).\n\nIn entrambi i casi, i bambini scolarizzati hanno una proporzione di successo significativamente diversa rispetto ai bambini lavoratori.\n\n71.6.7 Svolgimento con R\nDi seguito mostriamo due modalit√† per replicare i calcoli in R: (1) passo passo usando le formule manuali, (2) usando la funzione prop.test() di R. Verranno illustrate entrambe le analisi: quella per i problemi astratti e quella per i problemi matematici di mercato.\n\n71.6.7.1 Problemi astratti\nDati\n\nBambini lavoratori (gruppo 1): 670 successi su 1488 prove.\nBambini scolarizzati (gruppo 2): 320 successi su 542 prove.\n\n\n# Dati\nX1 &lt;- 670\nn1 &lt;- 1488\nX2 &lt;- 320\nn2 &lt;- 542\n\n# Proporzioni campionarie\np1 &lt;- X1 / n1\np2 &lt;- X2 / n2\n\n# Proporzione pooled (combinata)\np_pool &lt;- (X1 + X2) / (n1 + n2)\n\n# Differenza fra le proporzioni\ndiff_p &lt;- p1 - p2\n\n# Calcolo della varianza della differenza (usando la formula per due proporzioni)\nvar_diff &lt;- p_pool * (1 - p_pool) * (1/n1 + 1/n2)\n\n# Deviazione standard della differenza\nsd_diff &lt;- sqrt(var_diff)\n\n# Statistica z\nz_value &lt;- diff_p / sd_diff\n\n# p-value (test a due code)\np_value &lt;- 2 * pnorm(abs(z_value), lower.tail = FALSE)\n\n# Visualizzazione risultati\nz_value\n#&gt; [1] -5.588\np_value\n#&gt; [1] 2.295e-08\n\nSpiegazione passaggi chiave:\n\nCalcoliamo le proporzioni empiriche: \\(p_1 = X_1 / n_1\\), \\(p_2 = X_2 / n_2\\).\nCalcoliamo la proporzione ‚Äúpooled‚Äù: \\(p_{\\mathrm{pool}} = \\frac{X_1 + X_2}{n_1 + n_2}\\).\nCalcoliamo la differenza delle proporzioni: \\(\\Delta p = p_1 - p_2\\).\nCalcoliamo la varianza (approssimata) della differenza, usando \\(p_{\\mathrm{pool}}\\) per lo stimatore comune.\nOtteniamo la statistica \\(z\\) come \\(\\frac{\\Delta p}{\\text{deviazione standard}}\\).\nIl p-value (a due code) si ottiene come \\(2 \\times P(Z &gt; |z|)\\), con pnorm che fornisce la distribuzione cumulativa della normale.\n\n71.6.7.2 Analisi con funzione prop.test()\n\nPer ottenere direttamente il test di confronto di due proporzioni, possiamo usare la funzione prop.test di R. Attenzione che, di default, prop.test effettua una correzione per la continuit√† (Yates), che in questo contesto di solito disattiviamo per confrontare i risultati con i calcoli manuali (impostando correct = FALSE).\n\n# Confronto due proporzioni senza correzione per la continuit√†\ntest_astratti &lt;- prop.test(\n  x = c(X1, X2),\n  n = c(n1, n2),\n  alternative = \"two.sided\",\n  correct = FALSE\n)\n\ntest_astratti\n#&gt; \n#&gt;  2-sample test for equality of proportions without continuity\n#&gt;  correction\n#&gt; \n#&gt; data:  c(X1, X2) out of c(n1, n2)\n#&gt; X-squared = 31, df = 1, p-value = 2e-08\n#&gt; alternative hypothesis: two.sided\n#&gt; 95 percent confidence interval:\n#&gt;  -0.18864 -0.09163\n#&gt; sample estimates:\n#&gt; prop 1 prop 2 \n#&gt; 0.4503 0.5904\n\nIl risultato fornir√†:\n\nStatistica di test (approx. z).\np-value.\nStima delle due proporzioni e dell‚Äôintervallo di confidenza della loro differenza.\n\n71.6.7.3 Problemi matematici di mercato\n\n# Dati\nX1_m &lt;- 134\nn1_m &lt;- 373\nX2_m &lt;- 3\nn2_m &lt;- 271\n\n# Proporzioni campionarie\np1_m &lt;- X1_m / n1_m\np2_m &lt;- X2_m / n2_m\n\n# Proporzione pooled\np_pool_m &lt;- (X1_m + X2_m) / (n1_m + n2_m)\n\n# Differenza di proporzioni\ndiff_p_m &lt;- p1_m - p2_m\n\n# Varianza della differenza (usando la proporzione pooled)\nvar_diff_m &lt;- p_pool_m * (1 - p_pool_m) * (1/n1_m + 1/n2_m)\n\n# Deviazione standard\nsd_diff_m &lt;- sqrt(var_diff_m)\n\n# Statistica z\nz_value_m &lt;- diff_p_m / sd_diff_m\n\n# p-value (test a due code)\np_value_m &lt;- 2 * pnorm(abs(z_value_m), lower.tail = FALSE)\n\n# Visualizzazione risultati\nz_value_m\n#&gt; [1] 10.66\np_value_m\n#&gt; [1] 1.581e-26\n\nAnalogamente a quanto fatto per i problemi astratti:\n\n# Confronto due proporzioni\ntest_mercato &lt;- prop.test(\n  x = c(X1_m, X2_m),\n  n = c(n1_m, n2_m),\n  alternative = \"two.sided\",\n  correct = FALSE\n)\n\ntest_mercato\n#&gt; \n#&gt;  2-sample test for equality of proportions without continuity\n#&gt;  correction\n#&gt; \n#&gt; data:  c(X1_m, X2_m) out of c(n1_m, n2_m)\n#&gt; X-squared = 114, df = 1, p-value &lt;2e-16\n#&gt; alternative hypothesis: two.sided\n#&gt; 95 percent confidence interval:\n#&gt;  0.2979 0.3984\n#&gt; sample estimates:\n#&gt;  prop 1  prop 2 \n#&gt; 0.35925 0.01107\n\n\n71.6.7.3.1 Interpretazione dei risultati\n\n\nProblemi astratti\n\nStatistica z (calcolo manuale): circa -5.58\n\np-value: molto piccolo (&lt;&lt; 0.001)\n\nConclusione: rifiutiamo \\(H_0\\) e concludiamo che le proporzioni di successo dei bambini lavoratori e scolarizzati sono significativamente diverse.\n\n\n\nProblemi matematici di mercato\n\nStatistica z (calcolo manuale): circa 10.70\n\np-value: estremamente piccolo (&lt;&lt; 0.001)\n\nConclusione: rifiutiamo \\(H_0\\) e concludiamo che anche in questo caso le proporzioni di successo dei due gruppi sono significativamente diverse.\n\n\n\nNota: I valori di z in prop.test() potrebbero risultare leggermente diversi a causa di eventuali arrotondamenti o correzioni implementate nella funzione. Assicurandoci di disattivare la correzione per la continuit√† (correct = FALSE), dovremmo comunque ottenere risultati molto simili a quelli dei calcoli manuali.\n\n71.6.8 Approccio Bayesiano\nL‚Äôapproccio bayesiano utilizza un modello di regressione con una variabile indicatrice (dummy) per distinguere i due gruppi.\nConsideriamo i problemi astratti. Utilizziamo il pacchetto brms per stimare il modello, con distribuzioni a priori debolmente informative:\n\nX1 &lt;- 670\nn1 &lt;- 1488\nX2 &lt;- 320\nn2 &lt;- 542\n\ndat_a &lt;- data.frame(\n  count = c(X1, X2),\n  tot = c(n1, n2),\n  group = c(\"working\", \"non-working\")\n)\ndat_a\n\n\nfit_a &lt;- brm(count | trials(tot) ~ group, data = dat_a, family = binomial())\n\n\nsummary(fit_a)\n#&gt;  Family: binomial \n#&gt;   Links: mu = logit \n#&gt; Formula: count | trials(tot) ~ group \n#&gt;    Data: dat_a (Number of observations: 2) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept        0.37      0.09     0.19     0.54 1.00     1561     2015\n#&gt; groupworking    -0.57      0.10    -0.77    -0.36 1.00     1873     1865\n#&gt; \n#&gt; Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n# Extract posterior draws of the Intercept and groupworking coefficients\npost &lt;- posterior_samples(fit_a) \n# or posterior_draws(fit_a) in newer versions\n\n# Probability for reference group = logistic(Intercept)\npost$p_ref &lt;- plogis(post$b_Intercept)\n\n# Probability for working group = logistic(Intercept + groupworking)\npost$p_work &lt;- plogis(post$b_Intercept + post$b_groupworking)\n\n# Now summarize\nsummary_ref  &lt;- quantile(post$p_ref,  probs = c(0.025, 0.5, 0.975))\nsummary_work &lt;- quantile(post$p_work, probs = c(0.025, 0.5, 0.975))\n\nsummary_ref\n#&gt;   2.5%    50%  97.5% \n#&gt; 0.5471 0.5907 0.6321\nsummary_work\n#&gt;   2.5%    50%  97.5% \n#&gt; 0.4243 0.4504 0.4762\n\n\n# 1. Extract samples\npost &lt;- as_draws_df(fit_a) \n\n# 2. Summaries on logit \n# b_groupworking\nb_groupworking_CI &lt;- quantile(post$b_groupworking, probs = c(0.025, 0.5, 0.975))\nprint(\"b_groupworking (log-odds) [2.5%, 50%, 97.5%]:\")\n#&gt; [1] \"b_groupworking (log-odds) [2.5%, 50%, 97.5%]:\"\nb_groupworking_CI\n#&gt;    2.5%     50%   97.5% \n#&gt; -0.7707 -0.5670 -0.3612\n\n# 3. Summaries on OR\npost$OR_groupworking &lt;- exp(post$b_groupworking)\nOR_groupworking_CI &lt;- quantile(post$OR_groupworking, probs = c(0.025, 0.5, 0.975))\nprint(\"Odds Ratio for 'working' vs. reference [2.5%, 50%, 97.5%]:\")\n#&gt; [1] \"Odds Ratio for 'working' vs. reference [2.5%, 50%, 97.5%]:\"\nOR_groupworking_CI\n#&gt;   2.5%    50%  97.5% \n#&gt; 0.4627 0.5672 0.6968\n\n# 4. Summaries on prob. scale\n\n# Probability reference group\npost$p_ref  &lt;- plogis(post$b_Intercept)\n\n# Probability working group\npost$p_work &lt;- plogis(post$b_Intercept + post$b_groupworking)\n\n# Difference on probability scale\npost$diff_p_work_ref &lt;- post$p_work - post$p_ref\n\nsummary_ref  &lt;- quantile(post$p_ref,  probs = c(0.025, 0.5, 0.975))\nsummary_work &lt;- quantile(post$p_work, probs = c(0.025, 0.5, 0.975))\ndiff_p_CI    &lt;- quantile(post$diff_p_work_ref, probs = c(0.025, 0.5, 0.975))\n\n\ncat(\"\\nReference group probability [2.5%, 50%, 97.5%]:\\n\")\n#&gt; \n#&gt; Reference group probability [2.5%, 50%, 97.5%]:\nprint(summary_ref)\n#&gt;   2.5%    50%  97.5% \n#&gt; 0.5471 0.5907 0.6321\n\n\ncat(\"\\nWorking group probability [2.5%, 50%, 97.5%]:\\n\")\n#&gt; \n#&gt; Working group probability [2.5%, 50%, 97.5%]:\nprint(summary_work)\n#&gt;   2.5%    50%  97.5% \n#&gt; 0.4243 0.4504 0.4762\n\n\ncat(\"\\nDifference in probability (Working - Reference) [2.5%, 50%, 97.5%]:\\n\")\n#&gt; \n#&gt; Difference in probability (Working - Reference) [2.5%, 50%, 97.5%]:\nprint(diff_p_CI)\n#&gt;     2.5%      50%    97.5% \n#&gt; -0.18948 -0.14056 -0.08989\n\nSi noti come, usando prior debolmente informativi, i risultati ottenuti con i due approcci (frequentista e bayesiano) sono praticamente equivalenti.\nCome abbiamo osservato nel caso del confronto tra medie, l‚Äôapproccio bayesiano √® pi√π utile perch√©:\n\nNon si basa su un‚Äôipotesi nulla idealizzata che sappiamo non essere vera.\nStima direttamente la nostra incertezza rispetto alla differenza tra le proporzioni, fornendo una risposta concreta e interpretabile in termini di probabilit√†.\nPermette di integrare le evidenze dei dati con la conoscenza preesistente, per ottenere inferenze pi√π realistiche e informate.\n\n71.6.9 Intervallo di credibilit√†\nPer ottenere l‚Äôintervallo di credibilit√† (Highest Density Interval, HDI) sulla scala delle probabilit√† (e non su quella logit), √® necessario trasformare manualmente i draw a livello di probabilit√† e poi calcolare l‚ÄôHDI su quei valori trasformati. In altre parole:\n\n\nEstraiamo i draw posteriori di b_Intercept e b_groupworking.\n\n\nTrasformiamo i valori con la funzione logit-inversa (\\(\\operatorname{logistic}(x) = 1/(1+e^{-x})\\)) per ottenere le probabilit√†.\n\n\nSe ci concentriamo sul solo effetto sulla scala della probabilit√† (e.g.¬†differenza fra i due gruppi), calcoliamo la differenza tra la probabilit√† del gruppo ‚Äúworking‚Äù e quella del gruppo ‚Äúreference‚Äù per ciascun draw.\n\n\nApplichiamo hdi() su queste grandezze trasformate.\n\nDi seguito √® fornito il codice R con il workflow completo.\n\nEstrazione draw posteriori.\n\n\npost &lt;- as_draws_df(fit_a)\n\n\n\nCalcolo delle probabilit√† per ciascun draw. La variabile ‚Äògroup‚Äô abbia due livelli:\n\n‚Äúworking‚Äù (effetto =&gt; b_groupworking)\n‚Äúnon-working‚Äù (riferimento =&gt; b_Intercept)\n\n\n\n\npost &lt;- post %&gt;%\n  dplyr::mutate(\n    p_ref      = plogis(b_Intercept),                       # probabilit√† (referenza)\n    p_working  = plogis(b_Intercept + b_groupworking),      # prob. gruppo working\n    diff_working_ref = p_working - p_ref                    # differenza\n  )\n\n\nCalcolo dell‚ÄôHDI sull‚Äôeffetto (o sulle probabilit√†).\n\n\nHDI per la probabilit√† del gruppo ‚Äúworking‚Äù.\n\n\n\nhdi_working_prob &lt;- hdi(post$p_working, ci = 0.95)\nhdi_working_prob\n#&gt; 95% HDI: [0.42, 0.48]\n\n\nHDI per la probabilit√† del gruppo ‚Äúnon-working‚Äù (riferimento).\n\n\nhdi_ref_prob &lt;- hdi(post$p_ref, ci = 0.95)\nhdi_ref_prob\n#&gt; 95% HDI: [0.55, 0.64]\n\n\nHDI della differenza fra le due probabilit√†.\n\n\nhdi_diff &lt;- hdi(post$diff_working_ref, ci = 0.89)\nhdi_diff\n#&gt; 89% HDI: [-0.18, -0.10]\n\nInterpretazione\n\n\nhdi_working_prob fornisce l‚ÄôHDI al 95% (o al livello che specifichi) della probabilit√† di ‚Äúsuccesso‚Äù del gruppo ‚Äúworking‚Äù.\n\n\nhdi_ref_prob fa lo stesso per il gruppo di riferimento.\n\n\nhdi_diff restituisce l‚ÄôHDI della differenza in probabilit√† tra ‚Äúworking‚Äù e ‚Äúreference‚Äù (\\(p_{\\text{working}} - p_{\\text{reference}}\\)).\n\nIn questo modo ottieniamo l‚Äôintervallo di credibilit√† (HDI) sulla scala delle probabilit√†.\n\n71.6.10 Distribuzione Predittiva a Posteriori\nEffettuiamo un controllo grafico per confrontare i dati osservati con quelli predetti dal modello:\n\npp_check(fit_a)",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>71</span>¬† <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#riflessioni-conclusive",
    "href": "chapters/linear_models/12_two_proportions.html#riflessioni-conclusive",
    "title": "71¬† Confronto tra due proporzioni indipendenti",
    "section": "\n71.7 Riflessioni Conclusive",
    "text": "71.7 Riflessioni Conclusive\nIn questo capitolo abbiamo esplorato il confronto tra due proporzioni (per esempio, la proporzione di successi in due gruppi indipendenti) adottando sia l‚Äôapproccio frequentista sia quello bayesiano. L‚Äôobiettivo principale era valutare se la proporzione di successi in un gruppo differisse da quella osservata nell‚Äôaltro gruppo, e con quale grado di incertezza.\n\n71.7.1 Approccio Frequentista\n\n\nStatistica di test e p-value: Nella procedura classica frequentista (test per due proporzioni), si calcola una statistica di test (ad esempio, un test z) e il relativo p-value, ossia la probabilit√† di osservare un risultato cos√¨ estremo (o pi√π) assumendo che le due proporzioni reali siano uguali (ipotesi nulla).\n\n\nIntervallo di confidenza: √à possibile costruire un intervallo di confidenza (IC) per la differenza tra le due proporzioni. L‚Äôinterpretazione frequentista di tale IC, per√≤, si basa su un‚Äôipotetica ripetizione di campionamenti ed √® focalizzata sull‚Äôeventuale rifiuto o meno dell‚Äôipotesi che la differenza sia zero.\n\n\nLimiti interpretativi: L‚Äôapproccio frequentista si fonda sul concetto di ipotesi nulla ‚Äúnessuna differenza‚Äù e non fornisce una probabilit√† diretta di quanto la differenza vera sia maggiore o minore di un certo valore, limitandosi a indicare se i dati sono inusuali qualora la differenza fosse zero.\n\n71.7.2 Approccio Bayesiano\n\n\nDistribuzione a posteriori: Grazie alla regola di Bayes, combiniamo informazioni a priori (sul probabile valore delle proporzioni) con i dati osservati, per ottenere una distribuzione a posteriori della differenza tra le due proporzioni. Questa distribuzione descrive i valori plausibili della differenza, insieme alle relative credibilit√† (probabilit√†).\n\n\nCredible Interval o Highest Density Interval (HDI): Al posto di un intervallo di confidenza, l‚Äôapproccio bayesiano fornisce un intervallo di credibilit√†. Ad esempio, un 95% HDI indica i valori della differenza tra le proporzioni che cumulativamente contengono il 95% della probabilit√† a posteriori. √à un costrutto immediatamente interpretabile: ‚ÄúAbbiamo una probabilit√† del 95% che la differenza vera cada all‚Äôinterno di questo intervallo‚Äù.\n\n\nFlessibilit√† e interpretazione diretta: L‚Äôapproccio bayesiano permette di rispondere in modo pi√π naturale a domande come: ‚ÄúQual √® la probabilit√† che la differenza fra le due proporzioni sia maggiore di 0?‚Äù oppure ‚ÄúQual √® la probabilit√† che la proporzione di un gruppo superi quella dell‚Äôaltro di almeno una certa soglia rilevante?‚Äù.\n\n71.7.3 Confronto tra i due approcci\n\n\nInterpretazione dei risultati: Il p-value frequentista ci dice quanto il dato sia ‚Äúimprobabile‚Äù sotto l‚Äôipotesi di uguaglianza delle proporzioni; il Bayesianesimo risponde direttamente a quanto √® plausibile ogni possibile valore di differenza.\n\n\nCentralit√† dell‚Äôipotesi nulla: Nel frequentismo, l‚Äôipotesi nulla (differenza = 0) √® centrale. Nel modello bayesiano, √® invece possibile assegnare direttamente probabilit√† alla differenza e alla sua distanza da zero, evitando un focus eccessivo sull‚Äôuguaglianza perfetta delle due proporzioni.\n\n\nRuolo dei priors: L‚Äôuso di priors (non informativi o informativi) pu√≤ influire sulle stime bayesiane quando i dati sono scarsi, rendendo evidente la necessit√† di scelte trasparenti e ben motivate. Tuttavia, con campioni ampi, l‚Äôinfluenza dei priors tende a ridursi e la stima a posteriori √® dominata dai dati.\n\n\nCompletezza dell‚Äôinferenza: L‚Äôapproccio bayesiano consente di integrare nuove informazioni e di aggiornare la distribuzione a posteriori man mano che arrivano dati aggiuntivi. Al contrario, l‚Äôapproccio frequentista non fornisce un meccanismo diretto di ‚Äúaggiornamento‚Äù delle stime alla luce di nuovi dati.\n\n71.7.4 Conclusioni Finali\n\n\nApproccio frequentista: Si tratta di una metodologia consolidata e standard nella ricerca; fornisce risultati in termini di p-value e IC, ma l‚Äôinterpretazione del p-value e dell‚ÄôIC resta legata a procedure di campionamento ipotetico.\n\n\nApproccio bayesiano: Offre una maniera pi√π intuitiva di quantificare l‚Äôincertezza, assegnando probabilit√† dirette ai possibili valori di differenza fra le due proporzioni. Consente di formulare domande pi√π specifiche (es. la probabilit√† che la differenza superi un valore definito) e di integrare in modo naturale informazioni a priori.\n\n\nScelta o integrazione: Nella pratica della ricerca, l‚Äôapproccio frequentista rimane diffuso. Tuttavia, l‚Äôinferenza bayesiana fornisce un quadro interpretativo pi√π ricco e flessibile. Utilizzare entrambi i metodi, quando appropriato, pu√≤ potenziare l‚Äôanalisi e la comprensione dei dati, permettendo di trarre conclusioni pi√π robuste e trasparenti.\n\nNel complesso, il confronto fra due proporzioni mostra chiaramente che la differenza tra l‚Äôottica frequentista e quella bayesiana non √® solo tecnica, ma anche concettuale: si tratta di due modi diversi di gestire l‚Äôincertezza e le ipotesi in gioco. Conoscere entrambi i paradigmi e i relativi vantaggi pu√≤ aiutare a scegliere l‚Äôapproccio pi√π adeguato alle finalit√† dello studio e alle domande di ricerca poste.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>71</span>¬† <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/12_two_proportions.html#informazioni-sullambiente-di-sviluppo",
    "title": "71¬† Confronto tra due proporzioni indipendenti",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] insight_1.1.0     bayestestR_0.15.2 posterior_1.6.1   cmdstanr_0.8.1   \n#&gt;  [5] brms_2.22.0       Rcpp_1.0.14       thematic_0.1.6    MetBrewer_0.2.0  \n#&gt;  [9] ggokabeito_0.1.0  see_0.11.0        gridExtra_2.3     patchwork_1.3.0  \n#&gt; [13] bayesplot_1.11.1  psych_2.5.3       scales_1.3.0      markdown_2.0     \n#&gt; [17] knitr_1.50        lubridate_1.9.4   forcats_1.0.0     stringr_1.5.1    \n#&gt; [21] dplyr_1.1.4       purrr_1.0.4       readr_2.1.5       tidyr_1.3.1      \n#&gt; [25] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [29] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1     farver_2.1.2         loo_2.8.0           \n#&gt;  [4] fastmap_1.2.0        TH.data_1.1-3        tensorA_0.36.2.1    \n#&gt;  [7] pacman_0.5.1         digest_0.6.37        timechange_0.3.0    \n#&gt; [10] estimability_1.5.1   lifecycle_1.0.4      StanHeaders_2.32.10 \n#&gt; [13] processx_3.8.6       survival_3.8-3       magrittr_2.0.3      \n#&gt; [16] compiler_4.4.2       rlang_1.1.5          tools_4.4.2         \n#&gt; [19] yaml_2.3.10          labeling_0.4.3       bridgesampling_1.1-2\n#&gt; [22] htmlwidgets_1.6.4    curl_6.2.2           pkgbuild_1.4.7      \n#&gt; [25] mnormt_2.1.1         plyr_1.8.9           abind_1.4-8         \n#&gt; [28] multcomp_1.4-28      withr_3.0.2          stats4_4.4.2        \n#&gt; [31] grid_4.4.2           inline_0.3.21        xtable_1.8-4        \n#&gt; [34] colorspace_2.1-1     emmeans_1.11.0       MASS_7.3-65         \n#&gt; [37] cli_3.6.4            mvtnorm_1.3-3        rmarkdown_2.29      \n#&gt; [40] generics_0.1.3       RcppParallel_5.1.10  rstudioapi_0.17.1   \n#&gt; [43] reshape2_1.4.4       tzdb_0.5.0           rstan_2.32.7        \n#&gt; [46] splines_4.4.2        parallel_4.4.2       matrixStats_1.5.0   \n#&gt; [49] vctrs_0.6.5          V8_6.0.2             Matrix_1.7-3        \n#&gt; [52] sandwich_3.1-1       jsonlite_1.9.1       callr_3.7.6         \n#&gt; [55] hms_1.1.3            glue_1.8.0           ps_1.9.0            \n#&gt; [58] codetools_0.2-20     distributional_0.5.0 stringi_1.8.4       \n#&gt; [61] gtable_0.3.6         QuickJSR_1.6.0       munsell_0.5.1       \n#&gt; [64] pillar_1.10.1        htmltools_0.5.8.1    Brobdingnag_1.2-9   \n#&gt; [67] R6_2.6.1             rprojroot_2.0.4      evaluate_1.0.3      \n#&gt; [70] lattice_0.22-6       backports_1.5.0      rstantools_2.4.0    \n#&gt; [73] coda_0.19-4.1        nlme_3.1-167         checkmate_2.3.2     \n#&gt; [76] xfun_0.51            zoo_1.8-13           pkgconfig_2.0.3",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>71</span>¬† <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#bibliografia",
    "href": "chapters/linear_models/12_two_proportions.html#bibliografia",
    "title": "71¬† Confronto tra due proporzioni indipendenti",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBanerjee, A. V., Bhattacharjee, S., Chattopadhyay, R., Duflo, E., Ganimian, A. J., Rajah, K., & Spelke, E. S. (2025). Children‚Äôs arithmetic skills do not transfer between applied and academic mathematics. Nature, 1‚Äì9.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>71</span>¬† <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html",
    "href": "chapters/linear_models/13_poisson_model.html",
    "title": "\n72¬† Modello di Poisson\n",
    "section": "",
    "text": "72.1 Introduzione\nNel precedente Capitolo 54 abbiamo visto come si ottiene la distribuzione a posteriori per i parametri di una Poisson con prior Gamma. Qui, costruiremo lo stesso tipo di analisi in R tramite brms.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>72</span>¬† <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#domanda-della-ricerca",
    "href": "chapters/linear_models/13_poisson_model.html#domanda-della-ricerca",
    "title": "\n72¬† Modello di Poisson\n",
    "section": "\n72.2 Domanda della ricerca",
    "text": "72.2 Domanda della ricerca\nCome spiegato qui, i dati che esamineremo sono raccolti dal Washington Post con lo scopo di registrare ogni sparatoria mortale negli Stati Uniti ad opera di agenti di polizia, a partire dal 1¬∞ gennaio 2015. Il Washington Post ha adottato un approccio sistematico e accurato nella raccolta di queste informazioni, fornendo dati che possono essere utili per valutare i problemi legati alla violenza delle forze di polizia negli Stati Uniti.\nLo scopo della presente analisi dei dati √® determinare il tasso di sparatorie fatali da parte della polizia negli Stati Uniti per ogni anno, e fornire una stima dell‚Äôincertezza associata a questo valore.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>72</span>¬† <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#importazione-e-pre-processing-dei-dati",
    "href": "chapters/linear_models/13_poisson_model.html#importazione-e-pre-processing-dei-dati",
    "title": "\n72¬† Modello di Poisson\n",
    "section": "\n72.3 Importazione e pre-processing dei dati",
    "text": "72.3 Importazione e pre-processing dei dati\nScarichiamo i dati direttamente da GitHub:\n\nurl &lt;- \"https://raw.githubusercontent.com/washingtonpost/data-police-shootings/master/v2/fatal-police-shootings-data.csv\"\nfps_dat &lt;- read.csv(url, stringsAsFactors = FALSE)\nhead(fps_dat)\n#&gt;   id       date threat_type flee_status armed_with          city\n#&gt; 1  3 2015-01-02       point         not        gun       Shelton\n#&gt; 2  4 2015-01-02       point         not        gun         Aloha\n#&gt; 3  5 2015-01-03        move         not    unarmed       Wichita\n#&gt; 4  8 2015-01-04       point         not    replica San Francisco\n#&gt; 5  9 2015-01-04       point         not      other         Evans\n#&gt; 6 11 2015-01-04      attack         not        gun       Guthrie\n#&gt;          county state latitude longitude location_precision\n#&gt; 1         Mason    WA    47.25   -123.12      not_available\n#&gt; 2    Washington    OR    45.49   -122.89      not_available\n#&gt; 3      Sedgwick    KS    37.69    -97.28      not_available\n#&gt; 4 San Francisco    CA    37.76   -122.42      not_available\n#&gt; 5          Weld    CO    40.38   -104.69      not_available\n#&gt; 6         Logan    OK    35.88    -97.42      not_available\n#&gt;                 name age gender race   race_source\n#&gt; 1         Tim Elliot  53   male    A not_available\n#&gt; 2   Lewis Lee Lembke  47   male    W not_available\n#&gt; 3 John Paul Quintero  23   male    H not_available\n#&gt; 4    Matthew Hoffman  32   male    W not_available\n#&gt; 5  Michael Rodriguez  39   male    H not_available\n#&gt; 6  Kenneth Joe Brown  18   male    W not_available\n#&gt;   was_mental_illness_related body_camera agency_ids\n#&gt; 1                       True       False         73\n#&gt; 2                      False       False         70\n#&gt; 3                      False       False        238\n#&gt; 4                       True       False        196\n#&gt; 5                      False       False        473\n#&gt; 6                      False       False        101\n\nConvertiamo la colonna delle date e creiamo la variabile ‚Äúyear‚Äù:\n\nfps_dat$date &lt;- as.Date(fps_dat$date)  # conversione in oggetto Date\nfps_dat$year &lt;- as.numeric(format(fps_dat$date, \"%Y\"))\n\nRimuoviamo eventuali osservazioni del 2025 (dato che √® incompleto):\n\nfps &lt;- subset(fps_dat, year != 2025)\ntable(fps$year)\n#&gt; \n#&gt; 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 \n#&gt;  995  959  984  992  993 1021 1050 1097 1164 1173\n\nCreiamo poi un data frame con i conteggi per anno:\n\nyear_counts &lt;- table(fps$year)\ndf &lt;- data.frame(\n  year   = as.numeric(names(year_counts)),\n  events = as.vector(year_counts)\n)\ndf\n#&gt;    year events\n#&gt; 1  2015    995\n#&gt; 2  2016    959\n#&gt; 3  2017    984\n#&gt; 4  2018    992\n#&gt; 5  2019    993\n#&gt; 6  2020   1021\n#&gt; 7  2021   1050\n#&gt; 8  2022   1097\n#&gt; 9  2023   1164\n#&gt; 10 2024   1173\n\nQui, df$events indica quante sparatorie fatali sono state registrate in ogni anno compreso tra il 2015 e il 2023 (estremi inclusi).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>72</span>¬† <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#modello-di-poisson",
    "href": "chapters/linear_models/13_poisson_model.html#modello-di-poisson",
    "title": "\n72¬† Modello di Poisson\n",
    "section": "\n72.4 Modello di Poisson",
    "text": "72.4 Modello di Poisson\nVogliamo stimare il parametro \\(\\lambda\\) della Poisson (tasso di sparatorie all‚Äôanno). Se denotiamo con \\(Y\\) il numero di sparatorie in un anno, l‚Äôassunto √®:\n\\[\nY \\sim \\text{Poisson}(\\lambda).\n\\]",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>72</span>¬† <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#distribuzione-a-priori",
    "href": "chapters/linear_models/13_poisson_model.html#distribuzione-a-priori",
    "title": "\n72¬† Modello di Poisson\n",
    "section": "\n72.5 Distribuzione a priori",
    "text": "72.5 Distribuzione a priori\n\n72.5.1 Motivazione\nScegliamo una distribuzione a priori su \\(\\lambda\\). In teoria, potremmo adottare una Gamma(\\(\\alpha, \\beta\\)) ‚Äúesplicita‚Äù. Tuttavia, brms richiede di specificare i prior nella forma pi√π consueta per i modelli GLM in Stan, ovvero sul log della media di Poisson (in quanto, per difetto, la famiglia Poisson usa il link log).\nSe desiderassimo imporre esattamente una prior Gamma su \\(\\lambda\\), potremmo dover ricorrere a definizioni custom in Stan. Di solito, per√≤, si sceglie una normal sul log(\\(\\lambda\\)) che approssimi bene la forma desiderata (la log-normal √® un‚Äôapprossimazione comune di una generica gamma).\n\n72.5.2 Esempio di prior per \\(\\lambda\\)\n\nIpotizziamo una media a priori di 600 e una deviazione standard di 200. Se vogliamo approssimare questa gamma con una log-normal, basta trovare media e dev. std. (sul log-scale) corrispondenti. Faremo una stima spannometrica direttamente:\n\nmedia del log(\\(\\lambda\\)) \\(\\approx \\log(600)\\approx 6.4\\).\ndev. std. \\(\\approx 0.3\\) (che d√† un intervallo ragionevole intorno a 600 \\(\\pm\\) qualche centinaio).\n\nCos√¨ scriviamo:\n\nprior_approx &lt;- c(\n  prior(normal(6.4, 0.3), class = \"Intercept\")  # normal su log(lambda)\n)\n\nIn tal modo, stiamo dicendo a brms che il log della media di Poisson (cio√® l‚ÄôIntercept del modello) segue pressappoco \\(\\mathcal{N}(6.4, 0.3^2)\\). Questo corrisponde a una distribuzione su \\(\\lambda\\) (\\(\\exp(\\log(\\)\\())\\)) i cui valori plausibili si aggirano intorno a 600.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>72</span>¬† <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#stima-del-tasso-annuo",
    "href": "chapters/linear_models/13_poisson_model.html#stima-del-tasso-annuo",
    "title": "\n72¬† Modello di Poisson\n",
    "section": "\n72.6 Stima del tasso annuo",
    "text": "72.6 Stima del tasso annuo\n\n72.6.1 Costruzione del modello in brms\nCreiamo un modello di Poisson semplicissimo: un unico intercept (cio√® ipotizziamo che in tutti gli anni il tasso sia costante). Chiaramente questa √® un‚Äôapprossimazione: si potrebbe estendere per anno, trend, ecc. Ma qui mostriamo solo la logica gamma-Poisson di base.\n\n# df ha due colonne: year, events\n# Poich√© brms si aspetta le \"osservazioni\" riga per riga,\n# creeremo un data frame in cui ogni riga rappresenta un anno\n# e la colonna events √® il numero di sparatorie di quell'anno.\n\nm0 &lt;- brm(\n  formula = events ~ 1, # solo intercetta\n  family  = poisson(link = \"log\"),\n  data    = df,\n  prior   = prior_approx,\n  iter    = 3000, # numero di iterazioni (warmup+sampling)\n  warmup  = 1000,\n  chains  = 4,\n  seed    = 123\n)\n\nTerminato l‚Äôaddestramento del modello, esaminiamo un sommario dei parametri:\n\nsummary(m0)\n#&gt;  Family: poisson \n#&gt;   Links: mu = log \n#&gt; Formula: events ~ 1 \n#&gt;    Data: df (Number of observations: 10) \n#&gt;   Draws: 4 chains, each with iter = 3000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 8000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept     6.95      0.01     6.93     6.97 1.00     2879     3532\n#&gt; \n#&gt; Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nUscita tipica (semplificata):\n\n\nb_Intercept: stima dell‚Äôintercetta sullo scale log.\n\nEst.Error: errore standard a posteriori.\n\nl-95% CI e u-95% CI: limiti dell‚Äôintervallo di credibilit√† (IC) al 95% predefinito.\n\nPer ottenere il tasso \\(\\lambda\\) a posteriori possiamo ricorrere a:\n\n# Ottieni i campioni posteriori usando as_draws\nposterior_draws_m0 &lt;- as_draws(m0)\n\n# Estrai i campioni dell'intercetta (b_Intercept)\nb_Intercept_draws &lt;- posterior_draws_m0 %&gt;% \n  tidybayes::spread_draws(b_Intercept)\n\n# Converti i campioni in lambda (exp(b_Intercept))\nlambda_draws &lt;- exp(b_Intercept_draws$b_Intercept)\n\n# Calcola i quantili\nquantile(lambda_draws, probs = c(0.03, 0.5, 0.97))\n#&gt;   3%  50%  97% \n#&gt; 1022 1042 1061\n\nSe vogliamo un IC al 94% (invece del 95%), basta:\n\nquantile(lambda_draws, probs = c(0.03, 0.5, 0.97)) \n#&gt;   3%  50%  97% \n#&gt; 1022 1042 1061\n\no pi√π elegantemente:\n\ntidybayes::median_qi(lambda_draws, .width = 0.94)\n#&gt;      y ymin ymax .width .point .interval\n#&gt; 1 1042 1022 1061   0.94 median        qi\n\nQuesto ci dar√† una stima mediana a posteriori di \\(\\lambda\\) e l‚Äôintervallo di credibilit√† al 94%.\n\n72.6.2 Visualizzazione\nPossiamo infine tracciare la densit√† a posteriori del parametro \\(\\lambda\\):\n\ntibble(lambda = lambda_draws) %&gt;%\n  ggplot(aes(x = lambda)) +\n  stat_halfeye(fill = \"skyblue\", alpha = 0.6) +\n  labs(\n    title = \"Distribuzione a posteriori di Œª (tasso Poisson annuo)\",\n    x = \"Œª\",\n    y = \"Densit√† a posteriori\"\n  )\n\n\n\n\n\n\n\nIn sostanza, otteniamo (come nel caso Stan/Python) una stima del tasso \\(\\lambda\\) e un intervallo di incertezza.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>72</span>¬† <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#derivazione-analitica-breve-richiamo",
    "href": "chapters/linear_models/13_poisson_model.html#derivazione-analitica-breve-richiamo",
    "title": "\n72¬† Modello di Poisson\n",
    "section": "\n72.7 Derivazione analitica (breve richiamo)",
    "text": "72.7 Derivazione analitica (breve richiamo)\nQuando la verosimiglianza √® di tipo Poisson e si usa un prior Gamma(\\(\\alpha_0\\), \\(\\beta_0\\)), la posterior di \\(\\lambda\\) rimane gamma, con parametri aggiornati:\n\n\\(\\alpha_{\\text{post}} = \\alpha_0 + \\sum y_i\\)\n\n\\(\\beta_{\\text{post}}  = \\beta_0 + n\\),\n\ndove \\(n\\) √® il numero di osservazioni (in questo caso, anni) e \\(y_i\\) sono i conteggi. brms di default usa la scala log per le stime e calcola la posterior via MCMC. La soluzione chiusa rimane utile come conferma analitica.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>72</span>¬† <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#vittime-non-armate",
    "href": "chapters/linear_models/13_poisson_model.html#vittime-non-armate",
    "title": "\n72¬† Modello di Poisson\n",
    "section": "\n72.8 Vittime non armate",
    "text": "72.8 Vittime non armate\nRiprendiamo ora l‚Äôargomento di (Ross et al., 2021) sul differente tasso di sparatorie fatali tra persone di razza caucasica (bianche) e non-caucasica, limitandoci ai casi in cui la vittima risulti disarmata.\n\n72.8.1 Pre-processing dei dati\nFiltriamo i casi ‚Äúunarmed‚Äù:\n\nfps_unarmed &lt;- subset(fps, armed_with == \"unarmed\")\n\nSepariamo in due gruppi:\n\nwhite_df    &lt;- subset(fps_unarmed, race == \"W\")\nnon_white_df &lt;- subset(fps_unarmed, race != \"W\")\n\nVerifichiamo:\n\nhead(white_df)\n#&gt;      id       date threat_type flee_status armed_with        city\n#&gt; 9    16 2015-01-06    accident         not    unarmed  Burlington\n#&gt; 73  342 2015-01-29        move        foot    unarmed  Stillwater\n#&gt; 77  114 2015-02-02        flee        foot    unarmed Hummelstown\n#&gt; 120 159 2015-02-17        flee        foot    unarmed Springfield\n#&gt; 137 371 2015-02-23        move         not    unarmed       Omaha\n#&gt; 141 180 2015-02-26      threat         not    unarmed Terre Haute\n#&gt;         county state latitude longitude location_precision\n#&gt; 9   Des Moines    IA    40.81    -91.12      not_available\n#&gt; 73       Payne    OK    36.12    -97.05      not_available\n#&gt; 77     Dauphin    PA    40.27    -76.71      not_available\n#&gt; 120     Greene    MO    37.23    -93.32      not_available\n#&gt; 137    Douglas    NE    41.24    -95.93      not_available\n#&gt; 141       Vigo    IN    39.46    -87.38      not_available\n#&gt;                       name age gender race   race_source\n#&gt; 9            Autumn Steele  34 female    W not_available\n#&gt; 73            Ralph Willis  42   male    W not_available\n#&gt; 77           David Kassick  59   male    W not_available\n#&gt; 120        Michael Ireland  31   male    W not_available\n#&gt; 137           Daniel Elrod  39   male    W not_available\n#&gt; 141 Alexander Phillip Long  31   male    W not_available\n#&gt;     was_mental_illness_related body_camera agency_ids year\n#&gt; 9                        False        True        287 2015\n#&gt; 73                       False       False        164 2015\n#&gt; 77                       False       False        303 2015\n#&gt; 120                      False       False        350 2015\n#&gt; 137                      False       False        158 2015\n#&gt; 141                      False       False   377;3612 2015\n\n\nhead(non_white_df)\n#&gt;      id       date threat_type flee_status armed_with        city   county\n#&gt; 3     5 2015-01-03        move         not    unarmed     Wichita Sedgwick\n#&gt; 18   36 2015-01-08      attack         not    unarmed      Strong    Union\n#&gt; 63  352 2015-01-26        flee         car    unarmed      Tahoka     Lynn\n#&gt; 84  116 2015-02-04      attack         not    unarmed Tallahassee     Leon\n#&gt; 87  125 2015-02-04    accident         not    unarmed       Tempe Maricopa\n#&gt; 101 138 2015-02-10        flee        foot    unarmed       Pasco Franklin\n#&gt;     state latitude longitude location_precision                    name age\n#&gt; 3      KS    37.69    -97.28      not_available      John Paul Quintero  23\n#&gt; 18     AR    33.11    -92.36      not_available     Artago Damon Howard  36\n#&gt; 63     TX    33.17   -101.67      not_available      Joshua Omar Garcia  24\n#&gt; 84     FL    30.47    -84.33      not_available             Jeremy Lett  28\n#&gt; 87     AZ    33.38   -111.98      not_available       Joaquin Hernandez  28\n#&gt; 101    WA    46.23   -119.10      not_available Antonio Zambrano-Montes  35\n#&gt;     gender race   race_source was_mental_illness_related body_camera\n#&gt; 3     male    H not_available                      False       False\n#&gt; 18    male    B not_available                      False       False\n#&gt; 63    male    H not_available                      False       False\n#&gt; 84    male    B not_available                      False       False\n#&gt; 87    male    H not_available                      False       False\n#&gt; 101   male    H not_available                       True       False\n#&gt;           agency_ids year\n#&gt; 3                238 2015\n#&gt; 18               249 2015\n#&gt; 63               179 2015\n#&gt; 84               311 2015\n#&gt; 87  247;195;2267;319 2015\n#&gt; 101              331 2015\n\nOra costruiamo i conteggi anno per anno nei due gruppi:\n\ncount_white &lt;- table(white_df$year)\nevents_by_year_white &lt;- data.frame(\n  year = as.numeric(names(count_white)),\n  event_count = as.vector(count_white)\n)\n\ncount_non_white &lt;- table(non_white_df$year)\nevents_by_year_non_white &lt;- data.frame(\n  year = as.numeric(names(count_non_white)),\n  event_count = as.vector(count_non_white)\n)\n\n\nevents_by_year_white\n#&gt;    year event_count\n#&gt; 1  2015          31\n#&gt; 2  2016          29\n#&gt; 3  2017          29\n#&gt; 4  2018          26\n#&gt; 5  2019          26\n#&gt; 6  2020          27\n#&gt; 7  2021           7\n#&gt; 8  2022          23\n#&gt; 9  2023          18\n#&gt; 10 2024           6\n\n\nevents_by_year_non_white\n#&gt;    year event_count\n#&gt; 1  2015          63\n#&gt; 2  2016          35\n#&gt; 3  2017          40\n#&gt; 4  2018          33\n#&gt; 5  2019          28\n#&gt; 6  2020          34\n#&gt; 7  2021          26\n#&gt; 8  2022          28\n#&gt; 9  2023          33\n#&gt; 10 2024          22\n\n\n72.8.2 Una prior plausibile\nDalle medie dei due campioni, immaginiamo di mettere una prior lognormale su \\(\\lambda\\) attorno a 30 (dev. std. \\(\\approx 10\\)). Approfittiamo di un‚Äôulteriore approssimazione:\n\n# prior ~ lognormal(meanlog = 3.4, sdlog = 0.3) ~ circa media 30, sd ~10\nprior_unarmed &lt;- c(\n  prior(normal(3.4, 0.3), class = \"Intercept\")\n)\n\n\n72.8.3 Stima separata per i due gruppi\n\n72.8.3.1 Gruppo caucasico (white)\n\nm_white &lt;- brm(\n  formula = event_count ~ 1,\n  family  = poisson(link = \"log\"),\n  data    = events_by_year_white,\n  prior   = prior_unarmed,\n  iter    = 3000, warmup = 1000, seed = 123\n)\n\n\nsummary(m_white)\n#&gt;  Family: poisson \n#&gt;   Links: mu = log \n#&gt; Formula: event_count ~ 1 \n#&gt;    Data: events_by_year_white (Number of observations: 10) \n#&gt;   Draws: 4 chains, each with iter = 3000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 8000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept     3.11      0.07     2.98     3.24 1.00     2896     4026\n#&gt; \n#&gt; Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nOtteniamo la posterior su \\(\\lambda_{\\text{white}}\\):\n\n# Ottieni i campioni posteriori usando as_draws\nposterior_draws_m_white &lt;- as_draws(m_white)\n\n# Estrai i campioni dell'intercetta (b_Intercept)\nb_Intercept_draws &lt;- posterior_draws_m_white %&gt;% \n  tidybayes::spread_draws(b_Intercept)\n\n# Converti i campioni in lambda (exp(b_Intercept))\nlambda_draws &lt;- exp(b_Intercept_draws$b_Intercept)\n\nmedian_qi(lambda_draws, .width = 0.94)\n#&gt;       y  ymin  ymax .width .point .interval\n#&gt; 1 22.45 19.76 25.33   0.94 median        qi\n\n\n72.8.3.2 Gruppo non-caucasico\n\nm_non_white &lt;- brm(\n  formula = event_count ~ 1,\n  family  = poisson(link = \"log\"),\n  data    = events_by_year_non_white,\n  prior   = prior_unarmed,\n  iter    = 3000, warmup = 1000, seed = 123\n)\n\n\nsummary(m_non_white)\n#&gt;  Family: poisson \n#&gt;   Links: mu = log \n#&gt; Formula: event_count ~ 1 \n#&gt;    Data: events_by_year_non_white (Number of observations: 10) \n#&gt;   Draws: 4 chains, each with iter = 3000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 8000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept     3.53      0.05     3.42     3.63 1.00     3028     3565\n#&gt; \n#&gt; Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nEstraiamo la posterior e calcoliamo l‚Äôintervallo di credibilit√†:\n\n# Ottieni i campioni posteriori usando as_draws\nposterior_draws_m_non_white &lt;- as_draws(m_non_white)\n\n# Estrai i campioni dell'intercetta (b_Intercept)\nb_Intercept_draws &lt;- posterior_draws_m_non_white %&gt;% \n  tidybayes::spread_draws(b_Intercept)\n\n# Converti i campioni in lambda (exp(b_Intercept))\nlambda_draws &lt;- exp(b_Intercept_draws$b_Intercept)\n\nmedian_qi(lambda_draws, .width = 0.94)\n#&gt;       y  ymin  ymax .width .point .interval\n#&gt; 1 34.01 30.62 37.48   0.94 median        qi\n\nIl confronto tra i due intervalli di credibilit√†, come gi√† visto in precedenza, indica che il tasso di vittime disarmate (per anno) sia pi√π elevato tra i non-caucasici rispetto ai caucasici.\n\n72.8.4 Modello congiunto (due gruppi in un unico fit)\nPossiamo anche costruire un unico modello che stimi congiuntamente i due tassi e la loro differenza. Per far ci√≤, costruiamo un data frame in cui ogni riga √® un anno-gruppo:\n\nevents_white    &lt;- events_by_year_white %&gt;%\n  mutate(group = \"White\")\n\nevents_nonwhite &lt;- events_by_year_non_white %&gt;%\n  mutate(group = \"NonWhite\")\n\ndf_groups &lt;- bind_rows(events_white, events_nonwhite) %&gt;%\n  arrange(year, group)\n\ndf_groups\n#&gt;    year event_count    group\n#&gt; 1  2015          63 NonWhite\n#&gt; 2  2015          31    White\n#&gt; 3  2016          35 NonWhite\n#&gt; 4  2016          29    White\n#&gt; 5  2017          40 NonWhite\n#&gt; 6  2017          29    White\n#&gt; 7  2018          33 NonWhite\n#&gt; 8  2018          26    White\n#&gt; 9  2019          28 NonWhite\n#&gt; 10 2019          26    White\n#&gt; 11 2020          34 NonWhite\n#&gt; 12 2020          27    White\n#&gt; 13 2021          26 NonWhite\n#&gt; 14 2021           7    White\n#&gt; 15 2022          28 NonWhite\n#&gt; 16 2022          23    White\n#&gt; 17 2023          33 NonWhite\n#&gt; 18 2023          18    White\n#&gt; 19 2024          22 NonWhite\n#&gt; 20 2024           6    White\n\nOra adattiamo un modello con un effetto fittizio per ogni gruppo (senza intercetta globale, se vogliamo stime distinte e dirette sul link log):\n\n# Il simbolo 0 + group rimuove l‚Äôintercetta e stima un parametro di log-tasso\n# per il gruppo White e un altro per NonWhite.\n\nm_groups &lt;- brm(\n  formula = event_count ~ 0 + group,  # 2 coefficienti: groupWhite, groupNonWhite\n  family  = poisson(link = \"log\"),\n  data    = df_groups,\n  prior   = c(\n    prior(normal(3.4, 0.3), class=\"b\", coef=\"groupWhite\"),\n    prior(normal(3.4, 0.3), class=\"b\", coef=\"groupNonWhite\")\n  ),\n  iter = 3000, warmup = 1000, chains = 4, seed=123\n)\n\nsummary(m_groups)\n\nNell‚Äôoutput avremo:\n\n\nb_groupWhite: stima log(\\(\\lambda_{\\text{white}}\\))\n\nb_groupNonWhite: stima log(\\(\\lambda_{\\text{nonwhite}}\\))\n\n\n72.8.4.1 Calcolo della differenza delle frequenze attese\nSe vogliamo la differenza sulla scala naturale (cio√® \\(\\lambda_{\\text{nonwhite}} - \\lambda_{\\text{white}}\\)), basta estrarre i campioni e poi calcolare:\n\npost_mg &lt;- posterior_samples(m_groups)\nlambda_white_mg    &lt;- exp(post_mg$b_groupWhite)\nlambda_nonwhite_mg &lt;- exp(post_mg$b_groupNonWhite)\ndiff_lambda &lt;- lambda_nonwhite_mg - lambda_white_mg\n\nmedian_qi(diff_lambda, .width = 0.94)\n#&gt;       y  ymin  ymax .width .point .interval\n#&gt; 1 11.54 7.126 15.99   0.94 median        qi\n\nSe questo IC al 94% sta tutto sopra lo zero, possiamo concludere che \\(\\lambda_{\\text{nonwhite}} &gt; \\lambda_{\\text{white}}\\) con alta credibilit√†.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>72</span>¬† <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#riflessioni-conclusive",
    "href": "chapters/linear_models/13_poisson_model.html#riflessioni-conclusive",
    "title": "\n72¬† Modello di Poisson\n",
    "section": "\n72.9 Riflessioni Conclusive",
    "text": "72.9 Riflessioni Conclusive\nSulla base dei risultati ottenuti dal modello di Poisson, possiamo trarre le seguenti conclusioni:\n\nIl tasso stimato di incidenza delle vittime disarmate uccise dalla polizia negli Stati Uniti √® pi√π alto per il gruppo non caucasico rispetto al gruppo caucasico. La differenza media stimata tra i due tassi di incidenza √® di 11.508, con una deviazione standard di 2.586. Questo significa che, in media, il tasso per il gruppo non caucasico √® di circa 11.5 punti superiore rispetto al tasso per il gruppo caucasico.\nL‚Äôintervallo di credibilit√† al 94% per questa differenza va da 6.792 a 16.443, indicando che √® molto probabile che la vera differenza tra i tassi di incidenza dei due gruppi si trovi all‚Äôinterno di questo intervallo. Questo intervallo di credibilit√† non include lo zero, il che fornisce ulteriore evidenza che il tasso di incidenza per il gruppo non caucasico √® effettivamente pi√π alto rispetto al gruppo caucasico.\n\nInoltre, i tassi di incidenza stimati per ciascun gruppo sono i seguenti:\n\nGruppo non caucasico: tasso medio di 35.577 con un intervallo di credibilit√† al 94% tra 31.978 e 39.260.\nGruppo caucasico: tasso medio di 24.069 con un intervallo di credibilit√† al 94% tra 21.098 e 27.285.\n\nQuesti risultati indicano chiaramente che il gruppo non caucasico ha un tasso di incidenza pi√π alto di vittime disarmate uccise dalla polizia rispetto al gruppo caucasico. L‚Äôintervallo di credibilit√† per ciascun tasso fornisce una stima robusta e credibile della variabilit√† di questi tassi.\nIn sintesi, il modello di Poisson fornisce una forte evidenza che esiste una differenza robusta tra i tassi di incidenza dei due gruppi, con il gruppo non caucasico che presenta un tasso pi√π elevato di vittime disarmate uccise dalla polizia rispetto al gruppo caucasico.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>72</span>¬† <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#esercizi",
    "href": "chapters/linear_models/13_poisson_model.html#esercizi",
    "title": "\n72¬† Modello di Poisson\n",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nNella finale olimpica di calcio 2024, la Spagna ha sconfitto la Francia per 5 a 3. Supponiamo di voler calcolare la probabilit√† di superiorit√† della Spagna rispetto alla Francia utilizzando un modello coniugato Gamma-Poisson (o l‚Äôapprossimazione brms con prior lognormale).\n\nConsidera che il numero di gol segnati da una squadra segua una Poisson con parametro \\(\\lambda\\).\n\nSpecifica un prior su \\(\\lambda\\) per entrambe le squadre, ad esempio \\(\\alpha=1\\) e \\(\\beta=1\\) nella parametrizzazione Gamma classica (oppure una Normal(0,1.4) sull‚Äôintercetta, in modo da avere una media a posteriori analoga).\n\nAggiorna la distribuzione a posteriori conoscendo i gol segnati (5 per la Spagna e 3 per la Francia in una singola partita).\n\nCalcola la probabilit√† che \\(\\lambda_{\\text{Spagna}} &gt; \\lambda_{\\text{Francia}}\\).\n\n(Ispirato a ‚ÄúThe World Cup Problem‚Äù, (Downey, 2021).)\nSuggerimento: puoi risolvere il problema in modo analitico (Gamma-Poisson con un solo conteggio) oppure puoi usare brms costruendo un dataframe:\ndf_soccer &lt;- data.frame(\n  team = c(\"Spain\", \"France\"),\n  goals = c(5, 3)\n)\n\nModello: goals ~ 0 + team, family=poisson().\nPrior su b_teamSpain e b_teamFrance.\nInfine, estrai i draws e calcola la probabilit√† \\(\\Pr(\\exp(b_{\\text{Spain}}) &gt; \\exp(b_{\\text{France}}))\\).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>72</span>¬† <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/13_poisson_model.html#informazioni-sullambiente-di-sviluppo",
    "title": "\n72¬† Modello di Poisson\n",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] tidybayes_3.0.7  brms_2.22.0      Rcpp_1.0.14      HDInterval_0.2.4\n#&gt;  [5] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [9] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.5.3     \n#&gt; [13] scales_1.3.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [17] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [21] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [25] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] mnormt_2.1.1         inline_0.3.21        sandwich_3.1-1      \n#&gt;  [4] rlang_1.1.5          magrittr_2.0.3       multcomp_1.4-28     \n#&gt;  [7] matrixStats_1.5.0    compiler_4.4.2       loo_2.8.0           \n#&gt; [10] callr_3.7.6          vctrs_0.6.5          reshape2_1.4.4      \n#&gt; [13] pkgconfig_2.0.3      arrayhelpers_1.1-0   fastmap_1.2.0       \n#&gt; [16] backports_1.5.0      labeling_0.4.3       rmarkdown_2.29      \n#&gt; [19] tzdb_0.5.0           ps_1.9.0             xfun_0.51           \n#&gt; [22] jsonlite_1.9.1       parallel_4.4.2       R6_2.6.1            \n#&gt; [25] stringi_1.8.4        StanHeaders_2.32.10  estimability_1.5.1  \n#&gt; [28] rstan_2.32.7         zoo_1.8-13           pacman_0.5.1        \n#&gt; [31] Matrix_1.7-3         splines_4.4.2        timechange_0.3.0    \n#&gt; [34] tidyselect_1.2.1     rstudioapi_0.17.1    abind_1.4-8         \n#&gt; [37] yaml_2.3.10          codetools_0.2-20     curl_6.2.2          \n#&gt; [40] processx_3.8.6       pkgbuild_1.4.7       lattice_0.22-6      \n#&gt; [43] plyr_1.8.9           withr_3.0.2          bridgesampling_1.1-2\n#&gt; [46] posterior_1.6.1      coda_0.19-4.1        evaluate_1.0.3      \n#&gt; [49] survival_3.8-3       RcppParallel_5.1.10  ggdist_3.3.2        \n#&gt; [52] pillar_1.10.1        tensorA_0.36.2.1     checkmate_2.3.2     \n#&gt; [55] stats4_4.4.2         distributional_0.5.0 generics_0.1.3      \n#&gt; [58] rprojroot_2.0.4      hms_1.1.3            rstantools_2.4.0    \n#&gt; [61] munsell_0.5.1        xtable_1.8-4         glue_1.8.0          \n#&gt; [64] emmeans_1.11.0       tools_4.4.2          mvtnorm_1.3-3       \n#&gt; [67] grid_4.4.2           QuickJSR_1.6.0       colorspace_2.1-1    \n#&gt; [70] nlme_3.1-167         cli_3.6.4            svUnit_1.0.6        \n#&gt; [73] Brobdingnag_1.2-9    V8_6.0.2             gtable_0.3.6        \n#&gt; [76] digest_0.6.37        TH.data_1.1-3        htmlwidgets_1.6.4   \n#&gt; [79] farver_2.1.2         htmltools_0.5.8.1    lifecycle_1.0.4     \n#&gt; [82] MASS_7.3-65",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>72</span>¬† <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#bibliografia",
    "href": "chapters/linear_models/13_poisson_model.html#bibliografia",
    "title": "\n72¬† Modello di Poisson\n",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nDowney, A. B. (2021). Think Bayes. \" O‚ÄôReilly Media, Inc.\".\n\n\nRoss, C. T., Winterhalder, B., & McElreath, R. (2021). Racial disparities in police use of deadly force against unarmed individuals persist after appropriately benchmarking shooting data on violent crime rates. Social Psychological and Personality Science, 12(3), 323‚Äì332.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>72</span>¬† <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/introduction_frequentist_inference.html",
    "href": "chapters/frequentist_inference/introduction_frequentist_inference.html",
    "title": "Introduzione",
    "section": "",
    "text": "Differenze fondamentali tra i due approcci\nCome discusso nel capitolo dedicato all‚Äôinterpretazione delle probabilit√† (25¬† Interpretazione della probabilit√†), esistono due principali approcci nell‚Äôinferenza statistica: la statistica frequentista e la statistica bayesiana. Entrambi i metodi consentono di trarre conclusioni sulla popolazione di interesse attraverso l‚Äôanalisi dei dati e vengono utilizzati per stimare quantit√† sconosciute, formulare previsioni e testare ipotesi. Tuttavia, differiscono nell‚Äôinterpretazione della probabilit√† e nel modo in cui integrano le conoscenze pregresse e le evidenze disponibili.",
    "crumbs": [
      "Frequentismo",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/introduction_frequentist_inference.html#differenze-fondamentali-tra-i-due-approcci",
    "href": "chapters/frequentist_inference/introduction_frequentist_inference.html#differenze-fondamentali-tra-i-due-approcci",
    "title": "Introduzione",
    "section": "",
    "text": "Statistica frequentista\nNella statistica frequentista, la probabilit√† √® interpretata come la frequenza relativa di un evento in un numero infinito di prove. Questo approccio assume che il valore vero di un parametro della popolazione sia fisso ma sconosciuto e che debba essere stimato esclusivamente dai dati osservati. Le inferenze statistiche vengono effettuate attraverso metodi quali:\n\nStima puntuale: fornisce un singolo valore come miglior stima del parametro.\nIntervalli di confidenza: definiscono un intervallo in cui il parametro si trova con una data probabilit√†, sotto ripetute campionature.\nTest di ipotesi: valutano la compatibilit√† dei dati con un‚Äôipotesi nulla, attraverso il calcolo di p-value e statistiche test.\n\nQuesto approccio si basa su assunzioni riguardanti il processo che genera i dati e sull‚Äôidea che la verit√† statistica emerga dal comportamento asintotico di esperimenti ripetuti.\n\n\nStatistica bayesiana\nNella statistica bayesiana, la probabilit√† rappresenta un grado di credenza in un evento, soggetto ad aggiornamento alla luce di nuove evidenze (Jaynes, 2003). Questo approccio si fonda sull‚Äôapplicazione del teorema di Bayes, che consente di aggiornare la conoscenza su un parametro in base ai dati osservati.\n\nIl valore del parametro √® trattato come una variabile casuale con una distribuzione di probabilit√†.\nL‚Äôanalisi parte da una distribuzione a priori, che rappresenta la conoscenza precedente.\nI nuovi dati vengono combinati con la distribuzione a priori tramite la verosimiglianza (likelihood).\nIl risultato √® la distribuzione a posteriori, che sintetizza l‚Äôincertezza aggiornata sul parametro.\n\nQuesto approccio permette di incorporare informazioni pregresse ed √® particolarmente utile in contesti con dati limitati o conoscenze precedenti rilevanti.",
    "crumbs": [
      "Frequentismo",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/introduction_frequentist_inference.html#il-problema-dellinduzione-di-hume",
    "href": "chapters/frequentist_inference/introduction_frequentist_inference.html#il-problema-dellinduzione-di-hume",
    "title": "Introduzione",
    "section": "Il problema dell‚Äôinduzione di Hume",
    "text": "Il problema dell‚Äôinduzione di Hume\nUna prospettiva utile per comprendere la differenza tra questi due approcci √® il problema dell‚Äôinduzione, formulato da David Hume nel 1739 nel suo A Treatise of Human Nature (Hacking, 2006). Hume solleva un dubbio fondamentale: come possiamo giustificare le inferenze dal passato al futuro? Nessuna quantit√† di osservazioni passate garantisce che il futuro seguir√† lo stesso schema.\n\nL‚Äôapproccio frequentista presuppone implicitamente che il mondo segua regolarit√† statistiche costanti. Tuttavia, questo assunto √® vulnerabile alle critiche di Hume, poich√© non offre una giustificazione epistemica all‚Äôestrapolazione del passato.\nL‚Äôapproccio bayesiano integra l‚Äôincertezza nell‚Äôinferenza: la probabilit√† di un evento futuro √® un riflesso delle nostre credenze attuali e viene aggiornata alla luce di nuove osservazioni. Questo approccio si adatta meglio a situazioni in cui il mondo potrebbe non seguire regolarit√† fisse.",
    "crumbs": [
      "Frequentismo",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/introduction_frequentist_inference.html#un-esempio-pratico-il-lancio-di-una-moneta",
    "href": "chapters/frequentist_inference/introduction_frequentist_inference.html#un-esempio-pratico-il-lancio-di-una-moneta",
    "title": "Introduzione",
    "section": "Un esempio pratico: il lancio di una moneta",
    "text": "Un esempio pratico: il lancio di una moneta\nConsideriamo il classico esempio del lancio di una moneta per illustrare le differenze tra i due approcci:\n\nFrequentista: definisce la probabilit√† di ottenere testa come la proporzione di teste osservate in un numero infinito di lanci. La probabilit√† √® una propriet√† intrinseca della moneta, indipendente dalle credenze dell‚Äôosservatore.\nBayesiano: parte da una distribuzione a priori sulla probabilit√† della moneta di cadere su testa. Dopo ogni lancio, aggiorna la credenza utilizzando la verosimiglianza, ottenendo una nuova distribuzione a posteriori. Questo metodo riflette un aggiornamento razionale delle credenze alla luce di nuove osservazioni.\n\nL‚Äôapproccio bayesiano √® quindi pi√π flessibile e coerente con la prospettiva di Hume: accetta l‚Äôincertezza del futuro e la gestisce attraverso un meccanismo di aggiornamento continuo.",
    "crumbs": [
      "Frequentismo",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/introduction_frequentist_inference.html#obiettivo-di-questa-sezione",
    "href": "chapters/frequentist_inference/introduction_frequentist_inference.html#obiettivo-di-questa-sezione",
    "title": "Introduzione",
    "section": "Obiettivo di questa sezione",
    "text": "Obiettivo di questa sezione\nIn questa sezione della dispensa, esamineremo in dettaglio i metodi della statistica frequentista, tra cui la stima puntuale, gli intervalli di confidenza e il test di ipotesi. Questi strumenti costituiscono il nucleo dell‚Äôinferenza statistica tradizionale e offrono un quadro solido per analizzare i dati in assenza di informazioni pregresse. Tuttavia, come evidenziato dal problema di Hume, ogni approccio ha i suoi limiti e presupposti. La scelta tra frequentismo e bayesianesimo dipende dal contesto e dagli obiettivi dell‚Äôanalisi.",
    "crumbs": [
      "Frequentismo",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/introduction_frequentist_inference.html#bibliografia",
    "href": "chapters/frequentist_inference/introduction_frequentist_inference.html#bibliografia",
    "title": "Introduzione",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nHacking, I. (2006). The emergence of probability: A philosophical study of early ideas about probability, induction and statistical inference. Cambridge University Press.\n\n\nJaynes, E. T. (2003). Probability theory: The logic of science. Cambridge University Press.",
    "crumbs": [
      "Frequentismo",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html",
    "title": "73¬† Inferenza frequentista",
    "section": "",
    "text": "73.1 Introduzione\nIn questo capitolo esamineremo le radici storiche della statistica frequentista e le sue connessioni con il movimento eugenetico. Vedremo come alcune idee sviluppate nel contesto di questa corrente abbiano influenzato l‚Äôelaborazione dei metodi statistici che molti di noi utilizzano ancora oggi.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>73</span>¬† <span class='chapter-title'>Inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#i-frequentisti-sono-razzisti",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#i-frequentisti-sono-razzisti",
    "title": "73¬† Inferenza frequentista",
    "section": "\n73.2 I Frequentisti sono Razzisti?",
    "text": "73.2 I Frequentisti sono Razzisti?\nNel Capitolo 30, abbiamo esplorato le origini storiche e il contesto culturale che hanno portato all‚Äôinterpretazione del teorema di Bayes proposta da Richard Price. Quelle origini, legate alla rivoluzione americana, rappresentano il ‚Äúlato luminoso‚Äù del liberalismo moderno.\nLe origini dell‚Äôapproccio frequentista, invece, si collocano agli antipodi: sono strettamente intrecciate con ci√≤ che potremmo definire la ‚Äúparte oscura‚Äù della modernit√†. L‚Äôavversione per la soggettivit√†, tipica del frequentismo, riflette una visione pi√π rigida e deterministica, distante dall‚Äôapertura e dalla flessibilit√† del pensiero bayesiano.\n\n73.2.1 Francis Galton e l‚ÄôEugenetica\nFrancis Galton (1822-1911), cugino di Charles Darwin, fu un esploratore, un medico e un pioniere della meteorologia. Ma il suo contributo pi√π importante, e anche pi√π controverso, riguard√≤ la statistica e lo studio dell‚Äôereditariet√† del talento.\n\n\nDistribuzione Normale e Regressione\nGalton formalizz√≤ la distribuzione normale e introdusse il concetto di ‚Äúregressione verso la media‚Äù, chiamata inizialmente ‚Äúregressione verso la mediocrit√†‚Äù.\n\n\nHereditary Genius\nNel suo libro Hereditary Genius, Galton sosteneva che il talento fosse trasmesso all‚Äôinterno di specifiche famiglie. Fu lui a coniare la famosa espressione ‚Äúnature and nurture‚Äù per indicare il ruolo combinato di eredit√† e ambiente nello sviluppo umano.\n\n\nEugenetica\nGalton mirava a ‚Äúmigliorare la specie umana‚Äù promuovendo la riproduzione tra famiglie ritenute ‚Äúdi successo‚Äù e scoraggiandola tra quelle considerate ‚Äúinferiori‚Äù. Le sue idee, fortemente razziste, includevano l‚Äôidea che gli africani fossero ‚Äúinferiori‚Äù e ‚Äúpigri‚Äù, gli arabi ‚Äúsemplici consumatori della produzione altrui‚Äù e che gli anglosassoni fossero la ‚Äúrazza superiore‚Äù.\n\n73.2.2 L‚ÄôImpatto di Galton su Pearson e Fisher\nLe teorie di Galton influenzarono Karl Pearson (1857-1936) e Ronald Fisher (1890-1962), due figure chiave della statistica moderna. Entrambi condividevano idee razziste e appoggiavano l‚Äôeugenetica:\n\n\nKarl Pearson\nProfessore all‚ÄôUniversity College di Londra, svilupp√≤ strumenti come il test del chi quadrato e la deviazione standard. Eredit√≤ la cattedra di eugenetica fondata da Galton.\n\n\nRonald Fisher\nConsiderato uno dei padri della statistica moderna, svilupp√≤ l‚Äôanalisi della varianza (ANOVA), il concetto di significativit√† statistica e il metodo della massima verosimiglianza (MLE).\n\nQuesti autori cercarono di allontanare la statistica dalla prospettiva di Laplace e Bayes, rifiutando l‚Äôidea di introdurre componenti soggettive nella loro ‚Äúscienza‚Äù. Volevano che la statistica apparisse del tutto ‚Äúoggettiva‚Äù per sostenere teorie eugenetiche e gerarchie razziali come se fossero dimostrate scientificamente.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>73</span>¬† <span class='chapter-title'>Inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#implicazioni-per-le-pratiche-correnti",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#implicazioni-per-le-pratiche-correnti",
    "title": "73¬† Inferenza frequentista",
    "section": "\n73.3 Implicazioni per le Pratiche Correnti",
    "text": "73.3 Implicazioni per le Pratiche Correnti\nIn che misura dovremmo considerare le implicazioni storiche ed etiche del frequentismo quando lo utilizziamo oggi? Secondo (Chivers, 2024), sebbene sia evidente che l‚Äôideologia razziale nazista possa essere collegata alle idee di Galton, la questione centrale in statistica rimane: ‚ÄúQuale approccio √® metodologicamente corretto?‚Äù o, pi√π pragmaticamente, ‚ÄúQuale approccio √® pi√π utile?‚Äù.\nTuttavia, limitarsi a un dibattito puramente metodologico rischia di trascurare il fatto che la scienza non si svolge in una ‚Äútorre d‚Äôavorio‚Äù astratta, ma ha conseguenze concrete. Se una teoria A, pur essendo efficace in uno scenario ideale, ha effetti profondamente negativi nella realt√†, dovremmo davvero adottarla acriticamente? La risposta, per molti, √® no.\nNel caso del frequentismo, non solo emergono questioni etiche, ma ‚Äì come vedremo in seguito ‚Äì si evidenziano anche limiti metodologici. La sua pretesa di ‚Äúoggettivit√†‚Äù si rivela un‚Äôillusione quando si analizza in profondit√† il funzionamento reale delle procedure inferenziali. In psicologia, dove la variabilit√† individuale e le questioni etiche sono centrali, questi difetti possono avere conseguenze particolarmente dannose.\n\n\n\n\n\n\nNota didattica: L‚Äôapproccio frequentista viene presentato qui soprattutto per mostrare perch√© il suo uso esclusivo sia problematico. In questo capitolo descriveremo i fondamenti statistici del frequentismo e la logica delle sue procedure inferenziali. Nel capitoli successivi discuteremo invece come le sue applicazioni pratiche possano ostacolare il progresso della psicologia.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>73</span>¬† <span class='chapter-title'>Inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#il-paradigma-frequentista",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#il-paradigma-frequentista",
    "title": "73¬† Inferenza frequentista",
    "section": "\n73.4 Il Paradigma Frequentista",
    "text": "73.4 Il Paradigma Frequentista\nL‚Äôobiettivo della statistica frequentista √® trarre conclusioni su un‚Äôintera popolazione partendo da un campione di dati. In questo contesto:\n\nI dati osservati vengono considerati come un‚Äôestrazione casuale (un ‚Äúcampione‚Äù) da una popolazione pi√π ampia.\n\nIl modello statistico assume che esista un processo generatore dei dati, descritto da una distribuzione di probabilit√†.\n\nQuando raccogliamo un campione di dati, dobbiamo tenere presente che avremmo potuto ottenere molti altri campioni diversi (il principio di ripetizione del campionamento).\n\n\n73.4.1 Probabilit√† e Ripetizione del Campionamento\nIl frequentismo adotta un‚Äôinterpretazione della probabilit√† basata sulle frequenze: se ripetessimo un esperimento moltissime volte, la probabilit√† di un evento sarebbe il rapporto tra il numero di volte in cui l‚Äôevento si verifica e il numero totale di prove.\n\n73.4.2 Stima di un Parametro\nSupponiamo di voler stimare un parametro (ad esempio, la media di una popolazione). Il frequentismo cerca un stimatore ‚Äì una funzione del campione ‚Äì che abbia determinate propriet√†, tra cui l‚Äôassenza di distorsione (l‚Äôunbiasedness) e la consistenza (la vicinanza alla realt√† con l‚Äôaumentare del numero di dati).\nUn esempio comune √® la stima della media della popolazione tramite la media del campione. Sotto certe condizioni, si pu√≤ dimostrare che, ripetendo l‚Äôesperimento moltissime volte, la media del campione in media coincider√† con la vera media della popolazione.\n\n73.4.3 Intervalli di Confidenza\nNell‚Äôapproccio frequentista, invece di fornire un singolo valore come stima di un parametro, si costruisce un intervallo di confidenza. L‚Äôidea fondamentale √® che, se ripetessimo molte volte la stessa procedura di campionamento e di calcolo dell‚Äôintervallo, una certa percentuale di questi (ad esempio il 95%) conterr√† effettivamente il valore vero del parametro.\nPrima di raccogliere i dati, gli estremi di questo intervallo (i ‚Äúlimiti di confidenza‚Äù) sono variabili casuali, perch√© dipendono dal campione che otterremo. Di conseguenza, la probabilit√† (per esempio, il 95%) si riferisce alla procedura di costruzione dell‚Äôintervallo, non all‚Äôintervallo in s√© dopo l‚Äôosservazione dei dati. Una volta infatti che il campione √® stato raccolto e l‚Äôintervallo √® stato calcolato, quest‚Äôultimo √® un oggetto ‚Äúfisso‚Äù: o contiene il valore vero del parametro, o non lo contiene; non √® pi√π possibile attribuirgli una probabilit√† di contenere il parametro. L‚Äôaffermazione ‚Äúintervallo di confidenza al 95%‚Äù significa dunque che, sul lungo periodo, usando sempre la stessa procedura, il 95% degli intervalli costruiti conterr√† il parametro vero.\n\n73.4.4 Test delle Ipotesi: Approccio Frequentista e Limitazioni\nNel contesto del test di un‚Äôipotesi (ad esempio, \\(H_0\\): ‚Äúla media di una popolazione √® uguale a 0‚Äù), l‚Äôapproccio frequentista definisce una regione di rifiuto in base a un livello di significativit√† prefissato (ad esempio, \\(\\alpha = 0.05\\)). Se il risultato dell‚Äôanalisi (come il p-value) cade all‚Äôinterno di questa regione, si procede a rifiutare \\(H_0\\); altrimenti, si manca di rifiutare \\(H_0\\) (ovvero, non si rifiuta l‚Äôipotesi nulla).\n\n\nErrore di tipo I (falso positivo): si verifica quando si rifiuta \\(H_0\\) nonostante essa sia vera.\n\n\nErrore di tipo II (falso negativo): si verifica quando non si rifiuta \\(H_0\\) nonostante essa sia falsa.\n\nNel paradigma frequentista, il ricercatore controlla la probabilit√† di questi errori, in particolare l‚Äôerrore di tipo I, attraverso la scelta di \\(\\alpha\\) e il calcolo di indicatori come il p-value. Tuttavia, questo approccio presenta alcune criticit√†:\n\nDecisione dicotomica\nIl test conduce a una scelta binaria (rifiutare o non rifiutare \\(H_0\\)), che pu√≤ risultare eccessivamente rigida. I fenomeni reali spesso non si prestano a una categorizzazione netta basata su una soglia arbitraria, rendendo la distinzione ‚Äúsignificativo/non significativo‚Äù potenzialmente fuorviante. Una visione pi√π sfumata, che consideri l‚Äôentit√† dell‚Äôeffetto e l‚Äôincertezza, potrebbe essere pi√π informativa.\nSoglia arbitraria\nIl valore di \\(\\alpha\\) (comunemente fissato a 0.05) √® in gran parte una convenzione. Ad esempio, un valore-p di 0.049 porta al rifiuto di \\(H_0\\), mentre un valore-p di 0.051 non lo fa, nonostante la differenza tra i due casi sia minima. Questa arbitrariet√† pu√≤ influenzare in modo significativo l‚Äôinterpretazione dei risultati, creando una discontinuit√† artificiale.\nNessuna prova diretta di verit√†/falsit√†\nUn valore-p basso non implica che \\(H_0\\) sia ‚Äúfalsa‚Äù o che un‚Äôipotesi alternativa sia ‚Äúvera‚Äù. Indica semplicemente che, assumendo \\(H_0\\) vera, dati simili (o pi√π estremi) sarebbero rari sotto ripetuti campionamenti. Il test frequentista non fornisce una risposta alla domanda ‚ÄúQual √® la probabilit√† che \\(H_0\\) sia vera?‚Äù, limitando la sua capacit√† di supportare inferenze dirette sulla veridicit√† delle ipotesi.\n\nQueste criticit√† evidenziano come la rigidit√† del test (basato su una decisione binaria) e l‚Äôuso di soglie fisse possano risultare problematici, specialmente in discipline come la psicologia, dove le misurazioni sono spesso affette da rumore e le differenze tra condizioni possono essere sottili. Un approccio pi√π flessibile, che integri la stima degli effetti, gli intervalli di confidenza e una valutazione contestuale, potrebbe offrire una comprensione pi√π robusta e sfumata dei dati.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>73</span>¬† <span class='chapter-title'>Inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#riflessioni-conclusive",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#riflessioni-conclusive",
    "title": "73¬† Inferenza frequentista",
    "section": "\n73.5 Riflessioni Conclusive",
    "text": "73.5 Riflessioni Conclusive\nIn questo capitolo abbiamo mostrato come la statistica frequentista, pur essendo stata un pilastro dell‚Äôinferenza moderna, affondi le proprie radici in idee profondamente problematiche, come l‚Äôeugenetica e il razzismo sostenuti da Galton, Pearson e Fisher. Sebbene oggi queste teorie sembrino superate e distanti dalle nostre pratiche di laboratorio, conoscerne la genesi aiuta a comprendere come l‚Äôidea di un‚Äôoggettivit√† assoluta sia stata impiegata per legittimare visioni ideologiche discutibili.\nParallelamente, la riflessione storica solleva interrogativi sul metodo e sulle sue implicazioni pratiche. La metafora della ‚Äútorre d‚Äôavorio‚Äù mostra quanto sia pericoloso trattare la scienza come un sistema chiuso, ignorando le conseguenze etiche e sociali. Nel campo della psicologia, in particolare, la crisi di replicabilit√† (McElreath, 2020) rivela come l‚Äôuso acritico di procedure frequentiste possa influire sulla validit√† dei risultati.\nIn definitiva, il frequentismo non va considerato solo come un insieme di tecniche, ma come un paradigma con implicazioni culturali, etiche e metodologiche. Nel prossimo capitolo mostreremo come le applicazioni pratiche dell‚Äôapproccio frequentista possano risultare limitanti e, talvolta, dannose per il progresso della psicologia (Gelman et al., 1995). Conoscere le basi e le implicazioni di tale paradigma √® il primo passo per un uso pi√π consapevole e responsabile degli strumenti statistici.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>73</span>¬† <span class='chapter-title'>Inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#informazioni-sullambiente-di-sviluppo",
    "title": "73¬† Inferenza frequentista",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.5.3     \n#&gt;  [9] scales_1.3.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.9.1   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         rlang_1.1.5       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       tools_4.4.2       parallel_4.4.2    tzdb_0.5.0       \n#&gt; [21] colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5       R6_2.6.1         \n#&gt; [25] lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.1    \n#&gt; [29] gtable_0.3.6      glue_1.8.0        xfun_0.51         tidyselect_1.2.1 \n#&gt; [33] rstudioapi_0.17.1 farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-167     \n#&gt; [37] rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>73</span>¬† <span class='chapter-title'>Inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#bibliografia",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#bibliografia",
    "title": "73¬† Inferenza frequentista",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nChivers, T. (2024). Everything is Predictable: How Bayesian Statistics Explain Our World. Simon; Schuster.\n\n\nGelman, A., Carlin, J. B., Stern, H. S., & Rubin, D. B. (1995). Bayesian data analysis. Chapman; Hall/CRC.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>73</span>¬† <span class='chapter-title'>Inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01a_stime_parametri.html",
    "href": "chapters/frequentist_inference/01a_stime_parametri.html",
    "title": "74¬† Stime, stimatori e parametri",
    "section": "",
    "text": "74.1 Introduzione\nIn questo capitolo, ci concentreremo sul concetto di distribuzione campionaria, uno dei pilastri dell‚Äôinferenza statistica frequentista. La distribuzione campionaria descrive come le stime dei parametri della popolazione, come la media o la varianza, variano da campione a campione. Essa permette di stabilire propriet√† probabilistiche delle stime campionarie, come la loro media e varianza, che sono fondamentali per costruire intervalli di confidenza e condurre test di ipotesi, strumenti essenziali dell‚Äôinferenza statistica frequentista.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>74</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01a_stime_parametri.html#introduzione",
    "href": "chapters/frequentist_inference/01a_stime_parametri.html#introduzione",
    "title": "74¬† Stime, stimatori e parametri",
    "section": "",
    "text": "Domande introduttive\n\n\n\nPrima di iniziare a esplorare il concetto di distribuzione campionaria e il suo ruolo nell‚Äôinferenza statistica, considera le seguenti domande. Prova a formulare una risposta intuitiva basata sulle tue conoscenze attuali prima di procedere con la lettura del capitolo. Le simulazioni che seguiranno ti aiuteranno a confermare o rivedere le tue risposte.\n\nSe estraiamo ripetutamente campioni casuali dalla stessa popolazione e calcoliamo la loro media, come saranno distribuite queste medie campionarie rispetto alla media della popolazione?\nSupponiamo di estrarre campioni di dimensione \\(n=2\\) da una popolazione. L‚Äôinsieme delle medie campionarie sar√† pi√π concentrato intorno alla media della popolazione rispetto ai valori individuali della popolazione stessa?\nQuale relazione esiste tra la dimensione del campione \\(n\\) e la variabilit√† delle medie campionarie? In altre parole, se aumentiamo la dimensione del campione, cosa succede alla dispersione della distribuzione campionaria?\nLa distribuzione campionaria della media campionaria sar√† sempre normale? Quali fattori influenzano la sua forma?\nLa media della distribuzione campionaria coincide sempre con la media della popolazione? E la sua varianza √® maggiore o minore rispetto alla varianza della popolazione?\nSupponiamo di estrarre piccoli campioni da una popolazione che ha una distribuzione fortemente asimmetrica. Quale forma avr√† la distribuzione delle medie campionarie per piccoli campioni? E per campioni pi√π grandi?",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>74</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01a_stime_parametri.html#stime-stimatori-e-parametri",
    "href": "chapters/frequentist_inference/01a_stime_parametri.html#stime-stimatori-e-parametri",
    "title": "74¬† Stime, stimatori e parametri",
    "section": "\n74.2 Stime, stimatori e parametri",
    "text": "74.2 Stime, stimatori e parametri\nDopo aver esplorato il contesto culturale del frequentismo nel capitolo precedente, ci spostiamo ora su un piano strettamente statistico per introdurre il concetto di stima statistica.\nQuando si analizzano i dati, l‚Äôobiettivo √® spesso quello di ottenere informazioni su una caratteristica della popolazione. Tuttavia, nella maggior parte dei casi, si ha accesso solo a un campione di osservazioni. La quantit√† sconosciuta che vogliamo stimare viene chiamata parametro, mentre il valore che calcoliamo dal campione per approssimare questo parametro √® la stima. La formula o il procedimento matematico che utilizziamo per ottenere la stima √® detto stimatore. Formalmente, uno stimatore √® una funzione dei dati osservati utilizzata per produrre una stima di un parametro.\nIn altre parole, quando analizziamo un campione, cerchiamo di inferire propriet√† della popolazione da cui il campione √® tratto. Il parametro rappresenta una misura di queste propriet√†, ma raramente pu√≤ essere calcolato direttamente sulla popolazione intera. Pertanto, utilizziamo le osservazioni campionarie per ottenere una stima del parametro. La stima √® quindi un‚Äôapprossimazione del valore del parametro basata sui dati raccolti, mentre lo stimatore √® la regola matematica o statistica che la produce.\n√à importante sottolineare che le stime non coincidono necessariamente con il vero valore del parametro, poich√© sono soggette a incertezza dovuta alla variabilit√† del campionamento. In questo capitolo esamineremo come l‚Äôapproccio frequentista quantifica questa incertezza e come possiamo utilizzare tale quantificazione per trarre conclusioni affidabili sui parametri di interesse.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>74</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01a_stime_parametri.html#distribuzione-campionaria",
    "href": "chapters/frequentist_inference/01a_stime_parametri.html#distribuzione-campionaria",
    "title": "74¬† Stime, stimatori e parametri",
    "section": "\n74.3 Distribuzione campionaria",
    "text": "74.3 Distribuzione campionaria\nNell‚Äôinferenza frequentista applicata alla psicologia, il parametro di maggiore interesse √® spesso la media della popolazione‚Äîsi veda anche la discussione nella Sezione 19.9.1. In questo capitolo esploreremo come la media di un campione casuale possa essere utilizzata per stimare la media \\(\\mu\\) di una popolazione. Per valutare l‚Äôincertezza associata a questa stima, introdurremo il concetto di distribuzione campionaria, un principio fondamentale dell‚Äôapproccio frequentista.\nPer chiarire questa idea, inizieremo con un esempio basato su una popolazione finita di piccole dimensioni, pur consapevoli che le propriet√† illustrate si estendono anche a popolazioni di dimensioni maggiori.\n\n74.3.1 Esempio introduttivo\nConsideriamo la seguente popolazione:\n\nx &lt;- c(2, 4.5, 5, 5.5)\nx\n#&gt; [1] 2.0 4.5 5.0 5.5\n\nQuesti valori potrebbero rappresentare il tempo di reazione (in secondi) di quattro partecipanti a un esperimento di decisione rapida, in cui devono identificare il colore di uno stimolo visivo. In questo caso, l‚Äôintera popolazione √® costituita da tutti i partecipanti disponibili per lo studio, ad esempio se l‚Äôesperimento √® stato condotto in un piccolo gruppo di persone selezionate per caratteristiche specifiche, come quattro gemelli monozigoti in uno studio sulle differenze cognitive intra-familiari.\nL‚Äôistogramma sottostante rappresenta la distribuzione di frequenza della popolazione:\n\n# Creazione del dataframe\ndf &lt;- data.frame(Valori = c(2, 4.5, 5, 5.5))\n\n# Istogramma con ggplot2\nggplot(df, aes(x = Valori)) +\n  geom_histogram(bins = 5, aes(y = after_stat(density)), fill = \"lightblue\", color = \"black\") +\n  labs(title = \"Distribuzione della popolazione\", x = \"Valori\", y = \"Densit√†\") \n\n\n\n\n\n\n\nCalcoliamo la media e la varianza della popolazione:\n\nmean(x)  # Media\n#&gt; [1] 4.25\nvar(x)   # Varianza\n#&gt; [1] 2.417\n\n\n74.3.2 Campionamento\nConsideriamo ora tutti i possibili campioni di dimensione \\(n = 2\\) che possiamo estrarre dalla popolazione. Poich√© ogni valore pu√≤ essere selezionato indipendentemente in entrambe le posizioni del campione, il numero totale di combinazioni possibili si ottiene con il calcolo combinatorio:\n\\[\n\\text{Numero totale di campioni} = k^n ,\n\\]\ndove \\(k\\) √® la dimensione della popolazione e \\(n\\) √® la dimensione del campione. Nel nostro caso, con \\(k = 4\\) e \\(n = 2\\), otteniamo:\n\\[\n4^2 = 16 .\n\\]\nPossiamo generare esplicitamente queste combinazioni con il seguente codice:\n\nsamples &lt;- expand.grid(x, x)\nsamples\n#&gt;    Var1 Var2\n#&gt; 1   2.0  2.0\n#&gt; 2   4.5  2.0\n#&gt; 3   5.0  2.0\n#&gt; 4   5.5  2.0\n#&gt; 5   2.0  4.5\n#&gt; 6   4.5  4.5\n#&gt; 7   5.0  4.5\n#&gt; 8   5.5  4.5\n#&gt; 9   2.0  5.0\n#&gt; 10  4.5  5.0\n#&gt; 11  5.0  5.0\n#&gt; 12  5.5  5.0\n#&gt; 13  2.0  5.5\n#&gt; 14  4.5  5.5\n#&gt; 15  5.0  5.5\n#&gt; 16  5.5  5.5\n\nOgni riga rappresenta un campione possibile. Confermiamo il numero totale di campioni con:\n\nnrow(samples)\n#&gt; [1] 16\n\nOra calcoliamo la media di ciascun campione, ottenendo la distribuzione campionaria delle medie per \\(n = 2\\):\n\nsample_means &lt;- rowMeans(samples)\nsample_means\n#&gt;  [1] 2.00 3.25 3.50 3.75 3.25 4.50 4.75 5.00 3.50 4.75 5.00 5.25 3.75 5.00\n#&gt; [15] 5.25 5.50\n\nQuesta distribuzione campionaria mostra tutte le possibili medie che possiamo ottenere estraendo campioni casuali di dimensione 2 dalla popolazione. Si tratta di un concetto fondamentale in inferenza statistica frequentista, poich√© la distribuzione delle medie campionarie diventa progressivamente pi√π simmetrica e concentrata attorno alla media della popolazione man mano che \\(n\\) aumenta, come previsto dal teorema del limite centrale.\n\n74.3.3 Visualizzazione della distribuzione campionaria\nPossiamo visualizzare la distribuzione campionaria delle medie con un istogramma:\n\n# Creazione del dataframe\ndf &lt;- data.frame(Valori = sample_means)\n\n# Istogramma con ggplot2\nggplot(df, aes(x = Valori)) +\n  geom_histogram(bins = 5, aes(y = after_stat(density)), fill = \"lightblue\", color = \"black\") +\n  labs(title = \"Distribuzione campionaria delle medie (n = 2)\", x = \"Media campionaria\", y = \"Densit√†\") \n\n\n\n\n\n\n\nL‚Äôistogramma mostra come le medie campionarie non siano distribuite uniformemente, ma seguano una struttura precisa determinata dalla distribuzione dei valori originali della popolazione. Con un numero maggiore di osservazioni per campione (\\(n\\) pi√π grande), la distribuzione campionaria delle medie tende a diventare pi√π stretta e simmetrica attorno alla media della popolazione, illustrando cos√¨ il principio alla base dell‚Äôinferenza statistica frequentista.\n\n74.3.4 Verifiche teoriche\n\n74.3.4.1 Media della distribuzione campionaria\nSecondo la teoria statistica, la media della distribuzione campionaria deve coincidere con la media della popolazione. Questo implica che, se prendiamo la media di tutti i campioni possibili di una certa dimensione, il valore risultante sar√† uguale alla media della popolazione stessa. Possiamo verificarlo con il seguente calcolo:\n\nmean(x)  # Media della popolazione\n#&gt; [1] 4.25\nmean(sample_means)  # Media della distribuzione campionaria\n#&gt; [1] 4.25\n\n\n74.3.4.2 Varianza della distribuzione campionaria\nUn altro risultato importante √® che la varianza della distribuzione campionaria delle medie √® inferiore alla varianza della popolazione. In particolare, la teoria prevede che sia pari alla varianza della popolazione divisa per la dimensione del campione \\(n\\):\n\\[\n\\mathbb{V}(\\bar{X}) = \\frac{\\sigma^2}{n}\n\\]\nPoich√© in questo caso \\(n = 2\\), confrontiamo la varianza teorica con quella empirica:\n\n# Funzione per calcolare la varianza senza la correzione di Bessel\nvariance &lt;- function(x) {\n  mean((x - mean(x))^2)\n}\n\n\nvariance(x) / 2  # Varianza teorica\n#&gt; [1] 0.9062\nvariance(sample_means)  # Varianza empirica\n#&gt; [1] 0.9062\n\nOsserviamo che la varianza delle medie campionarie √® inferiore alla varianza della popolazione, confermando che le medie campionarie mostrano meno variabilit√† rispetto alle singole osservazioni.\n\n74.3.5 Esempio di campione osservato\nPer comprendere meglio questi concetti, consideriamo un singolo campione, ad esempio:\n\nobserved_sample &lt;- c(5, 5.5)\nobserved_sample\n#&gt; [1] 5.0 5.5\n\nCalcoliamo la sua media e deviazione standard:\n\nmean(observed_sample)  # Media del campione\n#&gt; [1] 5.25\nsqrt(variance(observed_sample))  # Deviazione standard del campione\n#&gt; [1] 0.25\n\nOra confrontiamo questi valori con quelli della popolazione:\n\nmean(x)  # Media della popolazione\n#&gt; [1] 4.25\nsqrt(variance(x))  # Deviazione standard della popolazione\n#&gt; [1] 1.346\n\nOsserviamo che la media del campione si avvicina a quella della popolazione, ma non coincide necessariamente con essa. Questo √® del tutto normale: ogni campione rappresenta solo una porzione della popolazione e la sua media pu√≤ variare leggermente a seconda delle osservazioni selezionate.\nPer quanto riguarda la deviazione standard, in questo caso specifico risulta inferiore a quella della popolazione. Tuttavia, in generale, la dispersione di un singolo campione pu√≤ essere maggiore o minore rispetto a quella della popolazione, poich√© dipende dalla variabilit√† casuale delle osservazioni estratte. Proprio per questo motivo, per trarre inferenze affidabili sulla popolazione, √® pi√π utile considerare la distribuzione campionaria delle medie piuttosto che un singolo campione isolato.\nQuesto esempio illustra bene il principio della stima campionaria: mentre un singolo campione fornisce un‚Äôinformazione parziale, l‚Äôanalisi di molteplici campioni consente di ottenere una stima pi√π precisa e stabile della media della popolazione, riducendo l‚Äôincertezza e migliorando l‚Äôaffidabilit√† dell‚Äôinferenza statistica.\n\n74.3.6 La Simulazione Illustra Due Principi\nDalla simulazione emergono due principi fondamentali dell‚Äôinferenza statistica:\n\n\nLa media della distribuzione campionaria coincide con la media della popolazione. Questo implica che se estraiamo molteplici campioni di dimensione \\(n\\) e calcoliamo la loro media, il valore atteso della media campionaria sar√† uguale alla media della popolazione \\(\\mu\\). Formalmente:\n\\[\n\\mathbb{E}(\\bar{X}_n) = \\mu .\n\\]\nQuesto risultato conferma che la media campionaria √® uno stimatore non distorto della media della popolazione.\n\n\nLa varianza della distribuzione campionaria √® minore della varianza della popolazione. Questo riflette il fatto che le medie campionarie tendono a essere pi√π stabili rispetto alle singole osservazioni. La relazione teorica che descrive questa propriet√† √®:\n\\[\n\\mathbb{V}(\\bar{X}) = \\frac{\\sigma^2}{n} .\n\\]\nCi√≤ significa che, aumentando la dimensione del campione \\(n\\), la variabilit√† delle medie campionarie si riduce, rendendo la stima della media della popolazione pi√π precisa. Questo concetto √® alla base della teoria del teorema centrale del limite, che diventa sempre pi√π evidente con campioni di dimensioni maggiori.\n\n\n\n\n\n\n\n\nDimostrazione che \\(\\bar{X}\\) √® uno stimatore corretto della media della popolazione\n\n\n\n\n\nDato un campione casuale di \\(n\\) osservazioni \\(X_1, X_2, \\dots, X_n\\) estratte da una popolazione con media \\(\\mu\\) e varianza \\(\\sigma^2\\), la media campionaria √® definita come:\n\\[\n\\bar{X}_n = \\frac{1}{n} \\sum_{i=1}^{n} X_i .\n\\]\nUtilizziamo la linearit√† dell‚Äôoperatore di aspettativa:\n\\[\n\\mathbb{E}(\\bar{X}_n) = \\mathbb{E} \\left( \\frac{1}{n} \\sum_{i=1}^{n} X_i \\right) .\n\\]\nPer la propriet√† della linearit√† dell‚Äôaspettativa, possiamo portare fuori il fattore costante \\(\\frac{1}{n}\\):\n\\[\n\\mathbb{E}(\\bar{X}_n) = \\frac{1}{n} \\sum_{i=1}^{n} \\mathbb{E}(X_i) .\n\\]\nPoich√© ogni \\(X_i\\) proviene dalla stessa popolazione, ha la stessa aspettativa \\(\\mathbb{E}(X_i) = \\mu\\), quindi:\n\\[\n\\mathbb{E}(\\bar{X}_n) = \\frac{1}{n} \\sum_{i=1}^{n} \\mu .\n\\]\nSommando \\(n\\) volte \\(\\mu\\), otteniamo:\n\\[\n\\mathbb{E}(\\bar{X}_n) = \\frac{1}{n} (n \\mu) = \\mu .\n\\]\nIn conclusione, abbiamo dimostrato che:\n\\[\n\\mathbb{E}(\\bar{X}_n) = \\mu .\n\\]\nQuesto significa che la media campionaria \\(\\bar{X}_n\\) √® uno stimatore corretto (non distorto) della media della popolazione \\(\\mu\\), poich√© il suo valore atteso coincide esattamente con la quantit√† che vogliamo stimare.\n\n\n\n\n\n\n\n\n\nDimostrazione della riduzione della varianza nelle medie campionarie\n\n\n\n\n\nSia \\(X_1, X_2, \\dots, X_n\\) un campione casuale di \\(n\\) osservazioni indipendenti estratte da una popolazione con media \\(\\mu\\) e varianza \\(\\sigma^2\\). La media campionaria √® definita come:\n\\[\n\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i.\n\\]\nPer definizione, la varianza di \\(\\bar{X}\\) √®:\n\\[\n\\mathbb{V}(\\bar{X}) = \\mathbb{V}\\left(\\frac{1}{n} \\sum_{i=1}^n X_i\\right).\n\\]\nPoich√© una costante moltiplicata da una variabile aleatoria pu√≤ essere ‚Äúestratta‚Äù dalla varianza, otteniamo:\n\\[\n\\mathbb{V}(\\bar{X}) = \\frac{1}{n^2} \\mathbb{V}\\left(\\sum_{i=1}^n X_i\\right).\n\\]\nOra dobbiamo calcolare \\(\\mathbb{V}\\left(\\sum_{i=1}^n X_i\\right)\\). Le variabili \\(X_1, X_2, \\dots, X_n\\) sono indipendenti, quindi la varianza della somma √® la somma delle varianze:\n\\[\n\\mathbb{V}\\left(\\sum_{i=1}^n X_i\\right) = \\sum_{i=1}^n \\mathbb{V}(X_i).\n\\]\nPoich√© tutte le variabili \\(X_i\\) hanno la stessa varianza \\(\\sigma^2\\):\n\\[\n\\mathbb{V}\\left(\\sum_{i=1}^n X_i\\right) = n \\sigma^2.\n\\]\nSostituendo nella formula precedente, otteniamo:\n\\[\n\\mathbb{V}(\\bar{X}) = \\frac{1}{n^2} \\cdot n \\sigma^2 = \\frac{\\sigma^2}{n}.\n\\]\nIn generale, dunque, per un campione di ampiezza \\(n\\), vale la relazione \\(\\mathbb{V}(\\bar{X}) = \\frac{\\sigma^2}{n}\\).",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>74</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01a_stime_parametri.html#propriet√†-della-distribuzione-campionaria",
    "href": "chapters/frequentist_inference/01a_stime_parametri.html#propriet√†-della-distribuzione-campionaria",
    "title": "74¬† Stime, stimatori e parametri",
    "section": "\n74.4 Propriet√† della distribuzione campionaria",
    "text": "74.4 Propriet√† della distribuzione campionaria\nUna caratteristica fondamentale della distribuzione campionaria riguarda la sua forma e il modo in cui dipende dalla distribuzione della popolazione da cui vengono estratti i campioni. Possiamo distinguere due casi principali:\n\nSe la popolazione segue una distribuzione normale, allora anche la distribuzione delle medie campionarie sar√† normalmente distribuita, indipendentemente dalla dimensione del campione \\(n\\). Questo significa che, anche con campioni molto piccoli, la media campionaria manterr√† la stessa forma della distribuzione originale.\nSe la popolazione non segue una distribuzione normale, entra in gioco il teorema centrale del limite. Questo teorema afferma che, man mano che la dimensione del campione \\(n\\) aumenta, la distribuzione delle medie campionarie tender√† comunque a una distribuzione normale, indipendentemente dalla forma della distribuzione di partenza. In pratica, per campioni sufficientemente grandi, possiamo approssimare la distribuzione delle medie campionarie con una normale, anche se la popolazione da cui provengono i dati √® asimmetrica o non gaussiana.\n\nQueste propriet√† sono fondamentali nell‚Äôinferenza statistica frequentista: permettono di stimare e testare parametri della popolazione utilizzando campioni, facilitando l‚Äôapplicazione di strumenti basati sulla distribuzione normale, come gli intervalli di confidenza e i test di ipotesi.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>74</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01a_stime_parametri.html#teorema-del-limite-centrale",
    "href": "chapters/frequentist_inference/01a_stime_parametri.html#teorema-del-limite-centrale",
    "title": "74¬† Stime, stimatori e parametri",
    "section": "\n74.5 Teorema del Limite Centrale",
    "text": "74.5 Teorema del Limite Centrale\nEsaminiamo ora pi√π in dettaglio il Teorema del Limite Centrale (TLC). Nel 1812, Pierre-Simon Laplace dimostr√≤ il TLC, che afferma che la somma (o la media) di una sequenza di variabili casuali indipendenti e identicamente distribuite (i.i.d.) tende a distribuirsi secondo una distribuzione Normale (o Gaussiana), al crescere della dimensione del campione. Inoltre, il TLC specifica i parametri della distribuzione Normale risultante in base ai valori attesi e alle varianze delle variabili casuali sommate.\n\nTeorema 74.1 Si consideri una sequenza di variabili aleatorie indipendenti e identicamente distribuite (i.i.d.) \\(Y_1, Y_2, \\dots, Y_n\\), con valore atteso \\(\\mathbb{E}(Y_i) = \\mu\\) e deviazione standard \\(\\text{SD}(Y_i) = \\sigma.\\) Si definisca una nuova variabile casuale come la media campionaria:\n\\[\nZ = \\frac{1}{n} \\sum_{i=1}^n Y_i.\n\\]\nAl tendere di \\(n\\) all‚Äôinfinito (\\(n \\rightarrow \\infty\\)), la distribuzione di \\(Z\\) converge a una distribuzione Normale con valore atteso \\(\\mu\\) e deviazione standard \\(\\frac{\\sigma}{\\sqrt{n}}\\):\n\\[\nZ \\sim \\mathcal{N}\\left(\\mu, \\, \\frac{\\sigma}{\\sqrt{n}} \\right).\n\\]\nIn altre parole, la densit√† di probabilit√† di \\(Z\\) tende a:\n\\[\np_Z(z) \\rightarrow \\mathcal{N}\\left(z \\ \\Bigg| \\ \\mu, \\, \\frac{\\sigma}{\\sqrt{n}} \\right).\n\\]\n\nIl TLC pu√≤ essere generalizzato anche a variabili casuali che non sono identicamente distribuite, purch√© siano indipendenti e abbiano valori attesi e varianze finite. Questo teorema spiega perch√© molti fenomeni naturali, come l‚Äôaltezza degli adulti o il peso di una popolazione, tendono a seguire una distribuzione Normale. Infatti, tali fenomeni sono spesso il risultato di una combinazione di numerosi effetti additivi e indipendenti, ciascuno dei quali contribuisce in modo relativamente piccolo. Indipendentemente dalla distribuzione individuale di ciascun effetto, la loro somma (o media) tende a distribuirsi in modo Normale. Questa √® la ragione per cui la distribuzione Normale fornisce una buona approssimazione per la distribuzione di molti fenomeni osservati in natura.\n\n74.5.1 Illustrazione del Teorema del Limite Centrale (TLC)\nPer comprendere il Teorema del Limite Centrale (TLC), consideriamo una popolazione iniziale che segue una distribuzione fortemente asimmetrica: la distribuzione Beta(2,1), caratterizzata da una forte asimmetria positiva.\n\n# Parametri della distribuzione Beta\na &lt;- 2\nb &lt;- 1\n\n# Genera valori per la distribuzione Beta\nx &lt;- seq(0, 1, length.out = 1000)  # Valori tra 0 e 1\ny &lt;- dbeta(x, shape1 = a, shape2 = b)  # Densit√† della distribuzione Beta\n\n# Crea un dataframe per qplot\ndata &lt;- data.frame(x = x, y = y)\n\n# Grafico con qplot\nqplot(x, y, data = data, geom = \"line\", \n      main = \"Distribuzione Beta(2, 1)\", \n      xlab = \"x\", \n      ylab = \"Densit√†\")\n\n\n\n\n\n\n\nEstrarremo pi√π volte campioni casuali di ampiezza \\(n\\) da questa popolazione e calcoleremo le medie campionarie. Il TLC prevede che, all‚Äôaumentare della dimensione del campione, la distribuzione delle medie campionarie tenda a una distribuzione normale, indipendentemente dalla forma della popolazione di partenza.\nPer verificare questa propriet√†, definiamo una funzione che genera campioni, calcola le medie e visualizza la loro distribuzione campionaria per diversi valori di \\(n\\):\n\n# Parametri della distribuzione Beta\nalpha &lt;- 2\nbeta &lt;- 1\n\n# Funzione per simulare e visualizzare la distribuzione campionaria\nplot_samples &lt;- function(n) {\n  # Media e deviazione standard della distribuzione Beta\n  mu &lt;- alpha / (alpha + beta)\n  sigma &lt;- sqrt(alpha * beta / ((alpha + beta)^2 * (alpha + beta + 1)))\n  \n  # Generazione di 50.000 campioni casuali di dimensione n\n  sample_means &lt;- replicate(50000, mean(rbeta(n, alpha, beta)))\n  \n  # Creazione del dataframe\n  df &lt;- data.frame(MediaCampionaria = sample_means)\n  \n  # Creazione del grafico con ggplot2\n  ggplot(df, aes(x = MediaCampionaria)) +\n    geom_histogram(aes(y = after_stat(density)), bins = 50, fill = \"lightblue\", color = \"black\") +\n    stat_function(fun = dnorm, args = list(mean = mu, sd = sigma / sqrt(n)), color = \"black\", lwd = 1.2) +\n    labs(title = paste(\"Distribuzione campionaria per n =\", n),\n         x = \"Media campionaria\",\n         y = \"Densit√†\") +\n    theme_minimal()\n}\n\n\n74.5.1.1 Visualizzazione della convergenza alla normalit√†\nAnalizziamo l‚Äôeffetto della dimensione del campione sulle medie campionarie:\n\n\nCampioni di ampiezza \\(n = 1\\)\nSe \\(n = 1\\), la distribuzione campionaria coincide esattamente con la distribuzione della popolazione di partenza, che in questo caso √® fortemente asimmetrica:\n\nplot_samples(1)\n\n\n\n\n\n\n\n\n\nCampioni di ampiezza \\(n = 2\\)\nCon \\(n = 2\\), la distribuzione delle medie campionarie inizia a perdere parte della sua asimmetria:\n\nplot_samples(2)\n\n\n\n\n\n\n\n\n\nCampioni di ampiezza \\(n = 4\\)\nPer \\(n = 4\\), la distribuzione delle medie campionarie diventa pi√π simmetrica e tende gi√† a una forma pi√π vicina a quella normale:\n\nplot_samples(4)\n\n\n\n\n\n\n\n\n\nCampioni di ampiezza \\(n = 30\\)\nQuando \\(n\\) diventa sufficientemente grande (ad esempio \\(n = 30\\)), la distribuzione campionaria delle medie √® praticamente indistinguibile da una normale:\n\nplot_samples(30)\n\n\n\n\n\n\n\n\n\n74.5.1.2 Conclusione\nIl Teorema del Limite Centrale (TLC) afferma che, indipendentemente dalla forma della distribuzione della popolazione:\n\nSe la dimensione del campione √® sufficientemente grande, la distribuzione delle medie campionarie \\(\\bar{X}\\) sar√† approssimativamente normale, anche se la popolazione di partenza non lo √®.\n\nLa distribuzione delle medie campionarie avr√† media uguale a quella della popolazione \\(\\mu\\) e deviazione standard pari a:\n\\[\n\\bar{X} \\sim \\mathcal{N}(\\mu, \\sigma / \\sqrt{n})\n\\]\ndove \\(\\sigma\\) √® la deviazione standard della popolazione e \\(n\\) √® la dimensione del campione.\n\n\n74.5.2 Implicazioni\n\nNormalit√† emergente\nIl TLC giustifica l‚Äôuso della distribuzione normale in molte applicazioni statistiche, anche quando i dati originali non seguono una distribuzione normale.\nErrore standard e precisione delle stime\nIl TLC fornisce una formula esplicita per calcolare l‚Äôerrore standard \\(\\sigma / \\sqrt{n}\\), che quantifica l‚Äôincertezza associata alla media campionaria. All‚Äôaumentare di \\(n\\), l‚Äôerrore standard diminuisce, migliorando la precisione della stima della media della popolazione.\n\nQuesta propriet√† √® alla base di molte tecniche statistiche, come gli intervalli di confidenza e i test di ipotesi, che assumono la normalit√† della distribuzione campionaria delle medie anche quando la popolazione di partenza non √® normale.\n\n74.5.3 Applicazioni in psicologia\nMolti fenomeni psicologici che misuriamo (ad esempio, il QI come media di molte abilit√† cognitive) derivano dalla media di pi√π variabili, e quindi seguono la distribuzione normale grazie al TLC. Questo spiega perch√© la distribuzione normale appare cos√¨ frequentemente nei dati sperimentali di psicologia e in molte altre discipline scientifiche.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>74</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01a_stime_parametri.html#distribuzioni-campionarie-di-altre-statistiche",
    "href": "chapters/frequentist_inference/01a_stime_parametri.html#distribuzioni-campionarie-di-altre-statistiche",
    "title": "74¬† Stime, stimatori e parametri",
    "section": "\n74.6 Distribuzioni campionarie di altre statistiche",
    "text": "74.6 Distribuzioni campionarie di altre statistiche\nAbbiamo gi√† analizzato la distribuzione campionaria della media dei campioni. Tuttavia, √® possibile costruire distribuzioni campionarie per altre statistiche campionarie. Ad esempio, consideriamo la distribuzione campionaria del valore massimo e della varianza.\n\n74.6.1 Distribuzione campionaria del valore massimo\nSupponiamo di avere una popolazione normalmente distribuita con media \\(\\mu = 100\\) e deviazione standard \\(\\sigma = 15\\). Generiamo 10.000 campioni casuali di ampiezza \\(n = 5\\) e calcoliamo il valore massimo per ogni campione.\n\n74.6.1.1 Simulazione e visualizzazione\n\nset.seed(123)  # Per risultati riproducibili\n\n# Parametri della distribuzione\nmu &lt;- 100\nsigma &lt;- 15\n\n# Simulazione: calcolo del valore massimo per ciascun campione\nn_samples &lt;- 10000\nsample_maxes &lt;- replicate(\n  n_samples, \n  max(rnorm(5, mean = mu, sd = sigma))\n)\n\n# Creazione del dataframe\ndf &lt;- data.frame(ValoreMassimo = sample_maxes)\n\n# Istogramma con ggplot2\nggplot(df, aes(x = ValoreMassimo)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 50, fill = \"lightblue\", color = \"black\") +\n  stat_function(fun = dnorm, args = list(mean = mu, sd = sigma), color = \"black\", lwd = 1.2) +\n  labs(title = \"Distribuzione campionaria del valore massimo\",\n       x = \"Valore massimo\",\n       y = \"Densit√†\")\n\n\n\n\n\n\n\nOsserviamo che il valore atteso della distribuzione campionaria del massimo √® maggiore della media della popolazione \\(\\mu\\).\n\n74.6.2 Distribuzione campionaria della varianza\nUn‚Äôaltra statistica interessante √® la varianza campionaria. La formula della varianza campionaria, basata sulla statistica descrittiva, √®:\n\\[\nS^2 = \\frac{\\sum_{i=1}^n (Y_i - \\bar{Y})^2}{n}.\n\\]\nCalcoliamo la distribuzione campionaria della varianza per campioni di ampiezza \\(n = 5\\).\n\n74.6.2.1 Simulazione e visualizzazione\n\nset.seed(123)\n\n# Parametri della distribuzione\nmu &lt;- 100\nsigma &lt;- 15\nn_samples &lt;- 10000\n\n# Funzione per calcolare la varianza senza la correzione di Bessel\nvariance &lt;- function(x) {\n  mean((x - mean(x))^2)  # Divisione per n invece di (n-1)\n}\n\n# Simulazione: calcolo della varianza per ciascun campione\nsample_vars &lt;- replicate(\n  n_samples, \n  variance(rnorm(5, mean = mu, sd = sigma))\n)\n\n# Creazione del dataframe\ndf &lt;- data.frame(Varianza = sample_vars)\n\n# Istogramma con ggplot2\nggplot(df, aes(x = Varianza)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 50, fill = \"lightblue\", color = \"black\") +\n  labs(title = \"Distribuzione campionaria della varianza\",\n       x = \"Varianza\",\n       y = \"Densit√†\")\n\n\n\n\n\n\n\n\n# Media empirica della varianza campionaria\nmean(sample_vars)\n#&gt; [1] 180.7\n\nSappiamo che la varianza della popolazione √® \\(\\sigma^2 = 15^2 = 225\\). Tuttavia, il valore medio empirico delle varianze campionarie calcolate con \\(S^2\\) risulta minore di 225. Questo avviene perch√© lo stimatore \\(S^2\\) √® distorto.\n\n74.6.3 Correzione della distorsione\nPer eliminare la distorsione, utilizziamo il seguente stimatore della varianza della popolazione:\n\\[\ns^2 = \\frac{\\sum_{i=1}^n (Y_i - \\bar{Y})^2}{n-1}.\n\\]\n\n74.6.3.1 Verifica con simulazione\n\nset.seed(123)\n\n# Simulazione: calcolo della varianza con la correzione\nsample_vars_unbiased &lt;- replicate(\n  n_samples, \n  var(rnorm(5, mean = mu, sd = sigma))\n)\n\n# Creazione del dataframe\ndf &lt;- data.frame(Varianza = sample_vars_unbiased)\n\n# Istogramma con ggplot2\nggplot(df, aes(x = Varianza)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 50, fill = \"lightblue\", color = \"black\") +\n  labs(title = \"Distribuzione campionaria della varianza (corretta)\",\n       x = \"Varianza\",\n       y = \"Densit√†\")\n\n\n\n\n\n\n\n\n# Media empirica della varianza corretta\nmean(sample_vars_unbiased)\n#&gt; [1] 225.8\n\nCon questo stimatore, la media della distribuzione campionaria coincide con la varianza reale della popolazione \\(\\sigma^2 = 225\\).\nIn conclusione:\n\nLa distribuzione campionaria del massimo mostra che il valore massimo dei campioni √®, in media, maggiore della media della popolazione.\nLa varianza campionaria non corretta (\\(S^2\\)) √® uno stimatore distorto, poich√© il suo valore atteso non coincide con la varianza della popolazione.\nLo stimatore corretto \\(s^2\\), che utilizza il divisore \\(n - 1\\), elimina la distorsione e fornisce una stima non distorta della varianza della popolazione.\n\nIn generale, uno stimatore √® considerato non distorto quando il valore atteso delle sue stime coincide con il valore reale del parametro. Nel caso della media campionaria e della varianza corretta, entrambi gli stimatori sono non distorti.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>74</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01a_stime_parametri.html#riflessioni-conclusive",
    "href": "chapters/frequentist_inference/01a_stime_parametri.html#riflessioni-conclusive",
    "title": "74¬† Stime, stimatori e parametri",
    "section": "\n74.7 Riflessioni Conclusive",
    "text": "74.7 Riflessioni Conclusive\nIn generale, i parametri della popolazione sono sconosciuti, ma possiamo stimarli utilizzando le informazioni del campione. Di seguito viene presentata una tabella che riassume i simboli comuni utilizzati per indicare le quantit√† note e sconosciute nel contesto dell‚Äôinferenza statistica. Questo ci aiuter√† a tenere traccia di ci√≤ che sappiamo e ci√≤ che non sappiamo.\n\n\n\n\n\n\n\nSimbolo\nNome\n√à qualcosa che conosciamo?\n\n\n\n\\(s\\)\nDeviazione standard del campione\nS√¨, la calcoliamo dai dati grezzi\n\n\n\\(\\sigma\\)\nDeviazione standard della popolazione\nNo, tranne in casi particolari o nelle simulazioni\n\n\n\\(\\hat{\\sigma}\\)\nStima della deviazione standard della popolazione\nS√¨, ma non √® uguale a \\(\\sigma\\)\n\n\n\n\\(s^2\\)\nVarianza del campione\nS√¨, la calcoliamo dai dati grezzi\n\n\n\\(\\sigma^2\\)\nVarianza della popolazione\nNo, tranne in casi particolari o nelle simulazioni\n\n\n\\(\\hat{\\sigma}^2\\)\nStima della varianza della popolazione\nS√¨, ma non √® uguale a \\(\\sigma^2\\)\n\n\n\n\n\nUtilizzando le informazioni di un campione casuale di ampiezza \\(n\\):\n\nLa stima migliore che possiamo ottenere per la media \\(\\mu\\) della popolazione √® la media del campione \\(\\bar{Y}\\).\nLa stima migliore che possiamo ottenere per la varianza \\(\\sigma^2\\) della popolazione √®:\n\n\\[\n\\hat{\\sigma}^2 = \\frac{1}{n-1} \\sum_{i=1}^n (Y_i - \\bar{Y})^2.\n\\]\n\n\n\n\n\n\nRisposte alle domande iniziali\n\n\n\n\n\nDopo aver esplorato il concetto di distribuzione campionaria attraverso simulazioni ed esempi pratici, possiamo ora confrontare le nostre risposte intuitive con quanto appreso:\n\nLe medie campionarie tendono a distribuirsi intorno alla media della popolazione, con una variabilit√† che dipende dalla dimensione del campione.\nS√¨, le medie campionarie sono meno disperse rispetto ai singoli valori della popolazione, il che significa che forniscono una stima pi√π stabile della media della popolazione.\nAll‚Äôaumentare di \\(n\\), la distribuzione campionaria delle medie diventa pi√π stretta, ossia la variabilit√† delle medie campionarie si riduce. La varianza della distribuzione campionaria √® pari a \\(\\sigma^2 / n\\), dove \\(\\sigma^2\\) √® la varianza della popolazione.\nNo, la distribuzione campionaria della media √® normale solo se la popolazione di partenza √® normale o se la dimensione del campione √® sufficientemente grande (Teorema del Limite Centrale).\nS√¨, la media della distribuzione campionaria coincide con la media della popolazione. Tuttavia, la varianza della distribuzione campionaria √® inferiore alla varianza della popolazione, poich√© viene divisa per la dimensione del campione (\\(n\\)).\nPer campioni piccoli, la distribuzione delle medie campionarie somiglier√† alla distribuzione della popolazione originale. Se la popolazione √® fortemente asimmetrica, anche la distribuzione campionaria per piccoli campioni sar√† asimmetrica. Tuttavia, aumentando \\(n\\), la distribuzione delle medie campionarie tender√† a una normale, indipendentemente dalla forma della popolazione di partenza.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>74</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01a_stime_parametri.html#esercizi",
    "href": "chapters/frequentist_inference/01a_stime_parametri.html#esercizi",
    "title": "74¬† Stime, stimatori e parametri",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nParte 1: Popolazione di Piccole Dimensioni Si consideri una popolazione con i seguenti valori:\n\\[\nx = \\{2, 4.5, 5, 5.5\\}\n\\]\n\nCalcolare la media e la varianza della popolazione.\nEstrarre tutti i possibili campioni di ampiezza \\(n = 2\\) con ripetizione e calcolare la media di ciascun campione.\nRappresentare graficamente la distribuzione campionaria delle medie.\nCalcolare la probabilit√† che la media campionaria sia inferiore a 3:\n\nEsattamente, utilizzando la distribuzione campionaria.\nApprossimativamente, assumendo una distribuzione normale se il campione fosse sufficientemente grande.\n\n\n\nParte 2: Popolazione di Grandi Dimensioni\nSi consideri ora una popolazione pi√π grande, generata da una distribuzione normale con media \\(\\mu = 10\\) e deviazione standard \\(\\sigma = 3\\).\n\nGenerare una popolazione di 1000 osservazioni.\nCalcolare la media e la varianza della popolazione.\nEstrarre 10.000 campioni casuali di ampiezza \\(n = 15\\) e calcolare la media campionaria per ciascun campione.\nRappresentare graficamente la distribuzione campionaria delle medie.\nCalcolare la probabilit√† che la media campionaria sia inferiore a 9:\n\nEsattamente, utilizzando la distribuzione campionaria.\nApprossimativamente, utilizzando la distribuzione normale.\n\n\n\nObiettivo: Verificare sperimentalmente le propriet√† della distribuzione campionaria della media e confrontare i risultati con le previsioni teoriche fornite dal Teorema del Limite Centrale.\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\nPropriet√† della Distribuzione Campionaria della Media\n\nMedia: La media della distribuzione campionaria coincide con la media della popolazione:\nVarianza: La varianza della distribuzione campionaria √® pari alla varianza della popolazione divisa per la dimensione del campione:\nForma:\n\n\nSe la popolazione segue una distribuzione normale, anche la distribuzione campionaria della media sar√† normale.\nSe la popolazione non √® normale, il Teorema del Limite Centrale garantisce che la distribuzione campionaria della media sar√† approssimativamente normale per campioni di dimensioni sufficientemente grandi (\\(n \\geq 30\\)).\n\nDefiniamo una popolazione e calcoliamo i parametri:\n\n# Popolazione\nx &lt;- c(2, 4.5, 5, 5.5)\nmean(x)  # Media della popolazione\n#&gt; [1] 4.25\nvar(x)   # Varianza della popolazione\n#&gt; [1] 2.417\n\nEstrarre tutti i possibili campioni di ampiezza \\(n = 2\\) e calcolare la media di ciascun campione:\n\n# Tutti i campioni di ampiezza 2\nsamples &lt;- expand.grid(x, x)\nsample_means &lt;- rowMeans(samples)\n\n# Visualizzare la distribuzione campionaria\ndf &lt;- data.frame(sample_means = sample_means)\n\nggplot(df, aes(x = sample_means)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 5, fill = \"blue\", alpha = 0.6) +\n  geom_density(color = \"red\", size = 1) +\n  labs(\n    title = \"Distribuzione campionaria delle medie\",\n    x = \"Media campionaria\",\n    y = \"Densit√†\"\n  )\n\n\n\n\n\n\n\nCalcoliamo la probabilit√† che, all‚Äôinterno della distribuzione campionaria, la media del campione sia minore di 3. Troviamo il valore esatto nella simulazione. Approssimiamo il valore esatto con il valore atteso se il campione fosse sufficientemente grande da poter assumere una distribuzione campionaria normale:\n\n# Probabilit√† esatta dalla distribuzione campionaria\nexact_probability &lt;- mean(sample_means &lt; 3)\nexact_probability\n#&gt; [1] 0.0625\n\n# Approssimazione tramite distribuzione normale\nmu &lt;- mean(x)  # Media della popolazione\nsigma &lt;- sqrt(var(x) / 2)  # Deviazione standard della distribuzione campionaria\napprox_probability &lt;- pnorm(3, mean = mu, sd = sigma)\napprox_probability\n#&gt; [1] 0.1277\n\nRipetiamo ora l‚Äôesempio, mantenendo la stessa struttura della simulazione, ma considerando una popolazione pi√π grande tale per cui si possa estrarre un campione di ampiezza 15:\n\n# Nuova popolazione\nset.seed(123)\nx_large &lt;- rnorm(1000, mean = 10, sd = 3)  # Popolazione pi√π grande\nmean(x_large)  # Media della popolazione\n#&gt; [1] 10.05\nvar(x_large)   # Varianza della popolazione\n#&gt; [1] 8.851\n\n# Estrazione di campioni di ampiezza 15\nsamples_large &lt;- replicate(10000, mean(sample(x_large, size = 15)))\n\n# Creazione del data frame per ggplot2\ndf_large &lt;- data.frame(sample_means = samples_large)\n\n# Visualizzazione con ggplot2\nggplot(df_large, aes(x = sample_means)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 50, fill = \"blue\", alpha = 0.6) +\n  geom_density(color = \"red\", size = 1) +\n  labs(\n    title = \"Distribuzione campionaria delle medie (n = 15)\",\n    x = \"Media campionaria\",\n    y = \"Densit√†\"\n  )\n\n\n\n\n\n\n\n\n# Probabilit√† esatta dalla simulazione\nexact_probability_large &lt;- mean(samples_large &lt; 9)\nexact_probability_large\n#&gt; [1] 0.0834\n\n\n# Approssimazione tramite distribuzione normale\nmu_large &lt;- mean(x_large)\nsigma_large &lt;- sqrt(var(x_large) / 15)\napprox_probability_large &lt;- pnorm(9, mean = mu_large, sd = sigma_large)\napprox_probability_large\n#&gt; [1] 0.08616\n\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nDistribuzione Campionaria della Differenza tra Medie\nL‚Äôobiettivo di questo esercizio √® esplorare le propriet√† della distribuzione campionaria della differenza tra medie campionarie, analizzando sia il caso di popolazioni finite di piccole dimensioni sia il caso di popolazioni pi√π grandi, con distribuzioni normali.\nEsercizio 1: Simulazione con Popolazioni di Piccole Dimensioni\nConsideriamo due popolazioni finite composte da un numero limitato di elementi:\n\n\nPopolazione 1: \\(x_1 = \\{2, 4.5, 5, 6\\}\\)\n\n\nPopolazione 2: \\(x_2 = \\{3, 3.5, 4, 7\\}\\)\n\n\n\n74.7.0.1 Compiti:\n\n\n\nCalcolo dei parametri delle popolazioni:\n\nDeterminare la media e la varianza di entrambe le popolazioni.\n\n\n\nEstrazione di campioni:\n\nEstrarre tutti i possibili campioni di ampiezza \\(n = 2\\) con ripetizione da entrambe le popolazioni.\nCalcolare la media campionaria di ciascun campione.\n\n\n\nDistribuzione campionaria della differenza tra le medie:\n\nCalcolare la differenza tra le medie di tutti i possibili campioni ottenuti dalle due popolazioni.\nRappresentare graficamente la distribuzione della differenza tra le medie.\n\n\n\nProbabilit√† della differenza tra le medie:\n\nCalcolare la probabilit√† che la differenza tra le medie campionarie sia maggiore di 1.\n\n\n\nEsercizio 2: Simulazione con Popolazioni di Grande Dimensione\nConsideriamo ora due popolazioni pi√π grandi, distribuite normalmente:\n\n\nPopolazione 1: \\(X_1 \\sim N(10, 4^2)\\) (media = 10, deviazione standard = 4)\n\nPopolazione 2: \\(X_2 \\sim N(8, 3^2)\\) (media = 8, deviazione standard = 3)\n\nCompiti:\n\n\nGenerazione delle popolazioni:\n\nCreare due popolazioni casuali di 10.000 osservazioni ciascuna, distribuite normalmente.\n\n\n\nEstrazione di campioni:\n\nEstrarre 10.000 campioni casuali di ampiezza \\(n_1 = 15\\) dalla prima popolazione e \\(n_2 = 20\\) dalla seconda popolazione.\nCalcolare la media di ciascun campione.\n\n\n\nDistribuzione campionaria della differenza tra le medie:\n\nCalcolare la differenza tra le medie campionarie ottenute dalle due popolazioni.\nRappresentare graficamente la distribuzione della differenza tra le medie.\n\n\n\nProbabilit√† della differenza tra le medie:\n\nCalcolare la probabilit√† che la differenza tra le medie campionarie sia maggiore di 2 in due modi:\n\n\nMetodo empirico: utilizzando la distribuzione ottenuta nella simulazione.\n\nMetodo teorico: approssimando la distribuzione con una normale e calcolando la probabilit√† con la formula teorica della varianza della differenza tra le medie.\n\n\n\n\n\nDomande di Discussione\n\nCome cambia la forma della distribuzione campionaria al variare delle dimensioni dei campioni \\(n_1\\) e \\(n_2\\)?\nLa probabilit√† stimata tramite simulazione coincide con quella calcolata utilizzando l‚Äôapprossimazione normale? Perch√©?\nCosa accadrebbe alla distribuzione campionaria se le popolazioni originali non fossero normali? Quale sarebbe il ruolo del Teorema del Limite Centrale?\n\n\n\n\n\n\n\n\n\n\nSoluzioni 2\n\n\n\n\n\nEsercizio 1: Simulazione con Popolazioni di Piccola Dimensione\nSupponiamo di avere due popolazioni finite definite come segue:\n\nPopolazione 1: \\(x_1 = \\{2, 4.5, 5, 6\\}\\)\n\nPopolazione 2: \\(x_2 = \\{3, 3.5, 4, 7\\}\\)\n\n\n\nCalcola le medie e le varianze delle due popolazioni:\n\n\n# Popolazione 1\nx1 &lt;- c(2, 4.5, 5, 6)\nmean(x1)  # Media di x1\n#&gt; [1] 4.375\nvar(x1)   # Varianza di x1\n#&gt; [1] 2.896\n\n\n# Popolazione 2\nx2 &lt;- c(3, 3.5, 4, 7)\nmean(x2)  # Media di x2\n#&gt; [1] 4.375\nvar(x2)   # Varianza di x2\n#&gt; [1] 3.229\n\n\nEstrai tutti i possibili campioni di ampiezza \\(n = 2\\) da entrambe le popolazioni:\n\n\n# Tutti i campioni di ampiezza 2\nsamples1 &lt;- expand.grid(x1, x1)\nsamples2 &lt;- expand.grid(x2, x2)\n\n# Medie campionarie\nsample_means1 &lt;- rowMeans(samples1)\nsample_means2 &lt;- rowMeans(samples2)\n\n\nCalcola la differenza tra le medie campionarie di ciascuna combinazione di campioni:\n\n\n# Differenze tra le medie campionarie\nsample_diff &lt;- as.vector(outer(sample_means1, sample_means2, \"-\"))\n\n\nVisualizza la distribuzione campionaria della differenza tra le medie:\n\n\n# Istogramma della differenza tra medie campionarie\n\n# Creazione del data frame per ggplot2\ndf_diff &lt;- data.frame(sample_diff = sample_diff)\n\n# Visualizzazione con ggplot2\nggplot(df_diff, aes(x = sample_diff)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 10, fill = \"blue\", alpha = 0.6) +\n  geom_density(color = \"red\", size = 1) +\n  labs(\n    title = \"Distribuzione campionaria della differenza tra medie\",\n    x = \"Differenza campionaria\",\n    y = \"Densit√†\"\n  )\n\n\n\n\n\n\n\n\nCalcola la probabilit√† che la differenza campionaria sia maggiore di 1:\n\n\n# Probabilit√† esatta dalla distribuzione campionaria\nexact_probability &lt;- mean(sample_diff &gt; 1)\nexact_probability\n#&gt; [1] 0.2656\n\nEsercizio 2: Simulazione con Popolazioni di Grande Dimensione\nOra considera due popolazioni pi√π grandi con distribuzioni normali:\n\nPopolazione 1: \\(X_1 \\sim N(10, 4^2)\\)\n\nPopolazione 2: \\(X_2 \\sim N(8, 3^2)\\)\n\n\n\nGenera due popolazioni casuali:\n\n\nset.seed(123)\npop1 &lt;- rnorm(10000, mean = 10, sd = 4)\npop2 &lt;- rnorm(10000, mean = 8, sd = 3)\n\n\nEstrai 10.000 campioni casuali di ampiezza \\(n_1 = 15\\) e \\(n_2 = 20\\) rispettivamente:\n\n\n# Estrazione di campioni e calcolo delle medie\nsample_means1 &lt;- replicate(10000, mean(sample(pop1, size = 15)))\nsample_means2 &lt;- replicate(10000, mean(sample(pop2, size = 20)))\n\n\nCalcola la differenza tra le medie campionarie:\n\n\n# Differenze tra medie campionarie\nsample_diff_large &lt;- sample_means1 - sample_means2\n\n\nVisualizza la distribuzione campionaria della differenza tra le medie:\n\n\n# Istogramma della distribuzione campionaria\n\n# Creazione del data frame per ggplot2\ndf_diff_large &lt;- data.frame(sample_diff = sample_diff_large)\n\n# Visualizzazione con ggplot2\nggplot(df_diff_large, aes(x = sample_diff)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 50, fill = \"blue\", alpha = 0.6) +\n  geom_density(color = \"red\", size = 1) +\n  labs(\n    title = \"Distribuzione campionaria della differenza tra medie (n1 = 15, n2 = 20)\",\n    x = \"Differenza campionaria\",\n    y = \"Densit√†\"\n  )\n\n\n\n\n\n\n\n\n\nCalcola la probabilit√† che la differenza campionaria sia maggiore di 2 utilizzando:\n\nla simulazione;\nl‚Äôapprossimazione normale.\n\n\n\n\n# Probabilit√† esatta\nexact_probability_large &lt;- mean(sample_diff_large &gt; 2)\nexact_probability_large\n#&gt; [1] 0.505\n\n\n# Approssimazione normale\nmu_diff &lt;- 10 - 8  # Differenza tra le medie delle popolazioni\nsigma_diff &lt;- sqrt(4^2 / 15 + 3^2 / 20)  # Deviazione standard della differenza\napprox_probability_large &lt;- 1 - pnorm(2, mean = mu_diff, sd = sigma_diff)\napprox_probability_large\n#&gt; [1] 0.5\n\nDomande di Discussione.\n\nCome cambia la forma della distribuzione campionaria al variare delle dimensioni campionarie \\(n_1\\) e \\(n_2\\)?\nLa probabilit√† calcolata tramite simulazione coincide con quella calcolata tramite approssimazione normale? Perch√©?\nCosa accadrebbe alla distribuzione campionaria se le popolazioni originali non fossero normali?\n\n\n\n\n\n\n\n\n\n\nProblemi 3\n\n\n\n\n\nProblema: Distribuzione Campionaria di una Proporzione\nL‚Äôobiettivo di questo esercizio √® esplorare la distribuzione campionaria di una proporzione campionaria \\(\\hat{p}\\) e verificare l‚Äôapplicabilit√† dell‚Äôapprossimazione normale per grandi dimensioni campionarie, come previsto dal Teorema del Limite Centrale.\nSituazione\nSupponiamo di avere una popolazione infinita in cui ciascun individuo pu√≤ appartenere a una di due categorie: ‚Äúsuccesso‚Äù (codificato come 1) o ‚Äúinsuccesso‚Äù (codificato come 0). La probabilit√† di successo nella popolazione √® data da \\(p = 0.6\\).\nCompiti\n\n\nDefinizione della popolazione e dei parametri:\n\nLa popolazione ha una proporzione di successi pari a \\(p = 0.6\\).\nLa deviazione standard teorica della distribuzione campionaria della proporzione √® calcolata come:\\[\n\\text{SD}(\\hat{p}) = \\sqrt{\\frac{p(1 - p)}{n}}\n\\]\n\nSi fissi una dimensione campionaria pari a \\(n = 100\\).\n\n\n\nSimulazione di campioni:\n\nGenerare 10.000 campioni casuali di ampiezza \\(n = 100\\).\nPer ogni campione, calcolare la proporzione campionaria \\(\\hat{p}\\), cio√® la frazione di successi nel campione.\n\n\n\nDistribuzione campionaria delle proporzioni:\n\nRappresentare graficamente la distribuzione delle proporzioni campionarie con un istogramma.\nSovrapporre la distribuzione normale teorica \\(N(p, \\text{SD}(\\hat{p}))\\) per confrontare l‚Äôandamento empirico con quello teorico.\n\n\n\nAnalisi della distribuzione:\n\nValutare se la distribuzione campionaria ottenuta rispetta l‚Äôapprossimazione normale.\nRiflettere su come la dimensione del campione e il valore di \\(p\\) influenzano questa approssimazione.\n\n\n\nDomande di Discussione\n\nLa distribuzione campionaria delle proporzioni \\(\\hat{p}\\) sembra approssimarsi a una distribuzione normale? Perch√©?\nCosa accadrebbe se la dimensione del campione fosse pi√π piccola, ad esempio \\(n = 30\\)?\nSe la probabilit√† di successo \\(p\\) fosse molto vicina a 0 o 1, l‚Äôapprossimazione normale sarebbe ancora valida? Perch√©?\n\n\n\n\n\n\n\n\n\n\nSoluzioni 3\n\n\n\n\n\nLa distribuzione campionaria di una proporzione descrive come la proporzione campionaria (\\(\\hat{p}\\)) varia tra campioni di una popolazione. Per campioni grandi, il Teorema del Limite Centrale garantisce che la distribuzione campionaria di \\(\\hat{p}\\) pu√≤ essere approssimata con una distribuzione normale.\n\n\nSupponiamo una popolazione infinita in cui la probabilit√† di successo (\\(p\\)) √® \\(p = 0.6\\). Scegli una dimensione campionaria \\(n = 100\\).\nSimula 10.000 campioni casuali di ampiezza \\(n\\) e calcola le proporzioni campionarie (\\(\\hat{p}\\)).\nConfronta l‚Äôistogramma delle proporzioni campionarie con la distribuzione normale teorica approssimativa.\n\n\n# Parametri della popolazione\np &lt;- 0.6  # Probabilit√† di successo nella popolazione\nn &lt;- 100  # Dimensione del campione\n\n# Simulazione di 10.000 campioni\nset.seed(123)\nsample_props &lt;- replicate(10000, mean(rbinom(n, size = 1, prob = p)))\n\n# Creazione di un data frame per ggplot2\ndf_props &lt;- data.frame(sample_props = sample_props)\n\n# Parametri della distribuzione normale teorica\nmean_theoretical &lt;- p\nsd_theoretical &lt;- sqrt(p * (1 - p) / n)\n\n# Visualizzazione con ggplot2\nggplot(df_props, aes(x = sample_props)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 40, fill = \"blue\", alpha = 0.6) +\n  stat_function(\n    fun = dnorm,\n    args = list(mean = mean_theoretical, sd = sd_theoretical),\n    color = \"red\",\n    size = 1\n  ) +\n  labs(\n    title = \"Distribuzione campionaria di una proporzione (n = 100)\",\n    x = \"Proporzione campionaria (\\u0302p)\",\n    y = \"Densit√†\"\n  ) \n\n\n\n\n\n\n\n\n\nPopolazione e parametri:\n\nLa popolazione √® definita da \\(p = 0.6\\).\nLa deviazione standard teorica della distribuzione campionaria √® calcolata come \\(\\text{SD}(\\hat{p}) = \\sqrt{\\frac{p(1-p)}{n}}\\).\n\n\n\nSimulazione:\n\nPer ogni campione, i successi (\\(0\\) o \\(1\\)) sono generati con rbinom, e la proporzione campionaria \\(\\hat{p}\\) √® calcolata come media.\n\n\n\nGrafico:\n\nL‚Äôistogramma delle proporzioni campionarie √® sovrapposto alla curva normale teorica (\\(N(p, \\text{SD}(\\hat{p}))\\)).\n\n\n\nDomande di Discussione.\n\nLa distribuzione campionaria di \\(\\hat{p}\\) sembra approssimarsi a una distribuzione normale? Perch√©?\nCosa accadrebbe se \\(n\\) fosse pi√π piccolo (es. \\(n = 30\\))?\nSe \\(p\\) fosse pi√π vicino a \\(0\\) o \\(1\\), l‚Äôapprossimazione normale sarebbe ancora valida? Spiega.\n\n\n\n\n\n\n\n\n\n\nProblemi 4\n\n\n\n\n\nProblema: Distribuzione Campionaria della Differenza tra Due Proporzioni\nL‚Äôobiettivo di questo esercizio √® esplorare la distribuzione campionaria della differenza tra due proporzioni campionarie, \\(\\hat{p}_1 - \\hat{p}_2\\), ottenute da due campioni indipendenti estratti da popolazioni diverse. Per campioni sufficientemente grandi, il Teorema del Limite Centrale garantisce che la distribuzione di \\(\\hat{p}_1 - \\hat{p}_2\\) pu√≤ essere approssimata con una distribuzione normale.\nSituazione\nAbbiamo due popolazioni con proporzioni di successo diverse:\n\n\nPopolazione 1 ha una proporzione di successo \\(p_1 = 0.6\\).\n\nPopolazione 2 ha una proporzione di successo \\(p_2 = 0.4\\).\n\nVogliamo studiare il comportamento della distribuzione campionaria della differenza tra le proporzioni campionarie quando preleviamo campioni indipendenti da ciascuna popolazione.\nCompiti\n\n\nDefinizione delle popolazioni e dei parametri:\n\nLa proporzione di successi nelle due popolazioni √® \\(p_1 = 0.6\\) e \\(p_2 = 0.4\\).\nEntrambi i campioni hanno dimensione \\(n_1 = n_2 = 150\\).\nLa deviazione standard teorica della distribuzione campionaria della differenza tra proporzioni √® calcolata come: \\[\n\\text{SD}(\\hat{p}_1 - \\hat{p}_2) = \\sqrt{\\frac{p_1 (1-p_1)}{n_1} + \\frac{p_2 (1-p_2)}{n_2}}\n\\]\n\n\n\n\nSimulazione di campioni:\n\nGenerare 10.000 campioni indipendenti di ampiezza \\(n_1 = 150\\) dalla prima popolazione e \\(n_2 = 150\\) dalla seconda popolazione.\nCalcolare la proporzione campionaria \\(\\hat{p}_1\\) e \\(\\hat{p}_2\\) per ciascun campione.\nCalcolare la differenza tra le proporzioni campionarie.\n\n\n\nDistribuzione campionaria della differenza tra le proporzioni:\n\nRappresentare graficamente la distribuzione di \\(\\hat{p}_1 - \\hat{p}_2\\) con un istogramma.\nSovrapporre la distribuzione normale teorica \\(N(p_1 - p_2, \\text{SD}(\\hat{p}_1 - \\hat{p}_2))\\) per confrontare l‚Äôandamento empirico con quello teorico.\n\n\n\nCalcolo della probabilit√† che la differenza tra proporzioni sia maggiore di un valore specifico:\n\n\nMetodo empirico: calcolare la proporzione di campioni in cui \\(\\hat{p}_1 - \\hat{p}_2 &gt; 0.1\\).\n\nMetodo teorico: utilizzare la distribuzione normale approssimata per stimare la probabilit√† che \\(\\hat{p}_1 - \\hat{p}_2 &gt; 0.1\\).\n\n\n\nDomande di Discussione\n\nL‚Äôapprossimazione normale √® valida in questo caso? Perch√©?\nCome cambierebbe la distribuzione campionaria se la dimensione del campione \\(n_1\\) o \\(n_2\\) fosse pi√π piccola?\nSe i valori di \\(p_1\\) o \\(p_2\\) fossero pi√π vicini a 0 o 1, come cambierebbe la probabilit√† calcolata e l‚Äôaccuratezza dell‚Äôapprossimazione normale?\n\n\n\n\n\n\n\n\n\n\nSoluzioni 4\n\n\n\n\n\nLa distribuzione campionaria della differenza tra due proporzioni (\\(\\hat{p}_1 - \\hat{p}_2\\)) descrive come la differenza tra le proporzioni campionarie varia tra due campioni indipendenti estratti da due popolazioni.\nPer campioni grandi, il Teorema del Limite Centrale garantisce che \\(\\hat{p}_1 - \\hat{p}_2\\) segue approssimativamente una distribuzione normale con media e varianza calcolate dalle proporzioni della popolazione.\nObiettivo:\n\nSimulare due popolazioni con proporzioni \\(p_1\\) e \\(p_2\\).\nEstrarre campioni indipendenti da ciascuna popolazione.\nCalcolare la distribuzione campionaria di \\(\\hat{p}_1 - \\hat{p}_2\\).\nCalcolare la probabilit√† che la differenza campionaria sia maggiore di un valore specifico (es. \\(0.1\\)).\n\nParametri del Problema:\n\nPopolazione 1: \\(p_1 = 0.6\\)\n\nPopolazione 2: \\(p_2 = 0.4\\)\n\nDimensione campionaria: \\(n_1 = n_2 = 150\\)\n\nValore specifico: \\(0.1\\)\n\n\n\n# Parametri delle due popolazioni\np1 &lt;- 0.6  # Proporzione di successi nella Popolazione 1\np2 &lt;- 0.4  # Proporzione di successi nella Popolazione 2\nn1 &lt;- 150  # Dimensione campionaria per la Popolazione 1\nn2 &lt;- 150  # Dimensione campionaria per la Popolazione 2\n\n# Simulazione di 10.000 campioni indipendenti\nset.seed(123)\nsample_p1 &lt;- replicate(10000, mean(rbinom(n1, size = 1, prob = p1)))\nsample_p2 &lt;- replicate(10000, mean(rbinom(n2, size = 1, prob = p2)))\n\n# Calcolo della differenza tra proporzioni campionarie\nsample_diff &lt;- sample_p1 - sample_p2\n\n# Parametri teorici della distribuzione normale approssimata\nmean_diff &lt;- p1 - p2\nsd_diff &lt;- sqrt((p1 * (1 - p1) / n1) + (p2 * (1 - p2) / n2))\n\n# Creazione del data frame per ggplot2\ndf_diff &lt;- data.frame(sample_diff = sample_diff)\n\n# Visualizzazione con ggplot2\nggplot(df_diff, aes(x = sample_diff)) +\n  geom_histogram(\n    aes(y = after_stat(density)), bins = 40, fill = \"blue\", alpha = 0.6\n  ) +\n  stat_function(\n    fun = dnorm,\n    args = list(mean = mean_diff, sd = sd_diff),\n    color = \"red\",\n    size = 1\n  ) +\n  labs(\n    title = \"Distribuzione campionaria della differenza tra proporzioni\",\n    x = \"Differenza campionaria (p1 - p2)\",\n    y = \"Densit√†\"\n  )\n\n\n\n\n\n\n\n\n# Calcolo della probabilit√† che la differenza sia maggiore di 0.1\nexact_probability &lt;- mean(sample_diff &gt; 0.1)\nexact_probability\n#&gt; [1] 0.9599\n\n\n# Approssimazione tramite distribuzione normale\napprox_probability &lt;- 1 - pnorm(0.1, mean = mean_diff, sd = sd_diff)\napprox_probability\n#&gt; [1] 0.9615\n\n\n\nParametri delle popolazioni:\n\nDue popolazioni con proporzioni \\(p_1 = 0.6\\) e \\(p_2 = 0.4\\).\nDimensioni campionarie \\(n_1 = n_2 = 150\\).\n\n\n\nSimulazione:\n\nPer ogni campione, i successi (\\(0\\) o \\(1\\)) sono generati con rbinom.\nCalcoliamo le proporzioni campionarie e la differenza tra di esse.\n\n\n\nDistribuzione teorica:\n\nMedia teorica: \\(p_1 - p_2\\).\nDeviazione standard teorica: \\(\\sqrt{\\frac{p_1 (1-p_1)}{n_1} + \\frac{p_2 (1-p_2)}{n_2}}\\).\n\n\n\nVisualizzazione:\n\nUn istogramma di \\(\\hat{p}_1 - \\hat{p}_2\\) sovrapposto alla curva della distribuzione normale teorica.\n\n\n\nCalcolo della probabilit√†:\n\nProbabilit√† esatta dalla simulazione: proporzione di \\(\\hat{p}_1 - \\hat{p}_2 &gt; 0.1\\).\nProbabilit√† approssimata dalla distribuzione normale.\n\n\n\nDomande di Discussione.\n\nL‚Äôapprossimazione normale √® valida in questo caso? Perch√©?\nCome cambierebbe la distribuzione campionaria se \\(n_1\\) o \\(n_2\\) fossero pi√π piccoli?\nCome influenzerebbe la probabilit√† calcolata un valore \\(p_1\\) o \\(p_2\\) pi√π vicino a \\(0\\) o \\(1\\)?",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>74</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01a_stime_parametri.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/01a_stime_parametri.html#informazioni-sullambiente-di-sviluppo",
    "title": "74¬† Stime, stimatori e parametri",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.5.3     \n#&gt;  [9] scales_1.3.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.9.1   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         rlang_1.1.5       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       tools_4.4.2       parallel_4.4.2    tzdb_0.5.0       \n#&gt; [21] colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5       R6_2.6.1         \n#&gt; [25] lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.1    \n#&gt; [29] gtable_0.3.6      glue_1.8.0        xfun_0.51         tidyselect_1.2.1 \n#&gt; [33] rstudioapi_0.17.1 farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-167     \n#&gt; [37] labeling_0.4.3    rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>74</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html",
    "href": "chapters/frequentist_inference/02_conf_interv.html",
    "title": "75¬† Intervalli di fiducia",
    "section": "",
    "text": "75.1 Introduzione\nGli intervalli di confidenza sono uno strumento fondamentale nell‚Äôinferenza statistica frequentista. Essi consentono di stimare un parametro sconosciuto di una popolazione, come la media \\(\\mu\\), tenendo conto dell‚Äôincertezza derivante dal fatto che la stima si basa su un campione. Questo materiale didattico si propone di spiegare in modo dettagliato e chiaro la costruzione di un intervallo di confidenza per la media di una popolazione, sia nel caso di varianza nota sia in quello di varianza incognita.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>75</span>¬† <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#inferenza-statistica-frequentista-e-media-campionaria",
    "href": "chapters/frequentist_inference/02_conf_interv.html#inferenza-statistica-frequentista-e-media-campionaria",
    "title": "75¬† Intervalli di fiducia",
    "section": "\n75.2 Inferenza Statistica Frequentista e Media Campionaria",
    "text": "75.2 Inferenza Statistica Frequentista e Media Campionaria\nQuando estraiamo un campione casuale semplice \\(X_1, X_2, \\dots, X_n\\) da una popolazione con media \\(\\mu\\) e varianza \\(\\sigma^2\\), la media campionaria \\(\\bar{X}\\) √® definita come:\n\\[\n\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i.\n\\]\nLa media campionaria \\(\\bar{X}\\) √® una variabile casuale perch√© dipende dai valori osservati nel campione, che sono essi stessi casuali. Le propriet√† della media campionaria sono le seguenti:\n\n\nMedia della distribuzione campionaria: \\(E[\\bar{X}] = \\mu\\). La media campionaria √® uno stimatore non distorto della media della popolazione.\n\nVarianza della distribuzione campionaria: \\(\\text{Var}(\\bar{X}) = \\frac{\\sigma^2}{n}\\). Questo significa che la precisione di \\(\\bar{X}\\) come stima di \\(\\mu\\) aumenta con il numero di osservazioni \\(n\\).\n\nQueste propriet√† sono fondamentali per calcolare un intervallo di confidenza, poich√© ci permettono di descrivere la distribuzione di \\(\\bar{X}\\).",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>75</span>¬† <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#intervallo-di-confidenza-per-la-media-caso-di-varianza-nota",
    "href": "chapters/frequentist_inference/02_conf_interv.html#intervallo-di-confidenza-per-la-media-caso-di-varianza-nota",
    "title": "75¬† Intervalli di fiducia",
    "section": "\n75.3 Intervallo di Confidenza per la Media: Caso di Varianza Nota",
    "text": "75.3 Intervallo di Confidenza per la Media: Caso di Varianza Nota\nSupponiamo che la popolazione sia distribuita normalmente con media \\(\\mu\\) e varianza \\(\\sigma^2\\), e che \\(\\sigma^2\\) sia nota. La distribuzione della media campionaria \\(\\bar{X}\\) √® anch‚Äôessa normale:\n\\[\n\\bar{X} \\sim \\mathcal{N}\\left(\\mu, \\frac{\\sigma^2}{n}\\right).\n\\]\nPasso 1: Standardizzazione della Media Campionaria.\nPer lavorare con una distribuzione normale standard (media 0 e varianza 1), standardizziamo \\(\\bar{X}\\) utilizzando la formula:\n\\[\nZ = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}}.\n\\]\nQui, \\(\\sigma / \\sqrt{n}\\) √® la deviazione standard della distribuzione campionaria di \\(\\bar{X}\\).\nDopo questa trasformazione, la variabile \\(Z\\) segue una distribuzione normale standard:\n\\[\nZ \\sim \\mathcal{N}(0, 1).\n\\]\nPasso 2: Determinazione del Livello di Confidenza.\nScegliamo un livello di confidenza \\(\\gamma\\), ad esempio \\(\\gamma = 0.95\\). Per una distribuzione normale standard, troviamo il valore critico \\(z\\) tale che la probabilit√† tra \\(-z\\) e \\(+z\\) sia pari al livello di confidenza:\n\\[\nP(-z \\leq Z \\leq z) = \\gamma.\n\\]\nPer un livello di confidenza del 95%, \\(z \\approx 1.96\\).\nPasso 3: Formulazione dell‚ÄôIntervallo di Confidenza.\nPartiamo dalla probabilit√† per \\(Z\\):\n\\[\nP(-z \\leq Z \\leq z) = \\gamma.\n\\]\nSostituiamo la definizione di \\(Z\\):\n\\[\nP\\left(-z \\leq \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}} \\leq z\\right) = \\gamma.\n\\]\nMoltiplichiamo tutti i membri per \\(\\sigma / \\sqrt{n}\\) per rimuovere il denominatore:\n\\[\nP\\left(-z \\cdot \\frac{\\sigma}{\\sqrt{n}} \\leq \\bar{X} - \\mu \\leq z \\cdot \\frac{\\sigma}{\\sqrt{n}}\\right) = \\gamma.\n\\]\nAggiungiamo \\(\\mu\\) a tutti i membri per isolare \\(\\mu\\):\n\\[\nP\\left(\\bar{X} - z \\cdot \\frac{\\sigma}{\\sqrt{n}} \\leq \\mu \\leq \\bar{X} + z \\cdot \\frac{\\sigma}{\\sqrt{n}}\\right) = \\gamma.\n\\]\nPasso 4: Limiti dell‚ÄôIntervallo di Confidenza.\nDefiniamo i limiti inferiore e superiore dell‚Äôintervallo di confidenza:\n\\[\n\\hat{a} = \\bar{X} - z \\cdot \\frac{\\sigma}{\\sqrt{n}}, \\quad \\hat{b} = \\bar{X} + z \\cdot \\frac{\\sigma}{\\sqrt{n}}.\n\\]\nL‚Äôintervallo di confidenza per \\(\\mu\\) √® quindi:\n\\[\n(\\hat{a}, \\hat{b}) = \\left(\\bar{X} - z \\cdot \\frac{\\sigma}{\\sqrt{n}}, \\bar{X} + z \\cdot \\frac{\\sigma}{\\sqrt{n}}\\right).\n\\]",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>75</span>¬† <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#intervallo-di-confidenza-per-la-media-caso-di-varianza-incognita",
    "href": "chapters/frequentist_inference/02_conf_interv.html#intervallo-di-confidenza-per-la-media-caso-di-varianza-incognita",
    "title": "75¬† Intervalli di fiducia",
    "section": "\n75.4 Intervallo di Confidenza per la Media: Caso di Varianza Incognita",
    "text": "75.4 Intervallo di Confidenza per la Media: Caso di Varianza Incognita\nNella maggior parte dei casi pratici, la varianza \\(\\sigma^2\\) non √® nota. In questi casi, stimiamo \\(\\sigma\\) con la deviazione standard campionaria \\(s\\) e utilizziamo la distribuzione t di Student, che tiene conto dell‚Äôincertezza aggiuntiva.\nPasso 1: Distribuzione t di Student.\nLa statistica che seguiamo √®:\n\\[\nT = \\frac{\\bar{X} - \\mu}{s / \\sqrt{n}},\n\\]\ndove \\(T\\) segue una distribuzione t con \\(n-1\\) gradi di libert√†.\nPasso 2: Costruzione dell‚ÄôIntervallo di Confidenza.\nAnalogamente al caso precedente, costruiamo l‚Äôintervallo partendo da:\n\\[\nP(-t^\\ast \\leq T \\leq t^\\ast) = \\gamma,\n\\]\ndove \\(t^\\ast\\) √® il valore critico della distribuzione t per il livello di confidenza \\(\\gamma\\) e \\(n-1\\) gradi di libert√†.\nSostituendo \\(T\\):\n\\[\nP\\left(-t^\\ast \\leq \\frac{\\bar{X} - \\mu}{s / \\sqrt{n}} \\leq t^\\ast\\right) = \\gamma.\n\\]\nMoltiplichiamo per \\(s / \\sqrt{n}\\):\n\\[\nP\\left(-t^\\ast \\cdot \\frac{s}{\\sqrt{n}} \\leq \\bar{X} - \\mu \\leq t^\\ast \\cdot \\frac{s}{\\sqrt{n}}\\right) = \\gamma.\n\\]\nAggiungiamo \\(\\mu\\):\n\\[\nP\\left(\\bar{X} - t^\\ast \\cdot \\frac{s}{\\sqrt{n}} \\leq \\mu \\leq \\bar{X} + t^\\ast \\cdot \\frac{s}{\\sqrt{n}}\\right) = \\gamma.\n\\]\nPasso 3: Limiti dell‚ÄôIntervallo.\nI limiti dell‚Äôintervallo sono:\n\\[\n\\hat{a} = \\bar{X} - t^\\ast \\cdot \\frac{s}{\\sqrt{n}}, \\quad \\hat{b} = \\bar{X} + t^\\ast \\cdot \\frac{s}{\\sqrt{n}}.\n\\]\nIn conclusione, gli intervalli di confidenza forniscono un modo per quantificare l‚Äôincertezza nelle stime di parametri sconosciuti. La loro costruzione dipende dalla distribuzione campionaria dello stimatore e dall‚Äôinformazione disponibile sulla varianza.\n\n75.4.1 Applicabilit√† e Limitazioni\n\nIl metodo presuppone che la popolazione segua una distribuzione normale e √® valido anche per campioni di piccole dimensioni (ad esempio, \\(n &lt; 30\\)) prelevati da tale popolazione.\nSe la popolazione non √® normalmente distribuita e la dimensione del campione √® ridotta, questo metodo potrebbe non essere idoneo.\nTuttavia, per campioni di grandi dimensioni (\\(n \\geq 30\\)), questo approccio rimane valido per la stima dell‚Äôintervallo di confidenza grazie al teorema del limite centrale, che si applica anche a popolazioni con distribuzioni non normali.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>75</span>¬† <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#livello-di-copertura",
    "href": "chapters/frequentist_inference/02_conf_interv.html#livello-di-copertura",
    "title": "75¬† Intervalli di fiducia",
    "section": "\n75.5 Livello di Copertura",
    "text": "75.5 Livello di Copertura\nPer interpretare correttamente gli intervalli di fiducia √® fondamentale considerare il concetto di ‚Äúlivello di copertura‚Äù. Questo livello indica la frequenza con cui l‚Äôintervallo di fiducia include il valore reale del parametro della popolazione, in una serie di esperimenti ripetuti.\nEsempio di Livello di Copertura:\n\nSe il livello di copertura √® del 95%, significa che, nel lungo periodo, il 95% degli intervalli di fiducia costruiti conterr√† il valore vero del parametro.\nImportante: Questo non implica che ci sia una probabilit√† del 95% che il valore vero del parametro cada in un particolare intervallo di fiducia. Infatti, il parametro della popolazione √® un valore fisso e non soggetto a probabilit√†; piuttosto, l‚Äôincertezza risiede nell‚Äôintervallo di fiducia stesso.\n\nCome Funziona la Copertura:\n\nNel contesto frequentista, la ‚Äúprobabilit√†‚Äù si riferisce alla frequenza a lungo termine di un certo evento in un gran numero di ripetizioni dell‚Äôesperimento.\nNel caso degli intervalli di fiducia, l‚Äô‚Äúesperimento‚Äù √® l‚Äôestrazione di un campione dalla popolazione, e l‚Äô‚Äúevento‚Äù √® la generazione di un intervallo di fiducia che contiene il valore vero del parametro.\nIl livello di copertura, generalmente indicato come \\(1-\\alpha\\), rappresenta la probabilit√† a lungo termine che intervalli di fiducia costruiti con questa metodologia includano il vero valore del parametro.\n\n\n75.5.1 Simulazione\n\nPer illustrare questo concetto, eseguiamo una simulazione con la popolazione degli adulti maschi italiani, assunta come normalmente distribuita con media 175 cm e varianza 49 cm¬≤.\nEseguiamo 1000 ripetizioni di un esperimento, estraendo ogni volta un campione di 30 individui.\nPer ciascun campione, calcoliamo l‚Äôintervallo di fiducia al 95% usando la formula:\n\n\\[\n\\bar{X} \\pm t \\frac{s}{\\sqrt{n}},\n\\]\ndove \\(\\bar{X}\\) √® la media campionaria, \\(s\\) √® la deviazione standard campionaria e \\(t\\) √® il valore critico della distribuzione t-Student per \\(n-1\\) gradi di libert√† al livello di significativit√† \\(\\alpha/2 = 0.025\\). - Registriamo i limiti di ciascun intervallo e controlliamo quanti di essi includono effettivamente il vero valore medio della popolazione.\nAttraverso questa simulazione, possiamo visualizzare concretamente il concetto di livello di copertura e la sua importanza nella statistica frequentista.\nIn questa simulazione, genereremo 1000 campioni casuali di dimensione \\(n = 30\\) da una distribuzione normale con media \\(\\mu = 175\\) e deviazione standard \\(\\sigma = 7\\). Successivamente, calcoleremo gli intervalli di confidenza al 95% per ciascun campione e valuteremo il livello di copertura.\n\nset.seed(123)  # Per riproducibilit√†\n\n# Parametri della distribuzione\nmu &lt;- 175\nsigma &lt;- 7\nn &lt;- 30\nn_samples &lt;- 1000\n\n# Generazione dei campioni\nsamples &lt;- replicate(n_samples, rnorm(n, mean = mu, sd = sigma))\ndim(samples)  # Verifica dimensioni: 30 righe per 1000 colonne\n#&gt; [1]   30 1000\n\nIl primo campione di ampiezza \\(n = 30\\) che abbiamo ottenuto √® il seguente:\n\nsamples[, 1]  # Primo campione\n#&gt;  [1] 171.1 173.4 185.9 175.5 175.9 187.0 178.2 166.1 170.2 171.9 183.6 177.5\n#&gt; [13] 177.8 175.8 171.1 187.5 178.5 161.2 179.9 171.7 167.5 173.5 167.8 169.9\n#&gt; [25] 170.6 163.2 180.9 176.1 167.0 183.8\n\nStampiamo le medie dei primi dieci campioni:\n\nsample_means &lt;- colMeans(samples)  # Medie di tutti i campioni\nsample_means[1:10]  # Prime dieci medie\n#&gt;  [1] 174.7 176.2 175.2 174.3 173.7 176.1 175.1 174.4 175.4 177.4\n\nTroviamo il valore critico della distribuzione \\(t\\) di Student con \\(n - 1\\) gradi di libert√† e livello di confidenza del 95% (\\(\\alpha = 0.05\\)):\n\nalpha &lt;- 0.05\nt_critical &lt;- qt(1 - alpha / 2, df = n - 1)  # Valore critico\nt_critical\n#&gt; [1] 2.045\n\nUtilizzando il valore critico \\(t\\), calcoliamo 1000 intervalli di confidenza per la media della popolazione:\n\n# Calcolo della deviazione standard campionaria\nsample_sds &lt;- apply(samples, 2, sd)\n\n# Ampiezza degli intervalli\ninterval_width &lt;- t_critical * sample_sds / sqrt(n)\n\n# Limiti degli intervalli di confidenza\nCI_low &lt;- sample_means - interval_width\nCI_high &lt;- sample_means + interval_width\n\nTroviamo il livello di copertura, ovvero la proporzione di intervalli di confidenza che contengono il vero valore della media della popolazione \\(\\mu\\):\n\ncoverage &lt;- mean(CI_low &lt; mu & mu &lt; CI_high)  # Proporzione di copertura\ncoverage\n#&gt; [1] 0.956\n\nIn conclusione, ripetendo la simulazione per 1000 campioni, abbiamo ottenuto un livello di copertura molto vicino al valore nominale di \\(1 - \\alpha = 0.95\\). Questo risultato dimostra che, con un campione di dimensione \\(n = 30\\), gli intervalli di confidenza al 95% calcolati utilizzando la distribuzione \\(t\\) di Student forniscono stime accurate della media della popolazione.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>75</span>¬† <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#il-concetto-di-livello-di-confidenza",
    "href": "chapters/frequentist_inference/02_conf_interv.html#il-concetto-di-livello-di-confidenza",
    "title": "75¬† Intervalli di fiducia",
    "section": "\n75.6 Il Concetto di Livello di Confidenza",
    "text": "75.6 Il Concetto di Livello di Confidenza\nGli intervalli di confidenza sono range di valori che, con una certa sicurezza statistica, si ritiene includano il parametro di interesse.\nSecondo l‚Äôapproccio frequentista, l‚Äôintervallo di confidenza si deve considerare come una metodologia:\n\nSe ripetiamo l‚Äôesperimento (estrarre un campione e calcolare l‚Äôintervallo di confidenza) molte volte, il metodo produce un intervallo che coprir√† il valore vero del parametro nel 95% dei casi, assumendo un livello di confidenza del 95%.\n\n\n75.6.1 Un Malinteso Comune nell‚ÄôInterpretazione degli Intervalli di Confidenza\n√à inesatto affermare che un determinato intervallo di confidenza contenga il valore vero di un parametro con una probabilit√† del 95%. Questo √® un errore diffuso, persino tra i ricercatori, che spesso interpretano l‚Äôintervallo di confidenza come indicativo della probabilit√† che il parametro (ad esempio, la media della popolazione \\(\\mu\\)) si trovi effettivamente all‚Äôinterno di un dato intervallo (es. \\([\\hat{a}, \\hat{b}]\\)).\nLa descrizione corretta √® la seguente:\n\n‚ÄúLa metodologia impiegata per calcolare l‚Äôintervallo \\([\\hat{a}, \\hat{b}]\\) ha il 95% di probabilit√† di generare un intervallo che include il vero valore del parametro‚Äù.\nCi√≤ significa che l‚Äôintervallo di confidenza non esprime una probabilit√† circa la posizione precisa del parametro, ma riflette la probabilit√† che la procedura adottata per determinarlo generi un intervallo che lo includa.\n\nIn conclusione, l‚Äôintervallo di confidenza ci fornisce una garanzia statistica riguardo alla affidabilit√† del metodo usato per la sua stima, piuttosto che sulla esatta ubicazione del parametro in questione.\n\n75.6.2 Fraintendimenti Comuni sugli Intervalli di Confidenza\nNel loro lavoro, Hoekstra et al. (2014) evidenziano come, nonostante l‚Äôampio riconoscimento dei limiti dei test di ipotesi nulle, gli intervalli di confidenza siano spesso consigliati per l‚Äôinferenza statistica. Anche l‚ÄôAmerican Psychological Association (APA) suggerisce che gli intervalli di confidenza siano ‚Äúin generale, la migliore strategia di reportistica‚Äù. Tuttavia, Hoekstra et al. (2014) sottolineano che queste raccomandazioni non considerano la difficolt√† nel fornire una corretta interpretazione degli intervalli di confidenza.\nPer indagare l‚Äôinterpretazione degli intervalli di confidenza, Hoekstra et al. (2014) hanno condotto uno studio con due domande principali:\n\nQuanto frequentemente intervalli di confidenza sono mal interpretati da studenti e ricercatori?\nL‚Äôesperienza nella ricerca riduce le interpretazioni errate degli intervalli di confidenza?\n\nPrima di presentare lo studio, Hoekstra et al. (2014) ricordano qual √® l‚Äôinterpretazione corretta degli intervalli di confidenza.\n\nA CI is a numerical interval constructed around the estimate of a parameter. Such an interval does not, however, directly indicate a property of the parameter; instead, it indicates a property of the procedure, as is typical for a frequentist technique. Specifically, we may find that a particular procedure, when used repeatedly across a series of hypothetical data sets (i.e., the sample space), yields intervals that contain the true parameter value in 95% of the cases. When such a procedure is applied to a particular data set, the resulting interval is said to be a 95% CI. The key point is that the CIs do not provide for a statement about the parameter as it relates to the particular sample at hand; instead, they provide for a statement about the performance of the procedure of drawing such intervals in repeated use. Hence, it is incorrect to interpret a CI as the probability that the true value is within the interval (e.g., Berger & Wolpert, 1988). As is the case with \\(p\\)-values, CIs do not allow one to make probability statements about parameters or hypotheses.\n\nNel loro studio, Hoekstra et al. (2014) hanno presentato un questionario a 596 partecipanti, tra cui studenti universitari e ricercatori, con le seguenti affermazioni riguardanti l‚Äôinterpretazione degli intervalli di confidenza.\n\nProfessor Bumbledorf conducts an experiment, analyzes the data, and reports: ‚ÄúThe 95% confidence interval for the mean ranges from 0.1 to 0.4.‚Äù Please mark each of the statements below as ‚Äòtrue‚Äô or ‚Äòfalse‚Äô.\n\n\n\nThe probability that the true mean is greater than 0 is at least 95%.\nThe probability that the true mean equals 0 is smaller than 5%.\nThe ‚Äúnull hypothesis‚Äù that the true mean equals 0 is likely to be incorrect.\nThere is a 95% probability that the true mean lies between 0.1 and 0.4.\nWe can be 95% confident that the true mean lies between 0.1 and 0.4.\nIf we were to repeat the experiment over and over, then 95% of the time the true mean falls between 0.1 and 0.4.\n\n\nSorprendentemente, anche se tutte le sei affermazioni nel questionario sono errate, molti partecipanti hanno concordato con esse. I risultati mostrano che, in media, i partecipanti hanno concordato con circa 3.5 affermazioni errate su 6. Non √® stata rilevata una differenza di rilievo nell‚Äôinterpretazione degli intervalli di confidenza tra studenti e ricercatori, suggerendo che l‚Äôesperienza nella ricerca non migliora la comprensione di questo concetto.\nI risultati indicano che molte persone interpretano erroneamente gli intervalli di confidenza, e che anche l‚Äôesperienza nella ricerca non garantisce una migliore comprensione. Questo solleva dubbi sull‚Äôefficacia degli intervalli di confidenza frequentisti e suggerisce che gli ‚Äúintervalli di credibilit√†‚Äù bayesiani possano rappresentare un‚Äôalternativa pi√π vantaggiosa. Quest‚Äôultimi tendono ad essere pi√π intuitivi e di pi√π facile interpretazione corretta.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>75</span>¬† <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#confronto-tra-intervalli-frequentisti-e-bayesiani",
    "href": "chapters/frequentist_inference/02_conf_interv.html#confronto-tra-intervalli-frequentisti-e-bayesiani",
    "title": "75¬† Intervalli di fiducia",
    "section": "\n75.7 Confronto tra Intervalli Frequentisti e Bayesiani",
    "text": "75.7 Confronto tra Intervalli Frequentisti e Bayesiani\nConcludiamo questo capitolo esaminando le differenze tra l‚Äôintervallo di confidenza frequentista e l‚Äôintervallo di credibilit√† bayesiano, utilizzando lo stesso set di dati per entrambi i calcoli.\n\n75.7.1 Intervallo di confidenza frequentista\nImmaginiamo di avere un gruppo di 20 osservazioni relative alla performance in un test cognitivo. Il nostro obiettivo √® stimare la media della popolazione da cui queste osservazioni sono tratte. Supponiamo che i dati provengano da una distribuzione normale con media \\(\\mu = 50\\) e deviazione standard \\(\\sigma = 10\\).\n\nset.seed(123)  # Per risultati riproducibili\n\n# Parametri della popolazione\nsample_size &lt;- 20\nmu &lt;- 50\nsigma &lt;- 10\n\n# Simulazione del campione\nsample_data &lt;- rnorm(sample_size, mean = mu, sd = sigma)\nprint(sample_data)\n#&gt;  [1] 44.40 47.70 65.59 50.71 51.29 67.15 54.61 37.35 43.13 45.54 62.24 53.60\n#&gt; [13] 54.01 51.11 44.44 67.87 54.98 30.33 57.01 45.27\n\nVisualizziamo la distribuzione dei dati:\n\ntibble(Valori = sample_data) |&gt;\n  ggplot(aes(x = Valori)) +\n  geom_histogram(aes(y = after_stat(density)),\n    bins = 30, # Puoi regolare il numero di bin\n    fill = \"skyblue\",\n    color = \"black\",\n    alpha = 0.7\n  ) +\n  labs(\n    title = \"Distribuzione dei dati campionari\",\n    x = \"Valori\",\n    y = \"Densit√†\"\n  )\n\n\n\n\n\n\n\nLa media campionaria (\\(\\hat{\\mu}\\)) viene calcolata come:\n\\[\n\\hat{\\mu} = \\frac{1}{n} \\sum_{i=1}^n X_i\n\\]\nIn R:\n\nsample_mean &lt;- mean(sample_data)\nsample_mean\n#&gt; [1] 51.42\n\nLa deviazione standard campionaria (\\(s\\)) si calcola come:\n\\[\ns = \\sqrt{\\frac{\\sum_{i=1}^n (X_i - \\bar{X})^2}{n-1}}\n\\]\nIn R:\n\nvariance &lt;- function(x) {\n  sum((x - mean(x))^2) / length(x)\n}\n\nsample_sd &lt;- sqrt(variance(sample_data))  # Deviazione standard campionaria\nsample_sd\n#&gt; [1] 9.48\n\nL‚Äôerrore standard della media (\\(SE\\)) √®:\n\\[\nSE = \\frac{s}{\\sqrt{n}}\n\\]\nIn R:\n\nstandard_error &lt;- sample_sd / sqrt(sample_size)\nstandard_error\n#&gt; [1] 2.12\n\nUn intervallo di confidenza √® definito come:\n\\[\n\\bar{X} \\pm t_{\\text{critico}} \\cdot SE\n\\]\ndove \\(t_{\\text{critico}}\\) √® il valore critico della distribuzione \\(t\\) di Student per un livello di confidenza del 95% (\\(\\alpha = 0.05\\)) e \\(n-1\\) gradi di libert√†. In R:\n\nalpha &lt;- 0.05\ndf &lt;- sample_size - 1\nt_critical &lt;- qt(1 - alpha / 2, df)\nt_critical\n#&gt; [1] 2.093\n\nCalcoliamo il margine di errore:\n\nmargin_of_error &lt;- t_critical * standard_error\nmargin_of_error\n#&gt; [1] 4.437\n\nCalcoliamo i limiti inferiore e superiore dell‚Äôintervallo di confidenza:\n\nconfidence_interval &lt;- \n  c(sample_mean - margin_of_error, sample_mean + margin_of_error)\nconfidence_interval\n#&gt; [1] 46.98 55.85\n\nPossiamo interpretare questo risultato dicendo che la procedura utilizzata per calcolare l‚Äôintervallo include il valore vero della media della popolazione nel 95% dei casi.\nCreiamo un grafico per mostrare la distribuzione dei dati, la media campionaria e l‚Äôintervallo di confidenza:\n\ntibble(Valori = sample_data) |&gt;\n  ggplot(aes(x = Valori)) +\n  geom_histogram(aes(y = ..density..),\n    bins = 30, # Puoi regolare il numero di bin\n    fill = \"skyblue\",\n    color = \"black\",\n    alpha = 0.7\n  ) +\n\n  # Linea per la media campionaria\n  geom_vline(aes(xintercept = sample_mean),\n    color = \"blue\",\n    linetype = \"dashed\",\n    linewidth = 1.2\n  ) +\n\n  # Linee per l'intervallo di confidenza\n  geom_vline(aes(xintercept = confidence_interval[1]),\n    color = \"darkgreen\",\n    linewidth = 1.2\n  ) +\n  geom_vline(aes(xintercept = confidence_interval[2]),\n    color = \"darkgreen\",\n    linewidth = 1.2\n  ) +\n\n  # Titoli e assi\n  labs(\n    title = \"Intervallo di Confidenza per la Media\",\n    x = \"Valori\",\n    y = \"Densit√†\"\n  ) +\n\n  # Legenda personalizzata\n  annotate(\"text\",\n    x = sample_mean, y = 0.02, label = \"Media campionaria\",\n    color = \"blue\", angle = 90, vjust = -0.5\n  ) +\n  annotate(\"text\",\n    x = confidence_interval[1], y = 0.02, label = \"IC Inferiore\",\n    color = \"darkgreen\", angle = 90, vjust = -0.5\n  ) +\n  annotate(\"text\",\n    x = confidence_interval[2], y = 0.02, label = \"IC Superiore\",\n    color = \"darkgreen\", angle = 90, vjust = -0.5\n  )\n\n\n\n\n\n\n\n\n75.7.1.1 Confronto tra gli Approcci Frequentista e Bayesiano\nIntervallo di Credibilit√† Bayesiano:\n\nRappresenta il grado di credenza (posteriori) che il parametro \\(\\mu\\) si trovi all‚Äôinterno dell‚Äôintervallo calcolato.\nDipende sia dai dati osservati sia dalle distribuzioni a priori utilizzate nel modello, che possono influenzare il risultato in base alla loro specificit√† o vaghezza.\n\nIntervallo di Confidenza Frequentista:\n\nNon esprime la probabilit√† che il parametro \\(\\mu\\) appartenga a un determinato intervallo.\nSi riferisce invece alla procedura di costruzione dell‚Äôintervallo: se il campionamento fosse ripetuto infinite volte, il 95% degli intervalli costruiti conterrebbe il vero valore di \\(\\mu\\).\n\nIn sintesi:\n\nL‚Äôintervallo di credibilit√† bayesiano fornisce una stima probabilistica diretta e interpretabile della posizione di \\(\\mu\\), basata su dati osservati e informazioni a priori.\nL‚Äôintervallo di confidenza frequentista, invece, valuta la affidabilit√† della procedura nel lungo termine, senza fare affermazioni dirette sulla probabilit√† che il parametro rientri nell‚Äôintervallo specifico.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>75</span>¬† <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#riflessioni-conclusive",
    "href": "chapters/frequentist_inference/02_conf_interv.html#riflessioni-conclusive",
    "title": "75¬† Intervalli di fiducia",
    "section": "\n75.8 Riflessioni Conclusive",
    "text": "75.8 Riflessioni Conclusive\nCome sottolineato da Hoekstra et al. (2014), √® comune riscontrare fraintendimenti riguardo agli intervalli di fiducia. Il ‚Äúlivello di confidenza del 95%‚Äù √® da interpretarsi come la probabilit√† a lungo termine che, in una serie di intervalli di fiducia calcolati, il 95% di essi includa il vero valore del parametro sconosciuto. Tuttavia, per un singolo intervallo di fiducia, non √® possibile dichiarare con sicurezza che questo contenga effettivamente il parametro di interesse. In altre parole, la certezza sulla presenza del parametro sconosciuto all‚Äôinterno di un dato intervallo di fiducia non √® garantita per ogni singolo caso analizzato.\n√à inoltre inesatto presumere che esista un legame diretto tra la varianza e la media di un campione, ipotizzando che un intervallo di fiducia pi√π ristretto implichi maggiore precisione. Nella prospettiva frequentista, la ‚Äúprecisione‚Äù √® strettamente legata al livello di copertura a lungo termine assicurato dal metodo usato per creare gli intervalli di fiducia. Questo concetto non si applica al singolo intervallo di fiducia osservato. Dunque, un intervallo di fiducia che si presenta estremamente ristretto potrebbe in realt√† essere significativamente lontano dal valore vero del parametro non noto.\n√à importante sottolineare che l‚Äôapproccio frequentista offre un metodo per calcolare gli intervalli di confidenza per una vasta gamma di statistiche. Questo include, ad esempio, la stima dell‚Äôintervallo di confidenza per la differenza tra due medie, per una proporzione o per la differenza tra due proporzioni. Ecco le formule per calcolare gli intervalli di confidenza per i casi menzionati:\nIntervallo di confidenza per la differenza tra due medie.\nSe abbiamo due campioni indipendenti di dimensione \\(n_1\\) e \\(n_2\\), con medie \\(\\bar{x}_1\\) e \\(\\bar{x}_2\\) e deviazioni standard \\(s_1\\) e \\(s_2\\), l‚Äôintervallo di confidenza per la differenza tra le medie √® calcolato come:\n\\[\n(\\bar{x}_1 - \\bar{x}_2) \\pm t_{\\alpha/2} \\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}},\n\\]\ndove \\(t_{\\alpha/2}\\) √® il valore critico della distribuzione t di Student con \\(\\alpha/2\\) di probabilit√† di coda e gradi di libert√† \\(df = n_1 + n_2 - 2\\).\nIntervallo di confidenza per una proporzione.\nPer stimare l‚Äôintervallo di confidenza per una proporzione \\(p\\) in un campione binomiale di dimensione \\(n\\), la formula √®:\n\\[\n\\hat{p} \\pm z_{\\alpha/2} \\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}},\n\\]\ndove \\(\\hat{p}\\) √® la proporzione campionaria e \\(z_{\\alpha/2}\\) √® il valore critico della distribuzione normale standard con \\(\\alpha/2\\) di probabilit√† di coda.\nIntervallo di confidenza per la differenza tra due proporzioni.\nPer stimare l‚Äôintervallo di confidenza per la differenza tra due proporzioni \\(p_1\\) e \\(p_2\\) in due campioni binomiali di dimensioni \\(n_1\\) e \\(n_2\\), la formula √®:\n\\[\n(\\hat{p}_1 - \\hat{p}_2) \\pm z_{\\alpha/2} \\sqrt{\\frac{\\hat{p}_1(1 - \\hat{p}_1)}{n_1} + \\frac{\\hat{p}_2(1 - \\hat{p}_2)}{n_2}},\n\\]\ndove \\(\\hat{p}_1\\) e \\(\\hat{p}_2\\) sono le proporzioni campionarie e \\(z_{\\alpha/2}\\) √® il valore critico della distribuzione normale standard con \\(\\alpha/2\\) di probabilit√† di coda.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>75</span>¬† <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#esercizi",
    "href": "chapters/frequentist_inference/02_conf_interv.html#esercizi",
    "title": "75¬† Intervalli di fiducia",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\n\nChe cos‚Äô√® un intervallo di confidenza dal punto di vista frequentista?\nChe cosa significa la copertura al 95% di un intervallo di confidenza?\nPerch√© non √® corretto dire che ‚Äúc‚Äô√® il 95% di probabilit√† che il valore vero di \\(\\mu\\) cada in questo intervallo di confidenza‚Äù?\nIn cosa consiste la differenza tra un intervallo di confidenza costruito con la distribuzione normale standard \\(Z\\) e uno costruito con la distribuzione \\(t\\) di Student?\nPerch√©, nel caso di varianza incognita, si usa la deviazione standard campionaria \\(s\\) al posto di \\(\\sigma\\)?\nCome influenza la dimensione del campione \\(n\\) l‚Äôampiezza dell‚Äôintervallo di confidenza?\nPerch√© gli intervalli di confidenza frequentisti si basano su un concetto di ‚Äúripetizione dell‚Äôesperimento‚Äù nel lungo periodo?\nQuali sono due fraintendimenti comuni sugli intervalli di confidenza?\nCome si interpreta correttamente un intervallo di confidenza al 95%?\nQual √® la differenza essenziale tra un intervallo di confidenza frequentista e un intervallo di credibilit√† bayesiano?\n\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\n\nChe cos‚Äô√® un intervallo di confidenza dal punto di vista frequentista?\n\nRisposta\nUn intervallo di confidenza (IC) √® un range di valori costruito attorno a una stima campionaria (ad esempio, la media campionaria) che, secondo il metodo frequentista adottato, conterr√† il valore vero del parametro in una certa proporzione di casi (ad esempio il 95%) se si ripetesse l‚Äôesperimento (ossia il campionamento) un numero molto grande di volte. Non esprime dunque la ‚Äúprobabilit√†‚Äù che il parametro sia dentro l‚Äôintervallo in un singolo caso, ma una frequenza di successo nel lungo periodo.\n\nChe cosa significa la copertura al 95% di un intervallo di confidenza?\n\nRisposta\nIl livello di copertura (ad esempio, 95%) indica che, in una serie ipotetica di infiniti campioni indipendenti e nel calcolo ripetuto di infiniti intervalli di confidenza secondo la stessa procedura, il 95% di tali intervalli conterr√† il valore vero del parametro. √à una propriet√† della procedura di costruzione degli intervalli, non di un singolo intervallo gi√† calcolato.\n\nPerch√© non √® corretto dire che ‚Äúc‚Äô√® il 95% di probabilit√† che il valore vero di \\(\\mu\\) cada in questo intervallo di confidenza‚Äù?\n\nRisposta\nNella prospettiva frequentista, il parametro \\(\\mu\\) √® considerato un valore fisso (non una variabile casuale). L‚Äôincertezza risiede nel campione e nella procedura di costruzione dell‚Äôintervallo, non nel parametro. Di conseguenza, non si pu√≤ associare una probabilit√† alla posizione di \\(\\mu\\) all‚Äôinterno di un singolo intervallo: l‚Äôintervallo o contiene \\(\\mu\\) oppure no, senza mezze misure probabilistiche.\n\nIn cosa consiste la differenza tra un intervallo di confidenza costruito con la distribuzione normale standard \\(Z\\) e uno costruito con la distribuzione \\(t\\) di Student?\n\nRisposta\n- Distribuzione \\(Z\\): si utilizza quando la varianza della popolazione \\(\\sigma^2\\) √® nota (o si approssima molto bene) e la popolazione √® normalmente distribuita, o quando il campione √® molto grande (per applicare il teorema del limite centrale).\n- Distribuzione \\(t\\): si impiega quando la varianza \\(\\sigma^2\\) non √® nota e bisogna stimarla con la deviazione standard campionaria \\(s\\). La distribuzione \\(t\\) ‚Äúcorregge‚Äù per l‚Äôincertezza aggiuntiva dovuta alla stima di \\(\\sigma\\) e diventa progressivamente simile alla normale standard quando il numero di gradi di libert√† (cio√® la dimensione del campione meno uno) √® elevato.\n\nPerch√©, nel caso di varianza incognita, si usa la deviazione standard campionaria \\(s\\) al posto di \\(\\sigma\\)?\n\nRisposta\nQuando \\(\\sigma\\) non √® nota, la si sostituisce con la stima campionaria \\(s\\). Poich√© \\(s\\) √® anch‚Äôessa una variabile casuale (cio√® dipende dai dati osservati), introduce un‚Äôulteriore fonte di incertezza. Questo giustifica l‚Äôuso della distribuzione \\(t\\) di Student anzich√© della normale standard, poich√© \\(t\\) ingloba tale incertezza aggiuntiva.\n\nCome influenza la dimensione del campione \\(n\\) l‚Äôampiezza dell‚Äôintervallo di confidenza?\n\nRisposta\nAumentando \\(n\\), l‚Äôerrore standard della media (cio√® \\(\\frac{\\sigma}{\\sqrt{n}}\\) oppure \\(\\frac{s}{\\sqrt{n}}\\)) diminuisce. Di conseguenza, l‚Äôintervallo di confidenza si restringe (a parit√† di livello di confidenza). In altre parole, con pi√π dati a disposizione la stima della media √® pi√π ‚Äúprecisa‚Äù nel senso frequentista, e ci√≤ si riflette in un IC pi√π stretto.\n\nPerch√© gli intervalli di confidenza frequentisti si basano su un concetto di ‚Äúripetizione dell‚Äôesperimento‚Äù nel lungo periodo?\n\nRisposta\nLa filosofia frequentista definisce la probabilit√† come una frequenza relativa di un evento dopo molteplici repliche dell‚Äôesperimento. Per gli intervalli di confidenza, ci√≤ implica che la probabilit√† di copertura (ad esempio 95%) √® intesa come la frequenza con cui, ripetendo infinite volte il campionamento e la costruzione di IC allo stesso modo, l‚Äôintervallo calcolato conterr√† il vero parametro. Non riguarda invece la probabilit√† del parametro di trovarsi in un intervallo specifico.\n\nQuali sono due fraintendimenti comuni sugli intervalli di confidenza?\n\nRisposta\n1. Credere che l‚ÄôIC fornisca una probabilit√† diretta di contenere il parametro (es. ‚Äúc‚Äô√® il 95% di probabilit√† che \\(\\mu\\) sia qui dentro‚Äù) ‚Äì in realt√†, nel frequentismo \\(\\mu\\) √® fisso e l‚ÄôIC varia.\n2. Pensare che l‚Äôintervallo di confidenza sia significativo per la singola stima pi√π che per la procedura ‚Äì in realt√†, il 95% di copertura si riferisce alla ripetizione dell‚Äôesperimento, non a un singolo intervallo.\n\nCome si interpreta correttamente un intervallo di confidenza al 95%?\n\nRisposta\n‚ÄúSe ripetiamo pi√π volte l‚Äôesperimento, ossia estraiamo molti campioni indipendenti dalla popolazione e costruiamo ogni volta un intervallo di confidenza con la stessa procedura, allora il 95% di quegli intervalli conterr√† il valore vero della media \\(\\mu\\).‚Äù √à dunque una garanzia circa l‚Äôefficacia della metodologia nel lungo periodo.\n\nQual √® la differenza essenziale tra un intervallo di confidenza frequentista e un intervallo di credibilit√† bayesiano?\n\nRisposta\n- Intervallo di confidenza frequentista: descrive la performance a lungo termine di una procedura; non permette di affermare ‚Äúla probabilit√† che \\(\\mu\\) sia nell‚Äôintervallo √® il 95%‚Äù.\n- Intervallo di credibilit√† bayesiano: esprime direttamente una credenza probabilistica a posteriori sul parametro (ad esempio, ‚Äúc‚Äô√® il 95% di probabilit√† che \\(\\mu\\) sia in questo intervallo‚Äù), perch√© il parametro √® trattato come variabile casuale, con una distribuzione a priori che si aggiorna con i dati osservati.\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nDi seguito trovi 10 esercizi incentrati sulla costruzione di intervalli di confidenza. I primi 5 richiedono di svolgere i calcoli ‚Äúa mano‚Äù (carta e penna o calcolatrice), gli ultimi 5 prevedono l‚Äôutilizzo di R.\nEsercizi da Risolvere ‚Äúa Mano‚Äù\n\nIntervallo di Confidenza per la Media (Varianza Nota)\n\nUna ricercatrice vuole stimare la media di un punteggio di reattivit√† emotiva (scala 0‚Äì100) in giovani adulti. Dai dati precedenti, si sa che la varianza vera (della popolazione) √® \\(\\sigma^2 = 16\\). Si raccoglie un campione di \\(n=25\\) partecipanti e la media campionaria risulta \\(\\bar{X} = 45\\).\n1. Calcola l‚Äôintervallo di confidenza al 95% per la media della popolazione (\\(\\mu\\)).\n2. Fornisci un‚Äôinterpretazione corretta (frequentista) del risultato.\n\nIntervallo di Confidenza per la Media (Varianza Incognita, 99%)\n\nIn un‚Äôindagine sulla soddisfazione lavorativa (scala da 1 a 7), vengono coinvolti \\(n=10\\) psicologi clinici. I dati raccolti forniscono:\n- Media campionaria \\(\\bar{X} = 5{,}6\\)\n- Deviazione standard campionaria \\(s=0{,}8\\)\nLa popolazione √® considerata approssimativamente normale ma la varianza √® ignota. Calcola l‚ÄôIC al 99% per la vera media di soddisfazione \\(\\mu\\).\n\nIntervallo di Confidenza per la Differenza tra Due Medie (Varianze Incognite Uguali)\n\nUn team di psicologi del lavoro vuole confrontare i livelli di stress (scala 0‚Äì50) tra due gruppi di dipendenti di un‚Äôazienda (Campione 1: reparto A, Campione 2: reparto B). I dati sono:\n\nReparto A (\\(n_1=12\\)):\\(\\bar{X}_1 = 22\\), \\(s_1 = 4\\)\nReparto B (\\(n_2=10\\)):\\(\\bar{X}_2 = 19\\), \\(s_2 = 3{,}5\\)\n\nAssumi che le due popolazioni siano normali con varianze ignote ma uguali e calcola l‚Äôintervallo di confidenza al 95% per \\(\\mu_A - \\mu_B\\). (Usa quindi la formula con la varianza pooled.)\n\nIntervallo di Confidenza per una Proporzione\n\nUno studio pilota su un programma di training per la gestione dell‚Äôansia vede 120 persone iscriversi. Alla fine del programma, 48 di loro riportano di aver diminuito la frequenza di attacchi di panico in modo ‚Äúsignificativo‚Äù.\n1. Stima la proporzione campionaria \\(\\hat{p}\\).\n2. Calcola l‚ÄôIC al 95% per la vera proporzione \\(p\\) di persone che trarrebbe beneficio ‚Äúsignificativo‚Äù dal programma.\n\nIntervallo di Confidenza per la Differenza tra Due Proporzioni\n\nIn un esperimento, due gruppi di partecipanti ricevono diversi percorsi di psicoterapia per ridurre l‚Äôinsonnia:\n\n\nGruppo 1 (\\(n_1=50\\)): 35 persone riportano un netto miglioramento del sonno.\n\n\nGruppo 2 (\\(n_2=40\\)): 20 persone riportano un netto miglioramento del sonno.\n\nSi vuole stimare la differenza \\((p_1 - p_2)\\) nelle proporzioni di successo dei due trattamenti. Calcola l‚ÄôIC al 95%.\nEsercizi da Risolvere con R\nNei prossimi esercizi, utilizza R per effettuare i calcoli. I dati sono gi√† contestualizzati in ambito psicologico.\n\nIntervallo di Confidenza per la Media (Varianza Incognita)\n\nHai misurato i tempi di reazione (in millisecondi) a uno stimolo di pericolo in un gruppo di 15 partecipanti. I dati (approssimati) sono:\nreaction_times &lt;- c(220, 250, 210, 240, 260, 270, 225, 255, 235, 245, 210, 270, 265, 220, 230)\n\nUtilizza R per calcolare la media e la deviazione standard campionaria.\n\nCostruisci (tramite t.test(reaction_times)) l‚Äôintervallo di confidenza al 95% per il tempo di reazione medio della popolazione.\n\n\nIntervallo di Confidenza per la Differenza tra Due Medie (Varianze Incognite)\n\nDue gruppi di studenti hanno svolto un test di memoria verbale dopo aver seguito differenti strategie di studio:\ngroupA &lt;- c(15, 12, 18, 10, 14, 16, 19, 11)\ngroupB &lt;- c(10, 9, 14, 11, 8, 12, 13, 15)\n\nCalcola in R le medie campionarie dei due gruppi.\n\nUtilizza t.test(groupA, groupB, var.equal = FALSE) per ottenere l‚ÄôIC al 95% della differenza \\(\\mu_A - \\mu_B\\).\n\nRiporta i risultati numerici.\n\n\nIntervallo di Confidenza per una Proporzione (Studio su Fobia Specifica)\n\nIn un piccolo studio, hai i dati (binari: 1 = ‚Äúattacco d‚Äôansia‚Äù, 0 = ‚Äúnessun attacco‚Äù) raccolti da 20 persone esposte a uno stimolo fobico:\nattacks &lt;- c(1,0,0,1,1,1,1,0,0,1,0,1,1,1,1,0,0,1,0,1)\n\nCalcola in R la proporzione campionaria di attacchi d‚Äôansia.\n\nUtilizza prop.test() per costruire l‚ÄôIC al 95% per la proporzione vera di attacchi d‚Äôansia in questa specifica situazione.\n\n\nIntervallo di Confidenza per la Differenza tra Due Proporzioni (Test A/B di un Training Psicologico)\n\nDue versioni di un training psicologico anti-stress (A e B) sono state testate su studenti universitari, registrando (binario: 1/0) se al termine del corso mostrano ridotti livelli di stress:\nversionA &lt;- c(1,1,0,1,1,0,1,0,1,1,0,1)\nversionB &lt;- c(0,0,1,1,1,0,1,0,0,1,0,0)\n\nCalcola in R \\(\\hat{p}_A\\) e \\(\\hat{p}_B\\).\n\nUsa prop.test(x = ..., n = ...) per l‚ÄôIC al 95% di \\((p_A - p_B)\\).\n\nRiporta i risultati.\n\n\nSimulazione di Copertura per l‚ÄôIC sulla Media (Contesto Psicologico)\n\nScrivi (o completa) uno script in R che simuli 1000 campioni di punteggi di ansia (scala 0‚Äì80) estratti da una distribuzione approssimata come Normale, con media vera \\(\\mu=40\\) e \\(\\sigma=10\\). Per ogni campione di ampiezza \\(n=25\\):\n\nCalcola la media campionaria e la deviazione standard.\n\nCostruisci l‚ÄôIC al 95% (usando la distribuzione t).\n\nVerifica quante volte l‚Äôintervallo contiene il vero valore \\(\\mu = 40\\).\n\nStima la proporzione di copertura e commenta se √® prossima a 0,95.\n\nEsempio di traccia:\nset.seed(123)\nn_sims &lt;- 1000\nn &lt;- 25\nmu &lt;- 40\nsigma &lt;- 10\n\ncount_included &lt;- 0\n\nfor(i in 1:n_sims){\n  sample_data &lt;- rnorm(n, mean = mu, sd = sigma)\n  # calcola media, sd, IC, verifica se 40 √® dentro l‚ÄôIC\n}\n\ncoverage &lt;- count_included / n_sims\ncoverage\n\n\n\n\n\n\n\n\n\nSoluzioni 2\n\n\n\n\n\nSoluzioni Esercizi ‚Äúa Mano‚Äù\nSoluzione 1\n\nDati: \\(\\sigma^2=16 \\implies \\sigma=4\\); \\(n=25\\); \\(\\bar{X}=45\\); livello di confidenza 95% (\\(\\alpha=0{,}05\\)).\n\nErrore standard:\\[\n\\text{SE} = \\frac{\\sigma}{\\sqrt{n}} = \\frac{4}{5} = 0{,}8.\n\\]\n\nValore critico \\(z_{\\alpha/2}\\approx 1{,}96\\).\n\nMargine di errore:\\[\nE = z_{\\alpha/2} \\times \\text{SE} \\approx 1{,}96 \\times 0{,}8 = 1{,}57.\n\\]\n\nIC 95%:\\[\n45 \\pm 1{,}57 \\quad \\Rightarrow \\quad (43{,}43;\\, 46{,}57).\n\\]\n\n\nSoluzione 2\n\nDati: \\(n=10\\), \\(\\bar{X}=5{,}6\\), \\(s=0{,}8\\), confidenza 99% (\\(\\alpha=0{,}01\\)).\n\nGradi di libert√† \\(df = 9\\). Il valore di \\(t_{\\alpha/2, df=9}\\) (per \\(\\alpha/2=0{,}005\\)) √® approssimativamente 3,25 (dipende dalla tabella).\n\nErrore standard:\\[\n\\text{SE} = \\frac{s}{\\sqrt{n}} = \\frac{0{,}8}{\\sqrt{10}} \\approx \\frac{0{,}8}{3{,}162} \\approx 0{,}253.\n\\]\n\nMargine di errore:\\[\nE = 3{,}25 \\times 0{,}253 \\approx 0{,}82.\n\\]\n\nIC al 99%:\\[\n5{,}6 \\pm 0{,}82 \\quad \\Rightarrow \\quad (4{,}78;\\, 6{,}42).\n\\]\n\n\nSoluzione 3\n\nDati:\n\nCampione 1 (A): \\(n_1=12\\), \\(\\bar{X}_1=22\\), \\(s_1=4\\).\n\nCampione 2 (B): \\(n_2=10\\), \\(\\bar{X}_2=19\\), \\(s_2=3{,}5\\).\n\nIC 95% \\(\\Rightarrow \\alpha=0{,}05\\).\n\nSi assume varianza uguale (\\(\\sigma_A^2 = \\sigma_B^2\\)) \\(\\Rightarrow\\) varianza pooled.\n\n\n\n\nVarianza campionaria: \\(s_1^2=16\\), \\(s_2^2=12{,}25\\).\n\nVarianza pooled:\\[\ns_p^2\n= \\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2}\n= \\frac{(11 \\times 16) + (9 \\times 12{,}25)}{12 + 10 - 2}.\n\\] \\[\n= \\frac{176 + 110{,}25}{20}\n= \\frac{286{,}25}{20}\n= 14{,}3125.\n\\] \\[\ns_p = \\sqrt{14{,}3125} \\approx 3{,}785.\n\\]\n\nErrore standard della differenza:\\[\n\\text{SE}(\\bar{X}_1 - \\bar{X}_2)\n= \\sqrt{\\,s_p^2\\!\\left(\\tfrac{1}{n_1} + \\tfrac{1}{n_2}\\right)}\n= \\sqrt{\\,14{,}3125 \\times \\left(\\tfrac{1}{12} + \\tfrac{1}{10}\\right)}.\n\\] \\[\n\\tfrac{1}{12} + \\tfrac{1}{10} = 0{,}0833 + 0{,}1 = 0{,}1833.\n\\] \\[\n14{,}3125 \\times 0{,}1833 \\approx 2{,}624\n\\quad \\Rightarrow \\quad \\sqrt{2{,}624} \\approx 1{,}62.\n\\]\n\nDifferenza campionaria: \\(\\bar{X}_1 - \\bar{X}_2 = 3\\).\n\nValore critico \\(t_{\\alpha/2}\\) con \\(df = n_1 + n_2 - 2 = 20\\): circa 2,086.\n\nMargine di errore: \\(E \\approx 2{,}086 \\times 1{,}62 \\approx 3{,}38\\).\n\nIC 95%:\\[\n3 \\pm 3{,}38 \\quad \\Rightarrow \\quad (-0{,}38;\\, 6{,}38).\n\\] (Approssimando: i valori variano un po‚Äô in base agli arrotondamenti.)\n\n\nSoluzione 4\n\nDati: \\(n=120\\), successo \\(x=48\\).\n\n\n\\(\\hat{p} = \\frac{48}{120}=0{,}4\\).\n\nErrore standard (approssimazione normale):\\[\n\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} = \\sqrt{\\frac{0{,}4 \\times 0{,}6}{120}} = \\sqrt{\\frac{0{,}24}{120}} = \\sqrt{0{,}002} \\approx 0{,}0447.\n\\]\n\nCon \\(\\alpha=0{,}05\\), \\(z_{\\alpha/2} \\approx 1{,}96\\).\n\nMargine di errore:\\[\nE = 1{,}96 \\times 0{,}0447 \\approx 0{,}0876.\n\\]\n\nIC 95%:\\[\n0{,}4 \\pm 0{,}0876 \\quad \\Rightarrow \\quad (0{,}3124;\\, 0{,}4876).\n\\]\n\n\nSoluzione 5\n\nDati:\n\nGruppo 1 (\\(n_1=50\\)): 35 successi \\(\\Rightarrow \\hat{p}_1=35/50=0{,}70\\).\n\nGruppo 2 (\\(n_2=40\\)): 20 successi \\(\\Rightarrow \\hat{p}_2=20/40=0{,}50\\).\n\n\n\nDifferenza: \\(\\hat{p}_1 - \\hat{p}_2=0{,}20\\).\n\nErrore standard:\\[\n\\sqrt{\\frac{0{,}70 \\cdot 0{,}30}{50} + \\frac{0{,}50 \\cdot 0{,}50}{40}}\n= \\sqrt{\\frac{0{,}21}{50} + \\frac{0{,}25}{40}}\n= \\sqrt{0{,}0042 + 0{,}00625}\n= \\sqrt{0{,}01045} \\approx 0{,}1022.\n\\]\n\nMargine di errore (al 95%, \\(z_{\\alpha/2}=1{,}96\\)):\\[\n1{,}96 \\times 0{,}1022 \\approx 0{,}200.\n\\]\n\nIC 95%:\\[\n0{,}20 \\pm 0{,}20 \\quad \\Rightarrow \\quad (0{,}00;\\, 0{,}40).\n\\] *(Pu√≤ capitare un limite inferiore esattamente 0, se si arrotonda.)\n\nSoluzioni Esercizi con R\n(I risultati possono variare leggermente a seconda della versione di R e di eventuali correzioni di continuit√† nelle funzioni di test.)\nSoluzione 6\nreaction_times &lt;- c(220, 250, 210, 240, 260, 270, 225, 255, 235, 245, 210, 270, 265, 220, 230)\n\nmean(reaction_times)         # media\nsd(reaction_times)           # deviazione standard\nt.test(reaction_times)       # t.test con conf.level = 0.95 di default\n\nEsempio di risultato:\n\nMedia campionaria \\(\\bar{X}\\approx 240\\) (dipende dai dati esatti)\n\n\nt.test() riporta un IC 95% (ad es.): \\((230, 250)\\) [numeri a titolo di esempio].\n\n\n\nSoluzione 7\ngroupA &lt;- c(15, 12, 18, 10, 14, 16, 19, 11)\ngroupB &lt;- c(10, 9, 14, 11, 8, 12, 13, 15)\n\nmean(groupA)  # ~ 14.375\nmean(groupB)  # ~ 11.50\nt.test(groupA, groupB, var.equal = FALSE)\n\n\nEsempio di output (fittizio):\nWelch Two Sample t-test\ndata:  groupA and groupB\nt = 2.35, df = 13.7, p-value = 0.033\n95 percent confidence interval:\n  0.47  5.77\nsample estimates:\n  mean of x  mean of y \n      14.375     11.500\nQuindi l‚ÄôIC 95% per \\(\\mu_A - \\mu_B\\) potrebbe essere circa \\((0{,}47;\\, 5{,}77)\\).\n\n\nSoluzione 8\nattacks &lt;- c(1,0,0,1,1,1,1,0,0,1,0,1,1,1,1,0,0,1,0,1)\n\nsum(attacks)        # conta quanti \"1\"\nlength(attacks)     # 20\n\nprop.test(sum(attacks), length(attacks), conf.level = 0.95)\n\nSe, ad esempio, vi fossero 12 ‚Äú1‚Äù su 20, \\(\\hat{p}=0{,}60\\).\n\nL‚Äôintervallo di confidenza al 95% (a seconda della continuity correction) potrebbe essere indicativamente \\((0{,}36;\\, 0{,}80)\\).\n\nSoluzione 9\nversionA &lt;- c(1,1,0,1,1,0,1,0,1,1,0,1)\nversionB &lt;- c(0,0,1,1,1,0,1,0,0,1,0,0)\n\nsumA &lt;- sum(versionA)\nsumB &lt;- sum(versionB)\nnA   &lt;- length(versionA)\nnB   &lt;- length(versionB)\n\nprop.test(c(sumA,sumB), c(nA,nB), conf.level = 0.95)\n\nEsempio:\n\n\nsum(versionA) = 8 successi su 12 (\\(\\hat{p}_A=0{,}666...\\))\n\n\nsum(versionB) = 5 successi su 12 (\\(\\hat{p}_B=0{,}416...\\))\n\nL‚ÄôIC per \\(\\hat{p}_A - \\hat{p}_B\\) potrebbe essere, ad esempio, \\((-0{,}05;\\, 0{,}61)\\).\n\n\n\n(I numeri esatti variano a seconda dell‚Äôeventuale correzione di continuit√†.)\nSoluzione 10\nUn possibile script:\nset.seed(123)\nn_sims &lt;- 1000\nn &lt;- 25\nmu &lt;- 40\nsigma &lt;- 10\n\ncount_included &lt;- 0\n\nfor(i in 1:n_sims){\n  sample_data &lt;- rnorm(n, mean = mu, sd = sigma)\n  xbar &lt;- mean(sample_data)\n  s &lt;- sd(sample_data)\n  \n  # t critico\n  t_crit &lt;- qt(0.975, df = n - 1)\n  \n  # IC\n  se &lt;- s / sqrt(n)\n  E &lt;- t_crit * se\n  lower &lt;- xbar - E\n  upper &lt;- xbar + E\n  \n  if(mu &gt;= lower & mu &lt;= upper){\n    count_included &lt;- count_included + 1\n  }\n}\n\ncoverage &lt;- count_included / n_sims\ncoverage\n\n\nEsempio di risultato:\n&gt; coverage\n[1] 0.948\nOvvero ~94,8% degli IC contengono il vero valore \\(\\mu=40\\), in linea con il 95% atteso (piccole differenze dovute al caso).\n\n\nCommento Conclusivo\nIn ogni caso, ricorda sempre che l‚Äôinterpretazione frequentista di un intervallo di confidenza si basa sulla ‚Äúcopertura a lungo termine‚Äù del metodo di costruzione dell‚ÄôIC, non sulla probabilit√† che il vero parametro cada nell‚Äôintervallo specifico appena calcolato.\n\n\n\n\n\n\n\n\n\nProblemi 3\n\n\n\n\n\nEsercizio 1 ‚Äì Calcolo e interpretazione dell‚ÄôIC frequentista per la media\n\n\nCalcola la media campionaria \\(\\bar{X}\\) e la deviazione standard campionaria \\(s\\).\n\nAssumendo che il punteggio SWLS nella popolazione di riferimento (ad esempio, ‚Äúgiovani adulti universitari‚Äù) sia approssimativamente normale ma con varianza sconosciuta, costruisci l‚Äôintervallo di confidenza al 95% per la media \\(\\mu\\) utilizzando la distribuzione \\(t\\) di Student con \\(n - 1\\) gradi di libert√† (dove \\(n=10\\)).\n\n\nInterpreta questo intervallo di confidenza in ottica frequentista. Metti in evidenza la distinzione fra l‚Äô‚Äúinterpretazione corretta‚Äù (copertura sul lungo periodo) e l‚Äô‚Äúinterpretazione scorretta‚Äù (credere che ci sia il 95% di probabilit√† che \\(\\mu\\) stia nell‚Äôintervallo calcolato).\n\nSpunti di riflessione sui limiti:\n- Con un campione molto piccolo, l‚Äôintervallo di confidenza potrebbe essere molto ampio.\n- Se la popolazione non fosse davvero normale, la validit√† dell‚ÄôIC con distribuzione \\(t\\) potrebbe essere compromessa.\n- In ottica frequentista, il singolo intervallo o contiene il vero valore di \\(\\mu\\) o non lo contiene: la ‚Äúprobabilit√† 95%‚Äù si riferisce alla procedura di costruzione, non a questo singolo intervallo specifico.\nEsercizio 2 ‚Äì Sensibilit√† dell‚ÄôIC a diversi livelli di confidenza\n\nUtilizzando gli stessi 10 dati, calcola:\n\nl‚Äôintervallo di confidenza all‚Äô80%\n\nl‚Äôintervallo di confidenza al 99%\n\n\n\nConfronta l‚Äôampiezza dei tre intervalli (80%, 95%, 99%).\n\nCommenta dal punto di vista dell‚Äôinterpretazione frequentista: perch√© l‚ÄôIC al 99% √® pi√π ampio di quello al 95%, e quest‚Äôultimo √® pi√π ampio di quello all‚Äô80%?\n\nSpunti di riflessione sui limiti:\n- Aumentare il livello di confidenza fa s√¨ che l‚ÄôIC si allarghi, spesso di molto se \\(n\\) √® piccolo.\n- Un IC pi√π ampio rassicura sulla ‚Äúcopertura‚Äù nel lungo periodo, ma √® meno informativo per il singolo studio.\nEsercizio 3 ‚Äì Utilizzo di software per il calcolo (ad esempio, R o altro)\n\n\nInserisci i dati in un software (come R). Puoi farlo in R con:\nswls_data &lt;- c(28, 22, 26, 18, 30, 24, 27, 17, 21, 25)\n\n\nCalcola la media e la deviazione standard in R, poi utilizza la funzione t.test():\nt.test(swls_data, conf.level = 0.95)\n\nRiporta l‚Äôintervallo di confidenza ottenuto e confrontalo con quello calcolato a mano.\nCommenta eventuali differenze (minime) dovute agli arrotondamenti o a correzioni interne di R.\nRibadisci la corretta interpretazione frequentista: se si ripetesse lo stesso studio molte volte (stessa dimensione campionaria, stesso contesto di popolazione, stessa procedura di calcolo), il 95% di questi IC conterrebbe il valore vero di \\(\\mu\\).\n\nEsercizio 4 ‚Äì Confronto pratico e riflessioni critiche\n\nImmagina di avere un‚Äôipotesi: ‚ÄúLa media SWLS nella popolazione dei giovani adulti universitari √® pari a 24‚Äù (un‚Äôipotesi plausibile se la scala totale va da 5 a 35).\n\nOsserva l‚ÄôIC al 95% che hai calcolato: contiene il valore 24?\n\nSe l‚ÄôIC contiene 24, puoi dire che il valore ‚Äú24‚Äù √® ‚Äúmolto probabile‚Äù? (No, attenzione! Vedi interpretazione corretta vs.¬†errata.)\n\nSe l‚ÄôIC non contiene 24, puoi concludere che la media reale √® ‚Äúsicuramente‚Äù diversa da 24? (No, perch√© hai solo un campione piccolo e il concetto di significativit√† vs.¬†copertura pu√≤ essere fuorviante.)\n\nSpunti di riflessione sui limiti:\n- Il ‚Äúlivello di fiducia‚Äù dell‚ÄôIC non √® una ‚Äúprobabilit√†‚Äù che \\(\\mu\\) sia all‚Äôinterno di un singolo intervallo: √® una propriet√† della procedura sul lungo periodo.\n- Con pochi dati, le assunzioni (come la normalit√†) e la variabilit√† casuale giocano un ruolo enorme: l‚Äôintervallo pu√≤ risultare poco stabile e molto sensibile a pochi valori estremi.\n- L‚ÄôIC non dice ‚Äúquanto √® plausibile 24‚Äù (questo sarebbe pi√π vicino a un approccio bayesiano, che definisce un intervallo di credibilit√†). L‚ÄôIC frequentista dice soltanto che, ripetendo molte volte la stessa procedura, nel 95% dei casi il vero \\(\\mu\\) cadr√† entro l‚Äôintervallo calcolato in ciascuna ripetizione.\n\n\n\n\n\n\n\n\n\nSoluzioni 3\n\n\n\n\n\nSupponiamo siano stati raccolti i dati seguenti (sostituisci con i dati effettivi):\n28, 22, 26, 18, 30, 24, 27, 17, 21, 25\nEsercizio 1\n\nCalcolo di media e deviazione standard campionaria\n\nIndichiamo i punteggi come \\(X_1, X_2, \\dots, X_{10}\\). La media campionaria √®:\n\\[\n\\bar{X} = \\frac{1}{n}\\sum_{i=1}^n X_i.\n\\]\nFacendo la somma \\(28 + 22 + 26 + 18 + 30 + 24 + 27 + 17 + 21 + 25 = 238\\).\nQuindi, con \\(n=10\\), otteniamo:\n\\[\n\\bar{X} = \\frac{238}{10} = 23.8.\n\\]\nPer la deviazione standard campionaria \\(s\\), si utilizza:\n\\[\ns = \\sqrt{\\frac{1}{n-1} \\sum_{i=1}^n \\bigl(X_i - \\bar{X}\\bigr)^2}.\n\\]\nCalcolando (o usando un foglio di calcolo / software), si ricava approssimativamente:\n\\[\ns \\approx 4.26.\n\\]\n\nCostruzione dell‚ÄôIntervallo di Confidenza al 95%\n\nPoich√© la varianza √® sconosciuta e il campione √® piccolo, usiamo la distribuzione \\(t\\) di Student con \\(n-1 = 9\\) gradi di libert√†.\n- Livello di confidenza: \\(95\\%\\).\n- \\(\\alpha = 0,05\\), quindi \\(\\alpha/2 = 0,025\\).\n- Il valore critico \\(t_{\\alpha/2,df=9}\\) √® circa 2,262 (da tavole o software).\n\nErrore standard\n\n\\[\n\\text{SE} = \\frac{s}{\\sqrt{n}} = \\frac{4.26}{\\sqrt{10}} \\approx 4.26 / 3.162 \\approx 1.35.\n\\]\n\nMargine di errore\n\n\\[\nE = t_{\\alpha/2} \\times \\text{SE} \\approx 2.262 \\times 1.35 \\approx 3.05.\n\\]\n\nIntervallo di confidenza\n\n\\[\n\\bar{X} \\pm E \\quad \\Rightarrow \\quad 23.8 \\pm 3.05\n\\quad \\Rightarrow \\quad (20.75;\\, 26.85).\n\\]\n\nInterpretazione frequentista corretta\n\n\n\nInterpretazione corretta: se ripetessimo lo stesso tipo di studio molte volte (stessa procedura di campionamento, stesse dimensioni, stesso metodo di calcolo dell‚ÄôIC), il 95% di questi intervalli conterr√† il vero valore della media della popolazione (\\(\\mu\\)).\n\n\nInterpretazione scorretta (da evitare): ‚ÄúC‚Äô√® il 95% di probabilit√† che la vera media sia qui dentro‚Äù. Nel frequentismo, \\(\\mu\\) √® considerato un valore fisso e non aleatorio. L‚Äôincertezza riguarda l‚Äôintervallo, non il parametro.\n\nLimite: con poche osservazioni (n=10), l‚Äôintervallo pu√≤ risultare piuttosto ampio. Inoltre, l‚Äôassunzione di normalit√† della popolazione di partenza potrebbe non essere pienamente soddisfatta.\nEsercizio 2\n\nCalcolo di due nuovi IC: 80% e 99%\n\nUtilizziamo gli stessi \\(\\bar{X} = 23.8\\), \\(s = 4.26\\), \\(n=10\\). Cambia solo il valore critico \\(t\\).\n\n\nIC all‚Äô80% (\\(\\alpha=0,20\\), \\(\\alpha/2 = 0,10\\)):\n\n\n\\(t_{0,10,df=9} \\approx 1.383\\)\n\n\n\\(\\text{SE} \\approx 1.35\\) (come prima)\n\nMargine di errore \\(E = 1.383 \\times 1.35 \\approx 1.87\\)\n\nIC 80%: \\((23.8 \\pm 1.87)\\) \\(\\Rightarrow\\) \\((21.93;\\, 25.67)\\).\n\n\n\nIC al 99% (\\(\\alpha=0,01\\), \\(\\alpha/2 = 0,005\\)):\n\n\n\\(t_{0,005,df=9} \\approx 3.25\\)\n\n\n\\(\\text{SE} \\approx 1.35\\)\n\nMargine di errore \\(E = 3.25 \\times 1.35 \\approx 4.39\\)\n\nIC 99%: \\((23.8 \\pm 4.39)\\) \\(\\Rightarrow\\) \\((19.41;\\, 28.19)\\).\n\n\n\n\nConfronto delle ampiezze\n\n\n\n80%: \\((21.93;\\, 25.67)\\) (pi√π stretto)\n\n\n95%: \\((20.75;\\, 26.85)\\) (intermedio)\n\n\n99%: \\((19.41;\\, 28.19)\\) (pi√π largo)\n\nAumentando il livello di confidenza, l‚Äôintervallo si espande. Per ‚Äúcoprire‚Äù il valore vero nel 99% delle volte, occorre un intervallo pi√π ampio.\nEsercizio 3\n\nCalcolo in R\n\nSe in R inseriamo i dati:\nswls_data &lt;- c(28, 22, 26, 18, 30, 24, 27, 17, 21, 25)\n\nmean(swls_data)  # ~ 23.8\nsd(swls_data)    # ~ 4.26\nt.test(swls_data, conf.level = 0.95)\n\nConfronto con il calcolo ‚Äúa mano‚Äù\n\nLa funzione t.test() (di default) eseguir√† un One Sample t-test con confidenza 95%. Restituisce:\n\nUn IC molto simile a \\((20.75;\\, 26.85)\\), con possibili piccole differenze di arrotondamento.\n\n\nRibadire l‚Äôinterpretazione\n\n\nIl risultato di t.test() potrebbe riportare:95 percent confidence interval: (20.72, 26.88)\n(o valori simili).\n\nAnche qui vale la regola: non √® una probabilit√† che \\(\\mu\\) sia dentro, bens√¨ una propriet√† della procedura (lungo periodo).\n\nEsercizio 4\n\n\nIpotesi: ‚ÄúLa media SWLS reale nella popolazione √® 24‚Äù.\n\n\nVerifica se 24 √® dentro l‚ÄôIC al 95%. Dall‚ÄôIC \\((20.75;\\, 26.85)\\), notiamo che 24 rientra in questo intervallo.\n\nSignifica che √® ‚Äúprobabile‚Äù 24?\n\nAttenzione: l‚ÄôIC frequentista non fornisce una probabilit√† su questo specifico valore. Dire che ‚Äú24 √® dentro l‚Äôintervallo‚Äù non equivale a dire ‚Äúla probabilit√† che \\(\\mu\\) = 24 √® 95%‚Äù.\n\n\n\nSe 24 fosse stato fuori dall‚Äôintervallo, non potremmo comunque affermare con certezza che \\(\\mu\\neq 24\\). Ricordiamo sempre che, con un campione cos√¨ piccolo, l‚Äôincertezza √® alta e l‚ÄôIC si basa su assunzioni (normalit√† e stima corretta).\n\nLimiti dell‚Äôinterpretazione\n\nCon campioni ridotti, basta poco (un outlier o una leggera deviazione dalla normalit√†) per alterare significativamente l‚Äôintervallo.\n\nIl livello di confidenza (ad es. 95%) √® una propriet√† della procedura: in una serie di infiniti studi simili, il 95% di quegli intervalli conterrebbe \\(\\mu\\). Non significa che, dato questo singolo intervallo, ci sia una ‚Äúprobabilit√† 95%‚Äù di includere il parametro.\n\nRiepilogo Finale\n\n\nValori Numerici:\n\nMedia \\(\\bar{X} = 23.8\\); dev. standard \\(s \\approx 4.26\\).\n\nIC 95% (a mano) \\(\\approx (20.75;\\, 26.85)\\).\n\nIC 80% \\(\\approx (21.93;\\, 25.67)\\); IC 99% \\(\\approx (19.41;\\, 28.19)\\).\n\n\n\n\nInterpretazione Frequentista:\n&gt; Nel lungo periodo, il 95% (o 99%, 80%, ecc.) degli intervalli calcolati con la stessa procedura conterr√† il vero valore di \\(\\mu\\).\n\n\nLimiti (campioni piccoli, ipotesi di normalit√†, differenza tra ‚Äúcopertura ripetuta‚Äù e ‚Äúprobabilit√† che \\(\\mu\\) sia in un singolo IC‚Äù).\n\nIn questo modo, gli studenti vedono sia la parte di calcolo (formule, tabelle/valori critici, software) sia gli aspetti interpretativi (come evitare i fraintendimenti pi√π comuni sul significato dell‚ÄôIC frequentista).\nConclusioni generali\n\nCon un campione cos√¨ piccolo (n=10), l‚Äôintervallo di confidenza pu√≤ essere largo e sensibile a qualsiasi deviazione dall‚Äôassunzione di normalit√†.\n\nL‚Äôinterpretazione frequentista si focalizza sulla ‚Äúprocedura‚Äù e sul ‚Äúlungo periodo‚Äù (ripetizione dell‚Äôesperimento), non sulla probabilit√† che \\(\\mu\\) sia dentro questo intervallo specifico.\n\n√à facile incorrere in fraintendimenti (‚Äúc‚Äô√® il 95% di probabilit√† che la vera media sia qui dentro?‚Äù), occorre ribadire che la probabilit√† secondo il frequentismo riguarda il campionamento e la costruzione dell‚Äôintervallo, non la posizione fissa del parametro.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>75</span>¬† <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/02_conf_interv.html#informazioni-sullambiente-di-sviluppo",
    "title": "75¬† Intervalli di fiducia",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] bayestestR_0.15.2 posterior_1.6.1   cmdstanr_0.8.1    thematic_0.1.6   \n#&gt;  [5] MetBrewer_0.2.0   ggokabeito_0.1.0  see_0.11.0        gridExtra_2.3    \n#&gt;  [9] patchwork_1.3.0   bayesplot_1.11.1  psych_2.5.3       scales_1.3.0     \n#&gt; [13] markdown_2.0      knitr_1.50        lubridate_1.9.4   forcats_1.0.0    \n#&gt; [17] stringr_1.5.1     dplyr_1.1.4       purrr_1.0.4       readr_2.1.5      \n#&gt; [21] tidyr_1.3.1       tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0  \n#&gt; [25] rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6         tensorA_0.36.2.1     xfun_0.51           \n#&gt;  [4] htmlwidgets_1.6.4    insight_1.1.0        processx_3.8.6      \n#&gt;  [7] lattice_0.22-6       tzdb_0.5.0           vctrs_0.6.5         \n#&gt; [10] tools_4.4.2          ps_1.9.0             generics_0.1.3      \n#&gt; [13] parallel_4.4.2       pacman_0.5.1         pkgconfig_2.0.3     \n#&gt; [16] checkmate_2.3.2      distributional_0.5.0 lifecycle_1.0.4     \n#&gt; [19] compiler_4.4.2       farver_2.1.2         munsell_0.5.1       \n#&gt; [22] mnormt_2.1.1         htmltools_0.5.8.1    pillar_1.10.1       \n#&gt; [25] abind_1.4-8          nlme_3.1-167         tidyselect_1.2.1    \n#&gt; [28] digest_0.6.37        stringi_1.8.4        labeling_0.4.3      \n#&gt; [31] rprojroot_2.0.4      fastmap_1.2.0        grid_4.4.2          \n#&gt; [34] colorspace_2.1-1     cli_3.6.4            magrittr_2.0.3      \n#&gt; [37] withr_3.0.2          backports_1.5.0      timechange_0.3.0    \n#&gt; [40] rmarkdown_2.29       hms_1.1.3            evaluate_1.0.3      \n#&gt; [43] rlang_1.1.5          glue_1.8.0           rstudioapi_0.17.1   \n#&gt; [46] jsonlite_1.9.1       R6_2.6.1",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>75</span>¬† <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#bibliografia",
    "href": "chapters/frequentist_inference/02_conf_interv.html#bibliografia",
    "title": "75¬† Intervalli di fiducia",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nHoekstra, R., Morey, R. D., Rouder, J. N., & Wagenmakers, E.-J. (2014). Robust misinterpretation of confidence intervals. Psychonomic Bulletin & Review, 21(5), 1157‚Äì1164.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>75</span>¬† <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html",
    "href": "chapters/frequentist_inference/03_sample_size.html",
    "title": "76¬† La grandezza del campione",
    "section": "",
    "text": "76.1 Introduzione\nLa scelta della dimensione del campione √® fondamentale per garantire che i risultati di uno studio siano affidabili, bilanciando precisione e costi. In questo capitolo, esamineremo come calcolare la dimensione minima del campione necessaria per stimare la media di una popolazione con un margine di errore prefissato e un determinato livello di confidenza. Utilizzeremo un esempio tratto dalla psicologia per illustrare il processo e fornire implementazioni pratiche in R.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>76</span>¬† <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html#la-logica-dietro-la-scelta-della-dimensione-campionaria",
    "href": "chapters/frequentist_inference/03_sample_size.html#la-logica-dietro-la-scelta-della-dimensione-campionaria",
    "title": "76¬† La grandezza del campione",
    "section": "\n76.2 La Logica Dietro la Scelta della Dimensione Campionaria",
    "text": "76.2 La Logica Dietro la Scelta della Dimensione Campionaria\nIn psicologia, √® comune stimare la media di una variabile (ad esempio, il punteggio medio di una scala psicometrica). I vantaggi di utilizzare campioni pi√π grandi includono:\n\n\nStime pi√π precise: Con un campione pi√π grande, la varianza dell‚Äôestimatore diminuisce, rendendo le stime pi√π accurate.\n\nMaggiore fiducia nei risultati: Un campione pi√π grande riduce il margine di errore, aumentando la certezza dei risultati.\n\nTuttavia, i campioni pi√π grandi richiedono risorse maggiori in termini di tempo e denaro. Pertanto, il problema si riduce spesso a trovare il campione pi√π piccolo che garantisca la precisione desiderata.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>76</span>¬† <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html#calcolo-della-dimensione-campionaria",
    "href": "chapters/frequentist_inference/03_sample_size.html#calcolo-della-dimensione-campionaria",
    "title": "76¬† La grandezza del campione",
    "section": "\n76.3 Calcolo della Dimensione Campionaria",
    "text": "76.3 Calcolo della Dimensione Campionaria\nPer campioni sufficientemente grandi, la media campionaria \\(\\bar{X}\\) segue una distribuzione normale:\n\\[\n\\bar{X} \\sim \\mathcal{N}\\left(\\mu, \\frac{\\sigma^2}{n}\\right),\n\\]\ndove:\n\n\n\\(n\\) √® la dimensione del campione,\n\n\\(\\mu\\) √® la vera media della popolazione,\n\n\\(\\sigma^2\\) √® la varianza della popolazione.\n\nIl nostro obiettivo √® trovare la dimensione campionaria \\(n\\) tale che:\n\\[\nP\\left(|\\bar{X} - \\mu| &lt; E\\right) \\geq 0.95,\n\\]\ndove:\n\n\n\\(\\bar{X}\\) √® la media campionaria,\n\n\\(\\mu\\) √® la media della popolazione,\n\n\\(E\\) √® il margine di errore massimo accettabile.\n\nSappiamo che, per il teorema centrale del limite, la media campionaria \\(\\bar{X}\\) pu√≤ essere standardizzata come segue:\n\\[\nZ = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}}.\n\\]\nQuesta quantit√† \\(Z\\) segue una distribuzione normale standard \\(\\mathcal{N}(0, 1)\\).\nQuindi, possiamo riscrivere la probabilit√† richiesta come:\n\\[\nP\\left(|\\bar{X} - \\mu| &lt; E\\right) = P\\left(|Z| &lt; z_{0.025}\\right),\n\\]\ndove \\(z_{0.025} = 1.96\\) √® il quantile superiore della distribuzione normale standard corrispondente a un livello di confidenza del \\(95\\%\\).\nDalla definizione della variabile standardizzata \\(Z\\), possiamo ricavare la relazione per il margine di errore:\n\\[\n|\\bar{X} - \\mu| &lt; E \\implies Z = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}} \\implies \\left|\\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}}\\right| &lt; \\frac{E}{\\sigma / \\sqrt{n}}.\n\\]\nSostituendo la condizione \\(|Z| &lt; z_{0.025}\\), otteniamo:\n\\[\n\\frac{E}{\\sigma / \\sqrt{n}} = z_{0.025}.\n\\]\nRisolvendo per \\(\\sqrt{n}\\), moltiplichiamo entrambi i membri per \\(\\sigma / \\sqrt{n}\\):\n\\[\nE = z_{0.025} \\cdot \\frac{\\sigma}{\\sqrt{n}}.\n\\]\nIsoliamo \\(\\sqrt{n}\\) dividendo entrambi i membri per \\(z_{0.025} \\cdot \\sigma\\):\n\\[\n\\sqrt{n} = \\frac{z_{0.025} \\cdot \\sigma}{E}.\n\\]\nInfine, eleviamo entrambi i membri al quadrato per ottenere \\(n\\):\n\\[\nn = \\left(\\frac{z_{0.025} \\cdot \\sigma}{E}\\right)^2.\n\\]\nIn conclusione, la dimensione campionaria minima \\(n\\) necessaria per soddisfare il margine di errore \\(E\\) e il livello di confidenza richiesto √®:\n\\[\nn = \\left(\\frac{z_{0.025} \\cdot \\sigma}{E}\\right)^2.\n\\]",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>76</span>¬† <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html#stima-della-media-del-punteggio-di-autostima",
    "href": "chapters/frequentist_inference/03_sample_size.html#stima-della-media-del-punteggio-di-autostima",
    "title": "76¬† La grandezza del campione",
    "section": "\n76.4 Stima della Media del Punteggio di Autostima",
    "text": "76.4 Stima della Media del Punteggio di Autostima\nConsideriamo un esempio pratico: vogliamo stimare la media del punteggio di autostima in una popolazione di giovani adulti, utilizzando la Rosenberg Self-Esteem Scale (RSES), che assegna un punteggio compreso tra 0 e 30.\nDettagli del Problema:\n\nDeviazione standard del punteggio: \\(\\sigma = 6\\) (stimata da studi precedenti).\nMargine di errore massimo accettabile: \\(E = 2\\).\nLivello di confidenza: \\(95\\%\\).\n\nImplementiamo in R la formula derivata in precedenza.\n\n# Parametri del problema\nsigma &lt;- 6     # Deviazione standard del punteggio RSES\nE &lt;- 2         # Margine di errore desiderato\nz_alpha &lt;- qnorm(0.975)  # Quantile superiore della distribuzione normale (95% confidenza)\n\n# Calcolo della dimensione campionaria\nn &lt;- (z_alpha * sigma / E)^2\nn &lt;- ceiling(n)  # Arrotondamento all'intero successivo\nn\n#&gt; [1] 35\n\nIn conclusione, la dimensione campionaria minima necessaria per stimare la media del punteggio di autostima con un margine di errore massimo di 2 punti e un livello di confidenza del 95% √® \\(n = 35\\).\n\n76.4.1 Approfondimenti\n\n\nPrecisione e Livello di Confidenza Aumentando \\(n\\), la varianza di \\(\\bar{X}\\) diminuisce:\n\\[\n\\text{Var}(\\bar{X}) = \\frac{\\sigma^2}{n}.\n\\]\nQuesto restringe l‚Äôintervallo di confidenza e migliora la precisione.\n\nCosto e Praticit√† Un campione pi√π grande comporta costi pi√π elevati. √à importante trovare il giusto compromesso tra precisione e fattibilit√†.\nAdattamento ad Altri Livelli di Confidenza Per altri livelli di confidenza, basta modificare il quantile \\(z_{\\alpha/2}\\). Ad esempio, per un livello di confidenza del 99%, \\(z_{0.005} \\approx\\) 2.576.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>76</span>¬† <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html#riflessioni-conclusive",
    "href": "chapters/frequentist_inference/03_sample_size.html#riflessioni-conclusive",
    "title": "76¬† La grandezza del campione",
    "section": "\n76.5 Riflessioni Conclusive",
    "text": "76.5 Riflessioni Conclusive\nDefinire la dimensione del campione rappresenta un passaggio cruciale nella progettazione di qualsiasi studio psicologico. Un approccio matematico rigoroso, fondato su analisi di potenza statistica e stime di effetti attesi, consente di ottimizzare il bilanciamento tra precisione dei risultati e limitazioni pratiche, come tempi, costi e disponibilit√† dei partecipanti. Questo equilibrio √® fondamentale per garantire che i dati raccolti siano sufficientemente robusti da supportare conclusioni valide, senza tuttavia sprecare risorse in campioni eccessivamente ampi. Una corretta determinazione del campione contribuisce inoltre a ridurre il rischio di errori di tipo I e II, rafforzando l‚Äôintegrit√† scientifica della ricerca.\nNel confronto tra paradigmi statistici, l‚Äôapproccio frequentista si distingue per la sua enfasi sul controllo degli errori e sulla replicabilit√† attraverso il calcolo del valore p e della potenza statistica. Questo metodo richiede una rigorosa pianificazione preliminare, con la determinazione a priori della dimensione del campione basata su stime dell‚Äôeffetto atteso e soglie prefissate di significativit√† e potenza. Tale rigidit√† metodologica, sebbene garantisca standardizzazione e controllo degli errori di Tipo I, pu√≤ presentare notevoli limitazioni. In particolare, non permette modifiche alla dimensione del campione durante lo studio senza compromettere la validit√† statistica e pu√≤ portare al problema dello ‚Äúoptional stopping‚Äù, dove il controllo ripetuto dei risultati aumenta il rischio di falsi positivi.\nL‚Äôapproccio bayesiano, d‚Äôaltra parte, offre una prospettiva complementare, ponendo l‚Äôaccento sulla stima e sull‚Äôaggiornamento delle credenze in base ai dati osservati. Nel contesto bayesiano, la dimensione del campione non √® solo uno strumento per garantire la significativit√† statistica, ma diventa un mezzo per affinare la precisione delle stime a posteriori. Questo approccio si caratterizza per una maggiore flessibilit√†, permettendo il monitoraggio continuo dell‚Äôevidenza attraverso i fattori di Bayes e l‚Äôaggiornamento sequenziale delle stime di probabilit√†. L‚Äôuso di distribuzioni a priori consente di incorporare conoscenze pregresse, portando a distribuzioni a posteriori che quantificano l‚Äôincertezza in modo pi√π intuitivo e direttamente interpretabile.\nLa scelta di quando interrompere la raccolta dati rappresenta un esempio emblematico delle differenze tra i due approcci. Mentre il metodo frequentista richiede una dimensione campionaria fissa determinata a priori, l‚Äôapproccio bayesiano permette una maggiore flessibilit√†, consentendo di interrompere la raccolta quando si raggiunge un livello desiderato di precisione nelle stime posteriori. Tuttavia, questa flessibilit√† comporta anche sfide specifiche, come la necessit√† di specificare distribuzioni a priori appropriate e una maggiore complessit√† computazionale.\nUna soluzione pragmatica potrebbe essere l‚Äôintegrazione dei punti di forza di entrambi gli approcci. Si potrebbe utilizzare l‚Äôanalisi della potenza frequentista per stabilire una dimensione minima del campione, implementando poi un monitoraggio bayesiano per valutare quando l‚Äôevidenza raccolta √® sufficiente. Questo approccio integrato dovrebbe essere guidato da regole decisionali stabilite a priori e supportato da analisi di sensitivit√† per valutare la robustezza delle conclusioni.\nIn sintesi, la scelta della dimensione del campione e la decisione su quando concludere la raccolta dati non dovrebbero essere viste solo come problemi tecnici, ma come opportunit√† per riflettere sulle priorit√† della ricerca, sul contesto teorico e sulle metodologie pi√π adatte. La combinazione dei punti di forza degli approcci frequentista e bayesiano pu√≤ portare a una ricerca pi√π robusta, flessibile e informativa, contribuendo a un progresso scientifico pi√π solido e sfaccettato. Tale scelta metodologica deve considerare gli obiettivi specifici dello studio, le risorse disponibili, i requisiti delle riviste scientifiche e la natura delle ipotesi da testare, bilanciando le esigenze di precisione con quelle di praticabilit√†. Pertanto, investire tempo nella pianificazione di questo aspetto non √® solo una scelta metodologica, ma un imperativo etico per chiunque si impegni nella produzione di conoscenza psicologica.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>76</span>¬† <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html#esercizi",
    "href": "chapters/frequentist_inference/03_sample_size.html#esercizi",
    "title": "76¬† La grandezza del campione",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nEsercizio 1: Dimensione del campione per un margine di errore prefissato\n\nEsaminando i dati raccolti, hai ottenuto una deviazione standard campionaria (stimata) \\(s \\approx 4{,}3\\) sui punteggi SWLS.\nHai stabilito di voler stimare la media SWLS con un margine di errore massimo \\(E = 2\\) punti e un livello di confidenza del 95%.\n\nUtilizzando il valore critico \\(z_{0.025} \\approx 1{,}96\\) (per il 95%), ipotizza che la deviazione standard di popolazione \\(\\sigma\\) possa essere approssimata da \\(s\\). Calcola quindi la dimensione del campione \\(n\\) necessaria:\n\\[\nn = \\left(\\frac{z_{\\alpha/2} \\times \\sigma}{E}\\right)^2.\n\\]\n\nInterpreta il risultato: √® un campione grande o piccolo? Quali fattori potrebbero influenzarne la validit√† (ad es. la stima di \\(\\sigma\\) da soli 10 soggetti)?\n\nEsercizio 2: Aumento del livello di confidenza e influenza su \\(n\\)\n\nCon gli stessi dati dell‚ÄôEsercizio 1 (stesso \\(\\sigma\\approx4{,}3\\), stesso \\(E=2\\)), calcola la dimensione \\(n\\) se volessi un livello di confidenza del 99%.\n\nConfronta tale dimensione con quella trovata al 95%.\n\nCommenta: perch√© un livello di confidenza pi√π elevato richiede un campione pi√π grande? E in che modo ci√≤ pu√≤ impattare sull‚Äôorganizzazione pratica della ricerca (tempi, costi, disponibilit√† di partecipanti)?\n\nEsercizio 3: Potere statistico per rilevare una differenza dalla media di riferimento\n\nIpotizza che la media SWLS di riferimento (ad es. in letteratura) sia 24.\n\nVuoi un test a una coda (one-sample t-test o z-test) con \\(\\alpha = 0{,}05\\), e desideri un potere (\\(1-\\beta\\)) dell‚Äô80% di rivelare una differenza di 3 punti (cio√® vuoi essere in grado di concludere che la vera media √® almeno 3 punti pi√π alta o pi√π bassa di 24).\n\nUsa come stima della deviazione standard la stessa \\(s \\approx 4{,}3\\). Sulla base delle formule di potenza statistica per un test a una coda, calcola un numero approssimativo di soggetti \\(n\\) necessari. (Suggerimento: puoi usare formule di power analysis o fare riferimento a software R, es. power.t.test() o pwr.t.test().)\n\n\nInterpreta la dimensione campionaria trovata: √® realistica per un esperimento in cui potresti raccogliere partecipanti simili a quelli del pilot? Oppure rappresenta un valore troppo elevato?\n\nEsercizio 4: Confronto tra due gruppi e potere statistico\n\nIpotizza di voler confrontare due gruppi indipendenti (ognuno con punteggi SWLS) e di voler rilevare una differenza media di 5 punti tra i due gruppi (Gruppo A vs Gruppo B).\n\nAssumi che ciascun gruppo abbia la stessa deviazione standard \\(\\sigma = 4{,}3\\).\n\nVuoi un test a due code, \\(\\alpha=0{,}05\\), e un potere dell‚Äô80%. Utilizza (se vuoi) la formula approssimata per due campioni indipendenti, oppure uno strumento in R (ad es. power.t.test con type=\"two.sample\").\n\nCalcola (o stima) la dimensione \\(n\\) per ciascun gruppo.\n\n\nCommenta: confronta il risultato con la disponibilit√† realistica dei partecipanti. Che implicazioni metodologiche o pratiche emergono?\n\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\nSoluzione Esercizio 1\nDati principali:\n- \\(\\sigma \\approx 4{,}3\\) (stimata dal pilot)\n- \\(E = 2\\) (margine di errore)\n- Livello di confidenza 95% \\(\\Rightarrow z_{\\alpha/2} \\approx 1{,}96\\)\nLa formula per la dimensione campionaria:\n\\[\nn = \\left(\\frac{z_{\\alpha/2} \\times \\sigma}{E}\\right)^2\n\\]\nCalcolo:\n\\[\nn\n= \\left(\\frac{1{,}96 \\times 4{,}3}{2}\\right)^2\n= \\left(\\frac{8{,}428}{2}\\right)^2\n= (4{,}214)^2\n\\approx 17{,}76.\n\\]\nArrotondando all‚Äôintero superiore:\n\\[\nn \\approx 18.\n\\]\nInterpretazione\n\nServirebbero circa 18 partecipanti (anzich√© 10) per ottenere un IC al 95% con margine d‚Äôerrore 2, ipotizzando \\(\\sigma \\approx 4{,}3\\).\n\n\nLimiti: la \\(\\sigma\\) deriva da un campione di sole 10 persone e potrebbe non rappresentare bene la deviazione standard reale dell‚Äôintera popolazione. Se in realt√† \\(\\sigma\\) fosse pi√π grande, \\(n\\) andrebbe rivisto al rialzo; se fosse minore, 18 potrebbe essere anche sovrastimato.\n\n18 non √® troppo elevato; potrebbe essere gestibile in uno studio con costi contenuti. Tuttavia, la validit√† dipende dalla solidit√† della stima di \\(\\sigma\\).\n\nSoluzione Esercizio 2\nCambio di livello di confidenza: da 95% a 99%. Ora \\(\\alpha=0{,}01\\) e \\(\\alpha/2=0{,}005\\).\nIl valore critico \\(z_{0.005}\\) √® circa 2,576.\n\\[\nn = \\left(\\frac{2,576 \\times 4{,}3}{2}\\right)^2\n= \\left(\\frac{11{,}0768}{2}\\right)^2\n= (5{,}5384)^2\n\\approx 30{,}7.\n\\]\nArrotondato in eccesso:\n\\[\nn \\approx 31.\n\\]\nConfronto con i 18 trovati prima\n- Aumentando la confidenza dal 95% al 99%, la dimensione campionaria passa da ~18 a ~31, cio√® un incremento notevole.\n- Motivo: per assicurare un intervallo che, nel lungo periodo, includa il vero valore nel 99% dei casi, occorre un margine di errore pi√π ‚Äútollerante‚Äù (oppure un campione pi√π grande per mantenere lo stesso \\(E\\)).\n- Impatto pratico: reclutare 31 soggetti (invece di 18) pu√≤ pesare in termini di costi e disponibilit√†, ma riduce l‚Äôincertezza dell‚ÄôIC dal punto di vista frequentista.\nSoluzione Esercizio 3\nPotere statistico (80%) per rilevare \\(\\Delta = 3\\) in un test a una coda contro il valore di riferimento 24.\n- \\(\\alpha=0{,}05\\) (quindi una coda, il valore critico si situa intorno a z=1.645 per la potenza, ma i calcoli precisi si fanno di solito con formule di power analysis).\n- \\(\\sigma \\approx 4{,}3\\).\n- \\(\\Delta = 3\\).\nIn R, con pwr.t.test() o power.t.test(), l‚Äôapprossimazione verrebbe impostata come:\nlibrary(pwr)  # se usi pwr\npwr.t.test(d = 3/4.3, sig.level = 0.05, power = 0.80,\n           type = \"one.sample\", alternative=\"greater\")\noppure:\npower.t.test(delta = 3, sd = 4.3, sig.level = 0.05, \n             power = 0.80, type = \"one.sample\", \n             alternative = \"one.sided\")\nEsempio di risultato (numeri indicativi): potresti ottenere \\(n \\approx 20\\). (Il valore preciso cambia a seconda delle approssimazioni e del software.)\nInterpretazione\n- Con 20 soggetti, se \\(\\Delta\\) fosse veramente di 3 punti rispetto a 24, il test a una coda dovrebbe avere l‚Äô80% di chance di rigettare l‚Äôipotesi nulla (cio√® di rilevare la differenza) a \\(\\alpha=0{,}05\\).\n- Se cercassi di replicare il pilot (dove avevi 10 soggetti), probabilmente la potenza sarebbe inferiore.\n- Potresti chiederti se 20 partecipanti siano facili da reclutare o se, dal punto di vista pratico, 20 restino pochi per altre ragioni (ad es. robustezza dei modelli, normalit√†, outlier).\nSoluzione Esercizio 4\n\nDue campioni indipendenti, differenza attesa = 5 punti, potere = 80%, test a due code\n\nCon formula approssimata (oppure software R), i parametri tipici:\n\n\nDifferenza minima rilevabile: \\(\\Delta = 5\\)\n\n\n\\(\\sigma = 4{,}3\\) in ciascun gruppo\n\n\n\\(\\alpha = 0{,}05\\) (due code), potere = 80%\n\nTipo di test: ‚Äútwo-sample t test‚Äù (Gruppo A vs Gruppo B, varianze uguali)\n\nIn R con power.t.test():\npower.t.test(delta = 5, sd = 4.3, sig.level = 0.05,\n             power = 0.80, type = \"two.sample\",\n             alternative = \"two.sided\")\nEsempio di risultato: potresti ottenere \\(n \\approx 14\\) per gruppo (quindi 28 totali). (Il numero pu√≤ variare leggermente a seconda delle approssimazioni.)\n\nCommento\n\n\n\n18 o 20 partecipanti totali potrebbero bastare per un one-sample test (Esercizi 1‚Äì3), ma qui servono 28 (14 per gruppo) per avere lo stesso potere su una differenza di 5 punti.\n\nIn pratica:\n\nSe hai risorse per arruolare solo 15‚Äì20 persone totali, potrebbe non esserci potere sufficiente (grande rischio di errore di tipo II).\n\nPotrebbe convenire ridurre la differenza minima desiderata (ma questo cambierebbe le conclusioni) o cercare un campione pi√π grande.\n\n\n\nLe considerazioni metodologiche includono: ‚ÄúPosso davvero aspettarmi 5 punti di differenza?‚Äù Se la differenza reale fosse pi√π piccola, servirebbe un campione ancora pi√π grande per rilevarla con sufficiente potenza.\n\nConclusioni Finali\n\nLa dimensione del campione dipende da molti fattori:\n\nVarianza (o deviazione standard) stimata.\n\nMargine di errore desiderato (o differenza minima rilevabile).\n\nLivello di confidenza o \\(\\alpha\\).\n\nPotere statistico \\((1-\\beta)\\).\n\n\n\nI dati SWLS di un pilot di 10 persone forniscono un‚Äôindicazione iniziale (stima di \\(\\sigma\\)), ma la precisione di quella stima √® limitata.\n\nPer studi sperimentali o correlazionali, i calcoli di dimensione campionaria andrebbero fatti a priori (idealmente ancor prima di raccogliere i dati) e basati su stime realistiche o su letteratura pre-esistente.\n\nSe la stima di \\(\\sigma\\) o della dimensione dell‚Äôeffetto \\(\\Delta\\) √® incerta, √® utile svolgere analisi di sensitivit√†, variando gli input per vedere come cambiano i risultati.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>76</span>¬† <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/03_sample_size.html#informazioni-sullambiente-di-sviluppo",
    "title": "76¬† La grandezza del campione",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.5.3     \n#&gt;  [9] scales_1.3.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.9.1   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         rlang_1.1.5       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       yaml_2.3.10       tools_4.4.2       parallel_4.4.2   \n#&gt; [21] tzdb_0.5.0        colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5      \n#&gt; [25] R6_2.6.1          lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3  \n#&gt; [29] pillar_1.10.1     gtable_0.3.6      glue_1.8.0        xfun_0.51        \n#&gt; [33] tidyselect_1.2.1  rstudioapi_0.17.1 farver_2.1.2      htmltools_0.5.8.1\n#&gt; [37] nlme_3.1-167      rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>76</span>¬† <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html#bibliografia",
    "href": "chapters/frequentist_inference/03_sample_size.html#bibliografia",
    "title": "76¬† La grandezza del campione",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGiner-Sorolla, R., Montoya, A. K., Reifman, A., Carpenter, T., Lewis Jr, N. A., Aberson, C. L., Bostyn, D. H., Conrique, B. G., Ng, B. W., Schoemann, A. M., et al. (2024). Power to detect what? Considerations for planning and evaluating sample size. Personality and Social Psychology Review, 28(3), 276‚Äì301.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>76</span>¬† <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html",
    "title": "\n77¬† Significativit√† statistica\n",
    "section": "",
    "text": "77.1 Introduzione\nIl test di ipotesi √® un metodo fondamentale della ricerca scientifica, utilizzato per fare inferenze sui parametri della popolazione a partire dai dati campionari. Nel contesto della psicologia, questo approccio viene frequentemente impiegato per valutare l‚Äôefficacia di interventi psicologici, confrontare teorie o approcci, analizzare l‚Äôinfluenza di variabili psicologiche su comportamenti e processi cognitivi, e approfondire i meccanismi alla base di fenomeni complessi come apprendimento, memoria ed emozioni.\nIn questo capitolo ci focalizzeremo sul test di ipotesi frequentista, un metodo largamente utilizzato ma non privo di limiti. √à importante sottolineare che la comunit√† statistica sconsiglia di affidarsi esclusivamente a questo approccio come criterio decisionale per valutare la validit√† di un risultato sperimentale.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>77</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#test-del-chi-quadrato",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#test-del-chi-quadrato",
    "title": "\n77¬† Significativit√† statistica\n",
    "section": "\n77.2 Test del Chi-Quadrato",
    "text": "77.2 Test del Chi-Quadrato\nPer introdurre il concetto di test di ipotesi nel contesto frequentista, iniziamo presentando uno dei test pi√π semplici e utilizzati: il test del Chi-Quadrato. Questo test √® particolarmente utile per valutare l‚Äôipotesi di indipendenza tra due variabili categoriali organizzate in una tabella di contingenza (per ulteriori dettagli sulla struttura delle tabelle di contingenza, si veda il Capitolo 16).\nUna tabella di contingenza √® una rappresentazione tabellare che mostra la distribuzione congiunta di due variabili categoriali. Ogni cella della tabella contiene la frequenza osservata delle combinazioni delle categorie delle due variabili. Inoltre, la tabella include i totali marginali, che rappresentano le somme delle frequenze per ciascuna riga e ciascuna colonna.\nIl test del Chi-Quadrato si pone una domanda fondamentale: ‚ÄúCome apparirebbe la tabella di contingenza se le due variabili fossero indipendenti?‚Äù. In altre parole, il test verifica se esiste una relazione significativa tra le due variabili o se, al contrario, le variabili sono indipendenti l‚Äôuna dall‚Äôaltra.\nCome gi√† visto in precedenza analizzando la distribuzione di probabilit√† congiunta, si ha indipendenza quando le probabilit√† congiunte sono uguali al prodotto delle probabilit√† marginali. Partendo dalle proporzioni marginali, possiamo quindi calcolare i valori teorici attesi in ciascuna cella della tabella di contingenza, assumendo che le due variabili siano indipendenti.\nVa sottolineato che l‚Äôindipendenza √® una propriet√† della popolazione, non del campione. Pertanto, nei dati campionari, ci aspettiamo che i valori osservati nelle celle della tabella differiscano leggermente dai valori teorici attesi, anche se nella popolazione le variabili sono realmente indipendenti. La discrepanza complessiva tra i valori osservati e quelli attesi, calcolati sotto l‚Äôipotesi di indipendenza, pu√≤ essere misurata utilizzando una statistica chiamata Chi-Quadrato (\\(\\chi^2\\)).\nLa formula della statistica Chi-Quadrato √®:\n\\[\n\\chi^2 = \\sum \\frac{(O_i - E_i)^2}{E_i} ,\n\\]\ndove:\n\n\n\\(O_i\\) rappresenta i valori osservati nelle celle della tabella,\n\n\n\\(E_i\\) rappresenta i valori attesi nelle celle, calcolati sotto l‚Äôipotesi di indipendenza,\n\nLa somma (\\(\\sum\\)) viene effettuata su tutte le celle della tabella.\n\n\n77.2.1 Interpretazione della Statistica Chi-Quadrato\nLa statistica Chi-Quadrato misura la discrepanza complessiva tra i valori osservati e quelli attesi. Se non ci fosse differenza tra i valori congiunti osservati e quelli teorici, la statistica Chi-Quadrato sarebbe pari a zero. All‚Äôaumentare della discrepanza tra valori osservati e attesi, il valore della statistica Chi-Quadrato aumenta.\nPer valutare l‚Äôimportanza della discrepanza osservata, utilizziamo la distribuzione campionaria della statistica Chi-Quadrato. Questa distribuzione descrive la probabilit√† di ottenere valori della statistica Chi-Quadrato sotto l‚Äôipotesi nulla (indipendenza tra le variabili). La forma della distribuzione dipende dai gradi di libert√† (\\(\\nu\\)), che si calcolano come:\n\\[\n\\nu = (n_{\\text{righe}} - 1)(n_{\\text{colonne}} - 1) ,\n\\]\ndove \\(n_{\\text{righe}}\\) e \\(n_{\\text{colonne}}\\) rappresentano rispettivamente il numero di righe e colonne della tabella di contingenza.\n\n77.2.2 Valutazione dell‚ÄôIpotesi di Indipendenza\nLa probabilit√† associata a una data discrepanza (\\(\\chi^2\\)) tra valori osservati e attesi, assumendo che l‚Äôipotesi nulla sia vera, corrisponde all‚Äôarea sotto la coda destra della distribuzione Chi-Quadrato, nell‚Äôintervallo [\\(C\\), \\(+\\infty\\)]. Questa probabilit√† √® indicata come \\(p\\)-value.\nSe il \\(p\\)-value √® molto piccolo (tipicamente inferiore a una soglia predefinita, come 0.05), possiamo rifiutare l‚Äôipotesi nulla e concludere che √® improbabile che le due variabili siano indipendenti nella popolazione.\n\n77.2.3 Riepilogo dei Passaggi del Test Chi-Quadrato\n\n\nCalcolo dei Valori Attesi: Per ogni cella, calcola \\(E_i\\) utilizzando la formula:\n\\[\nE_i = \\frac{\\text{Totale della Riga} \\times \\text{Totale della Colonna}}{\\text{Totale Complessivo}}\n\\]\n\n\nCalcolo della Statistica Chi-Quadrato: Usa la formula:\n\\[\n\\chi^2 = \\sum \\frac{(O_i - E_i)^2}{E_i}\n\\]\n\nDeterminazione dei Gradi di Libert√†: Calcola \\(\\nu\\) come \\((n_{\\text{righe}} - 1)(n_{\\text{colonne}} - 1)\\).\nConfronto con la Distribuzione Chi-Quadrato: Determina il \\(p\\)-value associato al valore di \\(\\chi^2\\) calcolato e valuta l‚Äôipotesi nulla.\n\nIn conclusione, il Test Chi-Quadrato rappresenta uno strumento per verificare l‚Äôindipendenza tra due variabili categoriali. Grazie alla sua semplicit√† di applicazione e interpretazione, costituisce un metodo di analisi largamente utilizzato in ambito psicologico, sociale e statistico. Tuttavia, √® importante prestare attenzione ai presupposti del test, come la sufficienza dei dati in ogni cella, per garantire risultati affidabili e interpretabili.\n\n# Creare la tabella di contingenza\nobserved &lt;- matrix(c(44, 0, 119, \n                              55, 68, 0, \n                              47, 0, 0),\n                            nrow = 3, byrow = TRUE)\n\n# Aggiungere i nomi di righe e colonne\nrownames(observed) &lt;- c(\"Biscoe\", \"Dream\", \"Torgersen\")\ncolnames(observed) &lt;- c(\"Adelie\", \"Chinstrap\", \"Gentoo\")\n\n# Visualizzare la tabella\nprint(observed)\n#&gt;           Adelie Chinstrap Gentoo\n#&gt; Biscoe        44         0    119\n#&gt; Dream         55        68      0\n#&gt; Torgersen     47         0      0\n\n\nchi_square_result &lt;- chisq.test(observed)\nchi_square_result\n#&gt; \n#&gt;  Pearson's Chi-squared test\n#&gt; \n#&gt; data:  observed\n#&gt; X-squared = 285, df = 4, p-value &lt;2e-16\n\nSvolgiamo i calcoli ‚Äúa mano‚Äù usando R. Per calcolare la statistica del test del Chi-Quadrato ‚Äúa mano‚Äù in R, segui questi passaggi:\nCalcoliamo i totali per righe e colonne e il totale complessivo.\n\n# Totali marginali\nrow_totals &lt;- rowSums(observed)\ncol_totals &lt;- colSums(observed)\ngrand_total &lt;- sum(observed)\n\n# Visualizzare i totali\nprint(\"Totali marginali per righe:\")\n#&gt; [1] \"Totali marginali per righe:\"\nprint(row_totals)\n#&gt;    Biscoe     Dream Torgersen \n#&gt;       163       123        47\nprint(\"Totali marginali per colonne:\")\n#&gt; [1] \"Totali marginali per colonne:\"\nprint(col_totals)\n#&gt;    Adelie Chinstrap    Gentoo \n#&gt;       146        68       119\nprint(paste(\"Totale complessivo:\", grand_total))\n#&gt; [1] \"Totale complessivo: 333\"\n\nI valori attesi si calcolano come:\n\\[\nE_{ij} = \\frac{\\text{Totale riga} \\times \\text{Totale colonna}}{\\text{Totale complessivo}} .\n\\]\n\n# Calcolo dei valori attesi\nexpected &lt;- outer(row_totals, col_totals) / grand_total\n\n# Visualizzare i valori attesi\nprint(\"Valori attesi:\")\n#&gt; [1] \"Valori attesi:\"\nprint(expected)\n#&gt;           Adelie Chinstrap Gentoo\n#&gt; Biscoe     71.47    33.285  58.25\n#&gt; Dream      53.93    25.117  43.95\n#&gt; Torgersen  20.61     9.598  16.80\n\nLa statistica Chi-Quadrato si calcola con:\n\\[\n\\chi^2 = \\sum \\frac{(O_{ij} - E_{ij})^2}{E_{ij}} .\n\\]\n\n# Calcolo della statistica Chi-Quadrato\nchi_square_stat &lt;- sum((observed - expected)^2 / expected)\n\n# Visualizzare il risultato\nprint(paste(\"Statistica Chi-Quadrato:\", chi_square_stat))\n#&gt; [1] \"Statistica Chi-Quadrato: 284.590012688092\"\n\nI gradi di libert√† si calcolano come:\n\\[\ndof = (\\text{n. righe} - 1) \\times (\\text{n. colonne} - 1) .\n\\]\n\n# Calcolo dei gradi di libert√†\ndof &lt;- (nrow(observed) - 1) * (ncol(observed) - 1)\n\n# Visualizzare i gradi di libert√†\nprint(paste(\"Gradi di libert√†:\", dof))\n#&gt; [1] \"Gradi di libert√†: 4\"\n\nConfrontiamo la statistica Chi-Quadrato con la distribuzione teorica per ottenere il p-value.\n\n# Calcolo del p-value\np_value &lt;- pchisq(chi_square_stat, df = dof, lower.tail = FALSE)\n\n# Visualizzare il p-value\nprint(paste(\"p-value:\", p_value))\n#&gt; [1] \"p-value: 2.28189154098739e-60\"\n\nInterpretazione:\nIl valore-\\(p\\) risulta molto piccolo, indicando che, se le variabili Isola e Specie fossero realmente indipendenti, sarebbe estremamente improbabile osservare una distribuzione delle specie di pinguini sulle tre isole cos√¨ diversa da quella teoricamente attesa. In altre parole, il valore-\\(p\\) rappresenta la probabilit√† di ottenere, per puro caso, una discrepanza tra i valori osservati e quelli attesi pari o superiore a quella riscontrata nei dati.\nPoich√© il valore-\\(p\\) √® estremamente basso, possiamo concludere che l‚Äôipotesi di indipendenza tra le variabili Isola e Specie non √® plausibile. Questo indica che la distribuzione delle specie di pinguini varia in relazione all‚Äôisola, ovvero che conoscendo l‚Äôisola √® possibile prevedere la distribuzione delle specie. In altre parole, le variabili Isola e Specie sono associate.\n\n77.2.4 Significativit√† Statistica: Un Concetto da Riconsiderare\nCome discusso nell‚Äôesempio precedente, un risultato √® considerato ‚Äústatisticamente significativo‚Äù se la probabilit√† che sia dovuto al caso √® bassa, il che suggerisce che il risultato sia stabile o reale. Al contrario, risultati ‚Äúnon significativi‚Äù vengono spesso etichettati come privi di valore e ignorati. Questa semplificazione, per√≤, pu√≤ portare a gravi fraintendimenti. Ad esempio:\n\n\nDipendenza dal campione: La significativit√† statistica √® fortemente influenzata dalla dimensione del campione; risultati apparentemente ‚Äúsignificativi‚Äù possono emergere anche da effetti molto piccoli in campioni ampi.\n\nRisultati non significativi: Un risultato non significativo non implica che l‚Äôeffetto sia nullo o irrilevante.\n\nScelte soggettive: Livelli di confidenza e test statistici differenti possono influenzare l‚Äôesito dell‚Äôanalisi, portando a interpretazioni arbitrarie.\n\n77.2.5 Limiti e Applicazioni del Metodo Frequentista\nIl problema pi√π grave dell‚Äôapproccio frequentista √® che esso non sempre mantiene la ‚Äúpromessa‚Äù di fornire una base oggettiva per la decisione statistica. Infatti, il ricorso esclusivo alla significativit√† statistica conduce a risultati opposti a quelli desiderati, aumentando il rischio di pubblicare risultati non replicabili o di trascurare evidenze importanti si veda il¬†82.\nIn alternativa, √® pi√π utile considerare il risultato osservato nel contesto scientifico pi√π ampio, integrandolo con altre analisi. Questo approccio critico e completo consente di superare i limiti della significativit√† statistica e di interpretare i risultati con maggiore rigore.\n\n77.2.6 Un Caso Specifico: La Media del Campione\nTorniamo ora a esaminare il test di ipotesi all‚Äôinterno del quadro frequentista, focalizzandoci sul caso di una variabile continua, diversamente dal contesto qualitativo trattato nel test del Chi-Quadrato. Per approfondire la comprensione della significativit√† statistica, analizzeremo in dettaglio l‚Äôutilizzo della media campionaria come stimatore della media della popolazione. Questa riflessione ci consentir√† di esplorare sia i limiti che le applicazioni pratiche di tale strumento all‚Äôinterno della statistica inferenziale frequentista. Attraverso questo esempio, potremo mettere in luce aspetti teorici e operativi dei test di ipotesi, nonch√© fornire indicazioni su come migliorare l‚Äôinterpretazione dei risultati, con particolare riferimento al campo della ricerca psicologica.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>77</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#il-test-di-ipotesi",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#il-test-di-ipotesi",
    "title": "\n77¬† Significativit√† statistica\n",
    "section": "\n77.3 Il Test di Ipotesi",
    "text": "77.3 Il Test di Ipotesi\nIl test di ipotesi √® un metodo statistico utilizzato per valutare se i dati sono coerenti con l‚Äôipotesi nulla (\\(H_0\\)). L‚Äôipotesi nulla solitamente afferma che non vi √® alcun effetto o differenza significativa, mentre l‚Äôipotesi alternativa (\\(H_1\\)) rappresenta l‚Äôaffermazione che si desidera testare. I dati del campione vengono analizzati per determinare se forniscono prove sufficienti per rifiutare l‚Äôipotesi nulla. Un passaggio cruciale consiste nel calcolare il value-p.\n\n77.3.1 La procedura di Test di Ipotesi\nEsaminiamo in dettaglio le varie fasi della procedura del test di ipotesi di stampo frequentista.\nPasso 1: Formulare l‚Äôipotesi nulla (\\(H_0\\)) e l‚Äôipotesi alternativa (\\(H_1\\)) basandosi sulla domanda di ricerca.\nPasso 2: Stabilire un livello di significativit√†, Œ± (solitamente 0.05).\nPasso 3: Selezionare il Test Statistico appropriato, verificare eventuali assunzioni e calcolare il test statistico.\nPasso 4: Decidere se il risultato √® ‚Äústatisticamente significativo‚Äù secondo (a) la regione di rifiuto o (b) il valore-p.\n\nL‚Äôapproccio della regione di rifiuto. Basandosi sulla distribuzione campionaria nota del test statistico, la regione di rifiuto √® un insieme di valori per il test statistico per i quali l‚Äôipotesi nulla viene rifiutata. Se il valore osservato del test statistico rientra nella regione di rifiuto, allora si rifiuta l‚Äôipotesi nulla.\nL‚Äôapproccio del valore-p.¬†Il valore-p √® la probabilit√† di ottenere i risultati osservati, o risultati ancora pi√π estremi, se l‚Äôipotesi nulla √® vera.\n\nConfrontiamo il valore-p calcolato con il livello di significativit√† Œ±:\n\nSe il valore-p &lt; Œ±, si rifiuta l‚Äôipotesi nulla (\\(H_0\\)).\nSe il valore-p ‚â• Œ±, non si rifiuta l‚Äôipotesi nulla (\\(H_0\\)).",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>77</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#il-test-di-ipotesi-nel-contesto-frequentista",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#il-test-di-ipotesi-nel-contesto-frequentista",
    "title": "\n77¬† Significativit√† statistica\n",
    "section": "\n77.4 Il Test di Ipotesi nel Contesto Frequentista",
    "text": "77.4 Il Test di Ipotesi nel Contesto Frequentista\nSi noti che i metodi bayesiani e frequentisti non sono semplicemente due approcci diversi per rispondere alla stessa domanda, ma formulano domande fondamentalmente diverse. Pertanto, per comprendere il test di ipotesi frequentista, √® essenziale chiarire cosa si intende per valore-p.\nL‚ÄôAmerican Statistical Association (ASA) definisce il valore-p come:\n\nthe probability under a specified statistical model that a statistical summary of the data (e.g., the sample mean difference between two compared groups) would be equal to or more extreme than its observed value (Wasserstein e Lazar 2016).\n\nQuesta definizione pu√≤ risultare difficile da comprendere perch√© contiene concetti complessi come ‚Äúprobabilit√†‚Äù e ‚Äúmodello statistico specificato‚Äù. Per capire meglio cosa rappresenta un valore-p, √® necessario esaminare attentamente entrambi questi concetti. Questo ci porter√† anche a una comprensione pi√π profonda di altri concetti fondamentali per l‚Äôinferenza frequentista e ci aiuter√† a distinguere tra inferenza frequentista e inferenza bayesiana.\nUna distinzione fondamentale tra l‚Äôapproccio frequentista e quello bayesiano riguarda l‚Äôinterpretazione della probabilit√†: il primo si basa sulla frequenza relativa degli eventi nel lungo periodo, mentre il secondo si basa sulla ‚Äúcertezza soggettiva‚Äù o sul grado di fiducia che un individuo attribuisce a un evento specifico.\nChiarito che la probabilit√† assume significati diversi nei contesti frequentista e bayesiano, possiamo chiederci quale nozione di probabilit√† sia implicita nella definizione del valore-p fornita dall‚ÄôASA. La visione comune suggerisce che si riferisca alle frequenze relative. Ma frequenze relative di cosa e ripetizioni di cosa?\nPossiamo riformulare la definizione dell‚ÄôASA in questo modo:\n\nIl valore-p si riferisce alla frequenza relativa di ottenere un riassunto statistico dei dati grande quanto o pi√π grande del valore osservato in ripetizioni ipotetiche di un esperimento descritto da un modello statistico specificato.\n\nQuindi, l‚Äôapproccio frequentista pu√≤ essere descritto come un metodo per stimare il valore di un parametro attraverso esperimenti ipotetici, confrontando i nostri dati con i risultati di tali esperimenti per giudicare se i nostri dati sono sorprendenti o meno.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>77</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#applicazione-alla-media-campionaria",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#applicazione-alla-media-campionaria",
    "title": "\n77¬† Significativit√† statistica\n",
    "section": "\n77.5 Applicazione alla Media Campionaria",
    "text": "77.5 Applicazione alla Media Campionaria\nIn questo capitolo ci concentreremo sull‚Äôapplicazione del processo di test di ipotesi frequentista alla media campionaria. Vedremo come la media di un campione possa essere impiegata per trarre inferenze sulla media di una popolazione, analizzandone limiti e possibili utilizzi nell‚Äôambito dell‚Äôinferenza statistica frequentista.\nI test su uno o due campioni (one-sample e two-sample tests) hanno rappresentato le prime fondamenta dell‚Äôanalisi statistica dei dati. Al giorno d‚Äôoggi, tuttavia, i nostri disegni sperimentali tendono a essere pi√π complessi di quanto questi semplici test possano gestire. Nonostante ci√≤, tali test ‚Äì in particolare il celebre t-test di Student ‚Äì costituiscono ancora un‚Äôottima porta d‚Äôingresso alla modellazione statistica, poich√© i principi su cui si basano sono relativamente intuitivi e consentono di familiarizzare con il processo di verifica dell‚Äôipotesi.\nPer comprendere meglio i valori-p e la verifica del test di ipotesi, pu√≤ essere molto utile ricorrere a simulazioni. Attraverso queste ultime √® possibile ricreare condizioni sperimentali ipotetiche e osservare la variabilit√† dei risultati, fornendo cos√¨ una prospettiva pi√π chiara sulle implicazioni della statistica frequentista.\n\n77.5.1 La Distribuzione della Media Campionaria\nQuando consideriamo la media campionaria come stima della media di una popolazione, assumiamo che questa popolazione segua una distribuzione normale. Vogliamo quindi esplorare la distribuzione della media campionaria (\\(\\bar{X}\\)), che descrive la variazione di \\(\\bar{X}\\) attraverso infiniti campioni di dimensione \\(n\\). Abbiamo gi√† dimostrato che, se la popolazione √® normalmente distribuita, anche la distribuzione campionaria di \\(\\bar{X}\\) seguir√† una distribuzione normale, con media \\(\\mu\\) (la media della popolazione) e deviazione standard \\(\\frac{\\sigma}{\\sqrt{n}}\\) (dove \\(\\sigma\\) √® la deviazione standard della popolazione e \\(n\\) √® la dimensione del campione).\n\n77.5.2 Test di Ipotesi sulla Media Campionaria\nSupponendo di conoscere \\(\\sigma\\) ma non \\(\\mu\\), utilizziamo i test di ipotesi per indagare quanto la media campionaria osservata si discosti da un valore ipotetico \\(\\mu_0\\), specificato dall‚Äôipotesi nulla. Questo processo ci permette di valutare la plausibilit√† di \\(\\mu_0\\) come vera media della popolazione.\n\n77.5.3 Calcolo della Statistica del Test\nPer valutare quanto la media campionaria osservata si discosti dall‚Äôipotesi nulla che propone \\(\\mu = \\mu_0\\), standardizziamo \\(\\bar{X}\\) usando la formula:\n\\[\nZ = \\frac{\\bar{X} - \\mu_0}{\\sigma/\\sqrt{n}}\n\\]\nQuesta trasformazione produce una variabile \\(Z\\) che segue una distribuzione normale standard \\(\\mathcal{N}(0, 1)\\). Valori estremi di \\(Z\\) (sia molto grandi che molto piccoli) suggeriscono che la media campionaria osservata √® incompatibile con \\(\\mu_0\\), portando al rigetto dell‚Äôipotesi nulla.\n\n77.5.3.1 Simulazione\nPer illustrare quanto espresso sopra attraverso una simulazione, consideriamo un esempio numerico. Supponiamo che \\(\\mu_0 = 100\\), \\(\\sigma = 15\\) e \\(n = 30\\). Vogliamo calcolare il valore-p per l‚Äôevento \\(\\bar{X} &gt; 105\\).\nLa simulazione pu√≤ essere eseguita come segue:\n\n# To make the simulation reproducible\nset.seed(123)\n\nmu_0 &lt;- 100\nsigma &lt;- 15\nn &lt;- 30\nn_sim &lt;- 10000  # Number of simulations\n\n# Generate n_sim sample means from a N(mu_0, sigma/sqrt(n))\nsample_means &lt;- rnorm(n_sim, mean = mu_0, sd = sigma / sqrt(n))\n\n# Calculate the p-value as the proportion of sample means &gt; 105\np_value &lt;- mean(sample_means &gt; 105)\n\n# Print the p-value\nprint(p_value)\n#&gt; [1] 0.0339\n\nQuesto script simula la distribuzione campionaria di \\(\\bar{X}\\) sotto l‚Äôipotesi nulla che \\(\\mu = \\mu_0\\) e calcola il valore-p per l‚Äôevento \\(\\bar{X} &gt; 105\\). Il valore-p indica la probabilit√† di osservare un valore di \\(\\bar{X}\\) cos√¨ estremo (o pi√π estremo) se l‚Äôipotesi nulla fosse vera.\nIl risultato della simulazione pu√≤ essere confrontato con il calcolo teorico del valore-p usando la distribuzione normale standard. Il valore \\(Z\\) per \\(\\bar{X} = 120\\) √® calcolato come:\n\\[\nZ = \\frac{105 - 100}{15/\\sqrt{30}}\n\\]\nPossiamo usare la funzione stats.norm.sf() per trovare l‚Äôarea sotto la curva normale standard a destra di questo valore \\(Z\\), che corrisponde al valore-p teorico.\n\n# Calculate the Z-score\nZ &lt;- (105 - 100) / (15 / sqrt(30))\nprint(Z)\n#&gt; [1] 1.826\n\n\n# Calculate the upper tail probability\nupper_tail_prob &lt;- pnorm(Z, lower.tail = FALSE)\n\nprint(upper_tail_prob)\n#&gt; [1] 0.03394\n\nOppure, in maniera equivalente\n\n# Calculate the upper tail probability\nupper_tail_prob &lt;- 1 - pnorm(105, mean = 100, sd = 15 / sqrt(30))\nprint(upper_tail_prob)\n#&gt; [1] 0.03394\n\nIl calcolo teorico mostra che il valore \\(Z\\) per una media campionaria di 105 √® 1.82. Questo valore indica una deviazione sostanziale dalla media ipotizzata sotto l‚Äôipotesi nulla (\\(\\mu_0 = 100\\)). Tale deviazione pu√≤ essere quantificata dalla ‚Äúsorpresa‚Äù indicata dal valore-p, dove valori-p piccoli rappresentano una maggiore sorpresa. Il valore-p ottenuto, pari a 0.0339, indica un elevato grado di sorpresa: come mostrato dalla simulazione, un valore di 105 o superiore si verifica solo nel 3.4% dei casi se l‚Äôesperimento viene ripetuto numerose volte sotto l‚Äôipotesi nulla. Questo suggerisce che un risultato del genere √® altamente improbabile se l‚Äôipotesi nulla fosse vera.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>77</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#applicazioni-pratiche",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#applicazioni-pratiche",
    "title": "\n77¬† Significativit√† statistica\n",
    "section": "\n77.6 Applicazioni pratiche",
    "text": "77.6 Applicazioni pratiche\nNella precedente discussione, abbiamo supposto \\(\\sigma\\) nota. Tuttavia, poich√© di solito non conosciamo il valore di \\(\\sigma\\) nella pratica, dobbiamo stimarlo utilizzando la deviazione standard campionaria \\(s\\). Pertanto, al posto di \\(\\sigma\\), possiamo utilizzare \\(s\\), ottenendo cos√¨ la statistica:\n\\[\nT = \\frac{\\bar{X} - \\mu_0}{\\frac{s}{\\sqrt{n}}}.\n\\]\nSi pu√≤ dimostrare che la statistica \\(T\\) segue una distribuzione \\(t\\) di Student con \\(n-1\\) gradi di libert√† se il campione casuale √® stato estratto da una popolazione normale.\nA questo punto, possiamo applicare la stessa logica descritta in precedenza e possiamom basarci sulla statistica \\(T\\) per testare un‚Äôipotesi sulla media della popolazione. Utilizzando il valore critico appropriato dalla distribuzione \\(t\\) di Student con \\(n-1\\) gradi di libert√† e un livello di significativit√† predefinito, possiamo determinare se i dati osservati supportano o respingono l‚Äôipotesi nulla sulla media della popolazione.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>77</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#ipotesi-statistiche",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#ipotesi-statistiche",
    "title": "\n77¬† Significativit√† statistica\n",
    "section": "\n77.7 Ipotesi statistiche",
    "text": "77.7 Ipotesi statistiche\nEsaminiamo in maggior dettaglio la procedura di test di ipotesi statistiche nel contesto frequentista. Definiamo innanzitutto l‚Äôipotesi statistica come una dichiarazione riguardante la distribuzione di probabilit√† di una variabile casuale. Tale ipotesi pu√≤ riguardare la forma funzionale della distribuzione o i parametri che la caratterizzano.\nIn particolare, l‚Äôipotesi che riguarda i parametri di una o pi√π popolazioni viene denominata ipotesi nulla e viene rappresentata come \\(H_0\\). Per un parametro sconosciuto \\(\\theta\\), l‚Äôipotesi nulla viene formulata come:\n\\[\nH_0: \\theta \\in \\Theta_0 \\subset \\Theta,\n\\]\ndove \\(\\Theta_0\\) √® un sottoinsieme del dominio \\(\\Theta\\), che rappresenta tutti i possibili valori del parametro \\(\\theta\\) coerenti con il modello statistico adottato. L‚Äôipotesi nulla pu√≤ essere semplice se \\(\\Theta_0\\) contiene un unico elemento, oppure composta se contiene pi√π di un elemento.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>77</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#i-passi-di-un-test-di-ipotesi",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#i-passi-di-un-test-di-ipotesi",
    "title": "\n77¬† Significativit√† statistica\n",
    "section": "\n77.8 I passi di un test di ipotesi",
    "text": "77.8 I passi di un test di ipotesi\nPer prendere una decisione tra accettare o respingere l‚Äôipotesi nulla, i frequentisti utilizzano un test statistico. Un test statistico frequentista ci permette di valutare se i dati osservati forniscono prove sufficienti per respingere o accettare un‚Äôipotesi riguardante una propriet√† di una popolazione di interesse e si pu√≤ descrivere nel modo seguente.\nIniziamo formulando l‚Äôipotesi nulla \\(H_0\\), che rappresenta un‚Äôaffermazione specifica sulla popolazione. L‚Äôipotesi alternativa \\(H_1\\) viene formulata come l‚Äôevento complementare rispetto all‚Äôevento specificato dall‚Äôipotesi nulla. Successivamente, definiamo una statistica campionaria \\(\\mathcal{G}_n(X_1, \\dots, X_n)\\) che viene calcolata a partire dai dati campionari e che ha una distribuzione nota quando l‚Äôipotesi nulla √® vera.\nSuccessivamente, suddividiamo l‚Äôinsieme di tutte le possibili realizzazioni della statistica \\(\\mathcal{G}_n\\) in due insiemi disgiunti: la ‚Äúregione di accettazione‚Äù \\(\\mathcal{A}\\) e la sua regione complementare, la ‚Äúregione di rifiuto‚Äù \\(\\mathcal{R}\\). La regione di accettazione rappresenta l‚Äôinsieme dei valori che la statistica pu√≤ assumere sotto l‚Äôipotesi nulla, mentre la regione di rifiuto rappresenta l‚Äôinsieme dei valori che la statistica pu√≤ assumere se l‚Äôipotesi nulla √® falsa.\nInfine, selezioniamo un livello di significativit√† \\(\\alpha\\), che rappresenta la massima probabilit√† di respingere erroneamente l‚Äôipotesi nulla quando questa √® vera. Se l‚Äôosservazione della statistica \\(\\mathcal{G}_n\\) rientra nella regione di accettazione, allora l‚Äôipotesi nulla non viene respinta; altrimenti, viene respinta a favore dell‚Äôipotesi alternativa.\nIn sintesi, il test statistico ci consente di stabilire se i dati osservati forniscono sufficienti evidenze per rifiutare l‚Äôipotesi nulla a favore dell‚Äôipotesi alternativa.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>77</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#ipotesi-alternativa",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#ipotesi-alternativa",
    "title": "\n77¬† Significativit√† statistica\n",
    "section": "\n77.9 Ipotesi alternativa",
    "text": "77.9 Ipotesi alternativa\nDurante un test di ipotesi, dopo aver definito l‚Äôipotesi nulla \\(H_0\\), possono essere considerate diverse ipotesi alternative \\(H_1\\). Le ipotesi alternative pi√π comuni si suddividono in tre tipi:\n\n\n\\(H_1: \\theta \\neq \\theta_0\\),\n\n\\(H_1: \\theta &gt; \\theta_0\\),\n\n\\(H_1: \\theta &lt; \\theta_0\\).\n\nQueste corrispondono rispettivamente a un test bidirezionale, un test unilaterale superiore (o destro) e un test unilaterale inferiore (o sinistro).\nLa scelta dell‚Äôipotesi alternativa determina la definizione della regione di rifiuto \\(\\mathcal{R}\\) dell‚Äôipotesi nulla \\(H_0\\). La regione di rifiuto rappresenta i valori estremi della distribuzione, nella direzione dell‚Äôipotesi alternativa \\(H_1\\). Nel caso di un test unilaterale inferiore, \\(\\mathcal{R}\\) si trova nella coda sinistra della distribuzione, nell‚Äôintervallo [\\(-\\infty\\), \\(\\theta_0\\)]. Nel caso di un test unilaterale superiore, \\(\\mathcal{R}\\) si trova nella coda destra della distribuzione, nell‚Äôintervallo [\\(\\theta_0\\), \\(\\infty\\)].\nI valori critici sono i valori che delimitano la regione di rifiuto \\(\\mathcal{R}\\) in un test unilaterale e i valori che delimitano le regioni di rifiuto \\(\\mathcal{R}\\) in un test bidirezionale. Il risultato di un test viene considerato statisticamente significativo se il valore della statistica del test si trova nella regione di rifiuto \\(\\mathcal{R}\\).",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>77</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#valore-p",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#valore-p",
    "title": "\n77¬† Significativit√† statistica\n",
    "section": "\n77.10 Valore-p",
    "text": "77.10 Valore-p\nIl valore-p √® definito come la probabilit√† che la statistica del test assuma un valore uguale o pi√π estremo di quello osservato, considerando la distribuzione campionaria costruita assumendo come vera l‚Äôipotesi nulla. La significativit√† statistica viene convenzionalmente definita come un valore-p inferiore a 0.05, indicando che l‚Äôevidenza osservata √® improbabile da ottenere se l‚Äôipotesi nulla √® vera. Se il risultato osservato non raggiunge la significativit√† statistica, significa che la stima non √® statisticamente significativa e che il valore osservato pu√≤ essere spiegato da una semplice variazione casuale.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>77</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#un-esempio-motivante",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#un-esempio-motivante",
    "title": "\n77¬† Significativit√† statistica\n",
    "section": "\n77.11 Un esempio motivante",
    "text": "77.11 Un esempio motivante\nPer esplorare il concetto di significativit√† statistica, possiamo prendere in considerazione uno studio svolto da Mehr et al. (2016) sul ruolo della musica nella trasmissione di messaggi sociali ai bambini. La musica √® una forma d‚Äôarte presente in molte attivit√† quotidiane e pu√≤ trasmettere informazioni relative alla cultura e all‚Äôappartenenza sociale. Gli autori dello studio hanno voluto indagare se i bambini di soli 5 mesi avessero una preferenza per individui sconosciuti che cantavano loro una canzone familiare rispetto ad altri individui sconosciuti che cantavano una canzone simile, ma con una diversa melodia.\nDalle analisi condotte da Mehr et al. (2016) √® emerso che la preferenza dei bambini si manifestava solo quando la canzone veniva cantata dai loro genitori durante la fase di familiarizzazione, ma non quando la stessa canzone veniva cantata da un estraneo. Secondo gli autori, questo dimostra che il significato sociale √® un elemento chiave nella preferenza dei bambini, oltre alla familiarit√† con la canzone.\n\n77.11.1 Domanda della ricerca e ipotesi statistiche\nLa ricerca condotta da Mehr et al. (2016) si √® concentrata sullo studio dell‚Äôinfluenza della musica sui messaggi sociali trasmessi ai bambini molto piccoli. Tuttavia, come molte altre ipotesi psicologiche, l‚Äôipotesi principale non pu√≤ essere valutata direttamente in termini quantitativi. Pertanto, i ricercatori devono formulare ipotesi statistiche, che, sebbene non coincidano con l‚Äôipotesi della ricerca, possono essere esaminate in termini probabilistici.\nPer chiarire questo punto, consideriamo l‚Äôesperimento condotto sui bambini da Mehr et al. (2016). Dopo la fase di familiarizzazione con la canzone di prova, i bambini partecipanti sono stati sottoposti a un test in laboratorio, durante il quale sono stati mostrati due video. Nel primo video, un estraneo cantava la canzone di prova, mentre nel secondo video, un altro individuo cantava una canzone simile ma non familiare ai bambini. I ricercatori hanno misurato il tempo in cui i bambini fissavano ciascun video. Nel primo esperimento, la variabile dipendente era la media delle proporzioni di tempo che i bambini fissavano il video ‚Äúfamiliare‚Äù rispetto al tempo di fissazione totale. Poich√© l‚Äôipotesi principale non pu√≤ essere valutata direttamente, i ricercatori hanno formulato ipotesi statistiche che possono essere esaminate in termini probabilistici.\nPoich√© nei tipici esperimenti psicologici, come nel caso della ricerca di Mehr et al. (2016), l‚Äôipotesi della ricerca non pu√≤ essere valutata direttamente, √® necessario stabilire una connessione tra l‚Äôipotesi della ricerca e l‚Äôipotesi statistica. Nel caso specifico, ci sono tre possibili scenari da considerare:\n\nNel caso in cui i bambini non mostrino alcuna preferenza tra i due tipi di video-registrazione, la media delle proporzioni di tempo di fissazione per la popolazione sar√† uguale a \\(\\mu = 0.5\\), in quanto i tempi di fissazione saranno uguali in media per le due video-registrazioni.\nSe invece gli autori della ricerca hanno ragione, i bambini mostreranno una preferenza per il video con la canzone familiare rispetto a quello con la canzone non familiare. In questo caso, l‚Äôipotesi statistica sar√† \\(\\mu &gt; 0.5\\), dove \\(\\mu = 0.5\\) rappresenta il livello di probabilit√† casuale.\nInfine, una terza possibilit√† √® che i bambini siano maggiormente attratti da una melodia non familiare, contrariamente a quanto suggerito dagli autori della ricerca. In tal caso, l‚Äôipotesi statistica diventa \\(\\mu &lt; 0.5\\).\n\nLe tre ipotesi precedenti sono esempi di ipotesi statistiche, che sono delle affermazioni riguardanti i valori di un parametro di un modello statistico. Nel caso dell‚Äôesperimento di Mehr et al. (2016), il modello statistico riguarda la distribuzione delle proporzioni dei tempi di fissazione di una popolazione virtuale di infiniti bambini di sei mesi di et√†. Ogni bambino avr√† una proporzione di tempi di fissazione diversa dagli altri bambini. Il modello statistico descritto dai ricercatori rappresenta la distribuzione dei possibili valori della proporzione del tempo di fissazione nei confronti del video ‚Äúfamiliare‚Äù. I dati raccolti dagli sperimentatori corrispondono alla media della proporzione del tempo di fissazione del video ‚Äúfamiliare‚Äù e possono essere messi in relazione con il modello statistico.\n\n77.11.2 Domanda della ricerca e ipotesi statistiche\nLa distinzione tra l‚Äôipotesi della ricerca e l‚Äôipotesi statistica √® cruciale durante il test delle ipotesi. L‚Äôipotesi della ricerca riguarda l‚Äôaffermazione che si intende testare sulla natura dei fenomeni psicologici, mentre l‚Äôipotesi statistica riguarda il modello generativo dei dati, ovvero le propriet√† della popolazione. Nel caso dell‚Äôesperimento condotto da Mehr e colleghi, l‚Äôipotesi della ricerca afferma che la preferenza sociale dei bambini √® influenzata dalla musica e, in particolare, dalla familiarit√† con i materiali musicali. L‚Äôipotesi statistica, invece, sostiene che la media della proporzione del tempo di fissazione dei bambini sul video ‚Äúfamiliare‚Äù sia maggiore di 0.5.\nI test di ipotesi vengono applicati alle ipotesi statistiche, non alle ipotesi della ricerca. Ci√≤ significa che se l‚Äôesperimento non viene condotto nella maniera appropriata, il collegamento tra l‚Äôipotesi statistica e la domanda della ricerca pu√≤ essere spezzato. Ad esempio, se l‚Äôattore che canta la melodia familiare assomiglia ad uno dei genitori del bambino, mentre l‚Äôaltro attore ha un aspetto molto diverso, allora potrebbe essere facile trovare evidenze a supporto dell‚Äôipotesi statistica secondo cui la proporzione media del tempo di fissazione dei bambini nei confronti del video ‚Äúfamiliare‚Äù √® maggiore di 0.5, ma ci√≤ non avrebbe nulla a che fare con la domanda della ricerca.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>77</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#ipotesi-nulla-e-ipotesi-alternativa",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#ipotesi-nulla-e-ipotesi-alternativa",
    "title": "\n77¬† Significativit√† statistica\n",
    "section": "\n77.12 Ipotesi nulla e ipotesi alternativa",
    "text": "77.12 Ipotesi nulla e ipotesi alternativa\nFino a qui il ragionamento √® stato semplice: il ricercatore ha un‚Äôipotesi a proposito dei fenomeni psicologici e a tale ipotesi di ricerca corrisponde un‚Äôipotesi statistica che riguarda il meccanismo generativo dei dati. Se il fenomeno psicologico possiede le propriet√† suggerite dall‚Äôipotesi della ricerca, allora il ricercatore pu√≤ aspettarsi che i dati osservati abbiano alcune specifiche caratteristiche. A questo punto, per√≤, il ragionamento diventa contro-intuitivo perch√© non √® possibile verificare direttamente l‚Äôipotesi statistica che corrisponde alla domanda della ricerca.\n\n77.12.1 Apagogia\nIn linea di principio, non √® mai possibile dimostrare direttamente la verit√† di una proposizione. Tuttavia, possiamo dimostrare la sua verit√† in modo indiretto, ovvero provando la falsit√† della sua proposizione complementare.\nL‚Äôesempio classico √® il seguente. Consideriamo la seguente proposizione: ‚ÄúTutti i cigni sono bianchi‚Äù (questo √® l‚Äôesempio ornitologico preferito da Popper). L‚Äôosservazione di un numero qualsiasi di cigni bianchi non √® sufficiente a dimostrare la verit√† di questa proposizione ‚Äì infatti, ci potrebbe essere da qualche parte un cigno non bianco che non abbiamo osservato (e infatti c‚Äô√®). D‚Äôaltra parte, invece, l‚Äôosservazione di un solo cigno che non sia bianco (ovvero, per esempio, l‚Äôosservazione di un cigno nero proveniente dall‚ÄôAustralia) pu√≤ falsificare la proposizione considerata. Questa √® la logica del falsificazionismo di Popper.\nQuesto modo di pensare √® stato trasferito nella procedura di test di ipotesi di stampo frequentista. Dato che non possiamo dimostrare vera l‚Äôipotesi statistica associata alla domanda della ricerca, seguiamo il percorso opposto. Ovvero, ci poniamo l‚Äôobiettivo di dimostrare falso l‚Äôevento complementare a quello specificato dall‚Äôipotesi statistica associata alla domanda della ricerca. L‚Äôipotesi statistica che vorremmo falsificare si chiama ‚Äúipotesi nulla‚Äù e viene denotata con \\(H_0\\). Nel caso dell‚Äôesempio che stiamo discutendo, l‚Äôipotesi nulla √®: \\(\\mu \\leq 0.5\\). Si noti che l‚Äôipotesi nulla include tutte le possibili ipotesi statistiche che si possono formulare (ovvero, \\(\\mu = 0.5\\) e \\(\\mu &lt; 0.5\\)), ad eccezione di quella che √® associata all‚Äôipotesi della ricerca (ovvero, \\(\\mu &gt; 0.5\\)). Questo definisce, nel caso presente, un test unilaterale.\nIn pratica, ci√≤ che stiamo facendo √® dividere tutti i possibili valori di \\(\\mu\\) in due gruppi: quei valori che sono coerenti con l‚Äôipotesi della ricerca (ovvero, i valori che specificano l‚Äôipotesi alternativa, denotata con \\(H_1\\)) e quei valori che non sono coerenti con l‚Äôipotesi della ricerca (ovvero, i valori che specificano l‚Äôipotesi nulla).\nAvendo detto questo, la cosa importante da riconoscere √® che l‚Äôobiettivo di un test di ipotesi frequentista non √® quello di dimostrare che l‚Äôipotesi alternativa √® (probabilmente) vera; l‚Äôobiettivo √® mostrare che l‚Äôipotesi nulla √® (probabilmente) falsa. La maggior parte delle persone ritiene che questo modo di ragionare sia piuttosto strano.\n\n77.12.2 La similitudine del processo penale\nUn test di ipotesi √® spesso comparato ad un processo penale, dove l‚Äôipotesi nulla rappresenta l‚Äôimputato, il ricercatore il pubblico ministero, e il test statistico il giudice. Cos√¨ come in un processo penale, anche in un test di ipotesi c‚Äô√® una presunzione di innocenza, dove l‚Äôipotesi nulla viene considerata vera a meno che il ricercatore non dimostri, con evidenza al di l√† di ogni ragionevole dubbio, che √® falsa. Il ricercatore progetta l‚Äôesperimento in modo da massimizzare la possibilit√† che i dati producano una condanna dell‚Äôipotesi nulla. Il test statistico, rappresentato dal giudice in questa metafora, stabilisce le regole che devono essere seguite per giungere al verdetto e tali regole sono pensate per proteggere l‚Äôipotesi nulla. In particolare, sono studiate per garantire che la probabilit√† di una condanna sia bassa se l‚Äôipotesi nulla √® effettivamente vera. √à importante sottolineare che l‚Äôipotesi nulla deve essere protetta, poich√© il ricercatore sta cercando di dimostrare che essa √® falsa.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>77</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#due-tipi-di-errori",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#due-tipi-di-errori",
    "title": "\n77¬† Significativit√† statistica\n",
    "section": "\n77.13 Due tipi di errori",
    "text": "77.13 Due tipi di errori\nPrima di entrare nei dettagli su come viene costruito un test statistico √® utile capire la logica su cui esso √® basato. In precedenza abbiamo paragonato il test di ipotesi nulla ad un processo penale, ma ora dobbiamo essere pi√π espliciti. Idealmente, vorremmo costruire il nostro test in modo da non commettere errori. Sfortunatamente, per√≤, questo non √® possibile: a volte il ricercatore √® sfortunato e finisce per prendere la decisione sbagliata, anche se adotta un processo decisionale razionale. Ad esempio, pu√≤ succedere che una moneta venga lanciata 10 volte di fila e produca testa tutte le 10 volte. Ci√≤ sembra fornire una prova molto forte del fatto che la moneta √® sbilanciata, ma c‚Äô√® una possibilit√† su 1024 che ci√≤ accada anche se la moneta √® equilibrata. In altre parole, nella vita reale dobbiamo sempre accettare la possibilit√† che le nostre scelte siano sbagliate, anche quando sembrano ragionevoli. Di conseguenza, l‚Äôobiettivo dei test delle ipotesi statistiche non √® quello di eliminare completamente gli errori (questo √® impossibile), ma di ridurre gli errori al minimo.\nA questo punto, dobbiamo precisare meglio cosa intendiamo per ‚Äúerrori‚Äù. Iniziamo con il rendere esplicito quello che √® ovvio: l‚Äôipotesi nulla pu√≤ essere vera o falsa, e il nostro test ci pu√≤ condurre a rifiutare l‚Äôipotesi nulla o a non rifiutarla. La decisione di rigettare o non rigettare l‚Äôipotesi nulla ci espone dunque al rischio di commettere uno di due tipi di errore, come indicato nella figura seguente. L‚Äôerrore di I tipo, denotato con \\(\\alpha\\), √® quello che commettiamo se rigettiamo l‚Äôipotesi nulla quando essa √® vera; l‚Äôerrore di II tipo, denotato con \\(\\beta\\), √® quello che commettiamo se accettiamo l‚Äôipotesi nulla mentre invece √® vera l‚Äôipotesi alternativa.\n\n\n77.13.1 Errore di I tipo: la protezione dei diritti dell‚Äôimputato\nIn precedenza abbiamo paragonato il test statistico ad un processo penale. Infatti, un processo penale richiede che si stabilisca la colpevolezza dell‚Äôimputato ‚Äúoltre ogni ragionevole dubbio‚Äù. Le regole del processo penale sono state progettate per garantire che non ci sia (quasi) nessuna possibilit√† di condannare ingiustamente un imputato innocente: il processo penale √® progettato (almeno in teoria) per proteggere i diritti dell‚Äôimputato. Detto in altri termini, il processo penale non mette sullo stesso piano i due tipi di errore che si possono commettere: punire un innocente o assolvere un colpevole. L‚Äôerrore che consiste nel punire un innocente viene considerato assai pi√π grave di quello che porta ad assolvere un colpevole.\nUn test statistico fa praticamente la stessa cosa: i test di ipotesi statistiche sono costruiti in modo tale da controllare la probabilit√† di un errore di I tipo, con l‚Äôobiettivo di mantenerla al di sotto di una certa soglia prefissata. Questa probabilit√†, denotata con \\(\\alpha\\), viene chiamata ‚Äúlivello di significativit√† del test‚Äù. Usando parole diverse, possiamo dire che un test di ipotesi ha un livello di significativit√† \\(\\alpha\\) se il tasso di errore di I tipo non √® pi√π grande di \\(\\alpha\\). Per convenzione, i ricercatori fanno uso di tre diversi livelli \\(\\alpha\\): 0.05, 0.01 e 0.001.\n\n77.13.2 Errore di II tipo: l‚Äôasimmetria del giudizio\nChe dire del tasso di errore di II tipo? In realt√†, vorremmo tenere anche quello sotto controllo e denotiamo la probabilit√† di un errore di II tipo con \\(\\beta\\). Il livello d‚Äôerrore \\(\\beta\\) viene raramente discusso ed √® molto pi√π comune fare riferimento alla potenza del test, che √® la probabilit√† dell‚Äôevento complementare, ovvero la probabilit√† con cui rifiutiamo l‚Äôipotesi nulla quando √® realmente falsa, ovvero \\(1-\\beta\\). Un test viene detto ‚Äúpotente‚Äù quando √® caratterizzato da un piccolo valore \\(\\beta\\) pur mantenendo il livello \\(\\alpha\\) sotto una piccola soglia di probabilit√† prefissata.\nSi noti l‚Äôasimmetria qui rivelata: i test di ipotesi sono progettati per garantire che il livello \\(\\alpha\\) sia mantenuto sotto la soglia prefissata, ma non esiste alcuna corrispondente garanzia a proposito di \\(\\beta\\). Sicuramente √® preferibile che il tasso di errore di II tipo sia piccolo, e in generale i ricercatori cercano di progettare i loro esperimenti in maniera tale da avere una ragionevole potenza del test (\\(1 - \\beta\\)) ‚Äì questo si ottiene utilizzando un campione sufficientemente grande ‚Äì ma nella logica della costruzione del test di ipotesi questo aspetto √® secondario rispetto alla necessit√† di controllare il tasso di errore di I tipo.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>77</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#come-si-costruisce-un-test-di-ipotesi",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#come-si-costruisce-un-test-di-ipotesi",
    "title": "\n77¬† Significativit√† statistica\n",
    "section": "\n77.14 Come si costruisce un test di ipotesi?",
    "text": "77.14 Come si costruisce un test di ipotesi?\nRitorniamo all‚Äôesempio relativo allo studio di Mehr et al. (2016). In questo caso, sulla base all‚Äôipotesi della ricerca, l‚Äôipotesi nulla pu√≤ essere formulata come \\(H_0: \\mu \\leq 0.5\\). Esaminando un campione di 32 bambini di et√† media pari a 5.6 mesi, Mehr et al. (2016) hanno scoperto che, in media, i bambini dirigevano lo sguardo verso il video ‚Äúfamiliare‚Äù nel 56% del tempo totale di fissazione. Dunque, la media campionaria √® \\(\\bar{X} = 0.56\\) Questo √® il valore campionario rilevante per il test dell‚Äôipotesi nulla.\nIngenuamente, potremmo pensare che, per decidere se \\(H_0\\) sia falsa o meno, sia sufficiente confrontare la proporzione calcolata nel campione con il valore \\(\\pi\\) specificato dall‚Äôipotesi nulla. Nel caso presente, l‚Äôipotesi nulla non specifica un unico valore \\(\\mu\\) ma bens√¨ un intervallo di valori: \\([0, 0.5]\\). I dati campionari specificano un valore \\(\\bar{X} = 0.56\\), ovvero un valore che non √® incluso nell‚Äôintervallo specificato da \\(H_0\\). Questo √® incoraggiante. Se invece avessimo osservato \\(\\bar{X} = 0.41\\), per esempio, allora non ci sarebbe stato nient‚Äôaltro da dire: se i dati osservati sono compatibili con \\(H_0\\) non c‚Äô√® bisogno di eseguire alcun test statistico ‚Äì abbiamo gi√† trovato la risposta alla domanda della ricerca.\n\n77.14.1 La variabilit√† campionaria\nNel caso dell‚Äôesperimento di Mehr et al. (2016) che stiamo discutendo, \\(\\bar{X}\\) non cade nell‚Äôintervallo specificato da \\(H_0\\). Sulla base del valore osservato \\(\\bar{X} = 0.56\\) possiamo dunque concludere che \\(H_0\\) √® falsa? Non cos√¨ presto. Non √® sufficiente trovare una differenza \\(\\bar{X} - \\mu\\) nella direzione giusta (cio√® positiva, nel nostro caso). √à anche necessario tenere in considerazione il fenomeno della variabilit√† campionaria.\nInfatti, la media \\(\\bar{X}\\) osservata in ogni singolo campione di ampiezza \\(n=32\\) √® una variabile aleatoria: in ciascun possibile campione di ampiezza 32 i bambini si comportano in maniera diversa e, di conseguenza, \\(\\bar{X}\\) assumer√† un valore diverso da campione a campione. Le statistiche campionarie ‚Äì nel nostro caso la media \\(\\bar{X}\\) ‚Äì sono di necessit√† diverse dai parametri. Ci√≤ a cui noi siamo interessati √® la media della popolazione, ovvero \\(\\mu\\), ma sfortunatamente conosciamo solo una sua realizzazione campionaria, ovvero \\(\\bar{X}\\).\nRisulta dunque chiaro che la nostra decisione rispetto ad \\(H_0\\) non pu√≤ essere unicamente basata sulla differenza tra \\(\\bar{X} - \\mu\\). Infatti, √® ragionevole pensare che, indipendentemente dal fatto che l‚Äôipotesi nulla sia vera o meno, in alcuni campioni la differenza \\(\\bar{X} - \\mu\\) sar√† positive mentre in altri campioni sar√† negativa. Dobbiamo dunque trovare una procedura che riduca la possibilit√† di rifiutare \\(H_0\\) per effetto del caso soltanto. Possiamo (e dobbiamo) fare di meglio che considerare unicamente la differenza \\(\\bar{X} - \\mu\\).\n\n77.14.2 Le distribuzioni delle statistiche test\nIl metodo seguito dall‚Äôapproccio frequentista per affrontare questo problema √® quello di costruire la distribuzione della statistica test \\(\\mathcal{G}_n\\), rilevante per il test di \\(H_0\\), assumendo come vera l‚Äôipotesi nulla. Questo √® il concetto pi√π contro-intuitivo di tutta la procedura di test di ipotesi dell‚Äôapproccio frequentista. Esaminiamolo pi√π in dettaglio.\nLo scopo della procedura di test statistici dell‚Äôapproccio frequentista non √® quello di verificare l‚Äôipotesi alternativa: questo non √® logicamente possibile. Invece, come suggerito dalla similitudine del processo penale all‚Äôipotesi nulla, l‚Äôapproccio frequentista si pone l‚Äôobiettivo di determinare se ci siano indizi sufficienti per ‚Äúcondannare‚Äù l‚Äôipotesi nulla, ovvero, per rigettarla. In questa reductio ad absurdum, la ‚Äúpresunzione di innocenza‚Äù di \\(H_0\\) corrisponde all‚Äôidea che dobbiamo assumere come vera l‚Äôipotesi nulla fino a prova contraria.\nNell‚Äôesempio che stiamo discutendo, assumere come vera l‚Äôipotesi nulla significa assumere che il parametro \\(\\mu\\) (la media della popolazione) sia uguale a 0.5. Sulla base di questa assunzione, per i dati dell‚Äôesempio presente, √® possibile costruire la distribuzione delle medie dei campioni di ampiezza 32. Standardizzando poi la media del campione, √® possibile stabilire quanto sia ‚Äúdistante‚Äù dal valore atteso della distribuzione campionaria costruita assumento come vera \\(H_0\\).\nLa standardizzazione di \\(\\bar{X}\\) si effettua mediante il rapporto\n\\[\nT = \\frac{\\bar{X} - \\mu}{\\frac{s}{\\sqrt{n}}},\n\\]\ndove \\(\\bar{X}\\) √® la media del campione (nel nostro caso, 0.56), \\(s\\) √® la deviazione standard del campione (gli autori riportano \\(s\\) = 0.179) e \\(n\\) √® l‚Äôampiezza del campione (ovvero, \\(n\\) = 32). Per il caso presente otteniamo:\n\nT &lt;- (0.56 - 0.50) / (0.179 / sqrt(32))\nprint(T)\n#&gt; [1] 1.896\n\n\n77.14.3 Regioni di rifiuto e regioni di non rifiuto\nConoscendo la distribuzione dei valori della statistica test (distribuzione determinata assumendo come vera \\(H_0\\)) diventa poi possibile dividere l‚Äôinsieme dei valori possibili di \\(\\mathcal{G}_n\\) (il nome che abbiamo assegnato ad una generica statistica test) in due regioni: i valori che ci portano a rigettare \\(H_0\\) (regione di rifiuto) e quelli che non ci consentono di rigettare \\(H_0\\) (regione di non rifiuto).\nPer decidere quanto deve essere grande la regione di rifiuto di \\(H_0\\) √® sufficiente collocare nella regione di rifiuto i valori estremi della statistica test \\(\\mathcal{G}_n\\), ovvero quelli che sarebbe molto improbabile osservare se \\(H_0\\) fosse vera.\n\n77.14.4 Quando rifiutare l‚Äôipotesi nulla\nSupponiamo che la figura seguente rappresenti la distribuzione campionaria della statistica test \\(\\mathcal{G}_n\\).\n\nSe i dati producono la statistica test \\(\\mathcal{G}_n^1\\), non possiamo rifiutare l‚Äôipotesi nulla \\(H_0\\). Se invece i dati producono \\(\\mathcal{G}_n^2\\) allora possiamo rifiutare l‚Äôipotesi nulla in favore dell‚Äôipotesi alternativa. Ci sono varie cose da notare.\n\nLa regione di rifiuto √® costituita da valori lontani dal centro della distribuzione campionaria della statistica test, la quale √® stata costruita assumendo come vera \\(H_0\\).\nLa regione di rifiuto √® situata nelle code della distribuzione. Vedremo in seguito anche degli esempi di regioni di rifiuto unilaterali.\nIn questa discussione, l‚Äôipotesi alternativa non √® menzionata. Rifiutiamo o non rifiutiamo \\(H_0\\) basandoci unicamente sulla distribuzione campionaria \\(f(\\mathcal{G}_n \\mid H_0)\\), cio√® sulla probabilit√† della statistica test condizionata all‚Äôipotesi nulla \\(H_0\\). L‚Äôipotesi alternativa \\(H_1\\) viene presa in considerazione quando si sceglie dove posizionare la regione di rifiuto di \\(H_0\\), ma formalmente non gioca alcun ruolo nel rigettare o meno \\(H_0\\).\n\n77.14.5 Specificazione delle regioni di rifiuto\nL‚Äôipotesi alternativa \\(H_1\\) pu√≤ assumere forme diverse e ci√≤ conduce a specificazioni diverse della regione di rifiuto \\(\\mathcal{R}\\) di \\(H_0\\). La regione di rifiuto \\(\\mathcal{R}\\) dell‚Äôipotesi nulla corrisponde ai valori collocati agli estremi della distribuzione secondo la direzione dell‚Äôipotesi alternativa \\(H_1\\).\n\nSe l‚Äôipotesi alternativa √® \\(H_1: \\theta \\neq \\theta_0\\) (dove \\(\\theta\\) √® un generico parametro e \\(\\theta_0\\) √® uno specifico valore del parametro), allora le evidenze coerenti con l‚Äôipotesi alternativa (e che portano al rigetto di \\(H_0\\)) sono contenute negli intervalli \\([-\\infty, \\theta_0]\\) e \\([\\theta_0, +\\infty]\\).\nSe l‚Äôipotesi alternativa √® \\(H_1: \\theta &lt; \\theta_0\\), allora le evidenze coerenti con l‚Äôipotesi alternativa (e che portano al rigetto di \\(H_0\\)) sono contenute nell‚Äôintervallo \\([-\\infty, \\theta_0]\\) e l‚Äôintera regione di rifiuto \\(\\mathcal{R}\\) √® collocata nella coda di sinistra della distribuzione.\nSe l‚Äôipotesi alternativa √® \\(H_1: \\theta &gt; \\theta_0\\), allora le evidenze coerenti con l‚Äôipotesi alternativa (e che portano al rigetto di \\(H_0\\)) sono contenute nell‚Äôintervallo \\([\\theta_0, \\infty]\\) e l‚Äôintera regione di rifiuto \\(\\mathcal{R}\\) √® collocata nella coda di destra della distribuzione.\n\nSi chiamano valori critici i valori che delimitano la regione di rifiuto \\(\\mathcal{R}\\) in un test unilaterale e i valori che delimitano le regioni di rifiuto \\(\\mathcal{R}\\) in un test bilaterale. In un test bidirezionale, i valori critici lasciano in ciascuna delle due code della distribuzione della statistica test una probabilit√† pari a \\(\\alpha/2\\); in un test unidirezionale lasciano una probabilit√† pari ad \\(\\alpha\\) in una sola coda. Il risultato di un test si dice statisticamente significativo quando il valore della statistica test ricade nella regione di rifiuto \\(\\mathcal{R}\\).\n\n77.14.6 La decisione statistica\nIl processo di decisione statistica viene descritto da von Mises (1964) nel modo seguente:\n\nControllare (checking) o saggiare (testing) ha la forma seguente: se il ‚Äúrisultato osservato‚Äù ha una ‚Äòpiccola‚Äô probabilit√† subordinatamente all‚Äôipotesi assunta, respingiamo l‚Äôipotesi. (p.¬†441)\n\nOvviamente l‚Äôipotesi a cui von Mises fa riferimento √® l‚Äôipotesi nulla.\nIn pratica, possiamo decidere se rigettare o meno l‚Äôipotesi nulla in due modi: determinando se la statistica test \\(\\mathcal{G}_n\\) cade o meno nella regione di rifiuto (come abbiamo descritto sopra) o confrontando il valore-\\(p\\) con \\(\\alpha\\) ‚Äì i due metodi sono equivalenti.\nIl valore-p rappresenta la probabilit√† di osservare un valore della statistica test \\(\\mathcal{G}_n\\) pari a quello effettivamente osservato, o maggiore, quanto l‚Äôipotesi nulla √® vera. Se il valore-\\(p\\) √® minore del livello di significativit√† \\(\\alpha\\), allora la statistica test cade nella regione di rifiuto di \\(H_0\\) e ci√≤ conduce al rifiuto dell‚Äôipotesi nulla. Tali concetti sono riassunti nella tabella seguente.\n\nPer l‚Äôesempio in discussione, la statistica \\(T\\) calcolata sopra si distribuisce come \\(t\\) di Student con \\(\\nu = 31\\) gradi di libert√†. Il valore-p corrisponde dunque all‚Äôarea sottesa ad una \\(t_{31}\\) nell‚Äôintervallo \\([1.896, +\\infty]\\) (test unidirezionale destro), ovvero\n\n# Calculate the upper tail probability for the t-distribution\np &lt;- 1 - pt(T, df = 31)\nprint(p)\n#&gt; [1] 0.03365\n\nDato che il valore-p √® minore di \\(\\alpha = 0.05\\), Mehr et al. (2016) rifiutano \\(H_0\\) (cio√® che la proporzione media del tempo di fissazione dei bambini nei confronti del video ‚Äúfamiliare‚Äù sia 0.5, o minore) e concludono che i bambini mostrano una preferenza per il video familiare.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>77</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#potenza-del-test",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#potenza-del-test",
    "title": "\n77¬† Significativit√† statistica\n",
    "section": "\n77.15 Potenza del test",
    "text": "77.15 Potenza del test\nRitorniamo ora al concetto di potenza del test. Il livello di significativit√† e la potenza del test vengono usati per quantificare la qualit√† dell‚Äôinferenza statistica. Idealmente, la procedura di test di ipotesi non dovrebbe giungere alla conclusione sbagliata. Ovvero, non dovrebbe respingere \\(H_0\\) quando essa √® vera e dovrebbe respingere \\(H_0\\) in favore dell‚Äôalternativa quando \\(H_1\\) √® vera. Ma questi sono solo due dei quattro esiti che, in principio, sono possibili, e corrispondono alle probabilit√† indicate di seguito.\n\nPossiamo pensare a \\(H_0\\) come all‚Äôipotesi che descrive l‚Äôevento ‚Äúnulla di interessante sta succedendo‚Äù ‚Äì ad esempio, ‚Äúla moneta √® bilanciata‚Äù, ‚Äúil trattamento non √® migliore del placebo‚Äù, ecc. ‚Äì e pensare ad \\(H_1\\) come al caso contrario, ovvero: ‚Äústa accadendo qualcosa di interessante‚Äù. Quindi la potenza del test, ovvero la probabilit√† \\(1 - \\beta\\) di rigettare \\(H_0\\) quando essa √® falsa, corrisponde alla probabilit√† di rilevare qualcosa di interessante, quando qualcosa di interessante √® effettivamente successo, mentre il livello di significativit√† corrisponde alla probabilit√† di affermare che qualcosa di interessante si √® verificato, quando in realt√† non √® successo nulla di interessante.\nIl calcolo della potenza di un test √® spesso difficile, perch√© richiede la conoscenza della distribuzione campionaria di \\(\\mathcal{G}_n\\) quando √® vera l‚Äôipotesi alternativa \\(H_1\\). Tipicamente possiamo aumentare la potenza di un test aumentando la numerosit√† del campione in maniera tale da diminuire la varianza delle distribuzioni della statistica test condizionate a \\(H_0\\) e ad \\(H_1\\). In un disegno sperimentale √® importante determinare in anticipo il numero di prove o dei soggetti necessari per raggiungere la potenza desiderata.\n\n77.15.1 Neyman e Fisher\nLa procedura di test di ipotesi statistiche descritta sopra combina due approcci teorici diversi, proposti da Sir Ronald Fisher e Jerzy Neyman. La storia di questi due approcci non √® lineare, poich√© Fisher e Neyman hanno modificato le loro opinioni nel tempo, senza mai fornire una ‚Äúverit√† definitiva‚Äù su come interpretare il loro lavoro.\nIn sintesi, Fisher considerava che il ricercatore avesse un‚Äôunica ipotesi (quella nulla) e che lo scopo fosse verificare se i dati fossero coerenti o meno con essa. In questo senso, il valore-\\(p\\) rappresenta la probabilit√† di osservare, sotto l‚Äôipotesi nulla, il risultato ottenuto o uno ancora pi√π estremo. Se il valore-\\(p\\) √® piccolo, Fisher rifiutava l‚Äôipotesi nulla. Tuttavia, poich√© non venivano formulate altre ipotesi, non c‚Äôera modo di ‚Äúaccettare l‚Äôalternativa‚Äù.\nAl contrario, Neyman adottava un approccio pi√π formale rispetto a Fisher e pensava che lo scopo della verifica delle ipotesi fosse quello di prendere decisioni. Secondo Neyman, il problema era decidere se accettare l‚Äôipotesi nulla o l‚Äôalternativa e il test serviva a stabilire quale supporto venisse fornito alle due alternative. Per questo motivo, era fondamentale specificare in modo preciso l‚Äôipotesi alternativa. Nel suo approccio, il valore-\\(p\\) non misurava la probabilit√† del risultato del test o di uno pi√π estremo sotto l‚Äôipotesi nulla, ma forniva una descrizione astratta dei ‚Äúpossibili test‚Äù che portavano all‚Äôaccettazione dell‚Äôipotesi nulla o dell‚Äôalternativa.\nAttualmente ci troviamo in una situazione strana e ambigua, dove sono presenti elementi di entrambi gli approcci. La procedura di verifica di ipotesi statistiche distingue tra un‚Äôipotesi nulla e un‚Äôipotesi alternativa, seguendo la visione di Neyman, ma definisce il valore-\\(p\\) in termini di dati estremi, come avrebbe fatto Fisher, in confronto con un livello \\(\\alpha\\) stabilito da Neyman. Alcuni test statistici specificano in modo chiaro l‚Äôipotesi alternativa, mentre altri sono pi√π vaghi in merito, adottando l‚Äôapproccio di Fisher. Inoltre, c‚Äô√® disaccordo tra i ricercatori riguardo alla possibilit√† di ‚Äúaccettare l‚Äôalternativa‚Äù, a seconda che si segua Neyman o Fisher. Questa confusione costituisce il ‚Äúpeccato originale‚Äù della procedura di verifica di ipotesi statistiche. Tuttavia, ci sono motivi pi√π specifici per cui questo approccio, noto come significativit√† statistica, viene criticato da molti ricercatori come una delle cause principali della crisi della replicabilit√† dei risultati della ricerca in psicologia e in altri campi. Nel capitolo ?sec-errors-s-m esploreremo queste ragioni in dettaglio.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>77</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#la-storia-del-test-dellipotesi-nulla-di-fisher-e-le-sue-contraddizioni",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#la-storia-del-test-dellipotesi-nulla-di-fisher-e-le-sue-contraddizioni",
    "title": "\n77¬† Significativit√† statistica\n",
    "section": "\n77.16 La Storia del Test dell‚ÄôIpotesi Nulla di Fisher e le Sue Contraddizioni",
    "text": "77.16 La Storia del Test dell‚ÄôIpotesi Nulla di Fisher e le Sue Contraddizioni\nConcludiamo l‚Äôanalisi della procedura dei test di ipotesi statistici esaminando l‚Äôevento che ha ispirato Ronald A. Fisher a sviluppare la sua teoria dell‚Äôinferenza statistica, focalizzata sul test dell‚Äôipotesi nulla. Questo episodio √® descritto dettagliatamente da Etz et al. (2018). L‚Äôaneddoto riguarda un t√® che Fisher aveva offerto alla sua collega, la Dott.ssa Muriel Bristol. Durante la preparazione della bevanda, la Dr.ssa Bristol contest√≤ il metodo adottato da Fisher, asserendo che il t√® avrebbe avuto un gusto migliore se il latte fosse stato versato prima dell‚Äôacqua bollente. Per verificare l‚Äôaffermazione della Dr.ssa Bristol, Fisher ide√≤ un esperimento di discriminazione sensoriale. Nei test condotti, la Dr.ssa Bristol fu in grado di individuare correttamente il processo di preparazione del t√® in cinque occasioni su sei.\nQuesto risultato pose Fisher di fronte a un interrogativo: la sua collega stava semplicemente facendo una supposizione fortunata, oppure era effettivamente in grado di discernere tra le due diverse modalit√† di preparazione? Per risolvere questa questione, Fisher elabor√≤ la sua metodologia per il test dell‚Äôipotesi nulla. Utilizz√≤ un valore-\\(p\\) calcolato sulla base della probabilit√† dell‚Äôevento osservato, nonch√© di qualsiasi altro evento pi√π estremo che potrebbe verificarsi sotto l‚Äôipotesi nulla.\nTuttavia, √® stato fatto notare che l‚Äôapproccio di Fisher al test dell‚Äôipotesi nulla pu√≤ essere insufficiente e portare a conclusioni errate (Etz et al., 2018). Una delle questioni fondamentali riguarda la definizione di un evento ‚Äúpi√π estremo‚Äù rispetto a quello osservato.\nSupponiamo che lo scopo dell‚Äôesperimento casuale sia di determinare l‚Äôaccuratezza delle riposte della Dr.ssa Bristol in esattamente sei tentativi (e non di pi√π). In tale caso, con 5 risposte corrette, il valore-\\(p\\) √® pari a 0.109, che non √® statisticamente significativo. In questo scenario, secondo la logica di Fisher, non si dovrebbe respingere l‚Äôipotesi nulla che la Dr.¬†Bristol stesse semplicemente indovinando.\nSupponiamo ora che lo scopo dell‚Äôesperimento casuale sia di continuare a servire t√® fino a quando la Dr.ssa Bristol non abbia raggiunto cinque risposte corrette (un risultato che, per coincidenza, si √® verificato dopo sei tentativi). Se analizziamo i dati in questo secondo scenario, il valore-\\(p\\) diventa pari a 0.031, che √® statisticamente significativo. In quest‚Äôultimo caso, l‚Äôipotesi nulla verrebbe respinta.\nQuello che emerge √® che, nonostante i dati osservati nei due scenari siano identici, giungiamo a conclusioni opposte come conseguenza delle diverse modalit√† di campionamento impiegate. Questa variabilit√† √® problematica poich√© il valore-\\(p\\), e quindi la nostra valutazione delle capacit√† discriminative della Dr.ssa Bristol, dipendono non solo dai dati effettivamente raccolti, ma anche dal disegno sperimentale adottato. Questa constatazione mette in discussione la robustezza del test dell‚Äôipotesi nulla come strumento fondamentale per l‚Äôinferenza scientifica.\nPer illustrare il problema, svolgiamo i calcoli utilizzando le distribuzioni statistiche richieste per i due tipi di campionamento: la distribuzione binomiale e la distribuzione geometrica negativa.\n\n77.16.1 Distribuzione Binomiale\nLa distribuzione binomiale √® la distribuzione da utilizzare quando il numero di tentativi √® prefissato e conosciuto a priori. Nel contesto dell‚Äôesempio del t√®, assumiamo che siano state servite esattamente sei tazze. La formula per determinare la probabilit√† di registrare esattamente \\(k\\) successi in \\(n\\) tentativi √® la seguente:\n\\[\nP(X = k) = \\binom{n}{k} \\times p^k \\times (1-p)^{(n-k)}\n\\]\nQui, \\(\\binom{n}{k}\\) rappresenta il coefficiente binomiale, \\(p\\) √® la probabilit√† di un singolo successo (ossia di indovinare correttamente la preparazione del t√®), e \\((1-p)\\) √® la probabilit√† di un singolo fallimento.\nPer calcolare il valore-\\(p\\) in questo specifico contesto, dobbiamo sommare le probabilit√† di ottenere un risultato di 5 o pi√π estremo su un totale di 6 tentativi.\n\n# Parameters\nn_binomial &lt;- 6  # Number of fixed trials for the binomial distribution\nn_success &lt;- 5  # Desired number of successes\np &lt;- 0.5  # Probability of success\n\n# Calculate the p-value for the binomial distribution\np_value_binomial &lt;- 1 - pbinom(n_success - 1, size = n_binomial, prob = p)\n\np_value_binomial\n#&gt; [1] 0.1094\n\n\n77.16.2 Distribuzione Geometrica Negativa\nNel contesto dell‚Äôesperimento del t√®, quando il test continua fino al raggiungimento di un numero prefissato di successi (nel nostro caso, cinque identificazioni corrette), la distribuzione di riferimento appropriata √® la distribuzione geometrica negativa.\nLa distribuzione geometrica negativa modella il numero di fallimenti \\(k\\) che si verificano prima di ottenere un numero prefissato \\(r\\) di successi in una sequenza di prove indipendenti di Bernoulli, dove ogni prova ha probabilit√† di successo \\(p\\).\nLa probabilit√† di osservare esattamente \\(k\\) fallimenti prima di ottenere \\(r\\) successi √® data da:\n\\[\nP(X = k) = \\binom{k+r-1}{k} p^r (1-p)^k,\n\\]\ndove:\n\n\n\\(k\\) √® il numero di fallimenti,\n\n\\(r\\) √® il numero di successi desiderato,\n\n\\(p\\) √® la probabilit√† di successo in ogni prova,\n\n\\(\\binom{k+r-1}{k}\\) √® il coefficiente binomiale che rappresenta il numero di modi possibili in cui \\(k\\) fallimenti e \\(r\\) successi possono essere ordinati.\n\nNel nostro caso specifico:\n\n\n\\(r = 5\\) (successi desiderati),\n\n\\(p = 0.5\\) (probabilit√† di indovinare correttamente sotto l‚Äôipotesi nulla),\n\n\\(k\\) varia da 0 a 1 (possibili fallimenti prima del quinto successo).\n\nIl valore-p si calcola sommando le probabilit√† per tutti i casi ‚Äúpi√π estremi‚Äù di quello osservato:\n\\[\n\\text{valore-p} = \\sum_{k=0}^{1} \\binom{k+5-1}{k} (0.5)^5 (0.5)^k.\n\\]\nImplementazione:\n\n# Parameters\nn_binomial &lt;- 6  # Number of fixed trials for the binomial distribution\nn_success &lt;- 5  # Desired number of successes\np &lt;- 0.5  # Probability of success (guessing the tea cup)\n\n# Calculate the p-value for the negative binomial distribution\np_value_geom_corrected &lt;- 0\nfor (k in 0:(n_binomial - n_success - 1)) {  # Number of failures before the 5th success\n  p_value_geom_corrected &lt;- p_value_geom_corrected + \n    choose(k + n_success - 1, k) * ((1 - p)^k) * (p^n_success)\n}\n\np_value_geom_corrected\n#&gt; [1] 0.03125\n\nIn conclusione,\n\nper la distribuzione binomiale, il p-value √® \\(0.109\\), che non √® statisticamente significativo (dato che √® maggiore di 0.05); quindi, secondo Fisher, in questo caso non dovremmo rigettare l‚Äôipotesi nulla che Dr.¬†Bristol stia indovinando.\nper la distribuzione geometrica negativa, il p-value √® \\(0.031\\), che √® statisticamente significativo (dato che √® minore di 0.05); in questo caso, dovremmo rigettare l‚Äôipotesi nulla, suggerendo che Dr.¬†Bristol non sta semplicemente indovinando.\n\nLa presente discussione mostra che, in base alla procedura del test dell‚Äôipotesi nulla, la stessa sequenza di eventi (5 successi su 6 tentativi) pu√≤ portare a conclusioni opposte a seconda delle ipotesi sul processo di campionamento. Questo paradosso √® uno dei motivi (per ulteriori critiche, si veda Wasserstein & Lazar (2016); Benjamin et al. (2018)) per cui l‚Äôinferenza bayesiana √® diventata pi√π popolare negli ultimi anni come quadro alternativo per il test delle ipotesi e la stima dei parametri.\n\n77.16.3 Approccio Bayesiano\nNel loro lavoro, Etz et al. (2018) propongono un‚Äôalternativa bayesiana per risolvere il problema esaminato da Fisher. Questa soluzione bayesiana evita le contraddizioni che emergono quando si cercano di definire ‚Äúrisultati pi√π estremi‚Äù che non sono stati osservati. L‚Äôapproccio bayesiano si focalizza esclusivamente sui dati effettivamente raccolti e utilizza queste osservazioni per aggiornare le probabilit√† iniziali (o ‚Äúa priori‚Äù) associate a diverse ipotesi. Il processo si basa sulla regola di Bayes e si sviluppa in tre fasi principali:\n\nStabilire Probabilit√† a Priori: Iniziamo assegnando una distribuzione di probabilit√† a priori a tutti i possibili tassi di successo che la Dr.¬†Bristol potrebbe avere. Questo include una probabilit√† specifica per l‚Äôipotesi nulla, che suggerisce che la Dr.¬†Bristol stia semplicemente indovinando (con un tasso di successo del 50%).\nAggiornare le Probabilit√† con Dati Osservati: Utilizziamo i dati raccolti nell‚Äôesperimento per aggiornare le nostre probabilit√† a priori. Questo aggiornamento √® fatto utilizzando la regola di Bayes.\nCalcolare il Fattore di Bayes: Questa metrica ci dice quanto i dati osservati influenzano le probabilit√† delle diverse ipotesi. Un Fattore di Bayes molto maggiore di 1 indicherebbe un forte supporto per l‚Äôipotesi alternativa rispetto all‚Äôipotesi nulla.\n\nNel caso specifico, il Fattore di Bayes calcolato √® risultato essere circa 147.33, un valore notevolmente alto. Questo suggerisce che i dati osservati sono molto pi√π compatibili con l‚Äôipotesi che la Dr.ssa Bristol possa effettivamente distinguere tra le diverse preparazioni del t√®, piuttosto che con l‚Äôipotesi che stia indovinando.\nEtz et al. (2018) concludono che l‚Äôapproccio bayesiano offre un quadro pi√π robusto e coerente per il test delle ipotesi. A differenza del metodo frequentista, esso non dipende dalla definizione di ‚Äúrisultati pi√π estremi‚Äù non osservati e si concentra invece esclusivamente sui dati effettivamente raccolti. Questa focalizzazione, in generale, rende l‚Äôapproccio bayesiano una soluzione pi√π solida per valutare le ipotesi scientifiche. Per una rivisitazione bayesiana dell‚Äôesperimento ‚ÄúThe Lady Tasting Tea‚Äù, si veda anche la discussione di Doorn et al. (2020).",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>77</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#malintesi-sul-valore-p",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#malintesi-sul-valore-p",
    "title": "\n77¬† Significativit√† statistica\n",
    "section": "\n77.17 Malintesi sul valore-p",
    "text": "77.17 Malintesi sul valore-p\nSono diffusi molti malintesi sul valore-p.¬†Ne esaminiamo qui quelli pi√π comuni.\nMalinteso 1: Un valore p non significativo significa che l‚Äôipotesi nulla √® vera.\nIl malinteso che un valore p non significativo (p &gt; 0.05) implichi l‚Äôassenza di effetto o la verit√† dell‚Äôipotesi nulla √® diffuso e porta a conclusioni errate. La chiave per evitare questo errore sta nel comprendere che i valori p riflettono la probabilit√† dei dati osservati sotto l‚Äôipotesi nulla, e non la probabilit√† dell‚Äôipotesi stessa. Un valore p elevato non dimostra che l‚Äôipotesi nulla sia vera, ma indica semplicemente che i dati osservati non sono sufficientemente insoliti da rifiutare l‚Äôipotesi nulla con un livello di confidenza predefinito.\nRisultati non significativi possono verificarsi anche quando esiste un effetto reale, ma i dati non sono abbastanza estremi da superare la soglia di significativit√† statistica.\nInvece di concludere affrettatamente l‚Äôassenza di effetto da un valore p non significativo, dovremmo riconoscere l‚Äôambiguit√† e considerare altre possibilit√†. Dichiarazioni come ‚Äúnon c‚Äôera differenza‚Äù dovrebbero essere riformulate in termini di assenza di differenza statisticamente significativa, lasciando aperta la questione dell‚Äôesistenza di un effetto reale.\nL‚Äôapproccio bayesiano offre una prospettiva diversa che pu√≤ essere particolarmente utile per interpretare risultati non significativi. A differenza dei valori p, che si limitano a valutare la probabilit√† dei dati sotto l‚Äôipotesi nulla, l‚Äôinferenza bayesiana permette di calcolare direttamente la probabilit√† delle ipotesi date i dati.\nL‚Äôapproccio bayesiano, quindi, non si limita a rifiutare o non rifiutare l‚Äôipotesi nulla, ma quantifica la forza dell‚Äôevidenza a favore di un‚Äôipotesi rispetto all‚Äôaltra, fornendo una conclusione pi√π informativa rispetto al semplice ‚Äúnon posso rifiutare l‚Äôipotesi nulla‚Äù.\nMalintesto 2: Un valore p significativo significa che l‚Äôipotesi nulla √® falsa.\nCome spiegato in precedenza, il valore-p quantifica la ‚Äúsorpresa‚Äù suscitata dai dati, alla luce dell‚Äôipotesi nulla. Non ci dice niente sull‚Äôipotesi che abbiamo assunto per quantificare la ‚Äúsorpresa‚Äù.\nMalinteso 3: Un valore p significativo significa che √® stato scoperto un effetto importante.\nLa distinzione tra ‚Äúsignificativit√† statistica‚Äù e ‚Äúrilevanza pratica‚Äù √® fondamentale: mentre la prima indica semplicemente che un risultato √® improbabile sotto l‚Äôipotesi nulla, la seconda valuta l‚Äôeffetto nel contesto di applicazioni reali e le sue implicazioni.\nUn effetto statisticamente significativo non garantisce che l‚Äôeffetto abbia un impatto pratico notevole o utile.\nInoltre, al di l√† della significativit√† pratica, l‚Äôabitudine di molti psicologi di escludere i predittori che non risultano ‚Äústatisticamente significativi‚Äù √® un grossolano errore: la significativit√† statistica non pu√≤ essere usata come un metodo per la selezione di variabili in un modello statistico.\nUn p &lt; 0.05 indica che, se l‚Äôipotesi nulla √® vera, abbiamo osservato dati che dovrebbero essere considerati sorprendenti. Tuttavia, solo perch√© i dati sono sorprendenti, non significa che dobbiamo preoccuparcene. √à principalmente l‚Äôetichetta verbale ‚Äúsignificativo‚Äù che causa confusione qui: in un contesto frequentista, un effetto ‚Äúsignificativo‚Äù √® un effetto ‚Äúsorprendente‚Äù alla luce di \\(H_0\\), non √® necessariamente un effetto ‚Äúimportante‚Äù.\nMalinteso 4: Se avete osservato un risultato significativo, la probabilit√† che abbiate commesso un errore di Tipo 1 (un falso positivo) √® del 5%.\nIl malinteso che la presenza di un risultato significativo (per esempio, p &lt; 0.05) indichi una probabilit√† del 5% di aver commesso un errore di Tipo 1 (falso positivo) riflette una comprensione errata della statistica frequentista. La probabilit√† del 5% si riferisce al tasso di errore di Tipo 1, che √® la proporzione di volte che potremmo aspettarci di rifiutare erroneamente l‚Äôipotesi nulla se questa fosse vera, su molteplici ripetizioni dell‚Äôesperimento sotto le stesse condizioni. In altre parole, se potessimo ripetere lo stesso studio infinite volte, osserveremmo risultati falsamente positivi nel 5% di questi studi, assumendo che l‚Äôipotesi nulla sia effettivamente vera in ogni caso.\nTuttavia, una volta che abbiamo raccolto i dati e ottenuto un risultato significativo in un unico studio, non possiamo dire che ‚Äúla probabilit√† che questo particolare risultato sia un errore di Tipo 1 √® del 5%‚Äù. In realt√†, in quel momento specifico, l‚Äôevento (commettere un errore di Tipo 1) √® gi√† accaduto o non √® accaduto; la probabilit√† associata a quel singolo risultato non √® pi√π applicabile nel modo in cui potremmo aspettarci intuitivamente. Il risultato √®, per cos√¨ dire, una realt√† fissa: o abbiamo rilevato un effetto che in realt√† non esiste (errore di Tipo 1), oppure abbiamo correttamente identificato un effetto reale. Senza ulteriori esperimenti o dati, non possiamo determinare con certezza in quale di queste categorie cade il nostro risultato.\nIn breve, il tasso del 5% di errore di Tipo 1 non si applica retroattivamente a un singolo risultato ottenuto, ma piuttosto descrive il comportamento a lungo termine di un test statistico sotto ripetute campionature. Questa distinzione √® cruciale per una corretta interpretazione dei risultati degli esperimenti e sottolinea l‚Äôimportanza di non sovrastimare la certezza di un singolo risultato statistico significativo.\nMalinteso 5: Uno meno il valore p √® la probabilit√† che l‚Äôeffetto si replichi quando ripetuto.\nIl concetto che 1 meno il valore p rappresenti la probabilit√† di replicazione di un effetto √® un malinteso diffuso. In realt√†, la probabilit√† di replicazione di un effetto non pu√≤ essere direttamente calcolata dal valore p di un singolo studio a causa della complessit√† dei fattori coinvolti, tra cui la vera differenza media tra i gruppi. La potenza statistica di un test, che dipende dalla dimensione dell‚Äôeffetto, dalla dimensione del campione e dal livello di significativit√† Œ±, fornisce una stima della probabilit√† di rilevare un effetto significativo se questo effetto esiste davvero. Tuttavia, osservare un effetto significativo in un unico studio (ad esempio, p = 0.03) non significa che vi sia una probabilit√† del 97% che tale effetto si replichi in studi futuri. La possibilit√† di replicare un risultato dipende dalla presenza di un vero effetto e dalla potenza statistica del test originale.\nIn sintesi, la replicabilit√† di un effetto √® influenzata da molti fattori e non pu√≤ essere inferita semplicemente dal valore p di un singolo risultato. La comprensione e l‚Äôinterpretazione corrette della replicabilit√† richiedono un‚Äôanalisi dettagliata della potenza statistica e della dimensione dell‚Äôeffetto, oltre che della consistenza dei risultati attraverso studi multipli.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>77</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#riflessioni-conclusive",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#riflessioni-conclusive",
    "title": "\n77¬† Significativit√† statistica\n",
    "section": "\n77.18 Riflessioni Conclusive",
    "text": "77.18 Riflessioni Conclusive\nIl presente capitolo ha messo in evidenza le numerose limitazioni e i potenziali pericoli dell‚Äôapproccio frequentista al test dell‚Äôipotesi nulla, portando alla luce una serie di paradossi e malintesi che minano la sua validit√† come strumento primario per l‚Äôinferenza scientifica. In particolare, abbiamo visto come il valore-p, spesso utilizzato come metro di giudizio assoluto per decidere se un risultato √® significativo o meno, possa condurre a conclusioni fuorvianti, dipendendo non solo dai dati osservati ma anche dal contesto sperimentale e dalle scelte soggettive del ricercatore. Questo approccio, che si basa su una logica binaria di ‚Äúaccettare‚Äù o ‚Äúrifiutare‚Äù l‚Äôipotesi nulla, sembra incapace di cogliere la complessit√† delle relazioni causali e degli effetti reali presenti nei fenomeni psicologici e sociali. Pi√π profondamente, emerge con chiarezza che il metodo frequentista, lungi dall‚Äôessere un sistema oggettivo per la decisione statistica, √® invece intriso di convenzioni arbitrarie (come il livello di significativit√† Œ± = 0.05) e di una visione riduzionistica della probabilit√†, concepita come frequenza relativa di eventi ripetibili nel tempo piuttosto che come misura della nostra incertezza riguardo a un evento specifico.\nTuttavia, al di l√† delle critiche tecniche, il problema pi√π grave risiede nella tendenza a considerare il test dell‚Äôipotesi nulla come uno strumento definitivo per valutare la veridicit√† di ipotesi scientifiche, anzich√© come un semplice punto di partenza per ulteriori indagini. La cultura prevalente nella comunit√† scientifica, che premia i risultati ‚Äústatisticamente significativi‚Äù, ha contribuito a creare un ambiente in cui gli studi replicabili sono rari e dove molti risultati pubblicati sono fragili e difficilmente generalizzabili. √à qui che l‚Äôapproccio bayesiano entra in gioco, offrendo una soluzione coerente e robusta che supera molte delle carenze del frequentismo. Al contrario del metodo frequentista, che si concentra su ipotesi nulle arbitrariamente definite e sulle distribuzioni campionarie di statistiche teoriche, il bayesianesimo ci permette di incorporare informazioni pregresse (prior) e di aggiornare queste conoscenze in base ai dati osservati, fornendo una stima diretta della probabilit√† delle ipotesi di interesse. Questo approccio, che mette al centro la nozione di evidenza, permette di quantificare la forza delle prove a favore di diverse ipotesi, evitando cos√¨ le dicotomie rigide tra ‚Äúsignificativo‚Äù e ‚Äúnon significativo‚Äù e promuovendo una visione pi√π sfumata e matematicamente fondata dell‚Äôinferenza statistica.\nIn conclusione, il test dell‚Äôipotesi nulla frequentista, pur essendo ampiamente utilizzato, rappresenta uno degli aspetti pi√π controversi e problematici dell‚Äôapproccio tradizionale. La sua rigidit√† metodologica e la dipendenza da concetti come il valore p e la significativit√† statistica lo rendono non solo impreciso, ma anche inadeguato a cogliere la complessit√† dei fenomeni che la ricerca psicologica si propone di esplorare. Abbandonare questo paradigma non √® solo una questione di precisione tecnica, ma di superare una mentalit√† riduzionista che limita la nostra capacit√† di interpretare i dati in modo sfumato e contestuale.\nL‚Äôadozione di metodologie bayesiane, al contrario, offre un quadro pi√π dinamico e flessibile, in cui le ipotesi non sono semplicemente accettate o rifiutate, ma valutate in termini probabilistici. Questo approccio incoraggia un confronto diretto tra modelli e ipotesi contrapposte, permettendo di aggiornare le nostre credenze alla luce dei nuovi dati. Non si tratta solo di un miglioramento tecnico nelle inferenze scientifiche, ma di un invito a ripensare il modo in cui concepiamo la conoscenza e il processo di scoperta. La prospettiva bayesiana, infatti, enfatizza l‚Äôincertezza come parte intrinseca della ricerca, trasformandola in uno strumento per affinare le nostre comprensioni piuttosto che un ostacolo da superare.\nIn un contesto psicologico intrinsecamente complesso e caratterizzato da incertezza, l‚Äôapproccio bayesiano rappresenta un‚Äôopportunit√† per adottare un‚Äôepistemologia pi√π flessibile e razionale. La sua forza risiede nella capacit√† di adattarsi alla natura multifattoriale dei fenomeni psicologici, integrando in modo coerente e trasparente sia le conoscenze pregresse sia le nuove evidenze. In questo senso, l‚Äôadozione del paradigma bayesiano non √® soltanto un avanzamento metodologico, ma anche un passo verso una scienza pi√π consapevole, critica e adatta alle sfide della psicologia contemporanea.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>77</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#esercizi",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#esercizi",
    "title": "\n77¬† Significativit√† statistica\n",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\n\nL‚ÄôIdea di Base del Test di Ipotesi\n\nSpiega il principio generale del test di ipotesi nulla in ambito frequentista. In che modo la logica dell‚Äô‚Äúassumere come vera l‚Äôipotesi nulla fino a prova contraria‚Äù √® paragonabile al concetto di ‚Äúpresunzione di innocenza‚Äù in un processo penale? Quali vantaggi e svantaggi comporta questa impostazione?\n\nIpotesi di Ricerca vs.¬†Ipotesi Statistica\n\nSpiega in che modo l‚Äôipotesi di ricerca (ad esempio, ‚Äúesiste un effetto della musica sul comportamento dei bambini‚Äù) differisce dall‚Äôipotesi statistica che si testa formalmente (ad esempio, ‚Äúla media di un indice di preferenza √® maggiore di 0.5‚Äù). Perch√© spesso la ricerca psicologica non pu√≤ testare direttamente l‚Äôipotesi di ricerca?\n\nSignificativit√† Statistica e Rilevanza Pratica\n\nChe differenza c‚Äô√® tra ‚Äúrisultato statisticamente significativo‚Äù e ‚Äúrisultato rilevante (o importante) dal punto di vista pratico o teorico‚Äù? Porta un esempio in cui un test frequenzista possa dare un valore-\\(p\\) molto basso senza che l‚Äôeffetto sia considerato rilevante nel contesto.\n\nMalinteso: Un Risultato non Significativo Implica Che \\(H_0\\) Sia Vera?\n\nPerch√© √® errato concludere che l‚Äôipotesi nulla sia vera quando il test non risulta significativo (cio√® quando \\(p \\ge 0.05\\))? Quali altre spiegazioni potrebbero esserci se un esperimento produce un valore-\\(p\\) alto?\n\nIl Ruolo della Variabilit√† Campionaria\n\nIn che modo la variabilit√† campionaria (cio√® il fatto che stime come la media campionaria varino da campione a campione) influisce sulla necessit√† di un test di ipotesi? Perch√© non √® sufficiente confrontare la media osservata con il valore ipotizzato per concludere se \\(H_0\\) √® falsa?\n\nErrori di I e II Tipo e Potenza del Test\n\nDescrivi i concetti di errore di I tipo (falso positivo) e errore di II tipo (falso negativo). Perch√© i test sono progettati primariamente per controllare l‚Äôerrore di I tipo? Che cos‚Äô√® la potenza (\\(1-\\beta\\)) di un test?\n\nIl Valore-\\(p\\): Che Cosa (non) Indica?\n\nSpiega la definizione di valore-\\(p\\) secondo l‚Äôapproccio frequentista. Quali sono due malintesi comuni su ci√≤ che il valore-\\(p\\) non rappresenta?\n\nCritica: Dipendenza dai ‚ÄúRisultati pi√π Estremi Non Osservati‚Äù\n\nNell‚Äôesempio dell‚Äôepisodio ‚ÄúThe Lady Tasting Tea‚Äù, come mai il test di ipotesi frequentista pu√≤ portare a conclusioni diverse pur avendo gli stessi dati osservati, a seconda di come √® definito il ‚Äúprocesso di campionamento‚Äù? Perch√© questa √® una limitazione?\n\nControllo dell‚ÄôErrore di I Tipo, ma Non dell‚ÄôErrore di II Tipo\n\nPerch√© nel test di ipotesi frequentista esiste un‚Äôasimmetria per cui si controlla rigorosamente l‚Äôerrore di I tipo (fissando \\(\\alpha\\)), ma non esiste un analogo vincolo obbligatorio sull‚Äôerrore di II tipo (\\(\\beta\\))? Quali conseguenze pratiche ne derivano per la pianificazione di uno studio?\n\nLimiti dell‚ÄôApproccio Frequentista e Alternative\n\nRiassumi in che senso il test di ipotesi nulla frequentista √® ritenuto da alcuni ricercatori insufficiente o fuorviante (es. ‚Äúdichotomania‚Äù del significato, p-value dipendente dal disegno, ecc.). Quali alternative o integrazioni sono state proposte in letteratura per superare questi limiti?\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\n\nL‚ÄôIdea di Base del Test di Ipotesi\n\n\nL‚Äôipotesi nulla (\\(H_0\\)) √® considerata ‚Äúinnocente‚Äù fino a che l‚Äôevidenza non la ‚Äúcondanna‚Äù.\n\nIl test statistico stabilisce la probabilit√† di osservare dati cos√¨ (o pi√π) estremi assumendo che \\(H_0\\) sia vera.\n\nVantaggio: stabilire un controllo sul rischio di un falso positivo (errore di I tipo).\n\nSvantaggio: non si dimostra direttamente l‚Äôipotesi di ricerca (\\(H_1\\)), ma si prova a ‚Äúfalsificare‚Äù \\(H_0\\).\n\n\nIpotesi di Ricerca vs.¬†Ipotesi Statistica\n\n\nL‚Äôipotesi statistica √® una versione quantificabile (e falsificabile) dell‚Äôipotesi di ricerca.\n\nLe ipotesi di ricerca in psicologia sono spesso complesse (costrutti non sempre direttamente misurabili).\n\nI ricercatori formulano un modello statistico semplificato per rendere l‚Äôipotesi testabile.\n\n\nSignificativit√† Statistica e Rilevanza Pratica\n\n\n‚ÄúSignificativo‚Äù in senso frequentista significa ‚Äúdati improbabili se \\(H_0\\) √® vera‚Äù.\n\nNon implica necessariamente un effetto ampio o di importanza pratica.\n\nCon campioni molto grandi, si possono rilevare anche differenze piccolissime, magari prive di valore applicativo.\n\n\nMalinteso: Un Risultato non Significativo Implica Che \\(H_0\\) Sia Vera?\n\n\nUn valore-\\(p\\) ‚Äúalto‚Äù segnala che i dati non forniscono sufficiente evidenza per rifiutare \\(H_0\\), non che \\(H_0\\) √® vera.\n\nPossibile mancanza di potenza statistica (campione troppo piccolo) o presenza di effetti molto ridotti.\n\nL‚Äôapproccio frequentista non quantifica la probabilit√† che \\(H_0\\) sia vera, ma la probabilit√† di osservare certi dati assumendo che \\(H_0\\) lo sia.\n\n\nIl Ruolo della Variabilit√† Campionaria\n\n\nAnche se la media campionaria si discosta da \\(H_0\\), potremmo aver ottenuto quella differenza per puro caso.\n\nOccorre stabilire quanto discostamento sia ‚Äúraro‚Äù secondo la distribuzione campionaria ipotizzata da \\(H_0\\).\n\nIl test calcola quante volte, nel lungo periodo, si osservano dati cos√¨ estremi casualmente.\n\n\nErrori di I e II Tipo e Potenza del Test\n\n\nErrore di I tipo: rigettare \\(H_0\\) quando √® vera.\n\nErrore di II tipo: non rigettare \\(H_0\\) quando √® falsa.\n\nIl test frequenzista fissa una soglia \\(\\alpha\\) (livello di significativit√†) per controllare l‚Äôerrore di I tipo.\n\nLa potenza quantifica la probabilit√† di individuare realmente un effetto quando esso esiste.\n\n\nIl Valore-\\(p\\): Che Cosa (non) Indica?\n\n\nIl valore-\\(p\\) √® la probabilit√† di ottenere un risultato almeno cos√¨ estremo se \\(H_0\\) √® vera.\n\nMalinteso 1: pensare che indichi la probabilit√† che \\(H_0\\) sia vera o falsa.\n\nMalinteso 2: confondere ‚Äú\\(p &lt; 0.05\\) =&gt; probabilit√† 95% che l‚Äôeffetto sia vero‚Äù (non √® cos√¨!).\n\n\nCritica: Dipendenza dai ‚ÄúRisultati pi√π Estremi Non Osservati‚Äù\n\n\nIl valore-\\(p\\) frequenzista include la probabilit√† di osservare anche ‚Äúrisultati pi√π estremi‚Äù non avvenuti nell‚Äôesperimento.\n\nSe l‚Äôesperimento era ‚Äúfissare a priori 6 tazze‚Äù vs.¬†‚Äúcontinuare finch√© non ottiene 5 successi‚Äù, pu√≤ cambiare la distribuzione usata (binomiale vs.¬†geometrica negativa).\n\nQuesto mostra che il valore-\\(p\\) dipende dal contesto sperimentale, non solo dai dati effettivi.\n\n\nControllo dell‚ÄôErrore di I Tipo, ma Non dell‚ÄôErrore di II Tipo\n\n\nSi vuole evitare di ‚Äúcondannare‚Äù un‚Äôipotesi nulla ‚Äúinnocente‚Äù.\n\nL‚Äôerrore di II tipo spesso viene trascurato e pu√≤ essere molto alto se il campione √® piccolo.\n\nConseguenze: molti studi hanno potenza insufficiente; i ‚Äúfalsi negativi‚Äù rimangono frequenti.\n\n\nLimiti dell‚ÄôApproccio Frequentista e Alternative\n\n\nCritiche: inflazione di falsi positivi, dipendenza arbitraria da \\(\\alpha=0.05\\), scarsa attenzione alla dimensione dell‚Äôeffetto, interpretazioni errate del p-value.\n\nAlternative:\n\n\nApproccio bayesiano (fattori di Bayes, posteriori, credibilit√†).\n\n\nConfidence intervals ampliati da riflessioni su potenza e dimensione dell‚Äôeffetto.\n\n\nMisure dell‚Äôeffetto e analisi approfondite invece di un giudizio binario su ‚Äúp&lt;0.05‚Äù.\n\n\n\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nEsercizi ‚ÄúA Mano‚Äù\nQuesti esercizi si possono affrontare con le formule del test di ipotesi (z-test o t-test per la media, test di proporzioni, ecc.), senza ricorrere a software.\nEsercizio 1: One-sample t-test sulla SWLS\n\n\nHai un piccolo campione di \\(n=9\\) studenti, con punteggi SWLS (ipotetici) riportati di seguito:\n\\[\n21, \\ 18, \\ 26, \\ 20, \\ 23, \\ 16, \\ 22, \\ 19, \\ 25\n\\]\n\nSupponi che, in letteratura, la media teorica su popolazioni simili sia di circa \\(\\mu_0 = 20\\).\nIpotesi nulla \\((H_0)\\): la media del campione non differisce da 20 (cio√® \\(\\mu = 20\\)).Ipotesi alternativa \\((H_1)\\): la media del campione differisce da 20 (two-sided test).\n\nRichiesta:\n\nCalcola la media campionaria \\(\\bar{X}\\) e la deviazione standard campionaria \\(s\\).\n\nEsegui un t-test a mano (con formula \\(t = \\frac{\\bar{X} - \\mu_0}{s/\\sqrt{n}}\\)).\n\nStabilisci se, con \\(\\alpha=0.05\\) (test a due code), si rifiuta o meno \\(H_0\\).\n\n\nSuggerimento: Usa la tabella della distribuzione t (o ricorri a tavole semplificate) per trovare il valore critico a \\(df = n-1 = 8\\). Solo per questo step, usa R.\n\nEsercizio 22: One-sample t-test sulla LSNS-6\n\n\nHai un campione di \\(n=8\\) persone anziane, con punteggi LSNS-6 (Scala della Rete Sociale di Lubben) ipotetici (in realt√† userai i dati raccolti):\n\\[\n10,\\ 14,\\ 8,\\ 13,\\ 12,\\ 7,\\ 15,\\ 9\n\\]\n\nIn letteratura si suppone che un punteggio medio su popolazioni simili sia \\(\\mu_0 = 12\\).\nIpotesi nulla: \\(\\mu = 12\\).Ipotesi alternativa: \\(\\mu \\neq 12\\).\n\nRichiesta:\n\nCalcola media e deviazione standard.\n\nCalcola la statistica \\(t\\) e confrontala con il valore critico per \\(\\alpha=0.05\\), two-sided, con \\(df = 7\\).\n\nConcludi se rifiuti l‚Äôipotesi nulla o meno.\n\n\n\nEsercizio 3: Due campioni indipendenti (SWLS)\n\n\nConsidera i dati raccolti dal tuo gruppo e quelli di un altro gruppo TPV (es., Gruppo A = 6 persone, Gruppo B = 5 persone) che hanno compilato la SWLS. Riporta per ipotesi i seguenti punteggi medi e DS (usa i dati reali):\n\nGruppo A: \\(\\bar{X}_A = 24,\\ s_A=4,\\ n_A=6\\)\n\nGruppo B: \\(\\bar{X}_B = 19,\\ s_B=3,\\ n_B=5\\)\n\n\n\nVuoi testare se le due medie differiscono in modo significativo (\\(\\alpha=0.05\\), due code).\nIpotesi nulla: \\(\\mu_A = \\mu_B\\).Ipotesi alternativa: \\(\\mu_A \\neq \\mu_B\\).\n\nRichiesta:\n\nCalcola la statistica \\(t\\) di un two-sample t-test (varianze incognite, assunte uguali).\n\nUsa la formula con la ‚Äúvarianza pooled‚Äù.\n\nCalcola i \\(df\\) approssimati come \\(n_A + n_B - 2\\).\n\nConcludi se rifiuti \\(H_0\\).\n\n\n\nEsercizio 4: Test su una proporzione (SWLS recodificata)\n\nA volte si trasforma la SWLS in una variabile binaria es. ‚Äú\\(\\mathrm{SWLS} \\ge 24\\) = soddisfatto, \\(\\mathrm{SWLS}&lt;24\\) = non soddisfatto‚Äù.\nConsidera i dati raccolti e i corrispondenti risultati binari (S√¨/No) siano 4 ‚Äúsoddisfatti‚Äù e 6 ‚Äúnon soddisfatti‚Äù.\nIpotesi nulla: la proporzione di ‚Äúsoddisfatti‚Äù √® \\(p_0 = 0.50\\) (ipotizzi che met√† dei partecipanti sia soddisfatta).Ipotesi alternativa: la proporzione \\(\\neq 0.50\\).\nCalcola la statistica \\(Z\\) per una proporzione (usando la formula della normal approx. se \\(\\hat{p}=4/10\\)).\nConfronta \\(|Z|\\) con il valore critico a \\(\\alpha=0.05\\) (due code), \\(z_{0.025}\\approx 1.96\\). Concludi.\n\nEsercizio 5: Confronto fra due proporzioni (LSNS-6 recodificata)\n\nConsiderai dati di due gruppi TPV (Gruppo A, Gruppo B).\n\nSupponi che, per Gruppo A (\\(n_A=8\\)), 3 persone abbiano un punteggio \\(\\ge 12\\) (considerato ‚Äúbuon supporto‚Äù). Per Gruppo B (\\(n_B=10\\)), 7 persone siano \\(\\ge 12\\) ‚Äì usa i dati reali.\n\nIpotesi nulla: \\(\\,p_A = p_B\\).Ipotesi alternativa: \\(\\,p_A \\neq p_B\\).\n\nCalcola \\(\\hat{p}_A = 3/8\\) e \\(\\hat{p}_B = 7/10\\).\n\nFai il test per il confronto di due proporzioni (con la formula per la ‚Äúpooled proportion‚Äù). Decidi se c‚Äô√® differenza significativa al 5%.\n\nEsercizi ‚ÄúCon R‚Äù\nOra proponiamo 5 esercizi da svolgere con il software R. Naturalmente, dovrete caricare il vostro dataset reale (ad esempio in formato CSV o XLS) e adattare i comandi di R.\nEsercizio 1: Calcolo e t-test di una sola media per la SWLS\n\n\nCaricate in R i vostri dati SWLS in un vettore, es.:\nswls_data &lt;- c(...)  # I vostri punteggi\n\n\nStampate la media e la deviazione standard:\nmean(swls_data)\nsd(swls_data)\n\nTest se la media differisce da 24, usando t.test(swls_data, mu = 24).\nOsservate il p-value e concludete se rifiutate \\(H_0\\): \\(\\mu=24\\) vs \\(H_1\\): \\(\\mu \\neq 24\\).\n\nEsercizio 2: Calcolo e t-test di una sola media per la LSNS-6\n\n\nFate lo stesso per la LSNS:\nlsns_data &lt;- c(...)  # I vostri punteggi\n\nCalcolate mean(lsns_data), sd(lsns_data).\nEseguite un test con t.test(lsns_data, mu = X) dove \\(X\\) √® un valore teorico (ad es. 12 o 10, a seconda delle informazioni di letteratura).\nInterpretate l‚Äôoutput, guardando estimate, conf.int, p-value.\n\nEsercizio 3: Confronto di due medie (SWLS) con due gruppi\n\n\nConsiderate i dati di due gruppi TPV. Avete due vettori in R:\ngroupA &lt;- c(...)  # SWLS di chi appartiene al gruppo A\ngroupB &lt;- c(...)  # SWLS di chi appartiene al gruppo B\n\nCalcolate mean(groupA), mean(groupB).\n\nEseguite:\nt.test(groupA, groupB, var.equal = FALSE)  # Welch Two Sample t-test\n\nConfrontate la differenza delle medie riportata con l‚Äôintervallo di confidenza. Il p-value indica se la differenza √® significativa (ipotesi nulla: medie uguali).\n\nEsercizio 4: Test su una proporzione (ricodifica SWLS)\n\n\nRicodificate i vostri punteggi SWLS in ‚Äú1 = soddisfatto‚Äù / ‚Äú0 = non soddisfatto‚Äù. Ad esempio:\nsatisfied &lt;- ifelse(swls_data &gt;= 24, 1, 0)\n\n\nContate la proporzione di ‚Äú1‚Äù:\nmean(satisfied)\n\nEffettuate il test con prop.test(sum(satisfied), length(satisfied), p = 0.5) (se ipotizzate \\(p_0=0.5\\)).\nGuardate l‚Äôoutput e interpretate: l‚Äôintervallo di confidenza e il p-value.\n\nEsercizio 5: Confronto di due proporzioni (ricodifica LSNS)\n\n\nFate una ricodifica binaria sul vostro vettore LSNS, ad esempio ‚Äú1 se \\(\\ge12\\), 0 se &lt;12‚Äù:\ngood_support &lt;- ifelse(lsns_data &gt;= 12, 1, 0)\n\n\nSeparate i partecipanti in due gruppi (ad esempio, un gruppo ‚ÄúA‚Äù e un gruppo ‚ÄúB‚Äù):\ngroupA_inds &lt;- (some condition)  # righe che corrispondono a Gruppo A\ngroupB_inds &lt;- (some other condition)\n\nCalcolate sum(good_support[groupA_inds]), length(groupA_inds) e idem per groupB.\nUsate prop.test(x = c(...), n = c(...)) per confrontare le due proporzioni.\nConcludete: se p-value &lt; 0.05, potete rifiutare \\(H_0\\) (le due proporzioni sono uguali).\n\n\n\n\n\n\n\n\n\n\nProblemi 3\n\n\n\n\n\nEsercizio 1 ‚Äì P-value e Interpretazione Probabilistica\nSpiega perch√© il valore-\\(p\\) del test di ipotesi nulla (frequentista) non pu√≤ essere interpretato come ‚Äúprobabilit√† che l‚Äôipotesi nulla sia vera‚Äù e in che modo l‚Äôapproccio bayesiano fornisce invece una ‚Äúprobabilit√† a posteriori‚Äù sull‚Äôipotesi. Descrivi due possibili conseguenze pratiche di questa differenza di interpretazione.\nEsercizio 2 ‚Äì Ruolo dei ‚ÄúRisultati pi√π Estremi Non Osservati‚Äù\nNel test frequentista, il valore-\\(p\\) si basa anche sulla probabilit√† di risultati pi√π estremi di quelli effettivamente osservati, ma che non si sono verificati. Perch√© questo √® considerato un limite (o un paradosso) e in che modo un‚Äôanalisi bayesiana eviterebbe (o ridurrebbe) questo problema?\nEsercizio 3 ‚Äì Dipendenza dal Disegno Sperimentale e Optional Stopping\nNel test di ipotesi frequenzista, il valore-\\(p\\) pu√≤ cambiare se il ricercatore modifica il piano di raccolta dati (ad es. fermare la raccolta quando si ottiene un certo risultato). Perch√© si parla di ‚Äúproblema dell‚Äôoptional stopping‚Äù? Come gestisce invece l‚Äôapproccio bayesiano la decisione di proseguire o fermare un esperimento sulla base dei dati via via raccolti?\nEsercizio 4 ‚Äì Significativit√† Statistica vs.¬†Dimensione dell‚ÄôEffetto\nUno dei limiti dell‚Äôapproccio frequentista √® la confusione tra ‚Äúsignificativit√† statistica‚Äù (p&lt;0.05) e ‚Äúimportanza/ampiezza dell‚Äôeffetto‚Äù. Spiega in che modo l‚Äôapproccio bayesiano pu√≤ incorporare in modo pi√π diretto la dimensione dell‚Äôeffetto e l‚Äôincertezza a riguardo (tramite le ‚Äúdistribuzioni a posteriori‚Äù o ‚Äúintervalli di credibilit√†‚Äù).\nEsercizio 5 ‚Äì Problemi di Replicabilit√†: Come Confrontare Modelli?\nSi osserva spesso che i risultati frequentisti (p&lt;0.05) non si replicano bene in studi successivi. Descrivi come un‚Äôanalisi bayesiana (con i ‚Äúfattori di Bayes‚Äù o i ‚Äúposterior odds‚Äù) possa dare un quadro pi√π flessibile per confrontare ipotesi alternative, riducendo il rischio di eccessive conclusioni basate su un singolo p-value.\n\n\n\n\n\n\n\n\n\nSoluzioni 3\n\n\n\n\n\nSoluzione 1 ‚Äì P-value e Probabilit√† dell‚ÄôIpotesi\n\n\nPunto chiave: Il valore-\\(p\\) √® la probabilit√† di ottenere dati ‚Äúuguali o pi√π estremi‚Äù dando per vera l‚Äôipotesi nulla. Invece, ‚Äúprobabilit√† che \\(H_0\\) sia vera‚Äù sarebbe un concetto diverso: √® la probabilit√† dell‚Äôipotesi data i dati osservati (interpretazione inversa).\n\n\nConseguenze pratiche:\n\nUn p-value ‚Äúbasso‚Äù non dice ‚Äúquanto √® probabile che \\(H_0\\) sia falsa‚Äù, ma solo che quei dati sarebbero rari sotto \\(H_0\\).\n\nI ricercatori spesso sovrastimano la ‚Äúconferma‚Äù contro \\(H_0\\) o interpretano male un p&gt;0.05 come ‚Äúipotesi nulla vera‚Äù.\n\n\n\n\nApproccio bayesiano: Consente di calcolare una posterior probability di \\(H_0\\) (o di \\(H_1\\)) grazie alla regola di Bayes, purch√© si disponga di una prior e di un modello.\n\nSoluzione 2 ‚Äì Risultati pi√π Estremi Non Osservati\n\n\nProblema: Nel frequentismo, il valore-\\(p\\) integra la probabilit√† di dati che non si sono verificati (‚Äúwhat if scenario‚Äù). Ci√≤ porta a dipendere da un insieme di risultati ipotetici e a potenziali paradossi (e.g.¬†‚ÄúLady Tasting Tea‚Äù).\n\n\nLimite: Pu√≤ capitare che stessi dati osservati, ma piani di raccolta diversi, generino p-value diversi.\n\n\nBayesian: Calcola la verosimiglianza solo sui dati effettivi e aggiorna la prior ‚Üí ‚Äúfocus su ci√≤ che √® effettivamente avvenuto‚Äù. Non serve considerare a posteriori ‚Äúrisultati pi√π estremi‚Äù che non si sono verificati, se non in misura minima (attraverso l‚Äôintegrazione sulle possibili distribuzioni posteriori, ma con un meccanismo diverso dal p-value).\n\nSoluzione 3 ‚Äì Optional Stopping e Disegno Sperimentale\n\n\nOptional Stopping: In un test frequentista, se continuiamo ad analizzare i dati e fermiamo la raccolta non appena otteniamo p&lt;0.05, si gonfia il rischio di errore di I tipo.\n\n\nLimite: Il p-value frequentista dipende dall‚Äôidea di un ‚Äúprotocollo fisso‚Äù a priori. Se si viola questo piano (aggiungendo dati finch√© non si ottiene ‚Äúsignificativit√†‚Äù), il test non √® pi√π valido.\n\n\nBayesiano: L‚Äôapproccio consente un monitoraggio sequenziale (monitoring) dei dati: si aggiorna la distribuzione a posteriori man mano che arrivano nuove osservazioni, e fermarsi quando la posterior probability (o il fattore di Bayes) supera (o non supera) una certa soglia. Questo non invalida formalmente l‚Äôinferenza perch√© si sta accumulando evidenza in modo coerente con Bayes.\n\nSoluzione 4 ‚Äì Ampiezza dell‚ÄôEffetto e Intervalli di Credibilit√†\n\n\nFrequenza: Un p-value significativo non dice quanto √® grande l‚Äôeffetto, solo che non si spiega ‚Äúfacilmente‚Äù con \\(H_0=0\\).\n\n\nLimite: Spesso si confonde ‚Äúp&lt;0.05‚Äù con ‚Äúeffetto grande/impact significativo‚Äù: in realt√†, la dimensione potrebbe essere piccola.\n\n\nBayesiano: Offre una distribuzione a posteriori sull‚Äôeffetto (\\(\\theta\\)), da cui si pu√≤ ricavare un intervallo di credibilit√† (dove, ad esempio, c‚Äô√® il 95% di probabilit√† che \\(\\theta\\) si trovi in quell‚Äôintervallo). Consente di valutare se l‚Äôeffetto √® davvero grande o molto stretto attorno allo 0.\n\nSoluzione 5 ‚Äì Replicabilit√† e Confronto di Ipotesi\n\n\nProblema di replicabilit√†: Molti studi con p&lt;0.05 non vengono replicati (forse per effetti piccoli, scarsa potenza, pubblicazione selettiva, etc.).\n\n\nLimite: Un singolo p-value non d√† informazioni su ‚Äúquanto credere a \\(H_1\\) rispetto a \\(H_0\\)‚Äù e non aiuta a cumulare evidenze in analisi meta-analitiche in modo flessibile.\n\n\nBayesiano: Utilizza fattori di Bayes (Bayes Factor) o ‚Äúposterior odds‚Äù, confrontando due modelli (es. \\(H_0\\) vs \\(H_1\\)). Se i dati futuri confermano una delle ipotesi, la posterior si rafforza. √à un sistema pi√π graduale e cumulativo di aggiornamento della credenza, riducendo la tendenza a ‚Äúcollezionare p&lt;0.05‚Äù.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>77</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#informazioni-sullambiente-di-sviluppo",
    "title": "\n77¬† Significativit√† statistica\n",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.17.0      thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0\n#&gt;  [5] see_0.11.0       gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1\n#&gt;  [9] psych_2.5.3      scales_1.3.0     markdown_2.0     knitr_1.50      \n#&gt; [13] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [17] purrr_1.0.4      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [21] ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      shape_1.4.6.1     xfun_0.51         htmlwidgets_1.6.4\n#&gt;  [5] lattice_0.22-6    tzdb_0.5.0        Rdpack_2.6.3      vctrs_0.6.5      \n#&gt;  [9] tools_4.4.2       generics_0.1.3    parallel_4.4.2    pan_1.9          \n#&gt; [13] pacman_0.5.1      jomo_2.7-6        pkgconfig_2.0.3   Matrix_1.7-3     \n#&gt; [17] lifecycle_1.0.4   compiler_4.4.2    farver_2.1.2      munsell_0.5.1    \n#&gt; [21] mnormt_2.1.1      codetools_0.2-20  htmltools_0.5.8.1 glmnet_4.1-8     \n#&gt; [25] nloptr_2.2.1      pillar_1.10.1     MASS_7.3-65       reformulas_0.4.0 \n#&gt; [29] iterators_1.0.14  rpart_4.1.24      boot_1.3-31       mitml_0.4-5      \n#&gt; [33] foreach_1.5.2     nlme_3.1-167      tidyselect_1.2.1  digest_0.6.37    \n#&gt; [37] stringi_1.8.4     splines_4.4.2     rprojroot_2.0.4   fastmap_1.2.0    \n#&gt; [41] grid_4.4.2        colorspace_2.1-1  cli_3.6.4         magrittr_2.0.3   \n#&gt; [45] survival_3.8-3    broom_1.0.7       withr_3.0.2       backports_1.5.0  \n#&gt; [49] timechange_0.3.0  rmarkdown_2.29    nnet_7.3-20       lme4_1.1-36      \n#&gt; [53] hms_1.1.3         evaluate_1.0.3    rbibutils_2.3     rlang_1.1.5      \n#&gt; [57] Rcpp_1.0.14       glue_1.8.0        minqa_1.2.8       rstudioapi_0.17.1\n#&gt; [61] jsonlite_1.9.1    R6_2.6.1",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>77</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#bibliografia",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#bibliografia",
    "title": "\n77¬† Significativit√† statistica\n",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBenjamin, D. J., Berger, J. O., Johannesson, M., Nosek, B. A., Wagenmakers, E.-J., Berk, R., Bollen, K. A., Brembs, B., Brown, L., Camerer, C., et al. (2018). Redefine statistical significance. Nature Human Behaviour, 2(1), 6‚Äì10.\n\n\nDoorn, J. van, Matzke, D., & Wagenmakers, E.-J. (2020). An in-class demonstration of Bayesian inference. Psychology Learning & Teaching, 19(1), 36‚Äì45.\n\n\nEtz, A., Gronau, Q. F., Dablander, F., Edelsbrunner, P. A., & Baribault, B. (2018). How to become a Bayesian in eight easy steps: An annotated reading list. Psychonomic bulletin & review, 25(1), 219‚Äì234.\n\n\nMehr, S. A., Song, L. A., & Spelke, E. S. (2016). For 5-month-old infants, melodies are social. Psychological Science, 27(4), 486‚Äì501.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:\n\n\nWasserstein, R. L., & Lazar, N. A. (2016). The ASA‚Äôs statement on p-values: context, process, and purpose. The American Statistician, 70(2), 129‚Äì133.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>77</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html",
    "title": "\n78¬† Test t di Student per campioni indipendenti\n",
    "section": "",
    "text": "78.1 Introduzione\nQuesto capitolo √® dedicato al test t di Student per campioni indipendenti, uno dei test statistici pi√π utilizzati nella pratica frequentista. Il test t di Student √® un metodo che permette di confrontare le medie di due gruppi diversi (o ‚Äúcampioni‚Äù) e determinare se la differenza osservata tra le medie sia statisticamente significativa o se possa essere attribuita a semplice casualit√†.\nIl test √® particolarmente utile quando si ha accesso solo a piccoli campioni provenienti da popolazioni sconosciute, ma √® importante comprendere bene i suoi principi fondamentali e limiti prima di applicarlo.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>78</span>¬† <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html#applicazioni-del-test-t-di-student",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html#applicazioni-del-test-t-di-student",
    "title": "\n78¬† Test t di Student per campioni indipendenti\n",
    "section": "\n78.2 Applicazioni del Test t di Student",
    "text": "78.2 Applicazioni del Test t di Student\nIl test t di Student per campioni indipendenti serve per rispondere alla domanda: ‚ÄúLe medie di due gruppi sono significativamente diverse?‚Äù Per esempio, potremmo voler sapere se ci sono differenze significative nel peso medio tra uomini e donne.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>78</span>¬† <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html#assunzioni-principali",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html#assunzioni-principali",
    "title": "\n78¬† Test t di Student per campioni indipendenti\n",
    "section": "\n78.3 Assunzioni Principali",
    "text": "78.3 Assunzioni Principali\nPrima di procedere con il test, √® essenziale assicurarsi che siano valide le seguenti ipotesi:\n\n\nIndipendenza: Le osservazioni nei due campioni devono essere indipendenti.\n\nNormalit√†: I dati nei due campioni provengono da popolazioni distribuite normalmente.\n\nUguaglianza delle Varianze (Omoschedasticit√†): Le varianze delle due popolazioni da cui provengono i campioni sono uguali.\n\nSe queste condizioni non sono soddisfatte, potrebbe essere necessario considerare alternative come il test di Welch, che non richiede l‚Äôuguaglianza delle varianze.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>78</span>¬† <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html#passaggi-del-test-t-di-student",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html#passaggi-del-test-t-di-student",
    "title": "\n78¬† Test t di Student per campioni indipendenti\n",
    "section": "\n78.4 Passaggi del Test t di Student",
    "text": "78.4 Passaggi del Test t di Student\nEcco una panoramica dei passaggi chiave:\n\n\nCalcolare la Differenza tra le Medie: Si calcola la differenza tra le medie dei due campioni.\n\\[\n\\bar{x}_1 - \\bar{x}_2\n\\]\ndove \\(\\bar{x}_1\\) e \\(\\bar{x}_2\\) sono le medie dei due campioni.\n\n\nStimare la Deviazione Standard Combinata: Se assumiamo che le varianze siano uguali (omoschedasticit√†), possiamo usare una stima combinata della deviazione standard, chiamata deviazione standard pooled \\(s_p\\):\n\\[\ns_p = \\sqrt{\\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2}}\n\\]\ndove \\(n_1\\) e \\(n_2\\) sono le dimensioni dei campioni, e \\(s_1^2\\) e \\(s_2^2\\) sono le varianze campionarie.\n\n\nCalcolare la Statistica t: La statistica t viene calcolata usando la formula seguente:\n\\[\nt = \\frac{(\\bar{x}_1 - \\bar{x}_2)}{s_p \\sqrt{\\left(\\frac{1}{n_1} + \\frac{1}{n_2}\\right)}}\n\\]\n\n\nDeterminare i Gradi di Libert√†: I gradi di libert√† (\\(df\\)) sono calcolati come:\n\\[\ndf = n_1 + n_2 - 2\n\\]\n\nCalcolare il Valore-p: Infine, si confronta la statistica t con la distribuzione t di Student per ottenere il valore-p.¬†Questo valore indica la probabilit√† di osservare una differenza cos√¨ estrema tra le medie dei campioni, dato che l‚Äôipotesi nulla √® vera.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>78</span>¬† <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html#dimostrazione",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html#dimostrazione",
    "title": "\n78¬† Test t di Student per campioni indipendenti\n",
    "section": "\n78.5 Dimostrazione",
    "text": "78.5 Dimostrazione\nPer dimostrare come calcolare la varianza della differenza tra due medie campionarie, consideriamo due campioni casuali indipendenti \\(X_1, X_2, \\dots, X_n\\) e \\(Y_1, Y_2, \\dots, Y_m\\), estratti dalla stessa popolazione con media \\(\\mu\\) e varianza \\(\\sigma^2\\). Definiamo \\(\\bar{X}\\) e \\(\\bar{Y}\\) come le medie campionarie di questi due campioni, rispettivamente.\nLe medie campionarie \\(\\bar{X}\\) e \\(\\bar{Y}\\) sono date da:\n\\[\n\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i ,\n\\] \\[\n\\bar{Y} = \\frac{1}{m} \\sum_{j=1}^m Y_j .\n\\]\nEntrambe le medie campionarie \\(\\bar{X}\\) e \\(\\bar{Y}\\) sono stimatori non distorti della media della popolazione \\(\\mu\\). Le loro varianze sono:\n\\[\n\\text{Var}(\\bar{X}) = \\frac{\\sigma^2}{n} ,\n\\] \\[\n\\text{Var}(\\bar{Y}) = \\frac{\\sigma^2}{m} .\n\\]\nSiamo interessati a calcolare la varianza della differenza \\(\\bar{X} - \\bar{Y}\\). Utilizzando le propriet√† della varianza per combinazioni lineari di variabili aleatorie indipendenti, otteniamo:\n\\[\n\\text{Var}(\\bar{X} - \\bar{Y}) = \\text{Var}(\\bar{X}) + \\text{Var}(\\bar{Y}) ,\n\\]\ndato che i termini incrociati si annullano per l‚Äôindipendenza di \\(\\bar{X}\\) e \\(\\bar{Y}\\). Sostituendo le varianze di \\(\\bar{X}\\) e \\(\\bar{Y}\\), abbiamo:\n\\[\n\\text{Var}(\\bar{X} - \\bar{Y}) = \\frac{\\sigma^2}{n} + \\frac{\\sigma^2}{m} ,\n\\] \\[\n\\text{Var}(\\bar{X} - \\bar{Y}) = \\sigma^2 \\left(\\frac{1}{n} + \\frac{1}{m}\\right) .\n\\]\nQuindi, la varianza della differenza tra le due medie campionarie √® una combinazione delle varianze delle singole medie, ponderate in base alle dimensioni dei campioni corrispondenti.\nPer giungere alla formula del test \\(t\\) di Student per due campioni indipendenti, dobbiamo considerare l‚Äôincertezza aggiuntiva derivante dal fatto che non conosciamo \\(\\sigma\\). Il modo migliore per stimare \\(\\sigma\\) √® utilizzare le due deviazioni standard dei campioni, ponderate per i rispettivi gradi di libert√†, come indicato nella formula della deviazione standard pooled:\n\\[\ns_p = \\sqrt{\\frac{(n - 1)s^2_x + (m - 1)s^2_y}{n + m - 2}},\n\\]\ndove \\(s_x\\) e \\(s_y\\) sono le deviazioni standard dei due campioni, e \\(n\\) e \\(m\\) sono le numerosit√† dei due campioni.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>78</span>¬† <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html#esempio-pratico",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html#esempio-pratico",
    "title": "\n78¬† Test t di Student per campioni indipendenti\n",
    "section": "\n78.6 Esempio Pratico",
    "text": "78.6 Esempio Pratico\nSupponiamo di avere due campioni:\n\n\nDonne: Pesi = [38.9, 61.2, 73.3, 21.8, 63.4, 64.6, 48.4, 48.8, 48.5]\n\nUomini: Pesi = [67.8, 60, 63.4, 76, 89.4, 73.3, 67.3, 61.3, 62.4]\n\nCreiamo un DataFrame in R e calcoliamo la statistica t:\n\nwomen_weight &lt;- c(38.9, 61.2, 73.3, 21.8, 63.4, 64.6, 48.4, 48.8, 48.5)\nmen_weight &lt;- c(67.8, 60, 63.4, 76, 89.4, 73.3, 67.3, 61.3, 62.4)\n\nweight &lt;- c(women_weight, men_weight)\nis_female &lt;- rep(c(1, 0), each = 9)  # 1 = Femmina, 0 = Maschio\n\ndf &lt;- data.frame(is_female = is_female, weight = weight)\n\nPer calcolare manualmente la statistica t:\n\n# Estraiamo i pesi per ogni gruppo\nweight_f &lt;- df$weight[df$is_female == 1]\nweight_m &lt;- df$weight[df$is_female == 0]\n\n# Calcolo della deviazione standard pooled\ns_pool_num &lt;- ((length(weight_f) - 1) * var(weight_f)) + ((length(weight_m) - 1) * var(weight_m))\ns_pool_denom &lt;- length(weight_f) + length(weight_m) - 2\ns_pool &lt;- sqrt(s_pool_num / s_pool_denom)\n\n# Calcolo della statistica t\nt_num &lt;- mean(weight_f) - mean(weight_m)\nt_denom &lt;- s_pool * sqrt(1 / length(weight_f) + 1 / length(weight_m))\nT &lt;- t_num / t_denom\nT\n#&gt; [1] -2.784\n\n\n# Gradi di libert√†\ndf_degrees &lt;- length(weight_f) + length(weight_m) - 2\ndf_degrees\n#&gt; [1] 16\n\n\n# Calcolo del valore-p\np_value &lt;- 2 * pt(abs(T), df = df_degrees, lower.tail = FALSE)\nprint(p_value)\n#&gt; [1] 0.01327\n\nIn alternativa, possiamo usare la funzione t.test di R:\n\nres &lt;- t.test(weight_f, weight_m, var.equal = TRUE)\nprint(res, digits = 7)\n#&gt; \n#&gt;  Two Sample t-test\n#&gt; \n#&gt; data:  weight_f and weight_m\n#&gt; t = -2.7842, df = 16, p-value = 0.01327\n#&gt; alternative hypothesis: true difference in means is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  -29.748019  -4.029759\n#&gt; sample estimates:\n#&gt; mean of x mean of y \n#&gt;  52.10000  68.98889\n\n\n78.6.1 Interpretazione dei Risultati\nIl test t di Student ha generato un valore-p inferiore a 0.05, indicando che la differenza osservata tra i pesi medi delle donne e degli uomini √® statisticamente significativa. Questo significa che, con un livello di confidenza del 95%, possiamo rifiutare l‚Äôipotesi nulla secondo cui le medie dei due gruppi sono uguali.\n√à importante ricordare che un basso valore-p suggerisce che la differenza osservata non √® dovuta al caso. Tuttavia, ci√≤ non prova automaticamente una relazione causale; piuttosto, apre la strada ad ulteriori indagini sulle cause della differenza.\n\n78.6.2 Riportare i Risultati\nQuando si riportano i risultati di un test t, √® fondamentale adottare pratiche che favoriscano una comprensione approfondita e accurata dei dati. Di seguito viene presentato un confronto tra due versioni dei risultati: una da evitare, che si basa su un‚Äôinterpretazione tradizionale della significativit√† statistica, e una versione migliorata che enfatizza l‚Äôintervallo di confidenza e l‚Äôampiezza dell‚Äôeffetto.\n\n78.6.2.1 Versione da Evitare\nLa seguente formulazione segue un approccio tradizionale incentrato sulla ‚Äúsignificativit√† statistica,‚Äù che √® oggi ritenuto inadeguato per una comunicazione efficace dei risultati:\n\nAbbiamo condotto un test t di Student per confrontare le medie dei due gruppi. I risultati mostrano una differenza significativa tra i pesi medi delle donne e degli uomini (t(16) = -2.78, p-value = 0.01). L‚Äôintervallo di confidenza al 95% per la differenza delle medie √® [-29.75, -4.03]. L‚Äôampiezza dell‚Äôeffetto, misurata con Cohen‚Äôs d, √® 1.31, indicando un effetto grande. La potenza statistica del test √® stata stimata al 74.4%.\n\nIn questa versione, il focus √® eccessivamente concentrato sul valore-p, che pu√≤ portare a interpretazioni riduttive e distorte dei risultati.\n\n78.6.2.2 Versione Migliorata\nEcco invece una versione migliore che mantiene un approccio frequentista, ma sposta l‚Äôenfasi sull‚Äôintervallo di confidenza e sull‚Äôampiezza dell‚Äôeffetto, offrendo una descrizione pi√π completa e informativa:\n\n√à stato condotto un test t di Student per confrontare le medie dei due gruppi. La differenza tra i pesi medi delle donne e degli uomini √® stata stimata in -16.89 kg (intervallo di confidenza al 95%: [-29.75, -4.03]), suggerendo che il peso medio degli uomini sia maggiore rispetto a quello delle donne nel campione analizzato. Questo intervallo indica che, con una fiducia del 95%, la differenza reale tra i pesi medi potrebbe variare tra circa -29.75 kg e -4.03 kg.\nL‚Äôampiezza dell‚Äôeffetto, misurata con Cohen‚Äôs d = 1.31, indica una differenza considerevole, equivalente a oltre una deviazione standard. Questo valore suggerisce che la differenza osservata non solo √® statisticamente rilevante, ma anche sostanziale dal punto di vista pratico.\nInoltre, la potenza del test, considerando la dimensione dell‚Äôeffetto osservata, √® pari al 74.4%, suggerendo che il test ha una buona capacit√† di rilevare differenze di questa entit√† nel campione analizzato. Ci√≤ significa che, se una differenza di tale magnitudine fosse presente nella popolazione, esisterebbe una probabilit√† superiore al 70% di rilevarla correttamente.\n\nQuesta modalit√† di reporting fornisce una descrizione pi√π dettagliata ed esplicativa dei risultati, evitando interpretazioni basate esclusivamente sul valore-p e concentrandosi invece sulla grandezza e sull‚Äôincertezza della stima. Tale approccio consente una valutazione pi√π equilibrata e informata dei dati, promuovendo una comprensione pi√π approfondita delle implicazioni pratiche e scientifiche dei risultati ottenuti.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>78</span>¬† <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html#riflessioni-conclusive",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html#riflessioni-conclusive",
    "title": "\n78¬† Test t di Student per campioni indipendenti\n",
    "section": "\n78.7 Riflessioni Conclusive",
    "text": "78.7 Riflessioni Conclusive\nIl test t di Student √® uno strumento statistico ampiamente utilizzato per l‚Äôinferenza su una media o per confrontare le medie di due gruppi. √à talmente importante che alcuni lo hanno definito il metodo statistico pi√π importante nella scienza. Tuttavia, come osserva Andrew Gelman, questa affermazione non va accettata acriticamente. Bench√© il test t sia semplice ed efficace in molti contesti, presenta notevoli limitazioni che ne riducono l‚Äôaffidabilit√† e l‚Äôapplicabilit√† quando si affrontano problemi complessi o si desidera una comprensione pi√π approfondita dei dati (Kruschke, 2013).\n\n78.7.1 Limiti del Test t di Student\nUno dei principali limiti del test t risiede nell‚Äôassunzione che i dati seguano una distribuzione normale (gaussiana). Questa assunzione √® spesso violata in pratica, specialmente con campioni piccoli o quando i dati presentano asimmetrie o code pesanti. Inoltre, nel caso di campioni indipendenti, il test richiede l‚Äôomogeneit√† delle varianze, un‚Äôaltra assunzione frequentemente infondata. Quando queste condizioni non sono soddisfatte, il test pu√≤ fornire risultati distorti, necessitando di correzioni come quella di Welch per gestire differenze di varianza.\nUn ulteriore limite del test t √® legato alla sua dipendenza dalla soglia di significativit√† \\(\\alpha\\), solitamente fissata a 0.05. Questa scelta √® arbitraria e pu√≤ influenzare criticamente le conclusioni. Il test valuta esclusivamente la compatibilit√† dei dati con l‚Äôipotesi nulla (\\(H_0\\)) e fornisce solo un p-value, senza offrire informazioni dirette sulla plausibilit√† dell‚Äôipotesi alternativa (\\(H_1\\)). Ci√≤ significa che un p-value basso non garantisce che \\(H_1\\) sia vera o che i dati supportino tale ipotesi.\n\n78.7.2 L‚ÄôApproccio Bayesiano: Una Soluzione Pi√π Potente\nIn contrasto con il paradigma frequentista, l‚Äôapproccio bayesiano offre un quadro statistico pi√π flessibile e informativo. Attraverso il teorema di Bayes, √® possibile calcolare direttamente la probabilit√† di un‚Äôipotesi dato l‚Äôinsieme dei dati osservati. Questo permette di quantificare la forza dell‚Äôevidenza a favore di un‚Äôipotesi rispetto alle altre, superando le limitazioni intrinseche del test t.\n\n78.7.2.1 Vantaggi dell‚ÄôApproccio Bayesiano\n\nNon richiede assunzioni rigide: A differenza del test t, che si basa su ipotesi restrittive come la normalit√† e l‚Äôomoschedasticit√†, l‚Äôinferenza bayesiana √® in grado di gestire modelli pi√π generali e robusti, adattandosi ai dati reali senza doverli forzare in strutture artificiali.\nIncorporazione delle informazioni pregresse: L‚Äôapproccio bayesiano permette di integrare conoscenze pregresse attraverso distribuzioni a priori, migliorando la qualit√† delle stime e consentendo analisi pi√π realistiche. Questo √® particolarmente utile in situazioni dove i dati disponibili sono scarsi o rumorosi.\nInferenze pi√π informative: Al posto di semplici decisioni binarie (‚Äúrifiuto‚Äù o ‚Äúnon rifiuto‚Äù di \\(H_0\\)), il bayesianismo fornisce distribuzioni a posteriori complete, che descrivono l‚Äôincertezza sui parametri di interesse. Questo consente inferenze pi√π dettagliate e interpretabili.\nGestione della complessit√†: L‚Äôapproccio bayesiano gestisce in modo naturale modelli complessi e gerarchici, rendendolo ideale per analisi avanzate. Ad esempio, Kruschke (2013) dimostra come tecniche bayesiane possano superare le limitazioni del test t anche in presenza di violazioni delle assunzioni classiche, producendo risultati pi√π stabili e affidabili.\n\n78.7.2.2 Implementazione Pratica\nSebbene l‚Äôapproccio bayesiano richieda una maggiore attenzione nella scelta delle distribuzioni a priori e nella specificazione del modello, l‚Äôavvento di software moderni come Stan, PyMC3 e JAGS ha reso l‚Äôimplementazione di modelli bayesiani sempre pi√π accessibile. Oggi, anche ricercatori con competenze statistiche moderate possono applicare metodi bayesiani per affrontare problemi complessi con maggiore precisione e coerenza.\n\n78.7.3 Conclusioni\nIl test t di Student rimane un valido strumento per analisi rapide e semplici, ma le sue limitazioni diventano evidenti quando si lavora con dati complessi o si cerca una comprensione pi√π profonda delle relazioni sottostanti. L‚Äôapproccio bayesiano rappresenta un‚Äôevoluzione concettuale e metodologica rispetto all‚Äôinferenza frequentista tradizionale, offrendo numerosi vantaggi: inferenze pi√π ricche, integrazione di informazioni pregresse, gestione delle violazioni delle assunzioni e produzione di stime pi√π robuste. Per questi motivi, il paradigma bayesiano √® sempre pi√π considerato come la scelta preferibile per chi desidera un‚Äôanalisi statistica solida, flessibile e informativa.\nIn ultima analisi, mentre il test t resta un punto di partenza utile, l‚Äôadozione dell‚Äôapproccio bayesiano permette di avanzare verso una comprensione pi√π completa e accurata dei dati.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>78</span>¬† <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html#informazioni-sullambiente-di-sviluppo",
    "title": "\n78¬† Test t di Student per campioni indipendenti\n",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.17.0      thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0\n#&gt;  [5] see_0.11.0       gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1\n#&gt;  [9] psych_2.5.3      scales_1.3.0     markdown_2.0     knitr_1.50      \n#&gt; [13] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [17] purrr_1.0.4      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [21] ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      shape_1.4.6.1     xfun_0.51         htmlwidgets_1.6.4\n#&gt;  [5] lattice_0.22-6    tzdb_0.5.0        Rdpack_2.6.3      vctrs_0.6.5      \n#&gt;  [9] tools_4.4.2       generics_0.1.3    parallel_4.4.2    pan_1.9          \n#&gt; [13] pacman_0.5.1      jomo_2.7-6        pkgconfig_2.0.3   Matrix_1.7-3     \n#&gt; [17] lifecycle_1.0.4   compiler_4.4.2    farver_2.1.2      munsell_0.5.1    \n#&gt; [21] mnormt_2.1.1      codetools_0.2-20  htmltools_0.5.8.1 glmnet_4.1-8     \n#&gt; [25] nloptr_2.2.1      pillar_1.10.1     MASS_7.3-65       reformulas_0.4.0 \n#&gt; [29] iterators_1.0.14  rpart_4.1.24      boot_1.3-31       mitml_0.4-5      \n#&gt; [33] foreach_1.5.2     nlme_3.1-167      tidyselect_1.2.1  digest_0.6.37    \n#&gt; [37] stringi_1.8.4     splines_4.4.2     rprojroot_2.0.4   fastmap_1.2.0    \n#&gt; [41] grid_4.4.2        colorspace_2.1-1  cli_3.6.4         magrittr_2.0.3   \n#&gt; [45] survival_3.8-3    broom_1.0.7       withr_3.0.2       backports_1.5.0  \n#&gt; [49] timechange_0.3.0  rmarkdown_2.29    nnet_7.3-20       lme4_1.1-36      \n#&gt; [53] hms_1.1.3         evaluate_1.0.3    rbibutils_2.3     rlang_1.1.5      \n#&gt; [57] Rcpp_1.0.14       glue_1.8.0        minqa_1.2.8       rstudioapi_0.17.1\n#&gt; [61] jsonlite_1.9.1    R6_2.6.1",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>78</span>¬† <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html#bibliografia",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html#bibliografia",
    "title": "\n78¬† Test t di Student per campioni indipendenti\n",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nKruschke, J. K. (2013). Bayesian estimation supersedes the t test. Journal of Experimental Psychology: General, 142(2), 573‚Äì603.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>78</span>¬† <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/introduction_replication_crisis.html",
    "href": "chapters/replication_crisis/introduction_replication_crisis.html",
    "title": "Introduzione",
    "section": "",
    "text": "Bibliografia\nIn psicologia, nelle scienze sociali e in altre discipline √® in corso una Riforma Metodologica, scaturita da una profonda crisi che ha colpito la scienza contemporanea: la crisi di replicazione dei risultati delle ricerche. Un esempio emblematico √® rappresentato dal sito Retraction Watch, che monitora le ritrattazioni di studi scientifici. Questa crisi mina la credibilit√† della ricerca scientifica e ha spinto a una revisione radicale delle metodologie alla base delle scienze psicologiche e di altre discipline affini (Korbmacher et al., 2023). Le cause della crisi di replicazione sono molteplici: frodi, pratiche di ricerca scorrette e incentivi distorti offerti dal sistema accademico. Una delle cause pi√π rilevanti per un corso sull‚Äôanalisi dei dati psicologici √® l‚Äôuso delle tecniche inferenziali di stampo frequentista, che ha contribuito alla proliferazione di pubblicazioni contenenti falsi positivi.\nUn articolo di Altmejd et al. (2019) identifica alcuni fattori semplici ma altamente predittivi della replicabilit√† degli studi: il campione era di dimensioni adeguate? I ricercatori hanno ottenuto un risultato appena sotto la soglia di significativit√† di p = 0.05? (Spesso un articolo pu√≤ rivendicare un risultato ‚Äúsignificativo‚Äù se questa soglia viene raggiunta, e molti utilizzano vari trucchi statistici per superare tale limite.) Lo studio ha rilevato un effetto sull‚Äôintera popolazione studiata o ha individuato un ‚Äúeffetto di interazione‚Äù (ad esempio, un effetto presente solo in un segmento pi√π piccolo della popolazione), che √® molto meno probabile che si riproduca?\n√à emerso inoltre che prevedere la replicazione di uno studio √® sorprendentemente semplice. Non √® necessario un approfondimento della metodologia statistica n√© un esame rigoroso dei dati, n√© tantomeno una scrupolosa analisi delle teorie pi√π esoteriche per individuare errori sottili: questi articoli presentano problemi evidenti, a livello superficiale. Uno studio pubblicato su Nature ha coinvolto scienziati in una scommessa su quali studi di scienze sociali sarebbero stati replicati. Camerer et al. (2018) ha scoperto che le previsioni degli scienziati in questo mercato delle scommesse erano estremamente accurate nel determinare quali articoli avrebbero avuto successo nella replicazione.\nUlteriori ricerche hanno dimostrato che non √® nemmeno necessario consultare esperti del settore per indovinare quali studi resisteranno a un esame rigoroso. Uno studio di Hoogeveen et al. (2020) ha coinvolto partecipanti senza un background professionale nelle scienze sociali, chiedendo loro di leggere articoli di psicologia e prevedere se questi si sarebbero replicati. ‚ÄúI non-esperti senza una formazione professionale nelle scienze sociali sono in grado di prevedere la replicabilit√† degli studi con una precisione superiore al caso,‚Äù conclude lo studio, ‚Äúbasandosi esclusivamente su semplici descrizioni verbali degli studi.‚Äù\nSebbene i non esperti non siano stati altrettanto precisi nelle loro previsioni rispetto agli scienziati nello studio pubblicato su Nature, il fatto che siano comunque riusciti a individuare molte replicazioni fallite suggerisce che molti di questi studi presentano difetti evidenti, riconoscibili anche da chi non √® un addetto ai lavori.\nLa pubblicazione di un articolo peer-reviewed non rappresenta l‚Äôultimo passo del processo scientifico. Dopo la pubblicazione, altri studi potrebbero citare l‚Äôarticolo originale, diffondendo eventuali errori o fraintendimenti. Uno studio di Yang et al. (2020) mostra che non esiste alcuna correlazione tra la replicabilit√† di uno studio e la sua frequenza di citazione. ‚ÄúGli studi falliti si diffondono nella letteratura scientifica con la stessa rapidit√† degli studi replicabili,‚Äù affermano Yang et al. (2020). Questo solleva una domanda: se gli scienziati sono abbastanza bravi nel prevedere se uno studio si replicher√†, perch√© sono altrettanto inclini a citare studi non replicabili quanto quelli validi?\nQueste considerazioni suggeriscono che la crisi di replicazione non richiede solo una revisione metodologica, ma √® il sintomo di un sistema scientifico che necessita di un ripensamento pi√π ampio. Le riviste scientifiche non sono sufficientemente responsabili per la pubblicazione di articoli discutibili, e il sistema accademico promuove incentivi distorti. In alcuni casi, la cultura accademica sembra addirittura incentivare la produzione di ricerche di bassa qualit√†. La pressione a pubblicare un elevato numero di articoli favorisce chi riesce a farlo rapidamente, spesso ricorrendo a ‚Äúscorciatoie‚Äù. Di conseguenza, si √® creato un sistema in cui gli incentivi continuano a promuovere la cattiva ricerca, nonostante si comprenda sempre meglio cosa costituisca una ricerca di qualit√†.\nIn questa sezione della dispensa, ci concentreremo su uno dei problemi che stanno alla base della crisi della riproducibilit√† dei risultati della ricerca, ovvero i limiti dell‚Äôinferenza frequentista (Baker, 2016). Analizzeremo gli errori di tipo S e di tipo M, concetti introdotti da Gelman & Carlin (2014), che hanno contribuito a migliorare la comprensione dei limiti della statistica frequentista. Inoltre, discuteremo alcuni possibili metodi per affrontare la crisi e le implicazioni che derivano dall‚Äôintegrit√† della ricerca.",
    "crumbs": [
      "Crisi",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/introduction_replication_crisis.html#bibliografia",
    "href": "chapters/replication_crisis/introduction_replication_crisis.html#bibliografia",
    "title": "Introduzione",
    "section": "",
    "text": "Altmejd, A., Dreber, A., Forsell, E., Huber, J., Imai, T., Johannesson, M., Kirchler, M., Nave, G., & Camerer, C. (2019). Predicting the replicability of social science lab experiments. PloS one, 14(12), e0225826.\n\n\nBaker, M. (2016). Reproducibility Crisis. Nature, 533(7604), 452‚Äì454.\n\n\nCamerer, C. F., Dreber, A., Holzmeister, F., Ho, T.-H., Huber, J., Johannesson, M., Kirchler, M., Nave, G., Nosek, B. A., Pfeiffer, T., et al. (2018). Evaluating the replicability of social science experiments in Nature and Science between 2010 and 2015. Nature human behaviour, 2(9), 637‚Äì644.\n\n\nGelman, A., & Carlin, J. (2014). Beyond Power Calculations: Assessing Type S (Sign) and Type M (Magnitude) Errors. Perspectives on Psychological Science, 9(6), 641‚Äì651.\n\n\nHoogeveen, S., Sarafoglou, A., & Wagenmakers, E.-J. (2020). Laypeople can predict which social-science studies will be replicated successfully. Advances in Methods and Practices in Psychological Science, 3(3), 267‚Äì285.\n\n\nKorbmacher, M., Azevedo, F., Pennington, C. R., Hartmann, H., Pownall, M., Schmidt, K., Elsherif, M., Breznau, N., Robertson, O., Kalandadze, T., et al. (2023). The replication crisis has led to positive structural, procedural, and community changes. Communications Psychology, 1(1), 3.\n\n\nYang, Y., Youyou, W., & Uzzi, B. (2020). Estimating the deep replicability of scientific findings using human and artificial intelligence. Proceedings of the National Academy of Sciences, 117(20), 10762‚Äì10768.",
    "crumbs": [
      "Crisi",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html",
    "href": "chapters/replication_crisis/01_crisis.html",
    "title": "79¬† La crisi della replicazione",
    "section": "",
    "text": "79.1 Introduzione\nIl presente capitolo introduce la crisi di replicazione che affligge la ricerca psicologica, analizzandone le cause precipue e ponendo in rilievo il ruolo che l‚Äôapproccio statistico frequentista ha avuto nel concorrere a tale problematica. Il contenuto di questo capitolo costituisce una sintesi rielaborata del testo A student‚Äôs guide to open science: Using the replication crisis to reform psychology (Pennington, 2023).",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>79</span>¬† <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#cosa-dovrebbe-essere-la-scienza",
    "href": "chapters/replication_crisis/01_crisis.html#cosa-dovrebbe-essere-la-scienza",
    "title": "79¬† La crisi della replicazione",
    "section": "\n79.2 Cosa dovrebbe essere la scienza",
    "text": "79.2 Cosa dovrebbe essere la scienza\nPennington (2023) avvia la sua discussione sulla crisi di replicazione delineando le caratteristiche di uno scenario ‚Äúideale‚Äù cui la prassi scientifica dovrebbe aspirare. Affinch√© la psicologia possa essere considerata una disciplina scientifica a pieno titolo, √® imprescindibile l‚Äôadesione ai principi di replicabilit√† e riproducibilit√†. In altri termini, qualora un effetto sia reale e robusto, qualsiasi ricercatore, a parit√† di procedure e con un‚Äôadeguata dimensione campionaria, dovrebbe essere in grado di rilevarlo. Ulteriori attributi auspicabili della ricerca scientifica sono i seguenti:\n\n\nCredibile: La scienza dovrebbe essere credibile, non incredibile. Gli scienziati dovrebbero essere disposti a sottoporre le loro affermazioni e scoperte a un esame equo e rigoroso.\n\n\nAffidabile: I risultati scientifici dovrebbero essere riportati in modo accurato. Il pubblico dovrebbe poterli considerare attendibili e usarli per prendere decisioni informate.\n\n\nTrasparente: La scienza dovrebbe essere assolutamente chiara. I metodi e i risultati scientifici dovrebbero essere descritti in dettaglio, permettendo repliche indipendenti, valutazioni e l‚Äôaccumulo di conoscenze.\n\n\nAccessibile: La scienza dovrebbe essere accessibile a tutti. Sia i ricercatori sia il pubblico generale dovrebbero poter accedere, leggere e valutare facilmente i risultati scientifici.\n\n\nInclusiva: La scienza dovrebbe essere diversificata e inclusiva. Gli scienziati appartenenti a gruppi sottorappresentati dovrebbero avere pari opportunit√† di partecipazione e accesso.\n\n\nCollaborativa: La scienza dovrebbe massimizzare l‚Äôuso delle risorse disponibili, incoraggiando la cooperazione tra ricercatori piuttosto che la competizione, per produrre lavori di alta qualit√†.\n\n\nAutocorrettiva: La scienza dovrebbe basarsi su prove accurate nel perseguimento della conoscenza. Gli errori riscontrati negli articoli dovrebbero essere corretti e spiegati, rendendo questa pratica normale nel processo scientifico.\n\nA questo punto, Pennington (2023) propone una riflessione retorica: ‚ÄúImmaginate di chiudere gli occhi e visualizzare uno scienziato stereotipato. Quale immagine vi si presenta? Quali azioni compie? Quali sono i suoi comportamenti?‚Äù.\nL‚Äôautore offre la propria visualizzazione: ‚ÄúIo vedo un uomo bianco, di mezza et√†, all‚Äôinterno di un laboratorio contrassegnato da un grande cartello con la scritta ‚ÄòDIVIETO DI ACCESSO!‚Äô. I suoi risultati rappresentano un tesoro personale, gelosamente custodito, precluso a qualsiasi osservatore esterno. Egli teme che qualcuno possa appropriarsi delle sue brillanti intuizioni, replicare il suo lavoro o tentare di riprodurne i risultati. Si tratta della sua scienza, non di una scienza condivisa.‚Äù\nTale rappresentazione incarna una scienza priva di trasparenza, accessibilit√† e spirito collaborativo.\nNella psicologia contemporanea √® in corso un ampio dibattito su quali cambiamenti siano necessari per superare le criticit√† emerse negli ultimi anni e promuovere una scienza pi√π rigorosa e affidabile. Nonostante la scienza si fondi su principi chiave, come replicabilit√† e riproducibilit√†, la prassi scientifica non √® sempre stata coerente con questi ideali. Questa discrepanza ha portato a ci√≤ che molti definiscono una crisi nella psicologia moderna.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>79</span>¬† <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#la-crisi-della-replicazione-in-psicologia",
    "href": "chapters/replication_crisis/01_crisis.html#la-crisi-della-replicazione-in-psicologia",
    "title": "79¬† La crisi della replicazione",
    "section": "\n79.3 La Crisi della Replicazione in Psicologia",
    "text": "79.3 La Crisi della Replicazione in Psicologia\nNegli ultimi decenni, la psicologia si √® trovata al centro di una crisi che ha messo in discussione molte delle sue basi epistemologiche e metodologiche: la crisi della replicazione. Questo fenomeno indica l‚Äôincapacit√† di replicare con successo un‚Äôampia parte degli studi pubblicati, con implicazioni rilevanti per la cultura accademica e il modo di concepire la ricerca scientifica (Parsons et al., 2022).\nPer fallimento della replicazione si intende il caso in cui uno studio, ripetuto da altri ricercatori seguendo le stesse procedure e utilizzando campioni simili, non riesce a ottenere risultati comparabili a quelli originali. Questo ha portato alla luce problemi sistemici legati alla metodologia di ricerca, all‚Äôinterpretazione dei dati e alle dinamiche del sistema accademico. La crisi della replicazione ha dunque evidenziato la necessit√† di un cambiamento strutturale nella pratica scientifica, sottolineando l‚Äôurgenza di un approccio pi√π trasparente, rigoroso e collaborativo.\nNelle sezioni seguenti vengono presentati gli eventi chiave di quella che possiamo chiamare la storia della crisi della replicazione.\n\n79.3.1 2005: ‚ÄúPerch√© la maggior parte dei risultati pubblicati √® falsa‚Äù (Ioannidis)\nUn primo momento cruciale √® stato l‚Äôarticolo di ‚ÄúWhy Most Published Research Findings Are False‚Äù (Ioannidis, 2005) che ha evidenziato come molti risultati scientifici fossero in realt√† falsi positivi. Ioannidis attribu√¨ questo fenomeno a campioni di piccole dimensioni, un‚Äôeccessiva enfasi sui valori-p per indicare significativit√†, flessibilit√† nei metodi di analisi e la competizione per produrre risultati ‚Äúinnovativi‚Äù. Questo articolo ha messo in luce problemi che trascendono la psicologia, ma che in seguito sarebbero emersi come centrali anche per questa disciplina.\n\n79.3.2 2011: Lo Studio di Daryl Bem, ‚ÄúFeeling the Future‚Äù\nUno degli eventi pi√π controversi √® stato lo studio di Daryl Bem ‚ÄúFeeling the Future‚Äù (Bem, 2011), che suggeriva l‚Äôesistenza della precognizione, ovvero la capacit√† di ‚Äúsentire‚Äù eventi futuri. Attraverso nove esperimenti, Bem pubblic√≤ risultati statisticamente significativi che sembravano sfidare le leggi della causalit√†.\nLo studio di Bem si inseriva nella tradizione degli esperimenti di ‚Äúpriming‚Äù, una tecnica ampiamente utilizzata in psicologia sociale dagli anni ‚Äô70. Gli esperimenti di priming tipicamente coinvolgevano studenti universitari, remunerati con modeste somme o crediti accademici. I partecipanti venivano esposti a determinati concetti per poi osservare come questi influenzassero il loro comportamento successivo. Un celebre esempio √® lo studio di John Bargh del 1996, che dimostr√≤ come l‚Äôesposizione a parole associate all‚Äôet√† avanzata inducesse i soggetti a camminare pi√π lentamente (Bargh et al., 1996). Un altro studio del 2006 rivel√≤ che il priming con concetti legati al denaro rendeva le persone meno propense ad aiutare gli altri. Questi studi sembravano dimostrare una straordinaria malleabilit√† della mente umana, suggerendo che il nostro comportamento potesse essere inconsciamente manipolato da sottili segnali ambientali (Leys, 2024). Tuttavia, lo studio di Bem introdusse un elemento nuovo in questo paradigma sperimentale.\nTra i vari esperimenti condotti da Bem, uno in particolare si distingueva. I soggetti venivano esposti a una parola con connotazione positiva o negativa e successivamente dovevano valutare rapidamente la piacevolezza di alcune immagini. Fin qui, nulla di insolito. La svolta radicale consisteva nel fatto che in met√† delle prove, il priming avveniva dopo che i soggetti avevano gi√† visto e valutato l‚Äôimmagine (Bem, 2011).\nSorprendentemente, i risultati mostravano che il priming funzionava anche in queste condizioni: i partecipanti erano pi√π veloci a giudicare piacevoli le immagini quando successivamente venivano esposti a una parola positiva. Questo effetto risultava statisticamente significativo, con un p-value di 0.01, sufficiente secondo gli standard correnti per rifiutare l‚Äôipotesi nulla.\nBem interpret√≤ questi risultati come prova della chiaroveggenza, una conclusione che suscit√≤ notevoli controversie e ridicolizz√≤ la psicologia. Gli altri otto esperimenti dello studio, tutti basati su classici paradigmi della psicologia sociale con l‚Äôordine temporale invertito, mostrarono risultati altrettanto statisticamente significativi.\nQuesti risultati ponevano la comunit√† scientifica di fronte a un dilemma: accettare l‚Äôesistenza di fenomeni paranormali o mettere in discussione le pratiche statistiche e metodologiche consolidate nella disciplina. Bem stesso continua a sostenere la validit√† dei suoi risultati come prova dell‚Äôesistenza di capacit√† precognitive.\nSebbene pubblicato su una rivista prestigiosa, lo studio sollev√≤ enormi dubbi metodologici. Le repliche successive non riuscirono a confermare i risultati di Bem, mostrando come pratiche discutibili, quali il p-hacking (modifiche al metodo di analisi per ottenere risultati significativi), potessero produrre falsi positivi apparentemente robusti.\n\n79.3.3 2011: Il Caso di Frode di Diederik Stapel\nNello stesso anno, Diederik Stapel, una figura di spicco della psicologia sociale, fu accusato di aver falsificato dati in decine di studi pubblicati. Tra i suoi esperimenti pi√π famosi vi era quello secondo cui ambienti disordinati aumenterebbero il razzismo. Un altro studio suggeriva che mangiare carne rendeva le persone pi√π antisociali. Tuttavia, si scopr√¨ che per quegli studi, e molti altri, non aveva mai condotto gli esperimenti n√© raccolto i dati. Li aveva semplicemente inventati. A volte le frodi accadono. Stapel fu scoperto (alla fine), licenziato e decine dei suoi articoli furono ritirati. Questo scandalo scosse profondamente la comunit√† accademica e divenne un simbolo della crisi.\n\n79.3.4 2011: La Meta-ricerca e le Pratiche di Ricerca Discutibili (QRPs)\nLa meta-ricerca √® un campo di studio che si concentra sul modo in cui viene condotta la ricerca scientifica. Comprende temi come i metodi, la trasparenza nella comunicazione, la riproducibilit√†, la valutazione e i sistemi di incentivi che regolano la scienza (Ioannidis et al., 2015). Questo ambito √® emerso con urgenza dopo una serie di casi controversi e di frodi conclamate, come gli studi di Daryl Bem e Diederik Stapel, che hanno evidenziato falle nei processi di ricerca. I ricercatori hanno cos√¨ iniziato ad analizzare pratiche note come Questionable Research Practices (QRPs, Pratiche di Ricerca Discutibili), che sfruttano aree grigie nelle norme scientifiche per raccogliere e analizzare i dati.\nSimmons et al.¬†(2011) hanno dimostrato come la flessibilit√† nella raccolta, analisi e comunicazione dei dati permetta ai ricercatori di far apparire ‚Äúsignificativo‚Äù praticamente qualsiasi risultato. Tra le pratiche discusse, spiccano:\n\n\nOptional stopping: Interrompere la raccolta dei dati non appena si raggiunge la significativit√† statistica, invece di seguire un piano prestabilito.\n\n\nP-hacking: Condurre molteplici test non pianificati, selezionando variabili o analisi solo quando producono un valore p inferiore a 0.05.\n\n\nHARKing (Hypothesizing After Results are Known): Modificare le ipotesi a posteriori per adattarle ai risultati ottenuti, presentandole come ipotesi iniziali.\n\nQueste pratiche non solo compromettono l‚Äôintegrit√† scientifica, ma rendono estremamente facile produrre falsi positivi. Per dimostrarlo, Simmons e colleghi hanno condotto simulazioni al computer e due esperimenti, rivelando quanto fosse ‚Äútroppo facile‚Äù raccogliere prove a sostegno di ipotesi false.\nLa portata di queste pratiche √® sorprendente. Simmons et al.¬†hanno scoperto che:\n\nUsare una sola QRP pu√≤ quasi raddoppiare il tasso di falsi positivi, portandolo dal 5% al 10%.\n\nCombinare pi√π QRPs pu√≤ far salire questa percentuale oltre il 60%.\n\nPer sottolineare il problema, i ricercatori hanno dimostrato, in modo volutamente ironico, che ascoltare la canzone dei Beatles ‚ÄúWhen I‚Äôm Sixty-Four‚Äù potrebbe far apparire le persone pi√π giovani di quanto fossero prima di ascoltarla. Questa dimostrazione satirica evidenziava che inseguire la significativit√† statistica senza un rigore metodologico pu√≤ produrre risultati assurdi.\nJohn et al.¬†(2012) hanno condotto un‚Äôindagine su larga scala, intervistando 2000 ricercatori per comprendere la diffusione delle QRPs. Con un approccio innovativo, hanno chiesto ai partecipanti non solo di riferire le proprie pratiche, ma anche quelle dei colleghi. I risultati sono stati sconvolgenti:\n\nOltre il 60% degli intervistati ha ammesso di non aver riportato tutte le variabili dipendenti misurate.\n\nPi√π del 50% ha interrotto la raccolta dati non appena ottenuti risultati significativi (optional stopping).\n\nPi√π del 40% ha selezionato e riportato solo esperimenti ‚Äúriusciti‚Äù.\n\nSorprendentemente, i ricercatori tendevano a dichiarare che i colleghi adottavano queste pratiche pi√π frequentemente di loro stessi. Molti giustificavano queste pratiche come ‚Äúnorme accademiche‚Äù del tempo.\nLa meta-ricerca ha giocato un ruolo cruciale nell‚Äôaprire gli occhi della comunit√† scientifica sui pericoli di queste decisioni apparentemente ‚Äúbanali‚Äù. In un contesto in cui le QRPs erano ampiamente accettate, la meta-ricerca ha evidenziato come queste pratiche possano seriamente danneggiare il progresso scientifico. Grazie al movimento dell‚ÄôOpen Science, si stanno introducendo norme che migliorano la credibilit√† della ricerca, spostando l‚Äôenfasi dalla produzione di risultati ‚Äúsignificativi‚Äù alla conduzione di studi rigorosi e trasparenti.\n\n79.3.5 2012: La Crisi di Fiducia della Psicologia\nSiamo nel 2012, un anno segnato da una serie di eventi che spingono Harold Pashler ed Eric-Jan Wagenmakers a dichiarare che la psicologia sta affrontando una ‚Äúcrisi di fiducia‚Äù. In un numero speciale della rivista Perspectives on Psychological Science (PoPs), i due autori raccolgono una molteplicit√† di prospettive sulla nascente crisi della replicazione, cercando di individuarne le cause e le implicazioni.\nLe reazioni alla crisi sono variegate e, in alcuni casi, contrastanti. Alcuni studiosi sostengono che le affermazioni di una crisi siano premature (Stroebe e Strack, 2014) e che i problemi di replicazione non siano un fenomeno nuovo (Spellman, 2015). Altri, invece, sottolineano come incentivare e valorizzare gli studi di replicazione rappresenti un metodo efficace e diretto per migliorare la qualit√† della scienza psicologica (Koole e Lakens, 2012).\nIl numero speciale evidenzia anche iniziative in corso per affrontare il problema. Tra queste, l‚ÄôOpen Science Collaboration (OSC), un progetto di larga scala avviato nel 2012, si propone di verificare empiricamente se la psicologia sia effettivamente alle prese con una crisi della replicazione. L‚Äôobiettivo del progetto √® ambizioso: replicare numerosi studi pubblicati per valutare la robustezza dei risultati originari. Sebbene i risultati di questa iniziativa non fossero ancora disponibili al momento della pubblicazione del numero speciale, il progetto rappresentava gi√† una pietra miliare per la disciplina.\nNonostante le preoccupazioni, il numero speciale si chiude con una nota positiva, destinata a risuonare nella comunit√† scientifica. I casi di frode, le pratiche di ricerca discutibili (QRPs) e i fallimenti nei tentativi di replicazione, sebbene dannosi, hanno aperto la strada a una riflessione critica. Questo processo ha permesso alla psicologia di affrontare i propri limiti, correggere errori, superare i bias e costruire una letteratura pi√π affidabile e trasparente.\nQuesto periodo storico segna un punto di svolta: la crisi di fiducia ha messo in discussione le fondamenta della disciplina, ma ha anche creato l‚Äôopportunit√† per un rinnovamento scientifico, stimolando pratiche pi√π rigorose e una maggiore attenzione alla replicabilit√† e alla trasparenza.\n\n79.3.6 2014: Il Progetto ‚ÄúMany Labs‚Äù\nNel 2014 fu pubblicato il primo tentativo su larga scala di replicare risultati psicologici: il progetto ‚ÄúMany Labs‚Äù. Questo imponente sforzo collaborativo, guidato da Klein et al.¬†(2014), test√≤ la replicabilit√† di 13 risultati classici della psicologia, coinvolgendo 6344 partecipanti in 12 paesi. Gli studi selezionati rispettavano tre criteri principali: erano relativamente brevi, avevano un design semplice e potevano essere facilmente condotti online.\nTra i fenomeni esaminati figurava la fallacia del costo irrecuperabile (sunk cost fallacy), secondo cui le persone tendono a proseguire un‚Äôattivit√† quando vi hanno gi√† investito tempo, sforzi o denaro. Un esempio classico: se hai acquistato un biglietto per vedere la tua squadra di calcio preferita e, il giorno della partita, inizia a piovere a dirotto, sarai pi√π propenso a partecipare perch√© hai gi√† speso i soldi per il biglietto (Oppenheimer e Monin, 2009).\nAltri studi replicati includevano:\n\nL‚Äôinfluenza del framing dei guadagni e delle perdite sul rischio (Tversky e Kahneman, 1981).\n\nLe differenze di genere negli atteggiamenti impliciti verso la matematica e le arti (Nosek et al., 2002).\n\nI risultati sembravano promettenti: il 77% degli studi replic√≤ con successo i risultati originali (10 su 13). Tuttavia, non tutti gli studi fornirono lo stesso livello di evidenza. Ad esempio:\n\nUno studio sull‚Äôefficacia del contatto sociale immaginato nel ridurre i pregiudizi (Husnu e Crisp, 2010) mostr√≤ supporto limitato, con solo 4 campioni su 36 che evidenziarono un effetto significativo.\n\nDue studi di priming non furono replicati. Nel primo, i ricercatori non trovarono che l‚Äôesposizione alla bandiera americana aumentasse il conservatorismo (Carter et al., 2011). Nel secondo, il priming con concetti legati al denaro non port√≤ a un incremento delle credenze o dei comportamenti capitalistici (Caruso et al., 2013).\n\nSebbene i risultati fossero accolti come una vittoria per la replicabilit√†, alcuni ricercatori sottolinearono limiti nel progetto Many Labs 1. Gli stessi autori riconobbero che molti degli studi selezionati erano gi√† noti per essere altamente replicabili. Secondo alcuni critici, il principale contributo di questo progetto era dimostrare che almeno dieci effetti psicologici erano replicabili, ma non forniva una panoramica pi√π ampia sulla replicabilit√† complessiva nella psicologia (Yarkoni, 2013).\nQuesto progetto rappresent√≤ comunque un passo fondamentale per affrontare la crisi della replicazione, sottolineando l‚Äôimportanza della collaborazione scientifica e del rigore metodologico.\n\n79.3.7 2015: Il Progetto di Riproducibilit√† della Open Science Collaboration\nNel 2015, la Open Science Collaboration (OSC) pubblic√≤ i risultati del Reproducibility Project: Psychology, dimostrando che la buona scienza richiede tempo e rigore. Superando i limiti del progetto Many Labs 1, un team composto da oltre 270 ricercatori internazionali si impegn√≤ a replicare 100 studi scelti casualmente da riviste di punta nel campo della psicologia.\nPer garantire risultati solidi e inattaccabili, il team adott√≤ una metodologia rigorosa:\n- Consultazione con gli autori originali: gli autori degli studi originali furono coinvolti per confermare il design sperimentale e ridurre al minimo eventuali discrepanze.\n- Aumento delle dimensioni campionarie: i campioni furono ampliati per garantire una potenza statistica sufficiente.\n- Registrazione preventiva dei metodi: i piani di analisi e raccolta dati furono registrati in anticipo per prevenire bias da parte dei ricercatori.\nGli studi selezionati per la replicazione includevano domande di ricerca come:\n\nLa convinzione che il comportamento umano sia predeterminato incoraggia il tradimento?\n\nI bambini seguono automaticamente lo sguardo per trovare oggetti nascosti?\n\n√à possibile osservare un ‚Äúeffetto after-motion‚Äù da fotografie fisse che rappresentano movimento?\n\nI risultati del progetto fecero scalpore e conquistarono i titoli dei giornali a livello globale. Solo il 36% degli studi replic√≤ con successo, ottenendo un valore-p inferiore a 0.05. La psicologia sociale si rivel√≤ particolarmente problematica, con un tasso di replicazione del 25%, rispetto al 50% degli studi di psicologia cognitiva.\nPer contestualizzare questi numeri, se gli effetti originali fossero stati realmente validi, il tasso minimo di replicazione atteso sarebbe stato dell‚Äô89% (Field et al., 2019). Anche tra gli studi replicati, le dimensioni degli effetti risultarono dimezzate rispetto a quelle riportate negli studi originali.\nQuesti risultati provocarono una forte reazione nella comunit√† scientifica. Ci si chiedeva: era la fine della psicologia? La disciplina avrebbe mai recuperato credibilit√†? Sebbene i dati fossero allarmanti, aprirono un dibattito pi√π ampio. Come sottolineato da Kuhn (1962) e Redish et al.¬†(2018), fallimenti nella replicazione possono segnare l‚Äôinizio di una rivoluzione scientifica, stimolando un ripensamento dei metodi, delle ipotesi e delle pratiche di ricerca.\nIl Reproducibility Project: Psychology non solo mise in luce le fragilit√† della disciplina, ma divenne un punto di partenza per migliorare la trasparenza, la collaborazione e la robustezza nella ricerca psicologica.\n\n79.3.7.1 Studi Successivi\nQuesti risultati sono stati ulteriormente corroborati da numerosi studi successivi, tra cui una ricerca pi√π recente basata su tecniche di machine learning, che ha esaminato studi di psicologia pubblicati in sei importanti riviste nell‚Äôarco di vent‚Äôanni. Questa ricerca suggerisce che poco pi√π della met√† di questi articoli di psicologia non supererebbe i test di replicazione (Youyou et al., 2023). Discipline come la psicologia sociale sono state oggetto di particolare preoccupazione, con un tasso di replicazione del solo 25% riportato dal Progetto di Riproducibilit√† (Collaboration, 2015). Questo dato √® in linea con il lavoro di Youyou et al. (2023), che ha mostrato come la replicabilit√† degli articoli di psicologia vari considerevolmente per sottocampo, con la psicologia sociale che mostra un tasso di replicazione stimato del 37%, un risultato leggermente pi√π incoraggiante rispetto a quanto riportato in precedenza, ma ancora tra i pi√π bassi dei sottocampi esaminati. Altri settori come la psicologia dello sviluppo, cognitiva e clinica hanno mostrato tassi di replicazione stimati rispettivamente del 36%, 42% e 44%, mentre aree come la psicologia delle organizzazioni e della personalit√† hanno mostrato tassi leggermente pi√π incoraggianti (50% e 55%, rispettivamente). Complessivamente, le evidenze suggeriscono che le preoccupazioni diffuse sulla robustezza e replicabilit√† dei risultati della ricerca psicologica siano fondate. Sebbene il problema non sia limitato esclusivamente alla psicologia, le questioni rilevate in questo campo hanno ricevuto notevole attenzione a causa dell‚Äôapparente portata del fenomeno.\nQuesti risultati confermavano in modo drammatico le previsioni formulate anni prima da John Ioannidis e Dennis Lindley. Le loro avvertenze riguardo alla possibilit√† che una larga parte, se non la maggioranza, dei risultati scientifici pubblicati potesse essere falsa, si rivelavano ora profetiche.\nIl Progetto di Riproducibilit√† di Nosek ha segnato un punto di svolta nel dibattito sulla crisi della replicazione in psicologia e, pi√π in generale, nelle scienze sociali e biomediche. Ha evidenziato non solo la fragilit√† di molti risultati ritenuti consolidati, ma anche la necessit√† di un riesame critico delle pratiche di ricerca e pubblicazione scientifica. Questo ripensamento delle metodologie scientifiche √® ancora in atto.\n\n79.3.8 2015: 1500 Scienziati Sollevano il Velo sulla Riproducibilit√†\nI risultati del progetto dell‚ÄôOpen Science Collaboration (2015) colpirono il mondo della psicologia come un fulmine a ciel sereno. Molti risultati psicologici, considerati affidabili, crollarono improvvisamente, generando un‚Äôondata di discussioni nei dipartimenti universitari: quale sarebbe stato il prossimo ‚Äúeffetto‚Äù a fallire? Tuttavia, nonostante la psicologia fosse diventata l‚Äôemblema delle repliche fallite, presto si comprese che non era un problema esclusivo della disciplina.\nNel 2016, Baker condusse un‚Äôindagine su 1500 scienziati provenienti da diverse discipline, tra cui chimica, medicina, fisica e ingegneria, per esplorare le preoccupazioni riguardo alla replicazione e alla riproducibilit√†. I risultati furono sorprendenti: circa il 90% dei partecipanti concord√≤ sull‚Äôesistenza di una crisi di riproducibilit√†, definita come significativa dal 52% e lieve dal 38%.\nUn dato particolarmente allarmante emerse dall‚Äôindagine:\n\nIn media, il 40% degli scienziati aveva riscontrato difficolt√† nel riprodurre i propri esperimenti.\n\nQuesta percentuale saliva a oltre il 60% quando si tentava di riprodurre gli esperimenti di altri ricercatori.\n\nTra le discipline, la chimica risult√≤ la pi√π problematica, con oltre l‚Äô85% dei ricercatori che riportavano fallimenti nel riprodurre i risultati altrui.\nL‚Äôarticolo di Baker riportava anche esperienze personali che riflettevano il senso di smarrimento generato da questa crisi. Il professor Marcus Munaf√≤, per esempio, descrisse cos√¨ il suo percorso:\n\n‚ÄúHo cercato di replicare ci√≤ che dalla letteratura sembrava semplice, ma non ci sono riuscito. Ho avuto una crisi di fiducia, e poi ho scoperto che questa esperienza non era affatto rara.‚Äù (Baker, 2016, p.¬†452)\n\nL‚Äôindagine di Baker non si limit√≤ a evidenziare il problema, ma esplor√≤ anche le possibili cause della crisi, come pratiche metodologiche inadeguate e pressioni accademiche, offrendo al contempo suggerimenti per interventi correttivi.\nL‚Äôindagine segn√≤ un momento cruciale: la crisi della riproducibilit√†, inizialmente confinata a discussioni accademiche, raggiunse una visibilit√† globale. Non era pi√π solo un problema della psicologia, ma un fenomeno che colpiva l‚Äôintero mondo scientifico, portando con s√© la necessit√† di una trasformazione radicale delle pratiche di ricerca.\nQuesto evento contribu√¨ a consolidare il riconoscimento della crisi della riproducibilit√† come una sfida centrale per tutta la scienza, spingendo verso un cambiamento culturale che mettesse al centro trasparenza, rigore e collaborazione.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>79</span>¬† <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#la-cultura-della-frode-nel-sistema-accademico",
    "href": "chapters/replication_crisis/01_crisis.html#la-cultura-della-frode-nel-sistema-accademico",
    "title": "79¬† La crisi della replicazione",
    "section": "\n79.4 La Cultura della Frode nel Sistema Accademico",
    "text": "79.4 La Cultura della Frode nel Sistema Accademico\nIn alcuni casi, la crisi della replicazione si intreccia con episodi di frode scientifica, rivelando un lato oscuro della ricerca accademica. Uno degli aspetti pi√π preoccupanti √® che il sistema accademico, con i suoi meccanismi di incentivo basati su pubblicazioni frequenti e finanziamenti competitivi, pu√≤ indirettamente favorire comportamenti disonesti. Questo sistema, orientato al publish or perish (pubblica o scompari), crea pressioni che talvolta spingono i ricercatori a compromettere l‚Äôintegrit√† scientifica per raggiungere i propri obiettivi di carriera.\n\n79.4.1 Il Caso Brian Wansink\nUn caso emblematico √® quello di Brian Wansink, ex ricercatore di spicco alla Cornell University, che ricevette cospicui finanziamenti federali durante l‚Äôamministrazione Obama. I suoi studi sul comportamento alimentare, come quello sugli uomini che mangiano di pi√π in presenza di donne o sull‚Äôeffetto dei nomi ‚Äúattraenti‚Äù dati alle verdure sul consumo da parte dei bambini, attirarono grande attenzione mediatica ma si rivelarono in seguito non replicabili. Le conseguenze per Wansink furono severe: diciotto suoi articoli furono ritirati, sette ricevettero ‚Äúespressioni di preoccupazione‚Äù, e quindici furono corretti. Nel 2019, Wansink si dimise dalla Cornell University dopo essere stato giudicato colpevole di cattiva condotta scientifica.\n\n79.4.2 Il Caso Sylvain Lesn√©\nUn altro esempio rilevante riguarda Sylvain Lesn√© e i suoi coautori che, nel 2006, pubblicarono su Nature un importante articolo sul morbo di Alzheimer. Questo lavoro era fondamentale per lo sviluppo dell‚Äôipotesi amiloide, un meccanismo proposto per spiegare come la malattia affligge le sue vittime. La ricerca sulla malattia di Alzheimer, che colpisce oltre 50 milioni di persone nel mondo, ha ricevuto oltre un miliardo di dollari in finanziamenti governativi fino al 2022, incoraggiata da studi come quello di Lesn√©.\nNel 2022, il neuroscienziato Matthew Schrag scopr√¨ immagini manipolate in questo e in molti altri articoli di Lesn√©, inclusi quelli che sostenevano l‚Äôipotesi amiloide. Le immagini erano state manualmente modificate e accorpate per mostrare falsamente supporto alle ipotesi degli articoli. Queste frodi passarono inosservate attraverso i processi di peer review formali di Nature e di altre sei riviste accademiche, venendo infine scoperte solo tramite canali non ufficiali.\nLe conseguenze di queste scoperte furono lente e frammentarie. Gli altri coautori dell‚Äôarticolo del 2006 alla fine accettarono di ritirarlo, ma non Lesn√© stesso. La lentezza della risposta a queste evidenze di frode, e il fatto che Lesn√© continui a essere finanziato dal National Institutes of Health e impiegato presso l‚ÄôUniversit√† del Minnesota, dimostra un fallimento sistemico nell‚Äôaffrontare la cattiva condotta scientifica.\n\n79.4.3 Altri Casi di Rilievo\nNel mondo accademico, diversi altri recenti scandali hanno messo in luce il problema della frode scientifica e le sue conseguenze spesso limitate per i responsabili. Ecco alcuni casi emblematici:\n\nMarc Tessier-Lavigne, ex presidente della Stanford University: Nel 2023, fu costretto a dimettersi dopo la rivelazione di dati falsificati in sue ricerche precedenti presso Genentech. Nonostante lo scandalo, Tessier-Lavigne ha subito conseguenze minime, diventando successivamente CEO di una nuova azienda di ricerca farmacologica. Lo scandalo fu portato alla luce grazie all‚Äôindagine condotta da Theo Baker, uno studente diciassettenne di Stanford.\n\nDan Ariely e Francesca Gino: Questi due rinomati psicologi, noti per le loro ricerche sulla disonest√† e il comportamento non etico, sono stati coinvolti in uno scandalo di frode scientifica.\n\nDan Ariely, nel 2021, fu implicato nella fabbricazione di dati in un articolo del 2012 sulla disonest√†.\nFrancesca Gino, docente presso la Harvard Business School, √® stata accusata di aver presentato lavori contenenti risultati falsificati. Il sito del Dipartimento ora riporta che √® in ‚Äúadministrative leave‚Äù.\n\n\n\nL‚Äôinefficacia delle istituzioni accademiche nel gestire la frode scientifica sembra riflettere un problema culturale di carattere sistemico. Gli incentivi attuali favoriscono la pubblicazione di risultati positivi e innovativi, spesso a scapito dell‚Äôintegrit√† scientifica. Gli studiosi che resistono a queste pressioni rischiano di essere emarginati, mentre chi adotta pratiche discutibili per ottenere risultati desiderati viene premiato con finanziamenti, promozioni e prestigio accademico.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>79</span>¬† <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#cosa-significa-fallimento-della-replicazione",
    "href": "chapters/replication_crisis/01_crisis.html#cosa-significa-fallimento-della-replicazione",
    "title": "79¬† La crisi della replicazione",
    "section": "\n79.5 Cosa Significa ‚ÄúFallimento della Replicazione‚Äù?",
    "text": "79.5 Cosa Significa ‚ÄúFallimento della Replicazione‚Äù?\nIl fallimento della replicazione non coincide necessariamente con l‚Äôidea che il fenomeno studiato sia inesistente. Al contrario, le cause di un esito negativo in un tentativo di replicazione possono essere molteplici e spesso difficili da individuare con precisione. Comprendere queste ragioni √® fondamentale per identificare le criticit√† metodologiche, migliorare il rigore scientifico e favorire il progresso della conoscenza. Al di l√† dei casi evidenti di frode, i fallimenti della replicazione rappresentano un‚Äôopportunit√† per riflettere sulla qualit√† delle pratiche di ricerca.\n\n79.5.1 Possibili Cause di Fallimento nella Replicazione\n\nFalsi positivi nello studio originale\nUn fallimento pu√≤ indicare che lo studio originale abbia rilevato un effetto inesistente per puro caso. Questo rischio √® particolarmente elevato in studi con campioni di piccole dimensioni e bassa potenza statistica, dove gli effetti riportati risultano spesso sovrastimati o instabili.\n\nFalsi negativi nella replica\nIl fallimento pu√≤ derivare da un falso negativo, ovvero la mancata rilevazione di un effetto realmente esistente. Le cause principali includono:\n\nDifferenze metodologiche o di popolazione tra studio originale e replica.\n\nConfondenti metodologici o una potenza statistica insufficiente.\n\nPresenza di variabili moderatrici che influenzano l‚Äôintensit√† dell‚Äôeffetto in determinati contesti.\n\n\n\n79.5.2 La Scienza tra Incertezza e Riproducibilit√†\nLa scienza raramente offre certezze assolute. Come evidenziato dall‚ÄôOpen Science Collaboration, un singolo studio, sia esso originale o di replica, non √® sufficiente a fornire una risposta definitiva. Solo replicazioni multiple e sistematiche possono distinguere effetti reali da errori casuali, offrendo una visione pi√π affidabile di un fenomeno. Questo approccio richiede tempo e risorse, ma rappresenta il cuore del metodo scientifico.\n\n79.5.3 Psicologia e Altri Campi\nSebbene la crisi della replicazione sia stata ampiamente discussa in psicologia, problemi simili affliggono molte altre discipline scientifiche. Studi di replicazione hanno evidenziato risultati preoccupanti: in oncologia, meno della met√† degli studi replicati ha prodotto risultati coerenti, con tassi di riproducibilit√† estremamente bassi in alcuni casi; nelle neuroscienze, i tentativi di replicare correlazioni cervello-comportamento hanno mostrato un altissimo tasso di insuccesso. Anche in discipline come l‚Äôeconomia e la filosofia sperimentale, pur registrando tassi di replicazione relativamente pi√π elevati, permangono dubbi sulla selezione degli studi replicati e sulla rappresentativit√† dei risultati (Pennington, 2023).\nQuesti dati dimostrano che la problematica della replicazione non √® esclusiva della psicologia, ma comune a diverse aree del sapere. Tuttavia, sollevano anche un interrogativo critico: √® corretto parlare di ‚Äúcrisi‚Äù o si tratta piuttosto di una fase di trasformazione necessaria per migliorare il rigore e la trasparenza nella ricerca scientifica?",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>79</span>¬† <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#dibattito-sulla-natura-della-crisi",
    "href": "chapters/replication_crisis/01_crisis.html#dibattito-sulla-natura-della-crisi",
    "title": "79¬† La crisi della replicazione",
    "section": "\n79.6 Dibattito sulla Natura della Crisi",
    "text": "79.6 Dibattito sulla Natura della Crisi\nIl tema della crisi della replicazione ha suscitato un dibattito acceso e opinioni contrastanti all‚Äôinterno della comunit√† scientifica:\n\nApproccio alle repliche: Alcuni ricercatori ritengono che le repliche esatte siano poco significative, preferendo le repliche concettuali che possano approfondire la comprensione di un fenomeno. Altri, invece, sostengono che solo repliche rigorose ed esatte siano in grado di verificare la robustezza di un effetto, garantendo maggiore affidabilit√†.\nInterpretazione dei dati dell‚ÄôOpen Science Collaboration (OSC): Il tasso di successo delle repliche riportato dall‚ÄôOSC, pari al 36%, ha alimentato ulteriori discussioni. Alcuni attribuiscono questo risultato a differenze metodologiche tra studi originali e tentativi di replica, come campioni diversi o contesti modificati. Tuttavia, ricerche successive hanno smentito queste ipotesi, indicando che tali variazioni non spiegano interamente i bassi tassi di replicazione.\n\nInvece di considerare i fallimenti di replicazione come una crisi, molti studiosi li interpretano come un‚Äôopportunit√† per rafforzare la scienza. La replicazione, infatti, rappresenta un elemento fondamentale del metodo scientifico: permette di identificare i limiti di un fenomeno e di migliorare la comprensione delle condizioni in cui si manifesta. Ogni fallimento diventa, cos√¨, uno stimolo per il progresso.\nQuesta visione ha dato origine a un movimento noto come ‚Äúrivoluzione della credibilit√†‚Äù, che punta a migliorare la qualit√† della ricerca attraverso trasparenza, autocorrezione e valorizzazione delle repliche. Progetti come il Loss of Confidence dimostrano che riconoscere i limiti e le incertezze degli studi precedenti non rappresenta una debolezza, ma un segno di integrit√† scientifica.\nIl passaggio dalla percezione di crisi a una rivoluzione della credibilit√† rappresenta un profondo cambiamento culturale nella comunit√† accademica. La scienza non √® un processo statico, ma un percorso dinamico che evolve grazie al confronto critico e alla riflessione. In questa prospettiva, ogni fallimento nella replicazione non √® un punto d‚Äôarrivo, ma un trampolino di lancio verso una conoscenza pi√π affidabile e trasparente.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>79</span>¬† <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#cause-della-crisi",
    "href": "chapters/replication_crisis/01_crisis.html#cause-della-crisi",
    "title": "79¬† La crisi della replicazione",
    "section": "\n79.7 Cause della Crisi",
    "text": "79.7 Cause della Crisi\n\n79.7.1 Incentivi Accademici e la Dominanza della Quantit√† sulla Qualit√†\nPer comprendere a fondo le problematiche che affliggono il mondo della ricerca, √® essenziale considerare il contesto lavorativo in cui operano i ricercatori. Sebbene spesso vengano idealizzati come figure obiettive e razionali, √® fondamentale ricordare che sono anche esseri umani, soggetti a pressioni professionali, responsabilit√† economiche e ambizioni di carriera. Il loro lavoro √® costantemente sottoposto a valutazione: oltre a gestire attivit√† didattiche e amministrative, devono pubblicare articoli su riviste di prestigio e assicurarsi finanziamenti per sostenere i loro gruppi di ricerca. Questo sistema premia la quantit√† a discapito della qualit√†, favorendo una mentalit√† di ‚Äúpubblica o perisci‚Äù.\nLa pressione a pubblicare incessantemente √® una delle principali cause dei problemi che alimentano la crisi di replicazione nella scienza. La cultura del ‚Äúpublish or perish‚Äù spinge i ricercatori a produrre rapidamente risultati rilevanti, spesso a scapito della rigorosit√† metodologica e della riproducibilit√† (Gopalakrishna et al., 2022; Grimes et al., 2018).\nQuesta situazione genera un paradosso: ci√≤ che favorisce la carriera individuale di uno scienziato non sempre coincide con gli interessi del progresso scientifico. Le motivazioni intrinseche di contribuire alla conoscenza vengono spesso offuscate da motivazioni estrinseche legate a indicatori di produttivit√† accademica. Non sorprende, quindi, che oltre il 60% dei ricercatori individui questa pressione come una delle principali cause dei problemi legati alla replicazione e alla riproducibilit√†.\n\n79.7.2 Bias Cognitivi e Distorsioni nella Ricerca\nI bias cognitivi rappresentano un ulteriore ostacolo alla qualit√† della ricerca. Tra i principali si trovano:\n\n\nBias di conferma: la tendenza a cercare o interpretare informazioni che confermano le proprie ipotesi iniziali, trascurando dati contrari.\n\nApofenia: il riconoscimento di schemi in dati casuali, spesso combinato con una preferenza per risultati positivi.\n\nBias retrospettivo: la convinzione che un evento fosse prevedibile solo dopo che si √® verificato, portando i ricercatori a presentare risultati in modo fuorviante.\n\nQuesti bias favoriscono la ricerca di risultati positivi a scapito di quelli nulli o contrari, contribuendo a creare un problema pi√π grande: il bias di pubblicazione.\n\n79.7.3 Bias di Pubblicazione e il Problema dei ‚ÄúFile Drawer‚Äù\nIl sistema di pubblicazione accademica incentiva risultati innovativi e positivi, spesso trascurando studi con risultati nulli o repliche. Questo bias, noto come file drawer problem, descrive la tendenza a relegare nei ‚Äúcassetti‚Äù studi non statisticamente significativi, rendendoli inaccessibili e distorcendo la letteratura scientifica.\nIn psicologia, l‚Äôimpatto di questo fenomeno √® particolarmente grave. Studi hanno rilevato che oltre il 90% degli articoli in psicologia riporta risultati positivi, una percentuale notevolmente pi√π alta rispetto ad altre discipline. Questo non solo crea una rappresentazione distorta della realt√†, ma amplifica il rischio di undead theories, teorie prive di solide basi empiriche che continuano a dominare il dibattito scientifico.\n\n79.7.4 Pratiche di Ricerca Dubbiamente Etiche\nLa pressione a pubblicare ha portato all‚Äôemergere di comportamenti noti come Questionable Research Practices (QRPs). Tra questi:\n\n\nP-hacking: manipolazione dei dati o analisi fino a ottenere un p-value significativo (&lt; 0.05).\n\nHARKing (Hypothesizing After Results are Known): modificare l‚Äôipotesi iniziale per adattarla ai risultati ottenuti.\n\nStopping opzionale: interrompere la raccolta dei dati quando si raggiunge un p-value desiderato.\n\nQueste pratiche, pur non essendo sempre considerate frodi, distorcono i risultati e compromettono la replicabilit√† degli studi, creando teorie difficili da falsificare.\n\n79.7.5 La Centralit√† dei Valori-p e la Crisi della Significativit√† Statistica\nIl valore-p, elemento centrale della metodologia scientifica basata sull‚Äôipotesi nulla (Null Hypothesis Significance Testing), √® diventato una ‚Äúvaluta‚Äù per la pubblicazione. Tuttavia, affidarsi esclusivamente ai valori-p presenta gravi limiti:\n\n\nParadosso di Lindley: con campioni di grandi dimensioni, valori-p vicini a 0.05 possono supportare l‚Äôipotesi nulla invece di confutarla.\n\nDistorsioni da QRPs: l‚Äôutilizzo di pratiche discutibili pu√≤ produrre falsi positivi statisticamente significativi.\n\nBench√© alcuni studiosi abbiano proposto l‚Äôabbassamento della soglia di significativit√† statistica a 0.005 o l‚Äôintegrazione dei valori-p con stime degli effetti e intervalli di confidenza, il punto centrale continua ad essere il fatto che l‚Äôenfasi dovrebbe spostarsi dai risultati statistici alla qualit√† metodologica degli studi.\nPer affrontare questi problemi, √® necessario un cambiamento culturale e strutturale. La trasparenza, l‚Äôautocorrezione e l‚Äôadozione di pratiche come la preregistrazione degli studi possono aiutare a ridurre l‚Äôimpatto dei bias e delle QRPs. Inoltre, incentivare repliche rigorose e promuovere un sistema di pubblicazione che premi la qualit√† rispetto alla quantit√† sono passi fondamentali per migliorare la credibilit√† della scienza.\n\n79.7.6 Campioni Troppo Piccoli\nUno dei fattori chiave che contribuiscono alla crisi della replicazione in psicologia √® l‚Äôuso di campioni di dimensioni ridotte. Questo approccio ha permesso ai ricercatori di massimizzare la quantit√† di pubblicazioni a scapito della qualit√† e dell‚Äôaffidabilit√† degli effetti rilevati. Higginson e Munaf√≤ (2016) sottolineano come questo fenomeno rappresenti una ‚Äúselezione naturale della cattiva scienza‚Äù, dove incentivi strutturali premiano metodologie di ricerca poco rigorose.\nContrariamente a quanto si potrebbe pensare, ottenere un effetto significativo con un campione piccolo non garantisce che lo stesso effetto rimanga significativo con un campione pi√π grande. Questo problema √® strettamente legato alla potenza statistica, che rappresenta la probabilit√†, nel lungo periodo, di rifiutare correttamente l‚Äôipotesi nulla quando l‚Äôipotesi alternativa √® vera. Una potenza statistica bassa comporta un‚Äôelevata probabilit√† di errori di Tipo II (falsi negativi) e, allo stesso tempo, riduce la probabilit√† che un risultato significativo rifletta un effetto reale.\nIn psicologia, la potenza statistica viene solitamente fissata a un minimo dell‚Äô80%, il che significa che, nel lungo termine, uno studio dovrebbe avere l‚Äô80% di possibilit√† di rilevare un effetto reale. Tuttavia, molti studi pi√π datati raramente menzionano la potenza statistica, nonostante il concetto sia noto dagli anni ‚Äô30. Questo ha contribuito a generare una letteratura scientifica con effetti sovrastimati o poco affidabili.\nIn un approccio frequentista, per calcolare la potenza di uno studio, √® necessario conoscere almeno due dei seguenti tre parametri: dimensione dell‚Äôeffetto atteso, criterio di significativit√† e dimensione del campione pianificata. Per esempio, un ricercatore che si aspetta di trovare un effetto ‚Äúmedio‚Äù (Cohen‚Äôs d = 0.50) con un criterio di significativit√† di p &lt; .05 pu√≤ determinare la dimensione del campione necessaria per garantire una potenza sufficiente. Tuttavia, molti studi psicologici hanno ignorato questo tipo di pianificazione, basandosi su campioni troppo piccoli per rilevare effetti affidabili.\nL‚Äôuso di campioni piccoli, combinato con pratiche discutibili di ricerca (Questionable Research Practices, QRPs) e bias di pubblicazione, ha portato a una letteratura scientifica piena di effetti inflazionati. Ad esempio, meta-analisi iniziali sul concetto di esaurimento dell‚Äôego (ego depletion) stimavano un effetto medio (d = 0.62). Tuttavia, repliche successive hanno trovato effetti molto pi√π piccoli, spesso inferiori a d = 0.10. Allo stesso modo, il progetto dell‚ÄôOpen Science Collaboration (2015) ha evidenziato che le dimensioni degli effetti nelle repliche erano, in media, dimezzate rispetto agli studi originali.\nCampioni di piccole dimensioni non solo riducono la probabilit√† di rilevare effetti reali, ma compromettono anche la credibilit√† dei risultati significativi. Una bassa potenza statistica mina l‚Äôobiettivo fondamentale della ricerca scientifica, limitando la capacit√† di trarre conclusioni solide e contribuendo alla crisi della replicazione. Per migliorare la qualit√† della scienza, √® essenziale adottare pratiche di ricerca pi√π rigorose, pianificando adeguatamente la dimensione del campione e garantendo una potenza statistica sufficiente.\n\n79.7.7 La Misurazione: Un Problema Sottovalutato\nOltre alle dimensioni campionarie inadeguate, la psicologia potrebbe soffrire di problemi legati alla misurazione. Per rispondere a domande scientifiche, i ricercatori devono definire e misurare con precisione il costrutto oggetto di indagine. Ad esempio, per investigare se una mentalit√† di crescita possa migliorare l‚Äôintelligenza, un ricercatore deve prima definire e poi misurare sia la mentalit√† che l‚Äôintelligenza. Tuttavia, la misurazione √® un processo complesso e impegnativo.\nL‚Äôintelligenza √® un costrutto latente, il che significa che, a differenza dell‚Äôaltezza di una persona, non pu√≤ essere osservata o misurata direttamente. Gli psicologi inferiscono l‚Äôintelligenza stimando il quoziente intellettivo (QI) di un individuo, basandosi sulle risposte a numerose domande di un test di intelligenza, adattate all‚Äôet√† del partecipante. Ma come possiamo sapere se il QI rappresenta un buon indicatore dell‚Äôintelligenza? √à necessario valutare la validit√† di costrutto, definita come la capacit√† di una misura di comportarsi in modo coerente con le ipotesi teoriche (Cronbach e Meehl, 1955; Fink, 2010). Alcuni ricercatori hanno sostenuto che una spiegazione spesso trascurata della crisi della replicazione risieda nella scarsa validit√† di costrutto delle nostre misure (Lilienfeld e Strother, 2020; Loken e Gelman, 2017).\nPer evidenziare il problema della misurazione in psicologia, Flake e colleghi hanno condotto una revisione di articoli pubblicati in una rivista prestigiosa. La loro analisi ha mostrato che molte scale di misurazione utilizzate non avevano una chiara fonte dichiarata, mentre altre erano state sviluppate senza una documentazione adeguata. Inoltre, una parte significativa delle scale citate era stata modificata rispetto alla versione originale, rendendo sconosciute le loro propriet√† psicometriche.\nGli autori hanno anche rilevato l‚Äôuso di Pratiche di Misurazione Discutibili (Questionable Measurement Practices, QMPs), che includono la mancata divulgazione di informazioni sulla validit√† delle misure quando questa non risulta soddisfacente. Questi problemi suggeriscono che molti costrutti psicologici non siano adeguatamente validati, un fattore che potrebbe contribuire alle difficolt√† di replicazione degli studi.\nAltri ricercatori hanno argomentato che problemi di validit√† interna ed esterna possano contribuire alla crisi della replicazione (Fabrigar et al., 2020). La validit√† interna si riferisce a come uno studio stabilisce una relazione di causa-effetto tra le variabili indipendenti e dipendenti (Cook e Campbell, 1979). Fabrigar et al.¬†suggeriscono che un tentativo di replicazione possa fallire se:\n\nLo studio originale ha sofferto di minacce alla validit√† che hanno causato un effetto spurio (alta validit√† interna nella replica).\nI ricercatori introducono elementi assenti nello studio originale (bassa validit√† interna nella replica).\n\nLa validit√† esterna riguarda la possibilit√† di generalizzare i risultati di uno studio ad altri contesti o popolazioni. Questo pu√≤ influenzare le repliche se, ad esempio, la replica viene condotta su una popolazione diversa o se i materiali dello studio sono tradotti da un‚Äôaltra lingua, causando incomprensioni nei partecipanti.\nPer sintetizzare questi problemi, Flake e Fried (2020) li definiscono ‚Äúmeasurement schmeasurement‚Äù, espressione che descrive la mancanza di attenzione verso la validit√† delle misure nella scienza psicologica. Se le misure utilizzate in uno studio non sono valide, ne consegue che anche i risultati e le conclusioni tratte non possono essere considerati affidabili. Quando tali studi vengono replicati, potrebbero essere destinati al fallimento ancor prima di iniziare.\n\n79.7.8 La Novit√† a Scapito della Replicazione: Una Distorsione nella Ricerca\nL‚Äôenfasi eccessiva sui risultati innovativi e il valore attribuito alle scoperte significative stanno incentivando pratiche di ricerca distorte, favorendo la sovrarappresentazione di risultati positivi e una mancanza di rigore metodologico (Ferguson & Heene, 2012; Ware & Munaf√≤, 2015).\nLa psicologia sperimentale, nata nel 1879 con il primo laboratorio fondato da Wilhelm Wundt, si trova oggi a fronteggiare una crisi di replicazione nonostante oltre un secolo di progresso scientifico. Una delle principali cause √® la scarsa attenzione dedicata agli studi di replicazione, storicamente poco valorizzati e raramente premiati nelle scienze sociali.\nLa cultura accademica attuale privilegia la novit√† e i risultati positivi, relegando i risultati nulli e gli studi di replicazione a un ruolo marginale. Questo fenomeno riflette ci√≤ che Antonakis (2017) definisce significosis ‚Äì un‚Äôossessione per i risultati significativi ‚Äì e neofilia ‚Äì un‚Äôeccessiva enfasi sulla novit√†. Gi√† Sterling (1959) aveva messo in guardia contro il rischio che i ricercatori testassero ripetutamente un‚Äôipotesi fino a ottenere, per puro caso, un risultato significativo, senza verificarlo attraverso replicazioni. In assenza di queste verifiche, interi ambiti di studio possono essere costruiti su un numero allarmante di affermazioni non supportate da dati solidi.\nQuesto squilibrio si riflette non solo nella letteratura scientifica, ma anche nei progetti di ricerca condotti dagli studenti. Le tesi di laurea in psicologia, spesso realizzate in autonomia, senza finanziamenti e con tempistiche ridotte, soffrono degli stessi problemi della ricerca accademica: campioni di piccole dimensioni, studi sottopotenziati e un‚Äôelevata probabilit√† di falsi positivi. Se pubblicati selettivamente, questi progetti rischiano di premiare la fortuna pi√π della qualit√† scientifica.\nIniziative come il Collaborative Replications and Education Project (CREP) rappresentano un passo verso un cambiamento culturale. CREP incoraggia gli studenti a condurre studi di replicazione come parte del loro percorso formativo, promuovendo una scienza pi√π collaborativa, rigorosa e orientata alla verifica dei risultati, contrastando cos√¨ la prevalenza della novit√† fine a se stessa.\n\n79.7.9 La scienza non si autocorregge come dovrebbe\nUn principio cardine della scienza √® l‚Äôautocorrezione, ma nella pratica accademica moderna, questo processo sembra spesso ostacolato da incentivi e preoccupazioni reputazionali. I ricercatori, pressati dalle scadenze per nuovi progetti o richieste di finanziamento, raramente dedicano il tempo necessario a rivedere e correggere i propri lavori passati. Questo mancato impegno rappresenta una delle spiegazioni della crisi di replicazione.\nUn esempio significativo √® il Registered Replication Report dello studio di Srull e Wyer (1979), replicato da McCarthy et al.¬†(2018). Lo studio originale aveva mostrato che il priming con stimoli aggressivi portava i partecipanti a interpretare un comportamento ambiguo come pi√π ostile. Tuttavia, il tentativo di replicazione ha rilevato un effetto trascurabile. Una possibile spiegazione √® che alcune statistiche dello studio originale fossero riportate in modo errato, un errore che, nonostante tutto, non √® mai stato corretto. Similmente, altri casi documentano gravi discrepanze nei dati riportati in letteratura, come dimostrato da van der Zee et al.¬†(2017) nel loro riesame di articoli del Cornell Food Lab, che ha rivelato oltre 150 incongruenze.\nLa microbiologa Elizabeth Bik ha inoltre evidenziato che la manipolazione di immagini scientifiche √® diventata una forma emergente di cattiva condotta, volta a rendere i risultati pi√π impressionanti o a mascherare dati problematici. Sebbene alcuni casi di manipolazione portino a ritrazioni o correzioni, il lavoro di revisione √® spesso svolto da altri ricercatori come attivit√† volontaria, suggerendo che la scienza sia pi√π ‚Äúeterocorrettiva‚Äù che autocorrettiva.\nNonostante le difficolt√†, il processo di autocorrezione √® fondamentale per il progresso scientifico. Vazire (2020) sostiene che il disagio provocato dalla revisione critica sia salutare e necessiti di una maggiore umilt√† intellettuale da parte dei ricercatori. Questo include il riconoscimento pubblico delle limitazioni dei propri studi e, quando necessario, la pubblicazione di correzioni o dichiarazioni di perdita di fiducia nei risultati originali.\n\n79.7.10 La Scienza Chiusa come Ostacolo alla Replicazione\nUno degli ostacoli principali alla replicazione √® la mancanza di trasparenza e dettaglio negli studi precedenti. In un sistema di ‚Äúscienza chiusa,‚Äù in cui dati e metodi sono trattati come segreti industriali, ricreare esperimenti e verificare analisi diventa un‚Äôimpresa ardua, se non impossibile. Questa opacit√† interessa molti aspetti della ricerca, dai materiali utilizzati ai dati raccolti, fino alle scelte analitiche effettuate durante lo studio.\nPratiche come la reportistica selettiva e la flessibilit√† non dichiarata nei metodi e nei dati compromettono l‚Äôintegrit√† della scienza. La riluttanza a condividere dati e materiali, insieme al bias di pubblicazione che favorisce i risultati significativi rispetto a quelli nulli, amplifica ulteriormente il problema (Bruton et al., 2020; Nosek et al., 2012).\nUn esempio concreto riguarda le decisioni prese durante l‚Äôanalisi dei dati, come la gestione dei valori anomali o le correzioni per analisi multiple. Queste scelte possono avere un impatto notevole sui risultati, ma se non vengono documentate in modo trasparente, altri ricercatori non saranno in grado di replicare gli stessi risultati. Questo problema √® noto come il giardino dei sentieri che si biforcano (garden of forking paths), dove una serie di decisioni non esplicitate porta a risultati divergenti e difficili da verificare (Gelman & Loken, 2013).\n\n\n\n\n\n\nLo psicologo Paul Meehl condusse uno studio su un campione di cinquantasettamila studenti delle scuole superiori del Minnesota, indagando su variabili quali religione, abitudini nel tempo libero, ordine di nascita, numero di fratelli, piani post-diploma e numerosi altri aspetti (Meehl, 2012). Complessivamente, le diverse risposte dei partecipanti potevano essere combinate in 990 modi distinti, permettendo analisi del tipo: ‚ÄúGli studenti appassionati di cucina hanno una maggiore probabilit√† di essere figli unici?‚Äù o ‚ÄúGli studenti provenienti da famiglie battiste sono pi√π inclini a partecipare a club politici scolastici?‚Äù. Meehl evidenzi√≤ che, analizzando i dati, il 92% di queste possibili combinazioni risultava in correlazioni statisticamente significative. Queste differenze, sebbene reali, presumibilmente derivano da cause multifattoriali e complesse.\nAndrew Gelman ha denominato questo fenomeno Il Giardino dei Sentieri che si Biforcano [Garden of Forking Paths; Gelman & Loken (2013)], riferendosi ai molteplici gradi di libert√† a disposizione del ricercatore nell‚Äôanalisi dei dati. Come nell‚Äôesempio di Meehl, √® possibile esaminare le differenze intergruppo (se questo √® l‚Äôoggetto di interesse) da molteplici prospettive. Con un campione sufficientemente ampio, alcune di queste differenze risulteranno ‚Äústatisticamente significative‚Äù. Ci√≤ indica che, in quello specifico campione, quel particolare aspetto dei dati √® rilevante. Tuttavia, questa differenza ‚Äústatisticamente significativa‚Äù non sar√† necessariamente generalizzabile ad un altro campione, il quale presenter√† le proprie idiosincrasie.\nIn altri termini, come sottolineato da Gelman & Loken (2013), l‚Äôapproccio basato sul test dell‚Äôipotesi nulla si limita a ‚Äúdescrivere il rumore‚Äù. Da un punto di vista teorico, simili esercizi statistici risultano privi di valore euristico e non contribuiscono in nessun modo all‚Äôavanzamento delle conoscenze sul fenomeno oggetto di studio.\nIn un‚Äôottica di inferenza statistica, questo problema √® riconducibile al concetto di ‚Äúp-hacking‚Äù o ‚Äúdata dredging‚Äù, dove l‚Äôesplorazione esaustiva di molteplici ipotesi statistiche su un singolo set di dati pu√≤ portare a falsi positivi e a una sovrastima della significativit√† statistica.\n\n\n\nLa soluzione √® chiara: promuovere una cultura di apertura, rendendo dati e metodi accessibili. Nonostante i progressi tecnologici che facilitano la condivisione, questa pratica rimane poco diffusa. Sebbene esistano ragioni valide per non condividere i dati, come la tutela dell‚Äôanonimato dei partecipanti, tali motivazioni dovrebbero essere dichiarate in modo esplicito e rigoroso.\nQuesti ostacoli sottolineano l‚Äôurgenza di una trasformazione culturale all‚Äôinterno della comunit√† scientifica, che favorisca trasparenza e collaborazione. Affrontare queste limitazioni strutturali √® essenziale per superare la crisi di replicazione, permettendo alla scienza di avanzare in modo pi√π affidabile e autoregolarsi nel tempo.\n\n79.7.11 La Probabilit√† Inversa\nOltre a questi fattori, alcuni studiosi sostengono che la radice della crisi della replicazione sia ancora pi√π profonda e risieda nell‚Äôapproccio statistico stesso, ampiamente adottato dalla comunit√† scientifica (Chivers, 2024; Gelman & Loken, 2014; Loken & Gelman, 2017). Questo punto di vista suggerisce che le difficolt√† nella replicazione dei risultati non siano solo il prodotto di comportamenti individuali discutibili, ma derivino in larga parte da un‚Äôinterpretazione e un‚Äôapplicazione problematica dei metodi statistici.\nPer comprendere meglio questa questione, dobbiamo tornare alle basi della statistica inferenziale. L‚Äôapproccio frequentista, dominante nella ricerca scientifica, si basa sulle probabilit√† di campionamento. Questo metodo, che risale a Jakob Bernoulli nel XVIII secolo, calcola la probabilit√† di osservare certi dati assumendo che una determinata ipotesi sia vera. Il famoso ‚Äúp-value‚Äù √® un esempio di questa logica: esso indica la probabilit√† di ottenere risultati estremi quanto o pi√π estremi di quelli osservati, supponendo che l‚Äôipotesi nulla sia vera.\nTuttavia, questo approccio ha un limite fondamentale: non ci dice direttamente quanto √® probabile che la nostra ipotesi sia vera alla luce dei dati raccolti. In altre parole, non fornisce una ‚Äúprobabilit√† inferenziale‚Äù, cio√® la probabilit√† che l‚Äôipotesi sia corretta in base ai risultati ottenuti. Qui entra in gioco l‚Äôapproccio bayesiano. Il teorema di Bayes offre un metodo per calcolare proprio questa probabilit√† inferenziale. L‚Äôapproccio bayesiano tiene conto non solo dei dati osservati, ma anche delle conoscenze pregresse (le ‚Äúprior‚Äù) relative all‚Äôipotesi in esame.\nLa differenza tra questi due approcci √® cruciale. Mentre il p-value ci dice quanto sono improbabili i nostri dati se l‚Äôipotesi nulla √® vera, l‚Äôapproccio bayesiano ci fornisce la probabilit√† che la nostra ipotesi sia vera alla luce dei dati raccolti e delle conoscenze precedenti.\n\n79.7.12 Implicazioni per la Pratica Scientifica\nQuesta distinzione ha implicazioni profonde per la pratica scientifica. L‚Äôuso esclusivo dell‚Äôapproccio frequentista pu√≤ portare a sovrastimare la forza delle evidenze a favore di un‚Äôipotesi, specialmente quando si lavora con campioni piccoli o si conducono molti test statistici, come spesso accade in psicologia.\nAlcune soluzioni proposte per affrontare la crisi della replicazione includono:\n\nAbbassare la soglia di significativit√† statistica, rendendo pi√π difficile dichiarare un risultato ‚Äúsignificativo‚Äù.\nRichiedere la preregistrazione delle ipotesi per prevenire l‚ÄôHARKing (Hypothesizing After Results are Known).\nFar s√¨ che le riviste accettino gli articoli basandosi sui metodi piuttosto che sui risultati, per evitare il bias verso la pubblicazione di risultati solo ‚Äúpositivi‚Äù o ‚Äúnuovi‚Äù.\n\nTuttavia, queste soluzioni, pur utili, non affrontano il problema fondamentale dell‚Äôinterpretazione delle evidenze statistiche. L‚Äôadozione di un approccio bayesiano offre una soluzione pi√π radicale, fornendo un quadro pi√π completo e realistico della forza delle evidenze a favore o contro un‚Äôipotesi scientifica.\n\n79.7.12.1 Guardare i Dati\nConsideriamo una simulazione, ispirata da Lakens (2015), che illustra come una pratica apparentemente innocua ‚Äì osservare i risultati man mano che vengono raccolti nell‚Äôapproccio frequentista ‚Äì possa avere conseguenze significative sulle conclusioni di uno studio. In particolare, questa pratica pu√≤ influire sulla probabilit√† di ottenere un risultato statisticamente significativo.\nNella simulazione seguente, due campioni casuali vengono estratti dalla stessa popolazione normale di partenza. Di conseguenza, l‚Äô‚Äúipotesi nulla‚Äù √® vera: non c‚Äô√® differenza tra le medie delle popolazioni. Tuttavia, a causa della variabilit√† campionaria, il p-valore risulta fortemente influenzato da ogni singola osservazione aggiunta al campione.\n\nsimulate_t_tests &lt;- function(seed, max_sample_size, mu = 0, sigma = 1) {\n  set.seed(seed)\n\n  # Intervallo di grandezza campionaria\n  sample_sizes &lt;- seq(2, max_sample_size, by = 2)\n  p_values &lt;- numeric(length(sample_sizes))\n\n  # Genera due campioni grandi iniziali da una distribuzione normale\n  full_sample1 &lt;- rnorm(max_sample_size, mean = mu, sd = sigma)\n  full_sample2 &lt;- rnorm(max_sample_size, mean = mu, sd = sigma)\n\n  # Simulazione\n  for (i in seq_along(sample_sizes)) {\n    n &lt;- sample_sizes[i]\n\n    # Estrai sottoinsiemi incrementali dai campioni completi\n    sample1 &lt;- full_sample1[1:n]\n    sample2 &lt;- full_sample2[1:n]\n\n    # Esegui il t-test per il confronto delle medie di due gruppi indipendenti\n    t_test &lt;- t.test(sample1, sample2, var.equal = TRUE)\n    p_values[i] &lt;- t_test$p.value\n  }\n\n  # Crea il grafico del p-valore in funzione della grandezza campionaria\n  plot(\n    sample_sizes, p_values, type = \"l\", col = \"#b97c7c\",\n    xlab = \"Grandezza Campionaria\", ylab = \"P-valore\",\n    main = \"P-valore in funzione della grandezza campionaria\"\n  )\n  abline(h = 0.05, col = \"#8f2727\", lty = 2, lwd = 1.5)\n  legend(\"topright\", legend = \"Significativit√† a 0.05\", col = \"#8f2727\", lty = 2, cex = 0.8)\n}\n\nNelle due simulazioni seguenti, osserviamo come il p-valore cambi progressivamente aumentando la dimensione dei campioni casuali da \\(n = 2\\) a \\(n = 300\\). √à evidente come il p-valore vari drasticamente con l‚Äôaggiunta di nuove osservazioni ai campioni. Inoltre, in alcune configurazioni, il p-valore pu√≤ scendere al di sotto della soglia critica di 0.05 per puro caso. Se un ricercatore interrompesse la raccolta dei dati in quel momento, otterrebbe un risultato ‚Äústatisticamente significativo‚Äù, pur avendo campioni estratti dalla stessa popolazione.\n\nsimulate_t_tests(seed = 1234, max_sample_size = 300, mu = 0, sigma = 2)\nsimulate_t_tests(seed = 2, max_sample_size = 300, mu = 0, sigma = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuesta simulazione mette in evidenza una limitazione fondamentale dell‚Äôapproccio frequentista: ogni test statistico considera esclusivamente i dati del campione corrente, ignorando le conoscenze accumulate in precedenza. Questo rende il processo decisionale estremamente volatile, poich√©, teoricamente, ad ogni nuovo studio si ‚Äúdimentica‚Äù tutta l‚Äôinformazione derivante dagli studi precedenti.\n\n79.7.12.2 Analisi Bayesiana\nL‚Äôapproccio bayesiano offre una soluzione elegante a questo problema. Nel framework bayesiano, la distribuzione a posteriori (cio√®, la nostra convinzione aggiornata dopo aver osservato i dati) bilancia sempre l‚Äôinformazione a priori (ci√≤ che sapevamo prima dell‚Äôesperimento) con la verosimiglianza (ci√≤ che i dati ci dicono). Questo equilibrio √® particolarmente prezioso quando i dati sono deboli o contengono molto rumore, come nel caso dei dati della simulazione che stiamo discutendo. In tali situazioni, l‚Äôinformazione a priori assume un ruolo pi√π rilevante, impedendo conclusioni affrettate basate su dati poco informativi.\nPer illustrare questa differenza, consideriamo l‚Äôanalisi bayesiana dei dati simulati in precedenza. Se questi dati vengono analizzati con l‚Äôapproccio frequentista, forniscono un risultato ‚Äústatisticamente significativo‚Äù, suggerendo una differenza tra i due gruppi.\nTuttavia, analizzando gli stessi dati con un approccio bayesiano, otteniamo un intervallo di credibilit√† al 95% compreso tra -0.52 e 1.12. Poich√© questo intervallo include lo zero, possiamo affermare, con un livello di certezza soggettiva del 95%, che non c‚Äô√® una differenza sostanziale tra le medie delle due popolazioni da cui sono stati estratti i campioni.\nQuesta discrepanza nei risultati evidenzia un punto cruciale: l‚Äôapproccio bayesiano √® pi√π resistente ai falsi positivi in presenza di dati rumorosi o campioni piccoli. Invece di forzare una decisione binaria (significativo/non significativo) basata su una soglia arbitraria, l‚Äôanalisi bayesiana fornisce una rappresentazione pi√π sfumata e realistica dell‚Äôincertezza associata alle nostre conclusioni.\nInoltre, l‚Äôapproccio bayesiano offre il vantaggio di essere cumulativo: ogni nuovo studio non parte da zero, ma incorpora naturalmente le conoscenze precedenti attraverso la distribuzione a priori.\n\n# Imposta il seme per la riproducibilit√†\nset.seed(12)\n\n# Parametri della distribuzione normale\nmu &lt;- 0\nsigma &lt;- 2\nmax_sample_size &lt;- 50\n\n# Genera due campioni indipendenti\nfull_sample1 &lt;- rnorm(max_sample_size, mean = mu, sd = sigma)\nfull_sample2 &lt;- rnorm(max_sample_size, mean = mu, sd = sigma)\n\n\n# Prepara i dati per Stan\nstan_data &lt;- list(\n  N1 = length(full_sample1),\n  N2 = length(full_sample2),\n  y1 = full_sample1,\n  y2 = full_sample2\n)\n\n# Visualizza i dati preparati\nprint(stan_data)\n#&gt; $N1\n#&gt; [1] 50\n#&gt; \n#&gt; $N2\n#&gt; [1] 50\n#&gt; \n#&gt; $y1\n#&gt;  [1] -2.9611  3.1543 -1.9135 -1.8400 -3.9953 -0.5446 -0.6307 -1.2565 -0.2129\n#&gt; [10]  0.8560 -1.5554 -2.5878 -1.5591  0.0239 -0.3048 -1.4069  2.3778  0.6810\n#&gt; [19]  1.0139 -0.5866  0.4473  4.0144  2.0240 -0.6049 -2.0505 -0.5348 -0.3982\n#&gt; [28]  0.2622  0.2916  0.7241  1.3480  4.1441 -1.0821 -2.1410 -0.7449 -0.9703\n#&gt; [37]  0.5496 -0.9590  1.5962 -2.0089  0.2100 -2.3120  1.1563 -3.1913 -0.6170\n#&gt; [46]  0.8989 -1.9541  0.3800  1.4629 -0.9852\n#&gt; \n#&gt; $y2\n#&gt;  [1] -0.085370 -0.225341  0.913654  4.040670 -2.101780  1.469304  1.078499\n#&gt;  [8] -2.628546 -0.500077  0.628409  0.813093  1.988841  1.711537  0.394258\n#&gt; [15]  1.668650  1.693580  3.908211 -4.298520  1.942241  2.290123 -1.050801\n#&gt; [22]  0.500640 -0.858813 -0.365039 -0.206621 -1.267676 -2.542108 -0.767901\n#&gt; [29]  1.033512 -0.355937  0.008516 -2.548119 -0.404221  2.328932 -0.046759\n#&gt; [36]  1.794313 -0.353449  2.227418 -1.083778 -1.926797  0.752897 -1.969348\n#&gt; [43]  1.795119  0.258525  2.067406 -0.684579  0.904563 -1.389476 -0.478027\n#&gt; [50] -2.014598\n\n\n# Path to the Stan file\nstan_file &lt;- here::here(\"stan\", \"two_means_diff.stan\")\n\n# Create a CmdStanModel object\nmod &lt;- cmdstan_model(stan_file)\nmod$code() # Stampa il codice del modello\n#&gt;  [1] \"data {\"                                                                \n#&gt;  [2] \"  int&lt;lower=0&gt; N1; // Numero di osservazioni nel gruppo 1\"             \n#&gt;  [3] \"  int&lt;lower=0&gt; N2; // Numero di osservazioni nel gruppo 2\"             \n#&gt;  [4] \"  vector[N1] y1; // Dati del gruppo 1\"                                 \n#&gt;  [5] \"  vector[N2] y2; // Dati del gruppo 2\"                                 \n#&gt;  [6] \"}\"                                                                     \n#&gt;  [7] \"parameters {\"                                                          \n#&gt;  [8] \"  real mu1; // Media del gruppo 1\"                                     \n#&gt;  [9] \"  real delta; // Differenza tra le medie\"                              \n#&gt; [10] \"  real&lt;lower=0&gt; sigma; // Deviazione standard comune\"                  \n#&gt; [11] \"  real&lt;lower=0&gt; nu; // Gradi di libert√† per la distribuzione t\"        \n#&gt; [12] \"}\"                                                                     \n#&gt; [13] \"transformed parameters {\"                                              \n#&gt; [14] \"  real mu2; // Media del gruppo 2\"                                     \n#&gt; [15] \"  mu2 = mu1 + delta;\"                                                  \n#&gt; [16] \"}\"                                                                     \n#&gt; [17] \"model {\"                                                               \n#&gt; [18] \"  // Priori\"                                                           \n#&gt; [19] \"  mu1 ~ normal(0, 5);\"                                                 \n#&gt; [20] \"  delta ~ normal(0, 2); // Priore su delta\"                            \n#&gt; [21] \"  sigma ~ cauchy(0, 5);\"                                               \n#&gt; [22] \"  nu ~ gamma(2, 0.1); // Priore sulla t-student\"                       \n#&gt; [23] \"  \"                                                                    \n#&gt; [24] \"  // Verosimiglianza\"                                                  \n#&gt; [25] \"  y1 ~ student_t(nu, mu1, sigma);\"                                     \n#&gt; [26] \"  y2 ~ student_t(nu, mu2, sigma);\"                                     \n#&gt; [27] \"}\"                                                                     \n#&gt; [28] \"generated quantities {\"                                                \n#&gt; [29] \"  real diff; // Differenza tra le medie (alias di delta per chiarezza)\"\n#&gt; [30] \"  diff = delta;\"                                                       \n#&gt; [31] \"}\"\n\nEsegui il campionamento:\n\nfit &lt;- mod$sample(\n  data = stan_data,\n  seed = 123,\n  chains = 4,\n  iter_sampling = 2000,\n  iter_warmup = 1000,\n  show_messages = FALSE\n)\n\nRiassumi i risultati per mu1, mu2 e delta:\n\nfit_summary &lt;- fit$summary(variables = c(\"mu1\", \"mu2\", \"delta\"))\nprint(fit_summary)\n#&gt; # A tibble: 3 √ó 10\n#&gt;   variable   mean median    sd   mad      q5    q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 mu1      -0.313 -0.312 0.241 0.238 -0.707  0.0818  1.00    5378.    5491.\n#&gt; 2 mu2       0.164  0.166 0.246 0.248 -0.235  0.568   1.00    9428.    6234.\n#&gt; 3 delta     0.477  0.474 0.341 0.344 -0.0887 1.04    1.00    5155.    5260.\n\nEstrai i campioni di delta:\n\ndelta_samples &lt;- fit$draws(variables = \"delta\", format = \"matrix\")[, 1]\n\nDisegna la distribuzione a posteriori di delta:\n\ndelta_df &lt;- data.frame(delta = delta_samples)\n\nggplot(delta_df, aes(x = delta)) +\n  geom_histogram(aes(y = ..density..), bins = 30, fill = \"#b97c7c\", alpha = 0.75) +\n  geom_vline(\n    xintercept = mean(delta_samples),\n    linetype = \"dashed\",\n    linewidth = 1.2,\n    label = paste(\"Mean:\", round(mean(delta_samples), 2))\n  ) +\n  labs(\n    x = \"delta\",\n    y = \"Density\",\n    title = \"Posterior distribution of delta\"\n  ) \n\n\n\n\n\n\n\nPuoi calcolare l‚Äôintervallo di credibilit√† usando per un intervallo al 95%:\n\nquantile(delta_samples, probs = c(0.025, 0.975))\n#&gt;    2.5%   97.5% \n#&gt; -0.1872  1.1553\n\n\n79.7.12.3 Garbage In, Garbage Out\nLa natura della statistica frequentista impone di prendere una decisione dicotomica: o si rifiuta l‚Äôipotesi nulla o non la si rifiuta. Ci√≤ implica che o esiste un effetto reale, oppure non esiste. Con un campione abbastanza grande, √® inevitabile trovare qualche effetto, anche se di minima entit√†.\nUn approccio bayesiano, invece, permette di stimare la dimensione dell‚Äôeffetto e di fornire una distribuzione di probabilit√†. Una distribuzione di probabilit√† √® una rappresentazione grafica delle diverse possibilit√† che potrebbero verificarsi. In questo contesto, si tratta della ‚Äúprobabilit√† inversa‚Äù, ovvero della plausibilit√† dell‚Äôipotesi alla luce dei dati osservati e delle conoscenze pregresse. Qui, il parametro \\(\\delta\\) rappresenta la differenza tra le due medie ed √® il parametro di interesse. Le credenze precedenti su \\(\\delta\\) sono espresse tramite una distribuzione a priori: in questo caso, una distribuzione Normale centrata su 0 con una deviazione standard di 2. La distribuzione a posteriori rappresenta la nostra conoscenza aggiornata su \\(\\delta\\) dopo l‚Äôaggiornamento bayesiano. Il parametro \\(\\delta\\) √® la nostra ipotesi sulla differenza tra le due medie, e l‚Äôinferenza bayesiana riguarda il cambiamento della nostra credenza dopo aver osservato i dati.\nL‚Äôapproccio frequentista, al contrario, produce una decisione dicotomica che non modifica la nostra concezione dell‚Äôipotesi dopo aver osservato i dati. Assume una determinata ipotesi come vera e verifica se i dati sono coerenti con essa. Tramite il concetto binario di ‚Äúsignificativit√† statistica‚Äù, non si modificano le ipotesi di interesse, ma si accettano o si rifiutano le ipotesi nulle.\nSebbene l‚Äôapproccio frequentista sia spesso considerato ‚Äúingenuo‚Äù da molti ricercatori, adottare l‚Äôapproccio bayesiano non rappresenta una soluzione miracolosa ai problemi della scienza contemporanea. Risolve alcuni problemi, ma non altri. In particolare, non affronta la questione degli incentivi accademici che favoriscono la pubblicazione di un elevato numero di articoli, indipendentemente dalla loro qualit√†. Un principio fondamentale della ricerca √® ‚ÄúGarbage in, garbage out‚Äù. Se i dati derivano da un disegno di ricerca fallace o poco creativo, se la ricerca non ha un solido fondamento teorico capace di avanzare le nostre conoscenze, o se la qualit√† delle misurazioni √® insufficiente, i dati raccolti sono puro rumore. Nessun metodo statistico, nemmeno quello bayesiano, pu√≤ trasformare la spazzatura in oro.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>79</span>¬† <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#esercizi",
    "href": "chapters/replication_crisis/01_crisis.html#esercizi",
    "title": "79¬† La crisi della replicazione",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nEsistono numerosi esempi di ricerche che non riescono a essere replicate (posso citare anche uno studio di replicazione che ho condotto io stesso: Caudek et al. (2017)). Un recente caso emblematico √® rappresentato dallo studio di Karata≈ü & Cutright (2023) e dal successivo tentativo di replicazione condotto da Moore et al. (2024). Analizzando le quattro principali argomentazioni sollevate da Gelman & Brown (2024) per criticare lo studio di Aungle & Langer (2023), si offra un‚Äôinterpretazione del perch√© lo studio di Karata≈ü & Cutright (2023) non sia stato replicato con successo.\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\n1) Sulla ‚ÄúCrisi della Replicazione‚Äù in Psicologia\nChe cosa si intende quando si parla di ‚Äúcrisi della replicazione‚Äù in psicologia?\n\n\nA. La difficolt√† di molti laboratori nel reperire fondi per la ricerca.\n\n\nB. L‚Äôincapacit√† o la grave difficolt√† di replicare, con risultati simili, una parte consistente degli studi pubblicati.\n\n\nC. La tendenza di alcuni scienziati a pubblicare risultati simili ad altri per sfruttare la loro notoriet√†.\n\n\nD. Lo scarso interesse degli editori di riviste nel pubblicare studi teorici.\n\n\nE. La mancanza di strumenti statistici adeguati per l‚Äôanalisi dei dati qualitativi.\n\n2) Cosa significa ‚Äúfallimento della replicazione‚Äù?\nQuale delle seguenti opzioni descrive correttamente il ‚Äúfallimento della replicazione‚Äù?\n\n\nA. Non riuscire a pubblicare uno studio su una rivista ad alto impatto.\n\n\nB. Non riuscire a confermare la robustezza metodologica dello studio originale in sede di peer-review.\n\n\nC. Riportare risultati che confermano un‚Äôipotesi gi√† discussa in letteratura.\n\n\nD. Non ottenere, con procedure simili e campioni simili, risultati paragonabili a quelli dello studio originale.\n\n\nE. Non riuscire a reclutare un numero sufficiente di partecipanti in una nuova ricerca.\n\n3) Quale studio scaten√≤ polemiche sulla precognizione?\nNel 2011, un autore pubblic√≤ uno studio che sembrava dimostrare capacit√† ‚Äúparanormali‚Äù nei partecipanti, scatenando polemiche e dubbi. Chi fu?\n\n\nA. Diederik Stapel, che us√≤ dati inventati.\n\n\nB. John Ioannidis, autore di ‚ÄúWhy Most Published Research Findings Are False‚Äù.\n\n\nC. Daryl Bem, con l‚Äôarticolo ‚ÄúFeeling the Future‚Äù sulle facolt√† precognitive.\n\n\nD. Brian Wansink, con studi su etichette ‚Äúattraenti‚Äù delle verdure.\n\n\nE. Daniel Kahneman, con esperimenti sui bias cognitivi e di giudizio.\n\n4) Cosa si intende per ‚Äúp-hacking‚Äù?\nLa pratica denominata p-hacking (nell‚Äôambito della crisi di replicazione) consiste nel:\n\n\nA. Interrompere la raccolta dati nel momento in cui si ottiene un risultato in linea con l‚Äôipotesi.\n\n\nB. Manipolare, in maniera fraudolenta, immagini o grafici.\n\n\nC. Tradurre erroneamente i questionari in pi√π lingue, alterando i risultati.\n\n\nD. Utilizzare molteplici analisi e combinazioni di variabili fino a ottenere un valore-(p) inferiore a 0.05.\n\n\nE. Avere pi√π autori su uno stesso manoscritto per dividerne la responsabilit√†.\n\n5) Qual √® il tasso di replicazione emerso dal ‚ÄúReproducibility Project: Psychology‚Äù (2015)?\nSecondo i dati dell‚ÄôOpen Science Collaboration (2015), approssimativamente quanti studi di psicologia replicarono con successo (ottenendo risultati ‚Äúsignificativi‚Äù simili agli originali)?\n\n\nA. Circa il 36%.\n\n\nB. Circa il 65%.\n\n\nC. Quasi il 90%.\n\n\nD. Nessuno studio √® stato replicato con successo.\n\n\nE. Circa il 10%.\n\n6) Cosa sono le Questionable Research Practices (QRPs)?\nQuale definizione descrive meglio le ‚ÄúQRPs‚Äù (Questionable Research Practices)?\n\n\nA. Pratiche statistiche avanzate che aumentano la robustezza dei risultati.\n\n\nB. Metodologie di campionamento probabilistico trasparenti e preregistrate.\n\n\nC. Pratiche di ricerca discutibili, come ‚Äúoptional stopping‚Äù e selezione post-hoc di ipotesi, che influiscono negativamente sull‚Äôintegrit√† scientifica.\n\n\nD. Strumenti di meta-analisi per combinare risultati di studi diversi.\n\n\nE. Procedure di controllo etico per proteggere i diritti dei partecipanti.\n\n7) Perch√© i campioni troppo piccoli sono considerati problematici?\nNella letteratura sulla crisi di replicazione, perch√© avere campioni di dimensione ridotta costituisce una criticit√†?\n\n\nA. Perch√© rendono pi√π facile l‚Äôanalisi statistica, riducendo la possibilit√† di trovare p &lt; .05.\n\n\nB. Perch√© riducono la potenza statistica, aumentando il rischio di sovrastimare effetti e di ottenere risultati non replicabili.\n\n\nC. Perch√© il costo di reclutamento √® troppo basso, compromettendo l‚Äôinteresse dei revisori.\n\n\nD. Perch√© obbligano a utilizzare necessariamente test non-parametrici.\n\n\nE. Perch√© la psicologia preferisce dataset qualitativi, non quantitativi.\n\n8) Che cosa significa ‚Äúbias di pubblicazione‚Äù?\nCon l‚Äôespressione ‚Äúbias di pubblicazione‚Äù (o publication bias), ci si riferisce a:\n\n\nA. La tendenza dei revisori a selezionare articoli soltanto se ben scritti.\n\n\nB. L‚Äôinclinazione delle riviste di settore a pubblicare preferibilmente i lavori dei ricercatori senior.\n\n\nC. La propensione alla pubblicazione di studi con risultati innovativi e statisticamente positivi, trascurando invece studi con risultati nulli.\n\n\nD. L‚Äôobbligo di pubblicare i protocolli di studio in forma open.\n\n\nE. Una norma deontologica che impone di nascondere i metodi inediti per evitare furti di idee.\n\n9) Quale scopo principale ha il movimento dell‚ÄôOpen Science?\nNel contesto della crisi di replicazione, qual √® l‚Äôobiettivo cardine promosso dal movimento per la Scienza Aperta (Open Science)?\n\n\nA. Aumentare il controllo sugli studi, rendendo segreti i metodi di analisi.\n\n\nB. Pubblicare soltanto studi che abbiano ottenuto finanziamenti pubblici.\n\n\nC. Rendere i dati, i materiali e le procedure il pi√π possibile trasparenti e accessibili, favorendo le repliche e la verifica indipendente.\n\n\nD. Abolire completamente l‚Äôuso di test statistici e valori-p.\n\n\nE. Prediligere esclusivamente studi qualitativi in ambito psicologico.\n\n10) Perch√© la scienza non si autocorregge come si afferma?\nSecondo quanto discusso, come mai la scienza non risulta sempre ‚Äúautocorrettiva‚Äù nella pratica reale?\n\n\nA. Perch√© gli editori impongono di inserire errori per testare la capacit√† dei revisori di individuarli.\n\n\nB. Perch√© √® molto costoso usare software di statistica adeguati.\n\n\nC. Perch√© la pressione a pubblicare risultati nuovi prevale sull‚Äôattenzione a errori e correzioni; i ricercatori non hanno incentivi sufficienti a pubblicare smentite, ritrazioni o correzioni.\n\n\nD. Perch√© l‚Äôuso della statistica bayesiana ha complicato la procedura di revisione.\n\n\nE. Perch√© tutti gli studi di psicologia sono in realt√† corretti al 99%.\n\n\n\n\n\n\n\n\n\n\n\nSoluzioni 2\n\n\n\n\n\n\n\nB\n\n\nD\n\n\nC\n\n\nD\n\n\nA\n\n\nC\n\n\nB\n\n\nC\n\n\nC\n\nC\n\nLa crisi della replicazione in psicologia √® il risultato di una combinazione di fattori sistemici e metodologici:\n\n\nIncentivi distorti (‚Äúpublish or perish‚Äù), che spingono a privilegiare la novit√† rispetto alla qualit√† e alla rigorosit√† delle ricerche.\n\n\nPratiche di ricerca discutibili (QRPs), tra cui p-hacking e optional stopping, che producono un numero elevato di falsi positivi.\n\n\nBias di pubblicazione, che favorisce i risultati statistici significativi a scapito di studi con esiti non significativi o repliche.\n\n\nBassa potenza statistica e campioni di piccole dimensioni, che gonfiano o sovrastimano l‚Äôeffetto di fenomeni psicologici.\n\n\nScarsa trasparenza e accessibilit√† (scienza ‚Äúchiusa‚Äù), che rende difficile verificare e replicare i risultati originari.\n\nNonostante i numeri allarmanti riportati da studi di vasta portata (come il Reproducibility Project), questa situazione pu√≤ essere vista come un‚Äôopportunit√† di ‚Äúrivoluzione della credibilit√†‚Äù:\n\nSi stanno diffondendo pratiche di Open Science, con la condivisione di dati, protocolli, codici e materiali, favorendo cos√¨ la replica e la validazione indipendente.\n\nLa cultura della replicazione viene valorizzata, incentivando studi pi√π rigorosi e focalizzati sulla robustezza degli effetti.\n\nL‚Äôapproccio statistico tradizionale (frequentista) √® posto in discussione, evidenziando la possibilit√† di integrare o sostituire i test di ipotesi nulla con metodologie pi√π robuste, tra cui quelle bayesiane, le analisi preregistrate e la valorizzazione di stime degli effetti con intervalli di credibilit√†.\n\nLa crisi di replicazione, quindi, non deve essere intesa come un fallimento totale, bens√¨ come un momento critico che ha avviato un rinnovamento, mirato a rendere la scienza psicologica (e altre discipline) pi√π rigorosa, trasparente e affidabile.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>79</span>¬† <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/replication_crisis/01_crisis.html#informazioni-sullambiente-di-sviluppo",
    "title": "79¬† La crisi della replicazione",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] posterior_1.6.1  cmdstanr_0.8.1   thematic_0.1.6   MetBrewer_0.2.0 \n#&gt;  [5] ggokabeito_0.1.0 see_0.11.0       gridExtra_2.3    patchwork_1.3.0 \n#&gt;  [9] bayesplot_1.11.1 psych_2.5.3      scales_1.3.0     markdown_2.0    \n#&gt; [13] knitr_1.50       lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1   \n#&gt; [17] dplyr_1.1.4      purrr_1.0.4      readr_2.1.5      tidyr_1.3.1     \n#&gt; [21] tibble_3.2.1     ggplot2_3.5.1    tidyverse_2.0.0  rio_1.2.3       \n#&gt; [25] here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6         tensorA_0.36.2.1     xfun_0.51           \n#&gt;  [4] htmlwidgets_1.6.4    processx_3.8.6       lattice_0.22-6      \n#&gt;  [7] tzdb_0.5.0           vctrs_0.6.5          tools_4.4.2         \n#&gt; [10] ps_1.9.0             generics_0.1.3       parallel_4.4.2      \n#&gt; [13] pacman_0.5.1         pkgconfig_2.0.3      data.table_1.17.0   \n#&gt; [16] checkmate_2.3.2      distributional_0.5.0 lifecycle_1.0.4     \n#&gt; [19] compiler_4.4.2       farver_2.1.2         munsell_0.5.1       \n#&gt; [22] mnormt_2.1.1         htmltools_0.5.8.1    yaml_2.3.10         \n#&gt; [25] pillar_1.10.1        abind_1.4-8          nlme_3.1-167        \n#&gt; [28] tidyselect_1.2.1     digest_0.6.37        stringi_1.8.4       \n#&gt; [31] labeling_0.4.3       rprojroot_2.0.4      fastmap_1.2.0       \n#&gt; [34] grid_4.4.2           colorspace_2.1-1     cli_3.6.4           \n#&gt; [37] magrittr_2.0.3       utf8_1.2.4           withr_3.0.2         \n#&gt; [40] backports_1.5.0      timechange_0.3.0     rmarkdown_2.29      \n#&gt; [43] matrixStats_1.5.0    hms_1.1.3            evaluate_1.0.3      \n#&gt; [46] rlang_1.1.5          glue_1.8.0           rstudioapi_0.17.1   \n#&gt; [49] jsonlite_1.9.1       R6_2.6.1",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>79</span>¬† <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#bibliografia",
    "href": "chapters/replication_crisis/01_crisis.html#bibliografia",
    "title": "79¬† La crisi della replicazione",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAungle, P., & Langer, E. (2023). Physical healing as a function of perceived time. Scientific Reports, 13(1), 22432.\n\n\nBargh, J. A., Chen, M., & Burrows, L. (1996). Automaticity of social behavior: Direct effects of trait construct and stereotype activation on action. Journal of Personality and Social Psychology, 71(2), 230‚Äì244.\n\n\nBem, D. J. (2011). Feeling the future: experimental evidence for anomalous retroactive influences on cognition and affect. Journal of Personality and Social Psychology, 100(3), 407‚Äì425.\n\n\nBruton, S. V., Medlin, M., Brown, M., & Sacco, D. F. (2020). Personal motivations and systemic incentives: Scientists on questionable research practices. Science and Engineering Ethics, 26(3), 1531‚Äì1547.\n\n\nCaudek, C., Lorenzino, M., & Liperoti, R. (2017). Delta plots do not reveal response inhibition in lying. Consciousness and Cognition, 55, 232‚Äì244.\n\n\nChivers, T. (2024). Everything is Predictable: How Bayesian Statistics Explain Our World. Simon; Schuster.\n\n\nCollaboration, O. S. (2015). Estimating the reproducibility of psychological science. Science, 349(6251), aac4716.\n\n\nFerguson, C. J., & Heene, M. (2012). A vast graveyard of undead theories: Publication bias and psychological science‚Äôs aversion to the null. Perspectives on Psychological Science, 7(6), 555‚Äì561.\n\n\nGelman, A., & Brown, N. J. (2024). How statistical challenges and misreadings of the literature combine to produce unreplicable science: An example from psychology.\n\n\nGelman, A., & Loken, E. (2013). The garden of forking paths: Why multiple comparisons can be a problem, even when there is no ¬´fishing expedition¬ª or ¬´p-hacking¬ª and the research hypothesis was posited ahead of time. Department of Statistics, Columbia University, 348(1-17), 3.\n\n\nGelman, A., & Loken, E. (2014). The statistical crisis in science. American scientist, 102(6), 460‚Äì465.\n\n\nGopalakrishna, G., Ter Riet, G., Vink, G., Stoop, I., Wicherts, J. M., & Bouter, L. M. (2022). Prevalence of questionable research practices, research misconduct and their potential explanatory factors: A survey among academic researchers in The Netherlands. PloS one, 17(2), e0263023.\n\n\nGrimes, D. R., Bauch, C. T., & Ioannidis, J. P. (2018). Modelling science trustworthiness under publish or perish pressure. Royal Society open science, 5(1), 171511.\n\n\nIoannidis, J. P. (2005). Why most published research findings are false. PLoS medicine, 2(8), e124.\n\n\nKarata≈ü, M., & Cutright, K. M. (2023). Thinking about God increases acceptance of artificial intelligence in decision-making. Proceedings of the National Academy of Sciences, 120(33), e2218961120.\n\n\nLakens, D. (2015). On the challenges of drawing conclusions from p-values just below 0.05. PeerJ, 3, e1142.\n\n\nLeys, R. (2024). Anatomy of a Train Wreck: The Rise and Fall of Priming Research. University of Chicago Press.\n\n\nLoken, E., & Gelman, A. (2017). Measurement Error and the Replication Crisis. Science, 355(6325), 584‚Äì585.\n\n\nMeehl, P. E. (2012). Why summaries of research on psychological theories are often uninterpretable. In Improving inquiry in social science (pp. 13‚Äì59). Routledge.\n\n\nMoore, D. A., Schroeder, J., Bailey, E. R., Gershon, R., Moore, J. E., & Simmons, J. P. (2024). Does thinking about God increase acceptance of artificial intelligence in decision-making? Proceedings of the National Academy of Sciences, 121(31), e2402315121.\n\n\nNosek, B. A., Spies, J. R., & Motyl, M. (2012). Scientific utopia: II. Restructuring incentives and practices to promote truth over publishability. Perspectives on Psychological Science, 7(6), 615‚Äì631.\n\n\nPennington, C. (2023). A student‚Äôs guide to open science: Using the replication crisis to reform psychology. McGraw-Hill Education (UK).\n\n\nWare, J. J., & Munaf√≤, M. R. (2015). Significance chasing in research practice: causes, consequences and possible solutions. Addiction, 110(1), 4‚Äì8.\n\n\nYouyou, W., Yang, Y., & Uzzi, B. (2023). A discipline-wide investigation of the replicability of Psychology papers over the past two decades. Proceedings of the National Academy of Sciences, 120(6), e2208863120.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>79</span>¬† <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html",
    "title": "80¬† Limiti dell‚Äôinferenza frequentista",
    "section": "",
    "text": "Introduzione\nPrerequisiti\nConcetti e Competenze Chiave\nIn questa sezione della dispensa, abbiamo approfondito il metodo ‚Äútradizionale‚Äù per il test di significativit√† dell‚Äôipotesi nulla (NHST). Comprendere la logica sottostante all‚Äôapproccio NHST √® fondamentale, poich√© esso ha rappresentato il principale strumento della statistica inferenziale sin dalla sua introduzione all‚Äôinizio del XX secolo, e la maggior parte dei ricercatori continua a basarsi su questa procedura per l‚Äôanalisi dei dati. Tuttavia, negli ultimi anni, l‚ÄôNHST √® stato oggetto di crescenti critiche, con molti studiosi che sostengono che questo approccio possa generare pi√π problemi di quanti ne risolva. Per questo motivo, √® cruciale esaminare le critiche avanzate dalla comunit√† scientifica nei confronti della procedura inferenziale NHST. In questa sezione, analizzeremo alcuni dei principali dubbi e limiti emersi riguardo a tale metodologia.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>80</span>¬† <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#luso-del-valore-p-nel-mondo-della-ricerca",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#luso-del-valore-p-nel-mondo-della-ricerca",
    "title": "80¬† Limiti dell‚Äôinferenza frequentista",
    "section": "80.1 L‚Äôuso del valore-\\(p\\) nel mondo della ricerca",
    "text": "80.1 L‚Äôuso del valore-\\(p\\) nel mondo della ricerca\nNel suo articolo ‚ÄúStatistical Errors‚Äù (2014), Nuzzo mette in luce i limiti dell‚Äôapproccio NHST nella pratica scientifica Nuzzo (2014). Sebbene il valore-\\(p\\) sia stato introdotto da Ronald Fisher negli anni ‚Äô20, egli non lo concep√¨ mai come un test formale. Fisher lo considerava piuttosto uno strumento informale per valutare se l‚Äôevidenza empirica fosse ‚Äúsignificativa‚Äù in senso colloquiale, ovvero meritevole di ulteriore attenzione. Nella pratica, Fisher suggeriva di assumere un‚Äôipotesi nulla e di calcolare la probabilit√† di osservare un risultato altrettanto estremo o pi√π estremo di quello ottenuto, presupponendo che il risultato fosse interamente dovuto alla variabilit√† campionaria. Tuttavia, per Fisher, il valore-\\(p\\) non era una conclusione definitiva, ma uno strumento da integrare in un processo decisionale pi√π ampio, che tenesse conto sia delle evidenze empiriche sia delle conoscenze pregresse del ricercatore. In altre parole, il valore-\\(p\\) era parte di un ragionamento scientifico, non il punto finale di tale ragionamento.\nVerso la fine degli anni ‚Äô20, Jerzy Neyman e Egon Pearson, rivali di Fisher, formalizzarono le procedure di decisione statistica con l‚Äôobiettivo di renderle pi√π rigorose e oggettive. Introdussero concetti come il potere statistico e il tasso di falsi positivi, ma si distanziarono dall‚Äôuso del valore-\\(p\\) proposto da Fisher. Le divergenze tra Fisher, Neyman e Pearson diedero vita a un acceso dibattito: Neyman defin√¨ il lavoro di Fisher ‚Äúmatematicamente peggiore dell‚Äôinutilit√†‚Äù, mentre Fisher boll√≤ l‚Äôapproccio di Neyman come ‚Äúinfantile‚Äù e ‚Äúdannoso per la libert√† intellettuale dell‚ÄôOccidente‚Äù.\nNel frattempo, altri autori iniziarono a scrivere manuali di statistica per guidare i ricercatori. Tuttavia, molti di questi autori non erano statistici e avevano una comprensione superficiale delle differenze tra i vari approcci. Il risultato fu un sistema ibrido che combinava il valore-\\(p\\) di Fisher con il framework rigoroso di Neyman e Pearson. Fu in questo contesto che la soglia di un valore-\\(p\\) pari a 0.05 venne arbitrariamente definita come ‚Äústatisticamente significativa‚Äù.\nStoricamente, tuttavia, il valore-\\(p\\) proposto da Fisher aveva un significato molto diverso rispetto a quello che gli viene attribuito oggi. Come abbiamo visto, per Fisher era uno strumento informale, da utilizzare all‚Äôinterno di un processo decisionale pi√π ampio e non come un criterio meccanico per stabilire la verit√† scientifica. L‚Äôuso del valore-\\(p\\) nel sistema ibrido adottato dai manuali di statistica √® quindi privo di una solida giustificazione teorica.\nNel 2016, l‚ÄôAmerican Statistical Association (ASA) ha espresso forti preoccupazioni riguardo all‚Äôuso inappropriato del valore-\\(p\\) nella pratica scientifica contemporanea Wasserstein & Lazar (2016):\n\n\\(P\\)-values do not measure the probability that the studied hypothesis is true, or the probability that the data were produced by random chance alone. Researchers often wish to turn a \\(p\\)-value into a statement about the truth of a null hypothesis, or about the probability that random chance produced the observed data. The \\(p\\)-value is neither. It is a statement about data in relation to a specified hypothetical explanation, and is not a statement about the explanation itself.\n\nL‚Äôarticolo prosegue sottolineando che:\n\nScientific conclusions and business or policy decisions should not be based only on whether a \\(p\\)-value passes a specific threshold. Practices that reduce data analysis or scientific inference to mechanical ‚Äúbright-line‚Äù rules (such as ‚Äú\\(p &lt; 0.05\\)‚Äù) for justifying scientific claims or conclusions can lead to erroneous beliefs and poor decision making. A conclusion does not immediately become ‚Äòtrue‚Äô on one side of the divide and ‚Äòfalse‚Äô on the other. Researchers should bring many contextual factors into play to derive scientific inferences, including the design of a study, the quality of the measurements, the external evidence for the phenomenon under study, and the validity of assumptions that underlie the data analysis. Pragmatic considerations often require binary, ‚Äòyes-no‚Äô decisions, but this does not mean that \\(p\\)-values alone can ensure that a decision is correct or incorrect. The widespread use of ‚Äústatistical significance‚Äù (generally interpreted as ) as a license for making a claim of a scientific finding (or implied truth) leads to considerable distortion of the scientific process.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>80</span>¬† <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#p-hacking",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#p-hacking",
    "title": "80¬† Limiti dell‚Äôinferenza frequentista",
    "section": "80.2 \\(P\\)-hacking",
    "text": "80.2 \\(P\\)-hacking\nLa pratica del \\(P\\)-hacking rappresenta una delle principali criticit√† associate all‚Äôuso del valore-\\(p\\) ed √® conosciuta anche con termini come data-dredging, snooping, fishing, significance-chasing o double-dipping. Secondo Uri Simonsohn, professore all‚ÄôUniversit√† della Pennsylvania, il \\(P\\)-hacking consiste nel manipolare i dati o le analisi fino a ottenere un risultato statisticamente significativo, tipicamente con un valore-\\(p\\) inferiore a 0.05. Ad esempio, si potrebbe dire: ‚ÄúQuel risultato sembra frutto di \\(P\\)-hacking; gli autori hanno escluso una condizione per far scendere il valore-\\(p\\) sotto la soglia di 0.05‚Äù oppure ‚ÄúLei √® un \\(P\\)-hacker, controlla continuamente i dati durante la raccolta per trovare un risultato significativo‚Äù.\nQuesta pratica trasforma uno studio esplorativo, che dovrebbe essere interpretato con estrema cautela, in uno studio confermativo (apparentemente robusto), i cui risultati, tuttavia, hanno una probabilit√† molto bassa di essere replicati in ricerche successive. Secondo le simulazioni condotte da Simonsohn, piccole modifiche nelle scelte analitiche possono aumentare il tasso di falsi positivi fino al 60% in un singolo studio.\nIl \\(P\\)-hacking √® particolarmente diffuso negli studi che cercano di dimostrare effetti di piccola entit√† utilizzando dati molto rumorosi. Un‚Äôanalisi della letteratura psicologica ha rivelato che i valori-\\(p\\) riportati tendono a concentrarsi appena al di sotto della soglia di 0.05, un fenomeno che pu√≤ essere interpretato come un segnale di \\(P\\)-hacking: i ricercatori eseguono molteplici test statistici fino a trovarne uno che raggiunge la ‚Äúsignificativit√† statistica‚Äù e poi riportano solo quello. Come evidenziato in figura, questa pratica non √® limitata alla psicologia, ma √® ampiamente diffusa in tutti i campi della ricerca scientifica, contribuendo a minare l‚Äôaffidabilit√† dei risultati pubblicati.\n\n\n\nDistribuzione dei valori-\\(p\\) nelle pubblicazioni scientifiche di economia, psicologia e biologia.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>80</span>¬† <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#critiche-al-valore-p",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#critiche-al-valore-p",
    "title": "80¬† Limiti dell‚Äôinferenza frequentista",
    "section": "80.3 Critiche al valore-\\(p\\)",
    "text": "80.3 Critiche al valore-\\(p\\)\nIl valore-\\(p\\) √® stato spesso paragonato a creature fastidiose e persistenti come le zanzare, oppure ai ‚Äúvestiti nuovi dell‚Äôimperatore‚Äù, metafora che rappresenta la tendenza a ignorare problemi evidenti preferendo fingere che tutto vada bene. √à stato anche definito un intellectual rake sterile, un termine che sottolinea la sua incapacit√† di produrre risultati utili. Non manca nemmeno l‚Äôironia sul fatto che la procedura di statistical hypothesis inference testing venga chiamata cos√¨ principalmente per l‚Äôacronimo che genera.\nIl valore-\\(p\\) promuove un modo di pensare distorto, spostando l‚Äôattenzione dal cuore della ricerca, ovvero la forza della manipolazione sperimentale, verso la dimostrazione di un‚Äôipotesi nulla che si sa gi√† essere falsa. Ad esempio, uno studio condotto su oltre 19,000 individui ha mostrato che le coppie che si incontrano online hanno una probabilit√† inferiore di divorziare (\\(p &lt; 0.002\\)) e riportano una maggiore soddisfazione nella vita matrimoniale (\\(p &lt; 0.001\\)) rispetto a quelle che si sono conosciute offline. Sebbene questi risultati possano sembrare interessanti, senza considerare la dimensione dell‚Äôeffetto ‚Äì come la riduzione del tasso di divorzio dal 7.67% al 5.96% o l‚Äôaumento dell‚Äôindice di soddisfazione matrimoniale da 5.48 a 5.64 su una scala a sette punti ‚Äì il loro impatto pratico rischia di essere sopravvalutato. In generale, la domanda chiave non dovrebbe essere ‚Äúc‚Äô√® un effetto?‚Äù, ma piuttosto ‚Äúquanto √® grande l‚Äôeffetto?‚Äù. Questo approccio permette di valutare meglio l‚Äôeffettiva rilevanza dei risultati, andando oltre la semplice significativit√† statistica.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>80</span>¬† <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#leffetto-sperimentale-√®-esattamente-nullo",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#leffetto-sperimentale-√®-esattamente-nullo",
    "title": "80¬† Limiti dell‚Äôinferenza frequentista",
    "section": "80.4 L‚Äôeffetto sperimentale √® esattamente nullo?",
    "text": "80.4 L‚Äôeffetto sperimentale √® esattamente nullo?\nUna delle critiche pi√π ricorrenti alla logica del test di verifica delle ipotesi statistiche riguarda l‚Äôassunzione irrealistica che l‚Äôeffetto della manipolazione sperimentale sia esattamente nullo. Ad esempio, la fisica ci dimostra che persino lo spostamento di un grammo di massa in una stella distante anni luce dalla Terra pu√≤ influenzare, seppur minimamente, il movimento delle molecole di un gas sul nostro pianeta (Borel, 1914). Questo esempio suggerisce che ogni manipolazione sperimentale, per quanto piccola, produca in qualche modo un effetto. Pertanto, come sottolinea Andrew Gelman, il problema non √® tanto dimostrare che l‚Äôipotesi nulla sia falsa ‚Äì ovvero che la manipolazione sperimentale non abbia alcun effetto ‚Äì quanto piuttosto valutare se la dimensione dell‚Äôeffetto sia sufficientemente grande da avere un impatto pratico e se tale effetto sia riproducibile.\nIn questo contesto, la logica del test dell‚Äôipotesi nulla risulta particolarmente problematica, specialmente quando si lavora con campioni piccoli ed effetti di modesta entit√†, come accade spesso negli studi psicologici. Questo approccio pu√≤ portare a una sovrastima della dimensione dell‚Äôeffetto e a una visione binaria dei risultati (vero/falso), distogliendo l‚Äôattenzione dalla stima accurata e non distorta della dimensione effettiva dell‚Äôeffetto. In altre parole, la ricerca dovrebbe concentrarsi meno sul rifiutare un‚Äôipotesi nulla spesso irrealistica e pi√π sulla comprensione e quantificazione dell‚Äôimpatto reale delle variabili studiate.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>80</span>¬† <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#attenti-al-valore-p",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#attenti-al-valore-p",
    "title": "80¬† Limiti dell‚Äôinferenza frequentista",
    "section": "80.5 Attenti al valore-\\(p\\)!",
    "text": "80.5 Attenti al valore-\\(p\\)!\nConsideriamo il seguente problema. Supponiamo di eseguire un \\(t\\)-test per due campioni indipendenti per verificare l‚Äôipotesi nulla che le medie delle due popolazioni siano uguali. Fissiamo un livello di significativit√† \\(\\alpha = 0.05\\) e otteniamo un valore-\\(p\\) pari a \\(0.04\\). La domanda √®: qual √® la probabilit√† che i due campioni provengano da distribuzioni con la stessa media?\nLe opzioni sono:\n(a) \\(19/20\\);‚ÄÉ(b) \\(1/19\\);‚ÄÉ(c) \\(1/20\\);‚ÄÉ(d) \\(95/100\\);‚ÄÉ(e) sconosciuta.\nLa risposta corretta √®: (e) sconosciuta. Questo perch√© la statistica frequentista calcola le probabilit√† dei dati condizionatamente alle ipotesi (assunte come vere), ma non permette di determinare la probabilit√† di un‚Äôipotesi. In altre parole, il valore-\\(p\\) non fornisce informazioni sulla probabilit√† che l‚Äôipotesi nulla sia vera o falsa; indica solo la probabilit√† di osservare i dati (o risultati pi√π estremi) assumendo che l‚Äôipotesi nulla sia vera.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>80</span>¬† <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#la-crisi-della-riprodicibilit√†-dei-risultati-della-ricerca",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#la-crisi-della-riprodicibilit√†-dei-risultati-della-ricerca",
    "title": "80¬† Limiti dell‚Äôinferenza frequentista",
    "section": "80.6 La crisi della riprodicibilit√† dei risultati della ricerca",
    "text": "80.6 La crisi della riprodicibilit√† dei risultati della ricerca\nNegli ultimi anni, la mancanza di replicabilit√† dei risultati della ricerca ‚Äì inclusa quella psicologica ‚Äì √® emersa come un tema di grande rilevanza nel dibattito scientifico. In questo contesto, √® stato evidenziato che alcuni aspetti del metodo scientifico, in particolare l‚Äôuso del valore-\\(p\\) e la pratica del test di significativit√† dell‚Äôipotesi nulla (NHST, Null Hypothesis Significance Testing), potrebbero contribuire a quella che √® stata definita una ‚Äúcrisi della ricerca scientifica‚Äù. Un‚Äôanalisi approfondita di questo problema √® stata proposta da Gelman (2016), il quale sostiene che la NHST sia intrinsecamente problematica. Questo approccio, infatti, spinge i ricercatori a cercare di rigettare un‚Äôipotesi ‚Äúfantoccio‚Äù (straw-man), spesso gi√† falsa a priori o di scarso interesse scientifico, a favore di un‚Äôipotesi alternativa che il ricercatore preferisce. In generale, √® pi√π ragionevole affermare che la differenza tra due condizioni sia molto piccola piuttosto che esattamente uguale a zero, ma la NHST non √® progettata per cogliere questa sfumatura.\nNei libri di statistica, la NHST viene spesso presentata come una sorta di ‚Äúalchimia‚Äù che trasforma la casualit√† in una falsa certezza, utilizzando termini come ‚Äúconfidenza‚Äù e ‚Äúsignificativit√†‚Äù (Gelman, 2016). Il processo di raccolta dei dati, analisi e inferenza statistica viene sintetizzato in una conclusione espressa in termini di valore-\\(p\\) e intervalli di confidenza che escludono lo zero. Tuttavia, questo pu√≤ creare l‚Äôimpressione errata che il ricercatore abbia una comprensione completa del fenomeno studiato. Il problema principale della NHST √® che spesso produce risultati ‚Äústatisticamente significativi‚Äù in contesti in cui le caratteristiche del fenomeno non giustificano le conclusioni tratte. Questo pu√≤ portare a una bassa replicabilit√† dei risultati, contribuendo alla crisi di fiducia nella ricerca.\nLa comunit√† statistica ha sottolineato come la non replicabilit√† sia particolarmente evidente quando i ricercatori, utilizzando la NHST, traggono conclusioni errate basate su piccoli campioni ed effetti di dimensioni ridotte. Queste condizioni, insieme ad altre, rendono l‚Äôapplicazione della NHST estremamente problematica. Purtroppo, queste situazioni descrivono molte delle ricerche recenti in psicologia, un campo in cui gli effetti sono spesso modesti e i campioni limitati.\nLa statistica √® stata definita come un metodo per prendere decisioni razionali in condizioni di incertezza. Gli statistici raccomandano ai ricercatori non solo di padroneggiare le tecniche statistiche, ma anche di imparare a convivere con l‚Äôincertezza, nonostante la crescente sofisticazione degli strumenti disponibili. Conviverci significa evitare di pensare che ottenere un valore-\\(p\\) ‚Äústatisticamente significativo‚Äù equivalga a risolvere un problema scientifico. Ma allora, come possiamo avere fiducia in ci√≤ che apprendiamo dai dati? Una possibile strategia √® la replicazione e la convalida esterna dei risultati, sebbene nella ricerca psicologica e nelle scienze sociali questo sia spesso difficile da realizzare a causa degli elevati costi e delle complessit√† pratiche. Il problema di quali strumenti metodologici e metodi statistici siano pi√π adatti per indagare i fenomeni psicologici, senza cadere in errori di interpretazione, rimane quindi una questione aperta e di cruciale importanza.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>80</span>¬† <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#commenti-e-considerazioni-finali",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#commenti-e-considerazioni-finali",
    "title": "80¬† Limiti dell‚Äôinferenza frequentista",
    "section": "80.7 Commenti e considerazioni finali",
    "text": "80.7 Commenti e considerazioni finali\nNon possiamo concludere senza affrontare la controversia che circonda il concetto di valore-\\(p\\). Nonostante sia ancora ampiamente utilizzato e spesso interpretato in modo errato, il valore-\\(p\\) conferisce solo una parvenza di legittimit√† a risultati dubbi, incoraggia cattive pratiche di ricerca e favorisce la produzione di falsi positivi. Inoltre, il suo significato √® spesso frainteso, persino dagli esperti: quando chiamati a definire il valore-\\(p\\), molti forniscono risposte imprecise o sbagliate. Ci√≤ che i ricercatori desiderano sapere √® se i risultati di uno studio siano corretti o meno, ma il valore-\\(p\\) non fornisce questa informazione. Non dice nulla sulla dimensione dell‚Äôeffetto, sulla forza dell‚Äôevidenza o sulla probabilit√† che il risultato sia frutto del caso. Allora, qual √® il suo vero significato? Stuart Buck lo spiega in modo efficace:\n\nImmaginate di avere una moneta che sospettate sia truccata a favore della testa (l‚Äôipotesi nulla √® che la moneta sia equa). La lanciate 100 volte e ottenete pi√π teste che croci. Il valore-\\(p\\) non vi dir√† se la moneta √® equa, ma vi indicher√† la probabilit√† di ottenere almeno lo stesso numero di teste osservato se la moneta fosse equa. Questo √® tutto ‚Äì niente di pi√π.\n\nIn sintesi, il valore-\\(p\\) risponde a una domanda molto specifica che, tuttavia, non ha alcuna rilevanza diretta per la validit√† scientifica dei risultati di una ricerca. In un‚Äôepoca in cui la crisi della riproducibilit√† dei risultati √® sempre pi√π evidente (Baker, 2016), il test dell‚Äôipotesi nulla e gli intervalli di confidenza frequentisti sono stati identificati come una delle principali cause del problema. Questo ha spinto molti ricercatori a cercare alternative metodologiche pi√π robuste e informative, in grado di superare i limiti intrinseci del valore-\\(p\\) e di promuovere una scienza pi√π affidabile e trasparente.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>80</span>¬† <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#bibliografia",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#bibliografia",
    "title": "80¬† Limiti dell‚Äôinferenza frequentista",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBaker, M. (2016). Reproducibility Crisis. Nature, 533(7604), 452‚Äì454.\n\n\nBorel, E. (1914). Introduction G√©om√©trique. G. Villars, New York.\n\n\nGelman, A. (2016). Commentary on ¬´Crisis in Science? Or Crisis in Statistics! Mixed Messages in Statistics with Impact on Science¬ª. Journal of Statistical Research, 48-50(1), 11‚Äì12.\n\n\nGoligher, E. C., Heath, A., & Harhay, M. O. (2024). Bayesian statistics for clinical research. The Lancet, 404(10457), 1067‚Äì1076. https://doi.org/10.1016/S0140-6736(24)00055-9\n\n\nNuzzo, R. (2014). Statistical Errors. Nature, 506(7487), 150‚Äì152.\n\n\nWasserstein, R. L., & Lazar, N. A. (2016). The ASA‚Äôs statement on p-values: context, process, and purpose. The American Statistician, 70(2), 129‚Äì133.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>80</span>¬† <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html",
    "href": "chapters/replication_crisis/03_effect_size.html",
    "title": "81¬† La grandezza dell‚Äôeffetto",
    "section": "",
    "text": "81.1 Introduzione\nLa dimensione dell‚Äôeffetto (effect size) √® un concetto chiave nella metodologia della ricerca, utilizzato per quantificare la forza della relazione statistica tra due variabili. Questa misura standardizzata descrive l‚Äôentit√† di un effetto, come quello di un intervento o di un trattamento, fornendo una valutazione quantitativa dell‚Äôimportanza di un fenomeno osservato.\n√à essenziale distinguere tra dimensione dell‚Äôeffetto e significativit√† statistica. Un risultato pu√≤ essere ‚Äústatisticamente significativo‚Äù anche se l‚Äôeffetto √® di piccole dimensioni, e viceversa. La conoscenza di uno di questi aspetti non fornisce automaticamente informazioni sull‚Äôaltro, evidenziando la necessit√† di considerare entrambi nell‚Äôanalisi dei dati.\nL‚Äôimportanza della dimensione dell‚Äôeffetto √® ampiamente riconosciuta nel mondo della ricerca scientifica. Il manuale dell‚ÄôAmerican Psychological Association (APA) del 2010 ne sottolinea la rilevanza, raccomandando di includere questa misura negli studi pubblicati. Di conseguenza, la maggior parte degli articoli nelle riviste associate all‚ÄôAPA riporta la dimensione dell‚Äôeffetto, solitamente indicata tra parentesi accanto al valore-\\(p\\).\nNonostante la sua importanza e la prassi di riportarla, la psicologia scientifica spesso mostra una carenza nella corretta valutazione e interpretazione delle dimensioni dell‚Äôeffetto. Molti ricercatori si limitano a comunicare questi valori senza analizzarli in profondit√†, portando a conclusioni che possono risultare superficiali, poco informative, fuorvianti o addirittura errate. Questa tendenza riflette una sottovalutazione sistematica e una diffusa incomprensione del concetto di dimensione dell‚Äôeffetto, persino tra i professionisti della ricerca.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>81</span>¬† <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html#misurazione-delleffetto-approcci-e-applicazioni",
    "href": "chapters/replication_crisis/03_effect_size.html#misurazione-delleffetto-approcci-e-applicazioni",
    "title": "81¬† La grandezza dell‚Äôeffetto",
    "section": "81.2 Misurazione dell‚ÄôEffetto: Approcci e Applicazioni",
    "text": "81.2 Misurazione dell‚ÄôEffetto: Approcci e Applicazioni\nTra le metriche pi√π utilizzate per quantificare l‚Äôeffetto di un trattamento o di una differenza tra gruppi troviamo il \\(d\\) di Cohen e l‚Äô\\(r\\) di Pearson. Il \\(d\\) di Cohen √® particolarmente utile per descrivere le differenze tra le medie di due gruppi sperimentali, esprimendo tale differenza in termini di deviazione standard aggregata.\nLa differenza standardizzata tra le medie di due gruppi pu√≤ essere calcolata con la seguente formula (equazione 5.1, Glass et al., 1981):\n\\[\nd_p = \\frac{M_1 - M_2}{S_p},\n\\]\ndove:\n\n\\(M_1\\) e \\(M_2\\) sono le medie dei due gruppi,\n\\(S_p\\) √® la deviazione standard combinata.\n\nUn valore positivo di \\(d_p\\) indica che la media del gruppo 1 √® maggiore di quella del gruppo 2. La deviazione standard combinata \\(S_p\\) √® calcolata come la radice quadrata della varianza media ponderata per i gradi di libert√† (\\(df = n-1\\)) dei due gruppi (pp.¬†108, Glass et al., 1981):\n\\[\nS_p = \\sqrt{\\frac{(n_1 - 1) S_1^2 + (n_2 - 1) S_2^2}{n_1 + n_2 - 2}},\n\\]\ndove:\n\n\\(n_1\\) e \\(n_2\\) sono le dimensioni dei due gruppi,\n\\(S_1^2\\) e \\(S_2^2\\) sono le varianze (quadrato della deviazione standard) dei due gruppi.\n\nIl \\(d_p\\) di Cohen √® strettamente correlato alla statistica \\(t\\) di un test \\(t\\) per campioni indipendenti. Infatti, √® possibile calcolare \\(d_p\\) a partire dalla statistica \\(t\\) utilizzando la seguente formula (equazione 5.3, Glass et al., 1981):\n\\[\nd = t \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}.\n\\]\nL‚Äôerrore standard di \\(d_p\\) √® dato da:\n\\[\nSE_{d_p} = \\sqrt{\\frac{n_1 + n_2}{n_1 n_2} + \\frac{d_p^2}{2(n_1 + n_2)}}.\n\\]\nD‚Äôaltra parte, la statistica \\(r\\) di Pearson misura il grado di correlazione lineare tra due variabili, indicando quanto una variabile possa predire l‚Äôaltra. √à interessante notare che queste due misure, \\(d\\) e \\(r\\), possono essere convertite l‚Äôuna nell‚Äôaltra attraverso la relazione:\n\\[\nd = \\frac{2r}{\\sqrt{1-r^2}}.\n\\]\nQuesta conversione permette di passare da una misura di differenza tra medie a una misura di correlazione, offrendo una maggiore flessibilit√† nell‚Äôinterpretazione dei risultati.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>81</span>¬† <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html#interpretazione-della-dimensione-delleffetto",
    "href": "chapters/replication_crisis/03_effect_size.html#interpretazione-della-dimensione-delleffetto",
    "title": "81¬† La grandezza dell‚Äôeffetto",
    "section": "81.3 Interpretazione della Dimensione dell‚ÄôEffetto",
    "text": "81.3 Interpretazione della Dimensione dell‚ÄôEffetto\nL‚Äôinterpretazione della dimensione dell‚Äôeffetto √® un aspetto cruciale nell‚Äôanalisi statistica, ma spesso viene affrontata in modi che possono risultare privi di significato o addirittura fuorvianti. Di seguito, esploriamo due approcci comuni e le loro criticit√†.\n\n81.3.1 Gli Standard di Cohen\nUno dei metodi pi√π diffusi per interpretare la dimensione dell‚Äôeffetto si basa sugli standard proposti da Jacob Cohen (1977, 1988). Cohen ha suggerito delle soglie arbitrarie per classificare l‚Äôeffetto:\n\nr = 0.10 ‚Üí effetto piccolo,\nr = 0.30 ‚Üí effetto medio,\nr = 0.50 ‚Üí effetto grande.\n\nTuttavia, come sottolineato da Funder (2019), queste soglie sono spesso utilizzate in modo acritico, senza considerare il contesto specifico. Lo stesso Cohen ha espresso rammarico per aver introdotto queste categorie, precisando che dovrebbero essere adottate solo in assenza di criteri pi√π solidi.\nLe etichette ‚Äúpiccolo‚Äù, ‚Äúmedio‚Äù e ‚Äúgrande‚Äù sono prive di significato se non vengono contestualizzate. Per un‚Äôinterpretazione corretta, √® essenziale porsi due domande fondamentali:\n\nRispetto a cosa? Cosa rappresenta un effetto piccolo, medio o grande nel contesto specifico dello studio?\nA quale scopo? Qual √® l‚Äôimpatto pratico o teorico dell‚Äôeffetto osservato?\n\nSenza rispondere a queste domande, l‚Äôuso degli standard di Cohen rischia di essere poco informativo o addirittura ingannevole.\n\n\n81.3.2 Elevare al Quadrato la Correlazione\nUn altro approccio comune, ma altrettanto problematico, consiste nell‚Äôelevare al quadrato il coefficiente di correlazione \\(r\\) per ottenere \\(r^2\\), interpretato come la ‚Äúproporzione di varianza spiegata‚Äù. Ad esempio, una correlazione \\(r = 0.30\\) corrisponde a \\(r^2 = 0.09\\), spesso descritto come ‚Äúsolo il 9% della varianza spiegata‚Äù.\nTuttavia, come evidenziato da Funder & Ozer (2019), questa pratica √® criticabile per due motivi principali:\n\nMancanza di interpretabilit√†: Mentre \\(r\\) rappresenta la pendenza di una regressione standardizzata, \\(r^2\\) √® molto meno intuitivo, poich√© riflette solo la proporzione di varianza condivisa tra due variabili.\nPotenziale fuorviante: Elevare al quadrato \\(r\\) pu√≤ distorcere la percezione dell‚Äôeffetto. Ad esempio, una correlazione \\(r = 0.30\\) (effetto medio secondo Cohen) diventa \\(r^2 = 0.09\\), che sembra trascurabile, ma in realt√† potrebbe avere un impatto significativo nel contesto applicativo.\n\nUn esempio chiaro √® fornito da Darlington (1990). Consideriamo un gioco in cui si lanciano due monete: un nickel (5¬¢) e un dime (10¬¢). Se esce testa, si vincono rispettivamente 5¬¢ o 10¬¢. Le correlazioni tra il valore delle monete e il pagamento sono:\n\nNickel: \\(r = 0.4472\\) (\\(r^2 = 0.20\\)),\nDime: \\(r = 0.8944\\) (\\(r^2 = 0.80\\)).\n\nSe interpretassimo \\(r^2\\) in modo letterale, potremmo erroneamente concludere che il dime ‚Äúconta quattro volte pi√π‚Äù del nickel. Tuttavia, le correlazioni originali mostrano che \\(0.8944\\) √® esattamente il doppio di \\(0.4472\\), offrendo un confronto pi√π accurato e informativo.\nIn sintesi, l‚Äôinterpretazione della dimensione dell‚Äôeffetto richiede cautela e contestualizzazione. Gli standard di Cohen, sebbene ampiamente utilizzati, sono arbitrari e possono essere fuorvianti se applicati in modo acritico. Allo stesso modo, elevare al quadrato la correlazione \\(r\\) per ottenere \\(r^2\\) rischia di distorcere la percezione dell‚Äôeffetto, rendendolo meno interpretabile e potenzialmente fuorviante. Per un‚Äôanalisi robusta, √® essenziale considerare il contesto e l‚Äôimpatto pratico dell‚Äôeffetto osservato, evitando di affidarsi esclusivamente a metriche standardizzate o trasformazioni matematiche poco informative.\n\n\n81.3.3 Alternative migliori\n√à cruciale interpretare le dimensioni degli effetti in modo che ne arricchisca il significato. Funder & Ozer (2019) propongono due strategie principali: l‚Äôadozione di benchmark (criteri di riferimento) e la valutazione delle implicazioni pratiche dei risultati.\n\nUtilizzare criteri di riferimento significa confrontare l‚Äôentit√† di un risultato con quella di risultati ben noti e ampiamente compresi. Simile al modo in cui giudichiamo l‚Äôaltezza di una persona basandoci su confronti con altri, i ricercatori possono ottenere una percezione accurata dell‚Äôimportanza di un risultato confrontandolo con la dimensione di effetti noti, sia quelli tipici del campo di studio sia quelli emersi da ricerche passate.\nUn approccio al benchmarking pu√≤ includere l‚Äôanalisi di risultati considerati ‚Äúclassici‚Äù nel campo di interesse o la considerazione di dimensioni dell‚Äôeffetto per risultati che hanno ottenuto un solido consenso nella comunit√† psicologica.\nIn un‚Äôottica pi√π ampia, alcuni ricercatori hanno proposto benchmark per la dimensione dell‚Äôeffetto calcolando medie su vasti corpi di letteratura. Ad esempio, uno studio di psicologia sociale ha esaminato 708 correlazioni ottenute meta-analiticamente, rivelando che la dimensione media dell‚Äôeffetto \\(r\\) era di .19.\nLa conoscenza comune o i risultati di ricerche non psicologiche possono offrire benchmark per valutare la forza di una relazione tra variabili. Un esempio √® l‚Äôefficacia degli antistaminici contro il comune raffreddore, che corrisponde a un \\(r\\) di .11, mentre l‚Äôeffetto degli anti-infiammatori non steroidei (come l‚Äôibuprofene) sul dolore √® di \\(r = .14\\).\n\nTali confronti illustrano come l‚Äôinterpretazione delle dimensioni dell‚Äôeffetto possa essere notevolmente approfondita e resa pi√π significativa attraverso il riferimento a benchmark consolidati o intuitivamente comprensibili, sia dentro che fuori il campo della psicologia. Questo metodo consente di inserire i risultati di nuove ricerche in un contesto pi√π vasto, favorendo una valutazione pi√π consapevole della loro rilevanza relativa.\n\n\n81.3.4 Alternative Migliori per Interpretare la Dimensione dell‚ÄôEffetto\nPer arricchire il significato delle dimensioni dell‚Äôeffetto, √® essenziale adottare approcci che vadano oltre le metriche standardizzate e si basino su criteri di riferimento concreti e contestualizzati. Funder & Ozer (2019) propone due strategie principali: l‚Äôuso di benchmark (criteri di riferimento) e la valutazione delle implicazioni pratiche dei risultati.\n\n81.3.4.1 1. Utilizzare Criteri di Riferimento (Benchmark)\nUn modo efficace per interpretare la dimensione dell‚Äôeffetto √® confrontarla con risultati ben noti e ampiamente compresi, sia all‚Äôinterno del campo di studio che in contesti pi√π generali. Questo approccio √® simile a come giudichiamo l‚Äôaltezza di una persona confrontandola con quella di altre persone.\n\nConfronto con Risultati Classici: I ricercatori possono ottenere una percezione pi√π accurata dell‚Äôimportanza di un risultato confrontandolo con dimensioni dell‚Äôeffetto di studi considerati ‚Äúclassici‚Äù nel proprio campo. Ad esempio, in psicologia, √® possibile fare riferimento a risultati che hanno ottenuto un solido consenso nella comunit√† scientifica.\nMedie da Meta-Analisi: Alcuni ricercatori hanno proposto benchmark calcolando medie su vasti corpi di letteratura. Ad esempio, uno studio di psicologia sociale ha analizzato 708 correlazioni ottenute meta-analiticamente, rilevando che la dimensione media dell‚Äôeffetto \\(r\\) era di 0.19. Questo valore pu√≤ servire come punto di riferimento per valutare l‚Äôentit√† di nuovi risultati.\nEsempi Trasversali: Anche conoscenze comuni o risultati di ricerche non psicologiche possono offrire benchmark utili. Ad esempio:\n\nL‚Äôefficacia degli antistaminici contro il comune raffreddore corrisponde a un \\(r = 0.11\\).\nL‚Äôeffetto degli anti-infiammatori non steroidei (come l‚Äôibuprofene) sul dolore √® pari a \\(r = 0.14\\).\n\n\nQuesti confronti mostrano come l‚Äôinterpretazione della dimensione dell‚Äôeffetto possa essere notevolmente approfondita e resa pi√π significativa attraverso il riferimento a benchmark consolidati o intuitivamente comprensibili.\n\n\n81.3.4.2 2. Valutare le Implicazioni Pratiche\nOltre ai benchmark, √® fondamentale considerare le implicazioni pratiche dei risultati. Un effetto statisticamente piccolo pu√≤ avere un impatto significativo se applicato a un contesto reale. Ad esempio:\n\nUn \\(r = 0.10\\) potrebbe sembrare trascurabile, ma se tradotto in un intervento su larga scala (ad esempio, un programma educativo o una politica sanitaria), potrebbe portare a benefici tangibili per un gran numero di persone.\n\nIn conclusione, l‚Äôinterpretazione della dimensione dell‚Äôeffetto pu√≤ essere notevolmente migliorata attraverso l‚Äôuso di benchmark e la valutazione delle implicazioni pratiche. Confrontare i risultati con studi classici, medie di meta-analisi o esempi tratti da altri campi consente di inserire i nuovi risultati in un contesto pi√π ampio e significativo. Questo approccio non solo arricchisce l‚Äôinterpretazione, ma favorisce anche una valutazione pi√π consapevole della rilevanza e dell‚Äôimpatto delle scoperte scientifiche.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>81</span>¬† <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html#riflessioni-conclusive",
    "href": "chapters/replication_crisis/03_effect_size.html#riflessioni-conclusive",
    "title": "81¬† La grandezza dell‚Äôeffetto",
    "section": "81.4 Riflessioni Conclusive",
    "text": "81.4 Riflessioni Conclusive\nLa sovrastima della grandezza degli effetti in psicologia rappresenta un problema diffuso e significativo. Un principio spesso enfatizzato nella psicologia sociale e nell‚Äôeconomia comportamentale, specialmente nei media e nei corsi di business, √® che piccoli interventi, o ‚Äúnudge‚Äù (spinte gentili), possano produrre effetti sorprendentemente ampi sul comportamento. Questa idea ha portato a numerose affermazioni sensazionalistiche, come l‚Äôipotesi che le elezioni possano essere influenzate dall‚Äôesito di partite di football o che stimoli subliminali, come una faccina sorridente, possano generare cambiamenti drastici negli atteggiamenti verso temi complessi come l‚Äôimmigrazione.\nAlla base di queste affermazioni c‚Äô√® un modello di mondo che non si limita al concetto di ‚Äúeffetto farfalla‚Äù (dove piccoli cambiamenti possono avere conseguenze imprevedibili e amplificate), ma suggerisce che piccoli interventi possano produrre effetti grandi e prevedibili. Questo approccio, talvolta definito ‚Äúmodello a pulsante‚Äù delle scienze sociali, presuppone che, facendo X, si possa aspettarsi di osservare Y in modo sistematico. Tuttavia, questa visione presenta diverse criticit√†:\n\n81.4.1 Problemi del Modello ‚Äúa Pulsante‚Äù\n\nSovrastima degli effetti: Molti studi riportano effetti esagerati per interventi minimi, che spesso non vengono replicati in ricerche successive. Questo solleva dubbi sulla validit√† e sull‚Äôaffidabilit√† di tali risultati.\nMancanza di considerazione delle interazioni: Se esistessero davvero molti effetti grandi e prevedibili, questi interferirebbero tra loro, rendendo difficile osservare risultati coerenti nei dati reali. La complessit√† del comportamento umano raramente si presta a relazioni lineari e isolate.\nInstabilit√† del sistema: Un sistema sociale caratterizzato da molti effetti grandi e prevedibili sarebbe intrinsecamente instabile e difficile da studiare, contraddicendo l‚Äôosservazione che le societ√† tendono a mostrare una certa stabilit√† nel tempo.\nGeneralizzazione eccessiva: Spesso i risultati ottenuti in contesti di laboratorio altamente controllati vengono estesi a situazioni reali molto pi√π complesse, senza considerare le differenze contestuali.\nBias di pubblicazione: Gli studi che riportano effetti grandi e statisticamente significativi hanno maggiori probabilit√† di essere pubblicati, creando una rappresentazione distorta della realt√† e alimentando un ciclo di sovrastima.\n\n\n\n81.4.2 Verso un Approccio pi√π Cauto e Sfumato\nNonostante queste criticit√†, √® importante riconoscere che la psicologia ha identificato molti fenomeni robusti, specialmente in aree come la psicologia clinica e la psicologia della percezione. Tuttavia, √® fondamentale adottare un approccio pi√π cauto e riflessivo nell‚Äôinterpretazione e nella comunicazione dei risultati della ricerca.\nLa consapevolezza di questi problemi ha portato a una serie di miglioramenti metodologici, tra cui:\n\nEnfasi sulla replicabilit√†: Maggiore attenzione alla riproducibilit√† degli studi per garantire che i risultati siano affidabili.\nUso di campioni pi√π ampi: Studi condotti su campioni pi√π grandi e diversificati per aumentare la validit√† esterna.\nMetodi statistici pi√π robusti: Adozione di tecniche statistiche avanzate per ridurre il rischio di falsi positivi.\nApproccio critico e riflessivo: La comunit√† scientifica sta diventando sempre pi√π consapevole della necessit√† di evitare semplificazioni eccessive e di riconoscere la complessit√† dei fenomeni psicologici.\n\nIn sintesi, mentre la psicologia offre intuizioni preziose sul comportamento umano, √® essenziale mantenere un sano scetticismo verso affermazioni di effetti grandi e facilmente ottenibili. La realt√† √® spesso pi√π complessa e sfumata di quanto suggerito da titoli sensazionalistici o da singoli studi. Un approccio equilibrato, che combina rigore metodologico, contestualizzazione e umilt√† scientifica, √® fondamentale per avanzare nella comprensione dei fenomeni psicologici e per evitare di cadere in trappole interpretative che possono distorcere la nostra visione del comportamento umano.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>81</span>¬† <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html#bibliografia",
    "href": "chapters/replication_crisis/03_effect_size.html#bibliografia",
    "title": "81¬† La grandezza dell‚Äôeffetto",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nFunder, D. C., & Ozer, D. J. (2019). Evaluating effect size in psychological research: Sense and nonsense. Advances in Methods and Practices in Psychological Science, 2(2), 156‚Äì168.\n\n\nGlass, G. V., McGaw, B., & Smith, M. L. (1981). Meta-analysis in Social Research. Sage Publications.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>81</span>¬† <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html",
    "href": "chapters/replication_crisis/04_s_m_errors.html",
    "title": "82¬† Errori di segno e errori di grandezza",
    "section": "",
    "text": "82.1 Introduzione\nIn questo capitolo analizzeremo la relazione tra la crisi della replicabilit√† e le procedure decisionali statistiche proprie dell‚Äôapproccio frequentista. In particolare, approfondiremo gli errori di tipo M (magnitude) e di tipo S (sign), discussi da Loken & Gelman (2017), e il loro impatto sulla validit√† dei risultati scientifici.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>82</span>¬† <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#introduzione",
    "href": "chapters/replication_crisis/04_s_m_errors.html#introduzione",
    "title": "82¬† Errori di segno e errori di grandezza",
    "section": "",
    "text": "Domande Iniziali\n\n\n\nPrima di esplorare le simulazioni e i risultati discussi in questo capitolo, prova a riflettere sulle seguenti domande. Ti invitiamo a formulare delle ipotesi sui risultati delle simulazioni prima di leggere le spiegazioni:\n\nSe si effettuano molteplici studi su un effetto molto piccolo utilizzando campioni di dimensioni ridotte, cosa pensi che accadr√† ai risultati pubblicati che ottengono significativit√† statistica? Saranno accurati rispetto alla vera grandezza dell‚Äôeffetto?\nIn uno scenario in cui non esiste alcuna differenza tra due gruppi, quanto spesso credi che un test t fornisca un risultato statisticamente significativo che verr√† pubblicato? Quali fattori potrebbero influenzare questa probabilit√†?\nSupponiamo che in una serie di esperimenti alcuni studi trovino effetti significativi e altri no. Quale pensi sia la tendenza degli studi pubblicati rispetto a quelli non pubblicati? Quale impatto pu√≤ avere questa tendenza sulla percezione della realt√† scientifica?\nSe dovessi valutare la replicabilit√† di uno studio basato sulla significativit√† statistica, quali problemi potresti incontrare se l‚Äôeffetto sottostante √® molto piccolo?\n\nTieni a mente le tue risposte mentre esplori le simulazioni presentate in questo capitolo. Alla fine del capitolo, confronteremo le previsioni con i risultati effettivi.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>82</span>¬† <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#il-filtro-della-significativit√†-statistica",
    "href": "chapters/replication_crisis/04_s_m_errors.html#il-filtro-della-significativit√†-statistica",
    "title": "82¬† Errori di segno e errori di grandezza",
    "section": "\n82.2 Il Filtro della Significativit√† Statistica",
    "text": "82.2 Il Filtro della Significativit√† Statistica\nNel ?sec-crisis abbiamo esplorato come la pratica scientifica contemporanea sia spesso compromessa da casi di frode, principalmente a causa delle significative implicazioni economiche legate alla pubblicazione su riviste scientifiche di alto prestigio. Questo fenomeno √® spesso sottovalutato, poich√© le riviste tendono a essere riluttanti nel riconoscere la necessit√† di correzioni o ritrattazioni degli articoli gi√† pubblicati.\nLa frode scientifica rappresenta una minaccia evidente alla riproducibilit√† dei risultati, un pilastro fondamentale del metodo scientifico. Tuttavia, le difficolt√† nel replicare i risultati pubblicati non sono attribuibili esclusivamente a frodi o a ‚Äúpratiche di ricerca disoneste‚Äù (Nelson et al., 2018). Un problema intrinseco risiede nel metodo statistico ampiamente adottato dai ricercatori: l‚Äôapproccio del test di ipotesi nulla e della significativit√† statistica di stampo fisheriano. Secondo questo metodo, i risultati che non raggiungono la soglia di ‚Äúsignificativit√† statistica‚Äù vengono scartati, mentre quelli che la superano sono considerati credibili, basandosi esclusivamente su questo criterio (Wagenmakers et al., 2008).\nTuttavia, l‚Äôidea che la significativit√† statistica sia un filtro affidabile per distinguere i risultati di ricerca ‚Äúvalidi‚Äù da quelli ‚Äúnon validi‚Äù √® fondamentalmente errata. Numerose evidenze dimostrano i limiti di questo approccio. Per approfondire questa problematica, esamineremo lo studio di Loken & Gelman (2017), che mette in luce la relazione tra la crisi della replicabilit√† e le procedure decisionali statistiche dell‚Äôapproccio frequentista.\nUno dei principali problemi evidenziati da Loken & Gelman (2017) √® che, in contesti di ricerca complessi, la significativit√† statistica fornisce prove molto deboli riguardo al segno (sign) o all‚Äôentit√† (magnitude) degli effetti sottostanti. In altre parole, il raggiungimento della significativit√† statistica non garantisce n√© la rilevanza n√© la consistenza dei risultati ottenuti. Questo solleva seri dubbi sull‚Äôaffidabilit√† di tale criterio come unico strumento per valutare la validit√† delle scoperte scientifiche.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>82</span>¬† <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#errori-di-tipo-m-e-s",
    "href": "chapters/replication_crisis/04_s_m_errors.html#errori-di-tipo-m-e-s",
    "title": "82¬† Errori di segno e errori di grandezza",
    "section": "\n82.3 Errori di tipo M e S\n",
    "text": "82.3 Errori di tipo M e S\n\nPer illustrare le implicazioni del processo decisionale basato sulla significativit√† statistica, Loken & Gelman (2017) hanno condotto una simulazione. In questa simulazione, hanno considerato uno scenario di ricerca ipotetico in cui era presente un effetto reale, sebbene molto debole, difficilmente rilevabile senza un ampio volume di dati. Utilizzando l‚Äôapproccio frequentista, hanno cercato di identificare questo effetto valutando la significativit√† statistica.\nI risultati della simulazione hanno mostrato che, anche in presenza di un effetto reale (seppur debole), l‚Äôapproccio frequentista riusciva a rilevare un effetto statisticamente significativo solo in una piccola percentuale dei casi. Inoltre, quando un effetto significativo veniva individuato, la stima della sua grandezza risultava altamente imprecisa e instabile.\nIn sintesi, la significativit√† statistica fornisce un‚Äôindicazione generica sulla presenza o assenza di un effetto, ma non offre informazioni affidabili sulla sua entit√† o replicabilit√†. Questo problema √® particolarmente rilevante in campi come la psicologia e le scienze sociali, dove gli studi spesso si basano su campioni di dimensioni ridotte e gli effetti osservati tendono a essere modesti. In tali contesti, l‚Äôapproccio frequentista rischia di produrre prove deboli e instabili, compromettendo la replicabilit√† e l‚Äôaffidabilit√† dei risultati.\n\n82.3.1 Simulazione semplificata\nRiproduciamo qui, in forma semplificata, la simulazione condotta da Loken & Gelman (2017). Iniziamo importando le librerie necessarie.\nConsideriamo due campioni casuali indipendenti di dimensioni \\(n_1 = 20\\) e \\(n_2 = 25\\), estratti rispettivamente dalle distribuzioni normali \\(\\mathcal{N}(102, 10)\\) e \\(\\mathcal{N}(100, 10)\\). La dimensione effettiva dell‚Äôeffetto (\\(d\\)) per la differenza tra le medie dei due campioni √® calcolata utilizzando la formula:\n\\[\nd = \\frac{\\bar{y}_1 - \\bar{y}_2}{s_p},\n\\]\ndove \\(\\bar{y}_1\\) e \\(\\bar{y}_2\\) rappresentano le medie campionarie dei due gruppi, e \\(s_p\\) √® la deviazione standard combinata, definita come:\n\\[\ns_p = \\sqrt{\\frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1 + n_2 - 2}}.\n\\]\nIn questo caso specifico, la dimensione effettiva dell‚Äôeffetto risulta molto piccola, indicando che la differenza osservata tra le medie dei due gruppi non ha una rilevanza pratica significativa. Ci√≤ suggerisce che la distinzione tra i due gruppi, seppur statisticamente rilevabile, non ha un impatto sostanziale in contesti reali.\n\n# Parametri\nmu_1 &lt;- 102  # Media del primo gruppo\nmu_2 &lt;- 100  # Media del secondo gruppo\nsigma &lt;- 10  # Deviazione standard comune\nn1 &lt;- 20     # Numero di osservazioni nel primo gruppo\nn2 &lt;- 25     # Numero di osservazioni nel secondo gruppo\n\n# Calcolo della differenza media\nmean_difference &lt;- abs(mu_1 - mu_2)\n\n# Calcolo della deviazione standard pooled\npooled_sd &lt;- sqrt(((n1 - 1) * sigma^2 + (n2 - 1) * sigma^2) / (n1 + n2 - 2))\n\n# Calcolo di Cohen's d\ncohen_d &lt;- mean_difference / pooled_sd\n\n# Output del risultato\ncat(\"Dimensione dell'effetto (Cohen's d):\", cohen_d, \"\\n\")\n#&gt; Dimensione dell'effetto (Cohen's d): 0.2\n\nEsaminiamo ora le conclusioni che emergerebbero applicando l‚Äôapproccio frequentista e la sua procedura di decisione statistica in questo contesto. Supponiamo di condurre una simulazione in cui vengono estratti due campioni: il primo composto da 20 osservazioni provenienti dalla prima popolazione e il secondo da 25 osservazioni provenienti dalla seconda popolazione. Successivamente, applichiamo il test \\(t\\) di Student per confrontare le medie dei due gruppi.\nNell‚Äôambito dell‚Äôapproccio frequentista, il valore-\\(p\\) ottenuto dal test determina la decisione statistica. Se il valore-\\(p\\) √® superiore a 0.05, i risultati vengono considerati non significativi e, di conseguenza, scartati. Al contrario, se il valore-\\(p\\) √® inferiore a 0.05, il risultato √® ritenuto ‚Äúpubblicabile‚Äù e si conclude che esiste una differenza statisticamente significativa tra i due gruppi.\nPer valutare in modo approfondito le conclusioni derivate da questa procedura, √® necessario ripetere l‚Äôintero processo per un numero elevato di iterazioni, ad esempio 50.000 volte. Ci√≤ significa che, in ciascuna iterazione, vengono estratti nuovi campioni, viene calcolato il test \\(t\\) di Student e viene determinato il corrispondente valore-\\(p\\). Ripetendo questo processo su larga scala, √® possibile ottenere una distribuzione completa dei risultati, che consente di analizzare la frequenza con cui si ottengono risultati significativi e la stabilit√† delle stime prodotte dall‚Äôapproccio frequentista in questo contesto.\n\n# Parametri\nn_samples &lt;- 50000\nmu_1 &lt;- 102\nmu_2 &lt;- 100\nsigma &lt;- 10\nn1 &lt;- 20\nn2 &lt;- 25\n\n# Inizializzazione del risultato\nres &lt;- c()\n\n# Simulazioni\nset.seed(123)  # Per la riproducibilit√†\nfor (i in 1:n_samples) {\n  # Generazione dei campioni casuali\n  y1 &lt;- rnorm(n1, mean = mu_1, sd = sigma)\n  y2 &lt;- rnorm(n2, mean = mu_2, sd = sigma)\n  \n  # Calcolo della dimensione dell'effetto\n  y1bar &lt;- mean(y1)\n  y2bar &lt;- mean(y2)\n  v1 &lt;- var(y1)\n  v2 &lt;- var(y2)\n  s &lt;- sqrt(((n1 - 1) * v1 + (n2 - 1) * v2) / (n1 + n2 - 2))\n  efsize &lt;- (y1bar - y2bar) / s\n  \n  # Calcolo del valore p\n  t_test &lt;- t.test(y1, y2, var.equal = TRUE)\n  \n  # Salvataggio della dimensione dell'effetto solo per risultati \"statisticamente significativi\"\n  if (t_test$p.value &lt; 0.05) {\n    res &lt;- c(res, efsize)\n  }\n}\n\n\nres_df &lt;- data.frame(effect_size = res)\n\nggplot(res_df, aes(x = effect_size)) +\n  geom_histogram(bins = 20, fill = \"blue\", color = \"black\", alpha = 0.7) +\n  geom_vline(\n    xintercept = 0.2, color = \"red\", linetype = \"dashed\", \n    size = 1.2, label = \"True Effect Size\") +\n  labs(\n    x = \"Effect Size\",\n    y = \"Frequency\",\n    title = \"Histogram of Effect Sizes for\\n'Statistically Significant' Results\"\n  ) \n\n\n\n\n\n\n\nCome evidenziato da Loken & Gelman (2017), l‚Äôapplicazione dell‚Äôapproccio frequentista nella procedura di decisione statistica pu√≤ condurre a due tipi di errori rilevanti. Il primo, noto come errore di magnitude (grandezza), si manifesta quando i risultati pubblicati tendono a sovrastimare la reale entit√† dell‚Äôeffetto. Nella simulazione condotta, nonostante la vera grandezza dell‚Äôeffetto fosse modesta (0.2), la media della grandezza dell‚Äôeffetto per i risultati classificati come ‚Äústatisticamente significativi‚Äù era circa 0.8, suggerendo un effetto di entit√† ‚Äúampia‚Äù. Questo indica una distorsione sistematica verso stime esagerate.\nIl secondo errore, chiamato errore di segno, si verifica quando, a causa della variabilit√† campionaria, la direzione dell‚Äôeffetto viene stimata in modo errato. In tali casi, il ricercatore potrebbe erroneamente concludere che \\(\\mu_2 &gt; \\mu_1\\), quando in realt√† non √® cos√¨. √à importante sottolineare che, anche in queste situazioni, la grandezza assoluta dell‚Äôeffetto risulta sovrastimata.\nUn aspetto degno di nota √® che queste conclusioni rimarrebbero valide anche se si considerasse l‚Äôintervallo di confidenza per la differenza tra le medie. In sintesi, l‚Äôapproccio frequentista introduce un errore sistematico nella stima della grandezza dell‚Äôeffetto, che rappresenta la quantit√† pi√π rilevante per il ricercatore. In alcuni casi, pu√≤ persino portare a errori nella determinazione della direzione dell‚Äôeffetto, compromettendo ulteriormente l‚Äôaffidabilit√† delle conclusioni scientifiche.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>82</span>¬† <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#riflessioni-conclusive",
    "href": "chapters/replication_crisis/04_s_m_errors.html#riflessioni-conclusive",
    "title": "82¬† Errori di segno e errori di grandezza",
    "section": "\n82.4 Riflessioni Conclusive",
    "text": "82.4 Riflessioni Conclusive\nIn conclusione, l‚Äôapproccio frequentista non rappresenta un metodo affidabile per valutare i risultati della ricerca e determinarne l‚Äôattendibilit√† o la necessit√† di scartarli (Gelman & Carlin, 2014; Loken & Gelman, 2017). Questa mancanza di affidabilit√† √® dovuta all‚Äôintroduzione di errori sistematici nella stima della grandezza degli effetti, che in alcuni casi possono persino portare a errori nella direzione dell‚Äôeffetto stesso. Alla luce di queste criticit√†, non sembrano esserci motivi validi per continuare a fare affidamento su questo approccio.\nAl contrario, l‚Äôadozione dell‚Äôapproccio bayesiano sembra offrire una soluzione pi√π precisa e affidabile per l‚Äôanalisi dei dati di ricerca. Questo metodo valuta la probabilit√† delle ipotesi alla luce dei dati osservati, evitando gli errori intrinseci dell‚Äôapproccio frequentista e fornendo una base pi√π solida per prendere decisioni informate sulla validit√† dei risultati. In questo modo, l‚Äôapproccio bayesiano si presenta come un‚Äôalternativa pi√π robusta e scientificamente rigorosa.\n\n\n\n\n\n\nRisposte alle domande iniziali\n\n\n\n\n\nOra confrontiamo le previsioni con i risultati ottenuti dalle simulazioni:\n\nSovrastima della grandezza dell‚Äôeffetto: I risultati pubblicati tendono a essere selezionati sulla base della significativit√† statistica, il che porta a una sovrastima sistematica della grandezza dell‚Äôeffetto rispetto alla realt√†. Questo fenomeno, noto come errore di tipo M (magnitude), si verifica perch√© solo gli effetti con valori estremi (per caso) superano la soglia di significativit√† statistica e vengono pubblicati.\nFalsi positivi e loro frequenza: In uno scenario in cui non esiste alcuna differenza tra i due gruppi (cio√® la vera differenza √® zero), il test t ha fornito risultati statisticamente significativi nel 5% dei casi, come previsto dalla soglia di Œ± = 0.05. Tuttavia, la selezione dei risultati pubblicati amplifica questo problema, rendendo pi√π probabile che i lettori incontrino falsi positivi nella letteratura scientifica.\nBias nella pubblicazione: Gli studi che riportano risultati significativi hanno maggiore probabilit√† di essere pubblicati rispetto a quelli che non trovano un effetto significativo. Questo porta a un effetto distorsivo nella letteratura scientifica, in cui i risultati pubblicati tendono a sovrastimare l‚Äôeffetto reale. Il ‚Äúfiltro della significativit√† statistica‚Äù crea una percezione distorta della realt√† scientifica, poich√© gli effetti nulli o piccoli tendono a essere sottorappresentati nella letteratura.\nReplicabilit√† e significativit√† statistica: Gli studi con effetti piccoli e campioni ridotti sono particolarmente vulnerabili al fallimento della replicazione. Anche quando un effetto reale esiste, la probabilit√† di ottenerne una stima precisa √® bassa, e la replicazione potrebbe risultare in un valore non significativo, generando confusione nella comunit√† scientifica.\n\nConsiderazioni Finali\nLe simulazioni evidenziano come la significativit√† statistica, utilizzata come criterio per la pubblicazione, contribuisca a un bias nella selezione dei risultati, distorcendo la percezione della realt√† scientifica. Questo fenomeno, noto come ‚Äúfiltro della significativit√† statistica‚Äù, √® una delle cause principali della crisi della replicabilit√†, poich√© induce i ricercatori e i lettori a sovrastimare la grandezza e la presenza di effetti studiati.\nPer affrontare queste problematiche, approcci alternativi, come quelli bayesiani, possono offrire soluzioni pi√π robuste, permettendo una valutazione pi√π affidabile delle ipotesi alla luce dei dati osservati.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>82</span>¬† <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#esercizi",
    "href": "chapters/replication_crisis/04_s_m_errors.html#esercizi",
    "title": "82¬† Errori di segno e errori di grandezza",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\n\nPerch√© la significativit√† statistica non √® un criterio affidabile per valutare la validit√† dei risultati scientifici?\nSpiega il concetto di ‚Äúfiltro della significativit√† statistica‚Äù e il suo impatto sulla pubblicazione dei risultati.\nQual √® la differenza tra errore di tipo M e errore di tipo S? Come influenzano l‚Äôinterpretazione dei risultati?\nPerch√© i risultati pubblicati tendono a sovrastimare la grandezza dell‚Äôeffetto rispetto alla realt√†?\nQuali sono le conseguenze della pubblicazione selettiva dei risultati per la replicabilit√† degli studi?\nPerch√© gli studi con campioni di piccole dimensioni sono pi√π vulnerabili a errori nella stima della grandezza dell‚Äôeffetto?\nIn che modo la selezione dei risultati pubblicati altera la percezione della forza degli effetti studiati?\nPerch√© un test frequentista pu√≤ portare a una falsa conclusione sulla direzione di un effetto?\nQuali sono le principali differenze tra l‚Äôapproccio frequentista e quello bayesiano nella valutazione della significativit√† di un effetto?\nIn che modo l‚Äôapproccio bayesiano pu√≤ ridurre il rischio di errori dovuti alla selezione dei risultati basata sulla significativit√† statistica?\n\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\n\nLa significativit√† statistica non garantisce la validit√† di un risultato perch√© dipende dalla dimensione del campione e da soglie arbitrarie (come p &lt; 0.05). Inoltre, non misura la rilevanza pratica di un effetto, ma solo la probabilit√† che i dati osservati siano ottenuti sotto l‚Äôipotesi nulla.\nIl ‚Äúfiltro della significativit√† statistica‚Äù si riferisce alla tendenza a pubblicare solo risultati con p &lt; 0.05, tralasciando studi con risultati non significativi. Questo porta a una distorsione nella letteratura scientifica e a una sovrastima della forza degli effetti riportati.\nErrore di tipo M (Magnitude) indica la sovrastima della grandezza dell‚Äôeffetto nei risultati pubblicati, mentre errore di tipo S (Sign) si riferisce all‚Äôerrata determinazione della direzione dell‚Äôeffetto. Questi errori si verificano perch√© solo gli effetti pi√π estremi tendono a superare il filtro della significativit√† statistica.\nI risultati pubblicati tendono a sovrastimare la grandezza dell‚Äôeffetto perch√© solo gli effetti pi√π grandi (anche per pura casualit√†) superano la soglia di significativit√† statistica e vengono pubblicati, mentre quelli pi√π piccoli restano inediti.\nLa pubblicazione selettiva riduce la replicabilit√† perch√© introduce una distorsione sistematica nei risultati disponibili. Le repliche spesso non trovano effetti altrettanto grandi o significativi, creando instabilit√† nella conoscenza scientifica.\nI campioni piccoli aumentano la variabilit√† delle stime dell‚Äôeffetto, rendendo pi√π probabile che un risultato significativo sia solo un‚Äôoscillazione casuale dei dati piuttosto che un vero effetto replicabile.\nLa selezione dei risultati pubblicati altera la percezione della forza degli effetti perch√© induce i lettori a credere che gli effetti siano pi√π forti e consistenti di quanto non siano realmente.\nUn test frequentista pu√≤ portare a una falsa conclusione sulla direzione dell‚Äôeffetto perch√©, in campioni piccoli, le stime dell‚Äôeffetto possono essere fortemente influenzate dal rumore, portando a interpretazioni errate.\nL‚Äôapproccio frequentista si basa sul valore-p e sulla soglia di significativit√†, mentre l‚Äôapproccio bayesiano utilizza la probabilit√† a posteriori per aggiornare la credibilit√† delle ipotesi alla luce dei dati osservati. Il metodo bayesiano permette inferenze pi√π flessibili e robuste.\nL‚Äôapproccio bayesiano riduce il rischio di errori dovuti alla selezione dei risultati perch√© non si basa su una soglia arbitraria di significativit√†, ma fornisce un quadro probabilistico della forza dell‚Äôeffetto, evitando distorsioni dovute alla pubblicazione selettiva.\n\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nIn questo esercizio simuleremo pi√π esperimenti, ognuno con 15 osservazioni, per comprendere come il filtro della significativit√† statistica possa distorcere le nostre conclusioni sugli effetti osservati.\nObiettivo\n\nComprendere come l‚Äôapproccio frequentista possa portare a stime errate dell‚Äôeffetto reale.\nEsplorare gli errori di tipo M (magnitude) e S (sign), derivanti dal filtro della significativit√† statistica.\n\nStruttura dell‚Äôesercizio\n\nSimuliamo esperimenti in cui il vero effetto tra due gruppi √® piccolo (Cohen‚Äôs d = 0.2). Consideriamo i dati SWLS e due popolazioni che differiscono nel modo indicato. Ipotizziamo che le due popolazioni SWLS siano normali.\nEstraiamo 15 osservazioni per gruppo.\nUsiamo un test t per verificare se la differenza tra i gruppi √® significativa.\nRegistriamo solo i risultati con p &lt; 0.05, calcolando la distribuzione degli effetti significativi.\nValutiamo se la stima dell‚Äôeffetto nei risultati pubblicabili √® gonfiata rispetto al vero effetto.\nContiamo i casi in cui il segno dell‚Äôeffetto √® invertito.\n\n\n\n\n\n\n\n\n\n\nSoluzioni 2\n\n\n\n\n\n# Librerie necessarie\nlibrary(ggplot2)\n\n# Impostazioni della simulazione\nset.seed(42)         # Per la riproducibilit√†\nn_sims &lt;- 50000      # Numero di simulazioni\nn_per_group &lt;- 15    # Numero di osservazioni per gruppo\ntrue_d &lt;- 0.2        # Vero effetto (Cohen's d)\nswls_mean &lt;- 25      # Media ipotizzata per il primo gruppo\nswls_sd &lt;- 5         # Deviazione standard ipotizzata per la SWLS\n\n# Calcolo della media del secondo gruppo sulla base di Cohen's d\nswls_mean_2 &lt;- swls_mean + true_d * swls_sd\n\n# Inizializziamo i vettori per registrare i risultati\neffect_sizes &lt;- c()\nfalse_sign_count &lt;- 0\n\n# Simulazioni\nfor (i in 1:n_sims) {\n  # Generazione dei due gruppi da distribuzioni normali\n  group1 &lt;- rnorm(n_per_group, mean = swls_mean, sd = swls_sd)\n  group2 &lt;- rnorm(n_per_group, mean = swls_mean_2, sd = swls_sd)\n  \n  # Calcolo della dimensione dell'effetto (Cohen's d)\n  mean_diff &lt;- mean(group2) - mean(group1)\n  pooled_sd &lt;- sqrt(((n_per_group - 1) * var(group1) + (n_per_group - 1) * var(group2)) / (2 * n_per_group - 2))\n  d_estimated &lt;- mean_diff / pooled_sd\n  \n  # Test t per confrontare le medie\n  t_test &lt;- t.test(group1, group2, var.equal = TRUE)\n  \n  # Consideriamo solo i risultati statisticamente significativi\n  if (t_test$p.value &lt; 0.05) {\n    effect_sizes &lt;- c(effect_sizes, d_estimated)\n    \n    # Conta i casi in cui il segno √® invertito\n    if (d_estimated &lt; 0) {\n      false_sign_count &lt;- false_sign_count + 1\n    }\n  }\n}\n\n# Creazione di un dataframe per la visualizzazione\nres_df &lt;- data.frame(effect_size = effect_sizes)\n\n# Istogramma della dimensione dell'effetto tra i risultati \"significativi\"\nggplot(res_df, aes(x = effect_size)) +\n  geom_histogram(bins = 30, fill = \"blue\", color = \"black\", alpha = 0.7) +\n  geom_vline(xintercept = true_d, color = \"red\", linetype = \"dashed\", size = 1.2) +\n  labs(\n    x = \"Dimensione dell'effetto stimata\",\n    y = \"Frequenza\",\n    title = \"Distribuzione degli effetti significativi (SWLS)\"\n  ) +\n  theme_minimal()\n\n# Output di sintesi\ncat(\"Numero di risultati statisticamente significativi:\", length(effect_sizes), \"\\n\")\ncat(\"Media della dimensione dell'effetto tra i risultati pubblicati:\", mean(effect_sizes), \"\\n\")\ncat(\"Numero di risultati con segno invertito:\", false_sign_count, \"\\n\")\ncat(\"Proporzione di risultati con segno invertito:\", false_sign_count / length(effect_sizes), \"\\n\")\nInterpretazione dei Risultati\n\n\nErrore di tipo M (Magnitude): La media degli effetti stimati nei risultati pubblicati sar√† molto pi√π grande di 0.2 (il vero effetto), dimostrando come il filtro della significativit√† tenda a sovrastimare gli effetti reali.\n\nErrore di tipo S (Sign): Una percentuale dei risultati pubblicabili mostrer√† effetti nella direzione sbagliata (d &lt; 0), dimostrando che il processo decisionale basato su p &lt; 0.05 pu√≤ portare a conclusioni errate.\n\nVisualizzazione: L‚Äôistogramma mostrer√† che la distribuzione degli effetti significativi √® spostata rispetto al vero effetto (linea rossa tratteggiata).\n\nDomande di discussione:\n\nPerch√© la stima dell‚Äôeffetto √® gonfiata nei risultati pubblicabili?\nCome cambia la situazione aumentando il numero di osservazioni per gruppo?\nQuali strategie alternative potrebbero ridurre questi errori?\n\nApprofondimento:\n\nRipetere l‚Äôesperimento con n_per_group = 50 e osservare se l‚Äôerrore di tipo M diminuisce.\nConfrontare questo approccio con un‚Äôanalisi Bayesiana per evidenziare il ruolo dell‚Äôinferenza basata su probabilit√† posteriori.\n\nConclusione\nQuesto esercizio mostra chiaramente i problemi dell‚Äôapproccio frequentista basato su p &lt; 0.05, evidenziando i limiti dell‚Äôuso della significativit√† statistica come filtro decisionale.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>82</span>¬† <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/replication_crisis/04_s_m_errors.html#informazioni-sullambiente-di-sviluppo",
    "title": "82¬† Errori di segno e errori di grandezza",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.5.3     \n#&gt;  [9] scales_1.3.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.9.1   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         rlang_1.1.5       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       yaml_2.3.10       tools_4.4.2       parallel_4.4.2   \n#&gt; [21] tzdb_0.5.0        colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5      \n#&gt; [25] R6_2.6.1          lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3  \n#&gt; [29] pillar_1.10.1     gtable_0.3.6      glue_1.8.0        xfun_0.51        \n#&gt; [33] tidyselect_1.2.1  rstudioapi_0.17.1 farver_2.1.2      htmltools_0.5.8.1\n#&gt; [37] nlme_3.1-167      labeling_0.4.3    rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>82</span>¬† <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#bibliografia",
    "href": "chapters/replication_crisis/04_s_m_errors.html#bibliografia",
    "title": "82¬† Errori di segno e errori di grandezza",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., & Carlin, J. (2014). Beyond Power Calculations: Assessing Type S (Sign) and Type M (Magnitude) Errors. Perspectives on Psychological Science, 9(6), 641‚Äì651.\n\n\nLoken, E., & Gelman, A. (2017). Measurement Error and the Replication Crisis. Science, 355(6325), 584‚Äì585.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nNelson, L. D., Simmons, J., & Simonsohn, U. (2018). Psychology‚Äôs renaissance. Annual review of psychology, 69(1), 511‚Äì534.\n\n\nWagenmakers, E.-J., Lee, M., Lodewyckx, T., & Iverson, G. J. (2008). Bayesian versus frequentist inference. Bayesian evaluation of informative hypotheses, 181‚Äì207.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>82</span>¬† <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/05_p_values.html",
    "href": "chapters/replication_crisis/05_p_values.html",
    "title": "\n83¬† La fragilit√† del p-valore\n",
    "section": "",
    "text": "83.1 Introduzione\nIl codice presentato √® ispirato da un post sul blog di Andrew Gelman. L‚Äôobiettivo √® esplorare la fragilit√† dei p-valori e la loro variabilit√† in diverse condizioni sperimentali.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>83</span>¬† <span class='chapter-title'>La fragilit√† del *p*-valore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/05_p_values.html#simulazione",
    "href": "chapters/replication_crisis/05_p_values.html#simulazione",
    "title": "\n83¬† La fragilit√† del p-valore\n",
    "section": "\n83.2 Simulazione",
    "text": "83.2 Simulazione\nQuesta simulazione mira a dimostrare quanto i p-valori possano essere instabili e variare significativamente da campione a campione, anche quando i dati provengono da una distribuzione con parametri molto simili. Questo evidenzia come il p-valore, comunemente utilizzato per valutare la significativit√† statistica di un effetto, possa essere fortemente influenzato dalla variabilit√† campionaria, specialmente in campioni di piccole dimensioni o con effetti deboli. Gelman & Stern (2006) esprimono questo concetto affermando che:\n\nla differenza tra ‚Äúsignificativo‚Äù e ‚Äúnon significativo‚Äù non √® di per s√© statisticamente significativa.\n\n\n83.2.1 Logica della Simulazione\n\n\nObiettivo:\n\nDimostrare la variabilit√† dei p-valori calcolati su diversi campioni estratti da una popolazione con una media molto vicina a zero.\nMostrare come, nonostante l‚Äôeffetto reale sia piccolo, i p-valori possano variare notevolmente a seconda della variabilit√† e delle dimensioni del campione.\n\n\n\nSetup della Simulazione:\n\nGeneriamo \\(J = 10\\) campioni indipendenti, ciascuno con un numero ridotto di osservazioni (\\(n = 10\\)), per massimizzare la variabilit√† dei risultati.\nOgni campione √® generato da una distribuzione normale con una media vera di \\(\\mu = 0.05\\) e una deviazione standard di \\(\\sigma = 0.1\\). Questi parametri sono scelti per rendere la media dei campioni vicina a zero, mantenendo una certa variabilit√†.\n\n\n\nCalcolo della media campionaria:\n\nPer ciascun campione, calcoliamo la media (\\(\\hat{\\mu}\\)) e la deviazione standard (\\(\\hat{\\sigma}\\)).\nLa media del campione (\\(\\hat{\\mu}\\)) √® utilizzata come stima del parametro.\n\n\n\nCalcolo del p-valore:\n\nApplichiamo un t-test per ciascun campione per verificare l‚Äôipotesi nulla (\\(H_0\\)) che la media del campione sia zero.\n\nIl p-valore viene calcolato utilizzando la formula classica del t-test:\n\\[\nt = \\frac{\\hat{\\mu}}{\\frac{\\hat{\\sigma}}{\\sqrt{n}}}\n\\]\ndove:\n\n\n\\(\\hat{\\mu}\\) √® la media del campione,\n\n\\(\\hat{\\sigma}\\) √® la deviazione standard del campione,\n\n\\(n\\) √® il numero di osservazioni per campione.\n\n\n\nSuccessivamente, il p-valore √® calcolato come:\n\\[\n\\text{p-value} = 2 \\times (1 - \\text{CDF}(|t|))\n\\]\ndove \\(\\text{CDF}\\) √® la funzione cumulativa della distribuzione t con \\(n-1\\) gradi di libert√†.\n\n\n\n\n83.2.2 Descrizione della Sintassi\nIl codice R √® strutturato come segue:\n\n\nGenerazione dei campioni:\n\nCreiamo una lista di campioni (10 campioni in totale), ciascuno con 10 osservazioni, utilizzando la distribuzione normale con media 0.05 e deviazione standard 0.1.\n\n\n\nCalcolo delle medie e dei p-valori:\n\nIteriamo su ciascun campione per calcolare la media (\\(\\hat{\\mu}\\)) e la deviazione standard (\\(\\hat{\\sigma}\\)).\nCalcoliamo il valore statistico \\(t\\) e il corrispondente p-valore utilizzando la distribuzione t.\n\n\n\nStampa dei risultati:\n\nI p-valori vengono arrotondati e stampati per osservare la loro variabilit√†.\n\n\n\n\n# Imposta il seme per riproducibilit√†\nset.seed(1234)\n\n# Parametri della simulazione\nJ &lt;- 10              # Numero di campioni indipendenti\nn &lt;- 10              # Numero di osservazioni per campione\ntrue_mean &lt;- 0.05    # Media vera della popolazione\ntrue_sd &lt;- 0.1       # Deviazione standard della popolazione\n\n# Genera i campioni casuali\nsamples &lt;- replicate(J, rnorm(n, mean = true_mean, sd = true_sd), simplify = FALSE)\n\n# Calcola statistiche campionarie e p-valori\nresults &lt;- lapply(samples, function(sample) {\n  sample_mean &lt;- mean(sample)                         # Media campionaria\n  sample_sd &lt;- sd(sample)                             # Deviazione standard campionaria\n  t_statistic &lt;- sample_mean / (sample_sd / sqrt(n))  # Statistica t\n  p_value &lt;- 2 * (1 - pt(abs(t_statistic), df = n - 1))  # p-valore bilaterale\n  list(mean = sample_mean, sd = sample_sd, t = t_statistic, p_value = p_value)\n})\n\n# Converti i risultati in un data frame per facilitarne la visualizzazione\nresults_df &lt;- do.call(rbind, lapply(results, as.data.frame))\nrownames(results_df) &lt;- paste(\"C\", 1:J)\n\n# Visualizza i risultati\nprint(results_df)\n#&gt;          mean      sd       t  p_value\n#&gt; C 1   0.01168 0.09958  0.3711 0.719183\n#&gt; C 2   0.03818 0.10673  1.1313 0.287183\n#&gt; C 3   0.01121 0.06660  0.5320 0.607576\n#&gt; C 4  -0.02662 0.08942 -0.9413 0.371116\n#&gt; C 5  -0.01098 0.07872 -0.4411 0.669552\n#&gt; C 6   0.02211 0.11860  0.5896 0.569941\n#&gt; C 7   0.11166 0.11442  3.0860 0.013013\n#&gt; C 8   0.04577 0.09237  1.5670 0.151566\n#&gt; C 9   0.03415 0.07349  1.4695 0.175755\n#&gt; C 10  0.10607 0.09840  3.4089 0.007763\n\n\nggplot(results_df, aes(x = rownames(results_df), y = p_value)) +\n  geom_point(size = 3, color = \"blue\") +\n  geom_hline(yintercept = 0.05, linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Variabilit√† dei p-valori nei campioni\",\n    x = \"Campioni\",\n    y = \"p-valore\"\n  ) \n\n\n\n\n\n\n\n\n83.2.3 Interpretazione dei Risultati\nImmaginiamo che questo sia un esperimento reale. Alcuni campioni potrebbero mostrare risultati compatibili con il puro rumore, altri fornire deboli indicazioni contro l‚Äôipotesi nulla, mentre altri ancora potrebbero sembrare altamente significativi dal punto di vista statistico. Tuttavia, la differenza tra ‚Äúsignificativo‚Äù e ‚Äúnon significativo‚Äù non √® di per s√© statisticamente significativa. Ad esempio, una differenza tra un p-valore di 0.336 e uno di 0.003 potrebbe sembrare rilevante, ma non lo √®.\nQuesto scenario estremo riflette una situazione in cui non c‚Äô√® una reale variazione sottostante. Se si utilizzasse un modello multilivello, probabilmente emergerebbe l‚Äôassenza di una variazione effettiva significativa.\n\n83.2.4 Punti Chiave\n\nIl p-valore descrive solo l‚Äôipotesi nulla: √à una misura relativa all‚Äôassenza di effetto, ma non ha necessariamente un significato diretto rispetto a un effetto reale, anche se piccolo.\nIl p-valore √® altamente variabile: Essendo una trasformazione non lineare dello z-score, il p-valore pu√≤ comportarsi in modi non intuitivi, soprattutto con campioni piccoli.\nLe simulazioni sono istruttive: Anche esperimenti semplici come questo possono essere estremamente utili per comprendere le limitazioni e l‚Äôinterpretazione dei risultati.\n\n83.2.5 Un Avvertimento Importante\nAnche le inferenze bayesiane sono soggette a variabilit√†. Qualsiasi sintesi dei dati porta con s√© un certo grado di incertezza. Il problema non risiede nei p-valori in s√©, ma nel loro utilizzo scorretto. Interpretare un p-valore come una dichiarazione forte sulla realt√†, invece di considerarlo un riassunto rumoroso di un esperimento specifico, √® un errore comune.\nAllo stesso modo, fraintendimenti e sovrainterpretazioni possono verificarsi anche con approcci bayesiani. Ad esempio, l‚Äôadattamento di un modello con prior non informativi e l‚Äôinterpretazione della probabilit√† posteriore di un parametro (ad esempio, maggiore di zero) sulla base di una soglia arbitraria pu√≤ portare a conclusioni altrettanto problematiche. Questi risultati ci ricordano l‚Äôimportanza di una sana cautela nell‚Äôinterpretazione statistica, indipendentemente dal metodo utilizzato.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>83</span>¬† <span class='chapter-title'>La fragilit√† del *p*-valore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/05_p_values.html#riflessioni-conclusive",
    "href": "chapters/replication_crisis/05_p_values.html#riflessioni-conclusive",
    "title": "\n83¬† La fragilit√† del p-valore\n",
    "section": "\n83.3 Riflessioni Conclusive",
    "text": "83.3 Riflessioni Conclusive\nLa simulazione mostra che, nonostante le medie dei campioni siano generate con una distribuzione simile, i p-valori possono variare drasticamente. Questo effetto √® amplificato dalla scelta di campioni piccoli e di una media vera molto vicina all‚Äôipotesi nulla (zero). Dimostra quanto il p-valore possa essere influenzato da piccole variazioni nei dati e perch√© non sia sempre un indicatore affidabile per valutare l‚Äôefficacia o la presenza di un effetto.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>83</span>¬† <span class='chapter-title'>La fragilit√† del *p*-valore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/05_p_values.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/replication_crisis/05_p_values.html#informazioni-sullambiente-di-sviluppo",
    "title": "\n83¬† La fragilit√† del p-valore\n",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.3.2\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.11.1 psych_2.5.3     \n#&gt;  [9] scales_1.3.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.1   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.3    stringi_1.8.4     lattice_0.22-6    hms_1.1.3        \n#&gt;  [5] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.3    grid_4.4.2       \n#&gt;  [9] timechange_0.3.0  fastmap_1.2.0     rprojroot_2.0.4   jsonlite_1.9.1   \n#&gt; [13] mnormt_2.1.1      cli_3.6.4         rlang_1.1.5       munsell_0.5.1    \n#&gt; [17] withr_3.0.2       tools_4.4.2       parallel_4.4.2    tzdb_0.5.0       \n#&gt; [21] colorspace_2.1-1  pacman_0.5.1      vctrs_0.6.5       R6_2.6.1         \n#&gt; [25] lifecycle_1.0.4   htmlwidgets_1.6.4 pkgconfig_2.0.3   pillar_1.10.1    \n#&gt; [29] gtable_0.3.6      glue_1.8.0        xfun_0.51         tidyselect_1.2.1 \n#&gt; [33] rstudioapi_0.17.1 farver_2.1.2      htmltools_0.5.8.1 nlme_3.1-167     \n#&gt; [37] labeling_0.4.3    rmarkdown_2.29    compiler_4.4.2",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>83</span>¬† <span class='chapter-title'>La fragilit√† del *p*-valore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/05_p_values.html#bibliografia",
    "href": "chapters/replication_crisis/05_p_values.html#bibliografia",
    "title": "\n83¬† La fragilit√† del p-valore\n",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., & Stern, H. (2006). The difference between ¬´significant¬ª and ¬´not significant¬ª is not itself statistically significant. The American Statistician, 60(4), 328‚Äì331.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>83</span>¬† <span class='chapter-title'>La fragilit√† del *p*-valore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html",
    "href": "chapters/replication_crisis/06_changes.html",
    "title": "84¬† Riforma",
    "section": "",
    "text": "84.1 Introduzione\nLa crisi della riproducibilit√† ha stimolato un profondo dibattito sullo stato della ricerca nelle scienze comportamentali, cognitive e sociali. La scoperta che molti studi pubblicati non sono replicabili ha minato la fiducia nella ricerca scientifica, evidenziando carenze metodologiche e strutturali nel sistema accademico. In risposta a questa crisi, sono state avanzate diverse proposte di riforma per migliorare la qualit√† e l‚Äôaffidabilit√† della ricerca scientifica.\nSecondo Korbmacher et al. (2023), sono necessarie riforme strutturali, cambiamenti procedurali e trasformazioni nella comunit√† scientifica.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>84</span>¬† <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#riforme-strutturali",
    "href": "chapters/replication_crisis/06_changes.html#riforme-strutturali",
    "title": "84¬† Riforma",
    "section": "84.2 Riforme Strutturali",
    "text": "84.2 Riforme Strutturali\n\n84.2.1 Integrazione della Riproducibilit√† nei Curriculum Educativi\nUna proposta chiave per affrontare la crisi della riproducibilit√† √® l‚Äôintegrazione delle pratiche di riproducibilit√† nei curriculum delle scienze psicologiche e affini. Attualmente, molti programmi di formazione non enfatizzano sufficientemente l‚Äôimportanza della replicabilit√† e della trasparenza nella ricerca. Includere questi temi nei corsi di metodologia della ricerca pu√≤ sensibilizzare le nuove generazioni di ricercatori sull‚Äôadozione di pratiche pi√π rigorose e trasparenti. Alcuni programmi universitari hanno gi√† iniziato a incorporare repliche di studi famosi nel percorso formativo, offrendo agli studenti l‚Äôopportunit√† di comprendere meglio i limiti e le potenzialit√† del processo scientifico.\n\n\n84.2.2 Incentivi per la Scienza Aperta\nUn altro aspetto cruciale √® la riforma dei sistemi di incentivazione accademica. Tradizionalmente, il sistema accademico ha privilegiato la quantit√† di pubblicazioni e la novit√† dei risultati, piuttosto che la loro qualit√† e replicabilit√†. Per promuovere pratiche di scienza aperta, come la preregistrazione degli studi e la condivisione aperta dei dati, si propone l‚Äôintroduzione di riconoscimenti ufficiali, come badge di ‚Äúopen science‚Äù o crediti accademici per la pubblicazione di rapporti registrati. Questi cambiamenti potrebbero favorire una maggiore adozione di pratiche che promuovono la trasparenza e rafforzano la fiducia nella ricerca scientifica.\nA tal proposito, uno studio di Scheel et al. (2021) ha confrontato i risultati di rapporti registrati pubblicati (N = 71) con un campione casuale di studi ipotetico-deduttivi della letteratura standard (N = 152) in psicologia. Analizzando la prima ipotesi di ciascun articolo, √® emerso che il 96% dei risultati nei rapporti standard erano positivi, contro solo il 44% nei rapporti registrati.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>84</span>¬† <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#cambiamenti-procedurali",
    "href": "chapters/replication_crisis/06_changes.html#cambiamenti-procedurali",
    "title": "84¬† Riforma",
    "section": "84.3 Cambiamenti Procedurali",
    "text": "84.3 Cambiamenti Procedurali\n\n84.3.1 Mercati di Previsione per la Credibilit√† della Ricerca\nI mercati di previsione sono stati proposti come strumento innovativo per valutare la credibilit√† della ricerca. In questi mercati, esperti e non esperti scommettono sulla probabilit√† che i risultati di determinati studi siano replicabili. Questo approccio ha dimostrato un‚Äôelevata accuratezza nella classificazione della replicabilit√† degli studi, offrendo un metodo alternativo e complementare alla replicazione diretta. I mercati di previsione potrebbero essere particolarmente utili in contesti in cui la raccolta dati √® costosa o difficile, fornendo una prima indicazione sulla solidit√† dei risultati di ricerca.\n\n\n84.3.2 Strumenti di Valutazione Statistica\nUn‚Äôaltra proposta riguarda l‚Äôadozione di nuovi strumenti di valutazione statistica per identificare e correggere il bias di pubblicazione e migliorare la potenza degli studi. Strumenti come la curva-p e la curva-z sono stati sviluppati per analizzare la distribuzione dei valori p e identificare eventuali distorsioni nei risultati pubblicati. Inoltre, alcuni studiosi hanno suggerito di abbassare il livello di significativit√† statistica standard da 0,05 a 0,005 per ridurre il tasso di falsi positivi e aumentare la robustezza dei risultati. Queste proposte rappresentano passi importanti verso una maggiore precisione nelle analisi statistiche.\n\n\n84.3.3 Analisi Multiverso\nL‚Äôanalisi multiverso √® un‚Äôaltra proposta innovativa che mira a gestire la molteplicit√† di scelte analitiche possibili in un singolo studio. Questa tecnica prevede l‚Äôesecuzione di molteplici analisi su uno stesso dataset, variando i parametri e le scelte metodologiche, per testare la stabilit√† dei risultati. L‚Äôadozione di questo approccio permette di evidenziare quanto i risultati siano sensibili alle scelte analitiche, contribuendo a una maggiore trasparenza e affidabilit√† nelle conclusioni tratte dagli studi.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>84</span>¬† <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#cambiamenti-nella-comunit√†",
    "href": "chapters/replication_crisis/06_changes.html#cambiamenti-nella-comunit√†",
    "title": "84¬† Riforma",
    "section": "84.4 Cambiamenti nella Comunit√†",
    "text": "84.4 Cambiamenti nella Comunit√†\n\n84.4.1 Big Team Science\nIl concetto di ‚ÄúBig Team Science‚Äù rappresenta un cambiamento significativo nella modalit√† di condurre ricerca. Questo approccio prevede la collaborazione su larga scala tra scienziati di diversi paesi e discipline, con l‚Äôobiettivo di replicare studi, raccogliere grandi campioni e condividere risorse. Questo modello di lavoro collettivo non solo aumenta l‚Äôefficienza della ricerca, ma promuove anche una maggiore diversit√† nei campioni e nei team di ricerca. Tuttavia, esistono anche criticit√†, come la possibilit√† di perpetuare disuguaglianze tra ricercatori di paesi sviluppati e in via di sviluppo, e la difficolt√† nel riconoscere adeguatamente i contributi individuali all‚Äôinterno di grandi consorzi.\n\n\n84.4.2 Collaborazioni Avversariali\nLe collaborazioni avversariali rappresentano un altro approccio interessante per migliorare la qualit√† della ricerca. In queste collaborazioni, ricercatori con visioni teoriche contrastanti lavorano insieme per progettare e condurre studi che testino le loro ipotesi in modo rigoroso. Questo tipo di collaborazione pu√≤ ridurre i bias personali e promuovere un confronto costruttivo, portando a conclusioni pi√π solide e condivise all‚Äôinterno della comunit√† scientifica.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>84</span>¬† <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#crisi-della-generalizzabilit√†",
    "href": "chapters/replication_crisis/06_changes.html#crisi-della-generalizzabilit√†",
    "title": "84¬† Riforma",
    "section": "84.5 Crisi della Generalizzabilit√†",
    "text": "84.5 Crisi della Generalizzabilit√†\nYarkoni (2022) affronta la questione critica della scarsa validit√† delle inferenze quantitative presenti nella letteratura psicologica pubblicata, proponendo tre strategie principali per migliorare la qualit√† della ricerca in psicologia.\n\n84.5.1 Do Something Else\nIl primo suggerimento √® di considerare l‚Äôabbandono della ricerca psicologica quantitativa quando risulta troppo difficile estrarre conclusioni significative e generalizzabili da effetti complessi e variabili. L‚Äôautore critica la tendenza a concludere ogni contributo di ricerca con una nota positiva, indipendentemente dalle evidenze raccolte. In alcuni casi, potrebbe essere pi√π saggio riconoscere i limiti della ricerca e scegliere percorsi di carriera alternativi, specialmente per i ricercatori alle prime armi.\n\n\n84.5.2 Abbracciare l‚ÄôAnalisi Qualitativa\nLa seconda opzione proposta √® continuare a fare ricerca psicologica, ma abbandonando in gran parte i metodi statistici inferenziali a favore di metodi qualitativi. L‚Äôautore sostiene che gran parte della scienza quantitativa in psicologia sia in realt√† un‚Äôanalisi qualitativa mascherata. In molti casi, l‚Äôanalisi qualitativa potrebbe fornire risposte pi√π profonde e significative rispetto a un approccio quantitativo superficiale.\n\n\n84.5.3 Adottare Standard Migliori\nLa terza strategia consiste nel migliorare gli standard della ricerca quantitativa in psicologia per renderla pi√π rigorosa e affidabile. L‚Äôautore propone diverse pratiche, tra cui:\n\nInferenze pi√π conservative: Evitare generalizzazioni ampie basate su dati limitati.\nRicerca descrittiva: Prendere pi√π seriamente la ricerca descrittiva, che si concentra sulla caratterizzazione delle relazioni tra variabili.\nModelli statistici pi√π espansivi: Utilizzare modelli che considerino una pi√π ampia gamma di variabili e fattori.\nProgettare con la variazione in mente: Abbracciare la variabilit√† naturale delle condizioni sperimentali.\nStime della varianza: Porre maggiore enfasi sull‚Äôanalisi delle componenti della varianza.\nPredizioni pi√π rischiose: Formulare predizioni teoriche che comportino un alto grado di rischio.\nUtilit√† predittiva pratica: Concentrarsi sull‚Äôutilit√† pratica delle predizioni piuttosto che su considerazioni puramente teoriche.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>84</span>¬† <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#sviluppare-teorie-formali",
    "href": "chapters/replication_crisis/06_changes.html#sviluppare-teorie-formali",
    "title": "84¬† Riforma",
    "section": "84.6 Sviluppare Teorie Formali",
    "text": "84.6 Sviluppare Teorie Formali\nOltre alle carenze metodologiche o statistiche, √® stato spesso sottolineato che la crisi di replicabilit√† trova le sue radici nella mancanza di un quadro teorico cumulativo. Senza un quadro teorico generale che generi ipotesi in diversi ambiti, i programmi empirici si sviluppano a partire da intuizioni personali e teorie popolari influenzate culturalmente. Fornendo strumenti per formulare previsioni chiare, anche attraverso l‚Äôuso di modelli formali, i quadri teorici stabiliscono aspettative che permettono di determinare se un nuovo risultato conferma le ricerche esistenti, integrandosi con esse, oppure se √® inaspettato e, pertanto, richiede ulteriori verifiche e approfondimenti (Muthukrishna & Henrich, 2019).",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>84</span>¬† <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#riflessioni-conclusive",
    "href": "chapters/replication_crisis/06_changes.html#riflessioni-conclusive",
    "title": "84¬† Riforma",
    "section": "84.7 Riflessioni Conclusive",
    "text": "84.7 Riflessioni Conclusive\nL‚Äôampio utilizzo dei test statistici frequentisti in psicologia risulta spesso fuorviante, poich√© attribuisce un‚Äôapparenza di rigore scientifico a inferenze che, in realt√†, sono principalmente qualitative. Si rende quindi necessaria una profonda riforma delle pratiche di ricerca, volta a promuovere una maggiore trasparenza e precisione, oltre a incoraggiare la disponibilit√† a mettere in discussione e abbandonare approcci metodologici che non superano una rigorosa analisi critica (Yarkoni, 2022).\nLa crisi di replicabilit√† ha spinto verso una serie di riforme con il potenziale di trasformare positivamente la ricerca psicologica. Tra queste iniziative vi sono la promozione della scienza aperta, l‚Äôadozione di standard metodologici pi√π rigorosi e una maggiore attenzione a pratiche di ricerca che privilegiano la qualit√† e la replicabilit√† dei risultati rispetto alla loro quantit√† e novit√†. Sebbene questi cambiamenti possano sembrare meno spettacolari rispetto ai metodi attualmente utilizzati, essi rappresentano un percorso fondamentale per garantire la credibilit√† e la sostenibilit√† a lungo termine della disciplina.\nAffinch√© queste riforme abbiano un impatto duraturo, √® essenziale un cambiamento strutturale a tutti i livelli della comunit√† scientifica:\n\nI ricercatori devono impegnarsi ad adottare pratiche pi√π rigorose e trasparenti, privilegiando la solidit√† metodologica e la replicabilit√† dei loro studi.\nGli enti finanziatori devono incentivare la qualit√† e la replicabilit√† degli studi, piuttosto che premiare esclusivamente la produzione di risultati innovativi o appariscenti.\nLe istituzioni accademiche devono rivedere i criteri di valutazione del merito scientifico, dando maggior peso all‚Äôimpatto a lungo termine delle ricerche e alla loro solidit√† metodologica.\nLe riviste scientifiche devono assicurarsi che i risultati pubblicati siano realmente robusti e generalizzabili, anzich√© limitarsi a privilegiare i risultati nuovi o sorprendenti.\n\nQuesti cambiamenti, sebbene complessi e talvolta impopolari, sono fondamentali per ristabilire la fiducia nel processo scientifico e per garantire che la ricerca psicologica continui a offrire contributi utili e affidabili nella comprensione della mente umana e del comportamento.\nIn conclusione, la sfida posta dalla crisi di replicabilit√† offre un‚Äôopportunit√† unica per ridefinire e rafforzare le fondamenta metodologiche della ricerca psicologica. Abbracciando questi cambiamenti, la psicologia pu√≤ emergere come una disciplina pi√π robusta, trasparente e affidabile, capace di fornire intuizioni utili e durature sul funzionamento della mente e del comportamento umano.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>84</span>¬† <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#bibliografia",
    "href": "chapters/replication_crisis/06_changes.html#bibliografia",
    "title": "84¬† Riforma",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nKorbmacher, M., Azevedo, F., Pennington, C. R., Hartmann, H., Pownall, M., Schmidt, K., Elsherif, M., Breznau, N., Robertson, O., Kalandadze, T., et al. (2023). The replication crisis has led to positive structural, procedural, and community changes. Communications Psychology, 1(1), 3.\n\n\nMuthukrishna, M., & Henrich, J. (2019). A problem in theory. Nature Human Behaviour, 3(3), 221‚Äì229.\n\n\nScheel, A. M., Schijen, M. R., & Lakens, D. (2021). An excess of positive results: Comparing the standard psychology literature with registered reports. Advances in Methods and Practices in Psychological Science, 4(2), 25152459211007467.\n\n\nYarkoni, T. (2022). The generalizability crisis. Behavioral and Brain Sciences, 45, e1.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>84</span>¬† <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/07_piranha.html",
    "href": "chapters/replication_crisis/07_piranha.html",
    "title": "85¬† Il Problema del priming: sfide e paradossi nella psicologia sociale",
    "section": "",
    "text": "85.1 Introduzione\nUn recente articolo di Tosh et al. (2025) affronta una questione centrale per la psicologia e la crisi della replicabilit√†: il cosiddetto ‚Äúproblema del piranha‚Äù. Questo argomento riguarda la convinzione, diffusa in molti studi psicologici, che piccoli interventi (o ‚Äúnudges‚Äù), apparentemente insignificanti, possano generare effetti notevoli sul comportamento. L‚Äôarticolo dimostra formalmente, con il supporto del teorema di Van der Corput (Tao, 2014), che se tali effetti fossero davvero cos√¨ grandi e consistenti, allora sarebbe possibile manipolare il comportamento umano in modi empiricamente irrealistici.\nIn altre parole, la letteratura psicologica spesso riporta effetti di dimensioni tali che richiederebbero assunzioni incompatibili con le evidenze empiriche. Questi risultati suggeriscono che le affermazioni di grandi effetti indipendenti sono pi√π probabilmente attribuibili a problemi metodologici, come bassa potenza statistica o ‚Äúgradi di libert√† del ricercatore‚Äù (Simmons et al., 2011).",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>85</span>¬† <span class='chapter-title'>Il Problema del priming: sfide e paradossi nella psicologia sociale</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/07_piranha.html#il-problema-del-piranha",
    "href": "chapters/replication_crisis/07_piranha.html#il-problema-del-piranha",
    "title": "85¬† Il Problema del priming: sfide e paradossi nella psicologia sociale",
    "section": "85.2 Il problema del piranha",
    "text": "85.2 Il problema del piranha\nTosh et al. (2025) evidenziano che, in un sistema complesso, se molte variabili esplicative hanno un forte impatto su una singola variabile di esito, queste devono inevitabilmente mostrare interazioni o correlazioni rilevanti tra loro.\n\n85.2.1 Punti chiave del problema\n\nEffetti ampi e interazioni: Il ‚Äúproblema del piranha‚Äù sottolinea che √® improbabile che molte variabili esplicative abbiano effetti ampi e indipendenti su una singola variabile di esito all‚Äôinterno di un sistema stabile. Questo principio si basa sulla disuguaglianza di Van der Corput, che dimostra come l‚Äôaumento del numero di variabili con grandi effetti richieda una considerazione delle loro interazioni. Tali interazioni generano una rete complessa di influenze, rendendo difficile isolare l‚Äôimpatto di un singolo fattore. Gli effetti osservati in un dato studio potrebbero non essere generalizzabili, poich√© dipendono dai livelli di altre variabili presenti nello stesso contesto.\nAnalogia con i piranha: L‚Äôanalogia del piranha descrive un sistema sovraffollato di variabili esplicative con grandi effetti, che interagiscono tra loro fino a ridurre la stabilit√† complessiva. Proprio come i piranha in un acquario competono tra loro fino a ridurre il loro numero, un sistema con molte variabili di forte impatto tende a generare interazioni che limitano la prevedibilit√† e la stabilit√† del sistema. In altre parole, gli effetti individuali vengono alterati, ridotti o cancellati attraverso la competizione tra variabili.\n\n\n\n85.2.2 Rilevanza per la crisi di replicabilit√†\nIl problema del piranha offre una prospettiva cruciale per comprendere le cause della crisi di replicabilit√† nella psicologia e nelle scienze sociali. Secondo Tosh et al. (2025), questa crisi non √® attribuibile soltanto a problemi metodologici come la bassa potenza statistica, ma riflette un limite intrinseco dell‚Äôidea stessa che numerosi grandi effetti indipendenti possano coesistere in un sistema complesso.\nI teoremi discussi nell‚Äôarticolo dimostrano che un sistema stabile non pu√≤ contenere numerosi effetti forti e indipendenti senza generare predizioni empiricamente insostenibili. Ci√≤ implica che la ricerca di molteplici ‚Äúgrandi effetti‚Äù rischia di essere basata su assunzioni irrealistiche riguardo alla natura delle interazioni tra variabili.\nIl problema del piranha √® particolarmente rilevante per la psicologia, dove spesso si cercano numerose cause indipendenti per spiegare fenomeni complessi. Tosh et al. (2025) mettono in discussione non tanto i singoli effetti riportati, quanto l‚Äôassunzione di base secondo cui il comportamento umano e le interazioni sociali sarebbero influenzati da un gran numero di effetti indipendenti.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>85</span>¬† <span class='chapter-title'>Il Problema del priming: sfide e paradossi nella psicologia sociale</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/07_piranha.html#il-priming-nella-psicologia-sociale",
    "href": "chapters/replication_crisis/07_piranha.html#il-priming-nella-psicologia-sociale",
    "title": "85¬† Il Problema del priming: sfide e paradossi nella psicologia sociale",
    "section": "85.3 Il priming nella psicologia sociale",
    "text": "85.3 Il priming nella psicologia sociale\nUno degli esempi analizzati da Tosh et al. (2025) riguarda la ricerca sul priming sociale, una linea di indagine ampiamente discussa e criticata nella psicologia sociale (si veda anche Leys, 2024). Gli autori utilizzano uno studio classico per illustrare le loro argomentazioni: un esperimento del 1996 condotto da Bargh et al. (1996), in cui i partecipanti riorganizzavano frasi contenenti parole associate alla vecchiaia (ad esempio, ‚ÄúFlorida‚Äù o ‚Äúsolo‚Äù). I risultati riportavano che questi partecipanti camminavano pi√π lentamente rispetto a un gruppo di controllo, con una riduzione del 13% nella velocit√† di camminata (Bargh et al., 1996).\nL‚Äôidea che una manipolazione cos√¨ semplice possa produrre un effetto tanto marcato √® stata successivamente oggetto di numerose critiche. I tentativi di replicare lo studio non hanno avuto successo, e il lavoro di Bargh et al. (1996) √® ora considerato un esempio emblematico di risultati impossibili da replicare. Questo studio rappresenta solo uno dei molti casi in cui sono stati riportati effetti sorprendentemente grandi per manipolazioni apparentemente insignificanti.\nTosh et al. (2025) sostengono che, se davvero piccoli interventi (nudges) producono effetti cos√¨ rilevanti, emergerebbe inevitabilmente il problema delle interazioni con numerosi altri fattori gi√† noti per influire sul comportamento umano. La letteratura psicologica include infatti studi che attribuiscono grandi effetti a fattori come ormoni, immagini subliminali, notizie di partite di calcio o attacchi di squali, incontri casuali con sconosciuti, stato socioeconomico dei genitori, condizioni meteorologiche, l‚Äôultima cifra dell‚Äôet√†, il genere del nome di un uragano, e molti altri. Secondo gli autori, se tutti questi fattori influenzassero realmente un singolo esito, le loro interazioni diventerebbero incredibilmente complesse e imprevedibili, rendendo impossibile individuare effetti stabili e replicabili.\nPer illustrare l‚Äôassurdit√† di alcuni di questi risultati, Tosh et al. (2025) propongono un esempio ipotetico. Supponiamo che 100 nudges producano ciascuno un effetto del 13% sulla velocit√† di camminata, come riportato da Bargh et al. (1996). Se questi effetti fossero indipendenti, l‚Äôeffetto combinato sarebbe enorme: la velocit√† di camminata potrebbe facilmente raddoppiare, dimezzarsi o variare ancora di pi√π. Tuttavia, tali variazioni sono empiricamente irrealistiche. In altre parole, le assunzioni su cui si basano molte di queste ricerche porterebbero a predizioni che non trovano riscontro nei dati osservabili.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>85</span>¬† <span class='chapter-title'>Il Problema del priming: sfide e paradossi nella psicologia sociale</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/07_piranha.html#riflessioni-conclusive",
    "href": "chapters/replication_crisis/07_piranha.html#riflessioni-conclusive",
    "title": "85¬† Il Problema del priming: sfide e paradossi nella psicologia sociale",
    "section": "85.4 Riflessioni Conclusive",
    "text": "85.4 Riflessioni Conclusive\nIl ‚Äúproblema del piranha‚Äù evidenzia i limiti intrinseci nell‚Äôassumere che numerosi effetti indipendenti e di grande entit√† possano coesistere all‚Äôinterno di un sistema complesso. In realt√†, tali effetti devono necessariamente interagire tra loro o essere correlati, rendendo improbabile la loro indipendenza. Questa dinamica crea instabilit√† nel sistema e porta a variazioni degli effetti nel tempo o tra popolazioni, compromettendo la possibilit√† di generalizzarne i risultati.\nTosh et al. (2025) suggeriscono che molti risultati pubblicati, che riportano effetti improbabilmente grandi, siano attribuibili non tanto a reali fenomeni psicologici, quanto a problemi metodologici, come bassa potenza statistica e i ‚Äúgradi di libert√† del ricercatore‚Äù (Simmons et al., 2011). La proliferazione di questi risultati contribuisce alla crisi di replicabilit√†, poich√© i presunti effetti si rivelano spesso instabili o non replicabili.\nLa consapevolezza dei limiti imposti dal problema del piranha invita la ricerca psicologica a focalizzarsi maggiormente sulla robustezza metodologica, sull‚Äôidentificazione di effetti plausibili e sulla considerazione delle interazioni tra variabili. Piuttosto che cercare di identificare molteplici grandi effetti, √® essenziale riconoscere che un sistema complesso, per essere stabile e prevedibile, richiede un approccio che consideri l‚Äôinterdipendenza delle variabili e la struttura complessiva del sistema. Questo approccio pu√≤ contribuire a migliorare la validit√† e la replicabilit√† della ricerca nelle scienze sociali.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>85</span>¬† <span class='chapter-title'>Il Problema del priming: sfide e paradossi nella psicologia sociale</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/07_piranha.html#bibliografia",
    "href": "chapters/replication_crisis/07_piranha.html#bibliografia",
    "title": "85¬† Il Problema del priming: sfide e paradossi nella psicologia sociale",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBargh, J. A., Chen, M., & Burrows, L. (1996). Automaticity of social behavior: Direct effects of trait construct and stereotype activation on action. Journal of Personality and Social Psychology, 71(2), 230‚Äì244.\n\n\nLeys, R. (2024). Anatomy of a Train Wreck: The Rise and Fall of Priming Research. University of Chicago Press.\n\n\nSimmons, J. P., Nelson, L. D., & Simonsohn, U. (2011). False-positive psychology: Undisclosed flexibility in data collection and analysis allows presenting anything as significant. Psychological science, 22(11), 1359‚Äì1366.\n\n\nTosh, C., Greengard, P., Goodrich, B., Gelman, A., Vehtari, A., & Hsu, D. (2025). The Piranha Problem: Large Effects Swimming in a Small Pond. Notices of the American Mathematical Society.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>85</span>¬† <span class='chapter-title'>Il Problema del priming: sfide e paradossi nella psicologia sociale</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/08_degrees_of_freedom.html",
    "href": "chapters/replication_crisis/08_degrees_of_freedom.html",
    "title": "86¬† I gradi di libert√† del ricercatore",
    "section": "",
    "text": "86.1 Introduzione\nLo studio di Gould et al. (2025), ripreso dalla rivista Science (O‚ÄôGrady, 2025), mostra come le scelte analitiche dei ricercatori possano generare una variabilit√† significativa nei risultati, persino quando si utilizzano gli stessi dati e si affronta la medesima domanda di ricerca in ecologia e biologia evolutiva. Questa discrepanza supera di gran lunga l‚Äôerrore statistico atteso, rivelando un problema sistemico che trascende i confini disciplinari.\nI risultati concordano con quelli di precedenti progetti ‚Äúmany analysts‚Äù ‚Äì tra cui il pionieristico lavoro in psicologia di Silberzahn et al. (2018) ‚Äì e sottolineano, come evidenziato dallo psicologo Eric Uhlmann, ‚Äúil ruolo cruciale delle decisioni soggettive nella pratica scientifica‚Äù. Ci√≤ conferma che la fragilit√† metodologica non √® un‚Äôesclusiva della psicologia, ma riguarda settori come le neuroscienze, le scienze sociali e, appunto, l‚Äôecologia.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>86</span>¬† <span class='chapter-title'>I gradi di libert√† del ricercatore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/08_degrees_of_freedom.html#metodologia",
    "href": "chapters/replication_crisis/08_degrees_of_freedom.html#metodologia",
    "title": "86¬† I gradi di libert√† del ricercatore",
    "section": "86.2 Metodologia",
    "text": "86.2 Metodologia\nGould et al. (2025) hanno coinvolto 174 team di ricerca (246 analisti) nell‚Äôanalisi indipendente di due dataset inediti:\n\nEcologia evolutiva: relazione tra numero di fratelli e crescita dei pulcini di cinciallegra (Cyanistes caeruleus).\nEcologia della conservazione: impatto della copertura erbosa sul reclutamento di piantine di Eucalyptus.\n\nOgni team ha risposto a una domanda specifica:\n\nDataset cinciallegra: ‚ÄúQuanto la competizione tra fratelli influenza la crescita dei pulcini?‚Äù\nDataset eucalipto: ‚ÄúIn che modo la copertura erbosa condiziona il reclutamento di piantine?‚Äù\n\nI ricercatori hanno fornito risultati, giustificazioni metodologiche, codice analitico e hanno sottoposto le procedure a peer review incrociata, creando un sistema di controllo reciproco.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>86</span>¬† <span class='chapter-title'>I gradi di libert√† del ricercatore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/08_degrees_of_freedom.html#risultati",
    "href": "chapters/replication_crisis/08_degrees_of_freedom.html#risultati",
    "title": "86¬† I gradi di libert√† del ricercatore",
    "section": "86.3 Risultati",
    "text": "86.3 Risultati\nLo studio ha evidenziato eterogeneit√† estrema nelle conclusioni, nonostante l‚Äôuniformit√† dei dati di partenza:\n\nCinciallegra: L‚Äôeffetto medio negativo (pi√π fratelli = minore crescita) nascondeva un‚Äôampia dispersione, con stime da -0.8 a +0.2 (Figura 1a).\nEucalipto: La relazione media era debolmente negativa e non significativa, ma con outlier che invertivano la tendenza (Figura 1b).\n\n\n\n\n\n\n\nFigura¬†86.1: Distribuzione degli effetti standardizzati nei due dataset: crescita dei pulcini (sinistra) e reclutamento di piantine (destra) (adattata da Gould et al., 2025).\n\n\n\nSorprendentemente, n√© la selezione di variabili, n√© l‚Äôuso di effetti casuali, n√© il giudizio dei revisori correlavano con la distanza dalla media meta-analitica. In altre parole, risultati divergenti non erano associati a scelte metodologicamente ‚Äúpeggiori‚Äù, ma a combinazioni altrettanto valide di decisioni analitiche.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>86</span>¬† <span class='chapter-title'>I gradi di libert√† del ricercatore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/08_degrees_of_freedom.html#il-problema-dei-gradi-di-libert√†-del-ricercatore",
    "href": "chapters/replication_crisis/08_degrees_of_freedom.html#il-problema-dei-gradi-di-libert√†-del-ricercatore",
    "title": "86¬† I gradi di libert√† del ricercatore",
    "section": "86.4 Il Problema dei Gradi di Libert√† del Ricercatore",
    "text": "86.4 Il Problema dei Gradi di Libert√† del Ricercatore\nIl lavoro illustra chiaramente come i ‚Äúgradi di libert√† analitici‚Äù ‚Äì le molteplici opzioni durante l‚Äôanalisi dati ‚Äì possano generare conclusioni divergenti. Tra le decisioni critiche:\n\nGestione di outlier e dati mancanti.\nDefinizione operativa delle variabili.\nScelta di modelli statistici e controlli.\n\nQueste scelte, spesso soggettive ma teoricamente giustificabili, definiscono un ‚Äúspazio analitico‚Äù con migliaia di percorsi possibili. Ogni studio pubblicato rappresenta dunque una singola traiettoria in questo labirinto metodologico, rischiando di offrire una visione parziale e potenzialmente distorta.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>86</span>¬† <span class='chapter-title'>I gradi di libert√† del ricercatore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/08_degrees_of_freedom.html#implicazioni-e-strategie-di-mitigazione",
    "href": "chapters/replication_crisis/08_degrees_of_freedom.html#implicazioni-e-strategie-di-mitigazione",
    "title": "86¬† I gradi di libert√† del ricercatore",
    "section": "86.5 Implicazioni e Strategie di Mitigazione",
    "text": "86.5 Implicazioni e Strategie di Mitigazione\nLa variabilit√† sistematica impone una revisione delle pratiche di ricerca:\n\nAnalisi di sensibilit√† avanzate:\n\nAnalisi multiverso: testare tutte le combinazioni plausibili di scelte metodologiche.\nCurve di specificazione: mappare come i risultati variano al mutare delle assunzioni.\n\nModelli aggregati: Combinare stime da approcci diversi (es., Bayesian Model Averaging) per ridurre la dipendenza da singole specifiche.\n\nTrasparenza procedurale:\n\nPreregistrazione: fissare ipotesi e metodi prima di accedere ai dati.\nPubblicazione di codice e dati grezzi.\n\nFormazione metodologica: Rafforzare le competenze statistiche, con enfasi sulla gestione della complessit√† analitica.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>86</span>¬† <span class='chapter-title'>I gradi di libert√† del ricercatore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/08_degrees_of_freedom.html#riflessioni-conclusive",
    "href": "chapters/replication_crisis/08_degrees_of_freedom.html#riflessioni-conclusive",
    "title": "86¬† I gradi di libert√† del ricercatore",
    "section": "86.6 Riflessioni Conclusive",
    "text": "86.6 Riflessioni Conclusive\nQuesto studio dimostra empiricamente che l‚Äôaffidabilit√† della scienza dipende non solo dai dati, ma da come li analizziamo. La variabilit√† indotta dai gradi di libert√† del ricercatore mina la riproducibilit√†, soprattutto in contesti con elevata discrezionalit√† analitica. La soluzione non √® l‚Äôuniformit√† metodologica, ma una cultura della trasparenza e della pluralit√† analitica, dove ogni risultato sia esplicitamente contestualizzato nel suo spazio di scelte possibili. Solo cos√¨ ecologia, psicologia e discipline affini potranno produrre conoscenze solide e autocritiche.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>86</span>¬† <span class='chapter-title'>I gradi di libert√† del ricercatore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/08_degrees_of_freedom.html#bibliografia",
    "href": "chapters/replication_crisis/08_degrees_of_freedom.html#bibliografia",
    "title": "86¬† I gradi di libert√† del ricercatore",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGould, E., Fraser, H. S., Parker, T. H., Nakagawa, S., Griffith, S. C., Vesk, P. A., Fidler, F., Hamilton, D. G., Abbey-Lee, R. N., Abbott, J. K., et al. (2025). Same data, different analysts: variation in effect sizes due to analytical decisions in ecology and evolutionary biology. BMC biology, 23(1), 35.\n\n\nO‚ÄôGrady, C. (2025). Given the same data, ecologists arrive at different conclusions. Science, 387(6738), 1026.\n\n\nSilberzahn, R., Uhlmann, E. L., Martin, D. P., Anselmi, P., Aust, F., Awtrey, E., Bahnƒ±ÃÅk, ≈†., Bai, F., Bannard, C., Bonnier, E., et al. (2018). Many analysts, one data set: Making transparent how variations in analytic choices affect results. Advances in Methods and Practices in Psychological Science, 1(3), 337‚Äì356.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>86</span>¬† <span class='chapter-title'>I gradi di libert√† del ricercatore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/09_integrity.html",
    "href": "chapters/replication_crisis/09_integrity.html",
    "title": "87¬† Integrit√† della ricerca",
    "section": "",
    "text": "87.1 Introduzione\nL‚Äôintegrit√† della ricerca si fonda su principi e standard professionali volti a garantire l‚Äôaffidabilit√† e la qualit√† degli studi scientifici. Essa si distingue dall‚Äôetica della ricerca, che invece si concentra sui principi morali. Elementi chiave per l‚Äôintegrit√† includono la condivisione dei dati, il consenso informato e la trasparenza nelle pratiche di ricerca. I codici di condotta svolgono un ruolo cruciale nel guidare i comportamenti etici sia dei ricercatori che delle istituzioni. Tra le principali sfide da affrontare vi sono le pratiche di ricerca discutibili, la fabbricazione e falsificazione dei dati, il plagio e la gestione dei conflitti di interesse. Promuovere una cultura della ricerca basata su onest√†, trasparenza e rispetto dei principi etici √® essenziale per preservare l‚Äôintegrit√† scientifica.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>87</span>¬† <span class='chapter-title'>Integrit√† della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/09_integrity.html#standard-professionali-nei-codici-di-condotta-per-lintegrit√†-della-ricerca",
    "href": "chapters/replication_crisis/09_integrity.html#standard-professionali-nei-codici-di-condotta-per-lintegrit√†-della-ricerca",
    "title": "87¬† Integrit√† della ricerca",
    "section": "87.2 Standard Professionali nei Codici di Condotta per l‚ÄôIntegrit√† della Ricerca",
    "text": "87.2 Standard Professionali nei Codici di Condotta per l‚ÄôIntegrit√† della Ricerca\nNel contesto della ricerca, aderire a principi di condotta responsabile √® fondamentale. Questi principi, spesso definiti come buone pratiche di ricerca, stabiliscono standard professionali che mirano a ottimizzare la qualit√† e l‚Äôaffidabilit√† degli studi. Sebbene i concetti di base su cosa costituisca una buona pratica di ricerca rimangano stabili nel tempo, la loro applicazione pratica si evolve in risposta a cambiamenti sociali, politici e tecnologici. Un esempio significativo di questa evoluzione √® l‚Äôenfasi crescente sulla condivisione dei dati di ricerca, resa possibile dall‚Äôuso di repository online gratuiti. Ci√≤ ha portato a un‚Äôaspettativa diffusa di trasparenza e accessibilit√† dei dati. Allo stesso modo, la condivisione del codice utilizzato per analizzare i dati √® diventata una pratica sempre pi√π incoraggiata.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>87</span>¬† <span class='chapter-title'>Integrit√† della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/09_integrity.html#differenziazione-tra-integrit√†-ed-etica-della-ricerca",
    "href": "chapters/replication_crisis/09_integrity.html#differenziazione-tra-integrit√†-ed-etica-della-ricerca",
    "title": "87¬† Integrit√† della ricerca",
    "section": "87.3 Differenziazione tra Integrit√† ed Etica della Ricerca",
    "text": "87.3 Differenziazione tra Integrit√† ed Etica della Ricerca\nL‚Äôintegrit√† della ricerca si basa su standard professionali, mentre l‚Äôetica della ricerca si fonda su principi morali come l‚Äôautonomia, la beneficenza, la non-maleficenza e la giustizia. Questi principi etici si traducono in pratiche specifiche, quali il consenso informato e la garanzia di verit√† e riservatezza nei confronti dei partecipanti. I ricercatori hanno l‚Äôobbligo di evitare studi che possano causare danni o risultare eccessivamente onerosi per i soggetti coinvolti.\nI codici di condotta per l‚Äôintegrit√† della ricerca presentano alcune variazioni tra le diverse fonti. Ad esempio, il Codice di condotta europeo per l‚Äôintegrit√† della ricerca sottolinea l‚Äôimportanza di principi come onest√†, trasparenza, accuratezza, responsabilit√†, affidabilit√†, rispetto e indipendenza. Questi principi si traducono in comportamenti specifici attesi sia dai ricercatori che dalle istituzioni, come la condivisione dei dati nel rispetto delle normative sulla protezione dei dati, tra cui il GDPR europeo.\nUn esempio pratico di come gli standard si siano evoluti √® rappresentato dalla condivisione dei dati di ricerca. In passato, questa pratica era limitata dalla mancanza di infrastrutture adeguate. Oggi, grazie ai repository online e alla pressione esercitata da riviste scientifiche e finanziatori, la condivisione dei dati √® diventata una pratica standard, riflettendo un cambiamento verso una maggiore apertura e trasparenza.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>87</span>¬† <span class='chapter-title'>Integrit√† della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/09_integrity.html#pressioni-e-sfide-nelladesione-ai-codici-di-condotta",
    "href": "chapters/replication_crisis/09_integrity.html#pressioni-e-sfide-nelladesione-ai-codici-di-condotta",
    "title": "87¬† Integrit√† della ricerca",
    "section": "87.4 Pressioni e Sfide nell‚ÄôAdesione ai Codici di Condotta",
    "text": "87.4 Pressioni e Sfide nell‚ÄôAdesione ai Codici di Condotta\nNonostante l‚Äôesistenza di codici di condotta, i ricercatori, specialmente quelli all‚Äôinizio della carriera, possono subire pressioni da parte dei supervisori per adottare comportamenti che deviano dagli standard stabiliti. Questo √® spesso dovuto alla competitivit√† nel campo scientifico e al sistema di valutazione basato sul numero di pubblicazioni. Tali dinamiche possono portare a pratiche di ricerca discutibili (PRD), come la pubblicazione selettiva dei risultati o l‚Äôuso di analisi dei dati flessibili per ottenere risultati statisticamente significativi.\nPer preservare l‚Äôintegrit√† della ricerca, √® essenziale creare un ambiente di lavoro che promuova apertura, inclusivit√† e discussione franca delle pressioni e delle sfide etiche. Ci√≤ richiede non solo l‚Äôadesione ai codici di condotta esistenti, ma anche un impegno attivo delle istituzioni nel promuovere la formazione etica e l‚Äôintegrit√† tra i ricercatori. Solo attraverso un approccio di questo tipo la comunit√† scientifica pu√≤ aspirare a una ricerca di alta qualit√†, sia eticamente responsabile che metodologicamente solida.\nUn esempio emblematico delle tensioni nel mondo accademico √® il gioco da tavolo Publish or Perish, recentemente promosso dalla prestigiosa rivista Nature. La descrizione del gioco √® provocatoria:\n\n‚ÄúFalsificare dati, screditare altri scienziati, pubblicare una montagna di articoli che ricevono una torre di citazioni: i cinici potrebbero descrivere questi come passi necessari per raggiungere il successo accademico.‚Äù\n\nQuesta iniziativa solleva interrogativi sullo stato attuale della ricerca scientifica. Il mondo accademico sembra offrire incentivi distorti, mentre il sistema economico delle riviste scientifiche presenta una componente di monetizzazione che spesso entra in conflitto con gli obiettivi fondamentali della ricerca. Questo contesto favorisce l‚Äôaccettazione di pratiche disoneste, funzionali al mantenimento dello status quo.\nIn questo scenario complesso, emergono voci di dissenso che auspicano una riforma del sistema scientifico (McElreath, 2020; Smaldino & McElreath, 2016). √à necessaria una riflessione profonda su come bilanciare la produttivit√† accademica con l‚Äôetica e la qualit√† della ricerca, nonch√© sul ruolo delle riviste scientifiche nel plasmare il panorama della ricerca contemporanea.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>87</span>¬† <span class='chapter-title'>Integrit√† della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/09_integrity.html#bibliografia",
    "href": "chapters/replication_crisis/09_integrity.html#bibliografia",
    "title": "87¬† Integrit√† della ricerca",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nSmaldino, P. E., & McElreath, R. (2016). The natural selection of bad science. Royal Society open science, 3(9), 160384.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>87</span>¬† <span class='chapter-title'>Integrit√† della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/epiloque/epiloque.html",
    "href": "chapters/epiloque/epiloque.html",
    "title": "Considerazioni Conclusive",
    "section": "",
    "text": "Limiti dell‚ÄôInferenza Frequentista\nL‚Äôinferenza bayesiana rappresenta un approccio rigoroso e trasparente per integrare conoscenze pregresse e dati empirici nell‚Äôanalisi psicologica. A differenza dei metodi frequentisti, l‚Äôapproccio bayesiano consente di quantificare l‚Äôincertezza e di costruire modelli che riflettono le nostre aspettative iniziali. Questa flessibilit√† √® particolarmente preziosa in psicologia, dove teorie e ipotesi svolgono un ruolo centrale nel guidare la ricerca. L‚Äôinferenza bayesiana rende esplicite le nostre assunzioni a priori e ci permette di valutare come i dati influenzano la nostra comprensione dei fenomeni psicologici.\nIn questo corso, abbiamo esaminato i limiti dell‚Äôinferenza frequentista, specialmente quando utilizzata come ‚Äúfiltro‚Äù per distinguere risultati scientifici rilevanti da quelli trascurabili. L‚Äôeccessiva dipendenza dai valori-p √® stata ampiamente criticata per la sua associazione con inferenze inadeguate. Gli effetti possono essere sovrastimati, talvolta anche nella direzione sbagliata, quando la stima √® vincolata alla significativit√† statistica in presenza di dati altamente variabili (Loken & Gelman, 2017).\nNonostante le critiche di lunga data e i dibattiti sul loro uso improprio (Gardner e Altman, 1986; Cohen, 1994; Anderson et al., 2000; Fidler et al., 2004; Finch et al., 2004), i valori-p persistono come indicatore di significativit√†. Questa tenacia riflette forse la necessit√† dei ricercatori di avere strumenti intuitivi, sebbene semplificati, per interpretare i dati. Tuttavia, l‚Äôuso rigido di soglie arbitrarie (ad esempio, 0.05, 0.01, 0.001) ha trasformato il raggiungimento della significativit√† in un obiettivo fine a se stesso, piuttosto che in uno strumento per comprendere i fenomeni sottostanti (Cohen, 1994; Kirk, 1996). Inoltre, i valori-p possono solo rifiutare l‚Äôipotesi nulla, ma non confermarla, poich√© un risultato non significativo non implica l‚Äôassenza di effetti o differenze (Wagenmakers, 2007; Amrhein et al., 2019).\nL‚Äôuso improprio dei valori-p, noto come ‚Äúp-hacking‚Äù (Simmons et al., 2011), ha favorito pratiche scientifiche discutibili, contribuendo alla crisi di riproducibilit√† nella psicologia (Chambers et al., 2014; Szucs e Ioannidis, 2016).",
    "crumbs": [
      "Epilogo",
      "Considerazioni Conclusive"
    ]
  },
  {
    "objectID": "chapters/epiloque/epiloque.html#la-crisi-della-replicabilit√†",
    "href": "chapters/epiloque/epiloque.html#la-crisi-della-replicabilit√†",
    "title": "Considerazioni Conclusive",
    "section": "La Crisi della Replicabilit√†",
    "text": "La Crisi della Replicabilit√†\nLa crisi della replicabilit√† rappresenta una delle principali sfide che affliggono la ricerca scientifica contemporanea, con effetti particolarmente rilevanti nel campo della psicologia. Quando i risultati di uno studio non possono essere riprodotti in condizioni simili, si mette in discussione non solo la validit√† delle teorie su cui si basano interventi clinici e politiche pubbliche, ma anche la fiducia generale nella scienza. Questo problema va oltre l‚Äôambito accademico, influenzando direttamente l‚Äôefficacia delle applicazioni pratiche delle ricerche.\n\nLe Cause Sottostanti\nUno dei fattori principali della crisi √® legato all‚Äôuso di metodologie di ricerca e analisi dei dati insufficientemente rigorose, che spesso portano a falsi positivi. Sebbene siano stati fatti appelli per migliorare le pratiche scientifiche, tali problemi persistono, indicando che il fenomeno non √® semplicemente frutto di errori o mancanza di comprensione. Secondo Smaldino e McElreath (2016), la causa radicale risiede nei sistemi di incentivi distorti che favoriscono la quantit√† piuttosto che la qualit√† della ricerca. In questo contesto, la pressione a pubblicare risultati significativi diventa prioritaria rispetto alla rigorosit√† metodologica, alimentando un circolo vizioso in cui la ‚Äúscienza scadente‚Äù si perpetua.\nPratiche comuni, come il p-hacking (manipolazione statistica per ottenere risultati significativi) o la selezione selettiva dei dati, vengono adottate inconsciamente o intenzionalmente per massimizzare le probabilit√† di pubblicazione. Questo meccanismo, descritto come una forma di ‚Äúselezione naturale della scienza scadente‚Äù, premia approcci che facilitano la produzione di risultati spettacolari, ma non necessariamente veritieri.\n\n\nVerso una Soluzione: Cambiare la Cultura Scientifica\nPer superare questa crisi, √® fondamentale operare un cambiamento culturale all‚Äôinterno della comunit√† scientifica. Non basta correggere gli errori metodologici; occorre modificare radicalmente gli incentivi per premiare la qualit√†, la trasparenza e la replicabilit√† della ricerca. Alcune strategie chiave includono:\n\nPromozione di Pratiche Rigorose:\n\nAdottare protocolli trasparenti, preregistrare gli studi prima del loro avvio e condividere apertamente dati e materiali.\nImplementare procedure di peer review pi√π severe e incoraggiare la revisione post-pubblicazione.\n\nValorizzazione della Replicazione:\n\nDare maggiore riconoscimento agli studi che replicano risultati precedenti, anzich√© privilegiare esclusivamente nuove scoperte.\nCreare riviste specializzate che si concentriano sulla verifica e sulla riproducibilit√† degli studi.\n\nRiforma dei Criteri di Valutazione:\n\nSpostare l‚Äôattenzione dalla quantit√† delle pubblicazioni alla loro qualit√† e impatto scientifico.\nIncorporare metriche alternative, come l‚Äôimpatto sociale e la contribuzione alla conoscenza consolidata.\n\n\n\n\nNuovi Approcci Metodologici\nAlcune proposte innovative mirano a migliorare la qualit√† delle analisi statistiche e ridurre la propensione a falsi positivi. Un esempio √® l‚Äôadozione dell‚Äôinferenza bayesiana, che offre vantaggi significativi rispetto ai metodi tradizionali:\n\nMaggiore flessibilit√† nell‚Äôanalisi di dati rumorosi o campioni piccoli.\nMinore propensione agli errori di tipo I.\nPossibilit√† di incorporare conoscenze pregresse nel processo decisionale.\n\nTuttavia, l‚Äôinferenza bayesiana da sola non pu√≤ risolvere completamente il problema. √à necessario affrontare anche le cause strutturali, come il sistema accademico che premia la produttivit√† quantitativa piuttosto che la qualit√†.\nUn‚Äôaltra prospettiva promettente √® quella avanzata da Richard McElreath, che suggerisce di passare da un approccio descrittivo a uno che descrive formalmente i meccanismi generativi dei dati. Questo significa formulare ipotesi esplicite sui processi sottostanti e testarle attraverso confronti quantitativi tra modelli. Tecniche come la validazione incrociata bayesiana Leave-One-Out (LOO) permettono di valutare la robustezza dei modelli e la loro capacit√† di generalizzare a nuovi contesti.\nInoltre, la ‚Äúrivoluzione causale‚Äù cerca di identificare relazioni causali in contesti naturali, superando i limiti degli esperimenti controllati tradizionali. Questo approccio richiede ai ricercatori di formulare ipotesi causali esplicite e confrontare modelli alternativi, migliorando cos√¨ la comprensione dei fenomeni studiati.\n\n\nImplicazioni Sociali e Educative\nLa crisi della replicabilit√† ha implicazioni concrete al di l√† del mondo accademico. Interventi clinici, politiche pubbliche e decisioni basate su ricerche non replicabili rischiano di essere inefficaci o dannose. Pertanto, garantire la replicabilit√† e l‚Äôaffidabilit√† delle scoperte scientifiche √® essenziale non solo per preservare l‚Äôintegrit√† accademica, ma anche per assumersi responsabilit√† sociali.\nUna revisione dei metodi didattici e dei programmi accademici √® altrettanto cruciale. Gli studenti devono essere formati per comprendere e applicare inferenze basate su dati empirici. Studiosi come Mine Dogucu hanno sottolineato l‚Äôimportanza di integrare approcci bayesiani e causalit√† nei corsi di formazione, e la presente dispensa si inserisce in questo sforzo (Dogucu & √áetinkaya-Rundel, 2021; Dogucu & Hu, 2022; Johnson et al., 2022; Rosenberg et al., 2022).",
    "crumbs": [
      "Epilogo",
      "Considerazioni Conclusive"
    ]
  },
  {
    "objectID": "chapters/epiloque/epiloque.html#conclusioni",
    "href": "chapters/epiloque/epiloque.html#conclusioni",
    "title": "Considerazioni Conclusive",
    "section": "Conclusioni",
    "text": "Conclusioni\nAffrontare e superare la crisi della replicabilit√† rappresenta una sfida fondamentale per la comunit√† scientifica, richiedendo un impegno collettivo per riformare profondamente la cultura della ricerca. Modificare gli incentivi che favoriscono quantit√† piuttosto che qualit√†, promuovere pratiche metodologiche rigorose e valorizzare la replicazione sono passi essenziali per costruire una scienza pi√π affidabile. Solo attraverso un approccio multidimensionale sar√† possibile ripristinare la fiducia nella psicologia scientifica e garantire che le sue applicazioni pratiche siano fondate su basi solide e verificabili.\nIn questo contesto, l‚Äôinferenza bayesiana emerge come uno strumento di grande valore per l‚Äôanalisi dei dati psicologici. Offrendo metodi avanzati per gestire l‚Äôincertezza, integrare conoscenze pregresse e adattarsi a modelli complessi, essa si dimostra particolarmente utile per esplorare i fenomeni legati alla mente umana e al comportamento. La sua capacit√† di fornire previsioni robuste e di aggiornare le ipotesi in base a nuovi dati la rende un approccio ideale per affrontare le sfide poste dalla natura intrinsecamente dinamica del campo psicologico.\nTuttavia, √® importante sottolineare che l‚Äôadozione di metodi bayesiani non costituisce da sola una soluzione completa alla crisi della replicabilit√†. Per migliorare realmente la qualit√† della ricerca, √® necessario integrare queste tecniche con pratiche metodologiche rigorose. Tra queste, spiccano la formalizzazione di modelli generativi, che consentono di descrivere esplicitamente i processi sottostanti ai dati osservati, e il confronto tra modelli alternativi, fondamentale per valutare l‚Äôadeguatezza delle teorie proposte. Inoltre, l‚Äôadozione di una prospettiva causale esplicita √® cruciale per identificare correttamente le relazioni di causa-effetto, superando i limiti degli studi correlazionali o degli esperimenti tradizionali.\nIn conclusione, solo un approccio integrato, che combini l‚Äôinferenza bayesiana con pratiche metodologiche avanzate e una riflessione critica sui sistemi di incentivi accademici, permetter√† di progredire verso una scienza psicologica pi√π affidabile e riproducibile. Questo sforzo collettivo non solo migliorer√† la qualit√† delle ricerche, ma contribuir√† anche a fornire una comprensione pi√π profonda e accurata del comportamento umano, consolidando cos√¨ la posizione della psicologia come disciplina scientifica solida e credibile.",
    "crumbs": [
      "Epilogo",
      "Considerazioni Conclusive"
    ]
  },
  {
    "objectID": "chapters/epiloque/epiloque.html#bibliografia",
    "href": "chapters/epiloque/epiloque.html#bibliografia",
    "title": "Considerazioni Conclusive",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nDogucu, M., & √áetinkaya-Rundel, M. (2021). Web scraping in the statistics and data science curriculum: Challenges and opportunities. Journal of Statistics and Data Science Education, 29(sup1), S112‚ÄìS122.\n\n\nDogucu, M., & Hu, J. (2022). The current state of undergraduate Bayesian education and recommendations for the future. The American Statistician, 76(4), 405‚Äì413.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nLoken, E., & Gelman, A. (2017). Measurement Error and the Replication Crisis. Science, 355(6325), 584‚Äì585.\n\n\nRosenberg, J. M., Kubsch, M., Wagenmakers, E.-J., & Dogucu, M. (2022). Making sense of uncertainty in the science classroom: A Bayesian approach. Science & Education, 31(5), 1239‚Äì1262.",
    "crumbs": [
      "Epilogo",
      "Considerazioni Conclusive"
    ]
  },
  {
    "objectID": "chapters/appendix/a01_shell.html",
    "href": "chapters/appendix/a01_shell.html",
    "title": "Appendice A ‚Äî La Shell",
    "section": "",
    "text": "A.1 Che cos‚Äô√® una Shell?\nUna shell √® un programma che riceve comandi dall‚Äôutente tramite tastiera (o da file) e li passa al sistema operativo per l‚Äôesecuzione. Pu√≤ essere accessibile tramite un terminale (o un emulatore di terminale).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>A</span>¬† <span class='chapter-title'>La Shell</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01_shell.html#che-cos√®-una-shell",
    "href": "chapters/appendix/a01_shell.html#che-cos√®-una-shell",
    "title": "Appendice A ‚Äî La Shell",
    "section": "",
    "text": "A.1.1 Breve Storia della Shell\n\n1971: Ken Thompson di Bell Labs sviluppa la shell per UNIX.\n1977: Stephen Bourne introduce la Bourne shell (sh).\nDopo il 1977: Viene sviluppata la C shell (csh) e tcsh.\nBash: Sviluppata da Brian Fox come sostituto migliorato della Bourne shell.\n1990: Paul Falsted sviluppa Zsh, che diventa la shell predefinita per macOS dal 2019.\n\n\n\nA.1.2 Windows vs macOS/Linux\n\nWindows 10: √à possibile utilizzare Bash attivando il Windows Subsystem for Linux. Tuttavia, l‚Äôambiente preferito √® solitamente PowerShell.\nmacOS/Linux: Zsh √® la shell predefinita in entrambi i sistemi. √à consigliabile sfruttare l‚Äôapplicazione warp per un‚Äôesperienza utente moderna e ottimizzata.\n\n\n\nA.1.3 Comandi di Base Unix\n\npwd: Mostra il percorso della directory corrente.\nls: Elenca file e cartelle nella directory corrente.\ncd: Cambia directory. Senza argomenti, ti porta alla directory home.\nmkdir: Crea una nuova directory.\nrmdir: Rimuove una directory vuota.\nImportante: Evitare spazi nei nomi di file e cartelle.\n\n\nA.1.3.1 Gestione File\n\nmv: Rinomina o sposta file (usa \\ o '' per i nomi di file con spazi).\ncp: Copia file o cartelle (usa -r per le cartelle).\nrm: Rimuove file o cartelle (usa -i per confermare prima di eliminare).\n\n\n\nA.1.3.2 Visualizzazione e Manipolazione Contenuti dei File\n\nless / more: Visualizza il contenuto dei file con possibilit√† di navigazione.\ncat: Mostra l‚Äôintero contenuto di un file.\nhead: Mostra le prime righe di un file.\ntail: Mostra le ultime righe di un file.\n\n\n\n\nA.1.4 Comandi di Base PowerShell\nPer adattare i comandi Unix per l‚Äôutilizzo in PowerShell di Windows, molti dei comandi rimangono simili grazie alla natura cross-platform di PowerShell e alla sua flessibilit√† nel gestire sia gli stili di comando Unix che quelli tradizionali di Windows. Ecco come si traducono i comandi:\n\nGet-Location o semplicemente pwd: Mostra il percorso della directory corrente, simile a pwd in Unix.\nGet-ChildItem o semplicemente ls: Elenca file e cartelle nella directory corrente, equivalente a ls in Unix.\nSet-Location o semplicemente cd: Cambia directory. cd senza argomenti ti porta alla directory home in PowerShell con cd ~.\nNew-Item -ItemType Directory -Name 'nomeDirectory': Crea una nuova directory, simile a mkdir in Unix.\nRemove-Item -Path 'nomeDirectory' -Force: Rimuove una directory, anche se non vuota. Equivalente a rmdir in Unix, ma pi√π potente perch√© pu√≤ rimuovere anche directory con contenuti utilizzando il parametro -Force.\n\n\nA.1.4.1 Gestione File\n\nMove-Item -Path 'origine' -Destination 'destinazione': Rinomina o sposta file, equivalente a mv in Unix.\nCopy-Item -Path 'origine' -Destination 'destinazione': Copia file o cartelle, simile a cp in Unix. Usa -Recurse per copiare cartelle.\nRemove-Item -Path 'file' -Force: Rimuove file o cartelle, simile a rm in Unix. Usa -Force per rimuovere senza conferme e -Recurse per rimuovere cartelle con contenuti.\n\n\n\nA.1.4.2 Visualizzazione e Manipolazione Contenuti dei File\n\nGet-Content 'file' | More: Visualizza il contenuto dei file con possibilit√† di navigazione, simile a less/more in Unix.\nGet-Content 'file': Mostra l‚Äôintero contenuto di un file, equivalente a cat in Unix.\nGet-Content 'file' -Head &lt;numero&gt;: Mostra le prime righe di un file, simile a head in Unix.\nGet-Content 'file' -Tail &lt;numero&gt;: Mostra le ultime righe di un file, equivalente a tail in Unix.\n\n\n\n\n\n\n\n√à cruciale familiarizzarsi con l‚Äôutilizzo dei percorsi relativi per semplificare gli spostamenti tra le diverse directory. L‚Äôimpiego dei percorsi relativi rende il processo di navigazione pi√π intuitivo e meno incline agli errori.\n\nNomi Chiari e Concisi: Evitate di includere spazi nei nomi dei file e delle cartelle. Preferite l‚Äôutilizzo di trattini bassi (_) per separare le parole e mantenere una struttura leggibile e facilmente comprensibile.\nEvitare Caratteri Speciali: √à importante evitare l‚Äôinserimento di caratteri speciali come asterischi (*), dollari ($), slash (/, \\), punti (.), virgole (,), punti e virgole (;), parentesi (()), parentesi quadre ([]), parentesi graffe ({}), ampersand (&), barre verticali (|), punti esclamativi (!), punti interrogativi (?) nei nomi dei file e delle cartelle. Talvolta, anche l‚Äôuso del trattino (-) pu√≤ causare problemi; quindi √® consigliabile evitarlo. Questi caratteri possono generare problemi di compatibilit√† con alcuni sistemi operativi o applicazioni, rendendo pi√π complessa la gestione dei file.\nDifferenziazione tra Maiuscole e Minuscole: Unix distingue tra maiuscole e minuscole (tratta le lettere come oggetti distinti), mentre Windows non lo fa. Per evitare confusioni, √® consigliabile adottare una politica conservativa: considerate i nomi che differiscono solo per la case delle lettere come distinti.\n\nSeguendo questi consigli, √® possibile ottimizzare notevolmente l‚Äôorganizzazione e la gestione dei propri file, migliorando l‚Äôefficienza del lavoro e riducendo il rischio di errori.\n\n\n\nCon la pratica, la riga di comando diventa uno strumento molto efficiente. Questa breve guida fornisce le basi per iniziare a esplorare e gestire i file dal terminale, offrendo una base di partenza per ulteriori apprendimenti (es., Robbins, 2016). La familiarit√† con la shell √® fondamentale nella data science.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>A</span>¬† <span class='chapter-title'>La Shell</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01_shell.html#bibliografia",
    "href": "chapters/appendix/a01_shell.html#bibliografia",
    "title": "Appendice A ‚Äî La Shell",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nRobbins, A. (2016). Bash Pocket Reference: Help for Power Users and Sys Admins. O‚ÄôReilly Media, Inc.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>A</span>¬† <span class='chapter-title'>La Shell</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01a_files.html",
    "href": "chapters/appendix/a01a_files.html",
    "title": "Appendice B ‚Äî Cartelle e documenti",
    "section": "",
    "text": "B.1 Introduzione\nI file su un computer sono organizzati tramite una struttura gerarchica chiamata struttura ad albero, costituita da cartelle (o directory) e file. Questa organizzazione permette una gestione ordinata e intuitiva delle informazioni.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>B</span>¬† <span class='chapter-title'>Cartelle e documenti</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01a_files.html#introduzione",
    "href": "chapters/appendix/a01a_files.html#introduzione",
    "title": "Appendice B ‚Äî Cartelle e documenti",
    "section": "",
    "text": "Radice (Root): √à il punto pi√π alto dell‚Äôalbero da cui partono tutte le ramificazioni.\nCartelle/Directory: Contenitori che possono includere file o altre cartelle.\nFile: Gli elementi finali che contengono dati.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>B</span>¬† <span class='chapter-title'>Cartelle e documenti</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01a_files.html#unixlinuxmacos",
    "href": "chapters/appendix/a01a_files.html#unixlinuxmacos",
    "title": "Appendice B ‚Äî Cartelle e documenti",
    "section": "B.2 Unix/Linux/macOS",
    "text": "B.2 Unix/Linux/macOS\nNei sistemi Unix, l‚Äôalbero ha una struttura chiara che inizia sempre dalla radice indicata con lo slash /.\nEsempio semplificato:\n/\n‚îú‚îÄ‚îÄ bin             # programmi di sistema essenziali\n‚îú‚îÄ‚îÄ etc             # file di configurazione\n‚îú‚îÄ‚îÄ home            # cartelle personali degli utenti\n‚îÇ   ‚îî‚îÄ‚îÄ utente\n‚îÇ       ‚îú‚îÄ‚îÄ Documenti\n‚îÇ       ‚îú‚îÄ‚îÄ Immagini\n‚îÇ       ‚îî‚îÄ‚îÄ Scaricati\n‚îú‚îÄ‚îÄ usr             # applicazioni e librerie utente\n‚îú‚îÄ‚îÄ var             # dati variabili come log e cache\n‚îî‚îÄ‚îÄ tmp             # file temporanei\nNei sistemi Unix i percorsi dei file si scrivono utilizzando lo slash (/), ad esempio:\n/home/utente/Documenti/tesi.docx",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>B</span>¬† <span class='chapter-title'>Cartelle e documenti</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01a_files.html#windows",
    "href": "chapters/appendix/a01a_files.html#windows",
    "title": "Appendice B ‚Äî Cartelle e documenti",
    "section": "B.3 Windows",
    "text": "B.3 Windows\nWindows organizza i file in maniera simile ma partendo da una o pi√π unit√† (dischi), tipicamente indicate da lettere come C:, D:, ecc. La radice di ogni albero corrisponde quindi all‚Äôunit√† disco.\nEsempio semplificato:\nC:\\\n‚îú‚îÄ‚îÄ Program Files   # applicazioni installate\n‚îú‚îÄ‚îÄ Windows         # sistema operativo e file di sistema\n‚îú‚îÄ‚îÄ Utenti          # dati degli utenti\n‚îÇ   ‚îî‚îÄ‚îÄ utente\n‚îÇ       ‚îú‚îÄ‚îÄ Documenti\n‚îÇ       ‚îú‚îÄ‚îÄ Immagini\n‚îÇ       ‚îî‚îÄ‚îÄ Download\n‚îî‚îÄ‚îÄ Temp            # file temporanei\nNei sistemi Windows i percorsi dei file si scrivono utilizzando il backslash (\\), ad esempio:\nC:\\Utenti\\utente\\Documenti\\tesi.docx",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>B</span>¬† <span class='chapter-title'>Cartelle e documenti</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01a_files.html#principali-comandi",
    "href": "chapters/appendix/a01a_files.html#principali-comandi",
    "title": "Appendice B ‚Äî Cartelle e documenti",
    "section": "B.4 Principali Comandi",
    "text": "B.4 Principali Comandi\nQui sotto viene presentata una panoramica sintetica dei principali comandi per gestire la struttura ad albero di file e cartelle nei sistemi Unix (Linux e macOS) e Windows.\n\nB.4.1 Unix/Linux/macOS (Terminale Bash o zsh)\n\n\n\n\n\n\n\n\nComando\nFunzione\nEsempio\n\n\n\n\npwd\nMostra la cartella corrente (Print Working Directory)\npwd ‚Üí /home/utente/Documenti\n\n\ncd\nCambia la cartella corrente (Change Directory)\ncd /home/utente/Scaricati\n\n\nls\nElenca il contenuto di una cartella (List)\nls o ls -l\n\n\nmkdir\nCrea una nuova cartella (Make Directory)\nmkdir nuova_cartella\n\n\nmv\nSposta o rinomina file/cartelle (Move)\nmv file.txt Documenti/ oppure mv vecchio.txt nuovo.txt\n\n\ncp\nCopia file/cartelle (Copy)\ncp file.txt copia_file.txt\n\n\nrm\nRimuove file (Remove)\nrm file.txt\n\n\nrmdir\nRimuove una cartella vuota (Remove Directory)\nrmdir cartella_vuota\n\n\nwhoami\nMostra l‚Äôutente corrente\nwhoami ‚Üí utente\n\n\n\nEsempio di uso dei comandi:\npwd\ncd /home/utente\nmkdir nuovo\ncd nuovo\ntouch prova.txt\nls\nmv prova.txt ../Documenti\ncd ../Documenti\ncp prova.txt copia_prova.txt\nrm prova.txt\nwhoami\n\n\nB.4.2 Windows (Prompt dei comandi, CMD)\n\n\n\n\n\n\n\n\nComando\nFunzione\nEsempio\n\n\n\n\ncd\nCambia la cartella corrente (Change Directory)\ncd C:\\Utenti\\utente\\Documenti\n\n\ncd\nMostra la cartella corrente\ncd ‚Üí C:\\Utenti\\utente\\Documenti\n\n\ndir\nElenca il contenuto della cartella\ndir\n\n\nmkdir\nCrea una nuova cartella\nmkdir nuova_cartella\n\n\nmove\nSposta o rinomina file/cartelle\nmove file.txt Documenti\\ o move vecchio.txt nuovo.txt\n\n\ncopy\nCopia file\ncopy file.txt copia_file.txt\n\n\ndel\nRimuove file\ndel file.txt\n\n\nrmdir\nRimuove cartella vuota\nrmdir cartella_vuota\n\n\nwhoami\nMostra l‚Äôutente corrente\nwhoami ‚Üí utente\n\n\n\nEsempio di uso dei comandi:\ncd C:\\Utenti\\utente\nmkdir nuovo\ncd nuovo\necho prova &gt; prova.txt\ndir\nmove prova.txt ..\\Documenti\ncd ..\\Documenti\ncopy prova.txt copia_prova.txt\ndel prova.txt\nwhoami\nNota finale.\nEntrambi i sistemi operativi consentono operazioni simili, ma hanno sintassi e convenzioni leggermente diverse. Questi comandi di base permettono una gestione essenziale e rapida della struttura ad albero.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>B</span>¬† <span class='chapter-title'>Cartelle e documenti</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01a_files.html#conclusioni",
    "href": "chapters/appendix/a01a_files.html#conclusioni",
    "title": "Appendice B ‚Äî Cartelle e documenti",
    "section": "Conclusioni",
    "text": "Conclusioni\nIn sintesi, entrambi i sistemi operativi utilizzano una struttura ad albero per facilitare la gestione, la navigazione e l‚Äôorganizzazione dei file e delle cartelle. Cambiano principalmente la notazione (/ o \\) e la gestione della radice (una singola radice / in Unix, pi√π radici contrassegnate da lettere come C: in Windows).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>B</span>¬† <span class='chapter-title'>Cartelle e documenti</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a02_math_symbols.html",
    "href": "chapters/appendix/a02_math_symbols.html",
    "title": "Appendice C ‚Äî Simbologia di base",
    "section": "",
    "text": "Per una scrittura pi√π sintetica possono essere utilizzati alcuni simboli matematici.\n\n\\(\\log(x)\\): il logaritmo naturale di \\(x\\).\nL‚Äôoperatore logico booleano \\(\\land\\) significa ‚Äúe‚Äù (congiunzione forte) mentre il connettivo di disgiunzione \\(\\lor\\) significa ‚Äúo‚Äù (oppure) (congiunzione debole).\nIl quantificatore esistenziale \\(\\exists\\) vuol dire ‚Äúesiste almeno un‚Äù e indica l‚Äôesistenza di almeno una istanza del concetto/oggetto indicato. Il quantificatore esistenziale di unicit√† \\(\\exists!\\) (‚Äúesiste soltanto un‚Äù) indica l‚Äôesistenza di esattamente una istanza del concetto/oggetto indicato. Il quantificatore esistenziale \\(\\nexists\\) nega l‚Äôesistenza del concetto/oggetto indicato.\nIl quantificatore universale \\(\\forall\\) vuol dire ‚Äúper ogni.‚Äù\n\\(\\mathcal{A, S}\\): insiemi.\n\\(x \\in A\\): \\(x\\) √® un elemento dell‚Äôinsieme \\(A\\).\nL‚Äôimplicazione logica ‚Äú\\(\\Rightarrow\\)‚Äù significa ‚Äúimplica‚Äù (se ‚Ä¶allora). \\(P \\Rightarrow Q\\) vuol dire che \\(P\\) √® condizione sufficiente per la verit√† di \\(Q\\) e che \\(Q\\) √® condizione necessaria per la verit√† di \\(P\\).\nL‚Äôequivalenza matematica ‚Äú\\(\\iff\\)‚Äù significa ‚Äúse e solo se‚Äù e indica una condizione necessaria e sufficiente, o corrispondenza biunivoca.\nIl simbolo \\(\\vert\\) si legge ‚Äútale che.‚Äù\nIl simbolo \\(\\triangleq\\) (o \\(:=\\)) si legge ‚Äúuguale per definizione.‚Äù\nIl simbolo \\(\\Delta\\) indica la differenza fra due valori della variabile scritta a destra del simbolo.\nIl simbolo \\(\\propto\\) si legge ‚Äúproporzionale a.‚Äù\nIl simbolo \\(\\approx\\) si legge ‚Äúcirca.‚Äù\nIl simbolo \\(\\in\\) della teoria degli insiemi vuol dire ‚Äúappartiene‚Äù e indica l‚Äôappartenenza di un elemento ad un insieme. Il simbolo \\(\\notin\\) vuol dire ‚Äúnon appartiene.‚Äù\nIl simbolo \\(\\subseteq\\) si legge ‚Äú√® un sottoinsieme di‚Äù (pu√≤ coincidere con l‚Äôinsieme stesso). Il simbolo \\(\\subset\\) si legge ‚Äú√® un sottoinsieme proprio di.‚Äù\nIl simbolo \\(\\#\\) indica la cardinalit√† di un insieme.\nIl simbolo \\(\\cap\\) indica l‚Äôintersezione di due insiemi. Il simbolo \\(\\cup\\) indica l‚Äôunione di due insiemi.\nIl simbolo \\(\\emptyset\\) indica l‚Äôinsieme vuoto o evento impossibile.\nIn matematica, \\(\\mbox{argmax}\\) identifica l‚Äôinsieme dei punti per i quali una data funzione raggiunge il suo massimo. In altre parole, \\(\\mbox{argmax}_x f(x)\\) √® l‚Äôinsieme dei valori di \\(x\\) per i quali \\(f(x)\\) raggiunge il valore pi√π alto.\n\\(a, c, \\alpha, \\gamma\\): scalari.\n\\(\\boldsymbol{x}, \\boldsymbol{y}\\): vettori.\n\\(\\boldsymbol{X}, \\boldsymbol{Y}\\): matrici.\n\\(X \\sim p\\): la variabile casuale \\(X\\) si distribuisce come \\(p\\).\n\\(p(\\cdot)\\): distribuzione di massa o di densit√† di probabilit√†.\n\\(p(y \\mid \\boldsymbol{x})\\): la probabilit√† o densit√† di \\(y\\) dato \\(\\boldsymbol{x}\\), ovvero \\(p(y = \\boldsymbol{Y} \\mid x = \\boldsymbol{X})\\).\n\\(f(x)\\): una funzione arbitraria di \\(x\\).\n\\(f(\\boldsymbol{X}; \\theta, \\gamma)\\): \\(f\\) √® una funzione di \\(\\boldsymbol{X}\\) con parametri \\(\\theta, \\gamma\\). Questa notazione indica che \\(\\boldsymbol{X}\\) sono i dati che vengono passati ad un modello di parametri \\(\\theta, \\gamma\\).\n\\(\\mathcal{N}(\\mu, \\sigma^2)\\): distribuzione gaussiana di media \\(\\mu\\) e varianza \\(sigma^2\\).\n\\(\\mbox{Beta}(\\alpha, \\beta)\\): distribuzione Beta di parametri \\(\\alpha\\) e \\(\\beta\\).\n\\(\\mathcal{U}(a, b)\\): distribuzione uniforme con limite inferiore \\(a\\) e limite superiore \\(b\\).\n\\(\\mbox{Cauchy}(\\alpha, \\beta)\\): distribuzione di Cauchy di parametri \\(\\alpha\\) (posizione: media) e \\(\\beta\\) (scala: radice quadrata della varianza).\n\\(\\mathcal{B}(p)\\): distribuzione di Bernoulli di parametro \\(p\\) (probabilit√† di successo).\n\\(\\mbox{Bin}(n, p)\\): distribuzione binomiale di parametri \\(n\\) (numero di prove) e \\(p\\) (probabilit√† di successo).\n\\(\\mathbb{KL} (p \\mid\\mid q)\\): la divergenza di Kullback-Leibler da \\(p\\) a \\(q\\).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>C</span>¬† <span class='chapter-title'>Simbologia di base</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a03_latex.html",
    "href": "chapters/appendix/a03_latex.html",
    "title": "Appendice D ‚Äî Equazioni Matematiche in LaTeX",
    "section": "",
    "text": "D.1 LaTeX\nLaTeX √® un potente strumento di composizione tipografica, ampiamente utilizzato per la produzione di documenti scientifici e tecnici. Una delle sue caratteristiche pi√π apprezzate √® la capacit√† di gestire equazioni matematiche in modo elegante e preciso. In questo articolo, esploreremo come scrivere equazioni matematiche in LaTeX, coprendo i modi matematici, le operazioni di base, l‚Äôallineamento delle equazioni e molto altro.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>D</span>¬† <span class='chapter-title'>Equazioni Matematiche in LaTeX</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a03_latex.html#modelli-matematici-in-latex",
    "href": "chapters/appendix/a03_latex.html#modelli-matematici-in-latex",
    "title": "Appendice D ‚Äî Equazioni Matematiche in LaTeX",
    "section": "D.2 Modelli Matematici in LaTeX",
    "text": "D.2 Modelli Matematici in LaTeX\nPer scrivere equazioni matematiche in LaTeX, esistono due modalit√† principali: la modalit√† inline e la modalit√† display.\n\nModalit√† Inline: Utilizzata per inserire equazioni all‚Äôinterno del testo. Le espressioni matematiche sono racchiuse tra simboli di dollaro ($), ad esempio $E=mc^2$ produce \\(E=mc^2\\).\nModalit√† Display: Utilizzata per equazioni che devono essere evidenziate e centrate su una nuova linea. Le espressioni possono essere racchiuse tra $$ e $$, o all‚Äôinterno di ambienti come \\begin{equation} e \\end{equation}.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>D</span>¬† <span class='chapter-title'>Equazioni Matematiche in LaTeX</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a03_latex.html#scrivere-costrutti-matematici-di-base",
    "href": "chapters/appendix/a03_latex.html#scrivere-costrutti-matematici-di-base",
    "title": "Appendice D ‚Äî Equazioni Matematiche in LaTeX",
    "section": "D.3 Scrivere Costrutti Matematici di Base",
    "text": "D.3 Scrivere Costrutti Matematici di Base\n\nD.3.1 Operazioni Aritmetiche\nLe operazioni aritmetiche possono essere scritte direttamente all‚Äôinterno del testo utilizzando il simbolo del dollaro. Ad esempio:\n\nAddizione: $a + b$ produce \\(a + b\\).\nMoltiplicazione: $a \\cdot b$ o $a \\times b$ produce \\(a \\cdot b\\) o \\(a \\times b\\).\nDivisione: $a / b$ o $a \\div b$ produce \\(a / b\\) o \\(a \\div b\\).\n\n\n\nD.3.2 Frazioni e Coefficienti Binomiali\nLe frazioni si scrivono utilizzando il comando \\frac{num}{den}. Ad esempio, $\\frac{a}{b}$ produce \\(\\frac{a}{b}\\).\nPer i coefficienti binomiali, si utilizza il comando \\binom{n}{k}. Ad esempio, $\\binom{n}{k}$ produce \\(\\binom{n}{k}\\).\n\n\nD.3.3 Pedici e Apici\nI pedici si ottengono con _, mentre gli apici con ^. Ad esempio:\n\n$a_{1}$ produce \\(a_{1}\\).\n$a^{2}$ produce \\(a^{2}\\).\n\n\n\nD.3.4 Integrali e Radici\nPer gli integrali, i limiti di integrazione si scrivono come pedici e apici. Ad esempio:\n\n$\\int_{a}^{b} f(x) \\, dx$ produce \\(\\int_{a}^{b} f(x) \\, dx\\).\n\nLe radici si ottengono con il comando \\sqrt{}. Ad esempio, $\\sqrt{a + b}$ produce \\(\\sqrt{a + b}\\).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>D</span>¬† <span class='chapter-title'>Equazioni Matematiche in LaTeX</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a03_latex.html#allineamento-delle-equazioni",
    "href": "chapters/appendix/a03_latex.html#allineamento-delle-equazioni",
    "title": "Appendice D ‚Äî Equazioni Matematiche in LaTeX",
    "section": "D.4 Allineamento delle Equazioni",
    "text": "D.4 Allineamento delle Equazioni\nPer allineare pi√π equazioni, si utilizza l‚Äôambiente align. Ad esempio:\n\\begin{align*}\na + b &= c \\\\\nd + e &= f\n\\end{align*}\nQuesto allinea le equazioni al segno di uguale.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>D</span>¬† <span class='chapter-title'>Equazioni Matematiche in LaTeX</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a03_latex.html#parentesi-e-operatori",
    "href": "chapters/appendix/a03_latex.html#parentesi-e-operatori",
    "title": "Appendice D ‚Äî Equazioni Matematiche in LaTeX",
    "section": "D.5 Parentesi e Operatori",
    "text": "D.5 Parentesi e Operatori\nLe parentesi possono essere ridimensionate utilizzando i comandi \\left( e \\right). Ad esempio:\n$$ \n\\left( \\frac{a}{b} \\right) \n$$\nGli operatori come seno, coseno e logaritmi si scrivono con comandi specifici come \\sin, \\cos, e \\log.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>D</span>¬† <span class='chapter-title'>Equazioni Matematiche in LaTeX</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a03_latex.html#conclusione",
    "href": "chapters/appendix/a03_latex.html#conclusione",
    "title": "Appendice D ‚Äî Equazioni Matematiche in LaTeX",
    "section": "D.6 Conclusione",
    "text": "D.6 Conclusione\nLaTeX offre una vasta gamma di strumenti per la scrittura di equazioni matematiche, rendendolo uno strumento indispensabile per chiunque lavori con documenti scientifici. Con un po‚Äô di pratica, √® possibile padroneggiare queste tecniche e produrre documenti di alta qualit√† con facilit√†.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>D</span>¬† <span class='chapter-title'>Equazioni Matematiche in LaTeX</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html",
    "href": "chapters/appendix/a11_numbers.html",
    "title": "Appendice E ‚Äî Numeri e intervalli",
    "section": "",
    "text": "E.1 Numeri binari\nI numeri binari rappresentano il sistema numerico pi√π elementare utilizzato in informatica, poich√© sono composti unicamente da due simboli: 0 e 1. Questa caratteristica li rende particolarmente adatti alla rappresentazione di situazioni dicotomiche (vero/falso, presente/assente) e consente ai computer di operare rapidamente ed efficacemente sui dati.\nUn esempio semplice d‚Äôimpiego dei valori logici binari si ottiene quando raccogliamo risposte a una domanda chiusa. Immaginiamo, ad esempio, di porre la domanda ‚ÄúTi piacciono i mirtilli?‚Äù a 10 studenti. Se le risposte vengono memorizzate in R come valori logici (TRUE per ‚ÄúS√¨‚Äù e FALSE per ‚ÄúNo‚Äù), potremmo avere:\nopinion &lt;- c(TRUE, FALSE, TRUE, TRUE, TRUE, FALSE, TRUE, TRUE, TRUE, FALSE)\nopinion\n\n [1]  TRUE FALSE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE FALSE\nIn questo caso, TRUE e FALSE corrispondono a 1 e 0 rispettivamente quando utilizzati in operazioni numeriche. Lo stesso avviene in Python, dove True √® interpretato come 1 e False come 0. Questa rappresentazione binaria permette di ottenere facilmente statistiche sintetiche. Per esempio, per calcolare la proporzione di risposte positive rispetto al totale, √® sufficiente sommare i valori (contando cos√¨ il numero di TRUE) e dividere per la lunghezza del vettore:\nsum(opinion) / length(opinion)\n\n[1] 0.7\nQuesto fornisce immediatamente la percentuale di studenti che hanno risposto ‚ÄúS√¨‚Äù alla domanda.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>¬† <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#numeri-interi",
    "href": "chapters/appendix/a11_numbers.html#numeri-interi",
    "title": "Appendice E ‚Äî Numeri e intervalli",
    "section": "\nE.2 Numeri interi",
    "text": "E.2 Numeri interi\nI numeri interi sono caratterizzati dall‚Äôassenza di componenti decimali. Essi includono sia i numeri naturali (1, 2, 3, ‚Ä¶), tradizionalmente utilizzati per il conteggio, sia i loro opposti negativi. L‚Äôinsieme dei numeri naturali √® indicato con \\(\\mathbb{N}\\), mentre l‚Äôinsieme dei numeri interi (che include i numeri naturali, i loro negativi e lo zero) si denota con \\(\\mathbb{Z}\\):\n\\[\n\\mathbb{Z} = \\{0, \\pm 1, \\pm 2, \\pm 3, \\dots\\}\n\\]",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>¬† <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#numeri-razionali",
    "href": "chapters/appendix/a11_numbers.html#numeri-razionali",
    "title": "Appendice E ‚Äî Numeri e intervalli",
    "section": "\nE.3 Numeri razionali",
    "text": "E.3 Numeri razionali\nI numeri razionali sono quei numeri che possono essere espressi come il rapporto tra due numeri interi, con il denominatore diverso da zero. Essi formano l‚Äôinsieme:\n\\[\n\\mathbb{Q} = \\left\\{\\frac{m}{n} \\mid m,n \\in \\mathbb{Z}, n \\neq 0\\right\\}.\n\\]\nPoich√© ogni numero naturale √® anche un intero, e ogni intero pu√≤ essere rappresentato come razionale (ad esempio \\(5 = \\frac{5}{1}\\)), si ha una catena d‚Äôinclusioni tra i diversi insiemi di numeri:\n\\[\n\\mathbb{N} \\subseteq \\mathbb{Z} \\subseteq \\mathbb{Q}.\n\\]\nSe si desidera considerare solo i numeri razionali non negativi, si utilizza la notazione:\n\\[\n\\mathbb{Q}^+ = \\{q \\in \\mathbb{Q} \\mid q \\geq 0\\}.\n\\]",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>¬† <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#numeri-irrazionali",
    "href": "chapters/appendix/a11_numbers.html#numeri-irrazionali",
    "title": "Appendice E ‚Äî Numeri e intervalli",
    "section": "\nE.4 Numeri irrazionali",
    "text": "E.4 Numeri irrazionali\nNon tutti i numeri possono essere espressi come rapporto di due interi. I numeri che non hanno questa propriet√† sono detti irrazionali. Essi non possono essere scritti in forma frazionaria e la loro espansione decimale √® infinita e non periodica. Esempi tipici di numeri irrazionali sono:\n\n\\(\\sqrt{2}\\)\n\\(\\sqrt{3}\\)\n\\(\\pi = 3.141592...\\)",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>¬† <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#numeri-reali",
    "href": "chapters/appendix/a11_numbers.html#numeri-reali",
    "title": "Appendice E ‚Äî Numeri e intervalli",
    "section": "\nE.5 Numeri reali",
    "text": "E.5 Numeri reali\nI numeri razionali non coprono tutti i possibili punti sulla retta reale. Per rappresentare ogni possibile misura, grandezza o punto su una linea continua, si considerano i numeri reali, denotati con \\(\\mathbb{R}\\). L‚Äôinsieme dei numeri reali comprende sia i razionali sia gli irrazionali:\n\\[\n\\mathbb{N} \\subseteq \\mathbb{Z} \\subseteq \\mathbb{Q} \\subseteq \\mathbb{R}.\n\\]\nIn statistica, la precisione con cui si esprime una misura √® spesso legata al numero di cifre decimali utilizzate, sfruttando cos√¨ appieno la ‚Äúcontinuit√†‚Äù offerta dai numeri reali.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>¬† <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#intervalli-numerici",
    "href": "chapters/appendix/a11_numbers.html#intervalli-numerici",
    "title": "Appendice E ‚Äî Numeri e intervalli",
    "section": "\nE.6 Intervalli Numerici",
    "text": "E.6 Intervalli Numerici\nDefinizione: Un intervallo numerico √® un sottoinsieme connesso della retta reale. Intuitivamente, rappresenta tutti i numeri reali compresi tra due estremi, che possono o meno essere inclusi nell‚Äôintervallo stesso.\nClassificazione degli intervalli: Gli intervalli vengono classificati in base all‚Äôinclusione o meno degli estremi:\n\n\nIntervallo chiuso: Include entrambi gli estremi. Si indica con \\([a, b]\\) e rappresenta l‚Äôinsieme dei numeri reali \\(x\\) tali che \\(a \\leq x \\leq b\\).\n\nIntervallo aperto: Non include alcun estremo. Si indica con \\((a, b)\\) e rappresenta l‚Äôinsieme dei numeri reali \\(x\\) tali che \\(a &lt; x &lt; b\\).\n\nIntervalli semiaperti:\n\n\nChiuso a sinistra e aperto a destra: Include l‚Äôestremo sinistro ma non quello destro. Si indica con \\([a, b)\\) e rappresenta l‚Äôinsieme dei numeri reali \\(x\\) tali che \\(a \\leq x &lt; b\\).\n\nAperto a sinistra e chiuso a destra: Include l‚Äôestremo destro ma non quello sinistro. Si indica con \\((a, b]\\) e rappresenta l‚Äôinsieme dei numeri reali \\(x\\) tali che \\(a &lt; x \\leq b\\).\n\n\n\nTabella riassuntiva:\n\n\nIntervallo\nNotazione\nCondizione\n\n\n\nChiuso\n\\([a, b]\\)\n\\(a \\leq x \\leq b\\)\n\n\nAperto\n\\((a, b)\\)\n\\(a &lt; x &lt; b\\)\n\n\nChiuso a sinistra, aperto a destra\n\\([a, b)\\)\n\\(a \\leq x &lt; b\\)\n\n\nAperto a sinistra, chiuso a destra\n\\((a, b]\\)\n\\(a &lt; x \\leq b\\)\n\n\n\nOsservazioni: * La scelta della notazione con parentesi quadre o tonde indica rispettivamente l‚Äôinclusione o l‚Äôesclusione degli estremi.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>¬† <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a12_sum_notation.html",
    "href": "chapters/appendix/a12_sum_notation.html",
    "title": "Appendice F ‚Äî Sommatorie",
    "section": "",
    "text": "F.1 Manipolazione di somme\nLe somme sono uno strumento fondamentale in molti contesti matematici e statistici, e per gestirle in modo efficace √® essenziale disporre di una notazione chiara e precisa. Consideriamo, ad esempio, la somma dei primi \\(n\\) numeri interi, che pu√≤ essere espressa come \\(1 + 2 + \\dots + (n-1) + n\\), dove i puntini di sospensione (\\(\\dots\\)) indicano che la sequenza deve essere completata seguendo il pattern definito dai termini precedenti e successivi. Tuttavia, una notazione come \\(1 + 7 + \\dots + 73.6\\) risulterebbe ambigua senza ulteriori specifiche. In generale, ci troveremo di fronte a somme della forma\n\\[\nx_1 + x_2 + \\dots + x_n,\n\\]\ndove \\(x_n\\) rappresenta un numero definito altrove. Sebbene questa notazione con i puntini di sospensione sia utile in alcuni contesti, pu√≤ risultare poco chiara in altri. Per questo motivo, si preferisce utilizzare la notazione di sommatoria:\n\\[\n\\sum_{i=1}^n x_i,\n\\]\nche si legge ‚Äúsommatoria per \\(i\\) che va da \\(1\\) a \\(n\\) di \\(x_i\\)‚Äù. Il simbolo \\(\\sum\\) (la lettera sigma maiuscola dell‚Äôalfabeto greco) rappresenta l‚Äôoperazione di somma, \\(x_i\\) √® il generico addendo, mentre \\(1\\) e \\(n\\) sono gli estremi della sommatoria, che definiscono l‚Äôintervallo di variazione dell‚Äôindice \\(i\\). Solitamente, l‚Äôestremo inferiore √® \\(1\\), ma potrebbe essere qualsiasi altro numero \\(m &lt; n\\). Pertanto, possiamo scrivere:\n\\[\n\\sum_{i=1}^n x_i = x_1 + x_2 + \\dots + x_n.\n\\]\nAd esempio, se i valori di \\(x\\) sono \\(\\{3, 11, 4, 7\\}\\), avremo:\n\\[\n\\sum_{i=1}^4 x_i = 3 + 11 + 4 + 7 = 25,\n\\]\ndove \\(x_1 = 3\\), \\(x_2 = 11\\), e cos√¨ via. La quantit√† \\(x_i\\) √® detta argomento della sommatoria, mentre la variabile \\(i\\), che assume valori interi successivi, √® chiamata indice della sommatoria.\nLa notazione di sommatoria pu√≤ anche essere espressa nella forma:\n\\[\n\\sum_{P(i)} x_i,\n\\]\ndove \\(P(i)\\) √® una proposizione logica riguardante \\(i\\) che pu√≤ essere vera o falsa. Quando √® evidente che si vogliono sommare tutte le \\(n\\) osservazioni, la notazione pu√≤ essere semplificata in \\(\\sum_{i} x_i\\) o addirittura \\(\\sum x_i\\). L‚Äôindice \\(i\\) pu√≤ essere sostituito da altre lettere, come \\(k, j, l, \\dots\\), a seconda del contesto.\nPer semplificare i calcoli che coinvolgono le sommatorie, √® utile conoscere alcune propriet√† fondamentali.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>F</span>¬† <span class='chapter-title'>Sommatorie</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a12_sum_notation.html#manipolazione-di-somme",
    "href": "chapters/appendix/a12_sum_notation.html#manipolazione-di-somme",
    "title": "Appendice F ‚Äî Sommatorie",
    "section": "",
    "text": "F.1.1 Propriet√† 1 (Somma di una costante)\nLa sommatoria di \\(n\\) valori tutti uguali a una costante \\(a\\) √® pari a \\(n\\) volte la costante stessa:\n\\[\n\\sum_{i=1}^{n} a = \\underbrace{a + a + \\dots + a}_{n \\text{ volte}} = n a.\n\\]\n\n\nF.1.2 Propriet√† 2 (Propriet√† distributiva)\nSe l‚Äôargomento della sommatoria contiene una costante, √® possibile fattorizzarla. Ad esempio:\n\\[\n\\sum_{i=1}^{n} a x_i = a x_1 + a x_2 + \\dots + a x_n = a (x_1 + x_2 + \\dots + x_n) = a \\sum_{i=1}^{n} x_i.\n\\]\n\n\nF.1.3 Propriet√† 3 (Propriet√† associativa)\nSe l‚Äôargomento della sommatoria √® una somma, possiamo separare i termini:\n\\[\n\\sum_{i=1}^{n} (a + x_i) = (a + x_1) + (a + x_2) + \\dots + (a + x_n) = n a + \\sum_{i=1}^{n} x_i.\n\\]\nIn generale, possiamo scrivere:\n\\[\n\\sum_{i=1}^{n} (x_i + y_i) = \\sum_{i=1}^{n} x_i + \\sum_{i=1}^{n} y_i.\n\\]\n\n\nF.1.4 Propriet√† 4 (Operazioni algebriche)\nSe √® necessario eseguire un‚Äôoperazione algebrica (come l‚Äôelevamento a potenza o il logaritmo) sull‚Äôargomento della sommatoria, questa operazione deve essere eseguita prima della somma. Ad esempio:\n\\[\n\\sum_{i=1}^{n} x_i^2 = x_1^2 + x_2^2 + \\dots + x_n^2 \\neq \\left( \\sum_{i=1}^{n} x_i \\right)^2.\n\\]\n\n\nF.1.5 Propriet√† 5 (Prodotto di termini)\nNel caso di un prodotto tra termini, il prodotto deve essere eseguito prima della somma:\n\\[\n\\sum_{i=1}^{n} x_i y_i = x_1 y_1 + x_2 y_2 + \\dots + x_n y_n.\n\\]\nInfatti, \\(a_1 b_1 + a_2 b_2 \\neq (a_1 + a_2)(b_1 + b_2)\\).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>F</span>¬† <span class='chapter-title'>Sommatorie</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a12_sum_notation.html#doppia-sommatoria",
    "href": "chapters/appendix/a12_sum_notation.html#doppia-sommatoria",
    "title": "Appendice F ‚Äî Sommatorie",
    "section": "F.2 Doppia sommatoria",
    "text": "F.2 Doppia sommatoria\nIn alcuni contesti, si incontrano espressioni con una doppia sommatoria e un doppio indice:\n\\[\n\\sum_{i=1}^{n} \\sum_{j=1}^{m} x_{ij}.\n\\]\nQuesta notazione implica che, per ogni valore dell‚Äôindice esterno \\(i\\) (da \\(1\\) a \\(n\\)), si deve sviluppare la sommatoria interna per \\(j\\) (da \\(1\\) a \\(m\\)). Ad esempio:\n\\[\n\\sum_{i=1}^{3} \\sum_{j=4}^{6} x_{ij} = (x_{1,4} + x_{1,5} + x_{1,6}) + (x_{2,4} + x_{2,5} + x_{2,6}) + (x_{3,4} + x_{3,5} + x_{3,6}).\n\\]\nUn caso particolare interessante √® la doppia sommatoria del prodotto di due variabili:\n\\[\n\\sum_{i=1}^{n} \\sum_{j=1}^{n} x_i y_j.\n\\]\nIn questo caso, poich√© \\(x_i\\) non dipende dall‚Äôindice \\(j\\), possiamo estrarre \\(x_i\\) dalla sommatoria interna:\n\\[\n\\sum_{i=1}^{n} \\left( x_i \\sum_{j=1}^{n} y_j \\right).\n\\]\nAllo stesso modo, la sommatoria interna \\(\\sum_{j=1}^{n} y_j\\) non dipende da \\(i\\), quindi pu√≤ essere estratta dalla sommatoria esterna:\n\\[\n\\sum_{i=1}^{n} \\sum_{j=1}^{n} x_i y_j = \\left( \\sum_{i=1}^{n} x_i \\right) \\left( \\sum_{j=1}^{n} y_j \\right).\n\\]\n\nF.2.1 Esempio pratico\nConsideriamo i vettori \\(x = \\{2, 3, 1\\}\\) e \\(y = \\{1, 4, 9\\}\\). Calcoliamo la doppia sommatoria:\n\\[\n\\begin{align}\n\\sum_{i=1}^3 \\sum_{j=1}^3 x_i y_j &= x_1 y_1 + x_1 y_2 + x_1 y_3 + x_2 y_1 + x_2 y_2 + x_2 y_3 + x_3 y_1 + x_3 y_2 + x_3 y_3 \\\\\n&= 2 \\times (1 + 4 + 9) + 3 \\times (1 + 4 + 9) + 1 \\times (1 + 4 + 9) \\\\\n&= 2 \\times 14 + 3 \\times 14 + 1 \\times 14 = 84.\n\\end{align}\n\\]\nD‚Äôaltra parte, il prodotto delle due sommatorie √®:\n\\[\n\\left( \\sum_{i=1}^3 x_i \\right) \\left( \\sum_{j=1}^3 y_j \\right) = (2 + 3 + 1) \\times (1 + 4 + 9) = 6 \\times 14 = 84.\n\\]\nI due risultati coincidono, confermando la validit√† della propriet√†.\nPer ulteriori approfondimenti, si consiglia la consultazione del testo Concrete Mathematics: A Foundation for Computer Science (Graham et al., 1994).\nEsercizi pratici sono disponibili sulla seguente pagina web.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>F</span>¬† <span class='chapter-title'>Sommatorie</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a12_sum_notation.html#bibliografia",
    "href": "chapters/appendix/a12_sum_notation.html#bibliografia",
    "title": "Appendice F ‚Äî Sommatorie",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGraham, R. L., Knuth, D. E., & Patashnik, O. (1994). Concrete Mathematics: A Foundation for Computer Science (2nd ed.). Addison-Wesley.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>F</span>¬† <span class='chapter-title'>Sommatorie</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html",
    "href": "chapters/appendix/a13_sets.html",
    "title": "Appendice G ‚Äî Insiemi",
    "section": "",
    "text": "G.1 Diagrammi di Eulero-Venn\nUn insieme (o collezione, classe, gruppo, ‚Ä¶) √® stato definito da Georg Cantor nel modo seguente:\nMentre non √® rilevante la natura degli oggetti che costituiscono l‚Äôinsieme, ci√≤ che importa √® distinguere se un dato oggetto appartenga o meno ad un insieme. Deve essere vera una delle due possibilit√†: il dato oggetto √® un elemento dell‚Äôinsieme considerato oppure non √® elemento dell‚Äôinsieme considerato. Due insiemi \\(A\\) e \\(B\\) si dicono uguali se sono formati dagli stessi elementi, anche se disposti in ordine diverso: \\(A=B\\). Due insiemi \\(A\\) e \\(B\\) si dicono diversi se non contengono gli stessi elementi: \\(A \\neq B\\). Ad esempio, i seguenti insiemi sono uguali:\n\\[\n\\{1, 2, 3\\} = \\{3, 1, 2\\} = \\{1, 3, 2\\}= \\{1, 1, 1, 2, 3, 3, 3\\}.\n\\]\nGli insiemi sono denotati da una lettera maiuscola, mentre le lettere minuscole, di solito, designano gli elementi di un insieme. Per esempio, un generico insieme \\(A\\) si indica con\n\\[\nA = \\{a_1, a_2, \\dots, a_n\\}, \\quad \\text{con } n &gt; 0.\n\\]\nLa scrittura \\(a \\in A\\) dice che \\(a\\) √® un elemento di \\(A\\). Per dire che \\(b\\) non √® un elemento di \\(A\\) si scrive \\(b \\notin A.\\)\nPer quegli insiemi i cui elementi soddisfano una certa propriet√† che li caratterizza, tale propriet√† pu√≤ essere usata per descrivere pi√π sinteticamente l‚Äôinsieme:\n\\[\nA = \\{x ~\\vert~ \\text{propriet√† posseduta da } x\\},\n\\]\nche si legge come ‚Äú\\(A\\) √® l‚Äôinsieme degli elementi \\(x\\) per cui √® vera la propriet√† indicata.‚Äù Per esempio, per indicare l‚Äôinsieme \\(A\\) delle coppie di numeri reali \\((x,y)\\) che appartengono alla parabola \\(y = x^2 + 1\\) si pu√≤ scrivere:\n\\[\nA = \\{(x,y) ~\\vert~ y = x^2 + 1\\}.\n\\]\nDati due insiemi \\(A\\) e \\(B\\), diremo che \\(A\\) √® un sottoinsieme di \\(B\\) se e solo se tutti gli elementi di \\(A\\) sono anche elementi di \\(B\\):\n\\[\nA \\subseteq B \\iff (\\forall x \\in A \\Rightarrow x \\in B).\n\\]\nSe esiste almeno un elemento di \\(B\\) che non appartiene ad \\(A\\) allora diremo che \\(A\\) √® un sottoinsieme proprio di \\(B\\):\n\\[\nA \\subset B \\iff (A \\subseteq B, \\exists~ x \\in B ~\\vert~ x \\notin A).\n\\]\nUn altro insieme, detto insieme delle parti, o insieme potenza, che si associa all‚Äôinsieme \\(A\\) √® l‚Äôinsieme di tutti i sottoinsiemi di \\(A\\), inclusi l‚Äôinsieme vuoto e \\(A\\) stesso. Per esempio, per l‚Äôinsieme \\(A = \\{a, b, c\\}\\), l‚Äôinsieme delle parti √®:\n\\[\n\\mathcal{P}(A) = \\{\n\\emptyset, \\{a\\}, \\{b\\}, \\{c\\},\n\\{a, b\\}, \\{a, c\\}, \\{c, b\\},\n\\{a, b, c\\}\n\\}.\n\\]\nI diagrammi di Venn sono uno strumento grafico molto utile per rappresentare gli insiemi e per verificare le propriet√† delle operazioni tra di essi. Questi diagrammi prendono il nome dal matematico inglese del 19¬∞ secolo John Venn, anche se rappresentazioni simili erano gi√† state utilizzate in precedenza da Leibniz e Eulero.\nI diagrammi di Venn rappresentano gli insiemi come regioni del piano delimitate da una curva chiusa. Nel caso di insiemi finiti, √® possibile evidenziare alcuni elementi di un insieme tramite punti, e in alcuni casi possono essere evidenziati tutti gli elementi degli insiemi considerati.\nIn sostanza, questi diagrammi sono un modo visuale per rappresentare le propriet√† degli insiemi e delle operazioni tra di essi. Sono uno strumento molto utile per visualizzare la relazione tra gli insiemi e per capire meglio come si combinano gli elementi all‚Äôinterno di essi.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>G</span>¬† <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html#appartenenza-ad-un-insieme",
    "href": "chapters/appendix/a13_sets.html#appartenenza-ad-un-insieme",
    "title": "Appendice G ‚Äî Insiemi",
    "section": "\nG.2 Appartenenza ad un insieme",
    "text": "G.2 Appartenenza ad un insieme\nUsiamo ora R\n\nSet1 &lt;- c(1, 2)\nprint(Set1)\n\n[1] 1 2\n\nprint(class(Set1))\n\n[1] \"numeric\"\n\n\n\nmy_list &lt;- c(1, 2, 3, 4)\nmy_set_from_list &lt;- unique(my_list)\nprint(my_set_from_list)\n\n[1] 1 2 3 4\n\n\nL‚Äôappartenenza ad un insieme si verifica con %in%.\n\nmy_set &lt;- c(1, 3, 5)\nprint(\"Ecco il mio insieme:\")\n\n[1] \"Ecco il mio insieme:\"\n\nprint(my_set)\n\n[1] 1 3 5\n\nprint(\"1 appartiene all'insieme:\")\n\n[1] \"1 appartiene all'insieme:\"\n\nprint(1 %in% my_set)\n\n[1] TRUE\n\nprint(\"2 non appartiene all'insieme:\")\n\n[1] \"2 non appartiene all'insieme:\"\n\nprint(2 %in% my_set)\n\n[1] FALSE\n\nprint(\"4 NON appartiene all'insieme:\")\n\n[1] \"4 NON appartiene all'insieme:\"\n\nprint(!(4 %in% my_set))\n\n[1] TRUE",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>G</span>¬† <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html#relazioni-tra-insiemi",
    "href": "chapters/appendix/a13_sets.html#relazioni-tra-insiemi",
    "title": "Appendice G ‚Äî Insiemi",
    "section": "\nG.3 Relazioni tra insiemi",
    "text": "G.3 Relazioni tra insiemi\nEsaminiamo le funzioni Python per descrivere le relazioni tra insiemi. In particolare, dopo avere definito l‚Äôinsieme universo e l‚Äôinsieme vuoto, considereremo la relazione di inclusione che conduce al concetto di sottoinsieme. Analogamente si definisce il concetto di sovrainsieme. Mostreremo anche come valutare se due insiemi sono disgiunti (si dicono disgiunti gli insiemi con intersezione vuota).\n\nUniv &lt;- 0:10\nSuper &lt;- Univ[Univ %% 2 == 0]\nDisj &lt;- Univ[Univ %% 2 == 1]\nSub &lt;- c(4, 6)\nNull &lt;- Univ[Univ &gt; 10]\n\n\nprint(\"Insieme Universo (tutti gli interi positivi fino a 10):\")\n\n[1] \"Insieme Universo (tutti gli interi positivi fino a 10):\"\n\nprint(Univ)\n\n [1]  0  1  2  3  4  5  6  7  8  9 10\n\nprint(\"Tutti gli interi positivi pari fino a 10:\")\n\n[1] \"Tutti gli interi positivi pari fino a 10:\"\n\nprint(Super)\n\n[1]  0  2  4  6  8 10\n\nprint(\"Tutti gli interi positivi dispari fino a 10:\")\n\n[1] \"Tutti gli interi positivi dispari fino a 10:\"\n\nprint(Disj)\n\n[1] 1 3 5 7 9\n\nprint(\"Insieme di due elementi, 4 e 6:\")\n\n[1] \"Insieme di due elementi, 4 e 6:\"\n\nprint(Sub)\n\n[1] 4 6\n\nprint(\"Un insieme vuoto:\")\n\n[1] \"Un insieme vuoto:\"\n\nprint(Null)\n\ninteger(0)\n\n\n\nprint('√à \"Super\" un sovrainsieme di \"Sub\"?')\n\n[1] \"√à \\\"Super\\\" un sovrainsieme di \\\"Sub\\\"?\"\n\nprint(all(Sub %in% Super))\n\n[1] TRUE\n\nprint('√à \"Super\" un sottoinsieme di \"Univ\"?')\n\n[1] \"√à \\\"Super\\\" un sottoinsieme di \\\"Univ\\\"?\"\n\nprint(all(Super %in% Univ))\n\n[1] TRUE\n\nprint('√à \"Sub\" un sovrainsieme di \"Super\"?')\n\n[1] \"√à \\\"Sub\\\" un sovrainsieme di \\\"Super\\\"?\"\n\nprint(all(Super %in% Sub))\n\n[1] FALSE\n\nprint('Sono \"Super\" e \"Disj\" insiemi disgiunti?')\n\n[1] \"Sono \\\"Super\\\" e \\\"Disj\\\" insiemi disgiunti?\"\n\nprint(length(intersect(Super, Disj)) == 0)\n\n[1] TRUE",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>G</span>¬† <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html#operazioni-tra-insiemi",
    "href": "chapters/appendix/a13_sets.html#operazioni-tra-insiemi",
    "title": "Appendice G ‚Äî Insiemi",
    "section": "\nG.4 Operazioni tra insiemi",
    "text": "G.4 Operazioni tra insiemi\nSi definisce intersezione di \\(A\\) e \\(B\\) l‚Äôinsieme \\(A \\cap B\\) di tutti gli elementi \\(x\\) che appartengono ad \\(A\\) e contemporaneamente a \\(B\\):\n\\[\nA \\cap B = \\{x ~\\vert~ x \\in A \\land x \\in B\\}.\n\\]\nSi definisce unione di \\(A\\) e \\(B\\) l‚Äôinsieme \\(A \\cup B\\) di tutti gli elementi \\(x\\) che appartengono ad \\(A\\) o a \\(B\\), cio√®\n\\[\nA \\cup B = \\{x ~\\vert~ x \\in A \\lor x \\in B\\}.\n\\]\nDifferenza. Si indica con \\(A \\setminus B\\) l‚Äôinsieme degli elementi di \\(A\\) che non appartengono a \\(B\\):\n\\[\nA \\setminus B = \\{x ~\\vert~ x \\in A \\land x \\notin B\\}.\n\\]\nInsieme complementare. Nel caso che sia \\(B \\subseteq A\\), l‚Äôinsieme differenza \\(A \\setminus B\\) √® detto insieme complementare di \\(B\\) in \\(A\\) e si indica con \\(B^C\\).\nDato un insieme \\(S\\), una partizione di \\(S\\) √® una collezione di sottoinsiemi di \\(S\\), \\(S_1, \\dots, S_k\\), tali che\n\\[\nS = S_1 \\cup S_2 \\cup \\dots S_k\n\\]\ne\n\\[\nS_i \\cap S_j, \\quad \\text{con } i \\neq j.\n\\]\nLa relazione tra unione, intersezione e insieme complementare √® data dalle leggi di DeMorgan:\n\\[\n(A \\cup B)^c = A^c \\cap B^c,\n\\]\n\\[\n(A \\cap B)^c = A^c \\cup B^c.\n\\]\nIn tutte le seguenti figure, \\(S\\) √® la regione delimitata dal rettangolo, \\(L\\) √® la regione all‚Äôinterno del cerchio di sinistra e \\(R\\) √® la regione all‚Äôinterno del cerchio di destra. La regione evidenziata mostra l‚Äôinsieme indicato sotto ciascuna figura.\n\n\nDiagrammi di Venn\n\nI diagrammi di Eulero-Venn che illustrano le leggi di DeMorgan sono forniti nella figura seguente.\n\n\nLeggi di DeMorgan\n\nVediamo ora come si eseguono le operazioni tra insiemi con R.\nIntersezione.\n\nS1 &lt;- seq(1, 10, by = 3)\nS2 &lt;- 1:6\nS_intersection &lt;- intersect(S1, S2)\nprint(\"Intersezione di S1 e S2:\")\n\n[1] \"Intersezione di S1 e S2:\"\n\nprint(S_intersection)\n\n[1] 1 4\n\n\nUnione. Si noti che il connettivo logico | corrisponde all‚Äôunione.\n\nS_union &lt;- union(S1, S2)\nprint(\"Unione di S1 e S2:\")\n\n[1] \"Unione di S1 e S2:\"\n\nprint(S_union)\n\n[1]  1  4  7 10  2  3  5  6\n\n\nInsieme complementare.\n\nS &lt;- seq(0, 20, by = 2)\nS_complement &lt;- setdiff(0:20, S)\nprint(\"S √® l'insieme dei numeri interi pari tra 0 e 20:\")\n\n[1] \"S √® l'insieme dei numeri interi pari tra 0 e 20:\"\n\nprint(S)\n\n [1]  0  2  4  6  8 10 12 14 16 18 20\n\nprint(\"S_complement √® l'insieme dei numeri interi dispari tra 0 e 20:\")\n\n[1] \"S_complement √® l'insieme dei numeri interi dispari tra 0 e 20:\"\n\nprint(S_complement)\n\n [1]  1  3  5  7  9 11 13 15 17 19\n\n\n\nprint(\"√à l'unione di S e S_complement uguale a tutti i numeri interi tra 0 e 20?\")\n\n[1] \"√à l'unione di S e S_complement uguale a tutti i numeri interi tra 0 e 20?\"\n\nprint(setequal(union(S, S_complement), 0:20))\n\n[1] TRUE\n\n\nDifferenza tra insiemi.\n\nS1 &lt;- seq(0, 30, by = 3)\nS2 &lt;- seq(0, 30, by = 5)\nprint(\"Differenza tra S2 e S1:\")\n\n[1] \"Differenza tra S2 e S1:\"\n\nprint(setdiff(S2, S1))\n\n[1]  5 10 20 25\n\nprint(\"Differenza tra S1 e S2:\")\n\n[1] \"Differenza tra S1 e S2:\"\n\nprint(setdiff(S1, S2))\n\n[1]  3  6  9 12 18 21 24 27\n\n\nDifferenza simmetrica. La differenza simmetrica, indicata con il simbolo Œî, √® un‚Äôoperazione insiemistica definita come unione tra la differenza tra il primo e il secondo insieme e la differenza tra il secondo e il primo insieme. In modo equivalente, la differenza simmetrica equivale all‚Äôunione tra i due insiemi meno la loro intersezione.\n\nsym_diff &lt;- union(setdiff(S1, S2), setdiff(S2, S1))\nprint(\"Differenza simmetrica:\")\n\n[1] \"Differenza simmetrica:\"\n\nprint(sym_diff)\n\n [1]  3  6  9 12 18 21 24 27  5 10 20 25",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>G</span>¬† <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html#coppie-ordinate-e-prodotto-cartesiano",
    "href": "chapters/appendix/a13_sets.html#coppie-ordinate-e-prodotto-cartesiano",
    "title": "Appendice G ‚Äî Insiemi",
    "section": "\nG.5 Coppie ordinate e prodotto cartesiano",
    "text": "G.5 Coppie ordinate e prodotto cartesiano\nUna coppia ordinata \\((x,y)\\) √® l‚Äôinsieme i cui elementi sono \\(x \\in A\\) e \\(y \\in B\\) e nella quale \\(x\\) √® la prima componente (o prima coordinata) e \\(y\\) la seconda. L‚Äôinsieme di tutte le coppie ordinate costruite a partire dagli insiemi \\(A\\) e \\(B\\) viene detto prodotto cartesiano:\n\\[\nA \\times B = \\{(x, y) ~\\vert~ x \\in A \\land y \\in B\\}.\n\\]\nAd esempio, sia \\(A = \\{1, 2, 3\\}\\) e \\(B = \\{a, b\\}\\). Allora,\n\\[\n\\{1, 2\\} \\times \\{a, b, c\\} = \\{(1, a), (1, b), (1, c), (2, a), (2, b), (2, c)\\}.\n\\]\nPi√π in generale, un prodotto cartesiano di \\(n\\) insiemi pu√≤ essere rappresentato da un array di \\(n\\) dimensioni, dove ogni elemento √® una ennupla o tupla ordinata (ovvero, una collezione o un elenco ordinato di \\(n\\) oggetti). Una n-pla ordinata si distingue da un insieme di \\(n\\) elementi in quanto fra gli elementi di un insieme non √® dato alcun ordine. Inoltre gli elementi di una ennupla possono anche essere ripetuti. Essendo la n-pla un elenco ordinato, in generale di ogni suo elemento √® possibile dire se sia il primo, il secondo, il terzo, eccetera, fino all‚Äôn-esimo. Il prodotto cartesiano prende il nome da Ren√© Descartes la cui formulazione della geometria analitica ha dato origine al concetto.\n\nA &lt;- c(\"a\", \"b\", \"c\")\nS &lt;- 1:3\ncartesian_product &lt;- expand.grid(A, S)\nprint(\"Prodotto cartesiano di A e S:\")\n\n[1] \"Prodotto cartesiano di A e S:\"\n\nprint(cartesian_product)\n\n  Var1 Var2\n1    a    1\n2    b    1\n3    c    1\n4    a    2\n5    b    2\n6    c    2\n7    a    3\n8    b    3\n9    c    3\n\n\nSi definisce cardinalit√† (o potenza) di un insieme finito il numero degli elementi dell‚Äôinsieme. Viene indicata con \\(\\vert A\\vert, \\#(A)\\) o \\(\\text{c}(A)\\).\n\nprint(\"La cardinalit√† dell'insieme prodotto cartesiano √®:\")\n\n[1] \"La cardinalit√† dell'insieme prodotto cartesiano √®:\"\n\nprint(nrow(cartesian_product))\n\n[1] 9\n\n\nPotenza del prodotto cartesiano\n\nA &lt;- c(\"Head\", \"Tail\")\np2 &lt;- expand.grid(A, A)\nprint(\"Il quadrato dell'insieme A √® un insieme che contiene:\")\n\n[1] \"Il quadrato dell'insieme A √® un insieme che contiene:\"\n\nprint(nrow(p2))\n\n[1] 4\n\nprint(p2)\n\n  Var1 Var2\n1 Head Head\n2 Tail Head\n3 Head Tail\n4 Tail Tail\n\n\n\np3 &lt;- expand.grid(A, A, A)\nprint(\"L'insieme A elevato alla terza potenza √® costituito da:\")\n\n[1] \"L'insieme A elevato alla terza potenza √® costituito da:\"\n\nprint(nrow(p3))\n\n[1] 8\n\nprint(p3)\n\n  Var1 Var2 Var3\n1 Head Head Head\n2 Tail Head Head\n3 Head Tail Head\n4 Tail Tail Head\n5 Head Head Tail\n6 Tail Head Tail\n7 Head Tail Tail\n8 Tail Tail Tail",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>G</span>¬† <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html",
    "href": "chapters/appendix/a14_combinatorics.html",
    "title": "Appendice H ‚Äî Calcolo combinatorio",
    "section": "",
    "text": "H.1 Principio della somma\nIl calcolo combinatorio studia il numero di modi in cui √® possibile combinare, ordinare o disporre elementi appartenenti a uno o pi√π insiemi, seguendo regole ben definite. Molti problemi di probabilit√† richiedono strumenti combinatori per determinare la probabilit√† di eventi complessi. In questo capitolo, esploreremo i concetti fondamentali del calcolo combinatorio, illustrandoli attraverso il modello del campionamento dall‚Äôurna. Tratteremo i principi della somma e del prodotto, fondamentali per affrontare problemi pi√π avanzati, come permutazioni, disposizioni e combinazioni.\nIl principio della somma si applica quando un insieme di elementi pu√≤ essere suddiviso in sottoinsiemi disgiunti (ossia senza sovrapposizioni). In questo caso, il numero totale di elementi √® dato dalla somma delle cardinalit√† dei sottoinsiemi:\n\\[\nn_{\\text{tot}} = n_1 + n_2 + \\dots + n_k .\n\\]\nEsempio\nUn distributore contiene tre scomparti di caramelle, ciascuno con un diverso tipo di dolci:\nQuante caramelle ci sono in totale nel distributore?\nSecondo il principio della somma, il numero totale di caramelle √®:\n\\[\nn_{\\text{tot}} = n_A + n_B + n_C = 10 + 8 + 12 = 30.\n\\]\nCalcolo in R:\nA &lt;- 10\nB &lt;- 8\nC &lt;- 12\n\ntotale_caramelle &lt;- A + B + C\ntotale_caramelle\n#&gt; [1] 30\nRisultato: Nel distributore ci sono 30 caramelle in totale.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>H</span>¬† <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#principio-della-somma",
    "href": "chapters/appendix/a14_combinatorics.html#principio-della-somma",
    "title": "Appendice H ‚Äî Calcolo combinatorio",
    "section": "",
    "text": "Scomparto A: 10 caramelle alla menta,\n\n\nScomparto B: 8 caramelle alla frutta,\n\n\nScomparto C: 12 caramelle al cioccolato.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>H</span>¬† <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#principio-del-prodotto",
    "href": "chapters/appendix/a14_combinatorics.html#principio-del-prodotto",
    "title": "Appendice H ‚Äî Calcolo combinatorio",
    "section": "\nH.2 Principio del prodotto",
    "text": "H.2 Principio del prodotto\nIl principio del prodotto si applica quando un‚Äôoperazione pu√≤ essere suddivisa in pi√π fasi indipendenti, ciascuna con un numero specifico di possibilit√†. In tal caso, il numero totale di combinazioni √® dato dal prodotto delle possibilit√† offerte da ciascuna fase:\n\\[\nn_{\\text{tot}} = n_1 \\cdot n_2 \\cdot \\dots \\cdot n_k .\n\\]\nEsempio\nSupponiamo di avere quattro urne contenenti palline di diverso colore:\n\n\nUrna A: 5 palline,\n\n\nUrna B: 6 palline,\n\n\nUrna C: 3 palline,\n\n\nUrna D: 2 palline.\n\nVogliamo formare insiemi di due palline, ciascuna estratta da urne differenti.\nSecondo il principio del prodotto, per ogni coppia di urne, il numero di combinazioni √® dato dal prodotto del numero di palline contenute nelle due urne. Utilizziamo poi il principio della somma per ottenere il totale complessivo:\n\\[\nn_{\\text{tot}} = AB + AC + AD + BC + BD + CD.\n\\]\nCalcolo in R:\n\nAB &lt;- 5 * 6\nAC &lt;- 5 * 3\nAD &lt;- 5 * 2\nBC &lt;- 6 * 3\nBD &lt;- 6 * 2\nCD &lt;- 3 * 2\n\ntotale_insiemi &lt;- AB + AC + AD + BC + BD + CD\ntotale_insiemi\n#&gt; [1] 91\n\nRisultato: √à possibile formare 91 insiemi di due palline, ciascuna estratta da urne differenti.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>H</span>¬† <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#il-modello-dellurna-e-i-metodi-di-campionamento",
    "href": "chapters/appendix/a14_combinatorics.html#il-modello-dellurna-e-i-metodi-di-campionamento",
    "title": "Appendice H ‚Äî Calcolo combinatorio",
    "section": "\nH.3 Il modello dell‚Äôurna e i metodi di campionamento",
    "text": "H.3 Il modello dell‚Äôurna e i metodi di campionamento\nMolti problemi di calcolo combinatorio possono essere interpretati come estrazioni di palline da un‚Äôurna. Esistono quattro modi fondamentali di effettuare un campionamento, a seconda che:\n\nle estrazioni siano con o senza ripetizione,\nl‚Äôordine degli elementi conti o meno.\n\nQueste quattro combinazioni danno origine a quattro principali metodi di campionamento:\n\n\nCon ripetizione e con ordine: Dopo ogni estrazione, la pallina viene rimessa nell‚Äôurna. (Es. formazione di codici numerici con ripetizioni)\n\nSenza ripetizione e con ordine: Ogni estrazione rimuove definitivamente la pallina dall‚Äôurna. (Es. assegnare premi in una gara)\n\nCon ripetizione e senza ordine: Si considerano i gruppi di elementi senza preoccuparsi dell‚Äôordine. (Es. selezionare un certo numero di ingredienti da una dispensa)\n\nSenza ripetizione e senza ordine: Si scelgono elementi distinti senza considerare l‚Äôordine. (Es. formare squadre da un gruppo di persone)\n\n\nEsempio H.1 ¬†\n\nurna &lt;- c(\"a\", \"b\", \"c\")\n\n# Con ripetizione e ordine\ncampionamento1 &lt;- expand.grid(urna, urna) |&gt;\n    rename(Elemento1 = Var1, Elemento2 = Var2)\n\n# Senza ripetizione e con ordine\ncampionamento2 &lt;- permutations(n = length(urna), r = 2, v = urna) |&gt;\n    as.data.frame() |&gt;\n    rename(Elemento1 = V1, Elemento2 = V2)\n\n# Con ripetizione e senza ordine\ncampionamento3 &lt;- combinations(\n    n = length(urna), r = 2, v = urna, repeats.allowed = TRUE\n) |&gt;\n    as.data.frame() |&gt;\n    rename(Elemento1 = V1, Elemento2 = V2)\n\n# Senza ripetizione e senza ordine\ncampionamento4 &lt;- combinations(n = length(urna), r = 2, v = urna) |&gt;\n    as.data.frame() |&gt;\n    rename(Elemento1 = V1, Elemento2 = V2)\n\n# Risultati\nlist(\n    `Con ripetizione e ordine` = campionamento1,\n    `Senza ripetizione e con ordine` = campionamento2,\n    `Con ripetizione e senza ordine` = campionamento3,\n    `Senza ripetizione e senza ordine` = campionamento4\n)\n#&gt; $`Con ripetizione e ordine`\n#&gt;   Elemento1 Elemento2\n#&gt; 1         a         a\n#&gt; 2         b         a\n#&gt; 3         c         a\n#&gt; 4         a         b\n#&gt; 5         b         b\n#&gt; 6         c         b\n#&gt; 7         a         c\n#&gt; 8         b         c\n#&gt; 9         c         c\n#&gt; \n#&gt; $`Senza ripetizione e con ordine`\n#&gt;   Elemento1 Elemento2\n#&gt; 1         a         b\n#&gt; 2         a         c\n#&gt; 3         b         a\n#&gt; 4         b         c\n#&gt; 5         c         a\n#&gt; 6         c         b\n#&gt; \n#&gt; $`Con ripetizione e senza ordine`\n#&gt;   Elemento1 Elemento2\n#&gt; 1         a         a\n#&gt; 2         a         b\n#&gt; 3         a         c\n#&gt; 4         b         b\n#&gt; 5         b         c\n#&gt; 6         c         c\n#&gt; \n#&gt; $`Senza ripetizione e senza ordine`\n#&gt;   Elemento1 Elemento2\n#&gt; 1         a         b\n#&gt; 2         a         c\n#&gt; 3         b         c",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>H</span>¬† <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#permutazioni-disporre-tutti-gli-elementi-con-ordine",
    "href": "chapters/appendix/a14_combinatorics.html#permutazioni-disporre-tutti-gli-elementi-con-ordine",
    "title": "Appendice H ‚Äî Calcolo combinatorio",
    "section": "\nH.4 Permutazioni: Disporre tutti gli elementi con ordine",
    "text": "H.4 Permutazioni: Disporre tutti gli elementi con ordine\nLe permutazioni rappresentano tutti i modi in cui √® possibile ordinare \\(n\\) elementi distinti. Il numero di permutazioni √® dato da:\n\\[\nP_n = n!\n\\]\ndove \\(n!\\) (n fattoriale) √® il prodotto di tutti i numeri da 1 a \\(n\\):\n\\[\nn! = n \\cdot (n-1) \\cdot (n-2) \\cdot \\dots \\cdot 1.\n\\]\n\nH.4.1 Intuizione della formula\nImmaginiamo di avere \\(n\\) elementi distinti e di doverli disporre in una sequenza. Il primo elemento pu√≤ essere scelto in \\(n\\) modi. Una volta scelto il primo, rimangono \\(n-1\\) possibilit√† per il secondo, poi \\(n-2\\) per il terzo e cos√¨ via, fino all‚Äôultimo elemento, che avr√† 1 sola possibilit√†. Applicando il principio del prodotto, otteniamo:\n\\[\nP_n = n \\times (n-1) \\times (n-2) \\times \\dots \\times 1 = n!\n\\]\n\nH.4.2 Metodo di campionamento corrispondente\n\n\nCampionamento senza ripetizione e con ordine: si estrae una pallina, la si esclude dall‚Äôurna e si continua fino a esaurire gli elementi.\n\n\nEsempio pratico: Ordinare i partecipanti di una gara su un podio (primo, secondo e terzo classificato).\n\nH.4.3 Esempio in R: Permutazioni di tre elementi\nSe abbiamo tre lettere {a, b, c}, le possibili permutazioni sono:\n\\[\nP_3 = 3! = 3 \\times 2 \\times 1 = 6.\n\\]\n\nA &lt;- c(\"a\", \"b\", \"c\")\nperm &lt;- permutations(n = length(A), r = length(A), v = A)\nprint(perm)\n#&gt;      [,1] [,2] [,3]\n#&gt; [1,] \"a\"  \"b\"  \"c\" \n#&gt; [2,] \"a\"  \"c\"  \"b\" \n#&gt; [3,] \"b\"  \"a\"  \"c\" \n#&gt; [4,] \"b\"  \"c\"  \"a\" \n#&gt; [5,] \"c\"  \"a\"  \"b\" \n#&gt; [6,] \"c\"  \"b\"  \"a\"\nnrow(perm)  # Verifica del numero di permutazioni\n#&gt; [1] 6\n\nRisultato:\n\\[\n\\{a, b, c\\}, \\{a, c, b\\}, \\{b, a, c\\}, \\{b, c, a\\}, \\{c, a, b\\}, \\{c, b, a\\}.\n\\]",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>H</span>¬† <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#disposizioni-selezionare-alcuni-elementi-con-ordine",
    "href": "chapters/appendix/a14_combinatorics.html#disposizioni-selezionare-alcuni-elementi-con-ordine",
    "title": "Appendice H ‚Äî Calcolo combinatorio",
    "section": "\nH.5 Disposizioni: Selezionare alcuni elementi con ordine",
    "text": "H.5 Disposizioni: Selezionare alcuni elementi con ordine\nLe disposizioni si usano quando si scelgono \\(k\\) elementi da un insieme di \\(n\\), rispettando l‚Äôordine. Il numero totale di disposizioni √®:\n\\[\nD_{n,k} = \\frac{n!}{(n-k)!} .\n\\]\n\nH.5.1 Intuizione della formula\nSupponiamo di avere \\(n\\) elementi e di voler scegliere solo \\(k\\) elementi, mantenendo l‚Äôordine.\n\nil primo elemento pu√≤ essere scelto in \\(n\\) modi;\nil secondo elemento pu√≤ essere scelto tra gli \\(n-1\\) elementi rimanenti;\n\nil terzo tra gli \\(n-2\\) rimanenti.\n\nSi prosegue fino a quando si hanno scelto \\(k\\) elementi, fermandosi prima di esaurire tutti gli elementi.\n\\[\nD_{n,k} = n \\times (n-1) \\times (n-2) \\times \\dots \\times (n-k+1) .\n\\]\nQuesta espressione corrisponde alla divisione del fattoriale di \\(n\\) per il fattoriale degli elementi che non vengono selezionati:\n\\[\nD_{n,k} = \\frac{n!}{(n-k)!} .\n\\]\n\nH.5.2 Metodo di campionamento corrispondente\n\n\nCampionamento senza ripetizione e con ordine: si estrae una pallina, la si esclude dall‚Äôurna e si continua fino a raggiungere il numero desiderato di elementi, fermandosi prima di esaurire tutti gli elementi.\n\n\nEsempio pratico: Estrarre casualmente 2 studenti da una classe di 10 e assegnare loro i ruoli di rappresentante e vice-rappresentante (l‚Äôordine conta).\n\nH.5.3 Esempio in R: Disposizioni di 2 elementi da {a, b, c}\nSe scegliamo 2 lettere su 3, il numero di disposizioni √®:\n\\[\nD_{3,2} = \\frac{3!}{(3-2)!} = \\frac{3 \\times 2 \\times 1}{1} = 6.\n\\]\n\ndisp &lt;- permutations(n = length(A), r = 2, v = A)\nprint(disp)\n#&gt;      [,1] [,2]\n#&gt; [1,] \"a\"  \"b\" \n#&gt; [2,] \"a\"  \"c\" \n#&gt; [3,] \"b\"  \"a\" \n#&gt; [4,] \"b\"  \"c\" \n#&gt; [5,] \"c\"  \"a\" \n#&gt; [6,] \"c\"  \"b\"\nnrow(disp)  # Verifica del numero di disposizioni\n#&gt; [1] 6\n\nRisultato:\n\\[\n\\{a, b\\}, \\{a, c\\}, \\{b, a\\}, \\{b, c\\}, \\{c, a\\}, \\{c, b\\}.\n\\]\nLe disposizioni considerano l‚Äôordine, quindi \\(\\{a, b\\}\\) √® diverso da \\(\\{b, a\\}\\).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>H</span>¬† <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#combinazioni-selezionare-alcuni-elementi-senza-ordine",
    "href": "chapters/appendix/a14_combinatorics.html#combinazioni-selezionare-alcuni-elementi-senza-ordine",
    "title": "Appendice H ‚Äî Calcolo combinatorio",
    "section": "\nH.6 Combinazioni: Selezionare alcuni elementi senza ordine",
    "text": "H.6 Combinazioni: Selezionare alcuni elementi senza ordine\nLe combinazioni rappresentano il numero di modi per scegliere \\(k\\) elementi da \\(n\\) senza considerare l‚Äôordine. Il numero di combinazioni √® dato da:\n\\[\nC_{n,k} = \\binom{n}{k} = \\frac{n!}{k!(n-k)!} .\n\\]\n\nH.6.1 Intuizione della formula\nSupponiamo di avere \\(n\\) elementi e di voler selezionare \\(k\\) elementi senza considerare l‚Äôordine.\nCome nel caso delle disposizioni, il primo elemento pu√≤ essere scelto in \\(n\\) modi, il secondo in \\(n-1\\), e cos√¨ via fino a selezionare \\(k\\) elementi.\n\\[\nD_{n,k} = n \\times (n-1) \\times \\dots \\times (n-k+1) .\n\\]\nTuttavia, in questo caso, l‚Äôordine non conta, quindi ogni selezione viene duplicata per il numero di modi in cui i \\(k\\) elementi possono essere ordinati, ossia \\(k!\\) permutazioni interne. Per correggere questa duplicazione, dobbiamo dividere per \\(k!\\):\n\\[\nC_{n,k} = \\frac{D_{n,k}}{k!} = \\frac{n!}{k!(n-k)!} .\n\\]\n\nH.6.2 Metodo di campionamento corrispondente\n\n\nCampionamento senza ripetizione e senza ordine: si estrae una pallina e la si esclude dall‚Äôurna, ma non importa l‚Äôordine in cui le palline vengono estratte.\n\n\nEsempio pratico: Formare una squadra di 2 studenti da un gruppo di 10 senza assegnare ruoli specifici (quindi \\(\\{a, b\\}\\) √® uguale a \\(\\{b, a\\}\\)).\n\nH.6.3 Esempio in R: Combinazioni di 2 elementi da {a, b, c}\nSe scegliamo 2 lettere su 3 senza considerare l‚Äôordine, otteniamo:\n\\[\nC_{3,2} = \\binom{3}{2} = \\frac{3!}{2!(3-2)!} = \\frac{3 \\times 2 \\times 1}{2 \\times 1 \\times 1} = 3.\n\\]\n\ncomb &lt;- combinations(n = length(A), r = 2, v = A)\nprint(comb)\n#&gt;      [,1] [,2]\n#&gt; [1,] \"a\"  \"b\" \n#&gt; [2,] \"a\"  \"c\" \n#&gt; [3,] \"b\"  \"c\"\nnrow(comb)  # Verifica del numero di combinazioni\n#&gt; [1] 3\n\nRisultato:\n\\[\n\\{a, b\\}, \\{a, c\\}, \\{b, c\\}.\n\\]\nLe combinazioni non considerano l‚Äôordine, quindi \\(\\{a, b\\}\\) √® uguale a \\(\\{b, a\\}\\).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>H</span>¬† <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#sintesi-quando-usare-ciascun-metodo",
    "href": "chapters/appendix/a14_combinatorics.html#sintesi-quando-usare-ciascun-metodo",
    "title": "Appendice H ‚Äî Calcolo combinatorio",
    "section": "\nH.7 Sintesi: Quando usare ciascun metodo?",
    "text": "H.7 Sintesi: Quando usare ciascun metodo?\n\n\n\n\n\n\n\n\n\nMetodo\nRipetizione?\nOrdine?\nFormula\nMetodo di campionamento\n\n\n\nPermutazioni\n‚ùå No\n‚úÖ S√¨\n\\(n!\\)\nSenza ripetizione e con ordine\n\n\nDisposizioni\n‚ùå No\n‚úÖ S√¨\n\\(\\frac{n!}{(n-k)!}\\)\nSenza ripetizione e con ordine\n\n\nCombinazioni\n‚ùå No\n‚ùå No\n\\(\\binom{n}{k} = \\frac{n!}{k!(n-k)!}\\)\nSenza ripetizione e senza ordine\n\n\n\nIn conclusione, abbiamo visto come il modello dell‚Äôurna aiuti a comprendere i problemi combinatori. Le differenze tra permutazioni, disposizioni e combinazioni dipendono da due fattori fondamentali: ripetizione e ordine.\nQuesta classificazione √® essenziale per risolvere problemi di probabilit√† e statistica in modo rigoroso. Gli esempi e il codice R forniscono strumenti concreti per applicare questi concetti nella pratica.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>H</span>¬† <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a15_calculus.html",
    "href": "chapters/appendix/a15_calculus.html",
    "title": "Appendice I ‚Äî Per liberarvi dai terrori preliminari",
    "section": "",
    "text": "I.1 Integrali\nIn questo capitolo, traduciamo e adattiamo il capitolo Per liberarvi dai terrori preliminari tratto da Calculus made easy.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>I</span>¬† <span class='chapter-title'>Per liberarvi dai terrori preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a15_calculus.html#integrali",
    "href": "chapters/appendix/a15_calculus.html#integrali",
    "title": "Appendice I ‚Äî Per liberarvi dai terrori preliminari",
    "section": "",
    "text": "Il terrore preliminare, che spesso impedisce agli studenti di avvicinarsi all‚Äôanalisi matematica, pu√≤ essere superato comprendendo il significato intuitivo dei due simboli principali utilizzati in questo campo.\nQuesti simboli, che possono sembrare intimidatori, sono in realt√† molto semplici:\n\n\\(d\\): Questo simbolo significa semplicemente ‚Äúun po‚Äô di‚Äù. Ad esempio, \\(\\operatorname{d}\\!x\\) indica un piccolo incremento di \\(x\\), mentre \\(\\operatorname{d}\\!u\\) rappresenta un piccolo incremento di \\(u\\). I matematici preferiscono dire ‚Äúun elemento di‚Äù invece di ‚Äúun po‚Äô di‚Äù, ma il concetto √® lo stesso. Questi piccoli incrementi possono essere considerati infinitamente piccoli.\n\\(\\int\\): Questo simbolo √® una S allungata e rappresenta ‚Äúla somma di‚Äù. Quindi, \\(\\int \\operatorname{d}\\!x\\) significa la somma di tutti i piccoli incrementi di \\(x\\), mentre \\(\\int \\operatorname{d}\\!t\\) indica la somma di tutti i piccoli incrementi di \\(t\\). I matematici chiamano questo simbolo ‚Äúintegrale‚Äù. Se consideri \\(x\\) come composto da tanti piccoli pezzi \\(\\operatorname{d}\\!x\\), sommandoli tutti otterrai l‚Äôintero valore di \\(x\\). La parola ‚Äúintegrale‚Äù significa semplicemente ‚Äúil tutto‚Äù. Ad esempio, se pensi a un‚Äôora come composta da 3600 secondi, la somma di tutti questi secondi ti dar√† un‚Äôora. Quando vedi un‚Äôespressione che inizia con \\(\\int\\), significa che devi sommare tutti i piccoli pezzi indicati dai simboli che seguono.\n\nEcco, il terrore √® svanito!\n\n\n\n\nI.1.1 Verifica con Simulazioni in R\nPer calcolare e visualizzare l‚Äôintegrale di una funzione di densit√†, possiamo utilizzare il linguaggio di programmazione R. Consideriamo come esempio la funzione di densit√† gaussiana, definita dalla seguente formula:\n\\[\nf(x; \\mu, \\sigma) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} e^{-\\frac{(x - \\mu)^2}{2 \\sigma^2}}.\n\\]\nIn R, possiamo definire questa funzione come segue:\n\ngaussian &lt;- function(x, mu, sigma) {\n  1 / (sigma * sqrt(2 * pi)) * exp(-((x - mu)^2) / (2 * sigma^2))\n}\n\nDefiniamo i parametri e generiamo i valori per il calcolo della funzione di densit√† su un intervallo:\n\nmu &lt;- 0      # Media\nsigma &lt;- 1   # Deviazione standard\na &lt;- -10     # Limite inferiore\nb &lt;- 10      # Limite superiore\nn &lt;- 10000   # Numero di punti\n\nx_range &lt;- seq(a, b, length.out = n)  # Valori x\nfx &lt;- gaussian(x_range, mu, sigma)   # Ordinata della funzione\n\nVisualizziamo la funzione utilizzando il pacchetto ggplot2:\n\nlibrary(ggplot2)\nlibrary(scales)\n\nggplot(data.frame(x = x_range, fx = fx), aes(x, fx)) +\n  geom_line(color = \"blue\") +\n  labs(\n    title = \"Funzione di densit√† gaussiana\", \n    x = \"x\", \n    y = \"f(x)\"\n  )\n\n\n\n\n\n\n\nCreiamo una funzione per approssimare l‚Äôintegrale sommando i prodotti \\(\\Delta x \\cdot f(x)\\):\n\nintegral_approximation &lt;- function(f, a, b, n) {\n  delta &lt;- (b - a) / n\n  sum(delta * f)\n}\n\n# Calcolo dell'integrale approssimato\napprox &lt;- integral_approximation(fx, a, b, n)\napprox\n\n[1] 0.9999\n\n\nConfrontiamo il risultato con il calcolo fornito dalla funzione integrate di R:\n\nintegrate(\n  function(x) gaussian(x, mu, sigma),\n  lower = a,\n  upper = b\n)\n\n1 with absolute error &lt; 7.4e-05\n\n\nCalcoliamo l‚Äôarea sotto la curva in intervalli di interesse. Ad esempio, per \\([-1.96, 1.96]\\), che corrisponde al 95% dell‚Äôarea nella distribuzione normale standard:\n\na &lt;- -1.96\nb &lt;- 1.96\nx_range &lt;- seq(a, b, length.out = n)\nfx &lt;- gaussian(x_range, mu, sigma)\n\napprox &lt;- integral_approximation(fx, a, b, n)\napprox\n\n[1] 0.9499321\n\n\nConfrontiamo con il risultato fornito da integrate():\n\nintegrate(\n  function(x) gaussian(x, mu, sigma),\n  lower = a,\n  upper = b\n)\n\n0.9500042 with absolute error &lt; 1e-11\n\n\nVerifichiamo l‚Äôarea sotto la curva per \\([-1, 1]\\), che rappresenta circa il 68% dell‚Äôarea totale:\n\na &lt;- -1.0\nb &lt;- 1.0\nx_range &lt;- seq(a, b, length.out = n)\nfx &lt;- gaussian(x_range, mu, sigma)\n\napprox &lt;- integral_approximation(fx, a, b, n)\napprox\n\n[1] 0.6826696\n\n\nConfronto:\n\nintegrate(\n  function(x) gaussian(x, mu, sigma),\n  lower = a,\n  upper = b\n)\n\n0.6826895 with absolute error &lt; 7.6e-15\n\n\nIn sintesi, questo approccio dimostra come calcolare l‚Äôintegrale di una funzione di densit√† in un intervallo utilizzando sia un metodo approssimativo basato sulla somma dei rettangoli sia il metodo numerico integrato. In entrambi i casi, l‚Äôobiettivo √® calcolare l‚Äôarea sotto la curva, che corrisponde all‚Äôintegrale della funzione di densit√†.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>I</span>¬† <span class='chapter-title'>Per liberarvi dai terrori preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a15_calculus.html#potenze",
    "href": "chapters/appendix/a15_calculus.html#potenze",
    "title": "Appendice I ‚Äî Per liberarvi dai terrori preliminari",
    "section": "\nI.2 Potenze",
    "text": "I.2 Potenze\nLe potenze sono un‚Äôoperazione matematica che rappresenta un prodotto ripetuto. Si indicano generalmente come:\n\\[\na^n,\n\\]\ndove:\n\n\n\\(a\\) √® la base,\n\n\\(n\\) √® l‚Äôesponente.\n\nLa potenza rappresenta il prodotto della base \\(a\\) ripetuto \\(n\\) volte.\n\nI.2.1 Definizione di potenza\n\\[\na^n = \\underbrace{a \\cdot a \\cdot \\dots \\cdot a}_{n \\text{ fattori}} \\quad \\text{con } n \\in \\mathbb{N}.\n\\]\nAd esempio:\n\n\n\\(2^3 = 2 \\cdot 2 \\cdot 2 = 8\\),\n\n\\(3^4 = 3 \\cdot 3 \\cdot 3 \\cdot 3 = 81\\).\n\n\nI.2.2 Propriet√† delle potenze\n\n\nMoltiplicazione di potenze con la stessa base:\n\\[\na^m \\cdot a^n = a^{m+n}\n\\]\nEsempio: \\(2^3 \\cdot 2^2 = 2^{3+2} = 2^5 = 32\\).\n\n\nDivisione di potenze con la stessa base:\n\\[\n\\frac{a^m}{a^n} = a^{m-n}, \\quad \\text{con } m \\geq n.\n\\]\nEsempio: \\(\\frac{5^4}{5^2} = 5^{4-2} = 5^2 = 25\\).\n\n\nPotenze di potenze:\n\\[\n(a^m)^n = a^{m \\cdot n}.\n\\]\nEsempio: \\((3^2)^3 = 3^{2 \\cdot 3} = 3^6 = 729\\).\n\n\nProdotto di potenze con basi diverse ma lo stesso esponente:\n\\[\na^n \\cdot b^n = (a \\cdot b)^n.\n\\]\nEsempio: \\(2^3 \\cdot 3^3 = (2 \\cdot 3)^3 = 6^3 = 216\\).\n\n\nDivisione di potenze con basi diverse ma lo stesso esponente:\n\\[\n\\frac{a^n}{b^n} = \\left(\\frac{a}{b}\\right)^n.\n\\]\nEsempio: \\(\\frac{4^2}{2^2} = \\left(\\frac{4}{2}\\right)^2 = 2^2 = 4\\).\n\n\nEsponente zero:\n\\[\na^0 = 1, \\quad \\text{con } a \\neq 0.\n\\]\nEsempio: \\(5^0 = 1\\).\n\n\nEsponente negativo:\n\\[\na^{-n} = \\frac{1}{a^n}.\n\\]\nEsempio: \\(2^{-3} = \\frac{1}{2^3} = \\frac{1}{8}\\).\n\n\nRadice come potenza frazionaria:\n\\[\na^{\\frac{1}{n}} = \\sqrt[n]{a}, \\quad a^{\\frac{m}{n}} = \\sqrt[n]{a^m}.\n\\]\nEsempio: \\(8^{\\frac{1}{3}} = \\sqrt[3]{8} = 2\\).\n\n\n\nI.2.3 Esempi pratici\n\n\nCalcolo semplice:\n\\[\n4^3 = 4 \\cdot 4 \\cdot 4 = 64.\n\\]\n\n\nUtilizzo delle propriet√†:\n\\[\n3^5 \\cdot 3^2 = 3^{5+2} = 3^7 = 2187.\n\\]\n\n\nDivisione:\n\\[\n\\frac{6^4}{6^2} = 6^{4-2} = 6^2 = 36.\n\\]\n\n\nEsponente negativo:\n\\[\n10^{-2} = \\frac{1}{10^2} = \\frac{1}{100} = 0.01.\n\\]\n\n\nRadice come potenza:\n\\[\n16^{\\frac{1}{2}} = \\sqrt{16} = 4.\n\\]\n\n\n\nI.2.4 Nota sui numeri razionali e reali\n\nLe potenze con esponenti interi sono definite per ogni base.\nLe potenze con esponenti frazionari o reali richiedono che la base sia positiva per evitare ambiguit√†.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>I</span>¬† <span class='chapter-title'>Per liberarvi dai terrori preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a15_calculus.html#logaritmi",
    "href": "chapters/appendix/a15_calculus.html#logaritmi",
    "title": "Appendice I ‚Äî Per liberarvi dai terrori preliminari",
    "section": "\nI.3 Logaritmi",
    "text": "I.3 Logaritmi\nIl logaritmo √® una funzione matematica che risponde alla domanda: ‚Äúquante volte devo moltiplicare un certo numero (chiamato‚Äùbase‚Äù) per ottenere un altro numero?‚Äù Matematicamente, questo √® espresso come:\n\\[\n\\log_b(a) = x \\iff b^x = a\n\\]\nAd esempio, \\(\\log_2(8) = 3\\) perch√© \\(2^3 = 8\\).\nNel contesto dei logaritmi, i valori molto piccoli (compresi tra 0 e 1) diventano pi√π grandi (in termini assoluti) e negativi quando applichiamo una funzione logaritmica. Questo √® utile per stabilizzare i calcoli, specialmente quando lavoriamo con prodotti di numeri molto piccoli che potrebbero portare a problemi di underflow.\nPer esempio:\n\n\\(\\log(1) = 0\\)\n\\(\\log(0.1) = -1\\)\n\\(\\log(0.01) = -2\\)\n\\(\\log(0.001) = -3\\)\n\nCome si pu√≤ vedere, i valori assoluti dei logaritmi crescono man mano che il numero originale si avvicina a zero.\nUna delle propriet√† pi√π utili dei logaritmi √® che consentono di trasformare un prodotto in una somma:\n\\[\n\\log_b(a \\times c) = \\log_b(a) + \\log_b(c)\n\\]\nQuesta propriet√† √® estremamente utile in calcoli complessi, come nella statistica bayesiana, dove il prodotto di molte probabilit√† potrebbe diventare un numero molto piccolo e causare problemi numerici.\nUn‚Äôaltra propriet√† utile dei logaritmi √® che un rapporto tra due numeri diventa la differenza dei loro logaritmi:\n\\[\n\\log_b\\left(\\frac{a}{c}\\right) = \\log_b(a) - \\log_b(c)\n\\]\nAnche questa propriet√† √® molto utilizzata in matematica, specialmente in situazioni in cui √® necessario normalizzare i dati.\nIn sintesi, i logaritmi sono strumenti potenti per semplificare e stabilizzare i calcoli matematici. Essi consentono di lavorare pi√π agevolmente con numeri molto grandi o molto piccoli e di trasformare operazioni complesse come prodotti e divisioni in somme e differenze, rendendo i calcoli pi√π gestibili e meno inclini a errori numerici.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>I</span>¬† <span class='chapter-title'>Per liberarvi dai terrori preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a50_lin_fun.html",
    "href": "chapters/appendix/a50_lin_fun.html",
    "title": "Appendice J ‚Äî La funzione lineare",
    "section": "",
    "text": "J.1 Concetto di Funzione\nNello studio dei fenomeni naturali e nella risoluzione di problemi tecnici e matematici, √® spesso necessario considerare la variazione di una grandezza come dipendente dalla variazione di un‚Äôaltra. Ad esempio, nello studio del moto, il percorso compiuto da un oggetto pu√≤ essere visto come una grandezza variabile in funzione del tempo: il cammino percorso √®, dunque, una funzione del tempo.\nQuesta considerazione ci conduce alla seguente definizione:\nSe a ogni valore della variabile \\(x\\) (all‚Äôinterno di un certo intervallo) corrisponde un valore ben definito di un‚Äôaltra variabile \\(y\\), allora si dice che \\(y\\) √® una funzione di \\(x\\). In notazione funzionale si scrive:\n\\[\ny = f(x) \\quad \\text{o anche} \\quad y = \\varphi(x).\n\\]\nLa variabile \\(x\\) √® detta variabile indipendente o argomento della funzione. La relazione che lega \\(x\\) a \\(y\\) si chiama relazione funzionale. La lettera \\(f\\) nella notazione \\(y = f(x)\\) indica che per ottenere il valore di \\(y\\) a partire da \\(x\\) √® necessario applicare una certa ‚Äúregola‚Äù o ‚Äúoperazione‚Äù. In modo analogo, si possono utilizzare anche altre notazioni come \\(u = \\varphi(x)\\).\nLa notazione \\(y = C\\), dove \\(C\\) √® una costante, indica una funzione il cui valore rimane invariato per qualunque valore di \\(x\\).\nL‚Äôinsieme dei valori di \\(x\\) per cui la funzione \\(y = f(x)\\) √® definita si chiama dominio di definizione della funzione.\nSe per valori crescenti della variabile indipendente \\(x\\) anche il valore della funzione \\(y = f(x)\\) aumenta, allora la funzione si dice crescente. Analogamente, se a valori crescenti di \\(x\\) corrispondono valori decrescenti della funzione \\(y = f(x)\\), la funzione si dice decrescente.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>J</span>¬† <span class='chapter-title'>La funzione lineare</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a50_lin_fun.html#la-retta",
    "href": "chapters/appendix/a50_lin_fun.html#la-retta",
    "title": "Appendice J ‚Äî La funzione lineare",
    "section": "J.2 La Retta",
    "text": "J.2 La Retta\nLa funzione lineare √® definita come:\n\\[\nf(x) = a + b x,\n\\]\ndove \\(a\\) e \\(b\\) sono costanti. Il grafico di tale funzione √® una retta. Qui, \\(b\\) √® detto coefficiente angolare, mentre \\(a\\) √® l‚Äôintercetta con l‚Äôasse delle \\(y\\). In altri termini, la retta interseca l‚Äôasse \\(y\\) nel punto \\((0, a)\\).\nPer comprendere il ruolo di \\(a\\) e \\(b\\), consideriamo prima il caso particolare:\n\\[\ny = b x.\n\\]\nQuesta espressione rappresenta una proporzionalit√† diretta tra \\(x\\) e \\(y\\): al crescere di \\(x\\), \\(y\\) varia in proporzione. Nel caso generale:\n\\[\ny = a + b x,\n\\]\nil termine \\(a\\) ‚Äútrasla‚Äù verticalmente il grafico, aggiungendo una costante a ogni valore \\(b x\\).\nIl segno del coefficiente \\(b\\) determina il comportamento della funzione lineare:\n\nSe \\(b &gt; 0\\), il valore di \\(y\\) aumenta all‚Äôaumentare di \\(x\\).\n\nSe \\(b &lt; 0\\), il valore di \\(y\\) diminuisce all‚Äôaumentare di \\(x\\).\n\nSe \\(b = 0\\), il grafico √® una retta orizzontale e \\(y\\) rimane costante.\n\nPossiamo dare un‚Äôinterpretazione geometrica ancora pi√π intuitiva se consideriamo variazioni (incrementi) di \\(x\\). Preso un punto \\(x_0\\) e aggiungendo un piccolo incremento \\(\\varepsilon\\), definiamo:\n\\[\n\\Delta x = (x_0 + \\varepsilon) - x_0 = \\varepsilon,\n\\] \\[\n\\Delta y = f(x_0 + \\varepsilon) - f(x_0).\n\\]\nIl coefficiente angolare \\(b\\) pu√≤ essere interpretato come il rapporto tra la variazione di \\(y\\) e la variazione di \\(x\\):\n\\[\nb = \\frac{\\Delta y}{\\Delta x} = \\frac{f(x_0 + \\varepsilon) - f(x_0)}{(x_0 + \\varepsilon) - x_0}.\n\\]\nQuesto rapporto √® costante e non dipende dalla scelta di \\(x_0\\) o di \\(\\varepsilon\\). In particolare, se scegliamo \\(\\Delta x = 1\\), il coefficiente angolare \\(b\\) rappresenta semplicemente di quanto varia \\(y\\) quando \\(x\\) aumenta di un‚Äôunit√†.\n\n\n\n\n\n\n\nFigura¬†J.1: La funzione lineare \\(y = a + bx\\).\n\n\n\nCome mostrato in figura, il coefficiente \\(b\\) indica la pendenza della retta, ossia quanto ‚Äúripida‚Äù √® la sua inclinazione rispetto all‚Äôasse orizzontale.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>J</span>¬† <span class='chapter-title'>La funzione lineare</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a71_install_cmdstan.html",
    "href": "chapters/appendix/a71_install_cmdstan.html",
    "title": "Appendice K ‚Äî Come installare CmdStan",
    "section": "",
    "text": "K.1 Windows\nSu macOS e Linux, questa configurazione dovrebbe essere gi√† pronta di default.\nSu Windows √® necessario installare RTools e configurare PATH:\nProblemi comuni:",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>K</span>¬† <span class='chapter-title'>Come installare CmdStan</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a71_install_cmdstan.html#windows",
    "href": "chapters/appendix/a71_install_cmdstan.html#windows",
    "title": "Appendice K ‚Äî Come installare CmdStan",
    "section": "",
    "text": "Installazione di RTools:\n\nVai su https://cran.r-project.org/bin/windows/Rtools/\nScarica la versione di RTools compatibile con la tua versione di R (Generalmente, RTools 4.3 per R 4.3.x, RTools 4.2 per R 4.2.x, etc.)\nEsegui l‚Äôinstaller scaricato\nIMPORTANTE: Durante l‚Äôinstallazione, seleziona la casella ‚ÄúAdd rtools to system PATH‚Äù\n\nVerifica dell‚Äôinstallazione e configurazione del PATH:\n\nApri PowerShell o Command Prompt\nVerifica se RTools √® nel PATH digitando:\n\ngcc --version\nSe vedi la versione di gcc, RTools √® nel PATH.\nSe RTools non √® nel PATH, devi aggiungerlo manualmente:\n\nCerca ‚ÄúImpostazioni di Sistema‚Äù in Windows\nClicca su ‚ÄúImpostazioni di sistema avanzate‚Äù\nClicca su ‚ÄúVariabili d‚Äôambiente‚Äù\nNella sezione ‚ÄúVariabili di sistema‚Äù, trova ‚ÄúPath‚Äù\nClicca ‚ÄúModifica‚Äù\nClicca ‚ÄúNuovo‚Äù e aggiungi questi percorsi (sostituisci X.X con la tua versione di RTools):\nC:\\rtools4X\\mingw64\\bin\nC:\\rtools4X\\usr\\bin\n\nVerifica finale:\n\nChiudi e riapri il terminale\nProva questi comandi:\n\ngcc --version\nmake --version\nSe entrambi i comandi mostrano le versioni, l‚Äôinstallazione √® completa.\nTest in R:\n\nApri R o RStudio\nEsegui:\n\nSys.which(\"make\")\nDovrebbe mostrare il percorso di make.\n\n\n\nSe i comandi non vengono riconosciuti dopo aver aggiunto il PATH, prova a riavviare il computer.\nSe usi RStudio, potrebbe essere necessario riavviarlo dopo aver modificato il PATH.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>K</span>¬† <span class='chapter-title'>Come installare CmdStan</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_bayes_theorem.html#il-teorema-di-bayes-nella-psicologia-il-modello-rescorla-wagner-come-esempio-di-adattamento-allambiente",
    "href": "chapters/probability/06_bayes_theorem.html#il-teorema-di-bayes-nella-psicologia-il-modello-rescorla-wagner-come-esempio-di-adattamento-allambiente",
    "title": "30¬† Il teorema di Bayes",
    "section": "\n30.2 Il Teorema di Bayes nella Psicologia: il Modello Rescorla-Wagner come Esempio di Adattamento all‚ÄôAmbiente",
    "text": "30.2 Il Teorema di Bayes nella Psicologia: il Modello Rescorla-Wagner come Esempio di Adattamento all‚ÄôAmbiente\nPer illustrare concretamente il ruolo del teorema di Bayes in psicologia, possiamo considerare un fenomeno molto comune nella vita quotidiana: l‚Äôapprendimento associativo. Questa capacit√† permette a esseri umani e altri organismi viventi di prevedere eventi futuri sulla base delle esperienze passate, adattando continuamente il proprio comportamento a un ambiente in costante mutamento.\nUn modello psicologico particolarmente influente che formalizza questo processo √® il modello Rescorla-Wagner. Nato inizialmente per spiegare come gli animali apprendano ad associare segnali ambientali a specifiche conseguenze, questo modello si √® rivelato utile anche per comprendere l‚Äôapprendimento umano. Esso mostra chiaramente come le persone aggiornino le proprie aspettative ogni volta che si trovano davanti a nuove informazioni o situazioni inattese, evidenziando un processo continuo di adattamento alle condizioni mutevoli dell‚Äôambiente circostante.\n\n30.2.1 Il Modello Rescorla-Wagner e l‚ÄôAdattamento all‚ÄôAmbiente\nSecondo il modello Rescorla-Wagner, quando ci troviamo di fronte a situazioni nuove o imprevedibili, sviluppiamo aspettative su ci√≤ che potrebbe accadere. Se queste aspettative vengono disattese (ad esempio, ricevendo una ricompensa diversa da quella prevista), sperimentiamo quello che il modello definisce ‚Äúerrore di previsione‚Äù. Questo errore, fondamentale per l‚Äôapprendimento, funge da meccanismo chiave per aggiornare rapidamente la nostra comprensione della realt√†.\nFacciamo un esempio: immaginiamo un agente che, in un contesto in cui premere un pulsante genera solitamente una ricompensa (una moneta, una caramella, ecc.), si trovi improvvisamente a non riceverla pi√π. L‚Äôerrore di previsione generato da questa discrepanza modifica le aspettative dell‚Äôagente. Di conseguenza, nelle occasioni successive, le sue previsioni si adatteranno alla nuova realt√†, riducendo la probabilit√† attesa della ricompensa.\nIl principale vantaggio del modello Rescorla-Wagner risiede nella sua essenzialit√†: basandosi su pochi principi fondamentali, riesce a descrivere in modo efficace come gli individui regolino le proprie aspettative in risposta a cambiamenti ambientali, garantendo un adattamento rapido e dinamico.\n\n30.2.2 Una Prospettiva Bayesiana sull‚ÄôApprendimento\nAnche se il modello di Rescorla-Wagner non nasce direttamente dal teorema di Bayes, pu√≤ essere interpretato facilmente come un caso speciale di aggiornamento bayesiano. Il teorema di Bayes, infatti, descrive come dovremmo modificare razionalmente le nostre credenze alla luce di nuove evidenze. In psicologia, questa ‚Äúevidenza‚Äù pu√≤ essere pensata come la differenza tra ci√≤ che ci aspettavamo e ci√≤ che realmente accade‚Äîproprio come fa il modello Rescorla-Wagner.\nNella prospettiva bayesiana, le aspettative di una persona vengono considerate come ‚Äúcredenze‚Äù che vengono aggiornate costantemente sulla base delle nuove informazioni che emergono. Ogni volta che riceviamo un‚Äôinformazione che contraddice le nostre aspettative iniziali, la nostra credenza viene rivista. Questo processo bayesiano permette di adattarsi in modo ottimale alle situazioni nuove o incerte, proprio come avviene con il modello Rescorla-Wagner (si veda l‚Äôesempio presentato nella Sezione 30.4).\nIn sintesi, il modello Rescorla-Wagner non solo rappresenta efficacemente come avviene l‚Äôapprendimento associativo nella vita quotidiana, ma fornisce anche un esempio pratico e intuitivo del ruolo del teorema di Bayes in psicologia: aiuta a capire come la nostra mente sia continuamente impegnata ad adattarsi razionalmente e rapidamente ai cambiamenti di un ambiente imprevedibile.\n\n30.2.3 Una Rivoluzione nel Pensiero Probabilistico\nPer comprendere appieno il teorema di Bayes, √® necessario delineare le sue origini storiche. Nel XVIII secolo, Thomas Bayes (1701-1761), ecclesiastico presbiteriano e matematico britannico, pose le basi di una rivoluzione concettuale nel campo della probabilit√† e della statistica. Il suo contributo teorico, passato alla storia come teorema di Bayes, ha plasmato in modo decisivo lo sviluppo scientifico e tecnologico dei secoli successivi, influenzando discipline che spaziano dalla medicina all‚Äôintelligenza artificiale (Chivers, 2024).\n\n30.2.4 La Figura di Thomas Bayes\nBayes proveniva da una famiglia benestante e studi√≤ teologia a Edimburgo, preparandosi al ministero religioso. Come ricorda il biografo David Bellhouse, Bayes non era un accademico nel senso moderno del termine, ma un erudito libero, interessato alla conoscenza per passione personale (Bellhouse, 2004).\nDurante la sua vita, Bayes pubblic√≤ due testi:\n\n\nUn trattato di teologia: Divine Benevolence: Or, an Attempt to Prove that the Principal End of the Divine Providence and Government is the Happiness of His Creatures (1731), una teodicea che cerca di spiegare come la legge naturale possa ottimizzare il benessere universale.\n\n\nUna difesa del calcolo infinitesimale: An Introduction to the Doctrine of Fluxions (1736), in risposta alle critiche di George Berkeley sugli infinitesimi e i concetti fondamentali del calcolo newtoniano (Jesseph, 1993).\n\nIl lavoro che segn√≤ la svolta nella teoria della probabilit√† fu per√≤ pubblicato postumo, nel 1763, sulle Philosophical Transactions of the Royal Society: An Essay towards Solving a Problem in the Doctrine of Chances. Per la prima volta, si formalizzava un metodo per aggiornare le ipotesi probabilistiche alla luce di nuove evidenze, ponendo le fondamenta dell‚Äôinferenza bayesiana (Stigler, 1990).\n\n30.2.5 Bayes e il Ruolo Culturale della Scienza\nCome sottolinea ancora Bellhouse, nel XVIII secolo era comune, tra le √©lite colte, dedicarsi allo studio di discipline scientifiche per prestigio sociale. Per Bayes, la matematica era dunque una passione coltivata con spirito libero. Il suo merito straordinario fu di spingere l‚Äôinterpretazione della probabilit√† verso una prospettiva epistemologica innovativa, dove la probabilit√† diventa espressione quantitativa della nostra ignoranza sul mondo.\nIn contrapposizione alla visione ‚Äúclassica‚Äù, che vedeva la probabilit√† come frequenza osservabile in eventi ripetuti, Bayes propose che essa potesse rappresentare il grado di fiducia di un osservatore, inevitabilmente influenzato da conoscenze pregresse e da pregiudizi individuali. In questo senso, la probabilit√† assume un carattere dinamico e soggettivo, configurandosi come uno strumento di conoscenza che si aggiorna di continuo al variare dei dati (Spiegelhalter, 2019).\n\n30.2.5.1 Un Esperimento Mentale Illuminante\nPer illustrare la sua idea, Bayes propose un semplice esempio: immagina di lanciare alcune palline su un tavolo da biliardo. Dopo aver segnato con una linea il punto in cui si ferma una pallina bianca (e averla poi rimossa), si lanciano altre palline rosse e si conta quante cadono a destra e quante a sinistra di quella linea. Sulla base di queste osservazioni, come si pu√≤ ‚Äúindovinare‚Äù la posizione della linea? E con quale probabilit√† la prossima pallina rossa cadr√† a sinistra di essa?\nLa soluzione di Bayes combina i dati osservati (numero di palline cadute a sinistra o a destra) con le convinzioni iniziali dell‚Äôosservatore (il cosiddetto ‚Äúprior‚Äù), delineando un processo di apprendimento graduale che guida la revisione critica delle ipotesi.\n\n30.2.6 Il Ruolo di Richard Price\nDopo la morte di Bayes, fu un altro ecclesiastico, Richard Price (1723-1791), a dare impulso alla diffusione del saggio bayesiano. Price aveva un‚Äôottima reputazione negli ambienti intellettuali dell‚Äôepoca, grazie anche alle sue relazioni con figure di spicco come Benjamin Franklin, Thomas Jefferson e John Adams.\nPrice prese in carico il manoscritto di Bayes, lo sottopose al fisico John Canton e ne cur√≤ la pubblicazione postuma, operando modifiche significative. Rispetto alla versione originale di Bayes, concentrata quasi esclusivamente sugli aspetti teorici, Price aggiunse una parte dedicata alle applicazioni pratiche, rendendo il testo pi√π fruibile a un pubblico pi√π ampio. Per questo motivo, lo storico Stephen Stigler lo definisce ¬´il primo bayesiano della storia¬ª.\n\n30.2.7 Dal Silenzio alla Riscoperta\nPer oltre cinquant‚Äôanni, il lavoro di Bayes rimase in ombra, oscurato dall‚Äôopera pionieristica di Pierre-Simon Laplace. Gi√† nel 1774, Laplace pervenne indipendentemente a principi analoghi, e successivamente li sistematizz√≤ nella monumentale Th√©orie analytique des probabilit√©s (1812). Solo in tempi pi√π recenti, con l‚Äôavvento dei metodi di calcolo moderno e dell‚Äôinformatica, la statura del teorema di Bayes √® emersa in tutta la sua importanza.\nOggi, il teorema di Bayes √® considerato un cardine della statistica moderna: formalizza il modo in cui aggiorniamo le nostre credenze alla luce di nuovi dati. Questo schema √® cruciale in ogni disciplina scientifica e tecnologica che debba fare i conti con incertezza e dati incompleti. Dalla genomica all‚Äôeconometria, dalla fisica delle particelle alle scienze cognitive, il paradigma bayesiano risulta prezioso per gestire e interpretare informazioni in continuo aggiornamento.\n\n30.2.8 L‚ÄôEredit√† di Bayes nell‚ÄôEra Digitale\nNell‚Äôintelligenza artificiale, le idee bayesiane sono alla base di sistemi di apprendimento automatico e modelli probabilistici complessi. Strumenti come i moderni modelli linguistici (ad esempio ChatGPT e Claude) sfruttano strategie di inferenza bayesiana ‚Äì anche se in forme estremamente avanzate ‚Äì per generare risposte, fare previsioni e adattarsi costantemente agli input degli utenti.\nLa parabola storica di questo teorema, nato dalle speculazioni di un pastore presbiteriano del Settecento, mostra chiaramente il potenziale trasformativo delle idee matematiche. Come sottolinea Tom Chivers nel suo Everything Is Predictable: How Bayesian Statistics Explain Our World, la statistica bayesiana √® diventata una sorta di ‚Äúgrammatica universale‚Äù per interpretare la realt√†, permettendoci di affrontare con metodo situazioni complesse, modellare l‚Äôincertezza e formulare previsioni in contesti dove l‚Äôinformazione √® inevitabilmente limitata (Chivers, 2024).\nIn sintesi, la forza del teorema di Bayes non risiede soltanto nella sua eleganza formale, ma soprattutto nella sua portata epistemologica: esso traduce in termini matematici la nostra naturale tendenza ad apprendere da ci√≤ che osserviamo e a rivedere continuamente ci√≤ che crediamo. Per questo rimane, ancora oggi, un punto di riferimento fondamentale in qualunque disciplina che affronti il problema della conoscenza in condizioni di incertezza. ## La Regola di Bayes e l‚Äôinferenza probabilistica\nL‚Äôinferenza bayesiana utilizza un principio centrale della teoria delle probabilit√† noto come regola di Bayes. Questo principio consente di aggiornare in modo razionale le nostre credenze sulla base di nuovi dati osservati, integrandoli con conoscenze pregresse.\n\n30.2.9 Derivazione della Regola di Bayes\nConsideriamo due eventi casuali, \\(A\\) e \\(B\\). La probabilit√† congiunta \\(P(A, B)\\), ossia la probabilit√† che entrambi gli eventi accadano simultaneamente, pu√≤ essere espressa in due modi equivalenti:\n\nTramite la regola della catena, possiamo scrivere: \\[\nP(A, B) = P(A \\mid B)P(B).\n\\] Qui, \\(P(A \\mid B)\\) √® la probabilit√† condizionata che si verifichi l‚Äôevento \\(A\\) sapendo che l‚Äôevento \\(B\\) √® avvenuto, mentre \\(P(B)\\) √® la probabilit√† marginale di \\(B\\), indipendente da \\(A\\).\nUtilizzando la simmetria della probabilit√† congiunta, possiamo invertire gli eventi: \\[\nP(A, B) = P(B \\mid A)P(A).\n\\]\n\nDato che entrambe le espressioni rappresentano la stessa probabilit√† congiunta, possiamo eguagliarle:\n\\[\nP(A \\mid B)P(B) = P(B \\mid A)P(A).\n\\]\nRisolvendo per \\(P(B \\mid A)\\) otteniamo la regola di Bayes:\n\\[\nP(B \\mid A) = \\frac{P(A \\mid B) P(B)}{P(A)}.\n\\tag{30.1}\\]\n\n30.2.10 Interpretazione dei termini della regola di Bayes\nLa regola di Bayes permette di aggiornare la nostra credenza sulla probabilit√† di un‚Äôipotesi o evento (\\(B\\)), dopo aver osservato un dato o evidenza (\\(A\\)):\n\n\n\\(P(B)\\) (prior): √® la probabilit√† iniziale assegnata all‚Äôevento \\(B\\) prima di osservare il dato \\(A\\). Rappresenta la nostra conoscenza pregressa o il nostro grado iniziale di fiducia.\n\n\\(P(A \\mid B)\\) (verosimiglianza): √® la probabilit√† di osservare il dato \\(A\\) nell‚Äôipotesi che \\(B\\) sia vero. Indica quanto il dato sia compatibile con l‚Äôipotesi.\n\n\\(P(B \\mid A)\\) (posterior): √® la probabilit√† aggiornata, cio√® la nostra nuova credenza sull‚Äôevento \\(B\\) dopo aver osservato il dato \\(A\\).\n\n\\(P(A)\\) (evidenza): √® la probabilit√† marginale del dato osservato, calcolata sommando o integrando su tutte le possibili ipotesi alternative che potrebbero aver generato tale dato. Agisce da termine di normalizzazione per garantire che la somma delle probabilit√† a posteriori sia uguale a 1.\n\n30.2.11 Applicazioni della Regola di Bayes\nNella pratica, l‚Äôinferenza bayesiana si svolge tipicamente nel seguente modo:\n\nSi parte da uno spazio delle ipotesi \\(\\mathcal{H}\\), ovvero un insieme di tutte le possibili spiegazioni o modelli che potrebbero aver generato i dati osservati \\(D\\).\nA ciascuna ipotesi \\(H \\in \\mathcal{H}\\) viene assegnata una probabilit√† a priori \\(P(H)\\) che riflette la nostra fiducia iniziale.\nUna volta raccolti i dati \\(D\\), aggiorniamo le probabilit√† delle ipotesi usando la formula:\n\n\\[\nP(H \\mid D) = \\frac{P(D \\mid H) \\, P(H)}{P(D)},\n\\tag{30.2}\\]\ndove:\n\n\n\\(P(D \\mid H)\\) √® la verosimiglianza, cio√® la probabilit√† che l‚Äôipotesi \\(H\\) abbia generato i dati \\(D\\);\n\n\\(P(D)\\) √® la probabilit√† marginale (evidenza), calcolata considerando tutte le possibili ipotesi:\n\n\\[\nP(D) = \\sum_{H' \\in \\mathcal{H}} P(D \\mid H')P(H'),\n\\]\nnel caso discreto, oppure:\n\\[\nP(D) = \\int_{\\mathcal{H}} P(D \\mid H')P(H') \\, dH',\n\\]\nnel caso continuo.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_bayes_theorem.html#sec-bayes-coin-hypotheses",
    "href": "chapters/probability/06_bayes_theorem.html#sec-bayes-coin-hypotheses",
    "title": "30¬† Il teorema di Bayes",
    "section": "\n30.4 Un Esempio Intuitivo: la Moneta Bilanciata o Truccata",
    "text": "30.4 Un Esempio Intuitivo: la Moneta Bilanciata o Truccata\nImmaginiamo questo scenario: sospettiamo che una moneta possa essere truccata e vogliamo verificarlo attraverso due lanci. Utilizzeremo il ragionamento bayesiano per combinare le nostre convinzioni iniziali con i dati osservati.\nLe Due Ipotesi.\nSupponiamo che la moneta possa essere:\n\n\nbilanciata (pari probabilit√† di Testa e Croce: 50% ciascuna);\n\ntruccata (sbilanciata, con probabilit√† di Testa del 80% e Croce del 20%).\n\nIl nostro obiettivo √® capire quale ipotesi sia pi√π plausibile dopo ogni lancio.\n\n30.4.1 Fase 1: Credenze Iniziali (Prior).\nPrima di lanciare la moneta, abbiamo una certa idea di quanto sia probabile ciascuna ipotesi:\n\\[\nP(\\text{Bilanciata}) = 0.85 \\quad\\text{e}\\quad P(\\text{Truccata}) = 0.15.\n\\]\nQueste probabilit√† rappresentano il prior, ovvero le nostre convinzioni iniziali prima di osservare qualunque risultato.\n\n30.4.2 Fase 2: Primo Lancio - Esce Testa\nLanciamo la moneta una volta e osserviamo il risultato: esce Testa.\nCi chiediamo: ‚ÄúQuanto √® probabile osservare Testa se ciascuna delle due ipotesi fosse vera?‚Äù\n\nSe la moneta √® bilanciata, la probabilit√† di osservare Testa √® 0.5 (50%).\nSe la moneta √® truccata, la probabilit√† di osservare Testa √® 0.8 (80%).\n\nQueste due probabilit√† rappresentano la verosimiglianza:\n\\[\nP(\\text{Testa} \\mid \\text{Bilanciata}) = 0.5 \\quad\\text{e}\\quad P(\\text{Testa} \\mid \\text{Truccata}) = 0.8.\n\\]\nEvidenza: Probabilit√† Complessiva dell‚ÄôEvento Osservato.\nVogliamo ora sapere quanto sia probabile osservare Testa in generale, considerando entrambe le ipotesi possibili. Per calcolarlo, usiamo la probabilit√† totale, che tiene conto di tutte le possibili ipotesi:\n\\[\nP(\\text{Testa}) = P(\\text{Testa} \\mid \\text{Bilanciata}) \\times P(\\text{Bilanciata}) + P(\\text{Testa} \\mid \\text{Truccata}) \\times P(\\text{Truccata}).\n\\]\nSostituiamo i valori numerici:\n\\[\nP(\\text{Testa}) = (0.5 \\times 0.85) + (0.8 \\times 0.15) = 0.425 + 0.12 = 0.545.\n\\]\nQuesta √® la probabilit√† marginale o evidenza del risultato osservato.\nPosterior: Aggiornamento delle Credenze dopo l‚ÄôEvidenza.\nOra possiamo usare il Teorema di Bayes per aggiornare le nostre credenze iniziali alla luce dell‚Äôevento osservato (Testa):\n\\[\n\\begin{align}\nP(\\text{Bilanciata} \\mid \\text{Testa}) &= \\frac{P(\\text{Testa} \\mid \\text{Bilanciata}) \\times P(\\text{Bilanciata})}{P(\\text{Testa})}\\notag\\\\\n&= \\frac{0.5 \\times 0.85}{0.545} \\notag\\\\\n&= 0.7798 \\quad (77.98\\%).\n\\end{align} \\notag\n\\]\n\\[\n\\begin{align}\nP(\\text{Truccata} \\mid \\text{Testa}) &= \\frac{P(\\text{Testa} \\mid \\text{Truccata}) \\times P(\\text{Truccata})}{P(\\text{Testa})} \\notag\\\\\n&= \\frac{0.8 \\times 0.15}{0.545} \\notag\\\\\n&= 0.2202 \\quad (22.02\\%). \\notag\n\\end{align}\n\\]\nInterpretazione Intuitiva.\nPrima del lancio, eravamo abbastanza sicuri (85%) che la moneta fosse bilanciata. Dopo aver osservato un singolo lancio che mostra Testa, questa certezza diminuisce (passa a circa 77.98%), mentre la probabilit√† che la moneta sia truccata aumenta (passa da 15% a circa 22.02%).\nQuesto esempio mostra come il prior, la verosimiglianza e l‚Äôevidenza si combinino nel ragionamento bayesiano per produrre un aggiornamento razionale e coerente delle credenze.\n\n30.4.3 Fase 3: Secondo Lancio - Esce Testa\nSupponiamo ora di lanciare la moneta una seconda volta, osservando ancora Testa. Usiamo le nuove probabilit√† ottenute (posterior) come prior aggiornati:\n\\[\nP(\\text{Bilanciata}) = 0.7798 \\quad\\text{e}\\quad P(\\text{Truccata}) = 0.2202.\n\\]\nCalcoliamo nuovamente l‚Äôevidenza:\n\\[\nP(\\text{Testa}) = (0.5 \\times 0.7798) + (0.8 \\times 0.2202) = 0.3899 + 0.1762 = 0.5661.\n\\]\nAggiorniamo quindi le credenze con il teorema di Bayes:\n\\[\nP(\\text{Bilanciata} \\mid \\text{Testa}) = \\frac{0.5 \\times 0.7798}{0.5661} = 0.6887 \\quad (68.87\\%).\n\\]\n\\[\nP(\\text{Truccata} \\mid \\text{Testa}) = \\frac{0.8 \\times 0.2202}{0.5661} = 0.3113 \\quad (31.13\\%).\n\\]\nInterpretazione del Secondo Aggiornamento.\nDopo il secondo lancio che mostra ancora Testa, la probabilit√† che la moneta sia bilanciata scende ulteriormente da 0.7798 a 0.6887, mentre la probabilit√† che la moneta sia truccata sale a 0.3113. Questo esempio mostra come l‚Äôaggiornamento bayesiano consenta di modificare progressivamente le nostre credenze, adattandole coerentemente a ogni nuova evidenza osservata.\n\n30.4.4 Applicazioni in Psicologia\nNegli ultimi anni, i modelli bayesiani hanno acquisito un ruolo centrale nello studio della cognizione umana, fornendo una struttura formale per comprendere come il cervello costruisca rappresentazioni del mondo e prenda decisioni sulla base di dati incerti. Come discusso da Griffiths et al. (2024), questi modelli sono stati applicati a una vasta gamma di processi cognitivi, tra cui:\n\n\nApprendimento e generalizzazione: i modelli bayesiani descrivono come gli individui apprendano nuove categorie e concetti sulla base di dati limitati e rumorosi (Tenenbaum, Griffiths, & Kemp, 2006).\n\nPercezione e interpretazione sensoriale: la percezione visiva e il riconoscimento di oggetti possono essere spiegati come un‚Äôinferenza bayesiana sulla base di segnali sensoriali ambigui (Domini & Caudek, 2003; Yuille & Kersten, 2006).\n\nControllo motorio: il sistema motorio umano sembra ottimizzare i movimenti attraverso una combinazione di modelli interni e aggiornamenti bayesiani (Kording & Wolpert, 2006).\n\nMemoria e recupero delle informazioni: i processi mnemonici, come il richiamo della memoria semantica, possono essere modellati come inferenze bayesiane basate su conoscenze pregresse (Steyvers, Griffiths, & Dennis, 2006).\n\nAcquisizione del linguaggio: l‚Äôapprendimento del linguaggio nei bambini pu√≤ essere descritto attraverso processi probabilistici che permettono di inferire le strutture grammaticali sulla base di dati linguistici limitati (Chater & Manning, 2006; Xu & Tenenbaum, in press).\n\nApprendimento causale: la capacit√† di inferire relazioni causali dagli eventi osservati √® coerente con un modello bayesiano, in cui la mente valuta la probabilit√† di una relazione causale sulla base dell‚Äôevidenza disponibile (Griffiths & Tenenbaum, 2005, 2007).\n\nRagionamento e decisione: il ragionamento simbolico e il processo decisionale possono essere formalizzati come un aggiornamento bayesiano delle credenze sulla base di nuove informazioni (Oaksford & Chater, 2001).\n\nCognizione sociale: le inferenze sulle intenzioni e credenze altrui possono essere modellate attraverso processi bayesiani, permettendo di spiegare come le persone comprendano il comportamento altrui (Baker, Tenenbaum, & Saxe, 2007).\n\n30.4.5 L‚ÄôInferenza Bayesiana nella Cognizione Umana\nUn tema centrale che emerge da questi programmi di ricerca √® la seguente domanda: come fa la mente umana ad andare oltre i dati dell‚Äôesperienza? In altre parole, come riesce il cervello a costruire modelli complessi del mondo a partire da informazioni limitate e spesso ambigue?\nL‚Äôapproccio bayesiano propone che il cervello utilizzi un processo di inferenza probabilistica per aggiornare continuamente le proprie credenze, combinando informazioni pregresse con nuove osservazioni per affinare le proprie rappresentazioni mentali. Questo meccanismo consente di spiegare molte delle capacit√† cognitive umane, dall‚Äôapprendimento rapido di nuove categorie alla capacit√† di adattarsi a un ambiente mutevole, fino alla formulazione di inferenze sociali e alla presa di decisioni in condizioni di incertezza (si veda la Sezione 30.2).\nL‚Äôadozione dei modelli bayesiani nella psicologia cognitiva ha portato a una nuova comprensione della mente come sistema predittivo, in grado di formulare ipotesi probabilistiche sugli eventi futuri e di correggerle dinamicamente sulla base dell‚Äôesperienza. Questo approccio ha profonde implicazioni per lo studio del comportamento umano e per lo sviluppo di nuove tecniche di modellizzazione nei campi della psicologia, delle neuroscienze e dell‚Äôintelligenza artificiale.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_bayes_theorem.html#esempio-chi-mi-ha-mandato-un-messaggio",
    "href": "chapters/probability/06_bayes_theorem.html#esempio-chi-mi-ha-mandato-un-messaggio",
    "title": "30¬† Il teorema di Bayes",
    "section": "\n30.3 Esempio: Chi mi ha mandato un messaggio?",
    "text": "30.3 Esempio: Chi mi ha mandato un messaggio?\nImmagina di avere ricevuto un messaggio anonimo sul tuo cellulare con scritto solo ‚ÄúCi vediamo stasera!‚Äù. Vuoi capire chi pu√≤ essere stato a mandartelo. In questo esempio, il tuo ‚Äúspazio delle ipotesi‚Äù sar√† rappresentato da tre persone possibili:\n\n\nAlice\n\n\nBruno\n\nCarla\n\nQuindi, hai un insieme di ipotesi molto semplice:\n\\[\n\\mathcal{H} = \\{\\text{Alice},\\, \\text{Bruno},\\, \\text{Carla}\\} .\n\\]\n1. Probabilit√† a priori (prima di guardare i dati).\nSupponi che ciascuna persona abbia una probabilit√† diversa di scriverti:\n\n\nIpotesi\n\\(P(H)\\)\n\n\n\nAlice\n0.5\n\n\nBruno\n0.3\n\n\nCarla\n0.2\n\n\n\nQueste sono le tue probabilit√† a priori, basate sulla tua esperienza o conoscenza passata (ad esempio, Alice tende a scriverti spesso, Carla raramente).\n2. Come le ipotesi generano i dati (informazioni aggiuntive).\nOra raccogli alcune informazioni utili (i tuoi dati \\(D\\)):\n\nIl messaggio dice ‚ÄúCi vediamo stasera!‚Äù.\n\nRifletti sul fatto che ciascuna delle tre persone usa questa frase con frequenze diverse (sai, ad esempio, che Alice usa spesso frasi brevi come questa, mentre Bruno e Carla la usano meno spesso, ovvero tendono a scrivere messaggi pi√π lunghi):\n\n\n\n\n\n\nIpotesi\nProbabilit√† di inviare questa specifica frase (\\(P(D \\mid H)\\))\n\n\n\nAlice\n0.7\n\n\nBruno\n0.4\n\n\nCarla\n0.1\n\n\n\nQueste probabilit√† rappresentano il ‚Äúmeccanismo generatore dei dati‚Äù, ovvero come ciascuna persona (ipotesi) potrebbe generare proprio il messaggio che hai ricevuto.\n3. Aggiornamento delle probabilit√† a posteriori (dopo aver osservato il messaggio).\nOra applichiamo la formula di Bayes per aggiornare la nostra fiducia iniziale:\n\\[\nP(H \\mid D) = \\frac{P(D \\mid H) \\, P(H)}{P(D)} .\n\\]\nPrima calcoliamo la probabilit√† totale di ricevere quello specifico messaggio, indipendentemente da chi l‚Äôha inviato. Usiamo il teorema della probabilit√† totale:\n\\[\nP(D) = P(D\\mid\\text{Alice})P(\\text{Alice}) + P(D\\mid\\text{Bruno})P(\\text{Bruno}) + P(D\\mid\\text{Carla})P(\\text{Carla}) .\n\\]\nCio√®:\n\\[\nP(D) = (0.7 \\times 0.5) + (0.4 \\times 0.3) + (0.1 \\times 0.2)\n= 0.35 + 0.12 + 0.02\n= 0.49 .\n\\]\nOra aggiorniamo ciascuna ipotesi:\n\nAlice:\n\n\\[\nP(\\text{Alice}\\mid D) = \\frac{0.7\\times0.5}{0.49} = \\frac{0.35}{0.49} \\approx 0.714 .\n\\]\n\nBruno:\n\n\\[\nP(\\text{Bruno}\\mid D) = \\frac{0.4\\times0.3}{0.49} = \\frac{0.12}{0.49} \\approx 0.245 .\n\\]\n\nCarla:\n\n\\[\nP(\\text{Carla}\\mid D) = \\frac{0.1\\times0.2}{0.49} = \\frac{0.02}{0.49} \\approx 0.041 .\n\\]\n4. Interpretazione finale (intuizione bayesiana).\nDopo aver osservato il messaggio (‚Äúdati‚Äù), la tua fiducia si √® aggiornata rispetto alle probabilit√† iniziali:\n\n\nIpotesi\nProbabilit√† a priori\nProbabilit√† a posteriori\n\n\n\nAlice\n0.5\n0.714\n\n\nBruno\n0.3\n0.245\n\n\nCarla\n0.2\n0.041\n\n\n\nOra credi molto pi√π fortemente che sia stata Alice a scriverti.\nIn sintesi, in questo esempio semplice, lo spazio delle ipotesi era costituito da tre persone possibili. Ciascuna ipotesi poteva ‚Äúgenerare‚Äù (cio√® produrre o inviare) lo specifico messaggio che hai ricevuto con una diversa probabilit√† (‚Äúmeccanismo generatore dei dati‚Äù). Prima dei dati avevi delle credenze su chi poteva averti scritto (‚Äúprobabilit√† a priori‚Äù), poi lo specifico messaggio osservato (‚Äúi dati‚Äù) ha modificato le tue convinzioni (‚Äúprobabilit√† a posteriori‚Äù), secondo la logica della Regola di Bayes.\nQuesto esempio chiarisce intuitivamente il significato di:\n\n\nspazio delle ipotesi (le possibili spiegazioni);\n\nmeccanismo generatore dei dati (la probabilit√† con cui ciascuna ipotesi produce il dato osservato);\n\naggiornamento bayesiano (come cambia la fiducia nelle ipotesi dopo aver visto i dati).\n\n\n30.3.1 Il Processo Iterativo dell‚ÄôAggiornamento Bayesiano\nL‚Äôinferenza bayesiana √® intrinsecamente iterativa. Ogni volta che emergono nuovi dati, la distribuzione a posteriori \\(P(H \\mid D)\\) ottenuta diventa il nuovo prior per aggiornamenti successivi. Questo permette un affinamento continuo delle credenze, adattando la nostra comprensione del mondo in modo dinamico e coerente con le nuove evidenze.\n\n30.3.2 Considerazioni Pratiche\nSpesso, il calcolo diretto della probabilit√† marginale \\(P(D)\\) pu√≤ essere complesso, specialmente quando lo spazio delle ipotesi √® ampio o continuo. Per affrontare questa difficolt√†, si ricorre a metodi computazionali approssimati come il campionamento Monte Carlo o i metodi variazionali, che consentono di stimare efficacemente queste quantit√† in situazioni realistiche.\nIn sintesi, la regola di Bayes fornisce uno schema formale e razionale per integrare informazioni pregresse con nuove osservazioni. Questa capacit√† di aggiornare continuamente le nostre credenze rappresenta il cuore del ragionamento probabilistico e rende l‚Äôapproccio bayesiano uno strumento fondamentale in molte discipline scientifiche e applicazioni pratiche.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_bayes_theorem.html#sec-bayes-message",
    "href": "chapters/probability/06_bayes_theorem.html#sec-bayes-message",
    "title": "30¬† Il teorema di Bayes",
    "section": "\n30.3 Esempio: Chi mi ha mandato un messaggio?",
    "text": "30.3 Esempio: Chi mi ha mandato un messaggio?\nImmagina di avere ricevuto un messaggio anonimo sul tuo cellulare con scritto solo ‚ÄúCi vediamo stasera!‚Äù. Vuoi capire chi pu√≤ essere stato a mandartelo. In questo esempio, il tuo ‚Äúspazio delle ipotesi‚Äù sar√† rappresentato da tre persone possibili:\n\n\nAlice\n\n\nBruno\n\nCarla\n\nQuindi, hai un insieme di ipotesi molto semplice:\n\\[\n\\mathcal{H} = \\{\\text{Alice},\\, \\text{Bruno},\\, \\text{Carla}\\} .\n\\]\n1. Probabilit√† a priori (prima di guardare i dati).\nSupponi che ciascuna persona abbia una probabilit√† diversa di scriverti:\n\n\nIpotesi\n\\(P(H)\\)\n\n\n\nAlice\n0.5\n\n\nBruno\n0.3\n\n\nCarla\n0.2\n\n\n\nQueste sono le tue probabilit√† a priori, basate sulla tua esperienza o conoscenza passata (ad esempio, Alice tende a scriverti spesso, Carla raramente).\n2. Come le ipotesi generano i dati (informazioni aggiuntive).\nOra raccogli alcune informazioni utili (i tuoi dati \\(D\\)):\n\nIl messaggio dice ‚ÄúCi vediamo stasera!‚Äù.\n\nRifletti sul fatto che ciascuna delle tre persone usa questa frase con frequenze diverse (sai, ad esempio, che Alice usa spesso frasi brevi come questa, mentre Bruno e Carla la usano meno spesso, ovvero tendono a scrivere messaggi pi√π lunghi):\n\n\n\n\n\n\nIpotesi\nProbabilit√† di inviare questa specifica frase (\\(P(D \\mid H)\\))\n\n\n\nAlice\n0.7\n\n\nBruno\n0.4\n\n\nCarla\n0.1\n\n\n\nQueste probabilit√† rappresentano il ‚Äúmeccanismo generatore dei dati‚Äù, ovvero come ciascuna persona (ipotesi) potrebbe generare proprio il messaggio che hai ricevuto.\n3. Aggiornamento delle probabilit√† a posteriori (dopo aver osservato il messaggio).\nOra applichiamo la formula di Bayes per aggiornare la nostra fiducia iniziale:\n\\[\nP(H \\mid D) = \\frac{P(D \\mid H) \\, P(H)}{P(D)} .\n\\]\nPrima calcoliamo la probabilit√† totale di ricevere quello specifico messaggio, indipendentemente da chi l‚Äôha inviato. Usiamo il teorema della probabilit√† totale:\n\\[\nP(D) = P(D\\mid\\text{Alice})P(\\text{Alice}) + P(D\\mid\\text{Bruno})P(\\text{Bruno}) + P(D\\mid\\text{Carla})P(\\text{Carla}) .\n\\]\nCio√®:\n\\[\nP(D) = (0.7 \\times 0.5) + (0.4 \\times 0.3) + (0.1 \\times 0.2)\n= 0.35 + 0.12 + 0.02\n= 0.49 .\n\\]\nOra aggiorniamo ciascuna ipotesi:\n\nAlice:\n\n\\[\nP(\\text{Alice}\\mid D) = \\frac{0.7\\times0.5}{0.49} = \\frac{0.35}{0.49} \\approx 0.714 .\n\\]\n\nBruno:\n\n\\[\nP(\\text{Bruno}\\mid D) = \\frac{0.4\\times0.3}{0.49} = \\frac{0.12}{0.49} \\approx 0.245 .\n\\]\n\nCarla:\n\n\\[\nP(\\text{Carla}\\mid D) = \\frac{0.1\\times0.2}{0.49} = \\frac{0.02}{0.49} \\approx 0.041 .\n\\]\n4. Interpretazione finale (intuizione bayesiana).\nDopo aver osservato il messaggio (‚Äúdati‚Äù), la tua fiducia si √® aggiornata rispetto alle probabilit√† iniziali:\n\n\nIpotesi\nProbabilit√† a priori\nProbabilit√† a posteriori\n\n\n\nAlice\n0.5\n0.714\n\n\nBruno\n0.3\n0.245\n\n\nCarla\n0.2\n0.041\n\n\n\nOra credi molto pi√π fortemente che sia stata Alice a scriverti.\nIn sintesi, in questo esempio semplice, lo spazio delle ipotesi era costituito da tre persone possibili. Ciascuna ipotesi poteva ‚Äúgenerare‚Äù (cio√® produrre o inviare) lo specifico messaggio che hai ricevuto con una diversa probabilit√† (‚Äúmeccanismo generatore dei dati‚Äù). Prima dei dati avevi delle credenze su chi poteva averti scritto (‚Äúprobabilit√† a priori‚Äù), poi lo specifico messaggio osservato (‚Äúi dati‚Äù) ha modificato le tue convinzioni (‚Äúprobabilit√† a posteriori‚Äù), secondo la logica della Regola di Bayes.\nQuesto esempio chiarisce intuitivamente il significato di:\n\n\nspazio delle ipotesi (le possibili spiegazioni);\n\nmeccanismo generatore dei dati (la probabilit√† con cui ciascuna ipotesi produce il dato osservato);\n\naggiornamento bayesiano (come cambia la fiducia nelle ipotesi dopo aver visto i dati).\n\n\n30.3.1 Il Processo Iterativo dell‚ÄôAggiornamento Bayesiano\nL‚Äôinferenza bayesiana √® intrinsecamente iterativa. Ogni volta che emergono nuovi dati, la distribuzione a posteriori \\(P(H \\mid D)\\) ottenuta diventa il nuovo prior per aggiornamenti successivi. Questo permette un affinamento continuo delle credenze, adattando la nostra comprensione del mondo in modo dinamico e coerente con le nuove evidenze.\n\n30.3.2 Considerazioni Pratiche\nSpesso, il calcolo diretto della probabilit√† marginale \\(P(D)\\) ‚Äî corrispondente, nell‚Äôesempio illustrato nella Sezione 30.3, alla probabilit√† di osservare lo specifico messaggio ricevuto sul dispositivo mobile ‚Äî risulta computazionalmente oneroso, in particolare quando lo spazio delle ipotesi √® discreto o continuo di alta dimensionalit√†. Per ovviare a questa limitazione, vengono impiegati metodi numerici approssimativi come il Campionamento Monte Carlo o le inferenze variazionali, tecniche che permettono di stimare in modo efficiente tali grandezze probabilistiche anche in scenari reali complessi, senza ricorrere a calcoli analitici esatti.\nIn sintesi, la regola di Bayes fornisce uno schema formale e razionale per integrare informazioni pregresse con nuove osservazioni. Questa capacit√† di aggiornare continuamente le nostre credenze rappresenta il cuore del ragionamento probabilistico e rende l‚Äôapproccio bayesiano uno strumento fondamentale in molte discipline scientifiche e applicazioni pratiche.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_bayes_theorem.html#sec-bayes-rescorla-wagner",
    "href": "chapters/probability/06_bayes_theorem.html#sec-bayes-rescorla-wagner",
    "title": "30¬† Il teorema di Bayes",
    "section": "\n30.2 Il Teorema di Bayes nella Psicologia: il Modello Rescorla-Wagner come Esempio di Adattamento all‚ÄôAmbiente",
    "text": "30.2 Il Teorema di Bayes nella Psicologia: il Modello Rescorla-Wagner come Esempio di Adattamento all‚ÄôAmbiente\nPer illustrare concretamente il ruolo del teorema di Bayes in psicologia, possiamo considerare un fenomeno molto comune nella vita quotidiana: l‚Äôapprendimento associativo. Questa capacit√† permette a esseri umani e altri organismi viventi di prevedere eventi futuri sulla base delle esperienze passate, adattando continuamente il proprio comportamento a un ambiente in costante mutamento.\nUn modello psicologico particolarmente influente che formalizza questo processo √® il modello Rescorla-Wagner. Nato inizialmente per spiegare come gli animali apprendano ad associare segnali ambientali a specifiche conseguenze, questo modello si √® rivelato utile anche per comprendere l‚Äôapprendimento umano. Esso mostra chiaramente come le persone aggiornino le proprie aspettative ogni volta che si trovano davanti a nuove informazioni o situazioni inattese, evidenziando un processo continuo di adattamento alle condizioni mutevoli dell‚Äôambiente circostante.\n\n30.2.1 Il Modello Rescorla-Wagner e l‚ÄôAdattamento all‚ÄôAmbiente\nSecondo il modello Rescorla-Wagner, quando ci troviamo di fronte a situazioni nuove o imprevedibili, sviluppiamo aspettative su ci√≤ che potrebbe accadere. Se queste aspettative vengono disattese (ad esempio, ricevendo una ricompensa diversa da quella prevista), sperimentiamo quello che il modello definisce ‚Äúerrore di previsione‚Äù. Questo errore, fondamentale per l‚Äôapprendimento, funge da meccanismo chiave per aggiornare rapidamente la nostra comprensione della realt√†.\nFacciamo un esempio: immaginiamo un agente che, in un contesto in cui premere un pulsante genera solitamente una ricompensa (una moneta, una caramella, ecc.), si trovi improvvisamente a non riceverla pi√π. L‚Äôerrore di previsione generato da questa discrepanza modifica le aspettative dell‚Äôagente. Di conseguenza, nelle occasioni successive, le sue previsioni si adatteranno alla nuova realt√†, riducendo la probabilit√† attesa della ricompensa.\nIl principale vantaggio del modello Rescorla-Wagner risiede nella sua essenzialit√†: basandosi su pochi principi fondamentali, riesce a descrivere in modo efficace come gli individui regolino le proprie aspettative in risposta a cambiamenti ambientali, garantendo un adattamento rapido e dinamico.\n\n30.2.2 Una Prospettiva Bayesiana sull‚ÄôApprendimento\nAnche se il modello di Rescorla-Wagner non nasce direttamente dal teorema di Bayes, pu√≤ essere interpretato facilmente come un caso speciale di aggiornamento bayesiano. Il teorema di Bayes, infatti, descrive come dovremmo modificare razionalmente le nostre credenze alla luce di nuove evidenze. In psicologia, questa ‚Äúevidenza‚Äù pu√≤ essere pensata come la differenza tra ci√≤ che ci aspettavamo e ci√≤ che realmente accade‚Äîproprio come fa il modello Rescorla-Wagner.\nNella prospettiva bayesiana, le aspettative di una persona vengono considerate come ‚Äúcredenze‚Äù che vengono aggiornate costantemente sulla base delle nuove informazioni che emergono. Ogni volta che riceviamo un‚Äôinformazione che contraddice le nostre aspettative iniziali, la nostra credenza viene rivista. Questo processo bayesiano permette di adattarsi in modo ottimale alle situazioni nuove o incerte, proprio come avviene con il modello Rescorla-Wagner (si veda l‚Äôesempio presentato nella Sezione 30.4).\nIn sintesi, il modello Rescorla-Wagner non solo rappresenta efficacemente come avviene l‚Äôapprendimento associativo nella vita quotidiana, ma fornisce anche un esempio pratico e intuitivo del ruolo del teorema di Bayes in psicologia: aiuta a capire come la nostra mente sia continuamente impegnata ad adattarsi razionalmente e rapidamente ai cambiamenti di un ambiente imprevedibile.\n\n30.2.3 Una Rivoluzione nel Pensiero Probabilistico\nPer comprendere appieno il teorema di Bayes, √® necessario delineare le sue origini storiche. Nel XVIII secolo, Thomas Bayes (1701-1761), ecclesiastico presbiteriano e matematico britannico, pose le basi di una rivoluzione concettuale nel campo della probabilit√† e della statistica. Il suo contributo teorico, passato alla storia come teorema di Bayes, ha plasmato in modo decisivo lo sviluppo scientifico e tecnologico dei secoli successivi, influenzando discipline che spaziano dalla medicina all‚Äôintelligenza artificiale (Chivers, 2024).\n\n30.2.4 La Figura di Thomas Bayes\nBayes proveniva da una famiglia benestante e studi√≤ teologia a Edimburgo, preparandosi al ministero religioso. Come ricorda il biografo David Bellhouse, Bayes non era un accademico nel senso moderno del termine, ma un erudito libero, interessato alla conoscenza per passione personale (Bellhouse, 2004).\nDurante la sua vita, Bayes pubblic√≤ due testi:\n\n\nUn trattato di teologia: Divine Benevolence: Or, an Attempt to Prove that the Principal End of the Divine Providence and Government is the Happiness of His Creatures (1731), una teodicea che cerca di spiegare come la legge naturale possa ottimizzare il benessere universale.\n\n\nUna difesa del calcolo infinitesimale: An Introduction to the Doctrine of Fluxions (1736), in risposta alle critiche di George Berkeley sugli infinitesimi e i concetti fondamentali del calcolo newtoniano (Jesseph, 1993).\n\nIl lavoro che segn√≤ la svolta nella teoria della probabilit√† fu per√≤ pubblicato postumo, nel 1763, sulle Philosophical Transactions of the Royal Society: An Essay towards Solving a Problem in the Doctrine of Chances. Per la prima volta, si formalizzava un metodo per aggiornare le ipotesi probabilistiche alla luce di nuove evidenze, ponendo le fondamenta dell‚Äôinferenza bayesiana (Stigler, 1990).\n\n30.2.5 Bayes e il Ruolo Culturale della Scienza\nCome sottolinea ancora Bellhouse, nel XVIII secolo era comune, tra le √©lite colte, dedicarsi allo studio di discipline scientifiche per prestigio sociale. Per Bayes, la matematica era dunque una passione coltivata con spirito libero. Il suo merito straordinario fu di spingere l‚Äôinterpretazione della probabilit√† verso una prospettiva epistemologica innovativa, dove la probabilit√† diventa espressione quantitativa della nostra ignoranza sul mondo.\nIn contrapposizione alla visione ‚Äúclassica‚Äù, che vedeva la probabilit√† come frequenza osservabile in eventi ripetuti, Bayes propose che essa potesse rappresentare il grado di fiducia di un osservatore, inevitabilmente influenzato da conoscenze pregresse e da pregiudizi individuali. In questo senso, la probabilit√† assume un carattere dinamico e soggettivo, configurandosi come uno strumento di conoscenza che si aggiorna di continuo al variare dei dati (Spiegelhalter, 2019).\n\n30.2.5.1 Un Esperimento Mentale Illuminante\nPer illustrare la sua idea, Bayes propose un semplice esempio: immagina di lanciare alcune palline su un tavolo da biliardo. Dopo aver segnato con una linea il punto in cui si ferma una pallina bianca (e averla poi rimossa), si lanciano altre palline rosse e si conta quante cadono a destra e quante a sinistra di quella linea. Sulla base di queste osservazioni, come si pu√≤ ‚Äúindovinare‚Äù la posizione della linea? E con quale probabilit√† la prossima pallina rossa cadr√† a sinistra di essa?\nLa soluzione di Bayes combina i dati osservati (numero di palline cadute a sinistra o a destra) con le convinzioni iniziali dell‚Äôosservatore (il cosiddetto ‚Äúprior‚Äù), delineando un processo di apprendimento graduale che guida la revisione critica delle ipotesi.\n\n30.2.6 Il Ruolo di Richard Price\nDopo la morte di Bayes, fu un altro ecclesiastico, Richard Price (1723-1791), a dare impulso alla diffusione del saggio bayesiano. Price aveva un‚Äôottima reputazione negli ambienti intellettuali dell‚Äôepoca, grazie anche alle sue relazioni con figure di spicco come Benjamin Franklin, Thomas Jefferson e John Adams.\nPrice prese in carico il manoscritto di Bayes, lo sottopose al fisico John Canton e ne cur√≤ la pubblicazione postuma, operando modifiche significative. Rispetto alla versione originale di Bayes, concentrata quasi esclusivamente sugli aspetti teorici, Price aggiunse una parte dedicata alle applicazioni pratiche, rendendo il testo pi√π fruibile a un pubblico pi√π ampio. Per questo motivo, lo storico Stephen Stigler lo definisce ¬´il primo bayesiano della storia¬ª.\n\n30.2.7 Dal Silenzio alla Riscoperta\nPer oltre cinquant‚Äôanni, il lavoro di Bayes rimase in ombra, oscurato dall‚Äôopera pionieristica di Pierre-Simon Laplace. Gi√† nel 1774, Laplace pervenne indipendentemente a principi analoghi, e successivamente li sistematizz√≤ nella monumentale Th√©orie analytique des probabilit√©s (1812). Solo in tempi pi√π recenti, con l‚Äôavvento dei metodi di calcolo moderno e dell‚Äôinformatica, la statura del teorema di Bayes √® emersa in tutta la sua importanza.\nOggi, il teorema di Bayes √® considerato un cardine della statistica moderna: formalizza il modo in cui aggiorniamo le nostre credenze alla luce di nuovi dati. Questo schema √® cruciale in ogni disciplina scientifica e tecnologica che debba fare i conti con incertezza e dati incompleti. Dalla genomica all‚Äôeconometria, dalla fisica delle particelle alle scienze cognitive, il paradigma bayesiano risulta prezioso per gestire e interpretare informazioni in continuo aggiornamento.\n\n30.2.8 L‚ÄôEredit√† di Bayes nell‚ÄôEra Digitale\nNell‚Äôintelligenza artificiale, le idee bayesiane sono alla base di sistemi di apprendimento automatico e modelli probabilistici complessi. Strumenti come i moderni modelli linguistici (ad esempio ChatGPT e Claude) sfruttano strategie di inferenza bayesiana ‚Äì anche se in forme estremamente avanzate ‚Äì per generare risposte, fare previsioni e adattarsi costantemente agli input degli utenti.\nLa parabola storica di questo teorema, nato dalle speculazioni di un pastore presbiteriano del Settecento, mostra chiaramente il potenziale trasformativo delle idee matematiche. Come sottolinea Tom Chivers nel suo Everything Is Predictable: How Bayesian Statistics Explain Our World, la statistica bayesiana √® diventata una sorta di ‚Äúgrammatica universale‚Äù per interpretare la realt√†, permettendoci di affrontare con metodo situazioni complesse, modellare l‚Äôincertezza e formulare previsioni in contesti dove l‚Äôinformazione √® inevitabilmente limitata (Chivers, 2024).\nIn sintesi, la forza del teorema di Bayes non risiede soltanto nella sua eleganza formale, ma soprattutto nella sua portata epistemologica: esso traduce in termini matematici la nostra naturale tendenza ad apprendere da ci√≤ che osserviamo e a rivedere continuamente ci√≤ che crediamo. Per questo rimane, ancora oggi, un punto di riferimento fondamentale in qualunque disciplina che affronti il problema della conoscenza in condizioni di incertezza. ## La Regola di Bayes e l‚Äôinferenza probabilistica\nL‚Äôinferenza bayesiana utilizza un principio centrale della teoria delle probabilit√† noto come regola di Bayes. Questo principio consente di aggiornare in modo razionale le nostre credenze sulla base di nuovi dati osservati, integrandoli con conoscenze pregresse.\n\n30.2.9 Derivazione della Regola di Bayes\nConsideriamo due eventi casuali, \\(A\\) e \\(B\\). La probabilit√† congiunta \\(P(A, B)\\), ossia la probabilit√† che entrambi gli eventi accadano simultaneamente, pu√≤ essere espressa in due modi equivalenti:\n\nTramite la regola della catena, possiamo scrivere: \\[\nP(A, B) = P(A \\mid B)P(B).\n\\] Qui, \\(P(A \\mid B)\\) √® la probabilit√† condizionata che si verifichi l‚Äôevento \\(A\\) sapendo che l‚Äôevento \\(B\\) √® avvenuto, mentre \\(P(B)\\) √® la probabilit√† marginale di \\(B\\), indipendente da \\(A\\).\nUtilizzando la simmetria della probabilit√† congiunta, possiamo invertire gli eventi: \\[\nP(A, B) = P(B \\mid A)P(A).\n\\]\n\nDato che entrambe le espressioni rappresentano la stessa probabilit√† congiunta, possiamo eguagliarle:\n\\[\nP(A \\mid B)P(B) = P(B \\mid A)P(A).\n\\]\nRisolvendo per \\(P(B \\mid A)\\) otteniamo la regola di Bayes:\n\\[\nP(B \\mid A) = \\frac{P(A \\mid B) P(B)}{P(A)}.\n\\tag{30.1}\\]\n\n30.2.10 Interpretazione dei termini della regola di Bayes\nLa regola di Bayes permette di aggiornare la nostra credenza sulla probabilit√† di un‚Äôipotesi o evento (\\(B\\)), dopo aver osservato un dato o evidenza (\\(A\\)):\n\n\n\\(P(B)\\) (prior): √® la probabilit√† iniziale assegnata all‚Äôevento \\(B\\) prima di osservare il dato \\(A\\). Rappresenta la nostra conoscenza pregressa o il nostro grado iniziale di fiducia.\n\n\\(P(A \\mid B)\\) (verosimiglianza): √® la probabilit√† di osservare il dato \\(A\\) nell‚Äôipotesi che \\(B\\) sia vero. Indica quanto il dato sia compatibile con l‚Äôipotesi.\n\n\\(P(B \\mid A)\\) (posterior): √® la probabilit√† aggiornata, cio√® la nostra nuova credenza sull‚Äôevento \\(B\\) dopo aver osservato il dato \\(A\\).\n\n\\(P(A)\\) (evidenza): √® la probabilit√† marginale del dato osservato, calcolata sommando o integrando su tutte le possibili ipotesi alternative che potrebbero aver generato tale dato. Agisce da termine di normalizzazione per garantire che la somma delle probabilit√† a posteriori sia uguale a 1.\n\n30.2.11 Applicazioni della Regola di Bayes\nNella pratica, l‚Äôinferenza bayesiana si svolge tipicamente nel seguente modo:\n\nSi parte da uno spazio delle ipotesi \\(\\mathcal{H}\\), ovvero un insieme di tutte le possibili spiegazioni o modelli che potrebbero aver generato i dati osservati \\(D\\).\nA ciascuna ipotesi \\(H \\in \\mathcal{H}\\) viene assegnata una probabilit√† a priori \\(P(H)\\) che riflette la nostra fiducia iniziale.\nUna volta raccolti i dati \\(D\\), aggiorniamo le probabilit√† delle ipotesi usando la formula:\n\n\\[\nP(H \\mid D) = \\frac{P(D \\mid H) \\, P(H)}{P(D)},\n\\tag{30.2}\\]\ndove:\n\n\n\\(P(D \\mid H)\\) √® la verosimiglianza, cio√® la probabilit√† che l‚Äôipotesi \\(H\\) abbia generato i dati \\(D\\);\n\n\\(P(D)\\) √® la probabilit√† marginale (evidenza), calcolata considerando tutte le possibili ipotesi:\n\n\\[\nP(D) = \\sum_{H' \\in \\mathcal{H}} P(D \\mid H')P(H'),\n\\]\nnel caso discreto, oppure:\n\\[\nP(D) = \\int_{\\mathcal{H}} P(D \\mid H')P(H') \\, dH',\n\\]\nnel caso continuo.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_random_var.html#riflessioni-conclusive",
    "href": "chapters/probability/07_random_var.html#riflessioni-conclusive",
    "title": "31¬† Variabili casuali",
    "section": "\n31.9 Riflessioni Conclusive",
    "text": "31.9 Riflessioni Conclusive\nIn questo capitolo abbiamo introdotto e approfondito il concetto fondamentale di variabile casuale, illustrando come questo strumento permetta di formalizzare e analizzare matematicamente fenomeni casuali complessi. Attraverso esempi intuitivi, come il lancio di dadi o la simulazione di situazioni reali, abbiamo osservato come le variabili casuali consentano di tradurre domande astratte in analisi concrete e interpretabili.\nAbbiamo esaminato le due principali tipologie di variabili casuali‚Äîdiscrete e continue‚Äîe discusso le relative distribuzioni di probabilit√†. Le distribuzioni discrete, caratterizzate da una funzione di massa di probabilit√† (PMF), si prestano particolarmente bene a modellare situazioni in cui gli eventi possono essere enumerati (come punteggi in test psicologici o risultati di giochi). Al contrario, le distribuzioni continue, descritte dalla funzione di densit√† di probabilit√† (PDF), sono essenziali per modellare misure precise, come l‚Äôaltezza o il tempo, dove il numero di possibili valori √® teoricamente infinito.\nUn aspetto importante trattato √® la funzione di distribuzione cumulativa (CDF), che fornisce una descrizione completa della distribuzione di una variabile casuale, facilitando la comprensione intuitiva della probabilit√† che un evento accada entro certi limiti. Conoscere le propriet√† della CDF aiuta a prevenire errori comuni nella sua interpretazione e a trarre conclusioni pi√π affidabili dai dati empirici.\nInfine, attraverso l‚Äôutilizzo della simulazione, abbiamo mostrato come sia possibile avvicinarsi empiricamente a una distribuzione teorica, confermando e visualizzando in modo pratico e immediato concetti astratti. Questa capacit√† di simulare e verificare empiricamente le distribuzioni √® estremamente utile, soprattutto quando i modelli teorici diventano troppo complessi da risolvere analiticamente.\nNei prossimi capitoli approfondiremo ulteriormente questi concetti, esaminando alcune distribuzioni di probabilit√† specifiche che sono comunemente usate nella ricerca psicologica e nelle applicazioni pratiche. Questo ci permetter√† di passare da una conoscenza teorica delle variabili casuali a una competenza concreta nel loro utilizzo e nella loro interpretazione, sviluppando strumenti che miglioreranno le nostre capacit√† di analisi e di decisione in ambito psicologico e statistico.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_expval_var.html#applicazioni",
    "href": "chapters/probability/09_expval_var.html#applicazioni",
    "title": "33¬† Propriet√† delle variabili casuali",
    "section": "\n33.10 Applicazioni",
    "text": "33.10 Applicazioni\nUn esempio psicologico per illustrare questo concetto √® il riconoscimento della memoria episodica, in particolare il fenomeno delle risposte ‚ÄúRemember-Know‚Äù in compiti di riconoscimento. Questo fenomeno √® misurato tramite una variabile discreta ed esistono almeno due modelli teorici che fanno previsioni diverse sulla distribuzione di probabilit√† delle risposte osservate.\nIniziamo a descrivere il compito sperimentale del paradigma ‚ÄúRemember-Know‚Äù. In un compito di memoria episodica, ai partecipanti viene mostrata una lista di parole o immagini. Dopo un intervallo di tempo, gli stessi soggetti vedono una nuova lista composta da alcuni elementi gi√† visti (old) e alcuni nuovi (new). Per ogni elemento ‚Äúold‚Äù riconosciuto correttamente, ai partecipanti viene chiesto di dichiarare se:\n\n\nRemember (R): l‚Äôelemento viene riconosciuto con dettagli vividi e specifici del contesto originale (ricordo consapevole).\n\nKnow (K): l‚Äôelemento viene riconosciuto senza dettagli specifici del contesto originale (familiarit√† senza ricordo esplicito).\n\nAbbiamo quindi una variabile discreta categorica con 3 possibili esiti in risposta a stimoli ‚Äúold‚Äù:\n\n‚ÄúRemember‚Äù\n‚ÄúKnow‚Äù\n‚ÄúMiss‚Äù (non riconosciuto)\n\nPer spiegare il comportamento dei soggetti in questo compito, sono state proposte due teorie concorrenti.\nTeoria a singolo processo (Strength Theory) (e.g., Wixted & Mickes, 2010):\n\nesiste un unico continuum di forza della traccia mnemonica;\nle risposte ‚ÄúRemember‚Äù sono risposte che superano un‚Äôalta soglia di forza, mentre ‚ÄúKnow‚Äù sono risposte che superano una soglia inferiore, senza alcuna differenza qualitativa tra R e K.\n\nIn questa teoria, la distribuzione delle risposte R/K dipende esclusivamente dalla forza della traccia (una singola variabile latente continua). La predizione tipica √® una certa distribazione di probabilit√†, spesso con prevalenza di risposte ‚ÄúKnow‚Äù e una certa proporzione (generalmente pi√π bassa) di risposte ‚ÄúRemember‚Äù, che varia in modo continuo al variare della forza mnemonica.\nTeoria dual-process  (e.g., Yonelinas, 2002):\n\nesistono due processi qualitativamente distinti:\n\n\nrecollection (ricordo consapevole, corrispondente alle risposte ‚ÄúRemember‚Äù), un processo qualitativo, che o avviene o non avviene (binario);\n\nfamiliarit√† (risposte ‚ÄúKnow‚Äù), un processo continuo indipendente.\n\n\n\nLa predizione di questa teoria √® che la distribuzione delle risposte R/K sia data da una miscela di due distribuzioni discrete separate:\n\nuna distribuzione ‚Äúbinaria‚Äù per il processo di ‚ÄúRemember‚Äù;\nuna distribuzione separata continua o discreta per la ‚Äúfamiliarit√†‚Äù (‚ÄúKnow‚Äù).\n\nQuesta teoria produce una distribuzione con una separazione pi√π netta tra le risposte R e K, con una specifica struttura diversa rispetto alla teoria del singolo processo.\nPredizioni sulle distribuzioni di probabilit√†.\nImmaginiamo che in un particolare esperimento siano mostrate 100 parole ‚Äúold‚Äù e che due modelli (singolo vs dual-process) prevedano diverse distribuzioni discrete delle risposte R/K/Miss:\n\n\n\n\n\n\n\nRisposte\nModello Single-Process (Forza continua)\nModello Dual-Process (Recollection separata)\n\n\n\nRemember\n25%\n40%\n\n\nKnow\n60%\n40%\n\n\nMiss\n15%\n20%\n\n\n\nCalcolo del valore atteso e varianza per le distribuzioni teoriche.\nPer calcolare valore atteso e varianza, trasformiamo le categorie in punteggi numerici (scelta didattica): Remember=2, Know=1, Miss=0).\n\n\nModello Single-Process:\n\n\\[\nE(X) = 2 \\cdot 0.25 + 1 \\cdot 0.60 + 0 \\cdot 0.15 = 1.10 .\n\\]\n\\[\n\\begin{align}\nVar(X) &= (2-1.10)^2 \\cdot 0.25 + (1-1.10)^2 \\cdot 0.60 + (0-1.10)^2 \\cdot 0.15 \\notag\\\\\n&= 0.2025 + 0.006 + 0.1815 = 0.39 .\n\\end{align}\n\\]\n\n\nModello Dual-Process:\n\n\\[\nE(X) = 2 \\cdot 0.40 + 1 \\cdot 0.40 + 0 \\cdot 0.20 = 1.20 .\n\\]\n\\[\n\\begin{align}\nVar(X) &= (2-1.20)^2 \\cdot 0.40 + (1-1.20)^2 \\cdot 0.40 + (0-1.20)^2 \\cdot 0.20 \\notag\\\\\n&= 0.256 + 0.016 + 0.288 = 0.56 .\n\\end{align}\n\\]\nQuindi abbiamo:\n\n\nModello\nValore Atteso\nVarianza\n\n\n\nSingle-process\n1.10\n0.39\n\n\nDual-process\n1.20\n0.56\n\n\n\nConfronto con i dati reali.\nSe misurassimo realmente le risposte di un gruppo di partecipanti (ad esempio pazienti con lievi deficit cognitivi vs.¬†controlli sani), potremmo confrontare il valore atteso e la varianza empirici con le predizioni teoriche dei due modelli.\nPer esempio, dati empirici osservati potrebbero essere:\n\n\nRisposte osservate\n% osservata\n\n\n\nRemember\n38%\n\n\nKnow\n42%\n\n\nMiss\n20%\n\n\n\nValore atteso empirico:\n\\[\nE(X) = 2 \\cdot 0.38 + 1 \\cdot 0.42 + 0 \\cdot 0.20 = 1.18 .\n\\]\nVarianza empirica:\n\\[\n\\begin{align}\nVar(X) &= (2-1.18)^2 \\cdot 0.38 + (1-1.18)^2 \\cdot 0.42 + (0-1.18)^2 \\cdot 0.20 \\notag\\\\\n&= 0.255 + 0.014 + 0.278 = 0.547 .\n\\end{align}\n\\]\n\n\nDati empirici\nValore Atteso\nVarianza\n\n\nOsservati\n1.18\n0.55\n\n\nQuesti dati reali risulterebbero pi√π vicini alle predizioni del modello dual-process.\nInterpretazione.\nQuesto esempio illustra i seguenti punti:\n\nle teorie psicologiche hanno implicazioni dirette sulla distribuzione di probabilit√† delle risposte discrete;\nvalore atteso e varianza sono propriet√† utili per confrontare in modo quantitativo predizioni teoriche diverse con dati empirici reali;\nquesto processo consente agli psicologi sperimentali e clinici di discriminare tra modelli teorici alternativi.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_expval_var.html#applicazioni-psicologiche-del-valore-atteso-e-della-varianza",
    "href": "chapters/probability/09_expval_var.html#applicazioni-psicologiche-del-valore-atteso-e-della-varianza",
    "title": "33¬† Propriet√† delle variabili casuali",
    "section": "\n33.10 Applicazioni Psicologiche del Valore Atteso e della Varianza",
    "text": "33.10 Applicazioni Psicologiche del Valore Atteso e della Varianza\nUn esempio pratico dell‚Äôuso del valore atteso e della varianza in psicologia √® rappresentato dagli studi sulla memoria episodica, in particolare attraverso il paradigma sperimentale delle risposte ‚ÄúRemember-Know‚Äù. Questo paradigma permette di esplorare come le persone riconoscano eventi passati, distinguendo tra ricordi dettagliati e semplici sensazioni di familiarit√†.\nIl Paradigma ‚ÄúRemember-Know‚Äù\nIn un tipico esperimento di memoria episodica:\n\nAi partecipanti viene presentata una lista di stimoli (es. parole o immagini).\nDopo un intervallo di tempo, viene mostrata una nuova lista contenente elementi precedentemente visti (old) e elementi nuovi (new).\n\nPer ogni stimolo old riconosciuto, i soggetti devono specificare se:\n\n\nRemember (R): Ricordano consapevolmente dettagli contestuali dell‚Äôepisodio di encoding (es. ‚ÄúRicordo che questa parola era scritta in rosso‚Äù).\n\nKnow (K): Avvertono familiarit√† con lo stimolo, ma senza accesso a dettagli specifici (es. ‚ÄúSembra conosciuto, ma non so perch√©‚Äù).\n\n\nMiss: Non riconoscono lo stimolo.\n\n\n\nLa variabile in gioco √® quindi categorica e discreta, con tre possibili esiti per gli stimoli old: {R, K, Miss}.\nModelli Teorici e Previsioni Statistiche\nDue importanti teorie cercano di spiegare come avviene questo riconoscimento:\n1. Teoria del Processo Unico (Strength Theory) (e.g., Wixted & Mickes, 2010)\n\n\nIpotesi centrale:\nC‚Äô√® una sola dimensione continua (la ‚Äúforza mnemonica‚Äù) che determina il tipo di risposta.\n\nLe risposte Remember derivano da tracce molto forti, quelle Know da tracce di forza intermedia, e i Miss da tracce troppo deboli.\n\n\n\nImplicazioni statistiche: molte risposte Know, meno risposte Remember, bassa varianza.\n\n2. Teoria del Doppio Processo (Dual-Process) (e.g., Yonelinas, 2002)\n\n\nIpotesi centrale:\nCi sono due processi indipendenti:\n\n\nRecollection (R): Processo qualitativo e binario (presente/assente), legato al ricordo consapevole di dettagli contestuali.\n\n\nFamiliarit√† (K): Processo continuo, basato su una sensazione generica di familiarit√†.\n\n\n\nImplicazioni statistiche: numero simile di risposte Remember e Know, alta varianza.\n\nQui entrano in gioco i concetti statistici: ogni teoria formula previsioni diverse sul valore atteso (es. proporzione attesa di risposte R o K) e sulla varianza (dispersione dei dati attorno a questi valori). Confrontando le osservazioni sperimentali con le aspettative teoriche, √® possibile testare quale modello sia pi√π coerente con i dati empirici, illustrando come strumenti probabilistici possano chiarire meccanismi cognitivi complessi.\n3. Confronto Statistico: Previsioni Teoriche\nImmaginiamo che in un particolare esperimento siano mostrate 100 parole ‚Äúold‚Äù e che due modelli (singolo vs dual-process) prevedano diverse distribuzioni discrete delle risposte R/K/Miss.\nPer confrontare quantitativamente i modelli, assegniamo i seguenti punteggi numerici alle categorie: Remember = 2, Know = 1, Miss = 0.\nModello Single-Process\nSenza entrare nei dettagli tecnici, per questo esperimento il modello Single-Process predice la seguente distribuzione attesa:\n\n\nR\nK\nMiss\n\n\n25%\n60%\n15%\n\n\nCalcoliamo dunque il valore atteso e la varianza:\n\\[\n  E(X) = 2 \\cdot 0.25 + 1 \\cdot 0.60 + 0 \\cdot 0.15 = 1.10\n  \\]\n\\[\n  Var(X) = (2-1.10)^2 \\cdot 0.25 + (1-1.10)^2 \\cdot 0.60 + (0-1.10)^2 \\cdot 0.15 = 0.39\n  \\]\nModello Dual-Process\nPer lo stesso esperimento, il modello Dual-Process predice la seguente distribuzione attesa:\n\n\nR\nK\nMiss\n\n\n40%\n40%\n20%\n\n\nIn questo caso, il valore atteso e la varianza sono:\n\\[\n  E(X) = 2 \\cdot 0.40 + 1 \\cdot 0.40 + 0 \\cdot 0.20 = 1.20\n  \\]\n\\[\n  Var(X) = (2-1.20)^2 \\cdot 0.40 + (1-1.20)^2 \\cdot 0.40 + (0-1.20)^2 \\cdot 0.20 = 0.56\n  \\]\nSintesi delle Previsioni\n\n\nModello\nValore Atteso\nVarianza\n\n\n\nSingle-Process\n1.10\n0.39\n\n\nDual-Process\n1.20\n0.56\n\n\n\n4. Applicazione a Dati Empirici\nSupponiamo ora di aver raccolto dati reali da 100 soggetti che hanno prodotto questa distribuzione:\n\n\nR\nK\nMiss\n\n\n38%\n42%\n20%\n\n\nCalcoliamo il valore atteso e la varianza empiriche:\n\\[\n  E(X) = 2 \\cdot 0.38 + 1 \\cdot 0.42 + 0 \\cdot 0.20 = 1.18\n  \\]\n\\[\n  Var(X) = (2-1.18)^2 \\cdot 0.38 + (1-1.18)^2 \\cdot 0.42 + (0-1.18)^2 \\cdot 0.20 = 0.55\n  \\]\nRisultati:\n\n\nDati\nValore Atteso\nVarianza\n\n\nEmpirici\n1.18\n0.55\n\n\nConfrontando questi risultati con le previsioni teoriche, notiamo che i dati empirici si avvicinano molto pi√π al modello dual-process (valore atteso: 1.20 vs.¬†1.18; varianza: 0.56 vs.¬†0.55).\n5. Implicazioni Psicologiche e Cliniche\n\nTeoriche: Il confronto tra distribuzioni osservate e teoriche, usando valore atteso e varianza, consente di identificare quale teoria cognitiva spieghi meglio i dati.\nCliniche: In contesti clinici (es. valutazione di deficit cognitivi), questo approccio consente di identificare se un paziente mostra un profilo riconducibile a un danno selettivo della recollection (R ‚Üì) o della familiarit√† (K ‚Üì).\n\nQuesto framework illustra come strumenti probabilistici di base possano tradurre ipotesi psicologiche complesse in predizioni quantitative verificabili, avanzando la comprensione dei meccanismi cognitivi.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_expval_var.html#applicazioni-psicologiche",
    "href": "chapters/probability/09_expval_var.html#applicazioni-psicologiche",
    "title": "33¬† Propriet√† delle variabili casuali",
    "section": "\n33.10 Applicazioni Psicologiche",
    "text": "33.10 Applicazioni Psicologiche\nUn esempio pratico dell‚Äôuso del valore atteso e della varianza in psicologia √® rappresentato dagli studi sulla memoria episodica, in particolare attraverso il paradigma sperimentale delle risposte ‚ÄúRemember-Know‚Äù. Questo paradigma permette di esplorare come le persone riconoscano eventi passati, distinguendo tra ricordi dettagliati e semplici sensazioni di familiarit√†.\nIl Paradigma ‚ÄúRemember-Know‚Äù\nIn un tipico esperimento di memoria episodica:\n\nAi partecipanti viene presentata una lista di stimoli (es. parole o immagini).\nDopo un intervallo di tempo, viene mostrata una nuova lista contenente elementi precedentemente visti (old) e elementi nuovi (new).\n\nPer ogni stimolo old riconosciuto, i soggetti devono specificare se:\n\n\nRemember (R): Ricordano consapevolmente dettagli contestuali dell‚Äôepisodio di encoding (es. ‚ÄúRicordo che questa parola era scritta in rosso‚Äù).\n\nKnow (K): Avvertono familiarit√† con lo stimolo, ma senza accesso a dettagli specifici (es. ‚ÄúSembra conosciuto, ma non so perch√©‚Äù).\n\n\nMiss: Non riconoscono lo stimolo.\n\n\n\nLa variabile in gioco √® quindi categorica e discreta, con tre possibili esiti per gli stimoli old: {R, K, Miss}.\nModelli Teorici e Previsioni Statistiche\nDue importanti teorie cercano di spiegare come avviene questo riconoscimento:\nTeoria del Processo Unico (Strength Theory) (e.g., Wixted & Mickes, 2010)\n\n\nIpotesi centrale:\nC‚Äô√® una sola dimensione continua (la ‚Äúforza mnemonica‚Äù) che determina il tipo di risposta.\n\nLe risposte Remember derivano da tracce molto forti, quelle Know da tracce di forza intermedia, e i Miss da tracce troppo deboli.\n\n\n\nImplicazioni statistiche: molte risposte Know, meno risposte Remember, bassa varianza.\n\nTeoria del Doppio Processo (Dual-Process) (e.g., Yonelinas, 2002)\n\n\nIpotesi centrale:\nCi sono due processi indipendenti:\n\n\nRecollection (R): Processo qualitativo e binario (presente/assente), legato al ricordo consapevole di dettagli contestuali.\n\n\nFamiliarit√† (K): Processo continuo, basato su una sensazione generica di familiarit√†.\n\n\n\nImplicazioni statistiche: numero simile di risposte Remember e Know, alta varianza.\n\nQui entrano in gioco i concetti statistici: ogni teoria formula previsioni diverse sul valore atteso (es. proporzione attesa di risposte R o K) e sulla varianza (dispersione dei dati attorno a questi valori). Confrontando le osservazioni sperimentali con le aspettative teoriche, √® possibile testare quale modello sia pi√π coerente con i dati empirici, illustrando come strumenti probabilistici possano chiarire meccanismi cognitivi complessi.\nConfronto Statistico: Previsioni Teoriche\nPer confrontare quantitativamente le previsioni dei due modelli, consideriamo un esperimento ipotetico con 100 stimoli old. Assegniamo punteggi numerici alle categorie di risposta per trasformarle in una variabile discreta, facilitando il calcolo di valore atteso e varianza:\n\n\nRemember (R) = 2\n\n\nKnow (K) = 1\n\nMiss = 0\n\nQuesta codifica riflette l‚Äôintensit√† mnemonica associata a ciascuna risposta, permettendo di quantificare le differenze teoriche tra i modelli.\n1. Modello Single-Process (Forza continua)\nSecondo questa teoria, la distribuzione attesa delle risposte √®:\n\n\nCategoria\nR\nK\nMiss\n\n\n% Prevista\n25%\n60%\n15%\n\n\nCalcoli statistici:\n- Valore atteso (media ponderata):\\[\n  E(X) = (2 \\cdot 0.25) + (1 \\cdot 0.60) + (0 \\cdot 0.15) = 1.10\n  \\]\n- Varianza (dispersione attorno alla media):\\[\n  \\begin{align}\n  Var(X) &= (2-1.10)^2 \\cdot 0.25 + (1-1.10)^2 \\cdot 0.60 + (0-1.10)^2 \\cdot 0.15 \\\\\n  &= 0.2025 + 0.006 + 0.1815 = 0.39\n  \\end{align}\n  \\]\n2. Modello Dual-Process (Recollection e Familiarit√†)\nLa teoria prevede una distribuzione basata su due meccanismi indipendenti:\n\n\nCategoria\nR\nK\nMiss\n\n\n% Prevista\n40%\n40%\n20%\n\n\nCalcoli statistici:\n- Valore atteso:\\[\n  E(X) = (2 \\cdot 0.40) + (1 \\cdot 0.40) + (0 \\cdot 0.20) = 1.20\n  \\]\n- Varianza:\\[\n  \\begin{align}\n  Var(X) &= (2-1.20)^2 \\cdot 0.40 + (1-1.20)^2 \\cdot 0.40 + (0-1.20)^2 \\cdot 0.20 \\\\\n  &= 0.256 + 0.016 + 0.288 = 0.56\n  \\end{align}\n  \\]\n\nSintesi del Confronto\nI due modelli generano previsioni distinte, riassunte nella tabella seguente:\n\n\n\n\n\n\n\n\nModello\nValore Atteso\nVarianza\nInterpretazione\n\n\n\nSingle-Process\n1.10\n0.39\nMedia pi√π bassa, varianza ridotta (distribuzione concentrata attorno a K).\n\n\nDual-Process\n1.20\n0.56\nMedia pi√π alta, varianza elevata (effetto della miscela tra due processi).\n\n\n\n\n\nValore atteso: Il modello dual-process predice una media superiore, coerente con la maggiore proporzione attesa di risposte Remember.\n\n\nVarianza: La differenza nella dispersione (0.39 vs.¬†0.56) riflette l‚Äôeterogeneit√† introdotta dalla separazione tra recollection e familiarit√† nel modello duale.\n\nApplicazione a Dati Empirici\nSupponiamo ora di aver raccolto dati reali da 100 soggetti che hanno prodotto questa distribuzione:\n\n\nR\nK\nMiss\n\n\n38%\n42%\n20%\n\n\nCalcoliamo il valore atteso e la varianza empiriche:\n\\[\n  E(X) = 2 \\cdot 0.38 + 1 \\cdot 0.42 + 0 \\cdot 0.20 = 1.18\n  \\]\n\\[\n  Var(X) = (2-1.18)^2 \\cdot 0.38 + (1-1.18)^2 \\cdot 0.42 + (0-1.18)^2 \\cdot 0.20 = 0.55\n  \\]\nRisultati:\n\n\nDati\nValore Atteso\nVarianza\n\n\nEmpirici\n1.18\n0.55\n\n\nConfrontando questi risultati con le previsioni teoriche, notiamo che i dati empirici si avvicinano molto pi√π al modello dual-process (valore atteso: 1.20 vs.¬†1.18; varianza: 0.56 vs.¬†0.55).\nImplicazioni Psicologiche e Cliniche\n\nTeoriche: Il confronto tra distribuzioni osservate e teoriche, usando valore atteso e varianza, consente di identificare quale teoria cognitiva spieghi meglio i dati.\nCliniche: In contesti clinici (es. valutazione di deficit cognitivi), questo approccio consente di identificare se un paziente mostra un profilo riconducibile a un danno selettivo della recollection (R ‚Üì) o della familiarit√† (K ‚Üì).\n\nQuesto framework illustra come strumenti probabilistici di base possano tradurre ipotesi psicologiche complesse in predizioni quantitative verificabili, avanzando la comprensione dei meccanismi cognitivi.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  }
]